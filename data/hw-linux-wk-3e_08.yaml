- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: A Closer Look at Processes and Resource Utilization
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 更深入地了解进程和资源利用
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: 'This chapter takes you deeper into the relationships between processes, the
    kernel, and system resources. There are three basic kinds of hardware resources:
    CPU, memory, and I/O. Processes vie for these resources, and the kernel’s job
    is to allocate resources fairly. The kernel itself is also a resource—a software
    resource that processes use to perform tasks such as creating new processes and
    communicating with other processes.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将深入探讨进程、内核和系统资源之间的关系。硬件资源有三种基本类型：CPU、内存和 I/O。进程争夺这些资源，内核的任务是公平地分配资源。内核本身也是一种资源——一个软件资源，供进程用来执行诸如创建新进程和与其他进程通信等任务。
- en: Many of the tools that you see in this chapter are considered performance-monitoring
    tools. They’re particularly helpful if your system is slowing to a crawl and you’re
    trying to figure out why. However, you shouldn’t get distracted by performance.
    Trying to optimize a system that’s already working correctly is a waste of time.
    The default settings on most systems are well chosen, so you should change them
    only if you have very unusual needs. Instead, concentrate on understanding *what*
    the tools actually measure, and you’ll gain great insight into how the kernel
    works and how it interacts with processes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中你看到的许多工具被视为性能监控工具。当你的系统变得非常缓慢，你试图找出原因时，它们特别有用。然而，你不应该过于关注性能。试图优化一个已经正常工作的系统是浪费时间。大多数系统的默认设置已经经过精心选择，因此只有在你有非常特殊的需求时才应该更改它们。相反，应该专注于理解工具实际衡量的*内容*，这样你将深入了解内核的工作方式以及它如何与进程交互。
- en: 8.1 Tracking Processes
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 跟踪进程
- en: You learned how to use `ps` in Section 2.16 to list processes running on your
    system at a particular time. The `ps` command lists current processes and their
    usage statistics, but it does little to tell you how processes change over time.
    Therefore, it won’t immediately help you to determine which process is using too
    much CPU time or memory.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 2.16 节中，你学会了如何使用 `ps` 命令列出在特定时间运行的系统进程。`ps` 命令列出了当前的进程及其使用统计信息，但它对进程如何随时间变化几乎没有提供帮助。因此，它并不会立即帮助你确定哪个进程占用了过多的
    CPU 时间或内存。
- en: The `top` program provides an interactive interface to the information that
    `ps` displays. It shows the current system status as well as the fields a `ps`
    listing shows, and it updates every second. Perhaps most important, `top` lists
    the most active processes (by default, those currently taking up the most CPU
    time) at the top of its display.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '`top` 程序提供了一个交互式界面，用于显示 `ps` 命令显示的信息。它展示了当前的系统状态以及 `ps` 列表中的字段，并且每秒更新一次。或许最重要的是，`top`
    会将最活跃的进程（默认情况下是当前占用最多 CPU 时间的进程）列在显示的顶部。'
- en: 'You can send commands to `top` with keystrokes. Its most frequently used commands
    deal with changing the sort order or filtering the process list:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过按键向 `top` 发送命令。其最常用的命令是更改排序顺序或过滤进程列表：
- en: Spacebar Updates the display immediately
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 空格键 立即更新显示
- en: M Sorts by current resident memory usage
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: M 按当前常驻内存使用量排序
- en: T Sorts by total (cumulative) CPU usage
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: T 按总 (累计) CPU 使用量排序
- en: P Sorts by current CPU usage (the default)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: P 按当前 CPU 使用率排序（默认）
- en: u Displays only one user’s processes
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: u 显示仅一个用户的进程
- en: f Selects different statistics to display
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: f 选择显示不同的统计数据
- en: '? Displays a usage summary for all `top` commands'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '? 显示所有 `top` 命令的使用摘要'
- en: Two similar utilities, `atop` and `htop`, offer an enhanced set of views and
    features. Most of their extra features add functionality found in other tools.
    For example, `htop` shares many of the `lsof` command’s abilities described in
    the next section.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`atop` 和 `htop` 两个相似的工具提供了增强的视图和功能集。它们的大多数额外功能添加了其他工具中存在的功能。例如，`htop` 共享了许多在下一节中描述的
    `lsof` 命令的功能。'
- en: 8.2 Finding Open Files with lsof
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 使用 lsof 查找打开的文件
- en: The `lsof` command lists open files and the processes using them. Because Unix
    places a lot of emphasis on files, `lsof` is among the most useful tools for finding
    trouble spots. But `lsof` doesn’t stop at regular files—it can list network resources,
    dynamic libraries, pipes, and more.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`lsof` 命令列出了打开的文件以及使用它们的进程。因为 Unix 非常重视文件，`lsof` 是找出故障点时最有用的工具之一。但是，`lsof`
    不仅仅局限于常规文件——它还可以列出网络资源、动态库、管道等。'
- en: 8.2.1 Reading the lsof Output
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 阅读 lsof 输出
- en: 'Running `lsof` on the command line usually produces a tremendous amount of
    output. The following is a fragment of what you might see. This output (slightly
    adjusted for readability) includes open files from the systemd (init) process
    as well as a running `vi` process:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在命令行运行 `lsof` 通常会产生大量的输出。以下是你可能会看到的一部分。这些输出（略作调整以提高可读性）包括了来自 systemd（init）进程以及正在运行的
    `vi` 进程的打开文件：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output lists the following fields in the top row:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 输出在顶部行列出以下字段：
- en: '`COMMAND` The command name for the process that holds the file descriptor.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`COMMAND` 持有文件描述符的进程的命令名称。'
- en: '`PID` The process ID.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`PID` 进程ID。'
- en: '`USER` The user running the process.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`USER` 运行进程的用户。'
- en: '`FD` This field can contain two kinds of elements. In most of the preceding
    output, the `FD` column shows the purpose of the file. The `FD` field can also
    list the *file descriptor* of the open file—a number that a process uses together
    with the system libraries and kernel to identify and manipulate a file; the last
    line shows a file descriptor of `3`.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`FD` 该字段可以包含两种元素。在前面的输出中，`FD` 列显示文件的用途。`FD` 字段还可以列出打开文件的 *文件描述符* —— 这是进程与系统库和内核一起用来标识和操作文件的数字；最后一行显示了一个文件描述符为
    `3` 的文件。'
- en: '`TYPE` The file type (regular file, directory, socket, and so on).'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`TYPE` 文件类型（常规文件、目录、套接字等）。'
- en: '`DEVICE` The major and minor number of the device that holds the file.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DEVICE` 持有文件的设备的主次设备号。'
- en: '`SIZE/OFF` The file’s size.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SIZE/OFF` 文件的大小。'
- en: '`NODE` The file’s inode number.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`NODE` 文件的 inode 号。'
- en: '`NAME` The filename.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`NAME` 文件名。'
- en: The lsof(1) manual page contains a full list of what you might see for each
    field, but the output should be self-explanatory. For example, look at the entries
    with `cwd` in the `FD` field. Those lines indicate the current working directories
    of the processes. Another example is the very last line, which shows a temporary
    file that a user’s `vi` process (PID 1994) is using.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`lsof(1)` 手册页包含了你可能在每个字段中看到的完整列表，但输出应该是自解释的。例如，查看 `FD` 字段中带有 `cwd` 的条目。这些行表示进程的当前工作目录。另一个例子是最后一行，它显示了一个用户的
    `vi` 进程（PID 1994）正在使用的临时文件。'
- en: 8.2.2 Using lsof
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 使用 lsof
- en: 'There are two basic approaches to running `lsof`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `lsof` 有两种基本方法：
- en: List everything and pipe the output to a command like `less`, and then search
    for what you’re looking for. This can take a while due to the amount of output
    generated.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出所有内容并将输出管道传输到像 `less` 这样的命令，然后搜索你要查找的内容。由于输出量巨大，这可能需要一些时间。
- en: Narrow down the list that `lsof` provides with command-line options.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用命令行选项缩小 `lsof` 提供的列表。
- en: 'You can use command-line options to provide a filename as an argument and have
    `lsof` list only the entries that match the argument. For example, the following
    command displays entries for open files in */usr* and all of its subdirectories:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用命令行选项提供一个文件名作为参数，让 `lsof` 只列出匹配该参数的条目。例如，以下命令显示了在 */usr* 及其所有子目录中打开的文件条目：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To list the open files for a particular process ID, run:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要列出某个特定进程ID的打开文件，请运行：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For a brief summary of `lsof`’s many options, run `lsof -h`. Most options pertain
    to the output format. (See Chapter 10 for a discussion of the `lsof` network features.)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要简要查看 `lsof` 的众多选项，请运行 `lsof -h`。大多数选项与输出格式有关。（有关 `lsof` 网络功能的讨论，请参见第10章。）
- en: 8.3 Tracing Program Execution and System Calls
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 跟踪程序执行和系统调用
- en: The tools we’ve seen so far examine active processes. However, if you have no
    idea why a program dies almost immediately after starting up, `lsof` won’t help
    you. In fact, you’d have a difficult time even running `lsof` concurrently with
    a failed command.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们到目前为止看到的工具检查的是活动进程。然而，如果你根本不知道为什么程序在启动后几乎立即死掉，`lsof` 是帮不上忙的。事实上，你甚至很难在命令失败时同时运行
    `lsof`。
- en: The `strace` (system call trace) and `ltrace` (library trace) commands can help
    you discover what a program attempts to do. Those tools produce extraordinarily
    large amounts of output, but once you know what to look for, you’ll have more
    information at your disposal for tracking down problems.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`strace`（系统调用跟踪）和 `ltrace`（库跟踪）命令可以帮助你发现程序试图执行的操作。这些工具会产生非常大量的输出，但一旦你知道该查找什么，你将能够获得更多的信息来追踪问题。'
- en: 8.3.1 strace
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.1 strace
- en: 'Recall that a *system call* is a privileged operation that a user-space process
    asks the kernel to perform, such as opening and reading data from a file. The
    `strace` utility prints all the system calls that a process makes. To see it in
    action, run this command:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，*系统调用*是用户空间进程请求内核执行的特权操作，比如打开文件并读取数据。`strace`工具会打印进程执行的所有系统调用。要查看它的实际操作，运行以下命令：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: By default, `strace` sends its output to the standard error. If you want to
    save the output in a file, use the `-o` `save_file` option. You can also redirect
    by appending `2>` `save_file` to your command line, but you’ll also capture any
    standard error from the command you’re examining.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`strace`将其输出发送到标准错误。如果你想将输出保存到文件中，可以使用`-o` `save_file`选项。你也可以通过在命令行中附加`2>`
    `save_file`来重定向输出，但这也会捕获你正在检查的命令的任何标准错误。
- en: 'In Chapter 1, you learned that when one process wants to start another process,
    it invokes the `fork()` system call to spawn a copy of itself, and then the copy
    uses a member of the `exec()` family of system calls to start running a new program.
    The `strace` command begins working on the new process (the copy of the original
    process) just after the `fork()` call. Therefore, the first lines of the output
    from this command should show `execve()` in action, followed by a memory initialization
    call, `brk()`, as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1章中，你学到当一个进程想要启动另一个进程时，它调用`fork()`系统调用来生成自己的副本，然后副本使用`exec()`系列系统调用中的一个来启动新程序。`strace`命令在`fork()`调用之后开始跟踪新进程（即原始进程的副本）。因此，来自此命令的输出的第一行应该显示`execve()`的执行，接着是内存初始化调用`brk()`，如下所示：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The next part of the output deals primarily with loading shared libraries.
    You can ignore this unless you really want to dig deep into the shared library
    system:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的下一部分主要涉及加载共享库。除非你真的想深入研究共享库系统，否则可以忽略这一部分：
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In addition, skip past the `mmap` output until you get to the lines near the
    end of the output that look like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，跳过`mmap`输出，直到你看到输出末尾附近的类似如下的行：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This part of the output shows the command at work. First, look at the `openat()`
    call (a slight variant of `open()`), which opens a file. The `3` is a result that
    means success (`3` is the file descriptor that the kernel returns after opening
    the file). Below that, you can see where `cat` reads from */dev/null* (the `read()`
    call, which also has `3` as the file descriptor). Then there’s nothing more to
    read, so the program closes the file descriptor and exits with `exit_group()`.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分输出展示了命令的执行情况。首先，查看`openat()`调用（`open()`的一个略微变化），它打开了一个文件。`3`是一个表示成功的结果（`3`是内核在打开文件后返回的文件描述符）。在其下方，你可以看到`cat`从*/dev/null*读取数据（即`read()`调用，文件描述符也是`3`）。然后没有更多的内容可以读取，所以程序关闭文件描述符并通过`exit_group()`退出。
- en: 'What happens when the command encounters an error? Try `strace cat``not_a_file`
    instead and examine the `open()` call in the resulting output:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当命令遇到错误时会发生什么？尝试运行`strace cat` `not_a_file`并检查结果输出中的`open()`调用：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Because `open()` couldn’t open the file, it returned `-1` to signal an error.
    You can see that `strace` reports the exact error and gives you a short description
    of the error.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 因为`open()`无法打开文件，所以它返回`-1`以指示错误。你可以看到`strace`报告了具体的错误，并给出了简短的错误描述。
- en: 'Missing files are the most common problem with Unix programs, so if the system
    log and other log information aren’t very helpful and you have nowhere else to
    turn when you’re trying to track down a missing file, `strace` can be of great
    use. You can even use it on daemons that fork or detach themselves. For example,
    to track down the system calls of a fictitious daemon called `crummyd`, enter:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 丢失的文件是Unix程序中最常见的问题，因此，如果系统日志和其他日志信息没有提供太多帮助，而且你在追踪丢失的文件时别无他法，`strace`可以发挥很大的作用。你甚至可以在那些会`fork()`或自我分离的守护进程上使用它。例如，要追踪一个名为`crummyd`的虚拟守护进程的系统调用，可以输入：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In this example, the `-o` option to `strace` logs the action of any child process
    that `crummyd` spawns into `crummyd_strace.``pid`, where `pid` is the process
    ID of the child process.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，`strace`的`-o`选项将`crummyd`产生的任何子进程的操作记录到`crummyd_strace.` `pid`文件中，其中`pid`是子进程的进程ID。
- en: 8.3.2 ltrace
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.2 ltrace
- en: The `ltrace` command tracks shared library calls. The output is similar to that
    of `strace`, which is why it’s being mentioned here, but it doesn’t track anything
    at the kernel level. Be warned that there are *many* more shared library calls
    than system calls. You’ll definitely need to filter the output, and `ltrace` itself
    has many built-in options to assist you.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`ltrace`命令跟踪共享库调用。它的输出与`strace`类似，因此在这里提到它，但它不会跟踪内核级别的任何内容。请注意，*共享库调用*比系统调用要多得多。你肯定需要过滤输出，`ltrace`本身有很多内建选项可以帮助你。'
- en: 8.4 Threads
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 线程
- en: In Linux, some processes are divided into pieces called *threads*. A thread
    is very similar to a process—it has an identifier (*thread ID*, or *TID*), and
    the kernel schedules and runs threads just like processes. However, unlike separate
    processes, which usually don’t share system resources such as memory and I/O connections
    with other processes, all threads inside a single process share their system resources
    and some memory.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux中，一些进程被划分为称为*线程*的部分。线程与进程非常相似——它有一个标识符（*线程ID*，或*TID*），并且内核像调度进程一样调度和运行线程。然而，不同于独立进程通常不共享系统资源（如内存和I/O连接），同一进程中的所有线程共享其系统资源和部分内存。
- en: 8.4.1 Single-Threaded and Multithreaded Processes
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.1 单线程和多线程进程
- en: Many processes have only one thread. A process with one thread is *single-threaded*,
    and a process with more than one thread is *multithreaded*. All processes start
    out single-threaded. This starting thread is usually called the *main thread*.
    The main thread may start new threads, making the process multithreaded, similar
    to the way a process can call `fork()` to start a new process.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 许多进程只有一个线程。一个有一个线程的进程是*单线程*的，而一个有多个线程的进程是*多线程*的。所有进程在启动时都是单线程的。这个起始线程通常称为*主线程*。主线程可能会启动新的线程，使进程变为多线程，类似于进程通过调用`fork()`启动一个新进程。
- en: The primary advantage of a multithreaded process is that when the process has
    a lot to do, threads can run simultaneously on multiple processors, potentially
    speeding up computation. Although you can also achieve simultaneous computation
    with multiple processes, threads start faster than processes, and it’s often easier
    or more efficient for threads to intercommunicate using their shared memory than
    it is for processes to communicate over a channel, such as a network connection
    or a pipe.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程进程的主要优势是，当进程有很多任务需要执行时，线程可以在多个处理器上同时运行，从而可能加速计算。尽管使用多个进程也能实现并行计算，但线程的启动速度比进程快，而且线程之间通常比进程通过网络连接或管道等通道进行通信更容易或更高效，因为它们共享内存。
- en: Some programs use threads to overcome problems managing multiple I/O resources.
    Traditionally, a process would sometimes use `fork()` to start a new subprocess
    in order to deal with a new input or output stream. Threads offer a similar mechanism
    without the overhead of starting a new process.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一些程序使用线程来克服管理多个I/O资源的问题。传统上，进程有时会使用`fork()`启动一个新的子进程，以处理新的输入或输出流。线程提供了类似的机制，但没有启动新进程的开销。
- en: 8.4.2 Viewing Threads
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.2 查看线程
- en: By default, the output from the `ps` and `top` commands shows only processes.
    To display the thread information in `ps`, add the `m` option. [Listing 8-1](#listing8-1)
    shows some sample output.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`ps`和`top`命令的输出只显示进程。要在`ps`中显示线程信息，需添加`m`选项。[清单 8-1](#listing8-1)展示了一些示例输出。
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Listing 8-1: Viewing threads with `ps m`'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 8-1：使用`ps m`查看线程
- en: This listing shows processes along with threads. Each line with a number in
    the PID column (at 1, 2, and 3) represents a process, as in the normal `ps` output.
    The lines with dashes in the PID column represent the threads associated with
    the process. In this output, the processes at 1 and 2 have only one thread each,
    but process 12534 at 3 is multithreaded, with four threads.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这个清单显示了进程及其线程。PID列中带有数字的每一行（在1、2和3的位置）表示一个进程，类似于正常的`ps`输出。PID列中带有破折号的行表示与进程关联的线程。在这个输出中，1和2位置的进程每个只有一个线程，但3位置的进程12534是多线程的，有四个线程。
- en: 'If you want to view the TIDs with `ps`, you can use a custom output format.
    [Listing 8-2](#listing8-2) shows only the PIDs, TIDs, and command:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用`ps`查看TID，你可以使用自定义输出格式。[清单 8-2](#listing8-2)仅显示PID、TID和命令：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Listing 8-2: Showing PIDs and TIDs with `ps m`'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 8-2：使用`ps m`显示PID和TID
- en: The sample output in this listing corresponds to the threads shown in [Listing
    8-1](#listing8-1). Notice that the TIDs of the single-threaded processes are identical
    to the PIDs; this is the main thread. For the multithreaded process 12534, thread
    12534 is also the main thread.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 本列表中的示例输出对应于[列表8-1](#listing8-1)中显示的线程。请注意，单线程进程的TID与PID相同；这就是主线程。对于多线程进程12534，线程12534也是主线程。
- en: Threads can confuse things when it comes to resource monitoring because individual
    threads in a multithreaded process can consume resources simultaneously. For example,
    `top` doesn’t show threads by default; you’ll need to press H to turn it on. For
    most of the resource monitoring tools that you’re about to see, you’ll have to
    do a little extra work to turn on the thread display.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 线程在资源监控中可能会引起混淆，因为多线程进程中的各个线程可以同时消耗资源。例如，`top`默认不显示线程；你需要按H来启用它。对于你即将看到的大多数资源监控工具，你需要做一些额外的操作才能启用线程显示。
- en: 8.5 Introduction to Resource Monitoring
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 资源监控简介
- en: Now we’ll discuss some topics in resource monitoring, including processor (CPU)
    time, memory, and disk I/O. We’ll examine utilization on a system-wide scale,
    as well as on a per-process basis.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将讨论一些资源监控的话题，包括处理器（CPU）时间、内存和磁盘I/O。我们将从系统范围和每个进程的角度来检查利用率。
- en: Many people touch the inner workings of the Linux kernel in the interest of
    improving performance. However, most Linux systems perform well under a distribution’s
    default settings, and you can spend days trying to tune your machine’s performance
    without meaningful results, especially if you don’t know what to look for. So
    rather than think about performance as you experiment with the tools in this chapter,
    think about seeing the kernel in action as it divides resources among processes.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人为了提高性能而接触Linux内核的内部机制。然而，大多数Linux系统在默认设置下已经能够很好地运行，你可以花费几天时间调整机器的性能，但如果你不知道该关注什么，可能得不到有意义的结果。所以，在你实验本章工具时，不要考虑性能，而是要关注观察内核如何在各个进程间分配资源。
- en: 8.5.1 Measuring CPU Time
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5.1 测量CPU时间
- en: 'To monitor one or more specific processes over time, use the `-p` option to
    `top`, with this syntax:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要随时间监控一个或多个特定进程，可以使用`top`的`-p`选项，语法如下：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To find out how much CPU time a command uses during its lifetime, use `time`.
    Unfortunately, there is some confusion here, because most shells have a built-in
    `time` command that doesn’t provide extensive statistics, and there’s a system
    utility at `/usr/bin/time`. You’ll probably encounter the `bash` shell built-in
    first, so try running `time` with the `ls` command:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解一个命令在其生命周期内使用了多少CPU时间，可以使用`time`。不幸的是，这里有一些混淆，因为大多数shell都有内置的`time`命令，它提供的统计信息并不丰富，而在`/usr/bin/time`中有一个系统工具。你可能首先遇到的是`bash`的内置命令，因此尝试使用`ls`命令运行`time`：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After `ls` terminates, `time` should print output like the following:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ls`终止后，`time`应该打印出类似以下的输出：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '*User time* (`user`) is the number of seconds that the CPU has spent running
    the program’s *own* code. Some commands run so quickly that the CPU time is close
    to 0\. The *system time* (`sys` or `system`) is how much time the kernel spends
    doing the process’s work (for example, reading files and directories). Finally,
    real time (`real`) (also called *elapsed time*) is the total time it took to run
    the process from start to finish, including the time that the CPU spent doing
    other tasks. This number is normally not very useful for performance measurement,
    but subtracting the user and system time from elapsed time can give you a general
    idea of how long a process spends waiting for system and external resources. For
    example, the time spent waiting for a network server to respond to a request would
    show up in the elapsed time, but not in the user or system time.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*用户时间*（`user`）是CPU运行程序的*自有*代码所花费的秒数。有些命令执行得非常快，以至于CPU时间接近0。*系统时间*（`sys`或`system`）是内核执行进程工作所花费的时间（例如，读取文件和目录）。最后，真实时间（`real`）（也叫*经过时间*）是从开始到结束运行进程所花费的总时间，包括CPU执行其他任务的时间。这个数字通常对性能测量不是很有用，但从经过时间中减去用户时间和系统时间，可以大致了解进程在等待系统和外部资源上的时间。例如，等待网络服务器响应请求所花费的时间会显示在经过时间中，但不会显示在用户时间或系统时间中。'
- en: 8.5.2 Adjusting Process Priorities
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5.2 调整进程优先级
- en: You can change the way the kernel schedules a process in order to give the process
    more or less CPU time than other processes. The kernel runs each process according
    to its scheduling *priority*, which is a number between –20 and 20, with –20 being
    the foremost priority. (Yes, this can be confusing.)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以改变内核如何调度进程，从而使该进程比其他进程获取更多或更少的 CPU 时间。内核根据进程的调度 *优先级* 运行每个进程，优先级是一个介于 –20
    和 20 之间的数字，其中 –20 代表最高优先级。（是的，这可能会让人感到困惑。）
- en: 'The `ps -l` command lists the current priority of a process, but it’s a little
    easier to see the priorities in action with the `top` command, as shown here:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`ps -l` 命令列出了进程的当前优先级，但通过 `top` 命令查看优先级的实际效果会更直观，如下所示：'
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this `top` output, the `PR` (priority) column lists the kernel’s current
    schedule priority for the process. The higher the number, the less likely the
    kernel is to schedule the process if others need CPU time. The schedule priority
    alone doesn’t determine the kernel’s decision to give CPU time to a process, however,
    and the kernel may also change the priority during program execution according
    to the amount of CPU time the process consumes.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个 `top` 输出中，`PR`（优先级）列列出了内核为该进程分配的当前调度优先级。数字越大，内核在其他进程需要 CPU 时间时调度该进程的可能性就越小。然而，仅凭调度优先级并不能完全决定内核是否分配
    CPU 时间给一个进程，内核还可能根据进程消耗的 CPU 时间在程序执行过程中调整优先级。
- en: Next to the priority column is the `NI` (*nice value*) column, which gives a
    hint to the kernel’s scheduler. This is what you care about when trying to influence
    the kernel’s decision. The kernel adds the nice value to the current priority
    to determine the next time slot for the process. When you set the nice value higher,
    you’re being “nicer” to other processes because the kernel prioritizes them.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在优先级列旁边是 `NI`（*nice 值*）列，它向内核调度器提供了一个提示。这是你在尝试影响内核决策时需要关注的内容。内核将 nice 值与当前优先级相加，确定下一个进程的时间片。当你将
    nice 值设置得更高时，你是在对其他进程“更友好”，因为内核会优先考虑这些进程。
- en: 'By default, the nice value is 0\. Now, say you’re running a big computation
    in the background that you don’t want to bog down your interactive session. To
    make that process take a back seat to other processes and run only when the other
    tasks have nothing to do, you can change the nice value to 20 with the `renice`
    command (where `pid` is the process ID of the process that you want to change):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，nice 值为 0。如果你正在后台运行一个大规模的计算任务，而不希望它影响到你的交互式会话，你可以通过 `renice` 命令将该进程的 nice
    值更改为 20，使得该进程在其他任务没有工作时才会运行（其中 `pid` 是你要更改的进程的进程 ID）：
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If you’re the superuser, you can set the nice value to a negative number, but
    doing so is almost always a bad idea because system processes may not get enough
    CPU time. In fact, you probably won’t need to alter nice values much because many
    Linux systems have only a single user, and that user doesn’t perform much real
    computation. (The nice value was much more important back when there were many
    users on a single machine.)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是超级用户，你可以将 nice 值设置为负数，但这样做几乎总是个坏主意，因为系统进程可能得不到足够的 CPU 时间。事实上，你可能不需要经常更改
    nice 值，因为许多 Linux 系统只有一个用户，而这个用户并不进行大量的实际计算。（nice 值在多用户共享单台机器时更为重要。）
- en: 8.5.3 Measuring CPU Performance with Load Averages
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5.3 使用负载平均值衡量 CPU 性能
- en: Overall CPU performance is one of the easier metrics to measure. The *load average*
    is the average number of processes currently ready to run. That is, it is an estimate
    of the number of processes that are *capable* of using the CPU at any given time—this
    includes processes that are running and those that are waiting for a chance to
    use the CPU. When thinking about a load average, keep in mind that most processes
    on your system are usually waiting for input (from the keyboard, mouse, or network,
    for example), meaning they’re not ready to run and shouldn’t contribute anything
    to the load average. Only processes that are actually doing something affect the
    load average.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 整体 CPU 性能是最容易衡量的指标之一。*负载平均值* 是当前准备运行的进程的平均数量。也就是说，它是任何给定时刻能够使用 CPU 的进程数量的估计——这包括正在运行的进程以及那些等待使用
    CPU 的进程。在考虑负载平均值时，请记住，系统中的大多数进程通常在等待输入（例如来自键盘、鼠标或网络的输入），这意味着它们没有准备好运行，因此不应对负载平均值产生影响。只有那些实际在执行某些任务的进程才会影响负载平均值。
- en: Using uptime
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 uptime
- en: 'The `uptime` command tells you three load averages in addition to how long
    the kernel has been running:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`uptime` 命令除了显示内核运行的时间外，还会告诉你三个负载平均值：'
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The three bolded numbers are the load averages for the past 1 minute, 5 minutes,
    and 15 minutes, respectively. As you can see, this system isn’t very busy: an
    average of only 0.01 processes have been running across all processors for the
    past 15 minutes. In other words, if you had just one processor, it was running
    user-space applications for only 1 percent of the last 15 minutes.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个加粗的数字分别表示过去1分钟、5分钟和15分钟的负载平均值。如你所见，这个系统并不是很繁忙：在过去的15分钟里，所有处理器上平均只有0.01个进程在运行。换句话说，如果你只有一个处理器，它在过去的15分钟里只有1%的时间在运行用户空间应用程序。
- en: Traditionally, most desktop systems would exhibit a load average of about 0
    when you were doing anything *except* compiling a program or playing a game. A
    load average of 0 is usually a good sign, because it means that your processor
    isn’t being challenged and you’re saving power.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，大多数桌面系统在你进行任何操作时，负载平均值大约为0，*除了*编译程序或玩游戏以外。负载平均值为0通常是一个好兆头，因为这意味着处理器没有受到挑战，你也节省了电力。
- en: However, user interface components on current desktop systems tend to occupy
    more of the CPU than those in the past. In particular, certain websites (and especially
    their advertisements) cause web browsers to become resource hogs.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当前桌面系统上的用户界面组件通常会占用更多的CPU资源，尤其是某些网站（尤其是它们的广告）导致Web浏览器变成资源消耗大户。
- en: If a load average goes up to around 1, a single process is probably using the
    CPU nearly all of the time. To identify that process, use the `top` command; the
    process will usually rise to the top of the display.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果负载平均值上升到大约1，可能是某个单一进程几乎一直在使用CPU。要识别这个进程，可以使用`top`命令；该进程通常会出现在显示的顶部。
- en: Most modern systems have more than one processor core or CPU, so multiple processes
    can easily run simultaneously. If you have two cores, a load average of 1 means
    that only one of the cores is likely active at any given time, and a load average
    of 2 means that both cores have just enough to do all of the time.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现代系统大多数都有多个处理器核心或CPU，因此多个进程可以轻松并行运行。如果你有两个核心，负载平均值为1意味着任何给定时刻只有一个核心可能在活动，而负载平均值为2则意味着两个核心的工作量恰好足够它们全天候运行。
- en: Managing High Loads
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 管理高负载
- en: A high load average doesn’t necessarily mean that your system is having trouble.
    A system with enough memory and I/O resources can easily handle many running processes.
    If your load average is high and your system still responds well, don’t panic;
    the system just has a lot of processes sharing the CPU. The processes have to
    compete with one another for processor time, and as a result, they’ll take longer
    to perform their computations than they would if they were each allowed to use
    the CPU all the time. Another case where a high load average might be normal is
    with a web or compute server, where processes can start and terminate so quickly
    that the load average measurement mechanism can’t function effectively.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 高负载平均值并不一定意味着你的系统出现问题。如果系统拥有足够的内存和I/O资源，它可以轻松地处理许多正在运行的进程。如果你的负载平均值很高且系统响应良好，不要惊慌；系统只是在大量进程共享CPU资源。这些进程必须相互竞争处理器时间，因此它们需要比平时更长时间才能完成计算。另一个高负载平均值可能是正常的情况是在Web服务器或计算服务器上，进程的启动和终止非常迅速，以至于负载平均值的测量机制无法有效地工作。
- en: However, if the load average is very high and you sense that the system is slowing
    down, you might be running into memory performance problems. When the system is
    low on memory, the kernel can start to *thrash*, or rapidly swap memory to and
    from the disk. When this happens, many processes will become ready to run, but
    their memory might not be available, so they’ll remain in the ready-to-run state
    (contributing to the load average) for much longer than they normally would. Next
    we’ll look at why this can happen by exploring memory in more detail.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果负载平均值非常高，并且你感觉系统变慢了，可能是遇到了内存性能问题。当系统内存不足时，内核可能会开始*交换*，或者迅速将内存交换到磁盘上并再交换回来。当这种情况发生时，许多进程会变得准备就绪，但是它们的内存可能不可用，因此它们会保持在准备就绪状态（导致负载平均值增高），比正常情况下停留的时间要长得多。接下来，我们将通过更详细地探讨内存，来了解为什么会发生这种情况。
- en: 8.5.4 Monitoring Memory Status
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5.4 监控内存状态
- en: One of the simplest ways to check your system’s memory status as a whole is
    to run the `free` command or view */proc/meminfo* to see how much real memory
    is being used for caches and buffers. As just mentioned, performance problems
    can arise from memory shortages. If not much cache/buffer memory is being used
    (and the rest of the real memory is taken), you may need more memory. However,
    it’s too easy to blame a shortage of memory for every performance problem on your
    machine.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 检查系统内存状态的最简单方法之一是运行`free`命令或查看*/proc/meminfo*，看看有多少真实内存用于缓存和缓冲区。如前所述，性能问题可能是由于内存不足引起的。如果没有使用太多缓存/缓冲区内存（而其余的真实内存已被占用），你可能需要更多内存。然而，将每个性能问题归咎于内存不足是过于简单的做法。
- en: How Memory Works
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 内存工作原理
- en: As Chapter 1 explained, the CPU has a memory management unit (MMU) to add flexibility
    in memory access. The kernel assists the MMU by breaking down the memory used
    by processes into smaller chunks called *pages*. The kernel maintains a data structure,
    called a *page table*, that maps a process’s virtual page addresses to real page
    addresses in memory. As a process accesses memory, the MMU translates the virtual
    addresses used by the process into real addresses based on the kernel’s page table.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如第一章所解释的，CPU有一个内存管理单元（MMU），它为内存访问提供灵活性。内核通过将进程使用的内存分解为称为*页面*的较小块来协助MMU。内核维护一个数据结构，称为*页表*，它将进程的虚拟页面地址映射到内存中的真实页面地址。当进程访问内存时，MMU根据内核的页表将进程使用的虚拟地址转换为真实地址。
- en: 'A user process doesn’t actually need all of its memory pages to be immediately
    available in order to run. The kernel generally loads and allocates pages as a
    process needs them; this system is known as *on-demand paging* or just *demand
    paging*. To see how this works, consider how a program starts and runs as a new
    process:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 用户进程实际上并不需要所有内存页面立即可用才能运行。内核通常会根据进程的需要加载和分配页面；这种系统被称为*按需分页*，或简称为*需求分页*。为了理解这个过程，考虑程序如何作为新进程启动和运行：
- en: The kernel loads the beginning of the program’s instruction code into memory
    pages.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内核将程序指令代码的开头加载到内存页面中。
- en: The kernel may allocate some working-memory pages to the new process.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内核可能会为新进程分配一些工作内存页面。
- en: As the process runs, it might reach a point where the next instruction in its
    code isn’t in any of the pages that the kernel initially loaded. At this point,
    the kernel takes over, loads the necessary page into memory, and then lets the
    program resume execution.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当进程运行时，它可能会到达一个点，此时其代码中的下一条指令并不在内核最初加载的任何页面中。此时，内核接管，加载必要的页面到内存中，然后让程序继续执行。
- en: Similarly, if the program requires more working memory than was initially allocated,
    the kernel handles it by finding free pages (or by making room) and assigning
    them to the process.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，如果程序需要比最初分配的更多工作内存，内核会通过寻找空闲页面（或腾出空间）并分配给进程来处理。
- en: 'You can get a system’s page size by looking at the kernel configuration:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过查看内核配置来获取系统的页面大小：
- en: '[PRE17]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This number is in bytes, and 4k is typical for most Linux systems.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数字是以字节为单位的，对于大多数Linux系统，4k是典型的值。
- en: The kernel does not arbitrarily map pages of real memory to virtual addresses;
    that is, it does not put all of the available pages into one big pool and allocate
    from there. Real memory has many divisions that depend on hardware limitations,
    kernel optimization of contiguous pages, and other factors. However, you shouldn’t
    worry about any of this when you’re just getting started.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 内核不会随意将真实内存页面映射到虚拟地址；也就是说，它不会把所有可用的页面放入一个大池中并从中分配。真实内存有许多分区，这些分区依赖于硬件限制、内核对连续页面的优化以及其他因素。然而，当你刚开始学习时，不必担心这些细节。
- en: Page Faults
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 页面错误
- en: 'If a memory page isn’t ready when a process wants to use it, the process triggers
    a *page fault*. In the event of a page fault, the kernel takes control of the
    CPU from the process in order to get the page ready. There are two kinds of page
    faults: minor and major.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果进程想要使用的内存页面还没准备好，进程会触发一个*页面错误*。在页面错误发生时，内核从进程那里接管CPU，以准备该页面。页面错误有两种类型：轻微页面错误和重大页面错误。
- en: Minor page faults
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 轻微页面错误
- en: A *minor page fault* occurs when the desired page is actually in main memory,
    but the MMU doesn’t know where it is. This can happen when the process requests
    more memory or when the MMU doesn’t have enough space to store all of the page
    locations for a process (the MMU’s internal mapping table is usually quite small).
    In this case, the kernel tells the MMU about the page and permits the process
    to continue. Minor page faults are nothing to worry about, and many occur as a
    process runs.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*次要页错误*发生在所需页面实际上已经在主内存中，但内存管理单元（MMU）不知道它的位置。这可能发生在进程请求更多内存时，或者当MMU没有足够的空间存储所有进程的页面位置时（MMU的内部映射表通常很小）。在这种情况下，内核会告知MMU页面的位置，并允许进程继续执行。次要页错误不需要担心，许多次要页错误会在进程运行时发生。'
- en: Major page faults
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 重大页错误
- en: A *major page fault* occurs when the desired memory page isn’t in main memory
    at all, which means that the kernel must load it from the disk or some other slow
    storage mechanism. A lot of major page faults will bog the system down, because
    the kernel must do a substantial amount of work to provide the pages, robbing
    normal processes of their chance to run.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*重大页错误*发生在所需的内存页根本不在主内存中时，这意味着内核必须从磁盘或其他较慢的存储机制加载它。大量的重大页错误会拖慢系统速度，因为内核必须进行大量工作才能提供这些页面，剥夺了正常进程的运行机会。'
- en: Some major page faults are unavoidable, such as those that occur when you load
    the code from disk when running a program for the first time. The biggest problems
    happen when you start running out of memory, which forces the kernel to start
    swapping pages of working memory out to the disk in order to make room for new
    pages and can lead to thrashing.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一些重大页错误是不可避免的，例如首次运行程序时从磁盘加载代码时发生的错误。最大的难题出现在内存不足时，内核必须开始将工作内存的页面交换到磁盘，以便为新页面腾出空间，这可能导致频繁的页面交换。
- en: 'You can drill down to the page faults for individual processes with the `ps`,
    `top`, and `time` commands. You’ll need to use the system version of `time` (`/usr/bin/time`)
    instead of the shell built-in. The following shows a simple example of how the
    `time` command displays page faults (the output of the `cal` command is irrelevant,
    so we’re discarding it by redirecting it to */dev/null*):'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`ps`、`top`和`time`命令深入查看单个进程的页错误。您需要使用系统版本的`time`（`/usr/bin/time`），而不是Shell内建的版本。以下是`time`命令如何显示页错误的简单示例（`cal`命令的输出无关紧要，因此我们通过将其重定向到*/dev/null*来丢弃它）：
- en: '[PRE18]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see from the bolded text, when this program ran, there were 2 major
    page faults and 254 minor ones. The major page faults occurred when the kernel
    needed to load the program from the disk for the first time. If you ran this command
    again, you probably wouldn’t get any major page faults because the kernel would
    have cached the pages from the disk.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从加粗文本中所见，当此程序运行时，共发生了2个重大页错误和254个次要页错误。重大页错误发生在内核第一次需要从磁盘加载程序时。如果您再次运行此命令，您可能不会遇到任何重大页错误，因为内核会从磁盘缓存这些页面。
- en: If you’d rather see the page faults of processes as they’re running, use `top`
    or `ps`. When running `top`, use `f` to change the displayed fields and select
    `nMaj` as one of the columns to display the number of major page faults. Selecting
    `vMj` (the number of major page faults since the last update) can be helpful if
    you’re trying to track down a process that might be misbehaving.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望在进程运行时查看页错误，请使用`top`或`ps`。运行`top`时，使用`f`来更改显示字段，并选择`nMaj`作为其中一个列，以显示重大页错误的数量。如果您正在追踪可能出现问题的进程，选择`vMj`（自上次更新以来的重大页错误数量）可能会有所帮助。
- en: 'When using `ps`, you can use a custom output format to view the page faults
    for a particular process. Here’s an example for PID 20365:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`ps`时，您可以使用自定义输出格式查看特定进程的页错误。以下是PID为20365的示例：
- en: '[PRE19]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `MINFL` and `MAJFL` columns show the numbers of minor and major page faults.
    Of course, you can combine this with any other process selection options, as described
    in the ps(1) manual page.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`MINFL`和`MAJFL`列显示了次要和重大页错误的数量。当然，您可以结合任何其他进程选择选项，如ps(1)手册页中所述。'
- en: Viewing page faults by process can help you zero in on certain problematic components.
    However, if you’re interested in your system performance as a whole, you need
    a tool to summarize CPU and memory action across all processes.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 按进程查看页错误有助于您锁定某些问题组件。然而，如果您对系统的整体性能感兴趣，您需要一种工具来总结所有进程的CPU和内存活动。
- en: 8.5.5 Monitoring CPU and Memory Performance with vmstat
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5.5 使用vmstat监控CPU和内存性能
- en: Among the many tools available to monitor system performance, the `vmstat` command
    is one of the oldest, with minimal overhead. You’ll find it handy for getting
    a high-level view of how often the kernel is swapping pages in and out, how busy
    the CPU is, and how I/O resources are being utilized.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多用于监控系统性能的工具中，`vmstat`命令是最古老且开销最小的工具之一。你会发现它非常方便，能帮助你从高层次了解内核交换页面的频率、CPU的繁忙程度，以及I/O资源的使用情况。
- en: 'The trick to unlocking the power of `vmstat` is to understand its output. For
    example, here’s some output from `vmstat 2`, which reports statistics every two
    seconds:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 解锁`vmstat`功能的诀窍是理解其输出。例如，以下是`vmstat 2`的输出，每两秒报告一次统计数据：
- en: '[PRE20]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output falls into categories: `procs` for processes, `memory` for memory
    usage, `swap` for the pages pulled in and out of swap, `io` for disk usage, `system`
    for the number of times the kernel switches into kernel code, and `cpu` for the
    time used by different parts of the system.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 输出分为几个类别：`procs`表示进程，`memory`表示内存使用情况，`swap`表示交换进出的页面，`io`表示磁盘使用情况，`system`表示内核切换到内核代码的次数，`cpu`表示系统各部分使用的时间。
- en: The preceding output is typical for a system that isn’t doing much. You’ll usually
    start looking at the second line of output—the first one is an average for the
    entire uptime of the system. For example, here the system has 320,416KB of memory
    swapped out to the disk (`swpd`) and around 3,027,000KB (3GB) of real memory `free`.
    Even though some swap space is in use, the zero-valued `si` (swap-in) and `so`
    (swap-out) columns report that the kernel is not currently swapping anything in
    or out from the disk. The `buff` column indicates the amount of memory that the
    kernel is using for disk buffers (see Section 4.2.5).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出典型地反映了一个系统在没有太多活动时的情况。你通常会关注第二行输出——第一行是系统整个运行时间的平均值。例如，这里系统有320,416KB的内存被交换到磁盘（`swpd`），大约有3,027,000KB（3GB）的实际内存是`free`的。即使有一些交换空间正在使用，零值的`si`（swap-in）和`so`（swap-out）列表明内核当前并没有将任何数据从磁盘交换进或交换出。`buff`列显示了内核用于磁盘缓冲区的内存量（参见第4.2.5节）。
- en: On the far right, under the CPU heading, you can see the distribution of CPU
    time in the `us`, `sy`, `id`, and `wa`columns. Respectively, these list the percentage
    of time the CPU is spending on user tasks, system (kernel) tasks, idle time, and
    waiting for I/O. In the preceding example, there aren’t too many user processes
    running (they’re using a maximum of 1 percent of the CPU); the kernel is doing
    practically nothing, and the CPU is sitting around doing nothing 99 percent of
    the time.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在最右侧的CPU部分，你可以看到`us`、`sy`、`id`和`wa`列中的CPU时间分布。这些分别表示CPU在用户任务、系统（内核）任务、空闲时间和等待I/O上的时间百分比。在前面的示例中，用户进程并不多（它们使用最多1%的CPU）；内核几乎没有做任何事情，CPU99%的时间都处于空闲状态。
- en: '[Listing 8-3](#listing8-3) shows what happens when a big program starts up.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表8-3](#listing8-3)显示了一个大型程序启动时的情况。'
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Listing 8-3: Memory activity'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8-3：内存活动
- en: As you can see at 1 in [Listing 8-3](#listing8-3), the CPU starts to see some
    usage for an extended period, especially from user processes. Because there is
    enough free memory, the amount of cache and buffer space used starts to increase
    as the kernel uses the disk more.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如[列表8-3](#listing8-3)中1所示，CPU开始长时间有一些使用，尤其是用户进程的使用。由于有足够的空闲内存，随着内核使用磁盘的频率增加，缓存和缓冲区的使用量也开始增加。
- en: 'Later on, we see something interesting: notice at 2 that the kernel pulls some
    pages into memory that were once swapped out (the `si` column). This means the
    program that just ran probably accessed some pages shared by another process,
    which is common—many processes use the code in certain shared libraries only when
    starting up.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们看到一些有趣的情况：注意第2行，内核将一些曾经被交换出去的页面拉回到内存中（`si`列）。这意味着刚刚运行的程序可能访问了一些由其他进程共享的页面，这很常见——许多进程仅在启动时使用某些共享库中的代码。
- en: Also notice from the `b` column that a few processes are *blocked* (prevented
    from running) while waiting for memory pages. Overall, the amount of free memory
    is decreasing, but it’s nowhere near being depleted. There’s also a fair amount
    of disk activity, as indicated by the increasing numbers in the `bi` (blocks in)
    and `bo` (blocks out) columns.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，从`b`列可以看到，有几个进程被*阻塞*（不能运行），因为它们在等待内存页面。总体来看，空闲内存的量在减少，但仍远未耗尽。磁盘活动也相当频繁，正如`bi`（blocks
    in）和`bo`（blocks out）列中数字的增加所示。
- en: The output is quite different when you run out of memory. As the free space
    depletes, both the buffer and cache sizes decrease because the kernel increasingly
    needs the space for user processes. Once there is nothing left, you’ll see activity
    in the `so` (swapped out) column as the kernel starts moving pages onto the disk,
    at which point nearly all of the other output columns change to reflect the amount
    of work the kernel is doing. You see more system time, more data going in and
    out of the disk, and more processes blocked because the memory they want to use
    isn’t available (it has been swapped out).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当内存用尽时，输出会有所不同。随着空闲空间的减少，缓冲区和缓存的大小会缩小，因为内核越来越需要这些空间来处理用户进程。一旦没有剩余空间，你会在`so`（已交换出去）列中看到活动，因为内核开始将页面移到磁盘上，这时几乎所有其他输出列都会发生变化，反映出内核正在进行的工作量。你会看到更多的系统时间、更多数据进出磁盘，以及更多进程被阻塞，因为它们想使用的内存不可用（已被交换出去）。
- en: We haven’t explored all of the `vmstat` output columns. You can dig deeper into
    them in the vmstat(8) manual page, but you might need to learn more about kernel
    memory management first from a class or a book like Silberschatz, Gagne, and Galvin’s
    *Operating System Concepts*, 10th edition (Wiley, 2018), in order to understand
    them.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有探索完`vmstat`输出的所有列。你可以在`vmstat(8)`手册页中深入了解这些列，但你可能需要先通过课堂或像 Silberschatz、Gagne
    和 Galvin 的《操作系统概念》第10版（Wiley，2018）这样的书籍，学习更多关于内核内存管理的知识，才能理解它们。
- en: 8.5.6 I/O Monitoring
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5.6 I/O 监控
- en: By default, `vmstat` provides some general I/O statistics. Although you can
    get very detailed per-partition resource usage with `vmstat -d`, you might be
    overwhelmed by the amount of output resulting from this option. Instead, try a
    tool just for I/O called `iostat`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`vmstat` 提供一些通用的 I/O 统计信息。尽管你可以通过`vmstat -d`获取非常详细的每个分区的资源使用情况，但这选项的输出可能会让你感到不知所措。相反，尝试使用一个专门用于
    I/O 的工具 `iostat`。
- en: Using iostat
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 iostat
- en: 'Like `vmstat`, when run without any options, `iostat` shows the statistics
    for your machine’s current uptime:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 和 `vmstat` 一样，`iostat` 在不带任何选项运行时，会显示机器当前的运行时统计信息：
- en: '[PRE22]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `avg-cpu` part at the top reports the same CPU utilization information
    as other utilities that you’ve seen in this chapter, so skip down to the bottom,
    which shows you the following for each device:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 顶部的`avg-cpu`部分报告了与本章其他工具相同的 CPU 利用率信息，因此跳到底部，底部会显示每个设备的以下信息：
- en: '`tps` Average number of data transfers per second'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tps` 每秒的数据传输平均次数'
- en: '`kB_read/s` Average number of kilobytes read per second'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kB_read/s` 每秒读取的千字节数'
- en: '`kB_wrtn/s` Average number of kilobytes written per second'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kB_wrtn/s` 每秒写入的千字节数'
- en: '`kB_read` Total number of kilobytes read'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kB_read` 读取的千字节总数'
- en: '`kB_wrtn` Total number of kilobytes written'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kB_wrtn` 写入的千字节总数'
- en: Another similarity to `vmstat` is that you can provide an interval argument,
    such as `iostat 2`, to give an update every two seconds. When using an interval,
    you might want to display only the device report by using the `-d` option (such
    as `iostat -d 2`).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个和 `vmstat` 相似的是，你可以提供一个间隔参数，比如 `iostat 2`，以便每两秒更新一次。在使用间隔时，你可能只想通过使用 `-d`
    选项显示设备报告（例如 `iostat -d 2`）。
- en: 'By default, the `iostat` output omits partition information. To show all of
    the partition information, use the `-p ALL` option. Because a typical system has
    many partitions, you’ll get a lot of output. Here’s part of what you might see:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`iostat` 输出省略了分区信息。要显示所有分区信息，可以使用`-p ALL`选项。由于典型系统有许多分区，你会得到大量的输出。以下是你可能看到的部分内容：
- en: '[PRE23]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In this example, `sda1`, `sda2`, and `sda5` are all partitions of the `sda`
    disk, so the read and written columns will have some overlap. However, the sum
    of the partition columns won’t necessarily add up to the disk column. Although
    a read from `sda1` also counts as a read from `sda`, keep in mind that you can
    read from `sda` directly, such as when reading the partition table.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`sda1`、`sda2` 和 `sda5` 都是 `sda` 磁盘的分区，因此读取和写入的列会有一些重叠。然而，分区列的总和不一定等于磁盘列。尽管从
    `sda1` 的读取也计为从 `sda` 的读取，但请记住，你可以直接从 `sda` 读取，例如读取分区表时。
- en: 'Per-Process I/O Utilization and Monitoring: iotop'
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 每进程 I/O 利用率与监控：iotop
- en: 'If you need to dig even deeper to see I/O resources used by individual processes,
    the `iotop` tool can help. Using `iotop` is similar to using `top`. It generates
    a continuously updating display that shows the processes using the most I/O, with
    a general summary at the top:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要更深入地了解各个进程使用的I/O资源，`iotop`工具可以提供帮助。使用`iotop`类似于使用`top`。它会生成一个持续更新的显示，展示使用最多I/O的进程，并在顶部提供一个概览：
- en: '[PRE24]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Along with the user, command, and read/write columns, notice that there’s a
    TID column instead of a PID column. The `iotop` tool is one of the few utilities
    that displays threads instead of processes.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 除了用户、命令和读/写列外，请注意，有一个TID列，而不是PID列。`iotop`是为数不多的显示线程而不是进程的工具之一。
- en: The `PRIO` (priority) column indicates the I/O priority. It’s similar to the
    CPU priority that you’ve already seen, but it affects how quickly the kernel schedules
    I/O reads and writes for the process. In a priority such as `be/4`, the `be` part
    is the *scheduling class*, and the number is the priority level. As with CPU priorities,
    lower numbers are more important; for example, the kernel allows more I/O time
    for a process with priority `be/3` than one with priority `be/4`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`PRIO`（优先级）列表示I/O优先级。它类似于你已经看到的CPU优先级，但它影响内核调度进程的I/O读写的速度。在像`be/4`这样的优先级中，`be`部分是*调度类*，数字表示优先级级别。与CPU优先级一样，数字越小越重要；例如，内核允许一个优先级为`be/3`的进程比一个优先级为`be/4`的进程有更多的I/O时间。'
- en: 'The kernel uses the scheduling class to add more control for I/O scheduling.
    You’ll see three scheduling classes from `iotop`:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 内核使用调度类来为I/O调度提供更多的控制。你将在`iotop`中看到三种调度类：
- en: '`be` Best effort. The kernel does its best to schedule I/O fairly for this
    class. Most processes run under this I/O scheduling class.'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`be` 最佳努力。内核尽力为这一类别公平地调度I/O。大多数进程都运行在这个I/O调度类别下。'
- en: '`rt` Real time. The kernel schedules any real-time I/O before any other class
    of I/O, no matter what.'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rt` 实时。无论如何，内核在调度任何其他类别的I/O之前，都会首先调度实时I/O。'
- en: '`idle` Idle. The kernel performs I/O for this class only when there is no other
    I/O to be done. The idle scheduling class has no priority level.'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`idle` 空闲。内核仅在没有其他I/O任务时才会为这一类执行I/O操作。空闲调度类没有优先级。'
- en: You can check and change the I/O priority for a process with the `ionice` utility;
    see the ionice(1) manual page for details. You’ll probably never need to worry
    about the I/O priority, though.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`ionice`工具查看和更改进程的I/O优先级；有关详细信息，请参见ionice(1)手册页。不过，你可能永远不需要关心I/O优先级。
- en: 8.5.7 Per-Process Monitoring with pidstat
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.5.7 使用pidstat进行每个进程的监控
- en: 'You’ve seen how you can monitor specific processes with utilities such as `top`
    and `iotop`. However, this display refreshes over time, and each update erases
    the previous output. The `pidstat` utility allows you to see the resource consumption
    of a process over time in the style of `vmstat`. Here’s a simple example for monitoring
    process 1329, updating every second:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看过如何使用像`top`和`iotop`这样的工具来监控特定进程。然而，这个显示会随着时间刷新，每次更新都会覆盖前面的输出。`pidstat`工具允许你以`vmstat`的风格查看一个进程随时间变化的资源消耗。以下是一个简单的例子，用于每秒更新监控进程1329：
- en: '[PRE25]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The default output shows the percentages of user and system time and the overall
    percentage of CPU time, and it even tells you on which CPU the process was running.
    (The `%guest` column here is somewhat odd—it’s the percentage of time that the
    process spent running something inside a virtual machine. Unless you’re running
    a virtual machine, don’t worry about this.)
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 默认输出显示用户时间和系统时间的百分比，以及CPU时间的总体百分比，它甚至会告诉你进程在哪个CPU上运行。（这里的`%guest`列有点奇怪——它表示进程在虚拟机中运行的时间百分比。除非你在运行虚拟机，否则不用担心这个。）
- en: Although `pidstat` shows CPU utilization by default, it can do much more. For
    example, you can use the `-r` option to monitor memory and `-d` to turn on disk
    monitoring. Try them out, and then look at the pidstat(1) manual page to see even
    more options for threads, context switching, or just about anything else that
    we’ve talked about in this chapter.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`pidstat`默认显示CPU使用率，但它可以做更多的事情。例如，你可以使用`-r`选项来监控内存，使用`-d`来开启磁盘监控。试试看，然后查看pidstat(1)手册页，了解更多关于线程、上下文切换或我们在本章中讨论的其他任何选项。
- en: 8.6 Control Groups (cgroups)
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6 控制组（cgroups）
- en: So far, you’ve seen how to view and monitor resource usage, but what if you’d
    like to limit what processes can consume beyond what you saw with the `nice` command?
    There are several traditional systems for doing so, such as the POSIX rlimit interface,
    but the most flexible option for most types of resource limits on Linux systems
    is now the *cgroup* (control group) kernel feature.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经了解了如何查看和监控资源使用情况，但如果你想要限制进程的资源消耗，超过 `nice` 命令的作用呢？有几种传统的系统可以做到这一点，比如
    POSIX 的 rlimit 接口，但在 Linux 系统中，最灵活的选择是 *cgroup*（控制组）内核特性，它可以用于大多数资源限制类型。
- en: The basic idea is that you place several processes into a cgroup, which allows
    you to manage the resources that they consume on a group-wide basis. For example,
    if you want to limit the amount of memory that a set of processes may cumulatively
    consume, a cgroup can do this.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 基本思路是，你将多个进程放入一个 cgroup，这样你就可以基于整个组来管理它们消耗的资源。例如，如果你想限制一组进程总共可以消耗的内存量，cgroup
    可以实现这一点。
- en: After creating a cgroup, you can add processes to it, and then use a *controller*
    to change how those processes behave. For example, there is a `cpu` controller
    allowing you to limit the processor time, a `memory` controller, and so on.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 cgroup 后，你可以将进程添加到其中，然后使用 *控制器* 来改变这些进程的行为。例如，`cpu` 控制器允许你限制处理器时间，`memory`
    控制器等也可以做到这一点。
- en: 8.6.1 Differentiating Between cgroup Versions
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.1 区分 cgroup 版本
- en: 'There are two versions of cgroups, 1 and 2, and unfortunately, both are currently
    in use and can be configured simultaneously on a system, leading to potential
    confusion. Aside from a somewhat different feature set, the structural differences
    between the versions can be summed up as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: cgroups 有两个版本，1 和 2，不幸的是，这两个版本当前都在使用，并且可以在同一系统上同时配置，可能会引起混淆。除了功能集有所不同外，这两个版本的结构差异可以总结如下：
- en: In cgroups v1, each type of controller (`cpu`, `memory`, and so on) has its
    own set of cgroups. A process can belong to one cgroup per controller, meaning
    that a process can belong to multiple cgroups. For example, in v1, a process can
    belong to a `cpu` cgroup and a `memory` cgroup.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 cgroups v1 中，每种类型的控制器（`cpu`、`memory` 等）都有自己的一组 cgroup。一个进程可以属于每个控制器中的一个 cgroup，这意味着一个进程可以属于多个
    cgroup。例如，在 v1 中，一个进程可以同时属于 `cpu` cgroup 和 `memory` cgroup。
- en: In cgroups v2, a process can belong to only one cgroup. You can set up different
    types of controllers for each cgroup.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 cgroups v2 中，一个进程只能属于一个 cgroup。你可以为每个 cgroup 设置不同类型的控制器。
- en: To visualize the difference, consider three sets of processes, A, B, and C.
    We want to use the `cpu` and `memory` controllers on each of them. [Figure 8-1](#figure8-1)
    shows the schematic for cgroups v1\. We need six cgroups total, because each cgroup
    is limited to a single controller.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解差异，可以考虑三个进程集合 A、B 和 C。我们希望在每个集合上使用 `cpu` 和 `memory` 控制器。[图 8-1](#figure8-1)
    显示了 cgroups v1 的示意图。我们总共需要六个 cgroup，因为每个 cgroup 只能使用一个控制器。
- en: '![f08001](image_fi/500402c08/f08001.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![f08001](image_fi/500402c08/f08001.png)'
- en: 'Figure 8-1: cgroups v1\. A process may belong to one cgroup per controller.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8-1：cgroups v1。一个进程可能属于每个控制器中的一个 cgroup。
- en: '[Figure 8-2](#figure8-2) shows how to do it in cgroups v2\. We need only three
    cgroups, because we can set up multiple controllers per cgroup.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-2](#figure8-2) 显示了如何在 cgroups v2 中操作。我们只需要三个 cgroup，因为每个 cgroup 可以设置多个控制器。'
- en: '![f08002](image_fi/500402c08/f08002.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![f08002](image_fi/500402c08/f08002.png)'
- en: 'Figure 8-2: cgroups v2\. A process may belong to only one cgroup.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8-2：cgroups v2。一个进程只能属于一个 cgroup。
- en: 'You can list the v1 and v2 cgroups for any process by looking at its *cgroup*
    file in */proc/<pid>*. You can start by looking at your shell’s cgroups with this
    command:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过查看进程的 *cgroup* 文件（位于 */proc/<pid>*）来列出 v1 和 v2 的 cgroup。你可以通过以下命令查看你的 shell
    的 cgroups：
- en: '[PRE26]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Don’t be alarmed if the output is significantly shorter on your system; this
    just means that you probably have only cgroups v2\. Every line of output here
    starts with a number and is a different cgroup. Here are some pointers on how
    to read it:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发现输出比系统上的要短，不必惊慌；这只是意味着你的系统可能只有 cgroups v2。这里的每一行输出都以一个数字开头，并代表一个不同的 cgroup。以下是如何阅读这些输出的一些提示：
- en: Numbers 2–12 are for cgroups v1\. The controllers for those are listed next
    to the number.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字 2-12 是用于 cgroups v1 的。每个数字旁边列出了对应的控制器。
- en: Number 1 is also for version 1, but it does not have a controller. This cgroup
    is for management purposes only (in this case, systemd configured it).
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字 1 也是用于版本 1，但它没有控制器。这个 cgroup 仅用于管理目的（在这种情况下是由 systemd 配置的）。
- en: The last line, number 0, is for cgroups v2\. No controllers are visible here.
    On a system that doesn’t have cgroups v1, this will be the only line of output.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一行，第0行，是cgroups v2的部分。这里没有控制器可见。如果系统没有cgroups v1，这将是唯一的输出行。
- en: Names are hierarchical and look like parts of file paths. You can see in this
    example that some of the cgroups are named */user.slice* and others */user.slice/user-1000.slice/session-2.scope*.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称是层级结构的，类似于文件路径的一部分。在这个例子中，你可以看到一些cgroups命名为*/user.slice*，而其他则命名为*/user.slice/user-1000.slice/session-2.scope*。
- en: The name */testcgroup* 1 was created to show that in cgroups v1, the cgroups
    for a process can be completely independent.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称*/testcgroup* 1是为了展示在cgroups v1中，进程的cgroups可以完全独立。
- en: Names under *user.slice* that include *session* are login sessions, assigned
    by systemd. You’ll see them when you’re looking at a shell’s cgroups. The cgroups
    for your system services will be under *system.slice*.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*user.slice*下，包含*session*的名称表示登录会话，由systemd分配。当你查看shell的cgroups时会看到它们。你系统服务的cgroups会在*system.slice*下。
- en: You may have surmised that cgroups v1 has flexibility in one respect over v2
    because you can assign different combinations of cgroups to processes. However,
    it turns out that no one actually used them this way, and this approach was more
    complicated to set up and implement than simply having one cgroup per process.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经推测到，cgroups v1在某些方面比v2更具灵活性，因为你可以将不同的cgroups组合分配给进程。然而，事实证明，没有人真正以这种方式使用它们，而且这种方法比每个进程只使用一个cgroup的设置和实施更为复杂。
- en: Because cgroups v1 is being phased out, our discussion will focus on cgroups
    v2 from this point forward. Be aware that if a controller is being used in cgroups
    v1, the controller cannot be used in v2 at the same time due to potential conflicts.
    This means that the controller-specific parts of what we’re about to discuss won’t
    work correctly if your system still uses v1, but you should still be able to follow
    along with the v1 equivalents if you look in the right place.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 由于cgroups v1正在逐步淘汰，我们从现在开始将重点讨论cgroups v2。请注意，如果在cgroups v1中使用了某个控制器，那么由于潜在的冲突，该控制器不能同时在v2中使用。这意味着我们接下来要讨论的控制器特定部分，如果你的系统仍在使用v1，将无法正常工作，但如果你查看正确的地方，你仍然能够跟随v1的等效部分。
- en: 8.6.2 Viewing cgroups
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.2 查看cgroups
- en: Unlike the traditional Unix system call interface for interacting with the kernel,
    cgroups are accessed entirely through the filesystem, which is usually mounted
    as a cgroup2 filesystem under */sys/fs/cgroup*. (If you’re also running cgroups
    v1, this will probably be under */sys/fs/cgroup/unified*.)
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的Unix系统调用接口不同，cgroups完全通过文件系统访问，通常挂载为*cgroup2*文件系统，位于*/sys/fs/cgroup*下。（如果你同时运行的是cgroups
    v1，通常会在*/sys/fs/cgroup/unified*下。）
- en: 'Let’s explore the cgroup setup of a shell. Open a shell and find its cgroup
    from */proc/self/cgroup* (as shown earlier). Then look in */sys/fs/cgroup* (or
    */sys/fs/cgroup/unified*). You’ll find a directory with that name; change to it
    and have a look around:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来探索一下shell的cgroup设置。打开一个shell，找到它的cgroup，路径为*/proc/self/cgroup*（如前所示）。然后查看*/sys/fs/cgroup*（或*/sys/fs/cgroup/unified*）。你会找到一个与之同名的目录；进入该目录并四处查看：
- en: '[PRE27]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Among the many files that can be here, the primary cgroup interface files begin
    with *cgroup*. Start by looking at *cgroup.procs* (using `cat` is fine), which
    lists the processes in the cgroup. A similar file, *cgroup.threads*, also includes
    threads.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里可能会有许多文件，其中主要的cgroup接口文件以*cgroup*开头。首先查看*cgroup.procs*（使用`cat`命令查看即可），该文件列出了cgroup中的进程。类似的文件*cgroup.threads*也包含线程。
- en: 'To see the controllers currently in use for the cgroup, look at *cgroup.controllers*:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看当前为该cgroup使用的控制器，查看*cgroup.controllers*：
- en: '[PRE28]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Most cgroups used for shells have these two controllers, which can control
    the amount of memory used and the total number of processes in the cgroup. To
    interact with a controller, look for the files that match the controller prefix.
    For example, if you want to see the number of threads running in the cgroup, consult
    *pids.current*:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数用于shell的cgroups有这两个控制器，可以控制cgroup中使用的内存量和进程总数。要与控制器交互，查找与控制器前缀匹配的文件。例如，如果你想查看cgroup中运行的线程数，请查阅*pids.current*：
- en: '[PRE29]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To see the maximum amount of memory that the cgroup can consume, take a look
    at *memory.max*:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看该cgroup可以消耗的最大内存，查看*memory.max*：
- en: '[PRE30]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: A value of `max` means that this cgroup has no specific limit, but because cgroups
    are hierarchical, a cgroup back down the subdirectory chain might limit it.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`max`的值表示该cgroup没有特定的限制，但由于cgroups是层级结构，子目录链中的某个cgroup可能会限制它。'
- en: 8.6.3 Manipulating and Creating cgroups
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.3 操作和创建 cgroup
- en: 'Although you probably won’t ever need to alter cgroups, it’s easy to do. To
    put a process into a cgroup, write its PID to its *cgroup.procs* file as root:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可能永远不需要修改 cgroup，但其实这很简单。要将进程放入 cgroup，只需将其 PID 以 root 用户身份写入 *cgroup.procs*
    文件：
- en: '[PRE31]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This is how many changes to cgroups work. For example, if you want to limit
    the maximum number of PIDs of a cgroup (to, say, 3,000 PIDs), do it as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是许多 cgroup 变更的工作方式。例如，如果你想限制一个 cgroup 的最大 PID 数量（比如 3,000 个 PID），可以按以下方式操作：
- en: '[PRE32]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Creating cgroups is trickier. Technically, it’s as easy as creating a subdirectory
    somewhere in the cgroup tree; when you do so, the kernel automatically creates
    the interface files. If a cgroup has no processes, you can remove the cgroup with
    `rmdir` even with the interface files present. What can trip you up are the rules
    governing cgroups, including:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 cgroup 较为复杂。技术上，它就像在 cgroup 树中创建一个子目录一样简单；当你这么做时，内核会自动创建接口文件。如果一个 cgroup
    中没有进程，即使接口文件存在，你也可以使用 `rmdir` 删除该 cgroup。可能会让你困扰的是管理 cgroup 的规则，包括：
- en: You can put processes only in outer-level (“leaf”) cgroups. For example, if
    you have cgroups named */my-cgroup* and */my-cgroup/my-subgroup*, you can’t put
    processes in */my-cgroup*, but */my-cgroup/my-subgroup* is okay. (An exception
    is if the cgroups have no controllers, but let’s not dig further.)
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你只能将进程放入外层（“叶子”）cgroup。例如，如果你有名为 */my-cgroup* 和 */my-cgroup/my-subgroup* 的 cgroup，你不能将进程放入
    */my-cgroup*，但是可以放入 */my-cgroup/my-subgroup*。（一个例外是如果 cgroup 没有控制器，但我们不再深入讨论这个话题。）
- en: A cgroup can’t have a controller that isn’t in its parent cgroup.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 cgroup 不能有一个不在其父 cgroup 中的控制器。
- en: You must explicitly specify controllers for child cgroups. You do this through
    the *cgroup.subtree_control* file; for example, if you want a child cgroup to
    have the `cpu` and `pids` controllers, write `+cpu +pids` to this file.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须显式指定子 cgroup 的控制器。你可以通过 *cgroup.subtree_control* 文件来实现；例如，如果你希望子 cgroup 拥有
    `cpu` 和 `pids` 控制器，可以将 `+cpu +pids` 写入该文件。
- en: An exception to these rules is the root cgroup found at the bottom of the hierarchy.
    You can place processes in this cgroup. One reason you might want to do this is
    to detach a process from systemd’s control.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这些规则的例外是位于层级结构底部的根 cgroup。你可以将进程放入该 cgroup。你可能希望这么做的一个原因是将进程从 systemd 的控制中分离出来。
- en: 8.6.4 Viewing Resource Utilization
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.4 查看资源利用情况
- en: 'In addition to being able to limit resources by cgroup, you can also see the
    current resource utilization of all processes across their cgroups. Even with
    no controllers enabled, you can see the CPU usage of a cgroup by looking at its
    *cpu.stat* file:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 除了可以通过 cgroup 限制资源外，你还可以查看所有进程在其 cgroup 中的当前资源使用情况。即使没有启用控制器，你也可以通过查看其 *cpu.stat*
    文件来看到一个 cgroup 的 CPU 使用情况：
- en: '[PRE33]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Because this is the accumulated CPU usage over the entire lifespan of the cgroup,
    you can see how a service consumes processor time even if it spawns many subprocesses
    that eventually terminate.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这是该 cgroup 在其整个生命周期中的累计 CPU 使用情况，你可以看到一个服务如何消耗处理器时间，即使它启动了许多最终终止的子进程。
- en: You can view other types of utilization if the appropriate controllers are enabled.
    For example, the `memory` controller gives access to the *memory.current* file
    for current memory use and *memory.stat* file containing detailed memory data
    for the lifespan of the cgroup. These files are not available in the root cgroup.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用了适当的控制器，你可以查看其他类型的资源利用情况。例如，`memory` 控制器可以访问 *memory.current* 文件，查看当前的内存使用情况，并访问
    *memory.stat* 文件，该文件包含 cgroup 生命周期内的详细内存数据。这些文件在根 cgroup 中不可用。
- en: You can get a lot more out of cgroups. The full details for how to use each
    individual controller, as well as all of the rules for creating cgroups, are available
    in the kernel documentation; just search online for “cgroups2 documentation” and
    you should find it.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从 cgroup 中获得更多信息。如何使用每个单独控制器的完整细节，以及创建 cgroup 的所有规则，都可以在内核文档中找到；只需在线搜索“cgroups2
    文档”即可找到。
- en: For now, though, you should have a good idea of how cgroups work. Understanding
    the basics of their operation helps explain how systemd organizes processes. Later
    on, when you read about containers, you’ll see how they’re used for a much different
    purpose.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，目前你应该已经对 cgroup 的工作原理有了较好的了解。理解它们的基本操作有助于解释 systemd 如何组织进程。稍后，当你阅读关于容器的内容时，你将看到它们如何用于截然不同的目的。
- en: 8.7 Further Topics
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.7 进一步的话题
- en: One reason there are so many tools to measure and manage resource utilization
    is that different types of resources are consumed in many different ways. In this
    chapter, you’ve seen CPU, memory, and I/O as system resources being consumed by
    processes, threads inside processes, and the kernel.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 工具如此之多，用来测量和管理资源利用率的一个原因是，不同类型的资源被消耗的方式各不相同。在本章中，你已经看到CPU、内存和I/O作为系统资源被进程、进程内部的线程以及内核消耗。
- en: The other reason the tools exist is that the resources are *limited*, and for
    a system to perform well, its components must strive to consume fewer resources.
    In the past, many users shared a machine, so it was necessary to make sure that
    each user had a fair share of resources. Now, although a modern desktop computer
    may not have multiple users, it still has many processes competing for resources.
    Likewise, high-performance network servers require intense system resource monitoring
    because they run many processes to handle multiple requests simultaneously.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具存在的另一个原因是资源是*有限的*，为了让系统良好运行，它的组件必须尽力减少资源的消耗。在过去，许多用户共享同一台机器，因此有必要确保每个用户公平地分配资源。如今，尽管现代桌面计算机可能没有多个用户，但它仍然有许多进程争夺资源。同样，高性能的网络服务器也需要密切监控系统资源，因为它们运行多个进程来处理多个请求。
- en: 'Further topics in resource monitoring and performance analysis you might want
    to explore include:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还想探索的资源监控和性能分析的进一步主题包括：
- en: '`sar`(System Activity Reporter) The `sar` package has many of the continuous
    monitoring capabilities of `vmstat`, but it also records resource utilization
    over time. With `sar`, you can look back at a particular time to see what your
    system was doing. This is handy when you want to analyze a past system event.'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`sar`（系统活动报告器） `sar`软件包具备`vmstat`的许多连续监控功能，但它还记录了资源利用情况随时间的变化。使用`sar`，你可以回顾特定时刻系统的状态，这在你想分析过去的系统事件时非常有用。'
- en: '`acct`(process accounting) The `acct` package can record the processes and
    their resource utilization.'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`acct`（进程记账） `acct`软件包可以记录进程及其资源利用情况。'
- en: Quotas You can limit the amount of disk space that a user can use with the `quota`
    system.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配额 你可以通过`quota`系统限制用户使用的磁盘空间。
- en: 'If you’re interested in systems tuning and performance in particular, *Systems
    Performance: Enterprise and the Cloud*, 2nd edition, by Brendan Gregg (Addison-Wesley,
    2020) goes into much more detail.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你特别对系统调优和性能感兴趣，布伦丹·格雷格（Brendan Gregg）所著的《系统性能：企业与云计算》（第2版，Addison-Wesley出版社，2020年）会讲解得更加详细。
- en: We also haven’t yet touched on the many, many tools you can use to monitor network
    resource utilization. To use those, though, you first need to understand how the
    network works. That’s where we’re headed next.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有涉及到许多可以用来监控网络资源利用率的工具。不过，要使用这些工具，首先需要理解网络是如何工作的。这正是我们接下来要探讨的内容。
