- en: Chapter 4. The P Value and the Base Rate Fallacy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：*p*值和基率谬误
- en: You’ve seen that *p* values are hard to interpret. Getting a statistically insignificant
    result doesn’t mean there’s no difference between two groups. But what about getting
    a significant result?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了*p*值很难解释。得到一个统计学上不显著的结果并不意味着两组之间没有差异。那么，得到一个显著的结果又该如何理解呢？
- en: Suppose I’m testing 100 potential cancer medications. Only 10 of these drugs
    actually work, but I don’t know which; I must perform experiments to find them.
    In these experiments, I’ll look for *p* < 0.05 gains over a placebo, demonstrating
    that the drug has a significant benefit.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我正在测试100种潜在的癌症药物。这些药物中只有10种有效，但我不知道哪种有效；我必须进行实验来找出它们。在这些实验中，我将寻找*p* < 0.05的结果，表明该药物具有显著的效果。
- en: '[Figure 4-1](ch04.html#each_square_represents_one_candidate_dru "Figure 4-1. Each
    square represents one candidate drug. The first row of the grid represents drugs
    that definitely work, but I obtained statistically significant results for only
    the eight darker-gray drugs. The black cells are false positives.") illustrates
    the situation. Each square in the grid represents one drug. In reality, only the
    10 drugs in the top row work. Because most trials can’t perfectly detect every
    good medication, I’ll assume my tests have a statistical power of 0.8, though
    you know that most studies have much lower power. So of the 10 good drugs, I’ll
    correctly detect around 8 of them, shown in darker gray.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-1](ch04.html#each_square_represents_one_candidate_dru "图4-1。每个方格代表一种候选药物。网格的第一行代表那些肯定有效的药物，但我只对8种深灰色的药物得到了统计学上显著的结果。黑色的格子代表假阳性。")展示了这种情况。网格中的每个方格代表一种药物。实际上，只有顶行的10种药物有效。因为大多数实验无法完美地检测出每种有效药物，所以我假设我的实验具有0.8的统计效能，尽管你知道大多数研究的统计效能要低得多。所以，在10种有效药物中，我将正确地检测出大约8种，显示为深灰色。'
- en: '![Each square represents one candidate drug. The first row of the grid represents
    drugs that definitely work, but I obtained statistically significant results for
    only the eight darker-gray drugs. The black cells are false positives.](httpatomoreillycomsourcenostarchimages2181913.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![每个方格代表一种候选药物。网格的第一行代表那些肯定有效的药物，但我只对8种深灰色的药物得到了统计学上显著的结果。黑色的格子代表假阳性。](httpatomoreillycomsourcenostarchimages2181913.png)'
- en: Figure 4-1. Each square represents one candidate drug. The first row of the
    grid represents drugs that definitely work, but I obtained statistically significant
    results for only the eight darker-gray drugs. The black cells are false positives.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 图4-1。每个方格代表一种候选药物。网格的第一行代表那些肯定有效的药物，但我只对8种深灰色的药物得到了统计学上显著的结果。黑色的格子代表假阳性。
- en: Because my *p* value threshold is 0.05, I have a 5% chance of falsely concluding
    that an ineffective drug works. Since 90 of my tested drugs are ineffective, this
    means I’ll conclude that about 5 of them have significant effects. These are shown
    in black.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我的*p*值阈值是0.05，所以我有5%的机会错误地认为一种无效的药物有效。由于我测试的90种药物都是无效的，这意味着我会错误地认为大约5种药物有显著效果。这些药物在图中显示为黑色。
- en: 'I perform my experiments and conclude there are 13 “working” drugs: 8 good
    drugs and 5 false positives. The chance of any given “working” drug being truly
    effective is therefore 8 in 13—just 62%! In statistical terms, my *false discovery
    rate*—the fraction of statistically significant results that are really false
    positives—is 38%.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我进行实验并得出结论，有13种“有效”药物：8种有效药物和5种假阳性。因此，任何一项“有效”药物真正有效的概率是8/13——仅为62%! 从统计学的角度来看，我的*假发现率*——即那些统计上显著但实际上是假阳性的结果所占的比例——为38%。
- en: 'Because the *base rate* of effective cancer drugs is so low (only 10%), I have
    many opportunities for false positives. Take this to the extreme: if I had the
    bad fortune of getting a truck-load of completely ineffective medicines, for a
    base rate of 0%, then I have *no* chance of getting a true significant result.
    Nevertheless, I’ll get a *p* < 0.05 result for 5% of the drugs in the truck.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由于有效癌症药物的*基率*非常低（仅为10%），我有很多机会得到假阳性。将情况极端化：如果我不幸地得到了一大车完全无效的药物，基率为0%，那么我将*不可能*获得真正显著的结果。然而，我会对车里的5%的药物得到*p*
    < 0.05的结果。
- en: The Base Rate Fallacy
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基率谬误
- en: 'You often see news articles quoting low *p* values as a sign that error is
    unlikely: “There’s only a 1 in 10,000 chance this result arose as a statistical
    fluke, because *p* = 0.0001.” No! This can’t be true. In the cancer medication
    example, a *p* < 0.05 threshold resulted in a 38% chance that any given statistically
    significant result was a fluke. This misinterpretation is called the *base rate
    fallacy*.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你常常看到新闻报道引用低*p*值作为错误不太可能的标志：“这个结果作为统计偶然的机会只有1/10,000，因为*p* = 0.0001。”不！这不可能是真的。在癌症药物的例子中，*p*
    < 0.05的阈值导致任何给定统计显著结果为偶然的概率达到38%。这种误解被称为*基础概率谬误*。
- en: 'Remember how *p* values are defined: the *p* value is the probability, under
    the assumption that there is no true effect or no true difference, of collecting
    data that shows a difference equal to or more extreme than what you actually observed.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 记住*p*值的定义：*p*值是在假设没有真实效应或没有真实差异的情况下，收集数据的概率，这些数据表现出一个与实际观察结果相同或更极端的差异。
- en: A *p* value is calculated under the assumption that the medication *does not
    work*. It tells me the probability of obtaining my data or data more extreme than
    it. It does *not* tell me the chance my medication is effective. A small *p* value
    is stronger evidence, but to calculate the probability that the medication is
    effective, you’d need to factor in the base rate.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*p*值是在假设药物*无效*的前提下计算出来的。它告诉我获得当前数据或更极端数据的概率。它并不*告诉*我药物有效的概率。一个小的*p*值是更强的证据，但要计算药物有效的概率，你还需要考虑基础概率。
- en: 'When news came from the Large Hadron Collider that physicists had discovered
    evidence for the Higgs boson, a long-theorized fundamental particle, every article
    tried to quote a probability: “There’s only a 1 in 1.74 million chance that this
    result is a fluke,” or something along those lines. But every news source quoted
    a different number. Not only did they ignore the base rate and misinterpret the
    *p* value, but they couldn’t calculate it correctly either.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当来自大型强子对撞机的新闻宣布物理学家发现了希格斯玻色子的证据时，每篇文章都试图引用一个概率：“这个结果作为偶然事件的机会只有1/174万”，或者类似的说法。但是每个新闻来源引用的数字都不同。他们不仅忽略了基础概率并误解了*p*值，而且连计算也不准确。
- en: So when someone cites a low *p* value to say their study is probably right,
    remember that the probability of error is actually almost certainly higher. In
    areas where most tested hypotheses are false, such as early drug trials (most
    early drugs don’t make it through trials), it’s likely that *most* statistically
    significant results with *p* < 0.05 are actually flukes.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以当有人引用一个低*p*值来说明他们的研究可能是正确的时，记住，实际上错误的概率几乎肯定更高。在大多数假设被证明是错误的领域，比如早期药物试验（大多数早期药物未能通过试验），*大多数*统计显著结果，*p*
    < 0.05，实际上很可能是偶然的。
- en: A Quick Quiz
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速小测验
- en: A 2002 study found that an overwhelming majority of statistics students—and
    instructors—failed a simple quiz about *p* values.^([1](apa.html#ch04en1)) Try
    the quiz (slightly adapted for this book) for yourself to see how well you understand
    what *p* really means.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一项2002年的研究发现，绝大多数统计学学生和教师未能通过一个关于*p*值的简单测验。^([1](apa.html#ch04en1)) 尝试这个测验（为本书稍作调整）来看看你对*p*值的真正含义理解得怎么样。
- en: Suppose you’re testing two medications, Fixitol and Solvix. You have two treatment
    groups, one that takes Fixitol and one that takes Solvix, and you measure their
    performance on some standard task (a fitness test, for instance) afterward. You
    compare the mean score of each group using a simple significance test, and you
    obtain *p* = 0.01, indicating there is a statistically significant difference
    between means.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在测试两种药物，Fixitol和Solvix。你有两个治疗组，一个服用Fixitol，另一个服用Solvix，然后你测量他们在某项标准任务（例如健身测试）上的表现。你使用简单的显著性检验比较每组的平均得分，并获得*p*
    = 0.01，表明均值之间存在统计显著差异。
- en: 'Based on this, decide whether each of the following statements is true or false:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 根据以下内容，判断每个陈述是对还是错：
- en: You have absolutely disproved the null hypothesis (“There is no difference between
    means”).
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你已经完全驳斥了零假设（“均值之间没有差异”）。
- en: There is a 1% probability that the null hypothesis is true.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 零假设为真的概率是1%。
- en: You have absolutely proved the alternative hypothesis (“There *is* a difference
    between means”).
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你已经完全证明了备择假设（“均值之间*有*差异”）。
- en: You can deduce the probability that the alternative hypothesis is true.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以推断出备择假设成立的概率。
- en: You know, if you decide to reject the null hypothesis, the probability that
    you are making the wrong decision.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你知道，如果你决定拒绝零假设，你犯错的概率。
- en: You have a reliable experimental finding, in the sense that if your experiment
    were repeated many times, you would obtain a significant result in 99% of trials.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你有一个可靠的实验结果，换句话说，如果你重复实验多次，你将在99%的试验中获得显著结果。
- en: You can find the answers in the footnote.^([[9](#ftn.ch04fn01a)])
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在脚注中找到答案。^([[9](#ftn.ch04fn01a)])
- en: The Base Rate Fallacy in Medical Testing
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 医学检测中的基本比率谬误
- en: 'There has been some controversy over the use of mammograms to screen for breast
    cancer. Some argue that the dangers of false positive results—which result in
    unnecessary biopsies, surgery, and chemotherapy—outweigh the benefits of early
    cancer detection; physicians groups and regulatory agencies, such as the United
    States Preventive Services Task Force, have recently stopped recommending routine
    mammograms for women younger than 50\. This is a statistical question, and the
    first step to answering it to ask a simpler question: if your mammogram turns
    up signs of cancer, what is the probability you actually have breast cancer? If
    this probability is too low, most positive results will be false, and a great
    deal of time and effort will be wasted for no benefit.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用乳腺X光检查筛查乳腺癌，存在一些争议。有些人认为，假阳性结果的危险——这会导致不必要的活检、手术和化疗——超过了早期发现癌症的好处；美国预防服务工作组等医生团体和监管机构最近已停止建议50岁以下女性进行常规乳腺X光检查。这是一个统计学问题，回答这个问题的第一步是问一个更简单的问题：如果你的乳腺X光检查出现癌症迹象，你实际患有乳腺癌的概率是多少？如果这个概率太低，大多数阳性结果都是假阳性，浪费大量时间和精力却没有任何好处。
- en: Suppose 0.8% of women who get mammograms have breast cancer. In 90% of women
    with breast cancer, the mammogram will correctly detect it. (That’s the statistical
    power of the test. This is an estimate, since it’s hard to tell how many cancers
    we miss if we don’t know they’re there.) However, among women with no breast cancer
    at all, about 7% will still get a positive reading on the mammogram. (This is
    equivalent to having a *p* < 0.07 significance threshold.) If you get a positive
    mammogram result, what are the chances you have breast cancer?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 假设接受乳腺X光检查的女性中有0.8%患有乳腺癌。在90%的乳腺癌患者中，乳腺X光检查能够正确检测出癌症。（这就是该检测的统计功效。这是一个估算值，因为如果我们不知道癌症的存在，很难判断我们漏掉了多少病例。）然而，在没有乳腺癌的女性中，大约7%的人仍然会在乳腺X光检查中得到阳性结果。（这相当于具有*p*
    < 0.07的显著性阈值。）如果你得到乳腺X光检查的阳性结果，你患乳腺癌的概率是多少？
- en: Ignoring the chance that you, the reader, are male,^([[10](#ftn.ch04fn02a)])
    the answer is 9%.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果忽略你作为男性读者的可能性，^([[10](#ftn.ch04fn02a)])答案是9%。
- en: How did I calculate this? Imagine 1,000 randomly selected women chose to get
    mammograms. On average, 0.8% of screened women have breast cancer, so about 8
    women in our study will. The mammogram correctly detects 90% of breast cancer
    cases, so about 7 of the 8 will have their cancer discovered. However, there are
    992 women without breast cancer, and 7% will get a false positive reading on their
    mammograms. This means about 70 women will be incorrectly told they have cancer.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我是如何计算的呢？假设随机选择了1,000名女性进行乳腺X光检查。平均而言，0.8%的筛查女性患有乳腺癌，因此我们研究中大约有8名女性会患癌。乳腺X光检查能正确检测90%的乳腺癌病例，所以大约7名患者会被发现患有癌症。然而，有992名没有乳腺癌的女性，7%的人会在乳腺X光检查中得到假阳性结果。这意味着大约70名女性将被错误告知她们患有癌症。
- en: In total, we have 77 women with positive mammograms, 7 of whom actually have
    breast cancer. Only 9% of women with positive mammograms have breast cancer.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们有77名乳腺X光检查结果为阳性的女性，其中7名实际上患有乳腺癌。只有9%的阳性乳腺X光结果女性患有乳腺癌。
- en: Even doctors get this wrong. If you ask them, two-thirds will erroneously conclude
    that a *p* < 0.05 result implies a 95% chance that the result is true.^([2](apa.html#ch04en2))
    But as you can see in these examples, the likelihood that a positive mammogram
    means cancer depends on the proportion of women who actually *have* cancer. And
    we are very fortunate that only a small proportion of women have breast cancer
    at any given time.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是医生也会犯这个错误。如果你问他们，三分之二的人会错误地得出结论，认为*p* < 0.05的结果意味着该结果有95%的概率是正确的。^([2](apa.html#ch04en2))
    但正如你在这些例子中所看到的，阳性乳腺X光结果意味着癌症的可能性取决于实际患有癌症的女性的比例。幸运的是，在任何时候，患乳腺癌的女性比例都很小。
- en: How to Lie with Smoking Statistics
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何通过吸烟统计数据来撒谎
- en: Renowned experts in statistics fall prey to the base rate fallacy, too. One
    high-profile example involves journalist Darrell Huff, author of the popular 1954
    book *How to Lie with Statistics*.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 知名的统计学专家也会陷入基本概率谬误。一例引人注目的案例是记者达雷尔·哈夫，他是1954年畅销书*如何通过统计数据撒谎*的作者。
- en: Although *How to Lie with Statistics* didn’t focus on statistics in the academic
    sense of the term—it was perhaps better titled *How to Lie with Charts, Plots,
    and Misleading Numbers*—the book was still widely adopted in college courses and
    read by a public eager to outsmart marketers and politicians, turning Huff into
    a recognized expert in statistics. So when the US Surgeon General’s famous report
    *Smoking and Health* came out in 1964, saying that tobacco smoking causes lung
    cancer, tobacco companies turned to Huff to provide their public rebuttal.^([[11](#ftn.ch04fn03a)])
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管*如何通过统计数据撒谎*并没有关注统计学的学术意义——或许更适合命名为*如何通过图表、图形和误导性数字撒谎*——这本书仍然被广泛采用于大学课程，并被渴望智胜营销人员和政治家的公众阅读，使哈夫成为统计学领域的公认专家。所以，当美国外科医生的著名报告*吸烟与健康*在1964年发布，称烟草吸烟会导致肺癌时，烟草公司寻求哈夫提供公开的反驳^([[11](#ftn.ch04fn03a)])。
- en: Attempting to capitalize on Huff’s respected status, the tobacco industry commissioned
    him to testify before Congress and then to write a book, tentatively titled *How
    to Lie with Smoking Statistics*, covering the many statistical and logical errors
    alleged to be found in the surgeon general’s report. Huff completed a manuscript,
    for which he was paid more than $9,000 (roughly $60,000 in 2014 dollars) by tobacco
    companies and which was positively reviewed by University of Chicago statistician
    (and paid tobacco industry consultant) K.A. Brownlee. Although it was never published,
    it’s likely that Huff’s friendly, accessible style would have made a strong impression
    on the public, providing talking points for watercooler arguments.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用哈夫在公众中的声望，烟草行业委托他在国会作证，并随后撰写一本书，暂定名为*如何通过吸烟统计数据撒谎*，内容涉及指控外科医生报告中存在的许多统计和逻辑错误。哈夫完成了这本手稿，烟草公司支付了他超过9,000美元（相当于2014年约60,000美元），这本书得到了芝加哥大学统计学家（也是烟草行业付费顾问）K.A.布朗利的好评。尽管这本书从未出版，但哈夫友好、易懂的写作风格可能会给公众留下深刻印象，为茶水间辩论提供了话题。
- en: 'In his [Chapter 7](ch07.html "Chapter 7. Continuity Errors"), he discusses
    what he calls *overprecise figures*—those presented without a confidence interval
    or any indication of uncertainty. For example, the surgeon general’s report mentions
    a “mortality ratio of 1.20,” which is “statistically significant at the 5 percent
    level.” This, presumably, meant that the ratio was significantly different from
    1.0, with *p* < 0.05\. Huff agrees that expressing the result as a mortality ratio
    is perfectly proper but states:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在他的[第7章](ch07.html "第7章。连续性错误")中，他讨论了他所称的*过于精确的数字*——那些没有置信区间或任何不确定性指示的数字。例如，外科医生报告中提到的“死亡率比为1.20”，这是“在5%显著性水平下具有统计意义的”。这大概意味着该比率显著不同于1.0，且*p*
    < 0.05。哈夫同意将结果表示为死亡率比是完全合适的，但他指出：
- en: 'It does have an unfortunate result: it makes it appear that we now know the
    actual mortality ratio of two kinds of groups right down to a decimal place. The
    reader must bring to his interpretation of this figure a knowledge that what looks
    like a rather exact figure is only an approximation. From the accompanying statement
    of significance (“5 percent level”) we discover that all that is actually known
    is that the odds are 19 to one that the second group truly does have a higher
    death rate than the first. The actual increase from one group to the other may
    be much less than the 20 percent indicated, or it may be more.'
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这确实带来了一个不幸的结果：它让人看起来我们现在能准确知道两类群体的实际死亡率比，精确到小数点后位。读者必须理解，这个看起来相当精确的数字其实只是一个近似值。从附带的显著性声明（“5%显著性水平”）中，我们发现实际上所知道的只是第二组的死亡率比第一组高的几率是19比1。第一组到第二组的实际差异可能远低于所示的20%，也可能更高。
- en: 'For the first half of this quote, I wanted to cheer Huff on: yes, statistically
    significant *doesn’t* mean that we know the precise figure to two decimal places.
    (A confidence interval would have been a much more appropriate way to express
    this figure.) But then Huff claims that the significance level gives 19-to-1 odds
    that the death rate really is different. That is, he interprets the *p* value
    as the probability that the results are a fluke.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这段引用的前半部分，我真想为哈夫加油：是的，统计学上的显著性*并不*意味着我们知道精确的两位小数的数字。（置信区间本来是表达这一数字的更合适方式。）但是接下来，哈夫声称显著性水平表明死亡率的差异的概率是19比1。也就是说，他将*p*值解释为结果是偶然的概率。
- en: Not even Huff is safe from the base rate fallacy! We don’t know the odds that
    “the second group truly does have a higher death rate than the first.” All we
    know is that if the true mortality ratio were 1, we would observe a mortality
    ratio larger than 1.20 in only 1 in 20 experiments.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至哈夫也无法避免基准率谬误！我们不知道“第二组的死亡率是否真的高于第一组”的概率。我们所知道的是，如果真实的死亡率比是1，那么在20次实验中，我们只有一次会观察到一个大于1.20的死亡率比。
- en: Huff’s complaint about overprecise figures is, in fact, impossibly precise.
    Notably, K.A. Brownlee read this comment—and several similar remarks Huff makes
    throughout the manuscript—without complaint. Instead, he noted that in one case
    Huff incorrectly quotes the odds as 20 to 1 rather than 19 to 1\. He did not seem
    to notice the far more fundamental base rate fallacy lurking.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 哈夫对过于精确数字的抱怨，实际上是极度精确的。值得注意的是，K.A. 布朗利阅读了这条评论——以及哈夫在整个手稿中所做的几次类似评论——并没有提出异议。相反，他指出，在一个案例中，哈夫错误地引用了赔率为20比1，而不是19比1。似乎他没有注意到更为根本的基准率谬误。
- en: Taking Up Arms Against the Base Rate Fallacy
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反击基准率谬误
- en: You don’t have to be performing advanced cancer research or early cancer screenings
    to run into the base rate fallacy. What if you’re doing social research? Say you’d
    like to survey Americans to find out how often they use guns in self-defense.
    Gun control arguments, after all, center on the right to self-defense, so it’s
    important to determine whether guns are commonly used for defense and whether
    that use outweighs the downsides, such as homicides.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你不必进行高级癌症研究或早期癌症筛查才能遇到基准率谬误。假如你在做社会研究呢？假设你想调查美国人自卫时使用枪支的频率。毕竟，枪支管控的争论集中在自卫权上，所以了解枪支是否常用于防卫，以及这种使用是否超过了其负面影响（如凶杀案件）是非常重要的。
- en: One way to gather this data would be through a survey. You could ask a representative
    sample of Americans whether they own guns and, if so, whether they’ve used the
    guns to defend their homes in burglaries or themselves from being mugged. You
    could compare these numbers to law enforcement statistics of gun use in homicides
    and make an informed decision about whether the benefits of gun control outweigh
    the drawbacks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 收集这些数据的一种方式是通过调查。你可以询问一部分具有代表性的美国人，他们是否拥有枪支，如果有，他们是否曾在入室盗窃或防止被抢劫时用枪支保护自己或家人。你可以将这些数字与执法机构关于枪支在凶杀案件中使用的统计数据进行对比，从而做出是否枪支管控的好处大于弊端的明智决定。
- en: Such surveys have been done, with interesting results. One 1992 telephone survey
    estimated that American civilians used guns in self-defense up to 2.5 million
    times that year. Roughly 34% of these cases were burglaries, meaning 845,000 burglaries
    were stymied by gun owners. But in 1992, there were only 1.3 million burglaries
    committed while someone was at home. Two-thirds of these occurred while the homeowners
    were asleep and were discovered only after the burglar had left. That leaves 430,000
    burglaries involving homeowners who were at home and awake to confront the burglar,
    845,000 of which, we are led to believe, were stopped by gun-toting residents.^([3](apa.html#ch04en3))
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这类调查已经做过，结果也很有意思。1992年的一项电话调查估算，美国平民在那一年使用枪支进行自卫的次数高达250万次。这些案件中大约34%是入室盗窃案件，也就是说有845,000起盗窃案件被枪支持有者制止了。但在1992年，实际发生的家庭盗窃案件只有130万起。三分之二的案件发生在房主熟睡时，只有在小偷离开后才被发现。那剩下的43万起盗窃案件是房主在家且清醒时与小偷对峙的，而我们被告知其中845,000起案件是被持枪居民阻止的。^([3](apa.html#ch04en3))
- en: Whoops.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀。
- en: One explanation could be that burglaries are dramatically underreported. The
    total number of burglaries came from the National Crime Victimization Survey (NCVS),
    which asked tens of thousands of Americans in detailed interviews about their
    experiences with crime. Perhaps respondents who fended off a burglar with their
    firearms didn’t report the crime—after all, nothing was stolen, and the burglar
    fled. But a massive underreporting of burglaries would be needed to explain the
    discrepancy. Fully two-thirds of burglaries committed against awake homeowners
    would need to have gone unreported.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解释可能是，入室盗窃案件被严重低报。入室盗窃的总数来自国家犯罪受害者调查（NCVS），该调查通过详细的访谈向成千上万的美国人询问他们的犯罪经历。也许那些用枪防卫成功的受访者没有报告犯罪——毕竟，没有任何财物被盗，且小偷逃跑了。但是，要解释这种差异，必须假设存在大规模的入室盗窃案件未被报告。实际上，三分之二的针对清醒房主的入室盗窃案件需要没有报告。
- en: 'A more likely answer is that the survey overestimated the use of guns in self-defense.
    How? In the same way mammograms overestimate the incidence of breast cancer: there
    are far more opportunities for false positives than false negatives. If 99.9%
    of people did not use a gun in self-defense in the past year but 2% of those people
    answered “yes” for whatever reason (to amuse themselves or because they misremembered
    an incident from long ago as happening in the past year), the true rate of 0.1%
    will appear to be nearly 2.1%, inflated by a factor of 21.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 更可能的答案是，调查高估了自卫时使用枪支的情况。怎么高估的呢？就像乳腺X光检查高估了乳腺癌的发生率一样：假阳性的机会远多于假阴性。如果99.9%的人在过去一年没有使用过枪支进行自卫，但其中2%的人由于某种原因（例如为了取乐，或记错了很久以前的事件，误认为发生在过去一年内）回答了“是”，那么真实的使用率0.1%看起来会接近2.1%，被夸大了21倍。
- en: What about false negatives? Could this effect be balanced by people who said
    “no” even though they gunned down a mugger just last week? A respondent may have
    been carrying the firearm illegally or unwilling to admit using it to a stranger
    on the phone. But even then, if few people genuinely use a gun in self-defense,
    then there are few opportunities for false negatives. Even if half of gun users
    don’t admit to it on the phone survey, they’re vastly outnumbered by the tiny
    fraction of nonusers who lie or misremember, and the survey will give a result
    20 times too large.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，假阴性呢？这种效应能否通过那些即使上周刚击倒抢劫犯的人，仍然回答“没有”来平衡？受访者可能是非法携带枪支，或不愿意在电话中承认使用过枪支。但是即便如此，如果很少有人真正使用枪支进行自卫，那么假阴性的机会就很少。即便有一半使用枪支的人在电话调查中不承认使用过，他们也远远少于那些撒谎或记错的非使用者群体，而调查结果将会显得比实际高出20倍。
- en: Since the false positive rate is the overwhelming error factor here, that’s
    what criminologists focus on reducing. A good way to do so is by conducting extremely
    detailed surveys. The NCVS, run by the Department of Justice, uses detailed sit-down
    interviews where respondents are asked for details about crimes and their use
    of guns in self-defense. Only respondents who report being victimized are asked
    about how they defended themselves, and so people who may be inclined to lie about
    or misremember self-defense get the opportunity only if they also lie about or
    misremember being a victim. The NCVS also tries to detect misremembered dates
    (a common problem) by interviewing the same respondents periodically. If the respondent
    reports being the victim of a crime within the last six months, but six months
    ago they reported the same crime a few months prior, the interviewer can remind
    them of the discrepancy.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于假阳性率是这里的主要误差因素，因此犯罪学家们的重点是减少这一误差。一个有效的做法是进行极其详细的调查。由司法部主办的NCVS使用详细的面对面访谈，受访者会被要求提供关于犯罪和自卫时使用枪支的细节。只有报告自己是受害者的人才会被询问如何进行自卫，因此，可能会撒谎或记错自卫情形的人，只有在他们也撒谎或记错自己是受害者的情况下，才会有机会报告。NCVS还通过定期对同一受访者进行多次访谈，试图检测到记忆错误的日期（这是一个常见问题）。如果受访者报告自己在过去六个月内成为犯罪的受害者，但六个月前他们报告的相同犯罪发生在几个月前，访谈员可以提醒他们这一不一致。
- en: The 1992 NCVS estimated a much lower number than the phone survey—something
    like 65,000 incidents per year, not millions.^([4](apa.html#ch04en4)) This figure
    includes not only defense against burglaries but also robberies, rapes, assaults,
    and car thefts. Even so, it is nearly 40 times smaller than the estimate provided
    by the telephone survey.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 1992年NCVS的估计数字比电话调查低得多——大约每年65,000起事件，而不是数百万起。^([4](apa.html#ch04en4)) 这个数字不仅包括防范入室盗窃，还包括抢劫、强奸、袭击和汽车盗窃等案件。即便如此，它的数字仍然比电话调查给出的估计值小了近40倍。
- en: 'Admittedly, people may have been nervous to admit illegal gun use to a federal
    government agency; the authors of the original phone survey claimed that most
    defensive gun use involves illegal gun possession.^([5](apa.html#ch04en5)) (This
    raises another research question: why are so many victims illegally carrying firearms?)
    This biases the NCVS survey results downward. Perhaps the truth is somewhere in
    between.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 诚然，人们可能对向联邦政府机构承认非法枪支使用感到紧张；原始电话调查的作者声称，大多数防御性枪支使用都涉及非法持枪。^([5](apa.html#ch04en5))（这引发了另一个研究问题：为什么这么多受害者非法携带枪支？）这使得NCVS调查结果偏低。也许真相就在两者之间。
- en: Unfortunately, the inflated phone survey figure is still often cited by gun
    rights groups, misinforming the public debate on gun safety. Meanwhile, the NCVS
    results hold steady at far lower numbers. The gun control debate is far more complicated
    than a single statistic, of course, but informed debate can begin only with accurate
    data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，膨胀的电话调查数据仍然经常被枪支权利团体引用，误导了公众对枪支安全的辩论。与此同时，NCVS的结果保持在远低于的数据上。枪支管控的辩论显然比单一统计数据要复杂得多，但有根据的辩论只能从准确的数据开始。
- en: If At First You Don’t Succeed, Try, Try Again
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如果一开始你没有成功，继续尝试
- en: The base rate fallacy shows that statistically significant results are false
    positives much more often than the *p* < 0.05 criterion for significance might
    suggest. The fallacy’s impact is magnified in modern research, which usually doesn’t
    make just one significance test. More often, studies compare a variety of factors,
    seeking those with the most important effects.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 基本率谬误表明，统计学上显著的结果往往是假阳性，远比*p* < 0.05显著性标准所暗示的要频繁。这种谬误在现代研究中的影响更为显著，因为现代研究通常不仅仅进行一次显著性测试。更多时候，研究会比较多种因素，寻找那些影响最重要的因素。
- en: For example, imagine testing whether jelly beans cause acne by testing the effect
    of every single jelly bean color on acne, as illustrated in [Figure 4-2](ch04.html#cartoon_from_xkcdcomma_by_randall_munroe
    "Figure 4-2. Cartoon from xkcd, by Randall Munroe ()").
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象一下通过测试每种果冻豆颜色对痤疮的影响来测试果冻豆是否引起痤疮，正如[图4-2](ch04.html#cartoon_from_xkcdcomma_by_randall_munroe
    "图4-2。来自xkcd的漫画，Randall Munroe创作 ()")所示。
- en: '![image with no caption](httpatomoreillycomsourcenostarchimages2181915.png.jpg)![Cartoon
    from xkcd, by Randall Munroe ()](httpatomoreillycomsourcenostarchimages2181917.png.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![无标题图像](httpatomoreillycomsourcenostarchimages2181915.png.jpg)![来自xkcd的漫画，Randall
    Munroe创作 ()](httpatomoreillycomsourcenostarchimages2181917.png.jpg)'
- en: Figure 4-2. Cartoon from xkcd, by Randall Munroe ([http://xkcd.com/882/](http://xkcd.com/882/))
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图4-2。来自xkcd的漫画，Randall Munroe创作 ([http://xkcd.com/882/](http://xkcd.com/882/))
- en: As the comic shows, making multiple comparisons means multiple chances for a
    false positive. The more tests I perform, the greater the chance that at least
    one of them will produce a false positive. For example, if I test 20 jelly bean
    flavors that do not cause acne at all and look for a correlation at *p* < 0.05
    significance, I have a 64% chance of getting at least one false positive result.
    If I test 45 flavors, the chance of at least one false positive is as high as
    90%. If I instead use confidence intervals to look for a correlation that is nonzero,
    the same problem will occur.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 正如漫画所示，进行多次比较意味着多次发生假阳性的机会。我执行的测试越多，至少有一个假阳性结果的机会就越大。例如，如果我测试20种完全不会引起痤疮的果冻豆口味，并在*p*
    < 0.05的显著性水平下寻找相关性，我有64%的机会得到至少一个假阳性结果。如果我测试45种口味，至少一个假阳性的机会高达90%。如果我改为使用置信区间来寻找非零的相关性，同样的问题也会出现。
- en: Note
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '*The math behind these numbers is fairly straightforward. Suppose we have*
    n *independent hypotheses to test, none of which is true. We set our significance
    criterion at* p < 0.05*. The probability of obtaining at least one false positive
    among the* n *tests is as follows:*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*这些数字背后的数学相当简单。假设我们有* n *个独立的假设要测试，且这些假设都不成立。我们将显著性标准设为* p < 0.05*。在* n *次测试中获得至少一个假阳性的概率如下：*'
- en: '*P*(false positive) = 1 – (1 – 0.05)^(*n*)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*P*(假阳性) = 1 – (1 – 0.05)^(*n*)'
- en: '*For* n = 100*, the false positive probability increases to 99%.*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*对于* n = 100*，假阳性概率增加到99%。*'
- en: 'Multiple comparisons aren’t always as obvious as testing 20 jelly bean colors.
    Track the symptoms of patients for a dozen weeks and test for significant benefits
    during any of those weeks: bam, that’s 12 comparisons. And if you’re checking
    for the occurrence of 23 different potential dangerous side effects? Alas! You
    have sinned.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 多重比较并不总是像测试20种果冻豆颜色那样显而易见。追踪患者症状几周，并在任何一周测试显著的效益：噢，这样就有了12次比较。如果你还要检查23种不同的潜在危险副作用的发生情况？唉！你犯了个错误。
- en: If you send out a 10-page survey asking about nuclear power plant proximity,
    milk consumption, age, number of male cousins, favorite pizza topping, current
    sock color, and a few dozen other factors for good measure, you’ll probably find
    that at least one of those things is correlated with cancer.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发送一份10页的调查问卷，询问核电厂距离、牛奶消费量、年龄、男性表兄弟数量、最喜欢的披萨配料、当前袜子颜色以及其他几十个因素，你可能会发现至少有一个因素与癌症有关。
- en: 'Particle physicists call this the *look-elsewhere effect*. An experiment like
    the Large Hadron Collider’s search for the Higgs boson involves searching particle
    collision data, looking for small anomalies that indicate the existence of a new
    particle. To compute the statistical significance of an anomaly at an energy of
    5 gigaelectronvolts,^([[12](#ftn.ch04fn04a)]) for example, physicists ask this:
    “How likely is it to see an anomaly this size or larger at 5 gigaelectronvolts
    by chance?” But they could have looked elsewhere—they are searching for anomalies
    across a large swath of energies, any one of which could have produced a false
    positive. Physicists have developed complicated procedures to account for this
    and correctly limit the false positive rate.^([6](apa.html#ch04en6))'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 粒子物理学家称这一现象为*他处观察效应*。像大型强子对撞机寻找希格斯玻色子的实验，涉及搜索粒子碰撞数据，寻找小的异常现象，以指示新粒子的存在。例如，要计算在5吉电子伏特能量下，异常现象的统计显著性，物理学家会问：“在5吉电子伏特的能量下，偶然看到如此大或更大异常现象的概率有多大？”但他们也可以在其他地方查找——他们在多个能量范围内寻找异常，其中任何一个都可能产生假阳性。物理学家们已经开发了复杂的程序来处理这个问题，并正确地限制假阳性率。^([6](apa.html#ch04en6))
- en: If we want to make many comparisons at once but control the *overall* false
    positive rate, the *p* value should be calculated under the assumption that *none*
    of the differences is real. If we test 20 different jelly beans, we would not
    be surprised if one out of the 20 “causes” acne. But when we calculate the *p*
    value for a specific flavor, as though each comparison stands on its own, we are
    calculating the probability that *this specific* group would be lucky—an unlikely
    event—not any 1 out of the 20\. And so the anomalies we detect appear much more
    significant than they are.^([7](apa.html#ch04en7))
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望同时进行多次比较，但控制*整体*假阳性率，*p*值应该在假设*没有*任何差异是真实的前提下计算。如果我们测试20种不同的果冻豆，我们不会感到惊讶如果其中一种“引起”了痤疮。但当我们计算某种特定口味的*p*值时，就好像每个比较都是独立的，我们其实是在计算*这个特定*小组幸运的概率——一个不太可能的事件，而不是20种中的任意一种。因此，我们检测到的异常看起来比实际更为显著。^([7](apa.html#ch04en7))
- en: A survey of medical trials in the 1980s found that the average trial made 30
    therapeutic comparisons. In more than half the trials, the researchers had made
    so many comparisons that a false positive was highly likely, casting the statistically
    significant results they did report into doubt. They may have found a statistically
    significant effect, but it could just have easily been a false positive.^([8](apa.html#ch04en8))
    The situation is similar in psychology and other heavily statistical fields.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 1980年代对医学试验的调查发现，平均每个试验进行了30次治疗比较。在超过一半的试验中，研究人员进行了如此多的比较，以至于假阳性几乎是必然的，这使得他们报告的统计显著结果受到怀疑。他们可能发现了一个统计显著的效果，但它也可能只是一个假阳性。^([8](apa.html#ch04en8))
    这种情况在心理学和其他高度依赖统计学的领域也类似。
- en: There are techniques to correct for multiple comparisons. For example, the Bonferroni
    correction method allows you to calculate *p* values as you normally would but
    says that if you make *n* comparisons in the trial, your criterion for significance
    should be *p* < 0.05/*n*. This lowers the chances of a false positive to what
    you’d see from making only one comparison at *p* < 0.05\. However, as you can
    imagine, this reduces statistical power, since you’re demanding much stronger
    correlations before you conclude they’re statistically significant. In some fields,
    power has decreased systematically in recent decades because of increased awareness
    of the multiple comparisons problem.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些技术可以用来修正多重比较问题。例如，本费罗尼校正方法允许你像平常一样计算*p*值，但指出如果在试验中进行*n*次比较，那么显著性的标准应该是*p*
    < 0.05/*n*。这样可以降低假阳性的概率，使其接近于仅进行一次比较时*p* < 0.05的情况。然而，正如你可以想象的那样，这会降低统计功效，因为你要求在得出统计显著性结论之前，必须有更强的相关性。在某些领域，由于对多重比较问题的认识增加，近年来统计功效已经系统性地下降。
- en: In addition to these practical problems, some researchers object to the Bonferroni
    correction on philosophical grounds. The Bonferroni procedure implicitly assumes
    that *every* null hypothesis tested in multiple comparisons is true. But it’s
    almost never the case that the difference between two populations is exactly zero
    or that the effect of some drug is exactly identical to a placebo. So why assume
    the null hypothesis is true in the first place?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些实际问题外，一些研究人员还从哲学角度反对使用**本费罗尼校正**方法。本费罗尼程序隐含地假设在多个比较中测试的*每一个*零假设都是正确的。但几乎从来都不是这样，两个群体之间的差异并非完全为零，某些药物的效果也不可能与安慰剂完全相同。那么，为什么一开始就假设零假设成立呢？
- en: If this objection sounds familiar, it’s because you’ve heard it before—as an
    argument against null hypothesis significance testing *in general*, not just the
    Bonferroni correction. Accurate estimates of the *size* of differences are much
    more interesting than checking only whether each effect could be zero. That’s
    all the more reason to use confidence intervals and effect size estimates instead
    of significance testing.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个反对意见听起来很熟悉，那是因为你之前曾听过类似的论点——这是针对零假设显著性检验*的一般*反对，而不仅仅是针对本费罗尼校正。与仅检查每个效应是否可能为零相比，准确估计差异的*大小*要有趣得多。这也更有理由使用置信区间和效应大小估计，而不是显著性检验。
- en: Red Herrings in Brain Imaging
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大脑成像中的“红鲱鱼”问题
- en: Neuroscientists do massive numbers of comparisons when performing functional
    MRI (fMRI) studies, where a three-dimensional image of the brain is taken before
    and after the subject performs some task. The images show blood flow in the brain,
    revealing which parts of the brain are most active when a person performs different
    tasks.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 神经科学家在进行功能性磁共振成像（fMRI）研究时会进行大量比较，在此类研究中，研究者会在受试者执行某个任务之前和之后分别拍摄三维的大脑图像。这些图像显示了大脑的血流情况，从而揭示出人们在执行不同任务时，大脑的哪些部分最为活跃。
- en: How exactly do you decide which regions of the brain are active? A simple method
    is to divide the brain image into small cubes called voxels. A voxel in the “before”
    image is compared to the voxel in the “after” image, and if the difference in
    blood flow is significant, you conclude that part of the brain was involved in
    the task. Trouble is, there are tens of thousands of voxels to compare and therefore
    many opportunities for false positives.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，究竟如何判断大脑哪些区域是活跃的呢？一种简单的方法是将大脑图像分成小立方体，称为体素（voxels）。将“前”图像中的一个体素与“后”图像中的体素进行比较，如果血流差异显著，就得出大脑的某一部分参与了任务的结论。问题是，需要比较数万个体素，因此存在很多假阳性的机会。
- en: One study, for instance, tested the effects of an “open-ended mentalizing task”
    on participants. Subjects were shown “a series of photographs depicting human
    individuals in social situations with a specified emotional valence” and asked
    to “determine what emotion the individual in the photo must have been experiencing.”
    You can imagine how various emotional and logical centers of the brain would light
    up during this test.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一项研究测试了“开放性思维任务”对参与者的影响。受试者观看了一系列“展示人在特定社交情境中、带有特定情感色彩的照片”，并被要求“判断照片中的人可能正在体验的情感”。你可以想象，在此测试过程中，大脑的各种情感和逻辑中心会被激活。
- en: The data was analyzed, and certain brain regions were found to change activity
    during the task. Comparison of images made before and after the “mentalizing task”
    showed a *p* = 0.001 difference in an 81mm³ cluster in the brain.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数据经过分析，发现某些大脑区域在任务期间活动发生了变化。对“心智化任务”前后图像的比较显示，在大脑的一个 81mm³ 区域，*p* = 0.001 存在差异。
- en: The study participants? Not college undergraduates paid $10 for their time,
    as is usual. No, the test subject was a 3.8-pound Atlantic salmon, which “was
    not alive at the time of scanning.”^([[13](#ftn.ch04fn05a)])
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 研究参与者？不是那些通常为参加者支付 10 美元的大学生。不是的，测试对象是一条重 3.8 磅的“大西洋三文鱼”，它“在扫描时已经不再活跃。”^([[13](#ftn.ch04fn05a)])
- en: Neuroscientists often attempt to limit this problem by requiring clusters of
    10 or more significant voxels with a stringent threshold of *p* < 0.005, but in
    a brain scan with tens of thousands of voxels, a false positive is still virtually
    guaranteed. Techniques like the Bonferroni correction, which control the rate
    of false positives even when thousands of statistical tests are made, are now
    common in the neuroscience literature. Few papers make errors as serious as the
    ones demonstrated in the dead salmon experiment. Unfortunately, almost every paper
    tackles the problem differently. One review of 241 fMRI studies found that they
    used 207 unique combinations of statistical methods, data collection strategies,
    and multiple comparison corrections, giving researchers great flexibility to achieve
    statistically significant results.^([9](apa.html#ch04en9))
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 神经科学家们通常通过要求有 10 个或更多显著体素的簇，并使用严格的 *p* < 0.005 阈值来限制这个问题，但在一个包含数万个体素的脑扫描中，假阳性几乎是无法避免的。像
    Bonferroni 校正这样的技术，能够在进行成千上万次统计检验时控制假阳性率，目前在神经科学文献中已很常见。很少有论文会犯像死三文鱼实验中那样严重的错误。不幸的是，几乎每篇论文都是以不同的方式处理这个问题。一项关于
    241 份 fMRI 研究的综述发现，它们使用了 207 种独特的统计方法、数据收集策略和多重比较校正组合，给研究人员提供了极大的灵活性，以获得统计显著的结果。^([9](apa.html#ch04en9))
- en: Controlling the False Discovery Rate
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制假发现率
- en: As I mentioned earlier, one drawback of the Bonferroni correction is that it
    greatly decreases the statistical power of your experiments, making it more likely
    that you’ll miss true effects. More sophisticated procedures than Bonferroni correction
    exist, ones with less of an impact on statistical power, but even these are not
    magic bullets. Worse, they don’t spare you from the base rate fallacy. You can
    still be misled by your *p* threshold and falsely claim there’s “only a 5% chance
    I’m wrong.” Procedures like the Bonferroni correction only help you eliminate
    some false positives.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前提到的，Bonferroni 校正的一个缺点是它大大降低了实验的统计效能，这使得你更有可能错过真正的效应。确实存在比 Bonferroni 校正更复杂的方法，这些方法对统计效能的影响较小，但即便如此，它们也不是灵丹妙药。更糟的是，它们并不能避免基本率谬误。你仍然可能会被你的
    *p* 阈值误导，错误地声称“我错的概率只有 5%”。像 Bonferroni 校正这样的程序只帮助你消除一些假阳性。
- en: 'Scientists are more interested in limiting the *false discovery rate*: the
    fraction of statistically significant results that are false positives. In the
    cancer medication example that started this chapter, my false discovery rate was
    38%, since fully one-third of my statistically significant results were flukes.
    Of course, the only reason you knew how many of the medications *actually* worked
    was because I told you the number ahead of time. In general, you don’t know how
    many of your tested hypotheses are true; you can compute the false discovery rate
    only by guessing. But ideally, you’d find it out from the data.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 科学家们更关心的是限制 *假发现率*：即统计显著结果中假阳性的比例。在本章开头提到的癌症药物例子中，我的假发现率为 38%，因为我所有统计显著结果中有三分之一都是偶然的。当然，你之所以知道哪些药物*确实*有效，是因为我事先告诉了你这个数字。一般来说，你并不知道你测试的假设中有多少是真的；你只能通过猜测来计算假发现率。但理想情况下，你应该通过数据来揭示这一点。
- en: 'In 1995, Yoav Benjamini and Yosef Hochberg devised an exceptionally simple
    procedure that tells you which *p* values to consider statistically significant.
    I’ve been saving you from mathematical details so far, but to illustrate just
    how simple the procedure is, here it is:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 1995年，Yoav Benjamini 和 Yosef Hochberg 提出了一个异常简单的程序，用来告诉你哪些 *p* 值在统计上是显著的。到目前为止，我一直在帮你避开数学细节，但为了说明这个程序有多简单，给你看看它的具体内容：
- en: Perform your statistical tests and get the *p* value for each. Make a list and
    sort it in ascending order.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行你的统计检验并获得每个检验的 *p* 值。列出这些结果，并按升序排序。
- en: Choose a false-discovery rate and call it *q*. Call the number of statistical
    tests *m*.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个假发现率，并将其称为 *q*。将统计测试的数量称为 *m*。
- en: Find the largest *p* value such that *p* ≤ *iq*/*m*, where *i* is the *p* value’s
    place in the sorted list.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到最大的 *p* 值，使得 *p* ≤ *iq*/*m*，其中 *i* 是 *p* 值在排序列表中的位置。
- en: Call that *p* value and all smaller than it statistically significant.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 *p* 值以及所有小于它的值称为统计显著。
- en: 'You’re done! The procedure guarantees that out of all statistically significant
    results, on average no more than *q* percent will be false positives.^([10](apa.html#ch04en10))
    I hope the method makes intuitive sense: the *p* cutoff becomes more conservative
    if you’re looking for a smaller false-discovery rate (smaller *q*) or if you’re
    making more comparisons (higher *m*).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 完成了！该程序保证，在所有统计显著的结果中，平均而言，不超过 *q* 百分比会是假阳性。^([10](apa.html#ch04en10)) 我希望这个方法在直觉上是有意义的：如果你正在寻找更小的假发现率（更小的
    *q*）或进行更多比较（更高的 *m*），则 *p* 截止值会变得更加保守。
- en: The Benjamini–Hochberg procedure is fast and effective, and it has been widely
    adopted by statisticians and scientists. It’s particularly appropriate when testing
    hundreds of hypotheses that are expected to be mostly false, such as associating
    genes with diseases. (The vast majority of genes have nothing to do with a particular
    disease.) The procedure usually provides better statistical power than the Bonferroni
    correction, and the false discovery rate is easier to interpret than the false
    positive rate.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Benjamini–Hochberg 程序既快速又有效，且已被统计学家和科学家广泛采用。当测试数百个假设并且预期大多数是假设为假时，它尤其适用，比如将基因与疾病相关联。（绝大多数基因与某种特定疾病无关。）该程序通常提供比
    Bonferroni 校正更好的统计功效，且假发现率比假阳性率更易于解释。
- en: Tips
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: Remember, *p* < 0.05 isn’t the same as a 5% chance your result is false.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记住，*p* < 0.05 并不等同于你的结果有 5% 的概率是错误的。
- en: If you are testing multiple hypotheses or looking for correlations between many
    variables, use a procedure such as Bonferroni or Benjamini–Hochberg (or one of
    their various derivatives and adaptations) to control for the excess of false
    positives.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在测试多个假设或寻找许多变量之间的相关性，使用类似于 Bonferroni 或 Benjamini–Hochberg 程序（或它们的各种衍生版本和改编）的程序来控制假阳性过多的问题。
- en: If your field routinely performs multiple tests, such as in neuroimaging, learn
    the best practices and techniques specifically developed to handle your data.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的领域经常进行多重测试，例如神经影像学，学习专门为处理你数据而开发的最佳实践和技术。
- en: Learn to use prior estimates of the base rate to calculate the probability that
    a given result is a false positive (as in the mammogram example).
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学会使用基准率的先验估计来计算给定结果是假阳性的概率（如乳腺X光例子）。
- en: '* * *'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^([[9](#ch04fn01a)]) I hope you’ve concluded that *every* statement is false.
    The first five statements ignore the base rate, while the last question is asking
    about the *power* of the experiment, not its *p* value.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[9](#ch04fn01a)]) 我希望你已经得出结论，*每个*陈述都是错误的。前五个陈述忽略了基准率，而最后一个问题询问的是实验的*功效*，而不是它的
    *p* 值。
- en: ^([[10](#ch04fn02a)]) Being male doesn’t actually exclude you from getting breast
    cancer, but it’s far less likely.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[10](#ch04fn02a)]) 做男性并不会真正排除你得乳腺癌的可能性，但这种可能性要小得多。
- en: ^([[11](#ch04fn03a)]) The account that follows is based on letters and reports
    from the Legacy Tobacco Documents Library, an online collection of tobacco industry
    documents created as a result of the Tobacco Master Settlement Agreement.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[11](#ch04fn03a)]) 以下叙述基于《遗产烟草文献库》中的信件和报告，这是一个在线收集的烟草行业文档库，是“烟草主和解协议”产生的结果。
- en: ^([[12](#ch04fn04a)]) Physicists have the best unit names. Gigaelectronvolts,
    jiffies, inverse femtobarns—my only regret as a physicist who switched to statistics
    is that I no longer have excuses to use these terms.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[12](#ch04fn04a)]) 物理学家拥有最棒的单位名称。吉电子伏特、时刻、倒数飞秒巴恩——作为一名转行统计学的物理学家，我唯一的遗憾是再也没有借口使用这些术语了。
- en: ^([[13](#ch04fn05a)]) “Foam padding was placed within the head coil as a method
    of limiting salmon movement during the scan, but proved to be largely unnecessary
    as subject motion was exceptionally low.”
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ^([[13](#ch04fn05a)]) “在头部线圈内放置泡沫垫，以限制扫描过程中鲑鱼的移动，但证明它在很大程度上是多余的，因为受试者的运动异常低。”
