- en: <hgroup>
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <hgroup>
- en: 5 VULNERABILITY SCANNING AND FUZZING
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 漏洞扫描与模糊测试
- en: </hgroup>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: </hgroup>
- en: '![](../images/opener.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/opener.jpg)'
- en: In [Chapter 4](chapter4.xhtml), we identified hosts on a network and a few running
    services, including HTTP, FTP, and SSH. Each of these protocols has its own set
    of tests we could perform. In this chapter, we’ll use specialized tools on the
    discovered services to find out as much as we can about them.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](chapter4.xhtml)中，我们识别了网络上的主机和几个运行中的服务，包括HTTP、FTP和SSH。每种协议都有我们可以执行的一组测试。在本章中，我们将使用专门的工具对已发现的服务进行测试，尽可能多地了解它们。
- en: In the process, we’ll use bash to run security testing tools, parse their output,
    and write custom scripts to scale security testing across many URLs. We’ll fuzz
    with tools such as ffuf and Wfuzz, write custom security checks using the Nuclei
    templating system, extract personally identifiable information (PII) from the
    output of tools, and create our own quick-and-dirty vulnerability scanners.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，我们将使用bash运行安全测试工具，解析其输出，并编写自定义脚本，以便在多个URL上进行大规模的安全测试。我们将使用ffuf和Wfuzz等工具进行模糊测试，使用Nuclei模板系统编写自定义安全检查，从工具的输出中提取个人身份信息（PII），并创建我们自己的简易漏洞扫描器。
- en: Scanning Websites with Nikto
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Nikto扫描网站
- en: '*Nikto* is a web scanning tool available on Kali. It performs banner grabbing
    and runs a few basic checks to determine if the web server uses security headers
    to mitigate known web vulnerabilities; these vulnerabilities include *cross-site
    scripting (XSS)*, which is a client-side injection vulnerability targeting web
    browsers, and *UI redressing* (also known as *clickjacking*), a vulnerability
    that lets attackers use decoy layers in a web page to hijack user clicks. The
    security headers indicate to browsers what to do when loading certain resources
    and opening URLs, protecting the user from falling victim to an attack.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*Nikto*是Kali中可用的Web扫描工具。它执行横幅抓取并进行一些基本检查，以确定Web服务器是否使用安全头部来缓解已知的Web漏洞；这些漏洞包括*跨站脚本攻击（XSS）*，这是一种针对Web浏览器的客户端注入漏洞，以及*UI重定向*（也称为*点击劫持*），这是一种漏洞，允许攻击者在网页中使用诱饵层来劫持用户点击。安全头部指示浏览器在加载特定资源和打开URL时该如何处理，从而保护用户免受攻击。'
- en: After performing these security checks, Nikto also sends requests to possible
    endpoints on the server by using its built-in wordlist of common paths. The requests
    can discover interesting endpoints that could be useful for penetration testers.
    Let’s use Nikto to perform a basic web assessment of the three web servers we’ve
    identified on the IP addresses 172.16.10.10 (*p-web-01*), 172.16.10.11 (*p-ftp-01*),
    and 172.16.10.12 (*p-web-02*).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行这些安全检查后，Nikto还通过使用其内置的常见路径词典向服务器的可能端点发送请求。这些请求可以发现一些有趣的端点，对于渗透测试人员来说可能很有用。让我们使用Nikto对我们在IP地址172.16.10.10（*p-web-01*）、172.16.10.11（*p-ftp-01*）和172.16.10.12（*p-web-02*）上识别出的三个Web服务器进行基本的Web评估。
- en: 'We’ll run a Nikto scan against the web ports we found to be open on the three
    target IP addresses. Open a terminal and run the following commands one at a time
    so you can dissect the output for each IP address:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将针对我们发现开放的Web端口，对三个目标IP地址运行Nikto扫描。打开终端，依次运行以下命令，这样你可以逐一分析每个IP地址的输出结果：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output for 172.16.10.10 on port 8081 shouldn’t yield much interesting information
    about discovered endpoints, but it should indicate that the server doesn’t seem
    to be hardened, as it doesn’t use security headers:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 172.16.10.10在8081端口的输出应该不会提供太多关于发现端点的有趣信息，但它应该表明该服务器似乎没有经过加固，因为它没有使用安全头部：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Nikto was able to perform a banner grab of the server, as indicated by the line
    that starts with the word Server. It then listed a few missing security headers.
    These are useful pieces of information but not enough to take over a server just
    yet.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Nikto能够执行服务器的横幅抓取，这从以“Server”开头的行中可以看出。然后它列出了几个缺失的安全头部。这些是有用的信息，但还不足以完全接管服务器。
- en: 'The IP address 172.16.10.11 on port 80 should give you a similar result, though
    Nikto also discovered a new endpoint, */backup*, and that directory indexing mode
    is enabled:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: IP地址172.16.10.11上的80端口应该会给出类似的结果，尽管Nikto还发现了一个新端点，*/backup*，并且启用了该目录的索引模式：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Directory indexing* is a server-side setting that, instead of a web page,
    lists files located at certain web paths. When enabled, the directory indexing
    setting lists the content of a directory when an index file is missing (such as
    *index.html* or *index.php*). Directory indexing is interesting to find because
    it could highlight sensitive files in an application, such as configuration files
    with connection strings, local database files (such as SQLite files), and other
    environmental files. Open the browser in Kali to *http://172.16.10.11/backup*
    to see the content of this endpoint ([Figure 5-1](chapter5.xhtml#fig5-1)).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*目录索引* 是一种服务器端设置，它会在缺少索引文件（如 *index.html* 或 *index.php*）时，列出位于某些网页路径下的文件。当启用时，目录索引设置会列出一个目录的内容。目录索引很有趣，因为它可能会暴露应用程序中的敏感文件，例如包含连接字符串的配置文件、地方数据库文件（如
    SQLite 文件）以及其他环境文件。在 Kali 上打开浏览器，访问 *http://172.16.10.11/backup*，以查看此端点的内容（[图
    5-1](chapter5.xhtml#fig5-1)）。'
- en: '![](../images/pg97.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/pg97.jpg)'
- en: 'Figure 5-1: Directory indexing found on 172.16.10.11/backup'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-1：在 172.16.10.11/backup 上找到的目录索引
- en: 'Directory indexing lets you view files in the browser. You can click directories
    to open them, click files to download them, and so on. On the web page, you should
    identify two folders: *acme-hyper-branding* and *acme-impact -alliance*. The *acme-hyper-branding*
    folder appears to contain a file named *app.py*. Download it to Kali by clicking
    it so it’s available for later inspection.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 目录索引让你可以在浏览器中查看文件。你可以点击目录打开它们，点击文件下载它们，等等。在网页上，你应该能找到两个文件夹：*acme-hyper-branding*
    和 *acme-impact -alliance*。*acme-hyper-branding* 文件夹似乎包含一个名为 *app.py* 的文件。点击它下载到
    Kali 上，以便后续检查。
- en: We’ll explore the third IP address in a moment, but first let’s use bash automation
    to take advantage of directory indexing.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会探索第三个 IP 地址，但首先让我们利用 bash 自动化来利用目录索引。
- en: Building a Directory Indexing Scanner
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建一个目录索引扫描器
- en: What if we wanted to run a scan against a list of URLs to check whether they
    enable directory indexing, then download all the files they serve? In [Listing
    5-1](chapter5.xhtml#Lis5-1), we use bash to carry out such a task.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要对一组 URL 进行扫描，以检查它们是否启用了目录索引，并下载它们提供的所有文件，该怎么做呢？在 [列表 5-1](chapter5.xhtml#Lis5-1)
    中，我们使用 bash 执行这样的任务。
- en: directory _indexing _scanner.sh
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: directory _indexing _scanner.sh
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Listing 5-1: Automatically downloading files available via directory indexing'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5-1：自动下载通过目录索引提供的文件
- en: In this script, we define the FILE and OUTPUT_FOLDER variables. Their assigned
    values are taken from the arguments the user passes on the command line ($1 and
    $2). We then fail and exit the script (exit 1) if the FILE variable is not of
    the file type and of length zero (-s) ❶. If the file has a length of zero, it
    means the file is empty.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个脚本中，我们定义了 FILE 和 OUTPUT_FOLDER 变量。它们的赋值来自用户在命令行上传递的参数（$1 和 $2）。如果 FILE 变量不是文件类型或文件长度为零（-s）❶，我们就会失败并退出脚本（exit
    1）。如果文件的长度为零，意味着文件为空。
- en: We then use a while loop to read the file at the path assigned to the FILE variable.
    At ❸, we ensure that each whitespace character in each line from the file is removed
    by piping it to the xargs command. At ❹, we use curl to make an HTTP GET request
    and follow any HTTP redirects (using -L). We silence verbose output from curl
    (using -s) and pipe it to grep to find any instances of the strings Index of /
    and [PARENTDIR]. These two strings exist in directory indexing pages. You can
    verify this by viewing the source HTML page at *http://172.16.10.11/backup*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用 `while` 循环读取分配给 FILE 变量的路径下的文件。在 ❸ 处，我们确保通过将其传递给 xargs 命令，移除文件中每一行的所有空白字符。在
    ❹ 处，我们使用 curl 发起一个 HTTP GET 请求，并跟踪任何 HTTP 重定向（使用 -L）。我们通过加上 -s 参数让 curl 静默输出详细信息，并将结果传递给
    grep，以查找字符串 *Index of /* 和 *[PARENTDIR]* 的出现。这两个字符串存在于目录索引页面中。你可以通过查看 *http://172.16.10.11/backup*
    的源 HTML 页面来验证这一点。
- en: If we find either string, we call the wget command ❺ with the quiet option (-q)
    to silence verbose output, the recursive option (-r) to download files recursively
    from folders, the no-parent option (-np) to ensure we download only files at the
    same level of hierarchy or lower (subfolders), and the reject option (-R) to exclude
    files starting with *index.html*. We then use the target folder option (-P) to
    download the content to the path specified by the user calling the script (the
    OUTPUT_FOLDER variable). If the user didn’t provide a destination folder, the
    script will default to using the *data* folder ❷.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们找到任一字符串，我们会调用 wget 命令 ❺，并加上静默选项 (-q) 来抑制详细输出，递归选项 (-r) 用于递归下载文件，禁止父目录选项
    (-np) 确保我们只下载与当前目录同级或更低层次的文件（子文件夹），以及拒绝选项 (-R) 用于排除以 *index.html* 开头的文件。然后我们使用目标文件夹选项
    (-P) 将内容下载到用户调用脚本时指定的路径（OUTPUT_FOLDER 变量）。如果用户没有提供目标文件夹，脚本将默认使用 *data* 文件夹 ❷。
- en: NOTE
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意
- en: '*You can download this chapter’s scripts from* [https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05](https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可以从以下链接下载本章的脚本* [https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05](https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05)。'
- en: The *acme-impact-alliance* folder we downloaded appears to be empty. But is
    it really? When dealing with web servers, you may run into what seem to be dead
    ends only to find out that something is hiding there, just not in an obvious place.
    Take note of the empty folder for now; we’ll resume this exploration in a little
    bit.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下载的 *acme-impact-alliance* 文件夹似乎是空的。但真的是空的吗？在处理 Web 服务器时，你可能会遇到看似死胡同的情况，但最终会发现有东西隐藏在那里，只是没有在明显的地方。暂时记下这个空文件夹；稍后我们将继续这个探索。
- en: Identifying Suspicious robots.txt Entries
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别可疑的 robots.txt 条目
- en: 'After scanning the third IP address, 172.16.10.12 (*p-web-02*), Nikto outputs
    the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在扫描完第三个 IP 地址 172.16.10.12（*p-web-02*）后，Nikto 输出如下内容：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Nikto was able to find a lot more information this time! It caught missing security
    headers (which is extremely common to see in the wild, unfortunately). Next, Nikto
    found that the server is running on Apache and Debian and that it is powered by
    PHP, a backend programming language commonly used in web applications.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这次 Nikto 能发现更多信息了！它捕获了缺失的安全头（不幸的是，这在野外是非常常见的）。接下来，Nikto 发现服务器正在运行 Apache 和 Debian，并且它是由
    PHP 支持的，PHP 是一种常用于 Web 应用程序中的后端编程语言。
- en: It also found an uncommon link that points to *http://172.16.10.12/wp-json*
    and found two suspicious entries in the *robots.txt* file—namely, */wp-admin/*
    and */donate.php*. The *robots.txt* file is a special file used to indicate to
    web crawlers (such as Google’s search engine) which endpoints to index and which
    to ignore. Nikto hints that the *robots.txt* file may have more entries than just
    these two and advises us to inspect it manually.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 它还发现了一个不常见的链接，指向 *http://172.16.10.12/wp-json*，并在 *robots.txt* 文件中发现了两个可疑条目——即
    */wp-admin/* 和 */donate.php*。*robots.txt* 文件是一个特殊文件，用于指示网络爬虫（例如 Google 搜索引擎）哪些端点应该被索引，哪些应该被忽略。Nikto
    提示 *robots.txt* 文件可能包含比这两个条目更多的内容，并建议我们手动检查。
- en: Finally, it also identified another endpoint at */wp-login.php*, which is a
    login page for WordPress, a blog platform. Navigate to the main page at *http://172.16.10.12/*
    to confirm you’ve identified a blog.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，它还识别出了另一个端点 */wp-login.php*，这是一个用于 WordPress 博客平台的登录页面。访问主页面 *http://172.16.10.12/*
    来确认你已经识别出一个博客。
- en: 'Finding these non-indexed endpoints is useful during a penetration test because
    you can add them to your list of possible targets to test. When you open this
    file, you should notice a list of paths:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在渗透测试中，发现这些未索引的端点是非常有用的，因为你可以将它们添加到可能的目标列表中进行测试。当你打开这个文件时，你应该会注意到一系列路径：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We identified some of these endpoints earlier (such as */donate.php* and */wp-admin*),
    but others we didn’t see when scanning with Nikto. In Exercise 5, you’ll use bash
    to automate your exploration of them.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前识别了一些这些端点（例如 */donate.php* 和 */wp-admin*），但有些端点在使用 Nikto 扫描时没有看到。在练习 5 中，你将使用
    bash 自动化探索这些端点。
- en: 'Exercise 5: Exploring Non-indexed Endpoints'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 5：探索未索引的端点
- en: Nikto scanning returned a list of non-indexed endpoints. In this exercise, you’ll
    use bash to see whether they really exist on the server. Put together a script
    that will make an HTTP request to *robots.txt*, return the response, and iterate
    over each line, parsing the output to extract only the paths. Then the script
    should make an additional HTTP request to each path and check the status code
    it returns.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Nikto扫描返回了一个非索引的端点列表。在这个练习中，你将使用bash脚本来查看这些端点是否真的存在于服务器上。编写一个脚本，通过HTTP请求访问*robots.txt*，返回响应并逐行遍历，解析输出以提取路径。然后，脚本应该向每个路径发出额外的HTTP请求，并检查返回的状态码。
- en: '[Listing 5-2](chapter5.xhtml#Lis5-2) is an example script that can get you
    started. It relies on a useful curl feature you’ll find handy in your bash scripts:
    built-in variables you can reference to extract particular values from HTTP requests
    and responses, such as the size of the request sent (%{size_request}) and the
    size of the headers returned in bytes (%{size_header}).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表5-2](chapter5.xhtml#Lis5-2)是一个示例脚本，可以帮助你入门。它依赖于一个非常有用的curl功能，这个功能在bash脚本中非常实用：内置变量，可以用来提取HTTP请求和响应中的特定值，例如发送请求的大小（%{size_request}）和返回的头部大小（%{size_header}）。'
- en: curl_fetch _robots_txt.sh
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: curl_fetch _robots_txt.sh
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Listing 5-2: Reading robots.txt and making requests to individual paths'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5-2：读取robots.txt并向各个路径发出请求
- en: At ❶, we read the output from the curl command at ❹ line by line. This command
    makes an HTTP GET request to *http://172.16.10.12/robots.txt*. We then parse each
    line and grab the second field (which is separated from the others by a space)
    to extract the path and assign it to the path variable ❷. We check that the path
    variable length is greater than zero to ensure we were able to properly parse
    it ❸.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在❶处，我们逐行读取curl命令在❹行中的输出。该命令向*http://172.16.10.12/robots.txt*发出HTTP GET请求。然后我们解析每一行并提取第二个字段（它由空格与其他字段分隔），提取路径并将其赋值给路径变量❷。我们检查路径变量的长度是否大于零，以确保我们能够正确解析它❸。
- en: Then we create a url variable, which is a string concatenated from the TARGET_URL
    variable plus each path from the *robots.txt* file, and make an HTTP request to
    the URL. We use the -w (write-out) variable %{http_code} to extract only the status
    code from the response returned by the web server.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建一个url变量，它是由TARGET_URL变量加上*robots.txt*文件中的每个路径拼接而成的字符串，并向该URL发出HTTP请求。我们使用-w（write-out）变量%{http_code}来仅提取Web服务器返回的状态码。
- en: To go beyond this script, try using other curl variables. You can find the full
    list of variables at *[https://curl.se/docs/manpage.html](https://curl.se/docs/manpage.html)*
    or by running the man curl command.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要进一步扩展这个脚本，试试使用其他curl变量。你可以在*[https://curl.se/docs/manpage.html](https://curl.se/docs/manpage.html)*中找到完整的变量列表，或者通过运行man
    curl命令来查看。
- en: Brute-Forcing Directories with dirsearch
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用dirsearch进行目录暴力破解
- en: The *dirsearch* fast directory brute-forcing tool is used to find hidden paths
    and files on web servers. Written in Python by Mauro Soria, dirsearch provides
    features such as built-in web directory wordlists, bring-your-own-dictionary options,
    and advanced response filtering. We’ll use it to try to identify additional attack
    vectors and verify that Nikto hasn’t missed anything obvious.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*dirsearch*是一个快速的目录暴力破解工具，用于查找Web服务器上的隐藏路径和文件。它由Mauro Soria用Python编写，提供了诸如内置Web目录字典、自定义字典选项和高级响应过滤等功能。我们将使用它来尝试识别额外的攻击向量，并验证Nikto是否遗漏了任何明显的内容。'
- en: 'First, let’s rescan port 8081 on *p-web-01* (172.16.10.10), which yielded no
    discovered endpoints when scanned by Nikto. The following dirsearch command uses
    the -u (URL) option to specify a base URL from which to start crawling:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们重新扫描*p-web-01*（172.16.10.10）的8081端口，Nikto扫描时未发现任何端点。以下dirsearch命令使用-u（URL）选项来指定一个起始爬行的基本URL：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Great! This tool was able to pick up two previously unknown endpoints named
    */upload* and */uploads*. This is why it’s important to double- and triple-check
    your results by using more than one tool and to manually verify the findings;
    tools sometimes produce false positives or use limited path-list databases. If
    you navigate to the */upload* page, you should see a file-upload form. Take note
    of this endpoint because we’ll test it in [Chapter 6](chapter6.xhtml).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！这个工具成功地识别出了两个先前未知的端点，分别是*/upload*和*/uploads*。这就是为什么使用多个工具并手动验证结果非常重要，必须进行双重和三重检查；因为工具有时会产生假阳性或使用有限的路径列表数据库。如果你访问*/upload*页面，你应该能看到一个文件上传表单。记住这个端点，因为我们将在[第6章](chapter6.xhtml)中进行测试。
- en: 'Let’s also use dirsearch to look for attack vectors in what looked like an
    empty folder on *p-ftp-01*, at *http://172.16.10.11/backup/acme-impact-alliance*:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 dirsearch 来寻找看起来像是空文件夹的攻击向量，位于*p-ftp-01*，网址为*http://172.16.10.11/backup/acme-impact-alliance*：
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: dirsearch inspects responses returned from the web server to identify interesting
    behaviors that could indicate the existence of an asset. For example, the tool
    might note whether a certain URL redirects to a new location (specified by an
    HTTP status code 301) and the response size in bytes. Sometimes you can infer
    information and observe behaviors solely by inspecting this data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: dirsearch 检查从 Web 服务器返回的响应，以识别可能表明资产存在的有趣行为。例如，工具可能会注意到某个 URL 是否重定向到新位置（由 HTTP
    状态码 301 指定）以及响应的字节数。有时你可以仅通过检查这些数据来推断信息并观察行为。
- en: This time, we’ve identified a subfolder within the *acme-impact-alliance* folder
    named *.git*. A folder with this name usually indicates the existence of a Git
    repository on the server. *Git* is a source code management tool, and in this
    case, it likely manages code running locally on the remote server.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们发现了一个名为*.git*的子文件夹，位于*acme-impact-alliance*文件夹内。一个名为*.git*的文件夹通常表示服务器上存在
    Git 仓库。*Git* 是一个源代码管理工具，在这种情况下，它可能管理着运行在远程服务器上的本地代码。
- en: Use dirsearch again to perform brute forcing against the second directory, */backup/acme-hyper-branding*.
    Save the results into their own folder, then check them. You should find a Git
    repository there too.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 再次使用 dirsearch 对第二个目录*/backup/acme-hyper-branding*进行暴力破解。将结果保存到自己的文件夹中，然后检查它们。你应该也能在那儿找到一个
    Git 仓库。
- en: Exploring Git Repositories
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 Git 仓库
- en: When you find a Git repository, it’s often useful to run a specialized Git cloner
    that pulls the repository and all its associated metadata so you can inspect it
    locally. For this task, we’ll use Gitjacker.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当你找到一个 Git 仓库时，通常使用一个专门的 Git 克隆工具来拉取仓库及其所有关联的元数据，这样你就可以在本地检查它。对于这项任务，我们将使用 Gitjacker。
- en: Cloning the Repository
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 克隆仓库
- en: 'Gitjacker’s command is pretty simple. The first argument is a URL, and the
    -o (output) argument takes a folder name into which the data will be saved if
    Gitjacker succeeds at pulling the repository:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Gitjacker 的命令非常简单。第一个参数是一个 URL，-o（输出）参数则接受一个文件夹名称，如果 Gitjacker 成功拉取仓库，数据将保存在该文件夹中：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As you can see, the tool returned a successful status and a few thousand objects.
    At this point, you should have a folder named *acme-impact-alliance-git*:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，工具返回了成功的状态和几千个对象。此时，你应该有一个名为*acme-impact-alliance-git*的文件夹：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Notice some familiar filenames in this list? We saw *donate.php* and *robots.txt*
    earlier, when we scanned the 172.16.10.12 (*p-web-02*) host.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到列表中有一些熟悉的文件名吗？我们之前在扫描 172.16.10.12 (*p-web-02*) 主机时，看到过*donate.php*和*robots.txt*。
- en: Viewing Commits with git log
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 git log 查看提交
- en: 'When you run into a Git repository, you should attempt a git log command to
    see the history of Git code commits made to the repository, as they may include
    interesting data we could use as attackers. In source code management, a *commit*
    is a snapshot of the code’s state that is taken before the code is pushed to the
    main repository and made permanent. Commit information could include details about
    who made the commit and a description of the change (such as whether it was a
    code addition or deletion):'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当你遇到一个 Git 仓库时，你应该尝试运行 git log 命令，查看对仓库做出的 Git 代码提交历史，因为这些提交可能包含我们作为攻击者可以利用的有趣数据。在源代码管理中，*commit*
    是在代码推送到主仓库并使其永久化之前，代码状态的一个快照。提交信息可能包括关于谁进行了提交以及变更描述（例如，是否是代码的添加或删除）的细节：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We’ve identified a person who has committed code to the Git repository: Kevin
    Peterson, at *kpeterson@acme-impact-alliance.com*. Take note of this information
    because this account could exist in other places found during the penetration
    test.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经识别出一个向 Git 仓库提交代码的人：Kevin Peterson，邮箱为*kpeterson@acme-impact-alliance.com*。请注意这些信息，因为该账户可能在渗透测试过程中发现的其他地方也存在。
- en: 'Try running Gitjacker again to hijack the Git repository that lives on the
    second folder, at */backup/acme-hyper-branding*. Then execute another git log
    command to see who committed code to this repository, as we did before. The log
    should reveal the identity of a second person: Melissa Rogers, at *mrogers@acme-hyper-branding.com*.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试再次运行 Gitjacker 来劫持位于第二个文件夹*/backup/acme-hyper-branding*中的 Git 仓库。然后执行另一个 git
    log 命令，查看是谁向该仓库提交了代码，就像我们之前做的那样。日志应该揭示第二个人的身份：Melissa Rogers，邮箱为*mrogers@acme-hyper-branding.com*。
- en: 'You may sometimes run into Git repositories with many contributors and many
    commits. We can use Git’s built-in --pretty=format option to easily extract all
    this metadata, like so:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你有时可能会遇到有许多贡献者和提交的Git仓库。我们可以使用Git的内置--pretty=format选项轻松提取所有这些元数据，如下所示：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The %ae (author name) and %ae (email) fields are built-in placeholders in Git
    that allow you to specify values of interest to include in the output. For the
    list of all available variables, see *[https://git-scm.com/docs/pretty-formats#_pretty_formats](https://git-scm.com/docs/pretty-formats#_pretty_formats)*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '%ae（作者名称）和%ae（电子邮件）字段是Git中的内置占位符，允许你指定需要包含在输出中的有用值。有关所有可用变量的列表，请参见*[https://git-scm.com/docs/pretty-formats#_pretty_formats](https://git-scm.com/docs/pretty-formats#_pretty_formats)*。'
- en: Filtering git log Information
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过滤git log信息
- en: 'Even without the pretty formatting, bash can filter git log output with a single
    line:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 即使没有漂亮的格式，bash也可以通过一行命令过滤git log输出：
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This bash code runs git log, uses grep to search for any lines that start with
    the word Author, and then pipes the results to another grep command, which uses
    regular expressions (-oP) to filter anything after the word Author: and print
    only the words that matched. This filtering leaves us with the Git commit author’s
    name and email.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这段bash代码运行git log，使用grep查找以“Author”开头的行，然后将结果传输到另一个grep命令，该命令使用正则表达式（-oP）过滤出“Author:”之后的内容，并仅打印匹配的单词。这个过滤过程会留下Git提交的作者姓名和电子邮件。
- en: Because the same author could have made multiple commits, we use sort to sort
    the list and use the -u option to remove any duplicated lines, leaving us with
    a list free of duplicated entries. Finally, since the email is surrounded by the
    characters <> by default, we trim these characters by using tr -d '<>'.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 因为同一个作者可能进行了多个提交，所以我们使用sort对列表进行排序，并使用-u选项去除任何重复的行，从而得到一个没有重复条目的列表。最后，由于电子邮件默认被<>字符包围，我们通过使用tr
    -d '<>'来去除这些字符。
- en: Inspecting Repository Files
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检查仓库文件
- en: 'The repository contains a file called *app.py*. Let’s inspect its contents
    by viewing it in a text editor. You should see that the file contains web server
    code written with Python’s Flask library:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 仓库包含一个名为*app.py*的文件。让我们通过文本编辑器查看它的内容。你应该能看到这个文件包含了使用Python的Flask库编写的Web服务器代码：
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The interesting parts here are the endpoints that are exposed via @app.route().
    You can see that the application exposes endpoints such as */*, */files*, */upload*,
    and */uploads*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有趣的部分是通过@app.route()暴露的端点。你可以看到应用程序暴露了如*/\*、*/files*、*/upload*和*/uploads*等端点。
- en: When we scanned the target IP address range with dirsearch and Nikto, we saw
    two endpoints, named */upload* and */uploads*, on *p-web-01* (172.16.10.10:8081).
    Because this Python file includes the same endpoints, this source code likely
    belongs to the application running on the server.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用dirsearch和Nikto扫描目标IP地址范围时，我们在*p-web-01*（172.16.10.10:8081）上看到了两个端点，分别是*/upload*和*/uploads*。因为这个Python文件包含了相同的端点，所以这个源代码很可能属于服务器上运行的应用程序。
- en: 'You may be asking yourself why we didn’t find the */files* endpoint in our
    scans. Well, web scanners often rely on response status codes returned by web
    servers to determine whether certain endpoints exist. If you run the following
    curl command with the -I (HEAD request) option, you’ll see that the */files* endpoint
    returns the HTTP status code 404 Not Found:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么我们没有在扫描中找到*/files*端点。实际上，Web扫描器通常依赖Web服务器返回的响应状态码来判断某些端点是否存在。如果你运行以下带有-I（HEAD请求）选项的curl命令，你将看到*/files*端点返回HTTP状态码404
    Not Found：
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Web scanners interpret these 404 errors as indicating that an endpoint doesn’t
    exist. Yet the reason we get 404 errors here is that, when called directly, */files*
    doesn’t serve any requests. Instead, it serves requests for web paths appended
    to */files*, such as */files/abc.jpg* or */files/salary.docx*.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Web扫描器将这些404错误解释为指示某个端点不存在。然而，我们在这里得到404错误的原因是，当直接调用时，*/files*并不处理任何请求。相反，它处理的是以*/files*为前缀的Web路径请求，例如*/files/abc.jpg*或*/files/salary.docx*。
- en: Vulnerability Scanning with Nuclei
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Nuclei进行漏洞扫描
- en: '*Nuclei* is one of the most impressive open source vulnerability scanners released
    in recent years. Its advantage over other tools stems from its community-powered
    templating system, which reduces false positives by matching known patterns against
    responses it receives from network services and files. It also reduces barriers
    to writing vulnerability checks, as it doesn’t require learning how to code. You
    can also easily extend it to do custom security checks.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*Nuclei*是近年来发布的最令人印象深刻的开源漏洞扫描器之一。它相对于其他工具的优势在于其由社区驱动的模板系统，通过将已知模式与来自网络服务和文件的响应进行匹配，从而减少误报。它还降低了编写漏洞检查的门槛，因为它不要求学习如何编写代码。您还可以轻松扩展它来执行自定义安全检查。'
- en: Nuclei naturally supports common network services, such as HTTP, DNS, and network
    sockets, as well as local file scanning. You can use it to send HTTP requests,
    DNS queries, and raw bytes over the network. Nuclei can even scan files to find
    credentials (for example, when you’ve identified an open Git repository and want
    to pull it locally to find secrets).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Nuclei天然支持常见的网络服务，如HTTP、DNS和网络套接字，以及本地文件扫描。您可以使用它发送HTTP请求、DNS查询和原始字节数据。Nuclei甚至可以扫描文件以查找凭证（例如，当您发现一个开放的Git仓库，并希望将其拉取到本地以查找机密信息时）。
- en: As of this writing, Nuclei has more than 8,000 templates in its database. In
    this section, we’ll introduce Nuclei and how to use it.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本文写作时，Nuclei的数据库中已有超过8,000个模板。在本节中，我们将介绍Nuclei及其使用方法。
- en: Understanding Templates
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解模板
- en: 'Nuclei templates are based on YAML files with the following high-level structure:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Nuclei模板基于YAML文件，具有以下高级结构：
- en: '**ID **A unique identifier for the template'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**ID** 模板的唯一标识符'
- en: '**Metadata **Information about the template, such as a description, the author,
    the severity, and tags (arbitrary labels that can group multiple templates, such
    as *injection* or *denial of service*)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**元数据** 有关模板的信息，如描述、作者、严重性和标签（可用于分组多个模板的任意标签，例如 *注入* 或 *拒绝服务*）'
- en: '**Protocol **The mechanism that the template uses to make its requests; for
    example, http is a protocol type that uses HTTP for web requests'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**协议** 模板用于发起请求的机制；例如，http是一个使用HTTP进行Web请求的协议类型'
- en: '**Operators **Used for matching patterns against responses received by a template
    execution (*matchers*) and extracting data (*extractors*), similarly to the filtering
    performed by tools like grep'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**操作符** 用于将模式与模板执行时收到的响应进行匹配（*匹配器*）并提取数据（*提取器*），类似于grep等工具执行的过滤操作'
- en: Here is a simple example of a Nuclei template that uses HTTP to find the default
    Apache HTML welcome page. Navigate to *http://172.16.10.11/* to see what this
    page looks like.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的Nuclei模板示例，使用HTTP查找默认的Apache HTML欢迎页面。请访问 *http://172.16.10.11/* 来查看该页面的样子。
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We define the template metadata, such as the template’s name, author, severity,
    and so on ❶. We then instruct Nuclei to use an HTTP client when executing this
    template ❷. We also declare that the template should use the GET method. Next,
    we define a variable that will be swapped with the target URL we’ll provide to
    Nuclei on the command line at scan time. Then, we define a single matcher of type
    word ❸ and a search pattern to match against the HTTP response body coming back
    from the server, defined by part: body.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义模板的元数据，如模板的名称、作者、严重性等❶。然后，我们指示Nuclei在执行此模板时使用HTTP客户端❷。我们还声明模板应使用GET方法。接下来，我们定义一个变量，该变量将在扫描时由我们提供给Nuclei的目标URL进行替换。然后，我们定义一个类型为word的匹配器❸，并定义一个搜索模式，用于与从服务器返回的HTTP响应体进行匹配，模式由部分：body定义。
- en: 'As a result, when Nuclei performs a scan against an IP address that runs some
    form of a web server, this template will make a GET request to its base URL (/)
    and look for the string Apache2 ubuntu Default Page: It works in the response.
    If it finds this string in the response’s body, the check will be considered successful
    because the pattern matched.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，当Nuclei对运行某种Web服务器的IP地址执行扫描时，模板将向其基本URL（/）发送GET请求，并查找响应中的字符串“Apache2 ubuntu
    Default Page: It works”。如果在响应体中找到该字符串，则表示检查成功，因为模式匹配成功。'
- en: We encourage you to explore Nuclei’s templating system at *[https://docs.projectdiscovery.io/introduction](https://docs.projectdiscovery.io/introduction)*,
    as you can easily use Nuclei with bash to perform continuous assessments.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们鼓励您探索Nuclei的模板系统，访问 *[https://docs.projectdiscovery.io/introduction](https://docs.projectdiscovery.io/introduction)*，因为您可以轻松地使用Nuclei与bash进行持续评估。
- en: Writing a Custom Template
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编写自定义模板
- en: 'Let’s write a simple template that finds the Git repositories we discovered
    earlier, on *p-ftp-01* (172.16.10.11). We’ll define multiple BaseURL paths to
    represent the two paths we’ve identified. Then, using Nuclei’s matchers, we’ll
    define a string ref: refs/heads/master to match the response body returned by
    the scanned server:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们编写一个简单的模板，查找我们之前发现的 Git 仓库，位于 *p-ftp-01*（172.16.10.11）。我们将定义多个 BaseURL 路径，以表示我们识别的两个路径。然后，使用
    Nuclei 的匹配器，我们将定义一个字符串 ref: refs/heads/master，用于匹配扫描服务器返回的响应体：'
- en: git-finder.yaml
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: git-finder.yaml
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This template works just like the one in the previous example, except this
    time we provide two paths to check against: */backup/acme-hyper-branding/.git/HEAD*
    and */backup/acme-impact-alliance/.git/HEAD*. The matcher defines the string we
    expect to see in the *HEAD* file. You can confirm the match by making a curl request
    to the Git repository at 172.16.10.11:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模板的工作原理和前一个示例中的模板一样，只不过这次我们提供了两个路径进行检查：*/backup/acme-hyper-branding/.git/HEAD*
    和 */backup/acme-impact-alliance/.git/HEAD*。匹配器定义了我们期望在 *HEAD* 文件中看到的字符串。你可以通过向
    172.16.10.11 的 Git 仓库发起 curl 请求来确认匹配：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Download this custom Nuclei template from the book’s GitHub repository.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 从本书的 GitHub 仓库下载这个自定义 Nuclei 模板。
- en: Applying the Template
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用模板
- en: 'Let’s run Nuclei against *p-ftp-01* (172.16.10.11) with the custom template
    we just wrote. Nuclei stores its built-in templates in the folder *~/.local/nuclei-templates*.
    First, run the following command to update Nuclei’s template database:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对 *p-ftp-01*（172.16.10.11）运行 Nuclei，使用我们刚刚编写的自定义模板。Nuclei 将其内置模板存储在文件夹 *~/.local/nuclei-templates*
    中。首先，运行以下命令以更新 Nuclei 的模板数据库：
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Next, save the custom template into the folder *~/.local/nuclei-templates/custom*
    and give it a name such as *git-finder.yaml*.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将自定义模板保存到文件夹 *~/.local/nuclei-templates/custom* 中，并命名为 *git-finder.yaml*。
- en: 'In the following command, the -u (URL) option specifies the address, and -t
    (template) specifies the path to the template:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下命令中，-u（URL）选项指定地址，-t（template）选项指定模板路径：
- en: '[PRE20]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you can see, we were able to identify the two Git repositories with the custom
    template.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们能够通过自定义模板识别出两个 Git 仓库。
- en: Running a Full Scan
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行完整扫描
- en: 'When not provided with a specific template, Nuclei will use its built-in templates
    during the scan. Running Nuclei is noisy, so we recommend tailoring the execution
    to a specific target. For instance, if you know a server is running Apache, you
    could select just the Apache-related templates by specifying the -tags option:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当未提供特定模板时，Nuclei 会在扫描中使用其内置模板。运行 Nuclei 会产生很多输出，因此我们建议根据特定目标定制执行。例如，如果你知道某个服务器运行
    Apache，你可以通过指定 -tags 选项来选择仅与 Apache 相关的模板：
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Run nuclei -tl to get a list of all available templates.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 nuclei -tl 获取所有可用模板的列表。
- en: 'Let’s run a full Nuclei scan against the three IP addresses in the 172.16.10.0/24
    network by using all its built-in templates:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对 172.16.10.0/24 网络中的三个 IP 地址运行一次完整的 Nuclei 扫描，使用所有内置模板：
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Nuclei tries to optimize the number of total requests made by using *clustering*.
    When multiple templates call the same web path (such as */backup*), Nuclei consolidates
    these into a single request to reduce network overhead. However, Nuclei could
    still send thousands of requests during a single scan. You can control the number
    of requests sent by specifying the rate limit option (-rl), followed by an integer
    indicating the number of allowed requests per second.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Nuclei 通过使用 *聚类* 来优化总请求次数。当多个模板调用相同的 Web 路径（如 */backup*）时，Nuclei 会将这些请求合并为一个，以减少网络开销。然而，Nuclei
    在一次扫描中仍然可能发送成千上万的请求。你可以通过指定速率限制选项 (-rl)，后跟一个整数，来控制每秒允许的请求数。
- en: 'The full scan results in a lot of findings, so append the output to a file
    (using >>) so that you can examine them one by one. As you’ll see, Nuclei can
    identify vulnerabilities, but it can also fingerprint the target server and the
    technologies running on it. Nuclei should have highlighted findings seen previously,
    as well as a few new ones. Here are some of the issues it detected:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 完整扫描结果会产生大量发现，因此将输出附加到文件中（使用 >>），以便逐一检查。正如你所看到的，Nuclei 可以识别漏洞，但它也可以指纹识别目标服务器及其运行的技术。Nuclei
    应该会高亮显示之前看到的发现，以及一些新的问题。以下是它检测到的一些问题：
- en: An FTP server with anonymous access enabled on 172.16.10.11 port 21
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 172.16.10.11 的 21 端口上启用了匿名访问的 FTP 服务器
- en: A WordPress login page at *172.16.10.12/wp-login.php*
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 位于 *172.16.10.12/wp-login.php* 的 WordPress 登录页面
- en: A WordPress user-enumeration vulnerability (CVE-2017-5487) at *[http://172.16.10.12/?rest_route=/wp/v2/users/](http://172.16.10.12/?rest_route=/wp/v2/users/)*
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WordPress 用户枚举漏洞（CVE-2017-5487）位于 *[http://172.16.10.12/?rest_route=/wp/v2/users/](http://172.16.10.12/?rest_route=/wp/v2/users/)*
- en: 'Let’s manually confirm these three findings to ensure there are no false positives.
    Connect to the identified FTP server at 172.16.10.11 by issuing the following
    ftp command. This command will connect to the server by using the *anonymous*
    user and an empty password:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们手动确认这三项发现，确保没有误报。通过执行以下 ftp 命令连接到标识出的 FTP 服务器 172.16.10.11。此命令将使用 *匿名* 用户和空密码连接到服务器：
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We were able to connect! Let’s issue an ls command to verify that we can list
    files and directories on the server:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功连接！让我们执行 ls 命令来验证是否能够列出服务器上的文件和目录：
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We see an *index.html* file and a *backup* folder. This is the same folder that
    stores the two Git repositories we saw earlier, except now we have access to the
    FTP server where these files actually live.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到一个 *index.html* 文件和一个 *backup* 文件夹。这与我们之前看到的两个 Git 仓库所在的文件夹相同，只是现在我们可以访问这些文件所在的
    FTP 服务器。
- en: Next, open a browser to *http://172.16.10.12/wp-login.php* from your Kali machine.
    You should see the page in [Figure 5-2](chapter5.xhtml#fig5-2).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，从你的 Kali 机器上打开浏览器，访问 *http://172.16.10.12/wp-login.php*。你应该能看到 [图 5-2](chapter5.xhtml#fig5-2)
    中的页面。
- en: '![](../images/pg109.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/pg109.jpg)'
- en: 'Figure 5-2: The WordPress login page'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-2：WordPress 登录页面
- en: 'Finally, verify the third finding: the WordPress user-enumeration vulnerability,
    which allows you to gather information about WordPress accounts. By default, every
    WordPress instance exposes an API endpoint that lists WordPress system users.
    The endpoint usually doesn’t require authentication or authorization, so a simple
    GET request should return the list of users.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，验证第三项发现：WordPress 用户枚举漏洞，它允许你收集有关 WordPress 账户的信息。默认情况下，每个 WordPress 实例都会公开一个
    API 端点，列出 WordPress 系统用户。该端点通常不需要身份验证或授权，因此一个简单的 GET 请求应该返回用户列表。
- en: 'We’ll use curl to send this request and then pipe the response to jq to prettify
    the JSON output that comes back. The result should be an array of user data:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 curl 发送此请求，然后将响应传递给 jq 来美化返回的 JSON 输出。结果应该是一个用户数据的数组：
- en: '[PRE25]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The blog has a single user, *jtorres*. This can be a good target to brute-force
    later. If this curl command had returned many users, you could have parsed only
    the usernames with jq ([Listing 5-3](chapter5.xhtml#Lis5-3)).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 该博客只有一个用户，*jtorres*。这可以作为后续暴力破解的好目标。如果这个 curl 命令返回了许多用户，你本可以只使用 jq 提取用户名 ([清单
    5-3](chapter5.xhtml#Lis5-3))。
- en: '[PRE26]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Listing 5-3: Extracting usernames from an HTTP response'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 5-3：从 HTTP 响应中提取用户名
- en: All three findings were true positives, which is great news for us. [Table 5-1](chapter5.xhtml#tab5-1)
    recaps the users we’ve identified so far.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 三项发现都是正确信号，这对我们来说是好消息。[表 5-1](chapter5.xhtml#tab5-1) 总结了我们到目前为止识别的用户。
- en: 'Table 5-1: Identity Information Gathered from Repositories and WordPress'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-1：从仓库和 WordPress 收集的身份信息
- en: '| Source | Name | Email |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 来源 | 姓名 | 电子邮件 |'
- en: '| --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| acme-impact-alliance Git repository | Kevin Peterson | kpeterson@acme-impact-alliance.com
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| acme-impact-alliance Git 仓库 | Kevin Peterson | kpeterson@acme-impact-alliance.com
    |'
- en: '| acme-hyper-branding Git repository | Melissa Rogers | mrogers@acme-hyper-branding.com
    |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| acme-hyper-branding Git 仓库 | Melissa Rogers | mrogers@acme-hyper-branding.com
    |'
- en: '| WordPress account | J. Torres | jtorres@acme-impact-alliance.com |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| WordPress 账户 | J. Torres | jtorres@acme-impact-alliance.com |'
- en: Because the *jtorres* account was found on the ACME Impact Alliance website
    and we already know the email scheme the website uses, it’s pretty safe to assume
    that the *jtorres* email is *jtorres@acme-impact-alliance.com*.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 因为在 ACME Impact Alliance 网站上找到了 *jtorres* 账户，而且我们已经知道该网站使用的邮箱格式，所以可以相对安全地假设
    *jtorres* 的电子邮件是 *jtorres@acme-impact-alliance.com*。
- en: 'Exercise 6: Parsing Nuclei’s Findings'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 6：解析 Nuclei 的发现
- en: 'Nuclei’s scan output is a little noisy and can be difficult to parse with bash,
    but not impossible. Nuclei allows you to pass a -silent parameter to show only
    the findings in the output. Before you write a script to parse it, consider Nuclei’s
    output format:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Nuclei 的扫描输出有些杂乱，用 bash 解析起来可能有点困难，但并非不可能。Nuclei 允许你传递 -silent 参数来仅显示输出中的发现项。在你编写脚本来解析之前，先了解
    Nuclei 的输出格式：
- en: '[template] [protocol] [severity] url [extractor]'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[template] [protocol] [severity] url [extractor]'
- en: Each field is enclosed in square brackets [] and separated by spaces. The template
    field is a template name (taken from the name of the template file); the protocol
    shows the protocol, such as HTTP; and the severity shows the severity of the finding
    (informational, low, medium, high, or critical). The fourth field is the URL or
    IP address, and the fifth field is metadata extracted by the template’s logic
    using extractors.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 每个字段用方括号 [] 括起来，并且用空格分隔。模板字段是模板的名称（取自模板文件的名称）；协议字段显示协议类型，例如 HTTP；严重性字段显示发现的严重性（信息、低、中、高或关键）。第四个字段是
    URL 或 IP 地址，第五个字段是通过模板逻辑和提取器提取的元数据。
- en: Now you should be able to parse this information with bash. [Listing 5-4](chapter5.xhtml#Lis5-4)
    shows an example script that runs Nuclei, filters for a specific severity of interest,
    parses the interesting parts, and emails you the results.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该能够使用 bash 解析这些信息。[清单 5-4](chapter5.xhtml#Lis5-4)展示了一个示例脚本，运行 Nuclei，筛选出感兴趣的特定严重性，解析出有趣的部分，并将结果通过邮件发送给你。
- en: nuclei-notifier.sh
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: nuclei-notifier.sh
- en: '[PRE27]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Listing 5-4: Scanning with Nuclei and sending yourself the results'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 5-4：使用 Nuclei 扫描并将结果发送给自己
- en: Let’s dissect the code to better understand what it’s doing. We use a for loop
    to iterate through values in the $@ variable, a special value you learned about
    in [Chapter 1](chapter1.xhtml) that contains the arguments passed to the script
    on the command line. We assign each argument to the ip_address variable.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们剖析一下代码，以更好地理解它的功能。我们使用 for 循环遍历 $@ 变量中的值，$@ 是一个特殊变量，你在[第 1 章](chapter1.xhtml)中学到，它包含传递给脚本的命令行参数。我们将每个参数赋值给
    ip_address 变量。
- en: Next, we run a Nuclei scan, passing it the -severity argument to scan for vulnerabilities
    categorized as either medium, high, or critical, and save the output to the result
    variable ❶. At ❷, we read the output passed to the while loop at ❹ line by line.
    From each line, we extract the first field, using the tr -d '[]' command to remove
    the [] characters for a cleaner output. We also extract the fourth field from
    each line, which is where Nuclei stores the vulnerable URL. At ❸, we send an email
    containing the relevant information.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们运行 Nuclei 扫描，传递 -severity 参数扫描中等、高危或关键类别的漏洞，并将输出保存到 result 变量❶中。在 ❷ 处，我们逐行读取传递给
    while 循环的输出，提取每一行的第一个字段，使用 tr -d '[]' 命令移除 [] 字符，以获得更清晰的输出。我们还从每一行中提取第四个字段，这是
    Nuclei 存储易受攻击 URL 的地方。在 ❸ 处，我们发送一封包含相关信息的邮件。
- en: 'To run this script, save it to a file and pass the IP addresses to scan on
    the command line:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此脚本，请将其保存到文件中，并在命令行中传递要扫描的 IP 地址：
- en: '[PRE28]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: To make this script your own, try having Nuclei output JSON data by using the
    -j option. Then pipe this output to jq, as shown in [Chapter 4](chapter4.xhtml).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 要将这个脚本自定义，尝试使用 -j 选项让 Nuclei 输出 JSON 数据。然后将输出传递给 jq，具体方法参见[第 4 章](chapter4.xhtml)。
- en: Fuzzing for Hidden Files
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对隐藏文件进行模糊测试
- en: Now that we’ve identified the potential location of files, let’s use fuzzing
    tools to find hidden files on *p-web-01* (*http://172.16.10.10:8081/files*). *Fuzzers*
    generate semi-random data to use as part of a payload. When sent to an application,
    these payloads can trigger anomalous behavior or reveal covert information. You
    can use fuzzers against web servers to find hidden paths or against local binaries
    to find vulnerabilities such as buffer overflows or DoS.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了潜在的文件位置，让我们使用模糊测试工具来查找 *p-web-01* 上的隐藏文件 (*http://172.16.10.10:8081/files*)。*Fuzzers*
    会生成半随机数据作为有效载荷的一部分。当这些数据发送到应用程序时，可能会触发异常行为或揭示隐秘信息。你可以使用模糊测试工具对 Web 服务器进行攻击，查找隐藏路径，或对本地二进制文件进行攻击，寻找缓冲区溢出或
    DoS 等漏洞。
- en: Creating a Wordlist of Possible Filenames
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建可能的文件名字典
- en: Fuzzing tools in the context of web application enumeration work best when fed
    custom wordlists tailored to your target. These lists could contain the name of
    the company, the individuals you’ve identified, relevant locations, and so on.
    These tailored wordlists can help you identify user accounts to attack, network
    and application services, valid domain names, covert files, email addresses, and
    web paths, for example.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Web 应用枚举的上下文中，模糊测试工具最好在输入定制的字典文件时使用，这些字典文件是针对你的目标量身定制的。字典文件可以包含公司名称、你已识别的个人、相关地点等等。这些定制的字典文件可以帮助你识别需要攻击的用户帐户、网络和应用服务、有效的域名、隐秘文件、电子邮件地址和
    Web 路径等。
- en: Let’s use bash to write a custom wordlist containing potential filenames of
    interest ([Listing 5-5](chapter5.xhtml#Lis5-5)).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 bash 编写一个自定义的字典文件，包含潜在的感兴趣文件名（参见[清单 5-5](chapter5.xhtml#Lis5-5)）。
- en: '[PRE29]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Listing 5-5: Using brace expansion to create multiple files with various extensions'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5-5：使用大括号扩展创建多个具有不同扩展名的文件
- en: This command creates files with probable file extensions tailored to our target’s
    name, ACME Hyper Branding. It uses echo with brace expansion {0..100} to create
    arbitrary strings ranging from 0 to 100 and then appends these to the company
    name. We also use brace expansion to create multiple file extension types, such
    as *.txt*, *.csv*, *.pdf*, and *.jpg*. The -e option, for echo, enables us to
    interpret backslash (\) escapes. This means that \n will be interpreted as a newline.
    We then pipe this output to the sed command to remove all whitespace from the
    output for a cleaner list.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令创建了带有可能的文件扩展名的文件，针对我们目标的名称——ACME Hyper Branding。它使用 echo 和大括号扩展 {0..100}
    来创建从 0 到 100 的任意字符串，并将其附加到公司名称后。我们还使用大括号扩展来创建多个文件扩展类型，如 *.txt*、*.csv*、*.pdf* 和
    *.jpg*。-e 选项用于 echo，允许我们解析反斜杠（\）转义字符。这意味着 \n 将被解释为换行符。然后，我们将此输出传递给 sed 命令，以删除输出中的所有空格，从而获得更清晰的列表。
- en: 'Use head to view the created files:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 head 查看创建的文件：
- en: '[PRE30]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As you can see, this command’s output follows the format *acme-hyper-branding-<some_number>.<some_extension>*.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，命令的输出遵循格式 *acme-hyper-branding-<some_number>.<some_extension>*。
- en: Fuzzing with ffuf
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 ffuf 进行模糊测试
- en: '*ffuf* (an acronym for *Fuzz Faster U Fool*) is a versatile and blazing-fast
    web fuzzing tool. We’ll use ffuf to discover potential files under the */files*
    endpoint that could contain interesting data.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '*ffuf*（全称 *Fuzz Faster U Fool*）是一个功能强大且超快的网页模糊测试工具。我们将使用 ffuf 来发现 * /files
    * 端点下可能包含有趣数据的文件。'
- en: 'The following ffuf command uses the -c (color) option to highlight the results
    in the terminal, the -w (wordlist) option to specify a custom wordlist, the -u
    (URL) option to specify a path, and the full URL to the endpoint to fuzz. We run
    ffuf against *p-web-01* (172.16.10.10):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 ffuf 命令使用 -c（color）选项在终端中突出显示结果，-w（wordlist）选项指定自定义字典，-u（URL）选项指定路径，以及完整的
    URL 用于目标模糊测试。我们在 *p-web-01*（172.16.10.10）上运行 ffuf：
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Note that the word FUZZ at the end of the URL is a placeholder that tells the
    tool where to inject the words from the wordlist. In essence, it will swap the
    word FUZZ with each line from our file.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，URL 末尾的 FUZZ 是一个占位符，指示工具从字典中注入单词。实际上，它将用文件中的每一行替换 FUZZ。
- en: According to the output, ffuf identified that the path *http://172.16.10.10:8081/files/acme-hyper-branding-5.csv*
    returned a status code of HTTP 200 OK. If you look closely at the output, you
    should see that the fuzzer sent 405 requests in less than a second, which is pretty
    impressive.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 根据输出，ffuf 识别到路径 *http://172.16.10.10:8081/files/acme-hyper-branding-5.csv* 返回了
    HTTP 200 OK 状态码。如果你仔细查看输出，你会发现 fuzzer 在不到一秒的时间内发送了 405 次请求，真是相当令人印象深刻。
- en: Fuzzing with Wfuzz
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Wfuzz 进行模糊测试
- en: '*Wfuzz* is another web fuzzing tool similar to ffuf. In fact, ffuf is based
    on Wfuzz. Let’s use Wfuzz to perform the same type of wordlist-based scan (-w)
    and then use its filtering capabilities to show only files that receive a response
    status code of 200 OK (--sc 200):'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '*Wfuzz* 是另一个与 ffuf 类似的网页模糊测试工具。事实上，ffuf 就是基于 Wfuzz 开发的。我们将使用 Wfuzz 执行相同类型的基于字典的扫描（-w），然后利用其过滤功能，仅显示那些收到
    200 OK 状态码响应的文件（--sc 200）：'
- en: '[PRE32]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, let’s use the wget command to download the identified file:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们使用 wget 命令下载识别出的文件：
- en: '[PRE33]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We’ve located a table of PII, including first and last names, titles, and email
    addresses. Take notes of every detail we’ve managed to extract in this chapter;
    you never know when it will come in handy.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经找到了一个包含个人身份信息（PII）的表格，包括姓名、职称和电子邮件地址。记下我们在本章中提取的每个细节；你永远不知道什么时候这些信息会派上用场。
- en: Note that fuzzers can cause unintentional DoS conditions, especially if they’re
    optimized for speed. You may encounter applications running on low-powered servers
    that will crash if you run a highly capable fuzzer against them, so make sure
    you have explicit permission from the company you’re working with to perform such
    activities.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，模糊测试工具可能会导致意外的 DoS（拒绝服务）状况，尤其是当它们经过优化以提高速度时。如果你在低功率服务器上运行高效的模糊测试工具，可能会导致应用程序崩溃，因此，请确保你已经获得了与公司合作的明确许可，才能进行此类活动。
- en: Assessing SSH Servers with Nmap’s Scripting Engine
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Nmap 脚本引擎评估 SSH 服务器
- en: Nmap contains many NSE scripts to test for vulnerabilities and misconfigurations.
    All Nmap scripts live in the */usr/share/nmap/scripts* path. When you run Nmap
    with the -A flag, it will blast all NSE scripts at the target, as well as enable
    operating system detection, version detection, script scanning, and traceroute.
    This is probably the noisiest scan you can do with Nmap, so never use it when
    you need to be covert.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Nmap包含许多NSE脚本，用于测试漏洞和配置错误。所有Nmap脚本都位于*/usr/share/nmap/scripts*路径下。当你使用-A标志运行Nmap时，它将向目标发送所有NSE脚本，同时启用操作系统检测、版本检测、脚本扫描和跟踪路由。这可能是你可以在Nmap中进行的最喧闹的扫描，因此在需要隐秘时绝不要使用它。
- en: 'In [Chapter 4](chapter4.xhtml), we identified a server running OpenSSH on *p-jumpbox-01*
    (172.16.10.13). Let’s use an NSE script tailored to SSH servers to see what we
    can discover about the supported authentication methods:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](chapter4.xhtml)中，我们确定了一个运行OpenSSH的服务器，位于*p-jumpbox-01*（172.16.10.13）。让我们使用专门针对SSH服务器的NSE脚本来看看我们能发现关于支持的认证方法的信息：
- en: '[PRE34]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The *ssh-auth-methods* NSE script enumerates the authentication methods offered
    by the SSH server. If *password* is one of them, this means that the server accepts
    passwords as an authentication mechanism. SSH servers that allow password authentication
    are prone to brute-force attacks. In [Chapter 7](chapter7.xhtml), we’ll perform
    a brute-force attack against SSH servers.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '*ssh-auth-methods* NSE脚本枚举了SSH服务器提供的认证方法。如果其中包括*password*，这意味着服务器接受密码作为认证机制。允许密码认证的SSH服务器容易受到暴力破解攻击。在[第7章](chapter7.xhtml)中，我们将对SSH服务器执行暴力破解攻击。'
- en: 'Exercise 7: Combining Tools to Find FTP Issues'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7：结合工具查找FTP问题
- en: The goal of this exercise is to write a script that calls several security tools,
    parses their output, and passes the output to other tools to act on it. Orchestrating
    multiple tools in this way is a common task in penetration testing, so we encourage
    you to get comfortable with building such workflows.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习的目标是编写一个脚本，调用几个安全工具，解析它们的输出，并将输出传递给其他工具以进行操作。以这种方式编排多个工具在渗透测试中是一个常见的任务，所以我们鼓励你熟悉构建这样的工作流程。
- en: 'Your script should do the following:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 你的脚本应该执行以下操作：
- en: 1.  Accept one or more IP addresses on the command line.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 1.  在命令行上接受一个或多个IP地址。
- en: 2.  Run a port scanner against the IP addresses; which port scanner you use
    is completely up to you.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 2.  对IP地址运行端口扫描器；你使用哪种端口扫描器完全取决于你。
- en: 3.  Identify open ports. If any of them are FTP ports (21/TCP), the script should
    pass the address to the vulnerability scanner in step 4.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 3.  识别开放端口。如果其中有FTP端口（21/TCP），脚本应将地址传递给步骤4中的漏洞扫描器。
- en: 4.  Use Nuclei to scan the IP addresses and ports. Try applying templates dedicated
    to finding issues in FTP servers. Search the Nuclei templates folder */home/kali/.local/nuclei-templates*
    for FTP-related templates, or use the -tags ftp Nuclei flag.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 4.  使用Nuclei扫描IP地址和端口。尝试应用专用于查找FTP服务器问题的模板。在Nuclei模板文件夹*/home/kali/.local/nuclei-templates*中搜索与FTP相关的模板，或者使用-tags
    ftp Nuclei标志。
- en: 5.  Scan the IP addresses with Nmap. Use NSE scripts that find vulnerabilities
    in FTP servers, which you can search for in the */usr/share/nmap/scripts* folder.
    For example, try *ftp-anon.nse*.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 5.  使用Nmap扫描IP地址。使用能够在FTP服务器中发现漏洞的NSE脚本，在*/usr/share/nmap/scripts*文件夹中搜索。例如，尝试*ftp-anon.nse*。
- en: 6.  Parse and write the results to a file, in a format of your choice. The file
    should include a description of the vulnerability, the relevant IP address and
    port, the timestamp at which it was found, and the name of the tool that detected
    the issue. There is no hard requirement about how to present the data; one option
    is to use an HTML table. If you need an example table, download *vulnerability_table.html*
    from the book’s GitHub repository and open it in a browser. Alternatively, you
    could write the results to a CSV file.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 6.  解析并将结果写入文件，使用你选择的格式。文件应包括漏洞描述、相关IP地址和端口、发现时间戳以及检测问题的工具名称。关于如何呈现数据没有硬性要求；一种选项是使用HTML表格。如果你需要一个示例表格，请从书的GitHub存储库下载*vulnerability_table.html*并在浏览器中打开。或者，你可以将结果写入CSV文件。
- en: As you should know by now, there is more than one way to write such a script.
    Only the end result matters, so craft the script as you see fit.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你现在应该知道的，编写这样一个脚本有多种方式。只有最终结果才重要，因此按照你的意愿编写脚本。
- en: Summary
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概要
- en: In this chapter, we wrapped up reconnaissance activities by performing vulnerability
    scanning and fuzzing. We also verified the vulnerabilities we discovered, weeding
    out potential false positives.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过进行漏洞扫描和模糊测试来总结了侦察活动。我们还验证了我们发现的漏洞，筛选出潜在的误报。
- en: Along the way, we used bash scripting to perform several tasks. We scanned for
    vulnerabilities, wrote custom scripts that can perform recursive downloads from
    misconfigured web servers, extracted sensitive information from Git repositories,
    and more. We also created custom wordlists using clever bash scripting and orchestrated
    the execution of multiple security tools to generate a report.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，我们使用bash脚本执行了多项任务。我们扫描了漏洞，编写了能够从配置错误的Web服务器进行递归下载的自定义脚本，从Git存储库中提取了敏感信息等等。我们还使用聪明的bash脚本创建了自定义字典，并编排了多个安全工具的执行以生成报告。
- en: 'Let’s recap what we’ve identified so far, from a reconnaissance perspective:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下到目前为止从侦察角度识别出的内容：
- en: Hosts running multiple services (HTTP, FTP, and SSH) and their versions
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行多个服务（HTTP、FTP和SSH）及其版本的主机
- en: A web server running WordPress with a login page enabled and a few vulnerabilities,
    such as user enumeration and an absence of HTTP security headers
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行WordPress的Web服务器，启用了登录页面，并且存在一些漏洞，如用户枚举和缺少HTTP安全头部
- en: A web server with a revealing *robots.txt* file containing paths to custom upload
    forms and a donation page
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有详细*robots.txt*文件的Web服务器，其中包含自定义上传表单和捐赠页面的路径
- en: An anonymous, login-enabled FTP server
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匿名的、启用登录的FTP服务器
- en: Multiple open Git repositories
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个开放的Git存储库
- en: OpenSSH servers that allow password-based logins
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许基于密码的登录的OpenSSH服务器
- en: In the next chapter, we’ll use the information identified in this chapter to
    establish an initial foothold by exploiting vulnerabilities and taking over servers.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将利用本章识别的信息通过利用漏洞来建立初步立足点并接管服务器。
