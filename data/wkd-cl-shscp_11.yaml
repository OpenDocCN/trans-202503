- en: '**10**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**10**'
- en: '**INTERNET SERVER ADMINISTRATION**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**互联网服务器管理**'
- en: '![image](../images/common4.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common4.jpg)'
- en: The job of managing a web server and service is often completely separate from
    the job of designing and managing content on the website. While the previous chapter
    offered tools geared primarily toward web developers and other content managers,
    this chapter shows how to analyze web server log files, mirror websites, and monitor
    network health.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 管理 web 服务器和服务的工作通常与设计和管理网站内容的工作完全分开。尽管前一章提供的工具主要面向 web 开发人员和其他内容管理者，本章将展示如何分析
    web 服务器日志文件、镜像网站以及监控网络健康状况。
- en: '**#73 Exploring the Apache access_log**'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**#73 探索 Apache 的 access_log**'
- en: If you’re running Apache or a similar web server that uses the *Common Log Format*,
    you can do quite a bit of quick statistical analysis with a shell script. In a
    standard configuration, the server writes *access_log* and *error_log* files for
    the site (generally in */var/log*, but this can be system dependent). If you’ve
    got your own server, you should definitely be archiving this valuable information.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行的是 Apache 或类似的 web 服务器，使用 *Common Log Format*，你可以通过 shell 脚本进行快速的统计分析。在标准配置下，服务器会为站点写入
    *access_log* 和 *error_log* 文件（通常位于 */var/log*，但这可能依赖于系统）。如果你有自己的服务器，应该务必归档这些宝贵的信息。
- en: '[Table 10-1](ch10.xhtml#ch10table1) lists the fields in an *access_log* file.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 10-1](ch10.xhtml#ch10table1) 列出了 *access_log* 文件中的字段。'
- en: '**Table 10-1:** Field Values in the *access_log* File'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 10-1：** *access_log* 文件中的字段值'
- en: '| **Column** | **Value** |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| **列** | **值** |'
- en: '| --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | IP of host accessing the server |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 访问服务器的主机 IP |'
- en: '| 2–3 | Security information for HTTPS/SSL connections |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 2–3 | HTTPS/SSL 连接的安全信息 |'
- en: '| 4 | Date and time zone offset of the specific request |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 特定请求的日期和时区偏移 |'
- en: '| 5 | Method invoked |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 调用的方法 |'
- en: '| 6 | URL requested |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 请求的 URL |'
- en: '| 7 | Protocol used |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 使用的协议 |'
- en: '| 8 | Result code |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 结果代码 |'
- en: '| 9 | Number of bytes transferred |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 传输的字节数 |'
- en: '| 10 | Referrer |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 引荐来源 |'
- en: '| 11 | Browser identification string |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 浏览器标识字符串 |'
- en: 'A typical line in *access_log* looks like this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*access_log* 中的典型一行如下所示：'
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The result code (field 8) of `301` indicates that the request was considered
    a success. The referrer (field 10) indicates the URL of the page that the user
    was visiting immediately before the page request. Ten years ago, this would have
    been the URL of the previous page; now it’s generally `"-"`, as you see here,
    for privacy reasons.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 结果代码（第8个字段）为`301`表示请求被认为是成功的。引荐来源（第10个字段）表示用户在请求页面之前访问的页面的 URL。十年前，这通常是上一页面的
    URL；现在，由于隐私原因，通常是`"-"`，就像你在这里看到的。
- en: The number of hits to the site can be determined by doing a line count on the
    log file, and the date range of entries in the file can be ascertained by comparing
    the first and last lines.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 站点的命中次数可以通过对日志文件进行行计数来确定，而文件中条目的日期范围可以通过比较第一行和最后一行来确认。
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: With these points in mind, the script in [Listing 10-1](ch10.xhtml#ch10ex1)
    produces a number of useful statistics from an Apache-format *access_log* file.
    This script expects the `scriptbc` and `nicenumber` scripts we wrote in [Chapter
    1](ch01.xhtml#ch01) to be in the `PATH`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些要点，[清单 10-1](ch10.xhtml#ch10ex1) 中的脚本可以从 Apache 格式的 *access_log* 文件中生成多个有用的统计数据。该脚本期望我们在[第1章](ch01.xhtml#ch01)中编写的`scriptbc`和`nicenumber`脚本已经存在于`PATH`中。
- en: '***The Code***'
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***代码***'
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Listing 10-1: The* `*webaccess*` *script*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 10-1：* `*webaccess*` *脚本*'
- en: '***How It Works***'
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***工作原理***'
- en: Let’s consider each block as a separate little script. For example, the first
    few lines extract the `firstdate` and `lastdate` ➊ by simply grabbing the fourth
    field of the first and last lines of the file. The number of hits is calculated
    by counting lines in the file using `wc` ➋, and the number of page views is calculated
    by simply subtracting requests for image files (that is, files with *.gif*, *.jpg*,
    or *.png* as their extension) from the hits. Total bytes transferred are calculated
    by summing up the value of the 10th field in each line and then invoking `nicenumber`
    to present it attractively.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将每个块看作是一个独立的小脚本。例如，前几行通过简单地抓取文件中第一行和最后一行的第四个字段，提取`firstdate`和`lastdate` ➊。通过使用`wc`
    ➋来计算文件中的行数，从而计算命中次数，页面查看次数则通过简单地从命中数中减去图像文件的请求（即扩展名为*.gif*、*.jpg*或*.png*的文件）来计算。传输的总字节数是通过将每行第10个字段的值相加，再调用`nicenumber`以便以更吸引人的方式呈现。
- en: To calculate the most popular pages, first we extract just the pages requested
    from the log file, and then we screen out any image files ➌. Next we use `uniq
    -c` to sort and calculate the number of occurrences of each unique line. Finally,
    we sort one more time to ensure that the most commonly occurring lines are presented
    first. In the code, this whole process is at ➍.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算最受欢迎的页面，首先我们从日志文件中提取出所有请求的页面，然后筛选出所有的图片文件 ➌。接着，我们使用 `uniq -c` 对每一行进行排序，并计算每一行出现的次数。最后，我们再排序一次，确保最常出现的行排在前面。在代码中，这整个过程位于
    ➍。
- en: 'Notice that we do normalize things a little bit: the `sed` invocation strips
    out any trailing slashes to ensure that `/subdir/` and `/subdir` are counted as
    the same request.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们确实对内容进行了些许规范化：`sed` 命令会去除末尾的斜杠，确保 `/subdir/` 和 `/subdir` 被视为相同的请求。
- en: Similar to the section that retrieves the 10 most requested pages, the section
    at ➎ pulls out the referrer information.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于提取 10 个最受请求页面的部分，第 ➎ 部分提取了引荐信息。
- en: This extracts field 11 from the log file, screening out entries that were referred
    from the current host as well as entries that are `"-"`, the value sent when the
    web browser is blocking referrer data. Then the code feeds the result to the same
    sequence of `sort|uniq -c|sort -rn|head -10` to get the 10 most common referrers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这会从日志文件中提取第 11 个字段，筛选掉来自当前主机的引荐条目以及值为 `"-"` 的条目，后者是当 web 浏览器阻止引荐数据时发送的值。然后，代码将结果输入到相同的
    `sort|uniq -c|sort -rn|head -10` 序列中，获取 10 个最常见的引荐网址。
- en: '***Running the Script***'
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***运行脚本***'
- en: To run this script, specify the name of an Apache (or other Common Log Format)
    log file as its only argument.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此脚本，只需将 Apache（或其他常见日志格式）日志文件的名称作为唯一参数传递。
- en: '***The Results***'
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***结果***'
- en: The result of running this script on a typical log file is quite informative,
    as [Listing 10-2](ch10.xhtml#ch10ex2) shows.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型日志文件上运行此脚本的结果非常有帮助，如[清单 10-2](ch10.xhtml#ch10ex2)所示。
- en: '![image](../images/f0238-01.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f0238-01.jpg)'
- en: '*Listing 10-2: Running the* `*webaccess*` *script on an Apache access log*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 10-2：在 Apache 访问日志上运行* `*webaccess*` *脚本*'
- en: '***Hacking the Script***'
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***修改脚本***'
- en: One challenge of analyzing Apache log files is that there are situations in
    which two different URLs refer to the same page; for example, */custer/* and */custer/index.html*
    are the same page. Calculating the 10 most popular pages should take this into
    account. The conversion performed by the `sed` invocation already ensures that
    */custer* and */custer/* aren’t treated separately, but knowing the default filename
    for a given directory might be a bit trickier (especially since this can be a
    special configuration on the web server).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 分析 Apache 日志文件的一大挑战是，有些情况下两个不同的 URL 会指向相同的页面；例如，*/custer/* 和 */custer/index.html*
    是同一个页面。计算最受欢迎的 10 个页面时，应该考虑到这一点。`sed` 命令执行的转换已经确保了 */custer* 和 */custer/* 不会被单独处理，但要知道一个目录的默认文件名可能会有点复杂（尤其是因为这可能是
    web 服务器的特定配置）。
- en: 'You can make the 10 most popular referrers more useful by trimming referrer
    URLs to just the base domain name (e.g., *slashdot.org*). [Script #74](ch10.xhtml#ch10lev1sec02),
    coming up next, explores additional information available from the referrer field.
    The next time your website gets “slashdotted,” you should have no excuse for not
    knowing!'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '通过将前 10 个最受欢迎的引荐网址的 URL 修剪为仅包含基础域名（例如，*slashdot.org*），你可以让这些引荐网址更有用。接下来的[脚本
    #74](ch10.xhtml#ch10lev1sec02)将探讨从引荐字段中可以获取的更多信息。下次你的网站被“slashdotted”时，你就没有理由不知道了！'
- en: '**#74 Understanding Search Engine Traffic**'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**#74 理解搜索引擎流量**'
- en: '[Script #73](ch10.xhtml#ch10lev1sec01) can offer a broad overview of some of
    the search engine queries that point to your site, but further analysis can reveal
    not only which search engines are delivering traffic but also what keywords were
    entered by users who arrived at your site via search engines. This information
    can be invaluable for understanding whether your site has been properly indexed
    by the search engines. Moreover, it can provide the starting point for improving
    the rank and relevancy of your search engine listings, though, as we mentioned
    earlier, this additional information is slowly being deprecated by Apache and
    web browser developers. [Listing 10-3](ch10.xhtml#ch10ex3) details the shell script
    for retrieving this information from your Apache logs.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[脚本 #73](ch10.xhtml#ch10lev1sec01)可以提供一些指向你网站的搜索引擎查询的总体概览，但进一步的分析不仅能揭示哪些搜索引擎正在带来流量，还能显示通过搜索引擎访问你网站的用户输入了哪些关键词。这些信息对于了解你的网站是否已被搜索引擎正确索引至关重要。此外，它还可以为改善你网站搜索引擎排名和相关性提供起点，尽管如前所述，这些附加信息正慢慢被Apache和网页浏览器开发者弃用。[清单10-3](ch10.xhtml#ch10ex3)详细描述了从Apache日志中获取这些信息的Shell脚本。'
- en: '***The Code***'
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***代码***'
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '*Listing 10-3: The* `*searchinfo*` *script*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单10-3：*`*searchinfo*`*脚本*'
- en: '***How It Works***'
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***工作原理***'
- en: The main `for` loop ➊ of this script extracts all entries in the log file that
    have a valid referrer with a string length greater than 4, a referrer domain that
    does not match the `$host` variable, and a `?` in the referrer string, indicating
    that a user search was performed.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本的主要`for`循环 ➊ 提取日志文件中所有有效的引用来源条目，这些条目的字符串长度大于4，引用来源域名与`$host`变量不匹配，并且引用来源字符串中包含`?`，表示用户进行了搜索。
- en: The script then tries to identify the domain name of the referrer and the search
    value entered by the user ➋. An examination of hundreds of search queries shows
    that common search sites use a small number of common variable names. For example,
    search on Yahoo! and your search string is `p=pattern`. Google and MSN use `q`
    as the search variable name. The `grep` invocation contains `p`, `q`, and the
    other most common search variable names.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，脚本尝试识别引用来源的域名以及用户输入的搜索值 ➋。对数百个搜索查询的检查表明，常见的搜索网站使用少量的常见变量名。例如，在雅虎上搜索时，搜索字符串是`p=pattern`。谷歌和MSN使用`q`作为搜索变量名。`grep`调用包含了`p`、`q`和其他最常见的搜索变量名。
- en: The invocation of `sed` ➌ cleans up the resultant search patterns, replacing
    `+` and `%20` sequences with spaces and chopping out quotes, and the `cut` command
    returns everything that occurs after the first equal sign. In other words, the
    code returns just the search terms.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`sed` ➌ 的调用清理结果搜索模式，替换`+`和`%20`序列为空格，并去除引号，`cut`命令返回等号后的所有内容。换句话说，代码仅返回搜索词。'
- en: The conditional immediately following these lines tests whether the `args` variable
    is empty. If it is (that is, if the query format isn’t a known format), then it’s
    a search engine we haven’t seen, so we output the entire pattern rather than a
    cleaned-up, pattern-only value.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 紧接着这些行的条件语句测试`args`变量是否为空。如果为空（即查询格式不是已知格式），则说明这是一个我们未见过的搜索引擎，因此我们输出整个模式，而不是仅输出清理后的模式值。
- en: '***Running the Script***'
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***运行脚本***'
- en: To run this script, simply specify the name of an Apache or other Common Log
    Format log file on the command line (see [Listing 10-4](ch10.xhtml#ch10ex4)).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此脚本，只需在命令行中指定Apache或其他常见日志格式文件的名称（参见[清单10-4](ch10.xhtml#ch10ex4)）。
- en: '**NOTE**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*This is one of the slowest scripts in this book because it’s spawning lots
    of subshells to perform various tasks, so don’t be surprised if it takes a while
    to run.*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*这是本书中最慢的脚本之一，因为它会生成大量子Shell来执行各种任务，因此如果运行时间较长，请不要感到惊讶。*'
- en: '***The Results***'
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***结果***'
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Listing 10-4: Running the* `*searchinfo*` *script on Apache logs*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单10-4：在Apache日志上运行*`*searchinfo*`*脚本*'
- en: '***Hacking the Script***'
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***破解脚本***'
- en: One way to tweak this script is to skip the referrer URLs that are most likely
    not from search engines. To do so, simply comment out the `else` clause at ➍.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 修改该脚本的一种方法是跳过最可能不是来自搜索引擎的引用来源URL。要做到这一点，只需注释掉 ➍ 处的`else`子句。
- en: 'Another way to approach this task would be to search for all hits coming from
    a specific search engine, entered as the second command argument, and then compare
    the search strings specified. The core `for` loop would change, like so:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种处理此任务的方法是搜索来自特定搜索引擎的所有访问，该搜索引擎作为第二个命令参数传递，然后比较指定的搜索字符串。核心的`for`循环将像这样更改：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You’ll also want to tweak the usage message so that it mentions the new second
    argument. Again, this script is going to eventually just report blank data due
    to changes in how web browsers—and Google in particular— report the Referer info.
    As you can see, of the matching entries in this log file, 771 reported no referrer
    and therefore no useful information about keyword usage.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要调整使用信息，使其提到新的第二个参数。再次强调，由于Web浏览器，尤其是Google，在报告Referer信息时发生的变化，这个脚本最终将仅报告空白数据。如你所见，在这个日志文件中，匹配的条目中有771个没有报告来源页面，因此没有提供关于关键字使用的有用信息。
- en: '**#75 Exploring the Apache error_log**'
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**#75 探索Apache error_log**'
- en: 'Just as [Script #73](ch10.xhtml#ch10lev1sec01) on [page 235](ch10.xhtml#page_235)
    reveals the interesting and useful statistical information found in the regular
    access log of an Apache or Apache-compatible web server, this script extracts
    the critical information from the *error_log* file.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '就像[脚本 #73](ch10.xhtml#ch10lev1sec01)在[第235页](ch10.xhtml#page_235)中展示的那样，Apache或兼容Apache的Web服务器的常规访问日志中包含有趣且有用的统计信息，本脚本则从*error_log*文件中提取关键信息。'
- en: 'For those web servers that don’t automatically split their logs into separate
    *access_log* and *error_log* components, you can sometimes split a central log
    file into these components by filtering based on the return code (field 9) of
    each entry in the log:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些没有自动将日志分为独立的*access_log*和*error_log*组件的Web服务器，你有时可以通过根据日志中每个条目的返回代码（第9字段）来过滤，从而将中央日志文件分为这些组件：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: A return code that begins with a 4 or a 5 is a failure (the 400s are client
    errors and the 500s are server errors), and a return code beginning with a 2 or
    a 3 is a success (the 200s are success messages and the 300s are redirects).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以4或5开头的返回代码表示失败（400系列是客户端错误，500系列是服务器错误），而以2或3开头的返回代码表示成功（200系列是成功消息，300系列是重定向）。
- en: Other servers that produce a single central log file containing both successes
    and errors denote the error message entries with an `[error]` field value. In
    that case, the split can be done with a `grep '[error]'` to create the error log
    and a `grep -v '[error]'` to create the access log.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 其他生成包含成功和错误的单一中央日志文件的服务器，通过`[error]`字段值来表示错误消息条目。在这种情况下，可以使用`grep '[error]'`来创建错误日志，使用`grep
    -v '[error]'`来创建访问日志。
- en: Whether your server automatically creates an error log or you have to create
    your own error log by searching for entries with the `'[error]'` string, just
    about everything in the error log is different from the content of the access
    log, including the way the date is specified.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你的服务器是否自动生成错误日志，还是需要通过查找包含`'[error]'`字符串的条目来创建自己的错误日志，错误日志中的几乎所有内容与访问日志的内容都不同，包括日期的指定方式。
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the access log, dates are specified as a compact one-field value with no
    spaces; the error log takes five fields instead. Furthermore, rather than a consistent
    scheme in which the word/string position in a space-delimited entry consistently
    identifies a particular field, entries in the error log have a meaningful error
    description that varies in length. An examination of just those description values
    reveals surprising variation, as shown here:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在访问日志中，日期作为一个紧凑的单字段值指定，没有空格；而错误日志则使用五个字段。此外，错误日志中的条目没有统一的方案，其中字段的词语/字符串位置在空格分隔条目中始终标识特定字段，而是具有一个有意义的错误描述，该描述的长度是可变的。仅查看这些描述值，就能发现令人惊讶的变化，如下所示：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Some of these errors should be examined by hand because they can be difficult
    to track backward to the offending web page.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些错误需要手动检查，因为它们可能很难追溯到引起问题的网页。
- en: The script in [Listing 10-5](ch10.xhtml#ch10ex5) focuses on the most common
    problems—in particular, `File does not exist` errors—and then produces a dump
    of all other error log entries that don’t match well-known error situations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单10-5](ch10.xhtml#ch10ex5)中的脚本专注于最常见的问题——特别是`文件不存在`错误——然后生成一个不匹配已知错误情况的其他错误日志条目的转储。'
- en: '***The Code***'
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***代码***'
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*Listing 10-5: The* `*weberrors*` *script*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单10-5：* `*weberrors*` *脚本*'
- en: '***How It Works***'
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***工作原理***'
- en: This script works by scanning the error log for the five errors specified in
    the calls to the `checkfor` function, extracting the last field on each error
    line with an `awk` call for `$NF` (which represents the number of fields in that
    particular input line). This output is then fed through `sort | uniq -c | sort
    -rn` ➋ to make it easy to extract the most commonly occurring errors for that
    category of problem.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本通过扫描错误日志，查找在 `checkfor` 函数中指定的五种错误，利用 `awk` 调用 `$NF`（表示该输入行中的字段数）提取每个错误行的最后一个字段。然后，使用
    `sort | uniq -c | sort -rn` ➋ 将输出排序，便于提取该类问题中最常见的错误。
- en: To ensure that only those error types with matches are shown, each specific
    error search is saved to the temporary file, which is then tested to make sure
    it isn’t empty before a message is output. This is all neatly done with the `checkfor()`
    function that appears near the top of the script.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保只显示那些与错误类型匹配的内容，每个特定的错误搜索会保存到临时文件中，然后测试该文件是否为空，只有在文件非空时才会输出消息。所有这些操作都通过脚本顶部附近的
    `checkfor()` 函数精心完成。
- en: The last few lines of the script identify the most common errors not otherwise
    checked for by the script but that are still in standard Apache error log format.
    The `grep` invocations at ➊ are part of a longer pipe.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本的最后几行识别出那些脚本没有检查的、但仍符合标准 Apache 错误日志格式的最常见错误。位于 ➊ 的 `grep` 调用是一个更长管道的一部分。
- en: Then the script identifies the most common errors not otherwise checked for
    by the script that *don’t* occur in standard Apache error log format. Again, the
    `grep` invocations at ➌ are part of a longer pipe.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，脚本识别出那些脚本没有检查的、*不*符合标准 Apache 错误日志格式的最常见错误。再次提醒，位于 ➌ 的 `grep` 调用是一个更长管道的一部分。
- en: '***Running the Script***'
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***运行脚本***'
- en: This script should be passed the path to a standard Apache-format error log
    as its only argument, shown in [Listing 10-6](ch10.xhtml#ch10ex6). If invoked
    with a `-l length` argument, it will display `length` number of matches per error
    type checked rather than the default of five entries per error type.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本应该传入一个标准 Apache 格式的错误日志路径作为唯一参数，见[示例 10-6](ch10.xhtml#ch10ex6)。如果传入 `-l
    length` 参数，它将显示每种错误类型检查的 `length` 个匹配项，而不是默认的每种错误类型五个条目。
- en: '***The Results***'
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***结果***'
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '*Listing 10-6: Running the* `*weberrors*` *script on Apache error logs*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 10-6：在 Apache 错误日志上运行* `*weberrors*` *脚本*'
- en: '**#76 Avoiding Disaster with a Remote Archive**'
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**#76 使用远程归档避免灾难**'
- en: Whether or not you have a comprehensive backup strategy, it’s a nice insurance
    policy to back up a few critical files with a separate off-site archive system.
    Even if it’s just that one key file with all your customer addresses, your invoices,
    or even emails from your sweetheart, having an occasional off-site archive can
    save your proverbial bacon when you least expect it.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是否拥有一个全面的备份策略，使用单独的异地归档系统备份一些关键文件都是一种很好的保险政策。即使只有一个包含所有客户地址的关键文件，或者你的发票，甚至是你与心上人之间的邮件，偶尔使用异地归档也能在你最意想不到的时候拯救你的“命运”。
- en: This sounds more complex than it really is, because as you’ll see in [Listing
    10-7](ch10.xhtml#ch10ex7), the “archive” is just a file emailed to a remote mailbox,
    which could even be a Yahoo! or Gmail mailbox. The list of files is kept in a
    separate data file, with shell wildcards allowed. Filenames can contain spaces,
    something that rather complicates the script, as you’ll see.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来比实际复杂，因为正如你在[示例 10-7](ch10.xhtml#ch10ex7)中看到的，“归档”实际上只是通过电子邮件发送到远程邮箱的文件，这个邮箱甚至可以是
    Yahoo! 或 Gmail 邮箱。文件列表保存在一个单独的数据文件中，并且允许使用 shell 通配符。文件名可以包含空格，这会让脚本变得相对复杂，正如你将看到的那样。
- en: '***The Code***'
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***代码***'
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Listing 10-7: The* `*remotebackup*` *script*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例 10-7：* `*remotebackup*` *脚本*'
- en: '***How It Works***'
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***原理***'
- en: After the basic validity checks, the script processes the file containing the
    list of critical files, which is supplied as the first command line argument,
    to ensure that spaces embedded in its filenames will work in the `while` loop
    ➊. It does this by prefacing every space with a backslash. Then it builds the
    archive with the `tar` command ➋, which lacks the ability to read standard input
    for its file list and thus must be fed the filenames via a `cat` invocation.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在基本有效性检查后，脚本处理包含关键文件列表的文件，这个文件作为第一个命令行参数传入，确保文件名中嵌入的空格在 `while` 循环 ➊ 中能够正常工作。它通过在每个空格前加上反斜杠来实现。然后，使用
    `tar` 命令 ➋ 构建归档文件，因为 `tar` 无法读取标准输入的文件列表，因此必须通过 `cat` 调用将文件名传递给它。
- en: The `tar` invocation automatically compresses the archive, and `uuencode` is
    then utilized to ensure that the resultant archive data file can be successfully
    emailed without corruption. The end result is that the remote address receives
    an email message with the uuencoded `tar` archive as an attachment.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`tar`命令自动压缩归档文件，随后使用`uuencode`确保最终的归档数据文件可以成功通过电子邮件发送而不被损坏。最终结果是，远程地址接收到一封带有`tar`归档的uuencoded附件的电子邮件。'
- en: '**NOTE**'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*The* `*uuencode*` *program wraps up binary data so that it can safely travel
    through the email system without being corrupted. See* `*man uuencode*` *for more
    information.*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*`*uuencode*` *程序将二进制数据打包，以便它可以安全地通过电子邮件系统传输而不会被损坏。有关更多信息，请参见* `*man uuencode*`
    *。*'
- en: '***Running the Script***'
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***运行脚本***'
- en: 'This script expects two arguments: the name of a file that contains a list
    of files to archive and back up and the destination email address for the compressed,
    `uuencoded` archive file. The file list can be as simple as this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本需要两个参数：一个文件名，包含待归档和备份的文件列表，以及压缩后的`uuencoded`归档文件的目标电子邮件地址。文件列表可以像这样简单：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '***The Results***'
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***结果***'
- en: '[Listing 10-8](ch10.xhtml#ch10ex8) details running the `remotebackup` shell
    script to back up all HTML and shell script files in the current directory, and
    then printing the results.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 10-8](ch10.xhtml#ch10ex8)详细说明了如何运行`remotebackup`shell脚本，以备份当前目录中的所有HTML和shell脚本文件，并打印结果。'
- en: '[PRE13]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '*Listing 10-8: Running the* `*remotebackup*` *script to back up HTML and shell
    script files*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 10-8：运行* `*remotebackup*` *脚本以备份HTML和shell脚本文件*'
- en: '***Hacking the Script***'
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***破解脚本***'
- en: First off, if you have a modern version of `tar`, you might find that it has
    the ability to read a list of files from `stdin` (for example, GNU’s `tar` has
    a `-T` flag to have the file list read from standard input). In this case, the
    script can be shortened by updating how the file list is given to `tar`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果你有现代版本的`tar`，你可能会发现它有能力从`stdin`读取文件列表（例如，GNU的`tar`有一个`-T`标志，可以从标准输入读取文件列表）。在这种情况下，通过更新文件列表给`tar`的方式，可以简化脚本。
- en: The file archive can then be unpacked or simply saved, with a mailbox trimmer
    script run weekly to ensure that the mailbox doesn’t get too big. [Listing 10-9](ch10.xhtml#ch10ex9)
    details a sample trimmer script.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，文件归档可以被解压或简单地保存，并且每周运行一个邮箱修剪脚本，以确保邮箱不会变得过大。[清单 10-9](ch10.xhtml#ch10ex9)详细说明了一个示例修剪脚本。
- en: '[PRE14]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '*Listing 10-9: The* `*trimmailbox*` *script, to be used in conjunction with
    the* `*remotebackup*` *script*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 10-9：* `*trimmailbox*` *脚本，需与* `*remotebackup*` *脚本一起使用*'
- en: This succinct script deletes all messages in the mailbox other than the most
    recent ones (`$keep`). Obviously, if you’re using something like Hotmail or Yahoo!
    Mail for your archive storage, this script won’t work and you’ll have to log in
    occasionally to trim things.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简洁的脚本删除邮箱中除了最新邮件（`$keep`）以外的所有邮件。显然，如果你使用的是像Hotmail或Yahoo! Mail这样的邮箱来存储归档文件，这个脚本就无法工作，你将需要偶尔登录去修剪邮箱。
- en: '**#77 Monitoring Network Status**'
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**#77 监控网络状态**'
- en: One of the most puzzling administrative utilities in Unix is `netstat`, which
    is too bad, because it offers quite a bit of useful information about network
    throughput and performance. With the `-s` flag, `netstat` outputs volumes of information
    about each of the protocols supported on your computer, including TCP, UDP, IPv4/v6,
    ICMP, IPsec, and more. Most of those protocols are irrelevant for a typical configuration;
    usually the protocol you want to examine is TCP. This script analyzes TCP protocol
    traffic, determining the percentage of packet transmission failure and including
    a warning if any values are out of bounds.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Unix中最令人困惑的管理工具之一是`netstat`，这有点遗憾，因为它提供了关于网络吞吐量和性能的很多有用信息。使用`-s`标志时，`netstat`输出关于你计算机上支持的每种协议的大量信息，包括TCP、UDP、IPv4/v6、ICMP、IPsec等。对于典型配置来说，大多数协议是不相关的；通常你想要检查的协议是TCP。这个脚本分析TCP协议流量，确定数据包传输失败的百分比，并在任何值超出范围时发出警告。
- en: Analyzing network performance as a snapshot of long-term performance is useful,
    but a much better way to analyze data is with trends. If your system regularly
    has 1.5 percent packet loss in transmission, and in the last three days the rate
    has jumped up to 7.8 percent, a problem is brewing and needs to be analyzed in
    more detail.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 将网络性能分析作为长期性能的快照是有用的，但分析数据的更好方法是通过趋势。如果你的系统在传输中定期有1.5%的丢包率，而在过去三天中，丢包率已经上升到7.8%，那么一个问题正在形成，需要更详细地分析。
- en: As a result, this script is two parts. The first part, shown in [Listing 10-10](ch10.xhtml#ch10ex10),
    is a short script that is intended to run every 10 to 30 minutes, recording key
    statistics in a log file. The second script ([Listing 10-11](ch10.xhtml#ch10ex11))
    parses the log file, reporting typical performance and any anomalies or other
    values that are increasing over time.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，该脚本由两部分组成。第一部分，如[列表 10-10](ch10.xhtml#ch10ex10)所示，是一个短脚本，旨在每 10 到 30 分钟运行一次，记录关键统计数据到日志文件中。第二个脚本（[列表
    10-11](ch10.xhtml#ch10ex11)）解析日志文件，报告典型的性能数据以及任何异常或其他随时间增加的值。
- en: '**WARNING**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**'
- en: '*Some flavors of Unix can’t run this code as is (though we’ve confirmed it’s
    working on OS X as is)! It turns out that there is quite a variation in the output
    format (many subtle whitespace changes or slight spelling) of the* `*netstat*`
    *command between Linux and Unix versions. Normalizing* `*netstat*` *output would
    be a nice script unto itself.*'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*某些版本的 Unix 无法按原样运行此代码（尽管我们已经确认它在 OS X 上能够正常工作）！事实证明，Linux 和 Unix 版本之间的 `netstat`
    命令输出格式存在相当大的差异（许多细微的空格变化或拼写略有不同）。标准化 `netstat` 输出将是一个非常有用的脚本。*'
- en: '***The Code***'
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***代码***'
- en: '[PRE15]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*Listing 10-10: The* `*getstats*` *script*'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 10-10：* `*getstats*` *脚本*'
- en: The second script, shown in [Listing 10-11](ch10.xhtml#ch10ex11), analyzes the
    `netstat` historical log file.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个脚本，如[列表 10-11](ch10.xhtml#ch10ex11)所示，分析 `netstat` 的历史日志文件。
- en: '[PRE16]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*Listing 10-11: The* `*netperf*` *script, to be used with the* `*getstats*`
    *script*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 10-11：* `*netperf*` *脚本，供与* `*getstats*` *脚本一起使用*'
- en: '***How It Works***'
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***工作原理***'
- en: The `netstat` program is tremendously useful, but its output can be intimidating.
    [Listing 10-12](ch10.xhtml#ch10ex12) shows just the first 10 lines of output.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`netstat` 程序非常有用，但它的输出可能令人畏惧。[列表 10-12](ch10.xhtml#ch10ex12) 显示了输出的前 10 行。'
- en: '[PRE17]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*Listing 10-12: Running* `*netstat*` *to get TCP information*'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 10-12：运行* `*netstat*` *以获取 TCP 信息*'
- en: The first step is to extract just those entries that contain interesting and
    important network performance statistics. That’s the main job of `getstats`, and
    it does this by saving the output of the `netstat` command into the temp file
    *$temp* and going through *$temp* to calculate key values, such as total packets
    sent and received. The line at ➊, for example, gets the number of packets sent.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是提取仅包含有趣和重要的网络性能统计数据的条目。这是 `getstats` 的主要工作，它通过将 `netstat` 命令的输出保存到临时文件 *$temp*
    中，然后遍历 *$temp* 计算关键值，例如发送和接收的总包数。比如在 ➊ 处的代码获取了发送的包数。
- en: 'The `sed` invocation removes any nondigit values to ensure that no tabs or
    spaces end up as part of the resulting value. Then all of the extracted values
    are written to the *netstat.log* log file in the format `var1Name=var1Value; var2Name=var2Value;`
    and so forth. This format will let us later use `eval` on each line in *netstat.log*
    and have all the variables instantiated in the shell:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`sed` 调用会移除任何非数字值，以确保没有标签或空格会成为结果值的一部分。然后，所有提取的值都以 `var1Name=var1Value; var2Name=var2Value;`
    的格式写入 *netstat.log* 日志文件中。这个格式将使我们稍后能够在 *netstat.log* 中对每一行使用 `eval`，并在 shell
    中实例化所有变量：'
- en: '![image](../images/f0253-01.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f0253-01.jpg)'
- en: The `netperf` script does the heavy lifting, parsing *netstat.log* and reporting
    both the most recent performance numbers and any anomalies or other values that
    are increasing over time. The `netperf` script calculates the current percentage
    of retransmits by dividing retransmits by packets sent and multiplying this result
    by 100\. An integer-only version of the retransmission percentage is calculated
    by taking the result of dividing retransmissions by total packets sent, multiplying
    it by 10,000, and then dividing by 100 ➌.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`netperf` 脚本负责繁重的工作，它解析 *netstat.log* 文件，并报告最新的性能数据以及任何异常或其他随时间增加的值。`netperf`
    脚本通过将重传包数除以发送的包数，并将结果乘以 100 来计算当前的重传百分比。重传百分比的整数版本是通过将重传包数除以发送的总包数，乘以 10,000，然后再除以
    100 来计算的 ➌。'
- en: As you can see, the naming scheme for variables within the script begins with
    the abbreviations assigned to the various `netstat` values, which are stored in
    *netstat.log* at the end of the `getstats` script ➋. The abbreviations are `snt`,
    `re`, `rec`, `dup`, `oo`, `creq`, `cacc`, and `reto`. In the `netperf` script,
    the `p` suffix is added to any of these abbreviations for variables that represent
    decimal percentages of total packets sent or received. The `pn` suffix is added
    to any of the abbreviations for variables that represent integer-only percentages
    of total packets sent or received. Later in the `netperf` script, the `ps` suffix
    denotes a variable that represents the percentage summaries (averages) used in
    the final calculations.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '如你所见，脚本中变量的命名方案以分配给各个 `netstat` 值的缩写开头，这些值存储在 `getstats` 脚本结束时的 *netstat.log*
    中 ➋。这些缩写包括 `snt`、`re`、`rec`、`dup`、`oo`、`creq`、`cacc` 和 `reto`。在 `netperf` 脚本中，所有表示总发送或接收数据包的十进制百分比的变量，都会在这些缩写后加上
    `p` 后缀；表示整数百分比的变量则加上 `pn` 后缀。之后，在 `netperf` 脚本中，`ps` 后缀用于表示在最终计算中使用的百分比摘要（平均值）变量。  '
- en: The `while` loop steps through each entry of *netstat.log*, calculating the
    four key percentile variables (`re`, `retr`, `dup`, and `oo`, which are retransmits,
    transmit timeouts, duplicates, and out of order, respectively). All are written
    to the `$stats` temp file, and then the `awk` script sums each column in `$stats`
    and calculates average column values by dividing the sums by the number of records
    in the file (`NR`).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`while` 循环逐个处理 *netstat.log* 中的每个条目，计算四个关键百分位变量（`re`、`retr`、`dup` 和 `oo`，分别代表重传、传输超时、重复包和乱序包）。所有结果都会写入
    `$stats` 临时文件，然后 `awk` 脚本会将 `$stats` 中的每一列求和，并通过将总和除以文件中的记录数（`NR`）来计算每列的平均值。  '
- en: The `eval` line at ➍ ties things together. The `awk` invocation is fed the set
    of summary statistics (`$stats`) produced by the `while` loop and utilizes the
    calculations saved in the `$awktmp` file to output `variable=value` sequences.
    These `variable=value` sequences are then incorporated into the shell with the
    `eval` statement, instantiating the variables `reps`, `retops`, `dupps`, and `oops`,
    which are average retransmit, average retransmit timeouts, average duplicate packets,
    and average out-of-order packets, respectively. The current percentile values
    can then be compared to these average values to spot problematic trends.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '➍ 位置的 `eval` 行将各部分联系在一起。`awk` 调用接收由 `while` 循环生成的统计摘要（`$stats`），并利用保存在 `$awktmp`
    文件中的计算结果输出 `variable=value` 序列。这些 `variable=value` 序列随后通过 `eval` 语句被引入到 shell
    中，从而实例化 `reps`、`retops`、`dupps` 和 `oops` 变量，分别代表平均重传、平均重传超时、平均重复包和平均乱序包。当前的百分位值可以与这些平均值进行比较，以发现可能的问题趋势。  '
- en: '***Running the Script***'
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***运行脚本***'
- en: 'For the `netperf` script to work, it needs information in the *netstat.log*
    file. That information is generated by having a `crontab` entry that invokes `getstats`
    with some level of frequency. On a modern OS X, Unix, or Linux system, the following
    `crontab` entry will work fine, with the correct path to the script for your system
    of course:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '为了让 `netperf` 脚本正常工作，它需要 *netstat.log* 文件中的信息。这些信息是通过设置一个 `crontab` 条目来调用 `getstats`，并按照某种频率生成的。在现代的
    OS X、Unix 或 Linux 系统上，以下 `crontab` 条目可以正常工作，当然，你需要使用适合你系统的脚本路径：  '
- en: '[PRE18]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It will produce a log file entry every 15 minutes. To ensure the necessary file
    permissions, it’s best to actually create an empty log file by hand before running
    `getstats` for the first time.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '它每 15 分钟会生成一条日志文件条目。为了确保必要的文件权限，最好在第一次运行 `getstats` 之前，手动创建一个空的日志文件。  '
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now the `getstats` program should chug along happily, building a historical
    picture of the network performance of your system. To analyze the contents of
    the log file, run `netperf` without any arguments.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，`getstats` 程序应该可以顺利运行，逐步构建你系统网络性能的历史数据图景。要分析日志文件的内容，运行 `netperf` 而不带任何参数。  '
- en: '***The Results***'
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***结果***  '
- en: First off, let’s check on the *.netstatlog* file, shown in [Listing 10-13](ch10.xhtml#ch10ex13).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，让我们查看 *.netstatlog* 文件，参见[列表 10-13](ch10.xhtml#ch10ex13)。  '
- en: '![image](../images/f0255-01.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0255-01.jpg)  '
- en: '*Listing 10-13: The last three lines of the* .netstatlog *that results from
    a* `*crontab*` *entry running the* `*getstats*` *script on a regular interval*'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 10-13：*.netstatlog* 文件的最后三行，这是由运行`*crontab*`条目的`*getstats*`脚本在定期间隔下生成的结果。  '
- en: It looks good. [Listing 10-14](ch10.xhtml#ch10ex14) shows the results of running
    `netperf` and what it has to report.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '看起来不错。[列表 10-14](ch10.xhtml#ch10ex14) 展示了运行 `netperf` 后的结果以及它的报告内容。  '
- en: '[PRE20]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*Listing 10-14: Running the* `*netperf*` *script to analyze the* .netstatlog
    *file*'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 10-14: 运行* `*netperf*` *脚本分析* .netstatlog *文件*'
- en: '***Hacking the Script***'
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***修改脚本***'
- en: You’ve likely already noticed that rather than using a human-readable date format,
    the `getstats` script saves entries in the *.netstatlog* file using epoch time,
    which represents the number of seconds that have elapsed since January 1, 1970\.
    For example, 1,063,983,000 seconds represents a day in late September 2003\. The
    use of epoch time will make it easier to enhance this script by enabling it to
    calculate the time elapsed between readings.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，`getstats` 脚本并没有使用人类可读的日期格式，而是使用纪元时间保存条目到 *.netstatlog* 文件中，纪元时间表示自
    1970 年 1 月 1 日以来经过的秒数。例如，1,063,983,000 秒表示 2003 年 9 月底的一天。使用纪元时间将使得增强此脚本变得更加容易，因为它能够计算读取之间的时间差。
- en: '**#78 Renicing Tasks by Process Name**'
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**#78 按进程名称调整任务优先级**'
- en: There are many times when it’s useful to change the priority of a task, whether
    a chat server is supposed to use only “spare” cycles, an MP3 player app is not
    that important, a file download has become less important, or a real-time CPU
    monitor needs an increase in priority. You can change a process’s priority with
    the `renice` command; however, it requires you to specify the process ID, which
    can be a hassle. A much more useful approach is to have a script like the one
    in [Listing 10-15](ch10.xhtml#ch10ex15) that matches process name to process ID
    and automatically renices the specified application.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多时候，改变任务的优先级是非常有用的，无论是聊天服务器应该只使用“空闲”周期，MP3 播放器应用程序不那么重要，文件下载变得不那么重要，还是实时 CPU
    监视器需要提高优先级。您可以使用 `renice` 命令更改进程的优先级；然而，它要求您指定进程 ID，这可能会有些麻烦。一种更有用的方法是使用像 [Listing
    10-15](ch10.xhtml#ch10ex15) 中的脚本，它通过匹配进程名称到进程 ID，自动调整指定应用程序的优先级。
- en: '***The Code***'
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***代码***'
- en: '[PRE21]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*Listing 10-15: The* `*renicename*` *script*'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 10-15: The* `*renicename*` *脚本*'
- en: '***How It Works***'
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***工作原理***'
- en: 'This script borrows liberally from [Script #47](ch06.xhtml#ch06lev1sec03) on
    [page 150](ch06.xhtml#page_150), which does a similar mapping of process name
    to process ID—but that script kills the jobs rather than just lowering their priority.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '该脚本借鉴了 [Script #47](ch06.xhtml#ch06lev1sec03) 在 [第 150 页](ch06.xhtml#page_150)
    上的代码，该脚本执行了类似的进程名称到进程 ID 的映射——不过那个脚本是结束作业，而不是仅仅降低它们的优先级。'
- en: In this situation, you don’t want to accidentally renice a number of matching
    processes (imagine `renicename -n 10 "*"`, for example), so the script fails if
    more than one process matches. Otherwise, it makes the change specified and lets
    the actual `renice` program report any errors that may have been encountered.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您不想不小心调整多个匹配进程的优先级（例如，想象一下 `renicename -n 10 "*" `），因此如果匹配的进程超过一个，脚本会失败。否则，它会进行指定的更改，并允许实际的
    `renice` 程序报告可能遇到的任何错误。
- en: '***Running the Script***'
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***运行脚本***'
- en: 'You have a number of possible options when running this script: `-n val` allows
    you to specify the desired `nice` (job priority) value. The default is specified
    as `niceval=1`. The `-u user` flag allows matching processes to be limited by
    user, while `-t tty` allows a similar filter by terminal name. To see just the
    matching process ID and not actually renice the application, use the `-p` flag.
    In addition to one or more flags, `renicename` requires a command pattern, which
    will be compared to the running process names on the system to ascertain which
    of the processes match.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此脚本时，您有多个可选选项：`-n val` 允许您指定所需的 `nice`（作业优先级）值。默认值为 `niceval=1`。`-u user`
    标志允许按用户限制匹配的进程，而 `-t tty` 允许按终端名称进行类似的筛选。要仅查看匹配的进程 ID，而不实际更改应用程序的优先级，可以使用 `-p`
    标志。除了一个或多个标志，`renicename` 还需要一个命令模式，该模式将与系统上运行的进程名称进行比较，以确定哪些进程匹配。
- en: '***The Results***'
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***结果***'
- en: First off, [Listing 10-16](ch10.xhtml#ch10ex16) shows what happens when there
    is more than one matching process.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，[Listing 10-16](ch10.xhtml#ch10ex16) 展示了当有多个匹配的进程时会发生什么情况。
- en: '[PRE22]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*Listing 10-16: Running the* `*renicename*` *script with a process name with
    multiple process IDs*'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 10-16: 运行* `*renicename*` *脚本，使用具有多个进程 ID 的进程名称*'
- en: We subsequently quit one of these processes and ran the same command.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们退出了其中一个进程，并运行了相同的命令。
- en: '[PRE23]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We can confirm that this worked and our `vi` process was prioritized by using
    the `-l` flag to `ps` with the process ID specified, shown in [Listing 10-17](ch10.xhtml#ch10ex17).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确认这个操作是有效的，并且通过使用 `-l` 标志配合指定的进程 ID 来查看我们的 `vi` 进程已被优先处理，如 [Listing 10-17](ch10.xhtml#ch10ex17)
    所示。
- en: '[PRE24]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '*Listing 10-17: Confirming the process has been niced appropriately*'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 10-17: 确认进程已被正确调整优先级*'
- en: It’s hard to read this super-wide output format from the `ps` command, but notice
    that field 7 is `NI` and that for this process its value is 1 ➊. Check any other
    process you’re running, and you’ll see they’re all priority 0, the standard user
    priority level.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 从`ps`命令的这个超宽输出格式很难读取，但请注意第7列是`NI`，对于这个进程，它的值是1 ➊。检查你运行的其他进程，你会看到它们的优先级都是0，这是标准用户的优先级水平。
- en: '***Hacking the Script***'
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***破解脚本***'
- en: An interesting addendum to this script would be another script that watches
    for any time-critical programs that are launched and automatically renices them
    to a set priority. This could be helpful if certain internet services or applications
    tend to consume a lot of CPU resources, for example. [Listing 10-18](ch10.xhtml#ch10ex18)
    uses `renicename` to map process name to process ID and then checks the process’s
    current nice level. It issues a `renice` if the nice level specified as a command
    argument is higher (a lesser priority) than the current level.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本的一个有趣补充是另一个脚本，它监视任何启动的时间敏感程序，并自动将其调整为设定的优先级。如果某些互联网服务或应用程序消耗大量CPU资源，这可能会很有帮助。例如，[列表10-18](ch10.xhtml#ch10ex18)使用`renicename`将进程名映射到进程ID，然后检查进程当前的nice级别。如果作为命令参数指定的nice级别低于当前级别（即优先级较低），则会发出`renice`命令。
- en: '[PRE25]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '*Listing 10-18: The* `*watch_and_nice*` *script*'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表10-18：* `*watch_and_nice*` *脚本*'
- en: Within a `cron` job, this script could be used to ensure that certain apps are
    pushed to the desired priority within a few minutes of being launched.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在`cron`作业中，可以使用此脚本确保某些应用在启动后几分钟内被推送到所需的优先级。
