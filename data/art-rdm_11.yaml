- en: '**11'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**11'
- en: COMPUTER SCIENCE ALGORITHMS**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机科学算法**
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/common.jpg)'
- en: While everything we’ve looked at so far can be called a “randomized algorithm,”
    in computer science the phrase refers to two broad categories of algorithms—the
    subject of this chapter.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们到目前为止所研究的所有内容都可以称为“随机化算法”，但在计算机科学中，这个术语指的是两大类算法——本章的主题。
- en: A *randomized algorithm* employs randomness as part of its operation. The algorithm
    succeeds in accomplishing its goal, either by producing the correct answer quickly,
    but sometimes not, or by running rapidly with some probability of returning a
    false or nonoptimal result.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*随机化算法*在其操作过程中使用随机性。该算法通过快速产生正确答案，但有时不产生，或者通过快速运行并以某种概率返回错误或非最优结果来完成其目标。'
- en: We’ll begin by defining the two broad categories of randomized algorithms with
    examples. Next, we’ll learn about estimating the number of animals in a population.
    Following that, we’ll learn how to demonstrate that a number is a prime to any
    desired level of certainty while avoiding the brute force approach of searching
    for all possible divisors. We’ll end with randomized Quicksort, the textbook example
    of a randomized algorithm.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先定义这两大类随机化算法并举例说明。接下来，我们将学习如何估算一个种群中的动物数量。之后，我们将学习如何证明一个数字是素数，且达到任何所需的可信度，同时避免通过穷举所有可能的除数来进行暴力搜索。最后，我们将介绍随机化快速排序，这是一种经典的随机化算法示例。
- en: '**Las Vegas and Monte Carlo**'
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**拉斯维加斯与蒙特卡洛**'
- en: Las Vegas and Monte Carlo are locations famously associated with gambling, that
    is, with games of chance dependent on randomness and probability. However, when
    computer scientists refer to Las Vegas and Monte Carlo, they are (usually) referring
    to the two main types of randomized algorithms.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 拉斯维加斯和蒙特卡洛是与赌博密切相关的地方，也就是依赖于随机性和概率的机会游戏。然而，当计算机科学家提到拉斯维加斯和蒙特卡洛时，他们通常是指两种主要类型的随机化算法。
- en: A *Las Vegas algorithm* always returns a correct result for its input in a random
    amount of time; that is, how long the algorithm takes to execute isn’t deterministic,
    but the output is correct.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*拉斯维加斯算法*总是能在随机的时间内返回正确的结果；也就是说，算法执行所需的时间不是确定性的，但输出是正确的。'
- en: On the other hand, a *Monte Carlo algorithm* offers no assurance that its output
    is correct, but the runtime is deterministic. There is a nonzero probability that
    the output isn’t correct, but for a practical Monte Carlo algorithm, this probability
    is small. Most algorithms we’ve encountered, including swarm intelligence and
    evolutionary algorithms, are Monte Carlo algorithms. Las Vegas algorithms can
    be transformed into Monte Carlo algorithms by allowing them to exit before locating
    the correct output.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*蒙特卡洛算法*不能保证输出是正确的，但其运行时间是确定性的。输出不正确的概率是非零的，但对于一个实际的蒙特卡洛算法，这个概率是很小的。我们遇到的大多数算法，包括群体智能和进化算法，都是蒙特卡洛算法。通过允许算法在找到正确输出之前退出，拉斯维加斯算法可以转变为蒙特卡洛算法。
- en: The first example we’ll investigate is a sorting algorithm that is, at our discretion,
    a Las Vegas or Monte Carlo algorithm. The second is a Monte Carlo algorithm for
    verifying matrix multiplication.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究的第一个例子是一个排序算法，它是一个 Las Vegas 或 Monte Carlo 算法，具体取决于我们的选择。第二个是一个用于验证矩阵乘法的
    Monte Carlo 算法。
- en: '***Permutation Sort***'
  id: totrans-11
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***排列排序***'
- en: 'A *permutation* is a possible arrangement of a set of items. If there are *n*
    items in the set, there are *n*! = *n*(*n* – 1)(*n* – 2) . . . 1 possible permutations.
    For example, if the set consists of three things, say *A* = {1, 2, 3}, then there
    are six possible permutations:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*排列*是对一组项目的可能排列。如果集合中有 *n* 个项目，则有 *n*! = *n*(*n* - 1)(*n* - 2) …… 1 种可能的排列。例如，如果集合包含三个元素，假设
    *A* = {1, 2, 3}，那么就有六种可能的排列：'
- en: '{1, 2, 3}, {1, 3, 2}, {2, 1, 3}, {2, 3, 1}, {3, 1, 2}, {3, 2, 1}'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '{1, 2, 3}, {1, 3, 2}, {2, 1, 3}, {2, 3, 1}, {3, 1, 2}, {3, 2, 1}'
- en: Notice that one permutation sorts the items from smallest to largest. Therefore,
    if given a vector of unsorted numbers, we might use a sort algorithm that generates
    permutations until finding the one that sorts the items. While we can implement
    this deterministically, we can also use random permutations with the hope that
    we might stumble across the correct ordering before testing too many candidate
    permutations. The *permutation sort* algorithm (also known as *bogosort* or *stupid
    sort*) implements this idea.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，一种排列将项目从小到大排序。因此，如果给定一个无序的数字向量，我们可能会使用一种排序算法，生成排列直到找到能排序项目的那个。虽然我们可以实现确定性排序，但我们也可以使用随机排列，希望在测试过多候选排列之前能偶然找到正确的顺序。*permutation
    sort*算法（也叫*bogosort*或*stupid sort*）实现了这个想法。
- en: 'Run the file *permutation_sort.py* with no arguments:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 运行文件*permutation_sort.py*时不带任何参数：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The code generates a random vector of integers in [0, 99] and sorts it by trying
    random permutations up to `limit`. To score each permutation, the code returns
    the fraction of pairs of elements that are out of order, where *a* > *b* for *a*
    at index *i* and *b* at index *i* + 1\. If the array is sorted, the score is zero.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 代码生成一个整数随机向量，范围在[0, 99]之间，并通过尝试随机排列最多达到`limit`来对其进行排序。为了对每个排列进行评分，代码返回一对对元素乱序的比例，其中*a*
    > *b*表示*a*位于索引*i*，*b*位于索引*i* + 1。如果数组已经排序，得分为零。
- en: If `limit` is zero, the algorithm runs until it finds the correct permutation,
    which depends on the number of possible permutations. As the number of permutations
    increases (*n*!), the runtime rapidly increases if we insist on trying until we
    succeed. In this way, a `limit` of 0 turns *permutation_sort.py* into a Las Vegas
    algorithm.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`limit`为零，算法将一直运行直到找到正确的排列，这取决于可能的排列数量。随着排列数的增加（*n*!），如果我们坚持尝试直到成功，运行时间会迅速增加。通过这种方式，`limit`为0会将*permutation_sort.py*变成一个拉斯维加斯算法。
- en: 'For example, to run *permutation_sort.py* as a Las Vegas algorithm, use:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要将*permutation_sort.py*作为拉斯维加斯算法运行，使用：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The code found the proper order of elements after testing 268 of the possible
    6! = 720 permutations. Changing the randomness source from `minstd` to `pcg64`
    sorts in 59 iterations while `mt19937` uses 20\. We set the limit to 0 to make
    the code run until success, but the number of permutations tested was often far
    less than the maximum.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 代码在测试了268个可能的6! = 720个排列后找到了正确的元素顺序。将随机源从`minstd`更改为`pcg64`时，排序需要59次迭代，而`mt19937`则使用了20次。我们将限制设置为0，使代码一直运行直到成功，但测试的排列数通常远小于最大值。
- en: 'If we switch to Monte Carlo:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们切换到蒙特卡罗算法：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'we get a partially sorted array with a score > 0\. Because of the fixed randomness
    source and seed, we know we need 268 iterations to sort the array:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一个部分排序的数组，得分大于0。由于固定的随机源和种子，我们知道需要268次迭代才能排序数组：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[Listing 11-1](ch011.xhtml#ch011list01) shows the main loop in *permutation_sort.py*.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 11-1](ch011.xhtml#ch011list01)显示了*permutation_sort.py*中的主循环。'
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Listing 11-1: The main loop in* permutation_sort.py'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 11-1：*permutation_sort.py中的主循环'
- en: We create the vector (`v`), along with an initial `score`. The main loop, `while`,
    runs until the score is zero or the `limit` is exceeded. If Las Vegas, we set
    `limit` to a huge number to play the odds that we’ll find the true ordering long
    before that many trials.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建向量（`v`），并初始化`score`。主循环`while`一直运行，直到得分为零或`limit`超出。如果是拉斯维加斯算法，我们将`limit`设置为一个非常大的数字，以增加在尝试这么多次之前找到真实排序的概率。
- en: The body of the `while` loop creates a random ordering of `v` and calculates
    the score. Whenever it finds a lower score, the code reorders `v` to return at
    least a partially ordered vector should the limit be reached; however, this is
    not strictly necessary.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`while`循环的主体创建了`v`的随机排序并计算得分。每当找到更低的得分时，代码会重新排序`v`，以便在达到限制时至少返回一个部分排序的向量；然而，这并不是严格必要的。'
- en: The remainder of the file displays the results or calculates the score ([Listing
    11-2](ch011.xhtml#ch011list02)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的其余部分显示结果或计算得分（[列表 11-2](ch011.xhtml#ch011list02)）。
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*Listing 11-2: Scoring a permutation*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 11-2：对排列进行评分*'
- en: Let’s plot the mean number of permutations tested as a function of the number
    of items to sort, *permutation_sort_plot.py*, which plots the mean and standard
    error for 10 calls to *permutation_sort.py* for *n* in [2, 10]. The result is
    [Figure 11-1](ch011.xhtml#ch011fig01).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制平均排列次数与要排序项目数量的关系，*permutation_sort_plot.py*，它为[n]范围在[2, 10]之间的10次调用*permutation_sort.py*绘制了均值和标准误差。结果见[图
    11-1](ch011.xhtml#ch011fig01)。
- en: '![Image](../images/11fig01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/11fig01.jpg)'
- en: '*Figure 11-1: The mean number of permutations (in millions) tested as a function
    of the number of items*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11-1：作为项目数量的函数，测试的排列平均数量（以百万计）*'
- en: '[Figure 11-1](ch011.xhtml#ch011fig01) illustrates *combinatorial explosion*,
    which is the rapid growth in a problem’s runtime or resource use as a function
    of the size of its input. Permutation sort works decently when sorting lists of
    up to nine items; any more and the complexity explodes.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-1](ch011.xhtml#ch011fig01)展示了*组合爆炸*，即问题的运行时间或资源使用量随着输入大小的增加而迅速增长的现象。当排序最多九个项目的列表时，排列排序工作还算不错；但如果超过九个，复杂度就会爆炸。'
- en: 'We also see this effect in *permutation_sort_plot.py*’s output:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*permutation_sort_plot.py*的输出中也看到了这种效果：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The output shows, as a function of *n*, the mean (± SE) time in seconds to sort
    a vector of that size. After seven elements, runtimes quickly increase.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了作为*n*的函数，排序该大小向量所需的平均时间（±标准误差）。七个元素后，运行时间迅速增加。
- en: Combinatorial explosion is the bane of many otherwise useful algorithms, often
    reaching a point where many lifetimes of the universe are insufficient to find
    the correct output.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 组合爆炸是许多原本有用的算法的诅咒，它通常会达到一个点，宇宙的多个生命周期都不足以找到正确的输出。
- en: 'Permutation sort is tied closely to the factorial, which is why we’re getting
    these results:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 排列排序与阶乘密切相关，这就是我们得到这些结果的原因：
- en: '| 2! = 2 | 5! = 120 | 8! = 40,320 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 2! = 2 | 5! = 120 | 8! = 40,320 |'
- en: '| 3! = 6 | 6! = 720 | 9! = 362,880 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 3! = 6 | 6! = 720 | 9! = 362,880 |'
- en: '| 4! = 24 | 7! = 5,040 | 10! = 3,628,800 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 4! = 24 | 7! = 5,040 | 10! = 3,628,800 |'
- en: The factorial grows at a tremendous rate. If we want to sort 20 items, we have
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 阶乘以惊人的速度增长。如果我们要对20个项目进行排序，我们需要
- en: 20! = 2,432,902,008,176,640,000
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 20! = 2,432,902,008,176,640,000
- en: permutations to check. At 1 millisecond per permutation, we’d need over 77 million
    years of computing time to check them all. This doesn’t mean permutation sort
    couldn’t, by pure chance, sort 20 items in less than a second, but the probability
    is exceedingly low. This is the paradox of randomized algorithms.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 需要检查的排列数。如果每个排列需要 1 毫秒的时间，我们就需要超过 7700 万年的计算时间才能检查完所有排列。这并不意味着排列排序不能偶然在不到一秒的时间内排序
    20 个项目，但这种概率极低。这就是随机算法的悖论。
- en: '***Matrix Multiplication***'
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***矩阵乘法***'
- en: I have three matrices, ***A***, ***B***, and ***C***. We’ll use bold, uppercase
    letters to represent matrices. Does ***AB*** = ***C***? How can we know?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我有三个矩阵，***A***、***B***和***C***。我们将用粗体大写字母表示矩阵。***AB*** = ***C***吗？我们怎么知道？
- en: '**Introducing Matrix Multiplication**'
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**引入矩阵乘法**'
- en: 'First, let’s ensure we’re on the same page regarding matrix multiplication.
    A *matrix* is a 2D array of numbers, so the matrices here might be:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们确保我们对矩阵乘法有相同的理解。*矩阵*是一个二维数字数组，因此这里的矩阵可能是：
- en: '![Image](../images/f0299-03.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0299-03.jpg)'
- en: These are 2×2 matrices with two rows and two columns. If the number of rows
    equals the number of columns, we’re working with *square matrices*. However, the
    number of rows and columns need not match; for example, we might have a matrix
    of 3×5 or 1,000×13\. The latter case is typical in machine learning, where rows
    represent observations and columns represent features associated with those observations.
    An *n*×1 matrix is a *column vector*, while a 1×*n* matrix is a *row vector*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是 2×2 矩阵，有两行和两列。如果行数等于列数，我们就正在处理*方阵*。然而，行数和列数不必相等；例如，我们可能有一个 3×5 或 1,000×13
    的矩阵。后者在机器学习中很常见，行代表观察值，列代表与这些观察值相关的特征。*n*×1 矩阵是*列向量*，而 1×*n* 矩阵是*行向量*。
- en: Asking whether ***AB*** = ***C*** implies that we know how to find ***AB***.
    In NumPy, in order to multiply two 2D arrays, we multiply each corresponding element
    ([Listing 11-3](ch011.xhtml#ch011list03)).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，是否***AB*** = ***C***意味着我们知道如何找到***AB***。在 NumPy 中，为了乘以两个二维数组，我们将每个对应的元素相乘（[清单
    11-3](ch011.xhtml#ch011list03)）。
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*Listing 11-3: Multiplying element-wise in NumPy*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 11-3：在 NumPy 中按元素相乘*'
- en: Unfortunately, multiplying matrices is more involved. We begin by checking that
    the number of columns of the first matrix equals the number of rows of the second.
    If not, then we can’t multiply the matrices. Therefore, to multiply an *n*×*m*
    matrix by a *u*×*v* matrix requires *m* = *u*. If this is true, we can multiply
    to produce an *n*×*v* result. The square matrices in this section automatically
    satisfy this requirement.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，矩阵乘法更为复杂。我们首先要检查第一个矩阵的列数是否等于第二个矩阵的行数。如果不相等，则不能进行矩阵乘法。因此，要将一个*n*×*m*矩阵乘以一个*u*×*v*矩阵，需要*m*
    = *u*。如果这一条件成立，我们就可以进行乘法运算，得到一个*n*×*v*的结果。本节中的方阵自动满足这一要求。
- en: 'The matrix multiplication process requires multiplying each column of the second
    matrix by the rows of the first matrix, where the elements of the column multiply
    the corresponding elements of the row. We then sum these products to produce a
    single output value. For example, in symbols, multiplying two 2×2 matrices returns
    a new 2×2 matrix:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法过程需要将第二个矩阵的每一列与第一个矩阵的行相乘，其中列的元素与行的对应元素相乘。然后我们将这些乘积求和以产生单一的输出值。例如，用符号表示，乘法两个
    2×2 矩阵返回一个新的 2×2 矩阵：
- en: '![Image](../images/f0300-01.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0300-01.jpg)'
- en: We’re indexing matrices from 0, as we would NumPy arrays. However, many math
    books index from 1 so that the first element of the first row of matrix ***A***
    is denoted *a*[11], not *a*[00].
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从 0 开始索引矩阵，就像我们处理 NumPy 数组一样。然而，许多数学书籍是从 1 开始索引的，所以矩阵 ***A*** 第一行的第一个元素记作
    *a*[11]，而不是 *a*[00]。
- en: 'Mathematically, if ***A*** is an *n* × *m* matrix and ***B*** is an *m* × *p*
    matrix, then the elements of ***C*** = ***AB***, an *n* × *p* matrix, are:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 数学上，如果 ***A*** 是一个 *n* × *m* 矩阵，***B*** 是一个 *m* × *p* 矩阵，那么 ***C*** = ***AB***
    的元素是一个 *n* × *p* 矩阵：
- en: '![Image](../images/f0300-02.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0300-02.jpg)'
- en: 'Remember that matrix multiplication does not commute; in general, ***AB***
    ≠ ***BA***. The sum over *k* in [Equation 11.1](ch011.xhtml#ch11equ01) illustrates
    why: the single index accesses by row for ***A*** and by column for ***B*** so
    that swapping the order of ***A*** and ***B*** means different elements of the
    matrices are mixed.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 记住矩阵乘法不满足交换律；一般来说，***AB*** ≠ ***BA***。在[方程 11.1](ch011.xhtml#ch11equ01)中的求和展示了这一点：单一的索引按行访问
    ***A***，按列访问 ***B***，因此交换 ***A*** 和 ***B*** 的顺序会导致矩阵中的不同元素被混合。
- en: 'The sum in [Equation 11.1](ch011.xhtml#ch11equ01) uses index variable *k* with
    two more implied sums over all values of *i* and *j* to fill in the output matrix,
    ***C***. These observations point toward an implementation: matrix multiplication
    becomes a triple loop indexing elements of 2D arrays.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[方程 11.1](ch011.xhtml#ch11equ01)中的求和使用了索引变量 *k*，并且对 *i* 和 *j* 的所有值进行了两次隐含的求和，以填充输出矩阵
    ***C***。这些观察结果指向一个实现：矩阵乘法变成了一个三重循环，索引 2D 数组的元素。'
- en: '[Listing 11-4](ch011.xhtml#ch011list04) translates the loops of [Equation 11.1](ch011.xhtml#ch11equ01)
    into code.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 11-4](ch011.xhtml#ch011list04)将[方程 11.1](ch011.xhtml#ch11equ01)中的循环转换为代码。'
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '*Listing 11-4: Naive matrix multiplication*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 11-4：朴素矩阵乘法*'
- en: We’ll use this implementation even though NumPy supports matrix multiplication
    natively in several ways, for example, via the `@` operator. To understand why,
    we’ll learn how computer scientists measure algorithm performance.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个实现，即使 NumPy 原生支持通过几种方式进行矩阵乘法，例如通过 `@` 运算符。为了理解原因，我们将学习计算机科学家如何衡量算法的性能。
- en: '**Introducing Big O Notation**'
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**引入大 O 符号**'
- en: Computer scientists characterize the resource use of an algorithm by comparing
    the algorithm’s performance as input size increases to a similar function that
    captures how the algorithm’s resource use changes as the input grows. Here, resource
    refers to either memory or time. For example, an ![Image](../images/c0301-01.jpg)(*n*)
    algorithm linearly increases the memory used as the size of the input, *n*, increases.
    A linear function can be written as *y* = *mx* + *b* for input *x*, but in big
    O notation, we ignore multiplicative and constant factors so that *y* = *x* is
    functionally the same as *x* gets very large.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机科学家通过将算法的性能与输入大小增加时类似的函数进行比较，来描述算法的资源使用情况，该函数能够捕捉算法的资源使用如何随着输入的增长而变化。这里的资源指的是内存或时间。例如，一个![Image](../images/c0301-01.jpg)的(*n*)算法会随着输入大小*n*的增加而线性增加所使用的内存。线性函数可以写作
    *y* = *mx* + *b*，其中 *x* 是输入，但在大 O 符号中，我们忽略乘法和常数因素，所以 *y* = *x* 在 *x* 非常大时与 *x*
    是功能上相同的。
- en: The matrix multiplication code in [Listing 11-4](ch011.xhtml#ch011list04) contains
    a triply nested loop. If the input matrices are square (*n*×*n*), then `I` = `J`
    = `K` = *n*. Each loop runs *n* times, making the innermost loop run *n* times
    for every increment of the next outer loop, which must run *n* times to increment
    the outermost loop. Therefore, the total number of operations required to multiply
    two *n*×*n* matrices scales as *n*³. The time needed to create the output matrix,
    `C`, and evaluate the first two lines of the function doesn’t alter the essential
    character of the function—namely that it takes *n*³ passes through the three loops.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 11-4](ch011.xhtml#ch011list04)中的矩阵乘法代码包含一个三重嵌套的循环。如果输入矩阵是方阵（*n*×*n*），则`I`
    = `J` = `K` = *n*。每个循环执行 *n* 次，使得最内层的循环每次外层循环递增时执行 *n* 次，外层循环也必须执行 *n* 次来递增最外层循环。因此，乘法两个
    *n*×*n* 矩阵所需的操作总数按 *n*³ 规模增长。创建输出矩阵 `C` 和计算函数前两行所需的时间不会改变该函数的本质特征——即它需要通过三个循环进行
    *n*³ 次迭代。'
- en: A computer scientist would therefore write that [Listing 11-4](ch011.xhtml#ch011list04)
    is an ![Image](../images/c0301-01.jpg)(*n*³) algorithm and an “*n* cubed” implementation.
    In general, we want algorithms that scale as ![Image](../images/c0301-01.jpg)(*n*)
    or better. As *n* increases, the work required by the algorithm scales linearly
    or, better still, sublinearly like ![Image](../images/c0301-01.jpg)(log *n*) or
    ![Image](../images/c0301-01.jpg)(*n* log *n*). In other words, a plot of the work
    as a function of *n* is a straight line. Ideally, we want ![Image](../images/c0301-01.jpg)(1)
    algorithms that run in constant time regardless of the size of their input, but
    that isn’t always possible. An algorithm that runs in ![Image](../images/c0301-01.jpg)(*n*²)
    is often tolerable, but ![Image](../images/c0301-01.jpg)(*n*³) is suitable only
    for small values of *n*.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，计算机科学家会写下 [清单 11-4](ch011.xhtml#ch011list04) 是一个 ![Image](../images/c0301-01.jpg)(*n*³)
    算法，并且是一个“*n* 立方”的实现。通常，我们希望算法的增长率为 ![Image](../images/c0301-01.jpg)(*n*) 或更优。随着
    *n* 的增加，算法所需的工作量按线性增长，或者更好的是，按子线性增长，如 ![Image](../images/c0301-01.jpg)(log *n*)
    或 ![Image](../images/c0301-01.jpg)(*n* log *n*)。换句话说，工作量与 *n* 的关系是一个直线图。理想情况下，我们希望
    ![Image](../images/c0301-01.jpg)(1) 算法，它们在常数时间内运行，无论输入的大小如何，但这并非总是可能的。一个在 ![Image](../images/c0301-01.jpg)(*n*²)
    时间内运行的算法通常是可以容忍的，但 ![Image](../images/c0301-01.jpg)(*n*³) 只适用于小的 *n* 值。
- en: Note that ![Image](../images/c0301-01.jpg)(*n*), ![Image](../images/c0301-01.jpg)(*n*²),
    and ![Image](../images/c0301-01.jpg)(*n*³) are all powers of *n*. Such algorithms
    are known as *polynomial time* algorithms. We never want algorithms that run in
    *superpolynomial time*, with a runtime (or resource use) such that no polynomial
    tracks it. For example, an algorithm running in ![Image](../images/c0301-01.jpg)(2*^n*)
    time is an *exponential time* algorithm, and its resource use grows dramatically
    with the size of the input at a rate no polynomial can match. Worse still is the
    permutation sort we experimented with previously; it’s an ![Image](../images/c0301-01.jpg)(*n*!)
    algorithm that runs in *factorial time*. To see how factorial time is worse than
    exponential time, make a plot comparing 2*^n* and *n*! for *n* = [1, 8].
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，![Image](../images/c0301-01.jpg)(*n*)、![Image](../images/c0301-01.jpg)(*n*²)
    和 ![Image](../images/c0301-01.jpg)(*n*³) 都是 *n* 的幂次。这类算法被称为 *多项式时间* 算法。我们永远不希望有在
    *超多项式时间* 内运行的算法，这类算法的运行时间（或资源使用）无法通过任何多项式来追踪。例如，一个运行在 ![Image](../images/c0301-01.jpg)(2*^n*)
    时间内的算法就是一个 *指数时间* 算法，它的资源使用随输入规模的增大而剧烈增长，增长速度远超任何多项式。更糟糕的是我们之前实验过的排列排序；它是一个 ![Image](../images/c0301-01.jpg)(*n*!)
    算法，运行在 *阶乘时间* 内。为了理解阶乘时间比指数时间更糟糕，可以绘制一个图，比较 *2*^*n* 和 *n*! 在 *n* = [1, 8] 时的增长情况。
- en: Matrix multiplication as in [Listing 11-4](ch011.xhtml#ch011list04) is ![Image](../images/c0301-01.jpg)(*n*³).
    Our goal is to quickly check whether ***AB*** = ***C*** when given three matrices.
    We first multiply ***A*** and ***B*** and then check whether each element of the
    result matches the corresponding element in ***C***. The multiplication is ![Image](../images/c0301-01.jpg)(*n*³)
    and the check runs in ![Image](../images/c0301-01.jpg)(*n*²) time because we have
    to examine each element. As the cube grows much faster than the square, the overall
    naive algorithm runs in essentially ![Image](../images/c0301-01.jpg)(*n*³) time.
    Let’s see if we can do better.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如[Listing 11-4](ch011.xhtml#ch011list04)中的矩阵乘法是![Image](../images/c0301-01.jpg)(*n*³)。我们的目标是快速检查在给定三个矩阵的情况下，是否***AB***
    = ***C***。我们首先将***A***和***B***相乘，然后检查结果的每个元素是否与***C***中对应的元素匹配。乘法是![Image](../images/c0301-01.jpg)(*n*³)，检查的时间是![Image](../images/c0301-01.jpg)(*n*²)，因为我们需要检查每个元素。由于立方体增长速度远快于平方，整体的朴素算法运行时间基本为![Image](../images/c0301-01.jpg)(*n*³)。让我们看看是否可以做得更好。
- en: '**Introducing Freivalds’ Algorithm**'
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**引入Freivalds算法**'
- en: In 1977, Latvian computer scientist Rūsiņš Freivalds invented a randomized algorithm
    that correctly answers the question of whether ***AB*** = ***C*** with high probability,
    yet runs in ![Image](../images/c0301-01.jpg)(*n*²) time.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 1977年，拉脱维亚计算机科学家Rūsiņš Freivalds发明了一种随机算法，能够以高概率正确回答***AB*** = ***C***的问题，并且运行时间为![Image](../images/c0301-01.jpg)(*n*²)。
- en: For the following, we’ll assume that ***A***, ***B***, and ***C*** are *n*×*n*
    matrices. The algorithm works for non-square matrices, but this restriction makes
    things easier to follow.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下内容，我们假设***A***、***B***和***C***是*n*×*n*的矩阵。该算法也适用于非方阵，但此限制使得理解过程更为简单。
- en: 'The algorithm itself is straightforward:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 算法本身是直接的：
- en: Pick a random *n*-element vector, ***r*** = {0, 1}*^n*, that is, a random vector
    of 0s and 1s.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个随机的*n*维向量，***r*** = {0, 1}*^n*，即一个由0和1组成的随机向量。
- en: 'Calculate ***D*** = ***A***(***Br***) – ***Cr***. (Note: the parentheses matter.)'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算***D*** = ***A***(***Br***) – ***Cr***。（注意：括号很重要。）
- en: If all elements of ***D*** are zero, claim “yes,” ***AB*** = ***C***; otherwise,
    claim “no.”
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果***D***的所有元素都是零，则声明“是”，***AB*** = ***C***；否则，声明“否”。
- en: At first glance, Freivalds’ algorithm doesn’t look like it will help. However,
    recall how matrix multiplication works. The expression ***Br*** is multiplying
    an *n*×*n* matrix by an *n*×1 vector, which returns an *n*×1 vector. The next
    multiplication by ***A*** returns another *n*×1 vector. Likewise, ***Cr*** is
    also an *n*×1 vector. At no point is a full *n*×*n* matrix multiplication happening.
    As *n* grows, the savings in the number of calculations grows all the faster.
    Freivalds’ algorithm runs in ![Image](../images/c0301-01.jpg)(*n*²) time—a considerable
    improvement over the ![Image](../images/c0301-01.jpg)(*n*³) runtime of the naive
    algorithm.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，Freivalds算法似乎不会有帮助。然而，回想一下矩阵乘法是如何工作的。表达式***Br***是将一个*n*×*n*的矩阵与一个*n*×1的向量相乘，返回一个*n*×1的向量。接下来的***A***乘法返回另一个*n*×1的向量。同样，***Cr***也是一个*n*×1的向量。此时并没有进行完整的*n*×*n*矩阵乘法。随着*n*的增大，计算节省的速度会更快。Freivalds的算法运行在![Image](../images/c0301-01.jpg)(*n*²)时间内，比起朴素算法的![Image](../images/c0301-01.jpg)(*n*³)运行时间，这是一个相当大的改进。
- en: 'Multiplying ***B*** by ***r*** is the equivalent of selecting a random subset
    of ***B***’s columns and adding their value across the rows. For example:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 将***B***乘以***r***相当于选择***B***的列的随机子集，并将它们的值在行中相加。例如：
- en: '![Image](../images/f0302-01.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0302-01.jpg)'
- en: The algorithm is betting that examining random elements of the three matrices
    will, if they are equal, result in ***D*** being a vector of all zeros more often
    than ***D*** being all zeros by chance. An analysis of the probabilities involved,
    which we won’t cover, demonstrates that the probability of ***D*** being all zeros
    given ***AB*** ≠ ***C*** is less than or equal to 1/2.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的假设是，检查三者矩阵的随机元素时，如果它们相等，结果将更频繁地使***D***成为全零向量，而不是***D***偶然变为全零。对所涉及概率的分析（我们不会在此讨论）表明，给定***AB***
    ≠ ***C***的情况下，***D***为全零的概率小于或等于1/2。
- en: If the probability of one calculation involving a randomly selected ***r***
    returning the wrong answer is at most 1/2, then two random vectors (if we run
    the algorithm twice) have a probability of returning the wrong answer of at most
    (1/2)(1/2) = 1/4\. Here the wrong answer is an output of “yes” when in fact ***AB***
    ≠ ***C***.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个计算涉及随机选择的***r***返回错误答案的概率至多为1/2，那么两次运行算法的随机向量（如果我们运行算法两次）返回错误答案的概率至多为(1/2)(1/2)
    = 1/4。这里的错误答案是输出“是”，但实际上***AB*** ≠ ***C***。
- en: Each application of the algorithm is independent of any previous application.
    For independent events, like the flip of a fair coin, probabilities multiply,
    so *k* runs of Freivalds’ algorithm implies that the probability of a false “yes”
    result is 1/2*^k* or less. This means we can be as confident of the result as
    we like by running the algorithm multiple times.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 每次应用算法都是独立于任何先前应用的。对于独立事件，如公平硬币的抛掷，概率是相乘的，因此*k*次运行Freivalds算法意味着错误“是”结果的概率为1/2*^k*或更小。这意味着通过多次运行算法，我们可以提高对结果的信心。
- en: The algorithm will always return “yes” when ***AB*** = ***C***, meaning it is
    *one sided*—an error in the output happens only if ***AB*** ≠ ***C***. In a *two-sided*
    error, the algorithm could be wrong in either case, with some probability.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当***AB*** = ***C***时，算法总是返回“是”，这意味着它是*单边的*——只有在***AB*** ≠ ***C***时，输出才会出错。在*双边的*错误中，算法可能在任何情况下都出错，具有一定的概率。
- en: '**Testing Freivalds’ Algorithm**'
  id: totrans-90
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**测试Freivalds算法**'
- en: Let’s give the algorithm a try using *freivalds.py*, which generates 1,000 random
    triplets of *n*×*n* matrices, with *n* given on the command line. In all cases,
    ***AB*** ≠ ***C***, so we report failures as a fraction of 1,000.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用*freivalds.py*算法，它生成1,000个随机的*n*×*n*矩阵三元组，*n*由命令行提供。在所有情况下，***AB*** ≠
    ***C***，因此我们将失败的次数作为1,000次中的一个比例报告。
- en: 'Run *freivalds.py* like so:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 按如下方式运行*freivalds.py*：
- en: '[PRE9]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The first argument is the dimensionality of the matrices. The second decides
    whether to use the naive algorithm that calculates ***AB*** – ***C*** or Freivalds’.
    The third is the number of times to repeat the test with random ***r*** vectors.
    We’ll use this option shortly to track the error rate. As usual, the other arguments
    enable any randomness source and a seed to repeat the same sequence of random
    matrices.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数是矩阵的维度。第二个参数决定是否使用计算***AB*** - ***C***的朴素算法或Freivalds算法。第三个参数是重复测试的次数，使用随机的***r***向量。我们稍后会使用这个选项来跟踪错误率。像往常一样，其他参数启用任何随机源和一个种子，以重复相同的随机矩阵序列。
- en: 'For example:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '[PRE10]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: tells us that testing 1,000 3×3 matrices using Freivalds’ algorithm once each
    took some 0.09 seconds and failed 13.2 percent of the 1,000 tests.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 告诉我们，使用Freivalds算法对1,000个3×3矩阵进行单次测试，每次测试大约需要0.09秒，并且在1,000次测试中失败了13.2%。
- en: 'To use the naive algorithm, change the 0 to 1 on the command line:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用朴素算法，只需在命令行上将0改为1：
- en: '[PRE11]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As expected, there are no failures because the complete calculation always catches
    when ***AB*** ≠ ***C***. While the naive algorithm seems to run faster than Freivalds’,
    this is an illusion; as *n* increases, the two diverge.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，没有失败，因为完整的计算总是能捕捉到当***AB*** ≠ ***C***时的情况。虽然朴素算法似乎比Freivalds算法运行得更快，但这只是一个错觉；随着*n*的增加，两者的差距会逐渐增大。
- en: 'Failing 13 percent of the time when checking 3×3 matrices isn’t too inspiring.
    Let’s repeat the test, but check twice instead of once:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查3×3矩阵时失败13%的时候并不是很令人振奋。让我们重新测试，但检查两次而不是一次：
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now we fail only 1.6 percent of the tests at the expense of nearly doubling
    the running time. Let’s try four tests instead of two:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们仅失败了1.6%的测试，但几乎加倍了运行时间。让我们尝试进行四次测试而不是两次：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: With four tests, Freivalds’ algorithm is 1,000 out of 1,000.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 经过四次测试，Freivalds算法成功率为1,000/1,000。
- en: Freivalds’ algorithm is probabilistic. The likelihood of error decreases quickly
    as matrix size increases. To see this effect, alter the matrix size while fixing
    the repetitions at 1\. By the time *n* = 11, the error is generally below 0.1
    percent.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Freivalds算法是概率性的。随着矩阵大小的增大，错误的可能性迅速减少。为了看到这个效果，在固定重复次数为1的情况下改变矩阵大小。当*n* = 11时，错误率通常低于0.1%。
- en: It makes sense that the error rate goes down with matrix size. The probability
    that a random selection of values sum by accident to two equal values (***A***(***Br***)
    and ***Cr***) should decrease as the number of values summed increases.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 错误率随着矩阵大小的增大而下降是有道理的。随机选择的数值之和恰好等于两个相等的值（***A***(***Br***) 和 ***Cr***）的概率应随着求和的数值增加而减少。
- en: Let’s explore running time as a function of *n*. Run *freivalds_plots.py* to
    produce the graphs in [Figure 11-2](ch011.xhtml#ch011fig02).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨一下运行时间与*n*的关系。运行*freivalds_plots.py*来生成[图11-2](ch011.xhtml#ch011fig02)中的图表。
- en: '![Image](../images/11fig02.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/11fig02.jpg)'
- en: '*Figure 11-2: Comparing Freivalds’ running time to the naive algorithm as a
    function of matrix size (left) and plotting Freivalds’ running time alone to show
    the* ![Image](../images/c0301-01.jpg)*(*n^(*2*)*) complexity—note the* y*-axis
    range (right)*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11-2：将Freivalds算法的运行时间与朴素算法的运行时间对比，作为矩阵大小的函数（左），并单独绘制Freivalds算法的运行时间，以展示其*
    ![Image](../images/c0301-01.jpg)*(*n^(*2*)*)复杂度——请注意* y*轴范围（右）*'
- en: On the left of [Figure 11-2](ch011.xhtml#ch011fig02), we see the growth in running
    time between Freivalds’ and the naive algorithm as the size of the matrices increases.
    The naive algorithm, ![Image](../images/c0301-01.jpg)(*n*³), grows substantially
    faster than Freivalds’ ![Image](../images/c0301-01.jpg)(*n*²), shown by itself
    on the right.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 11-2](ch011.xhtml#ch011fig02) 的左侧，我们可以看到随着矩阵大小的增加，Freivalds 算法与朴素算法之间运行时间的增长。朴素算法的复杂度为
    ![Image](../images/c0301-01.jpg)(*n*³)，比 Freivalds 算法的 ![Image](../images/c0301-01.jpg)(*n*²)
    增长得要快得多，后者单独显示在右侧。
- en: The combination of performance gain and decreasing likelihood of error as *n*
    increases makes Freivalds’ algorithm particularly nice. Yes, it’s probabilistic,
    but in the places where it’s most desirable (large *n*), it’s also most likely
    to be correct.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 性能提升与错误发生概率随 *n* 增加而减少的结合，使得 Freivalds 算法特别有用。是的，它是概率性的，但在最需要它的地方（大 *n*），它也最有可能是正确的。
- en: Before examining *freivalds.py*, I have a confession. We can do matrix multiplication
    better than ![Image](../images/c0301-01.jpg)(*n*³), especially for matrices with
    *n* > 100\. Volker Strassen’s 1969 matrix multiplication algorithm has a runtime
    of about ![Image](../images/c0301-01.jpg)(*n*^(log[2] 7)) *≈* ![Image](../images/c0301-01.jpg)(*n*^(2.807)),
    which is slightly better than the naive algorithm. NumPy, based on the BLAS library,
    makes use of Strassen’s algorithm, which is why we didn’t use NumPy in this section.
    However, ![Image](../images/c0301-01.jpg)(*n*²) is better than ![Image](../images/c0301-01.jpg)(*n*^(2.807)),
    so Freivalds’ algorithm is still useful, even with Strassen matrix multiplication.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看 *freivalds.py* 之前，我得做一个自白。我们可以做得比 ![Image](../images/c0301-01.jpg)(*n*³)
    更好，特别是对于 *n* > 100 的矩阵。Volker Strassen 的 1969 年矩阵乘法算法具有约为 ![Image](../images/c0301-01.jpg)(*n*^(log[2]
    7)) *≈* ![Image](../images/c0301-01.jpg)(*n*^(2.807)) 的运行时间，略好于朴素算法。基于 BLAS 库的
    NumPy 利用了 Strassen 算法，这也是为什么我们在这一节中没有使用 NumPy。然而， ![Image](../images/c0301-01.jpg)(*n*²)
    优于 ![Image](../images/c0301-01.jpg)(*n*^(2.807))，因此即使有 Strassen 矩阵乘法，Freivalds
    算法仍然是有用的。
- en: '**GALACTIC ALGORITHMS**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**银河算法**'
- en: There are matrix multiplication algorithms with even better asymptotic behavior
    than Strassen’s algorithm. The current best have complexity ![Image](../images/c0301-01.jpg)(*n*^(2.373))
    or so. However, these algorithms are, in practice, completely useless. The seeming
    contradiction has to do with Big O notation, which shows the overall behavior
    but ignores multiplicative factors and constants. This means that an algorithm
    running in 10*n*³ time is the same as one running in 10,000*n*³ + 10,000 time.
    Both scale as ![Image](../images/c0301-01.jpg)(*n*³), but in practice, the first
    is more likely to be helpful.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 还有比 Strassen 算法更具渐近行为的矩阵乘法算法。目前最好的算法具有复杂度 ![Image](../images/c0301-01.jpg)(*n*^(2.373))
    左右。然而，这些算法在实践中完全无用。这个看似矛盾的现象与大 O 表示法有关，大 O 表示法展示的是总体行为，但忽略了乘法因子和常数。这意味着，运行时间为
    10*n*³ 的算法与运行时间为 10,000*n*³ + 10,000 的算法是一样的。两者的规模都是 ![Image](../images/c0301-01.jpg)(*n*³)，但在实践中，第一个更可能是有用的。
- en: Matrix multiplication algorithms that beat Strassen’s algorithm in overall complexity,
    like the *Coppersmith–Winograd* algorithm, have constants so large that the algorithm
    becomes practical only once *n* is some number far larger than anything computers
    can currently handle, if ever.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 比 Strassen 算法在整体复杂度上更优的矩阵乘法算法，比如 *Coppersmith–Winograd* 算法，其常数非常大，只有当 *n* 大到远超过当前计算机能够处理的范围时（如果有可能的话），该算法才有实际意义。
- en: Such algorithms have been christened *galactic algorithms* by Kenneth W. Regan.
    We cannot effectively use galactic algorithms in practice even if they are “the
    best” in terms of asymptotic behavior. While these algorithms are of theoretical
    importance, they won’t show up in our toolkits any time soon.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些算法被 Kenneth W. Regan 称为 *银河算法*。即使这些算法在渐近行为上是“最优的”，我们在实践中也无法有效使用它们。尽管这些算法在理论上很重要，但它们不会很快出现在我们的工具箱中。
- en: '**Exploring the Code**'
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**代码解析**'
- en: '[Listing 11-5](ch011.xhtml#ch011list05) contains the code implementing Freivalds’
    algorithm. The `mmult` function is in [Listing 11-4](ch011.xhtml#ch011list04).
    The `array_equal` function asks whether the absolute maximum of the difference
    between ***A***(***Br***) and ***Cr*** is below `eps`, and returns `True` if so.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 11-5](ch011.xhtml#ch011list05)包含了实现 Freivalds 算法的代码。`mmult` 函数在 [列表 11-4](ch011.xhtml#ch011list04)
    中。`array_equal` 函数会判断 ***A***(***Br***) 与 ***Cr*** 之间差值的绝对最大值是否低于 `eps`，如果是，返回
    `True`。'
- en: '[PRE14]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '*Listing 11-5: Freivalds’ algorithm*'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 11-5：Freivalds 算法*'
- en: The outer `for` loop executes 1,000 trials using a randomly selected set of
    matrices each time. ***C*** is such that it never equals ***AB***, so every call
    to `array_equal` should return `False`.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 外部`for`循环执行1000次试验，每次使用随机选择的矩阵集。***C***是这样设置的，它永远不等于***AB***，因此每次调用`array_equal`都应返回`False`。
- en: The body of the outer `for` loop either multiplies ***A*** and ***B*** directly
    (`mode==1`), or uses Freivalds’ algorithm by generating a random binary vector,
    `r`. Note that `r` is reshaped to be an *n*×1 column vector, as required for matrix
    multiplication.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 外部`for`循环的主体要么直接相乘***A***和***B***（`mode==1`），要么通过生成一个随机二进制向量`r`来使用Freivalds算法。注意，`r`被重新形状为*n*×1的列向量，这是矩阵乘法所要求的。
- en: The inner `for` loop applies Freivalds’ repeatedly (`reps`) each time, AND-ing
    the result with `t`. The AND operation means that after `reps` tests with different
    `r` vectors each time, the only way `t` is still true is if all tests give a wrong
    result. Each test should see `array_equal` return `False` because ***AB*** ≠ ***C***
    by design. Once `t` becomes `False`, it remains `False` for all remaining tests,
    so even one correct output from `array_equal` causes `t` to have the expected
    value.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 内部的`for`循环每次应用Freivalds算法重复(`reps`)，并将结果与`t`进行与运算。与运算意味着，在进行`reps`次测试，每次使用不同的`r`向量后，只有当所有测试都给出错误结果时，`t`才会保持为真。每次测试都应该看到`array_equal`返回`False`，因为按设计***AB***
    ≠ ***C***。一旦`t`变为`False`，它将在剩余的所有测试中保持`False`，因此即使`array_equal`返回正确结果，也会导致`t`具有预期的值。
- en: If `t` is still `True` after the inner loop, then the trial failed and we increment
    `k`. After all trials, we print the total runtime and the fraction of the 1,000
    trials that failed.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在内部循环后`t`仍然为`True`，则说明试验失败，我们会增加`k`的值。所有试验完成后，我们将打印总运行时间以及1000次试验中失败的比例。
- en: Freivalds’ algorithm is a Monte Carlo algorithm because it might, with a probability
    we can minimize, produce a false output and claim ***AB*** = ***C*** when it isn’t
    true.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Freivalds算法是一种蒙特卡洛算法，因为它可能会产生一个错误输出并声称***AB*** = ***C***，尽管实际情况并非如此，而且这种错误输出的概率是可以最小化的。
- en: 'Let’s turn to a different type of question for the next section: to get an
    estimate of the number of things in a collection, is it necessary to count them
    individually?'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将转向另一类问题：要估算一个集合中物品的数量，是否有必要逐个计数？
- en: '**Counting Animals**'
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**动物计数**'
- en: Ecologists often want to know how many animals of a particular species live
    in an area, though counting each one is often impossible. Enter *mark and recapture*,
    a strategy for estimating population size from a small sample.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 生态学家通常希望知道某个特定物种在某一地区的数量，尽管逐一统计每只动物通常是不可能的。这时就需要使用*标记和再捕*方法，这是一种通过小样本来估算种群数量的策略。
- en: In mark and recapture, the ecologist first goes into the field and captures
    *n* specimens, which they then mark and release. A short while later, they revisit
    the field and capture animals again until they get at least one that is marked.
    If they capture *K* animals to get *k* that are marked, they now have everything
    necessary to estimate the full population size, *N*. They do this by using ratios.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在标记和再捕中，生态学家首先进入现场捕捉*n*只样本，然后进行标记并释放。过一段时间后，他们重新进入现场，再次捕捉动物，直到捕获到至少一只已标记的动物。如果他们捕获了*K*只动物，其中有*k*只被标记，那么他们现在就拥有了估算总体数量*N*所需的所有信息。他们通过使用比率来完成这个过程。
- en: 'Initially, the ecologist marked *n* of the *N* animals, meaning the fraction
    of the total population marked is *n*/*N*. The recapture phase netted *k* marked
    animals out of *K*. Assuming no births, deaths, or migrations, the two ratios
    should be approximately equal, so solving for *N* gives:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，生态学家标记了*N*动物中的*n*只，这意味着标记的动物占总体种群的比例为*n*/*N*。再捕阶段捕获了*K*只动物，其中有*k*只被标记。假设没有出生、死亡或迁徙，这两个比例应该大致相等，因此通过解这个方程得到*N*：
- en: '![Image](../images/f0306-01.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0306-01.jpg)'
- en: This equation results in the *Lincoln-Petersen population estimate*, hence *N[L]*.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程得出了*Lincoln-Petersen种群估算*，因此是*N[L]*。
- en: 'A slightly less biased estimate of the population (or so it’s claimed) comes
    from the *Chapman population estimate*:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一种稍微少偏的种群估算（或如此声称）来自*Chapman种群估算*：
- en: '![Image](../images/f0306-02.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0306-02.jpg)'
- en: 'Finally, we have a Bayesian approach to mark and recapture:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们采用贝叶斯方法来进行标记和再捕：
- en: '![Image](../images/f0306-03.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0306-03.jpg)'
- en: This approach requires at least three marked animals in the recapture group
    to avoid dividing by zero.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法要求再捕组中至少有三只标记的动物，以避免除以零的情况。
- en: 'Let’s compare these three different estimates for the same population size
    with *mark_recapture.py*:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过*mark_recapture.py*比较这三种对相同种群大小的不同估算方法：
- en: '[PRE15]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The code simulates marking and recapturing by randomly marking a specified
    number of animals before recapturing a fraction of the population to count how
    many are marked. Let’s run the code a few times to get a feel for the output.
    We’ll fix the true population size at 1,000 and initially mark 100, or 10 percent.
    Setting the repetitions to 1 takes a single sampling, which is similar to what
    an ecologist might do in practice. We get:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 代码通过随机标记指定数量的动物，然后重捕部分种群计算已标记的数量，来模拟标记和重捕的过程。我们先运行几次代码，熟悉输出。我们将真实种群大小固定为1,000，并最初标记100个动物，即10%。将重复次数设置为1时进行一次采样，这与生态学家在实际中可能做的相似。我们得到：
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The estimates vary widely from run to run, as we might expect from a randomized
    algorithm. While the Lincoln-Petersen and Chapman estimates are generally low,
    the Bayesian estimates are closer to or even exceed the population size.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 估算值在每次运行中差异较大，这是我们从随机化算法中可以预期的结果。虽然林肯-彼得森和查普曼估算值通常较低，但贝叶斯估算值更接近真实种群大小，甚至超过了种群大小。
- en: 'Using a single repetition is akin to attempting to generalize from a single
    collected data point, so let’s increase the repetitions:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单次重复相当于试图从单个收集的数据点进行概括，因此我们增加重复次数：
- en: '[PRE17]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The output now reflects the mean and standard errors for 25 repetitions, providing
    a better idea of how the estimates behave. The Lincoln-Petersen and Chapman results
    are closer to the actual population size, while the Bayesian estimate is consistently
    too high. The standard errors are illustrative as well, with the Bayesian standard
    error being larger than the others, indicating more trial-to-trial variation.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 输出现在反映了25次重复的平均值和标准误差，提供了更好的估算行为概览。林肯-彼得森和查普曼的结果接近真实种群大小，而贝叶斯估算值则持续偏高。标准误差也具有说明性，贝叶斯的标准误差比其他两个估算器要大，表明试次之间的变化较大。
- en: Try experimenting with different combinations of population size and number
    of animals initially marked.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试不同的种群大小和最初标记的动物数量组合进行实验。
- en: '[Figure 11-3](ch011.xhtml#ch011fig03) presents three somewhat crowded graphs.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-3](ch011.xhtml#ch011fig03)展示了三张有些拥挤的图表。'
- en: '![Image](../images/11fig03.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/11fig03.jpg)'
- en: '*Figure 11-3: The three mark and recapture estimators as a function of the
    true population size and the fraction of that size initially marked. The plots
    show the signed deviation from the true population size: Lincoln-Peterson (top
    left), Chapman (top right), and Bayesian (bottom).*'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11-3：三种标记重捕估算器作为真实种群大小和初始标记比例的函数。图中显示的是与真实种群大小的偏差：林肯-彼得森（左上）、查普曼（右上）和贝叶斯（底部）。*'
- en: In the top-left graph in [Figure 11-3](ch011.xhtml#ch011fig03), each of the
    seven plotted lines represents a different true population size from 100 to 10,000\.
    The *x*-axis indicates the fraction of the true population marked by the ecologist
    on their first trip to the field. The value plotted is the median signed difference
    between the Lincoln-Petersen estimate for that combination of population size
    and fraction initially marked and the true population size. If the curve is above
    zero, the estimate is too low; below zero, it’s too high. In other words, the
    graph shows *N*[true] – *N*[est], so underestimating is a positive difference
    and overestimating is negative. The remaining two graphs show the same information
    for the Chapman (top-right) and Bayesian (bottom) estimators.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 11-3](ch011.xhtml#ch011fig03)的左上方图表中，每条绘制的七条线代表不同的真实种群大小，范围从100到10,000。*x*轴表示生态学家第一次去野外时标记的真实种群比例。所绘制的值是林肯-彼得森估算值与该组合下的真实种群大小之间的中位数偏差。如果曲线高于零，说明估算值偏低；低于零，则偏高。换句话说，图表显示的是*N*[真实]
    – *N*[估算]，因此低估为正差，过度估算为负差。其余两张图展示了查普曼（右上）和贝叶斯（底部）估算器的相同信息。
- en: For populations above 1,000, the Lincoln-Petersen estimator is generally useful
    when initially marking more than 10 percent of the population, which may not be
    feasible in practice. However, for small populations, the estimator requires some
    20 percent of the population to be marked to achieve reliability. One might use
    a simulation to generate a correction function for the Lincoln-Petersen estimator
    based on the suspected population size and the number of animals initially marked.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于种群超过1,000的情况，林肯-彼得森估算器通常在初始标记超过10%的种群时有效，但在实践中可能难以实现。然而，对于小型种群，该估算器需要标记约20%的种群才能达到可靠性。可以使用模拟来基于怀疑的种群大小和最初标记的动物数量，生成林肯-彼得森估算器的修正函数。
- en: The Chapman estimator consistently underestimates the true population size to
    the point where one questions its utility compared to the Lincoln-Petersen estimate.
    However, the underestimate is relatively consistent for populations above 1,000,
    so again, a fudge factor might be derived from a simulation.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 查普曼估计器通常低估真实的种群数量，以至于人们开始质疑它与林肯-彼得森估计相比的实用性。然而，这种低估对于大于1000的种群来说是相对一致的，因此，同样可以通过模拟得出一个修正系数。
- en: The Bayesian estimator’s performance is quite different. It consistently overestimates
    the actual population, converging to the true population value only when the population
    becomes large and the percent initially marked is also significant (at least 15
    percent). In practice, these conditions are unlikely to be met.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯估计器的表现则截然不同。它总是高估实际的种群数量，只有当种群变大并且最初标记的百分比也较高（至少15%）时，才会趋近于真实的种群值。在实际操作中，这些条件很难满足。
- en: '[Figure 11-3](ch011.xhtml#ch011fig03) is the output of *mark_recapture_range.py*,
    which can be understood by examining the relevant parts of *mark_recapture.py*
    in [Listing 11-6](ch011.xhtml#ch011list06).'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11-3](ch011.xhtml#ch011fig03)是*mark_recapture_range.py*的输出，可以通过查看[清单11-6](ch011.xhtml#ch011list06)中*mark_recapture.py*的相关部分来理解。'
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '*Listing 11-6: Simulating mark and recapture estimates*'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 11-6：模拟标记和回捕估计*'
- en: The outer `for` loop over `nreps` handles the trials. For each trial, we create
    a population (`pop`) vector where `npop` is the population size from the command
    line. The vector is initially zero as we haven’t marked any animals yet.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 外部的`for`循环遍历`nreps`处理试验。对于每个试验，我们创建一个种群（`pop`）向量，其中`npop`是从命令行输入的种群大小。该向量最初为零，因为我们还没有标记任何动物。
- en: The next two lines represent the ecologist’s first field trip. The `argsort`
    trick, coupled with keeping only the first `nmark` elements of the sort order,
    sets `idx` to the indices of `pop` that the ecologist has initially captured and
    marked (`pop[idx]=1`).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两行表示生态学家的第一次实地考察。`argsort`技巧结合只保留排序顺序中的前`nmark`个元素，将`idx`设置为生态学家最初捕获并标记的`pop`索引（`pop[idx]=1`）。
- en: The second code paragraph represents the recapture phase in which the ecologist
    returns to the field and captures as many animals as were initially marked (`K`).
    We represent the captured animals by the `K` indices in `idx` as assigned in the
    inner `while` loop.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 第二段代码表示回捕阶段，在该阶段，生态学家返回现场并捕获与最初标记的动物数量相同的动物（`K`）。我们通过在内部`while`循环中分配的`idx`中的`K`索引来表示被捕获的动物。
- en: Marks are binary, so the sum of the selected elements of `pop` is the number
    of marked animals, `k`. If `k` is 3 or greater, break out of the `while` loop.
    Otherwise, increase `K` by five and try again. The final code paragraph calculates
    the three estimates of the true population size for this trial.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 标记是二进制的，因此`pop`中所选元素的总和即为已标记动物的数量`k`。如果`k`大于或等于3，则跳出`while`循环。否则，将`K`增加5并再次尝试。最后一段代码计算该试验中真实种群数量的三个估计值。
- en: When the outer `for` loop exits, we have three vectors of estimates for the
    given population size and number initially marked. The remainder of *mark_recapture.py*
    displays the results. Given the simulation results, my money’s on the Lincoln-Petersen
    estimator.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当外部`for`循环退出时，我们得到了三个关于给定种群大小和最初标记数量的估计向量。*mark_recapture.py*的其余部分显示了结果。根据模拟结果，我的偏好是林肯-彼得森估计器。
- en: Let’s move on from counting to the mathematically important task of primality
    testing.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从计数转向数学上重要的任务——素性测试。
- en: '**Testing Primality**'
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**素性测试**'
- en: Prime numbers—integers evenly divisible by only themselves and one—are greatly
    beloved by number theorists. Primes have fascinated humanity since antiquity,
    and significant computing power is currently devoted to locating *Mersenne primes*
    of the form 2*^p* – 1, where *p* is a prime number.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 素数——只能被自己和1整除的整数——深受数论学者的喜爱。自古以来，素数就吸引着人类的目光，目前大量计算能力被用于寻找*梅森素数*，其形式为2*^p* –
    1，其中*p*是素数。
- en: 'The largest known primes are Mersenne primes. As of this writing, the largest
    known Mersenne prime, discovered in 2018, is:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 已知最大的素数是梅森素数。截止到目前，已知的最大梅森素数是2018年发现的：
- en: '*M*[82,589,933] = 2^(82,589,933) − 1'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '*M*[82,589,933] = 2^(82,589,933) − 1'
- en: '*M*[82,589,933] is a 24,862,048-digit number. Mersenne primes are sometimes
    denoted by their number and not their exponent. Therefore, *M*[82,589,933], the
    51st Mersenne prime, might be given as *M*[51].'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '*M*[82,589,933]是一个24,862,048位的数字。梅森素数有时用其编号而非指数表示。因此，*M*[82,589,933]，即第51个梅森素数，可能被表示为*M*[51]。'
- en: '**NOTE**'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*To contribute in locating Mersenne primes, visit* [https://www.mersenne.org](https://www.mersenne.org)
    *and sign up for the Great Internet Mersenne Prime Search.*'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '*要为寻找梅森质数贡献力量，访问* [https://www.mersenne.org](https://www.mersenne.org) *并注册加入“大型互联网梅森质数搜索”计划。*'
- en: 'How do we know if *n* is a prime number? The definition gives us a natural
    starting point for a primality testing algorithm: if the only numbers that evenly
    divide *n* (resulting in no remainder) are 1 and *n*, then *n* is a prime.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何知道 *n* 是质数？定义为我们提供了一个自然的起点用于质数测试算法：如果唯一能整除 *n*（结果没有余数）的数字是1和 *n*，那么 *n*
    就是质数。
- en: Let’s turn this definition into an algorithm. The brute force approach is to
    test every number that could be a factor of *n*. In practice, this means testing
    every integer up to ![Image](../images/f0311-01.jpg) because any factor of *n*
    larger than ![Image](../images/f0311-01.jpg) will necessarily be multiplied by
    some number less than ![Image](../images/f0311-01.jpg), and will be caught before
    reaching ![Image](../images/f0311-01.jpg).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个定义转化为一个算法。蛮力法是测试每个可能是 *n* 因子的数字。实际上，这意味着要测试每个整数直到 ![Image](../images/f0311-01.jpg)，因为任何大于
    ![Image](../images/f0311-01.jpg) 的 *n* 因子必定会与某个小于 ![Image](../images/f0311-01.jpg)
    的数字相乘，并在到达 ![Image](../images/f0311-01.jpg) 之前就被发现。
- en: When contemplating numbers comprising nearly 25 million digits, the amount of
    work involved increases dramatically. And if *n* is prime, must we test *every*
    integer up to ![Image](../images/f0311-01.jpg)?
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 当考虑到包含接近2500万个数字的数字时，所涉及的工作量会急剧增加。如果 *n* 是质数，我们是否需要测试每一个整数直到 ![Image](../images/f0311-01.jpg)？
- en: The *Miller-Rabin test* is a fast, randomized algorithm to decide whether a
    positive integer, *n*, is prime. However, to understand the Miller-Rabin test,
    we need to know a bit about modular arithmetic.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*米勒-拉宾测试* 是一种快速的随机算法，用于判断一个正整数 *n* 是否为质数。然而，要理解米勒-拉宾测试，我们需要了解一些关于模运算的知识。'
- en: '***Modular Arithmetic***'
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***模运算***'
- en: 'We’re used to the set of integers, denoted ℤ from the German for number. Integers
    are unbounded and extend infinitely in both directions from zero. If we restrict
    the range to the set {0, 1, 2, 3}, we can define arithmetic operations over this
    set by wrapping around as needed. Adding works as expected if the sum is less
    than 4: 1 + 1 = 2 and 2 + 1 = 3\. However, if the sum exceeds 4, we wrap around.
    For example, 2+3 = 1 because 2+3 = 5, and we subtract 4 from 5 to get 1\. Another
    way to view these operations is to apply the modulo operator after each addition
    to return the remainder after dividing by 4\. For example, 5 mod 4 = 1.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们习惯于整数集合，表示为 ℤ，来自德语“Zahl”（数字）。整数是无限的，从零向两边无限延伸。如果我们将范围限制为集合 {0, 1, 2, 3}，我们可以通过需要时进行“回绕”来定义该集合上的算术运算。当和小于4时，加法按预期进行：1
    + 1 = 2 和 2 + 1 = 3。然而，如果和超过4，我们就会回绕。例如，2 + 3 = 1，因为 2 + 3 = 5，我们从5中减去4得到1。另一种看待这些运算的方式是，在每次加法后应用模运算符，返回除以4后的余数。例如，5
    mod 4 = 1。
- en: Pierre Fermat, a 17th-century French mathematician, realized that if *n* is
    a prime number, then
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 皮埃尔·费尔马，17世纪的法国数学家，意识到如果 *n* 是质数，那么
- en: '*a*^(*n* – 1) ≡ 1 (mod *n*), 0 < *a* < *n*'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '*a*^(*n* – 1) ≡ 1 (mod *n*), 0 < *a* < *n*'
- en: 'where ≡ means:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ≡ 表示：
- en: '*a*^(*n* – 1) mod *n* = 1 mod *n* = 1'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '*a*^(*n* – 1) mod *n* = 1 mod *n* = 1'
- en: 'Great! We have a primality test: pick an integer 0 < *a* < *n*, raise it to
    the *n* – 1 power, divide by *n*, and see if the remainder is 1\. If it is, then
    *n* is a prime number, so the algorithm works and identifies *n* as a prime. However,
    some composite numbers also pass the test for many values of *a*, meaning this
    alone isn’t sufficient to prove *n* is a prime. If this test fails, then *n* is
    definitely not a prime.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！我们有了一个质数测试：选择一个整数 0 < *a* < *n*，将其升到 *n* – 1 次方，再除以 *n*，看看余数是否为1。如果是，那么
    *n* 就是质数，所以算法有效并且能够识别 *n* 为质数。然而，一些合成数也会通过这个测试，对于许多 *a* 值，这意味着单靠这个测试不足以证明 *n*
    是质数。如果测试失败，则 *n* 绝对不是质数。
- en: The Miller-Rabin test combines Fermat’s test with another fact—if *n* is prime,
    the following is likely also true
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 米勒-拉宾测试结合了费尔马的测试和另一个事实——如果 *n* 是质数，那么以下公式也可能成立
- en: '![Image](../images/f0311-03.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0311-03.jpg)'
- en: for some *r* in [0, *s*) where *n* = 2*^sd* + 1 and *d* is odd. It’s likely
    true because there are sometimes *a* values satisfying the congruence even if
    *n* is composite. We’ll discuss these non-witness numbers shortly.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个 *r* 在 [0, *s*) 范围内，其中 *n* = 2*^sd* + 1 且 *d* 是奇数。这是可能成立的，因为有时即使 *n* 是合成数，也会存在满足该同余关系的
    *a* 值。我们稍后将讨论这些非见证数。
- en: The first condition, Fermat’s test, is straightforward enough, but let’s unpack
    this second condition. We need to express *n* as 2*^sd* + 1 or, equivalently,
    as *n*–1 = 2*^sd*. For suitable choices of *s* and *d*, 2*^sd* is another way
    of writing the exponent in the Fermat condition.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个条件，费马测试，足够简单，但让我们来拆解第二个条件。我们需要将 *n* 表示为 2*^sd* + 1，或者等价地，表示为 *n*–1 = 2*^sd*。对于适当选择的
    *s* 和 *d*，2*^sd* 是费马条件中指数的另一种表示方式。
- en: All of the math in ≡ –1 (mod *n*) is modulo *n*, meaning the numbers are in
    the set {0, 1, 2, . . . , *n* – 1}, usually denoted as ℤ*[n]*. We view a negative
    number as counting backward, so –1 ≡ *n* – 1.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ≡ –1 (mod *n*) 中的所有数学运算都是模 *n* 运算，这意味着数字位于集合 {0, 1, 2, . . . , *n* – 1} 中，通常表示为
    ℤ*[n]*。我们将负数视为倒数计数，因此 –1 ≡ *n* – 1。
- en: 'The second condition checks to see if *x*² ≡ –1 (mod *n*) for some *x*. The
    Miller-Rabin test uses a sequence of such values of *x*, looking for one that,
    when squared modulo *n*, gives –1 (that is, *n* – 1). The sequence begins with
    *r* = 0 and *d* as the exponent. The next check uses the square, which is the
    same as *r* = 1:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个条件检查是否存在某个 *x* 使得 *x*² ≡ –1 (mod *n*)。Miller-Rabin 测试使用一系列这样的 *x* 值，寻找一个当模
    *n* 平方时结果为 –1（即 *n* – 1）。序列从 *r* = 0 和 *d* 作为指数开始。下一个检查使用平方，实际上是 *r* = 1：
- en: '![Image](../images/f0312-01.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0312-01.jpg)'
- en: This is all modulo *n*. The next squaring returns *r* = 2, and so on.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都是模 *n* 运算。接下来的平方操作返回 *r* = 2，依此类推。
- en: If any of the sequence of such expressions is equivalent to *n* – 1, then *n*
    has a reasonably high probability of being a prime number. Otherwise, *n* is definitely
    *not* prime, and *a* is a *witness* to this fact.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这种表达式序列中的任何一个等于 *n* – 1，那么 *n* 具有相当高的概率是一个素数。否则，*n* 绝对不是素数，而 *a* 是这一事实的 *见证*。
- en: '***The Miller-Rabin Test***'
  id: totrans-191
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***Miller-Rabin 测试***'
- en: Let’s put Miller-Rabin into code, as in [Listing 11-7](ch011.xhtml#ch011list07).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把 Miller-Rabin 实现成代码，如 [列表 11-7](ch011.xhtml#ch011list07) 所示。
- en: '[PRE19]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '*Listing 11-7: Miller-Rabin in code*'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 11-7：Miller-Rabin 代码实现*'
- en: The function `MillerRabin` accepts *n* and `rounds` with a default value of
    5\. The first code paragraph captures trivial cases. As half of all numbers are
    even, testing directly for 2 and evenness saves time.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `MillerRabin` 接受 *n* 和 `rounds`，默认值为 5。第一段代码捕获了琐碎的情况。由于一半的数字是偶数，直接测试 2 和偶性可以节省时间。
- en: The second code paragraph locates *s* and *d* so that *n* = 2*^sd* + 1\. It’s
    always possible to find an *s* and *d* decomposition for any *n* (positive integer).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 第二段代码定位 *s* 和 *d* 使得 *n* = 2*^sd* + 1。对于任何 *n*（正整数），总是可以找到一个 *s* 和 *d* 的分解。
- en: For now, we’ll focus on the body of the outer `for` loop in the third paragraph,
    which implements a pass through the Miller-Rabin test for a randomly selected
    *a* and initial *x* value, *a^d* (mod *n*).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们将重点关注第三段中的外层 `for` 循环部分，该部分实现了对随机选择的 *a* 和初始 *x* 值 *a^d* (mod *n*) 的 Miller-Rabin
    测试。
- en: The built-in Python function, `pow`, computes exponents and accepts an optional
    third argument so that `pow(a,d,n)` efficiently implements *a^d* (mod *n*).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 内置的 Python 函数 `pow` 计算指数，并接受一个可选的第三个参数，因此 `pow(a,d,n)` 可以高效地实现 *a^d* (mod *n*)。
- en: The following `if` checks for 1 or –1\. If that’s the case, the Fermat test
    has passed, so this pass through the outer `for` loop is over.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的 `if` 检查是否为 1 或 –1。如果是这种情况，则费马测试通过，因此这一轮外层 `for` 循环结束。
- en: Otherwise, the inner `for` loop initiates the sequence of successive squarings
    of *x* = *a^d* while looking for one equivalent to –1\. If such a squaring is
    found, the inner loop breaks and the outer loop cycles; otherwise, *n* is composite
    and `MillerRabin` returns `False`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，内层 `for` 循环开始执行 *x* = *a^d* 的连续平方序列，同时寻找一个等于 –1 的结果。如果找到这样的平方，内层循环将中断，外层循环继续；否则，*n*
    是合数，`MillerRabin` 返回 `False`。
- en: When all rounds (the loop over `k`) are complete, and every test supports the
    notion that *n* is a prime, `MillerRabin` returns `True`.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有轮次（`k` 的循环）完成，并且每个测试都支持 *n* 是素数的假设时，`MillerRabin` 返回 `True`。
- en: The outer `for` loop applies the Miller-Rabin test repeated for randomly selected
    *a* values. Since an *a* value demonstrating *n* to be a composite number is a
    witness number, an *a* value that leads to a claim of prime when *n* is not prime
    is a *non-witness* number. It is never the case that all possible *a* values for
    a given *n* are non-witness numbers, so repeated applications of the outer loop
    body minimize the probability that a non-prime input will return `True`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 外部的`for`循环应用了米勒-拉宾测试，重复地为随机选择的*a*值进行测试。由于一个*a*值能够证明*n*是复合数的，它是一个见证数，而一个*a*值导致在*n*不是质数时错误地宣称它是质数的则是一个*非见证数*。对于给定的*n*，不可能所有的*a*值都是非见证数，因此多次应用外部循环主体可以最小化非质数输入返回`True`的概率。
- en: 'You’ll find `MillerRabin` in the file *miller_rabin.py*. It expects a number
    to test, the number of rounds (*a* values to try), and the randomness source:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在文件*miller_rabin.py*中找到`MillerRabin`。它需要一个待测试的数字、测试轮数（即要尝试的*a*值数量）以及随机数源：
- en: '[PRE20]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'For example:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: '[PRE21]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output must be correct for these cases as 73,939,133 is a prime, and the
    closest two primes can be to each other is 2 away:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些情况，输出必须是正确的，因为73,939,133是质数，并且最接近的两个质数之间相差2：
- en: '[PRE22]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Both 8,675,309 and 8,675,311 are twin primes, so the test is correct.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 8,675,309和8,675,311是孪生质数，因此测试是正确的。
- en: Miller-Rabin always labels a prime a prime. Let’s explore when Miller-Rabin
    fails.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 米勒-拉宾始终将质数标记为质数。让我们探讨米勒-拉宾何时会失败。
- en: '#### ***Non-witness Numbers***'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '#### ***非见证数***'
- en: As mentioned, a witness number, *a*, testifies to the fact that *n* isn’t prime.
    Also, there are composite numbers for which the Miller-Rabin test fails if it
    selects a non-witness number as *a*.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，见证数*a*证明*n*不是质数。此外，对于某些复合数，如果米勒-拉宾测试选择了一个非见证数作为*a*，测试将失败。
- en: We’ll force the Miller-Rabin algorithm to fail, probabilistically, using a composite
    number with a known set of non-witness numbers to see if we can detect the expected
    number of failures.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过使用一个已知的非见证数集来强制米勒-拉宾算法失败，以查看是否能够检测到预期的失败次数。
- en: Our target is *n* = 65\. As a multiple of 5, 65 is composite. There are 64 potential
    witness numbers, from 1 through 64\. Of these potential witness numbers, it’s
    known that 8, 18, 47, 57, and 64 are non-witness numbers. If the Miller-Rabin
    test runs for one round and selects a non-witness number for *a*, it fails and
    claims that 65 is prime.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是*n* = 65。作为5的倍数，65是复合数。共有64个潜在的见证数，从1到64。这些潜在见证数中，已知8、18、47、57和64是非见证数。如果米勒-拉宾测试进行一次并选择了一个非见证数作为*a*，它将失败并错误地宣称65是质数。
- en: Because there are five non-witness numbers out of 64 possible, the Miller-Rabin
    test for a single round should fail about 5/64 = 7.8 percent of the time. I checked
    this by running *miller_rabin.py* 1,000 times and counting the number of times
    the output indicated a prime, which it did precisely 78 times, implying a failure
    rate of 78/1, 000 = 7.8 percent.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在64个可能的数字中有五个非见证数，因此米勒-拉宾测试在单轮情况下应该大约有5/64 = 7.8%的时间失败。我通过运行*miller_rabin.py*
    1,000次，并统计输出显示为质数的次数，发现恰好有78次，意味着失败率为78/1,000 = 7.8%。
- en: At worst, the Miller-Rabin single-round failure probability for arbitrary *n*
    is 1/4\. Since each round is independent of the previous, running the test for
    *k* rounds means the worst possible failure probability is (1/4)*^k* = 4^(–*k*).
    However, for most *n* values, the actual failure probability is far less than
    this.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 最坏情况下，米勒-拉宾单轮失败的概率对于任意的*n*为1/4。由于每一轮与前一轮是独立的，运行*k*轮测试意味着最坏的失败概率为(1/4)*^k* =
    4^(-*k*)。然而，对于大多数*n*值，实际的失败概率远低于这个值。
- en: Let’s stick with 65\. Knowing that its single-round failure rate is about 7.8
    percent, running two rounds should fail (5/64)² ≈ 0.61 percent of the time. Running
    *miller_rabin.py* 20,000 times produced 131 failures, giving a failure rate of
    131/20, 000 = 0.655 percent. Three rounds puts the failure rate at about 0.05
    percent. We can achieve any desired precision by setting *k* high enough.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用65。知道它的单轮失败率大约为7.8%，运行两轮应该大约有(5/64)² ≈ 0.61%的时间失败。运行*miller_rabin.py*
    20,000次，得到了131次失败，失败率为131/20,000 = 0.655%。三轮测试的失败率大约为0.05%。我们可以通过将*k*设置得足够高来达到任何期望的精度。
- en: '***Miller-Rabin Performance***'
  id: totrans-218
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***米勒-拉宾性能***'
- en: Let’s compare Miller-Rabin’s runtime performance to the brute force approach
    implemented in *brute_primes.py*. The code in *prime_tests.py* runs both Miller-Rabin
    and the brute force algorithm for the largest 1, 2, 3, . . . , 15-digit prime
    numbers. Recall, the brute force algorithm runs the longest when the input is
    a prime.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将Miller-Rabin的运行时表现与在*brute_primes.py*中实现的暴力方法进行比较。*prime_tests.py*中的代码同时运行Miller-Rabin和暴力算法，测试最大1位、2位、3位……到15位的质数。回想一下，当输入是质数时，暴力算法的运行时间最长。
- en: The largest single-digit prime is 7, while the largest 15-digit prime is 999,999,999,999,989\.
    In [Figure 11-4](ch011.xhtml#ch011fig04), we plot the mean of five runs of *miller_rabin.py*
    and *brute_primes.py* for each prime to show how the runtime changed as the inputs
    grew.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 最大的单数字质数是7，而最大的15位质数是999,999,999,999,989。在[图11-4](ch011.xhtml#ch011fig04)中，我们绘制了对每个质数进行五次运行的*miller_rabin.py*和*brute_primes.py*的平均值，以展示随着输入增大，运行时间的变化。
- en: '![Image](../images/11fig04.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/11fig04.jpg)'
- en: '*Figure 11-4: Comparing Miller-Rabin to the brute force primality test*'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11-4：比较Miller-Rabin与暴力质数测试*'
- en: The runtime complexity of the brute force algorithm is ![Image](../images/f0315-01.jpg)
    while that of Miller-Rabin is ![Image](../images/c0301-01.jpg)(log³ *n*). The
    brute force algorithm quickly becomes unmanageable, even though it’s sublinear,
    because ![Image](../images/f0315-02.jpg) and 1/2 < 1.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 暴力算法的运行时复杂度是![Image](../images/f0315-01.jpg)，而Miller-Rabin的运行时复杂度是![Image](../images/c0301-01.jpg)(log³
    *n*)。尽管暴力算法是次线性的，但它很快变得不可管理，因为![Image](../images/f0315-02.jpg)且1/2 < 1。
- en: Miller-Rabin is a Monte Carlo algorithm because it claims *n* is a prime when
    there’s a nonzero probability that it isn’t. If *n* truly is a prime, Miller-Rabin
    always correctly labels it, but it also calls some composite numbers prime regardless
    of the number of rounds. Therefore, Miller-Rabin’s false positive rate is nonzero,
    but its false negative rate is identically zero. In practice, however, increasing
    the number of rounds can make the false-positive rate as low as desired.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Miller-Rabin是一个蒙特卡罗算法，因为它声称*n*是质数，即使在*n*不是质数时仍有非零的概率。如果*n*确实是质数，Miller-Rabin总是正确地标记它，但它也会错误地将一些合成数标记为质数，无论循环次数多少。因此，Miller-Rabin的假阳性率是非零的，但其假阴性率为零。然而，在实际应用中，增加轮次可以使假阳性率降低到任何期望的水平。
- en: We have one more randomized algorithm to contemplate.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有一个随机化算法需要考虑。
- en: '**Working with Quicksort**'
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**使用快速排序**'
- en: Quicksort was developed by British computer scientist Tony Hoare in 1959 and
    is probably still the most widely used sorting algorithm. It’s NumPy’s default,
    for example.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 快速排序由英国计算机科学家Tony Hoare于1959年开发，可能仍然是最广泛使用的排序算法。例如，它是NumPy的默认排序算法。
- en: 'If you take an undergraduate course in algorithms, you’ll almost assuredly
    run across Quicksort, as it’s easy to implement and understand, even if it’s recursive.
    While most courses focus on characterizing its runtime complexity, we’ll discuss
    the algorithm at a high level instead, and then run experiments on two versions:
    the standard nonrandom version and a randomized version.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你参加本科的算法课程，你几乎肯定会接触到快速排序，因为它实现简单且容易理解，即使它是递归的。虽然大多数课程都会专注于表征其运行时复杂度，我们将以更高的层次讨论该算法，并对两种版本进行实验：标准的非随机版本和随机版本。
- en: Quicksort is a recursive, *divide-and-conquer* algorithm, meaning it calls itself
    on smaller and smaller versions of the problem until it encounters a base condition,
    at which point the implementation pieces everything back together to produce a
    sorted output.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 快速排序是一种递归的*分治*算法，这意味着它会在更小的子问题上反复调用自身，直到遇到基本条件为止，此时实现会将所有部分重新组合，输出排序结果。
- en: 'The algorithm is as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 算法如下：
- en: If the input array is empty or has only one element, return it.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果输入数组为空或仅包含一个元素，直接返回它。
- en: Pick a *pivot* element, either the first in the array or at random.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个*基准*元素，可以是数组中的第一个元素或随机选取。
- en: 'Separate the array into three subsets: those elements less than the pivot,
    those equal to the pivot, and those greater than the pivot.'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数组分成三个子集：小于基准元素的、等于基准元素的以及大于基准元素的。
- en: Return the concatenation of Quicksort called on the lower elements, the elements
    matching the pivot, and Quicksort called on the higher elements.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回快速排序对较小元素、与基准相等的元素以及较大元素进行排序后的拼接结果。
- en: 'Step 1 is the base condition. If the array is empty or contains a single element,
    it’s sorted. step 2 picks a pivot value, an array element we use in Step 3 to
    split the array into three parts: those less than, equal to, and greater than
    the pivot. Step 2 is where randomness comes into play. Non-random Quicksort always
    picks a specific element of the array, as it’s already assumed to be in random
    order. Randomized Quicksort, however, selects its pivot element at random. We’ll
    experiment with the subtle difference between nonrandom and random Quicksort.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 第1步是基本条件。如果数组为空或只包含一个元素，那么它就是已排序的。第2步选择一个枢轴值，这是我们在第3步中用来将数组划分为三部分的元素：小于、等于和大于枢轴的部分。第2步是随机性发挥作用的地方。非随机快速排序总是选择数组中的特定元素，因为它已假设数组是随机排序的。然而，随机快速排序会随机选择枢轴元素。我们将实验非随机快速排序和随机快速排序之间的微妙差异。
- en: Step 4 is the recursive part. The array is sorted if we merge the sorted lower
    partition with the same partition followed by the sorted higher partition. We
    sort the lower and higher partitions by using the sorting routine, that is, by
    calling Quicksort again. Each call on a portion of the array will, we assume,
    work with a smaller number of elements until we have single elements, the base
    condition of step 1.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 第4步是递归部分。如果我们将已排序的低区间与相同的区间合并，再加上已排序的高区间，数组就会被排序。我们通过使用排序例程来排序低区间和高区间，也就是再次调用快速排序（Quicksort）。我们假设每次调用数组的一部分时，处理的元素数量会逐渐变少，直到最终每个部分只有一个元素，这是第1步的基本条件。
- en: Naive sorting methods, like bubble sort or gnome sort, run in ![Image](../images/c0301-01.jpg)(*n*²)
    time where *n* is the number of elements to sort. As we’ve learned, ![Image](../images/c0301-01.jpg)(*n*²)
    algorithms are acceptable for small *n* values, but quickly become unmanageable
    as *n* grows. Quicksort’s average runtime complexity is ![Image](../images/c0301-01.jpg)(*n*
    log *n*), which grows at a much slower rate. This is why Quicksort is still widely
    used over 50 years after its introduction.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 天真的排序方法，如冒泡排序或侏儒排序，运行时间是 ![Image](../images/c0301-01.jpg)(*n*²)，其中*n*是要排序的元素个数。正如我们所了解的那样，![Image](../images/c0301-01.jpg)(*n*²)
    算法适用于小*n*值，但随着*n*的增加，性能会迅速变得无法管理。快速排序的平均运行时间复杂度是 ![Image](../images/c0301-01.jpg)(*n*
    log *n*)，增长速度较慢。因此，尽管快速排序是在50多年前引入的，但至今仍被广泛使用。
- en: While Quicksort’s *average* complexity is ![Image](../images/c0301-01.jpg)(*n*
    log *n*), if the array passed to Quicksort is already mostly or completely sorted,
    the complexity becomes ![Image](../images/c0301-01.jpg)(*n*²), which is no better
    than bubble sort. This happens if the array is in order or reverse order. Let’s
    find out whether randomized Quicksort can help us here.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然快速排序的*平均*时间复杂度是 ![Image](../images/c0301-01.jpg)(*n* log *n*)，但如果传递给快速排序的数组已经大部分或完全排序，那么复杂度会变成
    ![Image](../images/c0301-01.jpg)(*n*²)，这和冒泡排序一样，效果并不好。这种情况发生在数组已经按顺序或逆顺序排列时。让我们来看看随机快速排序是否能帮我们解决这个问题。
- en: '***Running Quicksort in Python***'
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***在Python中运行快速排序***'
- en: The file *Quicksort.py* implements Quicksort twice. The first implementation
    uses a random pivot (`QuicksortRandom`), and the second implementation always
    uses the first element of the array as the pivot (`Quicksort`). The functions
    are in [Listing 11-8](ch011.xhtml#ch011list08).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 文件*Quicksort.py*实现了两次快速排序。第一次实现使用一个随机枢轴（`QuicksortRandom`），第二次实现总是使用数组的第一个元素作为枢轴（`Quicksort`）。这些函数位于[清单
    11-8](ch011.xhtml#ch011list08)中。
- en: '[PRE23]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '*Listing 11-8: Randomized and nonrandom Quicksort*'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 11-8：随机和非随机快速排序*'
- en: For this example, we use NumPy instead of our `RE` class because it’s already
    loaded, which minimizes the overhead when calling `QuicksortRandom`. The implementations
    differ only in how they assign `pivot`.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用NumPy而不是我们的`RE`类，因为NumPy已经加载，这样可以最小化调用`QuicksortRandom`时的开销。两者的实现唯一的区别在于如何分配`pivot`。
- en: Both implementations follow the Quicksort algorithm step-by-step. First, we
    check for the base condition where `arr` is already sorted. We then split into
    `low`, `same`, and `high` based on the selected `pivot`. Finally, NumPy’s `hstack`
    function concatenates the vectors returned by the recursive calls to `Quicksort`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 两种实现都遵循快速排序算法的每一步。首先，我们检查基本条件，即`arr`已经排序。然后，根据选定的`pivot`将数组分为`low`、`same`和`high`。最后，NumPy的`hstack`函数将递归调用`Quicksort`返回的向量进行拼接。
- en: A high-performance implementation wouldn’t call `where` three times, as each
    makes a full pass over `arr`, but we’re interested only in relative performance
    differences as the input size changes.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 一个高性能的实现不会调用`where`三次，因为每次都会对`arr`进行一次完整的遍历，但我们这里只关心随着输入大小变化，性能之间的相对差异。
- en: '***Experimenting with Quicksort***'
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***实验快速排序***'
- en: The file *quicksort_tests.py* generates two graphs. The first, on the left in
    [Figure 11-5](ch011.xhtml#ch011fig05), compares randomized Quicksort and nonrandom
    Quicksort as the input array size increases. In all cases, the input arrays are
    in random order. Therefore, the left side of [Figure 11-5](ch011.xhtml#ch011fig05)
    represents the average case runtime. The points plotted are the mean over five
    runs. The dashed line represents *y* = *n* log *n*.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 文件*quicksort_tests.py*生成了两张图。第一张，位于[图11-5](ch011.xhtml#ch011fig05)的左侧，比较了随机化快速排序和非随机快速排序随着输入数组大小增加的表现。在所有情况下，输入数组都是随机顺序的。因此，[图11-5](ch011.xhtml#ch011fig05)的左侧代表了平均情况运行时。绘制的点是五次运行的均值。虚线表示*y*
    = *n* log *n*。
- en: '![Image](../images/11fig05.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/11fig05.jpg)'
- en: '*Figure 11-5: Randomized and nonrandom Quicksort on random inputs (left) and
    the same algorithms on pathological inputs (right)*'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11-5：随机化和非随机快速排序在随机输入下（左）以及相同算法在病态输入下（右）的表现*'
- en: The rightmost graph in [Figure 11-5](ch011.xhtml#ch011fig05) shows the runtime
    for the case with already sorted input. This situation forces deterministic Quicksort
    into becoming an ![Image](../images/c0301-01.jpg)(*n*²) algorithm, which is why
    it tracks the curved plot, *y* = *n*². Randomized Quicksort, on the other hand,
    is unaffected by the order of the input and runs as before.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11-5](ch011.xhtml#ch011fig05)中最右侧的图展示了已经排好序的输入情况下的运行时间。这个情况迫使确定性快速排序变成了一个![Image](../images/c0301-01.jpg)(*n*²)算法，这就是它跟随曲线*y*
    = *n*²的原因。另一方面，随机化快速排序不受输入顺序的影响，仍然按之前的方式运行。'
- en: Correctly interpreting [Figure 11-5](ch011.xhtml#ch011fig05) requires an explanation.
    Asymptotic runtime performance of algorithms ignores multiplicative factors and
    constants as they don’t alter the overall form of the function as *n* increases.
    The randomized Quicksort function takes slightly longer to run than the non-random
    Quicksort because of the extra step of selecting a random index into the array.
    Therefore, plotting both runtimes together would make it somewhat difficult to
    see that the overall functional form is the same between `QuicksortRandom` and
    `Quicksort`. Moreover, plotting *y* = *n* log *n* follows an entirely different
    scale in terms of *y*-axis values, but again, the form of the function is the
    same. Therefore, to plot all three together, [Figure 11-5](ch011.xhtml#ch011fig05)
    divides each *y* value by the maximum *y* value to map the output to [0, 1] regardless
    of the actual range. This clarifies that randomized Quicksort and nonrandom Quicksort
    scale in the same way, and are following ![Image](../images/c0301-01.jpg)(*n*
    log *n*)—all curves lie essentially on top of each other.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 正确解读[图11-5](ch011.xhtml#ch011fig05)需要一些解释。算法的渐进运行时性能忽略了乘法因子和常数，因为它们不会改变随着*n*增大时函数的整体形式。随机化快速排序的运行时间比非随机快速排序稍长，因为它需要额外的一步：选择数组中的一个随机索引。因此，将两者的运行时间一起绘制会使得我们不容易看到`QuicksortRandom`和`Quicksort`之间的总体函数形式是相同的。此外，绘制*y*
    = *n* log *n*时，*y*轴的数值尺度完全不同，但函数的形式仍然相同。因此，为了将三者一起绘制，[图11-5](ch011.xhtml#ch011fig05)将每个*y*值除以最大*y*值，将输出映射到[0,
    1]，无论实际范围如何。这清晰地表明，随机化快速排序和非随机快速排序的规模是一样的，且都遵循![Image](../images/c0301-01.jpg)(*n*
    log *n*)——所有曲线基本重合。
- en: Now reconsider the right side of [Figure 11-5](ch011.xhtml#ch011fig05) showing
    the case where the input array is already sorted. Again, the dashed line shows
    *y* = *n* log *n*, and randomized Quicksort still follows that form. However,
    nonrandom Quicksort, which selects the first element of the array as its pivot,
    does not. Instead, it follows the dotted line, *y* = *n*², meaning the pathological
    input case alters nonrandom Quicksort, turning it into an ![Image](../images/c0301-01.jpg)(*n*²)
    algorithm.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现在重新考虑[图11-5](ch011.xhtml#ch011fig05)右侧的情况，即输入数组已经排好序。再次地，虚线表示*y* = *n* log
    *n*，随机化快速排序仍然遵循这一形式。然而，非随机快速排序，它将数组的第一个元素作为基准元素，却并不遵循这一形式。相反，它遵循虚线*y* = *n*²，这意味着这种病态输入情况改变了非随机快速排序，使其变成了一个![Image](../images/c0301-01.jpg)(*n*²)算法。
- en: Randomized Quicksort is a Las Vegas algorithm because it always returns the
    proper output—a sorted array. While the randomness involved doesn’t make the implementation
    easier, it protects against a pathological case that’s more frequent in practice
    than we might initially suspect. Therefore, I recommend always using randomized
    Quicksort.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 随机化快速排序是一种拉斯维加斯算法，因为它总是返回正确的输出——一个已排序的数组。尽管涉及的随机性不会使实现变得更容易，但它能够避免一个在实践中比我们最初预期的更常见的病态情况。因此，我推荐总是使用随机化快速排序。
- en: To understand why nonrandom Quicksort behaves so poorly with sorted input, consider
    what happens during a pass when the pivot is the smallest value in the array;
    for example, when picking the first element as the pivot and the input array is
    already sorted. When this happens, the low vector is empty and, ignoring duplicates
    of the pivot, all the remaining values in the array end up in the high vector.
    This happens every time the function recurses, turning the recursion into a list
    of function calls *n* deep. Add the ![Image](../images/c0301-01.jpg)(*n*) pass
    through the array on each recursive call (implicit in our implementation via `where`),
    and we arrive at an ![Image](../images/c0301-01.jpg)(*n*²) algorithm, which is
    no better than a bubble sort.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么非随机快速排序在已排序的输入上表现如此糟糕，可以考虑当枢轴是数组中最小的值时会发生什么；例如，当选取第一个元素作为枢轴并且输入数组已经排序时会发生什么。发生这种情况时，低向量为空，并且忽略枢轴的重复值，数组中剩余的所有值都进入高向量。每次函数递归时都会发生这种情况，将递归转化为*n*层深的函数调用列表。将每次递归调用中通过数组的![Image](../images/c0301-01.jpg)(*n*)次（通过`where`隐式实现），我们得到了一个![Image](../images/c0301-01.jpg)(*n*²)的算法，这与冒泡排序一样差。
- en: Selecting a random pivot at each level ensures that this situation won’t happen
    in the long run, as it would amount to a string of *n* rolls of an *n-*sided fair
    die each landing on 1—an increasingly unlikely event as *n* grows.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一层选择一个随机的枢轴，可以确保长期来看这种情况不会发生，因为这就相当于进行*n*次* n *面公正骰子掷骰，每次都掷出1—这随着*n*的增加会变得越来越不可能。
- en: '### **Exercises**'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '### **练习**'
- en: 'Consider the following exercises to further explore randomized algorithms:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下练习，进一步探索随机化算法：
- en: Write a Las Vegas algorithm to locate positive integers, *a*, *b*, and *c*,
    that satisfy *a*² + *b*² = *c*². Your code will be a Las Vegas algorithm because
    there are an infinite number of solutions, namely all the Pythagorean triples.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写一个拉斯维加斯算法，定位满足*a*² + *b*² = *c*²的正整数*a*、*b*和*c*。你的代码将是一个拉斯维加斯算法，因为有无数的解，即所有的毕达哥拉斯三元组。
- en: Can you write a successful Las Vegas program to find positive integers *a*,
    *b*, and *c* such that *a^n* + *b^n* = *c^n* for some *n* > 2? If not, how about
    a Monte Carlo algorithm? What might your stopping criteria be? I recommend searching
    for “Fermat’s last theorem.”
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能编写一个成功的拉斯维加斯程序，找到正整数*a*、*b*和*c*，使得存在某个*n* > 2，满足*a^n* + *b^n* = *c^n*吗？如果不能，那么一个蒙特卡洛算法如何？你的停止标准可能是什么？我建议搜索“费马最后定理”。
- en: Extend the permutation sort runtime plot for *n* = 11, 12, or even 13\. How
    long do you have to wait?
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展排列排序的运行时间图，考虑*n* = 11、12甚至13的情况。你需要等多久？
- en: Make a plot of the mean number of trials of Freivalds’ algorithm to get a failure
    case as a function of *n*, the size of the square matrices.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绘制Freivalds算法失败案例的平均试验次数图，作为* n *的函数，表示方阵的大小。
- en: The file *test_mmult.py* generates output suitable for *curves.py* from [Chapter
    4](ch04.xhtml). Use that output and *curves.py* to generate fits. Is the fit exponent
    what you expect for the naive algorithm? What about NumPy, with the knowledge
    that it uses Strassen’s algorithm?
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件*test_mmult.py*生成适合从[第4章](ch04.xhtml)的*curves.py*的输出。使用该输出和*curves.py*生成拟合。拟合的指数是你对朴素算法的预期吗？那么对于使用Strassen算法的NumPy呢？
- en: I have a bag full of marbles. I want to estimate how many are in the bag. Therefore,
    I pick one randomly, mark it, and put it back in the bag. I then pick another
    marble randomly, mark it, and put it back in the bag. I repeat this process, counting
    the number of marbles selected, until I pick a marble I’ve already marked. If
    the number of marbles picked and marked is *k*, then the number of marbles in
    the bag is approximately![Image](../images/f0319-01.jpg)
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我有一个装满弹珠的袋子。我想估算袋子里有多少个弹珠。因此，我随机挑选一个，做标记后放回袋子中。然后我再随机挑选一个弹珠，做标记后放回袋子中。我重复这个过程，计算所选弹珠的数量，直到我挑选到一个已经标记过的弹珠。如果所挑选并标记的弹珠数量是*k*，那么袋子里的弹珠数量大致为！[Image](../images/f0319-01.jpg)
- en: 'where the combination of floor (⌊) on the left and ceiling (⌉) on the right
    means “round to the nearest integer.” I encountered this algorithm via a brief
    description of the process, but the description had no derivation for the formula
    and no references. Nonetheless, it sort of works. After experimenting some, I
    realized that the estimate is better if the formula is tweaked slightly to become:'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中，左边的下取整符号（⌊）和右边的上取整符号（⌉）表示“舍入到最接近的整数”。我通过一个简短的描述了解了这个算法，但该描述没有推导公式，也没有引用文献。尽管如此，它还是起作用的。在进行了一些实验后，我发现如果稍微调整公式，它的估算会更好，调整后的公式是：
- en: '![Image](../images/f0319-04.jpg)'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![Image](../images/f0319-04.jpg)'
- en: Implement this algorithm and explore how well it works on average. Then examine
    *count.py*, which runs the algorithm for many iterations, averages the results,
    and produces plots. For example
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实现这个算法并探索它的平均效果。然后查看*count.py*，该程序运行算法进行多次迭代，计算结果的平均值并生成图表。例如
- en: '[PRE24]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: estimates slightly more than 1 billion marbles in the bag. The correct number
    is exactly 1 billion. It uses 40 iterations of the algorithm for a total of 1.7
    million marbles marked. [Figure 11-6](ch011.xhtml#ch011fig06) is the resulting
    plot, *count_plot.png*, which shows each of the 40 estimates, the true value (solid
    line), and overall estimate (dashed).
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 估算袋中略多于10亿颗弹珠。正确的数量恰好是10亿。它使用了40次算法迭代，总共标记了170万个弹珠。[图11-6](ch011.xhtml#ch011fig06)是结果图，*count_plot.png*，显示了40次估算的结果、真实值（实线）和总体估算（虚线）。
- en: '![Image](../images/11fig06.jpg)'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![Image](../images/11fig06.jpg)'
- en: '*Figure 11-6: Forty estimates of marbles*'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*图11-6：40次弹珠估算*'
- en: Please contact me if you know a reference for this algorithm or how to derive
    the estimate formula.
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你知道这个算法的参考文献或如何推导估算公式，请与我联系。
- en: Can you think of a “fudge factor” for the Lincoln-Petersen population estimate
    for the case where the population is believed to be small?
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能想到一种“修正因子”来调整林肯-彼得森人口估算方法吗，尤其是在认为总体较小时的情况？
- en: How does the runtime performance of nonrandom Quicksort vary as the array becomes
    more disordered? To figure this out, fix the array size (*n*) but change the degree
    of disorder in the array. For example, begin with a sorted array, then swap two
    elements, then three, and so on. Is the transition from ![Image](../images/c0301-01.jpg)(*n*²)
    to ![Image](../images/c0301-01.jpg)(*n* log *n*) linear with the number of elements
    swapped? Or does it seem more rapid?
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非随机快速排序的运行时性能如何随数组的无序程度增加而变化？为了弄清楚这一点，固定数组大小（*n*），但改变数组的无序程度。例如，先从一个已排序的数组开始，然后交换两个元素，再交换三个，依此类推。从![Image](../images/c0301-01.jpg)(*n*²)到![Image](../images/c0301-01.jpg)(*n*
    log *n*)的过渡，随着交换元素的数量增加，是否呈现线性变化？还是说它看起来更为快速？
- en: '### **Summary**'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '### **总结**'
- en: In this chapter, we explored randomized algorithms, differentiating between
    Las Vegas and Monte Carlo. The former always produced correct output, eventually,
    while the latter may produce incorrect output. We considered permutation sort
    and Freivalds’ algorithm for testing matrix multiplication. We learned that we
    can turn permutation sort from a Las Vegas algorithm into a Monte Carlo algorithm
    by imposing a limit on the number of candidate permutations considered. In general,
    we can transform Las Vegas algorithms into Monte Carlo algorithms, but not vice
    versa.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们探讨了随机化算法，区分了拉斯维加斯算法和蒙特卡洛算法。前者最终总是能产生正确的输出，而后者可能会产生不正确的输出。我们考虑了排列排序和弗雷瓦尔兹算法来测试矩阵乘法。我们了解到，通过对考虑的候选排列数量施加限制，我们可以将排列排序从拉斯维加斯算法转变为蒙特卡洛算法。一般来说，我们可以将拉斯维加斯算法转化为蒙特卡洛算法，但反之则不可。
- en: We then discussed the mark and recapture algorithm that ecologists use to estimate
    animal populations. We estimate the number of animals in a population by marking
    a known number and then recapturing animals and looking at the number marked.
    With sufficient numbers, the ratio of marked animals to animals recaptured should
    match the ratio of animals originally marked to the population size. We explored
    three estimators associated with this process and saw how they behave.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们讨论了生态学家用来估计动物种群的标记和重捕算法。我们通过标记已知数量的动物，然后重捕动物并观察标记的数量来估计种群中动物的数量。通过足够的数量，标记动物与重捕动物的比例应该与最初标记的动物与种群总数的比例相匹配。我们探索了与这一过程相关的三种估算器，并观察了它们的表现。
- en: The Miller-Rabin algorithm quickly decides whether a positive integer is a prime.
    However, as a randomized algorithm, there’s a certain probability that it’ll falsely
    claim a composite number is prime. We learned how to decrease the likelihood of
    a false positive by repeated applications.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 米勒-拉宾算法能够快速判断一个正整数是否是质数。然而，作为一种随机化算法，它有一定的概率错误地将合数判定为质数。我们学习了通过反复应用该算法来减少假阳性的可能性。
- en: We concluded the chapter by comparing nonrandom and randomized Quicksort implementations.
    Randomized Quicksort adds little to the runtime while protecting against pathological
    inputs that are already (or mostly) sorted.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过比较非随机和随机化快速排序的实现来结束这一章。随机化快速排序对运行时间几乎没有影响，同时能够防止已经（或大部分）排序的病态输入。
- en: In our final chapter, we’ll consider randomness as it relates to sampling from
    probability distributions.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的最后一章，我们将考虑随机性与从概率分布中抽样的关系。
