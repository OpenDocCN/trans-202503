- en: '**12**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**12**'
- en: '**ARITHMETIC AND LOGICAL EXPRESSIONS**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**算术与逻辑表达式**'
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common01.jpg)'
- en: 'One of the major advantages that high-level languages provide over low-level
    languages is the use of algebraic arithmetic and logical expressions (hereafter,
    “arithmetic expressions”). HLL arithmetic expressions are an order of magnitude
    more readable than the sequence of machine instructions the compiler produces.
    However, the conversion process from arithmetic expressions into machine code
    is also one of the more difficult transformations to do efficiently, and a fair
    percentage of a typical compiler’s optimization phase is dedicated to handling
    it. Because of the difficulty with translation, this is one area where you can
    help the compiler. This chapter will describe:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 高级语言相较于低级语言的一个主要优势是使用代数算术和逻辑表达式（以下简称“算术表达式”）。高级语言的算术表达式在可读性上比编译器生成的机器指令序列高一个数量级。然而，将算术表达式转换为机器代码的过程也是最难以高效完成的转换之一，典型编译器的优化阶段有相当一部分时间用于处理这一过程。由于翻译的难度，这是你可以帮助编译器的一个领域。本章将描述：
- en: How computer architecture affects the computation of arithmetic expressions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机架构如何影响算术表达式的计算
- en: The optimization of arithmetic expressions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算术表达式的优化
- en: Side effects of arithmetic expressions
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算术表达式的副作用
- en: Sequence points in arithmetic expressions
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算术表达式中的序列点
- en: Order of evaluation in arithmetic expressions
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算术表达式中的求值顺序
- en: Short-circuit and complete evaluation of arithmetic expressions
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算术表达式的短路与完全求值
- en: The computational cost of arithmetic expressions
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算术表达式的计算成本
- en: Armed with this information, you’ll be able to write more efficient and more
    robust applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些信息，你将能够编写更高效、更强大的应用程序。
- en: '**12.1 Arithmetic Expressions and Computer Architecture**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.1 算术表达式与计算机架构**'
- en: 'With respect to arithmetic expressions, we can classify traditional computer
    architectures into three basic types: stack-based machines, register-based machines,
    and accumulator-based machines. The major difference between these architectural
    types has to do with where the CPUs keep the operands for the arithmetic operations.
    Once the CPU fetches the data from these operands, the data is passed along to
    the arithmetic and logical unit, where the actual arithmetic or logical calculation
    occurs.^([1](footnotes.xhtml#ch12fn1)) We’ll explore each of these architectures
    in the following sections.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 就算术表达式而言，我们可以将传统的计算机架构分为三种基本类型：基于栈的机器、基于寄存器的机器和基于累加器的机器。这些架构类型之间的主要区别在于CPU将算术操作的操作数存放在哪里。一旦CPU从这些操作数中获取数据，数据将传递给算术和逻辑单元，实际的算术或逻辑计算将在这里发生。^([1](footnotes.xhtml#ch12fn1))我们将在接下来的章节中探讨这些架构。
- en: '**12.1.1 Stack-Based Machines**'
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.1.1 基于栈的机器**'
- en: 'Stack-based machines use memory for most calculations, employing a data structure
    called the *stack* in memory to hold all operands and results. Computer systems
    with a stack architecture offer some important advantages over other architectures:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于栈的机器在大多数计算中使用内存，采用一种名为*栈*的数据结构来存储所有操作数和结果。具有栈架构的计算机系统在某些方面相较于其他架构有一些重要的优势：
- en: The instructions are often smaller in stack architectures because the instructions
    generally don’t have to specify any operands.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在栈架构中，指令通常较小，因为这些指令通常不需要指定任何操作数。
- en: It is usually easier to write compilers for stack architectures than for other
    machines because converting arithmetic expressions to a sequence of stack operations
    is very easy.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写栈架构的编译器通常比编写其他机器的编译器更容易，因为将算术表达式转换为一系列栈操作非常简单。
- en: Temporary variables are rarely needed in a stack architecture, because the stack
    itself serves that purpose.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在栈架构中，临时变量很少需要，因为栈本身就可以完成这个任务。
- en: 'Unfortunately, stack machines also suffer from some serious disadvantages:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，栈机器也有一些严重的缺点：
- en: Almost every instruction references memory (which is slow on modern machines).
    Though caches can help mitigate this problem, memory performance is still a major
    problem on stack machines.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几乎每条指令都引用内存（在现代机器上内存较慢）。尽管缓存可以帮助缓解这个问题，但内存性能仍然是栈机器上的一个主要问题。
- en: Even though conversion from HLLs to a stack machine is very easy, there’s less
    opportunity for optimization than there is with other architectures.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管从高级语言转换到栈机器非常容易，但与其他架构相比，优化的机会较少。
- en: Because stack machines are constantly accessing the same data elements (that
    is, data on the *top of the stack*), pipelining and instruction parallelism is
    difficult to achieve.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于栈机器不断访问相同的数据元素（即栈顶的数据），因此实现流水线和指令并行性是困难的。
- en: '**NOTE**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*See* WGC1 *for details on pipelining and instruction parallelism.*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*参见* WGC1 *了解流水线和指令并行性的详细信息。*'
- en: 'With a stack you generally do one of three things: push new data onto it, pop
    data from it, or operate on the data that is currently sitting on the *top of
    stack* (and possibly the data immediately below that, or *next on stack*).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用栈时，通常会执行以下三种操作之一：将新数据压入栈、从栈中弹出数据，或操作当前位于*栈顶*的数据（并可能操作栈顶下方的数据，或*栈中的下一个数据*）。
- en: '**12.1.1.1 Basic Stack Machine Organization**'
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**12.1.1.1 基本栈机器组织**'
- en: A typical stack machine maintains a couple of registers inside the CPU (see
    [Figure 12-1](ch12.xhtml#ch12fig1)). In particular, you can expect to find a *program
    counter register* (like the 80x86’s RIP register) and a *stack pointer register*
    (like the 80x86 RSP register).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的栈机器在CPU内部维护几个寄存器（见[图 12-1](ch12.xhtml#ch12fig1)）。特别地，你可以找到一个*程序计数器寄存器*（如80x86的RIP寄存器）和一个*栈指针寄存器*（如80x86的RSP寄存器）。
- en: '![Image](../images/12fig01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/12fig01.jpg)'
- en: '*Figure 12-1: Typical stack machine architecture*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-1：典型的栈机器架构*'
- en: The stack pointer register contains the memory address of the current top of
    stack (TOS) element in memory. The CPU increments or decrements the stack pointer
    register whenever a program places data onto the stack or removes data from the
    stack. On some architectures the stack expands from higher memory locations to
    lower memory locations; on other architectures, the stack grows from lower memory
    locations toward higher memory locations. Fundamentally, the direction of stack
    growth is irrelevant; all it really determines is whether the machine decrements
    the stack pointer register when placing data on the stack (if the stack grows
    toward lower memory addresses) or increments the stack pointer register (when
    the stack grows toward higher memory addresses).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 栈指针寄存器包含当前栈顶元素（TOS）在内存中的地址。每当程序将数据压入栈中或从栈中移除数据时，CPU都会递增或递减栈指针寄存器。在某些架构中，栈从高地址向低地址扩展；在其他架构中，栈从低地址向高地址增长。从根本上讲，栈增长的方向并不重要；它真正决定的是，机器在将数据压入栈时是递减栈指针寄存器（如果栈向低地址增长）还是递增栈指针寄存器（如果栈向高地址增长）。
- en: '**12.1.1.2 The push Instruction**'
  id: totrans-31
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**12.1.1.2 push 指令**'
- en: 'To place data on the stack, you typically use the machine instruction `push`.
    This instruction generally takes a single operand that specifies the value to
    push onto the stack, like so:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要将数据压入栈中，通常使用机器指令`push`。该指令通常包含一个操作数，用于指定要压入栈的数据值，例如：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here are a couple of concrete examples:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个具体的例子：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: A `push` operation typically increases the value of the stack pointer register
    by the size of its operand in bytes and then copies that operand to the memory
    location the stack pointer now specifies. For example, [Figures 12-2](ch12.xhtml#ch12fig2)
    and [12-3](ch12.xhtml#ch12fig3) illustrate what the stack looks like before and
    after a `push 10` operation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`push`操作通常会将栈指针寄存器的值增加操作数大小的字节数，然后将该操作数复制到栈指针现在指定的内存位置。例如，[图 12-2](ch12.xhtml#ch12fig2)和[图
    12-3](ch12.xhtml#ch12fig3)展示了`push 10`操作前后的栈情况。'
- en: '![Image](../images/12fig02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/12fig02.jpg)'
- en: '*Figure 12-2: Before a push 10 operation*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-2：执行push 10操作前*'
- en: '![Image](../images/12fig03.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/12fig03.jpg)'
- en: '*Figure 12-3: After a push 10 operation*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-3：执行push 10操作后*'
- en: '**12.1.1.3 The pop Instruction**'
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**12.1.1.3 pop 指令**'
- en: 'To remove a data item from the top of a stack, you use a `pop` or `pull` instruction.
    (This book will use `pop`; just be aware that some architectures use `pull` instead.)
    A typical `pop` instruction might look as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要从栈顶移除数据项，使用`pop`或`pull`指令。（本书将使用`pop`；不过请注意，有些架构使用`pull`代替。）典型的`pop`指令可能如下所示：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**NOTE**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*You cannot pop data into a constant. The *pop* operand must be a memory location.*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*你不能将数据弹出到常量中。*pop*操作数必须是一个内存位置。*'
- en: The `pop` instruction makes a copy of the data pointed at by the stack pointer
    and stores it into the destination memory location. Then it decrements (or increments)
    the stack pointer register to point at the next lower item on the stack, or next
    on stack (NOS); see [Figures 12-4](ch12.xhtml#ch12fig4) and [12-5](ch12.xhtml#ch12fig5).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`pop` 指令将堆栈指针指向的数据复制并存储到目标内存位置。然后，它递减（或递增）堆栈指针寄存器，以指向堆栈上的下一个较低项或下一个堆栈项（NOS）；见
    [图 12-4](ch12.xhtml#ch12fig4) 和 [12-5](ch12.xhtml#ch12fig5)。'
- en: '![Image](../images/12fig04.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/12fig04.jpg)'
- en: '*Figure 12-4: Before a pop mem operation*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-4：执行 pop mem 操作之前*'
- en: '![Image](../images/12fig05.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/12fig05.jpg)'
- en: '*Figure 12-5: After a pop mem operation*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-5：执行 pop mem 操作之后*'
- en: Note that the value in stack memory that the `pop` instruction removes from
    the stack is still physically present in memory above the new TOS. However, the
    next time the program pushes data onto the stack, it will overwrite this value
    with the new value.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`pop` 指令从堆栈中移除的堆栈内存中的值仍然物理存在于新 TOS 上方的内存中。然而，下次程序将数据推送到堆栈时，它会用新值覆盖此值。
- en: '**12.1.1.4 Arithmetic Operations on a Stack Machine**'
  id: totrans-52
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**12.1.1.4 堆栈机器上的算术操作**'
- en: The arithmetic and logical instructions found on a stack machine generally do
    not allow any operands. This is why stack machines are often called *zero-address
    machines*; the arithmetic instructions themselves do not encode any operand addresses.
    For example, consider an `add` instruction on a typical stack machine. This instruction
    will pop two values from the stack (TOS and NOS), compute their sum, and push
    the result back onto the stack (see [Figures 12-6](ch12.xhtml#ch12fig6) and [12-7](ch12.xhtml#ch12fig7)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 堆栈机器上的算术和逻辑指令通常不允许任何操作数。这就是为什么堆栈机器通常被称为 *零地址机器*；算术指令本身并不编码任何操作数地址。例如，考虑一个典型堆栈机器上的
    `add` 指令。此指令将从堆栈中弹出两个值（TOS 和 NOS），计算它们的和，并将结果推送回堆栈（见 [图 12-6](ch12.xhtml#ch12fig6)
    和 [12-7](ch12.xhtml#ch12fig7)）。
- en: '![Image](../images/12fig06.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/12fig06.jpg)'
- en: '*Figure 12-6: Before an add operation*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-6：执行加法操作之前*'
- en: '![Image](../images/12fig07.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/12fig07.jpg)'
- en: '*Figure 12-7: After an add operation*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 12-7：执行加法操作之后*'
- en: Because arithmetic expressions are recursive in nature, and recursion requires
    a stack for proper implementation, it’s no surprise that converting arithmetic
    expressions to a sequence of stack machine instructions is relatively simple.
    Arithmetic expressions found in common programming languages use an *infix notation*,
    where the operator appears between two operands. For example, `a + b` and `c -
    d` are examples of infix notation because the operators (`+` and `-`) appear between
    the operands ([`a`, `b`] and [`c`, `d`]). Before you can do the conversion to
    stack machine instructions, you must convert these infix expressions into *postfix
    notation* (also known as *reverse polish notation*), where the operator immediately
    follows the operands to which it applies. For example, the infix expressions `a
    + b` and `c – d` would have the corresponding postfix forms `a b +` and `c d –`,
    respectively.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于算术表达式本质上是递归的，而递归需要堆栈才能正确实现，因此将算术表达式转换为堆栈机器指令序列相对简单也不足为奇。常见编程语言中的算术表达式使用 *中缀表示法*，即操作符位于两个操作数之间。例如，`a
    + b` 和 `c - d` 是中缀表示法的例子，因为操作符（`+` 和 `-`）出现在操作数（[`a`, `b`] 和 [`c`, `d`]）之间。在你能够进行堆栈机器指令的转换之前，你必须将这些中缀表达式转换为
    *后缀表示法*（也称为 *逆波兰表示法*），在后缀表示法中，操作符紧随其后作用的操作数。例如，中缀表达式 `a + b` 和 `c - d` 对应的后缀表达式分别为
    `a b +` 和 `c d -`。
- en: 'Once you have an expression in postfix form, converting it to a sequence of
    stack machine instructions is very easy. You simply emit a `push` instruction
    for each operand and the corresponding arithmetic instruction for the operators.
    For example, `a b +` becomes:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你拥有一个后缀表达式，将其转换为堆栈机器指令序列非常简单。你只需为每个操作数发出一个 `push` 指令，并为操作符发出相应的算术指令。例如，`a
    b +` 转换为：
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'and `c d -` becomes:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`c d -` 转换为：'
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: assuming, of course, that `add` adds the top two items on the stack and `sub`
    subtracts the TOS from the value immediately below it on the stack.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，假设 `add` 操作将堆栈顶部的两个项相加，`sub` 操作将 TOS 与其下方的值相减。
- en: '**12.1.1.5 Real-World Stack Machines**'
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**12.1.1.5 现实世界中的堆栈机器**'
- en: A big advantage of the stack architecture is that it’s easy to write a compiler
    for such a machine. It’s also very easy to write an emulator for a stack-based
    machine. For these reasons, stack architectures are popular in *virtual machines
    (VMs)* such as the Java Virtual Machine, the UCSD Pascal p-machine, and the Microsoft
    Visual Basic, C#, and F# CIL. Although a few real-world stack-based CPUs do exist,
    such as a hardware implementation of the Java VM, they’re not very popular because
    of the performance limitations of memory access. Nonetheless, understanding the
    basics of a stack architecture is important, because many compilers translate
    HLL source code into a stack-based form prior to emitting actual machine code.
    Indeed, in the worst (though rare) case, compilers are forced to emit code that
    emulates a stack-based machine when compiling complex arithmetic expressions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 栈架构的一个巨大优势是，它很容易为这种机器编写编译器。为基于栈的机器编写仿真器也非常简单。正因为如此，栈架构在*虚拟机 (VM)* 中非常流行，例如 Java
    虚拟机、UCSD Pascal p-machine，以及微软的 Visual Basic、C# 和 F# CIL。尽管确实存在一些现实世界中的基于栈的 CPU，例如
    Java VM 的硬件实现，但由于内存访问的性能限制，它们并不太受欢迎。尽管如此，理解栈架构的基本原理仍然很重要，因为许多编译器会在生成实际机器代码之前将高级语言源代码转换为基于栈的形式。事实上，在最糟糕的情况下（尽管这种情况很少见），编译器在编译复杂的算术表达式时被迫生成模拟基于栈的机器的代码。
- en: '**12.1.2 Accumulator-Based Machines**'
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.1.2 基于累加器的机器**'
- en: 'The simplicity of a stack machine instruction sequence hides an enormous amount
    of complexity. Consider the following stack-based instruction from the previous
    section:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 栈机器指令序列的简单性掩盖了巨大的复杂性。考虑上一节中的以下基于栈的指令：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This instruction looks simple, but it actually specifies a large number of
    operations:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指令看起来很简单，但实际上它指定了大量的操作：
- en: Fetch an operand from the memory location pointed to by the stack pointer.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从栈指针指向的内存位置获取一个操作数。
- en: Send the stack pointer’s value to the *ALU (arithmetic/logical unit)*.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将栈指针的值发送到*ALU (算术/逻辑单元)*。
- en: Instruct the ALU to decrement the stack pointer’s value just sent to it.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 ALU 减少刚刚发送给它的栈指针的值。
- en: Route the ALU’s value back to the stack pointer.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 ALU 的值路由回栈指针。
- en: Fetch the operand from the memory location pointed to by the stack pointer.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从栈指针指向的内存位置获取操作数。
- en: Send the values from the previous step and the first step to the ALU.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将上一步和第一步的值发送到 ALU。
- en: Instruct the ALU to add those values.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 ALU 对这些值进行加法运算。
- en: Store the sum away in the memory location pointed to by the stack pointer.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将和存储在栈指针指向的内存位置。
- en: 'The organization of a typical stack machine prevents many parallel operations
    that are possible with pipelining (see *WGC1* for more details on pipelining).
    So stack architectures are hit twice: typical instructions require many steps
    to complete, and those steps are difficult to execute in parallel with other operations.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型栈机器的组织方式会阻止许多通过流水线实现的并行操作（有关流水线的更多细节，请参见*WGC1*）。因此，栈架构面临两次挑战：典型的指令需要多个步骤才能完成，而且这些步骤很难与其他操作并行执行。
- en: One big problem with the stack architecture is that it goes to memory for just
    about everything. For example, if you simply want to compute the sum of two variables
    and store this result in a third variable, you have to fetch the two variables
    and write them to the stack (four memory operations); then you have to fetch the
    two values from the stack, add them, and write their sum back to the stack (three
    memory operations); and finally, you have to pop the item from the stack and store
    the result into the destination memory location (two memory operations). That’s
    a total of nine memory operations. When memory access is slow, this is an expensive
    way to compute the sum of two numbers.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 栈架构的一个大问题是它几乎所有的操作都需要访问内存。例如，如果你只是想计算两个变量的和并将结果存储到第三个变量，你必须先从内存中取出两个变量并将它们写入栈中（四次内存操作）；然后你必须从栈中取出这两个值，进行加法运算，并将它们的和写回栈中（三次内存操作）；最后，你必须从栈中弹出该项，并将结果存储到目标内存位置（两次内存操作）。总共是九次内存操作。当内存访问速度较慢时，这是一种计算两个数字和的高成本方式。
- en: 'One way to avoid this large number of memory accesses is to provide a general-purpose
    arithmetic register within the CPU. This is the idea behind an accumulator-based
    machine: you provide a single *accumulator* register, where the CPU computes temporary
    results rather than computing temporary values in memory (on the stack). Accumulator-based
    machines are also known as *one-address* or *single-address machines*, because
    most instructions that operate on two operands use the accumulator as the default
    destination operand for the computation and require a single memory or constant
    operand to use as the source operand. A typical example of an accumulator machine
    is the 6502, which includes the following instructions:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 避免大量内存访问的一种方法是提供一个通用算术寄存器。累加器机器的理念就是提供一个单一的*累加器*寄存器，CPU在此寄存器中计算临时结果，而不是在内存（栈上）中计算临时值。累加器机器也被称为*单地址*或*单一地址机器*，因为大多数操作两个操作数的指令都将累加器作为默认的目标操作数，并且需要一个内存或常数操作数作为源操作数。累加器机器的典型例子是6502，它包含以下指令：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Because one-address instructions require an operand that isn’t present in many
    of the zero-address instructions, individual instructions found on an accumulator-based
    machine tend to be larger than those found on a typical stack-based machine (because
    you have to encode the operand address as part of the instruction; see *WGC1*
    for details). However, programs are often smaller because fewer instructions are
    needed to do the same thing. Suppose, for example, you want to compute `x = y
    + z`. On a stack machine, you might use an instruction sequence like the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 由于单地址指令需要一个在许多零地址指令中不存在的操作数，因此，累加器机器上的单个指令通常比典型的栈机器上的指令更大（因为你必须将操作数地址作为指令的一部分进行编码；详情见*WGC1*）。然而，程序通常更小，因为完成相同操作所需的指令更少。例如，假设你要计算`x
    = y + z`。在栈机器上，你可能会使用如下的指令序列：
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'On an accumulator machine, you’d probably use a sequence like this:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在累加器机器上，你可能会使用如下的指令序列：
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Assuming that the `push` and `pop` instructions are roughly the same size as
    the accumulator machine’s `lda`, `add`, and `sta` instructions (a safe assumption),
    it’s clear that the stack machine’s instruction sequence is actually longer, because
    it requires more instructions. Even ignoring the extra instruction on the stack
    machine, the accumulator machine will probably execute the code faster, because
    it requires only three memory accesses (to fetch `y` and `z` and to store `x`),
    compared with the nine memory accesses the stack machine will require. Furthermore,
    the accumulator machine doesn’t waste any time manipulating the stack pointer
    register during computation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 假设`push`和`pop`指令的大小大致与累加器机器的`lda`、`add`和`sta`指令相同（这是一个安全的假设），可以明确看到栈机器的指令序列实际上更长，因为它需要更多的指令。即便忽略栈机器中的额外指令，累加器机器也可能执行代码更快，因为它只需要三次内存访问（用于获取`y`和`z`，以及存储`x`），相比之下栈机器需要九次内存访问。此外，累加器机器在计算过程中不会浪费时间操作栈指针寄存器。
- en: Even though accumulator-based machines generally have higher performance than
    stack-based machines (for reasons you’ve just seen), they’re not without their
    own problems. Having only one general-purpose register available for arithmetic
    operations creates a bottleneck in the system, resulting in *data hazards*. Many
    calculations produce temporary results that the application must write to memory
    in order to compute other components of the expression. This leads to extra memory
    accesses that could be avoided if the CPU provided additional accumulator registers.
    Thus, most modern general-purpose CPUs do not use an accumulator-based architecture,
    but instead provide a large number of general-purpose registers.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于累加器的机器通常比基于栈的机器具有更高的性能（正如你刚才所看到的原因），但它们也并非没有问题。由于仅有一个通用寄存器可用于算术操作，这在系统中形成了瓶颈，导致了*数据冒险*。许多计算会产生临时结果，应用程序必须将这些结果写入内存，以便计算表达式的其他部分。这导致了额外的内存访问，如果CPU提供额外的累加器寄存器，这些访问本可以避免。因此，大多数现代通用CPU不使用基于累加器的架构，而是提供大量的通用寄存器。
- en: '**NOTE**'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*See* WGC1 *for a discussion of data hazards.*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*参见* WGC1 *讨论数据冒险问题。*'
- en: Accumulator-based architectures were popular in early computer systems when
    the manufacturing process limited the number of features within the CPU, but today
    you rarely see them outside of low-cost embedded microcontrollers.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 基于累加器的架构在早期计算机系统中非常流行，当时制造工艺限制了 CPU 内的功能数量，但今天除了低成本嵌入式微控制器外，几乎看不到它们。
- en: '**12.1.3 Register-Based Machines**'
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.1.3 基于寄存器的机器**'
- en: Of the three architectures discussed in this chapter, register-based machines
    are the most prevalent today because they offer the highest performance. By providing
    a fair number of on-CPU registers, this architecture spares the CPU from expensive
    memory accesses during the computation of complex expressions.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章讨论的三种架构中，基于寄存器的机器是目前最常见的，因为它们提供了最高的性能。通过提供相当数量的 CPU 内寄存器，这种架构在计算复杂表达式时能够避免
    CPU 进行昂贵的内存访问。
- en: In theory, a register-based machine could have as few as two general-purpose
    (arithmetic-capable) registers. In practice, about the only machines that fall
    into this category are the Motorola 680x processors, which most people consider
    to be a special case of the accumulator architecture with two separate accumulators.
    Register machines generally contain at least eight “general-purpose” registers
    (this number isn’t arbitrary; it’s the number of general-purpose registers found
    on the 80x86 CPU, the 8080 CPU, and the Z80 CPU, which are probably the minimalist
    examples of what a computer architect would call a “register-based” machine).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，一个基于寄存器的机器可以只有两个通用（算术能力）寄存器。在实践中，唯一符合这一类别的机器是摩托罗拉 680x 处理器，大多数人认为它是带有两个独立累加器的累加器架构的一个特例。寄存器机器通常至少包含八个“通用”寄存器（这个数字并非随意的；它是80x86
    CPU、8080 CPU 和 Z80 CPU 中发现的通用寄存器数量，这些可能是计算机架构师所称的“基于寄存器”的机器的最简化示例）。
- en: Although some register-based machines (such as the 32-bit 80x86) have a small
    number of registers available, a general principle is “the more, the better.”
    Typical RISC machines, such as the PowerPC and ARM, have at least 16 general-purpose
    registers and often at least 32 registers. Intel’s Itanium processor, for example,
    provides 128 general-purpose integer registers. IBM’s CELL processor provides
    128 registers in each of the processing units found on the device (each processing
    unit is a mini-CPU capable of certain operations); a typical CELL processor contains
    eight such processing units along with a PowerPC CPU core.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些基于寄存器的机器（如 32 位的 80x86）有较少的可用寄存器，但一个普遍的原则是“越多越好”。典型的 RISC 机器，如 PowerPC 和
    ARM，至少有 16 个通用寄存器，并且通常至少有 32 个寄存器。例如，英特尔的 Itanium 处理器提供 128 个通用整数寄存器。IBM 的 CELL
    处理器在每个处理单元中提供 128 个寄存器（每个处理单元是一个能够执行特定操作的微型 CPU）；典型的 CELL 处理器包含八个这样的处理单元，并且配有一个
    PowerPC CPU 核心。
- en: 'The main reason for having as many general-purpose registers as possible is
    to avoid memory access. In an accumulator-based machine, the accumulator is a
    transient register used for calculations, but you can’t keep a variable’s value
    there for long periods of time, because you’ll need the accumulator for other
    purposes. In a register machine with a large number of registers, it’s possible
    to keep certain (often-used) variables in registers so you don’t have to access
    memory at all when using those variables. Consider the assignment statement `x
    := y+z`;. On a register-based machine (such as the 80x86), we could compute this
    result using the following HLA code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有尽可能多的通用寄存器的主要原因是为了避免内存访问。在基于累加器的机器中，累加器是一个用于计算的瞬态寄存器，但你不能将一个变量的值长时间保存在那里，因为你还需要使用累加器执行其他任务。在一个具有大量寄存器的寄存器机器中，可以将某些（经常使用的）变量保存在寄存器中，这样在使用这些变量时就不必进行内存访问。考虑赋值语句
    `x := y+z`；在一个基于寄存器的机器（如 80x86）上，我们可以使用以下 HLA 代码来计算这个结果：
- en: '[PRE9]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Only two instructions and no memory accesses (for the variables) are required
    here. This is quite a bit more efficient than the accumulator- or stack-based
    architectures. From this example, you can see why the register-based architecture
    has become prevalent in modern computer systems.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这里只需要两条指令，并且不需要进行内存访问（对于变量）。这比基于累加器或堆栈的架构效率要高得多。从这个例子中，您可以看到为什么基于寄存器的架构在现代计算机系统中变得如此普遍。
- en: As you’ll see in the following sections, register machines are often described
    as either two-address machines or three-address machines, depending on the particular
    CPU’s architecture.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您将在接下来的章节中看到的那样，寄存器机器通常被描述为两地址机器或三地址机器，具体取决于特定 CPU 的架构。
- en: '**12.1.4 Typical Forms of Arithmetic Expressions**'
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.1.4 算术表达式的典型形式**'
- en: 'Computer architects have studied typical source files extensively, and one
    thing they’ve discovered is that a large percentage of assignment statements take
    one of the following forms:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机架构师已经深入研究了典型的源文件，他们发现的一个事实是，大部分赋值语句采用以下几种形式之一：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Although other assignments do exist, the set of statements in a program that
    takes one of these forms is generally larger than any other group of assignment
    statements. Therefore, computer architects usually optimize their CPUs to efficiently
    handle these forms.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管其他类型的赋值语句也存在，但程序中采用这些形式的语句通常比其他任何赋值语句形式都要多。因此，计算机架构师通常会优化他们的CPU，以高效地处理这些形式。
- en: '**12.1.5 Three-Address Architectures**'
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.1.5 三地址架构**'
- en: 'Many machines use a *three-address architecture*. This means that an arithmetic
    statement supports three operands: two source operands and a destination operand.
    For example, most RISC CPUs offer an `add` instruction that will add together
    the values of two operands and store the result into a third operand:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器使用*三地址架构*。这意味着一个算术语句支持三个操作数：两个源操作数和一个目标操作数。例如，大多数RISC CPU提供`add`指令，将两个操作数的值相加并将结果存储到第三个操作数中：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'On such architectures, the operands are usually machine registers (or small
    constants), so typically you’d write this instruction as follows (assuming you
    use the names *R*0, *R*1, . . . , *Rn* to denote registers):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种架构中，操作数通常是机器寄存器（或小常数），所以通常你会按如下方式编写此指令（假设你使用*R*0、*R*1、……、*Rn*来表示寄存器）：
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Because RISC compilers attempt to keep variables in registers, this single
    instruction handles the last assignment statement given in the previous section:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于RISC编译器尝试将变量保存在寄存器中，因此这条单指令处理了上一节中给出的最后一个赋值语句：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Handling an assignment of the form:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 处理如下形式的赋值：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'is also relatively easy—just use the destination register as one of the source
    operands, like so:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 也相对简单——只需将目标寄存器作为其中一个源操作数，如下所示：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The drawback to a three-address architecture is that you must encode all three
    operands into each instruction that supports three operands. This is why three-operand
    instructions generally operate only upon register operands. Encoding three separate
    memory addresses can be quite expensive—just ask any VAX programmer. The DEC VAX
    computer system is a good example of a three-address CISC machine.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 三地址架构的缺点是，你必须将所有三个操作数编码到每个支持三个操作数的指令中。这就是为什么三操作数指令通常只对寄存器操作数进行操作的原因。编码三个单独的内存地址可能相当昂贵——问问任何VAX程序员就知道了。DEC
    VAX计算机系统是一个很好的三地址CISC机器示例。
- en: '**12.1.6 Two-Address Architectures**'
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.1.6 二地址架构**'
- en: 'The 80x86 architecture is known as a *two-address machine*. In this architecture,
    one of the source operands is also the destination operand. Consider the following
    80x86/HLA `add` instruction:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 80x86架构被称为*二地址机器*。在这种架构中，一个源操作数也是目标操作数。考虑以下80x86/HLA `add`指令：
- en: '[PRE16]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Two-address machines, such as the 80x86, can handle the first four forms of
    the assignment statement given earlier with a single instruction. The last form,
    however, requires two or more instructions and a temporary register. For example,
    to compute:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 二地址机器，如80x86，可以用单个指令处理前面给出的赋值语句的前四种形式。然而，最后一种形式需要两个或更多指令和一个临时寄存器。例如，要计算：
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'you’d need to use the following code (assuming *var2* and *var3* are memory
    variables and the compiler is keeping *var1* in the EAX register):'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要使用以下代码（假设*var2*和*var3*是内存变量，且编译器将*var1*保存在EAX寄存器中）：
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**12.1.7 Architectural Differences and Your Code**'
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.1.7 架构差异与你的代码**'
- en: 'One-address, two-address, and three-address architectures have the following
    hierarchy:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一地址、二地址和三地址架构具有以下层次结构：
- en: '**1Address** ⊂ **2Address** ⊂ **3Address**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**1地址** ⊂ **2地址** ⊂ **3地址**'
- en: That is, two-address machines are capable of doing anything a one-address machine
    can do, and three-address machines are capable of anything one-address or two-address
    machines can do. The proof is very simple:^([2](footnotes.xhtml#ch12fn2))
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，二地址机器能够做任何一地址机器能做的事情，而三地址机器能够做任何一地址或二地址机器能做的事情。证明非常简单：^([2](footnotes.xhtml#ch12fn2))
- en: To show that a two-address machine is capable of doing anything a one-address
    machine can do, simply choose one register on the two-address machine and use
    it as the “accumulator” when simulating a one-address architecture.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了证明二地址机器可以做任何单地址机器能做的事情，只需选择二地址机器上的一个寄存器，并在模拟单地址架构时将其用作“累加器”。
- en: To show that a three-address machine is capable of anything a two-address machine
    can do, simply use the same register for one of the source operands and the destination
    operand, thereby limiting yourself to two registers (operands/addresses) for all
    operations.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了证明三地址机器可以完成任何二地址机器能够做的事情，只需将同一个寄存器同时用作一个源操作数和目标操作数，从而使所有操作仅限于两个寄存器（操作数/地址）。
- en: Given this hierarchy, you might think that if you limit the code you write so
    that it runs well on a one-address machine, you’ll get good results on all machines.
    In reality, most general-purpose CPUs available today are two- or three-address
    machines, so writing your code to favor a one-address machine may limit the optimizations
    that are possible on a two- or three-address machine. Furthermore, optimization
    quality varies so widely among compilers that backing up an assertion like this
    would be very difficult. You should probably try to create expressions that take
    one of the five forms given earlier (in “Typical Forms of Arithmetic Expressions”
    on [page 394](ch12.xhtml#page_394)) if you want your compiler to produce the best
    possible code. Because most modern programs run on two- or three-address machines,
    the remainder of this chapter assumes that environment.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个层次结构，你可能会认为如果你限制编写的代码，使其在单地址机器上运行良好，那么它在所有机器上都会获得良好的结果。实际上，今天大多数通用CPU都是二地址或三地址机器，因此将代码写成偏向单地址机器可能会限制二地址或三地址机器上可能的优化。此外，优化质量在不同编译器之间差异如此之大，以至于很难为这样的说法提供支持。如果你希望编译器生成最佳的代码，最好还是尝试创建符合之前给出的五种形式的表达式（在《典型的算术表达式形式》部分的[第394页](ch12.xhtml#page_394)）。因为大多数现代程序都运行在二地址或三地址机器上，本章其余部分假设使用的是这种环境。
- en: '**12.1.8 Complex Expressions**'
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.1.8 复杂表达式**'
- en: 'Once your expressions get more complex than the five forms given earlier, the
    compiler will have to generate a sequence of two or more instructions to evaluate
    them. When compiling the code, most compilers internally translate a complex expression
    into a sequence of “three-address statements” that are semantically equivalent
    to it, as in the following example:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的表达式比之前给出的五种形式更复杂，编译器将必须生成两条或更多指令的序列来计算它们。在编译代码时，大多数编译器会将复杂的表达式内部转换为一系列与其语义等价的“三地址语句”，如以下示例所示：
- en: '[PRE19]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As you can see, these five statements are semantically equivalent to the complex
    expression appearing in the comment. The major difference in the computation is
    the introduction of two temporary values (`temp1` and `temp2`). Most compilers
    will attempt to use machine registers to maintain these temporary values.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这五条语句在语义上等同于注释中出现的复杂表达式。计算中的主要区别是引入了两个临时值（`temp1`和`temp2`）。大多数编译器会尝试使用机器寄存器来维护这些临时值。
- en: Because the compiler internally translates a complex instruction into a sequence
    of three-address statements, you may wonder if you can help it by converting complex
    expressions into three-address statements yourself. Well, it depends on your compiler.
    For many (good) compilers, breaking a complex calculation into smaller pieces
    may, in fact, thwart the compiler’s ability to optimize certain sequences. So,
    when it comes to arithmetic expressions, most of the time you should do your job
    (write the code as clearly as possible) and let the compiler do its job (optimize
    the result). However, if you can specify a calculation using a form that naturally
    converts to a two-address or three-address form, by all means do so. At the very
    least, it will have no effect on the code the compiler generates. At best, under
    some special circumstances, it could help the compiler produce better code. Either
    way, the resulting code will probably be easier to read and maintain if it is
    less complex.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 由于编译器内部将复杂指令转换为三地址语句的序列，你可能会想，是否可以通过自己将复杂的表达式转换为三地址语句来帮助编译器。嗯，这取决于你的编译器。对于许多（优秀的）编译器，将复杂的计算分解成更小的部分，实际上可能会妨碍编译器优化某些语句的能力。因此，在处理算术表达式时，大多数情况下你应该做好自己的工作（尽可能清晰地编写代码），让编译器做好它的工作（优化结果）。然而，如果你能使用一种自然转化为二地址或三地址形式的方式来指定计算，毫不犹豫地去做。至少，它对编译器生成的代码没有任何影响。在某些特殊情况下，它甚至可能帮助编译器生成更好的代码。不管怎样，结果代码可能会更易于阅读和维护，如果它不那么复杂的话。
- en: '**12.2 Optimization of Arithmetic Statements**'
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.2 算术语句的优化**'
- en: Because HLL compilers were originally designed to let programmers use algebraic-like
    expressions in their source code, this is one area in computer science that has
    been well researched. Most modern compilers that provide a reasonable optimizer
    do a decent job of translating arithmetic expressions into machine code. You can
    usually assume that the compiler you’re using doesn’t need a whole lot of help
    with optimizing arithmetic expressions (and if it does, you might consider switching
    to a better compiler instead of trying to manually optimize the code).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 因为高级语言编译器最初是为了让程序员在源代码中使用类似代数的表达式而设计的，所以这是计算机科学中一个已经得到充分研究的领域。大多数现代编译器都提供了合理的优化器，能够很好地将算术表达式转化为机器码。你通常可以假设你使用的编译器在优化算术表达式时不需要太多帮助（如果它确实需要，你可能考虑换一个更好的编译器，而不是尝试手动优化代码）。
- en: To help you appreciate the job the compiler is doing for you, this section discusses
    some of the typical optimizations you can expect from modern optimizing compilers.
    By understanding what a (decent) compiler does, you can avoid hand-optimizing
    those things that it is capable of handling.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助你理解编译器为你做的工作，本节讨论了一些你可以从现代优化编译器中预期的典型优化。通过了解一个（优秀的）编译器的工作，你可以避免手动优化那些它能够处理的部分。
- en: '**12.2.1 Constant Folding**'
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.1 常量折叠**'
- en: 'Constant folding is an optimization that computes the value of constant expressions
    or subexpressions at compile time rather than emitting code to compute their result
    at runtime. For example, a Pascal compiler that supports this optimization would
    translate a statement of the form `i := 5 + 6;` to `i := 11;` prior to generating
    machine code for the statement. This saves it from emitting an `add` instruction
    that would have to execute at runtime. As another example, suppose you want to
    allocate an array containing 16MB of storage. One way to do this is as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 常量折叠是一种优化技术，它在编译时计算常量表达式或子表达式的值，而不是在运行时生成代码来计算其结果。例如，支持这种优化的Pascal编译器会将类似`i
    := 5 + 6;`的语句在生成机器码之前转化为`i := 11;`。这样可以避免在运行时执行`add`指令。再举一个例子，假设你想分配一个包含16MB存储的数组。可以通过以下方式来实现：
- en: '[PRE20]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The only problem with this approach is that 16,777,216 is a magic number. It
    represents the value 2^(24) and not some other arbitrary value. Now consider the
    following C/C++ declaration:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法唯一的问题是16,777,216是一个魔法数字。它代表的是2^(24)的值，而不是其他任意值。现在考虑以下C/C++声明：
- en: '[PRE21]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Most programmers realize that 1,024 times 1,024 is a binary million, and 16
    times this value corresponds to 16 mega-somethings. Yes, you need to recognize
    that the subexpression `16*1024*1024` is equivalent to 16,777,216\. But this pattern
    is easier to recognize as 16MB (at least, when used within a character array)
    than `16777216` (or was it `16777214`?). In both cases the amount of storage the
    compiler allocates is exactly the same, but the second case is, arguably, more
    readable. Hence, it is better code.^([3](footnotes.xhtml#ch12fn3))
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数程序员知道 1,024 乘以 1,024 是二进制的百万，而这个值的 16 倍对应 16 兆什么的。是的，你需要知道子表达式 `16*1024*1024`
    等同于 16,777,216。但这个模式更容易被识别为 16MB（至少在字符数组中使用时），而不是 `16777216`（或者是 `16777214`？）。在这两种情况下，编译器分配的存储量完全相同，但第二种情况可以说更具可读性。因此，这是更好的代码。^([3](footnotes.xhtml#ch12fn3))
- en: Variable declarations aren’t the only place a compiler can use this optimization.
    Any arithmetic expression (or subexpression) containing constant operands is a
    candidate for constant folding. Therefore, if you can write an arithmetic expression
    more clearly by using constant expressions rather than computing the results by
    hand, you should definitely go for the more readable version and leave it up to
    the compiler to handle the constant calculation at compile time. If your compiler
    doesn’t support constant folding, you can certainly simulate it by performing
    all constant calculations manually. However, you should do this only as a last
    resort. Finding a better compiler is almost always a better choice.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 变量声明并不是唯一可以使用此优化的地方。任何包含常量操作数的算术表达式（或子表达式）都可以作为常量折叠的候选。因此，如果你能够通过使用常量表达式而不是手动计算结果，使算术表达式更清晰，应该选择更具可读性的版本，并让编译器在编译时处理常量计算。如果你的编译器不支持常量折叠，你当然可以通过手动执行所有常量计算来模拟它。然而，这应该仅作为最后的手段。寻找一个更好的编译器通常是更好的选择。
- en: Some good optimizing compilers may take extreme steps when folding constants.
    For example, some compilers with a sufficiently high optimization level enabled
    will replace certain function calls, with constant parameters, to the corresponding
    constant value. For example, a compiler might translate a C/C++ statement of the
    form `sineR = sin(0);` to `sineR = 0;` during compilation (as the sine of zero
    radians is `0`). This type of constant folding, however, is not all that common,
    and you usually have to enable a special compiler mode to get it.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一些优秀的优化编译器在折叠常量时可能会采取极端手段。例如，一些开启了足够高优化级别的编译器会将某些带有常量参数的函数调用替换为相应的常量值。例如，编译器可能会将
    C/C++ 语句 `sineR = sin(0);` 转换为 `sineR = 0;`（因为零弧度的正弦值为 `0`）。然而，这种类型的常量折叠并不常见，通常需要启用特别的编译器模式才能实现。
- en: 'If you ever have any questions about whether your particular compiler supports
    constant folding, have the compiler generate an assembly listing and look at its
    output (or view the disassembled output with a debugger). Here’s a trivial case
    written in C/C++ (compiled with Visual C++):'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对自己的编译器是否支持常量折叠有任何疑问，可以让编译器生成汇编清单并查看其输出（或使用调试器查看反汇编输出）。下面是一个用 C/C++ 编写的简单示例（使用
    Visual C++ 编译）：
- en: '[PRE22]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here’s a comparable program written in Java:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个用 Java 编写的相应程序：
- en: '[PRE23]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Note that the `ldc #2` instruction pushes a constant from a constant pool onto
    the stack. The comment attached to this bytecode instruction explains that the
    Java compiler converted `16*1024*1024` into a single constant `16777216`. Java
    performs the constant folding at compile time rather than computing this product
    at runtime.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意，`ldc #2` 指令将常量池中的常量推送到栈上。附加在这条字节码指令上的注释解释了 Java 编译器将 `16*1024*1024` 转换为一个单一常量
    `16777216`。Java 在编译时进行常量折叠，而不是在运行时计算这个乘积。'
- en: 'Here’s the comparable program in Swift, along with the assembly code emitted
    for the relevant portion^([4](footnotes.xhtml#ch12fn4)) of the main program:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这是相应的 Swift 程序，并附带了相关部分^([4](footnotes.xhtml#ch12fn4))的汇编代码：
- en: '[PRE24]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: As you can see, Swift also supports the constant folding optimization.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，Swift 也支持常量折叠优化。
- en: '**12.2.2 Constant Propagation**'
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.2 常量传播**'
- en: 'Constant propagation is an optimization a compiler uses to replace a variable
    access by a constant value if the compiler determines that it’s possible. For
    example, a compiler that supports constant propagation will make the following
    optimization:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 常量传播是一种优化技术，编译器使用它来将变量访问替换为常量值，如果编译器确定这样做是可能的。例如，支持常量传播的编译器将进行如下优化：
- en: '[PRE25]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In object code, manipulating immediate constants is often more efficient than
    manipulating variables; therefore, constant propagation often produces much better
    code. In some cases, constant propagation also allows the compiler to eliminate
    certain variables and statements altogether (in this example, the compiler could
    remove `variable = 1234;` if there are no later references to the variable object
    in the source code).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标代码中，操作立即常量通常比操作变量更有效；因此，常量传播通常会产生更好的代码。在某些情况下，常量传播还可以使编译器完全消除某些变量和语句（在这个例子中，如果源代码中没有后续对变量对象的引用，编译器可以删除
    `variable = 1234;`）。
- en: 'In some cases, well-written compilers can do some outrageous optimizations
    involving constant folding. Consider the following C code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，编写良好的编译器可以进行一些令人惊讶的优化，涉及常量折叠。考虑以下 C 代码：
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here’s the 80x86 output that GCC produces with the `-O3` (maximum) optimization
    option:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 GCC 在启用 `-O3`（最大）优化选项后生成的 80x86 输出：
- en: '[PRE27]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: A quick glance shows that the `rtn3()` function is nowhere to be found. With
    the `-O3` command-line option enabled, GCC figured out that `rtn3()` simply returns
    a constant, so it propagates that constant return result everywhere you call `rtn3()`.
    In the case of the `printf()` function call, the combination of constant propagation
    and constant folding yielded a single constant, `5`, that the code passes on to
    the `printf()` function.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查看表明，`rtn3()` 函数在哪里都找不到。启用了 `-O3` 命令行选项后，GCC 发现 `rtn3()` 仅仅返回一个常量，因此它将常量返回结果传播到你调用
    `rtn3()` 的每个地方。在 `printf()` 函数调用的情况下，常量传播和常量折叠的结合生成了一个单一的常量 `5`，该常量被传递给 `printf()`
    函数。
- en: As with constant folding, if your compiler doesn’t support constant propagation
    you can simulate it manually, but only as a last resort. Again, finding a better
    compiler is almost always a better choice.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 和常量折叠一样，如果你的编译器不支持常量传播，你可以手动模拟它，但这只是最后的手段。再次强调，找到一个更好的编译器几乎总是更好的选择。
- en: 'You can turn on the compiler’s assembly language output to determine if your
    compiler support constant propagation. For example, here is Visual C++’s output
    (with the `/O2` optimization level turned on):'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以开启编译器的汇编语言输出，来判断你的编译器是否支持常量传播。例如，以下是 Visual C++ 的输出（启用了 `/O2` 优化级别）：
- en: '[PRE28]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As you can see, Visual C++ also eliminated the `f()` function as well as the
    `i` and `j` variables. It computed the function result (`i+1`) at compile time
    and substituted the constant `16777217` (`16*1024*1024 + 1`) for all the computations.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，Visual C++ 也消除了 `f()` 函数以及 `i` 和 `j` 变量。它在编译时计算了函数结果（`i+1`），并将常量 `16777217`
    （`16*1024*1024 + 1`）替换到所有的计算中。
- en: 'Here’s an example using Java:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个使用 Java 的示例：
- en: '[PRE29]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: A quick review of this Java bytecode shows that the Java compiler (`java version
    "1.6.0_65"`) does not support the constant propagation optimization. Not only
    did it not eliminate the `f()` function, but it also doesn’t eliminate variables
    `i` and `j`, and it passes the value of `i` to function `f()` rather than passing
    the appropriate constant. One could argue that Java’s bytecode interpretation
    dramatically affects performance, so a simple optimization such as constant propagation
    won’t impact performance that much.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查看这个 Java 字节码显示，Java 编译器（`java version "1.6.0_65"`）不支持常量传播优化。它不仅没有消除 `f()`
    函数，而且也没有消除变量 `i` 和 `j`，并且它将 `i` 的值传递给 `f()` 函数，而不是传递合适的常量。有人可能会说，Java 的字节码解释会显著影响性能，因此像常量传播这样的简单优化不会对性能产生太大影响。
- en: 'Here’s the comparable program written in Swift, with the compiler’s assembly
    output:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用 Swift 编写的类似程序，以及编译器的汇编输出：
- en: '[PRE30]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The Swift compiler generates a tremendous amount of code in support of its runtime
    system, so you can hardly call Swift an *optimizing* compiler. That being said,
    the assembly code that it does generate demonstrates that Swift supports the constant
    propagation optimization. It eliminates the function `f()` and propagates the
    constants resulting from the calculations into the calls that print the values
    of `i` and `j`. It doesn’t eliminate `i` and `j` (probably because of some consistency
    issues regarding the runtime system), but it does propagate the constants through
    the compiled code.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Swift 编译器生成了大量代码来支持其运行时系统，因此你几乎不能称 Swift 为一个 *优化* 编译器。话虽如此，它生成的汇编代码表明，Swift
    支持常量传播优化。它消除了 `f()` 函数，并将计算结果的常量传播到打印 `i` 和 `j` 值的调用中。它没有消除 `i` 和 `j`（可能是因为与运行时系统有关的一些一致性问题），但它确实通过编译代码传播了常量。
- en: Given the excessive amount of code that the Swift compiler generates, it’s questionable
    whether this optimization is worthwhile. However, even with all the extra code
    (too much to print here, so feel free to look at it yourself), the output still
    runs faster than interpreted Java code.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于Swift编译器生成的代码量过大，是否值得进行这种优化值得怀疑。然而，即使有了所有这些额外的代码（这里太多了，无法全部打印出来，欢迎自己查看），输出仍然比解释执行的Java代码运行得更快。
- en: '**12.2.3 Dead Code Elimination**'
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.3 死代码消除**'
- en: Dead code elimination is the removal of the object code associated with a particular
    source code statement if the program never again uses the result of that statement.
    Often, this is a result of a programming error. (After all, why would someone
    compute a value and not use it?) If a compiler encounters dead code in the source
    file, it may warn you to check the logic of your code. In some cases, however,
    earlier optimizations can produce dead code. For example, the constant propagation
    for the value variable in the earlier example could result in the statement `variable
    = 1234;` being dead. Compilers that support dead code elimination will quietly
    remove the object code for this statement from the object file.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 死代码消除是指删除与特定源代码语句相关的目标代码，如果程序再也不使用该语句的结果。这通常是编程错误的结果。（毕竟，为什么有人会计算一个值却不使用它呢？）如果编译器在源文件中遇到死代码，它可能会警告你检查代码逻辑。然而，在某些情况下，早期的优化可能会产生死代码。例如，前面示例中值变量的常量传播可能会导致语句`variable
    = 1234;`变成死代码。支持死代码消除的编译器会悄悄地从目标文件中删除这条语句的目标代码。
- en: 'As an example of dead code elimination, consider the following C program and
    its corresponding assembly code:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 作为死代码消除的一个示例，考虑以下C程序及其相应的汇编代码：
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here’s the 32-bit 80x86 code GCC emits when supplied the `-O3` command-line
    option:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这是GCC在提供`-O3`命令行选项时生成的32位80x86代码：
- en: '[PRE32]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now consider the 80x86 output from GCC when optimization is not enabled:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑GCC在未启用优化时的80x86输出：
- en: '[PRE33]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In fact, one of the main reasons that program examples throughout this book
    call a function like `printf()` to display various values is to explicitly use
    those values to prevent dead code elimination from erasing the code we’re examining
    from the assembly output file. If you remove the final `printf()` from the C program
    in many of these examples, most of the assembly code will disappear because of
    dead code elimination.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，本书中大多数程序示例调用像`printf()`这样的函数来显示各种值，主要是为了显式地使用这些值，以防止死代码消除将我们正在检查的代码从汇编输出文件中删除。如果你从这些示例中的C程序中移除最后一个`printf()`，大部分汇编代码将因为死代码消除而消失。
- en: 'Here’s the output from the previous C++ code from Visual C++:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这是前面Visual C++代码的输出：
- en: '[PRE34]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Unlike GCC, Visual C++ did not eliminate the `rtn3()` function. However, it
    did remove the assignment to `i`—and the call to `rtn3()`—in the main program.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 与GCC不同，Visual C++没有删除`rtn3()`函数。然而，它确实删除了对`i`的赋值以及对`rtn3()`的调用——这些都在主程序中被移除。
- en: 'Here’s the equivalent Java program and the JBC output:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是等效的Java程序和JBC输出：
- en: '[PRE35]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'At first blush, it looks like Java does not support dead code elimination.
    However, the problem might be that our example code doesn’t trigger this optimization
    in the compiler. Let’s try something more obvious to the compiler:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，似乎Java不支持死代码消除。然而，问题可能是我们的示例代码没有触发编译器的这个优化。让我们尝试一些编译器更容易识别的代码：
- en: '[PRE36]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Now we’ve given the Java compiler something it can chew on. The main program
    eliminates the call to `rtn3()` and the assignment to `i`. The optimization isn’t
    quite as smart as GCC’s or Visual C++’s optimization, but (at least) for some
    cases, it works. Unfortunately, without constant propagation, Java misses many
    opportunities for dead code elimination.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们给Java编译器提供了一些它可以处理的内容。主程序消除了对`rtn3()`的调用和对`i`的赋值。这个优化不如GCC或Visual C++的优化聪明，但（至少）在某些情况下，它是有效的。不幸的是，没有常量传播，Java错过了很多死代码消除的机会。
- en: 'Here’s the equivalent Swift code for the earlier example:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是前一个示例的等效Swift代码：
- en: '[PRE37]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Note that Swift (at least for this example) does not support dead code elimination.
    However, let’s try the same thing we did with Java. Consider the following code:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Swift（至少对于这个示例）不支持死代码消除。然而，让我们尝试像在Java中做的那样。考虑以下代码：
- en: '[PRE38]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Compiling this code produces a list of warnings about the dead code, but the
    output demonstrates that Swift does support dead code elimination. Furthermore,
    because Swift supports constant propagation as well, it won’t miss as many opportunities
    for dead code elimination as Java (though Swift will need to mature a bit more
    before it catches up to GCC or Visual C++).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 编译这段代码会生成关于死代码的警告列表，但输出结果证明了Swift确实支持死代码消除。此外，由于Swift也支持常量传播，它不会像Java那样错过那么多死代码消除的机会（尽管Swift在追赶GCC或Visual
    C++之前可能还需要一些时间）。
- en: '**12.2.4 Common Subexpression Elimination**'
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.4 公共子表达式消除**'
- en: 'Often, a portion of some expressions—a *subexpression*—may appear elsewhere
    in the current function. If there are no changes to the values of the variables
    appearing in the subexpression, the program doesn’t need to compute its value
    twice. Instead, it can save the subexpression’s value on the first evaluation
    and then use that value everywhere the subexpression appears again. For example,
    consider the following Pascal code:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，一些表达式的部分—一个*子表达式*—可能在当前函数的其他地方出现。如果在子表达式中出现的变量的值没有发生变化，那么程序就不需要两次计算它的值。相反，它可以在第一次计算时保存子表达式的值，然后在子表达式再次出现时使用该值。例如，考虑以下Pascal代码：
- en: '[PRE39]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'A decent compiler might translate these to the following sequence of three-address
    statements:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 一个合格的编译器可能会将这些转换为以下三地址语句序列：
- en: '[PRE40]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Although the former statements use the subexpression `(a + b)` twice and the
    subexpression `(e div f)` three times, the three-address code sequence computes
    these subexpressions only once and uses their values when the common subexpressions
    appear later.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前面的语句分别使用了子表达式`(a + b)`两次和子表达式`(e div f)`三次，但三地址代码序列只计算这些子表达式一次，并在后续出现公共子表达式时使用它们的值。
- en: 'As another example, consider the following C/C++ code:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，考虑下面的C/C++代码：
- en: '[PRE41]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Here’s the 32-bit 80x86 assembly file that GCC generates (with the `-O3` option)
    for the preceding C code:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这是GCC为上述C代码生成的32位80x86汇编文件（使用`-O3`选项）：
- en: '[PRE42]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Note how the compiler maintains the results of the common subexpressions in
    various registers (see the comments in the assembly output for details).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 注意编译器如何在不同的寄存器中保持公共子表达式的结果（请参阅汇编输出中的注释以了解详细信息）。
- en: 'Here’s the (64-bit) output from Visual C++:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Visual C++的（64位）输出：
- en: '[PRE43]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Because of the extra registers available on the x86-64, Visual C++ was able
    to keep all the temporaries in registers and did an even better job of reusing
    precomputed values for common subexpressions.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 由于x86-64架构上额外的寄存器，Visual C++能够将所有临时变量保留在寄存器中，并且在重用公共子表达式的预计算值时做得更好。
- en: 'If the compiler you’re using doesn’t support common subexpression optimizations
    (you can determine this by examining the assembly output), chances are pretty
    good that its optimizer is subpar, and you should consider using a different compiler.
    However, in the meantime, you can always explicitly code this optimization yourself.
    Consider this version of the former C code, which manually computes common subexpressions:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的编译器不支持公共子表达式优化（你可以通过检查汇编输出来判断），那么它的优化器可能比较差，你应该考虑使用不同的编译器。然而，在此期间，你可以始终手动实现这种优化。考虑以下版本的前述C代码，它手动计算了公共子表达式：
- en: '[PRE44]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Of course, there was no reason to create the `ijExpr` and `kmnExpr` variables,
    as we could have simply used the *expr2* and *expr3* variables for this purpose.
    However, this code was written to make the changes to the original program as
    obvious as possible.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，没有必要创建`ijExpr`和`kmnExpr`变量，因为我们本可以直接使用*expr2*和*expr3*变量来达到目的。然而，这段代码的编写目的是让对原程序的更改尽可能明显。
- en: 'Here’s the similar Java code:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是类似的Java代码：
- en: '[PRE45]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Notice that Java does not optimize common subexpressions; instead, it recomputes
    the subexpressions each time it encounters them. Therefore, you should manually
    compute the values of common subexpressions when writing Java code.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Java不会优化公共子表达式；相反，它每次遇到子表达式时都会重新计算它。因此，在编写Java代码时，你应该手动计算公共子表达式的值。
- en: 'Here’s a variant of the current example in Swift (along with the assembly output):'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这是当前示例在Swift中的变体（以及汇编输出）：
- en: '[PRE46]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: If you carefully read through this code, you can see the Swift compiler properly
    optimizes away the common subexpressions and computes each subexpression only
    once.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细阅读这段代码，你可以看到Swift编译器正确地优化了公共子表达式，并且每个子表达式只计算一次。
- en: '**12.2.5 Strength Reduction**'
  id: totrans-218
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.5 强度减少**'
- en: 'Often, the CPU can directly compute some value using a different operator than
    the source code specifies, thereby replacing a more complex (or stronger) instruction
    with a simpler instruction. For example, a `shift` operation can implement multiplication
    or division by a constant that is a power of 2, and certain modulo (remainder)
    operations are possible using a bitwise `and` instruction (the `shift` and `and`
    instructions generally execute much faster than `multiply` and `divide` instructions).
    Most compiler optimizers are good at recognizing such operations and replacing
    the more expensive computation with a less expensive sequence of machine instructions.
    To see strength reduction in action, consider this C code and the 80x86 GCC output
    that follows it:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，CPU可以使用不同的操作符直接计算某个值，从而用更简单的指令替代更复杂（或更强大）的指令。例如，`shift`操作可以实现乘以或除以2的幂的常数，而某些取模（余数）操作可以使用按位`and`指令来完成（`shift`和`and`指令通常比`multiply`和`divide`指令执行得更快）。大多数编译器优化器擅长识别此类操作，并将更昂贵的计算替换为更便宜的一系列机器指令。要看到强度化简的实际效果，可以考虑以下C代码及其后面的80x86
    GCC输出：
- en: '[PRE47]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Here’s the resulting 80x86 code generated by GCC:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这是GCC生成的最终80x86代码：
- en: '[PRE48]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: In this 80x86 code, note that GCC never emitted a multiplication or division
    instruction, even though the C code used these two operators extensively. GCC
    replaced each of these (expensive) operations with less expensive address calculations,
    shifts, and logical AND operations.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段80x86代码中，请注意，GCC从未生成乘法或除法指令，即使C代码中大量使用了这两个操作符。GCC将每个（开销大的）操作替换为较便宜的地址计算、移位和逻辑与操作。
- en: 'This C example declared its variables as `unsigned` rather than as `int`. There’s
    a very good reason for this modification: strength reduction produces more efficient
    code for certain unsigned operands than it does for signed operands. This is a
    very important point: if you have a choice between using either signed or unsigned
    integer operands, always try to use unsigned values, because compilers can often
    generate better code when processing unsigned operands. To see the difference,
    here’s the previous C code rewritten using signed integers, followed by GCC’s
    80x86 output:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这个C示例将变量声明为`unsigned`而不是`int`。这样做有一个很好的理由：强度化简对于某些无符号操作数比有符号操作数生成更高效的代码。这是一个非常重要的点：如果你有选择使用有符号或无符号整数操作数的机会，总是尝试使用无符号值，因为编译器在处理无符号操作数时通常能够生成更好的代码。为了看到差异，以下是之前的C代码使用有符号整数重写后的版本，并附上GCC的80x86输出：
- en: '[PRE49]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Here is GCC’s (32-bit) 80x86 assembly output for this C code:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这是GCC（32位）为此C代码生成的80x86汇编输出：
- en: '[PRE50]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The difference in these two coding examples demonstrates why you should opt
    for unsigned integers (over signed integers) whenever you don’t absolutely need
    to deal with negative numbers.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个编码示例之间的差异展示了为什么在不需要处理负数时，你应该选择无符号整数（而不是有符号整数）。
- en: Attempting strength reduction manually is risky. While certain operations (like
    division) are almost always slower than others (like shifting to the right) on
    most CPUs, many strength reduction optimizations are not portable across CPUs.
    That is, substituting a left shift operation for multiplication may not always
    produce faster code when you compile for different CPUs. Some older C programs
    contain manual strength reductions that were originally added to improve performance.
    Today, those strength reductions can actually cause the programs to run slower
    than they should. Be very careful about incorporating strength reductions directly
    into your HLL code—this is one area where you should let the compiler do its job.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 手动进行强度化简是有风险的。虽然某些操作（如除法）在大多数CPU上通常比其他操作（如右移）慢，但许多强度化简优化在不同CPU之间并不具有可移植性。也就是说，用左移操作替代乘法操作，可能在你为不同CPU编译时并不会产生更快的代码。一些较旧的C程序包含了当初为了提高性能而手动加入的强度化简。今天，这些强度化简反而可能导致程序的运行速度比预期更慢。在将强度化简直接加入HLL代码时要非常小心——这是一个应该让编译器完成工作的领域。
- en: '**12.2.6 Induction**'
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.6 归纳**'
- en: 'In many expressions, particularly those appearing within a loop, the value
    of one variable in the expression is completely dependent on some other variable.
    As an example, consider the following `for` loop in Pascal:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多表达式中，特别是在循环中，表达式中某个变量的值完全依赖于另一个变量。例如，考虑以下Pascal中的`for`循环：
- en: '[PRE51]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'A compiler’s optimizer may recognize that `j` is completely dependent on the
    value of `i` and rewrite this code as follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器的优化器可能会识别到 `j` 完全依赖于 `i` 的值，并将此代码重写如下：
- en: '[PRE52]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This optimization saves some work in the loop (specifically, the computation
    of `j := i * 2`).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这个优化减少了循环中的一些工作量（具体来说，是 `j := i * 2` 的计算）。
- en: 'As another example, consider the following C code and the MASM output that
    Microsoft’s Visual C++ compiler produces:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个示例，考虑以下 C 代码以及 Microsoft 的 Visual C++ 编译器生成的 MASM 输出：
- en: '[PRE53]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Here’s the MASM (32-bit 80x86) output from Visual C++:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Visual C++ 生成的 MASM（32 位 80x86）输出：
- en: '[PRE54]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: As you can see in this MASM output, the Visual C++ compiler recognizes that
    `i` is not used in this loop. There are no calculations involving `i`, and it’s
    completely optimized away. Furthermore, there’s no `j = i * 2` computation. Instead,
    the compiler uses induction to determine that `j` increases by 2 on each iteration,
    and emits the code to do this rather than computing the value of `j` value from
    `i`. Finally, note that the compiler doesn’t index into the vector array. Instead,
    it marches a pointer through the array on each iteration of the loop—once again
    using induction to produce a faster and shorter code sequence than you’d get without
    this optimization.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在这个 MASM 输出中看到的，Visual C++ 编译器识别到 `i` 在这个循环中没有被使用。没有涉及 `i` 的计算，它被完全优化掉了。此外，也没有
    `j = i * 2` 的计算。相反，编译器使用归纳法来确定 `j` 在每次迭代中增加 2，并生成执行这一操作的代码，而不是从 `i` 计算 `j` 的值。最后，注意到编译器并没有索引到向量数组，而是通过每次迭代循环中的指针来遍历数组——再次使用归纳法生成比没有这个优化时更快、更短的代码序列。
- en: As for common subexpressions, you can manually incorporate induction optimization
    into your programs. The result is almost always harder to read and understand,
    but if your compiler’s optimizer fails to produce good machine code in a section
    of your program, manual optimization is always an option.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 至于常见的子表达式，你可以手动将归纳优化融入到你的程序中。结果几乎总是更难以阅读和理解，但如果编译器的优化器未能在程序的某个部分生成好的机器代码，手动优化始终是一个可行的选项。
- en: 'Here’s the Java variation of this example and the JBC output:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这个示例的 Java 变种和 JBC 输出：
- en: '[PRE55]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'It’s probably obvious that Java doesn’t optimize this code at all. If you want
    better code, you’ll have to manually optimize it:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，Java 完全没有优化这段代码。如果你希望获得更好的代码，就必须手动优化它：
- en: '[PRE56]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: As you can see, Java isn’t the best language choice if you’re interested in
    producing optimized runtime code. Perhaps Java’s authors felt that as a result
    of the interpreted bytecode execution, there was no real reason to try to optimize
    the compiler’s output, or perhaps they felt that optimization was the JIT compiler’s
    responsibility.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，如果你希望生成优化后的运行时代码，Java 可能不是最佳的语言选择。也许 Java 的作者认为由于字节码的解释执行，没有必要尝试优化编译器的输出，或者他们认为优化是
    JIT 编译器的责任。
- en: '**12.2.7 Loop Invariants**'
  id: totrans-247
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.7 循环不变式**'
- en: 'The optimizations shown so far have all been techniques a compiler can use
    to improve code that is already well written. Handling loop invariants, by contrast,
    is a compiler optimization for fixing bad code. A *loop invariant* is an expression
    that does not change on each iteration of some loop. The following Visual Basic
    code demonstrates a trivial loop-invariant calculation:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 目前为止展示的优化方法都是编译器可以用来改进已经编写得很好的代码的技巧。相比之下，处理循环不变式是编译器用来修复坏代码的优化方法。*循环不变式*是指在某个循环的每次迭代中都不会改变的表达式。下面的
    Visual Basic 代码演示了一个简单的循环不变式计算：
- en: '[PRE57]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The value of `k` does not change during the loop’s execution. Once the loop
    completes execution, `k`’s value is exactly the same as if the calculation of
    `k` had been moved before or after the loop. For example:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`k` 的值在循环执行过程中不会改变。一旦循环执行完毕，`k` 的值与将 `k` 的计算移到循环前后时的值完全相同。例如：'
- en: '[PRE58]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The difference between these two code fragments, of course, is that the second
    example computes the value `k = i * 2` only once rather than on each iteration
    of the loop.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个代码片段的区别显然是，第二个示例只计算一次 `k = i * 2`，而不是每次循环迭代时都计算。
- en: 'Many compilers’ optimizers will spot a loop-invariant calculation and use *code
    motion* to move it outside the loop. As an example of this operation, consider
    the following C program and its corresponding output:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 许多编译器的优化器会发现循环不变式计算，并使用*代码移动*将其移出循环。作为这种操作的示例，考虑以下 C 程序及其相应的输出：
- en: '[PRE59]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Here’s the 80x86 MASM code emitted by Visual C++:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Visual C++ 生成的 80x86 MASM 代码：
- en: '[PRE60]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: As you can see by reading the comments in the assembly code, the loop-invariant
    expression `j = k + 2` was moved out of the loop and executed prior to the start
    of the loop’s code, saving some execution time on each iteration of the loop.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从汇编代码中的注释中看到的那样，循环不变的表达式 `j = k + 2` 被移出了循环，并在循环代码开始之前执行，从而节省了每次循环迭代的执行时间。
- en: Unlike most optimizations, which you should leave up to the compiler if possible,
    you should move all loop-invariant calculations out of a loop unless there’s a
    justifiable reason for leaving them there. Loop-invariant calculations raise questions
    for someone reading your code (“Isn’t this supposed to change in the loop?”),
    because their presence actually makes the code harder to read and understand.
    If you want to leave the invariant code in the loop for some reason, be sure to
    comment your justification for anyone looking at your code later.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数优化不同，尽可能将循环不变的计算移出循环，除非有充分的理由将它们保留在循环内。循环不变的计算会让阅读代码的人产生疑问（“这不是应该在循环中变化吗？”），因为它们的存在实际上使代码更难以阅读和理解。如果你出于某种原因想将不变的代码保留在循环内，请务必在代码中添加注释，解释你的理由，方便以后查看代码的人理解。
- en: '**12.2.8 Optimizers and Programmers**'
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.2.8 优化器与程序员**'
- en: 'HLL programmers fall into three groups based on their understanding of these
    compiler optimizations:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: HLL 程序员根据对编译器优化的理解分为三类：
- en: The first group is unaware of how compiler optimizations work, and they write
    their code without considering the effect that their code organization will have
    on the optimizer.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一组程序员不了解编译器优化的原理，他们编写代码时没有考虑代码组织对优化器的影响。
- en: The second group understands how compiler optimizations work, so they write
    their code to be more readable. They assume that the optimizer will handle issues
    such as converting multiplication and division to shifts (where appropriate) and
    preprocessing constant expressions. This second group places a fair amount of
    faith in the compiler’s ability to correctly optimize their code.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二组程序员理解编译器优化的工作原理，因此他们编写更易于阅读的代码。他们假设优化器会处理诸如将乘法和除法转换为位移（适用时）和预处理常量表达式等问题。这第二组程序员对编译器能够正确优化代码抱有相当的信心。
- en: The third group is also aware of the general types of optimizations that compilers
    can do, but they don’t trust the compilers to do the optimization for them. Instead,
    they manually incorporate those optimizations into their code.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三组程序员也了解编译器可以进行的优化类型，但他们不信任编译器来为他们执行优化。相反，他们手动将这些优化融入到自己的代码中。
- en: Interestingly enough, compiler optimizers are actually designed for the first
    group of programmers, those who are ignorant of how the compiler operates. Therefore,
    a good compiler will usually produce roughly the same quality of code for all
    three types of programmers (at least with respect to arithmetic expressions).
    This is particularly true when you compile the same program across different compilers.
    However, keep in mind that this assertion is valid only for compilers that have
    decent optimization capabilities. If you have to compile your code on a large
    number of compilers and you can’t be confident that all of them have good optimizers,
    manual optimization may be one way to achieve consistently good performance across
    all compilers.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，编译器优化器实际上是为第一组程序员设计的，那些不了解编译器如何工作的程序员。因此，一个好的编译器通常会为这三类程序员生成大致相同质量的代码（至少在算术表达式方面）。当你在不同的编译器中编译同一程序时，这一点尤其如此。然而，记住，这一断言仅适用于那些具有良好优化能力的编译器。如果你不得不在大量编译器上编译代码，并且不能确保所有编译器都有良好的优化器，那么手动优化可能是实现跨所有编译器一致良好性能的一种方式。
- en: Of course, the real question is, “Which compilers are good, and which are not?”
    It would be nice to provide a table or chart in this book that describes the optimization
    capabilities of all the different compilers you might encounter, but unfortunately,
    the rankings change as compiler vendors improve their products, so anything printed
    here would rapidly become obsolete.^([5](footnotes.xhtml#ch12fn5)) Fortunately,
    there are several websites that try to keep up-to-date comparisons of compilers.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，真正的问题是：“哪些编译器好，哪些不好？”如果本书能够提供一个表格或图表，描述你可能遇到的所有不同编译器的优化能力，那就太好了。但不幸的是，随着编译器厂商不断改进产品，排名会发生变化，因此这里印刷的任何内容都会迅速过时。^([5](footnotes.xhtml#ch12fn5))
    幸运的是，有一些网站会尽力保持编译器的最新对比。
- en: '**12.3 Side Effects in Arithmetic Expressions**'
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.3 算术表达式中的副作用**'
- en: You’ll definitely want to give a compiler some guidance with respect to side
    effects that may occur in an expression. If you don’t understand how compilers
    deal with side effects in arithmetic expressions, you might write code that doesn’t
    always produce correct results, particularly when moving source code between different
    compilers. Wanting to write the fastest or the smallest possible code is all well
    and good, but if it doesn’t produce the correct answer any optimizations you make
    on the code are all for naught.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 你一定要为编译器提供关于表达式中可能发生的副作用的指导。如果你不理解编译器如何处理算术表达式中的副作用，你可能会写出不总是产生正确结果的代码，尤其是在不同编译器之间迁移源代码时。希望编写最快或最小的代码是可以理解的，但如果它没有产生正确的答案，那么你对代码的任何优化都将毫无意义。
- en: 'A *side effect* is any modification to the global state of a program outside
    the immediate result a piece of code is producing. The primary purpose of an arithmetic
    expression is to produce the expression’s result. Any other change to the system’s
    state in an expression is a side effect. The C, C++, C#, Java, Swift, and other
    C-based languages are especially guilty of allowing side effects in an arithmetic
    expression. For example, consider the following C code fragment:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '*副作用*是对程序全局状态的任何修改，超出了代码段所产生的即时结果。算术表达式的主要目的是产生表达式的结果。任何在表达式中对系统状态的其他更改都是副作用。C、C++、C#、Java、Swift及其他基于C的语言尤其容易在算术表达式中允许副作用。例如，考虑以下C语言代码片段：'
- en: '[PRE61]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'This expression exhibits four separate side effects:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表达式表现出四个独立的副作用：
- en: The decrement of `k` at the end of the expression
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表达式结束时`k`的递减。
- en: The assignment to `j` prior to using `j`’s value
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用`j`的值之前对`j`的赋值。
- en: The increment of the pointer `pi` after dereferencing `pi`
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在解引用`pi`之后对指针`pi`的递增。
- en: The assignment to `i`^([6](footnotes.xhtml#ch12fn6))
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对`i`的赋值^([6](footnotes.xhtml#ch12fn6))。
- en: 'Although few non–C-based languages provide as many ways to create side effects
    in arithmetic expressions as C does, most languages do allow you to create side
    effects within an expression via a function call. Side effects in functions are
    useful, for example, when you need to return more than a single value as a function
    result in languages that don’t directly support this capability. Consider the
    following Pascal code fragment:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管很少有非基于C的语言提供像C语言那样多的方式在算术表达式中创建副作用，但大多数语言确实允许通过函数调用在表达式中创建副作用。例如，在不直接支持此功能的语言中，当你需要返回多个值作为函数结果时，函数中的副作用非常有用。考虑以下Pascal代码片段：
- en: '[PRE62]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'In this example, the call to the `hasSideEffect()` function produces two different
    side effects:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，调用`hasSideEffect()`函数会产生两个不同的副作用：
- en: The modification of the global variable `k`.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对全局变量`k`的修改。
- en: The modification of the pass-by-reference parameter `j` (the actual parameter
    is `n` in this code fragment).
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对通过引用传递的参数`j`的修改（在这段代码中，实际参数是`n`）。
- en: The real purpose of the function is to compute its return result. Any modification
    of global values or reference parameters constitutes a side effect of that function;
    hence, invoking that function within an expression produces side effects. Any
    language that allows you to modify global values (either directly or through parameters)
    from a function is capable of producing side effects within an expression; this
    concept is not limited to Pascal programs.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数的真实目的是计算其返回结果。任何修改全局值或引用参数的行为都构成了该函数的副作用；因此，在表达式中调用该函数会产生副作用。任何允许你从函数中修改全局值（无论是直接修改还是通过参数）的语言，都能够在表达式中产生副作用；这一概念并不限于Pascal程序。
- en: 'The problem with side effects in an expression is that most languages do not
    guarantee the order of evaluation of the components that make up an expression.
    Many novice programmers incorrectly assume that when they write an expression
    such as the following:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 算术表达式中的副作用问题在于，大多数语言并不保证构成表达式的各个组件的求值顺序。许多初学者程序员错误地假设，当他们写下如下表达式时：
- en: '[PRE63]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'the compiler will emit code that first calls function `f()` and then calls
    function `g()`. Very few programming languages, however, require this order of
    execution. That is, some compilers will indeed call `f()`, then `g()`, and add
    their return results together. Other compilers, however, will call `g()` first,
    then `f()`, and compute the sum of the function return results. That is, the compiler
    could translate this expression into either of the following simplified code sequences
    before actually generating native machine code:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器会生成首先调用函数`f()`，然后调用函数`g()`的代码。然而，很少有编程语言要求这种执行顺序。也就是说，一些编译器确实会先调用`f()`，然后调用`g()`，并将它们的返回结果相加。然而，其他编译器则会先调用`g()`，再调用`f()`，并计算函数返回结果的和。也就是说，编译器在生成本地机器代码之前，可能会将此表达式转换为以下任一简化的代码序列：
- en: '[PRE64]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: These two different function call sequences could produce completely different
    results if `f()` or `g()` produces a side effect. For example, if function `f()`
    modifies the value of the `x` parameter you pass to it, the preceding sequence
    could produce different results.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`f()`或`g()`产生副作用，那么这两种不同的函数调用顺序可能会产生完全不同的结果。例如，如果函数`f()`修改了你传递给它的`x`参数，那么前面的顺序可能会产生不同的结果。
- en: Note that issues such as precedence, associativity, and commutativity have no
    bearing on whether the compiler evaluates one subcomponent of an expression before
    another.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，优先级、结合性和交换性等问题并不影响编译器是否在某个子表达式之前评估另一个子表达式。
- en: 'For example, consider the following arithmetic expression and several possible
    intermediate forms for the expression:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑以下算术表达式及其几种可能的中间形式：
- en: '[PRE65]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Other combinations are also possible.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 其他组合也是可能的。
- en: 'The specifications for most programming languages explicitly leave the order
    of evaluation undefined. This may seem somewhat bizarre, but there’s a good reason
    for it: sometimes the compiler can produce better machine code by rearranging
    the order in which it evaluates certain subexpressions within an expression. Any
    attempt by the language designer to force a particular order of evaluation on
    a compiler’s implementer, therefore, could limit the range of optimizations possible.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数编程语言的规范明确规定了求值顺序是未定义的。这看起来可能有些奇怪，但这样做有一个充分的理由：有时候，编译器通过重新排列表达式中某些子表达式的求值顺序，可以生成更高效的机器代码。因此，语言设计者若试图强制编译器实现特定的求值顺序，可能会限制优化的范围。
- en: 'There are, of course, certain rules that most languages do enforce. Probably
    the most common rule is that all side effects within an expression will occur
    prior to the completion of that statement’s execution. For example, if the function
    `f()` modifies the global variable `x`, then the following statements will always
    print the value of `x` after `f()` modifies it:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，也有一些规则是大多数语言都会强制执行的。最常见的规则可能是表达式中的所有副作用将在该语句执行完毕之前发生。例如，如果函数`f()`修改了全局变量`x`，那么以下语句将始终打印出`x`在`f()`修改之后的值：
- en: '[PRE66]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Another rule you can count on is that the assignment to a variable on the left-hand
    side of an assignment statement does not occur prior to the use of that same variable
    on the right-hand side of the expression. That is, the following code won’t store
    the result of the expression into variable `n` until it uses the previous value
    of `n` within the expression:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以依赖的另一个规则是，赋值语句左侧的变量赋值操作不会在表达式右侧同一变量被使用之前发生。也就是说，以下代码不会将表达式的结果存储到变量`n`中，直到它在表达式中使用了`n`的先前值：
- en: '[PRE67]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Because the order of the production of side effects within an expression is
    undefined in most languages, the result of the following code is generally undefined
    (in Pascal):'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 因为在大多数语言中，表达式中副作用的产生顺序是未定义的，所以以下代码的结果通常是未定义的（在 Pascal 中）：
- en: '[PRE68]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: The compiler is free to call the `incN()` function first (so `n` will contain
    `3` prior to executing the subexpression `n * 2`), or it can compute `n * 2` first
    and then call the `incN()` function. As a result, one compilation of this statement
    could produce the output `8`, while a different compilation might produce `6`.
    In both cases, `n` would contain `3` after the `writeln` statement is executed,
    but the order of computation of the expression in the `writeln` statement could
    vary.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器可以先调用`incN()`函数（这样`n`将在执行子表达式`n * 2`之前包含`3`），也可以先计算`n * 2`再调用`incN()`函数。因此，这条语句的某一次编译可能会产生输出`8`，而另一种编译则可能产生`6`。在这两种情况下，`n`在执行`writeln`语句后会包含`3`，但`writeln`语句中表达式的计算顺序可能会有所不同。
- en: 'Don’t make the mistake of thinking you can run some experiments to determine
    the order of evaluation. At the very best, such experiments will tell you only
    the order a particular compiler uses. A different compiler may well compute subexpressions
    in a different order. In fact, the same compiler might also compute the components
    of a subexpression differently based on the context of that subexpression. This
    means that a compiler might compute the result using one ordering at one point
    in the program and using a different ordering somewhere else in the same program.
    This is why it’s dangerous to “determine” the ordering your particular compiler
    uses and rely on that ordering. Even if the compiler is consistent in the order
    it uses to compute side effects, the compiler vendor could change the ordering
    in a later version. If you must depend upon the order of evaluation, first break
    the expression down into a sequence of simpler statements whose computational
    order you can control. For example, if you really need to have your program call
    `f()` before `g()` in this statement:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 不要误以为你可以通过做一些实验来确定求值顺序。最好的情况是，这些实验只能告诉你特定编译器使用的顺序。不同的编译器可能会以不同的顺序计算子表达式。事实上，即使是同一个编译器，也可能根据子表达式的上下文以不同的方式计算子表达式的各个组成部分。这意味着编译器可能在程序的某个位置使用一种顺序来计算结果，而在程序中的其他地方使用另一种顺序。这就是为什么“确定”你的特定编译器使用的顺序并依赖于该顺序是危险的原因。即使编译器在计算副作用时使用一致的顺序，编译器供应商也可能会在后续版本中改变这个顺序。如果你必须依赖于求值顺序，首先将表达式分解为一系列更简单的语句，从而能够控制它们的计算顺序。例如，如果你确实需要在这个语句中确保程序先调用`f()`再调用`g()`：
- en: '[PRE69]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'then you should write the code this way:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 那么你应该这样编写代码：
- en: '[PRE70]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: If you must control the order of evaluation within an expression, take special
    care to ensure that all side effects are computed at the appropriate time. To
    do this, you need to learn about sequence points.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你必须控制表达式内的求值顺序，请特别注意确保所有副作用在适当的时机被计算。为了做到这一点，你需要了解序列点。
- en: '**12.4 Containing Side Effects: Sequence Points**'
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.4 包含副作用：序列点**'
- en: As noted earlier, most languages guarantee that the computation of side effects
    completes before certain points, known as *sequence points*, in your program’s
    execution. For example, almost every language guarantees that all side effects
    will be computed by the time the statement containing the expression completes
    execution. The end of a statement is an example of a sequence point.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，大多数编程语言都保证在程序执行的某些时刻，副作用的计算会在被称为*序列点*的特定位置完成。例如，几乎所有的语言都保证在包含表达式的语句执行完成时，所有的副作用都会被计算完。语句结束就是一个序列点的例子。
- en: 'The C programming language provides several important sequence points within
    expressions, in addition to the semicolon at the end of a statement. C defines
    sequence points between each of the following operators:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: C 编程语言在表达式中提供了几个重要的序列点，除了语句结尾的分号外。C 定义了在以下每个操作符之间的序列点：
- en: '[PRE71]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: In these examples, C^([7](footnotes.xhtml#ch12fn7)) guarantees that all side
    effects in expression1 are completed before the computation of expression2 or
    expression3. Note that for the conditional expression, C evaluates only one of
    expression2 or expression3 so the side effects of only one of these subexpressions
    ever occurs on a given execution of the conditional expression. Similarly, short-circuit
    evaluation may cause only expression1 to evaluate in the `&&` and `||` operations.
    So, take care when using the last three forms.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些示例中，C^([7](footnotes.xhtml#ch12fn7))保证在计算表达式2或表达式3之前，表达式1中的所有副作用都已完成。请注意，对于条件表达式，C只会计算表达式2或表达式3中的一个，因此，只有其中一个子表达式的副作用会在每次执行条件表达式时发生。同样，短路求值可能只会导致`&&`和`||`操作中表达式1的求值。因此，在使用最后三种形式时，请小心。
- en: 'To understand how side effects and sequence points can affect the operation
    of your program, consider the following example in C:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解副作用和顺序点如何影响程序的操作，考虑以下C语言中的示例：
- en: '[PRE72]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Note that C does not define a sequence point across the assignment operator.
    Therefore, the language makes no guarantees about the value of the expression
    `i` it uses as an index. The compiler can choose to use the value of `i` before
    or after indexing into array. That the `++` operator is a post-increment operation
    implies only that `i++` returns the value of `i` prior to the increment; it doesn’t
    guarantee that the compiler will use the pre-increment value of `i` anywhere else
    in the expression. The bottom line is that the last statement in this example
    could be semantically equivalent to either of the following statements:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，C语言并没有定义赋值运算符之间的顺序点。因此，语言并不保证它使用的作为索引的表达式`i`的值。编译器可以选择在索引数组之前或之后使用`i`的值。`++`运算符是后置递增运算符，仅意味着`i++`返回递增前的`i`值；它并不保证编译器在表达式的其他地方使用递增前的`i`值。关键在于，这个示例中的最后一条语句在语义上可能等同于以下任一语句：
- en: '[PRE73]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: The C language definition allows either form; it doesn’t require the first form
    simply because the array index appears in the expression before the post-increment
    operator.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: C语言定义允许两种形式；它并不要求使用第一种形式，仅仅因为数组索引出现在表达式中并且在后置递增运算符之前。
- en: To control the assignment to `array` in this example, you have to ensure that
    no part of the expression depends upon the side effects of some other part of
    the expression. That is, you cannot both use the value of `i` at one point in
    the expression and apply the post-increment operator to `i` in another part of
    the expression, unless there is a sequence point between the two uses. Because
    there’s no such sequence point in this statement, the result is undefined by the
    C language standard.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，要控制对`array`的赋值，你必须确保表达式的任何部分都不依赖于表达式中其他部分的副作用。也就是说，除非两个使用之间有顺序点，否则你不能在表达式的某个地方使用`i`的值，并在另一个地方对`i`应用后置递增运算符。由于此语句中没有这样的顺序点，结果根据C语言标准是未定义的。
- en: 'To guarantee that a side effect occurs at an appropriate point, you must have
    a sequence point between two subexpressions. For example, if you’d like to use
    the value of `i` prior to the increment as the index into the array, you could
    write the following code:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保证副作用在合适的时刻发生，必须确保在两个子表达式之间有一个顺序点。例如，如果你希望在递增之前使用`i`的值作为数组的索引，你可以编写如下代码：
- en: '[PRE74]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'To use the value of `i` after the increment operation as the array index, you
    could use code such as the following:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用递增操作后的`i`值作为数组索引，你可以使用如下代码：
- en: '[PRE75]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Note, by the way, that a decent compiler won’t increment `i` and then compute
    `i - 1`. It will recognize the symmetry here, grab the value of `i` prior to the
    increment, and use that value as the index into array. This is an example of where
    someone who is familiar with typical compiler optimizations could take advantage
    of this knowledge to write code that is more readable. A programmer who inherently
    mistrusts compilers and their ability to optimize well might write code like this:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，一个合格的编译器不会先递增`i`然后再计算`i - 1`。它会识别这里的对称性，在递增之前获取`i`的值，并将该值作为数组索引。这是一个例子，说明熟悉典型编译器优化的人如何利用这些知识编写更具可读性的代码。一个天生不信任编译器及其优化能力的程序员可能会写出如下代码：
- en: '[PRE76]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: An important distinction is that a sequence point does not specify exactly when
    a computation will take place, only that it will happen before crossing the sequence
    point. The side effect could have been computed much earlier in the code, at any
    point between the previous sequence point and the current one. Another takeaway
    is that sequence points do not force the compiler to complete some computations
    between a pair of sequence points if that computation does not produce any side
    effects. Eliminating common subexpressions, for example, would be a far less useful
    optimization if the compiler could only use the result of common subexpression
    computations between sequence points. The compiler is free to compute the result
    of a subexpression as far ahead as necessary as long as that subexpression produces
    no side effects. Similarly, a compiler can compute the result of a subexpression
    as late as it cares to, as long as that result doesn’t become part of a side effect.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的区别是，序列点并未指定确切的计算时机，只是规定计算会发生在跨越序列点之前。副作用的计算可能早在代码的某个时刻就已完成，处于前一个序列点与当前序列点之间的任何位置。另一个关键点是，序列点并不强制编译器在一对序列点之间完成某些计算，尤其是当该计算没有产生副作用时。例如，消除公共子表达式就不是一个有用的优化，如果编译器只能在序列点之间使用公共子表达式的计算结果。只要该子表达式不产生副作用，编译器可以提前尽可能远地计算子表达式的结果。同样，编译器也可以推迟计算子表达式的结果，直到它想要计算，只要该结果不成为副作用的一部分。
- en: 'Because statement endings (that is, semicolons) are a sequence point in most
    languages, one way to control the computation of side effects is to manually break
    a complex expression down into a sequence of three-address-like statements. For
    example, rather than relying on the Pascal compiler to translate an earlier example
    into three-address code using its own rules, you can explicitly write the code
    using whichever set of semantics you prefer:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 由于语句结束符（即分号）在大多数语言中是序列点，控制副作用计算的一种方法是将复杂的表达式手动拆解成一系列类似三地址码的语句。例如，不必依赖 Pascal
    编译器将前面的示例翻译成三地址代码，你可以使用自己选择的语义集显式编写代码：
- en: '[PRE77]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Again, operator precedence and associativity do not control when a computation
    takes place in an expression. Even though addition is left associative, the compiler
    may compute the value of the addition operator’s right operand before it computes
    the value of the addition operator’s left operand. Precedence and associativity
    control how the compiler arranges the computation to produce the result. They
    do not control when the program computes the subcomponents of the expression.
    As long as the final computation produces the results expected based on precedence
    and associativity, the compiler is free to compute the subcomponents in any order
    and at any time it pleases.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，运算符的优先级和结合性并不控制表达式中计算的时机。即使加法是左结合的，编译器也可能在计算加法运算符的左操作数之前，先计算加法运算符的右操作数的值。优先级和结合性控制的是编译器如何安排计算以生成结果，而不控制程序何时计算表达式的子组件。只要最终的计算结果符合优先级和结合性的预期，编译器可以在任何顺序和任何时机计算子组件。
- en: 'Thus far, this section has implied that a compiler always computes the value
    of an assignment statement and completes that assignment (and any other side effects)
    upon encountering the semicolon at the end of the statement. Strictly speaking,
    this isn’t true. What many compilers do is ensure that all side effects occur
    between a sequence point and the next reference to the object changed by the side
    effect. For example, consider the following two statements:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本节内容暗示编译器总是在遇到语句末尾的分号时计算赋值语句的值，并完成该赋值（以及其他副作用）。严格来说，这并不完全正确。许多编译器的做法是确保所有副作用发生在一个序列点与下一个引用被副作用改变的对象之间。例如，考虑以下两个语句：
- en: '[PRE78]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Although the first statement in this code fragment has a side effect, some compilers
    might compute the value (or portions thereof) of the second statement before completing
    the execution of the first statement. Many compilers will rearrange various machine
    instructions to avoid data hazards and other execution dependencies in the code
    that might hamper performance (for details on data hazards, see *WGC1*). The semicolon
    sitting between these two statements does not guarantee that all computations
    for the first statement are complete before the CPU begins any new computation;
    it guarantees only that the program computes any side effects that precede the
    semicolon before executing any code that depends on them. Because the second statement
    does not depend upon the values of `j` or `i`, the compiler is free to start computing
    the second assignment prior to completing the first statement.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这段代码中的第一个语句有副作用，但一些编译器可能在完成第一个语句的执行之前就计算第二个语句的值（或其中的一部分）。许多编译器会重新排列各种机器指令，以避免数据风险和代码中可能影响性能的其他执行依赖关系（有关数据风险的详细信息，请参见*WGC1*）。这两个语句之间的分号并不能保证第一个语句的所有计算在CPU开始任何新计算之前都已经完成；它只保证程序在执行任何依赖于它们的代码之前，先计算任何先于分号的副作用。由于第二个语句不依赖于`j`或`i`的值，编译器可以在完成第一个语句之前开始计算第二个赋值。
- en: 'Sequence points act as barriers. A code sequence must complete its execution
    before any subsequent code affected by the side effect can execute. A compiler
    cannot compute the value of a side effect before executing all the code up to
    the previous sequence point in the program. Consider the following two code fragments:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 序列点充当屏障。一个代码序列必须在任何受副作用影响的后续代码执行之前完成其执行。编译器不能在执行程序中所有到达先前序列点的代码之前计算副作用的值。考虑以下两个代码片段：
- en: '[PRE79]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: In code fragment 1, the compiler must not rearrange the code so that it produces
    the side effect `++k` prior to using `k` in the previous statement. The end-of-statement
    sequence point guarantees that the first statement in this example uses the value
    of `k` prior to any side effects produced in subsequent statements. In code fragment
    2, however, the result of the side effect that `++n` produces does not affect
    anything in the `i = j + k;` statement, so the compiler is free to move the `++n`
    operation into the code that computes `i`’s value if doing so is more convenient
    or efficient.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码片段1中，编译器不能重新排列代码，使得副作用`++k`在使用`k`之前发生。语句末尾的序列点保证了本例中的第一个语句在任何后续语句产生副作用之前使用`k`的值。然而，在代码片段2中，`++n`产生的副作用结果并不影响`i
    = j + k;`语句中的任何内容，因此编译器可以将`++n`操作移到计算`i`值的代码中，如果这样做更方便或更高效的话。
- en: '**12.5 Avoiding Problems Caused by Side Effects**'
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.5 避免副作用引起的问题**'
- en: 'Because it’s often difficult to see the impact of side effects in your code,
    it’s a good idea to try to limit your program’s exposure to problems with side
    effects. Of course, the best way to do this is to eliminate side effects altogether
    in your programs. Unfortunately, that isn’t a realistic option. Many algorithms
    depend upon side effects for proper operation (functions returning multiple results
    via reference parameters or even global variables are good examples). You can,
    however, reduce unintended consequences of side effects by observing a few simple
    rules:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 因为通常很难看到代码中副作用的影响，所以尽量限制程序暴露于副作用问题中是个好主意。当然，最好的方法是完全消除程序中的副作用。不幸的是，这并不是一个现实的选择。许多算法依赖副作用才能正常运行（通过引用参数或甚至全局变量返回多个结果的函数就是一个很好的例子）。然而，您可以通过遵循一些简单的规则来减少副作用带来的不良后果：
- en: Avoid placing side effects in Boolean expressions within program flow control
    statements such as `if`, `while`, and `do..until`.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免在程序流程控制语句（如`if`、`while`和`do..until`）中的布尔表达式中引入副作用。
- en: If a side effect exists on the right side of an assignment operator, try moving
    the side effect into its own statement before or after the assignment (depending
    on whether the assignment statement uses the value of the object before or after
    it applies the side effect).
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果赋值运算符右侧存在副作用，尽量将副作用移入它自己的语句中，放在赋值语句之前或之后（取决于赋值语句是在应用副作用之前还是之后使用该对象的值）。
- en: Avoid multiple assignments in the same statement; break them into separate statements.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免在同一语句中进行多次赋值；将它们分解为单独的语句。
- en: Avoid calling more than one function (that might produce a side effect) in the
    same expression.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免在同一个表达式中调用多个可能产生副作用的函数。
- en: Avoid modifications to global objects (such as side effects) when writing functions.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写函数时，避免修改全局对象（例如副作用）。
- en: Always document side effects thoroughly. For functions, you should note the
    side effect in the function’s documentation, as well as on every call to that
    function.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 始终详细记录副作用。对于函数，应在函数文档中注明副作用，并在每次调用该函数时做出记录。
- en: '**12.6 Forcing a Particular Order of Evaluation**'
  id: totrans-338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.6 强制特定的求值顺序**'
- en: As noted earlier, operator precedence and associativity do not control when
    a compiler may compute subexpressions. For example, if `X`, `Y`, and `Z` are each
    subexpressions (which could be anything from a single constant or variable reference
    to a complex expression in and of themselves), then an expression of the form
    `X / Y * Z` does not imply that the compiler computes the value for `X` before
    it computes the value for `Y` and `Z`. In fact, the compiler is free to compute
    the value for `Z` first, then `Y`, and finally `X`. Operator precedence and associativity
    require only that the compiler must compute the value of `X` and `Y` (in any order)
    before computing `X/Y`, and must compute the value of the subexpression `X/Y`
    before computing `(X / Y) * Z`. Of course, compilers can transform expressions
    via applicable algebraic transformations, but they’re generally careful about
    doing so, because not all standard algebraic transformations apply in limited-precision
    arithmetic.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，运算符优先级和结合性并不控制编译器何时计算子表达式。例如，如果`X`、`Y`和`Z`都是子表达式（它们可以是从单一常量或变量引用到复杂的表达式本身），那么形如`X
    / Y * Z`的表达式并不意味着编译器会先计算`X`的值，再计算`Y`和`Z`的值。实际上，编译器可以自由选择先计算`Z`的值，然后是`Y`，最后是`X`。运算符优先级和结合性仅要求编译器必须在计算`X/Y`之前，先计算`X`和`Y`的值（顺序可以任意），并且必须在计算`(X
    / Y) * Z`之前，先计算子表达式`X/Y`的值。当然，编译器可以通过适用的代数变换来改变表达式，但它们通常会小心操作，因为并非所有标准的代数变换在有限精度的算术运算中都适用。
- en: 'Although compilers can compute subexpressions in any order they choose (which
    is why side effects can create obscure problems), they usually avoid rearranging
    the order of actual computations. For example, mathematically, the following two
    expressions are equivalent following the standard rules of algebra (versus limited-precision
    computer arithmetic):'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然编译器可以按照自己选择的顺序计算子表达式（这也是为什么副作用可能会导致难以察觉的问题），但它们通常避免重新排列实际计算的顺序。例如，在数学上，以下两个表达式在遵循标准代数规则（而非有限精度计算机算术）的情况下是等价的：
- en: '[PRE80]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'In standard mathematics, this identity exists because the multiplication operator
    is *commutative*; that is, *A* × *B* is equal to *B* × *A*. Indeed, these two
    expressions will generally produce the same result as long as they are computed
    as follows:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准数学中，这个恒等式成立是因为乘法运算符是*交换律*的；即，*A* × *B* 等于 *B* × *A*。实际上，只要按以下方式计算，这两个表达式通常会产生相同的结果：
- en: '[PRE81]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'The parentheses are used here not to show precedence, but to group calculations
    that the CPU must perform as a unit. That is, the statements are equivalent to:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用括号并不是为了表示优先级，而是为了将计算分组为CPU必须作为一个整体执行的单元。也就是说，这些语句等价于：
- en: '[PRE82]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'In most algebraic systems, `C` and `D` should have the same value. To understand
    why `C` and `D` may not be equivalent, consider what happens when `X`, `Y`, and
    `Z` are all integer objects with the values `5`, `2`, and `3`, respectively:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数代数系统中，`C`和`D`应该有相同的值。为了理解为什么`C`和`D`可能不等价，可以考虑当`X`、`Y`和`Z`都是整数对象，且其值分别为`5`、`2`和`3`时会发生什么：
- en: '[PRE83]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Again, this is why compilers are careful about algebraically rearranging expressions.
    Most programmers realize that `X * (Y / Z)` is not the same thing as `(X * Y)
    / Z`. Most compilers realize this too. In theory, a compiler should translate
    an expression of the form `X * Y / Z` as though it were `(X * Y) / Z`, because
    the multiplication and division operators have the same precedence and are left
    associative. However, good programmers never rely on the rules of associativity
    to guarantee this. Although most compilers will correctly translate this expression
    as intended, the next engineer who comes along might not realize what’s going
    on. Therefore, explicitly including the parentheses to clarify the intended evaluation
    is a good idea. Better still, treat integer truncation as a side effect and break
    the expression down into its constituent computations (using three-address-like
    expressions) to ensure the proper order of evaluation.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这也是编译器在代数变换表达式时非常小心的原因。大多数程序员都意识到，`X * (Y / Z)`与`(X * Y) / Z`并不相同。大多数编译器也意识到了这一点。从理论上讲，编译器应该将`X
    * Y / Z`这样的表达式翻译为`(X * Y) / Z`，因为乘法和除法操作符具有相同的优先级并且是左结合的。然而，好的程序员从不依赖结合性规则来保证这一点。尽管大多数编译器会按照预期正确地翻译这个表达式，但下一个工程师可能并不明白发生了什么。因此，明确地包含括号以澄清预期的求值顺序是个好主意。更好的做法是，将整数截断视为副作用，并将表达式分解为其组成计算（使用类似三地址的表达式），以确保正确的求值顺序。
- en: Integer arithmetic obviously obeys its own rules, and those of real algebra
    don’t always apply. However, don’t assume that floating-point arithmetic doesn’t
    suffer from the same set of problems. Any time you’re doing limited-precision
    arithmetic involving the possibility of rounding, truncation, overflow, or underflow—as
    is the case with floating-point arithmetic—standard real-arithmetic algebraic
    transformations may not be legal. In other words, applying arbitrary real-arithmetic
    transformations to a floating-point expression can introduce inaccuracies in the
    computation. Therefore, a good compiler won’t perform these types of transformations
    on real expressions. Unfortunately, some compilers do apply the rules of real
    arithmetic to floating-point operations. Most of the time, the results they produce
    are reasonably correct (within the limitations of the floating-point representation);
    in some special cases, however, they’re particularly bad.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 整数运算显然遵循其自身的规则，而实数代数的规则并不总是适用。然而，不要假设浮点运算不受相同问题的影响。每当进行有限精度的运算，涉及到舍入、截断、溢出或下溢的可能性时——就像浮点运算一样——标准的实数代数变换可能不合法。换句话说，对浮点表达式应用任意的实数代数变换可能会引入计算的不准确性。因此，一个好的编译器不会对实数表达式进行这些类型的变换。不幸的是，一些编译器确实会将实数算术规则应用于浮点运算。大多数情况下，它们产生的结果是相对正确的（在浮点表示的限制范围内）；然而，在一些特殊情况下，它们的结果特别糟糕。
- en: In general, if you must control the order of evaluation and when the program
    computes subcomponents of an expression, your only choice is to use assembly language.
    Subject to minor issues, such as out-of-order instruction execution, you can specify
    exactly when your software will compute various components of an expression when
    implementing the expression in assembly code. For very accurate computations,
    when the order of evaluation can affect the results you obtain, assembly language
    may be the safest approach. Although fewer programmers are capable of reading
    and understanding it, there’s no question that it allows you to exactly specify
    the semantics of an arithmetic expression—what you read is what you get without
    any modification by the assembler. This simply isn’t true for most HLL systems.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，如果你必须控制求值顺序以及程序何时计算表达式的子组件，你唯一的选择是使用汇编语言。尽管存在一些小问题，例如指令执行顺序不一致，但在实现汇编代码时，你可以精确地指定软件在何时计算表达式的各个组件。对于非常精确的计算，当求值顺序会影响你获得的结果时，汇编语言可能是最安全的方法。尽管并不是所有程序员都能读懂和理解汇编语言，但毫无疑问，它允许你准确地指定算术表达式的语义——你所看到的就是你得到的，不会被汇编器修改。这在大多数高级语言系统中并不成立。
- en: '**12.7 Short-Circuit Evaluation**'
  id: totrans-351
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.7 短路求值**'
- en: For certain arithmetic and logical operators, if one component of the expression
    has a certain value, the value for the whole expression is automatically known
    regardless of the values of the expression’s remaining components. A classic example
    is the multiplication operator. If you have an expression `A * B` and you know
    that either `A` or `B` is `0`, there’s no need to compute the other component,
    because the result is already `0`. If the cost of computing the subexpressions
    is expensive relative to the cost of a comparison, then a program can save some
    time by testing the first component to determine if it needs to bother computing
    the second component. This optimization is known as *short-circuit evaluation*
    because the program skips over (“short-circuits” in electronics terminology) computing
    the remainder of the expression.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些算术和逻辑运算符，如果表达式的一个组成部分具有某个值，则无论表达式的其他部分值如何，整个表达式的值都会自动确定。一个经典的例子是乘法运算符。如果你有一个表达式`A
    * B`，并且知道`A`或`B`之一是`0`，那么就无需计算另一个组成部分，因为结果已经是`0`。如果计算子表达式的代价相对于比较的代价较高，那么程序可以通过测试第一个组件来节省一些时间，以确定是否需要继续计算第二个组件。这个优化被称为*短路求值*，因为程序跳过了（在电子学术语中是“短路”）计算表达式的剩余部分。
- en: Although a couple of arithmetic operations could employ short-circuit evaluation,
    the cost of checking for the optimization is usually more expensive than just
    completing the computation. Multiplication, for example, could use short-circuit
    evaluation to avoid multiplication by zero, as just described. However, in real
    programs, multiplication by zero occurs so infrequently that the cost of the comparison
    against zero in all the other cases generally overwhelms any savings achieved
    by avoiding multiplication by zero. For this reason, you’ll rarely see a language
    system that supports short-circuit evaluation for arithmetic operations.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管一些算术运算可以使用短路求值，但检查优化的代价通常比完成计算的代价要高。例如，乘法可以使用短路求值来避免乘以零，如前所述。然而，在实际程序中，乘以零的情况很少发生，因此在所有其他情况下进行零值比较的成本通常超过了通过避免乘以零所带来的节省。因此，你很少会看到支持算术运算短路求值的语言系统。
- en: '**12.7.1 Using Short-Circuit Evaluation with Boolean Expressions**'
  id: totrans-354
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.7.1 使用短路求值与布尔表达式**'
- en: 'One type of expression that *can* benefit from short-circuit evaluation is
    a Boolean/logical expression. Boolean expressions are good candidates for short-circuit
    evaluation for three reasons:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 一种*可以*受益于短路求值的表达式是布尔/逻辑表达式。布尔表达式有三个原因使它们成为短路求值的好候选者：
- en: Boolean expressions produce only two results, `true` and `false`; therefore,
    it’s highly likely (50/50 chance, assuming random distribution) that one of the
    short-circuit “trigger” values will appear.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布尔表达式只有两种结果，`true`和`false`；因此，出现短路“触发”值的概率很高（50/50的机会，假设随机分布）。
- en: Boolean expressions tend to be complex.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布尔表达式往往很复杂。
- en: Boolean expressions occur frequently in programs.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布尔表达式在程序中经常出现。
- en: Because of these characteristics, you’ll find that many compilers use short-circuit
    evaluation when processing Boolean expressions.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些特性，你会发现许多编译器在处理布尔表达式时使用短路求值。
- en: 'Consider the following two C statements:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑以下两个C语言语句：
- en: '[PRE84]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Note that if `B` is `false`, then `A` will be `false` regardless of `C`’s value.
    Similarly, if `E` is `true`, then `D` will be `true` regardless of `F`’s value.
    We can, therefore, compute the values for `A` and `D` as follows:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果`B`为`false`，那么无论`C`的值如何，`A`都会是`false`。类似地，如果`E`为`true`，那么无论`F`的值如何，`D`都会是`true`。因此，我们可以如下计算`A`和`D`的值：
- en: '[PRE85]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Now this might seem like a whole lot of extra work (it’s certainly more typing!),
    but if `C` and `F` represent complex Boolean expressions, then this code sequence
    could possibly run much faster if `B` is usually `false` and `E` is usually `true`.
    Of course, if your compiler fully supports short-circuit evaluation, you’d never
    type this code; the compiler would generate the equivalent code for you.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这看起来可能是很多额外的工作（确实是更多的输入！），但如果`C`和`F`代表复杂的布尔表达式，那么如果`B`通常为`false`，而`E`通常为`true`，那么这段代码可能会运行得更快。当然，如果你的编译器完全支持短路求值，你根本不需要输入这段代码；编译器会为你生成等效的代码。
- en: By the way, the converse of short-circuit evaluation is *complete Boolean evaluation*.
    In complete Boolean evaluation, the compiler emits code that always computes each
    subcomponent of a Boolean expression. Some languages (such as C, C++, C#, Swift,
    and Java) specify the use of short-circuit evaluation. A few languages (such as
    Ada) let the programmer specify whether to use short-circuit or complete Boolean
    evaluation. Most languages (such as Pascal) don’t define whether expressions will
    use short-circuit or complete Boolean evaluation—the language leaves the choice
    up to the implementer. Indeed, the same compiler could use complete Boolean evaluation
    for one instance of an expression and use short-circuit evaluation for another
    occurrence of that same expression in the same program. Unless you’re using a
    language that strictly defines the type of Boolean evaluation, you’ll have to
    check with your specific compiler’s documentation to determine how it processes
    Boolean expressions. (Remember to avoid compiler-specific mechanisms if there’s
    a chance you’ll have to compile your code with a different compiler in the future.)
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，短路运算的对立面是*完整布尔运算*。在完整布尔运算中，编译器生成的代码始终计算布尔表达式的每个子组件。一些语言（如C、C++、C#、Swift和Java）规定使用短路运算。一些语言（如Ada）允许程序员指定是否使用短路或完整布尔运算。大多数语言（如Pascal）没有定义表达式是否使用短路或完整布尔运算——该语言将选择权留给实现者。实际上，同一个编译器可能在同一程序中，对于某个表达式的一个实例使用完整布尔运算，而对于该表达式的另一个实例使用短路运算。除非你使用的是严格定义布尔运算类型的语言，否则你需要查看你所使用的编译器文档，了解它是如何处理布尔表达式的。（如果将来可能需要使用不同的编译器编译代码，记得避免使用特定于编译器的机制。）
- en: 'Look again at the expansions of the earlier Boolean expressions. It should
    be clear that the program won’t evaluate `C` and `F` if `A` is `false` and `D`
    is `true`. Therefore, the left-hand side of a conjunction (`&&`) or disjunction
    (`||`) operator can act as a gate, preventing the execution of the right-hand
    side of the expression. This is an important point and, indeed, many algorithms
    depend on this property for correct operation. Consider the following (very common)
    C statement:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 再看看之前布尔表达式的展开。应该很清楚，如果`A`为`false`并且`D`为`true`，程序将不会计算`C`和`F`。因此，连接运算符（`&&`）或析取运算符（`||`）的左侧可以充当门控，防止执行表达式右侧的部分。这是一个重要的点，实际上，许多算法依赖于这个特性来保证正确运行。考虑下面这个（非常常见的）C语句：
- en: '[PRE86]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: This example could fail if it used complete Boolean evaluation. Consider the
    case where the `ptr` variable contains `NULL`. With short-circuit evaluation the
    program will not compute the subexpression `*ptr !=` '`\0`'`;` because it realizes
    the result is always `false`. As a result, control immediately transfers to the
    first statement beyond the ending brace in this `if` statement. Consider, however,
    what would happen if this compiler utilized complete Boolean evaluation instead.
    After determining that `ptr` contains `NULL`, the program would still attempt
    to dereference `ptr`. Unfortunately, this attempt would probably produce a runtime
    error. Therefore, complete Boolean evaluation would cause this program to fail,
    even though it dutifully checks to make sure that access via pointer is legal.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用完整的布尔运算，可能会导致这个示例失败。考虑`ptr`变量包含`NULL`的情况。使用短路运算时，程序不会计算子表达式`*ptr != '\0'`；因为它意识到结果总是`false`。因此，控制立即转移到这个`if`语句中结束括号后的第一条语句。然而，假设该编译器使用的是完整的布尔运算，会发生什么情况呢？在确定`ptr`包含`NULL`之后，程序仍然会尝试解引用`ptr`。不幸的是，这个尝试可能会产生运行时错误。因此，完整的布尔运算会导致该程序失败，尽管它认真地检查了通过指针访问是否合法。
- en: 'Another semantic difference between complete and short-circuit Boolean evaluation
    has to do with side effects. In particular, if a subexpression does not execute
    because of short-circuit evaluation, then that subexpression doesn’t produce any
    side effects. This behavior is incredibly useful but inherently dangerous. It
    is useful insofar as some algorithms absolutely depend upon short-circuit evaluation.
    It is dangerous because some algorithms also expect all the side effects to occur,
    even if the expression evaluates to `false` at some point. As an example, consider
    the following bizarre (but absolutely legal) C statement, which advances a “cursor”
    pointer to the next 8-byte boundary in a string or the end of the string (whichever
    comes first):'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 完全布尔求值和短路布尔求值之间的另一个语义差异与副作用有关。特别是，如果由于短路求值某个子表达式没有被执行，那么该子表达式就不会产生任何副作用。这种行为非常有用，但本质上是危险的。它之所以有用，是因为某些算法绝对依赖于短路求值。它之所以危险，是因为某些算法也期望所有副作用都能发生，即使在某个时刻表达式的值为`false`。例如，考虑以下奇特（但完全合法）的C语句，它将一个“游标”指针推进到字符串的下一个8字节边界，或者字符串的末尾（以先到者为准）：
- en: '[PRE87]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: This statement begins by incrementing a pointer and then fetching a byte from
    memory (pointed to by `ptr`). If the byte fetched was `0`, execution of this expression/statement
    immediately stops, as the entire expression evaluates to `false` at that point.
    If the character fetched is not `0`, the process repeats up to seven more times.
    At the end of this sequence, either `ptr` points at a `0` byte or it points 8
    bytes beyond the original position. The trick here is that the expression immediately
    terminates upon reaching the end of the string rather than mindlessly skipping
    beyond that point.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 这个语句首先递增指针，然后从内存中获取一个字节（由`ptr`指向）。如果获取的字节是`0`，则此表达式/语句的执行会立即停止，因为此时整个表达式的值为`false`。如果获取的字符不是`0`，则该过程会重复最多七次。在这一序列的末尾，`ptr`要么指向`0`字节，要么指向比原始位置前进8个字节的位置。这里的技巧是，在到达字符串的末尾时，表达式会立即终止，而不是盲目地跳过该点。
- en: Of course, there are complementary examples that demonstrate desirable behavior
    when side effects occur in Boolean expressions involving complete Boolean evaluation.
    The important thing to note is that no one scheme is correct or incorrect; it
    all depends on context. In different situations, a given algorithm may require
    the use of short-circuit Boolean evaluation or complete Boolean evaluation to
    produce correct results. If the definition of the language you’re using doesn’t
    explicitly specify which scheme to use, or you want to use the other one (such
    as complete Boolean evaluation in C), then you have to write your code such that
    it forces the evaluation scheme you prefer.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，也有一些互补的例子，展示了当在布尔表达式中发生副作用时，完全布尔求值会带来期望的行为。需要注意的重要一点是，没有一种方案是绝对正确或错误的；这一切取决于具体的上下文。在不同的情况下，给定的算法可能需要使用短路布尔求值或完全布尔求值才能得到正确的结果。如果你使用的语言的定义没有明确指定使用哪种方案，或者你想使用另一种方案（例如C语言中的完全布尔求值），那么你就需要编写代码以强制使用你偏好的求值方案。
- en: '**12.7.2 Forcing Short-Circuit or Complete Boolean Evaluation**'
  id: totrans-373
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.7.2 强制使用短路或完全布尔求值**'
- en: 'Forcing complete Boolean evaluation in a language where short-circuit evaluation
    is used (or may be used) is relatively easy. All you have to do is break the expression
    into individual statements, place the result of each subexpression into a variable,
    and then apply the conjunction and disjunction operators to these temporary variables.
    For example, consider the following conversion:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用（或可能使用）短路求值的语言中，强制执行完全布尔求值相对容易。你只需要将表达式拆分成各个独立的语句，将每个子表达式的结果存入一个变量中，然后对这些临时变量应用合取和析取运算符。例如，考虑以下转换：
- en: '[PRE88]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: The Boolean expression within the `if` statement still uses short-circuit evaluation.
    However, because this code evaluates the subexpressions prior to the `if` statement,
    this code ensures that all of the side effects produced by the `f()`, `g()`, and
    `predicate()` functions will occur.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '`if`语句中的布尔表达式仍然使用短路求值。然而，由于这段代码在`if`语句之前就对子表达式进行了求值，这段代码确保了`f()`、`g()`和`predicate()`函数产生的所有副作用都会发生。'
- en: Suppose you want to go the other way. That is, what if your language supports
    only complete Boolean evaluation (or doesn’t specify the evaluation type), and
    you want to force short-circuit evaluation? This direction is a little more work
    than the converse, but it’s still not difficult.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想反过来做。也就是说，如果你的语言只支持完整布尔求值（或没有指定求值类型），你想强制短路求值该怎么办？这种方向的工作量比反向略多，但仍然不难。
- en: Consider the following Pascal code:^([8](footnotes.xhtml#ch12fn8))
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下Pascal代码：^([8](footnotes.xhtml#ch12fn8))
- en: '[PRE89]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'To force short-circuit Boolean evaluation, you need to test the value of the
    first subexpression, and, only if it evaluates to `true`, evaluate the second
    subexpression (and the conjunction of the two expressions). You can do this with
    the following code:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 为了强制短路布尔求值，你需要测试第一个子表达式的值，只有当它求值为`true`时，才评估第二个子表达式（以及这两个表达式的连接）。你可以使用以下代码实现：
- en: '[PRE90]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: This code simulates short-circuit evaluation by using `if` statements to block
    (or force) execution of the `g()` and `predicate()` functions based on the current
    state of the Boolean expression (kept in the `boolResult` variable).
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码通过使用`if`语句来模拟短路求值，基于布尔表达式的当前状态（保存在`boolResult`变量中），阻止（或强制）执行`g()`和`predicate()`函数。
- en: Converting an expression to force short-circuit evaluation or complete Boolean
    evaluation looks as though it requires far more code than the original forms.
    If you’re concerned about the efficiency of this translation, relax. Internally,
    the compiler translates those Boolean expressions to three-address code that is
    similar to the translation that you did manually.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 将一个表达式转换为强制短路求值或完整布尔求值，似乎需要比原始形式更多的代码。如果你担心这种转换的效率，请放心。内部，编译器将这些布尔表达式转换为类似你手动翻译的三地址代码。
- en: '**12.7.3 Comparing Short-Circuit and Complete Boolean Evaluation Efficiency**'
  id: totrans-384
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**12.7.3 比较短路和完整布尔求值效率**'
- en: While you might have inferred from the preceding discussion that complete Boolean
    evaluation and short-circuit evaluation have equivalent efficiencies, that’s not
    the case. If you’re processing complex Boolean expressions or the cost of some
    of your subexpressions is rather high, then short-circuit evaluation is generally
    faster than complete Boolean evaluation. As to which form produces less object
    code, they’re roughly equivalent, and the exact difference will depend entirely
    upon the expression you’re evaluating.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可能从前面的讨论中推测出完整的布尔求值和短路求值具有相同的效率，但事实并非如此。如果你正在处理复杂的布尔表达式，或者某些子表达式的成本较高，那么短路求值通常比完整布尔求值更快。至于哪种形式生成的目标代码更少，它们大致相同，具体差异将完全依赖于你正在求值的表达式。
- en: To understand the efficiency issues surrounding complete versus short-circuit
    Boolean evaluation, look at the following HLA code, which implements this Boolean
    expression using both forms:^([9](footnotes.xhtml#ch12fn9))
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解完整与短路布尔求值周围的效率问题，查看以下HLA代码，该代码同时使用两种形式实现了这个布尔表达式：^([9](footnotes.xhtml#ch12fn9))
- en: '[PRE91]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Here’s the same expression using short-circuit Boolean evaluation:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用短路布尔求值的相同表达式：
- en: '[PRE92]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: As you can see by simply counting statements, the version using short-circuit
    evaluation is slightly shorter (11 instructions versus 12). However, the short-circuit
    version will probably run much faster because half the time the code will evaluate
    only two of the three expressions. This code evaluates all three subexpressions
    only when the first subexpression, `a < f(x)`, evaluates to `true` and the second
    expression, `b != g(y)`, evaluates to `false`. If the outcomes of these Boolean
    expressions are equally probable, this code will test all three subexpressions
    25 percent of the time. The remainder of the time it has to test only two subexpressions
    (50 percent of the time it will test `a < f(x)` and `predicate(a + b)`, 25 percent
    of the time it will test `a < f(x)` and `b != g(y)`, and the remaining 25 percent
    of the time it will need to test all three conditions).
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，通过简单地计数语句，使用短路求值的版本稍微短一些（11条指令对12条指令）。然而，短路版本可能会运行得更快，因为在一半的时间里，代码只会求值三个表达式中的两个。只有当第一个子表达式`a
    < f(x)`求值为`true`，且第二个表达式`b != g(y)`求值为`false`时，这段代码才会评估所有三个子表达式。如果这些布尔表达式的结果是等概率的，那么这段代码将有25%的时间测试所有三个子表达式。其余时间它只需要测试两个子表达式（50%的时间它将测试`a
    < f(x)`和`predicate(a + b)`，25%的时间它将测试`a < f(x)`和`b != g(y)`，剩下的25%时间它将需要测试所有三个条件）。
- en: The interesting thing to note about these two assembly language sequences is
    that complete Boolean evaluation tends to maintain the state of the expression
    (`true` or `false`) in an actual variable, whereas short-circuit evaluation maintains
    the current state of the expression by the program’s position in the code. Take
    another look at the short-circuit example. Note that it does not maintain the
    Boolean results from each of the subexpressions anywhere other than the position
    in the code. For example, if you get to the `TryOR` label in this code, you know
    that the subexpression involving conjunction (logical AND) is `false`. Likewise,
    if the program executes the call to `g(y)`, you know that the first subexpression
    in the example, `a < f(x)`, has evaluated to `true`. When you make it to the `DoStmts`
    label, you know that the entire expression has evaluated to `true`.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的有趣之处在于这两个汇编语言序列，完全的布尔运算评估倾向于在实际变量中维持表达式的状态（`true` 或 `false`），而短路评估则通过程序在代码中的位置维持当前的表达式状态。再看一遍短路示例。请注意，它并不会在代码中的其他位置保存每个子表达式的布尔结果，只有在代码中的位置会保存。例如，如果你到达了这段代码中的
    `TryOR` 标签，你就知道涉及结合（逻辑与）的子表达式是 `false`。同样，如果程序执行了对 `g(y)` 的调用，你就知道示例中的第一个子表达式
    `a < f(x)` 已经被评估为 `true`。当你到达 `DoStmts` 标签时，你就知道整个表达式已经评估为 `true`。
- en: 'If the execution time for the `f()`, `g()`, and `predicate()` functions is
    roughly the same in the current example, you can greatly improve the code’s performance
    with a nearly trivial modification:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在当前示例中，`f()`、`g()` 和 `predicate()` 函数的执行时间大致相同，你可以通过几乎微不足道的修改大大提升代码的性能：
- en: '[PRE93]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Again, if you assume that the outcome of each subexpression is random and evenly
    distributed (that is, there is a 50/50 chance that each subexpression produces
    `true`), then this code will, on average, run about 50 percent faster than the
    previous version. Why? Moving the test for `predicate()` to the beginning of the
    code fragment means the code can now determine with one test whether it needs
    to execute the body. Because 50 percent of the time `predicate()` returns `true`,
    you can determine if you’re going to execute the loop body with a single test
    about half the time. In the earlier example, it always took at least two tests
    to determine if we were going to execute the loop body.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 再次假设每个子表达式的结果是随机且均匀分布的（也就是说，每个子表达式产生 `true` 的概率为 50/50），那么这个代码的执行速度平均会比之前的版本快约
    50%。为什么？将 `predicate()` 的测试移到代码段的开始意味着代码现在可以通过一次测试来确定是否需要执行代码体。因为 `predicate()`
    有 50% 的时间会返回 `true`，你可以通过一次测试来确定是否会执行循环体。在之前的示例中，至少需要两次测试才能确定是否执行循环体。
- en: 'The two assumptions here (that the Boolean expressions are equally likely to
    produce `true` or `false` and that the costs of computing each subexpression are
    equal) rarely hold in practice. However, this means that you have an even greater
    opportunity to optimize your code, not less. For example, if the cost of calling
    the `predicate()` function is high (relative to the computation of the remainder
    of the expression), then you’ll want to arrange the expression so that it calls
    `predicate()` only when it absolutely must. Conversely, if the cost of calling
    `predicate()` is low compared to the cost of computing the other subexpressions,
    then you’ll want to call it first. The situation for the `f()` and `g()` functions
    is similar. Because the logical AND operation is commutative, the following two
    expressions are semantically equivalent (in the absence of side effects):'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个假设（布尔表达式同样可能产生 `true` 或 `false`，以及计算每个子表达式的成本相等）在实际中很少成立。然而，这意味着你有更多的机会来优化代码，而不是减少机会。例如，如果调用
    `predicate()` 函数的成本很高（相对于计算表达式其余部分的成本），那么你会希望安排表达式，使得只有在绝对必要时才调用 `predicate()`。相反，如果调用
    `predicate()` 的成本相对较低，比较于计算其他子表达式的成本，那么你会希望优先调用它。对于 `f()` 和 `g()` 函数的情况也是类似的。因为逻辑与操作是交换律的，以下两个表达式在语义上是等价的（没有副作用的情况下）：
- en: '[PRE94]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: When the compiler uses short-circuit evaluation, the first expression executes
    faster than the second if the cost of calling function `f()` is less than the
    cost of calling function `g()`. Conversely, if calling `f()` is more expensive
    than calling `g()`, then the second expression usually executes faster.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 当编译器使用短路评估时，如果调用函数 `f()` 的成本低于调用函数 `g()` 的成本，第一个表达式会比第二个表达式执行得更快。相反，如果调用 `f()`
    的成本高于调用 `g()`，那么第二个表达式通常执行得更快。
- en: 'Another factor that affects the performance of short-circuit Boolean expression
    evaluation is the likelihood that a given Boolean expression will return the same
    value on each call. Consider the following two templates:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 影响短路布尔表达式求值性能的另一个因素是给定布尔表达式在每次调用时返回相同值的可能性。考虑以下两个模板：
- en: '[PRE95]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: When working with conjunctions, try to place the expression that is more likely
    to return `true` on the right-hand side of the conjunction operator (`&&`). Remember,
    for the logical AND operation, if the first operand is `false`, a Boolean system
    employing short-circuit evaluation will not bother to evaluate the second operand.
    For performance reasons, you want to place the operand that is most likely to
    return `false` on the left-hand side of the expression. This will avoid the computation
    of the second operand more often than had you reversed the operands.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理连接操作时，尽量将更可能返回`true`的表达式放在连接操作符（`&&`）的右侧。记住，对于逻辑与操作，如果第一个操作数是`false`，采用短路求值的布尔系统将不会评估第二个操作数。出于性能考虑，您希望将最可能返回`false`的操作数放在表达式的左侧。这将避免更多地计算第二个操作数，相较于将操作数交换位置时。
- en: The situation is reversed for disjunction (`||`). In this case, you’d arrange
    your operands so that *expr3* is more likely to return `true` than *expr4*. By
    organizing your disjunction operations this way, you’ll skip the execution of
    the right-hand expression more often than if you had swapped the operands.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 对于析取（`||`），情况正好相反。在这种情况下，您应将操作数排列，使得 *expr3* 更可能返回`true`而不是*expr4*。通过这种方式组织析取操作，您将比交换操作数时更频繁地跳过执行右侧表达式。
- en: You cannot arbitrarily reorder Boolean expression operands if those expressions
    produce side effects, because the proper computation of those side effects may
    depend upon the exact order of the subexpressions. Rearranging the subexpressions
    may cause a side effect to happen that wouldn’t otherwise occur. Keep this in
    mind when you’re trying to improve performance by rearranging operands in a Boolean
    expression.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 如果布尔表达式会产生副作用，则不能随意重新排列操作数，因为副作用的正确计算可能依赖于子表达式的精确顺序。重新排列子表达式可能导致发生某个本不该发生的副作用。在您尝试通过重新排列布尔表达式中的操作数来提高性能时，请记住这一点。
- en: '**12.8 The Relative Cost of Arithmetic Operations**'
  id: totrans-403
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.8 算术操作的相对成本**'
- en: Most algorithm analysis methodologies use a simplifying assumption that all
    operations take the same amount of time.^([10](footnotes.xhtml#ch12fn10)) This
    assumption is rarely correct, because some arithmetic operations are two orders
    of magnitude slower than other computations. For example, a simple integer addition
    operation is often much faster than an integer multiplication. Similarly, integer
    operations are usually much faster than the corresponding floating-point operations.
    For algorithm analysis purposes, it may be okay to ignore the fact that one operation
    may be *n* times faster than some other operation. For someone interested in writing
    great code, however, knowing which operators are the most efficient is important,
    especially when you have the option of choosing among them.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数算法分析方法都使用简化假设，即所有操作所需时间相同。^([10](footnotes.xhtml#ch12fn10)) 这一假设很少是正确的，因为有些算术操作比其他计算慢两个数量级。例如，一个简单的整数加法操作通常比整数乘法要快得多。类似地，整数操作通常比相应的浮点操作要快。对于算法分析来说，忽略某个操作可能比其他操作快
    *n* 倍这一事实是可以接受的。然而，对于那些希望编写高效代码的人来说，了解哪些操作符最有效是很重要的，尤其是当你有选择的余地时。
- en: Unfortunately, we can’t create a table of operators that lists their relative
    speeds. The performance of a given arithmetic operator will vary by CPU. Even
    within the same CPU family, you see a wide variance in performance for the same
    arithmetic operation. For example, shift and rotate operations are relatively
    fast on a Pentium III (relative, say, to an addition operation). On a Pentium
    4, however, they’re considerably slower. These operations were faster on later
    Intel CPUs. So an operator such as the C/C++ `<<` or `>>` can be fast or slow,
    relative to an addition operation, depending upon which CPU it executes.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们无法创建一个列出操作符相对速度的表格。给定算术操作符的性能会因 CPU 而异。即使在同一 CPU 系列中，相同的算术操作性能也会有很大差异。例如，移位和旋转操作在
    Pentium III 上相对较快（相对于加法操作）。然而，在 Pentium 4 上，它们要慢得多。这些操作在后来的 Intel CPU 上更快。因此，像
    C/C++ 中的`<<`或`>>`操作符可能相对加法操作来说，执行速度快或慢，这取决于它执行的 CPU。
- en: That said, I can provide some general guidelines. For example, on most CPUs
    the addition operation is one of the most efficient arithmetic and logical operations
    around; few CPUs support faster arithmetic or logical operations than addition.
    Therefore, it’s useful to group various operations into classes based on their
    performance relative to an operation like addition (see [Table 12-1](ch12.xhtml#ch12tab1)
    for an example).
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我可以提供一些通用的指导。例如，在大多数CPU上，加法操作是最有效的算术和逻辑操作之一；很少有CPU支持比加法更快的算术或逻辑操作。因此，根据与加法等操作的性能相对关系，将不同的操作分组是很有用的（可以参考[表12-1](ch12.xhtml#ch12tab1)中的示例）。
- en: '**Table 12-1:** Relative Performances of Arithmetic Operations (Guidelines)'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '**表12-1：** 算术操作的相对性能（指导原则）'
- en: '| **Relative performance** | **Operations** |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| **相对性能** | **操作** |'
- en: '| Fastest | Integer addition, subtraction, negation, logical AND, logical OR,
    logical XOR, logical NOT, and comparisons |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 最快 | 整数加法、减法、取反、逻辑与、逻辑或、逻辑异或、逻辑非和比较 |'
- en: '|  | Logical shifts |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '|  | 逻辑移位 |'
- en: '|  | Logical rotates |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '|  | 逻辑旋转 |'
- en: '|  | Multiplication |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '|  | 乘法 |'
- en: '|  | Division |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '|  | 除法 |'
- en: '|  | Floating-point comparisons and negation |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '|  | 浮点比较和取反 |'
- en: '|  | Floating-point addition and subtraction |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '|  | 浮点加法和减法 |'
- en: '|  | Floating-point multiplication |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '|  | 浮点乘法 |'
- en: '| Slowest | Floating-point division |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| 最慢 | 浮点除法 |'
- en: The estimates in [Table 12-1](ch12.xhtml#ch12tab1) are not accurate for all
    CPUs, but they provide a “first approximation” from which you can work until you
    gain more experience with a particular processor. On many processors you’ll find
    anywhere between two and three orders of magnitude difference in the performances
    between the fastest and slowest operations. In particular, division tends to be
    quite slow on most processors (floating-point division is even slower). Multiplication
    is usually slower than addition, but again, the exact variance differs greatly
    between processors.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '[表12-1](ch12.xhtml#ch12tab1)中的估算值并不适用于所有CPU，但它们提供了一个“初步估算”，可以在你对特定处理器获得更多经验之前作为参考。在许多处理器中，你会发现最慢和最快操作之间的性能差距在两个到三个数量级之间。特别是，除法在大多数处理器上通常相当慢（浮点除法甚至更慢）。乘法通常比加法慢，但具体的差异在不同处理器之间差异较大。'
- en: If you absolutely need to do floating-point division, there’s little you can
    do to improve your application’s performance by using a different operation (although,
    in some cases, it is faster to multiply by the reciprocal). However, note that
    you can compute many integer arithmetic calculations using different algorithms.
    For example, a left shift is often less expensive than multiplication by 2\. While
    most compilers automatically handle such “operator conversions” for you, compilers
    aren’t omniscient and can’t always figure out the best way to calculate some result.
    However, if you manually do the “operator conversion” yourself, you don’t have
    to rely on the compiler to get this right for you.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你绝对需要进行浮点除法，使用其他操作对提高应用程序的性能几乎没有帮助（虽然在某些情况下，通过乘以倒数来实现浮点除法会更快）。然而，值得注意的是，你可以使用不同的算法来计算许多整数算术。举例来说，左移操作通常比乘以2便宜。虽然大多数编译器会自动为你处理这种“操作符转换”，但是编译器并非全知全能，并不是每次都能找出最佳的计算方法。然而，如果你自己手动进行“操作符转换”，就不必依赖编译器来正确处理它。
- en: '**12.9 For More Information**'
  id: totrans-420
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**12.9 获取更多信息**'
- en: 'Aho, Alfred V., Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman. *Compilers:
    Principles, Techniques, and Tools*. 2nd ed. Essex, UK: Pearson Education Limited,
    1986.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: Aho, Alfred V.，Monica S. Lam，Ravi Sethi，和Jeffrey D. Ullman. *编译原理：技术与工具*。第2版。英国埃塞克斯：Pearson
    Education Limited，1986年。
- en: 'Barrett, William, and John Couch. *Compiler Construction: Theory and Practice*.
    Chicago: SRA, 1986.'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: Barrett, William，和John Couch. *编译器构造：理论与实践*。芝加哥：SRA，1986年。
- en: 'Fraser, Christopher, and David Hansen. *A Retargetable C Compiler: Design and
    Implementation*. Boston: Addison-Wesley Professional, 1995.'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: Fraser, Christopher，和David Hansen. *可重定向C编译器：设计与实现*。波士顿：Addison-Wesley Professional，1995年。
- en: 'Duntemann, Jeff. *Assembly Language Step-by-Step*. 3rd ed. Indianapolis: Wiley,
    2009.'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: Duntemann, Jeff. *汇编语言逐步教程*。第3版。印第安纳波利斯：Wiley，2009年。
- en: 'Hyde, Randall. *The Art of Assembly Language*. 2nd ed. San Francisco: No Starch
    Press, 2010.'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: Hyde, Randall. *汇编语言的艺术*。第2版。旧金山：No Starch Press，2010年。
- en: 'Louden, Kenneth C. *Compiler Construction: Principles and Practice*. Boston:
    Cengage, 1997.'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: Louden, Kenneth C. *编译器构造：原理与实践*。波士顿：Cengage，1997年。
- en: 'Parsons, Thomas W. *Introduction to Compiler Construction*. New York: W. H.
    Freeman, 1992.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: Parsons, Thomas W. *编译器构造导论*。纽约：W. H. Freeman，1992年。
- en: Willus.com. “Willus.com’s 2011 Win32/64 C Compiler Benchmarks.” Last updated
    April 8, 2012\. *[https://www.willus.com/ccomp_benchmark2.shtml](https://www.willus.com/ccomp_benchmark2.shtml)*.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: Willus.com. “Willus.com的2011 Win32/64 C编译器基准测试。”最后更新于2012年4月8日。*[https://www.willus.com/ccomp_benchmark2.shtml](https://www.willus.com/ccomp_benchmark2.shtml)*。
