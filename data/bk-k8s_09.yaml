- en: '7'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '7'
- en: DEPLOYING CONTAINERS TO KUBERNETES
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 将容器部署到 Kubernetes
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common01.jpg)'
- en: We’re now ready to begin running containers on our working Kubernetes cluster.
    Because Kubernetes has a declarative API, we’ll create various kinds of resources
    to run them, and we’ll monitor the cluster to see what Kubernetes does for each
    type of resource.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已准备好在工作中的 Kubernetes 集群上运行容器。由于 Kubernetes 提供声明式 API，我们将创建各种资源类型来运行它们，并且会监控集群以查看
    Kubernetes 对每种资源类型的处理方式。
- en: Different containers have different use cases. Some might require multiple identical
    instances with autoscaling to perform well under load. Other containers might
    exist solely to run a one-time command. Still others may require a fixed ordering
    to enable selecting a single primary instance and providing controlled failover
    to a secondary instance. Kubernetes provides different *controller* resource types
    for each of those use cases. We’ll look at each in turn, but we’ll begin with
    the most fundamental of them, the *Pod*, which is utilized by all of those use
    cases.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的容器有不同的使用场景。有些容器可能需要多个相同的实例，并具备自动扩缩容功能，以在负载下表现良好。其他容器可能仅用于执行一次性命令。还有一些容器可能需要固定的顺序，以便选择单个主实例，并提供受控的故障转移到副实例。Kubernetes
    为这些使用场景提供了不同的 *控制器* 资源类型。我们将依次查看每个控制器，但我们将从最基本的资源——*Pod* 开始，它被所有这些使用场景所利用。
- en: Pods
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pods
- en: 'A Pod is the most basic resource in Kubernetes and is how we run containers.
    Each Pod can have one or more containers within it. The Pod is used to provide
    the process isolation we saw in [Chapter 2](ch02.xhtml#ch02). Linux kernel namespaces
    are used at the Pod and the container level:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 是 Kubernetes 中最基本的资源，是我们运行容器的方式。每个 Pod 可以包含一个或多个容器。Pod 用于提供我们在[第 2 章](ch02.xhtml#ch02)中看到的进程隔离。Linux
    内核命名空间在 Pod 和容器级别得到应用：
- en: 'mnt Mount points: each container has its own root filesystem; other mounts
    are available to all containers in the Pod.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: mnt 挂载点：每个容器都有自己的根文件系统；其他挂载点对 Pod 中的所有容器都可用。
- en: 'uts Unix time sharing: isolated at the Pod level.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: uts Unix 时间共享：在 Pod 级别进行隔离。
- en: 'ipc Interprocess communication: isolated at the Pod level.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ipc 进程间通信：在 Pod 级别进行隔离。
- en: 'pid Process identifiers: isolated at the container level.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: pid 进程标识符：在容器级别进行隔离。
- en: 'net Network: isolated at the Pod level.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: net 网络：在 Pod 级别进行隔离。
- en: The biggest advantage of this approach is that multiple containers can act like
    processes on the same virtual host, using the `localhost` address to communicate,
    while still being based on separate container images.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方式的最大优势是多个容器可以像同一虚拟主机上的进程一样工作，使用 `localhost` 地址进行通信，同时基于独立的容器镜像。
- en: Deploying a Pod
  id: totrans-13
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 部署 Pod
- en: To get started, let’s create a Pod directly. Unlike the previous chapter, in
    which we used `kubectl run` to have the Pod specification created for us, we’ll
    specify it directly using YAML so that we have complete control over the Pod and
    to prepare us for using controllers to create Pods, providing scalability and
    failover.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始使用，让我们直接创建一个 Pod。与上一章中我们使用 `kubectl run` 自动生成 Pod 规格不同，这次我们将直接使用 YAML 文件进行指定，以便完全控制
    Pod，并为以后使用控制器创建 Pods 做好准备，从而提供可扩展性和故障转移能力。
- en: '**NOTE**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*The example repository for this book is at* [https://github.com/book-of-kubernetes/examples](https://github.com/book-of-kubernetes/examples).
    *See “Running Examples” on [page xx](ch00.xhtml#ch00lev1sec2) for details on getting
    set up.*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*本书的示例仓库在* [https://github.com/book-of-kubernetes/examples](https://github.com/book-of-kubernetes/examples)。*有关设置详细信息，请参见“运行示例”部分，位于[第
    xx 页](ch00.xhtml#ch00lev1sec2)。*'
- en: 'The automation script for this chapter does a full cluster install with three
    nodes that run the control plane and regular applications, providing the smallest
    possible highly available cluster for testing. The automation also creates some
    YAML files for Kubernetes resources. Here’s a basic YAML resource to create a
    Pod running NGINX:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的自动化脚本执行完整的集群安装，包含三个节点，运行控制平面和常规应用，提供最小的高可用集群用于测试。自动化还会创建一些 Kubernetes 资源的
    YAML 文件。以下是一个基本的 YAML 资源，用于创建运行 NGINX 的 Pod：
- en: '*nginx-pod.yaml*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*nginx-pod.yaml*'
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Pods are part of the *core* Kubernetes API, so we just specify a version number
    of `v1` for the `apiVersion`. Specifying `Pod` as the `kind` tells Kubernetes
    exactly what resource we’re creating in the API group. We will see these fields
    in all of our Kubernetes resources.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 是 *核心* Kubernetes API 的一部分，因此我们只需为 `apiVersion` 指定 `v1` 的版本号。指定 `Pod` 作为
    `kind` 可以告诉 Kubernetes 我们在 API 组中创建的资源类型。我们将在所有 Kubernetes 资源中看到这些字段。
- en: The `metadata` field has many uses. For the Pod, we just need to provide the
    one required field of `name`. We don’t specify the `namespace` in the metadata,
    so by default this Pod will end up in the `default` Namespace.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`metadata`字段有许多用途。对于Pod，我们只需要提供一个必需的字段——`name`。我们没有在metadata中指定`namespace`，因此默认情况下，这个Pod将被放入`default`命名空间。'
- en: The remaining field, `spec`, tells Kubernetes everything it needs to know to
    run this Pod. For now we are providing the minimal information, which is a list
    of containers to run, but many other options are available. In this case, we have
    only one container, so we provide just the name and container image Kubernetes
    should use.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的字段`spec`告诉Kubernetes运行此Pod所需的一切。目前，我们提供的是最基本的信息，即要运行的容器列表，但还有许多其他选项可供选择。在这种情况下，我们只有一个容器，因此我们只提供Kubernetes应该使用的容器名称和镜像。
- en: 'Let’s add this Pod to the cluster. The automation added files to */opt*, so
    we can do it from `host01` as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个Pod添加到集群中。自动化将文件添加到了*/opt*，因此我们可以在`host01`上按如下方式操作：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In [Listing 7-1](ch07.xhtml#ch07list1), we can check the Pod’s status.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在[清单 7-1](ch07.xhtml#ch07list1)中，我们可以查看Pod的状态。
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Listing 7-1: Status of NGINX*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 7-1：NGINX状态*'
- en: It can take some time before the Pod shows `Running`, especially if you just
    set up your Kubernetes cluster and it’s still busy deploying core components.
    Keep trying this `kubectl` command to check the status.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在Pod显示为`Running`之前可能需要一些时间，特别是如果你刚刚设置了Kubernetes集群，它仍在忙于部署核心组件。不断尝试这个`kubectl`命令以检查状态。
- en: Instead of typing the `kubectl` command multiple times, you can also use `watch`.
    The `watch` command is a great way to observe changes in your cluster over time.
    Just add `watch` in front of your command, and it will be run for you every two
    seconds.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免多次输入`kubectl`命令，你也可以使用`watch`。`watch`命令是观察集群随时间变化的一个好方法。只需在命令前加上`watch`，它将每两秒钟自动执行一次。
- en: 'We added `-o wide` to the command to see the IP address and node assignment
    for this Pod. Kubernetes manages that for us. In this case, the Pod was scheduled
    on `host03`, so we need to go there to see the running container:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在命令中添加了`-o wide`选项，以查看此Pod的IP地址和节点分配。Kubernetes会为我们管理这些信息。在这种情况下，Pod被调度到了`host03`，所以我们需要去那里查看正在运行的容器：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Run this command on whatever host your NGINX Pod is on.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在NGINX Pod所在的主机上运行此命令。
- en: 'If we collect the Pod ID, we can see the container as well:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们收集了Pod ID，我们还可以看到容器：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This output looks very similar to the output from `kubectl get` in [Listing
    7-1](ch07.xhtml#ch07list1), which is not surprising given that our cluster gets
    that information from the `kubelet` service running on this node, which in turn
    uses the same Container Runtime Interface (CRI) API that `crictl` is also using
    to talk to the container engine.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出看起来非常类似于[清单 7-1](ch07.xhtml#ch07list1)中的`kubectl get`命令输出，这并不令人惊讶，因为我们的集群是通过在该节点上运行的`kubelet`服务获取这些信息的，而`kubelet`服务又使用与`crictl`相同的容器运行时接口（CRI）API与容器引擎进行通信。
- en: Pod Details and Logging
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Pod详情和日志
- en: The ability to use `crictl` with the underlying container engine to explore
    a container running in the cluster is valuable, but it does require us to connect
    to the specific host running the container. Much of the time, we can avoid that
    by using `kubectl` commands to inspect Pods from anywhere by connecting to our
    cluster’s API server. Let’s move back to `host01` and explore the NGINX Pod further.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`crictl`与底层容器引擎一起探查集群中运行的容器非常有价值，但它确实要求我们连接到运行该容器的特定主机。大多数时候，我们可以通过使用`kubectl`命令连接到集群的API服务器，从任何地方检查Pod，从而避免这一点。让我们回到`host01`，进一步探查NGINX
    Pod。
- en: 'In [Chapter 6](ch06.xhtml#ch06), we saw how we could use `kubectl describe`
    to see the status and event log for a cluster node. We can use the same command
    to see the status and configuration details of other Kubernetes resources. Here’s
    the event log for our NGINX Pod:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](ch06.xhtml#ch06)中，我们看到如何使用`kubectl describe`来查看集群节点的状态和事件日志。我们可以使用相同的命令查看其他Kubernetes资源的状态和配置详情。以下是我们NGINX
    Pod的事件日志：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We can use `kubectl describe` with many different Kubernetes resources, so we
    first tell `kubectl` that we are interested in a Pod and provide the name. Because
    we didn’t specify a Namespace, Kubernetes will look for this Pod in the `default`
    Namespace ➊.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`kubectl describe`查看许多不同的Kubernetes资源，因此我们首先告诉`kubectl`我们关注的是一个Pod，并提供Pod的名称。因为我们没有指定命名空间，Kubernetes将默认在`default`命名空间中查找该Pod
    ➊。
- en: '**NOTE**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*We use the default Namespace for most of the examples in this book to save
    typing, but it’s a good practice to use multiple Namespaces to keep applications
    separate, both to avoid naming conflicts and to manage access control. We look
    at Namespaces in more detail in [Chapter 11](ch11.xhtml#ch11).*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们在本书中的大多数示例使用默认命名空间，以减少输入，但使用多个命名空间来将应用分开是一个好习惯，这样可以避免命名冲突并管理访问控制。我们将在 [第11章](ch11.xhtml#ch11)
    中更详细地讨论命名空间。*'
- en: The `kubectl describe` command output provides an event log ➋, which is the
    first place to look for issues when we have problems starting a container.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl describe` 命令的输出提供了事件日志 ➋，这是在启动容器遇到问题时，第一个需要查看的地方。'
- en: Kubernetes takes a few steps when deploying a container. First, it needs to
    schedule it onto a node, which requires that node to be available with sufficient
    resources. Then, control passes to `kubelet` on that node, which has to interact
    with the container engine to pull the image, create a container, and start it.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 在部署容器时需要经过几个步骤。首先，它需要将容器调度到一个节点上，这要求该节点可用且具备足够的资源。然后，控制权转交给该节点上的`kubelet`，它需要与容器引擎交互，拉取镜像，创建容器并启动它。
- en: 'After the container is started, `kubelet` collects the standard out and standard
    error. We can view this output by using the `kubectl logs` command:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 容器启动后，`kubelet` 会收集标准输出和标准错误。我们可以使用 `kubectl logs` 命令查看这些输出：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `kubectl logs` command always refers to a Pod because Pods are the basic
    resource used to run containers, and our Pod has only one container, so we can
    just specify the name of the Pod as a single parameter to `kubectl logs`. As before,
    Kubernetes will look in the `default` Namespace because we didn’t specify the
    Namespace.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl logs` 命令始终指向一个 Pod，因为 Pod 是运行容器的基本资源，而我们的 Pod 只有一个容器，所以我们只需要将 Pod
    的名称作为一个参数传递给 `kubectl logs`。和之前一样，Kubernetes 会在 `default` 命名空间中查找，因为我们没有指定命名空间。'
- en: The container output is available even if the container has exited, so the `kubectl
    logs` command is the place to look if a container is pulled and started successfully
    but then crashes. Of course, we have to hope that the container printed a log
    message explaining why it crashed. In [Chapter 10](ch10.xhtml#ch10), we look at
    what to do if we can’t get a container going and don’t have any log messages.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 即使容器已经退出，容器输出仍然可用，因此如果容器被拉取并成功启动后崩溃，`kubectl logs` 命令是查看日志的地方。当然，我们希望容器打印出一条日志消息，解释为何崩溃。在
    [第10章](ch10.xhtml#ch10) 中，我们将讨论如果容器无法启动且没有日志消息时该怎么办。
- en: 'We’re done with the NGINX Pod, so let’s clean it up:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了 NGINX Pod 的操作，现在让我们清理它：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We can use the same YAML configuration file to delete the Pod, which is convenient
    when we have multiple Kubernetes resources defined in a single file, as a single
    command will delete all of them. The `kubectl` command uses the name of each resource
    defined in the file to perform the delete.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用相同的 YAML 配置文件删除 Pod，这在我们将多个 Kubernetes 资源定义在同一个文件中时非常方便，因为一个命令就能删除所有资源。`kubectl`
    命令使用文件中定义的每个资源的名称来执行删除操作。
- en: Deployments
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署
- en: To run a container, we need a Pod, but that doesn’t mean we generally want to
    create the Pod directly. When we create a Pod directly, we don’t get all of the
    scalability and failover that Kubernetes offers, because Kubernetes will run only
    one instance of the Pod. This Pod will be allocated to a node only on creation,
    with no re-allocation even if the node fails.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行一个容器，我们需要一个 Pod，但这并不意味着我们通常希望直接创建 Pod。当我们直接创建 Pod 时，我们无法获得 Kubernetes 提供的可扩展性和故障转移功能，因为
    Kubernetes 只会运行 Pod 的一个实例。这个 Pod 只会在创建时分配给一个节点，即使该节点发生故障，也不会重新分配。
- en: 'To get scalability and failover, we instead need to create a controller to
    manage the Pod for us. We’ll look at multiple controllers that can run Pods, but
    let’s start with the most common: the *Deployment*.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得可扩展性和故障转移，我们需要创建一个控制器来管理 Pod。我们将介绍多种可以运行 Pods 的控制器，但让我们先从最常见的 *Deployment*
    开始。
- en: Creating a Deployment
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建一个 Deployment
- en: A Deployment manages one or more *identical* Kubernetes Pods. When we create
    a Deployment, we provide a Pod template. The Deployment then creates Pods matching
    that template with the help of a *ReplicaSet*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment 管理一个或多个 *完全相同* 的 Kubernetes Pods。当我们创建一个 Deployment 时，我们提供一个 Pod
    模板。Deployment 然后借助 *ReplicaSet* 创建与该模板匹配的 Pods。
- en: '**DEPLOYMENTS AND REPLICASETS**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**DEPLOYMENTS 和 REPLICASETS**'
- en: Kubernetes has evolved its controller resources over time. The first type of
    controller, the *ReplicationController*, provided only basic functionality. It
    was replaced by the ReplicaSet, which has improvements in how it identifies which
    Pods to manage.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes随着时间的发展，逐步演化了其控制器资源。第一种类型的控制器，*ReplicationController*，仅提供了基本功能。它被ReplicaSet所取代，后者在识别要管理的Pod方面进行了改进。
- en: Part of the reason to replace ReplicationControllers with ReplicaSets is that
    ReplicationControllers were becoming more and more complicated, making the code
    difficult to maintain. The new approach splits up controller responsibility between
    ReplicaSets and Deployments. ReplicaSets are responsible for basic Pod management,
    including monitoring Pod status and performing failover. Deployments are responsible
    for tracking changes to the Pod template caused by configuration changes or container
    image updates. Deployments and ReplicaSets work together, but the Deployment creates
    its own ReplicaSet, so we usually need to interact only with Deployments. For
    this reason, I use the term *Deployment* generically to refer to features provided
    by the ReplicaSet, such as monitoring Pods to provide the requested number of
    replicas.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 替换ReplicationControllers为ReplicaSets的部分原因是ReplicationControllers变得越来越复杂，使得代码难以维护。新的方法将控制器的责任分拆给ReplicaSets和Deployments。ReplicaSets负责基本的Pod管理，包括监控Pod状态和执行故障切换。Deployments则负责跟踪由于配置更改或容器镜像更新而导致的Pod模板的变化。Deployments和ReplicaSets共同工作，但Deployment会创建自己的ReplicaSet，因此我们通常只需要与Deployments交互。出于这个原因，我通常使用*Deployment*这个术语泛指ReplicaSet提供的功能，例如监控Pod并提供所请求的副本数量。
- en: 'Here’s the YAML file we’ll use to create an NGINX Deployment:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将用来创建NGINX Deployment的YAML文件：
- en: '*nginx-deploy.yaml*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*nginx-deploy.yaml*'
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Deployments are in the `apps` API group, so we specify `apps/v1` for `apiVersion`.
    Like every Kubernetes resource, we need to provide a unique name ➊ to keep this
    Deployment separate from any others we might create.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Deployments位于`apps` API组中，因此我们为`apiVersion`指定`apps/v1`。像每个Kubernetes资源一样，我们需要提供一个唯一的名称
    ➊，以便将这个Deployment与我们可能创建的其他Deployment区分开来。
- en: The Deployment specification has a few important fields, so let’s look at them
    in detail. The `replicas` field tells Kubernetes how many identical instances
    of the Pod we want. Kubernetes will work to keep this many Pods running. The next
    field, `selector`, is used to enable the Deployment to find its Pods. The content
    of `matchLabels` must exactly match the content in the `template.metadata.labels`
    field ➋, or Kubernetes will reject the Deployment.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment规格包含几个重要字段，我们来详细看看它们。`replicas`字段告诉Kubernetes我们想要多少个相同的Pod实例。Kubernetes将努力保持这数量的Pod在运行。下一个字段，`selector`，用于使Deployment能够找到它的Pod。`matchLabels`的内容必须与`template.metadata.labels`字段
    ➋中的内容完全匹配，否则Kubernetes将拒绝该Deployment。
- en: Finally, the content of `template.spec` ➌ will be used as the `spec` for any
    Pods created by this Deployment. The fields here can include any configuration
    we can provide for a Pod. This configuration matches *nginx-pod.yaml* that we
    looked at earlier except that we add a CPU resource request ➍ so that we can configure
    autoscaling later on.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`template.spec` ➌的内容将作为此Deployment创建的任何Pod的`spec`。这里的字段可以包括我们为Pod提供的任何配置。此配置与我们之前查看的*nginx-pod.yaml*相匹配，不同之处在于我们添加了一个CPU资源请求
    ➍，以便以后可以配置自动扩缩容。
- en: 'Let’s create our Deployment from this YAML resource file:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从这个YAML资源文件创建我们的Deployment：
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can track the status of the Deployment with `kubectl get`:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`kubectl get`跟踪Deployment的状态：
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'When the Deployment is fully up, it will report that it has three replicas
    ready and available, which means that we now have three separate NGINX Pods managed
    by this Deployment:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当Deployment完全启动时，它将报告已准备好并可用的三个副本，这意味着我们现在有三个由这个Deployment管理的独立NGINX Pod：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The name of each Pod begins with the name of the Deployment. Kubernetes adds
    some random characters to build the name of the ReplicaSet, followed by more random
    characters so that each Pod has a unique name. We don’t need to create or manage
    the ReplicaSet directly, but we can use `kubectl get` to see it:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 每个Pod的名称以Deployment的名称开头。Kubernetes会添加一些随机字符来构建ReplicaSet的名称，然后再加上更多随机字符，以确保每个Pod都有唯一的名称。我们不需要直接创建或管理ReplicaSet，但可以使用`kubectl
    get`来查看它：
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Although we generally interact only with Deployments, it is important to know
    about the ReplicaSet, as some specific errors encountered when creating Pods are
    only reported in the ReplicaSet event log.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们通常只与Deployments交互，但了解ReplicaSet仍然很重要，因为在创建Pod时遇到的一些特定错误只会在ReplicaSet事件日志中报告。
- en: 'The `nginx` prefix on the ReplicaSet and Pod names are purely for convenience.
    The Deployment does not use names to match itself to Pods. Instead, it uses its
    selector to match the labels on the Pod. We can see these labels if we run `kubectl
    describe` on one of the three Pods:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`nginx` 前缀在 ReplicaSet 和 Pod 名称中纯粹是为了方便。Deployment 不使用名称来与 Pods 匹配。相反，它使用选择器来匹配
    Pod 上的标签。如果我们在其中一个 Pod 上运行`kubectl describe`，就能看到这些标签：'
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This matches the Deployment’s selector:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这与 Deployment 的选择器匹配：
- en: '[PRE14]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The Deployment queries the API server to identify Pods matching its selector.
    Whereas the Deployment uses the programmatic API, the `kubectl get` command in
    the following example generates a similar API server query, giving us an opportunity
    to see how that works:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment 查询 API 服务器以识别与其选择器匹配的 Pods。而 Deployment 使用程序化 API，下面的`kubectl get`命令生成了类似的
    API 服务器查询，给我们一个了解其工作原理的机会：
- en: '[PRE15]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Using `kubectl get all` in this case allows us to list multiple different kinds
    of resources as long as they match the selector. As a result, we see not only
    the three Pods but also the ReplicaSet that was created by the Deployment to manage
    those Pods.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，使用`kubectl get all`可以列出多种不同类型的资源，只要它们与选择器匹配。因此，我们不仅能看到三个 Pods，还能看到 Deployment
    为管理这些 Pods 而创建的 ReplicaSet。
- en: It may seem strange that the Deployment uses a selector rather than just tracking
    the Pods it created. However, this design makes it easier for Kubernetes to be
    self-healing. At any time, a Kubernetes node might go offline, or we might have
    a network split, during which some control nodes lose their connection to the
    cluster. If a node comes back online, or the cluster needs to recombine after
    a network split, Kubernetes must be able to look at the current state of all of
    the running Pods and figure out what changes are required to achieve the desired
    state. This might mean that a Deployment that started an additional Pod as the
    result of a node disconnection would need to shut down a Pod when that node reconnects
    so that the cluster can maintain the appropriate number of replicas. Using a selector
    avoids the need for the Deployment to remember all the Pods it has ever created,
    even Pods on failed nodes.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来可能有些奇怪，Deployment 使用选择器而不是仅仅跟踪它创建的 Pods。然而，这种设计使得 Kubernetes 更容易自我修复。在任何时候，Kubernetes
    节点可能会掉线，或者我们可能会遇到网络分割，期间某些控制节点与集群失去连接。如果一个节点重新上线，或者集群在网络分割后需要重新组合，Kubernetes 必须能够查看所有运行中的
    Pods 的当前状态，并找出需要进行哪些更改以实现所需的状态。这可能意味着，当由于节点断开连接导致 Deployment 启动了一个额外的 Pod 时，在该节点重新连接时，Deployment
    需要关闭一个 Pod，以便集群能够保持适当数量的副本。使用选择器避免了 Deployment 需要记住它曾创建过的所有 Pods，即使是那些在失败节点上的
    Pods。
- en: Monitoring and Scaling
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 监控与扩展
- en: 'Because the Deployment is monitoring its Pods to make sure we have the correct
    number of replicas, we can delete a Pod, and it will be automatically re-created:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 Deployment 正在监视它的 Pods，以确保我们有正确数量的副本，所以我们可以删除一个 Pod，它会被自动重新创建：
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As soon as the old Pod is deleted, the Deployment created a new Pod ➊. Similarly,
    if we change the number of replicas for the Deployment, Pods are automatically
    updated. Let’s add another replica:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦旧的 Pod 被删除，Deployment 就会创建一个新的 Pod ➊。类似地，如果我们更改 Deployment 的副本数量，Pods 会自动更新。让我们再添加一个副本：
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first command sets the number of replicas to four. As a result, Kubernetes
    needs to start a new identical Pod to meet the number we requested ➊. We can scale
    the Deployment by updating the YAML file and re-running `kubectl apply`, or we
    can use the `kubectl scale` command to edit the Deployment directly. Either way,
    this is a declarative approach; we are updating the Deployment’s resource declaration;
    Kubernetes then updates the actual state of the cluster to match.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令将副本数量设置为四个。因此，Kubernetes 需要启动一个新的相同 Pod 来满足我们请求的数量 ➊。我们可以通过更新 YAML 文件并重新运行`kubectl
    apply`来扩展 Deployment，或者我们可以使用`kubectl scale`命令直接编辑 Deployment。无论哪种方式，这都是一种声明式方法；我们在更新
    Deployment 的资源声明；然后，Kubernetes 会更新集群的实际状态以使其匹配。
- en: 'Similarly, scaling the Deployment down causes Pods to be automatically deleted:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，缩小 Deployment 会导致 Pods 被自动删除：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: When we scale down, Kubernetes selects two Pods to terminate. These Pods take
    a moment to finish shutting down, at which point we have only two NGINX Pods running.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们缩小时，Kubernetes 会选择两个 Pods 进行终止。这些 Pods 需要一些时间来完成关闭，届时我们只会有两个 NGINX Pods 在运行。
- en: Autoscaling
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自动扩展
- en: For an application that is receiving real requests from users, we would choose
    the number of replicas necessary to provide a quality application, while scaling
    down when possible to reduce the amount of resources used by our application.
    Of course, the load on our application is constantly changing, and it would be
    tedious to monitor each component of our application continually to scale it independently.
    Instead, we can have the cluster perform the monitoring and scaling for us using
    a *HorizontalPodAutoscaler*. The term *horizontal* in this case just refers to
    the fact that the autoscaler can update the number of replicas of the same Pod
    managed by a controller.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于正在接收用户真实请求的应用程序，我们会选择必要的副本数量以提供高质量的应用程序，同时在可能的情况下缩减副本数量，以减少应用程序使用的资源。当然，我们的应用程序负载是不断变化的，持续监控应用程序的每个组件并独立地进行缩放会很繁琐。相反，我们可以让集群为我们执行监控和缩放工作，使用
    *HorizontalPodAutoscaler*。这里的 *horizontal* 术语仅指自动缩放器可以更新由控制器管理的同一 Pod 的副本数量。
- en: 'To configure autoscaling, we create a new resource with a reference to our
    Deployment. The cluster then monitors resources used by the Pods and reconfigures
    the Deployment as needed. We could add a HorizontalPodAutoscaler to our Deployment
    using the `kubectl autoscale` command, but using a YAML resource file so that
    we can keep the autoscale configuration under version control is better. Here’s
    the YAML file:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要配置自动缩放，我们创建一个新的资源，引用我们的部署。然后，集群监控 Pod 使用的资源，并根据需要重新配置部署。我们可以使用 `kubectl autoscale`
    命令将 HorizontalPodAutoscaler 添加到我们的部署中，但使用 YAML 资源文件可以将自动缩放配置保持在版本控制下，这样更好。以下是
    YAML 文件：
- en: '*nginx-scaler.yaml*'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*nginx-scaler.yaml*'
- en: '[PRE19]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the `metadata` field, we add the label `app: nginx`. This does not change
    the behavior of the resource; its only purpose is to ensure that this resource
    shows up if we use an `app=nginx` label selector in a `kubectl get` command. This
    style of tagging the components of an application with consistent metadata is
    a good practice to help others understand what resources go together and to make
    debugging easier.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '在 `metadata` 字段中，我们添加了标签 `app: nginx`。这不会改变资源的行为；其唯一目的是确保如果我们在 `kubectl get`
    命令中使用 `app=nginx` 标签选择器时，这个资源能够显示出来。通过一致的元数据标记应用程序组件的这种方式是一个好习惯，有助于他人理解哪些资源是相关的，并且使调试更容易。'
- en: This YAML configuration uses version 2 of the autoscaler configuration ➊. Providing
    new versions of API resource groups is how Kubernetes accommodates future capability
    without losing any of its backward compatibility. Generally, alpha and beta versions
    are released for new resource groups before the final configuration is released,
    and there is at least one version of overlap between the beta version and the
    final release to enable seamless upgrades.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 YAML 配置使用了版本 2 的自动缩放器配置 ➊。提供新的 API 资源组版本是 Kubernetes 在不失去任何向后兼容性的情况下支持未来功能的方式。通常，在最终配置发布之前，会发布
    alpha 和 beta 版本的资源组，并且 beta 版本与最终版本之间至少有一个版本重叠，以支持无缝升级。
- en: Version 2 of the autoscaler supports multiple resources. Each resource is used
    to calculate a vote on the desired number of Pods, and the largest number wins.
    Adding support for multiple resources requires a change in the YAML layout, which
    is a common reason for the Kubernetes maintainers to create a new resource version.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 自动缩放器的版本 2 支持多个资源。每个资源用于计算对所需 Pod 数量的投票，最大数值将胜出。支持多个资源需要改变 YAML 布局，这是 Kubernetes
    维护者创建新资源版本的常见原因。
- en: We specify our NGINX Deployment ➋ as the target for the autoscaler using its
    API resource group, kind, and name, which is enough to uniquely identify any resource
    in a Kubernetes cluster. We then tell the autoscaler to monitor the CPU utilization
    of the Pods that belong to the Deployment ➍. The autoscaler will work to keep
    average CPU utilization by the Pods close to 50 percent over the long run, scaling
    up or down as necessary. However, the number of replicas will never go beyond
    the range we specify ➌.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 NGINX 部署 ➋ 的 API 资源组、类型和名称将其指定为自动缩放器的目标，这些足以唯一标识 Kubernetes 集群中的任何资源。然后，我们告诉自动缩放器监控属于该部署的
    Pod 的 CPU 使用率 ➍。自动缩放器将努力保持 Pod 的平均 CPU 使用率接近 50%，并根据需要进行扩展或缩减。然而，副本数将永远不会超过我们指定的范围
    ➌。
- en: 'Let’s create our autoscaler using this configuration:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用此配置创建自动缩放器：
- en: '[PRE20]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can query the cluster to see that it was created:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查询集群，查看它是否已被创建：
- en: '[PRE21]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The output shows the autoscaler’s target reference, the current and desired
    resource utilization, and the maximum, minimum, and current number of replicas.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了自动伸缩器的目标引用、当前和期望的资源利用率，以及副本的最大值、最小值和当前值。
- en: We use `hpa` as an abbreviation for `horizontalpodautoscaler`. Kubernetes allows
    us to use either singular or plural names and provides abbreviations for most
    of its resources to save typing. For example, we can type `deploy` for `deployment`
    and even `po` for `pods`. Every extra keystroke counts!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `hpa` 作为 `horizontalpodautoscaler` 的缩写。Kubernetes 允许我们使用单数或复数名称，并为大多数资源提供缩写，以节省输入。例如，我们可以输入
    `deploy` 来代替 `deployment`，甚至可以输入 `po` 来代替 `pods`。每一个额外的击键都很重要！
- en: 'The autoscaler uses CPU utilization data that the `kubelet` is already collecting
    from the container engine. This data is centralized by the metrics server we installed
    as a cluster add-on. Without that cluster add-on, there would be no utilization
    data, and the autoscaler would not make any changes to the Deployment. In this
    case, because we’re not really using our NGINX server instances, they aren’t consuming
    any CPU, and the Deployment is scaled down to a single Pod, the minimum we specified:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 自动伸缩器使用 `kubelet` 已经从容器引擎收集的 CPU 利用率数据。这个数据由我们作为集群附加组件安装的指标服务器集中管理。如果没有这个集群附加组件，就不会有利用率数据，自动伸缩器也不会对部署进行任何更改。在这种情况下，因为我们实际上没有使用我们的
    NGINX 服务器实例，它们没有消耗任何 CPU，部署被缩减到一个 Pod，即我们指定的最小值：
- en: '[PRE22]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The autoscaler has calculated that only one Pod is needed and has scaled the
    Deployment to match. The Deployment then selected a Pod to terminate to reach
    the desired scale.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 自动伸缩器已计算出只需要一个 Pod，并已将部署调整到匹配的规模。然后，部署选择一个 Pod 终止，以达到所需的规模。
- en: For accuracy, the autoscaler will not use CPU data from the Pod if it recently
    started running, and it has logic to prevent it from scaling up or down too often,
    so if you ran through these examples very quickly you might need to wait a few
    minutes before you see it scale.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准确性，自动伸缩器不会使用最近才启动的 Pod 的 CPU 数据，并且它有逻辑来防止过于频繁地进行缩放，因此如果你快速完成了这些示例，你可能需要等待几分钟才能看到其缩放。
- en: We explore Kubernetes resource utilization metrics in more detail when we look
    at limiting resource usage in [Chapter 14](ch14.xhtml#ch14).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 [第 14 章](ch14.xhtml#ch14) 中更详细地探讨 Kubernetes 资源利用率指标。
- en: Other Controllers
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他控制器
- en: Deployments are the most generic and commonly used controller, but Kubernetes
    has some other useful options. In this section, we explore *Job*s and *CronJob*s,
    *StatefulSets*, and *DaemonSets*.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 部署是最通用和最常用的控制器，但 Kubernetes 还有其他一些有用的选项。在本节中，我们将探讨 *Job* 和 *CronJob*、*StatefulSets*
    以及 *DaemonSets*。
- en: Jobs and CronJobs
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 作业和定时作业
- en: Deployments are great for application components because we usually want one
    or more instances to stay running indefinitely. However, for cases for which we
    need to run a command, either once or on a schedule, we can use a Job. The primary
    difference is a Deployment ensures that any container that stops running is restarted,
    whereas a Job can check the exit code of the main process and restart only if
    the exit code is non-zero, indicating failure.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 部署非常适合应用组件，因为我们通常希望一个或多个实例持续运行。然而，对于需要运行命令的情况，无论是一次性运行还是按计划运行，我们可以使用 Job。主要区别在于，部署确保任何停止运行的容器都会重启，而
    Job 可以检查主进程的退出代码，仅当退出代码非零时才会重启，表示失败。
- en: 'A Job definition looks very similar to a Deployment:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 作业定义与部署非常相似：
- en: '*sleep-job.yaml*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*sleep-job.yaml*'
- en: '[PRE23]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The `restartPolicy` can be set to `OnFailure`, in which case the container will
    be restarted for a non-zero exit code, or to `Never`, in which case the Job will
    be completed when the container exits regardless of the exit code.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`restartPolicy` 可以设置为 `OnFailure`，此时容器将在退出代码为非零时重启，或者设置为 `Never`，此时无论退出代码是什么，容器退出后作业将完成。'
- en: 'We can create and view the Job and the Pod it has created:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建并查看作业及其创建的 Pod：
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The Job has created a Pod per the specification provided in the YAML file. The
    Job reflects `0/1` completions because it is waiting for its Pod to exit successfully.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 作业根据 YAML 文件中提供的规范创建了一个 Pod。作业反映出 `0/1` 的完成状态，因为它正在等待其 Pod 成功退出。
- en: 'When the Pod has been running for 30 seconds, it exits with a code of zero,
    indicating success, and the Job and Pod status are updated accordingly:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Pod 运行了 30 秒后，它以零代码退出，表示成功，并且作业和 Pod 状态相应更新：
- en: '[PRE25]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The Pod is still available, which means that we could review its logs if desired,
    but it shows a status of `Completed`, so Kubernetes will not try to restart the
    exited container.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 仍然可用，这意味着我们可以查看其日志（如果需要的话），但它显示为 `Completed` 状态，因此 Kubernetes 不会尝试重新启动已退出的容器。
- en: 'A CronJob is a controller that creates Jobs on a schedule. For example, we
    could set up our sleep Job to run once per day:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: CronJob 是一种按照计划创建 Jobs 的控制器。例如，我们可以设置我们的 sleep Job 每天运行一次：
- en: '*sleep-cronjob.yaml*'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*sleep-cronjob.yaml*'
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The entire contents of the Job specification are embedded inside the `jobTemplate`
    field ➋. To this, we add a `schedule` ➊ that follows the standard format for the
    Unix `cron` command. In this case, `0 3 * * *` indicates that a Job should be
    created at 3:00 AM every day.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Job 规格的全部内容都嵌入在 `jobTemplate` 字段 ➋ 中。然后，我们添加一个遵循 Unix `cron` 命令标准格式的 `schedule`
    ➊。在这个例子中，`0 3 * * *` 表示 Job 应该在每天凌晨 3 点创建。
- en: One of Kubernetes’ design principles is that anything could go down at any time.
    For a CronJob, if the cluster has an issue during the time the Job would be scheduled,
    the Job might not be scheduled, or it might be scheduled twice, this means that
    you should take care to write Jobs in an idempotent way so that they can handle
    missing or duplicated scheduling.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的设计原则之一是任何东西都可能随时发生故障。对于 CronJob，如果集群在 Job 计划执行的时间遇到问题，Job 可能不会按计划执行，或者可能会被执行两次。这意味着你应该小心编写幂等的
    Job，以便它们能够处理缺失或重复的调度。
- en: If we create this CronJob
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们创建这个 CronJob
- en: '[PRE27]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'it now exists in the cluster, but it does not immediately create a Job or a
    Pod:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 它现在已存在于集群中，但不会立即创建 Job 或 Pod：
- en: '[PRE28]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Instead, the CronJob will create a new Job each time its schedule is triggered.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，每当 CronJob 的调度被触发时，它将创建一个新的 Job。
- en: StatefulSets
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: StatefulSets
- en: So far, we’ve been looking at controllers that create identical Pods. With both
    Deployments and Jobs, we don’t really care which Pod is which, or where it is
    deployed, as long as we run enough instances at the right time. However, that
    doesn’t always match the behavior we want. For example, even though a Deployment
    can create Pods with persistent storage, the storage must either be brand new
    for each new Pod, or the same storage must be shared across all Pods. That doesn’t
    align well with a “primary and secondary” architecture such as a database. For
    those cases, we want specific storage to be attached to specific Pods.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看过一些创建相同 Pods 的控制器。对于 Deployments 和 Jobs，我们并不在乎哪个 Pod 是哪个，或者它部署在哪里，只要我们在正确的时间运行足够的实例。然而，这并不总是符合我们所需的行为。例如，尽管
    Deployment 可以创建具有持久存储的 Pods，但存储必须是为每个新的 Pod 创建一个全新的存储，或者同一个存储必须在所有 Pods 之间共享。这与“主从”架构（例如数据库）并不完全匹配。对于这些情况，我们希望将特定的存储附加到特定的
    Pods 上。
- en: At the same time, because Pods can come and go due to hardware failures or upgrades,
    we need a way to manage the replacement of a Pod so that each Pod is attached
    to the right storage. This is the purpose of a *StatefulSet*. A StatefulSet identifies
    each Pod with a number, starting at zero, and each Pod receives matching persistent
    storage. When a Pod must be replaced, the new Pod is assigned the same numeric
    identifier and is attached to the same storage. Pods can look at their hostname
    to determine their identifier, so a StatefulSet is useful both for cases with
    a fixed primary instance as well as cases for which a primary instance is dynamically
    chosen.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，由于 Pod 可能因硬件故障或升级而来去变化，我们需要一种方法来管理 Pod 的替换，以确保每个 Pod 都附加到正确的存储上。这就是 *StatefulSet*
    的目的。StatefulSet 通过编号（从零开始）标识每个 Pod，并为每个 Pod 分配相应的持久存储。当 Pod 必须被替换时，新 Pod 会被分配相同的数字标识符，并附加到相同的存储上。Pods
    可以查看它们的主机名来确定其标识符，因此 StatefulSet 对于需要固定主实例的情况以及动态选择主实例的情况都很有用。
- en: We’ll explore a lot more details related to Kubernetes StatefulSets in the next
    several chapters, including persistent storage and Services. For this chapter,
    we’ll look at a basic example of a StatefulSet and then build on it as we introduce
    other important concepts.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几章中，我们将深入探讨 Kubernetes StatefulSets 的更多细节，包括持久存储和服务。对于这一章，我们将查看 StatefulSet
    的一个基本示例，然后在引入其他重要概念时进一步扩展。
- en: 'For this simple example, let’s create two Pods and show how they each get unique
    storage that stays in place even if the Pod is replaced. We’ll use this YAML resource:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个简单的示例，让我们创建两个 Pods，并展示它们如何获得独特的存储，这些存储即使 Pod 被替换也会保持不变。我们将使用这个 YAML 资源：
- en: '*sleep-set.yaml*'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*sleep-set.yaml*'
- en: '[PRE29]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: There are a few important differences here compared to a Deployment or a Job.
    First, we must declare a `serviceName` to tie this StatefulSet to a Kubernetes
    Service ➊. This connection is used to create a Domain Name Service (DNS) entry
    for each Pod. We must also provide a template for the StatefulSet to use to request
    persistent storage ➌ and then tell Kubernetes where to mount that storage in our
    container ➋.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Deployment 或 Job 相比，这里有一些重要的不同之处。首先，我们必须声明一个 `serviceName`，将这个 StatefulSet
    绑定到 Kubernetes Service ➊。这个连接用于为每个 Pod 创建一个 DNS（域名服务）条目。我们还必须提供一个模板，供 StatefulSet
    用来请求持久化存储 ➌，然后告诉 Kubernetes 在我们的容器中挂载该存储 ➋。
- en: The actual *sleep-set.yaml* file that the automation scripts install includes
    the `sleep` Service definition. We cover Services in detail in [Chapter 9](ch09.xhtml#ch09).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的 *sleep-set.yaml* 文件是自动化脚本安装的，其中包含 `sleep` 服务定义。我们将在[第 9 章](ch09.xhtml#ch09)中详细讲解服务。
- en: 'Let’s create the `sleep` StatefulSet:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建 `sleep` StatefulSet：
- en: '[PRE30]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The StatefulSet creates two Pods:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet 创建了两个 Pods：
- en: '[PRE31]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The persistent storage for each Pod is brand new, so it starts empty. Let’s
    create some content. The easiest way to do that is from within the container itself,
    using `kubectl exec`, which allows us to run commands inside a container, similar
    to `crictl`. The `kubectl exec` command works no matter what host the container
    is on, even if we’re connecting to our Kubernetes API server from outside the
    cluster.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Pod 的持久化存储是全新的，因此它开始时是空的。让我们创建一些内容。最简单的方法是通过容器内部，使用 `kubectl exec` 命令，它允许我们在容器内运行命令，类似于
    `crictl`。`kubectl exec` 命令无论容器在哪个主机上运行都能工作，即使我们从集群外部连接到 Kubernetes API 服务器也是如此。
- en: 'Let’s write each container’s hostname to a file and print it out so that we
    can verify it worked:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将每个容器的主机名写入文件并打印出来，以便验证它是否成功：
- en: '[PRE32]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Each of our Pods now has unique content in its persistent storage. Let’s delete
    one of the Pods and verify that its replacement inherits its predecessor’s storage:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的每个 Pod 在其持久化存储中都有独特的内容。让我们删除其中一个 Pod，并验证它的替代 Pod 是否继承了前一个 Pod 的存储：
- en: '[PRE33]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: After deleting `sleep-0`, we see a new Pod created with the same name, which
    is different from the Deployment for which a random name was generated for every
    new Pod. Additionally, for this new Pod, the file we created previously is still
    present because the StatefulSet attached the same persistent storage to the new
    Pod it created when the old one was deleted.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 删除 `sleep-0` 后，我们看到一个新 Pod 被创建，且其名称与之前不同，这与 Deployment 不同，因为 Deployment 为每个新
    Pod 生成一个随机名称。此外，对于这个新 Pod，我们之前创建的文件仍然存在，因为 StatefulSet 在删除旧 Pod 时，将相同的持久存储附加到了它创建的新
    Pod 上。
- en: Daemon Sets
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Daemon Sets
- en: The *DaemonSet* controller is like a StatefulSet in that the DaemonSet also
    runs a specific number of Pods, each with a unique identity. However, the DaemonSet
    runs exactly one Pod per node, which is useful primarily for control plane and
    add-on components for a cluster, such as a network or storage plug-in.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*DaemonSet* 控制器类似于 StatefulSet，DaemonSet 也运行特定数量的 Pods，每个 Pod 都有独特的身份。然而，DaemonSet
    每个节点只运行一个 Pod，这主要对集群的控制平面和附加组件（如网络或存储插件）非常有用。'
- en: Our cluster already has multiple DaemonSets installed, so let’s look at the
    `calico-node` DaemonSet that’s already running, which runs on each node to provide
    network configuration for all containers on that node.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的集群已经安装了多个 DaemonSets，因此让我们来看一下已经在运行的 `calico-node` DaemonSet，它在每个节点上运行，为该节点上的所有容器提供网络配置。
- en: 'The `calico-node` DaemonSet is in the `calico-system` Namespace, so we’ll specify
    that Namespace to request information about the DaemonSet:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`calico-node` DaemonSet 位于 `calico-system` 命名空间，因此我们将指定该命名空间来请求有关 DaemonSet
    的信息：'
- en: '[PRE34]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Our cluster has three nodes, so the `calico-node` DaemonSet has created three
    instances. Here’s the configuration of this DaemonSet in YAML format:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的集群有三个节点，因此 `calico-node` DaemonSet 创建了三个实例。以下是该 DaemonSet 的 YAML 格式配置：
- en: '[PRE35]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The `-o yaml` parameter to `kubectl get` prints out the configuration and status
    of one or more resources in YAML format, allowing us to inspect Kubernetes resources
    in detail.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`-o yaml` 参数用于 `kubectl get` 命令，输出一个或多个资源的配置和状态，格式为 YAML，这样我们可以详细检查 Kubernetes
    资源。'
- en: 'The selector for this DaemonSet expects a label called `k8s-app` to be set
    to `calico-node`. We can use this to show just the Pods that this DaemonSet creates:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 DaemonSet 的选择器期望标签 `k8s-app` 设置为 `calico-node`。我们可以使用它来仅显示此 DaemonSet 创建的
    Pods：
- en: '[PRE36]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The DaemonSet has created three Pods, each of which is assigned to one of the
    nodes in our cluster. If we add additional nodes to our cluster, the DaemonSet
    will schedule a Pod on the new nodes as well.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSet 已创建了三个 Pods，每个 Pod 都被分配到了我们集群中的一个节点。如果我们向集群中添加更多节点，DaemonSet 也会在新节点上调度一个
    Pod。
- en: Final Thoughts
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后的思考
- en: This chapter explored Kubernetes from the perspective of a regular cluster user,
    creating controllers that in turn create Pods with containers. Having this core
    knowledge of controller resource types is essential for building our applications.
    At the same time, it’s important to remember that Kubernetes is using the container
    technology we explored in [Part I](part01.xhtml#part01).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 本章从普通集群用户的角度探讨了 Kubernetes，创建控制器进而创建带有容器的 Pods。掌握这些控制器资源类型的核心知识对于构建我们的应用程序至关重要。与此同时，重要的是要记住，Kubernetes
    使用了我们在[第一部分](part01.xhtml#part01)中探讨过的容器技术。
- en: One key aspect of container technology is the ability to isolate containers
    in separate network namespaces. Running containers in a Kubernetes cluster adds
    additional requirements for networking because we now need to connect containers
    running on different cluster nodes. In the next chapter, we consider multiple
    approaches to make this work as we look at overlay networks.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 容器技术的一个关键方面是能够将容器隔离在不同的网络命名空间中。在 Kubernetes 集群中运行容器增加了网络方面的额外要求，因为我们现在需要连接运行在不同集群节点上的容器。在下一章中，我们将考虑多种方法来实现这一目标，并探讨覆盖网络。
