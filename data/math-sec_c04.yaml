- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Building a Network Traffic Analysis Tool
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 构建网络流量分析工具
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: For our first project, let’s start with something familiar. Most of us in the
    security realm have spent at least some time analyzing packet data and monitoring
    network traffic. In this chapter, we’ll apply the concepts we discussed in the
    previous chapter—multi-edge directed graphs, centrality, and information exchange—to
    build our own network traffic analysis tool. We’ll use captured network data to
    build a graph, calculate some metrics to learn about the properties of the observed
    traffic, and then use centrality measures to figure out what each machine is doing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的第一个项目，让我们从一个熟悉的主题开始。在安全领域，我们大多数人都至少花过一些时间分析数据包和监控网络流量。在本章中，我们将应用上一章讨论的概念——多边缘有向图、中心性和信息交换——来构建我们自己的网络流量分析工具。我们将使用捕获的网络数据来构建图形，计算一些指标以了解观察到的流量的属性，然后使用中心性度量来找出每台机器在做什么。
- en: When we talk about systems on a network, we often think in terms of their most
    prevalent use case. Some machines are on a network to serve files, others to route
    phone traffic, and still others to represent network users. By figuring out what
    part the machines are playing, we can make an educated guess about the type of
    traffic to expect from each machine.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论网络上的系统时，我们通常会想到它们最常见的使用场景。有些机器在网络上是为了提供文件服务，另一些则用于路由电话流量，还有一些则代表网络用户。通过弄清楚机器所扮演的角色，我们可以对每台机器产生的流量类型做出合理的猜测。
- en: We’ll use the information exchange ratio to determine which machines are creating
    and receiving the most traffic of a given type; this will help us determine the
    usual levels of traffic and thus potential threats. Finally, we’ll get started
    capturing and analyzing network traffic around us with a proof of concept that
    will generate graphs from live packet capture.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用信息交换比率来确定哪些机器正在创建和接收最多的某种类型的流量；这将帮助我们确定常规的流量水平，从而识别潜在威胁。最后，我们将开始捕获和分析周围的网络流量，使用一个概念验证工具从实时数据包捕获中生成图形。
- en: Let’s begin by looking at an example network map.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个示例网络图开始。
- en: Network Topology Visualization
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络拓扑可视化
- en: Most GUI-based packet analysis tools, like WireShark or Zenmap, allow you to
    visualize the network’s topology, combining packet analysis with graph theory
    to infer information about the network structure. [Figure 4-1](#figure4-1) shows
    an example captured on my research network.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数基于GUI的数据包分析工具，如WireShark或Zenmap，都允许你可视化网络拓扑，将数据包分析与图论结合起来推断网络结构信息。[图4-1](#figure4-1)展示了我在研究网络上捕获的一个示例。
- en: '![](image_fi/502567c04/f04001.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c04/f04001.png)'
- en: 'Figure 4-1: An example network topology view from Zenmap'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图4-1：来自Zenmap的示例网络拓扑视图
- en: Recall from [Chapter 3](c03.xhtml) that *V* represents all the vertices and
    *E* represents all the edges; *V* and *E* combine to make the graph *G*. In [Figure
    4-1](#figure4-1), each node in *V* represents a system generating traffic on the
    network. Each edge in *E* is a communication pathway defined by an observed packet.
    The nodes and edges both have attributes pulled from the dissected packet fields;
    we’ll use these attributes for further analysis. From the graph of my research
    network, we can infer that my machine was able to connect with 11 other machines
    located on the same local area network segment.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下[第3章](c03.xhtml)，其中*V*表示所有顶点，*E*表示所有边；*V*和*E*结合形成图*G*。在[图4-1](#figure4-1)中，*V*中的每个节点代表一个在网络上生成流量的系统。*E*中的每条边是由观察到的数据包定义的通信路径。节点和边都有从解析的数据包字段中提取的属性；我们将利用这些属性进行进一步分析。从我的研究网络图中，我们可以推断出我的机器能够与位于同一局域网段的11台其他机器进行连接。
- en: Generally speaking, we can interpret this graph as showing the communication
    relationship between computers on my research network. We can use this relationship
    map to infer conclusions about expected and unexpected behaviors (like why your
    coffee pot is sending network traffic to your printer). This can be extremely
    useful in security systems, as you might expect.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们可以将此图解读为展示我的研究网络中计算机之间的通信关系。我们可以使用这个关系图来推断出关于预期和意外行为的结论（例如，为什么你的咖啡壶会向你的打印机发送网络流量）。这在安全系统中非常有用，正如你所预料的那样。
- en: Most traditional network monitoring tools rely on *signature detection* to classify
    malicious traffic, wherein the monitoring tool will scan for behavior that indicates
    threats, such as a packet with a sender IP of a known command-and-control server.
    Typically these signatures take two forms. The first, and most popular, is an
    *Indicator of Compromise (IoC)*, which represents a unique action taken by malware.
    As their name implies, IoCs can help identify if a system has been compromised.
    For example, if a research analyst finds that a new malware variant tried to contact
    a particular URL during its setup, network administrators can add a rule to their
    monitoring software that blocks traffic to that URL and sends alerts on a potential
    infection. The problem is that the IoC approach relies on previous knowledge of
    behavior that’s unique enough that you can identify the infection with a high
    probability of success and a low probability of false alarms. This behavior can
    take hours of human research to identify and only minutes for the malware authors
    to change in their next variant. The sheer number of IoCs to keep up with is staggering,
    and applying them all—to all network traffic—can sometimes slow things to a crawl.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数传统的网络监控工具依赖*签名检测*来分类恶意流量，在这种方式下，监控工具会扫描出表示威胁的行为，例如一个包的发送者 IP 是已知的指挥与控制服务器。通常，这些签名有两种形式。第一种，也是最常见的，是*妥协指示符（IoC）*，它代表恶意软件执行的独特操作。顾名思义，IoC
    可以帮助识别系统是否已被入侵。例如，如果一位研究分析员发现某个新的恶意软件变种在其设置过程中试图联系特定的 URL，那么网络管理员可以在他们的监控软件中添加一条规则，阻止访问该
    URL 的流量，并发出潜在感染的警报。问题在于，IoC 方法依赖于对行为的先前了解，这些行为具有足够的独特性，可以高概率地识别感染并且低概率地误报。这些行为可能需要几个小时的人力研究来识别，而对于恶意软件作者来说，仅需几分钟时间即可在下一个变种中进行更改。需要跟踪的
    IoC 数量令人震惊，而将它们应用到所有网络流量中，有时会导致系统变得极为缓慢。
- en: We can remedy this with the second type of signature detection, aptly named
    *anomaly detection*. This signature relies on elements of graph theory to create
    a set of network metrics that are considered “normal” behavior. During live traffic
    analysis, an operator is alerted if one of these values moves outside the defined
    range (which will usually include an acceptable variance). By applying graph theory
    to network traffic, you’ll design systems that can detect and react to anomalous
    traffic without relying on previously seen samples. You can then take this a step
    further and define a system to automatically respond based on the type of alert
    being generated.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过第二种类型的签名检测来解决这个问题，恰当地命名为*异常检测*。这种签名依赖图论的元素来创建一组被认为是“正常”行为的网络指标。在实时流量分析中，如果这些值之一超出了定义的范围（通常包括一个可接受的偏差），操作员将会收到警报。通过将图论应用于网络流量，你可以设计出能够检测并应对异常流量的系统，而不依赖于以前见过的样本。然后，你可以进一步定义一个系统，根据生成的警报类型自动做出响应。
- en: To get from the theory we’ve discussed to an anomaly detection system, we have
    to first figure out how to turn network traffic data into a graph representation
    we can analyze. We’ll need to add another library to the mix to extract the data
    we want and feed it into NetworkX in a meaningful way.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要将我们讨论的理论转化为异常检测系统，我们首先需要弄清楚如何将网络流量数据转化为可以分析的图形表示。我们还需要添加另一个库来提取我们想要的数据，并以有意义的方式将其输入到
    NetworkX 中。
- en: Converting Network Information into a Graph
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将网络信息转换为图形
- en: We’ll use the Python library Scapy to extract information from a packet capture
    file, known as a *pcap*, and then create a graph from that information using the
    concepts from [Chapter 3](c03.xhtml). Scapy is Python’s version of a Swiss army
    knife for packet manipulation, providing tools for capturing, analyzing, crafting,
    and transmitting network packets. Scapy can even be used to quickly define entirely
    new network protocols. Scapy works off a platform-specific packet capture library.
    On Linux this is libpcap, which comes installed by default on most modern Linux
    platforms; it’s installed by default on the BSD-based distributions and macOS,
    and the stable version is usually installed by default on other Linux-based distributions.
    On Windows you’ll need to install an alternative library such as WinPcap (now
    deprecated) or Npcap ([https://npcap.com](https://npcap.com)). If you’ve worked
    with other packet analysis tools, like WireShark, on your Windows machine, you
    might already have one of these installed.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Python 库 Scapy 从数据包捕获文件（即 *pcap* 文件）中提取信息，然后利用[第 3 章](c03.xhtml)中的概念基于这些信息创建图表。Scapy
    是 Python 版本的瑞士军刀，用于数据包操作，提供了捕获、分析、构建和传输网络数据包的工具。Scapy 甚至可以用来快速定义全新的网络协议。Scapy
    基于平台特定的数据包捕获库工作。在 Linux 上，这是 libpcap，通常在大多数现代 Linux 平台上默认安装；它在基于 BSD 的发行版和 macOS
    上也默认安装，而在其他基于 Linux 的发行版上，通常也默认安装稳定版本。在 Windows 上，你需要安装如 WinPcap（现已弃用）或 Npcap（[https://npcap.com](https://npcap.com)）这样的替代库。如果你在
    Windows 机器上使用过其他数据包分析工具，如 WireShark，可能已经安装了其中一个库。
- en: We’ll read packets from the *network_sim.pcap* file, available for download
    in the book’s GitHub repository. Our aim is to recognize machines on the network
    that were behaving outside of normal, “expected” behaviors. We’re going to analyze
    the packets to identify the machines present in the data, who communicated with
    whom, and what type of communication was happening. To do so, we’ll apply a bit
    of knowledge about network protocols and a healthy dose of statistical analysis
    to our packet graph.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从 *network_sim.pcap* 文件中读取数据包，该文件可以在本书的 GitHub 仓库中下载。我们的目标是识别网络中那些表现出异常行为的机器，即与正常“预期”行为不同的机器。我们将分析这些数据包，识别数据中的机器，了解它们之间的通信情况，以及发生了什么类型的通信。为此，我们将应用一些网络协议知识，并用大量的统计分析方法来分析数据包图。
- en: Building a Communication Map
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建通信图
- en: The capture file contains traffic logged by a Snort collection point ([https://www.netresec.com/?page=ISTS](https://www.netresec.com/?page=ISTS)).
    The capture file contains 139,873 packets from 80 unique *media access control
    (MAC)* addresses. A MAC address is a unique identifier burned into the hardware
    memory of your *network interface card (NIC)* by the manufacturer. At a very simplified
    level, the NIC’s job is to physically transmit the data to the next device on
    the network (usually some type of router or switch). If you’re using an Ethernet
    cable, the NIC will send the electric pulses along the wire. If you’re using a
    wireless NIC, the data will be broadcast via some form of receiver and transmitter
    combination. When you sign on to a network at home or the coffee shop, your NIC
    sends its MAC address to the router, which assigns an IP address to the system
    based on its MAC. If the router has never seen the MAC before, it will allocate
    the next free IP address, but if the machine has been assigned an IP before and
    that IP is still available, the router will usually assign the same one again.
    However, sometimes the previous IP address has already been assigned to a different
    NIC, so the router will assign a new IP to a MAC it’s previously seen.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获文件包含由 Snort 收集点记录的流量（[https://www.netresec.com/?page=ISTS](https://www.netresec.com/?page=ISTS)）。该捕获文件包含来自
    80 个唯一 *媒体访问控制（MAC）* 地址的 139,873 个数据包。MAC 地址是由制造商烧录到网络接口卡（*NIC*）硬件内存中的唯一标识符。简化来说，NIC
    的工作是将数据物理传输到网络上的下一个设备（通常是某种类型的路由器或交换机）。如果你使用以太网电缆，NIC 会将电信号沿电缆传输。如果你使用无线 NIC，数据将通过某种接收器和发射器组合广播。当你在家或咖啡店连接到网络时，NIC
    会将其 MAC 地址发送给路由器，路由器会根据该 MAC 地址为系统分配一个 IP 地址。如果路由器之前没有见过这个 MAC 地址，它会分配下一个空闲的 IP
    地址；但如果该机器之前已分配过 IP 且该 IP 仍然有效，路由器通常会再次分配相同的 IP 地址。然而，有时之前的 IP 地址已被分配给另一个 NIC，因此路由器会为这个曾经见过的
    MAC 地址分配一个新的 IP。
- en: We’ll use the source and destination MAC of each device involved in a packet
    transfer as the edge identifiers in our graph. It’s unlikely that a machine has
    completely switched its NIC between connections, though, so the MAC address should
    remain the same. By using the MAC address to identify each machine, we’ll be able
    to recognize the same NIC across different IP addresses and build a somewhat accurate
    communication map that isn’t confused when a machine’s assigned IP address changes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用每个参与数据包传输的设备的源 MAC 地址和目标 MAC 地址作为图中的边标识符。然而，机器在连接之间完全更换网卡的可能性较小，因此 MAC
    地址应该保持不变。通过使用 MAC 地址来识别每台机器，我们将能够在不同的 IP 地址之间识别同一网卡，从而构建出一个相对准确的通信图，避免在机器的 IP
    地址发生变化时产生混淆。
- en: Now that we know what data we can use to identify systems, we can focus on the
    types of network data we’re interested in. With nearly 140,000 packets available,
    we want to filter to reduce the noise in the data and make our processing more
    efficient. This is where your knowledge of network protocols will come into play.
    There are potentially dozens, if not hundreds, of different network protocols
    present in network traffic. By understanding different protocols and when they’re
    likely to be used, you can more quickly zero in on the data of interest. We don’t
    have the space to cover packet analysis in depth, so I recommend you read one
    of the excellent books listed in the chapter summary to learn how powerful good
    packet filters can be for security analysis.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了可以用来识别系统的数据，我们可以专注于我们感兴趣的网络数据类型。由于有近 140,000 个数据包可用，我们希望进行筛选，以减少数据中的噪音并提高处理效率。此时，你对网络协议的知识将发挥作用。网络流量中可能存在数十种，甚至数百种不同的网络协议。通过理解不同协议及其可能的使用场景，你可以更快速地聚焦于感兴趣的数据。我们没有足够的篇幅深入讲解数据包分析，因此我建议你阅读章节总结中列出的优秀书籍，以了解良好的数据包过滤器在安全分析中的强大作用。
- en: 'The sample file includes packet data with the following protocol makeup:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 示例文件包括以下协议组成的数据包：
- en: 'TCP: 137,837'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP：137,837
- en: 'UDP: 2,716'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UDP：2,716
- en: 'ICMP: 297'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ICMP：297
- en: 'Other: 1,352'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他：1,352
- en: Our analysis will focus on TCP and UDP packets (the two major types of packets
    used in common network communication like web traffic). TCP and UDP are built
    above the IP layer, so we’ll ignore any packets that don’t have an IP layer to
    filter out all but these protocols. We’ll also extract IP addresses and ports.
    The port numbers will be important as we discuss the type of communication, because
    a lot of software (like databases and web servers) tend to have default port numbers,
    so their presence in the packet data can help us guess what systems might be on
    each side of the communication. By collecting the IP addresses with the information,
    we can analyze which MAC addresses have been paired with multiple IP addresses.
    This gives you an idea of how much error could be introduced from just using the
    IP address as the identifier.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分析将重点关注 TCP 和 UDP 数据包（这两种是常见网络通信中使用的主要数据包类型，例如网页流量）。TCP 和 UDP 是建立在 IP 层之上的，因此我们将忽略没有
    IP 层的数据包，从而筛选出除了这两种协议以外的数据包。我们还将提取 IP 地址和端口。端口号在我们讨论通信类型时非常重要，因为许多软件（如数据库和 Web
    服务器）往往会使用默认端口号，因此它们在数据包中的存在可以帮助我们猜测通信双方可能使用的系统。通过收集这些 IP 地址信息，我们可以分析哪些 MAC 地址与多个
    IP 地址配对。这可以让你了解，仅仅使用 IP 地址作为标识符可能引入多少错误。
- en: Building the Graph
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建图
- en: In [Listing 4-1](#listing4-1) we load the packet data into a `MultiDiGraph`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [Listing 4-1](#listing4-1) 中，我们将数据包数据加载到一个 `MultiDiGraph` 中。
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Listing 4-1: Populating the graph from a pcap file'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Listing 4-1：从 pcap 文件填充图
- en: The `net_graph` `MultiDiGraph` variable ❶ will be populated from the pcap file
    loaded with `rdpcap` ❷, a Scapy function that reads a pcap file and returns a
    list of Scapy `packet` objects in the `packets` variable. To filter for just TCP
    and UDP packets, we loop over each `packet` object ❸ and check if it has an `IP`
    layer defined ❹. If it does, we extract the source and destination MAC addresses
    from the base packet with `packet.src` and `packet.dst`, respectively ❺, giving
    us some edge attributes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`net_graph` `MultiDiGraph` 变量❶将通过 `rdpcap` ❷ 加载的 pcap 文件进行填充，`rdpcap` 是 Scapy
    的一个函数，能够读取 pcap 文件并返回 Scapy `packet` 对象列表，这些对象存储在 `packets` 变量中。为了只筛选 TCP 和 UDP
    数据包，我们会遍历每个 `packet` 对象❸，并检查它是否定义了 `IP` 层❹。如果定义了，我们将从基础数据包中提取源和目标 MAC 地址，分别使用
    `packet.src` 和 `packet.dst` ❺，这会给我们一些边缘属性。'
- en: 'Scapy `packet` objects store properties for each protocol encapsulated in the
    packet in layers, with Ethernet card data, like the MAC address, stored in the
    base layer. We access additional layers with dictionary-like indexing: for example,
    the source and destination IP addresses from the `IP` layer are in `packet[IP].src`
    and `packet[IP].dst` ❻. We extract these to store as edge attributes. To weight
    edges in *E* using the number of bytes sent per packet, we save the `packet[IP].len`
    property ❼ in `w`, and store that in the edge’s `weight` attribute later. Using
    `weight` as the specific attribute name will allow NetworkX to pick it up and
    use it during analysis. Weighting each edge by the length of the packet’s IP layer
    is a simple way to estimate the amount of data transmitted between machines.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Scapy `packet`对象以层的方式存储每个封装在数据包中的协议属性，像MAC地址这样的以太网卡数据存储在基础层中。我们通过类似字典的索引访问额外的层级：例如，`IP`层中的源IP地址和目标IP地址分别在`packet[IP].src`和`packet[IP].dst`
    ❻中。我们提取这些信息作为边属性。为了根据每个数据包发送的字节数来加权边，我们将`packet[IP].len`属性 ❼保存在`w`中，并稍后将其存储在边的`weight`属性中。使用`weight`作为属性名称，NetworkX将自动识别并在分析中使用它。通过数据包的IP层长度来加权每个边是估算机器间传输数据量的简单方法。
- en: Finally, we check the packet for a `TCP` ❽ or `UDP` layer ❾. We need to perform
    this additional check because not all packets with an IP layer are from the TCP
    or UDP protocols. For example, Internet Control Message Protocol (ICMP) packets
    have IP layer information but aren’t in the same format as a TCP or UDP packet.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们检查数据包是否有`TCP` ❽或`UDP`层 ❾。我们需要进行这个额外的检查，因为并非所有带有IP层的数据包都是来自TCP或UDP协议。例如，互联网控制消息协议（ICMP）数据包也有IP层信息，但它们的格式与TCP或UDP数据包不同。
- en: If a TCP or UDP layer is present in the packet, we extract the source and destination
    ports; otherwise, we skip the packet. We create an edge for each eligible packet
    using the collected properties as edge attributes and MAC addresses as node IDs
    ❿. Finally, we can print out the length of the `net_graph` object, which will
    tell us that 80 nodes were created. [Figure 4-2](#figure4-2) shows a 3D graph
    representation of the network data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据包中存在TCP或UDP层，我们提取源端口和目标端口；否则，我们跳过该数据包。我们使用收集到的属性作为边属性，并将MAC地址作为节点ID ❿，为每个符合条件的数据包创建一个边。最后，我们可以打印出`net_graph`对象的长度，这将告诉我们创建了80个节点。[图4-2](#figure4-2)展示了网络数据的三维图形表示。
- en: '![](image_fi/502567c04/f04002.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c04/f04002.png)'
- en: 'Figure 4-2: A 3D representation of the network'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图4-2：网络的三维表示
- en: I’ve generated the axis values for this figure using the `nx.random_layout`
    function as placeholders for the moment, since we haven’t yet defined what we’re
    looking for. The function generates only the *x* and *y* values by default, but
    you can pass the parameter `dim=3` to have it generate three-dimensional coordinates.
    We’ll be doing the rest of our analysis in 2D, but I wanted to show an example
    of the graph the way most people think about it—in 3D. Being able to easily display
    complex networks in 3D like this is a huge time saver. Even though this graph
    is tangled, you can already get a sense of important nodes in the communication.
    One node in the upper central area, for example, has many edges connecting it
    to many other nodes in the graph. Beyond very basic observations, though, you
    can’t gain much insight.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经使用`nx.random_layout`函数生成了这个图的坐标值，作为目前的占位符，因为我们还没有定义要寻找的内容。该函数默认只生成* x *和*
    y *值，但你可以传递参数`dim=3`，让它生成三维坐标。我们将进行其余的分析时使用2D，但我想展示大多数人思考的图的样子——三维的。能够像这样轻松地以三维形式展示复杂的网络，节省了大量时间。即使这个图看起来很复杂，你已经能从中感知到通信中的重要节点。例如，位于上方中央区域的一个节点，有很多边连接到图中其他节点。不过，除了这些非常基础的观察外，你不会获得太多的深刻见解。
- en: The number of nodes and complex interactions lends itself perfectly to an automated
    graph analysis approach. Using the theory we’ve already covered, we’ll untangle
    this graph into organized and informative subgraphs. You’ll apply your newfound
    knowledge of edge filtering and summation to discover which nodes are communicating,
    using interesting protocols like HTTP and HTTPS. We’ll examine which machines
    are contacting a large number of other machines using a measure of out-degree
    connections, and finally we’ll explore a proof-of-concept program that will allow
    you to capture and analyze packets from your own network.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 节点数量和复杂的交互使得自动化图分析方法非常适用。利用我们已经掌握的理论，我们将把这个图解开，变成有组织且富有信息的子图。你将运用新学到的边过滤和求和技巧，发现哪些节点在使用有趣的协议（如HTTP和HTTPS）进行通信。我们将检查哪些机器通过出度连接的度量与大量其他机器进行联系，最后，我们将探索一个概念验证程序，允许你捕获并分析自己网络中的数据包。
- en: Identifying Suspicious Machine Behavior
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别可疑的机器行为
- en: 'Let’s reexamine the concept of closeness in the context of our network data.
    Given that we recorded the packet’s destination port and defined the edge weight
    as the number of bytes transmitted in the corresponding packet, a natural first
    question to ask about the network is, “Which machines are using which protocols
    to communicate?” If we assume that traffic destined for certain ports belongs
    to a certain protocol or application (like 80 for HTTP, or 22 for SSH), the task
    is equivalent to asking, “Which node sends the most data (measured in packet bytes)
    to a given port?” Our simplifying assumption is actually the underlying basis
    for quick protocol fingerprinting in network tools like Nmap, so I feel comfortable
    making this particular leap of faith. We can reformulate the question of protocol
    use more formally as:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在网络数据的背景下重新审视“接近度”这一概念。既然我们记录了数据包的目标端口，并将边的权重定义为相应数据包中传输的字节数，那么我们对网络提出的第一个自然问题是：“哪些机器在使用哪些协议进行通信？”如果我们假设某些目标端口的流量属于某种协议或应用（例如，80端口用于HTTP，或22端口用于SSH），那么这个任务等同于问：“哪个节点向给定端口发送的数据量最多（按数据包字节数计算）？”我们的简化假设实际上是网络工具（如Nmap）中快速协议指纹识别的基础，所以我在这里做出这个假设是很有根据的。我们可以更正式地将协议使用的问题重新表述为：
- en: Given a set of protocols Ψ, determine which node has the highest weighted out-degree
    for protocol Ψ[(][*i*][)].
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 给定一组协议 Ψ，确定哪个节点具有协议 Ψ[(][*i*][)]的最高加权出度。
- en: In fact, investigators examining network operations frequently ask this question
    when they want to identify machines that are behaving abnormally (outside of the
    observed average), so it makes sense to automate the process.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，调查人员在检查网络操作时，常常会问这样一个问题：如何识别表现异常的机器（即偏离观察到的平均值的机器），因此将这一过程自动化是有意义的。
- en: Subgraph of Port Data Volume
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 端口数据量的子图
- en: You can investigate data volume on a given port simply and quickly by first
    creating a subgraph that contains only edges of type Ψ[(][*i*][)] (for example,
    SSH) and then measuring the weighted out-degree of each node in the subgraph.
    [Listing 4-2](#listing4-2) adds a helper function to the code in [Listing 4-1](#listing4-1)
    to create a subgraph for arbitrary port numbers.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过首先创建一个仅包含类型为 Ψ[(][*i*][)]（例如 SSH）边的子图，然后测量子图中每个节点的加权出度，简单快速地调查给定端口的数据量。[清单
    4-2](#listing4-2)为[清单 4-1](#listing4-1)中的代码添加了一个辅助函数，用于为任意端口号创建子图。
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Listing 4-2: A protocol subgraph helper function'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 4-2：一个协议子图辅助函数
- en: The function `protocol_subgraph` takes a graph and a port number as arguments,
    collects all edges representing traffic *to* the port, and creates a simple directed
    graph. The list comprehension with conditional statement `if d["dport"] == port`
    prunes the edge set to only the edges of interest. It then creates a `DiGraph`
    object and adds the pruned edge set with `nx.add_edges_from`. As I mentioned previously,
    this will also add nodes to the graph. Because NetworkX automatically sums the
    `weight` attribute of multiple edges between the same two nodes in a `DiGraph`,
    the `weight` attribute of each edge in the `subgraph` will represent the combined
    byte count of all packets between two devices.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`protocol_subgraph`接受图和端口号作为参数，收集所有表示流量*到*该端口的边，并创建一个简单的有向图。使用条件语句`if d["dport"]
    == port`的列表推导式将边集修剪为仅包含感兴趣的边。然后，它创建一个`DiGraph`对象，并通过`nx.add_edges_from`将修剪后的边集添加到图中。正如我之前提到的，这也会将节点添加到图中。因为NetworkX会自动对`DiGraph`中相同两个节点之间的多条边的`weight`属性进行求和，所以`subgraph`中每条边的`weight`属性将表示两台设备之间所有数据包的字节总数。
- en: We can then check the volume of outbound traffic of each node in the returned
    subgraph using the `nx.out_degree` function. [Listing 4-3](#listing4-3) shows
    how to retrieve this information for port 80.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用`nx.out_degree`函数检查返回的子图中每个节点的外向流量。[清单 4-3](#listing4-3)展示了如何获取端口 80
    的相关信息。
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Listing 4-3: Finding machines with the most outbound traffic for a single protocol'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 4-3：查找具有最多外向流量的单协议机器
- en: First we call the helper function defined in [Listing 4-2](#listing4-2) with
    the `MultiDiGraph` created in [Listing 4-1](#listing4-1) and the port of interest
    (`80`, in this example) and then we call the `out_degree` function, which returns
    the raw count of outbound edges for every node in the subgraph. To change the
    behavior to return the summed edge weight instead, we explicitly pass `out_degree`
    the `weight` parameter. Usually NetworkX picks up the `weight` parameter on its
    own, but for some reason it didn’t when I tested my code. Adding an explicit reference
    to the `weight` attribute solved the problem.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们调用[清单 4-2](#listing4-2)中定义的辅助函数，传入在[清单 4-1](#listing4-1)中创建的`MultiDiGraph`和感兴趣的端口（在此示例中为`80`），然后我们调用`out_degree`函数，该函数返回子图中每个节点的外部边的原始计数。为了将行为更改为返回求和后的边权重，我们显式传递`out_degree`的`weight`参数。通常，NetworkX会自动识别`weight`参数，但在我测试代码时，出于某些原因，它并没有识别。添加显式引用`weight`属性解决了该问题。
- en: 'To find the device that sends the most data on port 80, we sort the result
    using the `sorted` function. The `key` parameter takes in a function to use when
    sorting complex objects (like tuples or dictionaries). We pass in a lambda function
    that takes a tuple of the form `(``node ID``,` `out-degree weight``)` and sorts
    the items in the order `(``out-degree weight``,` `node ID``)`, so the nodes are
    sorted by out-degree first; if there’s a tie, the node’s ID is used as the tie
    breaker. The `reverse` option sorts the items in descending order (the default
    is ascending). The first item in the sorted list now has the highest out-degree,
    as you should see in the code’s output:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到在端口 80 上发送最多数据的设备，我们使用`sorted`函数对结果进行排序。`key`参数传入一个用于排序复杂对象（如元组或字典）的函数。我们传入一个lambda函数，它接受一个形如`（节点ID，外度权重）`的元组，并按`（外度权重，节点ID）`的顺序对项进行排序，因此节点首先按外度排序；如果存在平局，节点ID会作为决胜负的标准。`reverse`选项将项按降序排序（默认是升序）。排序后的列表中的第一个项现在具有最高的外度，正如你在代码输出中应该看到的那样：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Since our goal is to identify interesting or anomalous network activity, such
    as a sudden increase in network outbound activity on key services like SSH and
    HTTP, we want to take a list of protocols and determine the node with the highest-weighted
    out-degree for each. This is equivalent to
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的目标是识别有趣或异常的网络活动，例如在SSH和HTTP等关键服务上的网络外向活动突然增加，我们希望列出协议，并确定每个协议中具有最高加权外度的节点。这相当于
- en: '![](image_fi/502567c04/m04001.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c04/m04001.png)'
- en: which defines a |*V*| × *j* matrix (also called a two-dimensional array for
    you coders), where *j* is the number of protocols to examine. The entry ![m04002](image_fi/502567c04/m04002.png)
    holds the summed weight of edges with protocol *j* for node *u*.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法定义了一个 |*V*| × *j* 矩阵（也称为二维数组，适合代码员），其中 *j* 是要检查的协议数量。该条目 ![m04002](image_fi/502567c04/m04002.png)
    存储了协议 *j* 对于节点 *u* 的边的总权重。
- en: 'In [Listing 4-4](#listing4-4) we again leverage the `protocol_subgraph` function
    from [Listing 4-2](#listing4-2) to answer the question “Which machines have the
    highest weighted communication?” with four popular ports: HTTP, Digital Private
    Network Signaling System (DPNSS), the Metasploit RPC daemon default port (also
    used by Armitage team server), and HTTPS.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在[清单 4-4](#listing4-4)中，我们再次利用了[清单 4-2](#listing4-2)中的`protocol_subgraph`函数来回答“哪些机器具有最高的加权通信？”这个问题，涵盖了四个常见的端口：HTTP、数字专用网络信令系统（DPNSS）、Metasploit
    RPC守护进程的默认端口（Armitage团队服务器也使用该端口）以及HTTPS。
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Listing 4-4: Locating machines with the highest outbound traffic for multiple
    protocols'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 4-4：定位具有最高外向流量的多协议机器
- en: For each of the port numbers in `psi`, we create a protocol subgraph `dG`; then,
    for each node in the subgraph, we sum the weight attribute for all the out-degree
    edges. Once all the node weights have been calculated for the current protocol,
    we sort the scores by weight in ascending order and print out the first item from
    each result set.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`psi`中的每个端口号，我们创建一个协议子图`dG`；然后，对于子图中的每个节点，我们计算所有外度边的权重总和。一旦计算出当前协议中所有节点的权重，我们按权重升序对得分进行排序，并打印出每个结果集中的第一个项。
- en: 'Here’s the output of the function:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该函数的输出：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Each line of output gives us the port number, the node address, and the out-degree
    score for the node with the most traffic for each protocol. The first thing that
    should jump out to you, as a security researcher, is that the nodes for port 80
    and port 55553 are the same. This is interesting because port 55553 is used by
    the previously mentioned penetration testing software, and port 80 most often
    represents unencrypted web traffic. This could indicate a scanner of some kind,
    probing for unencrypted web content and reporting the data back to a Metasploit
    server. If I were investigating this network for suspicious users, I would start
    digging deeper into the behavior of `1c:6a:7a:0e:e0:41`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行输出都给出了端口号、节点地址以及每个协议中流量最多的节点的出度得分。作为安全研究人员，第一个应当引起你注意的是端口80和端口55553的节点是相同的。这一点很有趣，因为端口55553被之前提到的渗透测试软件使用，而端口80通常代表未加密的网页流量。这可能表示某种扫描器，在探测未加密的网页内容并将数据报告回Metasploit服务器。如果我在调查该网络中的可疑用户，我会开始深入挖掘`1c:6a:7a:0e:e0:41`的行为。
- en: Another item of interest is that DPNSS traffic on port 2503 may indicate the
    presence of a *Private Branch Exchange (PBX)*, which is a private telephone network
    used within an organization. It’s possible that `00:26:9e:3d:00:2a` is some kind
    of Voice over IP (VoIP) telephone, but you’d need to investigate further to confirm
    this hypothesis. VoIP is a fun protocol, because when improperly secured, it allows
    an attacker to eavesdrop on conversations, inject audio into telephone meetings,
    reroute or block calls, and otherwise terrorize the attached phone system.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得关注的项目是端口2503上的DPNSS流量可能表明存在*私人分支交换机(PBX)*，即组织内部使用的私人电话网络。`00:26:9e:3d:00:2a`很可能是某种IP语音(VoIP)电话，但你需要进一步调查以确认这一假设。VoIP是一种有趣的协议，因为如果安全措施不当，攻击者可以窃听通话、注入音频到电话会议中、重新路由或阻止通话，甚至以其他方式干扰连接的电话系统。
- en: Identifying Unusual Levels of Traffic
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别异常流量水平
- en: 'To find which nodes receive the most data for a given protocol, we could use
    the receiving port for the list comprehension in the `protocol_subgraph` function
    and measure in-degree instead. The question, then, is how to determine whether
    the amount of traffic received is normal or suspicious. To do this, we estimate
    the average amount of inbound traffic on the network by summing the weight of
    each edge and dividing by the number of edges in the protocol subgraph:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找出哪个节点接收了某个协议最多的数据，我们可以使用`protocol_subgraph`函数中的接收端口，并改为衡量入度。问题是，如何确定接收的流量量是否正常或可疑。为此，我们通过将每条边的权重求和并除以协议子图中的边数，来估算网络上入站流量的平均值：
- en: '![](image_fi/502567c04/m04003.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c04/m04003.png)'
- en: If we assume that the traffic for a protocol is normally distributed (meaning
    most systems would receive similar amounts of traffic for a given protocol), we
    can compare the detected usage to the average with the *z-score* formula, which
    scores nodes based on the probability that their difference from the average inbound
    traffic ϖ is due to normal variance. We can choose how confident we want to be
    (usually between 80 and 99.9 percent) that the variance isn’t by chance. A higher
    confidence level means more variance will be considered “normal” and fewer pieces
    of data will be flagged as anomalous, or, put more simply, how extreme the difference
    in the observed and expected value must be before we’re willing to consider it
    “strange behavior.” [Listing 4-5](#listing4-5) shows how to implement this for
    the HTTP protocol subgraph.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们假设某协议的流量是正态分布的（意味着大多数系统在特定协议下接收的流量是相似的），我们可以使用*z-score*公式，将检测到的使用量与平均值进行比较，根据其与平均入站流量ϖ的差异是否由正常变异引起，给节点打分。我们可以选择我们希望多有信心（通常在80到99.9%之间），即变异不是偶然的。更高的置信水平意味着更多的变异会被视为“正常”，而更少的数据会被标记为异常，或者更简单地说，观察值与期望值之间的差异必须多大，才能被认为是“奇怪的行为”。[列表
    4-5](#listing4-5)展示了如何为HTTP协议子图实现这一点。
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Listing 4-5: Identifying outliers using the z-score'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4-5：使用z-score识别异常值
- en: We start by importing the `stats` module from the SciPy library and importing
    the NumPy library as `np`. Next, we define the protocol subgraph `protoG` by passing
    the source graph and HTTP port 80 to the `protocol_subgraph` function we defined
    in [Listing 4-2](#listing4-2). We then calculate the weighted in-degree using
    the `protoG.in_degree` function. We use a NumPy array named `scores` to store
    the weighted in-degree scores. We next look up the *z* threshold value based on
    the level of confidence we chose; in this example, we choose 95 percent confidence,
    which relates to a *z* threshold of 1.645 ❶. This is the number of standard deviations
    away from the mean we’ll use to represent the cutoff between normal data and anomalous
    data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从SciPy库中导入`stats`模块，并将NumPy库导入为`np`。接下来，通过将源图和HTTP端口80传递给我们在[示例4-2](#listing4-2)中定义的`protocol_subgraph`函数，来定义协议子图`protoG`。然后，我们使用`protoG.in_degree`函数计算加权入度。我们使用一个名为`scores`的NumPy数组来存储加权入度得分。接下来，我们根据选择的置信水平查找*z*阈值；在这个例子中，我们选择95%的置信水平，相关的*z*阈值是1.645
    ❶。这个值表示我们用来区分正常数据和异常数据的标准差数。
- en: With this set, we calculate the z-score for each node in the protocol subgraph
    using the `stats.zscore` function and save it to `in_degree_z`. The z-scores are
    centered around 0, so there are negative values representing nodes that have weighted
    in-degree less than the mean. We’re not concerned with systems that have less
    traffic than average for the moment, so we take only the scores that are greater
    than the threshold we set using the function `np.where(in_degree_z > z_thresh)`,
    and we call those scores outliers.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这一组数据，我们通过`stats.zscore`函数计算协议子图中每个节点的z-score，并将其保存到`in_degree_z`中。z-score的值以0为中心，因此负值代表入度加权低于平均值的节点。由于目前我们不关注流量低于平均水平的系统，所以我们只保留那些大于我们通过`np.where(in_degree_z
    > z_thresh)`设置的阈值的得分，并将这些得分称为离群值。
- en: The result is a nested list of one element, so we take the 0th element, a NumPy
    array containing the index of values in the `scores` array that are higher than
    the threshold ❷. We save this to a list named `outlier_idx`. Finally, we convert
    the indexes to node IDs by looking up each element from the `outlier_idx` in `in_deg`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个包含单个元素的嵌套列表，因此我们取第0个元素，它是一个包含`scores`数组中高于阈值的值索引的NumPy数组 ❷。我们将其保存到一个名为`outlier_idx`的列表中。最后，我们通过查找`outlier_idx`中的每个元素在`in_deg`中的对应项，将索引转换为节点ID。
- en: 'We run the code and find two interesting node IDs that we’re 95 percent sure
    have received significantly more traffic on port 80 than the other nodes:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行代码并发现两个有趣的节点ID，我们有95%的把握，它们在端口80上的流量明显高于其他节点：
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[Figure 4-3](#figure4-3) shows the protocol subgraph for port 80 using the
    in-degree measure.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-3](#figure4-3)展示了端口80的协议子图，使用的是入度度量。'
- en: '![](image_fi/502567c04/f04003.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c04/f04003.png)'
- en: 'Figure 4-3: A protocol subgraph of HTTP traffic on the network'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图4-3：网络上HTTP流量的协议子图
- en: 'Each node in this graph sent or received packets on port 80\. The black diamond
    nodes indicate the nodes of interest that were returned by [Listing 4-5](#listing4-5).
    The labeled node has the highest in-degree: three distinct inbound connections
    on port 80\. The circular gray nodes were within normal margins for port 80 traffic.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的每个节点都在端口80上发送或接收了数据包。黑色菱形节点表示[示例4-5](#listing4-5)返回的感兴趣节点。带标签的节点具有最高的入度：在端口80上有三个不同的入站连接。圆形灰色节点的入度在端口80流量的正常范围内。
- en: From a security perspective, these two questions (who has sent the most traffic
    of a given type, and which systems have received a statistically significant amount
    of traffic of a given type) allow us to assess the behavior of nodes within a
    network. By measuring the normal, intruder-free traffic over a period of time
    (say, two weeks) and then comparing it to live captures, you can locate changes
    in behavior (in traffic volume or actions performed) that may indicate a compromise
    has occurred. For example, if you know that `00:26:9e:3d:00:2a` is definitely
    not a VoIP phone, the sudden outbound connections to a telephony network might
    raise alarms. At the very least, you’d want to contact the machine’s operator
    to understand why this behavior has changed.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从安全角度来看，这两个问题（哪个系统发送了最多某种类型的流量，以及哪些系统接收了统计学上显著数量的某种类型的流量）使我们能够评估网络中节点的行为。通过在一段时间（例如两周）内测量正常、无入侵的流量，然后与实时捕获的流量进行比较，您可以找到行为变化（无论是流量量变化还是执行的操作），这些变化可能表明发生了安全泄露。例如，如果您知道`00:26:9e:3d:00:2a`绝对不是一个VoIP电话，那么突然发出的连接到电话网络的行为可能会引起警觉。至少，您应该联系该机器的操作员，以了解为什么这种行为发生了变化。
- en: Examining How Machines Interact on the Network
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检查机器在网络上的交互
- en: As a security analyst, you’re likely interested in gaining insight into how
    machines interact on the network in different but related ways. You may ask protocol-agnostic
    information, such as “Which machine contacted the most other machines?” or “Which
    machine absorbs the most information?” On my network, it’s normal for there to
    be very little cross-talk between different machines (for example, my 3D printer
    shouldn’t be talking to my security camera controller) with the exception of my
    node, which regularly connects to all these machines. By examining the neighbors
    in my network, you’d quickly see which node I was running. And you might have
    guessed that I’d also score pretty highly for betweenness centrality because it
    implicitly favors machines that are neighbors of a high number of nodes that aren’t
    themselves interconnected.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名安全分析师，您可能有兴趣了解机器如何在网络中以不同但相关的方式进行交互。您可能会提出一些与协议无关的问题，例如“哪个机器联系了最多的其他机器？”或者“哪个机器吸收的信息最多？”在我的网络中，通常不同机器之间几乎没有互相通信（例如，我的3D打印机不应该与我的监控摄像头控制器通信），唯一的例外是我的节点，它会定期连接到所有这些机器。通过检查我的网络中的邻居，您很快就会发现我在运行哪个节点。而且您可能已经猜到，由于它隐性地倾向于那些是许多不互联节点的邻居的机器，我在介入中心性上的得分也会很高。
- en: Measuring how much information is exchanged between systems is another way to
    identify machines trying to exfiltrate data from a network and what systems they’re
    stealing data from. In an information exchange analysis, you’re likely to locate
    machines that serve as information repositories (such as file servers and databases),
    which typically take in more information than they send out. On the other side
    of the spectrum are data streaming servers, which produce far more data than they
    receive. To begin this analysis, first we’ll rephrase our questions more formally
    and then we’ll develop the code to investigate them.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 测量系统之间交换的信息量是识别试图从网络中窃取数据的机器及其窃取来源的另一种方法。在信息交换分析中，您可能会定位到作为信息存储库的机器（例如文件服务器和数据库），这些机器通常接收的信息比发送的多。另一类则是数据流服务器，它们产生的数据远多于接收的数据。为了开始这一分析，我们首先将问题更正式地表述，然后开发代码来进行调查。
- en: Identifying the Solicitor Node
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 确定请求节点
- en: 'The first question can be stated more formally as:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个问题可以更正式地表述为：
- en: For all nodes in *G*, find the node with the highest number of outbound neighbors.
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于*G*中的所有节点，找到具有最多外向邻居的节点。
- en: I call this node the solicitor because it behaves like a person going door-to-door
    in a neighborhood, trying to sell something or collect signatures. Network scanners
    (like Nmap) will create outbound connections to any machines it can find on the
    network, making a machine running one of these tools stand out during our analysis.
    We can find the answer to our question by summarizing any multiple edges between
    two nodes into single edges, then counting the out-degree of each node, as shown
    in [Listing 4-6](#listing4-6).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我称这个节点为“请求节点”，因为它的行为像一个在社区里逐门逐户推销产品或收集签名的人。网络扫描器（如Nmap）会对它在网络上找到的任何机器创建外向连接，这使得运行这些工具的机器在我们的分析中会显得特别突出。我们可以通过将两个节点之间的多个边缘汇总为单一边缘，然后计算每个节点的外度来找到我们问题的答案，如[Listing
    4-6](#listing4-6)所示。
- en: '[PRE8]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Listing 4-6: Finding the machine with the most outbound connections'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Listing 4-6：查找具有最多外部连接的机器
- en: We add all the edges from our `MultiDiGraph` `net_graph` to a new digraph, `dG`,
    so that NetworkX summarizes any multiple edges between nodes into a single edge
    with a combined `weight` attribute. Then we use out-degrees from the summarized
    graph to find the node(s) with the maximum values by sorting the list in descending
    order and selecting the first node. As I mentioned before, ties will be sorted
    based on the alphabetical sorting of the node ID. We create a network graph from
    packets broken by the lexicographical sorting of node IDs.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`MultiDiGraph` `net_graph`中的所有边添加到一个新的有向图`dG`中，这样NetworkX就可以将节点之间的多个边总结为一条具有合并`weight`属性的单一边。然后，我们使用总结后的图中的出度来找到具有最大值的节点，通过将列表按降序排序并选择第一个节点。正如我之前提到的，平局节点将根据节点ID的字母顺序进行排序。我们从分组中创建一个网络图，并通过节点ID的字典顺序进行排序。
- en: The code in [Listing 4-6](#listing4-6) will identify node `1c:6a:7a:0e:e0:44`
    as the one with the most outbound connections, connected with 13 other nodes in
    the network. The code in the Jupyter notebook *Chapter 4 - Packet Analysis with
    Graphs.ipynb* (in the supplemental materials) will collect these machines into
    a subgraph like the one shown in [Figure 4-4](#figure4-4).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[Listing 4-6](#listing4-6)中的代码将识别出节点`1c:6a:7a:0e:e0:44`作为具有最多外部连接的节点，它与网络中的13个其他节点相连。Jupyter笔记本中的代码*Chapter
    4 - Packet Analysis with Graphs.ipynb*（在补充材料中）将把这些机器收集成一个子图，类似于[Figure 4-4](#figure4-4)所示的样子。'
- en: '![](image_fi/502567c04/f04004.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c04/f04004.png)'
- en: 'Figure 4-4: A graph of the node with the most outbound connections'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 4-4：具有最多外部连接的节点的图示
- en: You can see the node generating the traffic on the left, with outbound arrows
    and all 13 systems it has communicated with spread out in what’s known as a *shell
    layout* (because it looks like a seashell).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到左侧显示了生成流量的节点，带有向外的箭头，并且它与13个通信过的系统在所谓的*外壳布局*中展开（因为它看起来像一个海贝壳）。
- en: You’d often perform an analysis like this as a follow-up step after you’ve identified
    a suspicious machine. By examining the types of systems that machine has contacted,
    you can gain more insight into the skills, motivations, and tools of the potential
    attacker. If you were to continue this analysis, the next step would be to gather
    the packets associated with each edge and analyze them using your favorite packet
    analysis methods.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你通常会在识别出一个可疑机器之后执行这样的分析作为后续步骤。通过检查该机器联系过的系统类型，你可以更深入了解潜在攻击者的技能、动机和工具。如果继续进行此分析，下一步将是收集与每条边相关的分组，并使用你喜欢的分组分析方法进行分析。
- en: Identifying the Most Absorbent Node
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 确定吸收最多数据的节点
- en: 'Next we want to find the machine that is absorbing (taking in more than it’s
    sending out) the most data, meaning the node with the largest information exchange
    ratio. The *information exchange ratio (IER)* can be stated mathematically as
    the ratio of in-degree weight to out-degree weight for a given node:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们要找出吸收（接收的数据多于发送的数据）最多数据的机器，也就是信息交换比率最大的节点。*信息交换比率（IER）*可以数学地表示为给定节点的入度权重与出度权重的比率：
- en: '![](image_fi/502567c04/m04004.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c04/m04004.png)'
- en: Intuitively, a machine that receives three bytes for every one byte sent will
    get a ratio like 3:1\. A machine that generates more packets than it consumes
    would have an inverse of this ratio, 1:3 (one byte received for every three bytes
    sent). The formula adds 1 to the numerator and denominator to avoid any 0s in
    the calculation. NetworkX doesn’t provide a handy function for information exchange
    ratios, so we create the function in [Listing 4-7](#listing4-7) to calculate the
    ratio for every node.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，一个每接收三字节数据、发送一字节数据的机器，其比率大致为3:1。一个生成的分组比消耗的更多的机器，其比率则是倒数，即1:3（每接收一个字节，发送三个字节）。这个公式通过在分子和分母上加1来避免计算中的0。NetworkX并没有提供一个方便的函数来计算信息交换比率，因此我们在[Listing
    4-7](#listing4-7)中创建了一个函数，用于计算每个节点的比率。
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Listing 4-7: A function for calculating all IERs'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Listing 4-7：用于计算所有IER的函数
- en: We start by looping over all of the node IDs in the input graph ❶ and calling
    the `graph.out_edges` and `graph.in_edges` functions for the current node ❷. For
    nodes with an outbound-edge count greater than zero, we use a list comprehension
    to gather the weights and then immediately pass this list of weights to the `sum`
    function, adding 1 to the sum ❸. We assign a base value of `1` to any nodes with
    out-degree `0` ❹. (A node with no inbound edges and no outbound edges would get
    a value of 1 / 1 = `1`.) A node with one inbound edge and zero outbound edges
    would get a score of 2 / 1, and so on. We repeat the process for inbound edges,
    then divide the two summed weights to produce the IER for the current node ❺.
    Finally, we return a list of tuples, sorted by the ratio value in ascending order.
    To sort by descending order instead, you would use the parameter `reverse=True`
    in the call to `sorted`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先遍历输入图中的所有节点 ID ❶，并为当前节点调用`graph.out_edges`和`graph.in_edges`函数 ❷。对于具有大于零的出度边数量的节点，我们使用列表推导式收集权重，并立即将这个权重列表传递给`sum`函数，再加上
    1 以得到总和 ❸。对于出度为`0`的节点，我们赋予其一个基础值`1` ❹。（没有入边和出边的节点将得到 1 / 1 = `1` 的值。）一个只有一个入边且没有出边的节点将得到
    2 / 1 的分数，依此类推。我们对入边进行相同的处理，然后将两个权重总和相除，得到当前节点的 IER ❺。最后，我们返回一个元组列表，按比例值升序排序。如果要按降序排序，只需在调用`sorted`时使用参数`reverse=True`。
- en: We can call the `exchange_ratios` function, as shown in [Listing 4-8](#listing4-8).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以调用`exchange_ratios`函数，如[清单 4-8](#listing4-8)所示。
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Listing 4-8: Finding the nodes with the highest information absorption ratio'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 4-8：查找具有最高信息吸收比的节点
- en: 'This code is very similar to [Listing 4-5](#listing4-5), where we measured
    the z-score of the in-degree for each node. We begin by calling the `exchange_ratios`
    function on the previously created `net_graph` object and storing the resulting
    list of tuples to the `ier_scores` variable ❶. Next we define the confidence threshold
    we’ll use for our z-score test ❷. A 99 percent confidence level (rounded to three
    decimal places) will consider data whose value is more than 2.326 standard deviations
    above the mean to be outliers. To generate the list of z-scores, we pass in a
    list containing just the score element of each tuple in the `ier_scores` list
    ❸. We use the `np.where` function to find the indexes where the z-score of the
    IER value is greater than our defined threshold ❹. Finally, we use the returned
    indexes to look up the corresponding node and IER score in the `ier_scores` list
    ❺. When I run the code, I get this output:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码与[清单 4-5](#listing4-5)非常相似，在那里我们测量了每个节点的入度 z 分数。我们首先调用之前创建的`net_graph`对象上的`exchange_ratios`函数，并将返回的元组列表存储到`ier_scores`变量
    ❶。接着，我们定义我们用于 z 分数测试的置信度阈值 ❷。99% 的置信度（四舍五入到小数点后三位）将认为值超过均值 2.326 个标准差的数据是异常值。为了生成
    z 分数列表，我们传入一个仅包含`ier_scores`列表中每个元组的分数元素的列表 ❸。我们使用`np.where`函数查找 IER 值的 z 分数大于我们定义的阈值的位置索引
    ❹。最后，我们使用返回的索引在`ier_scores`列表中查找相应的节点和 IER 分数 ❺。当我运行这段代码时，得到如下输出：
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: These three nodes all have IER scores we can be 99 percent sure fall outside
    the range of normal variance for this network. We can safely ignore the `ff:ff:ff:ff:ff:ff`
    result, which is known as the network’s *broadcast address*. Programs can send
    a packet to this address when they want to tell the network to broadcast the packet
    to all machines on the network. We’d expect the broadcast address to have one
    of the highest IERs since it shouldn’t be generating any traffic of its own. We
    find that the node with the highest absorption ratio is `01:00:5e:00:00:fb`, with
    46,026.0 bytes absorbed per byte generated. Another item to note about this result
    is that the lead node’s score of 46,026.0 is more than double the next highest
    outlier, `01:00:5e:7f:ff:fa` (ignoring the broadcast address).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个节点的 IER 分数，我们可以 99% 确定它们超出了该网络正常变异范围。我们可以放心地忽略`ff:ff:ff:ff:ff:ff`结果，它是网络的*广播地址*。程序可以将数据包发送到此地址，以告知网络将数据包广播到网络中的所有机器。我们预计广播地址会有最高的
    IER，因为它不应该生成任何自身的流量。我们发现，吸收比最高的节点是`01:00:5e:00:00:fb`，每生成一个字节就吸收了 46,026.0 字节。需要注意的是，领先节点的分数
    46,026.0 是下一个最高异常值`01:00:5e:7f:ff:fa`的两倍多（忽略广播地址）。
- en: Nodes that absorb a lot of data from the network are interesting for several
    security reasons. For one, a node with a higher IER than average could be downloading
    a large number of files; a download like this generally starts with one to two
    packets sent to request the file and a much larger number of packets received
    that contain the actual file data. The act of downloading a large amount of data
    from the network isn’t necessarily dangerous itself, but it may indicate someone
    who is crawling the network looking for sensitive information. It could also indicate
    an attempt to exfiltrate data after a breach has occurred. Therefore, it’s worth
    investigating the cause for the change in the IER.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收大量网络数据的节点在多个安全方面都很有趣。首先，一个比平均值更高的IER的节点可能正在下载大量文件；这样的下载通常从发送一到两个数据包请求文件开始，然后接收大量包含实际文件数据的数据包。下载大量数据本身不一定是危险的，但它可能表明有人在爬取网络寻找敏感信息。它也可能是发生泄露后试图窃取数据的表现。因此，值得调查IER变化的原因。
- en: I hope at this point I’ve piqued your curiosity about the structures you can
    find hidden in the network graph. This is a great starting point for identifying
    suspicious machines but leaves plenty for you to investigate on your own. For
    example, earlier we identified the suspicious machine `1c:6a:7a:0e:e0:41`. Can
    you determine from the data how many different IP addresses this machine has?
    Perhaps building a subgraph to show their communication over time would give you
    more insight into their behavior.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望到现在为止，我已经激起了你对网络图中隐藏结构的好奇心。这是识别可疑机器的一个很好的起点，但仍然有很多内容需要你自己去探索。例如，前面我们识别出了可疑机器`1c:6a:7a:0e:e0:41`。你能从数据中判断出这台机器有多少个不同的IP地址吗？也许构建一个子图，展示它们随时间的通信情况，会让你更深入地了解它们的行为。
- en: You might also try applying the clique analysis techniques we discussed in [Chapter
    3](c03.xhtml) to see if you can locate any communication clusters. First, ask
    yourself, “What network scenario would create a clique between computers?” and
    then see if any cliques in the network support or disprove this hypothesis. This
    pattern of guess-then-test is at the heart of all applied sciences. I haven’t
    investigated this avenue in the data myself, so you might find some interesting
    insights uniquely your own. Gaining these new self-motivated insights is the real
    power and reward of applying mathematics to security topics.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以尝试应用我们在[第3章](c03.xhtml)讨论的团体分析技术，看看能否找到任何通信簇。首先，问问自己：“什么样的网络场景会在计算机之间创建一个团体？”然后查看网络中是否有任何团体支持或反驳这个假设。这种猜测-再测试的模式是所有应用科学的核心。我自己并没有在数据中进行这方面的调查，所以你可能会找到一些你自己独特的、有趣的见解。获得这些自发的见解，才是真正应用数学到安全话题中的力量和奖励。
- en: 'The Proof of Concept: Network Traffic Analysis'
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概念验证：网络流量分析
- en: ''
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To continue applying graph theory to network traffic analysis, you can download
    publicly available pcaps or capture packets from the networks around you (with
    permission, of course!), then build a graph from the capture and analyze to your
    heart’s content. Where many researchers struggle isn’t with applying the analysis
    but with constructing the graph in the first place. You’ve already seen an example
    of this in [Listing 4-1](#listing4-1), so you’re ahead of the game! I’ll therefore
    conclude this chapter with a proof that shows how to practically bridge the gap
    between data in the wild and a pretty graph you can analyze. This proof of concept
    generates a graph from either a previously captured file or live data read from
    a network interface, then saves the graph as an edge list file that you can load
    into other analysis scripts. I encourage you to download the proof of concept,
    experiment with it, and then incorporate it into a larger tool specific to your
    application.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了继续将图论应用于网络流量分析，你可以下载公开的pcap文件，或者从你周围的网络捕获数据包（当然，需要获得许可！），然后从捕获的文件构建图并尽情分析。许多研究人员面临的困难不在于应用分析，而在于首先构建图。你已经在[示例4-1](#listing4-1)中看到了一个例子，因此你已经走在了前面！因此，我将在本章结束时提供一个证明，展示如何实际弥合野外数据和漂亮的可分析图之间的差距。这个概念验证从之前捕获的文件或从网络接口读取的实时数据生成图，然后将图保存为边列表文件，你可以将其加载到其他分析脚本中。我鼓励你下载这个概念验证，进行实验，然后将其整合到更大的工具中，特定于你的应用程序。
- en: 'You’ll need the files *packet_analysis/packet_analysis.py*, which contains
    the code to define the command line interface (CLI), and *packet_analysis/graph_funcs.py*,
    which contains the functions we’ve discussed so far and a few other helpful ones.
    The `pcap_graph` function defines a function wrapper for the code in [Listing
    4-1](#listing4-1), which allows you to pass in a list of packets to work from.
    The `save_packet` function is a convenience function used to append captured packet
    data to a given pcap file using Scapy’s `wrpcap` (short for *write pcap*) function.
    Once the file is written, you can use the `file_to_graph` function to load the
    captured data using Scapy’s `rdpcap` (short for *read pcap*) function. Then you’ll
    use the `pcap_graph` function to convert the packet data into a `MultiDiGraph`
    object for analysis, as shown in the following code:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你将需要*packet_analysis/packet_analysis.py*文件，该文件包含定义命令行接口（CLI）的代码，以及*packet_analysis/graph_funcs.py*文件，该文件包含我们目前讨论的函数和一些其他有用的函数。`pcap_graph`函数定义了一个函数包装器，用于[清单4-1](#listing4-1)中的代码，它允许你传入一个数据包列表进行处理。`save_packet`函数是一个便捷函数，用于使用Scapy的`wrpcap`（*write
    pcap*的缩写）函数将捕获的数据包数据附加到指定的pcap文件中。一旦文件被写入，你可以使用`file_to_graph`函数通过Scapy的`rdpcap`（*read
    pcap*的缩写）函数加载捕获的数据。然后，你将使用`pcap_graph`函数将数据包数据转换为`MultiDiGraph`对象进行分析，如下代码所示：
- en: '[PRE12]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Once the graph object has been created, you can use the `save_graph` function
    (which is a wrapper for NetworkX’s `write_weighted_edgelist` function) to write
    the weighted edge representation out to a file. Storing a packet capture as an
    edge list reduces the load time for graphs. Rather than converting packets to
    edges on each analysis run, you simply create the base graph one time and then
    load it (rather than the pcap data) for future analysis. This workflow is known
    as *write once, read many* (or *WORM*, after the data storage term of the same
    name).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦图形对象创建完成，你可以使用`save_graph`函数（这是NetworkX的`write_weighted_edgelist`函数的封装器）将加权边表示写入文件。将数据包捕获存储为边列表可以减少图形的加载时间。与其在每次分析运行时将数据包转换为边，不如一次性创建基础图并在未来的分析中加载它（而不是pcap数据）。这种工作流程被称为*写一次，读多次*（或*WORM*，源自同名的数据存储术语）。
- en: Whenever I’m working on a proof of concept, I forgo fancy UIs and usually wrap
    a CLI around the code I want to test. Keeping things simple lets you focus on
    the core concepts without getting sidetracked by display issues or unrelated interaction
    problems. The proof of concept for this chapter uses the optparse library to create
    a set of packet capture options you can use to configure how many packets to capture,
    where you want to capture them, and more. To start, open your command console,
    navigate to the *packet_analysis/* directory, and run
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我进行概念验证时，我都会放弃华丽的用户界面，通常会在我想测试的代码周围包装一个命令行界面（CLI）。保持简单可以让你专注于核心概念，而不会被显示问题或无关的交互问题分散注意力。本章的概念验证使用了optparse库来创建一组数据包捕获选项，你可以用来配置捕获多少数据包、你希望从哪里捕获它们，等等。首先，打开命令行控制台，导航到*packet_analysis/*目录，并运行
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This should bring up the options available for running the proof of concept,
    as shown in [Listing 4-9](#listing4-9).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该会显示用于运行概念验证的可用选项，如[清单4-9](#listing4-9)所示。
- en: '[PRE14]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Listing 4-9: Proof-of-concept run options'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 清单4-9：概念验证运行选项
- en: As you can see, the `-h` option corresponds to help. By default optparse includes
    this option and will print out whatever help messages you define for each option.
    These are a great way to jog your memory if you set a project down and have to
    come back to it. The rest of the options and the logic to implement them are stored
    in the *packet_analysis.py* file.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`-h`选项对应帮助。默认情况下，optparse包含此选项，并会打印出你为每个选项定义的帮助消息。如果你放下一个项目一段时间后再回来，这些帮助消息会是一个很好的提醒。其余的选项和实现它们的逻辑存储在*packet_analysis.py*文件中。
- en: 'To capture some number of packets from all network interfaces, then save them
    as a graph representation, use a command like this:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要从所有网络接口捕获一定数量的数据包，然后将它们保存为图形表示，可以使用类似下面的命令：
- en: '[PRE15]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `-i` (`--iface`) option takes an interface name as a string. In the special
    case of the string `all`, Scapy tries to bind to all available network interfaces.
    The `-c` (`--count`) option defines the number of packets to capture before exiting
    the sniffer. This isn’t strictly necessary in your programs, but it helps during
    prototyping to keep the file sizes manageable. Finally, the `-s` (`--graph-out`)
    option specifies where you want to output the weighted edge list file generated
    when you call the `nx.write_weighted_edgelist` function. Once you’ve saved the
    packet capture graph as a weighted edge list, you can use it in your own analysis
    scripts by reloading the edge list into a graph using `nx.read_weighted_edgelist`:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`-i`（`--iface`）选项接受一个接口名称作为字符串。在特殊情况下，字符串`all`表示Scapy会尝试绑定到所有可用的网络接口。`-c`（`--count`）选项定义在退出嗅探器之前要捕获的数据包数量。这个选项在你的程序中并非严格必要，但在原型设计时，它有助于保持文件大小可管理。最后，`-s`（`--graph-out`）选项指定你希望输出加权边列表文件的位置，该文件是在调用`nx.write_weighted_edgelist`函数时生成的。一旦你将数据包捕获图保存为加权边列表，你可以通过使用`nx.read_weighted_edgelist`将其重新加载到图中，供自己的分析脚本使用：'
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: By default, NetworkX creates an undirected graph from the edge list. To create
    a directed graph instead, you’d pass `nx.DiGraph` in the `create_using` parameter.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，NetworkX会从边列表创建一个无向图。要创建一个有向图，你需要在`create_using`参数中传入`nx.DiGraph`。
- en: 'You can also use the proof of concept to create a weighted edge list file from
    an existing pcap file, which can come in handy for retrospective analysis. To
    convert the *net_sim.pcap* file into a weighted edge list file, you combine the
    `-l` (`--load`) argument with the `-s` parameter like so:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用概念验证来从现有的pcap文件创建加权边列表文件，这对于事后分析非常有用。要将*net_sim.pcap*文件转换为加权边列表文件，你可以将`-l`（`--load`）参数与`-s`参数结合使用，如下所示：
- en: '[PRE17]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The proof of concept also supports capturing packets from a specific interface
    and saving them to both a pcap and an edge list file. By doing both simultaneously,
    you retain the most information. You can start future graphs right from the edge
    list without needing to convert a pcap file first, but can still send the pcap
    data to other tools. The next command shows how to use the `-r` (`--raw-out`)
    parameter in combination with other parameters to create a pcap file along with
    the graph. This is most useful when you’re capturing from a live traffic stream
    (otherwise you’d already have the pcap file). To capture traffic, the script needs
    permission to put the network card into promiscuous mode, which is a restricted
    function on most systems, so you’ll need to run the following command as the root
    user on Linux and macOS or as the administrator account on Windows. (If you’re
    running your setup in Anaconda, you’ll need to create the virtual environment
    using the privileged account so you can run the script with the proper permissions.)
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 概念验证还支持从特定接口捕获数据包并将其保存到pcap和边列表文件中。通过同时执行这两个操作，你可以保留更多信息。你可以直接从边列表开始创建未来的图，而无需先转换pcap文件，但仍然可以将pcap数据发送到其他工具。以下命令展示了如何将`-r`（`--raw-out`）参数与其他参数结合使用，以便同时创建pcap文件和图。这在从实时流量捕获时最为有用（否则你已经有了pcap文件）。要捕获流量，脚本需要权限将网卡设置为混杂模式，这是大多数系统上的受限功能，因此你需要在Linux和macOS上以root用户身份运行以下命令，或者在Windows上以管理员帐户运行。（如果你在Anaconda中运行设置，你需要使用特权帐户创建虚拟环境，以便能够以正确的权限运行脚本。）
- en: '[PRE18]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Make sure you change `eth0` to an interface on your machine when you run this
    command. If you’re on a Windows machine, it can be hard to locate the proper device
    name. It may be easiest to use the `-i all` option if you’re using only one network
    interface. The result will be an additional file that contains all of the raw
    packet information.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行此命令时，确保将`eth0`更改为你机器上的接口。如果你使用的是Windows系统，可能很难找到正确的设备名称。如果你只使用一个网络接口，最简单的方法是使用`-i
    all`选项。结果将是一个包含所有原始数据包信息的附加文件。
- en: This method takes up the most storage space of all the options. The exact amount
    of storage required depends on the number of packets captured as well as the amount
    of information stored for each edge. Be sure to monitor your machine’s storage
    capacity when doing large captures (more than 2,000 packets, for example). You
    can set the number of packets captured using the `-c` flag. Alternatively, you
    can send the resulting files to a cloud storage location, and potentially aggregate
    captures for truly big data analytics. We’ll discuss cloud deployments more in
    [Chapter 13](c13.xhtml).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法占用的存储空间是所有选项中最多的。所需的存储量取决于捕获的包数量以及为每个边存储的信息量。在进行大规模捕获（例如，超过2000个数据包）时，务必监控机器的存储容量。你可以使用`-c`标志来设置捕获的数据包数量。或者，你可以将结果文件发送到云存储位置，并可能将捕获数据汇总以进行真正的大数据分析。我们将在[第13章](c13.xhtml)中进一步讨论云部署。
- en: Summary
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter serves as a good starting point for you to build your future network
    analysis tools. You should now feel comfortable loading a network as a graph,
    locating interesting nodes using some statistical analysis, and reorganizing the
    data to suit your questions. You’ve seen practical examples of how to capture
    the source data in the proof-of-concept code. Now it’s time for you to expand
    on your own research. You can add more information to the edge attributes (including
    time of creation, for example), extend it to handle other protocol layers (ICMP
    would be a good place to start), and make many other useful improvements. Once
    you’re familiar with turning packet data into measurable graphs and manipulating
    them using NetworkX, you can refer to research dealing with the structure of computer
    networks, which is plentiful and easily accessible through search engines, to
    extend your analysis.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 本章为你构建未来的网络分析工具提供了一个良好的起点。你现在应该能够轻松地将网络加载为图形，使用一些统计分析找到有趣的节点，并重新组织数据以适应你的问题。你已经看到如何在概念验证代码中捕获源数据的实际例子。现在是时候展开你自己的研究了。你可以向边属性中添加更多信息（例如，创建时间），将其扩展到处理其他协议层（ICMP是一个不错的起点），并进行许多其他有用的改进。一旦你熟悉了如何将数据包数据转换为可度量的图形，并使用NetworkX进行操作，你可以参考有关计算机网络结构的研究，这些研究丰富且通过搜索引擎易于访问，从而扩展你的分析。
- en: For example, if you’re interested in applying graph theory to understand resource
    usage in the cloud, check out the research paper by Kanniga Devi Rangaswamy and
    Murugaboopathi Gurusamy, “Application of Graph Theory Concepts in Computer Networks
    and its Suitability for the Resource Provisioning Issues in Cloud Computing—A
    Review,”^([1](b01.xhtml#c04-endnote-001)) which also contains a list of resources
    related to graph theory and a description of the theory covered. That section
    alone makes the paper a must-read in my opinion.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你有兴趣将图论应用于理解云计算中的资源使用，可以查阅Kanniga Devi Rangaswamy和Murugaboopathi Gurusamy的研究论文《图论概念在计算机网络中的应用及其在云计算资源供应问题中的适用性——综述》^([1](b01.xhtml#c04-endnote-001))，该论文还包含了与图论相关的资源列表以及所涉及理论的描述。我认为，仅这一部分就使得该论文成为必读之作。
- en: As you’ve seen through this first project chapter, the key to translating theory
    into practice lies in formulating well-defined questions. For example, the protocol
    usage question allowed us to identify a potential threat on the network. Books
    like *Practical Packet Analysis*^([2](b01.xhtml#c04-endnote-002)) by Chris Sanders
    and *Attacking Network Protocols*^([3](b01.xhtml#c04-endnote-003)) by James Forshaw
    can give you more specific network dissection knowledge that will help you ask
    better questions of your data. As you read through these books, think of how the
    tools and techniques you learn about rely on the principles we’ve applied here.
    Perhaps you’ll find a unique way to analyze a network protocol of interest to
    you.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本项目的第一章中看到的那样，将理论转化为实践的关键在于提出明确的问题。例如，协议使用问题使我们能够识别网络中的潜在威胁。像*《实用数据包分析》*^([2](b01.xhtml#c04-endnote-002))（克里斯·桑德斯著）和*《攻击网络协议》*^([3](b01.xhtml#c04-endnote-003))（詹姆斯·福肖著）这样的书籍可以为你提供更具体的网络剖析知识，帮助你提出更好的数据问题。在阅读这些书籍时，思考你所学习的工具和技术如何依赖于我们在此应用的原则。或许你会找到一种独特的方式，来分析一个你感兴趣的网络协议。
- en: In the next chapter, we’ll leave behind this world of digital order for the
    less defined world of social networks and ask questions that will completely redefine
    our understanding of a graph.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将告别这个数字秩序的世界，进入一个定义不那么明确的社交网络世界，并提出问题，这些问题将彻底重新定义我们对图的理解。
