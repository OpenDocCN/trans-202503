- en: '**11 Neuroevolution**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**11 神经进化**'
- en: '*Reading about nature is fine, but if a person walks in the woods and listens
    carefully, they can learn more than what is in books.*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*读关于大自然的书固然好，但如果一个人走进森林，仔细倾听，他们能学到比书本上更多的东西。*'
- en: —George Washington Carver
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: —乔治·华盛顿·卡佛
- en: '![Image](../images/pg583_Image_874.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg583_Image_874.jpg)'
- en: '**Star-nosed moles (courtesy of New York Public Library, c. 1826–1828)**'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**星鼻鼹鼠（图片由纽约公共图书馆提供，约1826–1828年）**'
- en: The star-nosed mole (*Condylura cristata*), found mainly in the northeastern
    United States and eastern Canada, has a unique and highly specialized nasal organ.
    Evolved over numerous generations, its nose consists of 22 tentacles with over
    25,000 minute sensory receptors. Despite the moles being functionally blind, these
    tentacles allow them to create a detailed spatial map of their surroundings. They
    can navigate their dark underground habitat with astonishing precision and speed,
    quickly identifying and consuming edible items in a matter of milliseconds.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 星鼻鼹鼠（*Condylura cristata*）主要分布在美国东北部和加拿大东部，具有独特且高度专业化的鼻部器官。经过多代进化，它的鼻子由22个触角组成，拥有超过25,000个微小的感官受体。尽管鼹鼠功能性失明，这些触角使它们能够创建其周围环境的详细空间地图。它们可以在漆黑的地下栖息地中以惊人的精确度和速度导航，迅速识别并消耗可食用的物品，仅需毫秒级的时间。
- en: Congratulations! You’ve made it to the final act of this book. Take a moment
    to celebrate all that you’ve learned.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经完成了本书的最后一章。花点时间庆祝你所学到的一切。
- en: '![Image](../images/pg584_Image_875.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg584_Image_875.jpg)'
- en: Throughout this book, you’ve explored the fundamental principles of interactive
    physics simulations with p5.js, dived into the complexities of agent and other
    rule-based behaviors, and dipped your toe into the exciting realm of machine learning.
    You’ve become a natural!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，你已经探讨了使用 p5.js 进行互动物理仿真的基本原理，深入了解了智能体和其他基于规则的行为的复杂性，并初步接触了激动人心的机器学习领域。你已经变得非常自然！
- en: However, [Chapter 10](ch10.xhtml#ch10) merely scratched the surface of working
    with data and neural network–based machine learning—a vast landscape that would
    require countless sequels to this book to cover comprehensively. My goal was never
    to go deep into neural networks, but simply to establish the core concepts in
    preparation for a grand finale, where I find a way to integrate machine learning
    into the world of animated, interactive p5.js sketches and bring together as many
    of our new *Nature of Code* friends as possible for one last hurrah.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，[第10章](ch10.xhtml#ch10)仅仅触及了数据和基于神经网络的机器学习的表面——这是一个广阔的领域，若要全面覆盖，将需要无数本续集来完成。我的目标从来不是深入探讨神经网络，而是简单地建立核心概念，为一个盛大的结局做准备，在这个结局中，我将找到将机器学习融入动画、互动
    p5.js 草图的世界的方法，并为我们的*《代码的本质》*新朋友们带来最后的欢庆。
- en: The path forward passes through the field of **neuroevolution**, a style of
    machine learning that combines the GAs from [Chapter 9](ch09.xhtml#ch09) with
    the neural networks from [Chapter 10](ch10.xhtml#ch10). A neuroevolutionary system
    uses Darwinian principles to evolve the weights (and in some cases, the structure
    itself) of a neural network over generations of trial-and-error learning. In this
    chapter, I’ll demonstrate how to use neuroevolution with a familiar example from
    the world of gaming. I’ll then finish off by varying Craig Reynolds’s steering
    behaviors from [Chapter 5](ch05.xhtml#ch05) so that they are learned through neuroevolution.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的道路将穿过**神经进化**领域，这是一种将[第9章](ch09.xhtml#ch09)中的遗传算法与[第10章](ch10.xhtml#ch10)中的神经网络相结合的机器学习方法。神经进化系统利用达尔文进化原理，通过几代的试错学习来进化神经网络的权重（在某些情况下，甚至是网络结构本身）。在本章中，我将通过一个熟悉的游戏世界示例来演示如何使用神经进化。接着，我将通过神经进化来修改克雷格·雷诺兹在[第5章](ch05.xhtml#ch05)中的转向行为。
- en: '**Reinforcement Learning**'
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**强化学习**'
- en: Neuroevolution shares many similarities with another machine learning methodology
    that I briefly referenced in [Chapter 10](ch10.xhtml#ch10), **reinforcement learning**,
    which incorporates machine learning into a simulated environment. A neural network–backed
    agent learns by interacting with the environment and receiving feedback about
    its decisions in the form of rewards or penalties. It’s a strategy built around
    observation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 神经进化与我在[第10章](ch10.xhtml#ch10)中简要提到的另一种机器学习方法——**强化学习**有许多相似之处，后者将机器学习融入了一个模拟环境中。一个基于神经网络的智能体通过与环境互动，并通过奖励或惩罚的反馈来学习其决策。这是一种围绕观察建立的策略。
- en: Think of a little mouse running through a maze. If it turns left, it gets a
    piece of cheese; if it turns right, it receives a little shock. (Don’t worry,
    this is just a pretend mouse.) Presumably, the mouse will learn over time to turn
    left. Its biological neural network makes a decision with an outcome (turn left
    or right) and observes its environment (yum or ouch). If the observation is negative,
    the network can adjust its weights in order to make a different decision the next
    time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一只小鼠在迷宫里跑。如果它左转，它就能得到一块奶酪；如果它右转，它就会受到轻微的电击。（别担心，这只是只假装的小鼠。）可以假设，小鼠会随着时间的推移学会左转。它的生物神经网络做出决策并观察结果（左转或右转），如果观察结果是负面的，网络会调整权重，以便下次做出不同的决策。
- en: In the real world, reinforcement learning is commonly used not for tormenting
    rodents but rather for developing robots. At time *t*, the robot performs a task
    and observes the results. Did it crash into a wall or fall off a table, or is
    it unharmed? As time goes on, the robot learns to interpret the signals from its
    environment in the optimal way to accomplish its tasks and avoid harm.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，强化学习通常用于开发机器人，而不是用来折磨小动物。在时间 *t* 时，机器人执行任务并观察结果。它是否撞到墙壁或从桌子上掉下来，或者它是否没有受伤？随着时间的推移，机器人学会以最优的方式解读来自环境的信号，以完成任务并避免伤害。
- en: Instead of a mouse or a robot, now think about any of the example objects from
    earlier in this book (walker, mover, particle, vehicle). Imagine embedding a neural
    network into one of these objects and using it to calculate a force or another
    action. The neural network could receive its inputs from the environment (such
    as distance to an obstacle) and output some kind of decision. Perhaps the network
    chooses from a set of discrete options (move left or right) or picks a set of
    continuous values (the magnitude and direction of a steering force).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，不是小鼠或机器人，想象一下本书早些时候提到的示例对象（行走者、移动者、粒子、车辆）。假设将一个神经网络嵌入到这些对象中的一个，并用它来计算一个力或其他动作。神经网络可以从环境中获取输入（例如到障碍物的距离），并输出某种决策。也许网络从一组离散选项中做出选择（向左或向右移动），或者选择一组连续值（转向力的大小和方向）。
- en: Is this starting to sound familiar? It’s no different from the way a neural
    network performed after training in the [Chapter 10](ch10.xhtml#ch10) examples,
    receiving inputs and predicting a classification or regression! Actually training
    one of these objects to make a good decision is where the reinforcement learning
    process diverges from the supervised learning approach. To better illustrate,
    let’s start with a hopefully easy-to-understand and possibly familiar scenario,
    the game *Flappy Bird* (see [Figure 11.1](ch11.xhtml#ch11fig1)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这开始听起来有点熟悉吗？它和神经网络在[第10章](ch10.xhtml#ch10)中的例子完全一样，接收输入并预测分类或回归！实际上，训练这些对象做出正确决策的过程，就是强化学习与监督学习方法的区别所在。为了更好地说明这一点，让我们从一个可能容易理解且可能熟悉的场景开始——游戏
    *Flappy Bird*（见[图 11.1](ch11.xhtml#ch11fig1)）。
- en: The game is deceptively simple. You control a small bird that continually moves
    horizontally across the screen. With each tap or click, the bird flaps its wings
    and rises upward. The challenge? A series of vertical pipes spaced apart at irregular
    intervals emerge from the right. The pipes have gaps, and your primary objective
    is to navigate the bird safely through these gaps. If you hit a pipe, it’s game
    over. As you progress, the game’s speed increases, and the more pipes you navigate,
    the higher your score.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个游戏看似简单。你控制一只小鸟，它不断地横向移动。每次点击或触摸，鸟儿就会拍动翅膀并向上飞升。挑战是什么呢？一系列不规则间隔的竖直管道从右侧出现。管道之间有间隙，你的主要目标是让小鸟安全地穿过这些间隙。如果撞到管道，就会游戏结束。随着游戏的进行，速度逐渐加快，你穿越的管道越多，得分也越高。
- en: '![Image](../images/pg586_Image_876.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/pg586_Image_876.jpg)'
- en: 'Figure 11.1: The *Flappy Bird* game'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '图 11.1: *Flappy Bird* 游戏'
- en: Suppose you want to automate the gameplay, and instead of a human tapping, a
    neural network will make the decision of whether to flap. Could machine learning
    work here? Skipping over the initial data steps in the machine learning life cycle
    for a moment, let’s think about how to choose a model. What are the inputs and
    outputs of the neural network?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要自动化游戏玩法，而不是由人类点击，而是由神经网络决定是否要拍打翅膀。那么机器学习在这里能起作用吗？暂时跳过机器学习生命周期中的初始数据步骤，让我们来思考如何选择一个模型。神经网络的输入和输出是什么？
- en: This is quite the intriguing question because, at least in the case of the inputs,
    there isn’t a definitive answer. If you don’t know much about the game or don’t
    want to put your thumb on the scale in terms of identifying which aspects of the
    game are important, it might make the most sense to have the inputs be all the
    pixels of the game screen. This approach attempts to feed *everything* about the
    game into the model and let the model figure out for itself what matters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当有趣的问题，因为至少在输入的情况下，并没有明确的答案。如果你对游戏了解不多，或者不想在识别哪些游戏方面重要时偏袒一方，那么让输入成为游戏屏幕的所有像素可能是最合适的做法。这种方法尝试将*游戏的一切*都输入到模型中，让模型自己决定什么是重要的。
- en: 'I’ve played *Flappy Bird* enough that I feel I understand it quite well, however.
    I can therefore bypass feeding all the pixels to the model and boil down the essence
    of the game to just a few input data points necessary for making predictions.
    These data points, often referred to as **features** in machine learning, represent
    the distinctive characteristics of the data that are most salient for the prediction.
    Imagine biting into a mysteriously juicy fruit—features like its taste (sweet!),
    texture (crisp!), and color (a vibrant red!) help you identify it as an apple.
    In the case of *Flappy Bird*, the most crucial features are listed here:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我已经玩过足够多的*Flappy Bird*，并且感觉我已经相当了解它。因此，我可以跳过将所有像素输入到模型的步骤，并将游戏的本质简化为仅几个必要的输入数据点，用于做出预测。这些数据点在机器学习中通常被称为**特征**，代表了对于预测最为重要的数据的独特特征。想象一下咬一口神秘多汁的水果——它的味道（甜！）、质地（脆！）和颜色（鲜红！）等特征帮助你把它识别为苹果。在*Flappy
    Bird*的情况下，最关键的特征列举如下：
- en: The y-position of the bird
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 小鸟的y坐标
- en: The y-velocity of the bird
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 小鸟的y速度
- en: The y-position of the next top pipe’s opening
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个上方管道开口的y坐标
- en: The y-position of the next bottom pipe’s opening
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个下方管道开口的y坐标
- en: The x-distance to the next pipe
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到下一个管道的x距离
- en: These features are illustrated in [Figure 11.2](ch11.xhtml#ch11fig2).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特性在[图 11.2](ch11.xhtml#ch11fig2)中有说明。
- en: '![Image](../images/pg587_Image_877.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg587_Image_877.jpg)'
- en: 'Figure 11.2: The *Flappy Bird* input features for a neural network'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2：*Flappy Bird* 输入特征用于神经网络
- en: 'The neural network will have five inputs, one for each feature, but what about
    the outputs? Is this a classification problem or a regression problem? This may
    seem like an odd question to ask in the context of a game like *Flappy Bird*,
    but it’s actually quite important and relates to the way the game is controlled.
    Tapping the screen, pressing a button, or using keyboard controls are all examples
    of classification. After all, the player has only a discrete set of choices: tap
    or not; press W, A, S, or D on the keyboard. On the other hand, using an analog
    controller like a joystick leans toward regression. A joystick can be tilted in
    varying degrees in any direction, translating to continuous output values for
    both its horizontal and vertical axes.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络将有五个输入，每个特性对应一个输入，但输出呢？这是一个分类问题还是回归问题？在像*Flappy Bird*这样的游戏中提问这个问题似乎有些奇怪，但实际上它非常重要，并且与游戏的控制方式有关。点击屏幕、按下按钮或使用键盘控制都属于分类的例子。毕竟，玩家只有一个离散的选择集：点击或不点击；按下键盘上的
    W、A、S 或 D。另一方面，使用模拟控制器如摇杆则更倾向于回归。摇杆可以在任何方向上以不同的角度倾斜，从而在水平和垂直轴上产生连续的输出值。
- en: 'For *Flappy Bird*, the outputs represent a classification decision with only
    two choices:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*Flappy Bird*，输出代表一个分类决策，只有两个选择：
- en: Flap.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拍打。
- en: Don’t flap.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要拍打。
- en: This means the network should have two outputs, suggesting an overall network
    architecture like the one in [Figure 11.3](ch11.xhtml#ch11fig3).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着网络应该有两个输出，建议采用类似于[图 11.3](ch11.xhtml#ch11fig3)所示的整体网络架构。
- en: '![Image](../images/pg588_Image_878.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg588_Image_878.jpg)'
- en: 'Figure 11.3: The neural network for *Flappy Bird* as ml5.js might design it'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3：ml5.js可能设计的*Flappy Bird*神经网络
- en: 'I now have all the information necessary to configure a model and let ml5.js
    build it:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我拥有了配置模型并让 ml5.js 构建它所需的所有信息：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'What next? If I were following the steps I laid out in [Chapter 10](ch10.xhtml#ch10),
    I’d have to go back to steps 1 and 2 of the machine learning process: data collection
    and preparation. How exactly would that work here? One idea could be to scour
    the earth for the greatest *Flappy Bird* player of all time and record them playing
    for hours. I could log the input features for every moment of gameplay along with
    whether the player flapped or not. Feed all that data into the model, train it,
    and I can see the headlines already: “Artificial Intelligence Bot Defeats Flappy
    Bird.”'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来怎么办？如果我按照[第10章](ch10.xhtml#ch10)中列出的步骤进行操作，我就必须回到机器学习过程的第1步和第2步：数据收集和准备。这里具体该怎么做呢？一个想法是可以去寻找地球上最伟大的*Flappy
    Bird*玩家，并记录他们连续玩几个小时。我可以记录下每一时刻的输入特征以及玩家是否按下了翅膀。将所有这些数据输入模型，进行训练，我已经能看到头条新闻了：“人工智能机器人打败了*Flappy
    Bird*。”
- en: But wait a second; has a computerized agent really learned to play *Flappy Bird*
    on its own, or has it simply learned to mirror the gameplay of a human? What if
    that human missed a key aspect of *Flappy Bird* strategy? The automated player
    would never discover it. Not to mention that collecting all that data would be
    incredibly tedious.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 但等一下，计算机化的代理真的是自己学会了玩*Flappy Bird*，还是只是学会了模仿人类的游戏玩法？如果那个人错过了*Flappy Bird*策略的某个关键方面怎么办？自动化玩家永远无法发现这一点。更不用说收集所有这些数据将会非常繁琐。
- en: The problem here is that I’ve reverted to a supervised learning scenario like
    the ones from [Chapter 10](ch10.xhtml#ch10), but this is supposed to be a section
    about reinforcement learning. Unlike supervised learning, in which the correct
    answers are provided by a training dataset, the agent in reinforcement learning
    learns the answers—the optimal decisions—through trial and error by interacting
    with the environment and receiving feedback. In the case of *Flappy Bird*, the
    agent could receive a positive reward every time it successfully navigates a pipe,
    but a negative reward if it hits a pipe or the ground. The agent’s goal is to
    figure out which actions lead to the most cumulative rewards over time.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的问题是，我已经回到了像[第10章](ch10.xhtml#ch10)中的监督学习场景，但本节内容应该是关于强化学习的。与监督学习不同，在监督学习中，正确的答案是由训练数据集提供的，而在强化学习中，代理通过与环境互动并接受反馈，通过反复试验来学习答案——即最优决策。在*Flappy
    Bird*的情况下，代理每成功通过一个管道就能获得正奖励，但如果撞到管道或地面，则会得到负奖励。代理的目标是弄清楚哪些行为能够在时间上积累最多的奖励。
- en: At the start, the *Flappy Bird* agent won’t know the best time to flap its wings,
    leading to many crashes. As it accrues more and more feedback from countless play-throughs,
    however, it will begin to refine its actions and develop the optimal strategy
    to navigate the pipes without crashing, maximizing its total reward. This process
    of *learning by doing* and optimizing based on feedback is the essence of reinforcement
    learning.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始，*Flappy Bird*代理并不知道什么时候是最好的翅膀挥动时机，这会导致许多碰撞。然而，随着它从无数次游戏中积累越来越多的反馈，它将开始优化自己的行动，并开发出最佳策略，以避免碰撞并顺利通过管道，从而最大化其总奖励。这种通过*实践学习*并基于反馈进行优化的过程就是强化学习的本质。
- en: As the chapter goes on, I’ll explore the principles I’m outlining here, but
    with a twist. Traditional techniques in reinforcement learning involve defining
    a strategy (called a **policy**) and a corresponding **reward function** to provide
    feedback for adjusting the policy. Instead of going down this road, however, I’m
    going to turn toward the star of this chapter, neuroevolution.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 随着章节的推进，我将探讨这里概述的原理，但有个变化。传统的强化学习技术包括定义一个策略（称为**策略**）和相应的**奖励函数**，以便为调整策略提供反馈。然而，我不会走这条路，而是会转向本章的明星——神经进化。
- en: '**Evolving Neural Networks Is NEAT!**'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**进化神经网络真棒！**'
- en: Instead of using traditional backpropagation, a policy, and a reward function,
    neuroevolution applies principles of GAs and natural selection to train the weights
    in a neural network. This technique unleashes many neural networks on a problem
    at once. Periodically, the best-performing neural networks are “selected,” and
    their “genes” (the network connection weights) are combined and mutated to create
    the next generation of networks. Neuroevolution is especially effective in environments
    where the learning rules aren’t precisely defined or the task is complex, with
    numerous potential solutions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 神经进化（neuroevolution）通过应用遗传算法（GAs）和自然选择的原理来训练神经网络中的权重，而不是使用传统的反向传播、策略和奖励函数。这项技术能够同时将多个神经网络应用于一个问题。定期地，表现最好的神经网络会被“选择”，它们的“基因”（即网络连接权重）会被结合并发生突变，从而创造出下一代的网络。神经进化在学习规则不明确或任务复杂，且存在众多潜在解决方案的环境中，尤其有效。
- en: 'One of the first examples of neuroevolution can be found in the 1994 paper
    “Genetic Lander: An Experiment in Accurate Neuro-genetic Control” by Edmund Ronald
    and Marc Schoenauer (*[https://doi.org/10.1007/3-540-58484-6_288](https://doi.org/10.1007/3-540-58484-6_288)*).
    In the 1990s, traditional neural network training methods were still nascent,
    and this work explored an alternative approach. The paper describes how a simulated
    spacecraft—in a game aptly named *Lunar Lander*—can learn how to safely descend
    and land on a surface. Rather than use handcrafted rules or labeled datasets,
    the researchers opted to use GAs to evolve and train neural networks over multiple
    generations. And it worked!'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '神经进化的第一个示例之一可以在1994年Edmund Ronald和Marc Schoenauer的论文《Genetic Lander: An Experiment
    in Accurate Neuro-genetic Control》中找到（* [https://doi.org/10.1007/3-540-58484-6_288](https://doi.org/10.1007/3-540-58484-6_288)*）。在1990年代，传统的神经网络训练方法仍处于初期阶段，而这项工作探讨了一种替代方法。论文描述了如何通过在一个名为*Lunar
    Lander*的游戏中模拟航天器，使其学习如何安全降落并着陆。研究人员没有使用手工编写的规则或标注的数据集，而是选择使用遗传算法（GAs）对神经网络进行进化和训练，跨越多代进行演化。结果是成功的！'
- en: In 2002, Kenneth O. Stanley and Risto Miikkulainen expanded on earlier neuroevolutionary
    approaches with their paper “Evolving Neural Networks Through Augmenting Topologies”
    (*[https://doi.org/10.1162/106365602320169811](https://doi.org/10.1162/106365602320169811)*).
    Unlike the lunar lander method that focused on evolving the weights of a neural
    network, Stanley and Miikkulainen introduced a method that also evolved the network’s
    structure itself! Their NEAT algorithm—NeuroEvolution of Augmenting Topologies—starts
    with simple networks and progressively refines their topology through evolution.
    As a result, NEAT can discover network architectures tailored to specific tasks,
    often yielding more optimized and effective solutions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 2002年，Kenneth O. Stanley和Risto Miikkulainen在其论文《Evolving Neural Networks Through
    Augmenting Topologies》中扩展了早期的神经进化方法（* [https://doi.org/10.1162/106365602320169811](https://doi.org/10.1162/106365602320169811)*）。与专注于进化神经网络权重的月球着陆者方法不同，Stanley和Miikkulainen引入了一种方法，也进化了网络本身的结构！他们的NEAT算法——神经进化增强拓扑（NeuroEvolution
    of Augmenting Topologies）——从简单的网络开始，并通过进化逐步完善其拓扑结构。因此，NEAT能够发现针对特定任务量身定制的网络架构，通常能够产生更优化、更有效的解决方案。
- en: A comprehensive NEAT implementation would require going deeper into neural network
    architectures and working directly with TensorFlow.js. My goal instead is to emulate
    Ronald and Schoenauer’s original research in the modern context of the web browser
    with ml5.js. Rather than use the *Lunar Lander* game, I’ll give this a try with
    *Flappy Bird.* And for that, I first need to code a version of *Flappy Bird* where
    my neuroevolutionary network can operate.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个全面的NEAT实现需要深入了解神经网络架构，并直接使用TensorFlow.js进行工作。而我的目标是将Ronald和Schoenauer的原始研究成果，应用于现代的Web浏览器环境，并使用ml5.js来实现。与其使用*Lunar
    Lander*游戏，我决定尝试使用*Flappy Bird*。为此，我首先需要编写一个*Flappy Bird*的版本，以便我的神经进化网络能够在其中运行。
- en: '**Coding Flappy Bird**'
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**编程Flappy Bird**'
- en: '*Flappy Bird* was created by Vietnamese game developer Dong Nguyen in 2013\.
    In January 2014, it became the most downloaded app on the Apple App Store. However,
    on February 8 of that year, Nguyen announced that he was removing the game because
    of its addictive nature. Since then, it has become one of the most cloned games
    in history.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*Flappy Bird*由越南游戏开发者Dong Nguyen于2013年创建。2014年1月，它成为苹果App Store上下载量最多的应用。然而，在同年2月8日，Nguyen宣布他将撤下这款游戏，原因是其成瘾性。自那时以来，*Flappy
    Bird*成为历史上被克隆最多的游戏之一。'
- en: '*Flappy Bird* is a perfect example of Nolan’s law, an aphorism attributed to
    the founder of Atari and creator of *Pong*, Nolan Bushnell: “All the best games
    are easy to learn and difficult to master.” It’s also a terrific game for beginner
    coders to re-create as a learning exercise, and it fits perfectly with the concepts
    in this book.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*Flappy Bird* 是诺兰定律的完美示例，这一格言归功于Atari创始人以及*Pong*的创造者诺兰·布什内尔：“所有最好的游戏都容易学习，却难以精通。”这也是一个非常适合初学者编写的游戏，可以作为学习练习，它与本书中的概念完美契合。'
- en: To program the game with p5.js, I’ll start by defining a `Bird` class. This
    may shock you, but I’m going to skip using `p5.Vector` for this demonstration
    and instead use separate `x` and `y` properties for the bird’s position. Since
    the bird moves only along the vertical axis in the game, `x` remains constant!
    Therefore, the `velocity` (and all the relevant forces) can be a single scalar
    value for just the y-axis.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用p5.js编写游戏，我将从定义一个`Bird`类开始。这可能会让你感到惊讶，但为了演示，我决定跳过使用`p5.Vector`，而是直接使用独立的`x`和`y`属性来表示鸟的位置。由于鸟在游戏中仅沿着垂直轴移动，`x`值保持不变！因此，`velocity`（以及所有相关的力）可以是单一的标量值，只用于y轴。
- en: 'To simplify the code even further, I’ll add the forces directly to the bird’s
    velocity instead of accumulating them into an `acceleration` variable. In addition
    to the usual `update()`, I’ll include a `flap()` method for the bird to fly upward.
    The `show()` method isn’t included here as it only draws a circle. Here’s the
    code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步简化代码，我会将所有的力直接添加到鸟的速度中，而不是将它们累积到`acceleration`变量中。除了常规的`update()`方法，我还会添加一个`flap()`方法，让鸟向上飞。`show()`方法不在这里包含，因为它只是画一个圆形。以下是代码：
- en: '![Image](../images/pg591_Image_880.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/pg591_Image_880.jpg)'
- en: The other primary elements of the game are the pipes that the bird must navigate
    through. I’ll create a `Pipe` class to describe a pair of rectangles, one that
    emanates from the top of the canvas and one from the bottom. Just as the bird
    moves only vertically, the pipes slide along only the horizontal axis, so the
    properties can also be scalar values rather than vectors. The pipes move at a
    constant speed and don’t experience any other forces.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏的其他主要元素是鸟必须穿越的管道。我将创建一个`Pipe`类来描述一对矩形，一个从画布的顶部延伸，另一个从底部延伸。正如鸟仅沿垂直方向移动一样，管道也仅沿水平方向滑动，因此它们的属性可以是标量值而非向量。管道以恒定的速度移动，不受其他力的影响。
- en: '![Image](../images/pg591_Image_881.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/pg591_Image_881.jpg)'
- en: To be clear, the game depicts a bird flying through pipes—the bird is moving
    along two dimensions while the pipes remain stationary. However, it’s simpler
    to code the game as if the bird is stationary in its horizontal position and the
    pipes are moving.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了明确说明，这个游戏展示了一只鸟穿过管道——鸟在二维空间中移动，而管道保持静止。然而，更简单的做法是将鸟看作在水平方向上保持静止，管道在移动。
- en: 'With a `Bird` and `Pipe` class written, I’m almost set to run the game. However,
    a key piece is missing: collisions. The whole game rides on the bird attempting
    to avoid the pipes! Fortunately, this is nothing new. You’ve seen many examples
    of objects checking their positions against others throughout this book. I have
    a design choice to make, though. A method to check collisions could logically
    be placed in either the `Bird` class (to check whether the bird hits a pipe) or
    the `Pipe` class (to check whether a pipe hits the bird). Either can be justified,
    depending on your point of view.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写了`Bird`和`Pipe`类后，我几乎可以开始运行游戏了。然而，缺少一个关键部分：碰撞检测。整个游戏的核心就是让鸟避免撞到管道！幸运的是，这对你来说并不陌生。你在本书中已经看到过许多对象检查其与其他对象的位置的例子。不过，我需要做一个设计选择。碰撞检测方法可以逻辑上放在`Bird`类中（用来检查鸟是否撞到管道），也可以放在`Pipe`类中（用来检查管道是否撞到鸟）。根据你的观点，任意一种方式都能找到合理的理由。
- en: 'I’ll place the method in the `Pipe` class and call it `collides()`. The code
    itself is a little trickier than you might think at first glance, as the method
    needs to check both the top and bottom rectangles of a pipe against the position
    of the bird. I could approach this in a variety of ways. One way is to first check
    whether the bird is vertically within the bounds of either rectangle (either above
    the bottom of the top pipe or below the top of the bottom one). But the bird is
    colliding with the pipe only if the bird is also horizontally within the boundaries
    of the pipe’s width. An elegant way to write this is to combine each of these
    checks with a logical *and*:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我会把这个方法放在`Pipe`类中并命名为`collides()`。这段代码比你初看时可能想的要复杂一些，因为该方法需要检查管道的上下两个矩形与鸟的位置的碰撞。我可以用多种方式来实现这一点。一种方法是先检查鸟是否在任意矩形的垂直范围内（即在上管道底部之上或下管道顶部之下）。但只有当鸟水平位于管道宽度的边界内时，鸟才与管道发生碰撞。一个优雅的写法是将这些检查通过逻辑*与*运算符结合起来：
- en: '![Image](../images/pg592_Image_883.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg592_Image_883.jpg)'
- en: The algorithm currently treats the bird as a single point and doesn’t take into
    account its size. This detail should be improved for a more realistic version
    of the game.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 目前算法将鸟视为一个单一的点，并没有考虑它的大小。为了让游戏更具真实感，应该改进这一细节。
- en: All that’s left is to write `setup()` and `draw()`. I need a single variable
    for the bird and an array for a list of pipes. The interaction is just a single
    click of the mouse, which triggers the bird’s `flap()` method. Rather than build
    a fully functional game with a score, end screen, and other usual elements, I’ll
    just make sure that the game mechanics are working by drawing the text *OOPS!*
    near any pipe when a collision occurs. The code also assumes an additional `offscreen()`
    method on the `Pipe` class for when a pipe has moved beyond the left edge of the
    canvas.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的就是编写`setup()`和`draw()`函数。我需要一个表示鸟的变量和一个存储管道列表的数组。交互方式是点击鼠标一次，触发鸟的`flap()`方法。与其构建一个包含得分、结束屏幕和其他常规元素的完整游戏，不如通过在任何发生碰撞的管道附近绘制文本*OOPS!*来确保游戏机制正常工作。代码还假设`Pipe`类中有一个额外的`offscreen()`方法，用于处理管道移出画布左边缘的情况。
- en: '![Image](../images/pg593_Image_884.jpg)![Image](../images/pg594_Image_885.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg593_Image_884.jpg)![Image](../images/pg594_Image_885.jpg)'
- en: The trickiest aspect of this code lies in spawning the pipes at regular intervals
    with the `frameCount` variable and modulo operator. In p5.js, `frameCount` is
    a system variable that tracks the number of frames rendered since the sketch began,
    incrementing with each cycle of the `draw()` loop. The modulo operator, denoted
    by %, returns the remainder of a division operation. For example, `7 % 3` yields
    `1` because when dividing 7 by 3, the result is 2 with a remainder of 1\. The
    Boolean expression `frameCount % 100 === 0` therefore checks whether the current
    `frameCount` value, when divided by 100, has a remainder of 0\. This condition
    is true every 100 frames, and at those frames, a new pipe is spawned and added
    to the `pipes` array.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码最棘手的部分在于使用`frameCount`变量和取模运算符在固定间隔内生成管道。在p5.js中，`frameCount`是一个系统变量，用于追踪自从草图开始以来已经渲染的帧数，并随着`draw()`循环的每次执行而递增。取模运算符（%）返回除法操作的余数。例如，`7
    % 3`的结果是`1`，因为7除以3的商是2，余数是1。因此，布尔表达式`frameCount % 100 === 0`会检查当前的`frameCount`值是否能被100整除，余数为0。这个条件在每100帧时为真，在这些帧上，会生成一个新的管道并将其添加到`pipes`数组中。
- en: '![Image](../images/pencil.jpg) **Exercise 11.1**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![Image](../images/pencil.jpg) **练习 11.1**'
- en: Implement a scoring system that awards points for successfully navigating through
    each set of pipes. Feel free to also add your own visual design elements for the
    bird, pipes, and environment!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 实现一个得分系统，每成功穿过一组管道就为玩家奖励积分。你也可以为鸟、管道和环境添加你自己的视觉设计元素！
- en: '**Neuroevolutionary Flappy Bird**'
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**神经进化版Flappy Bird**'
- en: My *Flappy Bird* clone, as it currently stands, is controlled by mouse clicks.
    Now I want to cede control of the game to the computer and use neuroevolution
    to teach it how to play. Luckily, the process of neuroevolution is already baked
    into ml5.js, so making this switch will be relatively straightforward. The first
    step is to give the bird a brain so it can decide on its own whether to flap its
    wings.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我的*Flappy Bird*克隆游戏目前是通过鼠标点击来控制的。现在我想把游戏控制权交给计算机，并通过神经进化来教它如何玩。幸运的是，神经进化的过程已经集成在ml5.js中了，因此实现这一切相对简单。第一步是给鸟一个“大脑”，这样它就能自行决定是否拍动翅膀。
- en: '**The Bird Brain**'
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**鸟脑**'
- en: 'When I introduced reinforcement learning, I established a list of input features
    that should make up the bird’s decision-making process. I’m going to use that
    same list but with one simplification. Since the size of the opening between the
    pipes is constant, there’s no need to include the y-positions of both the top
    and bottom; one or the other will suffice. The input features are therefore as
    follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当我引入强化学习时，我建立了一份输入特征列表，应该用于鸟的决策过程。我将使用相同的列表，但做一个简化。由于管道之间的开口大小是恒定的，所以不需要包含顶部和底部的y坐标，任选其一即可。因此，输入特征如下：
- en: The y-position of the bird
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 鸟的y坐标
- en: The y-velocity of the bird
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 鸟的y方向速度
- en: The y-position of the next pipe’s top (or bottom!) opening
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个管道顶部（或底部！）开口的y坐标
- en: The x-distance to the next pipe
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到下一个管道的x距离
- en: 'The two outputs represent the bird’s two options: to flap or not to flap. With
    the inputs and outputs set, I can add a `brain` property to the bird’s constructor
    to hold an ml5.js neural network with the appropriate configuration. Just to demonstrate
    a different coding style here, I’ll skip including a separate `options` variable
    and pass the properties as an object literal directly into the `ml5.neuralNetwork()`
    function. Note the addition of a `neuroEvolution` property set to `true`. This
    is necessary to enable some of the features I’ll be using later in the code.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个输出表示鸟的两个选择：是否拍打翅膀。设置好输入和输出后，我可以在鸟的构造函数中添加一个`brain`属性，用来保存一个配置合适的ml5.js神经网络。为了展示一种不同的编码风格，我将跳过包含一个单独的`options`变量，而是直接将属性作为对象字面量传递给`ml5.neuralNetwork()`函数。请注意，添加了一个`neuroEvolution`属性并设置为`true`。这是启用我将在后续代码中使用的一些功能所必需的。
- en: '![Image](../images/pg595_Image_886.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg595_Image_886.jpg)'
- en: Next, I’ll add a new method called `think()` to the `Bird` class to calculate
    all the necessary inputs for the bird at each moment in time. The first two inputs
    are easy—they’re simply the `y` and `velocity` properties of the bird. However,
    for inputs 3 and 4, I need to determine which pipe is the next pipe.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将向`Bird`类添加一个名为`think()`的方法，用于计算鸟在每一时刻所需的所有输入。前两个输入很简单——它们只是鸟的`y`和`velocity`属性。然而，对于输入3和4，我需要确定下一个管道是哪一个。
- en: 'At first glance, it might seem that the next pipe is always the first one in
    the array, since the pipes are added one at a time to the end of the array. However,
    after a pipe passes the bird, it’s no longer relevant, and there’s still some
    time between when this happens and when that pipe exits the canvas and is removed
    from the beginning of the array. I therefore need to find the first pipe in the
    array whose right edge (x-position plus width) is greater than the bird’s x-position:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，似乎下一个管道总是数组中的第一个，因为管道是逐个添加到数组末尾的。然而，在管道通过鸟之后，它就不再相关了，并且在管道退出画布并从数组开头移除之间还有一段时间。因此，我需要找到数组中第一个右边缘（x坐标加上宽度）大于鸟的x坐标的管道：
- en: '![Image](../images/pg596_Image_888.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg596_Image_888.jpg)'
- en: 'Once I have the next pipe, I can create the four inputs:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我找到了下一个管道，就可以创建四个输入：
- en: '![Image](../images/pg596_Image_889.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg596_Image_889.jpg)'
- en: 'This is close, but I’ve forgotten a critical step. The range of all input values
    is determined by the dimensions of the canvas, but a neural network expects values
    in a standardized range, such as 0 to 1\. One method to normalize these values
    is to divide the inputs related to vertical properties by `height`, and those
    related to horizontal ones by `width`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经很接近了，但我忘记了一个关键步骤。所有输入值的范围是由画布的尺寸决定的，但神经网络期望的是标准化范围内的值，比如0到1。标准化这些值的一种方法是，将与垂直属性相关的输入除以`height`，而与水平方向相关的输入除以`width`：
- en: '![Image](../images/pg596_Image_890.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg596_Image_890.jpg)'
- en: 'With the inputs in hand, I’m ready to pass them to the neural network’s `classify()`
    method. I have another small problem, however: `classify()` is asynchronous, meaning
    I’d have to implement a callback inside the `Bird` class to process the model’s
    decision. This would add a significant level of complexity to the code, but luckily,
    it’s entirely unnecessary in this case. Asynchronous callbacks with ml5.js’s machine
    learning functions are typically needed because of the time required to process
    the large amount of data in the model. Without a callback, the code might have
    to wait a long time to get a result, and if the model is running as part of a
    p5.js sketch, that delay could severely impact the smoothness of the animation.
    The neural network here, however, has only four floating-point inputs and two
    output labels! It’s tiny and can run fast enough that there’s no reason to use
    asynchronous code.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 拿到输入数据后，我准备将它们传递给神经网络的`classify()`方法。不过，我还有一个小问题：`classify()`是异步的，这意味着我必须在`Bird`类中实现一个回调函数来处理模型的决策。这会给代码增加显著的复杂性，但幸运的是，在这种情况下完全不需要这样做。ml5.js的机器学习函数通常需要异步回调，因为模型处理大量数据需要时间。如果没有回调，代码可能会长时间等待结果，而如果模型在p5.js草图中运行，这种延迟可能会严重影响动画的流畅性。然而，这里的神经网络只有四个浮动输入和两个输出标签！它非常小，能够快速运行，因此没有必要使用异步代码。
- en: 'For completeness, I include a version of the example on the book’s website
    that implements neuroevolution with asynchronous callbacks. For this discussion,
    however, I’m going to use a feature of ml5.js that allows me to take a shortcut.
    The method `classifySync()` is identical to `classify()`, but it runs synchronously,
    meaning the code stops and waits for the results before moving on. You should
    be very careful when using this version of the method as it can cause problems
    in other contexts, but it will work well for this simple scenario. Here’s the
    end of the `think()` method with `classifySync()`:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，我在书本网站上包括了一个实现神经进化与异步回调的示例版本。然而，在本讨论中，我将使用ml5.js的一个特性，它让我能够走捷径。方法`classifySync()`与`classify()`完全相同，但它是同步运行的，这意味着代码会停下来等待结果，再继续执行。使用这个版本的方法时要非常小心，因为它可能在其他上下文中引发问题，但在这个简单的场景下，它能很好地工作。下面是`think()`方法的结尾部分，使用了`classifySync()`：
- en: '![Image](../images/pg597_Image_891.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/pg597_Image_891.jpg)'
- en: The neural network’s prediction is in the same format as the gesture classifier
    from [Chapter 10](ch10.xhtml#ch10), and the decision can be made by checking the
    first element of the `results` array. If the output label is `"flap"`, then call
    `flap()`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的预测格式与[第10章](ch10.xhtml#ch10)中的手势分类器相同，可以通过检查`results`数组的第一个元素来做出决策。如果输出标签是`"flap"`，则调用`flap()`。
- en: 'Now that I’ve finished the `think()` method, the real challenge can begin:
    teaching the bird to win the game by consistently flapping its wings at the right
    moment. This is where the GA comes back into the picture. Recalling the discussion
    from [Chapter 9](ch09.xhtml#ch09), three key principles underpin Darwinian evolution:
    variation, selection, and heredity. I’ll revisit each of these principles in turn
    as I implement the steps of the GA in this new context of neural networks.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经完成了`think()`方法，真正的挑战可以开始了：教会鸟在正确的时刻通过扑翅膀来赢得游戏。此时，遗传算法（GA）再次成为关键。回想一下[第9章](ch09.xhtml#ch09)的讨论，达尔文进化论的三个关键原则是：变异、选择和遗传。在我将GA的步骤应用于神经网络的全新背景时，我将依次回顾这些原则。
- en: '**Variation: A Flock of Flappy Birds**'
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**变异：一群扑腾的小鸟**'
- en: 'A single bird with a randomly initialized neural network isn’t likely to have
    any success at all. That lone bird will most likely jump incessantly and fly way
    off-screen, or sit perched at the bottom of the canvas awaiting collision after
    collision with the pipes. This erratic and nonsensical behavior is a reminder:
    a randomly initialized neural network lacks any knowledge or experience. The bird
    is essentially making wild guesses for its actions, so success is going to be
    rare.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一只随机初始化的神经网络鸟不太可能有任何成功。这只孤鸟很可能会不停地跳跃，飞出屏幕，或者坐在画布底部，等待与管道的每一次碰撞。这种反常且不合逻辑的行为提醒我们：一个随机初始化的神经网络没有任何知识或经验。鸟的行为本质上是在做胡乱的猜测，所以成功是非常罕见的。
- en: 'This is where the first key principle of GAs comes in: **variation**. The hope
    is that by introducing as many different neural network configurations as possible,
    a few might perform slightly better than the rest. The first step toward variation
    is to add an array of many birds ([Figure 11.4](ch11.xhtml#ch11fig4)).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是遗传算法（GA）中的第一个关键原则：**变异**。我们的期望是，通过引入尽可能多的不同神经网络配置，可能会有一些表现稍微优于其他的。变异的第一步是增加一个包含许多小鸟的数组（[图
    11.4](ch11.xhtml#ch11fig4)）。
- en: '![Image](../images/pg598_Image_892.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg598_Image_892.jpg)'
- en: 'Figure 11.4: A population of birds, each with unique neural networks, navigating
    through the pipes in the neuroevolution process'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4：一群小鸟，每只小鸟都有独特的神经网络，在神经进化过程中穿越管道
- en: '![Image](../images/pg598_Image_893.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg598_Image_893.jpg)'
- en: 'You might notice a peculiar line of code that’s crept into the `setup()` function:
    `ml5.setBackend("cpu")`. When running neural networks, a lot of the heavy computational
    lifting is often offloaded to the GPU. This is the default behavior, and it’s
    especially critical for the larger pretrained models included with ml5.js.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到一个出现在 `setup()` 函数中的特殊代码行：`ml5.setBackend("cpu")`。在运行神经网络时，很多繁重的计算任务通常会被卸载到
    GPU 上。这是默认行为，对于 ml5.js 中包含的大型预训练模型尤其重要。
- en: '![Image](../images/zoom.jpg) **GPU vs. CPU**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![Image](../images/zoom.jpg) **GPU 与 CPU**'
- en: '**Graphics processing unit (GPU):** Originally designed for rendering graphics,
    GPUs are adept at handling a massive number of operations in parallel. This makes
    them excellent for the kinds of math operations and computations that machine
    learning models frequently perform.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图形处理单元（GPU）：** 最初设计用于渲染图形，GPU 擅长处理大量的并行运算。这使得它们在处理机器学习模型频繁执行的数学运算和计算时表现出色。'
- en: '**Central processing unit (CPU):** Often considered the brain or general-purpose
    heart of a computer, a CPU handles a wider variety of tasks than the specialized
    GPU, but it isn’t built to do as many tasks simultaneously.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中央处理单元（CPU）：** 通常被认为是计算机的大脑或通用心脏，CPU 处理的任务种类比专门的 GPU 更广泛，但它并不是为同时执行大量任务而设计的。'
- en: But there’s a catch! Transferring data to and from the GPU introduces overhead.
    In most cases, the gains from the GPU’s parallel processing more than offset this
    overhead, but for a tiny model like the one here, copying data to the GPU and
    back actually slows the neural network. Calling `ml5.setBackend("cpu")` tells
    ml5.js to run the neural network computations on the CPU instead. At least in
    this simple case of tiny bird brains, this is the more efficient choice.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 但有一个陷阱！将数据传输到 GPU 并从 GPU 传回会引入开销。在大多数情况下，GPU 的并行处理所带来的收益足以抵消这些开销，但对于像这里这样的小型模型，数据复制到
    GPU 并返回实际上会减慢神经网络的速度。调用`ml5.setBackend("cpu")`告诉 ml5.js 将神经网络计算转移到 CPU 上运行。至少在这个简单的小鸟模型的案例中，这是更高效的选择。
- en: '**Selection: Flappy Bird Fitness**'
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**选择：Flappy Bird 适应度**'
- en: Once I have a diverse population of birds, each with its own neural network,
    the next step in the GA is **selection**. Which birds should pass on their genes
    (in this case, neural network weights) to the next generation? In the world of
    *Flappy Bird*, the measure of success is the ability to stay alive the longest
    by avoiding the pipes. This is the bird’s *fitness*. A bird that dodges many pipes
    is considered more fit than one that crashes into the first pipe it encounters.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我有了一个多样化的小鸟种群，每只小鸟都有自己的神经网络，遗传算法的下一步是 **选择**。哪些小鸟应该将它们的基因（在这里是神经网络权重）传递给下一代？在
    *Flappy Bird* 的世界里，成功的标准是能够通过避开管道生存得更久。这就是小鸟的 *适应度*。能够避开更多管道的小鸟被认为比撞到第一个管道就挂掉的小鸟更具适应性。
- en: 'To track each bird’s fitness, I’ll add two properties to the `Bird` class,
    `fitness` and `alive`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟踪每只小鸟的适应度，我将在 `Bird` 类中添加两个属性，`fitness` 和 `alive`：
- en: '![Image](../images/pg599_Image_894.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg599_Image_894.jpg)'
- en: I’ll assign the fitness a numeric value that increases by one every cycle through
    `draw()`, as long as the bird remains alive. The birds that survive longer should
    have a higher fitness value. This mechanism mirrors the reinforcement learning
    technique of rewarding good decisions. In reinforcement learning, however, an
    agent receives immediate feedback for every decision it makes, allowing it to
    adjust its policy accordingly. Here, the bird’s fitness is a cumulative measure
    of its overall success and will be applied only during the selection step of the
    GA.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我将为适应度分配一个数值，这个数值在每次通过`draw()`时都会增加，前提是鸟还活着。存活时间更长的鸟应该有更高的适应度值。这种机制类似于强化学习中的奖励良好决策的技巧。然而，在强化学习中，智能体对每个决策都会收到即时反馈，从而能够相应地调整其策略。在这里，鸟的适应度是其整体成功的累计衡量标准，只会在遗传算法的选择步骤中使用。
- en: '![Image](../images/pg600_Image_895.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg600_Image_895.jpg)'
- en: The `alive` property is a Boolean flag that’s initially set to `true`. When
    a bird collides with a pipe, this property is set to `false`. Only birds that
    are still alive are updated and drawn to the canvas.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`alive`属性是一个布尔标志，初始值为`true`。当一只鸟与管道碰撞时，该属性会被设置为`false`。只有那些还活着的鸟会被更新并绘制到画布上。'
- en: '![Image](../images/pg600_Image_896.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg600_Image_896.jpg)'
- en: In [Chapter 9](ch09.xhtml#ch09), I demonstrated two techniques for running an
    evolutionary simulation. In the smart rockets example, the population lived for
    a fixed amount of time each generation. The same approach could likely work here
    as well, but I want to allow the birds to accumulate the highest fitness value
    possible and not arbitrarily stop them based on a time limit. The second technique,
    demonstrated with the bloops example, eliminated the fitness score entirely and
    set a random probability for cloning any living creature. For *Flappy Bird*, this
    approach could become messy and risks overpopulation or all the birds dying out
    completely.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第九章](ch09.xhtml#ch09)中，我演示了两种运行进化仿真技术。在智能火箭示例中，种群在每一代中都生活了固定的时间。相同的方法可能在这里也能奏效，但我希望让鸟类积累尽可能高的适应度值，而不是根据时间限制随意停止它们。第二种技术，在bloops示例中演示，完全取消了适应度分数，并为任何存活生物设定了一个随机克隆概率。对于*Flappy
    Bird*，这种方法可能会变得混乱，并有导致过度繁殖或所有鸟类完全死亡的风险。
- en: 'I propose combining elements of both approaches. I’ll allow a generation to
    continue as long as at least one bird is still alive. When all the birds have
    died, I’ll select parents for the reproduction step and start anew. I’ll begin
    by writing a function to check whether all the birds have died:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我提议结合这两种方法的元素。我将允许一个世代继续，直到至少有一只鸟还活着。当所有鸟都死掉时，我将选择父母进行再生产步骤，并重新开始。我将先写一个函数来检查是否所有的鸟都已经死亡：
- en: '![Image](../images/pg600_Image_897.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg600_Image_897.jpg)'
- en: 'When all the birds have died, it’s time for selection! In the previous GA examples,
    I demonstrated a relay-race technique for giving a fair shot to all members of
    a population, while still increasing the chances of selection for those with higher
    fitness scores. I’ll use that same `weightedSelection()` function here:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有鸟都死亡时，就到了选择的时候！在之前的遗传算法示例中，我演示了一种接力赛技术，旨在给种群中的所有成员一个公平的机会，同时仍然增加那些适应度较高的个体被选择的机会。我将在这里使用相同的`weightedSelection()`函数：
- en: '![Image](../images/pg601_Image_899.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg601_Image_899.jpg)'
- en: 'For this algorithm to function properly, I need to first normalize the fitness
    values of the birds so that they collectively add up to 1:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个算法正常运行，我需要首先规范化鸟的适应度值，使它们的总和为1：
- en: '![Image](../images/pg601_Image_900.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg601_Image_900.jpg)'
- en: Once normalized, each bird’s fitness is equal to its probability of being selected.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦标准化，每只鸟的适应度就等于它被选择的概率。
- en: '**Heredity: Baby Birds**'
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**遗传学：小鸟宝宝**'
- en: 'Only one step is left in the GA—reproduction. In [Chapter 9](ch09.xhtml#ch09),
    I explored in great detail the two-step process for generating a child element:
    crossover and mutation. Crossover is where the third key principle of **heredity**
    arrives: the DNA from the two selected parents is combined to form the child’s
    DNA.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的唯一一步是遗传算法中的再生产。在[第九章](ch09.xhtml#ch09)中，我详细探讨了生成子元素的两步过程：交叉和变异。交叉是**遗传学**中的第三个关键原理：来自两个选择父代的DNA结合形成子代的DNA。
- en: 'At first glance, the idea of inventing a crossover algorithm for two neural
    networks might seem daunting, and yet it’s quite straightforward. Think of the
    individual “genes” of a bird’s brain as the weights within the neural network.
    Mixing two such brains boils down to creating a new neural network with each weight
    chosen by a virtual coin flip—the weight comes from either the first or the second
    parent:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始，发明一个用于两个神经网络的交叉算法可能看起来令人生畏，但实际上非常简单。可以把鸟类大脑的每个“基因”看作是神经网络中的权重。混合两个大脑的过程归结为创建一个新的神经网络，每个权重通过虚拟硬币投掷来选择——权重来自第一个或第二个父代：
- en: '![Image](../images/pg602_Image_901.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg602_Image_901.jpg)'
- en: 'Wow, today’s my lucky day! It turns out ml5.js includes a `crossover()` method
    that manages the algorithm for mixing the two neural networks. I can happily move
    on to the mutation step:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，今天真是我的幸运日！原来ml5.js包括一个`crossover()`方法，它管理着混合两个神经网络的算法。我可以高兴地进入变异步骤了：
- en: '![Image](../images/pg602_Image_902.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg602_Image_902.jpg)'
- en: My luck continues! The ml5.js library also provides a `mutate()` method that
    accepts a mutation rate as its primary argument. The rate determines how often
    a weight will be altered. For example, a rate of 0.01 indicates a 1 percent chance
    that any given weight will mutate. During mutation, ml5.js adjusts the weight
    slightly by adding a small random number to it, rather than selecting a completely
    new random value. This behavior mimics real-world genetic mutations, which typically
    introduce minor changes rather than entirely new traits. Although this default
    approach works for many cases, ml5.js offers more control over the process by
    allowing the use of a custom mutation function as an optional second argument
    to `mutate()`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我的运气真不错！ml5.js库还提供了一个`mutate()`方法，它接受一个变异率作为主要参数。这个变异率决定了权重会被改变的频率。例如，0.01的比率表示任何给定的权重有1%的概率会发生变异。在变异过程中，ml5.js会通过在权重上加一个小的随机数来稍微调整权重，而不是选择一个完全新的随机值。这种行为模拟了现实世界中的基因变异，通常是引入轻微的变化，而不是完全新的特征。尽管默认方法适用于许多情况，但ml5.js通过允许使用自定义变异函数作为`mutate()`的可选第二个参数，提供了对过程的更多控制。
- en: 'The crossover and mutation steps need to be repeated for the size of the population
    to create an entirely new generation of birds. This is accomplished by populating
    an empty local array `nextBirds` with the new birds. Once the population is full,
    the global `birds` array is then updated to this fresh generation:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉和变异步骤需要为种群的大小重复进行，以创建一个全新的鸟类世代。这是通过将一个空的本地数组`nextBirds`填充为新鸟类来实现的。一旦种群满员，全球的`birds`数组就会更新为这个新的世代：
- en: '![Image](../images/pg602_Image_903.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg602_Image_903.jpg)'
- en: 'If you look closely at the `reproduction()` function, you may notice that I’ve
    slipped in another new feature of the `Bird` class: an argument to the constructor.
    When I first introduced the idea of a bird brain, each new `Bird` object was created
    with a brand-new brain—a fresh neural network courtesy of ml5.js. However, I now
    want the new birds to *inherit* a child brain that was generated through the processes
    of crossover and mutation. To make this possible, I’ll subtly change the `Bird`
    constructor to look for an optional argument named, of course, `brain`:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察`reproduction()`函数，可能会注意到我悄悄加入了`Bird`类的另一个新特性：构造函数的一个参数。当我最初介绍鸟类大脑的概念时，每个新的`Bird`对象都会创建一个全新的大脑——一个由ml5.js提供的新神经网络。然而，现在我希望新的鸟类能够*继承*一个通过交叉和变异过程生成的子代大脑。为了实现这一点，我会巧妙地修改`Bird`构造函数，来查找一个名为`brain`的可选参数：
- en: '![Image](../images/pg603_Image_905.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg603_Image_905.jpg)'
- en: If no `brain` is provided when a new bird is created, the `brain` argument remains
    `undefined`. In JavaScript, `undefined` is treated as `false`. The `if (brain)`
    test will therefore fail, so the code will move on to the `else` statement and
    call `ml5.neuralNetwork()`. On the other hand, if an existing neural network is
    passed in, `brain` evaluates to `true` and is assigned directly to `this.brain`.
    This elegant trick allows a single constructor to handle multiple scenarios.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在创建新鸟时没有提供`brain`，那么`brain`参数将保持`undefined`。在JavaScript中，`undefined`被视为`false`。因此，`if
    (brain)`测试会失败，代码将跳转到`else`语句并调用`ml5.neuralNetwork()`。另一方面，如果传入了一个现有的神经网络，`brain`的值将为`true`，并直接赋值给`this.brain`。这个巧妙的技巧让一个构造函数能够处理多种场景。
- en: With that, the example is complete. All that’s left to do is call `normalizeFitness()`
    and `reproduction()` in `draw()` at the end of each generation, when all the birds
    have died out.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，示例已经完成。剩下的就是在每一代的末尾，当所有鸟都死亡时，在`draw()`中调用`normalizeFitness()`和`reproduction()`。
- en: '![Image](../images/pg604_Image_906.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg604_Image_906.jpg)'
- en: Note the addition of a new `resetPipes()` function. If I don’t remove the pipes
    before starting a new generation, the birds may immediately restart at a position
    colliding with a pipe, in which case even the best bird won’t have a chance to
    fly! The full online code for [Example 11.2](ch11.xhtml#ch11ex2) also adjusts
    the behavior of the birds so that they die when they leave the canvas, either
    by crashing into the ground or soaring too high above the top.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 注意新增了一个`resetPipes()`函数。如果在开始新一代之前不移除管道，鸟可能会立即从与管道相撞的位置重新开始，在这种情况下，即使是最好的鸟也没有机会飞行！[示例
    11.2](ch11.xhtml#ch11ex2)的完整在线代码还调整了鸟的行为，使得它们在离开画布时死亡，无论是撞到地面还是飞得太高超出顶部。
- en: '![Image](../images/pencil.jpg) **Exercise 11.2**'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![Image](../images/pencil.jpg) **习题 11.2**'
- en: It takes a very long time for [Example 11.2](ch11.xhtml#ch11ex2) to produce
    any results. Could you “speed up time” by skipping the drawing of every single
    frame of the game to reach an optimal bird faster? (A solution is presented in
    “Speeding Up Time” on [page 570](ch11.xhtml#ch00lev2sec113).) Additionally, could
    you add an overlay that displays information about the simulation’s status, such
    as the number of birds still in play, the current generation, and the life span
    of the best bird?
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 11.2](ch11.xhtml#ch11ex2)需要很长时间才能产生任何结果。你能否通过跳过游戏的每一帧绘制来“加速时间”，以更快地达到最优鸟？（解决方案在[第570页](ch11.xhtml#ch00lev2sec113)的“加速时间”中提供。）此外，你能否添加一个叠加层，显示有关模拟状态的信息，例如仍在游戏中的鸟的数量、当前代数和最优鸟的寿命？'
- en: '![Image](../images/pencil.jpg) **Exercise 11.3**'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![Image](../images/pencil.jpg) **习题 11.3**'
- en: To avoid starting the neuroevolution process from scratch every time, try using
    ml5.js’s neural network `save()` and `load()` methods. How might you add a feature
    that saves the best bird model as well as an option to load a previously saved
    model?
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免每次都从头开始神经进化过程，可以尝试使用ml5.js的神经网络`save()`和`load()`方法。你如何添加一个功能来保存最好的鸟模型，并提供加载先前保存模型的选项？
- en: '**Steering the Neuroevolutionary Way**'
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**神经进化引导方式**'
- en: Having explored neuroevolution with *Flappy Bird*, I’d like to shift the focus
    back to the realm of simulation, specifically the steering agents introduced in
    [Chapter 5](ch05.xhtml#ch05). What if, instead of me dictating the rules for an
    algorithm to calculate a steering force, a simulated creature could evolve its
    own strategy? Drawing inspiration from Reynolds’s aim of lifelike and improvisational
    behaviors, my goal isn’t to use neuroevolution to engineer the perfect creature
    that can flawlessly execute a task. Instead, I hope to create a captivating world
    of simulated life, where the quirks, nuances, and happy accidents of evolution
    unfold in the canvas.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索了*Flappy Bird*的神经进化后，我希望将焦点转回到模拟领域，特别是[第5章](ch05.xhtml#ch05)中介绍的引导代理。假设不是我来规定一个算法的规则来计算引导力，而是一个模拟生物能够进化出自己的策略呢？从Reynolds对栩栩如生和即兴行为的目标中汲取灵感，我的目标不是通过神经进化来创造一个完美的生物，它能完美地执行任务。相反，我希望创建一个迷人的模拟生命世界，在那里，进化的怪癖、细微差别和幸运的意外在画布上展开。
- en: 'I’ll begin by adapting the smart rockets example from [Chapter 9](ch09.xhtml#ch09).
    In that example, the genes for each rocket were an array of vectors:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从[第9章](ch09.xhtml#ch09)中适应智能火箭的示例开始。在该示例中，每个火箭的基因是一个向量数组：
- en: '![Image](../images/pg605_Image_907.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg605_Image_907.jpg)'
- en: 'I propose adapting this code to instead use a neural network to predict the
    vector or steering force, transforming the `genes` into a `brain`. Vectors can
    have a continuous range of values, so this is a regression task:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我提议调整这段代码，改为使用神经网络来预测向量或引导力，将`genes`转化为`brain`。向量可以具有连续的值范围，因此这是一个回归任务：
- en: '[PRE1]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the original example, the vectors from the `genes` array were applied sequentially,
    querying the array with a `counter` variable:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始示例中，来自`genes`数组的向量是顺序应用的，通过`counter`变量查询数组：
- en: '[PRE2]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, instead of an array lookup, I want the neural network to return a new
    vector for each frame of the animation. For regression tasks with ml5.js, the
    output of the neural network is received from the `predict()` method rather than
    `classify()`. And here, I’ll use the `predictSync()` variant to keep the code
    simple and allow for synchronous output data from the model in the rocket’s `run()`
    method:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，代替数组查找，我希望神经网络在每一帧动画中返回一个新的向量。对于 ml5.js 的回归任务，神经网络的输出是通过 `predict()` 方法接收的，而不是
    `classify()`。在这里，我将使用 `predictSync()` 变体来简化代码，并允许模型在火箭的 `run()` 方法中同步输出数据：
- en: '![Image](../images/pg606_Image_908.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg606_Image_908.jpg)'
- en: 'The neural network brain outputs two values: one for the angle of the vector
    and one for the magnitude. You might think to instead use these outputs for the
    vector’s x- and y-components. The default output range for an ml5.js neural network
    is from 0 to 1, however, and I want the forces to be capable of pointing in both
    positive and negative directions. Mapping the first output to an angle by multiplying
    it by `TWO_PI` offers the full range.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络大脑输出两个值：一个是向量的角度，另一个是向量的大小。你可能会想到使用这些输出作为向量的 x 分量和 y 分量。然而，ml5.js 神经网络的默认输出范围是从
    0 到 1，而我希望这些力能够指向正负两个方向。通过将第一个输出值乘以 `TWO_PI` 来映射角度，就可以实现完整的范围。
- en: You may have noticed that the code includes a variable called `inputs` that
    I have yet to declare or initialize. Defining the inputs to the neural network
    is where you, as the designer of the system, can be the most creative. You have
    to consider the nature of the environment and the simulated biology and capabilities
    of your creatures, and then decide which features are most important.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到代码中有一个名为 `inputs` 的变量，我还没有声明或初始化它。定义神经网络的输入是作为系统设计者的你可以发挥最大创造力的地方。你需要考虑环境的特性，以及你的生物体模拟的生物学和能力，然后决定哪些特征最为重要。
- en: 'As a first try, I’ll assign something basic for the inputs and see if it works.
    Since the smart rockets’ environment is static, with fixed obstacles and targets,
    what if the brain could learn and estimate a flow field to navigate toward its
    goal? As I demonstrated in [Chapter 5](ch05.xhtml#ch05), a flow field receives
    a position and returns a vector, so the neural network can mirror this functionality
    and use the rocket’s current x- and y-position as input. I just have to normalize
    the values according to the canvas dimensions:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一次尝试，我将为输入分配一些基本的值，看看是否能工作。由于智能火箭的环境是静态的，障碍物和目标是固定的，那么如果大脑能够学习并估算一个流场来导航到达目标会怎么样？正如我在[第
    5 章](ch05.xhtml#ch05)中演示的，流场接收一个位置并返回一个向量，因此神经网络可以模仿这一功能，使用火箭当前的 x 和 y 位置作为输入。我只需要根据画布的尺寸标准化这些值：
- en: '[PRE3]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'That’s it! Virtually everything else from the original example can remain unchanged:
    the population, the fitness function, and the selection process.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！几乎所有原始示例中的其他内容都可以保持不变：种群、适应度函数和选择过程。
- en: '![Image](../images/pg607_Image_909.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg607_Image_909.jpg)'
- en: Now that I’m using ml5.js, notice that I no longer need a separate `DNA` class
    with implementations of `crossover()` and `mutate()`. Instead, those methods are
    built into `ml5.neuralNetwork` and can be called directly.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我正在使用 ml5.js，注意到我不再需要一个单独的 `DNA` 类来实现 `crossover()` 和 `mutate()` 方法了。相反，这些方法已经内置在
    `ml5.neuralNetwork` 中，可以直接调用。
- en: '![Image](../images/pencil.jpg) **Exercise 11.4**'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![Image](../images/pencil.jpg) **练习 11.4**'
- en: A steering force, as defined by Reynolds, is the difference between an agent’s
    desired velocity and its current velocity. How might this evolutionary system
    mirror that methodology? Instead of using only the position as an input to the
    neural network, what if you feed in the rocket’s current velocity? You could try
    using the x- and y-components or the direction and magnitude of the vector. Remember
    to normalize these values!
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Reynolds 的定义，转向力是一个代理期望速度与其当前速度之间的差异。那么这个进化系统如何模仿这种方法呢？如果你不只使用位置作为神经网络的输入，而是输入火箭的当前速度会怎样？你可以尝试使用
    x 和 y 分量，或者向量的方向和大小。记得标准化这些值！
- en: '**Responding to Change**'
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**应对变化**'
- en: In the previous example, the environment was static, with a stationary target
    and obstacle. This made the rocket’s task of finding the target easy to accomplish
    using only its position as input. However, what if the target and the obstacles
    in the rocket’s path were moving? To handle a more complex and changing environment,
    I need to expand the neural network’s inputs and consider additional features
    of the environment. This is similar to what I did with *Flappy Bird*, as I identified
    the key data points of the environment to guide the bird’s decision-making process.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的示例中，环境是静态的，目标和障碍物都固定不动。这使得火箭仅通过位置作为输入就能轻松完成寻找目标的任务。然而，如果目标和火箭路径中的障碍物在移动呢？为了应对更复杂和变化的环境，我需要扩展神经网络的输入，考虑更多的环境特征。这类似于我在*Flappy
    Bird*中所做的，我识别了环境中的关键数据点来指导小鸟的决策过程。
- en: 'I’ll begin with the simplest version of this scenario, almost identical to
    the original smart rockets example, but removing obstacles and replacing the fixed
    target with a random walker controlled by Perlin noise. In this world, I’ll rename
    the `Rocket` to `Creature` and recast the walker as a `Glow` class that represents
    a gentle, drifting orb. Imagine that the creature’s goal is to reach the light
    source and dance in its radiant embrace as long as it can:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从这个场景的最简单版本开始，几乎与原始的智能火箭示例相同，但移除了障碍物，并将固定目标替换为由Perlin噪声控制的随机行走者。在这个世界里，我将`Rocket`重命名为`Creature`，并将行走者改为一个表示温和漂浮光球的`Glow`类。想象一下，这个生物的目标是到达光源，并在它的光辉怀抱中尽可能长时间地舞动：
- en: '![Image](../images/pg608_Image_910.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg608_Image_910.jpg)'
- en: 'As the glow moves, the creature should take the glow’s position into account
    in its decision-making process, as an input to its brain. However, it isn’t sufficient
    to know only the light’s position; it’s the position relative to the creature’s
    own that’s key. A nice way to synthesize this information as an input feature
    is to calculate a vector that points from the creature to the glow. Essentially,
    I’m reinventing the `seek()` method from [Chapter 5](ch05.xhtml#ch05), using a
    neural network to estimate the steering force:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 随着光源的移动，生物应该将光源的位置纳入其决策过程，作为输入到其大脑。然而，仅仅知道光源的位置是不够的；关键在于光源相对于生物自身的位置。一种很好的方式来综合这些信息作为输入特征，是计算一个从生物指向光源的向量。本质上，我在重新发明[第5章](ch05.xhtml#ch05)中的`seek()`方法，使用神经网络来估算转向力：
- en: '![Image](../images/pg608_Image_911.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg608_Image_911.jpg)'
- en: 'This is a good start, but the components of the vector don’t fall within a
    normalized input range. I could divide `v.x` by `width` and `v.y` by `height`,
    but since my canvas isn’t a perfect square, this may skew the data. Another solution
    is to normalize the vector, but while this would retain information about the
    direction from the creature to the glow, it would eliminate any measure of the
    distance. This won’t do either—if the creature is sitting on top of the glow,
    it should steer differently than if it were very far away. As a solution, I’ll
    save the distance in a separate variable before normalizing the vector. For it
    to work as an input feature, though, I still have to normalize the range. While
    not a perfect normalization from 0 to 1, I’ll divide it by the canvas width, which
    will provide a practical normalization that retains the relative magnitude:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个好的开始，但向量的分量没有落在标准化的输入范围内。我可以将`v.x`除以`width`，将`v.y`除以`height`，但由于我的画布不是完美的正方形，这可能会导致数据偏斜。另一种解决方案是标准化向量，但虽然这样可以保留从生物到光源的方向信息，但会消除任何关于距离的度量。这也不行——如果生物正坐在光源上方，它应该与远离光源时的行为不同。为了解决这个问题，我会在标准化向量之前将距离保存在一个单独的变量中。不过，为了让它作为输入特征有效，我仍然需要标准化范围。虽然这不是从0到1的完美标准化，但我将通过画布的宽度来进行除法，这样可以提供一种实用的标准化方式，保持相对的大小：
- en: '![Image](../images/pg609_Image_912.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg609_Image_912.jpg)'
- en: 'As you may recall, a key element of Reynolds’s steering formula involved comparing
    the desired velocity to the current velocity. How the vehicle is currently moving
    plays a significant role in how it should steer! For the creature to consider
    its own velocity as part of its decision-making, I can include the velocity vector
    in the inputs to the neural network as well. To normalize these values, dividing
    the vector’s components by the `maxspeed` property works beautifully. This retains
    both the direction and relative magnitude of the vector. The rest of the `seek()`
    method follows the same logic as the previous example, with the outputs of the
    neural network synthesized into a force to be applied to the creature:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能记得的，Reynolds 的引导公式的一个关键元素是将期望速度与当前速度进行比较。车辆当前的运动状态在决定如何转向时起着重要作用！为了让生物将自己的速度作为决策的一部分，我还可以将速度向量作为神经网络的输入之一。为了规范化这些值，将向量的分量除以
    `maxspeed` 属性效果非常好。这样既保留了向量的方向，也保留了相对大小。其余的 `seek()` 方法与之前的示例遵循相同的逻辑，神经网络的输出合成一个力，施加到生物身上：
- en: '![Image](../images/pg609_Image_913.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/pg609_Image_913.jpg)'
- en: 'Enough has changed in the transition from rockets to creatures that it’s also
    worth reconsidering the fitness function. Previously, fitness was calculated based
    on the rocket’s *record* distance from the target at the end of each generation.
    Since the target is now moving, I’d prefer to accumulate the amount of time the
    creature is able to catch the glow as the measure of fitness. This can be achieved
    by checking the distance between the creature and the glow in the `update()` method
    and incrementing a `fitness` value when they’re intersecting:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 从火箭到生物的过渡中，已经发生了足够的变化，因此值得重新考虑适应度函数。以前，适应度是基于火箭每代结束时距离目标的*记录*距离来计算的。由于目标现在在移动，我更愿意将生物能够捕捉到光点的时间量作为适应度的衡量标准。这可以通过在
    `update()` 方法中检查生物与光点之间的距离，并在它们相交时增加 `fitness` 值来实现：
- en: '![Image](../images/pg610_Image_915.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/pg610_Image_915.jpg)'
- en: Both the `Glow` and `Creature` classes include a radius property `r`, which
    I’m using to determine intersection.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`Glow` 和 `Creature` 类都包括一个半径属性 `r`，我用它来判断是否发生相交。'
- en: '**Speeding Up Time**'
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**加速时间**'
- en: One thing you may have noticed about evolutionary computing is that testing
    the code is a delightful exercise in patience. You have to watch the slow crawl
    of the simulation play out generation after generation. This is part of the point—I
    *want* to watch the process! It’s also a nice excuse to take a break, which is
    to be encouraged. Head outside and enjoy some nonsimulated nature for a while,
    or perhaps a soothing cup of tea. Then check back in on your creatures and see
    how they’re progressing. Take comfort in having to wait only billions of milliseconds
    rather than the billions of years required for actual biological evolution.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到进化计算的一个特点，那就是测试代码是一项需要耐心的愉快练习。你必须看到仿真一代又一代地缓慢运行。这也是其中的一部分——我*想*看到这个过程！这也是一个很好的借口去休息一下，值得提倡。去外面走一走，享受一段不经过模拟的大自然，或者泡一杯舒缓的茶。然后再回到你的生物，看看它们的进展。安慰自己的是，你所需要等待的只是数十亿毫秒，而不是实际生物进化所需的数十亿年。
- en: Nevertheless, for the system to evolve, there’s no inherent requirement that
    you draw and animate the world. Hundreds of generations could be completed in
    the blink of an eye if you could skip all the time spent rendering the scene.
    Or, rather than not render the environment at all, you could choose to simply
    render it *less often*. This will save you from tearing your hair out every time
    you change a small parameter and find yourself waiting what seems like hours to
    see whether it had any effect on the system’s evolution.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了使系统发展，没有固有的要求需要你绘制和动画化整个世界。如果你能够跳过渲染场景的所有时间，几百代可能会在眨眼间完成。或者，与你完全不渲染环境不同，你也可以选择仅仅*减少渲染的频率*。这样，你就不必每次更改一个小参数时都抓狂，等待看它是否对系统演化产生影响，仿佛等待了几个小时。
- en: 'Here’s where I can use one of my favorite features of p5.js: the ability to
    quickly create standard interface elements. You saw this before in [Example 9.4](ch09.xhtml#ch9ex4)
    with `createButton()`. This time I’ll create a slider to control the number of
    iterations of a `for` loop that runs inside `draw()`. The `for` loop will contain
    the code for updating (but not drawing) the simulation. The more times the loop
    repeats, the faster the animation will seem.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我可以使用p5.js的一个我最喜欢的功能：快速创建标准界面元素的能力。你之前在[示例9.4](ch09.xhtml#ch9ex4)中看到了这个功能，使用了`createButton()`。这次，我将创建一个滑块来控制`draw()`内部运行的`for`循环的迭代次数。`for`循环将包含更新（但不绘制）模拟的代码。循环重复的次数越多，动画看起来就越快。
- en: 'Here’s the code for this new time slider, excluding all the other global variables
    and their initializations in `setup()`. Notice that the code for the visuals is
    separated from the code for the physics to ensure that rendering still occurs
    only once per `draw()` cycle:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这个新时间滑块的代码，省略了`setup()`中所有其他全局变量及其初始化。请注意，视觉效果的代码与物理代码分开，以确保每个`draw()`周期内的渲染仍然只发生一次：
- en: '![Image](../images/pg611_Image_916.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg611_Image_916.jpg)'
- en: 'In p5.js, a slider is defined with three arguments: a minimum value (for when
    the slider is all the way to the left), a maximum value (for when it’s all the
    way to the right), and a starting value (for when the page first loads). In this
    case, the slider allows you to run the simulation at 20x speed to reach the results
    of evolution more quickly, then slow it back down to 1x speed to bask in the glory
    of the intelligent behaviors on display.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在p5.js中，滑块通过三个参数定义：最小值（滑块最左边时的值）、最大值（滑块最右边时的值）和初始值（页面首次加载时的值）。在这个案例中，滑块允许你以20倍速运行模拟，以更快地得到进化结果，然后将其慢速调整回1倍速，沉浸在智能行为展示的荣耀中。
- en: Here’s the final version of the example with a new `Creature` constructor to
    create a neural network. Everything else related to applying the steps of the
    GA has remained the same from the *Flappy Bird* example code.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最终版本的示例，包含一个新的`Creature`构造函数，用于创建神经网络。与应用GA步骤相关的其他部分与*Flappy Bird*示例代码保持一致。
- en: '![Image](../images/pg612_Image_917.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg612_Image_917.jpg)'
- en: It’s hard to believe, but this book has been a journey well over 10 years in
    the making. Thank you, dear reader, for sticking with it. I promise it’s not an
    infinite loop. However meandering it might have seemed, like a random walk, I’m
    finally using an arrival steering behavior to reach the final piece of the puzzle,
    an attempt to bring together all my past explorations in my own version of the
    Ecosystem Project.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 难以置信，但这本书的创作历程已经超过了10年。感谢亲爱的读者，感谢你一直陪伴。相信我，这不是一个无限循环。尽管它看起来像是在随意漫步，但我最终通过一个到达引导行为，达到了谜题的最后一块拼图，这是我试图将所有过去的探索汇聚到我自己版本的生态系统项目中的努力。
- en: '**A Neuroevolutionary Ecosystem**'
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**神经进化生态系统**'
- en: A few elements in this chapter’s examples don’t quite fit with my dream of simulating
    a natural ecosystem. The first goes back to an issue I raised in [Chapter 9](ch09.xhtml#ch09)
    with the introduction of the bloops. A system of creatures that all live and die
    together, starting completely over with each subsequent generation—that isn’t
    how the biological world works! I’d like to revisit this dilemma in this chapter’s
    context of neuroevolution.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的一些元素与我模拟自然生态系统的梦想不太契合。第一个问题可以追溯到我在[第9章](ch09.xhtml#ch09)中提出的关于bloop生物的问题。一种所有生物共同生活和死亡、每一代都完全从头开始的生物系统——这并不是生物世界的运作方式！我想在本章的神经进化背景下重新审视这个困境。
- en: 'Second, and perhaps more important, a major flaw exists in the way I’m extracting
    features from a scene to train a model. The creatures in [Example 11.4](ch11.xhtml#ch11ex4)
    are all-knowing. Sure, it’s reasonable to assume that a creature is aware of its
    own current velocity, but I’ve also allowed each creature to know the glow’s exact
    location, regardless of how far away it is or what might be blocking the creature’s
    vision or senses. This is a bridge too far. It flies in the face of one of the
    main tenets of autonomous agents I introduced in [Chapter 5](ch05.xhtml#ch05):
    an agent should have a *limited* ability to perceive its environment.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 第二点，可能更为重要的是，我从场景中提取特征以训练模型的方式存在一个重大缺陷。[示例11.4](ch11.xhtml#ch11ex4)中的生物是全知的。当然，合理的假设是生物能够感知其当前的速度，但我也允许每个生物知道光源的确切位置，无论它距离多远，或者有任何障碍物阻挡生物的视野或感官。这是远远不够的。它违背了我在[第5章](ch05.xhtml#ch05)中介绍的自治代理的主要原则之一：一个代理应该具有*有限*的感知其环境的能力。
- en: '**Sensing the Environment**'
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**感知环境**'
- en: A common approach to simulating how a real-world creature (or robot) would have
    a limited awareness of its surroundings is to attach **sensors** to an agent.
    Think back to that mouse in the maze from the beginning of the chapter (hopefully
    it’s been thriving on the cheese it’s been getting as a reward), and now imagine
    it has to navigate the maze in the dark. Its whiskers might act as proximity sensors
    to detect walls and turns. The mouse whiskers can’t see the entire maze, but only
    sense the immediate surroundings. Another example of sensors is a bat using echolocation
    to navigate, or a car on a winding road where the driver can see only what’s projected
    in front of the car’s headlights.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟现实世界中的生物（或机器人）对其周围环境的有限感知的一种常见方法是为代理附加**传感器**。回想一下本章开头迷宫中的那只老鼠（希望它在通过奶酪作为奖励后过得很好），现在想象它必须在黑暗中穿越迷宫。它的触须可能充当接近传感器，来探测墙壁和转弯。老鼠的触须无法看到整个迷宫，只能感知周围的即时环境。另一个传感器的例子是蝙蝠利用回声定位导航，或者在弯曲的道路上，司机只能看到车前灯照射到的区域。
- en: I’d like to build on this idea of the whiskers (or more formally the *vibrissae*)
    found in mice, cats, and other mammals. In the real world, animals use their vibrissae
    to navigate and detect nearby objects, especially in dark or obscured environments
    (see [Figure 11.5](ch11.xhtml#ch11fig5)). How can I attach whisker-like sensors
    to my neuroevolutionary-seeking creatures?
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我想在这个触须（或更正式地说是*振须*）的概念上进一步发展，这种触须存在于老鼠、猫以及其他哺乳动物身上。在现实世界中，动物利用它们的振须来导航并探测附近的物体，特别是在黑暗或障碍重重的环境中（参见[图11.5](ch11.xhtml#ch11fig5)）。我该如何将触须般的传感器附加到我的神经进化寻求生物上呢？
- en: '![Image](../images/pg614_Image_918.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/pg614_Image_918.jpg)'
- en: 'Figure 11.5: Clawdius the cat sensing his environment with his vibrissae'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5：猫咪Clawdius用它的触须感知环境
- en: 'I’ll keep the generic class name `Creature` but think of them now as the amoeba-like
    bloops from [Chapter 9](ch09.xhtml#ch09), enhanced with whisker-like sensors that
    emanate from their center in all directions:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我将保留通用类名`Creature`，但现在将其视为来自[第9章](ch09.xhtml#ch09)的类似变形虫的“bloop”生物，增强了从其中心向四面八方发射的触须感应器：
- en: '![Image](../images/pg614_Image_919.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/pg614_Image_919.jpg)'
- en: The code creates a series of vectors, each describing the direction and length
    of one whisker sensor attached to the creature. However, just the vector isn’t
    enough. I want the sensor to include a `value`, a numeric representation of what
    it’s sensing. This `value` can be thought of as analogous to the intensity of
    touch. Just as Clawdius the cat’s whiskers might detect a faint touch from a distant
    object or a stronger push from a closer one, the virtual sensor’s value could
    range to represent proximity.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 代码创建了一系列向量，每个向量描述了一个附加到生物上的触须传感器的方向和长度。然而，仅仅有向量是不够的。我希望传感器还包括一个`value`，这是它感知的数值表示。这个`value`可以类比于触觉的强度。就像猫咪Clawdius的触须可能感知到远处物体的轻微触碰，或者较近物体的强力推送，虚拟传感器的数值也可以反映接近度。
- en: 'Before I go any further, I need to give the creatures something to sense. How
    about a `Food` class to describe a circle of deliciousness that the creature wants
    to find? Each `Food` object will have a position and a radius:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在我进一步讲解之前，我需要给这些生物提供一些感知的内容。如何为它们设计一个`Food`类，用来描述生物想要寻找的美味圆圈？每个`Food`对象将有一个位置和一个半径：
- en: '![Image](../images/pg615_Image_920.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/pg615_Image_920.jpg)'
- en: How can I determine if a creature’s sensor is touching the food? One approach
    could be to use **raycasting**. This technique is commonly employed in computer
    graphics to project straight lines (often representing beams of light) from an
    origin point in a scene to determine which objects they intersect with. Raycasting
    is useful for visibility and collision checks, exactly what I’m doing here!
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我怎么判断一个生物的传感器是否接触到食物呢？一种方法可能是使用**射线投射**。这种技术通常用于计算机图形学中，将直线（通常代表光束）从场景中的起点投射出去，以确定它们与哪些物体相交。射线投射对于可见性和碰撞检测非常有用，这正是我在这里做的！
- en: 'While raycasting would provide a robust solution, it requires more mathematics
    than I’d like to delve into here. For those interested, an explanation and implementation
    are available in Coding Challenge #145 on the Coding Train website (*[https://thecodingtrain.com/raycasting](https://thecodingtrain.com/raycasting)*).
    For this example, I’ll opt for a more straightforward approach and check whether
    the endpoint of a sensor lies inside the food circle (see [Figure 11.6](ch11.xhtml#ch11fig6)).'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 射线投射（raycasting）虽然提供了一个稳健的解决方案，但它需要比我想在这里深入讨论的更多数学知识。对于感兴趣的人，可以在Coding Train网站的编码挑战#145中找到解释和实现
    (*[https://thecodingtrain.com/raycasting](https://thecodingtrain.com/raycasting)*)。对于这个例子，我将选择一个更简单的方法，检查传感器的端点是否位于食物圆圈内（见[图11.6](ch11.xhtml#ch11fig6)）。
- en: '![Image](../images/pg615_Image_921.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg615_Image_921.jpg)'
- en: 'Figure 11.6: The endpoint of a sensor is inside or outside the food, based
    on its distance to the center of the food.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6：传感器的端点是否在食物内外，取决于它与食物中心的距离。
- en: 'Because I want the sensor to store a value for its sensing along with the sensing
    algorithm, encapsulating these elements into a `Sensor` class makes sense:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我希望传感器能够存储它的感知值以及感知算法，所以将这些元素封装到一个`Sensor`类中是有意义的：
- en: '![Image](../images/pg616_Image_922.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg616_Image_922.jpg)'
- en: Notice that the sensing mechanism gauges the endpoint’s depth within the food’s
    radius by using the `map()` function. When the sensor’s endpoint is just touching
    the outer boundary of the food, `value` starts at 0\. As the endpoint moves closer
    to the center of the food, `value` increases, maxing out at 1\. If the sensor
    isn’t touching the food at all, `value` remains at 0\. This gradient of feedback
    mirrors the varying intensity of touch or pressure in the real world.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，感知机制通过使用`map()`函数来衡量端点在食物半径内的深度。当传感器的端点刚好接触到食物的外边界时，`value`的值为0。当端点逐渐接近食物中心时，`value`增加，最大值为1。如果传感器完全没有接触食物，`value`保持为0。这种反馈的梯度反映了现实世界中接触或压力的强度变化。
- en: 'Let’s test out this sensor mechanism with a simple example: one bloop (controlled
    by the mouse) and one piece of food (placed at the center of the canvas). When
    the sensors touch the food, they light up, and they get brighter as they get closer
    to the center of the food.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简单的例子来测试这种传感器机制：一个由鼠标控制的blooper和一个放在画布中心的食物。当传感器接触到食物时，它们会亮起，并随着它们接近食物中心而变得更亮。
- en: '![Image](../images/pg617_Image_923.jpg)![Image](../images/pg618_Image_924.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg617_Image_923.jpg)![Image](../images/pg618_Image_924.jpg)'
- en: In the example, the creature’s sensors are drawn as lines from its center. When
    a sensor detects something (when `value` is greater than 0), a circle appears.
    To visualize the strength of the sensor reading, I use `value` to set its transparency.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，生物的传感器以从中心延伸出去的线条形式绘制。当传感器探测到某物时（即`value`大于0时），一个圆圈会出现。为了可视化传感器读取的强度，我使用`value`来设置其透明度。
- en: '**Learning from the Sensors**'
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**从传感器中学习**'
- en: 'Are you thinking what I’m thinking? What if the values of a creature’s sensors
    are the inputs to a neural network? Assuming I give the creatures control of their
    own movements again, I could write a new `think()` method that processes the sensor
    values through the neural network brain and outputs a steering force, just as
    in the last two steering examples:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 你在想我在想什么吗？如果一个生物的传感器的值是神经网络的输入呢？假设我重新赋予生物控制自己动作的能力，我可以编写一个新的`think()`方法，通过神经网络大脑处理传感器的值并输出转向力，就像前两个转向的例子一样：
- en: '![Image](../images/pg619_Image_925.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg619_Image_925.jpg)'
- en: 'The logical next step might be to incorporate all the usual parts of the GA,
    writing a fitness function (how much food did each creature eat?) and performing
    selection after a fixed generational time period. But this is a great opportunity
    to revisit the principles of a continuous ecosystem and aim for a more sophisticated
    environment and set of potential behaviors for the creatures themselves. Instead
    of a fixed life span cycle for each generation, I’ll bring back [Chapter 9](ch09.xhtml#ch09)’s
    `health` score for each creature. For every cycle through `draw()` that a creature
    lives, its health deteriorates a little bit:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑上的下一步可能是将所有常见的GA（遗传算法）部分融入其中，编写一个适应度函数（每个生物吃了多少食物？），并在固定的世代时间后进行选择。但这是一个很好的机会，可以重新审视连续生态系统的原则，旨在为生物自身创造一个更复杂的环境和潜在行为模式。我将不再为每一代设置固定的生命周期，而是引入[第9章](ch09.xhtml#ch09)的`health`（健康）评分。对于每一次通过`draw()`的周期，每个生物的健康都会稍微下降：
- en: '![Image](../images/pg619_Image_926.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg619_Image_926.jpg)'
- en: 'In `draw()`, if any bloop’s health drops below 0, that bloop dies and is deleted
    from the `bloops` array. And for reproduction, instead of performing the usual
    crossover and mutation all at once, each bloop (with a health greater than 0)
    will have a 0.1 percent chance of reproducing:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在`draw()`函数中，如果任何bloop的健康值降到0以下，它会死亡并从`bloops`数组中删除。而对于繁殖，bloop不再一次性执行常规的交叉和变异，每个健康值大于0的bloop都有0.1%的几率进行繁殖：
- en: '[PRE4]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In `reproduce()`, I’ll use the `copy()` method (cloning) instead of the `crossover()`
    method (mating), with a higher-than-usual mutation rate to help introduce variation.
    (I encourage you to consider ways to incorporate crossover instead.) Here’s the
    code:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在`reproduce()`函数中，我将使用`copy()`方法（克隆）而不是`crossover()`方法（交配），并采用比平常更高的变异率来帮助引入变异。（我鼓励你考虑使用交叉方法。）这是代码：
- en: '![Image](../images/pg620_Image_927.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg620_Image_927.jpg)'
- en: 'For this to work, some bloops should live longer than others. By consuming
    food, their health increases, giving them extra time to reproduce. I’ll manage
    this in an `eat()` method of the `Creature` class:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使其生效，某些bloop应该比其他bloop活得更久。通过食物的摄取，它们的健康会提高，从而给它们更多的时间来繁殖。我将在`Creature`类的`eat()`方法中管理这一过程：
- en: '![Image](../images/pg620_Image_928.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg620_Image_928.jpg)'
- en: Is this enough for the system to evolve and find its equilibrium? I could dive
    deeper, tweaking parameters and behaviors in pursuit of the ultimate evolutionary
    system. The allure of this infinite rabbit hole is one I cannot easily escape,
    but I’ll explore it on my own time. For the purpose of this book, I invite you
    to run the example, experiment, and draw your own conclusions.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这就足够让系统进化并找到平衡了吗？我可以深入探讨，调整参数和行为，追求最终的进化系统。这个无限的兔子洞具有一种我无法轻易逃脱的魅力，但我将会在自己的时间里去探索。为了本书的目的，我邀请你运行这个示例，进行实验，并得出自己的结论。
- en: '![Image](../images/pg621_Image_929.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg621_Image_929.jpg)'
- en: The final example also includes a few additional features that you’ll find in
    the accompanying online code, such as an array of food that shrinks as it gets
    eaten (respawning when it’s depleted). Additionally, the bloops shrink as their
    health deteriorates.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的示例还包括一些附加功能，你将在随附的在线代码中找到它们，例如食物数组会随着被吃掉而缩小（当食物耗尽时会重新生成）。此外，随着健康状况的恶化，bloops也会缩小。
- en: '![Image](../images/bird.jpg) **The Ecosystem Project**'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '![Image](../images/bird.jpg) **生态系统项目**'
- en: Try incorporating the concept of a brain into the creatures in your world!
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试将“大脑”这一概念融入你世界中的生物！
- en: Can different creatures have different goals and incentives? Are some searching
    for food while others seek different resources? What about creatures avoiding
    dangers like predators or poisons?
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的生物是否有不同的目标和动机？有些生物是否在寻找食物，而其他生物则寻求不同的资源？那么，避开掠食者或毒药等危险的生物呢？
- en: What are each creature’s inputs and outputs?
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个生物的输入和输出是什么？
- en: How do the creatures perceive? Do they see everything or have limits based on
    sensors?
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些生物如何感知世界？它们是否能看到一切，还是仅限于某些传感器的范围？
- en: What strategies can you employ to establish and maintain balance in your ecosystem?
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你能采取哪些策略来建立并维持生态系统中的平衡？
- en: '![Image](../images/pg622_Image_931.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg622_Image_931.jpg)'
- en: '**The End**'
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**结束**'
- en: If you’re still reading, thank you! You’ve reached the end of the book. But
    for as much material as this book contains, I’ve barely scratched the surface
    of the physical world we inhabit and of techniques for simulating it. I intend
    for this book to live as an ongoing project, and I hope to continue adding new
    tutorials and examples to the book’s website, as well as expand and update the
    accompanying video tutorials at the Coding Train website.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还在阅读，感谢您！您已经读到了本书的结尾。尽管本书包含了大量内容，但我几乎只是触及了我们所居住的物理世界的表面，以及模拟该世界的技术。我希望这本书能作为一个持续进行的项目存在，我也希望继续向本书的网站添加新的教程和示例，并扩展和更新Coding
    Train网站上的配套视频教程。
- en: Your feedback is truly appreciated, so please get in touch via email at *[daniel@shiffman.net](mailto:daniel@shiffman.net)*
    or by contributing to the GitHub repository (*[https://github.com/nature-of-code](https://github.com/nature-of-code)*),
    in keeping with the open source spirit of the project. Share your work. Stay in
    touch. Let’s be two with nature.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢您的反馈，请通过电子邮件与我联系，地址是*([daniel@shiffman.net](mailto:daniel@shiffman.net))*，或通过向GitHub仓库贡献代码来与我联系
    (*[https://github.com/nature-of-code](https://github.com/nature-of-code)*)，以保持该项目的开源精神。分享您的作品，保持联系，让我们与自然同在。
- en: '![Image](../images/pg623_Image_932.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/pg623_Image_932.jpg)'
