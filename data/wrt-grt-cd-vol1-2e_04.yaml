- en: '**5'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**5'
- en: CHARACTER REPRESENTATION**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 字符表示**
- en: '![Image](../images/comm1.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/comm1.jpg)'
- en: Although computers are famous for their “number-crunching” capabilities, the
    truth is that most computer systems process character data far more often than
    numbers. The term *character* refers to a human- or machine-readable symbol that
    is typically a non-numeric entity. In general, a character is any symbol that
    you can type on a keyboard or show on a video display. In addition to alphabetic
    characters, character data includes punctuation marks, numeric digits, spaces,
    tabs, carriage returns (the ENTER key), other control characters, and other special
    symbols.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管计算机以“数字运算”能力而闻名，但事实是，大多数计算机系统处理字符数据的频率远高于数字数据。*字符*一词指的是一种人类或机器可读的符号，通常是非数字实体。一般来说，字符是你可以在键盘上输入或在显示器上显示的任何符号。除了字母字符外，字符数据还包括标点符号、数字、空格、制表符、回车符（回车键）、其他控制字符和其他特殊符号。
- en: This chapter looks at how to represent characters, strings, and character sets
    within a computer system. It also discusses various operations on these data types.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了如何在计算机系统中表示字符、字符串和字符集，并讨论了对这些数据类型的各种操作。
- en: '**5.1 Character Data**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**5.1 字符数据**'
- en: Most computer systems use a 1-byte or multibyte binary sequence to encode the
    various characters. Windows, macOS, and Linux fall into this category, using the
    ASCII or Unicode character sets, whose members can all be represented with 1-
    or multibyte binary sequences. The EBCDIC character set, in use on IBM mainframes
    and minicomputers, is another example of a single-byte character code.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数计算机系统使用 1 字节或多字节的二进制序列来编码各种字符。Windows、macOS 和 Linux 都属于这一类别，使用 ASCII 或 Unicode
    字符集，其成员可以通过 1 字节或多字节的二进制序列表示。EBCDIC 字符集在 IBM 大型机和小型计算机上使用，也是单字节字符编码的另一个例子。
- en: This chapter will discuss all three of these character sets and their internal
    representations, as well as how to create your own character sets.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将讨论这三种字符集及其内部表示方式，并介绍如何创建自己的字符集。
- en: '***5.1.1 The ASCII Character Set***'
  id: totrans-8
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.1 ASCII 字符集***'
- en: The ASCII (American Standard Code for Information Interchange) character set
    maps 128 characters to the unsigned integer values 0 through 127 (`$0` through
    `$7F`). Although the exact mapping of characters to numeric values is arbitrary
    and unimportant, a standardized mapping allows you to communicate between programs
    and peripheral devices. The standard ASCII codes are useful because nearly everyone
    uses them. If you use the ASCII code `65` to represent the character *A*, for
    example, you can be confident that some peripheral device (such as a printer)
    will correctly interpret this value as an *A*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ASCII（美国信息交换标准代码）字符集将 128 个字符映射到无符号整数值 0 到 127（`$0` 到 `$7F`）。尽管字符与数字值的精确映射是任意的并且并不重要，但标准化的映射使得你能够在程序和外部设备之间进行通信。标准
    ASCII 代码很有用，因为几乎每个人都使用它们。例如，如果你使用 ASCII 代码 `65` 来表示字符 *A*，你可以放心，某些外部设备（如打印机）会正确地将这个值解释为
    *A*。
- en: 'Because the ASCII character set provides only 128 different characters, you
    might be wondering: “What do we do with the additional 128 values (`$80..$FF`)
    that we can represent with a byte?” One option is to ignore those extra values,
    and that’s the primary approach of this book. Another possibility is to extend
    the ASCII character set by an additional 128 characters. Of course, unless you
    can get everyone to agree upon a particular extension of the character set^([1](footnotes.xhtml#fn5_1a))
    (a difficult task indeed), the whole purpose of having a standardized character
    set will be defeated.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 ASCII 字符集只提供 128 个不同的字符，你可能会问：“我们该如何处理额外的 128 个值（`$80..$FF`），这些值可以用一个字节表示？”一个选项是忽略这些额外的值，这也是本书的主要做法。另一种可能性是通过添加
    128 个字符来扩展 ASCII 字符集。当然，除非你能让每个人都同意某个特定的字符集扩展^([1](footnotes.xhtml#fn5_1a))（这确实是一个困难的任务），否则拥有标准化字符集的整个目的将会失效。
- en: Despite some major shortcomings, such as the inability to represent all characters
    and alphabets in use today, ASCII data is *the* standard for data interchange
    across computer systems and programs. Most programs can accept ASCII data, and
    most programs can produce it. Because you’ll probably be dealing with ASCII characters
    in your programs, it would be wise to study the layout of the character set and
    memorize a few key ASCII codes (such as those for *0*, *A*, and *a*).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在一些重大缺点，如无法表示今天使用的所有字符和字母，但ASCII数据仍然是跨计算机系统和程序数据交换的*标准*。大多数程序都能接受ASCII数据，也能生成ASCII数据。因为你可能会在程序中处理ASCII字符，所以研究字符集的布局并记住一些关键的ASCII代码（如*0*、*A*和*a*的代码）是明智的。
- en: '**NOTE**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Table A-1 in [Appendix A](app01.xhtml#app01) lists all the characters in the
    standard ASCII character set.*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*[附录 A](app01.xhtml#app01)中的表 A-1列出了标准ASCII字符集中的所有字符。*'
- en: The ASCII character set is divided into four groups of 32 characters. The first
    32 characters, ASCII codes `$0` through `$1F` (0 through 31), form a special set
    of nonprinting characters called the *[control characters](gloss01.xhtml#gloss01_59)*.
    As their name implies, these characters perform various printer and display control
    operations rather than displaying symbols. Examples of control characters include
    the carriage return, which positions the cursor at the beginning of the current
    line of characters;^([2](footnotes.xhtml#fn5_2a)) line feed, which moves the cursor
    down one line on the output device; and backspace, which moves the cursor back
    one position to the left. Unfortunately, because there’s very little standardization
    among output devices, different control characters perform different operations
    on different output devices. To find out exactly how a particular control character
    affects a certain device, consult the device’s manual.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ASCII字符集被分为四组32个字符。前32个字符，ASCII代码`$0`到`$1F`（0到31），形成了一组特殊的非打印字符，称为*[控制字符](gloss01.xhtml#gloss01_59)*。顾名思义，这些字符执行各种打印机和显示控制操作，而不是显示符号。控制字符的示例包括回车符，它将光标定位到当前行的开头；^([2](footnotes.xhtml#fn5_2a))
    换行符，它将光标向下移动一行；以及退格符，它将光标向左移动一个位置。不幸的是，由于输出设备之间几乎没有标准化，不同的控制字符在不同的输出设备上执行不同的操作。要准确了解某个控制字符如何影响某个设备，请查阅该设备的手册。
- en: The second group of 32 ASCII character codes comprises various punctuation symbols,
    special characters, and the numeric digits. The most notable characters in this
    group include the space character (ASCII code `$20`) and the numeric digits (ASCII
    codes `$30..$39`).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第二组32个ASCII字符代码包括各种标点符号、特殊字符和数字字符。该组中最显著的字符包括空格字符（ASCII代码`$20`）和数字字符（ASCII代码`$30..$39`）。
- en: The third group of 32 ASCII characters contains the uppercase alphabetic characters.
    The ASCII codes for the characters *A* through *Z* lie in the range `$41` through
    `$5A`. Because there are only 26 different alphabetic characters, the remaining
    six codes hold various special symbols.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 第三组32个ASCII字符包含大写字母字符。字符*A*到*Z*的ASCII代码范围为`$41`到`$5A`。因为只有26个不同的字母字符，其余六个代码用于表示各种特殊符号。
- en: The fourth and final group of 32 ASCII character codes represents the lowercase
    alphabetic symbols, five additional special symbols, and another control character
    (delete). The lowercase character symbols use the ASCII codes `$61` through `$7A`.
    If you convert the codes for the upper- and lowercase characters to binary, you’ll
    notice that the uppercase symbols differ from their lowercase equivalents in exactly
    one bit position. For example, consider the character codes for *E* and *e* in
    [Figure 5-1](ch05.xhtml#ch05fig01).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 第四组也是最后一组32个ASCII字符代码表示小写字母符号、五个额外的特殊符号和另一个控制字符（删除）。小写字母符号使用ASCII代码`$61`到`$7A`。如果你将大写和小写字符的代码转换为二进制，你会发现大写字母与其小写字母之间仅在一个比特位置上有所不同。例如，考虑[图
    5-1](ch05.xhtml#ch05fig01)中*E*和*e*的字符代码。
- en: '![image](../images/05fig01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/05fig01.jpg)'
- en: '*Figure 5-1: ASCII codes for E and e*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-1：E 和 e 的 ASCII 代码*'
- en: These two codes differ only in bit 5\. Uppercase alphabetic characters always
    contain a `0` in bit 5; lowercase alphabetic characters always contain a `1` in
    bit 5\. To quickly convert an alphabetic character between upper- and lowercase,
    simply invert bit 5\. To force an uppercase character to lowercase, set bit 5
    to `1`. Likewise, you can force a lowercase character to uppercase by setting
    bit 5 to `0`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个代码仅在位 5 上有所不同。大写字母字符的位 5 总是为 `0`；小写字母字符的位 5 总是为 `1`。要快速将字母字符在大写和小写之间转换，只需反转位
    5。要将大写字母转换为小写字母，只需将位 5 设置为 `1`。同样，你可以通过将位 5 设置为 `0` 将小写字母转换为大写字母。
- en: Bits 5 and 6 determine the character’s group (see [Table 5-1](ch05.xhtml#ch05tab01)).
    Therefore, you can convert any upper- or lowercase (or special) character to its
    corresponding control character by setting bits 5 and 6 to `0` (for example, *A*
    becomes CTRL-A when you set bits 5 and 6 to `0`; that is, `0x41` becomes `0x01`).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 位 5 和位 6 决定了字符的组（见 [表 5-1](ch05.xhtml#ch05tab01)）。因此，你可以通过将位 5 和位 6 设置为 `0`
    来将任何大写或小写字母（或特殊字符）转换为其对应的控制字符（例如，当你将位 5 和位 6 设置为 `0` 时，*A* 变为 CTRL-A；也就是说，`0x41`
    变为 `0x01`）。
- en: '**Table 5-1:** ASCII Character Groups Determined by Bits 5 and 6'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-1：** 由位 5 和位 6 决定的 ASCII 字符组'
- en: '| **Bit 6** | **Bit 5** | **Group** |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| **位 6** | **位 5** | **组** |'
- en: '| `0` | `0` | Control characters |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| `0` | `0` | 控制字符 |'
- en: '| `0` | `1` | Digits and punctuation |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| `0` | `1` | 数字和标点符号 |'
- en: '| `1` | `0` | Uppercase and special |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 1 | `0` | 大写字母和特殊字符 |'
- en: '| `1` | `1` | Lowercase and special |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 1 | `1` | 小写字母和特殊字符 |'
- en: Bits 5 and 6 aren’t the only bits that encode useful information. Consider,
    for a moment, the ASCII codes of the numeric digit characters in [Table 5-2](ch05.xhtml#ch05tab02).
    The decimal representations of these ASCII codes are not very enlightening. However,
    the hexadecimal representation reveals something very important—the LO nibble
    is the binary equivalent of the represented number. By stripping away (setting
    to `0`) the HO nibble of the ASCII code, you obtain the binary representation
    of that digit. Conversely, you can convert a binary value in the range `0` through
    `9` to its ASCII character representation by simply setting the HO nibble to `%0011`,
    or the decimal value `3`. You can use the logical AND operation to force the HO
    bits to `0`; likewise, you can use the logical OR operation to force the HO bits
    to `%0011`. For more information on string-to-numeric conversions, see [Chapter
    2](ch02.xhtml#ch02).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 位 5 和位 6 不是唯一编码有用信息的位。请考虑一下 [表 5-2](ch05.xhtml#ch05tab02) 中数字字符的 ASCII 码。这些
    ASCII 码的十进制表示并不太能提供直观的信息。然而，十六进制表示却揭示了非常重要的内容——低阶 nibble 是所表示数字的二进制等价物。通过去除（设置为
    `0`）ASCII 码的高阶 nibble，你就能得到该数字的二进制表示。反之，你可以通过简单地将高阶 nibble 设置为 `%0011`，即十进制值 `3`，将
    `0` 到 `9` 范围内的二进制值转换为其对应的 ASCII 字符表示。你可以使用逻辑与操作来强制将高阶位设置为 `0`；同样，你也可以使用逻辑或操作将高阶位强制设置为
    `%0011`。有关字符串到数字转换的更多信息，请参见 [第 2 章](ch02.xhtml#ch02)。
- en: '**Table 5-2:** ASCII Codes for the Numeric Digits'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-2：** 数字字符的 ASCII 码'
- en: '| **Character** | **Decimal** | **Hexadecimal** |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **字符** | **十进制** | **十六进制** |'
- en: '| 0 | `48` | `$30` |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 0 | `48` | `$30` |'
- en: '| 1 | `49` | `$31` |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 1 | `49` | `$31` |'
- en: '| 2 | `50` | `$32` |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 2 | `50` | `$32` |'
- en: '| 3 | `51` | `$33` |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 3 | `51` | `$33` |'
- en: '| 4 | `52` | `$34` |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 4 | `52` | `$34` |'
- en: '| 5 | `53` | `$35` |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 5 | `53` | `$35` |'
- en: '| 6 | `54` | `$36` |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 6 | `54` | `$36` |'
- en: '| 7 | `55` | `$37` |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 7 | `55` | `$37` |'
- en: '| 8 | `56` | `$38` |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 8 | `56` | `$38` |'
- en: '| 9 | `57` | `$39` |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 9 | `57` | `$39` |'
- en: Despite the fact that it is a “standard,” simply encoding your data using ASCII
    characters does not guarantee compatibility across systems. An *A* on one machine
    is most likely an *A* on another system; but, of the 32 control codes in the first
    group of ASCII codes, plus the delete code in the last group, only 4 control codes
    are commonly supported by most devices and applications—backspace (BS), tab, carriage
    return (CR), and line feed (LF). Worse still, different machines often use these
    “supported” control codes in different ways. End-of-line is a particularly troublesome
    example. Windows, MS-DOS, CP/M, and other systems mark end-of-line by the two-character
    sequence CR/LF. The original Apple Macintosh OS and many other systems mark end-of-line
    by a single CR character. Linux, BeOS, macOS, and other Unix systems mark end-of-line
    with a single LF character.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它是一个“标准”，但仅仅使用 ASCII 字符编码数据并不能保证在不同系统之间的兼容性。一个系统上的*A*字符在另一个系统上很可能仍然是*A*；然而，在
    ASCII 代码的第一组 32 个控制码中，加上最后一组的删除码，只有 4 个控制码在大多数设备和应用程序中得到普遍支持——退格（BS）、制表符、回车（CR）和换行符（LF）。更糟糕的是，不同的机器往往以不同的方式使用这些“支持的”控制码。行尾就是一个特别棘手的例子。Windows、MS-DOS、CP/M
    和其他系统使用两个字符的序列 CR/LF 来标记行尾。原版 Apple Macintosh 操作系统和许多其他系统通过单一的 CR 字符来标记行尾。Linux、BeOS、macOS
    和其他 Unix 系统则通过单一的 LF 字符来标记行尾。
- en: Exchanging simple text files between different systems can be an exercise in
    frustration. Even if you use standard ASCII characters in all your files, you
    still need to convert the data when exchanging files between systems. Fortunately,
    many text editors automatically handle files with different line endings (many
    available freeware utilities will also do this conversion for you). If you have
    to do this in your own software, simply copy all characters except the end-of-line
    sequence from one file to another, and then emit the new end-of-line sequence
    whenever you encounter an old end-of-line sequence in the input file.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同系统之间交换简单文本文件可能会让人感到沮丧。即使你在所有文件中都使用标准的 ASCII 字符，在不同系统之间交换文件时，你仍然需要转换数据。幸运的是，许多文本编辑器会自动处理具有不同换行符的文件（许多免费的实用工具也可以为你执行此转换）。如果你必须在自己的软件中进行此操作，只需将除行尾序列外的所有字符从一个文件复制到另一个文件，然后在遇到旧的行尾序列时，发出新的行尾序列。
- en: '***5.1.2 The EBCDIC Character Set***'
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.2 EBCDIC 字符集***'
- en: Although the ASCII character set is, unquestionably, the most popular character
    representation, it’s certainly not the only one available. For example, IBM uses
    the *[EBCDIC](gloss01.xhtml#gloss01_86)* code on many of its mainframe and mini-computer
    lines. However, you’ll rarely encounter it on personal computer systems, so we’ll
    consider it only briefly in this book.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 ASCII 字符集无疑是最流行的字符表示法，但它并不是唯一可用的。例如，IBM 在许多大型机和小型计算机产品线中使用 *[EBCDIC](gloss01.xhtml#gloss01_86)*
    码。然而，在个人计算机系统中，你很少会遇到它，因此在本书中我们仅简要讨论它。
- en: EBCDIC (pronounced “Eb-suh-dic”) stands for *Extended Binary Coded Decimal Interchange
    Code*. If you’re wondering whether there was an unextended version of this character
    code, the answer is yes. Earlier IBM systems and keypunch machines used *BCDIC
    (Binary Coded Decimal Interchange Code)*, a character set based on punched cards
    and decimal representation (for IBM’s older decimal machines).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: EBCDIC（发音为“Eb-suh-dic”）代表*扩展二进制编码十进制交换码*。如果你在想是否有这个字符编码的未扩展版本，答案是有的。早期的 IBM
    系统和打孔机使用的是*BCDIC（二进制编码十进制交换码）*，这是一个基于打孔卡和十进制表示法的字符集（用于 IBM 的老旧十进制机器）。
- en: BCDIC existed long before modern digital computers; it was born on old-fashioned
    IBM keypunches and tabulator machines. EBCDIC extended that encoding to provide
    a character set for IBM’s computers. However, EBCDIC inherited several traits
    from BCDIC that seem strange in the context of modern computers. For example,
    the encodings of the alphabetic characters are not contiguous. Originally, the
    alphabetic characters probably did have a sequential encoding; however, when IBM
    expanded the character set, it used some binary combinations that aren’t present
    in the BCD format (like `%1010..%1111`). These binary values appear between two
    otherwise sequential BCD values, which explains why certain character sequences
    (such as the alphabetic characters) aren’t contiguous in the EBCDIC encoding.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: BCDIC 在现代数字计算机出现之前就已经存在；它诞生于旧式的 IBM 打孔机和制表机。EBCDIC 扩展了这种编码，以便为 IBM 的计算机提供一个字符集。然而，EBCDIC
    继承了 BCDIC 的几个特性，这些特性在现代计算机的背景下显得有些奇怪。例如，字母字符的编码不是连续的。最初，字母字符可能确实有一个顺序编码；然而，当 IBM
    扩展字符集时，它使用了一些在 BCD 格式中不存在的二进制组合（如 `%1010..%1111`）。这些二进制值出现在两个原本连续的 BCD 值之间，这也解释了为什么某些字符序列（如字母字符）在
    EBCDIC 编码中不连续。
- en: EBCDIC is not a single character set; rather, it is a family of character sets.
    While the EBCDIC character sets have a common core (for example, the encodings
    for the alphabetic characters are usually the same), different versions, known
    as *[code pages](gloss01.xhtml#gloss01_51)*, have different encodings for punctuation
    and special characters. Because of the limited number of encodings available in
    a single byte, different code pages reuse some of the character encodings for
    their own special set of characters. So, if you’re given a file that contains
    EBCDIC characters and someone asks you to translate it to ASCII, you’ll quickly
    discover that it’s not a trivial task.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: EBCDIC 不是单一的字符集；它是一个字符集家族。虽然 EBCDIC 字符集有一个共同的核心（例如，字母字符的编码通常是相同的），不同的版本被称为 *[代码页](gloss01.xhtml#gloss01_51)*，它们对标点符号和特殊字符有不同的编码。由于单个字节中可用的编码数量有限，不同的代码页会重用一些字符编码来表示它们自己特殊的字符集。因此，如果你得到一个包含
    EBCDIC 字符的文件，有人让你将其翻译为 ASCII，你很快会发现这并不是一项简单的任务。
- en: Because of the weirdness of the EBCDIC character set, many common algorithms
    that work well on ASCII characters simply don’t work with EBCDIC. However, keep
    in mind that EBCDIC functional equivalents exist for most ASCII characters. Check
    out the IBM literature for more details.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 EBCDIC 字符集的奇特性，许多在 ASCII 字符上效果良好的常见算法在 EBCDIC 上根本无法使用。然而，请记住，大多数 ASCII 字符都有对应的
    EBCDIC 功能等价物。有关更多细节，请查阅 IBM 的文献。
- en: '***5.1.3 Double-Byte Character Sets***'
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.3 双字节字符集***'
- en: Because a byte can represent a maximum of 256 characters, some computer systems
    use *double-byte character sets (DBCSs)* to represent more than 256 characters.
    DBCSs do not encode every character using 16 bits; instead, they use a single
    byte for most character encodings and use double-byte codes only for certain characters.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 因为一个字节最多可以表示 256 个字符，一些计算机系统使用*双字节字符集（DBCSs）*来表示超过 256 个字符。DBCSs 并不是使用 16 位对每个字符进行编码；相反，它们对大多数字符编码使用一个字节，仅对某些字符使用双字节编码。
- en: 'A typical double-byte character set uses the standard ASCII character set along
    with several additional characters in the range `$80` through `$FF`. Certain values
    in this range are used as extension codes that tell the software that a second
    byte immediately follows. Each extension byte allows the DBCS to support another
    256 different character codes. With three extension values, for example, the DBCS
    can support up to 1,021 different characters: 256 characters for each of the extension
    bytes, and 253 (256 – 3) characters for the standard single-byte set (we subtract
    3 because the three extension byte values each consume one of the 256 combinations,
    and they don’t count as characters).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的双字节字符集使用标准的 ASCII 字符集以及 `$80` 到 `$FF` 范围内的几个额外字符。该范围内的某些值用作扩展码，告诉软件紧跟其后的是第二个字节。每个扩展字节使
    DBCS 能够支持另外 256 个不同的字符编码。例如，通过三个扩展值，DBCS 可以支持最多 1,021 个不同的字符：每个扩展字节支持 256 个字符，而标准单字节集支持
    253 个字符（256 – 3），我们减去 3 是因为这三个扩展字节的值每个都占用了 256 种组合中的一个，它们不算作字符。
- en: Back in the days when terminals and computers used memory-mapped character displays,
    double-byte character sets weren’t very practical. Hardware character generators
    really want each character to be the same size, and they want to process a limited
    number of characters. However, as bitmapped displays with software character generators
    became prevalent (such as Windows, Macintosh, Unix/XWindows machines, tablets,
    and smartphones), it became possible to process DBCSs.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端和计算机使用内存映射字符显示的年代，双字节字符集并不是很实用。硬件字符生成器确实希望每个字符的大小相同，并且希望处理有限数量的字符。然而，随着位图显示和软件字符生成器的普及（如
    Windows、Macintosh、Unix/XWindows 机器、平板电脑和智能手机），处理 DBCS 成为可能。
- en: Although DBCSs can compactly represent a large number of characters, more computing
    resources are required to process text in a DBCS format. For example, determining
    the length of a zero-terminated string containing DBCS characters (typical in
    the C/C++ languages) can be considerable work. Some characters in the string consume
    2 bytes, while most others consume only 1 byte, so a string length function has
    to scan the string byte-by-byte to locate any extension values indicating that
    a single character consumes 2 bytes. This process more than doubles the time a
    high-performance string length function takes to execute.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 DBCS 可以紧凑地表示大量字符，但处理 DBCS 格式的文本需要更多的计算资源。例如，确定一个包含 DBCS 字符的零终止字符串的长度（在 C/C++
    语言中很常见）可能需要相当大的工作量。字符串中的某些字符占用 2 个字节，而大多数其他字符只占用 1 个字节，因此字符串长度函数必须逐字节扫描字符串，定位任何扩展值，这些值指示一个字符占用
    2 个字节。这个过程使得高性能的字符串长度函数的执行时间增加了两倍以上。
- en: Worse still, many common algorithms used to manipulate string data fail when
    applied to DBCSs. For example, a common C/C++ trick to step through characters
    in a string is to either increment or decrement a pointer to the string using
    expressions like `++ptrChar` or `--ptrChar`. This won’t work with DBCSs. While
    someone using a DBCS probably has a set of standard C library routines that work
    on DBCSs, it’s also quite likely that other character functions they or others
    have written don’t work properly with the extended characters.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，许多用于操作字符串数据的常见算法在应用于双字节字符集（DBCS）时会失败。例如，一种常见的 C/C++ 技巧是通过使用 `++ptrChar`
    或 `--ptrChar` 等表达式递增或递减指向字符串的指针。这在 DBCS 中不起作用。虽然使用 DBCS 的人可能有一套可以在 DBCS 上工作的标准
    C 库例程，但其他他们或他人编写的字符函数也很可能无法正确处理扩展字符。
- en: The other big problem with DBCSs is the lack of consistent standard. Different
    DBCSs use the same exact encoding for different characters. For these reasons,
    if you need a standardized character set that supports more than 256 characters,
    you’re far better off using the Unicode character set.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: DBCS 的另一个大问题是缺乏一致的标准。不同的 DBCS 对不同的字符使用相同的编码。因此，如果你需要一个支持超过 256 个字符的标准化字符集，使用
    Unicode 字符集无疑是更好的选择。
- en: '***5.1.4 The Unicode Character Set***'
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.4 Unicode 字符集***'
- en: A few decades back, engineers at Aldus, NeXT, Sun, Apple Computer, IBM, Microsoft,
    the Research Library Group, and Xerox realized that their new computer systems
    with bitmaps and user-selectable fonts could display far more than 256 different
    characters at one time. At the time, DBCSs were the most common solution, but—as
    just noted—they had a couple of compatibility problems. So, the engineers sought
    a different route.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 几十年前，Aldus、NeXT、Sun、Apple Computer、IBM、Microsoft、Research Library Group 和 Xerox
    的工程师们意识到，他们的新计算机系统配备位图和用户可选字体，可以同时显示远超过 256 个不同的字符。当时，DBCS 是最常见的解决方案，但正如刚才所提到的，它们存在一些兼容性问题。因此，工程师们寻求了一条不同的道路。
- en: The solution they came up with was the Unicode character set. The engineers
    who originally developed Unicode chose a 2-byte character size. Like DBCSs, this
    approach still required special library code (existing single-byte string functions
    would not always work with double-byte characters), but other than changing the
    size of a character, most existing string algorithms would still work with 2-byte
    characters. The Unicode definition included all of the (known/living) character
    sets at the time, giving each character a unique encoding, to avoid the consistency
    problems that plagued differing DBCSs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 他们提出的解决方案是 Unicode 字符集。最初开发 Unicode 的工程师选择了 2 字节字符大小。与 DBCS 一样，这种方法仍然需要特定的库代码（现有的单字节字符串函数并不总是适用于双字节字符），但除了改变字符的大小外，大多数现有的字符串算法仍然能够与
    2 字节字符一起工作。Unicode 的定义包括了当时所有（已知/现存的）字符集，为每个字符分配了唯一的编码，以避免困扰不同 DBCS 的一致性问题。
- en: The original Unicode standard used a 16-bit word to represent each character.
    Therefore, Unicode supported up to 65,536 different character codes—a huge advance
    over the 256 possible codes that are representable with an 8-bit byte. Furthermore,
    Unicode is upward compatible from ASCII. If the HO 9 bits^([3](footnotes.xhtml#fn5_3a))
    of a Unicode character’s binary representation contain `0`, then the LO 7 bits
    use the standard ASCII code. If the HO 9 bits contain some nonzero value, then
    the 16 bits form an extended character code (extended from ASCII, that is). If
    you’re wondering why so many different character codes are necessary, note that,
    at the time, certain Asian character sets contained 4,096 characters. The Unicode
    character set even provided a set of codes you could use to create an application-defined
    character set. Approximately half of the 65,536 possible character codes have
    been defined, and the remaining character encodings are reserved for future expansion.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最初的 Unicode 标准使用 16 位字来表示每个字符。因此，Unicode 支持最多 65,536 个不同的字符代码——这比 8 位字节能够表示的
    256 个代码要大大提升。此外，Unicode 还与 ASCII 向后兼容。如果 Unicode 字符的二进制表示的高 9 位^([3](footnotes.xhtml#fn5_3a))
    为 `0`，则低 7 位使用标准的 ASCII 代码。如果高 9 位包含非零值，则这 16 位组成扩展字符代码（即扩展自 ASCII）。如果你想知道为什么需要如此多不同的字符代码，请注意，当时某些亚洲字符集包含了
    4,096 个字符。Unicode 字符集甚至提供了一组代码，可以用来创建应用程序定义的字符集。大约一半的 65,536 个可能字符代码已经被定义，剩余的字符编码则保留用于未来扩展。
- en: Today, Unicode is a universal character set, long replacing ASCII and older
    DBCSs. All modern operating systems (including macOS, Windows, Linux, iOS, Android,
    and Unix), web browsers, and most modern applications provide Unicode support.
    Unicode Consortium, a nonprofit corporation, maintains the Unicode standard. By
    maintaining the standard, Unicode, Inc. (*[https://home.unicode.org/](https://home.unicode.org/)*),
    helps guarantee that a character you write on one system will display as you expect
    on a different system or application.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，Unicode 是一个通用字符集，已经长期取代了 ASCII 和旧的 DBCS（双字节字符集）。所有现代操作系统（包括 macOS、Windows、Linux、iOS、Android
    和 Unix）、网页浏览器和大多数现代应用程序都提供 Unicode 支持。Unicode 联盟是一个非营利性公司，负责维护 Unicode 标准。通过维护该标准，Unicode,
    Inc. (*[https://home.unicode.org/](https://home.unicode.org/)*), 帮助确保你在一个系统中编写的字符会在不同的系统或应用程序中按照预期显示。
- en: '***5.1.5 Unicode Code Points***'
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.5 Unicode 码点***'
- en: Alas, as well thought-out as the original Unicode standard was, it couldn’t
    have anticipated the explosion in characters that would occur. Emojis, astrological
    symbols, arrows, pointers, and a wide variety of symbols introduced for the internet,
    mobile devices, and web browsers have greatly expanded the Unicode symbol repertoire
    (along with a desire to support historic, obsolete, and rare scripts). In 1996,
    systems engineers discovered that 65,536 symbols were insufficient. Rather than
    require 3 or 4 bytes for each Unicode character, those in charge of the Unicode
    definition gave up on trying to create a fixed-size representation of characters
    and allowed for opaque (and multiple) encodings of Unicode characters. Today,
    Unicode defines 1,112,064 code points, far exceeding the 2-byte capacity originally
    set aside for Unicode characters.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 可惜的是，尽管最初的 Unicode 标准考虑得非常周全，但它未能预见到字符数量的爆炸性增长。表情符号、星座符号、箭头、指示符号以及为互联网、移动设备和网页浏览器引入的各种符号大大扩展了
    Unicode 符号库（同时也包含了对历史、过时和罕见文字的支持）。1996 年，系统工程师发现 65,536 个符号不足以满足需求。为了避免每个 Unicode
    字符需要 3 或 4 个字节，Unicode 定义者放弃了创建固定大小字符表示的方法，允许使用不透明的（且可多重）编码来表示 Unicode 字符。今天，Unicode
    定义了 1,112,064 个码点，远远超过了最初为 Unicode 字符分配的 2 字节容量。
- en: A Unicode *[code point](gloss01.xhtml#gloss01_53)* is simply an integer value
    that Unicode associates with a particular character symbol; you can think of it
    as the Unicode equivalent of the ASCII code for a character. The convention for
    Unicode code points is to specify the value in hexadecimal with a `U+` prefix;
    for example, `U+0041` is the Unicode code point for the letter *A*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 Unicode *[码点](gloss01.xhtml#gloss01_53)* 只是一个整数值，Unicode 将其与特定的字符符号关联；你可以把它当作字符的
    ASCII 代码的 Unicode 等价物。Unicode 码点的约定是以十六进制表示，并以 `U+` 为前缀；例如，`U+0041` 是字母 *A* 的
    Unicode 码点。
- en: '**NOTE**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*See* [https://en.wikipedia.org/wiki/Unicode#General_Category_property](https://en.wikipedia.org/wiki/Unicode#General_Category_property)
    *for more details on code points.*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*详情请见* [https://en.wikipedia.org/wiki/Unicode#General_Category_property](https://en.wikipedia.org/wiki/Unicode#General_Category_property)
    *了解更多关于码点的信息。*'
- en: '***5.1.6 Unicode Code Planes***'
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.6 Unicode 编码平面***'
- en: Because of its history, blocks of 65,536 characters are special in Unicode—they
    are known as a *multilingual plane*. The first multilingual plane, `U+000000`
    to `U+00FFFF`, roughly corresponds to the original 16-bit Unicode definition;
    the Unicode standard calls this the *[Basic Multilingual Plane (BMP)](gloss01.xhtml#gloss01_24)*.
    Planes 1 (`U+010000` to `U+01FFFF`), 2 (`U+020000` to `U+02FFFF`), and 14 (`U+0E0000`
    to `U+0EFFFF`) are supplementary planes. Unicode reserves planes 3 through 13
    for future expansion and planes 15 and 16 for user-defined character sets.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其历史原因，Unicode 中的 65,536 字符块是特殊的——它们被称为 *多语言平面*。第一个多语言平面，`U+000000` 到 `U+00FFFF`，大致对应于原始的
    16 位 Unicode 定义；Unicode 标准将其称为 *[基本多语言平面（BMP）](gloss01.xhtml#gloss01_24)*。平面 1（`U+010000`
    到 `U+01FFFF`）、平面 2（`U+020000` 到 `U+02FFFF`）和平面 14（`U+0E0000` 到 `U+0EFFFF`）是补充平面。Unicode
    保留了平面 3 到 13 供未来扩展使用，而平面 15 和 16 则为用户定义字符集保留。
- en: 'The Unicode standard defines code points in the range `U+000000` to `U+10FFFF`.
    Note that `0x10ffff` is 1,114,111, which is where most of the 1,112,064 characters
    in the Unicode character set come from; the remaining 2,048 code points are reserved
    for use as *surrogates*, which are Unicode extensions. *Unicode scalar*, another
    term you might hear, is a value from the set of all Unicode code points *except*
    the 2,048 surrogate code points. The HO two hexadecimal digits of the six-digit
    code point value specify the multilingual plane. Why 17 planes? The reason, as
    you’ll see in a moment, is that Unicode uses special multiword entries to encode
    code points beyond `U+FFFF`. Each of the two possible extensions encodes 10 bits,
    for a total of 20 bits; 20 bits gives you 16 multilingual planes, which, plus
    the original BMP, produces 17 multilingual planes. This is also why code points
    fall in the range `U+000000` to `U+10FFFF`: it takes 21 bits to encode the 16
    multilingual planes plus the BMP.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Unicode 标准定义了范围为 `U+000000` 到 `U+10FFFF` 的码点。请注意，`0x10ffff` 是 1,114,111，这也是
    Unicode 字符集中的大多数 1,112,064 个字符的来源；剩余的 2,048 个码点被保留作为 *代理*，即 Unicode 扩展。你可能听说过的另一个术语
    *Unicode 标量*，是指所有 Unicode 码点的集合中的值，*除了* 2,048 个代理码点。六位码点值的 HO 两个十六进制数字指定了多语言平面。为什么是
    17 个平面？原因如你将看到的那样，Unicode 使用特殊的多字词条目来编码超出 `U+FFFF` 的码点。每个扩展编码 10 位，总共 20 位；20
    位可以表示 16 个多语言平面，再加上原始的 BMP，就得到了 17 个多语言平面。这也是为什么码点范围是 `U+000000` 到 `U+10FFFF`：编码这
    16 个多语言平面加上 BMP 需要 21 位。
- en: '***5.1.7 Surrogate Code Points***'
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.7 代理码点***'
- en: As noted earlier, Unicode began life as a 16-bit (2-byte) character set encoding.
    When it became apparent that 16 bits were insufficient to handle all the possible
    characters that existed at the time, an expansion was necessary. As of Unicode
    v2.0, the Unicode, Inc., organization extended the definition of Unicode to include
    multiword characters. Now Unicode uses surrogate code points (`U+D800` through
    `U+DFFF`) to encode values larger than `U+FFFF`. [Figure 5-2](ch05.xhtml#ch05fig02)
    shows the encoding.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Unicode 最初是作为一个 16 位（2 字节）字符集编码的。当显然 16 位不足以处理当时所有可能存在的字符时，扩展变得必要。从 Unicode
    v2.0 开始，Unicode, Inc. 组织扩展了 Unicode 的定义，包含了多字词字符。现在，Unicode 使用代理码点（`U+D800` 到
    `U+DFFF`）来编码大于 `U+FFFF` 的值。[图 5-2](ch05.xhtml#ch05fig02) 显示了这种编码方式。
- en: '![image](../images/05fig02.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/05fig02.jpg)'
- en: '*Figure 5-2: Surrogate code point encoding for Unicode planes 1–16*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-2：Unicode 平面 1-16 的代理码点编码*'
- en: Note that the two words (unit 1/high surrogate and unit 2/low surrogate) always
    appear together. The unit 1 value (with HO bits `%110110`) specifies the upper
    10 bits (`b`[`10`]..`b`[`19`]) of the Unicode scalar, and the unit 2 value (with
    HO bits `%110111`) specifies the lower 10 bits (`b`[`0`]..`b`[`9`]) of the Unicode
    scalar. Therefore, the value of bits `b`[`16`] through `b`[`19`] plus 1 specifies
    Unicode plane 1 through 16\. Bits `b`[`0`] through `b`[`15`] specify the Unicode
    scalar value within the plane.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，两个单元（单元 1/高代理和单元 2/低代理）总是一起出现。单元 1 的值（具有 HO 位 `%110110`）指定 Unicode 标量的高
    10 位（`b`[`10`]..`b`[`19`]），而单元 2 的值（具有 HO 位 `%110111`）指定 Unicode 标量的低 10 位（`b`[`0`]..`b`[`9`]）。因此，`b`[`16`]
    到 `b`[`19`] 位的值加 1 指定了 Unicode 平面 1 到 16，`b`[`0`] 到 `b`[`15`] 位则指定了该平面内的 Unicode
    标量值。
- en: Note that surrogate codes appear only in the BMP. None of the other multilingual
    planes contain surrogate codes. Bits `b`[`0`] through `b`[`19`], extracted from
    the unit 1 and 2 values, always specify a Unicode scalar value (even if the values
    fall in the range `U+D800` through `U+DFFF`).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，代理码仅出现在基本多文种平面（BMP）中。其他的多语言平面不包含代理码。位`b`[`0`]到`b`[`19`]，从单元1和2的值中提取，始终指定一个Unicode标量值（即使这些值落在`U+D800`到`U+DFFF`范围内）。
- en: '***5.1.8 Glyphs, Characters, and Grapheme Clusters***'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.8 字形、字符和字素集***'
- en: Each Unicode code point has a unique name. For example, `U+0045` has the name
    “LATIN CAPITAL LETTER A.” Note that the symbol *A* is *not* the name of the character.
    *A* is a *glyph*—a series of strokes (one horizontal and two slanted strokes)
    that a device draws in order to represent the character.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 每个Unicode码点都有一个唯一的名称。例如，`U+0045`的名称是“拉丁大写字母A”。请注意，符号*A*不是字符的名称。*A*是一个*字形*—设备绘制的一系列笔画（一个水平笔画和两个斜笔画），用以表示这个字符。
- en: There are many different glyphs for the single Unicode character “LATIN CAPITAL
    LETTER A.” For example, a Times Roman letter A and a Times Roman Italic letter
    *A* have different glyphs, but Unicode doesn’t differentiate between them (or
    between *A* characters in any two different fonts). The character “LATIN CAPITAL
    LETTER A” remains `U+0045` regardless of the font or style you use to draw it.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: “拉丁大写字母A”这个单一的Unicode字符有许多不同的字形。例如，Times Roman字体中的字母A和Times Roman斜体字母*A*有不同的字形，但Unicode不会区分它们（也不会区分任何两种不同字体中的*A*字符）。无论你使用什么字体或样式绘制，它的Unicode字符“拉丁大写字母A”始终是`U+0045`。
- en: 'As an interesting side note, if you have access to the Swift programming language,
    you can print the name of any Unicode character using the following code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一句，如果你可以访问Swift编程语言，你可以使用以下代码打印任何Unicode字符的名称：
- en: '[PRE0]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'So, what exactly is a character in Unicode? Unicode scalars are Unicode characters,
    but there’s a difference between what you’d normally call a character and the
    definition of a scalar. For example, is *©* one character or two? Consider the
    following Swift code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Unicode中的字符到底是什么呢？Unicode标量是Unicode字符，但你通常所称的字符与标量的定义是有所区别的。例如，*©*是一个字符还是两个？考虑下面的Swift代码：
- en: '[PRE1]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`"\u{301}"` is the Swift syntax for specifying a Unicode scalar value within
    a string; in this particular case `301` is the hexadecimal code for the *combining
    acute accent* character.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`"\u{301}"`是Swift语法，用于在字符串中指定一个Unicode标量值；在这个特定的案例中，`301`是*组合尖音符*字符的十六进制代码。'
- en: 'The first `print` statement:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个`print`语句：
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: prints the character (producing `©` on the output, as we expect).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 打印字符（在输出中生成`©`，正如我们所预期的那样）。
- en: 'The second `print` statement prints the number of characters Swift determines
    are present in the string:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个`print`语句打印出Swift确定在字符串中存在的字符数量：
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This prints `1` to the standard output.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这会在标准输出上打印`1`。
- en: 'The third `print` statement prints the number of elements (UTF-16 elements^([4](footnotes.xhtml#fn5_4a)))
    in the string:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个`print`语句打印出字符串中的元素数量（UTF-16元素^([4](footnotes.xhtml#fn5_4a)))：
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This prints `2` on the standard output, because the string holds two words of
    UTF-16 data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这会在标准输出上打印`2`，因为字符串包含两个UTF-16数据的单词。
- en: So, again, is this one character or two? Internally (assuming UTF-16 encoding),
    the computer sets aside 4 bytes of memory for this single character (two 16-bit
    Unicode scalar values).^([5](footnotes.xhtml#fn5_5a)) On the screen, however,
    the output takes only one character position and looks like a single character
    to the user. When this character appears within a text editor and the cursor is
    immediately to the right of the character, the user expects that pressing the
    backspace key will delete it. From the user’s perspective, then, this is a single
    character (as Swift reports when you print the `count` attribute of the string).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，再一次，这到底是一个字符还是两个？在内部（假设使用UTF-16编码），计算机会为这个单一字符预留4个字节的内存（两个16位的Unicode标量值）。^([5](footnotes.xhtml#fn5_5a))
    然而，在屏幕上，输出只占用一个字符位置，并且在用户看来像是一个单一字符。当这个字符出现在文本编辑器中，并且光标紧挨着字符右侧时，用户会期望按下退格键删除它。从用户的角度来看，这就是一个单一字符（正如Swift在打印字符串的`count`属性时报告的那样）。
- en: In Unicode, however, a character is largely equivalent to a code point. This
    is not what people normally think of as a character. In Unicode terminology, a
    *grapheme cluster* is what people commonly call a character—it’s a sequence of
    one or more Unicode code points that combine to form a single language element
    (that is, a single character). So, when we talk about characters with respect
    to symbols that an application displays to an end user, we’re really talking about
    grapheme clusters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在 Unicode 中，一个字符大体上等同于一个代码点。这并不是人们通常认为的字符。在 Unicode 术语中，*字形簇*是人们通常所称的字符——它是一个或多个
    Unicode 代码点的序列，这些代码点组合成一个单一的语言元素（即单个字符）。因此，当我们谈论与应用程序显示给终端用户的符号相关的字符时，我们实际上是在谈论字形簇。
- en: 'Grapheme clusters can make life miserable for software developers. Consider
    the following Swift code (a modification of the earlier example):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 字形簇可能会让软件开发人员感到头疼。考虑以下 Swift 代码（前一个示例的修改版）：
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This code produces the same `©` and `1` outputs from the first two `print`
    statements. The following produces `©`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码从前两个 `print` 语句输出相同的 `©` 和 `1`。以下输出 `©`：
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: and this `print` statement produces `1`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 并且这个 `print` 语句产生 `1`。
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'However, the third `print` statement:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，第三个 `print` 语句：
- en: '[PRE8]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: displays `3` rather than `2` (as in the original example).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 显示的是 `3`，而不是原始示例中的 `2`。
- en: There are definitely three Unicode scalar values in this string (`U+0065`, `U+0301`,
    and `U+0301`). When printing, the operating system combines the `e` and the two
    acute accent combining characters to form the single character `©` and then outputs
    the character to the standard output device. Swift is smart enough to know that
    this combination creates a single output symbol on the display, so printing the
    result of the `count` attribute continues to output `1`. However, there are (undeniably)
    three Unicode code points in this string, so printing `utf16.count` produces `3`
    on output.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这个字符串中确实有三个 Unicode 标量值（`U+0065`，`U+0301` 和 `U+0301`）。打印时，操作系统将 `e` 和两个急性重音组合字符结合，形成单一字符
    `©`，然后将该字符输出到标准输出设备。Swift 足够智能，知道这种组合会在显示器上创建一个单一的输出符号，因此打印 `count` 属性的结果仍然输出
    `1`。然而，这个字符串中确实有（三个）Unicode 代码点，因此打印 `utf16.count` 输出 `3`。
- en: '***5.1.9 Unicode Normals and Canonical Equivalence***'
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.9 Unicode 规范和规范等价性***'
- en: 'The Unicode character *©* actually existed on personal computers long before
    Unicode came along. It’s part of the original IBM PC character set and also part
    of the Latin-1 character set (used, for example, on old DEC terminals). As it
    turns out, Unicode uses the Latin-1 character set for the code points in the range
    `U+00A0` to `U+00FF`, and `U+00E9` just happens to correspond to the *©* character.
    Therefore, we can modify the earlier program as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Unicode 字符 *©* 实际上在 Unicode 出现之前就已经存在于个人计算机中。它是原始 IBM PC 字符集的一部分，也是 Latin-1
    字符集的一部分（例如，旧的 DEC 终端使用的字符集）。事实证明，Unicode 在 `U+00A0` 到 `U+00FF` 范围内使用了 Latin-1
    字符集，而 `U+00E9` 恰好对应于 *©* 字符。因此，我们可以按照以下方式修改之前的程序：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The outputs from this program are:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序的输出为：
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Ouch! Three different strings all producing `©` but containing a different number
    of code points. Imagine how this complicates programming strings containing Unicode
    characters. For example, if you have the following three strings (Swift syntax)
    and you try to compare them, what will the result be?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀！三个不同的字符串都输出 `©`，但包含不同数量的代码点。想象一下，这将如何使包含 Unicode 字符的字符串编程变得复杂。例如，如果你有以下三个字符串（Swift
    语法），并尝试比较它们，结果会是什么？
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: To the user, all three strings look the same on the screen. However, they clearly
    contain different values. If you compare them to see if they are equal, will the
    result be `true` or `false`?
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对用户而言，所有三种字符串在屏幕上看起来相同。然而，它们显然包含不同的值。如果你比较它们是否相等，结果是 `true` 还是 `false`？
- en: Ultimately, that depends upon whose string libraries you’re using. Most current
    string libraries would return `false` if you compared these strings for equality.
    Interestingly enough, Swift will claim that `eAccent1` is equal to `eAccent2`,
    but it isn’t smart enough to report that `eAccent1` is equal to `eAccent3` or
    that `eAccent2` is equal to `eAccent3`—despite the fact that it displays the same
    symbol for all three strings. Many languages’ string libraries simply report that
    all three strings are unequal.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，这取决于你使用的是哪个字符串库。大多数当前的字符串库如果比较这些字符串的相等性，会返回`false`。有趣的是，Swift会认为`eAccent1`等于`eAccent2`，但是它并不够聪明，无法报告`eAccent1`等于`eAccent3`，或者`eAccent2`等于`eAccent3`——尽管它显示这三个字符串的符号是相同的。许多编程语言的字符串库简单地报告这三者都不相等。
- en: The three Unicode/Swift strings `"\{E9}"`, `"e\{301}"`, and `"e\{301}\{301}"`
    all produce the same output on the display; therefore, they are canonically equivalent
    according to the Unicode standard. Some string libraries won’t report any of these
    strings as being equivalent, however. Others, like the one for Swift, will handle
    small canonical equivalences (such as `"\{E9}" == "e\{301}"`) but not arbitrary
    sequences that should be equivalent.^([6](footnotes.xhtml#fn5_6a))
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个 Unicode/Swift 字符串 `"\{E9}"`、`"e\{301}"` 和 `"e\{301}\{301}"` 在显示时都会产生相同的输出；因此，根据
    Unicode 标准，它们是规范等效的。然而，一些字符串库并不会将这些字符串视为相等。其他一些库，如 Swift 的字符串库，会处理小的规范等效（例如，`"\{E9}"
    == "e\{301}"`），但不会处理应该等效的任意序列。^([6](footnotes.xhtml#fn5_6a))
- en: Unicode defines *normal forms* for Unicode strings. One aspect of normal form
    is to replace canonically equivalent sequences with an equivalent sequence—for
    example, replace `"e\u{309}"` by `"\u{E9}"` or replace `"\u{E9}"` by `"e\u{309}"`
    (usually, the shorter form is preferable). Some Unicode sequences allow multiple
    combining characters. Often, the order of the combining characters is irrelevant
    to producing the desired grapheme cluster. However, it’s easier to compare two
    such strings if the combining characters are in a specified order. Normalizing
    Unicode strings may also produce results whose combining characters always appear
    in a fixed order (thereby improving efficiency of string comparisons).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Unicode 为 Unicode 字符串定义了*规范形式*。规范形式的一个方面是将规范等效的序列替换为等效的序列——例如，将 `"e\u{309}"`
    替换为 `"\u{E9}"`，或者将 `"\u{E9}"` 替换为 `"e\u{309}"`（通常较短的形式是首选）。一些 Unicode 序列允许多个组合字符。通常，组合字符的顺序对于生成所需的字形簇来说并不重要。然而，如果组合字符按照指定的顺序排列，比较这两个字符串会更容易。规范化
    Unicode 字符串还可能生成结果，其中的组合字符总是以固定顺序出现（从而提高字符串比较的效率）。
- en: '***5.1.10 Unicode Encodings***'
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.10 Unicode 编码***'
- en: As of Unicode v2.0, the standard supports a 21-bit character space capable of
    handling over a million characters (though most of the code points remain reserved
    for future use). Rather than use a fixed-size 3-byte (or worse, 4-byte) encoding
    to allow the larger character set, Unicode, Inc., allows different encodings—UTF-32,
    UTF-16, and UTF-8—each with its own advantages and disadvantages.^([7](footnotes.xhtml#fn5_7a))
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Unicode v2.0 起，标准支持一个 21 位的字符空间，能够处理超过一百万个字符（尽管大部分代码点仍然保留供将来使用）。为了支持更大的字符集，Unicode
    公司允许不同的编码方式——UTF-32、UTF-16 和 UTF-8——每种方式都有其自身的优缺点。^([7](footnotes.xhtml#fn5_7a))
- en: UTF-32 uses 32-bit integers to hold Unicode scalars. The advantage to this scheme
    is that a 32-bit integer can represent every Unicode scalar value (which requires
    only 21 bits). Programs that require random access to characters in strings—without
    having to search for surrogate pairs—and other constant-time operations are (mostly)
    possible with UTF-32\. The obvious drawback to UTF-32 is that each Unicode scalar
    value requires 4 bytes of storage—twice that of the original Unicode definition
    and four times that of ASCII characters. It may seem that using two or four times
    as much storage (over ASCII and the original Unicode) is a small price to pay.
    After all, modern machines have several orders of magnitude more storage than
    they did when Unicode first appeared. However, that extra storage has a huge impact
    on performance, because those additional bytes quickly consume cache storage.
    Furthermore, modern string processing libraries often operate on character strings
    8 bytes at a time (on 64-bit machines). With ASCII characters, that means a given
    string function can process up to eight characters concurrently; with UTF-32,
    that same string function can operate on only two characters concurrently. As
    a result, the UTF-32 version will run four times slower than the ASCII version.
    Ultimately, even Unicode scalar values are insufficient to represent all Unicode
    characters (that is, many Unicode characters require a sequence of Unicode scalars),
    so using UTF-32 doesn’t solve the problem.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: UTF-32 使用 32 位整数来存储 Unicode 标量值。该方案的优点是，32 位整数可以表示每一个 Unicode 标量值（该值只需要 21 位）。需要随机访问字符串中字符的程序——而不必查找代理对——以及其他常数时间操作（大部分情况下）都可以使用
    UTF-32 来实现。UTF-32 的明显缺点是每个 Unicode 标量值需要 4 个字节的存储——是原始 Unicode 定义的两倍，是 ASCII 字符的四倍。看起来，使用比
    ASCII 和原始 Unicode 多两倍或四倍的存储空间似乎是一个小代价。毕竟，现代计算机的存储空间比 Unicode 最初出现时要大几个数量级。然而，这额外的存储空间对性能有巨大影响，因为这些额外的字节很快就会消耗掉缓存存储。此外，现代字符串处理库通常一次处理
    8 个字节（在 64 位机器上）。对于 ASCII 字符，这意味着一个给定的字符串函数可以并行处理多达八个字符；而对于 UTF-32，相同的字符串函数只能并行处理两个字符。因此，UTF-32
    版本的执行速度将比 ASCII 版本慢四倍。最终，即便是 Unicode 标量值也不足以表示所有 Unicode 字符（即，许多 Unicode 字符需要一系列的
    Unicode 标量值），所以使用 UTF-32 并不能解决这个问题。
- en: The second encoding format the Unicode supports is UTF-16\. As the name suggests,
    UTF-16 uses 16-bit (unsigned) integers to represent Unicode values. To handle
    scalar values greater than `0xFFFF`, UTF-16 uses the surrogate pair scheme to
    represent values in the range `0x010000` to `0x10FFFF` (see “[Surrogate Code Points](#sec5_1_7)”
    on page [102](#sec5_1_7)). Because the vast majority of useful characters fit
    into 16 bits, most UTF-16 characters require only 2 bytes. For those rare cases
    where surrogates are necessary, UTF-16 requires 2 words (32 bits) to represent
    the character.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Unicode 支持的第二种编码格式是 UTF-16。顾名思义，UTF-16 使用 16 位（无符号）整数来表示 Unicode 值。为了处理大于 `0xFFFF`
    的标量值，UTF-16 使用代理对方案来表示 `0x010000` 到 `0x10FFFF` 范围内的值（参见页面 [102](#sec5_1_7) 中的
    “[代理码点](#sec5_1_7)”）。因为绝大多数有用的字符适合 16 位表示，所以大多数 UTF-16 字符只需要 2 个字节。对于那些需要代理的罕见情况，UTF-16
    需要 2 个字（32 位）来表示该字符。
- en: The last encoding, and unquestionably the most popular, is UTF-8\. The UTF-8
    encoding is forward compatible from the ASCII character set. In particular, all
    ASCII characters have a single-byte representation (their original ASCII code,
    where the HO bit of the byte containing the character contains a `0` bit). If
    the UTF-8 HO bit is `1`, then UTF-8 requires between 1 and 3 additional bytes
    to represent the Unicode code point. [Table 5-3](ch05.xhtml#ch05tab03) provides
    the UTF-8 encoding schema.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的编码格式，毫无疑问是最流行的编码格式，是 UTF-8。UTF-8 编码与 ASCII 字符集向前兼容。特别地，所有 ASCII 字符都有一个单字节表示（它们原本的
    ASCII 码，其中包含该字符的字节的高位包含 `0` 位）。如果 UTF-8 的高位是 `1`，则 UTF-8 需要额外的 1 到 3 个字节来表示 Unicode
    码点。[表 5-3](ch05.xhtml#ch05tab03) 提供了 UTF-8 编码方案。
- en: '**Table 5-3:** UTF Encoding'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-3：** UTF 编码'
- en: '| **Bytes** | **Bits for code point** | **First code point** | **Last code
    point** | **Byte 1** | **Byte 2** | **Byte 3** | **Byte 4** |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| **字节** | **码点位数** | **第一个码点** | **最后一个码点** | **字节 1** | **字节 2** | **字节 3**
    | **字节 4** |'
- en: '| `1` | `7` | `U+00` | `U+7F` | `0`xxxxxxx |  |  |  |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `1` | `7` | `U+00` | `U+7F` | `0`xxxxxxx |  |  |  |'
- en: '| `2` | `11` | `U+80` | `U+7FF` | `110`xxxxx | `10`xxxxxx |  |  |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `2` | `11` | `U+80` | `U+7FF` | `110`xxxxx | `10`xxxxxx |  |  |'
- en: '| `3` | `16` | `U+800` | `U+FFFF` | `1110`xxxx | `10`xxxxxx | `10`xxxxxx |  |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `3` | `16` | `U+800` | `U+FFFF` | `1110`xxxx | `10`xxxxxx | `10`xxxxxx |  |'
- en: '| `4` | `21` | `U+10000` | `U+10FFFF` | `11110`xxx | `10`xxxxxx | `10`xxxxxx
    | `10`xxxxxx |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `4` | `21` | `U+10000` | `U+10FFFF` | `11110`xxx | `10`xxxxxx | `10`xxxxxx
    | `10`xxxxxx |'
- en: The “xxx . . .” bits are the Unicode code point bits. For multibyte sequences,
    byte 1 contains the HO bits, byte 2 contains the next HO bits (LO bits compared
    to byte 1), and so on. For example, the 2-byte sequence (`%11011111`, `%10000001`)
    corresponds to the Unicode scalar `%0000_0111_1100_0001` (`U+07C1`).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: “xxx . . .”部分是Unicode码点的比特位。对于多字节序列，第1字节包含高位比特，第2字节包含下一个高位比特（与第1字节相比为低位比特），以此类推。例如，2字节序列（`%11011111`，`%10000001`）对应的Unicode标量是`%0000_0111_1100_0001`（`U+07C1`）。
- en: UTF-8 encoding is probably the most common encoding in use. Most web pages use
    it. Most C standard library string functions will operate on UTF-8 text without
    modification (although some C standard library functions can produce malformed
    UTF-8 strings if the programmer isn’t careful with them).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: UTF-8编码可能是最常用的编码。大多数网页都使用它。大多数C标准库字符串函数在处理UTF-8文本时无需修改（尽管一些C标准库函数如果程序员不小心，可能会产生格式错误的UTF-8字符串）。
- en: Different languages and operating systems use different encodings as their default.
    For example, macOS and Windows tend to use UTF-16 encoding, whereas most Unix
    systems use UTF-8\. Some variants of Python use UTF-32 as their native character
    format. By and large, though, most programming languages use UTF-8 because they
    can continue to use older ASCII-based character processing libraries to process
    UTF-8 characters. Apple’s Swift is one of the first programming languages that
    attempts to do Unicode right (though there is a huge performance hit for doing
    so).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的语言和操作系统使用不同的编码作为默认编码。例如，macOS和Windows倾向于使用UTF-16编码，而大多数Unix系统使用UTF-8。某些Python变种使用UTF-32作为其本地字符格式。然而，大多数编程语言都使用UTF-8，因为它们可以继续使用基于ASCII的旧字符处理库来处理UTF-8字符。苹果的Swift是首批尝试正确实现Unicode的编程语言之一（尽管这样做会带来巨大的性能损失）。
- en: '***5.1.11 Unicode Combining Characters***'
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.11 Unicode合成字符***'
- en: Although UTF-8 and UTF-16 encodings are much more compact than UTF-32, the CPU
    overhead and algorithmic complexities of dealing with multibyte (or multiword)
    characters sets complicates their use, introducing bugs and performance issues.
    Despite the issues of wasting memory (especially in the cache), why not simply
    define characters as 32-bit entities and be done with it? This seems like it would
    simplify string processing algorithms, improving performance and reducing the
    likelihood of defects in the code.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然UTF-8和UTF-16编码比UTF-32更紧凑，但处理多字节（或多字）字符集所带来的CPU开销和算法复杂性使得它们的使用变得复杂，容易引入bug和性能问题。尽管浪费内存（尤其是缓存）存在问题，为什么不直接将字符定义为32位实体，然后就此了结呢？这似乎可以简化字符串处理算法，提高性能并减少代码中的缺陷可能性。
- en: 'The problem with this theory is that you cannot represent all possible grapheme
    clusters with only 21 bits (or even 32 bits) of storage. Many grapheme clusters
    consist of several concatenated Unicode code points. Here’s an example from Chris
    Eidhof and Ole Begemann’s *Advanced Swift* (CreateSpace, 2017):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这个理论的问题在于，无法仅用21位（甚至32位）存储来表示所有可能的字形集群。许多字形集群由多个连接的Unicode码点组成。以下是Chris Eidhof和Ole
    Begemann的《*Advanced Swift*》（CreateSpace，2017）中的一个例子：
- en: '[PRE12]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Each of these Unicode grapheme clusters produces an identical character: an
    `ó` with a dot underneath the character (this is a character from the Yoruba character
    set). The character sequence (`U+1ECD`, `U+300`) is an `o` with a dot under it
    followed by a combining acute. The character sequence (`U+F2`, `U+323`) is an
    `ó` followed by a combining dot. The character sequence (`U+6F`, `U+323`, `U+300`)
    is an `o` followed by a combining dot, followed by a combining acute. Finally,
    the character sequence (`U+6F`, `U+300`, `U+323`) is an `o` followed by a combining
    acute, followed by a combining dot. All four strings produce the same output.
    Indeed, the Swift string comparisons treat all four strings as equal:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这些Unicode字形集群中的每一个都会产生相同的字符：一个带有下划点的`ó`（这是一个来自约鲁巴字符集的字符）。字符序列（`U+1ECD`，`U+300`）是一个带有下划点的`o`，后跟一个合成重音符号。字符序列（`U+F2`，`U+323`）是一个`ó`，后跟一个合成点。字符序列（`U+6F`，`U+323`，`U+300`）是一个`o`，后跟一个合成点，接着是一个合成重音符号。最后，字符序列（`U+6F`，`U+300`，`U+323`）是一个`o`，后跟一个合成重音符号，接着是一个合成点。所有四个字符串都会产生相同的输出。实际上，Swift的字符串比较将这四个字符串视为相等：
- en: '[PRE13]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that there is not a single Unicode scalar value that will produce this
    character. You must combine at least two Unicode scalars (or as many as three)
    to produce this grapheme cluster on the output device. Even if you used UTF-32
    encoding, it would still require two (32-bit) scalars to produce this particular
    output.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，并没有单一的 Unicode 标量值可以生成这个字符。你必须至少组合两个 Unicode 标量（或者最多三个）来在输出设备上生成这个字形簇。即使使用
    UTF-32 编码，它仍然需要两个（32 位）标量来生成这个特定的输出。
- en: Emojis present another challenge that can’t be solved using UTF-32\. Consider
    the Unicode scalar `U+1F471`. This prints an emoji of a person with blond hair.
    If we add a skin color modifier to this, we obtain (`U+1F471`, `U+1F3FF`), which
    produces a person with a dark skin tone (and blond hair). In both cases we have
    a single character displaying on the screen. The first example uses a single Unicode
    scalar value, but the second example requires two. There is no way to encode this
    with a single UTF-32 value.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 表情符号带来了另一个挑战，这个问题无法通过 UTF-32 解决。考虑 Unicode 标量 `U+1F471`，它会打印出一个有着金发的人的表情符号。如果我们为此添加一个肤色修饰符，就会得到（`U+1F471`，`U+1F3FF`），它生成的是一个肤色较深的金发人。在这两种情况下，屏幕上显示的都是一个字符。第一个例子使用了一个
    Unicode 标量值，而第二个例子则需要两个标量。没有办法通过单个 UTF-32 值来编码此内容。
- en: The bottom line is that certain Unicode grapheme clusters will require multiple
    scalars, no matter how many bits we assign to the scalar (it’s possible to combine
    30 or 40 scalars into a single grapheme cluster, for example). That means we’re
    stuck dealing with multiword sequences to represent a single “character” regardless
    of how hard we try to avoid it. This is why UTF-32 has never really taken off.
    It doesn’t solve the problem of random access into a string of Unicode characters.
    If you’ve got to deal with normalizing and combining Unicode scalars, it’s more
    efficient to use UTF-8 or UTF-16 encodings.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点是，某些 Unicode 字形簇需要多个标量，无论我们给标量分配多少位（例如，可能会将 30 或 40 个标量组合成一个字形簇）。这意味着我们必须处理多词序列来表示一个单一的“字符”，无论我们多么努力地避免这种情况。这就是为什么
    UTF-32 从未真正普及的原因。它并没有解决对 Unicode 字符串进行随机访问的问题。如果你必须处理 Unicode 标量的归一化和组合，使用 UTF-8
    或 UTF-16 编码会更有效率。
- en: Again, most languages and operating systems today support Unicode in one form
    or another (typically using UTF-8 or UTF-16 encoding). Despite the obvious problems
    with dealing with multibyte character sets, modern programs need to deal with
    Unicode strings rather than simple ASCII strings. Swift, which is almost “pure
    Unicode,” doesn’t even offer much in the way of standard ASCII character support.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，今天大多数语言和操作系统都以某种形式支持 Unicode（通常使用 UTF-8 或 UTF-16 编码）。尽管处理多字节字符集存在明显的问题，但现代程序需要处理
    Unicode 字符串，而不是简单的 ASCII 字符串。Swift 几乎是“纯 Unicode”的，甚至在标准的 ASCII 字符支持方面也没有太多内容。
- en: '**5.2 Character Strings**'
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**5.2 字符串**'
- en: 'After integers, character strings are probably the most common type in use
    in modern programs. In general, a *[character string](gloss01.xhtml#gloss01_47)*
    is a sequence of characters with two main attributes: a *length* and the *character
    data*.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在整数之后，字符字符串可能是现代程序中最常用的数据类型。一般来说，*字符字符串*是一个具有两个主要属性的字符序列：*长度*和*字符数据*。
- en: Character strings may also possess other attributes, such as the *maximum length*
    allowable for that particular variable or a *reference count* specifying how many
    different string variables refer to the same character string. We’ll look at these
    attributes and how programs can use them in this section, which describes various
    string formats and some of the possible string operations.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串也可能具有其他属性，例如该特定变量允许的*最大长度*或*引用计数*，用于指定有多少不同的字符串变量引用同一个字符字符串。在本节中，我们将探讨这些属性以及程序如何使用它们，描述了各种字符串格式和一些可能的字符串操作。
- en: '***5.2.1 Character String Formats***'
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.2.1 字符串格式***'
- en: Different languages use different data structures to represent strings. Some
    string formats use less memory, others allow faster processing, some are more
    convenient to use, and still others provide additional functionality for the programmer
    and operating system. To help you better understand the reasoning behind the design
    of character strings, let’s look at some common string representations popularized
    by various high-level languages.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的编程语言使用不同的数据结构来表示字符串。一些字符串格式占用更少的内存，其他格式则允许更快的处理，有的格式使用起来更为方便，还有的格式为程序员和操作系统提供了额外的功能。为了帮助你更好地理解字符字符串设计背后的原理，让我们看看一些由不同高级语言推广的常见字符串表示方式。
- en: '**5.2.1.1 Zero-Terminated Strings**'
  id: totrans-144
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.1.1 零终止字符串**'
- en: Without question, *[zero-terminated strings](gloss01.xhtml#gloss01_271)* are
    the most common string representation in use today, because this is the native
    string format for C, C++, and several other languages. In addition, you’ll find
    zero-terminated strings in programs written in languages that don’t have a specific
    native string format, such as assembly language.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，*零终止字符串*（[zero-terminated strings](gloss01.xhtml#gloss01_271)）是目前最常用的字符串表示方式，因为这是C、C++以及其他几种语言的原生字符串格式。此外，你会在没有特定原生字符串格式的语言编写的程序中发现零终止字符串，例如汇编语言。
- en: 'A zero-terminated ASCII string is a sequence containing zero or more 8-bit
    character codes ending with a byte containing `0` (or, in the case of UTF-16,
    a sequence containing zero or more 16-bit character codes and ending with a 16-bit
    word containing `0`). For example, in C/C++, the ASCII string `"abc"` requires
    4 bytes: 1 byte for each of the three characters `a`, `b`, and `c`, and a `0`
    byte.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 一个零终止的ASCII字符串是一个序列，包含零个或多个8位字符代码，以一个包含`0`字节的字节结尾（或者在UTF-16的情况下，序列包含零个或多个16位字符代码，并以一个包含`0`的16位字组成）。例如，在C/C++中，ASCII字符串`"abc"`需要4个字节：每个字符`a`、`b`和`c`各占1个字节，再加上一个`0`字节。
- en: 'Zero-terminated strings have a few advantages over other string formats:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 零终止字符串相较于其他字符串格式有一些优势：
- en: Zero-terminated strings can represent strings of any practical length with only
    one byte of overhead (2 bytes in UTF-16, 4 in UTF-32).
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零终止字符串可以用一个字节的开销（UTF-16中是2字节，UTF-32中是4字节）表示任何实际长度的字符串。
- en: Given the popularity of the C/C++ programming languages, high-performance string
    processing libraries are available that work well with zero-terminated strings.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鉴于C/C++编程语言的普及，已有高性能的字符串处理库可以很好地与零终止字符串配合使用。
- en: Zero-terminated strings are easy to implement. As far as the C and C++ languages
    are concerned, strings are just arrays of characters. That’s probably why C’s
    designers chose this format in the first place—so they wouldn’t have to clutter
    up the language with string operators.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零终止字符串很容易实现。就C和C++语言而言，字符串只是字符数组。这可能是C语言设计者最初选择这种格式的原因——这样他们就不必用字符串操作符来使语言变得更加复杂。
- en: You can easily represent zero-terminated strings in any language able to create
    an array of characters.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在任何能够创建字符数组的语言中轻松表示零终止字符串。
- en: 'However, zero-terminated strings also have disadvantages that mean they are
    not always the best choice for representing character string data:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，零终止字符串也有一些缺点，这意味着它们并不总是表示字符字符串数据的最佳选择：
- en: String functions that need to know the length of a string before working on
    the string data often aren’t very efficient when operating on zero-terminated
    strings. The only reasonable way to compute the length of a zero-terminated string
    is to scan the string from the beginning to the end. The longer your strings are,
    the slower this function runs, so the zero-terminated string format isn’t the
    best choice if you need to process long strings.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要在操作字符串数据之前知道字符串长度的字符串函数，在操作零终止字符串时通常效率不高。计算零终止字符串的长度的唯一合理方法是从字符串开始扫描到结尾。你的字符串越长，这个函数运行的速度就越慢，所以如果你需要处理长字符串，零终止字符串格式并不是最佳选择。
- en: Although it’s a minor problem, you cannot easily represent the character code
    `0` (such as the NUL character in ASCII and Unicode) with the zero-terminated
    string format.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管这是一个小问题，但你不能轻易地用零终止字符串格式表示字符代码`0`（例如ASCII和Unicode中的NUL字符）。
- en: Zero-terminated strings don’t contain any information that tells you how long
    the string can grow beyond the terminating `0` byte. Therefore, some string functions,
    like concatenation, can only extend the length of an existing string variable
    and check for overflow if the caller explicitly passes the maximum length.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零终止字符串不包含任何信息，告诉你字符串在终止`0`字节之后可以增长的长度。因此，某些字符串函数（如连接操作）只能扩展现有字符串变量的长度，并且只有在调用者明确传递最大长度时，才会检查是否有溢出。
- en: '**5.2.1.2 Length-Prefixed Strings**'
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.1.2 长度前缀字符串**'
- en: 'A second string format, *[length-prefixed strings](gloss01.xhtml#gloss01_135)*,
    overcomes some of the problems with zero-terminated strings. Length-prefixed strings
    are common in languages like Pascal; they generally consist of a single byte that
    specifies the length of the string, followed by zero or more 8-bit character codes.
    In a length-prefixed scheme, the string `"abc"` consists of 4 bytes: the length
    byte (`$03`), followed by `a`, `b`, and `c`.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种字符串格式，* [长度前缀字符串](gloss01.xhtml#gloss01_135) *，克服了零终止字符串的一些问题。长度前缀字符串在像 Pascal
    这样的语言中很常见；它们通常由一个字节组成，该字节指定字符串的长度，后面跟着零个或多个 8 位字符代码。在长度前缀方案中，字符串 `"abc"` 由 4 个字节组成：长度字节（`$03`），后面是
    `a`、`b` 和 `c`。
- en: 'Length-prefixed strings solve two of the problems associated with zero-terminated
    strings: they allow you to represent the NUL character, and string operations
    are more efficient. Another advantage to length-prefixed strings is that the length
    is usually located at position `0` in the string (if we view the string as an
    array of characters), so the first character of the string begins at index `1`
    in the array representation of the string. For many string functions, having a
    `1`-based index into the character data is much more convenient than a `0`-based
    index (which zero-terminated strings use).'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 长度前缀字符串解决了与零终止字符串相关的两个问题：它们允许你表示 NUL 字符，并且字符串操作更加高效。长度前缀字符串的另一个优点是长度通常位于字符串的`0`位置（如果我们将字符串视为字符数组），因此字符串的第一个字符在数组表示中从索引`1`开始。对于许多字符串函数来说，使用基于`1`的索引来访问字符数据比使用基于`0`的索引（零终止字符串使用的）更加方便。
- en: The principal drawback of length-prefixed strings that they are limited to a
    maximum of 255 characters in length (assuming a 1-byte length prefix). You can
    remove this limitation by using a 2- or 4-byte length value, but doing so increases
    the amount of overhead data from 1 to 2 or 4 bytes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 长度前缀字符串的主要缺点是它们的最大长度限制为 255 个字符（假设使用 1 字节的长度前缀）。你可以通过使用 2 字节或 4 字节的长度值来去除这个限制，但这样做会将每个字符串的开销数据从
    1 字节增加到 2 字节或 4 字节。
- en: '**5.2.1.3 Seven-Bit Strings**'
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.1.3 七位字符串**'
- en: The 7-bit string format is an interesting option that works for 7-bit encodings
    like ASCII. It uses the (normally unused) higher-order bit of the characters in
    the string to indicate the end of the string. All but the last character code
    in the string has its HO bit clear, and the last character in the string has its
    HO bit set.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 7 位字符串格式是一个有趣的选项，适用于像 ASCII 这样的 7 位编码。它使用字符串中字符的（通常未使用的）高位来表示字符串的结束。除了字符串中的最后一个字符代码外，所有字符的高位都被清除，字符串中的最后一个字符的高位被设置为
    1。
- en: 'This 7-bit string format has several disadvantages:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这种 7 位字符串格式有几个缺点：
- en: You have to scan the entire string in order to determine the length of the string.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你必须扫描整个字符串才能确定字符串的长度。
- en: You cannot have zero-length strings.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不能使用零长度字符串。
- en: Few languages provide literal string constants for 7-bit strings.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很少有语言为 7 位字符串提供字面量字符串常量。
- en: You’re limited to a maximum of 128 character codes, though this is fine when
    you’re using plain ASCII.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你最多只能使用128个字符代码，但在使用纯 ASCII 时这并不成问题。
- en: 'However, a big advantage of 7-bit strings is that they don’t require any overhead
    bytes to encode the length. Assembly language (using a macro to create literal
    string constants) is probably the best language to use when dealing with 7-bit
    strings. Because the benefit of 7-bit strings is that they’re compact and assembly
    language programmers tend to worry most about compactness, this is a good match.
    Here’s an HLA macro that converts a literal string constant to a 7-bit string:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，7 位字符串的一个大优点是它们不需要任何额外字节来编码长度。汇编语言（使用宏来创建字面量字符串常量）可能是处理 7 位字符串时最好的语言。因为 7
    位字符串的优势在于它们紧凑，而汇编语言程序员往往最关注紧凑性，所以这非常契合。以下是一个将字面量字符串常量转换为 7 位字符串的 HLA 宏：
- en: '[PRE14]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**5.2.1.4 HLA Strings**'
  id: totrans-169
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.1.4 HLA 字符串**'
- en: As long as you’re not too concerned about a few extra bytes of overhead per
    string, you can create a string format that combines the advantages of both length-prefixed
    and zero-terminated strings without their respective disadvantages. The High-Level
    Assembly language has done this with its native string format.^([8](footnotes.xhtml#fn5_8a))
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 只要你不太在乎每个字符串增加一些额外的字节开销，你就可以创建一种结合了长度前缀和零终止字符串优点的字符串格式，而没有它们各自的缺点。高级汇编语言已经通过其本地字符串格式实现了这一点。^([8](footnotes.xhtml#fn5_8a))
- en: 'The biggest drawback to the HLA character string format is the amount of overhead
    required for each string: 9 bytes per string,^([9](footnotes.xhtml#fn5_9a)) which
    can be significant, percentage-wise, if you’re in a memory-constrained environment
    and you process many small strings.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: HLA 字符串格式的最大缺点是每个字符串所需的开销：每个字符串 9 字节，^([9](footnotes.xhtml#fn5_9a))，如果你处于内存受限的环境中并且处理许多小字符串，这可能会占用显著的百分比。
- en: The HLA string format uses a 4-byte length prefix, allowing character strings
    to be just over four billion characters long (obviously, this is far more than
    any practical HLA application will use). HLA also appends a `0` byte to the character
    string data. The additional 4 bytes of overhead contain the maximum legal length
    for that string. Having this extra field allows HLA string functions to check
    for string overflow, if necessary. In memory, HLA strings take the form shown
    in [Figure 5-3](ch05.xhtml#ch05fig03).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: HLA 字符串格式使用 4 字节的长度前缀，允许字符字符串的长度超过四十亿个字符（显然，这远远超过任何实际的 HLA 应用程序所需的）。HLA 还会将一个
    `0` 字节附加到字符字符串数据后。额外的 4 字节开销包含该字符串的最大合法长度。拥有这个额外的字段允许 HLA 字符串函数在必要时检查字符串溢出。在内存中，HLA
    字符串呈现出 [图 5-3](ch05.xhtml#ch05fig03) 所示的形式。
- en: '![image](../images/05fig03.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/05fig03.jpg)'
- en: '*Figure 5-3: HLA string format*'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-3：HLA 字符串格式*'
- en: The 4 bytes immediately before the first character of the string contain the
    current string length. The 4 bytes preceding the current string length contain
    the maximum string length. Immediately following the character data is a `0` byte.
    Finally, HLA always ensures that the string data structure’s length is a multiple
    of 4 bytes long (for performance reasons), so there may be up to 3 additional
    bytes of padding at the end of the object in memory. (Note that the string in
    [Figure 5-3](ch05.xhtml#ch05fig03) requires only 1 byte of padding to ensure that
    the data structure is a multiple of 4 bytes in length.)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串第一个字符之前的 4 个字节包含当前字符串的长度。当前字符串长度之前的 4 个字节包含最大字符串长度。字符数据之后紧接着是一个 `0` 字节。最后，HLA
    始终确保字符串数据结构的长度是 4 字节的倍数（出于性能考虑），因此对象的末尾可能会有最多 3 个额外的填充字节。（注意，[图 5-3](ch05.xhtml#ch05fig03)
    中的字符串仅需要 1 字节的填充，以确保数据结构的长度是 4 字节的倍数。）
- en: 'HLA string variables are pointers that contain the byte address of the first
    character in the string. To access the length fields, you load the value of the
    string pointer into a 32-bit register, then access the `Length` field at offset
    –4 from the base register and the `MaxLength` field at offset –8 from the base
    register. Here’s an example:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: HLA 字符串变量是包含字符串中第一个字符字节地址的指针。要访问长度字段，你需要将字符串指针的值加载到 32 位寄存器中，然后访问偏移量为 -4 的 `Length`
    字段和偏移量为 -8 的 `MaxLength` 字段。以下是一个示例：
- en: '[PRE15]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As read-only objects, HLA strings are compatible with zero-terminated strings.
    For example, if you have a function written in C that’s expecting you to pass
    it a zero-terminated string, you can call that function and pass it an HLA string
    variable, like this:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 作为只读对象，HLA 字符串与零终止字符串兼容。例如，如果你有一个用 C 语言编写的函数，它期望你传递一个零终止字符串，你可以调用该函数并传递一个 HLA
    字符串变量，如下所示：
- en: '[PRE16]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The only catch is that the C function must not make any changes to the string
    that would affect its length (because the C code won’t update the `Length` field
    of the HLA string). Of course, you can always call a C `strlen()` function upon
    returning to update the length field yourself, but generally, it’s best not to
    pass HLA strings to a function that modifies zero-terminated strings.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的注意事项是 C 函数不能对字符串进行任何会影响其长度的修改（因为 C 代码不会更新 HLA 字符串的 `Length` 字段）。当然，你可以在返回时调用
    C 的 `strlen()` 函数来更新长度字段，但通常情况下，最好不要将 HLA 字符串传递给修改零终止字符串的函数。
- en: '**5.2.1.5 Descriptor-Based Strings**'
  id: totrans-181
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.1.5 基于描述符的字符串**'
- en: 'The string formats we’ve considered up to this point have kept the attribute
    information (that is, the lengths and terminating bytes) for a string in memory
    along with the character data. A slightly more flexible scheme is to maintain
    such information in a record structure, known as a *[descriptor](gloss01.xhtml#gloss01_73)*,
    that also contains a pointer to the character data. Consider the following Pascal/Delphi
    data structure:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们到目前为止考虑过的字符串格式都将属性信息（即长度和终止字节）与字符数据一起保存在内存中。一个稍微更灵活的方案是将这些信息保存在一个记录结构中，称为*[描述符](gloss01.xhtml#gloss01_73)*，该结构还包含指向字符数据的指针。考虑以下
    Pascal/Delphi 数据结构：
- en: '[PRE17]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note that this data structure does not hold the actual character data. Instead,
    the `strData` pointer contains the address of the first character of the string.
    The `curLength` field specifies the current length of the string. You could add
    any other fields you like to this record, like a maximum length field, though
    a maximum length isn’t usually necessary because most string formats employing
    a descriptor are *dynamic* (as the next section will discuss). Most string formats
    employing a descriptor just maintain the `Length` field.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个数据结构并不保存实际的字符数据。相反，`strData` 指针包含字符串第一个字符的地址。`curLength` 字段指定字符串的当前长度。你可以向这个记录中添加任何其他字段，比如最大长度字段，尽管通常不需要最大长度字段，因为大多数使用描述符的字符串格式是
    *动态的*（如下一节将讨论的那样）。大多数使用描述符的字符串格式只维护 `Length` 字段。
- en: An interesting attribute of a descriptor-based string system is that the actual
    character data associated with a string could be part of a larger string. Because
    there are no length or terminating bytes within the actual character data, it’s
    possible to have the character data for two strings overlap (see [Figure 5-4](ch05.xhtml#ch05fig04)).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 基于描述符的字符串系统的一个有趣特点是，关联到字符串的实际字符数据可以是更大字符串的一部分。因为实际字符数据中没有长度或终止字节，所以可以让两个字符串的字符数据重叠（见
    [图 5-4](ch05.xhtml#ch05fig04)）。
- en: '![image](../images/05fig04.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/05fig04.jpg)'
- en: '*Figure 5-4: Overlapping strings using descriptors*'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-4：使用描述符的重叠字符串*'
- en: In this example, there are two strings—`"Hello World"` and `"World"`—that overlap.
    This can save memory and make certain functions, like `substring()`, very efficient.
    Of course, when strings overlap like this, you can’t modify the string data because
    that could wipe out part of some other string.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，有两个字符串——`"Hello World"` 和 `"World"`——是重叠的。这可以节省内存并使某些函数（如 `substring()`）非常高效。当然，当字符串像这样重叠时，你不能修改字符串数据，因为这可能会擦除其他字符串的一部分。
- en: '**5.2.1.6 Java Strings**'
  id: totrans-189
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.1.6 Java 字符串**'
- en: Java uses a descriptor-based string form. The actual `String` data type (that
    is, the structure/class that defines the internal representation of a Java string)
    is *opaque*, which means you really aren’t supposed to know about or mess with
    it. It’s a very bad idea to attempt to manipulate Java strings other than via
    the Java String API, because the Java standard has changed their internal representation
    on a couple of occasions.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Java 使用基于描述符的字符串形式。实际的 `String` 数据类型（即定义 Java 字符串内部表示的结构/类）是 *不透明的*，这意味着你不应该知道或去修改它。尝试以
    Java String API 以外的方式操作 Java 字符串是一个非常糟糕的主意，因为 Java 标准已经在几个场合更改了它们的内部表示。
- en: 'For example, Java originally defined the `String` type as a descriptor with
    four items: a pointer to an array of 16-bit (original) Unicode characters (no
    extension beyond 16 bits), a count field, an offset field, and a hash code field.
    The offset and count fields allowed efficient substring operations, since all
    substrings into a larger string would share the same array of characters. Unfortunately,
    this format produced memory leaks in some degenerate cases, so Java’s designers
    changed the format and eliminated these fields. If you had code that used the
    offset and count fields (again, a bad idea), your code was broken by this change.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Java 最初将 `String` 类型定义为一个包含四个项的描述符：指向一个 16 位（原始）Unicode 字符数组的指针（不扩展到 16 位以上）、一个计数字段、一个偏移量字段和一个哈希码字段。偏移量和计数字段允许高效的子字符串操作，因为所有子字符串都将共享同一个字符数组。不幸的是，这种格式在一些退化的情况下产生了内存泄漏，因此
    Java 的设计者更改了格式并删除了这些字段。如果你的代码使用了偏移量和计数字段（同样，这是一个不好的做法），你的代码就会因为这个更改而崩溃。
- en: 'Java also switched from the original Unicode 2-byte definition to UTF-16 encoding
    once it became apparent that 16-bit characters were insufficient. However, after
    a bit of research into a wide variety of Java programs on the internet, Oracle
    (Java’s owner) discovered that most programs use only the Latin-1 character set
    (basically, ASCII). In Oracle’s own words:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Java 还从最初的 Unicode 2 字节定义切换到 UTF-16 编码，因为很明显 16 位字符是不够的。然而，在对互联网上各种 Java 程序进行一些研究后，Oracle（Java
    的所有者）发现大多数程序只使用 Latin-1 字符集（基本上是 ASCII）。正如 Oracle 自己所说：
- en: Data from different applications suggests that strings are a major component
    of Java heap usage and that most `java.lang.String` objects contain only Latin-1
    characters. Such characters require only one byte of storage. As a result, half
    of the space in the internal character arrays of `java.lang.String` objects are
    not used. The compact strings feature, introduced in Java SE 9, reduces the memory
    footprint, and reduces garbage collection activity.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 来自不同应用程序的数据表明，字符串是 Java 堆内存使用的主要组成部分，并且大多数 `java.lang.String` 对象只包含 Latin-1
    字符。这些字符仅需要一个字节的存储空间。因此，`java.lang.String` 对象的内部字符数组中有一半的空间未被使用。Java SE 9 引入的紧凑字符串特性减少了内存占用，并减少了垃圾回收活动。
- en: This change was largely transparent to Java users and their programs. Oracle
    added a new field to the `String` descriptor to specify whether the encoding was
    UTF-16 or Latin-1\. Once again, if your programs depended on the internal representation,
    they broke.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这一变化对 Java 用户及其程序几乎是透明的。Oracle 向 `String` 描述符中添加了一个新字段，用于指定编码是 UTF-16 还是 Latin-1。如果你的程序依赖于内部表示，它们将会受到影响。
- en: Always assume that Java `String`s are proper Unicode strings (typically using
    UTF-16 encoding). Java does not try to hide the ugliness of multiword characters.
    As a Java programmer, you must be aware of the difference between the number of
    characters, code points, and grapheme clusters in a string. Java provides functions—for
    example, `String.length()`, `String.codePointCount()`, and `BreakIterator.getCharacterInstance()`—to
    compute all these values for you, but your code must explicitly call them.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 始终假设 Java `String` 是标准的 Unicode 字符串（通常使用 UTF-16 编码）。Java 并不试图隐藏多字字符的复杂性。作为 Java
    程序员，你必须意识到字符串中字符数、代码点和字形集群之间的区别。Java 提供了一些函数——例如，`String.length()`、`String.codePointCount()`
    和 `BreakIterator.getCharacterInstance()`——来计算所有这些值，但你的代码必须显式地调用它们。
- en: '**5.2.1.7 Swift Strings**'
  id: totrans-196
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.1.7 Swift 字符串**'
- en: Like Java, the Swift programming language uses Unicode characters in its strings.
    Swift 4.x and earlier used a UTF-16 encoding, which is native to macOS (on which
    Apple developed Swift); with Swift v5.0, Apple switched to UTF-8 as the native
    encoding for Swift strings. As with Java, Swift’s `String` type is opaque, so
    you shouldn’t attempt to mess with (or otherwise use) its internal representation.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Java 类似，Swift 编程语言在其字符串中使用 Unicode 字符。Swift 4.x 及更早版本使用 UTF-16 编码，这是 macOS（Apple
    开发 Swift 所基于的操作系统）原生支持的编码；而在 Swift v5.0 中，Apple 将 Swift 字符串的原生编码更改为 UTF-8。与 Java
    一样，Swift 的 `String` 类型是透明的，因此你不应该尝试修改（或以其他方式使用）其内部表示。
- en: '**5.2.1.8 C# Strings**'
  id: totrans-198
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.1.8 C# 字符串**'
- en: The C# programming language uses UTF-16 encoding for characters in its strings.
    As with Java and Swift, C#’s `string` type is opaque and you shouldn’t attempt
    to mess with (or otherwise use) its internal representation. That being said,
    the Microsoft documentation does claim that C# strings are an array of (Unicode)
    characters.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: C# 编程语言使用 UTF-16 编码表示其字符串中的字符。与 Java 和 Swift 一样，C# 的 `string` 类型是透明的，因此你不应该尝试修改（或以其他方式使用）其内部表示。不过，微软的文档确实声称
    C# 字符串是（Unicode）字符的数组。
- en: '**5.2.1.9 Python Strings**'
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.1.9 Python 字符串**'
- en: The Python programming language originally used UCS-2 (original 16-bit Unicode,
    BMP-only) encoding for strings. Then Python was modified to support UTF-16 or
    UTF-32 encodings (the language was compiled in “narrow” or “wide” versions for
    16- or 32-bit characters). Today, modern versions of Python use a special string
    format that tracks the characters in strings and stores them as ASCII, UTF-8,
    UTF-16, or UTF-32, based on the most compact representation. You can’t really
    access the internal string representation directly within Python, so the caveats
    of opaque types aren’t relevant.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Python 编程语言最初使用 UCS-2（原始的 16 位 Unicode，仅限 BMP）编码表示字符串。然后，Python 被修改为支持 UTF-16
    或 UTF-32 编码（语言可以编译为“窄字符”或“宽字符”版本，分别支持 16 位或 32 位字符）。今天，现代版本的 Python 使用一种特殊的字符串格式，该格式跟踪字符串中的字符，并根据最紧凑的表示方式将它们存储为
    ASCII、UTF-8、UTF-16 或 UTF-32。你无法直接访问 Python 中的内部字符串表示，因此不需要担心不透明类型的问题。
- en: '***5.2.2 Types of Strings: Static, Pseudo-Dynamic, and Dynamic***'
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.2.2 字符串类型：静态、伪动态和动态***'
- en: Based on the various string formats covered thus far, we can now define three
    string types according to when the system allocates storage for the string. There
    are static, pseudo-dynamic, and dynamic strings.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 基于迄今为止覆盖的各种字符串格式，我们现在可以根据系统何时为字符串分配存储来定义三种字符串类型。它们是静态字符串、伪动态字符串和动态字符串。
- en: '**5.2.2.1 Static Strings**'
  id: totrans-204
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.2.1 静态字符串**'
- en: 'Pure *static strings* are those whose maximum size a programmer chooses when
    writing the program. Pascal strings and Delphi “short” strings fall into this
    category. Arrays of characters that you use to hold zero-terminated strings in
    C/C++ also fall into this category. Consider the following declaration in Pascal:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 纯*静态字符串*是那些程序员在编写程序时选择其最大大小的字符串。Pascal 字符串和 Delphi 的“短”字符串属于这一类。你在 C/C++ 中用来保存以零为终止符的字符串的字符数组也属于这一类。考虑以下在
    Pascal 中的声明：
- en: '[PRE18]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'And here’s an example in C/C++:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 C/C++ 中的一个示例：
- en: '[PRE19]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: While the program is running, there’s no way to increase the maximum sizes of
    these static strings. Nor is there any way to reduce the storage they will use;
    these string objects will consume 256 bytes at runtime, period. One advantage
    to pure static strings is that the compiler can determine their maximum length
    at compile time and implicitly pass this information to a string function so it
    can test for bounds violations at runtime.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序运行时，无法增加这些静态字符串的最大大小。也没有办法减少它们使用的存储空间；这些字符串对象在运行时将始终消耗 256 字节。纯静态字符串的一个优点是，编译器可以在编译时确定它们的最大长度，并隐式将此信息传递给字符串函数，以便它在运行时检查是否有越界违规。
- en: '**5.2.2.2 Pseudo-Dynamic Strings**'
  id: totrans-210
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.2.2 伪动态字符串**'
- en: A pseudo-dynamic string is one whose length the system sets at runtime by calling
    a memory management function like `malloc()` to allocate storage for it. However,
    once the system allocates storage for the string, the maximum length of the string
    is fixed. HLA strings generally fall into this category.^([10](footnotes.xhtml#fn5_10a))
    An HLA programmer typically calls the `stralloc()` function to allocate storage
    for a string variable, after which that particular string object has a fixed length
    that cannot change.^([11](footnotes.xhtml#fn5_11a))
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 伪动态字符串是其长度由系统在运行时通过调用类似 `malloc()` 的内存管理函数来分配存储空间的字符串。然而，一旦系统为字符串分配了存储空间，字符串的最大长度就会被固定。HLA
    字符串通常属于这一类。^([10](footnotes.xhtml#fn5_10a)) HLA 程序员通常会调用 `stralloc()` 函数为字符串变量分配存储空间，之后该特定字符串对象的长度将被固定，无法改变。^([11](footnotes.xhtml#fn5_11a))
- en: '**5.2.2.3 Dynamic Strings**'
  id: totrans-212
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**5.2.2.3 动态字符串**'
- en: Dynamic string systems, which typically use a descriptor-based format, automatically
    allocate sufficient storage for a string object whenever you create a new string
    or otherwise do something that affects an existing string. Operations like string
    assignment and substring are relatively trivial in dynamic string systems—generally
    they copy only the string descriptor data, so these operations are fast. However,
    as noted in the section “[Descriptor-Based Strings](#sec5_2_1_5)” on page [114](#sec5_2_1_5),
    when using strings this way, you cannot store data back into a string object,
    because it could modify data that is part of other string objects in the system.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 动态字符串系统通常使用基于描述符的格式，每当创建一个新字符串或执行任何影响现有字符串的操作时，它会自动分配足够的存储空间给字符串对象。在动态字符串系统中，像字符串赋值和子字符串操作这样的操作相对简单——通常它们只复制字符串描述符数据，因此这些操作非常快。然而，正如在“[基于描述符的字符串](#sec5_2_1_5)”一节中第[114页](#sec5_2_1_5)所提到的那样，当以这种方式使用字符串时，你无法将数据存储回字符串对象中，因为这可能会修改系统中其他字符串对象的部分数据。
- en: The solution to this problem is to use the copy-on-write technique. Whenever
    a string function needs to change characters in a dynamic string, the function
    first makes a copy of the string and then makes the necessary modifications to
    that copy. Research suggests that copy-on-write semantics can improve the performance
    of many typical applications, because operations like string assignment and substring
    extraction (which is just a partial string assignment) are far more common than
    the modification of character data within strings. The only drawback to this approach
    is that after several modifications to string data in memory, there may be sections
    of the string heap area that contain character data that’s no longer in use. To
    avoid a *[memory leak](gloss01.xhtml#gloss01_152)*, dynamic string systems employing
    copy on write usually provide *[garbage collection](gloss01.xhtml#gloss01_103)*
    code, which scans the string heap area looking for *stale* character data in order
    to recover that memory for other purposes. Unfortunately, depending on the algorithms
    in use, garbage collection can be quite slow.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的方法是使用写时复制技术。每当一个字符串函数需要修改动态字符串中的字符时，该函数首先会创建字符串的副本，然后对副本进行必要的修改。研究表明，写时复制语义能够提升许多典型应用程序的性能，因为像字符串赋值和子字符串提取（其实只是部分字符串赋值）这样的操作比修改字符串中的字符数据要常见得多。这种方法唯一的缺点是，在内存中多次修改字符串数据之后，可能会有一些字符串堆区域包含不再使用的字符数据。为了避免*
    [内存泄漏](gloss01.xhtml#gloss01_152) *，采用写时复制的动态字符串系统通常会提供* [垃圾回收](gloss01.xhtml#gloss01_103)
    *代码，它会扫描字符串堆区域，寻找*陈旧*的字符数据，并将该内存回收供其他用途。不幸的是，取决于使用的算法，垃圾回收可能会非常慢。
- en: '***5.2.3 Reference Counting for Strings***'
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.2.3 字符串的引用计数***'
- en: Consider the case where you have two string descriptors (or pointers) pointing
    at the same string data in memory. Clearly, you can’t *deallocate* (that is, reuse
    for a different purpose) the storage associated with one pointer while the program
    is still using the other pointer to access the same data. One common solution
    is to make the programmer responsible for keeping track of such details. Unfortunately,
    as applications become more complex, this approach often leads to dangling pointers,
    memory leaks, and other pointer-related problems in the software. A better solution
    is to allow the programmer to deallocate the storage for the character data in
    the string and to have the actual deallocation process hold off until the programmer
    releases the last pointer referencing that data. To accomplish this, a string
    system can use reference counters, which track the pointers and their associated
    data.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有两个字符串描述符（或指针）指向内存中的同一字符串数据。显然，在程序仍然使用另一个指针访问相同数据时，你不能*释放*（即，重新用于其他用途）与一个指针关联的存储空间。一个常见的解决方案是让程序员负责跟踪这些细节。不幸的是，随着应用程序变得更加复杂，这种方法常常导致悬空指针、内存泄漏和其他与指针相关的问题。一个更好的解决方案是允许程序员释放与字符串字符数据相关联的存储空间，并且实际的释放过程会推迟，直到程序员释放最后一个引用该数据的指针。为此，字符串系统可以使用引用计数器，它用于跟踪指针及其关联的数据。
- en: A *[reference counter](gloss01.xhtml#gloss01_214)* is an integer that counts
    the number of pointers that reference a string’s character data in memory. Every
    time you assign the address of the string to some pointer, you increment the reference
    counter by 1\. Likewise, whenever you wish to deallocate the storage associated
    with the character data for the string, you decrement the reference counter. Deallocation
    of the storage for the character data doesn’t happen until the reference counter
    decrements to 0.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '*[引用计数器](gloss01.xhtml#gloss01_214)* 是一个整数，用来计数在内存中引用字符串字符数据的指针数量。每当你将字符串的地址赋给某个指针时，你就将引用计数器加
    1。同样，每当你希望释放与字符串字符数据相关的存储空间时，你就将引用计数器减 1。只有当引用计数器减到 0 时，才会发生字符数据存储空间的释放。'
- en: Reference counting works great when the language handles the details of string
    assignment automatically for you. If you try to implement reference counting manually,
    you must be sure to always increment the reference counter when you assign a string
    pointer to some other pointer variable. The best way to do this is to never assign
    pointers directly, but rather to handle all string assignments via some function
    (or macro) call that updates the reference counters in addition to copying the
    pointer data. If your code fails to update the reference counter properly, you’ll
    wind up with dangling pointers or memory leaks.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 引用计数在语言自动处理字符串赋值的细节时效果非常好。如果你尝试手动实现引用计数，你必须确保在将字符串指针赋值给其他指针变量时始终递增引用计数。实现这一点的最佳方法是不要直接赋值指针，而是通过某个函数（或宏）调用处理所有字符串赋值，并在复制指针数据的同时更新引用计数。如果你的代码未能正确更新引用计数，你将会遇到悬空指针或内存泄漏问题。
- en: '***5.2.4 Delphi Strings***'
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.2.4 Delphi字符串***'
- en: Although Delphi provides a “short string” format that is compatible with the
    length-prefixed strings in earlier versions of Delphi, later versions of Delphi
    (4.0 and later) use dynamic strings. While this string format is unpublished (and,
    therefore, subject to change), indications are that Delphi’s string format is
    very similar to HLA’s. Delphi uses a zero-terminated sequence of characters with
    a leading string length and a reference counter (rather than a maximum length
    as HLA uses). [Figure 5-5](ch05.xhtml#ch05fig05) shows the layout of a Delphi
    string in memory.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Delphi提供了一种与早期版本Delphi中的长度前缀字符串兼容的“短字符串”格式，但后来的Delphi版本（4.0及更高版本）使用动态字符串。虽然这种字符串格式没有公开（因此可能会有所变化），但有迹象表明，Delphi的字符串格式与HLA非常相似。Delphi使用一个以零结尾的字符序列，前面有字符串长度和引用计数（而不是像HLA那样使用最大长度）。[图5-5](ch05.xhtml#ch05fig05)展示了Delphi字符串在内存中的布局。
- en: '![image](../images/05fig05.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/05fig05.jpg)'
- en: '*Figure 5-5: Delphi string data format*'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5-5：Delphi字符串数据格式*'
- en: As with HLA, Delphi string variables are pointers that point to the first character
    of the actual string data. To access the length and reference counter fields,
    the Delphi string routines use a negative offset of – 4 and –8 from the character
    data’s base address. However, because this string format is not published, applications
    should never access the length or reference counter fields directly. Delphi provides
    a length function that extracts the string length for you, and there’s really
    no need for your applications to access the reference counter field because the
    Delphi string functions maintain it automatically.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 与HLA一样，Delphi字符串变量是指向实际字符串数据第一个字符的指针。为了访问长度和引用计数字段，Delphi字符串例程使用从字符数据基地址向后的偏移量——4和——8。然而，由于这种字符串格式没有公开，应用程序不应直接访问长度或引用计数字段。Delphi提供了一个长度函数，用于提取字符串长度，实际上你的应用程序无需访问引用计数字段，因为Delphi字符串函数会自动维护它。
- en: '***5.2.5 Custom String Formats***'
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.2.5 自定义字符串格式***'
- en: Typically, you’ll use the string format your language provides, unless you have
    special requirements. If that’s the case, you’ll find that most languages provide
    user-defined data-structuring capabilities that enable you to create your own
    custom string formats.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你将使用语言提供的字符串格式，除非你有特殊的需求。如果是这样，你会发现大多数语言提供了用户定义的数据结构功能，允许你创建自己的自定义字符串格式。
- en: Note that the language will probably insist on a single string format for literal
    string constants. However, you can usually write a short conversion function that
    will translate the literal strings in your language to whatever format you choose.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，语言可能会坚持使用单一的字符串格式来表示文字字符串常量。然而，通常你可以编写一个简短的转换函数，将你的语言中的文字字符串转换为你选择的任何格式。
- en: '**5.3 Character Set Data Types**'
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**5.3 字符集数据类型**'
- en: 'Like strings, character set data types (or just *character sets*) are a composite
    data type built upon the character data type. A *character set* is a mathematical
    set of characters. Membership in a set is a binary relation: a character is either
    in the set or not, and you can’t have multiple copies of the same character in
    a character set. Furthermore, the concept of sequence (whether one character comes
    before another, as in a string) is foreign to a character set. If two characters
    are members of a set, their order in the set is irrelevant.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 与字符串一样，字符集数据类型（或称*字符集*）是一种复合数据类型，建立在字符数据类型之上。*字符集*是字符的数学集合。集合中的成员关系是二元关系：一个字符要么在集合中，要么不在，不能在字符集中出现同一个字符的多个副本。此外，顺序的概念（例如，某个字符是否在另一个字符之前出现，像在字符串中一样）对字符集而言是陌生的。如果两个字符是集合的成员，它们在集合中的顺序是无关紧要的。
- en: '[Table 5-4](ch05.xhtml#ch05tab04) lists some common operations that applications
    perform on character sets.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 5-4](ch05.xhtml#ch05tab04)列出了应用程序对字符集执行的一些常见操作。'
- en: '**Table 5-4:** Common Character Set Functions'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-4：** 常见的字符集函数'
- en: '| **Function/operator** | **Description** |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| **功能/操作符** | **描述** |'
- en: '| Membership (in) | Checks to see if a character is a member of a character
    set (returns `true`/`false`). |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 成员资格（在） | 检查一个字符是否是字符集的成员（返回`true`/`false`）。 |'
- en: '| Intersection | Returns the intersection of two character sets (that is, the
    set of characters that are members of both sets). |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 交集 | 返回两个字符集的交集（即，既属于两个集合的字符集合）。 |'
- en: '| Union | Returns the union of two character sets (that is, all the characters
    that are members of either set or both sets). |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 联集 | 返回两个字符集的并集（即，属于任意一个集合或两个集合的字符）。 |'
- en: '| Difference | Returns the difference of two sets (that is, those characters
    in one set that are not in the other). |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 差集 | 返回两个集合的差集（即，属于一个集合但不属于另一个集合的字符）。 |'
- en: '| Extraction | Extracts a single character from a set. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 提取 | 从集合中提取单个字符。 |'
- en: '| Subset | Returns `true` if one character set is a subset of another. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 子集 | 如果一个字符集是另一个字符集的子集，则返回`true`。 |'
- en: '| Proper subset | Returns `true` if one character set is a proper subset of
    another. |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 正确的子集 | 如果一个字符集是另一个字符集的正确子集，则返回`true`。 |'
- en: '| Superset | Returns `true` if one character set is a superset of another.
    |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 超集 | 如果一个字符集是另一个字符集的超集，则返回`true`。 |'
- en: '| Proper superset | Returns `true` if one character set is a proper superset
    of another. |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 正确的超集 | 如果一个字符集是另一个字符集的超集，则返回`true`。 |'
- en: '| Equality | Returns `true` if one character set is equal to another. |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 等式 | 如果一个字符集等于另一个字符集，则返回`true`。 |'
- en: '| Inequality | Returns `true` if one character set is not equal to another.
    |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 不等式 | 如果一个字符集不等于另一个字符集，则返回`true`。 |'
- en: '***5.3.1 Powerset Representation of Character Sets***'
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.3.1 字符集的幂集表示***'
- en: There are many different ways to represent character sets. Several languages
    implement them using an array of Boolean values (one Boolean value for each possible
    character code). Each Boolean value determines whether its corresponding character
    is (`true`) or is not (`false`) a member of the character set. To conserve memory,
    most character set implementations allocate only a single bit for each character
    in the set; therefore, they consume 16 bytes (128 bits) of memory when supporting
    128 characters, or 32 bytes (256 bits) when supporting up to 256 possible characters.
    This representation of a character set is known as a *[powerset](gloss01.xhtml#gloss01_199)*.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 表示字符集有许多不同的方式。一些语言使用布尔值数组来实现字符集（每个可能的字符代码对应一个布尔值）。每个布尔值决定它对应的字符是否（`true`）或不（`false`）是字符集的成员。为了节省内存，大多数字符集实现只为集合中的每个字符分配一个位；因此，当支持128个字符时，它们消耗16字节（128位）内存，当支持最多256个字符时，消耗32字节（256位）内存。这种字符集的表示方式被称为*[幂集](gloss01.xhtml#gloss01_199)*。
- en: The HLA language uses an array of 16 bytes to represent the 128 possible ASCII
    characters, which is organized in memory as shown in [Figure 5-6](ch05.xhtml#ch05fig06).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: HLA语言使用一个16字节的数组来表示128个可能的ASCII字符，该数组在内存中的组织方式如[图 5-6](ch05.xhtml#ch05fig06)所示。
- en: '![image](../images/05fig06.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/05fig06.jpg)'
- en: '*Figure 5-6: HLA character set representation*'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-6：HLA字符集表示*'
- en: Bit 0 of byte 0 corresponds to ASCII code `0` (the NUL character). If this bit
    is `1`, then the character set contains the NUL character; if this bit is `0`,
    then the character set does not contain the NUL character. Likewise, bit 1 of
    byte 8 corresponds to ASCII code `65`, an uppercase *A*. Bit 65 will contain a
    `1` if *A* is a current member of the character set, and `0` if it is not.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 字节 0 的位 0 对应于 ASCII 码 `0`（NUL 字符）。如果这个位是 `1`，则字符集包含 NUL 字符；如果这个位是 `0`，则字符集不包含
    NUL 字符。同样，字节 8 的位 1 对应于 ASCII 码 `65`，大写字母 *A*。如果 *A* 是字符集的当前成员，则位 65 将为 `1`，如果不是，则为
    `0`。
- en: Pascal (for example, Delphi) uses a similar scheme to represent character sets.
    Delphi allows up to 256 characters in a character set, so Delphi character sets
    consume 256 bits (or 32 bytes) of memory.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: Pascal（例如 Delphi）使用类似的方案来表示字符集。Delphi 允许在字符集中最多包含 256 个字符，因此 Delphi 字符集占用 256
    位（或 32 字节）内存。
- en: While there are other ways to implement character sets, this bit vector (array)
    implementation makes it very easy to perform set operations like union, intersection,
    difference comparison, and membership tests.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管实现字符集的方法有很多种，但这种位向量（数组）实现使得执行集合操作，如并集、交集、差集比较和成员测试，变得非常简单。
- en: '***5.3.2 List Representation of Character Sets***'
  id: totrans-251
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.3.2 字符集的列表表示***'
- en: Sometimes a powerset bitmap just isn’t the right representation for a character
    set. For example, if your sets are always very small (no more than three or four
    members), using 16 or 32 bytes to represent each of them can be overkill. In this
    case, you’d be better off using a character string to represent a list of characters.^([12](footnotes.xhtml#fn5_12a))
    If you rarely have more than a few characters in a set, scanning through a string
    to locate a particular character is probably efficient enough for most applications.
    Likewise, if your character set has a large number of possible characters, then
    the powerset representation could become huge (for example, implementing the original
    Unicode UCS-2 character set as a powerset would require 8,192 bytes of memory,
    even if there was only a single character in the set). In this situation, a list
    or character string representation could be more appropriate than a powerset,
    as you don’t need to reserve memory for all possible members of the set (only
    those that are actually present).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，幂集位图并不是表示字符集的最佳方式。例如，如果你的集合通常非常小（最多三个或四个成员），使用 16 或 32 字节来表示每个集合可能会显得过于浪费。在这种情况下，你最好使用字符字符串来表示字符列表。^([12](footnotes.xhtml#fn5_12a))
    如果你的集合中很少有超过几个字符的元素，那么扫描字符串以查找特定字符通常对大多数应用来说已经足够高效。同样，如果你的字符集有大量可能的字符，那么幂集表示法可能会变得非常庞大（例如，实现原始的
    Unicode UCS-2 字符集作为幂集需要 8,192 字节的内存，即使集合中只有一个字符）。在这种情况下，列表或字符字符串表示法可能比幂集表示法更为合适，因为你不需要为集合中的所有可能成员保留内存（只需要为实际存在的成员保留内存）。
- en: '**5.4 Designing Your Own Character Set**'
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**5.4 设计你自己的字符集**'
- en: Very little is sacred about the ASCII, EBCDIC, and Unicode character sets. Their
    primary advantage is that they are international standards to which many systems
    adhere. If you stick with one of these standards, chances are good you’ll be able
    to exchange information with other people, which is what these codes were designed
    for.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ASCII、EBCDIC 和 Unicode 字符集几乎没有什么是神圣不可侵犯的。它们的主要优点在于它们是国际标准，许多系统都遵循这些标准。如果你坚持使用其中一种标准，
    chances are good 你将能够与他人交换信息，这也是这些代码设计的初衷。
- en: However, they were not designed to make various character computations easy.
    ASCII and EBCDIC were developed with now-antiquated hardware in mind—mechanical
    teletypewriters’ keyboards and punched-card systems, respectively. Given that
    such equipment is found mainly in museums today, the layout of the codes in these
    character sets has almost no benefit in modern computer systems. If we could design
    our own character sets today, they’d be considerably different from ASCII or EBCDIC.
    They’d probably be based on modern keyboards (so they’d include codes for common
    keys, like LEFT ARROW, RIGHT ARROW, page up, and page down). They’d also be laid
    out to make various common computations a whole lot easier.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些字符集并不是为了简化各种字符计算而设计的。ASCII 和 EBCDIC 是在如今已经过时的硬件条件下开发的——分别是机械电传打字机的键盘和打孔卡片系统。鉴于如今这类设备主要只能在博物馆里找到，因此这些字符集中的代码布局在现代计算机系统中几乎没有任何优势。如果今天我们可以设计自己的字符集，它们与
    ASCII 或 EBCDIC 会有很大不同。它们可能会基于现代键盘（因此会包括常见按键的代码，如左箭头、右箭头、页面向上和页面向下）。它们的布局也会使得各种常见计算变得更加轻松。
- en: Although the ASCII and EBCDIC character sets are not going away any time soon,
    there’s nothing stopping you from defining your own application-specific character
    set. Of course, such a set is, well, application-specific, and you won’t be able
    to share text files containing characters encoded in your custom character set
    with applications that are ignorant of your private encoding. But it’s fairly
    easy to translate between different character sets using a lookup table, so you
    can convert between your application’s internal character set and an external
    character set (like ASCII) when performing I/O operations. Assuming you pick a
    reasonable encoding that makes your programs more efficient overall, the loss
    of efficiency during I/O can be worthwhile. But how do you choose an encoding?
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ASCII和EBCDIC字符集在短期内不会消失，但没有什么能阻止你定义自己的应用程序特定字符集。当然，这样的字符集是应用程序特定的，你将无法与不了解你私有编码的应用程序共享包含你自定义字符集的文本文件。但使用查找表在不同字符集之间进行转换是相当容易的，因此在执行输入/输出操作时，你可以在应用程序的内部字符集和外部字符集（如ASCII）之间进行转换。假设你选择了一个合理的编码，使得程序整体更高效，尽管输入/输出过程中的效率可能会有所损失，但还是值得的。那么，你该如何选择编码呢？
- en: The first question you have to ask yourself is, “How many characters do I want
    to support in my character set?” Obviously, the number of characters you choose
    will directly affect the size of your character data. An easy choice is 256 possible
    characters, because bytes are the most common primitive data type that software
    uses to represent character data. Keep in mind, however, that if you don’t really
    need 256 characters, you probably shouldn’t try to define that many in your character
    set. For example, if you can get by with 128, or even 64, characters in your custom
    character set, then “text files” you create with it will compress better. Likewise,
    data transmissions using it will be faster if you only have to transmit 6 or 7
    bits for each character instead of 8\. If you need more than 256 characters, you’ll
    have to weigh the advantages and disadvantages of using multiple code pages, double-byte
    character sets, or 16-bit characters. And keep in mind that Unicode provides support
    for user-defined characters. So, if you need more than 256 characters in your
    character set, you might consider inserting it into Unicode to remain “somewhat
    standard” with the rest of the world.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先要问自己的是：“我希望我的字符集支持多少个字符？”显然，你选择的字符数量将直接影响字符数据的大小。一个简单的选择是256个可能的字符，因为字节是软件用于表示字符数据的最常见原始数据类型。然而，记住，如果你实际上并不需要256个字符，你可能不应该在字符集里定义那么多。例如，如果你只需128个，甚至64个字符来满足需求，那么你使用它创建的“文本文件”将会更好地压缩。同样，使用它进行数据传输时，如果每个字符只需传输6或7位而不是8位，传输速度会更快。如果你需要超过256个字符，你必须权衡使用多个编码页、双字节字符集或16位字符的优缺点。并且请记住，Unicode支持用户自定义字符。所以，如果你需要超过256个字符，你可能需要考虑将其插入到Unicode中，以便与全球其他系统保持“某种程度的标准”。
- en: In this section, we’ll define a character set containing 128 characters using
    an 8-bit byte. For the most part, we’ll simply rearrange the codes in the ASCII
    character set to make them more convenient for several calculations, and we’ll
    rename a few of the control codes so they make sense on modern systems instead
    of the old mainframes and teletypes for which they were created. We’ll also add
    a few new characters beyond those defined by the ASCII standard. Again, the main
    purpose of this exercise is to make various computations more efficient, not create
    new characters. We’ll call this the *HyCode* character set.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将定义一个包含128个字符的字符集，使用8位字节表示。大多数情况下，我们将仅仅重新排列ASCII字符集中的代码，使其在进行几种计算时更加方便，并且会重新命名一些控制代码，以便它们在现代系统中更有意义，而不是当初为老旧的主机和电传打字机设计的那些代码。我们还会添加一些ASCII标准之外的新字符。同样，这个练习的主要目的是使各种计算更加高效，而不是创造新的字符。我们将这个字符集称为*HyCode*字符集。
- en: '**NOTE**'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*This point bears repeating: the use of HyCode in this chapter is not an attempt
    to create some new character set standard. It’s simply a demonstration of how
    you can create a custom, application-specific character set to improve your programs.*'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '*这一点需要重复强调：本章中使用HyCode并不是试图创建某种新的字符集标准。这只是一个如何创建自定义、应用程序特定字符集以提升程序效率的示范。*'
- en: '***5.4.1 Designing an Efficient Character Set***'
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.4.1 设计高效的字符集***'
- en: We should think about several things when designing a new character set. For
    example, do we need to be able to represent strings of characters using an existing
    string format? This can influence the encoding of our strings—if you want to use
    function libraries that operate on zero-terminated strings, then you need to reserve
    encoding `0` in your custom character set for use as an end-of-string marker.
    Keep in mind, however, that a fair number of string functions won’t work with
    your new character set, no matter what you do. Functions like `stricmp()` work
    only if you use the same representation for alphabetic characters as ASCII (or
    some other common character set). Therefore, you shouldn’t feel hampered by the
    requirements of some particular string representation, because you’re going to
    have to write many of your own string functions to process your custom characters
    anyway. The HyCode character set doesn’t reserve code `0` for an end-of-string
    marker, and that’s okay because zero-terminated strings are not very efficient.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计一个新的字符集时，我们应该考虑几个方面。例如，我们是否需要能够使用现有的字符串格式来表示字符字符串？这会影响我们字符串的编码——如果你想使用操作零终止字符串的函数库，那么你需要在自定义字符集中保留编码`0`，用于作为字符串结束标记。然而，请记住，很多字符串函数无论你做什么，都无法与新字符集一起使用。像`stricmp()`这样的函数只有在你使用与ASCII（或其他常见字符集）相同的字母字符表示时才有效。因此，你不应感到受某种特定字符串表示的限制，因为你无论如何都会编写许多自己的字符串函数来处理自定义字符。HyCode字符集不保留`0`编码作为字符串结束标记，这是可以的，因为零终止字符串效率不高。
- en: 'If you look at programs that use character functions, you’ll see that certain
    functions occur frequently, such as:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看使用字符函数的程序，你会发现某些函数经常出现，例如：
- en: Check a character to see if it is a digit.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是数字。
- en: Convert a digit character to its numeric equivalent.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数字字符转换为其对应的数字。
- en: Convert a numeric digit to its character equivalent.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数字字符转换为其对应的字符。
- en: Check a character to see if it is alphabetic.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是字母字符。
- en: Check a character to see if it is a lowercase character.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是小写字母字符。
- en: Check a character to see if it is an uppercase character.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是大写字母字符。
- en: Compare two characters (or strings) using a *case-insensitive* comparison.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*不区分大小写*的比较方法比较两个字符（或字符串）。
- en: Sort a set of alphabetic strings (case-sensitive and case-insensitive sorting).
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对字母字符串进行排序（区分大小写和不区分大小写排序）。
- en: Check a character to see if it is alphanumeric.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是字母数字字符。
- en: Check a character to see if it is legal in an identifier.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否在标识符中是合法的。
- en: Check a character to see if it is a common arithmetic or logical operator.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是常见的算术或逻辑运算符。
- en: Check a character to see if it is a bracketing character (that is, one of *(*,
    *)*, *[*, *]*, *{*, *}*, *<*, or *>*).
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是括号字符（即，*(*、*)*、*[*、*]*、*{*、*}*、*<* 或 *>*）。
- en: Check a character to see if it is a punctuation character.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是标点符号字符。
- en: Check a character to see if it is a *whitespace* character (such as a space,
    tab, or newline).
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是*空白*字符（如空格、制表符或换行符）。
- en: Check a character to see if it is a cursor control character.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是光标控制字符。
- en: Check a character to see if it is a scroll control key (such as PGUP, PGDN,
    HOME, and END).
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是滚动控制键（如 PGUP、PGDN、HOME 和 END）。
- en: Check a character to see if it is a function key.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查一个字符，看看它是否是功能键。
- en: We’ll design the HyCode character set to make these types of operations as efficient
    and easy as possible. One huge improvement we can make over the ASCII character
    set is to assign contiguous character codes to characters belonging to the same
    type, such as alphabetic characters and control characters, so we can do any of
    the preceding tests by using a pair of comparisons. For example, it would be nice
    if we could determine that a particular character is some sort of punctuation
    mark by comparing against two values that represent upper and lower bounds of
    the entire range of such characters, which we can’t do in ASCII because the punctuation
    marks are spread throughout the character set. While it’s not possible to satisfy
    every conceivable range comparison this way, we can design our character set to
    accommodate the most common tests with as few comparisons as possible.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将设计 HyCode 字符集，使这些类型的操作尽可能高效和简便。相较于 ASCII 字符集，我们可以做出一个巨大的改进，即为属于同一类型的字符（如字母字符和控制字符）分配连续的字符编码，这样我们就可以通过一对比较来进行上述任何测试。例如，如果我们能通过与表示整个标点符号字符范围上下限的两个值进行比较来确定某个字符是否为标点符号，那就太好了。ASCII
    中无法做到这一点，因为标点符号字符分散在整个字符集内。虽然我们无法通过这种方式满足每一个可能的范围比较，但我们可以设计我们的字符集，使其能够以最少的比较次数满足最常见的测试。
- en: '***5.4.2 Grouping the Character Codes for Numeric Digits***'
  id: totrans-282
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.4.2 数字字符编码分组***'
- en: We can achieve the first three functions in the previous list by reserving the
    character codes `0` through `9` for the characters 0 through 9\. First, by using
    a single unsigned comparison to check if a character code is less than or equal
    to `9`, we can see if a character is a digit. Next, converting between characters
    and their numeric representations is trivial, because the character code and the
    numeric representation are one and the same.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将字符编码 `0` 到 `9` 保留给数字字符 0 到 9 来实现前面列表中的前三个功能。首先，通过使用单一的无符号比较来检查字符编码是否小于或等于
    `9`，我们可以判断一个字符是否为数字。接下来，字符与其数字表示之间的转换非常简单，因为字符编码和数字表示是相同的。
- en: '***5.4.3 Grouping Alphabetic Characters***'
  id: totrans-284
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.4.3 字母字符分组***'
- en: 'The ASCII character set, though nowhere near as bad as EBCDIC, just isn’t well
    designed for dealing with alphabetic character tests and operations. Here are
    some problems with ASCII that we’ll solve with HyCode:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ASCII 字符集尽管远不如 EBCDIC 那样糟糕，但在处理字母字符的测试和操作时设计得并不好。以下是我们将通过 HyCode 解决的 ASCII 中的一些问题：
- en: The alphabetic characters lie in two disjoint ranges. Tests for an alphabetic
    character require four comparisons.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字母字符分布在两个不重叠的范围内。进行字母字符测试时需要四次比较。
- en: The lowercase characters have ASCII codes that are greater than the uppercase
    characters. If we’re going to do a case-sensitive comparison, it’s more intuitive
    to treat lowercase characters as being less than uppercase characters.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小写字母的 ASCII 编码大于大写字母。如果我们要进行区分大小写的比较，将小写字母视为小于大写字母会更直观。
- en: All lowercase characters have a greater value than any individual uppercase
    character. This leads to counterintuitive results, such as *a* being greater than
    *B*.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有小写字母的值都大于任何单个的大写字母。这会导致一些违反直觉的结果，例如 *a* 大于 *B*。
- en: 'HyCode solves these problems in a couple of interesting ways. First, HyCode
    uses encodings `$4C` through `$7F` to represent the 52 alphabetic characters.
    Because HyCode uses only 128 character codes (`$00..$7F`), the alphabetic codes
    consume the last 52 character codes. This means that we can test a character to
    see if it is alphabetic by comparing whether the code is greater than or equal
    to `$4C`. In a high-level language, you’d write the comparison like this:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: HyCode 以几种有趣的方式解决了这些问题。首先，HyCode 使用 `$4C` 到 `$7F` 的编码来表示 52 个字母字符。因为 HyCode
    只使用 128 个字符编码（`$00..$7F`），字母字符编码占用了最后的 52 个字符编码。这意味着我们可以通过比较字符编码是否大于或等于 `$4C`
    来测试一个字符是否为字母。在高级语言中，你会像这样写这个比较：
- en: '[PRE20]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Or, if your compiler supports the HyCode character set, like this:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你的编译器支持 HyCode 字符集，可以像这样：
- en: '[PRE21]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In assembly language, you could use a pair of instructions like the following:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在汇编语言中，你可以使用一对类似下面的指令：
- en: '[PRE22]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'HyCode interleaves the lowercase and uppercase characters (that is, the sequential
    encodings are for the characters *a*, *A*, *b*, *B*, *c*, *C*, and so on). This
    makes sorting and comparing strings very easy, regardless of whether you’re doing
    a case-sensitive or case-insensitive search. The interleaving uses the LO bit
    of the character code to determine whether the character code is lowercase (LO
    bit is `0`) or uppercase (LO bit is `1`). HyCode uses the following encodings
    for alphabetic characters:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: HyCode 交替使用小写字母和大写字母（即，顺序编码对应的字符为 *a*、*A*、*b*、*B*、*c*、*C* 等）。这使得排序和比较字符串变得非常容易，无论你是在进行区分大小写还是不区分大小写的搜索。交替使用字符编码的
    LO 位来确定字符编码是小写字母（LO 位为 `0`）还是大写字母（LO 位为 `1`）。HyCode 对字母字符使用以下编码：
- en: '[PRE23]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Checking for an uppercase or lowercase alphabetic using HyCode is more work
    than checking whether a character is alphabetic, but in assembly it’s still less
    work than the equivalent ASCII comparison. To test a character to see if it’s
    a member of a single case, you need two comparisons—first to see if it’s alphabetic,
    then to determine its case. In C/C++ you can use statements like the following:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 HyCode 检查字母字符是大写字母还是小写字母比检查字符是否是字母字符要多一些工作，但在汇编语言中，这仍然比等效的 ASCII 比较要少工作。要测试一个字符是否属于某一大小写，你需要进行两次比较——首先检查它是否是字母字符，然后判断它的大小写。在
    C/C++ 中，你可以使用如下语句：
- en: '[PRE24]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The subexpression `(c & 1)` evaluates `true` (`1`) if the LO bit of `c` is
    `1`, meaning we have an uppercase character if `c` is alphabetic. Likewise, `!(c
    & 1)` evaluates `true` if the LO bit of `c` is `0`, meaning we have a lowercase
    character. If you’re working in 80x86 assembly language, you can test a character
    to see if it’s uppercase or lowercase by using three machine instructions:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 子表达式 `(c & 1)` 如果 `c` 的 LO 位是 `1`，则为 `true`（`1`），意味着如果 `c` 是字母字符，那么它是大写字母。同样，`!(c
    & 1)` 如果 `c` 的 LO 位是 `0`，则为 `true`，意味着 `c` 是小写字母。如果你在 80x86 汇编语言中工作，你可以通过使用三条机器指令来测试一个字符是大写字母还是小写字母：
- en: '[PRE25]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Very few languages provide the equivalent of an `ror()` operation, and only
    a few allow you to (easily) treat character values as signed and unsigned within
    the same code sequence. Therefore, this sequence is probably limited to assembly
    language programs.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有语言提供 `ror()` 操作的等价功能，并且只有少数几种语言允许你（轻松地）在同一代码序列中将字符值视为有符号和无符号。因此，这个序列可能仅限于汇编语言程序。
- en: '***5.4.4 Comparing Alphabetic Characters***'
  id: totrans-302
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.4.4 比较字母字符***'
- en: 'The HyCode grouping of alphabetic characters means that lexicographical ordering
    (“dictionary ordering”) is almost free. Sorting your strings by comparing the
    HyCode character values gives you lexicographical order, because HyCode defines
    the following relations on the alphabetic characters:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: HyCode 对字母字符的分组意味着字典排序几乎是免费的。通过比较 HyCode 字符值对字符串进行排序，你可以获得字典顺序，因为 HyCode 定义了以下字母字符的关系：
- en: '[PRE26]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This is exactly the relationship you want for lexicographical ordering, and
    it’s also the one most people would intuitively expect. To do a case-insensitive
    comparison, you simply mask out the LO bits (or force them both to `1`) of the
    alphabetic characters.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是你所期望的字典排序关系，同时也是大多数人直觉上会期望的关系。要进行不区分大小写的比较，你只需屏蔽字母字符的 LO 位（或将它们都强制为 `1`）。
- en: 'To see the benefit of the HyCode character set when doing case-insensitive
    comparisons, let’s first take a look at what the standard case-insensitive character
    comparison would look like in C/C++ for two ASCII characters:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到在进行不区分大小写比较时 HyCode 字符集的优势，我们先来看一下在 C/C++ 中标准的不区分大小写字符比较对于两个 ASCII 字符的实现方式：
- en: '[PRE27]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This code doesn’t look too bad, but consider what the `toupper()` function (or,
    usually, macro) expands to:^([13](footnotes.xhtml#fn5_13a))
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码看起来不算太复杂，但考虑一下 `toupper()` 函数（或通常是宏）展开后的样子：^([13](footnotes.xhtml#fn5_13a))
- en: '[PRE28]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'With this macro, you wind up with the following once the C preprocessor expands
    the previous `if` statement:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个宏，当 C 预处理器展开前面的 `if` 语句时，结果如下：
- en: '[PRE29]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This expands to 80x86 code similar to this:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 这会展开为类似于以下的 80x86 代码：
- en: '[PRE30]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In HyCode, case-insensitive comparisons are much simpler. Here’s what the HLA
    assembly code would look like:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在 HyCode 中，不区分大小写的比较要简单得多。以下是 HLA 汇编代码的样子：
- en: '[PRE31]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As you can see, the HyCode sequence uses half the instructions for a case-insensitive
    comparison of two characters.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，HyCode 序列使用了用于不区分大小写的两个字符比较的一半指令。
- en: '***5.4.5 Grouping Other Characters***'
  id: totrans-317
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.4.5 分组其他字符***'
- en: 'Because alphabetic characters are at one end of the character code range and
    numeric characters are at the other, it takes two comparisons to check a character
    to see if it’s alphanumeric (which is still better than the four comparisons necessary
    in ASCII). Here’s the Pascal/Delphi code you’d use to see if a character is alphanumeric:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 因为字母字符位于字符编码范围的一端，而数字字符位于另一端，所以检查一个字符是否为字母数字字符需要进行两次比较（这仍然比 ASCII 中所需的四次比较要好）。以下是你可以用来检查一个字符是否为字母数字的
    Pascal/Delphi 代码：
- en: '[PRE32]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Several programs (beyond compilers) need to efficiently process strings of characters
    that represent program identifiers. Most languages allow alphanumeric characters
    in identifiers, and, as you just saw, we can check a character to see if it’s
    alphanumeric using only two comparisons.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 一些程序（超出编译器之外）需要高效地处理表示程序标识符的字符字符串。大多数语言允许标识符中使用字母数字字符，正如你刚刚看到的，我们可以通过仅进行两次比较来检查一个字符是否为字母数字字符。
- en: Many languages also allow underscores within identifiers, and some languages,
    such as MASM, allow other characters like the “at” character (`@`) and dollar
    sign (`$`) to appear within identifiers. Therefore, by assigning the underscore
    character the value `75`, and by assigning the `$` and `@` characters the respective
    codes `73` and `74`, we can still test for an identifier character using only
    two comparisons.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 许多语言也允许在标识符中使用下划线，并且一些语言，如 MASM，允许其他字符，如“at”符号（`@`）和美元符号（`$`）出现在标识符中。因此，通过将下划线字符分配值
    `75`，并将 `$` 和 `@` 字符分别分配代码 `73` 和 `74`，我们仍然可以仅通过两次比较来测试一个字符是否为标识符字符。
- en: For similar reasons, HyCode groups together the cursor control keys, the whitespace
    characters, the bracketing characters (parentheses, brackets, braces, and angle
    brackets), the arithmetic operators, the punctuation characters, and so on. [Table
    5-5](ch05.xhtml#ch05tab05) lists the complete HyCode character set. If you study
    the numeric codes assigned to each character, you’ll see that they allow for efficient
    computation of most of the character operations described earlier.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 由于类似的原因，HyCode 将光标控制键、空白字符、括号字符（圆括号、方括号、大括号和尖括号）、算术运算符、标点字符等分组在一起。[表格 5-5](ch05.xhtml#ch05tab05)列出了完整的
    HyCode 字符集。如果你研究每个字符所分配的数字代码，你会发现它们允许高效地计算前面描述的大多数字符操作。
- en: '**Table 5-5:** The HyCode Character Set'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '**表格 5-5：** HyCode 字符集'
- en: '| **Binary** | **Hex** | **Decimal** | **Character** | **Binary** | **Hex**
    | **Decimal** | **Character** |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| **二进制** | **十六进制** | **十进制** | **字符** | **二进制** | **十六进制** | **十进制** | **字符**
    |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| `0000_0000` | `00` | `0` | `0` | `0001_1110` | `1E` | `30` | End |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| `0000_0000` | `00` | `0` | `0` | `0001_1110` | `1E` | `30` | 结束 |'
- en: '| `0000_0001` | `01` | `1` | `1` | `0001_1111` | `1F` | `31` | Home |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| `0000_0001` | `01` | `1` | `1` | `0001_1111` | `1F` | `31` | Home |'
- en: '| `0000_0010` | `02` | `2` | `2` | `0010_0000` | `20` | `32` | PgDn |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| `0000_0010` | `02` | `2` | `2` | `0010_0000` | `20` | `32` | PgDn |'
- en: '| `0000_0011` | `03` | `3` | `3` | `0010_0001` | `21` | `33` | PgUp |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| `0000_0011` | `03` | `3` | `3` | `0010_0001` | `21` | `33` | PgUp |'
- en: '| `0000_0100` | `04` | `4` | `4` | `0010_0010` | `22` | `34` | Left |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| `0000_0100` | `04` | `4` | `4` | `0010_0010` | `22` | `34` | 左 |'
- en: '| `0000_0101` | `05` | `5` | `5` | `0010_0011` | `23` | `35` | Right |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| `0000_0101` | `05` | `5` | `5` | `0010_0011` | `23` | `35` | 右 |'
- en: '| `0000_0110` | `06` | `6` | `6` | `0010_0100` | `24` | `36` | Up |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| `0000_0110` | `06` | `6` | `6` | `0010_0100` | `24` | `36` | Up |'
- en: '| `0000_0111` | `07` | `7` | `7` | `0010_0101` | `25` | `37` | Down/linefeed
    |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| `0000_0111` | `07` | `7` | `7` | `0010_0101` | `25` | `37` | 下/换行 |'
- en: '| `0000_1000` | `08` | `8` | `8` | `0010_0110` | `26` | `38` | Nonbreaking
    space |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| `0000_1000` | `08` | `8` | `8` | `0010_0110` | `26` | `38` | 不换行空格 |'
- en: '| `0000_1001` | `09` | `9` | `9` | `0010_0111` | `27` | `39` | Paragraph |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| `0000_1001` | `09` | `9` | `9` | `0010_0111` | `27` | `39` | 段落 |'
- en: '| `0000_1010` | `0A` | `10` | Keypad | `0010_1000` | `28` | `40` | Carriage
    return |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| `0000_1010` | `0A` | `10` | 小键盘 | `0010_1000` | `28` | `40` | 回车 |'
- en: '| `0000_1011` | `0B` | `11` | Cursor | `0010_1001` | `29` | `41` | Newline/enter
    |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| `0000_1011` | `0B` | `11` | 光标 | `0010_1001` | `29` | `41` | 新行/回车 |'
- en: '| `0000_1100` | `0C` | `12` | Function | `0010_1010` | `2A` | `42` | Tab |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| `0000_1100` | `0C` | `12` | 功能 | `0010_1010` | `2A` | `42` | Tab |'
- en: '| `0000_1101` | `0D` | `13` | Alt | `0010_1011` | `2B` | `43` | Space |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| `0000_1101` | `0D` | `13` | Alt | `0010_1011` | `2B` | `43` | 空格 |'
- en: '| `0000_1110` | `0E` | `14` | Control | `0010_1100` | `2C` | `44` | `(` |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| `0000_1110` | `0E` | `14` | 控制 | `0010_1100` | `2C` | `44` | `(` |'
- en: '| `0000_1111` | `0F` | `15` | Command | `0010_1101` | `2D` | `45` | `)` |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| `0000_1111` | `0F` | `15` | 命令 | `0010_1101` | `2D` | `45` | `)` |'
- en: '| `0001_0000` | `10` | `16` | Len | `0010_1110` | `2E` | `46` | `[` |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| `0001_0000` | `10` | `16` | 长度 | `0010_1110` | `2E` | `46` | `[` |'
- en: '| `0001_0001` | `11` | `17` | Len128 | `0010_1111` | `2F` | `47` | `]` |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| `0001_0001` | `11` | `17` | Len128 | `0010_1111` | `2F` | `47` | `]` |'
- en: '| `0001_0010` | `12` | `18` | Bin128 | `0011_0000` | `30` | `48` | `{` |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| `0001_0010` | `12` | `18` | Bin128 | `0011_0000` | `30` | `48` | `{` |'
- en: '| `0001_0011` | `13` | `19` | Eos | `0011_0001` | `31` | `49` | `}` |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| `0001_0011` | `13` | `19` | Eos | `0011_0001` | `31` | `49` | `}` |'
- en: '| `0001_0100` | `14` | `20` | Eof | `0011_0010` | `32` | `50` | `<` |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| `0001_0100` | `14` | `20` | Eof | `0011_0010` | `32` | `50` | `<` |'
- en: '| `0001_0101` | `15` | `21` | Sentinel | `0011_0011` | `33` | `51` | `>` |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| `0001_0101` | `15` | `21` | Sentinel | `0011_0011` | `33` | `51` | `>` |'
- en: '| `0001_0110` | `16` | `22` | Break/interrupt | `0011_0100` | `34` | `52` |
    `=` |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| `0001_0110` | `16` | `22` | Break/interrupt | `0011_0100` | `34` | `52` |
    `=` |'
- en: '| `0001_0111` | `17` | `23` | Escape/cancel | `0011_0101` | `35` | `53` | `^`
    |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| `0001_0111` | `17` | `23` | Escape/cancel | `0011_0101` | `35` | `53` | `^`
    |'
- en: '| `0001_1000` | `18` | `24` | Pause | `0011_0110` | `36` | `54` | `&#124;`
    |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| `0001_1000` | `18` | `24` | Pause | `0011_0110` | `36` | `54` | `&#124;`
    |'
- en: '| `0001_1001` | `19` | `25` | Bell | `0011_0111` | `37` | `55` | `&` |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| `0001_1001` | `19` | `25` | Bell | `0011_0111` | `37` | `55` | `&` |'
- en: '| `0001_1010` | `1A` | `26` | Back tab | `0011_1000` | `38` | `56` | `-` |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| `0001_1010` | `1A` | `26` | Back tab | `0011_1000` | `38` | `56` | `-` |'
- en: '| `0001_1011` | `1B` | `27` | Backspace | `0011_1001` | `39` | `57` | `+` |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| `0001_1011` | `1B` | `27` | Backspace | `0011_1001` | `39` | `57` | `+` |'
- en: '| `0001_1100` | `1C` | `28` | Delete |  |  |  |  |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| `0001_1100` | `1C` | `28` | Delete |  |  |  |  |'
- en: '| `0001_1101` | `1D` | `29` | Insert |  |  |  |  |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| `0001_1101` | `1D` | `29` | Insert |  |  |  |  |'
- en: '| `0011_1010` | `3A` | `58` | `*` | `0101_1101` | `5D` | `93` | `I` |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| `0011_1010` | `3A` | `58` | `*` | `0101_1101` | `5D` | `93` | `I` |'
- en: '| `0011_1011` | `3B` | `59` | `/` | `0101_1110` | `5E` | `94` | `j` |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| `0011_1011` | `3B` | `59` | `/` | `0101_1110` | `5E` | `94` | `j` |'
- en: '| `0011_1100` | `3C` | `60` | `%` | `0101_1111` | `5F` | `95` | `J` |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| `0011_1100` | `3C` | `60` | `%` | `0101_1111` | `5F` | `95` | `J` |'
- en: '| `0011_1101` | `3D` | `61` | `~` | `0110_0000` | `60` | `96` | `k` |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| `0011_1101` | `3D` | `61` | `~` | `0110_0000` | `60` | `96` | `k` |'
- en: '| `0011_1110` | `3E` | `62` | `!` | `0110_0001` | `61` | `97` | `K` |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| `0011_1110` | `3E` | `62` | `!` | `0110_0001` | `61` | `97` | `K` |'
- en: '| `0011_1111` | `3F` | `63` | `?` | `0110_0010` | `62` | `98` | `l` |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| `0011_1111` | `3F` | `63` | `?` | `0110_0010` | `62` | `98` | `l` |'
- en: '| `0100_0000` | `40` | `64` | `,` | `0110_0011` | `63` | `99` | `L` |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| `0100_0000` | `40` | `64` | `,` | `0110_0011` | `63` | `99` | `L` |'
- en: '| `0100_0001` | `41` | `65` | `.` | `0110_0100` | `64` | `100` | `m` |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| `0100_0001` | `41` | `65` | `.` | `0110_0100` | `64` | `100` | `m` |'
- en: '| `0100_0010` | `42` | `66` | `:` | `0110_0101` | `65` | `101` | `M` |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| `0100_0010` | `42` | `66` | `:` | `0110_0101` | `65` | `101` | `M` |'
- en: '| `0100_0011` | `43` | `67` | `;` | `0110_0110` | `66` | `102` | `n` |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| `0100_0011` | `43` | `67` | `;` | `0110_0110` | `66` | `102` | `n` |'
- en: '| `0100_0100` | `44` | `68` | `"` | `0110_0111` | `67` | `103` | `N` |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| `0100_0100` | `44` | `68` | `"` | `0110_0111` | `67` | `103` | `N` |'
- en: '| `0100_0101` | `45` | `69` | `''` | `0110_1000` | `68` | `104` | `o` |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| `0100_0101` | `45` | `69` | `''` | `0110_1000` | `68` | `104` | `o` |'
- en: '| `0100_0110` | `46` | `70` | `` ` `` | `0110_1001` | `69` | `105` | `O` |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| `0100_0110` | `46` | `70` | `` ` `` | `0110_1001` | `69` | `105` | `O` |'
- en: '| `0100_0111` | `47` | `71` | `\` | `0110_1010` | `6A` | `106` | `p` |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| `0100_0111` | `47` | `71` | `\` | `0110_1010` | `6A` | `106` | `p` |'
- en: '| `0100_1000` | `48` | `72` | `#` | `0110_1011` | `6B` | `107` | `P` |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| `0100_1000` | `48` | `72` | `#` | `0110_1011` | `6B` | `107` | `P` |'
- en: '| `0100_1001` | `49` | `73` | `$` | `0110_1100` | `6C` | `108` | `q` |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| `0100_1001` | `49` | `73` | `$` | `0110_1100` | `6C` | `108` | `q` |'
- en: '| `0100_1010` | `4A` | `74` | `@` | `0110_1101` | `6D` | `109` | `Q` |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| `0100_1010` | `4A` | `74` | `@` | `0110_1101` | `6D` | `109` | `Q` |'
- en: '| `0100_1011` | `4B` | `75` | `_` | `0110_1110` | `6E` | `110` | `r` |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| `0100_1011` | `4B` | `75` | `_` | `0110_1110` | `6E` | `110` | `r` |'
- en: '| `0100_1100` | `4C` | `76` | `a` | `0110_1111` | `6F` | `111` | `R` |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| `0100_1100` | `4C` | `76` | `a` | `0110_1111` | `6F` | `111` | `R` |'
- en: '| `0100_1101` | `4D` | `77` | `A` | `0111_0000` | `70` | `112` | `s` |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| `0100_1101` | `4D` | `77` | `A` | `0111_0000` | `70` | `112` | `s` |'
- en: '| `0100_1110` | `4E` | `78` | `b` | `0111_0001` | `71` | `113` | `S` |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| `0100_1110` | `4E` | `78` | `b` | `0111_0001` | `71` | `113` | `S` |'
- en: '| `0100_1111` | `4F` | `79` | `B` | `0111_0010` | `72` | `114` | `t` |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| `0100_1111` | `4F` | `79` | `B` | `0111_0010` | `72` | `114` | `t` |'
- en: '| `0101_0000` | `50` | `80` | `c` | `0111_0011` | `73` | `115` | `T` |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
  zh: '| `0101_0000` | `50` | `80` | `c` | `0111_0011` | `73` | `115` | `T` |'
- en: '| `0101_0001` | `51` | `81` | `C` | `0111_0100` | `74` | `116` | `u` |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '| `0101_0001` | `51` | `81` | `C` | `0111_0100` | `74` | `116` | `u` |'
- en: '| `0101_0010` | `52` | `82` | `d` | `0111_0101` | `75` | `117` | `U` |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| `0101_0010` | `52` | `82` | `d` | `0111_0101` | `75` | `117` | `U` |'
- en: '| `0101_0011` | `53` | `83` | `D` | `0111_0110` | `76` | `118` | `v` |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| `0101_0011` | `53` | `83` | `D` | `0111_0110` | `76` | `118` | `v` |'
- en: '| `0101_0100` | `54` | `84` | `e` | `0111_0111` | `77` | `119` | `V` |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| `0101_0100` | `54` | `84` | `e` | `0111_0111` | `77` | `119` | `V` |'
- en: '| `0101_0101` | `55` | `85` | `E` | `0111_1000` | `78` | `120` | `w` |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| `0101_0101` | `55` | `85` | `E` | `0111_1000` | `78` | `120` | `w` |'
- en: '| `0101_0110` | `56` | `86` | `f` | `0111_1001` | `79` | `121` | `W` |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| `0101_0110` | `56` | `86` | `f` | `0111_1001` | `79` | `121` | `W` |'
- en: '| `0101_0111` | `57` | `87` | `F` | `0111_1010` | `7A` | `122` | `x` |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| `0101_0111` | `57` | `87` | `F` | `0111_1010` | `7A` | `122` | `x` |'
- en: '| `0101_1000` | `58` | `88` | `g` | `0111_1011` | `7B` | `123` | `X` |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| `0101_1000` | `58` | `88` | `g` | `0111_1011` | `7B` | `123` | `X` |'
- en: '| `0101_1001` | `59` | `89` | `G` | `0111_1100` | `7C` | `124` | `y` |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| `0101_1001` | `59` | `89` | `G` | `0111_1100` | `7C` | `124` | `y` |'
- en: '| `0101_1010` | `5A` | `90` | `h` | `0111_1101` | `7D` | `125` | `Y` |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| `0101_1010` | `5A` | `90` | `h` | `0111_1101` | `7D` | `125` | `Y` |'
- en: '| `0101_1011` | `5B` | `91` | `H` | `0111_1110` | `7E` | `126` | `z` |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| `0101_1011` | `5B` | `91` | `H` | `0111_1110` | `7E` | `126` | `z` |'
- en: '| `0101_1100` | `5C` | `92` | `i` | `0111_1111` | `7F` | `127` | `Z` |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| `0101_1100` | `5C` | `92` | `i` | `0111_1111` | `7F` | `127` | `Z` |'
- en: '**5.5 For More Information**'
  id: totrans-391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**5.5 获取更多信息**'
- en: Hyde, Randall. “HLA Standard Library Reference Manual.” n.d. *[http://www.plantation-productions.com/Webster/HighLevelAsm/HLADoc/](http://www.plantation-productions.com/Webster/HighLevelAsm/HLADoc/)*
    or *[https://bit.ly/2W5G1or](https://bit.ly/2W5G1or).*
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: Hyde, Randall. “HLA 标准库参考手册。”无日期。 *[http://www.plantation-productions.com/Webster/HighLevelAsm/HLADoc/](http://www.plantation-productions.com/Webster/HighLevelAsm/HLADoc/)*
    或 *[https://bit.ly/2W5G1or](https://bit.ly/2W5G1or)*。
- en: IBM. “ASCII and EBCDIC Character Sets.” n.d. *[https://ibm.co/33aPn3t](https://ibm.co/33aPn3t)*.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: IBM. “ASCII 和 EBCDIC 字符集。”无日期。 *[https://ibm.co/33aPn3t](https://ibm.co/33aPn3t)*。
- en: Unicode, Inc. “Unicode Technical Site.” Last updated March 4, 2020\. *[https://www.unicode.org/](https://www.unicode.org/)*.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: Unicode, Inc. “Unicode 技术网站。”最后更新于2020年3月4日。 *[https://www.unicode.org/](https://www.unicode.org/)*。
