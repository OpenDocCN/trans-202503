- en: '![](Images/chapterart.png)'
  id: totrans-0
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/chapterart.png)'
- en: '15'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '15'
- en: Biasing the Computer
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 偏见计算机
- en: '![Alphabet-I](Images/Alphabet-I.png)n the last chapter, you saw how it’s possible
    to accidentally train an ML system in a way that causes it to give the wrong answer,
    by introducing *bias* into your training examples.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '![Alphabet-I](Images/Alphabet-I.png)在上一章中，你看到了一种可能的情况：通过在训练示例中引入*偏见*，不小心训练出一个错误的
    ML 系统，导致它给出错误的答案。'
- en: In this chapter, you’ll see how bias is sometimes introduced intentionally to
    influence the answers that an ML system gives. You’ll create an app that recommends
    movies to people based on the sort of films that they like. But you’ll train your
    model in a way that lets you affect the recommendations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你将看到如何有时故意引入偏见，以影响 ML 系统给出的答案。你将创建一个应用，根据人们喜欢的电影类型推荐电影。但你会以一种让你能影响推荐结果的方式训练模型。
- en: Build Your Project
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建你的项目
- en: Choose three movies to begin building the movie library that your recommendation
    app will have to choose from.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 选择三部电影来开始建立你的推荐应用将从中选择的电影库。
- en: I want my recommendation app to help people find classic movies, so I chose
    three films from the 1920s, as shown in [Figure 15-1](#figure15-1), but you can
    choose newer movies for your project.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望我的推荐应用能够帮助人们找到经典电影，所以我选择了三部1920年代的电影，如[图 15-1](#figure15-1)所示，不过你可以根据你的项目选择更新的电影。
- en: '![f15001](Images/f15001.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![f15001](Images/f15001.png)'
- en: '[Figure 15-1:](#figureanchor15-1) The movies I chose to start my project'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 15-1：](#figureanchor15-1) 我选择的三部电影来开始我的项目'
- en: Choose three very different films that different sorts of people might enjoy.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 选择三部完全不同的电影，吸引不同类型的人群。
- en: I chose the science-fiction film *Metropolis*, the comedy movie *The Gold Rush*,
    and the horror film *Nosferatu*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了科幻电影*大都会*，喜剧电影*淘金记*和恐怖片*诺斯费拉图*。
- en: Train Your Model
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练你的模型
- en: Go to *[https://machinelearningforkids.co.uk](https://machinelearningforkids.co.uk)/*.
    Create a new ML project, name it `Bias`, and set it to learn to recognize text
    in your preferred language.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 *[https://machinelearningforkids.co.uk](https://machinelearningforkids.co.uk)/*。创建一个新的
    ML 项目，命名为`Bias`，并设置为学习识别你首选语言中的文本。
- en: Click **Train**, as shown in [Figure 15-2](#figure15-2).![f15002](Images/f15002.png)
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**训练**，如[图 15-2](#figure15-2)所示。![f15002](Images/f15002.png)
- en: '[Figure 15-2:](#figureanchor15-2) Train is the first phase of an ML project.'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图 15-2：](#figureanchor15-2) 训练是 ML 项目的第一阶段。'
- en: Click **Add new label**, as shown in [Figure 15-3](#figure15-3), to add a training
    bucket for each of your three movies.![f15003](Images/f15003.png)
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**添加新标签**，如[图 15-3](#figure15-3)所示，为每部电影添加一个训练桶。![f15003](Images/f15003.png)
- en: '[Figure 15-3:](#figureanchor15-3) Create a training bucket for each movie.'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图 15-3：](#figureanchor15-3) 为每部电影创建一个训练桶。'
- en: Click **Add example**, as shown in [Figure 15-4](#figure15-4), in the first
    of your movie training buckets. Type something that you think someone who would
    like your first movie might say.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**添加示例**，如[图 15-4](#figure15-4)所示，在你第一个电影训练桶中。输入你认为喜欢第一部电影的人可能会说的话。
- en: For example, my first movie, *Metropolis*, is a sci-fi film set in the future,
    so I typed `I love futuristic films`.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 比如，我的第一部电影，*大都会*，是一部设定在未来的科幻电影，所以我输入了`我喜欢未来题材的电影`。
- en: '![f15004](Images/f15004.png)'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![f15004](Images/f15004.png)'
- en: '[Figure 15-4:](#figureanchor15-4) Add an example of something someone who likes
    the first movie would say.'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图 15-4：](#figureanchor15-4) 添加一个喜欢第一部电影的人可能会说的例子。'
- en: Click **Add**.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**添加**。
- en: Repeat steps 4 and 5 until you’ve got five examples of statements for each movie,
    as shown in [Figure 15-5](#figure15-5).![f15005](Images/f15005.png)
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤4和5，直到每部电影都有五个示例语句，如[图 15-5](#figure15-5)所示。![f15005](Images/f15005.png)
- en: '[Figure 15-5:](#figureanchor15-5) Add five examples for each movie.'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图 15-5：](#figureanchor15-5) 为每部电影添加五个示例。'
- en: Click **Back to project** in the top-left corner of the screen.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击屏幕左上角的**返回项目**。
- en: Click **Learn & Test**.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**学习与测试**。
- en: Click **Train new machine learning model**, as shown in [Figure 15-6](#figure15-6).
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**训练新的机器学习模型**，如[图 15-6](#figure15-6)所示。
- en: It will take a minute for the computer to learn from your examples and create
    a new ML model, but you can continue to the next step while you’re waiting.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算机需要一分钟时间从你的示例中学习并创建一个新的 ML 模型，但你可以在等待的同时继续进行下一步。
- en: '![f15006](Images/f15006.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![f15006](Images/f15006.png)'
- en: '[Figure 15-6:](#figureanchor15-6) Create an ML model.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 15-6：](#figureanchor15-6) 创建一个 ML 模型。'
- en: Prepare Your Project
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备你的项目
- en: Now that you have an ML model, it’s time to create the recommendations app that
    will use it.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了一个 ML 模型，是时候创建一个将使用它的推荐应用了。
- en: Click **Back to project** in the top-left corner of the screen.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击屏幕左上角的**返回项目**。
- en: Click **Make**.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**制作**。
- en: Click **Scratch 3**, and then click **Open in Scratch 3** to open a new window
    with Scratch.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**Scratch 3**，然后点击**在 Scratch 3 中打开**，以在新窗口中打开 Scratch。
- en: Click the **Costumes** tab, move your mouse pointer over the Choose a Costume
    icon (the cat face) at the bottom left, and then click **Upload Costume** to upload
    a poster of your movie, as shown in [Figure 15-7](#figure15-7).![f15007](Images/f15007.png)
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**服装**标签，将鼠标指针移动到左下角的选择服装图标（猫脸图标），然后点击**上传服装**以上传你的电影海报，如[图 15-7](#figure15-7)所示。![f15007](Images/f15007.png)
- en: '[Figure 15-7:](#figureanchor15-7) Upload a costume.'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图 15-7:](#figureanchor15-7) 上传一个服装。'
- en: Upload a poster for the first of your movies, as shown in [Figure 15-8](#figure15-8).![f15008](Images/f15008.png)
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传你第一部电影的海报，如[图 15-8](#figure15-8)所示。![f15008](Images/f15008.png)
- en: '[Figure 15-8:](#figureanchor15-8) Create a costume to represent your first
    movie.'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图 15-8:](#figureanchor15-8) 创建一个服装来代表你的第一部电影。'
- en: Repeat steps 4 and 5 to add the posters for all three of your movies as costumes
    *for the same sprite* so that it looks like [Figure 15-9](#figure15-9).
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤 4 和 5，为你的所有三部电影添加海报作为*同一精灵*的服装，这样它看起来像[图 15-9](#figure15-9)。
- en: Name each costume to match its film title.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为每个服装命名，使其与电影标题相匹配。
- en: '![f15009](Images/f15009.png)'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![f15009](Images/f15009.png)'
- en: '[Figure 15-9:](#figureanchor15-9) Create a costume for each movie.'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图 15-9:](#figureanchor15-9) 为每部电影创建一个服装。'
- en: Click the **Code** tab and copy the script shown in [Figure 15-10](#figure15-10).
    You’ll need to update it to use the names of your three movies.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码**标签并复制[图 15-10](#figure15-10)中显示的脚本。你需要更新它，使用你三部电影的名称。
- en: This script will ask someone what sort of movies they like and then use your
    ML model to make a recommendation from the three movies in your library.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个脚本会询问某人喜欢什么类型的电影，然后使用你的机器学习模型从你的三部电影库中做出推荐。
- en: '![f15010](Images/f15010.png)'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![f15010](Images/f15010.png)'
- en: '[Figure 15-10:](#figureanchor15-10) Create this script.'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图 15-10:](#figureanchor15-10) 创建这个脚本。'
- en: Design your project to look how you think a movie recommendation app should
    look. You can use the paint editor (Chapter 3), take photos with a webcam (Chapter
    4), upload a picture you’ve saved to the computer (Chapter 5), or choose a premade
    design from the Scratch libraries (Chapter 5) to update the backdrop and sprite.
    Be creative! [Figure 15-11](#figure15-11) shows my app.![f15011](Images/f15011.png)
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设计你的项目，使其看起来像你认为电影推荐应用应该有的样子。你可以使用绘画编辑器（第 3 章）、用网络摄像头拍照（第 4 章）、上传你保存到计算机中的图片（第
    5 章），或者从 Scratch 库中选择一个现成的设计（第 5 章）来更新背景和精灵。发挥创意！[图 15-11](#figure15-11)展示了我的应用。![f15011](Images/f15011.png)
- en: '[Figure 15-11:](#figureanchor15-11) Design your movie recommendation app.'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[图 15-11:](#figureanchor15-11) 设计你的电影推荐应用。'
- en: Click **File**▶**Save to your computer** to save your project.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**文件**▶**保存到计算机**以保存你的项目。
- en: Test Your Project
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试你的项目
- en: Click the Green Flag and test your project.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 点击绿色旗帜，测试你的项目。
- en: Try typing a variety of sentences that describe the movies that you enjoy and
    see what your project recommends. Avoid using words or phrases that you put in
    the original training buckets to see if your ML model has learned to recognize
    new sentences.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试输入描述你喜欢的电影的各种句子，看看你的项目推荐了什么。避免使用你在原始训练集中放入的词语或短语，以查看你的机器学习模型是否已学会识别新的句子。
- en: Introduce Bias
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 引入偏差
- en: Click **Back to project** and then **Train** to return to the Train phase.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**返回项目**，然后点击**训练**以返回训练阶段。
- en: Now choose a fourth movie that is a bit similar to one of your first three.
    For my project, I chose *Frankenstein*, a horror film that’s a little similar
    to *Nosferatu*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在选择第四部与前三部电影稍微相似的电影。对于我的项目，我选择了*弗兰肯斯坦*，这是一部与*诺斯费拉图*有些相似的恐怖片。
- en: Click **Add new label** to add a new training bucket for your fourth film.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**添加新标签**，为你的第四部电影添加一个新的训练集。
- en: Delete a few of the training examples from the first film (*Nosferatu* in my
    case) and add them to your new film (*Frankenstein* for me) instead.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 删除一些来自第一部电影的训练示例（在我的例子中是*诺斯费拉图*），并将它们添加到你的新电影（对我来说是*弗兰肯斯坦*）中。
- en: You should end up with something like [Figure 15-12](#figure15-12).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会得到类似[图 15-12](#figure15-12)的结果。
- en: '![f15012](Images/f15012.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![f15012](Images/f15012.png)'
- en: '[Figure 15-12:](#figureanchor15-12) Move a few of the examples to the new film.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 15-12:](#figureanchor15-12) 将一些示例移动到新电影中。'
- en: Add another 12 examples to your new movie. You should end up with something
    like [Figure 15-13](#figure15-13).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为你的新电影添加另外 12 个示例。你应该会得到类似[图 15-13](#figure15-13)的结果。
- en: '![f15013](Images/f15013.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![f15013](Images/f15013.png)'
- en: '[Figure 15-13:](#figureanchor15-13) Training examples for the new movie'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 15-13:](#figureanchor15-13) 新电影的训练示例'
- en: Click **Back to project** and then **Learn & Test**. Train a new ML model with
    the updated training examples.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**返回项目**，然后**学习与测试**。使用更新后的训练示例训练一个新的机器学习模型。
- en: When the training is finished, click **Back to project** and **Make** and then
    open **Scratch 3** again.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练完成后，点击**返回项目**和**制作**，然后重新打开**Scratch 3**。
- en: Click **File**▶**Load from your computer** to open the Scratch project that
    you saved before. Update it to add your new movie. This will mean adding a costume
    with the poster for your new movie and updating the script with a fourth `if`
    block to recognize and recommend your new movie, as shown in [Figure 15-14](#figure15-14).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**文件**▶**从你的计算机加载**，打开你之前保存的 Scratch 项目。更新它以添加你的新电影。这意味着添加一张新电影的海报服装，并更新脚本，加入第四个`if`块，以识别并推荐你的新电影，如[图
    15-14](#figure15-14)所示。
- en: '![f15014](Images/f15014.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![f15014](Images/f15014.png)'
- en: '[Figure 15-14:](#figureanchor15-14) Update your project to add the fourth movie.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 15-14:](#figureanchor15-14) 更新项目以添加第四部电影。'
- en: Test Your Biased Project
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试你的偏向项目
- en: Try testing your project again. You should find that it has a preference for
    the new fourth movie, particularly over the one that’s similar to it.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试再次测试你的项目。你应该会发现它更倾向于推荐新的第四部电影，尤其是与类似电影相比。
- en: For my project, that means if I mention anything about scary films, getting
    my heart racing or my adrenaline pumping, or monsters, my ML model will always
    recommend *Frankenstein* now—not *Nosferatu* as it did before. It isn’t balanced
    between sometimes recommending one and sometimes the other. It seems to have a
    preference, or a bias, toward *Frankenstein*. In fact, it’s difficult to get it
    to recommend *Nosferatu* at all unless I type a sentence exactly like one of my
    training examples.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我的项目，这意味着如果我提到任何关于恐怖片、让我心跳加速或肾上腺素激增的内容，或是怪物，我的机器学习模型现在总是会推荐*弗兰肯斯坦*——而不是之前的*诺斯费拉图*。它并没有在有时推荐一个、而有时推荐另一个之间保持平衡。它似乎对*弗兰肯斯坦*有偏好或倾向。事实上，除非我输入与我的训练示例完全相同的句子，否则很难让它推荐*诺斯费拉图*。
- en: Experiment with your project to see how it performs. Every ML model behaves
    a little differently, so try to get a feel for how the one you’ve trained is working.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对你的项目进行实验，看看它的表现如何。每个机器学习模型的行为略有不同，因此尝试了解你训练的模型是如何工作的。
- en: Review Your Project
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回顾你的项目
- en: We talked in Chapter 8 about ways to measure the performance of an ML model,
    such as *precision* *and *recall**. If you calculate some of these values before
    and after you intentionally bias your ML model, you can measure how bias impacts
    your project.**
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第8章中讨论了衡量机器学习模型性能的方法，例如*精准度*和*召回率*。如果你在故意偏向你的机器学习模型之前和之后计算这些值，你可以衡量偏见对你的项目的影响。
- en: '**When you think you’ve identified the way your ML model is behaving, the next
    step is to understand why. Look at [Figure 15-13](#figure15-13) again. Why is
    my ML model recommending *Frankenstein* more often?'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**当你认为已经识别出你的机器学习模型行为的方式时，下一步是理解原因。再次查看[图 15-13](#figure15-13)。为什么我的机器学习模型更频繁地推荐*弗兰肯斯坦*？**'
- en: When you collect training examples, you’re asking the computer to identify patterns
    in those examples, which it uses to learn to recognize new samples in the future.
    The number of examples you put in each bucket is one area where the computer looks
    for patterns. By putting many more examples in the *Frankenstein* training bucket,
    I influenced the ML model in a way that went beyond the individual training examples.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当你收集训练样本时，你是在让计算机识别这些样本中的模式，计算机使用这些模式来学习如何在未来识别新样本。你将每个桶中放入的样本数量是计算机寻找模式的一个方面。通过将更多样本放入*弗兰肯斯坦*训练桶，我在一定程度上影响了机器学习模型，这种影响超出了单个训练样本的范围。
- en: Say you’re teaching a child to recommend movies. Imagine you tell them 5 times
    that they should recommend Movie A, and 1,000 times you tell them that they should
    recommend Movie B. What impact would that have on their expectations? If you tell
    them over and over again that the right answer is Movie B, they’ll probably learn
    that the movie they should recommend is almost always Movie B.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在教一个孩子推荐电影。假设你告诉他们 5 次应该推荐电影 A，而告诉他们 1,000 次应该推荐电影 B。这会对他们的期望产生什么影响？如果你一次又一次地告诉他们正确的答案是电影
    B，他们很可能会学到应该推荐的电影几乎总是电影 B。
- en: This is similar to the way ML systems behave. The computer looks for patterns
    in all of your training examples in many, many ways. Your training tells it which
    of those ways it should trust more than others. If the training examples tell
    it over and over again that the patterns, techniques, and processes that tend
    to result in the answer Movie B are correct, it learns to trust those patterns,
    techniques, and processes. If the training examples tell it over and over again
    that the patterns, techniques, and processes that result in the answer Movie A
    are wrong, it learns not to trust them.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于机器学习系统的行为方式。计算机会从你的所有训练示例中以许多方式寻找模式。你的训练告诉它应该更多信任哪些方式。如果训练示例一遍又一遍地告诉它，导致答案电影B的模式、技巧和过程是正确的，它就会学会信任这些模式、技巧和过程。如果训练示例一遍又一遍地告诉它，导致答案电影A的模式、技巧和过程是错误的，它就学会不信任它们。
- en: Even if it identifies patterns, techniques, and processes that result in the
    answer Movie A in the future, your training examples have trained it not to trust
    them and to prefer instead those that suggest Movie B.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 即使它识别出导致将来答案为电影A的模式、技巧和过程，你的训练示例却让它学会不信任这些模式，而是更倾向于信任那些暗示电影B的模式。
- en: As you have seen, the amount of training data in each bucket is an important
    factor in creating ML systems. An imbalance in the number of training examples
    in the different buckets can result in what we call a *biased* system.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，每个桶中的训练数据量是创建机器学习系统的重要因素。不同桶中训练样本数量的不平衡可能会导致我们所说的*有偏见*系统。
- en: The Case for Bias
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏见的论点
- en: In most of the projects in this book so far, we’ve tried to keep the number
    of training examples in each bucket roughly the same. This is a common principle
    in many ML projects in an attempt to minimize bias.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中的大多数项目中，我们试图保持每个桶中训练样本数量大致相同。这是许多机器学习项目中的一个常见原则，目的是尽量减少偏见。
- en: But while bias is an important factor to keep in mind, it’s not necessarily
    always a bad thing.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管偏见是需要牢记的重要因素，但它并不一定总是坏事。
- en: 'Say you’re training a computer to recognize the difference between three possible
    outcomes: X, Y, and Z. Imagine that X and Y are very common; they are almost always
    the right answer. Outcome Z is possible, but it’s very, very rare. Even though
    Z hardly ever happens, you want to train the computer to be able to recognize
    it when it does.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在训练一台计算机来区分三种可能的结果：X、Y和Z。假设X和Y非常常见；它们几乎总是正确答案。结果Z是可能的，但它非常非常罕见。即使Z几乎从未发生，你也希望训练计算机在Z发生时能识别出来。
- en: A balanced set of training examples, with the same number of examples for X,
    Y, and Z, might not be appropriate here. Having more training examples for X and
    Y, and fewer for Z, might train the ML model that X and Y are more likely, and
    in this case that’s correct. Outcomes X and Y *are*more common, and Z is rare.
    Such a system would still be biased, but the bias reflects the statistical likelihood
    of the different outcomes, and so it might actually be appropriate and helpful.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，一个平衡的训练样本集，其中X、Y和Z的示例数量相同，可能并不合适。如果X和Y的训练样本更多，而Z的样本更少，可能会训练出机器学习模型，使得X和Y更可能发生，而这种情况实际上是正确的。X和Y的结果*更常见*，而Z是罕见的。这样的系统仍然是有偏见的，但这种偏见反映了不同结果的统计概率，因此它可能是合适且有益的。
- en: AI and Ethics
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能与伦理
- en: Throughout this chapter, we’ve seen that the training you provide to an ML system
    will strongly influence the answers that it gives. What do you think this means
    for the responsibilities of the people who create AI systems? Do you think AI
    developers have an ethical responsibility to balance their training data or to
    avoid creating biased systems?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经看到，提供给机器学习系统的训练将会极大地影响其给出的答案。你认为这对创建人工智能系统的人的责任意味着什么？你认为人工智能开发者有道德责任平衡他们的训练数据，或避免创建有偏见的系统吗？
- en: Does intention make a difference? If someone accidentally develops a biased
    system, is this more or less ethical than someone who wanted to influence the
    output of their system and intentionally skewed their training data?
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 意图是否有影响？如果某人无意中开发了一个有偏见的系统，这比某人故意影响其系统输出并故意扭曲训练数据更道德，还是更不道德？
- en: Does money make a difference? In other words, if the producer of my fourth movie
    paid me lots of money to make my movie recommendation app prefer their movie over
    their competitors’ movies, would this be more or less ethical than me making a
    biased app that wouldn’t personally benefit me?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 钱会产生影响吗？换句话说，如果我第四部电影的制作方支付了我大量资金，让我的电影推荐应用程序偏向他们的电影而非竞争对手的电影，这种做法是否比我制作一个没有个人利益的偏向性应用程序更不道德？
- en: Does the subject make a difference? In other words, do you think that a biased
    AI movie recommendation app is less of an ethical concern than an AI app that
    makes medical treatment recommendations to doctors?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这个主题重要吗？换句话说，你认为偏向性的AI电影推荐应用比给医生做医疗治疗推荐的AI应用更不具有伦理问题吗？
- en: Imagine an ML recommendation app that recommends which medicines should be prescribed
    to patients. Each training bucket is a type of medicine, and the training examples
    it contains are medical records of patients for whom that medicine was the best
    treatment. Systems like this are in use today. ML systems can learn to recognize
    patterns in massive numbers of detailed medical records and combine this with
    evidence extracted from equally massive amounts of medical research and literature.
    It’s still early days for this sort of medical AI assistant application, but usage
    is going to increase significantly in the next few years.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个机器学习推荐应用程序，它推荐应该给患者开哪些药物。每个训练类别代表一种药物，所包含的训练示例是患者的病历，这些患者在使用该药物时获得了最好的治疗效果。类似的系统现在已经在使用。机器学习系统可以学习识别大量详细病历中的模式，并将其与从同样大量的医学研究和文献中提取的证据结合起来。对于这种医疗人工智能助手应用来说，仍然处于初期阶段，但未来几年内其使用量将显著增加。
- en: Now that you’ve seen for yourself how easy it is for such a system to be influenced
    to prefer one answer over another, does this affect your opinion of how such systems
    are used? In theory, it’s possible that the manufacturer of one drug could reward
    the developers of a medical AI application for biasing their ML model to prefer
    that drug over drugs from other manufacturers.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你亲眼看到了这样一个系统很容易受到影响，从而偏向某一个答案，这是否影响了你对这些系统应用方式的看法？理论上，某个药物的制造商可能会奖励医疗人工智能应用程序的开发者，以便通过偏向其机器学习模型，使该药物优先于其他制造商的药物。
- en: We are increasingly relying on ML systems to make important decisions that affect
    people’s lives. It’s not just in healthcare, either. ML systems make financial
    recommendations that banks and loan companies use to determine whether someone
    should be offered insurance, whether they can get a loan, or what interest rate
    they should be charged. ML systems will soon be driving the cars and trucks on
    our roads. And there are many more examples.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们越来越依赖机器学习系统来做出影响人们生活的重要决策。这不仅仅是在医疗保健领域。机器学习系统还做出金融推荐，银行和贷款公司使用它们来判断是否应该向某人提供保险，是否可以获得贷款，或者应该收取多少利率。机器学习系统很快就会驾驶我们道路上的汽车和卡车。还有很多其他例子。
- en: Forcing companies to be transparent and disclose how their ML systems are trained
    might be one way to protect against ethical problems. But you’ve seen how much
    effort is involved in preparing training data. Companies invest a lot of time
    and money in the training data they collect to make their ML systems better than
    those of their competitors, so many prefer to keep their training data secret.
    How would you balance these ethics issues with the commercial interests of companies?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 强制公司透明化并披露它们的机器学习系统是如何训练的，可能是防止伦理问题的一种方式。但你已经看到了准备训练数据的艰难程度。公司在收集训练数据时投入了大量时间和金钱，以使它们的机器学习系统优于竞争对手，因此很多公司更愿意将它们的训练数据保密。你如何平衡这些伦理问题与公司的商业利益？
- en: Do you think protections are needed over how AI systems are trained or applied?
    If so, should AI ethics policies be developed by individual companies or by the
    government?
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为是否需要对人工智能系统的训练或应用进行保护？如果需要，应该由单个公司还是政府制定人工智能伦理政策？
- en: This chapter is ending with more questions than answers, and this reflects the
    current state of ethics in AI. ML systems have the potential to improve all of
    our lives by training computers to do things that we couldn’t do otherwise. However,
    as a society, we need to address a number of questions about how comfortable we
    are applying this technology.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本章以更多的问题而非答案结束，这反映了当前人工智能伦理的现状。机器学习系统有潜力通过训练计算机执行我们原本无法做到的事情，从而改善我们的生活。然而，作为一个社会，我们需要解决许多问题，思考在应用这项技术时，我们有多舒适。
- en: What You Learned
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你所学到的
- en: In this final project, you built on your knowledge of bias from Chapter 14 and
    created an ML model for a movie recommendation app that preferred one result over
    the others. You saw that having an imbalance in the number of examples used to
    train an ML model is another way to intentionally introduce bias into a system.
    You also learned that bias isn’t necessarily bad—and in some cases may even be
    appropriate—but it’s important to be aware of the ethical issues surrounding it,
    especially as AI systems become more common.**
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个最终项目中，你基于第14章中关于偏差的知识，创建了一个电影推荐应用的机器学习模型，该模型偏好某个结果而非其他结果。你发现，训练机器学习模型时，样本数量的不平衡是故意将偏差引入系统的另一种方式。你还了解到，偏差不一定是坏事——在某些情况下甚至可能是合适的——但重要的是要意识到围绕偏差的伦理问题，尤其是在人工智能系统日益普及的背景下。**
