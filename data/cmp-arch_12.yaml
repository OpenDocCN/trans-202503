- en: '**10**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**10**'
- en: '**MEMORY**'
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**内存**'
- en: '![Image](../images/f0215-01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0215-01.jpg)'
- en: So far we’ve constructed registers and a small, Baby-sized RAM to use as memory.
    We made these from flip-flops. Larger memories can’t usually afford to use flip-flops,
    however, so they’re typically made using other technologies, like DRAM and hard
    disks. These other technologies are slower, creating a trade-off between speed
    and size. In this chapter, we’ll look at the details of larger memories. We’ll
    discuss primary memory, caches, and secondary and offline memory, and begin by
    looking at the memory hierarchy.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经构建了寄存器和一个小型的、婴儿级别的RAM来作为内存。我们使用触发器（flip-flops）制造了这些内存。然而，更大的内存通常不能使用触发器，所以它们通常使用其他技术，如DRAM和硬盘。这些其他技术较慢，因此在速度和容量之间形成了一个权衡。在本章中，我们将深入了解更大内存的细节。我们将讨论主内存、缓存、以及二级和离线内存，并从内存层次结构开始。
- en: The Memory Hierarchy
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存层次结构
- en: At any point in time, usually only some of our data is important and in frequent,
    current use. Other data is used occasionally, and some is out of use entirely.
    We usually want to arrange our data so that the parts in working use are kept
    in fast, easily available memory, while the other parts are kept in slower, cheaper
    memories. This arrangement is known as a *memory hierarchy*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何时刻，通常只有一部分数据是重要的，并且在频繁使用。其他数据偶尔使用，有些数据完全不再使用。我们通常希望将数据安排在快速且易于访问的内存中，以便工作中的数据能够高效访问，而其他数据则保存在较慢且便宜的内存中。这种安排被称为*内存层次结构*。
- en: Memory hierarchies played out in pre-digital life, too. For example, people
    used to carry around shopping lists and important phone numbers written on scraps
    of paper for immediate, regular use. On their desks would be larger paper documents
    used only when at work. Beyond the desk were shelves and cabinets containing books
    and files with data used less often. Still further removed were storage boxes
    in attics, then local and national libraries and archives that required increasing
    time to visit. Data could be promoted and demoted between these different stores
    at different times. For example, a book might sit in the library unused for years,
    then be promoted to your desk for a few weeks when you needed it. Unused documents
    on your desk could be demoted to a filing cabinet then to the attic.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 内存层次结构在数字化之前的生活中也存在。例如，人们过去会将购物清单和重要的电话号码写在纸片上，方便即时和经常使用。在他们的办公桌上，通常会有较大的纸质文件，只有在工作时才会用到。更远的地方是架子和柜子，里面存放着不常用的书籍和文件。更远的地方是阁楼里的存储箱，然后是本地和国家的图书馆和档案馆，访问这些地方需要更多时间。数据可以在这些不同的存储之间进行提升和降级。例如，一本书可能多年未被使用，静静地放在图书馆里，之后在需要时被提升到桌面上使用几周。桌面上不再使用的文件可以降级到文件柜，再到阁楼中。
- en: The same concepts apply to computer memory. When fast and slow versions of the
    same technology are available, the fast one is better, so it can command a higher
    price, meaning you can buy less of it compared to the slower one. Given a budget,
    you can thus trade off speed for capacity. Since most people want some data to
    be more readily accessible than other data, it makes economic sense to buy and
    use a mixture of memory types, ranging from small and fast for working data to
    large and slow for rarely used data. [Figure 10-1](ch10.xhtml#ch10fig1) shows
    the approximate speeds and capacities for each of the levels of memory hierarchy
    that we’ll discuss in this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的概念也适用于计算机内存。当同一技术有快速和慢速版本时，快速版本更好，因此它可以要求更高的价格，这意味着与较慢版本相比，你能购买的量较少。在有预算的情况下，你可以在速度和容量之间进行权衡。由于大多数人希望某些数据比其他数据更容易访问，因此购买和使用不同类型的内存（从小而快速的工作数据到大而慢的很少使用的数据）是有经济意义的。[图
    10-1](ch10.xhtml#ch10fig1)展示了本章中将讨论的每个内存层次的大致速度和容量。
- en: '![Image](../images/f0216-01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0216-01.jpg)'
- en: '*Figure 10-1: The memory hierarchy*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-1：内存层次结构*'
- en: 'These levels can be defined as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些层次可以定义如下：
- en: '**Registers** Memory inside the CPU, as described in [Chapter 7](ch07.xhtml).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**寄存器** 位于CPU内部的内存，如[第7章](ch07.xhtml)所描述。'
- en: '**Cache** Memory outside but close to the CPU, which contains fast copies of
    primary memory.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**缓存** 位于CPU外部但靠近CPU的内存，包含主内存的快速副本。'
- en: '**Primary memory** Memory stored in an address space that is directly accessible
    by the CPU’s load and store instructions.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**主内存** 存储在地址空间中，可以通过CPU的加载和存储指令直接访问的内存。'
- en: '**Secondary memory** Memory not directly accessible to the CPU via its registers
    and address space, but that can be moved into primary memory by I/O to enable
    such access.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**次级内存** 是CPU无法通过其寄存器和地址空间直接访问的内存，但可以通过I/O传输到主内存中以实现访问。'
- en: '**Tertiary memory** Memory that isn’t directly connected to the address space
    or to I/O, but that can be mechanically connected to I/O without human intervention.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**三级内存** 是不直接连接到地址空间或I/O的内存，但可以通过机械方式连接到I/O，无需人工干预。'
- en: '**Offline memory** Memory that can be connected only to the computer with human
    intervention.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**离线内存** 是只能通过人工干预连接到计算机的内存。'
- en: According to Church’s definition of a computer, any machine that relies on fixed-length
    addresses—such as the Manchester Baby we built in [Chapter 7](ch07.xhtml)—isn’t
    quite a computer. A Church computer needs to be able to simulate any other machine,
    and to do this it needs to be able to ask for and get more storage as needed.
    Machines based on a CPU and bus with fixed-sized addresses can’t easily extend
    their memory beyond that fixed size, however. To get around this problem, and
    to allow for unlimited memory, we need to use memory levels below primary memory,
    such as the secondary and tertiary levels shown in [Figure 10-1](ch10.xhtml#ch10fig1).
    These lower levels aren’t addressed directly from the CPU, but instead are devices
    that connect to it through I/O modules.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 根据丘奇对计算机的定义，任何依赖固定长度地址的机器——比如我们在[第7章](ch07.xhtml)中构建的曼彻斯特宝宝——都不完全算是计算机。丘奇计算机需要能够模拟任何其他机器，并且为了做到这一点，它必须能够按需请求并获取更多的存储空间。然而，基于固定大小地址的CPU和总线构建的机器，无法轻松扩展超出该固定大小的内存。为了绕过这个问题，并支持无限的内存，我们需要使用主内存以下的内存级别，例如在[图10-1](ch10.xhtml#ch10fig1)中显示的次级和三级内存。这些较低级别的内存不能直接从CPU寻址，而是通过I/O模块与CPU连接的设备。
- en: Primary Memory
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 主内存
- en: '*Primary memory* (aka *system memory*) is memory stored in an address space
    that’s directly accessible by the CPU’s load and store instructions. This includes
    RAM and ROM. Most modern machines use von Neumann architectures; remember, this
    means that the program and data are stored together in the same primary memory.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*主内存*（也称为*系统内存*）是存储在地址空间中的内存，这些地址空间可以被CPU的加载和存储指令直接访问。这包括RAM和ROM。大多数现代计算机使用冯·诺依曼架构；记住，这意味着程序和数据存储在同一主内存中。'
- en: In primary memory, each memory location is given a unique address. For example
    a 16-bit address space has 2^(16) = 65,536[10] unique addresses, numbered from
    0000[16] to FFFF[16]. Each address stores a fixed-size array of bits called a
    *word*. Often, but not always, the word length is chosen to be the same as the
    address length, such as storing 64-bit words in a 64-bit address space on a modern
    laptop. You saw a simple way to implement this structure using flip-flops in [Chapter
    6](ch06.xhtml); you saw how to attach it to a CPU directly in [Chapter 7](ch07.xhtml)
    and indirectly via a bus in [Chapter 9](ch09.xhtml).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在主内存中，每个内存位置都有一个唯一的地址。例如，一个16位的地址空间有2^(16) = 65,536[10]个唯一地址，编号从0000[16]到FFFF[16]。每个地址存储一个固定大小的位数组，称为*字*。通常，虽然不总是如此，字长被选择为与地址长度相同，例如在现代笔记本电脑的64位地址空间中存储64位字。你在[第6章](ch06.xhtml)中看到了实现这种结构的简单方法；在[第7章](ch07.xhtml)中你看到如何将其直接连接到CPU，在[第9章](ch09.xhtml)中则是通过总线间接连接。
- en: '*Bytes and Endianness*'
  id: totrans-21
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*字节与字节序*'
- en: Related to the SI versus binary prefix debate is the question of whether to
    measure memory in bits (b), bytes (B), or words (W). Bits are the most basic unit,
    and they work well with SI units.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 关于国际单位制（SI）与二进制前缀的争论，涉及到是否应以比特（b）、字节（B）或字（W）来衡量内存。比特是最基本的单位，它与国际单位制单位配合使用效果很好。
- en: In modern use, a byte means 8 bits, and the term comes from the 8-bit era, when
    what is now known as a word was by definition 8 bits. One byte was what was stored
    at one memory address, and what was brought into one register of the CPU for processing.
    The term *byte* is supposed to suggest the CPU taking the smallest “bite” of memory
    to process. It was deliberately misspelled to avoid confusion with the term *bit*.
    “Byte” originally meant *any* such natural CPU size, ranging between 1 and 6 bits
    in early processors of the 1950s. It only later came to be standardized to mean
    8 bits.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代使用中，一个字节表示8位，这一术语来源于8位时代，当时现在所称的字是按定义为8位的。一个字节是存储在一个内存地址中的数据，也是被带入CPU的一个寄存器进行处理的数据。术语*字节*应该意味着CPU从内存中“咬取”最小的一块进行处理。为了避免与*比特*这一术语混淆，它故意拼写错了。“字节”最初是指任何这种自然的CPU大小，早期1950年代的处理器中，字节的位数范围从1到6位。直到后来才标准化为8位。
- en: In the 8-bit era, it was very natural to measure primary memory in bytes and
    what are now called kibibytes. You would compute the number of addresses, such
    as 2^(16) for addresses that are 16 bits long, then append the word *bytes* to
    this number to get the total addressable memory size. For example, a “64 kibibyte”
    machine such as the Commodore 64 had 2^(16) addresses containing 1 byte each.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在8位时代，用字节和现在所谓的千字节（kibibyte）来衡量主存储器是非常自然的。你会计算地址的数量，比如2^(16)表示16位长的地址，然后在这个数字后加上字“bytes”来得到总的可寻址内存大小。例如，一台“64千字节”的机器，如Commodore
    64，具有2^(16)个地址，每个地址包含1个字节。
- en: The byte really should have little or no relevance in the modern 64-bit age,
    in which words are 64 bits rather than 8 bits. If we were to store 64-bit words
    at each of 2^(32) = 4 gibi addresses, we would talk about having primary memory
    sizes such as “4 gibiwords.”
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代64位时代，字节的意义应该几乎没有，尤其是在现在字长是64位而不是8位的情况下。如果我们在2^(32) = 4 gibi地址处存储64位字，我们将讨论像“4
    gibiwords”这样的主存储器大小。
- en: However, most actual current machines *don’t* address memory per word. For historical
    reasons, they usually continue to address memory per byte, just as they did in
    the 8-bit era. This is called *byte addressing* and it means that a word on, say,
    a 32-bit architecture is stored across 4 bytes with separate addresses. Suppose
    we want to store a 32-bit word such as 12B4A85C[16]. We do this using 4 bytes
    containing 12[16], B4[16], A8[16], and 5C[16].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数实际的现代计算机*并不*按字存取内存。出于历史原因，它们通常仍然按字节存取内存，就像在8位时代那样。这被称为*字节寻址*，意思是，在例如32位架构中，一个字被分散存储在4个字节中，每个字节有独立的地址。假设我们要存储一个32位字，如12B4A85C[16]。我们可以使用4个字节，分别包含12[16]，B4[16]，A8[16]，和5C[16]。
- en: A standards war raged for decades over the order in which these bytes should
    be stored in memory addresses. The ordering is referred to as *endianness*. *Big
    endians* believe the bytes should be stored in the order (12[16], B4[16], A8[16],
    5C[16]) because this looks like the human-readable number 12B4A85C[16]. Big endians
    say this makes life easier and nicer for the humans who see architecture, including
    architects themselves and assembly programmers.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些字节应该以何种顺序存储在内存地址中，经历了几十年的标准战争。这个顺序被称为*字节序*。*大端序*认为字节应该按照顺序（12[16]，B4[16]，A8[16]，5C[16]）存储，因为这看起来像人类可读的数字12B4A85C[16]。大端序认为，这种方式能让看到架构的人，包括架构师和汇编程序员，感到更轻松和更好。
- en: '*Little endians*, on the other hand, believe the number should be stored as
    (5C[16], A8[16], B4[16], 12[16]). This initially seems crazy to most Western people.
    In particular, if you string the bytes together in this order, you have the nonsensical
    number 5CA8B412[16] rather than the desired 12B4A85C[16]. However, little endians
    point out that such stringing is based on certain cultural prejudices.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，*小端序*认为数字应该按（5C[16]，A8[16]，B4[16]，12[16]）的顺序存储。这最初让大多数西方人觉得很疯狂。特别是，如果你按这个顺序将字节串联起来，你得到的将是没有意义的数字5CA8B412[16]，而不是期望的12B4A85C[16]。然而，小端序指出，这样的排序是基于某些文化偏见的。
- en: The West uses the Arabic decimal number system, which writes numbers with the
    highest power on the left and the lowest on the right. It imported this system
    unchanged from the original Arabic. But Arabic *text* is written and read from
    right to left, the opposite of Western text. In Arabic, a number string such as
    “24” is written the same, and has the same value, 24, as in the West, but it’s
    *read* from right to left as “four and twenty.” The zeroth column is the units,
    and the first column is the tens. This makes sense when arithmetic is performed
    using the number, because almost all arithmetic algorithms begin by operating
    on the zeroth column and move progressively up the higher-numbered columns. The
    numbers of these columns match the powers that the base is raised to—for example,
    the zeroth column is the units, or zeroth power.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 西方使用的是阿拉伯十进制数字系统，数字从左到右按从高到低的幂次排列。这个系统是从原始的阿拉伯数字中引入的，保持不变。但阿拉伯*文本*是从右到左书写和阅读的，正好与西方的文本相反。在阿拉伯语中，像“24”这样的数字字符串写法是相同的，数值也和西方一样是24，但它是从右到左读作“four
    and twenty”。零位列是单位，第一列是十位。这样做在进行算术运算时是有意义的，因为几乎所有的算术算法都是从零位列开始操作，并逐步处理较高的位列。这些列的数字与基础被提升的幂次相对应——例如，零位列是单位，或者说是零次幂。
- en: 'The little-endian system assigns numerical addresses so that the zeroth byte
    is at zero offset from the address of the word, and the *n*th byte is at an *n*
    byte offset. This can make arithmetic easier and faster for the machine in some
    cases. For example, if the machine is adding two words of different byte lengths
    (say, a short int plus a long int), it’s easy and quick to find the *n*th byte
    of each. Similar issues can also arise for words containing instructions of variable
    lengths: with little endianness, you can always be sure that the opcode is at
    zero offset rather than having to look for it. Little endianness is now dominant
    in commercial architectures, so it has effectively won the war.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 小端系统分配数值地址，使得第零字节位于字的地址零偏移处，第 *n* 个字节位于 *n* 字节的偏移位置。这在某些情况下可以使机器的算术运算更简便、更快速。例如，如果机器在加法运算中处理两个不同字节长度的字（比如，一个短整型和一个长整型），它就能快速且轻松地找到每个字节的
    *n* 位。同样的问题也可能出现在包含可变长度指令的字中：采用小端格式时，你总能确保操作码位于零偏移位置，而无需去寻找它。小端格式在商业架构中现在占主导地位，因此它实际上已经赢得了这场“战争”。
- en: '*Memory Modules*'
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*内存模块*'
- en: RAM and ROM often come in discrete modules that can be added and removed to
    change the amount of available memory. With a bus architecture, these modules
    can easily be attached and detached. For example, [Figure 10-2](ch10.xhtml#ch10fig2)
    shows one ROM module and two RAM modules on the same bus as a CPU.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: RAM 和 ROM 通常以离散模块的形式出现，可以通过添加和移除来更改可用内存的数量。采用总线架构时，这些模块可以很方便地连接或断开。例如，[图 10-2](ch10.xhtml#ch10fig2)
    显示了一个 ROM 模块和两个 RAM 模块与 CPU 共享同一总线的情况。
- en: '![Image](../images/f0219-01.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0219-01.jpg)'
- en: '*Figure 10-2: A bus architecture including a CPU, two RAM modules, and a ROM
    module*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-2：包括 CPU、两个 RAM 模块和一个 ROM 模块的总线架构*'
- en: In general, there could be many modules of both RAM and ROM. All the RAM modules
    can see the same signals passing along the bus, but each module is configured
    with a different part of the address space, so only the single module that hosts
    the specified address will actually respond.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，RAM 和 ROM 都可以有多个模块。所有的 RAM 模块都可以看到沿总线传输的相同信号，但每个模块被配置为与地址空间的不同部分对应，因此只有托管指定地址的单个模块会作出响应。
- en: All bus modules—including memory and I/O modules—are usually manufactured to
    respond to some default address space, such as starting at address 0\. However,
    when they’re mounted onto a bus, these addresses need to be remapped to be unique
    when compared to the other modules. This remapping is done by digital logic components
    called *memory controllers*, which listen to the bus for global addresses and
    route them to the appropriate module, converting to the module’s own local addresses.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 所有总线模块——包括内存和 I/O 模块——通常都会制造为响应某些默认的地址空间，比如从地址 0 开始。然而，当它们被安装到总线上时，这些地址需要重新映射，以便与其他模块进行比较时具有唯一性。这一重新映射是由称为
    *内存控制器* 的数字逻辑组件完成的，它们监听总线上的全局地址，并将其路由到相应的模块，转换为该模块的本地地址。
- en: '*Random-Access Memory*'
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*随机访问存储器*'
- en: '*Random access* means that any random location in memory can be chosen and
    accessed quickly, without some regions being faster to access than others. By
    contrast, something like a cassette tape or punch-card deck isn’t random access
    because it’s faster to access data in sequence than to fast-forward or rewind
    to a far-away location. While RAM stands for “random-access memory,” it’s a historical
    misnomer that doesn’t paint a full picture. By modern convention, RAM refers to
    memory that’s not only random access but also both readable and writable, as well
    as *volatile*, meaning its data is lost when the machine is powered off. Many
    ROMs are also random access, but they aren’t considered RAM under the conventional
    use of the term because they don’t fit the other parts of the definition.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*随机访问* 意味着可以快速选择并访问内存中的任何位置，而不需要某些区域比其他区域访问更快。相比之下，像磁带或打孔卡片那样的存储方式就不是随机访问，因为在顺序访问数据时，跳到远距离位置的速度通常比快进或倒带要慢。虽然
    RAM 代表“随机访问存储器”，但它是一个历史上的误称，并未全面描述其特点。根据现代约定，RAM 指的是不仅具有随机访问能力，还可以读写，并且是 *易失性*
    的内存，这意味着机器断电后数据会丢失。许多 ROM 也是随机访问的，但由于它们不符合该术语的其他定义，因此通常不被视为 RAM。'
- en: '**HISTORICAL RAMS**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**历史上的 RAM**'
- en: We’ve already discussed Babbage’s Analytical Engine RAM, which is still the
    foundation for RAM architecture today, in [Chapter 3](ch03.xhtml). In the Analytical
    Engine, each memory address corresponds to a stack of gears whose rotations represent
    a word. One address at a time can be physically connected to the bus. Once connected,
    any rotation of the gears will be transferred first to the linear motion of the
    bus, and then to rotation of a register in the CPU, and vice versa. Now let’s
    consider a few other historical examples of RAM.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第3章](ch03.xhtml)中讨论了巴贝奇的解析机内存，这也是今天RAM架构的基础。在解析机中，每个内存地址对应一堆齿轮的堆叠，其旋转代表一个字。一时间只能有一个地址与总线物理连接。一旦连接，任何齿轮的旋转都会首先传递到总线的线性运动，再传递到CPU中寄存器的旋转，反之亦然。现在让我们来看一些其他历史上的RAM实例。
- en: '**Acoustic Mercury Delay Line RAM**'
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**声学汞延迟线RAM**'
- en: In “From Combinatorial to Sequential Logic” on [page 144](ch06.xhtml#lev129),
    we discussed how the presence and absence of the audio feedback created by an
    electric guitar and amplifier feedback loop could be used to store 1 bit of information.
    This was, in fact, exactly how computer memory was implemented in the UNIVAC era,
    using mercury delay lines, as shown in the following figure.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在《从组合逻辑到顺序逻辑》一节中，[第144页](ch06.xhtml#lev129)我们讨论了由电吉他和功放反馈回路产生的音频反馈的有无如何用于存储1位信息。事实上，这正是UNIVAC时代计算机内存的实现方式，采用了汞延迟线，如下图所示。
- en: '![Image](../images/f0220-01.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0220-01.jpg)'
- en: A delay line was literally a microphone and speaker placed some distance apart
    and used to store a bit of information through feedback. By placing them at two
    ends of a tube and filling the tube with mercury, the speed of sound is delayed,
    so the tube can be made shorter than earlier versions using air.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟线实际上是将麦克风和扬声器放置在一定距离处，通过反馈来存储一位信息。通过将它们放置在管道的两端，并将管道填充汞，可以延迟声音的传播速度，从而使管道比使用空气的早期版本更短。
- en: In machines of this era, delay lines could be organized into an address space,
    as in the Analytical Engine. When the CPU executed a load or store, this would
    be implemented by making and breaking the electric circuits to connect the required
    delay line to the bus, disconnecting the others and placing a copy of the data
    onto the bus for transmission.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个时代的机器中，延迟线可以像在解析机中那样组织成地址空间。当CPU执行加载或存储操作时，会通过断开和连接电路来实现，将所需的延迟线连接到总线，断开其他线，并将数据的副本放到总线上进行传输。
- en: '**Williams Tube RAM**'
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**威廉姆斯管RAM**'
- en: The Manchester Baby was built to research a new type of RAM, known as the Williams
    tube. The technology, shown below, was conceived in 1946, based on the cathode
    ray tube (CRT), as found in old TV screens.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 曼彻斯特宝贝机是为研究一种新型RAM——威廉姆斯管而建造的。该技术如下面所示，诞生于1946年，基于旧电视屏幕中使用的阴极射线管（CRT）。
- en: '![Image](../images/f0221-01.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0221-01.jpg)'
- en: 'As with CRT screens, the Williams tube fires a stream of electrons in a beam,
    and uses adjustable magnets to deflect the beam to land on one pixel at a time,
    in a scanning pattern covering a screen. The screen is made from a fluorescent
    material, meaning that each pixel glows when absorbing the electron beam. Unlike
    CRT televisions and monitors, the Williams tube’s purpose was not as a human-readable
    display but as actual RAM storage. Pixels retain their charge and color for a
    short period of time after they’re hit by the beam. This means they can be used
    in a feedback system: we write a screen-full of pixels using the scanning beam,
    quickly read the screen’s state, and pass the data read off the screen back to
    the scanning beam to be written to the screen again. This refreshes the data on
    the screen, keeping it alive for as long as we like, rather than allowing the
    pixels to fade away.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 与CRT屏幕一样，威廉姆斯管通过电子束发射一束电子流，并利用可调磁铁来偏转电子束，使其一次落在一个像素上，扫描模式覆盖整个屏幕。屏幕由荧光材料制成，这意味着每个像素在吸收电子束时会发光。与CRT电视和显示器不同，威廉姆斯管的目的是作为实际的RAM存储，而不是供人类读取的显示器。像素在被电子束击中后，会在短时间内保持其电荷和颜色。这意味着它们可以用作反馈系统：我们使用扫描电子束写入满屏像素，快速读取屏幕状态，然后将读取的数据传回扫描电子束，再次写入屏幕。这种方式刷新了屏幕上的数据，使其保持活跃，直到我们希望它保持为止，而不是让像素逐渐消失。
- en: The original Williams tube’s screen contained 32 words of 32 bits each, with
    each row of the screen being one word and each column of the screen being a bit
    within a word. Thus, the whole system stored 32×32 = 1,024 bits. Phosphor was
    used as the fluorescent material, which glows green when stuck by the electron
    beam.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的威廉姆斯管屏幕包含 32 个字，每个字为 32 位，每行屏幕为一个字，每列屏幕为字中的一个比特。因此，整个系统存储了 32×32 = 1,024
    位。荧光材料采用磷光体，当电子束撞击时，它会发出绿色光。
- en: '**Static RAM**'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**静态 RAM**'
- en: The kind of RAM we saw previously in [Figure 6-22](ch06.xhtml#ch06fig22), made
    from flip-flops, is known as *static RAM* or *SRAM* (pronounced “es-ram”). Because
    SRAM is made from flip-flops (the same structures that are used to make CPU registers),
    it’s fast and expensive. The flip-flops are typically built from around four to
    six transistors each (depending on the flip-flop type and on how the logic gates
    are implemented). They have stable memory states, meaning they don’t have to be
    actively refreshed. They’re available for reading almost immediately after being
    written to. What sets SRAM apart from CPU registers is that SRAM is addressed,
    and CPU registers aren’t.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前在[图 6-22](ch06.xhtml#ch06fig22)中看到的由触发器构成的 RAM 被称为 *静态 RAM* 或 *SRAM*（发音为“es-ram”）。由于
    SRAM 是由触发器（与 CPU 寄存器相同的结构）构成的，它既快速又昂贵。触发器通常由大约四到六个晶体管组成（具体取决于触发器类型以及逻辑门的实现方式）。它们具有稳定的内存状态，这意味着它们不需要主动刷新。写入后几乎可以立即读取它们。SRAM
    与 CPU 寄存器的不同之处在于，SRAM 是寻址的，而 CPU 寄存器则不是。
- en: SRAM is typically used to implement caches, as we’ll discuss later in the chapter.
    It isn’t usually used for main memory, except in some specialized and expensive
    machines, such as high-end routers, where main memory access speed is critical.
    [Figure 10-3](ch10.xhtml#ch10fig3) shows an SRAM chip.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: SRAM 通常用于实现缓存，如本章后续所讨论的那样。它通常不用于主内存，除非在一些特殊且昂贵的机器中，例如高速路由器，在这些机器中，主内存访问速度至关重要。[图
    10-3](ch10.xhtml#ch10fig3) 显示了一个 SRAM 芯片。
- en: '![Image](../images/f0222-01.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0222-01.jpg)'
- en: '*Figure 10-3: An SRAM chip*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-3：一个 SRAM 芯片*'
- en: Cache chips like this may be placed between the CPU and RAM. Alternatively,
    a similar SRAM cache might be found on the same silicon as the CPU.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 类似这样的缓存芯片可以放置在 CPU 和 RAM 之间。或者，类似的 SRAM 缓存也可能与 CPU 在同一硅片上。
- en: '**Dynamic RAM**'
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**动态 RAM**'
- en: '*Dynamic RAM (DRAM)* is cheaper and more compact than SRAM, but slower. Instead
    of being made from flip-flops, it’s made using cheaper and slower capacitors.
    A *capacitor* is a component for storing electric charge. It consists of two metal
    plates separated by an insulator. Current can’t flow across the plates, but placing
    a current on them causes them to accumulate charge until they’re full of it. Capacitors
    don’t usually appear in CPU design; they’re a different kind of electronic component.
    One bit of DRAM storage is made from just one transistor plus one capacitor. Capacitors
    can be manufactured on silicon using similar masking processes to transistor manufacture.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*动态 RAM (DRAM)* 比 SRAM 更便宜且更紧凑，但速度较慢。它不是由触发器构成，而是使用更便宜且较慢的电容器。*电容器*是用于储存电荷的组件。它由两块金属板和一层绝缘物质隔开。电流不能穿过这两块板，但在其上施加电流会使它们积累电荷，直到它们充满电。电容器通常不会出现在
    CPU 设计中，它们是另一种电子元件。一个 DRAM 存储位由一个晶体管和一个电容器组成。电容器可以使用与晶体管制造相似的掩膜工艺在硅上制造。'
- en: As RAM, DRAM features the same addressing system as SRAM, and its circuit diagram
    has the same overall structure as SRAM, based on words stored at addresses. The
    difference is that the words are implemented with capacitors instead of flip-flops
    ([Figure 10-4](ch10.xhtml#ch10fig4)).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 RAM，DRAM 采用与 SRAM 相同的寻址系统，其电路图与 SRAM 基于存储在地址中的字的总体结构相同。不同之处在于，字是由电容器而非触发器实现的（[图
    10-4](ch10.xhtml#ch10fig4)）。
- en: DRAM is structured as a 2D array of words or bytes, with each located at a “row”
    and “column.” The requested address is converted (by a memory controller chip)
    into two smaller addresses per row and per column, which are AND gated together
    using a single transistor at the combined address. This saves a huge amount of
    digital logic, but the work needed to split the address into two parts makes DRAM
    addressing slower than SRAM addressing.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: DRAM 结构为一个 2D 数组，由字或字节组成，每个字或字节位于一个“行”和“列”中。请求的地址由内存控制芯片转换为每行和每列的两个较小的地址，这些地址通过一个单一的晶体管在组合地址上进行与门操作。这节省了大量的数字逻辑，但将地址分成两部分所需的工作使得
    DRAM 的寻址速度比 SRAM 慢。
- en: Due to the nature of capacitors, reading the DRAM discharges it and destroys
    the stored information (as in the Analytical Engine’s RAM). Reading and writing
    the capacitor state is an analog process, which takes time to complete. The charge
    can also leak away over time, as capacitors are analog devices. To handle these
    related problems, DRAM must be periodically refreshed, for example, around every
    64 milliseconds on a 2018 DRAM. (The need to constantly refresh is the source
    of the “dynamic” in DRAM.) Like mercury lines and Williams tubes, a refresh reads
    the current state and then rewrites it a short time later. Refreshing must be
    timed carefully and may sometimes conflict with and stall a CPU read or write,
    which then has to wait until the refresh completes before trying again.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于电容器的特性，读取DRAM会使其放电并销毁存储的信息（就像分析引擎的RAM一样）。读取和写入电容器状态是一个模拟过程，需要一定的时间来完成。由于电容器是模拟设备，电荷也可能随时间泄漏。为了处理这些相关问题，DRAM必须定期刷新，例如，在2018年版的DRAM上，大约每64毫秒刷新一次。（不断刷新是“动态”DRAM的根源。）像水银线路和威廉姆斯管一样，刷新过程会读取当前状态，然后在短时间内重写它。刷新必须小心计时，有时可能与CPU的读取或写入发生冲突，导致CPU需要等待刷新完成后才能重新尝试。
- en: '![Image](../images/f0223-01.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0223-01.jpg)'
- en: '*Figure 10-4: A DRAM circuit, showing capacitors and addressing*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-4：一个DRAM电路，展示了电容器和寻址*'
- en: DRAM benefits from *pre-charging*, roughly a way to “warm it up” just before
    it’s used; this avoids recharging conflicts with access. Hence, modern CPUs and
    memory controllers work together to try to predict—several instructions in advance—which
    memory should be “warmed up” before use.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: DRAM受益于*预充电*，这大致是一种在使用之前“预热”的方式；这样可以避免与访问发生冲突的重新充电。因此，现代的CPU和内存控制器会协作，尽量预测——提前几个指令——哪些内存在使用前应该被“预热”。
- en: Modern DRAM chips are usually packaged together on printed circuit board modules
    of around eight chips, each sharing part of an address space, as shown in [Figure
    10-5](ch10.xhtml#ch10fig5). These modules attach to a motherboard via a standard
    interface, as seen previously in the introduction ([Figure 2](fm03.xhtml#fig2)).
    Extra memory can be added to a desktop PC by adding more DRAM modules to its memory
    slots.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现代的DRAM芯片通常被打包在大约八个芯片的印刷电路板模块上，每个芯片共享一部分地址空间，如[图10-5](ch10.xhtml#ch10fig5)所示。这些模块通过标准接口连接到主板，如之前在介绍中所见（[图2](fm03.xhtml#fig2)）。可以通过将更多DRAM模块添加到台式机的内存插槽中，来增加额外的内存。
- en: '![Image](../images/f0223-02.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0223-02.jpg)'
- en: '*Figure 10-5: A DRAM module*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-5：一个DRAM模块*'
- en: '*Single in-line memory modules (SIMMs)* have a 32-bit bus width, and they were
    standard in 1990s PCs. Double in-line memory modules (DIMMs) replaced SIMMs in
    the 2000s. They have a 64-bit bus width, and each stores many gigabytes. Double
    data rate (DDR) DRAM doubled the speed of DRAM through technology that enables
    data to transfer on both the rising and falling edges of the clock. This doubles
    the bandwidth (as *bandwidth = bus width × clock speed* × *data rate*). SIMMs
    and DIMMs have gone through several improved standards that can be visually distinguished
    by the different notch positions, designed so they can be inserted only into the
    right type of sockets.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*单列内存模块(SIMMs)*具有32位总线宽度，它们曾是1990年代PC的标准。双列内存模块(DIMMs)在2000年代取代了SIMMs。它们具有64位总线宽度，每个DIMM存储多达几千兆字节。双倍数据速率(DDR)DRAM通过一种使数据能够在时钟的上升沿和下降沿同时传输的技术，使DRAM的速度翻倍。这使得带宽翻倍（因为*带宽
    = 总线宽度 × 时钟速度 × 数据速率*）。SIMMs和DIMMs经历了几个改进的标准，可以通过不同的缺口位置直观区分，设计目的是使它们只能插入到正确类型的插槽中。'
- en: '**Error Correction Code RAM**'
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**错误更正码RAM**'
- en: RAM, like other chips, has become so miniaturized that the component size is
    getting close to atomic scales. At these scales, quantum effects and particle
    physics come into play. Quantum effects can include various types of inherent
    noise and uncertainty about the location of particles used in memory. Cosmic rays
    are random particles most commonly including electrons, alpha particles, and muons,
    hurtling at high speed through space from either the sun or elsewhere in the galaxy.
    If a cosmic ray collides with a sensitive component of RAM, then it can corrupt
    it and flip its Boolean state.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: RAM像其他芯片一样，已经被微型化到接近原子尺度。在这些尺度下，量子效应和粒子物理学开始发挥作用。量子效应可能包括各种类型的固有噪声和关于用于内存的粒子位置的不确定性。宇宙射线是最常见的随机粒子，通常包括电子、α粒子和μ子，它们以高速穿越太空，来源可能是太阳或银河系的其他地方。如果宇宙射线与RAM的敏感组件发生碰撞，它可以破坏该组件并翻转其布尔状态。
- en: '*Error correction code RAM (ECC-RAM)* has extra chips on the DIMM that store
    extra copies or checksums of the data and use them to automatically correct such
    flips at the hardware level. ECC-RAM is primarily used in space applications where
    computers are located outside the protection of Earth’s atmosphere and so are
    more exposed to cosmic rays. As its price falls, it may also be found in other
    high-value, safety-critical systems on the ground.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*错误校正码内存 (ECC-RAM)* 在 DIMM 上有额外的芯片，这些芯片存储数据的额外副本或校验和，并利用它们在硬件级别自动修正类似的错误。ECC-RAM
    主要应用于太空领域，那里计算机位于地球大气层的保护之外，因此更容易受到宇宙射线的影响。随着价格的下降，ECC-RAM 也可能出现在其他高价值、关键安全系统中。'
- en: '**THE ROWHAMMER VULNERABILITIES**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**ROWHAMMER 漏洞**'
- en: '*Rowhammer* refers to a set of memory hardware vulnerabilities currently affecting
    computer security. DRAM capacitors are now so small and tightly packed that their
    electric fields may affect neighboring rows of memory. Security researchers have
    begun to exploit this effect to read and write memory belonging to target programs.
    The researchers write new programs and arrange for them to be stored in a region
    of memory physically next to, for example, the addresses containing your online
    banking password, owned by the target program. They then load and store data in
    their own program’s locations, in ways that are likely to trigger physical interactions
    between the capacitors in their own and the target’s memory. For example, this
    could include putting their own addresses into states likely to cause cosmic ray–style
    errors in the target memory. Or they might be able to infer the state of the target
    memory by observing similar errors or small time delays in their own reads and
    writes caused by the target’s capacitor states.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*Rowhammer* 指的是当前影响计算机安全的一组内存硬件漏洞。DRAM 电容器现在非常小且密集，以至于它们的电场可能会影响邻近的内存行。安全研究人员已经开始利用这一效应来读取和写入目标程序的内存。研究人员编写新程序，并安排将它们存储在内存中物理上紧邻目标程序的区域，例如存储在线银行密码的地址。然后，他们在自己程序的位置加载并存储数据，方式上可能会触发自己与目标内存中电容器的物理交互。例如，这可能包括将自己的地址置于可能引起目标内存中类似宇宙射线风格错误的状态。或者，他们可能通过观察自己读写中的相似错误或由于目标电容器状态引起的微小时间延迟来推断目标内存的状态。'
- en: Research is currently ongoing into defenses against rowhammer attacks. Approaches
    include use of ECC-RAM to correct any maliciously induced cosmic ray–style errors,
    use of higher memory refresh rates, and software-level solutions such as operating
    system code to randomize the locations of programs in memory and prevent deliverable
    co-location of code next to targets.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的研究正在进行，以防御 rowhammer 攻击。方法包括使用 ECC-RAM 来修正任何恶意引发的宇宙射线风格错误，使用更高的内存刷新率，以及通过操作系统代码等软件层面的解决方案来随机化程序在内存中的位置，从而防止代码与目标程序的交付性共同定位。
- en: '*Read-Only Memory*'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*只读存储器*'
- en: '*Read-only memory (ROM)* traditionally refers to memory chips that can only
    be read from, not written to, and that are pre-programmed with permanent collections
    of subroutines by their manufacturer, then mounted at fixed addresses in primary
    memory. ROMs have since evolved to include other types of memory that don’t fit
    this traditional definition or name very well or at all.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*只读存储器 (ROM)* 传统上指的是只能读取而不能写入的内存芯片，这些芯片由制造商预先编程，内含永久性的子程序集合，然后被安装在主内存中的固定地址处。ROM
    随着时间的推移，已经发展出包括其他类型的内存，这些内存并不完全符合这一传统定义或名称。'
- en: 'First, the ROM versus RAM distinction has never been a true partition because,
    as noted earlier, ROM chips are random access, just like RAM: they’re mounted
    in the main address space and accessing any address within them takes the same
    amount of time. The difference between ROM and RAM is that RAM is readable and
    writable, while ROM is traditionally only readable.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，ROM 与 RAM 的区别从未真正存在，因为如前所述，ROM 芯片和 RAM 一样是随机访问的：它们被安装在主地址空间中，访问其中的任何地址所需的时间都是一样的。ROM
    和 RAM 的区别在于，RAM 是可读写的，而 ROM 传统上只是可读的。
- en: Second, ROMs have evolved over time to allow increasing ease of rewriting, with
    programs stored in ROM that are able to be rewritten in some way now known as
    *firmware*. The following sections describe the main steps of this evolution,
    as illustrated in [Figure 10-6](ch10.xhtml#ch10fig6).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，ROM 随着时间的推移发展出了越来越容易重写的特性，存储在 ROM 中的程序现在可以以某种方式被重写，这些程序通常被称为 *固件*。以下部分描述了这一演变的主要步骤，如[图
    10-6](ch10.xhtml#ch10fig6)所示。
- en: '![Image](../images/f0225-01.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0225-01.jpg)'
- en: '*Figure 10-6: Evolution of ROMs: MROM, PROM, EPROM, EEPROM, and SD card–mounted
    flash. Note that, unusually, the actual silicon is visible in the EPROM package,
    through a transparent window, which is needed to expose it to light.*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-6：只读存储器的演变：MROM、PROM、EPROM、EEPROM和SD卡挂载的闪存。请注意，不同寻常的是，EPROM封装中实际的硅片是可见的，通过一个透明窗口，可以将其暴露在光下。*'
- en: Let’s go through a few of these types of ROM.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来了解一下这些不同类型的只读存储器。
- en: '**Mask ROM**'
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**掩膜只读存储器（Mask ROM）**'
- en: '*Mask ROM (MROM)* is ROM whose contents are programmed using photo-lithography
    by the manufacturer. It remains read-only forever and can’t be overwritten. If
    you want to update an MROM chip, you have to remove it, throw it away, and insert
    a brand new chip containing the new content. Photolithography is very expensive,
    so MROMs are difficult to produce and to upgrade.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*掩膜只读存储器（MROM）*是一种由制造商通过光刻技术编程的只读存储器。它永远是只读的，无法覆盖。如果你想更新MROM芯片，你必须将其取出、丢弃，然后插入一个包含新内容的全新芯片。光刻技术非常昂贵，因此MROM的生产和升级都很困难。'
- en: '**Programmable ROM**'
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**可编程只读存储器（Programmable ROM）**'
- en: '*Programmable ROM (PROM)* was a great advance over MROM. Similar to the programmable
    logic arrays (PLAs) discussed in [Chapter 5](ch05.xhtml), PROMs are chips manufactured
    by photolithography to include a generic circuit with many fuses. The programmer
    can then selectively blow the fuses to create different structures. While PLAs
    enable arbitrary digital logic networks to be burned in this way, PROMs instead
    contain a fixed structure of addresses and words, and allow only the bits composing
    the words to be burned, to make a ROM. Usually each bit contains 1 when its fuse
    is intact and changes to 0 if its fuse is blown. Like PLAs, PROMs can never be
    erased once they’re programmed.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*可编程只读存储器（PROM）*是对MROM的巨大改进。与[第5章](ch05.xhtml)中讨论的可编程逻辑阵列（PLAs）类似，PROM是通过光刻技术制造的芯片，包含一个通用电路和多个保险丝。程序员可以选择性地熔断保险丝来创建不同的结构。虽然PLAs使得可以以这种方式烧录任意数字逻辑网络，但PROM则包含一个固定的地址和字结构，只允许烧录组成字的位来制作只读存储器。通常，每个位在其保险丝完好时包含1，若其保险丝熔断则变为0。像PLAs一样，PROM一旦编程后就不能被擦除。'
- en: '**Erasable Programmable ROM**'
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**可擦除可编程只读存储器（Erasable Programmable ROM）**'
- en: '*Erasable programmable ROM (EPROM)* is like PROM, but the chip’s data can be
    erased using ultraviolet light. Then new data can be burned on. This cycle can
    be repeated many times. Although the erasing process was quite complex, requiring
    that you take the chip out of the computer and put it in a light box, it was still
    something you, a skilled end-user customer, could do without needing the computer
    manufacturer.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*可擦除可编程只读存储器（EPROM）*类似于PROM，但该芯片的数据可以通过紫外线照射来擦除。然后可以重新写入新的数据。这个过程可以反复进行很多次。尽管擦除过程相当复杂，需要将芯片从计算机中取出并放入光照盒中，但这仍然是你作为一名熟练的最终用户客户可以做的，无需计算机制造商的帮助。'
- en: '**Electrically Erasable Programmable ROM**'
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**电可擦可编程只读存储器（Electrically Erasable Programmable ROM）**'
- en: '*Electrically erasable programmable ROM (EEPROM)* is like EPROM in that you
    can wipe the entire chip and rewrite it, but here you only need to use electricity
    to erase and reprogram. This removes the need to physically manipulate the ROM;
    it can remain inside the computer. EEPROM is used today in ROMs that allow their
    firmware to be upgraded. If you’ve ever done a firmware update, you’ll have seen
    that it can be done entirely in software, without having to physically touch anything.
    You wouldn’t want to be updating firmware every day, but maybe once per year or
    whenever a bug fix has been found.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*电可擦可编程只读存储器（EEPROM）*类似于EPROM，你可以擦除整个芯片并重新写入它，但在这里你只需要使用电流来擦除和重新编程。这消除了物理操作ROM的需要；它可以保持在计算机内部。今天，EEPROM被用于那些可以升级固件的ROM。如果你曾经进行过固件更新，你会看到它完全可以通过软件完成，而无需物理接触任何东西。你不希望每天都更新固件，但可能每年更新一次，或者当发现有
    bug 修复时。'
- en: '**Flash Memory**'
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**闪存（Flash Memory）**'
- en: '*Flash memory* is EEPROM that can be erased and rewritten block-wise, meaning
    you can selectively wipe and rewrite just one small part, or block, of the memory
    at a time. This way you can leave most of the ROM intact, unlike with regular
    EEPROM, where you have to wipe and rewrite an entire chip of ROM at a time, as
    in a firmware update. Flash memory makes it much easier to rewrite portions of
    ROM frequently, while the chip is online, making it more feasible for day-to-day
    storage, functioning almost like RAM in some cases.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*闪存*是可以按块擦除和重写的EEPROM，这意味着你可以选择性地擦除和重写内存的一个小部分或块。这样，你就可以保持大部分ROM不变，不像常规EEPROM那样，每次必须擦除和重写整个ROM芯片，如固件更新时的做法。闪存使得在芯片在线时，频繁重写ROM的一部分变得更加容易，在某些情况下，它几乎像RAM一样起作用。'
- en: Caches
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缓存
- en: A *cache* is an extra layer in the memory pyramid between the fast registers
    of the CPU and the slower RAM. It stores copies of the most heavily used memory
    contents, making them available for quick retrieval. (*Cache* is an archaic word
    for a store of items such as food, weapons, or pirate treasure.) Without a cache,
    RAM would connect straight to the CPU, either directly, as discussed in [Chapter
    7](ch07.xhtml), or using a bus with control (C), address (A), and data (D) lines,
    as discussed in [Chapter 9](ch09.xhtml) and summarized in [Figure 10-7](ch10.xhtml#ch10fig7).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*缓存*是CPU的快速寄存器和较慢的RAM之间的内存金字塔中的额外层级。它存储最常用的内存内容的副本，使它们可以快速检索。（*缓存*是一个过时的词，指的是存储食物、武器或海盗宝藏等物品的地方。）没有缓存时，RAM会直接连接到CPU，要么是直接连接，如[第7章](ch07.xhtml)所讨论，要么是通过带有控制（C）、地址（A）和数据（D）线的总线连接，如[第9章](ch09.xhtml)所讨论，并在[图10-7](ch10.xhtml#ch10fig7)中总结。'
- en: '![Image](../images/f0226-01.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0226-01.jpg)'
- en: '*Figure 10-7: A basic CPU, bus, and RAM architecture*'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-7：基本的CPU、总线和RAM架构*'
- en: The problem with this kind of cacheless architecture is that most programs need
    to access RAM frequently, but the capacitors that implement DRAM are slower than
    the flip-flops that implement the CPU’s registers. RAM thus becomes a major bottleneck
    for system speed. It’s no use having a fast, gigahertz CPU if the RAM is running
    orders of magnitude slower and the CPU has to wait around for each load and store
    to complete. Adding an SRAM-based cache made from flip-flops between the CPU and
    RAM, as shown in [Figure 10-8](ch10.xhtml#ch10fig8), helps avoid these bottlenecks.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这种无缓存架构的问题在于，大多数程序需要频繁访问RAM，但实现DRAM的电容器比实现CPU寄存器的触发器要慢。因此，RAM成为系统速度的主要瓶颈。如果RAM的速度慢得多，而CPU需要等待每次加载和存储操作完成，那么即使有一个快速的千兆赫CPU也没有用。为了避免这些瓶颈，在CPU和RAM之间添加一个基于SRAM的缓存（如[图10-8](ch10.xhtml#ch10fig8)所示）有助于解决这个问题。
- en: '![Image](../images/f0227-01.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0227-01.jpg)'
- en: '*Figure 10-8: A basic CPU, bus, and RAM architecture with a cache in between*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-8：带有缓存的基本CPU、总线和RAM架构*'
- en: When the CPU needs to load some data, the cache checks if it has it, and returns
    it quickly if so. If not, the cache refers to the next memory level down (in [Figure
    10-8](ch10.xhtml#ch10fig8), RAM) and fetches the data from that level. Caching
    can also occur at *all* levels of the memory hierarchy, from registers to hard
    disks and jukeboxes (more on the latter in the “Tertiary Memory” section). However,
    it’s most commonly considered at the primary memory level, as we’re discussing
    here, between the registers and the main DRAM memory.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当CPU需要加载一些数据时，缓存会检查它是否已有该数据，如果有，则快速返回。如果没有，缓存会查阅下一级内存（如[图10-8](ch10.xhtml#ch10fig8)所示的RAM），并从该级别获取数据。缓存也可以发生在*所有*内存层级中，从寄存器到硬盘和自动唱机（关于后者将在“三级存储”部分进一步讨论）。然而，在这里我们主要讨论的是在寄存器和主DRAM内存之间的主内存级别的缓存。
- en: Initial designs began with a single cache, made from SRAM. More recent machines
    have made use of Moore’s law for transistor density to fill silicon with larger
    caches and more levels of cache. It’s common today to have at least three cache
    levels, called L1, L2, and L3, as in [Figure 10-9](ch10.xhtml#ch10fig9).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 初始设计使用了一个由SRAM构成的单一缓存。近年来的机器利用摩尔定律中晶体管密度的提升，将硅芯片填充上更大的缓存和更多级别的缓存。如今，至少有三个缓存层级——L1、L2和L3——这种设计已经很常见，如[图10-9](ch10.xhtml#ch10fig9)所示。
- en: '![Image](../images/f0227-02.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0227-02.jpg)'
- en: '*Figure 10-9: A basic CPU, bus, and RAM architecture with L1, L2, and L3 caches*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-9：带有L1、L2和L3缓存的基本CPU、总线和RAM架构*'
- en: All these cache layers between CPU and DRAM memory are typically made in SRAM,
    but they have different operations policies that trade off size and speed in their
    different digital logic implementations. Historically, caches lived on dedicated
    chips outside the CPU. While lower levels still do this, a major trend is to move
    bigger and higher cache levels onto the CPU silicon itself.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些位于CPU和DRAM内存之间的缓存层通常使用SRAM制造，但它们有不同的操作策略，通过不同的数字逻辑实现，权衡了大小和速度。在历史上，缓存通常位于CPU外部的专用芯片上。虽然较低级别的缓存仍然如此，但一个主要趋势是将更大、更高级别的缓存直接集成到CPU硅片中。
- en: Understanding the caches of your machines helps you write faster programs. Typically,
    each level of cache is 10 times faster than the one below it, so when you fill
    a level you’ll see a sudden slowdown in memory access. If you know the cache sizes,
    you can redesign your code to keep data in use within known cache-level limits
    to benefit from their speed.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 了解你机器的缓存有助于你编写更快的程序。通常，每一级缓存的速度是下一级缓存的10倍，因此当你填满某一级缓存时，你会看到内存访问的突然变慢。如果你知道缓存的大小，你可以重新设计代码，将正在使用的数据保持在已知缓存级别的限制内，从而利用缓存的速度。
- en: '*Cache Concepts*'
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*缓存概念*'
- en: Caches are based on the *principle of locality*, which states that only a small
    amount of memory space is being accessed at any given time, and values in that
    space are being accessed repeatedly. It’s therefore useful to copy recently accessed
    values and their neighbors from larger, slower memory to smaller, faster memory.
    There are several different ways to think about “neighbors” and “locality.” *Temporal
    locality* is the property that values tend to be accessed repeatedly at nearby
    times. *Sequential locality* is the property that some sequences tend to be re-accessed
    in the same order multiple times. *Spatial locality* is the property that values
    nearby in memory tend to be accessed together. These concepts apply to both instructions
    and data, often arising due to loops and subroutines.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存基于*局部性原理*，该原理指出，在任何给定时刻，只有少量的内存空间被访问，并且该空间中的值会被反复访问。因此，将最近访问的值及其邻近值从较大、较慢的内存复制到较小、较快的内存是有用的。有多种不同的方式来理解“邻近”和“局部性”。*时间局部性*是指值倾向于在相近的时间内被反复访问。*顺序局部性*是指某些序列倾向于以相同的顺序多次重新访问。*空间局部性*是指内存中相邻的值倾向于一起被访问。这些概念适用于指令和数据，通常由于循环和子程序的存在而产生。
- en: Cache memory is made of many *cache lines*. Each line contains a *block* with
    copies of several contiguous words from memory, as well as a *tag*, an address
    or other identifier describing which memory location has been copied into the
    block. Each line also has a *dirty bit* that tracks whether the CPU has changed
    the value in the cache, making it different from the equivalent value in memory.
    [Table 10-1](ch10.xhtml#ch10tab1) shows a few example cache lines.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存内存由许多*缓存行*组成。每一行包含一个*块*，该块包含多个来自内存的连续字的副本，以及一个*标签*，它是一个地址或其他标识符，描述了哪个内存位置的值被复制到了该块中。每一行还具有一个*脏位*，用于跟踪CPU是否已更改缓存中的值，使其与内存中相应的值不同。[表
    10-1](ch10.xhtml#ch10tab1)显示了一些示例缓存行。
- en: '**Table 10-1:** Cache Lines'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 10-1：** 缓存行'
- en: '| **Tag** | **Block** | **Dirty bit** |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| **标签** | **块** | **脏位** |'
- en: '| --- | --- | --- |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `$08F4` | `01101100 01101100 10011010` | `1` |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| `$08F4` | `01101100 01101100 10011010` | `1` |'
- en: '| `$2AD5` | `10010101 11100110 00110110` | `0` |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| `$2AD5` | `10010101 11100110 00110110` | `0` |'
- en: Each cache line shown in the table has a block of three 8-bit words, a tag consisting
    of the full address from a 16-bit address space, and a dirty bit. The 1 dirty
    bit for the first line indicates it’s been updated, while the 0 dirty bit for
    the second line indicates it hasn’t.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表中显示的每个缓存行包含一个由三个8位字组成的块，一个由16位地址空间中的完整地址构成的标签，以及一个脏位。第一行的脏位为1，表示该行已被更新，而第二行的脏位为0，表示该行未被更新。
- en: We don’t cache individual addresses, but rather lines because it’s very cheap
    to move around larger chunks of memory rather than individual words. By bringing
    in whole lines around a target word, we exploit spatial locality—data and programs
    in neighboring locations are likely to be used next. The line prepares for this.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不是缓存单个地址，而是缓存缓存行，因为移动较大块的内存比单个字更便宜。通过将目标字周围的整行数据带入缓存，我们利用了空间局部性——相邻位置的数据和程序很可能会被接下来使用。这一行已经为此做好准备。
- en: 'Some cache systems use “hash functions” to choose a location in the cache for
    storing a piece of data, usually based on the data’s address in lower-level memory.
    A *hash function* is a many-to-one function that maps a big input number to a
    smaller output number, the *hash value*. It’s not usually possible to recover
    the original value from the hash value. For example, a function that takes the
    last two hex digits of a hex number is a simple hash function: *hash*(9A8E[16])
    = 8E[16]. The function that performs a Boolean AND of all binary digits in a number
    is another hash function: *hash*(01101001[2]) = 0&1&1&0&1&0&0 = 0\. A commonly
    used hash function for caches is to compute the value of an address modulo the
    number of available lines in the cache.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一些缓存系统使用“哈希函数”来选择缓存中存储数据的位置，通常是基于数据在低级内存中的地址。*哈希函数*是一种多对一的函数，它将一个大的输入数字映射到一个较小的输出数字，即*哈希值*。通常无法从哈希值恢复出原始值。例如，取一个十六进制数字的最后两个十六进制数字是一个简单的哈希函数：*hash*(9A8E[16])
    = 8E[16]。对数字的所有二进制位执行布尔与运算的函数是另一个哈希函数：*hash*(01101001[2]) = 0&1&1&0&1&0&0 = 0。缓存中常用的哈希函数是计算地址对缓存行数取模的值。
- en: Finding an item in a cache is known as a *hit*. Not finding an item in a cache
    is known as a *miss*. When a miss occurs, we have to go back to the underlying
    memory and find the item there instead, usually making a new copy in the cache
    for future use. The *hit rate* is the ratio of hits to attempts (hits and misses
    together). This measures the proportion of cache lookups that are successful.
    The *miss rate* is the ratio of misses to attempts. This measures the proportion
    of cache lookups that are unsuccessful. The *hit time* is the time required to
    access requested data if a hit has occurred, and the *miss penalty* is the time
    required to process a miss.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在缓存中找到一个项目叫做*命中*。在缓存中找不到一个项目叫做*未命中*。当发生未命中时，我们必须回到底层内存去查找该项目，通常会在缓存中为将来使用创建一个新的副本。*命中率*是命中次数与尝试次数（命中和未命中）的比率。它衡量了成功的缓存查找的比例。*未命中率*是未命中次数与尝试次数的比率。它衡量了不成功的缓存查找的比例。*命中时间*是访问请求数据所需的时间，如果发生命中的话，*未命中惩罚*是处理未命中所需的时间。
- en: A cache has only a limited number of lines, and they quickly fill up as we store
    cached copies of everything that we access from the underlying memory. Once the
    cache is full, we’ll continue to request new addresses. These will initially miss,
    but temporal locality suggests that these new addresses are more likely to be
    reused than the older ones in the cache. We should therefore choose lines in the
    cache to overwrite, discarding their previously cached addresses and replacing
    them with the new ones. The contents of the overwritten lines are called *victims*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存只有有限数量的行，当我们存储从底层内存访问的所有数据副本时，这些行很快就会被填满。一旦缓存满了，我们将继续请求新的地址。初始时，这些请求会错过缓存，但时间局部性表明，这些新地址比缓存中的旧地址更可能被重用。因此，我们应该选择缓存中的某些行进行覆盖，丢弃它们之前缓存的地址，并用新地址替换它们。被覆盖行的内容称为*牺牲品*。
- en: Once we have a cache structure, we need algorithms, implemented in fast digital
    logic, to manage it. We need to decide how to best make use of the available lines,
    and how to create and look up tags. As with most digital logic design, there will
    be trade-offs between methods that are simple and methods that are fast. The latter
    tend to require more silicon, making them more complex, error-prone, and expensive.
    Let’s take a look at a few options for using caches.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了缓存结构，就需要使用快速数字逻辑实现算法来管理它。我们需要决定如何最好地利用可用的缓存行，以及如何创建和查找标签。与大多数数字逻辑设计一样，简单的方法和快速的方法之间总是存在权衡。后者通常需要更多的硅片，导致它们更加复杂、容易出错且成本更高。让我们来看看一些使用缓存的选项。
- en: '*Cache Read Policies*'
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*缓存读取策略*'
- en: Reading from a cache is a simpler task than writing to it, so we’ll first study
    some options for cache read algorithms.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 从缓存读取比写入缓存要简单，因此我们将首先研究一些缓存读取算法的选项。
- en: '**Direct Mapped**'
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**直接映射**'
- en: '*Direct mapping* is the simplest, easiest, and cheapest cache read policy to
    implement and understand. It’s sketched out in [Figure 10-10](ch10.xhtml#ch10fig10).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '*直接映射*是最简单、最容易理解且最便宜的缓存读取策略。它在[图 10-10](ch10.xhtml#ch10fig10)中有所展示。'
- en: '![Image](../images/f0229-01.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0229-01.jpg)'
- en: '*Figure 10-10: A direct mapping cache read policy (showing lookup and caching)*'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-10：直接映射缓存读取策略（显示查找和缓存）*'
- en: In essence, the line where we store or look for a tag is addressed using a fixed
    hash of the tag. A line with this tag will only ever be stored at a single location.
    If multiple lines compete for the location, the new one will replace the older
    one. For example, suppose we load from address 67AB[16]. We might compute *hash*(67AB[16])
    = 4[16], which means that this address and its contents will be cached in line
    4[16], victimizing anything that was previously on this line.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，我们存储或查找标签的行是使用该标签的固定哈希值来寻址的。带有此标签的行将始终只存储在一个位置。如果多个行争夺该位置，新的行将替换旧的行。例如，假设我们从地址67AB[16]加载数据。我们可能计算出*哈希*(67AB[16])
    = 4[16]，这意味着该地址及其内容将缓存到行4[16]，并覆盖该行之前的任何内容。
- en: The drawback is that direct mapping can’t keep multiple in-use addresses in
    cache if they share the same hash. Suppose our program has a tight loop that reads
    and writes the two alternating addresses 67AB[16] and 12C9[16] many times. The
    problem here is that *hash*(67AB[16]) = *hash*(12C0[16]) = 4[16]. Both addresses
    will continually fight and victimize one another, overwriting line 4[16], even
    if no other addresses or cache lines are being used in the loop at all. In such
    a case, the cache will give no benefit at all, as every attempt will miss.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点是直接映射如果多个地址共享相同的哈希值，无法将它们的多个在用地址保存在缓存中。假设我们的程序有一个紧密的循环，反复读取和写入两个交替的地址67AB[16]和12C9[16]。这里的问题是*哈希*(67AB[16])
    = *哈希*(12C0[16]) = 4[16]。这两个地址将不断相互竞争，互相覆盖行4[16]，即使在循环中没有使用其他地址或缓存行的情况下也是如此。在这种情况下，缓存根本不会带来任何好处，因为每次访问都会失败。
- en: '**Fully Associative**'
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**完全关联**'
- en: To fix the problem with direct mapping, we’d like to have addresses use different
    cache lines depending on how in-use our lines are, so that we victimize lines
    that are the least used, as sketched out in the *fully associative cache* of [Figure
    10-11](ch10.xhtml#ch10fig11).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决直接映射的问题，我们希望地址能够根据行的使用情况使用不同的缓存行，从而使得最少使用的行受到影响，正如在[图 10-11](ch10.xhtml#ch10fig11)中的*完全关联缓存*示意图所示。
- en: '![Image](../images/f0230-01.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0230-01.jpg)'
- en: '*Figure 10-11: A fully associative cache sketch*'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-11：完全关联缓存示意图*'
- en: Here, each line of cache RAM is given its own digital logic block, including
    a comparator, multiplexer, and OR arrays. Only three such blocks are shown for
    illustration purposes, but for a 256-line cache, for example, there would be 256
    such blocks, all running in parallel.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，每一行缓存RAM都有自己的数字逻辑模块，包括比较器、选择器和OR阵列。这里只为说明 purposes 展示了三个这样的模块，但对于一个256行的缓存，实际上会有256个这样的模块，全部并行工作。
- en: 'We want to be able to store a tag, block, and dirty bit on *any* available
    line and be able to find it quickly. Caching is the easy part here: we just create
    some digital logic to count how much use each line is getting and to pick out
    the line with the lowest count.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望能够在*任何*可用行上存储标签、数据块和脏位，并能快速找到它。缓存是这里的简单部分：我们只需创建一些数字逻辑来统计每一行的使用频率，并选择使用频率最低的行。
- en: The cache lookup is the harder part. In direct mapping, we just computed the
    same hash function as we used for caching, to tell us at which line to find a
    desired address. Now it could be anywhere in the cache, so we need to add lots
    of extra digital logic to check each of the lines’ tags for a match with the desired
    one and activate the matching line if it exists. Doing this in parallel (which
    is the only realistic way to make this fast enough to be useful) requires *N*
    copies of this matching digital logic, one for each of the *N* lines of cache,
    making it a much larger and more energy-consuming beast.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存查找是更难的部分。在直接映射中，我们只需计算与缓存使用相同的哈希函数，来告诉我们在哪一行找到所需的地址。现在它可能位于缓存中的任何位置，因此我们需要添加大量额外的数字逻辑，以检查每一行的标签是否与所需标签匹配，并在存在匹配时激活该行。以并行方式执行此操作（这是唯一可以让其足够快以便有用的方法）需要*N*个匹配数字逻辑的副本，每个缓存行有一个副本，使得系统变得更大且更耗能。
- en: '**Set Associative**'
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**集合关联**'
- en: '*Set associative* cache reading is an attempt to get the best of both of the
    above methods. Here we partition the *N*-line cache into several smaller sets
    of lines. We use hashing on addresses to hash to a set number, rather than a line
    number. During caching we find the set number from this hash, similar to the direct
    mapping approach, then choose as the victim the line within this set that has
    the least usage, similar to the fully associative approach. During lookup we again
    find the set number from the hash, then we use parallel matching checks on all
    items in just the one set to quickly find the matching line.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*集合关联*缓存读取是一种试图同时兼得上述两种方法优点的做法。在这里，我们将*N*行缓存分成几个较小的行集合。我们使用地址哈希来计算一个集合编号，而不是计算行号。在缓存过程中，我们通过这个哈希找到集合编号，类似于直接映射方法，然后选择该集合中使用最少的行作为替换行，类似于完全关联方法。在查找时，我们再次通过哈希找到集合编号，然后在该集合中并行匹配所有项，以快速找到匹配的行。'
- en: This approach means we only have to activate the comparators within a single
    set, rather than the entire cache, but we still avoid the direct-mapped problem
    of tight loops sharing hash values. In practice, this is often found to be a nice
    balance.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法意味着我们只需要激活单个集合中的比较器，而不是整个缓存，但我们仍然避免了紧密循环共享哈希值的直接映射问题。实际上，这通常被认为是一种良好的平衡。
- en: '*Cache Write Policies*'
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*缓存写入策略*'
- en: Caches become a bit more complicated when we do stores because a store changes
    the state of the memory. Suppose we’ve recently loaded an integer 17 from address
    540A[16] and cached a copy during the load. We want to increment this integer
    to 18 and store the result back at 540A[16]. Due to the locality principles, it’s
    likely that we’ll continue to both load and store from 540A[16] in the near future,
    so rather than store 18 directly in 540A[16], it may be faster to store it only
    in the cache line that’s currently caching 540A[16]. This means that all the future
    loads and stores can just hit the cache and don’t need to go to main memory.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行存储操作时，缓存会变得更加复杂，因为存储操作会改变内存的状态。假设我们最近从地址540A[16]加载了一个整数17，并在加载时缓存了一个副本。我们想将这个整数递增到18，并将结果存回到540A[16]。由于局部性原则，我们很可能在不久的将来继续从540A[16]加载和存储，因此与其直接将18存储到540A[16]，不如只将它存储在当前缓存540A[16]的缓存行中。这样，所有未来的加载和存储操作都可以直接命中缓存，而不需要访问主存。
- en: 'The problem is that eventually this line will be victimized and we’ll lose
    all the changes we’ve made to the value; the main memory still contains the old
    value of 17\. To avoid this, at some point we need to copy the modified value
    back to main memory. The dirty bit shown earlier in [Table 10-1](ch10.xhtml#ch10tab1)
    tracks whether this needs doing. It’s set to 0 if the value in the line is the
    same as the value in memory, or to 1 if the value in the line has been updated
    but the value in memory hasn’t. Algorithms called *cache write policies* use this
    dirty bit to manage the copying back to memory. Let’s look at two different approaches:
    write-back and write-through.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，最终这行数据会被替换，我们会丢失对值所做的所有更改；主存中仍然包含旧值17。为了避免这种情况，在某个时刻我们需要将修改后的值复制回主存。前面在[表10-1](ch10.xhtml#ch10tab1)中显示的脏位会跟踪是否需要进行此操作。如果缓存行中的值与内存中的值相同，脏位被设置为0；如果缓存行中的值已更新，但内存中的值没有变化，脏位则设置为1。名为*缓存写入策略*的算法利用这个脏位来管理回写到内存。我们来看两种不同的方式：写回和写穿透。
- en: '**Write-Back**'
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**写回**'
- en: '*Write-back* is the simpler cache writing method: it copies the contents of
    the cache block back to RAM only when the line is victimized. This is relatively
    slow, however, because victimization occurs only when an instruction is in a rush
    to get executed. We get told to start writing back only once the victimization
    has been announced, and the victimizing instruction will now have to wait for
    us to do a slow RAM access before it can overwrite our victim line.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*写回*是更简单的缓存写入方法：只有当缓存行被替换时，它才会将缓存块的内容复制回RAM。然而，这相对较慢，因为替换只有在指令急于执行时才会发生。我们被要求在替换被宣布后开始写回，而替换的指令将不得不等待我们进行一次缓慢的RAM访问，才能覆盖我们的替换行。'
- en: '**Write-Through**'
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**写穿透**'
- en: '*Write-through* is a potentially faster alternative to write-back, although
    it uses more resources. In write-through, we don’t wait until our line is victimized
    to copy our line’s block back to RAM; rather, we do it multiple times, continually,
    in the background, using digital logic attached to the cache line and bus. This
    logic acts similarly to an application like SyncThing or Dropbox, continually
    looking out for any changes in the cached version and copying them back to the
    main version in RAM. This doesn’t create extra work for the CPU, as the extra
    digital logic is located on the cache itself. It does, however, lead to more traffic
    on the bus, as we’re sending these updates many more times than with the write-back
    approach.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*写直达* 是一种可能比写回更快的替代方案，尽管它使用更多的资源。在写直达中，我们不会等到行被淘汰后才将行的块复制回 RAM；相反，我们会在后台不断地多次执行这个操作，使用附加在缓存行和总线上的数字逻辑。这些逻辑的作用类似于
    SyncThing 或 Dropbox 这样的应用程序，不断监视缓存版本中的任何更改，并将其复制回 RAM 中的主版本。由于这些额外的数字逻辑位于缓存本身，因此不会给
    CPU 增加额外工作。然而，这会导致总线上的流量增多，因为我们比起写回方式要更多次地发送这些更新。'
- en: '*Advanced Cache Architectures*'
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*高级缓存架构*'
- en: Consider how caches should interact with the advanced CPU developments of [Chapter
    8](ch08.xhtml). Pipelined CPUs need to care a lot about cache misses, as they
    form another possible hazard. An efficient pipeline may be timed to assume that
    memory accesses will be cached, and if there’s a miss they’ll need to stall or
    otherwise handle this hazard.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑缓存如何与[第8章](ch08.xhtml)中高级 CPU 技术互动。管道化 CPU 需要非常关注缓存未命中，因为它们会形成另一种可能的危险。高效的管道可能会假设内存访问将会被缓存，如果发生未命中，它们将需要停顿或以其他方式处理这种危险。
- en: You saw in [Chapter 8](ch08.xhtml) how branch prediction attempts to guess the
    flow of a program to enable pipelines and out-of-order execution to go more smoothly.
    This can be used in conjunction with caching to *preemptively* fetch and store
    data—that is, before the actual load and store instructions are reached. These
    instructions take much longer to execute than in-CPU operations, so it’s useful
    to initiate them early. CPUs can look ahead in the program to try to guess which
    parts of main memory are likely to be needed many instructions down the line,
    and start caching them in advance so the CPU fetches will be faster.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你在[第8章](ch08.xhtml)中看到过，分支预测试图猜测程序的执行流程，以便使管道和乱序执行更顺利。这可以与缓存配合使用，*预先* 获取和存储数据——也就是说，在实际的加载和存储指令到达之前就开始进行。这些指令的执行时间远长于
    CPU 内部操作，因此提前启动它们是有用的。CPU 可以提前预测程序中哪些主内存的部分可能在后续指令中需要，从而提前开始缓存这些部分，以使 CPU 的获取速度更快。
- en: 'As mentioned, each layer of the cache—L1, L2, and L3—provides roughly a tenfold
    speedup over the layer below it, so the potential gain from preemptively moving
    data higher up in the memory hierarchy isn’t trivial. The caches can always be
    rolled back and the CPU stalled if preemption gets it wrong. It’s not the end
    of the world if we bring the wrong data into the cache: the cache is a big place,
    and it’s okay to change what’s in it.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，缓存的每一层——L1、L2 和 L3——相较于其下层提供大约十倍的速度提升，因此，预先将数据移到更高层次的内存层次结构中所带来的潜在收益并非微不足道。如果抢占发生错误，缓存可以随时回滚，CPU
    会停顿。如果我们把错误的数据带入缓存，并不意味着世界末日：缓存是一个很大的地方，改变其中的内容是可以接受的。
- en: Due to the row-column structure of DRAM addressing, it’s faster to read multiple
    items in a single DRAM row all at once rather than individually. (Once a row is
    activated, it’s almost free to read many columns versus a single one.) Hence,
    modern DRAM controllers will typically work in harmony with the cache to move
    large DRAM rows into cache lines.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 DRAM 地址的行列结构，在一次性读取单个 DRAM 行中的多个项比单独读取更快。（一旦激活一行，读取多个列几乎是免费的，而读取单个列则相对较慢。）因此，现代
    DRAM 控制器通常会与缓存协同工作，将大块的 DRAM 行移入缓存行。
- en: Cache writes can unnecessarily slow down a system if we know in advance that
    the data won’t need to be read again soon. In this case, writing to the cache
    and then transferring to main memory can be slower than just writing directly
    to main memory. Modern CPUs may provide special instructions for cacheless writing,
    which canny programmers and compiler writers can use to make programs faster.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们事先知道数据不需要很快再次读取，缓存写入可能会不必要地拖慢系统速度。在这种情况下，写入缓存然后再传输到主内存的速度可能比直接写入主内存要慢。现代
    CPU 可能会提供专门的无缓存写入指令，机智的程序员和编译器开发者可以利用这些指令来加速程序执行。
- en: It’s been found empirically that L1 caches work more smoothly if they’re split
    into two separate, parallel caches, one for instructions and one for data. This
    can occur in Harvard architectures, where instructions and data are already separated
    in RAM, but also in von Neumann architectures, where instructions and data can
    be distinguished by which part of the CU is requesting them (instructions are
    requested during the fetch stage, while data is requested during the execute stage).
    This separation occurs only at L1, with lower cache levels sharing instructions
    and data, as in [Figure 10-12](ch10.xhtml#ch10fig12).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 经验表明，L1 缓存如果分为两个独立的并行缓存，一个用于指令，一个用于数据，通常能更平稳地工作。这种分离可以出现在哈佛架构中，其中指令和数据已经在 RAM
    中分开存储，也可以出现在冯·诺依曼架构中，在这种架构中，指令和数据可以通过控制单元（CU）请求它们的部分来区分（指令在取指阶段请求，而数据在执行阶段请求）。这种分离只发生在
    L1 级别，更低级的缓存共享指令和数据，如[图 10-12](ch10.xhtml#ch10fig12)所示。
- en: '![Image](../images/f0233-01.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0233-01.jpg)'
- en: '*Figure 10-12: A basic CPU, bus, and RAM architecture with separate L1 caches
    for instructions and data, and shared L2 and L3 caches*'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-12：一种基本的 CPU、总线和 RAM 架构，具有独立的 L1 缓存用于指令和数据，以及共享的 L2 和 L3 缓存*'
- en: Separating the instructions and data at the L1 level appears to be effective
    because both data and programs exhibit spatial locality individually, but with
    little locality between them. Also, instructions aren’t usually overwritten, while
    data often is, so separating out the instructions can simplify the cache write
    process.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在 L1 级别分离指令和数据似乎是有效的，因为指令和数据各自都有空间局部性，但它们之间几乎没有局部性。而且，指令通常不会被覆盖，而数据经常会，因此将指令分离出来可以简化缓存写入过程。
- en: Secondary and Offline Memory
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 二级存储和离线存储
- en: '*Secondary memory* is memory that can quickly be brought into addressed memory
    space via I/O. Data items in secondary memory don’t have addresses in the primary
    memory address space. Rather, they’re accessed via I/O, usually via an I/O module
    that *does* sit in the primary address space and relays requests to the secondary
    storage. Secondary storage is sometimes called *online storage* to emphasize that
    it’s powered, active, and available whenever the computer is on.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '*二级存储*是可以通过 I/O 快速加载到地址空间中的存储。二级存储中的数据项在主存地址空间中没有地址。相反，它们是通过 I/O 访问的，通常通过一个*位于*主地址空间中的
    I/O 模块，该模块将请求转发到二级存储。二级存储有时被称为*在线存储*，以强调它在计算机开启时有电、处于活动状态并且随时可用。'
- en: '*Offline memory* is that which can’t automatically be loaded into primary memory
    without *manual* human interventions. Often this includes secondary memory media
    that are physically ejectable and replaceable, such as tapes, discs, and USB devices.
    These media are secondary memory when connected to the computer, and offline memory
    when disconnected. Offline memory is typically used for backup and archival purposes,
    as well as for transportation. The fastest way to move petabytes of data around
    the world is still to put it on a truck as offline memory and drive it to its
    destination.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*离线存储*是指无法在没有*手动*干预的情况下自动加载到主存中的存储。通常这包括物理上可弹出和更换的二级存储介质，如磁带、光盘和 USB 设备。连接到计算机时，这些介质是二级存储，断开时则是离线存储。离线存储通常用于备份和归档，以及运输。将
    PB 级数据快速移动到世界各地的最快方法仍然是将其作为离线存储装载到卡车上，然后运输到目的地。'
- en: Secondary and offline memory should really nowadays be measured in bits and
    SI units—for example, describing an “8.8 terabit hard disk” instead of a “1 tebibyte
    hard disk.” This is because they aren’t part of primary memory address space and
    so aren’t addressed using primary memory’s word or byte addresses. The concept
    of bytes is even less relevant here than in modern primary memory. However, as
    primary memory is still often byte-addressed and measured in bytes, most people
    still have a better feel for sizes in bytes rather than bits, so they choose to
    measure secondary memory in the same units.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，二级存储和离线存储应该用比特和国际单位制（SI 单位）来衡量——例如，描述“8.8 太比特硬盘”而不是“1 tebibyte 硬盘”。这是因为它们不是主存地址空间的一部分，因此不使用主存的字或字节地址进行寻址。与现代主存相比，字节的概念在这里甚至更不相关。然而，由于主存仍然通常按字节寻址并以字节为单位进行测量，大多数人对字节单位的大小感知更好，因此他们选择以相同的单位来度量二级存储。
- en: Secondary (and offline) memory is usually characterized by requiring some mechanical
    motion to look up data, rather than being random access. This includes scrolling
    through tape or spinning discs made from various materials. We’ll look at some
    details of these technologies next.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 辅助（以及离线）内存通常的特点是需要一些机械运动来查找数据，而不是随机访问。这包括通过磁带滚动或旋转由各种材料制成的盘片。接下来，我们将详细了解这些技术的一些细节。
- en: '*Tapes*'
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*磁带*'
- en: '*Tapes* are one-dimensional data stores that must be scrolled left or right
    to locate a required datum. You can think of human-written paper scrolls, like
    the Torah, as the original tapes. Tapes aren’t random access because a reading
    device has a position at one point in the tape, and it takes longer to move the
    tape (or the reader) to access a far-away location than a nearby location. Fast
    algorithms using tape storage need to take this structure into account and optimize
    memory access to reduce large address jumps.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '*磁带* 是一维数据存储设备，必须左右滚动以定位所需的数据。你可以将人类手写的纸卷，如《托拉》经文，视为最初的磁带。磁带不是随机访问的，因为读取设备在磁带的某个位置，且移动磁带（或读取设备）以访问远距离位置所需的时间，比访问附近位置要长。使用磁带存储的快速算法需要考虑这种结构，并优化内存访问，以减少大的地址跳跃。'
- en: '**Punch Cards**'
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**打孔卡片**'
- en: '*Punch cards* are the original computational secondary storage, as used in
    the Jacquard loom and Analytical Engine (seen in [Figure 1-11](ch01.xhtml#ch01fig11)).
    They continued to be used in IBM Hollerith machines, and were used to store and
    read programs for early electronic machines of the 1960s. Occasional industrial
    use continued even into the 1980s, and allegedly at least one UK council may still
    be using them today. In punch cards, binary digits of data are represented by
    the presence or absence of holes punched or not punched at a series of physical
    locations on a card or piece of paper. The holes are usually about the size made
    by the desktop hole punchers you buy to file your paper documents into ring binders.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '*打孔卡片* 是最初的计算辅助存储设备，如在贾卡尔织机和分析机中使用（见[图1-11](ch01.xhtml#ch01fig11)）。它们继续在IBM霍勒里特机器中使用，并用于存储和读取20世纪60年代早期电子机器的程序。偶尔的工业使用甚至持续到1980年代，且据说至少有一个英国委员会至今仍在使用它们。在打孔卡片中，数据的二进制数字通过在卡片或纸张的系列物理位置上打孔或不打孔来表示。孔的大小通常和你买来为文件存档用的桌面打孔机的孔大小相似。'
- en: Cards are 2D, having rows and columns. Typically each row stores one word, with
    their row numbers acting as addresses (in a secondary address space, not primary
    RAM addresses). Conceptually, and sometimes physically, decks of cards are *chained*
    together to make what is really a 2D tape.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 卡片是二维的，具有行和列。通常每行存储一个字，行号作为地址（在辅助地址空间中，而不是主RAM地址）。从概念上讲，有时甚至在物理上，卡片的叠加是*链式*连接的，形成了实际上是二维的磁带。
- en: '**Punched Tape**'
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**打孔带**'
- en: '*Punched tape* is an alternative to punch cards. Such tapes were used by the
    British Post Office, formed the inspiration for the Turing Machine, and were also
    used in the Colossus, as seen in [Figure 1-22](ch01.xhtml#ch01fig22). Depending
    on your point of view, tape is conceptually simpler than cards because it’s just
    a single 1D row of bits; or it’s more complex than cards because you have to worry
    more about aligning and reading words, which on cards are easily presented as
    rows.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*打孔带* 是打孔卡片的一种替代品。这种带子曾被英国邮政局使用，构成了图灵机的灵感，并且也曾用于科洛苏斯（见[图1-22](ch01.xhtml#ch01fig22)）。根据你的视角，磁带在概念上比卡片更简单，因为它只是单一的一维位数组；或者它比卡片更复杂，因为你必须更多地关注对齐和读取单词，而卡片则可以轻松地按行呈现。'
- en: '**Magnetic Tape**'
  id: totrans-166
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**磁带**'
- en: '*Magnetic tape* was developed in the 1920s for analog audio recording in studios,
    commercialized for home use as 8-track systems in the 1960s, then used widely
    in 4-track compact cassettes during the 1980s. Analog magnetic tape was also widely
    used in the 1980s for home video recordings, following one of the first modern
    data standards wars between competing VHS and Betamax formats.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '*磁带* 在1920年代为模拟音频录制而开发，1960年代商业化为家庭使用的8轨系统，然后在1980年代广泛用于4轨的紧凑型磁带中。模拟磁带在1980年代也被广泛用于家庭视频录制，伴随了现代数据标准战争中竞争的VHS和Betamax格式。'
- en: In these systems, a magnetizable material such as iron oxide is formed into
    a tape structure, and the level of magnetization at each point along the tape
    is used to store data. Unlike punched paper, magnetic tape is easy to remagnetize
    and can be rewritten many times.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些系统中，像氧化铁这样的可磁化材料被形成磁带结构，并通过磁带上每个点的磁化水平来存储数据。与打孔纸不同，磁带容易重新磁化，可以反复写入多次。
- en: The same magnetic tapes can be used to store digital information, in various
    ways. For example, 0s and 1s can be encoded as single cycles of two different
    audible frequencies—a method that’s resilient to the heavy noise added by most
    tape devices. Algorithms developed for optimal access of punched tape carried
    over directly to magnetic tapes, as in the 1980s machine of [Figure 10-13](ch10.xhtml#ch10fig13).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的磁带可以以多种方式用于存储数字信息。例如，0和1可以通过两种不同的可听频率的单个周期进行编码——这是一种对大多数磁带设备添加的重噪声具有较强抗干扰性的技术。为优化打孔带访问开发的算法直接应用于磁带，正如在1980年代的[图10-13](ch10.xhtml#ch10fig13)中的机器所示。
- en: '![Image](../images/f0235-01.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0235-01.jpg)'
- en: '*Figure 10-13: A 1980s compact cassette and player/recorder, used for both
    analog music and digital file storage*'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-13：1980年代的紧凑型卡带及播放/录音机，用于模拟音乐和数字文件存储*'
- en: Magnetic tape is still in use today for offline storage, specifically for weekly
    or daily backups of company systems. Tape is cheap and cost-effective for large-scale
    storage, where access time is less important. Tapes are thus useful for the daily
    backup task because you want to have lots of old backups kept around for as long
    as possible. In particular, if someone attacks your company in a more subtle way
    than just deleting everything—for example, by making a series of small changes
    to your database—it’s useful to have a long series of backups so you can recover
    the state of the system from different days, weeks, months, years, and even decades.
    You can buy a new tape for a few dollars every day to get this assurance. Having
    many tapes around also means they can be kept at many more locations than can
    hard drives—for example, with a different employee taking one tape home each day
    so that even if half the staff’s houses burn down on the same day, you still have
    many recent backups around.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 磁带今天仍然被用于离线存储，特别是用于公司系统的每周或每日备份。磁带价格便宜、成本效益高，适合大规模存储，且对访问时间要求较低。因此，磁带非常适合用于日常备份任务，因为你希望尽可能长时间保留大量的旧备份。尤其是，如果有人以比单纯删除所有文件更微妙的方式攻击你的公司——例如，逐步对数据库进行小的修改——拥有一系列长期备份非常有用，这样你就可以从不同的日子、周、月、年甚至几十年前恢复系统的状态。你可以每天花几美元购买一卷新的磁带来确保这一点。拥有大量磁带的另一个好处是它们可以存放在比硬盘更多的地点——例如，每天让不同的员工带回一卷磁带，这样即使一半员工的家在同一天着火，你仍然可以拥有许多近期的备份。
- en: The most popular current standard for magnetic tape storage is *Linear Tape
    Open (LTO)*, shown in [Figure 10-14](ch10.xhtml#ch10fig14).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 当前最流行的磁带存储标准是*线性磁带开放式（LTO）*，见[图10-14](ch10.xhtml#ch10fig14)。
- en: '![Image](../images/f0236-01.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0236-01.jpg)'
- en: '*Figure 10-14: An IBM Ultrium Linear Tape Open cartridge and drive*'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-14：IBM Ultrium线性磁带开放式盒和驱动器*'
- en: LTO is an open source standard that, as of 2020, stored around 36TB on about
    1 km of tape in one cartridge that fits in your pocket and takes around 12 hours
    to write. This is a good size and time for most small businesses; they can back
    up the whole system overnight onto a single cartridge.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: LTO是一种开源标准，截至2020年，在一卷适合放入口袋的磁带中，大约存储了36TB的数据，写入过程大约需要12小时。这对大多数小型企业来说是一个很好的尺寸和时间；他们可以在一晚之间将整个系统备份到单个磁带中。
- en: '*Disks*'
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*磁盘*'
- en: Audio recording began in the 1870s with wax cylinders, as shown in [Figure 10-15](ch10.xhtml#ch10fig15).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 音频录制始于19世纪70年代的蜡筒，见[图10-15](ch10.xhtml#ch10fig15)。
- en: '![Image](../images/f0236-02.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0236-02.jpg)'
- en: '*Figure 10-15: A wax cylinder audio storage device*'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-15：蜡筒音频存储设备*'
- en: Here, sound waves enter the acoustic horn and are concentrated to vibrate a
    needle, etching the sound wave into a spiral around a hot wax cylinder as it rotates
    and is slowly moved left to right. When the wax cylinder is cool it can then be
    spun past the needle again to make it vibrate in the same ways, and have its motions
    amplified by the horn, replaying the sound.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，声波进入声学号角并被集中，振动针头，将声波刻录成旋转的热蜡筒上的螺旋形轨迹，同时蜡筒缓慢地从左向右移动。当蜡筒冷却后，可以再次旋转通过针头，使其以相同的方式振动，并通过号角放大其运动，从而重播声音。
- en: Wax cylinders were used commercially until 1898, when they were replaced by
    gramophones with discs, rotating at 78 revolutions per minute ([Figure 10-16](ch10.xhtml#ch10fig16),
    left). These “78” disks used the same idea of etching the analog sound wave directly
    into their spiral grooves, and their vinyl descendants—now with electrical amplification—are
    still in use by DJs today ([Figure 10-16](ch10.xhtml#ch10fig16), right).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 蜡筒唱片曾在商业上使用，直到1898年被旋转每分钟78转的唱片取代（[图 10-16](ch10.xhtml#ch10fig16)，左）。这些“78”转盘使用了将模拟声音波形直接刻入螺旋槽中的相同思想，它们的乙烯基后代——现在带有电放大——至今仍被DJ使用（[图
    10-16](ch10.xhtml#ch10fig16)，右）。
- en: '![Image](../images/f0237-01.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0237-01.jpg)'
- en: '*Figure 10-16: A gramophone (left) and a modern Technics SL-1200 turntable
    (right)*'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-16：留声机（左）和现代的Technics SL-1200转盘（右）*'
- en: Unlike audio discs, which have a single track spiraling in from the edge to
    the center, most data disks are truly 2D, as they have many independent *tracks*,
    each at a fixed radius, as shown in [Figure 10-17](ch10.xhtml#ch10fig17).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 与音频光盘不同，音频光盘只有一条从边缘到中心螺旋的轨道，大多数数据磁盘实际上是二维的，因为它们有许多独立的*轨道*，每个轨道在固定的半径上，如[图 10-17](ch10.xhtml#ch10fig17)所示。
- en: '![Image](../images/f0237-02.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0237-02.jpg)'
- en: '*Figure 10-17: The single track of an audio disc (left) and the 2D track of
    a data disk (right). The latter shows a track (A), sector (B), geometric sector
    (C), and cluster (D).*'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-17：音频光盘的单轨（左）和数据磁盘的二维轨道（右）。后者展示了轨道（A）、扇区（B）、几何扇区（C）和簇（D）。*'
- en: Tracks near the edge are larger than those in the center, so they store more
    data. Tracks are divided into fixed-data-size *sectors* around their circumference.
    Each sector has an address composed of its track ID and location within the track.
    In most systems, sectors store their own location in some of their bits so that
    we can figure out which part of the disk we’re looking at. They may also store
    redundant bits, which compensate for physical damage to the disk, using Shannon’s
    theory of communication. Sectors may be grouped into contiguous *clusters*, which
    are the smallest unit that can be read or written together.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 靠近边缘的轨道比中心的轨道更大，因此它们能存储更多的数据。轨道沿着其圆周被划分为固定数据大小的*扇区*。每个扇区都有一个地址，由轨道ID和轨道内的位置信息组成。在大多数系统中，扇区会存储一些位来表示它们的位置，这样我们就可以知道正在查看磁盘的哪一部分。它们还可能存储冗余位，用以补偿磁盘的物理损坏，利用香农的通信理论。扇区可以被组合成连续的*簇*，簇是可以一起读取或写入的最小单元。
- en: 'Data on disks can be accessed in an *almost* random-access manner: individual
    sectors can be stored or retrieved in any order, not only sequentially, but reads
    and writes to nearby sectors and tracks will be faster due to the motion of the
    disk and head. It’s easy and fast to read from a series of sectors in order around
    the same track as they spin past the head. If you want data on the same track
    but at a different angle from the current sector, you have to wait for the disk
    to spin around to bring that sector under your head. If you want data from a different
    track, you have to move your head along the radius, which is very slow, as it’s
    a physical device. I/O modules controlling spinning disks thus need to consider
    the *access time*—the time it takes to read or write one sector. Access time is
    composed of two main factors: *seek time* is the time it takes for the arm to
    position itself over the track, and *rotational delay* is the time it takes for
    the desired sector to position itself under the head.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 磁盘上的数据可以以*几乎*随机访问的方式进行访问：各个扇区可以按任意顺序存储或检索，不仅限于顺序访问，但由于磁盘和磁头的运动，访问相邻的扇区和轨道会更快。从同一轨道上依次读取扇区是非常容易且快速的，因为它们在旋转时经过磁头。如果你需要读取同一轨道但与当前扇区不同角度的数据，你必须等待磁盘旋转到该扇区下方。如果需要从不同的轨道读取数据，则需要将磁头沿半径移动，这个过程非常慢，因为它是一个物理装置。因此，控制旋转磁盘的I/O模块需要考虑*访问时间*——即读取或写入一个扇区所需的时间。访问时间由两个主要因素组成：*寻道时间*是磁臂定位到轨道上的时间，*旋转延迟*是所需扇区旋转到磁头下方所需的时间。
- en: '**Floppy Disks**'
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**软盘**'
- en: Magnetic disks use the same technology as magnetic tape to represent data, but
    they arrange the magnetizable material into a 2D disk rather than a 1D tape. The
    disk is read and written by a magnetic head on an arm, like a gramophone needle.
    *Floppy disks* ([Figure 10-18](ch10.xhtml#ch10fig18)) first appeared in the 1960s.
    They’re so-called because they physically flex.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 磁盘驱动器使用与磁带相同的技术来表示数据，但它们将磁性材料排列成二维的磁盘，而不是一维的磁带。磁盘通过安装在臂上的磁头进行读取和写入，就像留声机的唱针一样。*软盘*（[图10-18](ch10.xhtml#ch10fig18)）最早出现在1960年代。之所以叫“软盘”，是因为它们在物理上可以弯曲。
- en: '![Image](../images/f0238-01.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0238-01.jpg)'
- en: '*Figure 10-18: Three generations of floppy disks: 8 inch (1970s), 5 1/4 inch
    (1980s), and 3 1/2 inch (1990s)*'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-18：三代软盘：8英寸（1970年代）、5 1/4英寸（1980年代）和3 1/2英寸（1990年代）*'
- en: Floppy disks are vulnerable to damage, so they’re usually encased in a plastic
    sheath, as in the figure.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 软盘容易受到损坏，因此通常被包裹在塑料外壳中，如图所示。
- en: '**Hard Disks**'
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**硬盘**'
- en: '*Hard disks* are made of nonflexible materials. They can store higher information
    densities and spin faster than floppies. These devices usually require sealing
    the head into a package with the disk, as in [Figure 10-19](ch10.xhtml#ch10fig19),
    rather than allowing removable disks, as with floppies.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*硬盘*由非柔性材料制成，能够存储比软盘更高的信息密度，并且转速比软盘快。这些设备通常需要将读写头封闭在一个与磁盘一起的封装内，如[图10-19](ch10.xhtml#ch10fig19)所示，而不是像软盘那样允许更换磁盘。'
- en: '![Image](../images/f0238-02.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0238-02.jpg)'
- en: '*Figure 10-19: The inside of a magnetic hard drive*'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-19：磁性硬盘的内部结构*'
- en: Hard *drives* usually contain multiple hard disks packaged together, each with
    its own head, with a single address space spanning all of them. This can help
    reduce access times, because the heads can all read and write together. The disks
    spin at speeds such as 90 to 250 Hz, which causes a layer of air to lift the head
    off the surface, so the head doesn’t physically contact the platter. This means
    there’s no physical wear to the head or the disk. Designers have invested heavily
    in technology to automatically and rapidly park the head if the unit is in physical
    danger, such as being struck or pushed. Without this, the head would crash into
    the disk and destroy it during such an incident.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 硬盘*驱动器*通常包含多个硬盘磁盘，这些磁盘被包装在一起，每个磁盘都有自己的读写头，并且所有磁盘共享一个地址空间。这有助于减少访问时间，因为各个读写头可以一起进行读写操作。硬盘的转速通常在90到250
    Hz之间，这会使一层空气将读写头抬离表面，从而避免了读写头与盘片的物理接触。这意味着硬盘的头部和盘片都不会受到物理磨损。设计师在技术上投入了大量资金，以便在硬盘处于物理危险中时，自动且迅速地停放读写头，例如在硬盘被撞击或推挤时。如果没有这种技术，读写头会在这种情况下撞到磁盘并将其摧毁。
- en: '**Optical Discs**'
  id: totrans-200
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**光盘**'
- en: Optical discs are modern-day version of the Babylonian clay tablets seen in
    [Figure 1-5](ch01.xhtml#ch01fig5). Like those tablets, they’re solid objects with
    small cavities—known as pits—made in them to represent data, as shown in [Figure
    10-20](ch10.xhtml#ch10fig20). Like punch cards, they use binary encoding, so each
    location either contains a pit or doesn’t contain a pit. The pits are read using
    a laser, and their nanometer scales are comparable with the wavelengths of this
    laser light.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 光盘是现代版的巴比伦泥板，如[图1-5](ch01.xhtml#ch01fig5)所示。与这些泥板类似，光盘也是实心物体，表面有小的空洞—称为坑—用于表示数据，如[图10-20](ch10.xhtml#ch10fig20)所示。和穿孔卡片一样，光盘采用二进制编码，因此每个位置要么包含一个坑，要么不包含坑。这些坑通过激光读取，并且它们的纳米级尺寸与激光光线的波长相当。
- en: '![Image](../images/f0239-01.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0239-01.jpg)'
- en: '*Figure 10-20: Four generations of optical storage*'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-20：光盘存储的四个发展阶段*'
- en: '*LaserDisc* (1978) was the first optical disc, having a 12-inch diameter like
    a vinyl album and marketed for home video. *Compact discs*, or *CDs* (1982), used
    roughly 800 nm pits, read by a laser head, to store up to 700 MB of audio data.
    CDs started seeing use for general rather than audio data storage in 1988 with
    the *CD-ROM* specification. Like CDs, these became read-only after initially creating
    the pits on their surfaces. *CD-R* was a version that simplified the recording
    process, allowing home users to “burn” their own CD-ROMs, again only once. These
    were used in the late 1990s for copying audio music collections, first using CD
    audio representations and then using bulk MP3 storage. They were usually blue
    on the burnable side and gold on top. Their “burning” was a physical process involving
    lasers and heat; this is the origin of modern slang “burning” now used for writing
    to other types of ROM, such as flash or FPGA. *CD-RW* was an improved CD-ROM that
    could be rewritten several times.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '*激光光盘*（1978年）是第一种光盘，直径为12英寸，像黑胶唱片一样，并且主要用于家庭视频播放。*光盘*，或称*CD*（1982年），使用约800纳米的凹坑，通过激光头读取，用于存储最多700MB的音频数据。光盘在1988年开始用于一般数据存储，而不仅仅是音频数据存储，随着*CD-ROM*规范的出现。与光盘类似，这些光盘在初始刻录凹坑后变为只读。*CD-R*是简化录制过程的版本，允许用户在家中“刻录”自己的CD-ROM，且仅能刻录一次。这些光盘在1990年代后期被用于复制音频音乐收藏，最初使用CD音频格式，后来使用大容量MP3存储。它们通常在可刻录面为蓝色，顶部为金色。它们的“刻录”是一个物理过程，涉及激光和热量；这也是现代俚语“刻录”一词的来源，现在被用于写入其他类型的只读存储介质，如闪存或FPGA。*CD-RW*是改进版的CD-ROM，可以被多次重写。'
- en: '*Digital Versatile Disc (DVD)* (1995), was an order of magnitude improvement,
    reducing pit size to 400 nm to achieve disc capacity of up to 4.7GB using the
    same size physical disc as CDs. DVDs were initially used for video but soon also
    for general data. As with CDs, write-once DVD-R and rewritable DVD-RW were also
    developed. *Blu-ray* (like its short-lived competitor, HD-DVD) reduced the pit
    size again, this time to 150 nm, allowing storage up to 25GB on the same size
    disc. As these pits are smaller, they require shorter-wavelength blue rather than
    infrared or red laser light to read them, hence the name.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*数字多功能光盘（DVD）*（1995年），是一种数量级的改进，减小了凹坑的大小至400纳米，使得光盘容量可达到4.7GB，且使用与CD相同大小的物理光盘。DVD最初用于视频，但很快也用于一般数据存储。与CD类似，开发了可一次写入的DVD-R和可重写的DVD-RW。*蓝光光盘*（如同其短命竞争对手HD-DVD）再次减小了凹坑的大小，这次减小到150纳米，使得同样大小的光盘能够存储最多25GB的数据。由于这些凹坑较小，它们需要短波长的蓝色激光光来读取，而不是红外或红色激光，因此得名。'
- en: '*Solid-State Drives*'
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*固态硬盘*'
- en: For secondary storage, most current computers have moved from hard drives to
    *solid-state drives (SSDs)*. These are manufactured to have the same form factors
    and I/O interfaces, and similar capacities, as hard drives, but with no moving
    parts. This makes them faster, more reliable, lower power, quieter, smaller, and
    less prone to breakage when dropped. As there are no moving parts, they can be
    truly random access. SSDs are flash memory, as we’ve previously reviewed.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二级存储，大多数当前计算机已从硬盘驱动器转向*固态硬盘（SSDs）*。这些硬盘的制造方式使其具有与硬盘相同的外形尺寸和I/O接口，并且具有相似的存储容量，但没有活动部件。这使得它们更快、更可靠、功耗更低、噪音更小、更小巧，并且在掉落时不易损坏。由于没有活动部件，它们可以实现真正的随机访问。SSDs是闪存，如我们之前所回顾的。
- en: The same flash memory technology is also used as offline storage, where SSD
    drives are easily removable, such as when connected to I/O via USB (known as USB
    sticks) or SD (known as SD cards).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的闪存技术也被用于离线存储，其中SSD驱动器是易于移除的，例如通过USB（称为USB闪存）或SD卡（称为SD卡）连接到I/O时。
- en: Tertiary Memory
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第三存储
- en: '*Tertiary memory* is a recently proposed level in the memory hierarchy. It
    lies below secondary memory but above offline memory, and has been created to
    describe memories that used to be offline—requiring humans to physically load
    and eject media such as discs and tapes—but is now automated by mechanical processes.
    For example, automated Blu-ray and LTO tape jukeboxes as in [Figure 10-21](ch10.xhtml#ch10fig21)
    form tertiary memory.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*第三存储*是最近提出的内存层级中的一个新层级。它位于二级存储下方，但高于离线存储，旨在描述那些曾经是离线的内存——需要人类手动加载和弹出介质，如光盘和磁带——但现在通过机械过程自动化。例如，自动化的蓝光和LTO磁带机器人，正如在[图10-21](ch10.xhtml#ch10fig21)中所示，构成了第三存储。'
- en: '![Image](../images/f0240-01.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/f0240-01.jpg)'
- en: '*Figure 10-21: A robotic tape jukebox in a data center*'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-21：数据中心中的机器人磁带库*'
- en: In the figure, a robot arm is used—as in 1950s vinyl record jukeboxes—to pick
    up tapes and place them into the reader and storage containers. Similar robotic
    systems can be built around Blu-ray discs. Mobile robots driving baskets of hard
    disks around can now also be considered tertiary memory.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，使用了机器人臂——就像1950年代的黑胶唱片点唱机——来取放磁带并将其放入读写器和存储容器中。类似的机器人系统也可以围绕蓝光光盘构建。如今，驱动硬盘篮子的移动机器人也可以被视为第三层内存。
- en: Data Centers
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据中心
- en: When you put thousands, or tens or hundreds of thousands, of secondary and tertiary
    memories together in a warehouse-sized building, you get a *data center*. Search
    engines, social networks, online retailers, media streamers, and governments all
    now need to store and access data at this scale. A typical data center will contain
    many different layers of the lower levels of the memory hierarchy. For example,
    tapes take longer to fast-forward and rewind than disks, so these are more likely
    to be found as long-term backup systems than serving the latest social media posts.
    Once you access something from a slower backup system, it will then be cached
    somewhere higher up the memory hierarchy, such as on an SSD drive, making for
    faster retrieval next time.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将成千上万，甚至是数十万或数百万个辅助和第三层内存放在一个仓库大小的建筑物里时，你就得到了一个*数据中心*。搜索引擎、社交网络、在线零售商、媒体流媒体提供商和政府如今都需要以这种规模存储和访问数据。一个典型的数据中心将包含许多不同层次的低级内存结构。例如，磁带比磁盘更耗时进行快进和倒带，因此它们更可能作为长期备份系统而不是用于提供最新的社交媒体帖子。一旦你从较慢的备份系统中访问数据，它将被缓存到内存层次结构中更高的地方，比如SSD硬盘，这样下次检索就会更快。
- en: Data centers may be built with extreme security and resilience in mind. For
    example, HSBC’s literal “data mine” is widely believed to store backups of all
    its global financial data in a former UK coal mine. You can tell it’s a data center
    because there are huge air ducts rising out of the ground to disperse all the
    heat from the computers. The mine is thought to be robust to nuclear, chemical,
    and biological attack. In the event of a nuclear war, the rest of humanity may
    be bombed back to computing with Ishango bones, but the bank will still be able
    to come after your mortgage repayments.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心可能会以极高的安全性和韧性为设计目标。例如，汇丰银行的“数据矿”被广泛认为将其全球金融数据的备份存储在英国的一个废弃煤矿中。你可以通过地面上升的巨大空气管道辨认出它是一个数据中心，这些管道用于散热。该矿据说能抵御核、化学和生物攻击。在核战争爆发时，其他人类可能会被迫回到用伊尚戈骨头进行计算，但这家银行仍然能够追讨你的抵押贷款偿还。
- en: Summary
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结
- en: 'Memory architecture is driven by economics: you can buy big, slow, cheap memory;
    small, fast, expensive memory; or some mixture of both. Empirically, most programs
    show spatial, sequential, and temporal locality, in which different small parts
    of memory tend to be in heavy, repeated use at different times. Memory architectures
    are thus designed in hierarchies that fit both the economics and usage patterns,
    including caches between layers to promote currently in-use memory to higher levels.
    Primary memory is that which is addressed directly by the CPU, using the bus,
    while secondary memory is connected via I/O. Secondary memory often takes the
    form of spinning disks, which can be disconnected and replaced, becoming offline
    memory if humans are involved or tertiary memory if the process is automated by
    robotics.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 内存架构受到经济因素的驱动：你可以购买大而慢、便宜的内存；小而快、昂贵的内存；或者两者的混合。经验表明，大多数程序表现出空间、顺序和时间局部性，其中不同的小部分内存在不同的时间会被频繁和反复使用。因此，内存架构以适应经济和使用模式的层次结构设计，包括各层之间的缓存，以将当前使用的内存提升到更高层级。主内存是由CPU直接寻址的内存，通过总线进行访问，而辅助内存则通过I/O连接。辅助内存通常以旋转磁盘的形式存在，可以断开并更换，如果涉及到人工操作，则成为离线内存，如果过程由机器人自动化，则为第三层内存。
- en: Exercises
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习
- en: '**Your Computer’s Memory**'
  id: totrans-220
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**你计算机的内存**'
- en: Try to find the sizes and speeds for each type of memory in your own computer,
    including caches, RAM, and secondary storage. If you can open up your computer,
    look inside, locate them, and find their makes and model numbers, then look up
    their datasheets online. Most operating systems have utilities that will display
    useful information about their memory; for example, Linux will show caches with
    `lscpu` `or cat /proc/cpuinfo`, RAM with `free -h`, and secondary memory with
    `lsblk`.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试查找自己计算机中每种内存的大小和速度，包括缓存、RAM 和二级存储。如果你能打开电脑，查看内部并找到它们的品牌和型号，然后在网上查找它们的技术规格。大多数操作系统都有可以显示内存有用信息的工具；例如，Linux
    可以使用 `lscpu` 或 `cat /proc/cpuinfo` 查看缓存，使用 `free -h` 查看 RAM，使用 `lsblk` 查看二级存储。
- en: '**Building a Static RAM in LogiSim**'
  id: totrans-222
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**在 LogiSim 中构建静态 RAM**'
- en: Build the static random-access memory (SRAM) presented in [Figure 6-22](ch06.xhtml#ch06fig22)
    in LogiSim. It should be able to store and read 2-bit words at the four memory
    locations.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 LogiSim 中构建 [图 6-22](ch06.xhtml#ch06fig22) 所示的静态随机存取存储器（SRAM）。它应能在四个内存位置存储并读取
    2 位字。
- en: Extend your LogiSim SRAM to have longer words and more addresses.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展你的 LogiSim SRAM，使其具有更长的字长和更多的地址。
- en: '**Challenging**'
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**挑战**'
- en: Make four copies of your SRAM, representing multiple RAM chips. Each one will
    have the same address space, starting from address zero. Design a memory controller
    module that converts addresses from a larger global address space—having two extra
    bits—to sections of particular RAM chips and these local addresses within them.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制作四个 SRAM 副本，表示多个 RAM 芯片。每个副本将具有相同的地址空间，从地址零开始。设计一个内存控制器模块，将来自更大全局地址空间（具有两个额外位）的地址转换为特定
    RAM 芯片的部分以及这些 RAM 内部的本地地址。
- en: Try attaching this system to the Manchester Baby model in place of its previous
    LogiSim RAM.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试将该系统连接到曼彻斯特婴儿计算机模型中，替换其原有的 LogiSim RAM。
- en: '**More Challenging**'
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**更具挑战性**'
- en: Design and build a direct-mapped cache in LogiSim and link it to your LogiSim
    RAM from the previous task. (This won’t speed up that RAM, as it’s already fast
    SRAM, but it could then enable that SRAM to be replaced by a larger and cheaper,
    but slower, DRAM.)
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 LogiSim 中设计并构建一个直接映射缓存，并将其与之前任务中的 LogiSim RAM 连接起来。（这不会加速该 RAM，因为它已经是快速的 SRAM，但它可以让该
    SRAM 被更大、更便宜但较慢的 DRAM 所替代。）
- en: Try to build the other types of cache too, if you’re feeling brave. Use the
    sketches provided in this chapter as starting points.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你觉得有挑战，可以尝试构建其他类型的缓存。使用本章提供的示意图作为起点。
- en: Further Reading
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 延伸阅读
- en: For a definitive recent classic on memory, see U. Drepper, “What Every Programmer
    Should Know About Memory,” November 21, 2007, *[https://people.freebsd.org/~lstewart/articles/cpumemory.pdf](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf)*.
    In fact, this resource contains far more than any normal human should know about
    memory.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解关于内存的最新经典资料，请参考 U. Drepper 的文章《每个程序员应该了解的内存知识》，2007 年 11 月 21 日，* [https://people.freebsd.org/~lstewart/articles/cpumemory.pdf](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf)
    *。事实上，这篇文章包含了关于内存的知识，远超任何正常人所需了解的内容。
