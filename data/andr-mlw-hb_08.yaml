- en: '**5'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**5'
- en: MACHINE LEARNING FUNDAMENTALS**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习基础**
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: In the early days of the Android eco-system, defenders analyzed apps manually
    to determine whether they were malicious. This technique was feasible at the time
    because the operating system’s market share was small and, initially, few apps
    were developed for it. However, things have changed. Recent official reports show
    that more than 100,000 Android APKs are released each month on Google Play. Our
    own estimates suggest that the actual number is significantly higher.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在Android生态系统的早期，防御者通过手动分析应用程序来判断它们是否为恶意软件。这个技术在当时是可行的，因为操作系统的市场份额较小，且最初为其开发的应用程序不多。然而，情况已经发生了变化。最近的官方报告显示，每月有超过10万个Android
    APK文件在Google Play上发布。我们自己的估计表明，实际数字要高得多。
- en: It is no longer possible for companies to manually assess the security level
    of so many diverse apps. Initially, analysts solved this problem by relying on
    human-identified patterns present exclusively in malware. They wrote detection
    rules, using YARA or other tools, to flag applications containing such patterns.
    This approach failed to scale, however, as it quickly became infeasible for analysts
    to keep track of the features present in millions of apps.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，公司不再可能手动评估如此多种类繁多的应用程序的安全级别。最初，分析师通过依赖人类识别的仅存在于恶意软件中的模式来解决这个问题。他们编写了检测规则，使用YARA或其他工具，标记包含这些模式的应用程序。然而，这种方法无法扩展，因为分析师很快就发现，追踪数百万个应用程序中出现的特征变得不再可行。
- en: Instead, analysts began using machine learning algorithms, which have the ability
    to perform these tasks on a large number of applications without explicit programming
    by learning through examples. This approach proved vastly more efficient, and
    reduced the burden on human analysts. This chapter introduces the machine learning
    basics you’ll need to be familiar with in order to understand the material presented
    in the book’s remaining chapters, with a focus on the classification algorithms
    popular in malware detection. Readers already familiar with the topic can skip
    ahead.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，分析师开始使用机器学习算法，这些算法能够在没有明确编程的情况下，通过学习示例对大量应用程序执行这些任务。这种方法证明效率更高，减轻了人工分析师的负担。本章介绍了你需要熟悉的机器学习基础知识，以便理解本书其余章节中展示的内容，重点介绍了在恶意软件检测中流行的分类算法。已经熟悉该主题的读者可以跳过此部分。
- en: '**How Machine Learning for Malware Analysis Works**'
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**机器学习在恶意软件分析中的应用原理**'
- en: In malware analysis, we most often use machine learning methods to classify
    apps as benign, malicious, or, in some cases, possibly malicious. At a deeper
    level, more sophisticated methods can provide increasingly fine-grained labels
    that identify apps as a specific type of malware, like spyware, banking trojans,
    and so on. Given the support that automated methods provide, security analysts
    can focus on examining *gray zone* apps, or those that aren’t accurately classified
    as either goodware or malware. Machine learning significantly reduces the number
    of apps that analysts have to manually review.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在恶意软件分析中，我们最常使用机器学习方法将应用程序分类为良性、恶意，或者在某些情况下，可能是恶意的。从更深的层次来看，更复杂的方法可以提供越来越细致的标签，识别出应用程序属于特定类型的恶意软件，例如间谍软件、银行木马等。鉴于自动化方法提供的支持，安全分析师可以专注于检查*灰色区域*的应用程序，或者那些不能准确归类为良性软件或恶意软件的应用程序。机器学习大大减少了分析师需要手动审查的应用程序数量。
- en: Machine learning algorithms can be either supervised or unsupervised. *Supervised*
    algorithms require labeled datasets, while *unsupervised* algorithms learn patterns
    inherent in the data. Classification algorithms are the most common type of supervised
    algorithms, while clustering and anomaly detection are common examples of unsupervised
    algorithms. Each has its own purpose in security-related machine learning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法可以是有监督的或无监督的。*有监督*算法需要带标签的数据集，而*无监督*算法则通过学习数据中的内在模式来工作。分类算法是最常见的有监督算法，而聚类和异常检测是无监督算法的常见例子。每种算法在与安全相关的机器学习中都有其独特的用途。
- en: '*Classification* algorithms, also called *classifiers*, consider information
    about an entity, such as an app, a picture, or a user account, and place it into
    one or more classes. For example, in the case of an Android app, we might have
    two classes of interest: malware and goodware. But if we want to classify something
    else—for instance, Instagram accounts—we might have many more classes: *child*
    for those younger than 18, *young adult* for those 18–40 years old, *middle-aged*
    for those 41–65 years old, and *senior* for those 66 years old or older. Engineers
    working on the classification problem define the exact number of categories and
    the meaning of each. One challenge is that classification algorithms often require
    a large number of labeled samples (already classified samples that the algorithm
    can learn from) to produce accurate models, which might not always be available.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*分类*算法，也叫*分类器*，会考虑一个实体的信息，比如应用、图片或用户帐户，并将其划分到一个或多个类别中。例如，在Android应用的情况下，我们可能有两个感兴趣的类别：恶意软件和良性软件。但如果我们要对其他内容进行分类——例如Instagram帐户——我们可能会有更多的类别：*未成年*适用于18岁以下的人，*年轻成人*适用于18-40岁的人，*中年*适用于41-65岁的人，*老年*适用于66岁或以上的人。处理分类问题的工程师会定义类别的确切数量和每个类别的含义。一个挑战是，分类算法通常需要大量的标签样本（算法可以学习的已分类样本）来生成准确的模型，而这些样本并不总是可用的。'
- en: '*Clustering* algorithms take information from multiple entities and group similar
    samples into clusters. For instance, malicious developers often create multiple
    versions of their malware over time as they look for ways to avoid detection or
    add new functionality. In such cases, clusters might correspond to different versions
    of the same malware family. Clustering algorithms need a way to measure the similarity
    of or distance between the entities under observation, and domain experts are
    responsible for defining how that similarity will be computed based on the clustering
    goal.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*聚类*算法从多个实体中获取信息，并将相似的样本分组到簇中。例如，恶意开发者通常会随着时间的推移创建多个版本的恶意软件，以寻找避开检测或添加新功能的方法。在这种情况下，簇可能对应于同一恶意软件家族的不同版本。聚类算法需要一种方法来衡量观察实体之间的相似性或距离，领域专家负责定义如何根据聚类目标计算这种相似性。'
- en: While clustering algorithms don’t require labeled data, the clusters they produce
    can be hard to interpret if the algorithm isn’t aware of what the analyst is looking
    for. Malware and goodware often share SDKs and libraries, which might confuse
    the clustering system, causing it to group malware and goodware together merely
    because they share an SDK.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然聚类算法不需要标签数据，但如果算法不知道分析师正在寻找什么，那么它生成的聚类可能难以解释。恶意软件和良性软件经常共享SDK和库，这可能会混淆聚类系统，导致它仅仅因为共享一个SDK而将恶意软件和良性软件归为一类。
- en: '*Anomaly detection* or *outlier detection* algorithms try to identify entities
    that are substantially different from almost all others in a given dataset. For
    instance, efforts have been made to find malicious apps by checking whether their
    behavior differs substantially from the norm. However, a challenge for Android
    malware detection in particular is that most malware operates within the bounds
    of the Android security model, asking unwitting victims for permission to execute
    malicious actions. Is an app that sends all of your texts to a remote server some
    kind of spyware, or is it an SMS backup app? Anomaly detection algorithms may
    have a hard time distinguishing between these two cases.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*异常检测*或*离群点检测*算法尝试识别在给定数据集中与几乎所有其他实体明显不同的实体。例如，曾经有过通过检查应用程序行为是否与常规行为显著不同来寻找恶意应用的努力。然而，特别是在Android恶意软件检测中，一个挑战是，大多数恶意软件都在Android安全模型的范围内运行，请求毫不知情的受害者授权执行恶意行为。一个将所有短信发送到远程服务器的应用程序是间谍软件，还是一个短信备份应用程序？异常检测算法可能很难区分这两种情况。'
- en: 'As it turns out, the vast majority of successful efforts to use machine learning
    in malware detection have relied on classification algorithms. However, some techniques
    use a mix of clustering and classification in an attempt to identify the family
    to which a given malware sample belongs, such as the system proposed in “EC2:
    Ensemble Clustering and Classification for Predicting Android Malware Families”
    by Tanmoy Chakraborty et al.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，绝大多数成功将机器学习应用于恶意软件检测的努力都依赖于分类算法。然而，一些技术尝试通过混合使用聚类和分类来识别给定恶意软件样本所属的家族，例如Tanmoy
    Chakraborty等人提出的“EC2：集成聚类与分类预测Android恶意软件家族”系统。
- en: '***Identifying App Features***'
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***识别应用特征***'
- en: Most machine learning algorithms assume that each entity of interest has an
    associated *feature vector*, which is an ordered list of values belonging to important
    properties of the entity being studied. In the case of malware analysis, the entities
    of interest are the apps themselves. The feature vector includes attributes derived
    from the analysis of the APK or the app in execution and can be either handcrafted
    or automatically generated.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习算法假设每个感兴趣的实体都有一个相关的*特征向量*，这是一个有序的值列表，包含与正在研究的实体的重要属性。在恶意软件分析的情况下，感兴趣的实体是应用本身。特征向量包括从APK分析或应用执行中提取的属性，这些特征可以是手工制作的，也可以是自动生成的。
- en: For the purposes of malware detection and classification, features might relate
    to whether or not the app requests a specific permission (such as permission to
    read incoming texts), whether or not the code contains encrypted portions, whether
    or not the code tries to connect to an external server, and so forth. For each
    of these questions, the feature is set to 1 if the answer is yes and 0 otherwise.
    Other features may have *non-binary* values. For instance, we might have a feature
    corresponding to the number of times an app’s source code calls a given package
    in the Android API. Machine learning methods use these features to identify and
    classify entities. [Chapter 6](ch06.xhtml) will describe various types of features
    that are important to the analysis of Android malware.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在恶意软件检测与分类的过程中，特征可能与应用是否请求特定权限（例如读取接收短信的权限）、代码中是否包含加密部分、代码是否尝试连接外部服务器等相关。对于这些问题，如果答案是肯定的，则特征设为1，否则设为0。其他特征可能具有*非二元*值。例如，我们可能会有一个特征，表示应用源代码中调用Android
    API中某个包的次数。机器学习方法利用这些特征来识别和分类实体。[第6章](ch06.xhtml)将描述在安卓恶意软件分析中重要的各种特征类型。
- en: The content of an Android app alone provides a seemingly unlimited number of
    potential features, but we don’t have to limit the feature set to data found inside
    the APK. In fact, there is surprising value in connecting features from APK files
    to external information. For example, in the case of an app that connects to a
    certain domain, we could turn the Whois information for that domain into features.
    Similarly, if an app connects to a certain IP address, we can pull in information
    about who owns the IP address, the datacenter that serves it, the country where
    the associated server is located, or even information from the server itself,
    such as the operating system it runs or the other software it hosts.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 安卓应用的内容本身提供了看似无限数量的潜在特征，但我们不必仅限于APK内部的数据作为特征集。事实上，将APK文件中的特征与外部信息相连接，往往能带来意想不到的价值。例如，对于一个连接到特定域名的应用，我们可以将该域名的Whois信息转化为特征。类似地，如果一个应用连接到某个IP地址，我们可以获取有关该IP地址的所有者、为其提供服务的数据中心、服务器所在的国家，甚至是来自服务器本身的信息，例如它运行的操作系统或它托管的其他软件。
- en: To give another example, if an app sends messages to a premium SMS number, we
    might be able to determine which mobile carrier owns that number and what commercial
    entity has it registered in partnership with the mobile carrier. The developers
    of the machine learning system can choose to include these pieces of information
    as features to characterize certain malware families and developers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是，如果一个应用向一个高级短信号码发送信息，我们可能能够确定哪个移动运营商拥有该号码，以及该号码与该运营商合作注册的商业实体。机器学习系统的开发者可以选择将这些信息作为特征，来表征某些恶意软件家族和开发者。
- en: '***Creating Training Sets***'
  id: totrans-19
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***创建训练集***'
- en: A *training sample* for a classification algorithm is a computational object
    consisting of a feature vector and a class label. In formal terms, we say that
    it consists of a pair (*f* , *c*) where *f* is a feature vector and *c* is the
    class to which we believe the sample belongs. Note that in Android malware analysis,
    for an app to be a training sample we must already know its class (for instance,
    malware or goodware).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*训练样本*对于分类算法来说是一个计算对象，由特征向量和类别标签组成。从正式的角度来看，我们可以说它由一对(*f* , *c*)组成，其中*f*是特征向量，*c*是我们认为样本所属的类别。请注意，在安卓恶意软件分析中，要使一个应用成为训练样本，我们必须已经知道它的类别（例如，恶意软件或良性软件）。
- en: A *training set* is a finite set of training samples. We can usually represent
    it as a table or spreadsheet. In the case of the malware versus goodware classification,
    the rows in the table would correspond to apps and the columns would correspond
    to various features. A special column would represent the label or class; that
    is, whether the app in a given row is malware (set to 1) or goodware (set to 0).
    [Table 5-1](ch05.xhtml#ch5tab1) shows a small sample training set associated with
    Android apps.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*训练集*是一个有限的训练样本集合。我们通常可以将其表示为一个表格或电子表格。在恶意软件与良性软件分类的情况下，表格中的行对应于应用程序，列对应于各种特征。一个特殊的列代表标签或类别；也就是说，给定行中的应用程序是恶意软件（设置为1）还是良性软件（设置为0）。[表
    5-1](ch05.xhtml#ch5tab1)展示了与安卓应用程序相关的小样本训练集。'
- en: 'In this training set, we show only two features, for the sake of simplicity.
    The *telephony* feature captures the number of calls made to the *android.telephony.cdma*
    package by the app, and the *app* feature does the same for the *android.app*
    package. For instance, the app shown in the first row of [Table 5-1](ch05.xhtml#ch5tab1)
    makes 27 calls in its source code to classes in the *telephony* package and 2,655
    calls to classes in the *app* API package. This app is malware: we see that its
    value in the Label column is 1.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个训练集中，为了简化起见，我们只展示了两个特征。*电信*特征捕获了应用程序对*android.telephony.cdma*包发出的呼叫次数，而*应用程序*特征则捕获了对*android.app*包的调用次数。例如，在[表
    5-1](ch05.xhtml#ch5tab1)的第一行中显示的应用程序，其源代码中对*电信*包中的类进行了27次调用，对*应用程序*API包中的类进行了2,655次调用。这个应用程序是恶意软件：我们可以看到其标签列中的值为1。
- en: Each app in this training set can be thought of as a point on a scatter plot.
    For instance, we could position the first app in the table at the coordinate (27,2655).
    In [Figure 5-1](ch05.xhtml#ch5fig1), we depict it using a cross because it is
    malware. We denote goodware using dots. As you can see, an app’s feature vector
    determines its location in this feature space.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该训练集中的每个应用程序可以看作是散点图上的一个点。例如，我们可以将表中的第一个应用程序定位到坐标(27,2655)。在[图 5-1](ch05.xhtml#ch5fig1)中，我们用一个叉号表示它，因为它是恶意软件。我们用点表示良性软件。正如你所看到的，应用程序的特征向量决定了它在这个特征空间中的位置。
- en: Of course, in the real world, analysts might use a much larger training set
    (one with thousands of apps). The number of features might also be in the hundreds,
    thousands, or higher.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在现实世界中，分析人员可能会使用一个更大的训练集（包含成千上万的应用程序）。特征的数量可能也会达到数百、数千甚至更多。
- en: Creating good training sets is challenging. Training sets should ideally be
    vast and diverse, and their data, particularly their labels, must be as accurate
    as possible. For malware analysis, this poses a problem. How does one put together
    an accurately labeled set of thousands of malware and goodware apps without many
    months of careful and costly manual research and analysis?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 创建良好的训练集是具有挑战性的。理想情况下，训练集应该庞大且多样化，并且其数据，特别是标签，必须尽可能准确。对于恶意软件分析来说，这提出了一个问题。如何在没有几个月精心且昂贵的人工研究和分析的情况下，整理出一套精确标注的包含成千上万的恶意软件和良性软件的应用程序集？
- en: '**Table 5-1:** Simple Training Set'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-1：** 简单训练集'
- en: '| **The telephony feature** | **The app feature** | **Sample name** | **Label**
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| **电信特征** | **应用程序特征** | **样本名称** | **标签** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 27 | 2655 | 14292932679d6930f521a21de4e8bffd.apk | 1 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 27 | 2655 | 14292932679d6930f521a21de4e8bffd.apk | 1 |'
- en: '| 3 | 1764 | 04276665aaa3725ea34097c4c874873c.apk | 1 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1764 | 04276665aaa3725ea34097c4c874873c.apk | 1 |'
- en: '| 3 | 870 | e8290db04c7004ec8bb53f7cda155eb9.apk | 1 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 870 | e8290db04c7004ec8bb53f7cda155eb9.apk | 1 |'
- en: '| 3 | 2086 | 03f9eff3229e3a4eefc9224f916202b8.apk | 1 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 2086 | 03f9eff3229e3a4eefc9224f916202b8.apk | 1 |'
- en: '| 3 | 329 | 1c4e357a8ec5f13de4ffd57cc2711afe.apk | 1 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 329 | 1c4e357a8ec5f13de4ffd57cc2711afe.apk | 1 |'
- en: '| 3 | 1499 | 080b0ed2d9bf87e9f3d061a1ba48da33.apk | 1 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1499 | 080b0ed2d9bf87e9f3d061a1ba48da33.apk | 1 |'
- en: '| 27 | 2652 | 08026e2b63ec51cb36bc6cff00c28909.apk | 1 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 27 | 2652 | 08026e2b63ec51cb36bc6cff00c28909.apk | 1 |'
- en: '| 27 | 2637 | 094f67a3a682a0cd4305d720cc786e00.apk | 1 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 27 | 2637 | 094f67a3a682a0cd4305d720cc786e00.apk | 1 |'
- en: '| 3 | 877 | 3a895a2d19f040d7826e68c2f9596c55.apk | 1 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 877 | 3a895a2d19f040d7826e68c2f9596c55.apk | 1 |'
- en: '| 3 | 2163 | 1a7409b8e0f6cc299a4ac0b9ca67856e.apk | 1 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 2163 | 1a7409b8e0f6cc299a4ac0b9ca67856e.apk | 1 |'
- en: '| 1 | 2016 | Starbucks_2020-10-22_16_06_36.apk | 0 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2016 | Starbucks_2020-10-22_16_06_36.apk | 0 |'
- en: '| 1 | 1823 | Starbucks_2017-09-29_16_05_56.apk | 0 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1823 | Starbucks_2017-09-29_16_05_56.apk | 0 |'
- en: '| 6 | 6604 | TikTok_2020-12-03_19_11_34.apk | 0 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 6604 | TikTok_2020-12-03_19_11_34.apk | 0 |'
- en: '| 6 | 6604 | TikTok_2020-12-03_19_17_05.apk | 0 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 6604 | TikTok_2020-12-03_19_17_05.apk | 0 |'
- en: '| 1 | 11483 | Walgreens_2020-11-21_21_45_17.apk | 0 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 11483 | Walgreens_2020-11-21_21_45_17.apk | 0 |'
- en: '| 1 | 1555 | Starbucks_2016-01-19_16_04_34.apk | 0 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1555 | Starbucks_2016-01-19_16_04_34.apk | 0 |'
- en: '| 1 | 1738 | Starbucks_2016-09-08_16_02_23.apk | 0 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1738 | Starbucks_2016-09-08_16_02_23.apk | 0 |'
- en: '| 1 | 11483 | Walgreens_2020-11-21_21_46_22.apk | 0 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 11483 | Walgreens_2020-11-21_21_46_22.apk | 0 |'
- en: '| 1 | 1384 | Starbucks_2015-12-07_16_07_02.apk | 0 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1384 | Starbucks_2015-12-07_16_07_02.apk | 0 |'
- en: '| 1 | 1812 | Starbucks_2017-09-26_16_02_39.apk | 0 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1812 | Starbucks_2017-09-26_16_02_39.apk | 0 |'
- en: '![Image](../images/ch05fig01.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch05fig01.jpg)'
- en: '*Figure 5-1: A visualization of the training set as a scatter plot*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-1：训练集的可视化散点图*'
- en: Fortunately, academic researchers have released a few training sets for Android
    malware analysis, of which three are well known. The *Drebin* dataset contains
    5,560 applications from 179 different malware families collected between August
    2010 and October 2012\. You can find it at [*https://www.sec.cs.tubs.de/danarp/drebin*](https://www.sec.cs.tu-bs.de/~danarp/drebin).
    The *AndroZoo* dataset is a growing collection of Android applications that currently
    contains over 17 million APKs, each of which has been analyzed by different antivirus
    products. You can find it at [*https://androzoo.uni.lu*](https://androzoo.uni.lu).
    The *CCCS-CIC-AndMal-2020* dataset contains 200,000 benign samples and 200,000
    malicious ones drawn from 191 prominent malware families. The dataset can be found
    at [*https://www.unb.ca/cic/datasets/andmal2020.html*](https://www.unb.ca/cic/datasets/andmal2020.html).
    If one of these websites goes offline in the future, we’ll publish the samples
    at [*https://github.com/android-malware-ml-book*](https://github.com/android-malware-ml-book)
    so long as there is no legal impediment to doing so.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，学术研究人员已经发布了一些用于 Android 恶意软件分析的训练集，其中有三个是比较著名的。*Drebin* 数据集包含了来自 179 个不同恶意软件家族的
    5,560 个应用程序，这些应用程序收集于 2010 年 8 月到 2012 年 10 月之间。你可以在 [*https://www.sec.cs.tubs.de/danarp/drebin*](https://www.sec.cs.tu-bs.de/~danarp/drebin)
    找到它。*AndroZoo* 数据集是一个不断增长的 Android 应用程序集合，目前包含超过 1700 万个 APK，每个 APK 都已经通过不同的 antivirus
    产品进行分析。你可以在 [*https://androzoo.uni.lu*](https://androzoo.uni.lu) 找到它。*CCCS-CIC-AndMal-2020*
    数据集包含 200,000 个良性样本和 200,000 个恶意样本，来自 191 个知名恶意软件家族。数据集可以在 [*https://www.unb.ca/cic/datasets/andmal2020.html*](https://www.unb.ca/cic/datasets/andmal2020.html)
    找到。如果这些网站未来无法访问，我们会在 [*https://github.com/android-malware-ml-book*](https://github.com/android-malware-ml-book)
    上发布样本，只要没有法律障碍。
- en: '***Using Classification Algorithms***'
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***使用分类算法***'
- en: Classification algorithms take a training set as input and try to find some
    condition such that, when the condition is true for a given app’s feature vector,
    the probability that it is malicious is very high, whereas when the condition
    is false, the probability that the app is malicious is very low.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 分类算法将训练集作为输入，并试图找到一个条件，使得当这个条件对某个应用程序的特征向量为真时，应用程序是恶意软件的概率非常高，而当条件为假时，应用程序是恶意软件的概率非常低。
- en: For instance, if you consider [Figure 5-2](ch05.xhtml#ch5fig2), you’ll see that
    the condition of an app calling the *app* package fewer than 3,000 times does
    the job. All apps that satisfy this condition are malware (crosses), while all
    apps that don’t satisfy it are goodware (dots). In this case, the horizontal line
    at the 3,000 API calls mark splits the feature space into these two parts.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你查看 [图 5-2](ch05.xhtml#ch5fig2)，你会看到，当应用程序调用 *app* 包少于 3,000 次时，条件成立。所有满足这个条件的应用程序是恶意软件（叉号），而所有不满足该条件的应用程序是良性软件（圆点）。在这种情况下，位于
    3,000 次 API 调用标记处的水平线将特征空间分为这两个部分。
- en: '![Image](../images/ch05fig02.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch05fig02.jpg)'
- en: '*Figure 5-2: Two possible separators for the training set shown in [Figure
    5-1](ch05.xhtml#ch5fig1)*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-2：训练集的两种可能分隔线，如 [图 5-1](ch05.xhtml#ch5fig1) 所示*'
- en: However, this is not the only possible separator. We could just as easily have
    selected the dashed line shown in the plot. This line is *y* = 40*x* + 2,000,
    where *x* = *APIPackage:android.telephony.cdma* and *y* = *APIPackage:android.app*.
    All points above this line are goodware, and all points below it are malware.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不是唯一可能的分隔线。我们同样可以选择图中显示的虚线。这条线为 *y* = 40*x* + 2,000，其中 *x* = *APIPackage:android.telephony.cdma*
    和 *y* = *APIPackage:android.app*。所有在这条线之上的点是良性软件，而所有在其下方的点是恶意软件。
- en: At this point, you might have a number of questions. Should separators always
    split the feature space into two parts, as shown in this figure? Should separators
    always be linear, or can they include circles, ellipses, or other, even weirder
    shapes? [Figure 5-3](ch05.xhtml#ch5fig3) shows a situation in which the data is
    grouped into different regions, some containing goodware and some containing malware.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 到这个阶段，你可能会有很多问题。分隔符是否总是像图中所示那样将特征空间分割成两部分？分隔符是否必须总是线性的吗，还是可以包括圆形、椭圆形或其他更奇怪的形状？[图
    5-3](ch05.xhtml#ch5fig3)显示了一个情况，其中数据被分组为不同的区域，一些区域包含良性软件，另一些区域包含恶意软件。
- en: '![Image](../images/ch05fig03.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch05fig03.jpg)'
- en: '*Figure 5-3: Rectangular separators for the training set shown in [Figure 5-1](ch05.xhtml#ch5fig1)*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-3：在[图 5-1](ch05.xhtml#ch5fig1)中显示的训练集的矩形分隔符*'
- en: One potential problem here is that large parts of the feature space aren’t part
    of either a goodware or malware region, which might make sense, as no samples
    from those parts of the feature space have ever been seen before. In the next
    section, you’ll learn that classification algorithms can take various approaches
    to sorting their samples.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里一个潜在的问题是，特征空间的大部分区域既不属于良性软件区，也不属于恶意软件区，这可能是有道理的，因为从这些特征空间区域中从未见过样本。在下一节中，你将学习到分类算法可以采用不同的方法来排序它们的样本。
- en: '**Classification Algorithms**'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**分类算法**'
- en: In this section, we’ll discuss some well-known classification methods. As you
    will see, classifiers work in different ways.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将讨论一些著名的分类方法。正如你将看到的，分类器的工作方式各不相同。
- en: '***Decision Trees***'
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***决策树***'
- en: A decision tree classification algorithm builds a tree, each node of which compares
    a single feature with a single value. Thus, each path of the tree corresponds
    to a complex logical “and” condition, along with a class label showing the class
    that best matches that condition. Suppose we are given a training set *T* whose
    feature vectors are drawn from an *n*-dimensional space. The samples are Android
    apps that we want to classify into two classes, goodware and malware. To accomplish
    this, we would give each app *a* an associated feature vector *f*[*a*] consisting
    of *n* features. [Figure 5-4](ch05.xhtml#ch5fig4) shows a sample decision tree
    for classifying the apps.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树分类算法构建一棵树，每个节点将一个特征与一个特定值进行比较。因此，树的每一条路径都对应一个复杂的逻辑“与”条件，以及一个显示最佳匹配该条件的类别标签。假设我们给定了一个训练集*T*，其特征向量来自一个*n*维空间。这些样本是我们希望分类为良性软件和恶意软件的Android应用。为了实现这一点，我们会为每个应用*a*提供一个关联的特征向量*f*[*a*]，它由*n*个特征组成。[图
    5-4](ch05.xhtml#ch5fig4)显示了一个用于分类应用的示例决策树。
- en: '![Image](../images/ch05fig04.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch05fig04.jpg)'
- en: '*Figure 5-4: A sample decision tree*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-4：示例决策树*'
- en: 'Each node in a decision tree implicitly represents a subset of the training
    set. For instance, the root of the decision tree shown in [Figure 5-4](ch05.xhtml#ch5fig4)
    represents a training set of 1,000 apps. Each node includes a Boolean condition
    that splits the set into two disjoint sets: one consisting of all members that
    satisfy the condition and one consisting of all members that do not. For example,
    in the root node, the condition checks whether the number of calls to the opcode
    `iget-boolean` is less than or equal to 1989.5\. This opcode reads a Boolean instance
    field from registers and is expressed as bytecode in *Dalvik format*, which is
    the instruction set used by Android runtimes. All apps that satisfy this condition
    are associated with the left child of the root node, while those that do not satisfy
    the condition end up in the set of apps associated with the right child.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树中的每个节点都隐式地表示训练集的一个子集。例如，[图 5-4](ch05.xhtml#ch5fig4)中显示的决策树的根节点代表一个包含1,000个应用的训练集。每个节点包括一个布尔条件，将集合分成两个不相交的子集：一个包含所有满足条件的成员，另一个包含所有不满足条件的成员。例如，在根节点中，条件检查是否“iget-boolean”操作码的调用次数小于或等于1989.5。这个操作码从寄存器读取布尔实例字段，并以*Dalvik格式*的字节码表示，这是Android运行时使用的指令集。所有满足此条件的应用会与根节点的左子节点关联，而那些不满足条件的应用会被归类到与右子节点关联的应用集合中。
- en: The nodes also contain some other information to help us classify the apps as
    malicious or benign. For instance, if you look at the root node, you’ll see the
    number of samples, 1,000, and that each of the two classes (goodware followed
    by malware) contains 500 apps. Because there is a 50-50 split at the root node,
    this node can be labeled using either class. In this case, we’ve opted to call
    it goodware. Look now at the left child of the root node. We see that it contains
    519 apps. (That is, 519 samples from the training set satisfied the condition
    in the root node.) From the *Value* field, we see that 39 of these 519 apps are
    goodware, while the remaining 480 are malware. This node is therefore marked as
    malware, because that is how we classify the majority of its apps.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这些节点还包含一些其他信息，帮助我们将应用程序分类为恶意或良性。例如，如果你查看根节点，你会看到样本数量为1,000，并且两个类别（先是良性软件，再是恶意软件）各包含500个应用程序。因为根节点的分类是50-50的分布，所以该节点可以使用任意一个类别进行标记。在这种情况下，我们选择将其标记为良性软件。现在看一下根节点的左子节点。我们看到它包含519个应用程序。（也就是说，来自训练集的519个样本满足根节点的条件。）从*Value*字段，我们看到这519个应用程序中有39个是良性软件，而剩下的480个是恶意软件。因此，这个节点被标记为恶意软件，因为它的大多数应用程序属于这个类别。
- en: 'Now, two questions naturally arise. First, how does the decision tree algorithm
    decide what condition to choose at each node in the tree? And second, what is
    the *Gini* field shown in the nodes in [Figure 5-4](ch05.xhtml#ch5fig4)? The answers
    to these questions are closely related. Every decision tree considers some family
    of constraints in order to choose the conditions with which to label the nodes.
    In our sample decision tree, this class consists of constraints of the form *feature*
    ≤ *value*. Beyond this, the algorithm relies on the Gini value, an effort to measure
    the heterogeneity of the classes represented within the set of apps in the training
    sample for a node. For the root node in [Figure 5-4](ch05.xhtml#ch5fig4) the heterogeneity
    is maximized, as both classes are equally represented. But for its left child,
    the apps are overwhelming malware. The Gini metric assigns a high value to nodes
    that are heterogeneous and a low value to nodes that are homogeneous. Consequently,
    the Gini value assigned to the root node is higher than that assigned to its left
    child. The Gini value itself is defined as:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，自然会出现两个问题。首先，决策树算法是如何决定在树的每个节点选择什么条件的？第二，图[5-4](ch05.xhtml#ch5fig4)中节点上显示的*Gini*字段是什么意思？这两个问题的答案是紧密相关的。每个决策树都会考虑一组约束条件，以选择标记节点的条件。在我们的示例决策树中，这组条件包括形如*特征*
    ≤ *值*的约束。除此之外，算法依赖于Gini值，它试图衡量节点中训练样本集合所代表的类的异质性。对于图[5-4](ch05.xhtml#ch5fig4)中的根节点，异质性最大，因为两个类被同等代表。但是对于它的左子节点，应用程序几乎全是恶意软件。Gini度量会为异质的节点分配较高的值，而为均质的节点分配较低的值。因此，根节点的Gini值高于左子节点的Gini值。Gini值本身的定义为：
- en: '*Gini*(*X*) = 1 – *P*(*malware*|*X*)² – *P*(*goodware*|*X*)²'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*Gini*(*X*) = 1 – *P*(*恶意软件*|*X*)² – *P*(*良性软件*|*X*)²'
- en: Because at the root node the probability of an app being goodware is the same
    as the probability of it being malware, namely 50 percent, the Gini value of the
    root is 1 *–* (0.5)² – (0.5)² = 0.5\. For the left child of the root, the probability
    of an app being goodware is 480/519\. Hence, its Gini value is 1 – (39/519)² –
    (480/519)² = 1 – 0.075² – 0.925² = 1 – 0.0056 – 0.856 = 0.139.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 因为在根节点处，应用程序是良性软件的概率与它是恶意软件的概率相同，都是50%，所以根节点的Gini值为 1 *–* (0.5)² – (0.5)² =
    0.5。对于根节点的左子节点，应用程序是良性软件的概率为480/519。因此，它的Gini值为 1 – (39/519)² – (480/519)² = 1
    – 0.075² – 0.925² = 1 – 0.0056 – 0.856 = 0.139。
- en: We won’t go into the details of the decision tree algorithm itself. It suffices
    to say that when we build a decision tree, we try to find a condition from the
    set of all permitted splitting conditions such that the resulting Gini value of
    a combination of the two children is minimized. The process of splitting nodes
    continues until we reach nodes that are considered homogeneous enough, meaning
    their Gini scores fall below a given threshold.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入讨论决策树算法本身的细节。只需说，当我们构建决策树时，我们会尝试从所有允许的分裂条件集中找到一个条件，使得两个子节点的组合所产生的Gini值最小化。节点的分裂过程会持续进行，直到我们到达被认为足够均匀的节点，意味着它们的Gini值低于给定的阈值。
- en: There are many variants of decision trees. Some use criteria such as entropy
    rather than Gini scores to assess the quality of possible ways to split a node.
    Other variants change the types of conditions at each node and even set things
    up so that a decision tree makes a ternary or *n*-ary decision at each node, rather
    than a binary one. You can find more details about the construction of decision
    trees and their variants in “Top-Down Induction of Decision Trees Classifiers—A
    Survey” by Lior Rokach and Oded Maimon and “Optimizing Multi-Path Decision Tree
    by Clustering and K-Nearest Neighbor Methods” by Nasib S. Gill and Reena Hooda.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树有许多变种。有些使用像熵而不是基尼分数的标准来评估可能的节点分裂方式的质量。其他变种则改变每个节点的条件类型，甚至设置决策树在每个节点上做三元或*n*元决策，而不是二元决策。你可以在
    Lior Rokach 和 Oded Maimon 的《自顶向下的决策树分类器归纳法——一项调查》以及 Nasib S. Gill 和 Reena Hooda
    的《通过聚类和 K 最近邻方法优化多路径决策树》中找到更多关于决策树及其变种的细节。
- en: '***Bagging and Random Forest***'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***Bagging 和随机森林***'
- en: Bagging and random forest (RF) are quintessential examples of *ensemble* classifiers,
    algorithms that combine the predictions of multiple other classifiers. Ensemble
    classifiers typically start with a known classifier (sometimes referred to as
    a *weak learner*). In the case of bagging and RF classifiers, this is often a
    decision tree.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging 和随机森林（RF）是*集成*分类器的典型示例，集成分类器通过结合多个其他分类器的预测来做出决策。集成分类器通常从一个已知的分类器开始（有时称为*弱学习器*）。在
    Bagging 和 RF 分类器的情况下，这通常是一个决策树。
- en: Bagging and RF algorithms use two instruments to provide a level of robustness
    to the classification result based on the training set. The first instrument is
    to randomly select some number of subsets from the training set. The second is
    to randomly select a subset of the features. There is typically no requirement
    for constructing these subsets other than that the size of each be some percentage
    of the size of the original training set–for example, 65 or 80 percent. A weak
    learner is then separately and independently trained on each subset to yield a
    class label. The class of a new app is declared to be the class predicted by the
    majority of the weak learners.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging 和 RF 算法使用两种工具提供基于训练集的分类结果的鲁棒性。第一个工具是随机选择一些子集从训练集中获取。第二个工具是随机选择一个特征子集。通常，构建这些子集的唯一要求是每个子集的大小为原始训练集大小的某个百分比——例如
    65% 或 80%。然后，弱学习器会在每个子集上独立地进行训练，产生一个类别标签。新应用的类别将被声明为大多数弱学习器预测的类别。
- en: Bagging does not require the weak learner to be a decision tree; it could be
    any type of classifier. On the other hand, random forest classifiers assume that
    the weak learner is a decision tree. For each of the subsets discussed earlier,
    a decision tree is constructed, and at every node in any of the decision trees
    involved, a given set of attributes is deemed *active*. These active attributes
    are those that haven’t been used in the path from the decision tree’s root to
    that node. A random subset of active attributes is then selected at each node,
    and the best splitting condition is selected from the conditions definable by
    the active attributes only; inactive attributes are not considered, even if they
    provide a better Gini result. Each decision tree then generates a label, as before,
    and the class that gets more “votes” ends up being the class assigned to a given
    app.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging 不要求弱学习器必须是决策树；它可以是任何类型的分类器。另一方面，随机森林分类器假设弱学习器是决策树。对于前面讨论的每个子集，都会构建一棵决策树，并且在任何参与的决策树中的每个节点上，都会有一组被认为是*活跃的*属性。这些活跃属性是指那些从决策树根节点到该节点路径中尚未使用的属性。然后，在每个节点上随机选择一个活跃属性子集，并从由活跃属性定义的条件中选择最佳的分裂条件；即使不活跃的属性提供了更好的基尼指数结果，也不会考虑它们。然后，每棵决策树生成一个标签，和之前一样，获得更多“投票”的类别将是分配给特定应用的类别。
- en: '***Support Vector Machines***'
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***支持向量机***'
- en: A support vector machine (SVM) algorithm tries to find a *hyperplane* that splits
    the feature space into two in such a way that the feature vectors associated with
    one class (in our case, malware) primarily lie on one side of the hyperplane and
    the feature vectors associated with the other (goodware) lie on the other side.
    We showed two such hyperplanes in [Figure 5-2](ch05.xhtml#ch5fig2). In a two-dimensional
    feature space, a hyperplane is just a straight line. However, a hyperplane could
    also be a quadratic line or even a sine curve.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）算法试图找到一个*超平面*，将特征空间分为两部分，使得与一种类别（在我们的例子中是恶意软件）相关的特征向量主要位于超平面的一侧，而与另一类别（良性软件）相关的特征向量位于另一侧。我们在[图
    5-2](ch05.xhtml#ch5fig2)中展示了两个这样的超平面。在二维特征空间中，超平面就是一条直线。然而，超平面也可以是二次曲线甚至是正弦曲线。
- en: 'A *linear SVM* uses only straight lines as separators. In higher dimensions,
    a linear hyperplane has the following form:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*线性 SVM* 只使用直线作为分隔器。在更高维度中，线性超平面的形式如下：'
- en: '*a*[1]*x*[1] + *a*[2]*x*[2] + ... + *a[n]x[n]* = *b*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*a*[1]*x*[1] + *a*[2]*x*[2] + ... + *a*[n]x*[n]* = *b*'
- en: 'Here, *x*[1], *…*, *x*[*n*] represent the *n* features and *a*[1], *…*, *a*[*n*]
    and *b* are constants. Such a hyperplane divides the feature space into two parts:
    one part that satisfies *a*[1]*x*[1] + *a*[2]*x*[2] + *…* + *a*[*n*]*x*[*n*] ≥
    *b* and another part that satisfies *a*[1]*x*[1] + *a*[2]*x*[2] + … + *a[n]x[n]*
    ≤ *b*. The idea is that most malware will lie in one of these two parts and most
    goodware in the other. Implementers must decide what to do with apps whose feature
    vectors lie directly on the separating line.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*x*[1]、*…*、*x*[*n*] 代表 *n* 个特征，*a*[1]、*…*、*a*[*n*] 和 *b* 是常数。这样的超平面将特征空间分为两部分：一部分满足
    *a*[1]*x*[1] + *a*[2]*x*[2] + *…* + *a*[*n*]*x*[*n*] ≥ *b*，另一部分满足 *a*[1]*x*[1]
    + *a*[2]*x*[2] + … + *a[n]x[n]* ≤ *b*。其基本思想是，大多数恶意软件将位于这两部分之一，而大多数良性软件则位于另一部分。实现者必须决定如何处理那些特征向量恰好位于分隔线上的应用程序。
- en: 'To find a good separating hyperplane in a linear SVM, we usually consider two
    major factors: homogeneity of the feature vectors on either side of the hyperplane,
    and avoidance of feature vectors that lie close to the hyperplane. In terms of
    homogeneity, we want most of the app feature vectors on one side of the separator
    to be malware and most of the feature vectors on the other side to be goodware.
    For example, recall the horizontal separation in [Figure 5-2](ch05.xhtml#ch5fig2),
    where we classified a new app by merely counting the number of calls it made to
    classes in a certain package: if that number was greater than 3,000, we classified
    the app as goodware, and otherwise we classified it as malware. Of course, this
    is a highly simplified example. In the real world, the implementation would consider
    many more features, and the separator line’s equation would likely be far more
    complex.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在线性 SVM 中找到一个好的分隔超平面，我们通常考虑两个主要因素：超平面两侧特征向量的同质性，以及避免特征向量过于接近超平面。在同质性方面，我们希望分隔线一侧的大多数应用程序特征向量是恶意软件，而另一侧的大多数特征向量是良性软件。例如，回想一下[图
    5-2](ch05.xhtml#ch5fig2)中的水平分隔，我们通过仅仅计算一个新应用程序调用某个包中的类的次数来分类：如果次数超过 3000 次，我们将该应用程序分类为良性软件，否则分类为恶意软件。当然，这是一个高度简化的例子。在现实世界中，实施会考虑更多的特征，而分隔线的方程式可能会复杂得多。
- en: The second major factor in SVM design concerns feature vectors that lie very
    close to the separator line, like the malware specimen represented as a cross
    on the right side of [Figure 5-2](ch05.xhtml#ch5fig2), just below both separator
    lines. How certain can we be that such samples are correctly classified? To increase
    the distance between feature vectors and the separator line, we make use of *support
    vectors*, which are feature vectors in the training set that are as close to the
    separator line as possible. The distance between a separator line and its support
    vectors is called the *margin*. SVMs try to find the nearest separator line that
    maximizes the margin, reflecting the intuition that we do not want training points
    that are too close to the edge.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）设计中的第二个主要因素涉及那些特征向量非常接近分隔线的情况，例如位于[图 5-2](ch05.xhtml#ch5fig2)右侧、两个分隔线正下方的恶意软件样本。我们能有多大的信心认为这些样本被正确分类了呢？为了增加特征向量与分隔线之间的距离，我们利用了*支持向量*，即训练集中最接近分隔线的特征向量。分隔线与其支持向量之间的距离称为*间隔*。SVM
    试图找到一个最接近的分隔线，从而最大化间隔，这体现了我们不希望训练点过于接近边缘的直觉。
- en: The goals of maximizing the margin and minimizing classification errors often
    conflict. As a consequence, we usually formulate the problem of finding the best
    separator line as an optimization problem. We won’t go into the mathematical details
    of SVMs in this chapter, but the interested reader can find more information in
    “Support-Vector Networks” by Corinna Cortes and Vladimir Vapnik and “Improving
    the Accuracy and Speed of Support Vector Machines” by Christopher J. Burges and
    Bernhard Schölkopf.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 最大化边际和最小化分类错误的目标常常存在冲突。因此，我们通常将寻找最佳分隔线的问题表述为一个优化问题。我们在本章不会深入讨论 SVM 的数学细节，但有兴趣的读者可以在
    Corinna Cortes 和 Vladimir Vapnik 的《支持向量网络》以及 Christopher J. Burges 和 Bernhard
    Schölkopf 的《提高支持向量机的准确性和速度》中找到更多信息。
- en: There are also many nonlinear versions of SVMs. For instance, quadratic SVMs
    allow the separator hyperplane to take the form of a quadratic curve and tackle
    a more complex distribution of feature vectors. Other kinds of SVMs use *kernel*
    tricks, which map the original feature vector to a new feature vector. The mapping
    usually involves a nonlinear method. When we apply a linear SVM to this nonlinear
    transformation, it yields a nonlinear separator for the original data. As a consequence,
    the resulting separators can have unusual shapes. For example, [Figure 5-5](ch05.xhtml#ch5fig5)
    shows a modified training dataset in part (a) that is similar to the training
    set visualizations shown earlier in this chapter. Parts (b), (c), and (d) show
    the separators generated by SVMs using different kinds of kernels.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多非线性的支持向量机（SVM）版本。例如，二次支持向量机允许分隔超平面呈二次曲线形态，处理更复杂的特征向量分布。其他类型的 SVM 使用 *核*
    技巧，将原始特征向量映射到新的特征向量。这种映射通常涉及非线性方法。当我们将线性 SVM 应用于这种非线性变换时，它会为原始数据生成一个非线性分隔符。因此，生成的分隔符可能会有不寻常的形状。例如，[图
    5-5](ch05.xhtml#ch5fig5) 显示了一个修改后的训练数据集，其中部分 (a) 类似于本章前面展示的训练集可视化。部分 (b)、(c) 和
    (d) 显示了使用不同核函数的 SVM 所生成的分隔符。
- en: '![Image](../images/ch05fig05.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch05fig05.jpg)'
- en: '*Figure 5-5: Sample nonlinear SVM separators generated with kernels for a training
    set (a) with malware feature vectors (crosses) and goodware feature vectors (dots),
    (b) SVM separator using a polynomial kernel, (c) SVM separator using a quadratic
    kernel, and (d) SVM separator using a radial basis kernel*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-5：使用核函数生成的样本非线性 SVM 分隔符，训练集 (a) 包含恶意软件特征向量（叉号）和良性软件特征向量（圆点），(b) 使用多项式核的
    SVM 分隔符，(c) 使用二次核的 SVM 分隔符，以及 (d) 使用径向基核的 SVM 分隔符*'
- en: Notice that the generated regions are not as easy to describe as those using
    linear separators.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，生成的区域不像使用线性分隔符那样容易描述。
- en: '***k-Nearest Neighbors***'
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***k-最近邻算法***'
- en: A *k*-nearest neighbor classifier is very simple. It doesn’t really “learn”
    a model. It takes the feature vector of an app that it has never seen before,
    identifies the *k* feature vectors in the training data that are closest to the
    app’s feature vector using some distance metric (for example, Euclidean distance
    or cosine distance), and then finds the classes of those *k* apps. If more than
    half of the *k* apps are malware, it declares the app to be malware, too; otherwise
    it declares it to be goodware. For instance, consider the two apps, *A*1 and *A*2,
    shown in [Figure 5-6](ch05.xhtml#ch5fig6).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 *k* 最近邻分类器非常简单。它并不真正“学习”一个模型。它获取一个之前从未见过的应用程序的特征向量，使用某种距离度量（例如，欧几里得距离或余弦距离）确定与该应用程序特征向量最接近的
    *k* 个训练数据特征向量，然后查找这 *k* 个应用程序的类别。如果 *k* 个应用程序中超过一半是恶意软件，则该应用程序也会被判定为恶意软件；否则，它会被判定为良性软件。例如，考虑图
    [5-6](ch05.xhtml#ch5fig6) 中展示的两个应用程序，*A*1 和 *A*2。
- en: '![Image](../images/ch05fig06.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch05fig06.jpg)'
- en: '*Figure 5-6: A sample k-nearest neighbor classifier with* k = 3'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-6：一个样本的 k-最近邻分类器，k = 3*'
- en: Suppose we consider the three nearest neighbors (in other words, *k* = 3). In
    the case of *A*1, two of the three nearest neighbors are goodware, so app *A*1
    would be considered goodware. However, in the case of *A*2, two of the three nearest
    neighbors are classified as malware; hence, this app would also be classified
    as malware.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们考虑三个最近邻（换句话说，*k* = 3）。对于 *A*1，三个最近邻中的两个是良性软件，因此 *A*1 会被认为是良性软件。然而，对于 *A*2，三个最近邻中的两个被归类为恶意软件；因此，这个应用程序也会被分类为恶意软件。
- en: '***Naive Bayes***'
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***朴素贝叶斯***'
- en: Naive Bayes classifiers use a very different kind of intuition than the preceding
    classifier types. They learn a set of simple probabilities from the training data,
    then use these probabilities later to classify new feature vectors.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器使用与前述分类器类型非常不同的直觉。它们从训练数据中学习一组简单的概率，然后使用这些概率来分类新的特征向量。
- en: To classify apps as goodware or malware, a naive Bayes classifier may compute
    what we call *class-conditional* probabilities. For a given class (in our case,
    either goodware or malware), we could use the training set to derive the class-conditional
    probability that a feature vector’s *i*th feature has a certain value given that
    the app belongs to a specific class. Consider the small training set shown in
    [Table 5-2](ch05.xhtml#ch5tab2).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将应用程序分类为良性软件或恶意软件，朴素贝叶斯分类器可能会计算我们称之为 *类别条件* 概率。对于给定的类别（在我们这个例子中，良性软件或恶意软件），我们可以使用训练集来推导出一个特征向量的
    *i* 个特征在应用程序属于特定类别时具有某个值的类别条件概率。考虑下表所示的小型训练集 [表 5-2](ch05.xhtml#ch5tab2)。
- en: Features *A* and *B* represent calls to *APIPackage:android.app* and *Opcode:if-eq*,
    respectively. The probabilities *P*(*A* = 10*|*0) and *P*(*A* = 10*|*1) are the
    class-conditional probabilities of the attribute *A* having the value 10 when
    the classes are 0 and 1, respectively. Using the training set, we can see that
    *P*(*A* = 10*|*0) is 0.2, because 2 of the 10 goodware apps in the training set
    have a value of 10 for *A*. *P*(*A* = 10*|*1) is also 0.2\. In contrast, *P*(*A*
    = 3*|*0) equals 0, while *P*(*A* = 3*|*1) equals 0.3.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 特征 *A* 和 *B* 分别表示对 *APIPackage:android.app* 和 *Opcode:if-eq* 的调用。概率 *P*(*A*
    = 10*|*0) 和 *P*(*A* = 10*|*1*) 是在类别为 0 和 1 时，属性 *A* 的值为 10 的类别条件概率。通过训练集，我们可以看到
    *P*(*A* = 10*|*0*) 为 0.2，因为训练集中 10 个良性应用程序中有 2 个 *A* 的值为 10。*P*(*A* = 10*|*1*)
    也是 0.2。相比之下，*P*(*A* = 3*|*0*) 等于 0，而 *P*(*A* = 3*|*1*) 等于 0.3。
- en: '**Table 5-2:** Sample Training Set'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-2：** 示例训练集'
- en: '| **A** | **B** | **App ID** | **Class** |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| **A** | **B** | **应用程序 ID** | **类别** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 3 | 0 | app1 | 1 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0 | app1 | 1 |'
- en: '| 3 | 0 | app2 | 1 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0 | app2 | 1 |'
- en: '| 5 | 0 | app3 | 1 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 0 | app3 | 1 |'
- en: '| 12 | 0 | app4 | 1 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 0 | app4 | 1 |'
- en: '| 3 | 0 | app5 | 1 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0 | app5 | 1 |'
- en: '| 10 | 2 | app6 | 1 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 2 | app6 | 1 |'
- en: '| 10 | 1 | 1pp7 | 1 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | app7 | 1 |'
- en: '| 72 | 82 | app8 | 1 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 72 | 82 | app8 | 1 |'
- en: '| 72 | 24 | app9 | 1 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 72 | 24 | app9 | 1 |'
- en: '| 30 | 10 | app10 | 1 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 10 | app10 | 1 |'
- en: '| 0 | 0 | app11 | 0 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | app11 | 0 |'
- en: '| 0 | 0 | app12 | 0 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | app12 | 0 |'
- en: '| 0 | 0 | app13 | 0 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | app13 | 0 |'
- en: '| 0 | 0 | app14 | 0 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | app14 | 0 |'
- en: '| 0 | 0 | app15 | 0 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | app15 | 0 |'
- en: '| 10 | 1 | app16 | 0 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | app16 | 0 |'
- en: '| 10 | 1 | app17 | 0 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | app17 | 0 |'
- en: '| 72 | 190 | app18 | 0 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 72 | 190 | app18 | 0 |'
- en: '| 72 | 190 | app19 | 0 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 72 | 190 | app19 | 0 |'
- en: '| 30 | 144 | app20 | 0 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 30 | 144 | app20 | 0 |'
- en: 'A naive Bayes classifier might also calculate the *prior probability* of each
    class, which is simply the probability of a random app in the training set belonging
    to that class. In our small training set, these prior probabilities are 0.5 for
    each of the two classes, as the data has 10 goodware samples and 10 malware samples
    in it. Given a new app *a* with an associated feature vector consisting of values
    *f*[*a*] = (*v*[1], *…*, *v*[*n*]), naive Bayes computes the probability of this
    app belonging to class *c* via the Bayes rule, as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器还可能计算每个类别的 *先验概率*，即训练集中一个随机应用程序属于该类别的概率。在我们的小型训练集中，这些先验概率为 0.5，因为数据中有
    10 个良性软件样本和 10 个恶意软件样本。给定一个新的应用程序 *a*，其特征向量由值 *f*[*a*] = (*v*[1], *…*, *v*[*n*])
    组成，朴素贝叶斯通过贝叶斯规则计算该应用程序属于类别 *c* 的概率，如下所示：
- en: '![image](../images/math173.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/math173.jpg)'
- en: In plain English, this says that the probability of the app *a* belonging to
    the class *c* is the probability of *a*’s feature vector being generated by class
    *c* times the prior probability of class *c* divided by the prior probability
    of the feature vector of app *a*.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 用简单的英语来说，这意味着应用程序 *a* 属于类别 *c* 的概率是 *a* 的特征向量由类别 *c* 生成的概率，乘以类别 *c* 的先验概率，再除以应用程序
    *a* 的特征向量的先验概率。
- en: To determine the class of a new app *a* with the feature vector *f*[*a*], naive
    Bayes would find the class *c* for which *P*(*c*|*f*[*a*]) is maximal across all
    possible classes. The result is the same as finding the class *c* such that *P*(*f*[*a*]|*c*)
    ×*P*(*c*) is maximal, as the denominator of the probability formula remains the
    same regardless of the class considered. Let us call this product a *pseudo-probability*.
    We want to find the class *c* that maximizes this pseudo-probability.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定新应用程序 *a* 的类别，首先需要计算其特征向量 *f*[*a*]，朴素贝叶斯会找到使 *P*(*c*|*f*[*a*]) 在所有可能类别中最大化的类别
    *c*。这个结果与找到使 *P*(*f*[*a*]|*c*) × *P*(*c*) 最大化的类别 *c* 是相同的，因为概率公式的分母对于任何考虑的类别都是相同的。我们称这个乘积为
    *伪概率*。我们希望找到使这个伪概率最大化的类别 *c*。
- en: 'Now consider a new app *a* whose feature vector is (3, 1), meaning feature
    *A* equals 3 and *B* equals 1\. Notice that there is no app in the training set
    with this feature vector. Naive Bayes computes the probability of seeing the feature
    vector (3, 1) by making an independence assumption; it assumes that the probability
    of seeing the feature vector is the product of the probability of seeing each
    component of the feature vector. In formal terms, we can write this as:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑一个新应用程序 *a*，其特征向量为 (3, 1)，意味着特征 *A* 等于 3，*B* 等于 1。请注意，训练集中没有具有这个特征向量的应用程序。朴素贝叶斯通过做出独立性假设来计算看到特征向量
    (3, 1) 的概率；它假设看到特征向量的概率是看到特征向量中每个分量概率的乘积。用正式的术语来说，我们可以这样写：
- en: '![image](../images/math174-01.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/math174-01.jpg)'
- en: Here, ![image](../images/math174-02.jpg) is the conditional probability that
    ![image](../images/math174-03.jpg), given that an app is in class *c*, and ![image](../images/math174-04.jpg)
    represents the *i*th component of app *a*’s feature vector *f*[*a*].
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![image](../images/math174-02.jpg) 是在应用程序属于类别 *c* 的条件下，![image](../images/math174-03.jpg)
    的条件概率，而 ![image](../images/math174-04.jpg) 表示应用程序 *a* 的特征向量 *f*[*a*] 的第 *i* 个分量。
- en: 'Returning to the example in [Table 5-2](ch05.xhtml#ch5tab2), we see that the
    pseudo-probabilities for the feature vector (3, 1) are given by the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 回到 [表 5-2](ch05.xhtml#ch5tab2) 中的例子，我们可以看到特征向量 (3, 1) 的伪概率如下所示：
- en: '![image](../images/math174-05.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/math174-05.jpg)'
- en: As the latter is larger than the former, this particular app with feature vector
    (3, 1) is classified as malware.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于后者大于前者，因此具有特征向量 (3, 1) 的应用程序被分类为恶意软件。
- en: 'Naive Bayes classifiers have several problems. Often, especially when the feature
    vector is long, the numerator in the product calculation ends up being zero, which
    results in a probability of zero. A number of variants of naive Bayes fix such
    problems by making different types of assumptions about the way the values in
    each feature are distributed. For example, Gaussian naive Bayes assumes they are
    distributed in accordance with a normal distribution whose mean and standard deviation
    are computed from the observed values of the feature in the training data. You
    can find more information about naive Bayes classifiers and their different variants
    in “Discrete Bayesian Network Classifiers: A Survey” by Concha Bielza and Pedro
    Larranaga.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器存在几个问题。通常，尤其是在特征向量较长时，乘积计算中的分子最终会变成零，导致概率为零。一些朴素贝叶斯的变种通过对每个特征值的分布方式做出不同假设来解决这些问题。例如，高斯朴素贝叶斯假设它们符合正态分布，其均值和标准差是从训练数据中观察到的特征值计算得出的。你可以在Concha
    Bielza 和 Pedro Larranaga的《离散贝叶斯网络分类器：调查》中找到更多关于朴素贝叶斯分类器及其不同变种的信息。
- en: '**Evaluating Machine Learning Models**'
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**评估机器学习模型**'
- en: Once we’re done training a model, we want to know how well it performs. Researchers
    have developed multiple metrics to evaluate machine learning models. We’ll discuss
    a few important ones in this section, focusing on binary classifiers.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们完成了模型的训练，我们就希望知道它的表现如何。研究人员开发了多种指标来评估机器学习模型。在本节中，我们将讨论几个重要的指标，重点讨论二分类器。
- en: 'For the evaluation results to be useful, we should compute these metrics using
    samples that aren’t present in the training data. Having a large, randomly sampled
    evaluation set is key to understanding a classifier’s strengths and deficiencies.
    This evaluation set, like the training set, should contain individual samples,
    along with labels for each sample. Generally, our evaluation should take into
    account the following:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使评估结果有用，我们应使用不包含在训练数据中的样本来计算这些指标。拥有一个大规模、随机抽样的评估集对于了解分类器的优缺点至关重要。这个评估集应该像训练集一样，包含单独的样本及每个样本的标签。通常，我们的评估应考虑以下几点：
- en: '**True positives (TPs)** Apps that are predicted by the classifier to be malware
    and that are in fact labeled as malware'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**真正例（TPs）** 被分类器预测为恶意软件且实际标记为恶意软件的应用'
- en: '**False positives (FPs)** Apps that are predicted by the classifier to be malware
    but are in fact labeled as goodware'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**假阳性（FPs）** 被分类器预测为恶意软件但实际标记为良性软件的应用'
- en: '**True negatives (TNs)** Apps that are predicted to be goodware and are labeled
    as goodware'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**真负例（TNs）** 被分类器预测为良性软件且实际标记为良性软件的应用'
- en: '**False negatives (FNs)** Apps that are predicted to be goodware but are labeled
    as malware'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**假阴性（FNs）** 被预测为良性软件但实际上被标记为恶意软件的应用'
- en: Too many false positives or false negatives indicates poor performance. Other
    important statistical metrics to consider are shown in [Table 5-3](ch05.xhtml#ch5tab3),
    which presents the results of a random forest classifier on a “Goodware vs. Android
    Banking Trojans” dataset we’ve collected from a host of online websites. The following
    discussion describes those metrics in detail.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 过多的假阳性或假阴性表明性能较差。其他需要考虑的重要统计指标见[表 5-3](ch05.xhtml#ch5tab3)，该表展示了我们从多个在线网站收集的“良性软件与安卓银行木马”数据集上随机森林分类器的结果。接下来的讨论将详细描述这些指标。
- en: '**Table 5-3:** Example Metrics for Evaluating Machine Learning Models'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-3：** 评估机器学习模型的示例指标'
- en: '| **Dataset** | **Classifier** | **Accuracy** | **Precision** | **Recall**
    | **F1 score** | **AUC** |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| **数据集** | **分类器** | **准确率** | **精确度** | **召回率** | **F1 分数** | **AUC** |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| Goodware vs. Banking Trojans | RF | 0.9908 | 0.9909 | 0.9910 | 0.9910 | 0.9931
    |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 良性软件与银行木马 | RF | 0.9908 | 0.9909 | 0.9910 | 0.9910 | 0.9931 |'
- en: '*Accuracy* measures how many predictions a classifier got right in the evaluation
    set (in other words, the proportion of TPs and TNs with respect to the total number
    of predictions). We calculate it as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '*准确率*衡量分类器在评估集中的预测正确数量（换句话说，即真正例和真负例占所有预测总数的比例）。我们通过以下公式计算它：'
- en: '*A* = (*TP* + *TN*)/(*TP* + *FP* + *TN* + *FN*)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '*A* = (*TP* + *TN*)/(*TP* + *FP* + *TN* + *FN*)'
- en: While accuracy is an intuitive measurement, it has several issues when applied
    to the detection of malicious apps. Chief among these is that malware occurs very
    rarely, so most of the evaluation data is likely to be labeled as goodware if
    it is representative of real-world conditions. This means that a classifier can
    obtain a very good accuracy rating simply by predicting that every app is goodware.
    It isn’t uncommon for less than 1 percent of samples to be malware; in that case,
    such a classifier would have over 99 percent accuracy.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然准确率是一个直观的衡量标准，但在检测恶意软件应用时，它存在一些问题。最主要的问题是恶意软件发生的频率非常低，因此如果评估数据集能够代表现实世界的情况，大部分数据可能会被标记为良性软件。这意味着分类器如果将所有应用都预测为良性软件，就能获得一个非常高的准确率。通常情况下，恶意软件样本占比不到1%；在这种情况下，分类器的准确率可能会超过99%。
- en: '*Precision* measures how accurate our classifier is when it correctly predicts
    an app to be malware. We calculate it as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '*精确度*衡量我们的分类器在正确预测应用为恶意软件时的准确性。我们通过以下公式计算它：'
- en: '*P* = *TP*/(*TP* + *FP*)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*P* = *TP*/(*TP* + *FP*)'
- en: This metric captures the percentage of items predicted to belong to a class
    that were actually in the class. However, it does not capture the full picture.
    Let’s consider a set that contains 100 samples, of which 50 are malware. If our
    classifier predicts that only 1 sample from the set is malware and that 99 are
    goodware, it will have 100 percent precision, but it isn’t doing a very good job
    at finding malware.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指标捕捉了被预测为属于某个类别的项目中，实际属于该类别的百分比。然而，它并不能反映全部情况。假设我们有一个包含100个样本的集合，其中50个是恶意软件。如果我们的分类器预测该集合中只有1个样本是恶意软件，而其余99个是良性软件，那么它的精确度将达到100%，但在寻找恶意软件方面并没有做好工作。
- en: '*Recall* is a complementary measurement to precision that computes how many
    positive samples a classifier misses. We calculate it as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*召回率*是与精度互补的一个度量，计算分类器漏掉了多少正样本。我们可以通过以下公式计算：'
- en: '*R* = *TP*/(*TP* + *FN*)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '*R* = *TP*/(*TP* + *FN*)'
- en: Recall by itself might not be a good performance indicator, as a classifier
    that predicts everything to be malware will achieve 100 percent recall. In general,
    we want a classifier to have both good precision *and* good recall.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 单独使用召回率可能不是一个好的性能指标，因为一个将所有内容都预测为恶意软件的分类器将获得100%的召回率。通常，我们希望分类器能够同时具备良好的精度*和*良好的召回率。
- en: One solution is to combine the two. For example, we sometimes calculate the
    *F1 score* of a classifier, or the harmonic mean of precision and recall. This
    value is an attempt to balance the two metrics to identify strong classifiers.
    Most malware classifiers produce an F1 score between 0 and 1, where 0 represents
    higher confidence that the prediction is goodware and 1 means that the app is
    malware.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解决方案是将两者结合。例如，我们有时会计算分类器的*F1 分数*，或者精度和召回率的调和平均数。这个值试图平衡这两个指标，以识别强大的分类器。大多数恶意软件分类器的F1分数在0到1之间，其中0表示对预测为良性软件的信心较高，而1则表示该应用是恶意软件。
- en: 'The *receiver operating characteristic (ROC) curve* plots the performance of
    a classifier at various thresholds to help us pick a good threshold and compare
    different classifiers. A ROC graph has two axes. The *true positive rate* is the
    same as recall, and the *false positive rate* is calculated as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*接收者操作特征（ROC）曲线*绘制了分类器在不同阈值下的表现，帮助我们选择一个合适的阈值并比较不同的分类器。ROC图有两个坐标轴。*真正率*与召回率相同，而*假正率*则通过以下公式计算：'
- en: '*FPR* = *FP*/(*FP* + *TN*)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*FPR* = *FP*/(*FP* + *TN*)'
- en: The *area under the ROC curve (AUC)* gives an overall measurement of the classifier
    across all thresholds. To understand AUC, imagine sorting all the apps in an evaluation
    by the classifier’s score. AUC measures the probability of a randomly selected
    malware app having a higher score than a randomly selected goodware app. An ideal
    classifier would always provide lower scores to goodware than to malware; such
    a classifier would have an AUC of 1\. A really bad classifier that does the opposite
    would have an AUC of 0, and a random classifier would have an AUC of 0.5\. A sample
    ROC curve for the decision tree algorithm is shown in [Figure 5-7](ch05.xhtml#ch5fig7).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*接收者操作特征曲线（AUC）*提供了一个跨所有阈值的分类器整体表现度量。为了理解AUC，假设我们将所有应用程序根据分类器的得分进行排序。AUC衡量的是一个随机选择的恶意软件应用得分高于一个随机选择的良性软件应用的概率。理想的分类器总是会给良性软件分配低于恶意软件的分数；这样的分类器AUC为1。一个完全错误的分类器（正好相反）将具有AUC为0，而一个随机分类器的AUC将为0.5。决策树算法的一个示例ROC曲线见[图5-7](ch05.xhtml#ch5fig7)。'
- en: 'AUC has several advantages: notably, it is invariant to class skew (which occurs
    when the number of samples in one class far outnumbers that of the other class)
    and independent of specific thresholds. However, it treats both FPs and FNs equally.
    This might not be desirable if you want to make sure that no malware slips through.
    When you’re trying to protect a store like Google Play, for example, it’s better
    to err on the side of caution. That is, it’s preferable to manually review too
    many apps, even if they turn out to be goodware for the most part, than too few.
    So, you might instead want to pick a model that treats FPs as more desirable.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: AUC有几个优点：尤其是，它对类别偏斜（当一个类别的样本数远远超过另一个类别时）具有不变性，并且独立于特定的阈值。然而，它对FP和FN的处理是一样的。如果你想确保没有恶意软件漏网，这可能不太理想。例如，在你试图保护像Google
    Play这样的商店时，最好是偏向谨慎。也就是说，宁可手动审查过多的应用程序，即使它们大多数情况下是良性软件，也比审查过少更好。因此，你可能会更倾向于选择一个将FP视为更重要的模型。
- en: '![Image](../images/ch05fig07.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch05fig07.jpg)'
- en: '*Figure 5-7: The ROC curve for the decision tree classifier*'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*图5-7：决策树分类器的ROC曲线*'
- en: '**Struggles of Machine Learning Classifiers**'
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**机器学习分类器的挑战**'
- en: In this section, we describe some common pitfalls that can adversely affect
    the performance of machine learning classifiers.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了一些常见的陷阱，这些陷阱可能会对机器学习分类器的性能产生不利影响。
- en: '***Identical Feature Vectors***'
  id: totrans-164
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***相同特征向量***'
- en: Some malware identification datasets include apps with identical feature vectors.
    This can happen in two broad cases. In the first case, different apps in the dataset
    are variants of one another. We call these *isomorphic* apps. It’s important to
    make sure that no app in the training data has corresponding isomorphic apps in
    the test data. Otherwise, they will artificially inflate the performance of the
    classifier. The second case occurs when the feature set is impoverished. This
    is also very serious, because it suggests that the selected features aren’t adequate
    enough to distinguish between apps that are truly different.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 一些恶意软件识别数据集包含了具有相同特征向量的应用程序。这通常发生在两种广泛的情况下。在第一种情况下，数据集中的不同应用程序是彼此的变种，我们称这些应用程序为*同构*应用程序。必须确保训练数据中的任何应用程序在测试数据中没有对应的同构应用程序，否则它们会人为地提高分类器的性能。第二种情况发生在特征集贫乏时。这也是一个非常严重的问题，因为这表明所选特征不足以区分真正不同的应用程序。
- en: '***Balance vs. Imbalance***'
  id: totrans-166
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***平衡与不平衡***'
- en: Machine learning algorithms generally produce good models when the data is *balanced*,
    meaning it has reasonably comparable percentages of samples in the different classes.
    Conversely, some algorithms may struggle to perform when the data is massively
    imbalanced.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法通常在数据*平衡*时表现良好，这意味着不同类别的样本比例大致相当。相反，当数据极度不平衡时，一些算法可能会表现不佳。
- en: For instance, suppose we are trying to distinguish between Android spyware and
    goodware. In most general malware datasets available today, the number of spyware
    samples will be much smaller than the number of goodware samples. This may be
    due to the fact that the dataset was collected to distinguish all forms of malware
    (not just spyware) from goodware. If a classifier is trained to separate spyware
    from goodware, the number of spyware samples would be relatively small compared
    to the number of goodware samples.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，假设我们正在尝试区分安卓间谍软件和良性软件。在今天大多数可用的恶意软件数据集中，间谍软件样本的数量通常远小于良性软件样本的数量。这可能是因为数据集的收集目的是区分所有形式的恶意软件（不仅仅是间谍软件）与良性软件。如果一个分类器被训练用来区分间谍软件和良性软件，那么与良性软件样本数量相比，间谍软件样本的数量相对较小。
- en: Such imbalances in the class sizes can severely affect the performance of classification
    algorithms.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 类别大小的不平衡可能会严重影响分类算法的性能。
- en: '***Interpretability***'
  id: totrans-170
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***可解释性***'
- en: When detecting malware, security analysts must identify compelling evidence
    of an app’s malicious nature. Machine learning algorithms that return a verdict
    without providing information regarding why a particular app was flagged as malicious
    or benign may be useful for automated protection efforts but not for human-supported
    analysis. For confirmation, an analyst needs the algorithm to lead them toward
    the source of malicious behavior. Without any such guidance, verifying the algorithm’s
    verdict by analyzing the training set, the model, and its output becomes the equivalent
    of a complete app review and is like finding a needle in a haystack.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测恶意软件时，安全分析员必须识别出应用程序恶意性质的有力证据。那些在没有提供关于为何特定应用被标记为恶意或良性的原因的情况下做出判决的机器学习算法，可能对于自动化保护工作有用，但对于人工支持的分析则不够理想。为了确认，分析员需要算法引导他们找到恶意行为的源头。如果没有这种指导，验证算法的判决就变得相当于对整个应用程序进行审查，简直像是在大海捞针。
- en: For that reason, many malware detection methods use handcrafted features that
    enable the analyst to find malicious parts of the code or demonstrate malicious
    behavior when the code is run. This is also one major reason why deep learning
    methods aren’t always the best option for malware detection in industry. It is
    difficult to understand how these machine learning algorithms produce their output.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，许多恶意软件检测方法使用手工设计的特征，帮助分析员在代码中找到恶意部分或展示代码运行时的恶意行为。这也是深度学习方法在工业界进行恶意软件检测时并不总是最佳选择的一个主要原因。因为很难理解这些机器学习算法是如何产生其输出的。
- en: '***Cross-Validation vs. Rolling Window Prediction***'
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***交叉验证与滚动窗口预测***'
- en: Many machine learning–based malware detection algorithms have been evaluated
    in the literature using *k*-fold cross-validation, a technique that randomly splits
    the training data into *k* disjointed pieces, called *folds*, then performs *k*
    iterations over the folds. In each iteration, a corresponding fold (for example,
    the third fold on the third iteration) is removed and some classifier of a given
    type (such as an SVM) learns from all the remaining folds. The model then makes
    predictions about the removed fold, and its performance is computed on that iteration
    alone using a metric such as the AUC or F1 score, discussed earlier. The technique
    then makes a final assessment of a model type (for instance, SVM) by taking an
    aggregate value of the performance metric across all *k* folds.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 许多基于机器学习的恶意软件检测算法已在文献中使用*k*折交叉验证进行评估，这是一种将训练数据随机拆分成*k*个不相交的部分，称为*折叠*，然后在这些折叠上执行*k*次迭代的技术。在每次迭代中，移除一个对应的折叠（例如，第三次迭代中的第三个折叠），然后某种类型的分类器（例如SVM）从其余的折叠中学习。模型接着对移除的折叠进行预测，并仅在该次迭代中使用诸如AUC或F1分数等度量来计算其性能。然后，这项技术通过计算所有*k*个折叠上的性能度量的聚合值来对模型类型（例如SVM）进行最终评估。
- en: However, the use of cross-validation may not always be appropriate, because
    malware evolves over time and *k*-fold cross validation ignores the time at which
    a given app in the training data was first released into the wild. As a consequence,
    the folds used during any iteration might include apps that were released into
    the wild *after* some of the apps in the removed fold. Intuitively, what this
    means is that we are likely predicting the status of some apps using information
    from the future, which can artificially boost the performance of the classifier.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用交叉验证可能并不总是合适的，因为恶意软件会随着时间的推移不断演化，*k*折交叉验证忽略了训练数据中某个应用首次发布到互联网的时间。因此，在任何迭代过程中使用的折叠可能包含那些在移除折叠中的某些应用之后才发布到互联网的应用。直观地讲，这意味着我们很可能在使用未来的信息来预测一些应用的状态，这可能会人为地提升分类器的性能。
- en: In contrast, *rolling window prediction* sorts the apps *a*[1], *…*, *a*[*n*]
    in the dataset based on the times at which each app entered the wild. We then
    assume that we need at least *j* apps for decent training. For each *i*, such
    that *j* < *i* ≤ *n*, we train on the dataset {*a*[1], *…*, *a*[*j*]} and assess
    the performance ![image](../images/math179-01.jpg) of a given classifier. We consider
    the overall performance of the classifier to be the average of the ![image](../images/math179-01.jpg)s
    for *i* < *j* ≤ *n.* This methodology avoids the possibility of using information
    from the future to predict the past.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，*滚动窗口预测*根据每个应用首次进入互联网的时间对数据集中的应用*a*[1]、*…*、*a*[*n*]进行排序。我们接着假设我们至少需要*j*个应用进行有效的训练。对于每个*i*，使得*j*
    < *i* ≤ *n*，我们在数据集{*a*[1]、*…*、*a*[*j*]}上进行训练，并评估给定分类器的性能 ![image](../images/math179-01.jpg)。我们认为分类器的整体性能是对于*i*
    < *j* ≤ *n*的![image](../images/math179-01.jpg)的平均值。这种方法避免了使用未来信息来预测过去的可能性。
- en: '**Up Next**'
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**接下来**'
- en: This chapter presented an overview of machine learning algorithms that are widely
    used in malware analysis and detection. In the next chapter, we explore the features
    we can use as input to these algorithms.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了广泛应用于恶意软件分析和检测的机器学习算法。在下一章中，我们将探讨可以作为这些算法输入的特征。
- en: Though publicly available machine learning libraries are constantly evolving,
    you may find it worthwhile to explore the possibilities offered by the R, scikit-learn,
    and TensorFlow libraries. You can also find a list of app hashes, as well as the
    static and dynamic features described in this and the next chapter, at [*https://github.com/android-malware-ml-book*](https://github.com/android-malware-ml-book).
    Use these libraries to learn the different types of predictive models capable
    of separating malware from goodware.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管公开可用的机器学习库在不断发展，但你可能会觉得探索R、scikit-learn和TensorFlow库所提供的可能性是值得的。你还可以在[*https://github.com/android-malware-ml-book*](https://github.com/android-malware-ml-book)找到应用哈希值的列表，以及本章和下一章中描述的静态和动态特征。使用这些库来学习不同类型的预测模型，能够区分恶意软件和良性软件。
- en: '[*OceanofPDF.com*](https://oceanofpdf.com)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[*OceanofPDF.com*](https://oceanofpdf.com)'
