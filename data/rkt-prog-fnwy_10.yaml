- en: '10'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '10'
- en: 'TRAC: THE RACKET ALGEBRAIC CALCULATOR'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'TRAC: RACKET 代数计算器'
- en: '![Image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common01.jpg)'
- en: Racket provides an ecosystem for language-oriented programming. It has extensive
    built-in capabilities to construct macros, lexers, and parser generators. In this
    final chapter, we unfortunately won’t have time to explore all of these enticing
    topics. However, we’ll explore a number of new topics in computer science and
    utilize many of the topics introduced in previous chapters (and especially leverage
    a number of the computing machine concepts introduced in the previous chapter).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Racket 提供了一个面向语言编程的生态系统。它拥有广泛的内建功能，可以构建宏、词法分析器和解析器生成器。在本章的最后，我们遗憾地没有时间探索所有这些引人入胜的主题。然而，我们将探索计算机科学中的一些新话题，并利用前面章节中介绍的许多主题（尤其是前一章中介绍的计算机概念）。
- en: In the process, we’ll build a command line program called TRAC (The Racket Algebraic
    Calculator), which will take a string of characters representing an algebraic
    expression and compute its value. TRAC is, in fact, a stripped-down version of
    a programming language. If desired, it can be extended in a number of ways to
    implement a full-fledged programming language.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，我们将构建一个名为 TRAC（Racket 代数计算器）的命令行程序，它将接收一个表示代数表达式的字符字符串并计算其值。事实上，TRAC
    是一种简化版的编程语言。如果需要，它可以通过多种方式扩展，以实现一个完整的编程语言。
- en: 'This program will be able accommodate a dialog such as the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序将能够处理如下对话：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The TRAC Pipeline
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TRAC 流程
- en: To build TRAC, we’ll make use of the following pipeline, which processes the
    input in stages in order to compute the output.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建 TRAC，我们将使用以下的处理流程，该流程分阶段处理输入，以便计算输出。
- en: '![Image](../images/p0276-01.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/p0276-01.jpg)'
- en: 'The lexer (or *lexical analyzer*) is responsible for taking the input string
    and breaking it into a list of tokens that can then be passed to the parser for
    further processing. Take the following string, for example:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 词法分析器（或 *词法分析器*）负责接收输入字符串，并将其分解为一系列可以传递给解析器进一步处理的标记。例如，考虑以下字符串：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Given the above string, the lexical analyzer will return an output list similar
    to this:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 给定上述字符串，词法分析器将返回类似于以下的输出列表：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Once we’ve produced the token list, we can pass it on to the parser. The job
    of the parser is to determine the structure of the input by building something
    called the *abstract syntax tree* (or *AST*). An AST is a description of the structure
    of an expression. Mathematical expressions such as the one just introduced have
    an inverted tree-like structure. The AST for our example expression is shown in
    [Figure 10-1](ch10.xhtml#ch10fig1).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们生成了标记列表，我们就可以将其传递给解析器。解析器的任务是通过构建一种称为 *抽象语法树*（或 *AST*）的结构，来确定输入的结构。AST 是表达式结构的描述。像刚刚引入的数学表达式具有一种倒置的树状结构。我们示例表达式的
    AST 如 [图 10-1](ch10.xhtml#ch10fig1) 所示。
- en: '![Image](../images/10fig01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/10fig01.jpg)'
- en: '*Figure 10-1: AST for (*x* + 1.2)*(7.7 / *y*)*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-1：(*x* + 1.2)*(7.7 / *y*)* 的 AST'
- en: We can then pass the AST on to the *interpreter* to evaluate the expression
    and calculate the result. If we were building a full-blown computer language,
    the AST would be passed on to a compiler and optimizer, where it would be reduced
    to machine code for efficient execution. Strictly speaking, if the intent were
    to only build an interpreter, it wouldn’t be necessary to build an AST, since
    the parser could simply perform any required computations on the fly, but we’ll
    see later that having the AST available will allow us to manipulate it to derive
    other useful results.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将 AST 传递给 *解释器*，以评估表达式并计算结果。如果我们在构建一个完全的计算机语言，AST 将被传递给编译器和优化器，在那里它将被转换成机器代码，以便高效执行。严格来说，如果仅仅是构建一个解释器，则不需要构建
    AST，因为解析器可以直接在运行时进行任何必要的计算，但稍后我们会看到，拥有 AST 使我们能够操作它，从而推导出其他有用的结果。
- en: The processing pipeline (lexer, parser, interpreter), in addition to providing
    a clear separation of duties, allows us to plug in different modules optimized
    for specific tasks. For example, an interpreter works well for interactive computations
    but not so much for long running calculations. In such an instance, we’d want
    to substitute a compiler for the interpreter. This would permit our code to be
    converted to machine code and run at full speed by being executed directly by
    the CPU.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 处理流水线（词法分析器、解析器、解释器）除了提供明确的职责分离外，还允许我们插入针对特定任务优化的不同模块。例如，解释器适合交互式计算，但不适合长期运行的计算。在这种情况下，我们希望将解释器替换为编译器。这将允许我们的代码被转换为机器码，并通过CPU直接执行以全速运行。
- en: We’ll discuss and implement each of these components in turn, until we have
    a working algebraic calculator; then we’ll look at a few ways to improve TRAC.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将依次讨论并实现这些组件，直到我们拥有一个功能齐全的代数计算器；然后，我们将研究几种改进TRAC的方法。
- en: The Lexical Analyzer
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词法分析器
- en: In order to split the input into tokens, the lexical analyzer scans the input
    one character at a time looking for certain patterns. At a high level, a token
    is just some sequence of characters that can be categorized in a certain way.
    For example, a string of digits such a 19876 can be categorized as an integer
    token. Strings of characters that start with a letter and are followed by zero
    or more letters and digits (such as “AVG1” or “SIN") can be categorized as identifier
    tokens. Lexical analyzers typically ignore nonessential characters such as spaces
    and tabs (the language Python is a notable exception).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将输入分割成标记，词法分析器一次扫描一个字符，寻找特定的模式。从高层次来看，标记就是一些可以以某种方式分类的字符序列。例如，一串数字如19876可以被归类为整数标记。以字母开头，后面跟着零个或多个字母和数字的字符串（如“AVG1”或“SIN”）可以被归类为标识符标记。词法分析器通常会忽略不必要的字符，如空格和制表符（Python语言是一个显著的例外）。
- en: Each pattern can be represented by a finite-state machine, or FSM (see [Chapter
    9](ch09.xhtml)). One such FSM that we’ll use is a recognizer for unsigned integers.
    In the discussion that follows, certain sets of characters, when grouped together,
    are referred to as a *character class*. One such class we’ll need is the characters
    consisting of the digits from 0 to 9, which we simply designate as the *digit*
    class. An unsigned integer is exclusively composed of a string of digits from
    the digit class, so we can represent its recognizer by the following FSM shown
    in [Figure 10-2](ch10.xhtml#ch10fig2), where the digit class is represented by
    an uppercase italic *D*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模式都可以通过有限状态机（FSM）来表示（参见[第9章](ch09.xhtml)）。我们将使用的一个FSM是无符号整数的识别器。在接下来的讨论中，某些字符集组合在一起时，称为*字符类*。我们需要的一个字符类是由0到9的数字组成的字符，我们将其简单地指定为*数字*类。无符号整数完全由数字类中的数字串组成，因此我们可以通过下图所示的FSM来表示它的识别器，在该FSM中，数字类由一个大写斜体字母*D*表示。
- en: '![Image](../images/10fig02.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/10fig02.jpg)'
- en: '*Figure 10-2: FSM to recognize digits*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-2：用于识别数字的有限状态机（FSM）*'
- en: This diagram indicates that an unsigned integer always starts with a digit,
    and may be followed by any number of trailing digits. An alternative method for
    representing an unsigned integer is with a *syntax diagram*, such as the one given
    in [Figure 10-3](ch10.xhtml#ch10fig3).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表显示无符号整数总是以数字开始，后面可以跟任意数量的尾随数字。表示无符号整数的另一种方法是使用*语法图*，例如[图10-3](ch10.xhtml#ch10fig3)所示。
- en: '![Image](../images/10fig03.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/10fig03.jpg)'
- en: '*Figure 10-3: Syntax diagram to recognize digits*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10-3：用于识别数字的语法图*'
- en: 'In this case, the digit class is represented with a typewriter font like this:
    `digit`. A syntax diagram can sometimes provide a more intuitive representation
    of the pattern being recognized. The syntax diagram shows that, after accepting
    a digit, the analyzer can optionally loop back to accept another digit.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，数字类使用类似打字机字体的样式表示，如`digit`。语法图有时可以提供一种更直观的模式识别表示方式。语法图显示，在接受一个数字后，分析器可以选择性地循环回去接受另一个数字。
- en: To be truly useful, TRAC will need to be able to recognize more than just integers.
    The following syntax diagram in [Figure 10-4](ch10.xhtml#ch10fig4) illustrates
    a recognizer that will accept numbers that consist of unsigned integers, as well
    as floating-point numbers entered with a decimal point and numbers entered in
    scientific notation with an embedded `e`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了真正有用，TRAC 需要能够识别的不仅仅是整数。以下[图 10-4](ch10.xhtml#ch10fig4)中的语法图展示了一个可以接受由无符号整数、带小数点的浮点数以及带有嵌入
    `e` 的科学计数法表示的数字组成的识别器。
- en: '![Image](../images/10fig04.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/10fig04.jpg)'
- en: '*Figure 10-4: Syntax diagram to recognize numbers*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-4：识别数字的语法图*'
- en: 'Note that syntax diagrams can be nested: the boxes in [Figure 10-4](ch10.xhtml#ch10fig4)
    encapsulate the recognizer from [Figure 10-3](ch10.xhtml#ch10fig3). We leave it
    as an exercise for the reader to construct the corresponding FSM.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，语法图可以嵌套：[图 10-4](ch10.xhtml#ch10fig4)中的框包含了[图 10-3](ch10.xhtml#ch10fig3)中的识别器。我们留给读者作为练习，构建对应的
    FSM。
- en: 'In addition to recognizing numbers, TRAC recognizes identifiers (like `x` in
    `let x = 4`). TRAC identifiers always start with a letter, followed by any number
    of letters or digits. We’ll designate the letter class with an italic uppercase
    *L*. As such, the following FSM (see [Figure 10-5](ch10.xhtml#ch10fig5)) will
    be used to recognize TRAC identifiers:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了识别数字，TRAC 还可以识别标识符（如 `let x = 4` 中的 `x`）。TRAC 标识符总是以字母开头，后跟任意数量的字母或数字。我们将字母类指定为斜体大写字母
    *L*。因此，以下 FSM（见[图 10-5](ch10.xhtml#ch10fig5)）将用于识别 TRAC 标识符：
- en: '![Image](../images/10fig05.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/10fig05.jpg)'
- en: '*Figure 10-5: FSM to recognize identifiers*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-5：识别标识符的 FSM*'
- en: Here’s the corresponding syntax diagram in [Figure 10-6](ch10.xhtml#ch10fig6).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[图 10-6](ch10.xhtml#ch10fig6)中对应的语法图。
- en: '![Image](../images/10fig06.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/10fig06.jpg)'
- en: '*Figure 10-6: Syntax diagram to recognize identifiers*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-6：识别标识符的语法图*'
- en: '***Regular Expressions***'
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***正则表达式***'
- en: So far the discussion has been at a somewhat abstract level. The question now
    becomes, *How does one actually obtain an FSM that recognizes various character
    patterns?* The answer is *regular expressions*. A regular expression is essentially
    a special language used to build finite-state machines (in this case Racket builds
    the FSM for us, given the regular expression). Our tokens (for example, strings
    of digits constituting integers) are in fact regular languages. Recall from the
    last chapter that a regular language is one where there exists an FSM that can
    accept the entire set of strings. A regular expression is something a bit different.
    A regular expression (as distinct from a regular language) is really a specification
    used to build an FSM that recognizes a regular language.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，讨论一直处于一种相对抽象的层次。现在的问题是，*如何实际获得一个能够识别各种字符模式的有限状态机（FSM）？* 答案是*正则表达式*。正则表达式本质上是一种特殊语言，用于构建有限状态机（在这种情况下，Racket
    会为我们构建 FSM，给定正则表达式）。我们的标记（例如，构成整数的数字字符串）实际上是正则语言。回顾上一章，正则语言是指存在一个 FSM 可以接受整个字符串集的语言。正则表达式有些不同。正则表达式（与正则语言不同）实际上是用来构建一个识别正则语言的
    FSM 的规范。
- en: 'Here’s a regular expression that can be used to recognize unsigned integers:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可以用来识别无符号整数的正则表达式：
- en: '`[0-9][0-9]*`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`[0-9][0-9]*`'
- en: 'The expression in square brackets is a character class. In this case, it’s
    the class of digits from 0 to 9\. This regular expression contains two character
    classes, both for recognizing digits. The way to interpret this is that the first
    class will recognize a single digit, but the second, since it’s immediately followed
    by an asterisk, will recognize zero or more additional digits (the asterisk is
    called the *Kleene star* in honor of Stephen Kleene, who formalized the concept
    of regular expressions). A more succinct way to do this is with the following
    regular expression:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 方括号中的表达式是字符类。在这种情况下，它是从 0 到 9 的数字类。这个正则表达式包含了两个字符类，都是用来识别数字的。解释这种方式是，第一个类将识别一个数字，但第二个类，由于后面紧跟着星号，将识别零个或多个额外的数字（星号被称为
    *克里尼星号*，以纪念斯蒂芬·克里尼，他正式化了正则表达式的概念）。一种更简洁的方式是使用以下正则表达式：
- en: '`[0-9]+`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`[0-9]+`'
- en: The trailing plus sign (called the *Kleene plus*) indicates that we want to
    recognize a string of one or more characters in the class.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 后缀的加号（称为 *克里尼加号*）表示我们想要识别由一个或多个字符组成的字符串。
- en: 'The Kleene star and Kleene plus are called *quantifiers*. One additional regular
    expression quantifier is the question mark, `?`. The question mark matches zero
    or one occurrence of a regular expression. If we wanted to capture numbers that
    have exactly one or two digits, we could specify it this way:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 克利尼星号和克利尼加号被称为 *量词*。另外一个正则表达式量词是问号 `?`。问号匹配零次或一次正则表达式的出现。如果我们想捕捉恰好有一位或两位数字的数字，可以这样指定：
- en: '`[0-9][0-9]?`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`[0-9][0-9]?`'
- en: There are a number of additional ways to specify a regular expression class.
    The version we’ve seen for digits specifies a range of values, with the dash (`-`)
    separating the start and end characters. It’s possible to specify multiple ranges
    in a class. For example, to specify a class for both the upper- and lowercase
    characters, one could use `[A-Za-z]`. A class can also contain any arbitrary set
    of characters—for example `[abCD]`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他方式可以指定正则表达式类。我们已经看到的数字版本指定了一个范围，其中连字符 (`-`) 用于分隔起始字符和结束字符。还可以在一个类中指定多个范围。例如，要指定一个同时包含大写字母和小写字母的类，可以使用
    `[A-Za-z]`。一个类还可以包含任何任意字符集合——例如 `[abCD]`。
- en: 'For our purposes, we’ll define a class consisting of the arithmetic operators:
    `[-+/*^]`. There are a couple of items to note about this particular class. The
    first is that since the class starts with a dash, the dash isn’t used to specify
    a range, so it’s treated as an ordinary character. The second is that the circumflex
    (`^`) would be treated differently if it was the first item in the class. For
    example, the regular expression `[^abc]` would match all characters *except* `a`,
    `b`, or `c`.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的，我们将定义一个包含算术运算符的类：`[-+/*^]`。关于这个特定类，有几点需要注意。首先，由于类以连字符开始，因此连字符不会用于指定范围，它被当作普通字符处理。第二点是，如果连字符
    (`^`) 是类中的第一个项目，它将被特殊处理。例如，正则表达式 `[^abc]` 会匹配除 `a`、`b` 或 `c` 外的所有字符。
- en: These are just the basics. Given this overview, let’s look at how Racket implements
    regular expressions and in the process dig deeper into the capability of regular
    expressions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是基础知识。了解了这些概述后，让我们来看看 Racket 如何实现正则表达式，并在此过程中更深入地挖掘正则表达式的能力。
- en: '***Regular Expressions in Racket***'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***Racket 中的正则表达式***'
- en: 'Racket builds regular expressions with the `regexp` function, which takes a
    string and converts it to a regular expression:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Racket 使用 `regexp` 函数构建正则表达式，该函数接受一个字符串并将其转换为正则表达式：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: There’s also a special literal regexp value that starts with `#rx`. For example,
    a regexp value that recognizes unsigned integers is `#rx"[0-9]+"` (or `#rx"[0-9][0-9]*"`
    if you like typing). This syntax is a shorthand method of constructing regular
    expressions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个特殊的文字正则表达式值，它以 `#rx` 开头。例如，一个识别无符号整数的正则表达式值是 `#rx"[0-9]+"`（或者如果你喜欢打字，可以用
    `#rx"[0-9][0-9]*"`）。这种语法是一种构建正则表达式的简写方法。
- en: 'Regexp values are used in conjunction with the functions `regexp-match` and
    `regexp-match-positions`. Suppose we wanted to find the integer embedded in the
    string `"Is the number 1234 an integer?"`. One way to do it would be with the
    following:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式值与函数 `regexp-match` 和 `regexp-match-positions` 一起使用。假设我们想在字符串 `"Is the
    number 1234 an integer?"` 中查找嵌入的整数。可以通过以下方式之一来实现：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The match is returned in a list. The reason for this is that regular expressions
    can contain subexpressions that will result in additional matches being returned.
    We’ll touch on this a bit later. The `regexp-match-positions` functions works
    in a similar fashion to `regexp-match`. The difference is that `regexp-match-positions`
    doesn’t return the matched string; instead, it returns the indices that can be
    used with `substring` to extract the match. Here’s an example.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配结果以列表的形式返回。之所以这样做，是因为正则表达式可以包含子表达式，这会导致额外的匹配项被返回。我们稍后会讨论这一点。`regexp-match-positions`
    函数的工作方式与 `regexp-match` 类似。不同之处在于，`regexp-match-positions` 不返回匹配的字符串；相反，它返回可以与
    `substring` 一起使用的索引，以提取匹配的内容。下面是一个示例。
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: These functions have a number of useful optional parameters. Instead of searching
    the entire string, the range can be limited by specifying start and stop positions.
    Here are some examples.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数有许多有用的可选参数。通过指定起始位置和停止位置，可以限定搜索范围，而不是搜索整个字符串。以下是一些示例。
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice in the second example that `regexp-match-positions` always returns the
    position of the match from the start of the string and not from the specified
    starting position. The ending position is optional, and if not specified, the
    search continues until the end of the string is reached, as seen in the third
    example.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个例子中，注意 `regexp-match-positions` 总是返回从字符串开始位置的匹配位置，而不是从指定的起始位置开始。结束位置是可选的，如果没有指定，搜索会一直进行到字符串的末尾，就像第三个例子中所示。
- en: 'Probably the most basic regular expressions are just literal letters and digits.
    For example, to determine whether a string contains the string `"gizmo"`, one
    could form this query:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 可能最基本的正则表达式就是字面上的字母和数字。例如，要判断一个字符串是否包含字符串 `"gizmo"`，可以形成这样的查询：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Of course this type of functionality could be obtained from `string-contains?`,
    but regular expressions are much more powerful. Used in conjunction with the Kleene
    star and plus operators, we can form much more sophisticated queries.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这种功能也可以通过 `string-contains?` 来实现，但正则表达式要强大得多。与 Kleene 星号和加号操作符配合使用时，我们可以形成更加复杂的查询。
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The period in a regular expression will match any single character, so the regular
    expression above will match any substring that has the string `"cats"` followed
    somewhere else by the string `"dogs"`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式中的句点（`.`）会匹配任何单一字符，因此上面的正则表达式会匹配任何包含字符串 `"cats"`，并且在其他地方跟随字符串 `"dogs"`
    的子字符串。
- en: What if we just want to know if the string contains `"cats"` *or* `"dogs"`?
    This is where the regular expression *or* operator, which consists of a vertical
    bar (`|`), comes into play.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只想知道字符串中是否包含 `"cats"` *或* `"dogs"`，该怎么办？这时正则表达式的*或*操作符，即竖线（`|`），就派上用场了。
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The circumflex (`^`) and and dollar sign (`$`) characters are special regular
    expression markers. The circumflex indicates that the match must start at the
    beginning of the string or, if a start position is specified, at the start position.
    Likewise, the dollar sign indicates that the match must extend to the end of the
    string or the ending position, if specified.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 上箭头符号（`^`）和美元符号（`$`）是特殊的正则表达式标记。上箭头表示匹配必须从字符串的开始处开始，或者如果指定了起始位置，则从起始位置开始。同样，美元符号表示匹配必须延伸到字符串的末尾或结束位置（如果指定了的话）。
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[Table 10-1](ch10.xhtml#ch10tab1) provides a summary description of the various
    regular expression operators. The string “…” in the table represents an arbitrary
    list of characters.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[Table 10-1](ch10.xhtml#ch10tab1) 提供了各种正则表达式操作符的摘要描述。表格中的字符串“…”代表一组任意字符。'
- en: '**Table 10-1**: Regular Expression Operators'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**Table 10-1**：正则表达式操作符'
- en: '| **Operator** | **Description** |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| **Operator** | **描述** |'
- en: '| --- | --- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| . | Match any character |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| . | 匹配任何字符 |'
- en: '| *x** | Match *x* zero or more times |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| *x** | 匹配 *x* 零次或多次 |'
- en: '| *x*+ | Match *x* one or more times |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| *x*+ | 匹配 *x* 一次或多次 |'
- en: '| *x*? | Match *x* zero or one time |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| *x*? | 匹配 *x* 零次或一次 |'
- en: '| *x*∣*y* | Match *x* or *y* |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| *x*∣*y* | 匹配 *x* 或 *y* |'
- en: '| ^ | Match from start of string |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| ^ | 匹配字符串的开始 |'
- en: '| $ | Match to end of string |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| $ | 匹配字符串的结束 |'
- en: '| […] | Define character class |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| […] | 定义字符类 |'
- en: '| [^…] | Define excluded character class |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| [^…] | 定义排除字符类 |'
- en: One thing that’s not obvious in the discussion so far is that each letter and
    digit is in fact a regular expression. A string such as `"abc"` is actually the
    concatenation of the letters `a`, `b`, and `c`. Much like multiplication in a
    mathematical expression such as 3*a*, concatenation is implicit in regular expressions.
    Also like multiplication versus addition, concatenation has a higher precedence
    than the or (`|`) operator. This means that an expression like `"abc|def"` is
    interpreted as `"(abc)|(def)"` instead of `"ab(c|d)ef"` (note the parentheses
    in these last two strings are just examples of how the regular expression `"abc|def"`
    is *interpreted*, but see the following for more on how parentheses play into
    regular expressions).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止讨论中有一个不明显的地方，那就是每个字母和数字实际上都是一个正则表达式。像 `"abc"` 这样的字符串实际上是字母 `a`、`b` 和 `c`
    的连接。就像数学表达式中的乘法（例如 3*a*）一样，连接在正则表达式中是隐式的。并且像乘法与加法一样，连接的优先级高于或（`|`）操作符。这意味着像 `"abc|def"`
    这样的表达式会被解释为 `"(abc)|(def)"`，而不是 `"ab(c|d)ef"`（注意，最后两个字符串中的括号只是用来说明正则表达式 `"abc|def"`
    是如何被*解释*的，但请参见下面关于括号在正则表达式中的作用）。
- en: Parentheses are used in regular expressions to group subexpressions together
    and to specify order of evaluation. Let’s see how this plays out.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 括号在正则表达式中用于将子表达式组合在一起，并指定评估的顺序。让我们看看这如何发挥作用。
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The first two examples return the first part of the string that matches either
    `"abc"` or `"def"`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个示例返回匹配 `"abc"` 或 `"def"` 的字符串的第一部分。
- en: 'The third example, using subexpressions, returns three values. The first is
    the expected match for the overall regular expression. The second value represents
    the answer to the question: within the first returned value, what is the match
    for the subexpression `"(abc)"`? In this case, the value is just the string `"(abc)"`.
    The third value answers this question: within the first returned value, what is
    the match for the subexpression `"(def)"`? In this case there’s no match, so it
    returns `#f`.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个示例，使用子表达式，返回三个值。第一个是符合整体正则表达式的预期匹配。第二个值表示对这个问题的回答：在第一个返回值中，子表达式 `"(abc)"`
    的匹配是什么？在这个案例中，值就是字符串 `"(abc)"`。第三个值回答这个问题：在第一个返回值中，子表达式 `"(def)"` 的匹配是什么？在这个案例中没有匹配，因此返回
    `#f`。
- en: In the fourth example, the match fails because the regular expression is looking
    for a string with either `c` or `d`, but not both. In the last example, the entire
    string was matched, which is reflected in the first return value, but the second
    value reflects the fact that only the `"c"` from the subexpression `"(c|d)"` was
    matched.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在第四个示例中，匹配失败，因为正则表达式在查找包含 `c` 或 `d` 的字符串，但不能同时包含两者。在最后一个示例中，整个字符串被匹配，这在第一个返回值中有所体现，但第二个返回值反映了只有子表达式
    `"(c|d)"` 中的 `"c"` 被匹配。
- en: In our lexical analyzer, we’ll want to use subexpressions, but we’ll only want
    to know whether the overall regular expression found a match, and we won’t be
    interested in individual subexpression matches (that is, we’re mainly using it
    to control evaluation). In this case, we’ll use a special parentheses syntax,
    `"(?>...)"`, which indicates that we only want the overall match without bothering
    to return matched subexpressions (note that `?:` works in a similar way to `?>`,
    but `?:` allows specifying matching modes, like whether or not the match is case
    sensitive—see the Racket Documentation for specifics).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的词法分析器中，我们希望使用子表达式，但我们只关心整体正则表达式是否找到匹配，而不关心各个子表达式的匹配（也就是说，我们主要使用它来控制评估）。在这种情况下，我们将使用特殊的括号语法
    `"(?>...)"`，表示我们只想要整体匹配，而不返回匹配的子表达式（请注意，`?:` 的作用与 `?>` 类似，但 `?:` 允许指定匹配模式，如是否区分大小写——具体请参见
    Racket 文档）。
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: One interesting variant of `regexp-match` is `regexp-match*`. This particular
    function (although we won’t have a need for it in our application) returns the
    subexpression matches only.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`regexp-match` 的一个有趣变种是 `regexp-match*`。这个特定的函数（虽然我们在应用中不需要它）只返回子表达式的匹配项。'
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Notice that `regexp-match` only matches `"abc"`, but `regexp-match*` returns
    a list of all matches, so both `"abc"` and `"def"` are returned. See the Racket
    Documentation for more on `regexp-match*`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`regexp-match` 只匹配 `"abc"`，而 `regexp-match*` 返回所有匹配的列表，因此会返回 `"abc"` 和 `"def"`。更多信息请参见
    Racket 文档中的 `regexp-match*`。
- en: '**NOTE**'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Racket provides an additional form of regular expressions that conform to
    the ones used in the Perl programming language. The function used to create regular
    expressions of this form is called `pregexp`. There’s also a literal syntax, similar
    to the `#rx` form, but starting with `#px` instead. The Perl syntax provides a
    number of useful extensions, including predefined character classes. Since our
    needs are fairly simple, we’ll stick with the basic syntax outlined above.*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*Racket 提供了一种附加的正则表达式形式，符合 Perl 编程语言中使用的正则表达式。用于创建这种正则表达式的函数叫做 `pregexp`。还有一种文字语法，类似于
    `#rx` 形式，但以 `#px` 开头。Perl 语法提供了一些有用的扩展，包括预定义的字符类。由于我们的需求相对简单，我们将坚持使用上述基本语法。*'
- en: '***Regular Expressions in TRAC***'
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***TRAC中的正则表达式***'
- en: In TRAC (or any calculator for that matter), we need to identify valid numeric
    strings (floating-point numbers, to be exact). In addition we’ll want to define
    variables, so that means we’ll need to be able to define identifiers. We’ll need
    to specify mathematical operators for addition, subtraction, and so on as well
    as a judicious set of elementary function names. These items all dictate the use
    of regular expressions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TRAC（或者任何计算器中），我们需要识别有效的数字字符串（准确来说是浮动小数点数）。此外，我们还需要定义变量，这意味着我们需要能够定义标识符。我们还需要指定数学运算符，如加法、减法等，并定义一组合理的基本函数名。这些都需要使用正则表达式。
- en: 'For the purposes of our TRAC application, we’ll always specify the starting
    position for the regular expression search, so each regular expression will start
    with `^`. The recognizer for identifiers is defined as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了我们TRAC应用的需要，我们将始终指定正则表达式搜索的起始位置，因此每个正则表达式都会以`^`开始。标识符的识别器定义如下：
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: It should be clear from the information above that this will match any string
    that starts with a letter and is followed by zero or more letters or digits.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的信息应该能清楚地看出，这将匹配任何以字母开头，后面跟着零个或多个字母或数字的字符串。
- en: The recognizer for numbers (below) is a bit more involved, but the only new
    element is the portion with `\\.`. Since the period (`.`) is a regular expression
    that matches any character, it needs to be *escaped* so that it can be treated
    as a regular character (if a character has a special meaning in regular expressions,
    escaping is a means of removing, or *escaping*, that special meaning). To avoid
    having to escape the period, we could also have specified `\\.` as `[.]`, which
    might be easier to read in some contexts. The regular expression escape character
    is the backslash (`\`), and since it’s embedded in a Racket string, it must also
    be escaped by prefixing it with another slash.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 数字的识别器（如下所示）稍微复杂一点，但唯一的新元素是带有`\\.`的部分。由于句点（`.`）是一个匹配任意字符的正则表达式，它需要被*转义*，以便将其视为普通字符（如果字符在正则表达式中具有特殊含义，转义就是去除或*转义*这种特殊含义的一种方式）。为了避免转义句点，我们也可以将`\\.`指定为`[.]`，这在某些上下文中可能更容易阅读。正则表达式的转义字符是反斜杠（`\`），而且由于它嵌入在Racket字符串中，因此必须通过在前面加一个斜杠来转义。
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: While this is a bit long, it closely mirrors the definition specified by the
    syntax diagram given earlier in [Figure 10-4](ch10.xhtml#ch10fig4). Let’s review
    a few test cases.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这有点长，但它与前面[图 10-4](ch10.xhtml#ch10fig4)中给出的语法图定义非常相似。让我们回顾几个测试用例。
- en: '[PRE16]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Notice in the last expression that the match didn’t include the decimal point,
    since we specified that a decimal point must be followed by at least one digit.
    This is in line with the syntax diagram, since the match is up to but doesn’t
    include the decimal point. If the regular expression had ended with `$`, this
    match would have failed. Notice the following.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在最后的表达式中，匹配没有包括小数点，因为我们规定小数点后必须至少跟随一个数字。这与语法图一致，因为匹配是直到但不包括小数点。如果正则表达式以`$`结尾，这个匹配将会失败。请注意以下内容。
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In this case, the entire string is matched. Here are a few more examples.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，整个字符串都会被匹配。这里有几个更多的例子。
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Again, the match didn’t include the `e`, since we specified that an `e` must
    be followed by at least one digit.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，匹配没有包括`e`，因为我们规定`e`后必须跟随至少一个数字。
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The definition for arithmetic operators is obvious.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 算术运算符的定义很明显。
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We’ll want to skip over any space characters, so we add this to our toolbox:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望跳过任何空格字符，因此我们将其添加到我们的工具箱中：
- en: '[PRE21]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: To make TRAC truly useful, we include the usual transcendental functions.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让TRAC真正有用，我们包括了常见的超越函数。
- en: '[PRE22]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Finally, to facilitate variable assignment, we create a regular expression for
    keywords. For now, `let` is our only keyword.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了方便变量赋值，我们为关键字创建了一个正则表达式。目前，`let`是我们唯一的关键字。
- en: '[PRE23]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '***The Lexer***'
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***词法分析器***'
- en: 'With the essential definitions in place, we move on to actually defining the
    lexical analyzer. Rather than just returning a list of tokens, we’re going to
    supplement each token value with its type. For example, if an identifier is matched,
    we’re going to return a pair: the first element of the pair is the token type,
    in this case `identifier`, and the second element is the matched string. This
    additional information will make the job of the parser a bit easier.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了必要的定义后，我们继续实际定义词法分析器。我们不仅仅返回一个令牌列表，而是将每个令牌值与其类型进行补充。例如，如果匹配到了一个标识符，我们将返回一个对：对的第一个元素是令牌类型，在这种情况下是`identifier`，第二个元素是匹配的字符串。这些额外的信息将使解析器的工作稍微容易一点。
- en: 'The lexer is (conceptually) fairly simple: it just sequentially tries to match
    each token type while keeping track of the position of the matched string. If
    no match is found, the process fails. If a match is found, the token and its position
    are recorded, and the process repeats at the next position. This continues until
    the entire input string is consumed.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 词法分析器（从概念上讲）相当简单：它只是顺序地尝试匹配每种令牌类型，并跟踪匹配字符串的位置。如果没有找到匹配项，过程会失败。如果找到匹配项，则会记录令牌及其位置，并在下一个位置重复该过程。这个过程会一直持续，直到整个输入字符串被消耗完。
- en: Another point of interest is that we’re using `regexp-match-positions` as our
    matching function. This will allow us to easily get the position of the next location
    once a match has been made.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得注意的点是，我们使用`regexp-match-positions`作为我们的匹配函数。这将使我们在匹配成功后，轻松获取下一个匹配位置。
- en: The TRAC lexical analyzer is a function called `tokenize`, as given below. The
    main body of the code is a few lines long (see the `cond` block ➌); the rest of
    the code is composed of a few helper functions to manage some of the bookkeeping.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: TRAC的词法分析器是一个名为`tokenize`的函数，如下所示。代码的主体部分只有几行（见`cond`块➌）；其余部分由一些辅助函数组成，用于处理一些账务管理。
- en: '[PRE24]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: At each iteration of the loop beginning on the second line, the variable `i`
    has the current starting position within the input string `instr`. After initializing
    `str-len` and `next-pos`, the function reads past any whitespace ➊. The `match-reg`
    function executes the regular expression passed to it in `regex` and sets `next-pos`
    to the next position in the string if there is a match; otherwise it’s set to
    `#f`. If there’s a match, `next-pos` is returned; otherwise the function returns
    `#f`. The `classify` function ➋ merges the token type and the token value into
    a Racket `cons` cell. If the token is a number, it also converts the string value
    to the corresponding numeric value. The `at-end` function tests whether the tokenizer
    is at the end of a keyword or function. A string like `sine` is a valid variable
    name, but wouldn’t be valid as the function name `sin`, so `at-end` allows the
    tokenizer to differentiate one input type from another.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在从第二行开始的循环的每次迭代中，变量`i`表示输入字符串`instr`中的当前位置。初始化`str-len`和`next-pos`后，函数会跳过任何空白字符➊。`match-reg`函数执行传递给它的正则表达式，并将`next-pos`设置为字符串中的下一个位置（如果匹配成功）；否则设置为`#f`。如果匹配成功，则返回`next-pos`；否则返回`#f`。`classify`函数➋将标记类型和标记值合并到一个Racket的`cons`单元中。如果标记是数字，它还会将字符串值转换为相应的数字值。`at-end`函数测试词法分析器是否已经到达关键字或函数的结尾。像`sine`这样的字符串是有效的变量名，但不能作为函数名`sin`，因此`at-end`允许词法分析器区分不同的输入类型。
- en: With these functions available, the actual logic to tokenize the string is fairly
    straightforward. A check is made ➌ to see if we’re at the end of the string, and
    if so, the empty list is returned. Next is a series of checks ➍ to see whether
    the text at the current position in the string matches any one of the specified
    regular expressions; if so, the matching token is packaged up in a `cons` cell
    by `classify` and returned. If no match is found, the `cond` statement returns
    `#f`, which results in an error being generated ➑. If the value of `token` is
    anything other than `#f`, it’s added to the returned list ➐. We didn’t bother
    setting up regular expressions for parentheses, since they can be handled easily
    ➎ ➏.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些函数，实际的字符串标记化逻辑就相当简单。首先会进行检查➌，判断我们是否已经到达字符串的末尾，如果是，则返回空列表。接着进行一系列检查➍，判断当前字符串位置的文本是否与指定的某个正则表达式匹配；如果匹配，则通过`classify`将匹配的标记打包成一个`cons`单元并返回。如果没有找到匹配项，`cond`语句将返回`#f`，从而生成一个错误➑。如果`token`的值不是`#f`，则将其添加到返回的列表中➐。我们没有为括号设置正则表达式，因为它们可以很容易地通过➎➏处理。
- en: The order in which the regular expressions are evaluated is important. If `regex-ident`
    were evaluated before `regex-fname`, a function name like `cos` could mistakenly
    be interpreted as an ordinary variable name instead of the cosine function (this
    could be dealt with in the parser, but it’s better to offload as much work as
    possible to the lexical analyzer).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式的评估顺序是非常重要的。如果`regex-ident`在`regex-fname`之前被评估，像`cos`这样的函数名可能会被错误地解释为普通变量名，而不是余弦函数（这可以在解析器中处理，但最好将尽可能多的工作委托给词法分析器）。
- en: 'Here’s an example of the output:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是输出的一个示例：
- en: '[PRE25]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The Parser
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解析器
- en: Our next major TRAC component is the parser. The parser takes the token list
    from the lexical analyzer and outputs an abstract syntax tree that can be further
    processed by either an interpreter or a compiler. We first provide a formal definition
    of our grammar, which will be used as a guide in the construction of the parser.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一个主要TRAC组件是解析器。解析器接受来自词法分析器的标记列表，并输出一个抽象语法树，该语法树可以进一步由解释器或编译器处理。我们首先提供一个正式的语法定义，作为构建解析器的指导。
- en: '***TRAC Grammar Specification***'
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***TRAC 语法规范***'
- en: Computer languages are often specified by a metasyntax (a syntax that describes
    another syntax) called *extended Backus–Naur form (EBNF)*. You’ll notice many
    similarities between EBNF and regular expressions, but EBNF has more expressive
    power. EBNF can be used to describe *context-free grammars*, or *CFG* (see [“A
    Few Words About Languages” on page 272](ch09.xhtml#ch00lev1sec_54)), which are
    out of the reach of regular expressions. (TRAC utilizes a CFG.) This notation
    will be used to give a formal definition to TRAC. We’re going to begin simply,
    by formally defining what’s meant by `digit` (we’re actually going to use the
    lexical analyzer to recognize numbers and identifiers, but for the sake of introducing
    simple examples of EBNF, we also define them here).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机语言通常通过一种称为*扩展巴科斯–诺尔形式（EBNF）*的元语法（描述另一种语法的语法）来指定。你会发现EBNF与正则表达式有许多相似之处，但EBNF具有更强的表达能力。EBNF可用于描述*上下文无关文法*，或*CFG*（参见[第272页的“关于语言的一些话”](ch09.xhtml#ch00lev1sec_54)），这类文法超出了正则表达式的范围。（TRAC使用的是CFG）。这种符号将用于给TRAC提供形式定义。我们将从简单开始，正式定义`digit`的含义（实际上我们将使用词法分析器来识别数字和标识符，但为了介绍EBNF的简单示例，我们也在这里定义它们）。
- en: digit = "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9";
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: digit = "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9";
- en: This is called a *production rule*. As in regular expressions, the vertical
    bar (`|`) means *or*. Items in quotation marks (`"`) are called *terminals*, and
    the identifier `digit` is called a *nonterminal*. A terminal is a sequence of
    actual characters (such as what you type on your computer terminal). A nonterminal
    is a label for a rule, such as `digit` above. The definition for `letter` is similar,
    but we don’t show it here, because you can figure it out.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为*产生式规则*。与正则表达式一样，竖线（`|`）表示*或*。引号中的项目（`" "`）称为*终结符*，而标识符`digit`称为*非终结符*。终结符是一系列实际字符（例如你在计算机终端上输入的字符）。非终结符是一个规则的标签，例如上面的`digit`。`letter`的定义类似，但我们这里不展示，因为你可以自行推断。
- en: 'The production for `unsigned` follows directly from `digit`:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`unsigned`的产生式直接来自`digit`：'
- en: unsigned = digit , { digit };
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: unsigned = digit , { digit };
- en: In EBNF, curly brackets `{` and `}` function almost exactly like the Kleene
    star (except that they also allow grouping items together). This means the items
    within curly brackets can be repeated zero or more times. The comma (`,`) is the
    concatenation operator.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在EBNF中，大括号`{`和`}`几乎完全像克里尼星（Kleene star），不同之处在于它们还允许将项组合在一起。这意味着大括号内的项可以重复零次或多次。逗号（`,`）是连接操作符。
- en: 'With these entities established, we define `identifier` as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些实体确定后，我们定义`identifier`如下：
- en: identifier = letter , { letter | digit };
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: identifier = letter , { letter | digit };
- en: 'The production for `number` is as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`number`的产生式如下：'
- en: number = unsigned , [ "."  unsigned ]
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: number = unsigned , [ "." unsigned ]
- en: ', [ "e",  [ "+" | "-" ] , unsigned ];'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ', [ "e", [ "+" | "-" ] , unsigned ];'
- en: This production introduces the use of square brackets `[` and `]`. Much like
    the regular expression `?`, square brackets enclose optional items.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这个产生式引入了方括号`[`和`]`的使用。与正则表达式中的`?`类似，方括号包含可选项。
- en: 'Function names are defined as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 函数名定义如下：
- en: fname = "sin" | "cos" | "tan" | "asin" | "acos" | "atan"
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: fname = "sin" | "cos" | "tan" | "asin" | "acos" | "atan"
- en: '| "log" | "ln";'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '| "log" | "ln";'
- en: All these productions have regular expression equivalents, so the implementation
    is managed by the lexer. The parser will implement more complex production rules.
    Arithmetic expressions typically contain several levels of nested parenthetical
    expressions; such expressions constitute a context-free grammar. As mentioned
    in the previous chapter, parsing such expressions exceeds the capability of an
    FSA (and by extension, regular expressions). Therefore, we now need the expressive
    power of EBNF to complete our definitions.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些产生式都有正则表达式的等价形式，因此实现由词法分析器管理。语法分析器将实现更复杂的产生式规则。算术表达式通常包含多个层次的嵌套括号表达式；这样的表达式构成了上下文无关文法。如前一章所述，解析这种表达式超出了有限状态自动机（FSA，进而是正则表达式）的能力。因此，我们现在需要EBNF的表达能力来完成我们的定义。
- en: With these preliminaries out of the way, we can now give the rest of the definition
    of the TRAC grammar. Since we only use production names without spaces, commas
    will be omitted, and therefore concatenation is implicit.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些初步工作后，我们可以给出TRAC语法的其余部分定义。由于我们仅使用没有空格的产生式名称，因此省略逗号，因此连接操作是隐式的。
- en: statement = "let" identifier "=" expr
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: statement = "let" identifier "=" expr
- en: '| expr;'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '| expr;'
- en: expr = term { [ "+" | "-" ] term };
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: expr = term { [ "+" | "-" ] term };
- en: term = neg { [ "*" | "/" ] neg };
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: term = neg { [ "*" | "/" ] neg };
- en: neg = "-" neg
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: neg = "-" neg
- en: '| pow;'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '| pow;'
- en: pow = factor | factor "^" pow;
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: pow = factor | factor "^" pow;
- en: factor = number
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: factor = number
- en: '| identifier'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '| identifier'
- en: '| "(" expr ")"'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '| "(" expr ")"'
- en: '| fname  "(" expr ")";'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '| fname  "(" expr ")";'
- en: These rules are written in such a way that the higher-precedence operators are
    nested further down. Because of how EBNF is evaluated (example below), this ensures
    that multiplication and division occurs before addition and subtraction. Likewise,
    exponentiation occurs ahead of multiplication and division. Note also that the
    `pow` production is defined recursively, with the recursive call to the right
    of the operator. This makes exponentiation right-associative, which is how it’s
    normally handled (that is, `a^b^c` is interpreted as `a^(b^c)`, where the rightmost
    exponentiation is performed first).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这些规则是这样编写的，使得优先级更高的运算符被嵌套在更深的地方。因为EBNF的求值方式（见下例），这确保了乘法和除法在加法和减法之前发生。同样，指数运算发生在乘法和除法之前。还要注意，`pow`产生式是递归定义的，递归调用位于运算符的右侧。这使得指数运算是右结合的，这是正常的处理方式（即，`a^b^c`被解释为`a^(b^c)`，其中最右侧的指数运算首先进行）。
- en: '[Table 10-2](ch10.xhtml#ch10tab2) illustrates how the productions are expanded
    for the expression *a* * (1 + *b*).'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 10-2](ch10.xhtml#ch10tab2)展示了如何为表达式*a* * (1 + *b*)扩展产生式。'
- en: '**Table 10-2**: Expansion of *a* * (1 + *b*)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 10-2**：*a* * (1 + *b*)的展开'
- en: '![Image](../images/p0290.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/p0290.jpg)'
- en: Standard typeface is used to designate terminal tokens, and italics are used
    to designate nonterminal rules. The notation *expr-op* refers to the expression
    operators `+` and `-`, and *term-op* refers to the term operators `*` and `/`.
    Notice that only the leftmost production is expanded until a terminal value is
    recognized. Expansion starts with the *statement* rule on row 1\. A *statement*
    can be an *expr*, which in turn can be a *term*; this is reflected on rows 2 and
    3.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 标准字体用于表示终结符，而斜体用于表示非终结符规则。符号*expr-op*表示表达式运算符`+`和`-`，而*term-op*表示项运算符`*`和`/`。请注意，只有最左侧的产生式会展开，直到识别出一个终结符值。展开从第1行的*statement*规则开始。一个*statement*可以是一个*expr*，而*expr*又可以是一个*term*；这在第2行和第3行中得到了体现。
- en: A *term* can be a *neg* followed by a *term-op* followed by a *neg*. This is
    shown on row 4\. Expansion continues in this fashion until we get to row 7\. Notice
    that our leftmost rule is *identifier*. We now have a terminal, `a`, that satisfies
    this rule. The expansion of this rule is shown on row 8\. The leftmost rule on
    this row is *term-op*, which can be expanded to the terminal `*`. Expansion continues
    in this way until we have parsed the entire string on row 22.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*term*可以是一个*neg*，后跟一个*term-op*，再后跟一个*neg*。这一点在第4行展示。展开按这种方式继续，直到我们到达第7行。请注意，我们的最左侧规则是*identifier*。现在我们有一个终结符`a`，它满足这个规则。这个规则的展开显示在第8行。此行的最左侧规则是*term-op*，它可以展开为终结符`*`。展开继续进行，直到我们在第22行解析完整个字符串。
- en: This grammar is designed in such a way that it’s an *LL(1) grammar*. The term
    LL(1) means that it scans its input (the list of tokens from the lexer) left to
    right, using a leftmost derivation (as we did in the walk-through above), with
    a lookahead (lookahead just defines how far ahead we need to look into the list
    of input tokens) of one symbol (token). This particular type of grammar allows
    parsers to be constructed in such a way that no backtracking is required to parse
    the input stream. LL(1) grammars are recognized by *recursive descent parsers*
    in which each nonterminal production has a procedure (or function) that’s responsible
    for recognizing its portion of the grammar and returns the corresponding portion
    of the syntax tree (or generating an error if the input is incorrect).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个语法是设计成一个*LL(1)语法*。LL(1)中的LL表示它从左到右扫描输入（来自词法分析器的符号列表），使用最左推导（就像我们在上面的讲解中做的那样），并且具有一个向前看（向前看定义了我们需要查看输入符号列表的多远）的范围为一个符号（符号）。这种特定类型的语法允许解析器以一种无需回溯即可解析输入流的方式构建。LL(1)语法由*递归下降解析器*识别，其中每个非终结符产生式都有一个过程（或函数），负责识别其语法部分，并返回相应的语法树部分（如果输入不正确，则生成错误）。
- en: '***The TRAC Parser***'
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***TRAC解析器***'
- en: As mentioned in the previous section, TRAC will use a recursive descent parser.
    A recursive descent parser is mainly a set of mutually recursive functions where
    there’s a function for each grammar rule. There’s always a starting function (corresponding
    to the top-level rule—which is why this is called a top-down parser), which calls
    other functions as defined by the grammar. The *descent* part of the definition
    comes about due to the fact that the rules continue to nest down until a terminal
    (or error) is encountered.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一节所述，TRAC将使用递归下降解析器。递归下降解析器主要是一组相互递归的函数，每个语法规则都有一个对应的函数。总是有一个起始函数（对应于顶层规则——这就是为什么它被称为自顶向下解析器），该函数根据语法规则调用其他函数。定义中的*descent*部分之所以存在，是因为规则会继续嵌套，直到遇到终结符（或错误）。
- en: We need a few global variables to keep track of the tokens during the parsing
    process.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一些全局变量来跟踪解析过程中的令牌。
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Next are the predicates used to test various operator types.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是用于测试各种运算符类型的谓词。
- en: '[PRE27]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The following procedure updates the token info whenever the next token value
    is requested.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 以下过程会在每次请求下一个标记值时更新令牌信息。
- en: '[PRE28]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `accept` function tests whether the input token is of the expected type
    and, if so, reads in the next token and returns `#t`; otherwise, it returns `#f`.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`accept`函数测试输入的令牌是否为预期类型，如果是，则读取下一个令牌并返回`#t`；否则返回`#f`。'
- en: '[PRE29]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The `expect` function tests whether the input token is of the expected type
    and, if so, reads in the next token and returns `#t`; otherwise, it generates
    an error.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`expect`函数测试输入的令牌是否为预期类型，如果是，则读取下一个令牌并返回`#t`；否则，它会产生错误。'
- en: '[PRE30]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The reason we have both `accept` and `expect` is that in some cases we need
    to test for various token types without generating an error. For example, the
    *factor* rule accepts a number of different token types. We don’t want to generate
    an error if we’re testing for a number and the current token is an identifier,
    because if the number test fails, we still want to test for an identifier, so
    we use `accept`. On the other hand, if the expected token *must* be of a particular
    type, we use the `expect` function, which generates an error if the current token
    isn’t of the expected type.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们同时使用`accept`和`expect`的原因是，在某些情况下，我们需要测试各种令牌类型，而不产生错误。例如，*factor*规则接受多种不同类型的令牌。如果我们在测试一个数字时，当前令牌是一个标识符，我们不希望产生错误，因为即使数字测试失败，我们仍然希望测试标识符，因此使用`accept`。另一方面，如果预期的令牌*必须*是某种特定类型，我们使用`expect`函数，如果当前令牌不是预期的类型，它将产生错误。
- en: 'We’re now able to define the functions that correspond to each grammar production.
    Even though recursive descent parsers are top-down parsers, we’re going to present
    the code from the bottom up. Since there are fewer dependencies that way, it should
    be easier to understand. Given that, the first function is `factor`:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以定义与每个语法生成式对应的函数。尽管递归下降解析器是自顶向下的解析器，但我们将从底向上展示代码。这样依赖关系更少，应该更容易理解。基于此，第一个函数是`factor`：
- en: '[PRE31]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Note that we need to save the current token value in `val` (which is set in
    the first line of `let`). Once `accept` is called and a match is found, the variable
    `token-value` is set to the value of the next token, which isn’t what we need
    in the return value in the `cond` section of the code. The correspondence between
    the various `cond` tests and the production for `factor` should be self-evident.
    As a bit of explanation for the third condition branch ➊, if we look back at our
    rule for `factor`, we find `"(" expr ")"` as an accepted production. So we see
    that this portion of the code accepts a left parenthesis, calls `expr` to parse
    that part of the rule, and then *expects* a right parenthesis (and errors out
    if that isn’t the current token).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们需要将当前的令牌值保存在`val`中（它在`let`的第一行被设置）。一旦调用了`accept`并找到匹配项，变量`token-value`会被设置为下一个令牌的值，但这不是我们在代码的`cond`部分返回值所需要的内容。各种`cond`测试与`factor`生成式之间的对应关系应该是显而易见的。关于第三个条件分支➊的简要说明，如果我们回顾一下`factor`的规则，会发现`"("
    expr ")"`是一个有效的生成式。因此，我们看到这段代码接受一个左括号，调用`expr`来解析该部分规则，然后*期望*一个右括号（如果当前标记不是右括号，则会报错）。
- en: For each accepted value, a `cons` cell is created where the first element is
    a symbol identifying the node type and the second element is the value. The function
    call portion of the `factor` rule (`fname "(" expr ")"`) wasn’t given a name,
    but we specify ’`func-call` here to identify the node type. This pattern of defining
    functions for rules will be replicated in all the productions, with the end result
    being the desired parser to construct the syntax tree.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个接受的值，会创建一个`cons`单元，其中第一个元素是一个符号，用于标识节点类型，第二个元素是值。`factor`规则中的函数调用部分（`fname
    "(" expr ")"`）没有给它起名字，但我们在这里指定`func-call`来标识节点类型。定义规则的函数的这种模式将在所有的产生式中得到复制，最终的结果是构造语法树所需的解析器。
- en: 'Next up is the code for `pow`:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是`pow`的代码：
- en: '[PRE32]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This is written in such a way to enforce the grammar rule that requires it to
    be right-associative. This is managed by the recursive call to `pow` ➊. The value
    returned for `pow` is either just the value returned from `factor` or a new pair
    (if the symbol `^` is recognized). The first element of this new pair is the character
    `^` and the second element is another pair, where the first element is the base
    number (from `e1`) and the second element is the power it’s being raised to (from
    a recursive call to `pow`).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这是以一种方式编写的，目的是强制执行语法规则，要求它是右结合的。通过递归调用`pow` ➊来管理这一点。`pow`返回的值要么是`factor`返回的值，要么是一个新对（如果识别到符号`^`）。这个新对的第一个元素是字符`^`，第二个元素是另一个对，其中第一个元素是基数（来自`e1`），第二个元素是它的幂（来自对`pow`的递归调用）。
- en: The code for `neg` (unary minus) is quite simple. If needed, it appends a negation
    operator to the return value from `pow` to generate a node for unary minus.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`neg`（一元减法）的代码非常简单。如果需要，它会将一个否定操作符附加到`pow`的返回值上，从而生成一元减法的节点。'
- en: '[PRE33]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Multiplication and division are handled by the next function, `term`. As long
    as it keeps recognizing other `term` operators (`*` or `/`), it loops, gathering
    values from `neg`. Notice how this differs from the code for `pow`: this code
    makes `term` operators left-associative whereas the code for `pow` makes exponentiation
    right-associative.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 乘法和除法由下一个函数`term`处理。只要它继续识别其他`term`操作符（`*`或`/`），它就会循环，从`neg`中收集值。注意这与`pow`的代码不同：这段代码使得`term`操作符是左结合的，而`pow`的代码使得指数运算是右结合的。
- en: '[PRE34]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Addition and subtraction are managed by `expr`. This function works analogously
    to `term`.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 加法和减法由`expr`管理。这个函数的工作方式与`term`类似。
- en: '[PRE35]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Finally, we get to the top level, where most of the work that needs to be done
    is to set things up to parse the assignment statement.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们来到顶层，大部分需要做的工作是设置解析赋值语句的过程。
- en: '[PRE36]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The actual parser just has to call `tokenize` (the lexer) to convert the input
    string to a list of tokens and kick off the parsing process by calling `statement`.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的解析器只需要调用`tokenize`（词法分析器）将输入字符串转换成一个符号列表，并通过调用`statement`启动解析过程。
- en: '[PRE37]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Notice that if there’s anything left in `token-list`, an error is generated.
    Without this, an input that starts with a valid expression, but has some dangling
    tokens. For example, the following would return a partial result (in this case
    ’`(ident . "x")`) without alerting the user that the input was invalid.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果`token-list`中还有剩余的内容，会生成一个错误。如果没有这个机制，输入开始时是一个有效的表达式，但如果有一些悬挂的符号，也不会警告用户输入无效。例如，以下输入将返回一个部分结果（在这个例子中是`(ident
    . "x")`），却没有提醒用户输入无效。
- en: '[PRE38]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Here it goes with a test input expression:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个测试输入表达式：
- en: '[PRE39]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: It seems to work, but it’s a bit difficult to decipher what’s actually going
    on with this output. We need a procedure that will take the syntax tree and print
    it in a way that makes the structure more obvious. So here it is!
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 它似乎能工作，但要解读这个输出的实际内容有些困难。我们需要一个程序，它能够接收语法树，并以一种更直观的方式打印出来，从而使结构更明显。所以，这就是它的实现！
- en: '[PRE40]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: It’s essentially one big `match` statement that matches against the node type
    of the tree. The indentation varies depending on the depth of the node in the
    tree. This will provide a visual representation of how the child nodes are lined
    up. With this, we can generate output that is a bit more decipherable.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 它本质上是一个大的`match`语句，用来与树的节点类型进行匹配。缩进根据节点在树中的深度而变化。这将提供一个视觉化的表示，展示子节点如何排列。通过这种方式，我们可以生成更容易解读的输出。
- en: '[PRE41]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The parser creates a syntax tree of an input string, and `print-tree` prints
    out a visual representation of the tree. It turns out that `print-tree` provides
    a framework with which to build a routine that can reconstruct the input string
    from the syntax tree. This can be useful for debugging purposes, since it allows
    us to see whether an output string constructed from the AST corresponds to the
    input string. We reverse the process by first creating a token list from the syntax
    tree, and then we create an output string by appending the tokens together.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器创建了输入字符串的语法树，而`print-tree`打印出树的可视化表示。事实证明，`print-tree`提供了一个框架，通过它可以构建一个例程，从语法树中重构输入字符串。这对于调试非常有用，因为它允许我们检查从AST构建的输出字符串是否与输入字符串对应。我们通过首先从语法树创建一个标记列表，然后将这些标记拼接在一起生成输出字符串，来逆转这个过程。
- en: The biggest issue in creating a tree-to-string conversion function lies in deciding
    when to add parentheses around an expression. We certainly want to include them
    when required, but we don’t want to include unnecessary parentheses when they
    aren’t required. To facilitate this, we create a function that returns the precedence
    and associativity of each operator. This is needed to determine whether or not
    parentheses are required (for example, operators with lower precedence will require
    parentheses, and if the precedence is the same, the need for parentheses is dictated
    by the associativity).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 创建树到字符串的转换函数的最大难点在于决定何时在表达式周围加上括号。我们当然希望在需要时包含括号，但在不需要时我们不希望加入不必要的括号。为了解决这个问题，我们创建了一个返回每个操作符优先级和结合性的函数。这是为了判断是否需要括号（例如，优先级较低的操作符需要括号，如果优先级相同，则由结合性决定是否需要括号）。
- en: '[PRE42]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: If a symbol isn’t in the table, the second λ expression returns a default value
    of `(info 90` ’`n)`.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果符号不在表中，第二个λ表达式将返回默认值`(info 90` ’`n)`。
- en: 'With this function at hand, we can produce `ast->string`:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个功能，我们可以生成`ast->string`：
- en: '[PRE43]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'A local function called `push` has been defined that adds a token to the output
    string port (`expr-port`). One major difference between this code and `print-tree`
    is that all the `print` statements have been changed to `push` statements. In
    addition, the function that handles the various operators, `push-op` (instead
    of `print-op`), has been expanded to decide when to include parentheses. Aside
    from these changes, the structural similarities, starting with the `match` statement,
    between `ast->string` and `print-tree` should be fairly obvious. So now we can
    go full circle: input string to abstract syntax tree and back to input string:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了一个本地函数`push`，它将一个标记添加到输出字符串端口（`expr-port`）。这段代码与`print-tree`的主要区别在于，所有的`print`语句都被改成了`push`语句。此外，处理各种操作符的函数`push-op`（取代了`print-op`）被扩展，以决定何时加入括号。除了这些变化之外，从`match`语句开始，`ast->string`和`print-tree`之间的结构相似性应该是显而易见的。那么现在我们可以完整回环：从输入字符串到抽象语法树，再到输入字符串：
- en: '[PRE44]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: TRAC
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TRAC
- en: Once the syntax tree has been created, the rest of the work is smooth sailing.
    The main remaining components are a dictionary to hold our variable values and
    the code that actually evaluates our input expressions and produces a numeric
    value. Before we wrap up, we’ll look at a few enhancements, such as adding complex
    numbers and setting the angular mode.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦语法树创建完成，其余的工作就变得轻松了。剩下的主要部分是一个字典，用于保存变量值，以及实际计算输入表达式并生成数值的代码。在我们结束之前，我们将看一些改进，例如添加复数和设置角度模式。
- en: Adding a Dictionary
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加字典
- en: Since TRAC has the capability to assign values to variables, we’ll need a dictionary
    to hold the values. We’re actually going to create this in the form of a function,
    where we pass it an action (for example, `get` to retrieve a value and `set` to
    assign a value). This will make it easier to extend its functionality without
    cluttering up the namespace with additional definitions. This also provides an
    example of using a single *rest-id* in a lambda expression. A rest-id is a parameter
    that takes all the arguments supplied to the function in a single list. The `args`
    parameter in the code below is the rest-id that accepts a list of arguments. Notice
    that it’s not surrounded by parentheses.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 由于TRAC有能力为变量分配值，我们将需要一个字典来保存这些值。我们实际上将以函数的形式创建它，其中我们传递一个动作（例如，`get`用于检索值，`set`用于分配值）。这将使其更容易扩展其功能，而不会用额外的定义来弄乱命名空间。这也提供了一个在lambda表达式中使用单个*rest-id*的示例。rest-id是接受单个列表中提供给函数的所有参数的参数。下面代码中的`args`参数是一个rest-id，接受一个参数列表。请注意，它没有被括号包围。
- en: '[PRE45]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Observe that this code actually uses a closure to construct the dictionary (that
    is, `vars`, in the form of a hash table). This function returns a function that
    has the dictionary embedded in it.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此代码实际上使用闭包来构造字典（即`vars`，以哈希表的形式）。此函数返回一个嵌入了字典的函数。
- en: With a dictionary to hold variable values in place, we can now define the expression
    evaluator.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有了一个用于保持变量值的字典，我们可以定义表达式评估器。
- en: '[PRE46]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Notice that it follows a pattern similar to `ast->string` and `print-tree`;
    the difference is that now, instead of returning or printing a string, it traverses
    the syntax tree and computes the numerical values of the nodes.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 注意它遵循类似于`ast->string`和`print-tree`的模式；不同之处在于，现在它不是返回或打印字符串，而是遍历语法树并计算节点的数值。
- en: Let’s walk through what happens. Given the AST, we extract the parsed symbol
    (`sym`) and value (`val`) ➊. We then match the symbol ➍ and take the appropriate
    action. If we’re given a literal number, we simply return the value. If we have
    an identifier, then we extract the value from the dictionary using `(var` ’`get
    val)`. An arithmetic operation will result in calling `eval-op` ➋, which first
    recursively extracts arguments `n1` and `n2`. It then matches the input symbol
    to determine which operation to perform. A function call ➎ recursively extracts
    its argument via `(loop (cdr val))` and calls `eval-func` ➌ to actually perform
    the computation.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步走一遍发生的事情。给定AST，我们提取解析的符号（`sym`）和值（`val`）➊。然后我们匹配符号➍并采取适当的操作。如果给定的是字面数字，我们简单地返回值。如果是标识符，我们使用`(var`
    ’`get val)`从字典中提取值。算术运算将调用`eval-op` ➋，它首先递归提取参数`n1`和`n2`。然后，它匹配输入符号以确定要执行的操作。函数调用➎通过`(loop
    (cdr val))`递归提取其参数，并调用`eval-func` ➌来执行计算。
- en: We’re now in a position to actually perform some calculations.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以实际执行一些计算了。
- en: '[PRE47]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: To keep from having to call `parse` and `eval-ast` every time, we need to set
    up a read-evaluate-print loop (REPL). To do this, we create a `start` function
    that kicks off the process and sets up a few predefined variables.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免每次调用`parse`和`eval-ast`，我们需要设置一个交互式读取-评估-打印循环（REPL）。为此，我们创建一个`start`函数来启动这个过程并设置几个预定义变量。
- en: '[PRE48]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Now we can exercise TRAC in a more natural way.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以以更自然的方式运行TRAC了。
- en: '[PRE49]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '***A Few Enhancements***'
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***一些增强***'
- en: We’ve now established the basic functionality of TRAC, but to make it truly
    useful, we’ll add a few enhancements. One important enhancement is to have it
    fail gracefully if the user makes an input error. It might also be nice to provide
    advanced users the ability to work with complex numbers. We’ll explore these topics
    and more in the sections that follow.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经建立了TRAC的基本功能，但要使其真正有用，我们将添加一些增强功能。一个重要的增强功能是使其在用户输入错误时优雅地失败。如果能让高级用户能够处理复数也不错。我们将在接下来的部分中探讨这些主题及更多内容。
- en: '**Exception Handling**'
  id: totrans-233
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**异常处理**'
- en: 'As it stands, TRAC is quite fragile. The slightest misstep will cause it to
    fail:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，TRAC非常脆弱。稍有不慎就会导致失败：
- en: '[PRE50]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: It should be more forgiving of erroneous input (we’re human, after all). To
    alleviate this situation, we leverage Racket’s *exception handling* capability.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该更容忍输入错误（毕竟我们是人类）。为了缓解这种情况，我们利用了Racket的*异常处理*能力。
- en: When an error occurs in executing Racket code, an exception is raised. An exception
    will either have a type of `exn` or one of its subtypes. The exceptions raised
    by `error` have a type of `exn:fail`. To trap such errors, one wraps the code
    in a `with-handlers` form. A modified version of `start` that uses `with-handlers`
    is given here.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行 Racket 代码时发生错误，异常将被引发。异常将具有 `exn` 类型或其子类型之一。由 `error` 引发的异常具有 `exn:fail`
    类型。为了捕获这种错误，可以将代码包装在 `with-handlers` 结构中。这里给出了一个使用 `with-handlers` 的修改版 `start`
    函数。
- en: '[PRE51]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The `with-handlers` form can trap any number of different types of error. In
    this case, we use the `exn:fail?` predicate to trap generated `exn:fail` errors
    generated by the `error` form. Each trapped error type has a corresponding function
    to manage the trapped error.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '`with-handlers` 结构可以捕获多种不同类型的错误。在这种情况下，我们使用 `exn:fail?` 谓词来捕获由 `error` 结构生成的
    `exn:fail` 错误。每种捕获的错误类型都有一个相应的函数来处理捕获的错误。'
- en: Here we use a lambda expression to generate the somewhat uninformative `"An
    error occurred."` message. Evaluating the expression with the missing right parenthesis
    now produces the following outcome.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们使用一个 lambda 表达式来生成稍微不具信息性的 `"An error occurred."` 消息。现在，评估缺少右括号的表达式将产生以下结果。
- en: '[PRE52]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Observe that this time, even though an error has occurred, the `>` prompt appears,
    indicating that the program is still running. The user now has an opportunity
    to re-enter the expression and continue working.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这一次，尽管发生了错误，`>` 提示符仍然出现，表示程序仍在运行。用户现在有机会重新输入表达式并继续工作。
- en: 'Suppose we want to provide a more informative error message, like the one provided
    by Racket. The `e` parameter handed to the exception handling function is an `exn`
    structure. This structure has a `message` field that contains the actual text
    string of the raised error. So to print the text of the error message, we need
    to modify the lambda function to read as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想提供一个更具信息量的错误信息，类似于 Racket 提供的错误信息。传递给异常处理函数的 `e` 参数是一个 `exn` 结构体。这个结构体有一个
    `message` 字段，包含了引发的错误的实际文本字符串。所以，为了打印错误信息的文本，我们需要修改 lambda 函数，使其如下所示：
- en: '[PRE53]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'With this change in place, a session with an erroneous entry would proceed
    as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 进行此修改后，一个包含错误输入的会话将按如下方式进行：
- en: '[PRE54]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Notice that evaluating an expression such as `sqrt(-1)` will produce the complex
    number `0+1i`. This may be confusing to users not familiar with complex numbers.
    In this case, it may be preferable to raise an error instead of returning a result.
    To accommodate this, the `start` procedure could be modified as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，像 `sqrt(-1)` 这样的表达式会产生复数 `0+1i`。这可能会让不熟悉复数的用户感到困惑。在这种情况下，最好是引发一个错误，而不是返回结果。为此，可以将
    `start` 函数修改如下：
- en: '[PRE55]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'With this change in place, evaluating an expression that returns a complex
    number would produce the following result:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 进行此修改后，评估一个返回复数的表达式将产生以下结果：
- en: '[PRE56]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '**Complex Numbers**'
  id: totrans-251
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**复数**'
- en: In the previous section, we mentioned throwing an exception if a calculation
    produces a complex number. If users *are* familiar with complex numbers, the lexer
    could be modified to accept complex numbers, in which case the original `start`
    procedure could be kept in place. It’s not extremely difficult to modify TRAC’s
    lexical analyzer such that it works with complex numbers. One might be tempted
    to create a regular expression that recognizes a complex number such as `1+2i`.
    That would be a big mistake. If one evaluates an expression such as `2*1+2i`,
    the expected result is `2+2i` since multiplication has a higher precedence than
    addition. If the lexer returns the entire expression as a number, the parser will
    treat the expression `2*1+2i` as `2*(1+2i)`, which will give the result `2+4i`.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们提到如果计算结果是复数则抛出异常。如果用户*熟悉*复数，词法分析器可以修改为接受复数类型，在这种情况下，原始的 `start` 函数可以保持不变。修改
    TRAC 的词法分析器，使其能够处理复数，并不是非常困难。人们可能会倾向于创建一个识别复数（例如 `1+2i`）的正则表达式。那将是一个大错误。如果评估像
    `2*1+2i` 这样的表达式，期望的结果是 `2+2i`，因为乘法的优先级高于加法。如果词法分析器将整个表达式当作一个数字返回，解析器将把表达式 `2*1+2i`
    当作 `2*(1+2i)` 来处理，从而得到 `2+4i` 的结果。
- en: 'The actual solution is quite simple. Instead of recognizing the entire complex
    number, we only recognize the imaginary part. That is, the regular expression
    for a number becomes as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的解决方案非常简单。我们不是识别整个复数，而是只识别虚部。也就是说，数字的正则表达式变为如下所示：
- en: '[PRE57]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Notice that the only change in the expression is the inclusion of `i?` at the
    end, which means we accept an optional `i` at the end of a numeric input.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，表达式中唯一的变化是在末尾添加了`i?`，这意味着我们接受数字输入末尾的可选`i`。
- en: In addition, we make a small modification to `classify` (which is embedded in
    `tokenize`) to handle imaginary numbers.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们对`classify`（嵌入在`tokenize`中）进行了一些小修改，以处理虚数。
- en: '[PRE58]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'With these changes in place, we can compute the following in TRAC:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些更改完成后，我们可以在TRAC中进行如下计算：
- en: '[PRE59]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '**Mode, Reset, and Help Commands**'
  id: totrans-260
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**模式、重置和帮助命令**'
- en: 'Most calculators allow the user to compute trigonometric functions using either
    degrees or radians. We’d be remiss to omit this capability from TRAC. This will
    require a global variable to contain the trigonometric mode:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数计算器允许用户使用角度或弧度计算三角函数。如果TRAC没有这个功能那就太遗憾了。为此，我们需要一个全局变量来存储三角函数模式：
- en: '[PRE60]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: TRAC currently handles numeric entries exactly as Racket would. That is, if
    an exact value is divided by an exact value, a fraction results. For example entering
    `2/4` would return a result of `1/2`. This is typically not what’s expected for
    run-of-the-mill calculations. We’ll thus modify TRAC to give the user the option
    to treat all entries as floating-point numbers or to retain fractional entries.
    To enable this, we’ll use a global variable to maintain the numeric mode.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: TRAC目前处理数字输入的方式与Racket完全相同。也就是说，如果一个精确值除以另一个精确值，将返回一个分数结果。例如，输入`2/4`会返回`1/2`。这通常不是日常计算时所期望的结果。因此，我们将修改TRAC，让用户可以选择将所有输入当作浮点数处理，或者保留分数输入。为了实现这一点，我们将使用一个全局变量来维护数字模式。
- en: '[PRE61]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: It would also be nice to allow the user to reset TRAC to its default start-up
    state, so TRAC is given a new keyword called `reset`, which requires the following
    change to `regex-keyword`.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，允许用户将TRAC重置为默认启动状态也是很好的，因此TRAC引入了一个新的关键字`reset`，这要求对`regex-keyword`做出以下更改。
- en: '[PRE62]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The question mark at the end will allow TRAC to have a mini–help system, which
    is accessed by entering `?` on the command line (more on this shortly).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 末尾的问号将允许TRAC拥有一个迷你帮助系统，用户可以通过在命令行输入`?`来访问它（稍后会详细介绍）。
- en: 'Entering `reset` will result in clearing previous entries in the TRAC dictionary
    and priming it with the default values. These actions are bundled up into a `reset`
    procedure:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 输入`reset`将清除TRAC字典中的先前条目，并用默认值初始化它。这些操作被捆绑成一个`reset`过程：
- en: '[PRE63]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The `start` procedure then becomes as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`start`过程变为如下：
- en: '[PRE64]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'To accommodate the new `reset` and `?` keywords, the `statement` portion of
    the parser is updated as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 为了适应新的`reset`和`?`关键字，解析器的`statement`部分进行了如下更新：
- en: '[PRE65]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: If `reset` or `?` is entered for input, the function returns immediately without
    drilling down into the parser so that the expression evaluator can handle these
    commands directly.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 如果输入`reset`或`?`，函数会立即返回，而不会深入解析器，以便表达式求值器可以直接处理这些命令。
- en: Of course we still need to modify the trigonometric functions to work properly
    depending on the current mode. The handling of numeric entries will also need
    to be adjusted to ensure that they honor the current numeric mode. Here’s the
    tweaked version of `ast-eval`.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们仍然需要修改三角函数，以确保它们在当前模式下正确运行。数字输入的处理也需要调整，以确保它们遵循当前的数字模式。以下是调整过的`ast-eval`版本。
- en: '[PRE66]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The actual changes to the trigonometric functions are minor: just a multiplication
    or division by `mode` does the trick (observe how `trig-mode` is handled ➊). Code
    is also added to properly convert exact values to inexact when the mode is set
    to `FLOAT` ➋. Most of the remaining changes involve modifying the assignment statement
    to trap changes to `TrigMode` ➎ and `NumMode` ➏ to ensure that they can only be
    assigned proper values. Note the additions for `reset` ➌ and `help` ➍. The `print-help`
    procedure is provided here:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 对三角函数的实际更改是微小的：只需通过`mode`进行乘法或除法就能完成（观察`trig-mode`是如何处理的➊）。代码还增加了在模式设置为`FLOAT`时正确将精确值转换为不精确值的功能➋。其余的大多数更改都涉及修改赋值语句，以捕捉`TrigMode`➎和`NumMode`➏的变化，确保它们只能被赋予正确的值。注意`reset`➌和`help`➍的新增内容。这里提供了`print-help`过程：
- en: '[PRE67]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Here’s a session illustrating the new functionality.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个展示新功能的会话。
- en: '[PRE68]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Pretty cool, eh?
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 相当酷，是吧？
- en: '***Making Sure TRAC Works Properly***'
  id: totrans-282
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***确保TRAC正常工作***'
- en: Given the nature of this application, it would be nice to have some degree of
    comfort that it’s performing the calculations properly. If you were using this
    to calculate the landing trajectory of a spaceship to the moon, it wouldn’t do
    to have it return a calculation that results in the spaceship flying out into
    empty space instead.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这个应用的性质，能够确认其正确执行计算是很有必要的。如果你用这个计算月球着陆轨迹的话，结果应该是正确的，而不是返回一个将飞船送入空旷太空的计算。
- en: Of course one could sit down and manually enter a large number of test equations
    into TRAC and verify the results by entering the same equations on some other
    calculator and seeing if the results are the same. This clearly wouldn’t be much
    fun (or very efficient, for that matter). No, we want an automated process where
    we can have the computer do all the work. The approach we’re going to take is
    to build a procedure that will generate a random Racket expression. This expression
    can be evaluated using the Racket `eval` function to get a numeric value. In addition
    we’ll need a function that converts the Racket expression into a TRAC expression
    string. We can evaluate the TRAC expression to see if it returns the same value.
    We can then have the computer repeat this process thousands of times to make sure
    we don’t produce any mismatches.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，理论上你可以坐下来手动输入大量的测试方程到TRAC中，并通过在其他计算器上输入相同的方程来验证结果，看看它们是否一致。显然，这样做既不有趣（也不高效）。不，我们希望有一个自动化的过程，让计算机做所有的工作。我们采取的方法是构建一个程序，生成一个随机的Racket表达式。这个表达式可以通过Racket的`eval`函数计算出一个数值。此外，我们还需要一个函数，将Racket表达式转换为TRAC表达式字符串。我们可以评估TRAC表达式，看看它是否返回相同的值。接着，我们可以让计算机重复执行这个过程几千次，以确保没有出现任何不匹配的结果。
- en: Here’s the code for the random Racket expression generator.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是随机Racket表达式生成器的代码。
- en: '[PRE69]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: An operator from the `ops` vector is randomly selected by the `gen-racket` function.
    Values in `ops` include both the operator symbol and the number of arguments it’s
    expecting (this is called its *arity*). Notice that both `log` and minus (`-`)
    have two different arities. The function call `log(x)` (base-10 logarithm) in
    TRAC is the same as `(log x 10)` in Racket. Then `gen-racket` will build an expression
    containing from one to five random operations or functions with random floating-point
    numeric arguments. The result is an actual Racket expression instead of an AST,
    where its arguments and functions are populated with random values.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`gen-racket`函数会从`ops`向量中随机选择一个操作符。`ops`中的值包括操作符符号以及它所期望的参数个数（称为它的*元数*）。请注意，`log`和减号（`-`）有两个不同的元数。TRAC中的`log(x)`（以10为底的对数）与Racket中的`(log
    x 10)`是相同的。然后，`gen-racket`会构建一个包含从一个到五个随机操作或函数的表达式，且这些操作或函数的浮点数参数是随机生成的。结果是一个实际的Racket表达式，而非抽象语法树（AST），其参数和函数都会被随机值填充。'
- en: Here’s a look at some of the expressions that `gen-racket` produces.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是`gen-racket`生成的一些表达式的展示。
- en: '[PRE70]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Most of the work involves converting the Racket expressions into TRAC expressions.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分工作都涉及将Racket表达式转换为TRAC表达式。
- en: '[PRE71]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: This is largely an adaptation of the `ast->string` function, but using the randomly
    generated Racket expressions created by `gen-racket` as input instead of the TRAC
    syntax tree. We’ve had to make some accommodations to account for the multiple
    arities of `-` and `log`. We also match against the literal function symbols.
    Aside from these considerations, the code should closely mirror that of `ast->string`.
    Here are a few samples of its output.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这在很大程度上是`ast->string`函数的改编，但使用`gen-racket`生成的随机Racket表达式作为输入，而不是TRAC语法树。我们不得不做出一些调整，以考虑到`-`和`log`的多个元数。我们还会匹配字面上的函数符号。除了这些考虑之外，代码应当与`ast->string`非常相似。以下是其输出的一些示例。
- en: '[PRE72]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The basic idea is to automate the following process:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 基本思路是自动化以下过程：
- en: '[PRE73]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'So here’s our test bench:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们的测试平台：
- en: '[PRE74]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: The result of a computation could potentially result in a complex number (for
    example, `(sqrt -1)`), so we use `magnitude` to get the absolute value size of
    the difference between the values.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 计算结果可能会导致复数（例如，`(sqrt -1)`），因此我们使用`magnitude`来获取值之间差异的绝对值大小。
- en: And here’s the output from an initial test run, which in fact indicated that
    the TRAC evaluation routine wasn’t always producing the correct results.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是初步测试运行的输出，事实上显示TRAC的评估程序并不总是产生正确的结果。
- en: '[PRE75]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: The common thread in all the mismatches was the exponentiation operator `^`
    (mapped from Racket’s `expt` function), which was inadvertently defined with the
    division operator in `eval-ast` (the `eval-ast` code given above is correct, but
    you can introduce the same error if you want to test this). Once the correction
    was made, another test run produced the following result.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 所有不匹配的共同点是指数运算符 `^`（来自 Racket 的 `expt` 函数），它不小心与除法运算符在 `eval-ast` 中一起定义了（上面给出的
    `eval-ast` 代码是正确的，但如果您想测试这个错误，可以引入相同的错误）。一旦修正后，另一次测试运行产生了以下结果。
- en: '[PRE76]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: In this case, no news is *good* news.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，无新闻即是*好消息*。
- en: '***Making an Executable***'
  id: totrans-304
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***创建可执行文件***'
- en: There’s really no need to have TRAC dependent on the DrRacket environment. Only
    a few additional steps are required to create an executable file that can be launched
    without starting DrRacket. The first step is to simply add the `(start)` command
    to the last line of the definitions file (see below) so that the program starts
    executing immediately when launched.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 其实没有必要让 TRAC 依赖于 DrRacket 环境。只需几个额外的步骤，就可以创建一个可执行文件，该文件可以在不启动 DrRacket 的情况下启动。第一步是简单地在定义文件的最后一行添加
    `(start)` 命令（见下文），使得程序在启动时立即开始执行。
- en: '[PRE77]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Racket supports three different types of executables:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: Racket 支持三种不同类型的可执行文件：
- en: '**Launcher** This type of executable will execute the current version of your
    `.rkt` source file, so it will include the path to the source file in the executable.
    This will allow your executable to immediately reflect any enhancements to your
    program. The downside is that you can’t move the source file elsewhere or easily
    share the executable with someone else.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '**启动器** 这种类型的可执行文件将执行当前版本的 `.rkt` 源文件，因此它会在可执行文件中包含源文件的路径。这将使您的可执行文件能够立即反映程序的任何改进。缺点是您无法将源文件移到其他位置或轻松与他人共享可执行文件。'
- en: '**Standalone** This version embeds the source file in the executable, so there’s
    no problem moving it to another location on your machine. A standalone executable
    still depends on the installed Racket DLLs, so it may not work properly if moved
    to a different machine.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '**独立版** 这个版本将源文件嵌入到可执行文件中，因此可以将其移动到您计算机上的其他位置。独立版可执行文件仍然依赖于安装的 Racket DLL 文件，因此如果移到另一台计算机上，可能无法正常工作。'
- en: '**Distribution archive** A distribution archive bundles all needed files into
    an install file. The install file can be used to install TRAC on another machine
    as long as the destination machine uses the same operating system as the one the
    archive was created on.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '**分发归档** 分发归档将所有需要的文件捆绑到一个安装文件中。只要目标计算机使用的操作系统与创建归档时使用的操作系统相同，安装文件就可以用来在另一台计算机上安装
    TRAC。'
- en: Before you create an executable, it’s recommended that debugging be turned off.
    This can be done by going to the **Choose Language . . .** dialog (from the Language
    option on the main menu) and pressing the **Show Details** button. This will open
    a panel where you should select **No Debugging**. Once this is done, go to the
    Racket main menu, and from there select **Create Executable . . .** . In the dialog
    box, you may select which of the three different types of executables you want
    to create. It’s even possible to select a custom icon to give TRAC that personal
    touch.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建可执行文件之前，建议关闭调试功能。可以通过进入**选择语言 . . .**对话框（从主菜单的语言选项中）并点击**显示详情**按钮来实现。这将打开一个面板，您应该选择**不启用调试**。完成后，前往
    Racket 主菜单，从那里选择**创建可执行文件 . . .**。在对话框中，您可以选择要创建的三种不同类型的可执行文件中的一种。甚至可以选择一个自定义图标，为
    TRAC 增添个人风格。
- en: '[Figure 10-7](ch10.xhtml#ch10fig7) is a screenshot of TRAC running on our machine.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 10-7](ch10.xhtml#ch10fig7)是 TRAC 在我们机器上运行的截图。'
- en: '![Image](../images/10fig07.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/10fig07.jpg)'
- en: '*Figure 10-7: TRAC in action*'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10-7：TRAC 的实际操作*'
- en: Summary
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 概要
- en: In this chapter, we leveraged our knowledge of abstract computing machines and
    various automata (introduced in the previous chapter) to build an interactive
    command line expression calculator. Along the way we learned about lexers (and
    using regular expressions to construct them), parsers (which construct abstract
    syntax trees), and interpreters. We used EBNF (extended Backus–Naur form) to specify
    our calculator grammar. Once we had our basic calculator built, we enhanced it
    with additional capabilities, such as handling complex numbers and hand degrees
    or radians. Just to be sure our calculator doesn’t give us bogus numbers, we built
    a simple test bench to make certain our code was robust.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们利用了之前章节中介绍的抽象计算机和各种自动机的知识，构建了一个交互式命令行表达式计算器。在这个过程中，我们学习了词法分析器（以及如何使用正则表达式构建它们）、语法分析器（构建抽象语法树）和解释器。我们使用了
    EBNF（扩展巴科斯范式）来指定我们的计算器语法。构建好基础计算器后，我们增强了它的功能，例如处理复数和手动选择角度或弧度。为了确保我们的计算器不会给出错误的结果，我们建立了一个简单的测试平台，确保我们的代码具有鲁棒性。
- en: Well, that just about concludes our Racket journey for now. But we’ve only scratched
    the tip of the iceberg. There’s much more capability that we haven’t even hinted
    at. We encourage you to further explore Racket on your own via the Racket website
    and other available literature. Happy learning!
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这差不多就是我们目前 Racket 之旅的总结了。但我们仅仅是触及了冰山一角。还有更多的功能我们甚至没有提及。我们鼓励你通过 Racket 网站和其他可用文献进一步探索
    Racket。祝你学习愉快！
