- en: '17'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '17'
- en: CUSTOM RESOURCES AND OPERATORS
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义资源和操作员
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common01.jpg)'
- en: We’ve seen many different resource types used in a Kubernetes cluster to run
    container workloads, scale them, configure them, route network traffic to them,
    and provide storage for them. One of the most powerful features of a Kubernetes
    cluster, however, is the ability to define custom resource types and integrate
    these into the cluster alongside all of the built-in resource types we’ve already
    seen.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，Kubernetes集群中使用了许多不同的资源类型来运行容器工作负载、扩展它们、配置它们、路由网络流量并为它们提供存储。然而，Kubernetes集群的一个最强大的功能是能够定义自定义资源类型，并将这些类型与我们已经看到的所有内置资源类型集成到集群中。
- en: Custom resource definitions enable us to define any new resource type and have
    the cluster track corresponding resources. We can use this capability to add complex
    new behavior to our cluster, such as automating the deployment of a highly available
    database engine, while taking advantage of all of the existing capabilities of
    the built-in resource types and the resource and status management of the cluster’s
    control plane.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义资源定义使我们能够定义任何新的资源类型，并让集群跟踪相应的资源。我们可以利用这一能力为集群添加复杂的新行为，例如自动化部署一个高可用的数据库引擎，同时充分利用集群内置资源类型的所有现有功能以及集群控制平面的资源和状态管理。
- en: In this chapter, we’ll see how custom resource definitions work and how we can
    use them to deploy Kubernetes operators, extending our cluster to take on any
    additional behavior we desire.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看到自定义资源定义如何工作，以及我们如何利用它们部署Kubernetes操作员，从而扩展我们的集群以实现我们所需的任何额外行为。
- en: Custom Resources
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自定义资源
- en: In [Chapter 6](ch06.xhtml#ch06), we discussed how the Kubernetes API server
    provides a declarative API, where the primary actions are to create, read, update,
    and delete resources in the cluster. A declarative API has advantages for resiliency,
    as the cluster can track the desired state of resources and work to ensure that
    the cluster stays in that desired state. However, a declarative API also has a
    significant advantage in extensibility. The actions provided by the API server
    are generic enough that extending them to any kind of resource is easy.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](ch06.xhtml#ch06)中，我们讨论了Kubernetes API服务器如何提供声明式API，其中主要操作是创建、读取、更新和删除集群中的资源。声明式API具有弹性的优势，因为集群可以跟踪资源的期望状态，并努力确保集群保持在该期望状态。然而，声明式API在扩展性方面也具有显著优势。API服务器提供的操作足够通用，以至于将其扩展到任何类型的资源都很容易。
- en: We’ve already seen how Kubernetes takes advantage of this extensibility to update
    its API over time. Not only can Kubernetes support new versions of a resource
    over time, but brand-new resources with new capabilities can be added to the cluster
    while backward compatibility is maintained through the old resources. We saw this
    in [Chapter 7](ch07.xhtml#ch07) in our discussion on the new capabilities of version
    2 of the HorizontalPodAutoscaler as well as the way that the Deployment replaced
    the ReplicationController.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到Kubernetes如何利用这种扩展性逐步更新其API。Kubernetes不仅能够随着时间的推移支持资源的新版本，还能够将具有新功能的全新资源添加到集群中，同时通过旧资源保持向后兼容性。我们在[第7章](ch07.xhtml#ch07)中讨论了版本2的HorizontalPodAutoscaler的新功能，以及Deployment如何取代ReplicationController。
- en: We really see the power of this extensibility in the use of *CustomResourceDefinitions*.
    A CustomResourceDefinition, or CRD, allows us to add any new resource type to
    a cluster dynamically. We simply provide the API server with the name of the new
    resource type and a specification that’s used for validation, and immediately
    the API server will allow us to create, read, update, and delete resources of
    that new type.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实能在使用*CustomResourceDefinitions*时看到这种扩展性的强大。CustomResourceDefinition，或简称CRD，使我们能够动态地向集群添加任何新的资源类型。我们只需向API服务器提供新资源类型的名称和用于验证的规格，API服务器就会立即允许我们创建、读取、更新和删除该新类型的资源。
- en: CRDs are extremely useful and in widespread use. For example, the infrastructure
    components that are already deployed to our cluster include CRDs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: CRD非常有用并且被广泛使用。例如，已经部署到我们集群中的基础设施组件包括CRD。
- en: '**NOTE**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*The example repository for this book is at* [https://github.com/book-of-kubernetes/examples](https://github.com/book-of-kubernetes/examples).
    *See “Running Examples” on [page xx](ch00.xhtml#ch00lev1sec2) for details on/linebreak
    getting set up.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*本书的示例仓库位于* [https://github.com/book-of-kubernetes/examples](https://github.com/book-of-kubernetes/examples)。*有关设置的详细信息，请参见[第xx页](ch00.xhtml#ch00lev1sec2)中的“运行示例”部分。*'
- en: 'Let’s see the CRDs that are already registered with our cluster:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看已经在我们的集群中注册的 CRD：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To avoid naming conflicts, the CRD name must include a group, which is commonly
    based on a domain name to ensure uniqueness. This group is also used to establish
    the path to that resource for the REST API provided by the API server. In this
    example, we see CRDs in the `crd.projectcalico.org` group and the `operator.tigera.io`
    group, both of which are used by Calico. We also see a CRD in the `longhorn.io`
    group, used by Longhorn.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免命名冲突，CRD 的名称必须包含一个组名，通常基于域名来确保唯一性。这个组名也用于为 API 服务器提供的 REST API 建立到该资源的路径。在这个例子中，我们看到
    CRD 属于 `crd.projectcalico.org` 组和 `operator.tigera.io` 组，这两个组都由 Calico 使用。我们还看到一个属于
    `longhorn.io` 组的 CRD，这个 CRD 是 Longhorn 使用的。
- en: 'These CRDs allow Calico and Longhorn to use the Kubernetes API to record configuration
    and status information in `etcd`. CRDs also simplify custom configuration. For
    example, as part of deploying Calico to the cluster, the automation created an
    Installation resource that corresponds to the `installations.operator.tigera.io`
    CRD:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 CRD 允许 Calico 和 Longhorn 使用 Kubernetes API 将配置信息和状态信息记录在 `etcd` 中。CRD 还简化了自定义配置。例如，作为将
    Calico 部署到集群的一部分，自动化创建了一个安装资源，对应于 `installations.operator.tigera.io` CRD：
- en: '*custom-resources.yaml*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*custom-resources.yaml*'
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This configuration is the reason why we see Pods getting IP addresses in the
    `172.31.0.0/16` network block. This YAML file was automatically placed in */etc/kubernetes/components*
    and automatically applied to the cluster as part of Calico installation. On deployment,
    Calico queries the API server for instances of this Installation resource and
    configures networking accordingly.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配置是我们看到 Pods 获得 `172.31.0.0/16` 网络块中的 IP 地址的原因。这个 YAML 文件被自动放置在 */etc/kubernetes/components*
    中，并作为 Calico 安装的一部分自动应用到集群。当部署时，Calico 会查询 API 服务器，查找此安装资源的实例，并相应地配置网络。
- en: Creating CRDs
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建 CRD
- en: Let’s explore CRDs further by creating our own. We’ll use the definition provided
    in [Listing 17-1](ch17.xhtml#ch17list1).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过创建自己的 CRD 来进一步探索 CRD。我们将使用[列表 17-1](ch17.xhtml#ch17list1)中提供的定义。
- en: '*crd.yaml*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*crd.yaml*'
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Listing 17-1: Sample CRD*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表 17-1：示例 CRD*'
- en: There are multiple important parts to this definition. First, several types
    of names are defined. The metadata `name` field ➊ must combine the plural name
    of the resource ➎ and the group ➋. These naming components will also be critical
    for access via the API.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义包含多个重要部分。首先，定义了几种类型的名称。元数据 `name` 字段 ➊ 必须将资源的复数名称 ➎ 和组 ➋ 组合在一起。这些命名组件对于通过
    API 进行访问也至关重要。
- en: 'Naming also includes the `kind` ➐, which is used in YAML files. This means
    that when we create specific resources based on this CRD, we will identify them
    with `kind: Sample`. Finally, we need to define how to refer to instances of this
    CRD on the command line. This includes the full name of the resource, specified
    in the `singular` ➏ field, as well as any `shortNames` ➑ that we want the command
    line to recognize.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '命名还包括 `kind` ➐，它在 YAML 文件中使用。这意味着当我们基于这个 CRD 创建特定资源时，我们将使用 `kind: Sample` 来标识它们。最后，我们需要定义如何在命令行中引用这个
    CRD 的实例。这包括资源的完整名称，这在 `singular` ➏ 字段中指定，以及任何我们希望命令行识别的 `shortNames` ➑。'
- en: Now that we’ve provided Kubernetes with all of the necessary names for instances
    based on this CRD, we can move on to how the CRD is tracked and what data it contains.
    The `scope` ➍ field tells Kubernetes whether this resource should be tracked at
    the Namespace level or whether resources are cluster wide. Namespaced resources
    receive an API path that includes the Namespace they’re in, and authorization
    to access and modify Namespaced resources can be controlled on a Namespace-by-Namespace
    basis using Roles and RoleBindings, as we saw in [Chapter 11](ch11.xhtml#ch11).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经根据这个 CRD 为实例提供了所有必要的名称，接下来我们可以讨论 CRD 是如何被跟踪以及它包含了哪些数据。`scope` ➍ 字段告诉 Kubernetes
    这个资源应该在 Namespace 级别进行跟踪，还是资源是集群范围的。命名空间资源会收到包含其所在命名空间的 API 路径，可以通过角色（Roles）和角色绑定（RoleBindings）在每个命名空间的基础上控制对命名空间资源的访问和修改权限，正如我们在[第
    11 章](ch11.xhtml#ch11)中所看到的。
- en: Third, the `versions` section allows us to define the actual content that is
    valid when we create resources based on this CRD. To enable updates over time,
    there can be multiple versions. Each version has a `schema` that declares what
    fields are valid. In this case, we define a `spec` field that contains one field
    called `value`, and we declare this one field to be an integer.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，`versions` 部分允许我们定义在基于此 CRD 创建资源时有效的实际内容。为了支持版本更新，可以有多个版本。每个版本都有一个 `schema`，声明哪些字段是有效的。在这个例子中，我们定义了一个
    `spec` 字段，其中包含一个名为 `value` 的字段，并且我们声明这个字段的类型为整数。
- en: There was a lot of required configuration here, so let’s review the result.
    This CRD enables us to tell the Kubernetes cluster to track a brand new kind of
    resource for us, a *Sample*. Each instance of this resource (each Sample) will
    belong to a Namespace and will contain an integer in a `value` field.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多必需的配置，让我们回顾一下结果。这个 CRD 使我们能够告诉 Kubernetes 集群跟踪一种全新的资源类型——*Sample*。这个资源的每个实例（每个
    Sample）都将属于一个命名空间，并且在 `value` 字段中包含一个整数。
- en: 'Let’s create this CRD in our cluster:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在集群中创建这个 CRD：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can now create objects of this type and retrieve them from our cluster.
    Here’s an example YAML definition to create a new Sample using the CRD we defined:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建此类型的对象，并从集群中获取它们。以下是使用我们定义的 CRD 创建新示例的 YAML 定义示例：
- en: '*sample.yaml*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*sample.yaml*'
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We match the `apiVersion` and `kind` to our CRD and ensure that the `spec` is
    in alignment with the schema. This means that we’re required to supply a field
    called `value` with an integer value.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 `apiVersion` 和 `kind` 与我们的 CRD 匹配，并确保 `spec` 与 schema 对应。这意味着我们必须提供一个名为
    `value` 的字段，并且该字段的值必须是整数。
- en: 'We can now create this resource in the cluster just like any other resource:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以像创建其他资源一样，在集群中创建这个资源：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: There is now a Sample called `somedata` that is part of the `default` Namespace.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有一个名为 `somedata` 的示例，它是 `default` 命名空间的一部分。
- en: 'When we defined the CRD in [Listing 17-1](ch17.xhtml#ch17list1), we specified
    a plural, singular, and short name for Sample resources. We can use any of these
    names to retrieve the new resource:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在 [Listing 17-1](ch17.xhtml#ch17list1) 中定义 CRD 时，我们为 Sample 资源指定了复数、单数和简短名称。我们可以使用这些名称中的任何一个来检索新资源：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Just by declaring our CRD, we’ve extended the behavior of our Kubernetes cluster
    so that it understands what `samples` are, and we can use that not only in the
    API but also in the command line tools.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仅声明我们的 CRD，我们就扩展了 Kubernetes 集群的行为，使其能够理解什么是 `samples`，并且我们可以在 API 中以及命令行工具中使用它。
- en: 'This means that `kubectl describe` also works for Samples. We can see that
    Kubernetes tracks other data related to our new resource, beyond just the data
    we specified:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 `kubectl describe` 也适用于 Samples。我们可以看到 Kubernetes 跟踪了与我们的新资源相关的其他数据，不仅仅是我们指定的数据：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This additional data, including timestamps and resource versioning, is essential
    if we want to use the data from our CRD. To use our new resource effectively,
    we’re going to need a software component that continually monitors for new or
    updated instances of our resource and takes action accordingly. We’ll run this
    component using a regular Kubernetes Deployment that interacts with the Kubernetes
    API server.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些附加数据，包括时间戳和资源版本控制，对于我们想要使用 CRD 中的数据是必不可少的。为了有效地使用我们的新资源，我们需要一个持续监控资源新实例或更新实例的软件组件，并根据情况采取相应的行动。我们将使用一个常规的
    Kubernetes Deployment 来运行此组件，并与 Kubernetes API 服务器进行交互。
- en: Watching CRDs
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 观察 CRD
- en: With core Kubernetes resources, the control plane components communicate with
    the API server to take the correct action when a resource is created, updated,
    or deleted. For example, the controller manager includes a component that watches
    for changes to Services and Pods, enabling it to update the list of endpoints
    for each Service. The `kube-proxy` instance on each node then makes the necessary
    network routing changes to send traffic to Pods based on those endpoints.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于核心 Kubernetes 资源，控制平面组件通过与 API 服务器通信来采取正确的操作，当资源被创建、更新或删除时。例如，控制器管理器包括一个组件，监视服务和
    Pod 的变化，使其能够更新每个服务的端点列表。然后，每个节点上的 `kube-proxy` 实例根据这些端点进行必要的网络路由更改，将流量发送到 Pods。
- en: With CRDs, the API server merely tracks the resources as they are created, updated,
    and deleted. It is the responsibility of some other software to monitor instances
    of the resource and take the correct action. To make it easy to monitor resources,
    the API server offers a `watch` action, using *long polling* to keep a connection
    open and continually feed events as they occur. Because a long-polling connection
    could be cut off at any time, the timestamp and resource version data that Kubernetes
    tracks for us will enable us to detect what cluster changes we’ve already processed
    when we reconnect.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 CRD，API 服务器仅跟踪资源的创建、更新和删除。其他软件负责监视资源实例并采取正确的行动。为了方便监视资源，API 服务器提供了 `watch`
    操作，通过 *长轮询* 保持连接打开，并在事件发生时持续推送事件。由于长轮询连接可能会随时中断，Kubernetes 跟踪的时间戳和资源版本数据将使我们能够在重新连接时检测到我们已经处理的集群变化。
- en: 'We could use the API server’s `watch` capability directly from a `curl` command
    or directly in an HTTP client, but it’s much easier to use a Kubernetes client
    library. For this example, we’ll use the Python client library to illustrate how
    to watch our custom resource. Here’s the Python script we’ll use:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接从 `curl` 命令或 HTTP 客户端中使用 API 服务器的 `watch` 功能，但使用 Kubernetes 客户端库要容易得多。对于这个示例，我们将使用
    Python 客户端库来演示如何监视我们的自定义资源。以下是我们将使用的 Python 脚本：
- en: '*watch.py*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*watch.py*'
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To connect to the API server, we need to load cluster configuration. This includes
    the location of the API server as well as the authentication information we saw
    in [Chapter 11](ch11.xhtml#ch11). If we’re running in a container within a Kubernetes
    Pod, we’ll automatically have that information available to us, so we first try
    to load an in-cluster config ➊. However, if we’re outside a Kubernetes cluster,
    the convention is to use a Kubernetes config file, so we try that as a secondary
    option ➋.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要连接到 API 服务器，我们需要加载集群配置。这包括 API 服务器的位置以及我们在[第 11 章](ch11.xhtml#ch11)中看到的认证信息。如果我们在
    Kubernetes Pod 中运行容器，我们将自动获得这些信息，因此我们首先尝试加载集群内配置 ➊。然而，如果我们在 Kubernetes 集群外部，通常会使用
    Kubernetes 配置文件作为备选方案 ➋。
- en: After we’ve established how to talk to the API server, we use the custom objects
    API and a watch object to stream events related to our custom resource ➍. The
    `stream()` method takes the name of a function and the associated parameters,
    which we’ve loaded from the environment or from default values ➌. We use the `list_namespaced_custom_object`
    function because we’re interested in our custom resource. All of the various `list_*`
    methods in the Python library are designed to work with `watch` to return a stream
    of add, update, and remove events rather than simply retrieving the current list
    of objects. As events occur, we then print them to the console in an easy-to-read
    format ➎.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们建立与 API 服务器的连接方式之后，我们使用自定义对象 API 和一个 watch 对象来流式传输与我们的自定义资源相关的事件 ➍。`stream()`
    方法接受一个函数名和相关参数，这些参数我们已经从环境变量或默认值中加载 ➌。我们使用 `list_namespaced_custom_object` 函数，因为我们关心的是我们的自定义资源。Python
    库中的所有 `list_*` 方法都设计用于与 `watch` 一起工作，以返回添加、更新和删除事件的流，而不仅仅是检索当前对象列表。当事件发生时，我们会将它们打印到控制台中，格式易于阅读
    ➎。
- en: 'We’ll use this Python script within a Kubernetes Deployment. I’ve built and
    published a container image to run it, so this is an easy task. Here’s the Deployment
    definition:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 Kubernetes 部署中使用这个 Python 脚本。我已经构建并发布了一个容器镜像来运行它，所以这项任务非常简单。以下是部署定义：
- en: '*watch.yaml*'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*watch.yaml*'
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This Deployment will run the Python script that watches for events on instances
    of the Sample CRD. However, before we can create this Deployment, we need to ensure
    that our watcher script will have permissions to read our custom resource. The
    default ServiceAccount has minimal permissions, so we need to create a ServiceAccount
    for this Deployment and ensure that it has the rights to see our Sample custom
    resources.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此部署将运行一个 Python 脚本，监视 Sample CRD 实例上的事件。然而，在我们创建这个部署之前，我们需要确保我们的监视脚本有权限读取我们的自定义资源。默认的
    ServiceAccount 权限最小，因此我们需要为此部署创建一个 ServiceAccount，并确保它有权限查看我们的 Sample 自定义资源。
- en: We could bind a custom Role to our ServiceAccount to do this, but it’s more
    convenient to take advantage of role aggregation to add our Sample custom resource
    to the `view` ClusterRole that already exists. This way, any user in the cluster
    with the `view` ClusterRole will acquire rights to our Sample custom resource.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们本可以将一个自定义 Role 绑定到我们的 ServiceAccount 来实现这一点，但利用角色聚合将我们的 Sample 自定义资源添加到已经存在的
    `view` ClusterRole 中会更加方便。这样，集群中任何拥有 `view` ClusterRole 的用户都将获得对我们 Sample 自定义资源的访问权限。
- en: 'We start by defining a new ClusterRole for our custom resource:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先为我们的自定义资源定义一个新的 ClusterRole：
- en: '*sample-reader.yaml*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*sample-reader.yaml*'
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This ClusterRole gives permission to `get`, `watch`, and `list` our Sample custom
    resources ➋. We also add a label to the metadata ➊ to signal the cluster that
    we want these permissions to be aggregated into the `view` ClusterRole. Thus,
    rather than bind our ServiceAccount into the `sample-reader` ClusterRole we’re
    defining here, we can bind our ServiceAccount into the generic `view` ClusterRole,
    giving it read-only access to all kinds of resources.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 ClusterRole 赋予了 `get`、`watch` 和 `list` 我们的 Sample 自定义资源 ➋ 的权限。我们还在元数据 ➊ 中添加了一个标签，向集群指示我们希望这些权限被聚合到
    `view` ClusterRole 中。因此，我们不需要将 ServiceAccount 绑定到我们在这里定义的 `sample-reader` ClusterRole，而是可以将
    ServiceAccount 绑定到通用的 `view` ClusterRole，从而为它提供对所有资源的只读访问权限。
- en: 'We also need to declare the ServiceAccount and bind it to the `view` ClusterRole:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要声明 ServiceAccount，并将其绑定到 `view` ClusterRole：
- en: '*sa.yaml*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*sa.yaml*'
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We use a RoleBinding to limit this ServiceAccount to read-only access solely
    within the `default` Namespace. The RoleBinding binds the `watcher` ServiceAccount
    to the generic `view` ClusterRole. This ClusterRole will have access to our Sample
    custom resources thanks to the role aggregation we specified.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 RoleBinding 来限制该 ServiceAccount 仅对 `default` 命名空间内的资源具有只读访问权限。RoleBinding
    将 `watcher` ServiceAccount 绑定到通用的 `view` ClusterRole。由于我们指定的角色聚合，这个 ClusterRole
    将可以访问我们的 Sample 自定义资源。
- en: 'We’re now ready to apply all of these resources, including our Deployment:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备应用所有这些资源，包括我们的 Deployment：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After a little while, our watcher Pod will be running:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 不久之后，我们的监视器 Pod 将开始运行：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can print the watcher’s logs to see the events it has received from the
    API server:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以打印监视器的日志，以查看它从 API 服务器接收到的事件：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note that the watcher Pod receives an `ADDED` event for the `somedata` Sample
    we created, even though we created that Sample before we deployed our watcher.
    The API server is able to determine that our watcher has not yet retrieved this
    object, so it sends us an event immediately on connection as if the object were
    newly created, which avoids a race condition that we would otherwise be forced
    to handle. However, note that if the client is restarted, it will appear as a
    new client to the API server and will see the same `ADDED` event again for the
    same Sample. For this reason, when we implement the logic to handle our custom
    resources, it’s essential to make the logic idempotent so that we can handle processing
    the same event multiple times.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管我们在部署监视器之前就创建了 `somedata` Sample，但监视器 Pod 收到了这个 Sample 的 `ADDED` 事件。API
    服务器能够确定我们的监视器还没有检索到这个对象，因此在连接时它会立即向我们发送一个事件，就像该对象是新创建的一样，这避免了我们本来需要处理的竞争条件。然而，注意如果客户端被重新启动，它将作为一个新客户端出现在
    API 服务器上，并再次看到相同 Sample 的 `ADDED` 事件。因此，在我们实现处理自定义资源的逻辑时，必须确保逻辑是幂等的，以便我们能够多次处理相同的事件。
- en: Operators
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 操作员
- en: What kinds of actions would we take in response to the creation, update, or
    deletion of custom resources, other than just logging the events to the console?
    As we saw when we examined the way that custom resources are used to configure
    Calico networking in our cluster, one use for custom resources is to configure
    for cluster infrastructure components such as networking and storage. But another
    pattern that really makes the best use of custom resources is the Kubernetes *Operator*.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 除了将事件记录到控制台之外，我们还会采取什么样的行动来响应自定义资源的创建、更新或删除呢？正如我们在检查自定义资源如何用于配置集群中 Calico 网络时所看到的，自定义资源的一个用途是配置集群基础设施组件，例如网络和存储。但另一个真正充分利用自定义资源的模式是
    Kubernetes 的 *Operator*。
- en: The Kubernetes Operator pattern extends the behavior of the cluster to make
    it easier to deploy and manage specific application components. Rather than using
    the standard set of Kubernetes resources such as Deployments and Services directly,
    we simply create custom resources that are specific to the application component,
    and the operator manages the underlying Kubernetes resources for us.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes Operator 模式扩展了集群的行为，使得更容易部署和管理特定的应用程序组件。与直接使用 Kubernetes 资源集（如部署和服务）的标准集不同，我们只需创建特定于应用程序组件的自定义资源，操作器将为我们管理底层的
    Kubernetes 资源。
- en: Let’s look at an example to illustrate the power of the Kubernetes Operator
    pattern. We’ll add a Postgres Operator to our cluster that will enable us to deploy
    a highly available PostgreSQL database to our cluster by just adding a single
    custom resource.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个示例，以说明 Kubernetes Operator 模式的强大。我们将在集群中添加一个 Postgres Operator，这将使我们能够通过添加单个自定义资源来部署高可用的
    PostgreSQL 数据库到我们的集群。
- en: Our automation has staged the files that we need into */etc/kubernetes/components*
    and has performed some initial setup, so the only step remaining is to add the
    operator. The operator is a normal Deployment that will run in whatever Namespace
    we choose. It then will watch for custom `postgresql` resources and will create
    PostgreSQL instances accordingly.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的自动化已将所需文件暂存到 */etc/kubernetes/components* 并执行了一些初始设置，所以剩下的唯一步骤就是添加操作器。该操作器是一个普通的部署，将在我们选择的任何命名空间中运行。然后，它将监视自定义
    `postgresql` 资源，并相应地创建 PostgreSQL 实例。
- en: 'Let’s deploy the operator:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们部署该操作器：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This creates a Deployment for the operator itself, which creates a single Pod:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了操作器本身的部署，它创建一个单独的 Pod：
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The Pod communicates with the API server to create the CRD needed to define
    a PostgreSQL database:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 与 API 服务器通信以创建定义 PostgreSQL 数据库所需的 CRD：
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'No instances of PostgreSQL are running in the cluster yet, but we can easily
    deploy PostgreSQL by creating a custom resource based on that CRD:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 尚未在集群中运行任何 PostgreSQL 实例，但我们可以通过基于该 CRD 创建自定义资源来轻松部署 PostgreSQL：
- en: '*pgsql.yaml*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*pgsql.yaml*'
- en: '[PRE18]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This custom resource tells the Postgres Operator to spawn a PostgreSQL database
    using server version 14, with three instances (a primary and two backups). Each
    instance will have persistent storage. The primary instance will be configured
    with the specified user and database.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此自定义资源告诉 Postgres Operator 使用服务器版本 14 生成一个 PostgreSQL 数据库，具有三个实例（一个主实例和两个备份）。每个实例都将具有持久存储。主实例将配置为指定的用户和数据库。
- en: The real value of the Kubernetes Operator pattern is that the YAML resource
    file we declare is short, simple, and clearly relates to the PostgreSQL configuration
    we want to see. The operator’s job is to convert this information into a StatefulSet,
    Services, and other cluster resources as needed to operate this database.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes Operator 模式的真正价值在于我们声明的 YAML 资源文件简短、简单且明确地与我们想要看到的 PostgreSQL 配置相关联。操作器的工作是将此信息转换为
    StatefulSet、Services 和其他集群资源，以便操作此数据库。
- en: 'We apply this custom resource to the cluster like any other resource:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们像处理任何其他资源一样将此自定义资源应用于集群：
- en: '[PRE19]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After we apply it, the Postgres Operator will receive the add event and will
    create the necessary cluster resources for PostgreSQL:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用后，Postgres Operator 将接收添加事件，并为 PostgreSQL 创建必要的集群资源：
- en: '[PRE20]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Ultimately, there will be a StatefulSet and three Pods running (in addition
    to the Pod for the operator itself, which is still running):'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，将有一个 StatefulSet 和三个运行的 Pod（除了操作器本身仍在运行的 Pod）：
- en: '[PRE21]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: It can take several minutes for all of these resources to be fully running on
    the cluster.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些资源完全在集群上运行可能需要几分钟时间。
- en: 'Unlike the PostgreSQL StatefulSet we created in [Chapter 15](ch15.xhtml#ch15),
    all instances in this StatefulSet are configured for high availability, as we
    can demonstrate by inspecting the logs for each Pod:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在 [第 15 章](ch15.xhtml#ch15) 中创建的 PostgreSQL StatefulSet 不同，此 StatefulSet
    中的所有实例均配置为高可用性，这可以通过检查每个 Pod 的日志来演示：
- en: '[PRE22]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As we can see, the first instance, `pgsql-cluster-0`, has identified itself
    as the leader, whereas `pgsql-cluster-1` has configured itself as a follower that
    will replicate any updates to the leader’s databases.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，第一个实例 `pgsql-cluster-0` 已将自己标识为领导者，而 `pgsql-cluster-1` 则配置为跟随者，将复制到领导者数据库的任何更新。
- en: 'To manage the PostgreSQL leaders and followers and enable database clients
    to reach the leader, the operator has created multiple Services:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了管理 PostgreSQL 的领导者和跟随者，并使数据库客户端能够访问领导者，操作器已创建了多个服务：
- en: '[PRE23]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The `pgsql-cluster` Service routes traffic to the primary only; the other Services
    are used to manage replication to the backup instances. The operator handles the
    task of updating the Service if the primary instance changes due to failover.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`pgsql-cluster` 服务只将流量路由到主节点；其他服务用于管理复制到备份实例。操作员会处理在主实例由于故障切换而发生变化时更新服务的任务。'
- en: 'To remove the PostgreSQL database, we need to remove only the custom resource,
    and the Postgres Operator handles the rest:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要移除 PostgreSQL 数据库，我们只需要删除自定义资源，其余操作由 Postgres Operator 处理：
- en: '[PRE24]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The operator detects the removal and cleans up the associated Kubernetes cluster
    resources:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 操作员会检测到删除操作并清理相关的 Kubernetes 集群资源：
- en: '[PRE25]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The Postgres Operator has now removed the StatefulSet, persistent storage, and
    other resources associated with this database cluster.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Postgres Operator 现在已移除与该数据库集群相关的 StatefulSet、持久存储和其他资源。
- en: The ease with which we were able to deploy and remove a PostgreSQL database
    server, including multiple instances automatically configured in a highly available
    configuration, demonstrates the power of the Kubernetes Operator pattern. By defining
    a CRD, a regular Deployment can act to extend the behavior of our Kubernetes cluster.
    The result is a seamless addition of new cluster capability that is fully integrated
    with the built-in features of the Kubernetes cluster.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够轻松地部署和移除 PostgreSQL 数据库服务器，包括自动配置为高可用性配置的多个实例，这展示了 Kubernetes Operator 模式的强大。通过定义
    CRD，常规的部署可以扩展我们的 Kubernetes 集群的行为。结果是无缝地增加了集群的新功能，并且与 Kubernetes 集群的内置功能完全集成。
- en: Final Thoughts
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后的思考
- en: CustomResourceDefinitions and Kubernetes Operators bring advanced features to
    a cluster, but they do so by building on the basic Kubernetes cluster functionality
    we’ve seen throughout this book. The Kubernetes API server has the extensibility
    to handle storage and retrieval of any type of cluster resource. As a result,
    we’re able to define new resource types dynamically and have the cluster manage
    them for us.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: CustomResourceDefinitions 和 Kubernetes Operators 为集群带来高级功能，但它们是通过构建在我们在本书中看到的基本
    Kubernetes 集群功能之上的。Kubernetes API 服务器具有处理任何类型集群资源存储和检索的可扩展性。因此，我们能够动态定义新的资源类型，并让集群为我们管理这些资源。
- en: We’ve seen this pattern across many of the features we’ve examined in [Part
    II](part02.xhtml#part02) of this book. Kubernetes itself is built on the fundamental
    features of containers that we saw in [Part I](part01.xhtml#part01), and it is
    built so that its more advanced features are implemented by bringing together
    its more basic features. By understanding how those basic features work, we’re
    better able to understand the more advanced features, even if the behavior looks
    a bit magical at first.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本书的[第二部分](part02.xhtml#part02)中已经看到过这种模式。Kubernetes 本身是建立在我们在[第一部分](part01.xhtml#part01)中看到的容器基本功能之上的，且它是通过将更基本的功能整合在一起来实现其更高级的功能的。通过理解这些基本功能的工作原理，我们能够更好地理解这些高级功能，即使它们的行为乍一看有点神奇。
- en: We’ve now worked our way through the key capabilities of Kubernetes that we
    need to understand to build high-quality, performant applications. Next, we’ll
    turn our attention to ways to improve the performance and resiliency of our applications
    when running them in a Kubernetes cluster.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经了解了构建高质量、高性能应用程序所需掌握的 Kubernetes 关键能力。接下来，我们将关注在 Kubernetes 集群中运行应用时，如何提高应用的性能和弹性。
