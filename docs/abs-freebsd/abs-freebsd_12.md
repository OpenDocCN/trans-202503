## **12

Z 文件系统**

![image](img/common01.jpg)

大多数文件系统在计算机术语中都是古老的。我们因为硬件速度慢而丢弃 5 年前的设备，但我们却用一个 40 年历史的文件系统来格式化新硬盘。虽然我们已改进了这些文件系统并使其更加稳健，但它们仍然使用相同的基本架构。每当文件系统出问题时，我们都会咒骂并急于修复，同时迫切希望有更好的选择。

ZFS 是更好的选择。

并不是说 ZFS 使用了革命性的技术。ZFS 的所有个别组件都已经被很好地理解。哈希、数据树和索引都没有什么神秘之处。但 ZFS 将所有这些经过验证的原理结合成一个统一、良好工程化的整体。它的设计考虑了未来。今天的哈希算法可能无法满足 15 年后的需求，但 ZFS 的设计使得可以在不失去向后兼容性的前提下，为新版本添加新的算法和技术。

本章不会涵盖关于 ZFS 的所有知识。ZFS 几乎是一个独立的操作系统，或者说是一个专用数据库。已经有整本书专门讲解如何使用和管理 ZFS。不过，你会学到足够的 ZFS 工作原理，以便在服务器上使用它，并理解它最重要的特性。

虽然 ZFS 预计是直接安装在磁盘分区上的，但你也可以使用其他 GEOM 提供者作为 ZFS 存储。最常见的例子是，当你进行加密磁盘的安装时，FreeBSD 会在磁盘上放置一个 geli(8) geom 并在该 geom 上安装 ZFS。本章中，将任何存储提供者都称作“磁盘”，即使它可能是一个文件、加密提供者或其他任何东西。

如果你以前从未使用过 ZFS，可以在虚拟机上安装一个基于 ZFS 的 FreeBSD 系统并跟着操作。安装程序会自动处理一些前提条件，比如在 *loader.conf* 中设置 `zfs_load=YES`，并在 *rc.local* 中设置 `zfs_enable=YES`；你只需要关注文件系统即可。

**ZFS 代表什么？**

*Z 文件系统*。没错，真的是这样。曾几何时，它代表着*泽塔字节文件系统*，但这个缩写已经被重新定义了。

ZFS 将一大堆已被理解的技术融合成一个组合式卷管理器和文件系统。它期望处理从文件权限到跟踪哪些存储提供者上的哪些块存储哪些信息的一切。作为系统管理员，你只需告诉 ZFS 你拥有的硬件以及如何配置它，然后 ZFS 会继续处理其余的部分。

ZFS 有三个主要组件：数据集、池和虚拟设备。

### **数据集**

*数据集*被定义为一块有名称的 ZFS 数据。最常见的数据集类似于分区文件系统，但 ZFS 也支持其他类型的数据集，用于其他用途。快照（参见“快照”章节，见第 271 页）就是一种数据集。ZFS 还包括用于虚拟化和 iSCSI 目标、克隆等的块设备；所有这些都是数据集。本书主要集中在文件系统数据集上。传统文件系统，如 UFS，拥有多种小程序来管理文件系统，但你可以使用 zfs(8)管理所有 ZFS 数据集。

使用`zfs list`查看现有的数据集。输出看起来很像 mount(8)的结果。

```
   # zfs list
   NAME                     USED  AVAIL  REFER  MOUNTPOINT
➊ zroot                   4.71G   894G    88K  none
➋ zroot/ROOT              2.40G   894G    88K  none
➌ zroot/ROOT/2018-11-17      8K   894G  1.51G  /
➍ zroot/ROOT/default      2.40G   894G  1.57G  /
➎ zroot/usr               1.95G   894G    88K  /usr
➏ zroot/usr/home           520K   894G   520K  /usr/home
   --snip--
```

每一行以数据集名称开始，后面跟着该数据集所在的存储池或*zpool*。第一个条目是*zroot* ➊。这个条目代表池的*根数据集*。数据集树的其余部分悬挂在此数据集下。

接下来的两列显示了已使用空间和可用空间的数量。*zroot*池已使用 4.71GB，并且有 894GB 的可用空间。虽然可用空间的数值显然是正确的，但 4.71GB 的情况比看起来更复杂。一个数据集在“USED”列下显示的空间包含了该数据集*以及*所有子数据集的空间。一个根数据集的子数据集包括该 zpool 中的所有其他数据集。

`REFER`列是 ZFS 特有的。该列显示此特定数据集上可以访问的数据量，这不一定等同于已使用的空间量。一些 ZFS 功能，如快照，会在它们之间共享数据。这个数据集已经使用了 4.71GB 的数据，但只引用了 88KB。没有它的子数据集，这个数据集只有 88KB 的数据。

最后，我们看到了数据集的挂载点。这个根数据集没有挂载点；它没有被挂载。

看下一个数据集，*zroot/ROOT* ➋。这是为根目录及其相关文件创建的数据集。听起来很合理，但如果查看`REFER`列，你会发现它只包含 88KB 的数据，并且没有挂载点。根目录难道不应该存在吗？

接下来的两行解释了为什么...有点。数据集*zroot/ROOT/2018-11-17* ➌的挂载点是*/*，所以它是一个真实的根目录。下一个数据集，*zroot/ROOT/default* ➍，也有一个挂载点*/*。不，ZFS 不允许你将多个数据集挂载到同一个挂载点。一个 ZFS 数据集记录了其设置的许多内容，而挂载点只是其中之一。

稍微考虑一下这四个数据集。*zroot/ROOT*数据集是*zroot*数据集的子集。*zroot/ROOT/2018-11-17*和*zroot/ROOT/default*数据集是*zroot/ROOT*的子集。每个数据集的空间使用都算在它的子数据集上。

为什么要这么做？当你启动一个 FreeBSD ZFS 主机时，你可以轻松选择多个根目录。每个可启动的根目录称为 *启动环境*。假设你应用了一个补丁并重启系统，但新系统无法启动。通过启动到一个备用的启动环境，你可以轻松访问故障的根目录并尝试找出问题所在。

下一个数据集，*zroot/usr* ➎，是 *zroot* 的一个完全不同的子集。它有自己的子集，*zroot/usr/home* ➏。*zroot/usr/home* 中使用的空间会计入 *zroot/usr*，而两者都会计入它的父集，但它们的分配不会影响 *zroot/ROOT*。

#### ***数据集属性***

除了一些会计技巧外，数据集目前看起来与分区非常相似。但分区是磁盘的逻辑划分，填充存储设备上的非常特定的 LBA（逻辑块地址）。分区对分区上的数据没有感知。改变分区意味着摧毁其上的文件系统。

ZFS 紧密集成了文件系统和底层存储层。它可以根据需要动态地在各个文件系统之间划分存储空间。当分区通过控制可用块数来约束磁盘使用时，数据集可以使用配额来实现相同的效果。不过，如果没有这些配额，只要池中有空间，就可以使用它。

数据集可以使用的空间是一个 ZFS *属性*。ZFS 支持数十种属性，从控制数据集增长大小的 `quotas` 属性，到显示数据集是否挂载的 `mounted` 属性。

##### **查看和更改数据集属性**

使用 `zfs set` 来更改属性。

```
# zfs set quota=2G zroot/usr/home
```

使用 `zfs get` 查看属性。你可以指定某个特定的属性，或者使用 `all` 查看所有属性。你可以通过逗号分隔列出多个属性。如果指定了数据集名称，则只影响该数据集。

```
# zfs get mounted zroot/ROOT
NAME       PROPERTY  VALUE    SOURCE
zroot/ROOT  mounted     no    -
```

在这里，我们有数据集的名称、属性、属性值以及一个叫做 source 的东西。（我们将在 “属性继承” 中讨论那个东西，位于 第 261 页。）

我的真正问题是，哪个数据集被挂载为根目录？我可以检查两个挂载点为 */* 的数据集，但当我有几十个启动环境时，这会让我抓狂。通过添加 `-r` 标志，可以检查数据集及其所有子数据集的属性。

```
# zfs get -r mounted zroot/ROOT
NAME                                   PROPERTY  VALUE    SOURCE
zroot/ROOT                              mounted     no    -
zroot/ROOT/2018-11-17                   mounted     no    -
zroot/ROOT/default                      mounted   ➊yes    -
```

在这三个数据集中，只有 *zroot/ROOT/default* ➊ 被挂载。那是我们的活动启动环境。

##### **属性继承**

许多属性是可继承的。你可以在父数据集上设置它们，它们会传递到子数据集。在像挂载点这样的属性上，继承是没有意义的，但对于某些更高级的功能来说，继承是合适的。虽然我们将在 “压缩” 中讨论 `compression` 属性的作用，位于 第 273 页，但我们将在此处以它作为继承的示例。

```
# zfs get compression
NAME                     PROPERTY     VALUE     SOURCE
zroot                    compression  lz4       local
zroot/ROOT               compression  lz4       inherited from zroot
zroot/ROOT/2018-11-17    compression  lz4       inherited from zroot
zroot/ROOT/default       compression  lz4       inherited from zroot
zroot/tmp                compression  lz4       inherited from zroot
--snip--
```

根数据集 zroot 的 `compression` 属性设置为 lz4。源是本地的，这意味着该属性是设置在此数据集上的。现在看一下 *zroot/ROOT*。`compression` 属性也是 lz4，但源是从 zroot 继承的。这个数据集继承了父数据集的这个属性设置。

#### ***管理数据集***

ZFS 使用数据集的方式与传统文件系统使用分区的方式相似。使用 zfs(8) 管理数据集。你将需要创建、删除和重命名数据集。

##### **创建数据集**

使用 `zfs create` 创建数据集。通过指定池和数据集名称来创建一个文件系统数据集。在这里，我为我的包创建了一个新数据集。（请注意，这会破坏启动环境，正如我们将在本章稍后看到的那样。）

```
# zfs create zroot/usr/local
```

每个数据集必须有一个父数据集。默认的 FreeBSD 安装包含一个 *zroot/usr* 数据集，因此我可以创建一个 *zroot/usr/local*。我想为 */var/db/pkg* 创建一个数据集，但虽然 FreeBSD 包含一个 *zroot/var* 数据集，却没有 *zroot/var/db*。我需要创建 *zroot/var/db*，然后创建 *zroot/var/db/pkg*。

请注意，数据集是可以叠加的，就像 UFS 一样。如果我在 */usr/local* 目录中有文件，并且我在该目录上创建了一个数据集，ZFS 将会将该数据集挂载到目录上。我将无法访问这些文件。你必须移动文件以复制现有的目录。

##### **销毁和重命名数据集**

我创建的那个新的 *zroot/usr/local* 数据集？它隐藏了我 */usr/local* 目录中的内容。使用 `zfs destroy` 删除它，然后再试一次。

```
# zfs destroy zroot/usr/local
```

*/usr/local* 的内容重新出现了。或者，我可以选择重命名这个数据集，使用 `zfs rename`。

```
# zfs rename zroot/usr/local zroot/usr/new-local
```

我喜欢启动环境，因此我打算保持 */usr/local* 不变。不过，有时候你真的需要一个 */usr/local* 数据集……

##### **未挂载的父数据集**

作为一个 Postgres 用户，我希望为我的 Postgres 数据创建一个单独的数据集。FreeBSD 的 Postgres 9.6 包使用 */var/db/pgsql/data96*。没有 *zroot/var* 数据集，我无法创建这个数据集，而没有 *zroot/var* 又会破坏包的启动环境支持。该怎么办呢？

解决方案是为 */var/db* 创建一个数据集，但不使用它，通过设置 `canmount` 数据集属性。这个属性控制是否可以挂载数据集。FreeBSD 正是因为这个原因使用了一个未挂载的数据集作为 */var*。新数据集默认将 `canmount` 设置为 `on`，因此通常无需担心它。使用 `-o` 标志在创建数据集时设置属性。

```
# zfs create -o canmount=off zroot/var/db
```

*/var/db* 数据集存在，但无法挂载。检查你 */var/db* 目录的内容，确认一切仍然存在。现在你可以为 */var/db/postgres* 甚至 */var/db/pgsql/data96* 创建数据集。

```
# zfs create zroot/var/db/postgres
# zfs create zroot/var/db/postgres/data96
# chown -R postgres:postgres /var/db/postgres
```

你有一个用于数据库的数据集，且仍然有 */var/db* 目录中的文件，作为根数据集的一部分。现在初始化你新的 Postgres 数据库并开始使用吧！

在你探索 ZFS 的过程中，你会发现许多情况可能需要在数据集创建时设置属性，或者使用未挂载的父数据集。

##### **将文件移动到新数据集**

如果你需要为现有目录创建新的数据集，你需要将文件复制过去。我建议你创建一个稍有不同名称的数据集，将文件复制到该数据集，然后重命名目录，最后重命名数据集。在这里，我需要为*/usr/local*创建一个数据集，因此我使用了不同的名称创建它。

```
# zfs create zroot/usr/local/pgsql-new
```

使用 tar(1)命令复制文件，方式与为新的 UFS 分区复制文件时完全相同（参见第十一章）。

```
# tar cfC - /usr/local/pgsql . | tar xpfC - /usr/local/pgsql-new
```

完成后，将旧目录移开并重命名数据集。

```
# mv /usr/local/pgsql /usr/local/pgsql-old
# zfs rename zroot/usr/local/pgsql-new zroot/usr/local/pgsql
```

我的 Postgres 数据现在存放在自己的数据集中。

### **ZFS 池**

ZFS 按池而不是按磁盘组织其底层存储。ZFS 存储池，或称*zpool*，是对底层存储设备的抽象，使你能够将物理介质与其上方的用户可见文件系统分离。

使用 zpool(8)查看和管理主机的 ZFS 池。在这里，我使用`zpool list`查看我一台主机的池。

```
# zpool list
NAME      SIZE  ALLOC   FREE  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT
zroot     928G  4.72G   923G         -     0%     0%  1.00x  ONLINE  -
jail      928G  2.70G   925G         -     0%     0%  1.00x  ONLINE  -
scratch   928G  5.94G   922G         -     0%     0%  1.00x  ONLINE  -
```

这个主机有三个池：*zroot*、*jail*和*scratch*。每个池都有自己的一行。

`SIZE`列显示了池的总容量。所有这些池的容量为 928GB。`ALLOC`列显示每个池已使用的空间，而`FREE`列则显示剩余空间。这些磁盘几乎是空的，这很合理，因为我大约三小时前才安装了这个主机。

`EXPANDSZ`列显示底层存储提供商是否有空闲空间。当一个池具有虚拟设备冗余（我们将在下一节讨论）时，你可以替换池中的单个存储设备，并使池变大。就像把 RAID 阵列中的 5TB 硬盘换成 10TB 硬盘，以扩展其容量。

`FRAG`列显示了此池的碎片化程度。你可能听说过，碎片化会降低性能。不过，ZFS 最小化了碎片化的影响。

`CAP`列显示可用空间的使用百分比。

`DEDUP`列显示此池是否使用去重。尽管许多人将去重作为 ZFS 的一大特色，但它的实际效用可能并不像你期望的那么大。

`HEALTH`列显示池是否运行正常，或者底层磁盘是否有问题。

#### ***池的详细信息***

你可以通过运行`zpool status`获取更多关于池的信息，或者查看单个池的信息。如果省略池名称，你将看到所有池的信息。在这里，我检查了我的*jail*池的状态。

```
# zpool status jail
  pool: jail
 state: ONLINE
  scan: none requested
config:

        NAME               STATE     READ WRITE CKSUM
        jail               ONLINE       0     0     0
          mirror-0         ONLINE       0     0     0
            gpt/da2-jail   ONLINE       0     0     0
            gpt/ada2-jail  ONLINE       0     0     0

errors: No known data errors
```

我们从池名称开始。状态与`HEALTH`列类似；它显示池的任何问题。扫描字段展示了清理过程的信息（参见“池的完整性与修复”，见第 273 页）。

然后是池的配置。配置展示了池中虚拟设备的布局。当我们创建池时，我们会深入讨论这一点。

#### ***池属性***

类似于数据集，zpool 也有属性来控制和显示池的设置。有些属性是纯粹的信息性属性，例如`free`属性，表示池中剩余的空间。你可以更改其他属性。

#### ***查看池属性***

要查看池的所有属性，请使用`zpool get`。添加属性`all`可以查看每个属性。你也可以添加池名称，仅查看该池的属性。

```
# zpool get all zroot
NAME   PROPERTY       VALUE                          SOURCE
zroot  size           928G                           -
zroot  capacity       0%                             -
zroot  health         ONLINE                         -
zroot  guid           7955546176707282768            default
--snip--
```

一些信息会被提取到诸如`zpool status`和`zpool list`这样的命令中。你也可以通过使用属性名称查询所有池的单个属性。

```
# zpool get readonly
NAME     PROPERTY  VALUE   SOURCE
zroot    readonly  off     -
jail     readonly  off     -
scratch  readonly  off     -
```

与数据集属性不同，大多数池属性在创建或导入池时设置。

### **虚拟设备**

*虚拟设备（VDEV）*是存储设备的集合。你可以将 VDEV 视为 RAID 容器：一个大的 RAID-5 向操作系统呈现为一个巨大的设备，尽管系统管理员知道它实际上是由多个较小的磁盘组成的。虚拟设备是 ZFS 魔法发生的地方。你可以为不同的冗余级别安排池，或者放弃冗余以最大化空间。

ZFS 的自动错误修正发生在 VDEV 级别。ZFS 中的一切，从 znodes（索引节点）到数据块，都会进行校验和以验证完整性。如果你的池具有足够的冗余，ZFS 会注意到数据已损坏，并从一个良好的副本中恢复。如果池缺乏冗余，ZFS 会通知你数据已损坏，你可以从备份中恢复。

一个 zpool 由一个或多个相同的 VDEV 组成。池将数据条带化到所有 VDEV 中，没有冗余。丢失一个 VDEV 意味着池丢失。如果你有一个包含大量磁盘的池，确保使用冗余 VDEV。

#### ***VDEV 类型和冗余***

ZFS 支持几种不同类型的 VDEV，每种类型的冗余程度和样式有所不同。常见的镜像磁盘类型，其中每个磁盘复制另一个磁盘上的内容，是一种 VDEV 类型。没有冗余的磁盘堆是另一种 VDEV 类型。ZFS 还包括三种不同种类的基于奇偶校验的高级冗余，称为*RAID-Z*。

在池中使用多个 VDEV 会创建类似于高级 RAID 阵列的系统。RAID-Z2 阵列看起来非常像 RAID-6，但一个具有两个 RAID-Z2 VDEV 的 ZFS 池类似于 RAID-60。镜像 VDEV 的工作方式类似于 RAID-1，但池中多个镜像的行为像 RAID-10。在这两种情况下，ZFS 将数据条带化到 VDEV 中，没有冗余。各个 VDEV 提供冗余。

小心选择你的 VDEV 类型。

##### **条带化 VDEV**

由单个磁盘组成的 VDEV 称为*条带*，没有冗余。丢失该磁盘意味着数据丢失。虽然一个池可以包含多个条带化 VDEV，但每个磁盘都是独立的 VDEV。类似于 RAID-0，丢失一个磁盘意味着整个池丢失。

##### **镜像 VDEV**

镜像 VDEV 在每个磁盘上存储 VDEV 数据的完整副本。你可以丢失 VDEV 中的所有磁盘，除了一个，仍然可以访问数据。一个镜像可以包含任意数量的磁盘。

ZFS 可以同时从所有镜像磁盘中读取数据，因此读取数据非常快速。然而，当你写入数据时，ZFS 必须同时将数据写入所有磁盘。直到最慢的磁盘完成写入，写入才算完成。写入性能会受到影响。

##### **RAID-Z**

RAID-Z 将数据和奇偶校验信息分布到所有磁盘中，类似于传统的 RAID。如果 RAID-Z 中的某个磁盘出现故障或开始提供损坏的数据，RAID-Z 会使用奇偶校验信息重新计算丢失的数据。RAID-Z VDEV 必须包含至少三个磁盘，并且能够承受任何单个磁盘的损坏。RAID-Z 有时也被称为*RAID-Z1*。

你不能在 RAID-Z 中添加或移除磁盘。如果你创建了一个五盘的 RAID-Z，它将永远是一个五盘的 RAID-Z。不要以为你可以向 RAID-Z 中添加额外的磁盘来增加存储空间，你不能这样做。

如果你使用的是超过 2TB 的磁盘，在修复第一个磁盘时，第二个磁盘出现故障的可能性是非同小可的。对于大容量磁盘，你应该考虑使用 RAID-Z2。

##### **RAID-Z2**

RAID-Z2 将奇偶校验和数据分条存储在 VDEV 中的每个磁盘上，类似于 RAID-Z1，但将奇偶校验信息的数量加倍。这意味着 RAID-Z2 可以承受最多两个磁盘的损失。你不能在 RAID-Z2 中添加或移除磁盘。它的速度稍慢于 RAID-Z。

RAID-Z2 必须包含四个或更多的磁盘。

##### **RAID-Z3**

三重奇偶校验适用于最重要的数据，或者是那些有大量磁盘且没有时间浪费的系统管理员。你可以在 RAID-Z3 中丢失最多三个磁盘而不丢失数据。和其他 RAID-Z 一样，你不能在 RAID-Z3 中添加或移除磁盘。

RAID-Z3 必须包含五个或更多的磁盘。

##### **日志和缓存 VDEVs**

池可以通过专用的 VDEV 来提升性能。只有在性能问题需要时才调整或实现这些 VDEV；不要主动添加它们。^(1) 大多数人不需要它们，因此我不会详细讲解，但你应该知道它们的存在，以防万一你不走运。

*分离意图日志（SLOG* 或 *ZIL）* 是 ZFS 的文件系统日志。待写入的数据会被转存到 SLOG，然后以更合适的方式安排到主池中。每个池都会为 SLOG 分配一块磁盘空间，但你也可以使用一个独立的设备来作为 SLOG。如果你需要更快的写入速度，可以安装一个非常快速的磁盘并将其专门用作 SLOG。池会将所有初始写入操作转存到快速磁盘设备上，然后随着时间推移将这些写入操作迁移到较慢的介质中。一个专用的快速 SLOG 还会平滑突发的 I/O。

*二级自适应替换缓存（L2ARC）*类似于 SLOG，但用于读取。ZFS 将最近访问和最常访问的数据保存在内存中。通过添加一个非常快的设备作为 L2ARC，你可以扩大 ZFS 从缓存提供的数据量，而不是从慢磁盘读取。L2ARC 比内存慢，但比慢磁盘快。

##### **RAID-Z 和池**

你可以向池中添加 VDEV，但不能向 RAID-Z VDEV 添加磁盘。创建池之前，请考虑好你的存储需求和硬件配置。

假设你有一台可以容纳 20 个硬盘的服务器，但你只有 12 个硬盘。你用这 12 个硬盘创建了一个 RAID-Z2 VDEV，想着如果以后需要，可以再往池中添加更多硬盘。但你甚至还没安装完服务器，就已经失败了。

你可以向池中添加多个相同的 VDEV。如果你创建了一个 12 磁盘的 VDEV，而主机只能再容纳 8 个磁盘，那就无法创建第二个相同的 VDEV。一个 12 磁盘的 RAID-Z2 和一个 8 磁盘的 RAID-Z2 并不相同。你可以强制 ZFS 接受不同的 VDEV，但性能会受到影响。向池中添加 VDEV 是不可逆的操作。

提前规划。看看你的物理设备。决定如何扩展存储。这个 20 驱动的服务器可以使用两个 10 磁盘的 RAID-Z2 VDEV，或者一个 12 磁盘的池和一个独立的 8 磁盘池。不要让自己受阻。

一旦你知道了想要使用哪种 VDEV，就可以创建池了。

### **管理池**

既然你已经理解了不同的 VDEV 类型并开始规划你的存储，我们来创建一些不同类型的 zpool。首先设置你的磁盘块大小。

#### ***ZFS 和磁盘块大小***

第十章讲解了现代磁盘有两种不同的扇区大小，512 字节和 4KB。如果文件系统假设磁盘具有 4KB 的扇区，而实际上磁盘有 512 字节的扇区，你的性能将会急剧下降。ZFS 当然假设磁盘具有 512 字节的扇区。如果你的磁盘确实有 512 字节的扇区，那就没问题了。但如果你不确定物理扇区的大小，最好还是谨慎些，告诉 ZFS 使用 4KB 的扇区。通过*ashift*属性控制 ZFS 的磁盘扇区假设。ashift 为 9 时，ZFS 使用 512 字节的扇区，而 ashift 为 12 时表示 4KB 扇区。通过 sysctl `vfs.zfs.min_auto_ashift`来控制 ashift。

```
# sysctl vfs.zfs.min_auto_ashift=12
```

通过在*/etc/sysctl.conf*中设置它，使其永久生效。

在创建池之前，你*必须*设置 ashift。池创建后再设置 ashift 没有效果。

如果你不确定磁盘的扇区大小，可以使用 ashift 为 12。这也是 FreeBSD 安装程序所做的。你会损失一点性能，但如果在 4KB 磁盘上使用 ashift 为 9，会大幅度降低系统性能。

现在创建你的池。

#### ***创建和查看池***

使用 zpool `create`命令创建一个池。

```
# zpool create poolname vdevtype disks...
```

如果命令成功执行，你不会收到任何输出。

在这里，我创建了一个名为 *db* 的池，使用镜像 VDEV 和两个带有 GPT 标签的分区：

```
# zpool create db mirror gpt/zfs3 gpt/zfs4
```

我们分配的结构会在池状态中反映出来。

```
# zpool status db
--snip--
config:

        NAME          STATE     READ WRITE CKSUM
        db            ONLINE       0     0     0
        ➊ mirror-0    ONLINE       0     0     0
          ➋ gpt/zfs3  ONLINE       0     0     0
          ➌ gpt/zfs4  ONLINE       0     0     0
--snip--
```

池 db 包含一个名为 *mirror-0* ➊ 的 VDEV。它包括两个带有 GPT 标签的分区，*/dev/gpt/zfs3* ➋ 和 */dev/gpt/zfs* ➌。所有这些分区都在线。

如果你没有包括 VDEV 名称，`zpool(8)` 会创建一个没有冗余的条带池。在这里，我创建了一个名为 *scratch* 的条带池：

```
# zpool create scratch gpt/zfs3 gpt/zfs4
```

池状态显示每个 VDEV，名字来自底层磁盘。

```
--snip--
        NAME        STATE     READ WRITE CKSUM
        garbage     ONLINE       0     0     0
          gpt/zfs3  ONLINE       0     0     0
          gpt/zfs4  ONLINE       0     0     0
--snip--
```

创建任何类型的 RAID-Z 看起来都很像创建镜像。只需要使用正确的 VDEV 类型。

```
# zpool create db raidz gpt/zfs3 gpt/zfs4 gpt/zfs5
```

池状态与镜像的状态非常相似，但 VDEV 中有更多的磁盘。

#### ***多 VDEV 池***

当你创建池时，关键字 `mirror`、`raidz`、`raidz2` 和 `raidz3` 都会告诉 `zpool(8)` 创建一个新的 VDEV。列在这些关键字后的任何磁盘都会用于创建新的 VDEV。要创建一个包含多个 VDEV 的池，你可以像这样操作：

```
# zpool create poolname vdevtype disks... vdevtype disks...
```

在这里，我创建了一个包含两个 RAID-Z VDEV 的池，每个 VDEV 包含三个磁盘：

```
# zpool create db raidz gpt/zfs3 gpt/zfs4 gpt/zfs5 raidz gpt/zfs6 gpt/zfs7 gpt/zfs8
```

对这个新池执行 `zpool status` 命令时，显示的信息会稍有不同。

```
--snip--
        NAME          STATE     READ WRITE CKSUM
        db            ONLINE       0     0     0
        ➊ raidz1-0    ONLINE       0     0     0
            gpt/zfs3  ONLINE       0     0     0
            gpt/zfs4  ONLINE       0     0     0
            gpt/zfs5  ONLINE       0     0     0
        ➋ raidz1-1    ONLINE       0     0     0
            gpt/zfs6  ONLINE       0     0     0
            gpt/zfs7  ONLINE       0     0     0
            gpt/zfs8  ONLINE       0     0     0
--snip--
```

这个池包含一个名为 `raidz1-0` ➊ 的 VDEV，其中有三个磁盘。还有一个名为 `raidz1-1` ➋ 的第二个 VDEV，里面也有三个磁盘。很明显，这些池是相同的。数据在两个 VDEV 之间进行条带化存储。

#### ***销毁池***

要销毁一个池，使用 `zpool destroy` 和池的名称。

```
# zpool destroy db
```

注意，`zpool` 不会在销毁池之前询问你是否真的确定。是否确定要销毁池是你的问题，而不是 `zpool(8)` 的问题。

#### ***错误和 -f***

如果你输入一个没有意义的命令，`zpool(8)` 会报错。

```
# zpool create db raidz gpt/zfs3 gpt/zfs4 gpt/zfs5 raidz gpt/zfs6 gpt/zfs7
invalid vdev specification
use '-f' to override the following errors:
mismatched replication level: both 3-way and 2-way raidz vdevs are present
```

阅读错误信息时你首先看到的是“使用 `-f` 来覆盖此错误。”许多系统管理员会将其理解为“`-f` 使这个问题消失。”然而，ZFS 实际上是在说：“你的命令行是个大错误。添加 `-f` 会做一些无法修复、对系统稳定性有害的事，而且你会后悔直到这个系统不再运行。”

大多数 `zfs(8)` 和 `zpool(8)` 错误信息都有意义，但你需要仔细阅读。如果你不理解信息，可以查看 第一章 的故障排除说明。通常，重新检查你输入的内容会暴露问题所在。

在这个例子中，我让 `zpool(8)` 创建一个包含三个磁盘的 RAID-Z VDEV 和一个只包含两个磁盘的第二个 RAID-Z VDEV。我搞错了这个命令行。添加 `-f` 并继续将我的数据库安装到新的错误格式的 *db* 池中，只会确保我以后不得不重新创建这个池并重新安装数据库。^(2) 如果你发现自己处于这种情况，调查 `zfs send` 和 `zfs recv`。

### **写时复制**

在普通文件系统和 ZFS 中，文件以块的形式存在于磁盘上。当你在传统文件系统中编辑文件时，文件系统会取出块，修改它，并将其放回磁盘上的同一位置。写入过程中的系统故障可能会导致*损坏的写入*：文件的 50%是旧版本，50%是新版本，可能完全无法使用。

ZFS 永远不会覆盖文件中现有的块。当文件发生更改时，ZFS 会识别必须更改的块，并将其写入新的磁盘空间。旧版本会保持不变。这被称为*写时复制（COW）*。通过写时复制，短时间的写入可能会丢失文件的最新更改，但文件的先前版本会保持完好。

不会破坏文件是写时复制（COW）的一个很大优点，但 COW 也带来了其他可能性。元数据块也是写时复制，一直到形成 ZFS 池数据树根的*uberblocks*。ZFS 通过跟踪包含文件旧版本的块来创建快照。虽然这听起来很简单，但细节会让你迷失方向。

### **快照**

快照是数据集在某一特定时刻的副本。快照是只读的，永远不会改变。你可以访问快照的内容来访问文件的旧版本或甚至已删除的文件。虽然快照是只读的，你可以将数据集恢复到快照状态。在升级系统之前先创建一个快照，如果升级出了严重问题，你可以回滚到快照。ZFS 使用快照提供许多功能，例如启动环境（见 启动环境 在 第 276 页）。最棒的是，根据你的数据，快照可能只占用极少的空间。

每个数据集都有一堆元数据，所有这些元数据都是从一个顶级块构建成树形结构的。当你创建快照时，ZFS 会复制这个顶级块。一个元数据块与数据集一起，而另一个与快照一起。数据集和快照共享数据集中的数据块。

删除、修改或覆盖活动数据集中的文件意味着为新数据分配新的块，并断开包含旧数据的块。然而，快照需要一些旧数据块。在丢弃旧块之前，ZFS 会检查是否有快照仍然需要该块。如果快照需要一个块，但数据集不再需要，ZFS 会保留该块。

因此，快照仅仅是记录在创建快照时数据集使用的那些块的列表。创建快照会告诉 ZFS 保留这些块，即使数据集不再需要这些块。

#### ***创建快照***

使用 `zfs snapshot` 命令来创建快照。通过其完整路径指定数据集，然后添加 `@` 和快照名称。我习惯性地根据创建快照的日期和时间命名快照，原因将在本章末尾变得清晰。

我即将对用户的主目录进行维护，删除一些旧文件以释放空间。我很确定有人会抱怨我删除了他们的文件^(3)，所以在清理之前，我想先创建一个快照。

```
# zfs snapshot zroot/usr/home@2018-07-21-13:09:00
```

我没有收到任何反馈。发生了什么事吗？通过给 `zfs list` 添加 `-t snapshot` 参数来查看所有快照。

```
# zfs list -t snapshot
NAME                                    USED  AVAIL    REFER     MOUNTPOINT
zroot/usr/home@2018-07-21-13:09:00       ➊0     ➋-   ➌4.68G   ➍-
```

快照已经存在。`USED` 列显示它使用了零磁盘空间 ➊：它与它所在的数据集完全相同。由于快照是只读的，`AVAIL` 列显示的可用空间 ➋ 对它来说并不相关。`REFER` 列显示该快照占用了 4.68GB 的磁盘空间 ➌。如果你检查一下，你会发现这是 *zroot/usr/home* 的大小。最后，`MOUNTPOINT` 列显示该快照没有被挂载 ➍。

这是一个活跃的系统，其他人也已经登录。我等了一会儿，然后再次检查我的快照。

```
# zfs list -t snapshot
NAME                                    USED  AVAIL  REFER  MOUNTPOINT
zroot/usr/home@2018-07-21-13:09:00      ➊96K      -  4.68G  -
```

该快照现在使用了 96KB ➊。某个用户修改了数据集，快照因此占用了维持差异所需的空间。

现在我开始清理，删除我认为是垃圾的文件。

```
# zfs list -t snapshot
NAME                                    USED  AVAIL  REFER  MOUNTPOINT
zroot/usr/home@2018-07-21-13:09:00     1.62G      -  4.68G  -
```

现在这个快照使用了 1.62GB 的空间。这些是我已删除的文件，但它们仍然可以从快照中获取。我会保留这个快照一段时间，给用户一个投诉的机会。

#### ***访问快照***

每个 ZFS 数据集的根目录中都有一个隐藏的 *.zfs* 目录。它不会出现在 ls(1) 中；你需要知道它的存在。该目录包含一个快照目录，其中包含一个以每个快照命名的子目录。快照的内容就在该目录中。

对于我们的快照 *zroot/usr/home@2018-07-21-13:09:00*，我们需要进入 */usr/home/.zfs/snapshot/2018-07-21-13:09:00*。虽然 *.zfs* 目录在 ls(1) 中不会显示，但一旦进入该目录，ls(1) 就能正常工作。该目录包含了创建快照时文件的所有内容，即使我在创建该快照后删除或更改了这些文件。

从快照中恢复文件只需要将文件从快照复制到一个可读写的位置。

#### ***销毁快照***

快照是一个数据集，就像一个文件系统风格的数据集一样。使用 `zfs destroy` 命令来删除它。

```
# zfs destroy zroot/usr/home@2017-07-21-13:09:00
```

现在，快照占用的空间可以用来存储更多的垃圾文件。

### **压缩**

快照并不是 ZFS 节省空间的唯一方式。ZFS 使用实时压缩，透明地检查每个文件的内容，并在可能的情况下压缩其大小。使用 ZFS 时，你的程序不需要自己压缩日志文件：文件系统会实时为你完成压缩。虽然 FreeBSD 在安装时默认启用压缩，但如果你了解它是如何工作的，你会更有效地使用它。

压缩会改变系统性能，但可能不是你想象的方式。你需要 CPU 时间来压缩和解压缩数据，因为数据在磁盘之间进出。尽管如此，大多数磁盘请求通常比平常要小。你基本上是用处理器时间换取磁盘 I/O。我管理的每一台服务器，无论是裸机还是虚拟机，都拥有远远超过磁盘 I/O 的处理器能力，所以这是我愿意做出的交换。最终结果是，使用 ZFS 压缩通常会*提高*性能。

压缩在不同的数据集上表现不同。二进制文件本身已经压缩得非常紧凑；压缩*/usr/bin*几乎不会节省空间。然而，压缩*/var/log*通常会将文件大小减少六到七倍。检查属性`compressratio`以查看压缩效果如何缩小数据大小。我的主机写日志的频率远远高于写二进制文件。我会欣然接受这种常见任务的六倍性能提升。

ZFS 支持多种压缩算法，但默认使用*lz4*。lz4 算法的特别之处在于它能迅速识别无法压缩的文件。当你将二进制文件写入磁盘时，lz4 会检查它并说：“不，我帮不上忙，”然后立即停止尝试。这消除了无谓的 CPU 负载。然而，它会有效地压缩那些可以压缩的文件。

### **池完整性与修复**

ZFS 池中的每一块数据都有一个与之关联的加密哈希，存储在其元数据中以验证数据的完整性。每次访问数据时，ZFS 会重新计算该数据中每个块的哈希值。当 ZFS 在具有冗余的池中发现数据损坏时，它会透明地修正这些数据并继续。如果 ZFS 在没有冗余的池中发现数据损坏，它会发出警告并拒绝提供该数据。如果你的池中已识别任何数据错误，它们会显示在`zpool status`中。

#### ***完整性验证***

除了即时验证，ZFS 还可以显式地遍历整个文件系统树并验证池中的每个数据块。这叫做*扫描*。与 UFS 的 fsck(8)不同，扫描在池在线并且正在使用时进行。如果你之前运行过扫描，结果也会显示在池状态中。

```
  scan: scrub repaired 0 in 8h3m with 0 errors on Fri Jul 21 14:17:29 2017
```

要扫描池，运行`zpool scrub`并指定池名称。

```
# zpool scrub zroot
```

你可以使用`zpool status`查看扫描进度。

扫描池会降低其性能。如果你的系统已经接近极限，请仅在非高峰时段扫描池。你可以使用`-s`选项取消扫描^(4)。

```
# zpool scrub -s zroot
```

当负载下降时，再次运行扫描。

#### ***修复池***

磁盘会发生故障。这就是它们的用途。冗余的意义在于你可以用正常工作的磁盘替换故障或完全坏掉的磁盘，并恢复冗余。

镜像和 RAID-Z 虚拟设备专门设计用来重建磁盘故障时丢失的数据。从这个角度看，它们与 RAID 非常相似。如果 ZFS 镜像中的一块磁盘故障，你只需更换故障磁盘，ZFS 会将存活的镜像数据复制到新磁盘上。如果 RAID-Z VDEV 中的一块磁盘故障，你只需更换损坏的磁盘，ZFS 会从奇偶校验数据中重建该磁盘上的数据。

在 ZFS 中，这种重建操作被称为*resilvering*。与其他 ZFS 完整性操作类似，resilvering 只会在活动文件系统上进行。Resilvering 不像从奇偶校验重建 RAID 磁盘那样，ZFS 利用其对文件系统的了解来优化重新填充替换设备的过程。当你更换故障设备时，resilvering 会自动开始。ZFS 会以低优先级进行 resilvering，以免干扰正常操作。

#### ***池状态***

`zpool status`命令在`STATE`字段中显示底层存储硬件的健康状态。我们已经看到一些健康的池，接下来让我们看看一个不健康的池。

```
# zpool status db
  pool: db
 state: ➊DEGRADED
status: One or more devices could not be opened.  Sufficient replicas exist for
        the pool to continue functioning in a degraded state.
action: Attach the missing device and online it using 'zpool online'.
   see: http://illumos.org/msg/ZFS-8000-2Q
  scan: none requested
config:

        NAME                        STATE     READ WRITE CKSUM
        db                          DEGRADED     0     0     0
        ➋mirror-0                   DEGRADED     0     0     0
            gpt/zfs1                ONLINE       0     0     0
          ➌14398195156659397932   ➍UNAVAIL      0     0     0   ➎was /dev/gpt/zfs3

errors: No known data errors
```

池的状态是`DEGRADED` ➊。如果你进一步查看输出内容，会看到更多`DEGRADED`条目和一个`UNAVAIL` ➍。这究竟是什么意思？

池中的错误会向上蔓延。池状态是对池整体健康状况的总结。当池的虚拟设备*mirror-0* ➋处于`DEGRADED`状态时，整个池会显示为`DEGRADED`。这个错误源于底层磁盘处于`UNAVAIL`状态。我们可以获取该磁盘的 ZFS GUID ➌，以及用于创建池的标签 ➎。

当底层设备出现故障时，ZFS 池会显示错误。当池的状态不是`ONLINE`时，需深入查看 VDEV 和磁盘列表，直到找到真正的问题。

池、VDEV 和磁盘可以有六种状态：

**ONLINE** 该设备正常运行。

**DEGRADED** 该池或 VDEV 至少有一个提供者丢失、离线或产生的错误超过了 ZFS 的容忍范围。冗余机制正在处理该错误，但你需要立即解决这个问题。

**FAULTED** 故障磁盘已损坏或产生的错误超过了 ZFS 的容忍范围。故障 VDEV 会采用最后一个已知的良好数据副本。一个由两块故障磁盘组成的两盘镜像会处于故障状态。

**UNAVAIL** ZFS 无法打开该磁盘。也许它已经被移除、关闭，或者那个不稳定的电缆终于坏了。磁盘不在，所以 ZFS 无法使用它。

**OFFLINE** 该设备已被故意关闭。

**REMOVED** 一些硬件可以检测到在系统运行时物理移除的驱动器，从而让 ZFS 设置 REMOVED 标志。当你将驱动器重新插入时，ZFS 会尝试重新激活该磁盘。

我们丢失的磁盘处于 UNAVAIL 状态。由于某种原因，ZFS 无法访问*/dev/gpt/zfs3*，但磁盘镜像仍然可以提供数据，因为它有一块工作中的磁盘。现在你需要跑来跑去，搞清楚那个磁盘去哪儿了。你如何管理 ZFS 取决于你发现了什么问题。

##### **重新连接和断开驱动器**

不可用的磁盘可能并没有坏掉，它们可能只是断开了连接。如果你晃动磁盘托盘并突然看到绿色指示灯，那说明磁盘本身没问题，但连接出现故障。你应该解决这个硬件问题，是的，但在此期间，你可以重新激活该磁盘。你也可以重新激活故意移除的磁盘。使用`zpool online`命令，输入池名称和缺失磁盘的 GUID 作为参数。如果我示例中的池中的磁盘只是断开了连接，我可以这样重新激活它：

```
# zpool online db 14398195156659397932
```

ZFS 会重新同步磁盘并恢复正常功能。

如果你想移除一个磁盘，可以告诉 ZFS 通过`zpool offline`将其下线。作为参数提供池名和磁盘名。

```
# zpool offline db gpt/zfs6
```

将磁盘下线、物理移动它们、重新上线并允许池进行重新同步，能够让你在不产生停机时间的情况下将大型存储阵列从一个 SAS 机架迁移到另一个。

##### **更换磁盘**

如果磁盘不仅仅是松动，而是完全坏掉了，你需要用新磁盘替换它。ZFS 允许以多种方式更换磁盘，但最常见的方式是使用`zpool replace`。作为参数，提供池名、故障磁盘和新磁盘。在这里，我将 db 池中的*/dev/gpt/zfs3*磁盘替换为*/dev/gpt/zfs6*：

```
# zpool replace db gpt/zfs3 gpt/zfs6
```

该池将重新同步并恢复正常操作。

在大型存储阵列中，你还可以使用连续的`zpool replace`操作来清空一个磁盘架。只有当你所在组织的操作需求不允许将磁盘下线和重新上线时，才做这件事。

### **启动环境**

ZFS 帮助我们应对系统管理员所做的最危险的事情之一。不是我们的饮食习惯，也不是缺乏运动。我指的是系统升级。当升级顺利时，大家都很高兴。当升级失败时，可能会毁掉你的工作日、周末甚至工作。没有人喜欢在关键任务软件因共享库的新版本而崩溃时进行备份恢复。没有人喜欢恢复备份。

通过*启动环境*的魔力，ZFS 利用快照功能，让你在系统升级后只需要重启就能回退。启动环境是根数据集的克隆。它包括内核、基础系统的用户空间、附加包以及核心系统数据库。在执行升级之前，创建一个启动环境。如果升级顺利进行，那么一切正常。如果升级出了问题，你可以重启进入启动环境。这将恢复服务，让你调查升级失败的原因并修复这些问题。

启动环境在主机需要独立启动池时无法使用。安装程序会为你处理启动池。它们在结合 UEFI 和 GELI 时出现，或者在使用 ZFS 时出现在 MBR 分区的磁盘上。

使用启动环境需要一个启动环境管理器。我推荐使用 beadm(8)，它可以作为一个包安装。

```
# pkg install beadm
```

现在你可以使用启动环境了。

#### ***查看启动环境***

每个引导环境都是 *zroot/ROOT* 下的一个数据集。刚安装 beadm 的系统应该只有一个引导环境。使用 `beadm list` 可以查看所有引导环境。

```
  # beadm list
  BE        Active    Mountpoint  Space   Created
 ➊default  ➋NR      ➌/          ➍2.4G   ➎2018-05-04 13:13
```

这台主机有一个引导环境，名为 *default* ➊，对应的数据集是 *zroot/ROOT/default*。

Active 列 ➋ 显示这个引导环境是否正在使用中。`N` 表示该环境现在正在使用中。`R` 表示该环境将在重启后生效。当默认环境正在运行时，它们会一起出现。

Mountpoint 列 ➌ 显示了此引导环境的挂载点位置。大多数引导环境在未使用时不会挂载，但你可以使用 beadm(8) 挂载未使用的引导环境。

Space 列 ➍ 显示此引导环境使用的磁盘空间。它是基于一个快照构建的，因此该数据集中可能有比这个数量更多的数据。

Created 列 ➎ 显示了此引导环境的创建日期。在本例中，它是机器安装的日期。

在更改系统之前，创建一个新的引导环境。

#### ***创建和访问引导环境***

每个引导环境都需要一个名称。我建议使用基于当前操作系统版本和补丁级别或日期的名称。像“beforeupgrade”和“dangitall”这样的名称，虽然当时有意义，但以后会让你感到困惑。

使用 `beadm create` 创建新的引导环境。在这里，我检查当前的 FreeBSD 版本，并用它来创建引导环境的名称：

```
# freebsd-version
11.0-RELEASE-p11
# beadm create 11.0-p11
Created successfully
```

现在我有两个相同的引导环境。

```
# beadm list
BE  a       Active Mountpoint  Space Created
default    NR     /           12.3G 2015-04-28 11:53
11.0-p11   -      -          236.0K 2018-07-21 14:57
```

你可能注意到，新创建的引导环境已经占用了 236KB。这是一个实时系统。在我创建引导环境和列出这些环境之间，文件系统或其元数据发生了变化。

Active 列显示我们当前正在使用默认的引导环境，并且下次启动时将使用该环境。如果我更改了已安装的软件包或升级了基础系统，这些更改将影响默认环境。

每个引导环境都可以作为 *zroot/ROOT* 下的一个快照使用。如果你想访问一个引导环境并进行读写操作，可以使用 `beadm mount` 将其临时挂载到 */tmp* 下。使用 `beadm umount` 卸载这些环境。

#### ***激活引导环境***

假设你升级了软件包，系统崩溃了。通过激活一个引导环境并重启，你可以恢复到早期的操作系统安装状态。使用 `beadm activate` 激活引导环境。

```
# beadm activate 11.0-p11
Activated successfully
# beadm list
BE         Active Mountpoint  Space Created
default    N      /           12.4G 2015-04-28 11:53
11.0-p11   R      -          161.8M 2018-07-21 14:57
```

默认的引导环境的 Active 标志被设置为 `N`，表示当前正在运行。11.0-p11 环境有 `R` 标志，因此重启后它将生效。

重启系统后，你会突然回到先前的操作系统安装状态，系统中的不稳定更改也不会被保留。与其从备份中恢复，这样更简单。

#### ***删除引导环境***

在几次升级之后，你会发现你再也无法回到某些现有的启动环境。一旦我将这台主机升级到例如 12.2-RELEASE-p29，可能再也无法重启进入 11.0-p11。使用`beadm destroy`删除过时的启动环境并释放它们的磁盘空间。

```
# beadm destroy 11.0-p11
Are you sure you want to destroy '11.0-p11'?
This action cannot be undone (y/[n]): y
Destroyed successfully
```

当系统提示时，回答`y`，beadm 将删除该启动环境。

#### ***启动环境在启动时***

所以，你真的搞砸了操作系统。忘了进入多用户模式吧，你甚至无法进入*单用户*模式，除非生成一堆奇怪的错误信息。你可以在加载器提示符下选择一个启动环境。这需要控制台访问，但任何其他自救方法也都需要控制台访问。

启动加载器菜单包括一个选项，可以选择启动环境。选择该选项后，你会看到一个新的菜单，列出了主机上所有启动环境的名称。选择你想要的启动环境并按下 ENTER 键。系统将进入该环境，给你一个机会来查明为什么一切都出错了。

#### ***启动环境与应用程序***

升级失败并不足够糟糕，它可能还会带走你的应用程序数据。

大多数应用程序将它们的数据存储在根数据集的某个位置。MySQL 使用*/var/db/mysql*，而 Apache 使用*/usr/local/www*。这意味着回退到早期的启动环境时，可能会将你的应用程序数据一并回滚。根据你的应用程序，你可能希望或不希望发生这种回滚。

如果某个应用程序使用的数据不应该包含在启动环境中，你需要为该数据创建一个新的数据集。我在本章的 “未挂载的父数据集” 以及 第 262 页 中提供了一个示例。考虑你的应用程序的需求，并根据需要将数据分离。

虽然 ZFS 具有更多功能，但这篇文章涵盖了每个系统管理员*必须*知道的主题。你们中的许多人可能会发现克隆、委派或复制功能很有用。你也许会觉得 Allan Jude 和我自己所著的《FreeBSD Mastery: ZFS》（Tilted Windmill Press, 2015）和《FreeBSD Mastery: Advanced ZFS》（Tilted Windmill Press, 2016）这两本书很有帮助。你还会在互联网上找到很多关于这些主题的资源。

现在，让我们考虑一些 FreeBSD 管理员认为有用的其他文件系统。
