# 第一章：为什么容器很重要

![image](img/common01.jpg)

现在是做软件开发的好时机。创建一个全新的应用并使其能被数百万用户使用，从未如此简单。现代编程语言、开源库和应用平台使得编写少量代码并实现大量功能成为可能。然而，尽管开始并快速创建一个新应用很容易，但最优秀的应用开发者是那些不仅仅将应用平台视为一个“黑匣子”，而是能够真正理解它如何工作的开发者。创建一个可靠、具有韧性和可扩展的应用需要的不仅仅是知道如何在浏览器或命令行中创建部署。

在本章中，我们将探讨在一个可扩展、云原生的世界中的应用架构。我们将展示为什么容器是打包和部署应用组件的首选方式，以及容器编排如何满足容器化应用的关键需求。最后，我们将展示一个部署到 Kubernetes 的示例应用，给你一个关于这些技术的初步了解。

### 现代应用架构

现代软件应用的主要主题是*规模*。我们生活在一个拥有数百万同时在线用户的应用世界。值得注意的是，这些应用不仅能够实现这种规模，还能够保持一定的稳定性，以至于任何一次停机事件都能成为头条新闻，并成为数周或数月技术分析的素材。

随着如此多现代应用在大规模运行，往往很容易忘记，架构设计、构建、部署和维护这种高水平的应用需要付出大量的努力，无论它们设计的规模是面向数千、数百万还是数十亿用户。本章的任务是识别我们需要从应用平台中得到什么，以便运行一个可扩展、可靠的应用，并了解容器化和 Kubernetes 如何满足这些需求。我们将从看现代应用架构的三个关键特性开始，然后探讨这些特性带来的三个主要好处。

#### 特性：云原生

有很多方法可以定义*云原生*技术（一个好的起点是云原生计算基金会，[`cncf.io`](https://cncf.io)）。我喜欢从“云”是什么以及它能实现什么的角度出发，这样我们就能理解什么样的架构可以最好地利用它。

在其核心，云是一种抽象。在介绍中我们已经讨论了抽象，因此您知道抽象对于计算是至关重要的，但我们也需要深入了解我们的抽象才能正确地使用它们。在云的情况下，提供商正在抽象真实的物理处理器、内存、存储和网络，使得云用户可以简单地声明对这些资源的需求，并且按需分配它们。因此，要拥有“云原生”应用程序，我们需要一个能够利用该抽象的应用程序。在可能的情况下，应用程序不应绑定到特定的主机或特定的网络布局，因为我们不希望限制应用程序组件在主机之间的分布灵活性。

#### 属性：模块化

*模块化* 对应用架构并不是什么新鲜事物。其目标始终是*高内聚*，即模块内的一切都与单一目的相关，并且*低耦合*，即组织模块以最小化模块间通信。然而，尽管模块化仍然是一个关键的设计目标，但定义模块的方式已经有所不同。现代应用架构更倾向于将模块化带入运行时，而不仅仅是将其视为组织代码的一种方式，为每个模块提供独立的操作系统进程，并且不鼓励使用共享文件系统或共享内存进行通信。由于模块是独立的进程，模块间的通信是标准的网络（套接字）通信。

这种方法似乎对硬件资源的利用有些浪费。与其通过套接字复制数据，不如共享内存更为紧凑和快速。但是有两个很好的理由支持使用独立进程。首先，现代硬件速度很快，而且越来越快，想象套接字对我们的应用来说不够快速将是一种过早优化的形式。其次，无论我们有多大的服务器，能容纳的进程数量总是有限的，因此共享内存模型最终会限制我们的扩展能力。

#### 属性：基于微服务

现代应用架构基于形式各异的独立进程模块化，这些个体模块往往非常小。理论上，云可以为我们提供所需的强大虚拟服务器；然而实际上，使用少量强大的服务器比使用许多小型服务器更昂贵且不够灵活。如果我们的模块足够小，它们可以部署到廉价的通用服务器上，这意味着我们可以最大限度地利用云服务提供商的硬件优势。虽然没有一个单一的答案来说明模块需要多小才能成为*微服务*，但“足够小以便可以灵活地部署它”是一个很好的首要规则。

微服务架构在组织团队方面也具有实际的优势。自从弗雷德·布鲁克斯（Fred Brooks）写了《人月神话》（*The Mythical Man-Month*）以来，架构师们就意识到，组织人员是开发大型复杂系统的最大挑战之一。从许多小模块构建系统减少了测试的复杂性，同时也使得组织一个大团队变得可能，而不会让每个人都互相干扰。

**那么应用服务器呢？**

模块化服务的概念有着悠久的历史，其中一种流行的实现方式是构建模块并在应用服务器中运行，例如 Java 企业环境。那么，为什么不继续沿用这种应用程序的模式呢？

尽管应用服务器在许多场景中取得了成功，但它们并不像微服务架构那样具有相同程度的隔离性。因此，应用服务器存在更多的相互依赖问题，导致测试变得更加复杂，团队的独立性也有所降低。此外，通常每个主机上部署一个应用服务器，多个应用共享同一进程空间的模式，远没有容器化的方式灵活，而容器化方法将在本书中详细介绍。

这并不是说你应该立即抛弃应用服务器架构，而转向使用容器。容器化对于任何架构都有很多好处。但是，随着你逐步采用容器化架构，随着时间的推移，向真正的微服务架构迁移将会使你能够充分利用容器和 Kubernetes 所提供的优势。

我们已经看过了现代架构的三个关键属性。现在，让我们来看三个由此产生的关键好处。

#### 好处：可扩展性

让我们从构建最简单的应用程序开始。我们创建一个只在单台机器上运行、并且一次只与一个用户交互的可执行文件。现在，假设我们希望将该应用程序扩展，以便能够同时与成千上万的用户交互。显然，无论我们使用多么强大的服务器，最终某些计算资源都会成为瓶颈。不管瓶颈是处理能力、内存、存储还是网络带宽；一旦我们遇到瓶颈，我们的应用程序将无法处理更多的用户，并且会影响其他用户的性能。

解决这个问题的唯一方法是停止共享导致瓶颈的资源。这意味着我们需要找到一种方法，将应用程序分布到多个服务器上。但如果我们要真正扩展，不能仅此为止。我们还需要在多个网络间进行分布，否则会遇到单个网络交换机的限制。最终，我们甚至需要进行地理分布，否则整个广域网络将达到饱和。

为了构建无可扩展性限制的应用程序，我们需要一种能够根据需要运行额外应用实例的架构。而且，由于应用程序的速度只受限于最慢的组件，我们需要找到一种方法来扩展*所有*组件，包括我们的数据存储。显而易见，唯一有效的方式就是将应用程序从许多独立的组件构建而成，这些组件不依赖于特定的硬件。换句话说，云原生微服务。

#### 优势：可靠性

让我们回到最简单的应用程序。除了可扩展性限制外，它还有另一个缺陷。它运行在一台服务器上，如果这台服务器发生故障，整个应用程序就会失败。我们的应用程序缺乏可靠性。如同之前所说，解决这个问题的唯一方法就是停止共享可能发生故障的资源。幸运的是，当我们开始将应用程序分布到多台服务器时，我们有机会避免硬件中的单点故障，这样就不会导致整个应用程序的崩溃。而且，由于应用程序的可靠性取决于其最不可靠的组件，我们需要找到一种方法来分发所有内容，包括存储和网络。同样，我们需要云原生微服务，它们在运行位置和实例数量上都具有灵活性。

#### 优势：弹性

云原生微服务架构还有第三个、更微妙的优势。这一次，假设有一个运行在单个服务器上的应用程序，但它可以轻松地作为一个单独的包安装到任意数量的服务器上。每个实例都可以为一个新用户提供服务。理论上，由于我们可以随时将其安装到另一台服务器上，这个应用程序应该具有良好的可扩展性。总体来说，应用程序可以说是可靠的，因为单一服务器的故障只会影响到一个用户，而其他用户可以照常运行。

这种方法所缺失的是弹性的概念，或者说应用程序对故障的有意义响应能力。一个真正具有弹性的应用程序可以在应用程序中的某个硬件或软件发生故障时，确保最终用户根本不会注意到故障的存在。尽管如此，分离的、互不相关的实例在其中一个实例发生故障时仍然能够继续运行，但我们不能真正说这个应用程序表现出了弹性，至少从那个遭遇故障的用户的角度来看是这样。

另一方面，如果我们将应用程序构建为多个独立的微服务，每个微服务都能够通过网络与其他微服务进行通信，那么单个服务器的丧失可能会导致多个微服务实例的损失，但最终用户可以透明地切换到其他服务器上的实例，这样他们甚至不会注意到故障的发生。

### 为什么选择容器

我已经让现代应用架构和它那炫酷的云原生微服务听起来非常有吸引力了。然而，工程中充满了权衡，经验丰富的工程师会怀疑一定会有一些非常重大的权衡，当然，确实如此。

从许多小的组件构建一个应用程序是*非常困难*的。围绕微服务组织团队，使得它们能够独立工作可能是很好的，但当需要将这些组件组合成一个可以运行的应用程序时，组件数量庞大意味着我们必须担心如何打包它们，如何将它们交付到运行环境中，如何配置它们，如何为它们提供（可能存在冲突的）依赖项，如何更新它们，以及如何监控它们以确保它们正常工作。

当我们考虑到需要运行每个微服务的多个实例时，这个问题变得更加严重。现在，我们需要一个微服务能够找到另一个微服务的工作实例，并在所有工作实例之间均衡负载。我们需要负载均衡在发生硬件或软件故障时立即重新配置自己。我们需要无缝切换并重试失败的工作，以便将故障对终端用户隐藏起来。而且我们不仅需要监控每个单独的服务，还需要监控所有服务如何协同工作以完成任务。毕竟，如果我们有 99%的微服务正常工作，而 1%的故障使得用户无法使用我们的应用程序，我们的用户是不会在乎其他微服务是否正常工作的。

如果我们想从许多独立的微服务中构建一个应用程序，我们面临许多问题需要解决，并且我们不希望每个微服务团队都去解决这些问题，否则他们就永远没有时间写代码！我们需要一种共同的方式来管理微服务的打包、部署、配置和维护。我们来看一下所需属性的两类：适用于单个微服务的属性和适用于多个微服务共同工作的属性。

#### 容器的需求

对于单个微服务，我们需要以下内容：

**打包** 将应用程序打包以便交付，打包中需要包括依赖项，以便包是可移植的，并且我们避免微服务之间的冲突。

**版本控制** 唯一标识一个版本。我们需要随时间更新微服务，并且我们需要知道哪个版本正在运行。

**隔离性** 防止微服务相互干扰。这使得我们能够灵活地部署微服务。

**快速启动** 快速启动新的实例。我们需要这个来扩展和应对故障。

**低开销** 最小化运行微服务所需的资源，以避免对微服务大小的限制。

*容器* 正是为了解决这些需求而设计的。容器提供隔离，同时具有低开销和快速启动的特点。正如我们将在第五章中看到的，容器是从容器镜像中运行的，容器镜像为我们提供了一种将应用程序及其依赖项打包并唯一标识该包版本的方式。

#### 编排的需求

对于多个微服务协同工作，我们需要：

**集群** 提供跨多个服务器的容器处理、内存和存储。

**发现** 为一个微服务提供查找另一个微服务的方法。我们的微服务可能在集群中的任何地方运行，而且它们可能会移动。

**配置** 将配置与运行时分离，允许我们在不重新构建和重新部署微服务的情况下重新配置应用程序。

**访问控制** 管理创建容器的授权。这确保了正确的容器运行，错误的容器不会运行。

**负载均衡** 在工作实例之间分配请求，以避免最终用户或其他微服务自行跟踪所有微服务实例并平衡负载。

**监控** 识别失败的微服务实例。如果流量指向失败的实例，负载均衡将无法正常工作。

**弹性** 自动从故障中恢复。如果没有这个能力，故障链可能会致使我们的应用程序崩溃。

这些需求仅在我们在多个服务器上运行容器时才会发挥作用。这与仅打包并运行单个容器是不同的问题。为了解决这些需求，我们需要一个*容器编排*环境。像 Kubernetes 这样的容器编排环境使我们能够将多个服务器视为一组资源来运行容器，动态地将容器分配到可用的服务器，并提供分布式通信和存储。

### 运行容器

到现在为止，希望你已经对使用容器化微服务和 Kubernetes 构建应用程序的可能性感到兴奋。让我们先了解一些基础知识，这样你就可以看到这些想法在实践中的应用，并为本书后续深入研究容器技术奠定基础。

#### 容器的样子

在第二章，我们将研究容器平台与容器运行时之间的区别，并使用多个容器运行时来运行容器。目前，我们从一个简单的例子开始，在最流行的容器平台*Docker*上运行。我们的目标是学习基本的 Docker 命令，这些命令与通用的容器概念相一致。

##### 运行一个容器

第一个命令是`run`，它会创建一个容器并在其中运行一个命令。我们将告诉 Docker 使用哪个容器镜像的名称。关于容器镜像的详细内容，我们将在第五章中讨论；目前，知道它提供一个独特的名称和版本号就足够了，这样 Docker 就能准确知道运行什么。让我们开始使用本章的示例。

**注意**

*本书的示例代码库位于* [`github.com/book-of-kubernetes/examples`](https://github.com/book-of-kubernetes/examples)。*有关设置的详细信息，请参见第 xx 页中的“运行示例”部分。*

本节的一个关键概念是容器看起来像是一个完全独立的系统。为了说明这一点，在我们运行容器之前，让我们先看一下主机系统：

```
root@host01:~# cat /etc/os-release
NAME="Ubuntu"
...
root@host01:~# ps -ef
UID          PID    PPID  C STIME TTY          TIME CMD
root           1       0  0 12:59 ?        00:00:07 /sbin/init
...
root@host01:~# uname -v
#...-Ubuntu SMP ...
root@host01:~# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 ...
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
...
3: enp0s8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel ...
    link/ether 08:00:27:bf:63:1f brd ff:ff:ff:ff:ff:ff
    inet 192.168.61.11/24 brd 192.168.61.255 scope global enp0s8
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:febf:631f/64 scope link 
       valid_lft forever preferred_lft forever
...
```

第一个命令查看一个名为*/etc/os-release*的文件，里面包含有关已安装 Linux 发行版的信息。在这个例子中，我们的虚拟机正在运行 Ubuntu。这与接下来命令的输出相匹配，在该命令中我们看到一个基于 Ubuntu 的 Linux 内核。最后，我们列出网络接口，并看到一个 IP 地址`192.168.61.11`。

示例的设置步骤已自动安装 Docker，因此我们可以直接使用它。首先，让我们用一个命令下载并启动一个 Rocky Linux 容器：

```
root@host01:~# docker run -ti rockylinux:8
Unable to find image 'rockylinux:8' locally
8: Pulling from library/rockylinux
...
Status: Downloaded newer image for rockylinux:8
```

我们在`docker run`命令中使用`-ti`参数，告诉 Docker 我们需要一个交互式终端来运行命令。`docker run`的唯一其他参数是容器镜像`rockylinux:8`，它指定了名称`rockylinux`和版本`8`。由于我们没有提供要运行的命令，因此默认使用该容器镜像的`bash`命令。

现在我们在容器内有了一个 shell 提示符，可以运行一些命令，然后使用`exit`退出 shell 并停止容器：

```
➊ [root@18f20e2d7e49 /]# cat /etc/os-release
➋ NAME="Rocky Linux"
  ...
➌ [root@18f20e2d7e49 /]# yum install -y procps iproute
  ...
  [root@18f20e2d7e49 /]# ps -ef
  UID          PID    PPID  C STIME TTY          TIME CMD
  root        ➍ 1       0  0 13:30 pts/0    00:00:00 /bin/bash
  root          19       1  0 13:46 pts/0    00:00:00 ps -ef
  [root@18f20e2d7e49 /]# ip addr
  1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 ...
  link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
  inet 127.0.0.1/8 scope host lo
     valid_lft forever preferred_lft forever
➎ 18: eth0@if19: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 ... 
  link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
  inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
     valid_lft forever preferred_lft forever
  [root@18f20e2d7e49 /]# uname -v
➏ #...-Ubuntu SMP ...
  [root@18f20e2d7e49 /]# exit
```

当我们在容器内运行命令时，看起来就像是在一个 Rocky Linux 系统中运行。与主机系统相比，有多个差异：

+   shell 提示符中不同的主机名 ➊（我的主机名是`18f20e2d7e49`，但你的会不同）

+   不同的文件系统内容 ➋，包括像*/etc/os-release*这样的基础文件

+   使用`yum` ➌安装包，甚至基础命令也需要安装包

+   限制的运行进程集，没有基础系统服务，我们的 bash shell ➍作为进程 ID（PID）1

+   不同的网络设备 ➎，包括不同的 MAC 地址和 IP 地址

然而，奇怪的是，当我们运行`uname -v`时，我们看到的与主机上完全相同的 Ubuntu Linux 内核 ➏。显然，容器并不是我们想象的那样是一个完全独立的系统。

##### 镜像和卷挂载

乍一看，容器看起来像是常规进程和虚拟机的混合体。我们与 Docker 的交互方式更深刻地加强了这一印象。让我们通过运行一个 Alpine Linux 容器来说明这一点。我们将首先“拉取”容器镜像，这与下载虚拟机镜像非常相似：

```
root@host01:~# docker pull alpine:3
3: Pulling from library/alpine
...
docker.io/library/alpine:3
```

接下来，我们将从镜像运行一个容器。我们将使用*卷挂载*来查看主机上的文件，这在虚拟机中是一个常见任务。我们还会告诉 Docker 指定一个环境变量，这就是我们在运行常规进程时会做的事情：

```
root@host01:~# docker run -ti -v /:/host -e hello=world alpine:3
/ # hostname
75b51510ab61
```

我们可以像之前在 Rocky Linux 中一样打印容器内的*/etc/os-release*文件内容：

```
/ # cat /etc/os-release 
NAME="Alpine Linux"
ID=alpine
...
```

然而，这次我们还可以打印主机的*/etc/os-release*文件，因为主机文件系统已挂载到*/host*：

```
/ # cat /host/etc/os-release 
NAME="Ubuntu"
...
```

最后，在容器内我们也可以访问传入的环境变量：

```
/ # echo $hello
world
/ # exit
```

这种混合虚拟机和常规进程的概念有时会导致新容器用户提出类似“为什么我不能通过 SSH 连接到我的容器？”的问题。接下来几章的一个主要目标是阐明容器到底是什么。

#### 容器究竟是什么

尽管容器看起来像有自己的主机名、文件系统、进程空间和网络，但容器并不是虚拟机。它没有独立的内核，因此不能有独立的内核模块或设备驱动程序。一个容器可以有多个进程，但它们必须由第一个进程（PID 1）显式启动。所以，容器默认不会有 SSH 服务器，大多数容器也不会运行任何系统服务。

在接下来的几章中，我们将看看容器如何在看似是一个独立系统的同时，实际上只是一组进程。现在，让我们再试一个 Docker 示例，看看从主机系统看容器是什么样的。

首先，我们将下载并运行 NGINX，只需一个命令：

```
root@host01:~# docker run -d -p 8080:80 nginx
Unable to find image 'nginx:latest' locally
latest: Pulling from library/nginx
...
Status: Downloaded newer image for nginx:latest
e9c5e87020372a23ce31ad10bd87011ed29882f65f97f3af8d32438a8340f936
```

这个示例演示了几个额外有用的 Docker 命令。再次提醒，我们正在混合虚拟机和常规进程的概念。通过使用`-d`标志，我们告诉 Docker 以*守护进程模式*（后台模式）运行容器，这正是我们为常规进程所做的事情。然而，使用`-p 8080:80`带来了另一个虚拟机的概念，因为它指示 Docker 将主机上的 8080 端口转发到容器内的 80 端口，从而让我们即使容器有自己的网络接口，也能从主机连接到 NGINX。

NGINX 现在在 Docker 容器中后台运行。要查看它，请运行以下命令：

```
root@host01:~# docker ps
CONTAINER ID IMAGE ... PORTS                  NAMES
e9c5e8702037 nginx ... 0.0.0.0:8080->80/tcp   funny_montalcini
```

由于端口转发，我们可以通过`curl`从主机系统连接到它：

```
root@host01:~# curl http://localhost:8080/
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
...
```

通过这个示例，我们开始看到容器化如何满足我们在本章前面提到的一些需求。因为 NGINX 被打包成一个容器镜像，我们可以通过一个命令下载并运行它，而不必担心与主机上可能安装的其他内容产生冲突。

让我们再运行一个命令来探索我们的 NGINX 服务器：

```
root@host01:~# ps -ef | grep nginx | grep -v grep
root     35729 35703 0 14:17 ? 00:00:00 nginx: master ...
systemd+ 35796 35729 0 14:17 ? 00:00:00 nginx: worker ...
```

如果 NGINX 运行在虚拟机中，我们在主机系统的 `ps` 列表中是看不到它的。显然，NGINX 在容器中作为一个常规进程运行。同时，我们并不需要将 NGINX 安装到主机系统中就能让它工作。换句话说，我们可以享受虚拟机方法的好处，而无需承受虚拟机的开销。

### 将容器部署到 Kubernetes

为了在容器化应用程序中实现负载均衡和弹性，我们需要像 Kubernetes 这样的容器编排框架。我们的示例系统还自动安装了一个 Kubernetes 集群，并将 Web 应用程序和数据库部署到了其中。作为我们深入探讨 Kubernetes 的准备，在第二部分中，让我们来看一下这个应用程序。

有很多不同的安装和配置 Kubernetes 集群的选项，许多公司都提供了不同的发行版。在第六章中，我们讨论了多种 Kubernetes 发行版的选择。本章中，我们将使用来自 Rancher 公司的轻量级发行版“K3s”。

为了使用像 Kubernetes 这样的容器编排环境，我们必须放弃对容器的部分控制。我们不再直接执行命令来运行容器，而是告诉 Kubernetes 我们希望它运行哪些容器，Kubernetes 会决定在哪个节点上运行每个容器。Kubernetes 会为我们监控容器，并处理自动重启、故障转移、版本更新，甚至根据负载进行自动扩缩容。这种配置方式被称为*声明式*。

#### 与 Kubernetes 集群交互

Kubernetes 集群有一个 API 服务器，我们可以用它来获取状态并更改集群配置。我们通过 `kubectl` 客户端应用程序与 API 服务器交互。K3s 附带了它自己的内嵌 `kubectl` 命令，我们将使用它。让我们先获取一些关于 Kubernetes 集群的基本信息：

```
root@host01:~# k3s kubectl version
Client Version: version.Info{Major:"1", ...
Server Version: version.Info{Major:"1", ...
root@host01:~# k3s kubectl get nodes
NAME     STATUS   ROLES             AGE   VERSION
host01   Ready    control-plane...  2d    v1...
```

如你所见，我们正在使用一个单节点 Kubernetes 集群。当然，这并不能满足我们对高可用性的需求。大多数 Kubernetes 发行版，包括 K3s，都支持多节点、高可用性集群，我们将在第二部分中详细介绍这种方式。

#### 应用程序概述

我们的示例应用程序提供一个带有 Web 界面的“待办事项”列表、持久化存储以及条目状态跟踪。即使自动化脚本完成后，这个应用程序在 Kubernetes 中运行也需要几分钟时间。运行后，我们可以在浏览器中访问它，并应该看到类似图 1-1 的内容。

![Image](img/f0015-01.jpg)

*图 1-1：Kubernetes 中的示例应用程序*

这个应用程序被分为两种类型的容器，每种类型负责一个应用组件。Node.js 应用程序向浏览器提供文件并提供 REST API。Node.js 应用程序与 PostgreSQL 数据库通信。Node.js 组件是无状态的，因此可以根据用户数量轻松扩展到所需的多个实例。在这种情况下，我们的应用程序的 Deployment 向 Kubernetes 请求了三个 Node.js 容器：

```
root@host01:~# k3s kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
todo-db-7df8b44d65-744mt   1/1     Running   0          2d
todo-655ff549f8-l4dxt      1/1     Running   0          2d
todo-655ff549f8-gc7b6      1/1     Running   1          2d
todo-655ff549f8-qq8ff      1/1     Running   1          2d
```

命令 `get pods` 告诉 Kubernetes 列出 *Pods*。Pod 是一个包含一个或多个容器的组，Kubernetes 将其视为一个单元进行调度和监控。我们将在第二部分中更详细地查看 Pods。

在这里，我们有一个以 `todo-db` 开头的 Pod，它是我们的 PostgreSQL 数据库。其他三个以 `todo` 开头的 Pods 是 Node.js 容器。（稍后我们会解释为什么名称后面会有随机字符；你现在可以忽略这一点。）

根据 Kubernetes 的说法，我们的应用组件容器正在运行，所以我们应该能够在浏览器中访问我们的应用。如何操作取决于你是在 AWS 还是 Vagrant 中运行；示例设置脚本会打印出你在浏览器中应该使用的 URL。如果你访问那个 URL，你应该能看到类似于图 1-1 的内容。

#### Kubernetes 特性

如果我们的唯一目标是运行四个容器，我们可以仅使用之前描述的 Docker 命令来完成。然而，Kubernetes 提供了更多的功能。让我们快速了解一下最重要的功能。

除了运行我们的容器，Kubernetes 还在监控它们。因为我们要求有三个实例，Kubernetes 会确保始终保持三个实例运行。让我们销毁一个并观察 Kubernetes 如何自动恢复：

```
root@host01:~# k3s kubectl delete pod todo-655ff549f8-qq8ff
pod "todo-655ff549f8-qq8ff" deleted
root@host01:~# k3s kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
todo-db-7df8b44d65-744mt   1/1     Running   0          2d
todo-655ff549f8-l4dxt      1/1     Running   0          2d
todo-655ff549f8-gc7b6      1/1     Running   1          2d
todo-655ff549f8-rm8sh      1/1     Running   0          11s
```

要运行这个命令，你需要复制并粘贴你三个 Pods 之一的完整名称。这个名称会与你的稍微不同。当你删除一个 Pod 时，你应该会看到 Kubernetes 立即创建一个新的 Pod。（你可以通过 `AGE` 字段来识别哪个是新创建的。）

接下来，让我们探讨一下 Kubernetes 如何自动扩展我们的应用程序。稍后我们将看到如何让 Kubernetes 自动执行此操作，但现在我们将手动进行。假设我们决定需要五个 Pods，而不是三个。我们可以通过一条命令来做到这一点：

```
root@host01:~# k3s kubectl scale --replicas=5 deployment todo
deployment.apps/todo scaled
root@host01:~# k3s kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
todo-db-7df8b44d65-744mt   1/1     Running   0          2d
todo-655ff549f8-l4dxt      1/1     Running   0          2d
todo-655ff549f8-gc7b6      1/1     Running   1          2d
todo-655ff549f8-rm8sh      1/1     Running   0          5m13s
todo-655ff549f8-g7lxg      1/1     Running   0          6s
todo-655ff549f8-zsqp6      1/1     Running   0          6s
```

我们告诉 Kubernetes 扩展管理我们 Pods 的 *Deployment*。现在，你可以把 Deployment 看作是 Pods 的“所有者”；它监控它们并控制 Pods 的数量。这里，两个额外的 Pods 被立即创建。我们刚刚扩展了我们的应用程序。

在结束之前，让我们再来看一个至关重要的 Kubernetes 功能。当你在浏览器中加载应用程序时，Kubernetes 会将你的浏览器请求发送到可用的 Pod 之一。每次重新加载时，请求可能会被路由到不同的 Pod，因为 Kubernetes 会自动平衡应用程序的负载。为了实现这一点，当我们将应用程序部署到 Kubernetes 时，应用程序的配置包括一个*Service*：

```
root@host01:~# k3s kubectl describe service todo
Name:       todo
...
IPs:        10.43.231.177
Port:       <unset>  80/TCP
TargetPort: 5000/TCP
Endpoints:  10.42.0.10:5000,10.42.0.11:5000,10.42.0.14:5000 + 2 more...
...
```

每个服务都有自己的 IP 地址，并将流量路由到一个或多个端点。在这种情况下，由于我们将 Pod 数量扩展到五个，服务正在对所有五个端点的流量进行负载均衡。

### 最后的思考

现代应用程序通过基于微服务的架构实现可扩展性和可靠性，微服务可以独立部署并动态分配到可用的硬件上，包括云资源。通过使用容器和容器编排来运行我们的微服务，我们实现了一种通用的方法来打包、扩展、监控和维护微服务，使我们的开发团队可以专注于实际构建应用程序的艰苦工作。

在本章中，我们看到容器化如何创造出一个独立系统的外观，而实际上它只是一个以隔离方式运行的常规进程。我们还看到如何使用 Kubernetes 将整个应用程序作为一组容器进行部署，具备可扩展性和自愈性。当然，Kubernetes 的功能远不止我们在这里提到的这些，足够让我们用整本书来详细讲解！通过这一简要概述，我希望你能对容器和 Kubernetes 产生兴趣，深入了解如何构建高性能且可靠的应用程序。

我们将在本书的第二部分再次讨论 Kubernetes。现在，让我们仔细看看容器是如何创建出一个独立系统的假象的。我们将从使用 Linux 命名空间来实现进程隔离开始。
