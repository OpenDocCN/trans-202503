# 10

使用视频

![](img/chapterart.png)

## 草图 80：播放视频

我们可以使用 Processing 来播放视频，但正如处理音频时一样，Processing 本身没有提供视频播放功能。因此，我们使用`processing.video`库中的`Movie`类，它又使用了底层基于 Java 的视频功能。作为第一个示例，该草图将加载并显示一个短视频。

首先，我们在程序的第一行导入`processing.video`库 1：

```
import processing.video.*;
```

现在我们可以声明一个`Movie`类的实例 2，为每个我们想要播放的视频创建一个实例：

```
Movie movie;
```

我们在初始化类实例时通过调用其构造函数加载视频文件（见草图 43），并指定文件名作为参数 3：

```
movie = new Movie(this, "car.avi");
```

在`setup()`函数中，我们通过调用`movie.play()`函数开始从文件读取视频（这个函数不仅仅是播放视频，正如你所期望的那样）。视频是压缩的图像或帧的序列，就像动画一样，每一帧的读取和解码可能需要一些显著的时间。当我们调用`play()`后，系统尝试从文件中读取帧，当某一帧准备好时，`available()`函数返回`true`。然后我们可以使用`read()`获取该帧。像`PGraphics`对象一样，`Movie`对象可以作为图像进行处理，并使用`image()`函数显示。因此，显示电影的过程是这样的 4：

```
if (movie.available()) 
{
  movie.read();
  image (movie, 0, 0);
}
```

如果没有新的帧可用，`read()`将不会被调用，之前读取的帧将显示在其位置上。通常这种情况不容易察觉。

`Movie`类会与电影一起播放声音。

该草图还会在窗口顶部打印相关信息。它统计已读取的帧数并显示该数字。它还显示时间计数，即已经播放的秒数，通过调用`movie.time()`函数获取 5。当电影播放完成时，如`movie.time() >= movie.duration()`所示 6，计数器会重置，电影通过调用`movie.jump(0)`从第一帧重新播放。`jump(t)`函数调用将当前帧移至时间`t`的帧。通过调用`movie.loop()`而不是`movie.play()`，也可以实现循环播放。在这种情况下，电影从位置 0 重新播放将是自动的。

## 草图 81：使用快进拨盘播放视频

偏移轮（或快进拨盘）是一个通常呈圆形的设备，允许用户在视频中前进或后退。顺时针转动它会将视频逐帧向前播放，逆时针转动它会将视频向后播放。编辑人员通常使用它来精确定位每一帧的视频。这个草图将实现这种快进过程的近似。视频将开始播放，用户可以使用鼠标调整播放的速度和方向。在任何时刻，用户都可以停止视频并慢慢倒回，以达到任何特定的帧。

为了做到这一点，我们必须解决如何倒放视频的问题。`jump()`函数允许我们将视频定位到任何特定时刻 2。任何特定帧的时间取决于帧率，即每秒播放的帧数。假设帧率为`rate`，我们知道每一帧的持续时间是 1/`rate`秒。最后一帧发生在从开始算起的`duration()`秒处，因此可以使用以下调用将视频定位到该帧之前的帧：

```
movie.jump (movie.duration-(1/rate))
```

前一帧位于`movie.jump(movie.duration-(1/rate)*2)`，依此类推。通过这种方式，逐帧向后跳转，读取帧并显示它。

在该示例中，我们将当前帧的时间存储在`time`变量中，帧与帧之间的时间存储在`ftime`变量中。我们将使用鼠标来控制视频显示的速度。点击屏幕中间将通过将`ftime`设置为 0 来设置速度为 0。点击右侧将`ftime`设置为一个与屏幕中间的距离成比例的值，从而使视频向前播放；点击左侧将`ftime`设置为一个值，使视频倒放。最初`ftime = 1/rate`，但当点击最左边时，这个值变为原来的负 3 倍，点击最右边时，变为正 3 倍。这就是整个计算 3：

```
ftime = 3*((float)(width/2 - mouseX)/(width/2))/rate;
```

在视频的结尾（如果倒放的话，实际上是开始）会出现一个小问题。如果在向前播放时找到结尾，时间将被设置为 0；如果在倒放时找到开始，时间将被设置为`duration()-ftime`。

基本的显示过程 1 发生在`draw()`中，过程如下：

```
if (movie.available())  movie.read();  // Read a frame if one is there
image(movie,0,0);                      // Display it
time = time - ftime;                   // Advance/retard the time value
movie.jump(time);                      // Set frame to the one at that time
```

示例显示一个简单的校准界面，允许用户选择速度，并显示`ftime`的值。

## 示例 82：从视频中保存静止帧

这个示例允许用户从视频中保存一组静止图像帧。视频会循环播放，以便用户可以选择所需的所有帧。点击鼠标将开始保存图像，再次点击将停止保存。

保存帧是通过使用`Movie`类对象的`save()`函数实现的。如果`movie`是一个`Movie`对象，以下调用将当前帧保存到指定文件中，并根据文件扩展名指定文件类型：

```
movie.save("name.jpg");
```

这与我们保存`PImage`图片的方式相同。在这种情况下，我们保存 JPEG 格式，但 GIF、PNG 和其他文件格式也同样适用。

为了在不每次覆盖同一文件的情况下保存多个帧，我们可以将已经保存的静止图像的数量存储在变量`v`中，并将其加入文件名，示例如下：

```
movie.save("frame"+v+".jpg");
```

这意味着文件名将会是*frame1.jpg*、*frame2.jpg*，依此类推。

然而，使用这种标签方案时，无法判断保存的一个序列何时结束，另一个序列何时开始。这个草图通过将变量`nclicks`与`v`结合使用来解决这个问题。当用户在保存帧时点击鼠标时，保存停止，`nclicks`会增加，并且`v`被重置。我们通过帧计数和相对于`nclicks`变量的字母构建文件名：`nclicks` = 0 时在文件名中添加字母“`a`”，`nclicks` = 1 时添加字母“`b`”，依此类推。每个帧的文件实际上是按以下方式保存的：

```
movie.save("frame"+char(nclicks+int('a'))+v+".jpg");
```

第一组序列将是*framea1.jpg*、*framea2.jpg*，依此类推，第二组将是*frameb1.jpg*，依此类推。

草图会在屏幕上绘制时间，但这是为了用户查看——它不会出现在保存的图像中。

另一个保存视频帧的方法是将其显示在草图窗口中，然后将草图窗口保存为图像。如果我们在这种情况下这样做，窗口上绘制的时间实际上会与图像一起保存到文件中。

## 草图 83：实时处理视频

一些应用程序逐帧处理或分析视频帧，而不需要实时查看结果。例如，可以通过捕捉视频来分析击球手的挥棒动作，增强每一帧中的相关部分，然后将增强后的帧重新组合成视频形式。甚至当每一帧的分析不需要太多计算时，也可以在视频播放时进行处理，并看到实时结果。

在这个草图中，我们之前使用的那个视频将被转换为灰度图像，并在实时中进行阈值处理，就像我们在草图 23 中对静态图像所做的那样。

请记住，我们可以像对待`PImage`对象一样对待`Movie`对象（它们具有相同的本地功能）。我们使用`movie.loadPixels()`方法提取电影图像中的每个像素`p`，并通过计算颜色组件的平均值来得出亮度或灰度值：`(red(p)+green(p)+blue(p))/3`。如果该值小于阈值，则显示图像中的相应像素将被设置为黑色；否则，它将被设置为白色。在这个草图中，阈值为 100。结果是一个只显示黑白像素的视频。

设置与之前相同，但我们还创建了一个第二个图像，其大小与视频帧相同（命名为`display`），用于保存每个显示帧的处理副本。`draw()`函数在帧准备好时读取该帧，然后调用本地的`thresh()`函数来计算阈值处理后的图像。在`thresh()`创建了一个阈值化的电影图像版本后，两个图像会一个接一个地显示，并且这两个版本同时播放。

这种情况下的结果不算令人印象深刻，但它确实提供了我们可以做什么的一个想法。例如，如果我们仔细选择阈值，可能只会显示场景中汽车的运动，去除背景的杂乱。

在其他视频中，我们可以定位面部、增强和读取行驶中汽车的车牌，或者检查并计算传送带上经过摄像头的苹果。这些问题属于计算机视觉领域，Processing 是构建计算机视觉系统的一个好工具，因为它在处理图像方面非常简便。

## 示例 84：从网络摄像头捕捉视频

大多数电脑和几乎所有的笔记本电脑都有内置摄像头。之前的示例处理的是已经捕获的视频，意味着已经有一个视频文件可以展示或处理。这个示例将从网络摄像头捕获实时视频数据，并以灰度显示。

`Capture` 类处理相机和图像/视频捕捉。要使用它，首先声明一个实例 1：

```
Capture camera;
```

然后通过类构造函数初始化它。类构造函数可能只需要参数 `this`，或者 `this` 和设备说明符 2：

```
Camera = new Capture (this);  
camera = new Capture (this, myCamera);
```

`myCamera` 变量是一个设备说明符字符串，格式如下：

```
"name=USB2.0 HD UVC WebCam,size=160x120,fps=15"
```

该字符串中的大部分信息都有明显的含义，并且大多数并非绝对必要。如果你知道摄像头的分辨率为 640×480，以下调用将打开摄像头：

```
camera = new Capture (this, "size=640x480");
```

图像捕获始于调用 `start()` 3：

```
camera.start();
```

就像播放视频时一样，当 `camera.available()` 返回 `true` 时，帧数据可用。此时，摄像头实例可以像 `PImage` 一样处理，并通过调用 `image()` 来显示。

这个示例将摄像头图像复制到 `PImage` 变量 `display` 4 中。`grey()` 函数将彩色图像转换为灰度图像，并显示在原始图像位置。结果是一个实时的灰度图像，展示了摄像头正在捕捉的内容。请耐心等待——打开摄像头设备可能需要一些时间。

`Capture` 类的 `list()` 函数查看计算机上可用的摄像头设备，并返回一个可以在构造函数中使用的描述符列表。所以，如果这一行

```
String[] cameras = Capture.list();
```

这将紧随其后

```
for (int i=0; i<cameras.length; i++)
  println (cameras[i]);
```

然后，所有可用的摄像头将被打印到窗口上。我们可以选择一个，并在代码中使用该摄像头的索引，从 `cameras[]` 数组中选择它。例如，你可以搜索分辨率为 640×480 且帧率为 130fps 的摄像头，并在列表中找到它作为摄像头 `i`。然后你可以通过数组索引选择你想要的摄像头：

```
camera = new Capture (this, cameras[i]);
```

## 示例 85：将实时视频映射为纹理

在之前的示例中，你看到 `Movie` 对象可以作为 `PImage` 来处理，用于显示或从视频帧中提取像素。这个示例展示了将视频用作 3D 表面的纹理，再次像 `PImage` 一样。其思路是用视频绘制一个四角平面（四边形），使视频在 3D 平面上播放，并随着用户视角的变化而进行缩短。

草图的第一部分设置了网络摄像头（与之前相同），将`camera`变量作为图像源，并将 P3D 设置为当前的渲染器。在执行时，系统需要几秒钟来判断连接了哪些摄像头以及使用哪个摄像头。我们通过在`setup()`中调用`start()`来完成这一切，包括启动摄像头。

在`draw()`中，首先检查是否有新的图像可用。如果有，我们读取它；如果没有，则保留上一张图像作为当前图像。接下来，我们建立一个 3D 环境，通过调用`camera`设置视角。我们在 3D 空间中绘制一个四边形，并将网络摄像头作为纹理。视角会稍微摆动一下（x 在−30 到 100 之间）以显示视图正在变化。

效果是，四边形似乎在不断地改变位置和方向，而实时视频在四边形内播放。这个效果的一个有趣变种是绘制一个旋转的立方体，并将视频映射到所有面上。虽然这不会展示新内容，但它需要更多的代码。
