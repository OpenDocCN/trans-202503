# 检查与修改数据

![](img/chapterart.png)

如果我要向刚刚获得认证的数据分析师们敬酒，我会举杯说道：“愿你们的数据完美结构化，且无任何错误！”但现实中，你有时会收到状态糟糕的数据，难以分析，除非先进行修改。这就是所谓的*脏数据*，是一个总称，用于描述包含错误、缺失值或组织不良的数据，这些数据会使标准查询变得无效。在这一章中，你将使用 SQL 清理一组脏数据，并执行其他有用的维护任务，使数据变得可用。

脏数据可能有多种来源。从一种文件类型转换为另一种文件类型，或将列赋予错误的数据类型，可能导致信息丢失。人在输入或编辑数据时也可能不小心，留下拼写错误和不一致的地方。不论原因是什么，脏数据都是数据分析师的噩梦。

你将学习如何检查数据质量，如何修改数据和表格以便更容易进行分析。但你将学到的技巧不仅仅适用于清理数据。能够对数据和表格进行修改，让你有机会在新信息可用时更新或添加它们，从而使你的数据库从静态集合变成一个动态记录。

让我们从导入数据开始吧。

## 导入肉类、家禽和蛋类生产商的数据

在这个示例中，我们将使用美国肉类、家禽和蛋类生产商的目录。食品安全和检验局（FSIS），是美国农业部下属的一个机构，负责定期汇编并更新该数据库。FSIS 负责检查超过 6,000 家肉类加工厂、屠宰场、农场等地的动物和食品。如果检查员发现问题，例如细菌污染或标签错误，机构可以发出召回通知。任何对农业业务、食品供应链或食源性疾病爆发感兴趣的人都将发现该目录很有用。你可以在该机构的网站[`www.fsis.usda.gov/`](https://www.fsis.usda.gov/)上了解更多信息。

我们将使用的数据来自[`www.data.gov/`](https://www.data.gov/)，这是美国联邦政府运营的网站，汇集了来自各种联邦机构的数千个数据集（[`catalog.data.gov/dataset/fsis-meat-poultry-and-egg-inspection-directory-by-establishment-name/`](https://catalog.data.gov/dataset/fsis-meat-poultry-and-egg-inspection-directory-by-establishment-name/)）。我已将该网站上发布的 Excel 文件转换为 CSV 格式，你可以在[`nostarch.com/practical-sql-2nd-edition/`](https://nostarch.com/practical-sql-2nd-edition/)找到*MPI_Directory_by_Establishment_Name.csv*文件和本书的其他资源链接。

要将文件导入到 PostgreSQL 中，使用 清单 10-1 中的代码创建一个名为 `meat_poultry_egg_establishments` 的表，并使用 `COPY` 将 CSV 文件添加到表中。像之前的示例一样，使用 pgAdmin 连接到你的 `analysis` 数据库，然后打开查询工具运行代码。记得更改 `COPY` 语句中的路径，以反映你的 CSV 文件的位置。

```
CREATE TABLE meat_poultry_egg_establishments (
  1 establishment_number text CONSTRAINT est_number_key PRIMARY KEY,
    company text,
    street text,
    city text,
    st text,
    zip text,
    phone text,
    grant_date date,
  2 activities text,
    dbas text
);

3 COPY meat_poultry_egg_establishments
FROM '`C:\YourDirectory\`MPI_Directory_by_Establishment_Name.csv'
WITH (FORMAT CSV, HEADER);

4 CREATE INDEX company_idx ON meat_poultry_egg_establishments (company);
```

清单 10-1：导入 FSIS 肉类、家禽和蛋类检查目录

该表有 10 列。我们为 `establishment_number` 列 1 添加了一个自然主键约束，该列将保存唯一的值以标识每个机构。其余大部分列与公司的名称和位置相关。你将在本章末尾的“动手实践”练习中使用 `activities` 列 2，它描述了公司的活动。我们将大部分列设置为 `text` 类型。在 PostgreSQL 中，`text` 是一个可变长度的数据类型，允许我们存储最多 1GB 的数据（参见第四章）。`dbas` 列包含超过 1,000 个字符的字符串，因此我们已经准备好处理这些数据。我们导入 CSV 文件 3，然后在 `company` 列 4 上创建索引，以加速对特定公司的查询。

作为练习，让我们使用第九章中介绍的 `count()` 聚合函数来检查 `meat_poultry_egg_establishments` 表中有多少行：

```
SELECT count(*) FROM meat_poultry_egg_establishments;
```

结果应该显示 6,287 行。现在，让我们了解数据包含了什么，并确定是否可以直接从中提取有用信息，或者是否需要以某种方式进行修改。

## 数据集采访

采访数据是我分析中最喜欢的部分。我们采访数据集以发现其细节——它包含了什么，它能回答哪些问题，以及它对我们的目的是否合适——就像工作面试揭示候选人是否具备所需技能一样。

第九章中的聚合查询是一个有用的采访工具，因为它们常常揭示数据集的局限性，或者提出在得出结论并假设结果有效之前你可能想要问的问题。

例如，`meat_poultry_egg_establishments` 表的行描述了食品生产商。乍一看，我们可能会假设每一行中的每个公司都在一个不同的地址上运营。但在数据分析中，假设永远是不安全的，所以让我们使用 清单 10-2 中的代码来验证。

```
SELECT company,
       street,
       city,
       st,
       count(*) AS address_count
FROM meat_poultry_egg_establishments
GROUP BY company, street, city, st
HAVING count(*) > 1
ORDER BY company, street, city, st;
```

清单 10-2：查找位于相同地址的多个公司

在这里，我们按 `company`、`street`、`city` 和 `st` 列的唯一组合对公司进行分组。然后，我们使用 `count(*)`，它返回每个组合的行数，并给它一个别名 `address_count`。使用第九章介绍的 `HAVING` 子句，我们筛选结果，只显示那些具有相同值组合的多行数据。这应该返回公司所有重复的地址。

查询返回了 23 行，这意味着大约有两打的记录，其中同一公司在同一地址出现多次：

```
company                    street                     city          st    address_count
-----------------------    -----------------------    ----------    --    -------------
Acre Station Meat Farm     17076 Hwy 32 N             Pinetown      NC                2
Beltex Corporation         3801 North Grove Street    Fort Worth    TX                2
Cloverleaf Cold Storage    111 Imperial Drive         Sanford       NC                2
`--snip--`
```

这不一定是个问题。公司在同一地址出现多次可能有合理的原因。例如，可能存在两个同名的加工厂。另一方面，我们可能也发现了数据录入错误。不论如何，在依赖数据集之前，消除对其有效性的疑虑是明智的做法，这个结果应该促使我们在得出结论之前，先调查各个具体案例。然而，在我们能够从数据中提取有意义信息之前，这个数据集还有其他问题需要我们注意。我们来通过几个例子探讨一下。

### 检查缺失值

接下来，我们将检查是否包含了所有州的值，并且通过一个简单的问题来检查是否有行缺少州代码：每个州的肉类、家禽和蛋类加工公司有多少家？我们将使用聚合函数`count()`并结合`GROUP BY`来确定这个数字，如清单 10-3 所示。

```
SELECT st,
       count(*) AS st_count
FROM meat_poultry_egg_establishments
GROUP BY st
ORDER BY st;
```

清单 10-3：按州分组并计数

该查询是一个简单的计数，统计每个州邮政编码（`st`）在表中出现的次数。你的结果应包括 57 行，按州邮政编码（在`st`列中）分组。为什么超过 50 个美国州？因为数据中还包括波多黎各和其他未合并的美国领土，例如关岛和美属萨摩亚。阿拉斯加（`AK`）位于结果顶部，共有 17 家企业：

```
st    st_count
--    --------
AK          17
AL          93
AR          87
AS           1
`--snip--`
WA         139
WI         184
WV          23
WY           1
             3
```

然而，列表底部的这一行在`st`列中有`NULL`值，并且`st_count`中有`3`。这意味着有三行`st`的值是`NULL`。为了查看这些设施的详细信息，我们来查询这些行。

在清单 10-4 中，我们添加了一个`WHERE`子句，结合`st`列和`IS NULL`关键字来查找哪些行缺少州代码。

```
SELECT establishment_number,
       company,
       city,
       st,
       zip
FROM meat_poultry_egg_establishments
WHERE st IS NULL;
```

清单 10-4：使用`IS NULL`查找`st`列中的缺失值

这个查询返回了三行`st`列没有值的记录：

```
est_number           company                            city      st    zip
-----------------    -------------------------------    ------    --    -----
V18677A              Atlas Inspection, Inc.             Blaine          55449
M45319+P45319        Hall-Namie Packing Company, Inc                    36671
M263A+P263A+V263A    Jones Dairy Farm                                   53538
```

这是一个问题，因为任何包含`st`列的计数都会不准确，例如按州统计的企业数量。当你发现类似的错误时，值得快速检查一下你下载的原始文件。除非你处理的是数吉字节大小的文件，否则通常可以在我在第一章中提到的文本编辑器中打开 CSV 文件并搜索该行。如果你处理的是较大的文件，可以使用`grep`（在 Linux 和 macOS 上）或`findstr`（在 Windows 上）等工具查看源数据。在这个例子中，来自[`www.data.gov/`](https://www.data.gov/)的文件经过可视化检查后，确认确实在文件中的这些行没有列出州名，因此这个错误是数据本身的问题，而不是导入过程中引入的错误。

在对数据的初步审查中，我们发现需要向`st`列添加缺失的值以清理这个表格。让我们看看数据集中还有哪些问题，并列出清理任务。

### 检查不一致的数据值

不一致的数据是另一个可能妨碍我们分析的因素。我们可以通过使用`GROUP BY`和`count()`来检查列中不一致输入的数据。当你扫描结果中的去重值时，可能会发现名字或其他属性的拼写差异。

例如，我们表格中的 6,200 家公司中，许多是由少数跨国食品公司拥有的多个地点，如嘉吉公司（Cargill）或泰森食品（Tyson Foods）。为了找出每家公司拥有多少个地点，我们可以统计`company`列中的值。让我们看看使用列表 10-5 中的查询时会发生什么。

```
SELECT company,
       count(*) AS company_count
FROM meat_poultry_egg_establishments
GROUP BY company
ORDER BY company ASC;
```

列表 10-5：使用`GROUP BY`和`count()`来查找不一致的公司名称

滚动查看结果可以发现一些公司的名称以多种不同的方式拼写。例如，注意到 Armour-Eckrich 品牌的条目：

```
company                        company_count
---------------------------    -------------
`--snip--`
Armour - Eckrich Meats, LLC                1
Armour-Eckrich Meats LLC                   3
Armour-Eckrich Meats, Inc.                 1
Armour-Eckrich Meats, LLC                  2
`--snip--`
```

对于七个可能由同一家公司拥有的机构，至少有四种不同的拼写方式。如果我们稍后按公司进行聚合，标准化名称会有所帮助，这样所有计数或求和的项目可以正确分组。让我们将这一点加入需要修复的事项列表。

### 使用 length()检查格式错误的值

检查列中应该保持一致格式的意外值是个好主意。例如，`meat_poultry_egg_establishments`表中的`zip`列每个条目应该按照美国 ZIP 代码格式（五位数字）进行格式化。然而，这并不是我们数据集中所包含的内容。

````Solely for the purpose of this example, I replicated a common error I’ve committed before. When I converted the original Excel file to a CSV file, I stored the ZIP code in the default “General” number format instead of as a text value, and any ZIP code that begins with a zero lost its leading zero because an integer can’t start with a zero. As a result, 07502 appears in the table as `7502`. You can make this error in a variety of ways, including by copying and pasting data into Excel columns set to “General.” After being burned a few times, I learned to take extra caution with numbers that should be formatted as text.    My deliberate error appears when we run the code in Listing 10-6. The example introduces `length()`, a *string function* that counts the number of characters in a string. We combine `length()` with `count()` and `GROUP BY` to determine how many rows have five characters in the `zip` field and how many have a value other than five. To make it easy to scan the results, we use `length()` in the `ORDER BY` clause.    ``` SELECT length(zip),         count(*) AS length_count  FROM meat_poultry_egg_establishments  GROUP BY length(zip)  ORDER BY length(zip) ASC; ```    Listing 10-6: Using `length()` and `count()` to test the `zip` column    The results confirm the formatting error. As you can see, `496` of the ZIP codes are four characters long, and `86` are three characters long, which likely means these numbers originally had two leading zeros that my conversion erroneously eliminated:    ``` length    length_count  ------    ------------       3              86       4             496       5            5705 ```    Using the `WHERE` clause, we can see which states these shortened ZIP codes correspond to, as shown in Listing 10-7.    ``` SELECT st,         count(*) AS st_count  FROM meat_poultry_egg_establishments  1 WHERE length(zip) < 5  GROUP BY st  ORDER BY st ASC; ```    Listing 10-7: Filtering with `length()` to find short `zip` values    We use the `length()` function inside the `WHERE` clause 1 to return a count of rows where the ZIP code is less than five characters for each state code. The result is what we would expect. The states are largely in the Northeast region of the United States where ZIP codes often start with a zero:    ``` st    st_count  --    --------  CT          55  MA         101  ME          24  NH          18  NJ         244  PR          84  RI          27  VI           2  VT          27 ```    Obviously, we don’t want this error to persist, so we’ll add it to our list of items to correct. So far, we need to correct the following issues in our dataset:    *   Missing values for three rows in the `st` column *   Inconsistent spelling of at least one company’s name *   Inaccurate ZIP codes due to file conversion    Next, we’ll look at how to use SQL to fix these issues by modifying your data.    ## Modifying Tables, Columns, and Data    Almost nothing in a database, from tables to columns and the data types and values they contain, is set in concrete after it’s created. As your needs change, you can use SQL to add columns to a table, change data types on existing columns, and edit values. Given the issues we discovered in the `meat_poultry_egg_establishments` table, being able to modify our database will come in handy.    We’ll use two SQL commands. The first, `ALTER TABLE`, is part of the ANSI SQL standard and provides options to `ADD COLUMN`, `ALTER COLUMN`, and `DROP COLUMN`, among others.    The second command, `UPDATE`, also included in the SQL standard, allows you to change values in a table’s columns. You can supply criteria using `WHERE` to choose which rows to update.    Let’s explore the basic syntax and options for both commands and then use them to fix the issues in our dataset.    ### Modifying Tables with ALTER TABLE    We can use the `ALTER TABLE` statement to modify the structure of tables. The following examples show standard ANSI SQL syntax for common operations, starting with the code for adding a column to a table:    ``` ALTER TABLE `table` ADD COLUMN `column` `data_type`; ```    We can remove a column with the following syntax:    ``` ALTER TABLE `table` DROP COLUMN `column`; ```    To change the data type of a column, we would use this code:    ``` ALTER TABLE `table` ALTER COLUMN `column` SET DATA TYPE `data_type`; ```    We add a `NOT NULL` constraint to a column like so:    ``` ALTER TABLE `table` ALTER COLUMN `column` SET NOT NULL; ```    Note that in PostgreSQL and some other systems, adding a constraint to the table causes all rows to be checked to see whether they comply with the constraint. If the table has millions of rows, this could take a while.    Removing the `NOT NULL` constraint looks like this:    ``` ALTER TABLE `table` ALTER COLUMN `column` DROP NOT NULL; ```    When you execute `ALTER TABLE` with the placeholders filled in, you should see a message that reads `ALTER TABLE` in the pgAdmin output screen. If an operation violates a constraint or if you attempt to change a column’s data type and the existing values in the column won’t conform to the new data type, PostgreSQL returns an error. But PostgreSQL won’t give you any warning about deleting data when you drop a column, so use extra caution before dropping a column.    ### Modifying Values with UPDATE    The `UPDATE` statement, part of the ANSI SQL standard, modifies the data in a column that meets a condition. It can be applied to all rows or a subset of rows. Its basic syntax for updating the data in every row in a column follows this form:    ``` UPDATE `table`  SET `column` = `value`; ```    We first pass `UPDATE` the name of the table. Then to `SET` we pass the column we want to update. The new `value` to place in the column can be a string, number, the name of another column, or even a query or expression that generates a value. The new value must be compatible with the column data type.    We can update values in multiple columns by adding additional columns and source values and separating each with a comma:    ``` UPDATE `table`  SET `column_a` = `value`,   `column_b` = `value`; ```    To restrict the update to particular rows, we add a `WHERE` clause with some criteria that must be met before the update can happen, such as rows where values equal a date or match a string:    ``` UPDATE `table`  SET `column` = `value`  WHERE `criteria`; ```    We can also update one table with values from another table. Standard ANSI SQL requires that we use a *subquery*, a query inside a query, to specify which values and rows to update:    ``` UPDATE `table`  SET `column` = (SELECT `column`                FROM `table_b`                WHERE `table.column` = `table_b.column`)  WHERE EXISTS (SELECT `column`                FROM `table_b`                WHERE `table.column` = `table_b.column`); ```    The value portion of `SET`, inside the parentheses, is a subquery. A `SELECT` statement inside parentheses generates the values for the update by joining columns in both tables on matching row values. Similarly, the `WHERE EXISTS` clause uses a `SELECT` statement to ensure that we only update rows where both tables have matching values. If we didn’t use `WHERE EXISTS`, we might inadvertently set some values to `NULL` without planning to. (If this syntax looks somewhat complicated, that’s okay. I’ll cover subqueries in detail in Chapter 13.)    Some database managers offer additional syntax for updating across tables. PostgreSQL supports the ANSI standard but also a simpler syntax using a `FROM` clause:    ``` UPDATE `table`  SET `column` = `table_b.column`  FROM `table_b`  WHERE `table.column = table_b.column`; ```    When you execute an `UPDATE` statement, you’ll get a message stating `UPDATE` along with the number of rows affected.    ### Viewing Modified Data with RETURNING    If you add an optional `RETURNING` clause to `UPDATE`, you can view the values that were modified without having to run a second, separate query. The syntax of the clause uses the `RETURNING` keyword followed by a list of columns or a wildcard in the same manner that we name columns following `SELECT`. Here’s an example:    ``` UPDATE `table`  SET `column_a` = `value`  RETURNING `column_a`, `column_b`, `column_c`; ```    Instead of just noting the number of rows modified, `RETURNING` directs the database to show the columns you specify for the rows modified. This is a PostgreSQL-specific implementation that you also can use with `INSERT` and `DELETE FROM`. We’ll try it with some of our examples.    ### Creating Backup Tables    Before modifying a table, it’s a good idea to make a copy for reference and backup in case you accidentally destroy some data. Listing 10-8 shows how to use a variation of the familiar `CREATE TABLE` statement to make a new table from the table we want to duplicate.    ``` CREATE TABLE meat_poultry_egg_establishments_backup AS  SELECT * FROM meat_poultry_egg_establishments; ```    Listing 10-8: Backing up a table    The result should be a pristine copy of your table with the new specified name. You can confirm this by counting the number of records in both tables at once:    ``` SELECT      (SELECT count(*) FROM meat_poultry_egg_establishments) AS original,      (SELECT count(*) FROM meat_poultry_egg_establishments_backup) AS backup; ```    The results should return the same count from both tables, like this:    ``` original    backup  --------    ------      6287      6287 ```    If the counts match, you can be sure your backup table is an exact copy of the structure and contents of the original table. As an added measure and for easy reference, we’ll use `ALTER TABLE` to make copies of column data within the table we’re updating.    ### Restoring Missing Column Values    The query in Listing 10-4 earlier revealed that three rows in the `meat_poultry_egg_establishments` table don’t have a value in the `st` column:    ``` est_number           company                            city      st    zip  -----------------    -------------------------------    ------    --    -----  V18677A              Atlas Inspection, Inc.             Blaine          55449  M45319+P45319        Hall-Namie Packing Company, Inc                    36671  M263A+P263A+V263A    Jones Dairy Farm                                   53538 ```    To get a complete count of establishments in each state, we need to fill those missing values using an `UPDATE` statement.    #### Creating a Column Copy    Even though we’ve backed up this table, let’s take extra caution and make a copy of the `st` column within the table so we still have the original data if we make some dire error somewhere. Let’s create the copy and fill it with the existing `st` column values as in Listing 10-9.    ``` 1 ALTER TABLE meat_poultry_egg_establishments ADD COLUMN st_copy text;    UPDATE meat_poultry_egg_establishments  2 SET st_copy = st; ```    Listing 10-9: Creating and filling the `st_copy` column with `ALTER TABLE` and `UPDATE`    The `ALTER TABLE` statement 1 adds a column called `st_copy` using the same `text` data type as the original `st` column. Next, the `SET` clause 2 in `UPDATE` fills our new `st_copy` column with the values in column `st`. Because we don’t specify any criteria using `WHERE`, values in every row are updated, and PostgreSQL returns the message `UPDATE 6287`. Again, it’s worth noting that on a very large table, this operation could take some time and also substantially increase the table’s size. Making a column copy in addition to a table backup isn’t entirely necessary, but if you’re the patient, cautious type, it can be worthwhile.    We can confirm the values were copied properly with a simple `SELECT` query on both columns, as in Listing 10-10.    ``` SELECT st,         st_copy  FROM meat_poultry_egg_establishments  WHERE st IS DISTINCT FROM st_copy  ORDER BY st; ```    Listing 10-10: Checking values in the `st` and `st_copy` columns    To check for differences between values in the columns, we use `IS DISTINCT FROM` in the `WHERE` clause. You’ve used `DISTINCT` before to find unique values in a column (Chapter 3); in this context, `IS DISTINCT FROM` tests whether values in `st` and `st_copy` are different. This keeps us from having to scan every row ourselves. Running this query will return zero rows, meaning the values match throughout the table.    Now, with our original data safely stored, we can update the three rows with missing state codes. This is now our in-table backup, so if something goes drastically wrong while we’re updating the original column, we can easily copy the original data back in. I’ll show you how after we apply the first updates.    #### Updating Rows Where Values Are Missing    To update those rows’ missing values, we first find the values we need with a quick online search: Atlas Inspection is located in Minnesota; Hall-Namie Packing is in Alabama; and Jones Dairy is in Wisconsin. We add those states to the appropriate rows in Listing 10-11.    ``` UPDATE meat_poultry_egg_establishments  SET st = 'MN'  1 WHERE establishment_number = 'V18677A';    UPDATE meat_poultry_egg_establishments  SET st = 'AL'  WHERE establishment_number = 'M45319+P45319';    UPDATE meat_poultry_egg_establishments  SET st = 'WI'  WHERE establishment_number = 'M263A+P263A+V263A'  2 RETURNING establishment_number, company, city, st, zip; ```    Listing 10-11: Updating the `st` column for three establishments    Because we want each `UPDATE` statement to affect a single row, we include a `WHERE` clause 1 for each that identifies the company’s unique `establishment_number`, which is the table’s primary key. When we run the first two queries, PostgreSQL responds with the message `UPDATE 1`, showing that only one row was updated for each query. When we run the third, the `RETURNING` clause 2 directs the database to show several columns from the row that was updated:    ``` establishment_number   company           city      st    zip  --------------------   ----------------  --------  --    -----  M263A+P263A+V263A      Jones Dairy Farm            WI    53538 ```    If we rerun the code in Listing 10-4 to find rows where `st` is `NULL`, the query should return nothing. Success! Our count of establishments by state is now complete.    #### Restoring Original Values    What happens if we botch an update by providing the wrong values or updating the wrong rows? We’ll just copy the data back from either the full table backup or the column backup. Listing 10-12 shows the two options.    ``` 1 UPDATE meat_poultry_egg_establishments  SET st = st_copy;    2 UPDATE meat_poultry_egg_establishments original  SET st = backup.st  FROM meat_poultry_egg_establishments_backup backup  WHERE original.establishment_number = backup.establishment_number; ```    Listing 10-12: Restoring original `st` column values    To restore the values from the backup column in `meat_poultry_egg_establishments`, run an `UPDATE` query 1 that sets `st` to the values in `st_copy`. Both columns should again have the identical original values. Alternatively, you can create an `UPDATE` 2 that sets `st` to values in the `st` column from the `meat_poultry_egg_establishments_backup` table you made in Listing 10-8. This will obviate the fixes you made to add missing state values, so if you want to try this query, you’ll need to redo the fixes using Listing 10-11.    ### Updating Values for Consistency    In Listing 10-5, we discovered several cases where a single company’s name was entered inconsistently. These inconsistencies will hinder us if we want to aggregate data by company name, so we’ll fix them.    Here are the spelling variations of Armour-Eckrich Meats in Listing 10-5:    ``` `--snip--`  Armour - Eckrich Meats, LLC  Armour-Eckrich Meats LLC  Armour-Eckrich Meats, Inc.  Armour-Eckrich Meats, LLC  `--snip--` ```    We can standardize the spelling using an `UPDATE` statement. To protect our data, we’ll create a new column for the standardized spellings, copy the names in `company` into the new column, and work in the new column. Listing 10-13 has the code for both actions.    ``` ALTER TABLE meat_poultry_egg_establishments ADD COLUMN company_standard text;    UPDATE meat_poultry_egg_establishments  SET company_standard = company; ```    Listing 10-13: Creating and filling the `company_standard` column    Now, let’s say we want any name in `company` that starts with the string `Armour` to appear in `company_standard` as `Armour-Eckrich Meats`. (This assumes we’ve checked all Armour entries and want to standardize them.) With Listing 10-14, we can update all the rows matching the string `Armour` using `WHERE`.    ``` UPDATE meat_poultry_egg_establishments  SET company_standard = 'Armour-Eckrich Meats'  1 WHERE company LIKE 'Armour%'  2 RETURNING company, company_standard; ```    Listing 10-14: Using an `UPDATE` statement to modify column values that match a string    The important piece of this query is the `WHERE` clause that uses the `LIKE` keyword 1 for case-sensitive pattern matching introduced in Chapter 3. Including the wildcard syntax `%` at the end of the string `Armour` updates all rows that start with those characters regardless of what comes after them. The clause lets us target all the varied spellings used for the company’s name. The `RETURNING` clause 2 causes the statement to provide the results of the updated `company_standard` column next to the original `company` column:    ``` company                        company_standard  ---------------------------    --------------------  Armour-Eckrich Meats LLC       Armour-Eckrich Meats  Armour - Eckrich Meats, LLC    Armour-Eckrich Meats  Armour-Eckrich Meats LLC       Armour-Eckrich Meats  Armour-Eckrich Meats LLC       Armour-Eckrich Meats  Armour-Eckrich Meats, Inc.     Armour-Eckrich Meats  Armour-Eckrich Meats, LLC      Armour-Eckrich Meats  Armour-Eckrich Meats, LLC      Armour-Eckrich Meats ```    The values for Armour-Eckrich in `company_standard` are now standardized with consistent spelling. To standardize other company names in the table, we would create an `UPDATE` statement for each case. We would also keep the original `company` column for reference.    ### Repairing ZIP Codes Using Concatenation    Our final fix repairs values in the `zip` column that lost leading zeros. Zip codes in Puerto Rico and the US Virgin Islands begin with two zeros, so we need to restore two leading zeros to the values in `zip`. For the other states, located mostly in New England, we’ll restore a single leading zero.    We’ll use `UPDATE` in conjunction with the double-pipe *string concatenation operator* (`||`). Concatenation combines two string values into one (it will also combine a string and a number into a string). For example, inserting `||` between the strings `abc` and `xyz` results in `abcxyz`. The double-pipe operator is a SQL standard for concatenation supported by PostgreSQL. You can use it in many contexts, such as `UPDATE` queries and `SELECT`, to provide custom output from existing as well as new data.    First, Listing 10-15 makes a backup copy of the `zip` column as we did earlier.    ``` ALTER TABLE meat_poultry_egg_establishments ADD COLUMN zip_copy text;    UPDATE meat_poultry_egg_establishments  SET zip_copy = zip; ```    Listing 10-15: Creating and filling the `zip_copy` column    Next, we use the code in Listing 10-16 to perform the first update.    ``` UPDATE meat_poultry_egg_establishments  1 SET zip = '00' || zip  2 WHERE st IN('PR','VI') AND length(zip) = 3; ```    Listing 10-16: Modifying codes in the `zip` column missing two leading zeros    We use `SET` to set the value in the `zip` column 1 to the result of the concatenation of `00` and the existing value. We limit the `UPDATE` to only those rows where the `st` column has the state codes `PR` and `VI` 2 using the `IN` comparison operator from Chapter 3 and add a test for rows where the length of `zip` is `3`. This entire statement will then only update the `zip` values for Puerto Rico and the Virgin Islands. Run the query; PostgreSQL should return the message `UPDATE 86`, which is the number of rows we expect to change based on our earlier count in Listing 10-6.    Let’s repair the remaining ZIP codes using a similar query in Listing 10-17.    ``` UPDATE meat_poultry_egg_establishments  SET zip = '0' || zip  WHERE st IN('CT','MA','ME','NH','NJ','RI','VT') AND length(zip) = 4; ```    Listing 10-17: Modifying codes in the `zip` column missing one leading zero    PostgreSQL should return the message `UPDATE 496`. Now, let’s check our progress. Earlier in Listing 10-6, when we aggregated rows in the `zip` column by length, we found `86` rows with three characters and `496` with four.    Using the same query now returns a more desirable result: all the rows have a five-digit ZIP code.    ``` length    count  ------    -----       5     6287 ```    I’ll discuss additional string functions in Chapter 14 when we consider advanced techniques for working with text.    ### Updating Values Across Tables    In “Modifying Values with UPDATE” earlier in the chapter, I showed the standard ANSI SQL and PostgreSQL-specific syntax for updating values in one table based on values in another. This syntax is particularly valuable in a relational database where primary keys and foreign keys establish table relationships. In those cases, we may need information in one table to update values in another table.    Let’s say we’re setting an inspection deadline for each of the companies in our table. We want to do this by US regions, such as Northeast, Pacific, and so on, but those regional designations don’t exist in our table. However, they *do* exist in the file *state_regions.csv*, included with the book’s resources, that contains matching `st` state codes. Once we load that file into a table, we can use that data in an `UPDATE` statement. Let’s begin with the New England region to see how this works.    Enter the code in Listing 10-18, which contains the SQL statements to create a `state_regions` table and fill the table with data:    ``` CREATE TABLE state_regions (      st text CONSTRAINT st_key PRIMARY KEY,      region text NOT NULL  );    COPY state_regions  FROM '`C:\YourDirectory\`state_regions.csv'  WITH (FORMAT CSV, HEADER); ```    Listing 10-18: Creating and filling a `state_regions` table    We’ll create two columns in a `state_regions` table: one containing the two-character state code `st` and the other containing the `region` name. We set the primary key constraint to the `st` column, which holds a unique `st_key` value to identify each state. In the data you’re importing, each state is present and assigned to a census region, and territories outside the United States are labeled as outlying areas. We’ll update the table one region at a time.    Next, let’s return to the `meat_poultry_egg_establishments` table, add a column for inspection dates, and then fill in that column with the New England states. Listing 10-19 shows the code.    ``` ALTER TABLE meat_poultry_egg_establishments      ADD COLUMN inspection_deadline timestamp with time zone;    1 UPDATE meat_poultry_egg_establishments establishments  2 SET inspection_deadline = '2022-12-01 00:00 EST'  3 WHERE EXISTS (SELECT state_regions.region                FROM state_regions                WHERE establishments.st = state_regions.st                      AND state_regions.region = 'New England'); ```    Listing 10-19: Adding and updating an `inspection_deadline` column    The `ALTER TABLE` statement creates the `inspection_deadline` column in the `meat_poultry_egg_establishments` table. In the `UPDATE` statement, we give the table an alias of `establishments` to make the code easier to read 1 (and do so omitting the optional `AS` keyword). Next, `SET` assigns a timestamp value of `2022-12-01 00:00 EST` to the new `inspection_deadline` column 2. Finally, `WHERE EXISTS` includes a subquery that connects the `meat_poultry_egg_establishments` table to the `state_regions` table we created in Listing 10-18 and specifies which rows to update 3. The subquery (in parentheses, beginning with `SELECT`) looks for rows in the `state_regions` table where the `region` column matches the string `New England`. At the same time, it joins the `meat_poultry_egg_establishments` table with the `state_regions` table using the `st` column from both tables. In effect, the query is telling the database to find all the `st` codes that correspond to the New England region and use those codes to filter the update.    When you run the code, you should receive a message of `UPDATE 252`, which is the number of companies in New England states. You can use the code in Listing 10-20 to see the effect of the change.    ``` SELECT st, inspection_deadline  FROM meat_poultry_egg_establishments  GROUP BY st, inspection_deadline  ORDER BY st; ```    Listing 10-20: Viewing updated `inspection_date` values    The results should show the updated inspection deadlines for all New England companies. The top of the output shows Connecticut has received a deadline timestamp, for example, but states outside New England remain `NULL` because we haven’t updated them yet:    ``` st    inspection_deadline  --    ---------------------  `--snip--`  CA  CO  CT    2022-12-01 00:00:00-05  DC  `--snip--` ```    To fill in deadlines for additional regions, substitute a different region for `New England` in Listing 10-19 and rerun the query.    ## Deleting Unneeded Data    The most irrevocable way to modify data is to remove it entirely. SQL includes options to remove rows and columns along with options to delete an entire table or database. We want to perform these operations with caution, removing only data or tables we don’t need. Without a backup, your data is gone for good.    In this section, we’ll use a variety of SQL statements to delete data. If you didn’t back up the `meat_poultry_egg_establishments` table using Listing 10-8, now is a good time to do so.    Writing and executing these statements is fairly simple, but doing so comes with a caveat. If deleting rows, a column, or a table would cause a violation of a constraint, such as the foreign key constraint covered in Chapter 8, you need to deal with that constraint first. That might involve removing the constraint, deleting data in another table, or deleting another table. Each case is unique and will require a different way to work around the constraint.    ### Deleting Rows from a Table    To remove rows from a table, we can use either `DELETE FROM` or `TRUNCATE`, which are both part of the ANSI SQL standard. Each offers options that are useful depending on your goals.    Using `DELETE FROM`, we can remove all rows from a table, or we can add a `WHERE` clause to delete only the portion that matches an expression we supply. To delete all rows from a table, use the following syntax:    ``` DELETE FROM `table_name`; ```    To remove only selected rows, add a `WHERE` clause along with the matching value or pattern to specify which ones you want to delete:    ``` DELETE FROM `table_name` WHERE `expression`; ```    For example, to exclude US territories from our processors table, we can remove the companies in those locations using the code in Listing 10-21.    ``` DELETE FROM meat_poultry_egg_establishments  WHERE st IN('AS','GU','MP','PR','VI'); ```    Listing 10-21: Deleting rows matching an expression    Run the code; PostgreSQL should return the message `DELETE 105`. This means the 105 rows where the `st` column held any of the codes designating a territory that you supplied via the `IN` keyword have been removed from the table.    With large tables, using `DELETE FROM` to remove all rows can be inefficient because it scans the entire table as part of the process. In that case, you can use `TRUNCATE`, which skips the scan. To empty the table using `TRUNCATE`, use the following syntax:    ``` TRUNCATE `table_name`; ```    A handy feature of `TRUNCATE` is the ability to reset an `IDENTITY` sequence, such as one you may have created to serve as a surrogate primary key, as part of the operation. To do that, add the `RESTART IDENTITY` keywords to the statement:    ``` TRUNCATE `table_name` RESTART IDENTITY; ```    We’ll skip truncating any tables for now as we need the data for the rest of the chapter.    ### Deleting a Column from a Table    Earlier we created a backup `zip` column called `zip_copy`. Now that we’ve finished working on fixing the issues in `zip`, we no longer need `zip_copy`. We can remove the backup column, including all the data within the column, from the table using the `DROP` keyword in the `ALTER TABLE` statement.    The syntax for removing a column is similar to other `ALTER TABLE` statements:    ``` ALTER TABLE `table_name` DROP COLUMN `column_name`; ```    The code in Listing 10-22 removes the `zip_copy` column:    ``` ALTER TABLE meat_poultry_egg_establishments DROP COLUMN zip_copy; ```    Listing 10-22: Removing a column from a table using `DROP`    PostgreSQL returns the message `ALTER TABLE`, and the `zip_copy` column should be deleted. The database doesn’t actually rewrite the table to remove the column; it just marks the column as deleted in its internal catalog and no longer shows it or adds data to it when new rows are added.    ### Deleting a Table from a Database    The `DROP TABLE` statement is a standard ANSI SQL feature that deletes a table from the database. This statement might come in handy if, for example, you have a collection of backups, or *working tables*, that have outlived their usefulness. It’s also useful when you need to change the structure of a table significantly; in that case, rather than using too many `ALTER TABLE` statements, you can just remove the table and create a fresh one by running a new `CREATE TABLE` statement and re-importing the data.    The syntax for the `DROP TABLE` command is simple:    ``` DROP TABLE `table_name`; ```    For example, Listing 10-23 deletes the backup version of the `meat_poultry_egg_establishments` table.    ``` DROP TABLE meat_poultry_egg_establishments_backup; ```    Listing 10-23: Removing a table from a database using `DROP`    Run the query; PostgreSQL should respond with the message `DROP TABLE` to indicate the table has been removed.    ## Using Transactions to Save or Revert Changes    So far, our alterations in this chapter have been final. That is, after you run a `DELETE` or `UPDATE` query (or any other query that alters your data or database structure), the only way to undo the change is to restore from a backup. However, there is a way to check your changes before finalizing them and cancel the change if it’s not what you intended. You do this by enclosing the SQL statement within a *transaction*, which includes keywords that allow you to commit your changes if they are successful or roll them back if not. You define a transaction using the following keywords at the beginning and end of the query:    1.  `START TRANSACTION` Signals the start of the transaction block. In PostgreSQL, you can also use the non-ANSI SQL `BEGIN` keyword. 2.  `COMMIT` Signals the end of the block and saves all changes. 3.  `ROLLBACK` Signals the end of the block and reverts all changes.    You can include multiple statements between `BEGIN` and `COMMIT` to define a sequence of operations that perform one unit of work in a database. An example is when you buy concert tickets, which might involve two steps: charging your credit card and reserving your seats so someone else can’t buy them. A database programmer would want either both steps in the transaction to happen (say, when your card charge goes through) or neither to happen (if you cancel at checkout). Defining both steps as one transaction—also called a *transaction block*—keeps them as a unit; if one step is canceled or throws an error, the other gets canceled too. You can learn more details about transactions and PostgreSQL at [`www.postgresql.org/docs/current/tutorial-transactions.html`](https://www.postgresql.org/docs/current/tutorial-transactions.html).    We can use a transaction block to review changes a query makes and then decide whether to keep or discard them. In our table, let’s say we’re cleaning dirty data related to the company AGRO Merchants Oakland LLC. The table has three rows listing the company, but one row has an extra comma in the name:    ``` Company  ---------------------------  AGRO Merchants Oakland LLC  AGRO Merchants Oakland LLC  AGRO Merchants Oakland, LLC ```    We want the name to be consistent, so we’ll remove the comma from the third row using an `UPDATE` query, as we did earlier. But this time we’ll check the result of our update before we make it final (and we’ll purposely make a mistake we want to discard). Listing 10-24 shows how to do this using a transaction block.    ``` 1 START TRANSACTION;    UPDATE meat_poultry_egg_establishments  2 SET company = 'AGRO Merchantss Oakland LLC'  WHERE company = 'AGRO Merchants Oakland, LLC';    3 SELECT company  FROM meat_poultry_egg_establishments  WHERE company LIKE 'AGRO%'  ORDER BY company;    4 ROLLBACK; ```    Listing 10-24: Demonstrating a transaction block    Beginning with `START TRANSACTION;` 1, we’ll run each statement separately. The database responds with the message `START TRANSACTION`, letting you know that any succeeding changes you make to data will not be made permanent unless you issue a `COMMIT` command. Next, we run the `UPDATE` statement, which changes the company name in the row where it has an extra comma. I intentionally added an extra `s` in the name used in the `SET` clause 2 to introduce a mistake.    When we view the names of companies starting with the letters `AGRO` using the `SELECT` statement 3, we see that, oops, one company name is misspelled now.    ``` Company  ---------------------------  AGRO Merchants Oakland LLC  AGRO Merchants Oakland LLC  AGRO Merchantss Oakland LLC ```    Instead of rerunning the `UPDATE` statement to fix the typo, we can simply discard the change by running the `ROLLBACK;` 4 command. When we rerun the `SELECT` statement to view the company names, we’re back to where we started:    ``` Company  ---------------------------  AGRO Merchants Oakland LLC  AGRO Merchants Oakland LLC  AGRO Merchants Oakland, LLC ```    From here, you correct your `UPDATE` statement by removing the extra `s` and rerun it, beginning with the `START TRANSACTION` statement again. If you’re happy with the changes, run `COMMIT;` to make them permanent.    Transaction blocks are often used for more complex situations rather than checking simple changes. Here you’ve used them to test whether a query behaves as desired, saving you time and headaches. Next, let’s look at another way to save time when updating lots of data.    ## Improving Performance When Updating Large Tables    With PostgreSQL, adding a column to a table and filling it with values can quickly inflate the table’s size because the database creates a new version of the existing row each time a value is updated, but it doesn’t delete the old row version. That essentially doubles the table’s size. (You’ll learn how to clean up these old rows when I discuss database maintenance in “Recovering Unused Space with VACUUM” in Chapter 19.) For small datasets, the increase is negligible, but for tables with hundreds of thousands or millions of rows, the time required to update rows and the resulting extra disk usage can be substantial.    Instead of adding a column and filling it with values, we can save disk space by copying the entire table and adding a populated column during the operation. Then, we rename the tables so the copy replaces the original, and the original becomes a backup. Thus, we have a fresh table without the added old rows.    Listing 10-25 shows how to copy `meat_poultry_egg_establishments` into a new table while adding a populated column. To do this, if you didn’t already drop the `meat_poultry_egg_establishments_backup` table as shown in Listing 10-23, go ahead and drop it. Then run the `CREATE TABLE` statement.    ``` CREATE TABLE meat_poultry_egg_establishments_backup AS  1 SELECT *,        2 '2023-02-14 00:00 EST'::timestamp with time zone AS reviewed_date  FROM meat_poultry_egg_establishments; ```    Listing 10-25: Backing up a table while adding and filling a new column    The query is a modified version of the backup script in Listing 10-8. Here, in addition to selecting all the columns using the asterisk wildcard 1, we also add a column called `reviewed_date` by providing a value cast as a `timestamp` data type 2 and the `AS` keyword. That syntax adds and fills `reviewed_date`, which we might use to track the last time we checked the status of each plant.    Then we use Listing 10-26 to swap the table names.    ``` 1 ALTER TABLE meat_poultry_egg_establishments      RENAME TO meat_poultry_egg_establishments_temp;  2 ALTER TABLE meat_poultry_egg_establishments_backup      RENAME TO meat_poultry_egg_establishments;  3 ALTER TABLE meat_poultry_egg_establishments_temp      RENAME TO meat_poultry_egg_establishments_backup; ```    Listing 10-26: Swapping table names using `ALTER TABLE`    Here we use `ALTER TABLE` with a `RENAME TO` clause to change a table name. The first statement changes the original table name to one that ends with `_temp` 1. The second statement renames the copy we made with Listing 10-24 to the original name of the table 2. Finally, we rename the table that ends with `_temp` to the ending `_backup` 3. The original table is now called `meat_poultry_egg_establishments_backup`, and the copy with the added column is called `meat_poultry_egg_establishments`. This process avoids updating rows and thus inflating the table.    ## Wrapping Up    Gleaning useful information from data sometimes requires modifying the data to remove inconsistencies, fix errors, and make it more suitable for supporting an accurate analysis. In this chapter you learned some useful tools to help you assess dirty data and clean it up. In a perfect world, all datasets would arrive with everything clean and complete. But such a perfect world doesn’t exist, so the ability to alter, update, and delete data is indispensable.    Let me restate the important tasks of working safely. Be sure to back up your tables before you start making changes. Make copies of your columns, too, for an extra level of protection. When I discuss database maintenance for PostgreSQL later in the book, you’ll learn how to back up entire databases. These few steps of precaution will save you a world of pain.    In the next chapter, we’ll return to math to explore some of SQL’s advanced statistical functions and techniques for analysis.````
