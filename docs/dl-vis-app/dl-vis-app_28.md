# 第二十四章：参考文献

在可能的情况下，我倾向于使用在线可访问的参考文献，这样你可以立即访问它们。例外情况通常是书籍和其他印刷材料，但偶尔我也会包括一些重要的在线参考文献，即使它们被放置在付费墙后面。这里的每个链接在写作时都是有效的。但互联网是瞬息万变的，这些链接肯定会发生变化，或者干脆停止工作。如果你发现某个链接无法访问，我建议你使用搜索引擎查找你想要定位的参考文献的标题和/或作者。通常你会发现，它可能只是搬到了新位置。如果它已消失，你可以尝试在[`archive.org/web/`](https://archive.org/web/)的 Wayback Machine 上找到保存的副本。你还可以尝试使用 Google 搜索引擎查找该参考文献，它有时会提供一个已不再在线的页面的缓存版本。

如果你是以电子书的形式阅读本书，你可以直接点击任何链接以访问。如果你是纸质版阅读，可以将这些链接输入你最喜欢的浏览器，但更好的方法是前往 No Starch Press 网站上该章节的在线版本，那里链接是有效的：[`nostarch.com/deep-learning-visual-approach/`](https://nostarch.com/deep-learning-visual-approach/)。

## 第一章

Bishop, Christopher M. 2006\. *模式识别与机器学习*。纽约：Springer-Verlag 出版社。可在[`docs.google.com/viewer?a=v&pid=sites&srcid=aWFtYW5kaS5ldXxpc2N8Z3g6MjViZDk1NGI1NjQzOWZiYQ`](https://docs.google.com/viewer?a=v&pid=sites&srcid=aWFtYW5kaS5ldXxpc2N8Z3g6MjViZDk1NGI1NjQzOWZiYQ)获取。

Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2017\. *深度学习*。剑桥，MA：MIT 出版社。可在[`www.deeplearningbook.org/`](https://www.deeplearningbook.org/)获取。

Saba, Luca, Mainak Biswas, Venkatanareshbabu Kuppili, Elisa Cuadrado Godia, Harman S. Suri, Damodar Reddy Edla, Tomaž Omerzu, John R. Laird, Narendra N. Khanna, Sophie Mavrogeni 等. 2019\. “深度学习在放射学中的现状与未来。” *欧洲放射学杂志* 114（5 月）：14-24。

## 第二章

Anscombe, F. J. 1973\. “统计分析中的图形。” *美国统计学家* 27，第一期（2 月）：17-21。

Banchoff, Thomas F. 1990\. *超越第三维：几何学、计算机图形学与高维空间*。科学美国人图书系列。纽约：W. H. Freeman 出版社。

Brownlee, Jason. 2017\. “如何在 Python 中计算机器学习结果的 Bootstrap 置信区间。” *机器学习精通*（博客）。最后更新于 2020 年 8 月 14 日。[`machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/`](https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/)

Efron, Bradley, 和 Robert J. Tibshirani. 1993\. *引导法介绍*。佛罗里达州博卡拉顿：Chapman and Hall/CRC，Taylor and Francis 集团。

Matejka, Justin, 和 George Fitzmaurice. 2017. “相同统计，不同图表：通过模拟退火生成外观不同但统计相同的数据集。” 收录于 *2017 年 CHI 计算机系统中的人类因素会议论文集*（丹佛，CO，5 月 6–11 日）：1290–94。 [`www.autodesk.com/research/publications/same-stats-different-graphs`](https://www.autodesk.com/research/publications/same-stats-different-graphs).

Norton, John D. 2014. “四维空间是什么样的？” 讲义。匹兹堡大学历史与哲学科学系。 [`www.pitt.edu/~jdnorton/teaching/HPS_0410/chapters/four_dimensions/index.html`](https://www.pitt.edu/~jdnorton/teaching/HPS_0410/chapters/four_dimensions/index.html).

Teknomo, Kardi. 2015. “自助法抽样教程。” Revoledu. [`people.revoledu.com/kardi/tutorial/Bootstrap/index.html`](https://people.revoledu.com/kardi/tutorial/Bootstrap/index.html).

ten Bosch, Marc. 2020. “*N*维刚体动力学。” *ACM 图形学期刊* 39, 第 4 期（7 月）。 [`marctenbosch.com/ndphysics/NDrigidbody.pdf`](https://marctenbosch.com/ndphysics/NDrigidbody.pdf).

Wikipedia. 2017a. “安斯科姆四重奏。” 最后修改于 2020 年 6 月 21 日。 [`en.wikipedia.org/wiki/Anscombe%27s_quartet`](https://en.wikipedia.org/wiki/Anscombe%27s_quartet).

Wikipedia. 2017b. “随机变量。” 最后修改于 2020 年 8 月 21 日。 [`en.wikipedia.org/wiki/Random_variable`](https://en.wikipedia.org/wiki/Random_variable).

## 第三章

Glen, Stephanie. 2014. “边际分布。” Statisticshowto.com. 2014 年 2 月 6 日。 [`www.statisticshowto.com/marginal-distribution/`](http://www.statisticshowto.com/marginal-distribution/).

Jaynes, Edwin Thompson. 2003. *概率论：科学的逻辑*。剑桥，英国：剑桥大学出版社。

Kirby, Roger. 2011. *小腺体，大问题*。伦敦，英国：Health Press。

Kunin, Daniel, Jingru Guo, Tyler Dae Devlin, 和 Daniel Xiang. 2020. “理论可视化。” Seeing Theory. 访问于 2020 年 9 月 16 日。 [`seeing-theory.brown.edu/#firstPage`](https://seeing-theory.brown.edu/#firstPage).

Levitin, Daniel J. 2016. *谎言指南：信息时代的批判性思维*。纽约：Viking Press。

Walpole, Ronald E., Raymond H. Myers, Sharon L. Myers, 和 Keying E. Ye. 2011. *工程与科学家的概率与统计学*，第 9 版。纽约：Pearson。

Wikipedia. 2020. “灵敏度与特异性。” 最后更新于 2020 年 10 月 20 日。 [`en.wikipedia.org/wiki/Sensitivity_and_specificity`](https://en.wikipedia.org/wiki/Sensitivity_and_specificity).

## 第四章

Cthaeh, The. 2016a. “贝叶斯定理：非正式推导。” *概率世界*。2016 年 2 月 28 日。 [`www.probabilisticworld.com/anatomy-bayes-theorem/`](http://www.probabilisticworld.com/anatomy-bayes-theorem/).

Cthaeh, The. 2016 年 b. “通过贝叶斯定理计算硬币偏差。” *概率世界*。2016 年 3 月 21 日. [`www.probabilisticworld.com/calculating-coin-bias-bayes-theorem/`](http://www.probabilisticworld.com/calculating-coin-bias-bayes-theorem/).

Genovese, Christopher R. 2004 年. “贝叶斯分析教程（神经成像领域）。” 论文发表于加利福尼亚大学洛杉矶分校纯数学与应用数学研究所会议，2004 年 7 月 20 日. [`www.stat.cmu.edu/~genovese/talks/ipam-04.pdf`](http://www.stat.cmu.edu/~genovese/talks/ipam-04.pdf).

Kruschke, John K. 2014 年. *做贝叶斯数据分析：使用 R、JAGS 和 Stan 的教程*，第 2 版. 剑桥，马萨诸塞州：学术出版社.

Stark, P. B. 和 D. A. Freedman. 2016 年. “地震发生的概率是多少？” 加州大学伯克利分校统计系，技术报告 611，2016 年 10 月. [`www.stat.berkeley.edu/~stark/Preprints/611.pdf`](https://www.stat.berkeley.edu/~stark/Preprints/611.pdf).

VanderPlas, Jake. 2014 年. “频率主义与贝叶斯主义：一个基于 Python 的入门教程。” 康奈尔大学，天体物理学，arXiv:1411.5018，2014 年 11 月 18 日. [`arxiv.org/abs/1411.5018`](https://arxiv.org/abs/1411.5018).

## 第五章

3Blue1Brown. 2020 年. 3Blue1Brown 主页. 访问日期：2020 年 9 月 1 日. [`www.3blue1brown.com`](https://www.3blue1brown.com).

Apostol, Tom M. 1991 年. *微积分，第 1 卷：单变量微积分及线性代数导论*，第 2 版. 纽约：Wiley.

Berkey, Dennis D. 和 Paul Blanchard. 1992 年. *微积分*。波士顿：霍顿·米夫林·哈考特学校.

## 第六章

Bellizzi, Courtney. 2011 年. “被遗忘的历史：阿尔弗雷德·维尔与塞缪尔·莫尔斯。” 史密森学会档案馆. 2011 年 5 月 24 日. [`siarchives.si.edu/blog/forgotten-history-alfred-vail-and-samuel-morse`](http://siarchives.si.edu/blog/forgotten-history-alfred-vail-and-samuel-morse).

Ferrier, Andrew. 2020 年. “生成哈夫曼树的快速教程。” *Andrew Ferrier*（教程）。访问日期：2020 年 11 月 12 日. [`www.andrewferrier.com/oldpages/huffman_tutorial.html`](https://www.andrewferrier.com/oldpages/huffman_tutorial.html).

Huffman, David A. 1952 年. “最小冗余编码构建方法。” 收录于*IRE 会议录* 40 卷，第 9 期. [`web.stanford.edu/class/ee398a/handouts/papers/Huffman%20-%20Min%20Redundancy%20Codes%20-%20IRE52.pdf`](https://web.stanford.edu/class/ee398a/handouts/papers/Huffman%20-%20Min%20Redundancy%20Codes%20-%20IRE52.pdf).

Kurt, Will. 2017 年. “Kullback-Leibler 散度解释。” *Probably a Probability*（博客），Count Bayesie. 2017 年 5 月 10 日. [`www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained`](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained).

Longden, George. 1987 年. “G3ZQS 对 FISTS 名字由来的解释。” FISTS CW 俱乐部. 访问日期：2020 年 9 月 1 日. [`fists.co.uk/g3zqsintroduction.html`](https://fists.co.uk/g3zqsintroduction.html).

McEwen, Neal. 1997\. “摩尔斯电码还是维尔电码？”电报办公室。[`www.telegraph-office.com/pages/vail.html`](http://www.telegraph-office.com/pages/vail.html)。

Pope, Alfred. 1887\. “电报的美国发明者，特别提到阿尔弗雷德·维尔的贡献。” *世纪插图月刊* 35, no. 1 (十一月)。[`tinyurl.com/jobhn2b`](http://tinyurl.com/jobhn2b)。

Serrano, Luis. 2017\. “香农熵、信息增益和从桶中挑球。” *Medium*。2017 年 11 月 5 日。[`medium.com/udacity/shannon-entropy-information-gain-and-picking-balls-from-buckets-5810d35d54b4`](https://medium.com/udacity/shannon-entropy-information-gain-and-picking-balls-from-buckets-5810d35d54b4)。

Seuss, Dr. 1960\. *绿鸡蛋与火腿*。初学者图书。

Shannon, Claude E. 1948\. “通信的数学理论。” *贝尔实验室技术期刊*（七月）。[`people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf`](http://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf)。

Stevenson, Robert Louis. 1883\. *金银岛*。古腾堡计划。可在[`www.gutenberg.org/ebooks/120`](https://www.gutenberg.org/ebooks/120)查阅。

Thomas, Andrew. 2017\. “机器学习中的熵、交叉熵和 KL 散度简介。” *机器学习历险*（博客）。2017 年 3 月 29 日。

Twain, Mark. 1885\. *哈克贝里·费恩历险记（汤姆·索亚的同伴）*。查尔斯·L·韦伯斯特公司。可在[`www.gutenberg.org/ebooks/32325`](https://www.gutenberg.org/ebooks/32325)查阅。

Wikipedia. 2020\. “字母频率。”维基百科。最后修改日期：2020 年 8 月 31 日。[`en.wikipedia.org/wiki/Letter_frequency`](https://en.wikipedia.org/wiki/Letter_frequency)。

## 第七章

Aggarwal, Charu C., Alexander Hinneburg, 和 Daniel A. Keim. 2001\. “高维空间中距离度量的惊人表现。” 论文发表于 2001 年 1 月 4 日至 6 日在英国伦敦举行的国际数据库理论会议。[`bib.dbvis.de/uploadedFiles/155.pdf`](https://bib.dbvis.de/uploadedFiles/155.pdf)。

Arcuri, Lauren. 2019\. “如何照蛋。” *The Spruce*（博客）。2019 年 4 月 20 日。[`www.thespruce.com/definition-of-candling-3016955`](https://www.thespruce.com/definition-of-candling-3016955)。

Bellman, Richard Ernest. 1957\. *动态规划*。普林斯顿，NJ：普林斯顿大学出版社。

Domingos, Pedro. 2012\. “关于机器学习的一些有用知识。” *ACM 通讯* 55, no. 10（十月）。[`homes.cs.washington.edu/~pedrod/papers/cacm12.pdf`](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)。

Hughes, G. F. 1968\. “统计模式识别器的平均准确性。” *IEEE 信息理论学报* 14, no. 1: 55–63。

Nebraska Extension. 2017\. “照蛋法。”内布拉斯加州兰开斯特县内布拉斯加大学扩展中心。[`lancaster.unl.edu/4h/embryology/candling`](http://lancaster.unl.edu/4h/embryology/candling)。

Numberphile. 2017 年。“高维中的奇异球体。”YouTube。2017 年 9 月 18 日。[`www.youtube.com/watch?v=mceaM2_zQd8`](https://www.youtube.com/watch?v=mceaM2_zQd8)。

Spruyt, Vincent. 2014 年。“维度灾难。”*《傻瓜计算机视觉》*（博客）。2014 年 4 月 16 日。[`www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/`](http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/)。

## 第八章

Muehlhauser, Luke. 2011 年。“机器学习与意外后果。”*LessWrong*（博客）。2011 年 9 月 22 日。[`lesswrong.com/lw/7qz/machine_learning_and_unintended_consequences/`](http://lesswrong.com/lw/7qz/machine_learning_and_unintended_consequences/)。

Schneider, Jeff，和 Andrew W. Moore。1997 年。“交叉验证。”收录于*使用 Vizier 1.0 的局部加权学习教程*。卡内基梅隆大学计算机科学系，美国宾夕法尼亚州，1997 年 2 月 1 日。[`www.cs.cmu.edu/~schneide/tut5/node42.html`](https://www.cs.cmu.edu/~schneide/tut5/node42.html)。

## 第九章

Bishop, Christopher M. 2006 年。*《模式识别与机器学习》*。纽约：施普林格出版社。

Bullinaria, John A. 2015 年。“偏差与方差，欠拟合与过拟合。”*神经计算，第 9 讲*（讲义），伯明翰大学，英国。[`www.cs.bham.ac.uk/~jxb/INC/l9.pdf`](http://www.cs.bham.ac.uk/~jxb/INC/l9.pdf)。

Domke, Justin. 2008 年。“正则化为什么有效？”*Justin Domke 的博客*（博客）。2008 年 12 月 12 日。[`justindomke.wordpress.com/2008/12/12/why-does-regularization-work/`](https://justindomke.wordpress.com/2008/12/12/why-does-regularization-work/)。

Domingos, Pedro. 2015 年。*《大师算法》*。纽约：基础书籍。

Foer, Joshua. 2012 年。*《与爱因斯坦一起月球漫步：记忆的艺术与科学》*。纽约：企鹅书籍。

Macskassy, Sofus A. 2008 年。“机器学习（CS 567）笔记。”（PowerPoint 演示文稿，偏差-方差。2008 年秋季）[`www-scf.usc.edu/~csci567/17-18-bias-variance.pdf`](http://www-scf.usc.edu/~csci567/17-18-bias-variance.pdf)。

Proctor, Philip，和 Peter Bergman。1978 年。“脑力激荡记忆学校，”收录于*《给我们一个休息》*，水星唱片。[`www.youtube.com/watch?v=PD2Uh_TJ9X0`](https://www.youtube.com/watch?v=PD2Uh_TJ9X0)。

## 第十章

美国疾病控制与预防中心。2020 年。“体质指数（BMI）。”CDC.gov。2020 年 6 月 30 日。[`www.cdc.gov/healthyweight/assessing/bmi/`](https://www.cdc.gov/healthyweight/assessing/bmi/)。

Crayola. 2020 年。“1903 年 Crayola 蜡笔盒中的原始八种（8）颜色是什么？”访问时间：2020 年 9 月 10 日。[`www.crayola.com/faq/your-history/what-were-the-original-eight-8-colors-in-the-1903-box-of-crayola-crayons/`](http://www.crayola.com/faq/your-history/what-were-the-original-eight-8-colors-in-the-1903-box-of-crayola-crayons/)。

Turk, Matthew, 和 Alex Pentland. 1991\. “用于识别的特征脸.” *认知神经科学学报* 3, 第 1 期\. [`www.face-rec.org/algorithms/pca/jcn.pdf`](http://www.face-rec.org/algorithms/pca/jcn.pdf).

## 第十一章

Bishop, Christopher M. 2006\. *模式识别与机器学习*. 纽约: 斯普林格.

Raschka, Sebastian. 2015\. *Python 机器学习*. 伯明翰, 英国: Packt 出版社.

Steinwart, Ingo, 和 Andreas Christmann. 2008\. *支持向量机*. 纽约: 斯普林格.

VanderPlas, Jake. 2016\. *Python 数据科学手册*. 塞巴斯托波尔, CA: O'Reilly 出版社.

## 第十二章

Bonab, Hamed, R., 和 Fazli Can. 2016\. “在线集成学习中理想分类器数量的理论框架.” 收录于 *2016 年第 25 届 ACM 国际信息与知识管理会议（CIKM）论文集*（2016 年 10 月）: 2053–56.

Ceruzzi, Paul. 2015\. “阿波罗制导计算机与首批硅芯片.” 史密森国家航空航天博物馆, 2015 年 10 月 14 日\. [`airandspace.si.edu/stories/editorial/apollo-guidance-computer-and-first-silicon-chips`](https://airandspace.si.edu/stories/editorial/apollo-guidance-computer-and-first-silicon-chips).

Freund, Y., 和 R. E. Schapire. 1997\. “在线学习的决策理论推广及其在 Boosting 中的应用.” *计算机与系统科学学报* 55 (1): 119–39\.

Fumera, Giorgio, Roli Fabio, 和 Serrau Alessandra. 2008\. “将 Bagging 视为分类器的线性组合的理论分析.” *IEEE 模式分析与机器智能学报* 30, 第 7 期: 1293–99.

Kak, Avinash. 2017\. “决策树：如何构建决策树以及如何利用它们进行新数据分类.” 普渡大学 RVL 教程讲座, 2017 年 8 月 28 日\. [`engineering.purdue.edu/kak/Tutorials/DecisionTreeClassifiers.pdf`](https://engineering.purdue.edu/kak/Tutorials/DecisionTreeClassifiers.pdf).

RangeVoting.org. 2020\. “与投票相关术语词汇表.” 访问于 2020 年 9 月 16 日\. [`rangevoting.org/Glossary.html`](http://rangevoting.org/Glossary.html).

Schapire, Robert E., 和 Yoav Freund. 2012\. *Boosting 基础与算法*. 剑桥, MA: MIT 出版社.

Schapire, Robert E. 2013\. “解释 Adaboost.” 收录于 *经验推断：献给弗拉基米尔·N·瓦普尼克的庆典论文集*. 柏林, 德国: Springer-Verlag. 可在 [`rob.schapire.net/papers/explaining-adaboost.pdf`](http://rob.schapire.net/papers/explaining-adaboost.pdf) 查阅.

## 第十三章

Clevert, Djork-Arné, Thomas Unterthiner, 和 Sepp Hochreiter. 2016\. “通过指数线性单元（ELUs）实现快速且准确的深度网络学习.” 康奈尔大学, 计算机科学, arXiv:1511.07289, 2016 年 2 月 22 日\. [`arxiv.org/abs/1511.07289`](https://arxiv.org/abs/1511.07289).

Estebon, Michele D. 1997\. “感知器：一种联想学习网络，”弗吉尼亚理工大学。 [`ei.cs.vt.edu/~history/Perceptrons.Estebon.html`](http://ei.cs.vt.edu/~history/Perceptrons.Estebon.html).

Furber, Steve. 2012\. “低功耗芯片模拟十亿神经元。” *IEEE Spectrum*（7 月 31 日）。[`spectrum.ieee.org/computing/hardware/lowpower-chips-to-model-a-billion-neurons`](http://spectrum.ieee.org/computing/hardware/lowpower-chips-to-model-a-billion-neurons).

Glorot, Xavier, 和 Yoshua Bengio. 2010\. “理解训练深度前馈神经网络的难度，”发表于 *第 13 届国际人工智能与统计会议论文集（AISTATS 2010）*（意大利萨丁岛基亚拉拉古纳度假村）：249–56\. [`jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf`](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf).

Goldberg, Joseph. 2015\. “不同抗抑郁药的作用机制。”WebMD 医学参考（8 月）。[`www.webmd.com/depression/how-different-antidepressants-work`](http://www.webmd.com/depression/how-different-antidepressants-work).

Goodfellow, Ian J., David Warde-Farley, Mehdi Mirza, Aaron Courville, 和 Yoshua Bengio. 2013\. “Maxout 网络。”发表于 *第 30 届国际机器学习大会论文集（PMLR）* 28 卷，第 3 期：1319–27\. [`jmlr.org/proceedings/papers/v28/goodfellow13.pdf`](http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf).

He, Kaiming, Xiangyu Zhang, Shaoqing Ren, 和 Jian Sun. 2015\. “深入探讨整流器：超越人类水平的 ImageNet 分类性能。”康奈尔大学，计算机科学，arXiv:1502.01852，2015 年 2 月 6 日\. [`arxiv.org/abs/1502.01852`](https://arxiv.org/abs/1502.01852).

Julien, Robert M. 2011\. *药物作用概论*，第 12 版. 纽约：沃思出版公司.

Khanna, Asrushi. 2018\. “神经系统的细胞。” *教我生理学*（博客）。最后修改日期：2018 年 8 月 2 日\. [`teachmephysiology.com/nervous-system/components/cells-nervous-system`](https://teachmephysiology.com/nervous-system/components/cells-nervous-system).

Kuphaldt, Tony R. 2017\. “二极管与整流器介绍，第三章 - 二极管与整流器。”发表于 *电路课程，第 III 卷。关于电路的一切*。访问日期：2020 年 9 月 18 日\. [`www.allaboutcircuits.com/textbook/semiconductors/chpt-3/introduction-to-diodes-and-rectifiers/`](https://www.allaboutcircuits.com/textbook/semiconductors/chpt-3/introduction-to-diodes-and-rectifiers/).

LeCun, Yann, Leon Bottou, Genevieve B. Orr, 和 Klaus-Rober Müller. 1998\. “高效反向传播算法。”发表于 *神经网络：实践技巧*，由 Grégoire Montavon、Genevieve B. Orr 和 Klaus-Rober Müller 编辑。柏林：Springer-Verlag. 9–48\. [`yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf`](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf).

林默，斯特芬，和斯拉沃米尔·斯坦奇扎克。2017 年。“通过拉普拉斯技术的稀疏恢复的最优深度神经网络。”康奈尔大学，计算机科学，arXiv:1709.01112，2017 年 9 月 26 日。[`arxiv.org/abs/1709.01112`](https://arxiv.org/abs/1709.01112)。

洛迪什，哈维，阿诺德·伯克，S·劳伦斯·齐普尔斯基，保罗·松田，戴维·巴尔的摩，和詹姆斯·达内尔。2000 年。*分子细胞生物学*，第四版。纽约：W·H·弗里曼出版社；2000 年。[`www.ncbi.nlm.nih.gov/books/NBK21535/`](http://www.ncbi.nlm.nih.gov/books/NBK21535/)。

麦卡洛赫，沃伦·S. 和沃尔特·皮茨。1943 年。“神经活动中固有思想的逻辑演算。” *数学生物物理学通报* 5，第 1/2 期：115–133。[`www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf`](http://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf)。

穆尼耶，大卫，雷诺·兰比奥特，亚历克斯·福尔尼托，凯伦·D·厄舍，和爱德华·T·布尔莫尔。2009 年。“人脑功能网络中的层次模块化。” *神经信息学前沿*（2009 年 10 月 30 日）。[`www.frontiersin.org/articles/10.3389/neuro.11.037.2009/full`](https://www.frontiersin.org/articles/10.3389/neuro.11.037.2009/full)。

明斯基，马丁和西摩·帕帕特。1969 年。*感知机：计算几何学导论*。马萨诸塞州剑桥：麻省理工学院出版社。

奥本海姆，艾伦·V. 和萨米德·哈米德·纳瓦布。1996 年。*信号与系统*，第二版。新泽西州上萨德尔河：普伦蒂斯霍尔出版社。

普尔维斯，戴尔，乔治·J·奥古斯丁，戴维·菲茨帕特里克，劳伦斯·C·卡茨，安东尼-塞缪尔·拉曼提亚，詹姆斯·O·麦克纳马拉，和 S·马克·威廉姆斯。2001 年。*神经科学*，第二版，马萨诸塞州桑德兰：西纳尔出版社。[`www.ncbi.nlm.nih.gov/books/NBK11117/`](http://www.ncbi.nlm.nih.gov/books/NBK11117/)。

拉马钱德兰，普拉吉特，巴雷特·佐夫，和阔克·V·李。2017 年。“Swish：一种自门控激活函数。”康奈尔大学，计算机科学，arXiv:1710.05941，2017 年 10 月 27 日。[`arxiv.org/abs/1710.05941`](https://arxiv.org/abs/1710.05941)。

罗斯布拉特，弗兰克。1962 年。*神经动力学原理：感知机与大脑机制理论*。华盛顿特区：斯巴达出版社。

鲁梅尔哈特，大卫·E.，杰弗里·E.·欣顿，和罗纳德·J·威廉姆斯，1986 年。“通过反向传播误差学习表征。” *自然* 323，第 9 期：533–536。[`www.cs.utoronto.ca/~hinton/absps/naturebp.pdf`](https://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf)。

塞尔，托马斯。2014 年。“视觉系统的层次模型。”（研究笔记），认知语言学与心理学系，大脑科学研究所，布朗大学。[`serre-lab.clps.brown.edu/wp-content/uploads/2014/10/Serre-encyclopedia_revised.pdf`](https://serre-lab.clps.brown.edu/wp-content/uploads/2014/10/Serre-encyclopedia_revised.pdf)。

宋，塞巴斯蒂安。2013 年。*大脑连接组：大脑线路如何塑造我们是谁*。波士顿：马林纳图书出版社。

Sitzmann, Vincent, Julien N. P. Martel, Alexander W. Bergman, David B. Lindell, 和 Gordon Wetzstein. 2020. “带周期激活函数的隐式神经表示。” 康奈尔大学，计算机科学，arXiv:2006.09661，2020 年 6 月 17 日。 [`arxiv.org/abs/2006.09661`](https://arxiv.org/abs/2006.09661)。

Sporns, Olaf, Giulio Tononi, 和 Rolf Kötter. 2005. “人类连接组：人脑的结构描述。” *PLoS 计算生物学* 1 卷，第 4 期（2005 年 9 月）。 [`journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.0010042&type=printable`](http://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.0010042&type=printable)。

Timmer, John. 2014. “IBM 研究人员制造了一颗充满人工神经元的芯片。” *Ars Technica*，2014 年 8 月 7 日。 [`arstechnica.com/science/2014/08/ibm-researchers-make-a-chip-full-of-artificial-neurons/`](https://arstechnica.com/science/2014/08/ibm-researchers-make-a-chip-full-of-artificial-neurons/)。

Trudeau, Richard J. 1994. *图论导论*，第二版。纽约花园市：Dover 数学图书出版社。

Wikipedia. 2020a. “人工智能历史。” 最后修改于 2020 年 9 月 4 日。 [`en.wikipedia.org/wiki/History_of_artificial_intelligence`](https://en.wikipedia.org/wiki/History_of_artificial_intelligence)。

Wikipedia. 2020b. “神经元。” 最后修改于 2020 年 9 月 11 日。 [`en.wikipedia.org/wiki/Neuron`](https://en.wikipedia.org/wiki/Neuron)。

Wikipedia. 2020c. “感知机。” 最后修改于 2020 年 8 月 28 日。 [`en.wikipedia.org/wiki/Perceptron`](https://en.wikipedia.org/wiki/Perceptron)。

## 第十四章

Dauphin, Yann, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya Ganguli, 和 Yoshua Bengio. 2014. “识别并解决高维非凸优化中的鞍点问题。” 康奈尔大学，计算机科学，arXiv:1406.2572，2014 年 6 月 10 日。 [`arxiv.org/abs/1406.2572`](http://arxiv.org/abs/1406.2572)。

Fullér, Robert. 2010. “Δ学习规则教程。” 高级管理系统研究所，信息技术系，阿波大学，2010 年 11 月 4 日。 [`uni-obuda.hu/users/fuller.robert/delta.pdf`](http://uni-obuda.hu/users/fuller.robert/delta.pdf)。

NASA. 2012. “天文学家预测巨型碰撞：银河系对抗仙女座。” *NASA 科学博客*，制作编辑 Dr. Tony Phillips，2012 年 5 月 31 日。 [`science.nasa.gov/science-news/science-at-nasa/2012/31may_andromeda`](https://science.nasa.gov/science-news/science-at-nasa/2012/31may_andromeda)。

Nielsen, Michael A. 2015. “使用神经网络识别手写数字。” 载于 *神经网络与深度学习*。Determination Press。可于 [`neuralnetworksanddeeplearning.com/chap1.html`](http://neuralnetworksanddeeplearning.com/chap1.html) 获取。

Pyle, Katherine. 1918 年。*母亲的育儿故事*。纽约：E. F. Dutton & Company。可在[`www.gutenberg.org/files/49001/49001-h/49001-h.htm#Page_207`](https://www.gutenberg.org/files/49001/49001-h/49001-h.htm#Page_207)查阅。

Quote Investigator, 2020 年。“你只需去除一切不似大卫的部分。” Quote Investigator: 追溯名言。访问时间：2020 年 10 月 26 日。[`quoteinvestigator.com/tag/michelangelo/`](https://quoteinvestigator.com/tag/michelangelo/)。

Seung, Sebastian。2005 年。“神经网络导论。”9.641J 课程笔记，2005 年春季。MIT OpenCourseware，麻省理工学院。[`ocw.mit.edu/courses/brain-and-cognitive-sciences/9-641j-introduction-to-neural-networks-spring-2005/`](https://ocw.mit.edu/courses/brain-and-cognitive-sciences/9-641j-introduction-to-neural-networks-spring-2005/)。

## 第十五章

Bengio, Yoshua。2012 年。“基于梯度的深度架构训练的实用建议。”康奈尔大学，计算机科学系，arXiv:1206.5533。[`arxiv.org/abs/1206.5533v2`](https://arxiv.org/abs/1206.5533v2)。

Darken, C., J. Chang 和 J. Moody。1992 年。“加速随机梯度搜索的学习率调度。”见 *神经网络与信号处理 II，第 1992 年 IEEE 研讨会论文集*（9 月）：1-11。

Dauphin, Y., R. Pascanu, C. Gulcehre, K. Cho, S. Ganguli 和 Y. Bengio。2014 年。“识别并攻克高维非凸优化中的鞍点问题。”康奈尔大学，计算机科学系，arXiv:1406.2572，2014 年 6 月 10 日。[`arxiv.org/abs/1406.2572`](http://arxiv.org/abs/1406.2572)。

Duchi, John, Elad Hazan 和 Yoram Singer。2011 年。“在线学习与随机优化的自适应子梯度方法。” *机器学习研究期刊* 12 卷，第 61 期：2121-2159。[`jmlr.org/papers/v12/duchi11a.html`](http://jmlr.org/papers/v12/duchi11a.html)。

Hinton, Geoffrey, Nitish Srivastava 和 Kevin Swersky。2015 年。“机器学习中的神经网络：第 6a 讲，迷你批量梯度下降概述。”（讲座幻灯片）。多伦多大学，计算机科学系。[`www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf`](https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)。

Ioffe, Sergey 和 Christian Szegedy。2015 年。“批量归一化：通过减少内部协变量偏移加速深度网络训练。”康奈尔大学，计算机科学系，arXiv:1502.03167，2015 年 3 月 2 日。[`arxiv.org/abs/1502.03167`](https://arxiv.org/abs/1502.03167)。

Karpathy, Andrej。2016 年。“神经网络第三部分：学习与评估。”（斯坦福大学 CS231n 课程笔记）。加利福尼亚州，斯坦福大学。[`cs231n.github.io/neural-networks-2/`](http://cs231n.github.io/neural-networks-2/)。

Kingma, Diederik. P. 和 Jimmy L. Ba。2015 年。“Adam：一种随机优化方法。”第三届国际学习表征会议论文（美国加利福尼亚州圣地亚哥，5 月 7-9 日）：1-13。

Nesterov, Y. 1983. “一种无约束凸最小化问题的解法，收敛速率为 o(1/k2)。” *Doklady ANSSSR*（翻译为 *Soviet Mathematics: Doclady*）269：543–47。

Orr, Genevieve. 1999a. “学习率自适应。” 在 *CS-449: Neural Networks*。（课程笔记。）俄勒冈州塞勒姆：威拉米特大学。[`www.willamette.edu/~gorr/classes/cs449/intro.html`](https://www.willamette.edu/~gorr/classes/cs449/intro.html)。

Orr, Genevieve. 1999b. “动量。” 在 *CS-449: Neural Networks*。（课程笔记。）俄勒冈州塞勒姆：威拉米特大学。[`www.willamette.edu/~gorr/classes/cs449/intro.html`](https://www.willamette.edu/~gorr/classes/cs449/intro.html)。

Qian, N. 1999. “梯度下降学习算法中的动量项。” *Neural Networks* 12(1)：145–51。[`www.columbia.edu/~nq6/publications/momentum.pdf`](http://www.columbia.edu/~nq6/publications/momentum.pdf)。

Ruder, Sebastian. 2017. “梯度下降优化算法概述。” 康奈尔大学，计算机科学，arXiv:1609.04747，2017 年 6 月 15 日。[`arxiv.org/abs/1609.04747`](https://arxiv.org/abs/1609.04747)。

Srivasta, Nitish, Geoffrey Hinton, Alex Krizhevsky, 和 Ilya Sutskever. 2014. “Dropout：一种防止神经网络过拟合的简单方法。” *Journal of Machine Learning Research* 15（2014）：1929–58。[`jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf`](https://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf)。

Wolpert, David H. 1996. “学习定理之间缺乏先验区分。” *Neural Computation* 8，1341–90。[`citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.9734&rep=rep1&type=pdf`](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.9734&rep=rep1&type=pdf)。

Wolpert, D. H., 和 W. G. Macready. 1997. “优化的无免费午餐定理。” *IEEE Transactions on Evolutionary Computation* 1, 第 1 期：67–82。[`ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf`](https://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf)。

Zeiler, Matthew D. 2012. “ADADELTA：一种自适应学习率方法。” 康奈尔大学，计算机科学，arXiv:1212.5701。[`arxiv.org/abs/1212.5701`](http://arxiv.org/abs/1212.5701)。

## 第十六章

Aitken, Andrew, Christian Ledig, Lucas Theis, Jose Caballero, Zehan Wang, 和 Wenzhe Shi. 2017. “无棋盘伪影的子像素卷积：关于子像素卷积、尺寸调整卷积和卷积的简要说明。” 康奈尔大学，计算机科学，arXiv:1707.02937，2017 年 7 月 10 日。[`arxiv.org/abs/1707.02937`](https://arxiv.org/abs/1707.02937)。

Britz, Denny. 2015. “理解卷积神经网络在 NLP 中的应用，” *WildML*（博客），2015 年 11 月 7 日。[`www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/`](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)。

Canziani, Alfredo, Adam Paszke, 和 Eugenio Culurciello. 2017. “深度神经网络模型在实际应用中的分析。” 康奈尔大学，计算机科学，ArXiv:1605.07678，2016 年 4 月 4 日。[`arxiv.org/abs/1605.07678`](https://arxiv.org/abs/1605.07678)。

Culurciello, Eugenio. 2017. “神经网络架构。” *Medium: Towards Data Science*，2017 年 3 月 23 日。[`medium.com/towards-data-science/neural-network-architectures-156e5bad51ba`](https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba)。

Dumoulin, Vincent, 和 Francesco Visin. 2018. “深度学习卷积算术指南。” 康奈尔大学，计算机科学，arXiv:1603.07285，2018 年 1 月 11 日。[`arxiv.org/abs/1603.07285`](https://arxiv.org/abs/1603.07285)。

Esteva, Andre, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M. Blau, 和 Sebastian Thrun. 2017. “使用深度神经网络进行皮肤癌的皮肤科医生级分类。” *自然* 542（2 月 2 日）：115–18。[`cs.stanford.edu/people/esteva/nature/`](http://cs.stanford.edu/people/esteva/nature/)。

Ewert, J. P. 1985. “脊椎动物神经行为学的概念。” *动物行为* 33，第 1 期（2 月）：1–29。

Glorot, Xavier, 和 Yoshua Bengio. 2010. “理解训练深度前馈神经网络的困难。” 载于 *第 13 届国际人工智能与统计会议论文集*（意大利萨丁岛，5 月 13–15 日）：249–56。[`jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf`](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)。

He, Kaiming, Xiangyu Zhang, Shaoqing Ren, 和 Jian Sun. 2015. “深入研究修正函数：超越人类级别的 ImageNet 分类性能。” 康奈尔大学，计算机科学，arXiv:1502.01852，2015 年 2 月 6 日。[`arxiv.org/abs/1502.01852v1`](https://arxiv.org/abs/1502.01852v1)。

Kalchbrenner, Nal, Edward Grefenstette, 和 Phil Blunsom. 2014. “用于建模句子的卷积神经网络。” 康奈尔大学，计算机科学，arXiv:1404.2188v1，2014 年 4 月 8 日。[`arxiv.org/abs/1404.2188`](https://arxiv.org/abs/1404.2188)。

Karpathy, Andrej. 2016. “优化：随机梯度下降。” 斯坦福 CS231n 课程讲义，斯坦福，加利福尼亚州：斯坦福大学。[`cs231n.github.io/neural-networks-2/`](http://cs231n.github.io/neural-networks-2/)。

Kim, Yoon. 2014. “用于句子分类的卷积神经网络。” 康奈尔大学，计算机科学，arXiv:1408.5882，2014 年 9 月 3 日。[`arxiv.org/abs/1408.5882`](https://arxiv.org/abs/1408.5882)。

Levi, Gil, 和 Tal Hassner. 2015 年。“使用卷积神经网络进行年龄与性别分类。”IEEE 面部与手势分析与建模研讨会（AMFG），IEEE 计算机视觉与模式识别大会（CVPR）（波士顿，6 月）。[`www.openu.ac.il/home/hassner/projects/cnn_agegender/`](http://www.openu.ac.il/home/hassner/projects/cnn_agegender/)。

Lin, Min, Qiang Chen, 和 Shuicheng Yan. 2014 年。“网络中的网络。”康奈尔大学，计算机科学，arXiv:1312-4400v3，2014 年 3 月 4 日。[`arxiv.org/abs/1312.4400v3`](https://arxiv.org/abs/1312.4400v3)。

Mao, Xiao-Jiao, Chinhua Shen, 和 Yu-Bin Yang. 2016 年。“使用对称跳跃连接的卷积自编码器进行图像恢复。”康奈尔大学，计算机科学，arXiv:16.06.08921v3，2016 年 8 月 30 日。[`arxiv.org/abs/1606.08921`](https://arxiv.org/abs/1606.08921)。

Memmott, Mark. “你是否患有 RAS 综合症？” *‘Memmos’：Memmott 的信件与思考*，NPR，2015 年。[`www.npr.org/sections/memmos/2015/01/06/605393666/do-you-suffer-from-ras-syndrome`](https://www.npr.org/sections/memmos/2015/01/06/605393666/do-you-suffer-from-ras-syndrome)。

Odena, Augustus, Vincent Dumoulin, 和 Chris Olah. 2016 年。“反卷积与棋盘伪影。” *Distill*，2016 年 10 月 17 日。[`distill.pub/2016/deconv-checkerboard/`](https://distill.pub/2016/deconv-checkerboard/)。

Oppenheim, Alan V., 和 S. Hamid Nawab. 1996 年。*信号与系统*，第 2 版。新泽西州上萨德尔河：Prentice Hall。

Quiroga, R. Quian, L. Reddy, G. Kreiman, C. Koch, 和 I. Fried, 2005 年。“人脑单神经元的不可变视觉表征。” *自然* 435（6 月 23 日）：1102–07。[`www.nature.com/articles/nature03687`](https://www.nature.com/articles/nature03687)。

Serre, Thomas. 2014 年。“视觉系统的层次模型。”在 Jaeger D., Jung R.（编），*计算神经科学百科全书*。纽约：Springer。[`link.springer.com/referenceworkentry/10.1007%2F978-1-4614-7320-6_345-1`](https://link.springer.com/referenceworkentry/10.1007%2F978-1-4614-7320-6_345-1)。

Snavely, Noah. “CS1114 第六部分：卷积。”康奈尔大学 CS1114 课程笔记，使用 Matlab 和机器人学进行计算机入门，纽约伊萨卡：康奈尔大学，2013 年 2 月 27 日。[`www.cs.cornell.edu/courses/cs1114/2013sp/sections/S06_convolution.pdf`](https://www.cs.cornell.edu/courses/cs1114/2013sp/sections/S06_convolution.pdf)。

Springenberg, Jost Tobias, Alexey Dosovitskiy, Thomas Brox, 和 Martin Riedmiller. 2015 年。“追求简洁：全卷积网络。”康奈尔大学，计算机科学，arXiv:1412.6806，2015 年 4 月 13 日。[`arxiv.org/abs/1412.6806`](https://arxiv.org/abs/1412.6806)。

Sun, Y., X. Wang, 和 X. Tang. 2014 年。“通过预测 10,000 个类别进行深度学习面部表征。”会议论文，*2014 IEEE 计算机视觉与模式识别大会*（俄亥俄州哥伦布市，6 月 23-28 日）：1891–98。

Zeiler, Matthew D., Dilip Crishnana, Graham W. Taylor, 和 Rob Fergus. 2010\. “去卷积网络.” 计算机视觉与模式识别大会论文（2010 年 6 月 13 日–18 日）。[`www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf`](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf).

Zhang, Richard. 2019\. “使卷积网络重新具备平移不变性.” 康奈尔大学计算机科学，arXiv:1904.11486，2019 年 6 月 9 日。 [`arxiv.org/abs/1904.11486`](https://arxiv.org/abs/1904.11486).

## 第十七章

Chollet, François. 2017\. “Keras-team/Keras.” GitHub. [`keras.io/`](https://keras.io/).

Fei-Fei, Li, Jia Deng, Olga Russakovsky, Alex Berg, 和 Kai Li. 2020\. “下载.” ImageNet 网站。斯坦福视觉实验室。斯坦福大学/普林斯顿大学。访问日期：2020 年 10 月 4 日。 [`image-net.org/download`](http://image-net.org/download).

ImageNet. 2020\. “ILSVRC2014 的结果：分类 + 定位结果.” 斯坦福视觉实验室。斯坦福大学/普林斯顿大学。访问日期：2020 年 10 月 4 日。 [`image-net.org/challenges/LSVRC/2014/results`](http://image-net.org/challenges/LSVRC/2014/results).

LeCun, Y., B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, 和 L. D. Jackel. 1989\. “反向传播应用于手写邮政编码识别.” *Neural Computing* 1(4): 541–51\. 可在 [`yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf`](http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf) 查阅.

Moosavi-Dezfooli, Seyed-Mohsen, Alhussein Fawzi, Omar Fawzi, 和 Pascal Frossard. 2017\. “通用对抗扰动.” 康奈尔大学计算机科学，arXiv:1610.08401，2017 年 3 月 9 日。 [`arxiv.org/abs/1610.08401`](https://arxiv.org/abs/1610.08401).

Rauber, Jonas, 和 Wieland Brendel. 2017\. “欢迎使用 Foolbox Native.” Foolbox. [`foolbox.readthedocs.io/en/latest`](https://foolbox.readthedocs.io/en/latest).

Rauber, Jonas, Wieland Brendel, 和 Matthias Bethge. 2018\. “Foolbox: 一个用于基准测试机器学习模型鲁棒性的 Python 工具箱.” 康奈尔大学计算机科学，arXiv:1707.04131，2018 年 3 月 20 日。 [`arxiv.org/abs/1707.04131`](https://arxiv.org/abs/1707.04131).

Russakovsky, Olga, 等. 2015\. “ImageNet 大规模视觉识别挑战赛.” 康奈尔大学计算机科学，arXiv:1409.0575，2015 年 1 月 30 日。 [`arxiv.org/abs/1409.0575`](https://arxiv.org/abs/1409.0575).

Simonyan, Karen, 和 Andrew Zisserman. 2015\. “用于大规模图像识别的非常深的卷积网络.” 康奈尔大学计算机科学，arXiv:1409.1556，2015 年 4 月 10 日。 [`arxiv.org/abs/1409.1556`](https://arxiv.org/abs/1409.1556).

Zeiler, Matthew D., 和 Rob Fergus. 2013\. “可视化和理解卷积网络.” 康奈尔大学计算机科学，arXiv:1311.2901，2013 年 11 月 28 日。 [`arxiv.org/abs/1311.2901`](https://arxiv.org/abs/1311.2901).

## 第十八章

Altosaar, Jann. 2020\. “教程：什么是变分自编码器？” *Jaan Altosaar*（博客）。访问时间：2020 年 9 月 30 日。[`jaan.io/what-is-variational-autoencoder-vae-tutorial/`](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/).

Audio Mountain. 2020\. “音频文件大小计算。” AudioMountain.com 技术资源。访问时间：2020 年 9 月 30 日。[`www.audiomountain.com/tech/audio-file-size.html`](http://www.audiomountain.com/tech/audio-file-size.html).

Bako, Steve, Thijs Vogels, Brian McWilliams, Mark Meyer, Jan Novák, Alex Harvill, Prdeep Sen, Tony DeRose, 和 Fabrice Rousselle. 2017\. “用于去噪蒙特卡洛渲染的核预测卷积网络。”《*SIGGRAPH 17 会议录，ACM 图形学期刊*》36，第 4 期（文章 97）。[`s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20170630135237/Kernel-Predicting-Convolutional-Networks-for-Denoising-Monte-Carlo-Renderings-Paper33.pdf`](https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20170630135237/Kernel-Predicting-Convolutional-Networks-for-Denoising-Monte-Carlo-Renderings-Paper33.pdf).

Chaitanya, Chakravarty R. Alla, Anton Kaplanyan, Christoph Schied, Marco Salvi, Aaron Lefohn, Derek Nowrouzezahrai, 和 Timo Aila. 2017\. “使用递归去噪自编码器进行蒙特卡洛图像序列的交互式重建。”《*SIGGRAPH 17 会议录，ACM 图形学期刊*》36，第 4 期（7 月 1 日）。[`research.nvidia.com/publication/interactive-reconstruction-monte-carlo-image-sequences-using-recurrent-denoising`](http://research.nvidia.com/publication/interactive-reconstruction-monte-carlo-image-sequences-using-recurrent-denoising).

Chollet, François. 2017\. “在 Keras 中构建自编码器。” *Keras 博客*，2017 年 3 月 14 日。[`blog.keras.io/building-autoencoders-in-keras.html`](https://blog.keras.io/building-autoencoders-in-keras.html).

Doersch, Carl. 2016\. “变分自编码器教程。” 康奈尔大学，统计学，arXiv:1606.05908，2016 年 8 月 13 日。[`arxiv.org/abs/1606.05908`](https://arxiv.org/abs/1606.05908).

Donahue, Jeff. 2015\. “mnist_autoencoder.prototxt。” BVLC/Caffe. GitHub. 2015 年 2 月 5 日。[`github.com/BVLC/caffe/blob/master/examples/mnist/mnist_autoencoder.prototxt`](https://github.com/BVLC/caffe/blob/master/examples/mnist/mnist_autoencoder.prototxt).

Dürr, Oliver. 2016\. “变分自编码器简介。” 在瑞士温特图尔举行的 Datalab-Lunch 研讨会系列中做的报告，2016 年 5 月 11 日。[`tensorchiefs.github.io/bbs/files/vae.pdf`](https://tensorchiefs.github.io/bbs/files/vae.pdf).

Frans, Kevin. “变分自编码器解析。”（教程）Kevin Frans 网站，2016 年 8 月 6 日。[`kvfrans.com/variational-autoencoders-explained/`](http://kvfrans.com/variational-autoencoders-explained/).

Jia, Yangqing, 和 Evan Shelhamer, 2020. “Caffe。” 伯克利视觉在线文档，访问时间：2020 年 10 月 1 日。*http://caffe.berkeleyvision.org/*。

Kingma, Diederik P., 和 Max Welling, “自动编码变分贝叶斯。” 康奈尔大学，统计学，arXiv:1312.6114，2014 年 5 月 1 日。[`arxiv.org/abs/1312.6114`](https://arxiv.org/abs/1312.6114)。

Raffel, Colin. 2019. “一些不寻常的自编码器。” Slideshare.net。2019 年 2 月 24 日。[`www.slideshare.net/marlessonsa/a-few-unusual-autoencoder-colin-raffel`](https://www.slideshare.net/marlessonsa/a-few-unusual-autoencoder-colin-raffel)。

Rezende, Danilo Jimenez, Shakir Mohamed, 和 Daan Wierstra. 2014. “深度生成模型中的随机反向传播和近似推断。” *第 31 届国际机器学习大会（ICML）论文集，JMLR: W\&CP* 32（2014 年 5 月 30 日）。[`arxiv.org/abs/1401.4082`](https://arxiv.org/abs/1401.4082)。

Wikipedia. 2020a. “JPEG.” 访问时间：2020 年 9 月 30 日。[`en.wikipedia.org/wiki/JPEG`](https://en.wikipedia.org/wiki/JPEG)。

Wikipedia. 2020b. “MP3。” 访问时间：2020 年 9 月 30 日。[`en.wikipedia.org/wiki/MP3`](https://en.wikipedia.org/wiki/MP3)。

## 第十九章

Barrat, Robbie. 2018. “Rapping-Neural-Network。” GitHub，2018 年 10 月 29 日。[`github.com/robbiebarrat/rapping-neural-network`](https://github.com/robbiebarrat/rapping-neural-network)。

Bryant, Alice. 2019. “一个简单的句子，七种含义。” *VOA Learning English: Everyday Grammar*（博客）。2019 年 5 月 16 日。[`learningenglish.voanews.com/a/a-simple-sentence-with-seven-meanings/4916769.html`](https://learningenglish.voanews.com/a/a-simple-sentence-with-seven-meanings/4916769.html)。

Chen, Yutian, Matthew W. Hoffman, Sergio Gómez Colmenarejo, Misha Denil, Timothy P. Lillicrap, Matt Botvinick, 和 Nando de Freitas. 2017. “通过梯度下降来学习，无需梯度下降。” 康奈尔大学，统计学，arXiv:1611.03824v6，2017 年 6 月 12 日。[`arxiv.org/abs/1611.03824`](https://arxiv.org/abs/1611.03824)。

Chen, Qiming, 和 Ren Wu. 2017. “CNN 就是你所需的一切。” 康奈尔大学，计算机科学，arXiv:1712.09662，2017 年 12 月 27 日。[`arxiv.org/abs/1712.09662`](https://arxiv.org/abs/1712.09662)。

Chollet, Francois. 2017. “Keras 中的序列到序列学习十分钟入门。” *The Keras Blog*，2017 年 9 月 29 日。[`blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html`](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)。

Chu, Hang, Raquel Urtasun, 和 Sanja Fidler. 2016. “PI 之歌：一个音乐上合理的流行音乐生成网络。” 康奈尔大学，计算机科学，arXiv:1611.03477，2016 年 11 月 10 日。[`arxiv.org/abs/1611.03477`](https://arxiv.org/abs/1611.03477)。

Deutsch, Max. 2016a. “哈利·波特：由人工智能编写。” *深度写作*（博客），Medium。2016 年 7 月 8 日。[`medium.com/deep-writing/harry-potter-written-by-artificial-intelligence-8a9431803da6`](https://medium.com/deep-writing/harry-potter-written-by-artificial-intelligence-8a9431803da6).

Deutsch, Max. 2016b. “硅谷：由人工智能编写的新一集。” *深度写作*（博客），Medium，2016 年 7 月 11 日。[`medium.com/deep-writing/silicon-valley-a-new-episode-written-by-ai-a8f832645bc2`](https://medium.com/deep-writing/silicon-valley-a-new-episode-written-by-ai-a8f832645bc2).

Dickens, Charles. 1859. *双城记*. Project Gutenberg. [`www.gutenberg.org/ebooks/98`](https://www.gutenberg.org/ebooks/98).

Dictionary.com. 2020. “英语语言中有多少个单词？” 访问于 2020 年 10 月 29 日。[`www.dictionary.com/e/how-many-words-in-english/`](https://www.dictionary.com/e/how-many-words-in-english/).

Doyle, Arthur Conan. 1892. *福尔摩斯的冒险*. Project Gutenberg. [`www.gutenberg.org/files/1661/1661-0.txt`](https://www.gutenberg.org/files/1661/1661-0.txt).

Full Fact. 2020. “自动化事实核查。” 访问于 2020 年 10 月 29 日。[`fullfact.org/automated`](https://fullfact.org/automated).

Geitgey, Adam. 2016. “机器学习很有趣，第六部分：如何用深度学习做语音识别。” Medium，2016 年 12 月 23 日。[`medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a`](https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a).

Google. “Google 翻译。” 2020 年。[`translate.google.com/`](https://translate.google.com/).

Graves, Alex, Abdel-rahman Mohamed, 和 Geoffrey Hinton, “使用深度递归神经网络进行语音识别。” *2013 年 IEEE 国际声学、语音与信号处理会议（ICASSP）*，加拿大温哥华，2013 年 5 月 26 日–31 日。[`www.cs.toronto.edu/~fritz/absps/RNN13.pdf`](https://www.cs.toronto.edu/~fritz/absps/RNN13.pdf).

Heerman, Victor, 导演。1930. *动物饼干*。由 George S. Kaufman、Morrie Ryskind、Bert Kalmar 和 Harry Ruby 编剧。派拉蒙影业公司。[`www.imdb.com/title/tt0020640/`](https://www.imdb.com/title/tt0020640/).

Hochreiter, Sepp, Yoshua Bengio, Paolo Frasconi, 和 Jürgen Schmidhuber. 2001. “递归神经网络中的梯度流：学习长期依赖的困难。” 收录于 S. C. Kremer 和 J. F. Kolen 编，*动态递归神经网络实用指南*。纽约：IEEE 出版社。[`www.bioinf.jku.at/publications/older/ch7.pdf`](https://www.bioinf.jku.at/publications/older/ch7.pdf).

Hughes, John. 2020. “通过 Seq2Seq 架构进行英语到荷兰语的神经机器翻译。” GitHub。访问时间：2020 年 10 月 29 日。[`colab.research.google.com/github/hughes28/Seq2SeqNeuralMachineTranslator/blob/master/Seq2SeqEnglishtoDutchTranslation.ipynb#scrollTo=8q4ESVzKJgHd`](https://colab.research.google.com/github/hughes28/Seq2SeqNeuralMachineTranslator/blob/master/Seq2SeqEnglishtoDutchTranslation.ipynb#scrollTo=8q4ESVzKJgHd)。

Johnson, Daniel. 2015. “使用递归神经网络作曲。” *Daniel D. Johnson*（博客）。2015 年 8 月 3 日。[`www.danieldjohnson.com/2015/08/03/composing-music-with-recurrent-neural-networks/`](https://www.danieldjohnson.com/2015/08/03/composing-music-with-recurrent-neural-networks/)。

Jurafsky, Dan. 2020. “语言建模：介绍 N-grams。” 课堂笔记，斯坦福大学，2020 年冬季。[`web.stanford.edu/~jurafsky/slp3/slides/LM_4.pdf`](https://web.stanford.edu/~jurafsky/slp3/slides/LM_4.pdf)。

Kaggle. 2020. “太阳黑子。” 数据集，Kaggle.com。访问时间：2020 年 10 月 29 日。[`www.kaggle.com/robervalt/sunspots`](https://www.kaggle.com/robervalt/sunspots)。

Karim, Raimi. 2019. “Attn：插图中的注意力。” *Towards Data Science*（博客），Medium，2019 年 1 月 20 日。[`towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3`](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)。

Karpathy, Andrej, 和 Fei-Fei Li. 2013. “使用卷积神经网络和递归神经网络进行自动图像描述。” 演示文稿，斯坦福大学计算机科学系，斯坦福大学。 [`cs.stanford.edu/people/karpathy/sfmltalk.pdf`](https://cs.stanford.edu/people/karpathy/sfmltalk.pdf)。

Karpathy, Andrej. 2015. “递归神经网络的非凡有效性。” *Andrej Karpathy 博客*，GitHub，2015 年 5 月 21 日。[`karpathy.github.io/2015/05/21/rnn-effectiveness/`](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)。

Kelly, Charles. 2020. “制表符分隔的双语句子对。” Manythings.org。最后更新时间：2020 年 8 月 23 日。[`www.manythings.org/anki/`](http://www.manythings.org/anki/)。

Krishan. 2016. “通过递归神经网络生成宝莱坞歌词。” *从数据到决策*（博客），2016 年 12 月 8 日。[`iksinc.wordpress.com/2016/12/08/bollywood-lyrics-via-recurrent-neural-networks/`](https://iksinc.wordpress.com/2016/12/08/bollywood-lyrics-via-recurrent-neural-networks/)。

LISA Lab, 2018. “使用 RNN-RBM 建模和生成复调音乐序列。” 教程，Deeplearning.net。最后更新时间：2018 年 6 月 15 日。[`deeplearning.net/tutorial/rnnrbm.html#rnnrbm`](http://deeplearning.net/tutorial/rnnrbm.html#rnnrbm)。

Mao, Junhua, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, 和 Alan Yuille. 2015. “使用多模态递归神经网络（m-RNN）进行深度图像描述。” 康奈尔大学计算机科学，arXiv:1412.6632，2015 年 6 月 11 日。[`arxiv.org/abs/1412.6632`](https://arxiv.org/abs/1412.6632)。

McCrae, Pat. 2018 年。“关于‘英语中有多少个名词’的评论。”Quora。2018 年 11 月 15 日。[`www.quora.com/How-many-nouns-are-there-in-English`](https://www.quora.com/How-many-nouns-are-there-in-English)。

Moocarme, Matthew. 2020 年。“使用递归神经网络创建的乡村歌词。”*Matthew Moocarme*（博客）。访问日期：2020 年 10 月 29 日。[`www.mattmoocar.me/blog/RNNCountryLyrics/`](http://www.mattmoocar.me/blog/RNNCountryLyrics/)。

Mooney, Raymond J. 2019 年。“CS 343：人工智能：自然语言处理。”课程笔记，PowerPoint 幻灯片，德克萨斯大学奥斯汀分校。[`www.cs.utexas.edu/~mooney/cs343/slides/nlp.ppt`](http://www.cs.utexas.edu/~mooney/cs343/slides/nlp.ppt)。

O’Brien, Tim, 和 Irán Román. 2017 年。“用于音乐结构处理和期望的递归神经网络。”CS224d：自然语言处理深度学习报告，斯坦福大学，2017 年冬季。[`cs224d.stanford.edu/reports/O%27BrienRom%C2%B4an.pdf`](https://cs224d.stanford.edu/reports/O%27BrienRom%C2%B4an.pdf)。

Olah, Christopher. 2015 年。“理解 LSTM 网络。”*Colah’s Blog*，GitHub，2015 年 8 月 27 日。[`colah.github.io/posts/2015-08-Understanding-LSTMs/`](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)。

Pascanu, Razvan, Tomas Mikolov, 和 Yoshua Bengio. 2013 年。“训练递归神经网络的难点。”康奈尔大学，计算机科学，arXiv:1211.5063，2013 年 2 月 16 日。[`arxiv.org/abs/1211.5063`](https://arxiv.org/abs/1211.5063)。

R2RT. 2016 年。“书面记忆：理解、推导和扩展 LSTM。”*R2RT*（博客），2016 年 7 月 26 日。[`r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html`](https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html)。

Rajpurkar, Pranav, Robin Jia, 和 Percy Liang. 2018 年。“了解你不知道的：SQuAD 中的无解问题。”康奈尔大学，计算机科学，arXiv:1806.03822，2018 年 6 月 11 日。[`arxiv.org/abs/1806.03822`](https://arxiv.org/abs/1806.03822)。

Roberts, Adam, Colin Raffel, 和 Noam Shazeer. 2020 年。“你能将多少知识封装进语言模型的参数中？”康奈尔大学，计算机科学，arXiv:2002.08910，2020 年 10 月 5 日。[`arxiv.org/abs/2002.08910`](https://arxiv.org/abs/2002.08910)。

Robertson, Sean. 2017 年。“从零开始的 NLP：使用序列到序列网络和注意力机制的翻译。”教程，PyTorch。[`pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html`](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)。

Schuster, Mike, 和 Kuldip K. Paliwal. 1997 年。“双向递归神经网络。”IEEE 信号处理学报，45 卷，第 11 期（11 月）。*http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.331.9441&rep=rep1&type=pdf*。

Sturm, Bob L. 2015a. “无限的爱尔兰传统音乐会。” *High Noon GMT*（博客），Folk the Algorithms，2015 年 8 月 7 日\. [`highnoongmt.wordpress.com/2015/08/07/the-infinite-irish-trad-session/`](https://highnoongmt.wordpress.com/2015/08/07/the-infinite-irish-trad-session/).

Sturm, Bob L. 2015b. “‘Lisl 的 Stis’: 用于民间音乐生成的递归神经网络.” *High Noon GMT*（博客），Folk the Algorithms，2015 年 5 月 22 日\. [`highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/`](https://highnoongmt.wordpress.com/2015/05/22/lisls-stis-recurrent-neural-networks-for-folk-music-generation/).

Sutskever, Ilya, Oriol Vinyals, 和 Quoc V. Le. 2014\. “使用神经网络的序列到序列学习.” 康奈尔大学，计算机科学，arXiv:1409.3215，2014 年 12 月 14 日\. [`arxiv.org/abs/1409.3215`](https://arxiv.org/abs/1409.3215).

Unicode 联盟. 2020\. 版本 13.0.0，2020 年 3 月 10 日\. [`www.unicode.org/versions/Unicode13.0.0/`](https://www.unicode.org/versions/Unicode13.0.0/).

van den Oord, Äaron, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, 和 Koray Kavukcuoglu. 2016\. “WaveNet：一种原始音频的生成模型。” 康奈尔大学，计算机科学，arXiv:1609.03499，2016 年 9 月 19 日\. [`arxiv.org/abs/1609.03499`](https://arxiv.org/abs/1609.03499).

Vicente, Agustin, 和 Ingrid L. Falkum. 2017\. “多义性.” *牛津研究百科全书：语言学*。2017 年 7 月 27 日\. [`oxfordre.com/linguistics/view/10.1093/acrefore/9780199384655.001.0001/acrefore-9780199384655-e-325`](https://oxfordre.com/linguistics/view/10.1093/acrefore/9780199384655.001.0001/acrefore-9780199384655-e-325).

## 第二十章

Alammar, Jay. 2018\. “GPT3 的工作原理 - 可视化和动画.” *Jay Alammar: 一次性可视化机器学习概念*（博客）。GitHub。2020 年 11 月 5 日访问\. [`jalammar.github.io/how-gpt3-works-visualizations-animations/`](http://jalammar.github.io/how-gpt3-works-visualizations-animations/).

Alammar, Jay. 2019\. “首次使用 BERT 的可视化指南.” *Jay Alammar: 一次性可视化机器学习概念*（博客）。GitHub。2019 年 11 月 26 日\. [`jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/`](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/).

Bahdanau, Dzmitry, Kyunghyun Cho, 和 Yoshua Bengio. 2016\. “通过联合学习对齐和翻译的神经机器翻译.” 康奈尔大学，计算机科学，arXiv:1409.0473，2016 年 5 月 19 日\. [`arxiv.org/abs/1409.0473`](https://arxiv.org/abs/1409.0473).

Brown, Tom B., 等. 2020\. “语言模型是少量学习者。” 康奈尔大学，计算机科学，arXiv:2005.14165，2020 年 7 月 22 日\. [`arxiv.org/pdf/2005.14165.pdf`](https://arxiv.org/pdf/2005.14165.pdf).

Cer, Daniel, 等. 2018\. “通用句子编码器。”康奈尔大学，计算机科学，arXiv:1803.11175，2018 年 4 月 12 日。[`arxiv.org/abs/1803.11175`](https://arxiv.org/abs/1803.11175).

Cho, Kyunghyun, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, 和 Yoshua Bengio. 2014\. “使用 RNN 编码器-解码器学习短语表示法进行统计机器翻译。”发表于 *2014 年自然语言处理实证方法会议（EMNLP）*（卡塔尔多哈，2014 年 10 月 25 日至 29 日）：1724–34。[`emnlp2014.org/papers/pdf/EMNLP2014179.pdf`](http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf).

Chromiak, Michał. 2017\. “变换器—注意力就是一切。”*Michał Chromiak 的博客*，GitHub，2017 年 10 月 30 日。[`mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/`](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/).

Common Crawl. 2020\. Common Crawl 主页。访问时间：2020 年 11 月 15 日。[`commoncrawl.org/the-data/`](https://commoncrawl.org/the-data/).

Devlin, Jacob, Ming-Wei Chang, Kenton Lee, 和 Kristina Toutanova. 2019\. “BERT: 深度双向变换器的语言理解预训练。”康奈尔大学，计算机科学，arXiv:1810.04805，2019 年 5 月 24 日。[`arxiv.org/abs/1810.04805`](https://arxiv.org/abs/1810.04805).

Devlin, Jacob, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2020\. “Google-Research/bert。”GitHub。访问时间：2020 年 11 月 5 日。[`github.com/google-research/bert`](https://github.com/google-research/bert).

El Boukkouri, Hicham. 2018\. “词嵌入的算术性质。”*数据前沿*（博客），Medium，2018 年 11 月 21 日。[`medium.com/data-from-the-trenches/arithmetic-properties-of-word-embeddings-e918e3fda2ac`](https://medium.com/data-from-the-trenches/arithmetic-properties-of-word-embeddings-e918e3fda2ac).

Facebook 开源项目。2020\. “fastText: 高效文本分类与表示学习库。”开源软件。访问时间：2020 年 11 月 5 日。[`fasttext.cc/`](https://fasttext.cc/).

Frankenheimer, John, 导演。1962\. *重庆森林*，由 George Axelrod 编剧，改编自 Richard Condon 的小说。M. C. Productions。[`www.imdb.com/title/tt0056218/`](https://www.imdb.com/title/tt0056218/).

Gluon 作者。2020\. “使用预训练 ELMo 提取句子特征。”教程，Gluon，访问时间：2020 年 11 月 5 日。[`gluon-nlp.mxnet.io/examples/sentence_embedding/elmo_sentence_representation.html`](https://gluon-nlp.mxnet.io/examples/sentence_embedding/elmo_sentence_representation.html).

He, Kaiming, Xiangyu Zhang, Shaoqing Ren, 和 Jian Sun. 2015\. “深度残差学习用于图像识别。”康奈尔大学，计算机科学，arXiv:1512.03385，2015 年 12 月 10 日。[`arxiv.org/abs/1512.03385`](https://arxiv.org/abs/1512.03385).

Hendrycks, Dan, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, 和 Jacob Steinhardt. 2020 年。“测量大规模多任务语言理解。”康奈尔大学，计算机科学，arXiv:2009.03300，2020 年 9 月 21 日。[`arxiv.org/abs/2009.03300`](https://arxiv.org/abs/2009.03300)。

Howard, Jeremy 和 Sebastian Ruder. 2018 年。“用于文本分类的通用语言模型微调。”康奈尔大学，计算机科学，arXiv:1801.06146，2018 年 5 月 23 日。[`arxiv.org/abs/1801.06146`](https://arxiv.org/abs/1801.06146)。

Huston, Scott. 2020 年。“GPT-3 简介：理解 OpenAI 的前沿语言模型。”*Towards Data Science*（博客），2020 年 8 月 20 日。[`towardsdatascience.com/gpt-3-primer-67bc2d821a00`](https://towardsdatascience.com/gpt-3-primer-67bc2d821a00)。

Kaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, 和 Dario Amodei. 2020 年。“神经语言模型的扩展规律。”康奈尔大学，计算机科学，arXiv:2001.08361，2020 年 1 月 23 日。[`arxiv.org/abs/2001.08361`](https://arxiv.org/abs/2001.08361)。

Kazemnejad, Amirhossein. 2019 年。“Transformer 架构：位置编码。”*Amirhossein Kazemnejad 的博客*，2019 年 9 月 20 日。[`kazemnejad.com/blog/transformer_architecture_positional_encoding/`](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)。

Kelly, Charles. 2020 年。“制表符分隔的双语句子对。”Manythings.org。访问于 2020 年 11 月 6 日。[`www.manythings.org/anki/`](http://www.manythings.org/anki/)。

Klein, Guillaume, Yoon Kim, Yuntian Deng, Jean Senellart, 和 Alexander M. Rush. 2017 年。“OpenNMT：开源神经机器翻译工具包。”康奈尔大学，计算机科学，arXiv:1701.02810，2017 年 3 月 6 日。[`arxiv.org/abs/1701.02810`](https://arxiv.org/abs/1701.02810)。

刘扬、季力新、黄瑞阳、明拓思宇、高超、张剑鹏。2018 年。“一种用于句子分类的注意力门控卷积神经网络。”康奈尔大学，计算机科学，arXiv:2018.07325，2018 年 12 月 28 日。[`arxiv.org/abs/1808.07325`](https://arxiv.org/abs/1808.07325)。

Mansimov, Elman, Alex Wang, Sean Welleck, 和 Kyunghyun Cho. 2020 年。“一种用于无向序列模型的序列生成广义框架。”康奈尔大学，计算机科学，arXiv:1905.12790，2020 年 2 月 7 日。[`arxiv.org/abs/1905.12790`](https://arxiv.org/abs/1905.12790)。

McCormick Chris 和 Nick Ryan，2020 年。“BERT 微调教程与 PyTorch。”*Chris McCormick*（博客）。最后更新于 2020 年 3 月 20 日。[`mccormickml.com/2019/07/22/BERT-fine-tuning/`](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)。

Mikolov, Tomas, Kai Chen, Greg Corrado, 和 Jeffrey Dean. 2013 年. “词表示的高效估计.” 康奈尔大学，计算机科学，arXiv:1301.3781，2013 年 9 月 7 日. [`arxiv.org/abs/1301.3781`](https://arxiv.org/abs/1301.3781).

Mikolov, Tomas, Ilya Sutskever, Kai Chen, Greg Corrado, 和 Jeffrey Dean. 2013 年. “词语和短语的分布式表示及其组合性.” 康奈尔大学，计算机科学，arXiv:1310.4546，2013 年 10 月 16 日. [`arxiv.org/abs/1310.4546`](https://arxiv.org/abs/1310.4546).

Mishra, Prakhar. 2020 年. “基于 BERT 的自然语言生成介绍.” *TechViz: The Data Science Guy*（博客）。访问于 2020 年 11 月 6 日. [`prakhartechviz.blogspot.com/2020/04/natural-language-generation-using-bert.html`](https://prakhartechviz.blogspot.com/2020/04/natural-language-generation-using-bert.html).

Paulus, Romain, Caiming Xiong, 和 Richard Socher, 2017 年. “用于抽象摘要的深度强化学习模型.” 康奈尔大学，计算机科学，arXiv:1705.04304，2017 年 11 月 13 日. [`arxiv.org/abs/1705.04304`](https://arxiv.org/abs/1705.04304).

Pennington, Jeffrey, Richard Socher, 和 Christopher D. Manning. 2014 年. “GloVe: 全局词向量表示.” 收录于*2014 年自然语言处理实证方法会议（EMNLP）论文集*（10 月）：1532–43. [`nlp.stanford.edu/pubs/glove.pdf`](https://nlp.stanford.edu/pubs/glove.pdf).

Peters, Matthew E., Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, 和 Luke Zettlemoyer. 2018 年. “深度上下文化词表示.” 康奈尔大学，计算机科学，arXiv:1802.05365，2018 年 3 月 22 日. [`arxiv.org/abs/1802.05365`](https://arxiv.org/abs/1802.05365).

Radford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, 和 Ilya Sutskever. 2019 年. “语言模型是无监督的多任务学习者.” OpenAI, 旧金山，加利福尼亚州，2019 年. [`cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf`](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf).

Raffel, Colin, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, 和 Peter J. Liu. 2020 年. “探索统一文本到文本转换器的迁移学习极限.” 康奈尔大学，计算机科学，arXiv:1910.10683，2020 年 7 月 28 日. [`arxiv.org/abs/1910.10683`](https://arxiv.org/abs/1910.10683).

Rajasekharan, Ajit. 2019 年. “BERT 基础模型的综述.” *Towards Data Science*（博客），2019 年 6 月 17 日. [`towardsdatascience.com/a-review-of-bert-based-models-4ffdc0f15d58`](https://towardsdatascience.com/a-review-of-bert-based-models-4ffdc0f15d58).

Reisner, Alex. 2020 年. “做一只动物是什么感觉？” SpeedofAnimals.com. 访问于 2020 年 11 月 6 日. [`www.speedofanimals.com/`](https://www.speedofanimals.com/).

Russell, Stuart, 和 Peter Norvig. 2009. *人工智能：一种现代方法*，第 3 版。纽约：Pearson 出版社。

Sanh, Victor, Lysandre Debut, Julien Chaumond, 和 Thomas Wolf. 2020. “DistilBERT，BERT 的蒸馏版本：更小、更快、更便宜、更轻。” 康奈尔大学，计算机科学，arXiv:1910.01108，2020 年 3 月 1 日。[`arxiv.org/abs/1910.01108`](https://arxiv.org/abs/1910.01108)。

Scott, Kevin. 2020. “微软与 OpenAI 合作，独家授权 GPT-3 语言模型。” *官方微软博客*，2020 年 9 月 22 日。[`blogs.microsoft.com/blog/2020/09/22/microsoft-teams-up-with-openai-to-exclusively-license-gpt-3-language-model/`](https://blogs.microsoft.com/blog/2020/09/22/microsoft-teams-up-with-openai-to-exclusively-license-gpt-3-language-model/)。

Shao, Louis, Stephan Gouws, Denny Britz, Anna Goldie, Brian Strope, 和 Ray Kurzweil. 2017. “使用序列到序列模型生成高质量和有信息量的对话回复。” 康奈尔大学，计算机科学，arXiv:1701.03185，2017 年 7 月 31 日。[`arxiv.org/abs/1701.03185`](https://arxiv.org/abs/1701.03185)。

Singhal, Vivek. 2020. “NLP 中的变换器。” *研究/博客*，CellStrat，2020 年 5 月 19 日。[`www.cellstrat.com/2020/05/19/transformers-for-nlp/`](https://www.cellstrat.com/2020/05/19/transformers-for-nlp/)。

Socher, Richard, Alex Perelygin, Jean Y. Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, 和 Christopher Potts. 2013a. “深刻的移动：情感分析的深度学习——数据集。” 情感分析。2013 年 8 月。[`nlp.stanford.edu/sentiment/index.html`](https://nlp.stanford.edu/sentiment/index.html)。

Socher, Richard, Alex Perelygin, Jean Y. Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, 和 Christopher Potts. 2013b. “递归深度模型用于情感树库上的语义组合性。” 在自然语言处理经验方法会议（EMNLP）上的口头报告（西雅图，华盛顿州，2013 年 10 月 18 日至 21 日）。[`nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf`](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)。

spaCy 作者. 2020. “词向量与语义相似性。” spaCy：使用。[`spacy.io/usage/vectors-similarity`](https://spacy.io/usage/vectors-similarity)。

Sutskever, Ilya, Oriol Vinyals, 和 Quoc V. Le. 2014. “使用神经网络进行序列到序列学习。” 康奈尔大学，计算机科学，arXiv:1409.3215，2014 年 12 月 14 日。[`arxiv.org/abs/1409.3215`](https://arxiv.org/abs/1409.3215)。

Tay, Yi, Mostafa Dehghani, Dara Bahri, 和 Donald Metzler. 2020. “高效的变换器：综述。” 康奈尔大学，数学，arXiv:2009.0673，2020 年 9 月 1 日。[`arxiv.org/abs/2009.0673`](https://arxiv.org/abs/2009.0673)。

Taylor, Wilson L. 1953. “‘Cloze 程序’：一种衡量可读性的新工具。” *Journalism Quarterly*，30(4): 415–33。[`www.gwern.net/docs/psychology/writing/1953-taylor.pdf`](https://www.gwern.net/docs/psychology/writing/1953-taylor.pdf)。

TensorFlow 作者. 2018. “通用句子编码器。”教程，TensorFlow 模型档案，GitHub，2018 年。[`colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb#scrollTo=co7MV6sX7Xto`](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb#scrollTo=co7MV6sX7Xto)。

TensorFlow 作者, 2019a. “为什么使用位置嵌入而不是拼接？” *tensorflow/tensor2tensor*（博客）。2019 年 5 月 30 日。[`github.com/tensorflow/tensor2tensor/issues/1591`](https://github.com/tensorflow/tensor2tensor/issues/1591)。

TensorFlow 作者. 2019b. “用于语言理解的 Transformer 模型。”文档，TensorFlow，GitHub。[`colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb`](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb)。

TensorFlow 作者. 2020a. “Elmo。”TensorFlow Hub，2020 年 11 月 6 日。[`tfhub.dev/google/elmo/3`](https://tfhub.dev/google/elmo/3)。

TensorFlow 作者. 2020b. “用于语言理解的 Transformer 模型。”教程，TensorFlow 核心文档。最后更新于 2020 年 11 月 2 日。[`www.tensorflow.org/tutorials/text/transformer`](https://www.tensorflow.org/tutorials/text/transformer)。

Thiruvengadam, Aditya. 2018. “Transformer 架构：Attention Is All You Need。” *Aditya Thiruvengadam*（博客），Medium。2018 年 10 月 9 日。[`medium.com/@adityathiruvengadam/transformer-architecture-attention-is-all-you-need-aeccd9f50d09`](https://medium.com/@adityathiruvengadam/transformer-architecture-attention-is-all-you-need-aeccd9f50d09)。

Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jacob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, 和 Illia Polosukhim. 2017. “Attention Is All You Need。”康奈尔大学，计算机科学，arXiv:1706.03762v5，2017 年 12 月 6 日。[`arxiv.org/abs/1706.03762v5`](https://arxiv.org/abs/1706.03762v5)。

Vijayakumar, Ashwin K., Michael Cogswell, Ramprasath R. Selvaraju, Qing Sun, Stefan Lee, David Crandall, 和 Dhruv Batra. 2018. “多样性束搜索：从神经序列模型中解码多样化的解决方案。”康奈尔大学，计算机科学，arXiv:1610.02424。2018 年 10 月 22 日。[`arxiv.org/abs/1610.02424`](https://arxiv.org/abs/1610.02424)。

von Platen, Patrick. 2020. “如何生成文本：使用不同的解码方法生成语言，使用 Transformer。” *Huggingface*（博客），GitHub，2020 年 5 月。[`huggingface.co/blog/how-to-generate`](https://huggingface.co/blog/how-to-generate)。

Wallace, Eric, Tony Z. Zhao, Shi Feng, 和 Sameer Singh. 2020\. “通过隐蔽数据投毒自定义触发器。” 康奈尔大学，计算机科学，arXiv:2010.12563，2020 年 10 月 3 日\. [`arxiv.org/abs/2010.12563`](https://arxiv.org/abs/2010.12563).

Walton, Nick. 2020\. “AI Dungeon: Dragon 模型升级。” *Nick Walton*（博客）2020 年 7 月 14 日\. [`medium.com/@aidungeon/ai-dungeon-dragon-model-upgrade-7e8ea579abfe`](https://medium.com/@aidungeon/ai-dungeon-dragon-model-upgrade-7e8ea579abfe) 和 [`play.aidungeon.io/main/home`](https://play.aidungeon.io/main/home).

Wang, Alex, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, 和 Samuel R. Bowman. 2019\. “GLUE: 用于自然语言理解的多任务基准和分析平台。” 康奈尔大学，计算机科学，arXiv:1804.07461，2019 年 2 月 22 日\. [`arxiv.org/abs/1804.07461`](https://arxiv.org/abs/1804.07461).

Wang, Alex, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, 和 Samuel R. Bowman. 2020\. “GLUE 排行榜。” GLUE 基准测试。访问于 2020 年 11 月 6 日\. [`gluebenchmark.com/leaderboard/submission/zlssuBTm5XRs0aSKbFYGVIVdvbj1/-LhijX9VVmvJcvzKymxy`](https://gluebenchmark.com/leaderboard/submission/zlssuBTm5XRs0aSKbFYGVIVdvbj1/-LhijX9VVmvJcvzKymxy).

Warstadt, Alex, Amanpreet Singh, 和 Sam Bowman. 2018\. “CoLA: 语言接受度语料库。” NYU-MLL. [`nyu-mll.github.io/CoLA/`](https://nyu-mll.github.io/CoLA/).

Warstadt, Alex, Amanpreet Singh, 和 Sam Bowman. 2019\. “神经网络能力评估。” 康奈尔大学，计算机科学，arXiv:1805.12471，2019 年 10 月 1 日\. [`arxiv.org/abs/1805.12471`](https://arxiv.org/abs/1805.12471).

Welleck, Sean, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang, 和 Kyunghyun Cho. 2020\. “递归语言模型在不完全解码下的一致性。” 康奈尔大学，计算机科学，arXiv:2002.02492，2020 年 10 月 2 日\. [`arxiv.org/abs/2002.02492`](https://arxiv.org/abs/2002.02492).

Woolf, Max. 2019\. “使用 GPU 训练 GPT-2 文本生成模型。” Google Colab Notebook, 2019\. [`colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce#scrollTo=-xInIZKaU104`](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce#scrollTo=-xInIZKaU104).

Xu, Lei, Ivan Ramirez, 和 Kalyan Veeramachaneni. 2020\. “通过条件 BERT 采样重写有意义的句子，并应用于欺骗文本分类器。” 康奈尔大学，计算机科学，arXiv:2010.11869，2020 年 10 月 22 日\. [`arxiv.org/abs/2010.11869`](https://arxiv.org/abs/2010.11869).

Zhang, Aston, Zachary C. Lipton, Mu Li, 和 Alexander J. Smola. 2020\. “10.3: Transformer。” 在 *Dive into Deep Learning* 中. [`d2l.ai/chapter_attention-mechanisms/transformer.html`](https://d2l.ai/chapter_attention-mechanisms/transformer.html).

Zhang, Han, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena. 2019\. “自注意力生成对抗网络。” 康奈尔大学，统计学，arXiv:1805.08318，2019 年 6 月 14 日。 [`arxiv.org/abs/1805.08318`](https://arxiv.org/abs/1805.08318).

Zhu, Yukun, Ryan Kiros, Richard Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015\. “对齐书籍与电影：通过观看电影和阅读书籍，向故事般的视觉解释迈进。” 康奈尔大学，计算机科学，arXiv:1506.06724，2015 年 6 月 22 日。 [`arxiv.org/abs/1506.06724`](https://arxiv.org/abs/1506.06724).

## 第二十一章

Asadi, Kavosh, and Michael L. Littman. 2017\. “强化学习的另一种 Softmax 操作符。” 在*第 34 届国际机器学习大会论文集*（澳大利亚悉尼，8 月 6 日至 11 日）。 [`arxiv.org/abs/1612.05628`](https://arxiv.org/abs/1612.05628).

Craven, Mark, and David Page. 2018\. “使用 DNN 的强化学习：从 AlphaGo 到 AlphaZero。” CS 760 课程笔记，春季，威斯康星大学麦迪逊分校医学与公共卫生学院。 [`www.biostat.wisc.edu/~craven/cs760/lectures/AlphaZero.pdf`](https://www.biostat.wisc.edu/~craven/cs760/lectures/AlphaZero.pdf).

DeepMind team. 2020\. “Alpha Go。” *DeepMind*（博客）。2020 年 10 月 8 日访问。 [`deepmind.com/research/alphago/`](https://deepmind.com/research/alphago/).

Eden, Tim, Anthony Knittel, and Raphael van Uffelen. 2020\. “强化学习。” 新南威尔士大学。2020 年 10 月 8 日访问。 [`www.cse.unsw.edu.au/~cs9417ml/RL1/algorithms.html`](http://www.cse.unsw.edu.au/~cs9417ml/RL1/algorithms.html).

François-Lavet, Vincent, Peter Henderson, Riashat Islam, Marc G. Bellemare, Joelle Pineau, “深度强化学习简介。” 康奈尔大学，机器学习，arXiv:1811.12560，2018 年 12 月 3 日。 [`arxiv.org/abs/1811.12560`](https://arxiv.org/abs/1811.12560).

Hassabis, Demis, and David Silver. 2017\. “AlphaGo Zero：从零开始学习。” *DeepMind*（博客），2017 年 10 月 18 日。 [`deepmind.com/blog/alphago-zero-learning-scratch/`](https://deepmind.com/blog/alphago-zero-learning-scratch/).

Matiisen, Tambet. 2015\. “揭开深度强化学习的神秘面纱。” 计算神经科学实验室，塔尔图大学计算机科学学院，2015 年 12 月 15 日。 [`neuro.cs.ut.ee/demystifying-deep-reinforcement-learning/`](https://neuro.cs.ut.ee/demystifying-deep-reinforcement-learning/).

Melo, Francisco S. 2020\. “Q 学习的收敛性：一个简单的证明。” 系统与机器人研究所，葡萄牙高级技术学院。2020 年 10 月 9 日访问。 [`users.isr.ist.utl.pt/~mtjspaan/readingGroup/ProofQlearning.pdf`](http://users.isr.ist.utl.pt/~mtjspaan/readingGroup/ProofQlearning.pdf).

Mnih, Volodymyr, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, 和 Martin Riedmiller. 2013 年. “通过深度强化学习玩 Atari 游戏。” NIPS 深度学习研讨会，2013 年 12 月 19 日。[`arxiv.org/abs/1312.5602v1`](https://arxiv.org/abs/1312.5602v1)。

Rummery, G. A., 和 M. Niranjan. 1994 年. “使用联结系统进行在线 Q 学习。” 剑桥大学工程系，英国，1994 年 9 月。[`citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.2539&rep=rep1&type=pdf`](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.17.2539&rep=rep1&type=pdf)。

Silver, David, 等. 2017 年. “无须人类知识即可掌握围棋游戏。” *自然* 550（2017 年 10 月 19 日）：354–59。[`www.nature.com/articles/nature24270.epdf`](https://www.nature.com/articles/nature24270.epdf)。

Sutton, Richard S., 和 Andrew G. Baro. 2018 年. *强化学习：导论*，第二版. 美国马萨诸塞州剑桥：MIT 出版社。可在[`www.incompleteideas.net/book/the-book-2nd.html`](http://www.incompleteideas.net/book/the-book-2nd.html)查看。

Villanueva, John Carl. 2009 年. “宇宙中有多少个原子？” *宇宙今日*，2009 年 7 月 30 日。[`www.universetoday.com/36302/atoms-in-the-universe/`](http://www.universetoday.com/36302/atoms-in-the-universe/)。

Watkins, Christopher. 1989 年. “从延迟奖励中学习。” 博士论文，剑桥大学，英国。[`www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf`](http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf)。

## 第二十二章

Achlioptas, Panos, Olga Diamanti, Ioannis Mitliagkas, 和 Leonidas Guibas. 2018 年. “3D 点云的表示学习与对抗生成。” 康奈尔大学，计算机科学，arXiv:1707.02392，2018 年 6 月 12 日。[`arxiv.org/abs/1707.02392v1`](https://arxiv.org/abs/1707.02392v1)。

Arjovsky, Martin, 和 Léon Bottou. 2017 年. “朝着训练生成对抗网络的原则性方法迈进。” 康奈尔大学，统计学，arXiv:1701.04862，2017 年 1 月 17 日。[`arxiv.org/abs/1701.04862v1`](https://arxiv.org/abs/1701.04862v1)。

Arjovsky, Martin, Soumith Chintala, 和 Léon Bottou. 2017 年. “Wasserstein GAN。” 康奈尔大学，统计学，arXiv:1701.07875，2017 年 12 月 6 日。[`arxiv.org/abs/1701.07875v1`](https://arxiv.org/abs/1701.07875v1)。

Bojanowski, Piotr, Armand Joulin, David Lopez-Paz, 和 Arthur Szlam. 2019 年. “优化生成网络的潜在空间。” 康奈尔大学，统计学，arXiv 1717.05776，2019 年 5 月 20 日。[`arxiv.org/abs/1707.05776`](https://arxiv.org/abs/1707.05776)。

Chen, Janet, Su-I Lu, 和 Dan Vekhter. 2020 年. “博弈策略。” 载于 *博弈论*，斯坦福大学计算机科学系，斯坦福，加利福尼亚州。访问日期：2020 年 10 月 6 日。[`cs.stanford.edu/people/eroberts/courses/soco/projects/1998-99/game-theory/Minimax.html`](https://cs.stanford.edu/people/eroberts/courses/soco/projects/1998-99/game-theory/Minimax.html)。

Geitgey, Adam. 2017\. “Machine Learning Is Fun Part 7: Abusing Generative Adversarial Networks to Make 8-bit Pixel Art.” Medium。发表日期：2017 年 2 月 12 日。[`medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7#.v1o6o0dyi`](https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7#.v1o6o0dyi).

Gildenblat, Jacob. 2020\. “KERAS-DCGAN.” GitHub。访问日期：2020 年 10 月 6 日。[`github.com/jacobgil/keras-dcgan`](https://github.com/jacobgil/keras-dcgan).

Goodfellow, Ian J., Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, 和 Yoshua Bengio. 2014\. “Generative Adversarial Networks.” 康奈尔大学，统计学，arXiv:1406.2661，2014 年 6 月 10 日。[`arxiv.org/abs/1406.2661`](https://arxiv.org/abs/1406.2661).

Goodfellow, Ian. 2016\. “NIPS 2016 Tutorial: Generative Adversarial Networks.” 康奈尔大学，计算机科学，arXiv:1701.00160，2016 年 12 月 31 日。[`arxiv.org/abs/1701.00160`](https://arxiv.org/abs/1701.00160).

Karras, Tero, Timo Aila, Samuli Laine, 和 Jaakko Lehtinen. 2018\. “Progressive Growing of GANs for Improved Quality, Stability, and Variation.” 康奈尔大学，计算机科学，arXiv:1710.10196，2018 年 2 月 26 日。[`arxiv.org/abs/1710.10196`](https://arxiv.org/abs/1710.10196).

Myers, Andrew. 2002\. “CS312 Recitation 21: Minimax Search and Alpha-Beta Pruning.” 康奈尔大学，计算机科学系。[`www.cs.cornell.edu/courses/cs312/2002sp/lectures/rec21.htm`](https://www.cs.cornell.edu/courses/cs312/2002sp/lectures/rec21.htm).

Radford, Alec, Luke Metz, 和 Soumith Chintala. 2016\. “Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.” 康奈尔大学，计算机科学，arXiv:1511.06434，2016 年 1 月 7 日。[`arxiv.org/abs/1511.06434`](https://arxiv.org/abs/1511.06434).

Watson, Joel. 2013\. *Strategy: An Introduction to Game Theory*，第 3 版。纽约：W.W. Norton and Company。

## Chapter 23

The Art Story Foundation, 2020\. “Classical, Modern, and Contemporary Movements and Styles.” 艺术故事网站。访问日期：2020 年 10 月 7 日。[`www.theartstory.org/section_movements.htm`](http://www.theartstory.org/section_movements.htm).

Bonaccorso, Giuseppe. 2020\. “Neural_Artistic_Style_Transfer.” GitHub。访问日期：2020 年 10 月 7 日。[`github.com/giuseppebonaccorso/keras_deepdream`](https://github.com/giuseppebonaccorso/keras_deepdream).

Chollet, François. 2017\. *Deep Learning with Python*。纽约：Manning Publications。[`github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.3-neural-style-transfer.ipynb`](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.3-neural-style-transfer.ipynb).

Gatys, Leon A., Alexander S. Ecker, 和 Matthias Bethge. 2015\. “艺术风格的神经算法。” 康奈尔大学，计算机科学，arXiv:1508.06576，2015 年 9 月 2 日。 [`arxiv.org/abs/1508.06576`](https://arxiv.org/abs/1508.06576).

Gatys, Leon A., Alexander S. Ecker, 和 Matthias Bethge. 2016\. “使用卷积神经网络的图像风格迁移。” 载于 *2016 年 IEEE 计算机视觉与模式识别大会论文集* （拉斯维加斯，NV，6 月 27 日至 30 日）。 [`pdfs.semanticscholar.org/7568/d13a82f7afa4be79f09c295940e48ec6db89.pdf`](https://pdfs.semanticscholar.org/7568/d13a82f7afa4be79f09c295940e48ec6db89.pdf).

Jing, Yongcheng, Yezhou Yang, Zunlei Feng, Jingwen Ye, 和 Mingli Song. 2018\. “神经风格迁移：综述。” 康奈尔大学，计算机科学，arXiv:1705.04058v1，2018 年 10 月 30 日。 [`arxiv.org/abs/1705.04058`](https://arxiv.org/abs/1705.04058).

Li, Yanghao, Naiyan Wang, Jiaying Liu, 和 Xiaodi Hou. 2017\. “揭开神经风格迁移的神秘面纱。” 康奈尔大学，计算机科学，arXiv:1701.01036，2017 年 7 月 1 日。 [`arxiv.org/abs/1701.01036`](https://arxiv.org/abs/1701.01036).

Lowensohn, Josh. 2014\. “我让苹果的 QuickType 键盘接管了我的 iPhone。” *The Verge* （博客），2014 年 9 月 17 日。 [`www.theverge.com/2014/9/17/6337105/breaking-apples-quicktype-keyboard`](https://www.theverge.com/2014/9/17/6337105/breaking-apples-quicktype-keyboard).

Majumdar, Somshubra. 2020\. “Titu1994/Neural-Style-Transfer。” GitHub，2020 年 10 月 7 日访问。 [`github.com/titu1994/Neural-Style-Transfer`](https://github.com/titu1994/Neural-Style-Transfer).

Mordvintsev, Alexander, Christopher Olah, 和 Mike Tyka. 2015\. “Inceptionism：深入神经网络的探索。” *Google AI Blog*，2015 年 6 月 17 日。 [`research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html`](https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html).

O’Neil, Cathy. 2016\. *数学毁灭武器*。纽约：百老汇图书。

Orlowski, Jeff. 2020\. *社交困境*。Exposure Labs，Argent Pictures，和 Netflix。2020 年 10 月 7 日访问。 [`www.thesocialdilemma.com/the-film/`](https://www.thesocialdilemma.com/the-film/).

Ruder, Manuel, Alexey Dosovitskiy, 和 Thomas Brox. 2018\. “视频和球形图像的艺术风格迁移。” 康奈尔大学，计算机科学，arXiv:1708.04538，2018 年 8 月 5 日。 [`arxiv.org/abs/1708.04538`](https://arxiv.org/abs/1708.04538).

Simonyan, Karen, 和 Andrew Zisserman. 2020\. “用于大规模视觉识别的非常深的卷积网络。” *视觉几何组* （博客），牛津大学。2020 年 10 月 7 日访问。 [`www.robots.ox.ac.uk/~vgg/research/very_deep/`](http://www.robots.ox.ac.uk/~vgg/research/very_deep/).

Tyka, Mike. 2015 年. “Deepdream/Inceptionism - 回顾。”*Mike Tyka*（博客），2015 年 7 月 21 日。 [`mtyka.github.io/code/2015/07/21/one-month-after-deepdream.html`](https://mtyka.github.io/code/2015/07/21/one-month-after-deepdream.html).

Wikipedia 作者. 2020 年. “风格（视觉艺术）。”维基百科。2020 年 9 月 2 日。 [`en.wikipedia.org/wiki/Style_(visual_arts)`](https://en.wikipedia.org/wiki/Style_(visual_arts)).
