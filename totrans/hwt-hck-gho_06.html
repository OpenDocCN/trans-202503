<html><head></head><body>
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="45" id="Page_45"/>4</span><br/>
<span class="ChapterTitle">Healthy Stalking</span></h1>
</header>
<figure class="opener">
<img src="image_fi/book_art/chapterart.png" alt=""/>
</figure>
<p class="ChapterIntro">Our bouncing servers are silently humming in a datacenter somewhere in Europe. Our attacking infrastructure is eagerly awaiting our first order. Before we unleash the plethora of attack tools that routinely flood the InfoSec Twitter timeline, let’s take a couple of minutes to understand how our target, political consulting firm Gretsch Politico, actually works. What is their business model? Which products and services do they provide? This kind of information will give us a direction to go in and help us narrow down our attack targets. Drawing tangible goals may very well be our first challenge. Their main website (www.gretschpolitico.com) does not exactly help: it is a boiling, bubbling soup of fuzzy marketing keywords that only make sense to the initiated. We’ll start, then, with benign public-facing information.</p>
<h2 id="h1-501263c04-0001"><span epub:type="pagebreak" title="46" id="Page_46"/>Understanding Gretsch Politico</h2>
<p class="BodyFirst">In an effort to better understand this company, let’s dig up every PowerPoint deck and PDF presentation that bears a reference to “Gretsch Politico” (GP). SlideShare (<a href="https://www.slideshare.net/" class="LinkURL">https://www.slideshare.net/</a>) proves to be an invaluable ally in this quest. Many people simply forget to delete their presentations after a talk, or default them to “public access,” giving us a plethora of information to begin our quest for understanding (see <a href="#figure4-1" id="figureanchor4-1">Figure 4-1</a>).</p>
<figure>
<img src="image_fi/501263c04/f04001.png" alt="f04001"/>
<figcaption><p><a id="figure4-1">Figure 4-1</a>: Some Gretsch Politico slides</p></figcaption>
</figure>
<p>SlideShare is but one example of services hosting documents, so we next scour the web looking for resources uploaded to the most popular sharing platforms: Scribd, Google Drive, DocumentCloud, you name it. The following search terms will narrow down your results in most search engines:</p>
<pre><code># Public Google Drive documents
site:docs.google.com "Gretsch politico"

# Documents on documentcloud.org
site:documentcloud.org "Gretsch politico"

# Documents uploaded to Scribd
site:scribd.com "gretschpolitico.com"

# Public PowerPoint presentations
intext:"Gretsch politico" filetype:pptx

# Public PDF documents
intext:"Gretsch politico" filetype:pdf

# .docx documents on GP's website
intext:"Gretsch politico" filetype:docx</code></pre>
<p>Google may be your default search engine, but you may find you achieve better results in others, like Yandex, Baidu, Bing, and so on, since Google tends to observe copyright infringement laws and moderates its search output.</p>
<p><span epub:type="pagebreak" title="47" id="Page_47"/>Another great source of information about a company’s business is metasearch engines. Websites like Yippy and Biznar aggregate information from a variety of general and specialized search engines, giving a nice overview of the company’s recent activity.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	The compilation of resources available at <a href="https://osintframework.com/" class="LinkURL">https://osintframework.com/</a> is a goldmine for any open source intelligence operator. You can easily lose yourself exploring and cross-referencing results between the hundreds of reconnaissance tools and apps listed there.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>From my initial search, many interesting documents pop out, from campaign fund reports mentioning GP to marketing pitches for campaign directors. Manually skimming through this data makes it clear that GP’s core service is building voter profiles based on multiple data inputs. These voter profiles are then studied and fed into an algorithm that decides which pitch is most suitable to lock in a voter.</p>
<h2 id="h1-501263c04-0002">Finding Hidden Relationships</h2>
<p class="BodyFirst">GP’s algorithms mash the data, that much is clear, but where does the data come from? To understand GP, we need to understand its closest partners. Whatever company or medium is delivering all this data must be working closely with GP. Multiple documents hint at the existence of at least two main channels:</p>
<ol class="none">
<li><span class="RunInHead">Data brokers or data management platforms</span>  Companies that sell data gathered from telecom companies, credit card issuers, online stores, local businesses, and many more sources.</li>
<li><span class="RunInHead">Research studies and surveys</span>  It seems that GP reaches out to the population somehow to send out questionnaires and collect opinions.</li>
</ol>
<p>Although GP’s main website barely mentions advertising as a way to reach the public, PDF documents abound with references to a particular advertising platform with tremendous reach, both on social and traditional media websites. There’s no straight link to this advertising platform, but thanks to these selfsame social media websites they are so fond of, we dig out the retweet shown in <a href="#figure4-2" id="figureanchor4-2">Figure 4-2</a> from Jenny, VP of marketing at GP according to her Twitter profile.</p>
<figure>
<img src="image_fi/501263c04/f04002.png" alt="f04002"/>
<figcaption><p><a id="figure4-2">Figure 4-2</a>: A revealing GP retweet</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="48" id="Page_48"/>The link in the tweet innocuously points to an online advertising agency: MXR Ads. They deliver ads on all kinds of websites, charge per thousand impressions (CPM), and go quietly about their business of increasing the internet’s load time.</p>
<p>Short of this excited tweet by Jenny of GP, there is not a single visible link between the two companies; there’s barely even a backlink on Google. So what’s the connection? We quickly solve this mystery by consulting the legal records of the two companies on <a href="https://opencorporates.com/" class="LinkURL">https://opencorporates.com/</a>, a database of companies worldwide and an excellent resource for digging out old company filings, shareholder lists, related entities, and so on. It turns out that MXR Ads and Gretsch Politico share most of the same directors and officers—hell, they even shared the same address a couple of years back.</p>
<p>This kind of intertwined connection can be very profitable for both companies. MXR Ads gathers raw data about people’s engagement with a type of product or brand. They know, for example, that the person bearing the cookie 83bdfd57a5e likes guns and hunting. They transfer this raw data to Gretsch Politico, who analyze it and group it into a data segment of similar profiles labeled “people who like guns.” GP can then design creatives and videos to convince the population labeled “people who like guns” that their right to gun ownership is threatened unless they vote for the right candidate. GP’s client, who is running for office in some capacity, is pleased and starts dreaming about champagne bubble baths at the Capitol, while GP pushes these ads on every media platform with a functioning website. Of course, MXR Ads receives its share of creatives to distribute on its network as well, thus completing the self-feeding ouroboros of profit and desperation. Chilling.</p>
<p>From this close connection we can reasonably suspect that pwning either MXR Ads or GP could prove fatal to <em>both</em> companies. Their sharing of data implies some link or connection that we can exploit to bounce from one to the other. Our potential attack surface just expanded.</p>
<p>Now that we have a first, though very speculative, knowledge of the company’s modus operandi, we can set out to answer some interesting questions:</p>
<ul>
<li>How precise are these data segments? Are they casting a large net targeting, say, all 18- to 50-year-olds, or can they drill down to a person’s most intimate habits?</li>
<li>Who are GP’s clients? Not the pretty ponies they advertise on their slides, like health organizations trying to spread vaccines, but the ugly toads they bury in their databases.</li>
<li>And finally, what do these creatives and ads look like? It might seem like a trivial question, but since they’re supposedly customized to each target population, it is hard to have any level of transparency and accountability.</li>
</ul>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	Zeynep Tufekci has a great TED talk called “We’re Building a Dystopia Just to Make People Click on Ads” about the dystopian reality encouraged by online ads.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p><span epub:type="pagebreak" title="49" id="Page_49"/>In the next few chapters we’ll attempt to answer these questions. The agenda is pretty ambitious, so I hope you are as excited as I am to dive into this strange world of data harvesting and deceit.</p>
<h2 id="h1-501263c04-0003">Scouring GitHub</h2>
<p class="BodyFirst">A recurrent leitmotif in almost every presentation of Gretsch Politico and MXR Ads’ methodology is their investment in research and design and their proprietary machine learning algorithms. Such technology-oriented companies will likely have some source code published in public repositories for various purposes, such as minor contributions to the open source world used as bait to fish for talent, partial documentation of some API, code samples, and so on. We might just find some material that contains an overlooked password or sensitive link to their management platform. Fingers crossed!</p>
<p>Searching public repositories on GitHub is rather easy; you don’t even need to register for a free account. Simply proceed to look for keywords like “Gretsch Politico” and “MXR Ads.” <a href="#figure4-3" id="figureanchor4-3">Figure 4-3</a> shows the results when we search for MXR Ads’ repository.</p>
<figure>
<img src="image_fi/501263c04/f04003.png" alt="f04003"/>
<figcaption><p><a id="figure4-3">Figure 4-3</a>: The MXR Ads GitHub repository</p></figcaption>
</figure>
<p>A single company with 159 public repositories? That seems like a lot. After a cursory inspection, it’s clear only half a dozen of these repos actually belong to either MXR Ads or one of their employees. The rest are simply forks (copied repositories) that happen to mention MXR Ads—for instance, in ad-blocking lists. These forked repositories provide little to no value, so we’ll focus on those half a dozen original repos. Luckily, GitHub offers some patterns to weed out unwanted output. Using the two search prefixes <code>org:</code> and <code>repo:</code>, we can limit the scope of the results to the handful of accounts and repositories we decide are relevant.</p>
<p>We start looking for hardcoded secrets, like SQL passwords, AWS access keys, Google Cloud private keys, API tokens, and test accounts on the company’s advertising platform. Basically, we want anything that might grant us our first beloved access.</p>
<p>We enter these queries in the GitHub search and see what we get:</p>
<pre><code># Sample of GitHub queries

org:mxrAds  password
org:mxrAds  aws_secret_access_key
org:mxrAds  aws_key
<span epub:type="pagebreak" title="50" id="Page_50"/>org:mxrAds  BEGIN RSA PRIVATE KEY
org:mxrAds  BEGIN OPENSSH PRIVATE KEY
org:mxrAds  secret_key
org:mxrAds  hooks.slack.com/services
org:mxrAds  sshpass -p
org:mxrAds  sq0csp
org:mxrAds  apps.googleusercontent.com
org:mxrAds  extension:pem key</code></pre>
<p>The annoying limitation of GitHub’s search API is that it filters out special characters. When we search for “aws_secret_access_key,” GitHub will return any piece of code matching any of the four individual words (aws, secret, access, or key). This is probably the only time I sincerely miss regular expressions.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	The GitHub alternative Bitbucket does not provide a similar search bar. It even specifically instructs search engines to skip over URLs containing code changes (known as <em>commits</em>). Not to worry: <a href="http://Yandex.ru" class="LinkURL">Yandex.ru</a><em> </em>has the nasty habit of disregarding these rules and will gladly show you every master tree and commit history on Bitbucket public repos using something like <code>site:bitbucket.org inurl:master</code>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Keep in mind that this phase of the recon is not only about blindly grabbing dangling passwords; it’s also about discovering URL and API endpoints, and acquainting ourselves with the technological preferences of the two companies. Every team has some dogma about which framework to use and which language to work with. This information might later help us adjust our payloads.</p>
<p>Unfortunately, preliminary GitHub search queries did not return anything worthy, so we bring out the big guns and bypass GitHub limitations altogether. Since we’re only targeting a handful of repositories, we’ll download the entire repositories to disk to unleash the full wrath of good ol’ grep!</p>
<p>We’ll start with the interesting list of hundreds of regular expression (regex) patterns defined in <code>shhgit</code>, a tool specifically designed to look for secrets in GitHub, from regular passwords to API tokens (<a href="https://github.com/eth0izzle/shhgit/" class="LinkURL">https://github.com/eth0izzle/shhgit/</a>). The tool itself is also very useful for defenders, as it flags sensitive data pushed to GitHub by listening for webhook events—a <em>webhook</em> is a call to a URL following a given event. In this case, GitHub sends a POST request to a predefined web page every time a regex matches a string in the code submitted.</p>
<p>We rework the list of patterns, which you can find at <a href="https://www.hacklikeapornstar.com/secret_regex_patterns.txt" class="LinkURL">https://www.hacklikeapornstar.com/secret_regex_patterns.txt</a>, to make it grep-friendly. Then we download all the repos:</p>
<pre><code>root@Point1:~/# <b>while read p; do \</b>
<b>git clone www.github.com/MXRads/$p\</b>
<b>done &lt;list_repos.txt</b></code></pre>
<p><span epub:type="pagebreak" title="51" id="Page_51"/>And start the search party:</p>
<pre><code>root@Point1:~/# <b>curl -vs</b>
https://gist.github.com/HackLikeAPornstar/ff2eabaa8e007850acc158ea3495e95f
&gt; regex_patterns.txt

root@Point1:~/# <b>egrep -Ri -f regex_patterns.txt *</b></code></pre>
<p>This quick-and-dirty command will search through each file in the downloaded repositories. However, since we are dealing with Git repositories, <code>egrep</code> will omit previous versions of the code that are compressed and hidden away in Git’s internal filesystem structure (the <em>.git</em> folder). These old file versions are of course the most valuable assets! Think about all the credentials pushed by mistake or hardcoded in the early phases of a project. The famous line “It’s just a temporary fix” has never been more fatal than in a versioned repository.</p>
<p>The <code>git</code> command provides the necessary tools we’ll use to walk down the commit memory lane: <code>git rev-list</code>, <code>git log</code>, <code>git revert</code>, and the most relevant to us, <code>git grep</code>. Unlike the regular <code>grep</code>, <code>git grep</code> expects a commit ID, which we provide using <code>git</code> <code>rev-list</code>. Chaining the two commands using <code>xargs</code> (extended arguments), we can retrieve all the commit IDs (all changes ever made to the repo) and search each one for interesting patterns using <code>git grep</code>:</p>
<pre><code>root@Point1:~/# <b>git rev-list --all | xargs git grep "BEGIN [EC|RSA|DSA|OPENSSH] PRIVATE KEY"</b></code></pre>
<p>We could also have automated this search using a bash loop or completely relied on a tool like Gitleaks (<a href="https://github.com/zricethezav/gitleaks/" class="LinkURL">https://github.com/zricethezav/gitleaks/</a>) or truffleHog (<a href="https://github.com/dxa4481/truffleHog/" class="LinkURL">https://github.com/dxa4481/truffleHog/</a>) that takes care of sifting through all the commit files.</p>
<p>After a couple of hours of twisting that public source code in every fashion possible, one thing becomes clear: there seems to be no hardcoded credentials anywhere. Not even a fake dummy test or test account to boost our enthusiasm. Either MXR Ads and GP are good at concealment or we are just not that lucky. No matter, we’ll move on!</p>
<p>One feature of GitHub that most people tend to overlook is the ability to share snippets of code on <a href="https://gist.github.co" class="LinkURL">https://gist.github.co</a>, a service also provided by <a href="https://pastebin.com/" class="LinkURL">https://pastebin.com/</a><em>.</em> These two websites, and others such as <a href="https://codepen.io/" class="LinkURL">https://codepen.io/</a>, often contain pieces of code, database extracts, buckets, configuration files, and anything that developers want to exchange in a hurry. We’ll scrape some results from these sites using some search engine commands:</p>
<pre><code># Documents on gist.github.com
site:gist.github.com "mxrads.com"

# Documents on Pastebin
site:pastebin.com "mxrads.com"

# Documents on JustPaste.it
site:justpaste.it "mxrads.com"

<span epub:type="pagebreak" title="52" id="Page_52"/># Documents on PasteFS
site:pastefs.com "mxrads.com"

# Documents on CodePen
site:codepen.io "mxrads.com"</code></pre>
<p>One search yields the result shown in <a href="#figure4-4" id="figureanchor4-4">Figure 4-4</a>.</p>
<figure>
<img src="image_fi/501263c04/f04004.png" alt="f04004"/>
<figcaption><p><a id="figure4-4">Figure 4-4</a>: A snippet of an MXR Ads logfile</p></figcaption>
</figure>
<p>This seems to be an extract of a logfile just hanging in a public Gist, available for everyone to see. Isn’t that just lovely? Sadly, no critical information is immediately available, but we do get these unique URLs:</p>
<ul>
<li>format-true-v1.qa.euw1.mxrads.com</li>
<li>dash-v3-beta.gretschpolitico.com</li>
<li>www.surveysandstats.com/9df6c8db758b35fa0f1d73. . .</li>
</ul>
<p>We test these in a browser. The first link times out, and the second one redirects to a Google authentication page (see <a href="#figure4-5" id="figureanchor4-5">Figure 4-5</a>).</p>
<figure>
<img src="image_fi/501263c04/f04005.png" alt="f04005"/>
<figcaption><p><a id="figure4-5">Figure 4-5</a>: Gretsch Politico sign-in link found in the logfile snippet</p></figcaption>
</figure>
<p>Gretsch Politico evidently subscribes to Google Workspace (formerly G Suite) apps to manage its corporate emails and likely its user directory and internal documents. We’ll keep that in mind for later when we start scavenging for data.</p>
<p>The third URL, pointing to <a href="#figure4-6" id="figureanchor4-6">Figure 4-6</a>, is promising.</p>
<span epub:type="pagebreak" title="53" id="Page_53"/><figure>
<img src="image_fi/501263c04/f04006.png" alt="f04006"/>
<figcaption><p><a id="figure4-6">Figure 4-6</a>: Link to an MXR Ad survey found in the logfile snippet</p></figcaption>
</figure>
<p>This must be one of these surveys MXR Ads uses to gather seemingly harmless information about people. Attempting to pwn MXR Ads or Gretsch Politico through one of their pernicious forms is quite tempting, but we are still in the midst of our reconnaissance work, so let’s just note this for a later attempt.</p>
<h2 id="h1-501263c04-0004">Pulling Web Domains</h2>
<p class="BodyFirst">Passive reconnaissance has not yielded us many entry points so far. I believe it’s time we seriously start digging up all the domains and subdomains related to MXR Ads and Gretsch Politico. I’m sure we can find so much more than the three measly websites in a forgotten Gist paste. Hopefully we’ll land on a forlorn website with a sneaky vulnerability welcoming us inside.</p>
<p>We’ll begin our search by first checking certificate logs for subdomains.</p>
<h3 id="h2-501263c04-0001">From Certificates</h3>
<p class="BodyFirst">Censys (<a href="https://censys.io/" class="LinkURL">https://censys.io/</a>) is a tool that routinely scans certificate logs to ingest all newly issued TLS certificates, and it’s number one on any pentester’s domain discovery tool list. Upon their issuance by a certificate authority, certificates are pushed to a central repository called a <em>certificate log</em>. This repository keeps a binary tree of all certificates, where each node is the hash of its child nodes, thus guaranteeing the integrity of the entire chain. It’s roughly the same principle followed by the Bitcoin blockchain. In theory, all issued TLS certificates should be publicly published to detect domain spoofing, typo-squatting, homograph attacks, and other mischievous ways to deceive and redirect users.</p>
<p>We can search these certificate logs to eke out any new registrations matching certain criteria, like “mxr ads.” The ugly side of this beautiful canvas is that all domains and subdomain names are openly accessible online. Secret applications with little security hiding behind obscure domains are therefore easily exposed. Tools like Censys and <em>crt.sh</em> explore these certificate logs and help speed up subdomain enumeration by at least an order of magnitude—a cruel reminder that even the sweetest grapes can hide the most bitter seeds. In <a href="#figure4-7" id="figureanchor4-7">Figure 4-7</a> we use Censys to search for subdomains of gretschpolitico.com.</p>
<span epub:type="pagebreak" title="54" id="Page_54"/><figure>
<img src="image_fi/501263c04/f04007.png" alt="f04007"/>
<figcaption><p><a id="figure4-7">Figure 4-7</a>: Looking for subdomains with Censys</p></figcaption>
</figure>
<p>So much for transparency. It seems that GP did not bother registering subdomain certificates and has instead opted for a <em>wildcard certificate</em>: a generic certificate that matches any subdomain. One certificate to rule them all. Whether this is a brilliant security move or pure laziness, the fact is, we’re no further than the top domain. We try other top-level domains in Censys—gretschpolitico.io, mxrads.tech, mxrads.com, gretschpolitico.news, and so forth—but come up equally empty-handed. Our list of domains grew by a whopping big fat zero . . . but do not despair! We have other tricks up our collective sleeves.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	Of course, wildcard certificates present another security problem: they are a brazen single point of failure. Should we stumble upon the private key while roaming the company’s network, we could intercept the communication flow of all applications using that same parent domain.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2-501263c04-0002">By Harvesting the Internet</h3>
<p class="BodyFirst">If certificates are not the way to gather subdomains, then maybe the internet can lend us a helping hand. Sublist3r is a great and easy-to-use tool that harvests subdomains from various sources: search engines, PassiveDNS, even VirusTotal. First, we fetch the tool from the official repository and install requirements:</p>
<pre><code>root@Point1:~/# <b>git clone https://github.com/aboul3la/Sublist3r</b>
root@Point1:sub/# <b>python -m pip install -r requirements.txt</b></code></pre>
<p>Then we proceed to search for subdomains, as shown in <a href="#listing4-1" id="listinganchor4-1">Listing 4-1</a>.</p>
<pre><code>root@Point1:~/# <b>python sublist3r.py -d gretschpolitico.com</b>
[-] Enumerating subdomains now for gretschpolitico.com
[-] Searching now in Baidu..
[-] Searching now in Yahoo..
[-] Searching now in Netcraft..
[-] Searching now in DNSdumpster..
--<var>snip</var>--
[-] Searching now in ThreatCrowd..
[-] Searching now in PassiveDNS..

[-] Total Unique Subdomains Found: 12
dashboard.gretschpolitico.com
<span epub:type="pagebreak" title="55" id="Page_55"/>m.gretschpolitico.com
--<var>snip</var>--</code></pre>
<p class="CodeListingCaption"><a id="listing4-1">Listing 4-1</a>: Enumerating domains with sublist3r </p>
<p>We’ve found 12 subdomains, so that’s encouraging. I bet we’d have even more luck with mxrads.com. They are, after all, a media company. However, it can get boring to use the same tools and methods repeatedly. For the mrxads.com domain, let’s use a different tool to perform a classic brute-force attack using well-known subdomain keywords like staging.mxrads.com, help.mxrads.com, dev.mxrads.com, and so on. There are a few tools we can choose from for the job.</p>
<p>Amass (<a href="https://github.com/OWASP/Amass/" class="LinkURL">https://github.com/OWASP/Amass/</a>) from the Open Web Application Security Project (OWASP) is written in Golang and cleverly uses goroutines to parallelize the load of DNS queries. Whereas most other Python tools rely on the system’s DNS resolver to retrieve domains by calling functions like <code>socket.gethostname</code>, Amass crafts DNS queries from scratch and sends them to various DNS servers, thus avoiding the bottleneck caused by using the same local resolver. However, Amass is bloated with so many other colorful features, like visualizations and 3D graphs, that it may feel like wielding a 10-pound hammer to scratch an itch on your back. Tempting, but there are lighter alternatives.</p>
<p>A less mediatized yet very powerful tool that I highly recommend is Fernmelder<em> </em>(<a href="https://github.com/stealth/fernmelder/" class="LinkURL">https://github.com/stealth/fernmelder/</a>). It’s written in C, is barely a few hundred lines of code, and is probably the most efficient DNS bruteforcer I have tried lately. Fernmelder takes two inputs: a list of candidate DNS names and the IPs of DNS resolvers to use. This is what we’ll use.</p>
<p>First, we create our list of possible DNS names using some <code>awk</code> magic applied to a public subdomain wordlist, as shown in <a href="#listing4-2" id="listinganchor4-2">Listing 4-2</a>. Daniel Miessler’s SecLists is a good start, for instance:<em> </em><a href="https://github.com/danielmiessler/SecLists/" class="LinkURL">https://github.com/danielmiessler/SecLists/</a><em>.</em></p>
<pre><code>root@Point1:~/# <b>awk '{print $1".mxrads.com"}' top-10000.txt &gt; sub_mxrads.txt</b>
root@Point1:~/# <b>head sub_mxrads.txt</b>
test.mxrads.com
demo.mxrads.com
video.mxrads.com
<var>--snip--</var></code></pre>
<p class="CodeListingCaption"><a id="listing4-2">Listing 4-2</a>: Creating a list of potential MXR Ads subdomains</p>
<p>This gives us a few thousand potential subdomain candidates to try. As for the second input, you can borrow the DNS resolvers found at the Fernmelder repo, as shown in <a href="#listing4-3" id="listinganchor4-3">Listing 4-3</a>.</p>
<pre><code>root@Point1:~/# <b>git clone https://github.com/stealth/fernmelder</b>
root@Point1:~fern/# <b>make</b>

root@Point1:~fern/#<b>cat sub_mxr.txt | ./fernmelder -4 -N 1.1.1.1 \</b>
<b>-N 8.8.8.8 \</b>
<b>-N 64.6.64.6 \</b>
<span epub:type="pagebreak" title="56" id="Page_56"/><b>-N 77.88.8.8 \</b>
<b>-N 74.82.42.42 \</b>
<b>-N 1.0.0.1 \</b>
<b>-N 8.8.4.4 \</b>
<b>-N 9.9.9.10 \</b>
<b>-N 64.6.65.6 \</b>
<b>-N 77.88.8.1 \</b>
<b>-A</b></code></pre>
<p class="CodeListingCaption"><a id="listing4-3">Listing 4-3</a>: Resolving our subdomain candidates to see which are real</p>
<p>Be careful adding new resolvers, as some servers tend to play dirty and will return a default IP when resolving a nonexistent domain rather than the standard <code>NXDOMAIN</code> reply. The <code>-A</code> option at the end of the command hides any unsuccessful domain resolution attempts.</p>
<p>Results from <a href="#listing4-3">Listing 4-3</a> start pouring in impressively fast. Of the thousand subdomains we tried resolving, a few dozen responded with valid IP addresses:</p>
<pre><code>Subdomain              TTL Class   Type   Rdata
electron.mxrads.net.   60  IN      A      18.189.47.103
cti.mxrads.net.        60  IN      A      18.189.39.101
maestro.mxrads.net.    42  IN      A      35.194.3.51
files.mxrads.net.      5   IN      A      205.251.246.98
staging3.mxrads.net.   60  IN      A      10.12.88.32
git.mxrads.net.        60  IN      A      54.241.52.191
errors.mxrads.net.     59  IN      A      54.241.134.189
jira.mxrads.net.       43  IN      A      54.232.12.89
--<var>snip</var>--</code></pre>
<p>Watching these IP addresses roll by on the screen is mesmerizing. Each entry is a door waiting to be subtly engineered or forcefully raided to grant us access. This is why this reconnaissance phase is so important: it affords us the luxury of choice, with over 100 domains belonging to both organizations!</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	Check out Altdns, an interesting tool that leverages Markov chains to form predictable subdomain candidates: <a href="https://github.com/infosec-au/altdns/" class="LinkURL">https://github.com/infosec-au/altdns/</a>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1-501263c04-0005">Discovering the Web Infrastructure Used</h2>
<p class="BodyFirst">The traditional approach to examining these sites would be to run WHOIS queries on these newly found domains, from which we can figure out the IP segment belonging to the company. With that we can scan for open ports in that range using Nmap or Masscan, hoping to land on an unauthenticated database or poorly protected Windows box. We try WHOIS queries on a few subdomains:</p>
<pre><code>root@Point1:~/# <b>whois 54.232.12.89</b>
NetRange:       54.224.0.0 - 54.239.255.255
CIDR:           54.224.0.0/12
NetName:        AMAZON-2011L
<span epub:type="pagebreak" title="57" id="Page_57"/>OrgName:        Amazon Technologies Inc.
OrgId:          AT-88-Z</code></pre>
<p>However, looking carefully at this list of IP addresses, we quickly realize that they have nothing to do with Gretsch Politico or MXR Ads. It turns out that most of the subdomains we collected are running on AWS infrastructure. This is an important conclusion. Most internet resources on AWS, like load balancers, content distribution networks, S3 buckets, and so on, regularly rotate their IP addresses.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	A <em>content distribution network (CDN)</em> is a set of geographically distributed proxies that help decrease enduser latency and achieve high availability. They usually provide local caching, point users to the closest server, route packets through the fastest path, and offer other services. Cloudflare, Akamai, and AWS CloudFront are some of the key players.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>That means that if we feed this list of IPs to Nmap and the port scan drags on longer than a couple of hours, the addresses will have already been assigned to another customer and the results will no longer be relevant. Of course, companies can always attach a fixed IP to a server and directly expose their application, but that’s like intentionally dropping an iron ball right on your little toe. Nobody is that masochistic.</p>
<p>Over the last decade, we hackers have gotten into the habit of only scanning IP addresses and skipping DNS resolution in order to gain a few seconds, but when dealing with a cloud provider, this could prove fatal. Instead, we should scan domain names; that way, the name resolution will be performed closer to the actual scan to guarantee its integrity.</p>
<p>That’s what we will do next. We launch a fast Nmap scan on all the domain names we’ve gathered so far to look for open ports:</p>
<pre><code>root@Point1:~/# <b>nmap -F -sV -iL domains.txt -oA fast_results</b></code></pre>
<p>We focus on the most common ports using <code>-F</code>, grab the component’s version using <code>-sV</code>, and save the results in XML, RAW, and text formats with <code>-oA</code>. This scan may take a few minutes, so while waiting for it to finish, we’ll turn our attention to the actual content of the hundreds of domains and websites we found belonging to MXR Ads and Gretsch Politico.</p>
<h2 id="h1-501263c04-0006">Resources</h2>
<ul>
<li>Find an example of leaked credentials by searching for a bug report of a researcher finding API tokens in a Starbucks-owned repo: <a href="https://hackerone.com/reports/716292/" class="LinkURL">https://hackerone.com/reports/716292/</a>.</li>
<li>Search for Juri Strumpflohner’s tutorial at <a href="https://juristr.com/" class="LinkURL">https://juristr.com/</a> if you’re not familiar with Git’s internals.</li>
</ul>
</section>
</body></html>