- en: '9'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '9'
- en: HARD PROBLEMS
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 难题
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common01.jpg)'
- en: Hard computational problems are the cornerstone of modern cryptography. They’re
    problems that are simple to describe yet practically impossible to solve. These
    are problems for which even the best algorithm wouldn’t find a solution before
    the sun burns out.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 困难的计算问题是现代密码学的基石。它们是描述起来简单，但实际上几乎不可能解决的问题。这些问题即使是最好的算法，也无法在太阳熄灭之前找到解决方案。
- en: In the 1970s, the rigorous study of hard problems gave rise to a new field of
    science called computational complexity theory, which would dramatically impact
    cryptography and many other fields, including economics, physics, and biology.
    In this chapter, I’ll give you the conceptual tools from complexity theory necessary
    to understand the foundations of cryptographic security, and I’ll introduce the
    hard problems behind public-key schemes such as RSA encryption and Diffie–Hellman
    key agreement. We’ll touch on some deep concepts, but I’ll minimize the technical
    details and only scratch the surface. Still, I hope you’ll see the beauty in the
    way cryptography leverages computational complexity theory to maximize security.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在1970年代，对难题的严格研究催生了一个新的科学领域——计算复杂性理论，它将对密码学以及许多其他领域产生深远影响，包括经济学、物理学和生物学。在本章中，我将为你提供理解密码安全基础所需的复杂性理论概念工具，并介绍公共密钥方案（如RSA加密和Diffie–Hellman密钥协议）背后的难题。我们将涉及一些深奥的概念，但我会尽量减少技术细节，只做表面探讨。不过，我希望你能看到密码学如何利用计算复杂性理论来最大化安全性之美。
- en: Computational Hardness
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算难度
- en: A computational problem is a question that can be answered by doing enough computation,
    for example, “Is 2017 a prime number?” or “How many *i* letters are there in *incomprehensibilities*?”
    *Computational hardness* is the property of computational problems for which there
    is no algorithm that will run in a reasonable amount of time. Such problems are
    also called *intractable problems* and are often practically impossible to solve.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 计算问题是通过足够的计算来回答的问题，例如，“2017是质数吗？”或“在*incomprehensibilities*中有多少个*i*字母？”*计算难度*是指某些计算问题没有任何算法能在合理的时间内运行完成。这类问题也被称为*难解问题*，通常在实践中几乎不可能解决。
- en: Surprisingly, computational hardness is independent of the type of computing
    device used, be it a general-purpose CPU, an integrated circuit, or a mechanical
    Turing machine. Indeed, one of the first findings of computational complexity
    theory is that all computing models are equivalent. If a problem can be solved
    efficiently with one computing device, it can be solved efficiently on any other
    device by porting the algorithm to the other device’s language—an exception is
    quantum computers, but these do not exist (yet). The upshot is that we won’t need
    to specify the underlying computing device or hardware when discussing computational
    hardness; instead, we’ll just discuss algorithms.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，计算难度与所使用的计算设备类型无关，无论是通用CPU、集成电路，还是机械图灵机。事实上，计算复杂性理论的最初发现之一是，所有计算模型都是等效的。如果一个问题能在某个计算设备上高效解决，那么通过将算法移植到其他设备的语言上，也能在任何其他设备上高效解决——量子计算机是一个例外，但它们尚未问世（至少目前还没有）。因此，在讨论计算难度时，我们不需要指定底层计算设备或硬件，而是直接讨论算法。
- en: To evaluate hardness, we’ll first find a way to measure the complexity of an
    algorithm, or its running time. We’ll then categorize running times as hard or
    easy.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估难度，我们首先需要找到一种衡量算法复杂度或运行时间的方法。然后，我们将运行时间分为困难或容易。
- en: '*Measuring Running Time*'
  id: totrans-9
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*运行时间的测量*'
- en: Most developers are familiar with *computational complexity*, or the approximate
    number of operations done by an algorithm as a function of its input size. The
    size is counted in bits or in the number of elements taken as input. For example,
    take the algorithm shown in [Listing 9-1](ch09.xhtml#ch9list1), written in pseudocode.
    It searches for a value, *x*, within an array of *n* elements and then returns
    its index position.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数开发者都熟悉*计算复杂度*，即算法执行的操作次数，通常是输入大小的函数。大小通常以比特数或输入元素的数量来衡量。例如，以下是[清单9-1](ch09.xhtml#ch9list1)中展示的伪代码。它在包含*n*个元素的数组中查找一个值*x*，然后返回其索引位置。
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Listing 9-1: A simple search algorithm, written in pseudocode, of complexity
    linear with respect to the array length* n. *The algorithm returns the index where
    the value* x *is found in [1,* n*], or 0 if* x *isn’t found in the array.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表9-1：一个简单的搜索算法，采用伪代码编写，复杂度与数组长度*n*成线性关系。*该算法返回在[1，*n*]中找到的值*x*的索引，如果找不到*x*，则返回0。*'
- en: In this algorithm, we use a `for` loop to find a specific value, *x*, by iterating
    through an array. On each iteration, we assign the variable *i* a number starting
    with 1\. Then we check whether the value of position *i* in `array` is equal to
    the value of *x*. If it is, we return the position *i*. Otherwise, we increment
    *i* and try the next position until we reach *n*, the length of the array, at
    which point we return 0.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个算法中，我们使用`for`循环通过遍历数组来查找特定值*x*。每次迭代时，我们将变量*i*赋值为从1开始的数字。然后我们检查`array`中位置*i*的值是否等于*x*的值。如果是，我们返回位置*i*。否则，我们增加*i*并尝试下一个位置，直到我们到达*n*，即数组的长度，此时返回0。
- en: 'For this kind of algorithm, we count complexity as the number of iterations
    of the `for` loop: 1 in the best case (if *x* is equal to `array[1]`), *n* in
    the worst case (if *x* is equal to `array[n]` or if *x* is not in found in `array`),
    and *n*/2 on average if *x* is randomly distributed in one of the *n* cells of
    the array. With an array 10 times as large, the algorithm will be 10 times as
    slow. Complexity is therefore proportional to *n*, or “linear” in *n*. A complexity
    linear in *n* is considered fast, as opposed to complexities exponential in *n*.
    Although processing larger input values will be slower, it will make a difference
    of at most just seconds for most practical uses.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种算法，我们将复杂度定义为`for`循环的迭代次数：最佳情况为1（如果*x*等于`array[1]`），最坏情况为*n*（如果*x*等于`array[n]`，或者*x*在`array`中找不到），平均情况下为*n*/2（如果*x*随机分布在数组的*n*个单元格中的某一个）。如果数组的大小是原来的10倍，算法的速度将变慢10倍。因此，复杂度与*n*成正比，或者说是*n*的“线性”复杂度。*n*的线性复杂度被认为是快速的，与*n*呈指数增长的复杂度相对。尽管处理更大输入值会变慢，但对于大多数实际应用来说，差异通常只有几秒钟。
- en: 'But many useful algorithms are slower than that and have a complexity higher
    than linear. The textbook example is sorting algorithms: given a list of *n* values
    in a random order, you’ll need on average *n* × log *n* basic operations to sort
    the list, which is sometimes called *linearithmic complexity*. Since *n* × log
    *n* grows faster than *n*, sorting speed will slow down faster than proportionally
    to *n*. Yet such sorting algorithms will remain in the realm of *practical* computation,
    or computation that can be carried out in a reasonable amount of time.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 但许多有用的算法比这慢，并且具有高于线性复杂度的复杂度。教科书中的例子是排序算法：给定一组随机排列的*n*个值，通常需要*n* × log *n*次基本操作来排序该列表，这通常被称为*线性对数复杂度*。由于*n*
    × log *n*的增长速度快于*n*，排序的速度将比*n*的比例增长得更慢。然而，这些排序算法仍然属于*实用*计算领域，或者是能够在合理时间内完成的计算。
- en: 'At some point, we’ll hit the ceiling of what’s feasible even for relatively
    small input lengths. Take the simplest example from cryptanalysis: the brute-force
    search for a secret key. Recall from [Chapter 1](ch01.xhtml#ch1) that given a
    plaintext *P* and a ciphertext *C* = **E**(*K*, *P*), it takes at most 2^(*n*)
    attempts to recover an *n*-bit symmetric key because there are 2^(*n*) possible
    keys—an example of a complexity that grows exponentially. For complexity theorists,
    *exponential complexity* means a problem that is practically impossible to solve,
    because as *n* grows, the effort very rapidly becomes infeasible.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些时候，我们将遇到即使对于相对较小的输入长度也无法完成的上限。以密码分析中的最简单例子为例：暴力破解一个密钥。从[第1章](ch01.xhtml#ch1)回顾，当给定明文*P*和密文*C*
    = **E**(*K*, *P*)时，恢复一个*n*位对称密钥最多需要2^(*n*)次尝试，因为存在2^(*n*)种可能的密钥——这是一个增长呈指数级的复杂度的例子。对于复杂度理论家来说，*指数复杂度*意味着一个问题几乎不可能解决，因为随着*n*的增长，努力迅速变得不可行。
- en: 'You may object that we’re comparing oranges and apples here: in the `search()`
    function in [Listing 9-1](ch09.xhtml#ch9list1), we counted the number of `if (array[i]
    == x)` operations, whereas key recovery counts the number of encryptions, each
    thousands of times slower than a single `==` comparison. This inconsistency can
    make a difference if you compare two algorithms with very similar complexities,
    but most of the time it won’t matter because the number of operations will have
    a greater impact than the cost of an individual operation. Also, complexity estimates
    ignore *constant factors*: when we say that an algorithm takes time in the order
    of *n*³ operations (which is *quadratic com**plexity*), it may actually take 41
    × *n*³ operations, or 12345 × *n*³ operations—but again, as *n* grows, the constant
    factors lose significance to the point that we can ignore them. Complexity analysis
    is about theoretical hardness as a function of the input size; it doesn’t care
    about the exact number of CPU cycles it will take on your computer.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会反驳，我们这里比较的是苹果和橘子：在[清单9-1](ch09.xhtml#ch9list1)中的 `search()` 函数里，我们统计了 `if
    (array[i] == x)` 操作的次数，而密钥恢复则统计了加密次数，每次加密的速度比一次 `==` 比较慢几千倍。若比较两种非常相似复杂度的算法，这种不一致可能会有所不同，但大多数时候它无关紧要，因为操作次数对结果的影响要大于单个操作的成本。而且，复杂度估算忽略了
    *常数因子*：当我们说一个算法需要大约 *n*³ 次操作时间（即 *二次复杂度*），它实际上可能需要 41 × *n*³ 次操作，或者 12345 × *n*³
    次操作——但随着 *n* 增长，常数因子的影响会变得微不足道，以至于我们可以忽略它们。复杂度分析关注的是输入大小函数的理论难度；它不关心在你的计算机上需要多少个
    CPU 周期。
- en: You’ll often find the *O*() notation (“big O”) used to express complexities.
    For example, *O*(*n*³) means that complexity grows no faster than *n*³, ignoring
    potential constant factors. *O*() denotes the *upper bound* of an algorithm’s
    complexity. The notation *O*(1) means that an algorithm runs in *constant time*—that
    is, the running time doesn’t depend on the input length! For example, the algorithm
    that determines an integer’s parity by looking at its least significant bit (LSB)
    and returning “even” if it’s zero and “odd” otherwise will do the same thing at
    the same cost whatever the integer’s length.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你经常会看到 *O*() 符号（“大O”）用于表示复杂度。例如，*O*(*n*³) 意味着复杂度增长不超过 *n*³，忽略潜在的常数因子。*O*() 表示算法复杂度的
    *上界*。符号 *O*(1) 意味着一个算法在 *常数时间* 内运行——也就是说，运行时间不依赖于输入的长度！例如，判断一个整数的奇偶性的算法，通过检查其最低有效位（LSB），如果是零则返回“偶数”，否则返回“奇数”，无论整数的长度如何，它都会以相同的代价做同样的事情。
- en: To see the difference between linear, quadratic, and exponential time complexities,
    look at how complexity grows for *O*(*n*) (linear) versus *O*(*n*²) (quadratic)
    versus *O*(2^(*n*)) (exponential) in [Figure 9-1](ch09.xhtml#ch9fig1).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看线性、二次和指数时间复杂度之间的区别，可以参见[图9-1](ch09.xhtml#ch9fig1)，比较 *O*(*n*)（线性）、*O*(*n*²)（二次）与
    *O*(2^(*n*))（指数）的复杂度增长。
- en: '![image](../images/f09-01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f09-01.jpg)'
- en: '*Figure 9-1: Growth of exponential, quadratic, and linear complexities, from
    the fastest to the slowest growing*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9-1：指数、二次和线性复杂度的增长，从最快到最慢增长*'
- en: Exponential complexity means the problem is practically impossible to solve,
    and linear complexity means the solution is feasible, whereas quadratic complexity
    is somewhere between the two.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 指数复杂度意味着问题几乎不可能解决，而线性复杂度意味着解决方案是可行的，二次复杂度介于两者之间。
- en: '*Polynomial vs. Superpolynomial Time*'
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*多项式时间与超多项式时间*'
- en: The *O*(*n*²) complexity discussed in the last section (the middle curve in
    [Figure 9-1](ch09.xhtml#ch9fig1)) is a special case of the broader class of polynomial
    complexities, or *O*(*n*^(*k*)), where *k* is some fixed number such as 3, 2.373,
    7/10, or the square root of 17\. Polynomial-time algorithms are eminently important
    in complexity theory and in crypto because they’re the very definition of practically
    feasible. When an algorithm runs in *polynomial time*, or *poly**time* for short,
    it will complete in a decent amount of time even if the input is large. That’s
    why polynomial time is synonymous with “efficient” for complexity theorists and
    cryptographers.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节讨论的 *O*(*n*²) 复杂度（[图9-1](ch09.xhtml#ch9fig1)中的中间曲线）是更广泛的多项式复杂度类别的特例，或者 *O*(*n*^(*k*)),
    其中 *k* 是一些固定数字，如 3、2.373、7/10 或 17 的平方根。多项式时间算法在复杂度理论和密码学中非常重要，因为它们是实际可行性的定义。当一个算法在
    *多项式时间*（或简称 *poly**time*）内运行时，即使输入量很大，它也能在合理的时间内完成。这就是为什么多项式时间对于复杂度理论学家和密码学家来说是“高效”的代名词。
- en: In contrast, algorithms running in *superpolynomial* *time*—that is, in *O*(*f*(*n*)),
    where *f*(*n*) is any function that grows faster than any poly­nomial—are viewed
    as impractical. I’m saying superpolynomial, and not just exponential, because
    there are complexities in between polynomial and the well-known exponential complexity
    *O*(2^(*n*)), such as *O*(*n*^(log(*n*))), as [Figure 9-2](ch09.xhtml#ch9fig2)
    shows.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，运行在*超多项式* *时间*中的算法——即在*O*(*f*(*n*))中，其中*f*(*n*)是任何比任何多项式增长得更快的函数——被认为是不可行的。我这里说的是超多项式，而不仅仅是指数，因为在多项式和著名的指数复杂度*O*(2^(*n*))之间还有一些复杂度，例如*O*(*n*^(log(*n*)))，如[图
    9-2](ch09.xhtml#ch9fig2)所示。
- en: '![image](../images/f09-02.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f09-02.jpg)'
- en: '*Figure 9-2: Growth of the* 2^n, n^(log(n)), *and* n² *functions, from the
    fastest to the slowest growing*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-2：2^n、n^(log(n)) 和 n² 函数的增长，从增长最快到最慢*'
- en: '**NOTE**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Exponential complexity* O(2^n) *is not the worst you can get. Some complexities
    grow even faster and thus characterize algorithms even slower to compute—for example,
    the complexity* O(n^n) *or the* exponential factorial O(n^(f(n – 1))), *where
    for any* x, *the function* f *is here recursively defined as* f(x) = x^(f(x –
    1)). *In practice, you’ll never encounter algorithms with such preposterous complexities.*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*指数复杂度* O(2^n) *并不是最差的情况。有些复杂度增长得更快，从而使得算法计算变得更慢——例如，复杂度* O(n^n) *或* 指数阶乘 O(n^(f(n
    – 1)))，*其中对于任何* x，*函数* f *通过递归定义为* f(x) = x^(f(x – 1))。*实际上，你永远不会遇到如此荒谬复杂度的算法。*'
- en: '*O*(*n*²) or *O*(*n*³) may be efficient, but *O*(*n*^(99999999999)) obviously
    isn’t. In other words, polytime is fast as long as the exponent isn’t too large.
    Fortunately, all polynomial-time algorithms found to solve actual problems do
    have small exponents. For example, *O*(*n*^(1.465)) is the time for multiplying
    two *n*-bit integers, or *O*(*n*^(2.373)) for multiplying two *n* × *n* matrices.
    The 2002 breakthrough polytime algorithm for identifying prime numbers initially
    had a complexity *O*(*n*^(12)), but it was later improved to *O*(*n*⁶). Polynomial
    time thus may not be the perfect definition of a practical time for an algorithm,
    but it’s the best we have.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*O*(*n*²) 或 *O*(*n*³) 可能是高效的，但 *O*(*n*^(99999999999)) 显然不是。换句话说，只要指数不太大，多项式时间就是快速的。幸运的是，所有被发现能解决实际问题的多项式时间算法都有较小的指数。例如，*O*(*n*^(1.465))
    是两个 *n* 位整数相乘的时间，或 *O*(*n*^(2.373)) 是两个 *n* × *n* 矩阵相乘的时间。2002年突破性的多项式时间算法用于识别素数，最初的复杂度是
    *O*(*n*^(12))，但后来改进为 *O*(*n*⁶)。因此，多项式时间可能不是算法实际时间的完美定义，但它是我们所能拥有的最佳定义。'
- en: By extension, a problem that can’t be solved by a polynomial-time algorithm
    is considered impractical, or *hard*. For example, for a straightforward key search,
    there’s no way to beat the *O*(2^(*n*)) complexity unless the cipher is somehow
    broken.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步来说，无法通过多项式时间算法解决的问题被认为是不可行的，或称为*困难*。例如，对于简单的密钥搜索，除非加密算法被某种方式攻破，否则无法突破*O*(2^(*n*))的复杂度。
- en: We know for sure that there’s no way to beat the *O*(2^(*n*)) complexity of
    a brute-force key search (as long as the cipher is secure), but we don’t always
    know what the fastest way to solve a problem is. A large portion of the research
    in complexity theory is about proving complexity *bounds* on the running time
    of algorithms solving a given problem. To make their job easier, complexity theorists
    have categorized computational problems in different groups, or *classes*, according
    to the effort needed to solve them.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确定，对于暴力破解密钥搜索的*O*(2^(*n*))复杂度（只要加密算法是安全的），没有办法突破，但我们并不总是知道解决问题的最快方法。复杂性理论中的大量研究工作都是关于证明给定问题求解算法的复杂度*界限*。为了简化工作，复杂性理论家将计算问题按解决它们所需的努力程度划分为不同的组，或称为*类别*。
- en: Complexity Classes
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 复杂度类别
- en: In mathematics, a *class* is a group of objects with some similar attribute.
    For example, all computational problems solvable in time *O*(*n*²), which complexity
    theorists simply denote **TIME**(*n*²), are one class. Likewise, **TIME**(*n*³)
    is the class of problems solvable in time *O*(*n*³), **TIME**(2^(*n*)) is the
    class of problems solvable in time *O*(2^(*n*)), and so on. For the same reason
    that a supercomputer can compute whatever a laptop can compute, any problem solvable
    in *O*(*n*²) is also solvable in *O*(*n*³). Hence, any problem in the class **TIME**(*n*²)
    also belongs to the class **TIME**(*n*³), which both also belong to the class
    **TIME**(*n*⁴), and so on. The union of all these classes of problems, **TIME**(*n*^(*k*)),
    where *k* is a constant, is called **P**, which stands for polynomial time.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学中，*类*是具有某些相似属性的对象的集合。例如，所有能在时间 *O*(*n*²) 内解决的计算问题，复杂度理论学者通常用 **TIME**(*n*²)
    表示，它们属于同一个类。同样，**TIME**(*n*³) 是在时间 *O*(*n*³) 内能解决的问题类，**TIME**(2^(*n*)) 是在时间 *O*(2^(*n*))
    内能解决的问题类，依此类推。就像一台超级计算机能够计算任何一台笔记本电脑能计算的内容一样，任何在 *O*(*n*²) 内能解决的问题也能在 *O*(*n*³)
    内解决。因此，**TIME**(*n*²) 类中的任何问题也属于 **TIME**(*n*³) 类，而这两个类都属于 **TIME**(*n*⁴) 类，依此类推。所有这些问题类的并集，**TIME**(*n*^(*k*)),
    其中 *k* 是常数，被称为 **P**，表示多项式时间。
- en: If you’ve ever programmed a computer, you’ll know that seemingly fast algorithms
    may still crash your system by eating all its memory resources. When selecting
    an algorithm, you should not only consider its time complexity but also how much
    memory it uses, or its *space complexity*. This is especially important because
    a single memory access is usually orders of magnitudes slower than a basic arithmetic
    operation in a CPU.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经编写过计算机程序，你就会知道，看似快速的算法可能仍然因为消耗了所有的内存资源而导致系统崩溃。在选择算法时，你不仅要考虑它的时间复杂度，还要考虑它使用了多少内存，或者它的
    *空间复杂度*。这尤其重要，因为单次内存访问通常比 CPU 中的基本算术操作慢得多。
- en: Formally, you can define an algorithm’s memory consumption as a function of
    its input length, *n*, in the same way we defined time complexity. The class of
    problems solvable using *f*(*n*) bits of memory is **SPACE**(*f*(*n*)). For example,
    **SPACE**(*n*³) is the class of problems solvable using of the order of *n*³ bits
    of memory. Just as we had **P** as the union of all **TIME**(*n*^(*k*)), the union
    of all **SPACE**(*n*^(*k*)) problems is called **PSPACE**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 正式来说，你可以将算法的内存消耗定义为其输入长度 *n* 的一个函数，方式和我们定义时间复杂度一样。使用 *f*(*n*) 位内存能够解决的问题类是 **SPACE**(*f*(*n*)）。例如，**SPACE**(*n*³)
    是使用大约 *n*³ 位内存能够解决的问题类。就像我们有 **P** 作为所有 **TIME**(*n*^(*k*)) 的并集一样，所有 **SPACE**(*n*^(*k*))
    问题的并集被称为 **PSPACE**。
- en: 'Obviously, the lower the memory the better, but a polynomial amount of memory
    doesn’t necessarily imply that an algorithm is practical. Why? Well, take for
    example a brute-force key search: again, it takes only negligible memory but is
    slow as hell. More generally, an algorithm can take forever, even if it uses just
    a few bytes of memory.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，内存越低越好，但多项式量级的内存并不一定意味着算法是实用的。为什么？举个例子，比如暴力破解密钥搜索：它只需要微不足道的内存，但速度极慢。更一般地说，即使一个算法只使用了少量内存，它也可能需要很长时间才能完成。
- en: Any problem solvable in time *f*(*n*) needs at most *f*(*n*) memory, so **TIME**(*f*(*n*))
    is included in **SPACE**(*f*(*n*)). In time *f*(*n*), you can only write up to
    *f*(*n*) bits, and no more, because writing (or reading) 1 bit is assumed to take
    one unit of time; therefore, any problem in **TIME**(*f*(*n*)) can’t use more
    than *f*(*n*) space. As a consequence, **P** is a subset of **PSPACE**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 任何能在时间 *f*(*n*) 内解决的问题，最多只需要 *f*(*n*) 的内存，因此 **TIME**(*f*(*n*)) 包含于 **SPACE**(*f*(*n*)）。在时间
    *f*(*n*) 内，你只能写入最多 *f*(*n*) 位的内容，不能更多，因为写（或读）1位假设需要一个时间单位；因此，任何在 **TIME**(*f*(*n*))
    内能解决的问题，不能使用超过 *f*(*n*) 的空间。因此，**P** 是 **PSPACE** 的子集。
- en: '*Nondeterministic Polynomial Time*'
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*非确定性多项式时间*'
- en: '**NP** is the second most important complexity class, after the class **P**
    of all polynomial-time algorithms. No, **NP** doesn’t stand for non-polynomial
    time, but for *nondeterministic* polynomial time. What does that mean?'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**NP** 是第二重要的复杂度类，仅次于 **P** 类（所有多项式时间算法的类）。不，**NP** 并不代表非多项式时间，而是代表 *非确定性*
    多项式时间。这是什么意思呢？'
- en: '**NP** is the class of problems for which a solution can be verified in polynomial
    time—that is, efficiently—even though the solution may be hard to find. By *verified*,
    I mean that given a potential solution, you can run some polynomial-time algorithm
    that will verify whether you’ve found an actual solution. For example, the problem
    of recovering a secret key with a known plaintext is in **NP**, because given
    *P*, *C* = **E**(*K*, *P*), and some candidate key *K*[0], you can check that
    *K*[0] is the correct key by verifying that **E**(*K*[0], *P*) equals *C*. The
    process of finding a potential key (the solution) can’t be done in polynomial
    time, but checking whether the key is correct is done using a polynomial-time
    algorithm.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**NP**是一个问题类，其中的解可以在多项式时间内验证——也就是说，即使解可能很难找到，也能高效地验证。所谓的*验证*是指，给定一个潜在的解，你可以运行某个多项式时间的算法来验证你是否找到了一个实际的解。例如，通过已知明文恢复密钥的问题属于**NP**，因为给定*P*，*C*
    = **E**(*K*, *P*)，以及某个候选密钥*K*[0]，你可以通过验证**E**(*K*[0], *P*)是否等于*C*来检查*K*[0]是否是正确的密钥。找到潜在的密钥（解）本身不能在多项式时间内完成，但验证密钥是否正确是通过多项式时间的算法来进行的。'
- en: 'Now for a counterexample: what about known-ciphertext attacks? This time, you
    only get some **E**(*K*, *P*) values for random unknown plaintext *P*s. If you
    don’t know what the *P*s are, then there’s no way to verify whether a potential
    key, *K*[0], is the right one. In other words, the key-recovery problem under
    known-ciphertext attacks is not in **NP** (let alone in **P**).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来看一个反例：已知密文攻击怎么样？这次，你只得到一些**E**(*K*, *P*)的值，分别对应于随机未知的明文*P*。如果你不知道这些*P*是什么，那么就无法验证一个潜在密钥*K*[0]是否是正确的。换句话说，已知密文攻击下的密钥恢复问题不在**NP**中（更不用说在**P**中了）。
- en: Another example of a problem not in **NP** is that of verifying the *absence*
    of a solution to a problem. Verifying that a solution is correct boils down to
    computing some algorithm with the candidate solution as an input and then checking
    the return value. However, to verify that *no* solution exists, you may need to
    go through all possible inputs. And if there’s an exponential number of inputs,
    you won’t be able to efficiently prove that no solution exists. The absence of
    a solution is hard to show for the hardest problems in the class **NP**—the so-called
    **NP**-complete problems, which we’ll discuss next.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个不在**NP**中的问题是验证问题的*不存在*解。验证解是否正确归结为计算某个算法，输入候选解，然后检查返回值。然而，要验证*没有*解的存在性，你可能需要遍历所有可能的输入。如果输入的数量是指数级的，你就无法高效地证明没有解存在。对于**NP**类中最难的问题——即所谓的**NP**-完全问题，证明解不存在是非常困难的，我们接下来会讨论这些问题。
- en: '*NP-Complete Problems*'
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*NP-完全问题*'
- en: The hardest problems in the class **NP** are called **NP**-complete; we don’t
    know how to solve these problems in polynomial time. And as complexity theorists
    discovered in the 1970s when they developed the theory of **NP**-completeness,
    **NP**’s hardest problems are all equally hard. This was proven by showing that
    any efficient solution to any of the **NP**-complete problems can be turned into
    an efficient solution for any of the other **NP**-complete problems. In other
    words, if you can solve any **NP**-complete problem efficiently, you can solve
    all of them, as well as all problems in **NP**. How can this be?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**NP**类中最难的问题被称为**NP**-完全问题；我们不知道如何在多项式时间内解决这些问题。正如复杂性理论家在1970年代开发**NP**-完全性理论时所发现的那样，**NP**类最难的问题都是一样难的。这一点已经通过证明任何一个**NP**-完全问题的高效解法都可以转化为另一个**NP**-完全问题的高效解法来证明。换句话说，如果你能高效地解决任何一个**NP**-完全问题，那么你就能解决所有**NP**-完全问题，以及所有**NP**中的问题。怎么做到的呢？'
- en: '**NP**-complete problems come in different disguises, but they’re fundamentally
    similar from a mathematical perspective. In fact, you can reduce any **NP**-complete
    problem to any other **NP**-complete problem such that solving the first one depends
    on solving the second.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**NP**-完全问题有不同的表现形式，但从数学角度来看，它们本质上是相似的。实际上，你可以将任何一个**NP**-完全问题化简为另一个**NP**-完全问题，使得解决第一个问题依赖于解决第二个问题。'
- en: 'Here are some examples of **NP**-complete problems:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些**NP**-完全问题的示例：
- en: '**The traveling salesman problem** Given a set of points on a map (cities,
    addresses, or other geographic locations) and the distances between each point
    from each other point, find a path that visits every point such that the total
    distance is smaller than a given distance of *x*.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**旅行商问题** 给定地图上的一组点（城市、地址或其他地理位置）以及每两个点之间的距离，找出一条访问所有点的路径，使得总距离小于给定的*x*。'
- en: '**The clique problem** Given a number, *x*, and a graph (a set of nodes connected
    by edges, as in [Figure 9-3](ch09.xhtml#ch9fig3)), determine if there’s a set
    of *x* points or less such that all points are connected to each other.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**团问题** 给定一个数字 *x* 和一个图（如[图 9-3](ch09.xhtml#ch9fig3)所示，图是由一组通过边连接的节点组成），确定是否存在一个由
    *x* 个或更少的点组成的集合，使得这些点彼此之间都连接。'
- en: '**The knapsack problem** Given two numbers, *x* and *y*, and a set of items,
    each of a known value and weight, can we pick a group of items such that the total
    value is at least *x* and the total weight at most *y*?'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**背包问题** 给定两个数字 *x* 和 *y*，以及一组物品，每个物品都有已知的价值和重量，能否挑选出一组物品，使得总价值至少为 *x*，且总重量不超过
    *y*？'
- en: '![image](../images/f09-03.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f09-03.jpg)'
- en: '*Figure 9-3: A graph containing a clique of four points. The general problem
    of finding a clique (set of nodes all connected to each other) of given size in
    a graph is **NP**-complete.*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-3：包含四个点的团的图。寻找一个给定大小的团（所有节点互相连接的集合）在图中的一般问题是**NP**-完全的。*'
- en: Such **NP**-complete problems are found everywhere, from scheduling problems
    (given jobs of some priority and duration, and one or more processors, assign
    jobs to the processors by respecting the priority while minimizing total execution
    time) to constraint-satisfaction problems (determine values that satisfy a set
    of mathematical constraints, such as logical equations). Even the task of winning
    in certain video games can sometimes be proven to be **NP**-complete (for famous
    games including *Tetris*, *Super Mario Bros.*, *Pokémon*, and *Candy Crush Saga*).
    For example, the article “Classic Nintendo Games Are (Computationally) Hard” (*[https://arxiv.org/abs/1203.1895](https://arxiv.org/abs/1203.1895)*)
    considers “the decision problem of reachability” to determine the possibility
    of reaching the goal point from a particular starting point.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这种**NP**-完全问题无处不在，从调度问题（给定某些优先级和持续时间的工作，和一个或多个处理器，分配工作到处理器，同时尊重优先级并最小化总执行时间）到约束满足问题（确定满足一组数学约束的值，例如逻辑方程）。甚至在某些视频游戏中获胜的任务有时也被证明是**NP**-完全的（例如，*俄罗斯方块*、*超级马里奥兄弟*、*宝可梦*和*糖果传奇*等著名游戏）。例如，文章《经典任天堂游戏是（计算上）困难的》（*[https://arxiv.org/abs/1203.1895](https://arxiv.org/abs/1203.1895)*）考虑了“可达性决策问题”，即判断是否可以从某个特定起点到达目标点。
- en: Some of these video game problems are actually even harder than **NP**-complete
    and are called **NP**-*hard*. We say that a problem is **NP**-hard when it’s at
    least as hard as **NP**-complete problems. More formally, a problem is **NP**-hard
    if what it takes to solve it can be proven to also solve **NP**-complete problems.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这些视频游戏问题中的一些实际上比**NP**-完全问题还要难，称为**NP**-*困难*。我们说一个问题是**NP**-困难的，当它至少和**NP**-完全问题一样难。更正式地说，如果解决一个问题所需的步骤能够证明同时解决**NP**-完全问题，那么这个问题就是**NP**-困难的。
- en: I have to mention an important caveat. Not all *instances* of **NP**-complete
    problems are actually hard to solve. Some specific instances, because they’re
    small or because they have a specific structure, may be solved efficiently. Take,
    for example, the graph in [Figure 9-3](ch09.xhtml#ch9fig3). By just looking at
    it for a few seconds you’ll spot the clique, which is the top four connected nodes—even
    though the aforementioned clique problem is **NP**-hard, there’s nothing hard
    here. So being **NP**-complete doesn’t mean that all instances of a given problem
    are hard, but that as the problem size grows, many of them are.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须提到一个重要的警告，并非所有**NP**-完全问题的*实例*都确实难以解决。一些特定的实例，因为它们较小或者具有特定的结构，可能会高效地解决。以[图
    9-3](ch09.xhtml#ch9fig3)中的图为例，仅仅观察几秒钟，你就能找到那个团，它就是顶部四个连接的节点——尽管前述的团问题是**NP**-困难的，但在这里并不困难。因此，**NP**-完全并不意味着所有给定问题的实例都很难，而是随着问题规模的增长，很多问题变得难以解决。
- en: '*The P vs. NP Problem*'
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*P vs. NP 问题*'
- en: If you could solve the hardest **NP** problems in polynomial time, then you
    could solve *all* **NP** problems in polynomial time, and therefore **NP** would
    equal **P**. That sounds preposterous; isn’t it obvious that there are problems
    for which a solution is easy to verify but hard to find? For example, isn’t it
    obvious that exponential-time brute force is the fastest way to recover the key
    of a symmetric cipher, and therefore that the problem can’t be in **P**? It turns
    out that, as crazy as it sounds, no one has proved that **P** is different from
    **NP**, despite a bounty of literally one million dollars.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能在多项式时间内解决最难的 **NP** 问题，那么你也可以在多项式时间内解决 *所有* **NP** 问题，因此 **NP** 将等于 **P**。这听起来荒谬；难道不明显吗，某些问题的解决方案容易验证却难以找到？例如，难道不明显，指数时间的暴力破解是恢复对称密码密钥的最快方法，因此这个问题不可能在
    **P** 中吗？事实证明，尽管有高达百万美元的奖金，听起来多么荒谬，但至今没有人证明 **P** 不等于 **NP**。
- en: 'The Clay Mathematics Institute will award this bounty to anyone who proves
    that either **P** ≠ **NP** or **P** = **NP**. This problem, known as **P** vs.
    **NP**, was called “one of the deepest questions that human beings have ever asked”
    by renowned complexity theorist Scott Aaronson. Think about it: if **P** were
    equal to **NP**, then any easily checked solution would also be easy to find.
    All cryptography used in practice would be insecure, because you could recover
    symmetric keys and invert hash functions efficiently.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 克雷数学研究所将向任何证明 **P** ≠ **NP** 或 **P** = **NP** 的人颁发这笔奖金。这个问题，被称为 **P** 与 **NP**
    问题，曾被著名的复杂性理论学家斯科特·阿伦森称为“人类有史以来提出的最深刻的问题之一”。想一想：如果 **P** 等于 **NP**，那么任何容易验证的解决方案也会很容易找到。所有实际使用的加密技术将不再安全，因为你可以有效地恢复对称密钥并反转哈希函数。
- en: '![image](../images/f09-04.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f09-04.jpg)'
- en: '*Figure 9-4: The classes **NP**, **P**, and the set of **NP**-complete problems*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 9-4：**NP**、**P** 类及 **NP**-完全问题集合*'
- en: 'But don’t panic: most complexity theorists believe **P** isn’t equal to **NP**,
    and therefore that **P** is instead a strict subset of **NP**, as [Figure 9-4](ch09.xhtml#ch9fig4)
    shows, where **NP**-complete problems are another subset of **NP** not overlapping
    with **P**. In other words, problems that look hard actually are hard. It’s just
    difficult to prove this mathematically. While proving that **P** = **NP** would
    only need a polynomial-time algorithm for an **NP**-complete problem, proving
    the nonexistence of such an algorithm is fundamentally harder. But this didn’t
    stop wacky mathematicians from coming up with simple proofs that, while usually
    obviously wrong, often make for funny reads; for an example, see “The P-versus-NP
    page” (*[https://www.win.tue.nl/~gwoegi/P-versus-NP.htm](https://www.win.tue.nl/~gwoegi/P-versus-NP.htm)*).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 但不要恐慌：大多数复杂性理论学家相信 **P** 不等于 **NP**，因此 **P** 是 **NP** 的严格子集，正如[图 9-4](ch09.xhtml#ch9fig4)所示，**NP**-完全问题是
    **NP** 的另一个子集，与 **P** 不重叠。换句话说，看起来难的问题实际上确实很难。只是很难从数学上证明这一点。虽然证明 **P** = **NP**
    只需要为 **NP**-完全问题提供一个多项式时间的算法，但证明不存在这样的算法从根本上来说更为困难。但这并没有阻止一些古怪的数学家提出简单的证明，尽管这些证明通常显然是错误的，但常常成为有趣的阅读材料；例如，参见“**P**
    与 **NP** 页面” (*[https://www.win.tue.nl/~gwoegi/P-versus-NP.htm](https://www.win.tue.nl/~gwoegi/P-versus-NP.htm)*)。
- en: 'Now if we’re almost sure that hard problems do exist, what about leveraging
    them to build strong, provably secure crypto? Imagine a proof that breaking some
    cipher is **NP**-complete, and therefore that the cipher is unbreakable as long
    as **P** isn’t equal to **NP**. But reality is disappointing: **NP**-complete
    problems have proved difficult to use for crypto purposes because the very structure
    that makes them hard in general can make them easy in specific cases—cases that
    sometimes occur in crypto. Instead, cryptography often relies on problems that
    are *probably not* **NP**-hard.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们几乎可以确定确实存在难题，那么如何利用这些难题来构建强大且可证明安全的加密呢？想象一下，如果某个加密算法的破解被证明是 **NP**-完全的，那么只要
    **P** 不等于 **NP**，该加密算法就无法破解。但现实令人失望：**NP**-完全问题已经被证明在加密领域很难应用，因为正是使其在一般情况下困难的结构，在特定情况下可能使它们变得容易——这些情况有时会出现在加密中。相反，加密技术通常依赖于*可能不是*
    **NP**-困难的问题。
- en: The Factoring Problem
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 因式分解问题
- en: The factoring problem consists of finding the prime numbers *p* and *q* given
    a large number, *N* = *p* × *q*. The widely used RSA algorithms are based on the
    fact that factoring a number is difficult. In fact, the hardness of the factoring
    problem is what makes RSA encryption and signature schemes secure. But before
    we see how RSA leverages the factoring problem in [Chapter 10](ch10.xhtml#ch10),
    I’d like to convince you that this problem is indeed hard, yet probably not **NP**-complete.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因式分解问题的目标是给定一个大数字 *N* = *p* × *q*，找到质数 *p* 和 *q*。广泛使用的RSA算法就基于因式分解数字的困难性。事实上，因式分解问题的难度正是使RSA加密和签名方案得以安全的原因。但在我们看到RSA如何在[第10章](ch10.xhtml#ch10)中利用因式分解问题之前，我想先说服你，相信这个问题确实很难，但可能不是**NP**-完全的。
- en: First, some kindergarten math. A *prime number* is a number that isn’t divisible
    by any other number but itself and 1\. For example, the numbers 3, 7, and 11 are
    prime; the numbers 4 = 2 × 2, 6 = 2 × 3, and 12 = 2 × 2 × 3 are not prime. A fundamental
    theorem of number theory says that any integer number can be uniquely written
    as a product of primes, a representation called the *factorization* of that number.
    For example, the factorization of 123456 is 2⁶ × 3 × 643; the factorization of
    1234567 is = 127 × 9721; and so on. Any integer has a unique factorization, or
    a unique way to write it as a product of prime numbers. But how do we know that
    a given factorization contains only prime numbers or that a given number is prime?
    The answer is found through polynomial-time primality testing algorithms, which
    allow us to efficiently test whether a given number is prime. Getting from a number
    to its prime factors, however, is another matter.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，来点幼儿园数学。一个*质数*是指不能被其他任何数字整除，除了它本身和1。例如，数字3、7和11是质数；数字4 = 2 × 2，6 = 2 × 3，和12
    = 2 × 2 × 3则不是质数。数论中的一个基本定理表明，任何整数都可以唯一地表示为质数的乘积，这种表示被称为该数字的*因式分解*。例如，123456的因式分解是2⁶
    × 3 × 643；1234567的因式分解是127 × 9721；依此类推。任何整数都有唯一的因式分解，或者说唯一的质数乘积表示。那么我们怎么知道给定的因式分解只包含质数，或者某个数字是否是质数呢？答案可以通过多项式时间质数性测试算法找到，这些算法使我们能够高效地测试一个给定的数字是否为质数。然而，从一个数字到其质因数的过程则是另一个问题。
- en: '*Factoring Large Numbers in Practice*'
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*大数因式分解的实践*'
- en: So how do we go from a number to its factorization—namely, its decomposition
    as a product of prime numbers? The most basic way to factor a number, *N*, is
    to try dividing it by all the numbers lower than it until you find a number, *x*,
    that divides *N*. Then attempt to divide *N* with the next number, *x* + 1, and
    so on. You’ll end up with a list of factors of *N*. What’s the time complexity
    of this? First, remember that we express complexities as a function of the input’s
    *length*. The bit length of the number *N* is *n* = log[2] *N*. By the basic definition
    of logarithm, this means that *N* = 2^(*n*). Because all the numbers less than
    *N*/2 are reasonable guesses for possible factors of *N*, there are about *N/*2
    = 2^(*n*)/2 values to try. The complexity of our naive factoring algorithm is
    therefore *O*(2^(*n*)), ignoring the 1/2 coefficient in the *O*() notation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何从一个数字出发，得到它的因式分解——即它作为质数乘积的分解呢？因式分解一个数字 *N* 最基本的方法是尝试将它除以所有小于它的数字，直到找到一个数字
    *x*，使得 *x* 能整除 *N*。然后尝试用下一个数字 *x* + 1 来除 *N*，依此类推。最终你将得到 *N* 的因子列表。这个过程的时间复杂度是多少呢？首先，记住我们通常是将复杂度表示为输入的*长度*的函数。数字
    *N* 的比特长度是 *n* = log[2] *N*。根据对数的基本定义，这意味着 *N* = 2^(*n*)。因为所有小于 *N*/2 的数字都可以作为
    *N* 的可能因子，所以总共有大约 *N*/2 = 2^(*n*)/2 个值可以尝试。因此，我们朴素的因式分解算法的复杂度是 *O*(2^(*n*))，在
    *O*()符号中忽略1/2的系数。
- en: Of course, many numbers are easy to factor by first finding any small factors
    (2, 3, 5, and so on) and then iteratively factoring any other nonprime factors.
    But here we’re interested in numbers of the form *N* = *p* × *q*, where *p* and
    *q* are large, as found in cryptography.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，许多数字很容易通过先找到一些小因子（如2、3、5等），然后反复分解其他非质因子来因式分解。但这里我们关注的是类似 *N* = *p* × *q*
    这种形式的数字，其中 *p* 和 *q* 都是较大的数字，这在密码学中很常见。
- en: Let’s be a bit smarter. We don’t need to test all numbers lower than *N*/2,
    but rather only the prime numbers, and we can start by trying only those smaller
    than the square root of *N*. Indeed, if *N* is not a prime number, then it has
    to have at least one factor lower than its square root √*N.* This is because if
    both of *N*’s factors *p* and *q* are greater than √*N*, then their product would
    be greater than √*N* × √*N* = *N*, which is impossible. For example, if we say
    *N* = 100, then its factors *p* and *q* can’t both be greater than 10 because
    that would result in a product greater than 100\. Either *p* or *q* has to be
    smaller than √*N*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以稍微聪明一点。我们不需要测试所有小于*N*/2的数字，而只需要测试质数，我们可以从测试小于*N*平方根的质数开始。实际上，如果*N*不是质数，那么它必须至少有一个小于其平方根√*N*的因数。这是因为如果*N*的两个因数*p*和*q*都大于√*N*，那么它们的乘积将大于√*N*
    × √*N* = *N*，这是不可能的。例如，如果我们说*N* = 100，那么它的因数*p*和*q*不能都大于10，因为这样会导致乘积大于100。*p*或*q*必须小于√*N*。
- en: So what’s the complexity of testing only the primes less than √*N*? The *prime
    number theorem* states that there are approximately *N*/log *N* primes less than
    *N*. Hence, there are approximately √*N*/log √*N* primes less than √*N*. Expressing
    this value, we get approximately 2^(*n*/2)/*n* possible prime factors and therefore
    a complexity of *O*(2^(*n*/2)/*n*), since √*N* = 2^(*n*/2) and 1/log√*N* = 1/(*n*/2)
    = 2*n*. This is faster than testing all prime numbers, but it’s still painfully
    slow—on the order of 2^(120) operations for a 256-bit number. That’s quite an
    impractical computational effort.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，仅测试小于√*N*的质数的复杂度是多少？*质数定理*表明，小于*N*的质数大约有*N*/log *N*个。因此，小于√*N*的质数大约有√*N*/log
    √*N*个。表达这个值，我们得到大约2^(*n*/2)/*n*个可能的质因数，因此复杂度为*O*(2^(*n*/2)/*n*)，因为√*N* = 2^(*n*/2)，且1/log√*N*
    = 1/(*n*/2) = 2*n*。这种方法比测试所有质数要快，但仍然非常慢——对于一个256位数字，大约需要2^(120)次操作。这是一个相当不切实际的计算量。
- en: 'The fastest factoring algorithm is the *general number field sieve (GNFS)*,
    which I won’t describe here because it requires the introduction of several advanced
    mathematical concepts. A rough estimate of GNFS’s complexity is exp(1.91 × *n*^(1/3)
    (log *n*)^(2/3)), where exp(…) is just a different notation for the exponential
    function *e^x*, with *e* the exponential constant approximately equal to 2.718\.
    However, it’s difficult to get an accurate estimate of GNFS’s actual complexity
    for a given number size. Therefore, we have to rely on heuristical complexity
    estimates, which show how security increases with a longer *n*. For example:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最快的因式分解算法是*一般数域筛法（GNFS）*，我这里不描述它，因为它需要介绍几个高级数学概念。GNFS的复杂度的大致估算是exp(1.91 × *n*^(1/3)
    (log *n*)^(2/3))，其中exp(…)只是指数函数*e^x*的不同表示法，*e*是指数常数，约等于2.718。然而，很难准确估算GNFS对于特定数字大小的实际复杂度。因此，我们必须依赖启发式复杂度估算，它显示了随着*n*增大，安全性是如何增加的。例如：
- en: Factoring a **1024-bit** number, which would have two prime factors of approximately
    500 bits each, will take on the order of 2^(70) basic operations.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对一个**1024位**的数字进行因式分解，其中会有两个大约为500位的质因数，这将需要大约2^(70)次基本操作。
- en: Factoring a **2048-bit** number, which would have two prime factors of approximately
    1000 bits each, will take on the order of 2^(90) basic operations, which is about
    a million times slower than for a 1024-bit number.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对一个**2048位**的数字进行因式分解，其中会有两个大约为1000位的质因数，这将需要大约2^(90)次基本操作，比1024位数字要慢大约百万倍。
- en: 'And we estimate that at least 4096 bits are needed to reach 128-bit security.
    Note that these values should be taken with a grain of salt, and researchers don’t
    always agree on these estimates. Take a look at these experimental results to
    see the actual cost of factoring:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们估计，至少需要4096位才能达到128位的安全性。请注意，这些值应该谨慎对待，研究人员对这些估算并不总是达成一致。可以查看这些实验结果，看看因式分解的实际成本：
- en: In 2005, after about 18 months of computation—and thanks to the power of a cluster
    of 80 processors, with a total effort equivalent to 75 years of computation on
    a single processor—a group of researchers factored a **663-bit** (200-decimal
    digit) number.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2005年，在约18个月的计算之后——并且得益于一个由80个处理器组成的集群，其计算总量相当于在单一处理器上进行75年的计算——一组研究人员成功地对一个**663位**（200十进制数字）的数字进行了因式分解。
- en: In 2009, after about two years and using several hundred processors, with a
    total effort equivalent to about 2,000 years of computation on a single processor,
    another group of researchers factored a **768-bit** (232-decimal digit) number.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2009年，在大约两年的时间里，使用了数百个处理器，计算量相当于在单个处理器上进行约2000年的计算，另一个研究小组成功地因式分解了一个**768位**（232位十进制数字）的数字。
- en: As you can see, the numbers actually factored by academic researchers are shorter
    than those in real applications, which are at least 1024-bit and often more than
    2048-bit. As I write this, no one has reported the factoring of a 1024-bit number,
    but many speculate that well-funded organizations such as the NSA can do it.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，学术研究者实际因式分解的数字比实际应用中的要短，后者至少是1024位，通常超过2048位。当我写这篇文章时，没有人报告过因式分解1024位的数字，但许多人猜测像NSA这样的资金充足的组织可能能够做到。
- en: In sum, 1024-bit RSA should be viewed as insecure, and RSA should be used with
    at least a 2048-bit value—and preferably a 4096-bit one to ensure higher security.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，1024位RSA应视为不安全，RSA至少应使用2048位的密钥——最好使用4096位的密钥以确保更高的安全性。
- en: '*Is Factoring NP-Complete?*'
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*因式分解是NP完全吗？*'
- en: We don’t know how to factor large numbers efficiently, which suggests that the
    factoring problem doesn’t belong to **P**. However, factoring is clearly in **NP**,
    because given a factorization, we can verify the solution by checking that all
    factors are prime numbers, thanks to the aforementioned primality testing algorithm,
    and that when multiplied together, the factors do give the expected number. For
    example, to check that 3 × 5 is the factorization of 15, you’ll check that both
    3 and 5 are prime and that 3 times 5 equals 15.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不知道如何高效地因式分解大数，这表明因式分解问题不属于**P**类。然而，因式分解显然属于**NP**类，因为给定一个因式分解结果，我们可以通过检查所有因子是否为质数来验证解决方案，得益于上述的质数检测算法，并且当将这些因子相乘时，结果确实是期望的数字。例如，要检查3
    × 5是否是15的因式分解，你需要检查3和5是否都是质数，并且3乘以5确实等于15。
- en: 'So we have a problem that is in **NP** and that looks hard, but is it as hard
    as the hardest **NP** problems? In other words, is factoring **NP**-complete?
    Spoiler alert: probably not.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有一个属于**NP**类且看起来很难的问题，但它真的像最难的**NP**问题一样难吗？换句话说，因式分解是**NP**完全的吗？剧透：很可能不是。
- en: There’s no mathematical proof that factoring isn’t **NP**-complete, but we have
    a few pieces of soft evidence. First, all known **NP**-complete problems can have
    one solution, but can also have more than one solution, or no solution at all.
    In contrast, factoring always has exactly one solution. Also, the factoring problem
    has a mathematical structure that allows for the GNFS algorithm to significantly
    outperform a naive algorithm, a structure that **NP**-complete problems don’t
    have. Factoring would be easy if we had a *quantum computer*, a computing model
    that exploits quantum mechanical phenomena to run different kinds of algorithms
    and that would have the capability to factor large numbers efficiently (not because
    it’d run the algorithm faster, but because it could run a quantum algorithm dedicated
    to factoring large numbers). A quantum computer doesn’t exist yet, though—and
    might never exist. Regardless, a quantum computer would be useless in tackling
    **NP**-complete problems because it’d be no faster than a classical one (see [Chapter
    14](ch14.xhtml#ch14)).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因式分解是否是**NP**完全问题没有数学证明，但我们有一些软证据。首先，所有已知的**NP**完全问题可能有一个解，但也可能有多个解，或者根本没有解。相比之下，因式分解总是只有一个解。并且，因式分解问题具有一种数学结构，使得GNFS算法能显著优于朴素算法，这种结构是**NP**完全问题所不具备的。如果我们有一台*量子计算机*，一种利用量子力学现象运行不同算法的计算模型，它能够高效地因式分解大数（不是因为它能更快地运行算法，而是因为它能够运行专门为因式分解大数设计的量子算法）。然而，量子计算机目前还不存在——并且可能永远也不会出现。无论如何，量子计算机在解决**NP**完全问题时也将毫无用处，因为它的速度与经典计算机并无不同（见[第14章](ch14.xhtml#ch14)）。
- en: Factoring may then be slightly easier than **NP**-complete in theory, but as
    far as cryptography is concerned, it’s hard enough, and even more reliable than
    **NP**-complete problems. Indeed, it’s easier to build cryptosystems on top of
    the factoring problem than **NP**-complete problems, because it’s hard to know
    exactly how hard it is to break a cryptosystem based on some **NP**-complete problems—in
    other words, how many bits of security you’d get.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在理论上，因式分解问题可能比**NP**完全问题稍微容易些，但就密码学而言，它已经足够难，而且比**NP**完全问题更可靠。事实上，在因式分解问题上构建密码系统比在**NP**完全问题上构建密码系统更容易，因为很难准确知道破解基于某些**NP**完全问题的密码系统有多难——换句话说，就是难以确定你能获得多少位的安全性。
- en: The factoring problem is just one of several problems used in cryptography as
    a *hardness assumption*, which is an assumption that some problem is computationally
    hard. This assumption is used when proving that breaking a cryptosystem’s security
    is at least as hard as solving said problem. Another problem used as a hardness
    assumption, the *discrete logarithm problem (DLP)*, is actually a family of problems,
    which we’ll discuss next.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因式分解问题只是密码学中作为*困难假设*使用的多个问题之一，*困难假设*是指某个问题在计算上是困难的。这个假设在证明破解密码系统的安全性至少与解决该问题一样困难时被使用。另一个作为困难假设使用的问题是*离散对数问题（DLP）*，实际上它是一个问题家族，接下来我们将讨论它。
- en: The Discrete Logarithm Problem
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 离散对数问题
- en: The DLP predates the factoring problem in the official history of cryptography.
    Whereas RSA appeared in 1977, a second cryptographic breakthrough, the Diffie–Hellman
    key agreement (covered in [Chapter 11](ch11.xhtml#ch11)), came about a year earlier,
    grounding its security on the hardness of the DLP. Like the factoring problem,
    the DLP deals with large numbers, but it’s a bit less straightforward—it will
    take you a few minutes rather than a few seconds to get it and requires a bit
    more math than factoring. So let me introduce the mathematical notion of a *group*
    in the context of discrete logarithms.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: DLP在密码学的官方历史中早于因式分解问题。RSA虽然出现在1977年，但第二个密码学突破——Diffie–Hellman密钥交换（见[第11章](ch11.xhtml#ch11)）——出现在大约一年前，其安全性建立在DLP的困难性之上。与因式分解问题一样，DLP也涉及大数，但它稍微不那么直接——理解它可能需要几分钟，而不是几秒钟，并且它需要比因式分解更多的数学知识。所以让我介绍一下在离散对数的上下文中，*群*的数学概念。
- en: '*What Is a Group?*'
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*什么是群？*'
- en: In mathematical context, a *group* is a set of elements (typically, numbers)
    that are related to each other according to certain well-defined rules. An example
    of a group is the set of nonzero integers (between 1 and *p* – 1) modulo some
    prime number *p*, which we write **Z**[*p*]^*. For *p* = 5, we get the group **Z**[5]^*
    = {1,2,3,4}. In the group **Z**[5]^*, operations are carried out modulo 5; hence,
    we don’t have 3 × 4 = 12 but instead have 3 × 4 = 2, because 12 mod 5 = 2\. We
    nonetheless use the same sign (×) that we use for normal integer multiplication.
    Likewise, we also use the exponent notation to denote a group element’s multiplication
    with itself mod *p*, a common operation in cryptography. For example, in the context
    of **Z**[5]^*, 2³ = 2 × 2 × 2 = 3 rather than 8, because 8 mod 5 is equal to 3.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学上下文中，*群*是一个元素的集合（通常是数字），这些元素根据某些明确的规则彼此相关。群的一个例子是非零整数集合（介于1和*p* – 1之间），模某个质数*p*运算，我们将其表示为**Z**[*p*]^*。当*p*
    = 5时，我们得到群**Z**[5]^* = {1,2,3,4}。在群**Z**[5]^*中，运算是在模5的情况下进行的；因此，我们不会得到3 × 4 =
    12，而是得到3 × 4 = 2，因为12 mod 5 = 2。我们依然使用与普通整数乘法相同的符号（×）。同样，我们也使用指数表示法来表示群元素与自身模*p*的乘法，这是密码学中常见的操作。例如，在**Z**[5]^*的上下文中，2³
    = 2 × 2 × 2 = 3，而不是8，因为8 mod 5等于3。
- en: 'To be a group, a mathematical set should have the following characteristics,
    called *group axioms*:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 要成为一个群，一个数学集合应具备以下特征，称为*群公理*：
- en: '**Closure** For any two *x* and *y* in the group, *x* × *y* is in the group
    too. In **Z**[5]^*, 2 × 3 = 1 (because 6 = 1 mod 5), 2 × 4 = 3, and so on.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**封闭性** 对于群中的任意两个 *x* 和 *y*，*x* × *y* 也在该群内。在**Z**[5]^*中，2 × 3 = 1（因为6 = 1
    mod 5），2 × 4 = 3，依此类推。'
- en: '**Associativity** For any *x*, *y*, *z* in the group, (*x* × *y*) × *z* = *x*
    × (*y* × *z*). In **Z**[5]^*, (2 × 3) × 4 = 1 × 4 = 2 × (3 × 4) = 2 × 2 = 4.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**结合律** 对于群中的任意 *x*、*y*、*z*，有 (*x* × *y*) × *z* = *x* × (*y* × *z*)。在**Z**[5]^*中，(2
    × 3) × 4 = 1 × 4 = 2 × (3 × 4) = 2 × 2 = 4。'
- en: '**Identity existence** There’s an element *e* such that *e* × *x* = *x* × *e*
    = *x*. In any **Z**[*p*]^*, the identity element is 1.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**单位元存在** 存在一个元素 *e*，使得 *e* × *x* = *x* × *e* = *x*。在任何**Z**[*p*]^*中，单位元是1。'
- en: '**Inverse existence** For any *x* in the group, there’s a *y* such that *x*
    × *y* = *y* × *x* = *e*. In **Z**[5]^*, the inverse of 2 is 3, and the inverse
    of 3 is 2, while 4 is its own inverse because 4 × 4 = 16 = 1 mod 5.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**逆元素** 对于群中的任何 *x*，存在一个 *y* 使得 *x* × *y* = *y* × *x* = *e*。在 **Z**[5]^* 中，2
    的逆元素是 3，3 的逆元素是 2，而 4 是它自己的逆元素，因为 4 × 4 = 16 = 1 mod 5。'
- en: 'In addition, a group is called *commutative* if *x* × *y* = *y* × *x* for any
    group elements *x* and *y*. That’s also true for any multiplicative group of integers
    **Z**[*p*]^*. In particular, **Z**[5]^* is commutative: 3 × 4 = 4 × 3, 2 × 3 =
    3 × 2, and so on.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果对于任何群元素 *x* 和 *y*，*x* × *y* = *y* × *x*，则称该群为 *交换群*。这对于任何整数的乘法群 **Z**[*p*]^*
    也成立。特别地，**Z**[5]^* 是交换群：3 × 4 = 4 × 3，2 × 3 = 3 × 2，等等。
- en: A group is called *cyclic* if there’s at least one element *g* such that its
    powers (*g*¹, *g*², *g*³, and so on) mod *p* span all distinct group elements.
    The element *g* is then called a *generator* of the group. **Z**[5]^* is cyclic
    and has two generators, 2 and 3, because 2¹ = 2, 2² = 4, 2³ = 3, 2⁴ = 1, and 3¹
    = 3, 3² = 4, 3³ = 2, 3⁴ = 1.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在至少一个元素 *g*，使得其幂（*g*¹，*g*²，*g*³，等等）模 *p* 可以覆盖所有不同的群元素，则称该群为 *循环群*。此时，元素 *g*
    被称为群的 *生成元*。**Z**[5]^* 是一个循环群，具有两个生成元，2 和 3，因为 2¹ = 2，2² = 4，2³ = 3，2⁴ = 1，3¹
    = 3，3² = 4，3³ = 2，3⁴ = 1。
- en: 'Note that I’m using multiplication as a group operator, but you can also get
    groups from other operators. For example, the most straightforward group is the
    set of all integers, positive and negative, with addition as a group operation.
    Let’s check that the group axioms hold with addition, in the preceding order:
    clearly, the number *x* + *y* is an integer if *x* and *y* are integers (closure);
    (*x* + *y) + z* = *x* + *(y + z)* for any *x*, *y*, and *z* (associativity); zero
    is the identity element; and the inverse of any number *x* in the group is –*x*
    because *x* + (–*x*) = 0 for any integer *x*. A big difference, though, is that
    this group of integers is of infinite size, whereas in crypto we’ll only deal
    with *finite groups*, or groups with a finite number of elements. Typically, we’ll
    use groups **Z**[*p*]^*, where *p* is *thousands* of bits long (that is, groups
    that contain on the order of 2^(*p*) numbers).'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我使用的是乘法作为群运算符，但你也可以使用其他运算符得到群。例如，最简单的群是所有整数的集合，包括正整数和负整数，且加法作为群运算。让我们检查加法是否符合群的公理，按以下顺序：显然，*x*
    + *y* 是整数，如果 *x* 和 *y* 是整数（封闭性）；(*x* + *y*) + *z* = *x* + (*y* + *z*) 对任何 *x*，*y*
    和 *z* 都成立（结合性）；零是单位元；任何数 *x* 在该群中的逆元是 –*x*，因为 *x* + (–*x*) = 0 对任何整数 *x* 都成立。然而，存在一个很大的区别，那就是这个整数群是无限大小的，而在加密中我们只处理
    *有限群*，即具有有限个元素的群。通常，我们会使用群 **Z**[*p*]^*，其中 *p* 是 *成千上万* 位长（即包含大约 2^(*p*) 个数字的群）。
- en: '*The Hard Thing*'
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*困难的事情*'
- en: The DLP consists of finding the *y* for which *g*^(*y*) = *x*, given a base
    number *g* within some group **Z**[*p*]^*, where *p* is a prime number, and given
    a group element *x*. The DLP is called *discrete* because we’re dealing with integers
    as opposed to real numbers (continuous), and it’s called a *logarithm* because
    we’re looking for the logarithm of *x* in base *g*. (For example, the logarithm
    of 256 in base 2 is 8 because 2⁸ = 256.)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 离散对数问题（DLP）是寻找 *y*，使得 *g*^(*y*) = *x*，给定一个群 **Z**[*p*]^* 中的基数 *g*，其中 *p* 是素数，并且给定一个群元素
    *x*。离散对数问题之所以称为 *离散*，是因为我们处理的是整数，而不是实数（连续）；它之所以称为 *对数*，是因为我们在寻找 *x* 关于 *g* 的对数。（例如，256
    以 2 为底的对数是 8，因为 2⁸ = 256。）
- en: People often ask me whether factoring or a discrete logarithm is more secure—or
    in other words, which problem is the hardest? My answer is that they’re about
    equally hard. In fact, algorithms to solve DLP bear similarities with those factoring
    integers, and you get about the same security level with *n*-bit hard-to-factor
    numbers as with discrete logarithms in an *n*-bit group. And for the same reason
    as factoring, DLP isn’t **NP**-complete. (Note that there are certain groups where
    the DLP is easier to solve, but here I’m only referring to the case of DLP groups
    consisting of a number modulo a prime.)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 人们常问我，因式分解和离散对数哪个更安全——换句话说，哪个问题更难？我的回答是，它们差不多一样难。实际上，解决离散对数问题的算法与因式分解算法相似，而且使用
    *n* 位的难以因式分解的数字，得到的安全性与 *n* 位群中的离散对数相当。与因式分解的原因相同，离散对数问题不是 **NP**-完全问题。（请注意，有些群的离散对数问题更容易解决，但这里我仅指的是由素数模数构成的离散对数群。）
- en: How Things Can Go Wrong
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 问题如何出现
- en: More than 40 years later, we still don’t know how to efficiently factor large
    numbers or solve discrete logarithms. Amateurs may argue that someone may eventually
    break factoring—and we have no proof that it’ll never be broken—but we also don’t
    have proof that **P** ≠ **NP**. Likewise, you can speculate that **P** may be
    equal to **NP**; however, according to experts, that surprise is unlikely. So
    there’s no need to worry. And indeed all the public-key crypto deployed today
    relies on either factoring (RSA) or DLP (Diffie–Hellman, ElGamal, elliptic curve
    cryptography). However, although math may not fail us, real-world concerns and
    human error can sneak in.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 40多年过去了，我们仍然不知道如何高效地分解大数或解决离散对数问题。业余爱好者可能会辩称，总有一天某个人可能会破解因式分解——我们也没有证明它永远无法被破解——但我们也没有证明**P**
    ≠ **NP**。同样，你可以推测**P**可能等于**NP**；然而，根据专家们的说法，这种惊讶的可能性不大。所以不必担心。实际上，今天所有公开密钥加密技术都依赖于因式分解（RSA）或离散对数问题（Diffie–Hellman、ElGamal、椭圆曲线加密）。然而，尽管数学可能不会让我们失望，现实世界中的顾虑和人为错误却可能悄然潜入。
- en: '*When Factoring Is Easy*'
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*当因式分解很容易时*'
- en: 'Factoring large numbers isn’t always hard. For example, take the 1024-bit number
    *N*, which is equal to the following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 因式分解大数并不总是很难。例如，考虑这个1024位数字*N*，它等于以下形式：
- en: '![image](../images/f0176-01.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f0176-01.jpg)'
- en: 'For 1024-bit numbers used in RSA encryption or signature schemes where *N*
    = *pq*, we expect the best factoring algorithms to need around 2^(70) operations,
    as we discussed earlier. But you can factor this sample number in seconds using
    SageMath, a piece of Python-based mathematical software. Using SageMath’s `factor()`
    function on my 2015 MacBook, it took less than five seconds to find the following
    factorization:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在RSA加密或签名方案中使用的1024位数字，当*N* = *pq*时，我们预计最好的因式分解算法需要大约2^(70)次操作，正如我们之前所讨论的。但你可以使用SageMath（一个基于Python的数学软件）在几秒钟内分解这个示例数字。我在2015款MacBook上使用SageMath的`factor()`函数，花费不到五秒钟就找到了以下因式分解：
- en: '![image](../images/f0176-02.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/f0176-02.jpg)'
- en: Right, I cheated. This number isn’t of the form *N* = *pq* because it doesn’t
    have just two large prime factors but rather five, including very small ones,
    which makes it easy to factor. First, you’ll identify the 2^(800) × 641 × 6700417
    part by trying small primes from a precomputed list of prime numbers, which leaves
    you with a 192-bit number that’s much easier to factor than a 1024-bit number
    with two large factors.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对的，我作弊了。这个数字并不是*N* = *pq*的形式，因为它不仅有两个大素因子，而是有五个，包括非常小的因子，这使得它容易分解。首先，你会通过从预计算的素数列表中尝试小素数来识别2^(800)
    × 641 × 6700417部分，剩下的则是一个比1024位数字容易分解的192位数字，它仅有两个大因子。
- en: But factoring can be easy not only when *n* has small prime factors, but also
    when *N* or its factors *p* and *q* have particular forms—for example, when *N*
    = *pq* with *p* and *q* both close to some 2^(*b*), when *N* = *pq* and some bits
    of *p* or *q* are known, or when *N* is of the form *N* = *p*^(*r*)*q*^(*s*) and
    *r* is greater than log *p*. However, detailing the reasons for these weaknesses
    is way too technical for this book.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，因式分解不仅在*n*具有小素因子的情况下容易，还在*N*或其因子*p*和*q*具有特定形式时也容易——例如，当*N* = *pq*，其中*p*和*q*都接近某个2^(*b*)时，当*N*
    = *pq*且已知*p*或*q*的一些位时，或者当*N*的形式是*N* = *p*^(*r*)*q*^(*s*)且*r*大于log *p*时。然而，详细解释这些弱点的原因对于本书来说过于技术化。
- en: The upshot here is that the RSA encryption and signature algorithms (covered
    in [Chapter 10](ch10.xhtml#ch10)) will need to work with a value of *N* = *pq*,
    where *p* and *q* are carefully chosen, to avoid easy factorization of *N*, which
    can result in security disaster.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键是，RSA加密和签名算法（在[第10章](ch10.xhtml#ch10)中讨论）需要使用*N* = *pq*的值，其中*p*和*q*是经过仔细选择的，以避免*N*的易分解性，这可能会导致安全灾难。
- en: '*Small Hard Problems Aren’t Hard*'
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '*小的难题并不难*'
- en: Computationally hard problems become easy when they’re small enough, and even
    exponential-time algorithms become practical as the problem size shrinks. A symmetric
    cipher may be secure in the sense that there’s no faster attack than the 2^(*n*)-time
    brute force, but if the key length is *n* = 32, you’ll break the cipher in minutes.
    This sounds obvious, and you’d think that no one would be naive enough to use
    small keys, but in reality there are plenty of reasons why this could happen.
    The following are two true stories.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 计算上困难的问题在它们足够小的时候变得容易，即使是指数时间的算法，在问题规模缩小时也变得实际可行。对称加密可能在没有比2^(*n*)次的暴力破解攻击更快的攻击时仍然安全，但如果密钥长度为*n*
    = 32，你在几分钟内就能破解该加密。这听起来很显而易见，你可能认为没有人会天真到使用小密钥，但实际上，这种情况有很多可能的原因。以下是两个真实的故事。
- en: Say you’re a developer who knows nothing about crypto but has some API to encrypt
    with RSA and has been told to encrypt with 128-bit security. What RSA key size
    would you pick? I’ve seen real cases of 128-bit RSA, or RSA based on a 128-bit
    number *N* = *pq*. However, although factoring is impractically hard for an *N*
    thousands of bits long, factoring a 128-bit number is easy. Using the SageMath
    software, the commands shown in [Listing 9-2](ch09.xhtml#ch9list2) complete instantaneously.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你是一个对密码学一无所知的开发者，手上有一个 API 可以使用 RSA 加密，并被告知要使用 128 位安全性进行加密。那么，你会选择什么 RSA
    密钥大小呢？我见过一些真实的案例，使用 128 位 RSA，或者基于 128 位数字 *N* = *pq* 的 RSA。然而，尽管对一个几千位长的 *N*
    进行因式分解几乎不可能，但对一个 128 位数字进行因式分解却很容易。使用 SageMath 软件时，[清单 9-2](ch09.xhtml#ch9list2)
    中显示的命令瞬间完成。
- en: '[PRE1]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Listing 9-2: Generating an RSA modulus by picking two random prime numbers
    and factoring it instantaneously*'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 9-2：通过选择两个随机素数并即时因式分解来生成 RSA 模数*'
- en: '[Listing 9-2](ch09.xhtml#ch9list2) shows that a 128-bit number taken randomly
    as the product of two 64-bit prime numbers can be easily factored on a typical
    laptop. However, if I chose 1024-bit prime numbers instead by using `p = random_prime(2**1024)`,
    the command `factor(p*q)` would never complete, at least not in my lifetime.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[清单 9-2](ch09.xhtml#ch9list2) 显示，作为两个 64 位素数的乘积，随机选取的一个 128 位数可以在一台典型的笔记本电脑上轻松分解。然而，如果我改为选择
    1024 位的素数，通过使用 `p = random_prime(2**1024)`，命令 `factor(p*q)` 永远也不会完成，至少在我的一生中是如此。'
- en: To be fair, the tools available don’t help prevent the naive use of insecurely
    short parameters. For example, the OpenSSL toolkit lets you generate RSA keys
    as short as 31 bits without any warning; obviously, such short keys are totally
    insecure, as shown in [Listing 9-3](ch09.xhtml#ch9list3).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 公平地说，现有工具并不能有效防止不安全的短参数的天真使用。例如，OpenSSL 工具包允许你生成最短 31 位的 RSA 密钥而不发出任何警告；显然，这样短的密钥是完全不安全的，如[清单
    9-3](ch09.xhtml#ch9list3)所示。
- en: '[PRE2]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Listing 9-3: Generating an insecure RSA private key using the OpenSSL toolkit*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单 9-3：使用 OpenSSL 工具包生成不安全的 RSA 私钥*'
- en: When reviewing cryptography, you should not only check the type of algorithms
    used, but also their parameters and the length of their secret values. However,
    as you’ll see in the following story, what’s secure enough today may be insecure
    tomorrow.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在回顾密码学时，你不仅应检查所使用算法的类型，还应检查其参数和密钥值的长度。然而，正如你将在以下故事中看到的那样，今天足够安全的东西，明天可能就不安全了。
- en: In 2015, researchers discovered that many HTTPS servers and email servers still
    supported an older, insecure version of the Diffie–Hellman key agreement protocol.
    Namely, the underlying TLS implementation supported Diffie–Hellman within a group,
    **Z**[*p*]^*, defined by a prime number, *p*, of only 512 bits, where the discrete
    logarithm problem was no longer practically impossible to compute.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 2015 年，研究人员发现，许多 HTTPS 服务器和邮件服务器仍然支持旧版、不安全的 Diffie–Hellman 密钥交换协议。即，底层的 TLS
    实现支持在一个组中使用 Diffie–Hellman，**Z**[*p*]^*，该组由一个仅有 512 位的素数 *p* 定义，而离散对数问题已经不再是一个实际不可计算的问题。
- en: Not only did servers support a weak algorithm, but attackers could force a benign
    client to use that algorithm by injecting malicious traffic within the client’s
    session. Even better for attackers, the largest part of the attack could be carried
    out once and recycled to attack multiple clients. After about a week of computations
    to attack a specific group, **Z**[*p*]^*, it took only 70 seconds to break individual
    sessions of different users.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅服务器支持一个弱算法，攻击者还可以通过在客户端会话中注入恶意流量，强迫一个无辜的客户端使用这个算法。对攻击者来说更好的是，攻击的最大部分可以一次性执行，并重复用来攻击多个客户端。大约一周的计算用于攻击特定组，**Z**[*p*]^*，仅用了
    70 秒就能破解不同用户的独立会话。
- en: A secure protocol is worthless if it’s undermined by a weakened algorithm, and
    a reliable algorithm is useless if sabotaged by weak parameters. In cryptography,
    you should always read the fine print.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个安全协议被削弱的算法所破坏，那么它毫无价值；而如果一个可靠的算法被弱参数所破坏，它也没有任何用处。在密码学中，你总是应该阅读细则。
- en: 'For more details about this story, check the research article “Imperfect Forward
    Secrecy: How Diffie–Hellman Fails in Practice” (*[https://weakdh.org/imperfect-forward-secrecy-ccs15.pdf](https://weakdh.org/imperfect-forward-secrecy-ccs15.pdf)*).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于这个故事的细节，请查看研究文章《不完美的前向保密性：Diffie–Hellman 在实践中的失败》（*[https://weakdh.org/imperfect-forward-secrecy-ccs15.pdf](https://weakdh.org/imperfect-forward-secrecy-ccs15.pdf)*）。
- en: Further Reading
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: I encourage you to look deeper into the foundational aspects of computation
    in the context of computability (what functions can be computed?) and complexity
    (at what cost?), and how they relate to cryptography. I’ve mostly talked about
    the classes **P** and **NP**, but there are many more classes and points of interest
    for cryptographers. I highly recommend the book *Quantum Computing Since Democritus*
    by Scott Aaronson (Cambridge University Press, 2013). It’s in large part about
    quantum computing, but its first chapters brilliantly introduce complexity theory
    and cryptography.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你深入探讨计算的基础方面，特别是在可计算性（哪些函数是可计算的？）和复杂性（以什么代价计算？）的背景下，以及它们与密码学的关系。我大部分谈论的是**P**类和**NP**类问题，但对于密码学家来说，还有许多其他类别和有趣的点。我强烈推荐Scott
    Aaronson的书《量子计算自德谟克里特以来》（剑桥大学出版社，2013年）。这本书主要讲的是量子计算，但它的前几章精彩地介绍了复杂性理论和密码学。
- en: 'In the cryptography research literature you’ll also find other hard computational
    problems. I’ll mention them in later chapters, but here are some examples that
    illustrate the diversity of problems leveraged by cryptographers:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在密码学研究文献中，你还会发现其他一些计算困难的问题。我将在后续章节中提到它们，但这里有一些例子可以说明密码学家所利用问题的多样性：
- en: The Diffie–Hellman problem (given *g*^(*x*) and *g*^(*y*), find *g*^(xy)) is
    a variant of the discrete logarithm problem, and is widely used in key agreement
    protocols.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Diffie–Hellman问题（给定 *g*^(*x*) 和 *g*^(*y*)，求 *g*^(xy)）是离散对数问题的一种变体，广泛应用于密钥协商协议中。
- en: Lattice problems, such as the shortest vector problem (SVP) and the learning
    with errors (LWE) problem, are the only examples of **NP**-hard problems successfully
    used in cryptography.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 格问题，如最短向量问题（SVP）和带误差学习问题（LWE），是唯一成功应用于密码学的**NP**-困难问题。
- en: Coding problems rely on the hardness of decoding error-correcting codes with
    insufficient information, and have been studied since the late 1970s.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码问题依赖于解码纠错码时缺乏足够信息的困难性，自1970年代末以来一直是研究的重点。
- en: Multivariate problems are about solving nonlinear systems of equations and are
    potentially **NP**-hard, but they’ve failed to provide reliable cryptosystems
    because hard versions are too big and slow, and practical versions were found
    to be insecure.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多元问题涉及解非线性方程组，可能是**NP**-困难的，但由于其困难版本过大且过慢，且实践中的版本被发现不安全，未能提供可靠的加密系统。
- en: In [Chapter 10](ch10.xhtml#ch10), we’ll keep talking about hard problems, especially
    factoring and its main variant, the RSA problem.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](ch10.xhtml#ch10)中，我们将继续讨论困难问题，特别是因式分解及其主要变体——RSA问题。
