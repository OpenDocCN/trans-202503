- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with Video
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Sketch 80: Playing a Video'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use Processing to play videos but, as was the situation with audio, Processing
    does not have its own facility for doing so. Instead, we use the `Movie` class
    from the `processing.video` library, which in turn uses the underlying Java-based
    video functions. As a first example, this sketch will load and display a short
    video.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the `processing.video` library 1 as the first line in the
    program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can declare an instance of the `Movie` class 2, one for each movie we
    want to play:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We load the video file when we initialize the class instance by calling its
    constructor (see Sketch 43), specifying the name of the file as a parameter 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `setup()` function, we begin reading the video from the file by calling
    the `movie.play()` function (which doesn’t just play the video, as you’d expect).
    A video is a sequence of compressed images or frames, just like an animation,
    and each one can take some significant time to read and decode. After we call
    `play()`, the system tries to read frames from the file, and when one is ready,
    the `available()` function returns `true`. We can then acquire the frame using
    `read()`. Like a `PGraphics` object, a `Movie` object can be treated as an image
    and displayed using the `image()` function. Thus, this is the process for displaying
    a movie 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If no new frame were available, `read()` would not be called, and the previously
    read frame would be displayed in its place. This is usually not noticeable.
  prefs: []
  type: TYPE_NORMAL
- en: The `Movie` class plays the sound with the movie.
  prefs: []
  type: TYPE_NORMAL
- en: The sketch also prints relevant information at the top of the window. It counts
    the number of frames read in and displays that number. It also displays the time
    count, which is the number of seconds that have been played so far, retrieved
    using the `movie.time()` function call 5. When the movie is complete, as indicated
    by `movie.time() >= movie.duration()` 6, the counters reset and the movie resumes
    playing from the first frame by calling `movie.jump(0)`. The `jump(t)` function
    call moves the current frame to the one at time `t`. Playing in a loop could also
    be accomplished by calling `movie.loop()` instead of `movie.play()`. In that case,
    the replaying of the movie from location 0 would be automatic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 81: Playing a Video with a Jog Wheel'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A jog wheel (or shuttle dial) is a device, often circular, that allows the user
    to advance or back through a video. Turning it clockwise moves the video forward
    by individual frames, and turning it counterclockwise moves the video backward.
    Editors often use this for editing where the video needs to be positioned frame
    by frame. This sketch will implement an approximation of this jogging process.
    The video will begin to play, and the user can adjust the speed and direction
    of play using the mouse. At any point, the user can stop the video and back up
    slowly to arrive at any specific frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this we have to address the problem of how to play a video backward.
    The `jump()` function permits the positioning of the video at any moment in time
    2. The time of any particular frame depends on the frame rate, which is the number
    of frames played per second. Given a frame rate of `rate`, we know that each frame
    lasts 1/`rate` seconds. The final frame occurs at `duration()` seconds from the
    start, so positioning at the frame before that could be done with the following
    call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The frame before that one is at `movie.jump (movie.duration-(1/rate)*2)` and
    so on. Simply step backward through the frames in this way, read the frame, and
    display it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the sketch, we store the time of the current frame in a `time` variable,
    and the time between frames is in the variable `ftime`. We will use the mouse
    to control the speed with which the video will be displayed. A mouse click in
    the middle of the screen sets the speed to 0 by setting `ftime` to 0\. A click
    on the right sets `ftime` to a value in proportion to the distance from the middle,
    and it moves the video forward; a click on the left sets `ftime` to a value that
    moves the video backward. Initially `ftime = 1/rate`, but this becomes −3 times
    that for a far left click and +3 times that for a far right click. This is the
    whole calculation 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: A minor problem occurs at the end of the video, which is really the beginning
    if it is playing in reverse. Time is set to 0 if the end is found while moving
    forward, and it is set to `duration()-ftime` if the beginning is found while moving
    backward.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic display process 1 occurs within `draw()` and is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The sketch displays a simple calibration to allow the user to select a speed,
    and it also displays the value of `ftime`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 82: Saving Still Frames from a Video'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This sketch will allow the user to save a set of still image frames from a video.
    The video is played in a loop so that the user can select all of the frames they
    need. Clicking the mouse will start saving images, and clicking again will stop
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Saving frames is accomplished using the `save()` function of the `Movie` class
    object. If `movie` is a `Movie` object, the following call saves the current frame
    in the named file as the type indicated by the file extension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This is the same way we save `PImage` pictures. In this case, we save a JPEG,
    but GIF, PNG, and other file formats work too.
  prefs: []
  type: TYPE_NORMAL
- en: 'To save multiple frames without overwriting the same file each time, we might
    use the number of stills that we have already saved, stored in the variable `v`,
    in the filename, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This means that the filenames would be *frame1.jpg*, *frame2.jpg*, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this labeling scheme, however, there’s no way to tell where one saved
    sequence ends and the next one begins. This sketch solves that problem by using
    the variable `nclicks` in conjunction with `v`. When the user clicks the mouse
    while the frames are being saved, then saving ceases, `nclicks` is incremented,
    and `v` is reset. We build a filename using the frame count and a letter that
    is relative to the `nclicks` variable: `nclicks` = 0 adds the letter “`a`” to
    the name, `nclicks` = 1 adds “`b`” to the name, and so on. The file for each frame
    is actually saved as follows 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The first sequence would be *framea1.jpg*, *framea2.jpg*, . . . and the second
    would be *frameb1.jpg* and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The sketch draws the time on the screen, but this is for the user—it will not
    appear on the saved image.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to save video frames is to display them in the sketch window and
    then save the sketch window as an image. If we did that in this case, the time
    drawn on the window would in fact be saved to the file with the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 83: Processing Video in Real Time'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some applications process or analyze a video frame by frame, and it is not necessary
    to see the result in real time. For example, it is possible to analyze a batter’s
    swing by capturing a video, enhancing relevant portions in each frame, and then
    putting the enhanced frames back in video form. It is even possible, when the
    analysis of each frame does not require too much computational effort, to do the
    processing as the video is playing and see the result as the action is going on.
  prefs: []
  type: TYPE_NORMAL
- en: In this sketch, the video that we used in the previous two sketches will be
    converted to grayscale and then thresholded in real time, just as we did in Sketch
    23 for a still image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that we can treat a `Movie` object just like a `PImage` (they have the
    same local functions). We extract each pixel `p` in the movie image using `movie.loadPixels()`
    1 and calculate a brightness or grey level by averaging the color components:
    `(red(p)+green(p)+blue(p))/3` 2. If this value is less than a threshold, the corresponding
    pixel in the display image is set to black; otherwise it is set to white. In this
    sketch, the threshold value is 100\. The result is a video that displays only
    black and white pixels.'
  prefs: []
  type: TYPE_NORMAL
- en: The setup is the same as before, but we also create a second image the size
    of a video frame (named `display`) that will hold a processed copy of each frame
    as it is displayed. The `draw()` function reads a frame when it is ready and then
    calls a local `thresh()` function to calculate a thresholded image. After `thresh()`
    has created a thresholded version of the movie image, both are displayed, one
    above the other, and both versions play simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: The result in this case is unimpressive, but it does give an idea of what we
    could do. For example, if we choose the threshold carefully, it might be possible
    to show only the motion of the car in the scene, removing the background clutter.
  prefs: []
  type: TYPE_NORMAL
- en: In other videos, we could locate faces, enhance and read license plates on moving
    cars, or inspect and count apples moving past the camera on a conveyor belt. These
    are problems in computer vision, and Processing is a good tool for building computer
    vision systems because of the ease with which it deals with images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 84: Capturing Video from a Webcam'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Webcams are present on most computers and almost all laptops. The previous sketches
    dealt with video that had already been captured, in the sense that a video file
    was available to be displayed or processed. This sketch will capture live video
    data from a webcam and display it in grayscale.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Capture` class deals with cameras and image/video capture. To use it,
    first declare an instance 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then initialize it using the class constructor. The class constructor may take
    only the parameter `this`, or `this` and a device specifier 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The `myCamera` variable is a device specifier string of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Much of the information in this string has an obvious meaning, and most is
    not absolutely necessary. If you know that the camera has a resolution of 640×480,
    the following call will open the camera:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Image capture begins with a call to `start()` 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As when playing a video, a frame is available when `camera.available()` returns
    `true`. The camera instance can now be treated like a `PImage` and be displayed
    with a call to `image()`.
  prefs: []
  type: TYPE_NORMAL
- en: This sketch copies the camera image into a `PImage` variable, `display` 4. The
    function `grey()` converts the color image into a grey one, which is displayed
    in place of the original. The result is a moving grayscale image of what is being
    captured by the camera. Be patient—it can take some time to open the camera device.
  prefs: []
  type: TYPE_NORMAL
- en: The `Capture` class function `list()` looks at the camera devices available
    on the computer and returns a list of descriptors that can be used in the constructor.
    So, if this line
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: were to be followed by this
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'then a list of available cameras would be printed to the window. We could select
    one and use the index for it in the code to select it from the `cameras[]` array.
    For instance, you could search for a camera that is 640×480 at 130 frames per
    second and find it as camera `i` in the list. Then you could use the selector
    you want by indexing the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Sketch 85: Mapping Live Video as a Texture'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous sketches, you saw that a `Movie` object can be treated as a
    `PImage` for display purposes and even for extracting pixels from a video frame.
    This sketch shows the use of a video as a texture for a 3D surface, again like
    a `PImage`. The idea is to paint a four-cornered plane (a quad) with a movie so
    that the video plays on a 3D plane and is foreshortened as the user’s point of
    view changes.
  prefs: []
  type: TYPE_NORMAL
- en: The first part of the sketch sets up the webcam (as before), establishes the
    `camera` variable as a source of images, and establishes P3D as the current renderer.
    When executing, the system requires a few seconds to figure out what cameras are
    attached and which one to use. We do all of this, including starting the camera,
    by calling `start()` 1 in `setup()`.
  prefs: []
  type: TYPE_NORMAL
- en: In `draw()`, the first thing is to check if there is a new image available.
    If so, we read it; if not, then the previous image remains as the current one
    2. Then we establish a 3D environment, with a call to `camera` setting up the
    viewpoint 3. We draw a quad in the 3D space and use the webcam as a texture 4.
    The viewpoint oscillates a little bit (x between −30 and 100) 5 to show that the
    view is changing.
  prefs: []
  type: TYPE_NORMAL
- en: The effect is that the quad seems to continuously change location and orientation
    while the live video plays within the quad. An interesting variation on this would
    be to draw a rotating cube with the video mapped on all faces. This would show
    nothing new, but it would take more code.
  prefs: []
  type: TYPE_NORMAL
