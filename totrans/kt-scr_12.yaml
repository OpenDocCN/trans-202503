- en: <hgroup>
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
- en: 8 THE GENETIC ALGORITHM
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/icon.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
- en: Many wonders of modern science were inspired by nature. Airplane and glider
    designs were based on the flight of birds. Camouflage—a tactic for survival—derives
    from mimicry, a form of antipredator adaptation. The hooked barbs of a thistle
    led to the invention of Velcro. Even rather dull-looking termite mounds teach
    us about natural ventilation and cooling, an idea used in modern architecture.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: The world of computing is no different. The exciting field of machine learning,
    especially deep learning, is inspired by how the human brain processes information.
    By copying natural strategies that evolved over millions of years, we’ve developed
    algorithms to solve problems that were previously thought to be unsolvable with
    traditional mathematical tools.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter and the next, you’ll learn how these nature-inspired algorithms
    work, about their advantages and limitations, and how to implement them in Kotlin.
    This chapter focuses on the genetic algorithm, an evolutionary process–based method.
    The next chapter covers particle swarm optimization and ant colony systems, two
    methods that mimic the behavior of biological agents or species. For each method,
    I’ll start with the key concepts and then show you how to code and apply them
    to real-world problems.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Nature-Inspired Algorithms
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Nature-inspired computing refers to observing how nature solves complex biological
    or physical problems and then applying similar strategies to contemporary scientific,
    engineering, or management problems. The core of nature-inspired computing is
    *nature-inspired algorithms (NIAs)*, which rely on strategies learned from nature.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Biology-based NIAs can be observed in natural processes, such as the evolution
    of a species or the functioning of neurons in the human brain. These processes
    led to the development of genetic algorithms and deep neural networks. Individual
    and collective behaviors of members (or *agents*) of a population can also form
    the basis for new NIAs. For example, the foraging behavior of ants around their
    colony inspired the ant colony optimization algorithm. Whereas ants tend to work
    independently without any explicit collaboration with other members of the colony,
    the behavior of a large school of fish or birds indicates swarm intelligence,
    which has led to the development of the particle swarm optimization algorithm.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Even nonliving natural processes involve embedded strategies optimized for meeting
    certain goals. Examples of such algorithms include gravitational search (based
    on Newton’s law of gravity) and simulated annealing (based on thermodynamics).
    In general, these algorithms serve as powerful tools for optimizing various processes
    or systems, resulting in significant gains in efficiency and cost savings.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Before going into detail on genetic algorithms, I’ll introduce the concepts
    of optimization and global solutions. Additionally, I’ll highlight instances where
    NIAs prove more effective than traditional mathematical tools for solving real-world
    problems.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: The Optimization Problem
  id: totrans-12
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: NIAs are well suited to solving optimization problems, in which we want to find
    the best solution of all possible solutions. To solve such problems, we minimize
    or maximize an *objective function*, a mathematical expression that represents
    the goal of what we want to achieve through optimization. It is expressed in terms
    of one or more *decision variables*, quantities we can adjust to optimize the
    objective function.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: For real-world problems, the decision variables will be bounded. Additional
    constraints may limit and define the decision space within which the optimal solution
    must be found.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider a simple example with only one bounded decision variable:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (8.1)$Equation$ ![](../images/eq8-1.jpg)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: In Equation 8.1, *f*(*x*) is an objective function of a single variable *x*.
    Our goal is to find the value of *x* for which *f*(*x*) will be minimum, provided
    *x* stays within ±3.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Since *x* in this case has an exponent of 2, *x*² will always be positive (irrespective
    of whether *x* is positive or negative) and will continue to increase as *x* increases
    in absolute terms. Therefore, the right-hand side of Equation 8.1 will have the
    smallest value when *x* = 0\. In other words, the optimal solution (marked by
    an asterisk) for this problem is *x** = 0, and the corresponding optimum value
    of the function is *f*(*x*)* = –2.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-1](chapter8.xhtml#fig8-1) shows a visual representation of this function,
    which takes the shape of a parabola with its vertex at (0, –2). We can also visually
    confirm that *f*(*x*) has its minimum at point C (the vertex of the parabola).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-1.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-1: The optimal value for a parabolic function'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: A property of this function allows us to identify the optimal solution without
    knowing its exact location. The dashed lines touching the function at points A,
    B, and C in [Figure 8-1](chapter8.xhtml#fig8-1) show the *slope*, also called
    the *gradient*, of the function at those locations. The slope of a function measures
    how much the value of a function changes when the value of the decision variable
    changes by a small amount. Notice that the gradient at point C, where the function
    value is minimum, is 0 (the dashed line is horizontal). Thus, if we randomly started
    our search for the optimal solution at point A, we could have moved in the direction
    of decreasing gradient (for example, from A to B or from B to C) until the gradient
    becomes 0\. If we continue to move beyond the vertex to the opposite side, the
    slope will change its direction and start increasing. This will cause the function
    value to increase, and we’ll move away from the optimal solution.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: For a function that is smooth (no kinks) and continuous (no jumps) and has only
    one maximum or minimum within the decision space, the gradient-based search strategy
    will always work in finding the *global optimum*— the best possible solution for
    a given problem. In fact, for a well-behaved function like this, we can find the
    optimal solution by simply setting the slope of the function with respect to the
    decision variable (called the derivative in differential calculus) to 0 and solving
    the resulting equation for the optimal solution. This approach will also work
    for functions with two or more decision variables as long as the function is *well
    behaved*, meaning it is both smooth and continuous.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Things get messier when we deal with a multimodal function with multiple locations
    where the gradient is 0, as shown in [Figure 8-2](chapter8.xhtml#fig8-2).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-2.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-2: Local and global minima for a univariate function'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-2](chapter8.xhtml#fig8-2) shows four local minima at points A, C,
    D, and E, and one global minimum at point B within the decision space. In a situation
    like this, whether an algorithm based on gradient descent will converge to the
    global minimum depends on the point from which we start the search. Nothing guarantees
    that we’ll find the global minimum unless we make multiple attempts from different
    starting points (initial conditions).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: For a better appreciation of the challenge involved when we try to find global
    optima for a multivariate function, consider the graph in [Figure 8-3](chapter8.xhtml#fig8-3).
    This shows the results of the two-variable Eggholder function, discussed further
    in the final project of this chapter. For a problem like this, a simple gradient-based
    algorithm can easily get stuck at one of the many local minima. To make things
    worse, the equations defining such functions are typically not differentiable,
    and we cannot use calculus-based tools to estimate the global optima.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-3.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-3: The Eggholder function with numerous local minima'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Functions of two decision variables have a silver lining, however: we can create
    3D plots of these functions for a bounded decision space. Based on a visual inspection
    of the surface or contour plots, it may then be possible to narrow down the search
    space to a number of smaller subzones where we can conduct an extensive local
    search to uncover the global minima (more than one global minimum could exist).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: What about functions of higher dimensions? In fact, complex real-world optimization
    problems can have hundreds of decision variables. It is not humanly possible to
    conceive what a function of several hundred variables might look like in a *hyperspace*
    (a higher-dimensional space beyond human comprehension). Our best bet for identifying
    an optimal or near-optimal solution in a hyperspace is to conduct a broad-based
    search combining *heuristics* (special knowledge about the nature of the problem)
    and *randomization* (selecting initial conditions or intermediate values randomly).
    This strategy is likely to allow the algorithm to escape local optima and find
    solutions that are superior to what a pure random search might reveal. We typically
    repeat this process numerous times and accept the best-so-far solution as a proxy
    for the unknown global optima.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Even when looking for an optimal combination of decision variables that can
    have only discrete values (whole numbers), the brute-force approach of trying
    out all possible combinations normally doesn’t work in higher dimensions. This
    is because the number of combinations may be so large that it is practically impossible
    to complete that search in a reasonable amount of time. It’s in this context that
    nature-inspired algorithms come to our rescue.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: When to Use NIAs
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Compared to traditional mathematical tools, NIAs are less sensitive to the nature
    or complexity of the optimization problem. An objective function may be nonlinear,
    nonsmooth, multidimensional, and multimodal, but these attributes are not a big
    concern for NIAs (though we still have to choose the right tool from the basket
    of options). NIAs are especially suitable for solving very large optimization
    problems and finding near-optimal solutions without expending too many resources
    (such as computational time or energy use).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional optimization methods, whether they employ a gradient descent algorithm
    or not, are deterministic: if we start the search from a given point, we’ll always
    reach the same solution or approximation after a given number of steps. This feature
    makes deterministic algorithms more prone to getting stuck at local optima because
    no built-in freedom exists to explore a different path unless the initial condition
    is changed.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: NIAs, on the other hand, are *stochastic*, meaning that their results cannot
    be predicted beforehand. This is because NIAs typically have multiple built-in
    steps that rely on random selection. For the same initial condition, a stochastic
    algorithm can produce very different results. This innate ability to randomly
    choose a different path allows NIAs to avoid getting stuck at local optima and
    to eventually find the global or near-global optima.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: In addition, some NIAs are based on the efforts of agents that operate independently
    (for example, ants in the ant colony optimization algorithm). This allows us to
    implement the algorithm so that it can benefit from parallel processing to improve
    computational efficiency.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些自然启发算法基于独立操作的代理（例如，蚁群优化算法中的蚂蚁）。这使我们能够实现算法，从而利用并行处理提高计算效率。
- en: In sum, we can use NIAs to solve large, complex, multidimensional optimization
    problems for which no known analytical solutions exist or for which such solutions
    cannot be found due to the nature of the problem. However, NIAs are not the ideal
    choice for solving the many optimization problems that can be efficiently solved
    using deterministic methods (for example, using linear or integer programming
    or various graph search algorithms).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们可以使用自然启发算法来解决一些大型、复杂的多维优化问题，这些问题没有已知的解析解，或者由于问题的性质，无法找到这样的解。然而，NIA并非解决许多可以通过确定性方法高效解决的优化问题的理想选择（例如，使用线性或整数规划或各种图搜索算法）。
- en: An Overview of the Genetic Algorithm
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 遗传算法概述
- en: The genetic algorithm is among the best-known NIAs. It is modeled after the
    biological evolution of species driven by both the sexual reproduction of parents,
    who contribute genetic materials, and natural selection (survival of the fittest).
    In addition to inheriting genes from its parents, the offspring’s *chromosomes*
    (collections of genes) undergo random alterations called *mutation* that introduce
    new features to its gene pool. The offspring is then subjected to a selection
    process based on its *fitness* (a measure of how well an individual contributes
    to reaching a certain goal) before it is allowed to reproduce. The process eventually
    leads to a generation of individuals with a significantly enhanced gene pool.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传算法是最著名的自然启发算法（NIA）之一。它的模型灵感来源于物种的生物进化过程，受父母的性繁殖（父母提供遗传物质）和自然选择（适者生存）驱动。除了继承父母的基因外，后代的*染色体*（基因集合）会经历随机变异，称为*突变*，这为基因库引入新的特征。随后，后代将通过基于*适应度*（衡量个体如何为实现某个目标做出贡献的标准）的选择过程，决定是否可以繁殖。最终，这一过程会导致一代具有显著增强基因库的个体的出现。
- en: '[Figure 8-4](chapter8.xhtml#fig8-4) shows the main components of the genetic
    algorithm.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-4](chapter8.xhtml#fig8-4)展示了遗传算法的主要组成部分。'
- en: '![](../images/Figure8-4.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/Figure8-4.jpg)'
- en: 'Figure 8-4: The key components of the genetic algorithm'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8-4：遗传算法的关键组成部分
- en: All genetic algorithms start with a population of randomly created individuals.
    Each individual is essentially a potential solution represented by its gene pool.
    These individuals are evaluated and screened based on their fitness, which we
    attempt to maximize or minimize until a termination condition is met. Otherwise,
    we choose a batch of individuals with better fitness values who are then allowed
    to mate, produce offspring, and replace their parents as the next generation.
    I’ll explain these steps further in the upcoming sections.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 所有遗传算法都从一群随机创建的个体开始。每个个体本质上是一个潜在的解决方案，通过其基因库来表示。这些个体会根据其适应度进行评估和筛选，我们会尽力最大化或最小化适应度，直到满足终止条件。否则，我们会选择一批具有更好适应度值的个体，它们将进行交配、产生后代，并取代父母成为下一代。我将在接下来的章节中进一步解释这些步骤。
- en: Genetic Operators
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 遗传算子
- en: Genetic operators include the three core components of genetic algorithms—selection,
    crossover, and mutation—that work in tandem and allow the algorithm to converge
    toward a solution. *Selection* refers to the process of choosing an individual
    from a population based on their fitness (their potential contribution to finding
    the optimal solution). Selection may involve the entire population or a subset
    of the population, as individuals are drawn at random based on specific strategies.
    *Crossover* involves combining genetic materials from parents to create offspring.
    In the genetic algorithm, it always involves two parents and is therefore a binary
    operator. *Mutation* is a random alteration of an individual’s genetic information.
    It is a unary operator because it is applied to one individual at a time.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '#### Selection'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: The selection operation ensures that better genes are passed on from one generation
    to the next. The implementation of this process may vary depending on the problem,
    but the end goal is to select two parents (chromosomes) to participate in the
    reproduction through crossover. The commonly used strategies for selection include
    tournament, roulette wheel, and rank-based selection.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Tournament
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The tournament selection process is based on running fitness-based competitions
    among randomly selected individuals, as shown in [Figure 8-5](chapter8.xhtml#fig8-5).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-5.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-5: Using tournaments to select parents'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: To create a new child, the process starts by randomly selecting four individuals
    grouped into two pairs. From each pair, the individual with better fitness is
    selected as a parent. The process selects two parents per round who will reproduce
    via crossover (explained later) to give birth to an offspring.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Roulette Wheel
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As the name implies, roulette wheel selection is comparable to spinning a dial
    on a board divided into segments. The area of these segments is proportional to
    the relative fitness of the members of the population from which parents are to
    be chosen. Let me explain the process with a numerical example, as shown in [Table
    8-1](chapter8.xhtml#tab8-1).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8-1: Roulette Wheel Data'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '| Individual | Fitness | Relative fitness (RF) | Cumulative RF |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| P1 | 12 | 0.286 | 0.286 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: '| P2 | 5 | 0.119 | 0.405 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| P3 | 8 | 0.190 | 0.595 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| P4 | 10 | 0.238 | 0.833 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| P5 | 4 | 0.095 | 0.929 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| P6 | 3 | 0.071 | 1.000 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: '| SUM = | 42 | 1.000 |  |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: '[Figure 8-6](chapter8.xhtml#fig8-6) shows the graphical representation of the
    example in [Table 8-1](chapter8.xhtml#tab8-1).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-6.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-6: Selecting parents using the roulette wheel method'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we consider a population of six individuals, P1 through P6\.
    Their fitness values are given in the second column of [Table 8-1](chapter8.xhtml#tab8-1).
    The relative fitness (RF) values are calculated by dividing individual fitness
    values by the sum of all individual fitness values (for example, RF for P1 = 12/42).
    The last column represents the cumulative RF (CRF), which is created by adding
    all RF values up to a certain row. For example, the CRF corresponding to P2 =
    0.286 + 0.119 = 0.405\. The last CRF, which is the sum of all individual RF values,
    will be 1.0\. In the roulette wheel scheme, RF values are used as proxy probabilities
    for individuals to be selected at random when an unbiased virtual dial is spun.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们考虑了一个由六个个体（P1 到 P6）组成的群体。它们的适应度值在[表 8-1](chapter8.xhtml#tab8-1)的第二列中给出。相对适应度（RF）值是通过将个体的适应度值除以所有个体适应度值之和计算得出的（例如，P1
    的 RF = 12/42）。最后一列表示累积 RF（CRF），它是通过将所有 RF 值累加到某一行得到的。例如，P2 对应的 CRF = 0.286 + 0.119
    = 0.405。最后的 CRF，即所有个体 RF 值的总和，将为 1.0。在轮盘赌方案中，RF 值作为个体随机选择的代理概率，当一个没有偏见的虚拟拨盘旋转时，它将决定被选择的个体。
- en: 'In [Figure 8-6](chapter8.xhtml#fig8-6), these six individuals are represented
    by six different segments whose areas are the same as their RF values (shown next
    to the individual names). To implement the roulette wheel method, we draw a random
    number between 0 and 1 from a uniform distribution, which has the same effect
    as spinning the dial. (This is done programmatically by using the random() method
    in the standard Kotlin math library.) Let’s say that the value of this random
    number is 0.68, equivalent to having the dial stop inside the fourth segment (between
    CRFs of 0.595 and 0.833). Based on this draw, we would select P4 as parent 1 and
    repeat the process one more time to choose parent 2.  ##### Rank-Based Selection'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 8-6](chapter8.xhtml#fig8-6)中，这六个个体被表示为六个不同的区域，其面积与它们的 RF 值相同（在个体名称旁边显示）。为了实现轮盘赌方法，我们从
    0 到 1 的均匀分布中随机抽取一个数字，这与旋转拨盘的效果相同。（通过使用 Kotlin 标准数学库中的 random() 方法可以编程实现此操作。）假设该随机数的值为
    0.68，相当于拨盘停在第四个区域内（介于 0.595 和 0.833 的 CRF 之间）。根据这个抽取结果，我们会选择 P4 作为父母 1，并再次重复这一过程选择父母
    2。##### 基于排名的选择
- en: The third selection method, rank-based selection, is very similar to the roulette
    wheel method. Here, we order the individuals in ascending or descending order,
    depending on the problem, and assign each individual a rank based on their fitness.
    If two or more individuals have the same fitness, they are assigned an average
    value (based on their positions in the ordered list) as their rank. Finally, the
    ranks are used to calculate RF values and select the mating parents as we would
    using the roulette wheel scheme.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种选择方法，基于排名的选择，非常类似于轮盘赌方法。在这种方法中，我们根据问题的不同，将个体按升序或降序排序，并根据它们的适应度分配一个排名。如果两个或更多个体的适应度相同，它们将根据在有序列表中的位置被分配一个平均排名。最后，利用这些排名计算
    RF 值，并像使用轮盘赌方法一样选择配对父母。
- en: Crossover
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 交叉
- en: The crossover operation is designed to intermix the genes of two parents to
    create one or two offspring who become members of the next generation. As with
    the selection operator, many ways of splitting the chromosomes and recombining
    the genes are available. [Figure 8-7](chapter8.xhtml#fig8-7) shows the schema
    for a simple but effective approach to this operation, called a single-point crossover.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉操作旨在将两个父母的基因混合，生成一个或两个后代，后代将成为下一代的成员。与选择操作符一样，分裂染色体和重组基因的方法有很多种。[图 8-7](chapter8.xhtml#fig8-7)展示了一种简单但有效的交叉操作方法，称为单点交叉。
- en: '![](../images/Figure8-7.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/Figure8-7.jpg)'
- en: 'Figure 8-7: The single-point crossover operation'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8-7：单点交叉操作
- en: We start the process by identifying two parents through the selection operation.
    These parents would normally have chromosomes consisting of different genes. In
    the example in [Figure 8-7](chapter8.xhtml#fig8-7), both parents have chromosomes
    made of binary genes denoted by 0 or 1\. Parent 1’s genes are shown as white cells,
    whereas parent 2’s genes are gray cells.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过选择操作识别两个父母来开始这一过程。这些父母通常会有由不同基因组成的染色体。在[图 8-7](chapter8.xhtml#fig8-7)中的例子里，两个父母都有由二进制基因（以
    0 或 1 表示）组成的染色体。父母 1 的基因以白色单元格表示，而父母 2 的基因以灰色单元格表示。
- en: The first step of the crossover operation is to draw a random integer from a
    uniform distribution between 1 and the number of genes minus 1, which would be
    between 1 and 5 (inclusive) in our example. Let’s say the integer drawn is 4\.
    We’d then split chromosomes of both parents at this location (between the fourth
    and fifth genes shown in [Figure 8-7](chapter8.xhtml#fig8-7)). Finally, we’d swap
    the split parts by adding the last two genes from parent 2 to parent 1 (the two
    gray cells of child 1) and adding the last two genes from parent 1 to parent 2
    (the two white cells of child 2).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉操作的第一步是从1到基因数量减1之间的均匀分布中抽取一个随机整数，在我们的示例中，该值将位于1到5之间（包括1和5）。假设抽到的整数是4。然后，我们将在此位置（[图
    8-7](chapter8.xhtml#fig8-7)中的第四和第五个基因之间）分割两个父代的染色体。最后，我们将交换分割部分：将父代2的最后两个基因添加到父代1中（子代1的两个灰色单元格），并将父代1的最后两个基因添加到父代2中（子代2的两个白色单元格）。
- en: In this example, we used two parents to create two children. However, we could
    also decide to produce only one child per iteration to keep the algorithm simple
    and easy to code. For *real-coded genes*—genes represented by real numbers—a crossover
    operation will produce only one child because of the way the method is implemented.
    We’ll discuss real-coded genes further in the final project of this chapter.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们使用了两个父代来创造两个子代。然而，我们也可以决定每次迭代只产生一个子代，以保持算法简单并便于编码。对于*实数编码基因*（由实数表示的基因），由于方法的实现方式，交叉操作将只产生一个子代。我们将在本章的最终项目中进一步讨论实数编码基因。
- en: Many other types of crossover operations, such as multipoint crossover and ordered
    crossover, exist. For real-coded genes used in mathematical function optimization,
    crossover operations could be based on an arithmetic, geometric, or weighted mean
    of fitness values.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他类型的交叉操作，例如多点交叉和有序交叉。对于用于数学函数优化的实数编码基因，交叉操作可以基于适应度值的算术、几何或加权均值。
- en: Mutation
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 突变
- en: Mutation involves randomly changing the values of genes or, for real-coded genes,
    adding a small noise to those values before adding a child to the next generation.
    Mutation is applied to every gene in the chromosome one at a time. First, we randomly
    draw a real number between 0 and 1 and compare that with a mutation threshold
    (probability), typically set to a very small value. If the random value drawn
    is less than or equal to the mutation threshold, we alter the genetic content
    for that gene. For a binary chromosome where the genes are either 1 or 0 (indicating
    inclusion or exclusion of some entity in the solution), this alteration is conducted
    by flipping the gene value from 0 to 1 or vice versa.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 突变涉及随机改变基因的值，或者对于实数编码的基因，在将后代添加到下一代之前，向这些值添加一些小的噪声。突变应用于染色体中的每个基因，一次一个。首先，我们从0到1之间随机抽取一个实数，并将其与突变阈值（概率）进行比较，通常该值设置为非常小的值。如果抽取的随机值小于或等于突变阈值，我们将改变该基因的遗传内容。对于一个二进制染色体，其中的基因值为1或0（表示某个实体在解中是否包含），这种改变是通过将基因值从0翻转为1或反之进行的。
- en: '[Figure 8-8](chapter8.xhtml#fig8-8) visually explains this process.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-8](chapter8.xhtml#fig8-8)以图形方式解释了这一过程。'
- en: '![](../images/Figure8-8.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/Figure8-8.jpg)'
- en: 'Figure 8-8: Mutation in a binary chromosome'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8-8：二进制染色体中的突变
- en: In [Figure 8-8](chapter8.xhtml#fig8-8), the second and fifth genes have been
    randomly selected for mutation. Given that these are binary genes, their gene
    values have been flipped from 0 to 1.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 8-8](chapter8.xhtml#fig8-8)中，第二个和第五个基因被随机选择进行突变。鉴于这些是二进制基因，它们的基因值已经从0翻转为1。
- en: Elitism
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 精英主义
- en: Before we move on to tackling our first genetic algorithm project, I’ll introduce
    one more important concept—*elitism*. This technique involves sorting the current
    population based on their fitness, then adding a fraction of that sorted population
    to the next generation before attempting crossover and mutation. This operation
    is called elitism because it favors the fittest individuals. Elitism generally
    helps reduce the number of computations needed to locate the optimal solution
    because it protects some of the best chromosomes from getting altered or diluted
    by crossover and mutation operations.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始解决第一个遗传算法项目之前，我还会介绍一个重要的概念——*精英主义*。这种技术涉及根据适应度对当前种群进行排序，然后将排序后的一部分个体添加到下一代，再进行交叉和突变操作。这个操作被称为精英主义，因为它偏向于保留最适应的个体。精英主义通常有助于减少寻找最优解所需的计算量，因为它保护了一些最优秀的染色体，避免它们在交叉和突变操作中被改变或稀释。
- en: 'Project 33: Evolve Gibberish into Shakespeare'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 项目 33：将胡言乱语演变为莎士比亚语言
- en: 'In our first coding project, we’ll create a population with random collections
    of genes as their chromosomes. We’ll then use a genetic algorithm to refine those
    chromosomes until one of the individuals becomes as eloquent as Shakespeare and
    repeats Hamlet’s famous line “To be, or not to be: that is the question,” expressed
    in its gene sequence!'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第一个编码项目中，我们将创建一个包含随机基因集合作为染色体的种群。接着，我们将使用遗传算法来优化这些染色体，直到其中一个个体变得像莎士比亚一样口才出众，并重复《哈姆雷特》中那句著名的台词：“生存还是毁灭，这是个问题”，并将其表达在基因序列中！
- en: The Strategy
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 策略
- en: To solve this problem, we’ll create a population of size 100\. No hard-and-fast
    rule applies on this, and a bit of experimentation is required to estimate a reasonable
    size for a given problem. Many factors are at play that will determine the convergence
    rate of the algorithm, including population size, the way the genetic operators
    are implemented, and the stopping condition. One possible strategy is to start
    with a smaller population size and then gradually increase it until further improvements
    in the solution become negligible.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们将创建一个大小为100的种群。对此没有严格的规定，需要通过一些实验来估计给定问题的合理种群规模。影响算法收敛速度的因素有很多，包括种群规模、遗传操作的实现方式以及停止条件。一种可能的策略是从较小的种群规模开始，然后逐步增加，直到进一步改进解决方案变得微不足道。
- en: Next, we need to determine the size of the chromosomes. For this specific problem,
    each individual’s chromosome will have 42 genes—the length of the text we aim
    to reproduce using the algorithm. These genes will be randomly selected from a
    pool of 87 genes, which in this case is a collection of alphanumeric characters
    (including punctuation and parentheses). Since our goal is to exactly match the
    target text, this collection includes both uppercase and lowercase letters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要确定染色体的大小。对于这个特定的问题，每个个体的染色体将包含42个基因——这是我们希望通过算法再现的文本的长度。这些基因将从87个基因的池中随机选择，这些基因池包含字母数字字符（包括标点符号和括号）。由于我们的目标是精确匹配目标文本，因此这个基因池包含了大写字母和小写字母。
- en: In our genetic algorithm implementation, we’ll use elitism and tournament-based
    selection as our operators. Additionally, we’ll employ a single-point crossover
    scheme. For mutation, we will use a threshold of 1/42 to ensure that on average
    one gene will mutate for each new child created via crossover.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的遗传算法实现中，我们将使用精英策略和基于竞赛的选择作为操作符。此外，我们将采用单点交叉方案。对于突变，我们将使用1/42的阈值，以确保每次交叉创建新个体时，平均每个基因会发生一次突变。
- en: The Code
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 代码
- en: The overall structure of the code closely resembles the general structure of
    the genetic algorithm described in [Figure 8-4](chapter8.xhtml#fig8-4). We’ll
    discuss each of its components in the following sections.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的整体结构与[图8-4](chapter8.xhtml#fig8-4)中描述的遗传算法的一般结构非常相似。我们将在接下来的章节中讨论它的每个组成部分。
- en: Global Declarations
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 全局声明
- en: In this code segment, we create a data class, and declare and/or set required
    global parameters and collections. We also create two mutable lists of data objects
    to store population states for the current and next generations.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码段中，我们创建了一个数据类，并声明和/或设置了所需的全局参数和集合。我们还创建了两个可变的数据对象列表，用来存储当前代和下一代的种群状态。
- en: '[PRE0]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Let’s walk through this segment step by step. At the top of the block, we create
    a Solution object (data class) that will be used to create the individuals who
    will make up the population and undergo genetic alterations.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步步地讲解这个代码段。在代码块的顶部，我们创建了一个Solution对象（数据类），它将用于创建构成种群的个体，并进行基因变化。
- en: Next, we define the target string or the desired end state for the fittest individual
    in the population ❶. The target string has 42 characters (including spaces), which
    are stored in a string named TARGET. The target string is built from a pool of
    genes—characters that we typically use while composing phrases in English. This
    gene pool is saved as VALID_GENES ❷.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义目标字符串或种群中最适应个体的期望最终状态❶。目标字符串包含42个字符（包括空格），并存储在名为TARGET的字符串中。该目标字符串是从一个基因池构建的——这些字符是我们在英语中常用来构建短语的字符。这个基因池保存为VALID_GENES❷。
- en: We set the population size (POP_SIZE) to 100 and the number of generations (MAX_GEN)
    to 1,000\. We also employ elitism. Fifteen percent of the population (the top
    15 fittest individuals) will be automatically included in the next generation.
    The remaining members of the next generation will be produced through selection,
    crossover, and mutation. The threshold for mutation has been set to 1.0/chromosomeLength
    ❸ so that on average 1 gene out of 42 will undergo mutation per offspring. (You
    may need to adjust this rule of thumb for other optimization problems. For example,
    you may have to explicitly set the mutation threshold from 1 to 3 percent when
    too few genes exist in the chromosome.)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将种群大小（POP_SIZE）设置为100，将代数（MAX_GEN）设置为1,000。我们还使用了精英主义。种群中15%（即最适应的前15个个体）将自动进入下一代。下一代的其余成员将通过选择、交叉和变异生成。变异阈值已设置为1.0/chromosomeLength
    ❸，因此每个后代中平均会有42个基因中有1个基因发生变异。（对于其他优化问题，可能需要调整这个经验规则。例如，当染色体中基因较少时，可能需要将变异阈值从1%设置为3%。）
- en: The last two lines create two mutable lists of type Solution, which store the
    individuals belonging to the current generation (population) and to the next generation
    (nextgen).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的两行代码创建了两个可变类型为Solution的列表，这些列表分别存储当前代（种群）和下一代（nextgen）个体。
- en: Initializing Population and Fitness Evaluation
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 初始化种群和适应度评估
- en: The initial population is created by making a call to the initPopulation() function,
    which in turn relies on the getFitness() helper function.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 初始种群通过调用initPopulation()函数创建，该函数依赖于getFitness()辅助函数。
- en: '[PRE1]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The initPopulation() function creates the number of individuals specified by
    POP_SIZE (100, in this case) whose chromosomes are created by randomly picking
    individual genes (all 42 of them) from the supplied gene pool, VALID_GENES ❶.
    Once the chromosome is complete, its fitness is evaluated by calling the getFitness()
    function. A new Solution is created using the chromosome and fitness value and
    then added to the population ❷.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: initPopulation()函数创建了POP_SIZE指定数量的个体（在本例中为100个），这些个体的染色体是通过随机从提供的基因池VALID_GENES
    ❶中选取个体基因（共42个）来生成的。染色体完成后，通过调用getFitness()函数来评估其适应度。然后，使用染色体和适应度值创建一个新的Solution并将其添加到种群中
    ❷。
- en: Before exiting this function, we sort the population in descending order and
    print the best solution from the initial population. This presorting is needed
    to check for the termination condition and implement elitism for the first generation
    inside the runGA() function. For subsequent generations, sorting is done at the
    end of each iteration inside runGA().
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在退出该函数之前，我们按降序对种群进行排序，并打印出初始种群中的最佳解。此排序是为了检查终止条件并在runGA()函数内实现精英主义，以处理第一代。对于后续代，排序将在每次迭代结束时进行。
- en: Within the getFitness() function, we create a list named pairs of type Pair<Char,
    Char> and calculate the fitness value for the given chromosome based on pair-wise
    comparisons. For each matching gene, fitness is incremented by 1 ❸. If a chromosome
    matches the target string exactly, it will have a maximum fitness value of 42.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在getFitness()函数内，我们创建了一个名为pairs的列表，类型为Pair<Char, Char>，并根据基因对的比较来计算给定染色体的适应度值。对于每个匹配的基因，适应度加1
    ❸。如果一个染色体完全匹配目标字符串，它将拥有最大适应度值42。
- en: The Driver Function
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 驱动函数
- en: In the code block for the runGA() function, we implement the core components
    of the genetic algorithm. This includes iterating over multiple generations, checking
    for the termination condition, and creating the next generation by using elitism,
    selection, crossover, and mutation—the entire collection of genetic operators.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在runGA()函数的代码块中，我们实现了遗传算法的核心组件。这包括遍历多个代，检查终止条件，并通过精英主义、选择、交叉和变异——即一整套遗传操作符——来创建下一代。
- en: '[PRE2]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The outermost for loop ❶ runs the genetic processes for the specified number
    of generations. Inside this loop, we first check for the termination condition
    by comparing the best fitness value from the current population with the maximum
    possible fitness ❷. If the condition is met, the program terminates after printing
    a message that it has reached the target. If the condition is not met, we implement
    elitism by calling the selectElites() function ❸, discussed in detail in the next
    section.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: We then move on to the first inner for loop ❹, which creates the remaining members
    of the next generation by selecting new parents by tournament, creating a child
    by calling the crossover() function (which also applies mutation to the newly
    created chromosome, as discussed in the next section), and then adding the child
    to the mutable nextgen list.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: We use a second inner for loop ❺ to individually copy the next-generation solutions
    (nextgen) to population before nextgen is cleared for the next iteration. Notice
    that given the simple structure of the Solution data class, the copy() method
    applied to the elements of nextgen creates a deep copy and prevents cross-referencing
    between population and nextgen. In addition, transferring nextgen values to population
    at the end of each iteration eliminates the need to store multiple generations
    of solutions, which saves a lot of memory.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'In the final segment of the outermost for loop, we sort the newly updated population
    in descending order ❻ and print three key values per generation: the iteration
    number, the chromosome with the best fitness, and the corresponding fitness ❼.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: The Operator Functions
  id: totrans-117
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The runGA() function relies on several operator functions that perform the key
    genetic operations.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The selectElites() function is a one-liner. It promotes the top 15 individuals
    (eliteSize = 15) from the current generation to the next generation without subjecting
    them to further genetic processes ❶.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: The tournament() function randomly picks two individuals from the current population
    and returns the winner of the competition based on their fitness values ❷.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: The crossover() function takes in two parents as arguments, splits their chromosomes
    at a random location, and combines the split parts from both parents to create
    a new chromosome for the offspring ❸. Next, this newly created chromosome (crossChromosome)
    is passed to the mutation() function ❹, which returns the final chromosome saved
    as newChromosome. A single offspring is then returned once the fitness value for
    the newly created chromosome is calculated by making a call to getFitness() ❺.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the mutation() function applies mutation to randomly selected genes.
    It first converts the chromosome from a string object to a character array because
    strings are immutable in Kotlin. The mutation operation, triggered by the MUTATION_THRESHOLD
    parameter ❻, is applied to each gene in the chromosome. Once the mutation operation
    is done, the character array is converted back to a string and returned as the
    new (mutated) chromosome ❼.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The main() Function
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The main() function simply prints a few key problem-specific parameters and
    makes two function calls to finish the job.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The first call to initPopulation() initializes the current population with random
    chromosomes. The second call to runGA() conducts the necessary genetic operations.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Each time you run this program, it will take a different number of iterations
    to exactly match the target string. This is because we’re using a stochastic method
    that depends on many internal levels of random selection. This is a very helpful
    feature for solving large real-world problems that may not have a deterministic
    or known solution.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is some sample output from the program:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this instance, starting with chromosomes that had no resemblance to the target
    string, it took 379 generations for the algorithm to re-create the target string
    exactly. We haven’t made any attempt to fine-tune the global parameter values
    to increase the speed of convergence, yet the code converges to the optimal solution
    almost instantly (the processing time will depend on the configuration of your
    device). Pretty impressive!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 34: Solve the Knapsack Problem'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'You’re likely familiar with Noah’s ark, the vessel Noah and his followers built
    to save themselves from a great deluge. The challenge that Noah faced was massive:
    he had to build a vessel of unprecedented size and choose who or what to take
    on board. To a mathematician, this latter decision is a classic example of an
    optimization problem where one tries to maximize the value of the objects that
    can be accommodated within a limited space.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Let’s build a miniature version of this challenge and solve it using the genetic
    algorithm. We’ll name this project Jonah’s ark. Jonah lives in a flood plain that
    faces the risk of flash floods. Jonah knows he must be ready to leave the area
    at short notice. His quickest route to safety involves using a small-engine boat
    to get away from the rising river through a tributary beyond the reach of flood
    waters. Of course, the boat is small and can carry only so many items without
    sinking. Jonah must decide which of the valuable objects in his possession he
    should take with him without exceeding the capacity of the boat.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Jonah was able to come up with a short list of the 12 objects most valuable
    to him—which is still too many to take on board. Now he needs to figure out which
    combination of those objects he should choose so that their total worth (sum of
    assigned values) to him will be maximized without exceeding the capacity of his
    boat.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: The Strategy
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Jonah’s ark problem is a variation of what is known in mathematics as the
    *knapsack problem*:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Let n be the number of objects one has to choose from. Let ***V*** = [v[1],
    v[2], . . . , vn] be the list of values (worth) of those objects and ***W*** =
    [w[1], w[2], . . . , wn] be the list of weights of those objects. Also, let ***W***max
    be the maximum weight that the knapsack can carry. The goal is to find a subset
    of m objects so that the sum of values for that subset is maximized while ensuring
    that the sum of corresponding weights remains ≤ ***W***m[ax].
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We’ll leverage the genetic algorithm to address this problem. It’s evident that
    we’ll have to make changes to the problem definition part of the code. First,
    given that Jonah now has a choice among 12 distinct objects, we’ll set the number
    of chromosomes to 12\. Each gene in the chromosome will assume a binary value,
    where 1 signifies the inclusion of an object in the solution and 0 denotes its
    exclusion. We’ll also calculate the fitness of a solution differently based on
    which objects are included and their respective values and weights. I’ll explain
    this further when we discuss the related code segment.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: One important consideration is the composition of the initial population. We
    need to ensure that the initial population has some diversity. If all genes are
    randomly assigned, we might get a population with zero fitness. This would make
    crossover useless, and we would be relying solely on mutation, which is a very
    slow process. Therefore, while initiating the population, we’ll force each member
    to have a nonzero fitness.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Before we start coding, we need to address a few technical considerations. First,
    we’ll adopt a 0-1 approach to solve this problem, meaning we’ll either include
    an object or completely exclude it in the solution. We’re not allowed to take
    a fraction of an object (and a fraction of its value). Second, we assume that
    we have only one copy of each object, so we cannot repeat any object in our solution.
    Third, we assume that we have only one knapsack to fill.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We developed a fully functional genetic algorithm program in [Project 33](chapter8.xhtml#pre-33).
    For the most part, we’ll reuse that code and make a few adjustments needed to
    describe and solve the knapsack problem (or the Jonah’s ark problem).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Problem Definition and Global Parameters
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This code segment is composed of an import statement, data class declarations,
    the creation of a list of items to choose from, global parameters, and the creation
    of mutable lists to track population states for both the current and the next
    generations, as well as the best solutions from each generation.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The code segment begins with a single import statement for the roundToInt()
    method that we’ll use shortly. We then define two simple data classes, Solution
    and Item, which are used to create individual members of the population and objects
    with their key attributes (value and weight). Notice that we’re creating the chromosome
    as an integer array and not as a string, as in [Project 33](chapter8.xhtml#pre-33).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Depending on your IDE, you might encounter a “weak warning” while declaring
    the first data class of this project (*Solution*). This is because we’re using
    a property with an* Array *type (*chromosome*) in a data class (*Solution*). While
    this warning indicates potential issues for certain use cases, it does not apply
    to the problems discussed in this chapter and the next. If you find the warning
    bothersome, an alternative approach would be to use regular classes instead of
    data classes. In that case, you can manually add necessary custom methods that
    a data class generates automatically, such as* copy() *and* toString()*. I encourage
    you to experiment with this approach as a further learning opportunity.*'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Next, we create a List of type Item with the 12 objects ❶. The capacity limit
    for the boat (maxWeight) is set to 175 units ❷ (we’ll assume this is in addition
    to Jonah’s own weight).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Given the relatively small number of objects to choose from, we’ve set the population
    size (POP_SIZE) to 25 and the number of generations (MAX_GEN) to a modest 30\.
    Elitism has been set to 0.1, or 10 percent. The MUTATION_THRESHOLD value is set
    a bit differently (its value is rounded off to three significant digits after
    the decimal point) ❸, but it still complies with the rule of thumb.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Note that the mutation threshold can be rounded to a few decimal places without
    affecting the results. This can speed up the calculations for more complex problems
    that need larger populations and longer runs to converge.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: The last three lines of code create three mutable lists to store members of
    the current and next generations and the set of best solutions picked from successive
    generations.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Initializing Population and Fitness Evaluation
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This section differs in just a few ways to what we developed for [Project 33](chapter8.xhtml#pre-33).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Within the initPopulation() function, we first create each chromosome as an
    integer array ❶. This is because we’re allowing only binary gene values (0 or
    1) in individual chromosomes. Initially, all the genes will be set to 0 while
    the chromosome is initialized. We then randomly change these values to 1 and 0
    inside a while loop ❷. Further, we add only solutions that have nonzero or positive
    fitness values to the initial population ❸. This will help us get started with
    a better set of chromosomes and avoid a situation where all initial solutions
    have zero fitness values, which is difficult to improve on!
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: The remaining part of the function is the same as before—we’re sorting the initial
    population to get it ready for elitism inside the runGA() function and printing
    out the current best solution from the initial population.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: The helper function getFitness() receives a chromosome as its parameter and
    evaluates its fitness. It calculates the fitness as the weighted sum of values
    (sumValue), where weights are the genes from the chromosome ❹. It also calculates
    the weighted sum of weights as sumWeight ❺. If the sum of weights ≤ Wmax, the
    function returns the chromosome’s fitness; otherwise, 0 is returned.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, we must ensure that both sumWeight ≤ Wmax and sumValue
    > 0\. We enforce the former condition in this function. The latter is enforced
    inside the while loop of the initPopulation() function. A chromosome is used only
    if its fitness, as returned by the getFitness() function, is greater than zero
    ❸.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: The Driver Function
  id: totrans-162
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We likewise need to make only minor changes to this part of the code, which
    was developed for [Project 33](chapter8.xhtml#pre-33). First, we’ll delete the
    termination condition at the beginning. For knapsack problems, the optimal solution
    is generally unknown beforehand. We have to run the code several times to get
    a sense of what the best solution might be. Second, we’ll now save the best solutions
    from all generations in a list and pick the best overall solution from that list
    as the potential optimal solution.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the revised code for the runGA() function:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Apart from deleting the termination condition based on the fitness value, both
    of the revisions to the code are at the end of the code segment. First, the fittest
    solution from each generation is now added to the mutable bestSolutions list ❶.
    Second, we’ve added a new print function called printSolution() ❷ to tidy up the
    printing without adding clutter to runGA(). This function simply formats and prints
    the generation number along with the chromosome and fitness of the fittest solution
    for each generation.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This function prints a line composed of three substrings. The first substring
    represents the generation or iteration number. We assign 10 character spaces for
    this, of which 4 are allocated for displaying the number; the remaining spaces
    will be added after the number as padding (white spaces). The second substring
    simply contains the sequence of 12 genes converted into a string. The third substring
    contains the fitness value. We assign six spaces for the number, of which up to
    three will be used to display the fitness value; the remaining spaces will be
    added as padding in front of the characters displaying the fitness value.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: The Operator Functions
  id: totrans-169
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We’ll skip discussing the selectElites() and tournament() functions as no changes
    are required to use them in this example (you can copy them from [Project 33](chapter8.xhtml#pre-33)).
    However, we have a different chromosome structure for the knapsack problem and
    additional constraints to satisfy. This means we’ll have to make changes to the
    crossover() and mutation() functions.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As before, the crossover() function starts with randomly locating a point to
    split the chromosomes ❶. We use the copyRangeOf() method to copy different ranges
    of genes from parent 1 and parent 2 because the chromosomes are of type IntArray
    instead of String. The new chromosome is created by combining the first part of
    parent 1 with the second part of parent 2 (creating one child per crossover) ❷.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Next, we call the mutation() function to mutate this newly created chromosome
    in place ❸. Since arrays are passed by reference (memory location) rather than
    by value, all the genetic alterations will be applied directly to the selected
    elements of newChromosome, and we don’t need to return a separate mutated chromosome
    to the calling function.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Once this step is complete, a new child (Solution) is created and returned by
    using the newly created chromosome and its fitness ❹.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the mutation() function scans every gene in the chromosome and applies
    mutation to a gene by comparing a random number between 0 and 1 with the MUTATION_THRESHOLD.
    When the condition is met, it flips the value of the gene from 0 to 1 or vice
    versa ❺.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '##### The main() Function'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'The main() function for this project is similar to that of [Project 33](chapter8.xhtml#pre-33),
    with one additional call to printBestSolution() to print the best overall solution.
    Here is the code snippet including the print function:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The main() function is very short. It starts with printing key global parameters,
    then calls initPopulation() to create the initial population of solutions and
    the driver function runGA() to run the genetic algorithm that we’ve customized
    for the knapsack problem. Finally, it prints the best overall solution by calling
    the printBestSolution() function.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Next, the bestSolutions list is sorted in descending order so that the first
    item represents the best overall solution ❶. The properties of this item are then
    deconstructed as chromosome and fitness ❷. Finally, the sum of weights of the
    objects in this optimal (or near-optimal) solution is calculated as a weighted
    sum, the weights being the individual gene values (0, 1) ❸. The last line prints
    the sum of weights and fitness for the best overall solution.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following sample output from a run of the code provides an indication of
    what to expect when you run the code:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The optimal solution for Jonah is to choose objects 1, 2, 3, 4, and 12, which
    will give Jonah a combined value of 311 units. The total weight of the optimal
    choice is 173 units, just shy of the maximum allowable weight of 175 units.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: How do we know that no better solutions exist? In this case, you can verify
    the solution by using a brute-force approach—generating all possible combinations
    and checking corresponding sums of values and weights. I encourage you to search
    online for relevant tools or code examples you can use to confirm that 311 is
    indeed the best value Jonah can get under the circumstances.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Again, remember that the genetic algorithm is a stochastic algorithm, meaning
    no two runs will produce identical results. Moreover, nothing guarantees that
    for a given set of parameter values, the algorithm will consistently converge
    to the optimal solution every time you run the program. You may have to run the
    program multiple times or adjust the program parameters to eventually locate the
    optimal solution.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, genetic algorithms can help solve real-world combinatorial
    problems with hundreds of decision variables, where checking all possible combinations
    for the global optimal solution is impractical or impossible. They take far less
    time and require significantly less computational effort to generate near-optimal
    solutions.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 35: Optimize a Multivariate Function with the Genetic Algorithm'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: In this final project, we’ll learn how to apply the genetic algorithm to multivariate
    function optimization. The only requirement for the function is that it be defined
    in terms of the independent variables within the decision space. In contrast to
    gradient-based algorithms, this function does not have to be smooth or differentiable.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use a sufficiently challenging two-dimensional function known as the
    Eggholder function, defined by two independent variables: *x*[1] and *x*[2].'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (8.2) ![](../images/eq8-2.jpg)
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll find the minimum value of this function in the decision space defined
    as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ ![](../images/pg333.jpg)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: As shown earlier in [Figure 8-3](chapter8.xhtml#fig8-3), the Eggholder function
    has a very complex shape with numerous peaks and troughs. Because of this, deterministic
    gradient-based algorithms will have a hard time finding the global minimum. Deterministic
    search attempts will usually get stuck at local optima unless we use a hybrid
    approach that incorporates some random search features. In contrast, given enough
    diversity (population size) and time (number of generations), a genetic algorithm
    can locate the global minimum fairly quickly for this problem.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The Strategy
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To implement function optimization in a genetic algorithm, the decision variables
    are treated as individual genes, meaning the two-variable Eggholder function will
    have two genes. This time, however, these genes will be represented as real numbers,
    including fractions, instead of characters (as in [Project 33](chapter8.xhtml#pre-33))
    or binary values (as in [Project 34](chapter8.xhtml#pre-34)).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: We also need to address the fact that this is a minimization problem, not a
    maximization problem as in the previous two projects. In those cases, the goal
    was to find a solution with the greatest fitness, whereas now we want to find
    the solution with the smallest fitness. Fortunately, we can easily handle this
    case by multiplying the objective function by –1\. This adjustment allows us to
    continue using the existing code developed for maximization problems. Notably,
    if we were to switch back to a maximization problem, we could use the same code
    without needing to multiply the objective function by –1.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we need a new way to implement mutation for function optimization.
    In previous projects, we introduced mutation by randomly replacing a character
    or a binary value, but that approach does not make sense for a real number. Digits
    in a real number cannot be arbitrarily replaced, as their relative position within
    the number has additional significance. Therefore, for real-valued genes, mutation
    is introduced as a small noise that is randomly added to or subtracted from the
    genes (we still use a probability threshold). The magnitude of the noise is calculated
    as a small fraction of the range for a specific gene (decision variable). By doing
    so, we can properly scale the magnitude of the noise or mutation without having
    to worry about the underlying units used for the corresponding decision variable
    in the function.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The code for function optimization has the same general structure as Projects
    33 and 34\. It is worth reiterating that for minimization of the objective function,
    we’ll have to multiply it by –1, whereas for maximization no alteration to the
    objective function is needed.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '##### Problem Definition and Global Parameters'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: 'This code segment includes the import block, a data class, global parameters,
    and several collections of mutable lists:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The code segment begins by importing the necessary math functions to calculate
    the function value or fitness. Remember to import only the methods you need, instead
    of importing all of them using an import kotlin.math.* statement. We then declare
    the chromosome to be of type DoubleArray ❶ to deal with real-coded genes.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: We also define getFitness as a variable and assign it a reference to the Eggholder
    function ❷. This approach allows us to define other functions later. And to use
    those, we simply need to reassign getFitness to the desired function.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Because the Eggholder function is a function of two independent variables (*x*[1]
    and *x*[2]), we will need two real-coded genes per chromosome ❸.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: The next two lines set the bounds for the decision variables and calculate the
    range for each. For real-coded genes, the magnitude of mutation is typically set
    to a small value relative to the range of the decision variables. This approach
    has the benefit of being scale independent.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: The remaining part of the code segment is similar to that of previous projects.
    This time, the population is composed of 100 individuals (POP_SIZE), and it will
    evolve for 200 generations (MAX_GEN). The MUTATION_THRESHOLD is now set to 0.5
    ❹, in line with the practice of setting the mutation probability equal to the
    inverse of the number of genes.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we could’ve tried many other combinations of parameter values. The
    values used in this code segment were chosen based on a number of trials to ensure
    that the global minima for the Eggholder function can be found quickly.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Initializing Population and Fitness Evaluation
  id: totrans-210
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The general organization of this code snippet is very similar to that of the
    two previous projects, with a few problem-specific adjustments:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We generate the chromosome as a DoubleArray with two elements (*x*[0] will be
    gene 1, and *x*[1] will be gene 2) ❶. We then initialize the genes randomly, ensuring
    they stay within their respective bounds (defined by the decision space) ❷. The
    rest of the code segment assigns the solutions to the mutable list population,
    sorts the population in descending order, and prints the best solution from the
    initial population ❸.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, this code doesn’t include a getFitness function; instead,
    we had pointed getFitness to the eggHolder() function, which returns the value
    of the objective function (fitness). For convenience, we’ve broken down the objective
    function given by Equation 8.2 into three parts, which are later combined to calculate
    the fitness value ❹. Notice that we’re multiplying the fitness by –1 before returning
    the value to getFitness. Doing so enables us to use the code developed for maximization
    problems to solve a minimization problem.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: We’ll skip reviewing the runGA() function as it is identical to the one used
    for [Project 34](chapter8.xhtml#pre-34). The same goes for the selectElites()
    and tournament() functions. Therefore, we’ll move straight to the crossover()
    and mutation() functions.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Operator Functions for Crossover and Mutation
  id: totrans-216
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We’ll now move on to the two key operator functions performing crossover and
    mutation to examine the differences introduced for the real-coded genes.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The purpose of the crossover function for real-valued genes remains the same:
    to produce a new chromosome for the child by using genetic materials from the
    parents. Several methods are available for creating the new chromosome or genes.
    In this example, we’re using a random-weighted scheme based on a randomly selected
    value *s* between 0 and 1 ❶. (If we used a fixed weight, s=0.5, that would be
    equivalent to using the arithmetic average of the gene values from two parents
    to create a new gene.)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: We use the weighted average scheme to generate two new genes (x1 and x2) and
    ensure that these values are within the bounds of the decision variables. We then
    compose the new chromosome xNew as a DoubleArray, with two genes as its elements
    ❷.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Next, we call the mutation() function to mutate this newly created chromosome
    in place ❸. Since arrays are passed by reference (memory location), mutations
    can be directly applied to the elements (genes) of the array, and we don’t need
    to return anything to the calling function. Once mutation is applied, a new child
    (Solution) is created and returned using the newly created chromosome and its
    fitness ❹.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: The mutation() function, similar to [Project 34](chapter8.xhtml#pre-34), scans
    each gene and mutates it if a random number between 0 and 1 is less than MUTATION_THRESHOLD.
    It randomly picks the sign of the mutation (positive or negative) ❺ and calculates
    the value as the sign times the decision variable’s range times MUTATION_FACTOR
    ❻. It also ensures that the mutated genes are within the bounds of the corresponding
    decision variables.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we proceed to the main() function, we need to adjust the printSolution()
    function from [Project 34](chapter8.xhtml#pre-34). It now takes a solution with
    a chromosome of type DoubleArray instead of an IntArray. Use the following updated
    function in your code:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: You can review this code and compare it with the program output as an exercise,
    since you are familiar with these helper functions.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: The main() Function
  id: totrans-226
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The code snippet for the main() function, including the printBestSolution()
    function, is likewise similar to the main() functions in previous projects.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The main() function starts by printing key global parameters. It then calls
    initPopulation() to initialize the population and launches the driver function
    runGA() to carry out function minimization using a genetic algorithm.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: In the printBestSolution() function, we format and print the two real-valued
    genes on the same line by using a for loop. Finally, we print the negative fitness
    value to get the correct sign for the minimum fitness.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We’re now ready to run the code and examine the results. If you use the same
    global parameter values that I have used for this project, you are likely to get
    the global optimal solution within five to seven attempts. Let’s look at a sample
    output:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The first section of the results shows the global parameters used for solving
    this problem—population size (100) and number of generations (200). Elitism is
    set to 0.1, or 10 percent. We used a mutation threshold of 0.5 because we have
    two genes, but we could have used a lower threshold if this threshold caused the
    best solutions to oscillate rather than converge. Due to the presence of many
    near-optimal solutions within the decision space of this problem, a higher-than-usual
    mutation threshold may have helped the algorithm to get out of local minima and
    explore other regions.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: The initial best fitness value was –809.63, which is not that close to the global
    minimum of –959.64 located after 117 iterations (not shown in the partial output
    above). Once this value was reached, the best solution remained unchanged until
    the program ended after completing the maximum number of iterations.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: We can see from the last part of the results that the optimal solution is located
    at *x*[1] = 512.0 and *x*[2] = 404.23\. [Figure 8-9](chapter8.xhtml#fig8-9) shows
    this point as a white half-circle near the top-right corner of the contour plot
    of the Eggholder function.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-9.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-9: The contour plot of the Eggholder function'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the global solution is literally on the right-hand boundary of
    the decision space in [Figure 8-10](chapter8.xhtml#fig8-10). The grayscale bar
    indicates that the darker regions are troughs and the lighter regions are peaks.
    Clearly, the fitness values are close to the global minima in many cases (based
    on the darkness of the shade). This is why it is so difficult to find the global
    minima for the Eggholder function.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-10](chapter8.xhtml#fig8-10) shows the convergence pattern for this
    problem. The fitness value improves in a stepwise manner with the number of generations
    (iterations) until it reaches the global minima.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-10.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-10: The convergence pattern for the Eggholder function using the genetic
    algorithm'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: We’ll revisit this problem using particle swarm optimization (another NIA) and
    draw the corresponding convergence pattern in the next chapter. You’ll see that
    while both methods are capable of identifying the global optima, particle swarm
    optimization will do that much quicker!
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Stopping Condition for Genetic Algorithms
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When solving real-world optimization problems, we often lack knowledge of the
    global optimal solution. Consequently, we cannot directly use it as a stopping
    condition. To address this challenge, we can employ several strategies. In this
    section, I’ll discuss commonly used approaches for defining stopping conditions
    in genetic algorithms.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: First, the stopping condition can be implemented as the maximum number of generations,
    as we’ve done for all three projects on the genetic algorithm. In general, you
    wouldn’t know how many iterations it might take to solve a previously unsolved
    problem. This will depend on the nature of the problem, the global parameter values,
    and the specific schemes used for various operator functions. You’ll have to gradually
    adjust the number of iterations (along with other parameters) to find a combination
    of values that works for the problem at hand. Interestingly, we can use the genetic
    algorithm to find optimal combinations of global parameters. In the field of deep
    learning, the genetic algorithm has been used to optimize global parameters and
    quickly train neural networks that produce high-quality results.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Second, you could stop the algorithm from iterating if the best solution’s fitness
    does not show noticeable improvements for several generations (for example, very
    little or no improvement over the past 30 or 50 generations). This will require
    additional coding to track improvements dynamically, but this can be a strategy
    to let the algorithm stop automatically, even when the maximum number of iterations
    has not been reached.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Third, for certain types of problems, you may be able to set a target for the
    fitness and have the program terminate once that target is reached (recall that
    we had a text-matching target for the first project). When the target is difficult
    to reach, you could also terminate the program when a predetermined percentage
    of that target is reached (instead of matching the target exactly).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: A lot more could be said about genetic algorithms, and researchers are frequently
    developing new adaptive or hybrid strategies and finding new applications. If
    you are interested in the state of the art, I suggest reviewing recent journal
    articles on the application of the genetic algorithm in your field of interest.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Project 35](chapter8.xhtml#pre-35), we revised the code developed for function
    maximization to handle a minimization problem. However, changing the code back
    and forth can easily lead to errors. Therefore, in the next exercise you will
    develop new code to directly handle function minimization problems.  ### Summary'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you explored the fascinating world of nature-inspired algorithms,
    computational methods that mimic natural phenomena to solve complex problems.
    One key feature of these algorithms is that they are stochastic in nature: they
    exploit built-in randomness to tackle problems that are intractable or too complex
    for conventional methods. You learned about the benefits and challenges of using
    nature-inspired algorithms and focused on one of the most popular and powerful
    examples: the genetic algorithm.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'The genetic algorithm is inspired by the process of natural evolution and uses
    a population of candidate solutions that undergo selection, crossover, and mutation
    to find the best solution for a given problem. You learned several ways to implement
    these operations and adjust the parameters of the algorithm to achieve the best
    performance. You also applied genetic algorithms to three different projects in
    order to:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: Generate a target string from a random population of characters
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximize the value of items in a knapsack with a limited capacity
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Find the global optimum solution for a real-valued and highly complex multivariate
    objective function
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, you completed a set of exercises that cover additional techniques
    for the crossover operation and dedicated methods for solving minimization problems
    directly. By the end of this chapter, you gained a solid understanding of the
    theory and practice of genetic algorithms, and how they can be used to solve various
    types of optimization problems.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Brownlee, Jason. *Clever Algorithms: Nature-Inspired Programming Recipes*.
    Electronic version, June 16, 2012\. *[https://github.com/clever-algorithms/CleverAlgorithms](https://github.com/clever-algorithms/CleverAlgorithms)*.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'Buontempo, Frances. *Genetic Algorithms and Machine Learning for Programmers*.
    Raleigh, NC: The Pragmatic Bookshelf, 2019.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'Gen, Mitsuo, and Runwei Cheng. *Genetic Algorithms and Engineering Optimization*.
    New York: John Wiley & Sons, 2000.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: 'Goldberg, David. *Genetic Algorithms in Search, Optimization and Machine Learning*.
    Reading, MA: Addison-Wesley Professional, 1989.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: 'Haupt, Randy L., and Sue Ellen Haupt. *Practical Genetic Algorithms*. 2nd ed.
    Hoboken, NJ: John Wiley & Sons, 2004.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'Yang, Xin-She. *Nature-Inspired Optimization Algorithms*. 2nd ed. London: Academic
    Press, 2021.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
