- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: 8 THE GENETIC ALGORITHM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/icon.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Many wonders of modern science were inspired by nature. Airplane and glider
    designs were based on the flight of birds. Camouflage—a tactic for survival—derives
    from mimicry, a form of antipredator adaptation. The hooked barbs of a thistle
    led to the invention of Velcro. Even rather dull-looking termite mounds teach
    us about natural ventilation and cooling, an idea used in modern architecture.
  prefs: []
  type: TYPE_NORMAL
- en: The world of computing is no different. The exciting field of machine learning,
    especially deep learning, is inspired by how the human brain processes information.
    By copying natural strategies that evolved over millions of years, we’ve developed
    algorithms to solve problems that were previously thought to be unsolvable with
    traditional mathematical tools.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter and the next, you’ll learn how these nature-inspired algorithms
    work, about their advantages and limitations, and how to implement them in Kotlin.
    This chapter focuses on the genetic algorithm, an evolutionary process–based method.
    The next chapter covers particle swarm optimization and ant colony systems, two
    methods that mimic the behavior of biological agents or species. For each method,
    I’ll start with the key concepts and then show you how to code and apply them
    to real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: Nature-Inspired Algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Nature-inspired computing refers to observing how nature solves complex biological
    or physical problems and then applying similar strategies to contemporary scientific,
    engineering, or management problems. The core of nature-inspired computing is
    *nature-inspired algorithms (NIAs)*, which rely on strategies learned from nature.
  prefs: []
  type: TYPE_NORMAL
- en: Biology-based NIAs can be observed in natural processes, such as the evolution
    of a species or the functioning of neurons in the human brain. These processes
    led to the development of genetic algorithms and deep neural networks. Individual
    and collective behaviors of members (or *agents*) of a population can also form
    the basis for new NIAs. For example, the foraging behavior of ants around their
    colony inspired the ant colony optimization algorithm. Whereas ants tend to work
    independently without any explicit collaboration with other members of the colony,
    the behavior of a large school of fish or birds indicates swarm intelligence,
    which has led to the development of the particle swarm optimization algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Even nonliving natural processes involve embedded strategies optimized for meeting
    certain goals. Examples of such algorithms include gravitational search (based
    on Newton’s law of gravity) and simulated annealing (based on thermodynamics).
    In general, these algorithms serve as powerful tools for optimizing various processes
    or systems, resulting in significant gains in efficiency and cost savings.
  prefs: []
  type: TYPE_NORMAL
- en: Before going into detail on genetic algorithms, I’ll introduce the concepts
    of optimization and global solutions. Additionally, I’ll highlight instances where
    NIAs prove more effective than traditional mathematical tools for solving real-world
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: The Optimization Problem
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: NIAs are well suited to solving optimization problems, in which we want to find
    the best solution of all possible solutions. To solve such problems, we minimize
    or maximize an *objective function*, a mathematical expression that represents
    the goal of what we want to achieve through optimization. It is expressed in terms
    of one or more *decision variables*, quantities we can adjust to optimize the
    objective function.
  prefs: []
  type: TYPE_NORMAL
- en: For real-world problems, the decision variables will be bounded. Additional
    constraints may limit and define the decision space within which the optimal solution
    must be found.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider a simple example with only one bounded decision variable:'
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (8.1)$Equation$ ![](../images/eq8-1.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: In Equation 8.1, *f*(*x*) is an objective function of a single variable *x*.
    Our goal is to find the value of *x* for which *f*(*x*) will be minimum, provided
    *x* stays within ±3.
  prefs: []
  type: TYPE_NORMAL
- en: Since *x* in this case has an exponent of 2, *x*² will always be positive (irrespective
    of whether *x* is positive or negative) and will continue to increase as *x* increases
    in absolute terms. Therefore, the right-hand side of Equation 8.1 will have the
    smallest value when *x* = 0\. In other words, the optimal solution (marked by
    an asterisk) for this problem is *x** = 0, and the corresponding optimum value
    of the function is *f*(*x*)* = –2.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-1](chapter8.xhtml#fig8-1) shows a visual representation of this function,
    which takes the shape of a parabola with its vertex at (0, –2). We can also visually
    confirm that *f*(*x*) has its minimum at point C (the vertex of the parabola).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-1: The optimal value for a parabolic function'
  prefs: []
  type: TYPE_NORMAL
- en: A property of this function allows us to identify the optimal solution without
    knowing its exact location. The dashed lines touching the function at points A,
    B, and C in [Figure 8-1](chapter8.xhtml#fig8-1) show the *slope*, also called
    the *gradient*, of the function at those locations. The slope of a function measures
    how much the value of a function changes when the value of the decision variable
    changes by a small amount. Notice that the gradient at point C, where the function
    value is minimum, is 0 (the dashed line is horizontal). Thus, if we randomly started
    our search for the optimal solution at point A, we could have moved in the direction
    of decreasing gradient (for example, from A to B or from B to C) until the gradient
    becomes 0\. If we continue to move beyond the vertex to the opposite side, the
    slope will change its direction and start increasing. This will cause the function
    value to increase, and we’ll move away from the optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: For a function that is smooth (no kinks) and continuous (no jumps) and has only
    one maximum or minimum within the decision space, the gradient-based search strategy
    will always work in finding the *global optimum*— the best possible solution for
    a given problem. In fact, for a well-behaved function like this, we can find the
    optimal solution by simply setting the slope of the function with respect to the
    decision variable (called the derivative in differential calculus) to 0 and solving
    the resulting equation for the optimal solution. This approach will also work
    for functions with two or more decision variables as long as the function is *well
    behaved*, meaning it is both smooth and continuous.
  prefs: []
  type: TYPE_NORMAL
- en: Things get messier when we deal with a multimodal function with multiple locations
    where the gradient is 0, as shown in [Figure 8-2](chapter8.xhtml#fig8-2).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-2: Local and global minima for a univariate function'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-2](chapter8.xhtml#fig8-2) shows four local minima at points A, C,
    D, and E, and one global minimum at point B within the decision space. In a situation
    like this, whether an algorithm based on gradient descent will converge to the
    global minimum depends on the point from which we start the search. Nothing guarantees
    that we’ll find the global minimum unless we make multiple attempts from different
    starting points (initial conditions).'
  prefs: []
  type: TYPE_NORMAL
- en: For a better appreciation of the challenge involved when we try to find global
    optima for a multivariate function, consider the graph in [Figure 8-3](chapter8.xhtml#fig8-3).
    This shows the results of the two-variable Eggholder function, discussed further
    in the final project of this chapter. For a problem like this, a simple gradient-based
    algorithm can easily get stuck at one of the many local minima. To make things
    worse, the equations defining such functions are typically not differentiable,
    and we cannot use calculus-based tools to estimate the global optima.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-3: The Eggholder function with numerous local minima'
  prefs: []
  type: TYPE_NORMAL
- en: 'Functions of two decision variables have a silver lining, however: we can create
    3D plots of these functions for a bounded decision space. Based on a visual inspection
    of the surface or contour plots, it may then be possible to narrow down the search
    space to a number of smaller subzones where we can conduct an extensive local
    search to uncover the global minima (more than one global minimum could exist).'
  prefs: []
  type: TYPE_NORMAL
- en: What about functions of higher dimensions? In fact, complex real-world optimization
    problems can have hundreds of decision variables. It is not humanly possible to
    conceive what a function of several hundred variables might look like in a *hyperspace*
    (a higher-dimensional space beyond human comprehension). Our best bet for identifying
    an optimal or near-optimal solution in a hyperspace is to conduct a broad-based
    search combining *heuristics* (special knowledge about the nature of the problem)
    and *randomization* (selecting initial conditions or intermediate values randomly).
    This strategy is likely to allow the algorithm to escape local optima and find
    solutions that are superior to what a pure random search might reveal. We typically
    repeat this process numerous times and accept the best-so-far solution as a proxy
    for the unknown global optima.
  prefs: []
  type: TYPE_NORMAL
- en: Even when looking for an optimal combination of decision variables that can
    have only discrete values (whole numbers), the brute-force approach of trying
    out all possible combinations normally doesn’t work in higher dimensions. This
    is because the number of combinations may be so large that it is practically impossible
    to complete that search in a reasonable amount of time. It’s in this context that
    nature-inspired algorithms come to our rescue.
  prefs: []
  type: TYPE_NORMAL
- en: When to Use NIAs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Compared to traditional mathematical tools, NIAs are less sensitive to the nature
    or complexity of the optimization problem. An objective function may be nonlinear,
    nonsmooth, multidimensional, and multimodal, but these attributes are not a big
    concern for NIAs (though we still have to choose the right tool from the basket
    of options). NIAs are especially suitable for solving very large optimization
    problems and finding near-optimal solutions without expending too many resources
    (such as computational time or energy use).
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional optimization methods, whether they employ a gradient descent algorithm
    or not, are deterministic: if we start the search from a given point, we’ll always
    reach the same solution or approximation after a given number of steps. This feature
    makes deterministic algorithms more prone to getting stuck at local optima because
    no built-in freedom exists to explore a different path unless the initial condition
    is changed.'
  prefs: []
  type: TYPE_NORMAL
- en: NIAs, on the other hand, are *stochastic*, meaning that their results cannot
    be predicted beforehand. This is because NIAs typically have multiple built-in
    steps that rely on random selection. For the same initial condition, a stochastic
    algorithm can produce very different results. This innate ability to randomly
    choose a different path allows NIAs to avoid getting stuck at local optima and
    to eventually find the global or near-global optima.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, some NIAs are based on the efforts of agents that operate independently
    (for example, ants in the ant colony optimization algorithm). This allows us to
    implement the algorithm so that it can benefit from parallel processing to improve
    computational efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: In sum, we can use NIAs to solve large, complex, multidimensional optimization
    problems for which no known analytical solutions exist or for which such solutions
    cannot be found due to the nature of the problem. However, NIAs are not the ideal
    choice for solving the many optimization problems that can be efficiently solved
    using deterministic methods (for example, using linear or integer programming
    or various graph search algorithms).
  prefs: []
  type: TYPE_NORMAL
- en: An Overview of the Genetic Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The genetic algorithm is among the best-known NIAs. It is modeled after the
    biological evolution of species driven by both the sexual reproduction of parents,
    who contribute genetic materials, and natural selection (survival of the fittest).
    In addition to inheriting genes from its parents, the offspring’s *chromosomes*
    (collections of genes) undergo random alterations called *mutation* that introduce
    new features to its gene pool. The offspring is then subjected to a selection
    process based on its *fitness* (a measure of how well an individual contributes
    to reaching a certain goal) before it is allowed to reproduce. The process eventually
    leads to a generation of individuals with a significantly enhanced gene pool.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-4](chapter8.xhtml#fig8-4) shows the main components of the genetic
    algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-4: The key components of the genetic algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: All genetic algorithms start with a population of randomly created individuals.
    Each individual is essentially a potential solution represented by its gene pool.
    These individuals are evaluated and screened based on their fitness, which we
    attempt to maximize or minimize until a termination condition is met. Otherwise,
    we choose a batch of individuals with better fitness values who are then allowed
    to mate, produce offspring, and replace their parents as the next generation.
    I’ll explain these steps further in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: Genetic Operators
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Genetic operators include the three core components of genetic algorithms—selection,
    crossover, and mutation—that work in tandem and allow the algorithm to converge
    toward a solution. *Selection* refers to the process of choosing an individual
    from a population based on their fitness (their potential contribution to finding
    the optimal solution). Selection may involve the entire population or a subset
    of the population, as individuals are drawn at random based on specific strategies.
    *Crossover* involves combining genetic materials from parents to create offspring.
    In the genetic algorithm, it always involves two parents and is therefore a binary
    operator. *Mutation* is a random alteration of an individual’s genetic information.
    It is a unary operator because it is applied to one individual at a time.
  prefs: []
  type: TYPE_NORMAL
- en: '#### Selection'
  prefs: []
  type: TYPE_NORMAL
- en: The selection operation ensures that better genes are passed on from one generation
    to the next. The implementation of this process may vary depending on the problem,
    but the end goal is to select two parents (chromosomes) to participate in the
    reproduction through crossover. The commonly used strategies for selection include
    tournament, roulette wheel, and rank-based selection.
  prefs: []
  type: TYPE_NORMAL
- en: Tournament
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The tournament selection process is based on running fitness-based competitions
    among randomly selected individuals, as shown in [Figure 8-5](chapter8.xhtml#fig8-5).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-5: Using tournaments to select parents'
  prefs: []
  type: TYPE_NORMAL
- en: To create a new child, the process starts by randomly selecting four individuals
    grouped into two pairs. From each pair, the individual with better fitness is
    selected as a parent. The process selects two parents per round who will reproduce
    via crossover (explained later) to give birth to an offspring.
  prefs: []
  type: TYPE_NORMAL
- en: Roulette Wheel
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As the name implies, roulette wheel selection is comparable to spinning a dial
    on a board divided into segments. The area of these segments is proportional to
    the relative fitness of the members of the population from which parents are to
    be chosen. Let me explain the process with a numerical example, as shown in [Table
    8-1](chapter8.xhtml#tab8-1).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8-1: Roulette Wheel Data'
  prefs: []
  type: TYPE_NORMAL
- en: '| Individual | Fitness | Relative fitness (RF) | Cumulative RF |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| P1 | 12 | 0.286 | 0.286 |'
  prefs: []
  type: TYPE_TB
- en: '| P2 | 5 | 0.119 | 0.405 |'
  prefs: []
  type: TYPE_TB
- en: '| P3 | 8 | 0.190 | 0.595 |'
  prefs: []
  type: TYPE_TB
- en: '| P4 | 10 | 0.238 | 0.833 |'
  prefs: []
  type: TYPE_TB
- en: '| P5 | 4 | 0.095 | 0.929 |'
  prefs: []
  type: TYPE_TB
- en: '| P6 | 3 | 0.071 | 1.000 |'
  prefs: []
  type: TYPE_TB
- en: '| SUM = | 42 | 1.000 |  |'
  prefs: []
  type: TYPE_TB
- en: '[Figure 8-6](chapter8.xhtml#fig8-6) shows the graphical representation of the
    example in [Table 8-1](chapter8.xhtml#tab8-1).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-6: Selecting parents using the roulette wheel method'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we consider a population of six individuals, P1 through P6\.
    Their fitness values are given in the second column of [Table 8-1](chapter8.xhtml#tab8-1).
    The relative fitness (RF) values are calculated by dividing individual fitness
    values by the sum of all individual fitness values (for example, RF for P1 = 12/42).
    The last column represents the cumulative RF (CRF), which is created by adding
    all RF values up to a certain row. For example, the CRF corresponding to P2 =
    0.286 + 0.119 = 0.405\. The last CRF, which is the sum of all individual RF values,
    will be 1.0\. In the roulette wheel scheme, RF values are used as proxy probabilities
    for individuals to be selected at random when an unbiased virtual dial is spun.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Figure 8-6](chapter8.xhtml#fig8-6), these six individuals are represented
    by six different segments whose areas are the same as their RF values (shown next
    to the individual names). To implement the roulette wheel method, we draw a random
    number between 0 and 1 from a uniform distribution, which has the same effect
    as spinning the dial. (This is done programmatically by using the random() method
    in the standard Kotlin math library.) Let’s say that the value of this random
    number is 0.68, equivalent to having the dial stop inside the fourth segment (between
    CRFs of 0.595 and 0.833). Based on this draw, we would select P4 as parent 1 and
    repeat the process one more time to choose parent 2.  ##### Rank-Based Selection'
  prefs: []
  type: TYPE_NORMAL
- en: The third selection method, rank-based selection, is very similar to the roulette
    wheel method. Here, we order the individuals in ascending or descending order,
    depending on the problem, and assign each individual a rank based on their fitness.
    If two or more individuals have the same fitness, they are assigned an average
    value (based on their positions in the ordered list) as their rank. Finally, the
    ranks are used to calculate RF values and select the mating parents as we would
    using the roulette wheel scheme.
  prefs: []
  type: TYPE_NORMAL
- en: Crossover
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The crossover operation is designed to intermix the genes of two parents to
    create one or two offspring who become members of the next generation. As with
    the selection operator, many ways of splitting the chromosomes and recombining
    the genes are available. [Figure 8-7](chapter8.xhtml#fig8-7) shows the schema
    for a simple but effective approach to this operation, called a single-point crossover.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-7: The single-point crossover operation'
  prefs: []
  type: TYPE_NORMAL
- en: We start the process by identifying two parents through the selection operation.
    These parents would normally have chromosomes consisting of different genes. In
    the example in [Figure 8-7](chapter8.xhtml#fig8-7), both parents have chromosomes
    made of binary genes denoted by 0 or 1\. Parent 1’s genes are shown as white cells,
    whereas parent 2’s genes are gray cells.
  prefs: []
  type: TYPE_NORMAL
- en: The first step of the crossover operation is to draw a random integer from a
    uniform distribution between 1 and the number of genes minus 1, which would be
    between 1 and 5 (inclusive) in our example. Let’s say the integer drawn is 4\.
    We’d then split chromosomes of both parents at this location (between the fourth
    and fifth genes shown in [Figure 8-7](chapter8.xhtml#fig8-7)). Finally, we’d swap
    the split parts by adding the last two genes from parent 2 to parent 1 (the two
    gray cells of child 1) and adding the last two genes from parent 1 to parent 2
    (the two white cells of child 2).
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we used two parents to create two children. However, we could
    also decide to produce only one child per iteration to keep the algorithm simple
    and easy to code. For *real-coded genes*—genes represented by real numbers—a crossover
    operation will produce only one child because of the way the method is implemented.
    We’ll discuss real-coded genes further in the final project of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Many other types of crossover operations, such as multipoint crossover and ordered
    crossover, exist. For real-coded genes used in mathematical function optimization,
    crossover operations could be based on an arithmetic, geometric, or weighted mean
    of fitness values.
  prefs: []
  type: TYPE_NORMAL
- en: Mutation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Mutation involves randomly changing the values of genes or, for real-coded genes,
    adding a small noise to those values before adding a child to the next generation.
    Mutation is applied to every gene in the chromosome one at a time. First, we randomly
    draw a real number between 0 and 1 and compare that with a mutation threshold
    (probability), typically set to a very small value. If the random value drawn
    is less than or equal to the mutation threshold, we alter the genetic content
    for that gene. For a binary chromosome where the genes are either 1 or 0 (indicating
    inclusion or exclusion of some entity in the solution), this alteration is conducted
    by flipping the gene value from 0 to 1 or vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-8](chapter8.xhtml#fig8-8) visually explains this process.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-8: Mutation in a binary chromosome'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 8-8](chapter8.xhtml#fig8-8), the second and fifth genes have been
    randomly selected for mutation. Given that these are binary genes, their gene
    values have been flipped from 0 to 1.
  prefs: []
  type: TYPE_NORMAL
- en: Elitism
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before we move on to tackling our first genetic algorithm project, I’ll introduce
    one more important concept—*elitism*. This technique involves sorting the current
    population based on their fitness, then adding a fraction of that sorted population
    to the next generation before attempting crossover and mutation. This operation
    is called elitism because it favors the fittest individuals. Elitism generally
    helps reduce the number of computations needed to locate the optimal solution
    because it protects some of the best chromosomes from getting altered or diluted
    by crossover and mutation operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 33: Evolve Gibberish into Shakespeare'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our first coding project, we’ll create a population with random collections
    of genes as their chromosomes. We’ll then use a genetic algorithm to refine those
    chromosomes until one of the individuals becomes as eloquent as Shakespeare and
    repeats Hamlet’s famous line “To be, or not to be: that is the question,” expressed
    in its gene sequence!'
  prefs: []
  type: TYPE_NORMAL
- en: The Strategy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To solve this problem, we’ll create a population of size 100\. No hard-and-fast
    rule applies on this, and a bit of experimentation is required to estimate a reasonable
    size for a given problem. Many factors are at play that will determine the convergence
    rate of the algorithm, including population size, the way the genetic operators
    are implemented, and the stopping condition. One possible strategy is to start
    with a smaller population size and then gradually increase it until further improvements
    in the solution become negligible.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to determine the size of the chromosomes. For this specific problem,
    each individual’s chromosome will have 42 genes—the length of the text we aim
    to reproduce using the algorithm. These genes will be randomly selected from a
    pool of 87 genes, which in this case is a collection of alphanumeric characters
    (including punctuation and parentheses). Since our goal is to exactly match the
    target text, this collection includes both uppercase and lowercase letters.
  prefs: []
  type: TYPE_NORMAL
- en: In our genetic algorithm implementation, we’ll use elitism and tournament-based
    selection as our operators. Additionally, we’ll employ a single-point crossover
    scheme. For mutation, we will use a threshold of 1/42 to ensure that on average
    one gene will mutate for each new child created via crossover.
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The overall structure of the code closely resembles the general structure of
    the genetic algorithm described in [Figure 8-4](chapter8.xhtml#fig8-4). We’ll
    discuss each of its components in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Global Declarations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this code segment, we create a data class, and declare and/or set required
    global parameters and collections. We also create two mutable lists of data objects
    to store population states for the current and next generations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Let’s walk through this segment step by step. At the top of the block, we create
    a Solution object (data class) that will be used to create the individuals who
    will make up the population and undergo genetic alterations.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we define the target string or the desired end state for the fittest individual
    in the population ❶. The target string has 42 characters (including spaces), which
    are stored in a string named TARGET. The target string is built from a pool of
    genes—characters that we typically use while composing phrases in English. This
    gene pool is saved as VALID_GENES ❷.
  prefs: []
  type: TYPE_NORMAL
- en: We set the population size (POP_SIZE) to 100 and the number of generations (MAX_GEN)
    to 1,000\. We also employ elitism. Fifteen percent of the population (the top
    15 fittest individuals) will be automatically included in the next generation.
    The remaining members of the next generation will be produced through selection,
    crossover, and mutation. The threshold for mutation has been set to 1.0/chromosomeLength
    ❸ so that on average 1 gene out of 42 will undergo mutation per offspring. (You
    may need to adjust this rule of thumb for other optimization problems. For example,
    you may have to explicitly set the mutation threshold from 1 to 3 percent when
    too few genes exist in the chromosome.)
  prefs: []
  type: TYPE_NORMAL
- en: The last two lines create two mutable lists of type Solution, which store the
    individuals belonging to the current generation (population) and to the next generation
    (nextgen).
  prefs: []
  type: TYPE_NORMAL
- en: Initializing Population and Fitness Evaluation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The initial population is created by making a call to the initPopulation() function,
    which in turn relies on the getFitness() helper function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The initPopulation() function creates the number of individuals specified by
    POP_SIZE (100, in this case) whose chromosomes are created by randomly picking
    individual genes (all 42 of them) from the supplied gene pool, VALID_GENES ❶.
    Once the chromosome is complete, its fitness is evaluated by calling the getFitness()
    function. A new Solution is created using the chromosome and fitness value and
    then added to the population ❷.
  prefs: []
  type: TYPE_NORMAL
- en: Before exiting this function, we sort the population in descending order and
    print the best solution from the initial population. This presorting is needed
    to check for the termination condition and implement elitism for the first generation
    inside the runGA() function. For subsequent generations, sorting is done at the
    end of each iteration inside runGA().
  prefs: []
  type: TYPE_NORMAL
- en: Within the getFitness() function, we create a list named pairs of type Pair<Char,
    Char> and calculate the fitness value for the given chromosome based on pair-wise
    comparisons. For each matching gene, fitness is incremented by 1 ❸. If a chromosome
    matches the target string exactly, it will have a maximum fitness value of 42.
  prefs: []
  type: TYPE_NORMAL
- en: The Driver Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In the code block for the runGA() function, we implement the core components
    of the genetic algorithm. This includes iterating over multiple generations, checking
    for the termination condition, and creating the next generation by using elitism,
    selection, crossover, and mutation—the entire collection of genetic operators.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The outermost for loop ❶ runs the genetic processes for the specified number
    of generations. Inside this loop, we first check for the termination condition
    by comparing the best fitness value from the current population with the maximum
    possible fitness ❷. If the condition is met, the program terminates after printing
    a message that it has reached the target. If the condition is not met, we implement
    elitism by calling the selectElites() function ❸, discussed in detail in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: We then move on to the first inner for loop ❹, which creates the remaining members
    of the next generation by selecting new parents by tournament, creating a child
    by calling the crossover() function (which also applies mutation to the newly
    created chromosome, as discussed in the next section), and then adding the child
    to the mutable nextgen list.
  prefs: []
  type: TYPE_NORMAL
- en: We use a second inner for loop ❺ to individually copy the next-generation solutions
    (nextgen) to population before nextgen is cleared for the next iteration. Notice
    that given the simple structure of the Solution data class, the copy() method
    applied to the elements of nextgen creates a deep copy and prevents cross-referencing
    between population and nextgen. In addition, transferring nextgen values to population
    at the end of each iteration eliminates the need to store multiple generations
    of solutions, which saves a lot of memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the final segment of the outermost for loop, we sort the newly updated population
    in descending order ❻ and print three key values per generation: the iteration
    number, the chromosome with the best fitness, and the corresponding fitness ❼.'
  prefs: []
  type: TYPE_NORMAL
- en: The Operator Functions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The runGA() function relies on several operator functions that perform the key
    genetic operations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The selectElites() function is a one-liner. It promotes the top 15 individuals
    (eliteSize = 15) from the current generation to the next generation without subjecting
    them to further genetic processes ❶.
  prefs: []
  type: TYPE_NORMAL
- en: The tournament() function randomly picks two individuals from the current population
    and returns the winner of the competition based on their fitness values ❷.
  prefs: []
  type: TYPE_NORMAL
- en: The crossover() function takes in two parents as arguments, splits their chromosomes
    at a random location, and combines the split parts from both parents to create
    a new chromosome for the offspring ❸. Next, this newly created chromosome (crossChromosome)
    is passed to the mutation() function ❹, which returns the final chromosome saved
    as newChromosome. A single offspring is then returned once the fitness value for
    the newly created chromosome is calculated by making a call to getFitness() ❺.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the mutation() function applies mutation to randomly selected genes.
    It first converts the chromosome from a string object to a character array because
    strings are immutable in Kotlin. The mutation operation, triggered by the MUTATION_THRESHOLD
    parameter ❻, is applied to each gene in the chromosome. Once the mutation operation
    is done, the character array is converted back to a string and returned as the
    new (mutated) chromosome ❼.
  prefs: []
  type: TYPE_NORMAL
- en: The main() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The main() function simply prints a few key problem-specific parameters and
    makes two function calls to finish the job.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first call to initPopulation() initializes the current population with random
    chromosomes. The second call to runGA() conducts the necessary genetic operations.
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Each time you run this program, it will take a different number of iterations
    to exactly match the target string. This is because we’re using a stochastic method
    that depends on many internal levels of random selection. This is a very helpful
    feature for solving large real-world problems that may not have a deterministic
    or known solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is some sample output from the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this instance, starting with chromosomes that had no resemblance to the target
    string, it took 379 generations for the algorithm to re-create the target string
    exactly. We haven’t made any attempt to fine-tune the global parameter values
    to increase the speed of convergence, yet the code converges to the optimal solution
    almost instantly (the processing time will depend on the configuration of your
    device). Pretty impressive!
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 34: Solve the Knapsack Problem'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’re likely familiar with Noah’s ark, the vessel Noah and his followers built
    to save themselves from a great deluge. The challenge that Noah faced was massive:
    he had to build a vessel of unprecedented size and choose who or what to take
    on board. To a mathematician, this latter decision is a classic example of an
    optimization problem where one tries to maximize the value of the objects that
    can be accommodated within a limited space.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s build a miniature version of this challenge and solve it using the genetic
    algorithm. We’ll name this project Jonah’s ark. Jonah lives in a flood plain that
    faces the risk of flash floods. Jonah knows he must be ready to leave the area
    at short notice. His quickest route to safety involves using a small-engine boat
    to get away from the rising river through a tributary beyond the reach of flood
    waters. Of course, the boat is small and can carry only so many items without
    sinking. Jonah must decide which of the valuable objects in his possession he
    should take with him without exceeding the capacity of the boat.
  prefs: []
  type: TYPE_NORMAL
- en: Jonah was able to come up with a short list of the 12 objects most valuable
    to him—which is still too many to take on board. Now he needs to figure out which
    combination of those objects he should choose so that their total worth (sum of
    assigned values) to him will be maximized without exceeding the capacity of his
    boat.
  prefs: []
  type: TYPE_NORMAL
- en: The Strategy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Jonah’s ark problem is a variation of what is known in mathematics as the
    *knapsack problem*:'
  prefs: []
  type: TYPE_NORMAL
- en: Let n be the number of objects one has to choose from. Let ***V*** = [v[1],
    v[2], . . . , vn] be the list of values (worth) of those objects and ***W*** =
    [w[1], w[2], . . . , wn] be the list of weights of those objects. Also, let ***W***max
    be the maximum weight that the knapsack can carry. The goal is to find a subset
    of m objects so that the sum of values for that subset is maximized while ensuring
    that the sum of corresponding weights remains ≤ ***W***m[ax].
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We’ll leverage the genetic algorithm to address this problem. It’s evident that
    we’ll have to make changes to the problem definition part of the code. First,
    given that Jonah now has a choice among 12 distinct objects, we’ll set the number
    of chromosomes to 12\. Each gene in the chromosome will assume a binary value,
    where 1 signifies the inclusion of an object in the solution and 0 denotes its
    exclusion. We’ll also calculate the fitness of a solution differently based on
    which objects are included and their respective values and weights. I’ll explain
    this further when we discuss the related code segment.
  prefs: []
  type: TYPE_NORMAL
- en: One important consideration is the composition of the initial population. We
    need to ensure that the initial population has some diversity. If all genes are
    randomly assigned, we might get a population with zero fitness. This would make
    crossover useless, and we would be relying solely on mutation, which is a very
    slow process. Therefore, while initiating the population, we’ll force each member
    to have a nonzero fitness.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start coding, we need to address a few technical considerations. First,
    we’ll adopt a 0-1 approach to solve this problem, meaning we’ll either include
    an object or completely exclude it in the solution. We’re not allowed to take
    a fraction of an object (and a fraction of its value). Second, we assume that
    we have only one copy of each object, so we cannot repeat any object in our solution.
    Third, we assume that we have only one knapsack to fill.
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We developed a fully functional genetic algorithm program in [Project 33](chapter8.xhtml#pre-33).
    For the most part, we’ll reuse that code and make a few adjustments needed to
    describe and solve the knapsack problem (or the Jonah’s ark problem).
  prefs: []
  type: TYPE_NORMAL
- en: Problem Definition and Global Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This code segment is composed of an import statement, data class declarations,
    the creation of a list of items to choose from, global parameters, and the creation
    of mutable lists to track population states for both the current and the next
    generations, as well as the best solutions from each generation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The code segment begins with a single import statement for the roundToInt()
    method that we’ll use shortly. We then define two simple data classes, Solution
    and Item, which are used to create individual members of the population and objects
    with their key attributes (value and weight). Notice that we’re creating the chromosome
    as an integer array and not as a string, as in [Project 33](chapter8.xhtml#pre-33).
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Depending on your IDE, you might encounter a “weak warning” while declaring
    the first data class of this project (*Solution*). This is because we’re using
    a property with an* Array *type (*chromosome*) in a data class (*Solution*). While
    this warning indicates potential issues for certain use cases, it does not apply
    to the problems discussed in this chapter and the next. If you find the warning
    bothersome, an alternative approach would be to use regular classes instead of
    data classes. In that case, you can manually add necessary custom methods that
    a data class generates automatically, such as* copy() *and* toString()*. I encourage
    you to experiment with this approach as a further learning opportunity.*'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we create a List of type Item with the 12 objects ❶. The capacity limit
    for the boat (maxWeight) is set to 175 units ❷ (we’ll assume this is in addition
    to Jonah’s own weight).
  prefs: []
  type: TYPE_NORMAL
- en: Given the relatively small number of objects to choose from, we’ve set the population
    size (POP_SIZE) to 25 and the number of generations (MAX_GEN) to a modest 30\.
    Elitism has been set to 0.1, or 10 percent. The MUTATION_THRESHOLD value is set
    a bit differently (its value is rounded off to three significant digits after
    the decimal point) ❸, but it still complies with the rule of thumb.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the mutation threshold can be rounded to a few decimal places without
    affecting the results. This can speed up the calculations for more complex problems
    that need larger populations and longer runs to converge.
  prefs: []
  type: TYPE_NORMAL
- en: The last three lines of code create three mutable lists to store members of
    the current and next generations and the set of best solutions picked from successive
    generations.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing Population and Fitness Evaluation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This section differs in just a few ways to what we developed for [Project 33](chapter8.xhtml#pre-33).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Within the initPopulation() function, we first create each chromosome as an
    integer array ❶. This is because we’re allowing only binary gene values (0 or
    1) in individual chromosomes. Initially, all the genes will be set to 0 while
    the chromosome is initialized. We then randomly change these values to 1 and 0
    inside a while loop ❷. Further, we add only solutions that have nonzero or positive
    fitness values to the initial population ❸. This will help us get started with
    a better set of chromosomes and avoid a situation where all initial solutions
    have zero fitness values, which is difficult to improve on!
  prefs: []
  type: TYPE_NORMAL
- en: The remaining part of the function is the same as before—we’re sorting the initial
    population to get it ready for elitism inside the runGA() function and printing
    out the current best solution from the initial population.
  prefs: []
  type: TYPE_NORMAL
- en: The helper function getFitness() receives a chromosome as its parameter and
    evaluates its fitness. It calculates the fitness as the weighted sum of values
    (sumValue), where weights are the genes from the chromosome ❹. It also calculates
    the weighted sum of weights as sumWeight ❺. If the sum of weights ≤ Wmax, the
    function returns the chromosome’s fitness; otherwise, 0 is returned.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, we must ensure that both sumWeight ≤ Wmax and sumValue
    > 0\. We enforce the former condition in this function. The latter is enforced
    inside the while loop of the initPopulation() function. A chromosome is used only
    if its fitness, as returned by the getFitness() function, is greater than zero
    ❸.
  prefs: []
  type: TYPE_NORMAL
- en: The Driver Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We likewise need to make only minor changes to this part of the code, which
    was developed for [Project 33](chapter8.xhtml#pre-33). First, we’ll delete the
    termination condition at the beginning. For knapsack problems, the optimal solution
    is generally unknown beforehand. We have to run the code several times to get
    a sense of what the best solution might be. Second, we’ll now save the best solutions
    from all generations in a list and pick the best overall solution from that list
    as the potential optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the revised code for the runGA() function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Apart from deleting the termination condition based on the fitness value, both
    of the revisions to the code are at the end of the code segment. First, the fittest
    solution from each generation is now added to the mutable bestSolutions list ❶.
    Second, we’ve added a new print function called printSolution() ❷ to tidy up the
    printing without adding clutter to runGA(). This function simply formats and prints
    the generation number along with the chromosome and fitness of the fittest solution
    for each generation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This function prints a line composed of three substrings. The first substring
    represents the generation or iteration number. We assign 10 character spaces for
    this, of which 4 are allocated for displaying the number; the remaining spaces
    will be added after the number as padding (white spaces). The second substring
    simply contains the sequence of 12 genes converted into a string. The third substring
    contains the fitness value. We assign six spaces for the number, of which up to
    three will be used to display the fitness value; the remaining spaces will be
    added as padding in front of the characters displaying the fitness value.
  prefs: []
  type: TYPE_NORMAL
- en: The Operator Functions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We’ll skip discussing the selectElites() and tournament() functions as no changes
    are required to use them in this example (you can copy them from [Project 33](chapter8.xhtml#pre-33)).
    However, we have a different chromosome structure for the knapsack problem and
    additional constraints to satisfy. This means we’ll have to make changes to the
    crossover() and mutation() functions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As before, the crossover() function starts with randomly locating a point to
    split the chromosomes ❶. We use the copyRangeOf() method to copy different ranges
    of genes from parent 1 and parent 2 because the chromosomes are of type IntArray
    instead of String. The new chromosome is created by combining the first part of
    parent 1 with the second part of parent 2 (creating one child per crossover) ❷.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we call the mutation() function to mutate this newly created chromosome
    in place ❸. Since arrays are passed by reference (memory location) rather than
    by value, all the genetic alterations will be applied directly to the selected
    elements of newChromosome, and we don’t need to return a separate mutated chromosome
    to the calling function.
  prefs: []
  type: TYPE_NORMAL
- en: Once this step is complete, a new child (Solution) is created and returned by
    using the newly created chromosome and its fitness ❹.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the mutation() function scans every gene in the chromosome and applies
    mutation to a gene by comparing a random number between 0 and 1 with the MUTATION_THRESHOLD.
    When the condition is met, it flips the value of the gene from 0 to 1 or vice
    versa ❺.
  prefs: []
  type: TYPE_NORMAL
- en: '##### The main() Function'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main() function for this project is similar to that of [Project 33](chapter8.xhtml#pre-33),
    with one additional call to printBestSolution() to print the best overall solution.
    Here is the code snippet including the print function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The main() function is very short. It starts with printing key global parameters,
    then calls initPopulation() to create the initial population of solutions and
    the driver function runGA() to run the genetic algorithm that we’ve customized
    for the knapsack problem. Finally, it prints the best overall solution by calling
    the printBestSolution() function.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the bestSolutions list is sorted in descending order so that the first
    item represents the best overall solution ❶. The properties of this item are then
    deconstructed as chromosome and fitness ❷. Finally, the sum of weights of the
    objects in this optimal (or near-optimal) solution is calculated as a weighted
    sum, the weights being the individual gene values (0, 1) ❸. The last line prints
    the sum of weights and fitness for the best overall solution.
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following sample output from a run of the code provides an indication of
    what to expect when you run the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The optimal solution for Jonah is to choose objects 1, 2, 3, 4, and 12, which
    will give Jonah a combined value of 311 units. The total weight of the optimal
    choice is 173 units, just shy of the maximum allowable weight of 175 units.
  prefs: []
  type: TYPE_NORMAL
- en: How do we know that no better solutions exist? In this case, you can verify
    the solution by using a brute-force approach—generating all possible combinations
    and checking corresponding sums of values and weights. I encourage you to search
    online for relevant tools or code examples you can use to confirm that 311 is
    indeed the best value Jonah can get under the circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: Again, remember that the genetic algorithm is a stochastic algorithm, meaning
    no two runs will produce identical results. Moreover, nothing guarantees that
    for a given set of parameter values, the algorithm will consistently converge
    to the optimal solution every time you run the program. You may have to run the
    program multiple times or adjust the program parameters to eventually locate the
    optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, genetic algorithms can help solve real-world combinatorial
    problems with hundreds of decision variables, where checking all possible combinations
    for the global optimal solution is impractical or impossible. They take far less
    time and require significantly less computational effort to generate near-optimal
    solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 35: Optimize a Multivariate Function with the Genetic Algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: In this final project, we’ll learn how to apply the genetic algorithm to multivariate
    function optimization. The only requirement for the function is that it be defined
    in terms of the independent variables within the decision space. In contrast to
    gradient-based algorithms, this function does not have to be smooth or differentiable.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use a sufficiently challenging two-dimensional function known as the
    Eggholder function, defined by two independent variables: *x*[1] and *x*[2].'
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (8.2) ![](../images/eq8-2.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll find the minimum value of this function in the decision space defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ ![](../images/pg333.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: As shown earlier in [Figure 8-3](chapter8.xhtml#fig8-3), the Eggholder function
    has a very complex shape with numerous peaks and troughs. Because of this, deterministic
    gradient-based algorithms will have a hard time finding the global minimum. Deterministic
    search attempts will usually get stuck at local optima unless we use a hybrid
    approach that incorporates some random search features. In contrast, given enough
    diversity (population size) and time (number of generations), a genetic algorithm
    can locate the global minimum fairly quickly for this problem.
  prefs: []
  type: TYPE_NORMAL
- en: The Strategy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To implement function optimization in a genetic algorithm, the decision variables
    are treated as individual genes, meaning the two-variable Eggholder function will
    have two genes. This time, however, these genes will be represented as real numbers,
    including fractions, instead of characters (as in [Project 33](chapter8.xhtml#pre-33))
    or binary values (as in [Project 34](chapter8.xhtml#pre-34)).
  prefs: []
  type: TYPE_NORMAL
- en: We also need to address the fact that this is a minimization problem, not a
    maximization problem as in the previous two projects. In those cases, the goal
    was to find a solution with the greatest fitness, whereas now we want to find
    the solution with the smallest fitness. Fortunately, we can easily handle this
    case by multiplying the objective function by –1\. This adjustment allows us to
    continue using the existing code developed for maximization problems. Notably,
    if we were to switch back to a maximization problem, we could use the same code
    without needing to multiply the objective function by –1.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we need a new way to implement mutation for function optimization.
    In previous projects, we introduced mutation by randomly replacing a character
    or a binary value, but that approach does not make sense for a real number. Digits
    in a real number cannot be arbitrarily replaced, as their relative position within
    the number has additional significance. Therefore, for real-valued genes, mutation
    is introduced as a small noise that is randomly added to or subtracted from the
    genes (we still use a probability threshold). The magnitude of the noise is calculated
    as a small fraction of the range for a specific gene (decision variable). By doing
    so, we can properly scale the magnitude of the noise or mutation without having
    to worry about the underlying units used for the corresponding decision variable
    in the function.
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The code for function optimization has the same general structure as Projects
    33 and 34\. It is worth reiterating that for minimization of the objective function,
    we’ll have to multiply it by –1, whereas for maximization no alteration to the
    objective function is needed.
  prefs: []
  type: TYPE_NORMAL
- en: '##### Problem Definition and Global Parameters'
  prefs: []
  type: TYPE_NORMAL
- en: 'This code segment includes the import block, a data class, global parameters,
    and several collections of mutable lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The code segment begins by importing the necessary math functions to calculate
    the function value or fitness. Remember to import only the methods you need, instead
    of importing all of them using an import kotlin.math.* statement. We then declare
    the chromosome to be of type DoubleArray ❶ to deal with real-coded genes.
  prefs: []
  type: TYPE_NORMAL
- en: We also define getFitness as a variable and assign it a reference to the Eggholder
    function ❷. This approach allows us to define other functions later. And to use
    those, we simply need to reassign getFitness to the desired function.
  prefs: []
  type: TYPE_NORMAL
- en: Because the Eggholder function is a function of two independent variables (*x*[1]
    and *x*[2]), we will need two real-coded genes per chromosome ❸.
  prefs: []
  type: TYPE_NORMAL
- en: The next two lines set the bounds for the decision variables and calculate the
    range for each. For real-coded genes, the magnitude of mutation is typically set
    to a small value relative to the range of the decision variables. This approach
    has the benefit of being scale independent.
  prefs: []
  type: TYPE_NORMAL
- en: The remaining part of the code segment is similar to that of previous projects.
    This time, the population is composed of 100 individuals (POP_SIZE), and it will
    evolve for 200 generations (MAX_GEN). The MUTATION_THRESHOLD is now set to 0.5
    ❹, in line with the practice of setting the mutation probability equal to the
    inverse of the number of genes.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we could’ve tried many other combinations of parameter values. The
    values used in this code segment were chosen based on a number of trials to ensure
    that the global minima for the Eggholder function can be found quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing Population and Fitness Evaluation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The general organization of this code snippet is very similar to that of the
    two previous projects, with a few problem-specific adjustments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We generate the chromosome as a DoubleArray with two elements (*x*[0] will be
    gene 1, and *x*[1] will be gene 2) ❶. We then initialize the genes randomly, ensuring
    they stay within their respective bounds (defined by the decision space) ❷. The
    rest of the code segment assigns the solutions to the mutable list population,
    sorts the population in descending order, and prints the best solution from the
    initial population ❸.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, this code doesn’t include a getFitness function; instead,
    we had pointed getFitness to the eggHolder() function, which returns the value
    of the objective function (fitness). For convenience, we’ve broken down the objective
    function given by Equation 8.2 into three parts, which are later combined to calculate
    the fitness value ❹. Notice that we’re multiplying the fitness by –1 before returning
    the value to getFitness. Doing so enables us to use the code developed for maximization
    problems to solve a minimization problem.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll skip reviewing the runGA() function as it is identical to the one used
    for [Project 34](chapter8.xhtml#pre-34). The same goes for the selectElites()
    and tournament() functions. Therefore, we’ll move straight to the crossover()
    and mutation() functions.
  prefs: []
  type: TYPE_NORMAL
- en: Operator Functions for Crossover and Mutation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We’ll now move on to the two key operator functions performing crossover and
    mutation to examine the differences introduced for the real-coded genes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The purpose of the crossover function for real-valued genes remains the same:
    to produce a new chromosome for the child by using genetic materials from the
    parents. Several methods are available for creating the new chromosome or genes.
    In this example, we’re using a random-weighted scheme based on a randomly selected
    value *s* between 0 and 1 ❶. (If we used a fixed weight, s=0.5, that would be
    equivalent to using the arithmetic average of the gene values from two parents
    to create a new gene.)'
  prefs: []
  type: TYPE_NORMAL
- en: We use the weighted average scheme to generate two new genes (x1 and x2) and
    ensure that these values are within the bounds of the decision variables. We then
    compose the new chromosome xNew as a DoubleArray, with two genes as its elements
    ❷.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we call the mutation() function to mutate this newly created chromosome
    in place ❸. Since arrays are passed by reference (memory location), mutations
    can be directly applied to the elements (genes) of the array, and we don’t need
    to return anything to the calling function. Once mutation is applied, a new child
    (Solution) is created and returned using the newly created chromosome and its
    fitness ❹.
  prefs: []
  type: TYPE_NORMAL
- en: The mutation() function, similar to [Project 34](chapter8.xhtml#pre-34), scans
    each gene and mutates it if a random number between 0 and 1 is less than MUTATION_THRESHOLD.
    It randomly picks the sign of the mutation (positive or negative) ❺ and calculates
    the value as the sign times the decision variable’s range times MUTATION_FACTOR
    ❻. It also ensures that the mutated genes are within the bounds of the corresponding
    decision variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we proceed to the main() function, we need to adjust the printSolution()
    function from [Project 34](chapter8.xhtml#pre-34). It now takes a solution with
    a chromosome of type DoubleArray instead of an IntArray. Use the following updated
    function in your code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: You can review this code and compare it with the program output as an exercise,
    since you are familiar with these helper functions.
  prefs: []
  type: TYPE_NORMAL
- en: The main() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The code snippet for the main() function, including the printBestSolution()
    function, is likewise similar to the main() functions in previous projects.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The main() function starts by printing key global parameters. It then calls
    initPopulation() to initialize the population and launches the driver function
    runGA() to carry out function minimization using a genetic algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In the printBestSolution() function, we format and print the two real-valued
    genes on the same line by using a for loop. Finally, we print the negative fitness
    value to get the correct sign for the minimum fitness.
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We’re now ready to run the code and examine the results. If you use the same
    global parameter values that I have used for this project, you are likely to get
    the global optimal solution within five to seven attempts. Let’s look at a sample
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The first section of the results shows the global parameters used for solving
    this problem—population size (100) and number of generations (200). Elitism is
    set to 0.1, or 10 percent. We used a mutation threshold of 0.5 because we have
    two genes, but we could have used a lower threshold if this threshold caused the
    best solutions to oscillate rather than converge. Due to the presence of many
    near-optimal solutions within the decision space of this problem, a higher-than-usual
    mutation threshold may have helped the algorithm to get out of local minima and
    explore other regions.
  prefs: []
  type: TYPE_NORMAL
- en: The initial best fitness value was –809.63, which is not that close to the global
    minimum of –959.64 located after 117 iterations (not shown in the partial output
    above). Once this value was reached, the best solution remained unchanged until
    the program ended after completing the maximum number of iterations.
  prefs: []
  type: TYPE_NORMAL
- en: We can see from the last part of the results that the optimal solution is located
    at *x*[1] = 512.0 and *x*[2] = 404.23\. [Figure 8-9](chapter8.xhtml#fig8-9) shows
    this point as a white half-circle near the top-right corner of the contour plot
    of the Eggholder function.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-9: The contour plot of the Eggholder function'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the global solution is literally on the right-hand boundary of
    the decision space in [Figure 8-10](chapter8.xhtml#fig8-10). The grayscale bar
    indicates that the darker regions are troughs and the lighter regions are peaks.
    Clearly, the fitness values are close to the global minima in many cases (based
    on the darkness of the shade). This is why it is so difficult to find the global
    minima for the Eggholder function.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-10](chapter8.xhtml#fig8-10) shows the convergence pattern for this
    problem. The fitness value improves in a stepwise manner with the number of generations
    (iterations) until it reaches the global minima.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure8-10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-10: The convergence pattern for the Eggholder function using the genetic
    algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll revisit this problem using particle swarm optimization (another NIA) and
    draw the corresponding convergence pattern in the next chapter. You’ll see that
    while both methods are capable of identifying the global optima, particle swarm
    optimization will do that much quicker!
  prefs: []
  type: TYPE_NORMAL
- en: Stopping Condition for Genetic Algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When solving real-world optimization problems, we often lack knowledge of the
    global optimal solution. Consequently, we cannot directly use it as a stopping
    condition. To address this challenge, we can employ several strategies. In this
    section, I’ll discuss commonly used approaches for defining stopping conditions
    in genetic algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: First, the stopping condition can be implemented as the maximum number of generations,
    as we’ve done for all three projects on the genetic algorithm. In general, you
    wouldn’t know how many iterations it might take to solve a previously unsolved
    problem. This will depend on the nature of the problem, the global parameter values,
    and the specific schemes used for various operator functions. You’ll have to gradually
    adjust the number of iterations (along with other parameters) to find a combination
    of values that works for the problem at hand. Interestingly, we can use the genetic
    algorithm to find optimal combinations of global parameters. In the field of deep
    learning, the genetic algorithm has been used to optimize global parameters and
    quickly train neural networks that produce high-quality results.
  prefs: []
  type: TYPE_NORMAL
- en: Second, you could stop the algorithm from iterating if the best solution’s fitness
    does not show noticeable improvements for several generations (for example, very
    little or no improvement over the past 30 or 50 generations). This will require
    additional coding to track improvements dynamically, but this can be a strategy
    to let the algorithm stop automatically, even when the maximum number of iterations
    has not been reached.
  prefs: []
  type: TYPE_NORMAL
- en: Third, for certain types of problems, you may be able to set a target for the
    fitness and have the program terminate once that target is reached (recall that
    we had a text-matching target for the first project). When the target is difficult
    to reach, you could also terminate the program when a predetermined percentage
    of that target is reached (instead of matching the target exactly).
  prefs: []
  type: TYPE_NORMAL
- en: A lot more could be said about genetic algorithms, and researchers are frequently
    developing new adaptive or hybrid strategies and finding new applications. If
    you are interested in the state of the art, I suggest reviewing recent journal
    articles on the application of the genetic algorithm in your field of interest.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Project 35](chapter8.xhtml#pre-35), we revised the code developed for function
    maximization to handle a minimization problem. However, changing the code back
    and forth can easily lead to errors. Therefore, in the next exercise you will
    develop new code to directly handle function minimization problems.  ### Summary'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you explored the fascinating world of nature-inspired algorithms,
    computational methods that mimic natural phenomena to solve complex problems.
    One key feature of these algorithms is that they are stochastic in nature: they
    exploit built-in randomness to tackle problems that are intractable or too complex
    for conventional methods. You learned about the benefits and challenges of using
    nature-inspired algorithms and focused on one of the most popular and powerful
    examples: the genetic algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The genetic algorithm is inspired by the process of natural evolution and uses
    a population of candidate solutions that undergo selection, crossover, and mutation
    to find the best solution for a given problem. You learned several ways to implement
    these operations and adjust the parameters of the algorithm to achieve the best
    performance. You also applied genetic algorithms to three different projects in
    order to:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a target string from a random population of characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maximize the value of items in a knapsack with a limited capacity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Find the global optimum solution for a real-valued and highly complex multivariate
    objective function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, you completed a set of exercises that cover additional techniques
    for the crossover operation and dedicated methods for solving minimization problems
    directly. By the end of this chapter, you gained a solid understanding of the
    theory and practice of genetic algorithms, and how they can be used to solve various
    types of optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Brownlee, Jason. *Clever Algorithms: Nature-Inspired Programming Recipes*.
    Electronic version, June 16, 2012\. *[https://github.com/clever-algorithms/CleverAlgorithms](https://github.com/clever-algorithms/CleverAlgorithms)*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Buontempo, Frances. *Genetic Algorithms and Machine Learning for Programmers*.
    Raleigh, NC: The Pragmatic Bookshelf, 2019.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Gen, Mitsuo, and Runwei Cheng. *Genetic Algorithms and Engineering Optimization*.
    New York: John Wiley & Sons, 2000.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Goldberg, David. *Genetic Algorithms in Search, Optimization and Machine Learning*.
    Reading, MA: Addison-Wesley Professional, 1989.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Haupt, Randy L., and Sue Ellen Haupt. *Practical Genetic Algorithms*. 2nd ed.
    Hoboken, NJ: John Wiley & Sons, 2004.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Yang, Xin-She. *Nature-Inspired Optimization Algorithms*. 2nd ed. London: Academic
    Press, 2021.'
  prefs: []
  type: TYPE_NORMAL
