<html><head></head><body>
<div id="sbo-rt-content"><h2 class="h2"><span epub:type="pagebreak" id="page_1"/><strong>PREFACE</strong></h2>
<div class="image1"><img alt="Image" height="189" src="../images/common.jpg" width="189"/></div>
<p class="noindentsa">Many books teach you how to do artificial intelligence (AI). Similarly, many popular books tell you about AI. However, what seems to be missing is a book that teaches you how AI works at a conceptual level. AI isn’t magic; you can understand what it’s doing without burying yourself in complex mathematics.</p>
<p class="indent">This book fills that void with a math-free explanation of how AI works. While some books are down in the weeds and others offer a bird’s-eye view, this book is at treetop level. It aims to provide you with enough detail to understand the approach without getting bogged down in nitty-gritty mathematics. If that piques your interest, I invite you to read on.</p>
<p class="indent">You’ll run across places where **** appears throughout the book. These markers highlight a shift in the topic or a transition point. In a textbook, **** would indicate a new section, but this isn’t a textbook, nor do I want it to feel like one; so, instead of sections and subsections, I’ll use asterisks to warn you that a change is coming. Like this . . .</p>
<p class="center">****</p>
<p class="indent">I first learned about artificial intelligence in 1987, in an undergraduate course of the same name. What people typically mean by <em>AI</em> has changed <span epub:type="pagebreak" id="page_2"/>somewhat over the intervening decades. Still, the goal remains the same: to mimic intelligent behavior in a machine.</p>
<p class="indent">Few people in the 1980s had any reason to learn about AI, if they were even aware of it. AI had minimal impact on their daily lives, beyond the occasional renegade computer in science fiction TV shows and movies like <em>Star Trek</em> or <em>WarGames</em>, to say nothing of the relentless and terrifying <em>Terminator</em>.</p>
<p class="indent">However, the 1980s are long gone, current retro fashion trends notwithstanding, and AI is everywhere. It affects our lives in numerous ways every day, from phones telling us to drive here and not there, to labeling friends and family in pictures, to the articles and ads fed to us continuously online, like it or not. And this is to say nothing of the recent AI explosion involving large language models, which many interpret as “true AI” at last.</p>
<p class="indent">AI is also there behind the scenes in ways we seldom realize: airline flight planning, shipping and logistics, factory automation, satellite imaging of the earth, and helping your doctor decide if that lump is cancer, to name a few.</p>
<p class="indent">Why learn about AI now?</p>
<p class="indent">This book answers that question by explaining what happened, when it happened, why it happened, and, most importantly, how it happened—all without hype or a single mathematical equation. Frankly, the reality behind the AI revolution is impressive enough; the hype is unnecessary.</p>
<p class="indent">At this point, I feel some words about me are in order. After all, I’m asking you to join me on a journey through the world of AI, so it’s reasonable to wonder about your guide. I certainly would.</p>
<p class="indent">As mentioned earlier, I was introduced to AI in the late 1980s. I began working in AI, in the subfield known as <a href="glossary.xhtml#glo64"><em>machine learning</em></a>, in 2003, applying machine learning models to intravascular ultrasound images.</p>
<p class="indent">I first heard of deep learning in 2010. <a href="glossary.xhtml#glo29"><em>Deep learning</em></a> is a subfield of machine learning. I’ll clarify the difference between deep learning, machine learning, and artificial intelligence in <a href="ch01.xhtml">Chapter 1</a>, but for now you can think of them as the same thing.</p>
<p class="indent">In 2012, AI burst onto the scene—or at least into the news—with the advent of what came to be called AlexNet and a curious experiment at Google involving computers that learned to identify cats in YouTube videos. I was in the room at the 2012 International Conference on Machine Learning in Edinburgh, Scotland, when Google presented its paper. It was standing room only for the conference’s 800 or so attendees.</p>
<p class="indent">In 2016, I completed a PhD in computer science specializing in AI at the University of Colorado, Boulder, under the direction of Michael Mozer. I’ve worked in AI daily since then, primarily in the defense industry, with a short break in 2016 to help co-found a medical AI startup.</p>
<p class="indent">After AlexNet, things changed quickly, as seemingly monthly some new AI-related “miracle” appeared in the academic literature, if not on the evening news. The only way to keep up was to attend conferences multiple times per year; waiting for results to appear in an academic journal was pointless, as the field was progressing too rapidly for the typically slow pace of academic publishing.</p>
<p class="indent"><span epub:type="pagebreak" id="page_3"/>I’m writing this preface in November 2022 at the NeurIPS conference. NeurIPS is arguably the premier AI conference (no hate emails, please!), and this is the first time it’s been held in person since the COVID-19 pandemic. Attendance is high, though perhaps not as high as at the 2019 conference, for which a lottery was held to determine which 13,500 people could attend. The fact that conference attendance has blossomed from a few hundred to over 10,000 in a decade tells us how important AI research has become.</p>
<p class="indent">The names of the tech industry leaders who support these conferences, which are prime hunting grounds for graduate students, also reveal the significance of AI. You’ll find expo booths for Google, DeepMind (also Google), Meta (read: Facebook), Amazon, Apple, and others. AI drives much of what these companies do. AI is big bucks. AI runs on data, and these companies gobble up all the data we freely give them in exchange for their services.</p>
<p class="indent">By the end of the book, you’ll understand what AI is doing under the hood (or bonnet, if you prefer). Ultimately, it isn’t all that difficult to comprehend, though the devil is definitely in the details.</p>
<p class="indent">The book proceeds as follows:</p>
<div class="bqz">
<p class="noindent2a"><strong><a href="ch01.xhtml">Chapter 1, And Away We Go: An AI Overview</a></strong> We dive in with a quick overview of AI essentials and a basic example.</p>
<p class="noindent2a"><strong><a href="ch02.xhtml">Chapter 2, Why Now? A History of AI</a></strong> AI didn’t just fall from the sky. This chapter gives you AI’s backstory and clarifies why the revolution is happening now.</p>
<p class="noindent2a"><strong><a href="ch03.xhtml">Chapter 3, Classical Models: Old-School Machine Learning</a></strong> Modern AI is all neural networks, but to understand what neural networks are doing, it helps to understand the models that came before.</p>
<p class="noindent2a"><strong><a href="ch04.xhtml">Chapter 4, Neural Networks: Brain-Like AI</a></strong> If you want to know what a neural network is, how it’s trained, and how it’s used, then this chapter is for you.</p>
<p class="noindent2a"><strong><a href="ch05.xhtml">Chapter 5, Convolutional Neural Networks: AI Learns to See</a></strong> Much of the power of modern AI comes from learning new ways to represent data. If that sentence has no meaning for you, this chapter will help.</p>
<p class="noindent2a"><strong><a href="ch06.xhtml">Chapter 6, Generative AI: AI Gets Creative</a></strong> Traditional supervised machine learning models attach labels to inputs. Generative AI produces novel output, including text, images, and even video. This chapter explores two popular approaches: generative adversarial networks (GANs) and diffusion models. GANs provide the intuition we need to explore diffusion models and, in <a href="ch07.xhtml">Chapter 7</a>, large language models (LLMs). Diffusion models are adept at producing detailed, photorealistic images and videos from text prompts.</p>
<p class="noindent2a"><strong><a href="ch07.xhtml">Chapter 7, Large Language Models: True AI at Last?</a></strong> OpenAI’s fall 2022 release of its large language model, ChatGPT, might very well have ushered in the era of true AI. This chapter explores LLMs: what they are, how they work, and the claim that they are something new and disruptive.</p>
<p class="noindent2a"><span epub:type="pagebreak" id="page_4"/><strong><a href="ch08.xhtml">Chapter 8, Musings: The Implications of AI</a></strong> The advent of large language models has altered the AI landscape. This chapter muses on the implications.</p>
</div>
<p class="indent">At the end of the book, you’ll find a collection of additional resources to explore, should the AI bug bite and you want to learn more. Personally, and admittedly with bias, I recommend my books <em>Practical Deep Learning: A Python-Based Introduction</em> (2021) and <em>Math for Deep Learning: What You Need to Know to Understand Neural Networks</em> (2021), both available from No Starch Press. They will give you what you need to go from reading about how AI works conceptually to “doing” AI.</p>
<p class="indent">Finally, as you read, you’ll notice that specific phrases in the text are <em>emphasized</em>. Definitions for many of these emphasized words and phrases are found in the glossary at the end of the book. Like every field, AI has its jargon. Keeping all the terms in your head is burdensome, hence the glossary to help you remember them.</p>
<p class="indent">I’m a real person. I know because I can successfully identify and click images of trains and traffic lights. If you have comments or questions about the material in this book, I want to hear from you. Please email me at <a href="mailto:rkneuselbooks@gmail.com"><em>rkneuselbooks@gmail.com</em></a>.</p>
<p class="indent">Now, if you’re ready, away we go.</p>
</div></body></html>