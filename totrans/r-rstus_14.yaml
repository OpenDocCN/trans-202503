- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: 11 AUTOMATICALLY ACCESSING ONLINE DATA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/chapter.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So far, you’ve imported data into your projects from CSV files. Many online
    datasets allow you to export CSVs, but before you do so, you should look for packages
    to automate your data access. If you can eliminate the manual steps involved in
    fetching data, your analysis and reporting will be more accurate. You’ll also
    be able to efficiently update your report when the data changes.
  prefs: []
  type: TYPE_NORMAL
- en: R offers many ways to automate the process of accessing online data. In this
    chapter, I’ll discuss two such approaches. First, you will use the googlesheets4
    package to fetch data directly from Google Sheets. You’ll learn how to connect
    your R Markdown project to Google so you can automatically download data when
    a Google Sheet updates. Then, you’ll use the tidycensus package to access data
    from the US Census Bureau. You’ll work with two large census datasets, the Decennial
    Census and the American Community Survey, and practice visualizing them.
  prefs: []
  type: TYPE_NORMAL
- en: Importing Data from Google Sheets with googlesheets4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By using the googlesheets4 package to access data directly from Google Sheets,
    you avoid having to manually download data, copy it into your project, and adjust
    your code so it imports that new data every time you want to update a report.
    This package lets you write code that automatically fetches new data directly
    from Google Sheets. Whenever you need to update your report, you can simply run
    your code to refresh the data. In addition, if you work with Google Forms, you
    can pipe your data into Google Sheets, completely automating the workflow from
    data collection to data import.
  prefs: []
  type: TYPE_NORMAL
- en: Using the googlesheets4 package can help you manage complex datasets that update
    frequently. For example, in her role at the Primary Care Research Institute at
    the University of Buffalo, Meghan Harris used it for a research project about
    people affected by opioid use disorder. The data came from a variety of surveys,
    all of which fed into a jumble of Google Sheets. Using googlesheets4, Harris was
    able to collect all of her data in one place and use R to put it to use. Data
    that had once been largely unused because accessing it was so complicated could
    now inform research on opioid use disorder.
  prefs: []
  type: TYPE_NORMAL
- en: This section demonstrates how the googlesheets4 package works using a fake dataset
    about video game preferences that Harris created to replace her opioid survey
    data (which, for obvious reasons, is confidential).
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to Google
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To begin, install the googlesheets4 package by running install.packages("googlesheets4").
    Next, connect to your Google account by running the gs4_auth() function in the
    console. If you have more than one Google account, select the account that has
    access to the Google Sheet you want to work with.
  prefs: []
  type: TYPE_NORMAL
- en: Once you do so, a screen should appear. Check the box next to **See, Edit, Create,
    and Delete All Your Google Sheets Spreadsheets**. This will ensure that R can
    access data from your Google Sheets account. Click **Continue**, and you should
    see the message “Authentication complete. Please close this page and return to
    R.” The googlesheets4 package will now save your credentials so that you can use
    them in the future without having to reauthenticate.
  prefs: []
  type: TYPE_NORMAL
- en: Reading Data from a Sheet
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now that you’ve connected R to your Google account, you can import the fake
    data that Harris created about video game preferences (access it at *[https://data.rfortherestofus.com/google-sheet](https://data.rfortherestofus.com/google-sheet)*).
    [Figure 11-1](chapter11.xhtml#fig11-1) shows what it looks like in Google Sheets.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig11-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-1: The video game data in Google Sheets'
  prefs: []
  type: TYPE_NORMAL
- en: 'The googlesheets4 package has a function called read_sheet() that allows you
    to pull in data directly from a Google Sheet. Import the data by passing the spreadsheet’s
    URL to the function like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the survey_data_raw object to confirm that the data was imported.
    Using the glimpse() function from the dplyr package makes it easier to read:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The glimpse() function, which creates one output row per variable, shows that
    you’ve successfully imported the data directly from Google Sheets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Once you have the data in R, you can use the same workflow you’ve been using
    to create reports with R Markdown.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Data in R Markdown
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following code is taken from an R Markdown report that Harris made to summarize
    the video games data. You can see the YAML, the setup code chunk, a code chunk
    that loads packages, and the code to import data from Google Sheets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]{r setup, include=FALSE}'
  prefs: []
  type: TYPE_NORMAL
- en: knitr::opts_chunk$set(echo = FALSE,
  prefs: []
  type: TYPE_NORMAL
- en: warning = FALSE,
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: message = FALSE)
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]{r}'
  prefs: []
  type: TYPE_NORMAL
- en: library(tidyverse)
  prefs: []
  type: TYPE_NORMAL
- en: library(janitor)
  prefs: []
  type: TYPE_NORMAL
- en: library(googlesheets4)
  prefs: []
  type: TYPE_NORMAL
- en: library(gt)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]{r}'
  prefs: []
  type: TYPE_NORMAL
- en: Import data from Google Sheets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ❶ survey_data_raw <- read_sheet("https://docs.google.com/spreadsheets/d/
  prefs: []
  type: TYPE_NORMAL
- en: 1AR0_RcFBg8wdiY4Cj-k8vRypp_txh27MyZuiRdqScog/edit?usp=sharing")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This R Markdown document resembles those discussed in previous chapters, except
    for the way you import the data ❶. Because you’re bringing it in directly from
    Google Sheets, there’s no risk of, say, accidentally reading in the wrong CSV.
    Automating this step reduces the risk of error.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next code chunk cleans the survey_data_raw object, saving the result as
    survey_data_clean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]{r}'
  prefs: []
  type: TYPE_NORMAL
- en: Clean data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: survey_data_clean <- survey_data_raw %>%
  prefs: []
  type: TYPE_NORMAL
- en: clean_names() %>%
  prefs: []
  type: TYPE_NORMAL
- en: mutate(participant_id = as.character(row_number())) %>%
  prefs: []
  type: TYPE_NORMAL
- en: rename(
  prefs: []
  type: TYPE_NORMAL
- en: age = how_old_are_you,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: like_games = do_you_like_to_play_video_games,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: game_types = what_kind_of_games_do_you_like,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: favorite_game = whats_your_favorite_game
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ) %>%
  prefs: []
  type: TYPE_NORMAL
- en: relocate(participant_id, .before = age) %>%
  prefs: []
  type: TYPE_NORMAL
- en: mutate(age = factor(age, levels = c("Under 18", "18-24", "25-34",
  prefs: []
  type: TYPE_NORMAL
- en: '"35-44", "45-54", "55-64", "Over 65")))'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Here, the clean_names() function from the janitor package makes the variable
    names easier to work with. Defining a participant_id variable using the row_number()
    function then adds a consecutively increasing number to each row, and the as.character()
    function makes the number a character. Next, the code changes several variable
    names with the rename() function. The mutate() function then transforms the age
    variable into a data structure known as a *factor*, which ensures that age will
    show up in the right order in your chart. Finally, the relocate() function positions
    participant_id before the age variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can use the glimpse() function again to view your updated survey_data_clean
    data frame, which looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The rest of the report uses this data to highlight various statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]{r}'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate number of respondents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: number_of_respondents <- nrow(survey_data_clean) ❶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]{r}'
  prefs: []
  type: TYPE_NORMAL
- en: survey_data_clean %>%
  prefs: []
  type: TYPE_NORMAL
- en: select(participant_id, age) %>%
  prefs: []
  type: TYPE_NORMAL
- en: gt() %>% ❷
  prefs: []
  type: TYPE_NORMAL
- en: cols_label(
  prefs: []
  type: TYPE_NORMAL
- en: participant_id = "Participant ID",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: age = "Age"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ) %>%
  prefs: []
  type: TYPE_NORMAL
- en: tab_style(
  prefs: []
  type: TYPE_NORMAL
- en: style = cell_text(weight = "bold"),
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: locations = cells_column_labels()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ) %>%
  prefs: []
  type: TYPE_NORMAL
- en: cols_align(
  prefs: []
  type: TYPE_NORMAL
- en: align = "left",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: columns = everything()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ) %>%
  prefs: []
  type: TYPE_NORMAL
- en: cols_width(
  prefs: []
  type: TYPE_NORMAL
- en: participant_id ~ px(200),
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: age ~ px(700)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]{r}'
  prefs: []
  type: TYPE_NORMAL
- en: survey_data_clean %>%
  prefs: []
  type: TYPE_NORMAL
- en: count(like_games) %>%
  prefs: []
  type: TYPE_NORMAL
- en: ggplot(aes(
  prefs: []
  type: TYPE_NORMAL
- en: x = like_games, ❸
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: y = n,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: fill = like_games
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )) +
  prefs: []
  type: TYPE_NORMAL
- en: geom_col() +
  prefs: []
  type: TYPE_NORMAL
- en: scale_fill_manual(values = c(
  prefs: []
  type: TYPE_NORMAL
- en: '"No" = "#6cabdd",'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '"Yes" = "#ff7400"'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )) +
  prefs: []
  type: TYPE_NORMAL
- en: labs(
  prefs: []
  type: TYPE_NORMAL
- en: title = "How Many People Like Video Games?",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: x = NULL,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: y = "Number of Participants"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ) +
  prefs: []
  type: TYPE_NORMAL
- en: theme_minimal(base_size = 16) +
  prefs: []
  type: TYPE_NORMAL
- en: theme(
  prefs: []
  type: TYPE_NORMAL
- en: legend.position = "none",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: panel.grid.minor = element_blank(),
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: panel.grid.major.x = element_blank(),
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: axis.title.y = element_blank(),
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: plot.title = element_text(
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: face = "bold",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: hjust = 0.5
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: These sections calculate the number of survey respondents ❶, then put this value
    in the text using inline R code; create a table that breaks down the respondents
    by age group ❷; and generate a graph displaying how many respondents like video
    games ❸. [Figure 11-2](chapter11.xhtml#fig11-2) shows the resulting report.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig11-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-2: The rendered video game report'
  prefs: []
  type: TYPE_NORMAL
- en: You can rerun the code at any point to fetch updated data. The survey had five
    responses today, but if you run it again tomorrow and it has additional responses,
    they will be included in the import. If you used Google Forms to run your survey
    and saved the results to a Google Sheet, you could produce this up-to-date report
    simply by clicking the Knit button in RStudio.
  prefs: []
  type: TYPE_NORMAL
- en: Importing Only Certain Columns
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the previous sections, you read the data of the entire Google Sheet, but
    you also have the option to import only a section of a sheet. For example, the
    survey data includes a timestamp column. This variable is added automatically
    whenever someone submits a Google Form that pipes data into a Google Sheet, but
    you don’t use it in your analysis, so you could get rid of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, use the range argument in the read_sheet() function when importing
    the data like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This argument lets you specify a range of data to import. It uses the same
    syntax you may have used to select columns in Google Sheets. In this example,
    range = "Sheet1!B:E" imports columns B through E (but not A, which contains the
    timestamp). Adding glimpse() and then running this code produces output without
    the timestamp variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: There are a number of other useful functions in the googlesheets4 package. For
    example, if you ever need to write your output back to a Google Sheet, the write_sheet()
    function is there to help. To explore other functions in the package, check out
    its documentation website at *[https://googlesheets4.tidyverse.org/index.xhtml](https://googlesheets4.tidyverse.org/index.xhtml)*.
  prefs: []
  type: TYPE_NORMAL
- en: Now we’ll turn our attention to another R package that allows you to automatically
    fetch data, this time from the US Census Bureau.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing Census Data with tidycensus
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you’ve ever worked with data from the US Census Bureau, you know what a hassle
    it can be. Usually, the process involves visiting the Census Bureau website, searching
    for the data you need, downloading it, and then analyzing it in your tool of choice.
    This pointing and clicking gets very tedious after a while.
  prefs: []
  type: TYPE_NORMAL
- en: Kyle Walker, a geographer at Texas Christian University, and Matt Herman (creator
    of the Westchester COVID-19 website discussed in [Chapter 9](chapter9.xhtml))
    developed the tidycensus package to automate the process of importing Census Bureau
    data into R. With tidycensus, you can write just a few lines of code to get data
    about, say, the median income in all counties in the United States.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, I’ll show you how the tidycensus package works using examples
    from two datasets to which it provides access: the Decennial Census, administered
    every 10 years, and the annual American Community Survey. I’ll also show you how
    to use the data from these two sources to perform additional analysis and make
    maps by accessing geospatial and demographic data simultaneously.'
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to the Census Bureau with an API Key
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Begin by installing tidycensus using install.packages("tidycensus"). To use
    tidycensus, you must get an application programming interface (API) key from the
    Census Bureau. *API keys* are like passwords that online services use to determine
    whether you’re authorized to access data.
  prefs: []
  type: TYPE_NORMAL
- en: 'To obtain this key, which is free, go to *[https://api.census.gov/data/key_signup.xhtml](https://api.census.gov/data/key_signup.xhtml)*
    and enter your details. Once you receive the key by email, you need to put it
    in a place where tidycensus can find it. The census_api_key() function does this
    for you, so after loading the tidycensus package, run the function as follows,
    replacing 123456789 with your actual API key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The install = TRUE argument saves your API key in your *.Renviron* file, which
    is designed for storing confidential information. The package will look for your
    API key there in the future so that you don’t have to reenter it every time you
    use the package.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can use tidycensus to access Census Bureau datasets. While the Decennial
    Census and the American Community Survey are the most common, [Chapter 2](chapter2.xhtml)
    of Kyle Walker’s book *Analyzing US Census Data: Methods, Maps, and Models in
    R* discusses others you can access.'
  prefs: []
  type: TYPE_NORMAL
- en: Working with Decennial Census Data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The tidycensus packages includes several functions dedicated to specific Census
    Bureau datasets, such as get_decennial() for Decennial Census data. To access
    data from the 2020 Decennial Census about the Asian population in each state,
    use the get_decennial() function with three arguments as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Setting the geography argument to "state" tells get_decennial() to access data
    at the state level. In addition to the 50 states, it will return data for the
    District of Columbia and Puerto Rico. The variables argument specifies the variable
    or variables you want to access. Here, P1_006N is the variable name for the total
    Asian population. I’ll discuss how to identify other variables you may want to
    use in the next section. Finally, year specifies the year for which you want to
    access data—in this case, 2020.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running this code returns the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The resulting data frame has four variables. GEOID is the geographic identifier
    assigned to the state by the Census Bureau. Each state has a geographic identifier,
    as do all counties, census tracts, and other geographies. NAME is the name of
    each state, and variable is the name of the variable you passed to the get_decennial()
    function. Finally, value is the numeric value for the state and variable in each
    row. In this case, it represents the total Asian population in each state.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying Census Variable Values
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You’ve just seen how to retrieve the total number of Asian residents of each
    state, but say you want to calculate that number instead as a percentage of all
    the state’s residents. To do that, first you need to retrieve the variable for
    the state’s total population.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tidycensus package has a function called load_variables() that shows all
    of the variables from a Decennial Census. Run it with the year argument set to
    2020 and dataset set to pl as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this code pulls data from so-called redistricting summary data files
    (which Public Law 94-171 requires the Census Bureau to produce every 10 years)
    and returns the name, label (description), and concept (category) of all available
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: By looking at this list, you can see that the variable P1_001N returns the total
    population.
  prefs: []
  type: TYPE_NORMAL
- en: Using Multiple Census Variables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now that you know which variables you need, you can use the get_decennial()
    function again with two variables at once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding arrange(NAME) after get_decennial() sorts the results by state name,
    allowing you to easily see that the output includes both variables for each state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'When you’re working with multiple census variables like this, you might have
    trouble remembering what names like P1_001N and P1_006N mean. Fortunately, you
    can adjust the code in the call to get_decennial() to give these variables more
    meaningful names using the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Within the variables argument, this code specifies the new names for the variables,
    followed by the equal sign and the original variable names. The c() function allows
    you to rename multiple variables at one time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it’s much easier to see which variables you’re working with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Instead of P1_001N and P1_006N, the variables appear as total_population and
    asian_population. Much better!
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing Census Data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now you have the data you need to calculate the Asian population in each state
    as a percentage of the total. There are just a few functions to add to the code
    from the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The group_by(NAME) function creates one group for each state because you want
    to calculate the Asian population percentage in each state (not for the entire
    United States). Then mutate() calculates each percentage, taking the value in
    each row and dividing it by the total_population and asian_population rows for
    each state. The ungroup() function removes the state-level grouping, and filter()
    shows only the Asian population percentage.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you run this code, you should see both the total Asian population and
    the Asian population as a percentage of the total population in each state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This is a reasonable way to calculate the Asian population as a percentage of
    the total population in each state—but it’s not the only way.
  prefs: []
  type: TYPE_NORMAL
- en: Using a Summary Variable
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Kyle Walker knew that calculating summaries like you’ve just done would be
    a common use case for tidycensus. To calculate, say, the Asian population as a
    percentage of the whole, you need to have a numerator (the Asian population) and
    denominator (the total population). So, to simplify things, Walker included the
    summary_var argument, which can be used within get_decennial() to import the total
    population as a separate variable. Instead of putting P1_001N (total population)
    in the variables argument and renaming it, you can assign it to the summary_var
    argument as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns a nearly identical data frame to what you just got, except that
    the total population is now a separate variable, rather than additional rows for
    each state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'With the data in this new format, now you can calculate the Asian population
    as a percentage of the whole by dividing the value variable by the summary_value
    variable. Then you drop the summary_value variable because you no longer need
    it after doing this calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting output is identical to the output of the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: How you choose to calculate summary statistics is up to you; tidycensus makes
    it easy to do either way.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing American Community Survey Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once you’ve accessed data using the tidycensus package, you can do whatever
    you want with it. In this section, you’ll practice analyzing and visualizing survey
    data using the American Community Survey. This survey, which is conducted every
    year, differs from the Decennial Census in two major ways: it is given to a sample
    of people rather than the entire population, and it includes a wider range of
    questions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite these differences, you can access data from the American Community
    Survey nearly identically to how you access Decennial Census data. Instead of
    get_decennial(), you use the get_acs() function, but the arguments you pass to
    it are the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This code uses the B01002_001 variable to get median age data from 2020 for
    each state. Here’s what the output looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: You should notice two differences in the output from get_acs() compared to that
    from get_decennial(). First, instead of the value column, get_acs() produces a
    column called estimate. Second, it adds a column called moe, for the margin of
    error. These changes are the result of American Community Survey being given only
    to a sample of the population, since extrapolating values from that sample to
    produce an estimate for the population as a whole introduces a margin of error.
  prefs: []
  type: TYPE_NORMAL
- en: In the state-level data, the margins of error are relatively low, but in smaller
    geographies, they tend to be higher. Cases in which your margins of error are
    high relative to your estimates indicate a greater level of uncertainty about
    how well the data represents the population as a whole, so you should interpret
    such results with caution.
  prefs: []
  type: TYPE_NORMAL
- en: Making Charts
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To pipe your data on median age into ggplot to create a bar chart, add the
    following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: After importing the data with the get_acs() function, the ggplot() function
    pipes it directly into ggplot. States (which use the variable NAME) will go on
    the y-axis, and median age (estimate) will go on the x-axis. A simple geom_col()
    creates the bar chart shown in [Figure 11-3](chapter11.xhtml#fig11-3).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig11-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-3: A bar chart generated using data acquired with the get_asc() function'
  prefs: []
  type: TYPE_NORMAL
- en: This chart is nothing special, but the fact that it takes just six lines of
    code to create most definitely is!
  prefs: []
  type: TYPE_NORMAL
- en: Making Population Maps with the geometry Argument
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In addition to co-creating tidycensus, Kyle Walker created the tigris package
    for working with geospatial data. As a result, these packages are tightly integrated.
    Within the get_acs() function, you can set the geometry argument to TRUE to receive
    both demographic data from the Census Bureau and geospatial data from tigris:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'In the resulting data, you can see that it has the metadata and geometry column
    of the simple features objects that you saw in [Chapter 4](chapter4.xhtml):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The geometry type is MULTIPOLYGON, which you learned about in [Chapter 4](chapter4.xhtml).
    To pipe this data into ggplot to make a map, add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: After importing the data with get_acs() and piping it into the ggplot() function,
    this code sets the estimate variable to use for the fill aesthetic property; that
    is, the fill color of each state will vary depending on the median age of its
    residents. Then geom_sf() draws the map, and the scale_fill_viridis_c() function
    gives it a colorblind-friendly palette.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting map, shown in [Figure 11-4](chapter11.xhtml#fig11-4), is less
    than ideal because the Aleutian Islands in Alaska cross the 180-degree line of
    longitude, or the International Date Line. As a result, most of Alaska appears
    on one side of the map and a small part appears on the other side. What’s more,
    both Hawaii and Puerto Rico are hard to see.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig11-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-4: A hard-to-read map showing median age by state'
  prefs: []
  type: TYPE_NORMAL
- en: 'To fix these problems, load the tigris package, then use the shift_geometry()
    function to move Alaska, Hawaii, and Puerto Rico into places where they’ll be
    more easily visible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Setting the preserve_area argument to FALSE shrinks the giant state of Alaska
    and makes Hawaii and Puerto Rico larger. Although the state sizes in the map won’t
    be precise, the map will be easier to read, as you can see in [Figure 11-5](chapter11.xhtml#fig11-5).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/fig11-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-5: An easier-to-read map tweaked using tigris functions'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now try making the same map for all 3,000 counties by changing the geography
    argument to "county". Other geographies include region, tract (for census tracts),
    place (for census-designated places, more commonly known as towns and cities),
    and congressional district. There are also many more arguments in both the get_decennial()
    and get_acs() functions; I’ve shown you only a few of the most common. If you
    want to learn more, Walker’s book *Analyzing US Census Data: Methods, Maps, and
    Models in R* is a great resource.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter explored two packages that use APIs to access data directly from
    its source. The googlesheets4 package lets you import data from a Google Sheet.
    It’s particularly useful when you’re working with survey data, as it makes it
    easy to update your reports when new results come in. If you don’t work with Google
    Sheets, you could use similar packages to fetch data from Excel365 (Microsoft365R),
    Qualtrics (qualtRics), Survey Monkey (svmkrR), and other sources.
  prefs: []
  type: TYPE_NORMAL
- en: If you work with US Census Bureau data, the tidycensus package is a huge time-saver.
    Rather than having to manually download data from the Census Bureau website, you
    can use tidycensus to write R code that accesses the data automatically, making
    it ready for analysis and reporting. Because of the package’s integration with
    tigris, you can also easily map this demographic data.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re looking for census data from other countries, there are also R packages
    to bring data from Canada (cancensus), Kenya (rKenyaCensus), Mexico (mxmaps and
    inegiR), Europe (eurostat), and other regions. Before hitting that download button
    in your data collection tool to get a CSV file, it’s worth looking for a package
    that can import that data directly into R.
  prefs: []
  type: TYPE_NORMAL
- en: Additional Resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Isabella Velásquez and Curtis Kephart, “Automated Survey Reporting with googlesheets4,
    pins, and R Markdown,” Posit, June 15, 2022, *[https://posit.co/blog/automated-survey-reporting/](https://posit.co/blog/automated-survey-reporting/)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kyle Walker, *Analyzing US Census Data: Methods, Maps, and Models in R* (Boca
    Raton, FL: CRC Press, 2023), *[https://walker-data.com/census-r/](https://walker-data.com/census-r/)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
