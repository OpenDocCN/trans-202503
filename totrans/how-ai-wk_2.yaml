- en: '**2'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2'
- en: WHY NOW? A HISTORY OF AI**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么是现在？人工智能的历史**'
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: Rowan Atkinson’s comic masterpiece *Mr. Bean* opens in the dead of night on
    a deserted London street. A spotlight appears, the title character falls from
    the sky, and a choir sings in Latin, “ecce homo qui est faba”—behold the man who
    is a bean. Mr. Bean picks himself up, brushes off his suit, and runs awkwardly
    into the darkness. He is something otherworldly, a thing that literally fell from
    the sky, defying comprehension.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 罗温·艾金森的喜剧杰作*《憨豆先生》*开场时是在一个空无一人的伦敦街头的深夜。聚光灯打在一个人身上，主角从天而降，拉丁语合唱团唱道：“ecce homo
    qui est faba”——看啊，这就是一个豆子人。憨豆先生爬起来，拍掉身上的灰尘，笨拙地跑进黑暗中。他是一个异世界的存在，一个字面上从天而降、难以理解的存在。
- en: Given the parade of AI wonder after wonder in recent years, we might be excused
    for thinking that AI, like Mr. Bean, fell from the sky, fully formed and beyond
    our comprehension. However, none of this is true; indeed, I’d argue that AI is
    still in its infancy.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于近年来人工智能不断涌现的奇迹，我们或许会误以为人工智能就像《憨豆先生》一样，从天而降，已经完全形成且超出了我们的理解。然而，这一切都不是真的；事实上，我认为人工智能仍处于初期阶段。
- en: So why are we hearing about AI now? I’ll answer that question with a brief (and
    biased) history of AI, followed by a discussion of the advances in computing that
    acted as the catalyst for the AI revolution. This chapter provides context for
    the models we’ll explore throughout the remainder of the book.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么现在我们会听到关于人工智能的讨论呢？我将通过一段简短（且带有偏见）的人工智能历史来回答这个问题，并讨论推动人工智能革命的计算技术进展。本章为我们接下来将在全书中探讨的模型提供了背景。
- en: '****'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: 'Since its inception, AI has been divided into two main camps: symbolic AI and
    connectionism. *Symbolic* AI attempts to model intelligence by manipulating symbols
    and logical statements or associations. *Connectionism*, however, attempts to
    model intelligence by building networks of simpler components. The human mind
    embodies both approaches. We use symbols as elements of thought and language,
    and our minds are constructed from unbelievably complex networks of neurons, each
    neuron a simple processor. In computer programming terms, the symbolic approach
    to AI is top-down, while connectionism is bottom-up. Top-down design starts with
    high-level tasks, then breaks those tasks into smaller and smaller pieces. A bottom-up
    design begins with smaller pieces and combines them together.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 自人工智能诞生以来，它一直分为两大阵营：符号主义人工智能和联结主义。*符号主义*人工智能试图通过操作符号、逻辑陈述或关联来模拟智能。而*联结主义*则通过构建简单组件的网络来模拟智能。人类大脑体现了这两种方法。我们使用符号作为思维和语言的元素，我们的大脑由极其复杂的神经元网络构成，每个神经元都是一个简单的处理器。在计算机编程术语中，符号主义人工智能的方法是自上而下的，而联结主义则是自下而上的。自上而下的设计从高级任务开始，然后将任务拆解成越来越小的部分。自下而上的设计从较小的部分开始，并将它们组合在一起。
- en: Proponents of symbolic AI believe that intelligence can be achieved in the abstract,
    without a substrate resembling a brain. Connectionists follow the evolutionary
    development of brains and argue that there needs to be some foundation, like a
    massive collection of highly interconnected neurons, from which intelligence (however
    defined) can emerge.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 符号主义人工智能的支持者认为，智能可以在抽象层面上实现，而不需要类似大脑的基质。联结主义者则遵循大脑的进化发展，认为必须有某种基础，比如一个庞大且高度互联的神经元网络，从中可以产生智能（无论如何定义）。
- en: While the debate between symbolic AI and connectionism was long-lived, with
    the advent of deep learning it’s safe to say that the connectionists have won
    the day—though perhaps not the war. Recent years have seen a smattering of papers
    blending the two approaches. I suspect symbolic AI has a cameo or two left in
    it, if not ultimately starring in a supporting role.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然符号主义人工智能与联结主义的辩论持续了很长时间，但随着深度学习的出现，可以肯定地说，联结主义者已经赢得了这场战斗——尽管可能还不是最终的胜利者。近年来，出现了一些融合这两种方法的论文。我猜测符号主义人工智能还有一两次短暂的亮相，甚至可能最终以配角身份登场。
- en: My introduction to AI in the late 1980s was entirely symbolic. Connectionism
    was mentioned as another approach, but neural networks were thought inferior and
    likely to be marginally useful at best.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我在1980年代末接触到的人工智能完全是符号主义的。联结主义被提到作为另一种方法，但当时认为神经网络不如符号主义，并且最多只会是边缘性有用的技术。
- en: 'A complete history of artificial intelligence is beyond our scope. Such a magnum
    opus awaits a motivated and capable historian. Instead, I’ll focus on the development
    of machine learning while (very unfairly!) ignoring the mountain of effort expended
    over the decades by those in the symbolic camp. Know, however, that for most of
    AI’s history, people mostly spoke of symbolic AI, not connectionism. For a fairer
    presentation, I recommend Michael Wooldridge’s book *A Brief History of Artificial
    Intelligence* (Flatiron Books, 2021), or Pamela McCorduck’s deeply personal account
    in *This Could Be Important: My Life and Times with the Artificial Intelligentsia*
    (Lulu Press, 2019).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的完整历史超出了我们的讨论范围。这样的宏篇巨著等待着一位有动力且有能力的历史学家来完成。相反，我将聚焦于机器学习的发展，同时（非常不公平地！）忽略了那些在符号派阵营中付出数十年努力的工作。然而，请知道，在人工智能的大部分历史中，人们主要讨论的是符号AI，而不是联结主义。为了更公平的呈现，我推荐迈克尔·伍尔德里奇的《*人工智能简史*》（Flatiron
    Books, 2021），或者帕梅拉·麦考德克在《*这可能很重要：我与人工智能知识分子的生活与时代*》（Lulu Press, 2019）中的深刻个人叙述。
- en: With my apparent connectionist bias in mind, let’s take a stroll through the
    history of machine learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我明显的联结主义偏见，让我们一起回顾一下机器学习的历史。
- en: '***Pre-1900***'
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***1900年之前***'
- en: The dream of intelligent machines dates back to antiquity. Ancient Greeks related
    the myth of Talos, a giant robot meant to guard the Phoenician princess, Europa.
    Throughout the Middle Ages and Renaissance, many automatons—machines that moved
    and appeared lifelike—were developed. However, I suspect that none were believed
    to be intelligent or capable of thought. Some were even hoaxes, like the infamous
    Mechanical Turk that wowed the world by playing, and beating, many skilled chess
    players. In the end, it was discovered that a person hiding within the machine
    could control the “automaton” by manipulating a mechanical arm to move free-standing
    chess pieces on the board while viewing the board configuration from beneath.
    Still, the mechanical part of the machine was rather impressive for the late 18th
    century.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 智能机器的梦想可以追溯到古代。古希腊人讲述了塔罗斯的神话，塔罗斯是一个巨大的机器人，用来守护腓尼基公主欧罗巴。在中世纪和文艺复兴时期，许多自动机——会动且看起来栩栩如生的机器——被开发出来。然而，我怀疑当时没有人认为这些机器是智能的或具备思维能力的。有些甚至是骗局，比如臭名昭著的“机械土耳克”，它通过与许多高水平的棋手对弈并击败他们，令世人惊叹。最终，人们发现机器中隐藏着一个人，他通过操控机械臂在棋盘上移动独立的棋子，同时从下面观察棋盘的配置，来控制这个“自动机”。尽管如此，这台机器的机械部分对于18世纪末期来说，仍然相当令人印象深刻。
- en: Apart from automatons, there were also early attempts to understand thought
    as a mechanical process and efforts to produce a logical system capable of capturing
    thought. In the 17th century, Gottfried Leibniz described such a concept abstractly
    as an “alphabet of thought.” In the 1750s, Julien Offray de La Mettrie published
    *L’Homme Machine* (*Man as Machine*), arguing that thought is a mechanical process.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 除了自动机之外，还有早期的尝试试图将思维理解为一种机械过程，并且努力构建能够捕捉思维的逻辑系统。在17世纪，戈特弗里德·莱布尼茨抽象地描述了这样的概念，称其为“思维的字母表”。在1750年代，朱利安·奥夫雷·德·拉梅特里出版了《*人类机器*》（*L’Homme
    Machine*），主张思维是一个机械过程。
- en: The idea that human thought might emerge from the physical entity of the brain
    rather than the spiritual soul marked the beginning of a new chapter on the road
    to AI. If our minds are biological machines, why can’t there be another kind of
    machine that thinks?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 认为人类的思维可能来源于大脑的物理实体而非精神灵魂的想法，标志着通向人工智能的新篇章的开始。如果我们的思维是生物机器，为什么不能有另一种能够思考的机器呢？
- en: 'In the 19th century, George Boole attempted to create a calculus of thought,
    resulting in what we know now as Boolean algebra. Computers depend on Boolean
    algebra, to the point that it represents their very implementation as collections
    of digital logic gates. Boole was partially successful, but he didn’t achieve
    his stated goal: “to investigate the fundamental laws of those operations of the
    mind by which reasoning is performed; to give expression to them in the symbolic
    language of a Calculus” (*The Laws of Thought*, 1854). That Boole was willing
    to try represented another step toward the notion that AI might be possible.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在19世纪，乔治·布尔尝试创造一种思维的演算法，最终产生了我们现在所知的布尔代数。计算机依赖于布尔代数，甚至到它代表着计算机的实现形式——数字逻辑门的集合。布尔部分成功了，但他并未达成自己的目标：“调查那些思维运作的基本法则，通过这些法则进行推理；并用演算符号语言加以表达”（《思维的法则》，1854年）。布尔愿意尝试的精神，代表了朝向人工智能可能性的又一步迈进。
- en: What these early attempts were lacking was an actual calculating machine. People
    could dream of artificial minds or beings (like the creature from Mary Shelley’s
    *Frankenstein*) and, assuming their existence, discuss the repercussions. But
    until there was a machine capable of plausibly mimicking (implementing?) thought,
    all else was speculation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些早期尝试所缺乏的是一个真正的计算机器。人们可以梦想人工智能或生物（如玛丽·雪莱的*弗兰肯斯坦*中的生物），并假设它们的存在，讨论其后果。但在没有一个能够合理模仿（实现？）思维的机器之前，其他一切都只是猜测。
- en: 'It was Englishman Charles Babbage who, in the mid-19th century, first conceived
    of an implementable general-purpose calculating machine: the Analytical Engine.
    The Engine was never built in its entirety, but it contained all the essential
    components of a modern computer and would, in theory, be capable of the same operations.
    While it’s unclear if Babbage appreciated the potential versatility of his machine,
    his friend, Ada Lovelace, did. She wrote about the machine as a widely applicable,
    general-purpose device. Still, she did not believe the Engine was capable of thought,
    as this quote from her *Sketch of the Analytical Engine* (1843) demonstrates:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 正是英国人查尔斯·巴贝奇在19世纪中期首次构想到一个可实现的通用计算机器——分析机。尽管这台机器从未完全建成，但它包含了现代计算机的所有基本组件，并且理论上能够执行相同的操作。虽然不清楚巴贝奇是否意识到他那台机器的潜在多功能性，但他的朋友艾达·洛夫莱斯确实意识到了这一点。她将这台机器描述为一种广泛适用的通用设备。尽管如此，她并不认为这台机器能够进行思考，正如她在1843年所写的《分析机概述》中的这段话所表明的：
- en: The Analytical Engine has no pretensions whatever to originate anything. It
    can do whatever we know how to order it to perform. It can follow analysis; but
    it has no power of anticipating any analytical relations or truths. Its province
    is to assist us in making available what we are already acquainted with.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 分析机完全没有任何原创的野心。它可以做我们知道如何指令它执行的任何事情。它可以进行分析；但它没有预见任何分析关系或真理的能力。它的职能是帮助我们利用我们已经了解的东西。
- en: This quote may be the first to refer to the possibility of artificial intelligence
    involving a device potentially capable of achieving it. The phrase “do whatever
    we know how to order it to perform” implies programming. Indeed, Lovelace wrote
    a program for the Analytical Engine. Because of this, many people consider her
    to be the first computer programmer. The fact that her program had a bug in it
    proves to me that she was; nothing is more emblematic of programming than bugs,
    as my 40-plus years of programming experience have demonstrated distressingly
    often.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这句话可能是首次提到人工智能的可能性，并涉及一个可能实现这一目标的设备。短语“做我们知道如何指令它执行的任何事”意味着编程。事实上，洛夫莱斯为分析机编写了一个程序。正因为如此，许多人认为她是第一位计算机程序员。她的程序中有一个漏洞，这让我相信她确实是；没有什么比漏洞更能代表编程了，正如我40多年的编程经验所痛苦地证明的那样。
- en: '***1900 to 1950***'
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***1900 到 1950***'
- en: In 1936, a 24-year-old Englishman named Alan Turing, still a student at the
    time, wrote a paper that has since become the cornerstone of computer science.
    In this paper, Turing introduced a generic conceptual machine, what we now call
    a *Turing machine*, and demonstrated that it could calculate anything representable
    by an algorithm. He also explained that there are things that cannot be implemented
    by algorithms and that are, therefore, uncomputable. Since all modern programming
    languages are equivalent to a Turing machine, modern computers can implement any
    algorithm and compute anything computable. However, this says nothing about how
    long the computation might take or the memory required.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 1936年，当时还是学生的24岁英国人艾伦·图灵，写了一篇后来成为计算机科学基石的论文。在这篇论文中，图灵提出了一个通用的概念机器，今天我们称之为*图灵机*，并证明它可以计算任何由算法表示的事物。他还解释了有些事物是算法无法实现的，因此是不可计算的。由于所有现代编程语言都等同于图灵机，现代计算机可以实现任何算法并计算任何可计算的东西。然而，这并没有说明计算可能需要多长时间或需要多少内存。
- en: If a computer can compute anything that can be implemented as an algorithm,
    then a computer can perform any mental operation a human can perform. At last,
    here was the engine that might enable true artificial intelligence. Turing’s 1950
    paper “Computing Machinery and Intelligence” was an early recognition that digital
    computers might eventually lead to intelligent machines. In this paper, Turing
    described his “imitation game,” known now as the *Turing test*, by which humans
    might come to believe that a machine is intelligent. Many claims of AI systems
    that pass the Turing test have appeared, especially in recent years. One of these
    is OpenAI’s ChatGPT. However, few would be inclined to believe that ChatGPT is
    truly intelligent—in other words, I suspect that this test fails to capture what
    humans generally understand this term to mean, and a new test will likely be created
    at some point.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果计算机能够计算任何可以实现为算法的事情，那么计算机就能执行人类能够执行的任何思维操作。最终，这就是可能实现真正人工智能的引擎。图灵在1950年发表的论文《计算机器与智能》首次认识到数字计算机最终可能会导致智能机器的诞生。在这篇论文中，图灵描述了他的“模仿游戏”，现在被称为*图灵测试*，通过该测试，人类可能会认为一台机器是智能的。近年来，关于通过图灵测试的人工智能系统有很多宣称，其中之一就是OpenAI的ChatGPT。然而，少数人会倾向于认为ChatGPT是真正智能的——换句话说，我怀疑这个测试未必能捕捉到人类普遍理解的“智能”含义，未来可能会出现新的测试。
- en: In 1943, Warren McCulloch and Walter Pitts wrote “A Logical Calculus of Ideas
    Immanent in Nervous Activity,” which deserves an award for one of the most opaque
    yet intriguing paper titles ever. The paper represents “nervous nets” (collections
    of neurons) as logical statements in mathematics. The logical statements are difficult
    to parse (at least for me), but the authors’ description of “nets without circles”
    bears a strong resemblance to the neural networks we’ll explore in [Chapter 4](ch04.xhtml)—indeed,
    one could argue that McCulloch and Pitts’s groundbreaking paper led to what we
    now recognize as a neural network. Frankly, neural networks are far easier to
    parse and understand, which is good news for us.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 1943年，沃伦·麦卡洛克和沃尔特·皮茨写下了《神经活动中固有思想的逻辑演算》，这篇论文的标题可以说是最晦涩却引人入胜的之一。这篇论文将“神经网络”（即神经元的集合）表示为数学中的逻辑语句。这些逻辑语句难以解析（至少对我来说是这样），但作者对“没有回路的网络”的描述与我们在[第四章](ch04.xhtml)中将要探讨的神经网络非常相似——实际上，有人可以认为麦卡洛克和皮茨的开创性论文导致了我们今天所认知的神经网络。坦率来说，神经网络比这篇论文更容易解析和理解，这对我们来说是个好消息。
- en: The progression from fantastical stories about artificially intelligent machines
    and beings to a serious investigation of whether mathematics can capture thought
    and reasoning, combined with the realization that digital computers are capable
    of computing anything that can be described by an algorithm, set the stage for
    the advent of artificial intelligence as a legitimate research enterprise.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从关于人工智能机器和生物的幻想故事，到严肃探讨数学是否能够捕捉思维和推理，再到意识到数字计算机能够计算任何可以通过算法描述的事务，这一系列进展为人工智能作为一个合法的研究领域的出现奠定了基础。
- en: '***1950 to 1970***'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***1950到1970***'
- en: 'The 1956 Dartmouth Summer Research Project on Artificial Intelligence workshop
    is generally regarded as the birthplace of AI, and where the phrase “artificial
    intelligence” was first used consistently. The Dartmouth workshop had fewer than
    50 participants, but the list included several well-known names in the worlds
    of computer science and mathematics: Ray Solomonoff, John McCarthy, Marvin Minsky,
    Claude Shannon, John Nash, and Warren McCulloch, among others. At the time, computer
    science was a subfield of mathematics. The workshop was a brainstorming session
    that set the stage for early AI research.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 1956年达特茅斯夏季人工智能研究项目研讨会通常被认为是人工智能的发源地，也是“人工智能”这一术语首次被一致使用的地方。达特茅斯研讨会的参与者不到50人，但名单中包括了计算机科学和数学领域的几位知名人物：雷·所罗门诺夫、约翰·麦卡锡、马文·明斯基、克劳德·香农、约翰·纳什和沃伦·麦卡洛克等人。当时，计算机科学是数学的一个子领域。该研讨会是一次头脑风暴，为早期的人工智能研究奠定了基础。
- en: In 1957, Frank Rosenblatt of Cornell University created the Mark I Perceptron,
    widely recognized as the first application of neural networks. The Perceptron
    was remarkable in many respects, including that it was designed for image recognition,
    the same application where deep learning first proved itself in 2012.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 1957年，康奈尔大学的弗兰克·罗森布拉特创造了马克I感知机，被广泛认为是神经网络的首次应用。感知机在许多方面都非常出色，包括它被设计用于图像识别，这也是深度学习在2012年首次证明自己有效的应用领域。
- en: '[Figure 2-1](ch02.xhtml#ch02fig01) shows the conceptual organization as given
    in the *Perceptron Operators’ Manual*. The Perceptron used a 20×20-pixel digitized
    television image as input, which was then passed through a “random” set of connections
    to a set of association units that led to response units. This configuration is
    similar to some approaches to deep learning on images in use today and resembles
    a type of neural network known as an *extreme learning machine*.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2-1](ch02.xhtml#ch02fig01)展示了在《感知机操作手册》中给出的概念性组织结构。感知机使用一个20×20像素的数字化电视图像作为输入，然后通过一组“随机”连接传递到一组关联单元，最终导致响应单元的输出。这个配置与今天一些深度学习图像处理方法类似，且类似于一种称为*极限学习机*的神经网络类型。'
- en: '![Image](../images/ch02fig01.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch02fig01.jpg)'
- en: '*Figure 2-1: The organization of the Mark I Perceptron*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2-1：Mark I 感知机的组织结构*'
- en: 'If the Perceptron was on the right track, why was it all but forgotten for
    decades? One reason was Rosenblatt’s penchant for hype. At a 1958 conference organized
    by the US Navy (a sponsor of the Perceptron project), Rosenblatt’s comments were
    so hyperbolic that the *New York Times* reported:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果感知机走在正确的道路上，为什么它在几十年里几乎被遗忘了呢？其中一个原因是罗森布拉特的夸张言辞。1958年，美国海军（感知机项目的资助方）组织的一次会议上，罗森布拉特的言论夸大其词，以至于*纽约时报*报道了以下内容：
- en: The Navy revealed the embryo of an electronic computer today that it expects
    will be able to walk, talk, see, write, reproduce itself and be conscious of its
    existence. Later perceptrons will be able to recognize people and call out their
    names and instantly translate speech in one language to speech and writing in
    another language, it was predicted.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 海军今天揭示了一款电子计算机的雏形，预计它将能够走路、说话、看见、写作、自我复制，并意识到自己的存在。后来，感知机将能够识别人物并呼唤他们的名字，甚至瞬间将一种语言的语音翻译为另一种语言的语音和文字，预计如此。
- en: The comments ruffled many feathers at the time, though as modern AI systems
    do allow machines to walk, talk, see, write, recognize people, and translate speech
    and writing between languages, perhaps we should be more forgiving toward Rosenblatt.
    He was only some 60 years early.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些评论在当时引起了许多人的不满，尽管现代的人工智能系统确实允许机器走路、说话、看见、写作、识别人物，并且能够在不同语言之间进行语音和文字的翻译，也许我们应该对罗森布拉特宽容一些。他只是早了约60年。
- en: A few years later, in 1963, Leonard Uhr and Charles Vossler described a program
    that, like the Perceptron, interpreted a 20×20-pixel image represented as a matrix
    of 0s and 1s. Unlike the Perceptron, this program was able to generate the patterns
    and combinations of image features necessary to learn its inputs. Uhr and Vossler’s
    program was similar to the convolutional neural networks that appeared over 30
    years later and are the subject of [Chapter 5](ch05.xhtml).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 几年后，1963年，伦纳德·厄尔和查尔斯·沃斯勒描述了一个程序，类似于感知机，能够解释作为0和1的矩阵表示的20×20像素图像。与感知机不同，这个程序能够生成必要的图像特征模式和组合，以便学习其输入。厄尔和沃斯勒的程序与30多年后出现的卷积神经网络相似，后者是[第5章](ch05.xhtml)的主题。
- en: The first of what I call the “classical” machine learning models appeared in
    1967, courtesy of Thomas Cover and Peter Hart. Known as [*nearest neighbors*](glossary.xhtml#glo71),
    it is the simplest of all machine learning models, almost embarrassingly so. To
    label an unknown input, it simply finds the known input most like it and uses
    that input’s label as the output. When using more than one nearby known input,
    the method is called *k-nearest neighbors*, where *k* is a small number, like
    3 or 5\. Hart went on to write the first edition of *Pattern Classification*,
    along with Richard Duda and David Stork, in 1973; this seminal work introduced
    many computer scientists and software engineers to machine learning, including
    me.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我所称之为“经典”机器学习模型的第一个出现是在1967年，得益于托马斯·科弗和彼得·哈特。他们提出的[*最近邻*](glossary.xhtml#glo71)是所有机器学习模型中最简单的一种，甚至可以说有些令人羞愧。为了标记一个未知输入，它只需找到最相似的已知输入，并将该输入的标签作为输出。当使用多个邻近的已知输入时，这种方法被称为*k最近邻*，其中*k*是一个小数值，例如3或5。哈特后来与理查德·杜达和大卫·斯托克一起于1973年撰写了《模式分类》的第一版；这本开创性著作使许多计算机科学家和软件工程师（包括我）接触到了机器学习。
- en: 'The success of the Perceptron came to a screeching halt in 1969, when Marvin
    Minsky and Seymour Papert published their book *Perceptrons*, which demonstrated
    that single- and two-layer perceptron networks weren’t able to model interesting
    tasks. We’ll cover what “single-layer” and “two-layer” mean in time. *Perceptrons*,
    coupled with the 1973 release of “Artificial Intelligence: A General Survey” by
    James Lighthill, universally known as “the Lighthill report,” ushered in what
    is now referred to as the first AI winter; funding for AI research dried up in
    short order.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 感知机的成功在1969年戛然而止，当时马文·明斯基和西摩·帕珀特发布了他们的书籍《*感知机*》，书中展示了单层和双层感知机网络无法处理有趣任务的事实。我们稍后会解释“单层”和“双层”是什么意思。与《*感知机*》一书一起，1973年詹姆斯·莱特希尔发布的《人工智能：通用调查》（通常被称为“莱特希尔报告”）共同引发了现在所称的第一次AI寒冬；人工智能研究的资金迅速枯竭。
- en: Minsky and Papert’s criticisms of the perceptron model were legitimate; however,
    many people missed their observation that such limitations were not applicable
    to more complex perceptron models. Regardless, the damage was done, and connectionism
    virtually vanished until the early 1980s.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 明斯基和帕珀特对感知机模型的批评是有道理的；然而，许多人忽略了他们的观察——这些限制并不适用于更复杂的感知机模型。无论如何，损害已经造成，联结主义几乎在1980年代初期消失。
- en: 'Note the “virtually.” In 1979, Kunihiko Fukushima released a paper that was
    translated into English in 1980 as “Neocognitron: A Self-Organizing Neural Network
    Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position.”
    The name “Neocognitron” didn’t catch on, and this was perhaps one of the last
    uses of the “-tron” suffix that had been so popular in computer science for the
    previous three decades. While Uhr and Vossler’s 1963 program bore some similarities
    to a convolutional neural network, the Neocognitron is, to many people, the original.
    The success of convolutional neural networks led directly to the current AI revolution.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意“几乎”。1979年，福岛邦彦发布了一篇论文，该论文于1980年被翻译成英文，名为“Neocognitron: A Self-Organizing
    Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift
    in Position”。“Neocognitron”这个名字并未广泛传播，这也许是过去三十年计算机科学中“tron”后缀的最后一次使用。虽然乌尔和沃斯勒在1963年的程序与卷积神经网络有一些相似之处，但对许多人而言，Neocognitron才是最初的形式。卷积神经网络的成功直接引发了当前的AI革命。'
- en: '***1980 to 1990***'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***1980到1990***'
- en: In the early 1980s, AI went commercial with the advent of computers specifically
    designed to run the Lisp programming language, then the lingua franca of AI. (Today,
    it’s Python.) Along with Lisp machines came the rise of *expert systems*—software
    designed to capture the knowledge of an expert in a narrow domain. The commercialization
    of AI brought the first AI winter to an end.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在1980年代初，随着专门为运行Lisp编程语言设计的计算机的出现，人工智能开始商业化，Lisp曾是人工智能的通用语言。（如今，它是Python。）随着Lisp机器的出现，*专家系统*也崛起——这些软件旨在捕捉专家在特定领域的知识。人工智能的商业化使得第一次AI寒冬得以结束。
- en: The concept behind expert systems is, admittedly, seductive. To build an expert
    system that, for example, diagnoses a particular kind of cancer, you first interview
    experts to extract their knowledge and arrange it in a knowledge base. A knowledge
    base represents knowledge as a combination of rules and facts. Then, you combine
    the knowledge base with an inference engine, which uses the knowledge base to
    decide when and how to execute rules based on stored facts or input to the system
    by a user. Rules fire based on facts, which may lead to placing new facts in the
    knowledge base that cause additional rules to fire, and so on. A classic example
    of an expert system is CLIPS, which NASA developed in 1985 and released into the
    public domain in 1996.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 专家系统背后的概念，确实具有吸引力。例如，要构建一个诊断特定癌症类型的专家系统，你首先采访专家，提取他们的知识并将其整理成知识库。知识库将知识表示为规则和事实的组合。然后，你将知识库与推理引擎结合，推理引擎根据存储的事实或用户输入系统的信息来决定何时以及如何执行规则。规则根据事实触发，这可能导致将新的事实加入知识库，从而触发更多规则，依此类推。一个经典的专家系统示例是CLIPS，这是NASA在1985年开发的，并于1996年发布到公共领域。
- en: In an expert system, there’s no connectionist network or collection of units
    from which one might (hopefully) cause intelligent behavior to emerge, making
    it a good example of symbolic AI. Instead, the knowledge base is an essentially
    rigid collection of rules, like “if the engine temperature is above this threshold,
    then this other thing is the likely cause,” and facts, like “the engine temperature
    is below the threshold.” Knowledge engineers are the links between the experts
    and the expert system. Building a knowledge base from the experts’ answers to
    the questions posed by the knowledge engineers is complex, and the resulting knowledge
    base is hard to modify over time. However, the difficulty in designing expert
    systems doesn’t mean they’re useless; they still exist, mainly under the guise
    of “business rule management systems,” but currently have minimal impact on modern
    AI.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在专家系统中，并没有连接主义网络或单元集合可以（希望）促使智能行为的产生，这使得它成为符号AI的一个良好示例。相反，知识库本质上是一个僵化的规则集合，比如“如果发动机温度超过这个阈值，那么另一个原因很可能是这个”，以及事实，比如“发动机温度低于阈值”。知识工程师是专家与专家系统之间的纽带。从专家对知识工程师提出的问题的回答中构建知识库是复杂的，而且随着时间推移，得到的知识库难以修改。然而，设计专家系统的难度并不意味着它们毫无用处；它们仍然存在，主要以“业务规则管理系统”的形式存在，但目前对现代AI的影响很小。
- en: The hype surrounding expert systems, combined with early successes, drove renewed
    interest in AI in the early 1980s. But when it became clear that expert systems
    were too brittle to have a general use, the bottom fell out of the industry, and
    AI’s second winter hit in the middle of the decade.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 围绕专家系统的炒作，加上早期的成功，推动了1980年代初期对AI的重新关注。但当人们发现专家系统过于脆弱，无法具有广泛的应用时，整个行业陷入低谷，AI的第二次寒冬在十年中期到来。
- en: During the 1980s, connectionists occupied the background, but they were not
    sitting still. In 1982, John Hopfield demonstrated what are now known as Hopfield
    networks. A *Hopfield network* is a type of neural network that stores information
    in a distributed way within the weights of the network, and then extracts that
    information at a later time. Hopfield networks aren’t widely used in modern deep
    learning, but they proved an important demonstration of the utility of the connectionist
    approach.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在1980年代，连接主义者占据了背景位置，但他们并没有停滞不前。1982年，John Hopfield 展示了现在被称为Hopfield网络的模型。*Hopfield网络*是一种神经网络，它以分布式的方式存储信息在网络的权重中，然后在稍后的时间提取这些信息。Hopfield网络在现代深度学习中并不广泛使用，但它们证明了连接主义方法的实用性。
- en: In 1986, David Rumelhart, Geoffrey Hinton, and Ronald Williams released their
    paper “Learning Representations by Back-propagating Errors,” which outlined the
    backpropagation algorithm for training neural networks. Training a neural network
    involves adjusting the weights between the neurons so that the network operates
    as desired. The backpropagation algorithm was the key to making this process efficient
    by calculating how adjusting a particular weight affects the network’s overall
    performance. With this information, it becomes possible to iteratively train the
    network by applying known training data, then using the network’s errors when
    classifying to adjust the weights to force the network to perform better on the
    next iteration. (I’ll discuss neural network training in more depth in [Chapter
    4](ch04.xhtml).) With backpropagation, neural networks could go well beyond the
    limited performance of Rosenblatt’s Perceptron. However, even with backpropagation,
    neural networks in the 1980s were little more than toys. While there’s contention
    about who invented backpropagation and when, the 1986 paper is generally understood
    to be the presentation that influenced neural network researchers the most.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在1986年，David Rumelhart、Geoffrey Hinton 和 Ronald Williams 发布了他们的论文《通过反向传播误差学习表示》，该论文概述了用于训练神经网络的反向传播算法。训练神经网络涉及调整神经元之间的权重，以使网络按预期工作。反向传播算法通过计算调整特定权重对网络整体性能的影响，成为使这一过程高效的关键。有了这些信息，就可以通过应用已知的训练数据来迭代地训练网络，然后在分类时使用网络的误差来调整权重，迫使网络在下一次迭代中表现得更好。（我将在[第4章](ch04.xhtml)中更深入地讨论神经网络训练。）通过反向传播，神经网络可以远远超越Rosenblatt的感知机的有限表现。然而，即使有了反向传播，1980年代的神经网络仍然不过是一些玩具。关于谁发明了反向传播以及何时发明，仍然存在争议，但1986年的论文通常被认为是最能影响神经网络研究者的展示。
- en: '***1990 to 2000***'
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***1990到2000***'
- en: The second AI winter extended into the 1990s, but research continued in both
    the symbolic and connectionist camps. Corinna Cortes and Vladimir Vapnik introduced
    the machine learning community to [*support vector machines (SVMs)*](glossary.xhtml#glo92)
    in 1995\. In a sense, SVMs represent the high-water mark of classical machine
    learning. The success of SVMs in the 1990s through the early 2000s held neural
    networks at bay. Neural networks require large datasets and significant computational
    power; SVMs, on the other hand, are often less demanding of resources. Neural
    networks gain their power from the network’s ability to represent a function,
    a mapping from inputs to the desired outputs, while SVMs use clever mathematics
    to simplify difficult classification problems.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: The success of SVMs was noted in the academic community as well as the broader
    world of software engineering, where applications involving machine learning were
    increasing. The general public was largely unaware of these advances, though intelligent
    machines continued appearing frequently in science fiction.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: This AI winter ended in 1997 with the victory of IBM’s Deep Blue supercomputer
    against then world chess champion Garry Kasparov. At the time, few people thought
    a machine could ever beat the best human chess player. Interestingly, a decade
    earlier, one of my professors had predicted that an AI would accomplish this feat
    before the year 2000\. Was this professor clairvoyant? Not really. Deep Blue combined
    fast custom hardware with sophisticated software and applied known AI search algorithms
    (in particular, the Minimax algorithm). Combined with heuristics and a healthy
    dose of custom knowledge from other chess grandmasters, Deep Blue was able to
    out-evaluate its human opponent by searching more possible moves than any human
    could ever hope to contemplate. Regardless, at its core, Deep Blue implemented
    what AI experts knew *could* beat a human if the machine had enough resources
    at its disposal. Deep Blue’s victory was inevitable because researchers expected
    computers to eventually become fast enough to overcome a human’s abilities. What
    was needed was known; all that remained was to put the pieces together.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'The year 1998 saw the publication of “Gradient-Based Learning Applied to Document
    Recognition,” a paper by Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner
    that escaped public notice but was a watershed moment for AI and the world. While
    Fukushima’s Neocognitron bore strong similarities to the convolutional neural
    networks that initiated the modern AI revolution, this paper introduced them directly,
    as well as the (in)famous MNIST dataset we used in [Chapter 1](ch01.xhtml). The
    advent of convolutional neural networks (CNNs) in 1998 begs the question: why
    did it take another 14 years before the world took notice? We’ll return to this
    question later in the chapter.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '***2000 to 2012***'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Leo Breiman introduced [*random forests*](glossary.xhtml#glo83) in 2001 by
    forming the existing pieces of what would become the random forest algorithm into
    a coherent whole, much like Darwin did with evolution in the 19th century. Random
    forests are the last of the classical machine learning algorithms we’ll contemplate
    in [Chapter 3](ch03.xhtml). If “random forests” remind you of the decision trees
    in [Chapter 1](ch01.xhtml), there’s a reason: a random forest is a forest of decision
    trees.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Leo Breiman在2001年通过将随机森林算法的现有部分组织成一个连贯的整体，介绍了[*随机森林*](glossary.xhtml#glo83)，这就像19世纪达尔文将进化理论整合成一个完整的理论体系一样。随机森林是我们在[第3章](ch03.xhtml)中要讨论的最后一个经典机器学习算法。如果“随机森林”让你想起[第1章](ch01.xhtml)中的决策树，那是有原因的：随机森林实际上是由决策树组成的森林。
- en: Stacked denoising autoencoders are one type of intermediate model, and they
    were my introduction to deep learning in 2010\. An *autoencoder* is a neural network
    that passes its input through a middle layer before generating output. It aims
    to reproduce its input from the encoded form of the input in the middle layer.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠去噪自编码器是一种中间模型，它们是我在2010年接触深度学习的入门之一。一个*自编码器*是一个神经网络，它通过一个中间层传递输入数据，然后生成输出。它的目标是从中间层的编码形式重构输入数据。
- en: An autoencoder may seem like a silly thing to fiddle with, but while learning
    to reproduce its input, the middle layer typically learns something interesting
    about the inputs that captures their essence without focusing on fine, trivial
    details. For example, if the inputs are the MNIST digits, then the middle layer
    of an autoencoder learns about digits as opposed to letters.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器可能看起来像是一个愚蠢的玩意儿，但在学习重构输入时，中间层通常会学到一些关于输入的有趣信息，这些信息能够捕捉到输入的本质，而不会关注细微的、琐碎的细节。例如，如果输入是MNIST数字，那么自编码器的中间层就会学习到数字的特征，而不是字母。
- en: A *denoising autoencoder* is similar, but we discard a random fraction of the
    input values before pushing the input through the middle layer. The autoencoder
    must still learn to reproduce the entire input, but now it has a more challenging
    task because the input is incomplete. This process helps the autoencoder’s middle
    layer discover a better encoding of the input.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*去噪自编码器*类似，但我们会在将输入通过中间层之前随机丢弃一部分输入值。自编码器仍然需要学习重构整个输入，但现在它面临的任务更加困难，因为输入是不完整的。这个过程有助于自编码器的中间层发现输入的更好编码。'
- en: Finally, a *stacked denoising autoencoder* is a stack of denoising autoencoders,
    wherein the output of the middle layer of one becomes the input of the next. When
    arranged this way, the stack learns a new representation of the input, which often
    helps a classifier appended to the top of the stack to discriminate between classes.
    For example, in my work at the time, the inputs were small pieces of an image
    that may have contained a target of interest. Two or three layers of trained stacked
    denoising autoencoders were used to transform the inputs into a list of numbers
    that would hopefully represent the input’s essence while ignoring the image’s
    minutiae. The outputs were then used with a support vector machine to decide if
    the input was a target.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，*堆叠去噪自编码器*是由多个去噪自编码器堆叠而成，其中一个自编码器的中间层输出作为下一个自编码器的输入。以这种方式排列时，堆叠学习了输入的一个新表示，这通常有助于附加在堆叠顶部的分类器区分不同的类别。例如，在我当时的工作中，输入是图像的若干小片段，这些片段可能包含感兴趣的目标。使用经过训练的两到三层堆叠去噪自编码器，将输入转换成一个数字列表，这些数字通常能够代表输入的本质，同时忽略图像的细节。然后，这些输出会与支持向量机结合使用，以判断输入是否为目标。
- en: '***2012 to 2021***'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***2012到2021***'
- en: Deep learning caught the world’s attention in 2012 when AlexNet, a particular
    convolutional neural network architecture, won the ImageNet challenge with an
    overall error of just over 15 percent—far lower than any competitor. The ImageNet
    challenge asks models to identify the main subject of color images, whether a
    dog, a cat, a lawnmower, and so on. In reality, “dog” isn’t a sufficient answer.
    The ImageNet dataset contains 1,000 classes of objects, including some 120 different
    dog breeds. So, a correct answer would be “it’s a Border Collie” or “it’s a Belgian
    Malinois.”
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在2012年引起了全球的关注，当时AlexNet，这一特定的卷积神经网络架构，以仅15%以上的错误率赢得了ImageNet挑战赛，远低于任何竞争对手。ImageNet挑战赛要求模型识别彩色图像的主要主题，无论是狗、猫、割草机等。实际上，“狗”并不是一个足够的答案。ImageNet数据集包含1,000个类别的物体，其中包括大约120种不同的狗品种。所以，正确的回答应该是“它是一只边境牧羊犬”或者“它是一只比利时马利诺犬”。
- en: Random guessing means randomly assigning a class label to each image. In that
    case, we would expect an overall success rate of 1 in 1,000, or an error rate
    of 99.9 percent. AlexNet’s error of 15 percent was truly impressive—and that was
    in 2012\. By 2017, convolutional neural networks had reduced the error to about
    3 percent, below the approximate 5 percent achievable by the few humans brave
    enough to do the challenge manually. Can you discriminate between 120 different
    dog breeds? I certainly can’t.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 随机猜测意味着将一个类别标签随机分配给每一张图片。在这种情况下，我们可以预期总体成功率为千分之一，或者错误率为99.9%。AlexNet的15%的错误率确实令人印象深刻——那是在2012年。到2017年，卷积神经网络将错误率降低到大约3%，低于约5%的水平，这是少数勇敢地手动进行挑战的人能够实现的。你能分辨出120种不同的犬种吗？我当然做不到。
- en: 'AlexNet opened the floodgates. The new models broke all previous records and
    began to accomplish what no one had really expected from them: tasks like reimagining
    images in the style of another image or painting, generating a text description
    of the contents of an image along with the activity shown, or playing video games
    as well as or better than a human, among others.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet打开了洪水闸门。新模型打破了所有先前的记录，并开始实现没有人真正期望它们实现的任务：比如重新构想图像的风格，生成图像内容及活动的文本描述，或者像人类一样甚至更好地玩视频游戏等等。
- en: The field was proliferating so quickly that it became nearly impossible to keep
    up with each day’s deluge of new papers. The only way to stay current was to attend
    multiple conferences per year and review the new work appearing on websites such
    as arXiv ([*https://www.arxiv.org*](https://www.arxiv.org)), where research in
    many fields is first published. This led to the creation of sites like [*https://www.arxiv-sanity-lite.com*](https://www.arxiv-sanity-lite.com),
    which ranks machine learning papers according to reader interest in the hope that
    the “best” might become easier to find.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这一领域迅速发展，以至于几乎无法跟上每天涌现的新论文。保持最新状态的唯一方法是每年参加多场会议，并审查在如arXiv（[*https://www.arxiv.org*](https://www.arxiv.org)）这样的站点上首次发布的新研究，这里是许多领域的研究首发地。这促使了像[*https://www.arxiv-sanity-lite.com*](https://www.arxiv-sanity-lite.com)这样的站点的创建，它根据读者的兴趣对机器学习论文进行排名，希望能够更容易地找到“最好的”论文。
- en: In 2014, another breakthrough appeared on the scene, courtesy of researcher
    Ian Goodfellow’s insight during an evening’s conversation with friends. The result
    was the birth of [*generative adversarial networks (GANs)*](glossary.xhtml#glo46),
    which Yann LeCun called at the time the most significant breakthrough in neural
    networks in 20 to 30 years (overheard at NeurIPS 2016). GANs, which we’ll discuss
    in [Chapter 6](ch06.xhtml), opened a new area of research that lets models “create”
    output that’s related to but different from the data on which they were trained.
    GANs led to the current explosion of [*generative AI*](glossary.xhtml#glo47),
    including systems like ChatGPT and Stable Diffusion.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 2014年，另一个突破性进展出现在研究员Ian Goodfellow与朋友们在一个晚上交谈时的启发下。结果就是[*生成对抗网络（GANs）*](glossary.xhtml#glo46)的诞生，Yann
    LeCun在当时称之为20到30年来神经网络领域最重要的突破（在NeurIPS 2016上听到的）。我们将在[第六章](ch06.xhtml)中讨论GANs，它开辟了一个新的研究领域，让模型能够“创造”与训练数据相关但不同的输出。GANs导致了当前[*生成式AI*](glossary.xhtml#glo47)的爆炸性发展，包括像ChatGPT和Stable
    Diffusion这样的系统。
- en: '*Reinforcement learning* is one of the three main branches of machine learning,
    the other two being the supervised learning we’ve been discussing and unsupervised
    learning, which attempts to train models without labeled datasets. In reinforcement
    learning, an agent (a model) is taught via a reward function how to accomplish
    a task. The application to robotics is obvious.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*强化学习*是机器学习的三大分支之一，另外两个是我们一直在讨论的监督学习和尝试在没有标注数据集的情况下训练模型的无监督学习。在强化学习中，一个代理（即模型）通过奖励函数被教导如何完成任务。其在机器人技术中的应用显而易见。'
- en: 'Google’s DeepMind group introduced a deep reinforcement learning–based system
    in 2013 that could successfully learn to play Atari 2600 video games as well as
    or better than human experts. (Who counts as an expert in a then-35-year-old game
    system, I’m not sure.) The most impressive part of the system, to me, was that
    the model’s input was precisely the human’s input: an image of the screen, nothing
    more. This meant the system had to learn how to parse the input image and, from
    that, how to respond by moving the joystick to win the game (virtually—they used
    emulators).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Google的DeepMind团队在2013年推出了一个基于深度强化学习的系统，能够成功地学习玩Atari 2600视频游戏，且与人类专家的表现相当或更好。（我不确定当时35年的游戏系统中，谁算得上是专家。）对我来说，这个系统最令人印象深刻的部分是，模型的输入正是人类的输入：屏幕图像，仅此而已。这意味着该系统必须学会如何解析输入的图像，并从中学会如何通过移动操纵杆来赢得游戏（实际上是使用模拟器）。
- en: The gap between beating humans at primitive video games and beating humans at
    abstract strategy games like Go was, historically, deemed insurmountable. I was
    explicitly taught in the late 1980s that the Minimax algorithm used by systems
    like Deep Blue to win at chess did not apply to a game like Go; therefore, no
    machine would ever beat the best human Go players. My professors were wrong, though
    they had every reason at the time to believe their statement.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在击败人类原始视频游戏的能力与击败人类在围棋等抽象策略游戏中的能力之间的差距，历史上曾被认为是不可逾越的。我在1980年代末明确被教导，像Deep Blue这样通过Minimax算法在国际象棋中取胜的系统并不适用于围棋这样的游戏；因此，没有机器能够战胜最优秀的人类围棋选手。然而，我的教授们错了，尽管当时他们有充分的理由相信他们的观点。
- en: In 2016, Google’s AlphaGo system beat Go champion Lee Sedol in a five-game match,
    winning four to one. The world took notice, further enhancing the growing realization
    that a paradigm shift had occurred. By this time, machine learning was already
    a commercial success. However, AlphaGo’s victory was utterly impressive for machine
    learning researchers and practitioners.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 2016年，Google的AlphaGo系统在五局三胜制的比赛中以4比1击败了围棋冠军李世石。全世界都注意到了这一点，进一步增强了对一个范式转变已经发生的认知。到这时，机器学习已经取得了商业上的成功。然而，AlphaGo的胜利对于机器学习研究人员和从业者来说，仍然是完全令人印象深刻的。
- en: Most of the general public didn’t notice that AlphaGo, trained on thousands
    of human-played Go games, was replaced in 2017 by AlphaGo Zero, a system trained
    entirely from scratch by playing against itself, with no human input given. In
    short order, AlphaGo Zero mastered Go, even beating the original AlphaGo system
    (scoring a perfect 100 wins and no losses).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数普通公众没有注意到，AlphaGo在2017年被AlphaGo Zero所取代，后者是一个完全从零开始，通过与自己对弈进行训练的系统，完全没有任何人类输入。很快，AlphaGo
    Zero掌握了围棋，甚至战胜了原版的AlphaGo系统（取得了100场胜利，且一场未败）。
- en: 'However, in 2022, the current state-of-the-art Go system, KataGo, was repeatedly
    and easily defeated by a system trained not to win but to reveal the brittleness
    inherent in modern AI systems. The moves the adversarial system used were outside
    the range encountered by KataGo when it was trained. This is a real-world example
    of how models are good at interpolating but bad at extrapolating. When the adversarial
    system was trained not to be better at Go but to exploit and “frustrate” the AI,
    it was able to win better than three out of four games. I point the reader to
    the *Star Trek: The Next Generation* episode “Peak Performance,” where Data the
    android “wins” a difficult strategy game against a master not by attempting to
    win but by attempting to match and frustrate.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在2022年，目前最先进的围棋系统KataGo屡次且轻松地被一个训练目标不是为了赢得比赛，而是为了揭示现代AI系统固有脆弱性的对抗系统所击败。对抗系统所使用的棋招超出了KataGo训练时所遇到的范围。这是一个现实世界的例子，展示了模型擅长内插却不擅长外推。当对抗系统被训练为不是为了在围棋中更强，而是为了利用并“挫败”AI时，它能够赢得四局中的三局以上。我向读者推荐*星际迷航：下一代*的那集“巅峰表现”，其中安卓人Data并非试图赢得一场艰难的策略游戏，而是通过与对手匹敌并让对方感到挫败来“获胜”。
- en: Deep learning’s penchant for beating humans at video games continues. In place
    of primitive games like Atari’s, deep reinforcement learning systems are now achieving
    grandmaster-level performance at far more difficult games. In 2019, DeepMind’s
    AlphaStar system outperformed 99.8 percent of human players in *StarCraft II*,
    a strategy game requiring the development of units and a plan of battle.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在视频游戏中击败人类的趋势持续不减。取代像Atari这种原始游戏，深度强化学习系统如今在更复杂的游戏中达到了大师级表现。2019年，DeepMind的AlphaStar系统在*星际争霸
    II*这款策略游戏中超越了99.8%的玩家，该游戏要求发展单位并策划战斗计划。
- en: The 1975 Asilomar Conference on Recombinant DNA was an important milestone in
    recognizing biotechnology’s growth and potential ethical issues. The conference
    positively impacted future research, and that year its organizers published a
    summary paper outlining an ethical approach to biotechnology. The potential hazards
    of a field that was then primarily in its infancy were recognized early, and action
    was taken to ensure ethical issues were paramount when contemplating future research.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 1975年的阿西洛马重组DNA大会是认识到生物技术增长和潜在伦理问题的重要里程碑。该会议对未来的研究产生了积极影响，并且在当年，组织者发布了一篇总结性论文，概述了生物技术的伦理方法。那时，这个领域还处于初期阶段，但潜在的风险已经被早期认识到，并采取了措施，确保在考虑未来研究时，伦理问题始终处于重要位置。
- en: The 2017 Asilomar Conference on Beneficial AI intentionally mirrored the earlier
    conference to raise awareness of the potential hazards associated with AI. It
    is now common to encounter conference sessions with titles like “AI for Good.”
    The 2017 Asilomar conference resulted in the development of a set of principles
    to guide the growth and application of artificial intelligence. Similarly, as
    of 2023, the US government—specifically, the White House Office of Science and
    Technology Policy—has developed a “Blueprint for an AI Bill of Rights” meant to
    protect the American public from the harmful effects of AI indiscriminately applied.
    Indeed, White House officials have taken pains to address the AI community directly
    to encourage proper consideration in developing even more powerful AI systems.
    All of this is a good sign, but history teaches that human law often lags behind
    technological development, so the ultimate effectiveness of these necessary attempts
    at framing the field remains to be seen.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年的阿西洛马有益AI大会故意模仿了早期的会议，以提高人们对AI潜在危险的认识。如今，会议中常常能看到诸如“AI造福人类”这样的议题标题。2017年阿西洛马大会促成了人工智能发展与应用的指导原则的制定。类似地，到2023年，美国政府——具体来说是白宫科技政策办公室——已经制定了《AI权利法案蓝图》，旨在保护美国公众免受AI不加区分应用的有害影响。事实上，白宫官员们也特别致力于直接与AI社区沟通，鼓励在开发更强大的AI系统时充分考虑各种问题。所有这些都是一个好兆头，但历史告诉我们，人类的法律往往滞后于技术的发展，因此这些努力是否能够有效地框定这一领域，仍有待观察。
- en: '***2021 to Now***'
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***2021年至今***'
- en: The COVID-19 pandemic of 2020 brought most of the world to a standstill. However,
    the AI community was only minimally impacted by the pandemic, likely because remote
    collaboration and conferences work rather well in this field. In addition, we
    can access powerful computers over the internet, so physical proximity doesn’t
    limit research as it might in other disciplines where access to the hardware is
    necessary.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 2020年的COVID-19大流行使世界大多数地方陷入停滞。然而，AI社区受到的影响却非常有限，这可能是因为远程协作和会议在这个领域中运作得相当顺利。此外，我们可以通过互联网访问强大的计算机，因此物理上的接近性不会像其他学科那样限制研究，尤其是在这些学科中需要接触硬件。
- en: 'Beginning in 2021 and continuing as I write, an explosion of new models have
    appeared, each more impressive than the last. Most can accept text input written
    by humans to produce text, images, or even video output. Often, the input marries
    text and example imagery to guide the system. Current popular (and concerning)
    systems include DALL-E 2, Stable Diffusion, Midjourney, and ChatGPT, among others.
    Most large tech companies have also demonstrated cutting-edge techniques that
    generate video, audio, and even 3D models. The current buzz generated by these
    systems is reminiscent of the excitement in 2012, when deep learning proved its
    worth with AlexNet. It’s another paradigm shift; but, to be clear, none of these
    systems are conscious. I’m not alone in this opinion. Even ChatGPT agrees with
    me. I asked it: “Are you a conscious being?” Here’s its reply, verbatim:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 从2021年开始，并且持续到我写这篇文章时，新模型的爆炸式增长让人印象深刻，每一个比上一个更为强大。大多数模型能够接受人类书写的文本输入，进而生成文本、图像甚至视频输出。输入通常结合了文本和示例图像来引导系统。目前流行的（且令人担忧的）系统包括DALL-E
    2、Stable Diffusion、Midjourney和ChatGPT等。大多数大型科技公司也展示了生成视频、音频甚至3D模型的尖端技术。这些系统目前引发的热议让人想起了2012年深度学习凭借AlexNet证明其价值时的兴奋情绪。这又是一次范式转变；但需要明确的是，这些系统并没有意识。我并不是唯一有这种看法的人，甚至ChatGPT也同意我这个观点。我问它：“你是一个有意识的存在吗？”它的回答是，逐字如下：
- en: As a machine learning model, I am not a conscious being. I am a computer program
    that has been trained to generate text based on input from a user. I do not have
    the ability to think, reason, or experience consciousness in the same way that
    humans do. I am designed to provide information and assist users, but I do not
    have any independent thought or consciousness.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个机器学习模型，我并不是一个有意识的存在。我是一个计算机程序，经过训练，根据用户输入生成文本。我没有像人类一样思考、推理或体验意识的能力。我设计的目的是提供信息和帮助用户，但我没有独立的思想或意识。
- en: I think Ada Lovelace would be satisfied with this answer, though she might be
    puzzled about how an unthinking machine could generate it. Note, however, that
    ChatGPT didn’t claim not to think, only that it doesn’t think like humans do.
    We’ll explore image synthesis in [Chapter 6](ch06.xhtml) and large language models
    like ChatGPT in [Chapter 7](ch07.xhtml). Perhaps then we’ll find a resolution
    to her (assumed) confusion.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为艾达·洛夫莱斯会对这个答案感到满意，尽管她可能会对一个没有思维的机器是如何生成这个答案感到困惑。不过，请注意，ChatGPT并没有声称自己不思考，而是说它不像人类那样思考。我们将在[第6章](ch06.xhtml)中探讨图像合成，在[第7章](ch07.xhtml)中探讨像ChatGPT这样的庞大语言模型。也许到时候我们能找到解决她（假设的）困惑的方法。
- en: '****'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: So, why now? The short answer is the fall of symbolic AI and the rise of technological
    innovations highly favorable to the connectionist approach.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么是现在呢？简短的回答是符号人工智能的衰落和对连接主义方法极为有利的技术创新的兴起。
- en: Symbolic AI and connectionism emerged together, with symbolic AI dominating
    for decades and forcing connectionism into the background. But after two AI winters
    that left symbolic AI barely breathing, connectionism, assisted by key technological
    innovations, has risen to fill the void.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 符号人工智能和连接主义是同时出现的，符号人工智能主导了几十年，迫使连接主义处于背景中。然而，在经历了两次人工智能寒冬，符号人工智能几乎濒临灭绝之后，连接主义在关键技术创新的帮助下崛起，并填补了这一空白。
- en: I think of the relationship between symbolic AI and connectionism as akin to
    that between non-avian dinosaurs and mammals. Dinosaurs and mammals emerged at
    roughly the same time, geologically speaking, but large, terrestrial dinosaurs
    dominated the world for about 160 million years, forcing mammals to eke out an
    existence in the shadows. When the asteroid hit 66 million years ago, the large
    dinosaurs were wiped out, allowing the mammals to evolve and take over.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为符号人工智能与连接主义的关系，就像是非鸟类恐龙与哺乳动物之间的关系。从地质学的角度来看，恐龙和哺乳动物几乎在同一时期出现，但大型陆地恐龙主宰了地球约1.6亿年，迫使哺乳动物只能在阴影中勉强生存。当大约6600万年前小行星撞击地球时，大型恐龙灭绝了，给了哺乳动物进化并接管地球的机会。
- en: Of course, analogies ultimately break down. The dinosaurs didn’t die out completely—we
    now call them birds—and they didn’t go extinct because they were somehow inferior.
    In fact, the dinosaurs are one of Earth’s greatest success stories. Non-avian
    dinosaurs died because of plain old bad luck. It was, almost literally, a disaster
    that did them in (“disaster” from the Italian *disastro*, meaning “ill star”).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，类比最终会失效。恐龙并没有完全灭绝——我们现在称它们为鸟类——而且它们并不是因为某种劣势而灭绝的。事实上，恐龙是地球上最伟大的成功故事之一。非鸟类恐龙之所以灭绝，纯粹是因为运气不好。几乎可以说，是一场灾难导致了它们的灭绝（“灾难”这个词来源于意大利语*disastro*，意思是“坏星”）。
- en: Might symbolic AI reemerge? It’s likely in some form, but in cooperation with
    connectionism. Symbolic AI promised that intelligent behavior was possible in
    the abstract, and it didn’t deliver. Connectionism claims that intelligent behavior
    can emerge from a collection of simpler units. Deep learning’s successes support
    this view, to say nothing of the billions of living brains currently on the planet.
    But, as ChatGPT pointed out, existing connectionist models “do not think, reason,
    or experience consciousness in the same way that humans do.” Modern neural networks
    are not minds; they are representation-learning data processors. I’ll clarify
    what that means in [Chapter 5](ch05.xhtml).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 符号人工智能有可能重新出现吗？它可能会以某种形式出现，但会与连接主义合作。符号人工智能曾承诺智能行为在抽象层面上是可能的，但它没有实现这一点。连接主义声称，智能行为可以从一组更简单的单元中产生。深度学习的成功支持了这一观点，更不用说地球上当前存在的数十亿个活脑了。但正如ChatGPT所指出的，现有的连接主义模型“并不像人类那样思考、推理或体验意识。”现代神经网络不是心智；它们是表示学习的数据处理器。我将在[第5章](ch05.xhtml)中进一步阐明这一点。
- en: Though our species, *Homo sapiens*, relies critically on symbolic thought, it
    isn’t a requirement for intelligence. In his book *Understanding Human Evolution*
    (Cambridge University Press, 2022), anthropologist Ian Tattersall claims it was
    unlikely that Neanderthals used symbolic thought as we do, nor did they have language
    as we do, but that they were nonetheless intelligent. Indeed, the Neanderthals
    were sufficiently human for our ancestors to “make love, not war” with them more
    than once—the DNA of people of non-African ancestry testifies to this fact.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们物种*智人*在很大程度上依赖于符号思维，但符号思维并不是智能的必备条件。在他的书《理解人类进化》（剑桥大学出版社，2022年）中， 人类学家伊恩·塔特萨尔（Ian
    Tattersall）声称，尼安德特人不太可能像我们一样使用符号思维，也没有像我们一样的语言，但他们仍然具有智能。实际上，尼安德特人足够像人类，以至于我们的祖先曾多次与他们“作爱，而非打仗”——非非洲血统的人的DNA证明了这一事实。
- en: I expect a synergy between connectionism and symbolic AI in the near future.
    For example, because a system like ChatGPT is, in the end, only predicting the
    next output token (word or part of a word), it can’t know when it’s saying something
    wrong. An associated symbolic system could detect faulty reasoning in the response
    and correct it. How such a system might be implemented, I don’t know.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我预计，在不久的将来，联结主义和符号人工智能之间会产生协同效应。例如，由于像ChatGPT这样的系统最终只是在预测下一个输出符号（单词或单词的一部分），它无法知道自己何时说错话。一个关联的符号系统可以检测到响应中的错误推理并加以修正。至于这样的系统如何实现，我并不清楚。
- en: '****'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: Hints of what might emerge from connectionism were evident by the early 1960s.
    So, was it only symbolic AI bias that delayed the revolution for so many decades?
    No. Connectionism stalled because of speed, algorithm, and data issues. Let’s
    examine each in turn.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 到1960年代初，联结主义可能会出现的一些迹象已经显现。那么，是否仅仅是符号人工智能的偏见延迟了这场革命长达数十年？不是的。联结主义的发展停滞是因为速度、算法和数据问题。让我们逐一分析这些问题。
- en: '***Speed***'
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***速度***'
- en: 'To understand why speed stalled the growth of connectionism, we need to understand
    how computers work. Taking great liberties allows us to think of computers as
    memory, which holds data (numbers) and a processing unit, typically known as the
    central processing unit (CPU). A microprocessor—like the one in your desktop computer,
    smartphone, voice-controlled assistant, car, microwave, and virtually everything
    else you use that isn’t a toaster (oh, and in many toasters too)—is a CPU. Think
    of a CPU as a traditional computer: data comes into the CPU from memory or input
    devices like a keyboard or mouse, gets processed, then is sent out of the CPU
    to memory or an output device like a monitor or hard drive.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么速度阻碍了联结主义的发展，我们需要了解计算机是如何工作的。为了便于理解，我们可以把计算机看作是一个内存，它存储数据（数字）和一个处理单元，通常被称为中央处理单元（CPU）。一个微处理器——比如你桌面电脑、智能手机、语音控制助手、汽车、微波炉，以及几乎你所用的所有设备（除了烤面包机，哦，很多烤面包机也有）——就是一个CPU。把CPU想象成传统计算机：数据从内存或输入设备（如键盘或鼠标）进入CPU，经过处理后，再通过CPU发送到内存或输出设备（如显示器或硬盘）。
- en: 'Graphics processing units (GPUs), on the other hand, were developed for displays,
    primarily for the video game industry, to enable fast graphics. GPUs can perform
    the same operation, such as “multiply by 2,” on hundreds or thousands of memory
    locations (read: *pixels*) simultaneously. If a CPU wants to multiply a thousand
    memory locations by 2, it must multiply the first, second, third, and so on sequentially.
    As it happens, the primary operation needed to train and implement a neural network
    is ideally suited to what a GPU can do. GPU makers, like NVIDIA, realized this
    early and began developing GPUs for deep learning. Think of a GPU as a supercomputer
    on a card that fits in your PC.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，图形处理单元（GPU）是为显示器开发的，最初是为视频游戏产业设计的，目的是实现快速图形渲染。GPU能够同时对成百上千的内存位置（即*像素*）执行相同的操作，例如“乘以2”。如果CPU想要把一千个内存位置乘以2，它必须依次处理第一个、第二个、第三个，依此类推。事实上，训练和实现神经网络所需的主要操作正好适合GPU能够完成的任务。像NVIDIA这样的GPU制造商很早就意识到了这一点，并开始开发用于深度学习的GPU。把GPU看作是一张超计算机卡，可以插入到你的PC中。
- en: In 1945, the Electronic Numerical Integrator and Computer (ENIAC) was state-of-the-art.
    ENIAC’s speed was estimated to be around 0.00289 million instructions per second
    (MIPS). In other words, ENIAC could perform just under 3,000 instructions in one
    second. In 1980, a stock 6502 8-bit microprocessor like the ones in most then-popular
    personal computers ran at about 0.43 MIPS, or some 500,000 instructions per second.
    In 2023, the already somewhat outdated Intel i7-4790 CPU in the computer I’m using
    to write this book runs at about 130,000 MIPS, making my PC some 300,000 times
    faster than the 6502 from 1980 and about 45 million times faster than ENIAC.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 1945年，电子数值积分和计算机（ENIAC）是当时最先进的技术。ENIAC的速度估计为每秒约 0.00289 百万指令（MIPS）。换句话说，ENIAC
    每秒可以执行不到 3000 条指令。到1980年，像当时许多流行个人计算机中所用的 6502 8 位微处理器，运行速度约为 0.43 MIPS，或每秒大约
    50 万条指令。到2023年，我用来写这本书的电脑中已有些过时的 Intel i7-4790 CPU 运行速度约为 130,000 MIPS，使我的 PC
    比 1980 年的 6502 快了大约 300,000 倍，比 ENIAC 快了大约 4500 万倍。
- en: 'However, NVIDIA’s A100 GPU, when used for deep learning, is capable of 312
    teraflops (TFLOPS), or 312,000,000 MIPS: 730 million times faster than the 6502
    and an unbelievable 110 *billion* times faster than ENIAC. The increase in computational
    power over the timespan of machine learning boggles the mind. Moreover, training
    a large neural network on an enormous dataset often requires dozens to hundreds
    of such GPUs.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，NVIDIA 的 A100 GPU 在用于深度学习时，能够达到 312 太弗洛普（TFLOPS），即 312,000,000 MIPS：比 6502
    快 7.3 亿倍，比 ENIAC 快令人难以置信的 1100 *亿*倍。机器学习的计算能力在这个时间跨度内的增长令人瞠目结舌。而且，训练一个大型神经网络并处理一个庞大的数据集，通常需要数十到数百个这样的
    GPU。
- en: '*Conclusion: Computers were, until the advent of fast GPUs, too slow to train
    neural networks with the capacity needed to build something like ChatGPT.*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*结论：直到快速 GPU 的出现，计算机在训练具有构建像 ChatGPT 这样的能力的神经网络时，速度仍然太慢。*'
- en: '***Algorithm***'
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***算法***'
- en: 'As you’ll learn in [Chapter 4](ch04.xhtml), we construct neural networks from
    basic units that perform a simple task: collect input values, multiply each by
    a weight value, sum, add a bias value, and pass the result to an activation function
    to create an output value. In other words, many input numbers become one output
    number. The collective behavior emerging from thousands to millions of such units
    leading to billions of weight values lets deep learning systems do what they do.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你将在 [第4章](ch04.xhtml) 中学到的那样，我们是通过基本单元来构建神经网络，这些单元执行一个简单的任务：收集输入值，将每个值与权重值相乘，求和，加上偏置值，并将结果传递给激活函数生成输出值。换句话说，许多输入数字变成一个输出数字。成千上万到百万个这样的单元的集体行为，导致数十亿的权重值，使深度学习系统能够完成它们的任务。
- en: 'The structure of a neural network is one thing; conditioning the neural network
    to the desired task is another. Think of the network’s structure, known as its
    [*architecture*](glossary.xhtml#glo3), as anatomy. In anatomy, we’re interested
    in what constitutes the body: this is the heart, that’s the liver, and so on.
    Training a network is more like physiology: how does one part work with another?
    The anatomy (architecture) was there, but the physiology (training process) was
    incompletely understood. That changed over the decades, courtesy of key algorithmic
    innovations: backpropagation, network initialization, activation functions, dropout
    and normalization, and advanced gradient descent algorithms. It’s not essential
    to understand the terms in detail, only to know that improvements in what these
    terms represent—along with the already mentioned improvements in processing speed,
    combined with improved datasets (discussion coming up)—were primary enablers of
    the deep learning revolution.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的结构是一回事；将神经网络调整到所需任务是另一回事。可以将网络的结构，称为其 [*架构*](glossary.xhtml#glo3)，比作解剖学。在解剖学中，我们关心的是构成身体的各个部分：这是心脏，那是肝脏，等等。训练网络更像是生理学：如何让一个部分与另一个部分协同工作？解剖学（架构）存在，但生理学（训练过程）并未完全被理解。几十年来，这一切发生了变化，得益于关键的算法创新：反向传播、网络初始化、激活函数、丢弃法和归一化、以及先进的梯度下降算法。理解这些术语的详细含义并不至关重要，重要的是要知道，这些术语所代表的改进——以及前面提到的处理速度提升，结合改进的数据集（接下来会讨论）——是深度学习革命的主要推动力。
- en: While it was long known that the right weight and bias values would adapt a
    network to the desired task, what was missing for decades was an efficient way
    to *find* those values. The 1980s’ introduction of the backpropagation algorithm,
    combined with stochastic gradient descent, began to change this.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管长期以来人们知道，合适的权重和偏置值能使网络适应所需的任务，但缺乏的是一种高效的方法来*找到*这些值。1980年代引入的反向传播算法，结合随机梯度下降，开始改变这一状况。
- en: Training iteratively locates the final set of weight and bias values according
    to the model’s errors on the training data. Iterative processes repeat from an
    initial state, some initial set of weights and biases. However, what should those
    initial weights and biases be? For a long time, it was assumed that the initial
    weights and biases didn’t matter much; just select small numbers at random over
    some range. This approach often worked, but many times it didn’t, causing the
    network not to learn well, if at all. A more principled approach to initializing
    networks was required.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程通过迭代找到最终的权重和偏置值，这些值是根据模型在训练数据上的误差来调整的。迭代过程从初始状态开始，使用一组初始的权重和偏置。然而，这些初始的权重和偏置应该是什么呢？长期以来，人们认为初始的权重和偏置并不重要；只需在某个范围内随机选择一些小数值。这种方法通常有效，但也有很多时候不起作用，导致网络无法很好地学习，甚至根本不学习。因此，需要一种更有原则的网络初始化方法。
- en: Modern networks are still initialized randomly, but the random values depend
    on the network’s architecture and the type of activation function used. Paying
    attention to these details allowed networks to learn better. Initialization matters.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现代网络仍然是随机初始化的，但这些随机值依赖于网络的架构和所使用的激活函数类型。关注这些细节使得网络能够更好地学习。初始化很重要。
- en: 'We arrange neural networks in layers, where the output of one layer becomes
    the input of the next. The activation function assigned to each node in the network
    determines the node’s output value. Historically, the activation function was
    either a sigmoid or a hyperbolic tangent, both of which produce an *S*-shaped
    curve when graphed. These functions are, in most cases, inappropriate, and were
    eventually replaced by a function with a long name that belies its simplicity:
    the [*rectified linear unit (ReLU)*](glossary.xhtml#glo84). A ReLU asks a simple
    question: is the input less than zero? If so, the output is zero; otherwise, the
    output is the input value. Not only are ReLU activation functions better than
    the older functions, but computers can ask and answer that question virtually
    instantaneously. Switching to ReLUs was, therefore, a double win: improved network
    performance and speed.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将神经网络按层次排列，其中一层的输出成为下一层的输入。分配给网络中每个节点的激活函数决定了该节点的输出值。历史上，激活函数通常是sigmoid或双曲正切函数，这两者绘制出来时呈现出*S*形曲线。这些函数在大多数情况下是不合适的，最终被一种名字很长但实际上简单的函数所取代：[*修正线性单元（ReLU）*](glossary.xhtml#glo84)。ReLU提出了一个简单的问题：输入是否小于零？如果是，输出为零；否则，输出为输入值。因此，ReLU
    激活函数比旧的激活函数要好，而且计算机几乎可以瞬间问出并回答这个问题。因此，切换到 ReLU 是双赢：既提高了网络的性能，又加快了速度。
- en: Dropout and batch normalization are advanced training approaches that are somewhat
    difficult to describe at the level we care to know about them. Introduced in 2012,
    *dropout* randomly sets parts of the output of a layer of nodes to zero when training.
    The effect is like training thousands of models simultaneously, each independent
    but also linked. Dropout, when appropriate, has a dramatic impact on network learning.
    As a prominent computer scientist told me at the time, “If we had had dropout
    in the 1980s, this would be a different world now.”
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout 和批量归一化是一些较为高级的训练方法，描述起来有些复杂，尤其是在我们关心的层面上。2012年引入的*dropout*会在训练时随机将一层节点的部分输出设置为零。其效果就像是同时训练成千上万的模型，每个模型既独立又互相关联。适当使用
    dropout 会对网络学习产生显著影响。正如一位著名计算机科学家当时对我说的：“如果我们在1980年代就有 dropout，今天的世界可能会完全不同。”
- en: '*Batch normalization* adjusts the data moving between layers as it flows through
    the network. Inputs appear on one side of the network and flow through layers
    to get to the output. Schematically, this is usually presented as a left-to-right
    motion. Normalization is inserted between the layers to change the values to keep
    them within a meaningful range. Batch normalization was the first learnable normalization
    technique, meaning it learned what it should do as the network learned. An entire
    suite of normalization approaches evolved from batch normalization.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*批量归一化*调整数据在网络层之间流动时的表现。输入出现在网络的一侧，并通过各个层流动，直到输出。在示意图中，这通常呈现为从左到右的运动。归一化被插入层之间，以便调整数值，使其保持在有意义的范围内。批量归一化是首个可学习的归一化技术，意味着它在网络学习的过程中，学习如何处理数据。整个归一化方法系列都由批量归一化发展而来。'
- en: The last critical algorithmic innovation enabling the deep learning revolution
    involves gradient descent, which works with backpropagation to facilitate learning
    the weights and biases. The idea behind gradient descent is far older than machine
    learning, but the versions developed in the last decade or so have contributed
    much to deep learning’s success. We’ll learn more about this subject in [Chapter
    4](ch04.xhtml).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习革命的最后一项关键算法创新是梯度下降法，它与反向传播一起，帮助学习权重和偏差。梯度下降的思想早于机器学习的出现，但近年来所开发的版本对深度学习的成功做出了重要贡献。我们将在[第4章](ch04.xhtml)中进一步了解这一主题。
- en: '*Conclusion: The first approaches to training neural networks were primitive
    and unable to take advantage of their true potential. Algorithmic innovations
    changed that.*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*结论：最初的神经网络训练方法是原始的，无法发挥其真正的潜力。算法创新改变了这一点。*'
- en: '***Data***'
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '***数据***'
- en: 'Neural networks require lots of training data. When people ask me how much
    data is necessary to train a particular model for a specific task, my answer is
    always the same: all of it. Models learn from data; the more, the better because
    more data means an improved representation of what the model will encounter when
    used.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络需要大量的训练数据。当人们问我，训练特定任务的模型需要多少数据时，我的回答总是一样的：所有的数据。模型是从数据中学习的；数据越多，效果越好，因为更多的数据意味着模型在使用时能够更好地呈现遇到的实际情况。
- en: Before the World Wide Web, collecting, labeling, and processing datasets of
    the magnitude necessary to train a deep neural network proved difficult. This
    changed in the late 1990s and the early 2000s with the tremendous growth of the
    web and the explosion of data it represented.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在万维网出现之前，收集、标注并处理足够规模的数据集以训练深度神经网络是非常困难的。这一局面在1990年代末到2000年代初随着网络的快速增长以及它所代表的数据爆炸而发生了变化。
- en: For example, Statista ([*https://www.statista.com*](https://www.statista.com))
    claims that in 2022, 500 hours of new video were uploaded to YouTube *every minute*.
    It’s also estimated that approximately 16 million people were using the web in
    December 1995, representing 0.4 percent of the world’s population. By July 2022,
    that number had grown to nearly 5.5 billion, or 69 percent. Social media use,
    e-commerce, and simply moving from place to place while carrying a smartphone
    are enough to generate staggering amounts of data—all of which is captured and
    used for AI. Social media is free because we, and the data we generate, are the
    product.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Statista（[*https://www.statista.com*](https://www.statista.com)）声称，2022年，每分钟都有500小时的新视频上传到YouTube，*这一速度惊人*。还估计，1995年12月，约有1600万人在使用互联网，占全球人口的0.4%。到了2022年7月，这个数字增长到了近55亿人，占全球人口的69%。社交媒体的使用、电商以及携带智能手机四处走动，足以产生惊人的数据量——所有这些数据都被捕捉并用于人工智能。社交媒体之所以免费，是因为我们和我们生成的数据就是产品。
- en: A phrase I often hear in my work is “we used to be data-starved, but now we’re
    drowning in data.” Without large datasets and enough labels to go with them, deep
    learning cannot learn. But, on the other hand, with large datasets, awe-inspiring
    things can happen.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我在工作中常听到一句话：“我们曾经数据匮乏，但现在我们被数据淹没了。”没有足够的庞大数据集和标签，深度学习无法学习。但另一方面，拥有庞大数据集时，令人惊叹的事情会发生。
- en: '*Conclusion: In machine learning, data is everything.*'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*结论：在机器学习中，数据就是一切。*'
- en: '****'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: 'The main takeaways from this chapter are:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要收获包括：
- en: The symbolic AI versus connectionist feud appeared early and led to decades
    of symbolic AI dominance.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 符号人工智能与连接主义的争斗早期就已出现，并导致了几十年符号人工智能的主导地位。
- en: Connectionism suffered for a long time because of speed, algorithm, and data
    issues.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接主义曾因速度、算法和数据问题而长时间遭遇困境。
- en: With the deep learning revolution of 2012, the connectionists have won, for
    now.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着2012年深度学习革命的到来，连接主义者目前已取得胜利。
- en: The direct causes of the deep learning revolution were faster computers, the
    advent of graphics processing units, improved algorithms, and huge datasets.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习革命的直接原因是计算机速度的提升、图形处理单元的出现、算法的改进以及海量数据集的涌现。
- en: With this historical background complete enough for our purposes, let’s return
    to machine learning, starting with the classical algorithms.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们完成足够的历史背景介绍后，让我们回到机器学习，从经典算法开始。
