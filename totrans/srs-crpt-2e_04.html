<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><section epub:type="chapter" role="doc-chapter" aria-labelledby="ch2">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_25" aria-label="25"/>&#13;
<hgroup>&#13;
<h2 class="CHAPTER" id="ch2">&#13;
<span class="CN"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">2</samp></span>&#13;
<span class="CT"><samp class="SANS_Dogma_OT_Bold_B_11">RANDOMNESS</samp></span>&#13;
</h2>&#13;
</hgroup>&#13;
<figure class="opener"><img class="opener" src="../images/opener.jpg" alt="" width="401" height="386"/></figure>&#13;
<p class="TNI1">Randomness is found everywhere in cryptography: in the generation of secret keys, in encryption schemes, and even in the attacks on cryptosystems. Without randomness, cryptography would be impossible because all operations would become predictable and therefore insecure.</p>&#13;
<p class="TX">This chapter introduces the concept of randomness in the context of cryptography and its applications. We discuss pseudorandom number generators and how operating systems can produce reliable randomness, and we conclude with real examples showing how flawed randomness can impact security.</p>&#13;
<section epub:type="division" aria-labelledby="sec1">&#13;
<h3 class="H1" id="sec1"><span id="h1-16"/><samp class="SANS_Futura_Std_Bold_B_11">Random or Nonrandom?</samp></h3>&#13;
<p class="TNI">You’ve probably heard the phrase <i>random bits</i> before, but strictly speaking, there is no such thing as a series of random bits. What <i>is</i> random is the <span role="doc-pagebreak" epub:type="pagebreak" id="pg_26" aria-label="26"/><i>algorithm</i>, or process, that produces a series of random bits; therefore, when we say “random bits,” we actually mean randomly generated bits.</p>&#13;
<p class="TX">What do random bits look like? For example, the 8-bit string 11010110 might look more random than 00000000, although both have the same chance of being generated (namely, 1/256). The value 11010110 looks more random than 00000000 because it has the signs typical of a randomly generated value. That is, 11010110 has no obvious pattern.</p>&#13;
<p class="TX">When we see the string 11010110, our brain registers that it has 3 zeros and 5 ones, just like 55 other 8-bit strings (11111000, 11110100, 11110010, and so on), but only one 8-bit string has 8 zeros. Because the pattern 3-zeros-and-5-ones is more likely to occur than the pattern 8-zeros, we identify 11010110 as random and 00000000 as nonrandom, even if they’re not.</p>&#13;
<p class="TX">This example illustrates two types of errors people often make when identifying randomness:</p>&#13;
<p class="RunInPara"><b>Mistaking nonrandomness for randomness </b>Thinking that an object was randomly generated simply because it <i>looks</i> random</p>&#13;
<p class="RunInPara"><b>Mistaking randomness for nonrandomness </b>Thinking that patterns appearing by chance are there for a reason other than chance</p>&#13;
<p class="TX">The distinction between random-looking and actually random is crucial. Indeed, in crypto, nonrandomness is often synonymous with insecurity.</p>&#13;
<p class="TX">The saying “it happened by chance” reflects the property that from a complex system (in this case, our universe that obeys the laws of physics, deterministic at the macroscopic level and truly random at the subatomic, quantum level) can emerge specific patterns, such as the string 00000000. By the law of large numbers, if many events occur, some won’t look random—such as a series of sequential numbers in a lottery draw. Many pseudosciences and belief systems are in fact cases of mistaking randomness for nonrandomness.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec2">&#13;
<h3 class="H1" id="sec2"><span id="h1-17"/><samp class="SANS_Futura_Std_Bold_B_11">Randomness as a Probability Distribution</samp></h3>&#13;
<p class="TNI">Any randomized process is characterized by a <i>probability distribution</i>, which gives all there is to know about the randomness of the process. A probability distribution, or simply <i>distribution</i>, lists the outcomes of a randomized process where each outcome is assigned a probability.</p>&#13;
<p class="TX">A <i>probability</i> measures the likelihood of an event occurring. It’s expressed as a real number between 0 and 1 where a probability of 0 means impossible and a probability of 1 means certain. For example, when tossing a two-sided coin, each side has a 1/2 (or 0.5) probability of landing face up, and the probability of a coin landing on its edge has a probability close to 0.</p>&#13;
<p class="TX">A probability distribution must include all possible outcomes such that the sum of all probabilities is 1. Specifically, if there are <i>N</i> possible events, there are <i>N</i> probabilities <i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, . . . , <i>p</i><span class="ePub-I-SUB">N</span> with <i>p</i><sub>1</sub> + <i>p</i><sub>2</sub> + . . . + <i>p</i><span class="ePub-I-SUB">N</span> = 1. In the case of the coin toss, the distribution is 1/2 for heads and 1/2 for tails. The sum <span role="doc-pagebreak" epub:type="pagebreak" id="pg_27" aria-label="27"/>of both probabilities is equal to 1/2 + 1/2 = 1, because the coin will fall on one of its two faces.</p>&#13;
<p class="TX">A <i>uniform distribution</i> occurs when all probabilities in the distribution are equal, meaning that all outcomes are equally likely to occur. If there are <i>N</i> events, then each event has probability 1/<i>N</i>. For example, if a 128-bit key is picked uniformly at random—that is, according to a uniform distribution—then each of the 2<sup>128</sup> possible keys should have a probability of 1/2<sup>128</sup>.</p>&#13;
<p class="TX">In contrast, when a distribution is <i>nonuniform</i>, probabilities aren’t all equal. A coin toss with a nonuniform distribution is said to be biased and may yield heads with probability 1/4 and tails with probability 3/4, for example.</p>&#13;
<blockquote>&#13;
<p class="Note"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_15">NOTE</samp></span></p>&#13;
</blockquote>&#13;
<p class="NOTE-TXT"><i>It’s possible to cheat with a loaded die, preventing the probabilities of each of the six faces to be 1/6; however, one can’t bias a coin. Coin tosses can be biased only if “the coin is allowed to bounce or be spun rather than simply flipped in the air,” as described in the article “You Can Load a Die but You Can’t Bias a Coin” (available at</i> <span class="note_LinkURL_Italic"><a href="https://www.stat.berkeley.edu/~nolan/Papers/dice.pdf">https://<wbr/>www<wbr/>.stat<wbr/>.berkeley<wbr/>.edu<wbr/>/~nolan<wbr/>/Papers<wbr/>/dice<wbr/>.pdf</a></span>).</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec3">&#13;
<h3 class="H1" id="sec3"><span id="h1-18"/><samp class="SANS_Futura_Std_Bold_B_11">Entropy: A Measure of Uncertainty</samp></h3>&#13;
<p class="TNI"><i>Entropy</i> is the measure of uncertainty, or disorder, in a system. The higher the entropy, the less certainty found in the result of a randomized process.</p>&#13;
<p class="TX">We can compute the entropy of a probability distribution. If your distribution consists of probabilities <i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, . . . , <i>p</i><span class="ePub-I-SUB">N</span>, then its entropy is the negative sum of all probabilities multiplied by their logarithm, as shown in this expression:</p>&#13;
<figure class="DIS-IMG"><img class="img1" src="../images/pg27-1.jpg" alt="" width="1388" height="52"/></figure>&#13;
<p class="TX">Here the function <i>log</i> is the <i>binary logarithm</i>, or logarithm in base two. Unlike the natural logarithm, the binary logarithm expresses the information in bits and yields integer values when probabilities are powers of two. For example, log(1/2) = –1, log(1/4) = –2, and more generally log(1/2<i><sup>n</sup></i>) = –<i>n</i>. (We actually take the <i>negative sum</i> to end up with a positive number.) Random 128-bit keys produced using a uniform distribution therefore have the following entropy:</p>&#13;
<figure class="DIS-IMG"><img class="img1" src="../images/pg27-2.jpg" alt="" width="1388" height="65"/></figure>&#13;
<p class="TX">If you replace 128 with any integer <i>n</i>, the entropy of a uniformly distributed <i>n</i>-bit string will be <i>n</i> bits.</p>&#13;
<p class="TX">Entropy is maximized when the distribution is uniform because a uniform distribution maximizes uncertainty: no outcome is more likely than the others. Therefore, <i>n</i>-bit values can’t have more than <i>n</i> bits of entropy.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_28" aria-label="28"/>By the same token, when the distribution is not uniform, entropy is lower. Consider the coin toss example. The entropy of a fair toss is the following:</p>&#13;
<figure class="DIS-IMG"><img class="img1" src="../images/pg28-1.jpg" alt="" width="1430" height="50"/></figure>&#13;
<p class="TX">What if one side of the coin has a higher probability of landing face up than the other? Say heads has a probability of 1/4 and tails 3/4. (Remember that the sum of all probabilities should be 1.)</p>&#13;
<p class="TX">The entropy of such a biased toss is this:</p>&#13;
<figure class="DIS-IMG"><img class="img1" src="../images/pg28-2.jpg" alt="" width="1430" height="50"/></figure>&#13;
<p class="TX">The fact that 0.81 is less than the 1-bit entropy of a fair toss tells us that the more biased the coin, the less uniform the distribution and the lower the entropy. Taking this example further, if heads has a probability of 1/10, the entropy is 0.469; if the probability drops to 1/100, the entropy drops to 0.081.</p>&#13;
<blockquote>&#13;
<p class="Note"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_15">NOTE</samp></span></p>&#13;
</blockquote>&#13;
<p class="NOTE-TXT"><i>Entropy can also be viewed as a measure of information. For example, the result of a fair coin toss gives you exactly 1 bit of information—heads or tails—and you’re unable to predict the result of the toss in advance. In the case of the unfair coin toss, you know in advance that tails is more probable, so you can predict the outcome. The result of the unfair coin toss gives you the information needed to predict the result with certainty.</i></p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec4">&#13;
<h3 class="H1" id="sec4"><span id="h1-19"/><samp class="SANS_Futura_Std_Bold_B_11">Random and Pseudorandom Number Generators</samp></h3>&#13;
<p class="TNI">Cryptosystems need randomness to be secure and therefore need a component from which to get their randomness. The job of this component is to return random bits when requested to do so. To perform this randomness generation, you’ll need two things:</p>&#13;
<ul class="ul">&#13;
<li class="BL">A source of entropy, provided by random number generators.</li>&#13;
<li class="BL">A cryptographic algorithm to produce high-quality random bits from the source of entropy. This is found in pseudorandom number generators.</li>&#13;
</ul>&#13;
<p class="TX">Using both random and pseudorandom number generators is the key to making cryptography practical and secure. Let’s briefly look at how random number generators work before exploring pseudorandom number generators in depth.</p>&#13;
<p class="TX">Randomness comes from the environment, which is analog, chaotic, uncertain, and hence unpredictable. Randomness can’t be generated by computer-based algorithms alone. In cryptography, randomness usually comes from <i>random number generators (RNGs)</i>, which are software or hardware components that leverage entropy in the analog world to produce unpredictable bits in a digital system. For example, an RNG might directly <span role="doc-pagebreak" epub:type="pagebreak" id="pg_29" aria-label="29"/>sample bits from measurements of temperature, acoustic noise, air turbulence, or electrical static. Unfortunately, such analog entropy sources aren’t always available, and their entropy is often difficult to estimate.</p>&#13;
<p class="TX">RNGs can also harvest the entropy in a running operating system by drawing from attached sensors, I/O devices, network or disk activity, system logs, running processes, and user activities such as key presses and mouse movement. Such system- and human-generated activities can be a good source of entropy, but they can be fragile and manipulated by an attacker. Also, they’re slow to yield random bits.</p>&#13;
<blockquote>&#13;
<p class="Note"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_15">NOTE</samp></span></p>&#13;
</blockquote>&#13;
<p class="NOTE-TXT"><span class="note_Italic">Quantum random number generators (QRNGs)</span> <i>are a type of RNG that rely on the randomness arising from quantum mechanical phenomena, such as radioactive decay, photon polarization, or thermal noise. These phenomena, not being characterized by equations that determine the future state from the current state, are random in the absolute sense. In practice, however, the raw bits extracted from a QRNG may be biased and tend to be slow to produce. Like the previously cited entropy sources, they require postprocessing to generate reliable bits at high speed.</i></p>&#13;
<p class="TX"><i>Pseudorandom number generators (PRNGs)</i> address the challenge in generating randomness by reliably producing many artificial random bits from a few true random bits. For example, an RNG that translates mouse movements to random bits would stop working if you stop moving the mouse, whereas a PRNG always returns pseudorandom bits when requested to do so.</p>&#13;
<p class="TX">PRNGs rely on RNGs but behave differently: RNGs produce true random bits relatively slowly from analog sources, in a nondeterministic way, and with no guarantee of uniform distribution or of high entropy per bit. In contrast, PRNGs produce random-looking bits quickly from digital sources, in a deterministic way, uniformly distributed, and with an entropy guaranteed to be high enough for cryptographic applications. Essentially, PRNGs transform a few unreliable random bits into a long stream of reliable pseudorandom bits suitable for crypto applications, as <a href="chapter2.xhtml#fig2-1">Figure 2-1</a> shows.</p>&#13;
<figure class="IMG"><img id="fig2-1" class="img1" src="../images/fig2-1.jpg" alt="" width="1162" height="79"/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 2-1: RNGs produce few unreliable bits from analog sources, whereas PRNGs expand those bits to a long stream of reliable bits.</samp></p></figcaption>&#13;
</figure>&#13;
<section epub:type="division" aria-labelledby="sec5">&#13;
<h4 class="H2" id="sec5"><span id="h2-22"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">How PRNGs Work</samp></h4>&#13;
<p class="TNI">A PRNG receives random bits from an RNG at regular intervals and uses them to update the contents of a large memory buffer, called the <i>entropy pool</i>. The entropy pool is the PRNG’s source of entropy, just like the physical environment is to an RNG. When the PRNG updates the entropy pool, it mixes the pool’s bits together to help remove any statistical bias.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_30" aria-label="30"/>To generate pseudorandom bits, the PRNG runs a deterministic random bit generator (DRBG) algorithm that expands some bits from the entropy pool into a much longer sequence. As its name suggests, a DRBG is deterministic, not randomized: given one input, you will always get the same output. The PRNG ensures that its DRBG never receives the same input twice so it can generate unique pseudorandom sequences.</p>&#13;
<p class="TX">In the course of its work, the PRNG performs three operations:</p>&#13;
<p class="RunInPara"><b><i>init()</i> </b>Initializes the entropy pool and the internal state of the PRNG</p>&#13;
<p class="RunInPara"><b><i>refresh(R)</i> </b>Updates the entropy pool using some data, <i>R</i>, usually sourced from an RNG</p>&#13;
<p class="RunInPara"><b><i>next(N)</i> </b>Returns <i>N</i> pseudorandom bits and updates the entropy pool</p>&#13;
<p class="TX">The <i>init</i> operation resets the PRNG to a fresh state, reinitializes the entropy pool to some default value, and initializes any variables or memory buffers used by the PRNG to carry out the <i>refresh</i> and <i>next</i> operations.</p>&#13;
<p class="TX">The <i>refresh</i> operation is often called <i>reseeding</i>, and its argument <i>R</i> is called a <i>seed</i>. When no RNG is available, seeds may be unique values hardcoded in a system. The <i>refresh</i> operation is typically called by the operating system, whereas <i>next</i> is typically called or requested by applications. The <i>next</i> operation runs the DRBG and modifies the entropy pool to ensure that the next call will yield different pseudorandom bits.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec6">&#13;
<h4 class="H2" id="sec6"><span id="h2-23"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Security Concerns</samp></h4>&#13;
<p class="TNI">Let’s talk briefly about how PRNGs address high-level security concerns. Specifically, PRNGs should guarantee <i>backtracking resistance</i> and <i>prediction resistance</i>. Backtracking resistance (also called <i>forward secrecy</i>) means that previously generated bits are impossible to recover, whereas prediction resistance (<i>backward secrecy</i>) means that future bits should be impossible to predict.</p>&#13;
<p class="TX">To achieve backtracking resistance, the PRNG should ensure that the transformations performed when updating the state through the <i>refresh</i> and <i>next</i> operations are irreversible. This way, if an attacker compromises the system and obtains the entropy pool’s value, they can’t determine the previous values of the pool or the previously generated bits. To achieve prediction resistance, the PRNG should call <i>refresh</i> regularly with <i>R</i> values that are unknown to an attacker and are difficult to guess, thus preventing an attacker from determining future values of the entropy pool, even if the whole pool is compromised. (If the list of <i>R</i> values were known, you’d need to know the order in which <i>refresh</i> and <i>next</i> calls were made to reconstruct the pool.)</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec7">&#13;
<h4 class="H2" id="sec7"><span id="h2-24"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">The PRNG Fortuna</samp></h4>&#13;
<p class="TNI"><i>Fortuna</i> is a PRNG construction used in Windows originally designed in 2003 by Niels Ferguson and Bruce Schneier. Fortuna superseded <i>Yarrow</i>, a 1998 design by John Kelsey and Bruce Schneier that was for a long time used in the macOS and iOS operating systems and has been replaced by <span role="doc-pagebreak" epub:type="pagebreak" id="pg_31" aria-label="31"/>Fortuna. I won’t provide the Fortuna specification here or show you how to implement it, but I will try to explain how it works. You’ll find a complete description of Fortuna in <a href="chapter9.xhtml">Chapter 9</a> of <i>Cryptography Engineering</i> by Ferguson, Schneier, and Kohno (Wiley, 2010).</p>&#13;
<p class="TX">Fortuna’s internal memory includes the following:</p>&#13;
<ul class="ul">&#13;
<li class="BL">Thirty-two entropy pools, <i>P</i><sub>1</sub>, <i>P</i><sub>2</sub>, . . . , <i>P</i><sub>32</sub>, such that <i>P</i><span class="ePub-I-SUB">i</span> is used every 2<i><sup>i</sup></i> reseeds.</li>&#13;
<li class="BL">A key, <i>K</i>, and a counter, <i>C</i> (both 16 bytes). These form the internal state of Fortuna’s DRBG.</li>&#13;
</ul>&#13;
<p class="TX">In simplest terms, Fortuna works like this:</p>&#13;
<ul class="ul">&#13;
<li class="BL"><i>init</i>() sets <i>K</i> and <i>C</i> to zero and empties the 32 entropy pools <i>P</i><span class="ePub-I-SUB">i</span>, where <i>i</i> = 1 . . . 32.</li>&#13;
<li class="BL"><i>refresh</i>(<i>R</i>) appends the data, <i>R</i>, to one of the entropy pools. The system chooses the RNGs used to produce <i>R</i> values, and it should call <i>refresh</i> regularly.</li>&#13;
<li class="BL"><i>next</i>(<i>N</i>) updates <i>K</i> using data from one or more entropy pools, where the choice of the entropy pools depends mainly on how many updates of <i>K</i> have already been done. The <i>N</i> bits requested are then produced by encrypting <i>C</i> using <i>K</i> as a key. If encrypting <i>C</i> is not enough, Fortuna encrypts <i>C</i> + 1, then <i>C</i> + 2, and so on, to get enough bits.</li>&#13;
</ul>&#13;
<p class="TX">Although Fortuna’s operations look fairly simple, implementing them correctly is hard. For one, you need to get all the details of the algorithm right—how entropy pools are chosen, the type of cipher to be used in <i>next</i>, how to behave when no entropy is received, and so on. Although the specs define most of the details, they don’t include a comprehensive test suite to check that an implementation is correct, which makes it difficult to ensure that your implementation of Fortuna will behave as expected.</p>&#13;
<p class="TX">Even if Fortuna is correctly implemented, security failures may occur for reasons other than the use of an incorrect algorithm. For example, Fortuna might not notice if the RNGs fail to produce enough random bits, and as a result Fortuna will produce lower-quality pseudorandom bits, or it may stop delivering pseudorandom bits altogether.</p>&#13;
<p class="TX">Another risk inherent in Fortuna implementations lies in the possibility of exposing associated <i>seed files</i> to attackers. The data in Fortuna seed files is used to feed entropy to Fortuna through <i>refresh</i> calls when an RNG is not immediately available—for example, immediately after a system reboot and before the system’s RNGs have recorded any unpredictable events. However, if an identical seed file is used twice, Fortuna will produce the same bit sequence twice. Seed files should therefore be erased after use to ensure they aren’t reused.</p>&#13;
<p class="TX">Finally, if two Fortuna instances are in the same state because they’re sharing a seed file (meaning the same data in the entropy pools, including <i>C</i> and <i>K</i>), then the <i>next</i> operation will return the same bits in both instances.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec8">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_32" aria-label="32"/>&#13;
<h4 class="H2" id="sec8"><span id="h2-25"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Cryptographic vs. Noncryptographic PRNGs</samp></h4>&#13;
<p class="TNI">There are cryptographic and noncryptographic PRNGs. Noncrypto PRNGs are designed to produce uniform distributions for applications such as scientific simulations or video games. However, you should never use noncrypto PRNGs in crypto applications, because they’re insecure; they’re concerned only with the quality of the bits’ probability distribution and not with their predictability. Crypto PRNGs, on the other hand, are unpredictable because they’re also concerned with the strength of the underlying <i>operations</i> used to deliver well-distributed bits.</p>&#13;
<p class="TX">Unfortunately, most PRNGs exposed by programming languages—such as libc’s <samp class="SANS_TheSansMonoCd_W5Regular_11">rand</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">drand48</samp>, PHP’s <samp class="SANS_TheSansMonoCd_W5Regular_11">rand</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">mt_rand</samp>, Python’s <samp class="SANS_TheSansMonoCd_W5Regular_11">random</samp> module, and Java’s <samp class="SANS_TheSansMonoCd_W5Regular_11">java.util.Random</samp> class—are noncryptographic. Defaulting to a noncrypto PRNG is a recipe for disaster because it often ends up being used in crypto applications, so be sure to use only crypto PRNGs when generating randomness related to cryptographic or security applications.</p>&#13;
<section epub:type="division" aria-labelledby="sec9">&#13;
<h5 class="H3" id="sec9"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">A Popular Noncrypto PRNG: Mersenne Twister</samp></h5>&#13;
<p class="TNI">The <i>Mersenne Twister (MT)</i> algorithm is a noncryptographic PRNG used (at the time of this writing) in PHP, Python, R, Ruby, and many other systems. It’s even been used (unfortunately) in blockchain wallet key generators. MT generates uniformly distributed random bits without statistical bias, but it’s predictable: given a few bits produced by MT, one can guess which bits will follow.</p>&#13;
<p class="TX">Let’s look under the hood to see what makes the Mersenne Twister insecure. The MT algorithm is much simpler than that of crypto PRNGs: its internal state is an array, <i>S</i>, consisting of 624 32-bit words. This array is initially set to <i>S</i><sub>1</sub>, <i>S</i><sub>2</sub>, . . . , <i>S</i><sub>624</sub> and evolves to <i>S</i><sub>2</sub>, . . . , <i>S</i><sub>625</sub>, then <i>S</i><sub>3</sub>, . . . , <i>S</i><sub>626</sub>, and so on, according to this equation:</p>&#13;
<figure class="DIS-IMG"><img class="img1" src="../images/pg32-1.jpg" alt="" width="1383" height="52"/></figure>&#13;
<p class="TX">Here, <span class="symbol">⊕</span> denotes the bitwise XOR (<samp class="SANS_TheSansMonoCd_W5Regular_11">^</samp> in the C programming language), <span class="symbol">∧</span> denotes the bitwise AND (<samp class="SANS_TheSansMonoCd_W5Regular_11">&amp;</samp> in C), <span class="symbol">∨</span> denotes the bitwise OR (<samp class="SANS_TheSansMonoCd_W5Regular_11">|</samp> in C), and <b>A</b> is a function that transforms some 32-bit word, <i>x</i>, to (<i>x</i> &gt;&gt; 1) if <i>x</i>’s most significant bit is 0, or to (<i>x</i> &gt;&gt; 1) <span class="symbol">⊕</span> 0x9908b0df otherwise.</p>&#13;
<p class="TX">In this equation, bits of <i>S</i> interact with each other only through XORs. The operators <span class="symbol">∧</span> and <span class="symbol">∨</span> never combine 2 bits of <i>S</i> together but instead combine bits of <i>S</i> with bits from the constants 0x80000000 and 0x7fffffff. This way, any bit from <i>S</i><sub>625</sub> can be expressed as an XOR of bits from <i>S</i><sub>398</sub>, <i>S</i><sub>1</sub>, and <i>S</i><sub>2</sub>, and any bit from any future state can be expressed as an XOR combination of bits from the initial state <i>S</i><sub>1</sub>, . . . , <i>S</i><sub>624</sub>. (When you express, say, <i>S</i><sub>228 + 624</sub> = <i>S</i><sub>852</sub> as a function of <i>S</i><sub>625</sub>, <i>S</i><sub>228</sub>, and <i>S</i><sub>229</sub>, you can in turn replace <i>S</i><sub>625</sub> by its expression in terms of <i>S</i><sub>398</sub>, <i>S</i><sub>1</sub>, and <i>S</i><sub>2</sub>.)</p>&#13;
<p class="TX">Because there are exactly 624 × 32 = 19,968 bits in the initial state (or 624 32-bit words), any output bit can be expressed as an equation with at most 19,969 terms (19,968 bits plus one constant bit). That’s about 2.5KB of <span role="doc-pagebreak" epub:type="pagebreak" id="pg_33" aria-label="33"/>data. The converse is also true: bits from the initial state can be expressed as an XOR of output bits.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec10">&#13;
<h5 class="H3" id="sec10"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">Linearity Insecurity</samp></h5>&#13;
<p class="TNI">We call an XOR combination of bits a <i>linear combination</i>. For example, if <i>X</i>, <i>Y</i>, and <i>Z</i> are bits, then the expression <i>X</i> <span class="symbol">⊕</span> <i>Y</i> <span class="symbol">⊕</span> <i>Z</i> is a linear combination, whereas (<i>X</i> <span class="symbol">∧</span> <i>Y</i>) <span class="symbol">⊕</span> <i>Z</i> is not because there’s an AND (<span class="symbol">∧</span>). If you flip a bit of <i>X</i> in <i>X</i> <span class="symbol">⊕</span> <i>Y</i> <span class="symbol">⊕</span> <i>Z</i>, then the result changes as well, regardless of <i>Y</i>’s and <i>Z</i>’s values. In contrast, if you flip a bit of <i>X</i> in (<i>X</i> <span class="symbol">∧</span> <i>Y</i>) <span class="symbol">⊕</span> <i>Z</i>, the result changes only if <i>Y</i>’s bit at the same position is 1. The upshot is that linear combinations are predictable because you don’t need to know the value of the bits in order to predict how a change in their value will affect the result.</p>&#13;
<p class="TX">For comparison, if the MT algorithm were cryptographically strong, its equations would be <i>nonlinear</i> and would involve not only single bits but also AND combinations (<i>products</i>) of bits, such as <i>S</i><sub>1</sub><i>S</i><sub>15</sub><i>S</i><sub>182</sub> or <i>S</i><sub>17</sub><i>S</i><sub>256</sub><i>S</i><sub>257</sub><i>S</i><sub>354</sub><i>S</i><sub>498</sub><i>S</i><sub>601</sub>. Although linear combinations of those bits include at most 624 variables, nonlinear combinations allow for up to 2<sup>624</sup> variables. It would be impossible to solve, let alone write down, the whole of these equations. (Note that 2<sup>305</sup>, a much smaller number, is the estimated information capacity of the observable universe.)</p>&#13;
<p class="TX">The key here is that linear transformations lead to short equations (comparable in size to the number of variables), which are easy to solve, whereas nonlinear transformations give rise to equations of exponential size, which are practically unsolvable. The game of cryptographers is thus to design PRNG algorithms that emulate such complex nonlinear transformations using only a small number of simple operations.</p>&#13;
<blockquote>&#13;
<p class="Note"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_15">NOTE</samp></span></p>&#13;
</blockquote>&#13;
<p class="NOTE-TXT"><i>Linearity is just one of many security criteria. Although necessary, nonlinearity alone does not make a PRNG cryptographically secure.</i></p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec11">&#13;
<h4 class="H2" id="sec11"><span id="h2-26"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">The Uselessness of Statistical Tests</samp></h4>&#13;
<p class="TNI">Statistical test suites like TestU01, Diehard, or the National Institute of Standards and Technology (NIST) test suite are one way to test the quality of pseudorandom bits. These tests take a sample of pseudorandom bits produced by a PRNG (say, 1MB’s worth), compute some statistics on the distribution of certain patterns in the bits, and compare the results with the typical results obtained for a uniform distribution. For example, some tests count the number of 1 bits versus the number of 0 bits, or the distribution of 8-bit patterns. But statistical tests are largely irrelevant to cryptographic security, and it’s possible to design a cryptographically weak PRNG that fools any statistical test.</p>&#13;
<p class="TX">When you run statistical tests on randomly generated data, you will usually see a bunch of statistical indicators as a result. These are typically <i>p</i>-values, a common statistical indicator. These results aren’t always easy to interpret because they’re rarely as simple as passed or failed. If your first results seem abnormal, don’t worry: they may be the result of some <span role="doc-pagebreak" epub:type="pagebreak" id="pg_34" aria-label="34"/>accidental deviation, or you may be testing too few samples. To ensure that the results you see are normal, compare them with those obtained for some reliable sample of identical size—for example, one generated with the OpenSSL toolkit using the following command:</p>&#13;
<pre><code>$ <b>openssl rand <var>&lt;number of bytes&gt;</var></b><b> -out <var>&lt;output file&gt;</var></b></code></pre>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec12">&#13;
<h3 class="H1" id="sec12"><span id="h1-20"/><samp class="SANS_Futura_Std_Bold_B_11">Real-World PRNGs</samp></h3>&#13;
<p class="TNI">Let’s turn our attention to implementing PRNGs in the real world. You’ll find crypto PRNGs in the operating systems (OSs) of most platforms, from desktops and laptops to embedded systems such as routers and set-top boxes, as well as virtual machines, mobile phones, and so on. Most of these PRNGs are software based, but those that are pure hardware are used by applications running on the OS and sometimes by other PRNGs running on top of cryptographic libraries or applications.</p>&#13;
<p class="TX">Next, we’ll look at the most widely deployed PRNGs: for Linux, Android, and many other Unix-based systems; in Windows; and in recent Intel microprocessors, whose PRNG is hardware based.</p>&#13;
<section epub:type="division" aria-labelledby="sec13">&#13;
<h4 class="H2" id="sec13"><span id="h2-27"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Random Bits in Linux</samp></h4>&#13;
<p class="TNI">The device file <i>/dev/urandom</i> is the userland interface to the crypto PRNG in operating systems based on the Linux kernel. You’ll typically use it to generate reliable random bits. Because it’s a device file, you request random bits from <i>/dev/urandom</i> by reading it as a file. For example, the following command uses <i>/dev/urandom</i> to write 10MB of random bits to a file:</p>&#13;
<pre><code>$ <b>dd if=/dev/urandom of=</b><b><var>&lt;output file&gt;</var></b><b> bs=1M count=10</b></code></pre>&#13;
<section epub:type="division" aria-labelledby="sec14">&#13;
<h5 class="H3" id="sec14"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">The Wrong Way to Use /dev/urandom</samp></h5>&#13;
<p class="TNI">You could write a naive and insecure C program like the one shown in <a href="chapter2.xhtml#Lis2-1">Listing 2-1</a> to read random bits and hope for the best, but that would be a bad idea.</p>&#13;
<span id="Lis2-1"/><pre><code>int random_bytes_insecure(void *buf, size_t len)&#13;
{&#13;
    int fd = open("/dev/urandom", O_RDONLY);&#13;
    read(fd, buf, len);&#13;
    close(fd);&#13;
    return 0;&#13;
}</code></pre>&#13;
<p class="ListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 2-1: An insecure use of</samp> <samp class="SANS_Futura_Std_Book_11">/dev/urandom</samp></p>&#13;
<p class="TX">This code is insecure; it doesn’t even check the return values of <samp class="SANS_TheSansMonoCd_W5Regular_11">open()</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">read()</samp>, which means your expected random buffer could end up filled with zeros or left unchanged.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec15">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_35" aria-label="35"/>&#13;
<h5 class="H3" id="sec15"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">A Safer Way to Use /dev/urandom</samp></h5>&#13;
<p class="TNI"><a href="chapter2.xhtml#Lis2-2">Listing 2-2</a>, copied from the LibreSSL library, shows a safer way to use <i>/dev/urandom</i>.</p>&#13;
<span id="Lis2-2"/><pre><code>int random_bytes_safer(void *buf, size_t len)&#13;
{&#13;
    struct stat st;&#13;
    size_t i;&#13;
    int fd, cnt, flags;&#13;
    int save_errno = errno;&#13;
&#13;
start:&#13;
    flags = O_RDONLY;&#13;
#ifdef O_NOFOLLOW&#13;
    flags |= O_NOFOLLOW;&#13;
#endif&#13;
#ifdef O_CLOEXEC&#13;
    flags |= O_CLOEXEC;&#13;
#endif&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> fd = open("/dev/urandom", flags, 0);&#13;
    if (fd == -1) {&#13;
        if (errno == EINTR)&#13;
            goto start;&#13;
        goto nodevrandom;&#13;
    }&#13;
#ifndef O_CLOEXEC&#13;
    fcntl(fd, F_SETFD, fcntl(fd, F_GETFD) | FD_CLOEXEC);&#13;
#endif&#13;
&#13;
    /* Lightly verify that the device node looks sane. */&#13;
    if (fstat(fd, &amp;st) == -1 || !S_ISCHR(st.st_mode)) {&#13;
        close(fd);&#13;
        goto nodevrandom;&#13;
    }&#13;
    if (ioctl(fd, RNDGETENTCNT, &amp;cnt) == -1) {&#13;
        close(fd);&#13;
        goto nodevrandom;&#13;
    }&#13;
    for (i = 0; i &lt; len;) {&#13;
        size_t wanted = len - i;&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> ssize_t ret = read(fd, (char *)buf + i, wanted);&#13;
&#13;
        if (ret == -1) {&#13;
            if (errno == EAGAIN || errno == EINTR)&#13;
                continue;&#13;
            close(fd);&#13;
            goto nodevrandom;&#13;
        }&#13;
        i += ret;&#13;
    }&#13;
    close(fd);&#13;
    if (gotdata(buf, len) == 0) {&#13;
        errno = save_errno;&#13;
        return 0; /* Satisfied */&#13;
    }&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_36" aria-label="36"/>nodevrandom:&#13;
    errno = EIO;&#13;
    return -1;&#13;
}</code></pre>&#13;
<p class="ListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 2-2: A safe use of</samp> <samp class="SANS_Futura_Std_Book_11">/dev/urandom</samp></p>&#13;
<p class="TX">Unlike <a href="chapter2.xhtml#Lis2-1">Listing 2-1</a>, <a href="chapter2.xhtml#Lis2-2">Listing 2-2</a> makes several sanity checks. Compare, for example, the calls to <samp class="SANS_TheSansMonoCd_W5Regular_11">open()</samp> <span class="CodeAnnotation" aria-label="annotation1">❶</span> and to <samp class="SANS_TheSansMonoCd_W5Regular_11">read()</samp> <span class="CodeAnnotation" aria-label="annotation2">❷</span> with those in <a href="chapter2.xhtml#Lis2-1">Listing 2-1</a>: the safer code checks the return values of those functions and upon failure closes the file descriptor and returns –1.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec16">&#13;
<h5 class="H3" id="sec16"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">Differences Between /dev/urandom and /dev/random, Before 2022</samp></h5>&#13;
<p class="TNI">The Linux PRNG, defined in <i>drivers/char/random.c</i> in the Linux kernel, underwent major changes in 2022 (since kernel version 5.17).</p>&#13;
<p class="TX">First, the general structure of the PRNG, which is similar in the old and new versions, is based on a collection of entropy from various sources (including system activity, such as keyboard, mouse, and disk accesses), as well as from an entropy pool that can be seen as a large array, which is filled by hashing data collected from the entropy sources. Next, a DRBG is responsible for producing the pseudorandom data streams returned when <i>/dev/random</i> or <i>/dev/urandom</i> is read or when the <samp class="SANS_TheSansMonoCd_W5Regular_11">getrandom()</samp> system call is made.</p>&#13;
<p class="TX">Historically, prior to kernel version 5.17, the Linux PRNG behaved as follows: unlike <i>/dev/urandom</i>, the <i>/dev/random</i> interface was <i>blocking</i>; if the kernel estimated that the PRNG had an insufficient level of entropy, then <i>/dev/random</i> would stop returning bytes (“block”) when it was read, until a sufficient level of entropy was estimated by the kernel. This was not a good idea. For one thing, entropy estimators are notoriously unreliable and can be fooled by attackers (which is one reason why Fortuna ditched Yarrow’s entropy estimation). Furthermore, <i>/dev/random</i> ran out of estimated entropy pretty quickly, which could produce a denial-of-service condition, slowing applications that were forced to wait for more entropy. The upshot is that in practice, <i>/dev/random</i> was no better than <i>/dev/urandom</i> and created more problems than it solved.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec17">&#13;
<h5 class="H3" id="sec17"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">Differences Between /dev/urandom and /dev/random, Since 2022</samp></h5>&#13;
<p class="TNI">In versions of the Linux kernel from 2022 (5.17 onward), several improvements have been incorporated. First, the SHA-1 hash function has been replaced by BLAKE2 when creating the contents of the pool. The biggest change is the modification of the relative behavior of <i>/dev/random</i> and <i>/dev/urandom</i>; it has even been proposed to eliminate their differences altogether. At the time of writing, on most platforms both interfaces will detect if there isn’t enough entropy, but <i>/dev/urandom</i> will resume producing pseudorandom bits if the kernel fails to collect enough entropy, whereas <i>/dev/random</i> will block.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_37" aria-label="37"/>In addition, the kernel’s entropy estimation logic has been greatly improved: instead of considering that entropy decreases when PRNG bits are read (a cryptographic nonsense), the kernel just looks for the point when enough uncertainty (that is, entropy) has been collected—for example, at system startup.</p>&#13;
<p class="TX">You can read the entropy value of a Linux system in the <i>/proc/sys/kernel/random/entropy_avail</i> file. In older versions of the kernel, this value was a maximum of 4,096 bits and decreased with the generation of PRNG bits. In the new kernels, the value is capped at 256 bits and therefore no longer decreases.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec18">&#13;
<h4 class="H2" id="sec18"><span id="h2-28"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">The CryptGenRandom() Function in Windows</samp></h4>&#13;
<p class="TNI">In Windows, the legacy userland interface to the system’s PRNG is the <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptGenRandom()</samp> function from the Cryptography application programming interface (API). Recent Windows versions replace the <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptGenRandom()</samp> function with the <samp class="SANS_TheSansMonoCd_W5Regular_11">BcryptGenRandom()</samp> function in the Cryptography API: Next Generation (CNG). The Windows PRNG takes entropy from the kernel mode driver <i>cng.sys</i> (formerly <i>ksecdd.sys</i>), whose entropy collector is loosely based on Fortuna. As is usually the case in Windows, the process is complicated.</p>&#13;
<p class="TX"><a href="chapter2.xhtml#Lis2-3">Listing 2-3</a> shows a typical C++ invocation of <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptGenRandom()</samp> with the required checks.</p>&#13;
<span id="Lis2-3"/><pre><code>int random_bytes(unsigned char *out, size_t outlen)&#13;
{&#13;
    static HCRYPTPROV handle = 0; /* Only freed when the program ends */&#13;
    if(!handle) {&#13;
        if(!CryptAcquireContext(&amp;handle, 0, 0, PROV_RSA_FULL,&#13;
                                CRYPT_VERIFYCONTEXT | CRYPT_SILENT)) {&#13;
            return -1;&#13;
        }&#13;
    }&#13;
    while(outlen &gt; 0) {&#13;
        const DWORD len = outlen &gt; 1048576UL ? 1048576UL : outlen;&#13;
        if(!CryptGenRandom(handle, len, out)) {&#13;
            return -2;&#13;
        }&#13;
        out    += len;&#13;
        outlen -= len;&#13;
    }&#13;
    return 0;&#13;
}</code></pre>&#13;
<p class="ListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 2-3: Using the Windows</samp> <samp class="SANS_Futura_Std_Book_Oblique_I_11">CryptGenRandom()</samp> <samp class="SANS_Futura_Std_Book_Oblique_I_11">PRNG interface</samp></p>&#13;
<p class="TX">Prior to calling the actual PRNG, you need to declare a <i>cryptographic service provider</i> (<samp class="SANS_TheSansMonoCd_W5Regular_11">HCRYPTPROV</samp>) and then acquire a <i>cryptographic context</i> with <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptAcquireContext()</samp>, which increases the likelihood that things will go wrong. For instance, the final version of the TrueCrypt encryption software was found to call <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptAcquireContext()</samp> in a way that could silently fail, leading to suboptimal randomness without notifying the user. Fortunately, the <span role="doc-pagebreak" epub:type="pagebreak" id="pg_38" aria-label="38"/>newer and simpler <samp class="SANS_TheSansMonoCd_W5Regular_11">BCryptGenRandom()</samp> interface for Windows doesn’t require the code to explicitly open a handle (or at least makes it much easier to use without a handle).</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec19">&#13;
<h4 class="H2" id="sec19"><span id="h2-29"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">A Hardware-Based PRNG: Intel Secure Key</samp></h4>&#13;
<p class="TNI">We’ve discussed only software PRNGs so far, so let’s take a look at a hardware one. The <i>Intel Digital Random Number Generator</i>, or <i>Intel Secure Key</i>, is a hardware PRNG introduced in 2012 in Intel’s Ivy Bridge microarchitecture. It’s based on NIST’s SP 800-90 guidelines with the Advanced Encryption Standard (AES) in CTR_DRBG mode. Intel’s PRNG is accessed through the <samp class="SANS_TheSansMonoCd_W5Regular_11">RDRAND</samp> assembly instruction, which offers an interface independent of the operating system and is in principle faster than software PRNGs.</p>&#13;
<p class="TX">Whereas software PRNGs try to collect entropy from unpredictable sources, Intel Secure Key has a single entropy source that provides a serial stream of entropy data as zeros and ones. In hardware engineering terms, this entropy source is a dual differential jamb latch with feedback—essentially, a small hardware circuit that jumps between two states (0 or 1) depending on thermal noise fluctuations, at a frequency of 3 GHz. This is usually pretty reliable.</p>&#13;
<p class="TX">The <samp class="SANS_TheSansMonoCd_W5Regular_11">RDRAND</samp> assembly instruction takes as an argument a register of 16, 32, or 64 bits and then writes a random value. When invoked, <samp class="SANS_TheSansMonoCd_W5Regular_11">RDRAND</samp> sets the carry flag to 1 if the data set in the destination register is a valid random value, and to 0 otherwise; be sure to check the <samp class="SANS_TheSansMonoCd_W5Regular_11">CF</samp> flag if you write assembly code directly. Note that the C intrinsics available in common compilers don’t check the <samp class="SANS_TheSansMonoCd_W5Regular_11">CF</samp> flag but do return its value.</p>&#13;
<blockquote>&#13;
<p class="Note"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_15">NOTE</samp></span></p>&#13;
</blockquote>&#13;
<p class="NOTE-TXT"><i>Intel’s PRNG framework provides an assembly instruction other than RDRAND: the RDSEED assembly instruction returns random bits directly from the entropy source, after some conditioning or cryptographic processing. It’s intended to be able to seed other PRNGs.</i></p>&#13;
<p class="TX">Intel Secure Key is only partially documented, but it’s built on known standards and has been audited by the well-regarded company Cryptography Research (see its report titled “Analysis of Intel’s Ivy Bridge Digital Random Number Generator”). Nonetheless, there have been some concerns about its security, especially following Edward Snowden’s revelations about cryptographic backdoors: PRNGs are indeed the perfect target for sabotage. If you’re concerned but still want to use <samp class="SANS_TheSansMonoCd_W5Regular_11">RDRAND</samp> or <samp class="SANS_TheSansMonoCd_W5Regular_11">RDSEED</samp>, mix them with other entropy sources. Doing so will prevent effective exploitation of a hypothetical backdoor in Intel Secure Key’s hardware or in the associated microcode in all but the most far-fetched scenarios.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec20">&#13;
<h3 class="H1" id="sec20"><span id="h1-21"/><samp class="SANS_Futura_Std_Bold_B_11">How Things Can Go Wrong</samp></h3>&#13;
<p class="TNI">To conclude, I’ll present a few examples of randomness failures. There are countless examples to choose from, but I’ve chosen four that are simple enough to understand and illustrate different problems.</p>&#13;
<section epub:type="division" aria-labelledby="sec21">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_39" aria-label="39"/>&#13;
<h4 class="H2" id="sec21"><span id="h2-30"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Poor Entropy Sources</samp></h4>&#13;
<p class="TNI">In 1996, the SSL implementation of the Netscape browser was computing 128-bit PRNG seeds according to the pseudocode shown in <a href="chapter2.xhtml#Lis2-4">Listing 2-4</a>, copied from Goldberg and Wagner’s page at <i><a href="https://www.cs.berkeley.edu/~daw/papers/ddj-netscape.html">https://<wbr/>www<wbr/>.cs<wbr/>.berkeley<wbr/>.edu<wbr/>/~daw<wbr/>/papers<wbr/>/ddj<wbr/>-netscape<wbr/>.html</a></i>.</p>&#13;
<span id="Lis2-4"/><pre><code>global variable seed;&#13;
&#13;
RNG_CreateContext()&#13;
    (seconds, microseconds) = time of day; /* Time elapsed since 1970 */&#13;
    pid = process ID;  ppid = parent process ID;&#13;
    a = mklcpr(microseconds);&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> b = mklcpr(pid + seconds + (ppid &lt;&lt; 12));&#13;
    seed = MD5(a, b); /* Derivation of a 128-bit value using the hash MD5 */&#13;
&#13;
mklcpr(x) /* Not cryptographically significant; shown for completeness */&#13;
    return ((0xDEECE66D * x + 0x2BBB62DC) &gt;&gt; 1);&#13;
MD5() /* A very good standard mixing function, source omitted */</code></pre>&#13;
<p class="ListingCaption"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 2-4: Pseudocode of the Netscape browser’s generation of 128-bit PRNG seeds</samp></p>&#13;
<p class="TX">The problem here is that the PIDs and microseconds are guessable values. Assuming that you can guess the value of <samp class="SANS_TheSansMonoCd_W5Regular_11">seconds</samp>, <samp class="SANS_TheSansMonoCd_W5Regular_11">microseconds</samp> has only 10<sup>6</sup> possible values and thus an entropy of log(10<sup>6</sup>), or about 20 bits. The process ID (PID) and parent process ID (PPID) are 15-bit values, so you’d expect 15 + 15 = 30 additional entropy bits. But looking at how <samp class="SANS_TheSansMonoCd_W5Regular_11">b</samp> is computed <span class="CodeAnnotation" aria-label="annotation1">❶</span> shows that the overlap of 3 bits yields an entropy of about 15 + 12 = 27 bits, for a total entropy of only 47 bits, whereas a 128-bit seed should have 128 bits of entropy.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec22">&#13;
<h4 class="H2" id="sec22"><span id="h2-31"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Insufficient Entropy at Boot Time</samp></h4>&#13;
<p class="TNI">In 2012, researchers scanned the internet and harvested public keys from TLS certificates and SSH hosts. They found that a handful of systems had identical public keys, and in some cases very similar keys (namely, RSA keys with shared prime factors)—in short, two numbers, <i>n</i> = <i>pq</i> and <i>n</i><span class="symbol">′</span> = <i>p</i><span class="symbol">′</span><i>q</i><span class="symbol">′</span>, with <i>p</i> = <i>p</i><span class="symbol">′</span>, whereas normally all <i>p</i>s and <i>q</i>s should be different in distinct modulus values.</p>&#13;
<p class="TX">It turned out that many devices generated their public key early, at first boot, before having collected enough entropy, despite using an otherwise-decent PRNG (typically <i>/dev/urandom</i>). PRNGs in different systems produced identical random bits due to having the same entropy source (for example, a hardcoded seed).</p>&#13;
<p class="TX">At a high level, the presence of identical keys is due to key-generation schemes like the following, in pseudocode:</p>&#13;
<pre><code>prng.seed(seed)&#13;
p = prng.generate_random_prime()&#13;
q = prng.generate_random_prime()&#13;
n = p*q</code></pre>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_40" aria-label="40"/>If two systems run this code given an identical seed, they’ll produce the same <i>p</i>, the same <i>q</i>, and therefore the same <i>n</i>.</p>&#13;
<p class="TX">The presence of shared primes in different keys is due to key-generation schemes where additional entropy is injected during the process, as demonstrated here:</p>&#13;
<pre><code>prng.seed(seed)&#13;
p = prng.generate_random_prime()&#13;
prng.add_entropy()&#13;
q = prng.generate_random_prime()&#13;
n = p*q</code></pre>&#13;
<p class="TX">If two systems run this code with the same seed, they’ll produce the same <i>p</i>, but the injection of entropy through <samp class="SANS_TheSansMonoCd_W5Regular_11">prng.add_entropy()</samp> will ensure distinct <i>q</i>s.</p>&#13;
<p class="TX">The problem with shared prime factors is that given <i>n</i> = <i>pq</i> and <i>n</i><span class="symbol">′</span> = <i>pq</i><span class="symbol">′</span>, it’s trivial to recover the shared <i>p</i> by computing the greatest common divisor (GCD) of <i>n</i> and <i>n</i><span class="symbol">′</span>. For details, see the paper “Mining Your Ps and Qs” by Heninger, Durumeric, Wustrow, and Halderman, available at <i><a href="https://factorable.net">https://<wbr/>factorable<wbr/>.net</a></i>.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec23">&#13;
<h4 class="H2" id="sec23"><span id="h2-32"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Noncryptographic PRNG</samp></h4>&#13;
<p class="TNI">Earlier we discussed the difference between crypto and noncrypto PRNGs and why the latter should never be used for crypto applications. Alas, many systems overlook that detail, so we’ll look at one such example.</p>&#13;
<p class="TX">The popular MediaWiki application runs on Wikipedia and many other wikis. It uses randomness to generate things like security tokens and temporary passwords, which should be unpredictable. Unfortunately, a now obsolete version of MediaWiki used a noncrypto PRNG, the Mersenne Twister, to generate these tokens and passwords. Here’s a snippet from the vulnerable MediaWiki source code; look for the function called to get a random bit, and read the comments:</p>&#13;
<pre><code>        /**&#13;
         * Generate a hex-y looking random token for various uses.&#13;
         * Could be made more cryptographically sure if someone cares.&#13;
         * @return string&#13;
         */&#13;
function generateToken($salt = '') {&#13;
    $token = dechex(mt_rand()).dechex(mt_rand());&#13;
    return md5($token . $salt);&#13;
}</code></pre>&#13;
<p class="TX">Did you notice <samp class="SANS_TheSansMonoCd_W5Regular_11">mt_rand()</samp> in the preceding code? Here, <samp class="SANS_TheSansMonoCd_W5Regular_11">mt</samp> stands for Mersenne Twister. In 2012, researchers showed how to exploit the predictability of Mersenne Twister to predict future tokens and temporary passwords, given a couple of security tokens. MediaWiki was patched to use a crypto PRNG.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec24">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_41" aria-label="41"/>&#13;
<h4 class="H2" id="sec24"><span id="h2-33"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Sampling Bug with Strong Randomness</samp></h4>&#13;
<p class="TNI">The next bug shows how even a strong crypto PRNG with sufficient entropy can produce a biased distribution. The chat program Cryptocat was designed to offer secure communication. It used a function that attempted to create a uniformly distributed string of decimal digits—namely, numbers in the range 0 through 9. However, just taking random bytes modulo 10 doesn’t yield a uniform distribution; when taking all numbers between 0 and 255 and reducing them modulo 10, you don’t get an equal number of values in 0 to 9.</p>&#13;
<p class="TX">Cryptocat did the following to address that problem and obtain a uniform distribution:</p>&#13;
<pre><code>Cryptocat.random = function() {&#13;
    var x, o = '';&#13;
    while (o.length &lt; 16) {&#13;
        x = state.getBytes(1);&#13;
        if (x[0] &lt;= 250) {&#13;
            o += x[0] % 10;&#13;
        }&#13;
    }&#13;
    return parseFloat('0.' + o)&#13;
}</code></pre>&#13;
<p class="TX">And that was almost perfect. By taking only the numbers up to a multiple of 10 and discarding others, you’d expect a uniform distribution of the digits 0 through 9. Unfortunately, there was an off-by-one error in the <samp class="SANS_TheSansMonoCd_W5Regular_11">if</samp> condition. I’ll leave the details to you as an exercise. You should find that there is a small statistical bias in favor of the index 0 (hint: <samp class="SANS_TheSansMonoCd_W5Regular_11">&lt;=</samp> should have been <samp class="SANS_TheSansMonoCd_W5Regular_11">&lt;</samp>).</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec25">&#13;
<h3 class="H1" id="sec25"><span id="h1-22"/><samp class="SANS_Futura_Std_Bold_B_11">Further Reading</samp></h3>&#13;
<p class="TNI">I’ve just scratched the surface of randomness in cryptography. There is much more to learn about the theory of randomness, including different entropy notions, randomness extractors, and even the power of randomization and derandomization in complexity theory. To learn more about PRNGs and their security, read the classic 1998 paper “Cryptanalytic Attacks on Pseudorandom Number Generators” by Kelsey, Schneier, Wagner, and Hall. Then look at the implementation of PRNGs in your favorite applications and try to find their weaknesses. (Search online for “random generator bug” to find plenty of examples.)</p>&#13;
<p class="TX">We’re not done with randomness, though. We’ll encounter it multiple times throughout this book, and you’ll discover the many ways it helps to construct secure systems.</p>&#13;
</section>&#13;
</section>&#13;
</div>
</div>
</body></html>