- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Method to the Madness
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We seem to be wired to think about risk in a particular way: we instinctively
    zero in on dangers that are unusual or immediate, while paying much less attention
    to hazards that unfold more slowly or in a more familiar way.'
  prefs: []
  type: TYPE_NORMAL
- en: To give just one example, American public discourse—and our personal anxieties—tend
    to dwell on the threat of terrorism. The data on this particular risk is somewhat
    elusive, but by most estimates, fewer than 50 people are killed in terrorist incidents
    on American soil in a typical year.^([1](b02.xhtml#c01-endnote-1)) In contrast,
    approximately 65,000 annual deaths occur in the United States from unintentional
    poisonings, about 40,000 from falls, and roughly 3,500 from drownings.^([2](b02.xhtml#c01-endnote-2))
    In that sense, ladders, swimming pools, and over-the-counter pain medication are
    far more insidious foes than armed extremists, yet we rarely give these risks
    any thought.
  prefs: []
  type: TYPE_NORMAL
- en: This emphasis on the extreme is often derided as a harmful fallacy; for example,
    in a 2007 essay for *Wired*, noted security and privacy commentator Bruce Schneier
    blamed humankind’s sloppy risk management habits on the existence of an inherent
    tension between our primal instincts—supposedly housed in a tiny brain structure
    called the amygdala—and the rational thought processes of the conscious mind.^([3](b02.xhtml#c01-endnote-3))
    I’m unpersuaded.
  prefs: []
  type: TYPE_NORMAL
- en: A more purposeful explanation is that the everyday risks of ladders and swimming
    pools have been with us for a long time and almost certainly represent a long-settled,
    implicit trade-off between safety, liberty, and utility; there’s little to be
    gained by revisiting this subject over and over again. In contrast, we have a
    continued survival imperative to respond to unfamiliar threats in an immediate
    and forceful way, because the price of a measured reaction can be too high. To
    put it plainly, a bear in your tent requires action before we can take a vote
    at the next meeting of the Committee on the Problem of Bears in Tents. In that
    sense, far from being a cognitive defect or an evolutionary dead end, I suspect
    the way we think about risk may be an underappreciated but eminently rational
    optimization that reduces the cognitive burden of staying alive—and allows us
    to function in complex societies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whatever the utility of this heuristic in everyday life, it has one undeniable
    failure mode: when tasked with analyzing very distant threats, the pursuit of
    novelty combined with the dearth of personal experiences pushes us toward the
    plots of the dramatic, action-packed novels we read, the films we watch, and the
    computer games we play. In the context of emergency preparedness, this can have
    us focusing on scenarios that are not merely rare, but might not even be real.'
  prefs: []
  type: TYPE_NORMAL
- en: And so, to help with the task of sketching out a coherent and cost-effective
    preparedness strategy, the first part of this book outlines a handful of analytical
    tools for mapping out the unknown—and then robustly prioritizing the concerns.
  prefs: []
  type: TYPE_NORMAL
- en: A Method for Reducing Complexity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Any good story about the future is obliged to establish a link to the present
    through a sequence of plausible causative events. A daydream about immense wealth
    must begin with winning the lottery or making some other fortuitous bet; a nightmare
    about financial ruin must have a bitter divorce or a business dispute at its root.
    Whatever the scenario, our desire to know the cause is so strong that any tale
    lacking this component is nearly impossible to engage with. Even in time-travel
    fiction, if normal causality falls apart, the author must necessarily replace
    it with a new set of rules for us to follow along the way.
  prefs: []
  type: TYPE_NORMAL
- en: 'But what works for storytelling can be an impediment for holistically assessing
    risk. There are countless ways to lose a job or be saddled with debilitating debt,
    for example; trying to enumerate them all is a Sisyphean and profoundly demoralizing
    task. For this reason, I find it more useful to focus on the outcomes, not on
    the causes of events. For the most part, it doesn’t matter how you could end up
    in a financially precarious spot. Suffice to say, it’s a reasonably common occurrence,
    and your basic needs will almost always be the same: to put food on the table
    and pay the bills.'
  prefs: []
  type: TYPE_NORMAL
- en: This outcome-centric approach not only cuts down on the mental clutter, but
    also helps devise solutions that hold water even if the particulars of the scenario
    change in an unexpected way. Mitigating the risk of a layoff by sucking up to
    an insufferable boss is a narrowly tailored and uncertain strategy. In contrast,
    building a robust rainy-day fund can soften the blow of a wide range of adversities—from
    unemployment, to emergency dental expenses, to having to spend several nights
    in a hotel because of a natural disaster or in the aftermath of a kitchen fire.
  prefs: []
  type: TYPE_NORMAL
- en: With this method of mapping out risk, the overarching task is to catalog all
    outcomes of note, without overly concerning oneself with how they might come to
    be. Unfortunately, while some of the possibilities might be obvious, to channel
    the former US Secretary of Defense Donald Rumsfeld, there are also unknown unknowns—that
    is, situations that might be of great significance to emergency planning, but
    that don’t immediately come to mind, not without a specific prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'The best way to build a robust taxonomy of unknown unknowns without getting
    bogged down by long-winded hypotheticals might be to take a critical look at your
    daily routine, stress-testing every external dependency by asking, “What would
    happen if I could no longer perform this task the usual way?” Again, the precise
    reason doesn’t matter; for instance, you might be prevented from paying for food
    with a credit card because of a power outage, identity theft, or an IT problem
    at the bank. Whatever the reason, the outcome is the same, and the remedy is simple:
    have several days’ worth of cash on hand.'
  prefs: []
  type: TYPE_NORMAL
- en: A Model for Quantifying Risk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A catalog of all possible concerning outcomes could easily become overwhelming
    in itself, and the expense of trying to prevent any and all hardships knows no
    practical bound. To put such a parade of horribles into perspective, it helps
    to build a model for evaluating and prioritizing risk. The most fundamental concept
    of risk management is the examination of the potential impact of an event in tandem
    with the probability of that outcome coming true. By this criteria, stubbed toes
    and zombie outbreaks are equally uninteresting. The first one is of little consequence,
    and the other has nearly zero odds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since your resources are limited, another useful dimension to ponder is the
    minimum cost—in time, effort, and money—of mitigating a concern. To illustrate:
    more than a million burglaries happen in the United States every year, and the
    average loss is fairly consequential—just a tad over $2,500.^([4](b02.xhtml#c01-endnote-4))
    For many people, a burglary would pass the two-variable test outlined before;
    it’s a plausible scenario with a significant impact on one’s life. However, most
    burglaries happen when the occupant is not home, so the only reliable solution
    may be to install window bars, reinforced doors, and an alarm system. This set
    of measures may require spending $10,000 and picking a fight with the local homeowners
    association (HOA). With such a high mitigation cost, perhaps it’s reasonable to
    let this risk slide.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note my emphasis on the *minimum* cost of mitigation: heed the old saying that
    an ounce of prevention is worth a pound of cure. For example, car accidents are
    a major risk, especially for young males. The surest solution might not be to
    haul an expensive trauma kit in the trunk of the car, but to take a defensive
    driving course for a modest fee—and make the lesson stick.'
  prefs: []
  type: TYPE_NORMAL
- en: When tallying the expenses, it’s also good to distinguish between costs that
    are recoverable and ones that aren’t. There’s no way to recoup the money spent
    on window bars if you suddenly need cash to pay for a new roof or cover an unexpected
    dental bill. In contrast, there’s almost no penalty to maintaining a rainy-day
    fund, as the money can almost always be reallocated to scratch a different itch.
  prefs: []
  type: TYPE_NORMAL
- en: 'To recap: when prioritizing which outcomes to address, it’s best to focus on
    scenarios that are likely to happen, are potentially ruinous, and can be prevented
    or contained in a relatively simple way, as shown in this risk-ranking pseudo-formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![f01001](image_fi/502123c01/f01001.png)'
  prefs: []
  type: TYPE_IMG
- en: Of course, in practice, these variables can’t always be quantified with certainty.
    There’s no fixed conversion rate between the expenditure of free time, mental
    energy, and cash; the probability of some predictions is unknowable or hotly debated;
    and the worst-case impact of certain types of events has no meaningful upper bound.
    In other words, this risk-rank formula should not be taken as gospel—but it’s
    a good starting point for rough prioritization and for deciding where to draw
    the line.
  prefs: []
  type: TYPE_NORMAL
- en: The Challenge of Crony Beliefs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Whenever trying to reason about the future, it’s important to put our own assumptions
    and convictions to the test. A parable I’m fond of perfectly illustrates the pitfalls
    of blindly sticking to our beliefs.
  prefs: []
  type: TYPE_NORMAL
- en: 'It goes like this: imagine a company wishing to open an office in a small town
    run by a corrupt mayor. The mayor offers the executives of the company a simple
    deal: hire a friend of mine, and I’ll make sure all your problems with permits,
    inspections, and other administrative hurdles disappear. The executives, desperate
    to enter this market, decide to do what needs to be done. And so, they hire the
    fellow despite his utter lack of qualifications and skills.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But there’s a snag. To other employees and managers who aren’t in on the racket,
    the continued employment of the crony is proof that the company’s HR processes
    aren’t up to snuff. They soon band together to develop new, more rigorous standards
    for hiring and performance management—yet somehow, all they accomplish is making
    life more miserable for everybody *except* the crony employee. What they miss
    is obvious to us: the employee is there for a rational reason—it’s just not the
    reason they expect.'
  prefs: []
  type: TYPE_NORMAL
- en: In a 2016 essay, author Kevin Simler used this metaphor of corporate life to
    introduce the concept of what he called *crony beliefs*.^([5](b02.xhtml#c01-endnote-5))
    He noted that much like the misguided line managers in our story, people instinctively
    judge beliefs on a one-dimensional scale, essentially placing them somewhere between
    right and wrong, and expecting any conviction that’s proven false to immediately
    vanish in a puff of cognitive smoke. But to Simler, no biological imperative exists
    for any of us to hold only true opinions; our belief system, he argues, is far
    more utilitarian, and other dimensions make convictions desirable (and sincere),
    even if they don’t hold up to scientific scrutiny.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, some beliefs are held for a straightforward reason: because their
    predictive power helps us make sound decisions in everyday life. A good example
    is the working understanding of gravity. Its whole purpose is to predict what
    happens when an item is dropped, so we’re eager to routinely test our assumptions
    and revise them if we notice anything out of whack—such as if we discover that
    some goods are damaged more easily than we would have guessed. The bottom line
    is, because any discrepancy between the data and the theory would be counterproductive,
    we feel no obligation to stick to our guns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But a second class of convictions—Simler’s crony beliefs—also exists and serves
    a very different purpose: helping people thrive within communities. Such beliefs
    aren’t always about conformity. In some settings, one might be rewarded for taking
    provocative and contrarian positions to build a reputation as an independent thinker.
    But self-reinforcing groupthink certainly is a common theme. For example, people
    may have powerful social incentives to believe that their employer or political
    party is more virtuous than someone else’s, and to explain away any moral lapses
    within their own group as isolated and honest mistakes, without giving the same
    benefit of the doubt to the other side.'
  prefs: []
  type: TYPE_NORMAL
- en: The point of labeling such convictions as *cronies* is not to assert that the
    underlying belief is incorrect; rather, it’s to say that its primary function
    is not to help us navigate decisions of immediate consequence. Indeed, crony beliefs
    routinely deal with topics we have little or no agency over, such as corporate
    governance or international policy. Whatever the topic, the telltale characteristic
    of a suspect belief is that on an individual basis, the social consequences of
    doubting it appear far more severe than the consequences of being objectively
    wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'Crony beliefs make it easy to get swept up by compelling narratives of impending
    disasters when they align with our view of the world. An instructive tale is the
    story of the Population Bomb, a doomsday prophecy made in the 1960s by Paul R.
    Ehrlich, a biologist working at Stanford University. The prediction had its roots
    in solid science; extrapolating from contemporaneous data and animal models, Ehrlich
    concluded that the population of the world would continue to grow exponentially.
    He then looked at the best available estimates of agricultural capacity and the
    statistics of arable land. After combining the data sets, he noted that we were
    bound to exceed the world’s food production capabilities in a matter of years.
    He had to sound the alarm: without immediate government intervention to curb fertility,
    all that awaited our species would be starvation, disease, and war.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ehrlich’s elegant and intuitive prediction gained an immense following among
    scientists, policy makers, and prominent celebrities of the era. It did so not
    just because of its scientific merit, but also because it offered something for
    everybody to like. Many politicians imagined a vast expansion of their powers
    to engineer a better and more harmonious society. Scientists cheered the prospect
    of being taken seriously and given a seat at the table, dreaming of an expert-run
    meritocracy. And for conservationists, the anti-progress overtones of the Population
    Bomb meshed neatly with their beliefs and boosted their cause. In short, Ehrlich’s
    theory soon had all the hallmarks of a crony belief: a prediction that had its
    proponents far more invested in perpetuating the idea—and pushing for the associated
    policy prescriptions—than in validating, correcting, or contesting any of the
    claims.'
  prefs: []
  type: TYPE_NORMAL
- en: But before the movement’s more radical ideas could be truly put into motion,
    something odd started to happen. Fertility rates began to taper off in much of
    the world, seemingly in response to improved living conditions, reduced infant
    mortality, and the invention of the birth control pill.^([6](b02.xhtml#c01-endnote-6))
    Just as perplexingly, the efficiency of agricultural production improved dramatically,
    making food cheaper and more abundant than ever before—at least in part thanks
    to technologies such as harvesters, large-scale irrigation systems, modern insecticides
    and fertilizers, and pest-resistant crops.
  prefs: []
  type: TYPE_NORMAL
- en: None of this new data mattered to the proponents of the Population Bomb. The
    prediction was correct; it’s just that the date must have been a bit off. Doomsday
    was postponed until the late 1980s, then the 1990s, then the 2000s, The prophecy
    has a small but dedicated following to this day, an undead creature that’s entirely
    unfalsifiable and forever imminent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Meanwhile, we did learn something from one authoritarian country that embraced
    Ehrlich’s call to action: the sheer scale and horror of the resulting humanitarian
    abuses in China is slowly coming to light. In *One Child Nation*, a 2019 documentary
    produced by Amazon Studios, two Chinese-born filmmakers offer a sobering look
    at forced sterilizations, abortions, and widespread infanticide instigated by
    the Communist Party of China between 1979 and 2015.'
  prefs: []
  type: TYPE_NORMAL
- en: The story of the Population Bomb is recounted in *The Bet*, a captivating book
    written by Paul Sabin, a historian working at Yale University (Yale University
    Press, 2013). I bring it up not as a backhanded attempt to dismiss contemporary
    environmental worries, but to offer an important case study in how easy it is
    to mistake possibility for certainty, to get so engrossed in a movement as to
    lose the ability to evaluate new evidence, and to be blind to solutions that don’t
    align with one’s political views.
  prefs: []
  type: TYPE_NORMAL
- en: Our popular culture is replete with doomsday predictions that extrapolate from
    worst-case assumptions and take a uniquely dim view of our species’ ability to
    adapt and overcome. Today’s mainstream prophecies deal with cutting-edge particle
    physics, chain-reaction environmental collapses, god-like computer hackers, vast
    government conspiracies, and secret messages hidden in pop songs. We can’t really
    rule that stuff out—but when in doubt, it’s best to simplify. Historical data
    suggests that there’s a lot more merit in worrying about falling off a ladder
    or getting hit by a car than any of the more engrossing scenarios we see in the
    movies or read about on the internet.
  prefs: []
  type: TYPE_NORMAL
