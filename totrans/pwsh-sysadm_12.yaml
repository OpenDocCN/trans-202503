- en: '10'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PARSING STRUCTURED DATA
  prefs: []
  type: TYPE_NORMAL
- en: '![Images](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: With ingrained support for any .NET object, and just about every shell method
    you can think of, PowerShell is able to read, update, and remove data from numerous
    sources. If you’re lucky enough to have your data stored in some kind of structured
    way, working with that data is even easier.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll focus on a few common forms of structured data including
    CSV, Microsoft Excel spreadsheets, and JSON. You’ll learn how to manage each kind
    of data by using both native PowerShell cmdlets and .NET objects. By the end of
    the chapter, you should be a data-wrangling pro, able to use PowerShell to manage
    all sorts of structured data.
  prefs: []
  type: TYPE_NORMAL
- en: CSV Files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One of the easiest, most common ways to store data is to use a CSV file. A
    *CSV file* is a simple text file representing a table. Each item in the table
    is separated by a shared, predetermined symbol known as a *delimiter* (commas
    are the most common delimiter). Every CSV file shares the same basic structure:
    the first row in the CSV is the header row, containing all the headers for the
    table’s columns; the following rows contain all of the table’s contents.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, you’ll primarily be working with a couple of CSV cmdlets:
    `Import-Csv` and `Export-Csv`.'
  prefs: []
  type: TYPE_NORMAL
- en: Reading CSV Files
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Of all the CSV processing tasks PowerShell is equipped to do, the most common
    is almost certainly reading. Given how simple and effective the CSV structure
    is, it should be no surprise that CSV files are used by companies and applications
    throughout the tech world—hence the popularity of the `Import-Csv` PowerShell
    command.
  prefs: []
  type: TYPE_NORMAL
- en: 'But what exactly does it mean to *read* a CSV file? Though a CSV has all the
    information you want, you can’t just import it directly into your program; usually,
    you have to read through the file and convert it into usable data. This process
    is known as *parsing*. The `Import-Csv` command parses the CSV file: reading it
    in, and then transforming the data into PowerShell objects. I will go into the
    uses of `Import-Csv` in a moment, but first, it’s worth taking a dive under the
    hood to see what `Import-Csv` is doing.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with a simple spreadsheet containing a few employees at a fictional
    company, shown in [Figure 10-1](ch10.xhtml#ch10fig1).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-1: Employee CSV file*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 10-1](ch10.xhtml#ch10fig1) is an Excel screenshot, but you can easily
    see what the data looks like as a plaintext CSV file. For our sample CSV file,
    you’ll be working with *Employees.csv*, which can be found in this chapter’s resources;
    see [Listing 10-1](ch10.xhtml#ch10list1).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-1: Reading a CSV file with Get-Content*'
  prefs: []
  type: TYPE_NORMAL
- en: Here, you’re using the `Get-Content` command to query our text file (CSV). `Get-Content`
    is the PowerShell command to use for reading plaintext files of any kind.
  prefs: []
  type: TYPE_NORMAL
- en: You can see that this is a typical CSV file with a header row and multiple data
    rows separated into columns by a comma delimiter. Notice that you can read the
    file by using the `Get-Content` cmdlet. Since a CSV file is a text file, `Get-Content`
    works just fine for reading it (this is actually the first step that happens with
    `Import-Csv`).
  prefs: []
  type: TYPE_NORMAL
- en: 'But also notice how `Get-Content` returns the information: as a simple string.
    This is what happens when you use the `Raw` parameter. Otherwise, `Get-Content`
    returns an array of strings, with each element representing a row in the CSV file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Though the `Get-Content` command can read in the data, the command doesn’t *understand*
    a CSV file’s schema. `Get-Content` has no idea that the table has a header row
    or data rows, and it doesn’t know what to do with the delimiter. It just takes
    in the content and spits it back out. That’s why we have `Import-Csv`.
  prefs: []
  type: TYPE_NORMAL
- en: Using Import-Csv to Process Data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To see how `Import-Csv` works, compare the output in [Listing 10-1](ch10.xhtml#ch10list1)
    with the output from `Import-Csv` in [Listing 10-2](ch10.xhtml#ch10list2).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-2: Using Import-Csv*'
  prefs: []
  type: TYPE_NORMAL
- en: The first thing you’ll probably notice is that the headers are now separated
    from the data entries by a line. This means that `Import-Csv` reads the file,
    treats the top row as a header row, and knows to separate it from the rest of
    the file. You also may notice that there are no more commas—when a command reads
    and *understands* a CSV file, it knows that the delimiter is used to separate
    items in the table and shouldn’t show up in the table itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'But what happens if the code has a stray delimiter? Try putting a comma in
    the middle of *Adam* in *Employees.csv* and run the code. What happens? Now everything
    in the Adam row is shifted over: *am* is the new Last Name, *Bertram* the new
    Department, and *IT* the new Manager. `Import-Csv` is smart enough to understand
    a CSV’s format, but not smart enough to understand its content—that’s where you
    come in.'
  prefs: []
  type: TYPE_NORMAL
- en: Turning Raw Data into Objects
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '`Import-Csv` doesn’t just read in the CSV and print it out with fancy formatting.
    The content of the file is put into an array of `PSCustomObject`s. Here, each
    `PSCustomObject` is an object that holds the data for one row. Each object has
    properties that correspond to the headers in the header row, and if you want the
    data for that header’s column, all you have to do is access that property. Just
    by knowing which form of data to expect, `Import-Csv` can take a string of data
    it has never seen before and turn it into easy-to-use objects. Pretty cool!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Having the data as an array of `PSCustomObject`s allows you to use that data
    much more effectively. Let’s say you want to find only the employees with the
    last name of *Bertram*. Since each data row in the CSV is a `PSCustomObject`,
    you can do this by using `Where-Object`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If, instead, you want to return only rows in the CSV that have a department
    of Executive Office, you can do so easily! You use the same technique and change
    the property name from Last Name to Department, and the value from Bertram to
    Executive Office:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: What happens if you use semicolons for your delimiter instead of commas? Try
    changing the CSV file and see what happens. Not good, right? You don’t have to
    use a comma as a delimiter, but commas are the delimiter that `Import-Csv` natively
    understands. If you want to use a different delimiter, you have to specify the
    new delimiter in your `Import-Csv` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate, replace all the commas in our *Employees.csv* file with tabs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Once you have a tab-separated file, you can then specify the tab character (represented
    by a backtick and the `t` character) as the new delimiter by using the `Delimiter`
    parameter ([Listing 10-3](ch10.xhtml#ch10list3)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-3: Using the Delimiter parameter of Import-Csv*'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the output is the same as it was in [Listing 10-2](ch10.xhtml#ch10list2).
  prefs: []
  type: TYPE_NORMAL
- en: Defining Your Own Header
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: What if you have a table of data, but you want to change the header row to be
    more user-friendly? `Import-Csv` can do this too. As with the new delimiter, you
    want to pass a parameter in to `Import-Csv`. [Listing 10-4](ch10.xhtml#ch10list4)
    uses the `Header` parameter to pass in a series of strings separated by commas
    (the new headers).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-4: Using the Header parameter of Import-Csv*'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, after the command runs, each object in the data row will have
    the new labels as property names.
  prefs: []
  type: TYPE_NORMAL
- en: Creating CSV Files
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'So much for reading CSV files. What if you want to make your own? You could
    type one out by hand, but that would take time and energy, especially if you’re
    dealing with thousands of rows. Luckily, PowerShell also has a native cmdlet for
    creating CSV files: `Export-Csv`. You can use this cmdlet to create CSV files
    from any existing PowerShell object; you simply have to tell PowerShell which
    objects to use as rows, and where it should create the file.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s deal with the second requirement first. Say you run some PowerShell commands,
    and then you want to save the output in the console to a file somehow. You could
    use `Out-File`, but that would send the unstructured text directly to a new file.
    You want a nice structured file instead, complete with header rows and delimiters.
    Enter `Export-Csv`.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let’s say you want to pull all the running processes from your
    computer and record the process name, company, and description of each one. You
    can use `Get-Process` to do this and `Select-Object` to narrow down the properties
    you want to see, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In [Listing 10-5](ch10.xhtml#ch10list5), you can see what happens when you commit
    this output to the filesystem in a structured manner by using `Export-Csv`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-5: Using Export-Csv*'
  prefs: []
  type: TYPE_NORMAL
- en: By piping the output directly to `Export-Csv`, specifying the path to the CSV
    you’d like to create (using the `Path` parameter), and using the `NoTypeInformation`
    parameter, you’ve created a CSV file with the expected header row and data rows.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*The NoTypeInformation parameter is not required, but if you don’t use it,
    you will get a line at the top of your CSV file specifying the type of object
    it came from. Unless you’re reimporting the CSV file directly back into PowerShell,
    this usually isn’t desired. An example line looks like #TYPE Selected.System.Diagnostics.Process.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 1: Building a Computer Inventory Report'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To bring together everything you’ve learned so far, let’s work on a mini-project,
    something you may run into in your daily life.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine for a moment that your company has acquired another company that has
    no idea what servers and PCs it has on its network. All it has is a CSV file of
    IP addresses and the department where each device is located. You’ve been brought
    in to figure out what these devices are and to provide a new CSV file to management
    with the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'What do you have to do? At a high level, this is a two-step process: read in
    their CSV and write your own. Your CSV file will need the following information:
    each IP address you process, the department it’s supposed to be in, whether or
    not the IP address responds to a ping, and the DNS name of that device.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll start with a CSV file that looks just like that looks like the following
    snippet. The IP addresses are part of a full 255.255.255.0 network, so they go
    all the way up to 192.168.0.254:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: I’ve created a script called *Discover-Computer.ps1* that’s available in this
    chapter’s resources. As you move through this experiment, start adding code to
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to read each row in the CSV file. You do this with `Import-Csv`,
    which will capture each row of the CSV into a variable for further processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that you have the data, you need to use it. You’ll perform two actions
    on each IP address: pinging it and finding its hostname. Let’s go ahead and test
    these actions on a row of our CSV to ensure that you have the syntax right.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following listing, you use the `Test-Connection` command, which sends
    a single ICMP packet to the IP address you specify (here the IP address in the
    first row of our CSV file). The `Quiet` parameter tells the command to return
    either a `True` or `False` value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In the second line of this code, you’re obtaining the hostname by using the
    `Resolve-DnsName` command on the same IP address. The `Resolve-DnsName` command
    returns multiple properties. Here, because you’re concerned with only the name,
    you enclose the entire command in parentheses and use dot notation to return the
    `Name` property.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’re comfortable with the syntax for each action, you need to do this
    for every row in the CSV. The easiest way to do this is with a `foreach` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Run the code yourself. What happens? You get a bunch of `True`/`False` lines
    with hostnames, but no way to know which IP address the output is associated with.
    You’ll have to create a *hashtable* for each row and assign your own elements
    to it. You also need to account for if or when `Test-Connection` or `Resolve-DnsName`
    returns an error. [Listing 10-6](ch10.xhtml#ch10list6) shows an example of how
    to do all this.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-6: Mini-project—CSV file discovery*'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through what’s happening. First, you create a hashtable with values
    corresponding to the row’s columns and the extra information you want ❷. Next,
    test whether the computer is connected by pinging the IP address ❸. If the computer
    is connected, set `IsOnline` to `True`. Then do the same with the `HostName`,
    testing whether it’s found ❹ and updating the hashtable’s value if it is. If any
    errors occur, record that in the hashtable’s `Error` value ❺. Lastly, turn your
    hashtable into a `PSCustomObject` and return it (regardless of whether an error
    is thrown) ❻. Note that you’ve wrapped this whole function in a `try/catch` block
    ❶, which will execute the code in the `catch` block if the code in the `try` block
    throws an error. Because you’re using the `ErrorAction` parameter, `Resolve-DnsName`
    will throw an exception (an error) if something unexpected happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run this, and you should see output that looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Congrats! You’ve done most of the hard work, and now you can tell which IP address
    is associated with which output. All that’s left is to record the output to a
    CSV. As you learned earlier, you can do this with `Export-Csv`. You’ll simply
    pipe the `PSCustomObject` you created into `Export-Csv`, and the output will go
    directly into a CSV file rather than being output to the console.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that next, you’ll use the `Append` parameter. By default, `Export-Csv`
    overwrites the CSV file. Using the `Append` parameter adds a row to the end of
    an existing CSV file rather than overwriting it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the script runs, you’ll see that the CSV file will be the exact same as
    the output you saw in your PowerShell console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: You should now have a CSV file called *DeviceDiscovery.csv* (or whatever you
    named it) that has rows for each IP address in the original CSV, along with values
    for all of the original CSV file values and the values that you discovered with
    `Test-Connection` and `Resolve-DnsName`.
  prefs: []
  type: TYPE_NORMAL
- en: Excel Spreadsheets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It’s hard to imagine a business that doesn’t use Excel spreadsheets. Chances
    are, if you get a scripting project, it will involve an Excel spreadsheet. But
    before we dive deep into the world of Excel, it’s worth stating something clearly:
    if possible, don’t use it at all!'
  prefs: []
  type: TYPE_NORMAL
- en: A CSV file can store data as effectively as a simple Excel spreadsheet, and
    CSV files are much easier to manage with PowerShell. Excel spreadsheets come in
    a proprietary format, and you can’t even read them by using PowerShell unless
    you’re using an external library. If you have an Excel workbook with a single
    worksheet, do yourself a favor and save it as a CSV file. Of course, this isn’t
    always possible, but if it is, you’ll thank yourself later. Trust me.
  prefs: []
  type: TYPE_NORMAL
- en: But what if it isn’t possible to save it as a CSV? In that case, you need to
    use a community module. Once upon a time, reading *.xls* or *.xlsx* Excel spreadsheets
    with PowerShell required a software developer’s delicate touch. You had to have
    Excel installed, and you had to access *COM objects*, complex programming components
    that take all the fun out of working in PowerShell. Luckily, other people have
    done the hard work for you, so rather than focus on learning how to use COM, in
    this section, you’ll rely on Doug Finke’s wonderful `ImportExcel` module. This
    freely available community module does not require Excel to be installed, and
    it’s much simpler than COM objects.
  prefs: []
  type: TYPE_NORMAL
- en: First, you need to install the module. The `ImportExcel` module is available
    via the PowerShell Gallery and can be installed by running `Install-Module ImportExcel`.
    Once you’ve installed the `ImportExcel` module, it’s time to see what it can do.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Excel Spreadsheets
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To start, you need to create an Excel spreadsheet. Now, sure, you could create
    one the usual way by opening Excel and going through all that jazz—but where’s
    the fun in that? Let’s use PowerShell to create a simple spreadsheet with a single
    worksheet (you have to crawl before you can walk). To do this, you’ll use the
    `Export-Excel` command. Just like `Export-Csv`, `Export``-Excel` will read the
    property names of each object it receives, create a header row from them, and
    then create the data rows right below.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to use `Export-Excel` is to pipe one or more objects into it
    just as you would with `Export-Csv`. As an example, let’s create an Excel workbook
    with a single worksheet that contains all the running processes on my computer.
  prefs: []
  type: TYPE_NORMAL
- en: The input Get-Process | Export-Excel .\Processes.xlsx gives us a spreadsheet
    that looks like [Figure 10-2](ch10.xhtml#ch10fig2).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-2: The Excel spreadsheet*'
  prefs: []
  type: TYPE_NORMAL
- en: If you haven’t converted to CSVs yet, you’re probably working with something
    more complicated than just a single worksheet. Let’s add a couple more worksheets
    to our existing workbook. To do that, use the `WorksheetName` parameter, as shown
    in [Listing 10-7](ch10.xhtml#ch10list7). This will create additional worksheets
    by using the objects that are sent to `Export-Excel`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-7: Adding worksheets to an Excel workbook*'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a spreadsheet by using `Export-Excel` can be a *whole* lot more complicated,
    but to save us time (and the Earth a couple of trees), we don’t go into it here.
    If you’re curious, check out the help documentation on `Export-Excel` and you’ll
    see the dozens of parameters you can use!
  prefs: []
  type: TYPE_NORMAL
- en: Reading Excel Spreadsheets
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now that you have a spreadsheet you can work with, let’s focus on reading the
    rows inside. To read a spreadsheet, you use the `Import-Excel` command. This command
    reads a worksheet in a workbook and returns one or more `PSCustomObject` objects
    representing each row. The simplest way to use this command is to specify the
    workbook path by using the `Path` parameter. You’ll see in [Listing 10-8](ch10.xhtml#ch10list8)
    that `Import-Excel` returns an object that uses the column names as properties.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-8: Using Import-Excel*'
  prefs: []
  type: TYPE_NORMAL
- en: By default, `Import-Excel` will return only the first worksheet. Our example
    workbook has multiple worksheets, so you need to figure out a way to go through
    each sheet. But imagine it’s been a while since you last created that spreadsheet,
    and you can’t remember the worksheet names. No problem. You’ll use `Get-ExcelSheetInfo`
    to find all the worksheets in the workbook, as shown in [Listing 10-9](ch10.xhtml#ch10list9).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-9: Using Get-ExcelSheetInfo*'
  prefs: []
  type: TYPE_NORMAL
- en: You’ll use this output to pull data from all our worksheets. Make a `foreach`
    loop and call `Import-Excel` for every worksheet inside the workbook, just as
    in [Listing 10-10](ch10.xhtml#ch10list10).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-10: Getting all rows from all worksheets*'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that you use a calculated property with `Select-Object` ❶. Typically,
    when using the `Property` parameter of `Select-Object`, a simple string is used,
    specifying the property you want returned. When you use a calculated property,
    however, you provide `Select-Object` with a hashtable containing the name of the
    property to return and an expression that runs when `Select-Object` receives input.
    The result of the expression will be the value of the new, calculated property.
  prefs: []
  type: TYPE_NORMAL
- en: By default, `Import-Excel` doesn’t add the worksheet name as a property to each
    object—meaning you won’t know which worksheet the row comes from. To account for
    this, you need to create a property called `Worksheet` on each row object so you
    have something to reference later.
  prefs: []
  type: TYPE_NORMAL
- en: Adding to Excel Spreadsheets
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the previous section, you created a workbook from scratch. There will inevitably
    come a time when you need to add rows to a worksheet. Luckily, this is easy enough
    with the `ImportExcel` module; you just need to use the `Append` parameter on
    the `Export-Excel` command.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, let’s say you want to track process execution history on your
    computer. You’d like to export all the processes running on your computer over
    a period of time and then compare results in Excel later. To do so, you need to
    export all the running processes and make sure to include a timestamp on each
    row to indicate when the process information was gathered.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s add another worksheet to our demo workbook and call it **ProcessesOverTime**.
    You’ll use a calculated property to add a timestamp property to each process row,
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Run this command, and then open the Processes workbook. You should see a worksheet
    called ProcessesOverTime with a list of all running processes on your computer,
    and an additional timestamp column indicating when the process information was
    queried.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you’ll append additional rows to the worksheet by using the
    same command you just used, but this time with the `Append` parameter. This command
    can be run as many times as you like. It will just keep appending rows to the
    worksheet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Once you collect your data, you can review your Excel workbook and all the process
    information you collected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 2: Creating a Windows Service Monitoring Tool'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s put together the skills you learned in this section and work on another
    mini-project. This time, you’ll build a process to track Windows service states
    over time and record them to an Excel worksheet. Then, you’ll build a report showing
    when various services have changed state—basically, you’re making a lo-fi monitoring
    tool.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing you want to do is figure out how to pull all Windows services,
    returning only their name and state. You can do this easily enough by running
    `Get-Service | Select-Object -Property Name,Status`. Next, you need to get a timestamp
    on each row in the Excel worksheet. Just as you did in the lesson, you’ll use
    a calculated property to do this; see [Listing 10-11](ch10.xhtml#ch10list11).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-11: Exporting service states*'
  prefs: []
  type: TYPE_NORMAL
- en: You should now have an Excel workbook created called *ServiceStates.xlsx* with
    a single worksheet called Services that’ll look something like [Figure 10-3](ch10.xhtml#ch10fig3).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-3: The Excel workbook*'
  prefs: []
  type: TYPE_NORMAL
- en: Before running the same command again, let’s change the state of various Windows
    services. This will allow you to track changes over time. Stop and start a few
    services to change their states. Then run the same command as in [Listing 10-11](ch10.xhtml#ch10list11),
    although this time using the `Append` parameter to `Export-Excel`. This will get
    you some data to work with. (Don’t forget to use the `Append` parameter, or the
    command will overwrite the existing worksheet!)
  prefs: []
  type: TYPE_NORMAL
- en: Once you have the data, it’s time to summarize it. Excel provides multiple ways
    to do this, but for now, you’ll stick with a pivot table. A *pivot table* is a
    way to summarize data by grouping one or more properties together and then performing
    an action on those properties’ corresponding values (counting, adding, and so
    on). Using a pivot table, you can easily spot which services changed states and
    when they did so.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll use the `IncludePivotTable`, `PivotRows`, `PivotColumns`, and `PivotData`
    parameters to create a summary pivot table ([Figure 10-4](ch10.xhtml#ch10fig4)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-4: Service state pivot table*'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in [Listing 10-12](ch10.xhtml#ch10list12), you’re reading the
    data in the Services worksheet and using that data to create a pivot table.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-12: Creating an Excel pivot table with PowerShell*'
  prefs: []
  type: TYPE_NORMAL
- en: The `ImportExcel` PowerShell module has a suite of options you can use here.
    If you want to keep working with this dataset, play around with it and see what
    you can do. Take a look at the ImportExcel GitHub repository ([*https://github.com/dfinke/ImportExcel*](https://github.com/dfinke/ImportExcel)),
    or if you want to use different data, give that a go. As long as you have the
    data, PowerShell can manipulate and represent it just about any way you like!
  prefs: []
  type: TYPE_NORMAL
- en: JSON Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you’ve been working in tech for the last five years, you’ve probably read
    some JSON. Created in the early 2000s, *JavaScript Object Notation (JSON)* is
    a machine-readable, human-understandable language that represents hierarchical
    sets of data. As its name might suggest, it’s heavily used in JavaScript applications,
    meaning it has a strong presence in web development.
  prefs: []
  type: TYPE_NORMAL
- en: A recent surge in the number of online services that use a *REST API*—a technology
    used to send data between client and server—has led to a similar surge in the
    use of JSON. If you’re doing anything with the web, JSON is a good format to know,
    and it’s one you can easily manage in PowerShell.
  prefs: []
  type: TYPE_NORMAL
- en: Reading JSON
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Similar to reading the CSVs, you can read JSON a couple of ways in PowerShell:
    with parsing or no parsing. Since JSON is just plaintext, PowerShell treats it
    as a string by default. As an example, look at the JSON file *Employees.json*
    found in this chapter’s resources, reproduced here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: If you want only the string output, you can use `Get-Content -Path Employees``.json
    -Raw` to read the file and return a string. But there’s not much you can do with
    a string. You need structure. To get that, you need something that understands
    the JSON schema (the way individual nodes and arrays of nodes are represented
    in JSON) and can parse the file accordingly. You need the `ConvertFrom-Json` cmdlet.
  prefs: []
  type: TYPE_NORMAL
- en: The `ConvertFrom-Json` cmdlet is a native cmdlet in PowerShell that takes raw
    JSON as input and converts it into PowerShell objects. You can see in [Listing
    10-13](ch10.xhtml#ch10list13) that PowerShell knows `Employees` is a property
    now.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-13: Converting JSON to objects*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you take a look at the `Employees` property, you’ll see that all the employee
    nodes have been parsed out, with each key representing a column header, and each
    value representing the row value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `Employees` property is now an array of objects that you can query and manipulate
    just as you would any other array.
  prefs: []
  type: TYPE_NORMAL
- en: Creating JSON Strings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s say you have a whole bunch of data from a whole bunch of sources and
    you want to convert it all to JSON. What do you do? This is the magic of the `ConvertTo-Json`
    cmdlet: it can convert any object in PowerShell to JSON.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let’s convert the CSV file you built earlier in the chapter
    into *Employees.json*. First, you need to import our CSV:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: To do the conversion, you need to pipe the output to `ConvertTo-Json`, as in
    [Listing 10-14](ch10.xhtml#ch10list14).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-14: Converting objects to JSON*'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you might expect by now, there are a couple parameters you can pass in to
    modify the conversion. A nice one is the `Compress` parameter, which minifies
    the output by removing all the potentially unwanted line breaks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: If it has a property and a property value, `ConvertTo-Json` can do its job.
    The property will always be the node key, and the property value will always be
    the node value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 3: Querying and Parsing a REST API'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now that you know how to parse JSON, let’s do something a little fancier: let’s
    use PowerShell to query a REST API and parse the results. You could use just about
    any REST API, but some require authentication, and it’ll be easier to do this
    without the extra steps. Let’s use one that doesn’t require authentication. I’ve
    found a REST API at *postcodes.io*, a service that allows you to query UK postal
    codes from various criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The URI you’ll use is *[http://api.postcodes.io/random/postcodes](http://api.postcodes.io/random/postcodes)*.
    When you access this URI, it will query the *postcodes.io* API service and return
    a random postcode in JSON form. To query this URI, you’ll use PowerShell’s `Invoke-WebRequest`
    cmdlet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In Windows PowerShell, `Invoke-WebRequest` relies on Internet Explorer. If you
    don't have Internet Explorer on your computer, you may have to use the `-UseBasicParsing`
    parameter to remove the dependency. “Advanced” parsing breaks down the resulting
    HTML output a bit more but it's not needed in all cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s see if you can convert the result into a PowerShell object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'You can convert the response to JSON without a problem. But you have to use
    two commands, `Invoke-WebRequest` and `ConvertFrom-Json`. Wouldn’t life be great
    if you could use only one? It turns out that PowerShell has a command that will
    do everything for you: `Invoke-RestMethod`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Invoke-RestMethod` cmdlet is similar to `Invoke-WebRequest`; it sends
    various HTTP verbs to web services and returns the response. Because the *postcodes.io*
    API service does not require any authentication, you can simply use the `Uri`
    parameter on `Invoke-RestMethod` to get the API response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that `Invoke-RestMethod` returns an HTTP status code and the response
    from the API in the `result` property. So where’s the JSON? Well, just as you
    wanted, it’s already been converted to an object for you. There’s no need to manually
    convert the JSON to an object, as you can use the `result` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Working with JSON in PowerShell is a straightforward process. With PowerShell’s
    easy-to-use cmdlets, you’re usually spared any complicated string parsing—simply
    pass in JSON, or a soon-to-be-JSONified object, into the pipeline and watch the
    magic happen!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This chapter covered a few ways to structure data, as well as how to work with
    those structures in PowerShell. PowerShell’s native cmdlets make this process
    a breeze, abstracting away a lot of complicated code and leaving the user with
    easy-to-use commands. But don’t let its simplicity fool you: PowerShell can parse
    and manipulate nearly any kind of data. Even if it doesn’t have a native command
    to handle the data type, because of its .NET foundation, it’s able to dig into
    any .NET classes for any advanced concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll work with Microsoft’s Active Directory (AD). Full
    of repetitive tasks, AD is a common place to start when learning to use PowerShell;
    we’ll spend a lot of time on this great resource throughout the rest of this book.
  prefs: []
  type: TYPE_NORMAL
