<html><head></head><body>
<h2 class="h2" id="ch08"><span epub:type="pagebreak" id="page_71"/><strong><span class="big">8</span><br/>TEMPLATE INJECTION</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">A <em>template engine</em> is code that creates dynamic websites, emails, and other media by automatically filling in placeholders in the template when rendering it. By using placeholders, the template engine allows developers to separate application and business logic. For example, a website might use just one template for user profile pages with dynamic placeholders for profile fields, such as the user’s name, email address, and age. Template engines also usually provide additional benefits, such as user input sanitization features, simplified HTML generation, and easy maintenance. But these features don’t make template engines immune to vulnerabilities.</p>&#13;
<p class="indent"><em>Template injection</em> vulnerabilities occur when engines render user input without properly sanitizing it, sometimes leading to remote code execution. We’ll cover remote code execution in more detail in <a href="ch12.xhtml#ch12">Chapter 12</a>.</p>&#13;
<p class="indent">There are two types of template injection vulnerabilities: server side and client side.</p>&#13;
<h3 class="h3" id="ch08lev1sec1"><span epub:type="pagebreak" id="page_72"/><strong>Server-Side Template Injections</strong></h3>&#13;
<p class="noindent"><em>Server-side template injection (SSTI)</em> vulnerabilities occur when the injection happens in the server-side logic. Because template engines are associated with specific programming languages, when an injection occurs, you may sometimes be able to execute arbitrary code from that language. Whether or not you can do this depends on the security protections the engine provides, as well as the site’s preventative measures. The Python Jinja2 engine has allowed arbitrary file access and remote code execution, as has the Ruby ERB template engine that Rails uses by default. In contrast, Shopify’s Liquid Engine allows access to a limited number of Ruby methods in an attempt to prevent full remote code execution. Other popular engines include PHP’s Smarty and Twig, Ruby’s Haml, Mustache, and so on.</p>&#13;
<p class="indent">To test for SSTI vulnerabilities, you submit template expressions using the specific syntax for the engine in use. For example, PHP’s Smarty template engine uses four braces <span class="literal">{{ }}</span> to denote expressions, whereas ERB uses a combination of angle brackets, percent symbols, and an equal sign <span class="literal">&lt;%= %&gt;</span>. Typical testing for injections on Smarty involves submitting <span class="literal">{{7*7}}</span> and looking for areas where inputs are reflected back on the page (such as in forms, URL parameters, and so on). In this case, you’d look for <span class="literal">49</span> rendered from the code <span class="literal">7*7</span> executing in the expression. If you find <span class="literal">49</span>, you’ll know that you successfully injected your expression and the template evaluated it.</p>&#13;
<p class="indent">Because the syntax isn’t uniform across all template engines, you must know the software used to build the site you’re testing. Tools like Wappalyzer and BuiltWith are specifically designed for this purpose. After identifying the software, use that template engine’s syntax to submit a simple payload, such as <span class="literal">7*7</span>.</p>&#13;
<h3 class="h3" id="ch08lev1sec2"><strong>Client-Side Template Injections</strong></h3>&#13;
<p class="noindent"><em>Client-side template injection (CSTI)</em> vulnerabilities occur in client template engines and are written in JavaScript. Popular client template engines include Google’s AngularJS and Facebook’s ReactJS.</p>&#13;
<p class="indent">Because CSTIs occur in the user’s browser, you typically can’t use them to achieve remote code execution, but you can use them for XSS. However, achieving XSS can sometimes be difficult and requires bypassing preventative measures, just as with SSTI vulnerabilities. For example, ReactJS does a great job of preventing XSS by default. When testing applications using ReactJS, you should search the JavaScript files for the function <span class="literal">dangerouslySetInnerHTML</span>, where you can control input provided to the function. This intentionally bypasses ReactJS’s XSS protections. With regard to AngularJS, versions earlier than 1.6 include a Sandbox that limits access to some JavaScript functions and protects against XSS (to confirm the AngularJS version, enter <span class="literal">Angular.version</span> in the developer console in your browser). But ethical hackers routinely found and released <span epub:type="pagebreak" id="page_73"/>AngularJS Sandbox bypasses before the version 1.6 release. The following is a popular bypass for Sandbox versions 1.3.0 to 1.5.7 that you can submit when you find an AngularJS injection:</p>&#13;
<p class="programs">{{a=toString().constructor.prototype;a.charAt=a.trim;$eval('a,alert(1),a')}}</p>&#13;
<p class="indent">You’ll find other published AngularJS Sandbox escapes at <em><a href="https://pastebin.com/xMXwsm0N">https://pastebin.com/xMXwsm0N</a></em> and <em><a href="https://jsfiddle.net/89aj1n7m/">https://jsfiddle.net/89aj1n7m/</a></em>.</p>&#13;
<p class="indent">Demonstrating the severity of a CSTI vulnerability requires you to test the code you can potentially execute. Although you might be able to evaluate some JavaScript code, some sites might have additional security mechanisms to prevent exploitation. For example, I found a CSTI vulnerability by using the payload <span class="literal">{{4+4}}</span>, which returned <span class="literal">8</span> on a site using AngularJS. But when I used <span class="literal">{{4*4}}</span>, the text <span class="literal">{{44}}</span> was returned because the site sanitized the input by removing the asterisk. The field also removed special characters, such as <span class="literal">()</span> and <span class="literal">[]</span>, and it allowed a maximum of 30 characters. Combined, these preventative measures effectively rendered the CSTI useless.</p>&#13;
<h3 class="h3" id="ch08lev1sec3"><strong>Uber AngularJS Template Injection</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> High</p>&#13;
<p class="hang"><strong>URL:</strong> <em><a href="https://developer.uber.com/">https://developer.uber.com/</a></em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/125027/">https://hackerone.com/reports/125027/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> March 22, 2016</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $3,000</p>&#13;
<p class="noindent">In March 2016, James Kettle, the lead security researcher at PortSwigger (creator of Burp Suite) found a CSTI vulnerability in an Uber subdomain via the URL <em>https://developer.uber.com/docs/deep-linking?q=wrtz{{7*7}}</em>. If you viewed the rendered page source after visiting the link, you’d find the string <span class="literal">wrtz49</span>, showing that the template had evaluated the expression <span class="literal">7*7</span>.</p>&#13;
<p class="indent">As it turned out, <em><a href="http://developer.uber.com">developer.uber.com</a></em> used AngularJS to render its web pages. You could confirm this by using a tool such as Wappalyzer or BuiltWith or by viewing the page source and looking for <span class="literal">ng-</span> HTML attributes. As mentioned, older versions of AngularJS implemented a Sandbox, but the version Uber was using was vulnerable to a Sandbox escape. So in this case, a CSTI vulnerability meant you could execute XSS.</p>&#13;
<p class="indent">Using the following JavaScript within the Uber URL, Kettle escaped the AngularJS Sandbox and executed the <span class="literal">alert</span> function:</p>&#13;
<p class="programs">https://developer.uber.com/docs/deep-linking?q=wrtz{{(_="".sub).call.call({}<br/>&#13;
[$="constructor"].getOwnPropertyDescriptor(_.__proto__,$).value,0,"alert(1)")<br/>&#13;
()}}zzzz</p>&#13;
<p class="indent">Deconstructing this payload is beyond the scope of this book, given the publication of numerous AngularJS Sandbox bypasses and the removal <span epub:type="pagebreak" id="page_74"/>of the Sandbox in version 1.6. But the end result of the payload <span class="literal">alert(1)</span> is a JavaScript popup. This proof of concept demonstrated to Uber that attackers could exploit this CSTI to achieve XSS, resulting in potentially compromised developer accounts and associated apps.</p>&#13;
<h4 class="h4" id="ch08lev2sec1"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">After you confirm whether a site is using a client-side template engine, begin testing the site by submitting simple payloads using the same syntax as the engine, such as <span class="literal">{{7*7}}</span> for AngularJS, and watching for the rendered result. If the payload is executed, check which version of AngularJS the site is using by typing <em>Angular.version</em> in the browser console. If the version is greater than 1.6, you can submit a payload from the aforementioned resources without a Sandbox bypass. If it’s less than 1.6, you’ll need to submit a Sandbox bypass like Kettle’s, specific to the AngularJS version the application is using.</p>&#13;
<h3 class="h3" id="ch08lev1sec4"><strong>Uber Flask Jinja2 Template Injection</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> <em><a href="https://riders.uber.com/">https://riders.uber.com/</a></em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/125980/">https://hackerone.com/reports/125980/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> March 25, 2016</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $10,000</p>&#13;
<p class="noindent">When you’re hacking, it’s important to identify the technologies a company uses. When Uber launched its public bug bounty program on HackerOne, it also included a “treasure map” on its site at <em><a href="https://eng.uber.com/bug-bounty/">https://eng.uber.com/bug-bounty/</a></em> (a revised map was published in August 2017 at <em><a href="https://medium.com/uber-security-privacy/uber-bug-bounty-treasure-map-17192af85c1a/">https://medium.com/uber-security-privacy/uber-bug-bounty-treasure-map-17192af85c1a/</a></em>). The map identified a number of sensitive properties Uber operated, including the software each one used.</p>&#13;
<p class="indent">In its map, Uber disclosed that <em><a href="http://riders.uber.com">riders.uber.com</a></em> was built with Node.js, Express, and Backbone.js, none of which immediately jumps out as a potential SSTI attack vector. But the sites <em><a href="http://vault.uber.com">vault.uber.com</a></em> and <em><a href="http://partners.uber.com">partners.uber.com</a></em> were developed using Flask and Jinja2. Jinja2 is a server-side template engine that can allow remote code execution if implemented incorrectly. Although <em><a href="http://riders.uber.com">riders.uber.com</a></em> didn’t use Jinja2, if the site supplied input to either the <em>vault</em> or <em>partners</em> subdomains and those sites trusted the input without sanitizing it, an attacker might be able to exploit an SSTI vulnerability.</p>&#13;
<p class="indent">Orange Tsai, the hacker who found this vulnerability, entered <span class="literal">{{1+1}}</span> as his name to begin testing for SSTI vulnerabilities. He searched for whether any interaction took place between the subdomains.</p>&#13;
<p class="indent">In his write-up, Orange explained that any change to a profile on <em><a href="http://riders.uber.com">riders.uber.com</a></em> would result in an email to the account owner notifying them of the change—a common security approach. By changing his name on the site to include <span class="literal">{{1+1}}</span>, he received an email with a <span class="literal">2</span> in his name, as shown in <a href="ch08.xhtml#ch08fig01">Figure 8-1</a>.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_75"/><a id="ch08fig01"/><img alt="image" src="../images/08fig01.jpg"/></div>&#13;
<p class="figcap"><em>Figure 8-1: The email Orange received executing the code he had injected into his name</em></p>&#13;
<p class="indent">This behavior immediately raised a red flag because Uber evaluated his expression and replaced it with the result of the equation. Orange then tried to submit the Python code <span class="literal">{% for c in [1,2,3]%} {{c,c,c}} {% endfor %}</span> to confirm that a more complex operation could be evaluated. This code iterates over the array <span class="literal">[1,2,3]</span> and prints each number three times. The email in <a href="ch08.xhtml#ch08fig02">Figure 8-2</a> shows Orange’s name displayed as nine numbers that resulted from the <span class="literal">for</span> loop executing, which confirmed his finding.</p>&#13;
<p class="indent">Jinja2 also implements a Sandbox, which limits the ability to execute arbitrary code but can occasionally be bypassed. In this case, Orange would have been able to do just that.</p>&#13;
<div class="image"><a id="ch08fig02"/><img alt="image" src="../images/08fig02.jpg"/></div>&#13;
<p class="figcap"><em>Figure 8-2: The email that resulted from Orange’s injection of more complex code</em></p>&#13;
<p class="indent">Orange only reported the ability to execute code in his write-up, but he could have taken the vulnerability even further. In his write-up, he credited nVisium’s blog posts with providing the information necessary to find the bug. But these posts also contain additional information about the scope of Jinja2 vulnerabilities when combined with other concepts. Let’s take a slight <span epub:type="pagebreak" id="page_76"/>detour to see how this added information applies to Orange’s vulnerability by looking at nVisium’s blog post at <em><a href="https://nvisium.com/blog/2016/03/09/exploring-ssti-in-flask-jinja2.html">https://nvisium.com/blog/2016/03/09/exploring-ssti-in-flask-jinja2.html</a></em>.</p>&#13;
<p class="indent">In the blog post, nVisium walks through exploiting Jinja2 by using <em>introspection</em>, an object-oriented programming concept. Introspection involves inspecting the properties of an object at runtime to see what data is available to it. The details of how object-oriented introspection works are beyond the scope of this book. In the context of this bug, introspection allowed Orange to execute code and identify what properties were available to the template object when the injection occurred. Once an attacker knows that information, they could find potentially exploitable properties they could use to achieve remote code execution; I’ll cover this vulnerability type in <a href="ch12.xhtml#ch12">Chapter 12</a>.</p>&#13;
<p class="indent">When Orange found this vulnerability, he simply reported the ability to execute the code necessary to perform the introspection rather than attempting to take the vulnerability further. It’s best to take Orange’s approach because it ensures you don’t perform any unintended actions; also, companies can assess the potential impact of the vulnerability. If you’re interested in exploring the full severity of an issue, ask the company in your report whether you can continue testing.</p>&#13;
<h4 class="h4" id="ch08lev2sec2"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Note the technologies a site uses; often, these lead to insights into how you can exploit the site. Be sure to also consider how the technologies interact with each other. In this case, Flask and Jinja2 were great attack vectors, although they weren’t directly used on the vulnerable site. As with XSS vulnerabilities, check all possible places your input might be used, because a vulnerability might not be immediately apparent. In this case, the malicious payload was rendered as plaintext on the user’s profile page, and the code was executed when emails were sent.</p>&#13;
<h3 class="h3" id="ch08lev1sec5"><strong>Rails Dynamic Render</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> N/A</p>&#13;
<p class="hang"><strong>Source:</strong> <em>https://nvisium.com/blog/2016/01/26/rails-dynamic-render-to-rce-cve-2016-0752/</em></p>&#13;
<p class="hang"><strong>Date reported:</strong> February 1, 2015</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> N/A</p>&#13;
<p class="noindent">In early 2016, the Ruby on Rails team disclosed a potential remote code execution vulnerability in the way they handled rendering templates. A member of the nVisium team identified the vulnerability and provided a valuable write-up of the issue, assigned CVE-2016-0752. Ruby on Rails uses a <em>model, view, controller architecture (MVC)</em> design. In this design, the database <span epub:type="pagebreak" id="page_77"/>logic (the model) is separated from the presentation logic (the view) and the application logic (the controller). MVC is a common design pattern in programming that improves code maintainability.</p>&#13;
<p class="indent">In its write-up, the nVisium team explains how Rails controllers, which are responsible for the application logic, can infer what template file to render based on user-controlled parameters. Depending on how the site was developed, these user-controlled parameters might be passed directly to the <span class="literal">render</span> method responsible for passing data to the presentation logic. The vulnerability could occur from a developer passing the input to the <span class="literal">render</span> function, such as by calling the <span class="literal">render</span> method and <span class="literal">params[:template]</span> where the <span class="literal">params[:template]</span> value is the dashboard. In Rails, all parameters from an HTTP request are available to the application controller logic via the <span class="literal">params</span> array. In this case, a parameter <span class="literal">template</span> is submitted in the HTTP request and passed to the <span class="literal">render</span> function.</p>&#13;
<p class="indent">This behavior is noteworthy because the <span class="literal">render</span> method provides no specific context to Rails; in other words, it doesn’t provide a path or link to a specific file and just automagically determines which file should return content to the user. It’s able to do this because Rails strongly implements convention over configuration: whatever template parameter value is passed to the <span class="literal">render</span> function is used to scan for filenames to render content with. According to the discovery, Rails would first recursively search the application root directory <em>/app/views</em>. This is the common default folder for all files used to render content for users. If Rails couldn’t find a file using its given name, it scanned the application root directory. If it still couldn’t find the file, Rails scanned the server root directory.</p>&#13;
<p class="indent">Before CVE-2016-0752, a malicious user could pass <span class="literal">template=%2fetc%2fpasswd</span> and Rails would look for the file <em>/etc/passwd</em> in the views directory, then the application directory, and finally the server root directory. Assuming you were using a Linux machine and the file was readable, Rails would print your <em>/etc/passwd</em> file.</p>&#13;
<p class="indent">According to nVisium’s article, the search sequence Rails uses can also be used for arbitrary code execution when a user submits a template injection, such as <span class="literal">&lt;%25%3d`ls`%25&gt;</span>. If the site uses the default Rails template language ERB, this encoded input is interpreted as <span class="literal">&lt;%= `ls` %&gt;</span>, or the Linux command to list all files in the current directory. While the Rails team has fixed this vulnerability, you can still test for SSTI in case a developer passes user-controlled input to <span class="literal">render inline:</span> because <span class="literal">inline:</span> is used to supply ERB directly to the <span class="literal">render</span> function.</p>&#13;
<h4 class="h4" id="ch08lev2sec3"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Understanding how the software you’re testing works will help you uncover vulnerabilities. In this case, any Rails site was vulnerable if it was passing user-controlled input to the <span class="literal">render</span> function. Understanding the design patterns Rails uses undoubtedly helped to uncover this vulnerability. As with the template parameter in this example, be on the lookout for opportunities that arise when you control input that might be directly related to how content is being rendered.</p>&#13;
<h3 class="h3" id="ch08lev1sec6"><span epub:type="pagebreak" id="page_78"/><strong>Unikrn Smarty Template Injection</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> N/A</p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/164224/">https://hackerone.com/reports/164224/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> August 29, 2016</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $400</p>&#13;
<p class="noindent">On August 29, 2016, I was invited to the then-private bug bounty program for Unikrn, an eSports betting site. During my initial site reconnaissance, the Wappalyzer tool I was using confirmed that the site was using AngularJS. This discovery raised a red flag for me because I’d been successful at finding AngularJS injection vulnerabilities. I began looking for CSTI vulnerabilities by submitting <span class="literal">{{7*7}}</span> and looking for the number <span class="literal">49</span> rendered, beginning with my profile. Although I wasn’t successful on the profile page, I noticed you could invite friends to the site, so I also tested that functionality.</p>&#13;
<p class="indent">After submitting an invitation to myself, I received the odd email shown in <a href="ch08.xhtml#ch08fig03">Figure 8-3</a>.</p>&#13;
<div class="image"><a id="ch08fig03"/><img alt="image" src="../images/08fig03.jpg"/></div>&#13;
<p class="figcap"><em>Figure 8-3: The email I received from Unikrn with a Smarty error</em></p>&#13;
<p class="indent">The beginning of the email included a stack trace with a Smarty error that showed <span class="literal">7*7</span> was not recognized. It looked as though <span class="literal">{{7*7}}</span> was being injected into the template, and Smarty was trying to evaluate the code but didn’t recognize <span class="literal">7*7</span>.</p>&#13;
<p class="indent">I immediately consulted James Kettle’s indispensable article on template injection (<em><a href="http://blog.portswigger.net/2015/08/server-side-template-injection.html">http://blog.portswigger.net/2015/08/server-side-template-injection.html</a></em>) to test the Smarty payload he referenced (he also provides a great Black Hat presentation available on YouTube). Kettle specifically referenced <span epub:type="pagebreak" id="page_79"/>the payload <span class="literal">{self::getStreamVariable("file:///proc/self/loginuuid")}</span>, which calls the method <span class="literal">getStreamVariable</span> to read the file <em>/proc/self/loginuuid</em>. I tried the payload he shared but received no output.</p>&#13;
<p class="indent">Now I was skeptical of my finding. But then I searched the Smarty documentation for its reserved variables, which included the <span class="literal">{$smarty.version}</span> variable that returns the version of Smarty being used. I changed my profile name to <span class="literal">{$smarty.version}</span> and reinvited myself to the site. The result was an invitation email that used 2.6.18 as my name, which was the Smarty version installed on the site. My injection was being executed, and my confidence was restored.</p>&#13;
<p class="indent">When I continued to read the documentation, I learned that you can use the tags <span class="literal">{php} {/php}</span> to execute arbitrary PHP code (Kettle specifically mentions these tags in his article, but I had completely missed them). So, I tried the payload <span class="literal">{php}print "Hello"{/php}</span> as my name and submitted the invite again. The resulting email stated that Hello had invited me to the site, confirming that I had executed PHP’s <span class="literal">print</span> function.</p>&#13;
<p class="indent">As a final test, I wanted to extract the <em>/etc/passwd</em> file to demonstrate the potential of this vulnerability to the bounty program. Although the <em>/etc/passwd</em> file isn’t critical, accessing it is commonly used as a flag to demonstrate remote code execution. So I used the following payload:</p>&#13;
<p class="programs">{php}$s=file_get_contents('/etc/passwd');var_dump($s);{/php}</p>&#13;
<p class="indent">This PHP code opens the <em>/etc/passwd</em> file, reads its contents using <span class="literal">file_get_contents</span>, and assigns the contents to the <span class="literal">$s</span> variable. Once <span class="literal">$s</span> is set, I dump the contents of that variable using <span class="literal">var_dump</span>, expecting the email I receive will include the contents of <em>/etc/passwd</em> as the name of the person who invited me to the Unikrn site. But strangely enough, the email I received had a blank name.</p>&#13;
<p class="indent">I wondered whether Unikrn was limiting the length of names. This time I searched the PHP documentation for <span class="literal">file_get_contents</span>, which detailed how to limit the amount of data read at a time. I changed my payload to the following:</p>&#13;
<p class="programs">{php}$s=file_get_contents('/etc/passwd',NULL,NULL,0,100);var_dump($s);{/php}</p>&#13;
<p class="indent">The key parameters in this payload are <span class="literal">'/etc/passwd'</span>, <span class="literal">0</span>, and <span class="literal">100</span>. The path refers to the file to read, <span class="literal">0</span> instructs PHP where to start in the file (in this case at the beginning of the file), and <span class="literal">100</span> denotes the length of data to read. I reinvited myself to Unikrn using this payload, which produced the email shown in <a href="ch08.xhtml#ch08fig04">Figure 8-4</a>.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_80"/><a id="ch08fig04"/><img alt="image" src="../images/08fig04.jpg"/></div>&#13;
<p class="figcap"><em>Figure 8-4: The Unikrn invitation email showing contents of the</em> /etc/passwd <em>file</em></p>&#13;
<p class="indent">I successfully executed arbitrary code and, as proof of concept, extracted the <em>/etc/passwd</em> file 100 characters at a time. After I submitted my report, the vulnerability was fixed within the hour.</p>&#13;
<h4 class="h4" id="ch08lev2sec4"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Working on this vulnerability was great fun. The initial stack trace was a red flag that something was wrong, and as the saying goes, “Where there’s smoke, there’s fire.” If you find a potential SSTI, always read the documentation to determine how best to proceed—and be persistent.</p>&#13;
<h3 class="h3" id="ch08lev1sec7"><strong>Summary</strong></h3>&#13;
<p class="noindent">When you’re searching for vulnerabilities, it’s best to try to confirm the underlying technology (be it a web framework, frontend rendering engine, or something else) to identify possible attack vectors and ideas to test. The variety of template engines makes it difficult to determine what will and won’t work in all situations, but knowing which technology is being used will help you overcome that challenge. Be on the lookout for opportunities that arise when text you control is being rendered. Also, keep in mind that vulnerabilities might not be immediately apparent but could still exist in other functionality, such as in emails.</p>&#13;
</body></html>