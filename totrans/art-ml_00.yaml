- en: INTRODUCTION
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Machine learning! With such a science fiction-ish name, one might expect it
    to be technology that is strictly reserved for highly erudite specialists. Not
    true.
  prefs: []
  type: TYPE_NORMAL
- en: Actually, machine learning (ML) can easily be explained in commonsense terms,
    and anyone with a good grasp of charts, graphs, and the slope of a line should
    be able to both understand and productively *use* ML. Of course, as the saying
    goes, “The devil is in the details,” and one must work one’s way through those
    details. But ML is not rocket science, in spite of it being such a powerful tool.
  prefs: []
  type: TYPE_NORMAL
- en: 0.1 What Is ML?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ML is all about prediction. Does a patient have a certain disease? Will a customer
    switch from her current cell phone service to another? What is actually being
    said in this rather garbled audio recording? Is that bright spot observed by a
    satellite a forest fire or just a reflection?
  prefs: []
  type: TYPE_NORMAL
- en: We predict an *outcome* from one or more *features*. In the disease diagnosis
    example, the outcome is having the disease or not, and the features may be blood
    tests, family history, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'All ML methods involve a simple idea: similarity. In the cell phone service
    example, how do we predict the outcome for a certain customer? We look at past
    customers and select the ones who are most similar in features (size of bill,
    lateness record, yearly income, and so on) to our current customer. If most of
    those similar customers bolted, we predict the same for the current one. Of course,
    we are not guaranteed that outcome, but it is our best guess.'
  prefs: []
  type: TYPE_NORMAL
- en: 0.2 The Role of Math in ML Theory and Practice
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many ML methods are based on elegant mathematical theory, with support vector
    machines (SVMs) being a notable example. However, knowledge of this theory has
    very little use in terms of being able to apply SVM well in actual applications.
  prefs: []
  type: TYPE_NORMAL
- en: To be sure, a good *intuitive* understanding of how ML methods work is essential
    to effective use of ML in practice. This book strives to develop in the reader
    a keen understanding of the intuition, *without using advanced mathematics*. Indeed,
    there are very few equations in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 0.3 Why Another ML Book?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many great ML books out there, of course, but none really *empower*
    the reader to use ML effectively in real-world problems. In many cases, the problem
    is that the books are too theoretical, but I am equally concerned that the applied
    books tend to be “cookbooks” (too “recipe-oriented”) that treat the subject in
    a Step 1, Step 2, Step 3 manner. Their focus is on the syntax and semantics of
    ML software, with the result that while the reader may know the software well,
    the reader is not positioned to *use* ML well.
  prefs: []
  type: TYPE_NORMAL
- en: 'I wrote this book because:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a need for a book that *uses* the R language but is not *about* R.
    This is a book on ML that happens to use R for examples and not a book about the
    use of R in ML.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a need for an ML book that recognizes that *ML is an art, not a science.*
    (Hence the title of this book.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a need for an ML book that avoids advanced math but addresses the point
    that, in order to use ML effectively, *one does need to understand the concepts
    well—the why and how of ML methods.* Most “applied” ML books do too little in
    explaining these things.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'All three of these bullets go back to the “anti-cookbook” theme. My goal is,
    then, this:'
  prefs: []
  type: TYPE_NORMAL
- en: I would like those who use ML to not only know the definition of random forests
    but also be ready to cogently explain how the various hyperparameters in random
    forests may affect overfitting. MLers also should be able to give a clear account
    of the problems of “p-hacking” in feature engineering.
  prefs: []
  type: TYPE_NORMAL
- en: We will *empower* the reader with strong, *practical*, real-world knowledge
    of ML methods—their strengths and weaknesses, what makes them work and fail, what
    to watch out for. We will do so without much formal math and will definitely take
    a hands-on approach, using prominent software packages on real datasets. But we
    will do so in a savvy manner. We will be “informed consumers.”
  prefs: []
  type: TYPE_NORMAL
- en: 0.4 Recurring Special Sections
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are special recurring themes and sections throughout this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bias vs. Variance**'
  prefs: []
  type: TYPE_NORMAL
- en: Numerous passages explain in concrete terms—no superstition!—how these two central
    notions play out for each specific ML method.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pitfalls**'
  prefs: []
  type: TYPE_NORMAL
- en: Numerous sections with the “Pitfall” title warn the reader of potential problems
    and show how to avoid them.
  prefs: []
  type: TYPE_NORMAL
- en: 0.5 Background Needed
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What kind of background will the reader need to use this book profitably?
  prefs: []
  type: TYPE_NORMAL
- en: No prior exposure to ML or statistics is assumed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As to math in general, the book is mostly devoid of formal equations. As long
    as the reader is comfortable with basic graphs, such as histograms and scatterplots,
    and simple algebra notions, such as the slope of a line, that is quite sufficient.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The book does assume some prior background in R coding, such as familiarity
    with vectors, factors, data frames, and functions. The R command line (> prompt,
    Console in RStudio) is used throughout. Readers without a background in R, or
    those wishing to have a review, may find my `fasteR` tutorial useful: [*https://github.com/matloff/fasteR*](https://github.com/matloff/fasteR).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Make sure R and the `qeML` package are installed on your computer. For the
    package, the preferred installation source is GitHub, as it will always have the
    most up-to-date version of the package. You’ll need the `devtools` package; if
    you don’t already have it, type:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, to install `qeML`, type:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `qeML` package will also be on the CRAN R code repository but updated less
    frequently.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**0.6 The qe*-Series Software**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Most of the software used here will come from popular R packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '`e1071`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gbm`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`glmnet`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`keras`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`randomForest`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Readers can use these packages directly if they wish. But in order to keep
    things simple and convenient for readers, we usually will be using wrappers for
    the functions in those packages, which are available in my package, `qeML`. This
    is a big help in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: The wrappers provide a uniform interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That uniform interface is also ***simple***.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For instance, consider `day1`, a bike rental dataset used at various points
    in this book. We wish to predict `tot`, total ridership. Here’s how we would do
    that using random forests, an ML topic covered in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: For support vector machines, another major topic, the call would be
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: and so on. Couldn’t be simpler! No preparatory code, say, to define a model;
    just call one of the `qe` functions and go! The prefix `qe`- stands for “quick
    and easy.” One can also specify method-specific parameters, which we will do,
    but still, it will be quite simple.
  prefs: []
  type: TYPE_NORMAL
- en: For very advanced usage, this book shows how to use those packages directly.
  prefs: []
  type: TYPE_NORMAL
- en: 0.7 The Book’s Grand Plan
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here is the path we’ll take. The first three chapters introduce general concepts
    that recur throughout the book, as well as specific machine learning methods.
    The rough description of ML above—predict on the basis of similar cases—is most
    easily developed using an ML method known as *k-nearest neighbors (k-NN)*. [Part
    I](part1.xhtml) of the book will play two roles. First, it will cover k-NN in
    detail. Second, it will introduce the reader to general concepts that apply to
    all ML methods, such as choice of *hyperparameters*. In k-NN, the number of similar
    cases, usually denoted *k*, is the hyperparameter. For k-NN, what is the “Goldilocks”
    value of *k*—not too small and not too large? Again, choice of hyperparameters
    is key in most ML methods, and it will be introduced via k-NN.
  prefs: []
  type: TYPE_NORMAL
- en: '[Part II](part2.xhtml) will then present a natural extension of k-NN, *tree-based
    methods*, specifically *random forests* and *gradient boosting*. These methods
    work in a flowchart-like manner, asking questions about features one at a time.
    In the disease diagnosis example given before, the first question might be, Is
    the patient over age 50? The next might be something like, Is the patient’s body
    mass index below 20.2? In the end, this process partitions the patients into small
    groups in which the members are similar to each other, so it’s like k-NN. But
    the groups do take different forms from k-NN, and tree methods often outperform
    k-NN in prediction accuracy and are considered a major ML tool.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Part III](part3.xhtml) discusses methods based on linear relationships. Readers
    who have some background in linear regression analysis will recognize some of
    this, though again, no such background is assumed. This part closes with a discussion
    of the *LASSO* and *ridge regression*, which have the tantalizing property of
    deliberately shrinking down some classical linear regression estimates.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Part IV](part4.xhtml) involves methods based on separating lines and planes.
    Consider again the cell phone service example. Say we plot the data for the old
    customers who left the service using the color blue in our graph. Then on the
    same graph, we plot those who remained loyal in red. Can we find a straight line
    that separates most of the blue points from most of the red points? If so, we
    will predict the action of the new customer by checking which side of the line
    his case falls on. This description not only fits *SVM* but also fits, in a sense,
    the most famous ML method, *neural networks*, which we cover as well.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, [Part V](part5.xhtml) introduces several specific types of ML applications,
    such as *image classification*.
  prefs: []
  type: TYPE_NORMAL
- en: It’s often said that no one ML method works best in all applications. True,
    but hopefully this book’s structure will impart a good understanding of similarities
    and differences between the methods, appreciating where each fits in the grand
    scheme of things.
  prefs: []
  type: TYPE_NORMAL
- en: There is a website for the book at [*http://heather.cs.ucdavis.edu/artofml*](http://heather.cs.ucdavis.edu/artofml),
    which contains code, errata, new examples, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 0.8 One More Point
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In reading this book, keep in mind that *the prose is just as important as the
    code.* Avoid the temptation to focus only on the code and graphs. A page that
    is all prose—no math, no graphs, and no code—may be one of the most important
    pages in the book. It is there that you will learn the all-important *why* of
    ML, such as why choice of hyperparameters is so vital. The prose is crucial to
    your goal of becoming adept at ML with the most insight and predictive power!
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that those dazzling ML successes you’ve heard about come only after
    careful, lengthy tuning and thought on the analyst’s part, requiring real insight.
    This book aims to develop that insight. Formal math is minimized here, but note
    that this means the math will give way to prose that describes many key issues.
  prefs: []
  type: TYPE_NORMAL
- en: So, let’s get started. Happy ML-ing!
  prefs: []
  type: TYPE_NORMAL
