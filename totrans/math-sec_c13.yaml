- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Delivering Python Applications
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: Once you feel you’ve met the requirements for a minimum viable product, it’s
    time to focus on the delivery pipeline. A *delivery pipeline* defines how your
    users will get your application and any future updates. Truthfully, I tend to
    start my projects by defining these attributes, as they can make some development
    choices more or less advantageous. For example, if you decide to deploy your application
    to the cloud, saving the data as local files doesn’t make as much sense as it
    would if you plan to deliver your code as a local package. In this chapter, we’ll
    take a high-level look at four potential delivery pipelines. Each method has a
    deep pool of resource material to help you deliver your project, so I’ll focus
    on the important considerations, strengths, and weaknesses of each method.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to discussing the delivery aspects of each method, I’ll talk about
    the removal process. One part of an MVP that people often neglect is the uninstall
    capability. Having a good, clean uninstall function for your application is, in
    my opinion, one of the keys to being a good software vendor. The objective for
    your uninstaller should be to leave nothing behind for the user to clean up. As
    you’ll see, some methods make this easier than others.
  prefs: []
  type: TYPE_NORMAL
- en: One major influence on which delivery method to choose is whether or not you
    plan to monetize access to the application, and how. For example, if you want
    to charge users a subscription fee, you probably want to skip to the sections
    “[Distributing with Cloud Microservices](#h1-502567c13-0003)” or “[Licensing with
    PyArmor](#h1-502567c13-0004),” both options that would allow you to define who
    has access to your application. The downside is that neither option is free, so
    if you don’t plan to charge for access to your application, it may be more cost-effective
    to distribute the application via GitHub using the setup script or prepackage
    the application with all the files needed to run the application.
  prefs: []
  type: TYPE_NORMAL
- en: Using Setup Scripts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The simplest choice for distributing a Python application is to use a special
    configuration script named *setup.py*, which configures the underlying system
    with the libraries and supporting files necessary to run the code. You’ve probably
    run into this method if you’ve installed a Python module after manually downloading
    a GitHub repository. More generally speaking, installing code packaged using this
    method requires your users to install a library called setuptools, which handles
    the installation based on the structure you define in the setup script. You can
    learn more about the structure and options for the setup scripts by reading the
    PyPi documentation ([https://pythonhosted.org/an_example_pypi_project/setuptools.html](https://pythonhosted.org/an_example_pypi_project/setuptools.html)).
  prefs: []
  type: TYPE_NORMAL
- en: The major benefit to using this method is that you can get your project hosted
    on PyPi, which will then allow your users to install it simply using the pip tool.
    When you install a project from PyPi, the pip tool pulls the appropriate version
    of your project from a storage location you define (most often, a public GitHub
    repository, although there are other options as well). Your users won’t need to
    manually download repositories or run setup scripts, all of which is handled in
    the background.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are some definite drawbacks to this method. First, it’s very
    difficult to monetize the code. There are no controls to stop a user from copying
    the source code to another machine. There’s also no native way to remove the code
    once it’s installed, which means even if you found a way to monetize access, you’d
    be limited to charging a one-time fee for lifetime access. There would be no way
    to enforce something like a subscription plan. Second, the setup script relies
    on your users installing the application from the command line. This is fine if
    you expect your users to be familiar with that process, but this isn’t the best
    choice for delivering applications to the general population. Finally, installing
    an application this way makes changes to the user’s underlying system. It installs
    the packages and configures them. While this works most of the time, making any
    changes to a system runs the risk of corrupting something, colliding with existing
    files, and so on. If the user doesn’t install your application in an isolated
    virtual environment, there’s the very real risk of running into incompatible library
    versions with some other application the user installed.
  prefs: []
  type: TYPE_NORMAL
- en: Removing applications installed with this method poses its own problems and
    usually requires the user to remove the requirements and other resources from
    their system. If you opt to go this route, I recommend pushing your users to use
    separate virtual environments. If the user hasn’t set up the application in an
    isolated virtual environment, trying to helpfully uninstall a dependency may break
    other applications on their system. On the other hand, if your users do install
    everything in its own virtual environment, uninstalling is as easy as deleting
    the environment.
  prefs: []
  type: TYPE_NORMAL
- en: I recommend using the setup script method for open source applications and smaller
    projects that aren’t backed by the resources for a more complex delivery pipeline.
    You can deploy a module and setup script to PyPi in a matter of minutes once you
    have an account. Setup scripts are also a good entry point for understanding more
    complex deployments, like cloud services, because at some level, all these methods
    need a way to understand what dependencies must be present for the code to function.
    Overall, this is a solid delivery method every Python developer should be familiar
    with.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging with Python Interpreters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next option aims to address some of the shortcomings of the setup script
    method by taking some work off the user. The idea is to package the code, support
    files, and the Python interpreter to run it into a single archive that can be
    delivered to the user. The user then simply needs to extract the archive to a
    directory on their system and they’re ready to run the application.
  prefs: []
  type: TYPE_NORMAL
- en: This allows for better monetization than the setup script. By hosting the packaged
    application download behind a website, you can charge users for each new version
    or you can charge a monthly subscription fee to the site that includes access
    to the latest versions for download. There’s still nothing to stop a user from
    paying once and keeping that version forever, but they also have incentive to
    maintain their account for access to the latest features.
  prefs: []
  type: TYPE_NORMAL
- en: To handle the packaging, I use PyInstaller, a free application to help collect
    the necessary files to make your program stand-alone, meaning able to run without
    configuring the underlying system. Packaging with this method is often called
    *freezing* an application because it collects a copy of the current version of
    all dependencies and the Python interpreter installed on the system, and then
    it packages them such that the included interpreter will use only those packaged
    libraries to operate. The advantage here is that you don’t need to worry about
    what version of a package is installed or whether it will conflict with other
    applications on the user’s machine. The disadvantage is that if you need to update
    one of the underlying libraries after freezing the application—for instance, to
    mitigate a security risk in one of the dependencies—it requires releasing a patch
    or a new build of the application for distribution. If a user doesn’t apply the
    patch or download the latest version (all too common), their system is left at
    risk.
  prefs: []
  type: TYPE_NORMAL
- en: The other drawback is the size of most frozen applications. To make sure the
    internal code functions properly, the entire standard library is usually frozen
    along with the other dependencies. The large code base and the Python interpreter
    mean that even simple applications may end up being multiple megabytes. PyInstaller
    does what it can to minimize the bloat, and you can configure it to reduce the
    weight even further, but ultimately there will always be additional bloat with
    this method.
  prefs: []
  type: TYPE_NORMAL
- en: Like energy, complexity doesn’t just disappear. Taking the complexity off the
    user means putting it onto yourself. For the frozen delivery method to work, you’ll
    need to create a different package for each type of system you want to support.
    For example, you may end up with one package named *agp_linux64_amd.tar.gz* intended
    for users on a 64-bit Linux system that has an AMD, one named *agp_win64_intel.zip*
    intended for users who have 64-bit Windows running on an Intel platform, and so
    on. To package each of these, you need access to a copy of the underlying OS that
    can be used to package the system files. To run the application during development,
    I use VirtualBox with a copy of each OS as a virtual machine preconfigured with
    the proper dependencies and version of Python. I like this method because it allows
    me to automate the build process for several platforms at once using the VirtualBox-manager
    application and some custom scripting ([https://www.virtualbox.org/wiki/Documentation](https://www.virtualbox.org/wiki/Documentation)).
  prefs: []
  type: TYPE_NORMAL
- en: 'For Windows, you face a unique circumstance. At the time of writing, some of
    the necessary drivers are protected by Microsoft licenses. Redistributing these
    libraries within your application without paying a licensing fee could be a breach
    of the Microsoft terms of service, and may even result in you being held liable
    for any perceived loss of revenue. The caveat is that if the end user already
    has a copy of the libraries (as is usually the case), then sending them the application
    wouldn’t violate the Microsoft agreement. Suffice to say: when and how you can
    deliver a prepackaged Python application for Windows is a bit of a gray area.
    Don’t interpret this as legal advice; I am not a lawyer. I insist you consult
    with an attorney in your area who specializes in intellectual property disputes
    around technology licenses. They’ll be able to help you steer clear of any legal
    risks.'
  prefs: []
  type: TYPE_NORMAL
- en: Freezing your application might be a good choice if you want to deliver a stand-alone
    version of it for users. The benefit of a stand-alone project is that it’s easy
    to set up and remove from a machine—uninstalling can be as simple as deleting
    a folder. In a lot of cases, frozen applications can even be run from a USB storage
    device, meaning you can carry it with you anywhere, and you won’t need to install
    the code on a system to use it!
  prefs: []
  type: TYPE_NORMAL
- en: Distributing with Cloud Microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deploying to the cloud means different things for different people. You could
    argue that hosting the packages from the previous messages using some data storage
    service (like Amazon’s S3 or Google’s Cloud Storage) and hosting the website in
    a virtual machine served by the same vendor constitutes a cloud deployment. It’s
    true that the delivery pipeline is a cloud service at that point, but the application
    itself would still be downloaded and run locally by the user, so I don’t consider
    it a true cloud service.
  prefs: []
  type: TYPE_NORMAL
- en: To me, a cloud deployment runs the majority of its functional code from infrastructure
    hosted by a service provider (like Google or Amazon), meaning your application
    is served to users in a functional state, rather than sending them source code
    to run. For the rest of the chapter, I’ll refrain from speaking about any one
    service provider. The two major global cloud providers, Google Cloud Platform
    (GCP) and Amazon Web Services (AWS), maintain approximately equivalent features,
    so I think it’s more beneficial to discuss the concepts generally. You can take
    these concepts and learn how to apply them using your particular provider.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than hosting code to download, the user will generally be given access
    to your software via a website of some sort. It’s possible to have a user-side
    application that acts as the interface to the cloud structure, but this is less
    common because it adds complexity to an already complex process. The code is broken
    up into small chunks called *microservices*, each of which handles one small part
    of the application.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 13-1](#figure13-1) shows a simplified microservice architecture for
    the AGP project.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c13/f13001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-1: Microservice architecture diagram'
  prefs: []
  type: TYPE_NORMAL
- en: Each oval represents a small part of the application run inside a virtual machine
    with just enough resources to execute the function and then disappear once it’s
    no longer needed. The key to a good microservice deployment lies in cleanly separating
    the functions into services and efficiently managing the communication between
    the services (the black arrows in the figure).
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 13-1](#figure13-1), I’ve divided the project into four services.
    The user interface is moved into a website that most likely uses HTML5 for the
    interactive drawing and JavaScript for communicating with the rest of the services.
    JSON is a good choice for the communication protocol since the communication between
    services is mostly handled using HTTP requests, and both languages involved (Python
    and JavaScript) handle the format easily. The Data Manager service holds the functions
    for saving and loading project data for users.
  prefs: []
  type: TYPE_NORMAL
- en: One limitation of a lot of microservice designs is that they lack a permanent
    filesystem to serve files from. You can overcome this by creating a persistent
    storage location, or you could make the storage location a persistent database
    instance. In fact, with a bit of ingenuity, you can make any network-accessible
    storage location work for this purpose. In any case, placing the Data Manager
    service between the other services and the storage container means the Data Manager
    is the only service that needs to know how to read and write from the Cloud Storage
    container. If you decide to migrate to a different method of storage later, you’ll
    only need to update one service.
  prefs: []
  type: TYPE_NORMAL
- en: The Graph builder service contains all of the functions for the application
    to manage the graph representation of a gallery. It communicates with both the
    User Web Interface (to take in the JSON data representing the graph) and the Data
    Manager (to save the information once completed). The Triangle Solver service
    contains the functions for managing the polygon representation of a gallery, including
    the code to ultimately solve each floor using the Triangle library. It also talks
    with the User Web Interface service and the Data Manager service to handle the
    input and output for the code.
  prefs: []
  type: TYPE_NORMAL
- en: Docker is great for microservices because it allows you to configure each virtual
    machine to contain only the pieces necessary to run the service’s code, making
    them faster to create and more secure to operate. You can use Docker containers
    to define these tiny machines on most cloud providers ([https://docs.docker.com](https://docs.docker.com)).
    Furthermore, you can use a container orchestration platform like Kubernetes to
    automatically manage the creation and deletion of each service container as needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Automatically creating more instances of your application to serve to users
    is called *horizontal scaling*. Taking advantage of the horizontal scaling capabilities
    of your platform will allow your application to seamlessly adapt to changes in
    processing needs. You can define rules for each service individually, meaning
    you’ll scale only the parts of the application that need to and leave the rest
    alone. For example, suppose your application has 20 users who simultaneously request
    the solution for different floor plans. With a traditional architecture, the Triangle
    service would have to handle all 20 requests, so the last user in the queue will
    have a longer wait than the first. With horizontal scaling, the orchestration
    engine will see the increase in demand and add 19 more copies of the Triangle
    Solver service. The additional copies all run in parallel, so all the requests
    can be handled simultaneously. On the other hand, 20 users on a web server is
    usually fine, so you wouldn’t want the orchestration platform to add more copies
    of the User Interface Service. By configuring automated horizontal scaling rules
    for each service individually, you can save yourself hours of maintenance down
    the road. This is the third form of parallelism you can take advantage of: *hardware
    parallelism.* It’s similar to process parallelism, discussed in [Chapter 12](c12.xhtml),
    but the work is spread across different machines instead of different cores on
    the same machine.'
  prefs: []
  type: TYPE_NORMAL
- en: The cloud microservices method is probably the most complex to achieve initially,
    but the benefits are also numerous. We’ve already seen how its flexibility can
    allow for quick iterations and reduce maintenance time. Another benefit is that
    you can easily monetize the application with much greater control. Since the source
    code is never sent to the end user, they must maintain their account to continue
    accessing the service. There’s usually little to nothing for the user to uninstall
    if they choose to stop using the service as well. All a user needs to do is terminate
    their account and the service is gone, making it the cleanest exit method from
    this perspective.
  prefs: []
  type: TYPE_NORMAL
- en: You can run multiple versions of the application to serve users at your discretion.
    Most cloud service providers offer application layer traffic routing, which allows
    you to intelligently direct traffic to different copies of your application based
    on some rules you define. Kubernetes also has some traffic routing capabilities
    that can be used to achieve the same effect. You can use the traffic routing ability
    to selectively beta-test changes before distributing them to all users or to define
    separate testing and production versions (called *A/B* or *blue/green testing*).^([1](b01.xhtml#c13-endnote-001))
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, updates are entirely under your control. Users automatically have
    access to the newest production version as soon as you update it. Typically, microservices
    are built in several stages. The stages can vary from project to project but roughly
    follow these phases: code push, continuous integration testing, Docker container
    build, and finally, service deployment. The code push is probably already familiar
    to you. It occurs when you push some changes to the code repositories (for example,
    with the command `git push`). Pushing the code triggers the continuous integration
    tests. These tests are designed to ensure that you don’t introduce any common
    bugs with your changes ([https://circleci.com/blog/proactive-integration-testing](https://circleci.com/blog/proactive-integration-testing)).'
  prefs: []
  type: TYPE_NORMAL
- en: The major drawback is the monetary and time costs associated with building and
    maintaining the network of services required to make the application behave seamlessly
    for users. Each cloud provider comes with its own unique way of implementing the
    pieces, and the pieces themselves require you to understand auxiliary applications
    like Docker and Kubernetes to work. If you decide to deploy your application in
    the cloud, you’ll need to spend some time learning the idiosyncrasies of the platform
    you choose. It also doesn’t hurt to have a development team to support your cloud
    deployment efforts.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can’t expect to become an expert in all the different components necessary
    for a solid cloud deployment pipeline. I’ve been lucky through my career to have
    the pleasure of working with some of the best cloud engineers in the field, and
    what I learned was the value of a strong team made up of different specialists.
    Having someone who can focus on the architecture while another person focuses
    on the user interface while a third writes the main service code means the work
    can get done much quicker; this is parallel development. Having a team also allows
    each person to maintain focus on the areas where they are most knowledgeable,
    and your project to benefit from the added expertise. Of course, running a development
    team brings its own host of problems: conflicting personalities, failures on delivery
    dates, and so on. Deciding to use a development team means you also need someone
    who will be responsible for communication and coordination among the team members^([2](b01.xhtml#c13-endnote-002))
    (called the *project manager*). Cloud deployments are at the heart of all modern
    software-as-a-service (SaaS) companies because the long-term benefits far outweigh
    the initial development cost. Of course, cloud deployments may not be the best
    choice for a small project with only a few planned users.'
  prefs: []
  type: TYPE_NORMAL
- en: Licensing with PyArmor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next method is a bit of an oddball. PyArmor is a command line tool for obfuscating
    Python source code. It’s conceptually similar to the stand-alone application in
    the sense that you still deliver an executable to your users, but PyArmor tries
    to ensure that your Python applications are saved and run only from approved machines
    in an attempt to protect your intellectual property and help monetize executables
    you deliver to your users. *Obfuscation* is the process of hiding the structure
    and operation of the code to render the application inoperable without the proper
    de-obfuscation technique. An example of obfuscation might be changing the string
    `"Hello from PyArmor"` to something like `"H7ejl8l3ocb1fRr4osm9blPjy9Afr4mvo0rp"`.
    The application obfuscates constants and literal strings as well as the runtime
    code of each function. If someone attempts to read your source code, either at
    rest or in memory, they’ll be met by a wall of gibberish.
  prefs: []
  type: TYPE_NORMAL
- en: Obfuscating your application’s source code also enables you to bind your application
    to a single machine and expire the application remotely. Your code is hidden behind
    a startup application that contains the proper de-obfuscation technique. PyArmor
    startup scripts check for a license file that was created when the user installed
    your application. The license file uses some unique machine attributes to ensure
    it’s run on the same machine at each start.
  prefs: []
  type: TYPE_NORMAL
- en: You can also define a license server that manages the validity of each license.
    On each start, your application calls out to the license server with its license
    identifier. Your server can then respond with an authenticated message saying
    whether or not the application should allow itself to execute. Of course, this
    relies on your user having network access every time they want to run your software,
    which may or may not make sense for your project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Obfuscation shouldn’t be confused with encryption, and it certainly doesn’t
    offer the security of a strong encryption scheme. With encryption, you have some
    mathematical proof of security using some form of secret information. The bigger
    and harder to guess that secret is, the more secure the application. Obfuscation,
    on the other hand, is more like camouflage: it’s meant to hide the code from casual
    attempts at reverse engineering or bypassing the license restrictions. But once
    someone understands how the code has been obfuscated, they can always reverse
    the process. Going back to my previous example, if you examined the second string
    more closely, you may have realized that all I did was insert random characters
    between the letters of the phrase. Next, I replaced the spaces with a constant
    character, `b`. By reversing this process, replacing the even-numbered `b` characters
    with spaces and stripping every other character out, you can convert the jumbled
    string back to the original phrase. As if that weren’t bad enough, the part of
    the startup script that handles the de-obfuscation can’t be obfuscated itself,
    meaning the technique used is available to anyone who wishes to look for it. (If
    it could be obfuscated, you’d create a feedback loop as you’d need a de-obfuscator
    for the de-obfuscator.) To borrow a phrase used in the lock-picking world: “It’s
    good enough to keep honest people honest.” Depending on the level of obfuscation,
    this may only hinder a talented reverse engineer by a couple hours.'
  prefs: []
  type: TYPE_NORMAL
- en: Although there are some obvious limitations, I wouldn’t completely dismiss PyArmor
    either. PyArmor may make a good addition if you plan to monetize the stand-alone
    package delivery method because it does add some control and monitoring to the
    process. You can’t guarantee your controls won’t be bypassed, but it certainly
    makes it less likely than a stand-alone application without obfuscation and licensing
    applied. Another potential use for PyArmor’s licensing is tracking the number
    of active users. Even if you don’t plan to monetize your project, having a license
    in place allows you to approximate the number of users by looking at which licenses
    have checked in (meaning the application was started). As your project gains popularity,
    you can use these estimates to gain investor interest or potentially sell your
    project to a larger SaaS provider.
  prefs: []
  type: TYPE_NORMAL
- en: Open Source Delivery
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There’s no better place to finish than with the option of open source delivery.
    By far the easiest method to deliver your project and to give back to the community
    is to openly license the source code for your project to everyone. By design,
    open source software licenses promote collaboration and sharing as they permit
    other people to make modifications to source code and incorporate those changes
    into their own projects. By hosting your code base on a public GitHub repository
    (or similar), you get the benefits of crowd-sourcing development, getting feedback
    from potential users, reducing hosting costs, and more. Open source projects promote
    collaboration from diverse perspectives. Different people from around the globe
    can come together and contribute. People have different and unique ways of solving
    problems, so including contributions from people with diverse backgrounds can
    push your project to a level of functionality you never would have achieved on
    your own, even with a traditional development team.
  prefs: []
  type: TYPE_NORMAL
- en: One common misconception is that “open source” automatically means you can’t
    monetize your application. This isn’t true at all! While it’s true that most open
    source projects aren’t started for money, maintaining a large open source project—Kubernetes,
    for instance—is a lot of work! It takes several full-time developers who probably
    want to get paid for their time, so open source projects will often spawn successful
    companies. Projects are often open-sourced in conjunction with a cloud delivery
    option to provide both a free and paid version. Companies will pay for these cloud-hosted
    versions to reduce the number of systems they have to maintain internally. Red
    Hat, the maintainer of one of the most popular Linux distributions for enterprise
    use, is one example of a large open source company that follows this model. While
    Red Hat continues to offer the open source version of many of its applications,
    it also offers paid customizations and remote support to maintain the business.
    In short, choosing to open-source your code often will reduce your stress and
    encourage a better result for your project, but you don’t have to sacrifice monetization.
    I highly recommend you research the open source route when considering delivery
    methods for your application.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deploying your application for general use can seem like a whole project in
    itself. As you’ve seen, there are several factors that should influence your choice
    of method. These include the number of users you plan to serve and whether you
    want to charge for access. As I said at the start of the chapter, you should start
    with the basic concept of the delivery platform in place when you begin your project.
    Once you’ve decided how to deliver your application, you can let the choice inform
    the rest of your development decisions, such as what storage options are available
    to your code.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you should have an idea of the available options and the positives
    and negatives of each. You can take these basics and learn more about the process
    that suits your needs best. Whatever method you choose, it’s important to remember
    to think from a user’s perspective as well as from a developer’s. Be kind to users
    and give them intuitive ways to install, manage, and remove your application.
  prefs: []
  type: TYPE_NORMAL
- en: The internet is filled with resources for learning about software deployment
    plans, ranging from the very simple to the exceedingly complex. There are also
    excellent books covering various deployment technologies like Docker and Kubernetes
    ([https://bookauthority.org/books/new-continuous-delivery-books](https://bookauthority.org/books/new-continuous-delivery-books)).
    I recommend starting small and working your way up. If you’ve never used Git,
    jumping into a cloud deployment right away is going to lead to frustration. Start
    with something like PyPi, which will allow you to hone your repository management
    skills. Once you’re comfortable with each of the underlying pieces, you’ll be
    better equipped to tackle the large cloud deployment process.
  prefs: []
  type: TYPE_NORMAL
- en: And with that, we’ve come to the end of the book! If you’ve tackled all the
    concepts and projects, I congratulate you! I hope you feel that you understand
    the role that applied mathematics can play in your security tools. If you take
    anything away from this book, I hope it’s the idea that you can tackle seemingly
    complex research topics with only a basic knowledge of math and an understanding
    of programming. Topics such as facial recognition, privacy monitoring, and social
    network analysis may be getting all the headlines at the moment, but the number
    of open research problems in the broader security field is huge, and they would
    all benefit from a talented and dedicated researcher like you. If there’s a particular
    field that interests you, I encourage you to take the concepts you’ve learned
    and apply them to that field as well. The fields covered in the book all lend
    themselves incredibly well to multiple areas of interest, and when you mix and
    match them, you can achieve some very powerful analysis tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'The scariest part of applying security to the real world, where a mistake could
    cost lives, is the need to make decisions in the face of uncertainty. Analysis
    tools like the ones presented in the previous chapters allow us to examine the
    world in different ways and to make the most informed decisions possible. You
    may not be able to remove uncertainty completely, but you can minimize its impact
    on yourself and those around you. Remember: security isn’t just a job or career
    path, but a way of understanding the world. The future of security applications
    lies in the accurate collection, interpretation, and response to data collected
    from our physical and digital environments to aid us in that understanding.'
  prefs: []
  type: TYPE_NORMAL
