- en: '**8'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MUSIC**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this chapter, we’ll continue exploring randomness in art with sound and
    music. We’ll begin generating sound via random samples, random walks through frequency
    space, and random walks up and down a musical scale. These projects will prepare
    us for the chapter’s most ambitious experiment: evolving pleasant melodies from
    scratch. While we can’t really quantify such a melody, that won’t stop us from
    trying.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating Random Sounds**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At first blush, generating a random sound seems straightforward. For instance,
    if we have some way of creating a sound file, like a WAV (*.wav* file extension),
    it follows that we should just need random sound samples at a specified playback
    rate—right? Let’s implement this, as it will introduce us to the audio tools we
    need for this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'WAV files are easy to read and write via SciPy’s `wavfile` module. To write
    a WAV file, we need two things: a specified sampling rate and the samples themselves
    in some range that programs like `mplayer` or Audacity will understand.'
  prefs: []
  type: TYPE_NORMAL
- en: We measure the sampling rate, the speed with which the samples are played back,
    in samples per second. The higher the sampling rate, the better the audio quality.
    A sampling rate of 22,050 Hz (cycles per second) is sufficient for our purposes.
    This is half the rate of a compact disc.
  prefs: []
  type: TYPE_NORMAL
- en: The samples are quantized voltages, a continuous range partitioned into a specified
    number of discrete steps, with each discrete value specifying a particular analog
    voltage level. The discrete samples correspond to the output audio waveform. Samples
    are usually 16-bit signed integers, but we’ll work with 32-bit floating-point
    samples in the range [–1, 1]. Most audio programs will have little difficulty
    with floating-point samples.
  prefs: []
  type: TYPE_NORMAL
- en: To make random sounds, we need to generate random samples, set up the WAV output,
    and write the samples to disk for playback. Let’s give it a go and hear what happens.
    The code we want is in *random_sounds.py*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run it first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Play the three-second output file, *tmp.wav*. I recommend turning down the volume
    first. Did you hear what you expected to? Consider [Listing 8-1](ch08.xhtml#ch08list01).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 8-1: Generating random samples*'
  prefs: []
  type: TYPE_NORMAL
- en: I excluded the usual message about the proper form for the command line to focus
    on the relevant code.
  prefs: []
  type: TYPE_NORMAL
- en: First, we import `wavwrite` from SciPy. I renamed `write` as `wavwrite` to clarify
    what the function does. Ignore the `WriteOutputWav` function for a moment.
  prefs: []
  type: TYPE_NORMAL
- en: The main part of the file fixes the sampling `rate` and reads the duration in
    seconds from the command line, along with the output WAV filename (`oname`), before
    calculating `nsamples`.
  prefs: []
  type: TYPE_NORMAL
- en: If the samples are played at a given `rate`, and we want a total `duration`
    in seconds, then the product, rounded to an integer, provides us with the number
    of samples we must generate. The `samples` are randomly selected in [–1, 1) using
    NumPy’s pseudorandom generator. There’s no point in using `RE` here.
  prefs: []
  type: TYPE_NORMAL
- en: All that remains is to use `WriteOutputWav` to create the output WAV file. We’ll
    use this function for all the experiments in this section. The first line rescales
    the samples to be in the range [0, 1], which lets us be a bit freer with how we
    generate samples. The second line changes from [0, 1] to [–1, 1], the valid range
    for floating-point samples. The last line uses `wavwrite` to dump the WAV file.
  prefs: []
  type: TYPE_NORMAL
- en: The output of *random_sounds.py* is so grating due to how humans perceive sound.
    We like sound that is represented as nice collections of sine waves summed together;
    in other words, tones with a fundamental frequency and overtones (harmonics).
    A random collection of unrelated samples can be represented only by summing a
    large number of sine waves.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-1](ch08.xhtml#ch08fig01) shows a sine wave at 440 Hz on the left
    and random noise on the right.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/08fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-1: Top left: a sine wave; top right: random noise; bottom left: the
    frequency spectrum of the sine wave; bottom right: random noise*'
  prefs: []
  type: TYPE_NORMAL
- en: The top of [Figure 8-1](ch08.xhtml#ch08fig01) shows the actual sound samples
    over time. The bottom shows the frequency spectrum, the strength of the various
    sine waves that go into the signal, so the *x*-axis is no longer time but frequency.
  prefs: []
  type: TYPE_NORMAL
- en: The sine wave is, fundamentally, a single frequency at 440 Hz. The energy at
    other frequencies is likely due to an imperfect approximation of the pure sine
    wave. The vertical scale is logarithmic, meaning there is very little energy outside
    of 440 Hz. The random noise spectrum, however, is roughly uniform over the entire
    frequency range up to 8,000 Hz, reflecting the number of sine waves that must
    be summed to approximate the random signal. The *x*-axis is similarly logarithmic.
  prefs: []
  type: TYPE_NORMAL
- en: The following two sections explore other approaches to random sound generation,
    both utilizing the idea of a random walk—not in space, but in frequency. We’ll
    produce sound using the sum of sine waves. The first section pays no attention
    to the mix of frequencies, while the second uses frequencies from the notes of
    a C major scale.
  prefs: []
  type: TYPE_NORMAL
- en: '***Sine Waves***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If we add two sine waves with different frequencies, they merge to become a
    new wave. Where the two sine waves are positive, they reinforce each other, and
    the resulting wave is more positive. When one is positive and the other negative,
    they cancel each other. For example, consider [Figure 8-2](ch08.xhtml#ch08fig02).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/08fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-2: Two sine waves (left) and their sum (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: On the left are two sine waves with frequencies in the ratio of 3:1\. On the
    right is the sum of the two sine waves on the left. Sum enough waves and any desired
    output waveform is possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code in *sine_walker.py* creates a collection of random walkers that each
    generate 0.5-second sine waves before altering the frequency used for the next
    0.5 seconds. For each 0.5-second block of time, the final wave is the sum of all
    the walkers. Let’s run the code and then walk through it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This should produce a 5-second output file consisting of three independent sine
    wave random walks. Give *walk.wav* a listen; it reminds me of sound effects in
    1950s science fiction movies.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *sine_walker.py* file parses the command line and then configures the values
    we need for the random walks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: First, we use `nsamples` to define `samples`, which holds all output. The next
    two lines define `dur`, the step duration, and `step_samp`, the number of samples
    in a step. Each sine wave, for a specific frequency, creates this many samples.
    Next, `fstep` sets the step size in Hertz, and `freq` is a vector of initial frequencies
    in [40, 840) Hertz. The double-definition handles the case where there’s only
    one walker.
  prefs: []
  type: TYPE_NORMAL
- en: We then loop until we have generated all samples. Each step is 0.5 seconds long,
    and each walker generates a sine wave with `step_samp` samples using its current
    frequency and a randomly chosen amplitude. We sum the walkers and assign the summed
    wave to the next 0.5 second’s worth of samples; see [Listing 8-2](ch08.xhtml#ch08list02).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 8-2: Generating sine wave walks*'
  prefs: []
  type: TYPE_NORMAL
- en: A `while` loop runs over all the output samples ➊. The next `for` loop ➋ is
    over all walkers for the current step. A random value decides whether to increment,
    decrement, or leave each walker’s frequency unchanged. Then a quick check with
    `min` and `max` keeps the frequency in the range [100, 4000].
  prefs: []
  type: TYPE_NORMAL
- en: A sine wave can be written as *y* = *A* sin *ωx* for amplitude *A* and frequency
    *ω* (omega). We select a random amplitude ➌ and use it to create a step’s worth
    of samples that are added to any existing samples, `t`, thereby summing across
    all the walkers for the current step.
  prefs: []
  type: TYPE_NORMAL
- en: Each step’s waveform begins at zero amplitude because the sine function starts
    at zero. Therefore, we want the end of the previous step to also be at zero amplitude.
    The second `while` loop ➍ attempts to scan from the end of the step waveform to
    find a sample reasonably close to zero.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we place the samples for the step in the output `samples` vector ➎
    if they fit. When `samples` is full, it’s clipped to keep samples above the 10th
    percentile and below the 90th, and then written to disk via `WriteOutputWav`.
  prefs: []
  type: TYPE_NORMAL
- en: Generate a 15-second or longer sample with one walker. Do you hear the walk?
    It might help to temporarily set `amp=1` to make each step equally loud. Use an
    app on your smartphone to show the frequency spectrum in real time.
  prefs: []
  type: TYPE_NORMAL
- en: What happens if you add more walkers? Examine the waveform for 50 walkers using
    a program like Audacity. It should start to resemble noise with little structure.
  prefs: []
  type: TYPE_NORMAL
- en: Making strange sounds with arbitrary combinations of sine waves is fun, but
    let’s see if we can be more musical in our approach.
  prefs: []
  type: TYPE_NORMAL
- en: '***C Major Scale***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The sine walker stepped in frequency by a fixed interval of 5 Hz. The code
    in *note_walker.py* is nearly identical to that in *sine_walker.py*, but instead
    of altering the frequency of the sine waves by a constant number of Hertz, the
    walk takes place over the frequencies of the notes in a C major scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this list, middle C is 261.63 Hz, and A above middle C is 440 Hz. The *note_walker.py*
    file uses the same command line as *sine_walker.py*. Read through the code and
    give it a go. Is the result the same as *sine_walker.py*? What instrument does
    the output remind you of?
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Electronic oscillators of various frequencies pieced together with other circuits
    to modulate the resulting final waveform were the backbone of early analog music
    synthesizers. We can emulate an analog synthesizer in software; see* [https://github.com/yuma-m/synthesizer](https://github.com/yuma-m/synthesizer).
    *It’s Python based, and the page provides complete instructions for installing
    dependencies. The examples on the GitHub page use sine waves as the base waveform,
    just as we used here.*'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s make the leap from randomly varying sine waves to evolving a melody from
    scratch.
  prefs: []
  type: TYPE_NORMAL
- en: '**Generating Melodies**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ll use swarms in the service of generating melodies, with the goal of creating
    a “pleasant” sounding melody from a clean slate.
  prefs: []
  type: TYPE_NORMAL
- en: First, we’ll set up our environment. Then we’ll learn how to use the program
    *melody_maker.py* to generate melodies. Finally, we’ll walk through the essential
    parts of the code. The objective function is quite a bit more complicated than
    what we’ve worked with previously.
  prefs: []
  type: TYPE_NORMAL
- en: '***Swarm Search***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We’ll use MIDI files in this section instead of directly generating WAV files.
    *MIDI (Musical Instrument Digital Interface)* is the standard format for digital
    music. It can be complicated, but our use is as simple as it gets: a single melody
    line. Therefore, for us, MIDI becomes a NumPy vector of pairs of numbers, the
    first a note number (60 is middle C), and then a duration where the ratio between
    the durations marks whole, half, quarter, eighth notes, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: The melodies we evolve are expressed, ultimately, as MIDI files. Therefore,
    we need additional software beyond the usual toolkit to play MIDI files, work
    with MIDI files in code, and turn a MIDI file into an image of the musical score.
    Let’s install `wildmidi`, `midiutil`, and `musescore3`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Install `wildmidi` with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `wildmidi` add-on plays MIDI files (*.mid*) from the command line. For macOS
    and Windows, see the main website at *[https://github.com/Mindwerks/wildmidi/releases](https://github.com/Mindwerks/wildmidi/releases)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need `midiutil` to work with MIDI files in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `midiutil` library reads and writes MIDI files, though we’ll only ever write
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, to generate sheet music of our evolved melodies, we will need `musescore3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Versions for macOS and Windows are available from the main site (*[https://musescore.org/en/download](https://musescore.org/en/download)*).
    If `musescore3` is not found, install the latest version (`musescore4`) and update
    *melody_maker.py* accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Once everything’s installed, we’re good to go. If you didn’t install `musescore3`,
    the code will still run, but you won’t get to see the final result visually.
  prefs: []
  type: TYPE_NORMAL
- en: '#### ***The melody_maker.py code***'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code we need to evolve melodies is in *melody_maker.py*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Many command line arguments are familiar or self-evident, like the number of
    notes in the melody. The `mode` argument refers to the musical mode or scale we
    want to use. Traditionally, there are seven modes, all of which are supported,
    plus the blues and the pentatonic (rock) scales. The other modes use their classical
    Greek names, or `major` or `minor` for standard major and minor keys. The mode
    names are in [Table 8-1](ch08.xhtml#ch08tab01) along with a sequence of intervals
    and words often associated with the mode. The intervals of [Table 8-1](ch08.xhtml#ch08tab01)
    refer to the steps between the notes of the scale with `H` a half step (semitone)
    and `W` a whole step (tone).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 8-1:** The Modes, Intervals, and Characteristics'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Mode** | **Intervals** | **Characteristics** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Ionian (major) | `W W H W W W H` | Bright, positive, strong, simple |'
  prefs: []
  type: TYPE_TB
- en: '| Aeolian (minor) | `W H W W H W W` | Sad |'
  prefs: []
  type: TYPE_TB
- en: '| Dorian | `W H W W W H W` | Light, cool, jazzy |'
  prefs: []
  type: TYPE_TB
- en: '| Lydian | `W W W H W W H` | Bright, airy, sharp |'
  prefs: []
  type: TYPE_TB
- en: '| Mixolydian | `W W H W W H W` | Celtic |'
  prefs: []
  type: TYPE_TB
- en: '| Phrygian | `H W W W H W W` | Dark, depressing |'
  prefs: []
  type: TYPE_TB
- en: '| Locrian | `H W W H W W W` | Darker still, “evil” |'
  prefs: []
  type: TYPE_TB
- en: 'For example, if the first note of a candidate melody is middle C (MIDI note
    60), and the desired mode is `major`, then the notes of the scale are:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0246-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The objective function will score a candidate melody, in part, by how closely
    it follows the desired scale.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re not familiar with music, scales, or music theory of any kind, have
    no fear. All we need to know is that there are different scales, or different
    sets of intervals between notes, that, when played, affect the sound of the melody.
    For example, melodies in a major scale (Ionian mode) sound bright, while those
    in a minor key (Aeolian mode) tend to sound sad. These rules are not hard and
    fast—just guidelines. We’ll generate many melodies in different modes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run *melody_maker.py*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: I didn’t specify a seed, so your run will be entirely different. The output
    tells us about the search, then spits out a long string of integers and floats.
    This is the evolved melody as written to the output MIDI file, which is in the
    *tmp* directory along with several other files, including a NumPy vector, a Python
    pickle file, and the score (`score.png`). The melody is in pairs, so the first
    note is (63,0.9), a dotted eighth note E-flat above middle C.
  prefs: []
  type: TYPE_NORMAL
- en: The output MIDI file is in *tmp* as well. Play it with `wildmidi`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: where `BARE` is replaced by whatever swarm algorithm we select. I chose `mixolydian`
    for the mode, so, in theory, the melody should sound somewhat “celtic.” Does it?
    I really don’t know.
  prefs: []
  type: TYPE_NORMAL
- en: The evolved melody is in *score.png*; see [Figure 8-3](ch08.xhtml#ch08fig03).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/08fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-3: An evolved melody*'
  prefs: []
  type: TYPE_NORMAL
- en: I glossed over the objective function value for the returned melody. We’ll explore
    that in more detail when we glance at the code. However, as with all our optimization
    experiments, lower is better.
  prefs: []
  type: TYPE_NORMAL
- en: Try experimenting with melodies, modes, algorithms, swarm sizes, and iterations
    of different lengths. More iterations generally lead to better performance, which
    should mean a better sounding melody, or, at least, a melody more faithful to
    the desired mode.
  prefs: []
  type: TYPE_NORMAL
- en: You might wish to run the examples in *melody_examples*. The file works as a
    shell script
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: and produces directories *ex0* through *ex8* inside *example_melodies* using
    different swarm algorithms and modes. I fixed the seeds, so you’ll hear what I
    heard, which hints at the range of possible outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections experiment with *melody_maker.py*. The first queries
    the melodies as they evolve, the second focuses on the algorithms to understand
    what sort of melodies they favor, and the last builds a library of melodies in
    four modes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Evolving a Melody**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s evolve a melody in a major scale using bare-bones PSO. This experiment
    aims to listen to the melody as it evolves. It should go from erratic and far
    from the desired mode to a tune that a beginning piano student might play (or
    so I’ve been told).
  prefs: []
  type: TYPE_NORMAL
- en: The file *evolve.py* runs *melody_maker.py* to evolve a major scale melody of
    20 notes using 20 particles and bare-bones PSO. The generator and seed are fixed;
    all that changes between runs is the number of iterations, which vary from a low
    of 1 to a high of 50,000, as in [Figure 8-4](ch08.xhtml#ch08fig04).
  prefs: []
  type: TYPE_NORMAL
- en: The fixed seed means that the best melody found for 10 iterations passed through
    the best found in 1 iteration. Each higher number of iterations tells us where
    any earlier iteration would have ended if it were left to run. In other words,
    the same initial configuration is allowed to evolve for a varying number of iterations.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/08fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-4: Progressive melodies. From top: 1, 1,000, 10,000, and 50,000 iterations.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The directory *evolve_results* contains the MIDI files and score images for
    each number of iterations: 1, 10, 100, 1,000, 5,000, 10,000, and 50,000\. I recommend
    using `wildmidi` to play the files. How does the melody found after 1 iteration
    of the swarm compare to that after 50,000? [Figure 8-4](ch08.xhtml#ch08fig04)
    shows the score for select melodies by iteration. While the early melodies are
    a mess, there is little change—other than the key—between the melody after 10,000
    iterations and after 50,000.'
  prefs: []
  type: TYPE_NORMAL
- en: The objective function value, which we have yet to understand, decreases as
    the number of iterations increases. This is, of course, all it can do, but the
    rate at which it decreases levels off after 1,000 iterations. The slight change
    in the score between 10,000 iterations and 50,000 implies that we may not want
    to run the search for too long, as we risk eliminating potentially exciting melodies
    in the process.
  prefs: []
  type: TYPE_NORMAL
- en: What, precisely, happens when a melody evolves? Swarm algorithms are initialized
    randomly over an appropriate range of MIDI note numbers and durations. The selected
    musical mode effectively alters the objective function used by the swarm as it
    searches. While the swarm search includes randomness, it is the initial configuration
    of the swarm that most strongly influences the final result—at least, that’s what
    I think is happening. The combination of initial swarm configuration, algorithm
    approach, and randomness leads to convergence on a melody that more or less fits
    the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exploring the Algorithms**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The *algorithms.py* file runs *melody_maker.py* 10 times for each of the 7 swarm
    algorithms we’ve used throughout the book. Each run generates a 36-note melody
    in the Lydian mode utilizing a swarm of 20 particles and 10,000 iterations. You
    can run this file to produce output in the *algorithms* directory. Alternatively,
    since the seed values are fixed, you can listen to the seven MP3 files that concatenate
    the output by algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Even though the algorithms are tasked with the same overall goal—learning a
    melody in the Lydian mode—hopefully the resulting melodies reveal distinctions
    between the algorithms. Let’s see whether it matters which swarm algorithm we
    use, and whether some produce “nicer” results than others.
  prefs: []
  type: TYPE_NORMAL
- en: 'I listened to all the MP3 files (made by using `wildmidi`’s `-o` option followed
    by `lame`) and ranked the resulting melodies by how nice I thought they sounded.
    Here’s my ranking from best to worst, including ties where I couldn’t choose one
    algorithm over another:'
  prefs: []
  type: TYPE_NORMAL
- en: Bare-bones PSO
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Genetic algorithm, PSO
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Differential evolution, Jaya
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GWO
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Random optimization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your ranking might be different, but I suspect you’ll agree that bare-bones
    PSO works best in this case and random optimization is the worst. Both GWO and
    random optimization produce rushed output; the melodies play faster, so the resulting
    MP3 files are about 30 seconds shorter than the other algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll perform one more experiment before exploring the code in which we use
    the “best” algorithm, bare-bones PSO, to create a library of songs in different
    modes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Building a Library of Melodies**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The file *songs.py* is similar to *algorithms.py*, but uses bare-bones PSO
    repeatedly to generate 36-note melodies in four modes: major, minor, Dorian, and
    blues. In this case, there are 32 particles in the swarm and 30,000 iterations.
    The code takes some time to run, so I created MP3 files of the output: *major.mp3*,
    *minor.mp3*, *dorian.mp3*, and *blues.mp3*. Give them a listen while keeping the
    descriptions of [Table 8-1](ch08.xhtml#ch08tab01) in mind. If you agree with them,
    it means the objective function has at least captured something of the modes,
    if not much of what makes a good melody.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Implementation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The time has come to explore *melody_maker.py*. At a high level, it’s no different
    from any of the other swarm optimization experiments: we parse the command line,
    initialize swarm framework objects, and call `Optimize` to perform the search.
    The result is then converted into a MIDI file object and written to disk.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s understand the structure of the swarm—the mapping between particle position
    and melody—and then walk through the objective function class, as that’s the heart
    of the process.
  prefs: []
  type: TYPE_NORMAL
- en: If we want *n* notes in a melody, each particle becomes a 2*n*-element vector,
    a collection of *n* pairs, (MIDI note number, duration). MIDI note numbers are
    restricted (see `MusicBounds`) to [57, 81] with 57 interpreted as a rest. Again,
    middle C on the piano is note 60, and each increment or decrement corresponds
    to a semitone. Durations are integers that we multiply by 0.3 when creating the
    MIDI file to control the tempo. The ratio between the notes matters so that duration
    4 is twice as long as duration 2, and so on. Particles, then, *are* the melody
    under consideration, and the search seeks to find, given the random initial collection
    of melodies and the particulars of the selected algorithm, a best melody as decided
    by the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Everything depends on the `MusicObjective` class. It’s rather elaborate, with
    more than 150 lines of code. I’ll start at the end, the `Evaluate` method, and
    then fill in the pieces—standard top-down design. Recall, the swarm uses the score
    to decide the quality of the melody. The lower it is, the better. Here’s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The score is a multipart function of the output from the `Distance`, `Durations`,
    `Intervals`, and `Leaps` methods. The respective values are summed but not equally
    weighted so that the output of `Distance` is four times as important as the output
    from the `Leaps` method. Each part of the final score is in the range [0, 1],
    with lower being better.
  prefs: []
  type: TYPE_NORMAL
- en: The `Distance` method measures the Hamming distance between the notes of the
    current melody (particle) and the notes expected for a melody in the given mode.
    The `ModeNotes` method returns two binary vectors where a 1 indicates that the
    corresponding note is in the mode. The first vector is for the current melody,
    and the second includes the notes in that mode, assuming the first note of the
    melody to be the root. In other words, `ModeNotes` returns two binary numbers
    expressed as vectors of 0s and 1s. The Hamming distance between two binary numbers
    is the number of differing bits. For example, the Hamming distance between 10110111
    and 10100101 is 2 because two corresponding bit positions differ. The `Distance`
    method scales the Hamming distance by the number of notes to return a value in
    [0, 1]; it’s deemed the most important part of the objective function because
    a good melody in a specified mode should consist mostly of notes in that mode.
  prefs: []
  type: TYPE_NORMAL
- en: The `Durations` method is an ad hoc measure using a scaled root squared error
    distance between the count of the different note durations in the melody and the
    preferred favoring of quarter and half notes. The idea is to minimize dotted notes.
  prefs: []
  type: TYPE_NORMAL
- en: The `Intervals` method is another ad hoc metric that looks at the spacing from
    one note in the melody to the next. We humans generally prefer major or minor
    thirds and fifths, meaning the interval from note *i* to note *i* + 1 should be
    3, 4, or 7 semitones.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `Leaps` tries to minimize leaps, or intervals between notes that exceed
    5 semitones. This competes with what `Intervals` is measuring, but `Leaps` is
    weighted half as much.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a high-level understanding of what the objective function measures,
    let’s look at the corresponding code and its essential parts.
  prefs: []
  type: TYPE_NORMAL
- en: '**Distance**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The `Distance` method uses the Hamming distance between the notes of the melody
    and the notes that should be in the melody if it conforms to the desired mode.
    Here’s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `ModeNotes` method, not shown, returns two lists where each element is 1
    if the corresponding note is in the melody (`A`) or belongs in the melody given
    the mode (`B`). The versions in `a` and `b` cover the given melody’s range.
  prefs: []
  type: TYPE_NORMAL
- en: The `score` variable holds the Hamming distance between `a` and `b`. The Hamming
    distance is the number of mismatched bit positions. Scaling by the length of the
    melody transforms the count into a fraction of the melody, [0, 1], which is returned.
  prefs: []
  type: TYPE_NORMAL
- en: '**Durations**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The `Durations` method calculates a score reflecting how closely the distribution
    of note durations matches the ad hoc predefined “best” mix that favors quarter
    and half notes. In code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: First, we set `d` to the durations of the current melody so that `bincount`
    can create the corresponding distribution, `b`, which is scaled to a probability.
    The desired mix of note durations is in `a` and likewise scaled to be a probability.
  prefs: []
  type: TYPE_NORMAL
- en: The sum of the squared distance between the two distributions is returned as
    the duration score.
  prefs: []
  type: TYPE_NORMAL
- en: '**Intervals**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The interval between two notes is measured in semitones. The `Intervals` method
    counts the number of major thirds (4 semitones), minor thirds (3 semitones), and
    fifths (7 semitones) in the melody and transforms those numbers into a score.
    In code this becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The code examines each pair of notes in the melody. We use the difference in
    semitones to count the number of thirds and fifths. We then assign `w` the weighted
    mean of these counts where, by fiat, I’m favoring thirds over fifths by 3 to 1.
  prefs: []
  type: TYPE_NORMAL
- en: The higher `w` is, the more the melody conforms to the desired interval arrangement;
    therefore, subtract the scaled `w` score from 1 to minimize.
  prefs: []
  type: TYPE_NORMAL
- en: '**Leaps**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The final part of the objective function score is `Leaps`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: A leap is any difference between a pair of notes that exceeds 5 semitones, either
    up or down. Smaller distances imply a smoother melody. We return the fraction
    of the melody that are leaps.
  prefs: []
  type: TYPE_NORMAL
- en: Why use these components in the objective function and not others? No reason
    other than a perusal of thoughts on what makes a good melody mentions some of
    these. Music is subjective, and it isn’t possible to create an objective objective
    function. “Exercises” on [page 254](ch08.xhtml#ch00lev1_53) asks you to think
    of other terms that might fit well in `MusicObjective`.
  prefs: []
  type: TYPE_NORMAL
- en: '**GENERATIVE AI**'
  prefs: []
  type: TYPE_NORMAL
- en: The discussions of generative art and music in [Chapters 7](ch07.xhtml) and
    [8](ch08.xhtml) make no mention of artificial intelligence, and thus are incomplete.
    However, throwing AI into the mix would turn these chapters into a book. Instead,
    I’ll point you toward AI-based examples of generative art and music. Most of these
    use *generative adversarial networks*, *deep style transfer*, *variational autoencoders*,
    or related techniques that depend on deep neural networks to either sample from
    some learned representation space or merge features from embedded representations
    to build new output from multiple inputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to explore what AI can do in this area, *[https://aiartists.org](https://aiartists.org)*
    is a good place to start and has links to artists and tools to make AI-based art
    and music. A fun, advanced approach to evolutionary algorithms and music is found
    in Al Biles’ GenJam at *[https://genjam.org](https://genjam.org)*. I recommend
    the video examples, especially the TEDx talk demonstrating and explaining the
    system. We’ve witnessed an explosion of powerful AI-based text, image, and video
    generation systems, including Stable Diffusion, DALL-E 2, and ChatGPT. New systems
    and updates appear weekly, but these should get you started:'
  prefs: []
  type: TYPE_NORMAL
- en: '**DALL-E 2**   *[https://openai.com/dall-e-2](https://openai.com/dall-e-2)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stable Diffusion**   *[https://beta.dreamstudio.ai/](https://beta.dreamstudio.ai/)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**ChatGPT**   *[https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like generative art, there’s no end to what we can do with generative music.
    Here are some exercises related to this chapter’s experiments.
  prefs: []
  type: TYPE_NORMAL
- en: Alter the clipping range in *sine_walker.py*. How does this affect the overall
    sound? What does the waveform look like in Audacity?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can change the key in *note_walker.py* by altering the frequency table.
    For example, to change from C major to D minor, flatten the B notes: 246.94 →
    233.08, 493.88 → 466.16, and 987.77 → 932.33.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last argument to `addProgramChange` in *melody_maker*’s `StoreMelody` function
    specifies the MIDI instrument number. The default is 0 for an acoustic piano.
    Change this number using the *MIDI_instruments.txt* list. For example, try 30
    for a distorted electric guitar or 13 for a xylophone. The oboe, barely breathing,
    is 68\. Or go for broke with 114, steel drums.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alter *melody_maker*’s objective function weighting in the `Evaluate` method.
    Does it sound as nice if all components are weighted the same? What happens if
    you reverse the weighting?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What other terms can you add to *melody_maker*’s objective function?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter introduced us to randomness in generative music beginning with
    audio and a random walk of sine waves to produce otherworldly sound effects. Restricting
    the frequencies to those of a musical scale transformed the odd sounds into something
    akin to a pipe organ.
  prefs: []
  type: TYPE_NORMAL
- en: We closed the chapter by evolving melodies from scratch using swarm intelligence
    and evolutionary algorithms. We were moderately successful in that the evolved
    melodies did, for the most part, conform to the desired musical mode. Along the
    way, we saw an example of how to create simple MIDI files in code.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll change gears in the next chapter to explore randomness in an entirely
    different domain: recovering a signal from a small collection of measurements.'
  prefs: []
  type: TYPE_NORMAL
