- en: '**INDEX**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**A**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: active learning, [195](ch30.xhtml#page_195), [203](ch30.xhtml#page_203)–[204](ch30.xhtml#page_204),
    [222](appendix.xhtml#page_222)
  prefs: []
  type: TYPE_NORMAL
- en: Adam optimizer, [42](ch07.xhtml#page_42), [73](ch11.xhtml#page_73), [211](appendix.xhtml#page_211),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  prefs: []
  type: TYPE_NORMAL
- en: adapter methods, [119](ch18.xhtml#page_119), [121](ch18.xhtml#page_121)–[123](ch18.xhtml#page_123),
    [125](ch18.xhtml#page_125)–[126](ch18.xhtml#page_126), [216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: Add & Norm step, [107](ch17.xhtml#page_107)
  prefs: []
  type: TYPE_NORMAL
- en: adversarial examples, [27](ch05.xhtml#page_27)
  prefs: []
  type: TYPE_NORMAL
- en: adversarial validation, [154](ch23.xhtml#page_154), [190](ch29.xhtml#page_190)–[191](ch29.xhtml#page_191),
    [218](appendix.xhtml#page_218), [221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: AI (artificial intelligence)
  prefs: []
  type: TYPE_NORMAL
- en: data-centric, [143](ch21.xhtml#page_143)–[146](ch21.xhtml#page_146), [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: model-centric, [143](ch21.xhtml#page_143)–[144](ch21.xhtml#page_144), [145](ch21.xhtml#page_145)
  prefs: []
  type: TYPE_NORMAL
- en: AlexNet, [6](ch01.xhtml#page_6), [7](ch01.xhtml#page_7)
  prefs: []
  type: TYPE_NORMAL
- en: asymptotic coverage guarantees, confidence intervals, [177](ch26.xhtml#page_177)
  prefs: []
  type: TYPE_NORMAL
- en: attention mechanism. *See also* self-attention mechanism
  prefs: []
  type: TYPE_NORMAL
- en: Bahdanau, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101), [103](ch16.xhtml#page_103),
    [112](ch17.xhtml#page_112)
  prefs: []
  type: TYPE_NORMAL
- en: transformers, [40](ch07.xhtml#page_40), [43](ch08.xhtml#page_43)–[45](ch08.xhtml#page_45),
    [46](ch08.xhtml#page_46), [47](ch08.xhtml#page_47)
  prefs: []
  type: TYPE_NORMAL
- en: augmented data
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting with, [24](ch05.xhtml#page_24)–[25](ch05.xhtml#page_25),
    [26](ch05.xhtml#page_26), [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: for text, [93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97), [214](appendix.xhtml#page_214)–[215](appendix.xhtml#page_215)
  prefs: []
  type: TYPE_NORMAL
- en: autoencoders
  prefs: []
  type: TYPE_NORMAL
- en: defined, [51](ch09.xhtml#page_51)
  prefs: []
  type: TYPE_NORMAL
- en: latent space, [5](ch01.xhtml#page_5)–[6](ch01.xhtml#page_6)
  prefs: []
  type: TYPE_NORMAL
- en: variational, [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
  prefs: []
  type: TYPE_NORMAL
- en: automatic prompt engineering method, [125](ch18.xhtml#page_125)
  prefs: []
  type: TYPE_NORMAL
- en: autoregressive decoding, [107](ch17.xhtml#page_107)–[110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: autoregressive models, [54](ch09.xhtml#page_54)–[55](ch09.xhtml#page_55), [57](ch09.xhtml#page_57),
    [63](ch10.xhtml#page_63)–[64](ch10.xhtml#page_64)
  prefs: []
  type: TYPE_NORMAL
- en: auxiliary tasks, [199](ch30.xhtml#page_199)
  prefs: []
  type: TYPE_NORMAL
- en: '**B**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: backpropagation, [115](ch18.xhtml#page_115)–[116](ch18.xhtml#page_116)
  prefs: []
  type: TYPE_NORMAL
- en: back translation, [96](ch15.xhtml#page_96)
  prefs: []
  type: TYPE_NORMAL
- en: bag-of-words model, [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: continuous bag-of-words (CBOW) approach, [90](ch14.xhtml#page_90)
  prefs: []
  type: TYPE_NORMAL
- en: Bahdanau attention mechanism, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101),
    [103](ch16.xhtml#page_103), [112](ch17.xhtml#page_112)
  prefs: []
  type: TYPE_NORMAL
- en: BART encoder-decoder architecture, [112](ch17.xhtml#page_112)
  prefs: []
  type: TYPE_NORMAL
- en: base classes in few-shot learning, [16](ch03.xhtml#page_16)
  prefs: []
  type: TYPE_NORMAL
- en: Basic Linear Algebra Subprograms (BLAS), [148](ch22.xhtml#page_148), [152](ch22.xhtml#page_152)
  prefs: []
  type: TYPE_NORMAL
- en: batched inference, [147](ch22.xhtml#page_147)–[148](ch22.xhtml#page_148)
  prefs: []
  type: TYPE_NORMAL
- en: batch normalization (BatchNorm), [73](ch11.xhtml#page_73), [213](appendix.xhtml#page_213)
  prefs: []
  type: TYPE_NORMAL
- en: Berry–Esseen theorem, [167](ch25.xhtml#page_167), [171](ch25.xhtml#page_171)
  prefs: []
  type: TYPE_NORMAL
- en: BERT model
  prefs: []
  type: TYPE_NORMAL
- en: adopting for classification tasks, [112](ch17.xhtml#page_112), [215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: distributional hypothesis, [91](ch14.xhtml#page_91), [92](ch14.xhtml#page_92)
  prefs: []
  type: TYPE_NORMAL
- en: encoder-only architectures, [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
  prefs: []
  type: TYPE_NORMAL
- en: BERTScore, [132](ch19.xhtml#page_132)–[133](ch19.xhtml#page_133), [134](ch19.xhtml#page_134),
    [216](appendix.xhtml#page_216)–[217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: bias units
  prefs: []
  type: TYPE_NORMAL
- en: in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)
  prefs: []
  type: TYPE_NORMAL
- en: in fully connected layers, [72](ch11.xhtml#page_72), [76](ch12.xhtml#page_76)
  prefs: []
  type: TYPE_NORMAL
- en: binomial proportion confidence interval, [171](ch25.xhtml#page_171)
  prefs: []
  type: TYPE_NORMAL
- en: BLAS (Basic Linear Algebra Subprograms), [148](ch22.xhtml#page_148), [152](ch22.xhtml#page_152)
  prefs: []
  type: TYPE_NORMAL
- en: BLEU (bilingual evaluation understudy) score, [128](ch19.xhtml#page_128), [129](ch19.xhtml#page_129)–[131](ch19.xhtml#page_131),
    [133](ch19.xhtml#page_133), [134](ch19.xhtml#page_134)
  prefs: []
  type: TYPE_NORMAL
- en: bootstrapping
  prefs: []
  type: TYPE_NORMAL
- en: improving performance with limited data, [194](ch30.xhtml#page_194)
  prefs: []
  type: TYPE_NORMAL
- en: out-of-bag, [167](ch25.xhtml#page_167)–[169](ch25.xhtml#page_169), [170](ch25.xhtml#page_170),
    [171](ch25.xhtml#page_171)
  prefs: []
  type: TYPE_NORMAL
- en: test set predictions, [169](ch25.xhtml#page_169), [170](ch25.xhtml#page_170),
    [171](ch25.xhtml#page_171), [219](appendix.xhtml#page_219)
  prefs: []
  type: TYPE_NORMAL
- en: '**C**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: calibration set, [176](ch26.xhtml#page_176)
  prefs: []
  type: TYPE_NORMAL
- en: CBOW (continuous bag-of-words) approach, [90](ch14.xhtml#page_90)
  prefs: []
  type: TYPE_NORMAL
- en: CE (cross-entropy) loss, [128](ch19.xhtml#page_128), [182](ch27.xhtml#page_182)
  prefs: []
  type: TYPE_NORMAL
- en: central limit theorem, [167](ch25.xhtml#page_167), [171](ch25.xhtml#page_171)
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT model
  prefs: []
  type: TYPE_NORMAL
- en: autoregressive models, [54](ch09.xhtml#page_54)
  prefs: []
  type: TYPE_NORMAL
- en: randomness by design, [63](ch10.xhtml#page_63)
  prefs: []
  type: TYPE_NORMAL
- en: reinforcement learning with human feedback (RLHF), [124](ch18.xhtml#page_124)
  prefs: []
  type: TYPE_NORMAL
- en: stateless vs. stateful training, [141](ch20.xhtml#page_141), [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: zero-shot learning, [196](ch30.xhtml#page_196)
  prefs: []
  type: TYPE_NORMAL
- en: classic bias-variance theory, [31](ch06.xhtml#page_31), [35](ch06.xhtml#page_35)
  prefs: []
  type: TYPE_NORMAL
- en: classification head, [215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: classification tasks
  prefs: []
  type: TYPE_NORMAL
- en: adopting encoder-style transformers for, [112](ch17.xhtml#page_112), [215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: cross entropy and, [128](ch19.xhtml#page_128)
  prefs: []
  type: TYPE_NORMAL
- en: fine-tuning decoder-style transformers for, [112](ch17.xhtml#page_112), [216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: using pretrained transformers for, [113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116)
  prefs: []
  type: TYPE_NORMAL
- en: Cleanlab open source library, [146](ch21.xhtml#page_146)
  prefs: []
  type: TYPE_NORMAL
- en: '[CLS] token, [108](ch17.xhtml#page_108), [215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)'
  prefs: []
  type: TYPE_NORMAL
- en: CNNs. *See* convolutional neural networks; neural networks
  prefs: []
  type: TYPE_NORMAL
- en: coloring video data, [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: Colossal AI, [37](ch07.xhtml#page_37), [42](ch07.xhtml#page_42)
  prefs: []
  type: TYPE_NORMAL
- en: COMET neural framework, [131](ch19.xhtml#page_131), [135](ch19.xhtml#page_135)
  prefs: []
  type: TYPE_NORMAL
- en: computer vision
  prefs: []
  type: TYPE_NORMAL
- en: calculating number of parameters, [69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  prefs: []
  type: TYPE_NORMAL
- en: distributional hypothesis, [214](appendix.xhtml#page_214)
  prefs: []
  type: TYPE_NORMAL
- en: fully connected and convolutional layers, [75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78),
    [213](appendix.xhtml#page_213)
  prefs: []
  type: TYPE_NORMAL
- en: large training sets for vision transformers, [79](ch13.xhtml#page_79)–[85](ch13.xhtml#page_85),
    [213](appendix.xhtml#page_213)–[214](appendix.xhtml#page_214)
  prefs: []
  type: TYPE_NORMAL
- en: self-attention mechanism, [103](ch16.xhtml#page_103), [215](appendix.xhtml#page_215)
  prefs: []
  type: TYPE_NORMAL
- en: concept drift, [155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156)
  prefs: []
  type: TYPE_NORMAL
- en: confidence intervals
  prefs: []
  type: TYPE_NORMAL
- en: asymptotic coverage guarantees, [177](ch26.xhtml#page_177)
  prefs: []
  type: TYPE_NORMAL
- en: bootstrapping test set predictions, [169](ch25.xhtml#page_169)
  prefs: []
  type: TYPE_NORMAL
- en: bootstrapping training sets, [167](ch25.xhtml#page_167)–[169](ch25.xhtml#page_169)
  prefs: []
  type: TYPE_NORMAL
- en: vs. conformal predictions, [173](ch26.xhtml#page_173)–[178](ch26.xhtml#page_178)
  prefs: []
  type: TYPE_NORMAL
- en: defined, [164](ch25.xhtml#page_164)–[165](ch25.xhtml#page_165)
  prefs: []
  type: TYPE_NORMAL
- en: normal approximation intervals, [166](ch25.xhtml#page_166)–[167](ch25.xhtml#page_167)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [163](ch25.xhtml#page_163), [173](ch26.xhtml#page_173)
  prefs: []
  type: TYPE_NORMAL
- en: and prediction intervals, [174](ch26.xhtml#page_174)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for, [170](ch25.xhtml#page_170), [178](ch26.xhtml#page_178)
  prefs: []
  type: TYPE_NORMAL
- en: retraining models with different random seeds, [169](ch25.xhtml#page_169)–[170](ch25.xhtml#page_170)
  prefs: []
  type: TYPE_NORMAL
- en: confidence scores in active learning, [204](ch30.xhtml#page_204), [222](appendix.xhtml#page_222)
  prefs: []
  type: TYPE_NORMAL
- en: conformal predictions
  prefs: []
  type: TYPE_NORMAL
- en: benefits of, [177](ch26.xhtml#page_177)–[178](ch26.xhtml#page_178)
  prefs: []
  type: TYPE_NORMAL
- en: computing, [175](ch26.xhtml#page_175)–[176](ch26.xhtml#page_176)
  prefs: []
  type: TYPE_NORMAL
- en: example of, [176](ch26.xhtml#page_176)–[177](ch26.xhtml#page_177)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [173](ch26.xhtml#page_173)
  prefs: []
  type: TYPE_NORMAL
- en: and prediction intervals, [174](ch26.xhtml#page_174)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for, [178](ch26.xhtml#page_178)
  prefs: []
  type: TYPE_NORMAL
- en: connectivity, [80](ch13.xhtml#page_80), [81](ch13.xhtml#page_81)
  prefs: []
  type: TYPE_NORMAL
- en: consistency models, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57), [58](ch09.xhtml#page_58),
    [212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: continuous bag-of-words (CBOW) approach, [90](ch14.xhtml#page_90)
  prefs: []
  type: TYPE_NORMAL
- en: contrastive learning, [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: contrastive self-supervised learning, [12](ch02.xhtml#page_12)–[14](ch02.xhtml#page_14)
  prefs: []
  type: TYPE_NORMAL
- en: convolutional layers
  prefs: []
  type: TYPE_NORMAL
- en: calculating number of parameters in, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)
  prefs: []
  type: TYPE_NORMAL
- en: as high-pass and low-pass filters, [84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for, [78](ch12.xhtml#page_78)
  prefs: []
  type: TYPE_NORMAL
- en: replacing fully connected layers with, [75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)
  prefs: []
  type: TYPE_NORMAL
- en: convolutional neural networks (CNNs). *See also* neural networks
  prefs: []
  type: TYPE_NORMAL
- en: calculating number of parameters in, [69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  prefs: []
  type: TYPE_NORMAL
- en: embeddings from, [4](ch01.xhtml#page_4), [6](ch01.xhtml#page_6), [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: high-pass and low-pass filters in, [84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: inductive biases in, [80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for, [84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: with vision transformers, [79](ch13.xhtml#page_79), [82](ch13.xhtml#page_82)–[83](ch13.xhtml#page_83),
    [84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: convolution operation, [61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
  prefs: []
  type: TYPE_NORMAL
- en: cosine similarity, [132](ch19.xhtml#page_132), [134](ch19.xhtml#page_134), [216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: count data, [161](ch24.xhtml#page_161)
  prefs: []
  type: TYPE_NORMAL
- en: covariate shift, [153](ch23.xhtml#page_153)–[154](ch23.xhtml#page_154), [156](ch23.xhtml#page_156),
    [157](ch23.xhtml#page_157)
  prefs: []
  type: TYPE_NORMAL
- en: CPUs, data parallelism on, [42](ch07.xhtml#page_42), [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: cross-entropy (CE) loss, [128](ch19.xhtml#page_128), [182](ch27.xhtml#page_182)
  prefs: []
  type: TYPE_NORMAL
- en: cross-validation
  prefs: []
  type: TYPE_NORMAL
- en: 5-fold cross-validation, [187](ch28.xhtml#page_187), [188](ch28.xhtml#page_188),
    [221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: '*k*-fold cross-validation, [185](ch28.xhtml#page_185)–[188](ch28.xhtml#page_188),
    [221](appendix.xhtml#page_221)'
  prefs: []
  type: TYPE_NORMAL
- en: leave-one-out cross-validation (LOOCV), [188](ch28.xhtml#page_188), [221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: 10-fold cross-validation, [187](ch28.xhtml#page_187), [188](ch28.xhtml#page_188)
  prefs: []
  type: TYPE_NORMAL
- en: CUDA Deep Neural Network library (cuDNN), [62](ch10.xhtml#page_62)
  prefs: []
  type: TYPE_NORMAL
- en: '**D**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: data. *See also* limited labeled data
  prefs: []
  type: TYPE_NORMAL
- en: applying self-supervised learning to video, [14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: count, [161](ch24.xhtml#page_161)
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting with, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27),
    [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: self-supervised learning for tabular, [14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: synthetic, generation of, [96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
  prefs: []
  type: TYPE_NORMAL
- en: unlabeled, in self-supervised learning, [10](ch02.xhtml#page_10), [11](ch02.xhtml#page_11)
  prefs: []
  type: TYPE_NORMAL
- en: data augmentation
  prefs: []
  type: TYPE_NORMAL
- en: to reduce overfitting, [24](ch05.xhtml#page_24)–[25](ch05.xhtml#page_25), [26](ch05.xhtml#page_26),
    [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: for text, [93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97), [214](appendix.xhtml#page_214)–[215](appendix.xhtml#page_215)
  prefs: []
  type: TYPE_NORMAL
- en: data-centric AI, [143](ch21.xhtml#page_143)–[146](ch21.xhtml#page_146), [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: data distribution shifts
  prefs: []
  type: TYPE_NORMAL
- en: concept drift, [155](ch23.xhtml#page_155)
  prefs: []
  type: TYPE_NORMAL
- en: covariate shift, [153](ch23.xhtml#page_153)–[154](ch23.xhtml#page_154)
  prefs: []
  type: TYPE_NORMAL
- en: domain shift, [155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156)
  prefs: []
  type: TYPE_NORMAL
- en: label shift, [154](ch23.xhtml#page_154)–[155](ch23.xhtml#page_155)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [153](ch23.xhtml#page_153)
  prefs: []
  type: TYPE_NORMAL
- en: types of, [156](ch23.xhtml#page_156)–[157](ch23.xhtml#page_157)
  prefs: []
  type: TYPE_NORMAL
- en: data parallelism, [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38), [39](ch07.xhtml#page_39)–[40](ch07.xhtml#page_40),
    [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42), [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: datasets
  prefs: []
  type: TYPE_NORMAL
- en: for few-shot learning, [15](ch03.xhtml#page_15)
  prefs: []
  type: TYPE_NORMAL
- en: sampling and shuffling as source of randomness, [60](ch10.xhtml#page_60)
  prefs: []
  type: TYPE_NORMAL
- en: for transformers, [45](ch08.xhtml#page_45)
  prefs: []
  type: TYPE_NORMAL
- en: DBMs (deep Boltzmann machines), [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51),
    [57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: dead neurons, [209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: decision trees, [204](ch30.xhtml#page_204)
  prefs: []
  type: TYPE_NORMAL
- en: decoder network (VAE model), [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
  prefs: []
  type: TYPE_NORMAL
- en: decoders
  prefs: []
  type: TYPE_NORMAL
- en: in Bahdanau attention mechanism, [100](ch16.xhtml#page_100)–[101](ch16.xhtml#page_101)
  prefs: []
  type: TYPE_NORMAL
- en: in original transformer architecture, [105](ch17.xhtml#page_105)–[106](ch17.xhtml#page_106),
    [107](ch17.xhtml#page_107)
  prefs: []
  type: TYPE_NORMAL
- en: decoder-style transformers. *See also* encoder-style transformers
  prefs: []
  type: TYPE_NORMAL
- en: contemporary transformer models, [111](ch17.xhtml#page_111)–[112](ch17.xhtml#page_112)
  prefs: []
  type: TYPE_NORMAL
- en: distributional hypothesis, [91](ch14.xhtml#page_91)
  prefs: []
  type: TYPE_NORMAL
- en: encoder-decoder hybrids, [110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [105](ch17.xhtml#page_105), [108](ch17.xhtml#page_108)–[110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: synthetic data generation, [96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
  prefs: []
  type: TYPE_NORMAL
- en: terminology related to, [110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: deep Boltzmann machines (DBMs), [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51),
    [57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: deep generative models. *See* generative AI models
  prefs: []
  type: TYPE_NORMAL
- en: deep learning. *See also* generative AI models
  prefs: []
  type: TYPE_NORMAL
- en: embeddings, [3](ch01.xhtml#page_3)–[7](ch01.xhtml#page_7), [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: few-shot learning, [15](ch03.xhtml#page_15)–[18](ch03.xhtml#page_18), [208](appendix.xhtml#page_208)–[209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: lottery ticket hypothesis, [19](ch04.xhtml#page_19)–[21](ch04.xhtml#page_21),
    [209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: multi-GPU training paradigms, [37](ch07.xhtml#page_37)–[42](ch07.xhtml#page_42),
    [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting
  prefs: []
  type: TYPE_NORMAL
- en: with data, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27), [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: with model modifications, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: self-supervised learning, [9](ch02.xhtml#page_9)–[14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: sources of randomness, [59](ch10.xhtml#page_59)–[65](ch10.xhtml#page_65), [212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: transformers, success of, [43](ch08.xhtml#page_43)–[47](ch08.xhtml#page_47),
    [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: DeepSpeed, [37](ch07.xhtml#page_37), [42](ch07.xhtml#page_42)
  prefs: []
  type: TYPE_NORMAL
- en: deletion, word, as data augmentation technique, [94](ch15.xhtml#page_94)
  prefs: []
  type: TYPE_NORMAL
- en: deterministic algorithms, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  prefs: []
  type: TYPE_NORMAL
- en: diffusion models, [55](ch09.xhtml#page_55)–[56](ch09.xhtml#page_56), [57](ch09.xhtml#page_57),
    [58](ch09.xhtml#page_58)
  prefs: []
  type: TYPE_NORMAL
- en: dimension contrastive self-supervised learning, [14](ch02.xhtml#page_14)
  prefs: []
  type: TYPE_NORMAL
- en: direct convolution, [61](ch10.xhtml#page_61)
  prefs: []
  type: TYPE_NORMAL
- en: discriminative models, [49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
  prefs: []
  type: TYPE_NORMAL
- en: discriminator in GANs, [52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)
  prefs: []
  type: TYPE_NORMAL
- en: distance, embeddings as encoding, [5](ch01.xhtml#page_5)
  prefs: []
  type: TYPE_NORMAL
- en: distance functions, [179](ch27.xhtml#page_179)–[183](ch27.xhtml#page_183)
  prefs: []
  type: TYPE_NORMAL
- en: distributional hypothesis, [89](ch14.xhtml#page_89)–[92](ch14.xhtml#page_92),
    [214](appendix.xhtml#page_214)
  prefs: []
  type: TYPE_NORMAL
- en: domain shift (joint distribution shift), [155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156),
    [157](ch23.xhtml#page_157)
  prefs: []
  type: TYPE_NORMAL
- en: double descent, [32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33), [36](ch06.xhtml#page_36)
  prefs: []
  type: TYPE_NORMAL
- en: downstream model for pretrained transformers, [114](ch18.xhtml#page_114)
  prefs: []
  type: TYPE_NORMAL
- en: downstream task, [11](ch02.xhtml#page_11)
  prefs: []
  type: TYPE_NORMAL
- en: drivers as source of randomness, [62](ch10.xhtml#page_62)
  prefs: []
  type: TYPE_NORMAL
- en: dropout, [30](ch06.xhtml#page_30), [36](ch06.xhtml#page_36), [61](ch10.xhtml#page_61),
    [64](ch10.xhtml#page_64)–[65](ch10.xhtml#page_65), [212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: '**E**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: early stopping, [30](ch06.xhtml#page_30)–[31](ch06.xhtml#page_31), [35](ch06.xhtml#page_35),
    [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: EBMs (energy-based models), [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)
  prefs: []
  type: TYPE_NORMAL
- en: EfficientNetV2 CNN architecture, [85](ch13.xhtml#page_85)
  prefs: []
  type: TYPE_NORMAL
- en: embeddings
  prefs: []
  type: TYPE_NORMAL
- en: distributional hypothesis, [90](ch14.xhtml#page_90)–[91](ch14.xhtml#page_91)
  prefs: []
  type: TYPE_NORMAL
- en: in few-shot learning, [17](ch03.xhtml#page_17)
  prefs: []
  type: TYPE_NORMAL
- en: latent space, [5](ch01.xhtml#page_5)–[6](ch01.xhtml#page_6)
  prefs: []
  type: TYPE_NORMAL
- en: in original transformer architecture, [106](ch17.xhtml#page_106)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [3](ch01.xhtml#page_3)–[5](ch01.xhtml#page_5)
  prefs: []
  type: TYPE_NORMAL
- en: representations, [6](ch01.xhtml#page_6)
  prefs: []
  type: TYPE_NORMAL
- en: emergent properties, GPT models, [110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: encoder-decoder models, [110](ch17.xhtml#page_110), [111](ch17.xhtml#page_111)
  prefs: []
  type: TYPE_NORMAL
- en: encoder network (VAE model), [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
  prefs: []
  type: TYPE_NORMAL
- en: encoders
  prefs: []
  type: TYPE_NORMAL
- en: in Bahdanau attention mechanism, [100](ch16.xhtml#page_100)–[101](ch16.xhtml#page_101)
  prefs: []
  type: TYPE_NORMAL
- en: in original transformer architecture, [105](ch17.xhtml#page_105)–[107](ch17.xhtml#page_107)
  prefs: []
  type: TYPE_NORMAL
- en: encoder-style transformers. *See also* decoder-style transformers
  prefs: []
  type: TYPE_NORMAL
- en: contemporary transformer models, [111](ch17.xhtml#page_111)–[112](ch17.xhtml#page_112)
  prefs: []
  type: TYPE_NORMAL
- en: encoder-decoder hybrids, [110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [105](ch17.xhtml#page_105), [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
  prefs: []
  type: TYPE_NORMAL
- en: terminology related to, [110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: energy-based models (EBMs), [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)
  prefs: []
  type: TYPE_NORMAL
- en: ensemble methods, [33](ch06.xhtml#page_33)–[34](ch06.xhtml#page_34), [35](ch06.xhtml#page_35),
    [210](appendix.xhtml#page_210), [221](appendix.xhtml#page_221), [222](appendix.xhtml#page_222)
  prefs: []
  type: TYPE_NORMAL
- en: episodes in few-shot learning, [16](ch03.xhtml#page_16)
  prefs: []
  type: TYPE_NORMAL
- en: Euclidean distance, [181](ch27.xhtml#page_181)
  prefs: []
  type: TYPE_NORMAL
- en: evaluation metrics for generative LLMs
  prefs: []
  type: TYPE_NORMAL
- en: BERTScore, [132](ch19.xhtml#page_132)–[133](ch19.xhtml#page_133)
  prefs: []
  type: TYPE_NORMAL
- en: BLEU score, [129](ch19.xhtml#page_129)–[131](ch19.xhtml#page_131)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [127](ch19.xhtml#page_127)–[128](ch19.xhtml#page_128)
  prefs: []
  type: TYPE_NORMAL
- en: perplexity, [128](ch19.xhtml#page_128)–[129](ch19.xhtml#page_129)
  prefs: []
  type: TYPE_NORMAL
- en: ROUGE score, [131](ch19.xhtml#page_131)–[132](ch19.xhtml#page_132)
  prefs: []
  type: TYPE_NORMAL
- en: surrogate metrics, [133](ch19.xhtml#page_133)
  prefs: []
  type: TYPE_NORMAL
- en: extrinsic metrics, [128](ch19.xhtml#page_128)
  prefs: []
  type: TYPE_NORMAL
- en: '**F**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: fast Fourier transform (FFT)-based convolution, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  prefs: []
  type: TYPE_NORMAL
- en: FC layers. *See* fully connected layers
  prefs: []
  type: TYPE_NORMAL
- en: feature selection, self-attention as form of, [46](ch08.xhtml#page_46), [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: few-shot learning. *See also* in-context learning
  prefs: []
  type: TYPE_NORMAL
- en: datasets and terminology, [15](ch03.xhtml#page_15)–[17](ch03.xhtml#page_17)
  prefs: []
  type: TYPE_NORMAL
- en: limited labeled data, [195](ch30.xhtml#page_195)–[196](ch30.xhtml#page_196),
    [203](ch30.xhtml#page_203)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [15](ch03.xhtml#page_15)
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting with, [25](ch05.xhtml#page_25)
  prefs: []
  type: TYPE_NORMAL
- en: FFT (fast Fourier transform)-based convolution, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  prefs: []
  type: TYPE_NORMAL
- en: fine-tuning pretrained transformers, [113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116),
    [119](ch18.xhtml#page_119)–[124](ch18.xhtml#page_124), [125](ch18.xhtml#page_125)–[126](ch18.xhtml#page_126),
    [216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: finite-sample guarantees of conformal predictions, [177](ch26.xhtml#page_177)
  prefs: []
  type: TYPE_NORMAL
- en: 5-fold cross-validation, [187](ch28.xhtml#page_187), [188](ch28.xhtml#page_188),
    [221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: flow-based models (normalizing flows), [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54),
    [57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: Fréchet inception distance approach, [212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: fully connected (FC) layers
  prefs: []
  type: TYPE_NORMAL
- en: calculating number of parameters in, [70](ch11.xhtml#page_70), [72](ch11.xhtml#page_72)
  prefs: []
  type: TYPE_NORMAL
- en: lack of spatial invariance or equivariance, [82](ch13.xhtml#page_82)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for, [78](ch12.xhtml#page_78)
  prefs: []
  type: TYPE_NORMAL
- en: replacing with convolutional layers, [75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)
  prefs: []
  type: TYPE_NORMAL
- en: using to create embeddings, [6](ch01.xhtml#page_6), [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: '**G**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: generalization accuracy, [164](ch25.xhtml#page_164)
  prefs: []
  type: TYPE_NORMAL
- en: generalization performance, [32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33)
  prefs: []
  type: TYPE_NORMAL
- en: generative adversarial networks (GANs), [52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53),
    [54](ch09.xhtml#page_54), [57](ch09.xhtml#page_57), [58](ch09.xhtml#page_58)
  prefs: []
  type: TYPE_NORMAL
- en: generative AI models
  prefs: []
  type: TYPE_NORMAL
- en: autoregressive models, [54](ch09.xhtml#page_54)–[55](ch09.xhtml#page_55)
  prefs: []
  type: TYPE_NORMAL
- en: consistency models, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: diffusion models, [55](ch09.xhtml#page_55)–[56](ch09.xhtml#page_56)
  prefs: []
  type: TYPE_NORMAL
- en: energy-based models, [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)
  prefs: []
  type: TYPE_NORMAL
- en: flow-based models, [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54)
  prefs: []
  type: TYPE_NORMAL
- en: generative adversarial networks, [52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)
  prefs: []
  type: TYPE_NORMAL
- en: generative vs. discriminative modeling, [49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [49](ch09.xhtml#page_49)
  prefs: []
  type: TYPE_NORMAL
- en: randomness and, [62](ch10.xhtml#page_62)–[64](ch10.xhtml#page_64)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for, [57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: variational autoencoders, [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
  prefs: []
  type: TYPE_NORMAL
- en: generative large language models. *See* evaluation metrics for generative LLMs;
    large language models; natural language processing
  prefs: []
  type: TYPE_NORMAL
- en: generator in GANs, [52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)
  prefs: []
  type: TYPE_NORMAL
- en: Gibbs sampling, [51](ch09.xhtml#page_51)
  prefs: []
  type: TYPE_NORMAL
- en: GPT (generative pretrained transformer) models
  prefs: []
  type: TYPE_NORMAL
- en: decoder-style transformers, [91](ch14.xhtml#page_91), [109](ch17.xhtml#page_109)–[110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: fine-tuning for classification, [112](ch17.xhtml#page_112), [216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: randomness by design, [63](ch10.xhtml#page_63)
  prefs: []
  type: TYPE_NORMAL
- en: self-prediction, [12](ch02.xhtml#page_12)
  prefs: []
  type: TYPE_NORMAL
- en: GPUs. *See* multi-GPU training paradigms
  prefs: []
  type: TYPE_NORMAL
- en: grokking, [32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33), [36](ch06.xhtml#page_36)
  prefs: []
  type: TYPE_NORMAL
- en: '**H**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: hard attention, [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: hard parameter sharing, [200](ch30.xhtml#page_200)
  prefs: []
  type: TYPE_NORMAL
- en: hard prompt tuning, [117](ch18.xhtml#page_117)–[118](ch18.xhtml#page_118)
  prefs: []
  type: TYPE_NORMAL
- en: hardware as source of randomness, [62](ch10.xhtml#page_62)
  prefs: []
  type: TYPE_NORMAL
- en: hierarchical processing in CNNs, [80](ch13.xhtml#page_80)
  prefs: []
  type: TYPE_NORMAL
- en: histograms, [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: holdout validation as source of randomness, [60](ch10.xhtml#page_60)
  prefs: []
  type: TYPE_NORMAL
- en: homophones, [92](ch14.xhtml#page_92), [214](appendix.xhtml#page_214)
  prefs: []
  type: TYPE_NORMAL
- en: human feedback, reinforcement learning with, [124](ch18.xhtml#page_124)
  prefs: []
  type: TYPE_NORMAL
- en: hyperparameter tuning, [188](ch28.xhtml#page_188)
  prefs: []
  type: TYPE_NORMAL
- en: '**I**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: image denoising, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: image generation, [51](ch09.xhtml#page_51), [52](ch09.xhtml#page_52), [54](ch09.xhtml#page_54)–[57](ch09.xhtml#page_57),
    [211](appendix.xhtml#page_211)–[212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: image histograms, [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: “An Image Is Worth 16×16 Words” (Dosovitskiy et al.), [83](ch13.xhtml#page_83),
    [85](ch13.xhtml#page_85)
  prefs: []
  type: TYPE_NORMAL
- en: ImageNet dataset, [9](ch02.xhtml#page_9), [14](ch02.xhtml#page_14), [175](ch26.xhtml#page_175)
  prefs: []
  type: TYPE_NORMAL
- en: image processing. *See* computer vision
  prefs: []
  type: TYPE_NORMAL
- en: importance weighting, [154](ch23.xhtml#page_154), [155](ch23.xhtml#page_155),
    [157](ch23.xhtml#page_157), [218](appendix.xhtml#page_218)
  prefs: []
  type: TYPE_NORMAL
- en: in-context learning, [113](ch18.xhtml#page_113), [116](ch18.xhtml#page_116)–[119](ch18.xhtml#page_119),
    [125](ch18.xhtml#page_125), [216](appendix.xhtml#page_216). *See also* few-shot
    learning
  prefs: []
  type: TYPE_NORMAL
- en: indexing, [118](ch18.xhtml#page_118)–[119](ch18.xhtml#page_119), [125](ch18.xhtml#page_125)
  prefs: []
  type: TYPE_NORMAL
- en: inductive biases
  prefs: []
  type: TYPE_NORMAL
- en: in convolutional neural networks, [80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
  prefs: []
  type: TYPE_NORMAL
- en: limited labeled data, [202](ch30.xhtml#page_202)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [79](ch13.xhtml#page_79)
  prefs: []
  type: TYPE_NORMAL
- en: in vision transformers, [83](ch13.xhtml#page_83)–[84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: inference, speeding up. *See* model inference, speeding up
  prefs: []
  type: TYPE_NORMAL
- en: inpainting, [194](ch30.xhtml#page_194)–[195](ch30.xhtml#page_195), [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: input channels in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71),
    [76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
  prefs: []
  type: TYPE_NORMAL
- en: input embedding, [4](ch01.xhtml#page_4)
  prefs: []
  type: TYPE_NORMAL
- en: input representations, [6](ch01.xhtml#page_6), [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: InstructGPT model, [124](ch18.xhtml#page_124), [126](ch18.xhtml#page_126), [133](ch19.xhtml#page_133),
    [135](ch19.xhtml#page_135)
  prefs: []
  type: TYPE_NORMAL
- en: inter-op parallelism (model parallelism), [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38),
    [39](ch07.xhtml#page_39)–[40](ch07.xhtml#page_40), [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)
  prefs: []
  type: TYPE_NORMAL
- en: intra-op parallelism (tensor parallelism), [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38)–[40](ch07.xhtml#page_40),
    [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42), [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: intrinsic metrics, [128](ch19.xhtml#page_128)
  prefs: []
  type: TYPE_NORMAL
- en: iterative pruning, [20](ch04.xhtml#page_20), [31](ch06.xhtml#page_31)
  prefs: []
  type: TYPE_NORMAL
- en: '**J**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: joint distribution shift (domain shift), [155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156),
    [157](ch23.xhtml#page_157)
  prefs: []
  type: TYPE_NORMAL
- en: '**K**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: kernel size in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71),
    [76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
  prefs: []
  type: TYPE_NORMAL
- en: '*k*-fold cross-validation'
  prefs: []
  type: TYPE_NORMAL
- en: determining appropriate values for *k*, [187](ch28.xhtml#page_187)–[188](ch28.xhtml#page_188)
  prefs: []
  type: TYPE_NORMAL
- en: ensemble approach, [33](ch06.xhtml#page_33)–[34](ch06.xhtml#page_34)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [185](ch28.xhtml#page_185)–[186](ch28.xhtml#page_186)
  prefs: []
  type: TYPE_NORMAL
- en: as source of randomness, [60](ch10.xhtml#page_60)
  prefs: []
  type: TYPE_NORMAL
- en: trade-offs in selecting values for *k*, [186](ch28.xhtml#page_186)–[187](ch28.xhtml#page_187)
  prefs: []
  type: TYPE_NORMAL
- en: knowledge distillation, [31](ch06.xhtml#page_31)–[33](ch06.xhtml#page_33), [35](ch06.xhtml#page_35),
    [36](ch06.xhtml#page_36), [151](ch22.xhtml#page_151), [199](ch30.xhtml#page_199)
  prefs: []
  type: TYPE_NORMAL
- en: Kullback–Leibler divergence (KL divergence), [32](ch06.xhtml#page_32), [52](ch09.xhtml#page_52),
    [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: '**L**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*L*2 distance, [181](ch27.xhtml#page_181)'
  prefs: []
  type: TYPE_NORMAL
- en: '*L*2 regularization, [30](ch06.xhtml#page_30), [35](ch06.xhtml#page_35)'
  prefs: []
  type: TYPE_NORMAL
- en: labeled data, limited. *See* limited labeled data
  prefs: []
  type: TYPE_NORMAL
- en: label shift (prior probability shift), [154](ch23.xhtml#page_154)–[155](ch23.xhtml#page_155),
    [156](ch23.xhtml#page_156)
  prefs: []
  type: TYPE_NORMAL
- en: label smoothing, [27](ch05.xhtml#page_27)
  prefs: []
  type: TYPE_NORMAL
- en: language transformers. *See* transformers
  prefs: []
  type: TYPE_NORMAL
- en: large language models (LLMs). *See also* natural language processing; transformers
  prefs: []
  type: TYPE_NORMAL
- en: distributional hypothesis, [91](ch14.xhtml#page_91)
  prefs: []
  type: TYPE_NORMAL
- en: evaluation metrics for, [127](ch19.xhtml#page_127)–[135](ch19.xhtml#page_135),
    [216](appendix.xhtml#page_216)–[217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: stateless vs. stateful training, [141](ch20.xhtml#page_141), [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: synthetic data generation, [96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
  prefs: []
  type: TYPE_NORMAL
- en: latent space, [3](ch01.xhtml#page_3), [5](ch01.xhtml#page_5)–[7](ch01.xhtml#page_7)
  prefs: []
  type: TYPE_NORMAL
- en: layer input normalization techniques, [34](ch06.xhtml#page_34)–[35](ch06.xhtml#page_35)
  prefs: []
  type: TYPE_NORMAL
- en: layers
  prefs: []
  type: TYPE_NORMAL
- en: convolutional layers
  prefs: []
  type: TYPE_NORMAL
- en: calculating number of parameters in, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)
  prefs: []
  type: TYPE_NORMAL
- en: as high-pass and low-pass filters, [84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for, [78](ch12.xhtml#page_78)
  prefs: []
  type: TYPE_NORMAL
- en: replacing fully connected layers with, [75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)
  prefs: []
  type: TYPE_NORMAL
- en: normalization in original transformer architecture, [106](ch17.xhtml#page_106)–[107](ch17.xhtml#page_107)
  prefs: []
  type: TYPE_NORMAL
- en: updating when fine-tuning pretrained transformers, [115](ch18.xhtml#page_115)–[116](ch18.xhtml#page_116)
  prefs: []
  type: TYPE_NORMAL
- en: using to create embeddings, [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: leave-one-out cross-validation (LOOCV), [188](ch28.xhtml#page_188), [221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: limited labeled data
  prefs: []
  type: TYPE_NORMAL
- en: active learning, [195](ch30.xhtml#page_195)
  prefs: []
  type: TYPE_NORMAL
- en: bootstrapping data, [194](ch30.xhtml#page_194)
  prefs: []
  type: TYPE_NORMAL
- en: few-shot learning, [195](ch30.xhtml#page_195)–[196](ch30.xhtml#page_196)
  prefs: []
  type: TYPE_NORMAL
- en: inductive biases, [202](ch30.xhtml#page_202)
  prefs: []
  type: TYPE_NORMAL
- en: labeling more data, [193](ch30.xhtml#page_193)–[194](ch30.xhtml#page_194)
  prefs: []
  type: TYPE_NORMAL
- en: meta-learning, [196](ch30.xhtml#page_196)–[197](ch30.xhtml#page_197)
  prefs: []
  type: TYPE_NORMAL
- en: multimodal learning, [200](ch30.xhtml#page_200)–[202](ch30.xhtml#page_202)
  prefs: []
  type: TYPE_NORMAL
- en: multi-task learning, [199](ch30.xhtml#page_199)–[200](ch30.xhtml#page_200)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [193](ch30.xhtml#page_193)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for choosing technique, [202](ch30.xhtml#page_202)–[203](ch30.xhtml#page_203)
  prefs: []
  type: TYPE_NORMAL
- en: self-supervised learning, [194](ch30.xhtml#page_194)–[195](ch30.xhtml#page_195)
  prefs: []
  type: TYPE_NORMAL
- en: self-training, [199](ch30.xhtml#page_199)
  prefs: []
  type: TYPE_NORMAL
- en: semi-supervised learning, [198](ch30.xhtml#page_198)–[199](ch30.xhtml#page_199)
  prefs: []
  type: TYPE_NORMAL
- en: transfer learning, [194](ch30.xhtml#page_194)
  prefs: []
  type: TYPE_NORMAL
- en: weakly supervised learning, [197](ch30.xhtml#page_197)–[198](ch30.xhtml#page_198)
  prefs: []
  type: TYPE_NORMAL
- en: linear classifiers, [114](ch18.xhtml#page_114)
  prefs: []
  type: TYPE_NORMAL
- en: LLMs. *See* large language models; natural language processing; transformers
  prefs: []
  type: TYPE_NORMAL
- en: local connectivity in CNNs, [80](ch13.xhtml#page_80), [81](ch13.xhtml#page_81)
  prefs: []
  type: TYPE_NORMAL
- en: logistic regression classifier, [49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
  prefs: []
  type: TYPE_NORMAL
- en: LOOCV (leave-one-out cross-validation), [188](ch28.xhtml#page_188), [221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: loop fusion (operator fusion), [150](ch22.xhtml#page_150)–[151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: loop tiling (loop nest optimization), [149](ch22.xhtml#page_149)–[150](ch22.xhtml#page_150),
    [151](ch22.xhtml#page_151), [152](ch22.xhtml#page_152), [218](appendix.xhtml#page_218)
  prefs: []
  type: TYPE_NORMAL
- en: LoRA (low-rank adaptation), [119](ch18.xhtml#page_119), [123](ch18.xhtml#page_123)–[124](ch18.xhtml#page_124),
    [125](ch18.xhtml#page_125), [126](ch18.xhtml#page_126), [216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: loss function, VAEs, [52](ch09.xhtml#page_52)
  prefs: []
  type: TYPE_NORMAL
- en: lottery ticket hypothesis
  prefs: []
  type: TYPE_NORMAL
- en: overview, [19](ch04.xhtml#page_19)
  prefs: []
  type: TYPE_NORMAL
- en: practical implications and limitations, [20](ch04.xhtml#page_20)–[21](ch04.xhtml#page_21)
  prefs: []
  type: TYPE_NORMAL
- en: training procedure for, [19](ch04.xhtml#page_19)–[20](ch04.xhtml#page_20)
  prefs: []
  type: TYPE_NORMAL
- en: low-rank adaptation (LoRA), [119](ch18.xhtml#page_119), [123](ch18.xhtml#page_123)–[124](ch18.xhtml#page_124),
    [125](ch18.xhtml#page_125), [126](ch18.xhtml#page_126), [216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: low-rank transformation, [123](ch18.xhtml#page_123)
  prefs: []
  type: TYPE_NORMAL
- en: '**M**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MAE (mean absolute error), [183](ch27.xhtml#page_183), [220](appendix.xhtml#page_220)–[221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: majority voting, [33](ch06.xhtml#page_33)
  prefs: []
  type: TYPE_NORMAL
- en: MAPIE library, [178](ch26.xhtml#page_178)
  prefs: []
  type: TYPE_NORMAL
- en: masked (missing) input self-prediction methods, [12](ch02.xhtml#page_12)
  prefs: []
  type: TYPE_NORMAL
- en: masked frames, predicting, [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: masked language modeling, [91](ch14.xhtml#page_91), [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108),
    [194](ch30.xhtml#page_194)
  prefs: []
  type: TYPE_NORMAL
- en: mean absolute error (MAE), [183](ch27.xhtml#page_183), [220](appendix.xhtml#page_220)–[221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: mean squared error (MSE) loss, [180](ch27.xhtml#page_180)–[181](ch27.xhtml#page_181)
  prefs: []
  type: TYPE_NORMAL
- en: memory complexity of self-attention, [103](ch16.xhtml#page_103), [215](appendix.xhtml#page_215)
  prefs: []
  type: TYPE_NORMAL
- en: metadata (meta-features) extraction, [197](ch30.xhtml#page_197)
  prefs: []
  type: TYPE_NORMAL
- en: meta-learning, [17](ch03.xhtml#page_17), [196](ch30.xhtml#page_196)–[197](ch30.xhtml#page_197)
  prefs: []
  type: TYPE_NORMAL
- en: METEOR metric, [131](ch19.xhtml#page_131), [134](ch19.xhtml#page_134)
  prefs: []
  type: TYPE_NORMAL
- en: metrics, proper. *See* proper metrics
  prefs: []
  type: TYPE_NORMAL
- en: missing (masked) input self-prediction methods, [12](ch02.xhtml#page_12)
  prefs: []
  type: TYPE_NORMAL
- en: missing frames, predicting, [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: Mixup, [27](ch05.xhtml#page_27)
  prefs: []
  type: TYPE_NORMAL
- en: MLPs (multilayer perceptrons), [50](ch09.xhtml#page_50), [82](ch13.xhtml#page_82)
  prefs: []
  type: TYPE_NORMAL
- en: MNIST dataset, [15](ch03.xhtml#page_15), [18](ch03.xhtml#page_18), [26](ch05.xhtml#page_26),
    [208](appendix.xhtml#page_208), [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: model-centric AI, [143](ch21.xhtml#page_143)–[144](ch21.xhtml#page_144), [145](ch21.xhtml#page_145)
  prefs: []
  type: TYPE_NORMAL
- en: model ensembling, [33](ch06.xhtml#page_33)–[34](ch06.xhtml#page_34), [35](ch06.xhtml#page_35),
    [210](appendix.xhtml#page_210), [221](appendix.xhtml#page_221), [222](appendix.xhtml#page_222)
  prefs: []
  type: TYPE_NORMAL
- en: model evaluation. *See* predictive performance and model evaluation
  prefs: []
  type: TYPE_NORMAL
- en: model inference, speeding up
  prefs: []
  type: TYPE_NORMAL
- en: loop tiling, [149](ch22.xhtml#page_149)–[150](ch22.xhtml#page_150)
  prefs: []
  type: TYPE_NORMAL
- en: operator fusion, [150](ch22.xhtml#page_150)–[151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [147](ch22.xhtml#page_147)
  prefs: []
  type: TYPE_NORMAL
- en: parallelization, [147](ch22.xhtml#page_147)–[148](ch22.xhtml#page_148)
  prefs: []
  type: TYPE_NORMAL
- en: quantization, [151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: vectorization, [148](ch22.xhtml#page_148)–[149](ch22.xhtml#page_149)
  prefs: []
  type: TYPE_NORMAL
- en: model modifications, reducing overfitting with, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: model parallelism (inter-op parallelism), [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38),
    [39](ch07.xhtml#page_39)–[40](ch07.xhtml#page_40), [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)
  prefs: []
  type: TYPE_NORMAL
- en: model weight initialization as source of randomness, [59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
  prefs: []
  type: TYPE_NORMAL
- en: MSE (mean squared error) loss, [180](ch27.xhtml#page_180)–[181](ch27.xhtml#page_181)
  prefs: []
  type: TYPE_NORMAL
- en: multi-GPU training paradigms
  prefs: []
  type: TYPE_NORMAL
- en: data parallelism, [38](ch07.xhtml#page_38)
  prefs: []
  type: TYPE_NORMAL
- en: model parallelism, [38](ch07.xhtml#page_38) overview, [37](ch07.xhtml#page_37)
  prefs: []
  type: TYPE_NORMAL
- en: pipeline parallelism, [40](ch07.xhtml#page_40)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for, [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)
  prefs: []
  type: TYPE_NORMAL
- en: sequence parallelism, [40](ch07.xhtml#page_40)–[41](ch07.xhtml#page_41)
  prefs: []
  type: TYPE_NORMAL
- en: speeding up inference, [152](ch22.xhtml#page_152), [218](appendix.xhtml#page_218)
  prefs: []
  type: TYPE_NORMAL
- en: tensor parallelism, [38](ch07.xhtml#page_38)–[40](ch07.xhtml#page_40)
  prefs: []
  type: TYPE_NORMAL
- en: multilayer perceptrons (MLPs), [50](ch09.xhtml#page_50), [82](ch13.xhtml#page_82)
  prefs: []
  type: TYPE_NORMAL
- en: multimodal learning, [200](ch30.xhtml#page_200)–[202](ch30.xhtml#page_202),
    [204](ch30.xhtml#page_204)
  prefs: []
  type: TYPE_NORMAL
- en: multi-task learning, [199](ch30.xhtml#page_199)–[200](ch30.xhtml#page_200),
    [204](ch30.xhtml#page_204)
  prefs: []
  type: TYPE_NORMAL
- en: '**N**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: naive Bayes classifier, [49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
  prefs: []
  type: TYPE_NORMAL
- en: natural language processing (NLP). *See also* transformers
  prefs: []
  type: TYPE_NORMAL
- en: data augmentation for text, [93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97),
    [214](appendix.xhtml#page_214)–[215](appendix.xhtml#page_215)
  prefs: []
  type: TYPE_NORMAL
- en: distributional hypothesis, [89](ch14.xhtml#page_89)–[92](ch14.xhtml#page_92),
    [214](appendix.xhtml#page_214)
  prefs: []
  type: TYPE_NORMAL
- en: evaluating generative LLMs, [127](ch19.xhtml#page_127)–[135](ch19.xhtml#page_135),
    [211](appendix.xhtml#page_211)–[212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: self-attention, [99](ch16.xhtml#page_99)–[103](ch16.xhtml#page_103), [215](appendix.xhtml#page_215)
  prefs: []
  type: TYPE_NORMAL
- en: neural networks. *See also* convolutional neural networks; generative AI models;
    transformers
  prefs: []
  type: TYPE_NORMAL
- en: attention mechanism for, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101)
  prefs: []
  type: TYPE_NORMAL
- en: calculating number of parameters in, [69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  prefs: []
  type: TYPE_NORMAL
- en: embeddings, [3](ch01.xhtml#page_3)–[7](ch01.xhtml#page_7), [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: few-shot learning, [15](ch03.xhtml#page_15)–[18](ch03.xhtml#page_18), [208](appendix.xhtml#page_208)–[209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: lottery ticket hypothesis, [19](ch04.xhtml#page_19)–[21](ch04.xhtml#page_21),
    [209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: multi-GPU training paradigms, [37](ch07.xhtml#page_37)–[42](ch07.xhtml#page_42),
    [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting
  prefs: []
  type: TYPE_NORMAL
- en: with data, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27), [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: with model modifications, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: self-attention, [99](ch16.xhtml#page_99)–[103](ch16.xhtml#page_103)
  prefs: []
  type: TYPE_NORMAL
- en: self-supervised learning, [9](ch02.xhtml#page_9)–[14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: sources of randomness, [59](ch10.xhtml#page_59)–[65](ch10.xhtml#page_65), [212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: transformers, success of, [43](ch08.xhtml#page_43)–[47](ch08.xhtml#page_47),
    [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: next-sentence/next-word prediction task, [12](ch02.xhtml#page_12), [108](ch17.xhtml#page_108),
    [109](ch17.xhtml#page_109), [194](ch30.xhtml#page_194)
  prefs: []
  type: TYPE_NORMAL
- en: NICE (non-linear independent components estimation), [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54),
    [58](ch09.xhtml#page_58)
  prefs: []
  type: TYPE_NORMAL
- en: NLP. *See* natural language processing; transformers
  prefs: []
  type: TYPE_NORMAL
- en: noise
  prefs: []
  type: TYPE_NORMAL
- en: consistency models and, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: diffusion models and, [56](ch09.xhtml#page_56)
  prefs: []
  type: TYPE_NORMAL
- en: noise injection, [95](ch15.xhtml#page_95)–[96](ch15.xhtml#page_96)
  prefs: []
  type: TYPE_NORMAL
- en: nonconformity measure, [176](ch26.xhtml#page_176)–[177](ch26.xhtml#page_177)
  prefs: []
  type: TYPE_NORMAL
- en: nondeterministic algorithms, [61](ch10.xhtml#page_61)
  prefs: []
  type: TYPE_NORMAL
- en: non-linear independent components estimation (NICE), [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54),
    [58](ch09.xhtml#page_58)
  prefs: []
  type: TYPE_NORMAL
- en: normal approximation intervals, [166](ch25.xhtml#page_166)–[167](ch25.xhtml#page_167),
    [170](ch25.xhtml#page_170), [171](ch25.xhtml#page_171)
  prefs: []
  type: TYPE_NORMAL
- en: normalizing flows (flow-based models), [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54),
    [57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: nucleus sampling (top-*p* sampling), [63](ch10.xhtml#page_63)–[64](ch10.xhtml#page_64),
    [212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA graphics cards, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  prefs: []
  type: TYPE_NORMAL
- en: '*N*-way *K*-shot (few-shot learning), [15](ch03.xhtml#page_15)–[16](ch03.xhtml#page_16)'
  prefs: []
  type: TYPE_NORMAL
- en: '**O**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ODE (ordinary differential equation) trajectory, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: one-hot encoding, [4](ch01.xhtml#page_4), [207](appendix.xhtml#page_207)
  prefs: []
  type: TYPE_NORMAL
- en: online resources, [xxviii](ch00.xhtml#page_xxviii)
  prefs: []
  type: TYPE_NORMAL
- en: operator fusion (loop fusion), [150](ch22.xhtml#page_150)–[151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: ordinal regression, [161](ch24.xhtml#page_161)–[162](ch24.xhtml#page_162), [218](appendix.xhtml#page_218)–[219](appendix.xhtml#page_219)
  prefs: []
  type: TYPE_NORMAL
- en: ordinary differential equation (ODE) trajectory, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  prefs: []
  type: TYPE_NORMAL
- en: outlier detection, [218](appendix.xhtml#page_218)
  prefs: []
  type: TYPE_NORMAL
- en: out-of-bag bootstrapping, [167](ch25.xhtml#page_167)–[169](ch25.xhtml#page_169),
    [170](ch25.xhtml#page_170), [171](ch25.xhtml#page_171)
  prefs: []
  type: TYPE_NORMAL
- en: output channels in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71),
    [76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
  prefs: []
  type: TYPE_NORMAL
- en: output layers, updating, [115](ch18.xhtml#page_115)–[116](ch18.xhtml#page_116)
  prefs: []
  type: TYPE_NORMAL
- en: overfitting
  prefs: []
  type: TYPE_NORMAL
- en: overview, [23](ch05.xhtml#page_23)
  prefs: []
  type: TYPE_NORMAL
- en: reducing with data, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27), [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: reducing with model modifications, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: '**P**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: parallelization
  prefs: []
  type: TYPE_NORMAL
- en: model inference, speeding up, [147](ch22.xhtml#page_147)–[148](ch22.xhtml#page_148)
  prefs: []
  type: TYPE_NORMAL
- en: of transformers, [45](ch08.xhtml#page_45)–[46](ch08.xhtml#page_46)
  prefs: []
  type: TYPE_NORMAL
- en: parameter-efficient fine-tuning, [113](ch18.xhtml#page_113), [119](ch18.xhtml#page_119)–[124](ch18.xhtml#page_124),
    [125](ch18.xhtml#page_125), [126](ch18.xhtml#page_126)
  prefs: []
  type: TYPE_NORMAL
- en: parameters
  prefs: []
  type: TYPE_NORMAL
- en: calculating number of in CNNs, [69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  prefs: []
  type: TYPE_NORMAL
- en: of transformers, scale and number of, [45](ch08.xhtml#page_45), [47](ch08.xhtml#page_47)
  prefs: []
  type: TYPE_NORMAL
- en: patchifying inductive bias, [83](ch13.xhtml#page_83), [85](ch13.xhtml#page_85),
    [213](appendix.xhtml#page_213)–[214](appendix.xhtml#page_214)
  prefs: []
  type: TYPE_NORMAL
- en: perplexity metric, [127](ch19.xhtml#page_127)–[129](ch19.xhtml#page_129)
  prefs: []
  type: TYPE_NORMAL
- en: pipeline parallelism, [37](ch07.xhtml#page_37), [40](ch07.xhtml#page_40), [41](ch07.xhtml#page_41),
    [42](ch07.xhtml#page_42)
  prefs: []
  type: TYPE_NORMAL
- en: PixelCNN model, [54](ch09.xhtml#page_54), [58](ch09.xhtml#page_58)
  prefs: []
  type: TYPE_NORMAL
- en: pixel generation, autoregressive, [54](ch09.xhtml#page_54)–[55](ch09.xhtml#page_55)
  prefs: []
  type: TYPE_NORMAL
- en: Poisson regression, [161](ch24.xhtml#page_161)–[162](ch24.xhtml#page_162), [218](appendix.xhtml#page_218)–[219](appendix.xhtml#page_219)
  prefs: []
  type: TYPE_NORMAL
- en: polysemous words, [90](ch14.xhtml#page_90)
  prefs: []
  type: TYPE_NORMAL
- en: population parameters, [164](ch25.xhtml#page_164)
  prefs: []
  type: TYPE_NORMAL
- en: positive-unlabeled learning (PU-learning), [198](ch30.xhtml#page_198)
  prefs: []
  type: TYPE_NORMAL
- en: post-training quantization, [151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: prediction intervals, [173](ch26.xhtml#page_173)–[175](ch26.xhtml#page_175),
    [178](ch26.xhtml#page_178)
  prefs: []
  type: TYPE_NORMAL
- en: prediction regions, [174](ch26.xhtml#page_174)–[175](ch26.xhtml#page_175)
  prefs: []
  type: TYPE_NORMAL
- en: prediction sets, [174](ch26.xhtml#page_174), [178](ch26.xhtml#page_178), [219](appendix.xhtml#page_219)–[220](appendix.xhtml#page_220)
  prefs: []
  type: TYPE_NORMAL
- en: predictive analytics in healthcare, [146](ch21.xhtml#page_146), [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: predictive performance and model evaluation. *See also* limited labeled data
  prefs: []
  type: TYPE_NORMAL
- en: confidence intervals vs. conformal predictions, [173](ch26.xhtml#page_173)–[178](ch26.xhtml#page_178),
    [219](appendix.xhtml#page_219)–[220](appendix.xhtml#page_220)
  prefs: []
  type: TYPE_NORMAL
- en: constructing confidence intervals, [163](ch25.xhtml#page_163)–[171](ch25.xhtml#page_171),
    [219](appendix.xhtml#page_219)
  prefs: []
  type: TYPE_NORMAL
- en: '*k*-fold cross-validation, [185](ch28.xhtml#page_185)–[188](ch28.xhtml#page_188),
    [221](appendix.xhtml#page_221)'
  prefs: []
  type: TYPE_NORMAL
- en: Poisson and ordinal regression, [161](ch24.xhtml#page_161)–[162](ch24.xhtml#page_162),
    [218](appendix.xhtml#page_218)–[219](appendix.xhtml#page_219)
  prefs: []
  type: TYPE_NORMAL
- en: proper metrics, [179](ch27.xhtml#page_179)–[183](ch27.xhtml#page_183), [220](appendix.xhtml#page_220)–[221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: training and test set discordance, [189](ch29.xhtml#page_189)–[191](ch29.xhtml#page_191),
    [221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: prefix tuning, [119](ch18.xhtml#page_119), [120](ch18.xhtml#page_120)–[121](ch18.xhtml#page_121),
    [125](ch18.xhtml#page_125), [126](ch18.xhtml#page_126), [216](appendix.xhtml#page_216)
  prefs: []
  type: TYPE_NORMAL
- en: pretext tasks, [10](ch02.xhtml#page_10)
  prefs: []
  type: TYPE_NORMAL
- en: pretrained transformers
  prefs: []
  type: TYPE_NORMAL
- en: adapting, [124](ch18.xhtml#page_124)–[125](ch18.xhtml#page_125)
  prefs: []
  type: TYPE_NORMAL
- en: classification tasks, [113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116)
  prefs: []
  type: TYPE_NORMAL
- en: in-context learning, indexing, and prompt tuning, [116](ch18.xhtml#page_116)–[119](ch18.xhtml#page_119)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [113](ch18.xhtml#page_113)
  prefs: []
  type: TYPE_NORMAL
- en: parameter-efficient fine-tuning, [119](ch18.xhtml#page_119)–[124](ch18.xhtml#page_124)
  prefs: []
  type: TYPE_NORMAL
- en: reinforcement learning with human feedback (RLHF), [124](ch18.xhtml#page_124)
  prefs: []
  type: TYPE_NORMAL
- en: pretraining
  prefs: []
  type: TYPE_NORMAL
- en: encoder-only architectures, [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
  prefs: []
  type: TYPE_NORMAL
- en: to reduce overfitting, [25](ch05.xhtml#page_25)
  prefs: []
  type: TYPE_NORMAL
- en: with self-supervised learning, [10](ch02.xhtml#page_10)–[11](ch02.xhtml#page_11)
  prefs: []
  type: TYPE_NORMAL
- en: with transfer learning, [9](ch02.xhtml#page_9)–[10](ch02.xhtml#page_10)
  prefs: []
  type: TYPE_NORMAL
- en: transformers, via self-supervised learning, [45](ch08.xhtml#page_45)
  prefs: []
  type: TYPE_NORMAL
- en: for vision transformers, [83](ch13.xhtml#page_83)
  prefs: []
  type: TYPE_NORMAL
- en: prior probability shift (label shift), [154](ch23.xhtml#page_154)–[155](ch23.xhtml#page_155),
    [156](ch23.xhtml#page_156)
  prefs: []
  type: TYPE_NORMAL
- en: production and deployment
  prefs: []
  type: TYPE_NORMAL
- en: data distribution shifts, [153](ch23.xhtml#page_153)–[157](ch23.xhtml#page_157),
    [218](appendix.xhtml#page_218)
  prefs: []
  type: TYPE_NORMAL
- en: model inference, speeding up, [147](ch22.xhtml#page_147)–[152](ch22.xhtml#page_152),
    [218](appendix.xhtml#page_218)
  prefs: []
  type: TYPE_NORMAL
- en: stateless and stateful training, [139](ch20.xhtml#page_139)–[141](ch20.xhtml#page_141),
    [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: prompt tuning, [117](ch18.xhtml#page_117)–[118](ch18.xhtml#page_118)
  prefs: []
  type: TYPE_NORMAL
- en: proper metrics
  prefs: []
  type: TYPE_NORMAL
- en: criteria for, [179](ch27.xhtml#page_179)–[180](ch27.xhtml#page_180)
  prefs: []
  type: TYPE_NORMAL
- en: cross-entropy loss, [182](ch27.xhtml#page_182)
  prefs: []
  type: TYPE_NORMAL
- en: mean squared error loss, [180](ch27.xhtml#page_180)–[181](ch27.xhtml#page_181)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [179](ch27.xhtml#page_179)
  prefs: []
  type: TYPE_NORMAL
- en: protein modeling, [214](appendix.xhtml#page_214)
  prefs: []
  type: TYPE_NORMAL
- en: proximal policy optimization, [124](ch18.xhtml#page_124), [126](ch18.xhtml#page_126)
  prefs: []
  type: TYPE_NORMAL
- en: pruning, [31](ch06.xhtml#page_31), [32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33),
    [35](ch06.xhtml#page_35), [36](ch06.xhtml#page_36), [151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: pseudo-labelers, [199](ch30.xhtml#page_199) PU-learning (positive-unlabeled
    learning), [198](ch30.xhtml#page_198)
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch framework, [59](ch10.xhtml#page_59), [61](ch10.xhtml#page_61), [62](ch10.xhtml#page_62),
    [65](ch10.xhtml#page_65), [149](ch22.xhtml#page_149)
  prefs: []
  type: TYPE_NORMAL
- en: '**Q**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: quantization, [151](ch22.xhtml#page_151), [152](ch22.xhtml#page_152)
  prefs: []
  type: TYPE_NORMAL
- en: quantization-aware training, [151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: '**R**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: random characters, [95](ch15.xhtml#page_95)
  prefs: []
  type: TYPE_NORMAL
- en: random initialization, [209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: randomness, sources of
  prefs: []
  type: TYPE_NORMAL
- en: dataset sampling and shuffling, [60](ch10.xhtml#page_60)
  prefs: []
  type: TYPE_NORMAL
- en: different runtime algorithms, [61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
  prefs: []
  type: TYPE_NORMAL
- en: and generative AI, [62](ch10.xhtml#page_62)–[64](ch10.xhtml#page_64)
  prefs: []
  type: TYPE_NORMAL
- en: hardware and drivers, [62](ch10.xhtml#page_62)
  prefs: []
  type: TYPE_NORMAL
- en: model weight initialization, [59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
  prefs: []
  type: TYPE_NORMAL
- en: nondeterministic algorithms, [61](ch10.xhtml#page_61)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [59](ch10.xhtml#page_59)
  prefs: []
  type: TYPE_NORMAL
- en: random seeds, [169](ch25.xhtml#page_169)–[170](ch25.xhtml#page_170)
  prefs: []
  type: TYPE_NORMAL
- en: recall-oriented understudy for gisting evaluation (ROUGE) score, [128](ch19.xhtml#page_128),
    [131](ch19.xhtml#page_131)–[132](ch19.xhtml#page_132), [133](ch19.xhtml#page_133),
    [134](ch19.xhtml#page_134)
  prefs: []
  type: TYPE_NORMAL
- en: reconstruction error, measuring, [218](appendix.xhtml#page_218)
  prefs: []
  type: TYPE_NORMAL
- en: reconstruction loss, [52](ch09.xhtml#page_52)
  prefs: []
  type: TYPE_NORMAL
- en: rectified linear unit (ReLU) activation function, [21](ch04.xhtml#page_21),
    [209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: recurrent neural networks (RNNs), [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101),
    [103](ch16.xhtml#page_103), [112](ch17.xhtml#page_112). *See also* neural networks
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting
  prefs: []
  type: TYPE_NORMAL
- en: with data, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27), [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: with model modifications, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: regression, conformal prediction and confidence intervals for, [178](ch26.xhtml#page_178),
    [220](appendix.xhtml#page_220)
  prefs: []
  type: TYPE_NORMAL
- en: regularization, reducing overfitting with, [30](ch06.xhtml#page_30)–[31](ch06.xhtml#page_31),
    [36](ch06.xhtml#page_36)
  prefs: []
  type: TYPE_NORMAL
- en: reinforcement learning with human feedback (RLHF), [124](ch18.xhtml#page_124)
  prefs: []
  type: TYPE_NORMAL
- en: relative positional embeddings (relative positional encodings), [82](ch13.xhtml#page_82),
    [85](ch13.xhtml#page_85)
  prefs: []
  type: TYPE_NORMAL
- en: ReLU (rectified linear unit) activation function, [21](ch04.xhtml#page_21),
    [209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: reparameterization, [151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: representation learning, [11](ch02.xhtml#page_11)
  prefs: []
  type: TYPE_NORMAL
- en: representations, [3](ch01.xhtml#page_3), [6](ch01.xhtml#page_6)–[7](ch01.xhtml#page_7)
  prefs: []
  type: TYPE_NORMAL
- en: RepVGG CNN architecture, [151](ch22.xhtml#page_151), [152](ch22.xhtml#page_152)
  prefs: []
  type: TYPE_NORMAL
- en: residual connection in transformer architecture, [107](ch17.xhtml#page_107)
  prefs: []
  type: TYPE_NORMAL
- en: ResNet-34 convolutional neural networks, [146](ch21.xhtml#page_146), [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: resources, online, [xxviii](ch00.xhtml#page_xxviii)
  prefs: []
  type: TYPE_NORMAL
- en: retraining
  prefs: []
  type: TYPE_NORMAL
- en: with different random seeds, [169](ch25.xhtml#page_169)–[170](ch25.xhtml#page_170)
  prefs: []
  type: TYPE_NORMAL
- en: stateless, [139](ch20.xhtml#page_139)–[140](ch20.xhtml#page_140), [141](ch20.xhtml#page_141),
    [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: RLHF (reinforcement learning with human feedback), [124](ch18.xhtml#page_124)
  prefs: []
  type: TYPE_NORMAL
- en: RNNs (recurrent neural networks), [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101),
    [103](ch16.xhtml#page_103), [112](ch17.xhtml#page_112). *See also* neural networks
  prefs: []
  type: TYPE_NORMAL
- en: RoBERTa (robustly optimized BERT approach), [108](ch17.xhtml#page_108), [112](ch17.xhtml#page_112)
  prefs: []
  type: TYPE_NORMAL
- en: root mean square error (RMSE), [183](ch27.xhtml#page_183), [220](appendix.xhtml#page_220)–[221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: root-squared error, [181](ch27.xhtml#page_181)
  prefs: []
  type: TYPE_NORMAL
- en: ROUGE (recall-oriented understudy for gisting evaluation) score, [128](ch19.xhtml#page_128),
    [131](ch19.xhtml#page_131)–[132](ch19.xhtml#page_132), [133](ch19.xhtml#page_133),
    [134](ch19.xhtml#page_134)
  prefs: []
  type: TYPE_NORMAL
- en: runtime algorithms as source of randomness, [61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
  prefs: []
  type: TYPE_NORMAL
- en: '**S**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SAINT method, [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: sample contrastive self-supervised learning, [14](ch02.xhtml#page_14)
  prefs: []
  type: TYPE_NORMAL
- en: sampling as source of randomness, [60](ch10.xhtml#page_60), [65](ch10.xhtml#page_65)
  prefs: []
  type: TYPE_NORMAL
- en: sanity check, [189](ch29.xhtml#page_189)
  prefs: []
  type: TYPE_NORMAL
- en: scaled-dot product attention, [40](ch07.xhtml#page_40), [42](ch07.xhtml#page_42).
    *See also* self-attention mechanism
  prefs: []
  type: TYPE_NORMAL
- en: SCARF method, [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: score method of conformal prediction, [176](ch26.xhtml#page_176)–[177](ch26.xhtml#page_177),
    [178](ch26.xhtml#page_178)
  prefs: []
  type: TYPE_NORMAL
- en: SE (squared error) loss, [181](ch27.xhtml#page_181)
  prefs: []
  type: TYPE_NORMAL
- en: seeding random generator, [60](ch10.xhtml#page_60), [61](ch10.xhtml#page_61)
  prefs: []
  type: TYPE_NORMAL
- en: self-attention mechanism. *See also* transformers
  prefs: []
  type: TYPE_NORMAL
- en: vs. Bahdanau attention mechanism, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [99](ch16.xhtml#page_99), [101](ch16.xhtml#page_101)–[102](ch16.xhtml#page_102)
  prefs: []
  type: TYPE_NORMAL
- en: sequence parallelism, [40](ch07.xhtml#page_40)
  prefs: []
  type: TYPE_NORMAL
- en: transformers, [42](ch07.xhtml#page_42), [43](ch08.xhtml#page_43)–[45](ch08.xhtml#page_45),
    [46](ch08.xhtml#page_46), [47](ch08.xhtml#page_47)
  prefs: []
  type: TYPE_NORMAL
- en: in vision transformers, [83](ch13.xhtml#page_83)–[84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: self-prediction, [11](ch02.xhtml#page_11)–[12](ch02.xhtml#page_12)
  prefs: []
  type: TYPE_NORMAL
- en: self-supervised learning
  prefs: []
  type: TYPE_NORMAL
- en: contrastive, [12](ch02.xhtml#page_12)–[14](ch02.xhtml#page_14)
  prefs: []
  type: TYPE_NORMAL
- en: encoder-only architectures, [108](ch17.xhtml#page_108)
  prefs: []
  type: TYPE_NORMAL
- en: leveraging unlabeled data, [11](ch02.xhtml#page_11)
  prefs: []
  type: TYPE_NORMAL
- en: limited labeled data, [194](ch30.xhtml#page_194)–[195](ch30.xhtml#page_195),
    [203](ch30.xhtml#page_203), [204](ch30.xhtml#page_204), [221](appendix.xhtml#page_221)–[222](appendix.xhtml#page_222)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [9](ch02.xhtml#page_9)
  prefs: []
  type: TYPE_NORMAL
- en: pretraining transformers via, [45](ch08.xhtml#page_45)
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting with, [25](ch05.xhtml#page_25)
  prefs: []
  type: TYPE_NORMAL
- en: self-prediction, [11](ch02.xhtml#page_11)–[14](ch02.xhtml#page_14)
  prefs: []
  type: TYPE_NORMAL
- en: vs. transfer learning, [9](ch02.xhtml#page_9)–[11](ch02.xhtml#page_11)
  prefs: []
  type: TYPE_NORMAL
- en: self-training, [199](ch30.xhtml#page_199). *See also* knowledge distillation
  prefs: []
  type: TYPE_NORMAL
- en: semi-supervised learning, [198](ch30.xhtml#page_198)–[199](ch30.xhtml#page_199),
    [203](ch30.xhtml#page_203)
  prefs: []
  type: TYPE_NORMAL
- en: sentence shuffling, [95](ch15.xhtml#page_95)
  prefs: []
  type: TYPE_NORMAL
- en: '[SEP] token, [108](ch17.xhtml#page_108)'
  prefs: []
  type: TYPE_NORMAL
- en: sequence parallelism, [40](ch07.xhtml#page_40)–[41](ch07.xhtml#page_41), [42](ch07.xhtml#page_42)
  prefs: []
  type: TYPE_NORMAL
- en: sequence-to-sequence (seq2seq) models, [107](ch17.xhtml#page_107)–[110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: sequential inference, [148](ch22.xhtml#page_148)
  prefs: []
  type: TYPE_NORMAL
- en: SGD (stochastic gradient descent) optimizer, [73](ch11.xhtml#page_73), [212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: shortcut connection, [107](ch17.xhtml#page_107)
  prefs: []
  type: TYPE_NORMAL
- en: siamese network setup, [13](ch02.xhtml#page_13)
  prefs: []
  type: TYPE_NORMAL
- en: similarity, embeddings as encoding, [5](ch01.xhtml#page_5)
  prefs: []
  type: TYPE_NORMAL
- en: .632 bootstrap, [171](ch25.xhtml#page_171)
  prefs: []
  type: TYPE_NORMAL
- en: skip connection in transformer architecture, [107](ch17.xhtml#page_107)
  prefs: []
  type: TYPE_NORMAL
- en: skip-gram approach, Word2vec, [90](ch14.xhtml#page_90)
  prefs: []
  type: TYPE_NORMAL
- en: smaller models, reducing overfitting with, [31](ch06.xhtml#page_31)–[33](ch06.xhtml#page_33)
  prefs: []
  type: TYPE_NORMAL
- en: soft attention, [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: soft parameter sharing, [200](ch30.xhtml#page_200)
  prefs: []
  type: TYPE_NORMAL
- en: soft prompting, [119](ch18.xhtml#page_119)–[121](ch18.xhtml#page_121), [125](ch18.xhtml#page_125)
  prefs: []
  type: TYPE_NORMAL
- en: sources of randomness
  prefs: []
  type: TYPE_NORMAL
- en: dataset sampling and shuffling, [60](ch10.xhtml#page_60)
  prefs: []
  type: TYPE_NORMAL
- en: different runtime algorithms, [61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
  prefs: []
  type: TYPE_NORMAL
- en: and generative AI, [62](ch10.xhtml#page_62)–[64](ch10.xhtml#page_64)
  prefs: []
  type: TYPE_NORMAL
- en: hardware and drivers, [62](ch10.xhtml#page_62)
  prefs: []
  type: TYPE_NORMAL
- en: model weight initialization, [59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
  prefs: []
  type: TYPE_NORMAL
- en: nondeterministic algorithms, [61](ch10.xhtml#page_61)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [59](ch10.xhtml#page_59)
  prefs: []
  type: TYPE_NORMAL
- en: spatial attention, [215](appendix.xhtml#page_215)
  prefs: []
  type: TYPE_NORMAL
- en: spatial invariance, [80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
  prefs: []
  type: TYPE_NORMAL
- en: speeding up inference. *See* model inference, speeding up
  prefs: []
  type: TYPE_NORMAL
- en: squared error (SE) loss, [181](ch27.xhtml#page_181)
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion latent diffusion model, [58](ch09.xhtml#page_58)
  prefs: []
  type: TYPE_NORMAL
- en: stacking (stacked generalization), [33](ch06.xhtml#page_33)
  prefs: []
  type: TYPE_NORMAL
- en: stateful training, [139](ch20.xhtml#page_139), [140](ch20.xhtml#page_140)–[141](ch20.xhtml#page_141),
    [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: stateless training (stateless retraining), [139](ch20.xhtml#page_139)–[140](ch20.xhtml#page_140),
    [141](ch20.xhtml#page_141), [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: statistical population, [164](ch25.xhtml#page_164)
  prefs: []
  type: TYPE_NORMAL
- en: statistical two-sample tests, [218](appendix.xhtml#page_218)
  prefs: []
  type: TYPE_NORMAL
- en: stochastic diffusion process, [56](ch09.xhtml#page_56)
  prefs: []
  type: TYPE_NORMAL
- en: stochastic gradient descent (SGD) optimizer, [73](ch11.xhtml#page_73), [212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: stride, [78](ch12.xhtml#page_78), [213](appendix.xhtml#page_213)
  prefs: []
  type: TYPE_NORMAL
- en: structured pruning, [20](ch04.xhtml#page_20)
  prefs: []
  type: TYPE_NORMAL
- en: student in knowledge distillation, [31](ch06.xhtml#page_31)–[32](ch06.xhtml#page_32)
  prefs: []
  type: TYPE_NORMAL
- en: supervised learning, [15](ch03.xhtml#page_15). *See also* limited labeled data
  prefs: []
  type: TYPE_NORMAL
- en: support set in few-shot learning, [16](ch03.xhtml#page_16)
  prefs: []
  type: TYPE_NORMAL
- en: synonym replacement (text augmentation), [93](ch15.xhtml#page_93)–[94](ch15.xhtml#page_94)
  prefs: []
  type: TYPE_NORMAL
- en: synthetic data generation, [96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
  prefs: []
  type: TYPE_NORMAL
- en: '**T**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: TabNet, [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: tabular data, self-supervised learning for, [14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: teacher in knowledge distillation, [31](ch06.xhtml#page_31)–[32](ch06.xhtml#page_32)
  prefs: []
  type: TYPE_NORMAL
- en: 10-fold cross-validation, [187](ch28.xhtml#page_187), [188](ch28.xhtml#page_188)
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow framework, [59](ch10.xhtml#page_59), [62](ch10.xhtml#page_62), [149](ch22.xhtml#page_149)
  prefs: []
  type: TYPE_NORMAL
- en: tensor parallelism, [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38)–[40](ch07.xhtml#page_40),
    [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42), [211](appendix.xhtml#page_211)
  prefs: []
  type: TYPE_NORMAL
- en: test sets
  prefs: []
  type: TYPE_NORMAL
- en: bootstrapping, [169](ch25.xhtml#page_169), [170](ch25.xhtml#page_170), [171](ch25.xhtml#page_171)
  prefs: []
  type: TYPE_NORMAL
- en: conformal predictions, [176](ch26.xhtml#page_176)
  prefs: []
  type: TYPE_NORMAL
- en: discordance with training sets, [189](ch29.xhtml#page_189)–[191](ch29.xhtml#page_191),
    [221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: text, data augmentation for, [93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97),
    [214](appendix.xhtml#page_214)–[215](appendix.xhtml#page_215)
  prefs: []
  type: TYPE_NORMAL
- en: T5 encoder-decoder architecture, [112](ch17.xhtml#page_112)
  prefs: []
  type: TYPE_NORMAL
- en: time complexity of self-attention, [103](ch16.xhtml#page_103), [215](appendix.xhtml#page_215)
  prefs: []
  type: TYPE_NORMAL
- en: top-*k* sampling, [63](ch10.xhtml#page_63)–[64](ch10.xhtml#page_64), [212](appendix.xhtml#page_212)
  prefs: []
  type: TYPE_NORMAL
- en: training. *See also* multi-GPU training paradigms; pretraining; randomness,
    sources of; retraining
  prefs: []
  type: TYPE_NORMAL
- en: epochs, tuning number of, [35](ch06.xhtml#page_35), [210](appendix.xhtml#page_210)
  prefs: []
  type: TYPE_NORMAL
- en: post-training quantization, [151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: procedure for lottery ticket hypothesis, [19](ch04.xhtml#page_19)–[20](ch04.xhtml#page_20)
  prefs: []
  type: TYPE_NORMAL
- en: quantization-aware, [151](ch22.xhtml#page_151)
  prefs: []
  type: TYPE_NORMAL
- en: self-training, [199](ch30.xhtml#page_199)
  prefs: []
  type: TYPE_NORMAL
- en: stateless and stateful, [139](ch20.xhtml#page_139)–[141](ch20.xhtml#page_141),
    [217](appendix.xhtml#page_217)
  prefs: []
  type: TYPE_NORMAL
- en: training sets
  prefs: []
  type: TYPE_NORMAL
- en: conformal predictions, [176](ch26.xhtml#page_176), [177](ch26.xhtml#page_177)
  prefs: []
  type: TYPE_NORMAL
- en: discordance with test sets, [189](ch29.xhtml#page_189)–[191](ch29.xhtml#page_191),
    [221](appendix.xhtml#page_221)
  prefs: []
  type: TYPE_NORMAL
- en: for vision transformers, [79](ch13.xhtml#page_79)–[85](ch13.xhtml#page_85),
    [213](appendix.xhtml#page_213)–[214](appendix.xhtml#page_214)
  prefs: []
  type: TYPE_NORMAL
- en: transfer learning
  prefs: []
  type: TYPE_NORMAL
- en: limited labeled data, [194](ch30.xhtml#page_194), [203](ch30.xhtml#page_203),
    [204](ch30.xhtml#page_204), [221](appendix.xhtml#page_221)–[222](appendix.xhtml#page_222)
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting with, [25](ch05.xhtml#page_25), [26](ch05.xhtml#page_26),
    [209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: vs. self-supervised learning, [9](ch02.xhtml#page_9)–[11](ch02.xhtml#page_11)
  prefs: []
  type: TYPE_NORMAL
- en: transformers. *See also* self-attention mechanism
  prefs: []
  type: TYPE_NORMAL
- en: adapting pretrained language models, [124](ch18.xhtml#page_124)–[125](ch18.xhtml#page_125)
  prefs: []
  type: TYPE_NORMAL
- en: attention mechanism, [40](ch07.xhtml#page_40), [43](ch08.xhtml#page_43)–[45](ch08.xhtml#page_45)
  prefs: []
  type: TYPE_NORMAL
- en: classification tasks, [113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116)
  prefs: []
  type: TYPE_NORMAL
- en: contemporary models, [111](ch17.xhtml#page_111)–[112](ch17.xhtml#page_112)
  prefs: []
  type: TYPE_NORMAL
- en: decoders, [108](ch17.xhtml#page_108)–[110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: encoder-decoder hybrids, [110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: encoders, [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
  prefs: []
  type: TYPE_NORMAL
- en: in-context learning, indexing, and prompt tuning, [116](ch18.xhtml#page_116)–[119](ch18.xhtml#page_119)
  prefs: []
  type: TYPE_NORMAL
- en: multi-GPU training paradigms, [40](ch07.xhtml#page_40), [42](ch07.xhtml#page_42)
  prefs: []
  type: TYPE_NORMAL
- en: number of parameters, [45](ch08.xhtml#page_45)
  prefs: []
  type: TYPE_NORMAL
- en: original architecture for, [105](ch17.xhtml#page_105)–[110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: overview, [105](ch17.xhtml#page_105), [113](ch18.xhtml#page_113)
  prefs: []
  type: TYPE_NORMAL
- en: parallelization, [45](ch08.xhtml#page_45)–[46](ch08.xhtml#page_46)
  prefs: []
  type: TYPE_NORMAL
- en: parameter-efficient fine-tuning, [119](ch18.xhtml#page_119)–[124](ch18.xhtml#page_124)
  prefs: []
  type: TYPE_NORMAL
- en: pretraining via self-supervised learning, [45](ch08.xhtml#page_45)
  prefs: []
  type: TYPE_NORMAL
- en: reinforcement learning with human feedback (RLHF), [124](ch18.xhtml#page_124)
  prefs: []
  type: TYPE_NORMAL
- en: success of, [43](ch08.xhtml#page_43)–[47](ch08.xhtml#page_47)
  prefs: []
  type: TYPE_NORMAL
- en: terminology, [110](ch17.xhtml#page_110)
  prefs: []
  type: TYPE_NORMAL
- en: transfer learning, [11](ch02.xhtml#page_11)
  prefs: []
  type: TYPE_NORMAL
- en: translation
  prefs: []
  type: TYPE_NORMAL
- en: back, [96](ch15.xhtml#page_96)
  prefs: []
  type: TYPE_NORMAL
- en: invariance and equivariance, [80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
  prefs: []
  type: TYPE_NORMAL
- en: tokens, [44](ch08.xhtml#page_44)–[46](ch08.xhtml#page_46), [63](ch10.xhtml#page_63)–[64](ch10.xhtml#page_64),
    [102](ch16.xhtml#page_102), [106](ch17.xhtml#page_106)–[110](ch17.xhtml#page_110),
    [117](ch18.xhtml#page_117)–[118](ch18.xhtml#page_118)
  prefs: []
  type: TYPE_NORMAL
- en: triangle inequality, [180](ch27.xhtml#page_180), [181](ch27.xhtml#page_181),
    [182](ch27.xhtml#page_182)
  prefs: []
  type: TYPE_NORMAL
- en: true generalization accuracy, [164](ch25.xhtml#page_164)
  prefs: []
  type: TYPE_NORMAL
- en: two-dimensional embeddings, [4](ch01.xhtml#page_4)–[5](ch01.xhtml#page_5)
  prefs: []
  type: TYPE_NORMAL
- en: typo introduction, [95](ch15.xhtml#page_95)
  prefs: []
  type: TYPE_NORMAL
- en: '**U**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: unlabeled data in self-supervised learning, [10](ch02.xhtml#page_10), [11](ch02.xhtml#page_11)
  prefs: []
  type: TYPE_NORMAL
- en: unstructured pruning, [20](ch04.xhtml#page_20)
  prefs: []
  type: TYPE_NORMAL
- en: unsupervised pretraining. *See* self-supervised learning
  prefs: []
  type: TYPE_NORMAL
- en: '**V**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: variational autoencoders (VAEs), [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52),
    [53](ch09.xhtml#page_53), [54](ch09.xhtml#page_54), [57](ch09.xhtml#page_57),
    [58](ch09.xhtml#page_58)
  prefs: []
  type: TYPE_NORMAL
- en: variational inference, [51](ch09.xhtml#page_51)
  prefs: []
  type: TYPE_NORMAL
- en: vectorization, [148](ch22.xhtml#page_148)–[149](ch22.xhtml#page_149), [152](ch22.xhtml#page_152),
    [218](appendix.xhtml#page_218)
  prefs: []
  type: TYPE_NORMAL
- en: VideoBERT model, [201](ch30.xhtml#page_201), [204](ch30.xhtml#page_204)
  prefs: []
  type: TYPE_NORMAL
- en: video data, applying self-supervised learning to, [14](ch02.xhtml#page_14),
    [208](appendix.xhtml#page_208)
  prefs: []
  type: TYPE_NORMAL
- en: vision transformers (ViTs)
  prefs: []
  type: TYPE_NORMAL
- en: vs. convolutional neural networks, [79](ch13.xhtml#page_79), [82](ch13.xhtml#page_82)–[83](ch13.xhtml#page_83),
    [84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: inductive biases in, [83](ch13.xhtml#page_83)–[84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: large training sets for, [79](ch13.xhtml#page_79)
  prefs: []
  type: TYPE_NORMAL
- en: positional information in, [82](ch13.xhtml#page_82), [85](ch13.xhtml#page_85)
  prefs: []
  type: TYPE_NORMAL
- en: recommendations for, [84](ch13.xhtml#page_84)
  prefs: []
  type: TYPE_NORMAL
- en: '**W**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: weakly supervised learning, [197](ch30.xhtml#page_197)–[199](ch30.xhtml#page_199),
    [203](ch30.xhtml#page_203)
  prefs: []
  type: TYPE_NORMAL
- en: weight decay, [30](ch06.xhtml#page_30), [35](ch06.xhtml#page_35)
  prefs: []
  type: TYPE_NORMAL
- en: weighted loss function, [155](ch23.xhtml#page_155)
  prefs: []
  type: TYPE_NORMAL
- en: weight initialization, [59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
  prefs: []
  type: TYPE_NORMAL
- en: weight normalization, [34](ch06.xhtml#page_34)–[35](ch06.xhtml#page_35)
  prefs: []
  type: TYPE_NORMAL
- en: weight pruning, [19](ch04.xhtml#page_19), [20](ch04.xhtml#page_20)
  prefs: []
  type: TYPE_NORMAL
- en: weights
  prefs: []
  type: TYPE_NORMAL
- en: in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71),
    [76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
  prefs: []
  type: TYPE_NORMAL
- en: in fully connected layers, [72](ch11.xhtml#page_72), [76](ch12.xhtml#page_76)
  prefs: []
  type: TYPE_NORMAL
- en: weight sharing, [80](ch13.xhtml#page_80), [81](ch13.xhtml#page_81)
  prefs: []
  type: TYPE_NORMAL
- en: winning tickets (lottery ticket hypothesis), [20](ch04.xhtml#page_20), [21](ch04.xhtml#page_21)
  prefs: []
  type: TYPE_NORMAL
- en: Winograd-based convolution, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  prefs: []
  type: TYPE_NORMAL
- en: word deletion (text augmentation), [94](ch15.xhtml#page_94)
  prefs: []
  type: TYPE_NORMAL
- en: word embeddings. *See* embeddings
  prefs: []
  type: TYPE_NORMAL
- en: WordNet thesaurus, [94](ch15.xhtml#page_94), [97](ch15.xhtml#page_97)
  prefs: []
  type: TYPE_NORMAL
- en: word position swapping (word shuffling/permutation), [94](ch15.xhtml#page_94)–[95](ch15.xhtml#page_95)
  prefs: []
  type: TYPE_NORMAL
- en: Word2vec model, [90](ch14.xhtml#page_90), [92](ch14.xhtml#page_92)
  prefs: []
  type: TYPE_NORMAL
- en: '**X**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: XGBoost model, [26](ch05.xhtml#page_26), [209](appendix.xhtml#page_209)
  prefs: []
  type: TYPE_NORMAL
- en: '**Z**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: zero-shot learning, [195](ch30.xhtml#page_195)–[196](ch30.xhtml#page_196). *See
    also* few-shot learning; in-context learning
  prefs: []
  type: TYPE_NORMAL
- en: '*z*-scores (confidence intervals), [166](ch25.xhtml#page_166)'
  prefs: []
  type: TYPE_NORMAL
