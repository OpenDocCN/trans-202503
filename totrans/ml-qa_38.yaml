- en: '**INDEX**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**索引**'
- en: '**A**'
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**A**'
- en: active learning, [195](ch30.xhtml#page_195), [203](ch30.xhtml#page_203)–[204](ch30.xhtml#page_204),
    [222](appendix.xhtml#page_222)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习, [195](ch30.xhtml#page_195), [203](ch30.xhtml#page_203)–[204](ch30.xhtml#page_204),
    [222](appendix.xhtml#page_222)
- en: Adam optimizer, [42](ch07.xhtml#page_42), [73](ch11.xhtml#page_73), [211](appendix.xhtml#page_211),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Adam优化器, [42](ch07.xhtml#page_42), [73](ch11.xhtml#page_73), [211](appendix.xhtml#page_211),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
- en: adapter methods, [119](ch18.xhtml#page_119), [121](ch18.xhtml#page_121)–[123](ch18.xhtml#page_123),
    [125](ch18.xhtml#page_125)–[126](ch18.xhtml#page_126), [216](appendix.xhtml#page_216)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 适配器方法, [119](ch18.xhtml#page_119), [121](ch18.xhtml#page_121)–[123](ch18.xhtml#page_123),
    [125](ch18.xhtml#page_125)–[126](ch18.xhtml#page_126), [216](appendix.xhtml#page_216)
- en: Add & Norm step, [107](ch17.xhtml#page_107)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Add & Norm步骤, [107](ch17.xhtml#page_107)
- en: adversarial examples, [27](ch05.xhtml#page_27)
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗样本, [27](ch05.xhtml#page_27)
- en: adversarial validation, [154](ch23.xhtml#page_154), [190](ch29.xhtml#page_190)–[191](ch29.xhtml#page_191),
    [218](appendix.xhtml#page_218), [221](appendix.xhtml#page_221)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗验证, [154](ch23.xhtml#page_154), [190](ch29.xhtml#page_190)–[191](ch29.xhtml#page_191),
    [218](appendix.xhtml#page_218), [221](appendix.xhtml#page_221)
- en: AI (artificial intelligence)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能（AI）
- en: data-centric, [143](ch21.xhtml#page_143)–[146](ch21.xhtml#page_146), [217](appendix.xhtml#page_217)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以数据为中心, [143](ch21.xhtml#page_143)–[146](ch21.xhtml#page_146), [217](appendix.xhtml#page_217)
- en: model-centric, [143](ch21.xhtml#page_143)–[144](ch21.xhtml#page_144), [145](ch21.xhtml#page_145)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以模型为中心, [143](ch21.xhtml#page_143)–[144](ch21.xhtml#page_144), [145](ch21.xhtml#page_145)
- en: AlexNet, [6](ch01.xhtml#page_6), [7](ch01.xhtml#page_7)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet, [6](ch01.xhtml#page_6), [7](ch01.xhtml#page_7)
- en: asymptotic coverage guarantees, confidence intervals, [177](ch26.xhtml#page_177)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 渐近覆盖保证, 置信区间, [177](ch26.xhtml#page_177)
- en: attention mechanism. *See also* self-attention mechanism
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制。*另见* 自注意力机制
- en: Bahdanau, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101), [103](ch16.xhtml#page_103),
    [112](ch17.xhtml#page_112)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 巴赫达诺（Bahdanau）, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101), [103](ch16.xhtml#page_103),
    [112](ch17.xhtml#page_112)
- en: transformers, [40](ch07.xhtml#page_40), [43](ch08.xhtml#page_43)–[45](ch08.xhtml#page_45),
    [46](ch08.xhtml#page_46), [47](ch08.xhtml#page_47)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 转换器, [40](ch07.xhtml#page_40), [43](ch08.xhtml#page_43)–[45](ch08.xhtml#page_45),
    [46](ch08.xhtml#page_46), [47](ch08.xhtml#page_47)
- en: augmented data
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 增强数据
- en: reducing overfitting with, [24](ch05.xhtml#page_24)–[25](ch05.xhtml#page_25),
    [26](ch05.xhtml#page_26), [210](appendix.xhtml#page_210)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用减少过拟合的技术, [24](ch05.xhtml#page_24)–[25](ch05.xhtml#page_25), [26](ch05.xhtml#page_26),
    [210](appendix.xhtml#page_210)
- en: for text, [93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97), [214](appendix.xhtml#page_214)–[215](appendix.xhtml#page_215)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对文本的优化, [93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97), [214](appendix.xhtml#page_214)–[215](appendix.xhtml#page_215)
- en: autoencoders
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器
- en: defined, [51](ch09.xhtml#page_51)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 已定义, [51](ch09.xhtml#page_51)
- en: latent space, [5](ch01.xhtml#page_5)–[6](ch01.xhtml#page_6)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在空间, [5](ch01.xhtml#page_5)–[6](ch01.xhtml#page_6)
- en: variational, [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 变分方法, [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
- en: automatic prompt engineering method, [125](ch18.xhtml#page_125)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 自动提示工程方法, [125](ch18.xhtml#page_125)
- en: autoregressive decoding, [107](ch17.xhtml#page_107)–[110](ch17.xhtml#page_110)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归解码, [107](ch17.xhtml#page_107)–[110](ch17.xhtml#page_110)
- en: autoregressive models, [54](ch09.xhtml#page_54)–[55](ch09.xhtml#page_55), [57](ch09.xhtml#page_57),
    [63](ch10.xhtml#page_63)–[64](ch10.xhtml#page_64)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归模型, [54](ch09.xhtml#page_54)–[55](ch09.xhtml#page_55), [57](ch09.xhtml#page_57),
    [63](ch10.xhtml#page_63)–[64](ch10.xhtml#page_64)
- en: auxiliary tasks, [199](ch30.xhtml#page_199)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 辅助任务, [199](ch30.xhtml#page_199)
- en: '**B**'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**B**'
- en: backpropagation, [115](ch18.xhtml#page_115)–[116](ch18.xhtml#page_116)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播, [115](ch18.xhtml#page_115)–[116](ch18.xhtml#page_116)
- en: back translation, [96](ch15.xhtml#page_96)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 回译, [96](ch15.xhtml#page_96)
- en: bag-of-words model, [207](appendix.xhtml#page_207)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 词袋模型, [207](appendix.xhtml#page_207)
- en: continuous bag-of-words (CBOW) approach, [90](ch14.xhtml#page_90)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 连续词袋（CBOW）方法, [90](ch14.xhtml#page_90)
- en: Bahdanau attention mechanism, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101),
    [103](ch16.xhtml#page_103), [112](ch17.xhtml#page_112)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 巴赫达诺注意力机制, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101), [103](ch16.xhtml#page_103),
    [112](ch17.xhtml#page_112)
- en: BART encoder-decoder architecture, [112](ch17.xhtml#page_112)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: BART 编码器-解码器架构, [112](ch17.xhtml#page_112)
- en: base classes in few-shot learning, [16](ch03.xhtml#page_16)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 小样本学习中的基类, [16](ch03.xhtml#page_16)
- en: Basic Linear Algebra Subprograms (BLAS), [148](ch22.xhtml#page_148), [152](ch22.xhtml#page_152)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基本线性代数子程序（BLAS）, [148](ch22.xhtml#page_148), [152](ch22.xhtml#page_152)
- en: batched inference, [147](ch22.xhtml#page_147)–[148](ch22.xhtml#page_148)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 批量推理, [147](ch22.xhtml#page_147)–[148](ch22.xhtml#page_148)
- en: batch normalization (BatchNorm), [73](ch11.xhtml#page_73), [213](appendix.xhtml#page_213)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 批量归一化（BatchNorm）, [73](ch11.xhtml#page_73), [213](appendix.xhtml#page_213)
- en: Berry–Esseen theorem, [167](ch25.xhtml#page_167), [171](ch25.xhtml#page_171)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 贝瑞–埃西恩定理，[167](ch25.xhtml#page_167)，[171](ch25.xhtml#page_171)
- en: BERT model
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: BERT模型
- en: adopting for classification tasks, [112](ch17.xhtml#page_112), [215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 用于分类任务，[112](ch17.xhtml#page_112)，[215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)
- en: distributional hypothesis, [91](ch14.xhtml#page_91), [92](ch14.xhtml#page_92)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 分布假设，[91](ch14.xhtml#page_91)，[92](ch14.xhtml#page_92)
- en: encoder-only architectures, [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 仅编码器架构，[107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
- en: BERTScore, [132](ch19.xhtml#page_132)–[133](ch19.xhtml#page_133), [134](ch19.xhtml#page_134),
    [216](appendix.xhtml#page_216)–[217](appendix.xhtml#page_217)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: BERTScore，[132](ch19.xhtml#page_132)–[133](ch19.xhtml#page_133)，[134](ch19.xhtml#page_134)，[216](appendix.xhtml#page_216)–[217](appendix.xhtml#page_217)
- en: bias units
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差单元
- en: in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积层中，[70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)
- en: in fully connected layers, [72](ch11.xhtml#page_72), [76](ch12.xhtml#page_76)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在全连接层中，[72](ch11.xhtml#page_72)，[76](ch12.xhtml#page_76)
- en: binomial proportion confidence interval, [171](ch25.xhtml#page_171)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 二项式比例置信区间，[171](ch25.xhtml#page_171)
- en: BLAS (Basic Linear Algebra Subprograms), [148](ch22.xhtml#page_148), [152](ch22.xhtml#page_152)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: BLAS（基本线性代数子程序），[148](ch22.xhtml#page_148)，[152](ch22.xhtml#page_152)
- en: BLEU (bilingual evaluation understudy) score, [128](ch19.xhtml#page_128), [129](ch19.xhtml#page_129)–[131](ch19.xhtml#page_131),
    [133](ch19.xhtml#page_133), [134](ch19.xhtml#page_134)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: BLEU（双语评估下游任务）分数，[128](ch19.xhtml#page_128)，[129](ch19.xhtml#page_129)–[131](ch19.xhtml#page_131)，[133](ch19.xhtml#page_133)，[134](ch19.xhtml#page_134)
- en: bootstrapping
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 自助法
- en: improving performance with limited data, [194](ch30.xhtml#page_194)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用有限数据提高性能，[194](ch30.xhtml#page_194)
- en: out-of-bag, [167](ch25.xhtml#page_167)–[169](ch25.xhtml#page_169), [170](ch25.xhtml#page_170),
    [171](ch25.xhtml#page_171)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 包外样本，[167](ch25.xhtml#page_167)–[169](ch25.xhtml#page_169)，[170](ch25.xhtml#page_170)，[171](ch25.xhtml#page_171)
- en: test set predictions, [169](ch25.xhtml#page_169), [170](ch25.xhtml#page_170),
    [171](ch25.xhtml#page_171), [219](appendix.xhtml#page_219)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集预测，[169](ch25.xhtml#page_169)，[170](ch25.xhtml#page_170)，[171](ch25.xhtml#page_171)，[219](appendix.xhtml#page_219)
- en: '**C**'
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**C**'
- en: calibration set, [176](ch26.xhtml#page_176)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 校准集，[176](ch26.xhtml#page_176)
- en: CBOW (continuous bag-of-words) approach, [90](ch14.xhtml#page_90)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: CBOW（连续词袋模型）方法，[90](ch14.xhtml#page_90)
- en: CE (cross-entropy) loss, [128](ch19.xhtml#page_128), [182](ch27.xhtml#page_182)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: CE（交叉熵）损失，[128](ch19.xhtml#page_128)，[182](ch27.xhtml#page_182)
- en: central limit theorem, [167](ch25.xhtml#page_167), [171](ch25.xhtml#page_171)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 中心极限定理，[167](ch25.xhtml#page_167)，[171](ch25.xhtml#page_171)
- en: ChatGPT model
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT模型
- en: autoregressive models, [54](ch09.xhtml#page_54)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归模型，[54](ch09.xhtml#page_54)
- en: randomness by design, [63](ch10.xhtml#page_63)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 设计中的随机性，[63](ch10.xhtml#page_63)
- en: reinforcement learning with human feedback (RLHF), [124](ch18.xhtml#page_124)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习与人类反馈（RLHF），[124](ch18.xhtml#page_124)
- en: stateless vs. stateful training, [141](ch20.xhtml#page_141), [217](appendix.xhtml#page_217)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 无状态与有状态训练，[141](ch20.xhtml#page_141)，[217](appendix.xhtml#page_217)
- en: zero-shot learning, [196](ch30.xhtml#page_196)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本学习，[196](ch30.xhtml#page_196)
- en: classic bias-variance theory, [31](ch06.xhtml#page_31), [35](ch06.xhtml#page_35)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的偏差–方差理论，[31](ch06.xhtml#page_31)，[35](ch06.xhtml#page_35)
- en: classification head, [215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 分类头，[215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)
- en: classification tasks
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 分类任务
- en: adopting encoder-style transformers for, [112](ch17.xhtml#page_112), [215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 采用编码器风格变压器，[112](ch17.xhtml#page_112)，[215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)
- en: cross entropy and, [128](ch19.xhtml#page_128)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉熵和，[128](ch19.xhtml#page_128)
- en: fine-tuning decoder-style transformers for, [112](ch17.xhtml#page_112), [216](appendix.xhtml#page_216)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 微调解码器风格变压器，[112](ch17.xhtml#page_112)，[216](appendix.xhtml#page_216)
- en: using pretrained transformers for, [113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练变压器，[113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116)
- en: Cleanlab open source library, [146](ch21.xhtml#page_146)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Cleanlab开源库，[146](ch21.xhtml#page_146)
- en: '[CLS] token, [108](ch17.xhtml#page_108), [215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[CLS]标记，[108](ch17.xhtml#page_108)，[215](appendix.xhtml#page_215)–[216](appendix.xhtml#page_216)'
- en: CNNs. *See* convolutional neural networks; neural networks
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: CNN。*参见* 卷积神经网络；神经网络
- en: coloring video data, [208](appendix.xhtml#page_208)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 视频数据着色，[208](appendix.xhtml#page_208)
- en: Colossal AI, [37](ch07.xhtml#page_37), [42](ch07.xhtml#page_42)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Colossal AI，[37](ch07.xhtml#page_37)，[42](ch07.xhtml#page_42)
- en: COMET neural framework, [131](ch19.xhtml#page_131), [135](ch19.xhtml#page_135)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: COMET神经网络框架，[131](ch19.xhtml#page_131)，[135](ch19.xhtml#page_135)
- en: computer vision
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: calculating number of parameters, [69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 计算参数数量，见[69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73)、[212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
- en: distributional hypothesis, [214](appendix.xhtml#page_214)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 分布假设，见[214](appendix.xhtml#page_214)
- en: fully connected and convolutional layers, [75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78),
    [213](appendix.xhtml#page_213)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层和卷积层，见[75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)、[213](appendix.xhtml#page_213)
- en: large training sets for vision transformers, [79](ch13.xhtml#page_79)–[85](ch13.xhtml#page_85),
    [213](appendix.xhtml#page_213)–[214](appendix.xhtml#page_214)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 用于视觉变压器的大规模训练集，见[79](ch13.xhtml#page_79)–[85](ch13.xhtml#page_85)、[213](appendix.xhtml#page_213)–[214](appendix.xhtml#page_214)
- en: self-attention mechanism, [103](ch16.xhtml#page_103), [215](appendix.xhtml#page_215)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力机制，见[103](ch16.xhtml#page_103)、[215](appendix.xhtml#page_215)
- en: concept drift, [155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移，见[155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156)
- en: confidence intervals
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间
- en: asymptotic coverage guarantees, [177](ch26.xhtml#page_177)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 渐近覆盖保证，见[177](ch26.xhtml#page_177)
- en: bootstrapping test set predictions, [169](ch25.xhtml#page_169)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 引导式测试集预测，见[169](ch25.xhtml#page_169)
- en: bootstrapping training sets, [167](ch25.xhtml#page_167)–[169](ch25.xhtml#page_169)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 引导式训练集，见[167](ch25.xhtml#page_167)–[169](ch25.xhtml#page_169)
- en: vs. conformal predictions, [173](ch26.xhtml#page_173)–[178](ch26.xhtml#page_178)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 与拟合预测的对比，见[173](ch26.xhtml#page_173)–[178](ch26.xhtml#page_178)
- en: defined, [164](ch25.xhtml#page_164)–[165](ch25.xhtml#page_165)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 定义，见[164](ch25.xhtml#page_164)–[165](ch25.xhtml#page_165)
- en: normal approximation intervals, [166](ch25.xhtml#page_166)–[167](ch25.xhtml#page_167)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正态近似区间，见[166](ch25.xhtml#page_166)–[167](ch25.xhtml#page_167)
- en: overview, [163](ch25.xhtml#page_163), [173](ch26.xhtml#page_173)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，见[163](ch25.xhtml#page_163)、[173](ch26.xhtml#page_173)
- en: and prediction intervals, [174](ch26.xhtml#page_174)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 及预测区间，见[174](ch26.xhtml#page_174)
- en: recommendations for, [170](ch25.xhtml#page_170), [178](ch26.xhtml#page_178)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 的建议，见[170](ch25.xhtml#page_170)、[178](ch26.xhtml#page_178)
- en: retraining models with different random seeds, [169](ch25.xhtml#page_169)–[170](ch25.xhtml#page_170)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同随机种子重新训练模型，见[169](ch25.xhtml#page_169)–[170](ch25.xhtml#page_170)
- en: confidence scores in active learning, [204](ch30.xhtml#page_204), [222](appendix.xhtml#page_222)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习中的置信度分数，见[204](ch30.xhtml#page_204)、[222](appendix.xhtml#page_222)
- en: conformal predictions
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合预测
- en: benefits of, [177](ch26.xhtml#page_177)–[178](ch26.xhtml#page_178)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 的好处，见[177](ch26.xhtml#page_177)–[178](ch26.xhtml#page_178)
- en: computing, [175](ch26.xhtml#page_175)–[176](ch26.xhtml#page_176)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 计算，见[175](ch26.xhtml#page_175)–[176](ch26.xhtml#page_176)
- en: example of, [176](ch26.xhtml#page_176)–[177](ch26.xhtml#page_177)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 示例，见[176](ch26.xhtml#page_176)–[177](ch26.xhtml#page_177)
- en: overview, [173](ch26.xhtml#page_173)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，见[173](ch26.xhtml#page_173)
- en: and prediction intervals, [174](ch26.xhtml#page_174)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 及预测区间，见[174](ch26.xhtml#page_174)
- en: recommendations for, [178](ch26.xhtml#page_178)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 的建议，见[178](ch26.xhtml#page_178)
- en: connectivity, [80](ch13.xhtml#page_80), [81](ch13.xhtml#page_81)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 连接性，见[80](ch13.xhtml#page_80)、[81](ch13.xhtml#page_81)
- en: consistency models, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57), [58](ch09.xhtml#page_58),
    [212](appendix.xhtml#page_212)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性模型，见[56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)、[58](ch09.xhtml#page_58)、[212](appendix.xhtml#page_212)
- en: continuous bag-of-words (CBOW) approach, [90](ch14.xhtml#page_90)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 连续词袋模型（CBOW）方法，见[90](ch14.xhtml#page_90)
- en: contrastive learning, [208](appendix.xhtml#page_208)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对比学习，见[208](appendix.xhtml#page_208)
- en: contrastive self-supervised learning, [12](ch02.xhtml#page_12)–[14](ch02.xhtml#page_14)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对比自监督学习，见[12](ch02.xhtml#page_12)–[14](ch02.xhtml#page_14)
- en: convolutional layers
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层
- en: calculating number of parameters in, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 计算参数数量，见[70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)
- en: as high-pass and low-pass filters, [84](ch13.xhtml#page_84)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 作为高通和低通滤波器，见[84](ch13.xhtml#page_84)
- en: recommendations for, [78](ch12.xhtml#page_78)
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 的建议，见[78](ch12.xhtml#page_78)
- en: replacing fully connected layers with, [75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 用卷积层替换全连接层，见[75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)
- en: convolutional neural networks (CNNs). *See also* neural networks
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）。*另见* 神经网络
- en: calculating number of parameters in, [69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 计算参数数量，见[69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73)、[212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
- en: embeddings from, [4](ch01.xhtml#page_4), [6](ch01.xhtml#page_6), [207](appendix.xhtml#page_207)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[4](ch01.xhtml#page_4)、[6](ch01.xhtml#page_6)、[207](appendix.xhtml#page_207)的嵌入
- en: high-pass and low-pass filters in, [84](ch13.xhtml#page_84)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 高通和低通滤波器，见[84](ch13.xhtml#page_84)
- en: inductive biases in, [80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 归纳偏差，见[80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
- en: recommendations for, [84](ch13.xhtml#page_84)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐，[84](ch13.xhtml#page_84)
- en: with vision transformers, [79](ch13.xhtml#page_79), [82](ch13.xhtml#page_82)–[83](ch13.xhtml#page_83),
    [84](ch13.xhtml#page_84)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用视觉变换器，[79](ch13.xhtml#page_79)，[82](ch13.xhtml#page_82)–[83](ch13.xhtml#page_83)，[84](ch13.xhtml#page_84)
- en: convolution operation, [61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积操作，[61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
- en: cosine similarity, [132](ch19.xhtml#page_132), [134](ch19.xhtml#page_134), [216](appendix.xhtml#page_216)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度，[132](ch19.xhtml#page_132)，[134](ch19.xhtml#page_134)，[216](appendix.xhtml#page_216)
- en: count data, [161](ch24.xhtml#page_161)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 计数数据，[161](ch24.xhtml#page_161)
- en: covariate shift, [153](ch23.xhtml#page_153)–[154](ch23.xhtml#page_154), [156](ch23.xhtml#page_156),
    [157](ch23.xhtml#page_157)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 协变量偏移，[153](ch23.xhtml#page_153)–[154](ch23.xhtml#page_154)，[156](ch23.xhtml#page_156)，[157](ch23.xhtml#page_157)
- en: CPUs, data parallelism on, [42](ch07.xhtml#page_42), [211](appendix.xhtml#page_211)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: CPU上的数据并行，[42](ch07.xhtml#page_42)，[211](appendix.xhtml#page_211)
- en: cross-entropy (CE) loss, [128](ch19.xhtml#page_128), [182](ch27.xhtml#page_182)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉熵（CE）损失，[128](ch19.xhtml#page_128)，[182](ch27.xhtml#page_182)
- en: cross-validation
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证
- en: 5-fold cross-validation, [187](ch28.xhtml#page_187), [188](ch28.xhtml#page_188),
    [221](appendix.xhtml#page_221)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 5折交叉验证，[187](ch28.xhtml#page_187)，[188](ch28.xhtml#page_188)，[221](appendix.xhtml#page_221)
- en: '*k*-fold cross-validation, [185](ch28.xhtml#page_185)–[188](ch28.xhtml#page_188),
    [221](appendix.xhtml#page_221)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*折交叉验证，[185](ch28.xhtml#page_185)–[188](ch28.xhtml#page_188)，[221](appendix.xhtml#page_221)'
- en: leave-one-out cross-validation (LOOCV), [188](ch28.xhtml#page_188), [221](appendix.xhtml#page_221)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 留一交叉验证（LOOCV），[188](ch28.xhtml#page_188)，[221](appendix.xhtml#page_221)
- en: 10-fold cross-validation, [187](ch28.xhtml#page_187), [188](ch28.xhtml#page_188)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 10折交叉验证，[187](ch28.xhtml#page_187)，[188](ch28.xhtml#page_188)
- en: CUDA Deep Neural Network library (cuDNN), [62](ch10.xhtml#page_62)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA深度神经网络库（cuDNN），[62](ch10.xhtml#page_62)
- en: '**D**'
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**D**'
- en: data. *See also* limited labeled data
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 数据。*另请参见* 有限标签数据
- en: applying self-supervised learning to video, [14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 将自监督学习应用于视频，[14](ch02.xhtml#page_14)，[208](appendix.xhtml#page_208)
- en: count, [161](ch24.xhtml#page_161)
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 计数，[161](ch24.xhtml#page_161)
- en: reducing overfitting with, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27),
    [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 通过减少过拟合，[23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27)，[209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
- en: self-supervised learning for tabular, [14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习应用于表格数据，[14](ch02.xhtml#page_14)，[208](appendix.xhtml#page_208)
- en: synthetic, generation of, [96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据生成，[96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
- en: unlabeled, in self-supervised learning, [10](ch02.xhtml#page_10), [11](ch02.xhtml#page_11)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 无标签数据，在自监督学习中，[10](ch02.xhtml#page_10)，[11](ch02.xhtml#page_11)
- en: data augmentation
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强
- en: to reduce overfitting, [24](ch05.xhtml#page_24)–[25](ch05.xhtml#page_25), [26](ch05.xhtml#page_26),
    [210](appendix.xhtml#page_210)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 减少过拟合，[24](ch05.xhtml#page_24)–[25](ch05.xhtml#page_25)，[26](ch05.xhtml#page_26)，[210](appendix.xhtml#page_210)
- en: for text, [93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97), [214](appendix.xhtml#page_214)–[215](appendix.xhtml#page_215)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本，[93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97)，[214](appendix.xhtml#page_214)–[215](ch15.xhtml#page_215)
- en: data-centric AI, [143](ch21.xhtml#page_143)–[146](ch21.xhtml#page_146), [217](appendix.xhtml#page_217)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心化AI，[143](ch21.xhtml#page_143)–[146](ch21.xhtml#page_146)，[217](appendix.xhtml#page_217)
- en: data distribution shifts
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分布偏移
- en: concept drift, [155](ch23.xhtml#page_155)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移，[155](ch23.xhtml#page_155)
- en: covariate shift, [153](ch23.xhtml#page_153)–[154](ch23.xhtml#page_154)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 协变量偏移，[153](ch23.xhtml#page_153)–[154](ch23.xhtml#page_154)
- en: domain shift, [155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 领域偏移，[155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156)
- en: label shift, [154](ch23.xhtml#page_154)–[155](ch23.xhtml#page_155)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 标签偏移，[154](ch23.xhtml#page_154)–[155](ch23.xhtml#page_155)
- en: overview, [153](ch23.xhtml#page_153)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[153](ch23.xhtml#page_153)
- en: types of, [156](ch23.xhtml#page_156)–[157](ch23.xhtml#page_157)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 类型，[156](ch23.xhtml#page_156)–[157](ch23.xhtml#page_157)
- en: data parallelism, [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38), [39](ch07.xhtml#page_39)–[40](ch07.xhtml#page_40),
    [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42), [211](appendix.xhtml#page_211)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行，[37](ch07.xhtml#page_37)，[38](ch07.xhtml#page_38)，[39](ch07.xhtml#page_39)–[40](ch07.xhtml#page_40)，[41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)，[211](appendix.xhtml#page_211)
- en: datasets
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集
- en: for few-shot learning, [15](ch03.xhtml#page_15)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习，[15](ch03.xhtml#page_15)
- en: sampling and shuffling as source of randomness, [60](ch10.xhtml#page_60)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 作为随机源的采样和洗牌，[60](ch10.xhtml#page_60)
- en: for transformers, [45](ch08.xhtml#page_45)
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对于变换器，[45](ch08.xhtml#page_45)
- en: DBMs (deep Boltzmann machines), [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51),
    [57](ch09.xhtml#page_57)
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 深度玻尔兹曼机（DBMs），[50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)，[57](ch09.xhtml#page_57)
- en: dead neurons, [209](appendix.xhtml#page_209)
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 死神经元，[209](appendix.xhtml#page_209)
- en: decision trees, [204](ch30.xhtml#page_204)
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树，[204](ch30.xhtml#page_204)
- en: decoder network (VAE model), [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器网络（VAE 模型），[51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
- en: decoders
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器
- en: in Bahdanau attention mechanism, [100](ch16.xhtml#page_100)–[101](ch16.xhtml#page_101)
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在巴赫达瑙注意力机制中，[100](ch16.xhtml#page_100)–[101](ch16.xhtml#page_101)
- en: in original transformer architecture, [105](ch17.xhtml#page_105)–[106](ch17.xhtml#page_106),
    [107](ch17.xhtml#page_107)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始 Transformer 架构中，[105](ch17.xhtml#page_105)–[106](ch17.xhtml#page_106)，[107](ch17.xhtml#page_107)
- en: decoder-style transformers. *See also* encoder-style transformers
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器风格的 Transformer。*另见* 编码器风格的 Transformer
- en: contemporary transformer models, [111](ch17.xhtml#page_111)–[112](ch17.xhtml#page_112)
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当代 Transformer 模型，[111](ch17.xhtml#page_111)–[112](ch17.xhtml#page_112)
- en: distributional hypothesis, [91](ch14.xhtml#page_91)
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 分布假设，[91](ch14.xhtml#page_91)
- en: encoder-decoder hybrids, [110](ch17.xhtml#page_110)
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器-解码器混合，[110](ch17.xhtml#page_110)
- en: overview, [105](ch17.xhtml#page_105), [108](ch17.xhtml#page_108)–[110](ch17.xhtml#page_110)
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 概览，[105](ch17.xhtml#page_105)，[108](ch17.xhtml#page_108)–[110](ch17.xhtml#page_110)
- en: synthetic data generation, [96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据生成，[96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
- en: terminology related to, [110](ch17.xhtml#page_110)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相关的术语，[110](ch17.xhtml#page_110)
- en: deep Boltzmann machines (DBMs), [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51),
    [57](ch09.xhtml#page_57)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 深度玻尔兹曼机（DBMs），[50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)，[57](ch09.xhtml#page_57)
- en: deep generative models. *See* generative AI models
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 深度生成模型。*另见* 生成式 AI 模型
- en: deep learning. *See also* generative AI models
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习。*另见* 生成式 AI 模型
- en: embeddings, [3](ch01.xhtml#page_3)–[7](ch01.xhtml#page_7), [207](appendix.xhtml#page_207)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入，[3](ch01.xhtml#page_3)–[7](ch01.xhtml#page_7)，[207](appendix.xhtml#page_207)
- en: few-shot learning, [15](ch03.xhtml#page_15)–[18](ch03.xhtml#page_18), [208](appendix.xhtml#page_208)–[209](appendix.xhtml#page_209)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 少量学习，[15](ch03.xhtml#page_15)–[18](ch03.xhtml#page_18)，[208](appendix.xhtml#page_208)–[209](appendix.xhtml#page_209)
- en: lottery ticket hypothesis, [19](ch04.xhtml#page_19)–[21](ch04.xhtml#page_21),
    [209](appendix.xhtml#page_209)
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 彩票假设，[19](ch04.xhtml#page_19)–[21](ch04.xhtml#page_21)，[209](appendix.xhtml#page_209)
- en: multi-GPU training paradigms, [37](ch07.xhtml#page_37)–[42](ch07.xhtml#page_42),
    [211](appendix.xhtml#page_211)
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 多 GPU 训练范式，[37](ch07.xhtml#page_37)–[42](ch07.xhtml#page_42)，[211](appendix.xhtml#page_211)
- en: reducing overfitting
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 减少过拟合
- en: with data, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27), [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据相关，[23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27)，[209](appendix.xhtml#page_209)–[210](ch05.xhtml#page_210)
- en: with model modifications, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 模型修改，[29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36)，[210](appendix.xhtml#page_210)
- en: self-supervised learning, [9](ch02.xhtml#page_9)–[14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习，[9](ch02.xhtml#page_9)–[14](ch02.xhtml#page_14)，[208](appendix.xhtml#page_208)
- en: sources of randomness, [59](ch10.xhtml#page_59)–[65](ch10.xhtml#page_65), [212](appendix.xhtml#page_212)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 随机性来源，[59](ch10.xhtml#page_59)–[65](ch10.xhtml#page_65)，[212](appendix.xhtml#page_212)
- en: transformers, success of, [43](ch08.xhtml#page_43)–[47](ch08.xhtml#page_47),
    [211](appendix.xhtml#page_211)
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 的成功，[43](ch08.xhtml#page_43)–[47](ch08.xhtml#page_47)，[211](appendix.xhtml#page_211)
- en: DeepSpeed, [37](ch07.xhtml#page_37), [42](ch07.xhtml#page_42)
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSpeed，[37](ch07.xhtml#page_37)，[42](ch07.xhtml#page_42)
- en: deletion, word, as data augmentation technique, [94](ch15.xhtml#page_94)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 删除，作为数据增强技术的单词，[94](ch15.xhtml#page_94)
- en: deterministic algorithms, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 确定性算法，[62](ch10.xhtml#page_62)，[65](ch10.xhtml#page_65)
- en: diffusion models, [55](ch09.xhtml#page_55)–[56](ch09.xhtml#page_56), [57](ch09.xhtml#page_57),
    [58](ch09.xhtml#page_58)
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散模型，[55](ch09.xhtml#page_55)–[56](ch09.xhtml#page_56)，[57](ch09.xhtml#page_57)，[58](ch09.xhtml#page_58)
- en: dimension contrastive self-supervised learning, [14](ch02.xhtml#page_14)
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 维度对比自监督学习，[14](ch02.xhtml#page_14)
- en: direct convolution, [61](ch10.xhtml#page_61)
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 直接卷积，[61](ch10.xhtml#page_61)
- en: discriminative models, [49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 判别模型，[49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
- en: discriminator in GANs, [52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 中的判别器，[52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)
- en: distance, embeddings as encoding, [5](ch01.xhtml#page_5)
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 距离，作为编码的嵌入，[5](ch01.xhtml#page_5)
- en: distance functions, [179](ch27.xhtml#page_179)–[183](ch27.xhtml#page_183)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 距离函数，[179](ch27.xhtml#page_179)–[183](ch27.xhtml#page_183)
- en: distributional hypothesis, [89](ch14.xhtml#page_89)–[92](ch14.xhtml#page_92),
    [214](appendix.xhtml#page_214)
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 分布假设，[89](ch14.xhtml#page_89)–[92](ch14.xhtml#page_92)，[214](appendix.xhtml#page_214)
- en: domain shift (joint distribution shift), [155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156),
    [157](ch23.xhtml#page_157)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 域迁移（联合分布迁移），[155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156), [157](ch23.xhtml#page_157)
- en: double descent, [32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33), [36](ch06.xhtml#page_36)
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 双重下降，[32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33), [36](ch06.xhtml#page_36)
- en: downstream model for pretrained transformers, [114](ch18.xhtml#page_114)
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练Transformer的下游模型，[114](ch18.xhtml#page_114)
- en: downstream task, [11](ch02.xhtml#page_11)
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 下游任务，[11](ch02.xhtml#page_11)
- en: drivers as source of randomness, [62](ch10.xhtml#page_62)
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动因子作为随机性源，[62](ch10.xhtml#page_62)
- en: dropout, [30](ch06.xhtml#page_30), [36](ch06.xhtml#page_36), [61](ch10.xhtml#page_61),
    [64](ch10.xhtml#page_64)–[65](ch10.xhtml#page_65), [212](appendix.xhtml#page_212)
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: dropout，[30](ch06.xhtml#page_30), [36](ch06.xhtml#page_36), [61](ch10.xhtml#page_61),
    [64](ch10.xhtml#page_64)–[65](ch10.xhtml#page_65), [212](appendix.xhtml#page_212)
- en: '**E**'
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**E**'
- en: early stopping, [30](ch06.xhtml#page_30)–[31](ch06.xhtml#page_31), [35](ch06.xhtml#page_35),
    [210](appendix.xhtml#page_210)
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 提前停止，[30](ch06.xhtml#page_30)–[31](ch06.xhtml#page_31), [35](ch06.xhtml#page_35),
    [210](appendix.xhtml#page_210)
- en: EBMs (energy-based models), [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 能源模型（EBMs），[50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)
- en: EfficientNetV2 CNN architecture, [85](ch13.xhtml#page_85)
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: EfficientNetV2 CNN架构，[85](ch13.xhtml#page_85)
- en: embeddings
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入
- en: distributional hypothesis, [90](ch14.xhtml#page_90)–[91](ch14.xhtml#page_91)
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 分布假设，[90](ch14.xhtml#page_90)–[91](ch14.xhtml#page_91)
- en: in few-shot learning, [17](ch03.xhtml#page_17)
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在少样本学习中，[17](ch03.xhtml#page_17)
- en: latent space, [5](ch01.xhtml#page_5)–[6](ch01.xhtml#page_6)
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在空间，[5](ch01.xhtml#page_5)–[6](ch01.xhtml#page_6)
- en: in original transformer architecture, [106](ch17.xhtml#page_106)
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始Transformer架构中，[106](ch17.xhtml#page_106)
- en: overview, [3](ch01.xhtml#page_3)–[5](ch01.xhtml#page_5)
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[3](ch01.xhtml#page_3)–[5](ch01.xhtml#page_5)
- en: representations, [6](ch01.xhtml#page_6)
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 表示，[6](ch01.xhtml#page_6)
- en: emergent properties, GPT models, [110](ch17.xhtml#page_110)
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: GPT模型的涌现性质，[110](ch17.xhtml#page_110)
- en: encoder-decoder models, [110](ch17.xhtml#page_110), [111](ch17.xhtml#page_111)
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器-解码器模型，[110](ch17.xhtml#page_110), [111](ch17.xhtml#page_111)
- en: encoder network (VAE model), [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器网络（VAE模型），[51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
- en: encoders
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器
- en: in Bahdanau attention mechanism, [100](ch16.xhtml#page_100)–[101](ch16.xhtml#page_101)
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在Bahdanau注意力机制中，[100](ch16.xhtml#page_100)–[101](ch16.xhtml#page_101)
- en: in original transformer architecture, [105](ch17.xhtml#page_105)–[107](ch17.xhtml#page_107)
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始Transformer架构中，[105](ch17.xhtml#page_105)–[107](ch17.xhtml#page_107)
- en: encoder-style transformers. *See also* decoder-style transformers
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器风格的Transformer。*另见*解码器风格的Transformer
- en: contemporary transformer models, [111](ch17.xhtml#page_111)–[112](ch17.xhtml#page_112)
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现代Transformer模型，[111](ch17.xhtml#page_111)–[112](ch17.xhtml#page_112)
- en: encoder-decoder hybrids, [110](ch17.xhtml#page_110)
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器-解码器混合模型，[110](ch17.xhtml#page_110)
- en: overview, [105](ch17.xhtml#page_105), [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[105](ch17.xhtml#page_105), [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
- en: terminology related to, [110](ch17.xhtml#page_110)
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 相关术语，[110](ch17.xhtml#page_110)
- en: energy-based models (EBMs), [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 能源模型（EBMs），[50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)
- en: ensemble methods, [33](ch06.xhtml#page_33)–[34](ch06.xhtml#page_34), [35](ch06.xhtml#page_35),
    [210](appendix.xhtml#page_210), [221](appendix.xhtml#page_221), [222](appendix.xhtml#page_222)
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法，[33](ch06.xhtml#page_33)–[34](ch06.xhtml#page_34), [35](ch06.xhtml#page_35),
    [210](appendix.xhtml#page_210), [221](appendix.xhtml#page_221), [222](appendix.xhtml#page_222)
- en: episodes in few-shot learning, [16](ch03.xhtml#page_16)
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习中的回合，[16](ch03.xhtml#page_16)
- en: Euclidean distance, [181](ch27.xhtml#page_181)
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离，[181](ch27.xhtml#page_181)
- en: evaluation metrics for generative LLMs
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型大语言模型的评估指标
- en: BERTScore, [132](ch19.xhtml#page_132)–[133](ch19.xhtml#page_133)
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: BERTScore, [132](ch19.xhtml#page_132)–[133](ch19.xhtml#page_133)
- en: BLEU score, [129](ch19.xhtml#page_129)–[131](ch19.xhtml#page_131)
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: BLEU分数，[129](ch19.xhtml#page_129)–[131](ch19.xhtml#page_131)
- en: overview, [127](ch19.xhtml#page_127)–[128](ch19.xhtml#page_128)
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[127](ch19.xhtml#page_127)–[128](ch19.xhtml#page_128)
- en: perplexity, [128](ch19.xhtml#page_128)–[129](ch19.xhtml#page_129)
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 困惑度，[128](ch19.xhtml#page_128)–[129](ch19.xhtml#page_129)
- en: ROUGE score, [131](ch19.xhtml#page_131)–[132](ch19.xhtml#page_132)
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ROUGE分数，[131](ch19.xhtml#page_131)–[132](ch19.xhtml#page_132)
- en: surrogate metrics, [133](ch19.xhtml#page_133)
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 替代指标，[133](ch19.xhtml#page_133)
- en: extrinsic metrics, [128](ch19.xhtml#page_128)
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 外部指标，[128](ch19.xhtml#page_128)
- en: '**F**'
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**F**'
- en: fast Fourier transform (FFT)-based convolution, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 基于快速傅里叶变换（FFT）的卷积, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
- en: FC layers. *See* fully connected layers
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: FC层。*见*全连接层
- en: feature selection, self-attention as form of, [46](ch08.xhtml#page_46), [211](appendix.xhtml#page_211)
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择，作为自注意力的一种形式，[46](ch08.xhtml#page_46)，[211](appendix.xhtml#page_211)
- en: few-shot learning. *See also* in-context learning
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习。*另见*上下文学习
- en: datasets and terminology, [15](ch03.xhtml#page_15)–[17](ch03.xhtml#page_17)
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集和术语，[15](ch03.xhtml#page_15)–[17](ch03.xhtml#page_17)
- en: limited labeled data, [195](ch30.xhtml#page_195)–[196](ch30.xhtml#page_196),
    [203](ch30.xhtml#page_203)
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 有限标签数据，[195](ch30.xhtml#page_195)–[196](ch30.xhtml#page_196)，[203](ch30.xhtml#page_203)
- en: overview, [15](ch03.xhtml#page_15)
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[15](ch03.xhtml#page_15)
- en: reducing overfitting with, [25](ch05.xhtml#page_25)
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 用于减少过拟合，[25](ch05.xhtml#page_25)
- en: FFT (fast Fourier transform)-based convolution, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 基于FFT（快速傅里叶变换）的卷积，[62](ch10.xhtml#page_62)，[65](ch10.xhtml#page_65)
- en: fine-tuning pretrained transformers, [113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116),
    [119](ch18.xhtml#page_119)–[124](ch18.xhtml#page_124), [125](ch18.xhtml#page_125)–[126](ch18.xhtml#page_126),
    [216](appendix.xhtml#page_216)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 微调预训练的变换器，[113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116)，[119](ch18.xhtml#page_119)–[124](ch18.xhtml#page_124)，[125](ch18.xhtml#page_125)–[126](ch18.xhtml#page_126)，[216](appendix.xhtml#page_216)
- en: finite-sample guarantees of conformal predictions, [177](ch26.xhtml#page_177)
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 有限样本下的保型预测保证，[177](ch26.xhtml#page_177)
- en: 5-fold cross-validation, [187](ch28.xhtml#page_187), [188](ch28.xhtml#page_188),
    [221](appendix.xhtml#page_221)
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 5折交叉验证，[187](ch28.xhtml#page_187)，[188](ch28.xhtml#page_188)，[221](appendix.xhtml#page_221)
- en: flow-based models (normalizing flows), [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54),
    [57](ch09.xhtml#page_57)
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 基于流的模型（标准化流），[53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54)，[57](ch09.xhtml#page_57)
- en: Fréchet inception distance approach, [212](appendix.xhtml#page_212)
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: Fréchet Inception Distance方法，[212](appendix.xhtml#page_212)
- en: fully connected (FC) layers
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 完全连接（FC）层
- en: calculating number of parameters in, [70](ch11.xhtml#page_70), [72](ch11.xhtml#page_72)
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 计算参数数量，[70](ch11.xhtml#page_70)，[72](ch11.xhtml#page_72)
- en: lack of spatial invariance or equivariance, [82](ch13.xhtml#page_82)
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 空间不变性或等变性的缺乏，[82](ch13.xhtml#page_82)
- en: recommendations for, [78](ch12.xhtml#page_78)
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐，[78](ch12.xhtml#page_78)
- en: replacing with convolutional layers, [75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 用卷积层替代，[75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)
- en: using to create embeddings, [6](ch01.xhtml#page_6), [207](appendix.xhtml#page_207)
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建嵌入，[6](ch01.xhtml#page_6)，[207](appendix.xhtml#page_207)
- en: '**G**'
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**G**'
- en: generalization accuracy, [164](ch25.xhtml#page_164)
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 泛化准确性，[164](ch25.xhtml#page_164)
- en: generalization performance, [32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 泛化性能，[32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33)
- en: generative adversarial networks (GANs), [52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53),
    [54](ch09.xhtml#page_54), [57](ch09.xhtml#page_57), [58](ch09.xhtml#page_58)
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs），[52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)，[54](ch09.xhtml#page_54)，[57](ch09.xhtml#page_57)，[58](ch09.xhtml#page_58)
- en: generative AI models
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性AI模型
- en: autoregressive models, [54](ch09.xhtml#page_54)–[55](ch09.xhtml#page_55)
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归模型，[54](ch09.xhtml#page_54)–[55](ch09.xhtml#page_55)
- en: consistency models, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性模型，[56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
- en: diffusion models, [55](ch09.xhtml#page_55)–[56](ch09.xhtml#page_56)
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散模型，[55](ch09.xhtml#page_55)–[56](ch09.xhtml#page_56)
- en: energy-based models, [50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 基于能量的模型，[50](ch09.xhtml#page_50)–[51](ch09.xhtml#page_51)
- en: flow-based models, [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54)
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 基于流的模型，[53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54)
- en: generative adversarial networks, [52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络，[52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)
- en: generative vs. discriminative modeling, [49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型与判别模型，[49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
- en: overview, [49](ch09.xhtml#page_49)
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[49](ch09.xhtml#page_49)
- en: randomness and, [62](ch10.xhtml#page_62)–[64](ch10.xhtml#page_64)
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 随机性与，[62](ch10.xhtml#page_62)–[64](ch10.xhtml#page_64)
- en: recommendations for, [57](ch09.xhtml#page_57)
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐，[57](ch09.xhtml#page_57)
- en: variational autoencoders, [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 变分自编码器，[51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52)
- en: generative large language models. *See* evaluation metrics for generative LLMs;
    large language models; natural language processing
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性大型语言模型。*另见*生成性LLMs的评估指标；大型语言模型；自然语言处理
- en: generator in GANs, [52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: GAN中的生成器，[52](ch09.xhtml#page_52)–[53](ch09.xhtml#page_53)
- en: Gibbs sampling, [51](ch09.xhtml#page_51)
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: Gibbs采样，[51](ch09.xhtml#page_51)
- en: GPT (generative pretrained transformer) models
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: GPT（生成预训练变换器）模型
- en: decoder-style transformers, [91](ch14.xhtml#page_91), [109](ch17.xhtml#page_109)–[110](ch17.xhtml#page_110)
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器风格的变换器，[91](ch14.xhtml#page_91)，[109](ch17.xhtml#page_109)–[110](ch17.xhtml#page_110)
- en: fine-tuning for classification, [112](ch17.xhtml#page_112), [216](appendix.xhtml#page_216)
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 分类的微调，[112](ch17.xhtml#page_112)，[216](appendix.xhtml#page_216)
- en: randomness by design, [63](ch10.xhtml#page_63)
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 设计上的随机性，[63](ch10.xhtml#page_63)
- en: self-prediction, [12](ch02.xhtml#page_12)
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 自我预测，[12](ch02.xhtml#page_12)
- en: GPUs. *See* multi-GPU training paradigms
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: GPU。*参见* 多GPU训练范式
- en: grokking, [32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33), [36](ch06.xhtml#page_36)
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 理解，[32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33)，[36](ch06.xhtml#page_36)
- en: '**H**'
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**H**'
- en: hard attention, [211](appendix.xhtml#page_211)
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 硬注意力，[211](appendix.xhtml#page_211)
- en: hard parameter sharing, [200](ch30.xhtml#page_200)
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 硬参数共享，[200](ch30.xhtml#page_200)
- en: hard prompt tuning, [117](ch18.xhtml#page_117)–[118](ch18.xhtml#page_118)
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 硬提示调优，[117](ch18.xhtml#page_117)–[118](ch18.xhtml#page_118)
- en: hardware as source of randomness, [62](ch10.xhtml#page_62)
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件作为随机性来源，[62](ch10.xhtml#page_62)
- en: hierarchical processing in CNNs, [80](ch13.xhtml#page_80)
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络中的层次处理，[80](ch13.xhtml#page_80)
- en: histograms, [207](appendix.xhtml#page_207)
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图，[207](appendix.xhtml#page_207)
- en: holdout validation as source of randomness, [60](ch10.xhtml#page_60)
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 留出验证作为随机性来源，[60](ch10.xhtml#page_60)
- en: homophones, [92](ch14.xhtml#page_92), [214](appendix.xhtml#page_214)
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 同音词，[92](ch14.xhtml#page_92)，[214](appendix.xhtml#page_214)
- en: human feedback, reinforcement learning with, [124](ch18.xhtml#page_124)
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 人类反馈，强化学习中的，[124](ch18.xhtml#page_124)
- en: hyperparameter tuning, [188](ch28.xhtml#page_188)
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优，[188](ch28.xhtml#page_188)
- en: '**I**'
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**I**'
- en: image denoising, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 图像去噪，[56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
- en: image generation, [51](ch09.xhtml#page_51), [52](ch09.xhtml#page_52), [54](ch09.xhtml#page_54)–[57](ch09.xhtml#page_57),
    [211](appendix.xhtml#page_211)–[212](appendix.xhtml#page_212)
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 图像生成，[51](ch09.xhtml#page_51)，[52](ch09.xhtml#page_52)，[54](ch09.xhtml#page_54)–[57](ch09.xhtml#page_57)，[211](appendix.xhtml#page_211)–[212](appendix.xhtml#page_212)
- en: image histograms, [207](appendix.xhtml#page_207)
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图像直方图，[207](appendix.xhtml#page_207)
- en: “An Image Is Worth 16×16 Words” (Dosovitskiy et al.), [83](ch13.xhtml#page_83),
    [85](ch13.xhtml#page_85)
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: “一张图像等于16×16个词”（Dosovitskiy等），[83](ch13.xhtml#page_83)，[85](ch13.xhtml#page_85)
- en: ImageNet dataset, [9](ch02.xhtml#page_9), [14](ch02.xhtml#page_14), [175](ch26.xhtml#page_175)
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet 数据集，[9](ch02.xhtml#page_9)，[14](ch02.xhtml#page_14)，[175](ch26.xhtml#page_175)
- en: image processing. *See* computer vision
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图像处理。*参见* 计算机视觉
- en: importance weighting, [154](ch23.xhtml#page_154), [155](ch23.xhtml#page_155),
    [157](ch23.xhtml#page_157), [218](appendix.xhtml#page_218)
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 重要性加权，[154](ch23.xhtml#page_154)，[155](ch23.xhtml#page_155)，[157](ch23.xhtml#page_157)，[218](appendix.xhtml#page_218)
- en: in-context learning, [113](ch18.xhtml#page_113), [116](ch18.xhtml#page_116)–[119](ch18.xhtml#page_119),
    [125](ch18.xhtml#page_125), [216](appendix.xhtml#page_216). *See also* few-shot
    learning
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 语境学习，[113](ch18.xhtml#page_113)，[116](ch18.xhtml#page_116)–[119](ch18.xhtml#page_119)，[125](ch18.xhtml#page_125)，[216](appendix.xhtml#page_216)。*另见*
    小样本学习
- en: indexing, [118](ch18.xhtml#page_118)–[119](ch18.xhtml#page_119), [125](ch18.xhtml#page_125)
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 索引，[118](ch18.xhtml#page_118)–[119](ch18.xhtml#page_119)，[125](ch18.xhtml#page_125)
- en: inductive biases
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 归纳偏差
- en: in convolutional neural networks, [80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络中的，[80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
- en: limited labeled data, [202](ch30.xhtml#page_202)
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 有限的标注数据，[202](ch30.xhtml#page_202)
- en: overview, [79](ch13.xhtml#page_79)
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[79](ch13.xhtml#page_79)
- en: in vision transformers, [83](ch13.xhtml#page_83)–[84](ch13.xhtml#page_84)
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉转换器中的，[83](ch13.xhtml#page_83)–[84](ch13.xhtml#page_84)
- en: inference, speeding up. *See* model inference, speeding up
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 推理，加速。*参见* 模型推理，加速
- en: inpainting, [194](ch30.xhtml#page_194)–[195](ch30.xhtml#page_195), [208](appendix.xhtml#page_208)
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 图像修复，[194](ch30.xhtml#page_194)–[195](ch30.xhtml#page_195)，[208](appendix.xhtml#page_208)
- en: input channels in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71),
    [76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层中的输入通道，[70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)，[76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
- en: input embedding, [4](ch01.xhtml#page_4)
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 输入嵌入，[4](ch01.xhtml#page_4)
- en: input representations, [6](ch01.xhtml#page_6), [207](appendix.xhtml#page_207)
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 输入表示，[6](ch01.xhtml#page_6)，[207](appendix.xhtml#page_207)
- en: InstructGPT model, [124](ch18.xhtml#page_124), [126](ch18.xhtml#page_126), [133](ch19.xhtml#page_133),
    [135](ch19.xhtml#page_135)
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: InstructGPT 模型，[124](ch18.xhtml#page_124)，[126](ch18.xhtml#page_126)，[133](ch19.xhtml#page_133)，[135](ch19.xhtml#page_135)
- en: inter-op parallelism (model parallelism), [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38),
    [39](ch07.xhtml#page_39)–[40](ch07.xhtml#page_40), [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 操作间并行（模型并行），[37](ch07.xhtml#page_37)，[38](ch07.xhtml#page_38)，[39](ch07.xhtml#page_39)–[40](ch07.xhtml#page_40)，[41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)
- en: intra-op parallelism (tensor parallelism), [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38)–[40](ch07.xhtml#page_40),
    [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42), [211](appendix.xhtml#page_211)
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 操作间并行（张量并行），[37](ch07.xhtml#page_37)，[38](ch07.xhtml#page_38)–[40](ch07.xhtml#page_40)，[41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)，[211](appendix.xhtml#page_211)
- en: intrinsic metrics, [128](ch19.xhtml#page_128)
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 内在指标，[128](ch19.xhtml#page_128)
- en: iterative pruning, [20](ch04.xhtml#page_20), [31](ch06.xhtml#page_31)
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代剪枝，[20](ch04.xhtml#page_20)，[31](ch06.xhtml#page_31)
- en: '**J**'
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**J**'
- en: joint distribution shift (domain shift), [155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156),
    [157](ch23.xhtml#page_157)
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 联合分布漂移（领域漂移），[155](ch23.xhtml#page_155)–[156](ch23.xhtml#page_156)，[157](ch23.xhtml#page_157)
- en: '**K**'
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**K**'
- en: kernel size in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71),
    [76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层中的卷积核大小，[70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)，[76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
- en: '*k*-fold cross-validation'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*-折交叉验证'
- en: determining appropriate values for *k*, [187](ch28.xhtml#page_187)–[188](ch28.xhtml#page_188)
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 确定 *k* 的适当值，[187](ch28.xhtml#page_187)–[188](ch28.xhtml#page_188)
- en: ensemble approach, [33](ch06.xhtml#page_33)–[34](ch06.xhtml#page_34)
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法，[33](ch06.xhtml#page_33)–[34](ch06.xhtml#page_34)
- en: overview, [185](ch28.xhtml#page_185)–[186](ch28.xhtml#page_186)
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[185](ch28.xhtml#page_185)–[186](ch28.xhtml#page_186)
- en: as source of randomness, [60](ch10.xhtml#page_60)
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 作为随机源，[60](ch10.xhtml#page_60)
- en: trade-offs in selecting values for *k*, [186](ch28.xhtml#page_186)–[187](ch28.xhtml#page_187)
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择 *k* 值时的权衡，[186](ch28.xhtml#page_186)–[187](ch28.xhtml#page_187)
- en: knowledge distillation, [31](ch06.xhtml#page_31)–[33](ch06.xhtml#page_33), [35](ch06.xhtml#page_35),
    [36](ch06.xhtml#page_36), [151](ch22.xhtml#page_151), [199](ch30.xhtml#page_199)
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 知识蒸馏，[31](ch06.xhtml#page_31)–[33](ch06.xhtml#page_33)，[35](ch06.xhtml#page_35)，[36](ch06.xhtml#page_36)，[151](ch22.xhtml#page_151)，[199](ch30.xhtml#page_199)
- en: Kullback–Leibler divergence (KL divergence), [32](ch06.xhtml#page_32), [52](ch09.xhtml#page_52),
    [211](appendix.xhtml#page_211)
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 库尔巴克-莱布勒散度（KL散度），[32](ch06.xhtml#page_32)，[52](ch09.xhtml#page_52)，[211](appendix.xhtml#page_211)
- en: '**L**'
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**L**'
- en: '*L*2 distance, [181](ch27.xhtml#page_181)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '*L*2 距离，[181](ch27.xhtml#page_181)'
- en: '*L*2 regularization, [30](ch06.xhtml#page_30), [35](ch06.xhtml#page_35)'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '*L*2 正则化，[30](ch06.xhtml#page_30)，[35](ch06.xhtml#page_35)'
- en: labeled data, limited. *See* limited labeled data
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 有限标签数据。*见* 有限标签数据
- en: label shift (prior probability shift), [154](ch23.xhtml#page_154)–[155](ch23.xhtml#page_155),
    [156](ch23.xhtml#page_156)
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 标签偏移（先验概率偏移），[154](ch23.xhtml#page_154)–[155](ch23.xhtml#page_155)，[156](ch23.xhtml#page_156)
- en: label smoothing, [27](ch05.xhtml#page_27)
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 标签平滑，[27](ch05.xhtml#page_27)
- en: language transformers. *See* transformers
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 语言变换器。*见* 变换器
- en: large language models (LLMs). *See also* natural language processing; transformers
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）。*另见* 自然语言处理；变换器
- en: distributional hypothesis, [91](ch14.xhtml#page_91)
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 分布假设，[91](ch14.xhtml#page_91)
- en: evaluation metrics for, [127](ch19.xhtml#page_127)–[135](ch19.xhtml#page_135),
    [216](appendix.xhtml#page_216)–[217](appendix.xhtml#page_217)
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标，[127](ch19.xhtml#page_127)–[135](ch19.xhtml#page_135)，[216](appendix.xhtml#page_216)–[217](appendix.xhtml#page_217)
- en: stateless vs. stateful training, [141](ch20.xhtml#page_141), [217](appendix.xhtml#page_217)
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 无状态训练与有状态训练，[141](ch20.xhtml#page_141)，[217](appendix.xhtml#page_217)
- en: synthetic data generation, [96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据生成，[96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
- en: latent space, [3](ch01.xhtml#page_3), [5](ch01.xhtml#page_5)–[7](ch01.xhtml#page_7)
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 潜空间，[3](ch01.xhtml#page_3)，[5](ch01.xhtml#page_5)–[7](ch01.xhtml#page_7)
- en: layer input normalization techniques, [34](ch06.xhtml#page_34)–[35](ch06.xhtml#page_35)
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 层输入归一化技术，[34](ch06.xhtml#page_34)–[35](ch06.xhtml#page_35)
- en: layers
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 层
- en: convolutional layers
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层
- en: calculating number of parameters in, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 计算……中的参数数量，[70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)
- en: as high-pass and low-pass filters, [84](ch13.xhtml#page_84)
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 作为高通和低通滤波器，[84](ch13.xhtml#page_84)
- en: recommendations for, [78](ch12.xhtml#page_78)
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 针对……的建议，[78](ch12.xhtml#page_78)
- en: replacing fully connected layers with, [75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 用……替换全连接层，[75](ch12.xhtml#page_75)–[78](ch12.xhtml#page_78)
- en: normalization in original transformer architecture, [106](ch17.xhtml#page_106)–[107](ch17.xhtml#page_107)
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 原始变换器架构中的归一化，[106](ch17.xhtml#page_106)–[107](ch17.xhtml#page_107)
- en: updating when fine-tuning pretrained transformers, [115](ch18.xhtml#page_115)–[116](ch18.xhtml#page_116)
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 微调预训练变换器时的更新，[115](ch18.xhtml#page_115)–[116](ch18.xhtml#page_116)
- en: using to create embeddings, [207](appendix.xhtml#page_207)
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建嵌入，[207](appendix.xhtml#page_207)
- en: leave-one-out cross-validation (LOOCV), [188](ch28.xhtml#page_188), [221](appendix.xhtml#page_221)
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 留一法交叉验证（LOOCV），[188](ch28.xhtml#page_188)，[221](appendix.xhtml#page_221)
- en: limited labeled data
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 有限标签数据
- en: active learning, [195](ch30.xhtml#page_195)
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习，[195](ch30.xhtml#page_195)
- en: bootstrapping data, [194](ch30.xhtml#page_194)
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 自举数据，[194](ch30.xhtml#page_194)
- en: few-shot learning, [195](ch30.xhtml#page_195)–[196](ch30.xhtml#page_196)
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习，[195](ch30.xhtml#page_195)–[196](ch30.xhtml#page_196)
- en: inductive biases, [202](ch30.xhtml#page_202)
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 归纳偏差，[202](ch30.xhtml#page_202)
- en: labeling more data, [193](ch30.xhtml#page_193)–[194](ch30.xhtml#page_194)
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 标注更多数据，[193](ch30.xhtml#page_193)–[194](ch30.xhtml#page_194)
- en: meta-learning, [196](ch30.xhtml#page_196)–[197](ch30.xhtml#page_197)
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习，[196](ch30.xhtml#page_196)–[197](ch30.xhtml#page_197)
- en: multimodal learning, [200](ch30.xhtml#page_200)–[202](ch30.xhtml#page_202)
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态学习，[200](ch30.xhtml#page_200)–[202](ch30.xhtml#page_202)
- en: multi-task learning, [199](ch30.xhtml#page_199)–[200](ch30.xhtml#page_200)
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务学习，[199](ch30.xhtml#page_199)–[200](ch30.xhtml#page_200)
- en: overview, [193](ch30.xhtml#page_193)
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[193](ch30.xhtml#page_193)
- en: recommendations for choosing technique, [202](ch30.xhtml#page_202)–[203](ch30.xhtml#page_203)
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 选择技术的建议，[202](ch30.xhtml#page_202)–[203](ch30.xhtml#page_203)
- en: self-supervised learning, [194](ch30.xhtml#page_194)–[195](ch30.xhtml#page_195)
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习，[194](ch30.xhtml#page_194)–[195](ch30.xhtml#page_195)
- en: self-training, [199](ch30.xhtml#page_199)
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 自我训练，[199](ch30.xhtml#page_199)
- en: semi-supervised learning, [198](ch30.xhtml#page_198)–[199](ch30.xhtml#page_199)
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习，[198](ch30.xhtml#page_198)–[199](ch30.xhtml#page_199)
- en: transfer learning, [194](ch30.xhtml#page_194)
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习，[194](ch30.xhtml#page_194)
- en: weakly supervised learning, [197](ch30.xhtml#page_197)–[198](ch30.xhtml#page_198)
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 弱监督学习，[197](ch30.xhtml#page_197)–[198](ch30.xhtml#page_198)
- en: linear classifiers, [114](ch18.xhtml#page_114)
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 线性分类器，[114](ch18.xhtml#page_114)
- en: LLMs. *See* large language models; natural language processing; transformers
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）。*见* 大型语言模型；自然语言处理；变换器
- en: local connectivity in CNNs, [80](ch13.xhtml#page_80), [81](ch13.xhtml#page_81)
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNNs）中的局部连接，[80](ch13.xhtml#page_80)，[81](ch13.xhtml#page_81)
- en: logistic regression classifier, [49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归分类器，[49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
- en: LOOCV (leave-one-out cross-validation), [188](ch28.xhtml#page_188), [221](appendix.xhtml#page_221)
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: LOOCV（留一交叉验证），[188](ch28.xhtml#page_188)，[221](appendix.xhtml#page_221)
- en: loop fusion (operator fusion), [150](ch22.xhtml#page_150)–[151](ch22.xhtml#page_151)
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 循环融合（运算符融合），[150](ch22.xhtml#page_150)–[151](ch22.xhtml#page_151)
- en: loop tiling (loop nest optimization), [149](ch22.xhtml#page_149)–[150](ch22.xhtml#page_150),
    [151](ch22.xhtml#page_151), [152](ch22.xhtml#page_152), [218](appendix.xhtml#page_218)
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 循环瓦片化（循环嵌套优化），[149](ch22.xhtml#page_149)–[150](ch22.xhtml#page_150)，[151](ch22.xhtml#page_151)，[152](ch22.xhtml#page_152)，[218](appendix.xhtml#page_218)
- en: LoRA (low-rank adaptation), [119](ch18.xhtml#page_119), [123](ch18.xhtml#page_123)–[124](ch18.xhtml#page_124),
    [125](ch18.xhtml#page_125), [126](ch18.xhtml#page_126), [216](appendix.xhtml#page_216)
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: LoRA（低秩适配），[119](ch18.xhtml#page_119)，[123](ch18.xhtml#page_123)–[124](ch18.xhtml#page_124)，[125](ch18.xhtml#page_125)，[126](ch18.xhtml#page_126)，[216](appendix.xhtml#page_216)
- en: loss function, VAEs, [52](ch09.xhtml#page_52)
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数，变分自编码器（VAEs），[52](ch09.xhtml#page_52)
- en: lottery ticket hypothesis
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 彩票假设
- en: overview, [19](ch04.xhtml#page_19)
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[19](ch04.xhtml#page_19)
- en: practical implications and limitations, [20](ch04.xhtml#page_20)–[21](ch04.xhtml#page_21)
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 实践意义和局限性，[20](ch04.xhtml#page_20)–[21](ch04.xhtml#page_21)
- en: training procedure for, [19](ch04.xhtml#page_19)–[20](ch04.xhtml#page_20)
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程，[19](ch04.xhtml#page_19)–[20](ch04.xhtml#page_20)
- en: low-rank adaptation (LoRA), [119](ch18.xhtml#page_119), [123](ch18.xhtml#page_123)–[124](ch18.xhtml#page_124),
    [125](ch18.xhtml#page_125), [126](ch18.xhtml#page_126), [216](appendix.xhtml#page_216)
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩适配（LoRA），[119](ch18.xhtml#page_119)，[123](ch18.xhtml#page_123)–[124](ch18.xhtml#page_124)，[125](ch18.xhtml#page_125)，[126](ch18.xhtml#page_126)，[216](appendix.xhtml#page_216)
- en: low-rank transformation, [123](ch18.xhtml#page_123)
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩变换，[123](ch18.xhtml#page_123)
- en: '**M**'
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**M**'
- en: MAE (mean absolute error), [183](ch27.xhtml#page_183), [220](appendix.xhtml#page_220)–[221](appendix.xhtml#page_221)
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: MAE（平均绝对误差），[183](ch27.xhtml#page_183)，[220](appendix.xhtml#page_220)–[221](ch27.xhtml#page_221)
- en: majority voting, [33](ch06.xhtml#page_33)
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 多数投票，[33](ch06.xhtml#page_33)
- en: MAPIE library, [178](ch26.xhtml#page_178)
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: MAPIE库，[178](ch26.xhtml#page_178)
- en: masked (missing) input self-prediction methods, [12](ch02.xhtml#page_12)
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码（缺失）输入自预测方法，[12](ch02.xhtml#page_12)
- en: masked frames, predicting, [208](appendix.xhtml#page_208)
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码帧，预测，[208](appendix.xhtml#page_208)
- en: masked language modeling, [91](ch14.xhtml#page_91), [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108),
    [194](ch30.xhtml#page_194)
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码语言建模，[91](ch14.xhtml#page_91)，[107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)，[194](ch30.xhtml#page_194)
- en: mean absolute error (MAE), [183](ch27.xhtml#page_183), [220](appendix.xhtml#page_220)–[221](appendix.xhtml#page_221)
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 平均绝对误差（MAE），[183](ch27.xhtml#page_183)，[220](appendix.xhtml#page_220)–[221](ch27.xhtml#page_221)
- en: mean squared error (MSE) loss, [180](ch27.xhtml#page_180)–[181](ch27.xhtml#page_181)
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 均方误差（MSE）损失，[180](ch27.xhtml#page_180)–[181](ch27.xhtml#page_181)
- en: memory complexity of self-attention, [103](ch16.xhtml#page_103), [215](appendix.xhtml#page_215)
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力的内存复杂度，[103](ch16.xhtml#page_103), [215](appendix.xhtml#page_215)
- en: metadata (meta-features) extraction, [197](ch30.xhtml#page_197)
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据（元特征）提取，[197](ch30.xhtml#page_197)
- en: meta-learning, [17](ch03.xhtml#page_17), [196](ch30.xhtml#page_196)–[197](ch30.xhtml#page_197)
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 元学习，[17](ch03.xhtml#page_17), [196](ch30.xhtml#page_196)–[197](ch30.xhtml#page_197)
- en: METEOR metric, [131](ch19.xhtml#page_131), [134](ch19.xhtml#page_134)
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: METEOR指标, [131](ch19.xhtml#page_131), [134](ch19.xhtml#page_134)
- en: metrics, proper. *See* proper metrics
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 指标，正确的。*见* 正确的指标
- en: missing (masked) input self-prediction methods, [12](ch02.xhtml#page_12)
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失（遮蔽）输入自预测方法，[12](ch02.xhtml#page_12)
- en: missing frames, predicting, [208](appendix.xhtml#page_208)
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 预测缺失帧，[208](appendix.xhtml#page_208)
- en: Mixup, [27](ch05.xhtml#page_27)
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: Mixup，[27](ch05.xhtml#page_27)
- en: MLPs (multilayer perceptrons), [50](ch09.xhtml#page_50), [82](ch13.xhtml#page_82)
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知器（MLPs），[50](ch09.xhtml#page_50), [82](ch13.xhtml#page_82)
- en: MNIST dataset, [15](ch03.xhtml#page_15), [18](ch03.xhtml#page_18), [26](ch05.xhtml#page_26),
    [208](appendix.xhtml#page_208), [210](appendix.xhtml#page_210)
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST数据集，[15](ch03.xhtml#page_15), [18](ch03.xhtml#page_18), [26](ch05.xhtml#page_26),
    [208](appendix.xhtml#page_208), [210](appendix.xhtml#page_210)
- en: model-centric AI, [143](ch21.xhtml#page_143)–[144](ch21.xhtml#page_144), [145](ch21.xhtml#page_145)
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 以模型为中心的人工智能，[143](ch21.xhtml#page_143)–[144](ch21.xhtml#page_144), [145](ch21.xhtml#page_145)
- en: model ensembling, [33](ch06.xhtml#page_33)–[34](ch06.xhtml#page_34), [35](ch06.xhtml#page_35),
    [210](appendix.xhtml#page_210), [221](appendix.xhtml#page_221), [222](appendix.xhtml#page_222)
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 模型集成，[33](ch06.xhtml#page_33)–[34](ch06.xhtml#page_34), [35](ch06.xhtml#page_35),
    [210](appendix.xhtml#page_210), [221](appendix.xhtml#page_221), [222](appendix.xhtml#page_222)
- en: model evaluation. *See* predictive performance and model evaluation
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估。*见* 预测性能和模型评估
- en: model inference, speeding up
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 模型推理，加速
- en: loop tiling, [149](ch22.xhtml#page_149)–[150](ch22.xhtml#page_150)
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 循环切分，[149](ch22.xhtml#page_149)–[150](ch22.xhtml#page_150)
- en: operator fusion, [150](ch22.xhtml#page_150)–[151](ch22.xhtml#page_151)
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 操作符融合，[150](ch22.xhtml#page_150)–[151](ch22.xhtml#page_151)
- en: overview, [147](ch22.xhtml#page_147)
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 概览，[147](ch22.xhtml#page_147)
- en: parallelization, [147](ch22.xhtml#page_147)–[148](ch22.xhtml#page_148)
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化，[147](ch22.xhtml#page_147)–[148](ch22.xhtml#page_148)
- en: quantization, [151](ch22.xhtml#page_151)
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 量化，[151](ch22.xhtml#page_151)
- en: vectorization, [148](ch22.xhtml#page_148)–[149](ch22.xhtml#page_149)
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 向量化，[148](ch22.xhtml#page_148)–[149](ch22.xhtml#page_149)
- en: model modifications, reducing overfitting with, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 模型修改，通过减少过拟合，[29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36), [210](appendix.xhtml#page_210)
- en: model parallelism (inter-op parallelism), [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38),
    [39](ch07.xhtml#page_39)–[40](ch07.xhtml#page_40), [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 模型并行（操作符间并行），[37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38), [39](ch07.xhtml#page_39)–[40](ch07.xhtml#page_40),
    [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)
- en: model weight initialization as source of randomness, [59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 模型权重初始化作为随机性来源，[59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
- en: MSE (mean squared error) loss, [180](ch27.xhtml#page_180)–[181](ch27.xhtml#page_181)
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: MSE（均方误差）损失，[180](ch27.xhtml#page_180)–[181](ch27.xhtml#page_181)
- en: multi-GPU training paradigms
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 多GPU训练范式
- en: data parallelism, [38](ch07.xhtml#page_38)
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行，[38](ch07.xhtml#page_38)
- en: model parallelism, [38](ch07.xhtml#page_38) overview, [37](ch07.xhtml#page_37)
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 模型并行，[38](ch07.xhtml#page_38) 概览，[37](ch07.xhtml#page_37)
- en: pipeline parallelism, [40](ch07.xhtml#page_40)
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 管道并行，[40](ch07.xhtml#page_40)
- en: recommendations for, [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 建议，[41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42)
- en: sequence parallelism, [40](ch07.xhtml#page_40)–[41](ch07.xhtml#page_41)
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 序列并行，[40](ch07.xhtml#page_40)–[41](ch07.xhtml#page_41)
- en: speeding up inference, [152](ch22.xhtml#page_152), [218](appendix.xhtml#page_218)
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 加速推理，[152](ch22.xhtml#page_152), [218](appendix.xhtml#page_218)
- en: tensor parallelism, [38](ch07.xhtml#page_38)–[40](ch07.xhtml#page_40)
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 张量并行，[38](ch07.xhtml#page_38)–[40](ch07.xhtml#page_40)
- en: multilayer perceptrons (MLPs), [50](ch09.xhtml#page_50), [82](ch13.xhtml#page_82)
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知器（MLPs），[50](ch09.xhtml#page_50), [82](ch13.xhtml#page_82)
- en: multimodal learning, [200](ch30.xhtml#page_200)–[202](ch30.xhtml#page_202),
    [204](ch30.xhtml#page_204)
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态学习，[200](ch30.xhtml#page_200)–[202](ch30.xhtml#page_202), [204](ch30.xhtml#page_204)
- en: multi-task learning, [199](ch30.xhtml#page_199)–[200](ch30.xhtml#page_200),
    [204](ch30.xhtml#page_204)
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务学习，[199](ch30.xhtml#page_199)–[200](ch30.xhtml#page_200), [204](ch30.xhtml#page_204)
- en: '**N**'
  id: totrans-429
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**N**'
- en: naive Bayes classifier, [49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯分类器，[49](ch09.xhtml#page_49)–[50](ch09.xhtml#page_50)
- en: natural language processing (NLP). *See also* transformers
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）。*另见* 转换器
- en: data augmentation for text, [93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97),
    [214](appendix.xhtml#page_214)–[215](appendix.xhtml#page_215)
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 文本的数据增强，[93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97)，[214](appendix.xhtml#page_214)–[215](ch15.xhtml#page_215)
- en: distributional hypothesis, [89](ch14.xhtml#page_89)–[92](ch14.xhtml#page_92),
    [214](appendix.xhtml#page_214)
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 分布假设，[89](ch14.xhtml#page_89)–[92](ch14.xhtml#page_92)，[214](appendix.xhtml#page_214)
- en: evaluating generative LLMs, [127](ch19.xhtml#page_127)–[135](ch19.xhtml#page_135),
    [211](appendix.xhtml#page_211)–[212](appendix.xhtml#page_212)
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 评估生成型LLM，[127](ch19.xhtml#page_127)–[135](ch19.xhtml#page_135)，[211](appendix.xhtml#page_211)–[212](appendix.xhtml#page_212)
- en: self-attention, [99](ch16.xhtml#page_99)–[103](ch16.xhtml#page_103), [215](appendix.xhtml#page_215)
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力，[99](ch16.xhtml#page_99)–[103](ch16.xhtml#page_103)，[215](appendix.xhtml#page_215)
- en: neural networks. *See also* convolutional neural networks; generative AI models;
    transformers
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络。*另见* 卷积神经网络；生成型AI模型；转换器
- en: attention mechanism for, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101)
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 注意机制，[99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101)
- en: calculating number of parameters in, [69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 计算参数数量，[69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73)，[212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
- en: embeddings, [3](ch01.xhtml#page_3)–[7](ch01.xhtml#page_7), [207](appendix.xhtml#page_207)
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入，[3](ch01.xhtml#page_3)–[7](ch01.xhtml#page_7)，[207](appendix.xhtml#page_207)
- en: few-shot learning, [15](ch03.xhtml#page_15)–[18](ch03.xhtml#page_18), [208](appendix.xhtml#page_208)–[209](appendix.xhtml#page_209)
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 少样本学习，[15](ch03.xhtml#page_15)–[18](ch03.xhtml#page_18)，[208](appendix.xhtml#page_208)–[209](appendix.xhtml#page_209)
- en: lottery ticket hypothesis, [19](ch04.xhtml#page_19)–[21](ch04.xhtml#page_21),
    [209](appendix.xhtml#page_209)
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 彩票假设，[19](ch04.xhtml#page_19)–[21](ch04.xhtml#page_21)，[209](appendix.xhtml#page_209)
- en: multi-GPU training paradigms, [37](ch07.xhtml#page_37)–[42](ch07.xhtml#page_42),
    [211](appendix.xhtml#page_211)
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 多GPU训练范式，[37](ch07.xhtml#page_37)–[42](ch07.xhtml#page_42)，[211](appendix.xhtml#page_211)
- en: reducing overfitting
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 减少过拟合
- en: with data, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27), [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据，[23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27)，[209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
- en: with model modifications, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 模型修改，[29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36)，[210](appendix.xhtml#page_210)
- en: self-attention, [99](ch16.xhtml#page_99)–[103](ch16.xhtml#page_103)
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力，[99](ch16.xhtml#page_99)–[103](ch16.xhtml#page_103)
- en: self-supervised learning, [9](ch02.xhtml#page_9)–[14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习，[9](ch02.xhtml#page_9)–[14](ch02.xhtml#page_14)，[208](appendix.xhtml#page_208)
- en: sources of randomness, [59](ch10.xhtml#page_59)–[65](ch10.xhtml#page_65), [212](appendix.xhtml#page_212)
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 随机性来源，[59](ch10.xhtml#page_59)–[65](ch10.xhtml#page_65)，[212](appendix.xhtml#page_212)
- en: transformers, success of, [43](ch08.xhtml#page_43)–[47](ch08.xhtml#page_47),
    [211](appendix.xhtml#page_211)
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 转换器，成功的，[43](ch08.xhtml#page_43)–[47](ch08.xhtml#page_47)，[211](appendix.xhtml#page_211)
- en: next-sentence/next-word prediction task, [12](ch02.xhtml#page_12), [108](ch17.xhtml#page_108),
    [109](ch17.xhtml#page_109), [194](ch30.xhtml#page_194)
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 下一句/下一个词预测任务，[12](ch02.xhtml#page_12)，[108](ch17.xhtml#page_108)，[109](ch17.xhtml#page_109)，[194](ch30.xhtml#page_194)
- en: NICE (non-linear independent components estimation), [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54),
    [58](ch09.xhtml#page_58)
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: NICE（非线性独立成分估计），[53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54)，[58](ch09.xhtml#page_58)
- en: NLP. *See* natural language processing; transformers
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）。*见*自然语言处理；转换器
- en: noise
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声
- en: consistency models and, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性模型和，[56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
- en: diffusion models and, [56](ch09.xhtml#page_56)
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散模型和，[56](ch09.xhtml#page_56)
- en: noise injection, [95](ch15.xhtml#page_95)–[96](ch15.xhtml#page_96)
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声注入，[95](ch15.xhtml#page_95)–[96](ch15.xhtml#page_96)
- en: nonconformity measure, [176](ch26.xhtml#page_176)–[177](ch26.xhtml#page_177)
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 不合规度量，[176](ch26.xhtml#page_176)–[177](ch26.xhtml#page_177)
- en: nondeterministic algorithms, [61](ch10.xhtml#page_61)
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 非确定性算法，[61](ch10.xhtml#page_61)
- en: non-linear independent components estimation (NICE), [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54),
    [58](ch09.xhtml#page_58)
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 非线性独立成分估计（NICE），[53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54)，[58](ch09.xhtml#page_58)
- en: normal approximation intervals, [166](ch25.xhtml#page_166)–[167](ch25.xhtml#page_167),
    [170](ch25.xhtml#page_170), [171](ch25.xhtml#page_171)
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 正态近似区间，[166](ch25.xhtml#page_166)–[167](ch25.xhtml#page_167)，[170](ch25.xhtml#page_170)，[171](ch25.xhtml#page_171)
- en: normalizing flows (flow-based models), [53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54),
    [57](ch09.xhtml#page_57)
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化流（基于流的模型），[53](ch09.xhtml#page_53)–[54](ch09.xhtml#page_54)，[57](ch09.xhtml#page_57)
- en: nucleus sampling (top-*p* sampling), [63](ch10.xhtml#page_63)–[64](ch10.xhtml#page_64),
    [212](appendix.xhtml#page_212)
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: NVIDIA graphics cards, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '*N*-way *K*-shot (few-shot learning), [15](ch03.xhtml#page_15)–[16](ch03.xhtml#page_16)'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '**O**'
  id: totrans-465
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ODE (ordinary differential equation) trajectory, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: one-hot encoding, [4](ch01.xhtml#page_4), [207](appendix.xhtml#page_207)
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: online resources, [xxviii](ch00.xhtml#page_xxviii)
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: operator fusion (loop fusion), [150](ch22.xhtml#page_150)–[151](ch22.xhtml#page_151)
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: ordinal regression, [161](ch24.xhtml#page_161)–[162](ch24.xhtml#page_162), [218](appendix.xhtml#page_218)–[219](appendix.xhtml#page_219)
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: ordinary differential equation (ODE) trajectory, [56](ch09.xhtml#page_56)–[57](ch09.xhtml#page_57)
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: outlier detection, [218](appendix.xhtml#page_218)
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: out-of-bag bootstrapping, [167](ch25.xhtml#page_167)–[169](ch25.xhtml#page_169),
    [170](ch25.xhtml#page_170), [171](ch25.xhtml#page_171)
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: output channels in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71),
    [76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: output layers, updating, [115](ch18.xhtml#page_115)–[116](ch18.xhtml#page_116)
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: overfitting
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: overview, [23](ch05.xhtml#page_23)
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: reducing with data, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27), [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: reducing with model modifications, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: '**P**'
  id: totrans-480
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: parallelization
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: model inference, speeding up, [147](ch22.xhtml#page_147)–[148](ch22.xhtml#page_148)
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: of transformers, [45](ch08.xhtml#page_45)–[46](ch08.xhtml#page_46)
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: parameter-efficient fine-tuning, [113](ch18.xhtml#page_113), [119](ch18.xhtml#page_119)–[124](ch18.xhtml#page_124),
    [125](ch18.xhtml#page_125), [126](ch18.xhtml#page_126)
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: parameters
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: calculating number of in CNNs, [69](ch11.xhtml#page_69)–[73](ch11.xhtml#page_73),
    [212](appendix.xhtml#page_212)–[213](appendix.xhtml#page_213)
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: of transformers, scale and number of, [45](ch08.xhtml#page_45), [47](ch08.xhtml#page_47)
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: patchifying inductive bias, [83](ch13.xhtml#page_83), [85](ch13.xhtml#page_85),
    [213](appendix.xhtml#page_213)–[214](appendix.xhtml#page_214)
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: perplexity metric, [127](ch19.xhtml#page_127)–[129](ch19.xhtml#page_129)
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: pipeline parallelism, [37](ch07.xhtml#page_37), [40](ch07.xhtml#page_40), [41](ch07.xhtml#page_41),
    [42](ch07.xhtml#page_42)
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: PixelCNN model, [54](ch09.xhtml#page_54), [58](ch09.xhtml#page_58)
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: pixel generation, autoregressive, [54](ch09.xhtml#page_54)–[55](ch09.xhtml#page_55)
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: Poisson regression, [161](ch24.xhtml#page_161)–[162](ch24.xhtml#page_162), [218](appendix.xhtml#page_218)–[219](appendix.xhtml#page_219)
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: polysemous words, [90](ch14.xhtml#page_90)
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: population parameters, [164](ch25.xhtml#page_164)
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: positive-unlabeled learning (PU-learning), [198](ch30.xhtml#page_198)
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: post-training quantization, [151](ch22.xhtml#page_151)
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: prediction intervals, [173](ch26.xhtml#page_173)–[175](ch26.xhtml#page_175),
    [178](ch26.xhtml#page_178)
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
- en: prediction regions, [174](ch26.xhtml#page_174)–[175](ch26.xhtml#page_175)
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: prediction sets, [174](ch26.xhtml#page_174), [178](ch26.xhtml#page_178), [219](appendix.xhtml#page_219)–[220](appendix.xhtml#page_220)
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: predictive analytics in healthcare, [146](ch21.xhtml#page_146), [217](appendix.xhtml#page_217)
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: predictive performance and model evaluation. *See also* limited labeled data
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: confidence intervals vs. conformal predictions, [173](ch26.xhtml#page_173)–[178](ch26.xhtml#page_178),
    [219](appendix.xhtml#page_219)–[220](appendix.xhtml#page_220)
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
- en: constructing confidence intervals, [163](ch25.xhtml#page_163)–[171](ch25.xhtml#page_171),
    [219](appendix.xhtml#page_219)
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: '*k*-fold cross-validation, [185](ch28.xhtml#page_185)–[188](ch28.xhtml#page_188),
    [221](appendix.xhtml#page_221)'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: Poisson and ordinal regression, [161](ch24.xhtml#page_161)–[162](ch24.xhtml#page_162),
    [218](appendix.xhtml#page_218)–[219](appendix.xhtml#page_219)
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
- en: proper metrics, [179](ch27.xhtml#page_179)–[183](ch27.xhtml#page_183), [220](appendix.xhtml#page_220)–[221](appendix.xhtml#page_221)
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: training and test set discordance, [189](ch29.xhtml#page_189)–[191](ch29.xhtml#page_191),
    [221](appendix.xhtml#page_221)
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
- en: prefix tuning, [119](ch18.xhtml#page_119), [120](ch18.xhtml#page_120)–[121](ch18.xhtml#page_121),
    [125](ch18.xhtml#page_125), [126](ch18.xhtml#page_126), [216](appendix.xhtml#page_216)
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: pretext tasks, [10](ch02.xhtml#page_10)
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
- en: pretrained transformers
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
- en: adapting, [124](ch18.xhtml#page_124)–[125](ch18.xhtml#page_125)
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: classification tasks, [113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116)
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: in-context learning, indexing, and prompt tuning, [116](ch18.xhtml#page_116)–[119](ch18.xhtml#page_119)
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
- en: overview, [113](ch18.xhtml#page_113)
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
- en: parameter-efficient fine-tuning, [119](ch18.xhtml#page_119)–[124](ch18.xhtml#page_124)
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: reinforcement learning with human feedback (RLHF), [124](ch18.xhtml#page_124)
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: pretraining
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: encoder-only architectures, [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: to reduce overfitting, [25](ch05.xhtml#page_25)
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: with self-supervised learning, [10](ch02.xhtml#page_10)–[11](ch02.xhtml#page_11)
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
- en: with transfer learning, [9](ch02.xhtml#page_9)–[10](ch02.xhtml#page_10)
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
- en: transformers, via self-supervised learning, [45](ch08.xhtml#page_45)
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: for vision transformers, [83](ch13.xhtml#page_83)
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
- en: prior probability shift (label shift), [154](ch23.xhtml#page_154)–[155](ch23.xhtml#page_155),
    [156](ch23.xhtml#page_156)
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: production and deployment
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
- en: data distribution shifts, [153](ch23.xhtml#page_153)–[157](ch23.xhtml#page_157),
    [218](appendix.xhtml#page_218)
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
- en: model inference, speeding up, [147](ch22.xhtml#page_147)–[152](ch22.xhtml#page_152),
    [218](appendix.xhtml#page_218)
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: stateless and stateful training, [139](ch20.xhtml#page_139)–[141](ch20.xhtml#page_141),
    [217](appendix.xhtml#page_217)
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: prompt tuning, [117](ch18.xhtml#page_117)–[118](ch18.xhtml#page_118)
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: proper metrics
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
- en: criteria for, [179](ch27.xhtml#page_179)–[180](ch27.xhtml#page_180)
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: cross-entropy loss, [182](ch27.xhtml#page_182)
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: mean squared error loss, [180](ch27.xhtml#page_180)–[181](ch27.xhtml#page_181)
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
- en: overview, [179](ch27.xhtml#page_179)
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: protein modeling, [214](appendix.xhtml#page_214)
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
- en: proximal policy optimization, [124](ch18.xhtml#page_124), [126](ch18.xhtml#page_126)
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
- en: pruning, [31](ch06.xhtml#page_31), [32](ch06.xhtml#page_32)–[33](ch06.xhtml#page_33),
    [35](ch06.xhtml#page_35), [36](ch06.xhtml#page_36), [151](ch22.xhtml#page_151)
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
- en: pseudo-labelers, [199](ch30.xhtml#page_199) PU-learning (positive-unlabeled
    learning), [198](ch30.xhtml#page_198)
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch framework, [59](ch10.xhtml#page_59), [61](ch10.xhtml#page_61), [62](ch10.xhtml#page_62),
    [65](ch10.xhtml#page_65), [149](ch22.xhtml#page_149)
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
- en: '**Q**'
  id: totrans-541
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: quantization, [151](ch22.xhtml#page_151), [152](ch22.xhtml#page_152)
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
- en: quantization-aware training, [151](ch22.xhtml#page_151)
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
- en: '**R**'
  id: totrans-544
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: random characters, [95](ch15.xhtml#page_95)
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
- en: random initialization, [209](appendix.xhtml#page_209)
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
- en: randomness, sources of
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
- en: dataset sampling and shuffling, [60](ch10.xhtml#page_60)
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: different runtime algorithms, [61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
- en: and generative AI, [62](ch10.xhtml#page_62)–[64](ch10.xhtml#page_64)
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
- en: hardware and drivers, [62](ch10.xhtml#page_62)
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
- en: model weight initialization, [59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: nondeterministic algorithms, [61](ch10.xhtml#page_61)
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: overview, [59](ch10.xhtml#page_59)
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
- en: random seeds, [169](ch25.xhtml#page_169)–[170](ch25.xhtml#page_170)
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: recall-oriented understudy for gisting evaluation (ROUGE) score, [128](ch19.xhtml#page_128),
    [131](ch19.xhtml#page_131)–[132](ch19.xhtml#page_132), [133](ch19.xhtml#page_133),
    [134](ch19.xhtml#page_134)
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: reconstruction error, measuring, [218](appendix.xhtml#page_218)
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: reconstruction loss, [52](ch09.xhtml#page_52)
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
- en: rectified linear unit (ReLU) activation function, [21](ch04.xhtml#page_21),
    [209](appendix.xhtml#page_209)
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
- en: recurrent neural networks (RNNs), [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101),
    [103](ch16.xhtml#page_103), [112](ch17.xhtml#page_112). *See also* neural networks
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
- en: with data, [23](ch05.xhtml#page_23)–[27](ch05.xhtml#page_27), [209](appendix.xhtml#page_209)–[210](appendix.xhtml#page_210)
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
- en: with model modifications, [29](ch06.xhtml#page_29)–[36](ch06.xhtml#page_36),
    [210](appendix.xhtml#page_210)
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
- en: regression, conformal prediction and confidence intervals for, [178](ch26.xhtml#page_178),
    [220](appendix.xhtml#page_220)
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
- en: regularization, reducing overfitting with, [30](ch06.xhtml#page_30)–[31](ch06.xhtml#page_31),
    [36](ch06.xhtml#page_36)
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
- en: reinforcement learning with human feedback (RLHF), [124](ch18.xhtml#page_124)
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
- en: relative positional embeddings (relative positional encodings), [82](ch13.xhtml#page_82),
    [85](ch13.xhtml#page_85)
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
- en: ReLU (rectified linear unit) activation function, [21](ch04.xhtml#page_21),
    [209](appendix.xhtml#page_209)
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
- en: reparameterization, [151](ch22.xhtml#page_151)
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
- en: representation learning, [11](ch02.xhtml#page_11)
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
- en: representations, [3](ch01.xhtml#page_3), [6](ch01.xhtml#page_6)–[7](ch01.xhtml#page_7)
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
- en: RepVGG CNN architecture, [151](ch22.xhtml#page_151), [152](ch22.xhtml#page_152)
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: residual connection in transformer architecture, [107](ch17.xhtml#page_107)
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
- en: ResNet-34 convolutional neural networks, [146](ch21.xhtml#page_146), [217](appendix.xhtml#page_217)
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
- en: resources, online, [xxviii](ch00.xhtml#page_xxviii)
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
- en: retraining
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
- en: with different random seeds, [169](ch25.xhtml#page_169)–[170](ch25.xhtml#page_170)
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
- en: stateless, [139](ch20.xhtml#page_139)–[140](ch20.xhtml#page_140), [141](ch20.xhtml#page_141),
    [217](appendix.xhtml#page_217)
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
- en: RLHF (reinforcement learning with human feedback), [124](ch18.xhtml#page_124)
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
- en: RNNs (recurrent neural networks), [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101),
    [103](ch16.xhtml#page_103), [112](ch17.xhtml#page_112). *See also* neural networks
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
- en: RoBERTa (robustly optimized BERT approach), [108](ch17.xhtml#page_108), [112](ch17.xhtml#page_112)
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
- en: root mean square error (RMSE), [183](ch27.xhtml#page_183), [220](appendix.xhtml#page_220)–[221](appendix.xhtml#page_221)
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
- en: root-squared error, [181](ch27.xhtml#page_181)
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
- en: ROUGE (recall-oriented understudy for gisting evaluation) score, [128](ch19.xhtml#page_128),
    [131](ch19.xhtml#page_131)–[132](ch19.xhtml#page_132), [133](ch19.xhtml#page_133),
    [134](ch19.xhtml#page_134)
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: runtime algorithms as source of randomness, [61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
- en: '**S**'
  id: totrans-586
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SAINT method, [208](appendix.xhtml#page_208)
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
- en: sample contrastive self-supervised learning, [14](ch02.xhtml#page_14)
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
- en: sampling as source of randomness, [60](ch10.xhtml#page_60), [65](ch10.xhtml#page_65)
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: sanity check, [189](ch29.xhtml#page_189)
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: scaled-dot product attention, [40](ch07.xhtml#page_40), [42](ch07.xhtml#page_42).
    *See also* self-attention mechanism
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
- en: SCARF method, [208](appendix.xhtml#page_208)
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
- en: score method of conformal prediction, [176](ch26.xhtml#page_176)–[177](ch26.xhtml#page_177),
    [178](ch26.xhtml#page_178)
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
- en: SE (squared error) loss, [181](ch27.xhtml#page_181)
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
- en: seeding random generator, [60](ch10.xhtml#page_60), [61](ch10.xhtml#page_61)
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
- en: self-attention mechanism. *See also* transformers
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
- en: vs. Bahdanau attention mechanism, [99](ch16.xhtml#page_99)–[101](ch16.xhtml#page_101)
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
- en: overview, [99](ch16.xhtml#page_99), [101](ch16.xhtml#page_101)–[102](ch16.xhtml#page_102)
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
- en: sequence parallelism, [40](ch07.xhtml#page_40)
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
- en: transformers, [42](ch07.xhtml#page_42), [43](ch08.xhtml#page_43)–[45](ch08.xhtml#page_45),
    [46](ch08.xhtml#page_46), [47](ch08.xhtml#page_47)
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
- en: in vision transformers, [83](ch13.xhtml#page_83)–[84](ch13.xhtml#page_84)
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
- en: self-prediction, [11](ch02.xhtml#page_11)–[12](ch02.xhtml#page_12)
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
- en: self-supervised learning
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
- en: contrastive, [12](ch02.xhtml#page_12)–[14](ch02.xhtml#page_14)
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
- en: encoder-only architectures, [108](ch17.xhtml#page_108)
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
- en: leveraging unlabeled data, [11](ch02.xhtml#page_11)
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
- en: limited labeled data, [194](ch30.xhtml#page_194)–[195](ch30.xhtml#page_195),
    [203](ch30.xhtml#page_203), [204](ch30.xhtml#page_204), [221](appendix.xhtml#page_221)–[222](appendix.xhtml#page_222)
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 有限标注数据，[194](ch30.xhtml#page_194)–[195](ch30.xhtml#page_195)，[203](ch30.xhtml#page_203)，[204](ch30.xhtml#page_204)，[221](appendix.xhtml#page_221)–[222](appendix.xhtml#page_222)
- en: overview, [9](ch02.xhtml#page_9)
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[9](ch02.xhtml#page_9)
- en: pretraining transformers via, [45](ch08.xhtml#page_45)
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 通过预训练变压器，[45](ch08.xhtml#page_45)
- en: reducing overfitting with, [25](ch05.xhtml#page_25)
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 通过减少过拟合，[25](ch05.xhtml#page_25)
- en: self-prediction, [11](ch02.xhtml#page_11)–[14](ch02.xhtml#page_14)
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 自我预测，[11](ch02.xhtml#page_11)–[14](ch02.xhtml#page_14)
- en: vs. transfer learning, [9](ch02.xhtml#page_9)–[11](ch02.xhtml#page_11)
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 与迁移学习的比较，[9](ch02.xhtml#page_9)–[11](ch02.xhtml#page_11)
- en: self-training, [199](ch30.xhtml#page_199). *See also* knowledge distillation
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 自我训练，[199](ch30.xhtml#page_199)。*另见* 知识蒸馏
- en: semi-supervised learning, [198](ch30.xhtml#page_198)–[199](ch30.xhtml#page_199),
    [203](ch30.xhtml#page_203)
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习，[198](ch30.xhtml#page_198)–[199](ch30.xhtml#page_199)，[203](ch30.xhtml#page_203)
- en: sentence shuffling, [95](ch15.xhtml#page_95)
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 句子打乱，[95](ch15.xhtml#page_95)
- en: '[SEP] token, [108](ch17.xhtml#page_108)'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '[SEP]标记，[108](ch17.xhtml#page_108)'
- en: sequence parallelism, [40](ch07.xhtml#page_40)–[41](ch07.xhtml#page_41), [42](ch07.xhtml#page_42)
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 序列并行性，[40](ch07.xhtml#page_40)–[41](ch07.xhtml#page_41)，[42](ch07.xhtml#page_42)
- en: sequence-to-sequence (seq2seq) models, [107](ch17.xhtml#page_107)–[110](ch17.xhtml#page_110)
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 序列到序列（seq2seq）模型，[107](ch17.xhtml#page_107)–[110](ch17.xhtml#page_110)
- en: sequential inference, [148](ch22.xhtml#page_148)
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序推理，[148](ch22.xhtml#page_148)
- en: SGD (stochastic gradient descent) optimizer, [73](ch11.xhtml#page_73), [212](appendix.xhtml#page_212)
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: SGD（随机梯度下降）优化器，[73](ch11.xhtml#page_73)，[212](appendix.xhtml#page_212)
- en: shortcut connection, [107](ch17.xhtml#page_107)
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 跳跃连接，[107](ch17.xhtml#page_107)
- en: siamese network setup, [13](ch02.xhtml#page_13)
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 孪生网络设置，[13](ch02.xhtml#page_13)
- en: similarity, embeddings as encoding, [5](ch01.xhtml#page_5)
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 相似性，嵌入作为编码，[5](ch01.xhtml#page_5)
- en: .632 bootstrap, [171](ch25.xhtml#page_171)
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: .632自助法，[171](ch25.xhtml#page_171)
- en: skip connection in transformer architecture, [107](ch17.xhtml#page_107)
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器架构中的跳跃连接，[107](ch17.xhtml#page_107)
- en: skip-gram approach, Word2vec, [90](ch14.xhtml#page_90)
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 跳字法（skip-gram）方法，Word2vec，[90](ch14.xhtml#page_90)
- en: smaller models, reducing overfitting with, [31](ch06.xhtml#page_31)–[33](ch06.xhtml#page_33)
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 更小的模型，通过减少过拟合，[31](ch06.xhtml#page_31)–[33](ch06.xhtml#page_33)
- en: soft attention, [211](appendix.xhtml#page_211)
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 软注意力，[211](appendix.xhtml#page_211)
- en: soft parameter sharing, [200](ch30.xhtml#page_200)
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: '**软参数共享**，[200](ch30.xhtml#page_200)'
- en: soft prompting, [119](ch18.xhtml#page_119)–[121](ch18.xhtml#page_121), [125](ch18.xhtml#page_125)
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 软提示，[119](ch18.xhtml#page_119)–[121](ch18.xhtml#page_121)，[125](ch18.xhtml#page_125)
- en: sources of randomness
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: 随机性来源
- en: dataset sampling and shuffling, [60](ch10.xhtml#page_60)
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集采样和打乱，[60](ch10.xhtml#page_60)
- en: different runtime algorithms, [61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的运行时算法，[61](ch10.xhtml#page_61)–[62](ch10.xhtml#page_62)
- en: and generative AI, [62](ch10.xhtml#page_62)–[64](ch10.xhtml#page_64)
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 和生成性AI，[62](ch10.xhtml#page_62)–[64](ch10.xhtml#page_64)
- en: hardware and drivers, [62](ch10.xhtml#page_62)
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件和驱动程序，[62](ch10.xhtml#page_62)
- en: model weight initialization, [59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 模型权重初始化，[59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
- en: nondeterministic algorithms, [61](ch10.xhtml#page_61)
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 非确定性算法，[61](ch10.xhtml#page_61)
- en: overview, [59](ch10.xhtml#page_59)
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 概述，[59](ch10.xhtml#page_59)
- en: spatial attention, [215](appendix.xhtml#page_215)
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 空间注意力，[215](appendix.xhtml#page_215)
- en: spatial invariance, [80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 空间不变性，[80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
- en: speeding up inference. *See* model inference, speeding up
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: 加速推理。*参见* 模型推理，加速
- en: squared error (SE) loss, [181](ch27.xhtml#page_181)
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 平方误差（SE）损失，[181](ch27.xhtml#page_181)
- en: Stable Diffusion latent diffusion model, [58](ch09.xhtml#page_58)
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散潜在扩散模型，[58](ch09.xhtml#page_58)
- en: stacking (stacked generalization), [33](ch06.xhtml#page_33)
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠（堆叠泛化），[33](ch06.xhtml#page_33)
- en: stateful training, [139](ch20.xhtml#page_139), [140](ch20.xhtml#page_140)–[141](ch20.xhtml#page_141),
    [217](appendix.xhtml#page_217)
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 有状态训练，[139](ch20.xhtml#page_139)，[140](ch20.xhtml#page_140)–[141](ch20.xhtml#page_141)，[217](appendix.xhtml#page_217)
- en: stateless training (stateless retraining), [139](ch20.xhtml#page_139)–[140](ch20.xhtml#page_140),
    [141](ch20.xhtml#page_141), [217](appendix.xhtml#page_217)
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 无状态训练（无状态再训练），[139](ch20.xhtml#page_139)–[140](ch20.xhtml#page_140)，[141](ch20.xhtml#page_141)，[217](appendix.xhtml#page_217)
- en: statistical population, [164](ch25.xhtml#page_164)
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 统计总体，[164](ch25.xhtml#page_164)
- en: statistical two-sample tests, [218](appendix.xhtml#page_218)
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 统计两样本检验，[218](appendix.xhtml#page_218)
- en: stochastic diffusion process, [56](ch09.xhtml#page_56)
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 随机扩散过程，[56](ch09.xhtml#page_56)
- en: stochastic gradient descent (SGD) optimizer, [73](ch11.xhtml#page_73), [212](appendix.xhtml#page_212)
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
- en: stride, [78](ch12.xhtml#page_78), [213](appendix.xhtml#page_213)
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
- en: structured pruning, [20](ch04.xhtml#page_20)
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
- en: student in knowledge distillation, [31](ch06.xhtml#page_31)–[32](ch06.xhtml#page_32)
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
- en: supervised learning, [15](ch03.xhtml#page_15). *See also* limited labeled data
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
- en: support set in few-shot learning, [16](ch03.xhtml#page_16)
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
- en: synonym replacement (text augmentation), [93](ch15.xhtml#page_93)–[94](ch15.xhtml#page_94)
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
- en: synthetic data generation, [96](ch15.xhtml#page_96)–[97](ch15.xhtml#page_97)
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
- en: '**T**'
  id: totrans-658
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: TabNet, [208](appendix.xhtml#page_208)
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
- en: tabular data, self-supervised learning for, [14](ch02.xhtml#page_14), [208](appendix.xhtml#page_208)
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
- en: teacher in knowledge distillation, [31](ch06.xhtml#page_31)–[32](ch06.xhtml#page_32)
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
- en: 10-fold cross-validation, [187](ch28.xhtml#page_187), [188](ch28.xhtml#page_188)
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow framework, [59](ch10.xhtml#page_59), [62](ch10.xhtml#page_62), [149](ch22.xhtml#page_149)
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
- en: tensor parallelism, [37](ch07.xhtml#page_37), [38](ch07.xhtml#page_38)–[40](ch07.xhtml#page_40),
    [41](ch07.xhtml#page_41)–[42](ch07.xhtml#page_42), [211](appendix.xhtml#page_211)
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
- en: test sets
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
- en: bootstrapping, [169](ch25.xhtml#page_169), [170](ch25.xhtml#page_170), [171](ch25.xhtml#page_171)
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
- en: conformal predictions, [176](ch26.xhtml#page_176)
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
- en: discordance with training sets, [189](ch29.xhtml#page_189)–[191](ch29.xhtml#page_191),
    [221](appendix.xhtml#page_221)
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
- en: text, data augmentation for, [93](ch15.xhtml#page_93)–[97](ch15.xhtml#page_97),
    [214](appendix.xhtml#page_214)–[215](appendix.xhtml#page_215)
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
- en: T5 encoder-decoder architecture, [112](ch17.xhtml#page_112)
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
- en: time complexity of self-attention, [103](ch16.xhtml#page_103), [215](appendix.xhtml#page_215)
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
- en: top-*k* sampling, [63](ch10.xhtml#page_63)–[64](ch10.xhtml#page_64), [212](appendix.xhtml#page_212)
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
- en: training. *See also* multi-GPU training paradigms; pretraining; randomness,
    sources of; retraining
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
- en: epochs, tuning number of, [35](ch06.xhtml#page_35), [210](appendix.xhtml#page_210)
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
- en: post-training quantization, [151](ch22.xhtml#page_151)
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
- en: procedure for lottery ticket hypothesis, [19](ch04.xhtml#page_19)–[20](ch04.xhtml#page_20)
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
- en: quantization-aware, [151](ch22.xhtml#page_151)
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
- en: self-training, [199](ch30.xhtml#page_199)
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
- en: stateless and stateful, [139](ch20.xhtml#page_139)–[141](ch20.xhtml#page_141),
    [217](appendix.xhtml#page_217)
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
- en: training sets
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
- en: conformal predictions, [176](ch26.xhtml#page_176), [177](ch26.xhtml#page_177)
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
- en: discordance with test sets, [189](ch29.xhtml#page_189)–[191](ch29.xhtml#page_191),
    [221](appendix.xhtml#page_221)
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
- en: for vision transformers, [79](ch13.xhtml#page_79)–[85](ch13.xhtml#page_85),
    [213](appendix.xhtml#page_213)–[214](appendix.xhtml#page_214)
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
- en: transfer learning
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
- en: limited labeled data, [194](ch30.xhtml#page_194), [203](ch30.xhtml#page_203),
    [204](ch30.xhtml#page_204), [221](appendix.xhtml#page_221)–[222](appendix.xhtml#page_222)
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
- en: reducing overfitting with, [25](ch05.xhtml#page_25), [26](ch05.xhtml#page_26),
    [209](appendix.xhtml#page_209)
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
- en: vs. self-supervised learning, [9](ch02.xhtml#page_9)–[11](ch02.xhtml#page_11)
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
- en: transformers. *See also* self-attention mechanism
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
- en: adapting pretrained language models, [124](ch18.xhtml#page_124)–[125](ch18.xhtml#page_125)
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
- en: attention mechanism, [40](ch07.xhtml#page_40), [43](ch08.xhtml#page_43)–[45](ch08.xhtml#page_45)
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
- en: classification tasks, [113](ch18.xhtml#page_113)–[116](ch18.xhtml#page_116)
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
- en: contemporary models, [111](ch17.xhtml#page_111)–[112](ch17.xhtml#page_112)
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
- en: decoders, [108](ch17.xhtml#page_108)–[110](ch17.xhtml#page_110)
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
- en: encoder-decoder hybrids, [110](ch17.xhtml#page_110)
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
- en: encoders, [107](ch17.xhtml#page_107)–[108](ch17.xhtml#page_108)
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
- en: in-context learning, indexing, and prompt tuning, [116](ch18.xhtml#page_116)–[119](ch18.xhtml#page_119)
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
- en: multi-GPU training paradigms, [40](ch07.xhtml#page_40), [42](ch07.xhtml#page_42)
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
- en: number of parameters, [45](ch08.xhtml#page_45)
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
- en: original architecture for, [105](ch17.xhtml#page_105)–[110](ch17.xhtml#page_110)
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
- en: overview, [105](ch17.xhtml#page_105), [113](ch18.xhtml#page_113)
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
- en: parallelization, [45](ch08.xhtml#page_45)–[46](ch08.xhtml#page_46)
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
- en: parameter-efficient fine-tuning, [119](ch18.xhtml#page_119)–[124](ch18.xhtml#page_124)
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
- en: pretraining via self-supervised learning, [45](ch08.xhtml#page_45)
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
- en: reinforcement learning with human feedback (RLHF), [124](ch18.xhtml#page_124)
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
- en: success of, [43](ch08.xhtml#page_43)–[47](ch08.xhtml#page_47)
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
- en: terminology, [110](ch17.xhtml#page_110)
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
- en: transfer learning, [11](ch02.xhtml#page_11)
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
- en: translation
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
- en: back, [96](ch15.xhtml#page_96)
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
- en: invariance and equivariance, [80](ch13.xhtml#page_80)–[82](ch13.xhtml#page_82)
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
- en: tokens, [44](ch08.xhtml#page_44)–[46](ch08.xhtml#page_46), [63](ch10.xhtml#page_63)–[64](ch10.xhtml#page_64),
    [102](ch16.xhtml#page_102), [106](ch17.xhtml#page_106)–[110](ch17.xhtml#page_110),
    [117](ch18.xhtml#page_117)–[118](ch18.xhtml#page_118)
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
- en: triangle inequality, [180](ch27.xhtml#page_180), [181](ch27.xhtml#page_181),
    [182](ch27.xhtml#page_182)
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
- en: true generalization accuracy, [164](ch25.xhtml#page_164)
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
- en: two-dimensional embeddings, [4](ch01.xhtml#page_4)–[5](ch01.xhtml#page_5)
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
- en: typo introduction, [95](ch15.xhtml#page_95)
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
- en: '**U**'
  id: totrans-716
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: unlabeled data in self-supervised learning, [10](ch02.xhtml#page_10), [11](ch02.xhtml#page_11)
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
- en: unstructured pruning, [20](ch04.xhtml#page_20)
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
- en: unsupervised pretraining. *See* self-supervised learning
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
- en: '**V**'
  id: totrans-720
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: variational autoencoders (VAEs), [51](ch09.xhtml#page_51)–[52](ch09.xhtml#page_52),
    [53](ch09.xhtml#page_53), [54](ch09.xhtml#page_54), [57](ch09.xhtml#page_57),
    [58](ch09.xhtml#page_58)
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
- en: variational inference, [51](ch09.xhtml#page_51)
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
- en: vectorization, [148](ch22.xhtml#page_148)–[149](ch22.xhtml#page_149), [152](ch22.xhtml#page_152),
    [218](appendix.xhtml#page_218)
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
- en: VideoBERT model, [201](ch30.xhtml#page_201), [204](ch30.xhtml#page_204)
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
- en: video data, applying self-supervised learning to, [14](ch02.xhtml#page_14),
    [208](appendix.xhtml#page_208)
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
- en: vision transformers (ViTs)
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉变换器（ViTs）
- en: vs. convolutional neural networks, [79](ch13.xhtml#page_79), [82](ch13.xhtml#page_82)–[83](ch13.xhtml#page_83),
    [84](ch13.xhtml#page_84)
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: 与卷积神经网络相比，[79](ch13.xhtml#page_79)，[82](ch13.xhtml#page_82)–[83](ch13.xhtml#page_83)，[84](ch13.xhtml#page_84)
- en: inductive biases in, [83](ch13.xhtml#page_83)–[84](ch13.xhtml#page_84)
  id: totrans-728
  prefs: []
  type: TYPE_NORMAL
  zh: 归纳偏差，[83](ch13.xhtml#page_83)–[84](ch13.xhtml#page_84)
- en: large training sets for, [79](ch13.xhtml#page_79)
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模训练集，[79](ch13.xhtml#page_79)
- en: positional information in, [82](ch13.xhtml#page_82), [85](ch13.xhtml#page_85)
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: 位置信息，[82](ch13.xhtml#page_82)，[85](ch13.xhtml#page_85)
- en: recommendations for, [84](ch13.xhtml#page_84)
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐，[84](ch13.xhtml#page_84)
- en: '**W**'
  id: totrans-732
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**W**'
- en: weakly supervised learning, [197](ch30.xhtml#page_197)–[199](ch30.xhtml#page_199),
    [203](ch30.xhtml#page_203)
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: 弱监督学习，[197](ch30.xhtml#page_197)–[199](ch30.xhtml#page_199)，[203](ch30.xhtml#page_203)
- en: weight decay, [30](ch06.xhtml#page_30), [35](ch06.xhtml#page_35)
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 权重衰减，[30](ch06.xhtml#page_30)，[35](ch06.xhtml#page_35)
- en: weighted loss function, [155](ch23.xhtml#page_155)
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 加权损失函数，[155](ch23.xhtml#page_155)
- en: weight initialization, [59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 权重初始化，[59](ch10.xhtml#page_59)–[60](ch10.xhtml#page_60)
- en: weight normalization, [34](ch06.xhtml#page_34)–[35](ch06.xhtml#page_35)
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 权重归一化，[34](ch06.xhtml#page_34)–[35](ch06.xhtml#page_35)
- en: weight pruning, [19](ch04.xhtml#page_19), [20](ch04.xhtml#page_20)
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 权重剪枝，[19](ch04.xhtml#page_19)，[20](ch04.xhtml#page_20)
- en: weights
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 权重
- en: in convolutional layers, [70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71),
    [76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积层中，[70](ch11.xhtml#page_70)–[71](ch11.xhtml#page_71)，[76](ch12.xhtml#page_76)–[77](ch12.xhtml#page_77)
- en: in fully connected layers, [72](ch11.xhtml#page_72), [76](ch12.xhtml#page_76)
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 在全连接层中，[72](ch11.xhtml#page_72)，[76](ch12.xhtml#page_76)
- en: weight sharing, [80](ch13.xhtml#page_80), [81](ch13.xhtml#page_81)
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 权重共享，[80](ch13.xhtml#page_80)，[81](ch13.xhtml#page_81)
- en: winning tickets (lottery ticket hypothesis), [20](ch04.xhtml#page_20), [21](ch04.xhtml#page_21)
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 胜利彩票（彩票假设），[20](ch04.xhtml#page_20)，[21](ch04.xhtml#page_21)
- en: Winograd-based convolution, [62](ch10.xhtml#page_62), [65](ch10.xhtml#page_65)
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 Winograd 的卷积，[62](ch10.xhtml#page_62)，[65](ch10.xhtml#page_65)
- en: word deletion (text augmentation), [94](ch15.xhtml#page_94)
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 单词删除（文本增强），[94](ch15.xhtml#page_94)
- en: word embeddings. *See* embeddings
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 词嵌入。*另见* 嵌入
- en: WordNet thesaurus, [94](ch15.xhtml#page_94), [97](ch15.xhtml#page_97)
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: WordNet 同义词库，[94](ch15.xhtml#page_94)，[97](ch15.xhtml#page_97)
- en: word position swapping (word shuffling/permutation), [94](ch15.xhtml#page_94)–[95](ch15.xhtml#page_95)
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: 单词位置交换（单词洗牌/排列），[94](ch15.xhtml#page_94)–[95](ch15.xhtml#page_95)
- en: Word2vec model, [90](ch14.xhtml#page_90), [92](ch14.xhtml#page_92)
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: Word2vec 模型，[90](ch14.xhtml#page_90)，[92](ch14.xhtml#page_92)
- en: '**X**'
  id: totrans-750
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**X**'
- en: XGBoost model, [26](ch05.xhtml#page_26), [209](appendix.xhtml#page_209)
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost 模型，[26](ch05.xhtml#page_26)，[209](appendix.xhtml#page_209)
- en: '**Z**'
  id: totrans-752
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Z**'
- en: zero-shot learning, [195](ch30.xhtml#page_195)–[196](ch30.xhtml#page_196). *See
    also* few-shot learning; in-context learning
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: 零-shot 学习，[195](ch30.xhtml#page_195)–[196](ch30.xhtml#page_196)。*另见* 少-shot
    学习；上下文学习
- en: '*z*-scores (confidence intervals), [166](ch25.xhtml#page_166)'
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: '*z* 分数（置信区间），[166](ch25.xhtml#page_166)'
