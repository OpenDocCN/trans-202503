<html><head></head><body><div id="sbo-rt-content"><section class="frontmatter" epub:type="introduction">
<header><h1 class="FrontmatterTitle" id="fm-500723f06-0001"><span epub:type="pagebreak" title="xxiii" id="Page_xxiii"/>Introduction</h1></header>
<figure class="opener">
<img src="Images/chapterart.png" alt="" width="206" height="206"/>
</figure>
<p class="ChapterIntro">Imagine that you’re rubbing a golden lamp. You say, “Genie, for my three wishes, give me someone to love, great wealth, and a long and healthy life.” </p>
<p>Now imagine that you’re entering your home. You say, “House, bring the car around, ask Sarah if she’s free for lunch, schedule a haircut, and make me a latte. Oh, and play some Thelonious Monk, please.” </p>
<p>In both of these situations, you’re asking a disembodied being of great power to hear you, understand you, and fulfill your desires. The first scenario is a fantasy going back millennia. The second scenario is commonplace reality today, thanks to artificial intelligence, or AI. </p>
<p>How did we invent these magic genies? The revolution in AI that’s changing the world today is the result of three developments. </p>
<p>First, computers are getting bigger and faster every year, and special-purpose chips originally intended for generating images are now powering AI techniques as well.</p>
<p>Second, people keep developing new algorithms. Surprisingly, some of the algorithms powering AI today have been around for decades. They were more powerful than anyone knew and were just waiting for enough <span epub:type="pagebreak" title="xxiv" id="Page_xxiv"/>data and compute power to let them shine. Newer and even more powerful algorithms are now pushing the field forward at an increasingly rapid pace. Some of the most powerful algorithms used today belong to a category of AI called <em>deep learning</em>, and those are the techniques we’ll emphasize in this book. </p>
<p>Third, and perhaps most critically, there are now massive databases for these algorithms to learn from. Social networks, streaming services, governments, credit card agencies, and even supermarkets measure and retain every crumb of information they can gather. Public data on the web is also vast. As of late 2020, estimates suggest there are more than 4 billion hours of video freely available online, over 17 billion images, and an untold amount of text covering topics from sports history to weather patterns to municipal records. </p>
<p>In practice, these databases are often seen as the most valuable component of any new machine learning system. After all, anyone with money can buy computers, and the algorithms they run are almost all publicly available in research journals, books, and open source repositories. It’s the data that organizations jealously hoard, to use for themselves, or to sell to the highest bidder. It’s no stretch to say that databases are the new oil, the new gold.</p>
<p>Like any radical technology, AI has its rosy cheerleaders who foresee great advantages for the human race and dour predictors of doom who see nothing but ruin and the destruction of the societies and cultures that make up our world. Who is right? How can we judge the risks and rewards of this new technology? When should we embrace AI and when should we forbid it?</p>
<p>The best way to thoughtfully deal with a new technology is to understand it. When we know how it works, and the nature of its powers and limitations, we can determine where and how it should be used to create a future we want to inhabit. This book exists to help you understand what deep learning is and how it works. When you know the strengths and weaknesses of deep learning, you’ll be in a better position to use it for your own work and understand its actual and potential impacts on our cultures and societies. It will also help you see when people and organizations that hold power are using these tools, and then determine for yourself whether they’re using them for your advantage, or their own. </p>
<h2 id="h1-500723f06-0001">Who This Book Is For</h2>
<p class="BodyFirst">I wrote this book for anyone who’s interested in how deep learning works. You don’t need math or programming experience. You don’t need to be a computer whiz. You don’t have to be a technologist at all! </p>
<p>This book is for anyone with curiosity and a desire to look behind the headlines. You may be surprised that most of the algorithms of deep learning aren’t very complicated or hard to understand. They’re usually simple and elegant and gain their power by being repeated millions of times over huge databases.  </p>
<p><span epub:type="pagebreak" title="xxv" id="Page_xxv"/>In addition to satisfying pure intellectual curiosity (which I think is a fine reason to learn anything), I wrote this book for people who come face to face with deep learning, either in their own work or when interacting with others who use it. After all, one of the best reasons to understand AI is so we can use it ourselves! We can build AI systems now that help us do our work better, enjoy our hobbies more deeply, and understand the world around us more fully. </p>
<p>If you want to know how this stuff works, you’re going to feel right at home. </p>
<h2 id="h1-500723f06-0002">This Book Has No Complex Math and No Code</h2>
<p class="BodyFirst">Everybody has their own way of learning. I wrote this book because I felt there were people who would like to understand deep learning but didn’t want to get there by studying equations or programs. </p>
<p>So, rather than describe algorithms with equations or program listings, I use words and pictures. That doesn’t mean the descriptions are sloppy or vague. Rather, I’ve worked hard to be as clear as possible, and, when appropriate, precise. When you’re done with this book, you’ll have a solid grasp of the general principles. If you later decide that you’d like to reframe your understanding in mathematical language, or write programs with a specific computer language or library, you’ll find it much easier than starting from scratch.</p>
<h2 id="h1-500723f06-0003">There Is Code, If You Want It</h2>
<p class="BodyFirst">Although programming skills aren’t needed to read this book, translating the ideas into practice is important if you want to build and train your own systems. So, if you have that itch, I’ve provided the tools to scratch it. </p>
<p>I’ve provided three free bonus chapters on my GitHub at <a href="https://github.com/blueberrymusic" class="LinkURL">https://github.com/blueberrymusic</a>. One chapter addresses using Python’s free scikit-learn library, and the other two show how to build many of the deep learning systems we talk about in the book. With actual running code to build on and modify, you’ll be able to use existing networks or design and train your own networks for your own applications. The code is presented in the popular form of Jupyter notebooks, so it’s ready for your investigation, experimentation, adaptation, and use.</p>
<p>All of these programs are shared under the MIT license, which means you can use them in almost any way you like. </p>
<h2 id="h1-500723f06-0004">The Figures Are Available, Too!</h2>
<p class="BodyFirst">Also on my GitHub at <a href="https://github.com/blueberrymusic" class="LinkURL">https://github.com/blueberrymusic</a> you’ll find almost every figure that I drew for this book, in high-quality 300 dpi PNG format. <span epub:type="pagebreak" title="xxvi" id="Page_xxvi"/>The figures are provided under the same MIT license as the code, so you’re free to use or modify them for classes, talks, presentations, papers, or any other use where you feel one of these figures would help you out. </p>
<h2 id="h1-500723f06-0005">Errata</h2>
<p>No book of this size is going to be free of errors, from little typos to big mistakes. If you spot something that seems wrong, please let us know at <a href="http://mailto:errata@nostarch.com">errata@nostarch.com</a>. We’ll keep a list of the confirmed corrections at <a href="https://nostarch.com/deep-learning-visual-approach" class="LinkURL">https://nostarch.com/deep-learning-visual-approach</a>.</p>
<h2 id="h1-500723f06-0006">About This Book</h2>
<p class="BodyFirst">The first part of this book covers foundational ideas from probability, statistics, and information theory that we’ll need later on. Don’t let these topic names intimidate you! We’ll be sticking to the basic and essential ideas, with almost no mathematical notation. You may be surprised at how easy some of these topics are when they’re presented in plain language and diagrams.</p>
<p>The second part of the book covers basic machine learning concepts, including basic ideas and some classic algorithms. </p>
<p>With that background in place, the third and fourth parts of the book are where it all comes together, and we get into deep learning itself. </p>
<p>Here’s a brief overview of what you’ll find in each chapter.</p>
<h3 id="h2-500723f06-0001">Part I: Foundational Ideas</h3>
<ol class="none">
<li><b>Chapter 1:</b> <b>An Overview of Machine Learning</b>. We’ll look at the big picture and set the stage for how machine learning works.</li>
<li><b>Chapter 2:</b> <b>Essential Statistics</b>. A core idea in deep learning is finding patterns in data. The language of statistics allows us to identify and discuss those patterns.</li>
<li><b>Chapter 3:</b> <b>Measuring Performance</b>. When an algorithm answers a question, there is always some chance that answer is wrong. By carefully choosing how we measure, we can talk about what “wrong” really means.</li>
<li><b>Chapter 4:</b> <b>Bayes’ Rule</b>. We can discuss the likelihood that an algorithm is giving us correct results by considering both our expectations and what results we’ve seen so far. Bayes’ Rule is a powerful way to do this.</li>
<li><b>Chapter 5:</b> <b>Curves and Surfaces</b>. As a learning algorithm searches for patterns in data, it often makes use of abstracted curves and surfaces in imaginary spaces. To help us discuss those algorithms later in the book, here we discuss what those curves and surfaces look like.</li>
<li><b>Chapter 6:</b> <b>Information Theory</b>. A powerful idea used in machine learning is that we are representing and modifying information. The ideas of information theory let us quantify and measure different kinds of information.</li>
</ol>
<h3 id="h2-500723f06-0002"><span epub:type="pagebreak" title="xxvii" id="Page_xxvii"/>Part II: Basic Machine Learning</h3>
<ol class="none">
<li><b>Chapter 7:</b> <b>Classification</b>. We often want a computer to assign a specific class, or category, to a piece of data. For example, what animal is in a photo, or what word is being said into a phone? We look at the basic ideas for solving this problem.</li>
<li><b>Chapter 8:</b> <b>Training and Testing</b>. To build a deep learning system for use in the world, we must first train it to learn how to do what we want and then test its performance to be sure it’s doing the job well. </li>
<li><b>Chapter 9:</b> <b>Overfitting and Underfitting</b>. A surprising result of training a deep learning system is that it can start memorizing the data we’re using to train it. In an apparent paradox, this makes it worse at handling new data when the algorithm is released. We’ll see where this problem comes from and how to reduce its impact.</li>
<li><b>Chapter 10:</b> <b>Data Preparation</b>. We train a deep learning system by providing it with lots of data to learn from. We’ll see how to prepare that data so training is as efficient as possible.</li>
<li><b>Chapter 11:</b> <b>Classifiers</b>. We’ll look at specific machine learning algorithms for classifying data. These are often a good way to get to know our data before investing the time and effort to train a deep learning system. </li>
<li><b>Chapter 12:</b> <b>Ensembles</b>. We can assemble lots of very simple learning systems into a far more powerful composite system. Sometimes many small systems can return an answer faster, and more accurately, than a single big system.</li>
</ol>
<h3 id="h2-500723f06-0003">Part III: Deep Learning Basics</h3>
<ol class="none">
<li><b>Chapter 13:</b> <b>Neural Networks</b>. We look at artificial neurons, and how to connect them together to form a network. These networks form the basis of deep learning. </li>
<li><b>Chapter 14:</b> <b>Backpropagation</b>. The key algorithm that makes neural networks practical is a way of training them so that they learn from data. We look closely into the first of the two algorithms that make up the learning process. </li>
<li><b>Chapter 15:</b> <b>Optimizers</b>. The second algorithm for training a deep network actually modifies the numbers that make up the network, improving its performance. We’ll look at a variety of ways to do this effectively. </li>
</ol>
<h3 id="h2-500723f06-0004">Part IV: Beyond the Basics</h3>
<ol class="none">
<li><b>Chapter 16:</b> <b>Convolutional Neural Networks</b>. Powerful algorithms have been developed to handle spatial data like images. We’ll look at these algorithms and how they are used.</li>
<li><b>Chapter 17:</b> <b>Convnets in Practice</b>. Having covered the techniques of handling spatial data, we’ll look more closely at how we can use those techniques in practice to recognize objects. </li>
<li><span epub:type="pagebreak" title="xxviii" id="Page_xxviii"/><b>Chapter 18:</b> <b>Autoencoders</b>. We can simplify huge datasets so that they’re smaller in size and easier to manage. We can also remove noise, enabling us to clean up damaged images. </li>
<li><b>Chapter 19:</b> <b>Recurrent Neural Networks</b>. When we work with sequences, like text and audio clips, we need special tools. We’ll see one popular class of them here.</li>
<li><b>Chapter 20:</b> <b>Attention and Transformers</b>. Understanding text and language is particularly important. We’ll look at algorithms originally designed to interpret and generate text, but which are proving to also be useful in other applications.</li>
<li><b>Chapter 21:</b> <b>Reinforcement Learning</b>. Sometimes we don’t know the answers we want the computer to provide, such as when scheduling real-world activities involving unpredictable groups of people. We’ll see how to address these kinds of problem flexibly.</li>
<li><b>Chapter 22:</b> <b>Generative Adversarial Networks</b>. We often want to create, or generate, new instances of the data we have, for example to create newspaper stories from raw data, or perhaps worlds for people to explore in games. We’ll look at a powerful way to train such generators.</li>
<li><b>Chapter 23:</b> <b>Creative Applications</b>. We wrap up with some fun, applying the tools of deep learning to make psychedelic images, apply an artist’s signature style to a photograph, and generate new text in the style of any author.</li>
</ol>
<h2 id="h1-500723f06-0007">Final Words</h2>
<p class="BodyFirst">There’s a lot of material in this book!</p>
<p>It’s all there so that when you’re done, you’ll really know your stuff. You’ll be able to talk to other people about deep learning, sharing your insights and experience, and learn from theirs. And if you’re so motivated, you’ll be able to grab one of the many free deep learning libraries and design, train, test, and deploy your own systems for any purpose you can dream up.</p>
<p>Deep learning is a fascinating field that combines ideas from many intellectual disciplines to build algorithms that are forcing us to ask fundamental questions about the nature of intelligence and understanding. It’s also a whole lot of fun! </p>
<p>Welcome to the journey. You’re going to have a great time!</p>
</section>
</div></body></html>