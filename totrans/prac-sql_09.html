<html><head></head><body><div id="sbo-rt-content"><section>&#13;
<header>&#13;
<h1 class="chapter">&#13;
<span class="ChapterNumber"><span epub:type="pagebreak" title="139" id="Page_139"/>9</span><br/>&#13;
<span class="ChapterTitle">Extracting Information by Grouping and Summarizing</span></h1>&#13;
</header>&#13;
<figure class="opener">&#13;
<img src="Images/chapterart.png" alt="" width="200" height="200"/>&#13;
</figure>&#13;
<p class="ChapterIntro">Every dataset tells a story, and it’s the data analyst’s job to find it. In <span class="xref" itemid="xref_target_Chapter 3">Chapter 3</span>, you learned about interviewing data using <code>SELECT</code> statements by sorting columns, finding distinct values, and filtering results. You’ve also learned the fundamentals of SQL math, data types, table design, and joining tables. With these tools under your belt, you’re ready to glean more insights by using <em>grouping</em> and <em>aggregate functions</em> to summarize your data.</p>&#13;
<p>By summarizing data, we can identify useful information we wouldn’t see just by scanning the rows of a table. In this chapter, we’ll use the well-known institution of your local library as our example.</p>&#13;
<p>Libraries remain a vital part of communities worldwide, but the internet and advancements in library technology have changed how we use them. For example, ebooks and online access to digital materials now have a permanent place in libraries along with books and periodicals.</p>&#13;
<p><span epub:type="pagebreak" title="140" id="Page_140"/>In the United States, the Institute of Museum and Library Services (IMLS) measures library activity as part of its annual Public Libraries Survey. The survey collects data from about 9,000 library administrative entities, defined by the survey as agencies that provide library services to a particular locality. Some agencies are county library systems, and others are part of school districts. Data on each agency includes the number of branches, staff, books, hours open per year, and so on. The IMLS has been collecting data each year since 1988 and includes all public library agencies in the 50 states plus the District of Columbia and US territories such as American Samoa. (Read more about the program at <a href="https://www.imls.gov/research-evaluation/data-collection/public-libraries-survey/" class="LinkURL">https://www.imls.gov/research-evaluation/data-collection/public-libraries-survey/</a>.)</p>&#13;
<p>For this exercise, we’ll assume the role of an analyst who just received a fresh copy of the library dataset to produce a report describing trends from the data. We’ll create three tables to hold data from the 2018, 2017, and 2016 surveys. (Often, it’s helpful to assess multiple years of data to discern trends.) Then we’ll summarize the more interesting data in each table and join the tables to see how measures changed over time.</p>&#13;
<h2 id="h1-501065c09-0001">Creating the Library Survey Tables</h2>&#13;
<p class="BodyFirst">Let’s create the three library survey tables and import the data. We’ll use appropriate data types and constraints for each column and add indexes where appropriate. The code and three CSV files are available in the book’s resources.</p>&#13;
<h3 id="h2-501065c09-0001">Creating the 2018 Library Data Table</h3>&#13;
<p class="BodyFirst">We’ll start by creating the table for the 2018 library data. Using the <code>CREATE TABLE</code> statement, <a href="#listing9-1" id="listinganchor9-1">Listing 9-1</a> builds <code>pls_fy2018_libraries</code>, a table for the fiscal year 2018 Public Library System Data File from the Public Libraries Survey. The Public Library System Data File summarizes data at the agency level, counting activity at all agency outlets, which include central libraries, branch libraries, and bookmobiles. The annual survey generates two additional files we won’t use: one summarizes data at the state level, and the other has data on individual outlets. For this exercise, those files are redundant, but you can read about the data they contain at <a href="https://www.imls.gov/sites/default/files/2018_pls_data_file_documentation.pdf" class="LinkURL">https://www.imls.gov/sites/default/files/2018_pls_data_file_documentation.pdf</a>.</p>&#13;
<p>For convenience, I’ve created a naming scheme for the tables: <code>pls</code> refers to the survey title, <code>fy2018</code> is the fiscal year the data covers, and <code>libraries</code> is the name of the particular file from the survey. For simplicity, I’ve selected 47 of the more relevant columns from the 166 in the original survey file to fill the <code>pls_fy2018_libraries</code> table, excluding data such as the codes that explain the source of individual responses. When a library didn’t provide data, the agency derived the data using other means, but we don’t need that information for this exercise.</p>&#13;
<p><a href="#listing9-1">Listing 9-1</a> is abbreviated for convenience, as indicated by the <var>--snip--</var> noted in the code, but the full version is included with the book’s resources.</p>&#13;
<pre><code><span epub:type="pagebreak" title="141" id="Page_141"/>CREATE TABLE pls_fy2018_libraries (&#13;
    stabr text NOT NULL,&#13;
    <span class="CodeAnnotationHang" aria-label="annotation1">1</span> fscskey text CONSTRAINT fscskey_2018_pkey PRIMARY KEY,&#13;
    libid text NOT NULL,&#13;
    libname text NOT NULL,&#13;
    address text NOT NULL,&#13;
    city text NOT NULL,&#13;
    zip text NOT NULL,&#13;
<var>    --snip--</var>&#13;
    longitude numeric(10,7) NOT NULL,&#13;
    latitude numeric(10,7) NOT NULL&#13;
);&#13;
&#13;
<span class="CodeAnnotationHang" aria-label="annotation2">2</span> COPY pls_fy2018_libraries&#13;
FROM '<var>C:\YourDirectory\</var>pls_fy2018_libraries.csv'&#13;
WITH (FORMAT CSV, HEADER);&#13;
&#13;
<span class="CodeAnnotationHang" aria-label="annotation3">3</span> CREATE INDEX libname_2018_idx ON pls_fy2018_libraries (libname);</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-1">Listing 9-1</a>: Creating and filling the 2018 Public Libraries Survey table</p>&#13;
<p>After finding the code and data file for <a href="#listing9-1">Listing 9-1</a>, connect to your <code>analysis</code> database in pgAdmin and run it. Make sure you remember to change <var>C:\YourDirectory\</var> to the path where you saved the <em>pls_fy2018_libraries.csv</em> file.</p>&#13;
<p>First, the code makes the table via <code>CREATE TABLE</code>. We assign a primary key constraint to the column named <code>fscskey</code> <span class="CodeAnnotation" aria-label="annotation1">1</span>, a unique code the data dictionary says is assigned to each library. Because it’s unique, present in each row, and unlikely to change, it can serve as a natural primary key.</p>&#13;
<p>The definition for each column includes the appropriate data type and <code>NOT NULL</code> constraints where the columns have no missing values. The <code>startdate</code> and <code>enddate</code> columns contain dates, but we’ve set their data type to <code>text</code> in the code; in the CSV file, those columns include nondate values, and our import will fail if we try to use a <code>date</code> data type. In <span class="xref" itemid="xref_target_Chapter 10">Chapter 10</span>, you’ll learn how to clean up cases like these. For now, those columns are fine as is.</p>&#13;
<p>After creating the table, the <code>COPY</code> statement <span class="CodeAnnotation" aria-label="annotation2">2</span> imports the data from a CSV file named <em>pls_fy2018_libraries.csv</em> using the file path you provide. We add an index <span class="CodeAnnotation" aria-label="annotation3">3</span> to the <code>libname</code> column to provide faster results when we search for a particular library.</p>&#13;
<h3 id="h2-501065c09-0002">Creating the 2017 and 2016 Library Data Tables</h3>&#13;
<p class="BodyFirst">Creating the tables for the 2017 and 2016 library surveys follows similar steps. I’ve combined the code to create and fill both tables in <a href="#listing9-2" id="listinganchor9-2">Listing 9-2</a>. Note again that the listing shown is truncated, but the full code is in the book’s resources at <a href="https://nostarch.com/practical-sql-2nd-edition/" class="LinkURL">https://nostarch.com/practical-sql-2nd-edition/</a>.</p>&#13;
<p>Update the file paths in the <code>COPY</code> statements for both imports and execute the code.</p>&#13;
<pre><code>CREATE TABLE pls_fy2017_libraries (&#13;
    stabr text NOT NULL,&#13;
    <span class="CodeAnnotationHang" aria-label="annotation1">1</span> fscskey text CONSTRAINT fscskey_17_pkey PRIMARY KEY,&#13;
<span epub:type="pagebreak" title="142" id="Page_142"/>    libid text NOT NULL,&#13;
    libname text NOT NULL,&#13;
    address text NOT NULL,&#13;
    city text NOT NULL,&#13;
    zip text NOT NULL,&#13;
<var>    --snip--</var>&#13;
    longitude numeric(10,7) NOT NULL,&#13;
    latitude numeric(10,7) NOT NULL&#13;
);&#13;
&#13;
CREATE TABLE pls_fy2016_libraries (&#13;
    stabr text NOT NULL,&#13;
    fscskey text CONSTRAINT fscskey_16_pkey PRIMARY KEY,&#13;
    libid text NOT NULL,&#13;
    libname text NOT NULL,&#13;
    address text NOT NULL,&#13;
    city text NOT NULL,&#13;
    zip text NOT NULL,&#13;
<var>    --snip--</var>&#13;
    longitude numeric(10,7) NOT NULL,&#13;
    latitude numeric(10,7) NOT NULL&#13;
);&#13;
&#13;
<span class="CodeAnnotationHang" aria-label="annotation2">2</span> COPY pls_fy2017_libraries&#13;
FROM '<em>C:\YourDirectory\</em>pls_fy2017_libraries.csv'&#13;
WITH (FORMAT CSV, HEADER);&#13;
&#13;
COPY pls_fy2016_libraries&#13;
FROM '<em>C:\YourDirectory\</em>pls_fy2016_libraries.csv'&#13;
WITH (FORMAT CSV, HEADER);&#13;
&#13;
<span class="CodeAnnotationHang" aria-label="annotation3">3</span> CREATE INDEX libname_2017_idx ON pls_fy2017_libraries (libname);&#13;
CREATE INDEX libname_2016_idx ON pls_fy2016_libraries (libname);</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-2">Listing 9-2</a>: Creating and filling the 2017 and 2016 Public Libraries Survey tables</p>&#13;
<p>We start by creating the two tables, and in both we again use <code>fscskey</code> <span class="CodeAnnotation" aria-label="annotation1">1</span> as the primary key. Next, we run <code>COPY</code> commands <span class="CodeAnnotation" aria-label="annotation2">2</span> to import the CSV files to the tables, and, finally, we create an index on the <code>libname</code> column <span class="CodeAnnotation" aria-label="annotation3">3</span> in both tables.</p>&#13;
<p>As you review the code, you’ll notice that the three tables have an identical structure. Most ongoing surveys will have a handful of year-to-year changes because the makers of the survey either think of new questions or modify existing ones, but the columns I’ve selected for these three tables are consistent. The documentation for the survey years is at <a href="https://www.imls.gov/research-evaluation/data-collection/public-libraries-survey/" class="LinkURL">https://www.imls.gov/research-evaluation/data-collection/public-libraries-survey/</a>. Now, let’s mine this data to discover its story.</p>&#13;
<h2 id="h1-501065c09-0002">Exploring the Library Data Using Aggregate Functions</h2>&#13;
<p class="BodyFirst">Aggregate functions combine values from multiple rows, perform an operation on those values, and return a single result. For example, you might <span epub:type="pagebreak" title="143" id="Page_143"/>return the average of values with the <code>avg()</code> aggregate function, as you learned in <span class="xref" itemid="xref_target_Chapter 6">Chapter 6</span>. Some aggregate functions are part of the SQL standard, and others are specific to PostgreSQL and other database managers. Most of the aggregate functions used in this chapter are part of standard SQL (a full list of PostgreSQL aggregates is at <a href="https://www.postgresql.org/docs/current/functions-aggregate.html" class="LinkURL">https://www.postgresql.org/docs/current/functions-aggregate.html</a>).</p>&#13;
<p>In this section, we’ll work through the library data using aggregates on single and multiple columns and then explore how you can expand their use by grouping the results they return with values from additional columns.</p>&#13;
<h3 id="h2-501065c09-0003">Counting Rows and Values Using count()</h3>&#13;
<p class="BodyFirst">After importing a dataset, a sensible first step is to make sure the table has the expected number of rows. The IMLS documentation says the file we imported for the 2018 data has 9,261 rows; 2017 has 9,245; and 2016 has 9,252. The difference likely reflects library openings, closings, or mergers. When we count the number of rows in those tables, the results should match those counts.</p>&#13;
<p>The <code>count()</code> aggregate function, which is part of the ANSI SQL standard, makes it easy to check the number of rows and perform other counting tasks. If we supply an asterisk as an input, such as <code>count(*)</code>, the asterisk acts as a wildcard, so the function returns the number of table rows regardless of whether they include <code>NULL</code> values. We do this in all three statements in <a href="#listing9-3" id="listinganchor9-3">Listing 9-3</a>.</p>&#13;
<pre><code>SELECT count(*)&#13;
FROM pls_fy2018_libraries;&#13;
&#13;
SELECT count(*)&#13;
FROM pls_fy2017_libraries;&#13;
&#13;
SELECT count(*)&#13;
FROM pls_fy2016_libraries;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-3">Listing 9-3</a>: Using <code>count(</code><code>)</code> for table row counts</p>&#13;
<p>Run each of the commands in <a href="#listing9-3">Listing 9-3</a> one at a time to see the table row counts. For <code>pls_fy2018_libraries</code>, the result should be as follows:</p>&#13;
<pre><code>count&#13;
-----&#13;
 9261</code></pre>&#13;
<p>For <code>pls_fy2017_libraries</code>, you should see the following:</p>&#13;
<pre><code>count&#13;
-----&#13;
 9245</code></pre>&#13;
<p><span epub:type="pagebreak" title="144" id="Page_144"/>Finally, the result for <code>pls_fy2016_libraries</code> should be this:</p>&#13;
<pre><code>count&#13;
-----&#13;
 9252</code></pre>&#13;
<p>All three results match the number of rows we expected. This is a good first step because it will alert us to issues such as missing rows or a case where we might have imported the wrong file.</p>&#13;
<aside epub:type="sidebar">&#13;
<div class="top hr"><hr/></div>&#13;
<section class="note">&#13;
<h2><span class="NoteHead">Note</span></h2>&#13;
<p>	You can also check the row count using the pgAdmin interface, but it’s clunky. Right-clicking the table name in pgAdmin’s object browser and selecting <b>View/Edit Data</b><span class="MenuArrow">▶</span><b>All Rows</b> executes a SQL query for all rows. Then, a pop-up message in the results pane shows the row count, but it disappears after a few seconds.</p>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<h4 id="h3-501065c09-0001">Counting Values Present in a Column</h4>&#13;
<p class="BodyFirst">If we supply a column name instead of an asterisk to <code>count()</code>, it will return the number of rows that are not <code>NULL</code>. For example, we can count the number of non-<code>NULL</code> values in the <code>phone</code> column of the <code>pls_fy2018_libraries</code> table using <code>count()</code> as in <a href="#listing9-4" id="listinganchor9-4">Listing 9-4</a>.</p>&#13;
<pre><code>SELECT count(phone)&#13;
FROM pls_fy2018_libraries;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-4">Listing 9-4</a>: Using <code>count(</code><code>)</code> for the number of values in a column</p>&#13;
<p>The result shows 9,261 rows have a value in <code>phone</code>, the same as the total rows we found earlier.</p>&#13;
<pre><code>count&#13;
-----&#13;
 9261</code></pre>&#13;
<p>This means every row in the <code>phone</code> column has a value. You may have suspected this already, given that the column has a <code>NOT NULL</code> constraint in the <code>CREATE TABLE</code> statement. But running this check is worthwhile because the absence of values might influence your decision on whether to proceed with analysis at all. To fully vet the data, checking with topical experts and digging deeper into the data is usually a good idea; I recommend seeking expert advice as part of a broader analysis methodology (for more on this topic, see <span class="xref" itemid="xref_target_Chapter 20">Chapter 20</span>).</p>&#13;
<h4 id="h3-501065c09-0002">Counting Distinct Values in a Column</h4>&#13;
<p class="BodyFirst">In <span class="xref" itemid="xref_target_Chapter 3">Chapter 3</span>, I covered the <code>DISTINCT</code> keyword—part of the SQL standard—which with <code>SELECT</code> returns a list of unique values. We can use it to see unique values in a single column, or we can see unique combinations of values from multiple columns. We also can add <code>DISTINCT</code> to the <code>count()</code> function to return a count of distinct values from a column.</p>&#13;
<p><span epub:type="pagebreak" title="145" id="Page_145"/><a href="#listing9-5" id="listinganchor9-5">Listing 9-5</a> shows two queries. The first counts all values in the 2018 table’s <code>libname</code> column. The second does the same but includes <code>DISTINCT</code> in front of the column name. Run them both, one at a time.</p>&#13;
<pre><code>SELECT count(libname)&#13;
FROM pls_fy2018_libraries;&#13;
&#13;
SELECT count(DISTINCT libname)&#13;
FROM pls_fy2018_libraries;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-5">Listing 9-5</a>: Using <code>count(</code><code>)</code> for the number of distinct values in a column</p>&#13;
<p>The first query returns a row count that matches the number of rows in the table that we found using <a href="#listing9-3">Listing 9-3</a>:</p>&#13;
<pre><code>count&#13;
-----&#13;
 9261</code></pre>&#13;
<p>That’s good. We expect to have the library agency name listed in every row. But the second query returns a smaller number:</p>&#13;
<pre><code>count&#13;
-----&#13;
 8478</code></pre>&#13;
<p>Using <code>DISTINCT</code> to remove duplicates reduces the number of library names to the 8,478 that are unique. Closer inspection of the data shows that 526 library agencies in the 2018 survey shared their name with one or more other agencies. Ten library agencies are named <code>OXFORD PUBLIC LIBRARY</code>, each one in a city or town named Oxford in different states, including Alabama, Connecticut, Kansas, and Pennsylvania, among others. We’ll write a query to see combinations of distinct values in the “Aggregating Data Using GROUP BY” section.</p>&#13;
<h3 id="h2-501065c09-0004">Finding Maximum and Minimum Values Using max() and min()</h3>&#13;
<p class="BodyFirst">The <code>max()</code> and <code>min()</code> functions give us the largest and smallest values in a column and are useful for a couple of reasons. First, they help us get a sense of the scope of the values reported. Second, the functions can reveal unexpected issues with data, as you’ll see now.</p>&#13;
<p>Both <code>max()</code> and <code>min()</code> work the same way, with the name of a column as input. <a href="#listing9-6" id="listinganchor9-6">Listing 9-6</a> uses <code>max()</code> and <code>min()</code> on the 2018 table, taking the <code>visits</code> column that records the number of annual visits to the library agency and all of its branches. Run the code.</p>&#13;
<pre><code>SELECT max(visits), min(visits)&#13;
FROM pls_fy2018_libraries;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-6">Listing 9-6</a>: Finding the most and fewest visits using <code>max(</code><code>)</code> and <code>min()</code></p>&#13;
<p><span epub:type="pagebreak" title="146" id="Page_146"/>The query returns the following results:</p>&#13;
<pre><code>max         min&#13;
--------    ---&#13;
16686945     -3</code></pre>&#13;
<p>Well, that’s interesting. The maximum value of more than 16.6 million is reasonable for a large city library system, but <code>-3</code> as the minimum? On the surface, that result seems like a mistake, but it turns out that the creators of the library survey are employing a common but potentially problematic convention in data collection by placing a negative number or some artificially high value in a column to indicate some condition.</p>&#13;
<p>In this case, negative values in number columns indicate the following:</p>&#13;
<ol class="none">&#13;
<li>A value of <code>-1</code> indicates a “nonresponse” to that question.</li>&#13;
<li>A value of <code>-3</code> indicates “not applicable” and is used when a library agency has closed either temporarily or permanently.</li>&#13;
</ol>&#13;
<p>We’ll need to account for and exclude negative values as we explore the data, because summing a column and including the negative values will result in an incorrect total. We can do this using a <code>WHERE</code> clause to filter them. It’s a good reminder to always read the documentation for the data to get ahead of the issue instead of having to backtrack after spending a lot of time on deeper analysis!</p>&#13;
<aside epub:type="sidebar">&#13;
<div class="top hr"><hr/></div>&#13;
<section class="note">&#13;
<h2><span class="NoteHead">Note</span></h2>&#13;
<p>	A better alternative for this negative value scenario is to use <code>NULL</code> in rows in the <code>visits</code> column where response data is absent and then create a separate <code>visits_flag</code> column to hold codes explaining why.</p>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<h3 id="h2-501065c09-0005">Aggregating Data Using GROUP BY</h3>&#13;
<p class="BodyFirst">When you use the <code>GROUP BY</code> clause with aggregate functions, you can group results according to the values in one or more columns. This allows us to perform operations such as <code>sum()</code> or <code>count()</code> for every state in the table or for every type of library agency.</p>&#13;
<p>Let’s explore how using <code>GROUP BY</code> with aggregate functions works. On its own, <code>GROUP BY</code>, which is also part of standard ANSI SQL, eliminates duplicate values from the results, similar to <code>DISTINCT</code>. <a href="#listing9-7" id="listinganchor9-7">Listing 9-7</a> shows the <code>GROUP BY</code> clause in action.</p>&#13;
<pre><code>SELECT stabr&#13;
FROM pls_fy2018_libraries&#13;
<span class="CodeAnnotationHang" aria-label="annotation1">1</span> GROUP BY stabr&#13;
ORDER BY stabr;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-7">Listing 9-7</a>: Using <code>GROUP BY</code> on the <code>stabr</code> column</p>&#13;
<p>We add the <code>GROUP BY</code> clause <span class="CodeAnnotation" aria-label="annotation1">1</span> after the <code>FROM</code> clause and include the column name to group. In this case, we’re selecting <code>stabr</code>, which contains the state abbreviation, and grouping by that same column. We then use <code>ORDER BY</code> <code/><span epub:type="pagebreak" title="147" id="Page_147"/>stabr as well so that the grouped results are in alphabetical order. This will yield a result with unique state abbreviations from the 2018 table. Here’s a portion of the results:</p>&#13;
<pre><code>stabr&#13;
-----&#13;
AK&#13;
AL&#13;
AR&#13;
AS&#13;
AZ&#13;
CA&#13;
<var>--snip--</var>&#13;
WV&#13;
WY</code></pre>&#13;
<p>Notice that there are no duplicates in the 55 rows returned. These standard two-letter postal abbreviations include the 50 states plus Washington, DC, and several US territories, such as Guam and the US Virgin Islands.</p>&#13;
<p>You’re not limited to grouping just one column. In <a href="#listing9-8" id="listinganchor9-8">Listing 9-8</a>, we use the <code>GROUP BY</code> clause on the 2018 data to specify the <code>city</code> and <code>stabr</code> columns for grouping.</p>&#13;
<pre><code>SELECT city, stabr&#13;
FROM pls_fy2018_libraries&#13;
GROUP BY city, stabr&#13;
ORDER BY city, stabr;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-8">Listing 9-8</a>: Using <code>GROUP BY</code> on the <code>city</code> and <code>stabr</code> columns</p>&#13;
<p>The results get sorted by city and then by state, and the output shows unique combinations in that order:</p>&#13;
<pre><code>city          stabr&#13;
----------    -----&#13;
ABBEVILLE     AL&#13;
ABBEVILLE     LA&#13;
ABBEVILLE     SC&#13;
ABBOTSFORD    WI&#13;
ABERDEEN      ID&#13;
ABERDEEN      SD&#13;
ABERNATHY     TX&#13;
<var>--snip--</var></code></pre>&#13;
<p>This grouping returns 9,013 rows, 248 fewer than the total table rows. The result indicates that the file includes multiple instances where there’s more than one library agency for a particular city and state combination.</p>&#13;
<h4 id="h3-501065c09-0003">Combining GROUP BY with count()</h4>&#13;
<p class="BodyFirst">If we combine <code>GROUP BY</code> with an aggregate function, such as <code>count()</code>, we can pull more descriptive information from our data. For example, we know 9,261 library agencies are in the 2018 table. We can get a count of agencies <span epub:type="pagebreak" title="148" id="Page_148"/>by state and sort them to see which states have the most. <a href="#listing9-9" id="listinganchor9-9">Listing 9-9</a> shows how to do this.</p>&#13;
<pre><code><span class="CodeAnnotationHang" aria-label="annotation1">1</span> SELECT stabr, count(*)&#13;
FROM pls_fy2018_libraries&#13;
<span class="CodeAnnotationHang" aria-label="annotation2">2</span> GROUP BY stabr&#13;
<span class="CodeAnnotationHang" aria-label="annotation3">3</span> ORDER BY count(*) DESC;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-9">Listing 9-9</a>: Using <code>GROUP BY</code> with <code>count(</code><code>)</code> on the <code>stabr</code> column</p>&#13;
<p>We’re now asking for the values in the <code>stabr</code> column and a count of how many rows have a given <code>stabr</code> value. In the list of columns to query <span class="CodeAnnotation" aria-label="annotation1">1</span>, we specify <code>stabr</code> and <code>count()</code> with an asterisk as its input, which will cause <code>count()</code> to include <code>NULL</code> values. Also, when we select individual columns along with an aggregate function, we must include the columns in a <code>GROUP BY</code> clause <span class="CodeAnnotation" aria-label="annotation2">2</span>. If we don’t, the database will return an error telling us to do so, because you can’t group values by aggregating and have ungrouped column values in the same query.</p>&#13;
<p>To sort the results and have the state with the largest number of agencies at the top, we can use an <code>ORDER BY</code> clause <span class="CodeAnnotation" aria-label="annotation3">3</span> that includes the <code>count()</code> function and the <code>DESC</code> keyword.</p>&#13;
<p>Run the code in <a href="#listing9-9">Listing 9-9</a>. The results show New York, Illinois, and Texas as the states with the greatest number of library agencies in 2018:</p>&#13;
<pre><code>stabr    count&#13;
-----    -----&#13;
NY         756&#13;
IL         623&#13;
TX         560&#13;
IA         544&#13;
PA         451&#13;
MI         398&#13;
WI         381&#13;
MA         369&#13;
<var>--snip--</var></code></pre>&#13;
<p>Remember that our table represents library agencies that serve a locality. Just because New York, Illinois, and Texas have the greatest number of library agencies doesn’t mean they have the greatest number of outlets where you can walk in and peruse the shelves. An agency might have one central library only, or it might have no central libraries but 23 branches spread around a county. To count outlets, each row in the table also has values in the columns <code>centlib</code> and <code>branlib</code>, which record the number of central and branch libraries, respectively. To find totals, we would use the <code>sum()</code> aggregate function on both columns.</p>&#13;
<h4 id="h3-501065c09-0004">Using GROUP BY on Multiple Columns with count()</h4>&#13;
<p class="BodyFirst">We can glean yet more information from our data by combining <code>GROUP BY</code> with <code>count()</code> and multiple columns. For example, the <code>stataddr</code> column in <span epub:type="pagebreak" title="149" id="Page_149"/>all three tables contains a code indicating whether the agency’s address changed in the last year. The values in <code>stataddr</code> are as follows:</p>&#13;
<ol class="none">&#13;
<li><span class="RunInHead">00</span>  No change from last year</li>&#13;
<li><span class="RunInHead">07</span>  Moved to a new location</li>&#13;
<li><span class="RunInHead">15</span>  Minor address change</li>&#13;
</ol>&#13;
<p><a href="#listing9-10" id="listinganchor9-10">Listing 9-10</a> shows the code for counting the number of agencies in each state that moved, had a minor address change, or had no change using <code>GROUP BY</code> with <code>stabr</code> and <code>stataddr</code> and adding <code>count()</code>.</p>&#13;
<pre><code><span class="CodeAnnotationHang" aria-label="annotation1">1</span> SELECT stabr, stataddr, count(*)&#13;
FROM pls_fy2018_libraries&#13;
<span class="CodeAnnotationHang" aria-label="annotation2">2</span> GROUP BY stabr, stataddr&#13;
<span class="CodeAnnotationHang" aria-label="annotation3">3</span> ORDER BY stabr, stataddr;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-10">Listing 9-10</a>: Using <code>GROUP BY</code> with <code>count(</code><code>)</code> of the <code>stabr</code> and <code>stataddr</code> columns</p>&#13;
<p>The key sections of the query are the column names and the <code>count()</code> function after <code>SELECT</code> <span class="CodeAnnotation" aria-label="annotation1">1</span>, and making sure both columns are reflected in the <code>GROUP BY</code> clause <span class="CodeAnnotation" aria-label="annotation2">2</span> to ensure that <code>count()</code> will show the number of unique combinations of <code>stabr</code> and <code>stataddr</code>.</p>&#13;
<p>To make the output easier to read, let’s sort first by the state and address status codes in ascending order <span class="CodeAnnotation" aria-label="annotation3">3</span>. Here are the results:</p>&#13;
<pre><code>stabr    stataddr    count&#13;
-----    --------    -----&#13;
AK       00          82&#13;
AL       00         220&#13;
AL       07           3&#13;
AL       15           1&#13;
AR       00          58&#13;
AR       07           1&#13;
AR       15           1&#13;
AS       00           1&#13;
<var>--snip--</var></code></pre>&#13;
<p>The first few rows show that code <code>00</code> (no change in address) is the most common value for each state. We’d expect that because it’s likely there are more library agencies that haven’t changed address than those that have. The result helps assure us that we’re analyzing the data in a sound way. If code <code>07</code> (moved to a new location) was the most frequent in each state, that would raise a question about whether we’ve written the query correctly or whether there’s an issue with the data.</p>&#13;
<h4 id="h3-501065c09-0005">Revisiting sum() to Examine Library Activity</h4>&#13;
<p class="BodyFirst">Now let’s expand our techniques to include grouping and aggregating across joined tables using the 2018, 2017, and 2016 libraries data. Our goal is to identify trends in library visits spanning that three-year period. To do this, we need to calculate totals using the <code>sum()</code> aggregate function.</p>&#13;
<p><span epub:type="pagebreak" title="150" id="Page_150"/>Before we dig into these queries, let’s address the values <code>-3</code> and <code>-1</code>, which indicate “not applicable” and “nonresponse.” To prevent these negative numbers from affecting the analysis, we’ll filter them out using a <code>WHERE</code> clause to limit the queries to rows where values in <code>visits</code> are zero or greater.</p>&#13;
<p>Let’s start by calculating the sum of annual visits to libraries from the individual tables. Run each <code>SELECT</code> statement in <a href="#listing9-11" id="listinganchor9-11">Listing 9-11</a> separately.</p>&#13;
<pre><code>SELECT sum(visits) AS visits_2018&#13;
FROM pls_fy2018_libraries&#13;
WHERE visits &gt;= 0;&#13;
&#13;
SELECT sum(visits) AS visits_2017&#13;
FROM pls_fy2017_libraries&#13;
WHERE visits &gt;= 0;&#13;
&#13;
SELECT sum(visits) AS visits_2016&#13;
FROM pls_fy2016_libraries&#13;
WHERE visits &gt;= 0;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-11">Listing 9-11</a>: Using the <code>sum(</code><code>)</code> aggregate function to total visits to libraries in 2016, 2017, and 2018</p>&#13;
<p>For 2018, visits totaled approximately 1.29 billion:</p>&#13;
<pre><code>visits_2018&#13;
-----------&#13;
 1292348697</code></pre>&#13;
<p>For 2017, visits totaled approximately 1.32 billion:</p>&#13;
<pre><code>visits_2017&#13;
-----------&#13;
 1319803999</code></pre>&#13;
<p>And for 2016, visits totaled approximately 1.36 billion:</p>&#13;
<pre><code>visits_2016&#13;
-----------&#13;
 1355648987</code></pre>&#13;
<p>We’re onto something here, but it may not be good news for libraries. The trend seems to point downward with visits dropping about 5 percent from 2016 to 2018.</p>&#13;
<p>Let’s refine this approach. These queries sum visits recorded in each table. But from the row counts we ran earlier in the chapter, we know that each table contains a different number of library agencies: 9,261 in 2018; 9,245 in 2017; and 9,252 in 2016. The differences are likely due to agencies opening, closing, or merging. So, let’s determine how the sum of visits will differ if we limit the analysis to library agencies that exist in all three tables and have a non-negative value for <code>visits</code>. We can do that by joining the tables, as shown in <a href="#listing9-12" id="listinganchor9-12">Listing 9-12</a>.</p>&#13;
<pre><code><span epub:type="pagebreak" title="151" id="Page_151"/><span class="CodeAnnotationHang" aria-label="annotation1">1</span> SELECT sum(pls18.visits) AS visits_2018,&#13;
       sum(pls17.visits) AS visits_2017,&#13;
       sum(pls16.visits) AS visits_2016&#13;
<span class="CodeAnnotationHang" aria-label="annotation2">2</span> FROM pls_fy2018_libraries pls18&#13;
       JOIN pls_fy2017_libraries pls17 ON pls18.fscskey = pls17.fscskey&#13;
       JOIN pls_fy2016_libraries pls16 ON pls18.fscskey = pls16.fscskey&#13;
<span class="CodeAnnotationHang" aria-label="annotation3">3</span> WHERE pls18.visits &gt;= 0&#13;
       AND pls17.visits &gt;= 0&#13;
       AND pls16.visits &gt;= 0;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-12">Listing 9-12</a>: Using <code>sum(</code><code>)</code> to total visits on joined 2018, 2017, and 2016 tables</p>&#13;
<p>This query pulls together a few concepts we covered in earlier chapters, including table joins. At the top, we use the <code>sum()</code> aggregate function <span class="CodeAnnotation" aria-label="annotation1">1</span> to total the <code>visits</code> columns from each of the three tables. When we join the tables on the tables’ primary keys, we’re declaring table aliases <span class="CodeAnnotation" aria-label="annotation2">2</span> as we explored in <span class="xref" itemid="xref_target_Chapter 7">Chapter 7</span>—and here, we’re omitting the optional <code>AS</code> keyword in front of each alias. For example, we declare <code>pls18</code> as the alias for the 2018 table to avoid having to write its lengthier full name throughout the query.</p>&#13;
<p>Note that we use a standard <code>JOIN</code>, also known as an <code>INNER JOIN</code>, meaning the query results will only include rows where the values in the <code>fscskey</code> primary key match in all three tables.</p>&#13;
<p>As we did in <a href="#listing9-11">Listing 9-11</a>, we specify with a <code>WHERE</code> clause <span class="CodeAnnotation" aria-label="annotation3">3</span> that the result should include only those rows where <code>visits</code> are greater than or equal to 0 in the tables. This will prevent the artificial negative values from impacting the sums.</p>&#13;
<p>Run the query. The results should look like this:</p>&#13;
<pre><code>visits_2018   visits_2017   visits_2016&#13;
-----------   -----------   -----------&#13;
 1278148838    1319325387    1355078384</code></pre>&#13;
<p>The results are similar to what we found by querying the tables separately, although these totals are as much as 14 million smaller in 2018. Still, the downward trend holds.</p>&#13;
<p>For a full picture of how library use is changing, we’d want to run a similar query on all of the columns that contain performance indicators to chronicle the trend in each. For example, the column <code>wifisess</code> shows how many times users connected to the library’s wireless internet. If we use <code>wifisess</code> instead of <code>visits</code> in <a href="#listing9-11">Listing 9-11</a>, we get this result:</p>&#13;
<pre><code>wifi_2018  wifi_2017  wifi_2016&#13;
---------  ---------  ---------&#13;
349767271  311336231  234926102</code></pre>&#13;
<p>So, though visits were down, libraries saw a sharp increase in Wi-Fi network use. That provides a keen insight into how the role of libraries is changing.</p>&#13;
<aside epub:type="sidebar">&#13;
<div class="top hr"><hr/></div>&#13;
<section class="note">&#13;
<span epub:type="pagebreak" title="152" id="Page_152"/><h2><span class="NoteHead">Note</span></h2>&#13;
<p>	Although we joined the tables on <code>fscskey</code>, it’s entirely possible that some library agencies that appear in all three tables merged or split during the three years. A call to the IMLS asking about caveats for working with this data is a good idea.</p>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<h4 id="h3-501065c09-0006">Grouping Visit Sums by State</h4>&#13;
<p class="BodyFirst">Now that we know library visits dropped for the United States as a whole between 2016 and 2018, you might ask yourself, “Did every part of the country see a decrease, or did the degree of the trend vary by region?” We can answer this question by modifying our preceding query to group by the state code. Let’s also use a percent-change calculation to compare the trend by state. <a href="#listing9-13" id="listinganchor9-13">Listing 9-13</a> contains the full code.</p>&#13;
<pre><code><span class="CodeAnnotationHang" aria-label="annotation1">1</span> SELECT pls18.stabr,&#13;
       sum(pls18.visits) AS visits_2018,&#13;
       sum(pls17.visits) AS visits_2017,&#13;
       sum(pls16.visits) AS visits_2016,&#13;
       round( (sum(pls18.visits::numeric) - sum(pls17.visits)) /&#13;
            <span class="CodeAnnotationHang" aria-label="annotation2">2</span> sum(pls17.visits) * 100, 1 ) AS chg_2018_17,&#13;
       round( (sum(pls17.visits::numeric) - sum(pls16.visits)) /&#13;
            sum(pls16.visits) * 100, 1 ) AS chg_2017_16&#13;
FROM pls_fy2018_libraries pls18&#13;
       JOIN pls_fy2017_libraries pls17 ON pls18.fscskey = pls17.fscskey&#13;
       JOIN pls_fy2016_libraries pls16 ON pls18.fscskey = pls16.fscskey&#13;
WHERE pls18.visits &gt;= 0&#13;
       AND pls17.visits &gt;= 0&#13;
       AND pls16.visits &gt;= 0&#13;
<span class="CodeAnnotationHang" aria-label="annotation3">3</span> GROUP BY pls18.stabr&#13;
<span class="CodeAnnotationHang" aria-label="annotation4">4</span> ORDER BY chg_2018_17 DESC;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-13">Listing 9-13</a>: Using <code>GROUP BY</code> to track percent change in library visits by state</p>&#13;
<p>We follow the <code>SELECT</code> keyword with the <code>stabr</code> column <span class="CodeAnnotation" aria-label="annotation1">1</span> from the 2018 table; that same column appears in the <code>GROUP BY</code> clause <span class="CodeAnnotation" aria-label="annotation3">3</span>. It doesn’t matter which table’s <code>stabr</code> column we use because we’re only querying agencies that appear in all three tables. After the <code>visits</code> columns, we include the now-familiar percent-change calculation you learned in <span class="xref" itemid="xref_target_Chapter 6">Chapter 6</span>. We use this twice, giving the aliases <code>chg_2018_17</code> <span class="CodeAnnotation" aria-label="annotation2">2</span> and <code>chg_2017_16</code> for clarity. We end the query with an <code>ORDER BY</code> clause <span class="CodeAnnotation" aria-label="annotation4">4</span>, sorting by the <code>chg_2018_17</code> column alias.</p>&#13;
<p>When you run the query, the top of the results shows 10 states with an increase in visits from 2017 to 2018. The rest of the results show a decline. American Samoa, at the bottom of the ranking, had a 28 percent drop!</p>&#13;
<pre><code>stabr visits_2018 visits_2017 visits_2016 chg_2018_17 chg_2017_16&#13;
----- ----------- ----------- ----------- ----------- -----------&#13;
SD        3824804     3699212     3722376         3.4        -0.6&#13;
MT        4332900     4215484     4298268         2.8        -1.9&#13;
FL       68423689    66697122    70991029         2.6        -6.0&#13;
ND        2216377     2162189     2201730         2.5        -1.8&#13;
ID        8179077     8029503     8597955         1.9        -6.6&#13;
DC        3632539     3593201     3930763         1.1        -8.6&#13;
ME        6746380     6731768     6811441         0.2        -1.2&#13;
<span epub:type="pagebreak" title="153" id="Page_153"/>NH        7045010     7028800     7236567         0.2        -2.9&#13;
UT       15326963    15295494    16096911         0.2        -5.0&#13;
DE        4122181     4117904     4125899         0.1        -0.2&#13;
OK       13399265    13491194    13112511        -0.7         2.9&#13;
WY        3338772     3367413     3536788        -0.9        -4.8&#13;
MA       39926583    40453003    40427356        -1.3         0.1&#13;
WA       37338635    37916034    38634499        -1.5        -1.9&#13;
MN       22952388    23326303    24033731        -1.6        -2.9&#13;
<var>--snip--</var>&#13;
GA       26835701    28816233    27987249        -6.9         3.0&#13;
AR        9551686    10358181    10596035        -7.8        -2.2&#13;
GU          75119       81572       71813        -7.9        13.6&#13;
MS        7602710     8581994     8915406       -11.4        -3.7&#13;
HI        3456131     4135229     4490320       -16.4        -7.9&#13;
AS          48828       67848       63166       -28.0         7.4</code></pre>&#13;
<p>It’s helpful, for context, to also see the percent change in <code>visits</code> from 2016 to 2017. Many of the states, such as Minnesota, show consecutive declines. Others, including several at the top of the list, show gains after substantial decreases the year prior.</p>&#13;
<p>This is when it’s a good idea investigate what’s driving the changes. Data analysis can sometimes raise as many questions as it answers, but that’s part of the process. It’s always worth a phone call to a person who works closely with the data to review your findings. Sometimes, they’ll have a good explanation. Other times, an expert will say, “That doesn’t sound right.” That answer might send you back to the keeper of the data or the documentation to find out if you overlooked a code or a nuance with the data.</p>&#13;
<h4 id="h3-501065c09-0007">Filtering an Aggregate Query Using HAVING</h4>&#13;
<p class="BodyFirst">To refine our analysis, we can examine a subset of states and territories that share similar characteristics. With percent change in visits, it makes sense to separate large states from small states. In a small state like Rhode Island, a single library closing for six months for repairs could have a significant effect. A single closure in California might be scarcely noticed in a statewide count. To look at states with a similar volume in visits, we could sort the results by either of the <code>visits</code> columns, but it would be cleaner to get a smaller result set by filtering our query.</p>&#13;
<p>To filter the results of aggregate functions, we need to use the <code>HAVING</code> clause that’s part of standard ANSI SQL. You’re already familiar with using <code>WHERE</code> for filtering, but aggregate functions, such as <code>sum()</code>, can’t be used within a <code>WHERE</code> clause because they operate at the row level, and aggregate functions work across rows. The <code>HAVING</code> clause places conditions on groups created by aggregating. The code in <a href="#listing9-14" id="listinganchor9-14">Listing 9-14</a> modifies the query in <a href="#listing9-13">Listing 9-13</a> by inserting the <code>HAVING</code> clause after <code>GROUP BY</code>.</p>&#13;
<pre><code>SELECT pls18.stabr,&#13;
       sum(pls18.visits) AS visits_2018,&#13;
       sum(pls17.visits) AS visits_2017,&#13;
       sum(pls16.visits) AS visits_2016,&#13;
       round( (sum(pls18.visits::numeric) - sum(pls17.visits)) /&#13;
<span epub:type="pagebreak" title="154" id="Page_154"/>            sum(pls17.visits) * 100, 1 ) AS chg_2018_17,&#13;
       round( (sum(pls17.visits::numeric) - sum(pls16.visits)) /&#13;
            sum(pls16.visits) * 100, 1 ) AS chg_2017_16&#13;
FROM pls_fy2018_libraries pls18&#13;
       JOIN pls_fy2017_libraries pls17 ON pls18.fscskey = pls17.fscskey&#13;
       JOIN pls_fy2016_libraries pls16 ON pls18.fscskey = pls16.fscskey&#13;
WHERE pls18.visits &gt;= 0&#13;
       AND pls17.visits &gt;= 0&#13;
       AND pls16.visits &gt;= 0&#13;
GROUP BY pls18.stabr&#13;
<span class="CodeAnnotationHang" aria-label="annotation1">1</span> HAVING sum(pls18.visits) &gt; 50000000&#13;
ORDER BY chg_2018_17 DESC;</code></pre>&#13;
<p class="CodeListingCaption"><a id="listing9-14">Listing 9-14</a>: Using a <code>HAVING</code> clause to filter the results of an aggregate query</p>&#13;
<p>In this case, we’ve set our query results to include only rows with a sum of visits in 2018 greater than 50 million. That’s an arbitrary value I chose to show only the very largest states. Adding the <code>HAVING</code> clause <span class="CodeAnnotation" aria-label="annotation1">1</span> reduces the number of rows in the output to just six. In practice, you might experiment with various values. Here are the results:</p>&#13;
<pre><code>stabr visits_2018 visits_2017 visits_2016 chg_2018_17 chg_2017_16&#13;
----- ----------- ----------- ----------- ----------- -----------&#13;
FL       68423689    66697122    70991029         2.6        -6.0&#13;
NY       97921323   100012193   103081304        -2.1        -3.0&#13;
CA      146656984   151056672   155613529        -2.9        -2.9&#13;
IL       63466887    66166082    67336230        -4.1        -1.7&#13;
OH       68176967    71895854    74119719        -5.2        -3.0&#13;
TX       66168387    70514138    70975901        -6.2        -0.7</code></pre>&#13;
<p>All but one of the six states experienced a decline in visits, but notice that the percent-change variation isn’t as wide as in the full set of states and territories. Depending on what we learn from library experts, looking at the states with the most activity as a group might be helpful in describing trends, as would looking at other groupings. Think of a sentence you might write that would say, “Among states with the most library visits, Florida was the only one to see an increase in activity between 2017 and 2018; the rest saw visits decrease between 2 percent and 6 percent.” You could write similar sentences about medium-sized states and small states.</p>&#13;
<h2 id="h1-501065c09-0003">Wrapping Up</h2>&#13;
<p class="BodyFirst">If you’re now inspired to visit your local library and check out a couple of books, ask a librarian whether their branch has seen a rise or drop in visits over the last few years. You can probably guess the answer. In this chapter, you learned how to use standard SQL techniques to summarize data in a table by grouping values and using a handful of aggregate functions. By joining datasets, you were able to identify some interesting trends.</p>&#13;
<p>You also learned that data doesn’t always come perfectly packaged. The presence of negative values in columns, used as an indicator rather than as an actual numeric value, forced us to filter out those rows. Unfortunately, <span epub:type="pagebreak" title="155" id="Page_155"/>those sorts of challenges are part of the data analyst’s everyday world, so we’ll spend the next chapter learning how to clean up a dataset that has a number of issues. Later in the book, you’ll also discover more aggregate functions to help you find the stories in your data.</p>&#13;
<aside epub:type="sidebar">&#13;
<div class="top hr"><hr/></div>&#13;
<section class="box">&#13;
<h2>try it yourself</h2>&#13;
<p class="BoxBodyFirst">Put your grouping and aggregating skills to the test with these challenges:</p>&#13;
<ol>&#13;
<li value="1">We saw that library visits have declined recently in most places. But what is the pattern in library employment? All three library survey tables contain the column <code>totstaff</code>, which is the number of paid full-time equivalent employees. Modify the code in Listings 9-13 and 9-14 to calculate the percent change in the sum of the column over time, examining all states as well as states with the most visitors. Watch out for negative values!</li>&#13;
<li value="2">The library survey tables contain a column called <code>obereg</code>, a two-digit Bureau of Economic Analysis Code that classifies each library agency according to a region of the United States, such as New England, Rocky Mountains, and so on. Just as we calculated the percent change in visits grouped by state, do the same to group percent changes in visits by US region using <code>obereg</code>. Consult the survey documentation to find the meaning of each region code. For a bonus challenge, create a table with the <code>obereg</code> code as the primary key and the region name as text, and join it to the summary query to group by the region name rather than the code.</li>&#13;
<li value="3">Thinking back to the types of joins you learned in <span class="xref" itemid="xref_target_Chapter 7">Chapter 7</span>, which join type will show you all the rows in all three tables, including those without a match? Write such a query and add an <code>IS NULL</code> filter in a <code>WHERE</code> clause to show agencies not included in one or more of the tables.</li>&#13;
</ol>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
</section>&#13;
</div></body></html>