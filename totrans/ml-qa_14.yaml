- en: '**12'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: FULLY CONNECTED AND CONVOLUTIONAL LAYERS**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Under which circumstances can we replace fully connected layers with convolutional
    layers to perform the same computation?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Replacing fully connected layers with convolutional layers can offer advantages
    in terms of hardware optimization, such as by utilizing specialized hardware accelerators
    for convolution operations. This can be particularly relevant for edge devices.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'There are exactly two scenarios in which fully connected layers and convolutional
    layers are equivalent: when the size of the convolutional filter is equal to the
    size of the receptive field and when the size of the convolutional filter is 1\.
    As an illustration of these two scenarios, consider a fully connected layer with
    two input and four output units, as shown in [Figure 12-1](ch12.xhtml#ch12fig1).'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig01.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-1: Four inputs and two outputs connected via eight weight parameters*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 'The fully connected layer in this figure consists of eight weights and two
    bias units. We can compute the output nodes via the following dot products:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '**Node 1** *w*[1,1] *× x*[1] + *w*[1,2] *× x*[2] + *w*[1,3] *× x*[3] + *w*[1,4]
    *× x*[4] + *b*[1]'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '**Node 2** *w*[2,1] *× x*[1] + *w*[2,2] *× x*[2] + *w*[2,3] *× x*[3] + *w*[2,4]
    *× x*[4] + *b*[2]'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: The following two sections illustrate scenarios in which convolutional layers
    can be defined to produce exactly the same computation as the fully connected
    layer described.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '**When the Kernel and Input Sizes Are Equal**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s start with the first scenario, where the size of the convolutional filter
    is equal to the size of the receptive field. Recall from [Chapter 11](ch11.xhtml)
    how we compute a number of parameters in a convolutional kernel with one input
    channel and multiple output channels. We have a kernel size of 2*×*2, one input
    channel, and two output channels. The input size is also 2*×*2, a reshaped version
    of the four inputs depicted in [Figure 12-2](ch12.xhtml#ch12fig2).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig02.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-2: A convolutional layer with a 2×2 kernel that equals the input
    size and two output channels*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'If the convolutional kernel dimensions equal the input size, as depicted in
    [Figure 12-2](ch12.xhtml#ch12fig2), there is no sliding window mechanism in the
    convolutional layer. For the first output channel, we have the following set of
    weights:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0076-01.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: 'For the second output channel, we have the following set of weights:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0076-02.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: If the inputs are organized as
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0077-01.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
- en: 'we calculate the first output channel as *o*[1] = *∑i*(*W*[1] ***x**)*[i]*
    + *b*[1], where the convolutional operator * is equal to an element-wise multiplication.
    In other words, we perform an element-wise multiplication between two matrices,
    *W*[1] and **x**, and then compute the output as the sum over these elements;
    this equals the dot product in the fully connected layer. Lastly, we add the bias
    unit. The computation for the second output channel works analogously: *o*[2]
    = *∑i*(*W*[2] * **x**)*[i]* + *b*[2].'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算第一个输出通道为 *o*[1] = *∑i*(*W*[1] ***x**)*[i]* + *b*[1]，其中卷积运算符 * 等于逐元素相乘。换句话说，我们在两个矩阵
    *W*[1] 和 **x** 之间执行逐元素相乘，然后将这些元素的和作为输出；这等价于完全连接层中的点积。最后，我们加上偏置单元。第二个输出通道的计算方法类似：*o*[2]
    = *∑i*(*W*[2] * **x**)*[i]* + *b*[2]。
- en: As a bonus, the supplementary materials for this book include PyTorch code to
    show this equivalence with a hands-on example in the *supplementary/q12-fc-cnn-equivalence*
    subfolder at *[https://github.com/rasbt/MachineLearning-QandAI-book](https://github.com/rasbt/MachineLearning-QandAI-book)*.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作为奖励，本书的补充材料包括 PyTorch 代码，展示了这个等效性，并且可以在 *[https://github.com/rasbt/MachineLearning-QandAI-book](https://github.com/rasbt/MachineLearning-QandAI-book)*
    的 *supplementary/q12-fc-cnn-equivalence* 子文件夹中找到一个动手实践示例。
- en: '**When the Kernel Size Is 1**'
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**当卷积核大小为1时**'
- en: The second scenario assumes that we reshape the input into an input “image”
    with 1*×*1 dimensions where the number of “color channels” equals the number of
    input features, as depicted in [Figure 12-3](ch12.xhtml#ch12fig3).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种情况假设我们将输入重塑为一个“图像”，其尺寸为 1*×*1，其中“颜色通道”的数量等于输入特征的数量，如[图12-3](ch12.xhtml#ch12fig3)所示。
- en: '![Image](../images/12fig03.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/12fig03.jpg)'
- en: '*Figure 12-3: The number of output nodes equals the number of channels if the
    kernel size is equal to the input size.*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*图12-3：当卷积核大小等于输入大小时，输出节点的数量等于通道的数量。*'
- en: Each kernel consists of a stack of weights equal to the number of input channels.
    For instance, for the first output layer, the weights are
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 每个卷积核由一个与输入通道数相等的权重堆叠组成。例如，对于第一个输出层，权重为
- en: '![Image](../images/f0077-02.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0077-02.jpg)'
- en: 'while the weights for the second channel are:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，第二个通道的权重为：
- en: '![Image](../images/f0077-03.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0077-03.jpg)'
- en: To get a better intuitive understanding of this computation, check out the illustrations
    in [Chapter 11](ch11.xhtml), which describe how to compute the parameters in a
    convolutional layer.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地直观理解这个计算过程，请查阅[第11章](ch11.xhtml)中的插图，图中描述了如何计算卷积层中的参数。
- en: '**Recommendations**'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**建议**'
- en: The fact that fully connected layers can be implemented as equivalent convolutional
    layers does not have immediate performance or other advantages on standard computers.
    However, replacing fully connected layers with convolutional layers can offer
    advantages in combination with developing specialized hardware accelerators for
    convolution operations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管完全连接层可以作为等效的卷积层来实现，但在标准计算机上这并不会带来即时的性能或其他优势。然而，将完全连接层替换为卷积层，结合为卷积运算开发的专用硬件加速器，可能会带来优势。
- en: Moreover, understanding the scenarios where fully connected layers are equivalent
    to convolutional layers aids in understanding the mechanics of these layers. It
    also lets us implement convolutional neural networks without any use of fully
    connected layers, if desired, to simplify code implementations.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，理解完全连接层与卷积层等效的场景有助于理解这些层的机制。它还使我们能够在不使用完全连接层的情况下实现卷积神经网络（如果需要的话），从而简化代码实现。
- en: '**Exercises**'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**习题**'
- en: '**12-1.** How would increasing the stride affect the equivalence discussed
    in this chapter?'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**12-1.** 增加步幅会如何影响本章讨论的等效性？'
- en: '**12-2.** Does padding affect the equivalence between fully connected layers
    and convolutional layers?'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**12-2.** 填充是否会影响完全连接层与卷积层之间的等效性？'
