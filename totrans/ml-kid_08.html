<html><head></head><body><div id="sbo-rt-content"><section>
<header>
<figure class="opener">
<img src="Images/chapterart.png" alt=""/>
</figure>
<h1 class="chapterTitle">
<span class="ChapterNumber"><span epub:type="pagebreak" title="151" id="Page_151"/>10</span><br/>
<span class="ChapterTitle">Smart Assistants</span>
</h1>
</header>
<p class="ChapterIntro"><span class="OpenerCap"><img src="Images/Alphabet-I.png" alt="Alphabet-I" class="dropcap"/></span>n this chapter, we’ll look at a common household use of ML: smart assistants like Siri, Alexa, or Google Home that can do simple jobs for you when you ask, like set an alarm, start a timer, or play some music. </p>
<p><span epub:type="pagebreak" title="152" id="Page_152"/>Smart assistants are ML systems trained to recognize the meaning of text. You’ve seen that you can train a computer so that when you give it some writing, the computer can recognize what you’re trying to say. And if a computer can understand what you mean, it can understand what you’re asking it to do.</p>
<p>To create a program that categorizes text based on recognizing the text’s intention (<em>intent classification</em>), we collect a large number of examples of each type of command that we want it to recognize and then use ML to train a model. </p>
<p>From the projects you’ve done so far, you’re already familiar with the <em>classification</em><em/> part of intent classification. For example, messages can be classified as compliments or insults, and news­paper headlines can be classified as tabloids or broadsheets. The computer knows about some categories of writing, and when you give it some text, it tries to <em>classify</em> that text, or work out which category that text should go into. The <em>intent</em> part is because we’re using the ability to classify the text to recognize its intention.</p>
<p>Intent classification is useful for building computer systems that we can interact with in a natural way. For example, a computer could recognize that when you say, “Turn on the light,” the intention is for a light to be switched on. This is described as a <em>natural language interface</em><em/>. In other words, instead of needing to press a switch to turn the light on, you’re using <em>natural language</em><em/>—a language that has evolved naturally in humans, not one designed for computers—to communicate that intent. </p>
<p>The computer learns from the patterns in the examples we give it—patterns in the words we choose, the way we phrase commands, how we combine words for certain types of commands, and when we use commands that are short versus longer, just to name a few.</p>
<p>In this chapter, you’ll make a virtual smart assistant that can recognize your commands and carry out your instructions (see <a id="figureanchor10-1" href="#figure10-1">Figure 10-1</a>).</p>
<span epub:type="pagebreak" title="153" id="Page_153"/><figure>
<img src="Images/f10001.png" alt="f10001"/>
<figcaption><p><a id="figure10-1" href="#figureanchor10-1">Figure 10-1:</a> Making a smart assistant in Scratch</p></figcaption>
</figure>
<p>Let’s get started!</p>
<h2 id="h1-500563c10-0001">Build Your Project</h2>
<p class="BodyFirst">To start with, you’ll train the ML model to recognize commands to turn two devices—a fan and a lamp—on or off.</p>
<h3 id="h2-500563c10-0001">Code Your Project Without ML</h3>
<p class="BodyFirst">As we saw in <span class="xref" itemid="xref_target_Chapter 7">Chapter 7</span>, it’s useful to see the difference that ML makes by trying to code an AI project without it first. You can skip this step if you feel you have a good grasp of the difference between a rule-based approach and ML and would rather go straight to using ML.</p>
<ol>
<li value="1">Go to Scratch at <a href="https://machinelearningforkids.co.uk/scratch3/" class="LinkURL">https://machinelearningforkids.co.uk/scratch3/</a>. </li>
<li value="2">Click <b>Project templates</b> at the top of the screen, as shown in <a id="figureanchor10-2" href="#figure10-2">Figure 10-2</a>.
<span epub:type="pagebreak" title="154" id="Page_154"/><figure>
<img src="Images/f10002.png" alt="f10002"/>
<figcaption><p><a id="figure10-2" href="#figureanchor10-2">Figure 10-2:</a> Project templates include starter projects to save you time. </p></figcaption>
</figure>
</li>
<li value="3">Click the <b>Smart Classroom</b> template.</li>
<li value="4">Copy the script shown in <a id="figureanchor10-3" href="#figure10-3">Figure 10-3</a>. 
<figure>
<img src="Images/f10003.png" alt="f10003"/>
<figcaption><p><a id="figure10-3" href="#figureanchor10-3">Figure 10-3:</a> Coding a smart assistant using rules </p></figcaption>
</figure>
<p class="ListBody"><span epub:type="pagebreak" title="155" id="Page_155"/>This script asks you to enter a command. If you type <code>Turn</code><code>on</code> (or <code>off</code>) <code>the</code><code>fan</code> (or <code>lamp</code>), Scratch will play the corresponding animation. Let’s try it out.</p></li>
<li value="5">Test your project by clicking the Green Flag. Type the command <code class="bold">Turn on the fan</code> and check that the fan really does start spinning.
<p class="ListBody">What happens if you spell something wrong? What happens if you change the wording (for example, “Turn on the fan please”)? What happens if you don’t mention the word <em>fan</em> (for example, “I’m very hot, we need some air in here!”)?</p>
<p class="ListBody">Why don’t these work?</p>
<p class="ListBody">Do you think it’s possible to write a script that would work with any phrasing of these four commands? </p>
</li>
</ol>
<p>Think back to the definition in <span class="xref" itemid="xref_target_Chapter 1">Chapter 1</span>, where I said ML is not the only way to create AI systems. Here you’ve created an AI project using a rules-based approach instead of ML. By trying other techniques like this one and seeing where they fall short, you can better understand why ML is preferred for so many projects.</p>
<h3 id="h2-500563c10-0002">Train Your Model</h3>
<ol>
<li value="1">Create a new ML project, name it <code class="bold">Smart Classroom</code>, and set it to learn to recognize text in your preferred language. 
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note	</span></h2>
<p>If you’re not sure how to create an ML project, read the section <span class="xref" itemid="xref_target_“Creating a New ML Project” on page 9">“Creating a New ML Project” on page 9</span> in <span class="xref" itemid="xref_target_Chapter 2">Chapter 2</span>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
</li>
<li value="2">Click <b>Train</b>, as shown in <a id="figureanchor10-4" href="#figure10-4">Figure 10-4</a>.
<figure>
<img src="Images/f10004.png" alt="f10004"/>
<figcaption><p><a id="figure10-4" href="#figureanchor10-4">Figure 10-4:</a> The first phase is to collect training examples. </p></figcaption>
</figure>
</li>
<li value="3"><span epub:type="pagebreak" title="156" id="Page_156"/>Click <b>Add new label</b>, as shown in <a id="figureanchor10-5" href="#figure10-5">Figure 10-5</a>, and create a training bucket called <code class="bold">fan on</code>. Repeat this step to create three more training buckets named <code class="bold">fan off</code>, <code class="bold">lamp on</code>, and <code class="bold">lamp off</code>. (The underscores will be added automatically.)
<figure>
<img src="Images/f10005.png" alt="f10005"/>
<figcaption><p><a id="figure10-5" href="#figureanchor10-5">Figure 10-5:</a> Create training buckets for the commands to recognize. </p></figcaption>
</figure>
</li>
<li value="4">Click <b>Add example</b><b/> in the <b>fan_on</b> bucket and type an example of how you would ask someone to turn on the fan, as shown in <a id="figureanchor10-6" href="#figure10-6">Figure 10-6</a>.
<figure>
<img src="Images/f10006.png" alt="f10006"/>
<figcaption><p><a id="figure10-6" href="#figureanchor10-6">Figure 10-6:</a> Collecting examples of how to ask for the fan to be turned on </p></figcaption>
</figure>
<p class="ListBody"><span epub:type="pagebreak" title="157" id="Page_157"/>It can be short (for example, “fan on please”) or long (“Could you turn the fan on for me now, please?”). </p>
<p class="ListBody">It can be polite (“Would you please switch on the fan?”) or less polite (“Turn the fan on now”). </p>
<p class="ListBody">It can include the words <em>fan</em> and <em>on</em> (“Can you turn on the fan?”) or neither (“It’s too hot in here. Can we get some air in here, please?”).</p>
<p class="ListBody">Type as many as you can think of, as shown in <a href="#figure10-6">Figure 10-6</a>. You need at least five examples, but I’ve given you six already, so that should be easy!</p></li>
<li value="5">Click <b>Add example</b> in the <b>fan_off</b> bucket, as shown in <a id="figureanchor10-7" href="#figure10-7">Figure 10-7</a>.
<p class="ListBody">This time, type as many examples as you can think of for asking someone to turn off the fan. You need at least five examples. These are the examples your ML model will use to learn what a “fan off” command looks like.</p>
<p class="ListBody">Try to include some examples that don’t include the words <em>fan</em> or <em>off</em>.</p>
<figure>
<img src="Images/f10007.png" alt="f10007"/>
<figcaption><p><a id="figure10-7" href="#figureanchor10-7">Figure 10-7:</a> Collecting examples of how to ask for the fan to be turned off </p></figcaption>
</figure>
</li>
<li value="6">Repeat this process for the last two buckets, until you have at least five examples for all four commands, as shown in <a id="figureanchor10-8" href="#figure10-8">Figure 10-8</a>.
<span epub:type="pagebreak" title="158" id="Page_158"/><figure>
<img src="Images/f10008.png" alt="f10008"/>
<figcaption><p><a id="figure10-8" href="#figureanchor10-8">Figure 10-8:</a> Training data for the smart assistant project </p></figcaption>
</figure>
</li>
<li value="7">Click <b>Back to project</b> in the top-left corner of the screen.</li>
<li value="8">Click <b>Learn &amp; Test</b>.</li>
<li value="9">Click <b>Train new machine learning model</b>, as shown in <a id="figureanchor10-9" href="#figure10-9">Figure 10-9</a>. 
<p class="ListBody">The computer will use the examples you’ve written to learn how to recognize your four commands. This might take a minute.</p>
<figure>
<img src="Images/f10009.png" alt="f10009"/>
<figcaption><p><a id="figure10-9" href="#figureanchor10-9">Figure 10-9:</a> Train an ML model for your smart assistant.</p></figcaption>
</figure>
</li>
<li value="10">After training an ML model, we test it to see how good it is at recognizing new commands. Type a command into the <b>Test</b> box, as shown in <a id="figureanchor10-10" href="#figure10-10">Figure 10-10</a>.</li>
</ol>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<span epub:type="pagebreak" title="159" id="Page_159"/><h2><span class="NoteHead">Note	</span></h2>
<p>Make sure you test the model with commands that you didn’t include in the training buckets. You’re not interested in whether the computer can remember what you’ve already told it, but in whether it can recognize commands it hasn’t seen before.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<figure>
<img src="Images/f10010.png" alt="f10010"/>
<figcaption><p><a id="figure10-10" href="#figureanchor10-10">Figure 10-10:</a> Testing your ML model </p></figcaption>
</figure>
<p class="ListBody">If the model makes mistakes, you can go back to the Train phase and add more examples of the commands that it keeps getting wrong. This is like a teacher using a student’s poor exam result to figure out which subjects they need to review with the student to help improve the student’s understanding. </p>
<p class="ListBody">Once you’ve added more examples, go back to the Learn &amp; Test phase and train a new ML model. Then test it again to see if the computer is any better at recognizing commands.</p>
<h3 id="h2-500563c10-0003">Code Your Project with ML</h3>
<p class="BodyFirst">Now that you have an ML model that is able to recognize your commands, you can re-create the earlier project to use ML instead of the rules you used before.</p>
<ol>
<li value="1">Click <b>Back to project</b> in the top-left corner of the screen.</li>
<li value="2">Click <b>Make</b>.</li>
<li value="3">Click <b>Scratch 3</b>, and then click <b>Open in Scratch 3</b> to open a new window in Scratch.
<p class="ListBody">You should see a new set of blocks for your ML project in the Toolbox, as shown in <a id="figureanchor10-11" href="#figure10-11">Figure 10-11</a>.</p>
<span epub:type="pagebreak" title="160" id="Page_160"/><figure>
<img src="Images/f10011.png" alt="f10011"/>
<figcaption><p><a id="figure10-11" href="#figureanchor10-11">Figure 10-11:</a> Your ML project will be added to the Scratch Toolbox. </p></figcaption>
</figure>
</li>
<li value="4">Click <b>Project templates</b> in the top menu bar and choose the <b>Smart Classroom</b> template.</li>
<li value="5">Copy the script shown in <a id="figureanchor10-12" href="#figure10-12">Figure 10-12</a>.
<p class="ListBody">When you give this script commands, it will use your ML model to recognize the command and carry out the instruction.</p>
</li>
</ol>
<figure>
<img src="Images/f10012.png" alt="f10012"/>
<figcaption><p><a id="figure10-12" href="#figureanchor10-12">Figure 10-12:</a> ML approach for a smart assistant</p></figcaption>
</figure>
<h3 id="h2-500563c10-0004"><span epub:type="pagebreak" title="161" id="Page_161"/>Test Your Project</h3>
<p class="BodyFirst">Test your project by clicking the Green Flag and entering a variety of commands, phrased in lots of different ways. See how your smart assistant performs now compared to the version that didn’t use ML.</p>
<h2 id="h1-500563c10-0002">Review and Improve Your Project</h2>
<p class="BodyFirst">You’ve created your own smart assistant: a virtual version of Amazon’s Alexa or Apple’s Siri that can understand and carry out your commands! What could you do to improve the way that it behaves?</p>
<h3 id="h2-500563c10-0005">Using Your Model’s Confidence Score</h3>
<p class="BodyFirst">Back in the Learn &amp; Test phase, you should have noticed the confidence score displayed when you tested your model. That tells you how confident the computer is that it has recognized a command.</p>
<p>Go back to the Learn &amp; Test phase now and try typing something that doesn’t fit into one of the four commands that the computer has learned to recognize. </p>
<p>For example, you could try “What is the capital city of France?” as shown in <a id="figureanchor10-13" href="#figure10-13">Figure 10-13</a>.</p>
<figure>
<img src="Images/f10013.png" alt="f10013"/>
<figcaption><p><a id="figure10-13" href="#figureanchor10-13">Figure 10-13:</a> Testing your smart assistant </p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="162" id="Page_162"/>My ML model recognized it as “lamp on,” but it had 0 percent confidence in that classification. That was the ML model’s way of telling me that it hadn’t recognized the command. </p>
<p>“What is the capital city of France?” doesn’t look like any of the examples I’ve given the ML model. The question doesn’t match the patterns it has identified in the examples I used to train it. This means it can’t confidently recognize the question as one of the four commands it’s been trained to recognize.</p>
<p>Your ML model might have a higher confidence than 0, but it should still be a relatively low number. (If not, try adding more examples to train your ML model with.)</p>
<p>Experiment with other questions and commands that don’t have anything to do with a fan or lamp. Compare the confidence scores your ML model gives with those it displays when it recognizes actual fan on, fan off, lamp on, and lamp off commands. What kinds of confidence scores does your ML model give when it’s correctly recognized something? </p>
<p>Once you have a feel for how the confidence scores work for your ML model, you can use that in your Scratch project. Update your script to look like <a id="figureanchor10-14" href="#figure10-14">Figure 10-14</a>.</p>
<p>Now, if the model isn’t at least 80 percent confident that it has understood the command correctly, it will display a “sorry” response for 2 seconds and not carry out the action. </p>
<p>You’ll need to change the <code class="bold">80</code> value in this script to a percentage that matches the behavior of your own ML model. </p>
<p>What else could you do to improve your project?</p>
<span epub:type="pagebreak" title="163" id="Page_163"/><figure>
<img src="Images/f10014.png" alt="f10014"/>
<figcaption><p><a id="figure10-14" href="#figureanchor10-14">Figure 10-14:</a> Using confidence scores in your ML project </p></figcaption>
</figure>
<h3 id="h2-500563c10-0006">Using Speech Input Instead of Typing</h3>
<p class="BodyFirst">You could modify your project to be more like real-world smart assistants by using voice input instead of typing.</p>
<p>In the Toolbox, click the Extensions Library icon (it looks like two blocks and a plus sign), add the <b>Speech to Text</b> extension, and update your script as shown in <a id="figureanchor10-15" href="#figure10-5">Figure 10-5</a>.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note	</span></h2>
<p>At the time of writing, the Scratch Speech to Text extension can be used only in the Google Chrome web browser.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<span epub:type="pagebreak" title="164" id="Page_164"/><figure>
<img src="Images/f10015.png" alt="f10015"/>
<figcaption><p><a id="figure10-15" href="#figureanchor10-15">Figure 10-15:</a> Adding speech recognition to your smart assistant </p></figcaption>
</figure>
<p>What else could you do to improve your project?</p>
<h3 id="h2-500563c10-0007">Collecting Training Data</h3>
<p class="BodyFirst">ML is often used for recognizing text because it’s quicker than having to write rules. But training a model properly requires lots and lots of examples. To build these systems in the real world, we’d need more efficient ways of collecting examples than simply typing them all yourself like you’ve done so far. For example, instead of asking one person to write 100 examples, it might be better to ask 100 people to write one example each. Or 1,000 people. Or 10,000 people. </p>
<p><span epub:type="pagebreak" title="165" id="Page_165"/>If you can figure out when your ML model gets something wrong, you can collect more examples to add to your training buckets. For example, what if the ML model has a very low confidence score? Or what if someone keeps giving a similar command in slightly different ways? That probably means that the ML model isn’t recognizing the commands correctly or doing what the person wants, and that’s helpful feedback for your training. What if the person clicks a thumbs-down “I’m not happy” button? What if they end up pressing a button to do something? What if they sound more and more annoyed? </p>
<p>There are lots of ways to guess that something hasn’t worked well. And every time that happens, that’s an example you could collect and add to one of your training buckets so a newer ML model can work a little better next time. </p>
<p>We use all these sorts of techniques (collecting training examples from large numbers of people, getting feedback from users, and many more) to help us build computers and devices that can understand what you mean.</p>
<h2 id="h1-500563c10-0003">What You Learned</h2>
<p class="BodyFirst">In this chapter, we’ve looked at how ML is used to recognize the meaning of text, and how it can be used to build computer systems that can understand what we mean and do what we ask.</p>
<p>In your project, you used the same type of ML technology that enables <em>smart assistants</em><em/> like Amazon’s Alexa, Google Home, Microsoft’s Cortana, and Apple’s Siri. <em>Natural language interfaces</em><em/> let us tell our devices what we want them to do by using languages like English, instead of only by pressing screens or buttons. </p>
<p>When you ask a smartphone what the time is, or to set an alarm or a timer, or to play your favorite song, the computer needs to classify that command. It needs to take that series of words that you chose and recognize their intent. </p>
<p>The makers of smartphones and smart assistants trained an ML model to recognize the meaning of user commands by working out a list of categories—all of the possible commands they thought users might want to give. And then for each one, they collected lots and lots of examples of how someone might give that command. </p>
<p><span epub:type="pagebreak" title="166" id="Page_166"/>In both this project and the real world, the process works like this:</p>
<ol>
<li value="1">Predict commands that you might give.</li>
<li value="2">Collect examples of each of those commands.</li>
<li value="3">Use those examples to train an ML model.</li>
<li value="4">Script or code what you want the computer to do when it recognizes each command.</li>
</ol>
<p>To create a real smart assistant, you’d have to repeat these steps for thousands of commands, not just four. And you would need thousands, or tens of thousands, of examples for each command. </p>
<p>In the next chapter, you’ll use this capability to build programs that can answer questions.</p>
</section>
</div></body></html>