- en: '**10**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**STRING DATA TYPES**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/common01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: After integers, character strings are probably the most commonly used data type
    in modern programs; after arrays, they’re the second most commonly used composite
    data type. A string is a sequence of objects. Most often, the term *string* describes
    a sequence of character values, but it’s also possible to have strings of integers,
    real values, Boolean values, and so on (for example, I’ve already discussed bit
    strings in this book and in *WGC1*). In this chapter, though, we’ll stick to character
    strings.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, a character string possesses two main attributes: a *length* and
    some *character data*. Character strings can also possess other attributes, such
    as the *maximum length* allowable for that particular variable or a *reference
    count* specifying how many different string variables refer to the same character
    string. We’ll look at these attributes and how programs can use them, as well
    as the various string formats and possible string operations. Specifically, this
    chapter discusses the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Character string formats including zero-terminated strings, length-prefixed
    strings, HLA strings, and 7-bit strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When to use (and when not to use) standard library string processing functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static, pseudo-dynamic, and dynamic strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reference counting and strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unicode and UTF-8/UTF-16/UTF-32 character data in strings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: String manipulation consumes a fair amount of CPU time in today’s applications.
    Therefore, it’s important to understand how programming languages represent and
    operate on character strings if you want to write code that manipulates strings
    efficiently. This chapter provides the basic information you’ll need to do so.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.1 Character String Formats**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Different languages use different data structures to represent strings. Some
    string formats use less memory, others allow faster processing, some are more
    convenient to use, some are easy for compiler writers to implement, and some provide
    additional functionality for the programmer and operating system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although their internal representations vary, all string formats have one thing
    in common: the character data. This is a sequence of 0 or more bytes (the term
    *sequence* implies that the order of the characters is important). How a program
    references this sequence of characters varies by format. In some string formats,
    the sequence of characters is kept in an array; in other string formats the program
    maintains a pointer to the sequence of characters elsewhere in memory.'
  prefs: []
  type: TYPE_NORMAL
- en: All character string formats share the length attribute; however, they use several
    different ways to represent the length of a string. Some string formats use a
    special *sentinel character* to mark the end of the string. Other formats precede
    the character data with a numeric value that specifies the number of characters
    in the sequence. Still others encode the length as a numeric value in a variable
    that is not connected to the character sequence. Some character string formats
    use a special bit (set or cleared) to mark the end of a string. Finally, some
    string formats use a combination of these methods. How a particular string format
    determines the length of a string can have a big impact on the performance of
    the functions that manipulate those strings. It can also affect how much extra
    storage is needed to represent string data.
  prefs: []
  type: TYPE_NORMAL
- en: Some string formats provide additional attributes, such as a maximum length
    and reference count values, that certain string functions can use to operate on
    string data more efficiently. These extra attributes are optional insofar as they
    aren’t strictly necessary to define a string value. They do, however, allow string
    manipulation functions to provide certain tests for correctness or to work more
    efficiently than they would otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: To help you better understand the reasoning behind the design of character strings,
    let’s look at some common string representations popularized by various languages.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.1.1 Zero-Terminated Strings**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Without question, *zero-terminated strings* (see [Figure 10-1](ch10.xhtml#ch10fig1))
    are probably the most common string representation in use today, because this
    is the native string format for C, C++, and several other languages. In addition,
    you’ll find zero-terminated strings used in programs written in languages that
    don’t have a specific native string format, such as assembly language.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-1: Zero-terminated string format*'
  prefs: []
  type: TYPE_NORMAL
- en: 'A zero-terminated ASCII string, also called an *ASCIIz* string or a *zstring*,
    is a sequence containing zero or more 8-bit character codes and ending with a
    byte containing `0`—or, in the case of Unicode (UTF-16), a sequence containing
    zero or more 16-bit character codes and ending with a 16-bit word containing `0`.
    For UTF-32 strings, each item in the string is 32 bits (4 bytes) wide, ending
    with a 32-bit `0` value. For example, in C/C++, the ASCIIz string `"abc"` requires
    4 bytes: 1 byte for each of the three characters `a`, `b`, and `c`, followed by
    a `0` byte.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Zero-terminated strings have a few advantages over other string formats:'
  prefs: []
  type: TYPE_NORMAL
- en: Zero-terminated strings can represent strings of any practical length with only
    1 byte of overhead (2 bytes in UTF-16, 4 in UTF-32).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given the popularity of the C/C++ programming languages, high-performance string
    processing libraries are available that work well with zero-terminated strings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-terminated strings are easy to implement. Indeed, except for dealing with
    string literal constants, the C/C++ programming languages don’t provide native
    string support. As far as those languages are concerned, strings are just arrays
    of characters. That’s probably why C’s designers chose this format in the first
    place—so they wouldn’t have to clutter up the language with string operators.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can easily represent zero-terminated strings in any language that provides
    the ability to create an array of characters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, zero-terminated strings also have disadvantages that mean they are
    not always the best choice for representing character string data:'
  prefs: []
  type: TYPE_NORMAL
- en: String functions often aren’t very efficient when operating on zero-terminated
    strings. Many string operations need to know the length of the string before working
    on the string data. The only reasonable way to compute the length of a zero-terminated
    string is to scan the string from the beginning to the end. The longer your strings
    are, the slower this function runs, so the zero-terminated string format isn’t
    the best choice if you need to process long strings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although it’s a minor problem, you cannot easily represent the character code
    `0` (such as the NUL character in ASCII and Unicode) with the zero-terminated
    string format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-terminated strings don’t contain any information that tells you how long
    the string can grow beyond the terminating `0` byte. Therefore, some string functions,
    like concatenation, can only extend the length of an existing string variable
    and check for overflow if the caller explicitly passes the maximum length.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As noted, one nice feature of zero-terminated strings is that you can easily
    implement them using pointers and arrays of characters. Consider the following
    C/C++ statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the code the Borland C++ v5.0 compiler generates for this statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The Borland C++ compiler simply emits the literal string `"Hello World"` to
    the global data segment in memory and then loads the `someCharPtrVar` variable
    with the address of the first character of this string literal in the data segment.
    From that point forward, the program can refer to the string data indirectly via
    this pointer. This is a very convenient scheme from the compiler writer’s point
    of view.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using zero-terminated strings in a language like C, C++, Python, or any
    of a dozen other languages that have adopted C’s string format, you can improve
    the performance of your string-handling code sequences by keeping a few points
    in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Try to use the language’s runtime library functions rather than attempting to
    code comparable functions yourself. Most compiler vendors provide highly optimized
    versions of their string functions that will probably run many times faster than
    code you would write yourself.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you’ve computed the length of a string by scanning the entire string, save
    that length for future use (rather than recomputing it every time you need it).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid copying string data from one string variable to another. Doing so is one
    of the more expensive operations (after length computation) in applications using
    zero-terminated strings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following subsections discuss each point in turn.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.1.1.1 When to Use C Standard Library String Functions**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Some programmers are skeptical that someone else could write faster or higher-quality
    code. But when it comes to standard library functions, you should avoid the temptation
    to replace them with code of your own choosing. Unless the library code you’re
    considering is especially bad, chances are you won’t come close to duplicating
    its efficiency. This is especially true for string functions that handle zero-terminated
    strings in languages like C and C++. There are three main reasons why standard
    libraries generally perform better than code you write yourself: experience, maturity,
    and inline substitution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The typical programmer who writes compiler runtime libraries has a lot of experience
    with string-handling functions. Although in the past new compilers were often
    accompanied by notoriously inefficient libraries, over time compiler programmers
    have gained considerable experience writing those library routines and have figured
    out how to deliver well-written string-handling functions. Unless you’ve spent
    considerable time writing those same types of routines, it’s highly unlikely that
    your code will perform as well as theirs. Many compiler vendors purchase their
    standard library code from a third party that specializes in writing library code,
    so now, even if the compiler you’re using is fairly new, it may have a good library.
    Few commercial compilers today contain horribly inefficient library code. For
    the most part, only research or “hobby” compilers contain library code so bad
    that you can easily write something better. Consider a simple example—the C standard
    library `strlen()` (string length) function. Here’s a typical implementation of
    `strlen()` that an inexperienced programmer might write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The 80x86 machine code that Microsoft’s Visual C++ compiler generates for `myStrlen()`
    is probably what any assembly programmer would expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'No doubt, an experienced assembly language programmer could rearrange these
    particular instructions to speed them up a bit. Indeed, even an average 80x86
    assembly language programmer could point out that the 80x86 `scasb` instruction
    does most of the work in this code sequence. Although this code is fairly short
    and easy to understand, by no means will it run as fast as possible. An expert
    assembly language programmer might note that this loop repeats one iteration for
    each character in the string and accesses the characters in memory 1 byte at a
    time, and might improve upon it by unrolling^([1](footnotes.xhtml#ch10fn1)) the
    loop and processing more than one character per loop iteration. For example, consider
    the following HLA standard library `zstr.len()` function, which computes the length
    of a zero-terminated string by processing four characters at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Even though this function is much longer and more complex than the simple example
    given earlier, it runs faster because it processes four characters per loop iteration
    rather than one, which means it executes far fewer loop iterations. Also, this
    code reduces loop overhead by unrolling eight copies of the loop (that is, expanding
    eight copies of the loop body inline), which saves the execution of 87 percent
    of the loop control instructions. As a result, this code runs anywhere from two
    to six times faster than the code given earlier; the exact savings depend upon
    the length of the string.^([2](footnotes.xhtml#ch10fn2))
  prefs: []
  type: TYPE_NORMAL
- en: The second reason to avoid writing your own library functions is the maturity
    of the code. Most popular optimizing compilers available today have been around
    for a while. During this time, the compiler vendors have used their routines,
    determined where the bottlenecks lie, and optimized their code. When you write
    your own version of a standard library string-handling function, you probably
    won’t have comparable time to dedicate to optimizing it—you’ve got your entire
    application to worry about. Because of project time constraints, you’ll likely
    never go back and rewrite that string function to improve its performance. Even
    if there’s a slight performance advantage to your routine now, the compiler vendor
    may very well update their library in the future, and you could take advantage
    of those improvements by simply relinking the updated code with your project.
    However, if you write the library code yourself, it will never improve unless
    you explicitly update it yourself. Most people are too busy working on new projects
    to go back and clean up their old code, so the likelihood of improving self-written
    string functions in the future is quite low.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third reason for using standard library string functions in a language
    like C or C++ is the most important: inline expansion. Many compilers recognize
    certain standard library function names and expand them inline to efficient machine
    code in place of the function call. This inline expansion can be many times faster
    than an explicit function call, especially if the function call contains several
    parameters. As a simple example, consider the following (almost trivial) C program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding 64-bit x86-64 assembly code that Visual C++ produces is quite
    interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The compiler recognizes what’s going on and substitutes four inline instructions
    that copy the 12 bytes of the string from the literal constant in memory to the
    `localStr` variable (specifically, it copies 8 bytes using the XMM0 register and
    4 bytes using the EAX register; note that this code uses RCX to pass the address
    of `localStr` to the `printf()` function). The overhead of a call and return to
    an actual `strcpy()` function will be more expensive than this (and that’s without
    considering the work needed to copy the string data). This example demonstrates
    quite well why you should usually call standard library functions rather than
    writing your own “optimized” functions to do the same job.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.1.1.2 When Not to Use Standard Library Functions**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Although, as you’ve seen, it’s usually better to call a standard library routine
    rather than writing your own version, there are some special situations when you
    should *not* rely on one or more library functions in the standard library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Library functions work great when they perform exactly the function you need—no
    more and no less. One area where programmers get into trouble is when they misuse
    a library function and call it to do something that it wasn’t really intended
    to do, or they need only part of the functionality it provides. For example, consider
    the C standard library `strcspn()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This function returns the number of characters in the source string up to the
    first character it finds that also appears in the cset string. It’s not at all
    uncommon to see calls to this function that look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The intent here is to return the number of characters in SomeString before
    the first occurrence of an `a` character in that string. That is, it attempts
    to do something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Unfortunately, the call to the `strcspn()` function is probably a lot slower
    than this simple `while` loop implementation. That’s because `strcspn()` actually
    does a lot more work than search for a single character within a string. It looks
    for any character from a set of characters within the source string. The generic
    implementation of this function might be something like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: With a little analysis (and noting that we have a pair of nested loops here),
    it’s clear that this code is slower than the code given earlier, even if you pass
    in a `cset` string containing a single character. This is a classic example of
    calling a function that is more general than you need, because it searches for
    any of several termination characters rather than the special case of a single
    terminating character. When a function does exactly what you want, using the standard
    library’s version of it is a good idea. However, when it does more than you need,
    using the standard library function can be expensive, and it’s better to write
    your own version.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.1.1.3 Why to Avoid Length Recomputing Data**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The last example in the previous section demonstrates a common C programming
    mistake. Consider the coded fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'On each iteration of this loop, the code tests the loop index to see if it
    is less than the length of the `cset` string. But because the loop body does not
    modify the `cset` string (and because, presumably, this is not a multithreaded
    application with another thread modifying the `cset` string), there’s really no
    need to recompute the string length on each iteration of this loop. Look at the
    code that the Microsoft Visual C++ 32-bit compiler emits for this code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, the machine code recalculates the string’s length on every iteration
    of the innermost `for` loop, but because the `cset` string’s length never changes,
    this is totally unnecessary. We can easily rectify this problem by rewriting the
    code fragment this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: On the plus side, recent versions of Microsoft’s VC++ compiler will recognize
    this situation if you have optimizations turned on. As VC++ determines that the
    string length is a loop-invariant calculation (that is, its value does not change
    from one loop iteration to the next), VC++ will move the call to `strlen()` out
    of the loop. Unfortunately, VC++ can’t catch this in every situation. For example,
    if you call some function that VC++ doesn’t know about and you pass it the address
    of `localStr` as a (non-`const`) parameter, VC++ will have to assume that the
    string’s length could change (even if it doesn’t) and it won’t be able to move
    the `strlen()` call out of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'A fair number of string operations require the string’s length before they
    can execute. Consider the `strdup()` function commonly found in many C libraries.^([3](footnotes.xhtml#ch10fn3))
    The following code is a common implementation of this function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Fundamentally, nothing is wrong with this implementation of `strdup()`. If
    you know absolutely nothing about the string object you’re passing as a parameter,
    then you must compute the string’s length so you know how much memory to allocate
    for a copy of that string. Consider, however, the following code sequence that
    calls `strdup()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The problem here is that you wind up calling `strlen()` twice: once for the
    explicit call to `strlen()` in this code fragment, and once for the call buried
    in the `strdup()` function. Worse, it isn’t obvious that you’re calling `strlen()`
    twice, so it’s not even clear that you’re wasting CPU cycles in this code. This
    is another example of calling a function that is more general than you need, causing
    the program to recompute the string’s length (an inefficient process). One solution
    is to provide a less general version of `strdup()`, say `strduplen()`, that lets
    you pass it the length of the string you’ve already computed. You could implement
    `strduplen()` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Notice the use of `memcpy()` rather than `strcpy()` (or, better yet, `strncpy()`).
    Again, we already know the length of the string, so there’s no need to execute
    any code looking for the `0` terminating byte (as both `strcpy()` and `strncpy()`
    will do). Of course, this function implementation assumes that the caller passes
    the correct length, but that’s a standard C assumption for most string and array
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.1.1.4 Why to Avoid Copying Data**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Copying strings, especially long strings, can be a time-consuming process on
    a computer. Most programs maintain string data in memory, and memory is much slower
    than the CPU (often by an order of magnitude or more). Although cache memory can
    help mitigate this problem, processing a lot of string data can eliminate other
    data from the cache and lead to thrashing problems if you don’t frequently reuse
    all the string data you move through the cache. It’s not always possible to avoid
    moving string data around, but many programs needlessly copy data, and that can
    hamper program performance.
  prefs: []
  type: TYPE_NORMAL
- en: A better solution is to pass around *pointers* to zero-terminated strings rather
    than copying those strings from string variable to string variable. Pointers to
    zero-terminated strings can fit in registers and don’t consume much memory when
    you use memory variables to hold them. Therefore, passing pointers has far less
    impact on cache and CPU performance than copying string data among string variables.
  prefs: []
  type: TYPE_NORMAL
- en: As you’ve seen in this section, zero-terminated string functions are generally
    less efficient than functions that manipulate other types of strings. Furthermore,
    programs that utilize zero-terminated strings tend to make mistakes, such as calling
    `strlen()` multiple times or abusing generic functions to achieve specific goals.
    Fortunately, designing and using a more efficient string format is easy enough
    in languages whose native string format is the zero-terminated string.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.1.2 Length-Prefixed Strings**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A second common string format, *length-prefixed strings*, overcomes some of
    the problems with zero-terminated strings. Length-prefixed strings are common
    in languages like Pascal; they generally consist of a single byte that specifies
    the length of the string, followed by zero or more 8-bit character codes (see
    [Figure 10-2](ch10.xhtml#ch10fig2)). In a length-prefixed scheme, the string `"String"`
    would consist of 4 bytes: the length byte (`6`), followed by the characters `S`,
    `t`, `r`, `i`, `n`, and `g`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-2: Length-prefixed string format*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Length-prefixed strings solve two of the problems associated with zeroterminated
    strings:'
  prefs: []
  type: TYPE_NORMAL
- en: NUL characters can be represented in length-prefixed strings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: String operations are more efficient.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another advantage to length-prefixed strings is that the length is usually located
    at position `0` in the string (if we view the string as an array of characters),
    so the first character of the string begins at index `1` in the array representation
    of the string. For many string functions, having a `1`-based index into the character
    data is much more convenient than a `0`-based index (which zero-terminated strings
    use).
  prefs: []
  type: TYPE_NORMAL
- en: Length-prefixed strings do suffer from their own drawbacks, the principal one
    being that they’re limited to a maximum of 255 characters in length (assuming
    a 1-byte length prefix). You can remove this limitation by using a 2- or 4-byte
    length value, but doing so increases the amount of overhead data from 1 to 2 or
    4 bytes. It also changes the starting index of the string from 1 to either 2 or
    4, eliminating the `1`-based index feature. While there are ways to overcome this
    problem, they entail even more overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Many string functions are much more efficient with length-prefixed strings.
    Obviously, computing the length of a string is a trivial operation—it’s just a
    memory access—but other string functions that ultimately need the string’s length
    (such as concatenation and assignment) are usually more efficient than similar
    functions for zero-terminated strings. Furthermore, you don’t have to worry about
    recomputing the string’s length every time you call a string function that is
    built into the language’s standard library.
  prefs: []
  type: TYPE_NORMAL
- en: Despite these advantages, don’t get the impression that programs using length-prefixed
    string functions are always going to be efficient. You can still waste many CPU
    cycles by needlessly copying data. As with zero-terminated strings, if you use
    only a subset of a string function’s capabilities, you can waste lots of CPU cycles
    performing unnecessary tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using length-prefixed string functions, keep the following points in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Try to use the language’s runtime library functions rather than attempting to
    code comparable functions yourself. Most compiler vendors provide highly optimized
    versions of their string functions that will probably run many times faster than
    code you would write yourself.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although computing the string length when using the length-prefixed string format
    is fairly trivial, many (Pascal) compilers actually emit a function call to extract
    the length value from the string’s data. The function call and return is far more
    expensive than retrieving the length value from a variable. So, once you compute
    the string’s length, consider saving that length in a local variable if you intend
    to use that value again. Of course, if a compiler is smart enough to replace a
    call to the length function with a simple data fetch from the string’s data structure,
    this “optimization” won’t buy you much.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid copying string data from one string variable to another. Doing so is one
    of the more expensive operations in programs using length-prefixed strings. Passing
    around pointers to strings has the same benefit as for zero-terminated strings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**10.1.3 Seven-Bit Strings**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The 7-bit string format is an interesting option that works for 7-bit encodings
    like ASCII. It uses the (normally unused) higher-order bit of the characters in
    the string to indicate the end of the string. All but the last character code
    in the string has its HO bit clear, and the last character in the string has its
    HO bit set (see [Figure 10-3](ch10.xhtml#ch10fig3)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-3: Seven-bit string format*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This 7-bit string format has several disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: You have to scan the entire string in order to determine the length of the string.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You cannot have zero-length strings in this format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Few languages provide literal string constants for 7-bit strings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You’re limited to a maximum of 128 character codes, although this is fine when
    you are using plain ASCII.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, the big advantage of 7-bit strings is that they don’t require any
    overhead bytes to encode the length. Assembly language (using a macro to create
    literal string constants) is probably the best language to use when dealing with
    7-bit strings. Because the benefit of 7-bit strings is that they’re compact and
    assembly language programmers tend to worry most about compactness, this is a
    good match. Here’s an HLA macro that converts a literal string constant to a 7-bit
    string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Because few languages provide support for 7-bit strings, the first suggestion
    that applied to zero-terminated and length-prefixed strings doesn’t apply to 7-bit
    strings: you’ll probably have to write your own string-handling functions. Computing
    lengths and copying data are expensive operations even with 7-bit strings, however,
    so these two suggestions still apply:'
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve computed the length of a string by scanning the entire string, save
    that length for future use (rather than recomputing it every time you need it).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid copying string data from one string variable to another. Doing so is one
    of the more expensive operations in programs using 7-bit strings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**10.1.4 HLA Strings**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As long as you’re not too concerned about a few extra bytes of overhead per
    string, you can create a string format that combines the advantages of both length-prefixed
    and zero-terminated strings without their respective disadvantages. The High-Level
    Assembly language has done this with its native string format.^([4](footnotes.xhtml#ch10fn4))
  prefs: []
  type: TYPE_NORMAL
- en: The biggest drawback to the HLA character string format is the amount of overhead
    required for each string (which can be significant, percentage-wise, if you’re
    in a memory-constrained environment and you process many small strings). HLA strings
    contain a length prefix and a zero-terminating byte, as well as some other information,
    totaling 9 bytes of overhead per string.^([5](footnotes.xhtml#ch10fn5))
  prefs: []
  type: TYPE_NORMAL
- en: The HLA string format uses a 4-byte length prefix, allowing character strings
    to be just over 4 billion characters long (far more than any practical application
    will use). HLA also appends a `0` byte to the character string data, so HLA strings
    are compatible with string functions that reference (but do not change the length
    of) zero-terminated strings. The remaining 4 bytes of overhead in an HLA string
    contain the maximum legal length for that string (plus a `0` terminating byte).
    Having this extra field allows HLA string functions to check for string overflow,
    if necessary. In memory, HLA strings take the form shown in [Figure 10-4](ch10.xhtml#ch10fig4).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-4: HLA string format*'
  prefs: []
  type: TYPE_NORMAL
- en: The 4 bytes immediately before the first character of the string contain the
    current string length. The 4 bytes preceding the current string length contain
    the maximum string length. Immediately following the character data is a `0` byte.
    Finally, HLA always ensures that the string data structure’s length is a multiple
    of 4 bytes for performance reasons, so there may be up to 3 additional bytes of
    padding at the end of the object in memory. (Note that the string shown in [Figure
    10-4](ch10.xhtml#ch10fig4) requires only 1 byte of padding to ensure that the
    data structure is a multiple of 4 bytes in length.)
  prefs: []
  type: TYPE_NORMAL
- en: 'HLA string variables are actually pointers that contain the byte address of
    the first character in the string. To access the length fields, you load the value
    of the string pointer into a 32-bit register, then access the length field at
    offset –4 from the register and the maximum length field at offset –8 from the
    register. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'As noted earlier, the amount of memory reserved to hold an HLA string’s character
    data (including the `0` byte) is always a multiple of 4 bytes. Therefore, it’s
    always guaranteed that you can move data from one HLA string to another by copying
    double words rather than individual bytes. This allows string copy routines to
    run up to four times faster, because you execute one-fourth the number of loop
    iterations copying a string of double words as you would copying the string a
    byte at a time. For example, here’s the highly modified version of the pertinent
    code in the HLA `str.cpy()` function that copies one string to another:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The HLA `str.cpy()` function also checks for string overflows and `NULL` pointer
    references (for clarity, that code does not appear in this example). However,
    the takeaway here is that HLA copies the strings as double words in order to improve
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'One nice thing about HLA string variables is that (as read-only objects) HLA
    strings are compatible with zero-terminated strings. For example, if you have
    a function written in C or some other language that expects you to pass a zero-terminated
    string to it, you can call that function and pass an HLA string variable to it,
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The only catch is that the C function must not make any changes to the string
    that would affect its length (because the C code won’t update the `Length` field
    of the HLA string). Of course, you can always call a C `strlen()` function upon
    returning to update the length field yourself, but generally, it’s best not to
    pass HLA strings to a function that modifies zero-terminated strings.
  prefs: []
  type: TYPE_NORMAL
- en: 'The comments on length-prefixed strings generally apply to HLA strings, specifically:'
  prefs: []
  type: TYPE_NORMAL
- en: Try to use the HLA standard library functions rather than attempting to code
    comparable functions yourself. While you might want to check out the library function’s
    source code (available with HLA), most of the string functions do a good job on
    generic string data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although, in theory, you shouldn’t count on the explicit length field appearing
    in the HLA string data format, most programs simply grab the length from the 4
    bytes immediately preceding the string data, so there’s generally no need to save
    the length. Careful HLA programmers will actually call the `str.len()` function
    in the HLA standard library and simply save this value in a local variable for
    future use. However, accessing the length directly is probably safe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid copying string data from one string variable to another. Doing so is one
    of the more expensive operations in programs using HLA strings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**10.1.5 Descriptor-Based Strings**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The string formats we’ve considered up to this point have kept the attribute
    information (that is, the lengths and terminating bytes) for a string in memory
    along with the character data. A slightly more flexible scheme is to maintain
    such information in a record structure, known as a *descriptor*, that also contains
    a pointer to the character data. Consider the following Pascal/Delphi data structure
    (see [Figure 10-5](ch10.xhtml#ch10fig5)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![Image](../images/10fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-5: String descriptors*'
  prefs: []
  type: TYPE_NORMAL
- en: Note that this data structure does not hold the actual character data. Instead,
    the `strData` pointer contains the address of the first character of the string.
    The `curLength` field specifies the current length of the string. You could add
    any other fields you like to this record, such as a maximum length field, although
    a maximum length isn’t usually necessary because most string formats employing
    a descriptor are dynamic (as the next section will discuss).
  prefs: []
  type: TYPE_NORMAL
- en: An interesting attribute of a descriptor-based string system is that the actual
    character data associated with a string could be part of a larger string. Because
    no length or terminating bytes are in the actual character data, it’s possible
    to have the character data for two strings overlap (see [Figure 10-6](ch10.xhtml#ch10fig6)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-6: Overlapping strings using descriptors*'
  prefs: []
  type: TYPE_NORMAL
- en: This example shows two strings—`"Hello World"` and `"World"`—that overlap. This
    can save memory and make certain functions, like `substring()`, very efficient.
    Of course, when strings overlap as these do, you can’t modify the string data
    because that could wipe out part of some other string.
  prefs: []
  type: TYPE_NORMAL
- en: The suggestions given for other string formats don’t apply as strongly to descriptor-based
    strings. Certainly, if standard libraries are available, you should call those
    functions because they’re probably more efficient than the ones you would write
    yourself. There is no need to save the length, because extracting the length field
    from the string’s descriptor is usually a minor task. Also, many descriptor-based
    string systems use *copy on write* (see *WGC1* and the section “Dynamic Strings”
    on [page 317](ch10.xhtml#page_317)) to reduce string copy overhead. In a string
    descriptor system, you should avoid making changes to a string, because the copy-on-write
    semantics generally require the system to make a complete copy of the string whenever
    you change a single character (something that isn’t necessary with other string
    formats).
  prefs: []
  type: TYPE_NORMAL
- en: '**10.2 Static, Pseudo-Dynamic, and Dynamic Strings**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Having covered the various string data formats, it’s time to consider where
    to store string data in memory. Strings can be classified according to when and
    where the system allocates storage for them. There are three categories: static
    strings, pseudo-dynamic strings, and dynamic strings.'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.2.1 Static Strings**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Pure *static strings* are those whose maximum size a programmer chooses when
    writing the program. Pascal strings and Delphi *short strings* fall into this
    category. Arrays of characters that you use to hold zero-terminated strings in
    C/C++ also fall into this category, as do fixed-length arrays of characters. Consider
    the following declaration in Pascal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'And here’s an example in C/C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: While the program is running, there’s no way to increase the maximum sizes of
    these static strings. Nor is there any way to reduce the storage they will use;
    these string objects will consume 256 bytes at runtime, period. One advantage
    to pure static strings is that the compiler can determine their maximum length
    at compile time and implicitly pass this information to a string function so it
    can test for bounds violations at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.2.2 Pseudo-Dynamic Strings**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A pseudo-dynamic string is one whose length the system sets at runtime by calling
    a memory management function like `malloc()` to allocate storage for it. However,
    once the system allocates storage for the string, the maximum length of the string
    is fixed. HLA strings generally fall into this category.^([6](footnotes.xhtml#ch10fn6))
    An HLA programmer typically calls the `stralloc()` function to allocate storage
    for a string variable, after which that particular string object has a fixed length
    that cannot change.^([7](footnotes.xhtml#ch10fn7))
  prefs: []
  type: TYPE_NORMAL
- en: '**10.2.3 Dynamic Strings**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Dynamic string systems, which typically use a descriptor-based format, automatically
    allocate sufficient storage for a string object whenever you create a new string
    or otherwise do something that affects an existing string. Operations like string
    assignment and substring extraction are relatively trivial in dynamic string systems—generally
    they copy only the string descriptor data, so these operations are fast. However,
    as noted in the section “Descriptor-Based Strings” on [page 315](ch10.xhtml#page_315),
    when using strings this way, you cannot store data back into a string object,
    because it could modify data that is part of other string objects in the system.
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this problem is to use the copy-on-write technique. Whenever
    a string function needs to change characters in a dynamic string, the function
    first makes a copy of the string and then makes the necessary modifications to
    that copy. Research suggests that copy-on-write semantics can improve the performance
    of many typical applications, because operations like string assignment and substring
    extraction (which is just a partial string assignment) are far more common than
    the modification of character data within strings. The only drawback to this approach
    is that after several modifications to string data in memory, there may be sections
    of the string heap area that contain character data that’s no longer in use. To
    avoid a memory leak, dynamic string systems employing copy on write usually provide
    garbage collection code, which scans the string heap area looking for stale character
    data in order to recover that memory for other purposes. Unfortunately, depending
    on the algorithms in use, garbage collection can be quite slow.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*See [Chapter 9](ch09.xhtml#ch09) for more information on memory leaks and
    garbage collection.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.3 Reference Counting for Strings**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Consider the case where you have two string descriptors (or pointers) pointing
    at the same string data in memory. Clearly, you can’t deallocate the storage associated
    with one pointer while the program is still using the other pointer to access
    the same data. One common solution is to make the programmer responsible for keeping
    track of such details. Unfortunately, as applications become more complex, this
    approach often leads to dangling pointers, memory leaks, and other pointer-related
    problems in the software. A better solution is to allow the programmer to deallocate
    the storage for the character data in the string and to have the actual deallocation
    process hold off until the programmer releases the last pointer referencing that
    data. To accomplish this, a string system can use *reference counters*, which
    track the pointers and their associated data.
  prefs: []
  type: TYPE_NORMAL
- en: A reference counter is an integer that counts the number of pointers that reference
    a string’s character data in memory. Every time you assign the address of the
    string to some pointer, you increment the reference counter by 1\. Likewise, whenever
    you want to deallocate the storage associated with the character data for the
    string, you decrement the reference counter. Deallocation of the storage for the
    actual character data doesn’t happen until the reference counter decrements to
    0.
  prefs: []
  type: TYPE_NORMAL
- en: Reference counting works great when the language handles the details of string
    assignment automatically for you. If you try to implement reference counting manually,
    you must be sure to always increment the reference counter when you assign a string
    pointer to some other pointer variable. The best way to do this is to never assign
    pointers directly, but rather handle all string assignments via some function
    (or macro) call that updates the reference counters in addition to copying the
    pointer data. If your code fails to update the reference counter properly, you’ll
    wind up with dangling pointers or memory leaks.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.4 Delphi Strings**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although Delphi provides a “short string” format that is compatible with the
    length-prefixed strings in earlier versions of Delphi and Turbo Pascal, later
    versions of Delphi (v4.0 and later) use dynamic strings for their native string
    format. While this string format is unpublished (and, therefore, subject to change),
    indications are that Delphi’s string format is very similar to HLA’s. Delphi uses
    a zero-terminated sequence of characters with a leading string length and a reference
    counter (rather than a maximum length as HLA uses). [Figure 10-7](ch10.xhtml#ch10fig7)
    shows the layout of a Delphi string in memory.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-7: Delphi string data format*'
  prefs: []
  type: TYPE_NORMAL
- en: As with HLA, Delphi string variables are pointers holding the address of the
    first character of the actual string data. To access the length and reference
    counter fields, the Delphi string routines use a negative offset of –4 and –8
    from the character data’s base address. However, because this string format is
    not published, applications should never access the length or reference counter
    fields directly (for example, these fields could be 64-bit values one day). Delphi
    provides a length function that extracts the string length for you, and there’s
    really no need for your applications to access the reference counter field because
    the Delphi string functions maintain it automatically.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.5 Using Strings in a High-Level Language**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Strings are a very common data type in high-level programming languages. Because
    applications often make extensive use of string data, many HLLs provide libraries
    with lots of complex string manipulation routines that hide considerable complexity
    from the programmer. Unfortunately, it’s easy to forget the amount of work involved
    in a typical string operation when you execute a statement like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In a typical Pascal implementation, this assignment statement calls a function
    that winds up copying each character from the string literal to the storage reserved
    for the aLengthPrefixedString variable. That is, this statement roughly expands
    to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This code doesn’t even include the overhead of the procedure call, return, and
    parameter passing. As noted throughout the chapter, copying string data is one
    of the more expensive operations programs commonly do. This is why many HLLs have
    switched to dynamic strings and copy-on-write semantics—string assignments are
    far more efficient when you copy only a pointer rather than all of the character
    data. This is not to suggest that copy on write is always better, but for many
    string operations—such as assignment, substring, and other operations that do
    not change the string’s character data—it can be very efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Although few programming languages give you the option of choosing which string
    format you want to use, many do let you create pointers to strings, so you can
    manually support copy on write. If you’re willing to write your own string-handling
    functions, you can create some very efficient programs by avoiding the use of
    your language’s built-in string-handling capabilities. For example, the substring
    operation in C is usually handled by the `strncpy()` function and is often implemented
    like so:^([8](footnotes.xhtml#ch10fn8))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'A typical “substring” operation might use `strncpy()` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: where substring is the destination string object, fullString is the source string,
    start is the starting index of the substring to copy, and length is the length
    of the substring to copy.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you create a descriptor-based string format in C using a `struct`, similar
    to the HLA record in “Descriptor-Based Strings” on [page 315](ch10.xhtml#page_315),
    you could do a substring operation with the following two statements in C:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This code executes much faster than the `strncpy()` version.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, a particular programming language won’t provide access to the underlying
    string data representation it supports, and you’ll have to live with the performance
    loss, switch languages, or write your own string-handling code in assembly language.
    Generally, though, there are alternatives to copying string data in your applications,
    such as using a string descriptor as in the example just given.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6 Unicode Character Data in Strings**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Up to this point, we’ve assumed that each character in a string consumes exactly
    1 byte of storage. We’ve also assumed the use of the 7-bit ASCII character set
    when discussing the character data appearing in a string. Traditionally, this
    has been the way programming languages have represented a string’s character data.
    Today, however, the ASCII character set is too limited for worldwide use, and
    several new character sets have risen in popularity, including the Unicode variants:
    UTF-8, UTF-16, UTF-32, and UTF-7\. Because these character formats can have a
    big impact on the efficiency of string functions that operate upon them, we’ll
    spend some time covering them.'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6.1 The Unicode Character Set**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A few decades back, engineers at Aldus, NeXT, Sun, Apple Computer, IBM, Microsoft,
    the Research Library Group, and Xerox realized that their new computer systems
    with bitmaps and user-selectable fonts could display far more than 256 different
    characters at one time. At the time, *double-byte character sets (DBCSs)* were
    the most common solution. DBCSs had a couple of issues, however. First, as they
    were typically variable-length encodings, DBCSs required special library code;
    common character/string algorithms that depended upon fixed-length character encodings
    would not work properly with them. Second, there was no consistent standard—different
    DBCSs used the same encoding for different characters. So, wanting to avoid these
    compatibility problems, the engineers sought a different route.
  prefs: []
  type: TYPE_NORMAL
- en: The solution they came up with was the Unicode character set. The engineers
    who originally developed Unicode chose a 2-byte character size. Like DBCSs, this
    approach still required special library code (existing single-byte string functions
    would not always work with 2-byte characters), but other than changing the size
    of a character, most existing string algorithms would still work with 2-byte characters.
    The Unicode definition included all of the (known/living) character sets at the
    time, giving each character a unique encoding, to avoid the consistency problems
    that plagued differing DBCSs.
  prefs: []
  type: TYPE_NORMAL
- en: The original Unicode standard used a 16-bit word to represent each character.
    Therefore, Unicode supported up to 65,536 different character codes—a huge advance
    over the 256 possible codes that are representable with an 8-bit byte. Furthermore,
    Unicode is upward compatible from ASCII. If the HO 9 bits^([9](footnotes.xhtml#ch10fn9))
    of a Unicode character’s binary representation contain `0`, then the LO 7 bits
    use the standard ASCII code. If the HO 9 bits contain some nonzero value, then
    the 16 bits form an extended character code (extended from ASCII, that is). If
    you’re wondering why so many different character codes are necessary, note that,
    at the time, certain Asian character sets contained 4,096 characters. The Unicode
    character set even provided a set of codes you could use to create an application-defined
    character set. Approximately half of the 65,536 possible character codes have
    been defined, and the remaining character encodings are reserved for future expansion.
  prefs: []
  type: TYPE_NORMAL
- en: Today, Unicode is a universal character set, long replacing ASCII and older
    DBCSs. All modern operating systems (including macOS, Windows, Linux, iOS, Android,
    and Unix), web browsers, and most modern applications provide Unicode support.
    Unicode Consortium, a nonprofit corporation, maintains the Unicode standard. By
    maintaining the standard, Unicode, Inc. (*[https://home.unicode.org](https://home.unicode.org)*),
    helps guarantee that a character you write on one system will display as you expect
    on a different system or application.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6.2 Unicode Code Points**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Alas, as well thought-out as the original Unicode standard was, it couldn’t
    have anticipated the explosion in characters that would occur. Emojis, astrological
    symbols, arrows, pointers, and a wide variety of symbols introduced for the internet,
    mobile devices, and web browsers have greatly expanded the Unicode symbol repertoire
    (along with a desire to support historic, obsolete, and rare scripts). In 1996,
    systems engineers discovered that 65,536 symbols were insufficient. Rather than
    require 3 or 4 bytes for each Unicode character, those in charge of the Unicode
    definition gave up on trying to create a fixed-size representation of characters
    and allowed for opaque (and multiple) encodings of Unicode characters. Today,
    Unicode defines 1,112,064 code points, far exceeding the 2-byte capacity originally
    set aside for Unicode characters.
  prefs: []
  type: TYPE_NORMAL
- en: A Unicode *code point* is simply an integer value that Unicode associates with
    a particular character symbol; you can think of it as the Unicode equivalent of
    the ASCII code for a character. The convention for Unicode code points is to specify
    the value in hexadecimal with a `U+` prefix; for example, `U+0041` is the Unicode
    code point for the letter *A*.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*See* [https://en.wikipedia.org/wiki/Unicode#General_Category_property](https://en.wikipedia.org/wiki/Unicode#General_Category_property)
    *for more details on code points.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6.3 Unicode Code Planes**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Because of its history, blocks of 65,536 characters are special in Unicode—they
    are known as a *multilingual plane*. The first multilingual plane, `U+000000`
    to `U+00FFFF`, roughly corresponds to the original 16-bit Unicode definition;
    the Unicode standard calls this the *Basic Multilingual Plane (BMP)*. Planes 1
    (`U+010000` to `U+01FFFF`), 2 (`U+020000` to `U+02FFFF`), and 14 (`U+0E0000` to
    `U+0EFFFF`) are supplementary planes. Unicode reserves planes 3 through 13 for
    future expansion and planes 15 and 16 for user-defined character sets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Unicode standard defines code points in the range `U+000000` to `U+10FFFF`.
    Note that `0x10ffff` is 1,114,111, which is where most of the 1,112,064 characters
    in the Unicode character set come from; the remaining 2,048 code points are reserved
    for use as *surrogates*, which are Unicode extensions. *Unicode scalar* is another
    term you might hear; this is a value from the set of all Unicode code points *except*
    the 2,048 surrogate code points. The HO two hexadecimal digits of the six-digit
    code point value specify the multilingual plane. Why 17 planes? The reason, as
    you’ll see in a moment, is that Unicode uses special multiword entries to encode
    code points beyond `U+FFFF`. Each of the two possible extensions encodes 10 bits,
    for a total of 20 bits; 20 bits gives you 16 multilingual planes, which, plus
    the original BMP, produces 17 multilingual planes. This is also why code points
    fall in the range `U+000000` to `U+10FFFF`: it takes 21 bits to encode the 16
    multilingual planes plus the BMP.'
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6.4 Surrogate Code Points**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As noted earlier, Unicode began life as a 16-bit (2-byte) character set encoding.
    When it became apparent that 16 bits were insufficient to handle all the possible
    characters that existed at the time, an expansion was necessary. As of Unicode
    v2.0, the Unicode, Inc., organization extended the definition of Unicode to include
    multiword characters. Now Unicode uses surrogate code points (`U+D800` through
    `U+DFFF`) to encode values larger than `U+FFFF`. [Figure 10-8](ch10.xhtml#ch10fig8)
    shows the encoding.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/10fig08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-8: Surrogate code point encoding for Unicode planes 1 through 16*'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the two words (unit 1/high surrogate and unit 2/low surrogate) always
    appear together. The unit 1 value (with HO bits `%110110`) specifies the upper
    10 bits (`b[10]`..`b[19]`) of the Unicode scalar, and the unit 2 value (with HO
    bits `%110111`) specifies the lower 10 bits (`b[0]`..`b[9]`) of the Unicode scalar.
    Therefore, the value of bits `b[16]`..`b[19]` plus 1 specifies Unicode plane 1
    through 16\. Bits `b[0]`..`b[15]` specify the Unicode scalar value within the
    plane.
  prefs: []
  type: TYPE_NORMAL
- en: Note that surrogate codes only appear in the BMP. None of the other multilingual
    planes contain surrogate codes. Bits `b[0]`..`b[19]` extracted from the unit 1
    and 2 values always specify a Unicode scalar value (even if the values fall in
    the range `U+D800` through `U+DFFF`).
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6.5 Glyphs, Characters, and Grapheme Clusters**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Each Unicode code point has a unique name. For example, `U+0045` has the name
    “LATIN CAPITAL LETTER A.” Note that the symbol *A* is *not* the name of the character.
    *A* is a *glyph*—a series of strokes (one horizontal and two slanted strokes)
    that a device draws in order to represent the character.
  prefs: []
  type: TYPE_NORMAL
- en: There are many different glyphs for the single Unicode character “LATIN CAPITAL
    LETTER A.” For example, a Times Roman A and a Times Roman Italic *A* have different
    glyphs, but Unicode doesn’t differentiate between them (or between the *A* character
    in any two different fonts). The character “LATIN CAPITAL LETTER A” remains `U+0045`
    regardless of the font or style you use to draw it.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an interesting side note, if you have access to the Swift programming language,
    you can print the name of any Unicode character using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'So, what exactly is a character in Unicode? Unicode scalars are Unicode characters,
    but there’s a difference between what you’d normally call a character and the
    definition of a Unicode character (scalar). For example, is *é* one character
    or two? Consider the following Swift code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '`"\u{301}"` is the Swift syntax for specifying a Unicode scalar value within
    a string; in this particular case `301` is the hexadecimal code for the *combining
    acute accent* character.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first `print` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: prints the character (producing `é` on the output, as we expect).
  prefs: []
  type: TYPE_NORMAL
- en: 'The second `print` statement prints the number of characters Swift determines
    are present in the string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This prints `1` to the standard output.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third `print` statement prints the number of elements (UTF-16 elements^([10](footnotes.xhtml#ch10fn10)))
    in the string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This prints `2` on the standard output, because the string holds 2 words of
    UTF-16 data.
  prefs: []
  type: TYPE_NORMAL
- en: So, again, is this one character or two? Internally (assuming UTF-16 encoding),
    the computer sets aside 4 bytes of memory for this single character (two 16-bit
    Unicode scalar values).^([11](footnotes.xhtml#ch10fn11)) On the screen, however,
    the output takes only one character position and looks like a single character
    to the user. When this character appears within a text editor and the cursor is
    immediately to the right of the character, the user expects that pressing the
    backspace key will delete it. From the user’s perspective, then, this is a single
    character (as Swift reports when you print the `count` attribute of the string).
  prefs: []
  type: TYPE_NORMAL
- en: In Unicode, however, a character is largely equivalent to a code point. This
    is not what people normally think of as a character. In Unicode terminology, a
    *grapheme cluster* is what people normally call a character—it’s a sequence of
    one or more Unicode code points that combine to form a single language element
    (that is, a single character). So, when we talk about characters with respect
    to symbols that an application displays to an end user, we’re really talking about
    grapheme clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Grapheme clusters can make life miserable for software developers. Consider
    the following Swift code (a modification of the earlier example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This code produces the same `é` and `1` outputs from the first two `print`
    statements. The following produces `é`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: and this `print` statement produces `1`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'However, the third `print` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: displays `3` rather than `2` (as in the original example).
  prefs: []
  type: TYPE_NORMAL
- en: There are definitely three Unicode scalar values in this string (`U+0065`, `U+0301`,
    and `U+0301`). When printing, the operating system combines the `e` and the two
    acute accent combining characters to form the single character `é` and then outputs
    the character to the standard output device. Swift is smart enough to know that
    this combination creates a single output symbol on the display, so printing the
    result of the `count` attribute continues to output `1`. However, there are (undeniably)
    three Unicode code points in this string, so printing `utf16.count` produces `3`
    on output.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6.6 Unicode Normals and Canonical Equivalence**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Unicode character *é* actually existed on personal computers long before
    Unicode came along. It’s part of the original IBM PC character set and also part
    of the Latin-1 character set (used, for example, on old DEC terminals). As it
    turns out, Unicode uses the Latin-1 character set for the code points in the range
    `U+00A0` to `U+00FF`, and `U+00E9` just happens to correspond to the *é* character.
    Therefore, we can modify the earlier program as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'And here are the outputs from this program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Ouch! Three different strings all producing `é` but containing a different number
    of code points. Imagine how this complicates programming strings containing Unicode
    characters. For example, if you have the following three strings (Swift syntax)
    and you try to compare them, what will the result be?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: To the user, all three strings look the same on the screen. However, they clearly
    contain different values. If you compare them to see if they are equal, will the
    result be `true` or `false`?
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, that depends upon whose string libraries you’re using. Most current
    string libraries would return `false` if you compared these strings for equality.
    Interestingly enough, Swift will claim that `eAccent1` is equal to `eAccent2`,
    but it isn’t smart enough to report that `eAccent1` is equal to `eAccent3` or
    that `eAccent2` is equal to `eAccent3`—despite the fact that it displays the same
    symbol for all three strings. Many languages’ string libraries simply report that
    all three strings are unequal.
  prefs: []
  type: TYPE_NORMAL
- en: The three Unicode/Swift strings `"\u{E9}"`, `"e\u{301}"`, and `"e\u{301}\u{301}"`
    all produce the same output on the display. Therefore, they are canonically equivalent
    according to the Unicode standard. Some string libraries won’t report any of these
    strings as being equivalent. Some, like the one accompanying Swift, will handle
    small canonical equivalences (such as `"\u{E9}" == "e\u{301}"`) but not arbitrary
    sequences that should be equivalent (probably a good balance of correctness versus
    efficiency; it can be computationally expensive to handle all the weird cases
    that won’t normally happen, such as `"e\u{301}\u{301}"`).
  prefs: []
  type: TYPE_NORMAL
- en: Unicode defines *normal forms* for Unicode strings. One aspect of normal form
    is to replace canonically equivalent sequences with an equivalent sequence—for
    example, replace `"e\u{309}"` by `"\u{E9}"` or replace `"\u{E9}"` by `"e\u{309}"`
    (usually, the shorter form is preferable). Some Unicode sequences allow multiple
    combining characters. Often, the order of the combining characters is irrelevant
    to producing the desired grapheme cluster. However, it’s easier to compare two
    such strings if the combining characters are in a specified order. Normalizing
    Unicode strings may also produce results whose combining characters always appear
    in a fixed order (thereby improving efficiency of string comparisons).
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6.7 Unicode Encodings**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As of Unicode v2.0, the standard supports a 21-bit character space capable of
    handling over a million characters (though most of the code points remain reserved
    for future use). Rather than use a fixed-size 3-byte (or worse, 4-byte) encoding
    to allow the larger character set, Unicode, Inc., allows different encodings—UTF-32,
    UTF-16, and UTF-8—each with its own advantages and disadvantages.^([12](footnotes.xhtml#ch10fn12))
  prefs: []
  type: TYPE_NORMAL
- en: UTF-32 uses 32-bit integers to hold Unicode scalars. The advantage to this scheme
    is that a 32-bit integer can represent every Unicode scalar value (which requires
    only 21 bits). Programs that require random access to characters in strings—without
    having to search for surrogate pairs—and other constant-time operations are (mostly)
    possible when using UTF-32\. The obvious drawback to UTF-32 is that each Unicode
    scalar value requires 4 bytes of storage—twice that of the original Unicode definition
    and four times that of ASCII characters. It may seem that using two or four times
    as much storage (over ASCII and the original Unicode) is a small price to pay.
    After all, modern machines have several orders of magnitude more storage than
    they did when Unicode first appeared. However, that extra storage has a huge impact
    on performance, because those additional bytes quickly consume cache storage.
    Furthermore, modern string processing libraries often operate on character strings
    8 bytes at a time (on 64-bit machines). With ASCII characters, that means a given
    string function can process up to eight characters concurrently; with UTF-32,
    that same string function can operate on only two characters concurrently. As
    a result, the UTF-32 version will run four times slower than the ASCII version.
    Ultimately, even Unicode scalar values are insufficient to represent all Unicode
    characters (that is, many Unicode characters require a sequence of Unicode scalars),
    so using UTF-32 doesn’t solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: The second encoding format the Unicode supports is UTF-16\. As the name suggests,
    UTF-16 uses 16-bit (unsigned) integers to represent Unicode values. To handle
    scalar values greater than `0xFFFF`, UTF-16 uses the surrogate pair scheme to
    represent values in the range `0x010000` to `0x10FFFF` (see “Surrogate Code Points”
    on [page 323](ch10.xhtml#page_323)). Because the vast majority of useful characters
    fit into 16 bits, most UTF-16 characters require only 2 bytes. For those rare
    cases where surrogates are necessary, UTF-16 requires 2 words (32 bits) to represent
    the character.
  prefs: []
  type: TYPE_NORMAL
- en: The last encoding, and unquestionably the most popular, is UTF-8\. The UTF-8
    encoding is forward compatible from the ASCII character set. In particular, all
    ASCII characters have a single-byte representation (their original ASCII code,
    where the HO bit of the byte containing the character contains a `0` bit). If
    the UTF-8 HO bit is `1`, then UTF-8 requires between 1 and 3 additional bytes
    to represent the Unicode code point. [Table 10-1](ch10.xhtml#ch10tab1) provides
    the UTF-8 encoding schema.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 10-1:** UTF Encoding'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Bytes** | **Bits for code point** | **First code point** | **Last code
    point** | **Byte 1** | **Byte 2** | **Byte 3** | **Byte 4** |'
  prefs: []
  type: TYPE_TB
- en: '| `1` | `7` | `U+00` | `U+7F` | `0`*xxxxxxx* |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| `2` | `11` | `U+80` | `U+7FF` | `110`*xxxxx* | `10`*xxxxxx* |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| `3` | `16` | `U+800` | `U+FFFF` | `1110`*xxxx* | `10`*xxxxxx* | `10`*xxxxxx*
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| `4` | `21` | `U+10000` | `U+10FFFF` | `11110`*xxx* | `10`*xxxxxx* | `10`*xxxxxx*
    | `10`*xxxxxx* |'
  prefs: []
  type: TYPE_TB
- en: The “xxx . . . ” bits are the Unicode code point bits. For multibyte sequences,
    Byte 1 contains the HO bits, Byte 2 contains the next HO bits (LO bits compared
    to byte 1), and so on. For example, the 2-byte sequence (`%11011111`, `%10000001`)
    corresponds to the Unicode scalar `%0000_0111_1100_0001` (`U+07C1`).
  prefs: []
  type: TYPE_NORMAL
- en: UTF-8 encoding is probably the most common encoding in use. Most web pages use
    it. Most C standard library string functions will operate on UTF-8 text without
    modification (although some C standard library functions can produce malformed
    UTF-8 strings if the programmer isn’t careful with them).
  prefs: []
  type: TYPE_NORMAL
- en: Different languages and operating systems use different encodings as their default.
    For example, macOS and Windows tend to use UTF-16 encoding, whereas most Unix
    systems use UTF-8\. Some variants of Python use UTF-32 as their native character
    format. By and large, though, most programming languages use UTF-8 because they
    can continue to use older ASCII-based character processing libraries to process
    UTF-8 characters. Apple’s Swift is one of the first programming languages that
    attempts to do Unicode right (though there is a huge performance hit for doing
    so).
  prefs: []
  type: TYPE_NORMAL
- en: '**10.6.8 Unicode Combining Characters**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although UTF-8 and UTF-16 encodings are much more compact than UTF-32, the CPU
    overhead and algorithmic complexities of dealing with multibyte (or multiword)
    characters sets complicates their use (introducing bugs and performance issues).
    Despite the issues of wasting memory (especially in the cache), why not simply
    define characters as 32-bit entities and be done with it? This seems like it would
    simplify string processing algorithms, improving performance and reducing the
    likelihood of defects in the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem with this theory is that you cannot represent all possible grapheme
    clusters with only 21 bits (or even 32 bits) of storage. Many grapheme clusters
    consist of several concatenated Unicode code points. Here’s an example from Chris
    Eidhof and Ole Begemann’s *Advanced Swift* (CreateSpace, 2017):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Each of these Unicode grapheme clusters produces an identical character: an
    `ó` with a dot underneath the character (this is a character from the Yoruba character
    set). The character sequence (`U+1ECD`, `U+300`) is an `o` with a dot under it
    followed by a combining acute. The character sequence (`U+F2`, `U+323`) is an
    `ó` followed by a combining dot. The character sequence (`U+6F`, `U+323`, `U+300`)
    is an `o` followed by a combining dot, followed by a combining acute. Finally,
    the character sequence (`U+6F`, `U+300`, `U+323`) is an `o` followed by a combining
    acute, followed by a combining dot. All four strings produce the same output.
    Indeed, the Swift string comparisons treat all four strings as equal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Note that there is not a single Unicode scalar value that will produce this
    character. You must combine at least two Unicode scalars (or as many as three)
    to produce this grapheme cluster on the output device. Even if you used UTF-32
    encoding, it would still require two (32-bit) scalars to produce this particular
    output.
  prefs: []
  type: TYPE_NORMAL
- en: Emojis present another challenge that can’t be solved using UTF-32\. Consider
    the Unicode scalar `U+1F471`. This prints an emoji of a person with blond hair.
    If we add a skin color modifier to this, we obtain (`U+1F471`, `U+1F3FF`), which
    produces a person with a dark skin tone (and blond hair). In both cases we have
    a single character displaying on the screen. The first example uses a single Unicode
    scalar value, but the second example requires two. There is no way to encode this
    with a single UTF-32 value.
  prefs: []
  type: TYPE_NORMAL
- en: The bottom line is that certain Unicode grapheme clusters will require multiple
    scalars, no matter how many bits we assign to the scalar (it’s possible to combine
    30 or 40 scalars into a single grapheme cluster, for example). That means we’re
    stuck dealing with multiword sequences to represent a single “character” regardless
    of how hard we try to avoid it. This is why UTF-32 has never really taken off.
    It doesn’t solve the problem of random access into a string of Unicode characters.
    If you’ve got to deal with normalizing and combining Unicode scalars, it’s more
    efficient to use UTF-8 or UTF-16 encodings.
  prefs: []
  type: TYPE_NORMAL
- en: Again, most languages and operating systems today support Unicode in one form
    or another (typically using UTF-8 or UTF-16 encoding). Despite the obvious problems
    with dealing with multibyte character sets, modern programs need to deal with
    Unicode strings rather than simple ASCII strings. Swift, which is almost “pure
    Unicode,” doesn’t even offer much in the way of standard ASCII character support.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.7 Unicode String Functions and Performance**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Unicode strings have one fundamental problem: because Unicode is a multibyte
    character set, the number of bytes in a character string is not equal to the number
    of characters (or, more importantly, the number of glyphs) in the string. Unfortunately,
    the only way to determine the length of a string is to scan all bytes in the string
    (from the beginning to the end) and count those characters. In this respect, the
    performance of a Unicode string length function will be proportional to the size
    of the string, just as it is for zero-terminated strings.'
  prefs: []
  type: TYPE_NORMAL
- en: Worse still, the only way to compute the index of a character position in a
    string (that is, the offset in bytes from the beginning of the string) is to scan
    from the beginning of the string and count off the desired number of characters.
    Even zero-terminated (ASCII) strings don’t suffer from this problem. In Unicode,
    functions like substring or insert/delete characters in a string can be very expensive.
  prefs: []
  type: TYPE_NORMAL
- en: The Swift standard library’s string function performance suffers as a result
    of the language’s Unicode purity. Swift programmers have to exercise caution when
    processing strings because operations that would normally be fast in C/C++ or
    other languages can be a source of performance problems in Swift’s Unicode environment.
  prefs: []
  type: TYPE_NORMAL
- en: '**10.8 For More Information**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Hyde, Randall. *The Art of Assembly Language*. 2nd ed. San Francisco: No Starch
    Press, 2010.'
  prefs: []
  type: TYPE_NORMAL
- en: '———. *Write Great Code, Volume 1: Understanding the Machine*. 2nd ed. San Francisco:
    No Starch Press, 2020.'
  prefs: []
  type: TYPE_NORMAL
