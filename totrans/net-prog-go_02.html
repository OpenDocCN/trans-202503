<html><head></head><body>
<section>&#13;
<header>&#13;
<h1 class="chapter">&#13;
<span class="ChapterNumber"><span epub:type="pagebreak" id="Page_3" title="3"/>1</span><br/>&#13;
<span class="ChapterTitle">An Overview of Networked Systems</span>&#13;
</h1>&#13;
</header>&#13;
<figure class="opener">&#13;
<img alt="" src="image_fi/book_art/chapterart.png"/>&#13;
</figure>&#13;
<p class="ChapterIntro">In the digital age, an increasing number of devices communicate over computer networks. A <em>computer network</em> is a connection between two or more devices, or <em>nodes</em>, that allows each node to share data. These connections aren’t inherently reliable or secure. Thankfully, Go’s standard library and its rich ecosystem are well suited for writing secure, reliable network applications.</p>&#13;
<p>This chapter will give you the foundational knowledge needed for this book’s exercises. You’ll learn about the structure of networks and how networks use protocols to communicate.</p>&#13;
<h2 id="h1-500884c01-0001">Choosing a Network Topology</h2>&#13;
<p class="BodyFirst">The organization of nodes in a network is called its<em> topology. </em>A network’s topology can be as simple as a single connection between two nodes or as <span epub:type="pagebreak" id="Page_4" title="4"/>complex as a layout of nodes that don’t share a direct connection but are nonetheless able to exchange data. That’s generally the case for connections between your computer and nodes on the internet. Topology types fall into six basic categories: point-to-point, daisy chain, bus, ring, star, and mesh.</p>&#13;
<p>In the simplest network,<em> point-to-point</em>, two nodes share a single connection (<a href="#figure1-1" id="figureanchor1-1">Figure 1-1</a>). This type of network connection is uncommon, though it is useful when direct communication is required between two nodes.</p>&#13;
<figure>&#13;
<img alt="f01001" src="image_fi/500884c01/f01001.png"/>&#13;
<figcaption><p><a id="figure1-1">Figure 1-1</a>: A direct connection between two nodes</p></figcaption>&#13;
</figure>&#13;
<p>A series of point-to-point connections creates a <em>daisy chain</em>. In the daisy chain in <a href="#figure1-2" id="figureanchor1-2">Figure 1-2</a>, traffic from node C, destined for node F, must traverse nodes D and E. Intermediate nodes between an origin node and a destination node are commonly known as <em>hops</em>. You are unlikely to encounter this topology in a modern network.</p>&#13;
<figure>&#13;
<img alt="f01002" src="image_fi/500884c01/f01002.png"/>&#13;
<figcaption><p><a id="figure1-2">Figure 1-2</a>: Point-to-point segments joined in a daisy chain</p></figcaption>&#13;
</figure>&#13;
<p><em>Bus</em> topology nodes share a common network link. Wired bus networks aren’t common, but this type of topology drives wireless networks. The nodes on a wired network see all the traffic and selectively ignore or accept it, depending on whether the traffic is intended for them. When node H sends traffic to node L in the bus diagram in <a href="#figure1-3" id="figureanchor1-3">Figure 1-3</a>, nodes I, J, K, and M receive the traffic but ignore it. Only node L accepts the data because it’s the intended recipient. Although wireless clients can see each other’s traffic, traffic is usually encrypted.</p>&#13;
<figure>&#13;
<img alt="f01003" src="image_fi/500884c01/f01003.png"/>&#13;
<figcaption><p><a id="figure1-3">Figure 1-3</a>: Nodes connected in a bus topology</p></figcaption>&#13;
</figure>&#13;
<p><span epub:type="pagebreak" id="Page_5" title="5"/>A <em>ring</em> topology, which was used in some fiber-optic network deployments, is a closed loop in which data travels in a single direction. In <a href="#figure1-4" id="figureanchor1-4">Figure 1-4</a>, for example, node N could send a message destined for node R by way of nodes O, P, and Q. Nodes O, P, and Q retransmit the message until it reaches node R. If node P fails to retransmit the message, it will never reach its destination. Because of this design, the slowest node can limit the speed at which data travels. Assuming traffic travels clockwise and node Q is the slowest, node Q slows traffic sent from node O to node N. However, traffic sent from node N to node O is not limited by node Q’s slow speed since that traffic does not traverse node Q.</p>&#13;
<figure>&#13;
<img alt="f01004" src="image_fi/500884c01/f01004.png"/>&#13;
<figcaption><p><a id="figure1-4">Figure 1-4</a>: Nodes arranged in a ring, with traffic traveling in a single direction</p></figcaption>&#13;
</figure>&#13;
<p>In a <em>star</em> topology, a central node has individual point-to-point connections to all other nodes. You will likely encounter this network topology in wired networks. The central node, as shown in <a href="#figure1-5" id="figureanchor1-5">Figure 1-5</a>, is often a <em>network switch</em>, which is a device that accepts data from the origin nodes and retransmits data to the destination nodes, like a postal service. Adding nodes is a simple matter of connecting them to the switch. Data can traverse only a single hop within this topology.</p>&#13;
<figure>&#13;
<img alt="f01005" src="image_fi/500884c01/f01005.png"/>&#13;
<figcaption><p><a id="figure1-5">Figure 1-5</a>: Nodes connected to a central node, which handles traffic between nodes</p></figcaption>&#13;
</figure>&#13;
<p>Every node in a fully connected <em>mesh</em> network has a direct connection to every other node (<a href="#figure1-6" id="figureanchor1-6">Figure 1-6</a>). This topology eliminates single points of failure because the failure of a single node doesn’t affect traffic between any other nodes on the network. On the other hand, costs and complexity increase as the number of nodes increases, making this topology untenable for large-scale networks. This is another topology you may encounter only in larger wireless networks.</p>&#13;
<span epub:type="pagebreak" id="Page_6" title="6"/><figure>&#13;
<img alt="f01006" src="image_fi/500884c01/f01006.png"/>&#13;
<figcaption><p><a id="figure1-6">Figure 1-6</a>: Interconnected nodes in a mesh network</p></figcaption>&#13;
</figure>&#13;
<p>You can also create a hybrid network topology by combining two or more basic topologies. Real-world networks are rarely composed of just one network topology. Rather, you are likely to encounter hybrid topologies. <a href="#figure1-7" id="figureanchor1-7">Figure 1-7</a> shows two examples. The <em>star-ring</em> hybrid network is a series of ring networks connected to a central node. The <em>star-bus</em> hybrid network is a hierarchical topology formed by the combination of bus and star network topologies.</p>&#13;
<figure>&#13;
<img alt="f01007" src="image_fi/500884c01/f01007.png"/>&#13;
<figcaption><p><a id="figure1-7">Figure 1-7</a>: The star-ring and star-bus hybrid topologies</p></figcaption>&#13;
</figure>&#13;
<p>Hybrid topologies are meant to improve reliability, scalability, and flexibility by taking advantage of each topology’s strengths and by limiting the disadvantages of each topology to individual network segments.</p>&#13;
<p>For example, the failure of the central node in the <em>star-ring</em> hybrid in <a href="#figure1-7">Figure 1-7</a> would affect inter-ring communication only. Each ring network would continue to function normally despite its isolation from the other rings. The failure of a single node in a ring would be much easier to diagnose in a star-ring hybrid network than in a single large ring network. Also, the outage would affect only a subset of the overall network.</p>&#13;
<h2 id="h1-500884c01-0002">Bandwidth vs. Latency</h2>&#13;
<p class="BodyFirst">Network <em>bandwidth</em> is the amount of data we can send over a network connection in an interval of time. If your internet connection is advertised as <em><span epub:type="pagebreak" id="Page_7" title="7"/>100Mbps download</em>, that means your internet connection should theoretically be able to transfer up to 100 megabits every second from your internet service provider (ISP) to your modem. </p>&#13;
<p>ISPs inundate us with advertisements about the amount of bandwidth they offer, so much so that it’s easy for us to fixate on bandwidth and equate it with the speed of the connection. However, faster doesn’t always mean greater performance. It may seem counterintuitive, but a lower-bandwidth network connection may seem to have better performance than a higher-bandwidth network connection because of one characteristic: latency.</p>&#13;
<p>Network <em>latency</em> is a measure of the time that passes between sending a network resource request and receiving a response. An example of latency is the delay that occurs between clicking a link on a website and the site’s rendering the resulting page. You’ve probably experienced the frustration of clicking a link that fails to load before your web browser gives up on ever receiving a reply from the server. This happens when the latency is greater than the maximum amount of time your browser will wait for a reply. </p>&#13;
<p>High latency can negatively impact the user experience, lead to attacks that make your service inaccessible to its users, and drive users away from your software or service. The importance of managing latency in network software is often underappreciated by software developers. Don’t fall into the trap of thinking that bandwidth is all that matters for optimal network performance.</p>&#13;
<p>A website’s latency comes from several sources: the network latency between the client and server, the time it takes to retrieve data from a data store, the time it takes to compile dynamic content on the server side, and the time it takes for the web browser to render the page. If a user clicks a link and the page takes too long to render, the user likely won’t stick around for the results, and the latency will drive traffic away from your application. Keeping latency to a minimum while writing network software, be it web applications or application-programming interfaces, will pay dividends by improving the user experience and your application’s ranking in popular search engines.</p>&#13;
<p>You can address the most common sources of latency in several ways. First, you can reduce both the distance and the number of hops between users and your service by using a content delivery network (CDN) or cloud infrastructure to locate your service near your users. Optimizing the request and response sizes will further reduce latency. Incorporating a caching strategy in your network applications can have dramatic effects on performance. Finally, taking advantage of Go’s concurrency to minimize server-side blocking of the response can help. We’ll focus on this in the later chapters of this book.</p>&#13;
<h2 id="h1-500884c01-0003">The Open Systems Interconnection Reference Model</h2>&#13;
<p class="BodyFirst">In the 1970s, as computer networks became increasingly complex, researchers created the <em>Open Systems Interconnection (OSI) reference model</em> to standardize <span epub:type="pagebreak" id="Page_8" title="8"/>networking. The OSI reference model serves as a framework for the development of and communication about protocols. <em>Protocols</em> are rules and procedures that determine the format and order of data sent over a network. For example, communication using the <em>Transmission Control Protocol</em><em>(TCP)</em> requires the recipient of a message to reply with an acknowledgment of receipt. Otherwise, TCP may retransmit the message.</p>&#13;
<p>Although OSI is less relevant today than it once was, it’s still important to be familiar with it so you’ll understand common concepts, such as lower-level networking and routing, especially with respect to the involved hardware.</p>&#13;
<h3 id="h2-500884c01-0001">The Hierarchal Layers of the OSI Reference Model</h3>&#13;
<p class="BodyFirst">The OSI reference model divides all network activities into a strict hierarchy composed of seven layers. Visual representations of the OSI reference model, like the one in <a href="#figure1-8" id="figureanchor1-8">Figure 1-8</a>, arrange the layers into a stack, with Layer 7 at the top and Layer 1 at the bottom.</p>&#13;
<figure>&#13;
<img alt="f01008" src="image_fi/500884c01/f01008.png"/>&#13;
<figcaption><p><a id="figure1-8">Figure 1-8</a>: Seven layers of the OSI reference model</p></figcaption>&#13;
</figure>&#13;
<p>It’s easy to interpret these layer designations as independent units of code. Rather, they describe abstractions we ascribe to parts of our software. For example, there is no <em>Layer 7</em> library you can incorporate into your software. But you can say that the software you wrote implements a service at Layer 7. The seven layers of the OSI model are as follows:</p>&#13;
<ol class="none">&#13;
<li><span class="RunInHead">Layer 7—application layer</span>  Your network applications and libraries most often interact with the application layer, which is responsible for identifying hosts and retrieving resources. Web browsers, Skype, and bit torrent clients are examples of Layer 7 applications.</li>&#13;
<li><span epub:type="pagebreak" id="Page_9" title="9"/><span class="RunInHead">Layer 6—presentation layer</span>  The presentation layer prepares data for the network layer when that data is moving down the stack, and it presents data to the application layer when that data moves up the stack. Encryption, decryption, and data encoding are examples of Layer 6 functions.</li>&#13;
<li><span class="RunInHead">Layer 5—session layer</span>  The session layer manages the connection life cycle between nodes on a network. It’s responsible for establishing the connection, managing connection time-outs, coordinating the mode of operation, and terminating the connection. Some Layer 7 protocols rely on services provided by Layer 5.</li>&#13;
<li><span class="RunInHead">Layer 4—transport layer</span>  The transport layer controls and coordinates the transfer of data between two nodes while maintaining the reliability of the transfer. Maintaining the reliability of the transfer includes correcting errors, controlling the speed of data transfer, chunking or segmenting the data, retransmitting missing data, and acknowledging received data. Often protocols in this layer might retransmit data if the recipient doesn’t acknowledge receipt of the data.</li>&#13;
<li><span class="RunInHead">Layer 3—network layer</span>  The network layer is responsible for transmitting data between nodes. It allows you to send data to a network address without having a direct point-to-point connection to the remote node. OSI does not require protocols in this layer to provide reliable transport or report transmission errors to the sender. The network layer is home to network management protocols involved in routing, addressing, multicasting, and traffic control. The next chapter covers these topics.</li>&#13;
<li><span class="RunInHead">Layer 2—data link layer</span>  The data link layer handles data transfers between two directly connected nodes. For example, the data link layer facilitates data transfer from a computer to a switch and from the switch to another computer. Protocols in this layer identify and attempt to correct errors on the physical layer.</li>&#13;
<li>The data link layer’s retransmission and flow control functions are dependent on the underlying physical medium. For example, Ethernet does not retransmit incorrect data, whereas wireless does. This is because bit errors on Ethernet networks are infrequent, whereas they’re common over wireless. Protocols further up the network protocol stack can ensure that the data transmission is reliable if this layer doesn’t do so, though generally with less efficiency.</li>&#13;
<li><span class="RunInHead">Layer 1—physical layer</span>  The physical layer converts bits from the network stack to electrical, optic, or radio signals suitable for the underlying physical medium and from the physical medium back into bits. This layer controls the bit rate. The bit rate is the data speed limit. A gigabit per second bit rate means data can travel at a maximum of 1 billion bits per second between the origin and destination.</li>&#13;
</ol>&#13;
<p><span epub:type="pagebreak" id="Page_10" title="10"/>A common confusion when discussing network transmission rates is using bytes per second instead of bits per second. We count the number of zeros and ones, or <em>bits</em>, we can transfer per second. Therefore, network transmission rates are measured in bits per second. We use bytes per second when discussing the amount of data transferred.</p>&#13;
<p>If your ISP advertises a 100Mbps download rate, that doesn’t mean you can download a 100MB file in one second. Rather, it may take closer to eight seconds under ideal network conditions. It’s appropriate to say we can transfer a maximum of 12.5MB per second over the 100Mbps connection.</p>&#13;
<h3 id="h2-500884c01-0002">Sending Traffic by Using Data Encapsulation</h3>&#13;
<p class="BodyFirst"><em>Encapsulation</em> is a method of hiding implementation details or making only relevant details available to the recipient. Think of encapsulation as being like a package you send through the postal service. We could say that the envelope encapsulates its contents. In doing so, it may include the destination address or other crucial details used by the next leg of its journey. The actual contents of your package are irrelevant; only the details on the package are important for transport.</p>&#13;
<p>As data travels down the stack, it’s encapsulated by the layer below. We typically call the data traveling down the stack a <em>payload</em>, although you might see it referred to as a <em>message body</em>. The literature uses the term <em>service data unit</em><em>(SDU)</em>. For example, the transport layer encapsulates payloads from the session layer, which in turn encapsulates payloads from the presentation layer. When the payload moves up the stack, each layer strips the header information from the previous stack.</p>&#13;
<p>Even protocols that operate in a single OSI layer use data encapsulation. Take version 1 of the <em>HyperText Transfer Protocol</em><em>(HTTP/1)</em>, for example, a Layer 7 protocol that both the client and the server use to exchange web content. HTTP defines a complete message, including header information, that the client sends from its Layer 7 to the server’s Layer 7; the network stack delivers the client’s request to the HTTP server application. The HTTP server application initiates a response to its network stack, which creates a Layer 7 payload and sends it back to the client’s Layer 7 application (<a href="#figure1-9" id="figureanchor1-9">Figure 1-9</a>).</p>&#13;
<p>Communication between the client and the server on the same layer is called <em>horizontal communication, </em>a term that makes it sound like a single-layer protocol on the client directly communicates with its counterpart on the server. In fact, in horizontal communication, data must travel all the way down the client’s stack, then back up the server’s stack.</p>&#13;
<p>For example, <a href="#figure1-10" id="figureanchor1-10">Figure 1-10</a> shows how an HTTP request traverses the stack.</p>&#13;
<p>Generally, a payload travels down the client’s network stack, over physical media to the server, and up the server’s network stack to its corresponding layer. The result is that data sent from one layer at the origin node arrives at the same layer on the destination node. The server’s response takes the same path in the opposite direction. On the client’s side, Layer 6 receives Layer 7’s <span epub:type="pagebreak" id="Page_11" title="11"/>payload, then encapsulates the payload with a header to create Layer 6’s payload. Layer 5 receives Layer 6’s payload, adds its own header, and sends its payload on to Layer 4, where we’re introduced to our first transmission protocol: TCP.</p>&#13;
<figure>&#13;
<img alt="f01009" src="image_fi/500884c01/f01009.png"/>&#13;
<figcaption><p><a id="figure1-9">Figure 1-9</a>: Horizontal communication from the client to the server and back</p></figcaption>&#13;
</figure>&#13;
<figure>&#13;
<img alt="f01010" src="image_fi/500884c01/f01010.png"/>&#13;
<figcaption><p><a id="figure1-10">Figure 1-10</a>: An HTTP request traveling from Layer 7 on the client to Layer 7 on the server</p></figcaption>&#13;
</figure>&#13;
<p><span epub:type="pagebreak" id="Page_12" title="12"/>TCP is a Layer 4 protocol whose payloads are also known as <em>segments</em> or <em>datagrams</em>. TCP accepts Layer 5’s payload and adds its header before sending the segment on to Layer 3. The <em>Internet Protocol</em><em>(IP)</em> at Layer 3 receives the TCP segment and encapsulates it with a header to create Layer 3’s payload, which is known as a <em>packet</em>. Layer 2 accepts the packet and adds a header and a footer, creating its payload, called a <em>frame</em>. Layer 2’s header translates the recipient’s IP address into a <em>media access control</em><em>(MAC)</em> address, which is a unique identifier assigned to the node’s network interface. Its footer contains a <em>frame check sequence</em><em>(FCS)</em>, which is a checksum to facilitate error detection. Layer 1 receives Layer 2’s payload in the form of bits and sends the bits to the server. </p>&#13;
<p>The server’s Layer 1 receives the bits, converts them to a frame, and sends the frame up to Layer 2. Layer 2 strips its header and footer from the frame and passes the packet up to Layer 3. The process of reversing each layer’s encapsulation continues up the stack until the payload reaches Layer 7. Finally, the HTTP server receives the client’s request from the network stack.</p>&#13;
<h2 id="h1-500884c01-0004">The TCP/IP Model</h2>&#13;
<p class="BodyFirst">Around the same time as researchers were developing the OSI reference model, the Defense Advanced Research Projects Agency (DARPA), an agency of the US Department of Defense, spearheaded a parallel effort to develop protocols. This effort resulted in a set of protocols we now call the <em>TCP/IP model</em>. The project’s impact on the US military, and subsequently the world’s communications, was profound. The TCP/IP model reached critical mass when Microsoft incorporated it into Windows 95 in the early 1990s. Today, TCP/IP is ubiquitous in computer networking, and it’s the protocol stack we’ll use in this book.</p>&#13;
<p>TCP/IP—named for the Transmission Control Protocol and the Internet Protocol—facilitated networks designed using the <em>end-to-end principle</em>, whereby each network segment includes only enough functionality to properly transmit and route bits; all other functionality belongs to the endpoints, or the sender and receiver’s network stacks. Contrast this with modern cellular networks, where more of the network functionality must be provided by the network between cell phones to allow for a cell phone connection to jump from tower to tower without disconnecting its phone call. The TCP/IP specification recommends that implementations be robust; they should send well-formed packets yet accept any packet whose intention is clear, regardless of whether the packet adheres to technical specifications. </p>&#13;
<p>Like the OSI reference model, TCP/IP relies on layer encapsulation to abstract functionality. It consists of four named layers: the application, transport, internet, and link layers. TCP/IP’s application and link layers generalize their OSI counterparts, as shown in <a href="#figure1-11" id="figureanchor1-11">Figure 1-11</a>.</p>&#13;
<span epub:type="pagebreak" id="Page_13" title="13"/><figure>&#13;
<img alt="f01011" src="image_fi/500884c01/f01011.png"/>&#13;
<figcaption><p><a id="figure1-11">Figure 1-11</a>: The four-layer TCP/IP model compared to the seven-layer OSI reference model</p></figcaption>&#13;
</figure>&#13;
<p>The TCP/IP model simplifies OSI’s application, presentation, and session layers into a single application layer, primarily because TCP/IP’s protocols frequently cross boundaries of OSI Layers 5 through 7. Likewise, OSI’s data link and physical layers correspond to TCP/IP’s link layer. TCP/IP’s and OSI’s transport and network layers share a one-to-one relationship.</p>&#13;
<p>This simplification exists because researchers developed prototype implementations first and then formally standardized their final implementation, resulting in a model geared toward practical use. On the other hand, committees spent considerable time devising the OSI reference model to address a wide range of requirements before anyone created an implementation, leading to the model’s increased complexity.</p>&#13;
<h3 id="h2-500884c01-0003">The Application Layer</h3>&#13;
<p class="BodyFirst">Like OSI’s application layer, the TCP/IP model’s <em>application layer</em> interacts directly with software applications. Most of the software we write uses protocols in this layer, and when your web browser retrieves a web page, it reads from this layer of the stack.</p>&#13;
<p>You’ll notice that the TCP/IP application layer encompasses three OSI layers. This is because TCP/IP doesn’t define specific presentation or session functions. Instead, the specific application protocol implementations concern themselves with those details. As you’ll see, some TCP/IP application layer protocols would be hard-pressed to fit neatly into a single upper layer of the OSI model, because they have functionality that spans more than one OSI layer.</p>&#13;
<p>Common TCP/IP application layer protocols include HTTP, the <em>File Transfer Protocol</em><em>(FTP)</em> for file transfers between nodes, and the <em>Simple Mail Transfer Protocol</em><em>(SMTP)</em> for sending email to mail servers. The <em><span epub:type="pagebreak" id="Page_14" title="14"/>Dynamic Host Configuration Protocol</em><em>(DHCP)</em> and the <em>Domain Name System</em><em>(DNS)</em> also function in the application layer. DHCP and DNS provide the addressing and name resolution services, respectively, that allow other application layer protocols to operate. HTTP, FTP, and SMTP are examples of protocol implementations that provide the presentation or session functionality in TCP/IP’s application layer. We’ll discuss these protocols in later chapters.</p>&#13;
<h3 id="h2-500884c01-0004">The Transport Layer</h3>&#13;
<p class="BodyFirst"><em>Transport layer</em> protocols handle the transfer of data between two nodes, like OSI’s Layer 4. These protocols can help ensure <em>data integrity</em> by making sure that all data sent from the origin completely and correctly makes its way to the destination. Keep in mind that data integrity doesn’t mean the destination will receive all segments we send through the transport layer. There are just too many causes of packet loss over a network. It does mean that TCP specifically will make sure the data received by the destination is in the correct order, without duplicate data or missing data.</p>&#13;
<p>The primary transport layer protocols you’ll use in this book are TCP and the <em>User Datagram Protocol (UDP)</em>. As mentioned in <span class="xref" itemid="xref_target_“Sending Traffic by Using Data Encapsulation” on page 10">“Sending Traffic by Using Data Encapsulation” on page 10</span>, this layer handles segments, or datagrams. </p>&#13;
<aside epub:type="sidebar">&#13;
<div class="top hr"><hr/></div>&#13;
<section class="note">&#13;
<h2><span class="NoteHead">NOTE</span></h2>&#13;
<p>TCP also overlaps a bit with OSI’s Layer 5, because TCP includes session-handling capabilities that would otherwise fall under the scope of OSI’s session layer. But, for our purposes, it’s okay to generalize the transport layer as representing OSI’s Layer 4.</p>&#13;
<div class="bottom hr"><hr/></div>&#13;
</section>&#13;
</aside>&#13;
<p>Most of our network applications rely on the transport layer protocols to handle the error correction, flow control, retransmission, and transport acknowledgment of each segment. However, the TCP/IP model doesn’t require every transport layer protocol to fulfill each of those elements. UDP is one such example. If your application requires the use of UDP for maximal throughput, the onus is on you to implement some sort of error checking or session management, since UDP provides neither.</p>&#13;
<h3 id="h2-500884c01-0005">The Internet Layer</h3>&#13;
<p class="BodyFirst">The <em>internet layer</em> is responsible for routing packets of data from the upper layers between the origin node and the destination node, often over multiple networks with heterogeneous physical media. It has the same functions as OSI’s Layer 3 network layer. (Some sources may refer to TCP/IP’s internet layer as the <em>network layer</em>.)</p>&#13;
<p><em>Internet Protocol version 4 (IPv4)</em>, <em>Internet Protocol version 6 (IPv6)</em>, <em>Border Gateway Protocol</em><em>(BGP)</em>, <em>Internet Control Message Protocol</em><em>(ICMP)</em>, <em>Internet Group Management Protocol (IGMP)</em>, and the <em>Internet Protocol Security</em><em>(IPsec)</em> suite, among others, provide host identification and routing to TCP/IP’s internet layer. We will cover these protocols in the next chapter, when we discuss <span epub:type="pagebreak" id="Page_15" title="15"/>host addressing and routing. For now, know that this layer plays an integral role in ensuring that the data we send reaches its destination, no matter the complexity between the origin and destination.</p>&#13;
<h3 id="h2-500884c01-0006">The Link Layer</h3>&#13;
<p class="BodyFirst">The <em>link layer</em>, which corresponds to Layers 1 and 2 of the OSI reference model, is the interface between the core TCP/IP protocols and the physical media.</p>&#13;
<p>The link layer’s <em>Address Resolution Protocol</em><em>(ARP)</em> translates a node’s IP address to the MAC address of its network interface. The link layer embeds the MAC address in each frame’s header before passing the frame on to the physical network. We’ll discuss MAC addresses and their routing significance in the next chapter.</p>&#13;
<p>Not all TCP/IP implementations include link layer protocols. Older readers may remember the joys of connecting to the internet over phone lines using analog modems. Analog modems made serial connections to ISPs. These serial connections didn’t include link layer support via the serial driver or modem. Instead, they required the use of link layer protocols, such as the <em>Serial Line Internet Protocol</em><em>(SLIP)</em> or the <em>Point-to-Point Protocol</em><em>(PPP)</em>, to fill the void. Those that do not implement a link layer typically rely on the underlying network hardware and device drivers to pick up the slack. The TCP/IP implementations over Ethernet, wireless, and fiber-optic networks we’ll use in this book rely on device drivers or network hardware to fulfill the link layer portion of their TCP/IP stack.</p>&#13;
<h2 id="h1-500884c01-0005">What You’ve Learned</h2>&#13;
<p class="BodyFirst">In this chapter, you learned about common network topologies and how to combine those topologies to maximize their advantages and minimize their disadvantages. You also learned about the OSI and TCP/IP reference models, their layering, and data encapsulation. You should feel comfortable with the order of each layer and how data moves from one layer to the next. Finally, you learned about each layer’s function and the role it plays in sending and receiving data between nodes on a network.</p>&#13;
<p>This chapter’s goal was to give you enough networking knowledge to make sense of the next chapter. However, it’s important that you explore these topics in greater depth, because comprehensive knowledge of networking principles and architectures can help you devise better algorithms. I’ll suggest additional reading for each of the major topics covered in this chapter to get you started. I also recommend you revisit this chapter after working through some of the examples in this book.</p>&#13;
<p>The OSI reference model is available for reading online at <a class="LinkURL" href="https://www.itu.int/rec/T-REC-X.200-199407-I/en/">https://www.itu.int/rec/T-REC-X.200-199407-I/en/</a>. Two Requests for Comments (RFCs)—detailed publications meant to describe internet technologies—outline the TCP/IP reference model: RFC 1122 and RFC 1123 (<a class="LinkURL" href="https://tools.ietf.org/html/rfc1122/">https://tools.ietf.org/html/rfc1122/</a> and <a class="LinkURL" href="https://tools.ietf.org/html/rfc1123/">https://tools.ietf.org/html/rfc1123/</a>). RFC 1122 covers the lower <span epub:type="pagebreak" id="Page_16" title="16"/>three layers of the TCP/IP model, whereas RFC 1123 describes the application layer and support protocols, such as DNS. If you’d like a more comprehensive reference for the TCP/IP model, you’d be hard-pressed to do better than <em>The TCP/IP Guide</em> by Charles M. Kozierok (No Starch Press, 2005).</p>&#13;
<p>Network latency has plagued countless network applications and spawned an industry. Some CDN providers write prolifically on the topic of latency and interesting issues they’ve encountered while improving their offerings. CDN blogs that provide insightful posts include the Cloudflare Blog (<a class="LinkURL" href="https://blog.cloudflare.com/">https://blog.cloudflare.com/</a>), the KeyCDN Blog (<a class="LinkURL" href="https://www.keycdn.com/blog/">https://www.keycdn.com/blog/</a>), and the Fastly Blog (<a class="LinkURL" href="https://www.fastly.com/blog/">https://www.fastly.com/blog/</a>). If you’re purely interested in learning more about latency and its sources, consider “Latency (engineering)” on Wikipedia (<a class="LinkURL" href="https://en.wikipedia.org/wiki/Latency_(engineering)">https://en.wikipedia.org/wiki/Latency_(engineering)</a>) and Cloudflare’s glossary (<a class="LinkURL" href="https://www.cloudflare.com/learning/performance/glossary/what-is-latency/">https://www.cloudflare.com/learning/performance/glossary/what-is-latency/</a>) as starting points.</p>&#13;
</section>&#13;
</body></html>