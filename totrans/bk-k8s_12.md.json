["```\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n  nodeSelector:\n ➊ purpose: special\n```", "```\nroot@host01:~# kubectl apply -f /opt/nginx-selector.yaml\npod/nginx created\n```", "```\nroot@host01:~# kubectl get pods -o wide\nNAME    READY   STATUS    RESTARTS   AGE    IP       NODE     ...\nnginx   0/1     Pending   0          113s   <none>   <none>   ...\n```", "```\nroot@host01:~# kubectl describe pod nginx\nName:         nginx\nNamespace:    default\n...\nStatus:       Pending\n...\nNode-Selectors:              purpose=special\n\nEvents:\n  Type     Reason            Age    From               Message\n  ----     ------            ----   ----               -------\n  Warning  FailedScheduling  4m36s  default-scheduler  0/3 nodes are \n    available: 3 node(s) didn't match Pod's node affinity/selector.\n  Warning  FailedScheduling  3m16s  default-scheduler  0/3 nodes are \n    available: 3 node(s) didn't match Pod's node affinity/selector.\n```", "```\nroot@host01:~# kubectl get nodes\nNAME     STATUS   ROLES        ...\nhost01   Ready    control-plane...\nhost02   Ready    control-plane...\nhost03   Ready    control-plane...\nroot@host01:~# kubectl label nodes host02 purpose=special\nnode/host02 labeled\n```", "```\nroot@host01:~# kubectl get pods -o wide\nNAME    READY   STATUS    RESTARTS   AGE   IP               NODE     ...\nnginx   1/1     Running   0          10m   172.31.89.196   host02   ...\nroot@host01:~# kubectl describe pod nginx\nName:         nginx\nNamespace:    default\n...\nEvents:\n  Type     Reason            Age    From               Message\n  ----     ------            ----   ----               -------\n  Warning  FailedScheduling  10m    default-scheduler  0/3 nodes are \n    available: 3 node(s) didn't match Pod's node affinity/selector.\n Warning  FailedScheduling  9m17s  default-scheduler  0/3 nodes are \n    available: 3 node(s) didn't match Pod's node affinity/selector.\n  Normal   Scheduled         2m22s  default-scheduler  Successfully assigned \n    default/nginx to host02\n...\n```", "```\nroot@host01:~# kubectl delete -f /opt/nginx-selector.yaml\npod \"nginx\" deleted\n```", "```\nroot@host01:~# kubectl label nodes host02 purpose-\nnode/host02 unlabeled\n```", "```\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sleep\nspec:\n  containers:\n  - name: sleep\n    image: busybox\n command: \n      - \"/bin/sleep\"\n      - \"3600\"\n    resources:\n      requests:\n        cpu: \"2\"\n  - name: sleep2\n    image: busybox\n    command: \n      - \"/bin/sleep\"\n      - \"3600\"\n    resources:\n      requests:\n        cpu: \"2\"\n```", "```\nroot@host01:~# kubectl apply -f /opt/sleep-multiple.yaml\npod/sleep created\nroot@host01:~# kubectl get pods -o wide\nNAME    READY   STATUS    RESTARTS   AGE   IP       NODE   ...\nsleep   0/2     Pending   0          7s    <none>   <none> ...\n```", "```\nroot@host01:~# kubectl describe pod sleep\nName:         sleep\nNamespace:    default\n...\nEvents:\n  Type     Reason            Age   From               Message\n  ----     ------            ----  ----               -------\n  Warning  FailedScheduling  71s   default-scheduler  0/3 nodes are \n    available: 3 Insufficient cpu.\n```", "```\nroot@host01:~# kubectl top node\nNAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \nhost01   429m         21%    1307Mi          69%\nhost02   396m         19%    1252Mi          66%\nhost03   458m         22%    1277Mi          67%\n```", "```\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sleep\nspec:\n  containers:\n  - name: sleep\n    image: busybox\n    command: \n      - \"/bin/sleep\"\n      - \"3600\"\n    resources:\n      requests:\n     ➊ cpu: \"100m\"\n  - name: sleep2\n    image: busybox\n    command: \n      - \"/bin/sleep\"\n      - \"3600\"\n    resources:\n      requests:\n        cpu: \"100m\"\n```", "```\nroot@host01:~# kubectl apply -f /opt/sleep-sensible.yaml\nThe Pod \"sleep\" is invalid: spec: Forbidden: pod updates may not change \n  fields other than ...\n```", "```\nroot@host01:~# kubectl delete pod sleep\npod \"sleep\" deleted\nroot@host01:~# kubectl apply -f /opt/sleep-sensible.yaml\npod/sleep created\n```", "```\nroot@host01:~# kubectl get pods -o wide\nNAME    READY   STATUS    RESTARTS   AGE   IP               NODE  ...\nsleep   2/2     Running   0          51s   172.31.89.199   host02 ...\n```", "```\nroot@host01:~# kubectl describe node host02\nName:               host02\n...\nCapacity:\n  cpu:                2\n...\nNon-terminated Pods:          (10 in total)\n  Namespace  Name     CPU Requests  CPU Limits  ...\n  ---------  ----     ------------  ----------  ...\n...\n  default    sleep ➊ 200m (10%)    0 (0%)      ... \n...\n```", "```\nroot@host01:~# kubectl delete pod sleep\npod \"sleep\" deleted\n```", "```\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginz\n```", "```\nroot@host01:~# kubectl apply -f /opt/nginx-typo.yaml\npod/nginx created\nroot@host01:~# kubectl get pods\nNAME    READY   STATUS             RESTARTS   AGE\nnginx   0/1     ImagePullBackOff   0          20s\n```", "```\nroot@host01:~# kubectl describe pod nginx\nName:         nginx\nNamespace:    default\n...\nStatus:     ➊ Pending \n...\nEvents:\n  Type     Reason     Age                 From               Message\n  ----     ------     ----                ----               -------\n  Normal   Scheduled  114s                default-scheduler  Successfully \n    assigned default/nginx to host03\n...\n  Warning  Failed     25s (x4 over 112s)  kubelet            Failed to pull \n    image \"nginz\": ... ➋ pull access denied, repository does not exist or may \n    require authorization  ...\n...\n  Normal   BackOff    1s ➌ (x7 over 111s)   kubelet            ...\n```", "```\nroot@host01:~# kubectl describe pod nginx\nName:         nginx\nNamespace:    default\n...\nEvents:\n  Type     Reason     Age                   From               Message\n  ----     ------     ----                  ----               -------\n...\n  Normal   BackOff    4m38s (x65 over 19m)  kubelet            ...\n```", "```\nroot@host01:~# kubectl set image pod nginx nginx=nginx\npod/nginx image updated\nroot@host01:~# kubectl get pods\nNAME    READY   STATUS             RESTARTS   AGE\nnginx   0/1     ImagePullBackOff   0          28m\n```", "```\nroot@host01:~# kubectl get pods\nNAME    READY   STATUS    RESTARTS   AGE\nnginx   1/1     Running   0          32m\n```", "```\nroot@host01:~# kubectl delete pod nginx\npod \"nginx\" deleted\n```", "```\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: postgres\nspec:\n  containers:\n  - name: postgres\n    image: postgres\n```", "```\nroot@host01:~# kubectl apply -f /opt/postgres-misconfig.yaml\npod/postgres created\n```", "```\nroot@host01:~# kubectl get pods\nNAME       READY   STATUS             RESTARTS     AGE\npostgres   0/1     CrashLoopBackOff   1 (8s ago)   25s\n```", "```\nroot@host01:~# kubectl get pods\nNAME       READY   STATUS             RESTARTS       AGE\npostgres   0/1     CrashLoopBackOff   5 (117s ago)   5m3s\n```", "```\nroot@host01:~# kubectl describe pod postgres\nName:         postgres\nNamespace:    default\n...\nContainers:\n  postgres:\n...\n    State:          Waiting\n      Reason:       CrashLoopBackOff\n    Last State:     Terminated\n      Reason:       Error\n      Exit Code:    1\n...\nEvents:\n  Type     Reason     Age                    From               Message\n  ----     ------     ----                   ----               -------\n...\n  Warning  BackOff    3m13s (x24 over 8m1s)  kubelet            Back-off \n    restarting failed container\n```", "```\nroot@host01:~# kubectl logs postgres\nError: Database is uninitialized and superuser password is not specified.\n  You must specify POSTGRES_PASSWORD to a non-empty value for the\n  superuser. For example, \"-e POSTGRES_PASSWORD=password\" on \"docker run\".\n...\n```", "```\n---\napiVersion: v1\nkind: Pod\nmetadata:\n name: postgres\nspec:\n  containers:\n  - name: postgres\n    image: postgres\n ➊ env:\n    - name: POSTGRES_PASSWORD\n      value: \"supersecret\"\n```", "```\nroot@host01:~# kubectl delete pod postgres\npod \"postgres\" deleted\nroot@host01:~# kubectl apply -f /opt/postgres-fixed.yaml\npod/postgres created\n```", "```\nroot@host01:~# kubectl get pods\nNAME       READY   STATUS    RESTARTS   AGE\npostgres   1/1     Running   0          77s\n```", "```\nroot@host01:~# kubectl delete pod postgres\npod \"postgres\" deleted\n```", "```\nint main() {\n  char *s = \"12\";\n  s[2] = '3';\n return 0;\n}\n```", "```\n$ gcc -g -static -o crasher crasher.c\n```", "```\nFROM alpine AS builder\nCOPY ./crasher.c /\nRUN apk --update add gcc musl-dev && \\\n    gcc -g -o crasher crasher.c\n\nFROM alpine\nCOPY --from=builder /crasher /crasher\nCMD [ \"/crasher\" ]\n```", "```\n---\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: crasher\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: crasher\n  template:\n    metadata:\n      labels:\n        app: crasher\n    spec:\n      containers:\n      - name: crasher\n        image: bookofkubernetes/crasher:stable\n```", "```\nroot@host01:~# kubectl apply -f /opt/crasher-deploy.yaml\ndeployment.apps/crasher created\n```", "```\nroot@host01:~# kubectl get pods\nNAME                       READY   STATUS             RESTARTS      AGE\ncrasher-76cdd9f769-5blbn   0/1     CrashLoopBackOff   3 (24s ago)   73s\n```", "```\nroot@host01:~# kubectl get pod crasher-7978d9bcfb-wvx6q -o json | \\\n  jq '.status.containerStatuses[].lastState.terminated.exitCode'\n139\n```", "```\nroot@host01:~# kubectl logs crasher-76cdd9f769-5blbn\n[ no output ]\n```", "```\nroot@host01:~# kubectl edit deployment crasher\n```", "```\n    spec:\n      containers:\n      - image: bookofkubernetes/crasher:stable\n        imagePullPolicy: IfNotPresent\n```", "```\n    spec:\n      containers:\n      - image: bookofkubernetes/crasher:stable\n        args: [\"/bin/sleep\", \"infinity\"]\n        imagePullPolicy: IfNotPresent\n```", "```\ndeployment.apps/crasher edited\n```", "```\nroot@host01:~# kubectl get pods\nNAME                       READY   STATUS    RESTARTS   AGE\ncrasher-58d56fc5df-vghbt   1/1     Running   0          3m29s\n```", "```\nroot@host01:~# kubectl exec -ti crasher-58d56fc5df-vghbt -- /bin/sh\n/ #\n```", "```\n/ # /crasher\nSegmentation fault (core dumped)\n```", "```\n/ # apk add gdb\n...\n(13/13) Installing gdb (10.1-r0)\nExecuting busybox-1.32.1-r3.trigger\nOK: 63 MiB in 27 packages\n```", "```\n/ # gdbserver localhost:2345 /crasher\nProcess /crasher created; pid = 25\nListening on port 2345\n```", "```\nroot@host01:~# kubectl port-forward pods/crasher-58d56fc5df-vghbt 2345:2345\nForwarding from 127.0.0.1:2345 -> 2345\nForwarding from [::1]:2345 -> 2345\n```", "```\nroot@host01:~# cd /opt\n```", "```\nroot@host01:/opt# gdb -q\n(gdb) target remote localhost:2345\nRemote debugging using localhost:2345\n...\nReading /crasher from remote target...\nReading symbols from target:/crasher...\n0x0000000000401bc0 in _start ()\n```", "```\n(gdb) continue\nContinuing.\n\nProgram received signal SIGSEGV, Segmentation fault.\nmain () at crasher.c:3\n3         s[2] = '3';\n```"]