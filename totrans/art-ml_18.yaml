- en: '**13'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**13'
- en: HANDLING TIME SERIES AND TEXT DATA**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 处理时间序列和文本数据**
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: 'A *time series* is a dataset indexed by time, usually at regular time intervals.
    Here are some familiar examples:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*时间序列*是按时间索引的数据集，通常是在规律的时间间隔内。这里有一些熟悉的例子：'
- en: Stock market data consisting of the price of a given equity on a daily basis,
    or even hourly, and so on
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 股票市场数据，包括某个特定股票的每日价格，甚至是每小时的价格，等等
- en: Weather data, daily or in even finer granularity
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天气数据，按天或更细粒度的时间尺度
- en: Demographic data, such as the number of births, say, monthly or even yearly,
    to plan for school capacity
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口统计数据，例如每月或甚至每年出生的人数，用于规划学校的容量
- en: Electrocardiogram data measuring electrical activity in the heart at regular
    time intervals
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量心脏电活动的心电图数据，通常在规律的时间间隔内采集
- en: A special type of time series is that of written or spoken speech. Here “time”
    is word positioning. If, say, we are working at the sentence level, and a sentence
    consists of eight words, there would be Word 1, Word 2, and so on through Word
    8, with the index 1 through 8 playing the role of “time.”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一种特殊类型的时间序列是书面或口语的语音数据。在这里，“时间”指的是单词的位置。举个例子，假设我们在句子级别进行工作，一个句子由八个单词组成，那么会有单词1、单词2，一直到单词8，其中索引1到8起到了“时间”的作用。
- en: The field of time series methodology has been highly developed by statisticians,
    economists, and the like. As usual, ML specialists have developed their own methods,
    mainly as applications of neural networks. The methods known as *recurrent neural
    networks (RNNs)* and *long short-term memories (LSTMs)* are especially notable.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列方法学领域已经被统计学家、经济学家等高度发展。像往常一样，机器学习专家们也发展了他们自己的方法，主要是神经网络的应用。被称为*递归神经网络（RNNs）*和*长短期记忆（LSTMs）*的方法尤其值得注意。
- en: Both the statistical and ML approaches use very subtle and intricate techniques
    whose mathematical content is well above the math level of this book. Nevertheless,
    one can still build some very powerful ML applications while sticking to the basics,
    and this chapter will have this theme. It will present methods to apply the `qe*`-series
    functions to general time series problems, and to a special kind of text recognition
    setting (that does not make use of the time series nature of the text).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学和机器学习方法都使用非常精妙和复杂的技术，其数学内容远高于本书的数学水平。然而，即便如此，人们仍然可以在遵循基础原理的同时，构建一些非常强大的机器学习应用，本章将围绕这个主题展开。它将介绍如何将`qe*`-系列函数应用于一般的时间序列问题，以及应用于一种特殊的文本识别设置（这种设置不利用文本的时间序列性质）。
- en: 13.1 Converting Time Series Data to Rectangular Form
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1 将时间序列数据转换为矩形形式
- en: One often hears the terms *rectangular data* and *tabular data* in discussions
    of ML, referring to the usual *n* × *p* data frame or matrix of *n* rows, with
    each row representing one data point of *p* features. As a quick non−time series
    example we’ve used several times in this book, say we are trying to predict human
    weight from height and age, with a sample of 1,000 people. Then we would have
    *n* = 1000 and *p* = 2.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论机器学习时，人们常听到*矩形数据*和*表格数据*这两个术语，指的是通常的*n* × *p*数据框或矩阵，其中*n*是行数，每行代表一个数据点的*p*个特征。作为一个非时间序列的简单例子，我们在本书中使用过好几次，假设我们尝试通过身高和年龄预测体重，样本量为1,000人。那么我们会有*n*
    = 1000 和 *p* = 2。
- en: It’s clear that the words “rectangular” and “tabular” are allusions to the rectangular
    shape or table of the associated data frame or matrix. But this is rather misleading.
    Image data also has the form, such as *n* = 70000 and *p* = 28² = 784 for the
    MNIST data, yet image data is not referred to as rectangular.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，“矩形”和“表格”这两个词是指与相关数据框或矩阵的矩形形状或表格结构。但这其实有些误导。图像数据也有类似的形式，例如对于MNIST数据，*n* =
    70000 和 *p* = 28² = 784，然而图像数据并不被称为矩形数据。
- en: In the case of time series, though, one in fact can convert a time series to
    rectangular form and then apply ML methods, which is what we’ll do here.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在时间序列的情况下，实际上可以将时间序列转换为矩形形式，然后应用机器学习方法，这也是我们在这里要做的。
- en: '***13.1.1 Toy Example***'
  id: totrans-15
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***13.1.1 玩具示例***'
- en: Say our training set time series `x` is (5,12,13,8,88,6). For concreteness,
    let’s say this is daily data, so we have six days of data here, which we’ll call
    day 1, day 2, and so on. On each day, we know the series values up to the present
    and wish to predict the next day.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的训练集时间序列`x`是（5,12,13,8,88,6）。为了具体说明，假设这是每日数据，那么我们这里有六天的数据，分别称为第1天、第2天，依此类推。在每一天，我们知道截至当前的序列值，并希望预测第二天的值。
- en: 'We’ll use a *lag* of 2, which means that we predict a given day by the previous
    two. In `x` above, that means we:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个*滞后*值为 2，这意味着我们通过前两天的数据来预测某一天。在上面的 `x` 中，这意味着我们：
- en: Predict day 3 from the 5 and 12
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据第 5 天和第 12 天预测第 3 天
- en: Predict day 4 from the 12 and 13
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据第 12 天和第 13 天预测第 4 天
- en: Predict day 5 from the 13 and 8
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据第 13 天和第 8 天预测第 5 天
- en: Predict day 6 from the 8 and 88
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据第 8 天和第 88 天预测第 6 天
- en: 'Think of what the above description (“predicting the 13 . . .”) means in terms
    of our usual “X” (features matrix) and “Y” (outcomes vector) notation:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 想想上面描述的内容（“预测第 13... ”）在我们通常的“X”（特征矩阵）和“Y”（结果向量）符号中意味着什么：
- en: '![Image](../images/unch13equ01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/unch13equ01.jpg)'
- en: Note that X has only 4 rows, not 6, and Y is of length 4, not 6\. That is due
    to our lag of 2; we need 2 prior data points. So we cannot even start our analysis
    until day 3.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，X 只有 4 行，不是 6 行，而 Y 的长度是 4，不是 6。这是因为我们有 2 的滞后；我们需要 2 个先前的数据点。因此，在第 3 天之前我们甚至无法开始分析。
- en: Here we will deal only with *univariate* time series. But we can also handle
    the multivariate case—for example, predicting daily temperature, humidity, and
    wind speed from their previous values.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们只处理*单变量*时间序列。但我们也可以处理多变量情况——例如，根据先前的值预测每日的温度、湿度和风速。
- en: '***13.1.2 The regtools Function TStoX()***'
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***13.1.2 regtools 函数 TStoX()***'
- en: 'The function `TStoX()` does what its name implies—converts a time series to
    an “X” matrix. “Y” is created too and returned in the final column. For the previous
    toy example, we have:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`TStoX()`做的就是它的名字所暗示的——将时间序列转换为“X”矩阵。“Y”也会创建并返回在最后一列。对于之前的示例，我们有：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Our “X” data are then in the first two columns, and “Y” is the third column.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的“X”数据位于前两列，而“Y”则是第三列。
- en: 'The function returns a matrix, which we can convert to a data frame if we wish:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数返回一个矩阵，如果需要，我们可以将其转换为数据框：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We could then use any of our `qe*`-series functions, such as random forests:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用任何一个`qe*`系列的函数，例如随机森林：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In other words, everything was done as before, with one exception: we cannot
    take our holdout set to be a random subset of the data, as the remaining data
    would no longer be for consecutive time periods. We will elaborate on this point
    shortly.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，除了一个例外，其他一切与之前一样：我们不能将 holdout 集作为数据的随机子集，因为剩下的数据将不再是连续时间段的数据。我们将很快详细说明这一点。
- en: 13.2 The qeTS() Function
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2 `qeTS()` 函数
- en: 'But, instead of calling, say, `qeRF()` “by hand,” as above, we again have a
    convenient wrapper, `qeTS()`, which transforms from time series format to “X,
    Y” form and then applies our favorite ML method to the result. The wrapper’s call
    form is:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，和上面一样，我们不需要手动调用 `qeRF()`，我们有一个方便的包装函数 `qeTS()`，它将时间序列格式转换为“X，Y”形式，然后应用我们最喜欢的机器学习方法。包装函数的调用形式是：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here `qeName` is the quoted name of a `qe*`-series function—for example, `'qeRF'`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 `qeName` 是一个 `qe*` 系列函数的引用名——例如，`'qeRF'`。
- en: 'The argument `opts` allows us to use nondefault versions of the arguments of
    the quoted-name function. For instance, to use k-NN and *k* = 10, write:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 参数 `opts` 允许我们使用被引用函数的非默认版本的参数。例如，要使用 k-NN 并将 *k* 设置为 10，可以这样写：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: A comment should be made regarding `holdout`. While it plays its usual role
    in the `qe*`-series, note that cross-validation is usually difficult in time series
    contexts. We cannot choose for our holdout set some randomly chosen numbers from
    our data, since in time series we predict one datum from its immediately preceding,
    time-contiguous values. But here, we conduct the holdout operation on the output
    of `TStoX()`, whose output *is* rows of sets of contiguous values, so it works.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 需要对 `holdout` 做一些说明。虽然它在 `qe*` 系列中发挥着常规作用，但需要注意的是，在时间序列上下文中，交叉验证通常是困难的。我们不能随机从数据中选择一些数字作为我们的
    holdout 集，因为在时间序列中，我们是通过前一个时间点的数据预测当前数据。但是在这里，我们对 `TStoX()` 的输出进行 holdout 操作，其输出*是*一组连续值的行，因此这是有效的。
- en: '13.3 Example: Weather Data'
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3 示例：天气数据
- en: Here we will use some weather time series data collected by NASA, which is included
    in `regtools`.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用由 NASA 收集的一些天气时间序列数据，这些数据包含在 `regtools` 中。
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'That last column is precipitation. Let’s fit a model for it and then predict
    the first day after the end of the data, day 4018, based on day 4016 and day 4017:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一列是降水量。让我们为它拟合一个模型，然后根据第 4016 天和第 4017 天的数据，预测数据结束后的第一天，即第 4018 天：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: So, we predict a bit more than 1 inch of rain.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们预测降雨量略多于 1 英寸。
- en: We used a lag of 2 days here. How would other lag values fare? We could use
    `qeFT()` here, but things are a bit complicated. For example, there is no `yName`
    argument for `qeTS()`, so instead we use `replicMeans()` (see [Section 3.2.2](ch03.xhtml#ch03lev2sec2)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这里使用了2天的时滞。其他时滞值会如何表现呢？我们可以在这里使用`qeFT()`，但事情有点复杂。例如，`qeTS()`没有`yName`参数，所以我们改用`replicMeans()`（参见[第3.2.2节](ch03.xhtml#ch03lev2sec2)）。
- en: How about a lag of 1 instead of 2? We call `replicMeans()`, asking it to execute
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如何用1的时滞而不是2？我们调用`replicMeans()`，要求它执行
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '1,000 times and then report the mean of the resulting 1,000 values of `testAcc`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 进行1,000次实验，然后报告得到的1,000个`testAcc`值的平均值：
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This gives us a Mean Squared Prediction Error of 2.12\. Is that good? As usual,
    let’s compare this to how well we can predict from the mean alone:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们带来了2.12的均方预测误差。这算好吗？像往常一样，让我们将其与仅用均值进行预测的效果进行比较：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Ah, we’re in business.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 啊，我们开始有了进展。
- en: What about other lags?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 那么其他时滞怎么样？
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: It does seem that the lag makes some difference. A lag of 3 days seems best,
    though as usual, we must keep in mind the effect of sampling variation. (The `replicMeans()`
    function also provides a standard error, which is not shown here.)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，时滞似乎会有一些影响。3天的时滞似乎是最好的，尽管像往常一样，我们必须记住采样变异的影响。（`replicMeans()`函数还提供了标准误差，这里没有显示。）
- en: 'How about trying some other ML methods? Let’s consider a linear model, since
    most classical time series methods use linear models:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如何尝试一些其他的机器学习方法呢？让我们考虑一个线性模型，因为大多数经典的时间序列方法都使用线性模型：
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As noted, classical time series methods, for example, the *autoregressive* model,
    are linear. We see that a linear model doesn’t work so well on this particular
    dataset. Fitting a polynomial improves things substantially but still doesn’t
    match k-NN.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，经典的时间序列方法，例如*自回归*模型，是线性的。我们看到，线性模型在这个特定数据集上效果并不理想。拟合多项式可以显著改善结果，但仍然不如k-NN。
- en: Maybe random forests?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 或许是随机森林？
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: It’s still not as good as k-NN. However, with hyperparameter tuning in both
    cases, either method might end up the victor.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 它仍然不如k-NN。然而，通过调整超参数，在这两种情况下，任一方法都可能最终成为胜者。
- en: 13.4 Bias vs. Variance
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.4 偏差与方差
- en: The value of the lag impacts bias and variance, though in possibly complex ways.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 时滞的值会影响偏差和方差，尽管这种影响可能是复杂的。
- en: A larger lag clearly increases bias; time periods in the more distant past are
    likely less relevant. It’s similar to the problem of a large *k* in k-NN.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 较大的时滞显然增加了偏差；过去较远时间段的相关性可能较低。这类似于k-NN中较大*k*的问题。
- en: On the other hand, the variance aspect is tricky. A larger lag smooths out the
    day-to-day (or other temporal) variation—that is, it reduces variance. But a larger
    lag also increases *p*, the number of features, increasing variance. The overall
    effect is thus complex.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，方差方面是棘手的。较大的时滞平滑了日常（或其他时间段）变化——即减少了方差。但较大的时滞也增加了*p*，即特征的数量，从而增加了方差。整体效果因此是复杂的。
- en: 13.5 Text Applications
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.5 文本应用
- en: 'The field of text analysis is highly complex, similar to that of the image
    recognition field. As in the latter case, in this book we can only scratch the
    surface, in two senses:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分析领域非常复杂，类似于图像识别领域。正如后者的情况一样，在本书中，我们只能浅尝辄止，主要从两个方面进行介绍：
- en: We will limit ourselves to document classification, as opposed to, say, language
    translation.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将限制在文档分类领域，而不是比如说，语言翻译。
- en: We will limit ourselves to the bag-of-words model (see the next section). This
    approach merely relies on how often various words appear in a document and not
    on the order in which the words appear.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将限制在词袋模型（请参见下一节）。该方法仅依赖于各种单词在文档中出现的频率，而不依赖于单词出现的顺序。
- en: So, we do not cover advanced methods such as the aforementioned *recurrent neural
    networks (RNNs)*, or even more advanced methods such as *hidden Markov models
    (HMMs)*.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们没有涵盖诸如前述的*循环神经网络（RNNs）*等高级方法，甚至更高级的方法，如*隐马尔可夫模型（HMMs）*。
- en: '***13.5.1 The Bag-of-Words Model***'
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***13.5.1 词袋模型***'
- en: Say we wish to do automatic classification of newspaper articles. Our software
    notices that the words *bond* and *yield* are contained in some document and classifies
    it in the Financial category.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望自动分类报纸文章。我们的软件发现某些文档中包含了*bond*和*yield*这两个词，并将其分类为金融类别。
- en: This is the *bag-of-words model*. We decide on a set of words, the “bag,” and
    compute the frequency of appearance of each word in each document class. These
    frequencies are often stored in a *document-term matrix (DTM)*, `d`. The entry
    `d[i,j]` is equal to the number of times word `j` appears in document `i` in our
    training set. Or, `d[i,j]` may simply be 1 or 0, indicating whether word `j` appears
    in document `i` at all.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这是*袋装词模型*。我们决定一组词语，即“词袋”，并计算每个词语在每个文档类别中出现的频率。这些频率通常存储在*文档-词项矩阵（DTM）*中，`d`。`d[i,j]`表示在训练集中，词语`j`出现在文档`i`中的次数。或者，`d[i,j]`可能仅为1或0，表示词语`j`是否出现在文档`i`中。
- en: The matrix `d` then becomes our “X,” with “Y” being the vector of class labels,
    such as Financial, Sports, and so on. Each row of X represents our data on one
    document, with a corresponding label in Y.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵`d`则成为我们的“X”，而“Y”是类别标签的向量，比如金融、体育等。X的每一行表示我们对一个文档的数据，Y中有一个对应的标签。
- en: Again, this is a simple model. Our guess that the document above is in the Financial
    class may be incorrect if, say, a sentence in the document reads “The bond between
    family members will typically yield a stable family environment.” A more sophisticated
    analysis would account for, say, the words in between *bond* and *yield*. The
    bag-of-words model may, in some cases, be less accurate than a time series−based
    approach. Yet it is easy to implement and performs well in many applications.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然是一个简单的模型。如果我们猜测上面的文档属于金融类别，可能会不准确。例如，如果文档中有一句话写着：“家庭成员之间的纽带通常会产生稳定的家庭环境。”
    更复杂的分析会考虑到*纽带*和*产生*之间的词语。袋装词模型在某些情况下可能不如基于时间序列的方法准确。然而，它易于实现，并且在许多应用中表现良好。
- en: '***13.5.2 The qeText() Function***'
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***13.5.2 qeText()函数***'
- en: 'And, of course, there is a `qeML` function for this, `qeText()`. It has this
    call form:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，也有一个`qeML`函数来处理这个，`qeText()`。它的调用形式如下：
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In the `data` argument, there is assumed one row per document, with the column
    indicated by `yName` stating the class of each document, such as Financial; the
    other column (there must be exactly two) stores the document texts. The argument
    `qeName` specifies the ML method to be used, and `opts` specifies optional arguments
    for that method. The term *stop words* refers to rather insignificant words such
    as *the* and *is*, which are ignored.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在`data`参数中，假定每个文档占一行，由`yName`指示每个文档的类别，如金融；另一列（必须正好有两列）存储文档文本。参数`qeName`指定要使用的ML方法，`opts`则指定该方法的可选参数。术语*停用词*指的是一些不太重要的词语，如*the*和*is*，这些词会被忽略。
- en: 'The role of the `kTop` argument is as follows: the software does a census of
    all the words in the documents in the training data and selects the `kTop` most
    frequent ones to use as features.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`kTop`参数的作用如下：软件对训练数据中文档中的所有词语进行普查，选择最频繁的`kTop`个词语作为特征。'
- en: '***13.5.3 Example: Quiz Data***'
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***13.5.3 示例：测验数据***'
- en: The `qeML` package has a built-in dataset named `quizzes`, consisting of the
    text of quizzes I’ve given in various courses. One might ask whether one can predict
    the course from the text.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`qeML`包有一个内置的数据集，名为`quizzes`，包含我在各种课程中给出的测验文本。人们可能会问，是否能根据文本预测课程。'
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There were 143 quiz documents. The eighth of these will have the quiz text
    stored in `quizzes[8,1]` as one very long character string:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 共有143个测验文档。其中第八个文档将有测验文本存储在`quizzes[8,1]`中，作为一个非常长的字符字符串：
- en: '[PRE15]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The course number is in `quizzes[8,2]`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 课程编号在`quizzes[8,2]`中：
- en: '[PRE16]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This was ECS 158, Introduction to Parallel Computation.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这是ECS 158，平行计算导论。
- en: 'As an illustration, let’s pretend we don’t know the class of this document
    and try to predict it using random forests:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，假设我们不知道该文档的类别，尝试使用随机森林来预测：
- en: '[PRE17]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The predicted course is ECS 158.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 预测的课程是ECS 158。
- en: '***13.5.4 Example: AG News Dataset***'
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***13.5.4 示例：AG新闻数据集***'
- en: 'This dataset consists of short news articles in four categories: World, Sports,
    Business, and Sci/Tech. It is obtainable from the CRAN package `textdata`, which
    provides interfaces for downloading various text data testbeds:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集由四个类别的短新闻文章组成：世界、体育、商业和科技。可以从CRAN包`textdata`中获得，该包提供了下载各种文本数据测试库的接口：
- en: '[PRE18]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let’s take a look around:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们四处看看：
- en: '[PRE19]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Plenty of data here with 120,000 documents. Well, maybe *too* much, as the
    run time may be long. For a quick example, let’s just take 10,000 rows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有大量数据，共有120,000个文档。嗯，也许*太*多了，因为运行时间可能会很长。为了快速示范，我们只取10,000行：
- en: '[PRE20]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'So, let’s try fitting a model, say, SVM:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们试着拟合一个模型，比如SVM：
- en: '[PRE21]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Not too bad. We reduced a base error of 74 percent to 46 percent. The latter
    is still rather high, so we would next try tweaking the SVM hyperparameters. Note
    that `kTop` is also a hyperparameter! We should try different values for it too.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 还不错。我们将基础误差从 74% 降低到了 46%。虽然后者仍然相对较高，因此接下来我们会尝试调整 SVM 超参数。请注意，`kTop` 也是一个超参数！我们应该也尝试不同的值。
- en: 13.6 Summary
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.6 总结
- en: We see here that, even without advanced methods, one may be able to fit good
    prediction models for time series and text data. In both cases, `qe*`-series functions
    `qeTS()` and `qeText()` enable convenient use of our favorite ML methods.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，即使没有高级方法，也可能能够为时间序列和文本数据拟合出良好的预测模型。在这两种情况下，`qe*`-series 函数 `qeTS()` 和
    `qeText()` 使我们能够方便地使用我们喜爱的机器学习方法。
