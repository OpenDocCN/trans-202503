- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Identifying Threats with Social Network Analysis
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用社交网络分析识别威胁
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: '*Social network analysis (SNA)* is a subset of graph theory that describes
    complex human interactions mathematically; it can be used in any research where
    human interaction is a factor. Security researchers use SNA for everything from
    predicting the spread of malicious content to identifying potential insider threats.
    We’ll do our own SNA in this chapter: we’ll build a humble social network graph
    from Mastodon posts, then use it to understand influence and information exchange
    among users. Specifically, we’ll be looking at a real social network effect known
    as the *small-world phenomenon*. Then we’ll look at how to build a graph from
    posts, answer a few research questions, and end with a proof-of-concept project,
    where you’ll be able to capture data from your own Mastodon timelines.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*社交网络分析 (SNA)* 是图论的一个子集，它用数学方式描述复杂的人类互动；它可以应用于任何涉及人类互动的研究领域。安全研究人员使用SNA进行从预测恶意内容传播到识别潜在内部威胁的各种工作。在本章中，我们将进行自己的SNA：我们将从Mastodon的帖子构建一个简单的社交网络图，然后利用它来理解用户之间的影响力和信息交换。具体来说，我们将研究一个真实的社交网络效应，称为*小世界现象*。接下来，我们将看看如何从帖子中构建图形，回答几个研究问题，最后进行一个概念验证项目，在该项目中，你将能够从你自己的Mastodon时间线收集数据。'
- en: The Small-World Phenomenon
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小世界现象
- en: Stanley Milgram’s *small-world experiments* demonstrated the influence of group
    conformity on human decision-making. The aim of the experiments was to examine
    the average path length for social networks in the United States, where the *path
    length* is the number of people it takes to get a letter from one person in the
    network to another, seemingly disconnected person. Milgram typically chose individuals
    in the US cities of Omaha, Nebraska, and Wichita, Kansas, to be the starting points;
    someone in Boston, Massachusetts, was the typical end point. Upon receiving the
    invitation to participate, the person designated as the original letter sender
    (the starting point) was asked whether they personally knew the randomly selected
    final recipient (the end point). If so, the starting point was to forward the
    letter directly to the end point. In the more likely scenario—the starting point
    doesn’t know the end point—the starting point was asked to think of a friend or
    relative who was more likely to know the end point. People along the path could
    forward the letter to anyone they knew who might be able to get the letter closer
    to the end point.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 斯坦利·米尔格拉姆的*小世界实验*展示了群体从众对人类决策的影响。实验的目的是研究美国社交网络的平均路径长度，其中*路径长度*是指从网络中的一个人到另一个看似不相关的人的信件传递所需的人员数量。米尔格拉姆通常选择美国内布拉斯加州奥马哈和堪萨斯州威奇托的个人作为起点；马萨诸塞州波士顿的人通常作为终点。在收到参与邀请后，被指定为原始信件发送者（起点）的人需要被询问是否个人认识随机选中的最终接收人（终点）。如果认识，起点需要直接将信件转交给终点。在更常见的情况下——起点不认识终点——起点会被要求想到一个更可能认识终点的朋友或亲戚。路径上的人们可以将信件转交给他们认识的任何人，以便将信件送得更接近终点。
- en: 'Technically speaking, a social network exhibits the small-world phenomenon
    if any two individuals in the network are likely to be connected through a small
    number of intermediate acquaintances. Milgram’s research showed that our society
    is a strongly connected network: any two members of the network are likely to
    be connected through three to six intermediate acquaintances (this is popularly
    known as *six degrees of separation*, a specific case of the small-world phenomenon).
    The mechanism at play in the small-world phenomenon is called *preferential attachment*,
    where a person is more likely to form a connection to someone who already has
    a lot of connections. Put simply, you are statistically more likely to meet a
    new person who goes out and meets a lot of new people than to meet a shut-in with
    only a few social interactions. These types of networks, it turns out, are abundant
    in nature, having been observed everywhere from animal social structures to the
    human brain. Clearly, it’s worth our time as security analysts to understand it.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，如果社交网络中任意两个人之间通过少数中介熟人很可能被连接，那么该社交网络就展现了小世界现象。Milgram 的研究表明，我们的社会是一个强连接的网络：任何两个网络成员之间，很可能通过三到六个中介熟人相连（这通常被称为
    *六度分隔*，即小世界现象的一个特定案例）。在小世界现象中起作用的机制被称为 *优先连接*，即一个人更可能与已经有许多连接的人建立联系。简而言之，统计上你更可能遇到一个去结识许多新人的人，而不是遇到一个几乎没有社交互动的隐士。事实证明，这种类型的网络在自然界中广泛存在，从动物社会结构到人脑中都有观察到。显然，作为安全分析师，理解这一点非常值得我们花时间去研究。
- en: 'Our goal for analyzing our data set of fictional posts and users is to answer
    the following research questions:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析虚拟帖子和用户数据集的目标是回答以下研究问题：
- en: How much information gets propagated?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有多少信息会被传播？
- en: What cliques exist in this network?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个网络中存在哪些社交圈？
- en: Who are the three most influential users?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁是三位最具影响力的用户？
- en: Who are the three most influenced users?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁是三位最受影响的用户？
- en: Who could introduce the most new connections?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁能引入最多的新连接？
- en: Over the rest of this chapter, we’ll cover each topic in turn, see how we can
    reinterpret the previous theory to gain insight into social network user interactions,
    and explore new graph theory topics, like residual information and node ancestry.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将依次讨论每个主题，看看如何重新解读之前的理论以深入理解社交网络用户交互，并探索新的图论主题，如残余信息和节点谱系。
- en: Graphing Social Network Data
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绘制社交网络数据
- en: To turn our social network data into a graph, first we need to structure it
    into a searchable table format. We’ll be using the pandas library, which gives
    us access to functions and data structures that help us organize our data to prepare
    it for graphing.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们的社交网络数据转化为图形，首先我们需要将其结构化为可搜索的表格格式。我们将使用 pandas 库，它为我们提供了帮助组织数据并为图形化做准备的函数和数据结构。
- en: First, let’s look at the raw JSON data. The file *fake_posts.json*, included
    with the book’s supplemental materials, contains 28,034 post-like objects formatted
    in the JSON schema shown in [Listing 5-1](#listing5-1).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看原始的 JSON 数据。文件 *fake_posts.json*，随书的补充材料提供，包含了 28,034 个类似帖子的对象，格式遵循[列表
    5-1](#listing5-1)中展示的 JSON 架构。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Listing 5-1: A mock API response using an example of the Mastodon schema'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5-1：使用 Mastodon 架构示例的模拟 API 响应
- en: The `id` field ❶ holds a numeric ID that the API assigns to an individual record—the
    post—when the post is created. The `content` field ❷ contains the data being added
    to the network—that is, the text that makes up the post. Some posts are originals
    and the rest are replies to posts, or replies to replies, and so on. The `reblog_count`
    field ❺ tallies how many times a post object received a reply. An object representing
    a reblog will contain the field names that start with `in_reply_to_` ❸. The `account`
    field ❹ is a nested JSON object that identifies the post creator.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`id` 字段 ❶ 包含一个由 API 在创建帖子时分配给单个记录——即帖子——的数字 ID。`content` 字段 ❷ 包含添加到网络中的数据——也就是构成帖子的文本。一些帖子是原创的，其余的是对帖子、或对回复的回复，依此类推。`reblog_count`
    字段 ❺ 统计帖子对象收到多少次回复。表示转发的对象将包含以 `in_reply_to_` 开头的字段名称 ❸。`account` 字段 ❹ 是一个嵌套的
    JSON 对象，用于标识帖子的创建者。'
- en: Structuring the Data
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据结构化
- en: We’ll be retaining a lot more data from the post objects than we did from packets
    in [Chapter 4](c04.xhtml), and the post object structure is nested, so first we
    need to load the data file into a pandas `DataFrame` object. A `DataFrame` object
    is the pandas version of row and column data storage for tabular data. It’s similar
    in structure to a database (and even supports some of the same operations, like
    filtering and joining data). Using `DataFrame` gives us a more convenient syntax
    for sorting and selecting relevant post objects, and it highlights the power of
    combining analytical libraries. By combining tools (in this case, pandas and NetworkX),
    you can choose the right tool for a particular job instead of trying to make a
    library do something it wasn’t designed for.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从帖子对象中保留比 [第 4 章](c04.xhtml) 中的包对象更多的数据，并且帖子对象结构是嵌套的，所以首先我们需要将数据文件加载到 pandas
    `DataFrame` 对象中。`DataFrame` 对象是 pandas 中用于存储表格数据的行和列数据结构。它在结构上类似于数据库（甚至支持一些相同的操作，如数据过滤和连接）。使用
    `DataFrame` 可以为我们提供更方便的语法来排序和选择相关的帖子对象，它也展示了将分析库结合使用的强大功能。通过结合使用工具（在这种情况下是 pandas
    和 NetworkX），你可以为特定任务选择合适的工具，而不是强迫某个库做它本来不擅长的事。
- en: The code in [Listing 5-2](#listing5-2) defines a `DataFrame` object from the
    example data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 5-2](#listing5-2) 中的代码定义了一个来自示例数据的 `DataFrame` 对象。'
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Listing 5-2: Creating a pandas `DataFrame` object from example JSON data'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5-2：从示例 JSON 数据创建 pandas `DataFrame` 对象
- en: After importing the required libraries ❶, we define a helper function called
    `user_to_series` ❷, which I’ll discuss in depth in a moment; at a high level,
    this function converts each JSON user object into a row suitable for use in a
    pandas `DataFrame`. We load *fake_posts.json* in the typical fashion using `with
    open` ❸, remove any trailing whitespace characters with the `strip` function,
    and split the file data into rows using the remaining `"\n"` characters. The pandas
    library can create a `DataFrame` from a list of JSON objects, so we convert each
    string row into a JSON object using `json.loads` ❹ and collect the objects in
    the `series_data` list ❺.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入所需的库❶之后，我们定义了一个名为 `user_to_series` 的辅助函数❷，稍后我会详细讲解这个函数；从高层次上看，这个函数将每个 JSON
    用户对象转换为适合在 pandas `DataFrame` 中使用的行。我们使用常规方式通过 `with open` ❸ 加载 *fake_posts.json*
    文件，使用 `strip` 函数去除任何尾随的空白字符，并通过剩余的 `"\n"` 字符将文件数据分割为行。pandas 库可以从 JSON 对象列表中创建
    `DataFrame`，因此我们使用 `json.loads` ❹ 将每一行字符串转换为 JSON 对象，并将这些对象收集到 `series_data` 列表中❺。
- en: Unfortunately, when the JSON contains nested objects, like the `account` field,
    pandas doesn’t know how to unpack them. We need to turn the nested fields into
    a flat pandas object using the pandas functions `apply` and `concat` ❻ to apply
    the `user_to_series` function to each row in the data, creating a flat pandas
    `Series`. You can think of a *series* as similar to a row in database parlance—it
    groups all of the data relevant to a single entry.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，当 JSON 包含嵌套对象时，比如 `account` 字段，pandas 并不知道如何解包它们。我们需要使用 pandas 的 `apply`
    和 `concat` ❻ 函数将嵌套字段转换为扁平化的 pandas 对象，通过对数据中的每一行应用 `user_to_series` 函数，生成一个扁平的
    pandas `Series`。你可以将 *series* 理解为类似于数据库术语中的一行 —— 它将所有与单个条目相关的数据组织在一起。
- en: The `pd.concat` pandas function appends these new features to the current `DataFrame`
    for all rows. The `axis=1` parameter tells pandas to use the series as *features*
    (columns in database parlance), which results in the `DataFrame` having a column
    matching each piece of data in the user field (such as username and ID). Each
    row then represents the user, and each column holds the value of that field for
    that particular user.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.concat` pandas 函数将这些新特性附加到当前的 `DataFrame`，并应用于所有行。`axis=1` 参数告诉 pandas
    使用序列作为 *特征*（在数据库术语中是列），这使得 `DataFrame` 中每一列与用户字段中的每一项数据相匹配（如用户名和 ID）。每一行代表一个用户，每一列则保存该用户对应字段的值。'
- en: Lastly we remove the original `account` feature, which is no longer needed,
    using `DataFrame.drop` ❼. Once we’ve loaded the initial data set and applied all
    the column processing, we can print out the structure of the data by calling `post_df.info`.
    [Listing 5-3](#listing5-3) shows the structure resulting from [Listing 5-2](#listing5-2),
    which you can see in the Jupyter notebook *Mastodon_network.ipynb* in the supplemental
    materials.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过 `DataFrame.drop` ❼ 删除不再需要的原始 `account` 特性。加载完初始数据集并应用了所有列处理后，我们可以通过调用
    `post_df.info` 打印出数据的结构。[列表 5-3](#listing5-3) 展示了从 [列表 5-2](#listing5-2) 得到的结构，你可以在补充材料中的
    Jupyter notebook *Mastodon_network.ipynb* 中看到它。
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Listing 5-3: Post data structure in pandas'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5-3：pandas 中的帖子数据结构
- en: The data structure tells us a few important things. First, the `RangeIndex`
    property tells us how many rows of data are currently in the `DataFrame` object.
    In this case we have loaded 28,034 post records, indexed from `0` to `28033`.
    Next, we can see that there’s no longer an `account` column in the list, which
    means our drop operation in [Listing 5-2](#listing5-2) successfully modified the
    `DataFrame`. The number to the right of the column name represents how many rows
    in the data have a non-null value in that column. We can see most of our columns
    have values in every row because the non-null count matches the index count. In
    contrast, the columns starting with `in_reply_to_*` have non-null values in 10,302
    of the 28,034 rows. This is because these values are present only on posts that
    are responses. We’ll take advantage of this difference between original posts
    and replies later.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 数据结构告诉我们一些重要的信息。首先，`RangeIndex`属性告诉我们当前`DataFrame`对象中有多少行数据。在这个例子中，我们已经加载了28,034条帖子记录，索引从`0`到`28033`。接下来，我们可以看到列表中已经没有`account`列，这意味着我们在[Listing
    5-2](#listing5-2)中的删除操作成功地修改了`DataFrame`。列名右侧的数字表示数据中有多少行在该列中有非空值。我们可以看到大多数列在每一行中都有值，因为非空计数与索引计数相匹配。相比之下，以`in_reply_to_*`开头的列在28,034行数据中只有10,302行有非空值。这是因为这些值仅出现在作为回复的帖子中。稍后我们将利用原创帖子和回复之间的这一差异。
- en: To the right of the value count is the type of data stored in the column. If
    you don’t explicitly define types for the data as you import it, pandas will do
    its best to logically interpret the types. Unfortunately, it’s really only good
    at finding integer and float types. For the rest of the columns, you can see it
    has assigned the generic type `object`. This is the pandas way of saying it really
    doesn’t know what to make of the data in the column. It may be of an unorderable
    type (like the strings stored in the `user_name` column) or there may be two or
    more data types in the same column (such as the column `in_reply_to_screen_name`,
    where some rows have an integer value and others have a null value). Before you
    begin any analysis, it’s important to understand the structure of the underlying
    data. You’ll become familiar with the different data types available and when
    to use each, but for now we don’t need to change anything, so we’ll move on to
    the last two rows of the output. The `dtypes` property just gives a summary of
    the data types in the column for convenience. We can see that one column was determined
    to be a floating-point number, three were determined to be integers, and the rest
    pandas left as generic `object` types.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在值计数的右侧是列中存储的数据类型。如果在导入数据时没有明确地定义数据类型，pandas会尽力逻辑地解释这些类型。不幸的是，它主要擅长识别整数和浮动类型。对于其他列，你可以看到它为这些列分配了通用类型`object`。这是pandas表示它并不清楚如何处理该列数据的一种方式。可能是数据类型无法排序（就像`user_name`列中存储的字符串）或者同一列中可能有两种或更多数据类型（例如`in_reply_to_screen_name`列，其中某些行有整数值，而其他行则有空值）。在开始任何分析之前，理解底层数据的结构非常重要。你会逐渐熟悉可用的不同数据类型以及何时使用它们，但现在我们不需要做任何更改，因此我们将继续查看输出的最后两行。`dtypes`属性只是为了方便总结列中的数据类型。我们可以看到，其中一列被确定为浮动数值，三列被确定为整数，其余列则被pandas保留为通用`object`类型。
- en: Finally, the memory usage line estimates the amount of memory used to store
    the entire `DataFrame` object. You can use this value to get a rough idea of data
    storage requirements for your application, but there are some caveats here. Depending
    on your configuration, pandas can calculate this number in one of two ways. By
    default, pandas simply multiplies the bytes required to store a value of each
    column’s data type by the number of rows in the `DataFrame`. For example, an `int64`
    value takes up 8 bytes, so the `id` column takes up approximately 8 × 28,034 =
    224,272 bytes (a little over 224KB). By repeating this for each column and summing
    the results, pandas quickly approximates memory usage. The problem is that some
    data types (the `object` type, for instance) don’t have a maximum size, so pandas
    can only guess the minimum space assigned to these types. That’s why there’s a
    `+` symbol after the memory usage.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，内存使用行估算了存储整个`DataFrame`对象所需的内存量。你可以使用这个值大致了解应用程序的数据存储需求，但这里也有一些注意事项。根据你的配置，pandas可能会通过两种方式之一来计算这个数字。默认情况下，pandas只是将每列数据类型存储一个值所需的字节数与`DataFrame`中的行数相乘。例如，一个`int64`值占用8个字节，所以`id`列大约占用8
    × 28,034 = 224,272字节（约224KB）。通过对每一列重复这个过程并汇总结果，pandas快速估算内存使用情况。问题是某些数据类型（比如`object`类型）没有最大大小，因此pandas只能猜测这些类型分配的最小空间。这就是为什么内存使用后面会有一个`+`符号的原因。
- en: Visualizing the Social Network
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化社交网络
- en: With the `post_df` object defined, you can analyze the data structure and choose
    which fields to use in your graph definitions. Let’s define a node ID *u* as a
    unique user account using the network. The `user_id` and `user_screen_name` have
    a 1:1 relationship, so either is a good candidate for the node ID. The `user_screen_name`
    field makes the graphs more aesthetically pleasing, but the `user_id` might be
    better for an automated system—for example, one that uses the network analysis
    results to look up user profile information by ID. We’ll be using the `user_screen_name`
    field so the graphs are more engaging and memorable; it beats staring at a bunch
    of randomly generated IDs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了`post_df`对象后，你可以分析数据结构并选择用于图形定义的字段。我们将定义一个节点ID *u*，作为使用该网络的唯一用户账户。`user_id`和`user_screen_name`具有1:1的关系，所以两者都是节点ID的良好候选字段。`user_screen_name`字段使得图形更加美观，但`user_id`可能更适合自动化系统——例如，用于通过ID查找用户个人信息的网络分析结果。为了让图形更具吸引力和记忆性，我们将使用`user_screen_name`字段；毕竟，看着一堆随机生成的ID可没那么有趣。
- en: For edges, we’ll look at when two users interacted over a post, shown in [Listing
    5-4](#listing5-4).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于边，我们会查看两位用户是否在一条帖子上进行了互动，具体见[Listing 5-4](#listing5-4)。
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Listing 5-4: Representing the post data as a directed graph'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Listing 5-4：将帖子数据表示为有向图
- en: The `in_reply_to_*` fields allow us to see when a post is in response to an
    earlier post (ostensibly from another user). When user B replies to a post from
    user A, we’ll consider this an edge between them, *e*[*(a→b)*]. I’ll discuss more
    about edges and interpreting them as we go along.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`in_reply_to_*`字段使我们能够看到某条帖子是否是对早期帖子的回复（显然是来自其他用户）。当用户B回复用户A的帖子时，我们将把它视为它们之间的一个边，*e*[*(a→b)*]。我将继续讨论关于边的内容，以及如何解读它们。'
- en: First we create a directed graph ❶ from the previously defined `DataFrame` object.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从之前定义的`DataFrame`对象创建一个有向图❶。
- en: We loop over each index in the `post_df` object ❷ and use the `DataFrame.loc`
    function to retrieve each row individually ❸. We add edges to the graph whenever
    one user reblogs another user’s message ❹. The user who created the original post
    (the source node) is held in the `in_reply_to_account_id` field, and the user
    who’s responding (the terminal node) is held in the `user_screen_name` field.
    We then include the length of the text as a specially named version of edge weight
    called `capacity` ❺. This is a very simplistic measure of information contained
    in a post, as we’ll discuss more shortly. Finally, we can print out the length
    of the list of graph nodes to verify we’ve added 85 post objects to our graph.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历`post_df`对象中的每个索引❷，并使用`DataFrame.loc`函数逐行检索❸。每当一个用户转发另一个用户的帖子时，我们会在图中添加一条边❹。创建原始帖子的用户（源节点）保存在`in_reply_to_account_id`字段中，回应的用户（终端节点）保存在`user_screen_name`字段中。接下来，我们将帖子文本的长度作为一个名为`capacity`的特定边权重形式包含在内❺。这是衡量帖子中包含信息的一个非常简单的方式，稍后我们会详细讨论。最后，我们可以打印图节点列表的长度，确认我们已经将85个帖子对象添加到图中。
- en: '[Figure 5-1](#figure5-1) shows a 3D representation of the graph generated from
    [Listing 5-4](#listing5-4).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[Figure 5-1](#figure5-1)展示了从[Listing 5-4](#listing5-4)生成的图的3D表示。'
- en: Each dot is a node representing a different user on the network, and each dashed
    line is an edge representing a post interaction between two users. Posts without
    replies don’t create edges in the graph, and so aren’t visualized here. Even though
    there’s a lot of data and the graph looks like a mess at first glance, there are
    some takeaways. For example, you can already see this is a highly connected network.
    Looking at the nodes around the periphery, you can see that most users have a
    lot of edges leading to various other users, which means at some point they interacted
    through a post. Also note that some of the nodes have a lot more edges than others.
    Just as we did with the computer network in the previous chapter, let’s begin
    to untangle this cloud of connectivity to see if we can make any interesting observations
    related to our research.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每个点都是一个节点，代表网络中的不同用户，而每条虚线则是表示两个用户之间的帖子互动的边。没有回复的帖子不会在图中创建边，因此这里没有可视化出来。尽管数据量很大，图看起来一开始有些混乱，但其实还是有一些可以总结的地方。例如，你可以看到这是一个高度连接的网络。观察外围的节点，你会发现大多数用户有很多条边指向不同的其他用户，这意味着他们在某个时刻通过帖子进行了互动。还要注意，有些节点的边远比其他节点多。就像我们在上一章对计算机网络的分析一样，接下来我们将开始理清这片连接的云，看看能否从中得出一些与我们研究相关的有趣观察。
- en: '![](image_fi/502567c05/f05001.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c05/f05001.png)'
- en: 'Figure 5-1: A 3D visualization of the social network graph'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-1：社交网络图的 3D 可视化
- en: Network Analysis Insights
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络分析见解
- en: With our graph built, we can turn our attention to our research questions, starting
    with how much information gets propagated within the network.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建了我们的图后，我们可以将注意力转向我们的研究问题，首先探讨网络中传播了多少信息。
- en: Calculating Information Propagation
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算信息传播
- en: Calculating the amount of information something contains is an age-old problem
    with a lot of deep mathematical research behind it. Most truly useful methods
    deal with a concept called *information entropy* and dive into measuring the probability
    of some value (such as a phrase) existing by random occurrence. These measures
    are often complex to describe mathematically and would require a whole other discussion
    around linguistics and Markov chains. Instead, I’ve opted for the crude substitute
    of text length. Essentially, each post is treated as one unit of data and the
    post’s total information is exchanged with each interaction. We consider information
    propagated when a user replies to a post.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 计算某物所包含的信息量是一个古老的问题，背后有大量深奥的数学研究。大多数真正有用的方法都涉及一个叫做*信息熵*的概念，并深入测量某个值（如一个短语）随机出现的概率。这些度量通常用数学语言来描述是相当复杂的，并且需要展开一整篇关于语言学和马尔可夫链的讨论。相反，我选择了一个粗略的替代方法——文本长度。本质上，每个帖子被当作一个数据单元处理，帖子的总信息在每次互动时交换。当用户回复帖子时，我们就认为信息被传播了。
- en: 'We’ll use a different method for the information exchange rate than the one
    we used in NetworkX (see “[Examining How Machines Interact on the Network](c04.xhtml#h2-502567c04-0005)”
    in [Chapter 4](c04.xhtml)). Instead, we’ll consider the *residual information
    (RI)* score, the difference between the amount of information added to a network
    and the amount consumed from it. For example, you could consider the residual
    information of your local library as the difference between all the books it has
    and all the books people in the area have read. It’s very likely that there are
    some esoteric volumes that sit idle, waiting for the day someone will need them.
    The same can be said of a social network like Mastodon. When a user creates a
    new post, they add *potential information* to the network—that is, information
    waiting to be discovered by other users. When a user replies to an existing post,
    potential information converts to *kinetic information* through information exchange:
    information transfers from one user to another through the act of reading and
    responding to the original message. In this case, information flows from the origin
    user to the terminal user via a directed edge *e*, so the edge set *p* can also
    be viewed as the set of kinetic exchanges.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采用与在 NetworkX 中使用的不同的信息交换率方法（参见[《分析机器如何在网络中互动》](c04.xhtml#h2-502567c04-0005)，《第4章》）。相反，我们将考虑*剩余信息（RI）*得分，即网络中新增的信息量与消耗的信息量之间的差异。例如，您可以将本地图书馆的剩余信息视为它拥有的所有书籍与该地区人们已经阅读的书籍之间的差异。很可能有一些冷门书籍静静地待在书架上，等待某一天有人需要它们。社交网络如
    Mastodon 也是如此。当用户创建新帖子时，他们向网络中添加*潜在信息*——也就是说，等待其他用户发现的信息。当用户回复现有帖子时，潜在信息通过信息交换转化为*动能信息*：信息通过阅读和回复原始信息的行为从一个用户流向另一个用户。在这种情况下，信息通过有向边*e*从起始用户流向终端用户，因此边集*p*也可以视为动能交换的集合。
- en: You can then reframe the question “How much information gets propagated?” as
    “How much potential information is required before some is likely to become kinetic?”
    or simply, “How many posts does it take before someone else is likely to read
    and respond?” One way we can answer this question is by calculating the ratio
    of original posts without replies (*o*) to original posts with replies (*p*);
    this gives us the RI score. For now, let’s say a whole post is one unit of information,
    so, for each edge, one unit of information is exchanged from *u* to *v*. This
    is a *balanced exchange*, where all (and only) the information in the post is
    passed. If the node receiving the information could receive only half of it at
    a time, it would be an *unbalanced exchange* because the sender can send more
    than the receiver can handle.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以将问题“传播了多少信息？”重新表述为“在多少潜在信息之后，某些信息有可能转化为动能信息？”或者简单地说，“需要多少帖子才能让别人阅读并回复？”我们可以通过计算没有回复的原创帖子(*o*)与有回复的原创帖子(*p*)的比率来回答这个问题；这给出了RI得分。暂时假设一整个帖子是一个信息单位，因此对于每条边，信息从*u*交换到*v*。这是一种*平衡交换*，其中帖子中的所有（且仅有的）信息都被传递。如果接收信息的节点每次只能接收一半的信息，那将是*不平衡交换*，因为发送方可以发送更多信息，而接收方无法处理。
- en: Using these definitions, you can look at the overall tendency for information
    to spread through the entire network by comparing the ratio of potential information
    to kinetic information exchanged. The formula *RI* = *|p|* / *|o|* describes the
    amount of potential information left in the network after all the exchanges have
    occurred. The result tells you approximately how much information must be added
    to the network before some of it is likely to be consumed by another user (by
    reading and replying). If every post on the network were responded to, you’d get
    an RI score of 0 / *n* = 0\. When there is zero residual information on the network,
    you need to add one piece of information for it to be consumed by another user.
    A network with no replies (all original messages) has an RI score of *n* / 0 =
    NaN, which indicates there is *only* residual information in the network, meaning
    no known amount of potential information will become kinetic. If there are twice
    as many original posts as there are response posts, the ratio is 2:1—for every
    two posts created, one post would get a reply. In another network with an RI score
    of 6 (a 6:1 ratio), only one in six posts get a reply, meaning the information
    flow is more resistant to propagating.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些定义，你可以通过比较潜在信息和动能信息的交换比例，观察信息在整个网络中传播的整体趋势。公式*RI* = *|p|* / *|o|* 描述了所有交换发生后，网络中剩余的潜在信息量。结果告诉你大概需要向网络中添加多少信息，才能使其中一部分被另一个用户消费（通过阅读和回复）。如果网络中的每一条帖子都有回应，你将得到RI分数为0
    / *n* = 0。当网络中没有剩余信息时，你需要添加一条信息才能被其他用户消费。一个没有回复（全部为原创消息）的网络，其RI分数为 *n* / 0 = NaN，这意味着网络中*只有*剩余信息，表示没有已知的潜在信息会变成动能信息。如果原创帖子是回复帖子的两倍，比例为2:1——每创作两条帖子，就会有一条得到回复。在另一个RI分数为6（6:1比例）的网络中，只有六分之一的帖子得到回复，意味着信息流的传播更加难以进行。
- en: '[Listing 5-5](#listing5-5) calculates the example network’s RI score using
    the `DataFrame` object `post_df`.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表5-5](#listing5-5)使用`DataFrame`对象`post_df`计算示例网络的RI分数。'
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Listing 5-5: Applying the RI algorithm to the example data'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5-5：将RI算法应用于示例数据
- en: To measure the amount of potential and kinetic information in the network, we
    collect original posts (those that don’t have a value for `in_reply_to_id`) into
    `o_posts` ❶ and reblogs into `r_posts`. We separate original posts that didn’t
    receive any replies (*p*) into `o_no_r` ❸, and those that did (*o*) into `o_posts`,
    by gathering the IDs of posts with responses ❷ from the list of replies and creating
    a new list that excludes `replied_to` posts. The posts in `o_no_r` represent the
    potential information remaining in the network after the exchanges have all occurred.
    Finally, we take the ratio of the lengths of `o_no_r` and `o_posts` to get the
    RI score ❹. The result should be about `2.6358` for the sample data, indicating
    slightly fewer than three original posts are created for every one reply.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量网络中潜在信息和动能信息的量，我们将原创帖子（没有`in_reply_to_id`值的帖子）收集到`o_posts` ❶ 中，并将转发帖子收集到`r_posts`中。我们将没有收到回复的原创帖子（*p*）分离到`o_no_r`
    ❸中，并将收到回复的原创帖子（*o*）分离到`o_posts`中，通过从回复列表中收集包含回复的帖子ID ❷，并创建一个排除`replied_to`帖子的新的列表。`o_no_r`中的帖子代表在所有交换发生后网络中剩余的潜在信息。最后，我们取`o_no_r`和`o_posts`长度的比值来计算RI分数
    ❹。对于示例数据，结果应约为`2.6358`，表明每收到一条回复，大约有三条原创帖子被创建。
- en: Identifying Cliques and Most Influential Users
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别团体和最有影响力的用户
- en: A key aspect of network analysis is detecting smaller communities, or cliques,
    nested inside the larger network. Recall from [Chapter 3](c03.xhtml) that a clique
    is a group of nodes that are all directly connected to one another. In the case
    of our social network, this would represent a group of users who are all familiar
    with each other and have interacted previously.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 网络分析的一个关键方面是检测嵌套在大网络中的较小社区或团体。回顾[第3章](c03.xhtml)，团体是指一组相互直接连接的节点。在我们的社交网络中，这代表了一群彼此熟悉并且曾经互动过的用户。
- en: 'Let’s find some cliques, starting by cleaning up the data set and displaying
    the graph. Cliques are meaningful only for nodes with connections to other nodes,
    so first we need to clean up the data to include only those posts with replies.
    We can drop posts without replies from the `DataFrame` like so:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始寻找一些团体，首先通过清理数据集并显示图表来进行。团体只有在节点与其他节点有连接时才有意义，所以首先我们需要清理数据，只包括那些有回复的帖子。我们可以像这样从`DataFrame`中删除没有回复的帖子：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: All posts whose `in_reply_to_id` field is populated will be grouped in the `r_posts`
    object. We already discussed the second research question, “What cliques exist
    in this network?” from a theoretical perspective in [Chapter 3](c03.xhtml), so
    let’s apply that knowledge to understand the underlying structure of this network.
    A clique is a subset of nodes *u* wherein all the nodes of *u* are directly connected
    to one another, so if we assume that users read replies to their posts, we can
    defensibly loosen our directed graph to an undirected graph for the purposes of
    identifying these cliques. [Listing 5-6](#listing5-6) converts the graph and then
    finds the cliques as a list. We’ll continue our analysis using the directed graph
    in combination with the clique list from the undirected graph.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所有`in_reply_to_id`字段已填充的帖子将被归类到`r_posts`对象中。我们已经在[第3章](c03.xhtml)从理论角度讨论了第二个研究问题：“这个网络中存在哪些社交圈？”所以现在让我们应用这些知识，来理解这个网络的潜在结构。社交圈是节点子集*u*，其中所有节点*u*彼此之间都是直接连接的，因此，如果我们假设用户会阅读对其帖子的回复，那么我们可以合理地将有向图转化为无向图，以便识别这些社交圈。[清单
    5-6](#listing5-6)会转换图形，并将社交圈作为列表找到。我们将继续使用有向图进行分析，并结合无向图中的社交圈列表。
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Listing 5-6: Converting to an undirected graph to find cliques'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 5-6：转换为无向图以寻找社交圈
- en: 'Cliques in the network are interesting because they provide a picture of which
    users interact. Larger cliques usually represent users with some common association;
    they can reveal the formation of alliances and even predict fractures. Cliques
    by themselves may also be interesting: they tell you who knows whom, for example.
    However, it’s when you start to analyze the members of different cliques that
    you really gain insight. You might identify the leaders of the cliques to see
    who has influence or status over the rest of the network. That’s exactly what
    we’ll do: we’ll take what we’ve learned about the underlying cliques in the network
    to find which groups contain the most influential users in our Mastodon-like network.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 网络中的社交圈很有趣，因为它们提供了用户互动的图景。较大的社交圈通常代表有某种共同联系的用户；它们可以揭示联盟的形成，甚至预测断裂。社交圈本身也可能很有趣：它们告诉你谁认识谁。例如。然而，真正有价值的分析是当你开始分析不同社交圈的成员时，你才会真正获得洞察。你可能会识别出社交圈的领导者，看看谁对网络中其他成员有影响力或地位。正是我们将要做的事情：我们将运用对网络中潜在社交圈的理解，找到哪些群体包含了我们类似
    Mastodon 网络中最有影响力的用户。
- en: The out-degree of a node in this case indicates the number of times other users
    have replied to a post the original node authored. A node with a high out-degree
    could be viewed as “more popular” since those posts tend to trigger more responses.
    By identifying the nodes who are close to this popular node, we can zero in on
    the underlying influencer. [Listing 5-7](#listing5-7) finds the node with the
    highest out-degree in the directed graph, then finds the cliques containing this
    node.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，节点的出度表示其他用户回复原始节点所发布帖子的次数。一个具有较高出度的节点可以被视为“更受欢迎”，因为这些帖子通常会引发更多的回应。通过识别与这个受欢迎节点接近的节点，我们可以聚焦于潜在的影响者。[清单
    5-7](#listing5-7)找到有向图中出度最高的节点，然后找到包含该节点的社交圈。
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Listing 5-7: Finding all maximal cliques for the highest out-degree node'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 5-7：查找具有最高出度节点的所有最大社交圈
- en: First, we get the out-degree for all the nodes in the directed graph ❶. When
    analyzing relationships, you may sometimes want to quantify the strength of the
    connection between nodes along with the rest of the data. For example, if you
    know two users in the network are married, you may want to weight the edges between
    them higher than an edge between two people who are coworkers. In [Listing 5-3](#listing5-3),
    we captured the length of the text as a crude measure of the amount of data exchanged.
    We can use this information now to rate the quality of communications between
    users. To account for the quality of edges as well as the number, we replace the
    simple out-degree measure with a weighted out-degree measure like Dijkstra’s algorithm
    (as I mentioned in [Chapter 4](c04.xhtml), you do so by explicitly passing the
    `weight` parameter to the shortest path algorithm). After sorting the nodes in
    ascending order by out-degree count, we select the last item, the user who is
    the top source of posts that get responses, as the target node, and then use a
    list comprehension ❷ to extract the cliques that contain the target node.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们获取有向图中所有节点的出度 ❶。在分析关系时，有时你可能想要量化节点之间连接的强度以及其余数据。例如，如果你知道网络中有两个用户结婚了，你可能想要赋予它们之间的边更高的权重，而不是两个同事之间的边。在[清单
    5-3](#listing5-3)中，我们通过捕捉文本的长度作为交换数据量的粗略度量。现在我们可以利用这些信息来评估用户之间交流的质量。为了考虑边的质量以及数量，我们将简单的出度度量替换为加权出度度量，像是
    Dijkstra 算法（正如我在[第 4 章](c04.xhtml)中提到的那样，你通过显式传递`weight`参数给最短路径算法来实现）。在按出度数升序排列节点后，我们选择最后一项，即作为帖子来源的目标节点，接着使用列表推导式
    ❷ 提取包含目标节点的团体。
- en: '[Figure 5-2](#figure5-2) shows the subgraph created by selecting the first
    of these cliques ❸.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-2](#figure5-2) 显示了通过选择这些团体 ❸ 中的第一个所创建的子图。'
- en: '![](image_fi/502567c05/f05002.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c05/f05002.png)'
- en: 'Figure 5-2: The clique subgraph for the user most responded to'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-2：用户最回应的团体子图
- en: The popular user, `dannyhoover`, has an outbound edge to each node in the graph.
    The users `michaelcruz` and `falvarez` reply to the largest number of other clique
    members. You can infer that `dannyhoover` is likely to be more influential (for
    these clique members) than either `michaelcruz` or `falvarez`. That isn’t to say
    that those two users aren’t influential in other contexts. Remember, when working
    with subgraphs, the information you derive is always with regard to the subgraph,
    not the graph as a whole.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 流行用户`dannyhoover`向图中的每个节点发送出边。用户`michaelcruz`和`falvarez`回复了最多其他团体成员的帖子。你可以推测，`dannyhoover`在这些团体成员中比`michaelcruz`或`falvarez`更具影响力。但这并不意味着这两位用户在其他情境下不具影响力。记住，在处理子图时，你获得的信息总是与子图相关，而不是整个图。
- en: For the third research question, “Who are the three most influential users?”
    we just extend the code in [Listing 5-7](#listing5-7) to consider the top three
    source nodes. Influential users are those who add potential information that’s
    more likely to initiate a kinetic exchange. As an exercise, try to determine if
    the top three influential nodes are in the same clique. What can you possibly
    infer from the result?
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第三个研究问题，“谁是三个最有影响力的用户？”，我们只需扩展[清单 5-7](#listing5-7)中的代码，考虑排名前三的源节点。影响力用户是那些能增加更可能引发动态交换的潜在信息的用户。作为练习，尝试确定前三个影响力节点是否在同一个团体中。你能从结果中推断出什么？
- en: Finding the Most Influenced Users
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 寻找最受影响的用户
- en: The next question posed explores the inverse relationship in the graph; that
    is, “Who are the three most influenced users?” is related to nodes with the highest
    in-degree. If you consider our definition of influence for this network, an influencer
    is someone who creates an original post that’s likely to get a response from one
    or more users. In contrast, a highly *influenced* user is one who responds to
    a lot of other users’ original posts. Luckily, the code is very similar to [Listing
    5-7](#listing5-7). Simply swapping `G.in_degree` for `G.out_degree` produces a
    graph similar to the one in [Figure 5-3](#figure5-3).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的问题探讨了图中的反向关系；即，“谁是三个最受影响的用户？”与具有最高入度的节点相关。如果你考虑我们对这个网络中影响力的定义，影响者是那些发布原创帖子，且这些帖子可能会得到一个或多个用户回应的人。相反，*受影响*较大的用户是那些回复大量其他用户原创帖子的用户。幸运的是，代码与[清单
    5-7](#listing5-7)非常相似。只需将`G.in_degree`替换为`G.out_degree`，就能生成类似于[图 5-3](#figure5-3)中的图。
- en: '![](image_fi/502567c05/f05003.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c05/f05003.png)'
- en: 'Figure 5-3: Finding the most influenced user'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-3：寻找最有影响力的用户
- en: The user `juliekennedy` is responsible for a large portion of the kinetic information
    exchange in the network, which means they reply to the most users. Given our assumption
    that the person responding to a post has been influenced somewhat (at least enough
    to create a response), we can conclude that the user `juliekennedy` has been influenced
    by the largest number of users. Of course, you’re free to (and probably should)
    debate the validity of this assumption. We’re dealing with an area of security
    where you must be prepared to defend the assumptions you build into your analysis.
    When analyzing something as complex as human interaction, keep in mind there are
    limits to the accuracy and validity of the claims we can make.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 用户`juliekennedy`负责网络中大部分的动能信息交换，这意味着他们回复了最多的用户。根据我们的假设，回应帖子的人在某种程度上已经受到了影响（至少足以做出回应），我们可以得出结论，用户`juliekennedy`受到了最多用户的影响。当然，你可以自由地（而且可能应该）对这一假设的有效性进行辩论。我们正在处理一个安全领域，你必须准备好为你在分析中建立的假设进行辩护。在分析像人类互动这样复杂的事物时，请记住，我们所能做出的主张是有限制的，准确性和有效性也有其界限。
- en: Using Topic-Based Information Exchange
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用基于主题的信息交换
- en: Going a little off-track on our research questions, we can answer the two previous
    questions of influence for more specific post topics using *topic-based information
    exchange*, in which we consider the most influential and influenced users within
    a certain context or topic. For instance, we might consider the most influential
    heart surgeon or the most influential hacker. By examining influence and popularity
    with a contextual example, we can gain more insight into the interactions we’ve
    recorded. Simply put, we can answer “What are these user interactions about?”
    We’ll find the most influential and influenced users for particular topics, such
    as environment and politics, but you can extend the same principle just as easily
    to search for users discussing current events or other topics of interest.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 偏离一下我们的研究问题，我们可以通过*基于主题的信息交换*来回答之前关于影响力的两个问题，具体来说，我们在此过程中考虑某一特定情境或主题下最具影响力和受影响的用户。例如，我们可能会考虑最具影响力的心脏外科医生或最具影响力的黑客。通过用情境实例来分析影响力和受欢迎程度，我们可以更深入地了解我们记录的互动内容。简单来说，我们可以回答“这些用户互动到底是什么？”我们会找出某些特定主题（如环境和政治）下最具影响力和受影响的用户，但你同样可以很容易地扩展这一原则，用于寻找讨论当前事件或其他感兴趣话题的用户。
- en: For topic-based information exchange, we use the *Hyperlink-Induced Topic Search*,
    or *HITS* (also known as *Hubs and Authorities*), an algorithm for analyzing the
    link relationships in a directed graph.^([1](b01.xhtml#c05-endnote-001)) Originally
    designed for internet search engines to score web pages on their relevance to
    a given topic, HITS has been adapted to many other types of link analysis. In
    terms of security and social network analysis, HITS can give useful context to
    the concept of generic influence measure, like information exchange ratio (IER).
    For example, security researchers used Twitter to track information related to
    a terrorist attack in Mumbai^([2](b01.xhtml#c05-endnote-002)) by examining topics
    related to the attack and determining which users seemed to have the most authoritative
    understanding of the events.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于主题的信息交换，我们使用*超链接诱导主题搜索*（*HITS*，也称为*中心和权威*）算法，它用于分析有向图中的链接关系^[1](b01.xhtml#c05-endnote-001)。最初为互联网搜索引擎设计，用来根据与特定主题的相关性对网页进行评分，HITS已被应用于许多其他类型的链接分析。在安全性和社交网络分析方面，HITS可以为通用影响力度量（如信息交换比率，IER）提供有用的背景。例如，安全研究人员曾利用Twitter追踪与孟买恐怖袭击相关的信息^[2](b01.xhtml#c05-endnote-002)，通过分析与袭击相关的话题并确定哪些用户似乎对事件有最权威的理解。
- en: 'The intuition behind the original algorithm is fairly simple: certain sites,
    known as *hubs*, serve as large website directories. Pages are sorted by relevance
    to a queried topic. A good hub is one that points to many other pages across many
    subjects. If multiple hubs point to the same source page for a topic, that page
    is considered to be an authority on the subject. In other words, an authoritative
    node represents one that is linked to by many different hubs. The higher the hub
    scores, the more authoritative the node. The more authoritative nodes a hub connects
    to, the higher its hub score becomes. Modern search engines are excellent examples
    of hubs. These sites aren’t authoritative on any one topic they catalog, but they
    can lead users to other sites that *are* authoritative.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 原始算法背后的直觉非常简单：某些站点，被称为*中心节点*，充当大型网站目录。页面按照与查询主题的相关性排序。一个好的中心节点是指向许多不同主题的其他页面。如果多个中心节点指向同一源页面，那么该页面被视为该主题的权威页面。换句话说，权威节点是指被许多不同中心节点链接的节点。中心节点的得分越高，节点的权威性就越强。一个中心节点连接的权威节点越多，其中心得分越高。现代搜索引擎就是典型的中心节点。这些站点并不是它们所收录的某一特定主题的权威，但它们可以将用户引导到其他*权威*的站点。
- en: 'In our network, a hub would be a user whose post on a subject is reblogged
    by a large number of authoritative users. On the other side of the information
    flow are the authority nodes, which equate to users who reblog the information
    from several quality information hubs. NetworkX relies on the SciPy library under
    the hood to convert the graph into a *sparse adjacency matrix* (a list where every
    possible connection in the graph is recorded as either present in the data or
    not). In turn, SciPy relies on NumPy to handle the matrix math. Unfortunately,
    this dependency chain can be fragile. Depending on how you install the packages,
    you might get an attribute error like `module ''scipy.sparse'' has no attribute
    ''coo_array''` when running the *Mastodon_network.ipynb* file. I was able to temporarily
    resolve this by installing NetworkX version 2.6.3 using the command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的网络中，中心节点将是一个其帖子被大量权威用户转发的用户。信息流的另一端是权威节点，等同于从多个优质信息中心节点转发信息的用户。NetworkX
    在底层依赖 SciPy 库将图转换为*稀疏邻接矩阵*（一种列表，记录图中每个可能的连接是否存在）。反过来，SciPy 依赖 NumPy 处理矩阵数学。不幸的是，这一依赖链可能会很脆弱。根据你安装包的方式，运行
    *Mastodon_network.ipynb* 文件时，可能会遇到类似 `module 'scipy.sparse' has no attribute 'coo_array'`
    的属性错误。我通过使用以下命令安装 NetworkX 版本 2.6.3 暂时解决了这个问题：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The HITS algorithm is performed iteratively over a subset of relevant nodes,
    typically returned from some search algorithm. With each iteration, the algorithm
    recalculates the two real values representing the hub score and authority score
    for each node in the subset. Since the hub score for a good hub should increase
    with each new iteration, the score it lends to each authority will also increase,
    and vice versa. The final output is two scores for every node in the subset.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: HITS 算法会在一个相关节点子集上迭代执行，通常这个子集是通过某种搜索算法返回的。在每次迭代中，算法会重新计算每个节点的中心得分和权威得分这两个实数值。由于一个好的中心节点的得分应当随着每次迭代而增加，因此它给予每个权威节点的得分也会增加，反之亦然。最终输出的是子集内每个节点的两个得分。
- en: '[Listing 5-8](#listing5-8) shows a method to find hubs and authorities relating
    to posts containing the word *environment*, using the `DataFrame` object from
    [Listing 5-2](#listing5-2) once again.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 5-8](#listing5-8)展示了一种方法，用于查找与包含单词*environment*的帖子相关的中心节点和权威节点，再次使用[列表
    5-2](#listing5-2)中的`DataFrame`对象。'
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Listing 5-8: Building a topic-based subgraph and running the HITS algorithm'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5-8：构建基于主题的子图并运行 HITS 算法
- en: We begin by casting the post text to lowercase ❶ (so we can perform case-insensitive
    matching), and then use the built-in pandas `contains` function for locating rows
    based on text content to retrieve all posts with the related root word ❷. This
    will also match environment*al*, environment*alist*, and so on. We use each row’s
    post ID to extract the set of responses to these posts of interest ❸. We loop
    over each of the reply rows and create a directed edge, which indicates the flow
    of influence for the related topic, in the resulting subgraph ❹.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将帖子文本转换为小写 ❶（这样我们可以进行不区分大小写的匹配），然后使用内置的 pandas `contains` 函数根据文本内容查找相关行，检索所有包含相关根词的帖子
    ❷。这还会匹配如 environment*al*、environment*alist* 等词。我们使用每一行的帖子 ID 提取相关帖子的回复集合 ❸。然后，我们遍历每一条回复，并在结果子图中创建一个有向边，表示相关主题的影响流
    ❹。
- en: Finally, we use the resulting subgraph to calculate the HITS hub and authority
    scores ❺. The `max_iter` parameter passed to the `networkx.hits` function (part
    of the NetworkX core library) controls the maximum value of iterations the algorithm
    will run in cases where the code doesn’t converge on a solution (see the NetworkX
    documentation for a description of how the HITS algorithm reaches convergence).
    The `tol` parameter controls the error tolerance to check for convergence. If
    the algorithm fails to converge on an answer within the tolerance and max iterations,
    a `PowerIterationFailedConvergence` exception will be raised.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用得到的子图计算HITS中心和权威得分❺。传递给`networkx.hits`函数的`max_iter`参数（NetworkX核心库的一部分）控制算法在代码未收敛到解时最大迭代次数（有关HITS算法如何收敛的描述，请参见NetworkX文档）。`tol`参数控制用于检查收敛性的误差容忍度。如果算法未能在容忍度和最大迭代次数内收敛到答案，则会引发`PowerIterationFailedConvergence`异常。
- en: 'The algorithm starts from the assumption that all nodes have a hub score and
    authority score of 1\. At each subsequent step, it computes two update rules:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 算法从假设所有节点的中心得分和权威得分都为1开始。在每个后续步骤中，它计算两个更新规则：
- en: '**Update authority scores**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**更新权威得分**'
- en: 'Update each node’s authority score to be equal to the sum of the hub scores
    of each node that points to it. That is, a node is given a higher authority score
    by reblogging messages of users recognized as information hubs. This is represented
    by:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 更新每个节点的权威得分，使其等于指向它的每个节点的中心得分之和。也就是说，通过转发被认为是信息中心的用户的消息，某个节点会获得更高的权威得分。其表示为：
- en: '![](image_fi/502567c05/m05001.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c05/m05001.png)'
- en: where *n* is the number of incoming references to *u*, and *v* is the node at
    the opposite end of the *i*th edge.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *n* 是指向 *u* 的传入引用数量，*v* 是 *i*th 边的对端节点。
- en: '**Update hub scores**'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**更新中心得分**'
- en: 'Update each node’s hub score to be equal to the sum of the authority scores
    of each node that it points to. In our example, a node is given a high hub score
    by writing posts that are reblogged by nodes considered to be authorities on the
    subject. This is represented by:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 更新每个节点的中心得分，使其等于指向它的每个节点的权威得分之和。在我们的示例中，通过写作被被认为是该主题权威的节点转发的帖子，某个节点会获得较高的中心得分。其表示为：
- en: '![](image_fi/502567c05/m05002.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c05/m05002.png)'
- en: where *n* is the number of outgoing references from *u*, and *v* is the node
    at the opposite end of the *i*th edge.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *n* 是 *u* 的外向引用数量，*v* 是 *i*th 边的对端节点。
- en: You can now reframe the second and third research questions in terms of a given
    subject. For instance, “Who are the top three hubs for the topic of environment?”
    and “Who are the top three authorities for the topic of politics?” The topic-based
    subgraphs in [Figure 5-4](#figure5-4) show the results from our sample data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以从给定主题的角度重新审视第二和第三个研究问题。例如，“环境主题的前三个中心节点是谁？”以及“政治主题的前三个权威节点是谁？”[图 5-4](#figure5-4)中的主题子图展示了我们样本数据的结果。
- en: '![](image_fi/502567c05/f05004.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c05/f05004.png)'
- en: 'Figure 5-4: Topic subgraph examples for environment and politics'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-4：环境和政治主题子图示例
- en: Rather than labeling the nodes, I used the `nx.spring_layout` function to visually
    graph the influence structure for the two topics. According to the documentation,
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 与其标记节点，我使用了`nx.spring_layout`函数来直观地绘制两个主题的影响结构。根据文档说明，
- en: The [spring layout] algorithm simulates a force-directed representation of the
    network treating edges as springs holding nodes close, while treating nodes as
    repelling objects, sometimes called an anti-gravity force. Simulation continues
    until the positions are close to an equilibrium.
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Spring布局]算法模拟了一个基于力的网络表示，将边视为弹簧将节点拉近，同时将节点视为排斥物体，有时称为反重力力。仿真将持续进行，直到位置接近平衡。'
- en: This has the effect of pushing highly connected nodes more toward the center
    depending on the relative connectivity of the rest of the nodes. Nodes near the
    center have exerted influence on more users, so the other nodes have pushed farther
    away. You can see that the graph for politics on the right of [Figure 5-4](#figure5-4)
    has a larger number of small clustered influences near the edges of the graph,
    with only a few nodes showing more influence than the others. The environment
    graph on the left, however, shows a distinctly influential user near the center
    and then a few smaller clusters of local influence around the edges. When using
    the `spring_layout` function, keep in mind that the initial positions are randomized
    so the resulting graph is stochastic (random). Rerunning the code will likely
    result in a different visual layout, but the most influential nodes will always
    have pushed the other nodes farther away than less influential nodes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的效果是，依据其他节点的相对连接性，高度连接的节点会更倾向于向中心移动。靠近中心的节点对更多用户产生了影响，因此其他节点被推得更远。你可以看到右侧的政治图（[图
    5-4](#figure5-4)）中，图的边缘有更多小的聚集影响，只有少数节点显示出比其他节点更大的影响力。而左侧的环境图则显示了一个明显的有影响力的用户位于中心，然后是几组较小的本地影响力集群分布在边缘。在使用`spring_layout`函数时，请记住初始位置是随机的，因此生成的图是随机的（stochastic）。重新运行代码可能会导致不同的可视化布局，但最具影响力的节点总会将其他节点推得比影响力较小的节点更远。
- en: After running the HITS algorithm, you should find that the top three hubs for
    environment (in descending order of hub score) are `williamclarke`, `victoria73`,
    and `nromero`. The top three authorities for politics (also in descending order
    of authority score) are `wernerbrianna`, `trivera`, and `susanjohnson`. Remember
    that the scores produced by the HITS algorithm are relevant only to the topic
    subset. A node with a high authority score for “pet food” wouldn’t score the same
    on “programming.”
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 HITS 算法后，你应该会发现环境领域的前三个枢纽（按枢纽得分降序排列）是`williamclarke`、`victoria73`和`nromero`。政治领域的前三个权威（同样按权威得分降序排列）是`wernerbrianna`、`trivera`和`susanjohnson`。请记住，HITS
    算法生成的得分仅与主题子集相关。一个在“宠物食品”领域具有高权威得分的节点，在“编程”领域的得分可能会有所不同。
- en: At the start of the chapter I mentioned how social network connections and influence
    could be used to predict the spread of malicious content; this is your first real
    method for doing so. A lot of malware is spread through social network message
    attachments. Once you identify a malicious message on your network (and extract
    some useful topic information), you can leverage the HITS algorithm to predict
    which users are more likely to respond to the message. By doing so, you can deal
    with the risks in descending order of importance. A real-world example of this
    occurred as I was revising this chapter. During the height of the COVID-19 pandemic
    fear, attackers used an infected version of a tracking map to trick concerned
    users into visiting a malicious website. Once this story broke ([https://krebsonsecurity.com/2020/03/live-coronavirus-map-used-to-spread-malware](https://krebsonsecurity.com/2020/03/live-coronavirus-map-used-to-spread-malware)),
    security teams used the HITS algorithm to track which, if any, of their users
    might have been impacted.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章开始时，我提到过社交网络连接和影响力如何被用来预测恶意内容的传播；这就是你第一个真正可以使用的方法。许多恶意软件通过社交网络消息附件传播。一旦你在网络中识别出恶意消息（并提取一些有用的主题信息），你可以利用
    HITS 算法预测哪些用户更可能响应该消息。通过这样做，你可以按重要性降序处理风险。一个现实世界的例子发生在我修订本章时。在 COVID-19 大流行的恐慌高峰期，攻击者利用一个被感染的跟踪地图欺骗关注的用户访问恶意网站。一旦这个消息被披露（[https://krebsonsecurity.com/2020/03/live-coronavirus-map-used-to-spread-malware](https://krebsonsecurity.com/2020/03/live-coronavirus-map-used-to-spread-malware)），安全团队使用
    HITS 算法追踪哪些用户（如果有的话）可能受到了影响。
- en: Analyzing Network Organization
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络组织分析
- en: The final question we want to answer—“Who could introduce the most new connections?”—is
    a bit more complex but important nonetheless. Researchers and analysts use this
    type of information when analyzing the organization of networks from street gangs
    to military battalions—anywhere individuals may not directly interact but share
    some common oversight “higher up the ladder.” For example, a soldier in unit A
    may send information about enemy troop movement to the unit commander, who in
    turn forwards the information to the base commander. The base commander is in
    communication with several different unit commanders at any given time and may
    send the message to another unit commander in unit B, who then moves to intercept
    the enemy. In the US, this chain of command is an implementation of a node ancestry
    that can be traced from the office of the president (as commander in chief) all
    the way to each individual soldier in boot camp. By examining which nodes can
    facilitate connections between large numbers of currently disconnected nodes,
    you can begin to understand each person’s importance in the hierarchy.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要回答的最终问题——“谁能引入最多的新连接？”——虽然有些复杂，但仍然非常重要。研究人员和分析师在分析网络组织时，通常会使用这类信息，网络的范围从街头帮派到军事营地——任何地方，个体可能不会直接互动，但会有一些共同的监管“上层”负责。例如，A单位的一名士兵可能会把敌军部队的动向信息传递给单位指挥官，后者再将信息转发给基地指挥官。基地指挥官随时与几位不同单位的指挥官保持联系，可能会将信息发送给B单位的另一位指挥官，该指挥官随后将采取行动拦截敌军。在美国，这种指挥链体现了一个可以追溯到总统办公室（作为总司令）一直到每个新兵的节点祖先结构。通过检查哪些节点能够促进大量当前未连接的节点之间的连接，你可以开始理解每个人在等级结构中的重要性。
- en: '[Figure 5-5](#figure5-5) shows a tree structure for an example that’s probably
    more familiar to you, a company organization chart.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-5](#figure5-5)展示了一个你可能更熟悉的树形结构示例——公司组织图。'
- en: '![](image_fi/502567c05/f05005.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c05/f05005.png)'
- en: 'Figure 5-5: An example tree from an organization chart'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-5：来自组织图的示例树
- en: The root of this tree is the CEO at the top, below whom are three managers who
    all report directly to him. Below each manager are the subordinates that make
    up their team. Understanding the influence within social structures is vital to
    planning (or circumventing) security controls intended for interaction with humans,
    such as social engineering; social engineers use the concept intuitively to gain
    legitimacy with other employees. Simply put, if you can convince an influential
    person to introduce you, you can bypass most resistance. Of course, you wouldn’t
    want to directly call the CEO of a large company if the branch manager is capable
    of making the introduction you need. The first common node between yourself and
    the person you’d like to be introduced to is the *lowest common ancestor (LCA)*.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这棵树的根是位于顶端的CEO，在他下面是三位直接向他汇报的经理。每位经理下方是构成其团队的下属。理解社会结构中的影响力对规划（或规避）与人类互动相关的安全控制至关重要，例如社交工程；社交工程师直观地利用这一概念来获得其他员工的信任。简单来说，如果你能说服一位有影响力的人介绍你，你就能绕过大多数阻力。当然，如果分公司经理能够做你所需的介绍，你是不会直接联系大型公司的CEO的。你和你希望被介绍的对象之间的第一个共同节点就是*最低公共祖先（LCA）*。
- en: To determine the LCA, we first need to define *node ancestry* as it relates
    to trees (rather than genealogy). In graph theory, a tree is a special type of
    graph structure in which any two nodes are connected by exactly one path ([https://mathworld.wolfram.com/Tree.html](https://mathworld.wolfram.com/Tree.html)).
    The node at the start of the tree is the root node; offspring nodes are called
    branch nodes unless an offspring branch has no branch nodes of its own (a dead
    end), in which case it’s called a leaf node.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定LCA（最低公共祖先），我们首先需要定义*节点祖先*，它与树的关系（而不是家谱）。在图论中，树是一种特殊类型的图结构，其中任意两个节点之间有且只有一条路径（[https://mathworld.wolfram.com/Tree.html](https://mathworld.wolfram.com/Tree.html)）。树的起始节点是根节点；子节点称为分支节点，除非某个子分支没有自己的分支节点（即死胡同），在这种情况下，它被称为叶节点。
- en: 'By definition, a simple graph has no directionality and no cycles. A *polytree*
    extends the concept of a simple graph to include directionality, making a *directed
    acyclic graph (DAG)*. This seemingly simple change imparts a lot of interesting
    properties. For example, a DAG has a *topological ordering*: the nodes are ordered
    so the root node has a lower value than the leaf nodes. DAGs are one of the most
    studied of all graph structures because they appear so frequently in nature. From
    the literal branching of trees and plants, the veins in your body, and rivers
    to the structure of most computer programs, DAGs can represent a huge number of
    natural and artificial systems. In our case, using a DAG to represent the relationship
    between nodes will allow us to encode a hierarchy of membership in the social
    network.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 根据定义，简单图没有方向性和环。*多重树*将简单图的概念扩展到包括方向性，从而形成*有向无环图（DAG）*。这个看似简单的变化赋予了图结构许多有趣的属性。例如，DAG具有*拓扑排序*：节点按顺序排列，使得根节点的值低于叶节点。DAG是所有图结构中研究最深入的之一，因为它们在自然界中频繁出现。从树木和植物的分支、人体中的血管到河流，再到大多数计算机程序的结构，DAG可以表示大量的自然和人工系统。在我们的案例中，使用DAG来表示节点之间的关系，将使我们能够在社交网络中编码一个成员等级结构。
- en: Node ancestry for arbitrary polytrees is similar in concept and structure to
    that of a family tree. However, the order relies on the topological sorting of
    DAGs, rather than being strictly chronological. The most influential users are
    those nodes with some amount of out-degree and no in-degree (users, like `dannyhoover`,
    who have more influence than other users) and these form the roots for distinct
    trees. Each node they influence becomes a branch in the tree. For each branch
    node, the out-degree edges are again added as branches. Branching continues until
    all nodes are placed. This leads to leaf nodes with an out-degree of zero and
    some amount of in-degree (the users most influenced by other members of the network).
    Ordering the nodes in this manner gives you an idea of the flow of influence.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 任意多重树的节点祖先在概念和结构上类似于家谱树。然而，节点的顺序依赖于DAG的拓扑排序，而不是严格的时间顺序。最有影响力的用户是那些具有一定出度且没有入度的节点（如`dannyhoover`，比其他用户更有影响力），这些用户形成了不同树的根节点。每个受影响的节点成为树中的一条分支。对于每个分支节点，出度边再次作为分支添加。分支继续，直到所有节点都被放置。这样就形成了具有零出度和一定入度的叶节点（这些用户是最受网络中其他成员影响的）。以这种方式对节点进行排序，可以帮助你了解影响的流动方向。
- en: 'Formally speaking, an ancestor of node *u* is any other node *v* such that
    a directed path exists in the graph from *v* to *u* or, written more algebraically:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上讲，节点*u*的祖先是任何其他节点*v*，使得在图中从*v*到*u*存在有向路径，或者用更代数的方式写作：
- en: Ancestry ( u ) = ( u ← v ) ∈ E
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 祖先(u) = ( u ← v ) ∈ E
- en: 'The *common ancestors* for two nodes (*u*,*v*) are any nodes *x* that have
    a directed path to both *u* and *v* in the set of edges. This can be written as
    the intersection of these two subsets of edges:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 两个节点（*u*，*v*）的*公共祖先*是那些具有指向*u*和*v*的有向路径的节点*x*，这些节点属于边集的交集：
- en: CommAnc( u ∧ v ) = ( x → u ∈ E ) ∪ ( x → v ∈ E )
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: CommAnc( u ∧ v ) = ( x → u ∈ E ) ∪ ( x → v ∈ E )
- en: The LCA of two nodes (*u*,*v*) is the common ancestor with the shortest path
    distance to both nodes, which is also the ancestor with the maximum path length
    from the root of the graph. For example, you and your cousin share some of the
    same great-grandparents. However, you also share some of the same grandparents.
    While both your great-grandparents and your grandparents are your ancestors, since
    your grandparents are closer to your generation than your great-grandparents are,
    they would be your LCA. [Figure 5-6](#figure5-6) shows two examples of ancestry
    on the same tree.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 两个节点（*u*，*v*）的LCA（最近公共祖先）是指从两个节点到公共祖先的最短路径距离的节点，这也是从图的根节点到该祖先的最大路径长度。例如，你和你的表兄妹有一些相同的曾祖父母。然而，你们也有一些相同的祖父母。虽然曾祖父母和祖父母都是你的祖先，但由于祖父母距离你这一代更近，所以他们是你的LCA。[图
    5-6](#figure5-6)展示了同一棵树上祖先的两个例子。
- en: '![](image_fi/502567c05/f05006.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/502567c05/f05006.png)'
- en: 'Figure 5-6: A general ancestry illustration'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-6：一般的祖先示意图
- en: In each tree the shaded node with the dashed outline is the LCA of the other
    two shaded nodes. On the left, the LCA for the nodes *D* and *E* is the root of
    the tree, *A*. On the right, although node *A* is still a common ancestor, node
    *B* is farther from the root and therefore the LCA. Thinking about this in terms
    of information security, the LCA of two nodes is the closest potential pivot point
    between them. If a user at node *G* wanted to be introduced to the user at node
    *E*, they could ask the user at node *B* to introduce them. In [Listing 5-9](#listing5-9)
    we tally the occurrence of each node as the LCA of other node pairs.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个树中，带有虚线轮廓的阴影节点是另外两个阴影节点的LCA。在左侧，节点*D*和*E*的LCA是树的根节点*A*。在右侧，虽然节点*A*仍然是一个共同的祖先，但节点*B*离根节点更远，因此是LCA。用信息安全的角度来思考，两个节点的LCA是它们之间最近的潜在枢纽点。如果节点*G*的用户想要认识节点*E*的用户，他们可以请求节点*B*的用户进行介绍。在[清单
    5-9](#listing5-9)中，我们统计了每个节点作为其他节点对的LCA出现的次数。
- en: '[PRE10]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Listing 5-9: Counting LCA occurrences for all nodes'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 5-9：计算所有节点的LCA出现次数
- en: First, we generate the list of ancestors using the NetworkX function `nx.all_pairs_lowest_common_ancestor`
    ❶, which returns a dictionary where the key is a pair of nodes from the graph,
    and the value is the LCA node for that pair of nodes. With the `ancestors` list
    populated, we then use a `for` loop to assign the pair of nodes to the variable
    `p` and the resulting ancestor to the `lca` variable, in order to count how many
    connections `lca` can bridge. We ignore pairs of nodes with an edge between them,
    since one of the nodes is the direct ancestor of the other ❷. For example, the
    pair of nodes *B* and *E* from [Figure 5-6](#figure5-6) can be ignored, even though
    the NetworkX function produces the LCA of the pair. For each pair of nodes without
    a direct edge between them, we check if their `lca` is in the `pred_count` dictionary,
    which counts the number of times a node is the LCA for two other nodes. If the
    LCA node is already in the dictionary, increment the count by 1 ❸. Otherwise,
    create a new entry with a value of `1` ❹. Running this code will print the top
    five users along with the number of connections they can potentially bridge, as
    shown in [Listing 5-10](#listing5-10).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用NetworkX函数`nx.all_pairs_lowest_common_ancestor`❶生成祖先列表，该函数返回一个字典，其中键是图中的一对节点，值是该节点对的LCA节点。填充好`ancestors`列表后，我们使用`for`循环将节点对赋值给变量`p`，并将结果的祖先赋值给变量`lca`，以便计算`lca`可以连接多少个节点。我们忽略有边连接的节点对，因为其中一个节点是另一个节点的直接祖先❷。例如，图5-6中的节点对*B*和*E*可以忽略，尽管NetworkX函数生成了该对节点的LCA。对于每个没有直接边连接的节点对，我们检查其`lca`是否在`pred_count`字典中，该字典统计了节点作为其他两个节点的LCA出现的次数。如果LCA节点已经在字典中，则将计数加1❸。否则，创建一个新条目，值为`1`❹。运行此代码后，将打印出前五个用户以及他们可以潜在连接的节点数，如[清单
    5-10](#listing5-10)所示。
- en: '[PRE11]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Listing 5-10: The results of the LCA analysis'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 5-10：LCA分析的结果
- en: The root user, `dannyhoover`, is tied for first and can potentially bridge 444
    new connections within the network. Since we already think this user is very influential,
    that may come as no surprise. Their position at the root of the tree also means
    they’re the last possible LCA for all pairs of nodes, if no other ancestor can
    be found, so this result may not be as interesting as the second and third place.
    The fact that the user `georgejohnson` got the same exact score as `dannyhoover`
    is interesting and may point to two structures in the data worth investigating.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 根用户`dannyhoover`排名并列第一，且可以在网络中潜在地建立444个新连接。由于我们已经认为该用户非常有影响力，这个结果并不意外。由于他们位于树的根部，这也意味着他们是所有节点对的最后一个LCA（最近公共祖先），如果没有找到其他祖先。因此，这个结果可能不像第二和第三名那么有趣。用户`georgejohnson`和`dannyhoover`获得相同的分数这一点很有意思，可能表明数据中有两个值得研究的结构。
- en: The user `judith20` can bridge 336 connections. As an exercise, examine how
    this user fits into the structure of the tree. Who influences their activity (inbound
    edges) and who do they influence (outbound edges)? What measures of centrality
    do they score most highly on?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 用户`judith20`可以连接336个节点。作为练习，检查该用户如何融入树形结构中。谁影响了他们的活动（入度边）？他们又影响了谁（出度边）？他们在哪些中心性指标上得分最高？
- en: 'The Proof of Concept: Social Network Analysis'
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概念验证：社交网络分析
- en: The proof-of-concept code for this chapter, found in the *social_network/post_graph.py*
    file in the book’s resources, allows you to capture the post data from your personal
    timeline into JSON data you can analyze using the methods shown here.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的概念验证代码位于书籍资源中的*social_network/post_graph.py*文件，它允许你将个人时间线的帖子数据捕获为JSON数据，您可以使用本书中展示的方法进行分析。
- en: You’ll need to register for an account on whichever Mastodon instance you choose
    (I’m using defcon.social). You’ll then need to register an application for your
    own set of API credentials ([https://docs.joinmastodon.org/client/token](https://docs.joinmastodon.org/client/token)).
    Registering an application gets you an API token and API token secret that identifies
    a specific application under your account and grants access to authorized functions
    (such as liking posts and following users). Depending on the Mastodon instance
    you choose, you may be required to answer some questions to qualify for different
    use cases; otherwise, you simply need to define the scope of the access token
    as you create it. A lot of Mastodon instances are friendly to researchers, as
    long as you plan to protect the privacy of individuals’ data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要在选择的Mastodon实例上注册一个账户（我使用的是defcon.social）。然后，你需要为自己的API凭证注册一个应用程序（[https://docs.joinmastodon.org/client/token](https://docs.joinmastodon.org/client/token)）。注册应用程序后，你将获得一个API令牌和API令牌密钥，用于标识你的账户下的特定应用程序，并授予访问授权功能（如点赞帖子和关注用户）的权限。根据你选择的Mastodon实例，可能需要回答一些问题以符合不同的使用场景；否则，你只需在创建令牌时定义访问令牌的范围。许多Mastodon实例对研究人员很友好，只要你计划保护个人数据的隐私。
- en: You’ll be given a unique API key that identifies your API account to the Mastodon
    instance, paired with an API secret that should be protected like other cryptographic
    keys.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 你将获得一个唯一的API密钥，用于标识你的API账户与Mastodon实例配对，并获得一个API密钥秘密，它应像其他加密密钥一样受到保护。
- en: Once you’ve registered, you can use the API via the Python Mastodon library
    to scrape your own timelines. Refer to the Mastodon library documentation ([https://mastodonpy.readthedocs.io/en/stable](https://mastodonpy.readthedocs.io/en/stable))
    and the Mastodon API documentation ([https://docs.joinmastodon.org/api](https://docs.joinmastodon.org/api))
    to get a sense of the data that’s available and how to access it using this library.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 注册后，你可以通过Python Mastodon库使用API抓取自己的时间线。请参考Mastodon库文档（[https://mastodonpy.readthedocs.io/en/stable](https://mastodonpy.readthedocs.io/en/stable)）和Mastodon
    API文档（[https://docs.joinmastodon.org/api](https://docs.joinmastodon.org/api)）了解可以获取的数据以及如何使用此库访问这些数据。
- en: '[Listing 5-11](#listing5-11) shows the proof-of-concept code.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 5-11](#listing5-11)展示了概念验证代码。'
- en: '[PRE12]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Listing 5-11: Capturing Mastodon public timeline data to a CSV file'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5-11：将Mastodon公共时间线数据捕获到CSV文件
- en: First, we import the `mastodon` library ❶. Once we have the API credentials,
    we modify the template file with the access token and base URL ❷ and run it from
    our terminal. The code uses these credentials to create an authenticated API object
    ❸, used to retrieve the timeline data ❹, which is conveniently delivered as a
    dictionary suitable for JSON encoding. We loop over these results and write them
    into the output CSV file ❺.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入`mastodon`库❶。获取API凭证后，我们通过访问令牌和基本URL修改模板文件❷，并从终端运行它。代码使用这些凭证创建一个经过身份验证的API对象❸，该对象用于获取时间线数据❹，这些数据方便地以字典格式提供，适合进行JSON编码。我们遍历这些结果并将它们写入输出的CSV文件❺。
- en: Now you can use code similar to Listings 5-2 and 5-4 to read the data back into
    a pandas `DataFrame`, then mold it into significant features and finally a relevant
    directed (or undirected) graph using NetworkX. You can also bypass writing to
    an intermediate file by combining this code with a data processing pipeline to
    analyze status information in near real time. We’ll discuss processing pipelines
    in [Part III](p03.xhtml).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以使用类似于列表5-2和5-4中的代码将数据读取回pandas `DataFrame`，然后将其塑造成重要特征，最后使用NetworkX构建相关的有向（或无向）图。你还可以通过将这段代码与数据处理管道结合起来，在几乎实时的情况下分析状态信息，从而绕过写入中间文件的过程。我们将在[第三部分](p03.xhtml)中讨论处理管道。
- en: The Darker Side of Social Network Analysis
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 社交网络分析的阴暗面
- en: Hopefully now you have an idea of how quickly and easily someone can build a
    map of someone else’s social life. The important thing to remember is, like maps,
    social network graphs require interpretation. When we interpret social network
    information, we’re invariably viewing the data through our own social biases.
    The core of the issue is that we’re trying to reduce a highly complex, multifaceted
    problem, such as the motivation behind people’s interactions, into a tightly controlled
    and well-defined mathematical model. To do so, we have to apply heuristics we
    choose based on our own social experience. For example, I mentioned earlier that
    you might want to weight interactions between married couples higher than those
    between coworkers. This shows one of my heuristic biases, which comes from my
    experiences, education, and understanding but doesn’t necessarily reflect the
    reality of everyone’s situation. You’ll need to make many such assumptions when
    building a SNA model, and it’s important to understand when, where, and how much
    you’re allowing your own biases to impact the analysis. This is one of the primary
    reasons I recommend doing SNA with a team. Peer review, especially from peers
    of diverse backgrounds, is one of the best counters to the problems inherited
    from a single-perspective interpretation.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 希望现在你对别人如何快速且轻松地建立社会生活地图有了概念。需要记住的一个重要点是，像地图一样，社交网络图需要解读。当我们解读社交网络信息时，我们不可避免地是通过自己的社会偏见来观察数据。问题的核心是，我们试图将一个高度复杂、多面性的难题——比如人们互动背后的动机——简化为一个严格控制且明确定义的数学模型。为了做到这一点，我们必须基于自己的社会经验应用选择的启发式方法。例如，我之前提到过，你可能会希望将已婚夫妇之间的互动加权比同事之间的互动更高。这展示了我自己的启发式偏见，它源于我的经验、教育和理解，但不一定反映每个人的实际情况。在构建SNA模型时，你需要做出许多这样的假设，理解你在何时、何地以及多少程度上允许自己的偏见影响分析至关重要。这也是我推荐与团队一起进行SNA的主要原因之一。同行评审，尤其是来自不同背景的同行评审，是解决单一视角解释带来的问题的最佳方法之一。
- en: The other reason I recommend caution is that SNA raises moral and ethical questions.
    It is perhaps the dark arts of applied mathematics in security, primarily because
    there can be very real and dangerous consequences when it is abused. SNA has been
    used by tyrannical governments to attack dissidents, threaten whistleblowers,
    and manipulate the people of a society. Unfortunately, not all ethically questionable
    uses of SNA are as easy to spot. There are tools and sites designed to make it
    even easier to collect someone’s publicly available (and sometimes private) information.
    We live in a world that constantly struggles to balance privacy and openness.
    The small-world experiment can be used to link movies to Kevin Bacon or to link
    each one of us to any number of criminal figures and organizations. As an analyst,
    you’re responsible for understanding what’s ethically and morally appropriate.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我推荐保持谨慎的另一个原因是，社会网络分析（SNA）会引发道德和伦理问题。它或许是应用数学在安全领域中的“黑暗艺术”，主要是因为当它被滥用时，可能会产生非常真实且危险的后果。SNA曾被暴政政府用来攻击异见者、威胁举报人以及操控社会民众。不幸的是，并非所有伦理上有疑问的SNA使用方式都容易被发现。有一些工具和网站专门设计用来更容易收集某人的公开（有时是私人）信息。我们生活在一个不断努力平衡隐私与开放的世界中。小世界实验可以用来将电影与凯文·贝肯（Kevin
    Bacon）联系起来，也可以将我们每个人与任何数量的犯罪人物和组织联系起来。作为分析师，你有责任理解什么是伦理上和道德上合适的。
- en: Summary
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Although this chapter demonstrates the concept of social network analysis using
    Mastodon as an example, none of these concepts are inherently tied to the Mastodon
    platform. The US government and university researchers have been working on different
    technologies to leverage the information obtained from analyzing the reply network
    structure of discussions in dark web forums to understand the extent to which
    dark web information can be useful for predicting real-world cyberattacks.^([3](b01.xhtml#c05-endnote-003))
    In his paper “Tracking, Destabilizing and Disrupting Dark Networks with Social
    Networks Analysis,” written for the US Navy, Sean Everton covers SNA as a means
    to develop strategies for tracking and disrupting criminal and terrorist networks.^([4](b01.xhtml#c05-endnote-004))
    The paper serves as both a tactical and strategic introduction, so I highly recommend
    reading it.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章使用Mastodon作为示例来展示社交网络分析的概念，但这些概念并不固有地与Mastodon平台绑定。美国政府和大学研究人员一直在开发不同的技术，通过分析暗网论坛中讨论的回复网络结构来获取信息，以了解暗网信息在多大程度上可以帮助预测现实世界中的网络攻击。^([3](b01.xhtml#c05-endnote-003))
    在他为美国海军撰写的论文《使用社交网络分析追踪、破坏和干扰暗网络》中，Sean Everton介绍了SNA作为一种追踪和破坏犯罪及恐怖分子网络的策略手段。^([4](b01.xhtml#c05-endnote-004))
    这篇论文既是战术性的，也是战略性的入门，我强烈推荐阅读。
- en: As you extend your own SNA to work in the wild, you’ll want to reference the
    API documentation for whatever social network you’re using. If no API exists (or
    the platform starts charging exorbitant rates), you may have to resort to old-fashioned
    web-scraping techniques to gather the data you need. Such tasks are outside the
    scope of this book, but there are many excellent materials for doing so.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将自己的社交网络分析（SNA）扩展到实际应用时，你需要参考你所使用的社交网络的API文档。如果没有API（或者平台开始收取高额费用），你可能需要诉诸传统的网页抓取技术来收集所需的数据。这类任务超出了本书的范围，但有许多优秀的材料可以帮助你实现这一点。
- en: So far, everything we’ve used graph analysis for has been focused on the past.
    You can think of this as *descriptive* security analysis because it aims to classify
    things as they are now (or as they were when the data was captured). *Preventative*
    security analysis, however, seeks to analyze what might occur in the future so
    that hopefully we can step in and prevent a security incident from occurring in
    the first place. To achieve this, we’ll use one of my favorite simulation algorithms,
    Monte Carlo simulations—the subject of the next chapter.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用图分析的所有内容都集中在过去。你可以把它看作是*描述性*安全分析，因为它旨在将事物分类为现在的状态（或者数据捕获时的状态）。然而，*预防性*安全分析则试图分析未来可能发生的事件，从而希望我们能够提前介入，防止安全事件的发生。为了实现这一目标，我们将使用我最喜欢的模拟算法之一——蒙特卡罗模拟，这是下一章的内容。
