- en: '**14'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**14'
- en: MASS STORAGE DEVICES AND FILESYSTEMS**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大容量存储设备和文件系统**
- en: '![Image](../images/comm1.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/comm1.jpg)'
- en: The most prevalent I/O device on modern computers is probably the mass storage
    device. Whereas some PCs don’t have a display (they’re operated *headlessly*),
    or even a keyboard or mouse (they’re accessed remotely), almost every computer
    system recognizable as a PC has a mass storage device of some sort. This chapter
    will focus on the types of mass storage devices—hard drives, floppy disks, tape
    drives, flash drives, solid state drives, and more—as well as the special filesystem
    format they use to organize the data they store.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现代计算机中最常见的输入输出设备可能就是大容量存储设备了。尽管有些PC没有显示器（它们是*无头*操作的），甚至没有键盘或鼠标（它们是远程访问的），几乎所有被认作PC的计算机系统都配有某种大容量存储设备。本章将重点介绍各种大容量存储设备——硬盘、软盘、磁带驱动器、闪存驱动器、固态硬盘等——以及它们用于组织存储数据的特殊文件系统格式。
- en: '**14.1 Disk Drives**'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**14.1 磁盘驱动器**'
- en: Almost all modern computer systems include some sort of disk drive unit to provide
    online mass storage. At one time, certain workstation vendors produced *diskless
    workstations*, but the relentless drop in price and increasing storage space of
    fixed (aka “hard”) disk and solid-state drive (SSD) units have all but obliterated
    the diskless computer system. Disk drives are so ubiquitous in modern systems
    that most people take them for granted. However, it’s dangerous for a programmer
    to take a disk drive for granted. Software constantly interacts with the disk
    drive as a medium for application file storage, so it’s very important to understand
    how disk drives operate if you want to write efficient code.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有现代计算机系统都包含某种硬盘驱动单元，以提供在线大容量存储。曾几何时，某些工作站厂商生产*无盘工作站*，但由于固定（即“硬”）磁盘和固态硬盘（SSD）单元的价格不断下降，存储空间不断增加，几乎完全消除了无盘计算机系统的存在。磁盘驱动器在现代系统中如此普及，以至于大多数人都视其为理所当然。然而，对于程序员来说，理所当然地看待磁盘驱动器是非常危险的。软件不断与磁盘驱动器交互，作为应用文件存储的媒介，因此，如果你想编写高效的代码，理解磁盘驱动器的工作原理是非常重要的。
- en: '***14.1.1 Floppy Disk Drives***'
  id: totrans-6
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.1.1 软盘驱动器***'
- en: Floppy disks have all but disappeared from today’s PCs. Their limited storage
    capacity (typically 1.44MB) is far too small for modern applications and the data
    they produce. It’s hard to believe that at the beginning of the PC revolution
    a 143KB (that’s *kilo*bytes, not megabytes or gigabytes) floppy drive was considered
    a high-ticket item. However, floppy disk drives have failed to keep up with technological
    advances in the computer industry. Therefore, we won’t consider them further in
    this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 软盘几乎已经从今天的PC中消失。它们有限的存储容量（通常为1.44MB）对于现代应用程序及其产生的数据来说过于小。很难相信，在PC革命初期，一个143KB（那是*千*字节，不是兆字节或吉字节）容量的软盘驱动器曾被视为高档商品。然而，软盘驱动器未能跟上计算机行业技术的进步。因此，我们在本章中不再考虑它们。
- en: '***14.1.2 Hard Drives***'
  id: totrans-8
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.1.2 硬盘***'
- en: 'The fixed disk drive, more commonly known as the hard drive, is the most common
    mass storage device in use today (though, as of 2020, SSDs are rapidly replacing
    hard drives). The modern hard drive is truly an engineering marvel. Between 1982
    and 2020, the capacity of a single drive unit has increased over 2,400,000-fold,
    from 5MB to over 16TB (terabytes). At the same time, the minimum price for a new
    unit has dropped from $2,500 (US) to below $50\. No other component in the computer
    system has enjoyed such a radical increase in capacity and performance along with
    a comparable drop in price. (Semiconductor RAM probably comes in second: paying
    the 1982 price today would get you about 40,000 times the capacity.)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 固定磁盘驱动器，通常称为硬盘，是当今最常见的大容量存储设备（不过，截止到2020年，SSD正在迅速取代硬盘）。现代硬盘真的是一项工程奇迹。1982年到2020年间，单个硬盘驱动单元的容量增长了超过240万倍，从5MB增至超过16TB（千兆字节）。与此同时，新的硬盘驱动单元的最低价格从2500美元降至50美元以下。没有其他计算机系统组件经历过如此激烈的容量和性能提升，同时价格却大幅下降。（半导体RAM可能排名第二：如果你用1982年的价格，今天能买到大约40,000倍容量的RAM。）
- en: While hard drives were decreasing in price and increasing in capacity, they
    were also becoming faster. In the early 1980s, a hard-drive subsystem was doing
    well to transfer 1MBps between the drive and the CPU’s memory; modern hard drives
    can transfer more than 2,500MBps.^([1](footnotes.xhtml#fn14_1a)) While this increase
    in performance isn’t as great as that of memory or CPUs, keep in mind that disk
    drives are mechanical units on which the laws of physics place greater limitations.
    In some cases, the dropping cost of hard drives has allowed system designers to
    improve their performance by using disk arrays (see “[RAID Systems](#sec14_1_3)”
    on page [388](#sec14_1_3) for details). By using certain hard-disk subsystems
    like disk arrays, you could achieve 2500MBps (or better) transfer rates, though
    it’s not especially cheap to do so.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在硬盘价格逐渐降低、容量逐渐增加的同时，它们的速度也在不断提升。在1980年代初，硬盘子系统能够实现每秒1MB的数据传输速率，往返于硬盘和CPU内存之间；而现代硬盘的传输速率可以超过2500MBps。^([1](footnotes.xhtml#fn14_1a))
    尽管这种性能提升不像内存或CPU那样显著，但要记住，硬盘是机械设备，物理定律对其有更大的限制。在某些情况下，硬盘成本的下降使得系统设计人员可以通过使用磁盘阵列来提升性能（详见第[388](#sec14_1_3)页的“[RAID系统](#sec14_1_3)”）。通过使用某些硬盘子系统，如磁盘阵列，你可以实现2500MBps（或更高）的传输速率，尽管这样做并不便宜。
- en: Hard drives are so named because their data is stored on a small, rigid disk
    that is usually made out of aluminum or glass and is coated with a magnetic material.
    Floppy disks, in contrast, store their information on a thin piece of flexible
    Mylar plastic.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 硬盘之所以叫这个名字，是因为它们的数据存储在一个小而坚硬的盘片上，盘片通常由铝或玻璃制成，并涂有磁性材料。与此相对，软盘则将数据存储在一片薄薄的可弯曲的Mylar塑料上。
- en: In disk-drive terminology, the small aluminum or glass disk is known as a *platter*.
    Each platter has two surfaces, front and back (or top and bottom), both of which
    have the magnetic coating. During operation, the hard-drive unit spins this platter
    at a particular speed, which these days is usually 3,600; 5,400; 7,200; 10,000;
    or 15,000 revolutions per minute (RPM). Generally, though not always, the faster
    the platter spins, the faster the data is read from the disk and the higher the
    data transfer rate between the disk and the system. The smaller disk drives in
    laptop computers typically spin at much slower speeds, like 2,000 or 4,000 RPM,
    to conserve battery life and generate less heat.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在硬盘驱动的术语中，小型的铝或玻璃盘片称为*盘片*。每个盘片有两个表面，前面和后面（或顶部和底部），这两个表面都涂有磁性涂层。在操作过程中，硬盘单元以特定的速度旋转这个盘片，通常的速度是3600、5400、7200、10000或15000转每分钟（RPM）。一般来说，虽然并不总是如此，盘片转速越快，从磁盘读取数据的速度越快，磁盘和系统之间的数据传输速率也越高。笔记本电脑中的小型硬盘通常以较慢的速度旋转，比如2000或4000
    RPM，以节省电池寿命并减少热量产生。
- en: 'A hard-disk subsystem contains two main active components: the disk platter(s)
    and the read/write head. The read/write head, when held stationary, floats above
    concentric circles, or *tracks*, on the disk surface. Each track is broken up
    into a sequence of sections known as *sectors* or *blocks*. The actual number
    of sectors varies by drive design, but a typical hard drive has between 32 and
    128 sectors per track (see [Figure 14-1](ch14.xhtml#ch14fig01)). Each sector typically
    holds between 256 and 4,096 bytes of data. Many disk-drive units let the OS choose
    between several different sector sizes, the most common being 512 bytes and 4,096
    bytes.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 硬盘子系统包含两个主要的活动组件：磁盘盘片和读写磁头。读写磁头在静止时，悬浮在磁盘表面的同心圆上，或称为*轨道*。每个轨道被分成一个个被称为*扇区*或*块*的部分。扇区的实际数量因硬盘设计而异，但典型的硬盘每个轨道上有32到128个扇区（参见[图14-1](ch14.xhtml#ch14fig01)）。每个扇区通常包含256到4096字节的数据。许多硬盘驱动单元允许操作系统在几种不同的扇区大小之间进行选择，最常见的有512字节和4096字节。
- en: '![image](../images/14fig01.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/14fig01.jpg)'
- en: '*Figure 14-1: Tracks and sectors on a hard-disk platter*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14-1：硬盘盘片上的轨道和扇区*'
- en: The disk drive records data when the read/write head sends a series of electrical
    pulses to the platter, which translates them into magnetic pulses that the platter’s
    magnetic surface retains. The frequency at which the disk controller can record
    these pulses is limited by the quality of the electronics, the read/write head
    design, and the quality of the magnetic surface.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 硬盘通过读写磁头向盘片发送一系列电脉冲来记录数据，这些电脉冲转化为磁脉冲并被盘片的磁性表面保存。磁盘控制器记录这些脉冲的频率受到电子质量、读写磁头设计和磁性表面质量的限制。
- en: The magnetic medium is capable of recording two adjacent bits on its disk surface
    and then differentiating between them during a later read operation. However,
    as you record bits closer and closer together, it becomes increasingly difficult
    to differentiate between them in the magnetic domain. *Bit density* is a measure
    of how closely a particular hard disk can pack data into its tracks—the higher
    the bit density, the more data you can squeeze onto a single track. However, recovering
    densely packed data requires faster and more expensive electronics.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 磁介质能够在其磁盘表面记录两个相邻的比特，并在稍后的读取操作中区分它们。然而，随着比特记录越来越紧密，它在磁性领域中变得越来越难以区分它们。*比特密度*是衡量某个硬盘能在其轨道中压缩数据的紧密程度——比特密度越高，单个轨道上可以挤压的数据就越多。然而，恢复密集压缩的数据需要更快和更昂贵的电子设备。
- en: The bit density has a big impact on the performance of the drive. If the drive’s
    platters are rotating at a fixed number of RPM, then the higher bit density, the
    more bits will rotate underneath the read/write head over a certain duration.
    Larger disk drives tend to be faster than smaller disk drives because they employ
    a higher bit density.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 比特密度对驱动器的性能有很大影响。如果驱动器的盘片以固定的转速旋转，那么比特密度越高，在一定时间内，更多的比特将会旋转到读写头下方。较大的磁盘驱动器通常比小型磁盘驱动器更快，因为它们采用了更高的比特密度。
- en: By moving the disk’s read/write head in a roughly linear path from the center
    of the disk platter to the outside edge, the system can position a single read/write
    head over any one of several thousand tracks. Yet the use of only one read/write
    head means that it will take a fair amount of time to move the head among the
    disk’s many tracks. Indeed, two of the most cited hard-disk performance parameters
    are the read/write head’s average seek time and track-to-track seek time.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将磁盘的读写头大致沿着从磁盘盘片中心到外缘的直线路径移动，系统可以将单个读写头定位到几千个轨道中的任何一个。然而，仅使用一个读写头意味着在磁盘的多个轨道之间移动头部需要相当长的时间。实际上，两个最常引用的硬盘性能参数是读写头的平均寻道时间和轨道到轨道寻道时间。
- en: The *average seek time* is half the amount of time it takes to move the read/write
    head from the edge of the disk to the center, or vice versa. A typical high-performance
    disk drive has an average seek time between 5 and 10 milliseconds. On the other
    hand, its *track-to-track seek time*—that is, the amount of time it takes to move
    the disk head from one track to the next—is on the order of 1 or 2 milliseconds.
    From these numbers, you can see that the acceleration and deceleration of the
    read/write head consumes a much greater percentage of the track-to-track seek
    time than of the average seek time. It takes only 20 times longer to traverse
    1,000 tracks than it does to move to the next track. And because moving the read/write
    heads from one track to the next is usually the most common operation, the track-to-track
    seek time is probably a better indication of the disk’s performance. Regardless
    of which metric you use, however, keep in mind that moving the disk’s read/write
    head is one of the most expensive operations you can do on a disk drive, so it’s
    something you want to minimize.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*平均寻道时间*是将读写头从磁盘的边缘移动到中心，或者反向移动所需时间的一半。一个典型的高性能磁盘驱动器的平均寻道时间在5到10毫秒之间。另一方面，它的*轨道到轨道寻道时间*——即将磁盘读写头从一个轨道移动到下一个轨道所需的时间——大约是1或2毫秒。从这些数字可以看出，读写头的加速和减速在轨道到轨道寻道时间中占据的比例远远高于在平均寻道时间中的比例。横跨1000个轨道的时间是移动到下一个轨道的时间的20倍。而且，由于将读写头从一个轨道移动到下一个轨道通常是最常见的操作，因此轨道到轨道寻道时间可能更能反映磁盘的性能。然而，无论你使用哪种度量标准，都要记住，移动磁盘的读写头是你在磁盘驱动器上可以执行的最昂贵的操作之一，所以你应该尽量减少这类操作。'
- en: Because most hard-drive subsystems record data on both sides of a disk platter,
    there are two read/write heads associated with each platter—one for the top and
    one for the bottom. And because most hard drives incorporate multiple platters
    in their disk assembly in order to increase storage capacity (see [Figure 14-2](ch14.xhtml#ch14fig02)),
    a typical drive has multiple pairs of read/write heads.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数硬盘子系统在磁盘盘片的两面上记录数据，因此每个盘片上有两个读写头——一个用于顶部，一个用于底部。由于大多数硬盘为了增加存储容量而在磁盘组件中采用多个盘片（见[图14-2](ch14.xhtml#ch14fig02)），一个典型的硬盘有多个读写头对。
- en: '![image](../images/14fig02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/14fig02.jpg)'
- en: '*Figure 14-2: Multiple-platter hard-disk assembly*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14-2：多盘片硬盘组件*'
- en: The various read/write heads are physically connected to the same actuator.
    Therefore, each head sits above the same track on its respective platter, and
    all the heads move across the disk surfaces as a unit. The set of all tracks over
    which the read/write heads are currently sitting is known as a *cylinder* (see
    [Figure 14-3](ch14.xhtml#ch14fig03)).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 各种读写头物理上连接到同一个执行器。因此，每个读写头都位于其各自盘片上的同一轨道上，并且所有读写头作为一个整体一起在磁盘表面上移动。当前所有读写头所在的轨道集合称为*圆柱*（参见[图
    14-3](ch14.xhtml#ch14fig03)）。
- en: '![image](../images/14fig03.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/14fig03.jpg)'
- en: '*Figure 14-3: A hard-disk cylinder*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14-3：硬盘圆柱*'
- en: Although using multiple heads and platters increases the cost of a hard-disk
    drive, it also improves the performance. The performance boost occurs when data
    the system needs isn’t located on the current track. In a hard-disk subsystem
    with only one platter, the read/write head would need to move to another track
    to locate the data. But in a subsystem with multiple platters, the next block
    of data to read is usually located within the same cylinder. And because the hard-disk
    controller can quickly switch between read/write heads electronically, doubling
    the number of platters in a disk subsystem nearly doubles the disk unit’s track-to-track
    seek performance because it winds up doing half the number of seek operations.
    Of course, increasing the number of platters also increases the unit’s capacity,
    which is another reason why high-capacity drives are often higher-performance
    drives as well.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用多个读写头和盘片会增加硬盘驱动器的成本，但也能提高性能。当系统所需的数据不位于当前轨道时，性能提升尤为明显。在只有一个盘片的硬盘子系统中，读写头需要移动到另一个轨道以找到数据。但在一个具有多个盘片的子系统中，下一块要读取的数据通常位于同一个圆柱内。而且，由于硬盘控制器可以快速在读写头之间进行电子切换，因此将盘片数量加倍，几乎可以使磁盘单元的轨道到轨道寻道性能加倍，因为它减少了寻道操作的次数。当然，增加盘片数量还会增加单元的存储容量，这也是高容量硬盘通常具有更高性能的原因之一。
- en: With older disk drives, when the system wants to read a particular sector from
    a particular track on one of the platters, it commands the disk to position the
    read/write head over the appropriate track, and the disk drive then waits for
    the desired sector to rotate underneath. But by the time the head settles down,
    there’s a chance that the desired sector has just passed under the head, in which
    case the disk has to wait for almost one complete rotation before it can read
    the data. On average, the desired sector appears halfway across the disk. If the
    disk is rotating at 7,200 RPM (120 revolutions per second), it requires 8.333
    milliseconds for one complete rotation of the platter. Typically, 4.2 milliseconds
    will pass before the sector rotates underneath the head. This delay is known as
    the *[average rotational latency](gloss01.xhtml#gloss01_22)* of the drive, and
    it is usually equal to the time needed for one rotation, divided by 2.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在较旧的磁盘驱动器中，当系统希望从某个盘片的某个轨道读取特定扇区时，它会指示磁盘将读写头定位到相应的轨道上，然后磁盘驱动器等待所需的扇区转到读写头下方。但是在读写头定位好之前，所需的扇区有可能已经刚好从读写头下方经过，这时磁盘必须等到几乎完成一整圈旋转后才能读取数据。平均而言，所需的扇区大约出现在磁盘的中间位置。如果磁盘以
    7,200 转每分钟（每秒 120 转）的速度旋转，则完成一次盘片旋转需要 8.333 毫秒。通常，在扇区转到读写头下方之前会有 4.2 毫秒的延迟。这种延迟称为*[平均旋转延迟](gloss01.xhtml#gloss01_22)*，通常等于一次旋转所需的时间除以
    2。
- en: To see how average rotational latency can be a problem, consider that an OS
    usually manipulates disk data in sector-sized chunks. For example, when reading
    data from a disk file, the OS typically requests that the disk subsystem read
    a sector of data and return that data. Upon receiving the data, the OS processes
    it and then very likely makes a request for additional data from the disk. But
    what happens when this second request is for data located on the next sector of
    the current track? Unfortunately, while the OS is processing the first sector’s
    data, the disk platters are still moving underneath the read/write heads. If the
    OS wants to read the next sector on the disk’s surface but doesn’t notify the
    drive immediately after reading the first sector, the second sector will rotate
    underneath the read/write head. When this happens, the OS will have to wait for
    almost a complete disk rotation before it can read the second sector. This is
    known as *blowing revs* (revolutions). If the OS (or application) is constantly
    blowing revs when reading data from a file, filesystem performance suffers dramatically.
    In early “single-tasking” OSes running on slower machines, blowing revs was an
    unpleasant fact of life. If a track had 64 sectors, it would often take 64 revolutions
    of the disk in order to read all the data on a single track.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解平均旋转延迟可能带来的问题，可以考虑操作系统通常以扇区大小的数据块来操作磁盘数据。例如，当从磁盘文件中读取数据时，操作系统通常请求磁盘子系统读取一个数据扇区并返回该数据。在收到数据后，操作系统会处理数据，然后很可能会向磁盘发出额外的数据请求。但是，当第二次请求的数据位于当前磁道的下一个扇区时会发生什么情况呢？不幸的是，当操作系统正在处理第一个扇区的数据时，磁盘盘片仍然在读写磁头下方转动。如果操作系统在读取第一个扇区后没有立即通知驱动器读取下一个磁道上的扇区，那么第二个扇区会在读写磁头下方旋转。这时，操作系统将不得不等待几乎一整个磁盘旋转周期，才能读取第二个扇区。这种现象被称为*转速丧失*（blowing
    revs）。如果操作系统（或应用程序）在读取文件数据时不断发生转速丧失，文件系统性能会显著下降。在早期的“单任务”操作系统中，这种转速丧失是一个令人不愉快的生活事实。如果一个磁道有64个扇区，通常需要磁盘旋转64次才能读取完一个磁道上的所有数据。
- en: To combat this problem, the disk-formatting routines for older drives allow
    the user to interleave sectors. *Interleaving* is the process of spreading out
    sectors within a track so that logically adjacent sectors are not physically adjacent
    on the disk surface (see [Figure 14-4](ch14.xhtml#ch14fig04)).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，旧款驱动器的磁盘格式化程序允许用户交错扇区。*交错*是将扇区分布在磁道上，使得逻辑上相邻的扇区在磁盘表面上并不物理相邻的过程（见[图14-4](ch14.xhtml#ch14fig04)）。
- en: The advantage of interleaving sectors is that once the OS reads a sector, it
    will take a full sector’s rotation time before the logically adjacent sector moves
    under the read/write head. This gives the OS time to do some processing and to
    issue a new disk I/O request before the desired sector moves underneath the head.
    However, in modern multitasking OSes, it’s difficult to guarantee that an application
    will gain control of the CPU so that it can respond before the next logical sector
    moves under the head, so interleaving isn’t very effective.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 交错扇区的优点是，一旦操作系统读取一个扇区，在逻辑上相邻的扇区旋转到读写磁头下方之前，会经过一个完整的扇区旋转时间。这给操作系统提供了时间来进行一些处理，并在所需的扇区进入读写磁头下方之前发出新的磁盘I/O请求。然而，在现代的多任务操作系统中，很难保证一个应用程序能获得CPU的控制权，以便在下一个逻辑扇区进入磁头下方之前做出响应，因此交错并不是很有效。
- en: '![image](../images/14fig04.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/14fig04.jpg)'
- en: '*Figure 14-4: Interleaving sectors*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*图14-4：扇区交错*'
- en: To solve this problem, as well as improve disk performance in general, most
    modern disk drives include memory on the disk controller that allows it to read
    data from an entire track in one disk revolution. Once it caches the track data
    in memory, the controller can communicate disk read/write operations at RAM speed
    rather than at disk rotation speeds, which can dramatically improve performance.
    Reading the first sector from a track still exhibits rotational latency, but once
    the disk controller reads the entire track, the latency is all but eliminated
    for that track.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，并提高磁盘性能，现代大多数磁盘驱动器在磁盘控制器中包括内存，使其能够在一次磁盘旋转中读取整个磁道的数据。一旦控制器将磁道数据缓存到内存中，控制器可以以RAM速度而非磁盘旋转速度进行磁盘读写操作，这可以显著提高性能。读取磁道的第一个扇区仍然会表现出旋转延迟，但一旦磁盘控制器读取整个磁道，延迟几乎会消失。
- en: A typical track may have 64 sectors of 512 bytes each, for a total of 32KB per
    track. Because newer disks usually have between 8MB and 512MB of on-controller
    memory, the controller can buffer hundreds of tracks in its memory. Therefore,
    the disk controller cache improves not only the performance of disk read/write
    operations on a single track, but also overall disk performance. Note that the
    disk controller cache speeds up read operations *and* write operations. For example,
    the CPU can often write data to the disk controller’s cache memory within a few
    microseconds and then return to normal data processing while the disk controller
    moves the disk read/write heads into position. When the disk heads are finally
    in position at the appropriate track, the controller can write the data from the
    cache to the disk surface.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的轨道可能有 64 个扇区，每个扇区 512 字节，总共 32KB 每个轨道。由于新型硬盘通常具有 8MB 到 512MB 的控制器内存，因此控制器可以在其内存中缓存数百个轨道。因此，磁盘控制器缓存不仅提高了单个轨道上磁盘读写操作的性能，还提高了整体磁盘性能。请注意，磁盘控制器缓存加速了读操作*和*写操作。例如，CPU
    通常可以在几微秒内将数据写入磁盘控制器的缓存内存，然后返回到正常的数据处理，同时磁盘控制器将磁头移动到适当的轨道位置。当磁头最终到达适当的轨道位置时，控制器可以将缓存中的数据写入磁盘表面。
- en: From an application designer’s perspective, advances in disk subsystem design
    have reduced the need to understand how disk-drive geometries (track and sector
    layouts) and disk-controller hardware affect the application’s performance. Despite
    these attempts to make the hardware transparent to the application, though, software
    engineers wanting to write great code must always remain cognizant of the disk
    drive’s underlying operation. For example, it’s valuable to know that sequential
    file operations are usually much faster than random-access operations because
    sequential operations require fewer head seeks. Also, if you know that a disk
    controller has an on-board cache, you can write file data in smaller blocks, doing
    other processing between the block operations, to give the hardware time to write
    the data to the disk surface. Though the techniques early programmers used to
    maximize disk performance don’t apply to modern hardware, by understanding how
    disks operate and how they store their data, you can avoid various pitfalls that
    produce slow code.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从应用设计者的角度来看，磁盘子系统设计的进展减少了理解磁盘驱动器几何结构（轨道和扇区布局）以及磁盘控制器硬件如何影响应用程序性能的必要性。尽管有这些努力使硬件对应用程序透明，然而，想要编写出优秀代码的软件工程师必须始终意识到磁盘驱动器的底层操作。例如，知道顺序文件操作通常比随机访问操作快得多是非常有价值的，因为顺序操作需要的磁头寻道次数较少。此外，如果你知道磁盘控制器有板载缓存，你可以将文件数据写入较小的块，在块操作之间做其他处理，从而为硬件写入数据到磁盘表面提供时间。尽管早期程序员用来最大化磁盘性能的技术不适用于现代硬件，但通过了解磁盘的工作原理及其数据存储方式，你可以避免导致代码运行缓慢的各种陷阱。
- en: '***14.1.3 RAID Systems***'
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.1.3 RAID 系统***'
- en: Because a modern disk drive typically has between 8 and 16 heads, you might
    wonder if you could improve performance by simultaneously reading or writing data
    on multiple heads. While this is certainly possible, it really didn’t happen until
    SATA and larger disk caches came along. But there’s yet another way to improve
    disk drive performance using parallel read and write operations—the *redundant
    array of inexpensive disks (RAID)* configuration.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于现代硬盘通常有 8 到 16 个磁头，你可能会想知道是否可以通过同时在多个磁头上读取或写入数据来提高性能。虽然这在理论上是可能的，但直到 SATA
    和更大的磁盘缓存出现之前，实际上并没有发生过这种情况。但还有另一种提高磁盘驱动器性能的方法，那就是使用并行读写操作——*冗余廉价磁盘阵列（RAID）*配置。
- en: 'The RAID concept is quite simple: you connect multiple hard-disk drives to
    a special host controller card (sometimes known as an *adapter*), which simultaneously
    reads and writes the various disk drives. By hooking up two disk drives to a RAID
    controller card, you can read and write data about twice as fast as you could
    with a single disk drive. By hooking up four disk drives, you can improve average
    performance by almost a factor of 4.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: RAID 的概念非常简单：你将多个硬盘驱动器连接到一个特殊的主机控制卡（有时称为*适配器*），该控制卡同时读取和写入各个硬盘驱动器。通过将两个硬盘连接到
    RAID 控制卡，你可以实现比单个硬盘驱动器快大约两倍的读写速度。通过连接四个硬盘驱动器，你可以将平均性能提高接近四倍。
- en: RAID controllers support different configurations depending on the purpose of
    the disk subsystem. So-called *[RAID 0](gloss01.xhtml#gloss01_209)* subsystems
    use multiple disk drives simply to increase the data transfer rate. If you connect
    two 150GB disk drives to a RAID controller, you’ll produce the equivalent of a
    300GB disk subsystem with double the data transfer rate. This is a typical configuration
    for personal RAID systems—those systems that are not installed on a file server.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: RAID控制器根据磁盘子系统的用途支持不同的配置。所谓的*[RAID 0](gloss01.xhtml#gloss01_209)*子系统使用多个磁盘驱动器仅仅是为了提高数据传输速率。如果你将两块150GB的磁盘驱动器连接到RAID控制器，你将得到相当于300GB的磁盘子系统，并且数据传输速率翻倍。这是个人RAID系统的典型配置——即那些没有安装在文件服务器上的系统。
- en: Many high-end file-server systems are *RAID 1* (and higher) subsystems that
    store multiple copies of the data across the multiple disk drives, rather than
    increasing the data transfer rate between the system and the disk drive. In such
    configurations, should one disk fail, a copy of the data is still available on
    another disk drive. Some even higher-level RAID subsystems combine four or more
    disk drives to increase the data transfer rate and provide redundant data storage.
    This type of configuration usually appears on high-end, high-availability file
    server systems.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 许多高端文件服务器系统是*RAID 1*（及更高版本）子系统，这些系统将数据的多个副本存储在多个磁盘驱动器上，而不是通过提高系统与磁盘驱动器之间的数据传输速率。在这种配置下，如果某块磁盘发生故障，数据的副本仍会保存在另一块磁盘上。一些更高级别的RAID子系统结合了四块或更多的磁盘驱动器，以提高数据传输速率并提供冗余数据存储。这种配置通常出现在高端、高可用性的文件服务器系统中。
- en: 'Modern RAID system configurations can be categorized as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现代RAID系统配置可以分为以下几类：
- en: '**RAID 0** Interleaves data across all disks to increase performance (at the
    expense of reliability). This is known as *striping*. Requires a minimum of two
    disks.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAID 0** 将数据交错存储在所有磁盘上以提高性能（以牺牲可靠性为代价）。这被称为*条带化*。需要至少两块磁盘。'
- en: '**RAID 1** Replicates data on pairs of drives to increase reliability (at the
    cost of performance; also cuts in half the total amount of storage available).
    Allows failure of at least one drive without data loss (depending on the drives
    that fail, could support two or more drive failures). Requires an even number
    of drives, with a minimum of two disks. This is known as *mirroring*.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAID 1** 将数据复制到成对的磁盘上，以提高可靠性（以牺牲性能为代价；同时将可用的总存储空间减少一半）。允许至少一块磁盘故障而不丢失数据（根据故障磁盘的不同，可能支持两块或更多磁盘的故障）。需要偶数块磁盘，最少两块磁盘。这被称为*镜像*。'
- en: '**RAID 5** Stores parity information on the drives. Faster than RAID 1, slower
    than RAID 0\. Allows failure of one drive without data loss. Requires a minimum
    of three drives. At three drives, 66 percent of the total storage is available
    for data; any drives you add beyond three increase data storage by the size of
    the added drive.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAID 5** 在磁盘上存储校验信息。比RAID 1快，比RAID 0慢。允许一块磁盘故障而不丢失数据。最少需要三块磁盘。使用三块磁盘时，66%的总存储空间可用于数据；超过三块磁盘时，增加的磁盘空间将提高数据存储容量。'
- en: '**RAID 6** Stores duplicate parity information across the drives. Faster than
    RAID 1, slower than RAID 0 and 5\. Allows failure of two drives without data loss.
    Requires a minimum of four drives. At four drives, half the total storage is available
    for data, but any drives you add beyond four increase system storage by the size
    of the added drive.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAID 6** 在磁盘上存储冗余的校验信息。比RAID 1快，比RAID 0和RAID 5慢。允许两块磁盘故障而不丢失数据。最少需要四块磁盘。使用四块磁盘时，一半的总存储空间可用于数据，但超过四块磁盘时，增加的磁盘空间将提高系统存储容量。'
- en: '**RAID 10** Combination of RAID 1 + RAID 0\. Minimum four drives; expansion
    has to be in pairs of drives. Interleaved (striped) data across drives to speed
    up performance, plus redundant storage on pairs of drives for reliability. Faster
    than RAID 1 (but slower than RAID 0).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAID 10** 是RAID 1 + RAID 0的组合。最少需要四块驱动器；扩展必须以成对驱动器的形式进行。数据在磁盘间交错（条带化）以提高性能，并且在成对的驱动器上提供冗余存储以确保可靠性。比RAID
    1快（但比RAID 0慢）。'
- en: '**RAID 50****, 60** Combination of RAID 5 + RAID 0 or RAID 6 + RAID 0.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAID 50**, **RAID 60** 是RAID 5 + RAID 0 或 RAID 6 + RAID 0的组合。'
- en: There are other RAID combinations (like 2, 3, and 4), but most are obsolete
    and you won’t find them in use in modern systems.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他RAID组合（如2、3和4），但大多数已经过时，你不会在现代系统中看到它们的使用。
- en: RAID systems enable you to dramatically increase disk subsystem performance
    without having to purchase exotic and expensive mass storage solutions. Though
    a software engineer can’t assume that every computer system in the world has a
    fast RAID subsystem available, for those applications that demand the absolute
    highest-performance storage subsystem, RAID (possibly using SSDs) could be a solution.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: RAID系统使你能够显著提高磁盘子系统的性能，而无需购买昂贵且特殊的大容量存储解决方案。尽管软件工程师不能假设世界上所有的计算机系统都有可用的快速RAID子系统，但对于那些要求绝对最高性能存储子系统的应用，RAID（可能使用SSD）可以是一个解决方案。
- en: '***14.1.4 Optical Drives***'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.1.4 光驱***'
- en: 'An optical drive uses a laser beam and a special photosensitive medium to record
    and play back digital data. Optical drives have a few advantages over hard-disk
    subsystems that use magnetic media:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 光驱使用激光束和特殊的光敏介质来记录和播放数字数据。与使用磁性介质的硬盘子系统相比，光驱有一些优势：
- en: They are more shock resistant, so banging the disk drive around during operation
    won’t destroy the drive unit as easily as it would a hard disk.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们更具抗震性，因此在操作过程中敲击磁盘驱动器时，不会像硬盘那样轻易损坏驱动单元。
- en: The medium is usually removable, allowing you to maintain an almost unlimited
    amount of offline or near-line storage.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该介质通常是可拆卸的，可以让你保持几乎无限量的离线或近线存储。
- en: They’re fairly high-capacity (though modern USB memory sticks and SD cards have
    greater capacities).
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们的容量相当大（尽管现代的USB闪存驱动器和SD卡的容量更大）。
- en: 'At one time, optical storage systems appeared to be the wave of the future
    because they offered very high storage capacity in a small space. Unfortunately,
    they have fallen out of favor in all but a few niche markets because they also
    have several drawbacks:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 曾几何时，光存储系统看起来像是未来的趋势，因为它们在一个小空间内提供了非常高的存储容量。不幸的是，除了少数一些细分市场外，它们已不再受欢迎，因为它们也有几个缺点：
- en: While their read performance is okay, their write speed is very slow—an order
    of magnitude slower than a hard drive and only a few times faster than a *floptical*
    (older combined magnetic/optical floppy) drive.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然它们的读取性能尚可，但写入速度非常慢——比硬盘慢一个数量级，而且只比*磁光*（旧的结合磁性/光学的软盘）驱动器快几倍。
- en: Although the optical medium is far more robust than the magnetic medium, the
    magnetic medium in a hard drive is usually sealed away from dirt, humidity, and
    abrasion. In contrast, optical media is easily accessible to someone who really
    wants to do damage to the disk’s surface.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管光学介质比磁性介质要坚固得多，但硬盘中的磁性介质通常被密封，以防尘土、湿气和磨损。相比之下，光学介质很容易被任何真正想要损坏磁盘表面的人接触到。
- en: Seek times for optical-disk subsystems are much slower than for magnetic disks.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光盘子系统的寻址时间远比磁盘慢。
- en: Optical disks have limited storage capacity, currently less than about 128GB
    (Blu-ray).
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光盘的存储容量有限，目前低于约128GB（蓝光）。
- en: Ultimately, the low price and increasing capacity of USB flash drives killed
    off optical drives for personal computer use.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，USB闪存驱动器的低价和日益增长的容量使得光驱在个人电脑中的使用逐渐消失。
- en: One area where optical-disk subsystems are still in use, however, is in *near-line
    storage subsystems*, which typically use a robotic jukebox to manage hundreds
    or thousands of optical disks. Although you could argue that a rack of high-capacity
    hard-disk drives would provide a more space-efficient storage solution, it would
    consume far more power, generate far more heat, and require a more sophisticated
    interface than an optical jukebox, which usually has only a single optical-drive
    unit and a robotic disk-selection mechanism. For archival storage, where the server
    system rarely needs access to any particular piece of data in the storage subsystem,
    a jukebox system is a very cost-effective solution.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，光盘子系统仍然在*近线存储子系统*中使用，这些系统通常使用机器人唱机来管理数百或数千张光盘。虽然可以争辩说，一排高容量硬盘驱动器会提供更节省空间的存储解决方案，但它将消耗更多电力，产生更多热量，并且需要比光盘唱机更复杂的接口，后者通常只有一个光驱单元和一个机器人磁盘选择机制。对于归档存储，服务器系统很少需要访问存储子系统中的任何特定数据，唱机系统是一种非常具有成本效益的解决方案。
- en: If you wind up writing software that manipulates files on an optical-drive subsystem,
    the most important thing to remember is that read access is much faster than write
    access. You should try to use the optical system as a “read-mostly” device and
    avoid writing data as much as possible to the device. You should also avoid random
    access on an optical disk’s surface, as seek times are very slow.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你编写的软件需要操作光驱子系统上的文件，最重要的是记住读取访问速度远快于写入访问速度。你应该尽量将光驱系统作为“以读为主”的设备，并尽量避免向设备写入数据。你还应该避免在光盘表面进行随机访问，因为寻道时间非常慢。
- en: CD, DVD, and Blu-ray drives are also optical drives. However, because of their
    widespread use, and their sufficiently different organization and performance
    when compared with standard optical drives, they warrant a separate discussion.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: CD、DVD和Blu-ray驱动器也是光驱。不过，由于它们的广泛使用，以及与标准光驱相比，其组织和性能的显著不同，它们值得单独讨论。
- en: '***14.1.5 CD, DVD, and Blu-ray Drives***'
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.1.5 CD、DVD和Blu-ray驱动器***'
- en: CD-ROM was the first optical drive subsystem to gain wide acceptance in the
    personal computer market. CD-ROM disks were based on the audio CD digital recording
    standard, and they provided a large amount of storage (650MB) when compared to
    hard-disk-drive storage capacities at the time (typically 100MB). As time passed,
    of course, this relationship reversed. Still, CD-ROMs became the preferred distribution
    vehicle for most commercial applications, completely replacing the floppy-disk
    medium for this purpose.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: CD-ROM是第一个在个人计算机市场上获得广泛接受的光驱子系统。CD-ROM磁盘基于音频CD的数字录音标准，并且与当时的硬盘驱动器存储容量（通常为100MB）相比，它们提供了大量存储（650MB）。随着时间的推移，当然这种关系发生了反转。不过，CD-ROM仍然成为大多数商业应用的首选分发载体，完全取代了软盘作为这一目的的媒介。
- en: Although the CD-ROM format is a very inexpensive distribution medium in large
    quantities, often costing only a few cents per disk, it’s not appropriate for
    small production runs. The problem is that it typically costs several hundreds
    or thousands of dollars to produce a disk master (from which the run of CD-ROMs
    are made), meaning that CD-ROM is usually cost-effective only when the quantity
    of disks being produced is at least in the thousands.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管CD-ROM格式在大批量分发中非常便宜，通常每张磁盘只需几美分，但它不适合小批量生产。问题在于，制作一个磁盘母盘（用于制作一批CD-ROM）通常需要花费数百或数千美元，这意味着只有在生产的磁盘数量达到至少几千张时，CD-ROM才通常具有成本效益。
- en: The solution was a new CD medium, CD-Recordable (CD-R), which allowed the production
    of one-off CD-ROMs. CD-R uses a write-once optical disk technology, known euphemistically
    as *WORM* (write-once, read-many). When first introduced, CD-R disks cost about
    $10 to $15\. However, once the drives reached critical mass and media manufacturers
    began producing blank CD-R disks in huge quantities, their bulk retail price fell
    to about $0.25\. As a result, CD-R made it possible to distribute a fair amount
    of data in small quantities.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是新的CD介质——CD-可记录（CD-R），它允许制作一次性CD-ROM。CD-R使用一次写入的光盘技术，委婉地称为*WORM*（一次写入，多次读取）。首次推出时，CD-R磁盘的价格大约为10到15美元。然而，一旦驱动器达到临界数量，媒体制造商开始大规模生产空白CD-R磁盘，它们的批发零售价格降至大约0.25美元。因此，CD-R使得分发大量小数据成为可能。
- en: One obvious drawback to CD-R is the “write-once” limitation. To overcome it,
    the CD-Rewriteable (CD-RW) drive and medium were created. CD-RW, as its name suggests,
    supports both reading and writing. Unlike with optical disks, however, you can’t
    simply rewrite a single sector on CD-RW. Instead, to rewrite the data on a CD-RW
    disk, you must first erase the whole disk.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: CD-R的一个明显缺点是“一次写入”的限制。为了解决这一问题，创建了CD-可重写（CD-RW）驱动器和介质。顾名思义，CD-RW支持读取和写入。然而，与光盘不同的是，你不能仅仅重写CD-RW上的某一个扇区。相反，要在CD-RW磁盘上重写数据，你必须先擦除整个磁盘。
- en: Although the 650MB of storage on a CD seemed like a gargantuan amount when CDs
    were first introduced, the old maxim that data and programs expand to fill up
    all available space certainly held true. Though CDs were ultimately expanded to
    700MB, various games (with embedded video), large databases, developer documentation,
    programmer development systems, clip art, stock photographs, and even regular
    applications reached the point where a single CD was woefully inadequate. The
    DVD-ROM (and later, DVD-R, DVD-RW, DVD+RW, and DVD-RAM) disk reduced this problem
    by offering between 3GB and 17GB of storage on a single disk. Except for the DVD-RAM
    format, you can view the DVD formats as faster, higher-capacity versions of the
    CD formats. There are some clear technical differences between the two, but most
    of them are transparent to the software. Today, Blu-ray optical discs deliver
    up to 128GB of storage (Blu-ray BDXL). However, electronic distribution via the
    internet has largely replaced physical media, so Blu-ray discs have never become
    as popular as distribution or storage media.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管当 CD 首次推出时，650MB 的存储空间看起来像是一个巨大的容量，但“数据和程序会填满所有可用空间”这一古老的格言在实际中完全成立。尽管 CD
    最终扩展到了 700MB，但各种游戏（含嵌入视频）、大型数据库、开发者文档、程序员开发系统、剪贴画、股票照片，甚至常规应用程序，都达到了一个单一 CD 无法满足的程度。DVD-ROM（后来是
    DVD-R、DVD-RW、DVD+RW 和 DVD-RAM）磁盘通过在单个磁盘上提供 3GB 到 17GB 的存储空间解决了这个问题。除了 DVD-RAM
    格式外，DVD 格式可以看作是 CD 格式的更快、更大容量的版本。两者之间有一些明显的技术差异，但大多数差异对软件而言是透明的。今天，蓝光光盘提供高达 128GB
    的存储空间（蓝光 BDXL）。然而，通过互联网进行的电子分发已经在很大程度上取代了物理介质，因此蓝光光盘从未像分发或存储介质那样普及。
- en: The CD and DVD formats were created for reading data in a continuous stream—*streaming*
    data—from the storage medium. The track-to-track head movement time required to
    read data stored on a hard disk creates a big gap in the streaming sequence, which
    is unacceptable for audio and video applications. CDs and DVDs record information
    on a single, very long track that forms a spiral across the surface of the whole
    disk. Thus, the CD or DVD player can continuously read the data simply by moving
    the laser beam along the disk’s single spiral track at a constant rate.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: CD 和 DVD 格式是为了从存储介质中读取连续流数据——*流式*数据而创建的。读取硬盘上存储的数据所需的磁头到磁头的移动时间，在流式数据传输序列中产生了一个较大的间隙，这对于音频和视频应用来说是不可接受的。CD
    和 DVD 将信息记录在一个单一的、非常长的轨道上，这个轨道在整个磁盘表面形成一个螺旋形。因此，CD 或 DVD 播放器可以通过以恒定速度沿着磁盘的单一螺旋轨道移动激光束，来连续读取数据。
- en: Although having a single track is great for streaming data, it does make it
    a bit more difficult to locate a specific sector on the disk. The CD or DVD drive
    can only approximate a sector’s position by mechanically positioning the laser
    beam to some point on the disk. Next, it must actually read data from the disk
    surface to determine where the laser is positioned, and then do some fine-tuning
    to locate the desired sector. As a result, searching for a specific sector on
    a CD or DVD disk can take an order of magnitude longer than searching for a specific
    sector on a hard disk.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然拥有单一轨道非常适合流式数据的传输，但这也使得在磁盘上定位特定扇区变得更加困难。CD 或 DVD 驱动器只能通过机械地将激光束定位到磁盘上的某个位置，来大致估算扇区的位置。接下来，它必须从磁盘表面实际读取数据，以确定激光的位置，然后进行微调以定位所需的扇区。因此，在
    CD 或 DVD 磁盘上搜索特定扇区的时间可能比在硬盘上搜索特定扇区的时间长一个数量级。
- en: The most important thing to remember for a programmer writing code that interacts
    with CD or DVD media is that random access is verboten. These media were designed
    for sequential streaming access, and seeking data on such media will hinder your
    application performance. If you’re using these disks to deliver your application
    and its data to the end user, you should have the user copy the data to a hard
    disk before use if high-performance random access is necessary.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于编写与 CD 或 DVD 媒体交互的代码的程序员来说，最重要的要记住的是随机访问是禁忌的。这些媒体是为顺序流式访问设计的，在这样的媒体上查找数据会影响你的应用程序性能。如果你使用这些光盘来将应用程序及其数据提供给最终用户，如果需要高性能的随机访问，应该让用户在使用前将数据复制到硬盘上。
- en: '**14.2 Tape Drives**'
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**14.2 磁带驱动器**'
- en: Tape drives were also popular mass storage devices. Traditionally, PC owners
    used tape drives to back up data stored on hard-disk drives back in the days when
    hard drives were much smaller. For many years, tape storage was far more cost-effective
    than hard-disk storage on a cost-per-megabyte basis. Indeed, at one time there
    was an order of magnitude difference in cost per megabyte between tape storage
    and magnetic disk storage. And because tape drives held more data than most hard-disk
    drives, they were more space-efficient too.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 磁带驱动器曾是流行的大容量存储设备。在硬盘驱动器容量较小的年代，PC 用户通常使用磁带驱动器来备份存储在硬盘上的数据。许多年里，磁带存储的每兆字节成本远低于硬盘存储。事实上，曾经磁带存储和磁盘存储之间每兆字节的成本差距达到了一个数量级。而且，由于磁带驱动器比大多数硬盘驱动器存储更多的数据，它们在空间利用上也更高效。
- en: However, because of competition and technological advances in the hard-disk-drive
    marketplace, tapes have lost these advantages. Hard-disk drives now exceed 16TB
    in storage, and the optimum price point for hard disks is about $0.25 per gigabyte.
    Tape storage today costs far more per megabyte than hard-disk storage. Plus, only
    a few tape technologies allow you to store 250GB on a single tape, and those that
    do (such as Digital Linear Tape, or DLT) are extremely expensive. It’s not surprising
    that tape drives are seeing less and less use these days in home PCs and are typically
    found only in larger file server machines. Linear Tape-Open (LTO) drives extend
    the capacity to around 12TB (expected to increase to around 200TB in the future).
    Nevertheless, today a typical LTO-8 tape costs almost $130 (US), about half the
    price per megabyte of a hard drive.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于竞争和硬盘驱动器市场的技术进步，磁带逐渐失去了这些优势。如今，硬盘驱动器的存储容量已超过16TB，硬盘的最优价格点大约为每GB $0.25。如今，磁带存储每兆字节的成本远高于硬盘存储。此外，只有少数几种磁带技术可以在单个磁带上存储250GB的数据，而且这些技术（如数字线性磁带（DLT））非常昂贵。难怪磁带驱动器在如今的家庭PC中使用越来越少，通常只出现在大型文件服务器上。线性磁带开放（LTO）驱动器的容量已扩展到大约12TB（预计未来可达到约200TB）。尽管如此，今天一盘典型的LTO-8磁带的价格几乎为$130（美元），每兆字节的价格大约是硬盘的一半。
- en: Back in the days of mainframes, application programs interacted with tape drives
    in much the same way that today’s applications interact with hard-disk drives.
    A tape drive, however, is not an efficient random-access device. That is, although
    software can read a random set of blocks from a tape, it cannot do so with acceptable
    performance. Of course, in the days when most applications ran on mainframes,
    applications generally were not interactive, and CPUs were much slower; thus,
    the standard for “acceptable performance” was different.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型机时代，应用程序与磁带驱动器的交互方式与今天的应用程序与硬盘驱动器的交互方式非常相似。然而，磁带驱动器并不是一个高效的随机访问设备。也就是说，尽管软件可以从磁带中读取随机位置的数据块，但其性能并不理想。当然，在大多数应用程序运行在大型机上的时代，应用程序通常不是交互式的，而且CPU的处理速度也更慢；因此，“可接受性能”的标准是不同的。
- en: In a tape drive, the read/write head is fixed, and the tape transport mechanism
    moves the tape past the head linearly, from the beginning of the tape to the end,
    or vice versa. If the beginning of the tape is currently positioned over the read/write
    head and you want to read data at the end of the tape, you have to move the entire
    tape past the head to get to the desired data. This can be very slow, requiring
    tens or even hundreds of seconds, depending on the length and format of the tape.
    Compare this with the tens of milliseconds it takes to reposition a hard disk’s
    read/write head (or the negligible time it takes to get data from an SSD). Therefore,
    to perform well on a tape drive, software must be written to account for the limitations
    of a sequential access device. In particular, data should be read or written sequentially
    on a tape.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在磁带驱动器中，读写头是固定的，磁带传输机制会将磁带沿线性方式从磁带的起始位置移动到结束位置，或反之。如果此时磁带的起始位置正好位于读写头下方，而你想读取磁带末端的数据，就必须将整个磁带移动过读写头，才能到达所需的数据。这可能非常缓慢，可能需要几十秒甚至几百秒，具体取决于磁带的长度和格式。相比之下，硬盘读写头重新定位的时间通常只有几十毫秒（或者SSD的数据访问几乎是瞬间完成的）。因此，为了在磁带驱动器上获得良好的性能，软件必须针对顺序访问设备的限制进行编写。特别是，数据应该在磁带上按顺序读取或写入。
- en: Originally, data was written to tapes in blocks (much like sectors on a hard
    disk), and the drives were designed to allow quasi-random access to the tape’s
    blocks. If you’ve ever watched old movies that used the reel-to-reel drives, with
    the reels constantly stopping, starting, stopping, reversing, stopping, and continuing,
    you’ve seen “random access” in action. Such tape drives were very expensive because
    they required powerful motors, finely tooled tape-path mechanisms, and so on.
    As hard drives became larger and less expensive, applications stopped using tape
    as a data manipulation medium and used it only for offline storage (to back up
    data from hard disks).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，数据是以块的形式写入磁带（就像硬盘上的扇区一样），并且驱动器被设计为允许准随机访问磁带的块。如果你曾经看过使用磁带驱动器的老电影，看到磁带卷轴不断地停止、启动、停止、反转、停止、继续，你就看到了“随机访问”的实际操作。这种磁带驱动器非常昂贵，因为它们需要强大的电机、精细加工的磁带路径机制等等。随着硬盘容量的增加和价格的下降，应用程序不再将磁带作为数据处理介质，仅将其用于离线存储（备份硬盘数据）。
- en: Because sequential data access on tape does not require the heavy-duty mechanics
    of the original tape drives, tape-drive manufacturers sought to make a lower-cost
    product suitable for sequential access only. Their solution was the *streaming
    tape drive*, which was designed to keep the data constantly moving from the CPU
    to the tape, or vice versa. For example, while backing up the data from a hard
    disk to tape, a streaming tape drive treats the data like a video or audio recording
    and just lets the tape run, constantly writing the data from the hard disk to
    the tape. Because of the way streaming tape drives work, very few applications
    deal directly with the tape unit. Today, it’s very rare for anything other than
    a tape backup utility program, run by the system administrator, to access the
    tape hardware.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于磁带的顺序数据访问不再需要原始磁带驱动器的重型机械结构，磁带驱动器制造商试图制造一种低成本的产品，专门用于顺序访问。它们的解决方案是*流式磁带驱动器*，其设计目的是让数据不断地从CPU传输到磁带，或者反之。例如，在将硬盘数据备份到磁带时，流式磁带驱动器像录音视频一样处理数据，让磁带不断运行，将硬盘数据持续写入磁带。由于流式磁带驱动器的工作方式，极少有应用程序直接与磁带单元交互。今天，除了由系统管理员运行的磁带备份工具程序外，其他任何程序几乎都不会访问磁带硬件。
- en: '**14.3 Flash Storage**'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**14.3 闪存存储**'
- en: An interesting storage medium that has become popular because of its compact
    form factor^([2](footnotes.xhtml#fn14_2a)) is flash storage. The flash medium
    is actually a semiconductor device, based on *electrically erasable programmable
    read-only memory (EEPROM)* technology, which, despite its name, is both readable
    and writable. Unlike regular semiconductor memory, flash storage is *nonvolatile*,
    meaning it maintains its data even when disconnected from power. Like other semiconductor
    technologies, flash storage is purely electronic and doesn’t require any motors
    or other electromechanical devices for proper operation. Therefore, flash storage
    devices are more reliable and shock resistant, and they use far less power than
    mechanical storage solutions such as disk drives. This makes flash storage especially
    valuable in portable battery-powered devices like cell phones, tablets, laptop
    computers, electronic cameras, MP3 playback devices, and recorders.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一种由于其紧凑的形态而变得流行的存储介质是闪存。闪存介质实际上是一种半导体设备，基于*电可擦可编程只读存储器（EEPROM）*技术，尽管名称中包含“只读”，但它既可读取也可写入。与常规的半导体存储器不同，闪存是*非易失性的*，意味着即使断电，它也能保持数据。像其他半导体技术一样，闪存存储完全依赖电子操作，不需要任何马达或其他机电设备才能正常工作。因此，闪存存储设备比机械存储解决方案（如硬盘驱动器）更可靠、更抗震，并且消耗的电量远低于这些机械存储设备。这使得闪存存储在便携式电池驱动设备中尤其有价值，如手机、平板电脑、笔记本电脑、电子相机、MP3播放器和录音机。
- en: Flash storage modules now provide in excess of 1TB of storage, and their optimal
    price point is about $0.15 (US) per gigabyte. This makes them comparable, per
    bit, to hard-disk storage.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，闪存存储模块提供超过1TB的存储空间，其最佳价格大约为每千兆字节0.15美元（美国）。这使得它们在每比特的成本上与硬盘存储相当。
- en: Flash devices are sold in many different form factors. OEMs (original equipment
    manufacturers) can buy flash storage devices that look like other semiconductor
    chips and mount them directly on their circuit boards. However, most flash memory
    devices sold today are built into one of several standard forms, including SDHC
    cards, CompactFlash cards, smart-memory modules, memory sticks, USB/flash modules,
    or SSDs. For example, you might remove a CompactFlash card from your camera, insert
    it into a special CompactFlash card reader on your PC, and access your photographs
    just as you would files on a disk drive.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 闪存设备以多种不同的形式销售。OEM（原始设备制造商）可以购买外观类似其他半导体芯片的闪存存储设备，并将其直接安装在电路板上。然而，今天销售的大多数闪存存储设备都被集成在几种标准形式中，包括SDHC卡、CompactFlash卡、智能内存模块、存储棒、USB/闪存模块或SSD。例如，你可能会从相机中取出CompactFlash卡，将其插入PC上的特殊CompactFlash卡读卡器，然后像访问磁盘驱动器上的文件一样访问你的照片。
- en: Memory in a flash storage module is organized in blocks of bytes, not unlike
    sectors on a hard disk. In contrast to regular semiconductor memory or RAM, however,
    you can’t write individual bytes in a flash storage module. Although you can generally
    *read* an individual byte from a flash storage device, to write to a particular
    byte you must first erase the entire block on which it resides. The block size
    varies by device, but most OSes treat these flash blocks like a disk sector for
    the purposes of reading and writing. Although the basic flash storage device itself
    could connect directly to the CPU’s memory bus, most common flash storage packages
    (such as CompactFlash cards and memory sticks) contain electronics that simulate
    a hard-disk interface, and you access the flash device just as you would a hard-disk
    drive.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 闪存存储模块中的内存是以字节块的形式组织的，类似于硬盘上的扇区。然而，与普通的半导体内存或RAM不同，你不能在闪存存储模块中写入单个字节。尽管通常可以*读取*闪存存储设备中的单个字节，但要写入特定字节，你必须首先擦除该字节所在的整个块。块的大小因设备而异，但大多数操作系统会将这些闪存块视为磁盘扇区，用于读取和写入。尽管基本的闪存存储设备本身可以直接连接到CPU的内存总线，但大多数常见的闪存存储包（如CompactFlash卡和存储棒）包含模拟硬盘接口的电子元件，你可以像访问硬盘驱动器一样访问闪存设备。
- en: One interesting aspect to flash memory devices, and EEPROM devices in general,
    is that they have a limited write lifetime. That is, you can write to a particular
    memory cell in a flash memory module only a certain number of times before that
    cell begins to have problems retaining the information. This was a big concern
    in early EEPROM/flash devices, because the average number of write cycles before
    failures began occurring was around 10,000\. That is, if some software wrote to
    the same memory block 10,000 times in a row, the EEPROM/flash device would probably
    develop a bad memory cell in that block, effectively rendering the entire chip
    useless. On the other hand, if the software wrote just once to 10,000 separate
    blocks, the device could still take 9,999 more writes to each memory cell. Therefore,
    the OSes of these early devices would try to spread out write operations across
    the entire device to minimize damage. Although modern flash devices still exhibit
    this problem, technological advances have reduced it almost to the point where
    we can ignore it. A modern flash memory cell supports an average of about a million
    write cycles before it will go bad. Furthermore, today’s OSes simply mark bad
    flash blocks, the same way they mark bad sectors on a disk, and will skip a block
    once they determine that it has gone bad.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 闪存内存设备，尤其是EEPROM设备，的一个有趣方面是它们有一个有限的写入寿命。也就是说，你只能在闪存内存模块的特定存储单元中写入一定次数的数据，超过这个次数后，该单元将开始无法保持信息。早期的EEPROM/闪存设备中，这个问题尤为严重，因为在出现故障之前的平均写入次数大约为10,000次。也就是说，如果某个软件连续写入同一个内存块10,000次，那么该EEPROM/闪存设备可能会在该块中产生坏内存单元，从而使整个芯片失效。另一方面，如果软件仅在10,000个独立的块中各写一次，该设备仍然可以在每个存储单元上进行9,999次写入。因此，这些早期设备的操作系统会尽量将写操作分散到整个设备中，以减少损坏。尽管现代闪存设备仍然存在这个问题，但技术进步已经将其减少到几乎可以忽略不计的程度。现代闪存内存单元支持大约一百万次写入周期，之后才会出现问题。此外，今天的操作系统会像标记硬盘上的坏扇区一样标记坏闪存块，一旦确定某个块坏了，操作系统会跳过该块。
- en: Being electronic, flash devices do not exhibit rotational latency times at all,
    and they don’t exhibit much in the way of seek times either. There’s a tiny amount
    of time needed to write an address to a flash memory module, but it’s nothing
    compared to the head seek times on a hard disk. Despite this, flash memory is
    generally nowhere near as fast as typical RAM. Reading data from a flash device
    itself usually takes microseconds (rather than nanoseconds), and the interface
    between the flash memory device and the system may require additional time to
    set up a data transfer. In addition, it’s common to interface a flash storage
    module to a PC using a USB flash reader device, and this can further reduce the
    average read time per byte to hundreds of microseconds.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 由于是电子设备，闪存设备根本没有旋转延迟时间，也没有太多寻道时间。写入地址到闪存模块需要一点点时间，但与硬盘的磁头寻道时间相比，这几乎可以忽略不计。尽管如此，闪存的速度通常远不及典型的RAM。读取闪存设备的数据通常需要微秒（而不是纳秒），而闪存设备与系统之间的接口可能还需要额外的时间来设置数据传输。此外，通常会通过USB闪存读卡器设备将闪存存储模块与PC连接，这进一步将每字节的平均读取时间降低到几百微秒。
- en: Write performance is even worse. To write a block of data to flash, you must
    write the data, read it back, compare it to the original data, and rewrite it
    if they don’t match. This process can take several tens or even hundreds of milliseconds.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 写入性能更差。为了将一块数据写入闪存，你必须先写入数据，再读取回来，与原始数据进行比较，如果不匹配则重新写入。这个过程可能需要几十分甚至几百毫秒的时间。
- en: As a result, flash memory modules are generally quite a bit slower than high-performance
    hard-disk subsystems. However, thanks mainly to demand from high-end digital camera
    users who want to be able to snap as many pictures as possible in a short time,
    technological advances are boosting their performance. Though flash memory performance
    probably won’t catch up with hard-disk performance any time soon, you can expect
    it to continue improving over time.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，闪存存储模块通常比高性能硬盘子系统慢得多。然而，主要由于高端数码相机用户希望能够在短时间内拍摄尽可能多的照片，技术进步正在提升它们的性能。尽管闪存的性能可能短期内无法赶上硬盘性能，但预计它将随着时间的推移不断提高。
- en: '**14.4 RAM Disks**'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**14.4 RAM磁盘**'
- en: Another interesting mass storage device is the RAM disk, a semiconductor solution
    that treats a large block of the computer system’s memory as though it were a
    disk drive, simulating blocks and sectors using memory arrays. The advantage of
    memory-based disks is that they are very high performance. RAM disks don’t suffer
    from the time delays associated with head seek time and rotational latency that
    you find on hard, optical, and floppy drives. Their interface to the CPU is also
    much faster, so data transfer times are very short, often running at the maximum
    bus speed. It’s hard to imagine a faster storage technology than a RAM disk.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的大容量存储设备是RAM磁盘，它是一种半导体解决方案，将计算机系统的大块内存当作磁盘驱动器来使用，利用内存阵列模拟块和扇区。基于内存的磁盘的优势在于它们具有非常高的性能。RAM磁盘不受硬盘、光盘和软盘驱动器上与磁头寻道时间和旋转延迟相关的时间延迟的影响。它们与CPU的接口也更快，因此数据传输时间非常短，通常以最大总线速度运行。很难想象有比RAM磁盘更快的存储技术。
- en: 'RAM disks, however, have two disadvantages: cost and volatility. The cost per
    byte of storage in a RAM disk system is very high. Indeed, byte for byte, semiconductor
    storage is as much as 10,000 times more expensive than magnetic hard-disk storage.
    As a result, RAM disks usually have low storage capacities, typically no more
    than several gigabytes. And RAM disks are volatile—they lose their memory unless
    they are powered at all times. This generally means that semiconductor disks are
    great for storing temporary files and files you’ll copy back to some permanent
    storage device before shutting down the system. They are not particularly well
    suited for maintaining important information over long periods of time.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，RAM磁盘有两个缺点：成本和易失性。RAM磁盘系统中每字节存储的成本非常高。事实上，按字节计算，半导体存储比磁盘硬盘存储贵多达10,000倍。因此，RAM磁盘通常具有较低的存储容量，通常不超过几GB。而且RAM磁盘是易失性的——如果没有持续供电，它们会丢失数据。这通常意味着半导体磁盘非常适合存储临时文件和在关机之前会复制回永久存储设备的文件。它们不太适合长期保存重要信息。
- en: '**14.5 Solid-State Drives**'
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**14.5 固态硬盘**'
- en: Modern high-performance PCs use solid-state drives (SSDs). SSDs use flash memory
    (like USB sticks) with a high-performance interface to the system. But SSDs aren’t
    simply USB flash drives in different clothing. USB flash drives are designed for
    low cost per bit—except for certain camera applications (particularly 4K and 8K
    camcorders), speed is secondary to cost and capacity. A typical USB flash drive,
    for example, is quite a bit slower than a mediocre hard drive. SSDs, on the other
    hand, must be fast. Because of their solid-state design, they’re typically an
    order of magnitude faster than rotating magnetic media. With a RAID configuration,
    SSDs can actually achieve the performance limits of SATA interfaces.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现代高性能PC使用固态硬盘（SSD）。SSD使用闪存（如USB闪存驱动器）并通过高性能接口与系统连接。但SSD不仅仅是外观不同的USB闪存驱动器。USB闪存驱动器设计时主要考虑每比特的成本——除了某些相机应用（特别是4K和8K摄像机）外，速度通常是次要的，成本和容量才是主要考量。例如，典型的USB闪存驱动器速度远不及一款中等水平的硬盘。另一方面，SSD必须非常快速。由于其固态设计，它们通常比旋转磁介质快一个数量级。通过RAID配置，SSD实际上能够达到SATA接口的性能极限。
- en: As this was being written, SSDs cost between 4 and 16 times as much as high-capacity
    hard drives (8TB drives and 1TB SSDs both cost about $100 US). However, the price-per-gigabyte
    gap has been closing. SSDs are rapidly replacing rotating magnetic drives, and
    rotating magnetic media will likely be relegated to the trash bin of history (much
    like tape drives). Before that point, why would anyone pay more for an SSD?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，SSD的价格是高容量硬盘的4到16倍（8TB硬盘和1TB SSD的价格大约都是100美元）。然而，按每千兆字节计算的价格差距正在缩小。SSD正在迅速取代旋转磁盘驱动器，而旋转磁介质可能会被历史的垃圾桶所淘汰（就像磁带驱动器一样）。在那之前，为什么还会有人愿意为SSD支付更多呢？
- en: SSDs typically use a different underlying technology to store data and provide
    a much faster electronic interface to the PC. This is why an SSD tends to be much
    more expensive than a USB flash drive. That’s also why SSDs can achieve 2,500MBps
    data transfer rates, while high-quality memory cards are capable of only around
    100MBps (and USB flash/thumb drives are even worse).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: SSD通常使用不同的底层技术来存储数据，并提供更快速的电子接口到计算机。这就是为什么SSD通常比USB闪存驱动器要贵得多的原因。这也是为什么SSD能够实现2,500MBps的数据传输速度，而高质量的存储卡只能达到大约100MBps（而USB闪存/拇指驱动器的速度甚至更慢）。
- en: From a programmer’s perspective, one of the big advantages of SSDs is that you
    no longer have to worry about seek times and other latency issues. SSDs tend to
    be true(r) random-access devices (at least when compared with hard drives). Accessing
    data at the beginning of the drive and then at the end takes only a little longer
    than accessing any pair of data elements elsewhere on the SSD.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 从程序员的角度来看，SSD的一个重大优势是你不再需要担心寻道时间和其他延迟问题。与硬盘相比，SSD通常是更接近真正的随机访问设备。在SSD上，从驱动器的开始位置访问数据，再到结束位置的访问时间，仅比访问驱动器中其他数据元素的时间稍长。
- en: There are a couple of disadvantages to SSDs, though. First of all, their write
    performance is usually much slower than their read performance (though writing
    to an SSD is still much faster than writing to a hard drive). Fortunately, data
    is read far more often than it is written, but this is something to consider when
    you’re working on software that writes data to a SSD. The second drawback is that
    SSDs wear out after a while. Writing to the same location over and over again
    will eventually cause the associated memory cell(s) to fail. Fortunately, modern
    OSes work around these failures. However, when you write applications that continuously
    overwrite file data, keep this issue in mind.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，SSD也有一些缺点。首先，它们的写入性能通常比读取性能慢得多（尽管写入SSD的速度仍然比写入硬盘快）。幸运的是，读取数据的频率远高于写入，但在处理向SSD写入数据的软件时，必须考虑这一点。第二个缺点是SSD在一段时间后会磨损。反复写入同一位置最终会导致相关的存储单元失败。幸运的是，现代操作系统能够绕过这些故障。然而，当你编写持续覆盖文件数据的应用程序时，请牢记这一问题。
- en: '**14.6 Hybrid Drives**'
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**14.6 混合硬盘**'
- en: Most modern hard drives contain an on-board RAM cache (to hold entire tracks
    of data to eliminate rotational latency, for example). Hybrid drives, such as
    Apple’s older Fusion Drive, combine a small SSD with a large hard drive—typically
    a 32GB to 128GB SSD and a 2TB magnetic disk, in Apple’s case. Frequently accessed
    data stays in the SSD cache, and is swapped out to the hard drive when space is
    needed for new data. This works the same way as caching in main memory, boosting
    the system performance to near-SSD speeds for data that is accessed regularly.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代硬盘都包含板载RAM缓存（例如，用于存储整个磁道的数据，以消除旋转延迟）。混合硬盘，如苹果公司早期的Fusion Drive，结合了一块小型SSD与一个大容量硬盘——在苹果的例子中，通常是一个32GB到128GB的SSD和一个2TB的磁盘。常访问的数据会保留在SSD缓存中，当需要为新数据腾出空间时，它会被交换到硬盘中。这与主内存中的缓存工作方式相同，可以提高系统性能，使经常访问的数据接近SSD的速度。
- en: '**14.7 Filesystems on Mass Storage Devices**'
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**14.7 大容量存储设备上的文件系统**'
- en: Very few applications access mass storage devices directly. That is, applications
    do not generally read and write tracks, sectors, or blocks on a mass storage device;
    instead, they open, read, write, and otherwise manipulate *files* on it. The OS’s
    *file manager* abstracts away the physical configuration of the underlying storage
    device and provides a convenient storage facility for multiple independent files
    on a single device.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有应用程序直接访问大容量存储设备。也就是说，应用程序通常不会直接读取和写入大容量存储设备上的磁道、扇区或块；相反，它们是在存储设备上打开、读取、写入并以其他方式操作*文件*。操作系统的*文件管理器*抽象化了底层存储设备的物理配置，并为单个设备上的多个独立文件提供了一个方便的存储设施。
- en: On the earliest computer systems, applications were responsible for tracking
    the physical location of data on a mass storage device, because there was no file
    manager available to do so. They were able to maximize their performance by carefully
    considering the layout of data on the disk. For example, they could manually interleave
    data across various sectors on a track to give the CPU time to process it between
    reading and writing those sectors on the track. Such software was often many times
    faster than comparable software using a generic file manager. Later, when file
    managers were commonly available, some application authors still managed their
    files on a storage device for performance reasons. This was especially true back
    in the days of floppy disks, when low-level software written to manipulate data
    at the track and sector level often ran 10 times faster than the same application
    using a file manager system.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在最早的计算机系统中，应用程序负责跟踪数据在大容量存储设备上的物理位置，因为当时没有文件管理器可用来执行此操作。它们通过仔细考虑数据在磁盘上的布局来最大化性能。例如，它们可以手动交错数据在磁道的不同扇区中，以便在读取和写入磁道上的扇区之间，给CPU留出时间进行处理。这类软件通常比使用通用文件管理器的软件快好几倍。后来，当文件管理器变得普遍可用时，一些应用程序开发者仍然出于性能原因自行管理存储设备上的文件。特别是在软盘时代，低级软件通过在磁道和扇区级别操作数据，通常比使用文件管理器系统的相同应用程序快10倍。
- en: In theory, today’s software could benefit from this approach as well, but in
    practice you rarely see this kind of low-level disk access in modern applications,
    for several reasons. First, writing software that manipulates a mass storage device
    at such a low level locks you into using that particular device. That is, if your
    software manipulates a disk with 48 sectors per track, 12 tracks per cylinder,
    and 768 cylinders per drive, that software will not work optimally (if at all)
    on a drive with a different sector, track, and cylinder layout. Second, accessing
    the drive at a low level makes it difficult to share the device among different
    applications, something that can be especially costly on a multitasking system
    that may have several applications sharing the device at once. For example, if
    you’ve laid out your data on various sectors on a track to coordinate computation
    time with sector access, your work is lost when the OS interrupts your program
    and gives some other application its time slice—time you were counting on to do
    any necessary computations prior to the next data sector rotating under the read/write
    head. Third, some of the features of modern mass storage devices, such as on-board
    caching controllers and SCSI interfaces that present a storage device as a sequence
    of blocks rather than as something with a given track and sector geometry, eliminate
    any advantage that low-level software might have had. Fourth, modern OSes typically
    contain file buffering and block caching algorithms that provide good filesystem
    performance, obviating the need to operate at such a low level. Finally, low-level
    disk access is very complex, and writing such software is difficult.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，今天的软件也可以从这种方法中受益，但在实践中，你很少会在现代应用程序中看到这种低级别的磁盘访问，原因有几个。首先，编写能够以如此低的级别操作大容量存储设备的软件会让你依赖于特定的设备。也就是说，如果你的软件操作的是一个每个磁道有48个扇区、每个柱面有12个磁道、每个驱动器有768个柱面的磁盘，那么该软件在不同扇区、磁道和柱面布局的驱动器上将无法实现最佳性能（如果能运行的话）。第二，以低级别访问磁盘会使得在不同应用程序之间共享设备变得困难，尤其是在多任务系统中，可能会有多个应用程序同时共享该设备。例如，如果你已经在磁道的各个扇区上布置了数据，以便将计算时间与扇区访问协调，那么当操作系统中断你的程序并分配时间片给其他应用程序时，你的工作将会丢失——这段时间本来是用来在下一个数据扇区经过读写头之前完成必要的计算的。第三，一些现代大容量存储设备的功能，例如板载缓存控制器和将存储设备呈现为一系列块的SCSI接口，而不是呈现为具有特定磁道和扇区几何结构的设备，消除了低级软件可能具有的任何优势。第四，现代操作系统通常包含文件缓冲和块缓存算法，可以提供良好的文件系统性能，从而无需以如此低的级别操作。最后，低级磁盘访问非常复杂，编写这种软件很困难。
- en: '***14.7.1 Sequential Filesystems***'
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.7.1 顺序文件系统***'
- en: The earliest file manager systems stored files sequentially on the disk’s surface.
    That is, if each sector/block on the disk held 512 bytes and a file was 32KB long,
    that file would consume 64 consecutive sectors/blocks on the disk’s surface. To
    access that file at some future time, the file manager only needed to know the
    file’s starting block number and the number of blocks it occupied. The filesystem
    had to maintain these two pieces of information somewhere in nonvolatile storage.
    The obvious place was on the storage media itself, in a data structure known as
    the *directory*—an array of values starting at a specific disk location that the
    OS can reference when an application requests a particular file. The file manager
    can search through the directory for the file’s name and extract its starting
    block and length. With this information, the filesystem can provide the application
    with access to the file’s data.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最早的文件管理系统将文件顺序存储在磁盘表面。也就是说，如果磁盘上的每个扇区/块存储512字节，并且一个文件的大小是32KB，那么该文件将在磁盘表面上占用64个连续的扇区/块。为了在未来的某个时间访问该文件，文件管理器只需要知道文件的起始块号和它占用的块数。文件系统必须在某个非易失性存储介质中维护这两条信息。显然，这些信息存储在存储介质本身中，称为*目录*——这是一个从特定磁盘位置开始的值数组，操作系统可以在应用程序请求特定文件时引用。文件管理器可以在目录中查找文件的名称，并提取其起始块和长度。通过这些信息，文件系统可以向应用程序提供访问文件数据的权限。
- en: One advantage of the sequential filesystem is that it is very fast. The OS can
    read or write a single file’s data very rapidly if the file is stored in sequential
    blocks on the disk’s surface. But a sequential file organization has some serious
    problems, too. The biggest and most obvious drawback is that you can’t extend
    the size of a file once the file manager places another file at the next block
    on the disk. Disk fragmentation is another big problem. As applications create
    and delete many small and medium files, the disk fills up with short sequences
    of unused sectors that, individually, are too small for most files. On sequential
    filesystems, disks often had free space sufficient to hold some data, but they
    couldn’t use it because it was scattered in small pieces all over the disk’s surface.
    To solve this problem, users had to run disk compaction programs to coalesce all
    the free sectors and move them to the end of the disk by physically rearranging
    files on its surface. Another solution was to copy files from one full disk to
    another empty disk, collecting the many small, unused sectors together. Obviously,
    this was extra work that the user had to do—work that the OS should have been
    doing.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序文件系统的一个优点是非常快速。如果文件存储在磁盘表面上的顺序块中，操作系统可以非常迅速地读取或写入单个文件的数据。但顺序文件组织也存在一些严重的问题。最大且最明显的缺点是，一旦文件管理器将另一个文件放置在磁盘上的下一个块处，就无法扩展文件的大小。磁盘碎片化是另一个大问题。随着应用程序创建和删除许多小型和中型文件，磁盘会填满许多短小的未使用扇区，这些扇区单独来看对于大多数文件来说太小了。在顺序文件系统上，磁盘上常常有足够的空闲空间来存储一些数据，但因为它被分散在磁盘表面的小块上，无法使用。为了解决这个问题，用户必须运行磁盘压缩程序，将所有空闲扇区合并并通过物理重新排列文件，将它们移动到磁盘的末端。另一种解决方案是将文件从一个满磁盘复制到另一个空磁盘，收集那些许多小的未使用扇区。显然，这是用户必须做的额外工作——这本应该是操作系统执行的任务。
- en: The sequential file storage scheme really falls apart when used with multitasking
    OSes. If two applications attempt to write file data to the disk concurrently,
    the filesystem must place the starting block of the second application’s file
    beyond the last block required by the first application’s file. As the OS has
    no way of determining how large the files can grow, each application has to tell
    the OS the maximum length of the file when the application first opens it. Unfortunately,
    many applications cannot determine in advance how much space they’ll need for
    their files, so they have to guess the size of the file when opening it. If the
    estimated file size is too small, either the program has to abort with a “file
    full” error, or the application has to create a larger file, copy the old data
    from the “full” file to the new file, and then delete the old file. As you can
    imagine, this is horribly inefficient and definitely not great code.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序文件存储方案在多任务操作系统中真正崩溃。如果两个应用程序试图同时将文件数据写入磁盘，文件系统必须将第二个应用程序文件的起始块放置在第一个应用程序文件所需的最后一个块之后。由于操作系统无法确定文件可以增长多大，每个应用程序在首次打开文件时必须告诉操作系统文件的最大长度。不幸的是，许多应用程序无法预先确定它们需要多少空间来存储文件，因此它们在打开文件时必须猜测文件的大小。如果估算的文件大小太小，程序要么必须因“文件已满”错误而中止，要么应用程序必须创建一个更大的文件，将“已满”文件中的旧数据复制到新文件中，然后删除旧文件。正如你能想象的那样，这种做法效率极低，绝对不是优良的代码。
- en: To avoid such performance problems, many applications grossly overestimate the
    amount of space they need for their files. As a result, they wind up wasting disk
    space when the files don’t actually use all the data allocated to them, a form
    of *internal* fragmentation. Furthermore, if applications truncate their files
    when closing them, the resulting free sections returned to the OS tend to fragment
    the disk into the small, unusable blocks of free space described previously, a
    problem known as *external* fragmentation. For these reasons, sequential storage
    on the disk has been replaced by more sophisticated storage management schemes
    in modern OSes.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免此类性能问题，许多应用程序严重高估了它们所需的文件空间。因此，当文件实际上没有使用分配给它们的所有数据时，它们最终会浪费磁盘空间，这是一种*内部*碎片化形式。此外，如果应用程序在关闭文件时截断了文件，那么返回给操作系统的空闲部分往往会把磁盘分割成之前描述的那些小的、无法使用的空闲块，这个问题被称为*外部*碎片化。基于这些原因，现代操作系统已经用更为复杂的存储管理方案取代了磁盘上的顺序存储。
- en: '***14.7.2 Efficient File Allocation Strategies***'
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.7.2 高效的文件分配策略***'
- en: Most modern file allocation strategies allow files to be stored across arbitrary
    blocks on the disk. Because the filesystem can now place bytes of the file in
    any free block on the disk, the problems of external fragmentation and the limitation
    on file size are all but eliminated. As long as there’s at least one free block
    on the disk, you can expand the size of any file. However, with this flexibility
    comes some added complexity. In a sequential filesystem, it was easy to locate
    free space on the disk; by simply noting the starting block numbers and sizes
    of the files in a directory, the filesystem could locate a free block large enough
    to satisfy the current disk allocation request, if one was available. But with
    files stored across arbitrary blocks, scanning the directory and noting which
    blocks a file uses is far too expensive to compute, so the filesystem has to keep
    track of the free and used blocks. Most modern OSes use one of three data structures—a
    set, a table (array), or a list—to keep track of which sectors are free and which
    are not. Each scheme has its advantages and disadvantages.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代文件分配策略允许文件存储在磁盘的任意块上。由于文件系统现在可以将文件的字节放置在磁盘上的任何空闲块中，因此外部碎片和文件大小限制的问题几乎被消除了。只要磁盘上至少有一个空闲块，就可以扩展任何文件的大小。然而，这种灵活性也带来了一些额外的复杂性。在顺序文件系统中，查找磁盘上的空闲空间很容易；只需记下目录中各个文件的起始块号和大小，文件系统就可以找到足够大的空闲块来满足当前的磁盘分配请求（如果有的话）。但在文件跨任意块存储的情况下，扫描目录并记录一个文件使用了哪些块计算起来太昂贵，因此文件系统必须跟踪空闲和已使用的块。大多数现代操作系统使用三种数据结构之一——集合、表格（数组）或列表——来跟踪哪些扇区是空闲的，哪些是已用的。每种方案都有其优缺点。
- en: '**14.7.2.1 Free-Space Bitmaps**'
  id: totrans-112
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**14.7.2.1 空间位图**'
- en: The free-space bitmap scheme uses a set data structure to maintain a set of
    free blocks on the disk drive. If a block is a member of that set, the file manager
    can remove it whenever it needs another block for a file. Because set membership
    is a Boolean relationship (a block is either in the set or it’s not), it takes
    exactly 1 bit to specify the set membership of each block.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 空间位图方案使用集合数据结构来维护磁盘驱动器上的空闲块集合。如果一个块是该集合的成员，文件管理器可以在需要另一个块为文件时将其移除。由于集合成员关系是布尔关系（一个块要么在集合中，要么不在），因此只需要1位就能指定每个块的集合成员关系。
- en: Typically, a file manager reserves a certain section of the disk to hold a bitmap
    that specifies which blocks on the disk are free. The bitmap consumes some integral
    number of blocks on the disk, with each block consumed representing a specific
    number of other blocks on the disk, which we can calculate by multiplying the
    block size (in bytes) by 8 (bits per byte). For example, if the OS uses 4,096-byte
    blocks on the disk, a bitmap consisting of a single block can track up to 32,768
    other blocks on the disk.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，文件管理器会保留磁盘的某个部分来存放一个位图，该位图指定磁盘上哪些块是空闲的。位图会占用磁盘上的若干块，每个块所占的空间表示磁盘上其它块的数量，我们可以通过将块大小（以字节为单位）乘以8（每字节的位数）来计算。例如，如果操作系统在磁盘上使用4,096字节的块，则由一个块组成的位图可以跟踪磁盘上最多32,768个其他块。
- en: The disadvantage of the bitmap scheme is that as disks get large, so does the
    bitmap. For example, on a 120GB drive with 4,096-byte blocks, the bitmap will
    be almost 4MB long. While this is a small percentage of the total disk capacity,
    accessing a single bit in a bitmap this large can be clumsy. To find a free block,
    the OS has to do a linear search through this 4MB bitmap. Even if you keep the
    bitmap in system memory (which is a bit expensive, considering that you have to
    do it for each drive), searching through it every time you need a free sector
    is an expensive proposition. As a result, you don’t see this scheme used much
    on larger disk drives.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 位图方案的缺点是，随着磁盘容量的增大，位图也会变得越来越大。例如，在一个120GB的驱动器上，块大小为4,096字节时，位图几乎长达4MB。虽然这只是磁盘总容量的一个小比例，但访问这么大位图中的单个比特位可能会很笨拙。为了找到一个空闲块，操作系统必须在线性查找中遍历这个4MB的位图。即使你将位图保存在系统内存中（考虑到每个磁盘都必须这样做，这其实是有点昂贵的），每次需要空闲扇区时查找它也是一种昂贵的提议。因此，你很少会看到这种方案用于较大的磁盘驱动器上。
- en: One advantage (and also a disadvantage) of the bitmap scheme is that the file
    manager uses it only to keep track of the free space on the disk, not which sectors
    belong to a given file. As a result, if the free-space bitmap is damaged somehow,
    nothing is permanently lost; you can easily reconstruct it by searching through
    all the disk directories and computing which sectors are being used by the files
    in those directories (the remaining sectors, obviously, are the free ones). Although
    this process is somewhat time-consuming, it’s nice to have the option if disaster
    strikes.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 位图方案的一个优点（也是缺点）是，文件管理器仅使用它来跟踪磁盘上的空闲空间，而不是跟踪属于某个特定文件的扇区。因此，如果空闲空间位图发生损坏，实际上并不会永久丢失任何数据；你可以通过遍历所有磁盘目录并计算哪些扇区被这些目录中的文件使用来轻松重建它（显然，剩余的扇区就是空闲的）。虽然这个过程有点耗时，但如果发生灾难时，能够有这个选项还是挺好的。
- en: '**14.7.2.2 File Allocation Tables**'
  id: totrans-117
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**14.7.2.2 文件分配表**'
- en: Another way to track disk-sector usage is with a table of sector pointers, or
    a *file allocation table (FAT)*. This scheme is widely used. Cementing its popularity,
    this is also the default file allocation scheme used on most USB flash drives.
    An interesting facet of the FAT structure is that it combines both free-space
    management and file-sector allocation management into the same data structure,
    ultimately saving space when compared to the bitmap scheme, which uses separate
    data structures for each. Furthermore, unlike the bitmap scheme, FAT doesn’t require
    an inefficient linear search to find the next available free sector.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种跟踪磁盘扇区使用情况的方法是使用扇区指针表，或者称为*文件分配表（FAT）*。这种方案被广泛使用，巩固了它的流行性，这也是大多数USB闪存驱动器上默认的文件分配方案。FAT结构的一个有趣方面是，它将空闲空间管理和文件扇区分配管理合并为同一数据结构，与使用各自独立数据结构的位图方案相比，最终节省了空间。此外，与位图方案不同，FAT不需要进行低效的线性搜索来找到下一个可用的空闲扇区。
- en: 'The FAT is really nothing more than an array of self-relative pointers (that
    is, indexes into itself), setting aside one pointer for each sector/block on the
    storage device. When a disk is initialized, the first several blocks on its surface
    are reserved for objects like the root directory and the FAT itself, and the remaining
    blocks on the disk are free. Somewhere in the root directory is a free-space pointer
    that specifies the next available free block on the disk. Assuming the free-space
    pointer initially contains the value `64`, implying that the next free block is
    block 64, the FAT entries at indexes 64, 65, 66, and so on, would contain the
    following values, assuming there are *n* blocks on the disk, numbered from 0 to
    *n* – 1:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: FAT实际上不过是一组自相对指针数组（也就是说，指向自身的索引），为存储设备上的每个扇区/块保留一个指针。当磁盘初始化时，它的表面上的前几个块被保留给根目录和FAT本身等对象，磁盘上剩余的块则是空闲的。根目录中的某个地方有一个空闲空间指针，它指定磁盘上下一个可用的空闲块。假设空闲空间指针最初包含值`64`，意味着下一个空闲块是块64，那么FAT中索引64、65、66等位置的条目将包含以下值，假设磁盘上有*n*个块，从0到*n*–1编号：
- en: '| **FAT index** | **FAT entry value** |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **FAT 索引** | **FAT 条目值** |'
- en: '| . . . | . . . |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| . . . | . . . |'
- en: '| 64 | `65` |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 64 | `65` |'
- en: '| 65 | `66` |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 65 | `66` |'
- en: '| 66 | `67` |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 66 | `67` |'
- en: '| 67 | `68` |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 67 | `68` |'
- en: '| . . . | . . . |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| . . . | . . . |'
- en: '| *n* – 2 | *n* – 1 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| *n* – 2 | *n* – 1 |'
- en: '| *n* – 1 | `0` |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| *n* – 1 | `0` |'
- en: The entry at block 64 tells you the next available free block on the disk, 65\.
    Moving on to entry 65, you’ll find the value of the next available free block
    on the disk, `66`. The last entry in the FAT contains a `0` (block 0 contains
    meta-information for the entire disk partition and is never available).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 块64中的条目告诉你磁盘上下一个可用的空闲块是65。接着查看条目65，你会发现磁盘上下一个可用空闲块的值是`66`。FAT中的最后一个条目包含一个`0`（块0包含整个磁盘分区的元数据，永远不会被使用）。
- en: 'Whenever an application needs one or more blocks to hold some new data on the
    disk’s surface, the file manager grabs the free-space pointer value and then continues
    going through the FAT entries for however many blocks are required to store the
    new data. For example, if each block is 4,096 bytes long and the current application
    is attempting to write 8,000 bytes to a file, the file manager will need to remove
    two blocks from the free-block list, following these steps:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 每当应用程序需要一个或多个块来存储一些新数据时，文件管理器会获取空闲空间指针的值，然后继续遍历FAT条目，直到找到足够的块来存储新数据。例如，如果每个块大小为4,096字节，而当前应用程序试图向一个文件写入8,000字节，文件管理器需要从空闲块列表中移除两个块，步骤如下：
- en: Get the value of the free-space pointer.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取空闲空间指针的值。
- en: Save the value of the free-space pointer in order to determine the first free
    sector.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存空闲空间指针的值，以便确定第一个空闲扇区。
- en: Continue going through the FAT entries for the number of blocks required to
    store the application’s data.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续查看FAT条目，直到存储应用程序数据所需的块数。
- en: Extract the FAT entry value of the last block where the application needs to
    store its data, and set the free-space pointer to this value.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取应用程序需要存储其数据的最后一个块的FAT条目值，并将空闲空间指针设置为该值。
- en: Store a `0` over the FAT entry value of the last block that the application
    uses, marking the end to the list of blocks that the application needs.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在应用程序使用的最后一个块的FAT条目值上存储一个`0`，标记应用程序所需块列表的结束。
- en: Return the original (as it was prior to these steps) value of the free-space
    pointer into the FAT as the pointer to the list of blocks that are now allocated
    for the application.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将空闲空间指针的原始值（即在这些步骤之前的值）返回到FAT中，作为指向现在已分配给应用程序的块列表的指针。
- en: 'After the block allocation in our earlier example, the application has blocks
    64 and 65 at its disposal, the free-space pointer contains `66`, and the FAT looks
    like this:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的示例中，块分配之后，应用程序可以使用块64和65，空闲空间指针包含`66`，FAT看起来如下所示：
- en: '| **FAT index** | **FAT entry value** |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| **FAT索引** | **FAT条目值** |'
- en: '| . . . | . . . |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| . . . | . . . |'
- en: '| 64 | `65` |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 64 | `65` |'
- en: '| 65 | `0` |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 65 | `0` |'
- en: '| 66 | `67` |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 66 | `67` |'
- en: '| 67 | `68` |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 67 | `68` |'
- en: '| . . . | . . . |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| . . . | . . . |'
- en: '| *n* – 2 | *n* – 1 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| *n* – 2 | *n* – 1 |'
- en: '| *n* – 1 | `0` |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| *n* – 1 | `0` |'
- en: 'This is not to imply that entries in the FAT *always* contain the index of
    the next entry in the table. As the file manager allocates and deallocates storage
    for files on the disk, these numbers tend to become scrambled. For example, if
    an application returns block 64 to the free list but holds on to block 65, the
    free-space pointer would contain the value `64`, and the FAT would have the following
    values:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着FAT中的条目*总是*包含表中下一个条目的索引。随着文件管理器为磁盘上的文件分配和释放存储空间，这些数字往往会变得混乱。例如，如果一个应用程序将块64归还到空闲列表，但仍保留块65，空闲空间指针将包含值`64`，FAT将具有以下值：
- en: '| **FAT index** | **FAT entry value** |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| **FAT索引** | **FAT条目值** |'
- en: '| . . . | . . . |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| . . . | . . . |'
- en: '| 64 | `66` |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 64 | `66` |'
- en: '| 65 | `0` |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 65 | `0` |'
- en: '| 66 | `67` |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 66 | `67` |'
- en: '| 67 | `68` |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 67 | `68` |'
- en: '| . . . | . . . |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| . . . | . . . |'
- en: '| *n* – 2 | *n* – 1 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| *n* – 2 | *n* – 1 |'
- en: '| *n* – 1 | `0` |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| *n* – 1 | `0` |'
- en: As noted earlier, one advantage of the FAT data structure is that it combines
    both free-space management and file allocation management into a single data structure.
    This means that each file doesn’t have to carry around a list of the blocks its
    data occupies. Instead, it needs only a single pointer value specifying an index
    into the FAT where the first block of the file’s data can be found. You can find
    the remaining blocks containing the file’s data by stepping through the FAT.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，FAT数据结构的一个优点是，它将空闲空间管理和文件分配管理合并为一个单一的数据结构。这意味着每个文件不需要携带其数据占用的块的列表。相反，它只需要一个指针值，指定FAT中的一个索引，从该索引可以找到文件数据的第一个块。剩余包含文件数据的块可以通过遍历FAT来找到。
- en: One important advantage of the FAT scheme over the set (bitmap) scheme is that
    once the disk using a FAT filesystem is full, it doesn’t maintain information
    about which blocks are free. In contrast, the bitmap scheme consumes space on
    the disk to track free blocks even when there are none available. The FAT scheme
    replaces the entries originally used to track free blocks with the file-block
    pointers. When the disk is full, the values that originally maintained the free-block
    list are no longer consuming disk space because they’re all now tracking blocks
    in files. In this case, the free-space pointer contains `0` (to denote an empty
    free-space list) and all the FAT entries contain chains of block indexes for file
    data.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: FAT方案相对于集合（位图）方案的一个重要优势是，一旦使用FAT文件系统的磁盘满了，它就不再维护哪些块是空闲的。相比之下，位图方案即使没有空闲块可用，仍然会占用磁盘空间来跟踪空闲块。FAT方案用文件块指针替换了原本用来跟踪空闲块的条目。当磁盘满时，原本用于维护空闲块列表的值不再占用磁盘空间，因为它们现在都在跟踪文件中的块。在这种情况下，空闲空间指针包含`0`（表示空的空闲空间列表），所有FAT条目都包含文件数据的块索引链。
- en: However, the FAT scheme does have a couple of disadvantages. First, unlike the
    bitmap in a set scheme filesystem, the table in a FAT filesystem represents a
    single point of failure. If the FAT is somehow destroyed, it can be very difficult
    to repair the disk and recover files; losing some free space on a disk is a problem,
    but losing track of where your files are on the disk is a *major* problem. Furthermore,
    because the disk head tends to spend more time in the FAT area of a storage device
    than in any other single area on the disk, the FAT is the most likely part of
    a hard disk to be damaged by a head crash, and the most likely part of a floppy
    or optical drive to exhibit excessive wear. This is a sufficiently big concern
    that some FAT filesystems provide an option to maintain an extra copy of the FAT
    on the disk.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，FAT方案确实有几个缺点。首先，FAT文件系统中的表格与集合方案文件系统中的位图不同，它代表了一个单点故障。如果FAT以某种方式被破坏，修复磁盘和恢复文件可能会非常困难；丢失磁盘上的一些空闲空间是一个问题，但丢失文件在磁盘上的位置则是一个*重大*问题。此外，由于磁盘头通常比在磁盘的任何其他区域花费更多时间在FAT区域，FAT是硬盘最容易受到磁头撞击损坏的部分，也是软盘或光驱最容易出现过度磨损的部分。这是一个足够重要的担忧，以至于一些FAT文件系统提供了在磁盘上保留FAT额外副本的选项。
- en: Another problem with the FAT is that it’s usually located at a fixed place on
    the disk, typically at some low block number. In order to determine which block
    or blocks to read for a particular file, the disk heads must move to the FAT,
    so if the FAT is at the beginning of the disk, they’ll constantly be traveling
    to and from the FAT across large distances. This massive head movement not only
    is slow but tends to wear out the mechanical parts of the disk drive sooner. In
    newer versions of Microsoft OSes, the FAT-32 scheme eliminates part of this problem
    by allowing the FAT to be positioned somewhere other than the beginning of the
    disk, though still at a fixed location. Application file I/O performance can be
    quite low with a FAT filesystem unless the OS caches the FAT in main memory, which
    can be dangerous if the system crashes, because you could lose track of all file
    data whose FAT entries have not been written to disk.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: FAT的另一个问题是它通常位于磁盘上的固定位置，通常是在某些较低的块号处。为了确定要读取哪个块或哪些块以获取特定文件，磁盘读写头必须移动到FAT区域，因此，如果FAT位于磁盘的开头，它们将不断地来回移动，跨越较大的距离。这种大规模的读写头移动不仅很慢，而且容易加速磁盘驱动器机械部件的磨损。在微软操作系统的新版本中，FAT-32方案通过允许将FAT定位在磁盘的开头以外的位置来解决部分问题，尽管FAT仍然处于固定位置。如果操作系统没有将FAT缓存到主内存中，FAT文件系统的应用程序文件I/O性能可能会非常低，这在系统崩溃时可能很危险，因为你可能会失去所有尚未写入磁盘的FAT条目对应的文件数据。
- en: The FAT scheme is also inefficient for doing random access on a file. To read
    from offset *m* to offset *n* in a file, the file manager must divide *n* by the
    block size to obtain the block offset into the file containing the byte at offset
    *n*, divide *m* by the block size to obtain its block offset, and then sequentially
    search through the FAT chain between these two blocks to find the sector(s) containing
    the desired data. This linear search can be expensive if the file is a large database
    with many thousands of blocks between the current block position and the desired
    block position.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: FAT方案对于文件的随机访问也非常低效。为了从文件的偏移量*m*读取到偏移量*n*，文件管理器必须将*n*除以块大小，以获得包含偏移量*n*的字节的块偏移量，将*m*除以块大小以获得其块偏移量，然后依次在这两个块之间的FAT链中查找包含所需数据的扇区。这种线性搜索可能非常耗时，尤其是当文件是一个大型数据库，当前块位置与所需块位置之间有成千上万个块时。
- en: Yet another problem with the FAT filesystem, though this one is rather esoteric,
    is that it doesn’t support sparse files. That is, you cannot write to byte 0 and
    byte 1,000,000 of a file without also allocating every byte of data between those
    two points on the disk surface. Some non-FAT file managers allocate only the blocks
    where an application has written data. For example, if an application writes data
    only to bytes 0 and 1,000,000 of a file, the file manager allocates only two blocks
    for the file. If the application attempts to read a block that hasn’t been previously
    allocated (for example, if the application in the current example attempts to
    read the byte at offset 500,000 without first writing to that location), the file
    manager simply returns `0`s for the read operation without actually using any
    space on the disk. But because of how a FAT is organized, you can’t create sparse
    files on the disk.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: FAT文件系统的另一个问题，虽然相对深奥，却依然存在，那就是它不支持稀疏文件。也就是说，你不能在文件的字节0和字节1,000,000之间写入数据，而不在这两个位置之间的每个字节上都分配磁盘空间。一些非FAT的文件管理器只分配应用程序写入数据的块。例如，如果一个应用程序只在文件的字节0和1,000,000处写入数据，那么文件管理器只为该文件分配两个块。如果应用程序尝试读取一个未先分配的块（例如，如果应用程序在当前示例中尝试读取偏移量为500,000的字节，而该位置之前没有写入过数据），文件管理器会简单地返回`0`，而不会实际占用磁盘上的任何空间。但由于FAT的组织方式，你无法在磁盘上创建稀疏文件。
- en: '**14.7.2.3 Lists of Blocks**'
  id: totrans-163
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**14.7.2.3 块列表**'
- en: To overcome the limitations of the FAT filesystem, advanced OSes—such as Windows
    NT/2000/XP/7/8/10, macOS (APFS), and various flavors of Unix—use a list-of-blocks
    scheme instead. Indeed, the list scheme enjoys all the advantages of a FAT system
    (such as efficient, nonlinear free-block location, and efficient storage of the
    free-block list), and it solves many of FAT’s problems.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服FAT文件系统的局限性，先进的操作系统——如Windows NT/2000/XP/7/8/10、macOS（APFS）以及各种版本的Unix——采用了块列表方案。事实上，块列表方案享有FAT系统的所有优点（如高效的非线性空闲块定位和空闲块列表的高效存储），同时解决了许多FAT系统的问题。
- en: The list scheme begins by setting aside several blocks on the disk for the purpose
    of keeping (generally) 32- or 64-bit pointers to each free block on the disk.
    If each block on the disk holds 4,096 bytes, a block can hold 1,024 (or 512) pointers.
    Dividing the number of blocks on the disk by 1,024 (512) determines the number
    of blocks the free-block list will initially consume. As you’ll soon see, the
    system uses these blocks to store data once the disk fills up, so there’s no storage
    overhead associated with the blocks consumed by the free-block list.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 块列表方案的实现方式是首先在磁盘上预留几个块，用于存储（通常是）32位或64位的指针，指向磁盘上的每个空闲块。如果磁盘上的每个块大小为4,096字节，则一个块可以存储1,024（或512）个指针。通过将磁盘上的块数除以1,024（或512），可以确定空闲块列表最初将消耗的块数。正如你很快会看到的那样，一旦磁盘被填满，系统将使用这些块来存储数据，因此空闲块列表所占用的块并不会带来额外的存储开销。
- en: 'If a block in the free-block list contains 1,024 pointers (the following examples
    all assume 32-bit pointers), then the first 1,023 pointers contain the block numbers
    of free blocks on the disk. The file manager maintains two pointers on the disk:
    one that holds the block number of the current block containing free-block pointers,
    and one that holds an index into that current block. Whenever the filesystem needs
    a free block, it obtains the index for one from the free-block list by using these
    two pointers. Then the file manager increments the index into the free-block list
    to the next available entry in the list. When the index increments to 1,023 (the
    1,024th item in the free-block list), instead of using the pointer entry value
    at that index to locate a free block, the file manager uses it as the address
    of the next block containing a list of free-block pointers on the disk, and it
    uses the current block, containing a now-empty list of block pointers, as the
    free block. This is how the file manager reuses the blocks originally designated
    to hold the free-block list, rather than reusing the pointers in the free-block
    list to keep track of the blocks belonging to a given file, as FAT does. Once
    the file manager uses up all the free-block pointers in a given block, it uses
    that block for actual file data.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果空闲块列表中的一个块包含 1,024 个指针（以下示例假设使用 32 位指针），那么前 1,023 个指针包含磁盘上空闲块的块号。文件管理器在磁盘上维护两个指针：一个保存当前包含空闲块指针的块的块号，另一个保存该块中的索引。每当文件系统需要一个空闲块时，它会通过这两个指针从空闲块列表中获取一个索引。然后，文件管理器将索引增加到空闲块列表中的下一个可用条目。当索引增加到
    1,023（即空闲块列表中的第 1,024 项）时，文件管理器不会使用该索引处的指针值来定位一个空闲块，而是将其作为包含磁盘上空闲块指针列表的下一个块的地址，并将当前块（其中包含现在空的块指针列表）用作空闲块。这就是文件管理器如何重用最初用于保存空闲块列表的块，而不是像
    FAT 那样重用空闲块列表中的指针来跟踪属于给定文件的块。一旦文件管理器用完了某个块中的所有空闲块指针，它将使用该块来存储实际的文件数据。
- en: Unlike the FAT, the list scheme does not merge the free-block list and the file
    list into the same data structure. Instead, a separate data structure for each
    file holds the list of blocks associated with that file. Under typical Unix and
    Linux filesystems, the directory entry for the file actually holds the first 8
    to 16 entries in the list (see [Figure 14-5](ch14.xhtml#ch14fig05)). This allows
    the OS to track small files (up to 32KB or 64KB) without having to allocate any
    extra space on the disk.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 与 FAT 不同，列表方案并不将空闲块列表和文件列表合并为同一数据结构。相反，每个文件都有一个独立的数据结构，用于保存与该文件相关联的块列表。在典型的
    Unix 和 Linux 文件系统中，文件的目录项实际上保存了列表中的前 8 到 16 个条目（见 [图 14-5](ch14.xhtml#ch14fig05)）。这样，操作系统就能追踪小文件（最大
    32KB 或 64KB），而不需要在磁盘上分配任何额外的空间。
- en: '![image](../images/14fig05.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/14fig05.jpg)'
- en: '*Figure 14-5: Block list for small files*'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14-5：小文件的块列表*'
- en: Research on various flavors of Unix suggests that the vast majority of files
    are small, and embedding several pointers into the directory entry provides an
    efficient way to access small files. Of course, as time passes, the average file
    size seems to increase. But as it turns out, block sizes tend to increase as well.
    When the research was first done, the typical block size was 512 bytes, but today
    it’s 4,096 bytes. During that time, then, average file sizes could have increased
    by a factor of 8 without, on average, requiring any extra space in the directory
    entries.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不同类型的 Unix 系统的研究表明，绝大多数文件都很小，将多个指针嵌入目录项提供了一种高效访问小文件的方式。当然，随着时间的推移，平均文件大小似乎有所增加。但事实证明，块大小也趋向于增大。最初进行这项研究时，典型的块大小为
    512 字节，而今天已经是 4,096 字节。因此，在这段时间内，平均文件大小可能增加了 8 倍，而在平均情况下，目录项并未需要额外的空间。
- en: For medium files, up to about 4MB, the OS will allocate a single block with
    1,024 pointers to the blocks that store the file’s data. The OS continues to use
    the pointers found in the directory entry for the first few blocks of the file,
    and then it uses a block on the disk to hold the next group of block pointers.
    Generally, the last pointer in the directory entry holds the location of this
    block (see [Figure 14-6](ch14.xhtml#ch14fig06)).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 对于中等大小的文件，最大约为 4MB，操作系统将分配一个包含 1,024 个指针的单个块，用于指向存储文件数据的块。操作系统继续使用目录项中找到的指针来指向文件的前几个块，然后它使用磁盘上的一个块来存储下一组块指针。通常，目录项中的最后一个指针保存此块的位置（见
    [图 14-6](ch14.xhtml#ch14fig06)）。
- en: '![image](../images/14fig06.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/14fig06.jpg)'
- en: '*Figure 14-6: Block list for medium files*'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14-6：中等文件的块列表*'
- en: For files larger than about 4MB, the filesystem switches to a three-tiered block
    scheme, which works for file sizes up to 4GB. In this scheme, the last pointer
    in the directory entry stores the location of a block of 1,024 pointers, and each
    pointer in this block holds the location of an additional block of 1,024 pointers,
    with each pointer in *this* block storing the location of a block that contains
    actual file data. See [Figure 14-7](ch14.xhtml#ch14fig07) for the details.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大于大约 4MB 的文件，文件系统切换到三级块方案，该方案适用于最大 4GB 的文件大小。在该方案中，目录条目的最后一个指针存储了一个包含 1,024
    个指针的块的位置，而该块中的每个指针都指向另一个包含 1,024 个指针的块，这些指针存储的每个指针在*这个*块中指向包含实际文件数据的块。详细信息请参见
    [图 14-7](ch14.xhtml#ch14fig07)。
- en: '![image](../images/14fig07.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/14fig07.jpg)'
- en: '*Figure 14-7: Three-level block list for large files (up to 4GB)*'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14-7：适用于大文件（最大 4GB）的三级块列表*'
- en: 'One advantage to this tree structure is that it readily supports sparse files:
    an application can write to block 0 and block 100 of a file without having to
    allocate data blocks for every block between those two points. By placing a special
    block pointer value (typically `0`) in the intervening entries in the block list,
    the OS can determine whether a block isn’t present in the file. Should an application
    attempt to read a missing block in the file, the OS can simply return all `0`s
    for the empty block. Of course, once the application writes data to a block that
    hadn’t been previously allocated, the OS must copy the data to the disk and fill
    in the appropriate block pointer in the block list.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这种树形结构的一个优点是，它可以轻松支持稀疏文件：应用程序可以在文件的第 0 块和第 100 块写入数据，而无需为这两个点之间的每个块分配数据块。通过在块列表的中间条目中放置一个特殊的块指针值（通常是
    `0`），操作系统可以判断文件中是否不存在某个块。如果应用程序尝试读取文件中丢失的块，操作系统可以简单地返回所有 `0`，表示该块为空。当然，一旦应用程序向一个先前未分配的块写入数据，操作系统必须将数据复制到磁盘，并在块列表中填入相应的块指针。
- en: As disks became larger, the 4GB file limit imposed by this scheme began to create
    some problems for certain applications, such as video editors, large database
    applications, and web servers. One could easily extend this scheme 1,000 times—to
    4TB—by adding another level to the block-list tree. The only problem with this
    approach is that the more levels of indirection you have, the slower random file
    access becomes, because the OS may have to read several blocks from the disk in
    order to get a single block of data. (When it has one level, it makes sense to
    cache the block-pointer list in memory, but with two and three levels, it’s impractical
    to do this for every file). Another way to extend the maximum size 4GB at a time
    is to use multiple pointers to second-tier file blocks (for example, have all
    or most of the original 8 to 16 pointers in the directory point at second-tier
    block-list entries rather than directly at file data blocks). Although there’s
    no current convention for extending beyond three levels, rest assured that as
    the need arises, OS designers will develop schemes for accessing large files efficiently.
    For example, 64-bit OSes can use 64-bit pointers, rather than 32-bit pointers,
    and eliminate the 4GB limitation.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 随着磁盘容量的增大，这种方案所施加的 4GB 文件限制开始对某些应用程序（如视频编辑器、大型数据库应用程序和 Web 服务器）造成问题。通过向块列表树中添加另一级，可以轻松将此方案扩展
    1,000 倍，达到 4TB。这个方法的唯一问题是，间接层级越多，随机文件访问速度越慢，因为操作系统可能需要从磁盘读取多个块才能获取一个数据块。（当只有一层时，将块指针列表缓存在内存中是有意义的，但有两层和三层时，想对每个文件都这样做就不现实了）。另一种扩展最大文件大小（每次扩展
    4GB）的方法是使用多个指针指向二级文件块（例如，将目录中的所有或大部分 8 到 16 个指针指向二级块列表项，而不是直接指向文件数据块）。虽然目前没有扩展超过三层的惯例，但可以放心，一旦需求出现，操作系统设计师将会开发高效访问大文件的方案。例如，64
    位操作系统可以使用 64 位指针，而不是 32 位指针，从而消除 4GB 限制。
- en: '**14.8 Writing Software That Manipulates Data on a Mass Storage Device**'
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**14.8 编写操作大容量存储设备上数据的软件**'
- en: Understanding how different mass storage devices behave is important if you
    want to write high-performance software that manipulates files on these devices.
    Although modern OSes attempt to isolate applications from the physical realities
    of mass storage, an OS can only do so much for you. Furthermore, because an OS
    can’t predict how your particular application will access files on a mass storage
    device, it can’t tailor file access optimizations to your application; instead,
    its optimizations are geared toward applications exhibiting *typical* file access
    patterns. The less typical your application’s file I/O is, then, the less likely
    you’ll get the best performance out of the system. In this section, we’ll look
    at how you can coordinate your file access activities with the OS to achieve the
    best performance.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 理解不同大容量存储设备的行为非常重要，特别是当你想编写能够操作这些设备中文件的高性能软件时。尽管现代操作系统试图将应用程序与大容量存储的物理现实隔离开来，但操作系统能为你做的事是有限的。而且，由于操作系统无法预测你特定应用程序如何访问大容量存储设备上的文件，它无法为你的应用程序量身定制文件访问优化；相反，它的优化是针对具有*典型*文件访问模式的应用程序设计的。因此，如果你的应用程序的文件
    I/O 方式不典型，那么你就不太可能从系统中获得最佳的性能。在本节中，我们将探讨如何与操作系统协调文件访问活动，以实现最佳性能。
- en: '***14.8.1 File Access Performance***'
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.8.1 文件访问性能***'
- en: Although disk drives and most other mass storage devices are often thought of
    as “random access” devices, the fact is that mass storage access is usually more
    efficient when done sequentially. Sequential access on a disk drive is relatively
    efficient because the OS can move the read/write head one track at a time (assuming
    the file appears in sequential blocks on the disk). This is much faster than accessing
    one block on the disk, moving the read/write head to some other track, accessing
    another block, moving the head again, and so on. Therefore, you should avoid random
    file access in an application if at all possible.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然磁盘驱动器和大多数其他大容量存储设备常被认为是“随机访问”设备，但实际上，大容量存储的访问通常在顺序访问时更为高效。磁盘驱动器上的顺序访问相对高效，因为操作系统可以一次移动读写头一个磁道（假设文件按顺序块出现在磁盘上）。这比访问磁盘上的一个块、将读写头移动到另一个磁道、访问另一个块、再移动读写头，依此类推，要快得多。因此，如果可能的话，你应该避免应用程序中的随机文件访问。
- en: You should also try to read or write large blocks of data on each file access
    rather than reading or writing small amounts more frequently. There are two reasons
    for this. First, OS calls are not fast, so if you make half as many calls by reading
    or writing twice as much data on each access, the application will often run twice
    as fast. Second, the OS must read or write whole disk blocks. If your block size
    is 4,096 bytes, but you just write 2,000 bytes to some block and then seek to
    some other position in the file outside that block, the OS will actually have
    to read the entire 4,096-byte block from the disk, merge in the 2,000 bytes, and
    then finally write the entire 4,096 bytes back to the disk. Contrast this with
    a write operation that writes a full 4,096 bytes—in this case, the OS wouldn’t
    have to read the data from the disk first; it would only have to write the block.
    Writing full blocks improves disk access performance by a factor of 2, because
    writing partial blocks requires the OS to first read the block, merge the data,
    and then write the block; writing whole blocks renders the read operation unnecessary.
    Even if your application doesn’t write data in increments that are even multiples
    of the disk’s block size, writing large blocks improves performance. If you write
    16,000 bytes to a file in one write operation, the OS will still have to write
    the last block of those 16,000 bytes using a read-merge-write operation, but it
    will write the first three blocks using only write operations.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 你还应该尽量在每次文件访问时读取或写入大块数据，而不是更频繁地读取或写入小块数据。这有两个原因。首先，操作系统调用的速度并不快，因此，如果你通过每次读取或写入更多的数据来减少调用次数，应用程序通常会运行得更快。其次，操作系统必须读取或写入整个磁盘块。如果你的块大小是4,096字节，但你只向某个块写入2,000字节，然后又跳到文件中的另一个位置进行访问，操作系统实际上必须先从磁盘读取整个4,096字节的块，将2,000字节合并进去，然后再将整个4,096字节写回磁盘。与此对比，如果写入操作是一次性写入完整的4,096字节，操作系统就不必先从磁盘读取数据；它只需要写入这个块。写入完整的块提高了磁盘访问性能，提升幅度为2倍，因为写入部分块需要操作系统首先读取块、合并数据，再写入块；而写入完整块则无需读取操作。即使你的应用程序没有按磁盘块大小的整数倍写入数据，写入大块数据仍然能提高性能。如果你在一次写入操作中向文件写入16,000字节，操作系统仍然需要使用读-合并-写操作来写入那16,000字节中的最后一个块，但它将只使用写操作来写入前面三个块。
- en: If you start with a relatively empty disk, the OS generally attempts to write
    the data for new files in sequential blocks. This organization is probably most
    efficient for future file access. However, as the system’s users create and delete
    files on the disk, the blocks of data for individual files may be distributed
    nonsequentially. In a very bad case, the OS may wind up allocating a few blocks
    here and a few blocks there all across the disk’s surface. As a result, even sequential
    file access can behave like slow random file access. As discussed previously,
    this kind of file fragmentation can dramatically decrease filesystem performance.
    Unfortunately, there’s no way for an application to determine if its file data
    is fragmented across the disk surface and, even if it could, there’s little it
    could do about the situation. Although there are utilities available to *defragment*
    the blocks on the disk’s surface, an application generally can’t request their
    execution (and “defragger” utilities are quite slow anyway).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从一个相对空的磁盘开始，操作系统通常会尝试将新文件的数据写入顺序块。这种组织方式对于未来文件访问可能是最有效的。然而，随着系统用户在磁盘上创建和删除文件，单个文件的数据块可能会非顺序分布。在非常糟糕的情况下，操作系统可能会在磁盘的不同位置分配几个块。这会导致即使是顺序文件访问，也可能像慢速的随机文件访问那样表现。如前所述，这种文件碎片化会显著降低文件系统的性能。不幸的是，应用程序无法确定其文件数据是否在磁盘表面上碎片化，即使它能确定，也几乎无法解决这一问题。虽然有一些工具可以*整理*磁盘表面上的数据块，应用程序通常不能请求它们的执行（而且“碎片整理”工具本身也非常慢）。
- en: Although applications rarely get the opportunity to defragment their data files
    during normal program execution, there are some things you can do to reduce the
    probability of your data files becoming fragmented. The best advice you can follow
    is to always write file data in large chunks. Indeed, if you can write the whole
    file in a single write operation, do so. In addition to speeding up access to
    the OS, writing large amounts of data tends to result in the allocation of sequential
    blocks. When you write small blocks of data to the disk, other applications in
    a multitasking environment could also be writing to the disk concurrently. In
    this case, the OS may interleave the block allocation requests for the files being
    written by several different applications, making it unlikely that a particular
    file’s data will be written sequentially. It is important to try to write a file’s
    data in sequential blocks, even if you plan to access portions of that data randomly,
    since searching for random records in a file written sequentially generally requires
    far less head movement than searching for random records in a file whose blocks
    are scattered all over.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管应用程序在正常程序执行过程中很少有机会对数据文件进行碎片整理，但你可以采取一些措施来减少数据文件碎片化的概率。你可以遵循的最佳建议是始终以大块数据写入文件。实际上，如果你能够通过一次写操作将整个文件写入，最好这样做。除了加快操作系统的访问速度外，写入大量数据往往会导致分配顺序块。当你将小块数据写入磁盘时，其他应用程序在多任务环境下也可能同时写入磁盘。在这种情况下，操作系统可能会交错不同应用程序对文件的块分配请求，从而使某个特定文件的数据不太可能按顺序写入。即使你计划随机访问数据的某些部分，也要尽量将文件的数据写入顺序块，因为在顺序写入的文件中查找随机记录通常需要的寻道时间远少于查找那些数据块散布在各处的文件。
- en: If you’re going to create a file and then access its blocks of data repeatedly,
    whether randomly or sequentially, try to preallocate the blocks on the disk. If
    you know, for example, that your file’s data will not exceed 1MB, you could write
    a block of one million `0`s to the disk before your application starts manipulating
    the file. By doing so, you help ensure that the OS will write your file to sequential
    blocks on the disk. Though you pay an initial price to write all those `0`s (an
    operation you wouldn’t normally do, presumably), the savings in read/write head-seek
    times could easily make up for it. This scheme is especially useful if an application
    is reading or writing two or more files concurrently (which would almost guarantee
    the interleaving of the blocks for the various files).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算创建一个文件并反复访问其数据块，无论是随机访问还是顺序访问，最好在磁盘上预分配这些数据块。例如，如果你知道文件的数据不会超过1MB，你可以在应用程序开始操作文件之前，先将一百万个`0`写入磁盘。这样做可以帮助确保操作系统将文件写入磁盘的顺序块中。尽管你需要付出初始代价来写入这些`0`（这通常不是你会做的操作），但在读写头寻道时间上的节省很可能弥补了这一点。如果一个应用程序同时读取或写入两个或更多文件（这几乎肯定会导致不同文件的数据块交错），这种方法尤其有用。
- en: '***14.8.2 Synchronous and Asynchronous I/O***'
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.8.2 同步与异步 I/O***'
- en: Because most mass storage devices are mechanical, and, therefore, subject to
    mechanical delays, applications that use them extensively have to wait for them
    to complete read/write operations. Most disk I/O operations are *synchronous*,
    meaning that an application that makes a call to the OS must wait until that I/O
    request is complete before continuing subsequent operations.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数大容量存储设备是机械式的，因此会受到机械延迟的影响，频繁使用它们的应用程序必须等待它们完成读写操作。大多数磁盘 I/O 操作是*同步的*，意味着发出操作系统调用的应用程序必须等待该
    I/O 请求完成后才能继续后续操作。
- en: This is why most modern OSes also provide an *[asynchronous I/O](gloss01.xhtml#gloss01_19)*
    capability, in which the OS begins the application’s request and then returns
    control to the application without waiting for the I/O operation to complete.
    While the I/O operation proceeds, the application promises not to do anything
    with the data buffer specified for it. However, the application can do computation
    and schedule additional I/O operations, because the OS will notify it when the
    original request completes. This is especially useful when you’re accessing files
    on multiple disk drives in the system, which is usually possible only with SCSI
    and other high-end drives.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么大多数现代操作系统也提供* [异步 I/O](gloss01.xhtml#gloss01_19)*功能的原因，在这种功能中，操作系统启动应用程序的请求后，会立即将控制权返回给应用程序，而无需等待
    I/O 操作完成。当 I/O 操作进行时，应用程序承诺不会对指定的数据缓冲区进行任何操作。然而，应用程序可以进行计算并安排额外的 I/O 操作，因为操作系统会在原始请求完成时通知它。当你在系统中访问多个磁盘驱动器上的文件时，这种方式尤其有用，通常只有
    SCSI 和其他高端驱动器才能做到这一点。
- en: '***14.8.3 The Implications of I/O Type***'
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.8.3 I/O 类型的影响***'
- en: 'Another important consideration for writing software that manipulates mass
    storage devices is the type of I/O you’re performing. *Binary I/O* is usually
    faster than *formatted text I/O*, because of the format of the data written to
    disk. For example, suppose you have an array of 16 integer values that you want
    to write to a file. To achieve this, you could use either of the following two
    C/C++ code sequences:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 编写处理大容量存储设备的软件时，另一个重要的考虑因素是你所执行的 I/O 类型。*二进制 I/O* 通常比*格式化文本 I/O* 更快，因为写入磁盘的数据格式不同。例如，假设你有一个包含
    16 个整数值的数组，想要将其写入文件。为此，你可以使用以下两段 C/C++ 代码序列中的任何一个：
- en: '[PRE0]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The second sequence looks like it would run slower than the first because it
    uses a loop, rather than a single call, to step through each element of the array.
    But although the extra execution overhead of the loop does have a small negative
    impact on the execution time of the write operation, this efficiency loss is minor
    compared to the real problem with the second sequence. Whereas the first code
    sequence writes out a 64-byte memory image consisting of 16 32-bit integers to
    the disk, the second code sequence converts each of the 16 integers to a string
    of characters and then writes each string to the disk. This integer-to-string
    conversion process is relatively slow. Furthermore, the `fprintf()` function has
    to interpret the format string (`"%d"`) at runtime, which incurs an additional
    delay.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个代码序列看起来比第一个运行得慢，因为它使用了循环，而不是单一的调用，来逐步遍历数组中的每个元素。但是，尽管循环带来的额外执行开销对写操作的执行时间有些许负面影响，这种效率损失与第二个序列中的真正问题相比微不足道。第一个代码序列将由
    16 个 32 位整数组成的 64 字节内存映像写入磁盘，而第二个代码序列则将每个 16 个整数转换为字符串，然后将每个字符串写入磁盘。这种整数到字符串的转换过程相对较慢。此外，`fprintf()`
    函数必须在运行时解释格式字符串（`"%d"`），这也会带来额外的延迟。
- en: The advantage of formatted I/O is that the resulting file is both human-readable
    and easily read by other applications. However, if you’re using a file to hold
    data that is of interest only to your application, a more efficient approach might
    be to write the data as a memory image.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 格式化 I/O 的优势在于，生成的文件既易于人类阅读，也容易被其他应用程序读取。然而，如果你使用文件来存储只对你的应用程序有意义的数据，更高效的方法可能是将数据以内存映像的形式写入文件。
- en: '***14.8.4 Memory-Mapped Files***'
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***14.8.4 内存映射文件***'
- en: Memory-mapped files use the OS’s virtual memory capabilities to map memory addresses
    in the application space directly to blocks on the disk. Modern OSes have highly
    optimized virtual memory subsystems, so piggy-backing file I/O on top of the virtual
    memory subsystem results in very efficient file access. Furthermore, memory-mapped
    file access is easy. When you open a memory-mapped file, the OS returns a memory
    pointer to some block of memory. By simply accessing the memory locations referenced
    by this pointer, just as you would any other in-memory data structure, you can
    access the file’s data. This makes file access almost trivial, while often improving
    file manipulation performance, especially when file access is random.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 内存映射文件利用操作系统的虚拟内存功能，将应用程序空间中的内存地址直接映射到磁盘上的块。现代操作系统拥有高度优化的虚拟内存子系统，因此将文件 I/O 叠加在虚拟内存子系统之上，可以实现非常高效的文件访问。此外，内存映射文件的访问非常简便。当你打开一个内存映射文件时，操作系统会返回指向某个内存块的内存指针。只需像访问任何其他内存数据结构一样访问此指针引用的内存位置，你就可以访问文件数据。这使得文件访问几乎变得微不足道，同时通常能提高文件操作性能，尤其是在文件访问是随机的情况下。
- en: One of the reasons that memory-mapped files are so much more efficient than
    regular files is that the OS reads the list of blocks belonging to memory-mapped
    files only once. It then sets up the system’s memory management tables to point
    at each block belonging to the file. After opening the file, the OS rarely has
    to read any file metadata from the disk, which greatly reduces superfluous disk
    access during random file access. It also improves sequential file access, though
    to a lesser degree. The OS doesn’t constantly have to copy data between the disk,
    internal OS buffers, and application data buffers.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 内存映射文件比普通文件更高效的原因之一是操作系统只需要读取一次内存映射文件所属的块的列表。然后，操作系统会设置系统的内存管理表，指向文件所属的每个块。打开文件后，操作系统很少需要从磁盘读取任何文件元数据，这大大减少了在随机文件访问过程中多余的磁盘访问。它也改善了顺序文件访问，尽管程度较轻。操作系统不需要不断地在磁盘、操作系统内部缓冲区和应用程序数据缓冲区之间复制数据。
- en: Memory-mapped file access does have some disadvantages. First, you can’t map
    gigantic files entirely into memory, at least on older PCs and OSes that have
    a 32-bit address bus and set aside a maximum of 4GB per application. Generally,
    it isn’t practical to use a memory-mapped access scheme for files larger than
    256MB, though this has changed as more CPUs with 64-bit addressing capabilities
    have become available. It’s also not a good idea to use memory-mapped files when
    an application is already using most of the RAM physically present in the system.
    Fortunately, these two situations are not typical, so they don’t limit the use
    of memory-mapped files much.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 内存映射文件访问确实有一些缺点。首先，你无法将庞大的文件完全映射到内存中，至少在那些使用32位地址总线并为每个应用程序分配最多4GB内存的旧PC和操作系统上无法实现。通常，对于大于256MB的文件，使用内存映射访问方案并不实际，尽管随着越来越多支持64位寻址的CPU的问世，这一情况有所改变。当应用程序已经使用了系统中大部分物理内存时，使用内存映射文件也不是一个好主意。幸运的是，这两种情况并不常见，因此它们对内存映射文件的使用限制不大。
- en: A more common and significant issue is that when you first create a memory-mapped
    file, you have to tell the OS the file’s maximum size. If it’s impossible to determine
    the file’s final size, you’ll have to overestimate it and then truncate the file
    when you close it. Unfortunately, this wastes system memory while the file is
    open. Memory-mapped files work well when you’re manipulating files in read-only
    mode or simply reading and writing data in an existing file without extending
    the file’s size. Fortunately, you can always create a file using traditional file
    access mechanisms and then use memory-mapped file I/O to access the file later.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更常见且重要的问题是，当你首次创建一个内存映射文件时，必须告诉操作系统该文件的最大大小。如果无法确定文件的最终大小，你必须高估它，然后在关闭文件时截断它。不幸的是，这会在文件打开时浪费系统内存。内存映射文件在你以只读模式操作文件或只是读取和写入现有文件中的数据而不扩展文件大小时表现良好。幸运的是，你总是可以先使用传统的文件访问机制创建一个文件，然后使用内存映射文件I/O在稍后访问该文件。
- en: Finally, almost every OS does memory-mapped file access differently, so it’s
    unlikely that memory-mapped file I/O code will be portable between OSes. Nevertheless,
    the code to open and close memory-mapped files is quite short, and it’s easy enough
    to provide multiple copies of the code for the various OSes you need to support.
    Of course, actually accessing the file’s data consists of simple memory accesses,
    and that’s independent of the OS. For more information on memory-mapped files,
    consult your OS’s API reference. Given their convenience and performance, you
    should seriously consider using memory-mapped files whenever possible in your
    applications.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，几乎每个操作系统对内存映射文件的访问方式都不同，因此内存映射文件的I/O代码在操作系统之间不太可能是可移植的。不过，打开和关闭内存映射文件的代码非常简短，而且为需要支持的不同操作系统提供多个版本的代码也并不难。当然，实际访问文件数据的操作是简单的内存访问，这与操作系统无关。有关内存映射文件的更多信息，请查阅操作系统的API参考文档。鉴于它们的便利性和性能，你应该在应用程序中尽可能考虑使用内存映射文件。
- en: '**14.9 For More Information**'
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**14.9 更多信息**'
- en: 'Silberschatz, Abraham, Peter Baer Galvin, and Greg Gagne. *Operating System
    Concepts*. 8th ed. Hoboken, NJ: John Wiley & Sons, 2009.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Silberschatz, Abraham, Peter Baer Galvin, 和 Greg Gagne. *操作系统概念*。第8版。霍博肯，NJ：John
    Wiley & Sons, 2009.
