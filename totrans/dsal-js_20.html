<html><head></head><body>
<section epub:type="chapter" role="doc-chapter" aria-labelledby="ch17">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_425" aria-label="425"/>&#13;
<hgroup>&#13;
&#13;
<h2 class="CHAPTER" id="ch17">&#13;
<span class="CN"><span class="SANS_Futura_Std_Bold_Condensed_B_11">17</span></span>&#13;
<span class="CT"><span class="SANS_Dogma_OT_Bold_B_11">GRAPHS</span></span>&#13;
</h2>&#13;
</hgroup>&#13;
<figure class="opener"><img class="opener" src="../images/opener.jpg" alt=""/>&#13;
</figure>&#13;
<p class="INTRO">In the previous chapters we discussed several data structures, and in this chapter we’ll consider a new topic, how to represent graphs<i>.</i> We’ll also look at several algorithms related to graphs, such as finding the shortest paths, calculating distances, checking software dependencies, and more.</p>&#13;
<section epub:type="division" aria-labelledby="sec1">&#13;
&#13;
<h3 class="H1" id="sec1"><span id="h1-90"/><span class="SANS_Futura_Std_Bold_B_11">What Are Graphs?</span></h3>&#13;
<p class="TNI1">An abstract definition might be that a graph is a set of objects in which pairs of those objects are somehow related. The objects are called <i>vertices</i> (plural of <i>vertex</i>), but they’re also called <i>points</i> and <i>nodes</i>. The relationships between pairs of vertices are graphically represented with lines joining the pairs. These lines are called <i>edges</i>, <i>arcs</i>, <i>arrows</i>, or just plain <i>links</i>. The number of arcs connected to a point is called its <i>degree</i>. Points linked in this fashion are sometimes called <i>neighbors</i> or are considered to be <i>adjacent</i> to each <span role="doc-pagebreak" epub:type="pagebreak" id="pg_426" aria-label="426"/>other. The same word is used in a similar sense: edges are considered to be adjacent if they share a common vertex.</p>&#13;
<p class="TX">These definitions may sound vague or rather “mathematical” (in fact, a branch of mathematics that specifically studies graphs and their properties is called <i>graph theory</i>), so this chapter will explore some practical examples. (We’ve actually already studied graphs. Trees are graphs; indeed, the definition fits them.) Some use cases for graphs include the following:</p>&#13;
<ul class="ul">&#13;
<li class="ListBullet">Relationships among people, where you can have people (nodes) and friendships (arcs), so that if two people are friends, they are linked</li>&#13;
<li class="ListBullet">Dependencies in code, with modules (nodes) that import components (arcs) exported from other modules</li>&#13;
<li class="ListBullet">Projects with tasks (nodes) that can’t be started until some other tasks have been finished (arcs)</li>&#13;
<li class="ListBullet">Maps, as in GPS-based applications, with cities (nodes) and roads (arcs)</li>&#13;
</ul>&#13;
<p class="TX"><a href="chapter17.xhtml#fig17-1">Figure 17-1</a> shows an example of the latter, using a graph to represent a part of a city or a country.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-1" src="../images/Figure17-1.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-1: A graph representing some cities and roads linking them</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">In this graphical map, vertices represent cities (or street corners, or countries), and the edges represent roads (or street blocks, or flights). In <a href="chapter17.xhtml#fig17-1">Figure 17-1</a>, the edges are <i>undirected</i>, meaning that one may travel any direction—for example, from A to E or from E to A.</p>&#13;
<p class="TX">In a city map, where streets may be one-way only, we’d need a <i>directed</i> graph instead, as shown in <a href="chapter17.xhtml#fig17-2">Figure 17-2</a>. In these graphs, we can speak of the <i>outdegree</i> of a node (how many arcs lead out from it) or the <i>indegree</i> of a node (how many arcs lead into it).</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_427" aria-label="427"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-2" src="../images/Figure17-2.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-2: A directed graph where you can travel the roads in only one direction</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Edges usually have values associated with them, like time or cost, making them <i>weighted</i> graphs. <i>Unweighted</i> graphs with no values associated with edges are also possible; the association itself is all that matters. Don’t assume that symmetry or any other rules apply to directed graphs. For instance, in the graph in <a href="chapter17.xhtml#fig17-2">Figure 17-2</a>, you can go from B to C directly, but you can’t go back from C to B in one step. Also, going from A to B doesn’t cost the same as going from B to A. Finally, going from G to D via F could be cheaper than going directly from G to F. In some cases weights could be negative, but we’re always working here with non-negative values.</p>&#13;
<blockquote>&#13;
<p class="Note"><span class="SANS_Dogma_OT_Bold_B_15">NOTE</span></p>&#13;
</blockquote>&#13;
<p class="NOTE-TXT"><i>Graphs can also have multiple edges between any pair of vertices, but we’re not going to consider those. For all the algorithms in the chapter, it’ll be enough to just use the shortest edge and simply ignore the others. Another possibility we’ll ignore here is edges from a vertex to itself, which are called loops.</i></p>&#13;
<p class="TX">We’ll consider the following kinds of processes:</p>&#13;
<ul class="ul">&#13;
<li class="ListBullet">Given two vertices, you may want to know whether there’s a path from the first to the second. As an extension to this, you might want to find the path with the minimum cost (the <i>shortest path</i>) from one vertex to another one or to all other vertices.</li>&#13;
<li class="ListBullet">A directed graph may represent a project with tasks and dependencies between them: you might want to find an ordering so that no task can start until all previous tasks have been finished; this is called a <i>topological sort</i>.</li>&#13;
<li class="ListBullet">Building on this example of tasks and dependencies, you may worry that some kind of cycle (A before B before C before A) would make sorting impossible. A related problem to topological sorting is <i>cycle detection</i>.</li>&#13;
<li class="ListBullet">An undirected graph may represent geographic points with the edges showing the cost of joining them with, say, electrical lines or communication cables. A <i>minimum spanning tree</i> shows how to choose edges so all points are connected to each other at the lowest total cost.</li>&#13;
<li class="ListBullet"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_428" aria-label="428"/>Along the same lines, given the previous graph, you could ask whether it’s connected (meaning that it’s possible to reach every point from any other point) or unconnected. In that case, you want to implement <i>connectivity detection</i>.</li>&#13;
</ul>&#13;
<p class="TX">This list of procedures isn’t complete, but it covers the most important algorithms. Let’s start by considering how to represent graphs and then move on to the necessary algorithms.</p>&#13;
<p class="TX">One final note: when discussing the performance of algorithms, we’ll use <i>v</i> to stand for the number of vertices and <i>e</i> for the number of edges. Take care not to confuse this with the mathematical constant <i>e</i>, the basis for natural logarithms, 2.718281728 ...!</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec2">&#13;
&#13;
<h3 class="H1" id="sec2"><span id="h1-91"/><span class="SANS_Futura_Std_Bold_B_11">Representing Graphs</span></h3>&#13;
<p class="TNI1">There are several ways to represent graphs, and we’ll consider the three most used methods: adjacency matrix, adjacency list, and adjacency set.</p>&#13;
<section epub:type="division" aria-labelledby="sec3">&#13;
&#13;
<h4 class="H2" id="sec3"><span id="h2-175"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Adjacency Matrix Representation for Graphs</span></h4>&#13;
<p class="TNI1">The <i>adjacency matrix</i> representation is the simplest and basically shows which nodes are adjacent to each other. This type of graph is represented by a square matrix, with a row and column for each vertex. If there’s a link from vertex <i>i</i> to vertex <i>j</i>, the matrix has a value at position <span class="SANS_TheSansMonoCd_W5Regular_11">[i][j]</span>: this is just a true value for unweighted graphs or the associated edge’s cost for weighted graphs. If there’s no link between those vertices, the matrix has <span class="SANS_TheSansMonoCd_W5Regular_11">false</span> or a special value (zero or +infinity) at the corresponding position. For undirected graphs, note that position <span class="SANS_TheSansMonoCd_W5Regular_11">[i][j]</span> will always be equal to position <span class="SANS_TheSansMonoCd_W5Regular_11">[j][i]</span>; the matrix will be symmetrical with regard to its main diagonal.</p>&#13;
<p class="TX">Consider the directed graph from the previous section again (<a href="chapter17.xhtml#fig17-2">Figure 17-2</a>). The matrix representation for that graph could be as <a href="chapter17.xhtml#fig17-3">Figure 17-3</a> shows.</p>&#13;
<figure class="IMG"><img class="img5" id="fig17-3" src="../images/Figure17-3.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-3: The adjacency matrix representation for the graph in <a href="chapter17.xhtml#fig17-2">Figure 17-2</a></span></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_429" aria-label="429"/>We’ve used the option of representing missing edges with zero; an equally valid solution is to represent those with +infinity. No matter how you represent missing edges, in both cases, the diagonal of the matrix is zero. There’s no cost involved in going from a point to itself; you’re already there.</p>&#13;
<p class="TX">This representation is quite easy to work with, but it requires a lot of space for large graphs. As to performance, operations like checking whether two vertices are adjacent or adding or removing edges are <i>O</i>(1), which is as fast as possible. On the other hand, processing the list of edges of a vertex is <i>O</i>(<i>v</i>) no matter how many neighbors a node actually has.</p>&#13;
<p class="TX">If nodes have only a few neighbors, most of the matrix will be marked as empty (making it a <i>sparse</i> matrix), which means you’re wasting space. For those cases, you can choose adjacency list representations.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec4">&#13;
&#13;
<h4 class="H2" id="sec4"><span id="h2-176"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Adjacency List Representation for Graphs</span></h4>&#13;
<p class="TNI1">The matrix shown in <a href="chapter17.xhtml#fig17-3">Figure 17-3</a> wastes too much space and causes all procedures that need the list of arcs out of a point to be <i>O</i>(<i>v</i>). You can use lists so that for each vertex, you’ll have all the points to which it connects and also all of the points that connect to it.</p>&#13;
<p class="TX">For the same directed graph shown in <a href="chapter17.xhtml#fig17-2">Figure 17-2</a>, the <i>adjacency lists</i> representation is as shown in <a href="chapter17.xhtml#fig17-4">Figure 17-4</a> (compare this with the matrix representation in <a href="chapter17.xhtml#fig17-3">Figure 17-3</a>).</p>&#13;
<figure class="IMG"><img class="img5" id="fig17-4" src="../images/Figure17-4.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-4: The adjacency list representation is an alternative to the adjacency matrix.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">For each vertex, you have two lists: one with outgoing edges (shown horizontally, as rows) and one with incoming edges (shown vertically, as columns). For example, in the first row, you see that from A, one may reach B (at a cost of 4) or E (at a cost of 11). Looking at the first column, you see that you can reach A from B (at a cost of 3) or D (at a cost of 5). Each element in the structure would have a pointer to the next in the same row and another to the next in the same column. You could also work with doubly linked lists for easier updates. Nodes also have to carry the identities of both endpoints.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_430" aria-label="430"/>With this structure, it’s easy to process all edges that start or end at a given vertex quickly, and that will speed up several algorithms. However, things become slower if you just want to know whether two given points are directly connected; with this structure, it would be an <i>O</i>(<i>e</i>) operation. You may opt for using sets instead of lists, as shown later.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec5">&#13;
&#13;
<h4 class="H2" id="sec5"><span id="h2-177"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Adjacency Set Representation for Graphs</span></h4>&#13;
<p class="TNI1">The more complex solution we can propose involves using sets (as in <span class="Xref"><a href="chapter11.xhtml">Chapter 11</a></span>) or trees (as in <span class="Xref"><a href="chapter12.xhtml">Chapter 12</a></span>) instead of lists. For instance, when working with balanced search trees, checking whether two points are connected is a <i>O</i>(log <i>e</i>) operation. (You could consider an average degree of <i>e</i>/<i>v</i> edges per node, and then it would be <i>O</i>(log <i>e/v</i>) instead.) With this structure, each vertex is associated with two maps: one for outgoing edges and one for incoming edges. The key for both maps would be the “other” point in the edge. Adding and removing edges are both <i>O</i>(log <i>e</i>) operations, so performance is better. Processing all arcs out of a node is as fast as with lists.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec6">&#13;
&#13;
<h3 class="H1" id="sec6"><span id="h1-92"/><span class="SANS_Futura_Std_Bold_B_11">Finding the Shortest Paths</span></h3>&#13;
<p class="TNI1">A common problem is as follows: given two points in a graph, find a path from the first to the second. A path is a sequence of adjacent edges (each starting where the previous ends) that begins at the first point and ends at the second one.</p>&#13;
<p class="TX">We already considered this kind of problem when you found a path through a maze in <span class="Xref"><a href="chapter5.xhtml">Chapter 5</a></span>, so instead solve a more complex problem: finding the <i>shortest</i> path from a node to another node, or even more generally, finding the shortest path for a node to all other nodes. These algorithms will not only find whether a path exists, but they’ll also find the best one (cheapest, shortest) among all possibilities. If you just want to find a path, any path, you can simply stop searching as soon as you reach the destination point.</p>&#13;
<section epub:type="division" aria-labelledby="sec7">&#13;
&#13;
<h4 class="H2" id="sec7"><span id="h2-178"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Floyd-Warshall’s “All Paths” Algorithm</span></h4>&#13;
<p class="TNI1">This first algorithm is interesting because it applies dynamic programming, which you explored in <span class="Xref"><a href="chapter5.xhtml">Chapter 5</a></span>. The <i>Floyd-Warshall algorithm</i> doesn’t have the best possible performance (you’ll see other options for that), but it’s definitely the simplest. There’s another difference: here, you’ll find the shortest distance between all pairs of nodes, while in other cases you may just want to find the distance between a specific pair. This stipulation will have an impact on the performance, but in some cases, having the whole table of distances may be exactly what’s required.</p>&#13;
<p class="TX">Assume the existence of a function <i>distance</i>(<i>i,j,k</i>) that returns the length of the shortest path from point <i>i</i> to point <i>j</i> using, at most, the first <i>k</i> nodes in the graph for the path. (In other words, you’re not considering any path through the rest of the nodes.) You want to calculate <i>distance</i>(<i>i,j,n</i>) for all values of <i>i</i> and <i>j</i>.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_431" aria-label="431"/>The value of <i>distance</i>(<i>i,j,k</i>) must be either a path that doesn’t include the <i>k</i>th node or else a path that goes from <i>i</i> to <i>k</i> and then from <i>k</i> to <i>j</i>, whichever is shortest. In other words, <i>distance</i>(<i>i,j,k</i>) is the minimum of <i>distance</i>(<i>i,j,k</i> – 1) and <i>distance</i>(<i>i,k,k</i> – 1) + <i>distance</i>(<i>k,j,k</i> – 1). This formula is key; be sure you totally agree with it. The definition is recursive, but the base case is simple: <i>distance</i>(<i>i,i,</i>0) is 0 for all points, and for <i>i ≠ j</i>, <i>distance</i>(<i>i,j,</i>0) is the edge from <i>i</i> to <i>j</i>, if it exists, or +infinity instead. (What about finding the actual paths and not just the distances? See question 17.1.)</p>&#13;
<p class="TX">As an example, work with the graph in <a href="chapter17.xhtml#fig17-5">Figure 17-5</a>. It’s undirected for simplicity, but the algorithm works with directed graphs as well.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-5" src="../images/Figure17-5.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-5: A graph for which you want to find minimum distances between any pair of points</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><a href="chapter17.xhtml#fig17-6">Figure 17-6</a> shows the initial array of distances in <a href="chapter17.xhtml#fig17-5">Figure 17-5</a>.</p>&#13;
<figure class="IMG"><img class="img5" id="fig17-6" src="../images/Figure17-6.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-6: The adjacency matrix for the graph in <a href="chapter17.xhtml#fig17-5">Figure 17-5</a>, using infinity values for missing edges</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The diagonal in <a href="chapter17.xhtml#fig17-6">Figure 17-6</a> is all zeros, and everything is +infinity except for the existing edges. (This is just the adjacency matrix using +infinity instead of zero for missing edges, as mentioned earlier in the chapter.) In the first iteration, check whether adding the first point (A) <span role="doc-pagebreak" epub:type="pagebreak" id="pg_432" aria-label="432"/>as an intermediate shortens some distances. In effect, you find that now you can go from B to D at a cost of 9, as shown in <a href="chapter17.xhtml#fig17-7">Figure 17-7</a>.</p>&#13;
<figure class="IMG"><img class="img5" id="fig17-7" src="../images/Figure17-7.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-7: When you try adding A as an intermediate point, you find a shorter distance between B and D.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The second iteration checks whether adding B as an intermediate makes for shorter routes. You find that you can now go from A to C at a cost of 13 and from C to D (C to B and then B to D via A) at a cost of 18, as shown in <a href="chapter17.xhtml#fig17-8">Figure 17-8</a>.</p>&#13;
<figure class="IMG"><img class="img5" id="fig17-8" src="../images/Figure17-8.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-8: When you try adding B as an intermediate, you find two other shorter routes.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">In the next iteration you’ll check whether adding C as an intermediate helps; then, you’ll try D, E, and so on. You keep iterating until all the nodes have been considered and the final result (check it out) provides all the distances between nodes (see <a href="chapter17.xhtml#fig17-9">Figure 17-9</a>).</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_433" aria-label="433"/>&#13;
<figure class="IMG"><img class="img5" id="fig17-9" src="../images/Figure17-9.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-9: After trying out all possible intermediate points, you compute the final distances matrix.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The code is short:</p>&#13;
<pre id="pre-344"><code>const distances = (graph) =&gt; {&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> const n = graph.length;&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> const distance = [];&#13;
<span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> for (let i = 0; i &lt; n; i++) {&#13;
    distance[i] = Array(n).fill(+Infinity);&#13;
  }&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> graph.forEach((r, i) =&gt; {&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> distance[i][i] = 0;&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation6">❻</span> r.forEach((c, j) =&gt; {&#13;
      if (c &gt; 0) {&#13;
        distance[i][j] = graph[i][j];&#13;
      }&#13;
    });&#13;
  });&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation7">❼</span> for (let k = 0; k &lt; n; k++) {&#13;
    for (let i = 0; i &lt; n; i++) {&#13;
      for (let j = 0; j &lt; n; j++) {&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation8">❽</span> if (distance[i][j] &gt; distance[i][k] + distance[k][j]) {&#13;
          distance[i][j] = distance[i][k] + distance[k][j];&#13;
        }&#13;
      }&#13;
    }&#13;
  }&#13;
&#13;
 <span class="Code_CodeAnnotation" aria-label="annotation9">❾</span> return distance;&#13;
};</code></pre>&#13;
<p class="TX">The <span class="SANS_TheSansMonoCd_W5Regular_11">n</span> variable <span class="CodeAnnotation" aria-label="annotation1">❶</span> helps shorten the code; it’s just the number of nodes in the graph. The <span class="SANS_TheSansMonoCd_W5Regular_11">distance</span> array of arrays <span class="CodeAnnotation" aria-label="annotation2">❷</span> includes the distances from every node to every other node. Initially, set all distances to +infinity <span class="CodeAnnotation" aria-label="annotation3">❸</span> and then correct <span class="CodeAnnotation" aria-label="annotation4">❹</span>. The distance from a point to itself is zero <span class="CodeAnnotation" aria-label="annotation5">❺</span>, and the <span role="doc-pagebreak" epub:type="pagebreak" id="pg_434" aria-label="434"/>distance from a point to another, if connected, is the edge’s length <span class="CodeAnnotation" aria-label="annotation6">❻</span>. The <span class="SANS_TheSansMonoCd_W5Regular_11">distance</span> array now has all distances with no intermediate points as described previously. The three nested loops systematically apply the dynamic programming calculation described earlier <span class="CodeAnnotation" aria-label="annotation7">❼</span>, and if you find a better (smaller) distance <span class="CodeAnnotation" aria-label="annotation8">❽</span>, update the table. In this case, you’re keeping only the last table; the values for the <i>k</i>th iteration replace those of the previous one, because you won’t need them any more. The final result <span class="CodeAnnotation" aria-label="annotation9">❾</span> is the table of distances between all pairs of points, as described.</p>&#13;
<p class="TX">What’s the runtime order of this algorithm? The three nested loops, each <i>O</i>(<i>v</i>), provide the answer: <i>O</i>(<i>v</i><sup>3</sup>). This is steep, as mentioned, but it produces all distances among all pairs. For just the distance from one node to all the others, or even more specifically from one given node to another, you’ll see better algorithms.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec8">&#13;
&#13;
<h4 class="H2" id="sec8"><span id="h2-179"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Bellman-Ford Algorithm</span></h4>&#13;
<p class="TNI1">Now consider a different problem: find the distance from a given node to all the others. The idea of the <i>Bellman-Ford algorithm</i> is to see whether you can find a better path between two nodes by following a given edge, and repeat this process until no more alternatives are possible. Start by considering paths that are one edge long, and then check whether a shorter path is available when using two edges, then three edges, then four, and so on. If a graph has <i>n</i> nodes, the longest path can have <i>n</i> – 1 edges, so that’s a limit for iterating.</p>&#13;
<p class="TX">Let’s work with the same graph and calculate minimum distances from F to all the other nodes. (The algorithm works equally well with directed graphs, but you’re using an undirected one for simplicity.) The initial situation is shown in <a href="chapter17.xhtml#fig17-10">Figure 17-10</a>. Without processing any edges (not taking any routes), only F can (trivially!) be reached from F, and you cannot reach other nodes.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-10" src="../images/Figure17-10.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-10: Apply the Bellman-Ford algorithm to find the minimum distances from F to all other points.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_435" aria-label="435"/>Assume that nodes are processed in alphabetical order. When you process the edges from A, B, or C, you cannot calculate distances because you don’t know how to reach those nodes. When you process the (F,D) edge, you are now able to reach node D, and you have the first step in the paths, as shown in <a href="chapter17.xhtml#fig17-11">Figure 17-11</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-11" src="../images/Figure17-11.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-11: Processing nodes in order, the first other node you can reach from F is D.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">You now know that you can reach D with a cost of 3. Now process the next edge, (F,G), and you can reach another node, as shown in <a href="chapter17.xhtml#fig17-12">Figure 17-12</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-12" src="../images/Figure17-12.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-12: The other node you can reach from F is G; you’ll reprocess D at a later iteration.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">You can then process the edges out of G, because now you know that you can reach G. Processing edges (G,C) and (G,E) marks two other nodes as reachable. (Don’t forget: any paths or distances you find may change later if better alternatives appear.) <a href="chapter17.xhtml#fig17-13">Figure 17-13</a> shows the new situation.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_436" aria-label="436"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-13" src="../images/Figure17-13.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-13: When processing G, which was reached from F, you can reach C and E as well.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The first pass is done. So far, you know you can reach five of the seven nodes, and you have possible (but maybe not optimal) paths for each.</p>&#13;
<p class="TX">Now start a new pass. You still can’t do anything with edges out of A or B, because you still haven’t gotten to those nodes, but you can process edge (C,B) and add a new path, as shown in <a href="chapter17.xhtml#fig17-14">Figure 17-14</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-14" src="../images/Figure17-14.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-14: A second iteration now finds that B is reachable from the previously reached C.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The (C,E) and (C,G) edges don’t represent shorter distances, so you do nothing. (For example, you can go from F to E at a cost of 23; going through C would cost 26, so it’s no good.) When considering the (D,A) and (D,E) edges, things get interesting. You can now reach A, and you find a better path to E through D (see <a href="chapter17.xhtml#fig17-15">Figure 17-15</a>).</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_437" aria-label="437"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-15" src="../images/Figure17-15.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-15: A second look at D finds a shorter path to E. The previous way was from F to G to E, which was longer than from F to D to E.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The previous best path from F to E was through G, at a cost of 23, but now you find you can go through D at a cost of 10. No more changes are possible, so start a third pass. One further enhancement is that it’s a shorter route to B by going through A than through E (see <a href="chapter17.xhtml#fig17-16">Figure 17-16</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-16" src="../images/Figure17-16.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-16: A third pass finds a better way from A to B, but no further changes.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The third pass doesn’t add any more changes, and further passes won’t either, so you’re done. You know the shortest paths from the starting point F to all other points, and you know what edges to follow to achieve that cost.</p>&#13;
<p class="TX">You can code this algorithm as follows:</p>&#13;
<pre id="pre-345"><code>const distances = (graph, from) =&gt; {&#13;
  const n = graph.length;&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> const previous = Array(n).fill(null);&#13;
<span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> const distance = Array(n).fill(+Infinity);&#13;
<span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> distance[from] = 0;&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> const edges = [];&#13;
  for (let i = 0; i &lt; n; i++) {&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_438" aria-label="438"/>    for (let j = 0; j &lt; n; j++) {&#13;
      if (graph[i][j]) {&#13;
        edges.push({from: i, to: j, dist: graph[i][j]});&#13;
      }&#13;
    }&#13;
  }&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> for (let i = 0; i &lt; n - 1; i++) {&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation6">❻</span> edges.forEach((v) =&gt; {&#13;
      const w = v.dist;&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation7">❼</span> if (distance[v.from] + w &lt; distance[v.to]) {&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation8">❽</span> distance[v.to] = distance[v.from] + w;&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation9">❾</span> previous[v.to] = v.from;&#13;
      }&#13;
    });&#13;
  }&#13;
&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation10">❿</span> return [distance, previous];&#13;
};</code></pre>&#13;
<p class="TX">Use a <span class="SANS_TheSansMonoCd_W5Regular_11">previous</span> array <span class="CodeAnnotation" aria-label="annotation1">❶</span> to learn from which node you arrived at the corresponding node; if <span class="SANS_TheSansMonoCd_W5Regular_11">previous[j]</span> is <span class="SANS_TheSansMonoCd_W5Regular_11">i</span>, the shortest path from the start to <span class="SANS_TheSansMonoCd_W5Regular_11">j</span> passed through <span class="SANS_TheSansMonoCd_W5Regular_11">i</span> right before going to <span class="SANS_TheSansMonoCd_W5Regular_11">j</span>. The <span class="SANS_TheSansMonoCd_W5Regular_11">distance</span> array <span class="CodeAnnotation" aria-label="annotation2">❷</span> keeps track of the distances from the start to every node; initialize all distances to +infinity, except the distance from the start to itself <span class="CodeAnnotation" aria-label="annotation3">❸</span>, which is obviously zero. In order to process all edges without having to go through the whole matrix, create an <span class="SANS_TheSansMonoCd_W5Regular_11">edges</span> array <span class="CodeAnnotation" aria-label="annotation4">❹</span>; iterating with this array will be faster. Now iterate <span class="SANS_TheSansMonoCd_W5Regular_11">n</span> – 1 times <span class="CodeAnnotation" aria-label="annotation5">❺</span>: for each edge <span class="CodeAnnotation" aria-label="annotation6">❻</span>, see whether using it provides a shorter way between its two endpoints <span class="CodeAnnotation" aria-label="annotation7">❼</span>; if so, update the distance to the second node <span class="CodeAnnotation" aria-label="annotation8">❽</span> and record from which node you came <span class="CodeAnnotation" aria-label="annotation9">❾</span>. (Can you do better with fewer passes? See question 17.2.) The results of this algorithm are an array with distances and an array showing indirectly how to reach the start <span class="CodeAnnotation" aria-label="annotation10">❿</span> from any node.</p>&#13;
<p class="TX">What’s the order of this algorithm? Given that the loop runs <i>O</i>(<i>v</i>) times and each time it goes through all edges, the result is <i>O</i>(<i>ve</i>). This is better than Floyd-Warshall’s algorithm, but it finds all distances from a single origin to all the rest. You can do even better, as you’ll see in a final algorithm for that problem.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec9">&#13;
&#13;
<h4 class="H2" id="sec9"><span id="h2-180"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Dijkstra’s Algorithm</span></h4>&#13;
<p class="TNI1">If you want to find the shortest path from one point to all others (or to a specific point in particular), Dijkstra’s algorithm is quite efficient. It proceeds by starting at the first point (considered to be <i>visited</i>, at distance zero from itself), which becomes the initial <i>current</i> point. All other points are considered to be <i>unvisited</i> and at distance +infinity. From then on, it does the following:</p>&#13;
<p class="ListNumberF">	1.	Studies all as yet unvisited neighbors of the current node, and if there’s a shorter path to the neighbor, it chooses that path and updates the distance to the unvisited node.</p>&#13;
<p class="ListNumber"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_439" aria-label="439"/>	2.	After having processed all the unvisited neighbors of the current node, mark that node as visited, and you’re done with it.</p>&#13;
<p class="ListNumber">	3.	If any unvisited points remain, choose the one with the shortest distance, make it the current node, and repeat the process.</p>&#13;
<p class="ListNumberL">	4.	The algorithm ends when no unvisited points remain (if you want the distances from the origin to all other points) or when the destination point has been marked as visited (if you just want that particular distance).</p>&#13;
<p class="TX">Consider an example and then the implementation. For simplicity, you’ll work with the same undirected graph as before, but Dijkstra’s algorithm works equally well with directed graphs. <a href="chapter17.xhtml#fig17-17">Figure 17-17</a> shows the initial configuration, with the origin point marked as visited.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-17" src="../images/Figure17-17.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-17: The initial setup for Dijkstra’s algorithm: the distance from A to itself is zero, and distances from A to other nodes are set to +infinity.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Considering adjacencies from the current point (A), you know you can reach B, D, and E (see <a href="chapter17.xhtml#fig17-18">Figure 17-18</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-18" src="../images/Figure17-18.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-18: Considering the edges from A to its neighbors, you can tentatively update the distances to B, D, and E.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_440" aria-label="440"/>You’ve updated the distances to those three nodes, but they’re strictly tentative at this point, as you may find better paths later—and you will, as there’s a shorter way from A to E, for example.</p>&#13;
<p class="TX">The next step marks B as the current point, because it’s the closest unvisited one (see <a href="chapter17.xhtml#fig17-19">Figure 17-19</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-19" src="../images/Figure17-19.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-19: Repeat the procedure starting from B, the closest unvisited node, and find better distances to C and E.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">You found a way to C with a distance of 13, because B was at a distance of 4, and the (B,C) edge costs 9. You also found a shorter way to E, so update those distances. Point B now is marked as visited, and you turn to D as the new current node (see <a href="chapter17.xhtml#fig17-20">Figure 17-20</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-20" src="../images/Figure17-20.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-20: You now start from D, the next closest but not yet visited node, and find better distances to F and G.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Working from D allows you to update the distances and paths to F and G. The distance to E wasn’t modified, because going through D would have required a distance of 12, and you already found a shorter path. Now, F becomes the current node, and the process will go quickly, because it allows only one path out, as shown in <a href="chapter17.xhtml#fig17-21">Figure 17-21</a>.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_441" aria-label="441"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-21" src="../images/Figure17-21.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-21: Processing F finds a better way to G.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">You’ve updated the best (as of yet) path to G, which now is 21, going from A to D to F first. You’re close to finishing, and E is the next node to process (see <a href="chapter17.xhtml#fig17-22">Figure 17-22</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-22" src="../images/Figure17-22.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-22: E is processed next and allows you to update distances to C and G.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Going through E makes the distances to C and G shorter, so update them. The next steps choose C and then G, and you don’t need any further changes. <a href="chapter17.xhtml#fig17-23">Figure 17-23</a> shows the final result with the selected paths and calculated distances from A.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_442" aria-label="442"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-23" src="../images/Figure17-23.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-23: When you’re done with all nodes, you get optimum distances from A to all other nodes.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">To achieve good performance, it’s important to be able to determine the next node (the one with shortest distance) to process quickly. A straightforward loop would be an <i>O</i>(<i>v</i>) algorithm, but you’ve already seen an appropriate structure for that: a heap. Using that structure allows you to find the next node to process in <i>O</i>(1) time, and updating the heap is then <i>O</i>(log <i>v</i>), which is better.</p>&#13;
<p class="TX">The main algorithm is as follows, but you’ll look at a portion of it related to the heap later:</p>&#13;
<pre id="pre-346"><code>const distance = (graph, from) =&gt; {&#13;
  const n = graph.length;&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> const points = [];&#13;
  for (let i = 0; i &lt; n; i++) {&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> points[i] = {&#13;
      i,&#13;
      done: false,&#13;
      dist: i === from ? 0 : +Infinity,&#13;
      prev: null,&#13;
      index: -1&#13;
    };&#13;
  }&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> const heap = [from];&#13;
  for (let i = 0; i &lt; n; i++) {&#13;
    if (i !== from) {&#13;
      heap.push(i);&#13;
    }&#13;
  }&#13;
<span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> heap.forEach((v, i) =&gt; (points[v].index = i));&#13;
&#13;
  // heap functions, omitted for now&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> while (heap.length) {&#13;
    const closest = heap[0];&#13;
    points[closest].done = true;&#13;
    const dist = points[closest].dist;&#13;
&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_443" aria-label="443"/>  <span class="Code_CodeAnnotation" aria-label="annotation6">❻</span> swap(0, heap.length – 1);&#13;
    heap.pop();&#13;
    sinkDown(0);&#13;
&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation7">❼</span> graph[closest].forEach((v, next) =&gt; {&#13;
      if (v &gt; 0 &amp;&amp; !points[next].done) {&#13;
        const newDist = dist + graph[closest][next];&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation8">❽</span> if (newDist &lt; points[next].dist) {&#13;
          points[next].dist = newDist;&#13;
          points[next].prev = closest;&#13;
          bubbleUp(points[next].index);&#13;
        }&#13;
      }&#13;
    });&#13;
  }&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation9">❾</span> return points;&#13;
};</code></pre>&#13;
<p class="TX">The <span class="SANS_TheSansMonoCd_W5Regular_11">points</span> array <span class="CodeAnnotation" aria-label="annotation1">❶</span> contains the distances from the starting point (<span class="SANS_TheSansMonoCd_W5Regular_11">from</span>) to all others. The <span class="SANS_TheSansMonoCd_W5Regular_11">i</span> attribute identifies the point; <span class="SANS_TheSansMonoCd_W5Regular_11">done</span> marks whether you’ve finished processing it; <span class="SANS_TheSansMonoCd_W5Regular_11">dist</span> is the distance, initialized to +infinity for all points except the initial; and <span class="SANS_TheSansMonoCd_W5Regular_11">prev</span> shows from which point you arrived at the current one <span class="CodeAnnotation" aria-label="annotation2">❷</span>. The <span class="SANS_TheSansMonoCd_W5Regular_11">index</span> attribute requires explanation. As mentioned, you’ll be keeping the distances in a heap and updating them, which may cause them to bubble up. However, you need to know where each point is in the heap, and that’s what the <span class="SANS_TheSansMonoCd_W5Regular_11">index</span> indicates. This way, whenever you update the distance for a point <span class="SANS_TheSansMonoCd_W5Regular_11">p</span> you know that <span class="SANS_TheSansMonoCd_W5Regular_11">points[p].index</span> is the corresponding place in the heap.</p>&#13;
<p class="TX">Push every point in the heap starting with <span class="SANS_TheSansMonoCd_W5Regular_11">from</span> <span class="CodeAnnotation" aria-label="annotation3">❸</span> and update all the index values <span class="CodeAnnotation" aria-label="annotation4">❹</span>. (Because there’s a single zero distance in the <span class="SANS_TheSansMonoCd_W5Regular_11">points</span> array and all others are +infinity, you’ve created a heap without needing any comparisons.) While the heap isn’t empty <span class="CodeAnnotation" aria-label="annotation5">❺</span>, you remove the top point <span class="CodeAnnotation" aria-label="annotation6">❻</span> and mark it as done and proceed to update the distances to all the nodes that it can reach <span class="CodeAnnotation" aria-label="annotation7">❼</span>. If a distance gets updated with a lower value <span class="CodeAnnotation" aria-label="annotation8">❽</span>, check whether it should bubble up in the heap. The final result <span class="CodeAnnotation" aria-label="annotation9">❾</span> is the updated <span class="SANS_TheSansMonoCd_W5Regular_11">points</span> array with distances from the initial node to all others.</p>&#13;
<p class="TX">Now consider the heap code, directly based on what we saw in <span class="Xref"><a href="chapter14.xhtml">Chapter 14</a></span>:</p>&#13;
<pre id="pre-347"><code><span class="codeannotated_CodeAnnotation" aria-label="annotation1">❶</span> const swap = (i, j) =&gt; {&#13;
    [heap[i], heap[j]] = [heap[j], heap[i]];&#13;
    points[heap[i]].index = i;&#13;
    points[heap[j]].index = j;&#13;
  };&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> const sinkDown = (i) =&gt; {&#13;
    const l = 2 * i + 1;&#13;
    const r = l + 1;&#13;
    let g = i;&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> if (l &lt; heap.length &amp;&amp; points[heap[l]].dist &lt; points[heap[g]].dist) {&#13;
      g = l;&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_444" aria-label="444"/>    }&#13;
    if (r &lt; heap.length &amp;&amp; points[heap[r]].dist &lt; points[heap[g]].dist) {&#13;
      g = r;&#13;
    }&#13;
    if (g !== i) {&#13;
      swap(g, i);&#13;
      sinkDown(g);&#13;
    }&#13;
  };&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> const bubbleUp = (i) =&gt; {&#13;
    if (i &gt; 0) {&#13;
      const p = Math.floor((i - 1) / 2);&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> if (points[heap[i]].dist &lt; points[heap[p]].dist) {&#13;
        swap(p, i);&#13;
        bubbleUp(p);&#13;
      }&#13;
    }&#13;
  };</code></pre>&#13;
<p class="TX">The <span class="SANS_TheSansMonoCd_W5Regular_11">swap(...)</span> function just exchanges two values in the heap <span class="CodeAnnotation" aria-label="annotation1">❶</span> and also updates the corresponding <span class="SANS_TheSansMonoCd_W5Regular_11">index</span> attributes in the <span class="SANS_TheSansMonoCd_W5Regular_11">points</span> array, so you can keep track of where each node is in the heap. The <span class="SANS_TheSansMonoCd_W5Regular_11">sinkDown(...)</span> function <span class="CodeAnnotation" aria-label="annotation2">❷</span> works as you saw in <span class="Xref"><a href="chapter14.xhtml">Chapter 14</a></span>. Notice that you don’t compare the heap values <span class="CodeAnnotation" aria-label="annotation3">❸</span>, but rather compare the distances from the <span class="SANS_TheSansMonoCd_W5Regular_11">points</span> array using the heap values as indices. (In the sorting code in <span class="Xref"><a href="chapter14.xhtml">Chapter 14</a></span>, we directly compared the heap values.) The same change applies in the <span class="SANS_TheSansMonoCd_W5Regular_11">bubbleUp(...)</span> function <span class="CodeAnnotation" aria-label="annotation4">❹</span>&#13;
<span class="CodeAnnotation" aria-label="annotation5">❺</span>.</p>&#13;
<p class="TX">What’s the performance of this algorithm? As is, each point is processed once, and for each point you check whether you need to update the distances to all the others, so it’s <i>O</i>(<i>v</i><sup>2</sup>). You can enhance it by having a list of adjacent points, as with the adjacency list representation for graphs, and then the performance becomes <i>O</i>(<i>v</i> <span class="Emphasis">l</span>og <i>v</i>) because of the heap usage.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec10">&#13;
&#13;
<h3 class="H1" id="sec10"><span id="h1-93"/><span class="SANS_Futura_Std_Bold_B_11">Sorting a Graph</span></h3>&#13;
<p class="TNI1">At the beginning of this chapter we mentioned some real-life applications of graphs, like tracking dependencies in code (modules that import from other modules) or project management (showing tasks that rely on the completion of other tasks). In that situation, we may want to find whether a certain ordering of nodes will make everything work out smoothly. Conversely, we may want to check whether code has circular dependencies or whether completing a given task will be impossible. We want to be able detect such issues with graphs.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_445" aria-label="445"/>This type of task is called <i>topological sorting</i>, and it implies that given a graph, we sort its nodes in order so that all links “go forward” and there’s never a link from a vertex to a previous node. We’ll consider two algorithms for such a sort: Kahn’s algorithm, which is based on a simple procedure involving counting, and Tarjan’s algorithm, which applies depth-first searching to produce the order we want in a backward fashion where the last vertices are output first.</p>&#13;
<section epub:type="division" aria-labelledby="sec11">&#13;
&#13;
<h4 class="H2" id="sec11"><span id="h2-181"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Kahn’s Algorithm</span></h4>&#13;
<p class="TNI1">Consider a basic argument: if a graph has topological ordering, there must be at least one node with no incoming edges, and <i>Kahn’s algorithm</i> is based on that. (This is similar to saying that in any set of numbers, there must be one that is less than the rest.) You can select each of these nodes with no problems. If you then discard all the edges that start from those nodes, you should be left with nodes that have no incoming edges, and you can repeat the procedure. If at some point you’ve still got nodes to consider but all have at least one incoming edge, no topological sort is possible.</p>&#13;
<p class="TX"><a href="chapter17.xhtml#fig17-24">Figure 17-24</a> illustrates the procedure with the same directed graph we’ve been using for all the examples in this chapter. After first doing a count of incoming edges, the numbers in the nodes are the calculated counts.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-24" src="../images/Figure17-24.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-24: A graph is set up for topological sorting where the numbers show how many incoming edges are there at each point.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Given that you found at least one node with zero incoming edges, you can proceed. Points E and F can be output in any order, and you then reduce the counts of the nodes that you can reach from those two points (see <a href="chapter17.xhtml#fig17-25">Figure 17-25</a>).</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_446" aria-label="446"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-25" src="../images/Figure17-25.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-25: Points E and F can be output because they had no incoming edges, and you “forget” the outgoing edges from those two points.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Points E and F were output, which are in positions 0 and 1 of the output array. (The nodes in black show index values.) Again, you find at least one node with no incoming edges, so B is at position 2 of the output array, and you decrease the counts of nodes A and C (see <a href="chapter17.xhtml#fig17-26">Figure 17-26</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-26" src="../images/Figure17-26.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-26: Point B now has no predecessors, so its output and edges are removed.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Now repeat the process: points A and C are output, reduce the counts, and you get to the situation shown in <a href="chapter17.xhtml#fig17-27">Figure 17-27</a>.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_447" aria-label="447"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-27" src="../images/Figure17-27.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-27: Point A is next, then D, and G will be last.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The last two steps output D first and then G. <a href="chapter17.xhtml#fig17-28">Figure 17-28</a> shows the final status, and the topological order you want is E, F, B, A, C, D, and G.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-28" src="../images/Figure17-28.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-28: The final result, where the numbers show in which order the points were output.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">You can code the algorithm as follows:</p>&#13;
<pre id="pre-348"><code>const topologicalSort = (graph) =&gt; {&#13;
  const n = graph.length;&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> const queue = [];&#13;
<span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> const sorted = [];&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> const incoming = Array(n).fill(0);&#13;
  for (let i = 0; i &lt; n; i++) {&#13;
    for (let j = 0; j &lt; n; j++) {&#13;
      if (graph[i][j]) {&#13;
        incoming[j]++;&#13;
      }&#13;
    }&#13;
  }&#13;
&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_448" aria-label="448"/><span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> incoming.forEach((v, i) =&gt; {&#13;
    if (v === 0) {&#13;
      queue.push(i);&#13;
    }&#13;
  });&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> while (queue.length &gt; 0) {&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation6">❻</span> const i = queue.shift();&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation7">❼</span> sorted.push(i);&#13;
&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation8">❽</span> graph[i].forEach((v, j) =&gt; {&#13;
      if (v) {&#13;
        incoming[j]--;&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation9">❾</span> if (incoming[j] === 0) {&#13;
          queue.push(j);&#13;
        }&#13;
      }&#13;
    });&#13;
  }&#13;
&#13;
 <span class="Code_CodeAnnotation" aria-label="annotation10">❿</span> return sorted.length === n ? sorted : null;&#13;
};</code></pre>&#13;
<p class="TX">Put nodes to be processed in a <span class="SANS_TheSansMonoCd_W5Regular_11">queue</span> <span class="CodeAnnotation" aria-label="annotation1">❶</span>, and from there place them in the output <span class="SANS_TheSansMonoCd_W5Regular_11">sorted</span> array <span class="CodeAnnotation" aria-label="annotation2">❷</span>. The <span class="SANS_TheSansMonoCd_W5Regular_11">incoming</span> array will count the number of incoming edges for every node <span class="CodeAnnotation" aria-label="annotation3">❸</span>, adding 1 for every such edge. Every node with no incoming edges is pushed into the queue for processing <span class="CodeAnnotation" aria-label="annotation4">❹</span>, and then you can start the sort itself. While there still are nodes to process <span class="CodeAnnotation" aria-label="annotation5">❺</span>, you remove them from the queue <span class="CodeAnnotation" aria-label="annotation6">❻</span> and push them into the output list <span class="CodeAnnotation" aria-label="annotation7">❼</span>. For every node you output <span class="CodeAnnotation" aria-label="annotation8">❽</span>, discard its connections to other nodes, decreasing the incoming counts <span class="CodeAnnotation" aria-label="annotation9">❾</span>. When there are no more nodes to process, if all were sorted, you succeeded <span class="CodeAnnotation" aria-label="annotation10">❿</span>; otherwise, you failed. The remaining nodes have at least one incoming edge, which means no topological sort is possible.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec12">&#13;
&#13;
<h4 class="H2" id="sec12"><span id="h2-182"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Tarjan’s Algorithm</span></h4>&#13;
<p class="TNI1">We’ll apply a depth-first search algorithm for another way to produce a topological sort. The idea is to start <i>traveling</i> from a node, marking the way at each node you pass (Hansel and Gretel style) and seeing how far you can get before arriving at a dead end or returning to a node that you already marked, which means you found a cycle and no topological sort is possible. You can mark the nodes from which no more movement is possible as <i>done</i> and output them and then ignore them from then on. In this fashion, you’ll produce the topological sort in reverse order: you’ll output the last nodes in the sort first, and the first nodes will be last.</p>&#13;
<p class="TX"><a href="chapter17.xhtml#fig17-29">Figure 17-29</a> shows an example with the same graph we’ve used throughout the chapter. Start at point A, mark it as <i>in progress</i> (in gray), and consider all the edges out of it. There’s only one. If in future steps you get back to node A and it’s gray, you’ll have found a cycle.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_449" aria-label="449"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-29" src="../images/Figure17-29.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-29: The same graph as in the previous section set up for Tarjan’s algorithm. You started at A and reached D; A is grayed out.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">You’re now at point D, which hasn’t been visited. Mark it gray as well and check which nodes you can reach from it. In this case, you can reach only G (see <a href="chapter17.xhtml#fig17-30">Figure 17-30</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-30" src="../images/Figure17-30.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-30: After D, you reach G; D is grayed out.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Repeat the process at G, and no edges come out of it, so mark it as <i>done</i> and output it. The sorted list starts as shown in <a href="chapter17.xhtml#fig17-31">Figure 17-31</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-31" src="../images/Figure17-31.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-31: From G you can’t reach any other point, so output G to the sorted list.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_450" aria-label="450"/>Having dealt with G, you can mark D as <i>done</i> (and output it) and then do the same with A (see <a href="chapter17.xhtml#fig17-32">Figure 17-32</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-32" src="../images/Figure17-32.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-32: D has no further connections to other nodes, so it may be output, and then A is output too.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">When you’re done with A, start from B. The link from B to A goes to a node marked <i>done</i>, so you ignore it. The link from B to C needs processing, though: B is marked <i>in progress</i>, and you go to C (see <a href="chapter17.xhtml#fig17-33">Figure 17-33</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-33" src="../images/Figure17-33.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-33: Starting at B, you can reach only one point that has not yet been output: C.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Mark C as <i>in progress</i>, but its only edge goes to a node marked <i>done</i> (G), so mark C as <i>done</i> and add it to the output. After that, you’re done with B as well, which also is output (see <a href="chapter17.xhtml#fig17-34">Figure 17-34</a>).</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_451" aria-label="451"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-34" src="../images/Figure17-34.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-34: C is linked only to an already output point, so you can output C and, after that, output B.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The final steps are similar. From E all the links lead to nodes marked as <i>done</i>, so E becomes marked as <i>done</i> and is output; the same happens to F, and you’re finished, having visited all nodes and produced a topological sort, as shown in <a href="chapter17.xhtml#fig17-35">Figure 17-35</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-35" src="../images/Figure17-35.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-35: When all points have been output, the algorithm ends.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The code for this algorithm follows. The <i>in-progress</i> nodes are marked with a 1 (a temporary mark) and the <i>done</i> nodes are marked with a 2 (a final mark):</p>&#13;
<pre id="pre-349"><code>const topologicalSort = (graph) =&gt; {&#13;
   const n = graph.length;&#13;
<span class="Code_CodeAnnotation1" aria-label="annotation1">❶</span> const marks = Array(n).fill(0); // 1:temp, 2:final&#13;
<span class="Code_CodeAnnotation1" aria-label="annotation2">❷</span> const sorted = [];&#13;
&#13;
<span class="Code_CodeAnnotation1" aria-label="annotation3">❸</span> const visit = (p) =&gt; {&#13;
  <span class="Code_CodeAnnotation1" aria-label="annotation4">❹</span> if (marks[p] === 1) {&#13;
      throw new Error("Not a DAG");&#13;
  <span class="Code_CodeAnnotation1" aria-label="annotation5">❺</span>} else if (marks[p] === 0) {&#13;
      marks[p] = 1;&#13;
    <span class="Code_CodeAnnotation1" aria-label="annotation6">❻</span> graph[p].forEach((v, q) =&gt; {&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_452" aria-label="452"/>      <span class="Code_CodeAnnotation1" aria-label="annotation7">❼</span> if (v &amp;&amp; marks[q] !== 2) {&#13;
          visit(q);&#13;
        }&#13;
      });&#13;
&#13;
    <span class="Code_CodeAnnotation1" aria-label="annotation8">❽</span> marks[p] = 2;&#13;
    <span class="Code_CodeAnnotation1" aria-label="annotation9">❾</span> sorted.unshift(p);&#13;
    }&#13;
  };&#13;
&#13;
  try {&#13;
  <span class="Code_CodeAnnotation1" aria-label="annotation10">❿</span> marks.forEach((v, i) =&gt; {&#13;
      visit(i);&#13;
    });&#13;
    return sorted;&#13;
  } catch (e) {&#13;
    return null;&#13;
  }&#13;
};</code></pre>&#13;
<p class="TX">The <span class="SANS_TheSansMonoCd_W5Regular_11">marks</span> array <span class="CodeAnnotation" aria-label="annotation1">❶</span> keeps track of visited and unvisited nodes. A <span class="SANS_TheSansMonoCd_W5Regular_11">0</span> means the node hasn’t been visited yet. A <span class="SANS_TheSansMonoCd_W5Regular_11">1</span> means it was visited and you’re going through all its reachable nodes, and a <span class="SANS_TheSansMonoCd_W5Regular_11">2</span> means that the node has been dealt with and output already. The <span class="SANS_TheSansMonoCd_W5Regular_11">sorted</span> array <span class="CodeAnnotation" aria-label="annotation2">❷</span> gets the output of the algorithm. You define a recursive function <span class="CodeAnnotation" aria-label="annotation3">❸</span> to visit all nodes that a <span class="SANS_TheSansMonoCd_W5Regular_11">p</span> starting node can reach. If the node was marked with a <span class="SANS_TheSansMonoCd_W5Regular_11">1</span> <span class="CodeAnnotation" aria-label="annotation4">❹</span>, it means that, when starting from there, you eventually returned to it. In other words, there’s a cycle, so no topological sort is possible. If the node is marked with a <span class="SANS_TheSansMonoCd_W5Regular_11">0</span> <span class="CodeAnnotation" aria-label="annotation5">❺</span>, temporarily mark it with a <span class="SANS_TheSansMonoCd_W5Regular_11">1</span> and visit all the unvisited nodes that are reachable from it <span class="CodeAnnotation" aria-label="annotation6">❻</span>; skip visiting any nodes marked with <span class="SANS_TheSansMonoCd_W5Regular_11">2</span> <span class="CodeAnnotation" aria-label="annotation7">❼</span> because those were already analyzed. After all the visiting is finished, change the <span class="SANS_TheSansMonoCd_W5Regular_11">1</span> to <span class="SANS_TheSansMonoCd_W5Regular_11">2</span> <span class="CodeAnnotation" aria-label="annotation8">❽</span> and output the current node <span class="SANS_TheSansMonoCd_W5Regular_11">p</span> <span class="CodeAnnotation" aria-label="annotation9">❾</span>; use <span class="SANS_TheSansMonoCd_W5Regular_11">unshift()</span> to get the right order. To produce the topological sort <span class="CodeAnnotation" aria-label="annotation10">❿</span>, all you have to do is start from every possible node and apply the visiting logic.</p>&#13;
<p class="TX">What’s the performance of this algorithm? Each node is visited once, and all its links are processed, but for each node, it checks the whole row for possible links to traverse, making this implementation <i>O</i>(<i>v</i><sup>2</sup>). The algorithm would benefit from an adjacency list representation, because then you would be able to process the edges from a node directly, producing <i>O</i>(<i>ve</i>).</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec13">&#13;
&#13;
<h3 class="H1" id="sec13"><span id="h1-94"/><span class="SANS_Futura_Std_Bold_B_11">Detecting Cycles</span></h3>&#13;
<p class="TNI1">Another question to consider is whether a graph includes any cycles. (In other words, is the graph a tree or a forest or not?) For example, when programming, if there’s a cycle in a list of dependencies among modules, something is seriously wrong! A cycle-detection algorithm just needs to check whether it can find at least one cycle in a given graph.</p>&#13;
<p class="TX">Fortunately, we’ve already seen an algorithm that does this type of detection: Tarjan’s topological sort includes the logic to detect when a cycle <span role="doc-pagebreak" epub:type="pagebreak" id="pg_453" aria-label="453"/>is found, so we’ve already got what we need. The following code is directly extracted from that algorithm:</p>&#13;
<pre id="pre-350"><code>const hasCycle = (graph) =&gt; {&#13;
  const n = graph.length;&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> const marks = Array(n).fill(0); // 1:temp, 2:final&#13;
&#13;
  const visit = (p) =&gt; {&#13;
    if (marks[p] === 1) {&#13;
      throw new Error("cycle found");&#13;
    } else if (marks[p] === 0) {&#13;
      marks[p] = 1;&#13;
      graph[p].forEach((v, q) =&gt; {&#13;
        if (v &amp;&amp; marks[q] !== 2) {&#13;
          visit(q);&#13;
        }&#13;
      });&#13;
&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> marks[p] = 2;&#13;
    }&#13;
  };&#13;
&#13;
  try {&#13;
    marks.forEach((v, i) =&gt; {&#13;
      visit(i);&#13;
    });&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> return false; // no cycles found&#13;
  } catch (e) {&#13;
    return true;&#13;
  }&#13;
};</code></pre>&#13;
<p class="TX">All the code is the same; the only differences here are that you don’t define a <span class="SANS_TheSansMonoCd_W5Regular_11">sorted</span> array for the output <span class="CodeAnnotation" aria-label="annotation1">❶</span>. You obviously don’t add anything when marking a node as totally visited <span class="CodeAnnotation" aria-label="annotation2">❷</span>, and you return a boolean value instead of an array or null <span class="CodeAnnotation" aria-label="annotation3">❸</span>.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec14">&#13;
&#13;
<h3 class="H1" id="sec14"><span id="h1-95"/><span class="SANS_Futura_Std_Bold_B_11">Detecting Connectivity</span></h3>&#13;
<p class="TNI1">Now consider a different problem: How can you determine whether a given graph is fully connected? An undirected graph is connected if there’s a path between every pair of points in the graph; there’s no point you can’t reach from any other point. (A border case is that a graph with only one vertex is also considered to be connected.) If a graph doesn’t satisfy this condition, we can split it into two or more connected subgraphs.</p>&#13;
<p class="TX">Several algorithms can detect whether a given graph is connected; we’ll consider two here. One algorithm introduces another data structure that allows merging sets, and the other uses a recursive traversal of the graph.</p>&#13;
<section epub:type="division" aria-labelledby="sec15">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_454" aria-label="454"/>&#13;
<h4 class="H2" id="sec15"><span id="h2-183"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Detecting Connectivity with</span> <span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Sets</span></h4>&#13;
<p class="TNI1">There’s a rather simple way to find how many connected parts a graph has. Start by forming different sets, each with a single vertex. Then, go through all the edges in the graph, and if an edge links vertices that appear in different sets, join them so that they form a new, larger set. After going through all the edges, if you’re left with a single set, the graph was connected; if you’re left with several sets, the graph was unconnected.</p>&#13;
<p class="TX">The question is how to implement these sets. You need to be able to determine whether any two points are in the same set and be able to join two sets. There’s an efficient way of doing this by working with a forest of trees, as we explored in <span class="Xref"><a href="chapter13.xhtml">Chapter 13</a></span>.</p>&#13;
<p class="TX">Consider how this concept works. Each set is represented by an <i>upward</i> tree with pointers that go up from the leaves to the root (the opposite of what you did in previous chapters). The leaves of the tree are its elements, and intermediate nodes are added as needed. To see whether two values are in the same set, follow the path up to the root from each leaf. If you reach the same root, the values are in the same set. Finally, to join two sets, just add a new root and make the roots of the two sets point to it. <a href="chapter17.xhtml#fig17-36">Figure 17-36</a> shows an initial setup with six values, each in a separate set. Note that all pointers are implied to go up, which is a big difference from previous chapters.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-36" src="../images/Figure17-36.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-36: Start with each node in its individual tree.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">If you want to check whether, say, D and E are in the same set, follow the pointers up, and upon arriving at different roots, you can conclude that they aren’t.</p>&#13;
<p class="TX">To make them part of a single set, just add a new root, and you get the situation shown in <a href="chapter17.xhtml#fig17-37">Figure 17-37</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-37" src="../images/Figure17-37.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-37: Putting D and E in the same set requires adding a new root; now D and E are in the same tree.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">If you now check whether D and E are in the same set, the answer is yes, because following pointers up, you’d arrive at the same root. If you ask whether F and D (or F and E) are in the same set, the answer is no, and joining the sets produces the situation shown in <a href="chapter17.xhtml#fig17-38">Figure 17-38</a>.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_455" aria-label="455"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-38" src="../images/Figure17-38.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-38: Adding F to the previous (D,E) set again adds a new root, and now the three original trees are joined.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">You can handle all of this with simple pointer manipulation and end up with an upside-down forest. Joining A with C and then A with E produces a new configuration (see <a href="chapter17.xhtml#fig17-39">Figure 17-39</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-39" src="../images/Figure17-39.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-39: In this final scheme, you find that (A,C,D,E,F) are a set and (B) is a separate set.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">In <a href="chapter17.xhtml#fig17-39">Figure 17-39</a>, you have only two sets: a singleton (with just B) and another set that contains all the other values.</p>&#13;
<p class="TX">The algorithm is short:</p>&#13;
<pre id="pre-351"><code>const isConnected = (graph) =&gt; {&#13;
  const n = graph.length;&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> const groups = Array(n)&#13;
    .fill(0)&#13;
    .map(() =&gt; ({ptr: null}));&#13;
<span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> let count = n;&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> const findParent = (x) =&gt; (x.ptr !== null ? findParent(x.ptr) : x);&#13;
&#13;
  for (let i = 0; i &lt; n; i++) {&#13;
    for (let j = i + 1; j &lt; n; j++) {&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> if (graph[i][j]) {&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> const pf = findParent(groups[i]);&#13;
        const pt = findParent(groups[j]);&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation6">❻</span> if (pf !== pt) {&#13;
          pf.ptr = pt.ptr = {ptr: null};&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_456" aria-label="456"/>        <span class="Code_CodeAnnotation" aria-label="annotation7">❼</span> count--;&#13;
        }&#13;
      }&#13;
    }&#13;
  }&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation8">❽</span> return count === 1;&#13;
};</code></pre>&#13;
<p class="TX">Start by defining all <span class="SANS_TheSansMonoCd_W5Regular_11">groups</span> with just a single element <span class="CodeAnnotation" aria-label="annotation1">❶</span>, and the <span class="SANS_TheSansMonoCd_W5Regular_11">count</span> variable tracks how many groups exist at any moment <span class="CodeAnnotation" aria-label="annotation2">❷</span>. The <span class="SANS_TheSansMonoCd_W5Regular_11">findParent(...)</span> auxiliary function goes up from each vertex to find the root of its group <span class="CodeAnnotation" aria-label="annotation3">❸</span>. The rest is straightforward: go through all edges <span class="CodeAnnotation" aria-label="annotation4">❹</span> and check whether both endpoints of edges <span class="CodeAnnotation" aria-label="annotation5">❺</span> are in the same group; if not <span class="CodeAnnotation" aria-label="annotation6">❻</span>, join the groups by creating a new, common root for both trees and decrease the group count by one <span class="CodeAnnotation" aria-label="annotation7">❼</span>. After processing all the edges, if you’re left with a single group <span class="CodeAnnotation" aria-label="annotation8">❽</span>, the graph was connected. If you want to know how many subgraphs it has, you could check the <span class="SANS_TheSansMonoCd_W5Regular_11">count</span> instead.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec16">&#13;
&#13;
<h4 class="H2" id="sec16"><span id="h2-184"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Detecting Connectivity with Searches</span></h4>&#13;
<p class="TNI1">The second algorithm we’ll consider is based on starting from any point and applying a systematic, recursive search. Check which points you can reach, and then which points you can reach from those, and so on, until you’ve considered all the edges. Every time you start visiting from a certain point, mark it as <i>visited</i> to avoid trying it again.</p>&#13;
<p class="TX">Given the same graph you’ve been using, shown in <a href="chapter17.xhtml#fig17-40">Figure 17-40</a>, and arbitrarily starting at A, which would be the first node to visit?</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-40" src="../images/Figure17-40.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-40: To check connectivity, start at any point, in this case A, and mark it.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">From A, you reach B, D, and E, and none of them have been visited already. Mark them and start searching from B, as shown in <a href="chapter17.xhtml#fig17-41">Figure 17-41</a>.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_457" aria-label="457"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-41" src="../images/Figure17-41.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-41: From A you can reach unmarked points B, D, and E, which you mark.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">From B, you can reach A or E, but those are already marked as visited, so just add C to your search (see <a href="chapter17.xhtml#fig17-42">Figure 17-42</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-42" src="../images/Figure17-42.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-42: From B you can add the still-unmarked C, and from D you add the unmarked F and G.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">From D, you can reach A, E, F, and G, but A and E are already marked, so just add F and G to the process (see <a href="chapter17.xhtml#fig17-43">Figure 17-43</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-43" src="../images/Figure17-43.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-43: All points have been marked, so the graph is connected.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_458" aria-label="458"/>The rest of the algorithm is quick, because no unmarked nodes remain to be reached from E, C, F, or G (in the order you checked them), so you’re done, and since all vertices ended up marked, the graph was connected. If there had been a separate subgraph, you wouldn’t have been able to reach it, so its nodes would have been left unmarked and the algorithm would have returned false.</p>&#13;
<p class="TX">You can also do the search in depth-first style, which is actually simpler to code:</p>&#13;
<pre id="pre-352"><code>const isConnected = (graph) =&gt; {&#13;
  const n = graph.length;&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> const visited = Array(n).fill(false);&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> const visit = (x) =&gt; {&#13;
&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> graph[x].forEach((v, i) =&gt; {&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> if (v &gt; 0 &amp;&amp; !visited[i]) {&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> visited[i] = true;&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation6">❻</span> visit(i);&#13;
      }&#13;
    });&#13;
  };&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation7">❼</span> visited[0] = true;&#13;
<span class="Code_CodeAnnotation" aria-label="annotation8">❽</span> visit(0);&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation9">❾</span> return visited.every((x) =&gt; x);&#13;
};</code></pre>&#13;
<p class="TX">Start by marking all points as unvisited <span class="CodeAnnotation" aria-label="annotation1">❶</span>. The auxiliary <span class="SANS_TheSansMonoCd_W5Regular_11">visit(...)</span> recursive function <span class="CodeAnnotation" aria-label="annotation2">❷</span> does the search. Given a point, it goes through all of its outgoing edges <span class="CodeAnnotation" aria-label="annotation3">❸</span>. If it finds an unvisited point <span class="CodeAnnotation" aria-label="annotation4">❹</span>, it marks it <span class="CodeAnnotation" aria-label="annotation5">❺</span> and visits it <span class="CodeAnnotation" aria-label="annotation6">❻</span>. To run the algorithm, start by marking any point (the first in this case) as visited <span class="CodeAnnotation" aria-label="annotation7">❼</span>, and call the <span class="SANS_TheSansMonoCd_W5Regular_11">visit</span> function <span class="CodeAnnotation" aria-label="annotation8">❽</span> to do the search. If you finish the algorithm with every point marked as visited <span class="CodeAnnotation" aria-label="annotation9">❾</span>, you’ve succeeded.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec17">&#13;
&#13;
<h3 class="H1" id="sec17"><span id="h1-96"/><span class="SANS_Futura_Std_Bold_B_11">Finding a Minimum Spanning Tree</span></h3>&#13;
<p class="TNI1">This problem applies to weighted undirected graphs. Imagine we want to connect people to the electrical grid or some other similar service and we know the cost of linking a given pair of points together. We don’t need to build <i>all</i> possible connections between points; rather, we want to choose a set that, at minimum cost, allows all the vertices to connect to each other. Several algorithms solve this problem, and we’ll consider the two best known here: <i>Prim’s algorithm</i> and <i>Kruskal’s algorithm</i>. If those algorithms are applied to connected graphs, the output will be a tree linking all of its nodes. If a graph is not connected, we’ll find a forest of trees instead for each independent group of nodes.</p>&#13;
<section epub:type="division" aria-labelledby="sec18">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_459" aria-label="459"/>&#13;
<h4 class="H2" id="sec18"><span id="h2-185"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Prim’s Algorithm</span></h4>&#13;
<p class="TNI1">The description for <i>Prim’s algorithm</i> is simple: to build the tree, start with any node and keep adding the closest node (meaning, minimum link cost) not yet connected to the tree until no more nodes are left. It can be proven that this will produce the desired minimum tree, but we won’t go into that proof here.</p>&#13;
<p class="TX">Start with the same undirected graph we’ve been using (see <a href="chapter17.xhtml#fig17-44">Figure 17-44</a>) and arbitrarily choose A as the starting node.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-44" src="../images/Figure17-44.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-44: Prim’s algorithm starts by choosing any node. In this case, start with A.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Now, all of the points still aren’t selected, so choose the closest one, which is B in this case (see <a href="chapter17.xhtml#fig17-45">Figure 17-45</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-45" src="../images/Figure17-45.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-45: Out of all the points adjacent to A, choose the closest, which is B.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">You’ve got two nodes in the spanning tree. Repeat the selection: the closest point to either A or B not yet selected is D, so add that one (see <a href="chapter17.xhtml#fig17-46">Figure 17-46</a>).</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_460" aria-label="460"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-46" src="../images/Figure17-46.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-46: Out of the points adjacent to A or B, you again choose the closest, which is D.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The upcoming steps are easy to predict: first, add F (which is only three units away from the selected nodes), then E, C, and finally G, for a total cost of 30 units, as shown in <a href="chapter17.xhtml#fig17-47">Figure 17-47</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-47" src="../images/Figure17-47.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-47: After finishing with all nodes, you get a spanning tree.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Coding this is straightforward. In order to know which is the closest remaining unchosen point, you again use a heap. The implementation is a tad different: this time, you’ll have objects in the heap with attributes <span class="SANS_TheSansMonoCd_W5Regular_11">from</span> (a point), <span class="SANS_TheSansMonoCd_W5Regular_11">to</span> (the closest already selected point), and <span class="SANS_TheSansMonoCd_W5Regular_11">dist</span> (the distance to the closest point, which is the length of the edge between those two points). First explore the heap algorithms, which were coded iteratively instead of recursively just for variety:</p>&#13;
<pre id="pre-353"><code>  const bubbleUp = (i) =&gt; {&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> while (i &gt; 0) {&#13;
      const p = Math.floor((i - 1) / 2);&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> if (heap[i].dist &gt; heap[p].dist) {&#13;
        return;&#13;
      }&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> [heap[p], heap[i]] = [heap[i], heap[p]];&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> i = p;&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_461" aria-label="461"/>    }&#13;
  };&#13;
&#13;
  const sinkDown = (i) =&gt; {&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> for (;;) {&#13;
      const l = 2 * i + 1;&#13;
      const r = l + 1;&#13;
      let m = i;&#13;
      if (l &lt; heap.length &amp;&amp; heap[l].dist &lt; heap[m].dist) {&#13;
        m = l;&#13;
      }&#13;
      if (r &lt; heap.length &amp;&amp; heap[r].dist &lt; heap[m].dist) {&#13;
        m = r;&#13;
      }&#13;
      if (m === i) {&#13;
      <span class="Code_CodeAnnotation" aria-label="annotation6">❻</span> return;&#13;
      }&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation7">❼</span> [heap[m], heap[i]] = [heap[i], heap[m]];&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation8">❽</span> i = m;&#13;
    }&#13;
  };</code></pre>&#13;
<p class="TX">When bubbling up a value, check whether you’re not already at the top <span class="CodeAnnotation" aria-label="annotation1">❶</span>. If not, calculate the position of its parent and compare distances; if the parent is lower <span class="CodeAnnotation" aria-label="annotation2">❷</span>, you’re done. If not, exchange heap positions <span class="CodeAnnotation" aria-label="annotation3">❸</span> and repeat the procedure at the parent’s position <span class="CodeAnnotation" aria-label="annotation4">❹</span>. To sink down a value, set up an endless loop <span class="CodeAnnotation" aria-label="annotation5">❺</span> that exits when the value cannot sink any lower <span class="CodeAnnotation" aria-label="annotation6">❻</span> because it’s smaller than its children. If the value has to sink down, do an exchange <span class="CodeAnnotation" aria-label="annotation7">❼</span> and loop again at the child’s position <span class="CodeAnnotation" aria-label="annotation8">❽</span>.</p>&#13;
<p class="TX">The code for Prim’s algorithm is as follows:</p>&#13;
<pre id="pre-354"><code>const spanning = (graph) =&gt; {&#13;
  const n = graph.length;&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> const newGraph = Array(n)&#13;
    .fill(0)&#13;
    .map(() =&gt; Array(n).fill(0));&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> const heap = Array(n)&#13;
    .fill(0)&#13;
    .map((v, i) =&gt; ({from: i, to: i, dist: +Infinity}));&#13;
&#13;
  //<span class="SANS_TheSansMonoCd_W5Regular_Italic_11"> </span>bubbleUp and sinkDown, excluded&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> while (heap.length) {&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> const from = heap[0].from;&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> const to = heap[0].to;&#13;
&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation6">❻</span> newGraph[from][to] = graph[from][to];&#13;
    newGraph[to][from] = graph[to][from];&#13;
&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation7">❼</span> heap[0] = heap[heap.length – 1];&#13;
    heap.pop(); // or the more unconventional heap.length--;&#13;
    sinkDown(0);&#13;
&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_462" aria-label="462"/>  <span class="Code_CodeAnnotation" aria-label="annotation8">❽</span> for (let i = 0; i &lt; heap.length; i++) {&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation9">❾</span> const v = heap[i];&#13;
      const dist = graph[v.from][from];&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation10">❿</span> if (dist &gt; 0 &amp;&amp; dist &lt; v.dist) {&#13;
        v.to = from;&#13;
        v.dist = dist;&#13;
        bubbleUp(i);&#13;
      }&#13;
    }&#13;
  }&#13;
&#13;
  return newGraph;&#13;
};</code></pre>&#13;
<p class="TX">Start by setting up the <span class="SANS_TheSansMonoCd_W5Regular_11">newGraph</span> matrix for the output graph <span class="CodeAnnotation" aria-label="annotation1">❶</span> and the heap with all points in it: the <span class="SANS_TheSansMonoCd_W5Regular_11">from</span> attribute is the point itself, the <span class="SANS_TheSansMonoCd_W5Regular_11">to</span> attribute is the closest already selected point, and the <span class="SANS_TheSansMonoCd_W5Regular_11">dist</span> attribute is the minimum distance from the point to an already selected point of the spanning tree <span class="CodeAnnotation" aria-label="annotation2">❷</span>. While the heap isn’t empty (implying you haven’t yet considered all vertices), consider the top <span class="CodeAnnotation" aria-label="annotation3">❸</span>, which is the closest point to the already chosen ones that hasn’t been chosen itself yet. The path linking points <span class="SANS_TheSansMonoCd_W5Regular_11">from</span> <span class="CodeAnnotation" aria-label="annotation4">❹</span> and <span class="SANS_TheSansMonoCd_W5Regular_11">to</span> <span class="CodeAnnotation" aria-label="annotation5">❺</span> corresponds to the shortest pending distance, so add it to <span class="SANS_TheSansMonoCd_W5Regular_11">newGraph</span> <span class="CodeAnnotation" aria-label="annotation6">❻</span>. Then pop the node from the heap <span class="CodeAnnotation" aria-label="annotation7">❼</span> and proceed to adjust the distances between the <span class="SANS_TheSansMonoCd_W5Regular_11">from</span> point and all the remaining heap points <span class="CodeAnnotation" aria-label="annotation8">❽</span>. Then take each heap element <span class="CodeAnnotation" aria-label="annotation9">❾</span> and consider the distance from it to the <span class="SANS_TheSansMonoCd_W5Regular_11">from</span> point; if there’s a shorter (cheaper) edge <span class="CodeAnnotation" aria-label="annotation10">❿</span>, record the edge that allows this better path and the corresponding distance and make the node bubble up if needed. (So the heap points will always have the shortest distance from them to the already chosen points.) When the heap is empty, you’ll have the spanning tree in the <span class="SANS_TheSansMonoCd_W5Regular_11">newGraph</span> matrix.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec19">&#13;
&#13;
<h4 class="H2" id="sec19"><span id="h2-186"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_11">Kruskal’s Algorithm</span></h4>&#13;
<p class="TNI1"><i>Kruskal’s algorithm</i> also finds the minimum spanning tree for an undirected graph. Instead of adding points one at a time as Prim’s does, this algorithm works by adding edges to an initially empty graph. The idea is to sort the edges in ascending order and attempt to add each edge unless it would cause a cycle. (We won’t give the proof that this algorithm is correct either, but rest assured it can be done.) How do we detect cycles? Initially, you have all the points in separate, disjointed sets, and every time you add an edge linking two nodes, join the corresponding sets (it’s similar to the process in the section “<span class="Xref">Detecting Connectivity with Sets</span>” on <span class="Xref"><a href="chapter17.xhtml#pg_454">page 454</a></span>). Never add an edge whose extremes are both in the same set.</p>&#13;
<p class="TX">Now explore how the algorithm works with the same example graph (see <a href="chapter17.xhtml#fig17-48">Figure 17-48</a>).</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_463" aria-label="463"/>&#13;
<figure class="IMG"><img class="img7" id="fig17-48" src="../images/Figure17-48.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-48: The same graph used for Prim’s algorithm</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Add edges one at the time, starting with the lowest, so the first step adds the (C,E) edge; now points C and E are in the same set, as shown in <a href="chapter17.xhtml#fig17-49">Figure 17-49</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-49" src="../images/Figure17-49.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-49: Add the smallest edge (C,E) to start.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The next two steps add edges (D,F) and (A,B); no cycles occur anywhere, as shown in <a href="chapter17.xhtml#fig17-50">Figure 17-50</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-50" src="../images/Figure17-50.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-50: Keep adding edges, in ascending size, if they do not create cycles. First (D,F) was added and then (A,B).</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_464" aria-label="464"/>The next steps add (A,D), so A, B, D, and F all end up belonging to the same set, and then add (B,E), which makes a big set with all points from A to F (see <a href="chapter17.xhtml#fig17-51">Figure 17-51</a>).</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-51" src="../images/Figure17-51.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-51: Repeating the procedure now adds (A,D).</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Now things get interesting! The next edge in order is (D,E), but D and E already are in the same set, so don’t add that edge. The next step adds (E,G), and you get the final tree, as shown in <a href="chapter17.xhtml#fig17-52">Figure 17-52</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-52" src="../images/Figure17-52.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-52: You should add (D,E), but it would create a cycle, so skip it and add (E,G) instead.</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Future steps won’t add anything, because the edges will always link points that are already in the same set, so you’ve got your spanning tree.</p>&#13;
<p class="TX">Kruskal’s algorithm is as follows:</p>&#13;
<pre id="pre-355"><code>const spanning = (graph) =&gt; {&#13;
  const n = graph.length;&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> const newGraph = Array(n)&#13;
    .fill(0)&#13;
    .map(() =&gt; Array(n).fill(0));&#13;
&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_465" aria-label="465"/><span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> const edges = [];&#13;
  for (let i = 0; i &lt; n; i++) {&#13;
    for (let j = i + 1; j &lt; n; j++) {&#13;
      if (graph[i][j]) {&#13;
        edges.push({from: i, to: j, dist: graph[i][j]});&#13;
      }&#13;
    }&#13;
  }&#13;
<span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> edges.sort((a, b) =&gt; a.dist – b.dist);&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> const groups = Array(n)&#13;
    .fill(0)&#13;
    .map(() =&gt; ({ptr: null}));&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> const findParent = (x) =&gt; {&#13;
    while (x.ptr) {&#13;
      x = x.ptr;&#13;
    }&#13;
    return x;&#13;
  };&#13;
&#13;
<span class="Code_CodeAnnotation" aria-label="annotation6">❻</span> edges.forEach((v) =&gt; {&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation7">❼</span> const pf = findParent(groups[v.from]);&#13;
    const pt = findParent(groups[v.to]);&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation8">❽</span> if (pf !== pt) {&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation9">❾</span> pf.ptr = pt.ptr = {ptr: null};&#13;
      newGraph[v.from][v.to] = newGraph[v.to][v.from] = graph[v.to][v.from];&#13;
    }&#13;
  });&#13;
&#13;
 <span class="Code_CodeAnnotation" aria-label="annotation10">❿</span> return newGraph;&#13;
};</code></pre>&#13;
<p class="TX">Start by creating an empty matrix for the new tree <span class="CodeAnnotation" aria-label="annotation1">❶</span>. Then generate a list of all edges in the graph <span class="CodeAnnotation" aria-label="annotation2">❷</span> and sort it <span class="CodeAnnotation" aria-label="annotation3">❸</span> with the simplest method, which is JavaScript’s own. (For a better way, check out question 17.8.) You now need to initialize all disjointed sets <span class="CodeAnnotation" aria-label="annotation4">❹</span>, as you did earlier when detecting connectivity. The groups array will have a pointer to the root of each set, all of which will start with a single element. You’ll use an iterative version of the earlier recursive <span class="SANS_TheSansMonoCd_W5Regular_11">findParent(...)</span> function <span class="CodeAnnotation" aria-label="annotation5">❺</span> to find to which set a node belongs. The rest of the algorithm is as follows: go through the sorted list of edges <span class="CodeAnnotation" aria-label="annotation6">❻</span>, and for each one, find the parents of both of its extremes <span class="CodeAnnotation" aria-label="annotation7">❼</span>. If they don’t match <span class="CodeAnnotation" aria-label="annotation8">❽</span>, join both sets by creating a new root <span class="CodeAnnotation" aria-label="annotation9">❾</span> and add the edge to the output graph, which you return at the end <span class="CodeAnnotation" aria-label="annotation10">❿</span>.</p>&#13;
<p class="TX">The performance of the algorithm can be shown to be <i>O</i>(<i>e</i> log <i>e</i>), basically because you have to sort all the edges and then go through the list possibly joining sets, which also produces the same result. The only disadvantage in this implementation is that getting the list of the nodes is <i>O</i>(<i>v</i><sup>2</sup>) due to having to go through the whole matrix, but you can enhance it if you adopt another representation for the graph using adjacency lists, as we’ve seen.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec20">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_466" aria-label="466"/>&#13;
<h3 class="H1" id="sec20"><span id="h1-97"/><span class="SANS_Futura_Std_Bold_B_11">Summary</span></h3>&#13;
<p class="TNI1">This chapter introduced the concept of graphs. We considered representations for them and studied many algorithms for common requirements, such as finding paths or distances, sorting nodes, detecting cycles, and minimizing costs. These algorithms have also benefited from previous algorithms (like sorting and searching) and data structures (heaps, bitmaps, trees, forests, and lists), providing a way to apply the previous knowledge you’ve gained in various ways.</p>&#13;
<p class="TX">In the next and final chapter of the book, we’ll move on to specific considerations for data structures that are meant for a fully functional programming style of work, which entails some advantages but also some challenging disadvantages.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec21">&#13;
&#13;
<h3 class="H1" id="sec21"><span id="h1-98"/><span class="SANS_Futura_Std_Bold_B_11">Questions</span></h3>&#13;
<p class="ListHead"><b>17.1  Where’s the Path?</b></p>&#13;
<p class="ListPlainFirst">Floyd-Warshall’s algorithm finds the shortest distances between every pair of points, but what do you do if you also want to know which path to take? Modify the algorithm so that finding paths is simple. Hint: whenever you find that going from <i>i</i> to <i>j</i> is better by passing through <i>k</i>, make a note so that later, when trying to find the actual path, you’ll know to go to <i>k</i>.</p>&#13;
<p class="ListHead"><b>17.2  Stop Searching Sooner</b></p>&#13;
<p class="ListPlainFirst">When considering the Bellman-Ford algorithm, we mentioned that a certain number of passes ensured finding the shortest paths, but can you do better? Hint: in the example we showed in that section, fewer passes were actually needed.</p>&#13;
<p class="ListHead"><b>17.3  Just One Will Do</b></p>&#13;
<p class="ListPlainFirst">How would you modify Dijkstra’s algorithm if you care only about finding the shortest path to a single point?</p>&#13;
<p class="ListHead"><b>17.4  The Wrong Way</b></p>&#13;
<p class="ListPlainFirst">Imagine you take a directed graph, reverse all of its edges, and then apply Kahn’s topological sort algorithm to it. What will be the output of this algorithm?</p>&#13;
<p class="ListHead"><b>17.5  Joining Sets Faster</b></p>&#13;
<p class="ListPlainFirst">When joining two distinct sets in the section “<span class="listplain_Xref">Detecting Connectivity with Sets</span>” on page <span class="listplain_Xref">454</span>, you always add a new root, but doing so isn’t necessary, because you could just have one root point at the other one. Consider adding a <span class="SANS_TheSansMonoCd_W5Regular_11">size</span> attribute in each root (with the number of nodes in the corresponding subtree) and join the smallest tree as a subtree of the largest one. Can you implement these changes?</p>&#13;
<p class="ListHead"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_467" aria-label="467"/><b>17.6  Take a Shortcut</b></p>&#13;
<p class="ListPlainFirst">When joining sets, doing a little work up-front can save time later. Look again at <a href="chapter17.xhtml#fig17-39">Figure 17-39</a> from the section “<span class="listplain_Xref">Detecting Connectivity with Sets</span>” on page <span class="listplain_Xref">454</span>. Suppose you want to know whether C and D are in the same group. You would need to walk from both nodes up to the root before finding the answer. However, if you are later asked again about C or D, you’d have to redo the path, unless you modify some links, as shown in <a href="chapter17.xhtml#fig17-53">Figure 17-53</a>.</p>&#13;
<figure class="IMG"><img class="img7" id="fig17-53" src="../images/Figure17-53.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_11">Figure 17-53: An optimized algorithm for joining sets</span></p></figcaption>&#13;
</figure>&#13;
<p class="ListBody">Three links were changed to point to the root directly, so you can get there more quickly. (From C or D, it’s just one step to the root, and from E, it’s one step shorter than before.) Make a change in the <span class="SANS_TheSansMonoCd_W5Regular_11">findParent(...)</span> function so it creates “shortcut” paths that’ll make future processes faster.</p>&#13;
<p class="ListHead"><b>17.7  A Spanning Tree for a Tree?</b></p>&#13;
<p class="ListPlainFirst">What happens if you apply a spanning tree algorithm to a tree?</p>&#13;
<p class="ListHead"><b>17.8  A Heap of Edges</b></p>&#13;
<p class="ListPlainFirst">Can you replace JavaScript’s sort with heapsort, quicksort, or any other method discussed in the book?</p>&#13;
</section>&#13;
</section>&#13;
</body></html>