<html><head></head><body>
<div id="sbo-rt-content">
<section epub:type="chapter" role="doc-chapter" aria-labelledby="ch5">

<hgroup>
<h2 class="CHAPTER" id="ch5">

<span class="CN"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_119" aria-label=" Page 119. "/><samp class="SANS_Futura_Std_Bold_Condensed_B_11">5</samp></span>

<span class="CT"><samp class="SANS_Dogma_OT_Bold_B_11">DOCKER, ALEPH, AND MAKING DATASETS SEARCHABLE</samp></span>

</h2>
</hgroup>

<p class="COS">When I get my hands on a new dataset, the first thing I do is search it for any juicy, easy-to-find revelations. Depending on the dataset, I might look for politicians, organizations, or the city where I live. In the previous chapter, you learned to search text files like CSV or JSON files using <samp class="SANS_TheSansMonoCd_W5Regular_11">grep</samp>, but <samp class="SANS_TheSansMonoCd_W5Regular_11">grep</samp> won’t work on binary files like PDFs or Office documents. In this chapter, you’ll expand your search capabilities with Aleph, an open source investigation tool.</p>

<p class="TX">Aleph is developed by the Organized Crime and Corruption Reporting Project, a group of investigative journalists largely based in eastern Europe and central Asia. The tool allows you to <i>index</i> datasets, extracting all the text they contain so they’re easy to search. You can use Aleph to search for keywords or <i>entities</i> (like people, companies, organizations, or addresses) and discover related entities in other datasets. Aleph also performs optical <span role="doc-pagebreak" epub:type="pagebreak" id="pg_120" aria-label=" Page 120. "/>character recognition (OCR), which, as mentioned in <span class="Xref"><a href="chapter1.xhtml">Chapter 1</a></span>, takes flat images like scanned documents or screenshots, uses artificial intelligence to recognize any words, and converts those words into text that you can search or copy and paste.</p>

<p class="TX">In the first half of this chapter, you’ll learn the ins and outs of using Docker and Docker Compose, the software required for running Aleph. In the second half, you’ll use your new Docker skills to run an Aleph server, then index and search part of the BlueLeaks dataset.</p>

<section epub:type="division" aria-labelledby="sec1">

<h3 class="H1" id="sec1"><span id="h-110"/><samp class="SANS_Futura_Std_Bold_B_11">Introducing Docker and Linux Containers</samp></h3>

<p class="TNI">Docker is the most popular software for running <i>Linux containers</i>, a type of software package. Linux containers can organize ready-to-go Linux software—complete with all of its dependencies, configuration, and source code—into a single bundle called a <i>container image</i> that you can quickly and easily run. The software inside containers is isolated from the rest of your computer; it can’t access any of those files unless you allow it to do so.</p>

<p class="TX">For example, let’s say you want to set up the popular WordPress blogging software in Linux. You use a package manager like apt to install the software WordPress depends on. You then put the WordPress source code in a location on your disk with the right permissions, configure your web server software so it knows where to look for that source code, and configure a database to store the blog’s data. You can then save all this work in a Linux container called <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> and reuse that container to spin up new WordPress sites with a single Docker command.</p>

<p class="TX">Because Linux containers are isolated from the rest of your computer, multiple WordPress containers can run at the same time without interfering with each other. If someone hacks the software running in your container, they won’t be able to access any of the data located elsewhere on your computer—at least, not without also hacking Docker itself. This is why Dangerzone relies on Linux containers: if a malicious document manages to hack the Dangerzone container you’re using, your computer should still be safe. In addition to software like WordPress, you can use Linux containers to run commands in most Linux distributions without having to install those operating systems.</p>

<p class="TX">Docker comes with two commands you’ll use in this chapter: <samp class="SANS_TheSansMonoCd_W5Regular_11">docker</samp>, which runs individual containers, and <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose</samp>, which lets you run multiple containers at once. You’ll practice using the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker</samp> command by running Linux containers for the Ubuntu and Kali Linux operating systems, as well as for the data science software Jupyter Notebook. You’ll then use <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose</samp> to run a WordPress server and an Aleph server. Aleph requires a small network of services that communicate with each other, but as with WordPress, you can use a single Docker command to start up all these individual servers in their own containers. This process should prepare you to run Linux containers with Docker for other purposes later in the book.</p>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_121" aria-label=" Page 121. "/>This chapter covers two applications for running Docker containers: Docker Desktop and Docker Engine. Docker Desktop runs Docker containers on workstation computers in a Linux VM. Docker Engine, on the other hand, runs Docker directly on a Linux computer. Windows and Mac users, turn to Exercise 5-1 to set up Docker Desktop. Linux users, turn to Exercise 5-2 to install Docker Engine.</p>
<blockquote>

<p class="NOTE"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp></span></p>
</blockquote>

<p class="NOTE-TXT"><i>It’s possible for Linux users to install Docker Desktop, but I don’t recommend it for this chapter. Without a VM, Docker will be free to use all of your computer’s memory and processors, which will make indexing datasets in Aleph much faster.</i></p>

</section>

<section epub:type="division" aria-labelledby="sec2">

<h3 class="H1F" id="sec2"><span id="h-111"/><samp class="SANS_Futura_Std_Heavy_B_21">Exercise 5-1: Initialize Docker Desktop on Windows and macOS</samp></h3>

<p class="TNI">When you installed Dangerzone in Exercise 1-3, Docker Desktop also should have been installed, since Dangerzone requires it. Confirm that Docker Desktop is installed by checking whether your <i>Applications</i> folder in macOS or Start menu in Windows has a Docker program; if not, download it from <a href="https://www.docker.com/products/docker-desktop/"><i>https://<wbr/>www<wbr/>.docker<wbr/>.com<wbr/>/products<wbr/>/docker<wbr/>-desktop<wbr/>/</i></a>.</p>

<p class="TX">Open Docker and follow the onscreen instructions to initialize the software. You may need to reboot your computer. Docker Desktop’s Linux VM should be up and running before you can use Docker. If you click the Docker icon in your system tray and it tells you that Docker Desktop is running, you’re ready to proceed.</p>

<p class="TX">If you’re using Windows, you can use either PowerShell or Ubuntu with WSL for this chapter, since the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-desktop</samp> commands should run fine in either. Even when you use Docker from PowerShell, it technically relies on WSL under the hood.</p>

<p class="TX">If you’re using macOS, click the Docker icon in your system tray and choose <b>Preferences</b>. Switch to the Resources tab and make sure that the Memory resource is set to at least 6GB—higher if you have more to spare—to be sure Docker’s Linux VM has enough memory to handle Aleph. Click <b>Apply &amp; Restart</b>.</p>

<p class="TX">For either operating system, to test whether Docker is working, open a terminal and run this command:</p>

<pre id="pre-156"><code><b>docker run hello-world</b></code></pre>

<p class="TX">This command should run a Docker container image called <samp class="SANS_TheSansMonoCd_W5Regular_11">hello-world</samp>. If you don’t already have the <samp class="SANS_TheSansMonoCd_W5Regular_11">hello-world</samp> image on your computer, Docker should download it first. The output should look something like this:</p>

<pre id="pre-157"><code>Unable to find image 'hello-world:latest' locally

latest: Pulling from library/hello-world

2db29710123e: Pull complete

Digest: sha256:10d7d58d5ebd2a652f4d93fdd86da8f265f5318c6a73cc5b6a9798ff6d2b2e67

Status: Downloaded newer image for hello-world:latest

<span role="doc-pagebreak" epub:type="pagebreak" id="pg_122" aria-label=" Page 122. "/>

Hello from Docker!

This message shows that your installation appears to be working correctly.

<var>--snip--</var></code></pre>

<p class="TX">Your computer is ready to run Linux containers. Skip to the <span class="Xref">“Running Containers with Docker”</span> section on <span class="Xref">page 123</span>.</p>

</section>

<section epub:type="division" aria-labelledby="sec3">

<h3 class="H1F" id="sec3"><span id="h-112"/><samp class="SANS_Futura_Std_Heavy_B_21">Exercise 5-2: Initialize Docker Engine on Linux</samp></h3>

<p class="TX">Follow the detailed instructions for Server rather than Desktop at <a href="https://docs.docker.com/engine/install/"><i>https://<wbr/>docs<wbr/>.docker<wbr/>.com<wbr/>/engine<wbr/>/install<wbr/>/</i></a> to install Docker Engine for your version of Linux. In Ubuntu, the installation process involves adding a new apt repository to your computer and installing some Docker packages.</p>

<p class="TX">Docker Engine on Linux requires root access to run containers. After completing this exercise, if you’re using Linux, add <samp class="SANS_TheSansMonoCd_W5Regular_11">sudo</samp> to the beginning of all <samp class="SANS_TheSansMonoCd_W5Regular_11">docker</samp> or <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose</samp> commands in this book. To run all your Docker commands as root automatically without using <samp class="SANS_TheSansMonoCd_W5Regular_11">sudo</samp>, check the Docker Engine documentation for instructions on adding your Linux user to the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker</samp> group; however, keep in mind that doing so decreases your computer’s security and isn’t recommended.</p>

<p class="TX">Once Docker is installed, open a terminal and run:</p>

<pre id="pre-158"><code><b>sudo docker run hello-world</b></code></pre>

<p class="TX">This command runs a Docker container image called <samp class="SANS_TheSansMonoCd_W5Regular_11">hello-world</samp>. If you don’t already have the <samp class="SANS_TheSansMonoCd_W5Regular_11">hello-world</samp> image on your computer, Docker downloads it first. The output should look something like this:</p>

<pre id="pre-159"><code>Unable to find image 'hello-world:latest' locally

latest: Pulling from library/hello-world

2db29710123e: Pull complete

Digest: sha256:507ecde44b8eb741278274653120c2bf793b174c06ff4eaa672b713b3263477b

Status: Downloaded newer image for hello-world:latest



Hello from Docker!

This message shows that your installation appears to be working correctly.

<var>--snip--</var></code></pre>

<p class="TX">If the <samp class="SANS_TheSansMonoCd_W5Regular_11">hello-world</samp> container ran successfully, you can now use the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker</samp> command on your computer. Next, run the following command to install the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose</samp> package, which will give you access to the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose</samp> command:</p>

<pre id="pre-160"><code><b>sudo apt install docker-compose</b></code></pre>

<p class="TX">Your computer is now ready to run Linux containers.</p>
<aside class="box" aria-labelledby="box-15">

<h4 class="BH" id="box-15"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_123" aria-label=" Page 123. "/><samp class="SANS_Dogma_OT_Bold_B_11">PODMAN</samp></h4>

<p class="BoxBodyCustom1"><samp class="SANS_Futura_Std_Book_11">Podman (</samp><a href="https://podman.io"><samp class="SANS_Futura_Std_Book_Oblique_I_11">https://podman.io</samp></a><samp class="SANS_Futura_Std_Book_11">)</samp> <samp class="SANS_Futura_Std_Book_11">is another software solution for running Linux containers. It’s lightweight and doesn’t require root access, which makes it more secure than Docker. I prefer Podman—in fact, Dangerzone for Linux uses it instead of Docker. However, Docker is more popular, and some containers that work in Docker may not run properly in Podman. I recommend sticking with Docker while you follow along with this chapter. If you become a Linux container nerd, you can try out Podman on your own later.</samp></p>
</aside>
</section>

<section epub:type="division" aria-labelledby="sec4">

<h3 class="H1" id="sec4"><span id="h-113"/><samp class="SANS_Futura_Std_Bold_B_11">Running Containers with Docker</samp></h3>

<p class="TNI">The <samp class="SANS_TheSansMonoCd_W5Regular_11">docker</samp> command you’ve just installed allows you to run Linux containers on your computer. In this section you’ll learn how to use this command to open a shell inside containers, force running containers to quit, mount volumes to save persistent data or access certain files, set environment variables, and publish ports so your computer can connect to network services inside your container. This foundational understanding of Docker will prepare you to run Docker containers in Exercise 5-3 and help you troubleshoot any problems you later encounter with Aleph.</p>
<blockquote>

<p class="NOTE"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp></span></p>
</blockquote>

<p class="NOTE-TXT"><i>For additional information on Docker commands, run</i> <samp class="SANS_TheSansMonoCd_W7Bold_Italic_BI_11">docker help</samp> <i>or check the documentation at</i> <a href="https://docs.docker.com"><span class="note_LinkURL_Italic">https://docs.docker.com</span></a><i>.</i></p>

<section epub:type="division" aria-labelledby="sec5">

<h4 class="H2" id="sec5"><span id="h-114"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Running an Ubuntu Container</samp></h4>

<p class="TNI">You’ll begin by learning how to run a Linux container with the Ubuntu operating system in it. People often base more complicated container images on the Ubuntu container image to access all Ubuntu software that apt can install. An Ubuntu container is also a convenient way to access a shell on a clean Ubuntu system, allowing you to install software or test programs.</p>

<p class="TX">Docker commands use the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker</samp> <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">command</samp> syntax. Run the following to start your own Ubuntu container (if you’re using Linux, remember to add <samp class="SANS_TheSansMonoCd_W5Regular_11">sudo</samp>):</p>

<pre id="pre-161"><code><b>docker run -it ubuntu:latest bash</b></code></pre>

<p class="TX">This command runs <samp class="SANS_TheSansMonoCd_W5Regular_11">ubuntu:latest</samp>, the latest version of the <samp class="SANS_TheSansMonoCd_W5Regular_11">ubuntu</samp> image. If that image isn’t already on your computer, Docker automatically downloads it from Docker Hub, a library of public container images at <a href="https://hub.docker.com"><i>https://<wbr/>hub<wbr/>.docker<wbr/>.com</i></a>. Next, the <samp class="SANS_TheSansMonoCd_W5Regular_11">bash</samp> command runs, giving you shell access inside that <span role="doc-pagebreak" epub:type="pagebreak" id="pg_124" aria-label=" Page 124. "/>container. Include the <samp class="SANS_TheSansMonoCd_W5Regular_11">-it</samp> argument, which is short for <samp class="SANS_TheSansMonoCd_W5Regular_11">-i</samp> (or <samp class="SANS_TheSansMonoCd_W5Regular_11">--interactive</samp>) and <samp class="SANS_TheSansMonoCd_W5Regular_11">-t</samp> (or <samp class="SANS_TheSansMonoCd_W5Regular_11">--tty</samp>), after <samp class="SANS_TheSansMonoCd_W5Regular_11">docker run</samp> whenever you plan to open a shell in a container, so that any commands you type in the terminal run in the container. Without the <samp class="SANS_TheSansMonoCd_W5Regular_11">-it</samp> argument, the bash shell would immediately quit before you could run any commands, as would the container.</p>

<p class="TX">This command gives me the following output:</p>

<pre id="pre-162"><code>micah@trapdoor ~ % <b>docker run -it ubuntu:latest bash</b>

Unable to find image 'ubuntu:latest' locally

latest: Pulling from library/ubuntu

d19f32bd9e41: Pull complete

Digest: sha256:34fea4f31bf187bc915536831fd0afc9d214755bf700b5cdb1336c82516d154e

Status: Downloaded newer image for ubuntu:latest

root@5661828c22a2:/#</code></pre>

<p class="TX">Since I didn’t already have the <samp class="SANS_TheSansMonoCd_W5Regular_11">ubuntu:latest</samp> image, the command downloaded that image, started the container, and dropped me into a bash shell. I can now run whatever commands I want inside this container, such as installing software or running programs.</p>

<p class="TX">Running the <samp class="SANS_TheSansMonoCd_W5Regular_11">exit</samp> command quits the container. If you start a new <samp class="SANS_TheSansMonoCd_W5Regular_11">ubuntu:latest</samp> container, it contains none of the old container’s data. For example, with the following commands, I create a file called <i>test.txt</i> in one container, quit the container, and start a new one:</p>

<pre id="pre-163"><code>root@5661828c22a2:/# <b>echo "Hacks, Leaks, and Revelations" &gt; test.txt</b>

root@5661828c22a2:/# <b>cat test.txt</b>

Hacks, Leaks, and Revelations

root@5661828c22a2:/# <b>exit</b>

exit

micah@trapdoor ~ % <b>docker run -it ubuntu:latest bash</b>

root@e8888f73a106:/# <b>cat test.txt</b>

cat: test.txt: No such file or directory

root@e8888f73a106:/#</code></pre>

<p class="TX">The output shows that <i>test.txt</i> no longer exists. For data in a container to persist when you rerun the container image, you need to use volumes, as we’ll discuss in <span class="Xref">“Mounting and Removing Volumes”</span> on <span class="Xref">page 125</span>.</p>

</section>

<section epub:type="division" aria-labelledby="sec6">

<h4 class="H2" id="sec6"><span id="h-115"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Listing and Killing Containers</samp></h4>

<p class="TNI">If you’ve exited your Ubuntu container, run a new one. With that container running in the background, open a second terminal window and run the <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker ps</samp> command. This should show you a list of all containers currently running. Here’s the output I get, for example:</p>

<pre id="pre-164"><code>CONTAINER ID   IMAGE           COMMAND   CREATED           STATUS         PORTS     NAMES

337a795a53b2   ubuntu:latest   "bash"    9 minutes   ago   Up 9 minutes             epic_borg</code></pre>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_125" aria-label=" Page 125. "/>When you start a container with <samp class="SANS_TheSansMonoCd_W5Regular_11">docker run</samp>, you can give it a name with the arguments <samp class="SANS_TheSansMonoCd_W5Regular_11">--name</samp> <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">your_container_name</samp>. Otherwise, it will be assigned a random name. The container in my <samp class="SANS_TheSansMonoCd_W5Regular_11">docker ps</samp> output is called <samp class="SANS_TheSansMonoCd_W5Regular_11">epic_borg</samp>.</p>

<p class="TX">To <i>kill</i> a container, or force it to quit, you run <samp class="SANS_TheSansMonoCd_W5Regular_11">docker kill</samp> <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">container_name</samp>. For example, running the following command in my other terminal window quits my <samp class="SANS_TheSansMonoCd_W5Regular_11">epic_borg</samp> container:</p>

<pre id="pre-165"><code>docker kill epic_borg</code></pre>

<p class="TX">Run this command for your own container. If you switch back to your other terminal window, the container should have quit, and you should be back in your normal shell.</p>

<p class="TX">When you exit a container, Docker still keeps track of it, allowing you to restart it if you want. To see all of the containers Docker is tracking, including ones that aren’t running anymore, you run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker ps -a</samp> (short for <samp class="SANS_TheSansMonoCd_W5Regular_11">--all</samp>). Here’s the output I get when I run this command:</p>

<pre id="pre-166"><code>CONTAINER ID   IMAGE         ...   STATUS                     PORTS     NAMES

337a795a53b2   ubuntu:latest ...   Exited (0) 43 minutes ago            nostalgic_keldysh</code></pre>

<p class="TX">It’s good practice to run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker rm</samp> <samp class="SANS_TheSansMonoCd_W7Bold_Italic_BI_11">container_name</samp> to prune your stopped Docker containers when you’re done using them. For example, I’d run <samp class="SANS_TheSansMonoCd_W5Regular_11">docker rm nostalgic_keldysh</samp> to remove my <samp class="SANS_TheSansMonoCd_W5Regular_11">nostalgic_keldysh</samp> container.</p>

<p class="TX">You can run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker container prune</samp> to remove all stopped containers at once. When I ran this command, I saw the following output:</p>

<pre id="pre-167"><code>WARNING! This will remove all stopped containers.

Are you sure you want to continue? [y/N]</code></pre>

<p class="TX">I entered <samp class="SANS_TheSansMonoCd_W5Regular_11">y</samp> and got the following output:</p>

<pre id="pre-168"><code>Deleted Containers:

337a795a53b25e6c28888a44a0ac09fac9bf6aef4ab1c3108844ca447cce4226



Total reclaimed space: 5B</code></pre>

<p class="TX">This displays the container ID, a long string of random-looking text, for each container that’s deleted. In my case, I deleted a single container.</p>

</section>

<section epub:type="division" aria-labelledby="sec7">

<h4 class="H2" id="sec7"><span id="h-116"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Mounting and Removing Volumes</samp></h4>

<p class="TNI">Containers support <i>volumes</i>, which you can think of as folders in your container designed to store persistent data. You can use volumes to save changes you’ve made to your container after you quit and remove it.</p>

<p class="TX">For example, suppose you start a container without any volumes that runs the PostgreSQL database software. Any data you add to it is saved to the <i>/var/lib/postgresql/data</i> folder inside your container. When you quit and remove the container, you’ll lose all of your data. If you instead <i>mount</i> a folder on your host operating system into <i>/var/lib/postgresql/data</i> on the container, when software in the container accesses that folder, it’s actually <span role="doc-pagebreak" epub:type="pagebreak" id="pg_126" aria-label=" Page 126. "/>accessing the folder on your host operating system. You’ll still have all of your data when the container closes and is removed, and you can start the container again in the future with the same data.</p>

<p class="TX">Docker has two main types of volumes: <i>bind mounts</i>, or folders from your host machine mounted into a container, and normal Docker volumes, where Docker keeps track of your persistent folders without your having to provide a path on your host operating system. For example, if you want to store your database container’s data in the <i>/Volumes/datasets/volumes/db-data</i> folder on your host filesystem, you would mount this folder as a bind mount. If you don’t need your data to be stored in a specific folder on your host, just use a normal volume, and Docker will keep track of where it’s stored.</p>
<blockquote>

<p class="NOTE"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp></span></p>
</blockquote>

<p class="NOTE-TXT"><i>Storing volumes in a Linux VM with Docker Desktop makes them faster than bind mounts, but your VM might run out of disk space if your volumes get too big (if you index large datasets into Aleph, for example). In macOS, you can increase the amount of disk space available to your VM in the Docker Desktop preferences under the Resources tab. In Windows, your VM will use as much space on the</i> <span class="note_Italic">C:</span> <i>drive as it needs, but again, this drive could run out of disk space if you’re dealing with large amounts of data. Alternatively, you could use bind mounts instead of volumes, storing data on external disks.</i></p>

<p class="TX">You can also use volumes to access data outside of a container while that container is running. In Exercise 5-5, you’ll bind-mount your <i>datasets</i> USB disk as a folder in an Aleph container. This way, your container can access the BlueLeaks dataset, allowing you to index it.</p>

<p class="TX">Use this command to start a container with a volume:</p>

<pre id="pre-169"><code><b>docker run --mount type=volume,src=</b><b><var>volume-name</var></b><b>,dst=</b><b><var>/container/path image</var></b></code></pre>

<p class="TX">Use this command to start a container with a bind mount:</p>

<pre id="pre-170"><code><b>docker run --mount type=bind,src=</b><b><var>/path/on/host</var></b><b>,dst=</b><b><var>/container/path image</var></b></code></pre>

<p class="TX">The <samp class="SANS_TheSansMonoCd_W5Regular_11">--mount</samp> argument tells Docker that you’re going to mount a volume and is followed by comma-separated details about that volume. The <samp class="SANS_TheSansMonoCd_W5Regular_11">type</samp> parameter specifies the type of mount: <samp class="SANS_TheSansMonoCd_W5Regular_11">volume</samp> for volumes and <samp class="SANS_TheSansMonoCd_W5Regular_11">bind</samp> for bind mounts. The <samp class="SANS_TheSansMonoCd_W5Regular_11">src</samp> parameter specifies the source of the volume or bind mount. For volumes, its value is the volume name; for bind mounts, its value is the absolute path on your host filesystem to the folder you want to mount. The <samp class="SANS_TheSansMonoCd_W5Regular_11">dst</samp> parameter specifies the destination of the volume or bind mount, in both cases the absolute path of the folder inside the container to which you’re mounting.</p>

<p class="TX">Let’s practice these two commands, starting with mounting a volume. Run the following code (your prompt will be different from mine):</p>

<pre id="pre-171"><code>micah@trapdoor ~ % <b>docker run -it --mount type=volume,src=test-data,dst=</b><b>/mnt</b>

<b>ubuntu:latest bash</b><span role="doc-pagebreak" epub:type="pagebreak" id="pg_127" aria-label=" Page 127. "/>

root@50b8b6f86e4d:/# <b>echo "Hacks, Leaks, and Revelations" &gt; /mnt/test.txt</b>

root@50b8b6f86e4d:/# <b>exit</b></code></pre>

<p class="TX">This code starts an Ubuntu container and mounts a volume called <samp class="SANS_TheSansMonoCd_W5Regular_11">test-data</samp> into the <i>/mnt</i> folder in the container. It then saves some data into the <i>/mnt/test.txt</i> file and exits the container.</p>

<p class="TX">Use the following commands to open a separate container, mounting the same volume into it to see whether your data is still there (again, your command prompt will be different):</p>

<pre id="pre-172"><code>micah@trapdoor ~ % <b>docker run -it --mount type=volume,src=</b><b>test-data,dst=/mnt</b>

<b>ubuntu:latest bash</b>

root@665f910bb21c:/# <b>cat /mnt/test.txt</b>

Hacks, Leaks, and Revelations

root@665f910bb21c:/# <b>exit</b></code></pre>

<p class="TX">This time, because you mounted <i>/mnt</i> in the <samp class="SANS_TheSansMonoCd_W5Regular_11">test-data</samp> volume, the data persisted.</p>

<p class="TX">To see a list of the volumes that Docker is managing, run the <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker volume ls</samp> command. You should get the following output:</p>

<pre id="pre-173"><code>DRIVER    VOLUME NAME

local     test-data</code></pre>

<p class="TX">You can remove volumes only from containers that have been completely removed from Docker. If you’ve just stopped a container but Docker is still tracking it, it won’t let you remove the volume. Completely remove all stopped containers by running <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker container prune</samp>, which then allows you to remove any volumes attached to those containers. You should get the following output:</p>

<pre id="pre-174"><code>WARNING! This will remove all stopped containers.

Are you sure you want to continue? [y/N]</code></pre>

<p class="TX">Enter <samp class="SANS_TheSansMonoCd_W7Bold_B_11">y</samp> to continue:</p>

<pre id="pre-175"><code>Deleted Containers:

665f910bb21ca701be416da94c05ee6a226117923367d2f7731693062683a402

50b8b6f86e4d0eab9eb0ba9bf006ae0473525d572ea687865f8afca8a92e7087



Total reclaimed space: 82B</code></pre>

<p class="TX">You can now run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker volume rm</samp> <samp class="SANS_TheSansMonoCd_W7Bold_Italic_BI_11">volume-name</samp> to remove any volumes attached to those containers, or run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker volume prune</samp> to delete all volumes that Docker containers aren’t currently using. Run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker volume rm test-data</samp> to remove the <samp class="SANS_TheSansMonoCd_W5Regular_11">test-data</samp> volume, then run the <samp class="SANS_TheSansMonoCd_W7Bold_B_11">docker volume ls</samp> command again. This time, you shouldn’t see any volumes listed in the output.</p>

<p class="TX">Next, you’ll practice bind mounting by mounting the folder on your host system containing the BlueLeaks dataset into a container running Kali Linux. This Linux distribution is designed for <i>penetration testing</i>, in which <span role="doc-pagebreak" epub:type="pagebreak" id="pg_128" aria-label=" Page 128. "/>people hack into systems with permission from the system owners to find and fix security flaws.</p>

<p class="TX">If you’re a Mac or Linux user, run the following command, replacing the path with the appropriate path on your machine:</p>

<pre id="pre-176"><code><b>docker run -it --mount type=</b><b>bind,src=</b><b><var>/Volumes/datasets/BlueLeaks-extracted</var></b><b>,dst=/blueleaks</b>

<b>kalilinux/kali-rolling bash</b></code></pre>

<p class="TX">This should run a <samp class="SANS_TheSansMonoCd_W5Regular_11">kalilinux/kali-rolling</samp> container, mounting your <i>BlueLeaks-extracted</i> folder in it at the path <i>/blueleaks</i>, and drop you into a bash shell.</p>

<p class="TX">Windows users might have trouble bind-mounting a folder on the <i>datasets</i> USB disk into a container, because Docker Desktop for Windows runs Linux containers using WSL, and WSL doesn’t always have access to your USB disks. To avoid this problem, if you plugged in your USB disk after opening a WSL terminal or using Docker, restart WSL by running <samp class="SANS_TheSansMonoCd_W7Bold_B_11">wsl --shutdown</samp> in PowerShell. You should see a notification from Docker Desktop asking if you want to restart it. Click <b>Restart</b>. After you restart WSL with the USB disk already plugged in, Docker should be able to mount it. (See <span class="Xref">Appendix A</span> for more information.)</p>

<p class="TX">If you’re using Windows with PowerShell to work through this chapter, run the following command to mount the folder that contains the BlueLeaks data into <i>/datasets</i>, replacing <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">D:/BlueLeaks-extracted</samp> with the appropriate path:</p>

<pre id="pre-177"><code><b>docker run -it –mount type-bind,src=</b><b><var>D:/BlueLeaks-extracted</var></b><b>,dst=/blueleaks kalilinux/</b>

<b>kali-rolling bash</b></code></pre>

<p class="TX">If you’re using Ubuntu with WSL in Windows, mount the <i>BlueLeaks</i> folder by accessing the <i>D:</i> drive from <i>/mnt/d</i> with the following syntax:</p>

<pre id="pre-178"><code><b>docker run -it --mount type=bind,src=</b><b><var>/mnt/d/BlueLeaks-extracted</var></b><b>,dst=/blueleaks kalilinux/</b>

<b>kali-rolling bash</b></code></pre>

<p class="TX">From within your Kali container, you can now use the tools that come with Kali on the BlueLeaks dataset. By default, Kali customizes your bash shell to look slightly different than Ubuntu does. The prompt will look something like this:</p>

<pre id="pre-179"><code>┌──(root㉿6a36e316663c)-[/]

└─#</code></pre>

<p class="TX">Docker containers are assigned random hostnames. In this case, <samp class="SANS_TheSansMonoCd_W5Regular_11">root</samp> is the name of the current user, <samp class="SANS_TheSansMonoCd_W5Regular_11">6a36e316663c</samp> is the hostname of the computer, and <samp class="SANS_TheSansMonoCd_W5Regular_11">/</samp> is the current working directory. From here, run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">ls /blueleaks/</samp> to list the files in the <i>BlueLeaks</i> folder:</p>
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_129" aria-label=" Page 129. "/>

<pre id="pre-180"><code>211sfbay               iowaintex               pleasantonpolice

Securitypartnership    jerseyvillagepd         prvihidta

acprlea                jric                    pspddoc

acticaz                kcpers                  publicsafetycadets

<var>--snip--</var></code></pre>

<blockquote>

<p class="NOTE"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp></span></p>
</blockquote>

<p class="NOTE-TXT"><i>You can learn more about volumes and bind mounts at</i> <a href="https://docs.docker.com/storage/">https://<wbr/>docs<wbr/>.docker<wbr/>.com<wbr/>/storage<wbr/>/</a>.</p>

</section>

<section epub:type="division" aria-labelledby="sec8">

<h4 class="H2" id="sec8"><span id="h-117"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Passing Environment Variables</samp></h4>

<p class="TNI">You can also use environment variables, introduced in <span class="Xref"><a href="chapter4.xhtml">Chapter 4</a></span>, to pass sensitive information like database credentials into containers. When starting up a container, you pass an environment variable into it using the <samp class="SANS_TheSansMonoCd_W5Regular_11">-e</samp> <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">variable_name</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">=</samp><samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">value</samp> (the <samp class="SANS_TheSansMonoCd_W5Regular_11">-e</samp> is short for <samp class="SANS_TheSansMonoCd_W5Regular_11">--env</samp>) arguments. Programs in the container can then access the value of that variable.</p>

<p class="TX">For example, run the following command:</p>

<pre id="pre-181"><code><b>docker run -it -e DB_USER=root -e DB_PASSWORD=yourefired ubuntu:latest bash</b></code></pre>

<p class="TX">This starts an Ubuntu container with the variable <samp class="SANS_TheSansMonoCd_W5Regular_11">DB_USER</samp> set to <samp class="SANS_TheSansMonoCd_W5Regular_11">root</samp> and the variable <samp class="SANS_TheSansMonoCd_W5Regular_11">DB_PASSWORD</samp> set to <samp class="SANS_TheSansMonoCd_W5Regular_11">yourefired</samp>. From inside the container, try displaying the values of those variables to confirm that you can access this information there, using the <samp class="SANS_TheSansMonoCd_W5Regular_11">echo $</samp><samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">variable_name</samp> command like so:</p>

<pre id="pre-182"><code>bash-5.1# <b>echo $DB_USER</b>

root

bash-5.1# <b>echo $DB_PASSWORD</b>

yourefired</code></pre>

<p class="TX">You’ll practice passing environment variables to containers further in Exercise 5-3.</p>

</section>

<section epub:type="division" aria-labelledby="sec9">

<h4 class="H2" id="sec9"><span id="h-118"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Running Server Software</samp></h4>

<p class="TNI">You can also run robust, fully configured software on the operating systems running in containers. This technique is mostly used to access <i>server software</i>, software to which you can connect over a network using web browsers, database clients, or other similar programs. You’ll need this skill for Exercise 5-3 and, eventually, to run Aleph.</p>

<p class="TX">Different computers (or VMs, or containers), called <i>hosts</i>, are identified by IP addresses or hostnames. Your own computer’s IP address is always 127.0.0.1, and its hostname is always <i>localhost</i>. Hosts can listen on different ports for incoming network connections, meaning the host is available for other hosts to connect to over a network. A <i>port</i> is a number that the computer uses to sort out which network traffic should go to which application.</p>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_130" aria-label=" Page 130. "/>Different services have different default ports. For example, HTTP and HTTPS services are two types of websites that use port 80 and port 443, respectively. When you load the URL <i>http://<wbr/>example<wbr/>.com</i> in your browser, it will try to connect to the host <i>example.com</i> on port 80 using HTTP. If you load <i>https://<wbr/>example<wbr/>.com</i>, it will try to connect on port 443 using HTTPS.</p>

<p class="TX">However, you can change the default ports that services use. If you’re running an HTTP service on <i>localhost</i> on port 5000, the URL for that service would be <i>http://<wbr/>localhost:5000</i>, where <i>http://<wbr/></i> means you’re using the HTTP protocol, <i>localhost</i> means you’re connecting to the <i>localhost</i> host, and <i>:5000</i> means you’re connecting to port 5000 instead of the default HTTP port, 80.</p>

<p class="TX">To connect to a network port inside your Docker container, you must <i>publish</i> a network port when you run your container, making that port available on the host operating system. To do so, use the arguments <samp class="SANS_TheSansMonoCd_W5Regular_11">-p</samp> <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">host_port</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">:</samp><samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">container_port</samp> (<samp class="SANS_TheSansMonoCd_W5Regular_11">-p</samp> is short for <samp class="SANS_TheSansMonoCd_W5Regular_11">--publish</samp>). Once the container starts up, your host operating system will listen on <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">host_port</samp>. If you connect to that port, your connection will be forwarded to <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">container_port</samp> inside the container.</p>

<p class="TX">Let’s look at an example of running server software and publishing a port so that you can connect to it from your host computer. Run the following command:</p>

<pre id="pre-183"><code><b>docker run -p 8000:8888 jupyter/scipy-notebook:latest</b></code></pre>

<p class="TX">This command should download and run the latest version of the <i>jupyter/scipy-notebook</i> container image, which includes the most popular science-related Python libraries. (Jupyter Notebook is a powerful data science tool for creating and sharing computational documents.) Jupyter Notebook starts an HTTP service on port 8888 in the container. The arguments <samp class="SANS_TheSansMonoCd_W5Regular_11">-p 8000:8888</samp> mean that <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">host_port</samp> is <samp class="SANS_TheSansMonoCd_W5Regular_11">8000</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">container_port</samp> is <samp class="SANS_TheSansMonoCd_W5Regular_11">8888</samp>. If you connect to <i>localhost</i> on port 8000, using either the URL <i>http://<wbr/>localhost:8000</i> or <i>http://<wbr/>127<wbr/>.0<wbr/>.0<wbr/>.1:8000</i>, you’ll now actually connect to port 8888 inside the container.</p>

<p class="TX">Here’s the output from the previous command:</p>

<pre id="pre-184"><code>Unable to find image 'jupyter/scipy-notebook:latest' locally

latest: Pulling from jupyter/scipy-notebook

08c01a0ec47e: Pull complete

<var>--snip--</var>

Status: Downloaded newer image for jupyter/scipy-notebook:latest

Entered start.sh with args: jupyter lab

Executing the command: jupyter lab

<var>--snip--</var>

    

    To access the server, open this file in a browser:

        file:///home/jovyan/.local/share/jupyter/runtime/jpserver-7-open.html

    Or copy and paste one of these URLs:

        http://cc4a555569e4:8888/lab?token=d570e7d9ecc59bbc77536ea4ade65d02dd575ff3c6713dd4

    or http://127.0.0.1:8888/lab?token=d570e7d9ecc59bbc77536ea4ade65d02dd575ff3c6713dd4</code></pre>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_131" aria-label=" Page 131. "/>The output shows that this command downloaded the latest version of the <i>jupyter/scipy-notebook</i> container image from Docker Hub and then ran it. This time, instead of starting a shell in the container, the container runs only the service it was designed for, which is Jupyter Notebook. Each time Jupyter Notebook outputs a log message, the terminal window now displays it.</p>

<p class="TX">The end of the output shows three different URLs to access the server. Copy the final URL, paste it in your browser, and change the port number from 8888 to 8000 before you load it. When you connect to your own computer on port 8000 (127.0.0.1:8000), your connection will be forwarded to the container on port 8888. Your browser should load the Jupyter Notebook service running in your container. When this happens, you should see more log messages appear in the terminal.</p>

<p class="TX"><a href="#fig5-1">Figure 5-1</a> shows a web browser running on my Mac, connected to a Jupyter Notebook server, which is running in my Linux container.</p>
<figure class="IMG"><img class="img100" id="fig5-1" src="Images/Figure5-1.png" alt="A screenshot of a web browser loading Jupyter Notebook running in a container. The open document shows a snippet of Python code that was run." width="696" height="345"/>

<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 5-1: Jupyter Notebook running in a container</samp></p></figcaption>

</figure>

<p class="TX">The container keeps running until you press <small>CTRL</small>-C to quit it. If you need to run any other terminal commands while the container is still running, you’ll need to open a separate terminal window. For now, press <small>CTRL</small>-C in your terminal to exit the Jupyter Notebook container.</p>

<p class="TX">You won’t use Jupyter Notebook further in this book, but you’ll rely on your new understanding of running server software to run a WordPress website in Exercise 5-3.</p>
<blockquote>

<p class="NOTE"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp></span></p>
</blockquote>

<p class="NOTE-TXT"><i>For more information about Jupyter Notebook, visit</i> <a href="https://jupyter.org"><span class="note_LinkURL_Italic">https://jupyter.org</span></a><i>,</i> <i>and for thorough documentation on running Jupyter Notebook in Docker, see</i> <a href="https://jupyter-docker-stacks.readthedocs.io"><span class="note_LinkURL_Italic">https://jupyter-docker-stacks.readthedocs.io</span></a><i>.</i></p>

</section>

<section epub:type="division" aria-labelledby="sec10">

<h4 class="H2" id="sec10"><span id="h-119"/><span role="doc-pagebreak" epub:type="pagebreak" id="pg_132" aria-label=" Page 132. "/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Freeing Up Disk Space</samp></h4>

<p class="TNI">Docker images take up a lot of disk space. To free up space quickly, use the following command to delete all of the container images you’ve downloaded from Docker Hub and other data that Docker stores (besides volumes):</p>

<pre id="pre-185"><code><b>docker system prune -a</b></code></pre>

<p class="TX">Since this command doesn’t delete volumes, it won’t delete any of your important data. The next time you use <samp class="SANS_TheSansMonoCd_W5Regular_11">docker run</samp> commands, you’ll just redownload the container images you need from Docker Hub.</p>

</section>
</section>

<section epub:type="division" aria-labelledby="sec11">

<h3 class="H1F" id="sec11"><span id="h-120"/><samp class="SANS_Futura_Std_Heavy_B_21">Exercise 5-3: Run a WordPress Site with</samp> <samp class="SANS_Futura_Std_Heavy_B_21">Docker Compose</samp></h3>

<p class="TNI">More complicated software like Aleph requires running multiple containers that interact with each other. To do that, you’ll need to learn to use Docker Compose, as the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker run</samp> command’s arguments quickly become hard to keep track of when used to run more complicated containers—those with volumes, environment variables, publishing ports, and so on. It’s especially unwieldy to run a single application that requires multiple containers at once.</p>

<p class="TX">Docker Compose makes it easier to define and run such Docker applications. The tool allows you to configure your containers (choosing images, volumes, environment variables, published ports, and so on) in a single file, and to start and stop all of your containers with a single command. I often use Docker Compose even for software that requires a single container, because it simplifies keeping track of all of the configuration. You’ll need to be proficient in Docker Compose to run an Aleph server.</p>

<p class="TX">In this exercise, you’ll familiarize yourself with Docker Compose by using it to run WordPress. You won’t need WordPress for the remainder of this book, but here it serves as an example to prepare you for using Docker Compose with Aleph.</p>

<section epub:type="division" aria-labelledby="sec12">

<h4 class="H2" id="sec12"><span id="h-121"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Make a docker-compose.yaml File</samp></h4>

<p class="TNI">The YAML file format (<a href="https://yaml.org"><i>https://<wbr/>yaml<wbr/>.org</i></a>) is popular among programmers for storing configuration files because it’s relatively human-readable. YAML files have either a <i>.yml</i> or <i>.yaml</i> file extension. Docker Compose defines containers and their settings in a file called <i>docker-compose.yaml</i>.</p>

<p class="TX">Open a terminal and change to your <i>exercises</i> folder. Make a new folder called <i>wordpress</i> for this exercise and then, using your text editor, make a file in that folder called <i>docker-compose.yaml</i>. Enter the following code into <i>that</i> file (or copy and paste it from <a href="https://github.com/micahflee/hacks-leaks-and-revelations/blob/main/chapter-5/wordpress/docker-compose.yaml"><i>https://<wbr/>github<wbr/>.com<wbr/>/micahflee<wbr/>/hacks<wbr/>-leaks<wbr/>-and<wbr/>-revelations<wbr/>/blob<wbr/>/main<wbr/>/chapter<wbr/>-5<wbr/>/wordpress<wbr/>/docker<wbr/>-compose<wbr/>.yaml</i></a>):</p>
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_133" aria-label=" Page 133. "/>

<pre id="pre-186"><code>services:

  wordpress:

    image: wordpress:latest

    volumes:

      - wordpress_data:/var/www/html

    ports:

      - 8000:80

    restart: always

  <span class="CodeAnnotationCode-1" aria-label="annotation1">❶</span> environment:

      - WORDPRESS_DB_HOST=db

      - WORDPRESS_DB_USER=wordpress

      - WORDPRESS_DB_PASSWORD=yourefired

      - WORDPRESS_DB_NAME=wordpress

  db:

    image: mariadb:10.9

    volumes:

      - db_data:/var/lib/mysql

    restart: always

  <span class="CodeAnnotationCode-1" aria-label="annotation2">❷</span> environment:

      - MYSQL_ROOT_PASSWORD=supersecurepassword

      - MYSQL_USER=wordpress

      - MYSQL_PASSWORD=yourefired

      - MYSQL_DATABASE=wordpress

      

volumes:

  db_data:

  wordpress_data:</code></pre>

<p class="TX">YAML files are whitespace sensitive, meaning that indentations affect the meaning of the code. This file defines two containers named <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">db</samp>. For each container, it defines which container image to use, what volumes to mount, which ports to publish (in the case of the <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> container), which environment variables to set, and other settings.</p>

<p class="TX">The <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> container uses the <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress:latest</samp> image to create an instance of the WordPress web application. The <samp class="SANS_TheSansMonoCd_W5Regular_11">db</samp> container uses the <samp class="SANS_TheSansMonoCd_W5Regular_11">mariadb:10.9</samp> container image to create an instance of a MySQL database server. (MySQL is a popular data management system that you’ll learn more about in <span class="Xref"><a href="chapter12.xhtml">Chapter 12</a></span>.)</p>

<p class="TX">Because these two containers are defined in the same <i>docker-compose.yaml</i> file, by default they’re part of the same Docker network so that they can communicate with each other. The <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> container sets <samp class="SANS_TheSansMonoCd_W5Regular_11">WORDPRESS_DB_HOST</samp> to <samp class="SANS_TheSansMonoCd_W5Regular_11">db</samp>, the name of the other container, because it connects to that hostname. The <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> environment variables <span class="CodeAnnotation" aria-label="annotation1">❶</span> also match the <samp class="SANS_TheSansMonoCd_W5Regular_11">db</samp> environment variables <span class="CodeAnnotation" aria-label="annotation2">❷</span>. If these database credentials aren’t the same, WordPress gets a “permission denied” error when trying to connect to the database.</p>
<blockquote>

<p class="NOTE"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp></span></p>
</blockquote>

<p class="NOTE-TXT"><i>The WordPress</i> <span class="note_Italic">docker-compose.yaml</span> <i>file in this example is a slightly modified version of a sample file in the Docker documentation at</i> <a href="https://docs.docker.com/samples/wordpress/"><span class="note_LinkURL_Italic">https://docs.docker.com/samples/wordpress/</span></a><i>.</i> <i>See the documentation for a more thorough description of how to use Docker Compose.</i></p>

</section>

<section epub:type="division" aria-labelledby="sec13">

<h4 class="H2" id="sec13"><span id="h-122"/><span role="doc-pagebreak" epub:type="pagebreak" id="pg_134" aria-label=" Page 134. "/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Start Your WordPress Site</samp></h4>

<p class="TNI">In your terminal, change to the folder you created for this exercise and run the following command to start both containers at the same time:</p>

<pre id="pre-187"><code><b>docker-compose up</b></code></pre>

<p class="TX">The first time you run it, Docker should download the <samp class="SANS_TheSansMonoCd_W5Regular_11">mariadb:10.9</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress:latest</samp> container images from Docker Hub. The command should then run a MySQL container and a web server container running WordPress, and you should see logs from both containers scroll by in your terminal. Logs from the <samp class="SANS_TheSansMonoCd_W5Regular_11">db</samp> container start with <samp class="SANS_TheSansMonoCd_W5Regular_11">db_1</samp>, while logs from the <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> container start with <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress_1</samp>.</p>

<p class="TX">The <samp class="SANS_TheSansMonoCd_W5Regular_11">db</samp> container doesn’t need to publish any ports for WordPress to connect to it, since both containers share a Docker network. However, the <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> container publishes ports 8000:80. This means that loading <i>http://<wbr/>127<wbr/>.0<wbr/>.0<wbr/>.1:8000</i> in your browser connects to your host operating system on port 8000 and loads the web server in the <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> container running on port 80.</p>

<p class="TX">Enter <b><i>http://<wbr/>127<wbr/>.0<wbr/>.0<wbr/>.1:8000</i></b> in your browser, and you’re running WordPress! <a href="#fig5-2">Figure 5-2</a> shows the WordPress installation process that appears when I load that URL on my Mac after selecting English as my language.</p>
<figure class="IMG"><img class="img100" id="fig5-2" src="Images/Figure5-2.png" alt="A screenshot of a web browser loading WordPress running in a container. It shows the installation screen where the user sets a website title, a username, and a password." width="695" height="534"/>

<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 5-2: WordPress running in two containers with Docker Compose</samp></p></figcaption>

</figure>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_135" aria-label=" Page 135. "/>Fill out the form with your WordPress site’s title, a username, and a password, and then explore your new WordPress site.</p>

<p class="TX">To open a shell and run commands in an active container with Docker Compose, you use the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose exec</samp> <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">container_name command</samp> syntax. For example, this is how you’d get a shell in the <samp class="SANS_TheSansMonoCd_W5Regular_11">wordpress</samp> container:</p>

<pre id="pre-188"><code><b>docker-compose exec wordpress bash</b></code></pre>

<p class="TX">While <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose run</samp> starts a new container, <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose exec</samp> runs a command in an active container—a little like opening a new terminal window inside a running container.</p>

<p class="TX">Exit the shell when you are done. Back in the terminal running <samp class="SANS_TheSansMonoCd_W5Regular_11">docker -compose up</samp>, press <small>CTRL</small>-C to shut down the containers. Now you’re ready to use your new Docker and Docker Compose skills to make your datasets searchable with Aleph.</p>

</section>
</section>

<section epub:type="division" aria-labelledby="sec14">

<h3 class="H1" id="sec14"><span id="h-123"/><samp class="SANS_Futura_Std_Bold_B_11">Introducing Aleph</samp></h3>

<blockquote epub:type="epigraph" role="doc-epigraph">

<p class="EP"><i>Truth cannot penetrate a closed mind. If all places in the universe are in the Aleph, then all stars, all lamps, all sources of light are in it, too.</i></p>
<footer class="EPC"><span class="epigraphsource_Italic">—Jorge Luis Borges, “The Aleph”</span></footer>

</blockquote>

<p class="TNI">The Organized Crime and Corruption Reporting Project (OCCRP), founded in 2006, has a history of publishing high-profile investigations into corruption, often leading to criminal investigations, arrests, and seizure of stolen funds. In partnership with dozens of newsrooms around the world, the group relies on large datasets for its investigations. For example, OCCRP, along with the International Consortium of Investigative Journalists (ICIJ), was part of a coalition investigating the Panama Papers, an offshore tax haven dataset that led to over 40 stories about corruption. One of those stories implicated a close friend of Vladimir Putin who had embezzled $230 million from Russian taxpayers. Because OCCRP deals with so much data, it developed Aleph as an investigation tool to make it easier to track white-collar crime, follow the money, and cross-reference various datasets.</p>

<p class="TX">OCCRP runs an Aleph server available to the public at <a href="https://data.occrp.org"><i>https://<wbr/>data<wbr/>.occrp<wbr/>.org</i></a>. This server includes over 250 public datasets with documents from 139 different countries and territories. While there’s some overlap with datasets published by DDoSecrets, most public datasets in OCCRP’s Aleph server are different. Many of them are regularly updated datasets of public records: registries of company ownership around the world, lists of people and organizations facing international sanctions, and court records. These datasets might not seem exciting on their own, but when your investigation leads you to a specific person or company, they can be crucial for helping you fill in the gaps. OCCRP’s Aleph server also contains many more private datasets, which are available to journalists who apply for access.</p>

<p class="TX">Take some time to check out OCCRP’s Aleph server, explore which public datasets are available, and make some searches. For example, if you search <span role="doc-pagebreak" epub:type="pagebreak" id="pg_136" aria-label=" Page 136. "/>for Rudy Giuliani (Donald Trump’s confidant and former lawyer, and the former mayor of New York City) and filter by the US Federal Courts Archive dataset, you’ll find a series of court documents that reference Giuliani.</p>

<p class="TX">You can upload your own datasets to OCCRP’s Aleph server only if OCCRP makes an account for you. Even if you do have an account, you won’t be able to upload medium- or high-security datasets without sharing this data with a third party: OCCRP. That’s why I help run a private Aleph server for The Intercept. You won’t use OCCRP’s public Aleph server further in this book. Instead, in Exercise 5-4, you’ll run a small Aleph server and bring up Aleph containers on your own laptop.</p>

</section>

<section epub:type="division" aria-labelledby="sec15">

<h3 class="H1F" id="sec15"><span id="h-124"/><samp class="SANS_Futura_Std_Heavy_B_21">Exercise 5-4: Run Aleph Locally in Linux Containers</samp></h3>

<p class="TNI">This exercise prepares you to run your own server directly on your computer with Docker Compose. Instead of accessing Aleph at <a href="https://data.occrp.org"><i>https://<wbr/>data<wbr/>.occrp<wbr/>.org</i></a>, you’ll bring up your Aleph containers and access your private server at <i>http://<wbr/>127<wbr/>.0<wbr/>.0<wbr/>.1:8080</i>. You’ll use Docker Compose to run the many different services Aleph requires on your computer with a single command.</p>

<p class="TX">Make a new folder called <i>aleph</i> to use for this exercise and the next. Save a copy of <i>docker-compose.yml</i> and <i>aleph.env.tmpl</i> from Aleph’s git repo, located at <a href="https://github.com/alephdata/aleph"><i>https://<wbr/>github<wbr/>.com<wbr/>/alephdata<wbr/>/aleph</i></a>, into the <i>aleph</i> folder.</p>

<p class="TX">The <i>docker-compose.yml</i> file describes the nine containers that Aleph requires and all of their configuration, including the volumes that will save the indexed versions of your datasets. One of these containers, called <samp class="SANS_TheSansMonoCd_W5Regular_11">shell</samp>, includes a bind mount that maps your home folder (<i>~</i>) on your host filesystem to <i>/host</i> in the container:</p>

<pre id="pre-189"><code>- "~:/host"</code></pre>

<p class="TX">In your copy of <i>docker-compose.yml</i>, delete this line or comment it out by prepending a hash mark (<samp class="SANS_TheSansMonoCd_W5Regular_11">#</samp>) to make Aleph run faster and avoid giving the container access to your home folder.</p>

<p class="TX">Now rename <i>aleph.env.tmpl</i> to <i>aleph.env</i>, and open that file in your text editor. This file contains the settings for your Aleph instance on different lines, in the format <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">SETTING_NAME</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">=</samp><samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">setting_value</samp>, which you’ll need to modify in a few ways.</p>

<p class="TX">First, run the following command to generate a random value for <samp class="SANS_TheSansMonoCd_W5Regular_11">ALEPH_SECRET_KEY</samp> (Windows users, run this in your Ubuntu terminal):</p>

<pre id="pre-190"><code><b>openssl rand -hex 24</b></code></pre>

<p class="TX">Since you’re running Aleph on your computer instead of setting it up on a server for others to use, change <samp class="SANS_TheSansMonoCd_W5Regular_11">ALEPH_SINGLE_USER</samp> in <i>aleph.env</i> to <samp class="SANS_TheSansMonoCd_W5Regular_11">true</samp> instead of <samp class="SANS_TheSansMonoCd_W5Regular_11">false</samp>, which allows you to use Aleph without having to create an admin user for yourself. Save the file.</p>

<p class="TX">Aleph relies on many different services to run, including three databases: PostgreSQL, Redis, and Elasticsearch. Elasticsearch is designed to <span role="doc-pagebreak" epub:type="pagebreak" id="pg_137" aria-label=" Page 137. "/>search large amounts of data for text strings. For it to operate quickly, it needs to hold lots of data in memory. Linux’s default memory management setting <samp class="SANS_TheSansMonoCd_W5Regular_11">vm.max_map_count</samp> is far too low for Elasticsearch to work properly. If you’re using Linux or Windows with WSL, run the following command to increase the value of <samp class="SANS_TheSansMonoCd_W5Regular_11">vm.max_map_count</samp>:</p>

<pre id="pre-191"><code><b>sudo sysctl -w vm.max_map_count=262144</b></code></pre>

<p class="TX">If you’re using macOS, run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">sysctl -w vm.max_map_count=262144</samp> inside of your Linux VM managed by Docker Desktop. To do this, run the following command to start a shell directly in your Linux VM:</p>

<pre id="pre-192"><code><b>docker run -it --rm --privileged --pid=host alpine:edge nsenter -t 1 -m -u -n -i sh</b></code></pre>

<p class="TX">Once you’re in this shell, run this command:</p>

<pre id="pre-193"><code><b>sysctl -w vm.max_map_count=262144</b></code></pre>

<p class="TX">Run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">exit</samp> to exit the Linux VM shell. Each time you restart Docker Desktop, this change is undone, so you’ll need to run these commands again to continue using Elasticsearch. (Refer to the <span class="Xref">“Increasing Elasticsearch Memory in Docker Desktop”</span> box to speed up this process in the future.)</p>
<aside class="box" aria-labelledby="box-16">

<h4 class="BH" id="box-16"><samp class="SANS_Dogma_OT_Bold_B_11">INCREASING ELASTICSEARCH MEMORY IN DOCKER DESKTOP</samp></h4>

<p class="BoxBodyFirst"><samp class="SANS_Futura_Std_Book_11">If you’re using macOS, you’ll need to change settings before starting the Aleph containers. Instead of referring to this chapter to remember what commands to run, store them as the following shell script (which you can also find at</samp> <a href="https://github.com/micahflee/hacks-leaks-and-revelations/blob/main/chapter-5/aleph/fix-es-memory.sh"><samp class="SANS_Futura_Std_Book_Oblique_I_11">https://github.com/micahflee/hacks-leaks-and-revelations/blob/main/chapter-5/aleph/fix-es-memory.sh</samp></a><samp class="SANS_Futura_Std_Book_11">):</samp></p>

<pre id="pre-194"><code>#!/bin/bash

docker run -it --rm --privileged --pid=host alpine:edge \

    nsenter -t 1 -m -u -n -i \

    sysctl -w vm.max_map_count=262144</code></pre>

<p class="BoxBodyContinued"><samp class="SANS_Futura_Std_Book_11">Save a copy of this script in the same folder as your</samp> <samp class="SANS_Futura_Std_Book_Oblique_I_11">docker-compose.yml</samp> <samp class="SANS_Futura_Std_Book_11">file for Aleph, and run</samp> <samp class="SANS_TheSansMonoCd_W7Bold_B_11">chmod</samp> <samp class="SANS_TheSansMonoCd_W7Bold_B_11">+</samp><samp class="SANS_TheSansMonoCd_W7Bold_B_11">x fix-es-memory.sh</samp> <samp class="SANS_Futura_Std_Book_11">to make sure it’s executable. You can now run the script before starting the Aleph containers with just these two commands:</samp></p>

<pre id="pre-195"><code><b>./fix-es-memory.sh</b>

<b>docker-compose up</b></code></pre>

<p class="BoxBodyLast"><samp class="SANS_Futura_Std_Book_11">You’ll need to run this script only once each time you restart Docker Desktop.</samp></p>
</aside>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_138" aria-label=" Page 138. "/>Finally, for all operating systems, run the following command to start Aleph:</p>

<pre id="pre-196"><code><b>docker-compose up</b></code></pre>

<p class="TX">The first time you run this command, you’ll download a few gigabytes of container images. Text will scroll past in the terminal while Aleph boots up; wait for it to stop.</p>

<p class="TX">You also need to run an <samp class="SANS_TheSansMonoCd_W5Regular_11">upgrade</samp> command the first time you use Aleph and whenever you upgrade your version of it. Once Aleph finishes booting, open a second terminal, change to the <i>exercises</i> folder, and run:</p>

<pre id="pre-197"><code><b>docker-compose run --rm shell aleph upgrade</b></code></pre>

<p class="TX">This command initializes the databases that Aleph uses by running the command <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph upgrade</samp> inside the <samp class="SANS_TheSansMonoCd_W5Regular_11">shell</samp> container. Wait for this command to completely finish; you’ll know it’s done when the program stops displaying output and you end up back at your terminal’s command prompt.</p>
<blockquote>

<p class="NOTE"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp></span></p>
</blockquote>

<p class="NOTE-TXT"><i>For more detailed documentation for Aleph, see</i> <a href="https://docs.aleph.occrp.org">https://docs.aleph.occrp.org</a><i>.</i></p>

</section>

<section epub:type="division" aria-labelledby="sec16">

<h3 class="H1" id="sec16"><span id="h-125"/><samp class="SANS_Futura_Std_Bold_B_11">Using Aleph’s Web and Command Line Interfaces</samp></h3>

<p class="TNI">Now that you have a local Aleph server, you can explore its two different interfaces: the web interface, which you’ll use to investigate datasets, and the CLI interface, which you’ll use to index new datasets or administer your Aleph server.</p>

<p class="TX">With your Aleph containers up, open <i>http://<wbr/>127<wbr/>.0<wbr/>.0<wbr/>.1:8080<wbr/>/</i> in a browser to see the web interface. For example, <a href="#fig5-3">Figure 5-3</a> shows Aleph running in Docker containers on my Mac.</p>
<figure class="IMG"><img class="img100" id="fig5-3" src="Images/Figure5-3.png" alt="A screenshot of Aleph loaded in a web browser, with link to “Search entities,” “Browse datasets,” “Start an investigation,” and “Create a search alert.”" width="695" height="338"/>

<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 5-3: Aleph hosted in Docker containers</samp></p></figcaption>

</figure>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_139" aria-label=" Page 139. "/>You’ll use this interface to search data you upload into Aleph. The search bar at the top allows you to search every dataset you’ve indexed in your Aleph server at once, and the slider icon just to the right of the search box lets you perform advanced searches.</p>

<p class="TX">The Datasets and Investigations buttons at the top show you the datasets in Aleph; for now, both of those pages will be empty. In Aleph, datasets and investigations are both collections of documents, with different user interfaces for exploring each. A dataset should be static, while an investigation is a collection of documents that you might still be adding to.</p>

<p class="TX">After performing a search in Aleph, you can optionally save your search query as an alert. This feature is useful only on servers that have multiple users and are configured to send email. In those cases, the server automatically searches any new data indexed into the server for all of a user’s saved alerts. If it gets a hit, it sends an email to the user. In the example, you set <samp class="SANS_TheSansMonoCd_W5Regular_11">ALEPH_SINGLE_USER</samp> to <samp class="SANS_TheSansMonoCd_W5Regular_11">true</samp>, so that feature doesn’t apply.</p>

<p class="TX">In addition to the web-based user interface you just explored, designed for journalists and researchers, Aleph has a command line interface designed for running the Aleph server itself. You must use the command line interface for administrative tasks like creating Aleph users (if you aren’t using the <samp class="SANS_TheSansMonoCd_W5Regular_11">ALEPH_SINGLE_USER</samp> setting in future projects) or indexing folders of data, which you’ll do later in this chapter.</p>

<p class="TX">To use the command line interface, run <samp class="SANS_TheSansMonoCd_W5Regular_11">bash</samp> inside the container called <samp class="SANS_TheSansMonoCd_W5Regular_11">shell</samp> to start an Aleph shell like so:</p>

<pre id="pre-198"><code><b>docker-compose run --rm shell bash</b></code></pre>

<p class="TX">When you first opened a shell in a container using Docker Compose, you used <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose exec</samp>, which executes a command in an already running container. Here, <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose run</samp> runs a new container in which to execute your command. The <samp class="SANS_TheSansMonoCd_W5Regular_11">--rm</samp> argument tells Docker to remove the container as soon as your command finishes running. In this case, your command is <samp class="SANS_TheSansMonoCd_W5Regular_11">bash</samp>, so you can run <samp class="SANS_TheSansMonoCd_W5Regular_11">exit</samp> in the bash shell to remove this temporary container.</p>

<p class="TX">You can now use the <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph</samp> command. Run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">aleph --help</samp> to see a list of all of the commands that Aleph supports. To learn more about a specific command, run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">--help</samp> on it. For example, to learn more about the <samp class="SANS_TheSansMonoCd_W5Regular_11">crawldir</samp> command (which we’ll discuss in Exercise 5-5), you’d run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">aleph crawldir --help</samp>.</p>

<p class="TX">Run <samp class="SANS_TheSansMonoCd_W7Bold_B_11">exit</samp> to quit the Aleph shell. Back in your other terminal window, press <small>CTRL</small>-C to shut down all the Aleph containers when you’re not using them. When you run <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose up</samp> to start the containers again, all the data in Aleph—including any datasets that you’ve added to it—will still be there, because that data is stored in Docker volumes, making it persistent.</p>

</section>

<section epub:type="division" aria-labelledby="sec17">

<h3 class="H1" id="sec17"><span id="h-126"/><samp class="SANS_Futura_Std_Bold_B_11">Indexing Data in Aleph</samp></h3>

<p class="TNI">Adding data to Aleph is called <i>indexing</i>. By loading and processing every file in a dataset, Aleph allows you to extract useful information, which you can browse and search via its web-based user interface.</p>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_140" aria-label=" Page 140. "/>Indexing works differently for different types of files:</p>

<p class="RunInPara"><b>Office documents and PDFs</b> Aleph extracts all of the searchable text from these documents and attempts to find anything that looks like a person’s name, a company name, or other types of data that Aleph calls <i>entities</i>. It also extracts any metadata it can find.</p>

<p class="RunInPara"><b>Email messages</b>#x2003;Aleph again extracts searchable text and entities. This time, the entities it finds are likely to include both names and email addresses, which it determines by checking the sender and recipient of each email. It also extracts email attachments and indexes those individually.</p>

<p class="RunInPara"><b>Compressed files, such as ZIP files</b> Aleph decompresses these files, then indexes each file inside them individually, which can become as recursive as necessary. For example, a ZIP file might contain an email file with an attachment that contains another ZIP file, and so on.</p>

<p class="TX">Indexing datasets can take hours, days, or weeks, depending on the size of the dataset and the computational resources available to your Aleph server. In Exercise 5-5, you’ll index a single BlueLeaks folder called <i>icefishx</i>.</p>

</section>

<section epub:type="division" aria-labelledby="sec18">

<h3 class="H1F" id="sec18"><span id="h-127"/><samp class="SANS_Futura_Std_Heavy_B_21">Exercise 5-5: Index a BlueLeaks Folder in Aleph</samp></h3>

<p class="TNI">The <i>icefishx</i> folder contains data from an American police intelligence network called Intelligence Communications Enterprise for Information Sharing and Exchange (ICEFISHX), a partnership between law enforcement in Minnesota, North Dakota, and South Dakota. I’ve selected this data because it covers the state where Minneapolis cop Derek Chauvin murdered George Floyd, sparking the 2020 Black Lives Matter uprising. Searching this dataset for <i>George Floyd</i> might reveal some interesting internal docs about police violence or the protests that it triggered.</p>

<section epub:type="division" aria-labelledby="sec19">

<h4 class="H2" id="sec19"><span id="h-128"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Mount Your Datasets into the Aleph Shell</samp></h4>

<p class="TNI">If you don’t already have Aleph running, change to your <i>aleph</i> folder and enter the following command:</p>

<pre id="pre-199"><code><b>docker-compose up</b></code></pre>

<p class="TX">Wait for Aleph to boot up.</p>

<p class="TX">In a separate terminal, start an Aleph shell. This time, however, bind-mount your <i>datasets</i> USB disk into the container, using the following command, substituting the correct path for your USB disk:</p>

<pre id="pre-200"><code><b>docker-compose run --rm -v </b><b><var>/Volumes/datasets</var></b><b>:/datasets:ro shell bash</b></code></pre>

<p class="TX">The arguments in this command are similar to the <samp class="SANS_TheSansMonoCd_W5Regular_11">--mount</samp> argument you used earlier to mount a volume with the <samp class="SANS_TheSansMonoCd_W5Regular_11">docker</samp> command. The <samp class="SANS_TheSansMonoCd_W5Regular_11">-v</samp> argument (short for <samp class="SANS_TheSansMonoCd_W5Regular_11">--volume</samp>) is followed by the colon-separated list <span role="doc-pagebreak" epub:type="pagebreak" id="pg_141" aria-label=" Page 141. "/><samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">/Volumes/datasets</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">:/datasets:ro</samp> containing three parts: the absolute path to the folder on the host operating system (on my computer, this is <i>/Volumes/datasets</i>), the absolute path to the folder in the container (<i>/datasets</i>), and the <samp class="SANS_TheSansMonoCd_W5Regular_11">ro</samp> option. Short for “read-only,” <samp class="SANS_TheSansMonoCd_W5Regular_11">ro</samp> gives the container permission to access the files in the bind mount but not to change any of them or create new files.</p>

<p class="TX">When you run this command, make sure to use the correct path for your USB disk. In macOS, the path is <i>/Volumes/datasets</i> or similar; in Linux, it’s <i>/media/micah/datasets</i> or similar; and in Windows with WSL, it’s <i>/mnt/d</i> or similar. If you’re using Windows with PowerShell, mount the <i>D:</i> drive into the container at the path <i>/datasets</i> with this command:</p>

<pre id="pre-201"><code><b>docker-compose run --rm -v D:/datasets:ro shell bash</b></code></pre>

<p class="TX">Altogether, this command runs a new <samp class="SANS_TheSansMonoCd_W5Regular_11">shell</samp> container and executes the <samp class="SANS_TheSansMonoCd_W5Regular_11">bash</samp> command inside of it. Your <i>datasets</i> folder on your host operating system becomes accessible as the folder <i>/datasets</i> in the container, and it’s mounted in read-only mode, preventing the container from modifying anything on the USB disk.</p>

<p class="TX">Now that you have access to your datasets within the Aleph shell, you’ll index the <i>icefishx</i> data.</p>

</section>

<section epub:type="division" aria-labelledby="sec20">

<h4 class="H2" id="sec20"><span id="h-129"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Index the icefishx Folder</samp></h4>

<p class="TNI">To index a dataset, you use the <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph crawldir</samp> command. Aleph’s use of the term <i>crawl</i> means to open the folder and index each file in it, then open each subfolder it finds and index each file in that, and so on, until everything in the original folder has been indexed.</p>

<p class="TX">Run the following command to start indexing the <i>icefishx</i> folder:</p>

<pre id="pre-202"><code><b>aleph crawldir -l eng /datasets/BlueLeaks-extracted/icefishx</b></code></pre>

<p class="TX">This command tells Aleph to index data in the <i>/datasets/BlueLeaks-extracted/icefishx</i> folder in the container (which is actually <i>/Volumes/datasets/BlueLeaks-extracted/icefishx</i> on my host operating system). The <samp class="SANS_TheSansMonoCd_W5Regular_11">-l</samp> option (short for <samp class="SANS_TheSansMonoCd_W5Regular_11">--language</samp>) helps you use OCR on documents. Because different languages use different alphabets and words, using <samp class="SANS_TheSansMonoCd_W5Regular_11">-l</samp> tells the OCR software what language you’re dealing with—in this case, English (<samp class="SANS_TheSansMonoCd_W5Regular_11">eng</samp>).</p>

<p class="TX">Aleph should begin to work its way through each of the 19,992 files in the <i>icefishx</i> folder, totaling over 2GB. The output should display the filename of each file, which is added to a list of files to crawl. Even before the <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph crawldir</samp> command finishes, Aleph begins to index each file.</p>

<p class="TX">Switch to your other terminal window running Docker Compose and watch the output as it indexes and performs OCR on each file.</p>
<blockquote>

<p class="NOTE"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp></span></p>
</blockquote>

<p class="NOTE-TXT"><i>You can use OCR for documents in languages other than English, too. To index a Russian dataset, for example, you’d use -<samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">l rus</samp> so that Aleph recognizes Russian words in the Cyrillic alphabet. Under the hood, Aleph uses software called Tesseract to do the OCR; for a list of valid language codes in Tesseract’s documentation, see</i> <a href="https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html"><span class="note_LinkURL_Italic">https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html</span></a><i>.</i></p>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_142" aria-label=" Page 142. "/>The <i>icefishx</i> folder took about an hour and a half to index on my Mac. It also used about 17GB worth of Docker volumes. Indexing larger quantities of data could take days and require much more disk space.</p>

</section>

<section epub:type="division" aria-labelledby="sec21">

<h4 class="H2" id="sec21"><span id="h-130"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Check Indexing Status</samp></h4>

<p class="TNI">After <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph crawldir</samp> has finished running, while you’re waiting for the indexing to complete, try a few more Aleph commands to query your Aleph server and check the indexing status.</p>

<p class="TX">First, run the following command to see a list of all of the datasets and investigations (known together as <i>collections</i>) in your Aleph server:</p>

<pre id="pre-203"><code>root@26430936533f:/aleph# <b>aleph collections</b>

Foreign ID                                         ID  Label

-----------------------------------------------  ----  ------------------

28c82cbe1ba247e6a16e3fb4b7d50a67                    1  Test Investigation

directory:datasets-blueleaks-extracted-icefishx     2  icefishx</code></pre>

<p class="TX">The <samp class="SANS_TheSansMonoCd_W5Regular_11">Foreign ID</samp> field is the unique identifier for each dataset, and the <samp class="SANS_TheSansMonoCd_W5Regular_11">Label</samp> field is the human-readable name for the dataset displayed in the Aleph web application. I used the Aleph web interface to create a new investigation called Test Investigation before I started indexing <i>icefishx</i>, so I have two collections. When you use the web interface to make investigations, they get assigned completely random foreign IDs. When you use <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph crawldir</samp> to create them, the <samp class="SANS_TheSansMonoCd_W5Regular_11">Foreign ID</samp> is based on the filesystem path that you’re indexing; alternatively, you can use the <samp class="SANS_TheSansMonoCd_W5Regular_11">-f</samp> <samp class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">foreign_id</samp> arguments to specify your own if you like.</p>

<p class="TX">Next, run the following command while indexing <i>icefishx</i> to check the status of the indexing:</p>

<pre id="pre-204"><code>root@26430936533f:/aleph# <b>aleph status</b>

  Collection  Job                               Stage       Pending     Running    Finished

------------  --------------------------------  -------   ---------   ---------  ----------

           2                                                  19263           4        3387

           2  a4bb59c4e23b4b96b14d747ff78c69e2  ingest        19239           3        1145

           2  a4bb59c4e23b4b96b14d747ff78c69e2  analyze          24           1        1123

           2  a4bb59c4e23b4b96b14d747ff78c69e2  index             0           0        1119</code></pre>

<p class="TX">This command displays a table of data that tells you the number of pending, running, and finished tasks for each collection that’s indexing, split into <samp class="SANS_TheSansMonoCd_W5Regular_11">analyze</samp>, <samp class="SANS_TheSansMonoCd_W5Regular_11">ingest</samp>, and <samp class="SANS_TheSansMonoCd_W5Regular_11">index</samp> phases. The <samp class="SANS_TheSansMonoCd_W5Regular_11">Collection</samp> column shows the ID of the collection—if you look back at the output of <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph collections</samp>, the ID of the ICEFISHX dataset is <samp class="SANS_TheSansMonoCd_W5Regular_11">2</samp>. When I ran <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph status</samp>, based on the total pending and finished numbers, indexing was roughly 15 percent complete (though this might be misleading; for example, one of those pending files could be a ZIP file containing another 1,000 files).</p>

<p class="TX">If Aleph breaks in the middle of indexing a dataset, you can recover your progress. If you’re seeing a lot of error messages in the Docker Compose logs or in the Aleph web interface, the simplest solution is to restart the <span role="doc-pagebreak" epub:type="pagebreak" id="pg_143" aria-label=" Page 143. "/>containers. In your Docker Compose terminal window, you’d press <small>CTRL</small>-C to quit all of the containers and then run <samp class="SANS_TheSansMonoCd_W5Regular_11">docker-compose up</samp> to start them again. After a few minutes, your containers should finish booting and the indexing should commence where it left off. If something failed before your <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph crawldir</samp> command finished running in the Aleph shell, you can run <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph crawldir</samp> again. This will reindex the entire dataset, but it should be quicker the second time around, because it won’t redo time-consuming tasks like performing OCR on documents that have already been processed.</p>

<p class="TX">You can also check the indexing status via the Aleph web interface. In your browser, navigate to the Investigations page. From there, click the ICEFISHX investigation, and you should see a progress bar showing you how the indexing is doing. <span class="Xref"><a href="#fig5-4">Figure 5-4</a></span> shows the indexing status from inside the web application.</p>
<figure class="IMG"><img class="img100" id="fig5-4" src="Images/Figure5-4.png" alt="A screenshot of Aleph showing that the ICEFISHX dataset is 29% finished indexing." width="846" height="289"/>

<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 5-4: The ICEFISHX dataset in the process of indexing</samp></p></figcaption>

</figure>

<p class="TX">While you’re here, click the gear icon in the top-right corner of the screen and go to <b>Settings</b>. From there you can change the label, category, and summary of this dataset. For example, you can change the label from <i>icefishx</i> to something more descriptive, like <i>BlueLeaks: Intelligence Communications Enterprise for Information Sharing and Exchange (ICEFISHX)</i>. The default category is Investigations. If you change it to anything else, like Leaks, Court Archives, or Other Material, ICEFISHX will appear under Datasets instead of Investigations. For now, stick with the Investigations category.</p>

<p class="TX">Sit back and wait for Aleph to finish indexing the ICEFISHX dataset before moving on to the next section, where you’ll begin to use Aleph to explore the data.</p>
<blockquote>

<p class="NOTE"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp></span></p>
</blockquote>

<p class="NOTE-TXT"><i>It’s possible to start looking through datasets in Aleph before indexing is complete, but it’s best to wait for the full index to finish before digging too deep. If you don’t, you’ll search only the data that’s been indexed to that point, so your searches might miss important documents.</i></p>

</section>
</section>

<section epub:type="division" aria-labelledby="sec22">

<h3 class="H1" id="sec22"><span id="h-131"/><span role="doc-pagebreak" epub:type="pagebreak" id="pg_144" aria-label=" Page 144. "/><samp class="SANS_Futura_Std_Bold_B_11">Explore BlueLeaks with Aleph</samp></h3>

<p class="TNI">Once you’ve finished indexing the <i>icefishx</i> folder, navigate to the ICEFISHX dataset you’ve just imported in the Aleph web interface. It should be listed under the Investigations link at the top of the page. The Documents link in the left sidebar lets you manually browse the files in the dataset and open various documents, but where Aleph really shines is its search engine.</p>

<p class="TX">When you enter a term in the search field, Aleph searches every dataset you’ve imported. You can filter your results in a variety of ways, using the left sidebar: for example, you can filter to a specific dataset, a specific date range, or even to documents that mention specific email addresses, phone numbers, or names. Once you’ve filtered the search results, you can click on documents to preview them.</p>

<p class="TX"><a href="#fig5-5">Figure 5-5</a> shows some of the 335 search results for the term <i>George Floyd</i> in the ICEFISHX dataset.</p>
<figure class="IMG"><img class="img100" id="fig5-5" src="Images/Figure5-5.png" alt="A screenshot of Aleph search results, with a document selected that’s titled “Possibility for Increased Threatening Activity towards Law Enforcement and Government Officials Following Worldwide Coverage of Minneapolis In-Custody Death.”" width="845" height="571"/>

<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 5-5: Aleph’s search interface with results returned for the term</samp> <samp class="SANS_Futura_Std_Book_11">George Floyd</samp></p></figcaption>

</figure>

<p class="TX">The document selected in <a href="#fig5-5">Figure 5-5</a>, classified as U//LES (Unclassified, Law Enforcement Sensitive), was created by the Minnesota Fusion Center on May 27, 2020. It warns of an increase in threatening activity toward law enforcement officers in response to George Floyd’s murder in police custody two days earlier. According to the document, two of the four officers involved had been doxed, and people protested outside one of <span role="doc-pagebreak" epub:type="pagebreak" id="pg_145" aria-label=" Page 145. "/>their homes. Thousands of people began marching in the streets, and there were “increased discussions on White Supremacist Extremist (WSE) online forums.” The document recommends that police “avoid wearing organizationally-affiliated clothing outside of work settings,” “reduce social media footprint and use an alias,” and consider “varying travel patterns to avoid surveillance.”</p>

<p class="TX">Aleph makes it easy to find connections between documents. If you click Expand in the top left of the selected document, you should end up at that document’s detail page. This page shows the document’s metadata on the left, as well as any names or email addresses it finds that are also mentioned in other documents. If you click on one of those—for example, on someone’s name or email—you should be taken to search results that list all of the documents mentioning that person.</p>

<p class="TX">When you’re done exploring <i>icefishx</i>, try indexing additional folders in BlueLeaks or even the entire <i>BlueLeaks-extracted</i> folder.</p>

</section>

<section epub:type="division" aria-labelledby="sec23">

<h3 class="H1" id="sec23"><span id="h-132"/><samp class="SANS_Futura_Std_Bold_B_11">Additional Aleph Features</samp></h3>

<p class="TNI">There’s a lot more to Aleph than what we’ve covered so far. This section will introduce a few of the other cool things it can do, which you’ll find useful in the future as you continue to analyze hacked and leaked datasets. As you’ve seen, Aleph is great at indexing folders full of a wide variety of documents, but it also supports importing <i>structured data</i>—data that follows a consistent and well-defined data model. Entities in Aleph, which I mentioned earlier, are an example of structured data. Specifically, Aleph uses a data model called FollowTheMoney, which contains types of entities like Person, Company, Organization, or Address. Learn more about the FollowTheMoney data model and how to import these entities directly into Aleph at <a href="https://followthemoney.tech"><i>https://<wbr/>followthemoney<wbr/>.tech</i></a>.</p>

<p class="TX">When you index a dataset in Aleph, it automatically extracts its best guess at entities—data like the names of people and companies, and phone numbers and addresses—but its guesses are far from perfect. Aleph also allows you to manually create and edit entities in more detail. You can add a list of people to an investigation, for example, providing not just their names but also their contact information and any relationships they have to other entities like their employers. When you’re viewing an entity in Aleph’s web interface, it shows you all of the data about that entity and links to all of its related entities.</p>

<p class="TX">You can also generate entities from data in spreadsheets like CSV or Excel files. For example, the ICEFISHX dataset has a spreadsheet called <i>Registrations.csv</i> that lists the name, rank, agency, home address, email address, phone number, supervisor, and other information about all 6,000 people who had accounts on the site. From the detail page of this file in the Aleph web interface, you can click Generate Entities to define exactly how this data should map to entities, and even how these entities should relate to other entities. This could help you build an organization chart of who reports to whom, for example.</p>

<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_146" aria-label=" Page 146. "/>In addition to the <samp class="SANS_TheSansMonoCd_W5Regular_11">aleph crawldir</samp> command you used in Exercise 5-5, there are other ways to index data into Aleph. First, you can use a different CLI program called <samp class="SANS_TheSansMonoCd_W5Regular_11">alephclient</samp>, which allows you to index data and push it into a remote Aleph server over the internet using Aleph’s application programming interface (API), without opening an Aleph shell. APIs are designed to allow software, rather than humans, to communicate. Every user on an Aleph server (or, if it’s a server with users disabled, the whole server) has an API secret access key, a credential that allows software to add data to, or otherwise interact with, the Aleph server. You can pass this API key into <samp class="SANS_TheSansMonoCd_W5Regular_11">alephclient</samp> as an argument to index large datasets on an Aleph server that someone else runs. The command to install <samp class="SANS_TheSansMonoCd_W5Regular_11">alephclient</samp> is <samp class="SANS_TheSansMonoCd_W5Regular_11">python3 -m pip install alephclient</samp>.</p>

<p class="TX">Alternatively, you can create a new investigation directly in the web interface by clicking Investigations at the top, then New Investigation. You’ll be prompted to give your investigation a title and an optional summary and language. You can upload files to your investigation directly from your web browser. This is useful if you want to upload a spreadsheet of names and email address and cross-reference it with the rest of the data in your Aleph server. For uploading big datasets like BlueLeaks, however, using the Aleph shell or <samp class="SANS_TheSansMonoCd_W5Regular_11">alephclient</samp> is easier and less error-prone.</p>

<p class="TX">One of Aleph’s most powerful features is its ability to search multiple datasets at once. For example, you could index the BlueLeaks dataset, the Oath Keepers dataset you downloaded in <span class="Xref"><a href="chapter4.xhtml">Chapter 4</a></span>, and several others to search them all for someone’s name, email address, or phone number. Since the BlueLeaks dataset is full of PII of law enforcement officers and the Oath Keepers militia is known to recruit retired police, you could check if any Oath Keepers members or donors are mentioned in BlueLeaks. (I recommend waiting to try this until you further explore the Oath Keepers dataset in <span class="Xref"><a href="chapter6.xhtml">Chapter 6</a></span>.)</p>

<p class="TX">Aleph can also cross-reference the entities from one dataset with entities in all of the other datasets that have been indexed in a server. Navigating to an investigation and clicking Cross-Reference in the left sidebar allows you to compare each entity in the investigation with entities in every other dataset or investigation. For example, you could upload a spreadsheet of people you’re investigating—say, everyone who works at the White House—into an investigation, use the Generate Entities feature to convert it into a detailed list of Person entities, and then cross-reference this list with all of the other datasets you’ve indexed to see if any White House employees show up in them.</p>

<p class="TX">Spend some time experimenting with Aleph and getting to know its features on your own. When DDoSecrets publishes a dataset that you’re interested in, try downloading it and indexing it in Aleph. Explore searching multiple datasets at once as well as using the cross-referencing feature. Aleph’s documentation is available at <a href="https://docs.aleph.occrp.org"><i>https://<wbr/>docs<wbr/>.aleph<wbr/>.occrp<wbr/>.org</i></a>.</p>

</section>

<section epub:type="division" aria-labelledby="sec24">

<h3 class="H1" id="sec24"><span id="h-133"/><span role="doc-pagebreak" epub:type="pagebreak" id="pg_147" aria-label=" Page 147. "/><samp class="SANS_Futura_Std_Bold_B_11">Dedicated Aleph Servers</samp></h3>

<p class="TNI">Running Aleph in containers on your computer works well if you want to search just a few small datasets yourself. However, to index a large amount of data (such as all of BlueLeaks) that will stretch your laptop’s computational resources, or to work with others on the same datasets, consider setting up a dedicated Aleph server instead. Full instructions on doing that are outside the scope of this book, but this section provides an introduction.</p>

<p class="TX">In <span class="Xref"><a href="chapter4.xhtml">Chapter 4</a></span>, you learned how to create servers in the cloud; earlier in this chapter, you learned how to set up your own Aleph server. By combining those skills, you should be able to set up Aleph running in Docker containers on a cloud server. However, you’ll also need to decide how to secure the server and make sure it stays updated. How will you manage its users, and how will you restrict access to the server? How will you know and what will you do if someone hacks it? To run an Aleph server for your organization, I recommend that you bring in a professional system administrator or DevOps engineer to set it up and maintain it over time.</p>

<p class="TX">As you set up your server, consider the security levels of the datasets on which you plan to use Aleph. For low- to medium-security datasets, you can host Aleph in a cloud server, which allows you to temporarily give your server more RAM or processing power to index a dataset more quickly. For medium- to high-security datasets, host Aleph on physical hardware, like a server in an office or in a server closet in a data center. Decide whether to require people to come into the office to use Aleph or to configure it so that they can access it over the internet. If you choose the latter, you’ll need to secure your Aleph server and the data it contains. For the highest-security datasets, you’ll have to download Linux containers on a computer with internet access, export the datasets, and import them on an air-gapped server.</p>
<aside class="box" aria-labelledby="box-17">

<h4 class="BH" id="box-17"><samp class="SANS_Dogma_OT_Bold_B_11">INTELLA AND DATASHARE</samp></h4>

<p class="BoxBodyFirst"><samp class="SANS_Futura_Std_Book_11">You can use software besides Aleph to help you make datasets searchable. As mentioned in <a href="chapter1.xhtml">Chapter 1</a>, the first leaked dataset I worked on was the Snowden Archive. At that time, Aleph didn’t exist. To index and search the Snowden Archive, we used proprietary software called Intella, installed on air-gapped Windows laptops. Intella, developed by Vound Software, is investigation software that was designed for law firms and law enforcement to explore large datasets, like email dumps or the contents of seized computers.</samp></p>

<p class="BoxBody"><samp class="SANS_Futura_Std_Book_11">The Intercept used to have a license for Intella Connect, a web-based version of Intella. This software has a few advantages over Aleph: it rarely has technical issues, it comes with tech support, and it allows you to index and search large datasets faster. Like Aleph, Intella Connect supports collaborating with multiple users. After Russia invaded Ukraine in 2022 and hackers started</samp> <span role="doc-pagebreak" epub:type="pagebreak" id="pg_148" aria-label=" Page 148. "/><samp class="SANS_Futura_Std_Book_11">dumping</samp> <samp class="SANS_Futura_Std_Book_11">terabytes of data from Russian companies online, I began downloading and indexing all of these datasets into Intella Connect. I quickly found that this project was far too complicated for The Intercept alone to handle, especially considering that all of the data was in Russian. I helped spearhead a project to invite outside journalists who spoke Russian or were interested in these datasets to use our Intella service. This project grew into a major international collaboration with OCCRP and dozens of reporters around the world, including both Russian and Ukrainian journalists, to research the Russian datasets. The project’s collaborators used both Intella Connect and OCCRP’s Aleph server, and we organized our findings on an internal wiki.</samp></p>

<p class="BoxBody"><samp class="SANS_Futura_Std_Book_11">The Intercept has now decided to stop paying for Intella Connect and uses Aleph exclusively instead. Intella has some disadvantages: it doesn’t have Aleph’s ability to cross-reference between datasets and map out relationships between entities, it’s quite expensive, and it requires Windows.</samp></p>

<p class="BoxBodyLast"><samp class="SANS_Futura_Std_Book_11">Another open source tool for indexing datasets is Datashare, developed by ICIJ, the group that worked in a coalition on the Panama Papers dataset along with OCCRP. Datashare is similar to Aleph but is designed for a single user to run it locally on their computer, rather than on a server. Like Aleph, Datashare runs inside of Docker containers. While it’s a very promising project, I ran into issues trying to install it at the time of writing. Because it’s open source and actively developed, however, I expect this will improve over time. You can read more about Datashare at</samp> <a href="https://datashare.icij.org"><samp class="SANS_Futura_Std_Book_Oblique_I_11">https://datashare.icij.org</samp></a> <samp class="SANS_Futura_Std_Book_11">and</samp> <a href="https://github.com/ICIJ/datashare"><samp class="SANS_Futura_Std_Book_Oblique_I_11">https://github.com/ICIJ/datashare</samp></a><samp class="SANS_Futura_Std_Book_11">.</samp></p>
</aside>
</section>

<section epub:type="division" aria-labelledby="sec25">

<h3 class="H1" id="sec25"><span id="h-134"/><samp class="SANS_Futura_Std_Bold_B_11">Summary</samp></h3>

<p class="TNI">In this chapter, you’ve learned how to run software in Linux containers using Docker, then applied those skills to run Aleph on your computer and index the <i>icefishx</i> folder from BlueLeaks, making it searchable. A search for the keyword <i>George Floyd</i> uncovered interesting law enforcement documents about the 2020 racial justice protests that you couldn’t have uncovered with just <samp class="SANS_TheSansMonoCd_W5Regular_11">grep</samp>. You’ve also learned about some Aleph features you can explore on your own, the possibility of running a dedicated Aleph server instead of running it on your laptop, and dataset-indexing tools other than Aleph.</p>

<p class="TX">You’ll revisit Docker in <span class="Xref"><a href="chapter10.xhtml">Chapter 10</a></span>, when you learn to use BlueLeaks Explorer, and in <span class="Xref"><a href="chapter12.xhtml">Chapter 12</a></span>, when you learn about SQL databases. In the following chapter, you’ll learn the tools and techniques required to dig through one of the most prevalent forms of data leaks: email dumps.</p>

</section>
</section>

</div></body></html>