- en: '**7'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: COMPOSITE DATA TYPES AND MEMORY OBJECTS**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/comm1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Composite data types are composed of other, more primitive, types. Examples
    include pointers, arrays, records or structures, tuples, and unions. Many high-level
    languages (HLLs) provide syntactical abstractions for these composite data types
    that make them easy to declare and use, while hiding their underlying complexities.
  prefs: []
  type: TYPE_NORMAL
- en: Though the costs of using these composite data types are not terrible, a programmer
    who doesn’t understand them can easily introduce inefficiencies into an application.
    This chapter provides an overview of those costs to better enable you to write
    great code.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.1 Pointer Types**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *[pointer](gloss01.xhtml#gloss01_194)* is a variable whose value refers to
    some other object. High-level languages like Pascal and C/C++ hide the simplicity
    of pointers behind a wall of abstraction. This added complexity can be intimidating
    if you don’t understand what’s going on behind the scenes. However, a little knowledge
    will go a long way toward easing your mind.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with something simple: an array. Consider the following array declaration
    in Pascal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`M` is an array with 1,024 integers in it, indexed from `M[0]` to `M[1023]`.
    Each array element can hold an integer value that is independent of the others.
    In other words, this array gives you 1,024 different integer variables, each of
    which you access via array index rather than by name.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The statement `M[0]:=100` stores the value `100` into the first element of
    the array `M`. Now consider the following two statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'These two statements do the same thing as `M[0]:=100;`. You can use any integer
    expression in the range `0` through `1023` as an index of this array. The following
    statements *still* perform the same operation as the earlier statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: But how about the following?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Whoa! Now that takes a few moments to digest. However, if you take it slowly,
    you’ll realize that these two instructions perform the same operation as before.
    The first statement stores `0` into array element `M[1]`. The second statement
    fetches the value of `M[1]`, which is `0`, and uses that value to determine where
    it stores the value `100`.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re willing to accept this example as reasonable—perhaps bizarre, but
    usable nonetheless—then you’ll have no problems with pointers, because `M[1]`
    is a pointer! Well, not really, but if you were to change `M` to “memory” and
    treat each element of this array as a separate memory location, then this meets
    the definition of a pointer—that is, a memory variable whose value is the address
    of some other memory object.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.1.1 Pointer Implementation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although most languages implement pointers using memory addresses, a pointer
    is actually an abstraction of a memory address. Therefore, a language could define
    a pointer using any mechanism that maps the value of the pointer to the address
    of some object in memory. Some implementations of Pascal, for example, use offsets
    from some fixed memory address as pointer values. Some languages (including dynamic
    languages like LISP) implement pointers by using *double indirection*; that is,
    the pointer object contains the address of some memory variable whose value is
    the address of the object to be accessed. This approach may seem convoluted, but
    it offers certain advantages in a complex memory management system. However, for
    simplicity’s sake, this chapter will assume that, as defined earlier, a pointer
    is a variable whose value is the address of some other object in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you’ve seen in examples from previous chapters, you can indirectly access
    an object using a pointer with two 32-bit 80x86 machine instructions (or with
    a similar sequence on other CPUs), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Access to data via double indirection is less efficient than the straight pointer
    implementation because it takes an extra machine instruction to fetch the data
    from memory. This isn’t obvious in an HLL like C/C++ or Pascal, where you’d use
    double indirection as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This looks very similar to single indirection. In assembly language, however,
    you’ll see the extra work involved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Contrast this with the two earlier assembly instructions needed to access an
    object using single indirection. Because double indirection requires 50 percent
    more code than single indirection, many languages implement pointers using single
    indirection.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.1.2 Pointers and Dynamic Memory Allocation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pointers typically reference anonymous variables that you allocate on the *[heap](gloss01.xhtml#gloss01_109)*
    (a region in memory reserved for dynamic storage allocation) using memory allocation/deallocation
    functions like `malloc()`/`free()` in C, `new()`/`dispose()` in Pascal, and `new()`/`delete()`
    in C++ (note, however, that C++11 and later prefer `std::unique_ptr` and `std_shared_ptr`
    for memory allocation, with automatic memory deallocation). Java, Swift, C++11
    (and later) and other more modern languages only provide a function equivalent
    to `new()`. These languages handle deallocation automatically via garbage collection.
  prefs: []
  type: TYPE_NORMAL
- en: Objects you allocate on the heap are known as *[anonymous variables](gloss01.xhtml#gloss01_12)*
    because you refer to them by their address rather than by a name. And because
    the allocation functions return the address of an object on the heap, you typically
    store the function’s return result into a pointer variable. While the pointer
    variable may have a name, that name applies to the pointer’s data (an address),
    not the object referenced by this address.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.1.3 Pointer Operations and Pointer Arithmetic***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most languages that provide the pointer data type let you assign addresses to
    pointer variables, compare pointer values for equality or inequality, and indirectly
    reference an object via a pointer. Some languages allow additional operations,
    as you’ll see in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many languages enable you to do limited arithmetic with pointers. At the very
    least, these languages provide the ability to add an integer constant to, or subtract
    one from, a pointer. To understand the purpose of these two arithmetic operations,
    note the syntax of the `malloc()` function in the C standard library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The parameter you pass `malloc()` specifies the number of bytes of storage
    to allocate. A good C programmer generally supplies an expression like `sizeof(int)`
    as this parameter. The `sizeof()` function returns the number of bytes needed
    by its single parameter. Therefore, `sizeof(int)` tells `malloc()` to allocate
    at least enough storage for an `int` variable. Now consider the following call
    to `malloc()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If the size of an integer is 4 bytes, this call to `malloc()` will allocate
    storage for 32 bytes, at consecutive addresses in memory (see [Figure 7-1](ch07.xhtml#ch07fig01)).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-1: Memory allocation with `malloc(sizeof(int) * 8)`*'
  prefs: []
  type: TYPE_NORMAL
- en: The pointer that `malloc()` returns contains the address of the first integer
    in this set, so the C program can directly access only the very first of these
    eight integers. To access the individual addresses of the other seven integers,
    you need to add an integer offset to that *base* address. On machines that support
    byte-addressable memory (such as the 80x86), the address of each successive integer
    in memory is the address of the previous integer plus the integer’s size. For
    example, if a call to the C standard library `malloc()` routine returns the memory
    address `$0300_1000`, then the eight integers that `malloc()` allocates will reside
    at the memory addresses shown in [Table 7-1](ch07.xhtml#ch07tab01).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 7-1:** Integer Addresses Allocated for Base Address `$0300_1000`'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Integer** | **Memory addresses** |'
  prefs: []
  type: TYPE_TB
- en: '| `0` | `$0300_1000..$0300_1003` |'
  prefs: []
  type: TYPE_TB
- en: '| `1` | `$0300_1004..$0300_1007` |'
  prefs: []
  type: TYPE_TB
- en: '| `2` | `$0300_1008..$0300_100b` |'
  prefs: []
  type: TYPE_TB
- en: '| `3` | `$0300_100c..$0300_100f` |'
  prefs: []
  type: TYPE_TB
- en: '| `4` | `$0300_1010..$0300_1013` |'
  prefs: []
  type: TYPE_TB
- en: '| `5` | `$0300_1014..$0300_1017` |'
  prefs: []
  type: TYPE_TB
- en: '| `6` | `$0300_1018..$0300_101b` |'
  prefs: []
  type: TYPE_TB
- en: '| `7` | `$0300_101c..$0300_101f` |'
  prefs: []
  type: TYPE_TB
- en: '**7.1.3.1 Adding an Integer to a Pointer**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Because these integers described in the preceding section are exactly 4 bytes
    apart, we add 4 to the address of the first integer to obtain the address of the
    second integer; add 4 to the address of the second integer to get the address
    of the third integer; and so on. In assembly language, we could access these eight
    integers using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Notice the use of the 80x86 indexed addressing mode to access the eight integers
    that `malloc()` allocates. The EAX register maintains the base (first) address
    of the eight integers that this code allocates, and the constant in the addressing
    mode of the `mov()` instructions selects the offset of the specific integer from
    this base address.
  prefs: []
  type: TYPE_NORMAL
- en: Most CPUs use byte addresses for memory objects. Therefore, when a program allocates
    multiple copies of some *n*-byte object in memory, the objects won’t begin at
    consecutive memory addresses; instead, they’ll appear in memory at addresses that
    are *n* bytes apart. Some machines, however, don’t allow a program to access memory
    at an arbitrary address in memory; rather, they require it to access data on address
    boundaries that are a multiple of a word, a double word, or even a quad word.
    Any attempt to access memory on some other boundary will raise an exception and
    potentially halt the application. If an HLL supports pointer arithmetic, it must
    account for this fact and provide a generic pointer arithmetic scheme that’s portable
    across many different CPU architectures. The most common solution that HLLs use
    when adding an integer offset to a pointer is to multiply that offset by the size
    of the object that the pointer references. That is, if you’ve got a pointer `p`
    to a 16-byte object in memory, then `p + 1` points 16 bytes beyond the address
    where `p` points. Likewise, `p + 2` points 32 bytes beyond that address. As long
    as the size of the data object is a multiple of the required alignment size (which
    the compiler can enforce by adding padding bytes, if necessary), this scheme avoids
    problems on those architectures that require aligned data access.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the addition operator only makes sense between a pointer and an integer
    value. For example, in C/C++ you can indirectly access objects in memory using
    an expression like `*(p + i)` (where `p` is a pointer to an object and `i` is
    an integer value). It doesn’t make sense to add two pointers together, or to add
    other data types to a pointer. For example, adding a floating-point value to a
    pointer isn’t logical. (What would it mean to reference the data at some base
    address plus 1.5612?) Integers—signed and unsigned—are the only reasonable values
    to add to a pointer.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, not only can you add an integer to a pointer, but you can
    also add a pointer to an integer and the result is still a pointer (both `p` `+`
    `i` and `i` `+` `p` are legal). This is because addition is *[commutative](gloss01.xhtml#gloss01_55)*—the
    order of the operands does not affect the result.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.1.3.2 Subtracting an Integer from a Pointer**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Subtracting an integer from a pointer references a memory location immediately
    before the address held in the pointer. However, subtraction is not commutative,
    and subtracting a pointer from an integer is not a legal operation (`p` `-` `i`
    is legal, but `i` `-` `p` is not).
  prefs: []
  type: TYPE_NORMAL
- en: In C/C++ `*(p` `-` `i)` accesses the `ith` ^(object immediately before the object
    at which `p` points. In 80x86 assembly language, as in assembly on many processors,
    you can also specify a negative constant offset when using an indexed addressing
    mode. For example:)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that 80x86 assembly language uses byte offsets, not object offsets
    (as C/C++ does). Therefore, this statement loads into EAX the double word in memory
    immediately preceding the memory address in EBX.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.1.3.3 Subtracting a Pointer from a Pointer**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In contrast to addition, it makes sense to subtract the value of one pointer
    variable from another. Consider the following C/C++ code, which proceeds through
    a string of characters looking for the first `e` character that follows the first
    `a` that it finds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Subtracting one pointer from the other produces the number of data objects that
    exist between them (in this case, `ePtr` and `aPtr` point at characters, so the
    subtraction result produces the number of characters, or bytes, between the two
    pointers).
  prefs: []
  type: TYPE_NORMAL
- en: The subtraction of two pointer values makes sense only if they both reference
    the same data structure (for example, pointing at characters within the same string,
    as in this C/C++ example) in memory. Although C/C++ (and certainly assembly language)
    will allow you to subtract two pointers that point at completely different objects
    in memory, the result will probably have very little meaning.
  prefs: []
  type: TYPE_NORMAL
- en: For pointer subtraction in C/C++, the base types of the two pointers must be
    identical (that is, the two pointers must contain the addresses of two objects
    whose types are identical). This restriction exists because pointer subtraction
    in C/C++ produces the number of objects, not the number of bytes, between the
    two pointers. It wouldn’t make any sense to compute the number of objects between
    a byte in memory and a double word in memory; would you be counting the number
    of bytes or the number of double words? In assembly language you can get away
    with this (and the result is always the number of bytes between the two pointers),
    but it still doesn’t make much sense semantically.
  prefs: []
  type: TYPE_NORMAL
- en: The subtraction of two pointers could return a negative number if the left pointer
    operand is at a lower memory address than the right pointer operand. Depending
    on your language and its implementation, you may need to take the absolute value
    of the result if you’re interested only in the distance between the two pointers
    and you don’t care which pointer contains the greater address.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.1.3.4 Comparing Pointers**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Almost every language that supports pointers will let you compare two pointers
    to see whether or not they are equal. Comparing two pointers will tell you whether
    they reference the same object in memory. Some languages (such as assembly and
    C/C++) will also let you compare two pointers to see if one pointer is less than
    or greater than the other. Such a comparison only makes sense, however, if both
    pointers have the same base type and contain the address of some object within
    the same data structure (such as an array, string, or record). If you find that
    one pointer is less than the other, this tells you that it references an object
    within the data structure that appears before the object referenced by the second
    pointer. The converse is true for the greater-than comparison.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.2 Arrays**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After strings, arrays are probably the most common composite (or *aggregate*)
    data type. Abstractly, an array is an aggregate data type whose members (elements)
    are all of the same type. You select a member from the array by specifying its
    array index with an integer (or with some value whose underlying representation
    is an integer, such as character, enumerated, and Boolean types). In this chapter,
    we’ll assume that the integer indices of an array are numerically contiguous (though
    this is not required). That is, if both `x` and `y` are valid indices of the array,
    and if `x` `<` `y`, then all `i` such that `x` `<` `i` `<` `y` are also valid
    indices. We’ll also assume that array elements occupy contiguous locations in
    memory. Therefore, an array with five elements will appear in memory as shown
    in [Figure 7-2](ch07.xhtml#ch07fig02).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-2: Array layout in memory*'
  prefs: []
  type: TYPE_NORMAL
- en: The *base address* of an array is the address of its first element and occupies
    the lowest memory location. The second array element directly follows the first
    in memory, the third element follows the second, and so on. There is no requirement
    that the indices start at `0`; they can start with any number as long as they’re
    contiguous. However, we’ll begin arrays at index `0` unless there’s a good reason
    to do otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever you apply the indexing operator to an array, the result is the array
    element specified by that index. For example, `A[i]` chooses the `i`th element
    from array `A`.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.2.1 Array Declarations***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Array declarations are very similar across many HLLs. C, C++, and Java all
    let you declare an array by specifying the total number of elements in it. The
    syntax for an array declaration in these languages is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some sample C/C++ array declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If you declare these arrays as automatic variables, then C/C++ “initializes”
    them with whatever bit patterns exist in memory. If, on the other hand, you declare
    these arrays as static objects, then C/C++ zeros out each array element. If you
    want to initialize an array yourself, you can use the following C/C++ syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a typical example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Swift array declarations are a bit different from other C-based languages.
    Swift array declarations take one of the following two (equivalent) forms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike other languages, arrays in Swift are purely dynamic. You don’t normally
    specify the number of elements when you first create the array; instead, you add
    elements to the array as needed using functions like `append()` or `insert()`.
    If you want to predeclare an array with some number of elements, you use this
    special array constructor form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, initial_value is a value of type element_type and elements
    is the number of array elements to create in the array. For example, the following
    Swift code creates two arrays of 100 `Int` values, each initialized to `0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You can still extend the size of this array (for example, by using the `append()`
    function); because Swift arrays are dynamic, their size can grow or shrink at
    runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'Swift arrays can be created with initial values, as these examples demonstrate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'C# arrays are also dynamic objects; though their syntax is slightly different
    from Swift, the concept is the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Here, type is the data type (for example, `double` or `int`), array_name is
    the array variable name, and elements is the number of elements to allocate in
    the array.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also initialize C# arrays in a declaration as follows (other syntaxes
    are possible; this is just a simple example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The array declaration syntax in HLA (High-Level Assembly) takes the following
    form, which is semantically equivalent to the C/C++ declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some examples of HLA array declarations that allocate storage for
    uninitialized arrays (the second example assumes that you have defined the `integer`
    data type in a `type` section of the HLA program):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also initialize the array elements using declarations like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Both of these definitions create arrays with eight elements. The first definition
    initializes each 4-byte `real32` array element with one of the values in the range
    `0.0` through `7.0`. The second declaration initializes each `integer` array element
    with one of the values in the range `8` through `15`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pascal/Delphi uses the following syntax to declare an array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'As in the previous examples, array_name is the identifier, and data_type is
    the type of each element in this array. Unlike C/C++, Java, Swift, and HLA, in
    Free Pascal/Delphi you specify the upper and lower bounds of the array rather
    than the array’s size. The following are typical array declarations in Pascal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Although these Pascal examples start their indices at `0`, Pascal does not
    require it. The following Pascal array declaration is also perfectly valid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The program that declares this array would use indices `1998` through `2039`
    when accessing elements of this array, not `0` through `41`.
  prefs: []
  type: TYPE_NORMAL
- en: Many Pascal compilers provide a very useful feature to help you locate defects
    in your programs. Whenever you access an element of an array, these compilers
    automatically insert code that will verify that the array index is within the
    bounds specified by the declaration. This extra code will stop the program if
    the index is out of range. For example, if an index into `Profits``ByYear` is
    outside the range `1998` through `2039`, the program will abort with an error.^([1](footnotes.xhtml#fn7_1a))
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, array indices are integer values, though some languages allow other
    *ordinal types* (data types that use an underlying integer representation). For
    example, Pascal allows `char` and `boolean` array indices. In Pascal, it’s perfectly
    reasonable and useful to declare an array as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'You access elements of `alphaCnt` using a character expression as the array
    index. For example, consider the following Pascal code, which initializes each
    element of `alphaCnt` to `0` (assuming `ch:char` appears in the `var` section):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Assembly language and C/C++ treat most ordinal values as special instances of
    integer values, so they are legal array indices. Most implementations of BASIC
    allow a floating-point number as an array index, though BASIC always truncates
    the value to an integer before using it as an index.^([2](footnotes.xhtml#fn7_2a))
  prefs: []
  type: TYPE_NORMAL
- en: '***7.2.2 Array Representation in Memory***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Abstractly, an array is a collection of variables that you access using an index.
    Semantically, we can define an array any way we please, as long as it maps distinct
    indices to distinct objects in memory and always maps the same index to the same
    object. In practice, however, most languages use a few common algorithms that
    provide efficient access to the array data.
  prefs: []
  type: TYPE_NORMAL
- en: The number of bytes of storage an array consumes is the product of the number
    of elements multiplied by the number of bytes per element in the array. Many languages
    also add a few bytes of padding at the end of the array so that the total length
    of the array is an even multiple of a nice value like 4 or 8 (on a 32- or 64-bit
    machine, a compiler may append bytes to the array in order to extend its length
    to some multiple of the machine’s word size). However, a program must *not* depend
    on these extra padding bytes, because they may or may not be present. Some compilers
    always put them in, some never do, and still others put them in depending on the
    type of object that immediately follows the array in memory.
  prefs: []
  type: TYPE_NORMAL
- en: Many optimizing compilers attempt to start an array at a memory address that
    is an even multiple of some common size like 2, 4, or 8 bytes. Effectively, this
    adds padding bytes before the beginning of the array or, if you prefer to think
    of it this way, after the previous object in memory (see [Figure 7-3](ch07.xhtml#ch07fig03)).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-3: Adding padding bytes before an array*'
  prefs: []
  type: TYPE_NORMAL
- en: 'On machines that do not support byte-addressable memory, compilers that attempt
    to place the first element of an array on an easily accessed boundary will allocate
    storage for an array on whatever boundary the machine supports. If the size of
    each array element is less than the minimum size memory object the CPU supports,
    the compiler implementer has two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Allocate the smallest accessible memory object for each element of the array.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pack multiple array elements into a single memory cell.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first option has the advantage of being fast, but it wastes memory because
    each array element carries along some extra storage that it doesn’t need. The
    second option is compact but slower, as it requires extra instructions to pack
    and unpack data when accessing array elements. Compilers on such machines often
    let you specify whether you want the data packed or unpacked so you can choose
    between space and speed.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re working on a byte-addressable machine (like the 80x86), you probably
    don’t have to worry about this issue. However, if you’re using an HLL and your
    code might wind up running on a different machine in the future, you should choose
    an array organization that is efficient on all machines.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.2.3 Accessing Elements of an Array***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If you allocate all the storage for an array in contiguous memory locations,
    and the first index of the array is `0`, then accessing an element of a one-dimensional
    array is simple. You can compute the address of any given element of an array
    using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Element_Size is the number of bytes that each array element occupies. Thus,
    if each array element is of type `byte`, the Element_Size field is `1` and the
    computation is very simple. If each element is a `word` (or another 2-byte type),
    then Element_Size is `2`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following Pascal array declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'To access an element of the `SixteenInts` on a byte-addressable machine, assuming
    4-byte integers, you’d use this calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'In assembly language (where you would actually have to do this calculation
    manually rather than having the compiler do it for you), you’d use code like the
    following to access array element `SixteenInts[index]`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '***7.2.4 Multidimensional Arrays***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most CPUs can easily handle one-dimensional arrays. Unfortunately, though, there’s
    no magic addressing mode that lets you easily access elements of multidimensional
    arrays. That takes some work and several machine instructions.
  prefs: []
  type: TYPE_NORMAL
- en: Before discussing how to declare or access multidimensional arrays, let’s look
    at how to implement them in memory. The first challenge is figuring out how to
    store a multidimensional object in a one-dimensional memory space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider for a moment a Pascal array of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This array contains 16 bytes organized as four rows of four characters. We need
    to map each of the 16 bytes in this array to each of the 16 contiguous bytes in
    main memory. [Figure 7-4](ch07.xhtml#ch07fig04) shows one way to do this.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-4: Mapping a 4×4 array to sequential memory locations*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The actual mapping is not important as long as it adheres to two rules:'
  prefs: []
  type: TYPE_NORMAL
- en: No two entries in the array can occupy the same memory location(s).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each element in the array must always map to the same memory location.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Therefore, you need a function with two input parameters—one for a row and
    one for a column value—that produces an offset into a contiguous block of 16 memory
    locations. Any function that satisfies these two constraints will work fine. However,
    what you really want is a mapping function that computes efficiently at runtime
    and works for arrays with any number of dimensions and any bounds on those dimensions.
    While there are numerous functions that fit this bill, there are two categories
    that most HLLs use: *[row-major ordering](gloss01.xhtml#gloss01_218)* and *[column-major
    ordering](gloss01.xhtml#gloss01_54)*.'
  prefs: []
  type: TYPE_NORMAL
- en: Before I actually describe row- and column-major ordering, let’s go over some
    terminology. The term *row index* describes a numeric index into a row; that is,
    if a single row were treated as a one-dimensional array, the row index would be
    the index into that array. *Column index* has a similar meaning; if a single column
    were treated as a one-dimensional array, the column index would be the index into
    that array. If you look back at [Figure 7-4](ch07.xhtml#ch07fig04), the numbers
    0, 1, 2, and 3 above each column are the *column numbers*, and those same values
    to the left of the rows are the *row numbers*. It’s easy to get confused with
    this terminology because *the column number is the same value as the row index*;
    that is, the column number is equivalent to an index into any one of the four
    rows. Similarly, *a row number is the same value as a column index*. This book
    uses the terms *row index* and *column index*, but note that other authors may
    use the terms *row* and *column* to mean row number and column number.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.2.4.1 Row-Major Ordering**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Row-major ordering assigns array elements to successive memory locations by
    moving across a row and then down the columns. [Figure 7-5](ch07.xhtml#ch07fig05)
    demonstrates this mapping.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-5: Row-major ordering*'
  prefs: []
  type: TYPE_NORMAL
- en: Row-major ordering is the method employed by most high-level programming languages,
    including Pascal, C/C++, Java, C#, Ada, and Modula-2\. This organization is very
    easy to implement and easy to use in machine language. The conversion from a two-dimensional
    structure to a linear sequence is very intuitive. [Figure 7-6](ch07.xhtml#ch07fig06)
    provides another view of the ordering of a 4×4 array.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-6: Another view of row-major ordering for a 4×4 array*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The function that converts the set of multidimensional array indices into a
    single offset is a slight modification of the formula for computing the address
    of an element of a one-dimensional array. The formula to compute the offset for
    a 4×4 two-dimensional row-major-ordered array given an access of this form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: As usual, Base_Address is the address of the array’s first element (`A[0][0]`
    in this case) and Element_Size is the size of an individual element of the array,
    in bytes. row_size is the number of elements in one row of the array (`4`, in
    this case, because each row has four elements). Assuming Element_Size is `1`,
    this formula computes the offsets shown in [Table 7-2](ch07.xhtml#ch07tab02) from
    the base address.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 7-2:** Offsets for Two-Dimensional Row-Major-Ordered Array'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Column index** | **Row index** | **Offset into array** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `0` | `0` | `0` |'
  prefs: []
  type: TYPE_TB
- en: '| `0` | `1` | `1` |'
  prefs: []
  type: TYPE_TB
- en: '| `0` | `2` | `2` |'
  prefs: []
  type: TYPE_TB
- en: '| `0` | `3` | `3` |'
  prefs: []
  type: TYPE_TB
- en: '| `1` | `0` | `4` |'
  prefs: []
  type: TYPE_TB
- en: '| `1` | `1` | `5` |'
  prefs: []
  type: TYPE_TB
- en: '| `1` | `2` | `6` |'
  prefs: []
  type: TYPE_TB
- en: '| `1` | `3` | `7` |'
  prefs: []
  type: TYPE_TB
- en: '| `2` | `0` | `8` |'
  prefs: []
  type: TYPE_TB
- en: '| `2` | `1` | `9` |'
  prefs: []
  type: TYPE_TB
- en: '| `2` | `2` | `10` |'
  prefs: []
  type: TYPE_TB
- en: '| `2` | `3` | `11` |'
  prefs: []
  type: TYPE_TB
- en: '| `3` | `0` | `12` |'
  prefs: []
  type: TYPE_TB
- en: '| `3` | `1` | `13` |'
  prefs: []
  type: TYPE_TB
- en: '| `3` | `2` | `14` |'
  prefs: []
  type: TYPE_TB
- en: '| `3` | `3` | `15` |'
  prefs: []
  type: TYPE_TB
- en: 'The following C/C++ code access sequential memory locations in a row-major-ordered
    array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'For a three-dimensional array, the formula to compute the offset into memory
    is only slightly more complex. Consider the following C/C++ array declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'If you have an array access similar to `A[`depth_index`][`col_index`][`row_index`]`,
    then the computation that yields the offset into memory is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Again, Element_Size is the size, in bytes, of a single array element.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’ve got an *n*-dimensional array declared in C/C++ as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'and you wish to access the following element of this array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'then you can compute the address of a particular array element using the following
    algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '**7.2.4.2 Column-Major Ordering**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Column-major ordering, the other common array element address function, is used
    by FORTRAN and various dialects of BASIC (such as older versions of Microsoft
    BASIC) to index arrays. A column-major-ordered array is organized as shown in
    [Figure 7-7](ch07.xhtml#ch07fig07).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-7: Column-major ordering*'
  prefs: []
  type: TYPE_NORMAL
- en: The formula for computing the address of an array element when using column-major
    ordering is very similar to that for row-major ordering. The difference is that
    you reverse the order of the index and size variables in the computation. That
    is, rather than working from the leftmost index to the rightmost, you operate
    from right to left.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a two-dimensional column-major array, the formula is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'For a three-dimensional column-major array, the formula is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: And so on. Other than using these new formulas, accessing elements of an array
    using column-major ordering is identical to accessing arrays using row-major ordering.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.2.4.3 Declaring Multidimensional Arrays**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: An “*m* × *n*” array has `m` × `n` elements and requires `m` × `n` × Element_Size
    bytes of storage. To allocate storage for an array, you must reserve this amount
    of memory. With one-dimensional arrays, the syntax is very similar among the different
    HLLs. However, their syntax starts to diverge with multidimensional arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'In C, C++, and Java, you use the following syntax to declare a multidimensional
    array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, here’s a three-dimensional array declaration in C/C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: This example creates an array with 64 elements organized with a depth of 4 by
    2 rows by 8 columns. Assuming each `int` object requires 4 bytes, this array consumes
    256 bytes of storage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pascal’s syntax supports two equivalent ways of declaring multidimensional
    arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'C# uses the following syntax to define multidimensional arrays:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Semantically, there are only two major differences among different languages.
    The first is whether the array declaration specifies the overall size of each
    array dimension or the upper and lower bounds. The second is whether the starting
    index is `0`, `1`, or a user-specified value.
  prefs: []
  type: TYPE_NORMAL
- en: Swift doesn’t really support multidimensional arrays in the traditional sense.
    It allows you to create arrays of arrays (of arrays . . .), which can provide
    the same functionality as multidimensional arrays, but behave in subtly different
    ways. See “[Swift Array Implementation](#sec7_2_4_5)” on page [179](#sec7_2_4_5)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.2.4.4 Accessing Elements of a Multidimensional Array**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: It’s so easy to access an element of a multidimensional array in an HLL that
    many programmers do so without considering the associated costs. In this section,
    to give you a clearer picture of those costs, we’ll look at some of the assembly
    language sequences you’ll need to access elements of a multidimensional array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider again the C/C++ declaration of the `ThreeDInts` array from the previous
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'In C/C++, if you wanted to set element `[i][j][k]` of this array to `n`, you’d
    probably use the following statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This statement, however, hides a great deal of complexity. Recall the formula
    needed to access an element of a three-dimensional array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ThreeDInts` example does not avoid this calculation, it only hides it
    from you. The machine code that the C/C++ compiler generates is similar to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Actually, `ThreeDInts` is special. The sizes of all the array dimensions are
    nice powers of 2\. This means that the CPU can use shifts instead of multiplication
    instructions to multiply EBX by 2 and by 4 in this example. Because shifts are
    often faster than multiplication, a decent C/C++ compiler will generate the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Note that a compiler can use this faster code only if an array dimension is
    a power of 2; this is why many programmers attempt to declare arrays with those
    dimensions. Of course, if you must declare extra elements in the array to achieve
    this goal, you may wind up wasting space (especially with higher-dimensional arrays)
    to achieve only a small increase in speed.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you need a 10×10 array and you’re using row-major ordering,
    you could create a 10×16 array to allow the use of a shift (by 4) instruction
    rather than a multiply (by 10) instruction. When using column-major ordering,
    you’d probably want to declare a 16×10 array to achieve the same effect, since
    row-major calculation doesn’t use the size of the first dimension when calculating
    an offset into an array, and column-major calculation doesn’t use the size of
    the second dimension when calculating an offset. In either case, however, the
    array would wind up having 160 elements instead of 100 elements. Only you can
    decide if this extra space is worth the minor improvement in speed.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.2.4.5 Swift Array Implementation**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Swift arrays are different from those found in many other languages. First
    of all, Swift arrays are an opaque type based on `struct` objects (rather than
    just a collection of elements in memory). Swift doesn’t guarantee that array elements
    appear in continuous memory locations. However, the language provides the following
    `ContiguousArray` type specification, which guarantees they’ll appear in contiguous
    memory locations (as in C/C++ and other languages):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: So far, so good. With contiguous arrays, the storage of the actual array data
    matches other languages. However, when you start declaring multidimensional arrays,
    the similarity ends. As noted earlier, Swift doesn’t actually have multidimensional
    arrays; instead, it supports *arrays of arrays*.
  prefs: []
  type: TYPE_NORMAL
- en: For most programming languages, where an array object is strictly the sequence
    of array elements in memory, an array of arrays and a multidimensional array are
    the same thing. However, Swift uses descriptor (`struct`-based) objects to specify
    an array. Like string descriptors, Swift arrays consist of a data structure containing
    various fields (like the current number of array elements and one or more pointers
    to the actual array data).
  prefs: []
  type: TYPE_NORMAL
- en: 'When you create an array of arrays, you’re actually creating an array of these
    descriptors, with each pointing at a subarray. Consider the following two (equivalent)
    Swift array-of-arrays declarations (`a1` and `a2`) and sample program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this program produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: For two-dimensional arrays you would expect this type of output. However, internally,
    `a1` and `a2` are one-dimensional arrays with two elements each. Those two elements
    are array descriptors that themselves point at arrays, each containing three elements.
  prefs: []
  type: TYPE_NORMAL
- en: It is unlikely that the six array elements associated with `a2` will appear
    in contiguous memory locations, even though `a2` is a `ContiguousArray` type.
    The two array descriptors held in `a2` may appear in contiguous memory locations,
    but that doesn’t necessarily carry over to the six data elements at which they
    collectively point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because Swift allocates arrays dynamically, the rows in a two-dimensional array
    could have differing element counts. Consider the following modification to the
    previous Swift program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this program produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The two rows in the `a2` array have differing sizes. This could be useful or
    a source of defects, depending on what you’re trying to accomplish.
  prefs: []
  type: TYPE_NORMAL
- en: One way to get standard multidimensional array storage in Swift is to declare
    a one-dimensional `ContiguousArray` with sufficient elements for all the elements
    of the multidimensional array. Then use the row-major (or column-major) functionality,
    without the element size operand, to compute the index into the array.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.3 Records/Structures**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another major composite data structure is the Pascal *[record](gloss01.xhtml#gloss01_213)*
    or C/C++ *structure*. The Pascal terminology is probably better, as it avoids
    confusion with the term *data structure*, so we’ll generally use *record* here.
  prefs: []
  type: TYPE_NORMAL
- en: An array is *homogeneous*, meaning that its elements are all of the same type.
    A record, on the other hand, is *heterogeneous*—its elements can have differing
    types. The purpose of a record is to let you encapsulate logically related values
    into a single object.
  prefs: []
  type: TYPE_NORMAL
- en: Arrays let you select a particular element via an integer index. With records,
    you must select an element, known as a *[field](gloss01.xhtml#gloss01_96)*, by
    the field’s name. Each of the field names within the record must be unique; that
    is, you can’t use the same field name two or more times in the same record. However,
    all field names are local to their record, and you can reuse those names elsewhere
    in the program.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.3.1 Records in Pascal/Delphi***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Here’s a typical record declaration for a `Student` data type in Pascal/Delphi:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Many Pascal compilers allocate all of the fields in contiguous memory locations.
    This means that Pascal will reserve the first 65 bytes for the name,^([3](footnotes.xhtml#fn7_3a))
    the next 2 bytes for the major code, the next 12 bytes for the Social Security
    number, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.3.2 Records in C/C++***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Here’s the same declaration in C/C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Because C++ structures are actually a specialized form of the class declaration,
    they behave differently from C structures and may include extra data in memory
    that is not present in the C variant. (This is why the memory storage for structures
    in C++ may be different; see “[Memory Storage of Records](#sec7_3_5)” on page
    [184](#sec7_3_5)). There are also differences in namespaces and other minor distinctions
    between C and C++ structures.
  prefs: []
  type: TYPE_NORMAL
- en: 'As it turns out, though, you can tell C++ to compile a true C `struct` definition
    using the `extern` `"C"` block as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Java doesn’t support anything corresponding to the C `struct`—it supports
    only classes (see “[Classes](#sec7_5)” on page [192](#sec7_5)).*'
  prefs: []
  type: TYPE_NORMAL
- en: '***7.3.3 Records in HLA***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In HLA, you can also create structure types using the `record`/`endrecord`
    declaration. For example, you would encode the record from the previous sections
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the HLA declaration is very similar to the Pascal declaration.
    To stay consistent with the Pascal declaration, this example uses character arrays
    rather than strings for the `Name` and `SSN` (Social Security number) fields.
    In a typical HLA record declaration, you’d probably use a `string` type for at
    least the `Name` field (keeping in mind that a string variable is a 4-byte pointer).
  prefs: []
  type: TYPE_NORMAL
- en: '***7.3.4 Records (Tuples) in Swift***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although Swift doesn’t support the concept of a record, you can simulate one
    using a Swift *[tuple](gloss01.xhtml#gloss01_247)*. While Swift does not store
    record (tuple) elements in memory in the same way as other programming languages
    (see “[Memory Storage of Records](#sec7_3_5)” on page [184](#sec7_3_5)), tuples
    are a useful construct if you want to create a composite/aggregate data type without
    the overhead of a class.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Swift tuple is simply a list of values in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The types of the values within the tuple don’t need to be identical.
  prefs: []
  type: TYPE_NORMAL
- en: 'Swift typically uses tuples to return multiple values from functions. Consider
    the following short Swift code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'The `returns3Ints()` function returns three values (`1`, `2`, and `3`). The
    following statement stores those three integer values into `r1`, `r2`, and `r3`,
    respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also assign tuples to a single variable and access “fields” of the
    tuple using integer indices as the field names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Of course, using field names like `.0` results in very hard-to-maintain code.
    While you could create records out of tuples, referring to the fields by an integer
    index is rarely suitable in real-world programs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, Swift allows you to assign each tuple field a label, which you
    can then use instead of an integer index to refer to the field. Consider the following
    Swift code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: Using Swift tuples this way is the syntactical equivalent of using a Pascal
    or HLA record (or a C structure). Keep in mind, however, that the storage of the
    tuple in memory might not map to the same layout as a record or structure in these
    other languages. Like arrays in Swift, tuples are an opaque type, without a guaranteed
    definition for how Swift will store them in memory.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.3.5 Memory Storage of Records***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following Pascal example demonstrates a typical `Student` variable declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Given the earlier declaration for the Pascal `Student` data type, this allocates
    81 bytes of storage laid out in memory as shown in [Figure 7-8](ch07.xhtml#ch07fig08).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-8: Student data structure storage in memory*'
  prefs: []
  type: TYPE_NORMAL
- en: If the label `John` corresponds to the *base address* of this record, then the
    `Name` field is at offset `John+0`, the `Major` field is at offset `John+65`,
    the `SSN` field is at offset `John+67`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most programming languages let you refer to a record field by its name rather
    than by its numeric offset into the record. The typical syntax for field access
    uses the *dot operator* to select a field from a record variable. Given the variable
    `John` from the previous example, here’s how you could access various fields in
    this record:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 7-8](ch07.xhtml#ch07fig08) suggests that all fields of a record appear
    in memory in the order of their declaration, and this is usually the case in practice.
    In theory, though, a compiler can freely place the fields anywhere in memory that
    it chooses. The first field usually appears at the lowest address in the record,
    the second field appears at the next highest address, the third field follows
    the second field in memory, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-8](ch07.xhtml#ch07fig08) also suggests that compilers pack the fields
    into adjacent memory locations with no gaps between them. While this is true for
    many languages, it’s certainly not the most common memory organization for a record.
    For performance reasons, most compilers actually align the fields of a record
    on appropriate memory boundaries. The exact details vary by language, compiler
    implementation, and CPU, but a typical compiler places fields at an offset within
    the record’s storage area that is “natural” for that particular field’s data type.
    On the 80x86, for example, compilers that follow the Intel ABI (application binary
    interface) allocate 1-byte objects at any offset within the record, words only
    at even offsets, and double-word or larger objects on double-word boundaries.
    Although not all 80x86 compilers support the Intel ABI, most do, which allows
    records to be shared among functions and procedures written in different languages
    on the 80x86\. Other CPU manufacturers provide their own ABI for their processors,
    and programs that adhere to an ABI can share binary data at runtime with other
    programs that adhere to the same ABI.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to aligning the fields of a record at reasonable offset boundaries,
    most compilers also ensure that the length of the entire record is a multiple
    of 2, 4, 8, or even 16 bytes. As mentioned earlier in the chapter, they accomplish
    this by appending padding bytes to fill out the record’s size. This ensures that
    the record’s length is an even multiple of the size of the largest scalar (noncomposite
    data type) object in the record or the CPU’s optimal alignment size, whichever
    is smaller. For example, if a record has fields whose lengths are 1, 2, 4, 8,
    and 10 bytes, then an 80x86 compiler generally will pad the record’s length so
    that it is an even multiple of 8\. This allows you to create an array of records
    and be assured that each record in the array starts at a reasonable address in
    memory.
  prefs: []
  type: TYPE_NORMAL
- en: Although some CPUs don’t allow access to objects in memory at misaligned addresses,
    many compilers allow you to disable the automatic alignment of fields within a
    record. Generally, the compiler has an option you can use to globally disable
    this feature. Many compilers also provide a `pragma` or a `packed` keyword that
    lets you turn off field alignment on a record-by-record basis. Disabling the automatic
    field alignment feature may save some memory by eliminating the padding bytes
    between the fields and at the end of the record (again, provided that field misalignment
    is acceptable on your CPU). However, the program may run a little bit slower when
    it needs to access misaligned values in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'One reason to use a packed record is to gain manual control over the alignment
    of the record’s fields. For example, suppose you have a couple of functions written
    in two different languages, and both functions need to access some data in a record.
    Suppose also that the two compilers for these functions do not use the same field
    alignment algorithm. A record declaration like the following (in Pascal) may not
    be compatible with the way both functions access the record data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: The problem here is that the first compiler could use the offsets 0, 2, and
    4 for the `bField`, `wField`, and `dField` fields, respectively, while the second
    compiler might use offsets 0, 4, and 8.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose, however, that the first compiler allows you to specify the `packed`
    keyword before the `record` keyword, causing the compiler to store each field
    immediately following the previous one. Although using the `packed` keyword doesn’t
    make the records compatible with both functions, it does allow you to manually
    add padding fields to the record declaration, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Adding padding manually can make code maintenance a real chore. However, if
    incompatible compilers need to share data, it’s a trick worth knowing. For the
    exact details on packed records, consult your language’s reference manual.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.4 Discriminant Unions**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A discriminant union (or just *[union](gloss01.xhtml#gloss01_252)*) is very
    similar to a record. Like records, unions have fields that you access using dot
    notation. In many languages, the only syntactical difference between records and
    unions is the use of the keyword `union` rather than `record`. Semantically, however,
    there’s a big difference between them. In a record, each field has its own offset
    from the base address of the record, and the fields do not overlap. In a union,
    however, all fields have the same offset, 0, and all the fields of the union overlap.
    As a result, the size of a record is the sum of the sizes of all the fields (plus,
    possibly, some padding bytes), whereas a union’s size is the size of its largest
    field (plus, possibly, some padding bytes at the end).
  prefs: []
  type: TYPE_NORMAL
- en: Because the fields of a union overlap, you might think it’s of little use in
    a real-world program. After all, if the fields all overlap, then changing the
    value of one field changes the values of all the others as well. This means that
    union fields are *mutually exclusive*—that is, you can use only one at a time.
    While it’s true that this makes unions less generally applicable than records,
    they still have many uses.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.4.1 Unions in C/C++***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Here’s an example of a union declaration in C/C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Assuming the C/C++ compiler allocates 4 bytes for unsigned integers, the size
    of a `unionType` object will be 4 bytes (because all three fields are 4-byte objects).
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Unfortunately, Java doesn’t support discriminant unions due to the safety
    issues involved. You can implement some features of discriminant unions using
    subclassing, but Java does not support explicitly sharing memory locations among
    different variables.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***7.4.2 Unions in Pascal/Delphi***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Pascal/Delphi use *case-variant records* to create a discriminant union. The
    syntax for a case-variant record is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: In this example, tag is either a type identifier (such as `boolean`, `char`,
    or some user-defined type) or a field declaration of the form identifier`:`type.
    If the tag item takes this latter form, then identifier becomes another field
    of the record, not a member of the *variant section* (those declarations following
    the `case`), and has the specified type. In addition, the Pascal compiler could
    generate code that raises an exception whenever the application attempts to access
    any of the variant fields except the one specified by the value of the tag field.
    In practice, though, almost no Pascal compilers do this check. Still, keep in
    mind that the Pascal language standard suggests that compilers should do it, so
    some compilers out there might.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of two different case-variant record declarations in Pascal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the `hasTagRecord` union, a Pascal case-variant record does
    not require any normal record fields. This is true even if you do not have a tag
    field.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.4.3 Unions in Swift***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Swift does not directly support the concept of a discriminant union. Unlike
    Java, however, Swift does provide an alternative—equivalent to Pascal’s case-variant
    record—that supports the safe use of unions: enumerated data types.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following Swift enumeration definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'So far, this is just an enumerated data type that has nothing to do with unions.
    However, we can attach a value (actually, a tuple of values) to each case in an
    enumerated data type. Consider the following Swift program, which demonstrates
    `enum` *[associated values](gloss01.xhtml#gloss01_17)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'This program produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: A variable of type `EnumType` takes on one of the enumeration values `isInt`,
    `isReal`, or `isString` (these are the three constants of type `EnumType`). In
    addition to whatever internal encoding Swift chooses for these three constants
    (probably `0`, `1`, and `2`, though their actual values are irrelevant), Swift
    associates an integer value with `isInt`, a 64-bit double-precision floating-point
    value with `isReal`, and a string value with `isString`. The three `let` statements
    assign the appropriate values to `EnumType` variables; as you can see, to assign
    the value you include it in parentheses after the constant’s name. You can then
    extract the value using a `switch` statement.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.4.4 Unions in HLA***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'HLA supports unions as well; here’s a typical union declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '***7.4.5 Memory Storage of Unions***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As noted previously, the big difference between a union and a record is the
    fact that records allocate storage for each field at different offsets, whereas
    unions overlay all of the fields at the same offset in memory. For example, consider
    the following HLA record and union declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: If you declare a variable, `n`, of type `numericRec`, you access the fields
    as `n.i`, `n.u`, and `n.r`, exactly as though you had declared the `n` variable
    to be type `numericUnion`. However, the size of a `numericRec` object is 16 bytes,
    because the record contains two double-word fields and a quad-word (`real64`)
    field. The size of a `numericUnion` variable, though, is 8 bytes. [Figure 7-9](ch07.xhtml#ch07fig09)
    shows the memory arrangement of the `i`, `u`, and `r` fields in both the record
    and union.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-9: Layout of a union versus a record variable*'
  prefs: []
  type: TYPE_NORMAL
- en: Note that Swift `enum` types are opaque. They may not store the associated values
    from each enumeration case in the same memory address—and even if they currently
    do, there’s no guarantee they will in future versions of Swift.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.4.6 Other Uses of Unions***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In addition to conserving memory, another common reason why programmers use
    unions is to create aliases in their code. An *alias* is a second name for some
    memory object. Although aliases are often a source of confusion in a program and
    should be used sparingly, sometimes it’s convenient to use them. For example,
    in some section of your program you might need to constantly use type coercion
    to refer to a particular object. To avoid this, you could use a union variable
    with each field representing one of the different types you want to use for the
    object. Consider the following HLA code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'With a declaration like this, you can manipulate an `uns32` object by accessing
    `v.u`. If, at some point, you need to treat the LO byte of this `uns32` variable
    as a character, you can do so by simply accessing the `v.c` variable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Another common practice is to use unions to disassemble a larger object into
    its constituent bytes. Consider the following C/C++ code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: Although composing and decomposing data types this way is a useful trick to
    employ every now and then, keep in mind that this code isn’t portable. The HO
    and LO bytes of a multibyte object appear at different addresses on big-endian
    versus little-endian machines. As a result, this code fragment works fine on little-endian
    machines, but fails to display the correct bytes on big-endian CPUs. Any time
    you use unions to decompose larger objects, you should be aware of this limitation.
    Still, this trick is usually much more efficient than using shift lefts, shift
    rights, and AND operations, so you’ll see it used quite a bit.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Swift’s type safety system does not allow you to access a collection of bits
    as different types using discriminant unions. If you really want to convert one
    type to another by raw bit assignment, you can use the Swift `unsafeBitCast()`
    function. See the Swift standard library documentation for more details.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**7.5 Classes**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At first glance, classes in a programming language like C++, Object Pascal,
    or Swift look like they are simple extensions to records (or structures) and should
    have a similar memory organization. Indeed, most programming languages do organize
    class data fields in memory very similarly to records and structures. The compiler
    lays out the fields in sequential memory locations as it encounters them in a
    class declaration. However, classes have several additional features that you
    won’t find in pure record and structures; specifically, member functions (functions
    declared inside a class), inheritance, and polymorphism have a big impact on how
    compilers implement class objects in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following HLA structure and HLA class declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: As with records, HLA allocates storage for all `var` fields in a class sequentially.
    Indeed, if a class consists only of `var` data fields, its memory representation
    is nearly identical to that of a corresponding record declaration (see [Figures
    7-10](ch07.xhtml#ch07fig10) and [7-11](ch07.xhtml#ch07fig11)).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-10: Layout of the HLA `student` record*'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-11: Layout of the HLA `student2` class*'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from these figures, the difference is the presence of the VMT
    pointer field at the beginning of the `student2` class data. *[VMT](gloss01.xhtml#gloss01_259)*,
    which stands for *[virtual method table](gloss01.xhtml#gloss01_257)*, is a pointer
    to an array of pointers to the methods (functions) associated with the class.^([4](footnotes.xhtml#fn7_4a))
    In the `student2` example, the VMT field would point at a table containing two
    32-bit pointers—one pointing at the `setName()` method and one pointing at the
    `getName()` method. When a program calls one of the virtual methods `setName()`
    or `getName()` in this class, it does not call them directly at their address
    in memory. Instead, it fetches the address of the VMT from the object in memory,
    uses that pointer to fetch the specific method address (`setName()` will likely
    be at the first index into the VMT and `getName()` at the second), and then use
    the fetched address to call the method indirectly.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.5.1 Inheritance***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Obtaining the method address from the VMT is a lot of work. Why would the compiled
    code do this rather than calling the method directly? The reason is because of
    a pair of magical features that classes and objects support: inheritance and polymorphism.
    Consider the following HLA class declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: The `student3` class inherits all the data fields and methods from the `student2`
    class (as specified by the `inherits` clause in the class declaration) and then
    defines a new data field, `extraTime`, that allots extra time, in minutes, for
    the student during examinations. The `student3` declaration also defines a new
    method, `setName()`, that replaces the original `setName()` method in the `student2`
    class (it also defines an overridden `create` procedure, but we’ll ignore this
    for now). The memory layout for a `student3` object appears in [Figure 7-12](ch07.xhtml#ch07fig12).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-12: Layout of the HLA `student3` class*'
  prefs: []
  type: TYPE_NORMAL
- en: In memory, the difference between the `student2` and `student3` objects is the
    extra 2 bytes at the end of the `student3` data structure and the value held by
    the VMT field. For `student2` objects the VMT field points at the VMT for the
    `student2` class (there is only one actual `student2` VMT in memory, and all `student2`
    objects contain a pointer to it). If we have a pair of `student2` objects named
    `John` and `Joan`, their VMT fields will both contain the address of the same
    VMT in memory, which has the information shown in [Table 7-3](ch07.xhtml#ch07tab03).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 7-3:** VMT Entries for `student2` VMT'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Offset^([5](footnotes.xhtml#fn7_5a))** | **Entry** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 (bytes) | Pointer to the (`student2`) `setName()` method |'
  prefs: []
  type: TYPE_TB
- en: '| 4 (bytes) | Pointer to the `getName()` method |'
  prefs: []
  type: TYPE_TB
- en: Now consider the case where we have a `student3` object in memory (let’s name
    it `Jenny`). The memory layout for `Jenny` is similar to that of `John` and `Joan`
    (see [Figures 7-11](ch07.xhtml#ch07fig11) and [7-12](ch07.xhtml#ch07fig12)). However,
    whereas the VMT fields in `John` and `Joan` both contain the same value (a pointer
    to the `student2` VMT), the VMT field for the `Jenny` object will point at the
    `student3` VMT (see [Table 7-4](ch07.xhtml#ch07tab04)).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 7-4:** VMT Entries for `student3` VMT'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Offset** | **Entry** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 (bytes) | Pointer to the (`student3`) `setName()` method |'
  prefs: []
  type: TYPE_TB
- en: '| 4 (bytes) | Pointer to the `getName()` method |'
  prefs: []
  type: TYPE_TB
- en: 'Although the `student3` VMT looks almost identical to the `student2` VMT, there
    is one critical difference: the first entry in [Table 7-3](ch07.xhtml#ch07tab03)
    points at the `student2` `setName()` method, whereas the first entry in [Table
    7-4](ch07.xhtml#ch07tab04) points at the `student3` `setName()` method.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding fields inherited from a *[base class](gloss01.xhtml#gloss01_23)* to
    another class must be done carefully. Remember, an important attribute of a class
    that inherits fields from a base class is that you can use a pointer to the base
    class to access its fields, even if the pointer contains the address of some other
    class (that inherits the fields from the base class). Consider the following classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: Because both `tChildClassA` and `tChildClassB` inherit the fields of `tBaseClass`,
    these two child classes include the `i`, `j`, and `r` fields as well as their
    own specific fields.
  prefs: []
  type: TYPE_NORMAL
- en: For inheritance to work properly, the `i`, `j`, and `r` fields must appear at
    the same offsets in all child classes as they do in `tBaseClass`. This way, an
    instruction of the form `mov((type tBaseClass [ebx]).i, eax);` will correctly
    access the `i` field even if EBX points at an object of type `tChildClassA` or
    `tChildClassB`. [Figure 7-13](ch07.xhtml#ch07fig13) shows the layout of the child
    and base classes.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the new fields in the two child classes bear no relation to one another,
    even if they have the same name (for example, the `c` fields in the two child
    classes do not lie at the same offset). Although the two child classes share the
    fields they inherit from their common base class, any new fields they add are
    unique and separate. Two fields in different classes share the same offset only
    by coincidence if those fields are not inherited from a common base class.
  prefs: []
  type: TYPE_NORMAL
- en: All classes (even those that aren’t related to one another) place the pointer
    to the VMT at the same offset within the object (typically offset 0). There is
    a single VMT associated with each class in a program; even when classes inherit
    fields from some base class, their VMT (generally) differs from the base class’s
    VMT. [Figure 7-14](ch07.xhtml#ch07fig14) shows how objects of type `tBaseClass`,
    `tChildClassA`, and `tChildClassB` point at their specific VMTs.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-13: Layout of base and child classes in memory*'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-14: VMT references from objects*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever a child class inherits fields from some base class, the child class’s
    VMT also inherits entries from the base class’s VMT. For example, the VMT for
    the class `tBaseClass` contains only a single entry—a pointer to the method `tBaseClass.mBase()`.
    The VMT for the class `tChildClassA` contains two entries: pointers to `tBaseClass.mBase()`
    and `tChildClassA.mA()`. Because `tChildClassB` doesn’t define any new methods
    or iterators, its VMT contains only a single entry: a pointer to the `tBaseClass.mBase()`
    method. Note that `tChildClassB`’s VMT is identical to `tBaseclass`’s table. Nevertheless,
    HLA produces two distinct VMTs. [Figure 7-15](ch07.xhtml#ch07fig15) shows this
    relationship.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-15: Layout of base and child classes in memory*'
  prefs: []
  type: TYPE_NORMAL
- en: '***7.5.2 Class Constructors***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before you can actually call any methods in a VMT, you have to make sure that
    the table is actually present in memory (holding the addresses of the methods
    defined in a class), and you also have to initialize the VMT pointer field in
    every class you create. If you’re using an HLL (such as C++, C#, Java, or Swift),
    the compiler will automatically generate the VMTs for you when you compile the
    class definitions. As for initializing the VMT pointer field in the object itself,
    that’s usually handled by the default constructor (object initialization function)
    for each class. All this work is hidden from an HLL programmer. That’s why these
    class examples are using HLA—in assembly language (even a high-level assembly
    language), very little is hidden from you. With HLA examples, then, you get to
    see exactly how objects work and the cost of using them.
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin with, HLA does not automatically create the VMTs for you. You must
    explicitly declare them in your code for each class you define. For the `student2`
    and `student3` examples, you can declare them as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: Technically, these don’t have to appear in a `readonly` section (they could
    also appear in an HLA `static` section); however, you’ll never change the VMT
    values, so this section is a good place to declare them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `VMT` declarations in this example define two symbols you can access in
    the HLA program: `student2._VMT_` and `student3._VMT_`. These symbols correspond
    to the address of the first entry in each VMT. Somewhere in your code (typically
    in the constructor procedure), you need to initialize the VMT field of the object
    with the address of the VMT for the associated class. The HLA convention for the
    class constructors appears in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '`student2.create()` and `student3.create()` are *class procedures* (also known
    as *static class methods* or *functions* in some languages). The main point to
    class procedures is that the code calls them directly, not indirectly (that is,
    through the VMT). So, if you call `John.create()` or `Joan.create()`, you’re always
    going to call the `student2.create()` class procedure. Likewise, if you call `Jenny.create()`—or
    any `student3` variable’s `create` constructor—you’ll always be calling the `student3.create()`
    procedure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The two statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: copy the address of the VMT (for the given class) into the VMT pointer field
    (`this._pVMT_`) in the objects being created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note the following statement in the `student3.create()` constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: Upon arriving at this point, the 80x86 ESI register contains a pointer to a
    `student3` object. The text `(type student2 [esi])` typecasts this to a `student2`
    pointer. This winds up calling the parent class’s constructor (in order to initialize
    any fields in the base class).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: If you look at the `_pVMT_` entries in the `John` and `Joan` objects, you’ll
    find that they contain the address of the VMT for the `student2` class. Likewise,
    the `_pVMT_` field of the `Jenny` object contains the address of the VMT for the
    `student3` class.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.5.3 Polymorphism***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If you have an HLA `student2` variable (that is, a variable that contains a
    pointer to a `student2` object in memory), you can call the `setName()` method
    for that object using the following HLA code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'These particular calls are examples of high-level activity taking place in
    HLA. The machine code that the HLA compiler emits for the first of these statements
    looks something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s what this code is doing:'
  prefs: []
  type: TYPE_NORMAL
- en: The first line copies the address held in the `John` pointer into the ESI register.
    This is because most indirect accesses on the 80x86 take place in a register,
    not in memory variables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The VMT pointer is a field in the `student2` object structure. The code needs
    to obtain the pointer to the `setName()` method, held in the VMT. The `_pVMT_`
    field of the object (which is in memory) holds the address of the VMT. Once again,
    we must load this into a register to access that data indirectly. The program
    copies the VMT pointer into the 80x86 EDI register.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The VMT (at which EDI now points) contains two entries. The first entry (offset
    0) contains the address of the `student2.setName()` method; the second entry (offset
    4) contains the address of the `student2.getName()` method. Because we want to
    call the `student2.setName()` method, the third instruction in this sequence calls
    the method at the address held in the memory location pointed at by `[edi+0]`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, this is quite a bit more work than calling `student.``setName()`
    directly. Why do we go through all this effort? After all, we know that `John`
    and `Joan` are both `student2` objects. We also know that `Jenny` is a `student3`
    object. So, we ought to be able to call the `student2.setName()` or `student3.setName()`
    methods directly. That would take only one machine instruction, which is both
    faster and shorter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason for all this extra work is to support polymorphism. Suppose we declare
    a generic `student2` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'What happens when we assign the value of `Jenny` to `student` and call `student.setName()`?
    Well, the code sequence is identical to that for the call for `John` given earlier.
    That is, the code loads the pointer held in `student` into the ESI register, copies
    the `_pVMT_` field into the EDI register, and then jumps indirectly through the
    first entry of the VMT (which points at the `setName()` method). There is, however,
    one major difference between this example and the previous: in this case, `student`
    is pointing at a `student3` object in memory. So, when the code loads the address
    of the VMT into the EDI register, EDI is actually pointing at the `student3` VMT,
    not the `student2` VMT (as was the case when we used the `John` pointer). Therefore,
    when the program calls the `setName()` method, it’s actually calling the `student3.setName()`
    method, not the `student2.setName()` method. This behavior is the basis for polymorphism
    in modern object-oriented programming languages.'
  prefs: []
  type: TYPE_NORMAL
- en: '***7.5.4 Abstract Methods and Abstract Base Classes***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An *[abstract base class](gloss01.xhtml#gloss01_2)* exists solely to supply
    a set of common fields to its derived classes. You never declare variables whose
    type is an abstract base class; you always use one of the derived classes. An
    abstract base class is a template for creating other classes, nothing more.
  prefs: []
  type: TYPE_NORMAL
- en: The only difference in syntax between a standard base class and an abstract
    base class is the presence of at least one abstract method declaration. An *[abstract
    method](gloss01.xhtml#gloss01_3)* is a special method that does not have an actual
    implementation in the abstract base class. Any attempt to call that method will
    raise an exception. If you’re wondering what possible good an abstract method
    could be, keep reading.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you want to create a set of classes to hold numeric values. One class
    could represent unsigned integers, another class could represent signed integers,
    a third could implement BCD values, and a fourth could support `real64` values.
    While you could create four separate classes that function independently of one
    another, doing so passes up an opportunity to make this set of classes more convenient
    to use. To understand why, consider the following HLA class declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: The implementation of these classes is not unreasonable. They have fields for
    the data, and they have a `put()` method that, presumably, writes the data to
    the standard output device. They probably have other methods and procedures to
    implement various operations on the data. There are, however, two problems with
    these classes, one minor and one major, both occurring because these classes do
    not inherit any fields from a common base class.
  prefs: []
  type: TYPE_NORMAL
- en: The minor problem is that you have to repeat the declaration of several common
    fields in these classes. For example, the `put()` method is declared in each class.^([6](footnotes.xhtml#fn7_6a))
    The major problem is that this approach is not generic—that is, you can’t create
    a generic pointer to a “numeric” object and perform operations like addition,
    subtraction, and output on that value (regardless of the underlying numeric representation).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can easily solve these two problems by turning the previous class declarations
    into a set of derived classes. The following code demonstrates an easy way to
    do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: First, by making the `put()` method inherit from `numeric`, this code encourages
    the derived classes to always use the name `put()`, which makes the program easier
    to maintain. Second, because this example uses derived classes, it’s possible
    to create a pointer to the `numeric` type and load that pointer with the address
    of a `uint`, `sint`, or `r64` object. The pointer can invoke the methods found
    in the `numeric` class to do functions like addition, subtraction, or numeric
    output. Therefore, the application that uses this pointer doesn’t need to know
    the exact data type; it deals with numeric values only in a generic fashion.
  prefs: []
  type: TYPE_NORMAL
- en: One problem with this scheme is that it’s possible to declare and use variables
    of type `numeric`. Unfortunately, such numeric variables aren’t capable of representing
    any type of number (notice that the data storage for the numeric fields actually
    appears in the derived classes). Worse, because you’ve declared the `put()` method
    in the `numeric` class, you actually have to write some code to implement that
    method even though you should never really call it; the actual implementation
    should occur only in the derived classes. While you could write a dummy method
    that prints an error message (or, better yet, raises an exception), you shouldn’t
    have to resort to that. Fortunately, there’s no reason to do so—if you use *abstract*
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The HLA `abstract` keyword, when it follows a method declaration, tells HLA
    that you aren’t going to provide an implementation of the method for this class.
    Instead, all derived classes are responsible for providing a concrete implementation
    for the abstract method. HLA will raise an exception if you attempt to call an
    abstract method directly. The following code modifies the `numeric` class to convert
    `put()` to an abstract method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: An abstract base class has at least one abstract method. But you don’t have
    to make *all* methods abstract in an abstract base class; it’s perfectly legal
    to declare some standard methods (and, of course, provide their implementation)
    within it.
  prefs: []
  type: TYPE_NORMAL
- en: Abstract method declarations provide a mechanism by which a base class can specify
    some generic methods that the derived classes must implement. If the derived classes
    don’t provide concrete implementations of all abstract methods, that makes them
    abstract base classes themselves.
  prefs: []
  type: TYPE_NORMAL
- en: A little earlier, you read that you should never create variables whose type
    is an abstract base class. Remember, if you attempt to execute an abstract method,
    the program will immediately raise an exception to complain about this illegal
    method call.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.6 Classes in C++**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Up to this point, all the examples of classes and objects have used HLA. That
    made sense because the discussion concerned the low-level implementation of classes,
    which is something HLA illustrates well. However, you may not ever use HLA in
    a program you write. So now we’ll look at how high-level languages implement classes
    and objects. As C++ was one of the earliest HLLs to support classes, we’ll start
    with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a variant of the `student2` class in C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: The first major difference from HLA’s classes is the presence of the `private`,
    `protected`, and `public` keywords. C++ and other HLLs make a concerted effort
    to support *encapsulation* (information hiding), and these three keywords are
    one of the main tools C++ uses to enforce it. Scope, privacy, and encapsulation
    are syntactical issues that are useful for software engineering constructs, but
    they really don’t impact the *implementation* of classes and objects in memory.
    Thus, since this book’s focus is implementation, we’ll leave further discussion
    of encapsulation for *[WGC4](gloss01.xhtml#gloss01_266)* and *[WGC5](gloss01.xhtml#gloss01_267)*.
  prefs: []
  type: TYPE_NORMAL
- en: The layout of the C++ `student2` object in memory will be very similar to the
    HLA variant (of course, different compilers could lay things out differently,
    but the basic idea of data fields and the VMT still applies).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of inheritance in C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Structures and classes are almost identical in C++. The main difference between
    the two is that the default visibility at the beginning of a class is `private`,
    whereas the default visibility for `struct` is `public`. So, we could rewrite
    the `student3` class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: '***7.6.1 Abstract Member Functions and Classes in C++***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'C++ has an especially weird way of declaring abstract member functions—you
    place “`= 0;`” after the function definition in the class, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: As with HLA, if a class contains at least one abstract function, the class is
    an abstract class. Note that abstract functions must also be virtual, as they
    must be overridden in some derived class to be useful.
  prefs: []
  type: TYPE_NORMAL
- en: '***7.6.2 Multiple Inheritance in C++***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'C++ is one of the few modern programming languages that supports *[multiple
    inheritance](gloss01.xhtml#gloss01_168)*; that is, a class can inherit the data
    and member functions from multiple classes. Consider the following C++ code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: In this example, class `c` inherits all the information from classes `a` and
    `b`. In memory, a typical C++ compiler will create an object like that shown in
    [Figure 7-16](ch07.xhtml#ch07fig16).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-16: Multiple inheritance memory layout*'
  prefs: []
  type: TYPE_NORMAL
- en: The `VMT` pointer entry points at a typical VMT containing the addresses of
    the `setI()`, `setJ()`, and `setK()` methods (as shown in [Figure 7-17](ch07.xhtml#ch07fig17)).
    If you call the `setI()` method, the compiler will generate code that loads the
    `this` pointer with the address of the `VMT` pointer entry in the object (the
    base address of the `c` object in [Figure 7-16](ch07.xhtml#ch07fig16)). Upon entry
    into `setI()`, the system believes that `this` is pointing at an object of type
    `a`. In particular, the `this.VM``T` field points at a VMT whose first (and, as
    far as type `a` is concerned, only) entry is the address of the `setI()` method.
    Likewise, at offset `(this+4`) in memory (as the `VMT` pointer is 4 bytes), the
    `setI()` method will find the `i` data value. As far as the `setI()` method is
    concerned, `this` is pointing at a class type `a` object (even though it’s actually
    pointing at a type `c` object).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/07fig17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-17: Multiple inheritance `this` values*'
  prefs: []
  type: TYPE_NORMAL
- en: When you call the `setK()` method, the system also passes the base address of
    the `c` object. Of course, `setK()` is expecting a type `c` object and `this`
    is pointing at a type `c` object, so all the offsets into the object are exactly
    as `setK()` expects. Note that objects of type `c` (and methods in the `c` class)
    will normally ignore the `VMT2` pointer field in the `c` object.
  prefs: []
  type: TYPE_NORMAL
- en: The problem occurs when the program attempts to call the `setJ()` method. Because
    `setJ()` belongs to class `b`, it expects `this` to hold the address of a VMT
    pointer pointing at a VMT for class `b`. It also expects to find data field `j`
    at offset (`this+4`). Were we to pass the `c` object’s `this` pointer to `setJ()`,
    accessing (`this+4`) would reference the `i` data field, not `j`. Furthermore,
    were a class `b` method to make a call to another method in class `b` (such as
    `setJ()` making a recursive call to itself), the VMT pointer would be wrong—it
    points at a VMT with a pointer to `setI()` at offset 0, whereas class `b` expects
    it to point at a VMT with a pointer to `setJ()` at offset 0\. To resolve this
    issue, a typical C++ compiler will insert an extra VMT pointer into the `c` object
    immediately prior to the `j` data field. It will initialize this second VMT field
    to point into the `c` VMT at the location where the class `b` method pointers
    begin (see [Figure 7-17](ch07.xhtml#ch07fig17)). When calling a method in class
    `b`, the compiler will emit code that initializes the `this` pointer with the
    address of this second VMT pointer (rather than pointing at the beginning of `c`-type
    object in memory). Now, upon entry to a class `b` method—such as `setJ()`—`this`
    will point at a legitimate VMT pointer for class `b`, and the `j` data field will
    appear at the offset (`this+4`) that class `b` methods expect.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.7 Classes in Java**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Java, as a C-based language, has class definitions that are somewhat similar
    to C++ (though Java doesn’t support multiple inheritance and has a more rational
    way of declaring abstract methods). Here’s a sample set of Java class declarations
    to give you a sense of how they work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '**7.8 Classes in Swift**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Swift is also a member of the C language tree. Like C++, Swift allows you to
    declare classes using the `class` or `struct` keyword. Unlike C++, Swift structures
    and classes are different things. A Swift structure is somewhat like a C++ class
    variable, whereas a Swift class is similar to a C++ pointer to an object. In Swift
    terminology, structures are *value* objects and classes are *reference* objects.
    Basically, when you create a structure object, Swift allocates sufficient memory
    for the entire object and binds that storage to the variable.^([7](footnotes.xhtml#fn7_7a))
    Like Java, Swift doesn’t support multiple inheritance; only single inheritance
    is legal. Also note that Swift doesn’t support abstract member functions or classes.
    Here’s an example of a pair of Swift classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: In Swift, all member functions are virtual by default. Also, the `init()` function
    is Swift’s constructor. Destructors have the name `deinit()`.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.9 Protocols and Interfaces**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Java and Swift don’t support multiple inheritance, because it has some logical
    problems. The classic example is the “diamond lattice” data structure. This occurs
    when two classes (say, `b` and `c`) both inherit information from the same class
    (say, `a`) and then a fourth class (say, `d`) inherits from both `b` and `c`.
    As a result, `d` inherits the data from `a` twice—once through `b` and once through
    `c`.
  prefs: []
  type: TYPE_NORMAL
- en: Although multiple inheritance can lead to some weird problems like this, there’s
    no question that being able to inherit from multiple locations is often useful.
    Thus, the solution in languages such as Java and Swift is to allow a class to
    inherit methods or functions from multiple sources but to inherit data fields
    from only a single ancestor class. This avoids most of the problems with multiple
    inheritance (specifically, an ambiguous choice of inherited data fields) while
    allowing programmers to include methods from various sources. Java calls such
    extensions *interfaces*, and Swift calls them *protocols*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of a couple of Swift protocol declarations and a class supporting
    that protocol:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: Swift protocols don’t supply any functions. Instead, a class that supports a
    protocol promises to provide an implementation of the functions the protocol(s)
    specify. In the preceding example, the `supportsProtocols` class is responsible
    for supplying all functions required by the protocols it supports. Effectively,
    protocols are like abstract classes containing only abstract methods—the inheriting
    class must provide actual implementations for all the abstract methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the previous example coded in Java and demonstrating its comparable
    mechanism, the interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'Interfaces and protocols behave somewhat like base class types in Java and
    Swift. If you instantiate a class object and assign that instance to a variable
    that is an interface/protocol type, you can execute the supported member functions
    for that interface or protocol. Consider the following Java example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a comparable example in Swift:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: You implement a protocol or interface using a pointer to a VMT that contains
    the addresses of the functions declared in that protocol or interface. So, the
    data structure for the Swift `g` class in the previous example would have three
    VMT pointers in it—one for protocol `a`, one for protocol `d`, and one for the
    class `g` (holding a pointer to the `local()` function).
  prefs: []
  type: TYPE_NORMAL
- en: When you create a variable whose type is a protocol/interface (`x` in the previous
    example), the variable holds the VMT pointer for that protocol. In the current
    example, the assignment of `g()` to the `x` variable actually just copies the
    VMT pointer for protocol `a` into `x`. Then, when the code executes `x.b` and
    `x.c`, it obtains the addresses of the actual functions from the VMT.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.10 Generics and Templates**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although classes and objects allow software engineers to extend their systems
    in ways that aren’t possible without object-oriented programming, objects don’t
    provide a completely generic solution. *Generics*, first introduced by the ML
    programming language in 1973 and popularized by the Ada programming language,
    provide the key missing feature to extensibility that plain object-oriented programming
    was missing. Today, most modern programming languages—C++ (templates), Swift,
    Java, HLA (via macros), and Delphi—support some form of generic programming. In
    the generic programming style, you develop algorithms that operate on arbitrary
    data types to be defined in the future, and supply the actual data type immediately
    prior to using the generic type.
  prefs: []
  type: TYPE_NORMAL
- en: The classic example is a linked list. It’s very easy to write a simple, singly
    linked list class—say, to manage a list of integers. However, after creating your
    list of integers, you decide you need a list of doubles. A quick copy-and-paste
    operation (plus changing the node type from `int` to `double`), and you’ve got
    a class that handles linked lists of double values. Oh wait, now you want a list
    of strings? Another cut-and-paste operation, and you’ve got lists of strings.
    Now you need a list of objects? Okay, yet another cut-and-paste. . . . You get
    the idea. Before too long, you’ve created a half-dozen different list classes
    and, whoops, you discover a bug in the original implementation. Now you get to
    go back and correct that bug in every list class you’ve created. Good luck with
    that, if you’ve used the list implementation in several different projects (you’ve
    just discovered why “cut and paste” programming is not considered great code).
  prefs: []
  type: TYPE_NORMAL
- en: Generics (C++ templates) come to the rescue. With a generic class definition,
    you specify only the algorithms (methods/member functions) that manipulate the
    list; you don’t worry about the node type. You fill in the node type when you
    declare an object of the generic class type. To create integer, double, string,
    or object lists, you simply provide the type you want to the generic list class,
    and that’s it. Should you discover a bug in the original (generic) implementation,
    all you do is fix the defect once and recompile your code; everywhere you’ve used
    the generic type, the compilation applies the correction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a C++ node and list definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'The `<T>` sequence in this C++ code is a *[parameterized type](gloss01.xhtml#gloss01_190)*.
    This means that you’ll supply a type and the compiler will substitute that type
    everywhere it sees `T` in the template. So, in the preceding code, if you supply
    `int` as the parameter type, the C++ compiler will substitute `int` for every
    instance of `T`. To create a list of integers and doubles, you could use the following
    C++ code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: The easiest way to implement generics is by using macros. When a compiler sees
    a declaration such as `list <int> integerList;` it expands the associated template
    code, substituting `int` for `T` throughout the expansion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because template expansion can generate a massive amount of code, modern compilers
    try to optimize the process wherever possible. For example, if you declare two
    variables like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: there’s really no need to create two separate `list` classes, both of type `int`.
    Clearly, the template expansions would be identical, so any decent compiler would
    use the same class definition for both declarations.
  prefs: []
  type: TYPE_NORMAL
- en: Even smarter compilers would recognize that some functions, like `remove()`,
    don’t really care about the underlying node data type. The basic removal operation
    is the same for all data types; as the list data type uses a pointer for the node
    data, there’s no reason to generate different `remove()` functions for each type.
    With polymorphism, a single `remove()` member function would work fine. Recognizing
    this requires a little more sophistication on the compiler’s part, but it’s certainly
    doable.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, however, template/generic expansion is a macro expansion process.
    Anything else that happens is simply an optimization by the compiler.
  prefs: []
  type: TYPE_NORMAL
- en: '**7.11 For More Information**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Hyde, Randall. *The Art of Assembly Language*. 2nd ed. San Francisco: No Starch
    Press, 2010.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Knuth, Donald. *The Art of Computer Programming, Volume I: Fundamental Algorithms*.
    3rd ed. Boston: Addison-Wesley Professional, 1997.'
  prefs: []
  type: TYPE_NORMAL
