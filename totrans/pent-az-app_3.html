<html><head></head><body>
<h2 class="h2b" id="ch04"><span epub:type="pagebreak" id="page_69" class="calibre1"/><strong class="calibre2"><span class="big">4</span></strong><br class="calibre9"/><strong class="calibre2">EXAMINING STORAGE</strong></h2>
<div class="image"><img src="../images/00015.jpeg" alt="image" class="calibre3"/></div>
<p class="noindent">Over the next several chapters, we dive into specific Azure services and the pentest techniques and tools unique to each. We’ll begin with Azure Storage accounts, which are used by several Azure services to store everything from logs to virtual machine “hard disk” images. Customers also use storage accounts for document sharing and backups—essentially a cloud-based replacement for on-premises file servers. Of course, centralizing all of this data in one place makes for a tempting target for attackers.</p>
<p class="indent">Aside from the potential value of its data, a storage account is an ideal target for several reasons; the most important is that every storage account has two keys that grant full control to its data. These keys are shared by all services using the storage account and all account administrators. To make matters worse, most customers never change them.</p>
<p class="indent">These practices cause problems with repudiation, authorization, and remediation (if an attack does occur). Storage account keys also might <span epub:type="pagebreak" id="page_70"/>have a user-inflicted weakness: because so many applications require storage access, developers often embed storage keys in their code or configuration files without considering the possible security ramifications.</p>
<p class="indent">In this chapter, we first discuss the different authentication methods available in Azure Storage. We then look at how to find these credentials in source code, followed by a look at each of the popular tools used to access and manage Azure Storage and how credentials can be stolen from them. This is important, because you won’t know ahead of time what utilities you’ll encounter on developer systems. Finally, we look at how to retrieve different forms of data from storage accounts. This serves two purposes: first, it demonstrates to clients that improperly secured cloud storage poses a significant risk of a data breach; second, the data in the accounts can sometimes be used to obtain additional access to an environment.</p>
<h3 class="h1" id="lev95"><strong class="calibre2">Best Practices: Storage Security</strong></h3>
<p class="noindent">Improperly configured cloud storage has been mentioned in over two dozen publicly disclosed data breaches between 2016 and 2018. Generally, issues arise when developers write code that programmatically accesses a cloud storage container, and the developer embeds the access key in their source code and checks it in to source control. Since many companies use services like GitHub to host their code, the developer might not realize that the repository they checked the password into was publicly accessible. Occasionally, breaches also occur when storage accounts are configured to be readable by anyone, without requiring a password. Since malicious actors routinely scan public repositories looking for passwords and storage account URLs, trying to gain access, the time between a mistake and a breach can be very short. But even when access to a repository is limited, the number of people with access to the code is usually higher than the number of people who are authorized to have access keys. In addition, secrets and keys should never be stored in cleartext, even temporarily.</p>
<p class="indent">As an administrator, you can take several steps to protect against these issues. First, regularly practice “rolling” or resetting the access keys for your storage accounts and document any places where the keys need to be updated. This way, if a real incident does occur, you can begin remediation without worrying about breaking dependent services.</p>
<p class="indent">Next, enable encryption of data in transit and at rest for your cloud storage whenever possible. As of late 2017, Azure defaults to encrypting all data at rest in Azure Storage, using a key that is managed automatically. If desired, administrators can provide their own encryption key using the storage account settings in the Azure portal. However, although this setting protects the data on its storage medium, it doesn’t protect the data as it is uploaded or downloaded from the storage account. For this, the storage account must be configured to allow connections only over the HTTPS <span epub:type="pagebreak" id="page_71"/>protocol. This can be done in the storage account configuration settings in Azure portal by enabling the “Secure transfer required” option. It can also be enabled via PowerShell:</p>
<p class="programs">PS C:\&gt; <span class="codestrong1">Set-AzureRmStorageAccount -Name "</span><span class="codestrongitalic">StorageName</span><span class="codestrong1">" -ResourceGroupName "</span><br class="calibre5"/><span class="codestrongitalic">GroupName</span><span class="codestrong1">" -EnableHttpsTrafficOnly $True</span></p>
<p class="indent">To ensure that storage accounts can’t be accessed by more people than intended, regularly check the Access Type setting for your storage containers. It should be set to Private unless you intend to allow anonymous access. Additionally, you can use Shared Access Signature (SAS) access tokens to specify more granular permissions within storage accounts, including limiting access to specific time spans and IP ranges. For more information about these permissions, see <em class="calibre7"><a href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-manage-access-to-resources/" class="calibre6">https://docs.microsoft.com/en-us/azure/storage/blobs/storage-manage-access-to-resources/</a></em>.</p>
<p class="indent">Lastly, perform regular code reviews to look for instances of developers checking secrets into source code. You might even consider using a code analysis tool to automatically check for the presence of passwords whenever new code is checked in. This can be helpful not only for finding storage account keys but other credentials as well.</p>
<h3 class="h1" id="lev96"><strong class="calibre2">Accessing Storage Accounts</strong></h3>
<p class="noindent">Azure Storage can be accessed through storage account keys, user credentials, and <em class="calibre7">Shared Access Signature (SAS)</em> tokens, which are URLs with embedded access keys that usually provide access to a limited subset of files and may have other restrictions. Each type of credential has a different purpose, and some are more useful to a penetration tester than others. Let’s examine each of them.</p>
<h4 class="h2" id="lev97"><strong class="calibre2"><em class="calibre10">Storage Account Keys</em></strong></h4>
<p class="noindent">Using storage account keys, paired with the name of a storage account, is the most desired and frequently used method of attack because they grant full access to the entire storage account without the need for 2FA. Storage accounts have only two keys—a primary and secondary—and all storage account users share these keys. These keys don’t expire on their own, but they can be rolled. Unlike passwords, which can be chosen by a user, storage keys are automatically generated 64-byte values represented in base64 encoding, which makes them easy to identify in source code or configuration files.</p>
<p class="indent">Storage keys are also supported by every Azure Storage utility and storage-related API, making them highly versatile. Additionally, they are the most common credential used by developers and are changed infrequently, so the chances of obtaining valid keys are good.</p>
<h4 class="h2" id="lev98"><strong class="calibre2"><em class="calibre10">User Credentials</em></strong></h4>
<p class="noindent">Obtaining user credentials is the next-best way in. Although role-based permissions could limit a user account’s ability to perform certain actions <span epub:type="pagebreak" id="page_72"/>against a storage account, in practice, permissions this granular are rarely implemented. The biggest downside to relying on these credentials is the potential for encountering 2FA. If a user’s account has 2FA enabled, it’s impossible to impersonate them without using one of the methods discussed in “<a href="part0011.html#lev38" class="calibre6">Encountering Two-Factor Authentication</a>” on <a href="part0011.html#page_26" class="calibre6">page 26</a>. Those methods add additional complexity to an attack and decrease the odds of success. An additional hurdle when employing user credentials is the lack of tool support. Many of the Azure Storage utilities we’ll look at later in this chapter only accept storage keys, so you may have to log in to the Azure portal with the user credentials and copy the storage keys to use them.</p>
<h4 class="h2" id="lev99"><strong class="calibre2"><em class="calibre10">SAS Tokens</em></strong></h4>
<p class="noindent">SAS tokens are keys that grant only certain rights to a subset of objects in a storage account. For example, SAS tokens are used to enable the “share a file” options in OneDrive, SharePoint Online, Office 365, Dropbox, and similar services.</p>
<p class="indent">Azure SAS tokens are formatted as URLs that point to Azure Storage and contain a long string of parameters and a unique SHA256-hashed, base64-encoded key that looks something like this: <em class="calibre7"><a href="https://storagerm.blob.core.windows.net/container/file.txt?st=2017-04-09T01%3A00%3A00Z&amp;se=2017-04-20T01%3A00%3A00Z&amp;sp=r&amp;sip=127.0.0.1-127.0.0.100&amp;sig=7%2BwycBOdzx8IS4zhMcKNw7AHvnZlYwk8wXIqNtLEu4s%3D" class="calibre6">https://storagerm.blob.core.windows.net/container/file.txt?st=2017-04-09T01%3A00%3A00Z&amp;se=2017-04-20T01%3A00%3A00Z&amp;sp=r&amp;sip=127.0.0.1-127.0.0.100&amp;sig=7%2BwycBOdzx8IS4zhMcKNw7AHvnZlYwk8wXIqNtLEu4s%3D</a></em>.</p>
<p class="indent">Penetration testers may find SAS tokens not particularly useful, not only because they are usually scoped to a subset of files but also because they may have assigned permissions (via the SP parameter) such as read-only. SAS tokens can also be designated to work only from a specific IP address or range (via the SIP parameter), so even if you get a SAS token, it might only work from the machine for which it was originally created. SAS tokens might also have designated start and end times (via the ST and SE parameters, respectively) that limit a token’s lifetime to that period.</p>
<p class="indent">As if all this wasn’t discouraging enough, most Azure tools don’t support SAS tokens. This means you’ll likely be limited to using them through a web browser. What’s more, if you somehow find a cache of these tokens, it will take some time to go through them sequentially, thus using up valuable testing hours. That said, if the prior two credential types aren’t available, a usable SAS token is better than no access at all.</p>
<div class="sidebar">
<p class="sidebart"><strong class="calibre4">DEFENDER’S TIP</strong></p>
<p class="spara">Microsoft provides detailed guidance on choosing the correct storage authentication options, common pitfalls, possible mitigations, and ways to recover from a compromised credential at <em class="calibre10"><a href="https://docs.microsoft.com/en-us/azure/storage/storage-security-guide" class="calibre11">https://docs.microsoft.com/en-us/azure/storage/storage-security-guide</a></em>.</p>
</div>
<h3 class="h1" id="lev100"><span epub:type="pagebreak" id="page_73" class="calibre1"/><strong class="calibre2">Where to Find Storage Credentials</strong></h3>
<p class="noindent">Now that you know the types of credentials to look for, let’s examine the most common places where they can be found: source code and storage management utilities. For source code sleuthing, you’ll need access to either a developer’s machine or their source code control system. To get keys out of storage utilities, you’ll need to find where these tools are installed; typically, this is on developer workstations. With access to these systems, you can begin hunting for keys.</p>
<h4 class="h2" id="lev101"><strong class="calibre2"><em class="calibre10">Finding Keys in Source Code</em></strong></h4>
<p class="noindent">The most straightforward way to find storage keys is in the source code of applications that use Azure Storage—usually in configuration files used to build everything from an Azure website to custom business applications that use the cloud to store data. You have several ways to quickly locate storage keys in source code, but the method you should choose depends on the type of code you find.</p>
<p class="indent">Microsoft provides libraries for .NET (C# and Visual Basic) and Java to make it easier to access storage and other Azure features. Fortunately, the name of functions used to authenticate to Azure Storage are consistent across these libraries. Search for instances of the <em class="calibre7">StorageCredentials</em> class, and you’ll likely find where any application uses storage keys. If that doesn’t work, try searching for the library’s full name, such as <em class="calibre7">Microsoft.WindowsAzure.Storage.Auth</em> in .NET or <em class="calibre7">com.microsoft.azure.storage.StorageCredentials</em> in Java.</p>
<p class="indent">If you suspect that a certain storage instance may use SAS tokens, search code repositories for <em class="calibre7">.core.windows.net</em>, the domain used in all SAS token URLs. (The base64 signature in SAS tokens should make them easy to distinguish from any other <em class="calibre7">windows.net</em> domain references.)</p>
<p class="indent">Many code bases place storage account keys into configuration files, especially when coupled with ASP.NET and Azure websites. ASP.NET and Azure websites use files named <em class="calibre7">web.config</em>, whereas other websites often use <em class="calibre7">app.config</em> files. Storage account keys in config files are often labeled <em class="calibre7">StorageAccountKey</em>, <em class="calibre7">StorageServiceKeys</em>, or <em class="calibre7">StorageConnectionString</em> (the name used in some Microsoft documentation sample code).</p>
<p class="indent">You can identify Azure Storage use within JavaScript files by scanning for <em class="calibre7">azure-storage.common.js</em>. If you find this script reference in code, also look for <em class="calibre7">AzureStorage.createBlobService</em>; you’ll need it in order to authenticate to Azure. (The JavaScript library allows the use of both storage keys and SAS tokens, but greatly encourages the use of highly restricted SAS tokens because users can view JavaScript code.)</p>
<h4 class="h2" id="lev102"><strong class="calibre2"><em class="calibre10">Obtaining Keys from a Developer’s Storage Utilities</em></strong></h4>
<p class="noindent">If you can’t find storage keys in source code, you may be able to recover them from tools that the developers used to transfer files to Azure. To find these keys, you first need to access a developer’s workstation and then look for Azure Storage management applications. Once you have access, check the application to see if it exposes saved keys in its user interface or if it saves the keys in an insecure manner.</p>
<p class="indent"><span epub:type="pagebreak" id="page_74"/>In this section, we look at the tools most commonly used to manage storage accounts to see if they’re susceptible to this attack.</p>
<div class="sidebar">
<p class="sidebart"><strong class="calibre4">DEFENDER’S TIP</strong></p>
<p class="spara">Notice in the following discussion that only Microsoft Azure Storage Explorer makes key recovery difficult for an attacker. If you must use a tool to manage Azure Storage and if you have cached credentials on your system, Microsoft Azure Storage Explorer is the safest choice.</p>
</div>
<h5 class="h3" id="lev103"><strong class="calibre2">Getting Keys from Microsoft Azure Storage Explorer</strong></h5>
<p class="noindent">Azure Storage Explorer is well designed, with storage key protection as an obvious goal. It offers no option to show a key once it’s saved in the interface, and the encrypted keys are stored in Windows Credential Manager, which makes recovering them directly impractical.</p>
<p class="indent">Despite these security features, all is not lost. Because Azure Storage Explorer needs to decrypt the keys in order to provide them to Azure’s API when transferring data, you can set a breakpoint in Storage Explorer’s code on the line just after the keys are decrypted and then view them directly in memory with the built-in debugger.</p>
<p class="indent">To perform this test, follow these steps:</p>
<ol class="calibre16">
<li class="noindent1" value="1"><p class="list">Launch Azure Storage Explorer on the target engineer’s workstation.</p></li>
<li class="noindent1" value="2"><p class="list">Choose <strong class="calibre4">Help</strong> <span class="ent">▸</span> <strong class="calibre4">Toggle Developer Tools</strong>. You should see the debugger interface.</p></li>
<li class="noindent1" value="3"><p class="list">In the debugging window, click the <strong class="calibre4">Sources</strong> tab at the top of the screen and then click the vertical ellipse menu and choose <strong class="calibre4">Go to file</strong>, as shown in <a href="part0013.html#ch04fig1" class="calibre6">Figure 4-1</a>.</p>
<div class="image1"><a id="ch04fig1" class="calibre6"/><img src="../images/00021.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-1: The Sources view in Azure Storage Explorer</em></p></li>
<li class="noindent1" value="4"><p class="list"><span epub:type="pagebreak" id="page_75"/>In the file list dialog that appears, enter <span class="codestrong">AzureStorageUtilities.js</span> and click the first entry to load the <em class="calibre7">AzureStorageUtilities.js</em> file, which contains the logic to load the storage account keys.</p></li>
<li class="noindent1" value="5"><p class="list">Expand the debugger window so you can read the source code; then find the function <span class="literal">loadStorageAccounts(host, key)</span>, which is shown in <a href="part0013.html#ch04list1" class="calibre6">Listing 4-1</a>.</p>
<p class="programs">    /**<br class="calibre5"/>     * Load the stored storage accounts:<br class="calibre5"/>     * Get account data from localStorage<br class="calibre5"/>     * Combine session key and account data as user account manager key <br class="calibre5"/>     * to get account key stored there.<br class="calibre5"/>     * @param host<br class="calibre5"/>     * @param key<br class="calibre5"/>     */<br class="calibre5"/>    function loadStorageAccounts(host, key) {<br class="calibre5"/>        --<span class="codeitalic">snip</span>--<br class="calibre5"/>                switch (account.connectionType) {<br class="calibre5"/>                    case 1 /* sasAttachedAccount */:<br class="calibre5"/>                        account.connectionString = confidentialData;<br class="calibre5"/>                        break;<br class="calibre5"/>                    case 3 /* key */:<br class="calibre5"/>                        account.accountKey = confidentialData;<br class="calibre5"/>                        break;<br class="calibre5"/>                    default:<br class="calibre5"/>                        // For backward compatibility reasons if the <br class="calibre5"/>                        // connection type is not set<br class="calibre5"/>                        // we assume it is a key<br class="calibre5"/>                        account.accountKey = confidentialData;<br class="calibre5"/>                }<br class="calibre5"/>              return account;<br class="calibre5"/>            });<br class="calibre5"/>            return storageAccounts;<br class="calibre5"/>        });<br class="calibre5"/>    }</p>
<p class="listing" id="ch04list1"><em class="calibre7">Listing 4-1: Code snippet from Microsoft Azure Storage Explorer’s</em> <span class="codeitalic2">loadStorageAccounts()</span> <em class="calibre7">function</em></p></li>
<li class="noindent1" value="6">Set a breakpoint in this function just before the account information is returned to the application by clicking the line number for the line <span class="literal">return account;</span> on the left side of the window, as shown in <a href="part0013.html#ch04fig2" class="calibre6">Figure 4-2</a>.</li>
<li class="noindent1" value="7">Now, to trigger the application to reload the account information so that the breakpoint will be hit, click <strong class="calibre4">Refresh All</strong> above the list of accounts. The debugger should break in and pause the application. Look for the <span class="codestrong">account: Object</span> variable on the right side of the window (as shown in <a href="part0013.html#ch04fig2" class="calibre6">Figure 4-2</a>) and click the arrow next to <span class="literal">account</span> to expand it.</li>
</ol>
<div class="image1"><span epub:type="pagebreak" id="page_76"/><a id="ch04fig2" class="calibre6"/><img src="../images/00022.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-2: Account object expanded in the debugger</em></p>
<p class="indent">The <span class="literal">account</span> object should list the <span class="literal">accountKey</span> as well as the <span class="literal">accountName</span> of the first storage account registered in Azure Storage Explorer. To see if there are multiple accounts, press F8 to continue execution. If there are more storage accounts, the debugger should immediately break in again and update the account object with the next account details. Keep pressing F8 until you have recovered the connection information for each storage account.</p>
<p class="indent">Once the last storage account’s details are shown, press F8 again to return the application to normal operation. Then remove your breakpoint by right-clicking in the Breakpoints list in the pane on the right and choosing <strong class="calibre4">Remove All Breakpoints</strong>. Finally, click <strong class="calibre4">Help</strong> <span class="ent">▸</span> <strong class="calibre4">Toggle Developer Tools</strong> to close the debugging tools and then exit the application.</p>
<h5 class="h3" id="lev104"><strong class="calibre2">Getting Keys from Redgate’s Azure Explorer</strong></h5>
<p class="noindent">Redgate’s Azure Explorer gives you two ways to access the keys it contains: a connection editor dialog and a Copy option in each account’s context menu. To view account keys, launch Redgate’s Azure Explorer, open the account, and then right-click the account to dig into its details, as shown in <a href="part0013.html#ch04fig3" class="calibre6">Figure 4-3</a>.</p>
<div class="image1"><a id="ch04fig3" class="calibre6"/><img src="../images/00023.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-3: Redgate’s storage account menu</em></p>
<p class="indent">The Edit Connection Details option opens a dialog like the one shown in <a href="part0013.html#ch04fig4" class="calibre6">Figure 4-4</a>, where you can update the key associated with a storage account. The dialog conveniently displays the current key in plaintext.</p>
<div class="image1"><span epub:type="pagebreak" id="page_77"/><a id="ch04fig4" class="calibre6"/><img src="../images/00024.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-4: Storage account key in Redgate’s Azure Explorer</em></p>
<p class="indent">The Copy Connection String option is also interesting. You can use it to copy the key to the clipboard in SQL Connection String format, which contains the key itself and the account name, and also indicates whether the storage account should be accessed using SSL or an unencrypted connection. Use this option to grab all required connection information for an account and then paste it into a small document. Repeat this for each listed account.</p>
<div class="note">
<p class="notet"><strong class="calibre2"><span class="notes">NOTE</span></strong></p>
<p class="notep"><em class="calibre7">Because Redgate encrypts storage keys in Azure Explorer’s settings file</em> %UserProfile%\AppData\Local\Red Gate\Azure Explorer\Settings.xml<em class="calibre7">, you will need to be able to run Azure Explorer to recover the keys; you can’t simply take the XML file.</em></p>
</div>
<h5 class="h3" id="lev105"><strong class="calibre2">Getting Keys from ClumsyLeaf’s CloudXplorer</strong></h5>
<p class="noindent">ClumsyLeaf Software makes three products for interacting with cloud-based storage: CloudXplorer, TableXplorer, and AzureXplorer. All of these tools allow you to manage not just Azure Storage but also storage offerings from other providers, such as Amazon and Google.</p>
<p class="indent">CloudXplorer interacts with files and blob storage, whereas TableXplorer provides a SQL-like interface for tabular cloud storage. AzureXplorer is a Visual Studio plug-in to make interacting with cloud content easier during development.</p>
<p class="indent">You can view and edit stored keys in CloudXplorer by right-clicking a storage account in the left pane and choosing <strong class="calibre4">Properties</strong>, as shown in <a href="part0013.html#ch04fig5" class="calibre6">Figure 4-5</a>.</p>
<div class="image1"><span epub:type="pagebreak" id="page_78"/><a id="ch04fig5" class="calibre6"/><img src="../images/00025.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-5: Storage account context menu in CloudXplorer</em></p>
<p class="indent">The Account window (see <a href="part0013.html#ch04fig6" class="calibre6">Figure 4-6</a>) shows which Azure instance is being used and whether SSL is enabled, and should allow you to copy both the name and key of the storage account.</p>
<div class="image1"><a id="ch04fig6" class="calibre6"/><img src="../images/00026.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-6: Account information in CloudXplorer</em></p>
<div class="note">
<p class="notet"><strong class="calibre2"><span class="notes">NOTE</span></strong></p>
<p class="notep"><em class="calibre7">CloudXplorer’s Configuration</em> <span class="ent">▸</span> <em class="calibre7">Export option exports all of the storage account connection details, but they’re encrypted. You’re not likely to find that very useful.</em></p>
</div>
<p class="indent">Like Redgate, ClumsyLeaf also encrypts its account information within an XML file. You’ll find it at <em class="calibre7">%AppData%\ClumsyLeaf Software\CloudXplorer\accounts.xml</em>.</p>
<h5 class="h3" id="lev106"><span epub:type="pagebreak" id="page_79" class="calibre1"/><strong class="calibre2">Getting Keys from ClumsyLeaf’s TableXplorer</strong></h5>
<p class="noindent">To use TableXplorer to view storage accounts, click <strong class="calibre4">Manage Accounts</strong>, as shown in <a href="part0013.html#ch04fig7" class="calibre6">Figure 4-7</a>, to open the Manage Accounts window.</p>
<div class="image1"><a id="ch04fig7" class="calibre6"/><img src="../images/00027.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-7: The Manage Accounts button in TableXplorer</em></p>
<p class="indent">The Manage Accounts window should display each account, as shown in <a href="part0013.html#ch04fig8" class="calibre6">Figure 4-8</a>. Azure Storage accounts are marked with a Windows logo and Amazon accounts with an orange cube. Click the name of an account and choose <strong class="calibre4">Edit</strong>.</p>
<div class="image1"><a id="ch04fig8" class="calibre6"/><img src="../images/00028.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-8: Account list in TableXplorer</em></p>
<p class="indent">The Edit window will look just like the CloudXplorer window shown earlier in <a href="part0013.html#ch04fig6" class="calibre6">Figure 4-6</a>. Also, like CloudXplorer, TableXplorer encrypts the keys in its configuration file, which is located at <em class="calibre7">%AppData%\ClumsyLeaf Software\TableXplorer\accounts.xml</em>.</p>
<h5 class="h3" id="lev107"><strong class="calibre2">Getting Keys from Azure Storage Explorer 6</strong></h5>
<p class="noindent">Azure Storage Explorer 6 is probably the oldest tool on this list. Although it’s no longer maintained, it was the standard for years, and you’ll probably find it on many developer systems for years to come.</p>
<p class="indent"><span epub:type="pagebreak" id="page_80"/>To view storage account settings through Azure Storage Explorer 6, follow these steps:</p>
<ol class="calibre16">
<li class="noindent1" value="1"><p class="list">Launch the application and choose an account from the drop-down list.</p></li>
<li class="noindent1" value="2"><p class="list">Select the account and then choose <strong class="calibre4">Storage Account</strong> <span class="ent">▸</span> <strong class="calibre4">View Connection String</strong>, as shown in <a href="part0013.html#ch04fig9" class="calibre6">Figure 4-9</a>.</p>
<div class="image1"><a id="ch04fig9" class="calibre6"/><img src="../images/00029.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-9: The Storage Account menu in Azure Storage Explorer 6</em></p></li>
<li class="noindent1" value="3"><p class="list">You should see a pop-up message box appear, displaying the SQL Connection String–formatted account key, as shown in <a href="part0013.html#ch04fig10" class="calibre6">Figure 4-10</a>. Click <strong class="calibre4">OK</strong> to copy the value to the clipboard.</p>
<div class="image1"><a id="ch04fig10" class="calibre6"/><img src="../images/00030.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-10: Storage account connection string in Azure Storage Explorer 6</em></p></li>
</ol>
<p class="indent">Prior to version 6 of Azure Storage Explorer, unencrypted credentials were stored in <em class="calibre7">%AppData%\AzureStorageExplorer\AzureStorageExplorer.config</em>, making this a valuable file to look for any time you suspect a machine has been used to manage storage accounts. Beginning with version 6, these settings were encrypted and moved to <em class="calibre7">%AppData%\Neudesic\AzureStorageExplorer\&lt;Version&gt;\AzureStorageExplorer6.dt1</em>. However, because Azure Storage Explorer is open source and because the same encryption <span epub:type="pagebreak" id="page_81"/>key is used in every installation, it’s very easy to find the encryption key it uses to “protect” these files online, as well as the encryption and decryption code. Of course, it’s easier to recover storage keys from the GUI, but it’s helpful to have another option if you can’t launch applications on the system you’re targeting.</p>
<h3 class="h1" id="lev108"><strong class="calibre2">Accessing Storage Types</strong></h3>
<p class="noindent">Once you have access to a storage account, it’s time to find out what kind of data you can obtain. First, you’ll need to determine which storage mechanisms each account uses (blob, table, queue, and/or file), bearing in mind that a single account can use more than one mechanism. Be sure to check each account for each storage type.</p>
<h4 class="h2" id="lev109"><strong class="calibre2"><em class="calibre10">Identifying the Storage Mechanisms in Use</em></strong></h4>
<p class="noindent">Although you can check for storage account content using the Azure portal, a penetration tester could face a couple of challenges with that method. First, an account may have only a management certificate, which won’t provide direct portal access. Second, the Azure portal doesn’t display a summary of each storage type in one view; you have to click each account, click to view any blobs in that account, and then click the button for files, and so on. This process takes a while when subscriptions contain numerous storage accounts.</p>
<p class="indent">The best way to identify the storage types in use is with PowerShell. For example, the PowerShell script shown in <a href="part0013.html#ch04list2" class="calibre6">Listing 4-2</a> will enumerate all storage accounts in a subscription, check each storage mechanism for content, and then display a summary of anything it finds.</p>
<p class="programs">   # ASM Storage Accounts<br class="calibre5"/>   Write-Output "&gt;&gt;&gt; ASM &lt;&lt;&lt;"<br class="calibre5"/><span class="ent">➊</span> $storage = Get-AzureStorageAccount<br class="calibre5"/>   foreach($account in $storage)<br class="calibre5"/>   {<br class="calibre5"/>       $accountName = $account.StorageAccountName<br class="calibre5"/>       Write-Output "======= ASM Storage Account: $accountName ======="<br class="calibre5"/>    <span class="ent">➋</span> $key = Get-AzureStorageKey -StorageAccountName $accountName<br class="calibre5"/>    <span class="ent">➌</span> $context = New-AzureStorageContext -StorageAccountName `<br class="calibre5"/>           $accountName -StorageAccountKey $key.Primary<br class="calibre5"/>    <span class="ent">➍</span> $containers = Get-AzureStorageContainer -Context $context<br class="calibre5"/>       foreach($container in $containers)<br class="calibre5"/>       {<br class="calibre5"/>           Write-Output "----- Blobs in Container: $($container.Name) -----"<br class="calibre5"/>        <span class="ent">➎</span> Get-AzureStorageBlob -Context $context -Container $container.Name |<br class="calibre5"/>               format-table Name, Length, ContentType, LastModified -auto<br class="calibre5"/>       }<br class="calibre5"/>       Write-Output "----- Tables -----"<br class="calibre5"/>    <span class="ent">➏</span> Get-AzureStorageTable -Context $context | format-table Name -auto<br class="calibre5"/>       Write-Output "----- Queues -----"<br class="calibre5"/>    <span class="ent">➐</span> Get-AzureStorageQueue -Context $context |<br class="calibre5"/>           format-table Name, Uri, ApproximateMessageCount -auto<br class="calibre5"/><span epub:type="pagebreak" id="page_82"/>    <span class="ent">➑</span> $shares = Get-AzureStorageShare -Context $context<br class="calibre5"/>       foreach($share in $shares)<br class="calibre5"/>       {<br class="calibre5"/>           Write-Output "----- Files in Share : $($share.Name) -----"<br class="calibre5"/>        <span class="ent">➒</span> Get-AzureStorageFile -Context $context -ShareName $share.Name |<br class="calibre5"/>               format-table Name, @{label='Size';e={$_.Properties.Length}} -auto<br class="calibre5"/>       }<br class="calibre5"/>       Write-Output ""<br class="calibre5"/>   }<br class="calibre5"/>   Write-Output ""<br class="calibre5"/><br class="calibre5"/>   # ARM Storage Accounts<br class="calibre5"/>   Write-Output "&gt;&gt;&gt; ARM &lt;&lt;&lt;"<br class="calibre5"/>   $storage = Get-AzureRmStorageAccount<br class="calibre5"/>   foreach($account in $storage)<br class="calibre5"/>   {<br class="calibre5"/>       $accountName = $account.StorageAccountName<br class="calibre5"/>       Write-Output "======= ARM Storage Account: $accountName ======="<br class="calibre5"/>       $key = Get-AzureRmStorageAccountKey -StorageAccountName `<br class="calibre5"/>           $accountName -ResourceGroupName $account.ResourceGroupName<br class="calibre5"/>       $context = New-AzureStorageContext -StorageAccountName `<br class="calibre5"/>           $accountName -StorageAccountKey $key[0].Value<br class="calibre5"/>       $containers = Get-AzureStorageContainer -Context $context<br class="calibre5"/>       foreach($container in $containers)<br class="calibre5"/>       {<br class="calibre5"/>           Write-Output "----- Blobs in Container: $($container.Name) -----"<br class="calibre5"/>           Get-AzureStorageBlob -Context $context -Container $container.Name |<br class="calibre5"/>               format-table Name, Length, ContentType, LastModified -auto<br class="calibre5"/>       }<br class="calibre5"/>       Write-Output "----- Tables -----"<br class="calibre5"/>       Get-AzureStorageTable -Context $context | format-table Name -auto<br class="calibre5"/>       Write-Output "----- Queues -----"<br class="calibre5"/>       Get-AzureStorageQueue -Context $context |<br class="calibre5"/>           format-table Name, Uri, ApproximateMessageCount -auto<br class="calibre5"/>       $shares = Get-AzureStorageShare -Context $context<br class="calibre5"/>       foreach($share in $shares)<br class="calibre5"/>       {<br class="calibre5"/>           Write-Output "----- Files in Share : $($share.Name) -----"<br class="calibre5"/>           Get-AzureStorageFile -Context $context -ShareName $share.Name |<br class="calibre5"/>               format-table Name, @{label='Size';e={$_.Properties.Length}} -auto<br class="calibre5"/>       }<br class="calibre5"/>       Write-Output ""<br class="calibre5"/>   }</p>
<p class="listing" id="ch04list2"><em class="calibre7">Listing 4-2: Listing storage account usage via PowerShell</em></p>
<p class="indent">This script is split into two parts: the first part searches ASM storage accounts, and the second searches ARM.</p>
<p class="indent">We begin by getting a list of all ASM storage accounts in the subscription <span class="ent">➊</span>. For each account, we obtain the key <span class="ent">➋</span> and then create a <em class="calibre7">context</em> for that storage account <span class="ent">➌</span>—a PowerShell object that contains both the name and key of the storage account. We can use this context when accessing a storage account in the future.</p>
<p class="indent"><span epub:type="pagebreak" id="page_83"/>Next, the script begins examining the different storage types, as discussed in the following sections, before repeating the process for ARM storage accounts.</p>
<h4 class="h2" id="lev110"><strong class="calibre2"><em class="calibre10">Accessing Blobs</em></strong></h4>
<p class="noindent">A blob is the most basic form of storage in Azure: it’s an unstructured collection of bits that applications can use without restriction. Blobs are most commonly used to store virtual hard disk files for Azure virtual machines.</p>
<p class="indent">You’ll find three kinds of blobs in Azure: <em class="calibre7">page</em>, <em class="calibre7">append</em>, and <em class="calibre7">block</em>. As a pentester, it can be helpful to know the primary usage for each blob type so you can make an educated guess about the contents of a given blob without necessarily having to download it. In my assessments, I’ve found it can be enormously frustrating to download a multi-gigabyte file over several hours, only to discover it isn’t what I expected.</p>
<ul class="calibre8">
<li class="noindent1"><em class="calibre7">Page blobs</em> are made up of sets of bytes, referred to as <em class="calibre7">pages</em>. Each page is 512 bytes, and a page blob itself can be up to 1TB in size. The total size must be set when the blob is created, which means there is a strong chance a page blob file will be quite large, but only a small fraction of it will be data—the rest will likely be empty. Because page blobs are very efficient at random reads/writes, they are the blob type used for hard disk images.</li>
<li class="noindent1"><em class="calibre7">Append blobs</em> are optimized for adding new data, but changes are prohibited to existing data within the blob. They can be up to 195GB in size and are ideal for log files. Log files may be interesting if you are trying to identify additional user accounts, IP addresses, or servers that could be related to your assessment; however, if you are just hoping to modify logs to erase your tracks, append blobs won’t let you do so.</li>
<li class="noindent1"><em class="calibre7">Block blobs</em> are the default type. They consist of one or more blocks of bytes that can vary in size up to 100MB. Up to 50,000 blocks can be placed in a single blob, and block blobs can grow as needed. This is used for all other types of unstructured data.</li>
</ul>
<p class="indent">Azure requires users to place all blobs in a <em class="calibre7">container</em>, which is like a file directory, except that it can’t be nested. In other words, a container can hold blobs, but not other containers. Each storage account can have an unlimited number of containers, and each container can have any number of blobs within it.</p>
<p class="indent">The script in <a href="part0013.html#ch04list2" class="calibre6">Listing 4-2</a> obtains a list of all blob containers at <span class="ent">➍</span> with the <span class="literal">Get-AzureStorageContainer</span> cmdlet and then prints a table for each container using <span class="literal">Get-AzureStorageBlob</span>, with one line per blob <span class="ent">➎</span>. The table includes the blob’s name, size, data type, and the date it was last changed, as shown in <a href="part0013.html#ch04list3" class="calibre6">Listing 4-3</a>. Look through this list for files that sound useful, ignoring any <em class="calibre7">.status</em> files and most logs, and focusing instead on documents, <span epub:type="pagebreak" id="page_84"/>source code, and configuration files. Once you have a list of interesting files, use one of the Azure Storage management tools to begin collecting the files.</p>
<div class="programs1"><img src="../images/00031.jpeg" alt="image" class="calibre3"/></div>
<p class="listing" id="ch04list3"><em class="calibre7">Listing 4-3: Output from blob commands</em></p>
<p class="indent">To view a blob’s content, Microsoft Azure Storage Explorer is probably the best option for a penetration tester. It’s free, properly exposes all types of blobs, and supports opening both ASM and ARM storage. Perhaps most importantly, it allows access to storage accounts using a variety of sign-in options, including the following:</p>
<ul class="calibre8">
<li class="noindent1">Shared Access Signature token</li>
<li class="noindent1">Storage account key in SQL Connection String format</li>
<li class="noindent1">Storage account name and key</li>
<li class="noindent1">Username and password of a user with access to the subscription</li>
</ul>
<p class="indent">The username and password login feature is especially nice because it will populate the application with the storage accounts for every subscription the user can access. You can also add more than one user account so that you can view files for every compromised account simultaneously.</p>
<p class="indent">With all the storage accounts added to Microsoft Azure Storage Explorer, expand the blob storage section under the desired storage accounts; then browse the list of containers, select a file of interest, and click the <strong class="calibre4">Download</strong> button to pull down a copy, as shown in <a href="part0013.html#ch04fig11" class="calibre6">Figure 4-11</a>.</p>
<div class="image1"><a id="ch04fig11" class="calibre6"/><img src="../images/00032.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-11: Downloading blobs from Microsoft Azure Storage Explorer</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_85"/>Once you’ve retrieved the files, be sure to check them for additional credentials. I’ve found a surprising number of secrets stored in Azure Storage. This makes it a fantastic place to gain access to additional systems or services, moving deeper into the target’s environment.</p>
<div class="sidebar">
<p class="sidebart"><strong class="calibre4">DEFENDER’S TIP</strong></p>
<p class="spara">Azure Storage blobs aren’t an ideal place to store unencrypted secrets. Because of the broad access and repudiation that access keys provide, secrets should be kept elsewhere—or at the very least encrypted with a key not kept in a storage account. Azure Key Vault, although not completely immune from attack, as I’ll discuss in <a href="part0016.html#ch07" class="calibre11">Chapter 7</a>, is a far better choice for secret storage.</p>
</div>
<h4 class="h2" id="lev111"><strong class="calibre2"><em class="calibre10">Accessing Tables</em></strong></h4>
<p class="noindent">Tables provide storage of tabular data in Azure. They are great for keeping semi-structured data like web service logs or website content databases, and they are good alternatives to a resource-intensive, costlier database solution like SQL Server.</p>
<p class="indent"><a href="part0013.html#ch04list2" class="calibre6">Listing 4-2</a> calls the <span class="literal">Get-AzureStorageTable</span> cmdlet <span class="ent">➏</span>, which will return all the table names in the provided storage context, as shown in <a href="part0013.html#ch04list4" class="calibre6">Listing 4-4</a>. You can also use the only other cmdlet for Azure tables, <span class="literal">Get-AzureStorageTableStoredAccessPolicy</span>, which displays any special permissions for a table. I rarely find access policies in use, so I typically skip it. With such limited PowerShell options, you need to use a stand-alone tool to access a table’s data.</p>
<p class="programs">----- Tables -----<br class="calibre5"/><br class="calibre5"/>Name<br class="calibre5"/>----<br class="calibre5"/>TestTable<br class="calibre5"/>TransactionAudits<br class="calibre5"/>SchemasTable</p>
<p class="listing" id="ch04list4"><em class="calibre7">Listing 4-4: Output from</em> <span class="codeitalic2">Get-AzureStorageTable</span> <em class="calibre7">command</em></p>
<p class="indent">Selecting the right tool is easy because there aren’t many options. The primary ones are Microsoft Azure Storage Explorer and ClumsyLeaf’s TableXplorer. In this case, I prefer TableXplorer, even though it’s not freeware, because it’s very quick, has options for exporting data, and provides a query option, shown in <a href="part0013.html#ch04fig12" class="calibre6">Figure 4-12</a>, that uses normal SQL syntax. This last feature makes identifying data incredibly easy for anyone with a SQL background. Microsoft Azure Storage Explorer also has a query capability, but it doesn’t work with SQL syntax and is slower than TableXplorer.</p>
<p class="indent"><span epub:type="pagebreak" id="page_86"/>In TableXplorer, you might find a number of tables, with names starting with <span class="literal">$Metrics</span>, that don’t appear when using PowerShell. Azure automatically generates and uses these tables to store details about the storage account in which they reside. The dollar sign (<span class="literal">$</span>) at the beginning of the name marks them as hidden, so PowerShell doesn’t enumerate them.</p>
<div class="image1"><a id="ch04fig12" class="calibre6"/><img src="../images/00033.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-12: Using TableXplorer to query Azure Storage tables with SQL syntax</em></p>
<p class="indent">Data in these metrics tables track things like the total number of blobs being stored and any transactions that have billing implications, such as the addition or removal of data. These files typically have little value to an attacker, unless they want to look for log entries that show activity they performed against the storage account. Unfortunately, you can’t remove these entries because the metrics tables are read-only.</p>
<h4 class="h2" id="lev112"><strong class="calibre2"><em class="calibre10">Accessing Queues</em></strong></h4>
<p class="noindent">Azure Storage queues provide a place to line up transactions and process them sequentially as resources become available. Mainly software developers use queues; after all, few people other than developers need to worry about processing data in order.</p>
<p class="indent">From a penetration testing perspective, I used to find queues boring. They usually sit empty, waiting for a flood of work to come in, and are drained shortly thereafter when the tasks are all handled. I changed my opinion, though, when I saw the most beautiful, yet horrifying use of queues imaginable: a queue to send unsigned commands to a server for execution. Many security researchers will spend weeks or even months trying to find <span epub:type="pagebreak" id="page_87"/>vulnerable software and develop <em class="calibre7">remote code execution</em> exploits—getting a process on a different computer to run code under the attacker’s control. Here, it wasn’t a vulnerability but rather an intentional feature!</p>
<p class="indent">Although that particular instance is an extreme case, queues actually lend themselves to this kind of behavior if a developer isn’t careful. Developers generally use them as an input into some custom application, like an order fulfillment system. The application’s developer might expect that the queue only contains work items from another trusted system they own, such as the order page on their website, so the developer neglects to put in proper validation on the work item’s fields. That means an attacker can inject their own custom messages into the queue, and the service that processes them might not confirm that the data in those messages makes sense. If these fields happen to contain the price of items for sale, the bank account where payments should be sent, or what system commands the computer processing the request should run, then the attacker has found a very high-priority bug.</p>
<div class="sidebar">
<p class="sidebart"><strong class="calibre4">DEFENDER’S TIP</strong></p>
<p class="spara">If you use a queue to transport confidential data or to send commands that must come from a verified source, you should use asymmetric cryptography to encrypt or sign the messages before they are placed in the queue. Then, the receiver can decrypt the message or validate its signature to ensure it is authentic and hasn’t been tampered with.</p>
</div>
<p class="indent">Queues are often used as a backend service that developers typically use to facilitate communication between applications, so they have good API support and interacting with them is limited without writing custom applications. PowerShell only has two relevant cmdlets to display queue information. One is <span class="literal">Get-AzureStorageQueue</span>, which I use in the script in <a href="part0013.html#ch04list2" class="calibre6">Listing 4-2</a> <span class="ent">➐</span> to enumerate the queues and their current message count, as shown in <a href="part0013.html#ch04list5" class="calibre6">Listing 4-5</a>. The second is <span class="literal">Get-AzureStorageQueueStoredAccessPolicy</span>, which is used for viewing SAS token permissions and restrictions, which are rarely used. Note that there are no cmdlets to create or view items in the queue.</p>
<p class="programs">----- Queues -----<br class="calibre5"/>Name      Uri                                               ApproximateMessageCount<br class="calibre5"/>----      ---                                               -----------------------<br class="calibre5"/>testqueue https://storeasm.queue.core.windows.net/testqueue                       0</p>
<p class="listing" id="ch04list5"><em class="calibre7">Listing 4-5: Output from</em> <span class="codeitalic2">Get-AzureStorageQueue</span> <em class="calibre7">command</em></p>
<p class="indent">To actually see and insert messages into a queue, you must, once again, turn to Microsoft Azure Storage Explorer. From its interface, select a storage <span epub:type="pagebreak" id="page_88"/>account, expand the Queues list below that account, and then select a queue. This will open a view that shows all currently queued messages, and it allows you to view the contents of a message or insert a new message. I suggest examining any existing messages to get a sense of what valid messages look like before trying to insert your own. If the queue is empty, try to find the source code for the application that processes the messages to see what it’s expecting.</p>
<div class="note">
<p class="notet"><strong class="calibre2"><span class="notes">WARNING</span></strong></p>
<p class="notep"><em class="calibre7">Azure queues, like queue data structures in other programming languages, have two functions related to viewing a message. You can use</em> <span class="codeitalic1">PeekMessage</span> <em class="calibre7">to view the next message in the queue without changing or removing it. On the other hand,</em> <span class="codeitalic1">GetMessage</span> <em class="calibre7">actually takes the item from the queue and hides it from any other program that’s using the queue. If you’re just using Microsoft Azure Storage Explorer, you don’t have to worry about this, but if you develop a custom application to snoop on queues, calling</em> <span class="codeitalic1">GetMessage</span> <em class="calibre7">might prevent Azure from processing a legitimate request (from the queue). So be sure you fully understand these APIs before using them!</em></p>
</div>
<h4 class="h2" id="lev113"><strong class="calibre2"><em class="calibre10">Accessing Files</em></strong></h4>
<p class="noindent">The latest addition to Azure Storage’s offerings, called Azure Files, is a cloud-based SMB file share service. It allows users to create shared directories and fill them with files, just like in an on-premises file server. This is useful for migrating legacy applications that depend on SMB shares to Azure. Azure Files allows connections from clients that support the SMB 2.1 or SMB 3.0 protocol.</p>
<p class="indent">While Azure Files is designed to be a drop-in replacement for an existing enterprise file server, it does have some limitations. First, any clients connecting to it must be able to reach the service on the native SMB port: TCP 445. This might not sound like a big deal, but some corporate networks block TCP 445 traffic in both directions, because file shares are normally considered an internal resource. However, the biggest difference from a traditional Windows file server is the lack of user accounts and permissions.</p>
<p class="indent">On a normal SMB share, a user can assign Read, Change, and Full Control permissions to any number of users or groups. Additionally, a user can specify file system–level permissions on files within these shares to further restrict access.</p>
<p class="indent">Azure Files is different. By design, its shares have only one user and it isn’t configurable. The share’s user is <span class="literal">AZURE\</span><span class="codeitalic1">Name_of_Storage_Account</span>, and the password is the primary key for that storage account, once again highlighting the importance of protecting storage account keys from unauthorized access. So to get full access to an Azure Files share named <span class="codeitalic1">myshare</span> within a storage account named <span class="codeitalic1">mysa</span>, you would run the following from a Windows command line:</p>
<p class="programs"><span class="codestrong1">net use</span> <span class="codestrong1">* \\</span><span class="codestrongitalic">mysa</span><span class="codestrong1">.file.core.windows.net\</span><span class="codestrongitalic">myshare</span> <span class="codestrong1">/u:AZURE\</span><span class="codestrongitalic">mysa Primary_Key</span></p>
<div class="note">
<p class="notet"><span epub:type="pagebreak" id="page_89" class="calibre1"/><strong class="calibre2"><span class="notes">NOTE</span></strong></p>
<p class="notep"><em class="calibre7">Connections from remote machines to Azure Files is limited to Windows hosts that support SMB 3.0 because Linux, and Windows versions prior to Windows 8, don’t support encrypted SMB connections. Linux and older Windows versions can connect to Azure Files, but only if they are virtual machines running within Azure and are in the same Azure region.</em></p>
</div>
<p class="indent">To enumerate the shares, use the <span class="literal">Get-AzureStorageShare</span> cmdlet shown in <a href="part0013.html#ch04list2" class="calibre6">Listing 4-2</a> at <span class="ent">➑</span>. For each share, you can use the cmdlet <span class="literal">Get-AzureStorageFile</span> to see a list of files within that share. At <span class="ent">➒</span> in <a href="part0013.html#ch04list2" class="calibre6">Listing 4-2</a>, I piped the output of <span class="literal">Get-AzureStorageFile</span> to the format-table command—with some rather ugly parameters—to display each file on one line and to include the name of the file with its size in bytes. Because the file size is buried in the properties of each file object (and is called “Length”), you need to display it using PowerShell’s hash table syntax. The <span class="literal">-auto</span> switch adjusts the column widths of the table automatically. The resulting output is shown in <a href="part0013.html#ch04list6" class="calibre6">Listing 4-6</a>.</p>
<p class="programs">----- Files in Share : asmshare -----<br class="calibre5"/><br class="calibre5"/>Name         Size<br class="calibre5"/>----         ----<br class="calibre5"/>testfile.txt   33</p>
<p class="listing" id="ch04list6"><em class="calibre7">Listing 4-6: Output from file commands</em></p>
<p class="indent">Aside from using PowerShell and the built-in SMB connectivity of Windows, you can also view Azure Files through Microsoft Azure Storage Explorer (see <a href="part0013.html#ch04fig13" class="calibre6">Figure 4-13</a>).</p>
<div class="image1"><a id="ch04fig13" class="calibre6"/><img src="../images/00034.jpeg" alt="image" class="calibre3"/></div>
<p class="figcap"><em class="calibre7">Figure 4-13: Accessing Azure Files using Microsoft Azure Storage Explorer</em></p>
<p class="indent">Microsoft Azure Storage Explorer doesn’t provide any more functionality than PowerShell and the Windows SMB client in tandem, but it does get around the TCP 445 firewall issue by using Azure’s APIs for access instead of connecting directly through SMB. It also has a handy button <span epub:type="pagebreak" id="page_90"/>labeled <strong class="calibre4">Connect VM</strong> that will automatically create and display the properly formatted <span class="literal">net use</span> SMB command so you can connect to the share using Windows.</p>
<h3 class="h1" id="lev114"><strong class="calibre2">Summary</strong></h3>
<p class="noindent">In this chapter, we discussed some design limitations in the authentication design of Azure Storage as well as the different types of credentials an attacker can use to access Azure Storage: storage account keys, usernames and passwords, and Shared Access Signatures. Next, we examined places where attackers often find credentials, such as source code, configuration files, and stored within a number of storage management tools. Then, we discussed the different types of storage available in Azure, including blobs, tables, queues, and files, and how an attacker can access each of them. Using this information, you can retrieve all of the data from a target’s storage account, which often includes documents, log files, hard disk images, and source code.</p>
<p class="indent">In the next chapter, we’ll take a look at the biggest user of Azure Storage: Azure Virtual Machines.</p>
</body></html>