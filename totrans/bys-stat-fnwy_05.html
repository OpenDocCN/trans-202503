<html><head></head><body>
<h2 class="h2" id="ch04"><span epub:type="pagebreak" id="page_33"/><strong><span class="big">4</span><br/>CREATING A BINOMIAL PROBABILITY DISTRIBUTION</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">In <a href="ch03.xhtml#ch03">Chapter 3</a>, you learned some basic rules of probability corresponding to the common logical operators: AND, OR, and NOT. In this chapter we’re going to use these rules to build our first <em>probability distribution</em>, a way of describing all possible events and the probability of each one happening. Probability distributions are often visualized to make statistics more palatable to a wider audience. We’ll arrive at our probability distribution by defining a function that <em>generalizes</em> a particular group of probability problems, meaning we’ll create a distribution to calculate the probabilities for a whole range of situations, not just one particular case.</p>&#13;
<p class="indent">We generalize in this way by looking at the common elements of each problem and abstracting them out. Statisticians use this approach to make solving a wide range of problems much easier. This can be especially useful <span epub:type="pagebreak" id="page_34"/>when problems are very complex, or some of the necessary details may be unknown. In these cases, we can use well-understood probability distributions as estimates for real-world behavior that we don’t fully understand.</p>&#13;
<p class="indent">Probability distributions are also very useful for asking questions about ranges of possible values. For example, we might use a probability distribution to determine the probability that a customer makes between $30,000 and $45,000 a year, the probability of an adult being taller than 6’ 10’’, or the probability that between 25 percent and 35 percent of people who visit a web page will sign up for an account there. Many probability distributions involve very complex equations and can take some time to get used to. However, all the equations for probability distributions are derived from the basic rules of probability covered in the previous chapters.</p>&#13;
<h3 class="h3" id="ch04lev1sec1"><strong>Structure of a Binomial Distribution</strong></h3>&#13;
<p class="noindent">The distribution you’ll learn about here is the <em>binomial distribution</em>, used to calculate the probability of a certain number of successful outcomes, given a number of trials and the probability of the successful outcome. The “bi” in the term <em>binomial</em> refers to the two possible outcomes that we’re concerned with: an event happening and an event <em>not</em> happening. If there are more than two outcomes, the distribution is called <em>multinomial</em>. Example problems that follow a binomial distribution include the probability of:</p>&#13;
<ul>&#13;
<li class="noindent">Flipping two heads in three coin tosses</li>&#13;
<li class="noindent">Buying 1 million lottery tickets and winning at least once</li>&#13;
<li class="noindent">Rolling fewer than three 20s in 10 rolls of a 20-sided die</li>&#13;
</ul>&#13;
<p class="noindent">Each of these problems shares a similar structure. Indeed, all binomial distributions involve three <em>parameters</em>:</p>&#13;
<p class="hangt"><em><strong>k</strong></em> The number of outcomes we care about</p>&#13;
<p class="hang"><em><strong>n</strong></em> The total number of trials</p>&#13;
<p class="hangb"><em><strong>p</strong></em> The probability of the event happening</p>&#13;
<p class="indent">These parameters are the inputs to our distribution. So, for example, when we’re calculating the probability of flipping two heads in three coin tosses:</p>&#13;
<ul>&#13;
<li class="noindent"><em>k</em> = 2, the number of events we care about, in this case flipping a heads</li>&#13;
<li class="noindent"><em>n</em> = 3, the number times the coin is flipped</li>&#13;
<li class="noindent"><em>p</em> = 1/2, the probability of flipping a heads in a coin toss</li>&#13;
</ul>&#13;
<p class="indent">We can build out a binomial distribution to generalize this kind of problem, so we can easily solve any problem involving these three parameters. The shorthand notation to express this distribution looks like this:</p>&#13;
<p class="equ"><em>B</em>(<em>k</em>;<em>n</em>, <em>p</em>)</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_35"/>For the example of three coin tosses, we would write <em>B</em>(2; 3, 1/2). The <em>B</em> is short for <em>binomial</em> distribution. Notice that the <em>k</em> is separated from the other parameters by a semicolon. This is because when we are talking about a distribution of values, we usually care about all values of <em>k</em> for a fixed <em>n</em> and <em>p</em>. So <em>B</em>(<em>k</em>; <em>n</em>, <em>p</em>) denotes each value in our distribution, but the entire distribution is usually referred to by simply <em>B</em>(<em>n</em>, <em>p</em>).</p>&#13;
<p class="indent">Let’s take a look at this more closely and see how we can build a function that allows us to generalize all of these problems into the binomial distribution.</p>&#13;
<h3 class="h3" id="ch04lev1sec2"><strong>Understanding and Abstracting Out the Details of Our Problem</strong></h3>&#13;
<p class="noindent">One of the best ways to see how creating distributions can simplify your probabilities is to start with a concrete example and try to solve that, and then abstract out as many of the variables as you can. We’ll continue with the example of calculating the probability of flipping two heads in three coin tosses.</p>&#13;
<p class="indent">Since the number of possible outcomes is small, we can quickly figure out the results we care about with just pencil and paper. There are three possible outcomes with two heads in three tosses:</p>&#13;
<p class="equ">HHT, HTH, THH</p>&#13;
<p class="indent">Now it may be tempting to just solve this problem by enumerating all the other possible outcomes and dividing the number we care about by the total number of possible outcomes (in this case, 8). That would work fine for solving <em>just</em> this problem, but our aim here is to solve any problem that involves desiring a set of outcomes, from a number of trials, with a given probability that the event occurs. If we did not generalize and solved only this one instance of the problem, changing these parameters would mean we have to solve the new problem again. For example, just saying, “What is the probability of getting two heads in <em>four</em> coin tosses?” means we need to come up with yet another unique solution. Instead, we’ll use the rules of probability to reason about this problem.</p>&#13;
<p class="indent">To start generalizing, we’ll break this problem down into smaller pieces we can solve right now, and reduce those pieces into manageable equations. As we build up the equations, we’ll put them together to create a generalized function for the binomial distribution.</p>&#13;
<p class="indent">The first thing to note is that each outcome we care about will have the <em>same</em> probability. Each outcome is just a <em>permutation</em>, or reordering, of the others:</p>&#13;
<p class="equ"><em>P</em>({heads, heads, tails}) = <em>P</em>({heads, tails, heads}) = <em>P</em>({tails, heads, heads})</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_36"/>Since this is true, we’ll simply call it:</p>&#13;
<p class="equ"><em>P</em>(Desired Outcome)</p>&#13;
<p class="indent">There are three outcomes, but only one of them can possibly happen and we don’t care which. And because it’s only possible for one outcome to occur, we know that these are mutually exclusive, denoted as:</p>&#13;
<p class="equ"><em>P</em>({heads, heads, tails},{heads, tails, heads},{tails, heads, heads}) = 0</p>&#13;
<p class="indent">This makes using the sum rule of probability easy. Now we can summarize this nicely as:</p>&#13;
<p class="equ"><em>P</em>({heads, heads, tails} or {heads, tails, heads} or {tails, heads, heads}) = <em>P</em>(Desired Outcome) + <em>P</em>(Desired Outcome) + <em>P</em>(Desired Outcome)</p>&#13;
<p class="indent">Of course adding these three is just the same as:</p>&#13;
<p class="equ">3 × <em>P</em>(Desired Outcome)</p>&#13;
<p class="indent">We’ve got a condensed way of referencing the outcomes we care about, but the trouble as far as generalizing goes is that the value 3 is specific to this problem. We can fix this by simply replacing 3 with a variable called <em>N</em><sub>outcomes</sub>. This leaves us with a pretty nice generalization:</p>&#13;
<p class="equ"><em>B</em>(<em>k</em>;<em>n</em>, <em>p</em>) = <em>N</em><sub>outcomes</sub> × <em>P</em>(Desired Outcome)</p>&#13;
<p class="indent">Now we have to figure out two subproblems: how to count the number of outcomes we care about, and how to determine the probability for a single outcome. Once we have these fleshed out, we’ll be all set!</p>&#13;
<h3 class="h3" id="ch04lev1sec3"><strong>Counting Our Outcomes with the Binomial Coefficient</strong></h3>&#13;
<p class="noindent">First we need to figure out how many outcomes there are for a given <em>k</em> (the outcomes we care about) and <em>n</em> (the number of trials). For small numbers we can simply count. If we were looking at four heads in five coin tosses, we know there are five outcomes we care about:</p>&#13;
<p class="equ">HHHHT, HTHHH, HHTHH, HHHTH, HHHHT</p>&#13;
<p class="indent">But it doesn’t take much for this to become too difficult to do by hand—for example, “What is the probability of rolling two 6s in three rolls of a six-sided die?”</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_37"/>This is still a binomial problem, because the only two possible outcomes are getting a 6 or not getting a 6, but there are far more events that count as “not getting a 6.” If we start enumerating we quickly see this gets tedious, even for a small problem involving just three rolls of a die:</p>&#13;
<p class="equ">6 – 6 – 1<br/>6 – 6 – 2<br/>6 – 6 – 3<br/>. . .<br/>4 – 6 – 6<br/>. . .<br/>5 – 6 – 6<br/>. . .</p>&#13;
<p class="indent">Clearly, enumerating all of the possible solutions will not scale to even reasonably trivial problems. The solution is combinatorics.</p>&#13;
<h4 class="h4" id="ch04lev2sec1"><strong><em>Combinatorics: Advanced Counting with the Binomial Coefficient</em></strong></h4>&#13;
<p class="noindent">We can gain some insight into this problem if we take a look at a field of mathematics called <em>combinatorics</em>. This is simply the name for a kind of advanced counting.</p>&#13;
<p class="indent">There is a special operation in combinatorics, called the <em>binomial coefficient</em>, that represents counting the number of ways we can select <em>k</em> from <em>n</em>—that is, selecting the outcomes we care about from the total number of trials. The notation for the binomial coefficient looks like this:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0037-01.jpg"/></div>&#13;
<p class="indent">We read this expression as “<em>n</em> choose <em>k</em>.” So, for our example, we would represent “in three tosses choose two heads” as:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0037-02.jpg"/></div>&#13;
<p class="indent">The definition of this operation is:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0037-03.jpg"/></div>&#13;
<p class="indent">The ! means <em>factorial</em>, which is the product of all the numbers up to and including the number before the ! symbol, so 5! = (5 × 4 × 3 × 2 × 1).</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_38"/>Most mathematical programming languages indicate the binomial coefficient using the <span class="literal">choose()</span> function. For example, with the mathematical language R, we would compute the binomial coefficient for the case of flipping two heads in three tosses with the following call:</p>&#13;
<p class="programs">choose(3,2)<br/>&#13;
&gt;&gt;3</p>&#13;
<p class="indent">With this general operation for calculating the number of outcomes we care about, we can update our generalized formula like so:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0038-01.jpg"/></div>&#13;
<p class="indent">Recall that <em>P</em>(Desired Outcome) is the probability of any one of the combinations of getting two heads in three coin tosses. In the preceding equation, we use this value as a placeholder, but we don’t actually know how to calculate what this value is. The only missing piece of our puzzle is solving <em>P</em>(Single Outcome). After that, we’ll be able to easily generalize an entire class of problems!</p>&#13;
<h4 class="h4" id="ch04lev2sec2"><strong><em>Calculating the Probability of the Desired Outcome</em></strong></h4>&#13;
<p class="noindent">All we have left to figure out is the <em>P</em>(Desired Outcome), which is the probability of any of the possible events we care about. So far we’ve been using <em>P</em>(Desired Outcome) as a variable to help organize our solution to this problem, but now we need to figure out exactly how to calculate this value. Let’s look at the probability of getting two heads in five tosses. We’ll focus on a single case of an outcome that meets this condition: HHTTT.</p>&#13;
<p class="indent">We know the probability of flipping a heads in a single toss is 1/2, but to generalize the problem we’ll work with it as <em>P</em>(heads) so we won’t be stuck with a fixed value for our probability. Using the product rule and negation from the previous chapter, we can describe this problem as:</p>&#13;
<p class="equ"><em>P</em>(heads, heads, not heads, not heads, not heads)</p>&#13;
<p class="indent">Or, more verbosely, as: “The probability of flipping heads, heads, not heads, not heads, and not heads.”</p>&#13;
<p class="indent">Negation tells us that we can represent “not heads” as 1 – <em>P</em>(heads). Then we can use the product rule to solve the rest:</p>&#13;
<p class="equ"><em>P</em>(heads, heads, not heads, not heads, not heads) = <em>P</em>(heads) × <em>P</em>(heads) × (1 – <em>P</em>(heads)) × (1 – <em>P</em>(heads)) × (1 – <em>P</em>(heads))</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_39"/>Let’s simplify the multiplication by using exponents:</p>&#13;
<p class="equ"><em>P</em>(heads)<sup>2</sup> × (1 – <em>P</em>(heads))<sup>3</sup></p>&#13;
<p class="indent">If we put this all together, we see that:</p>&#13;
<p class="equ">(two heads in five tosses) = <em>P</em>(heads)<sup>2</sup> × (1 – <em>P</em>(heads))<sup>3</sup></p>&#13;
<p class="indent">You can see that the exponents for <em>P</em>(heads)<sup>2</sup> and 1 – <em>P</em>(heads)<sup>3</sup> are just the number of heads and the number of not heads in that scenario. These equate to <em>k</em>, the number of outcomes we care about, and <em>n</em> – <em>k</em>, the number of trials minus the outcomes we care about. We can put all of this together to create this much more general formula, which eliminates numbers specific to this case:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0039-01.jpg"/></div>&#13;
<p class="indent">Now let’s generalize it for any probability, not just heads, by replacing <em>P</em>(heads) with just <em>p</em>. This gives us a general solution for <em>k</em>, the number of outcomes we care about; <em>n</em>, the number of trials; and <em>p</em>, the probability of the individual outcome:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0039-02.jpg"/></div>&#13;
<p class="indent">Now that we have this equation, we can solve any problem related to outcomes of a coin toss. For example, we could calculate the probability of flipping exactly 12 heads in 24 coin tosses like so:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0039-03.jpg"/></div>&#13;
<p class="indent">Before you learned about the binomial distribution, solving this problem would have been much trickier!</p>&#13;
<p class="indent">This formula, which is the basis of the binomial distribution, is called a <em>Probability Mass Function (PMF)</em>. The <em>mass</em> part of the name comes from the fact that we can use it to calculate the amount of probability for <em>any</em> given <em>k</em> using a fixed <em>n</em> and <em>p</em>, so this is the mass of our probability.</p>&#13;
<p class="indent">For example, we can plug in all the possible values for <em>k</em> in 10 coin tosses into our PMF and visualize what the binomial distribution looks like for all possible values, as shown in <a href="ch04.xhtml#ch04fig01">Figure 4-1</a>.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_40"/><a id="ch04fig01"/><img alt="Image" src="../images/04fig01.jpg"/></div>&#13;
<p class="figcap"><em>Figure 4-1: Bar graph showing the probability of getting</em> k <em>in 10 coin flips</em></p>&#13;
<p class="indent">We can also look at the same distribution for the probability of getting a 6 when rolling a six-sided die 10 times, shown in <a href="ch04.xhtml#ch04fig02">Figure 4-2</a>.</p>&#13;
<div class="image"><a id="ch04fig02"/><img alt="Image" src="../images/04fig02.jpg"/></div>&#13;
<p class="figcap"><em>Figure 4-2: The probability of getting a 6 when rolling a six-sided die 10 times</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_41"/>As you can see, a probability distribution is a way of generalizing an entire class of problems. Now that we have our distribution, we have a powerful method to solve a wide range of problems. But always remember that we derived this distribution from our simple rules of probability. Let’s put it to the test.</p>&#13;
<h3 class="h3" id="ch04lev1sec4"><strong>Example: Gacha Games</strong></h3>&#13;
<p class="noindent"><em>Gacha games</em> are a genre of mobile games, particularly popular in Japan, in which players are able to purchase virtual cards with in-game currency. The catch is that all cards are given at random, so when players purchase cards they can’t choose which ones they receive. Since not all cards are equally desirable, players are encouraged to keep pulling cards from the stack until they hit the one they want, in a fashion similar to a slot machine. We’ll see how the binomial distribution can help us to decide to take a particular risk in an imaginary Gacha game.</p>&#13;
<p class="indent">Here’s the scenario. You have a new mobile game, <em>Bayesian Battlers</em>. The current set of cards you can pull from is called a <em>banner</em>. The banner contains some average cards and some featured cards that are more valuable. As you may suspect, all of the cards in <em>Bayesian Battlers</em> are famous probabilists and statisticians. The top cards in this banner are as follows, each with its respective probability of being pulled:</p>&#13;
<ul>&#13;
<li class="noindent">Thomas Bayes: 0.721%</li>&#13;
<li class="noindent">E. T. Jaynes: 0.720%</li>&#13;
<li class="noindent">Harold Jeffreys: 0.718%</li>&#13;
<li class="noindent">Andrew Gelman: 0.718%</li>&#13;
<li class="noindent">John Kruschke: 0.714%</li>&#13;
</ul>&#13;
<p class="indent">These featured cards account for only 0.03591 of the total probability. Since probability must sum to 1, the chance of pulling the less desirable cards is the other 0.96409. Additionally, we treat the pile of cards that we pull from as effectively infinite, meaning that pulling a specific card does not change the probability of getting any other card—the card you pull here does not then disappear from the pile. This is different than if you were to pull a physical card from a single deck of cards without shuffling the card back in.</p>&#13;
<p class="indent">You really want the E. T. Jaynes card to complete your elite Bayesian team. Unfortunately, you have to purchase the in-game currency, Bayes Bucks, in order to pull cards. It costs one Bayes Buck to pull one card, but there’s a special on right now allowing you to purchase 100 Bayes Bucks for only $10. That’s the maximum you are willing to spend on this game, and <em>only</em> if you have at least an even chance of pulling the card you want. This means you’ll buy the Bayes Bucks only if the probability of getting that awesome E. T. Jaynes card is greater than or equal to 0.5.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_42"/>Of course we can plug our probability of getting the E. T. Jaynes card into our formula for the binomial distribution to see what we get:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0042-01.jpg"/></div>&#13;
<p class="indent">Our result is less than 0.5, so we should give up. But wait—we forgot something very important! In the preceding formula we calculated only the probability of getting <em>exactly one</em> E. T. Jaynes card. But we might pull two E. T. Jaynes cards, or even three! So what we really want to know is the probability of getting one or more. We could write this out as:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0042-02.jpg"/></div>&#13;
<p class="indent">And so on, for the 100 cards you can pull with your Bayes Bucks, but this gets really tedious, so instead we use the special mathematical notation Σ (the capital Greek letter sigma):</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0042-03.jpg"/></div>&#13;
<p class="indent">The Σ is the summation symbol; the number at the bottom represents the value we start with and the number at the top represents the value we end with. So the preceding equation is simply adding up the values for the binomial distribution for every value of <em>k</em> from 1 to <em>n</em>, for a <em>p</em> of 0.00720.</p>&#13;
<p class="indent">We’ve made writing this problem down much easier, but now we actually need to compute this value. Rather than pulling out your calculator to solve this problem, now is a great time to start using R. In R, we can use the <span class="literal">pbinom()</span> function to automatically sum up all these values for <em>k</em> in our PMF. <a href="ch04.xhtml#ch04fig03">Figure 4-3</a> shows how we use <span class="literal">pbinom()</span> to solve our specific problem.</p>&#13;
<div class="image"><a id="ch04fig03"/><img alt="Image" src="../images/04fig03.jpg"/></div>&#13;
<p class="figcap"><em>Figure 4-3: Using the <span class="codeitalic">pbinom()</span> function to solve our</em> Bayesian Battlers <em>problem</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_43"/>The <span class="literal">pbinom()</span> function takes three required arguments and an optional fourth called <span class="literal">lower.tail</span> (which defaults to <span class="literal">TRUE</span>). When the fourth argument is <span class="literal">TRUE</span>, the first argument sums up all of the probabilities <em>less than or equal</em> to our argument. When <span class="literal">lower.tail</span> is set to <span class="literal">FALSE</span>, it sums up the probabilities <em>strictly greater than</em> the first argument. By setting the first argument to <span class="literal">0</span>, we are looking at the probability of getting one or more E. T. Jaynes cards. We set <span class="literal">lower.tail</span> to <span class="literal">FALSE</span> because that means we want values greater than the first argument (by default, we get values less than the first argument). The next value represents <em>n</em>, the number of trials, and the third argument represents <em>p</em>, the probability of success.</p>&#13;
<p class="indent">If we plug in our numbers here and set <span class="literal">lower.tail</span> to <span class="literal">FALSE</span> as shown in <a href="ch04.xhtml#ch04fig03">Figure 4-3</a>, R will calculate your probability of getting <em>at least one</em> E. T. Jaynes card for your 100 Bayes Bucks:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0043-01.jpg"/></div>&#13;
<p class="indent">Even though the probability of getting <em>exactly one</em> E. T. Jaynes card is only 0.352, the probability of getting <em>at least one</em> E. T. Jaynes card is high enough for you to risk it. So shell out that $10 and complete your set of elite Bayesians!</p>&#13;
<h3 class="h3" id="ch04lev1sec5"><strong>Wrapping Up</strong></h3>&#13;
<p class="noindent">In this chapter we saw that we can use our rules of probability (combined with a trick from combinatorics) to create a general rule that solves an entire class of problems. Any problem that involves wanting to determine the probability of <em>k</em> outcomes in <em>n</em> trials, where the probability of the outcomes is <em>p</em>, we can solve easily using the binomial distribution:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0043-02.jpg"/></div>&#13;
<p class="indent">Perhaps surprisingly, there is nothing more to this rule than counting and applying our rules of probability.</p>&#13;
<h3 class="h3" id="ch04lev1sec6"><strong>Exercises</strong></h3>&#13;
<p class="noindent">Try answering the following questions to make sure you’ve grasped binomial distributions fully. The solutions can be found at <em><a href="https://nostarch.com/learnbayes/">https://nostarch.com/learnbayes/</a></em>.</p>&#13;
<ol>&#13;
<li class="noindent">What are the parameters of the binomial distribution for the probability of rolling either a 1 or a 20 on a 20-sided die, if we roll the die 12 times?</li>&#13;
<li class="noindent">There are four aces in a deck of 52 cards. If you pull a card, return the card, then reshuffle and pull a card again, how many ways can you pull just one ace in five pulls?</li>&#13;
<li class="noindent"><span epub:type="pagebreak" id="page_44"/>For the example in question 2, what is the probability of pulling five aces in 10 pulls (remember the card is shuffled back in the deck when it is pulled)?</li>&#13;
<li class="noindent">When you’re searching for a new job, it’s always helpful to have more than one offer on the table so you can use it in negotiations. If you have a 1/5 probability of receiving a job offer when you interview, and you interview with seven companies in a month, what is the probability you’ll have at least two competing offers by the end of that month?</li>&#13;
<li class="noindent">You get a bunch of recruiter emails and find out you have 25 interviews lined up in the next month. Unfortunately, you know this will leave you exhausted, and the probability of getting an offer will drop to 1/10 if you’re tired. You really don’t want to go on this many interviews unless you are at least twice as likely to get at least two competing offers. Are you more likely to get at least two offers if you go for 25 interviews, or stick to just 7?</li>&#13;
</ol>&#13;
</body></html>