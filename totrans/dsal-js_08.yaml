- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: 6 SORTING
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/opener.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In previous chapters we discussed concepts related to programming and designing
    algorithms. Now we’ll start considering their actual application. The problem
    we’ll explore is how to sort a set of records into order, where each record consists
    of a key (alphabetical, numerical, or several fields) and data.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm’s output should include the exact same set of records, but shuffled
    so that the keys are in order. You usually want the keys in ascending order, but
    descending order requires only a minor change in sorting algorithms—namely, reversing
    comparisons—so you won’t see it here. (See question 6.1 at the end of the chapter.)
  prefs: []
  type: TYPE_NORMAL
- en: We’ll first consider general aspects of the sorting problem and then moves on
    to look at several algorithms based on comparisons of keys (the most common algorithms),
    followed by a few algorithms based on other principles. We’ll consider the performance
    of all algorithms and even toss in some humorous algorithms for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: '### The Sorting Problem'
  prefs: []
  type: TYPE_NORMAL
- en: 'A *sorting algorithm* is basically an algorithm that, given a list of records
    containing a key and some data, reorders the list so that the keys are in nondecreasing
    order (no key is smaller than its preceding key), and the output list is a permutation
    of the input list, retaining all original records. Forgetting the second condition
    is easy, but ignoring it would mean that the following would be a valid sorting
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Sorting is important in and of itself, but it also affects the efficiency of
    other algorithms. For instance, in [Chapter 9](chapter9.xhtml) we’ll see how working
    with sorted data allows for more efficient search procedures.
  prefs: []
  type: TYPE_NORMAL
- en: For our examples, we’ll usually assume single-field keys that you can directly
    compare using the < and > operators. For more generic cases, you could modify
    the algorithms to use the compare(a,b) comparison function, as JavaScript’s sorting
    algorithm does (see the section “JavaScript’s Own Sort Method” on page 95). In
    the code examples in this book, you’ll always write tests as a>b, so modifying
    the code for generic sorting requires only changing that comparison to compare(a,b)>0.
    (See question 6.2 for a variation.) In [Chapter 14](chapter14.xhtml), you’ll actually
    use this kind of solution by applying a goesHigher(a,b) function to decide which
    of a or b should be higher in a heap.
  prefs: []
  type: TYPE_NORMAL
- en: Internal vs. External Sorting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An important consideration when sorting data is whether it can all be stored
    in memory at the same time, or whether it’s so large that it must reside in a
    storage device. The first case is called *internal sorting*, and the second is
    called *external sorting*. All the algorithms in this chapter fall into the first
    category, but what if you need to sort more data than can fit in memory?
  prefs: []
  type: TYPE_NORMAL
- en: External sorting breaks up all the input into runs that are as large as possible
    to fit in memory, then uses internal sorting to sort the runs, saves them to external
    storage, and merges the sorted runs into the final output. That said, it’s highly
    likely that for large sorting tasks like this, you’ll be better off using a standard
    system sort utility, which also might be optimized to use parallel threads, multiple
    central processing units (CPUs), and so on. In any case, should you decide to
    roll out your own external sort procedure, the algorithms in this section cover
    the needed internal sorting, and using a heap (as in [Chapter 14](chapter14.xhtml))
    would help with writing efficient merge code.
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive Sorting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A sorting algorithm is called *adaptive* if it somehow takes advantage of whatever
    existing order already exists in its input. Shell sort, which you’ll learn about
    in the section “Making Bigger Jumps with Comb and Shell Sort” on page 103, is
    such a case: the algorithm performs better when data is partially sorted. On the
    other hand, quicksort, which you’ll learn about in the section “Going for Speed
    with Quicksort” on page 105, could be considered anti-adaptive. Its worst performance
    happens when data is already in order (though there are ways around this).'
  prefs: []
  type: TYPE_NORMAL
- en: In-Place and Out-of-Place Sorting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another consideration for sorting algorithms is whether they require extra data
    structures (and thus extra space). This requirement is often relaxed to allow
    for constant, less than *O*(*n*) extra memory—the key rule is whether extra space
    proportional to the input size is needed. We don’t take into account the *O*(*n*)
    space needed to store the *n* elements to be sorted. Algorithms that don’t require
    such extra space are called *in-place*, and those that do require more memory
    are known as *out-of-place* or *not-in-place* algorithms. This doesn’t mean that
    out-of-place algorithms return a new list; they may perfectly well reorder the
    input list in place, but they require *O*(*n*), or more, extra space to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider carefully how much memory an algorithm uses: some recursive algorithms
    like quicksort require internally using a stack that is *O*(*log n*) but that
    is also allowed to count as in-place. Merge sort usually requires extra space
    to merge sequences, so it has *O*(*n*) needs and thus falls into the out-of-place
    category.'
  prefs: []
  type: TYPE_NORMAL
- en: Online and Offline Sorting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another distinction to make when considering algorithms is whether they can
    process the input data in a serial stream-like fashion or whether all the data
    needs to be available from the beginning. Algorithms in the first category are
    called *online algorithms*, and those in the second are *offline algorithms*.
    This distinction applies not only to sorting but to other problems as well; for
    example, you’ll see it again when discussing sampling in [Chapter 8](chapter8.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: In terms of sorting, an online algorithm will always have a sorted list, adding
    new elements to it as they come in, while an offline algorithm will have to wait
    until all elements are available. Offline algorithms usually have better performance,
    though. Online algorithms don’t know the whole input, so they have to make decisions
    that may turn out later to be suboptimal, which is the same kind of situation
    as with greedy algorithms (see [Chapter 5](chapter5.xhtml)).
  prefs: []
  type: TYPE_NORMAL
- en: As an example of this distinction, consider how you could sort a set of playing
    cards. If you keep the cards you’ve sorted so far in your hand and then every
    time you get a new card you insert it into place among the previous ones, you
    are implementing an online algorithm—in fact, it’s an *insertion sort*, which
    we’ll study in the section “Sorting Strategies for Playing Cards” on page 100.
    If you wait until you have all the cards and then sort them somehow, that’s an
    offline sort.
  prefs: []
  type: TYPE_NORMAL
- en: Sorting Stability
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Sorting data with possibly equal keys raises a question: In what relative order
    do the elements with equal keys end up? A *stable sorting* algorithm maintains
    the same order as the input, so if one element preceded another and both had the
    same key, in the ordered output, the first one will precede the second.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Why does stability matter? Imagine you want to have a drop-down element in
    an HTML page that shows your contacts but with this rule: starred contacts (favorites)
    should appear first, in alphabetical order, followed by nonstarred contacts, also
    in alphabetical order.'
  prefs: []
  type: TYPE_NORMAL
- en: To achieve the required ordering, you could first order the whole list by name
    and then reorder it so starred contacts are first. [Figure 6-1](chapter6.xhtml#fig6-1)
    illustrates this method.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-1: Sorting by two fields with a stable sorting algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: The first sort reorders the list by name, alphabetically, and the second sort
    places starred names before the ones without stars. If the second sort is stable,
    this ordering won’t affect the previous alphabetical sorting. With an unstable
    sort, that might not be true. Stability is the reason Joliet precedes Romeo in
    the final list. Joliet preceded Romeo when sorting by name, and when sorting by
    star, they keep the same relative order.
  prefs: []
  type: TYPE_NORMAL
- en: You can modify any sorting algorithm to force it to be stable. No matter what
    the key for ordering is, consider a new extended key formed by the original key
    followed by the item’s position in the list. Ordering this array by the new extended
    key, items that shared the same (original) key value will be sorted together,
    but because of the added position, they will keep the same original relative order,
    as shown in [Figure 6-2](chapter6.xhtml#fig6-2).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-2: Sorting made stable by using an extended key'
  prefs: []
  type: TYPE_NORMAL
- en: The first step adds the item’s position as an extra key; the second step sorts
    by name and position. Elements that had the same original key (Alpha and Echo
    in the example) are kept in their original relative positions to each other. You
    would finish by dropping the added field.
  prefs: []
  type: TYPE_NORMAL
- en: '#### JavaScript’s Own Sort Method'
  prefs: []
  type: TYPE_NORMAL
- en: When sorting data in JavaScript, don’t forget that the language already provides
    a .sort(...) method, and despite considering more (and possibly better) sorting
    algorithms later in this chapter, in many cases using JavaScript’s own sort might
    be most effective. Let’s quickly review how this sort works (see *[https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/sort](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/sort)*
    for more information).
  prefs: []
  type: TYPE_NORMAL
- en: 'Given an array, the .sort(comparisonFunction) method reorders the array in
    place using an optional comparison function. (The newer .toSorted() method doesn’t
    sort in place, but rather produces a new, sorted version of the array.) If that
    function is omitted, JavaScript converts elements to strings and then sorts lexicographically,
    which may not be what you wanted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To accommodate other ways of sorting, you need to provide a function that will
    receive two elements, a and b, and return a negative value if a should precede
    b, a positive value if a should follow b, and zero if both keys are equal and
    if a and b could be in any order. You can fix the previous example quite easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also implement more complex comparisons; the following example shows
    how you would sort objects by date and name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The data to sort ❶ has dates as three separate fields (d, m, and y, for day,
    month, and year) and name (n). If two persons are from different years ❷, you
    return the correct negative or positive value by subtracting years. If the years
    are equal, you can compare months with the same kind of logic ❸, and if the months
    are also equal ❹, you do the same once more for days. If the dates are equal,
    you resort to comparing names ❺, and since you cannot use math and just subtract
    dates, you need to make actual comparisons, date part by date part. The final
    return 0 is done ❻ only if all fields were compared and found to match.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you sort the people array with the dateNameCompare(...) function you just
    wrote, you get the expected result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Finally, consider stability. Originally, the specification for the .sort(...)
    method didn’t require it, but ECMAScript 2019 added the requirement. Be aware,
    however, that if using an earlier JavaScript engine, you cannot assume stability,
    so you might have to resort to the solution described in “Sorting Stability” on
    [page 93](chapter6.xhtml#pg_93). Also, keep in mind that any given engine may
    just not correctly implement the standard.
  prefs: []
  type: TYPE_NORMAL
- en: Sort Performance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you have to sort *n* values, your logic has to be able to deal with all possible
    *n*! permutations of those values. How many comparisons will be needed for that?
    Think of the game of 20 questions. In that game, you have to guess a selected
    object by asking, at most, 20 yes or no questions. If you plan your questions
    carefully, you should be able to pick any element out of more than a million (2^(20)
    = 1,048,576, actually) possible options. You can apply that logic to sorting *n*
    elements.
  prefs: []
  type: TYPE_NORMAL
- en: If you are comparing elements to sort an array, it’s indirectly implied that
    you’re deciding which was the original permutation. Well-placed questions divide
    the range of options in half, so you need to know how many questions are needed
    for *n*! possibilities. This is equivalent to asking how many times you should
    divide *n*! by 2 until you get down to 1\. The answer is log *n!*, in base 2\.
    (Alternatively, you can see it as asking what value of *k* is such that 2*^k*
    > *n*!) This section won’t go into its derivation, but Stirling’s approximation
    says that *n*! grows as *n**^n*, so the logarithm of *n*! is *O*(*n* log *n*).
  prefs: []
  type: TYPE_NORMAL
- en: This automatically implies that any algorithm based on comparing elements will
    be *O*(*n* log *n*) at the very least. No better results are achievable, but worse
    results are obviously possible. With that in mind, in the next section we’ll consider
    several algorithms, from worst to best performance.
  prefs: []
  type: TYPE_NORMAL
- en: Note, however, the observation about these algorithms being “based on comparing
    elements.” If you manage to sort a list without making actual comparisons, all
    bets are off. You’ll see that some methods allow sorting in *O*(*n*) time, without
    ever comparing keys to each other.
  prefs: []
  type: TYPE_NORMAL
- en: Sorting with Comparisons
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned previously, we’ll consider the major sorting algorithms, all of
    which depend on comparing values to each other. The first algorithms we’ll consider
    are *O*(*n*²), so they’re not optimum, but we’ll move on to better ones until
    we reach several that achieve the best *O*(*n* log *n*) performance.
  prefs: []
  type: TYPE_NORMAL
- en: In all cases you’ll write functions that receive an array of values (as stated
    earlier, you don’t have to worry about key + data pairs, as that can easily be
    accommodated), and you’ll also pass parameters to specify which part of the array
    (from, to) should be sorted. As usual, you’ll want to sort the whole array. Those
    parameters will have default values, so the whole array will be sorted if they’re
    not present.
  prefs: []
  type: TYPE_NORMAL
- en: Bubbling Up and Down
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We’ll start our review of sorting algorithms with *bubble sort*, which probably
    has the catchiest name, possibly to compensate for its subpar performance. This
    algorithm is easy to implement, but you’d use it only for smaller sets of data.
    It also has generated several variations (you’ll look at comb sort in the next
    section, which actually leads to a better-performing algorithm).
  prefs: []
  type: TYPE_NORMAL
- en: Bubble Sort
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The bubble sort algorithm derives its name from the simple idea that larger
    numbers represent bubbles that bubble up to the top of the list. It starts at
    the beginning of the array and goes in order through all elements in the array,
    and if an element is greater than the following element, it swaps them (see [Figure
    6-3](chapter6.xhtml#fig6-3)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-3: With bubble sort, each pass moves another element to its place.'
  prefs: []
  type: TYPE_NORMAL
- en: The first pass at the top of [Figure 6-3](chapter6.xhtml#fig6-3) goes from left
    to right, comparing adjacent values and swapping if needed so that the higher
    value is always to the right. After the first pass, 60 goes to the top of the
    array. You proceed in the same way with the rest of the array, and after the second
    pass, 56 goes to the next-to-last position, so you have at least two elements
    in the right place. After the third pass, three elements will be in place, and
    so on. The last two rows required no swapping, because previous passes had already
    moved the elements to the correct places, which frequently happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the logic for this algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'All sorting functions share the same signature: an array to sort (arr) and
    the limits for sorting (from, to) that, by default, will be the array’s extremes
    ❶. The outer loop ❷ goes from the right to the left; after each pass, the element
    in position j of the array will be in the right place. The inner loop ❸ goes from
    the left extreme to the right up to (but not reaching) the outer loop j; you compare
    each element with the next ❹, and if the second is smaller, you swap them.'
  prefs: []
  type: TYPE_NORMAL
- en: You can improve performance in most sorted arrays (a not uncommon case) by checking
    whether any swaps occurred on each pass through the array. If none were detected,
    it means the array is in order (see question 6.7).
  prefs: []
  type: TYPE_NORMAL
- en: 'The performance of this algorithm is *O*(*n*²), which is easy to calculate.
    First count comparisons: the first pass does (*n* – 1) comparisons, the second
    pass does (*n* – 2), the third (*n* – 3), and so on. The total number of comparisons
    is then the sum of all numbers from (*n* – 1) down to 1, which is *n*(*n* – 1)
    / 2, so *O*(*n*²).  ##### Sinking Sort and Shuttle Sort'
  prefs: []
  type: TYPE_NORMAL
- en: Bubble sort quickly moves the greatest values to the end of an array, but the
    smallest values may take a while to reach their final positions. Similarly, *sinking
    sort* (see question 6.6) makes the lowest values quickly sink to the beginning
    of the array, but correspondingly, it takes longer for the greatest values to
    go to their places. You can alternate a pass of bubbling with a pass of sinking
    to get an enhanced algorithm, called *shuttle sort* (also known as *cocktail shaker
    sort* or *bidirectional* bubble sort). In comparison with bubble sort, the first
    passes of the shuttle sort proceed as shown in [Figure 6-4](chapter6.xhtml#fig6-4).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-4: Shuttle sort alternates left-to-right and right-to-left passes.'
  prefs: []
  type: TYPE_NORMAL
- en: Starting with the same elements, the first pass is the same as bubble sort’s,
    moving 60, which is the greatest value in the array, to the rightmost position.
    The second pass goes right to left and moves 04, the smallest value in the array,
    to the leftmost position. The third pass again goes left to right and moves 56
    to its place; after that, it goes right to left, then left to right, and so on,
    alternating direction every time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the corresponding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As mentioned earlier, the signature for this sort function is always the same:
    an array to sort and the portion to put in order ❶. You have two variables ❷ that
    mark how far to the left and right the array is already sorted: f (as in *from*)
    starts at the left and grows by 1 after each right-to-left pass, and t (as in
    *to*) starts at the right and decreases by 1 after each left-to-right pass. When
    these variables meet ❸, the sort is done. You perform a left-to-right pass as
    shown earlier ❹, and then you decrement t ❺, since you’ve placed a new value in
    the right place. After this pass, you do the same ❻, but right to left, and you
    increment f ❼ to finish.'
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm is still *O*(*n*²), but the actual implementation typically is
    double the speed or even better if you include testing for swaps (see question
    6.7). In any case, it’s easy to show that it can’t do any worse, for in each pass,
    it places one number at its final position, so after having placed (*n* – 1) numbers
    at their place, it will be done, the same as bubble sort.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, despite the catchy name, this sort algorithm is not good enough
    in comparison with those that we’ll explore later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Sorting Strategies for Playing Cards
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Thinking about how you do simple tasks can provide tips for developing an algorithm.
    For example, suppose you have a few playing cards in your hand and want to order
    them from lowest to highest. You could apply a couple of different strategies,
    which we’ll look at next: selection sort or insertion sort.'
  prefs: []
  type: TYPE_NORMAL
- en: Selection Sort
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'A simple solution is to look for the lowest card and place it farthest to the
    left in your hand. Then look for the next lowest card and place it after the first,
    and keep doing that, always selecting the lowest remaining card and placing it
    next to the already sorted cards. This process is the basis for the *selection
    sort* algorithm, which adds a small detail: when placing a card to the left, you
    do a swap with the other card (see [Figure 6-5](chapter6.xhtml#fig6-5)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-5: Selection sort looks for the smallest element and swaps it to get
    it into place.'
  prefs: []
  type: TYPE_NORMAL
- en: In the first pass at the top, you find that the minimum number is 04, and you
    do a swap to move it to the first place in the array. The second pass finds 09
    and swaps it with 12, so you now have two numbers in order. The process continues
    the same way; an exception is in the next-to-last line, in which no swap is needed
    because 56 was already in the correct place.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Go in order ❶ from the first place in the array to the last. The m variable
    ❷ keeps track of the position of the minimum value already found. As you loop
    through the yet unsorted numbers ❸, if you find a new minimum candidate ❹, you
    update m. After finishing this loop, if the minimum isn’t already in place ❺,
    do a swap.
  prefs: []
  type: TYPE_NORMAL
- en: The order of this algorithm is, again, *O*(*n*²). You have to look at *n* elements
    to find what should go in the first place; then look at *n* – 1 for the second
    place, *n* – 2 for the third, and so on. You already know this sum is *O*(*n*²).
    The algorithm in the next section is also based on how you’d sort playing cards,
    but it has slightly better performance.
  prefs: []
  type: TYPE_NORMAL
- en: Insertion Sort
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: With selection sort, we thought about sorting playing cards, but you could have
    considered another method. Take the first card; that’s clearly already in order
    by itself. Now look at the second card, and either place it before the first (if
    it’s lower) or leave it where it is (if it’s higher). You now have two cards in
    order. Look at the third card, decide where it should go among the previous two,
    and place it there. As you go through all the cards in your hand, you’ll end up
    putting them in order, and this is called an *insertion sort*, because of the
    way you insert new cards among the previously sorted ones (see [Figure 6-6](chapter6.xhtml#fig6-6)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-6: Sorting by insertion works the way one sorts playing cards.'
  prefs: []
  type: TYPE_NORMAL
- en: Start with a single card in order, in this case, number 34\. Then consider the
    next value, 12, and place it to the left of 34, so the two numbers are in order.
    Then consider 22, which goes between 12 and 34, and now three values are ordered.
    Continue working this way, always inserting the next number where it belongs among
    the previously sorted ones, until you reach the last line. After placing 14 among
    the already sorted numbers, the whole array becomes ordered.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code implements this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Set up a loop that starts at the second place in the array and goes to the end
    ❶, and loop back as long as the list isn’t in order ❷, swapping to get new numbers
    in place ❸.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at this carefully, you’ll notice it’s doing too many swaps to get the
    new element to its place.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can quickly optimize the code to avoid that and do just one swap per loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The first loop ❶ is exactly the same as earlier, but the difference lies within.
    You set the number to be inserted among the previously sorted aside ❷, and you
    loop to find where it should go ❸, pushing values that are greater to the right.
    At the end ❹, you place the new value in its final position.
  prefs: []
  type: TYPE_NORMAL
- en: Insertion sort is a simple algorithm, which makes it a good choice for smaller
    arrays. Later in the chapter we’ll look at how it’s sometimes used in hybrid sorting
    algorithms as a replacement for theoretically more convenient, but practically
    slower, alternative methods.
  prefs: []
  type: TYPE_NORMAL
- en: Making Bigger Jumps with Comb and Shell Sort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Bubble sort and its variants are not the best-performing sorting algorithms.
    However, the idea of swapping elements to make them bubble up or sink down isn’t
    bad, and applying the idea of making larger jumps (for example, swapping elements
    that are farther apart) eventually leads to a better algorithm, *Shell sort*.
    You’ll explore this idea with a bubble sort variant called *comb sort* first.
  prefs: []
  type: TYPE_NORMAL
- en: Comb Sort
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s go back to bubble sort and consider how keys move in an array like rabbits
    and turtles. Rabbits represent the large values near the beginning of the list,
    which quickly move to their places at the end of the array, swap after swap. On
    the other hand, turtles represent the small values near the end of the list, which
    slowly move to their places in a single swap per pass. You want both turtles and
    rabbits to move quickly to their respective sides of the array.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is to perform some passes with swaps, but instead of comparing one
    element with the next one, you’ll consider larger gaps. Thus, rabbits will jump
    further distances toward the right, but turtles will correspondingly jump further
    distances toward the left. You’ll do passes with successively smaller gaps, and
    when the gap becomes 1, you’ll apply the common bubble sort to finish.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logic is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It has been determined empirically that the first gap should equal the array’s
    length divided by 1.3, the “shrink factor” ❶, and successive gaps will always
    be 1.3 times smaller ❷. When the gap becomes 1 ❸, just apply bubble sort, and
    you’re done. While the gap is greater than 1 ❹, you do what’s essentially the
    central logic of bubble sort, but instead of comparing elements one place apart,
    you compare elements gap places apart.
  prefs: []
  type: TYPE_NORMAL
- en: Comb sort usually performs better than bubble sort, but it’s still *O*(*n*²)
    in the worst case and becomes *O*(*n* log *n*) in the best case. However, that’s
    not why we’re considering this idea; rather, the concept of sorting elements that
    are far apart provides real benefits, and you’ll see that Shell sort that does
    exactly that in a way similar to comb sort.
  prefs: []
  type: TYPE_NORMAL
- en: Shell Sort
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To understand how Shell sort works, assume you want to order the array shown
    in [Figure 6-7](chapter6.xhtml#fig6-7).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-7: Shell sort works similarly to insertion sort, but with larger gaps.'
  prefs: []
  type: TYPE_NORMAL
- en: In the first pass, do an insertion sort, but for elements set four places apart,
    which leads to an array consisting of four short-ordered sequences. Then lower
    the gap size to 2 and repeat the sort. The array now consists of two ordered sequences.
    Eventually, you reach a gap size of 1, and in that case, you’re just doing an
    insertion sort, but because of the previous partial sorts, it doesn’t do as many
    comparisons or swaps as with the normal algorithm, which is the advantage of Shell
    sort.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the Shell sort implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: First select what gaps to use ❶, keeping in mind that the last one to be applied
    must be 1\. You’ll find many suggestions online as to which sequence to use, but
    this example will use Knuth’s proposal (1, 4, 13, 40, 121, . . . , with each term
    being triple the previous one, plus 1), which leads to an *O*(*n*^(1.5)) algorithm.
    Then, you take gaps in decreasing order ❷ and essentially do an insertion sort
    ❸ but for elements gap spaces apart ❹. With larger gaps, you’re ordering sequences
    of fewer elements, but as you decrease the gap size, you deal with longer sequences
    that tend to be almost in order, so insertion sort behaves well.
  prefs: []
  type: TYPE_NORMAL
- en: Going for Speed with Quicksort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s move on to the quicker algorithms that achieve the *O*(*n* log *n*) theoretical
    speed limit—albeit with a problematic worst-case quadratic performance! *Quicksort*
    (also known as *partition-exchange sort*) was created by Tony Hoare in the 1960s
    and is a divide-and-conquer algorithm with high speed. We’ll consider the standard
    version first and then discuss some possible enhancements.
  prefs: []
  type: TYPE_NORMAL
- en: Standard Version
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: How does quicksort work? The idea is first to select a “pivot” element from
    the array to be sorted and redistribute all the other elements in two subarrays,
    according to whether they are smaller or larger than the pivot. The array ends
    with lower values first, then the pivot, and then higher values. Then, each subarray
    is sorted recursively, and when that’s done, the whole array is sorted (see [Figure
    6-8](chapter6.xhtml#fig6-8)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-8: Quicksort works by partitioning arrays and recursively sorting
    the parts.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say we always choose the rightmost element of the array as the pivot.
    (It won’t prove to be a very wise option, as you’ll see.) In this case, the first
    choice is 14, and you rearrange the array so all values less than 14 come first,
    then 14 itself, and finally all values greater than 14\. The same procedure (select
    the pivot, rearrange, and sort recursively) is applied to each subarray until
    the whole array is sorted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a direct implementation of the procedure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: First, check whether there’s actually anything to sort; if the left pointer
    is equal to or greater than the right one, you’re done ❶. The rightmost element
    will be the pivot ❷. Next, go through the array from left to right ❸ in a fashion
    reminiscent of the insertion sort, exchanging elements if needed so smaller elements
    move to the left, greater ones to the right, and the pivot ends at position p
    ❹. It would be a good idea to simulate a run of the pivoting code by hand. Despite
    its short length, it’s a bit tricky to get right. (What happens if the pivot value
    appears several times in the array? See question 6.10.) Finally, apply recursion
    to sort the two partitions ❺.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis shows that *on average*, quicksort works in *O*(*n* log *n*) time.
    However, the worst case is easy to find. Consider sorting an already sorted (in
    ascending or descending order) array. Examining the code shows that partitioning
    will always end with just one subarray, and you’ll have the equivalent of a selection
    sort or bubble sort, which means performance goes down to *O*(*n*²). But you can
    fix that.
  prefs: []
  type: TYPE_NORMAL
- en: Pivot Selection Techniques
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: How you choose the pivot can have a serious impact on quicksort’s performance.
    In particular, if you always choose the largest (or smallest) element in the array,
    you’ll get a negative hit in speed, so consider some alternative pivot-selecting
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first solution to avoid problems with sorted arrays is to choose the pivot
    randomly. Select a random position between left and right inclusive and, if needed,
    swap the selected element to move it to the rightmost position, so you can go
    on with the rest of the algorithm without any further changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We’ll look at random selection in more detail in [Chapter 8](chapter8.xhtml),
    but the way you calculate iPivot (the position of the pivot) ❶ selects a value
    from left to right inclusive with equal odds. The rest of the sorting algorithm
    assumes that the chosen pivot was at the right of the array, so if the chosen
    pivot is elsewhere ❷, just do a swap.
  prefs: []
  type: TYPE_NORMAL
- en: This random selection solves the worst-case behavior for almost-sorted arrays,
    but there’s still the (assuredly low) probability that you’ll always just happen
    to pick the highest or lowest value in the array to be sorted, and in that case,
    performance will suffer.
  prefs: []
  type: TYPE_NORMAL
- en: 'What’s the ideal pivot? Choosing the array’s median (the value that splits
    the array in two) would be optimum. A rule that comes close is called the *median
    of three*: choose the median of the left, middle, and right elements of the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Testing this code with all possible permutations of three values shows that
    arr[right] always ends with the middle value. Even better, you might pick the
    “ninther,” defined as a “median of medians”: divide the array in three parts,
    apply the median of three to each third, and then take the median of those three
    values.'
  prefs: []
  type: TYPE_NORMAL
- en: You can help quicksort become faster by selecting pivots carefully, but you
    can enhance it even further.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid Version
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Quicksort is fast, but all the pivots and recursion have an impact on running
    times, so for small arrays, a combination of simpler algorithms may actually perform
    faster. You can apply a *hybrid algorithm* that uses two distinct methods together.
    For instance, you may find that for arrays under a certain cutoff limit, an insertion
    sort performs better, so whenever you want to sort an array smaller than the limit,
    switch to that algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The lines in bold are all you need to change. Define the cutoff limit, and when
    sorting, if the array is small enough, apply the alternative sort.
  prefs: []
  type: TYPE_NORMAL
- en: Dual-Pivot Version
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You can extend the idea of splitting an array to be sorted in two parts, separated
    by a pivot, to splitting the array in three parts, separated by two pivots. This
    dual-pivot version is usually faster. (Java uses it as its default sorting algorithm
    for primitive types.) Choose the leftmost and rightmost elements as pivots, as
    shown in [Figure 6-9](chapter6.xhtml#fig6-9).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-9: Dual-pivot sort is like quicksort, but it splits the array in three
    parts instead of two.'
  prefs: []
  type: TYPE_NORMAL
- en: Start by choosing 34 and 14 as pivots, and rearrange the array so that all values
    less than 14 (12, 9, 4) come first, then 14 itself, then values between 14 and
    34 (just 22), then 34, and finally values greater than 34 (60, 56). Each subarray
    is then sorted again with the same method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm is similar to a basic quicksort; the main differences are in
    the selection of pivots and partitioning. For performance reasons, you’ll use
    the hybrid approach and turn to an insertion sort if the array to be sorted is
    small enough; for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'You’re choosing the leftmost and rightmost elements as pivots, but, of course,
    you could take any two values and swap them so they end up in the extremes of
    the array, with the smaller on the left ❶. (Actually, when dealing with arrays
    nearly in order, choosing two middle elements is better.) Next, you start swapping
    elements, maintaining these invariants:'
  prefs: []
  type: TYPE_NORMAL
- en: pivotLeft is at the left of the array.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From positions left + 1 to ll - 1, all values are less than pivotLeft.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From positions ll to mm - 1, all values are strictly between pivotLeft and pivotRight.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From positions mm to rr, the status of values is yet unknown.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From positions rr + 1 to right - 1, the values are greater than pivotRight.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pivotRight is at the right of the array.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can establish this invariant from the beginning by setting mm to left +
    1 and making it go up until it reaches the end of the array ❷. If the element
    at mm is less than pivotLeft ❸, a mere swap maintains the invariant. If the element
    at mm is greater than pivotRight ❹, you have to do a bit more work to maintain
    the invariant, moving rr to the left. (Remember, the idea is to keep the invariants;
    this loop ensures the next-to-last one.) After the loop is done ❺, swap the pivots
    to their final places and apply recursion to sort the three partitions ❻.
  prefs: []
  type: TYPE_NORMAL
- en: Quicksort is a great algorithm with several variants, but it always comes with
    the possibility (albeit remote) of bad performance.
  prefs: []
  type: TYPE_NORMAL
- en: Merging for Performance with Merge Sort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We’ll wrap up our study of comparison-based sorts with the *merge sort* algorithm
    that guarantees a constant performance, but with the cost of a higher need for
    memory. Merge sort basically does all sorting by merging. If you have two ordered
    sequences of values, *n* in total, merging them into a single-order sequence can
    be done in an *O*(*n*) process. The key idea of a merge sort is to apply recursion.
    First, split the array to be sorted into two halves, then recursively sort each
    half, and finally merge both ordered halves into a single sequence (see [Figure
    6-10](chapter6.xhtml#fig6-10)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-10: Merge sort splits the array into two parts, sorts them, and ends
    by merging them.'
  prefs: []
  type: TYPE_NORMAL
- en: Each array to be sorted is split into two parts, which are sorted and then joined
    back together. To sort an 8-element array, you need to sort two 4-element arrays,
    which means you have to sort four 2-element arrays, and that requires sorting
    eight 1-element arrays. Sorting the latter is trivial (nothing to do), and doing
    the merge reconstructs the original array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a recursive implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'First, check whether you even need to sort ❶, which could include a hybrid
    approach, and if the array is small enough, you’d apply some other method, not
    merge sort. Then split the array in half ❷ and recursively sort each half ❸. Next,
    merge both sorted arrays ❹: ll and rr will traverse each array, and the output
    will go into the original array. Finally, return the sorted array.'
  prefs: []
  type: TYPE_NORMAL
- en: Merge sort has very good performance (despite the extra space needed to perform
    the merge), and it’s actually the basis of *Tim sort*, a stable adaptive method
    that’s widely used. Java utilizes it, JavaScript also applies it in the V8 engine,
    and other languages use it as well. We won’t delve into the actual implementation,
    as the algorithm is quite longer than the ones we’ve been considering (a couple
    of implementations in GitHub run to almost 1,000 lines each). Tim sort takes advantage
    of runs of elements that are already in order, merging shorter runs to create
    longer ones, and applying an insertion sort to make sure runs are long enough.
    You’ve already studied all the pieces that make up the complete Tim sort algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*There’s more to learn about comparison-based sorting methods, but we’ll postpone
    considering more algorithms until we’ve seen some data structures. In [Chapter
    14](chapter14.xhtml) we’ll explore priority queues and heaps. Likewise, in [Chapter
    12](chapter12.xhtml) we’ll study binary trees and, in particular, binary search
    trees. By adding all elements to be sorted into such a structure, you can traverse
    it in order later, thus producing another sort, although the performance and relative
    complexity of that solution don’t make it very attractive. Binary search trees
    are more oriented toward searching; sorting is just a* *by-product. In the same
    way, other structures such as skip lists (which we’ll analyze in [Chapter 11](chapter11.xhtml))
    could also provide a sorting method, but as with binary search trees, sorting
    isn’t the intended goal.*'
  prefs: []
  type: TYPE_NORMAL
- en: Sorting Without Comparisons
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous section, all of the sorting algorithms depended on comparing
    keys and using that information to move, swap, or partition values. But there
    are other ways to sort. As an example, imagine you’re in charge of customer assistance
    and receive email for many different reasons. How can you simplify the classification
    task? You could use a different email address for each category so that messages
    are automatically sorted into the correct bins for processing.
  prefs: []
  type: TYPE_NORMAL
- en: This simple solution provides a glimmer of what we’re going to do. Basically,
    you won’t compare keys; instead, you’ll use their values to figure out where they
    should go in the final, ordered list. It’s not always possible, but if you can
    apply the methods here, performance becomes *O*(*n*), which is impossible to beat.
    After all, no algorithm can sort *n* values without at least looking at them once,
    and that’s already an *O*(*n*) process. In this section, we’ll consider a couple
    of methods, *bitmap sort* and *counting sort*, and we’ll also look at a very old
    sorting method, *radix sort*, whose origins are on par with tabulating machines
    that used punched cards to do census work.
  prefs: []
  type: TYPE_NORMAL
- en: Bitmap Sort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s start with a sorting method that has excellent performance but some limitations,
    if you can live with them. We have to make three suppositions. First, you’re going
    to sort only numbers on their own (no key + data). Second, you know the possible
    range of numbers, and it’s not very big. (For instance, if all you knew was that
    they were 64-bit numbers, the range from lowest to highest numbers would make
    you forget about attempting this algorithm.) And, third, the numbers are never
    going to be duplicated; all numbers to sort will be different.
  prefs: []
  type: TYPE_NORMAL
- en: With these (too many) restrictions in mind, you can easily use a bitmap. Assume
    you are starting with all bits turned off, and whenever you read a number, set
    that bit to on. After you’re done, go through the bits in order, and whenever
    a bit is set, output the corresponding number, and you’re done (see [Figure 6-11](chapter6.xhtml#fig6-11)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-11: Bitmap sort takes advantage of knowing the range of values to
    be sorted.'
  prefs: []
  type: TYPE_NORMAL
- en: You must go through all the numbers to find the minimum and maximum values to
    define the size of the bitmap. After that, go through the numbers again, setting
    bits whenever a number appears. In [Figure 6-11](chapter6.xhtml#fig6-11), bits
    corresponding to numbers 22, 24, 25, 27, 28, and 31 are set. (JavaScript mandates
    that all arrays start at position 0, so you have to remember that position 0 actually
    corresponds to key 22, position 1 to key 23, and so on.) Finally, go through the
    bitmap, outputting the numbers whose bits are set; it’s simple.
  prefs: []
  type: TYPE_NORMAL
- en: 'This algorithm is limited, but it’s the basis for a different, enhanced algorithm.
    For simplicity, this example will use an array of booleans instead of a bitmap
    and write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: First make a copy of the input array ❶ to simplify the next step, which is determining
    the minimum and maximum keys ❷. (This could be done in a single loop a tad more
    efficiently.) Then create a bitmap array of the right length ❸, but in reality
    you’ll be using common booleans, not bits. You need to be careful with indices,
    because JavaScript’s arrays always start at zero; a bit of index math will be
    needed to relate keys to array positions. Then go through the input array ❹ and
    check whether the key already appeared. If so ❺, there’s a problem. If not ❻,
    just mark that the number did appear. Finally, go through the bitmap ❼, and whenever
    you find a set flag ❽, output the corresponding number.
  prefs: []
  type: TYPE_NORMAL
- en: Not being able to allow for duplicate keys is a serious limitation, and dealing
    with numbers only is another; you need to be able to sort elements consisting
    of a key + data, as in all the other algorithms you’ve explored so far.
  prefs: []
  type: TYPE_NORMAL
- en: '#### Counting Sort'
  prefs: []
  type: TYPE_NORMAL
- en: The previous sort is quite effective but applies in only limited cases. You
    can make improvements by calculating where each sorted element should go. To do
    that, you need to count how many times each key appears and then use that information
    to decide where to place sorted elements in the output array (see [Figure 6-12](chapter6.xhtml#fig6-12)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-12: Count sort is somewhat similar to bitmap sort, but it can deal
    with repeated keys.'
  prefs: []
  type: TYPE_NORMAL
- en: In the same way as with bitmap sort, you need to find the minimum and maximum
    values in the array to be sorted and set up an appropriate array with counters,
    all initialized to zero. (Again, remember that position 0 corresponds to the minimum
    key, which is 47 in this case; position 1 corresponds to 48, and so on.) Then
    go through the array again, incrementing the corresponding counters. After you
    have all the counts, you can follow an easy procedure to determine where each
    key goes. For instance, elements with the minimum key (47) start at position 0
    of the output array; elements with the next key (48) follow two places later (because
    there were two 47s) at place 2\. Each new key is placed to the right of the previous
    key, leaving as many empty spaces as needed to place all the previous elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'The implementation for this algorithm follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The first three lines of this algorithm are the same as the bitmap sort ❶, and
    you create a copy of the input array and determine the minimum and maximum keys.
    You then create an array with the counts for all keys (initialized to zero and
    needing the same kind of index math as in bitmap sort ❷). Then go through the
    input data ❸ and increment counts for each key value. Now generate a new array
    ❹ to calculate the starting place for elements with each key. The minimum key
    starts at position 0, and each key is a few spaces away from the previous one,
    according to the count of the previous key ❺. (For example, if the previous count
    was 5, you’ll have the new key 5 places away from the first occurrence of the
    previous key.) Finally, use the place array to start positioning sorted elements
    in their right places ❻; each time an element goes into the output array, the
    corresponding place is incremented by 1 ❼ for the next element with the same key.
  prefs: []
  type: TYPE_NORMAL
- en: Radix Sort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The last sorting algorithm in this chapter is probably the oldest. It was used
    with Hollerith punch cards (see [Figure 6-13](chapter6.xhtml#fig6-13)) when tabulating
    census data, back in the days when IBM was founded.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-13: An original Hollerith card (public domain)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose you have a disordered set of punch cards, numbered in columns 1 to
    6, and you want to sort them. Using a *classifier*, a machine that processes cards
    and separates them into bins according to the value on a specific column, you
    would follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 1. Separate cards into bins according to column 6 and choose cards with a 0,
    then cards with a 1, and so on, finishing with cards with a 9\. You have sorted
    the cards by the sixth column, but you have to keep working.
  prefs: []
  type: TYPE_NORMAL
- en: 2. Redo the same process, but use column 5\. When you pick the cards up, you’ll
    find that they are sorted by two columns (refer back to the “Sorting Stability”
    section on page 93 to understand why).
  prefs: []
  type: TYPE_NORMAL
- en: 3. Do the process again for columns 4, 3, 2, and 1, in that order, and you’ll
    end up with a totally sorted deck of cards.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll explore this algorithm in more detail in [Chapter 10](chapter10.xhtml)
    when looking at lists, which will be the way you’ll emulate the bins.
  prefs: []
  type: TYPE_NORMAL
- en: Inefficient Sorting Algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ll finish on a not-too-serious note by considering some algorithms that are
    really inefficient, going from bad to worse. These algorithms are not intended
    for actual use!
  prefs: []
  type: TYPE_NORMAL
- en: Stooge Sort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The name of this algorithm comes from the Three Stooges comedy group, and if
    you’re familiar with them, its inefficiency will remind you of their antics. The
    process to sort a list starts by comparing its first and last elements and swapping
    them (if needed) to ensure the greater one is at the end. Next, it recursively
    applies Stooge sort to the initial two-thirds of the list, then it sorts the last
    two-thirds of the list (which ensures that the last third will have the greatest
    values, in order), and finally, it sorts the first two-thirds of the list again.
    The number of comparisons needed for *n* elements satisfies *C*(*n*) = 3*C*(2*n*
    / 3) + 1, so the algorithm has a complexity of *O*(*n*^(2.71)), which makes it
    perform worse than bubble sort, but there’s even worse.
  prefs: []
  type: TYPE_NORMAL
- en: Slow Sort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This algorithm was designed as a joke. Rather than divide and conquer, it’s
    based on “multiply and surrender.” The authors were proud to have found an algorithm
    worse than any that were previously created. To sort an array with two or more
    elements, the algorithm first splits it in half, and then it uses recursion to
    sort each half. Finally, it compares the last element of each half and places
    it (swapping if needed) at the end of the original array. After doing that, the
    algorithm proceeds to sort the list with the maximum extracted. The number of
    comparisons for this algorithm satisfies *C*(*n*) = 2*C*(*n* / 2) + *C*(*n* –
    1) + 1, and its time is *O*(*n* ^(log) *^n*). It’s not even polynomial!
  prefs: []
  type: TYPE_NORMAL
- en: '#### Permutation Sort'
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Chapter 5](chapter5.xhtml), you saw how to go forward from one permutation
    of values to the following one, which suggests an even worse algorithm for sorting
    a sequence: repeatedly attempting to produce the next permutation of the elements
    until the algorithm fails because the last permutation was reached and then reversing
    the sequence. For a random order, this algorithm requires testing on average *n*!
    / 2 permutations, which means its time is at least factorial. For almost any size,
    the algorithm becomes impossible to run because of its running time.'
  prefs: []
  type: TYPE_NORMAL
- en: Bogosort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The last algorithm derives its name from a portmanteau of the words *bogus*
    and *sort*, and it’s a probabilistic algorithm that sorts its input with probability
    1, but without any certainty as to its running time. The idea also has to do with
    permutations: if the list to be sorted isn’t in order, it shuffles its elements
    randomly (we’ll look at such algorithms in [Chapter 8](chapter8.xhtml)) and tests
    again. If you were to apply this method to sorting a deck of cards, the logic
    would be as follows: if the cards are not in order, throw them into the air, pick
    them up, and check again—the odds of getting it right are 1/52!, so roughly around
    one in a hundred million million million million million million million million
    million million million. Not good!'
  prefs: []
  type: TYPE_NORMAL
- en: Sleep Sort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The last sort is specifically meant for JavaScript, and its running time depends
    on the maximum key to be sorted. It works with numeric keys, and the idea is that
    if an input key is *K*, wait *K* seconds and output its value. After enough time
    has passed, all values will be output in order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Even if this algorithm seems to work, with a sufficiently large dataset, it
    may crash (too many timeouts waiting) or fail. The algorithm goes through the
    list and starts to output numbers—think of processing a list such as 1, 2, 2,
    2, . . . , 2, 2, 0, and with enough 2s, the initial 1 may be output before the
    last 0 is processed.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter we’ve explored several sorting algorithms with different performance
    levels. In the next chapter, we’ll touch on a similar subject, the selection problem,
    which is akin to sorting only part of an array, because instead of getting all
    elements in order in their proper place, you care only about placing a single
    element in its final place, not necessarily sorting the whole list.
  prefs: []
  type: TYPE_NORMAL
- en: '### Questions'
  prefs: []
  type: TYPE_NORMAL
- en: '**6.1  Forced Reversal**'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you want to order a set of numbers in descending order, but you have
    a sorting function that sorts only in ascending order with no options whatsoever
    to change how it works. How can you manage to sort your data as you wish?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.2  Only Lower**'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you had a boolean function lower(a,b) that returns true if a is lower
    in sorting order than b and false otherwise. How can you use it to decide whether
    a is higher in sorting order than b? And how can you use it to see whether both
    keys are equal in order?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.3  Testing a Sort Algorithm**'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you’re trying out a new sorting algorithm of your own. How would you
    test that it actually sorted correctly?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.4  Missing ID**'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you got a set of six-digit IDs, but the count is under 1,000,000, so
    at least one ID is missing. How can you find one?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.5  Unmatched One**'
  prefs: []
  type: TYPE_NORMAL
- en: Say you have an array with transaction numbers, and each number should appear
    twice somewhere in the array, but you know there was a mistake, and there’s a
    single transaction that appears only once. How do you detect it?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.6  Sinking Sort**'
  prefs: []
  type: TYPE_NORMAL
- en: This is a variant of bubble sort. Instead of starting at the bottom of the array
    and making higher values bubble to the top, sinking sort starts at the top of
    the array and makes smaller values sink to the bottom. In terms of performance,
    it’s the same as bubble sort, but it may be used if you want to find only the
    *k* lowest elements of the array, as you’ll see in [Chapter 7](chapter7.xhtml).
    Can you implement sinking sort?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.7  Bubble Swap Checking**'
  prefs: []
  type: TYPE_NORMAL
- en: Add a test to bubble sort after each pass through the array to exit earlier
    if no swaps were detected. This test will speed things up if you deal with arrays
    that were practically in order and just a few swap passes get everything in its
    place.
  prefs: []
  type: TYPE_NORMAL
- en: '**6.8  Inserting Recursively**'
  prefs: []
  type: TYPE_NORMAL
- en: Can you implement insertion sort in a recursive way?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.9  Stable Shell?**'
  prefs: []
  type: TYPE_NORMAL
- en: Is Shell sort stable?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.10  A Dutch Enhancement**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Dutch National Flag Problem requires you to arrange an array with elements
    that are either red, white, or blue, so all red elements come first, followed
    by all white ones, and finishing with all blue ones, as in the Dutch national
    flag. Show how you may similarly enhance quicksort’s performance with repeated
    elements by rearranging the array to be sorted into three parts: all elements
    less than the pivot, all elements equal to the pivot, and all elements greater
    than the pivot. The middle part won’t need any further sorting.'
  prefs: []
  type: TYPE_NORMAL
- en: '**6.11  Simpler Merging?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'When merging halves in merge sort, you wrote the following (look specifically
    at the text in bold):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Why is it written that way? You always want to compare using the greater- than
    operator to be able to easily substitute a function for more complex comparisons,
    but why not write arr[rr]>arr[ll] instead?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.12  Try Not to Be Negative**'
  prefs: []
  type: TYPE_NORMAL
- en: What happens with radix sort if some numbers are negative? Also, what happens
    if you have noninteger values? Can you do something about this?
  prefs: []
  type: TYPE_NORMAL
- en: '**6.13  Fill It Up!**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In radix sort, imagine you wanted to initialize the buckets array with 10 empty
    arrays, and you did it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Why wouldn’t the following alternative work?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: And what about this other possibility?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '**6.14  What About Letters?**'
  prefs: []
  type: TYPE_NORMAL
- en: How would you modify radix sort to work with alphabetical strings?
  prefs: []
  type: TYPE_NORMAL
