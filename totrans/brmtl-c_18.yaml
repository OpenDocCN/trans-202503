- en: '16'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Floating-Point Numbers
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: In this part of the book, we work through some C features that aren’t typically
    useful in embedded programming but that you may encounter in mainframe programming.
    Floating-point numbers aren’t common in embedded programming because a lot of
    low-end processor chips can’t handle them. Even when you have a CPU that does
    work with them, floating-point arithmetic is slow, inexact, and tricky to use.
  prefs: []
  type: TYPE_NORMAL
- en: However, because you will occasionally encounter these numbers in scientific
    or 3D graphic programs, you should be prepared. This chapter covers the basics
    of floating point, why floating-point operations are so expensive to compute,
    and some of the errors that can occur while using them.
  prefs: []
  type: TYPE_NORMAL
- en: What Is a Floating-Point Number?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *floating-point number* is one in which the decimal point floats. It can occur
    in different places in the number, such as `1.0`, `0.1`, `0.0001`, or `1000.0`.
    Strictly speaking, having a digit after the decimal point isn’t required. For
    example, `1.0` and `1.` are the same number. However, floating-point numbers are
    easier to read and more obvious if they have digits on both sides of the decimal
    point.
  prefs: []
  type: TYPE_NORMAL
- en: We can also write floating-point numbers using exponent notation, such as `1.0e33`,
    which represents the number 1.0 × 10^(33). (You can use an uppercase `E` or lowercase
    `e`, but the lowercase version is more readable.)
  prefs: []
  type: TYPE_NORMAL
- en: Floating-Point Types
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In C, the floating-point types are `float`, `double`, and `long double`. The
    `double` type is supposed to have twice the precision and range of the `float`
    (single-precision) type. The `long double` has a greater precision and range than
    the other two types.
  prefs: []
  type: TYPE_NORMAL
- en: All floating-point constants are of the `double` type unless you tell C differently.
    Adding an `F` suffix to the end of a number makes it a single-precision `float`,
    and adding an `L` at the end makes it a `long double`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The decimal point is required for floating-point numbers. Consider the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first assignment does not assign `f1` the value 0.3333\. Instead, it assigns
    it the value 0.0, because 1 and 3 are integers. C performs an *integer divide*
    (which results in integer 0), promotes it to floating point, and makes the assignment.
    The second line does what we want and assigns the value 0.3333.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic Conversions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'C does some automatic conversions behind your back. If one operand of an expression
    is a floating-point number, C automatically converts the other to a float. Here’s
    an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the 3 will be turned into 3.0 before the division operation. This
    example is considered bad form because you don’t want to mix integers and floating-point
    constants if you can help it. Also, if you assign a floating-point number to an
    integer, it is converted to an integer.
  prefs: []
  type: TYPE_NORMAL
- en: Problems with Floating-Point Numbers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the problems with floating-point numbers is that they’re not exact. For
    example, 1/3 in decimal floating point is 0.333333\. No matter how many digits
    you use, it still is not exact. Rather than show what happens with binary floating
    point (used by a computer), we’re going to use a decimal floating point (familiar
    to humans). Everything that can go wrong with our decimal floating point can go
    wrong with the binary version. The only difference is that with decimal floating
    point, the examples are easier to understand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Decimal floating point is a limited version of scientific notation. Here’s
    an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This number has a sign (+), a fraction (four digits), and an exponent. This
    is not a problem for humans, but representing numbers like this in a computer
    is tricky.
  prefs: []
  type: TYPE_NORMAL
- en: Computers use a similar format, except the exponent and fraction are in binary.
    Also, they mix up the order and store the components in the order sign, exponent,
    and then fraction. For more details, see the IEEE-754 floating-point specification,
    which is used by almost all computers currently.
  prefs: []
  type: TYPE_NORMAL
- en: Rounding Errors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You know that 1 + 1 is 2, but 1/3 + 1/3 is not 2/3\. Let’s take look at how
    this works. First, let’s add the numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'However, 2/3 is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This is an example of a rounding error. There is a small error between `+3.333e-01`
    and 1/3\. Because of the standard rounding rules we are using, we round down.
    When we compute 2/3, we get `6.67e-1`. In this case, the rounding rules cause
    us to round up, so although 1 + 1 = 2 (integer), 1/3 + 1/3 != 2/3 (floating point).
  prefs: []
  type: TYPE_NORMAL
- en: We can use some tricks to minimize rounding errors here. One trick most computers
    use is to add guard digits during calculations. A *guard digit* is an extra digit
    added to the number while the calculations are being done. When the result is
    computed, the guard digit is dropped.
  prefs: []
  type: TYPE_NORMAL
- en: Digits of Precision
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Single-precision floating point (`float`) should give you about 6.5 digits of
    precision, but that’s not always true. How many digits can you trust? In the previous
    example, we might be tempted to say that the first three digits of our decimal
    floating point are accurate, but we can’t rely on that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s compute 2/3 – 1/3 – 1/3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: How many digits are correct? The first digit of our result is 1\. (*Normalization*
    means that we change the number so that there is a digit in the first location.
    All floating-point numbers are stored normalized, except for a few edge cases
    that we’ll cover later.) The correct first digit should be 0.
  prefs: []
  type: TYPE_NORMAL
- en: A number of problems are inherent in the design of floating-point arithmetic.
    Mainly they boil down to the fact that most numbers are inexact, which can result
    in computational errors and problems with exact comparisons.
  prefs: []
  type: TYPE_NORMAL
- en: If you are doing a limited amount of floating-point operations, they probably
    won’t bite you, but you should be aware of them. If you are doing a lot of floating-point
    operations, you should check out the branch of computer science called *numerical
    analysis* that’s devoted to dealing with floating-point issues and how to get
    stable results out of them, but that’s beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Infinity, NaN, and Subnormal Numbers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The IEEE floating-point format has a few bit patterns that make no sense as
    numbers. For example, consider the number 0*10⁵. Since 0 times anything is 0,
    we can use the exponent in this case to indicate a special value. In this section,
    we’ll look at a few of these, as well as the edge cases of the floating-point
    format.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: If this were an integer, dividing it by zero would abort your program. However,
    because it’s floating point, the result is that `f` is assigned the value `INFINITY`
    (this constant is defined in the `#include <math.h>` header file).
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, the statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: assigns `f` the value `-INFINITY`.
  prefs: []
  type: TYPE_NORMAL
- en: The numbers `INFINITY` and `-INFINITY` are not floating-point numbers (they
    have no digits and no decimal point), but the IEEE floating-point specification
    has defined several of these special numbers. Since you are likely to encounter
    these types of numbers (especially if your program contains bugs), it’s important
    to know what they are.
  prefs: []
  type: TYPE_NORMAL
- en: 'You also may encounter a `NaN` (for Not a Number), which is generated when
    an operation cannot produce a result. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Newer versions of the C standard include complex numbers, but the `sqrt` function
    always returns a `double`, so `sqrt(-1.0)` always returns `NaN`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, what’s the tiniest number we can represent in our floating-point scheme?
    You might be tempted to say it’s the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The fraction 1.0000 is the smallest fraction we can create. (If we used 0.5000,
    it would get normalized to 5.0000.) And –99 is the smallest exponent we can get
    with two digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we can get smaller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'And smaller still:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Up to this point, the numbers we’ve been discussing have been normalized, which
    means a digit is always in the first position. Those numbers are considered to
    be *subnormal*. We’ve also lost some significant digits. We have five significant
    digits with the number `+1.2345e-99`, but only one for `+0.0001e-99`.
  prefs: []
  type: TYPE_NORMAL
- en: In C, the `isnormal` macro returns true if a number is normalized, and the `issubnormal`
    macro returns true if the number is subnormalized.
  prefs: []
  type: TYPE_NORMAL
- en: If you encounter subnormalized numbers, you’ve reached into the darkest corners
    of the C floating point. So far, I’ve not seen any real program that’s made use
    of them, but they exist and you should be aware of them.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Floating points can be implemented in a variety of ways. Let’s start with the
    STM chip we’ve been using. Implementation is simple: you can’t have floating point.
    The hardware doesn’t do it, and the machine doesn’t have enough power to do it
    in software.'
  prefs: []
  type: TYPE_NORMAL
- en: Lower-end chips generally have no floating-point unit. As a result, floating-point
    operations are done through the use of a software library, which comes with a
    cost. Floating-point operations in general take about 1,000 times longer than
    their integer counterparts.
  prefs: []
  type: TYPE_NORMAL
- en: Once you get into the better chips, you’ll find native floating-point support.
    The operations are still expensive; a floating-point operation will take roughly
    10 times longer than an integer operation.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the best ways to deal with floating point is to not use it. As mentioned
    previously, one example is when working with money. If you store money as a float,
    rounding errors will eventually cause you to generate incorrect totals. If instead
    you store money as an integer number of cents, you’ll avoid floating point and
    all its ills.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s define a simple fixed-point number with the number of digits after the
    decimal fixed at 2\. Here are some examples and an integer implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To add or subtract fixed point, just add or subtract the underlying implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'To multiply fixed-point numbers, multiply the two numbers and divide by 100
    to correct for the placement of the decimal point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'To divide, you do the opposite: divide the underlying numbers and multiply
    by a correction.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 15-1 contains a program demonstrating the use of fixed-point numbers.
  prefs: []
  type: TYPE_NORMAL
- en: '**fixed.c**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 16-1: Using fixed-point numbers'
  prefs: []
  type: TYPE_NORMAL
- en: This is not a perfect implementation. Rounding errors occur in some places,
    such as the multiply and divide operations, but if you’re really into fixed point,
    you should be able to spot them easily.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understanding the underlying implementation and the limitations of floating-point
    numbers is important. As mentioned previously, you should never use floating point
    for money. Accountants like exact numbers, and rounding errors can result in incorrect
    answers. The numerical analysis branch of computer science deals with analyzing
    how computations are made and figuring out how to minimize errors. This chapter
    shows you the basics. If you’re going to use floating-point numbers extensively,
    you should have a working knowledge of numerical analysis. However, the best way
    of using floating point is to avoid it altogether, so make sure you understand
    that alternatives to floating point, such as fixed point, exist.
  prefs: []
  type: TYPE_NORMAL
- en: 'Wikipedia has a good article on the IEEE floating-point standard with links
    to lots of online reference material: [https://en.wikipedia.org/wiki/IEEE_754](https://en.wikipedia.org/wiki/IEEE_754).'
  prefs: []
  type: TYPE_NORMAL
- en: Programming Problems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Write a function that computes the `sin` of an angle. How many factors do you
    need to compute to get an accurate answer?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using a `float`, compute pi to as many digits as possible. How many digits more
    will you get if you change the data type to `double`? How many for `long double`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Say you want to find the number of bits in the fraction part of a floating-point
    number. Write a program that starts with *x* = 1 and keeps dividing *x* by 2 until
    (1.0 + *x* = 1.0). The number of times you divided by 2 is the number of bits
    in your floating-point calculations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
