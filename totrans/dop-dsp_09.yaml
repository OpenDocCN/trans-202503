- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Orchestrating with Kubernetes
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: A container makes applications portable and consistent, but it’s only one piece
    of a modern application stack. Imagine needing to manage thousands of containers
    on different hosts, network ports, and shared volumes. What if one container stopped?
    How could you scale for load? How could you force containers to run on different
    hosts for availability? Container *orchestration* solves all these issues and
    more. *Kubernetes*, or *K8s*, is the open-source orchestration system many companies
    use to manage their containers. Kubernetes comes preloaded with some useful patterns
    (such as networking, role-based access control, and versioned APIs), but it’s
    meant to be the foundational framework on which to build your unique infrastructure
    and tools. Kubernetes is the standard in container orchestration. You can think
    of it as a low-level piece of your infrastructure, just like Linux.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you’ll learn some basic Kubernetes resources and concepts concerning
    container orchestration. To put orchestration into practice, you’ll deploy the
    telnet-server container image from Chapter 6 inside your Kubernetes cluster using
    the `kubectl` command line client.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes from 30,000 Feet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes (which means *helmsman* in Greek) evolved from its predecessors,
    Borg and Omega, at Google. It was open-sourced in 2014 and has received great
    community support and many enhancements since then.
  prefs: []
  type: TYPE_NORMAL
- en: A Kubernetes cluster consists of one or more control plane nodes and one or
    more worker nodes. A *node* can be anything from a cloud VM to a bare-metal racked
    server to a Raspberry Pi. The *control plane nodes* handle things like the Kubernetes
    API calls, the cluster state, and the scheduling of containers. The core services
    (such as the API, etcd, and the scheduler) run on the control plane. The *worker
    nodes* run the containers and resources that are scheduled by the control plane.
    See [Figure 7-1](#figure7-1) for more details.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram showing the command line interface, connected to the control plane
    node 1, which has the API server, scheduler, controller, and etcd layers. The
    control plane connects to the worker node 1\. Inside the worker node are pods
    1 and 2, docker, and the kubelet and kube-proxy layers.](image_fi/502482c07/f07001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-1: The basic building blocks of a Kubernetes cluster'
  prefs: []
  type: TYPE_NORMAL
- en: Networking and scheduling are the most complex issues you’ll encounter when
    orchestrating containers. When networking containers, you must consider all the
    ports and access they need. Containers can communicate with each other, both inside
    and outside the cluster. This happens with microservices internal communication
    or when running a public-facing web server. When scheduling containers, you must
    take into account the current system resources and any special placement strategies.
    You can tune a worker node for a specific use case, like high connections, and
    then create rules to ensure that the applications that need that feature end up
    on that specific worker node. This is called *node affinity*. As a container orchestrator,
    you also need to restrict user authentication and authorizations. You can use
    an approach like role-based access control, which allows containers to run in
    a safe and controlled manner. These approaches represent just a small part of
    the complex glue and wiring you’ll need. It takes a whole framework to successfully
    deploy and manage containers.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes Workload Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *resource* is a type of object that encapsulates state and intent. To make
    this concept a little clearer, let’s consider an automobile analogy. If a workload
    running on Kubernetes were a car, the resources would describe the parts of the
    car. For example, you could set your car to have two seats and four doors. You
    would not have to understand how to make a seat or a door. You would just need
    to know that Kubernetes will maintain the given count for both (no more, no less).
    Kubernetes resources are defined in a file called a *manifest*. Throughout this
    chapter, we will use the terms *resource* and *object* interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the most commonly used Kubernetes resources in a modern application
    stack.
  prefs: []
  type: TYPE_NORMAL
- en: Pods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Pods* are the smallest building blocks in Kubernetes, and they form the foundation
    for everything interesting you’ll do with containers. A Pod is made up of one
    or more containers that share network and storage resources. Each container can
    connect to the other containers, and all containers can share a directory between
    them by a mounted volume. You won’t deploy Pods directly; instead, they’ll be
    incorporated into a higher-level abstraction layer like a ReplicaSet.'
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *ReplicaSet* resource is used to maintain a fixed number of identical Pods.
    If a Pod is killed or deleted, the ReplicaSet will create another Pod to take
    its place. You’ll only want to use a ReplicaSet if you need to create a custom
    orchestration behavior. Typically, you should reach for a Deployment to manage
    your application instead.
  prefs: []
  type: TYPE_NORMAL
- en: Deployments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *Deployment* is a resource that manages Pods and ReplicaSets. It is the most
    widely used resource for governing applications. A Deployment’s main job is to
    maintain the state that is configured in its manifest. For example, you can define
    the number of Pods (which are called *replicas* in this context) along with the
    strategy for deploying new Pods. The Deployment resource controls a Pod’s lifecycle—from
    creation, to updates, to scaling, to deletion. You can also roll back to earlier
    versions of a Deployment if needed. Anytime your application needs to be long
    lived and fault tolerant, a Deployment should be your first choice.
  prefs: []
  type: TYPE_NORMAL
- en: StatefulSets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *StatefulSet* is a resource for managing stateful applications, such as PostgreSQL,
    ElasticSearch, and etcd. Similar to a Deployment, it can manage the state of Pods
    defined in a manifest. However, it also adds features like managing unique Pod
    names, managing Pod creation, and ordering termination. Each Pod in a StatefulSet
    has its own state and data bound to it. If you are adding a stateful application
    to your cluster, choose a StatefulSet over a Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Services
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Services* allow you to expose applications running in a Pod or group of Pods
    within the Kubernetes cluster or over the internet. You can choose from the following
    basic Service types:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ClusterIP` This is the default type when you create a Service. It is assigned
    an internal routable IP address that proxies connections to one or more Pods.
    You can access a `ClusterIP` only from within the Kubernetes cluster.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Headless` This does not create a single-service IP address. It is not load
    balanced.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`NodePort` This exposes the Service on the node’s IP addresses and port.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`LoadBalancer` This exposes the Service externally. It does this either by
    using a cloud provider’s component, like AWS’s Elastic Load Balancing (ELB), or
    a bare-metal solution, like MetalLB.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`ExternalName` This maps a Service to the contents of the `externalName` field
    to a `CNAME` record with its value.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You’ll use `ClusterIP` and `LoadBalancer` the most. Note that only the `LoadBalancer`
    and `NodePort` Services can expose a Service outside the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Volumes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *Volume* is basically a directory, or a file, that all containers in a Pod
    can access, with some caveats. Volumes provide a way for containers to share and
    store data between them. If a container in a Pod is killed, the Volume and its
    data will survive; if the entire Pod is killed, the Volume and its contents will
    be removed. Thus, if you need storage that is not linked to a Pod’s lifecycle,
    use a *Persistent Volume (PV)* for your application. A PV is a resource in a cluster
    just like a node. Pods can use the PV resource, but the PV does not terminate
    when the Pod does. If your Kubernetes cluster is running in AWS, you can use *Amazon
    Elastic Block Storage (Amazon EBS)* as your PV. This makes Pod catastrophes easier
    to survive.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Secrets* are convenient resources for safely and reliably sharing sensitive
    information (such as passwords, tokens, SSH keys, and API keys) with Pods. You
    can access Secrets either via environment variables or as a Volume mount inside
    a Pod. Secrets are stored in a RAM-backed filesystem on the Kubernetes nodes until
    a Pod requests them. When not used by a Pod, they are stored in memory, instead
    of in a file on disk. However, be careful because the Secrets manifest expects
    the data to be in Base64 encoding, which is not a form of encryption.'
  prefs: []
  type: TYPE_NORMAL
- en: With Secrets, sensitive information is kept separate from the application. This
    is because such information is more likely to be exposed in the continuous integration/continuous
    deployment process than if it’s living in a resource. You still need to keep your
    Secret manifests safe by using RBAC to restrict broad access to the Secrets API.
    You can also store the sensitive data encrypted in the Secret and have another
    process to decrypt it on the Pod once it is mounted or needed. Another option
    is to encrypt the manifests locally before adding them to version control. No
    matter which method you choose, make sure you have a secure plan for storing sensitive
    information in Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: ConfigMaps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*ConfigMaps* allow you to mount nonsensitive configuration files inside a container.
    A Pod’s containers can access the ConfigMap from an environment variable, from
    command line arguments, or as a file in a Volume mount. If your application has
    a configuration file, putting it into a ConfigMap manifest provides two main benefits.
    First, you can update or deploy a new manifest file without having to redeploy
    your whole application. Second, if you have an application that watches for changes
    in a configuration file, then when it gets updated, your application will be able
    to reload the configuration without having to restart.'
  prefs: []
  type: TYPE_NORMAL
- en: Namespaces
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *Namespace* resource allows you to divide a Kubernetes cluster into several
    smaller virtual clusters. When a Namespace is set, it provides a logical separation
    of resources, even though those resources can reside on the same nodes. If you
    don’t specify a Namespace when creating a resource, it will inherit the Namespace
    cleverly named *default*. If your team has many users and a lot of projects spread
    among them, you might split those teams or applications into separate Namespaces.
    This makes it easy to apply secure permissions or other constraints to only those
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Sample telnet-server Application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To start exploring Kubernetes, you’ll create a Deployment and two Services for
    the telnet-server application. I have chosen a Deployment to provide fault tolerance
    for your application. The two Services will expose the telnet-server application
    port and the application metrics port. By the end of this section, you’ll have
    a Kubernetes Deployment with two Pods (replicas) running the telnet-server application
    that can be accessed from your local host.
  prefs: []
  type: TYPE_NORMAL
- en: Interacting with Kubernetes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before you can deploy your telnet-server application, you’ll need to make sure
    you can connect to your Kubernetes cluster. The most direct way to interact with
    the cluster is to use the `kubectl` command line application, which you can get
    in two ways. The first way is to download the standalone binary from [https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/)
    for your specific OS. The second way, which you’ll use here, is to leverage minikube’s
    built-in support for `kubectl`. Minikube will fetch the `kubectl` binary for you
    the first time you invoke the `minikube kubectl` command (if it’s not already
    installed).
  prefs: []
  type: TYPE_NORMAL
- en: When using `minikube kubectl`, most commands will require double dashes (`--`)
    between `minikube kubectl` and subcommands. The standalone version of `kubectl`,
    however, does not need dashes between the commands. If you already have `kubectl`
    installed or want to use the standalone version, drop the `minikube` prefix and
    the double dashes from all the examples that follow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start out with a simple command so minikube can download the `kubectl`
    binary and test access to the cluster. Use the `cluster-info` subcommand for this
    example to verify that the cluster is up and running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You’ll want to see similar output that indicates you can connect to the Kubernetes
    cluster. If there were an issue with talking to the cluster, you might see an
    error like `"The control plane node must be running for this command"`. If that
    happens, enter the `minikube status` command to make sure minikube is still up
    and running.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the Manifests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you have access to the cluster, review the provided manifests for the
    Deployment and Services. Kubernetes manifests are files designed to describe the
    desired state for applications and services. They manage resources like Deployments,
    Pods, and Secrets. These files can either be in JSON or YAML; we use the YAML
    format for this book, purely out of preference. The manifest files should be kept
    under source control. You’ll usually find the files co-residing with the application
    they describe.
  prefs: []
  type: TYPE_NORMAL
- en: I have provided the manifest files to create the telnet-server Deployment and
    two Services. The files are located in the repository at [https://github.com/bradleyd/devops_for_the_desperate/](https://github.com/bradleyd/devops_for_the_desperate/).
    Navigate to the *telnet-server/* directory and list the files in the *kubernetes/*
    subdirectory. There, you should find two files. The first file, *deployment.yaml*,
    creates a Kubernetes Deployment with two Pods of the telnet-server container image.
    The second file, *service.yaml*, creates two separate Services. The first Service
    creates a `LoadBalancer` so you can connect to the telnet-server from outside
    the Kubernetes cluster. The other Service creates a `ClusterIP`, which exposes
    the metrics endpoint from within the cluster. Don’t worry about the metrics port
    for this chapter—we’ll use it in Chapter 9 when discussing monitoring and metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'These manifest files can be quite verbose, so we’ll focus on the basic structure
    each file contains. To describe a complex object, you’ll need multiple fields,
    subfields, and values to define how a resource behaves. Because of this, it can
    be difficult to write a manifest from scratch. Among all these fields and values,
    there is a subset of required fields called *top-level fields*. These are common
    across all manifest files. Understanding top-level fields makes it easier to remember
    and parse a manifest file. The four top-level fields are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`apiVersion` This is a Kubernetes API version and group, like apps/v1\. Kubernetes
    uses versioned APIs and groups to deliver different versions of features and support
    for resources.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`kind` This is the type of resource you want to create, such as a Deployment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`metadata` This is where you set things like names, annotations, and labels.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`spec` This is where you set the desired behavior for the resource (kind).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each of these top-level fields contains multiple subfields. The subfields contain
    information such as name, replica count, template, and container image. For example,
    `metadata` has `name` and `labels` subfields. The formats for the fields can be
    different for each Kubernetes resource. I won’t describe every field, but I’ll
    often use the `labels` subfield. *Labels* provide a way for the user to tag a
    resource with identifiable key values. For example, you could add a label to all
    resources that are in the `production environment`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can use these `labels` to narrow down search results and group similar applications
    together, as with a frontend website and its backend database counterpart. You’ll
    use `labels` later, when you invoke the `minikube kubectl` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing all the different field structures in a manifest file would take up
    a lot of real estate. Instead, you can explore the documentation in two different
    places. The Kubernetes documentation at [https://kubernetes.io/docs/concepts/overview/working-with-objects/](https://kubernetes.io/docs/concepts/overview/working-with-objects/)
    describes all the resources and provides examples. The second place to explore,
    which is my favorite, is the `explain` subcommand for `kubectl`. The `explain`
    subcommand describes the fields associated with each resource type. You can use
    the dot (`.`) notation as a type field separator when searching for nested fields.
    For example, to learn more about a Deployment’s `metadata` `labels` subfield,
    enter the following in a terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Notice how this example first searches for the resource type, then its top-level
    field, and then the subfield.
  prefs: []
  type: TYPE_NORMAL
- en: Examining the telnet-server Deployment
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now that you have an understanding of the building blocks of a manifest file,
    let’s apply what you’ve learned to the telnet-server Deployment manifest. I’ve
    broken the *deployment.yaml* file into sections to make it easier to dissect.
    The first section at the top of the file has the `apiVersion`, `kind`, and `metadata`
    fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The type (`kind`) is `Deployment`, which uses the Kubernetes API group `apps`
    and API version `v1`. Under the `metadata` field, the Deployment `name` is set
    to `telnet-server`, and the `labels` are set to `app: telnet-server`. You’ll use
    this label when searching for the telnet-server Deployment later on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next section of the file contains the parent `spec` field that describes
    the behavior and specification of the Deployment. The `spec` field contains a
    lot of subfields and values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: First, `spec` describes the `replicas` count for the Deployment; it’s set to
    `2` to reflect the number of Pods you want to run. Inside the `selector` field,
    `matchLabels` locates the Pods that this Deployment will affect. The key value
    used in `matchLabels` must match the Pod’s template labels (more on this later).
  prefs: []
  type: TYPE_NORMAL
- en: The `strategy` field describes how to replace the current running Pods with
    new ones during a rollout. This example uses a `RollingUpdate`, which will replace
    one Pod at a time as it goes. This is the default strategy for a Deployment. The
    other option for strategy, `Recreate`, kills the current running Pods before creating
    the new ones.
  prefs: []
  type: TYPE_NORMAL
- en: The `maxSurge` and `maxUnavailable` keys control the number of Pods created
    and terminated. Here, it’s set to bring up an extra Pod during a rollout, which
    temporarily brings the Pod count to `replicas` + 1 (or three, in this case). Once
    the new Pod is up and running, one of the old Pods will be terminated. Then, the
    process repeats until all the new Pods are running and the old Pods are terminated.
    These settings will ensure that there is always a Pod to serve traffic during
    a Deployment. See [https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy/](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy/)
    for more information about strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next part of the `spec` section is the `template` field. This field (along
    with its subfields) describes the Pods that this Deployment will create. The major
    subfields in this section are `metadata` and `spec`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the `app: telnet-server` key value is added for each Pod in the Deployment,
    using the `labels` subfield under `template` and `metadata`. The `app: telnet-server`
    label matches the key and value you used earlier in the `spec` `selector:` field.
    (You’ll use this label again when searching for the Pods later.)'
  prefs: []
  type: TYPE_NORMAL
- en: The `containers` field sets the container image for the first container in the
    Pod. In this case, it’s set to the *dftd/telnet-server:v1* image you built in
    Chapter 6. This container `name` is `telnet-server`, just like the Deployment.
    Using the same `name` isn’t a requirement; the `name` could be any string you
    choose so long as it is unique among the containers in the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: The next subfield under `containers` is `resources`, which controls CPU and
    memory for a container. You can define `requests` and `limits` for each container
    individually. The `requests`are used for Kubernetes scheduling (orchestration)
    and overall application health. If a container needs a minimum of 2GB of memory
    and one CPU to start, you don’t want Kubernetes to schedule that Pod (container)
    on a node that has only 1GB of memory or no CPUs available. `Requests` are the
    minimum resources your application needs. `Limits`, on the other hand, control
    the maximum CPU and memory a container can use on a node. You don’t want a container
    to use all the memory or CPU on a node while starving any other containers running
    on it. In this example, the `CPU` limit is set to `500m` (millicpu), or half of
    a CPU. This unit can also be expressed as a decimal, like 0.5\. In Kubernetes,
    one CPU is equivalent to one CPU core. The `memory` limit is set to `100Mi`, or
    104,857,600 bytes. In Kubernetes, `memory` is expressed in bytes, but you can
    use more familiar units like M, Mi, G, and Gi. When these `limits` are set and
    the telnet-server container consumes more than `100Mi` of `memory`, Kubernetes
    will terminate it. However, if the `CPU` limit (`500m`) is surpassed, Kubernetes
    won’t just kill the container. It will throttle, or limit, the CPU request time
    for that container. For more details on how Kubernetes quantifies resources, see
    [https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/).
  prefs: []
  type: TYPE_NORMAL
- en: The container `ports` field sets the exposed ports you want to announce. This
    example exposes ports `2323` (`telnet`) and `9000` (`metrics`). These port definitions
    are for informational purposes only and have no bearing on whether a container
    can receive traffic. They simply let the user and Kubernetes know on what ports
    you expect the container to be listening.
  prefs: []
  type: TYPE_NORMAL
- en: Examining the telnet-server Service
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The next manifest to examine is the `Service` resource. The *service.yaml*
    file creates two separate Services: one to expose the telnet-server and the other
    to expose the application metrics. We’ll look at only the `telnet` Service and
    specific fields here since the `metric` Service is almost identical:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'A `Service`resource is set in the `kind` field, which is different from the
    Deployment manifest shown earlier. The Service `name` can be anything, but it
    must be unique within a Kubernetes Namespace. I’ve kept the `names` consistent
    with the rest of the resources here, for ease of use. I’ve also used the same
    `app: telnet-server` label to make finding things uniform and simple.'
  prefs: []
  type: TYPE_NORMAL
- en: The `ports` field tells the `Service` which port to expose and how to connect
    it to the Pods. This exposes port `2323` (`telnet`) and forwards any traffic to
    port `2323` on the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as with the `selector` field for a Deployment, a `Service` uses a `selector`
    field to find the Pods to forward traffic to. This instance uses the familiar
    Pod label `app: telnet-server` as the match for the `selector`, which means any
    Pods with the label `app: telnet-server` will receive traffic from this `Service`.
    If there is more than one Pod, like in the Deployment, the traffic will be sent
    to all the Pods in a round-robin manner. Since the goal of the `telnet-server`
    application is to be exposed outside the cluster, it’s set as a `LoadBalancer`.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Deployment and Services
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is time to create the Deployment and Services. To turn the sample application
    into a Kubernetes Deployment, you’ll use the `minikube` `kubectl` command line
    tool and the manifest files you just reviewed ([https://github.com/bradleyd/devops_for_the_desperate/](https://github.com/bradleyd/devops_for_the_desperate/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'To create and update resources, you can pass `minikube` `kubectl` two subcommands:
    `create` and `apply`. The `create` subcommand is *imperative*, which means it
    makes the resource reassemble the manifest file. It also throws an error if the
    resource already exists. The `apply` subcommand is *declarative*, which means
    it creates the resource if it does not exist and updates it if it does. For this
    scenario, you’ll use the `apply` command with an `-f` flag to instruct `kubectl`
    to run the operation against all the files in the *kubernetes/* directory. The
    `-f` flag can take filenames in lieu of directories as well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From within the *telnet-server/* directory, enter the following command to
    create the `Deployment` and two `Services`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The output should show that all three resources have been `created`. Be sure
    to investigate any errors if they arise from this command. Common errors you might
    see are usually due to syntax errors or typos in the YAML file.
  prefs: []
  type: TYPE_NORMAL
- en: Viewing the Deployment and Services
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the telnet-server Deployment and Services are created, you need to know
    how to find them. Kubernetes provides multiple ways to view any object’s status.
    The easiest method is to use the `minikube kubectl -- get <``resource``> <``name``>`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can start by fetching the Deployment status by its name and then explore
    the Services. Enter the following to get the `Deployment` status for the `telnet-server`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The output should show that the `telnet-server` Deployment has two replicas
    (Pods) running (`2/2 READY`) and that they have been running for seven seconds
    (`7s AGE`). This should match the number of replicas set in the Deployment manifest.
    The `UP-TO-DATE` and `AVAILABLE` columns show how many Pods were updated to get
    to the desired number (`2`) and how many are available (`2`) to users, respectively.
    In this case, Kubernetes believes the Deployment is up and running and fully available.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also run the `minikube kubectl get pods` command to find out whether
    a Deployment is ready for traffic. Because you could have hundreds of Pods, you
    want to narrow down your results with the `-l` label filter flag. Enter the following
    to show only the `telnet-server` Pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This command lists any Pods that have the label `app: telnet-server` set; it’s
    the same label set in the *deployment.yaml* file under the `spec.template.metadata.labels`
    field. The output shows two `telnet-server` Pods ready for traffic. You know this
    because the `READY` column shows `1/1` containers running and your Deployment
    has only one container (`telnet-server`). If you had a Pod with multiple containers,
    you would want the number of running containers over the number of total containers
    to be the same.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, use the same command as above but substitute `services` for the `pods`
    resource to display the two Services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Since you used the same label (`app: telnet-server`) to organize your application,
    you can use the `-l` flag to find your match. The output shows that two Services
    were created about 10 minutes ago. One Service type is a `LoadBalancer`, and the
    other is a `ClusterIP`. The `LoadBalancer` is for exposing the `telnet-server`
    application. Don’t be alarmed if your `EXTERNAL-IP` status is `<pending>`. Because
    you are running on minikube, no real `LoadBalancer` piece is included.'
  prefs: []
  type: TYPE_NORMAL
- en: The `ClusterIP` Service allows the application metrics to be scraped from within
    the cluster. In this example, internal applications can reach the metrics endpoint
    by using either the `telnet-server-metrics` canonical name or the IP `10.96.53.191`.
    Using the canonical name is recommended.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the Deployment and Services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that the telnet-server Deployment and Services are running, you’ll want
    to test connectivity and availability. You want to be able to access the telnet-server
    application, like you did in Chapter 6, with the telnet client. After that, you’ll
    test the Deployment’s resiliency by killing a telnet-server Pod and watching it
    recover. Finally, you’ll learn how to *scale*, meaning change the number of replicas
    that the Deployment has up and down from the command line, in the case of a change
    in load.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the Telnet Server
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ll use the `minikube tunnel` command to expose your `LoadBalancer` Service
    outside the Kubernetes cluster. This command will provide you with an IP address
    that you can use to connect, using the `telnet` `client` command again. The `tunnel`
    subcommand runs in the foreground, so it should be run in a terminal that won’t
    get closed. The command also requires *root* privileges. If you do not have *root*
    privileges on your local machine, use the `minikube service` command instead.
    Visit [https://minikube.sigs.k8s.io/docs/commands/service/](https://minikube.sigs.k8s.io/docs/commands/service/)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a terminal, enter the following to create the network `tunnel` to the `telnet-server`
    Service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: After entering your password, the command outputs a `route`, the `services`
    exposed, and any present `errors`. Make sure you leave this running while you
    try to connect to the `telnet-server`. Once the `tunnel` is closed, all the connections
    will drop. Since there are `no errors` to report, the `tunnel` should be operational
    at this point. Don’t do it now, but when you want to close the `tunnel`, press
    CTRL-C to shut it down.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, with the tunnel up, you need to get the new external IP address for the
    `LoadBalancer` Service. As a shortcut, pass the Service name to `get services`
    `telnet-server` (in this case) to view only the Service you are interested in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `EXTERNAL-IP` column should now be populated with an IP address instead
    of `<pending>`. Here, the `telnet-server` application IP address is set to `10.105.187.105`,
    and the external `PORT` is set to `2323`. Your `EXTERNAL-IP` may be different
    from mine, so just use the IP from this column.
  prefs: []
  type: TYPE_NORMAL
- en: In another terminal that is not running the tunnel, use the `telnet client`
    command again (`telnet` `10.105.187.105`) with the new IP address to access the
    `telnet-server`, as shown in [Figure 7-2](#figure7-2).
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the telnet-server responded with the ASCII art logo. Press Q
    to quit, since you are just testing connectivity. The `tunnel` command made it
    possible to hit the Service using an assigned IP like it was a public-facing application.
    If this were on a cloud provider like AWS, the IP would be accessible to anyone
    on the internet. Feel free to kill the `tunnel` command in the other terminal,
    but you’ll use it again in future chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot showing the DFTD banner in green ASCII art in a terminal window
    with a black background](image_fi/502482c07/f07002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-2: Testing telnet access to telnet-server'
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting Tips
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you cannot connect to the telnet-server like in [Figure 7-2](#figure7-2),
    check that the Pods are still running and that they are reporting that `1/1` containers
    are `READY`. If the `READY` column shows `0/1` instead and the `STATUS` column
    has an error like `ImagePullBackOff`or `ErrImagePull`, then the Pod could not
    find the telnet-server image you built in Chapter 6. Make sure the image is built
    and available when you list the Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the `READY` and `STATUS` columns are correct, the next step is to make sure
    your Service is wired up to your Pods. One way to check this connection is with
    the `kubectl get endpoints` command, which will tell you if the Service can find
    the Pods you specified in the Service `spec.selector` field located in the *service.yaml*
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ENDPOINTS` column shows the internal Pod IP addresses with ports. Since
    you have two Pods, there are two IP addresses separated by a comma for each Service.
    If the Service can’t locate the Pods, the `ENDPOINTS` column will be set to `<none>`.
    If your `ENDPOINTS` column has `<none>`, check that the `spec.selector` field
    in your Service matches what is in the `spec.template.metadata.labels` field in
    the *deployment.yaml* file. I have preset it to the label `app: telnet-server`
    in the example. Having mismatched labels between a Service and a resource is a
    common mistake; it will happen to you at least once.'
  prefs: []
  type: TYPE_NORMAL
- en: Killing a Pod
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another great feature of Deployments is recovery. Failure is going to happen,
    so embrace it! A Deployment will get you back up and to full strength in no time.
    Remember, a Deployment’s main purpose is to keep the desired number of Pods running.
    To test this, you’ll delete one of the `telnet-server` Pods and then watch the
    Deployment respawn another in its place. First, you’ll need to fetch one of the
    `telnet-server` Pods’ names and delete it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the following to get the `telnet-server` Pods again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: It really doesn’t matter which Pod you delete, so just choose the first one
    on the list, which is `telnet-server-775769766-2bmd5` on my cluster. (Your Pod
    names will be different, as they are autogenerated.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, enter the following command to `delete` the selected Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The command might appear to hang for a few seconds, but it will eventually finish
    when the Pod has terminated.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you list the Pods again, you’ll see two Pods are still running, but now
    the `telnet-server-775769766-2bmd5` is gone and has been replaced with a new Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This new Pod, named `telnet-server-775769766-rdg5w`, is more than a minute old,
    is `Running`, and is ready to accept connections.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s pretend the telnet-server application really resonates with the nostalgic
    over-35 crowd and becomes a runaway success. The two telnet-servers will no longer
    be adequate for handling the increased traffic, so you’ll need to scale up your
    replicas to a count greater than two. You can do this in two ways. The first way
    is to edit the *deployment.yaml* manifest file and apply the changes to the cluster
    using the `minikube apply` command. The second way is to use the `minikube kubectl
    scale` command. I’ll demonstrate this example using the `minikube kubectl scale`
    command, since you already learned how to apply manifest files earlier in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'You are going to increase the Deployment replica count by one, bringing the
    total number of Pods to three. (In a real production environment, you would base
    the replica count number off some key metrics instead of a finger in the wind.)
    Enter the following command to scale up the `telnet-server` Deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `scale deployment` command takes a `--replicas` flag to set the number of
    Pod replicas. The output shows the `telnet-server` Deployment has `scaled`, but
    let’s verify this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the following command to verify that the replica count has changed for
    your Deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Here, you get the Deployment resource information for `telnet-server`. The Deployment
    has three out of three `(3/3)` replicas `READY`, up from the two it had earlier.
  prefs: []
  type: TYPE_NORMAL
- en: The `scale` command changes the replica count in real time on the cluster. This
    can be dangerous. If a colleague pushes out a new version of the `telnet-server`
    application right after you scaled from the command line, the replica state will
    not match. This is because when he or she runs the `minikube kubectl -- apply
    -f kubernetes/deployment.yaml` command, the Deployment replica count would go
    back to two, since that’s what’s stated in the *deployment.yaml* manifest file.
  prefs: []
  type: TYPE_NORMAL
- en: Logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The last piece of orchestration to test is accessing the telnet-server application
    logs. Fortunately, Kubernetes makes this simple with the `kubectl` `logs` subcommand.
    You want to grab the logs for all three of your telnet-server Pods. One way to
    do this is to execute the `logs` command for each of the three Pods and view the
    results. Enter the following command to view one of the Pods logs (remember, your
    Pod names will be different from mine):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This works fine if you do not have many Pods or if you know which Pod an event
    happened on. If not, a better option is to grab all the Pods logs at the same
    time and mark each log line with the Pod name from which it came. Enter the following
    command to fetch all the logs for each Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Quite a few flags are used in this command; let’s break each one down:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To fetch only Pods with this label: `-l app=telnet-server`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When you have multiple Pods and want to see all the logs: `--all-containers=true`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each log line with the Pod name from which the log came: `--prefix=true`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output should show at least six log lines—two start-up log lines for each
    Pod (3) and whatever other logs may have shown up from connecting earlier with
    the `telnet` command. The log output is not important now, as you just need to
    make sure you can access the logs for your application.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you learned how to run the telnet-server container image inside
    a Kubernetes cluster. You successfully orchestrated your application by using
    a Kubernetes Deployment resource that you exposed to your local host via a Kubernetes
    Service. Finally, you explored how to create, query, and view your resources and
    logs with the `minikube kubectl` command. In the next chapter, you’ll learn to
    automate the deployment of telnet-server by implementing a simple delivery pipeline
    inside Kubernetes.
  prefs: []
  type: TYPE_NORMAL
