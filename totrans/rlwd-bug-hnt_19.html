<html><head></head><body>
<h2 class="h2" id="ch19"><span epub:type="pagebreak" id="page_191"/><strong><span class="big">19</span><br/>FINDING YOUR OWN BUG BOUNTIES</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">Unfortunately, there is no magical formula to hacking, and there are too many constantly evolving technologies for me to explain every method of finding a bug. Although this chapter won’t make you an elite hacking machine, it should teach you the patterns successful bug hunters follow. This chapter guides you through a basic approach to begin hacking any application. It’s based on my experience interviewing successful hackers, reading blogs, watching videos, and actually hacking.</p>&#13;
<p class="indent">When you first start hacking, it’s best to define your success based on the knowledge and experience you gain, rather than on the bugs you find or money you earn. This is because if your goal is to find bugs on high-profile programs or to find as many bugs as you can or simply to make money, <span epub:type="pagebreak" id="page_192"/>you may be unsuccessful at first if you are brand new to hacking. Very smart and accomplished hackers test mature programs, such as Uber, Shopify, Twitter, and Google, on a daily basis, so there are far fewer bugs to find and it can be easy to get discouraged. If you focus on learning a new skill, recognizing patterns, and testing new technologies, you can stay positive about your hacking during dry spells.</p>&#13;
<h3 class="h3" id="ch19lev1sec1"><strong>Reconnaissance</strong></h3>&#13;
<p class="noindent">Begin approaching any bug bounty program using some <em>reconnaissance</em>, or <em>recon</em>, to learn more about the application. As you know from previous chapters, there’s a lot to consider when you’re testing an application. Start by asking these and other basic questions:</p>&#13;
<ul>&#13;
<li class="noindent">What’s the scope of the program? Is it <em>*.&lt;example&gt;.com</em> or just <em>www.&lt;example&gt;.com</em>?</li>&#13;
<li class="noindent">How many subdomains does the company have?</li>&#13;
<li class="noindent">How many IP addresses does the company own?</li>&#13;
<li class="noindent">What type of site is it? Software as a service? Open source? Collaborative? Paid or free?</li>&#13;
<li class="noindent">Which technologies does it use? Which programming language is it coded in? Which database does it use? Which frameworks is it using?</li>&#13;
</ul>&#13;
<p class="indent">These questions are only some of the considerations you need to think about when you first start hacking. For the purposes of this chapter, let’s assume you’re testing an application with an open scope, like <em>*.&lt;example&gt;.com</em>. Start with the tools you can run in the background so you can do other recon while you’re waiting for the tools’ results. You can run these tools from your computer, but you risk companies like Akamai banning your IP address. Akamai is a popular web application firewall, so if it bans you, you might be unable to visit common sites.</p>&#13;
<p class="indent">To avoid a ban, I recommend spinning up a virtual private server (VPS) from a cloud-hosting provider that allows security testing from its systems. Be sure to research your cloud provider because some don’t allow this type of testing (for example, at the time of this writing, Amazon Web Services doesn’t allow security testing without explicit permission).</p>&#13;
<h4 class="h4" id="ch19lev2sec1"><strong><em>Subdomain Enumeration</em></strong></h4>&#13;
<p class="noindent">If you’re testing on an open scope, you can begin your recon by finding subdomains using your VPS. The more subdomains you find, the more attack surface you’ll have. To do this, I recommend using the SubFinder tool, which is fast and written in the Go programming language. SubFinder will pull in subdomain records for a site based on a variety of sources, including certificate registrations, search engine results, the Internet Archive Wayback Machine, and others.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_193"/>The default enumeration that SubFinder conducts might not find all subdomains. But subdomains associated with a specific SSL certificate are easy to find because of certificate transparency logs that record registered SSL certificates. For example, if a site registers a certificate for <em>test.&lt;example&gt;.com</em>, it’s likely that subdomain will exist, at least at the time of registration. But it’s possible for a site to register a certificate for a wildcard subdomain (<em>*.&lt;example&gt;.com</em>). If that’s the case, you might only be able to find some subdomains through brute-force guessing.</p>&#13;
<p class="indent">Conveniently, SubFinder can also help you brute-force subdomains using a common word list. The security list GitHub repository SecLists, referenced in <a href="app01.xhtml#app01">Appendix A</a>, has lists of common subdomains. Also, Jason Haddix has published a helpful list at <em><a href="https://gist.github.com/jhaddix/86a06c5dc309d08580a018c66354a056/">https://gist.github.com/jhaddix/86a06c5dc309d08580a018c66354a056/</a></em>.</p>&#13;
<p class="indent">If you don’t want to use SubFinder and just want to browse SSL certificates, <em><a href="http://crt.sh">crt.sh</a></em> is a great reference to check whether wildcard certificates have been registered. If you find a wildcard certificate, you can search <em><a href="http://censys.io">censys.io</a></em> for the certificate hash. Usually, there’s even a direct link to <em><a href="http://censys.io">censys.io</a></em> on <em><a href="http://crt.sh">crt.sh</a></em> for each certificate.</p>&#13;
<p class="indent">Once you’ve finished enumerating subdomains for <em>*.&lt;example&gt;.com</em>, you can port scan and screenshot the sites you find. Before moving on, also consider whether it makes sense to enumerate subdomains of subdomains. For example, if you find that a site registers an SSL certificate for <em>*.corp.&lt;example&gt;.com</em>, it’s likely you’ll find more subdomains by enumerating that subdomain.</p>&#13;
<h4 class="h4" id="ch19lev2sec2"><strong><em>Port Scanning</em></strong></h4>&#13;
<p class="noindent">After you’ve enumerated subdomains, you can start port scanning to identify more attack surfaces, including running services. For example, by port scanning Pornhub, Andy Gill found an exposed Memcache server, and earned $2,500, as discussed in <a href="ch18.xhtml#ch18">Chapter 18</a>.</p>&#13;
<p class="indent">The results of the port scan can also be indicative of a company’s overall security. For example, a company that has closed all ports except 80 and 443 (common web ports for hosting HTTP and HTTPS sites) is likely to be security conscious. But a company with lots of open ports is likely the opposite and might have better potential for bounties.</p>&#13;
<p class="indent">Two common port-scanning tools are Nmap and Masscan. Nmap is an older tool and can be slow unless you know how to optimize it. But it’s great because you can give it a list of URLs and it will determine the IP address to scan. It’s also modular, so you can include other checks in your scan. For example, the script titled <em>http-enum</em> will perform file and directory brute-forcing. In contrast, Masscan is extremely fast and might be best when you have a list of IP addresses to scan. I use Masscan to search commonly open ports, such as 80, 443, 8080, or 8443, and then combine the results with screenshotting (a topic I discuss in the next section).</p>&#13;
<p class="indent">Some details to note when port scanning from a list of subdomains are the IP addresses those domains are resolved to. If all but one subdomain resolves to a common IP address range (for example, IP addresses owned by AWS or Google Cloud Compute), it might be worthwhile to investigate <span epub:type="pagebreak" id="page_194"/>the outlier. The different IP address might indicate a custom-built or third-party application that doesn’t share the same level of security as the company’s core applications, which reside on the common IP address range. As described in <a href="ch14.xhtml#ch14">Chapter 14</a>, Frans Rosen and Rojan Rijal exploited third-party services when taking over subdomains from Legal Robot and Uber.</p>&#13;
<h4 class="h4" id="ch19lev2sec3"><strong><em>Screenshotting</em></strong></h4>&#13;
<p class="noindent">As with port scanning, a good step to take once you have a list of subdomains is to screenshot them. This is helpful because it gives you a visual overview of the program’s scope. When you’re reviewing the screenshots, there are some common patterns that may be indicative of vulnerabilities. First, look for common error messages from services known to be associated with subdomain takeovers. As described in <a href="ch14.xhtml#ch14">Chapter 14</a>, an application that relies on external services might change over time, and the DNS records for it might have been left and forgotten. If an attacker can take over the service, that could have significant implications for the application and its users. Alternatively, the screenshot might not reveal an error message but might still show that the subdomain is relying on a third-party service.</p>&#13;
<p class="indent">Second, you can look for sensitive content. For example, if all the subdomains found on <em>*.corp.&lt;example&gt;.com</em> return a 403 access denied except one subdomain, which has a login to an unusual website, investigate that unusual site because it might be implementing custom behavior. Similarly, also watch out for administrative login pages, default installation pages, and so on.</p>&#13;
<p class="indent">Third, look for applications that don’t match ones that are typical on other subdomains. For example, if there is only one PHP application and all the other subdomains are Ruby on Rails applications, it may be worthwhile to focus on that one PHP application because the company’s expertise seems to be in Rails. The importance of applications found on subdomains can be difficult to determine until you become familiar with them, but they can lead to great bounties like the one Jasmin Landry found when he escalated his SSH access to a remote code execution, as described in <a href="ch12.xhtml#ch12">Chapter 12</a>.</p>&#13;
<p class="indent">A few tools can help you screenshot sites. At the time of this writing, I use HTTPScreenShot and Gowitness. HTTPScreenShot is helpful for two reasons: first, you can use it with a list of IP addresses, and it will screenshot them and enumerate other subdomains associated with SSL certificates it parses. Second, it will cluster your results into groups based on whether the pages are 403 messages or 500 messages, whether they use the same content management systems, and other factors. The tool also includes the HTTP headers it finds, which is also useful.</p>&#13;
<p class="indent">Gowitness is a fast, lightweight alternative for screenshotting. I use this tool when I have a list of URLs instead of IP addresses. It also includes the headers it receives when screenshotting.</p>&#13;
<p class="indent">Although I don’t use it, Aquatone is another tool worth mentioning. At the time of this writing, it has recently been rewritten in Go and includes clustering, easy result outputting to match the format required by other tools, and other features.</p>&#13;
<h4 class="h4" id="ch19lev2sec4"><span epub:type="pagebreak" id="page_195"/><strong><em>Content Discovery</em></strong></h4>&#13;
<p class="noindent">Once you’ve reviewed your subdomains and visual recon, you should look for interesting content. You can approach the content discovery phase in a few different ways. One way is to attempt to discover files and directories by brute-forcing them. The success of this technique depends on the word list you use; as mentioned earlier, SecLists provides good lists, particularly the raft lists, which are the ones I use. You can also track the results of this step over time to compile your own list of commonly found files.</p>&#13;
<p class="indent">Once you have a list of files and directory names, you have a few tools to choose from. I use Gobuster or Burp Suite Pro. Gobuster is a customizable and fast brute-forcing tool written in Go. When you give it a domain and word list, it tests for the existence of directories and files, and confirms the response from the server. Additionally, the Meg tool, developed by Tom Hudson and also written in Go, allows you to test multiple paths on many hosts simultaneously. This is ideal when you’ve found a lot of subdomains and want to discover content across all of them simultaneously.</p>&#13;
<p class="indent">As I’m using Burp Suite Pro to proxy my traffic, I’ll use either its built-in content discovery tool or Burp Intruder. The content discovery tool is configurable and allows you to use a custom word list or the built-in one, find file extension permutations, define how many nested folders to brute-force, and more. When using Burp Intruder, on the other hand, I’ll send send a request for the domain I’m testing to Intruder and set the payload on the end of the root path. Then I’ll add my list as the payload and run the attack. Typically, I’ll sort my results based on content length or response status depending on how the application responds. If I discover an interesting folder this way, I might run Intruder again on that folder to discover nested files.</p>&#13;
<p class="indent">When you need to go beyond file and directory brute-forcing, Google dorking, as described in the vulnerability Brett Buerhaus found in <a href="ch10.xhtml#ch10">Chapter 10</a>, can also provide some interesting content discovery. Google dorking can save you time, particularly when you find URL parameters that are commonly associated with vulnerabilities such as <span class="literal">url</span>, <span class="literal">redirect_to</span>, <span class="literal">id</span>, and so on. Exploit DB maintains a database of Google dorks for specific use cases at <em><a href="https://www.exploit-db.com/google-hacking-database/">https://www.exploit-db.com/google-hacking-database/</a></em>.</p>&#13;
<p class="indent">Another approach to finding interesting content is to check the company’s GitHub. You might find open source repositories from the company or helpful information about the technologies it uses. This was how Michiel Prins discovered the remote code execution on Algolia, as discussed in <a href="ch12.xhtml#ch12">Chapter 12</a>. You can use the Gitrob tool to crawl GitHub repositories for application secrets and other sensitive information. Additionally, you can review code repositories and find third-party libraries an application is relying on. If you’re able to find an abandoned project or vulnerability in the third party that affects the site, both could be worth a bug bounty. Code repositories can also give you insight into how a company handled previous vulnerabilities, especially for companies like GitLab that are open source.</p>&#13;
<h4 class="h4" id="ch19lev2sec5"><span epub:type="pagebreak" id="page_196"/><strong><em>Previous Bugs</em></strong></h4>&#13;
<p class="noindent">One of the last steps of reconnaissance is to familiarize yourself with previous bugs. Hacker write-ups, disclosed reports, CVEs, published exploits, and so on are good resources for this. As repeated throughout this book, just because code is updated doesn’t mean all vulnerabilities have been fixed. Be sure to test any changes. When a fix is deployed, it means new code was added, and that new code could contain bugs.</p>&#13;
<p class="indent">The $15,250 bug Tanner Emek found in Shopify Partners, as described in <a href="ch15.xhtml#ch15">Chapter 15</a>, was the result of reading a previously disclosed bug report and retesting the same functionality. As with Emek, when interesting or novel vulnerabilities are publicly disclosed, be sure to read the report and visit the application. At worst, you won’t find a vulnerability, but you’ll develop new skills while testing that functionality. At best, you might bypass the developer’s fix or find a new vulnerability.</p>&#13;
<p class="indent">Having covered all the major areas of reconnaissance, it’s time to move on to testing the application. As you’re testing, keep in mind that reconnaissance is an ongoing part of finding bug bounties. It’s always a good idea to revisit a target application because it constantly evolves.</p>&#13;
<h3 class="h3" id="ch19lev1sec2"><strong>Testing the Application</strong></h3>&#13;
<p class="noindent">There’s no one-size-fits-all approach to testing an application. The methodology and techniques you use depend on the type of application you’re testing, similar to the way the program scope can define your recon. In this section, I’ll provide a general overview of the considerations you need to bear in mind and the thought processes you need to use when approaching a new site. But regardless of the application you’re testing, there’s no better advice than Matthias Karlsson’s: “Don’t think ‘everyone else has looked, there’s nothing left.’ Approach every target like nobody’s been there before. Don’t find anything? Choose another one.”</p>&#13;
<h4 class="h4" id="ch19lev2sec6"><strong><em>The Technology Stack</em></strong></h4>&#13;
<p class="noindent">One of the first tasks I do when testing a new application is identify the technologies being used. This includes, but isn’t limited to, frontend JavaScript frameworks, server-side application frameworks, third-party services, locally hosted files, remote files, and so on. I usually do this by watching my web proxy history and noting the files served, the domains captured in the history, whether HTML templates are served, any JSON content returned, and so on. The Firefox plug-in Wappalyzer is also very handy for quickly fingerprinting technologies.</p>&#13;
<p class="indent">While I’m doing this, I leave the default configuration for Burp Suite enabled and walk through the site to understand the functionality and note what design patterns developers have used. Doing so allows me to refine the types of payloads I’ll use in my testing, as Orange Tsai did when he found the Flask RCE on Uber in <a href="ch12.xhtml#ch12">Chapter 12</a>. For example, if a site uses AngularJS, <span epub:type="pagebreak" id="page_197"/>test <span class="literal">{{7*7}}</span> to see whether <span class="literal">49</span> is rendered anywhere. If the application is built with ASP.NET with XSS protection enabled, you might want to focus on testing other vulnerability types first and check for XSS as a last resort.</p>&#13;
<p class="indent">If a site is built with Rails, you might know that URLs typically follow a <span class="codeitalic">/CONTENT_TYPE/RECORD_ID</span> pattern, where the <span class="codeitalic">RECORD_ID</span> is an autoincremented integer. Using HackerOne as an example, report URLs follow the pattern <em><a href="http://www.hackerone.com/reports/12345">www.hackerone.com/reports/12345</a></em>. Rails applications commonly use integer IDs, so you might prioritize testing insecure direct object reference vulnerabilities because this vulnerability type is easy for developers to overlook.</p>&#13;
<p class="indent">If an API returns JSON or XML, you might recognize that those API calls unintentionally return sensitive information that isn’t rendered on the page. Those calls might be a good testing surface and could lead to information disclosure vulnerabilities.</p>&#13;
<p class="indent">Here are some factors to keep in mind at this stage:</p>&#13;
<p class="hangt"><strong>Content formats a site expects or accepts</strong> For example, XML files come in different shapes and sizes, and XML parsing can always be associated with XXE vulnerabilities. Keep an eye out for sites that accept .<em>docx</em>, .<em>xlsx</em>, .<em>pptx</em>, or other XML file types.</p>&#13;
<p class="hang"><strong>Third-party tools or services that are easily misconfigured</strong> Whenever you read reports about hackers exploiting such services, try to understand how those reporters discovered the vulnerability and apply that process to your testing.</p>&#13;
<p class="hang"><strong>Encoded parameters and how an application handles them</strong> Oddities might be indicative of multiple services interacting in the backend, which could be abused.</p>&#13;
<p class="hang"><strong>Custom implemented authentication mechanisms, such as OAuth flows</strong> Subtle differences in how an application handles redirect URLs, encoding, and state parameters might lead to significant vulnerabilities.</p>&#13;
<h4 class="h4" id="ch19lev2sec7"><strong><em>Functionality Mapping</em></strong></h4>&#13;
<p class="noindent">Once I understand a site’s technologies, I move on to <em>functionality mapping</em>. At this stage, I’m still browsing, but my testing can go one of a few ways here: I might look for markers of vulnerabilities, define a specific goal for my testing, or follow a checklist.</p>&#13;
<p class="indent">When I’m looking for markers of vulnerabilities, I look for behavior commonly associated with vulnerabilities. For example, does the site allow you to create webhooks with URLs? If so, this might lead to SSRF vulnerabilities. Does a site allow for user impersonation? This could lead to sensitive personal information being disclosed. Can you upload files? How and where these files are rendered could lead to a remote code execution vulnerability, XSS, and so on. When I find something of interest, I stop and begin application testing, as described in the next section, and look for some indication <span epub:type="pagebreak" id="page_198"/>of a vulnerability. This might be an unexpected message returned, a delay in response time, unsanitized input being returned, or a server-side check being bypassed.</p>&#13;
<p class="indent">In contrast, when I define and work toward a goal, I decide what I’ll do before testing the application. The goal could be to find a server-side request forgery, local file inclusion, remote code execution, or some other vulnerability. Jobert Abma, a co-founder of HackerOne, commonly employs and advocates for this approach, and Philippe Harewood used this method when he found his Facebook app takeover. With this approach, you ignore all other possibilities and focus entirely on your end goal. You only stop and begin testing if you find something that leads to your goal. For example, if you’re looking for a remote code execution vulnerability, unsanitized HTML returned in a response body wouldn’t be of interest.</p>&#13;
<p class="indent">Another testing approach is to follow a checklist. Both OWASP and Dafydd Stuttard’s <em>Web Application Hacker’s Handbook</em> provide comprehensive testing checklists for reviewing an application, so there’s no reason for me to try to outdo either resource. I don’t follow this path because it’s too monotonous and reminiscent of employment rather than a pleasurable hobby. Nonetheless, following a checklist can help you avoid missing vulnerabilities by forgetting to test specific things or forgetting to follow general methodologies (like reviewing JavaScript files).</p>&#13;
<h4 class="h4" id="ch19lev2sec8"><strong><em>Finding Vulnerabilities</em></strong></h4>&#13;
<p class="noindent">Once you have an understanding of how an application works, you can start testing. Rather than setting a specific goal or using a checklist, I suggest beginning by looking for behavior that could indicate a vulnerability. At this stage, you might assume you should run automated scanners, like Burp’s scanning engine to look for vulnerabilities. But most programs I’ve looked at don’t permit this, it’s unnecessarily noisy, and it requires no skill or knowledge. Instead, you should focus on manual testing.</p>&#13;
<p class="indent">If I’ve begun my application testing without finding anything exciting to look at during my functionality mapping, I start using the site as if I were a customer. I’ll create content, users, teams, or whatever the application provides. While doing this, I usually submit payloads wherever input is accepted and look for anomalies and unexpected behavior from the site. I typically use the payload <span class="literal">&lt;s&gt;000'")};--//</span>, which includes all the special characters that could break the context the payload is rendered in, whether that’s HTML, JavaScript, or a backend SQL query. This type of payload is often referred to as a <em>polyglot</em>. The <span class="literal">&lt;s&gt;</span> tag is also innocent, easy to spot when rendered unsanitized in HTML (you would see strikethrough text when that happens), and frequently left unmodified when a site attempts to sanitize output by altering input.</p>&#13;
<p class="indent">Additionally, when there’s a chance the content I’m creating could be rendered on an administration panel, like my username, address, and so forth, I’ll use a different payload to target blind XSS from XSSHunter (an XSS tool discussed in <a href="app01.xhtml#app01">Appendix A</a>). Finally, if the site uses a templating engine, I’ll also add payloads associated with the template. For AngularJS, <span epub:type="pagebreak" id="page_199"/>this would look like <span class="literal">{{8*8}}[[5*5]]</span>, and I would look for <span class="literal">64</span> or <span class="literal">25</span> rendered. Although I’ve never found a server-side template injection in Rails, I still try the payload <span class="literal">&lt;%= `ls` %&gt;</span> in case an inline render shows up one day.</p>&#13;
<p class="indent">Although submitting these types of payloads covers injection type vulnerabilities (such as XSS, SQLi, SSTI, and so on), it also doesn’t require much critical thinking and can quickly become repetitive and boring. So, to avoid burn out, it’s important to keep an eye on your proxy history for unusual functionality commonly associated with vulnerabilities. Common vulnerabilities and areas to keep an eye out for include, but are not limited to, the following:</p>&#13;
<p class="hangt"><strong>CSRF vulnerabilities</strong> The types of HTTP requests that change data and whether they’re using and validating CSRF tokens or checking the referrer or origin headers</p>&#13;
<p class="hang"><strong>IDORs</strong> Whether there are any ID parameters that can be manipulated</p>&#13;
<p class="hang"><strong>Application logic</strong> Opportunities to repeat requests across two separate user accounts</p>&#13;
<p class="hang"><strong>XXEs</strong> Any XML-accepting HTTP requests</p>&#13;
<p class="hang"><strong>Information disclosures</strong> Any content that is guaranteed to be, or should be, kept private</p>&#13;
<p class="hang"><strong>Open redirects</strong> Any URLs that have a redirect-related parameter</p>&#13;
<p class="hang"><strong>CRLFs, XSS, and some open redirects</strong> Any requests that echo URL parameters in the response</p>&#13;
<p class="hang"><strong>SQLi</strong> Whether adding a single quote, bracket, or semicolon to a parameter changes a response</p>&#13;
<p class="hang"><strong>RCEs</strong> Any type of file upload or image manipulation</p>&#13;
<p class="hang"><strong>Race conditions</strong> Delayed data processing or behaviors related to the time of use or time of check</p>&#13;
<p class="hang"><strong>SSRFs</strong> Functionality that accepts URLs, such as webhooks or external integrations</p>&#13;
<p class="hangb"><strong>Unpatched security bugs</strong> Disclosed server information, such as versions of PHP, Apache, Nginx, and so on, that can reveal outdated technology</p>&#13;
<p class="indent">Of course, this list is endless and arguably always evolving. When you need more inspiration for where to hunt for bugs, you can always look at the takeaway sections in each chapter of this book. After you’ve dug into the functionality and need a break from HTTP requests, you can flip back to your file and directory brute-forcing to see what, if any, interesting files or directories have been discovered. You should review those findings and visit the pages and files. This is also the perfect time to reassess what you’re brute-forcing and determine whether there are other areas to focus on. For example, if you discovered an <span class="literal">/api/</span> endpoint, you could brute-force new paths on that, which can sometimes lead to hidden, undocumented functionality to test. Similarly, if you used Burp Suite to proxy your HTTP traffic, Burp might have picked up additional pages to check based on the links <span epub:type="pagebreak" id="page_200"/>it parsed from the pages you’d already visited. These unvisited pages, which might lead you to untested functionality, are gray in Burp Suite to differentiate them from already-visited links.</p>&#13;
<p class="indent">As previously mentioned, hacking web applications isn’t magic. Being a bug hunter requires one-third knowledge, one-third observation, and one-third perseverance. Digging deeper into the application and thoroughly testing without wasting your time is key. Unfortunately, recognizing the difference takes experience.</p>&#13;
<h3 class="h3" id="ch19lev1sec3"><strong>Going Further</strong></h3>&#13;
<p class="noindent">Once you’ve completed your recon and have thoroughly tested all the functionality you can find, you should research other ways to make your bug search more efficient. Although I can’t tell you how to do that in all situations, I do have some suggestions.</p>&#13;
<h4 class="h4" id="ch19lev2sec9"><strong><em>Automating Your Work</em></strong></h4>&#13;
<p class="noindent">One way to save time is by automating your work. Although we’ve used some automated tools in this chapter, most of the techniques described have been manual, which means we’re limited by time. To move beyond the time barrier, you need computers to hack for you. Rojan Rijal disclosed a Shopify bug he discovered five minutes after the subdomain he found the bug on went live. He was able to discover it so quickly because he automated his recon on Shopify. How to automate your hacking is beyond the scope of this book—and it’s also entirely possible to be a successful bug bounty hacker without it—but it’s one way hackers increase their income. You can begin by automating your reconnaissance. For example, you can automate several tasks, such as subdomain brute-forcing, port scanning, and visual recon, to name a few.</p>&#13;
<h4 class="h4" id="ch19lev2sec10"><strong><em>Looking at Mobile Apps</em></strong></h4>&#13;
<p class="noindent">Another opportunity to find more bugs is by looking at any mobile applications that are included in the program’s scope. This book has focused on web hacking, but mobile hacking offers plenty of new opportunities to find bugs. You can hack mobile apps in one of two ways: testing the application code directly or testing the APIs the app interacts with. I focus on the latter because it’s similar to web hacking and I can concentrate on vulnerability types like IDOR, SQLi, RCE, and so on. To start testing mobile app APIs, you’ll need to proxy your phone traffic as you’re using the app through Burp. This is one way to see the HTTP calls being made so you can manipulate them. But sometimes an app uses <em>SSL pinning</em>, meaning it won’t recognize or use the Burp SSL certificate, so you can’t proxy the app’s traffic. Bypassing SSL pinning, proxying your phone, and general mobile hacking is beyond the scope of this book, but they do represent a great opportunity for new learning.</p>&#13;
<h4 class="h4" id="ch19lev2sec11"><span epub:type="pagebreak" id="page_201"/><strong><em>Identifying New Fuctionality</em></strong></h4>&#13;
<p class="noindent">The next area to focus on is identifying new functionality as it’s added to the application you’re testing. Philippe Harewood is an amazing example of someone who has mastered this skill. Among the top-ranked hackers in the Facebook program, he openly shares the vulnerabilities he discovers on his website at <em><a href="https://philippeharewood.com/">https://philippeharewood.com/</a></em>. His write-ups routinely reference new functionality he’s discovered and the vulnerabilities he’s found before others can because of his quick identification. Frans Rosen shares some of his methodology for identifying new functionality on the Detectify blog at <em><a href="https://blog.detectify.com/">https://blog.detectify.com/</a></em>. To track new functionality on the websites you’re testing, you can read the engineering blogs of the sites you test, monitor their engineering Twitter feeds, sign up for their newsletters, and so on.</p>&#13;
<h4 class="h4" id="ch19lev2sec12"><strong><em>Tracking JavaScript Files</em></strong></h4>&#13;
<p class="noindent">You can also discover new site functionality by tracking JavaScript files. Focusing on JavaScript files is particularly powerful when a site relies on frontend JavaScript frameworks to render its content. The application will rely on having most of the HTTP endpoints a site uses included in its JavaScript files. Changes in the files might represent new or changed functionality you can test. Jobert Abma, Brett Buerhaus, and Ben Sadeghipour have discussed approaches on how they have tracked JavaScript files; you can find their write-ups with a quick Google search of their names and the word “reconnaissance.”</p>&#13;
<h4 class="h4" id="ch19lev2sec13"><strong><em>Paying for Access to New Functionality</em></strong></h4>&#13;
<p class="noindent">Although it might seem counterintuitive when you’re trying to earn money through bounties, you can also pay for access to functionality. Frans Rosen and Ron Chan have discussed the success they’ve enjoyed by paying for access to new functionality. For example, Ron Chan paid a couple of thousand dollars to test an application and found a significant number of vulnerabilities that made the investment very worthwhile. I’ve also been successful paying for products, subscriptions, and services that increase my potential testing scope. Others aren’t likely to want to pay for functionality on sites they don’t use, so this functionality has more undiscovered vulnerabilities.</p>&#13;
<h4 class="h4" id="ch19lev2sec14"><strong><em>Learning the Technology</em></strong></h4>&#13;
<p class="noindent">Additionally, you can look into the technologies, libraries, and software that you know a company is using and learn how they work in detail. The more you know how a technology works, the more likely you are to find bugs based on how it’s being used in the applications you test. For example, finding the ImageMagick vulnerabilities in <a href="ch12.xhtml#ch12">Chapter 12</a> required an understanding of how ImageMagick and its defined file types work. You might <span epub:type="pagebreak" id="page_202"/>be able to find additional vulnerabilities by looking at other technology linked to libraries like ImageMagick. Tavis Ormandy did this when he disclosed additional vulnerabilities in Ghostscript, which ImageMagick supports. You can find more information about these Ghostscript vulnerabilities at <em><a href="https://www.openwall.com/lists/oss-security/2018/08/21/2">https://www.openwall.com/lists/oss-security/2018/08/21/2</a></em>. Similarly, FileDescriptor revealed in a blog post that he reads RFCs on web functionality and focuses on security considerations to understand how something is supposed to work versus how it’s actually implemented. His intimate knowledge of OAuth is a great example of deep diving into a technology that numerous websites use.</p>&#13;
<h3 class="h3" id="ch19lev1sec4"><strong>Summary</strong></h3>&#13;
<p class="noindent">In this chapter, I’ve tried to shed some light on possible approaches to hacking based on my own experience and interviews with top bug bounty hackers. To date, I’ve had the most success after exploring a target, understanding the functionality it provides, and mapping that functionality to vulnerability types for testing. But areas that I continue to explore, and encourage you to look into as well, are automation and documenting your methodology.</p>&#13;
<p class="indent">Lots of hacking tools are available that can make your life easier: Burp, ZAP, Nmap, and Gowitness are some of the few I’ve mentioned. To make better use of your time, keep these tools in mind as you hack.</p>&#13;
<p class="indent">Once you’ve exhausted the typical avenues you’d use to find bugs, look for ways to make your bug searches more successful by digging deeper into mobile applications and new functionality developed on the websites you’re testing.</p>&#13;
</body></html>