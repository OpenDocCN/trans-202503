- en: '**7**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**EVALUATING MALWARE DETECTION SYSTEMS**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/common01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the previous chapter, you learned how machine learning can help you build
    malware detectors. In this chapter, you learn the basic concepts necessary to
    predict how malware detection systems will perform. The ideas you learn here will
    prove crucial in improving any malware detection system you build, because without
    a way to measure your system’s performance, you will not know how to improve it.
    Please note that while this chapter is dedicated to introducing basic evaluation
    concepts, [Chapter 8](ch08.xhtml#ch08) continues this thread, introducing essential
    evaluation concepts like cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: First, I introduce the basic ideas behind detection accuracy evaluation, and
    then I introduce more advanced ideas concerning the environment in which you deploy
    your system when evaluating its performance. To do this, I walk you through an
    evaluation of a hypothetical malware detection system.
  prefs: []
  type: TYPE_NORMAL
- en: '**Four Possible Detection Outcomes**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose you run a malware detection system on a software binary and get the
    system’s “opinion” about whether the binary is malicious or benign. As illustrated
    in [Figure 7-1](ch07.xhtml#ch07fig1), four possible outcomes may occur.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0120-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-1: The four possible detection outcomes*'
  prefs: []
  type: TYPE_NORMAL
- en: 'These outcomes can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True positive** The binary is malware and the system says it is malware.'
  prefs: []
  type: TYPE_NORMAL
- en: '**False negative** The binary is malware and the system says it’s not malware.'
  prefs: []
  type: TYPE_NORMAL
- en: '**False positive** The binary is not malware and the system says it is malware.'
  prefs: []
  type: TYPE_NORMAL
- en: '**True negative** The binary is not malware and the system says it’s not malware.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, there are two scenarios in which your malware detection system
    can produce inaccurate results: false negatives and false positives. In practice,
    true positive and true negative results are what we desire, but they are often
    difficult to obtain.'
  prefs: []
  type: TYPE_NORMAL
- en: You’ll see these terms used throughout this chapter. In fact, most of detection
    evaluation theory is built on this simple vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: '***True and False Positive Rates***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now suppose you want to test the detection system’s accuracy using a set of
    benignware and malware. You can run the detector on each binary and keep count
    of which of the four possible outcomes the detector gives you over the entire
    test set. At this point, you need some summary statistics to give you an overall
    sense of the system’s accuracy (that is, how likely it is that your system will
    generate false positives or false negatives).
  prefs: []
  type: TYPE_NORMAL
- en: One such summary statistic is the *true positive rate* of the detection system,
    which you can calculate by dividing the number of true positives on your test
    set by the total number of malware samples in your test set. Because this calculates
    the percentage of malware samples your system is able to detect, it measures your
    system’s ability to recognize malware when it “sees” malware.
  prefs: []
  type: TYPE_NORMAL
- en: However, simply knowing that your detection system will raise alarms when it
    sees malware is insufficient to evaluate its accuracy. For example, if you only
    used the true positive rate as an evaluation criterion, a simple function that
    says “yes, this is malware” on all files would yield a perfect true positive rate.
    The real test of a detection system is whether or not it says “yes, this is malware”
    when it sees malware and “no, this is not malware” when it sees benignware.
  prefs: []
  type: TYPE_NORMAL
- en: To measure a system’s ability to discern whether something is not malware, you
    also need to measure the system’s *false positive rate*, which is the rate at
    which your system issues a malware alarm when it sees benignware. You can calculate
    your system’s false positive rate by dividing the number of benign samples the
    system flags as malware by the total number of benign samples tested.
  prefs: []
  type: TYPE_NORMAL
- en: '***Relationship Between True and False Positive Rates***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When designing a detection system, you want to keep the false positive rate
    as low as possible while keeping the true positive rate as high as possible. Unless
    you build a truly perfect malware detection system that is always right (which
    is really an impossibility given the evolving nature of malware), there will always
    be tension between the desire for a high true positive and the desire for a low
    false positive rate.
  prefs: []
  type: TYPE_NORMAL
- en: To see why this is the case, imagine a detection system that, before deciding
    whether or not a binary is malware, adds up all the evidence that the binary is
    malware to create a *suspiciousness score* for the binary. Let’s call this hypothetical
    suspiciousness-score-generating system MalDetect. [Figure 7-2](ch07.xhtml#ch07fig2)
    shows an example of the values that MalDetect might output for 12 sample binaries,
    where the circles represent individual software binaries. The further to the right
    a binary, the higher the suspiciousness score given by MalDetect.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0121-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-2: Suspiciousness scores output by the hypothetical MalDetect system
    for individual software binaries*'
  prefs: []
  type: TYPE_NORMAL
- en: Suspiciousness scores are informative, but in order to calculate MalDetect’s
    true positive rate and false positive rate on our files, we need to convert MalDetect’s
    suspiciousness scores to “yes” or “no” answers regarding whether or not a given
    software binary is malicious. To do this, we use a threshold rule. For example,
    we decide that if the suspiciousness score is greater or equal to some number,
    the binary in question raises a malware alarm. If the score is lower than the
    threshold, it doesn’t.
  prefs: []
  type: TYPE_NORMAL
- en: 'Such a threshold rule is the standard way to convert a suspiciousness score
    into a binary detection choice, but where should we set the threshold? The problem
    is that there is no right answer. [Figure 7-3](ch07.xhtml#ch07fig3) shows the
    conundrum: the higher we set the threshold, the less likely we are to get false
    positives, but the more likely we are to get false negatives.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0122-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-3: An illustration of the relationship between false positive rate
    and true positive rate when deciding on a threshold value*'
  prefs: []
  type: TYPE_NORMAL
- en: For example, let’s consider the leftmost threshold shown in [Figure 7-3](ch07.xhtml#ch07fig3),
    where binaries to the left of the threshold are classified as benign and binaries
    to its right are classified as malware. Because this threshold is low, we get
    a great true positive rate (classifying 100 percent of the malware samples correctly)
    but a terrible false positive rate (falsely classifying 33 percent of the benign
    samples as malicious).
  prefs: []
  type: TYPE_NORMAL
- en: Our intuition might be to increase the threshold so that only samples with a
    higher suspiciousness score are deemed to be malware. Such a solution is given
    by the middle threshold in [Figure 7-3](ch07.xhtml#ch07fig3). Here, the false
    positive rate drops to 0.17, but unfortunately the true positive rate drops as
    well, to 0.83\. If we continue to move the threshold to the right, as shown by
    the rightmost threshold, we eliminate any false positives, but detect only 50
    percent of the malware.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there is no such thing as a perfect threshold. A detection threshold
    that yields a low false positive rate (good) will tend to miss more malware, yielding
    a low true positive rate (bad). Conversely, using a detection threshold that has
    a high true positive rate (good) will also increase the false positive rate (bad).
  prefs: []
  type: TYPE_NORMAL
- en: '***ROC Curves***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The tradeoff between the true positive rate and false positive rate of detection
    systems is a universal problem for all detectors, not just malware detectors.
    Engineers and statisticians have thought long and hard about this phenomenon and
    come up with the *Receiver Operating Characteristic (ROC)* curve to describe and
    analyze it.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you’re confused by the phrase Receiver Operating Characteristic, don’t
    worry about it—this phrase* is *confusing and pertains to the context in which
    ROC curves were originally developed, which is radar-based detection of physical
    objects.*'
  prefs: []
  type: TYPE_NORMAL
- en: ROC curves characterize a detection system by plotting false positive rates
    against their associated true positive rates at various threshold settings. This
    helps us evaluate the tradeoff between lower false positive rates and higher true
    positive rates, and in doing so determine the “best” threshold for our situation.
  prefs: []
  type: TYPE_NORMAL
- en: For example, for our hypothetical MalDetect system from [Figure 7-3](ch07.xhtml#ch07fig3),
    the system’s true positive rate is 0.5 when its false positive rate is 0 (low
    threshold), and the system’s true positive rate is 1.00 when the false positive
    rate is 0.33 (high threshold).
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-4](ch07.xhtml#ch07fig4) shows how this works in more detail.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0123-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-4: An illustration of what ROC curves mean and how they are constructed*'
  prefs: []
  type: TYPE_NORMAL
- en: To build the ROC curve, we start with the three thresholds used in [Figure 7-3](ch07.xhtml#ch07fig3)
    and plot their resulting false and true positive rates, shown in the left half
    of [Figure 7-3](ch07.xhtml#ch07fig3). The plot on the right of [Figure 7-4](ch07.xhtml#ch07fig4)
    shows the same thing, but for all possible thresholds. As you can see, the higher
    the false positive rates, the higher the true positive rates. Similarly, the lower
    the false positive rates, the lower the true positive rates.
  prefs: []
  type: TYPE_NORMAL
- en: The “curve” of the ROC curve is a line within the two-dimensional ROC plot that
    represents how we think our detection system will do on its true positive rate
    over all possible false positive values, and how we think our detection system
    will do on its false positive rate over all possible true positive values. There
    are multiple ways of generating such a curve, but that goes beyond the scope of
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: One simple method, however, is to try many threshold values, observe the corresponding
    false and true positive rates, plot them, and connect the dots using a line. This
    connected line, shown in the right plot of [Figure 7-4](ch07.xhtml#ch07fig4),
    becomes our ROC curve.
  prefs: []
  type: TYPE_NORMAL
- en: '**Considering Base Rates in Your Evaluation**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As you’ve seen, ROC curves can tell you how your system will perform in terms
    of the rate at which it calls malicious binaries malicious (true positive rate)
    and the rate at which it calls benign binaries malicious (false positive rate).
    However, ROC curves will not tell you the *percentage* of your system’s alarms
    that will be true positives, which we call the *precision* of the system. The
    precision of a system is related to the percentage of binaries the system encounters
    that are actually malware, which we call the *base rate*. Here’s a breakdown of
    each term:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision** The percentage of system detection alarms that are true positives
    (meaning that they are detections of actual malware). In other words, *precision*
    is the detection system’s number of *true positives / (true positives + false
    positives)* when tested against some set of binaries.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Base rate** The percentage of the data fed to the system that has the quality
    we are looking for. In our case, *base rate* refers to the percentage of binaries
    that are *actually malware*.'
  prefs: []
  type: TYPE_NORMAL
- en: We discuss how these two metrics are related in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: '***How Base Rate Affects Precision***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although a detection system’s true and false positive rates do not change when
    the base rate changes, the system’s precision is affected by changes in the malware
    base rate—often dramatically. To see why this is true, let’s consider the following
    two cases.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose the false positive rate of MalDetect is 1 percent and the true positive
    rate is 100 percent. Now suppose we set MalDetect loose on a network that we know
    upfront has no malware on it (perhaps the network has just been created from scratch
    in a laboratory). Because we know in advance there is no malware on the network,
    every alarm the MalDetect throws will by definition be a false positive, because
    the only binaries that MalDetect encounters will be benignware. In other words,
    precision will be 0 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, if we run MalDetect on a dataset composed of entirely malware,
    none of its alarms will ever be false positives: there simply will never be an
    opportunity for MalDetect to generate a false positive since there is no benignware
    in the software dataset. Therefore, precision will be 100 percent.'
  prefs: []
  type: TYPE_NORMAL
- en: In both of these extreme cases, the base rates have a huge impact on MalDetect’s
    precision, or the probability that its alarm is a false positive.
  prefs: []
  type: TYPE_NORMAL
- en: '***Estimating Precision in a Deployment Environment***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You now know that depending on the proportion of malware in a test dataset
    (base rate), your system will yield very different precision values. What if you
    want to estimate the precision your system will have based on an estimate of the
    base rate of the environment in which you deploy it? All you have to do is use
    your deployment environment’s estimated base rate to estimate the variables in
    the precision formula: *true positives / (true positives + false positives)*.
    You’ll need three numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**True positive rate (TPR)** of the system, or the percentage of malware samples
    the system will correctly detect'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**False positive rate (FPR)** of the system, or the percentage of benign samples
    the system will incorrectly alarm on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Base rate (BR)** of the binaries against which you will use the system (for
    example, the percentage of binaries downloaded from piracy sites you expect will
    be malware, if this is what you’ll be using your system on)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The numerator of the precision equation—the number of true positives—can be
    estimates by *true positive rate × base rate*, giving you the percentage of malware
    your system will correctly detect. Similarly, the denominator of the equation—that
    is, *(true positives + false positives)*—can be estimated by *true positive rate
    × base rate + false positive rate × (1 – base rate)*, giving you the percentage
    of *all* binaries the system will alarm on by calculating the number of malware
    binaries that will be detected correctly plus the fraction of benignware binaries
    for which false positives will be issued.
  prefs: []
  type: TYPE_NORMAL
- en: 'In sum, you calculate the expected precision of your system as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0125-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let’s consider another example to see how base rate can have a profound impact
    on the performance of a detection system. For example, suppose we have a detection
    system that has an 80 percent true positive rate and a 10 percent false positive
    rate, and 50 percent of the software binaries we run it against are expected to
    be malware. This would lead to an expected precision of 89 percent. But when the
    base rate is 10 percent, our precision drops to 47 percent.
  prefs: []
  type: TYPE_NORMAL
- en: What happens if our base rate is very low? For example, in a modern enterprise
    network, very few software binaries are actually malware. Using our precision
    equation, if we assume a base rate of 1 percent (1 in 100 binaries are malware),
    we get a precision of about 7.5 percent, which means that 92.5 percent of our
    system’s alarms would be false positives! And if we assume a base rate of 0.1
    percent (1 in 1000 binaries are likely to be malware), we get a precision of 1
    percent, meaning 99 percent of our system’s alarms would be false positives! Finally,
    at a base rate of 0.01 percent (1 in 10,000 binaries are likely to be malware—probably
    the most realistic assumption on an enterprise network), our expected precision
    drops to 0.1 percent, meaning the overwhelming majority of our system’s alerts
    will be false positives.
  prefs: []
  type: TYPE_NORMAL
- en: One takeaway from this analysis is that detection systems that have high false
    positive rates will almost never be useful in enterprise settings, because their
    precision will be far too low. Therefore, a key goal in building malware detection
    systems is to minimize the false positive rate such that the precision of the
    system is reasonable.
  prefs: []
  type: TYPE_NORMAL
- en: Another related takeaway is that when you do the ROC curve analysis introduced
    earlier in this chapter, you should effectively ignore false positive rates over,
    say, 1 percent, if you are developing your system to be deployed in an enterprise
    setting, because any higher false positive rate will likely result in a system
    that has such low precision that it is rendered useless.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, you learned basic detection evaluation concepts, including
    true positive rate, false positive rate, ROC curves, base rates, and precision.
    You saw how maximizing the true positive rate and minimizing the false positive
    rate are both important in building a malware detection system. Because of the
    way base rate affects precision, reducing the false positive rate is particularly
    important if you want to deploy your detection system within an enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t feel completely fluent in these concepts, don’t worry. You’ll get
    more practice with them in the next chapter, where you’ll build and evaluate a
    malware detection system from the ground up. In the process, you’ll learn additional
    machine learning–specific evaluation concepts that will help you improve your
    machine learning–based detectors.
  prefs: []
  type: TYPE_NORMAL
