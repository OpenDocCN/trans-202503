["```\nCREATE TABLE pls_fy2018_libraries (\n    stabr text NOT NULL,\n    1 fscskey text CONSTRAINT fscskey_2018_pkey PRIMARY KEY,\n    libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n `--snip--`\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\n2 COPY pls_fy2018_libraries\nFROM '`C:\\YourDirectory\\`pls_fy2018_libraries.csv'\nWITH (FORMAT CSV, HEADER);\n\n3 CREATE INDEX libname_2018_idx ON pls_fy2018_libraries (libname);\n```", "```\nCREATE TABLE pls_fy2017_libraries (\n    stabr text NOT NULL,\n    1 fscskey text CONSTRAINT fscskey_17_pkey PRIMARY KEY,\n libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n `--snip--`\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\nCREATE TABLE pls_fy2016_libraries (\n    stabr text NOT NULL,\n    fscskey text CONSTRAINT fscskey_16_pkey PRIMARY KEY,\n    libid text NOT NULL,\n    libname text NOT NULL,\n    address text NOT NULL,\n    city text NOT NULL,\n    zip text NOT NULL,\n `--snip--`\n    longitude numeric(10,7) NOT NULL,\n    latitude numeric(10,7) NOT NULL\n);\n\n2 COPY pls_fy2017_libraries\nFROM '*C:\\YourDirectory\\*pls_fy2017_libraries.csv'\nWITH (FORMAT CSV, HEADER);\n\nCOPY pls_fy2016_libraries\nFROM '*C:\\YourDirectory\\*pls_fy2016_libraries.csv'\nWITH (FORMAT CSV, HEADER);\n\n3 CREATE INDEX libname_2017_idx ON pls_fy2017_libraries (libname);\nCREATE INDEX libname_2016_idx ON pls_fy2016_libraries (libname);\n```", "```\nSELECT count(*)\nFROM pls_fy2018_libraries;\n\nSELECT count(*)\nFROM pls_fy2017_libraries;\n\nSELECT count(*)\nFROM pls_fy2016_libraries;\n```", "```\ncount\n-----\n 9261\n```", "```\ncount\n-----\n 9245\n```", "```\ncount\n-----\n 9252\n```", "```\nSELECT count(phone)\nFROM pls_fy2018_libraries;\n```", "```\ncount\n-----\n 9261\n```", "```\nSELECT count(libname)\nFROM pls_fy2018_libraries;\n\nSELECT count(DISTINCT libname)\nFROM pls_fy2018_libraries;\n```", "```\ncount\n-----\n 9261\n```", "```\ncount\n-----\n 8478\n```", "```\nSELECT max(visits), min(visits)\nFROM pls_fy2018_libraries;\n```", "```\nmax         min\n--------    ---\n16686945     -3\n```", "```\nSELECT stabr\nFROM pls_fy2018_libraries\n1 GROUP BY stabr\nORDER BY stabr;\n```", "```` ``` stabr  -----  AK  AL  AR  AS  AZ  CA  `--snip--`  WV  WY ```    Notice that there are no duplicates in the 55 rows returned. These standard two-letter postal abbreviations include the 50 states plus Washington, DC, and several US territories, such as Guam and the US Virgin Islands.    You’re not limited to grouping just one column. In [Listing 9-8](#listing9-8), we use the `GROUP BY` clause on the 2018 data to specify the `city` and `stabr` columns for grouping.    ``` SELECT city, stabr  FROM pls_fy2018_libraries  GROUP BY city, stabr  ORDER BY city, stabr; ```    Listing 9-8: Using `GROUP BY` on the `city` and `stabr` columns    The results get sorted by city and then by state, and the output shows unique combinations in that order:    ``` city          stabr  ----------    -----  ABBEVILLE     AL  ABBEVILLE     LA  ABBEVILLE     SC  ABBOTSFORD    WI  ABERDEEN      ID  ABERDEEN      SD  ABERNATHY     TX  `--snip--` ```    This grouping returns 9,013 rows, 248 fewer than the total table rows. The result indicates that the file includes multiple instances where there’s more than one library agency for a particular city and state combination.    #### Combining GROUP BY with count()    If we combine `GROUP BY` with an aggregate function, such as `count()`, we can pull more descriptive information from our data. For example, we know 9,261 library agencies are in the 2018 table. We can get a count of agencies by state and sort them to see which states have the most. [Listing 9-9](#listing9-9) shows how to do this.    ``` 1 SELECT stabr, count(*)  FROM pls_fy2018_libraries  2 GROUP BY stabr  3 ORDER BY count(*) DESC; ```    Listing 9-9: Using `GROUP BY` with `count(``)` on the `stabr` column    We’re now asking for the values in the `stabr` column and a count of how many rows have a given `stabr` value. In the list of columns to query 1, we specify `stabr` and `count()` with an asterisk as its input, which will cause `count()` to include `NULL` values. Also, when we select individual columns along with an aggregate function, we must include the columns in a `GROUP BY` clause 2. If we don’t, the database will return an error telling us to do so, because you can’t group values by aggregating and have ungrouped column values in the same query.    To sort the results and have the state with the largest number of agencies at the top, we can use an `ORDER BY` clause 3 that includes the `count()` function and the `DESC` keyword.    Run the code in [Listing 9-9](#listing9-9). The results show New York, Illinois, and Texas as the states with the greatest number of library agencies in 2018:    ``` stabr    count  -----    -----  NY         756  IL         623  TX         560  IA         544  PA         451  MI         398  WI         381  MA         369  `--snip--` ```    Remember that our table represents library agencies that serve a locality. Just because New York, Illinois, and Texas have the greatest number of library agencies doesn’t mean they have the greatest number of outlets where you can walk in and peruse the shelves. An agency might have one central library only, or it might have no central libraries but 23 branches spread around a county. To count outlets, each row in the table also has values in the columns `centlib` and `branlib`, which record the number of central and branch libraries, respectively. To find totals, we would use the `sum()` aggregate function on both columns.    #### Using GROUP BY on Multiple Columns with count()    We can glean yet more information from our data by combining `GROUP BY` with `count()` and multiple columns. For example, the `stataddr` column in all three tables contains a code indicating whether the agency’s address changed in the last year. The values in `stataddr` are as follows:    1.  00 No change from last year 2.  07 Moved to a new location 3.  15 Minor address change    [Listing 9-10](#listing9-10) shows the code for counting the number of agencies in each state that moved, had a minor address change, or had no change using `GROUP BY` with `stabr` and `stataddr` and adding `count()`.    ``` 1 SELECT stabr, stataddr, count(*)  FROM pls_fy2018_libraries  2 GROUP BY stabr, stataddr  3 ORDER BY stabr, stataddr; ```    Listing 9-10: Using `GROUP BY` with `count(``)` of the `stabr` and `stataddr` columns    The key sections of the query are the column names and the `count()` function after `SELECT` 1, and making sure both columns are reflected in the `GROUP BY` clause 2 to ensure that `count()` will show the number of unique combinations of `stabr` and `stataddr`.    To make the output easier to read, let’s sort first by the state and address status codes in ascending order 3. Here are the results:    ``` stabr    stataddr    count  -----    --------    -----  AK       00          82  AL       00         220  AL       07           3  AL       15           1  AR       00          58  AR       07           1  AR       15           1  AS       00           1  `--snip--` ```    The first few rows show that code `00` (no change in address) is the most common value for each state. We’d expect that because it’s likely there are more library agencies that haven’t changed address than those that have. The result helps assure us that we’re analyzing the data in a sound way. If code `07` (moved to a new location) was the most frequent in each state, that would raise a question about whether we’ve written the query correctly or whether there’s an issue with the data.    #### Revisiting sum() to Examine Library Activity    Now let’s expand our techniques to include grouping and aggregating across joined tables using the 2018, 2017, and 2016 libraries data. Our goal is to identify trends in library visits spanning that three-year period. To do this, we need to calculate totals using the `sum()` aggregate function.    Before we dig into these queries, let’s address the values `-3` and `-1`, which indicate “not applicable” and “nonresponse.” To prevent these negative numbers from affecting the analysis, we’ll filter them out using a `WHERE` clause to limit the queries to rows where values in `visits` are zero or greater.    Let’s start by calculating the sum of annual visits to libraries from the individual tables. Run each `SELECT` statement in [Listing 9-11](#listing9-11) separately.    ``` SELECT sum(visits) AS visits_2018  FROM pls_fy2018_libraries  WHERE visits >= 0;    SELECT sum(visits) AS visits_2017  FROM pls_fy2017_libraries  WHERE visits >= 0;    SELECT sum(visits) AS visits_2016  FROM pls_fy2016_libraries  WHERE visits >= 0; ```    Listing 9-11: Using the `sum(``)` aggregate function to total visits to libraries in 2016, 2017, and 2018    For 2018, visits totaled approximately 1.29 billion:    ``` visits_2018  -----------   1292348697 ```    For 2017, visits totaled approximately 1.32 billion:    ``` visits_2017  -----------   1319803999 ```    And for 2016, visits totaled approximately 1.36 billion:    ``` visits_2016  -----------   1355648987 ```    We’re onto something here, but it may not be good news for libraries. The trend seems to point downward with visits dropping about 5 percent from 2016 to 2018.    Let’s refine this approach. These queries sum visits recorded in each table. But from the row counts we ran earlier in the chapter, we know that each table contains a different number of library agencies: 9,261 in 2018; 9,245 in 2017; and 9,252 in 2016\\. The differences are likely due to agencies opening, closing, or merging. So, let’s determine how the sum of visits will differ if we limit the analysis to library agencies that exist in all three tables and have a non-negative value for `visits`. We can do that by joining the tables, as shown in [Listing 9-12](#listing9-12).    ``` 1 SELECT sum(pls18.visits) AS visits_2018,         sum(pls17.visits) AS visits_2017,         sum(pls16.visits) AS visits_2016  2 FROM pls_fy2018_libraries pls18         JOIN pls_fy2017_libraries pls17 ON pls18.fscskey = pls17.fscskey         JOIN pls_fy2016_libraries pls16 ON pls18.fscskey = pls16.fscskey  3 WHERE pls18.visits >= 0         AND pls17.visits >= 0         AND pls16.visits >= 0; ```    Listing 9-12: Using `sum(``)` to total visits on joined 2018, 2017, and 2016 tables    This query pulls together a few concepts we covered in earlier chapters, including table joins. At the top, we use the `sum()` aggregate function 1 to total the `visits` columns from each of the three tables. When we join the tables on the tables’ primary keys, we’re declaring table aliases 2 as we explored in Chapter 7—and here, we’re omitting the optional `AS` keyword in front of each alias. For example, we declare `pls18` as the alias for the 2018 table to avoid having to write its lengthier full name throughout the query.    Note that we use a standard `JOIN`, also known as an `INNER JOIN`, meaning the query results will only include rows where the values in the `fscskey` primary key match in all three tables.    As we did in [Listing 9-11](#listing9-11), we specify with a `WHERE` clause 3 that the result should include only those rows where `visits` are greater than or equal to 0 in the tables. This will prevent the artificial negative values from impacting the sums.    Run the query. The results should look like this:    ``` visits_2018   visits_2017   visits_2016  -----------   -----------   -----------   1278148838    1319325387    1355078384 ```    The results are similar to what we found by querying the tables separately, although these totals are as much as 14 million smaller in 2018\\. Still, the downward trend holds.    For a full picture of how library use is changing, we’d want to run a similar query on all of the columns that contain performance indicators to chronicle the trend in each. For example, the column `wifisess` shows how many times users connected to the library’s wireless internet. If we use `wifisess` instead of `visits` in [Listing 9-11](#listing9-11), we get this result:    ``` wifi_2018  wifi_2017  wifi_2016  ---------  ---------  ---------  349767271  311336231  234926102 ```    So, though visits were down, libraries saw a sharp increase in Wi-Fi network use. That provides a keen insight into how the role of libraries is changing.    #### Grouping Visit Sums by State    Now that we know library visits dropped for the United States as a whole between 2016 and 2018, you might ask yourself, “Did every part of the country see a decrease, or did the degree of the trend vary by region?” We can answer this question by modifying our preceding query to group by the state code. Let’s also use a percent-change calculation to compare the trend by state. [Listing 9-13](#listing9-13) contains the full code.    ``` 1 SELECT pls18.stabr,         sum(pls18.visits) AS visits_2018,         sum(pls17.visits) AS visits_2017,         sum(pls16.visits) AS visits_2016,         round( (sum(pls18.visits::numeric) - sum(pls17.visits)) /              2 sum(pls17.visits) * 100, 1 ) AS chg_2018_17,         round( (sum(pls17.visits::numeric) - sum(pls16.visits)) /              sum(pls16.visits) * 100, 1 ) AS chg_2017_16  FROM pls_fy2018_libraries pls18         JOIN pls_fy2017_libraries pls17 ON pls18.fscskey = pls17.fscskey         JOIN pls_fy2016_libraries pls16 ON pls18.fscskey = pls16.fscskey  WHERE pls18.visits >= 0         AND pls17.visits >= 0         AND pls16.visits >= 0  3 GROUP BY pls18.stabr  4 ORDER BY chg_2018_17 DESC; ```    Listing 9-13: Using `GROUP BY` to track percent change in library visits by state    We follow the `SELECT` keyword with the `stabr` column 1 from the 2018 table; that same column appears in the `GROUP BY` clause 3. It doesn’t matter which table’s `stabr` column we use because we’re only querying agencies that appear in all three tables. After the `visits` columns, we include the now-familiar percent-change calculation you learned in Chapter 6. We use this twice, giving the aliases `chg_2018_17` 2 and `chg_2017_16` for clarity. We end the query with an `ORDER BY` clause 4, sorting by the `chg_2018_17` column alias.    When you run the query, the top of the results shows 10 states with an increase in visits from 2017 to 2018\\. The rest of the results show a decline. American Samoa, at the bottom of the ranking, had a 28 percent drop!    ``` stabr visits_2018 visits_2017 visits_2016 chg_2018_17 chg_2017_16  ----- ----------- ----------- ----------- ----------- -----------  SD        3824804     3699212     3722376         3.4        -0.6  MT        4332900     4215484     4298268         2.8        -1.9  FL       68423689    66697122    70991029         2.6        -6.0  ND        2216377     2162189     2201730         2.5        -1.8  ID        8179077     8029503     8597955         1.9        -6.6  DC        3632539     3593201     3930763         1.1        -8.6  ME        6746380     6731768     6811441         0.2        -1.2  NH        7045010     7028800     7236567         0.2        -2.9  UT       15326963    15295494    16096911         0.2        -5.0  DE        4122181     4117904     4125899         0.1        -0.2  OK       13399265    13491194    13112511        -0.7         2.9  WY        3338772     3367413     3536788        -0.9        -4.8  MA       39926583    40453003    40427356        -1.3         0.1  WA       37338635    37916034    38634499        -1.5        -1.9  MN       22952388    23326303    24033731        -1.6        -2.9  `--snip--`  GA       26835701    28816233    27987249        -6.9         3.0  AR        9551686    10358181    10596035        -7.8        -2.2  GU          75119       81572       71813        -7.9        13.6  MS        7602710     8581994     8915406       -11.4        -3.7  HI        3456131     4135229     4490320       -16.4        -7.9  AS          48828       67848       63166       -28.0         7.4 ```    It’s helpful, for context, to also see the percent change in `visits` from 2016 to 2017\\. Many of the states, such as Minnesota, show consecutive declines. Others, including several at the top of the list, show gains after substantial decreases the year prior.    This is when it’s a good idea investigate what’s driving the changes. Data analysis can sometimes raise as many questions as it answers, but that’s part of the process. It’s always worth a phone call to a person who works closely with the data to review your findings. Sometimes, they’ll have a good explanation. Other times, an expert will say, “That doesn’t sound right.” That answer might send you back to the keeper of the data or the documentation to find out if you overlooked a code or a nuance with the data.    #### Filtering an Aggregate Query Using HAVING    To refine our analysis, we can examine a subset of states and territories that share similar characteristics. With percent change in visits, it makes sense to separate large states from small states. In a small state like Rhode Island, a single library closing for six months for repairs could have a significant effect. A single closure in California might be scarcely noticed in a statewide count. To look at states with a similar volume in visits, we could sort the results by either of the `visits` columns, but it would be cleaner to get a smaller result set by filtering our query.    To filter the results of aggregate functions, we need to use the `HAVING` clause that’s part of standard ANSI SQL. You’re already familiar with using `WHERE` for filtering, but aggregate functions, such as `sum()`, can’t be used within a `WHERE` clause because they operate at the row level, and aggregate functions work across rows. The `HAVING` clause places conditions on groups created by aggregating. The code in [Listing 9-14](#listing9-14) modifies the query in [Listing 9-13](#listing9-13) by inserting the `HAVING` clause after `GROUP BY`.    ``` SELECT pls18.stabr,         sum(pls18.visits) AS visits_2018,         sum(pls17.visits) AS visits_2017,         sum(pls16.visits) AS visits_2016,         round( (sum(pls18.visits::numeric) - sum(pls17.visits)) /   sum(pls17.visits) * 100, 1 ) AS chg_2018_17,         round( (sum(pls17.visits::numeric) - sum(pls16.visits)) /              sum(pls16.visits) * 100, 1 ) AS chg_2017_16  FROM pls_fy2018_libraries pls18         JOIN pls_fy2017_libraries pls17 ON pls18.fscskey = pls17.fscskey         JOIN pls_fy2016_libraries pls16 ON pls18.fscskey = pls16.fscskey  WHERE pls18.visits >= 0         AND pls17.visits >= 0         AND pls16.visits >= 0  GROUP BY pls18.stabr  1 HAVING sum(pls18.visits) > 50000000  ORDER BY chg_2018_17 DESC; ```    Listing 9-14: Using a `HAVING` clause to filter the results of an aggregate query    In this case, we’ve set our query results to include only rows with a sum of visits in 2018 greater than 50 million. That’s an arbitrary value I chose to show only the very largest states. Adding the `HAVING` clause 1 reduces the number of rows in the output to just six. In practice, you might experiment with various values. Here are the results:    ``` stabr visits_2018 visits_2017 visits_2016 chg_2018_17 chg_2017_16  ----- ----------- ----------- ----------- ----------- -----------  FL       68423689    66697122    70991029         2.6        -6.0  NY       97921323   100012193   103081304        -2.1        -3.0  CA      146656984   151056672   155613529        -2.9        -2.9  IL       63466887    66166082    67336230        -4.1        -1.7  OH       68176967    71895854    74119719        -5.2        -3.0  TX       66168387    70514138    70975901        -6.2        -0.7 ```    All but one of the six states experienced a decline in visits, but notice that the percent-change variation isn’t as wide as in the full set of states and territories. Depending on what we learn from library experts, looking at the states with the most activity as a group might be helpful in describing trends, as would looking at other groupings. Think of a sentence you might write that would say, “Among states with the most library visits, Florida was the only one to see an increase in activity between 2017 and 2018; the rest saw visits decrease between 2 percent and 6 percent.” You could write similar sentences about medium-sized states and small states.    ## Wrapping Up    If you’re now inspired to visit your local library and check out a couple of books, ask a librarian whether their branch has seen a rise or drop in visits over the last few years. You can probably guess the answer. In this chapter, you learned how to use standard SQL techniques to summarize data in a table by grouping values and using a handful of aggregate functions. By joining datasets, you were able to identify some interesting trends.    You also learned that data doesn’t always come perfectly packaged. The presence of negative values in columns, used as an indicator rather than as an actual numeric value, forced us to filter out those rows. Unfortunately, those sorts of challenges are part of the data analyst’s everyday world, so we’ll spend the next chapter learning how to clean up a dataset that has a number of issues. Later in the book, you’ll also discover more aggregate functions to help you find the stories in your data. ````"]