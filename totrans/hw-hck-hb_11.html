<html><head></head><body>
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="323" id="Page_323"/>11</span><br/>
<span class="ChapterTitle">Gettin’ Nerdy with It: Advanced Power Analysis</span></h1>
</header>
<figure class="opener">
<img src="image_fi/book_art/chapterart.png" alt=""/>
</figure>
<p class="ChapterIntro">The previous two chapters, and power analysis literature in general, focused on theoretical understanding of the attacks and applying them in lab conditions. As people who have witnessed a plethora of such attacks, we can tell you that for the majority of actual targets, 10 percent of your time is spent getting the measurement set up in order; 10 percent of your time is running actual power analysis attacks, and the other 80 percent of your time is spent trying to figure out why the attacks are not showing any leakage. That is because your attack will show leakage only if you got every step from trace acquisition to trace analysis correct, and until you actually find leakage, it can be difficult to determine which step was wrong in the first place. In reality, power analysis requires patience, sprinkled with a lot of step analysis, a bunch of trial and error, and topped off with computing power. This chapter is more about the <em>art</em> of power analysis than the science.</p>
<p><span epub:type="pagebreak" title="324" id="Page_324"/>In practice, you’ll need some extra tools to overcome the various obstacles that a real-life target will throw at you. These obstacles will largely determine how difficult it will be to extract a secret from a device successfully. Some properties inherent in the target you’re testing will affect the signal and noise characteristics, as will properties like programmability, device complexity and clock speed, type of side channel, and countermeasures. When measuring a software implementation of AES on a microcontroller, you’ll probably be able to identify the individual encryption rounds from a single trace with one eye closed and a hand behind your back. When you’re measuring a hardware AES running at 800 MHz embedded in a full System-on-Chip (SoC), forget about ever seeing the encryption rounds in a single trace. Many parallel processes cause amplitude noise—never mind that the leakage signal is extremely small. The simplest AES implementations may break in less than 100 traces and 5 minutes of analysis, whereas the most complex attacks we’ve seen succeed have passed beyond a billion(!) traces and months of analysis—and, sometimes the attack still fails.</p>
<p>In the next sections, we’ll provide tools to apply in various situations and a general recipe for how to approach the entire power analysis topic. Equipped with these tools, it’s up to you to find out if, when, and how to apply them on your favorite target. As such, this chapter is a bit of a mixed bag. First, we discuss a number of more powerful attacks and provide references. Next, we dive into a number of ways to measure key extraction success and how to measure improvements in your setup. Then, we talk about measuring real devices, as opposed to some easy lab-based, full-control targets. After that, there is a section on trace analysis and processing, and, finally, we provide some additional references.</p>
<h2 id="h1-278748c11-0001">The Main Obstacles</h2>
<p class="BodyFirst">Power analysis comes in various flavors. We’ll refer to <em>simple power analysis (SPA)</em>, <em>differential power analysis (DPA)</em>, and the <em>correlation power attack (CPA)</em> in this chapter, or simply to <em>power analysis</em> when a statement applies to all three.</p>
<p>The differences between theory and attacking actual devices are significant. You’ll meet your main obstacles when doing actual power analysis. These obstacles include the following:</p>
<p class="ListHead"><b>Amplitude noise</b></p>
<p class="ListBody">This is the hiss you hear when listening to AM radio transmissions, the noise from all the other electrical components in your setup, or the random noise added as a countermeasure. Various parts of your measurement setup will cause it, but non-interesting-yet-parallel operations in the actual device will also end up in your measurement. You’ll encounter amplitude noise in all measurements you take, and it’s a problem to your power attack because it obscures the actual power variations due to data leakage. For CPA, it causes your correlation peak to decrease in amplitude.</p>
<p class="ListHead"><b><span epub:type="pagebreak" title="325" id="Page_325"/>Temporal noise (also known as misalignment)</b></p>
<p class="ListBody">Timing jitter caused by oscilloscope triggering or nonconstant time paths to your target operation result in the operation of interest appearing at different times with each trace. This jitter affects a correlation power attack because the attack assumes that the leakage always appears at the same time index. The jitter has the undesired effect of widening your correlation peak and decreasing its amplitude.</p>
<p class="ListHead"><b>Side-channel countermeasures</b></p>
<p class="ListBody">Yes, chip and device vendors also read this book. The unintentional noise sources just described can also be introduced by device designers intentionally to decrease the effectiveness of a power attack. Not only are noise sources introduced, but the leakage signals are decreased by using algorithms and chip designs such as masking and blinding (see Thomas S. Messerges’s “Securing the AES Finalists Against Power Analysis Attacks”), constant key rotation in a protocol (see Pankaj Rohatgi’s “Leakage Resistant Encryption and Decryption”), as well as constant power circuits (see Thomas Popp and Stefan Mangard’s “Masked Dual-Rail Pre-charge Logic: DPA-Resistance Without Routing Constraints”) and SCA-resistant cell libraries (see Kris Tiri and Ingrid Verbauwhede’s “A Logic Level Design Methodology for a Secure DPA Resistant ASIC or FPGA Implementation”).</p>
<p>Don’t despair, though. For each source of noise or countermeasure, a tool exists to recover at least some fraction of the leakage. As an attacker, your goal is to combine all these tools into a successful attack; as a defender, your goal is to present sufficient countermeasures that cause your attacker to run out of resources like skill, time, patience, computing power, and disk space.</p>
<h3 id="h2-278748c11-0001">More Powerful Attacks</h3>
<p class="BodyFirst">What we’ve described so far about power analysis are actually some of the more basic attacks in the field. A variety of more powerful attacks exist, and many are well beyond the scope of this chapter. Nevertheless, we don’t want to leave you on the wrong side of the Dunning-Kruger curve of actual knowledge versus perceived knowledge. We want to make sure you have sufficient knowledge to know that you don’t have all the knowledge.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">NOTE</span></h2>
<p>	The Dunning-Kruger effect is what happens when you first learn about a subject and think to yourself, “This isn’t too hard.” David Dunning briefly summarized this effect as follows: “If you’re incompetent, you can’t know you’re incompetent. [. . .] the skills you need to produce a right answer are exactly the skills you need to recognize what a right answer is.”</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Everything you have learned up to now has used a <em>leakage model</em>. This model made some basic assumptions—for example, that greater power being drawn can mean that more wires are set high. A more powerful <span epub:type="pagebreak" title="326" id="Page_326"/>method is the template attack (see Suresh Chari, Josyula R. Rao, and Pankaj Rohatgi’s “Template Attacks”). In a <em>template attack</em>, instead of assuming a leakage model, you measure it directly from a device for which you know the data (and key!) being processed. The knowledge of the data and key provides you with an indication of the power used for a range of known data values, which is encoded in a template for each value. A template of known data values helps you recognize the unknown data values on the same or similar device.</p>
<p>Making such a template model means you need a device you can completely control by setting your own key values and allowing the desired encryption to occur. The practicability of this approach varies because it may be difficult to reprogram your target device, or you may have only a single copy of the target that you can’t reprogram to generate templates. Other times, like with generic microcontrollers, you could access as many programmable devices as you need.</p>
<p>The advantage of template attacks is that they operate on a more precise model than CPA and, therefore, can perform key retrieval in fewer traces, possibly revealing an entire encryption key with just a <em>single encryption operation</em>. Another advantage is that if the device you’re attacking is performing some nonstandard algorithm, a template attack doesn’t require you to have a model for the leakage. The downside of these more powerful attacks is the computational complexity and memory requirements, which are greater than a simple correlation with a Hamming weight. Therefore, choosing whether to use templates or other techniques, such as <em>linear regression</em> (see Julien Doget, Emmanuel Prouff, Matthieu Rivain, and François-Xavier Standaert’s “Univariate Side Channel Attacks and Leakage Modeling”), <em>mutual information analysis</em> (see Benedikt Gierlichs, Lejla Batina, Pim Tuyls, and Bart Preneel’s “Mutual Information Analysis”), <em>deep learning</em> (see Guilherme Perin, Baris Ege, and Jasper van Woudenberg’s, “Lowering the Bar: Deep Learning for Side-Channel Analysis”), or <em>differential cluster analysis</em> (see Lejla Batina, Benedikt Gierlichs, and Kerstin Lemke-Rust’s “Differential Cluster Analysis”), depends on what is required or available in your attack circumstances, such as having the least number of traces, the shortest wall clock time, the least computational complexity, lesser human analysis, and any number of other circumstances. </p>
<p>In terms of more practical tips, Victor Lomné, Emmanuel Prouff, and Thomas Roche wrote “Behind the Scene of Side Channel Attacks — Extended Version,” which contains many tips on various attacks. Specifically, <em>conditional leakage averaging</em> for CPA can save a lot of time. You can find an implementation of it and various other algorithms as part of Riscure’s open source Jlsca project at <a href="https://github.com/Riscure/Jlsca/" class="LinkURL">https://github.com/Riscure/Jlsca/</a>.</p>
<p>At the end of this chapter, we’ll discuss further references.</p>
<h2 id="h1-278748c11-0002">Measuring Success</h2>
<p class="BodyFirst">How we measure success in life is a topic prone to philosophical ramblings. Fortunately, engineers and scientists have little time for ramblings, so <span epub:type="pagebreak" title="327" id="Page_327"/>here are a variety of methods that allow us to measure the success of side-channel analysis attacks. We’ll discuss several data types and graphs you are likely to run into during your further research.</p>
<h3 id="h2-278748c11-0002">Success Rate–Based Metrics</h3>
<p class="BodyFirst">One of the original metrics used in academia was based on the success rate of the attack. The most basic version of it might be to test how many traces are required for an attack that <em>completely recovers the encryption key</em>. This metric generally isn’t too useful. If you’re just doing a single trial, it might be that you got exceptionally lucky; usually it would take more traces than what you have reported.</p>
<p>To counter this unrealistic situation, we use plots of the success rate versus number of traces. We will first refer to the <em>global success rate (GSR)</em>, which provides the percentage of attacks that successfully recovered the complete key for a particular number of traces. <a href="#figure11-1" id="figureanchor11-1">Figure 11-1</a> shows a sample GSR graph.</p>
<figure>
<img src="image_fi/278748c11/f11001.png" alt="f11001"/>
<figcaption><p><a id="figure11-1">Figure 11-1</a>: Sample graph of global success rate for a leaky AES-256 target</p></figcaption>
</figure>
<p>The graph in <a href="#figure11-1">Figure 11-1</a> shows that if we had 40 traces recorded from the device, we would expect to recover the complete encryption key about 80 percent of the time. We can find this metric simply by performing the experiment on the device many times, ideally with different encryption keys in case certain values of the key generate more leakage than other keys do.</p>
<p>Rather than using the GSR, we might also plot the <em>partial success rate</em>. Here, <em>partial</em> means that we are considering each of the 16 bytes in the AES-128 key independently of the other bytes, which provides 16 values, each representing the probability of recovering the correct value for one particular byte, given a fixed number of traces.</p>
<p><span epub:type="pagebreak" title="328" id="Page_328"/>The global success rate could be misleading because in some particular implementations, one of the key bytes might not leak. The GSR, thus, will always be zero, since the entire encryption key is never recovered, but plots of the partial success rate will reveal whether only one of the 16 bytes cannot be recovered. We could then brute-force that last byte within 1 second, whereas a zero GSR would not have revealed a real probability of recovering the key.</p>
<h3 id="h2-278748c11-0003">Entropy-Based Metrics</h3>
<p class="BodyFirst">Entropy-based metrics are based on the principle that we can do some guessing to recover the key. The original AES-128 key would require, on average, 0.5 × 2<sup>128</sup> guesses to recover the key without any prior knowledge. This number is so large, the key cannot be computed before the cluster brute-forcing the key will be melted and/or eaten by the sun as it transforms into a red giant (about 5 billion years from now).</p>
<p>The outcome of a side-channel analysis attack provides more information than a simple “key is XYZ” or “key not found.” In fact, each key guess has a confidence level associated with it—the confidence that a key guess is correct relative to a particular analysis method. In CPA, this confidence value is the absolute value of the correlation of that particular key guess. The outcome of a CPA attack on one byte of an AES-128 key is therefore a ranked list of key guesses with confidence levels, with our best guess at the top and worst guess at the bottom.</p>
<p>Let’s say that using a power analysis attack, we know the actual key byte is in the top three of each list. Then there are in total 3<sup>16</sup> guesses to make for the key, which is about 43 million, so it can easily be done on a smartphone. We have, thus, reduced the entropy. The original key was a random collection of bits, but we now have some information about the most likely state of certain bits and can use this to speed up the brute-force attack.</p>
<p>The easiest plot to represent this is the <em>partial guessing entropy (PGE)</em>. The PGE asks the following question: after you performed the attack with a certain number of traces, how many key guesses were incorrectly ranked as more likely than the correct key value? If you are doing key guesses for each byte, you will have a PGE value for each byte of the key; for AES-128, you will end up with 16 PGE plots. PGE provides information about the reduction in key-search space being made by the side-channel attack. <a href="#figure11-2" id="figureanchor11-2">Figure 11-2</a> shows an example of such a plot.</p>
<p>The graph in <a href="#figure11-2">Figure 11-2</a> also averages all the 16 PGE plots to get an average PGE for the attack. The partial guessing entropy can be a little misleading, as we might not have an ideal way to combine guessing across all keys. For instance, if for one key byte the correct value is ranked first, and for a second key byte ranked third, we still need to take a worst-case assumption and brute-force all top three candidates. Such a brute-force attack very quickly becomes impossible, however, if the PGE is not even across all bytes.</p>
<span epub:type="pagebreak" title="329" id="Page_329"/><figure>
<img src="image_fi/278748c11/f11002.png" alt="f11002"/>
<figcaption><p><a id="figure11-2">Figure 11-2</a>: Partial guessing entropy</p></figcaption>
</figure>
<p>Algorithms for ideally combining the output of the attack exist, and they can be used to generate a true total guessing entropy (see Nicholas Veyrat-Charvillon, Benoît Gérard, François-Xavier Standaert’s “Security Evaluations Beyond Computing Power”). The total guessing entropy provides exact details of the reduction of the guessing space of the key that resulted from running the attack algorithm.</p>
<h3 id="h2-278748c11-0004">Correlation Peak Progression</h3>
<p class="BodyFirst">Another format is to plot the correlation of each key guess over a number of traces. This method is designed to show the progression of the amplitude of correlation peaks over time; see <a href="#figure11-3" id="figureanchor11-3">Figure 11-3</a> as an example. It shows for each key guess what the correlation peak is when we increase the number of traces. For wrong key guesses, this correlation will trend toward zero, whereas for the right key guess, it will trend toward the actual level of leakage.</p>
<span epub:type="pagebreak" title="330" id="Page_330"/><figure>
<img src="image_fi/278748c11/f11003.png" alt="f11003"/>
<figcaption><p><a id="figure11-3">Figure 11-3</a>: Plots of correlation peak vs. trace number show the correct guess.</p></figcaption>
</figure>
<p>This graph removes information about at which point in time the maximum correlation peak occurred, but it now shows how that peak becomes differentiated from the “wrong guesses.” The point where the correct peak crosses over all the incorrect guesses is considered to be where the algorithm was broken. Plots of correlation output against the trace number show the correct key guess slowly evolving out of the noise of incorrect key guesses.</p>
<p>An advantage of the graph shown in <a href="#figure11-3">Figure 11-3</a> is that it indicates the margin between the incorrect and the correct guess. If that margin is large, you can be more confident that the attack will be successful in general.</p>
<h3 id="h2-278748c11-0005">Correlation Peak Height</h3>
<p class="BodyFirst">The success metrics described so far provide an idea of how close you are to key extraction, but they do not help much in debugging your setup or trace-processing approach. For those tasks, there is one simple approach: looking at the output traces from the attack algorithm, such as correlation traces for CPA (or t-traces for TVLA, which we discuss later). These output traces are one of the main ways to improve your setup or processing.</p>
<p>The plot you make, such as in <a href="#figure11-4" id="figureanchor11-4">Figure 11-4</a>, highlights all the correlation traces of incorrect key guesses in one color and the correct key guess in another color.</p>
<span epub:type="pagebreak" title="331" id="Page_331"/><figure>
<img src="image_fi/278748c11/f11004.png" alt="f11004"/>
<figcaption><p><a id="figure11-4">Figure 11-4</a>: Plot of the raw output from the attack algorithm</p></figcaption>
</figure>
<p><a href="#figure11-4">Figure 11-4</a> shows that the correct key guess has the largest correlation peak, and it also provides the time index of this peak. This plot shows correlation as a function of time, where the correct key guess is highlighted in dark gray in the figure, and the incorrect guesses are light gray. Overlaying this plot with power traces can be useful for visualizing where the leakage happens.</p>
<p>This type of plotting comes in very handy when you are optimizing your setup. Simply calculate the plot before and after you change one of your acquisition parameters or processing steps. If the peak gets stronger, you’ve improved your side-channel attack; if it decreases, it has gotten worse.</p>
<h2 id="h1-278748c11-0003">Measurements on Real Devices</h2>
<p class="BodyFirst">When the time comes to measure a real device—not a simple experimental platform designed for side-channel analysis—you need to make some additional considerations. This section briefly outlines them.</p>
<h3 id="h2-278748c11-0006">Device Operation</h3>
<p class="BodyFirst">The first step in attacking a real device is operating it. The requirements for doing so depend on the attack you are performing, but we can give you some general guidance and hints on running crypto operations and choosing what inputs to send.</p>
<h4 id="h3-278748c11-0001"><span epub:type="pagebreak" title="332" id="Page_332"/>Initiating Encryption</h4>
<p class="BodyFirst">Real devices may not provide an “encrypt this block” function. Part of the work in side-channel analysis attacks is to determine exactly how to attack such devices. For example, if we’re attacking a bootloader that authenticates firmware before decrypting it, we cannot just send random input data to decrypt. However, for power analysis, often just knowing the ciphertext or the plaintext is sufficient. In this case, we can just feed the original firmware image, which will pass the authenticity check and will then be decrypted. Since we know the ciphertext of the firmware, we can still perform a power attack.</p>
<p>Similarly, many devices will have a challenge-response-based authentication function. These functions typically require you to respond to a random nonce value by encrypting it. The device will separately also encrypt the nonce. Now the device can verify whether the response from you was encrypted properly, thereby proving you share the same key as the device. If you send the device a random garbage value, the authentication check will ultimately fail. However, that failure is irrelevant; we have captured the nonce and the power signal of the device during encryption. If we collect a set of those signals, it could give us sufficient information for a power analysis attack. Proper implementations will include rate limiting or a fixed number of tries to avoid this attack.</p>
<p>Another problem when dealing with device communication will be timing the acquisition. As demonstrated previously, we don’t care about finding the exact moment the encryption happened, as the CPA attack will reveal this for us (assuming alignment, but we’ll talk about that later). We do need to get within the general vicinity of the correct timing (for example, by triggering our oscilloscope based on when we send the last packet of an encrypted block). We don’t know when the encryption occurs, but we do know that it clearly must occur sometime between sending that block and the device sending back a response message.</p>
<p>Triggering based on sniffing I/O lines will be more difficult. Often the easiest way is to implement a custom device that monitors the I/O lines for the relevant activity. You could program a microcontroller simply to read all data being sent and set an I/O pin high when it detects the desired byte(s), which in turn triggers the oscilloscope.</p>
<p>Starting and capturing the operation is mostly an engineering hurdle, but it’s important to make it as stable and jitter-free as possible. Jittery timing behavior results in timing noise and other issues down the line, which may make it impossible to do proper analysis of the traces later.</p>
<h4 id="h3-278748c11-0002">Repeating and Separating Operations</h4>
<p class="BodyFirst">Another trick to remember is that if you have programmatic control over your target, it helps to get many operations in a single trace. You can do this by making the number of times that the target operation is called within one trace an input variable in your protocol. The simplest trick is to put a loop around the call to the operation on the target itself. In some cases, you <span epub:type="pagebreak" title="333" id="Page_333"/>can have it loop at a lower level by, for instance, giving an AES-ECB encryption engine a large number of blocks to encrypt.</p>
<p>Now, if you perform acquisitions with an increasing number of calls to the target operation (for instance, by doubling it every trace), you’ll soon start to see an expansion where the crypto operations are being performed. This happens because although a single crypto operation may be an invisible blip, the more operations you do, the longer they will take. At some point, it becomes visible in your trace. You then can easily pinpoint the timing of the operation and calculate the average duration of a single operation.</p>
<p>It may also be worthwhile to experiment with a variable delay loop (or nop slide; <em>nop</em> means a no-operation, which effectively causes the processor to do nothing for a very specific amount of time) in between the operations. Once the previous trick has shown you the timing, you can use that information to separate the individual operation calls, which can actually help to detect leaks, because the leakage from one operation does not then bleed into successive operations.</p>
<h4 id="h3-278748c11-0003">From Random Inputs to Chosen Inputs</h4>
<p class="BodyFirst">Up to now, we’ve been inputting fully random data into our crypto algorithms, which provides good properties for the CPA calculation. Some specific attacks require chosen inputs, like certain attacks on AES (see Kai Schramm, Gregor Leander, Patrick Felke, and Christof Paar’s “A Collision-Attack on AES: Combining Side Channel- and Differential-Attack”) or for the intermediate round variant of test vector leakage assessment (TVLA) using Welch’s t-test (more details in the “Test Vector Leakage Assessment” section later in this chapter).</p>
<p>Without going into the details of why (we will later), you can create a number of different sets during trace acquisition, such as measurements associated with constant or random input data, and various carefully chosen inputs.</p>
<p>You’ll be doing various statistical analyses on these sets, so it’s crucially important that the only statistically relevant differences between your sets are caused by differences in your input data. In reality, trace acquisition campaigns that run for more than a few hours will have detectable changes in perhaps the average power level (see the “Analysis Techniques” section later in this chapter). If you measure set A at minute 0 and set B at minute 60, your statistics will surely show power differences between those sets. These power differences may appear to be insignificant until you discover that suspected leakage is in fact due to your air conditioning kicking in at minute 59 and cooling the target device, and not due to a leaky target. Whenever you do statistical analysis over several sets, you must make sure there is no accidental correlation with anything but the input data. This means that for each trace you measure, you must randomly select for which set you want to generate input. You also do <em>not</em> even want the target to know for which set you are doing a measurement; all it needs to know is the data on which to operate. If you send the target information regarding the set, it will show up in your traces. If you interleave the sets instead of choose <span epub:type="pagebreak" title="334" id="Page_334"/>them randomly, it will show up in your traces. These uninteresting correlations are extremely hard to debug, as they will show up as (false) leakage, so you should work hard at avoiding them. You are detecting extremely small changes in power, and a switch statement running on the target based on the trace set is going to overshadow any interesting leakage.</p>
<h3 id="h2-278748c11-0007">The Measurement Probe</h3>
<p class="BodyFirst">To perform the side-channel attack, you need to measure your device’s power consumption. Taking this measurement was trivial when attacking a target board you designed, but it requires more creativity on real devices. We’ll discuss the two main methods: using a physical shunt resistor and using an electromagnetic probe.</p>
<h4 id="h3-278748c11-0004">Inserting Shunt Resistors</h4>
<p class="BodyFirst">If attempting to measure power on a “standard” board, you’ll need to make some modifications to the board for the power consumption measurements. This will differ from board to board, but as an example, see <a href="#figure11-5" id="figureanchor11-5">Figure 11-5</a>, which shows how you can lift the leg of a thin quad flat pack (TQFP) package to insert a surface-mount resistor.</p>
<figure>
<img src="image_fi/278748c11/f11005.png" alt="f11005"/>
<figcaption><p><a id="figure11-5">Figure 11-5</a>: Inserting a resistor into the leg of a TQFP package</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="335" id="Page_335"/>You then have to connect your oscilloscope probe to either side of the resistor, which allows you to measure the voltage drop across the resistor and thereby the current consumption of a specific voltage net.</p>
<h4 id="h3-278748c11-0005">Electromagnetic Probes</h4>
<p class="BodyFirst">A more advanced alternative is to use an electromagnetic probe (also called an H-field probe, near-field probe, or magnetic field probe), which can be positioned above or close to the area of interest. The resulting analysis is called <em>electromagnetic analysis (EMA)</em>. EMA requires no modifications to the device under attack, as the probe can just be placed directly over the chip or above the decoupling capacitors around the chip. These probes are sold in sets known as <em>near-field probe sets</em>, and they typically include an amplifier.</p>
<p>The theory on why this works is simple. High-school physics teaches us that a current flowing through a wire creates a magnetic field around the wire. The righthand rule tells us that if we hold the wire such that our thumb is pointing in the direction of the current, the magnetic field lines would circle around the wire in the direction of our fingers. Now, any activity inside the chip is simply switching currents. Instead of measuring the switching current directly, we probe the switching magnetic field around it. This works on the principle that a switching magnetic field induces a current in a wire. We can measure that wire with a scope, which rather indirectly reflects the switching activity in the chip.</p>
<h4 id="h3-278748c11-0006">Rolling Your Own Electromagnetic Probe</h4>
<p class="BodyFirst">As an alternative to buying a probe, you can build a simple probe yourself. Building your own EM probe is fun for the whole family, provided the family likes working with sharp objects, soldering irons, and chemicals. In addition to the probe, you’ll need to build a low-noise amplifier for increasing the strength of the signal your oscilloscope or other device is measuring.</p>
<p>The probe itself is built from a length of semi-flexible coaxial cable. You can purchase this from various sources (Digi-Key, eBay) by looking for “SMA to SMA cables,” such as Crystek Part Number CCSMA-MM-086-8, which is available from Digi-Key for around US$10. Cutting this cable in half gives you two lengths of semi-flexible cable, each with an SMA connector on the one end (one of which is shown in <a href="#figure11-6" id="figureanchor11-6">Figure 11-6</a>).</p>
<figure>
<img src="image_fi/278748c11/f11006.png" alt="f11006"/>
<figcaption><p><a id="figure11-6">Figure 11-6</a>: Home-built EM probes from a semi-flexible SMA cable</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="336" id="Page_336"/>Cut a slot <span class="CodeAnnotation" aria-label="annotation1">1</span> around the entire outer shield. Strip away a few millimeters from the end <span class="CodeAnnotation" aria-label="annotation2">2</span>. Gently round this into a circle <span class="CodeAnnotation" aria-label="annotation3">3</span>, gripping the slot with pliers to stop the internal conductor wire from kinking. To complete the basic probe, solder the circle shut <span class="CodeAnnotation" aria-label="annotation4">4</span>, making sure that the internal conductor wire is included in the solder connection between the outer shields.</p>
<p>Because the outer shield is conductive, you might want to coat the surface with a nonconductive material, such as a rubber coating like Plasti Dip, or wrap it with self-fusing tape.</p>
<p>The signal picked up at the narrow gap in this probe will be tiny, so you’ll need an amplifier to see any signal on your oscilloscope. You can use a simple IC as the basis for a low-noise amplifier. It requires a clean 3.3 V power supply, so consider also building the voltage regulator onto the circuit board. If your oscilloscope isn’t sufficiently sensitive, you might even need to chain two amplifiers together to achieve enough gain. <a href="#figure11-7" id="figureanchor11-7">Figure 11-7</a> shows an example of a simple amplifier built around a $0.50 IC (part number BGA2801,115).</p>
<figure>
<img src="image_fi/278748c11/f11007.png" alt="f11007"/>
<figcaption><p><a id="figure11-7">Figure 11-7</a>: Simple amplifier for an EM probe</p></figcaption>
</figure>
<p>If you want to build the amplifier yourself, see <a href="#figure11-8" id="figureanchor11-8">Figure 11-8</a> for the schematic.</p>
<p>The choice of side-channel measurement can significantly affect the signal and noise characteristics. There is generally low noise when directly measuring power drawn by a chip, as compared to, for instance, the noise in an electromagnetic measurement, or in an acoustic side channel (see Daniel Genkin, Adi Shamir, and Eran Tromer’s “RSA Key Extraction via Low-Bandwidth Acoustic Cryptanalysis”), or in a measurement of the chassis potential (see Daniel Genkin, Itamar Pipman, and Eran Tromer’s “Get <span epub:type="pagebreak" title="337" id="Page_337"/>Your Hands Off My Laptop: Physical Side-Channel Key-Extraction Attacks on PCs”). However, a direct measurement of power means that you measure all of the power consumption, including the power drawn by processes you’re not interested in. On an SoC, you may get a better signal with an EM measurement if your probe is carefully positioned over the physical location of the leakage. You may encounter countermeasures that minimize leakage in direct power measurement but do not limit it in the EM measurement, or vice versa. As a rule of thumb, try EM first on complex chips and SoCs, and try power first on smaller microcontrollers.</p>
<figure>
<img src="image_fi/278748c11/f11008.png" alt="f11008"/>
<figcaption><p><a id="figure11-8">Figure 11-8</a>: Schematic for simple amplifier for an EM probe</p></figcaption>
</figure>
<h3 id="h2-278748c11-0008">Determining Sensitive Nets</h3>
<p class="BodyFirst">Whether using a resistive shunt or an EM probe, we have to determine what part of the device must be measured. The objective is to measure power consumption of the logic circuit performing the sensitive operation—be it a hardware peripheral or the general-purpose core executing a software program.</p>
<p>In the case of the resistive shunt, this means looking at power pins on the IC. Here you need to measure at one of the pins powering the internal cores, not at the pins that power the I/O pin drivers. Small microcontrollers might have a single power supply used for all parts of the microcontroller. Even these simple microcontrollers can have multiple power pins with the same name, so select one that’s most easily accessed. Be sure not to select a supply dedicated to the analog portion, such as the analog-to-digital converter power supply, as that will likely not power the components of interest.</p>
<p>More advanced devices might have four or more power supplies. For example, the memory, CPU, clock generator, and analog section could all be separate supplies. Again, you may need to do some experimentation, but <span epub:type="pagebreak" title="338" id="Page_338"/>almost certainly, the supply you want will be one of the supplies with the word <em>CPU</em> or <em>CORE</em> in the name. You can use the data you dug up with the help of <span class="xref" itemid="xref_target_Chapter 3">Chapter 3</span> to identify the most likely targets.</p>
<p>If targeting a device using an EM probe, you’ll need to experiment to determine the correct orientation and location for the probe. It’s also worth placing the probe near the decoupling capacitors surrounding the target, as high currents will tend to flow through those parts. In this case, you would need to determine which decoupling capacitors are associated with the core components of the device, similar to determining which power supply to target.</p>
<p>Letting your target run encryptions while displaying live trace captures on a screen can be enlightening. As the probe moves, you’ll see the captured traces vary wildly. A good rule of thumb is to find a place where the field is weak before and after the crypto phase and strong while performing the crypto routine. It helps to display a trigger that “hugs” the operation as well. It doesn’t hurt to move the probe around manually to get a quick sense of the leakage over various parts of the chip.</p>
<h3 id="h2-278748c11-0009">Automated Probe Scanning</h3>
<p class="BodyFirst">Mounting the probe on an XY stage and automatically capturing traces over various positions on the chip allows more precise localization of interesting areas. <a href="#figure11-9" id="figureanchor11-9">Figure 11-9</a> shows a sample setup.</p>
<p>You can use TVLA to get another nice visualization, as explained in the “Test Vector Leakage Assessment” section later in this chapter. TVLA measures leakage without doing a CPA attack, so if you visualize the TVLA outcome, you’ll see a plot of actual leakage over the area of the chip. The downside is that in order to calculate TVLA values, you need to have two full measurement sets for each spot on the chip, which increases the length of your trace acquisition campaign dramatically.</p>
<p>Probing more spots increases the chances that you find the <em>right</em> spot, but it decreases your efficiency. Scan at a spatial resolution that gives more continuous data gradients in the visualization to ensure that your XY scan step size is smaller than the sensitive area of your probe.</p>
<p>Scanning is of particular interest when combined with the technique described later in this chapter in the “Filtering for Visualization” section. If you know your target operation’s leakage frequency, you can visualize the signal strength at that frequency as a function of the position over your chip. This leads to pretty pictures such as the one in <a href="#figure11-10" id="figureanchor11-10">Figure 11-10</a>, which shows an XY scan visualization of the leakage intensity over different areas on the chip in the 31-to-34 MHz band. These kinds of images can help localize areas of interest and can be done with as little as one trace per location.</p>
<span epub:type="pagebreak" title="339" id="Page_339"/><figure>
<img src="image_fi/278748c11/f11009.png" alt="f11009"/>
<figcaption><p><a id="figure11-9">Figure 11-9</a>: Example of a Riscure electromagnetic probe mounted on an XY stage</p></figcaption>
</figure>
<figure>
<img src="image_fi/278748c11/f11010.png" alt="f11010"/>
<figcaption><p><a id="figure11-10">Figure 11-10</a>: XY scan visualization of leakage areas from a chip</p></figcaption>
</figure>
<h3 id="h2-278748c11-0010">Oscilloscope Setup</h3>
<p class="BodyFirst">An oscilloscope is an ideal tool for capturing and presenting the leakage signals from a magnetic probe. You’ll have to set up your oscilloscope carefully to get good information. We discussed the various input types available for your oscilloscope in <span class="xref" itemid="xref_target_Chapter 2">Chapter 2</span>, along with the general advice on avoiding the use of probes that will introduce considerable noise on a very small signal. To reduce noise further, some sort of amplification is often required on the input to the oscilloscope for boosting the signal.</p>
<p>You can use a <em>differential amplifier</em> to do this, which amplifies only the <em>difference</em> between the two signal points. Beyond just boosting the signal, the differential amplifier removes noise present on both signal points (called <em>common-mode </em>noise). In real life, this means that noise generated by the power supply will mostly be removed, leaving only the voltage variation that is measured across your measurement resistor.</p>
<p>Oscilloscope manufacturers sell commercial <em>differential probes</em>, but they’re typically extremely expensive. As an alternative, you can simply build a differential amplifier using a commercial operational amplifier (or <em>op-amp</em>). A differential probe can measure power consumption across the resistor to reduce noise contribution. A sample open source design is available as part of the ChipWhisperer project, which uses the Analog Devices AD8129. <a href="#figure11-11" id="figureanchor11-11">Figure 11-11</a> is a photo of this probe in use on a physical device.</p>
<span epub:type="pagebreak" title="340" id="Page_340"/><figure>
<img src="image_fi/278748c11/f11011.png" alt="f11011"/>
<figcaption><p><a id="figure11-11">Figure 11-11</a>: A differential probe in use on a target board</p></figcaption>
</figure>
<p>In <a href="#figure11-11">Figure 11-11</a>, the differential probe has a positive (+) and negative (–) pin. These pins are marked on the lower-right side on the black probe PCB silkscreen. Wires <span class="CodeAnnotation" aria-label="annotation2">2</span> and <span class="CodeAnnotation" aria-label="annotation1">1</span> connect the positive and negative pins, respectively, to two sides of the shunt resistor mounted onto the target PCB. The differential probe is used in this example because the power flowing into the shunt resistor is noisy, and we want to remove this common-mode noise.</p>
<p>The schematic for the differential probe is shown in <a href="#figure11-12" id="figureanchor11-12">Figure 11-12</a>, in case you are curious about the details of its connection.</p>
<figure>
<img src="image_fi/278748c11/f11012.png" alt="f11012"/>
<figcaption><p><a id="figure11-12">Figure 11-12</a>: Differential probe schematic</p></figcaption>
</figure>
<h4 id="h3-278748c11-0007"><span epub:type="pagebreak" title="341" id="Page_341"/>Sampling Rate</h4>
<p class="BodyFirst">So far, we assume you’ve magically been able to read your measurements into the computer. Previous chapters briefly explained that when setting up your oscilloscope, you need to select an appropriate sampling rate. The upper limit on this sampling rate is based on how much you paid for your oscilloscope; if you have enough money, you can buy 100 GS/s (giga-samples per second) or faster devices.</p>
<p>More is not always better. Longer traces mean lots of storage space and much longer processing times. You might want to sample at a very high rate and then <em>downsample</em> (that is, average consecutive samples) when storing your data, which will improve your waveforms considerably. First, downsampling results in a virtual increase in your scope’s quantization resolution. If your scope has an 8-bit ADC running at 100 MHz and you average every two samples, you effectively have a 9-bit scope running at 50 MHz. This is simply because if a sample value of 55 and a sample value of 56 are averaged, they produce 55.5. The inclusion of these “half” values effectively adds 1 bit of resolution. Or, you can average over four consecutive samples to have an effective 10-bit scope at 25 MHz.</p>
<p>Second, sampling fast reduces time jitter in the measurements. A trigger event happens at some point during a sampling period, and the scope will start measuring only at the next sampling period. The fact that the trigger event happens asynchronously to the oscilloscope sampling clock means there is jitter between the trigger event and the next sampling period. This jitter manifests itself as a misalignment in traces.</p>
<p>Consider the situation where the oscilloscope is sampling at a slower rate, like 25 MS/s, meaning that samples are being taken every 40ns. Whenever the trigger event occurs (that is, the start of the encryption), you’ll have some delay until the start of the next sample. This delay would be on average 20ns (half the sample period), since the time base of the oscilloscope is completely independent of the time base on the target device.</p>
<p>If you sample much faster (say, at 1 GS/s), that delay from the trigger to the start of the first sample will be only 0.5ns, or 40 times better! Once you record the data, you can then downsample it to reduce your memory requirements. The resulting waveform will have the same number of points as if you performed the capture at 25 MS/s, but now the jitter is no more than 0.5ns, thus considerably improving the outcome of a side-channel attack (see Colin O’Flynn and Zhizhang Chen’s, “Synchronous Sampling and Clock Recovery of Internal Oscillators for Side Channel Analysis and Fault Injection”).</p>
<p>True downsampling from a <em>digital signal processing (DSP)</em> perspective uses a filter, and any downsampling routines built in to a DSP framework for your language of choice would support this. However, in practice, downsampling by averaging consecutive points, or even only keeping every 40th sample point, tends to maintain exploitable leakage.</p>
<p>Some oscilloscopes can perform this operation for you; some PicoScope devices have a downsample option that’s performed in hardware. Check your oscilloscope’s detailed programming manual to see whether this option exists.</p>
<p><span epub:type="pagebreak" title="342" id="Page_342"/>Finally, you can use hardware that captures synchronously to the device clock. In <span class="xref" itemid="xref_target_Appendix A">Appendix A</span>, we describe the ChipWhisperer hardware that’s designed specifically to perform this task. Some oscilloscopes will have a <em>reference in</em> capability, which usually allows the input of only up to a 10 MHz synchronization reference. This capability is less useful in real life, since it means you would have to feed your device from a 10 MHz clock (the same as the synchronization reference going to the scope) in order to achieve the synchronous sampling capability. </p>
<h2 id="h1-278748c11-0004">Trace Set Analysis and Processing</h2>
<p class="BodyFirst">The assumption so far has been that you record power traces and then perform an analysis algorithm. Realistically, you’ll include an intermediate step: preprocessing the traces, which means performing some action on them <em>before</em> passing them on to the analysis algorithm (such as CPA). All these steps aim to decrease noise, and/or increase the level of the leakage signal. Your measurement setup and CPA scripts at this point should be <em>fire and forget</em>. Trace processing is largely a process of trial-and-error and relies on experimentation to find what works best on your target. In this section, we assume you’ve made a trace set of measurements but haven’t yet started CPA.</p>
<p>Four main preprocessing techniques you might use include <em>normalizing/dropping</em>, <em>resynchronizing</em>, <em>filtering</em>, and <em>compression</em> (see the section “Processing Techniques” later in this chapter). To determine whether your preprocessing step is actually helping you, we’ll first describe some analysis techniques, such as calculating <em>average</em> and <em>standard deviations</em>, <em>filtering</em> (yes, again), <em>spectrum analysis</em>, <em>intermediate correlation</em>, <em>known-key CPA</em>, and <em>TVLA</em> (listed in the typical order you apply them). You won’t necessarily require them all, and when doing analysis on a simple, leaky experimental platform that you fully control, you’ll probably be able to ignore most of them completely. All of these techniques are <em>standard</em> digital signal processing (DSP) tools, applied in a power analysis context. Consult DSP literature for inspiration on more advanced techniques.</p>
<p>The analysis techniques become more valuable as you transition away from an experimental platform and move to real-life measurements made under non-ideal situations. You’ll use a preprocessing technique and then check its result using an analysis technique. If you know the key, you can always check whether your attack improved by using known-key CPA or TVLA. If you don’t know the key, you rinse and repeat until you think you’re ready to do CPA. If it works, hooray; if not, you’ll have to backtrack to each step to figure out whether you should try something else. Unfortunately, it isn’t a hard science, but the analysis techniques described here can give you some starting points.</p>
<h3 id="h2-278748c11-0011">Analysis Techniques</h3>
<p class="BodyFirst">This section describes some standard analysis techniques that provide a measure of how close you are to having a good enough signal for CPA. With CPA, you performed measurements using different input data. Many of the visualizations in the following section should first be performed with the <span epub:type="pagebreak" title="343" id="Page_343"/>same operation and with the same data, and then later you can use different information as you get closer to a CPA attack.</p>
<h4 id="h3-278748c11-0008">Averages and Standard Deviations over a Data Acquisition Campaign (per Trace)</h4>
<p class="BodyFirst">Let’s say you represent each trace as a single point—namely, the average of all samples in that trace. Recall <em>t</em><sub><em>d,j</em></sub> , where <em>j</em> = 0,1,…,<em>T</em> – 1 is the time index in the trace, and <em>d</em> = 0,1,…,<em>D</em> – 1 is the trace number. Your calculation is </p>
<figure class="graphic">
<img src="image_fi/278748c11/e11001.png" alt="e11001"/></figure>
 
<p class="BodyContinued">Plotting all these points shows changes in the average of the traces over time and can help you find anomalies in your trace acquisition campaign; see, for instance, <a href="#figure11-13" id="figureanchor11-13">Figure 11-13</a>.</p>
<figure>
<img src="image_fi/278748c11/f11013.png" alt="f11013"/>
<figcaption><p><a id="figure11-13">Figure 11-13</a>: Average value of all samples per trace, showing traces 58, 437, and 494 to be outliers</p></figcaption>
</figure>
<p>One type of anomaly is a drifting average—for example, due to temperature changes (yes, you will see the air conditioning kick in) or due to a complete outlier caused, perhaps, by a missed trigger. You either want to correct these traces or drop them altogether. (See the “Normalizing Traces” section later in this chapter for details on what to do with this information.) The standard deviation will give you a different perspective on the same acquisition campaign. We recommend calculating them both, as the computational overhead is insignificant.</p>
<h4 id="h3-278748c11-0009">Averages and Standard Deviations over Operations (per Sample)</h4>
<p class="BodyFirst">The other way of calculating an average is per sample: </p>
<figure class="graphic">
<img src="image_fi/278748c11/e11002.png" alt="e11002"/></figure>

<p class="BodyContinued">This average can help provide a clearer view of what the operation you are capturing actually looks like, because it reduces amplitude noise. <a href="#figure11-14" id="figureanchor11-14">Figure 11-14</a> shows a raw trace in the upper graph and a sample-averaged trace in the lower graph.</p>
<p>The sample-averaged trace makes the process steps more obvious. However, its usefulness decreases with increasing temporal noise. A little misalignment is typically not an issue for visualization, as you lose only high-frequency signals, but the more misaligned the traces are, the lower the highest frequencies that you can see will be. A little misalignment can <span epub:type="pagebreak" title="344" id="Page_344"/>be bad for CPA if your leakage is only in the higher frequencies. You can use the average to judge misalignment visually by looking at the higher-frequency content.</p>
<figure>
<img src="image_fi/278748c11/f11014.png" alt="f11014"/>
<figcaption><p><a id="figure11-14">Figure 11-14</a>: Raw trace (top) and sample-averaged trace (bottom)</p></figcaption>
</figure>
<p>Another effective method is to calculate the standard deviation per sample. As a rule of thumb, the lower the standard deviation, the less misalignment you have, as shown in <a href="#figure11-15" id="figureanchor11-15">Figure 11-15</a>. In this example, the time between 300 and 460 samples has low standard deviation, indicating little misalignment.</p>
<p>Perfectly aligned traces with the same operations can still show differences for both the average and standard deviation, which is due to differences in data and therefore an indication of data leakage.</p>
<figure>
<img src="image_fi/278748c11/f11015.png" alt="f11015"/>
<figcaption><p><a id="figure11-15">Figure 11-15</a>: Standard deviation over a trace set</p></figcaption>
</figure>
<h4 id="h3-278748c11-0010">Filtering for Visualization</h4>
<p class="BodyFirst">Frequency filtering can be used as a method for generating visual representations of the trace data. You can aggressively cancel certain frequencies (usually high frequencies) to get a better view of operations being performed, without having to calculate an average over an entire trace set. A simple low-pass filter can be implemented by taking a moving average over samples (see <a href="#figure11-16" id="figureanchor11-16">Figure 11-16</a>). A low-pass filter is a quick way to clean up a visual representation of trace data.</p>
<span epub:type="pagebreak" title="345" id="Page_345"/><figure>
<img src="image_fi/278748c11/f11016.png" alt="f11016"/>
<figcaption><p><a id="figure11-16">Figure 11-16</a>: Raw trace (top) and low-pass filtered race (bottom)</p></figcaption>
</figure>
<p>You can also use more precise and computationally complex filters (see the “Frequency Filtering” section later in this chapter), but doing so may be overkill for visualization purposes. This visualization step is only to provide an idea of what’s going on below the noise; it’s not a preprocessing step, as you’ll likely remove the leakage signal as well. An exception is for some simple power analysis type of attacks: visualization of secret-dependent operations, such as square/multiply in RSA, can break the private key!</p>
<h4 id="h3-278748c11-0011">Spectrum Analysis</h4>
<p class="BodyFirst">What you can’t see in the time domain may be visible in the frequency domain. If you don’t know what the frequency domain means, think about music and sound. If you record music, it captures the time domain information: the air pressure caused by sound waves through time. But when you listen to music, you hear the frequency domain: different pitches of sounds through time.</p>
<p>Two visualizations are typically useful: the <em>average spectrum</em>, which is the “pure” frequency domain without any representation for time, and the <em>average spectrogram</em>, which is a combination of frequency and time information. The spectrum shows the magnitude of each frequency in a single trace and is a one-dimensional signal. It is obtained by calculating the fast Fourier transform (FFT) of a trace. The spectrogram shows the progression over time of all frequencies for a single trace. Because it adds a time dimension, it is a two-dimensional signal. It is calculated by doing an FFT over small chunks of a trace.</p>
<p>The average spectrum and average spectrogram represent the average of these signals over an entire trace set. When we say we look at the average, we mean we first calculate the signal for each individual trace and then average them all per sample.</p>
<p><span epub:type="pagebreak" title="346" id="Page_346"/>The chip spectrum shown in <a href="#figure11-17" id="figureanchor11-17">Figure 11-17</a> has a clock around 35 MHz, which can be seen from the frequency spikes every 35 MHz. There are smaller spikes every 17.5 MHz, indicating that there are repeating processes that take two clock cycles.</p>
<figure>
<img src="image_fi/278748c11/f11017.png" alt="f11017"/>
<figcaption><p><a id="figure11-17">Figure 11-17</a>: Average spectrum over an entire trace set</p></figcaption>
</figure>
<p>You can perform a few interesting analyses. The frequency spikes every 35 MHz are caused by <em>harmonics</em> of a square wave at 35 MHz; in other words, they’re caused by a digital signal that switches on and off at 35 MHz. Would you suggest that this is the clock? Correct. The spectrum can be used to identify one or more clock domains on a system.</p>
<p>This analysis can be particularly useful if your target (crypto) operation is running at a different clock frequency from that of other components. It gets even better when you do a differential analysis of two average spectra. Let’s say you know that some time section of your trace contains the target operation, and the rest of the trace does not. You now independently calculate the average spectrum for each of the two sections, and subtract one from the other; that is, you calculate the difference between these two averages. You’ll get a <em>differential spectrum</em>, showing exactly what frequencies are more (or less) active during the target operation, which can be a great starting point for frequency filtering (see the “Frequency Filtering”<span class="xref" itemid="xref_target_ "> </span>section later in this chapter).</p>
<p>Another way to find the frequency of an operation is to do known-key CPA on the frequency domain of traces. Known-key CPA is explained in the equally named section later in this chapter, but in a nutshell, because you know the key, you can find how close an unknown-key CPA is to recovering a key. To find the frequency of an operation, first transform all traces using FFT, and then perform known-key CPA on the transformed traces. Now you may be able to see at what frequencies the leakage appears. You can do the same trick with TVLA. These methods don’t always work, and you may need (significantly) more traces to get a signal.</p>
<p>The nice thing about spectrum analysis is that it is relatively independent of timing and thus of misalignment, as we are not looking at the phase component of the signal. Instead of resynchronization of traces, you can actually do CPA on the spectrum, though the efficiency depends on the type of leakage (see “Correlation Power Analysis in the Frequency Domain” by O. Schimmel et al., presented at COSADE 2010).</p>
<p><span epub:type="pagebreak" title="347" id="Page_347"/>The spectrogram, which does contain timing information, can also help you identify <em>interesting</em> events. If you know when your target operation starts, you may be able to see certain frequencies appear or disappear. Alternatively, if you don’t know when the target operation starts, it can be helpful to note a point in time where the frequency pattern changes. See <a href="#figure11-18" id="figureanchor11-18">Figure 11-18</a>, where the entire spectrum clearly changes at, for example, 5ms and 57ms.</p>
<p>The change in frequency characteristics of the signal could be due to a cryptographic engine being started. Unlike with spectrum analysis, you’re looking at time-based information, so this spectrogram method is more sensitive to timing noise.</p>
<figure>
<img src="image_fi/278748c11/f11018.png" alt="f11018"/>
<figcaption><p><a id="figure11-18">Figure 11-18</a>: Spectrogram over a cryptographic operation (top) and the original trace (bottom)</p></figcaption>
</figure>
<h4 id="h3-278748c11-0012"><span epub:type="pagebreak" title="348" id="Page_348"/>Intermediate Correlations</h4>
<p class="BodyFirst">You know now that you can use CPA to determine keys by calculating a correlation trace for each key hypothesis. You can use the correlation trace for other purposes as well: to detect other data values that are being processed by the target, for instance, where the plaintext or ciphertext are being used in an operation. In this section, we assume you actually know the data values you want to correlate against, so no hypothesis testing is required. The most immediate and interesting candidates are plaintext and ciphertext consumed and produced by a cipher algorithm. With known data values and a leakage model, you can correlate traces and find out if and when those data values leak.</p>
<p>Let’s assume you have an AES encryption for which you know the plaintext of each execution, and you know that it leaks the Hamming weight (HW) of 8-bit values. You can now correlate the HW of each plaintext byte with your measurements and see when the algorithm consumes them; this is also known as <em>input correlation</em>. Depending on your trace acquisition window, you may see many moments of correlation: every bus transfer, buffer copy, or other processing of the plaintext may cause a spike. However, one of those spikes could be the actual input to the first <code>AddRoundKey</code>, soon after which you’ll want to attack the Substitute operation.</p>
<p>Another trick is to calculate the correlation with the ciphertext; this is also known as <em>output correlation</em>. Although plaintext spikes can theoretically appear throughout your trace, ciphertext spikes<em> can appear only after the crypto has completed.</em> Therefore, the first spike of ciphertext indicates that the crypto must have happened before that spike. A good rule of thumb is to dig for crypto operations between the first ciphertext spike and the plaintext spike immediately before that.</p>
<p>Observing a spike in ciphertext correlation is a good thing. It’s an indication that you have sufficient traces, insignificant misalignment, and a leakage model that captures the ciphertext. Of course, not seeing a spike means you need to fix any of the above, and you may not necessarily know which one. The approach is usually trial and error. Note that with CPA, you are attacking crypto intermediates, and not plaintext or ciphertext. Correlation with plaintext or ciphertext is, therefore, merely an indication you have your processing right; the actual crypto intermediates may need a slightly different alignment, a different filter, or more traces.</p>
<p>The final correlation trick you can use if you know the key to a crypto execution is <em>intermediate</em> <em>correlation</em>. If you know the key, ciphertext or plaintext, and the type of crypto implementation, you can calculate all intermediate states of the cipher algorithm. For instance, you can correlate with the HW of each of the 8-bit outputs of <code>MixColumns</code> in AES, for every round. This way, you should see 16 spikes for each round, slightly delayed with respect to each other. This idea can be extended to correlating with the HW of an entire 128-bit AES round state at once, which works in parallel implementations of AES.</p>
<p>You can also use this trick to brute-force the leakage model—for instance, by not only calculating the HW but also the Hamming distance (HD) and <span epub:type="pagebreak" title="349" id="Page_349"/>seeing which gives the highest spikes. The downside is that you need to know the key, but the upside is that if you see spikes here, you’re getting close to a successful CPA. (The reason you can’t conclude you’re there yet is because CPA cares about “correct spikes” versus “incorrect spikes,” and we’ve analyzed only “correct spikes” here.)</p>
<h4 id="h3-278748c11-0013">Known-Key CPA</h4>
<p class="BodyFirst">The <em>known-key CPA</em> technique combines the results of the CPA and partial guessing entropy principles addressed earlier in this chapter to tell whether you actually can extract a key. You calculate a full CPA and then use PGE to analyze (for each subkey) the rank of the correct key candidate versus the number of traces. Once you see subkeys structurally drop in rank, you know you are on to something. </p>
<p>Don’t get overexcited when just a few of your keys drop to very low ranks. Statistics can produce strange results. They may just as well go up again with a growing trace set. Only if most keys drop and stay low may you be on to something. We’ve also observed the opposite effect: 9 out of 10 key bytes at rank 1, whereas the last one takes forever to find. Again, statistics can produce strange results. Only when all subkeys are at a low rank do you enter the territory of being able to brute-force your way out.</p>
<p>In contrast to intermediate correlation, this method actually tells you whether you can extract a key. However, the computational complexity is significantly larger; you need to calculate 256 correlation values for each key byte, instead of one correlation value in the case of intermediate correlation. As with intermediate correlation, not seeing spikes can be caused by insufficient traces, significant misalignment, or a bad leakage model. It may take trial-and-error to determine this.</p>
<h4 id="h3-278748c11-0014">Test Vector Leakage Assessment</h4>
<p class="BodyFirst"><em>Welch’s t-test</em> is a statistical test used to determine whether two sample sets have equal mean values. We’ll use this test to answer a simple question: if you have grouped power traces into two sets, are those sets statistically distinguishable? That is, if we have performed 100 encryption operations with key A and 100 encryption operations with key B, is there a detectable difference in the power traces? If the average power consumption of the device at a certain time in the trace differs for key A and key B, it might suggest that the device is leaking information.</p>
<p>We apply this test to a certain point in time for each of two sets of power traces. The result is the probability that the two sets of power traces have equal means at that point in time, regardless of the standard deviation. We’ll intentionally create two trace sets, and in each set, the target processes different values. If these values give rise to changes in the average power level, we then know we have leakage. See the “Trace Set Analysis and Processing” earlier in this chapter for notes on acquiring multiple sets and to learn more about choosing the input data. We cannot emphasize this enough: if you generated two sets by running 100 traces with key A <span epub:type="pagebreak" title="350" id="Page_350"/>and then sequentially after that 100 with key B, your traces are useless. The statistical test is almost certain to find a difference between them, since physical changes (such as temperature) are quite likely to occur between the times when each set was captured. Before acquisition of each trace, randomly decide on the PC (not the target) whether it will be with key A or key B. Ask us how we know.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="box">
<h2>further research</h2>
<p class="BoxBodyFirst">For more background on applying this test for the purposes of leakage detection, “A Testing Methodology for Side Channel Resistance Validation,” by Gilbert Goodwill, Benjamin Jun, Josh Jaffe, and Pankaj Rohatgi, is a good start, and “Test Vector Leakage Assessment (TVLA) Methodology in Practice,” by G. Becker et al., is another great reference. TVLA was designed to standardize measuring leakage so that it can be used in a pass/fail certification scenario, without having to depend on the qualities of an individual side-channel analyst. See <span class="xref" itemid="xref_target_Chapter 14 ">Chapter 14 </span>for more information about certification.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside><p>We can plot the value of Welch’s <em>t</em> over time and observe spikes where leakage is detected, similar to a correlation trace. The value of Welch’s <em>t</em> is calculated by </p>
<figure class="graphic">
<img src="image_fi/278748c11/e11003.png" alt="e11003"/></figure>

<p class="BodyContinued">where <span class="GraphicInline"><img src="image_fi/278748c11/e11004.png" alt="e11004"/></span>  is the average sample value at time <em>j</em> for trace set <em>A</em>, <em>var()</em> is the sample variance, and <em>D</em><sup><em>A</em></sup> is the number of traces in trace set <em>A</em>. The higher <em>w</em><sub><em>j</em></sub> is, the more likely it is that trace set <em>A</em> and trace set <em>B</em> actually are generated by a process with a different mean at time <em>j</em>. In our experience, for trace sets of at least a few hundred traces, absolute values for <em>w</em><sub><em>j</em></sub> of say 10 and higher indicate that there most likely is leakage, and a CPA attack may succeed if <em>w</em><sub><em>j</em></sub> is 80 or higher. In other literature you’ll often see the value of 4.5, which in our experience has led to some false positives.</p>
<p>We’ll give you a few sample sets for AES you can test so you get the idea of what we’re after here:</p>
<ol class="none">
<li><span class="RunInHead">Create one set with random input data and one set with constant input data.</span>  The idea is that if the target doesn’t leak, the power measurements inside the crypto algorithm should be statistically indistinguishable, even if the characteristics of the processed data clearly vary. Note that power measurements of the transporting of input data to the crypto engine will probably leak, which this test will detect. Obviously, differences in input data are not real leakage and cannot be exploited, so watch out for false <em>t</em> peaks caused by this “input leakage.”</li>
<li><span epub:type="pagebreak" title="351" id="Page_351"/><span class="RunInHead">Create one set where an intermediate data bit <b><i>X</i></b>  has the value 0 and another set where <b><i>X</i></b>  has the value 1.</span>  This example is of most interest when testing a bit in a middle round of AES, such as any AES state bit after the <code>SubBytes</code> or <code>MixColumns</code> operations in round 5. With this test, there will be no false positives like “input leakage”; bits in round 5 of AES have effectively no correlation with the input or output bits of AES. If you want to test Hamming distance leakage, you can also calculate bit <em>X</em> as the XOR between, for instance, the input and output of an entire AES round. You should perform this test with a known key, but you can do it with fully random inputs. Since you don’t know which bit <em>X</em> actually leaks, you can calculate the statistics for all imaginable intermediate bits—for instance, for the 3 × 128 bits of state after <code>AddRoundKey</code>, <code>SubBytes</code>, and <code>MixColumns</code> (<code>ShiftRows</code> doesn’t flip bits) in round 5.</li>
<li><span class="RunInHead">Create one set where intermediate <b><i>Y</i></b>  is <b><i>A</i></b>  and another set where <b><i>Y</i></b>  is not <b><i>A</i></b>.</span>  This is an extension of the previous idea. You can, for instance, test whether one byte of <code>SubBytes</code> output has a bias in the power measurements when its value is, for example, 0x80. Again, you can calculate the t-test for any intermediate <em>Y</em> and value <em>A</em>, so you can run 16 × 256 tests for the <code>Substitute</code> output state in round 5.</li>
<li><span class="RunInHead">Create one set where the entire 128-bit round <b><i>R</i></b>  state of AES has exactly <b><i>N</i></b>  bits set to 1 and then create another random set.</span>  This one is clever. Let’s say we pick round <em>R</em> = 5, and we generate a 128-bit state with, say, <em>N</em> = 16 randomly selected bits set to 1. This is a significant bias: under normal circumstances, on average, 64 bits are set to 1, and it’s highly unlikely for the biased state to appear. However, using the known key, we can calculate what plaintext would have generated that biased state under that key. Due to the properties of crypto, the bytes of these plaintexts will appear uniformly random. The same holds for the ciphertext. In fact, when calculating <em>t</em>, the only bias you may theoretically detect is actually in round <em>R</em>, because there shouldn’t be any other bias (except for some minor biasing of rounds <em>R</em> – 1 and <em>R</em> + 1). Therefore, you won’t get any <em>t</em> spikes caused by transfer of plaintext or ciphertext. Because you are biasing an entire round state, you may detect leakage with fewer traces than with the previous methods; therefore, it’s a great first way of detecting leakage before any CPA method can detect it.</li>
</ol>
<p>As you can see, you can use the t-test to detect various types of leakage. Note that we have not specified an explicit power model, which makes the t-test a more generic leakage detector than CPA and friends. The biasing of an inner round especially amplifies leakage. The t-test is a great tool to determine the timing of leaks, the location of EM leaks, or for improving filters by tuning them for the highest value of <em>t</em>. One cool trick that can help if you have a lot of misalignment is first to do an FFT and then calculate <em>t</em> in the frequency domain to find out at what frequency your leakage is.</p>
<p>The downsides to t-tests are that you may need the key and that these tests don’t actually do key extraction. In other words, you’ll still need to use CPA and figure out a power model, and you may not succeed. Just like CPA, not seeing spikes means you may need to improve your trace processing.</p>
<p><span epub:type="pagebreak" title="352" id="Page_352"/>Because you aren’t actually recovering the key, it’s also easy for the t-test to produce false positives. These can occur because there is a statistical difference between the groups of traces unrelated to cryptographic leakage (for instance, due to not properly randomizing your acquisition campaign). In addition, the t-test will detect leakage related to the loading or unloading of data from the cryptographic core, which may be useless to attack. The t-test simply tells you that two groups have the same or different means, and <em>you</em> must correctly understand what that implies. It is, however, a really handy tool for tweaking your processing techniques: if the <em>t</em> value goes up, you’re heading in the right direction.</p>
<h3 id="h2-278748c11-0012">Processing Techniques</h3>
<p class="BodyFirst">In the “Analysis Techniques” section earlier in this chapter, we presented some standard methods that provide a measure of how close you are to having a good-enough signal for CPA. In this section, we’ll describe some techniques for processing trace sets. Some practical advice: check your results after each step and twice on Sunday. Otherwise, it’s too easy to make a misstep and lose the leakage signal forever. It’s more time-efficient to detect issues earlier rather than later when you need to debug your entire processing chain.</p>
<h4 id="h3-278748c11-0015">Normalizing Traces</h4>
<p class="BodyFirst">Once you have acquired a trace set, it’s always helpful to calculate the average and standard deviation per trace, as explained in the “Averages and Standard Deviations over Operations (per Sample)” section earlier in this chapter. You’ll see two things: outliers that in only one trace will jump outside the “normal” range and a slow drift of the normal range due to environmental conditions as well as possible errors/bugs in your acquisition. To improve your trace set’s quality, you’ll want to drop traces that are outliers by only allowing a certain range of average/standard deviation values. After that, you can correct for drift by <em>normalizing</em> traces. A typical normalization strategy is to subtract the average per trace and divide all sample values by the standard deviation for that trace. The result is that each trace has an average sample value of 0 and a standard deviation of 1.</p>
<h4 id="h3-278748c11-0016">Frequency Filtering</h4>
<p class="BodyFirst">When capturing data with the oscilloscope, we can use analog filters on the input to the scope. These filters can also be computed digitally: a variety of environments provides libraries that easily allow you to pass traces through filters. Examples include scipy.signal for Python and SPUC for C++. Digital filters form the backbone of most digital signal processing work, so most programming languages have excellent filtering libraries.</p>
<p><span epub:type="pagebreak" title="353" id="Page_353"/>When doing <em>frequency</em> <em>filtering</em>, your aim is to take advantage of the fact that the leakage signal you are interested in, or some specific source of noise, may be present in a distinct part of the frequency spectrum. (The “Spectrum Analysis” section earlier in this chapter contains a description of how to analyze the spectrum for noise or signal.)</p>
<p>By either passing the signal or blocking the noise, you can improve the CPA’s effectiveness. You probably want to apply the same filter to the harmonics of the base signal; for instance, if your target clock is 4 MHz, it will probably help to keep 3.9–4.1, 7.9–8.1, 11.9–12.1 MHz, and so on. If your system has a switching regulator adding noise to your measurements, you might need a <em>high-pass</em> or <em>band-pass</em> filter to eliminate that noise. Often, <em>low-pass</em> filtering can help alleviate high-frequency noise present in these systems, but in some cases, your leakage signal is entirely in the high-frequency components, so high-pass filtering would rule out any chance of success! In other words, it requires some trial and error.</p>
<p>For DPA, you most likely will be using (multi-)notch filters to pass or block base frequencies and their harmonics. A <em>finite impulse response (FIR)</em> or <em>infinite impulse response (IIR)</em> filter design for notch filtering can be complicated; you can always revert to the more computationally complex way of doing an FFT, and then block/pass arbitrary parts of the spectrum by setting the amplitude to 0 and doing an inverse FFT.</p>
<h4 id="h3-278748c11-0017">Resynchronization</h4>
<p class="BodyFirst">Ideally, we would know when the encryption operation occurs, and we would trigger our oscilloscope to record that exact moment in time. Unfortunately, we might not have such a precise trigger but instead are triggering our oscilloscope based on a message being sent to the microcontroller. The amount of time that passes between the microcontroller receiving the message and performing the encryption isn’t constant, since it might not immediately act on the message.</p>
<p>This discrepancy means we need to resynchronize multiple traces. <a href="#figure11-19" id="figureanchor11-19">Figure 11-19</a> shows three traces before resynchronization (<em>misaligned traces</em>), and the same three traces after resynchronization (<em>aligned traces</em>).</p>
<p>The three traces on the top are not synchronized. By doing a <em>sum of absolute difference (SAD)</em> process on the three traces, the synchronized output shows a clear trace on the bottom.</p>
<p>Applying the SAD method, you take a trace that forms your <em>reference trace</em>. This is the trace to which you’ll then align all others. From this reference trace, you select a group of points, usually some feature that appears in all the traces. Finally, you try to shift each trace such that the absolute difference between the two traces is minimized. This chapter comes with a small Jupyter notebook (<a href="https://nostarch.com/hardwarehacking/" class="LinkURL">https://nostarch.com/hardwarehacking/</a>) that implements the SAD and produces <a href="#figure11-19">Figure 11-19</a>.</p>
<span epub:type="pagebreak" title="354" id="Page_354"/><figure>
<img src="image_fi/278748c11/f11019.png" alt="f11019"/>
<figcaption><p><a id="figure11-19">Figure 11-19</a>: Synchronizing traces using the sum of absolute difference (SAD) method</p></figcaption>
</figure>
<p>An alternative is to use the <em>circular convolution theorem</em>.<em> </em>The convolution between two signals is basically the point-wise multiplication of two signals at different shifts <em>n</em>. The value of <em>n</em> at which this multiplication has the lowest value is the “best fitting” shift for those signals. The naïve calculation is very expensive. Luckily, you can obtain a convolution by performing an FFT on both signals, multiplying the signals point-wise, and then doing an inverse FFT. This process will give you the result of the convolution between two signals for each shift value <em>n</em>, after which you just need to scan for the minimum.</p>
<p>Several other simple resynchronization modules can be found in the ChipWhisperer software. Resynchronizing can become more advanced than simply applying a static shift. You might need to warp the traces in time or remove sections of a trace where an interrupt occurred in only a handful of traces. We don’t cover these details here, but see Jasper G. J. van Woudenberg, Marc F. Witteman, and Bram Bakker’s “Improving Differential Power Analysis by Elastic Alignment” for more details on <em>elastic alignment</em>.</p>
<h4 id="h3-278748c11-0018">Trace Compression</h4>
<p class="BodyFirst">Capturing long traces can take up a lot of disk and memory space. Using a high-speed oscilloscope sampling at GS/s or more, you’ll quickly discover that the size of your traces grows annoyingly large. Even worse, the analysis becomes very slow, since it is performed on every sample in succession.</p>
<p><span epub:type="pagebreak" title="355" id="Page_355"/>If the real objective is to find some leakage information about each clock cycle, you might guess that you don’t need every single sample of every clock cycle. Rather, it’s often sufficient to keep one sample from each clock cycle. This is called <em>trace compression</em>, since you greatly reduce the number of sample points.</p>
<p>As previously mentioned in this chapter’s “Sampling Rate” section, you can perform trace compression by simply downsampling, but doing so won’t yield as much a savings as what true trace compression does.</p>
<p>True trace compression uses a function to determine the value by which to represent each clock cycle. It could be the minimum, maximum, or average value over an entire clock cycle or over only a part of the entire clock cycle. If your target device has a stable crystal oscillator, you can perform this trace compression by taking samples at a certain offset from the trigger, since the device and sample clock should both be stable. For non-stable clocks, you’ll need to do some clock recovery—for instance, by finding peaks indicating clock start. Once you have the clock, you may find that only the first <em>x</em> percent of a clock cycle contains most of the leakage, so you can disregard the rest.</p>
<p>When compressing EM probe measurements, take into account that the EM signal is the derivative of the power signal. So, for a single power spike, there will be a positive EM spike followed by a negative one. You don’t want to average the positive and negative parts of the captured waves; by their nature they cancel out! In this case, you just want to take the sum of the absolute sample values for that clock. </p>
<h3 id="h2-278748c11-0013">Deep Learning Using Convolutional Neural Networks</h3>
<p class="BodyFirst">Staying relevant requires that a field like side-channel analysis must keep up with the machine learning (ML) trends. There are actually two seemingly fruitful ways to frame the side-channel problem in terms of machine learning: the first being side-channel analysis as a sequence of steps by an (intelligent) agent, and the second way being side-channel analysis as a classification problem. This research topic is still young at the time of writing, but it’s an important one. Side-channel analysis is becoming increasingly important, and there aren’t enough of us to keep up with market demands. Any automation such as machine learning is crucial.</p>
<p>Consider the <em>agent</em> frame: agents observe their world, perform an action, and are punished/rewarded in relation to how their actions change the world. We could train an agent to decide what steps to take next, such as deciding whether to use alignment, filtering, or resampling based on how high a <em>t</em> spike is. The future will tell whether this is brilliant or foolish, as this topic is currently unstudied.</p>
<p>Now consider the <em>classification problem</em>. Classification is the science of taking in an object and assigning it to a class. For instance, modern-day deep learning classifiers can take in an arbitrary image and, with high accuracy, detect whether a cat or a dog is in the image. The neural networks used to perform the classification are trained by presenting millions of pictures that are already labeled with “cat” or “dog.” Training means <span epub:type="pagebreak" title="356" id="Page_356"/>tuning the network parameters such that they detect features in the images representative of either cats or dogs. The interesting part about neural networks is that the tuning happens purely by observation; no expert needs to describe the features needed to detect “cat” or “dog.” (At the time of writing, experts are still needed to design the structure of the network and how the network is trained). Side-channel analysis is essentially a classification problem: we try to classify intermediate values from traces we are presented with. Knowing the intermediate values, we can calculate the key.</p>
<p><a href="#figure11-20" id="figureanchor11-20">Figure 11-20</a> illustrates the process where a neural network is being trained to perform side-channel analysis.</p>
<figure>
<img src="image_fi/278748c11/f11020.png" alt="f11020"/>
<figcaption><p><a id="figure11-20">Figure 11-20</a>: Training a neural network for side-channel analysis</p></figcaption>
</figure>
<p>We’ve replaced our lovely cats and dogs with a cute set of traces, which we individually label with the Hamming weight of the intermediate value we are targeting. For AES, this label could be the Hamming weight of a specific S-box output. This labeled set of traces will be the training set for the neural network, which will then, hopefully, learn how to determine the Hamming weight from a given trace. The outcome is a trained model that can be used for assigning probabilities over the Hamming weights for a new trace.</p>
<p><a href="#figure11-21" id="figureanchor11-21">Figure 11-21</a> shows how a network’s classification can be used to obtain confidence values for intermediates (and thus keys).</p>
<p>This diagram shows the neural network processing a single trace. The trace goes through the neural network, which results in a probability distribution over the Hamming weights. In this example, the most likely Hamming weight is 6 with a probability of 0.65.</p>
<p>We can train a neural network by presenting it with traces and known intermediate values, as shown in <a href="#figure11-20">Figure 11-20</a>, and thereafter let the network classify a trace with an unknown intermediate value, as shown in <a href="#figure11-21">Figure 11-21</a>, which in effect is an SPA method. Such an SPA analysis can be <span epub:type="pagebreak" title="357" id="Page_357"/>useful for ECC or RSA, where we need to classify chunks of traces that represent the calculation over one or a few key bits.</p>
<figure>
<img src="image_fi/278748c11/f11021.png" alt="f11021"/>
<figcaption><p><a id="figure11-21">Figure 11-21</a>: Using the network’s classification to help with finding keys</p></figcaption>
</figure>
<p>The DPA approach is to use the probability distribution (which is output of the neural network) for intermediate values, transform this probability distribution into confidence values over key bytes, and update these confidences for each observed trace. Here is where we diverge from usual neural network classification: we don’t care about classifying each trace perfectly, as long as on average we bias the confidence value for the relevant key byte. In other words, we don’t intend to identify a cat or dog perfectly in each picture, but we have a gazillion extremely noisy pictures of one animal, and we try to make out whether it is a cat.</p>
<p>Properly trained networks, specifically convolutional neural networks, detect objects irrespective of orientation, scale, irrelevant color changes, and some level of noise. So, hypothetically, these networks would be able to reduce human effort by analyzing traces that need filtering and alignment. In the 2018 Black Hat talk by Jasper, “Lowering the Bar: Deep Learning for Side Channel Analysis” (available on YouTube), he shows the work of his co-authors Guilherme Perin and Baris Ege.<em> </em>He demonstrates that neural networks are a viable approach for analyzing traces of asymmetric crypto and software implementations of symmetric ciphers where there is misalignment and some noise. It’s still an open question how well this extends to hardware implementation with harder countermeasures. One interesting result from the work was that it broke a second-order masked implementation by detecting first-order leakage with the network.</p>
<p>The goal of this work is to eliminate the need for a human analyst to interpret traces. We have not yet reached that goal, though we arguably made it easier by shifting the effort to network design, rather than the multidomain complexities of side-channel analysis.</p>
<h2 id="h1-278748c11-0005"><span epub:type="pagebreak" title="358" id="Page_358"/>Summary</h2>
<p class="BodyFirst">In the introduction to this chapter, we mentioned it would be about the <em>art</em> of power analysis, as opposed to the <em>science</em> of power analysis. The science is the easy part—just trying to understand what the tools do. The art is in applying them at the right time in the right way or even designing your own tools. Achieving expertise in this art requires experience, which you’ll gain only through experimentation. For every skill level, there are interesting targets to play with. In our lab, we analyze multi-GHz SoCs, but that requires a team of people who’ve done this type of analysis professionally for a few years, and it may take a few months to start seeing any leakage. At the other end of the spectrum, in only a few hours, we are able to teach how to break the key on a simple microcontroller to people without experience. Whatever you play with, try to match it with your experience level.</p>
<p>Another great exercise is to build your own countermeasures. Grab a target you’re comfortable breaking that allows you to load your own code. Try to think what would really make it difficult for you as an attacker to break the implementation; one of the tricks to employ is to take one of the steps in your analysis and break the assumptions that step makes. A simple one is to randomize the timing of the algorithm, which breaks DPA and forces you to do alignment of the traces. This way, you improve your system’s security, you improve your attacker skills, and you give yourself something to do on the next weekend.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="box">
<h2><span epub:type="pagebreak" title="359" id="Page_359"/>Resources</h2>
<p class="BoxBodyFirst">This book has dedicated three chapters to side-channel analysis and has barely scratched the surface of resources available. We’ve collected some tools and resources you might find useful.</p>
<p><em>Power Analysis Attacks</em><em>: Revealing the Secrets of Smart Cards</em> (Springer, 2010),<b> </b>by Stefan Mangard, Elisabeth Oswald, and Thomas Popp, should be your go-to reference for more side-channel fun. This book includes details of more advanced attacks, such as template attacks, and has several sample workspaces available at <a href="http://www.dpabook.org/" class="LinkURL">http://www.dpabook.org/</a>.</p>
<p><em>Serious Cryptography</em> (No Starch Press, 2018), by Jean-Philippe Aumasson, provides an overview and details of various cryptographic algorithms. Applying side-channel analysis attacks will require understanding various aspects of the algorithm, and this book is a good reference to most algorithms you are likely to encounter.</p>
<p class="BoxBodyFirst">The area of side-channel analysis is a large academic field, resulting in university and commercial researchers frequently publishing results about new attacks and countermeasures. If you are interested in further details of this field, you will undoubtedly want to look into these academic resources.</p>
<p>The workshop on Cryptographic Hardware and Embedded Systems (CHES) remains one of the premier events in the area of side-channel analysis and general embedded hardware security. It is normally co-located with a conference on fault-tolerance (FDTC) and security proofs (PROOFS), and occasionally co-located with one of the main CRYPTO conferences. CHES typically has hundreds of attendees.</p>
<p>The workshop on Constructive Side-Channel Analysis and Secure Design (COSADE) also deals with side-channel analysis. This conference is much smaller than CHES but has a strong focus on secure embedded hardware design.</p>
<p>Smart Card Research and Advanced Application Conference (CARDIS)<b> </b>concentrates on smart card research, but this includes side-channel analysis and fault injection. This conference is smaller than CHES.</p>
<p>CT-RSA is a specific track (the Cryptographer’s Track) of the main RSA Conference, which has had around 42,000 attendees in the past.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
</section>
</body></html>