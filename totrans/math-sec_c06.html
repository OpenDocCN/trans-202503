<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="index: http://www.index.com/" lang="en" xml:lang="en">
<head>
<title>Chapter 6: Analyzing Social Networks to Prevent Security Incidents</title>
<link href="NSTemplate_v1.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:1ff3c234-c763-4a12-a0c7-4ddf7c732e40" name="Adept.expected.resource"/>
</head>
<body epub:type="bodymatter chapter">
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" id="Page_91" title="91"/>6</span><br/>
<span class="ChapterTitle">Analyzing Social Networks to Prevent Security Incidents</span></h1>
</header>
<figure class="opener">
<img alt="" src="image_fi/book_art/chapterart.png"/>
</figure>
<p class="ChapterIntro">In the last three chapters on graph theory, we’ve built graphs from a snapshot of a network at a particular moment in time; that is, we’ve worked from fixed, historical data. But finding and responding to events in the past always leaves the white hats one step behind the black hats. If we want to know more about what happened before or after the time captured in the data, we need new analytic techniques. The future requires <em>predictive analytics</em>, a branch of mathematics that aims to statistically determine the probability of future or past events given some set of known observations. The goal is to stop the security incident before it ever gets started. To achieve this, though, we need a way to predict how things will change over time. We’ll use a specific algorithm, the Monte Carlo simulation, to model network activity that hasn’t occurred yet. While this chapter presents the topic in the context of social network analysis, Monte Carlo simulations are suited to a wide variety of topics and network types. For example, I’ve used Monte Carlo simulations to predict which machine an adversary would attack next.</p>
<p><span epub:type="pagebreak" id="Page_92" title="92"/>Here, we’ll attempt to predict the answers to the following questions about a social network:</p>
<ul class="disc">
<li>How far is information likely to spread from a given node?</li>
<li>Which nodes are being influenced by other nodes?</li>
<li>What links could be severed to disrupt the flow of information between two nodes?</li>
</ul>
<p>From a security perspective, these questions assess the resilience of a social network in the face of adversarial behavior. They ask, “How easy would it be to break up an association of people?” Companies ask these questions about themselves to determine if they could withstand losing key employees, facilities, or vendors. Law enforcement asks them when they assess a criminal syndicate.<sup class="endnote"><a href="b01.xhtml#c06-endnote-001" id="c06-noteref-001">1</a></sup> Criminals also ask these questions about an organization when they want to select the targets for spear phishing and other social engineering attacks.<sup class="endnote"><a href="b01.xhtml#c06-endnote-002" id="c06-noteref-002">2</a></sup></p>
<p>We’ll begin this chapter by looking at how to define and construct a Monte Carlo simulation. We’ll discuss how different levels of randomness can be applied to replace unknowns. Then we’ll use the Monte Carlo simulation we’ve built to predict the way a piece of information might move through the social network from <span class="xref" itemid="xref_target_Chapter 5"><a href="c05.xhtml">Chapter 5</a></span>, given previous observations. Finally, in the proof of concept for this chapter, we’ll see how to modify our simulation to account for adversarial behavior. By the end of this chapter, you’ll be able to use your knowledge of graph theory and apply Monte Carlo simulations to predict the outcome of different scenarios on your own social networks.</p>
<h2 id="h1-502567c06-0001">Using Monte Carlo Simulations to Predict Attacks</h2>
<p class="BodyFirst">For the rest of this chapter to make sense, we need a little bit more theory on top of the graph theory we’ve already covered. Specifically, I’ve been throwing around the word <em>simulation</em> without really defining it. Generally speaking, a simulation is a controlled imitation of a real-world process. Simulations rely on models to describe the key characteristics and behaviors present in the simulated environment. The simulation code acts as the manager of the model, choosing various actions and applying them to evolve the model at each step. Modern models and simulations are most often designed using a combination of programming languages like C and Python, where C is used for critical functions and user-friendly Python syntax is used for the rest. Luckily, all the underlying C code has already been handled for us, so we can focus on the Python interface.</p>
<p>In theory, any phenomenon that can be reduced to data and equations can be simulated on a computer. In practice, however, simulation is difficult because most real-world processes are subject to a practically infinite number of influences, and it’s impossible to account for them all. </p>
<p> A Monte Carlo simulation is a way of quickly gathering statistics about some seemingly random (or at least hard to predict) variable, given a set of constraints. Unlike other forecasting methods, which work with a set of fixed <span epub:type="pagebreak" id="Page_93" title="93"/>input values, a Monte Carlo simulation predicts a set of outcomes based on an estimated range of values. You’ve probably seen the results of a Monte Carlo simulation in the form of a storm path map (sometimes called a <em>spaghetti model</em>). Monte Carlo simulations are most useful when the probability of varying outcomes can’t be determined because of random variable interference. A Monte Carlo simulation focuses on repeating the test with random samples to achieve certain results. It also helps to explain the impact of risk and uncertainty in prediction and forecasting models because the values for the random variables are chosen using the distribution of previously recorded values. The larger the variance in the random value, the more variance in the different results of the simulation. In principle, Monte Carlo methods can be used to investigate any problem with a probabilistic interpretation. </p>
<p>In a security context, I’ve used Monte Carlo simulations to predict and interrupt attacks. To do so, I programmed some rules that mimicked the previous decisions of the attacker and ran thousands of simulations to predict where the attacker would end up. My team created a network graph (similar to the one from the previous chapter) in which we weighed the ease of access along with the machine’s attractiveness to the attacker (in terms of data or lateral movement). We then ran simulations with the attacker starting from random machines we knew had been exploited and using a stochastic process to determine if the attacker could successfully move from one machine to another. </p>
<p>We had additional rules to define how the attacker selected machines and so forth, but the question we were trying to answer was simple: After six days of active exploitation, which machines had the highest probability of being infected? In math terms, the law of large numbers tells us that integrals described by the expected value of some random variable can be approximated by taking the empirical mean (sometimes called the <em>sample mean</em>) of independent samples of the variable. In lay terms, the machines with the highest probability in our network simulation tests were likely those with the actual highest probability. And there’s our definition for “predicting” the future: we can state, with some degree of confidence, the statistical probability of each outcome. Unfortunately, that means things won’t always turn out as predicted.</p>
<p>Modeling changes requires that we first have a way to describe what can and can’t happen. We’ll use a mathematical construct known as a finite state machine to handle this task. We then need to create a fake world for our simulation to inhabit. NetworkX will fill this role by providing the graph of our social network. Finally, we need some way of recording the different events so that we can analyze them. This is where the Monte Carlo algorithm really starts to take shape. Let’s start by defining each piece, and then we can tie it all together with some different simulations.</p>
<h3 id="h2-502567c06-0001">Finite State Machines</h3>
<p class="BodyFirst">A <em>finite state machine</em> (<em>FSM</em> or simply <em>state machine</em>) is a hypothetical machine that can be in exactly one of a finite number of states at a given moment in time, where a <em>state</em> is a unique configuration of variables. If you think of a board with three switches on it, each possible switch configuration <span epub:type="pagebreak" id="Page_94" title="94"/>represents a possible state for the board. It’s called a <em>finite</em> state machine because you can count the number of possible states. In the example switchboard, if each switch can be in one of two possible positions, there’s a total of eight possible configurations, or states, the switchboard could be in. If you think of these switches like bits in binary, you could represent the values between 000 and 111, or 0 through 7 in base 10. The state machine can change from one state to another in response to some external <em>input</em>, or decision (such as flipping one of the switches on the board). Changes from one state to another are called <em>transitions</em>. </p>
<p>Formally, a state machine <em>M</em> is defined by a quintuple <em>M</em> = (Ξ, <em>S</em>, <em>S</em><sub>0</sub>, δ) comprising a finite number of possible inputs (Ξ, the <em>input alphabet</em>), a set of all possible states (<em>S</em>), an initialization state (<em>S</em><sub>0</sub>) where <em>S</em><sub>0</sub> ∈ <em>S</em>, and finally the conditions for each valid transition between states, δ. We can represent a state machine as a directed graph wherein each node is a potential state of the machine, and each edge is the required input to transition from state <em>u</em> to state <em>v</em>. <a href="#figure6-1" id="figureanchor6-1">Figure 6-1</a> shows a simple FSM graph with five states and four transition inputs.</p>
<figure>
<img alt="" class="" src="image_fi/502567c06/f06001.png"/>
<figcaption><p><a id="figure6-1">Figure 6-1</a>: A simple finite state machine</p></figcaption>
</figure>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	The code to generate <a href="#figure6-1">Figure 6-1</a> is in the 1st cell of the <em>State_Machine_Graphs.ipynb</em> notebook. </p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Looking at this graph, you might be confused; after all, I just said there were four transitions, but there are nine edges here (the bidirectional edges between <em>S</em><sub>0</sub> and <em>S</em><sub>1</sub> and <em>S</em><sub>3</sub> and <em>S</em><sub>4</sub> count as two each). This is because the same input may be used in multiple transitions. The inputs Ξ<sub>3</sub> and Ξ<sub>2</sub> in <a href="#figure6-1">Figure 6-1</a> are both examples of this: Ξ<sub>2</sub> is used to transition between <em>S</em><sub>0</sub> and <em>S</em><sub>1</sub> as well as between <em>S</em><sub>4</sub> and <em>S</em><sub>2</sub>, while Ξ<sub>3</sub> can be used to transition from <em/><span epub:type="pagebreak" id="Page_95" title="95"/>S3 to <em>S</em><sub>1</sub> or from <em>S</em><sub>1</sub> to <em>S</em><sub>2</sub>. Think of the input Ξ<sub>2</sub> as an action, like flipping a particular switch. Depending on what state you’re in currently, the action of flipping the switch may take you to a different state. If you’re in <em>S</em><sub>0</sub> and flip the switch, you end up in <em>S</em><sub>1</sub>. If you’re in <em>S</em><sub>4</sub> and flip the switch, you’ll end up in <em>S</em><sub>2</sub>. The input hasn’t changed—it’s still Ξ<sub>2</sub>—which illustrates an important relationship between inputs and states. The same input may result in arriving at a different state, depending on the current state.</p>
<p>FSMs are either <em>deterministic</em>, meaning each transition has a single guaranteed outcome, or <em>stochastic</em>, meaning the outcome of an input is influenced by randomness and not guaranteed to produce the same result every time. To illustrate the difference between the two types of FSMs, imagine picking up a pencil. In a deterministic world, attempting to pick up the pencil will always result in successfully picking up the pencil—or transitioning to the state where you have the pencil, in FSM parlance. In a stochastic world, you may fail to pick up the pencil with some probability 0 &lt; <em>p </em>&lt; 1. If you fail to pick up the pencil, you transition to a different state than if you’d succeeded. Perhaps you dropped the pencil on the floor and you’re now in that state instead. This is a very simplistic example, but the point is that stochastic FSMs allow randomness to influence the results. This is powerful for generalizing the description of complex interactions because you don’t have to understand the mechanisms at work, you only need to measure the statistical distribution of possible outcomes and you can approximate the same phenomenon. </p>
<p>You’ll often see a mix of deterministic and stochastic inputs in the same FSM. For example, in the FSM from <a href="#figure6-1">Figure 6-1</a>, Ξ<sub>4</sub> is deterministic. If you’re at <em>S</em><sub>2</sub>, the input Ξ<sub>4</sub> is guaranteed to transition you to <em>S</em><sub>3</sub> and there’s no other possible outcome. On the other hand, Ξ<sub>1</sub> is stochastic: if you’re at <em>S</em><sub>4</sub> and select action Ξ<sub>1</sub>, you might end up at <em>S</em><sub>1</sub> or at <em>S</em><sub>3</sub>. If no probabilities are given for these outcomes, it’s assumed to be uniformly random. If probabilities are given, the probability distribution is used in a weighted-random selection function. NetworkX has parameters for labeling the edges, which can be useful when showing the probabilities or, as I’ve done here, the transition names. You can see examples of this code in the accompanying Jupyter notebook. For more detailed examples of using FSMs, I highly recommend checking Wolfram Alpha.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Other materials may denote the state machine’s input alphabet as an uppercase sigma (Σ), which more commonly denotes the summation function.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Now that you understand FSM structure a bit better, let’s move on to how we can leverage it using an algorithmic gem known as random walks. Random walks allow us to repeatedly choose random inputs for our FSM to automate the simulation of these choices based on the rules we define. </p>
<h3 id="h2-502567c06-0002">Network Modeling with Random Walks </h3>
<p class="BodyFirst">In math terms, a <em>random walk</em> is a series of randomly chosen steps (or transitions) within a system that result in a random final state after some number of steps. I like the analogy of a tourist wandering in an unfamiliar city. They may walk up the street a bit, decide to turn left, go a few blocks, and <span epub:type="pagebreak" id="Page_96" title="96"/>then decide to turn around and go back the other way. These walks are erratic and unpredictable by definition. Versions of the random walk model have been applied to research topics from economics to neurology, and now information security! </p>
<p>We’re going to apply this methodology to model how people pass information to one another and ultimately utilize the network. We can then use this information to explore what might happen if we change some of the parameters (such as an attacker taking over one or more lines of communication) without risking actual disruption to the network. Randomly selecting a series of transitions within a state machine over <em>n</em> steps (<em>T</em>(<em>n</em>)) updates the state of the system with the result of the input. The subsequent decision must be based on the new state, and all actions may not be valid in all states. The set of valid transitions from a given state is denoted Ξ<sub>(</sub><sub><em>S</em></sub><sub>)</sub>. At each step a transition is selected from Ξ<sub>(</sub><sub><em>S</em></sub><sub>)</sub> and appended to <em>T</em>(<em>n</em>). We can write this as:</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06001.png"/></figure>

<p>The state is updated and the process is repeated until all <em>n</em> steps have been taken, or no valid state transitions are left. The resulting <em>terminal state</em> is the product of applying the random walk defined in <em>T</em>(<em>n</em>) to the state machine <em>M</em> (<em>M</em> × <em>T</em>(<em>n</em>) <em>= S(Tn</em>)). </p>
<p>As a concrete example, let’s define a simple state machine. Imagine you’re standing in the center of a large empty room. This is the initial state, <em>S</em><sub>0</sub>. On the floor is a 7×7 grid of squares, and positions in the room can be expressed as location tuples (<em>x</em>, <em>y</em>) on the Cartesian plane (your position is <em>S</em><sub>0</sub> = (4, 4)). You can move forward, backward, left, or right one square with each step. Given an arbitrary set of instructions, you may end up standing on any square in the room; therefore, each square can be viewed as a potential state in <em>S</em>. The inputs [<em>forward</em>, <em>backward</em>, <em>left</em>, <em>right</em>] form the input alphabet Ξ. The two diagrams in <a href="#figure6-2" id="figureanchor6-2">Figure 6-2</a> show the same uniformly random walk for <em>n</em> = 10 in two dimensions on the left and three dimensions on the right. </p>
<figure>
<img alt="" class="" src="image_fi/502567c06/f06002.png"/>
<figcaption><p><a id="figure6-2">Figure 6-2</a>: A 2D and 3D random walk example</p></figcaption>
</figure>
<p><span epub:type="pagebreak" id="Page_97" title="97"/>In the 3D example, the third dimension is time (you wouldn’t actually start to levitate as you moved around the room). </p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	The code to generate the two images in <a href="#figure6-2">Figure 6-2</a> is in the 3rd cell of the <em>State_Machine_Graphs.ipynb</em> notebook.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>In contrast to a uniformly random walk, where each input is equally likely, in a <em>biased random walk</em> (or just <em>biased walk</em>), one or more of the inputs is likely to occur more than the rest. In a biased walk, we extend Ξ to a set of tuples: (<em>input</em>, <em>probability</em>).<sup class="endnote"><a href="b01.xhtml#c06-endnote-003" id="c06-noteref-003">3</a></sup> At each step we select one of the inputs from the list using a weighted random selection function—that is, one that respects the probability distribution we pass to it. We’ll construct a version of this later, but for now the key takeaway is that biased walks allow you to add any a priori information you have about behavior probabilities to your modeling. For example, if you know there’s a malicious actor who’s looking for financial information, you may choose to bias your model of their behavior toward nodes in the network that have access to such information.</p>
<p>Up until now we’ve covered what a state machine is and how we can use one to simulate a series of choices. Because a random walk represents a single set of choices made within a stochastic FSM, you could rerun the simulation and the results would likely be different. Even with a biased random walk, the results on each iteration may be a little more predictable but still not the same. If the result were always the same, the system would be deterministic and no fun to analyze. It’s the differences between simulation results that we’re interested in analyzing. Repeated stochastic simulation is the defining characteristic of a Monte Carlo simulation, so in the next section, we’ll complete our algorithm by defining how we want to run each test and collect the results in a meaningful way. Once we have the final piece to the puzzle, we’ll start using our Monte Carlo simulation to predict some possible future states for our social network. </p>
<h3 id="h2-502567c06-0003">Monte Carlo Simulation</h3>
<p class="BodyFirst">We can illustrate the relationship between random walks and Monte Carlo simulations with the simple example of flipping a coin. If we flip a coin and it lands on heads, what have we learned about the coin? Well, we’ve learned that with an extremely small sample size of 1, the coin lands on heads. Now, how useful do you think this information is for making predictions about the result of future coin flips? Could you predict if this is a fair coin or a trick coin? The answer is no, you couldn’t. This single result is not very useful—not yet, anyway. To get a clearer picture, we’d need to repeat this test a reasonably large number of times and record each outcome. Suppose we flip the coin 99 more times and it always lands on heads. This is way outside the expected result of roughly 50 percent, so we could state the coin is definitely not fair. </p>
<p>This situation is similar to the relationship between random walks and Monte Carlo simulations. Monte Carlo simulations are a subset of <em/><span epub:type="pagebreak" id="Page_98" title="98"/>repeated-sampling algorithms, which repeat a test some large number of times to gather statistical distributions. What makes a Monte Carlo simulation different from other repeated sampling algorithms is that it uses repeated random walks to simplify simulating complex interactions within a state machine over time. The random walk through the FSM acts like a single test—a coin flip, a space walk, or some other singular occurrence. The Monte Carlo algorithm then adds a layer to repeat this test over and over to collect the large sample size needed to make accurate predictions about future outcomes.</p>
<p>One predominant use for Monte Carlo simulations is in the field of General Game Playing (GGP). The goal for GGP researchers is to find a generalized algorithm that can play any arbitrary but well-defined game. Think about a system like Deep Blue or the more recent Alpha Go, but designed to play chess and <em>Go</em>, as well as backgammon, tic-tac-toe, <em>Risk</em>, <em>Battleship</em>, and so on. This realm of study extends to single-player games (so-called puzzle games) like <em>Tower of Hanoi</em> as well. The automated system, called the <em>player</em>, needs to decide on the next valid move from a list of potential moves. This process is known as <em>goal-oriented planning</em>. In a state machine with a large number of potential states (chess matches, for example), it’s prohibitive to exhaustively search the options to conclusion. Instead, a player needs a strategy to quickly weigh possible options to identify advantageous ones. Monte Carlo simulations are one option that researchers have used with some success<sup class="endnote"><a href="b01.xhtml#c06-endnote-004" id="c06-noteref-004">4</a></sup> by reducing each game to a limited-length random walk through potential game states, then repeatedly testing the outcome of these walks for some goal condition. </p>
<p>As I’ve mentioned, security often comes down to one researcher’s offensive knowledge against another’s defensive knowledge. Game theory would label this a zero-sum multiplayer scenario. The term <em>zero-sum</em> refers to the case that, for one player to win points, the other player must lose an equal amount of points. Simply put: if you win, I must lose, and vice versa. Chess is the most famous example of zero-sum games, but we also see these conditions in a lot of adversarial interactions like security. For me to bypass your security, your security must get bypassed. For your security controls to block me, my attacks must fail. There are already schools like Stanford University that teach game theory as a way for humans to analyze their security posture. There are also researchers using game theory to model attack and defense scenarios.<sup class="endnote"><a href="b01.xhtml#c06-endnote-005" id="c06-noteref-005">5</a></sup> It seems to me that programmatically applying game theory within information security research is a natural progression from the tools available today, and the simplest place to start that process is with Monte Carlo simulations.</p>
<p>Of course, this simplicity can come at a cost. Monte Carlo simulations can miss obvious advantageous decisions due to the random nature of selection. You can tune the accuracy of the model a bit by adjusting the number of random walks, as well as the maximum length of each random walk. <a href="#figure6-3" id="figureanchor6-3">Figure 6-3</a> shows an example Monte Carlo simulation of random walks like the one in <a href="#figure6-2">Figure 6-2</a>.</p>
<span epub:type="pagebreak" id="Page_99" title="99"/><figure>
<img alt="" class="" src="image_fi/502567c06/f06003.png"/>
<figcaption><p><a id="figure6-3">Figure 6-3</a>: A random walk Monte Carlo simulation</p></figcaption>
</figure>
<p>Each walk is shaded differently so you can tell where they overlap. They all start from the same location but then take unpredictable paths. </p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	The code to generate the random walks and 3D plot in <a href="#figure6-3">Figure 6-3</a> is in the 4th cell of the <em>State_Machine_Graphs.ipynb</em> notebook.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>The Monte Carlo simulation we’ll look at is an algorithm that relies on <em>k</em> random walks of length <em>n</em>, through a state machine <em>M</em>, to obtain the result list ζ<em>R</em>. The result is a list of terminal states from each random walk performed:</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06002.png"/></figure>

<p class="BodyContinued">For convenience, I also output the path traversed by each random walk:</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06003.png"/></figure>

<p class="BodyContinued">Choosing values for <em>n</em> and <em>k</em> is an equal mix of domain knowledge, statistical theory, and art. For <em>n</em>, we need to choose a value large enough to allow our model to reach interesting outcome states without creating a bunch of repetitive data. For state machines with a large number of potential transitions and states, you may need to pick a value for <em>n</em> that balances long <span epub:type="pagebreak" id="Page_100" title="100"/>enough paths with a reasonable program runtime. Our state machine has a small number of potential transitions and will tend to reach a terminal state fairly quickly, so a small value between 10 and 20 steps will suffice. </p>
<p>Choosing a good value for <em>k</em> is largely related to the number of potential states in the machine. You want to run the simulation as many times as it takes to collect statistical data to support a claim about the outcome, so the more possible outcomes there are, the more times you’ll want to run the simulation. When you move a project like this into production, you can use statistical methods to calculate the exact sample size required to justify an empirical claim, called <em>sample size determination</em>. Here, our simulation has a relatively small number of terminal states and we’re only trying to prove out the system, so somewhere between 10 and 25 runs will suffice for testing purposes.</p>
<h2 id="h1-502567c06-0002">Simulating Social Networks</h2>
<p class="BodyFirst">To answer our research questions about a social network, we’re going to write our own <em>Matrix</em>-like world, where simulated users live out their digital lives according to the rules of the system we put in place. The rules we choose represent all the decisions a user can make in our simulated world. I base the rules I use on the observations already present in the data (for example, which users have communicated in the past, and on what topics), as well as a simplified version of some link prediction theory published in 2009.<sup class="endnote"><a href="b01.xhtml#c06-endnote-006" id="c06-noteref-006">6</a></sup><em> Link prediction theory</em> attempts to describe how edges in a graph have formed previously and use that information to predict how they’ll form in the future. </p>
<p>Our goal in designing the rules for the FSM is to accurately simulate which users might form connections, dissolve their association with other users, or pass information along to their connections. We’ll then look at how we can enhance the simulation by adding an adversary who is working to disrupt the network. This allows us to move into the realm of “what if” simulations. What if the head of HR suddenly leaves the company? What if the router in the office crashes? You’ll start seeing chances to apply simulations everywhere. After reading through this implementation, think about the rules and assumptions we’ve built up and how you might improve the simulation with more realistic constraints and behaviors.</p>
<h3 id="h2-502567c06-0004">Modeling User Interaction</h3>
<p class="BodyFirst">To answer the question “How far is information likely to spread from a given node?” we can simulate a message <em>q</em> propagating through the network by being transmitted from one user to another, and determine how many users are likely to receive the message. We’ll model the user interactions by generating biased random walks for the message to move from node to node. Assume, for the moment, that only one copy of the message can exist at a time. (See “<span class="xref" itemid="xref_target_Modeling Information Flow"><a href="#h2-502567c06-0006">Modeling Information Flow</a></span>” for handling multiple copies <span epub:type="pagebreak" id="Page_101" title="101"/>of a message.) Think of this like a budget report making its way around an office. As each employee reads the report, they decide whether to forward it on to one of their coworkers. Because the report is sensitive, no one is allowed to make copies, so only one person can be holding the information at any given time. By selecting a starting node and allowing the message to propagate probabilistically, we can simulate possible paths the report is likely to follow, then count the unique nodes that eventually received the message. The average count of unique nodes after all the walks have been completed can be seen as the number of nodes likely to receive the information originating from the selected starting node.</p>
<p>For a Monte Carlo simulation, you must define the state machine that will act as the core of the system. The social network graph nodes (the users) represent states the message can occupy in the FSM. Edges indicate potential transitions between states (which is based on past communications between users). In the beginning of our simulations these will remain static, and we’ll be examining the network as it exists at the current point in time. (In the proof of concept for this chapter, the edges will change to simulate users making and severing connections within the network.) Finally, the input alphabet, which defines valid actions for the available transitions, models interactions between nodes (for example, one user passing the message to another). Defining inputs and transitions for the FSM is similar to defining what are valid choices and when. For the first question, which deals with information transmitted between nodes, the input alphabet is [<em>Send</em>, <em>Pass</em>], representing the two actions a user may take when they receive a piece of information. </p>
<p>To start, we’ll define the initial state <em>S</em><sub>0</sub> as the node with the highest out-degree holding the message, so the simulation has the best chance of reaching a large number of unique nodes on different simulations. Later, we’ll measure the effect of starting from different nodes. The node holding the message at any given moment is <em>u</em>(<em>q</em>). </p>
<p>At each step in a random walk, the node <em>u</em>(<em>q</em>) uniformly selects one of two possible inputs Ξ = [<em>Send</em>, <em>Pass</em>]. The a priori probability of an input being selected is:</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06004.png"/></figure>

<p> <em>Pr</em> (Ξ<sub><em>(Send)</em></sub>) denotes the probability of <em>Send</em>. If <em>u</em>(<em>q</em>) chooses <em>Send</em>, <em>q</em> is passed to a uniformly selected neighbor of <em>u</em>(<em>q</em>) (I still denote the neighbors of a node as Γ<sub><em>(u)</em></sub>). If <em>Pass</em> is chosen, <em>u</em>(<em>q</em>) does nothing for that step. </p>
<p>The a priori probability of a given neighbor <em>v</em> being selected is:</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06005.png"/></figure>

<p>Here <span class="math" title="v in %iGAMMA sub ( u sup (q) )"><span class="mi">v</span> <span class="mo">∈</span> <span class="mi">Γ</span><span class="msub"><span class="mo">(</span><span class="msup"><span class="MathSubscript">u</span><span class="MathParenSubSuperscript">(</span><span class="MathSubSuperscript">q</span> <span class="MathParenSubSuperscript">)</span></span> <span class="mo">)</span></span></span>. Simply put, this means the starting probability for each neighbor is equal. The larger the number of neighbors a node has, the lower the probability of any one neighbor receiving the message next. For <span epub:type="pagebreak" id="Page_102" title="102"/>example, if <em>u</em>(<em>q</em>) has three neighbors (<span class="math" title="abs { %iGAMMA sub (u sup (q)) }=3"><span class="mo">|</span><span class="mi">Γ</span><span class="msub"><span class="mo">(</span><span class="msup"><span class="MathSubscript">u</span><span class="MathParenSubSuperscript">(</span><span class="MathSubSuperscript">q</span><span class="MathParenSubSuperscript">)</span></span><span class="mo">)</span></span><span class="mo">|</span> <span class="mo">=</span> <span class="MathOperand">3</span></span>), then <span class="GraphicInline eq"><img alt="m06006r" src="image_fi/502567c06/m06006r.png"/></span>. You could also write this as a conditional probability (<em>Pr</em>(<em>A</em>|<em>B</em>)):</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06007.png"/></figure>

<p>The formula states that the probability of a particular neighbor receiving the message, given the input is <em>Send</em>, is 0.33, or 33 percent.</p>
<p>The overall probability of a message propagating without presuming that <em>Send</em> is the selected input is defined in the numerator of the previous equation. Intuitively, you can think of this as the probability of each event occurring in isolation. More properly, the independent probability of a message propagating forward to a given neighbor of <em>u</em>(<em>q</em>) (assuming three neighbors) is:</p>
<p class="MathEquation"><span class="math" title="Pr( u sup (q) rightarrow v) = {Pr( %iXI sub ( Send ) and v sup (q))} = {0.5 * 0.33}=0.165"> <span class="mi">Pr </span><span class="mo">(</span><span class="mi">u</span><span class="msup"><span class="mo">(</span><span class="mi">q</span><span class="mo">)</span></span> <span class="mo">→</span> <span class="mi">v</span> <span class="mo">)</span> <span class="mo"> = </span> <span class="mi">Pr</span> <span class="mo">(</span> <span class="mi">Ξ</span><span class="msub"><span class="mo">(</span> <span class="MathSubscript">Send</span> <span class="mo">)</span></span> <span class="mo">∧</span> <span class="mi">v</span><span class="msup"><span class="mo">(</span><span class="mi">q</span><span class="mo">)</span></span> <span class="mo">)</span> <span class="mo"> = </span> <span class="mn">0.5</span> <span class="mo">×</span> <span class="mn">0.33</span> <span class="mo"> = </span> <span class="mn">0.165</span></span></p>
<p>Before we generate random walks, we need to set up the simulation, as shown in <a href="#listing6-1" id="listinganchor6-1">Listing 6-1</a>.</p>
<pre><code><span aria-label="annotation1" class="CodeAnnotationHang">❶</span> XI = ["send", None]
<span aria-label="annotation2" class="CodeAnnotationHang">❷</span> k = 10
n = 10
out_deg = G.out_degree()
valkey_sorted = sorted(out_deg, key=lambda x: (x[1], x[0]))
<span aria-label="annotation3" class="CodeAnnotationHang">❸</span> S0 = valkey_sorted[-1][0]</code></pre>
<p class="CodeListingCaption"><a id="listing6-1">Listing 6-1</a>: The initialization code for the Monte Carlo simulation</p>
<p>The code relies on the graph <em>G</em> being populated using the method back in Listings <span class="xref" itemid="xref_target_5-2">5-2</span> and <span class="xref" itemid="xref_target_5-4">5-4</span>. Assuming the graph <em>G</em> has already been populated, we start with the input alphabet <code>XI</code>, which represents <em>Send</em> as expected and <em>Pass</em> using <code>None</code> <span aria-label="annotation1" class="CodeAnnotation">❶</span>; the number of simulations, <code>k</code> <span aria-label="annotation2" class="CodeAnnotation">❷</span>; and the number of steps in each simulation, <code>n</code>. To set the start state <code>S0</code> <span aria-label="annotation3" class="CodeAnnotation">❸</span>, we select the node with the highest out-degree. </p>
<p>Continuing from <a href="#listing6-1">Listing 6-1</a>, <a href="#listing6-2" id="listinganchor6-2">Listing 6-2</a> shows a deterministic, uniformly random implementation of the message-passing Monte Carlo simulation algorithm.</p>
<pre><code>from random import choice
<span aria-label="annotation1" class="CodeAnnotationHang">❶</span> R = []
<span aria-label="annotation2" class="CodeAnnotationHang">❷</span> for i in range(k):
  <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> message_at = S0
    Tn = []
  <span aria-label="annotation4" class="CodeAnnotationCode">❹</span> for j in range(n):
        if choice(XI) is not None:
          <span aria-label="annotation5" class="CodeAnnotationCode">❺</span> gamma_uq = list(nx.neighbors(G, message_at))
          <span aria-label="annotation6" class="CodeAnnotationCode">❻</span> if len(gamma_uq) &gt; 1:
                vq = choice(gamma_uq)
                Tn.append((message_at, vq))
                message_at = vq
            elif len(gamma_uq) == 1:
<span epub:type="pagebreak" id="Page_103" title="103"/>                vq = gamma_uq[0]
                Tn.append((message_at, vq))
                message_at = vq
          <span aria-label="annotation7" class="CodeAnnotationCode">❼</span> else:
                conc = "Message terminated at node %s in %d steps"
                print( conc % (message_at, len(Tn)))
                break
  <span aria-label="annotation8" class="CodeAnnotationCode">❽</span> R.append((message_at, Tn))
tot = 0
<span aria-label="annotation9" class="CodeAnnotationHang">❾</span> for end, path in R:
    uniq = unique(path)
    tot = len(uniq) - 1
<span aria-label="annotation10" class="CodeAnnotationHang">❿</span> print(S0, (tot / len(R)) / (len(G.nodes.keys()) - 1))</code></pre>
<p class="CodeListingCaption"><a id="listing6-2">Listing 6-2</a>: A deterministic message-passing Monte Carlo simulation</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	This code is in the 3rd cell of the <em>MonteCarloSimulation.ipynb</em> notebook in the chapter’s supplemental material, wrapped in a function called <code>run_sim_1</code>. </p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>First, we initialize the results list <code>R</code> <span aria-label="annotation1" class="CodeAnnotation">❶</span>, and then we use nested <code>for</code> loops <span aria-label="annotation24" class="CodeAnnotation"><span class="CodeAnnotation">24</span></span> to perform <code>k</code> random walks with up to <code>n</code> steps in each. </p>
<p>Each walk begins with the message at the node <code>S0</code> <span aria-label="annotation3" class="CodeAnnotation">❸</span>. At each step, we gather the neighbors for the currently selected node <span aria-label="annotation5" class="CodeAnnotation">❺</span>. If exactly one neighbor exists, this neighbor is automatically selected. However, if more than one neighbor exists <span aria-label="annotation6" class="CodeAnnotation">❻</span>, we select one uniformly at random using the <code>choice</code> function, then update the <code>message_at</code> variable. If the message ever reaches a node with no out-degree <span aria-label="annotation7" class="CodeAnnotation">❼</span>, we record the node as the result and conclude the walk with <code>break</code>. At the end of each walk, we append the terminating node <code>Tn</code> to the results list <span aria-label="annotation8" class="CodeAnnotation">❽</span>.</p>
<p>We summarize the likely <em>information flow distance</em>, or <em>IFD</em> (<span class="GraphicInline eq2"><img alt="m06008" src="image_fi/502567c06/m06008.png"/></span>), as the mean number of unique nodes (disregarding the starting node) in each path <span aria-label="annotation9" class="CodeAnnotation">❾</span>, then normalize the IFD by the total number of nodes in <code>G</code> (again, disregarding the starting node) <span aria-label="annotation10" class="CodeAnnotation">❿</span> and print it out to the screen. The <code>unique</code> function simply takes the path and reduces it to only unique entries. (You can see how I implemented it in the 2nd cell of the <em>MonteCarloSimulations.ipynb</em> notebook in the chapter’s supplemental materials. You can also choose to use one of the library’s versions of the code, such as NumPy’s <code>unique</code>.)</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	The absolute value of a list with repeated items is the length of its set equivalent; that is, |<em>T</em><sub><em>(n)</em></sub>| counts only the unique elements in the random walk, even if the message passes to the same user more than once. </p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>If you run the code in <a href="#listing6-2">Listing 6-2</a> a few times, you’ll notice the output isn’t consistent. While <em>S</em><sub><em>0</em></sub> is deterministic, the route from there is stochastic. You could edit this model to be entirely deterministic by replacing the <code>vq = choice(gamma_uq)</code> call with a deterministic selection method, such as always passing <em>q</em> to the neighbor of <em>u</em>(<em>q</em>) with the highest out-degree. This would be a good option to model a specific behavior pattern that’s known in advance. </p>
<p><span epub:type="pagebreak" id="Page_104" title="104"/>To implement the simulation with a biased walk instead of a uniformly random walk, you can add another element to <code>XI</code> that is the same as one already present. By doing so, you change the relative probabilities of each input variable being selected. For example, adding another <code>"send"</code> to the list will weight <em>Send</em> to twice as likely as <em>Pass</em>:</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06009.png"/></figure>

<p>For more fine-tuned control over the probability (bias) of each input, switch out the simple <code>choice</code> function for one that can process a dictionary of <code>{action: probability}</code> definitions. (See the proof of concept at the end of the chapter for an example.)</p>
<p>Congratulations, you’ve now defined your first predictive model using Monte Carlo simulations! This is a simplistic model where we rely on uniform selection for randomness and some basic actions, like send and pass, to describe what might occur to some arbitrary message on our network. Try starting the message from different users and see how it impacts the number of steps the message travels and where it ends up. We refer to this as a <em>naive model</em>, because we didn’t include any specific information about the history of the network, message contents, or user preferences. We assume each node is equally likely to send any message to any other node it can contact. While simplifying assumptions like this make the code easier to write and interpret, they do so at the expense of accuracy. In the next section, we’ll extend our model to incorporate more details about the message and users to more accurately predict the probable flow of information given what we’ve already witnessed about data flow in the network.</p>
<h3 id="h2-502567c06-0005">Modeling Topic-Based Influence</h3>
<p class="BodyFirst">To answer the question “Which nodes are being influenced by other nodes?” we’ll extend the investigation of topic-based influence from <span class="xref" itemid="xref_target_Chapter 5"><a href="c05.xhtml">Chapter 5</a></span>. Recall that we previously weighed each user’s potential interest in a topic by measuring their interaction with other messages containing the same topic, using the Hyperlink-Induced Topic Search algorithm (HITS). If we reframe our current model with respect to a given message topic, like the environment, we can incorporate hub and authority information into our state machine model to control the information exchange probability. In this case, we’ll use a user’s HITS score to determine the probability of a message being reblogged based on the message’s content, instead of just blindly assuming all messages have the same probability for all users all the time. </p>
<p>Modeling message propagation in this fashion assumes that a user is more likely to reblog a message similar to a message they have reblogged previously. Users who have reblogged posts involving a given topic get a higher authority score for that topic than those who haven’t, which translates to a higher probability of receiving a message about that topic. If you think about the content you see on people’s social network feeds, you’ll probably see a fairly common theme among the information they share and <span epub:type="pagebreak" id="Page_105" title="105"/>reshare (this is one of those assumptions you may want to challenge later). Some people choose to share business news; others, arts and entertainment; and still others, security. </p>
<p>Let’s update the previous implementation to compare the spread of different message types (<em>qx</em>) so we can examine the interests of different users and predict what messages they’re most likely to reblog in the future. If you were designing a viral message attack for this network, it would make sense for you to examine different topics and choose the one with the highest probability of propagating farthest through the network. From a defensive perspective, you can flip this analysis and track a malicious message back to the probable source. We’ll be keeping the same definition of influence between users (so a user reblogging a message is influenced by that message to some degree), but instead of using the <em>Send</em> action, our nodes will be selecting messages to reblog. Nothing about the action changes, so I’ve opted to keep the name, but renaming it might help to keep the direction of influence clear in your model.</p>
<p><a href="#listing6-3" id="listinganchor6-3">Listing 6-3</a> shows the code to run a topic-based message-passing Monte Carlo simulation: </p>
<pre><code>import graph_funcs as ext
qx = "environment"
<span aria-label="annotation1" class="CodeAnnotationHang">❶</span> hG = term_subgraph(qx, post_df)
hub_scores, auth_scores = nx.hits(hG, max_iter=1000, tol=0.01)
hub_max = max(hub_scores.values())
S0_i = list(hub_scores.values()).index(hub_max)
<span aria-label="annotation2" class="CodeAnnotationHang">❷</span> S0 = list(hub_scores.keys())[S0_i]

for i in range(k):
    uq = S0
    Tn = []
    for j in range(n):
      <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> send_msg = ext.hub_send(hub_scores[uq])
        if send_msg:
          <span aria-label="annotation4" class="CodeAnnotationCode">❹</span> vq = ext.scored_neighbor_select(hG, uq, auth_scores)
            if vq is None:
                conc = "Message terminated at node %s in %d steps"
                print( conc % (uq, len(Tn)))
                break
            else:
                Tn.append((uq, vq))
              <span aria-label="annotation5" class="CodeAnnotationCode">❺</span> uq = vq
    R.append((uq, Tn))
ended_at = {}
<span aria-label="annotation6" class="CodeAnnotationHang">❻</span> for end, path in R:
    if end in ended_at.keys():
        ended_at[end] += 1
    else:
        ended_at[end] = 1
return (S0, ended_at)</code></pre>
<p class="CodeListingCaption"><a id="listing6-3">Listing 6-3</a>: A topic-based message-passing Monte Carlo simulation</p>
<p><span epub:type="pagebreak" id="Page_106" title="106"/>This code prints a tuple of <code>(S0, {node: termination_count})</code>, using the same values for <code>k</code> and <code>n</code> defined in <a href="#listing6-1">Listing 6-1</a>, as well as the <code>term_subgraph</code> function <span aria-label="annotation1" class="CodeAnnotation">❶</span>, which is based on code you’ll see later in <a href="#listing6-5" id="listinganchor6-5">Listing 6-5</a>. </p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	This code is in the 4th cell of the <em>MonteCarloSimulations.ipynb</em> file in the chapter’s supplemental materials in a function named called <code>run_sim_2</code>. </p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>In this simulation, <em>S</em><sub>0</sub> <span aria-label="annotation2" class="CodeAnnotation">❷</span> is the node with the highest hub score for the selected topic (<em>S</em><sub>0</sub> = <em>max</em>(<em>hub</em>(<em>qx</em>)(<em>G</em>))), and <em>Pr</em> (Ξ<sub><em>(Send)</em></sub>) is the hub score of <em>u</em>(<em>q</em>) for the message type <em>x</em>: <em>Pr</em> (Ξ<sub><em>(Send)</em></sub>) = <em>hub</em><sub><em>(qx)</em></sub>(<em>u</em>). The <code>hub_send</code> function (defined in the <em>graph_funcs.py</em> file, provided in the book’s supplementary materials) takes the hub score of <code>uq</code> and returns whether <code>uq</code> passes the message on <span aria-label="annotation3" class="CodeAnnotation">❸</span>. The <code>hub_send</code> function is based on another function, <code>weighted_choice</code>, which is also included in the <em>graph_funcs.py</em> file. There are still only two possible actions in Ξ, so the probability of <em>Pass</em> is equal to 1 minus the probability of <em>Send</em>: <em>Pr</em> (Ξ<sub><em>(Pass)</em></sub>) = 1 – <em>Pr</em> (Ξ<sub><em>(Send)</em></sub>). The probability for selecting a given neighbor is the normalized authority score for that neighbor, given the message type <em>qx</em> (<em>Pr</em>(<em>v</em>(<em>qx</em>)) = <em>auth</em>(<em>qx</em>)(<em>v</em>)). </p>
<p>If the message is sent, we select the neighbor using the <code>scored_neighbor_select</code> function (also defined in the <em>graph_funcs.py</em> file and based on the <code>weighted_choice</code> function) <span aria-label="annotation4" class="CodeAnnotation">❹</span>. If a neighbor is returned, we add the edge between the sender and recipient to the path <code>Tn</code> and update the message location <span aria-label="annotation5" class="CodeAnnotation">❺</span>; otherwise, we terminate the simulation with the <code>break</code> statement. </p>
<p>If we assume a message ending at a node imparts some influence, we can count how many times a message ends at a particular user and claim that the node with the highest count is most likely to be influenced by the given message type from the given user. This intuitively means that the user would likely end up reblogging the message at some point. All roads lead home, so to speak. To find this node, we loop over the ending locations and tally the results to build the <code>{node: termination_count}</code> dictionary <span aria-label="annotation6" class="CodeAnnotation">❻</span>, then print the results. This constitutes one run of the Monte Carlo simulation. </p>
<p>We want to collect several runs and average the results for the most accurate predictions, so we wrap the code in a function definition called <code>run_sim_2</code>, which will take in the topic list and the Mastodon post data as parameters. (You can see the <code>run_sim_2</code> function in the 4th cell of the <em>MonteCarloSimulation.ipynb</em> notebook.) Finally, we return the source node and the dictionary containing the users at whom the message terminated, so we can collect the results until we’re ready to analyze them. Let’s call this newly defined function in a loop to collect a reasonable sample size. <a href="#listing6-4" id="listinganchor6-4">Listing 6-4</a> shows how to collect the samples and average them for the final output.</p>
<pre><code>all_runs = {}
started_at = ""
<span aria-label="annotation1" class="CodeAnnotationHang">❶</span> for run_i in range(0, 10):
  <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> started_at, results = run_sim(["environment"], post_df)
  <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> for ks in results:
        if ks in all_runs.keys():
            all_runs[ks] += results[ks]
<span epub:type="pagebreak" id="Page_107" title="107"/>        else:
            all_runs[ks] = results[ks]
<span aria-label="annotation4" class="CodeAnnotationHang">❹</span> for node in all_runs.keys():
    if node != started_at:
        print("%s influenced %s an average of %.2f times" % (
            started_at, node, all_runs[node]/10
        ))</code></pre>
<p class="CodeListingCaption"><a id="listing6-4">Listing 6-4</a>: Averaging the Monte Carlo simulation results</p>
<p>Here are the results from averaging 10 runs of the simulation:</p>
<pre><code>gutierrezjamie influenced iwatkins an average of 1.80 times
gutierrezjamie influenced hartmanmatthew an average of 2.20 times
gutierrezjamie influenced shannon42 an average of 0.90 times
gutierrezjamie influenced daniel99 an average of 0.70 times
gutierrezjamie influenced garciajames an average of 1.00 times
gutierrezjamie influenced grosslinda an average of 0.30 times</code></pre>
<p>Using these results, we could claim that the user <code>gutierrezjamie</code> is most likely to influence <code>hartmanmatthew</code> on the topic of environment. What’s important here isn’t the numbers themselves but the relative sizes of the numbers, so you might also conclude that <code>shannon42</code> is three times more likely than <code>grosslinda</code> to end up reblogging the message. Of course, this is just the result of one small group of simulations. Ten simulations on a topic as complex as information flow and influence is hardly definitive. To strengthen this claim of influence, repeat the simulations some large number of times by increasing <em>k</em> (using the statistical method mentioned earlier) and average those results. In general, the more possible outcomes for the simulation, the more times it should be run. There’s a point of diminishing returns to this, though. You’ll want to experiment with different simulation counts and lengths by updating the values for <em>k</em> and <em>n</em>, respectively.</p>
<p>The last part of the code we’re going to examine is the <code>term_subgraph</code> function, which we called in <a href="#listing6-3">Listing 6-3</a>. The function in <a href="#listing6-5">Listing 6-5</a> takes in a term of interest and searches the underlying data to find all relevant posts.</p>
<pre><code>def term_subgraph(term, df):
    dat_rows = df[df["text"].str.contains(term)]
    dat_replies = df[df["in_reply_to_id"].isin(dat_rows["id"].values)]
    hG = nx.DiGraph()
    for idx in dat_replies.index:
        row = dat_replies.loc[idx]
        hG.add_edge(row["in_reply_to_screen_name"], row["user_screen_name"])    
    return hG</code></pre>
<p class="CodeListingCaption"><a id="listing6-5">Listing 6-5</a>: Defining the subgraph based on terms </p>
<p>The function takes in the term we’re interested in searching for and the <code>post_df</code> <code>DataFrame</code> object we defined previously. Using the <code>str.contains</code> function, we filter the data down to only rows whose text column contains the search term. We then collect the replies to these posts by searching the <code>in_reply_to_id</code> column for any relevant post IDs, storing them in a <code>DataFrame</code> <span epub:type="pagebreak" id="Page_108" title="108"/>called <code>dat_replies</code>. Next, we define the <code>DiGraph</code> object that will hold the resulting graph data and store it in a variable named <code>hG</code>. We loop over the <code>dat_replies</code> index list, and, for each entry, we look up the row associated with the index. We use the row’s <code>in_reply_to_screen_name</code> and <code>user_screen_name</code> to create an edge in the graph, showing the direction of influence on the topic of interest. Once we’ve completed the loop, we return the completed subgraph.</p>
<p>Now that we’ve defined all the basic code we’ll need, we can start to improve upon our simple model. In the next section, we’ll cover how to make our message behave more realistically through resource allocation.</p>
<h3 id="h2-502567c06-0006">Modeling Information Flow</h3>
<p class="BodyFirst">So far, our simulation treats the message like a single object moving from node to node, like a package being delivered to an address. But what about the cases where a message may be transferred to multiple users simultaneously? Our model is fine for single copies of messages, but it’d be nice if we could find a way to model the information more intuitively as flowing through the network instead. Think about it like this: you don’t send one birthday party invitation and ask each invitee to pass the message on to the next person on the list; you send multiple invitations to the people you want to attend. Each invitee may then invite another person to go to the party with them, so the message spreads even further along the network simultaneously. To model this type of information flow, we need to improve our state machine to treat the message as if multiple copies exist.</p>
<p>To simulate the case where more than one copy of <em>q</em> can exist, we can reformulate message passing as a question of resource flow within the network. By doing so, we can figure out how much information two people have communicated in the past and use that as an indicator of how much they may communicate in the future. <em>Resource allocation (RA)</em> is a model that was first posed to describe the nonlinear correlation between airport connectivity and travel capacity.<sup class="endnote"><a href="b01.xhtml#c06-endnote-007" id="c06-noteref-007">7</a></sup> We’ll be using the same principle as a way to quantify the quality of information exchange as the message spreads through the network. </p>
<p>Generally speaking, RA describes the potential flow of resources between two nodes (<em>u</em>, <em>v</em>) where <em>v</em> is not a neighbor of <em>u</em>, but they’re connected by a directed path (<em>v </em>∉ <em>Γ</em><sub>(</sub><sub><em>u</em></sub><sub>) </sub>∧ ρ(<em>u</em>→<em>v</em>) ∈ <em>E</em>). Supposing a node <em>u</em> in a directed graph has one unit of resources to distribute evenly among all its direct neighbors, the resources allocated to any member of the network is the sum of the resources at the end of each path between <em>u</em> and <em>v</em>: </p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06010.png"/></figure>

<p>You can think of this value as the importance of node <em>v</em> in the case of distribution for node <em>u</em>. If |ρ(<em>u</em>, <em>v</em>)| &gt; 2, this process is repeated for all nodes between, until some amount of resource reaches <em>v</em>. Therefore, you might instead wish to think of this value as the amount of resources <em>u</em> provides to <em>v </em>through the distribution network. </p>
<p><span epub:type="pagebreak" id="Page_109" title="109"/>As a concrete example, suppose you’re investigating a criminal organization that sells counterfeit goods it purchases from a forger. The boss of this hypothetical organization buys 100 boxes of knock-off handbags (the initial amount of resources at <em>S</em><sub>0</sub>). He then distributes the merchandise to his top 4 lieutenants by dividing the 100 boxes into 25 boxes for each. Finally, each lieutenant divides their 25 boxes among their street corner shops. If each lieutenant has connections to 5 storefronts, each store would get 5 boxes. If the crime boss were to lose one of these stores, the loss would account for only 5 percent of his inventory. This is a very simplistic model that assumes each node and path can evenly carry the resource in question. However, that’s not always the case. </p>
<p>Formally, the <span class="GraphicInline eq3"><img alt="m06011" src="image_fi/502567c06/m06011.png"/></span> portion of the previous formula is known as the <em>flow function</em>, which models a specific type of behavior for passing or receiving resources. Using this flow function, the resource gets divided evenly among all the neighbors of the node <em>u</em>, the same as the boxes of counterfeit goods. There are a few different flow functions built into NetworkX. Unfortunately, they’re not implemented for directed graphs as defined here. As you shift from research to applications, you’ll often be responsible for extending your code libraries with missing definitions like this. The <em>graph_funcs.py</em> file includes the code for directed resource allocation, so you can use it to experiment.</p>
<p>By combining the historical analysis of the HITS algorithm with the simultaneous flow of resource allocation, we can create a respectable model, capable of simulating user behavior based on previous observations. You should be able to build on this framework of state machines and Monte Carlo simulation to model all sorts of interesting phenomena, not just in social networks but throughout the topic of information security as a whole. </p>
<p>In the next section, we’ll move on to a proof-of-concept application that will take us deeper into applied game theory and Monte Carlo simulation by simulating an adversarial face-off on our social network platform. Let’s get ready to rumble!</p>
<h2 class="HeadProject" id="h1-502567c06-0003"><span>The Proof of Concept: Disrupting the Flow of Information</span></h2><h2 id="h1-502567c06-0004"/>
<p class="BodyFirst">The final question for this chapter—“What links could be severed to disrupt the flow of information between two nodes?”—is a very interesting security topic. There are many scenarios in which disrupting the flow of information to a particular subset of nodes could be catastrophic. Imagine a hospital tied to a single source of electricity. To disconnect any outlet in the hospital from electricity, you’d only need to sever the single link between the hospital and its power source. This is a <em>single point of failure</em>, and to avoid it hospitals deploy multipoint connections to the power grid and install backup generators for more severe disruptions. Many home networks suffer from this design flaw as well. To sever all the connected devices behind the router, you simply need to sever the connection forward of the router. In social networks, like businesses, failure points like these occur regularly. Companies often have people known as “linchpin employees”<span epub:type="pagebreak" id="Page_110" title="110"/><sup class="endnote"><a href="b01.xhtml#c06-endnote-008" id="c06-noteref-008">8</a></sup> who fill roles no other employees can, or possess arcane knowledge the company needs to operate. Linchpin employees inspired the proof of concept for this chapter: Monte Carlo simulations to model the potential to disrupt information flow within an evolving social network.</p>
<p>For the rest of this chapter, we’ll be building a simulation where our social network is under attack from a nefarious outsider. We’ll use some of the same analysis techniques that gave birth to the modern internet to see how difficult it would be to disrupt our social network. Sometimes it’s fun to be the bad guy!</p>
<h3 id="h2-502567c06-0007">Modeling an Evolving Network</h3>
<p class="BodyFirst">In a static network, you could find the set of edges that, when removed, would separate two nodes (you’ll see a method for producing this list in a moment), but that doesn’t account for network adaptations, like cross-training another employee in the linchpin employee’s arcane knowledge to alleviate a single point of failure. To model an evolving network, we’ll mimic a two-player, turn-based game scenario, wherein one player tries to get a message through from a starting user to an end user as their adversary tries to stop the message from reaching the end. To make the game more complex, the network itself evolves on each turn as users reblog messages from other users or disconnect from people who were previous connections. Player 1 acts on the part of the network and all its users, while player 2 acts as the adversarial force. Player 1’s goal is to send a message <em>u</em> from a source node (<em>u</em>A) to a sink node (<em>v</em><sub>Ω</sub>). Player 2 seeks to keep this message from reaching the sink node by selectively removing paths from the network. The game play is broken up into three phases: network adaptations, message movement, and finally adversarial movement (in that order).</p>
<p>The game is over if <em>q</em> reaches <em>v</em><sub>Ω</sub>, or when no path exists to complete the transmission:</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06012.png"/></figure>

<p>This equation can be translated into the convenient helper function in <a href="#listing6-6" id="listinganchor6-6">Listing 6-6</a>.</p>
<pre><code>def check_win(G, uq, omega):
  <span aria-label="annotation1" class="CodeAnnotationCode">❶</span> if uq != omega and nx.has_path(G, uq, omega):
        return None
  <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> elif uq == omega:
        return 1
  <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> elif not nx.has_path(G, uq, omega):
        return -1</code></pre>
<p class="CodeListingCaption"><a id="listing6-6">Listing 6-6</a>: Checking for terminal conditions </p>
<p>This function takes in the graph object, the ID of the node currently holding the message, and the ID of the goal node. If these two nodes aren’t the same and there’s a path between them <span aria-label="annotation1" class="CodeAnnotation">❶</span>, the game isn’t over, so <span epub:type="pagebreak" id="Page_111" title="111"/>the code returns <code>None</code> (as in no winner). If the two nodes aren’t equal and there’s no path between the current node and the goal node <span aria-label="annotation3" class="CodeAnnotation">❸</span>, player 2 has succeeded in isolating the message, and the function returns <code>-1</code>. If the two IDs match <span aria-label="annotation2" class="CodeAnnotation">❷</span>, the message has reached the goal node, so the function returns <code>1</code>.</p>
<h3 id="h2-502567c06-0008">Moving the Message Through the Network</h3>
<p class="BodyFirst">The second helper function, <code>weighted_choice</code>, shown in <a href="#listing6-7" id="listinganchor6-7">Listing 6-7</a>, will be used for weighted random selection of the next node to a receive the message.</p>
<pre><code>def weighted_choice(scores):
    totals = []
    running_total = 0
  <span aria-label="annotation1" class="CodeAnnotationCode">❶</span> for w in scores.values():
        running_total += w
        totals.append(running_total)
  <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> rnd = random() * running_total
    for i in range(len(totals)):
      <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> if rnd &lt;= totals[i]:
            key = list(scores.keys())[i]
            return key</code></pre>
<p class="CodeListingCaption"><a id="listing6-7">Listing 6-7</a>: Weighted random selection function for biased walks</p>
<p>The input parameter <code>scores</code> is a dictionary of <code>{item: weight}</code>, giving each item that may be selected and its weight. (The weights do not need to sum to 1; only the relative size of the values matters.) The <code>totals</code> list partitions the real number space between 0 and the sum of the weights (<span class="GraphicInline eq2"><img alt="m06013" src="image_fi/502567c06/m06013.png" style="margin-top:0px;"/></span>) into bins proportional in size to the weight of the item they represent, by adding each item to a <code>running_total</code>, then recording the running total after each item is added <span aria-label="annotation1" class="CodeAnnotation">❶</span>. The sum of all the weights then scales a random value <span aria-label="annotation2" class="CodeAnnotation">❷</span> to fall into one of the bins, and the bin determines which item is selected <span aria-label="annotation3" class="CodeAnnotation">❸</span>. Items with larger weights map to larger bins, meaning the items are more likely to be selected, hence “weighted random selection.”</p>
<p>As a concrete example, take an input dictionary <code>{"A":1,"B":2,"C":3}</code>. After the first loop executes, the <code>totals</code> list contains <code>[1,3,6]</code> and the <code>running_total</code> is <code>6</code>. The random real value <code>rnd</code> (between 0 and 1) is selected using the <code>random</code> function, then multiplied by <code>running_total</code> <span aria-label="annotation2" class="CodeAnnotation">❷</span> to produce the percentage of the weight randomly selected. The random value <code>1.0</code> means the maximum weight, in this case:</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06014.png"/></figure>

<p>We can verify that the break points accurately reflect our input weights by calculating the amount of space on the number line assigned to the key, called its <em>key space</em>. These should equate to 1 / 6 = 0.166, 2 / 6 = 0.333, and 3 / 6 = 0.5 for keys <code>A</code>, <code>B</code>, and <code>C</code>, respectively. We find the key space by subtracting the key’s lower selection boundary from its upper selection boundary. To <span epub:type="pagebreak" id="Page_112" title="112"/>select key <code>A</code>, <code>rnd</code> must be lower than or equal to approximately 0.166 (0.166 × 6 = 0.996). To select key <code>B</code>, <code>rnd</code> needs to be between 0.166 and 0.5 (0.5 × 6 = 3), which means the key space for <code>B</code> is (0.5 – 0.166 = 0.333). We can divide <code>B</code>’s key space by <code>A</code>’s to get a relative size comparison (0.333 / 0.166 = 2.006), which means the key space for <code>B</code> is twice the size of the one for <code>A</code>, just as we requested. Finally, <code>rnd</code> needs to be greater than 0.5 and less than or equal to 1.0 for key <code>C</code> to be selected. The key space for <code>C</code> is (1 – 0.5 = 0.5). You can continue the key space logic to prove that the space provided to <code>C</code> is three times the space provided for <code>A</code> (0.5 / 0.166 = 3.0) and one and a half times larger than the key space for <code>B</code> (0.5 / 0.333 = 1.5). I hope this helps to illustrate how the values in our input dictionary control the size of the key space created during the random selection process. We’ll be relying heavily on the <code>weighted_choice</code> function during our proof, so it’s worth taking the time to understand it in detail.</p>
<h3 id="h2-502567c06-0009">Measuring the Amount of Information Flow</h3>
<p class="BodyFirst">Some connections between nodes in a network may be capable of carrying more information than others. In a social network, for example, some members may be more effective at spreading information, like a linchpin employee at a company. The amount of information flow between two nodes in a social network isn’t straightforward to measure, and depends on your research question. For the purposes of our simulation game, the edge capacity is the number of characters in a given post (maximum 500, at the time of writing). </p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	The number of characters in the text body associated with each edge just measures raw data flow between nodes, and naively assumes all data translates equally to information. See the chapter’s summary for recommended reading on other heuristic measures for measuring information in text. </p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>By adding an attribute named <em>capacity</em>, which represents the maximum amount of information that can be transmitted along the particular edge in one unit of time, to the edges in <em>E</em>, we can compare the effect of removing different subsets of edges on the overall flow and capacitance of the network using the <em>max-flow, min-cut theorem</em>.<sup class="endnote"><a href="b01.xhtml#c06-endnote-009" id="c06-noteref-009">9</a></sup> We’ll take a deeper look at this theorem when we improve player 2, but for the moment just know that it allows us to model a resource that gets spread out across a network, rather than moving from point to point as we’ve seen previously.</p>
<p>Now is a good time to step back and remember why this matters to us. Our ultimate goal is to test how difficult it would be for an adversary to significantly disrupt the communication of the network. The max-flow, min-cut theorem gives us the information needed to test if two nodes can still communicate (because there’s still a path between the two nodes). It also helps us determine what cuts are more or less advantageous for the adversary, as well as giving them a way to quickly judge their options. An attacker who knows the max-flow, min-cut theory will likely have a much higher chance at sabotaging the network than one who attacks random communication channels. <span epub:type="pagebreak" id="Page_113" title="113"/>We’ll examine this hypothesis by implementing two versions of the adversary in the following game and comparing the damage they can achieve.</p>
<h3 id="h2-502567c06-0010">How the Game Works</h3>
<p class="BodyFirst">The game is actually very simple. The objective for player 1, the white hat, is to get a message from a node on one side of the network to a node on the other side. To achieve this they have the entire network at their disposal. On each turn, they will move the message around the network trying to reach the sink node. They win if the message successfully traverses the network from the source node to the sink node. On the other side of the virtual table is player 2, the black hat. Their job is stop that message, at any cost. On each turn, they’ll select an edge to remove from the network. Player 2 wins if they successfully disconnect the network so that there’s no way the message can reach the sink node. </p>
<h4 id="h3-502567c06-0001">Evolving the Network</h4>
<p class="BodyFirst">Social networks rarely have a static topography: the links and membership are changing even as you try to measure them. The network adaptation phase models the evolving topography by allowing edges to be created or removed probabilistically. This means that new routes may open up suddenly and old paths may disappear on their own. Neither player can fully trust the network to do what they expect it to. I chose to implement this as part of player 1’s turn since they’re the network administrator in this scenario. On each turn, player 1 chooses an input action from the input alphabet for every node that’s not holding the message (∀<em>u</em><sup>(¬</sup><sup><em>q</em></sup><sup>) </sup>∈<em>V wrs</em>(Ξ), where <em>wrs</em>(Ξ) is the weighted random selection function defined previously). <a href="#listing6-8" id="listinganchor6-8">Listing 6-8</a> shows the weighted input alphabet, which includes the creation and dissolution of edges with <code>connect</code> and <code>disconnect</code>, or the option to <code>pass</code> as before.</p>
<pre><code>XI = {
    "connect": 2,
    "disconnect": 1,
    "pass": 2
}</code></pre>
<p class="CodeListingCaption"><a id="listing6-8">Listing 6-8</a>: Weighted inputs for nodes without the message</p>
<p>The weights in <code>XI</code> describe the tendency of the network over time. These values create a scenario where the network is likely to grow over time since <code>connect</code> and <code>pass</code> both have an individual weight of 40 percent (2 / 5 = 0.4), a combined 80 percent of the selection space, while <code>disconnect</code> has only 20 percent. If <code>connect</code> is chosen, the node forms a new edge with (meaning it receives a reply from) another node in the graph, which means we need a way to select the user they connect to. I’ve chosen to implement this based on <em>preferential attachment</em>, the idea that users with many connections are more likely to form new connections than those with fewer connections. In our network, this means that nodes that receive replies from many other users (large out-degrees) are more likely to receive a reply from users who reply to many users (high in-degrees). (Even if the current node doesn’t <span epub:type="pagebreak" id="Page_114" title="114"/>tend to receive many replies, it’s still more likely to get a reply from a more active user.)<sup class="endnote"><a href="b01.xhtml#c06-endnote-010" id="c06-noteref-010">10</a></sup></p>
<p>Formally, the <em>undirected preferential attachment (UPA)</em> score for two nodes (<em>u</em>, <em>v</em>) is the product of the length of their neighbors:</p>
<p class="MathEquation"><span class="math" title="UPA(u,v) =abs {%iGAMMA sub ( u )}*abs {%iGAMMA sub ( v )}"> <span class="mi">UPA</span><span class="mo">(</span> <span class="mi">u, v</span> <span class="mo">)</span> <span class="mo"> = </span> <span class="mo">|</span><span class="mi">Γ</span><span class="msub"><span class="mo">(</span> <span class="MathSubscript">u</span> <span class="mo">)</span></span><span class="mo">|</span> <span class="mo"> × </span> <span class="mo">|</span><span class="mi">Γ</span><span class="msub"><span class="mo">(</span> <span class="MathSubscript">v</span> <span class="mo">)</span></span><span class="mo">|</span></span></p>
<p class="BodyContinued">To account for the directionality of our network graph, we can define <em>directed preferential attachment (DPA)</em> using outgoing neighbors of <em>u</em> and incoming neighbors of <em>v</em>:</p>
<p class="MathEquation"><span class="math" title="DPA(u rightarrow v) =abs {%iGAMMA sub ( u rightarrow)}*abs {%iGAMMA sub ( v leftarrow)}"> <span class="mi">DPA</span><span class="mo">(</span> <span class="mi">u</span> <span class="mo">→</span> <span class="mi">v</span> <span class="mo">)</span> <span class="mo"> = </span> <span class="mo">|</span><span class="mi">Γ</span><span class="msub"><span class="mo">(</span> <span class="MathSubscript">u</span> <span class="mo">→</span> <span class="mo">)</span></span><span class="mo">|</span> <span class="mo"> × </span> <span class="mo">|</span><span class="mi">Γ</span><span class="msub"><span class="mo">(</span> <span class="MathSubscript">v</span> <span class="mo">←</span><span class="mo">)</span></span><span class="mo">|</span></span></p>
<p><a href="#listing6-9" id="listinganchor6-9">Listing 6-9</a> shows the weighted random connection function, which will be called from the player 1 logic shown in <a href="#listing6-12" id="listinganchor6-12">Listing 6-12</a>.</p>
<pre><code>def wrs_connect(G, u):
    scores = {}
  <span aria-label="annotation1" class="CodeAnnotationCode">❶</span> for i in range(len(G.nodes.keys())):
        v = list(G.nodes.keys())[i]
        if v == u:
            continue
      <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> dpa_score = G.out_degree(u) * G.in_degree(v)      
        scores[v] = dpa_score
  <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> return weighted_choice(scores) # Previously defined choice function</code></pre>
<p class="CodeListingCaption"><a id="listing6-9">Listing 6-9</a>: A directed preferential attachment weighted random selection</p>
<p>The function <code>wrs_connect</code> takes the graph and the connecting node as input and loops over each ID in the graph <span aria-label="annotation1" class="CodeAnnotation">❶</span> to calculate the DPA score <span aria-label="annotation2" class="CodeAnnotation">❷</span> between the input node and each other node (skipping the input node with <code>continue</code>). The <code>weighted_choice</code> function uses the <code>scores</code> dictionary to pick a node to connect to <span aria-label="annotation3" class="CodeAnnotation">❸</span>:</p>
<p class="MathEquation"><span class="math" title="v_conn=wrs( [DPA(u sup (neg q), neg u) ] forall neg u in V)"><span class="mi">v</span><span class="msub"><span class="MathSubscript">conn</span></span> <span class="mo"> = </span> <span class="mi">wrs</span><span class="mo">(</span> <span class="mo">[</span> <span class="mi">DPA</span><span class="mo">(</span> <span class="mi">u</span><span class="msup"><span class="mo">(</span> <span class="mo">¬</span> <span class="mi">q</span> <span class="mo">)</span></span><span class="mi">,</span> <span class="mo">¬</span> <span class="mi">u</span> <span class="mo">)</span><span class="mo">]</span> <span class="mo">∀</span>  <span class="mo">¬</span> <span class="mi">u</span> <span class="mo">∈</span> <span class="mi">V</span> <span class="mo">)</span></span></p>
<p>If <code>disconnect</code> is chosen, the user disassociates from another user who sends them the least information (as measured by the definition of capacity given previously). The <code>capacity</code> attribute of each edge in <code>G.in_edges</code> is used in the weighted random selection process to choose a neighbor to disassociate from. <a href="#listing6-10" id="listinganchor6-10">Listing 6-10</a> shows the code to calculate the capacity and selection weight for a given node. </p>
<pre><code>def ncap_weights(G, u):
    u_in = list(G.in_edges(u, data=True))
    n_capacity = {}
  <span aria-label="annotation1" class="CodeAnnotationCode">❶</span> for v,u,d in u_in:
        n_capacity[v] = d["capacity"]
  <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> Q = 1 + max([itm[1] for itm in list(n_capacity.items())])
  <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> n_weight = {k: (Q - n_capacity[k]) for k in n_capacity.keys()}
    return (n_capacity, n_weight)</code></pre>
<p class="CodeListingCaption"><a id="listing6-10">Listing 6-10</a>: Capacity weighting for a node</p>
<p><span epub:type="pagebreak" id="Page_115" title="115"/>We start by looping over the neighbor data from the set of inbound edges for the node <span aria-label="annotation1" class="CodeAnnotation">❶</span> and collecting these into the <code>n_capacity</code> dictionary. If we hadn’t condensed the multiple edges previously (by using a <code>DiGraph</code> instead of a <code>MultiDiGraph</code>), we’d need to sum up the capacity of each in-edge incident to the node first: </p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06015.png"/></figure>

<p>We weight edges with lower <em>N</em><sub><em>capacity</em></sub> entries more heavily in the selection process, then invert the capacities by subtracting them from a modifier <em>Q</em> = 1 + <em>max</em>(<em>N</em><sub><em>capacity</em></sub> ) <span aria-label="annotation2" class="CodeAnnotation">❷</span>, which results in the weighting formula <span class="GraphicInline eq3"><img alt="m06016" src="image_fi/502567c06/m06016.png" style="height:1.4em;"/></span> <span aria-label="annotation3" class="CodeAnnotation">❸</span>. </p>
<p>For example, if <em>max</em>(<em>N</em><sub><em>capacity</em></sub>) = 10 ⇔ <em>Q</em> = 11, an edge with <span class="GraphicInline eq3"><img alt="m06017" src="image_fi/502567c06/m06017.png"/></span> will get a weight of <code>1</code> (<span class="GraphicInline eq3"><img alt="m06018" src="image_fi/502567c06/m06018.png"/></span>), while an edge with <span class="GraphicInline eq3"><img alt="m06019" src="image_fi/502567c06/m06019.png"/></span> will get a weight of <code>10</code> (<span class="GraphicInline eq3"><img alt="m06020" src="image_fi/502567c06/m06020.png"/></span>). </p>
<p>We’ll set the return value for a given node to the tuple (<em>N</em><sub><em>capacity</em></sub> , <em>N</em><sub><em>weight</em></sub> ). Both <code>n_capacity</code> and <code>n_weight</code> are dictionaries keyed off of the neighboring node’s ID. The <code>wrs_disconnect</code> function in <a href="#listing6-11" id="listinganchor6-11">Listing 6-11</a> uses the <code>n_weight</code> dictionary to select the least informative neighbor to disconnect <code>u</code> from.</p>
<pre><code>def wrs_disconnect(G, u):
  <span aria-label="annotation1" class="CodeAnnotationCode">❶</span> u_in = list(G.in_edges(u))
    if len(u_in) &lt; 1:
        return None
  <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> caps, scores = ncap_weights(G, u)
    if scores is not None:
      <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> return ext.weighted_choice(scores)</code></pre>
<p class="CodeListingCaption"><a id="listing6-11">Listing 6-11</a>: A weighted random disconnection function</p>
<p>If there are no inbound edges for the node <code>u</code> (meaning it has no in-degree neighbors to disconnect from) the function returns <code>None</code> <span aria-label="annotation1" class="CodeAnnotation">❶</span>, resulting in the same outcome as <code>pass</code>. If more than one edge is found, the capacity scores for all the inbound neighbors are calculated using the function from <a href="#listing6-10">Listing 6-10</a> <span aria-label="annotation2" class="CodeAnnotation">❷</span>. The key returned from this function is the neighbor to disassociate from (<em>v</em><sub><em>disconn</em></sub> = <em>wrs</em>(<em>N</em><sub><em>weight</em></sub> )) <span aria-label="annotation3" class="CodeAnnotation">❸</span>. The edge (<em>u</em><sup>(¬</sup><sup><em>q</em></sup><sup>)</sup> ← <em>v</em><sub><em>disconn</em></sub> ) is then removed from the graph in the player 1 logic in <a href="#listing6-12">Listing 6-12</a>. </p>
<h4 id="h3-502567c06-0002">Moving the Message</h4>
<p class="BodyFirst">After the network evolution phase, the game moves into the message movement phase, where the only possible input is <code>send</code>. If an edge exists between the node currently holding the message, <em>u</em>(<em>q</em>), and the goal node, <em>v</em><sub>Ω</sub>, the message passes along that edge and player 1 wins the game. Otherwise, the paths between <em>u</em>(<em>q</em>) and <em>v</em><sub>Ω</sub> are calculated, and the message is passed to the next node along one of these paths, selected uniformly at random.</p>
<p>The code in <a href="#listing6-12">Listing 6-12</a> handles player 1’s turn, which includes both the network adaptations and message movement phases. The function <code>player_one_turn</code> takes the graph, the node holding the message, and the goal <span epub:type="pagebreak" id="Page_116" title="116"/>node as parameters and returns the node that receives the message and the new state of the graph.</p>
<pre><code>def player_one_turn(G, uq, omega):
  <span aria-label="annotation1" class="CodeAnnotationCode">❶</span> if G.has_edge(uq, omega):
        return (omega, G)
    caps = [d["capacity"] for u,v,d in G.edges(data=True)]
  <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> avg_cap = sum(caps) / len(caps)
    
  <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> for u in list(G.nodes.keys()):
        if u == uq:
            try:
              <span aria-label="annotation4" class="CodeAnnotationCode">❹</span> paths = list(nx.all_shortest_paths(G, u, omega))
            except nx.exception.NetworkXNoPath:
                return (uq, G)
          <span aria-label="annotation5" class="CodeAnnotationCode">❺</span> path = choice(paths)
            pass_to = path[1]
        else:
          <span aria-label="annotation6" class="CodeAnnotationCode">❻</span> act = ext.weighted_choice(XI)
          <span aria-label="annotation7" class="CodeAnnotationCode">❼</span> if act == "pass":
                continue
          <span aria-label="annotation8" class="CodeAnnotationCode">❽</span> elif act == "connect":
                v_conn = wrs_connect(G, u)
                G.add_edge(u, v_conn, capacity=avg_cap)
          <span aria-label="annotation9" class="CodeAnnotationCode">❾</span> else:
                v_disconn = wrs_disconnect(G, u)
                if v_disconn is None:
                    continue
                G.remove_edge(v_disconn, u)
  <span aria-label="annotation10" class="CodeAnnotationCode">❿</span> return (pass_to, G)</code></pre>
<p class="CodeListingCaption"><a id="listing6-12">Listing 6-12</a>: The logic defining player 1’s turn</p>
<p>If an edge exists between <code>uq</code> and the goal node <code>omega</code> <span aria-label="annotation1" class="CodeAnnotation">❶</span>, we pass the message to <code>omega</code>. This will end the turn (and game) with a victory for player 1! Otherwise, we calculate the average capacity of the graph <span aria-label="annotation2" class="CodeAnnotation">❷</span>, which will be used as the capacity of any new edges added during network adaptation. This allows the average to change from turn to turn, depending on which edges (if any) were removed during the previous network adaptation phase. </p>
<p>To perform network adaption and message passing, we loop over each node in the graph <span aria-label="annotation3" class="CodeAnnotation">❸</span>. For <em>u</em>(<em>q</em>), we attempt to find valid paths between it and the goal node <span aria-label="annotation4" class="CodeAnnotation">❹</span> (the message movement phase). If this attempt fails with an <code>nx.exception.NetworkXNoPath</code>, the function returns and the round ends with a victory for player 2, since the message can’t reach the destination. Otherwise, we randomly select a path using the <code>choice</code> function <span aria-label="annotation5" class="CodeAnnotation">❺</span> and pass the message to the first node in this path. </p>
<p>For all other nodes, we select an action using the weighted random function and the <code>XI</code> dictionary defined in <a href="#listing6-8">Listing 6-8</a> <span aria-label="annotation6" class="CodeAnnotation">❻</span>. If <code>pass</code> is chosen, the code jumps to the next node using the <code>continue</code> keyword <span aria-label="annotation7" class="CodeAnnotation">❼</span>. If <code>connect</code> is returned, we use the <code>wrs_connect</code> function shown in <a href="#listing6-9">Listing 6-9</a> to form a new edge <span aria-label="annotation8" class="CodeAnnotation">❽</span>. Otherwise, <code>disconnect</code> was chosen, so we use the <code>wrs_disconnect</code> <span epub:type="pagebreak" id="Page_117" title="117"/>function from <a href="#listing6-11">Listing 6-11</a> to remove an edge from the graph <span aria-label="annotation9" class="CodeAnnotation">❾</span>. Finally, we return the receiving node and the updated graph <span aria-label="annotation10" class="CodeAnnotation">❿</span>.</p>
<h4 id="h3-502567c06-0003">Disrupting the Network</h4>
<p class="BodyFirst">Player 2 then gets to select an edge to remove from the network to try to disrupt the flow of the message. One of the strengths of Monte Carlo simulation is in its ability to compare different strategies over time. To illustrate this, let’s compare two strategies for player 2 to achieve their goal. In the first strategy (<a href="#listing6-13" id="listinganchor6-13">Listing 6-13</a>), player 2 selects an edge from <em>E</em> uniformly at random:</p>
<pre><code>def player_two_random(G):
  <span aria-label="annotation1" class="CodeAnnotationCode">❶</span> e = choice(list(G.edges()))
  <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> G.remove_edge(*e)
  <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> return G</code></pre>
<p class="CodeListingCaption"><a id="listing6-13">Listing 6-13</a>: The player 2 random implementation</p>
<p class="BodyFirst">This will act as a good baseline, since it most closely resembles a truly random walk. The code randomly selects <span aria-label="annotation1" class="CodeAnnotation">❶</span> and then removes <span aria-label="annotation2" class="CodeAnnotation">❷</span> an edge from the graph; we then return the updated graph <span aria-label="annotation3" class="CodeAnnotation">❸</span>.</p>
<p>The results of such a strategy can be seen as a null control, as if an adversary just blindly started removing things with no real concept of what they were impacting. We’ll look at the second strategy, where player 2 selects their moves to inflict the most damage using the flow information of the network, after we demonstrate the simulation using this simple strategy and gather our baseline network performance.</p>
<p>Once player 2 has finished selecting the edge to disrupt, the round is complete. If neither player has won, the next round starts and gameplay continues in this fashion until one of the players succeeds in reaching their objective. </p>
<p>In the next section, we’ll cover how to select the start and end nodes. In much larger networks (like the ones you’re likely to see in the wild), having methods for automating tasks like finding data will save you a lot of manual exploration before running your first simulation.</p>
<h3 id="h2-502567c06-0011">The Game Objective</h3>
<p class="BodyFirst">Before we tie this all together into a functional simulation, let’s look at the <code>shortest_path_scores</code> helper function, shown in <a href="#listing6-14" id="listinganchor6-14">Listing 6-14</a>, which returns a list of average path lengths for all pairs of nodes that are not directly connected. </p>
<pre><code>def shortest_path_scores(G):
    pairs = []
  <span aria-label="annotation1" class="CodeAnnotationCode">❶</span> for u, v in nx.non_edges(G):
        if u == v:
            continue
        if not nx.has_path(G, u, v):
            continue
<span epub:type="pagebreak" id="Page_118" title="118"/>      <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> uv_paths = list(nx.all_shortest_paths(G, u, v))
      <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> avg_len = sum([len(p) for p in uv_paths]) / len(uv_paths)
        pairs.append(((u, v), len(uv_paths), avg_len))
    sorted_scores = sorted(
        pairs,
      <span aria-label="annotation4" class="CodeAnnotationCode">❹</span> key=lambda kv: (kv[2], kv[1], kv[0]),
        reverse=True
    )
    return sorted_scores</code></pre>
<p class="CodeListingCaption"><a id="listing6-14">Listing 6-14</a>: Creating an average-length score for weighted selection</p>
<p>The <code>for</code> loop <span aria-label="annotation1" class="CodeAnnotation">❶</span> calls the NetworkX function <code>nx.non_edges</code> to get a list of all possible node combinations not directly connected by an edge, checks that the two nodes <em>u</em> and <em>v</em> are different, and checks that one or more paths exist between the nodes. If any condition fails, we skip that pair of nodes with the <code>continue</code> keyword. Otherwise, we use the <code>nx.all_shortest_paths</code> function to make a list of all potential paths between the source and sink nodes at the start of the game <span aria-label="annotation2" class="CodeAnnotation">❷</span>, then calculate the average path length <span aria-label="annotation3" class="CodeAnnotation">❸</span> and append it to the <code>pairs</code> list. Once all the pairs have been processed, we sort the results in descending order, based on the average path length first, then the ID of the node <em>u</em>, and finally the ID of the node <em>v</em> <span aria-label="annotation4" class="CodeAnnotation">❹</span>.</p>
<p>In <a href="#listing6-15" id="listinganchor6-15">Listing 6-15</a> we’ll combine these scores with the <code>weighted_choice</code> function to randomly select the source and sink pair while favoring pairs that have more, or longer, paths than those with fewer, shorter ones. I chose this method so the simulation has enough routes to make it interesting. You may choose the source and sink nodes based on other parameters in your simulation. You might even extend your simulation to test all possible combinations of source and sink node.</p>
<h3 id="h2-502567c06-0012">The Game Simulation</h3>
<p class="BodyFirst">Finally, it’s time to tie all these functions together into a single cohesive game with the code in <a href="#listing6-15">Listing 6-15</a>. We’ll run the game simulation 25 times, each with a different pair of source and sink nodes. Each run will generate <em>k</em> random walks, representing one game between player 1 and player 2 per walk, and tally the number of wins for each player. The average of the <em>k</em> scores is the score for the run overall. Using different source and sink nodes, instead of running the same scenario over and over, will give us a better sense of the network as a whole. The code in <a href="#listing6-15">Listing 6-15</a> assumes you’ve already built the graph (using code similar to <a href="#listing6-3">Listing 6-3</a>). </p>
<pre><code>path_scores = shortest_path_scores(G)
k = 10 # Number of random walks
n = 10 # Number of steps in each walk
<span aria-label="annotation1" class="CodeAnnotationHang">❶</span> path_weights = {(p[0][0], p[0][1]): p[2] for p in path_scores}
played = []
for r in range(25): # Run the simulation 25 times
  <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> selected = weighted_choice(path_weights)
    while selected in played:
        selected = weighted_choice(path_weights) # Avoid repeated selection
<span epub:type="pagebreak" id="Page_119" title="119"/>    played.append(selected)    # Track new pair
    alpha = selected[0]        # Source node
    omega = selected[1]        # Sink node
    game_res = []              # Results from k random walks
  <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> for i in range(k):         # Perform k random walk simulations
        newG = G.copy()        # Copy the graph to maintain the original state
        now_at = alpha
      <span aria-label="annotation4" class="CodeAnnotationCode">❹</span> for j in range(n):     # Perform at most n steps in each walk
          <span aria-label="annotation5" class="CodeAnnotationCode">❺</span> w = check_win(newG, now_at, omega)
            if w is not None:
                game_res.append(w)
                break
          <span aria-label="annotation6" class="CodeAnnotationCode">❻</span> now_at, newG = player_one_turn(newG, now_at, omega)
          <span aria-label="annotation7" class="CodeAnnotationCode">❼</span> if not check_win(newG, now_at, omega):
              <span aria-label="annotation8" class="CodeAnnotationCode">❽</span> newG = player_two_random(newG)
  <span aria-label="annotation9" class="CodeAnnotationCode">❾</span> tally = sum(game_res)
    avg = tally / len(game_res)
    print("\t Average %.4f" % avg)</code></pre>
<p class="CodeListingCaption"><a id="listing6-15">Listing 6-15</a>: The main game simulation function</p>
<p>Before running the group of simulations, we get the list of average path lengths between nodes with <code>shortest_path_scores</code> (<a href="#listing6-14">Listing 6-14</a>) <span aria-label="annotation1" class="CodeAnnotation">❶</span>, convert the average path lengths returned into a list of <code>path_weights</code> (meaning nodes with longer average shorter path lengths get weighted higher), and select a pair of nodes (which is the key returned from <code>path_weights</code>) <span aria-label="annotation2" class="CodeAnnotation">❷</span>. If that pair of nodes and associated paths have already been used in a simulation (tracked by the <code>played</code> list), we select another. From the selected pair and path, we set the source and sink nodes, <code>alpha</code> and <code>omega</code>.</p>
<p>Once we’ve found a valid source and sink pair, we perform the <em>k</em> random walks. Each iteration of the <code>for</code> loop <span aria-label="annotation3" class="CodeAnnotation">❸</span> constitutes one complete game, played on a copy of the graph (<code>newG</code>) to maintain the original topology between matches. Each <em>n</em>-step random walk <span aria-label="annotation4" class="CodeAnnotation">❹</span> generates up to <em>n</em> turns for both players <span aria-label="annotation68" class="CodeAnnotation"><span class="CodeAnnotation">68</span></span> and checks the win condition at each phase <span aria-label="annotation57" class="CodeAnnotation"><span class="CodeAnnotation">57</span></span>. The result of each game is appended to <code>game_res</code>. Each iteration of this loop counts as one complete turn cycle within a game. </p>
<p>Once the <em>k</em> walks are complete, we tally the wins (1 point for a win by player 1 and –1 point for a win by player 2) <span aria-label="annotation9" class="CodeAnnotation">❾</span> by summing <code>game_res</code>, then take the average <code>tally</code> as the overall score for the<em> k</em> walks. </p>
<p>Run the code in <a href="#listing6-15">Listing 6-15</a> to see the result of 25 simulations. The averages produced by each test (the outermost <code>for</code> loop) may vary wildly, as you can see from this snippet: </p>
<pre><code>Average 0.7600
Average 0.2800
Average 0.6000
Average 0.1200
Average -0.5200
Average 0.6800
Average -0.7600
<var>--snip--</var>
<span epub:type="pagebreak" id="Page_120" title="120"/>Average 0.9200
Average 0.8400
Average -0.3600
Average 0.5200
Average 0.6000
Average 0.2000
Average -0.5200</code></pre>
<p>A score of <code>0.0</code> means both players won the same number of matches. Positive averages indicate player 1 won more often than player 2. The closer to <code>+1</code> this gets, the more heavily the matches favored player 1. The opposite is true as the score moves below 0. An average score of <code>-1</code> indicates player 2 won every match. </p>
<p>The final step is to summarize the result from all the tests. We can do so by summing the individual averages and then dividing by the number of tests. We’ll call this the <em>population mean</em>. The benefit of the population mean is twofold. First, it summarizes all the tests into a single number you can interpret, rather than a list of test results. Second, the population mean should be relatively stable compared to the values observed between individual run results. If we rerun the code, we’ll get different individual test results. The population mean should be relatively stable, though. </p>
<p>When analyzing the model three times, I got the population averages 0.2160, 0.2320, and 0.1808. Of course in statistics we deal with uncertainty, so a better measure of the population mean is the numeric range we believe the actual population mean will fall between, given some desired level of confidence. To do this, we use the <code>scipy.stats.t.interval</code> function and pass in the results from our simulations and our desired confidence interval (called the <em>alpha parameter</em>) as a float. The result is a tuple containing the lower and upper bounds within which we can predict the true population mean will fall. For example, I ran the simulation 6,250 times and I can say with 95 percent confidence the true population mean for the simulation (as it’s currently configured) will be between 0.1078 and 0.2225, which means there is a slight advantage to player 1. The current design seems to slightly favor the defender because of its growth and the lack of intelligence from the adversary. </p>
<p>Now that we’ve established a baseline performance for our network, let’s see if we can improve the adversary’s chances by letting them observe the network and pick which routes to sever. We can then compare the results of the two simulations (in terms of predicted population means) and see if our changes significantly impact player 2’s chance at disrupting the network.</p>
<h3 id="h2-502567c06-0013">Improvements to Player 2</h3>
<p class="BodyFirst">Let’s see what happens if we give player 2 a little more intelligence. In this version, player 2 uses the updated graph and current message position to remove an edge that’s important to the path between the message position and the goal (a relatively intuitive strategy for human players). </p>
<p><span epub:type="pagebreak" id="Page_121" title="121"/>To codify this strategy, player 2 will use the max-flow, min-cut theorem. A max-flow, min-cut analysis was one of the driving forces behind the creation of the modern TCP/IP internet. The protocol breaks messages into little chunks called <em>packets</em> and then chooses different routes for different parts of the transmission based on response times and carrying capacity. The basic idea of the design is that someone would have to take out a large percentage of the network before they could disconnect two distant nodes from each other. The list of nodes that would need to be removed is known as the <em>cutset</em>. The adversary in our simulation game will take advantage of the cutset information to carry out the exact type of attack Paul Baran, the inventor of packet-switching networks, was concerned with in his research (<a class="LinkURL" href="https://www.rand.org/about/history/baran.list.html">https://www.rand.org/about/history/baran.list.html</a>)—that is, the selective targeting and removal of communication channels to disrupt the network. </p>
<p>In short, the max-flow, min-cut theorem tells us two key pieces of information. First, the max-flow portion describes the maximum amount of resources that can flow along all paths between two nodes (<em>u</em>, <em>v</em>). The min-cut section describes the minimum number of edges someone would need to remove from the network to sever all paths between the two nodes. More formally: given two nodes (<em>u, v</em>), the max-flow, min-cut theorem tells you the total capacity for the fewest set of edges you need to remove so there’s no path between the two nodes (the cutset). A cut is a graph partitioning <em>G</em>(<em>S</em>, <em>T</em>) such that <em>u</em> is in <em>S</em> and <em>v</em> is in <em>T</em>.</p>
<p>The <em>capacity constraint</em> defined in the max-flow, min-cut theorem limits the volume flowing through each edge, per simulation step, to less than or equal to the maximum capacity of the edge:</p>
<p class="MathEquation"><span class="math" title="( u rightarrow v )_flow &lt;= (u rightarrow v)_capacity"><span class="mo">(</span><span class="mi">u</span> <span class="mo">→</span> <span class="mi">v</span><span class="mo">)</span><span class="msub"> <span class="MathSubscript">flow</span></span> <span class="mo"> ≤ </span> <span class="mo">(</span><span class="mi">u</span> <span class="mo">→</span> <span class="mi">v</span><span class="mo">)</span><span class="msub"> <span class="MathSubscript">capacity</span></span></span></p>
<p>The <em>conservation constraint</em> of the theorem states the amount that flows into each node is equal to the amount flowing out:</p>
<figure class="graphic equation">
<img alt="" class="" src="image_fi/502567c06/m06021.png"/></figure>

<p>Once again, this can be restated more simply: every node sends out all the resources it receives; it doesn’t keep any for itself. This constraint applies to all nodes except <em>u</em>α and <em>v</em><sub>Ω </sub>. In terms of our simulation, this means that any user who reblogs the message receives as much information as the post contains, and if someone then reblogs the message from them, that person also receives the same amount of information. The source and sink nodes are treated specially due to their position in the flow. The source node is like a faucet capable of adding a certain amount of resource to the network, so nothing flows into the source, only out. In our graph this is synonymous with a user who is likely to receive a lot of reblogs, but isn’t likely to reblog a lot themselves (nodes with high out-degree and low in-degree). Conversely, the sink node is like a sponge that absorbs some amount of information from the network without passing any on. Whatever information hits the sink node is absorbed there. </p>
<p><span epub:type="pagebreak" id="Page_122" title="122"/>The <code>nx.minimum_cut</code> function in <a href="#listing6-16" id="listinganchor6-16">Listing 6-16</a> uses the max-flow, min-cut theorem to determine the minimum cut value between two nodes (<em>u</em>, <em>v</em>) and the partition created by the cut, returned as a tuple (<code>cut_value</code>, <code>partition</code>). The <code>partition</code> is a tuple of (<code>reachable</code>, <code>unreachable</code>) nodes that indicates which nodes would be reachable and unreachable from <em>u</em>. Recall from the previous definition that a cut partitions the graph so that the two nodes are in separate, disconnected components if the cutset is removed.</p>
<pre><code>def player_two_turn(G, uq, omega):
  <span aria-label="annotation1" class="CodeAnnotationCode">❶</span> cut_value, partition = nx.minimum_cut(G, uq, omega)
    reachable, unreachable = partition
    cutset = set()
  <span aria-label="annotation2" class="CodeAnnotationCode">❷</span> for u, nbrs in ((n, G[n]) for n in reachable):
        cutset.update((u, v) for v in nbrs if v in unreachable)
  <span aria-label="annotation3" class="CodeAnnotationCode">❸</span> if len(cutset) &gt;= 2:
        cut = choice(list(cutset))
        G.remove_edge(*cut)
  <span aria-label="annotation4" class="CodeAnnotationCode">❹</span> elif len(cutset) == 1:
        cut = list(cutset)[0]
        G.remove_edge(*cut)
    return G</code></pre>
<p class="CodeListingCaption"><a id="listing6-16">Listing 6-16</a>: Updating player 2 with more intelligence</p>
<p>We start by computing the <code>cutset</code> between <em>u</em>(<em>q</em>) and <em>v</em><sub>Ω</sub> <span aria-label="annotation1" class="CodeAnnotation">❶</span>. To convert the <code>partition</code> tuple into the <code>cutset</code>, we loop over the pairs of neighbors in the <code>reachable</code> set <span aria-label="annotation2" class="CodeAnnotation">❷</span>. For each node in the set, we loop over all their neighbors in the graph. If one of their neighbors is found in the <code>unreachable</code> set, then the edge(s) between the node in the <code>reachable</code> set and the node in the <code>unreachable</code> set belong to the cutset. Once we’ve processed all the nodes this way, we’ll have the list of all edges required to disconnect the two nodes. If there’s only one edge in the set, player 2 chooses this edge for removal <span aria-label="annotation4" class="CodeAnnotation">❹</span>. Otherwise, player 2 chooses an edge from the <code>cutset</code> uniformly at random, again relying on the <code>choice</code> function <span aria-label="annotation3" class="CodeAnnotation">❸</span>.</p>
<p>This output shows the result of rerunning the simulation with the new strategy for player 2:</p>
<pre><code>Average -0.9200
Average -1.0000
Average -1.0000
Average -1.0000
Average -0.6000
Average -0.8400
Average -1.0000
<var>--snip--</var>
Average -1.0000
Average -0.9200
Average -0.9200
Average -1.0000
Average -1.0000
Average -0.3600
Average -0.9200</code></pre>
<p><span epub:type="pagebreak" id="Page_123" title="123"/>After analyzing the modified player 2 in 6,250 simulations, I got a population mean of –0.8144 and can say with 95 percent confidence that the population mean for simulations with the modified player 2 is between –0.9484 and –0.6803. When you run the code on your machine, you might see slightly different results (remember, we’re dealing with a lot of randomness), but the overall trend should remain consistent. It seems that this simple strategy changes the simulation to heavily favor player 2, even with the network growth still favoring player 1.</p>
<p>There’s always a chance we’re erroneously claiming that we’ve improved player 2’s chances. Since we can’t simulate every possible outcome, we can never be 100 percent sure our population means are accurate. How, then, can we be sure this result isn’t due to some random fluke? The truth is, we can be sure only up to a certain point. We have to accept that we can’t know for certain. This brings up an important point: we need to think about how much risk we’re willing to accept of coming to an incorrect conclusion. When you perform an analysis in the wild, there are often real-world consequences for acting on incorrect conclusions. You should pick a confidence level that complements the amount of risk in the event that you’re wrong. The higher the risk, the higher confidence you should require. Once you’ve chosen your desired level of confidence, you can convert it into your t-test threshold by subtracting the desired confidence level from 100. For example, I want to be very certain our result is not a fluke, so I’ll set the confidence level to 99 percent, which means we’re willing to accept a 1 percent probability of coming to an incorrect conclusion. We can now use this threshold to test our claim that we’ve improved player 2’s chance of winning.</p>
<p>More formally, we can state the hypothesis that changing player 2’s logic has created a significant reduction in the population mean (<em>h</em><sub>1</sub> = μ<sub>0</sub> &gt; μ<sub>1</sub>). The null hypothesis, then, is that the random sample’s mean will be equal to or less than that of the modified player (<em>h</em><sub>1</sub> = μ<sub>0</sub> ≥ μ<sub>1</sub>). We can compare the population mean of this set of results using a statistical method known as the <em>two-sample t-test</em>. This t-test quantifies the difference between the arithmetic means of the two samples. A common application is to test if a new process or treatment is superior to a current process or treatment. In our case, we’ll use it to determine if the difference between the two population means is significant enough to claim that our changed strategy for player 2 has in fact improved their chance of winning. </p>
<p>The proof of concept uses the <code>scipy.stats.ttest_ind</code> function to run this test. The result is an object with an attribute named <code>pvalue</code>. The p-value quantifies the probability of observing a value as or more extreme than the tested value, assuming the null hypothesis is true. We compare this number against our threshold of 1 percent to determine if we’re confident enough in the result to reject the null hypothesis. In this case I’ve run the test over a dozen times and every time the improved player 2 score is significantly low enough to support the claim that we are 99 percent sure the change we made to player 2 improved their chance of winning. We can visualize the two probability distributions as in <a href="#figure6-4" id="figureanchor6-4">Figure 6-4</a> to see just how big of an impact the change has had.</p>
<span epub:type="pagebreak" id="Page_124" title="124"/><figure>
<img alt="" class="" src="image_fi/502567c06/f06004.png"/>
<figcaption><p><a id="figure6-4">Figure 6-4</a>: Comparing probability distributions</p></figcaption>
</figure>
<p>This graph shows the likelihood of all possible test outcomes for both the random and improved player 2 models. The light gray dotted line represents the baseline performance of the random player model. The dark gray continuous line is the performance of the improved player model. The large peak and steep drop-off around –0.8 shows that the improved player performed more consistently and could win most series by a large margin. In fact, it would be incredibly unlikely for any series of tests to average as high as –0.25 using the improved player 2 code. We can interpret this as an indication that the ability to selectively remove edges has the potential to highly disrupt the information flow within this network. </p>
<p>You can run the proof of concept using the command <code>python mcs_multiplayer.py</code> in the <em>Chapter 6</em> directory in the book’s supplemental materials. On each execution, the code runs a group of simulations for both player 2 types, then calculates the population means and compares them using the one-tailed t-test. It will output a line telling us whether or not we can reject the null hypothesis, and finally it generates a graph like the one in <a href="#figure6-4">Figure 6-4</a> for analysis. As an exercise, try adjusting the weights in <code>XI</code> to more heavily favor new connections and see if this impacts the result to player 1’s benefit. What other changes could you make to player 1 to improve their ability to defend the network?</p>
<h2 id="h1-502567c06-0005">Summary</h2>
<p class="BodyFirst">The concepts introduced in this chapter—Monte Carlo simulations, finite state machines, random walks, weighted choice—combined with the foundational graph theory from the last three chapters make up an extremely flexible set of tools that go far beyond social network analysis. By defining finite state machines for simulations, analyzing repeated simulations to <span epub:type="pagebreak" id="Page_125" title="125"/>determine the likelihood of a particular outcome, modifying simulations to get different results and insights, and modeling how graphs may evolve over time, you can quantitatively assess security risks by modeling potential changes to the environment.</p>
<p>One scenario where I constantly find myself applying Monte Carlo simulations is in crowd flow dynamics. Predicting how people will move through an area, where they’ll gather, and how they might change that movement in response to different types of obstructions is one of the keys to planning effective physical security controls. We’ll discuss this a bit more in the context of the art gallery problem in <span class="xref" itemid="xref_target_Part III"><a href="p03.xhtml">Part III</a></span>, but you may already have some idea of how you could approach this task using what we’ve covered here.</p>
<p>This is just the beginning of Monte Carlo simulations, though. By changing the logic at each simulation step, you can model all kinds of unique behaviors in the network. Designing an appropriate simulation is as much an art as it is a science, so don’t be afraid to branch out and explore some wild simulation ideas. </p>
<p>To help you as you go forth, the Jupyter notebook that accompanies this chapter has code to display random walks in 2D and 3D, which you can use to visualize the simulations you develop. Often, seeing the results distributed visually can lead to interesting discoveries (like paths that always cross a single point). By combining the random walk display code with the animation code from the supplemental materials, you can even create a video of the simulation. </p>
<p>As you explore the related literature, you’ll find numerous advanced discussions of how to select a “best move” within the Monte Carlo simulation. As you saw in the proof of concept, small changes to parameters can have a drastic impact on the result. It’s important to be aware of the rationale and implications of each change to the model so that you can formulate more accurate assessments and draw well-founded conclusions about the networks you simulate. </p>
<p>You can learn more about GGP theory and algorithms from Stanford University’s online course (<a class="LinkURL" href="http://ggp.stanford.edu">http://ggp.stanford.edu</a>). Several of these models lend themselves well to various information security tasks, such as risk analysis, budget planning, and incident response. If you’d like to learn more about information flow, check out the research paper “An Information Flow Model for Conflict and Fission in Small Groups,”<sup class="endnote"><a href="b01.xhtml#c06-endnote-011" id="c06-noteref-011">11</a></sup> which describes a formal process for measuring information flow and detecting unbalanced sentiment in a social network.</p>
</section>
</body>
</html>