<html><head></head><body>
<h2 class="h2" id="ch12"><strong><span epub:type="pagebreak" id="page_323"/><span class="big">12</span><br/>SAMPLING</strong></h2>
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>
<p class="noindent">We’ve powered the majority of our experiments by extracting samples from the uniform distribution. While we’ve also worked with the normal distribution (<a href="ch01.xhtml">Chapter 1</a>), beta distribution (<a href="ch03.xhtml">Chapter 3</a>), and binomial distribution (<a href="ch09.xhtml">Chapter 9</a>), the tried-and-true uniform distribution is our oldest and dearest friend.</p>
<p class="indent">In this chapter, we’ll sample from arbitrary probability distributions, be they discrete or continuous. This ability is critical to simulation and fundamental to Bayesian inference.</p>
<p class="indent">First, we’ll discuss terminology and unpack the term <em>Bayesian inference</em>. Following that, we’ll dive into sampling from arbitrary discrete probability distributions, first in one dimension, then in two.</p>
<p class="indent">Discrete distributions dealt with, we’ll move on to sampling from continuous distributions via inverse transform sampling, rejection sampling, and Markov Chain Monte Carlo sampling using the Metropolis-Hastings algorithm.</p>
<p class="indent">This is perhaps our most mathematical chapter, but don’t let that throw you. If you want to continue exploring the algorithms or apply them to different situations, the code is what matters.</p>
<h3 class="h3" id="ch00lev1_78"><strong>Introduction to Sampling</strong></h3>
<p class="noindent"><span epub:type="pagebreak" id="page_324"/>Before diving into sampling, let’s agree on terminology and the concepts that terminology entails. We’ll also introduce notions related to Bayesian statistics and inference, with the latter being a prime motivator for, and beneficiary of, the development of sampling algorithms.</p>
<h4 class="h4" id="ch00lev2_96"><em><strong>Terminology</strong></em></h4>
<p class="noindent">If we roll a standard die, we’ll get one of six possible outputs, each occurring with equal probability. We express this distribution as a bar graph with bars labeled 1 through 6, each of equal height corresponding to the fraction 1/6. The sum of the fractions represented by each bar is 1 because the graph is a discrete probability distribution.</p>
<p class="indent">The <em>probability mass function (PMF)</em> tells us the probability of any discrete outcome. For a standard die, the PMF is 1/6 for each outcome. For a binomial distribution, the PMF depends on the number of trials (<em>n</em>) and the probability of an event happening (<em>p</em>) per trial according to the formula <img alt="Image" class="inline" src="../images/f0324-01.jpg"/>. Here <em>k</em>, <em>k</em> = 0, . . . , <em>n</em>, is the number of events occurring during the <em>n</em> trials. Think of the continuous case as moving the discrete case to more and more possible outcomes; for example, a bar graph where the bars become increasingly narrow until they have an infinitesimal width. Talk of infinitesimals often implies calculus, as is the case here. The discrete distribution morphs into a continuous one so that:</p>
<div class="image1"><img alt="Image" src="../images/f0324-02.jpg"/></div>
<p class="noindent">Here, <em>f</em>(<em>x</em>) is a <em>probability density function (PDF)</em>, the continuous analog of a probability mass function. The notation <em>P</em>(<em>X</em> = <em>i</em>) stands for the probability of a random variable, <em>X</em>, taking on the value <em>i</em>.</p>
<p class="indent">The <em>∫</em> symbol is simply an old-fashioned script “S” for “sum.” The thing summed is an infinite number of areas formed by rectangles of width <em>dx</em> (a single entity, not the product of <em>d</em> and <em>x</em>) and height <em>f</em>(<em>x</em>), that is, the PDF function value at <em>x</em>. If limits are given, <img alt="Image" class="inline" src="../images/f0324-01a.jpg"/>, the sum is for <em>x</em> = <em>a</em> through <em>x</em> = <em>b</em>. No limits given implies “sum over all <em>x</em> that matter, even if from –<em>∞</em> to +<em>∞</em>.”</p>
<p class="indent">Sample a discrete distribution, and the probability of returning <em>x</em> is <em>P</em>(<em>X</em> = <em>x</em>), or the probability associated with the bar labeled <em>x</em>. The probability of sampling a continuous distribution and getting a specific <em>x</em> is, counterintuitively, <em>P</em>(<em>x</em>) = 0 for any real number <em>x</em>. We can’t talk of the probability of returning <em>x</em> as a sample, but instead, the probability of the sample lying in some range, [<em>a</em>, <em>b</em>]. That probability is:</p>
<div class="image1"><img alt="Image" src="../images/f0324-04.jpg"/></div>
<p class="noindent">This is nothing more than the area under the PDF from <em>a</em> to <em>b</em>. The variables in the integral are dummy variables. I switched from <em>x</em> to <em>t</em> to avoid confusion with the <em>x</em> we’re asking about on the left-hand side of the equation.</p>
<p class="indent"><span epub:type="pagebreak" id="page_325"/>We must talk about the probability over a range in the continuous case because not all infinities are created equal, a fact first realized by Georg Cantor in the 19th century. Because there are so many more real numbers than integers, the probability of selecting any one from a continuous distribution becomes identically zero. While the algorithms of this chapter return samples that appear to come from the desired continuous distribution, don’t be fooled. As with all computation, we never use real numbers, but rational numbers in one form or another. Ultimately, our samples approximate the desired continuous probability distribution. However, as they say, if it walks like a duck and quacks like a duck, it’s a duck—or a reasonably useful facsimile of one.</p>
<p class="indent">The PMF and PDF relate to the probability of sampling a particular value from a distribution. A related concept is the <em>cumulative distribution function (CDF)</em>, which we use for both discrete and continuous distributions. The CDF at <em>x</em> is the sum of the area under the PMF or PDF from its lowest value to <em>x</em>. If we sum over all the bars of the discrete distribution or integrate over all of the PDF, we get an area of 1, so the CDF is a function running from 0 on the left to 1 on the right as <em>x</em> increases.</p>
<p class="indent">For example, <a href="ch012.xhtml#ch012fig01">Figure 12-1</a> shows the PMF (top left) and CDF (top right) for a binomial distribution with <em>n</em> = 10 trials, each with probability <em>p</em> = 0.7. On the bottom are the PDF and CDF for a standard normal distribution. In both cases, the CDF approaches 1 from the left.</p>
<div class="image"><img alt="Image" id="ch012fig01" src="../images/12fig01.jpg"/></div>
<p class="figcap"><em>Figure 12-1: The PMF and CDF for a binomial distribution (top) and a standard normal distribution (bottom)</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_326"/>The code to generate <a href="ch012.xhtml#ch012fig01">Figure 12-1</a> is in <em>cdf.py</em>, which demonstrates how to realize pure math as code, at least with regard to probability functions. I’ll skip the plotting portion of the code; see <a href="ch012.xhtml#ch012list01">Listing 12-1</a> for the remaining relevant bits.</p>
<pre class="pre">np.random.seed(8675309)
z = np.random.binomial(10,0.7,size=10000)
h = np.bincount(z, minlength=11)
h = h / h.sum()
cdf = np.cumsum(h)

np.random.seed(73939133)
x = np.linspace(-7,7,10000)
y = (1/np.sqrt(2*np.pi))*np.exp(-x**2/2)
cdf = np.cumsum(y*(x[1]-x[0]))</pre>
<p class="list" id="ch012list01"><em>Listing 12-1: Generating CDFs from PMFs and PDFs</em></p>
<p class="indent">The first code paragraph generates samples from the binomial distribution. To save effort, I’m using NumPy’s function to draw 10,000 random samples, meaning <code>z</code> is a vector of 10,000 values, each a randomly selected sample from the binomial distribution. To get the distribution itself, we need a histogram. The samples, in <code>z</code>, are integers, so the most efficient way to get the counts is with the <code>bincount</code> method. There were <em>n</em> = 10 trials, but there are 11 possible outcomes from 0 events up to 10, hence <code>minlength=11</code> in the call to <code>bincount</code>.</p>
<p class="indent">Let’s turn to the <code>h = h / h.sum()</code> line. The <code>bincount</code> method returns the per-outcome counts. We want a discrete probability distribution, which must sum to 1, so we divide each count by the total to transform them into fractions adding to 1. Therefore, <code>h</code> is now an <em>estimate</em> of the discrete binomial probability distribution for <em>n</em> = 10 and <em>p</em> = 0.7. For a better estimate of the true binomial distribution, increase the number of samples to 20,000 or more.</p>
<p class="indent">A discrete distribution’s CDF is the running sum of the per-outcome probabilities. In other words</p>
<div class="image1"><img alt="Image" src="../images/f0326-01.jpg"/></div>
<p class="noindent">NumPy’s <code>cumsum</code> calculates this cumulative sum for us to generate the entire CDF in a single function call.</p>
<p class="indent">The continuous case is similar, though we don’t need to draw samples from it because the PDF of the normal distribution has a closed-form representation. For the standard normal (<em>µ</em> = 0, <em>σ</em> = 1), the PDF is:</p>
<div class="image1"><img alt="Image" src="../images/f0326-02.jpg"/></div>
<p class="noindent"><span epub:type="pagebreak" id="page_327"/>In code, we estimate this function (<code>y</code>) using 10,000 values of <em>x</em> equally spaced from –7 to 7 (<code>linspace</code>).</p>
<p class="indent">To estimate the CDF, however, we can’t simply sum the values in <code>y</code> as in the discrete case. The area under the PDF must sum to 1, but because it’s an area, we multiply each <em>y</em> value by the width of the rectangle it makes with the <em>x</em>-axis. The rectangle’s width is the difference between successive <code>x</code> values, so we multiply <code>y</code> by <code>x[1] - x[0]</code> before summing. There’s no need to scale <code>y</code>, as the values in <code>y</code> are the actual PDF values, not counts.</p>
<p class="indent">This chapter’s goal is to sample from arbitrary distributions, where “sampling” means that we ask a distribution to give us a number according to the probabilities assigned to possible outputs. The higher the <em>y</em>-axis value of a distribution in a PMF or PDF plot, the higher the oracle’s probability of selecting that number (discrete) or a number in a very narrow range about that position (continuous).</p>
<p class="indent">For example, the code in <em>nselect.py</em> generates the plot in <a href="ch012.xhtml#ch012fig02">Figure 12-2</a>, in which the black dots on the <em>x</em>-axis signify 30 samples from the normal distribution.</p>
<div class="image"><img alt="Image" id="ch012fig02" src="../images/12fig02.jpg"/></div>
<p class="figcap"><em>Figure 12-2: Thirty samples from a standard normal distribution</em></p>
<p class="indent">The samples are concentrated near the center of the PDF—the most likely region to be sampled. As we draw more samples, their density along the <em>x</em>-axis increases in proportion to the probability of being selected. Transforming the density into counts via a histogram approximates the PDF itself.</p>
<p class="indent">Now, let’s discuss Bayesian inference, as its use depends on efficient sampling from complicated probability distributions.</p>
<h4 class="h4" id="ch00lev2_97"><em><strong>Bayesian Inference</strong></em></h4>
<p class="noindent">English minister Thomas Bayes (1701–1761) originated a seemingly simple equation that has recently turned the world of statistics on its head. Deriving the equation is an exercise in basic probability theory.</p>
<p class="indent"><span epub:type="pagebreak" id="page_328"/>We write the probability of event <em>B</em> happening, given that event <em>A</em> has already happened, as <em>P</em>(<em>B</em>|<em>A</em>). This is the <em>conditional probability</em> of <em>B</em> given <em>A</em>. The probability of <em>A</em> happening is <em>P</em>(<em>A</em>), and the probability of both <em>B</em> and <em>A</em> happening is their <em>joint probability</em>, <em>P</em>(<em>A</em>, <em>B</em>).</p>
<p class="indent">Probability theory states that <em>P</em>(<em>B</em>, <em>A</em>) = <em>P</em>(<em>B</em>|<em>A</em>)<em>P</em>(<em>A</em>), which, switching the order of events, gives us <em>P</em>(<em>A</em>, <em>B</em>) = <em>P</em>(<em>A</em>|<em>B</em>)<em>P</em>(<em>B</em>). Joint probabilities represent the probability of all combinations of the events, meaning <em>P</em>(<em>B</em>, <em>A</em>) = <em>P</em>(<em>A</em>, <em>B</em>). Putting these observations together tells us that:</p>
<div class="image1"><img alt="Image" src="../images/f0328-01.jpg"/></div>
<p class="noindent">The final equation is <em>Bayes’ theorem</em>, which relates the <em>posterior probability</em>, <em>P</em>(<em>B</em>|<em>A</em>), to the product of the <em>likelihood</em>, <em>P</em>(<em>A</em>|<em>B</em>), and the <em>prior probability</em>, <em>P</em>(<em>B</em>). The denominator on the right, <em>P</em>(<em>A</em>), is the <em>evidence</em>. It’s a normalizing value to ensure that the posterior probability is a probability—that the sum over the PDF of the posterior is 1. In practice, <em>P</em>(<em>A</em>) becomes an integral that typically can’t be expressed in closed form. In Bayesian modeling, the likelihood and prior probabilities are selected and known functional forms, but the evidence becomes intractable. This is where the sampling methods we’ll discuss soon come into play. Drawing samples from the posterior is <em>Bayesian inference</em>. Without advanced sampling methods, Bayesian inference is all but impossible; with them, Bayesian inference becomes a paradigm shift, as Sharon Bertsch McGrayne notes in her book <em>The Theory That Would Not Die</em> (Yale University Press, 2011):</p>
<p class="bq">The combination of Bayes and Markov Chain Monte Carlo has been called “arguably the most powerful mechanism ever created for processing data and knowledge.”</p>
<p class="noindent">Markov Chain Monte Carlo is one of the sampling algorithms we’ll explore in this chapter. While we recognize Monte Carlo from <a href="ch011.xhtml">Chapter 11</a>, we’ll discuss the Markov chain aspect in time.</p>
<p class="indent">Let’s start sampling from arbitrary distributions.</p>
<h3 class="h3" id="ch00lev1_79"><strong>Discrete Distributions</strong></h3>
<p class="noindent">An arbitrary, one-dimensional discrete probability mass function might look like:</p>
<p class="center"><em>p<sub>X</sub></em>(<em>x</em>) = [1, 1, 3, 4, 5, 1, 7, 4, 3]</p>
<p class="indent">While perhaps unexpected, as far as we’re concerned this is a perfectly valid PMF represented as a Python list. It illustrates a distribution returning samples in the range 0 through 8 (the list has nine elements), and each sample returns an index into the PMF. As it stands, the PMF isn’t <em>normalized</em>, so the sum of the “probabilities” isn’t 1; it’s 1 + 1 + 3 + 4 + 5 + 1 + 7 + 4 + 3 = 29. To get probabilities, we divide each number by this sum.</p>
<p class="indent"><span epub:type="pagebreak" id="page_329"/>The PMF tells us the proportion with which each value—0 through 8—appears, on average, after a large number of samples. For example, 6 appears seven times as often as 0 because the ratio between 6 and 0 is 7 : 1. Likewise, the ratio between 6 and 7 is 7 : 4, and so on.</p>
<p class="indent">Let’s calculate the ratio between the probability of sampling a 6 (7/29) and the probability of getting a 0 (1/29):</p>
<div class="image1"><img alt="Image" src="../images/f0329-01.jpg"/></div>
<p class="noindent">The result is as expected.</p>
<p class="indent">This section explores three approaches to sampling from arbitrary discrete distributions. Two approaches expect the PMF to be normalized (sums to 1), while the third uses a PMF expressed as integer ratios between the elements. This may seem to be a drawback, but we often sample from distributions approximated by histograms, and the bins of a histogram are integer counts.</p>
<h4 class="h4" id="ch00lev2_98"><em><strong>Sequential Search</strong></em></h4>
<p class="noindent">In <a href="ch07.xhtml">Chapter 7</a>, we generated fractals using IFS by applying maps selected according to a given probability. In other words, we sampled from a distribution over maps. The code we used is in <a href="ch012.xhtml#ch012list02">Listing 12-2</a>.</p>
<pre class="pre">def ChooseMap(self):
    r = self.rng.random()
    a = 0.0
    k = 0
    for i in range(self.nmaps):
        if (r &gt; a):
            k = i
        else:
            return k
        a += self.probs[i]
    return k</pre>
<p class="list" id="ch012list02"><em>Listing 12-2: Choosing a map</em></p>
<p class="indent"><a href="ch012.xhtml#ch012list02">Listing 12-2</a> implements a version of <em>inversion sampling by sequential search</em>; at least, that’s what Luc Devroye calls it in his book <em>Non-Uniform Random Variate Generation</em> (Springer, 1986). You’ll find Devroye’s book on his website, <em><a href="http://luc.devroye.org/books-luc.html">http://luc.devroye.org/books-luc.html</a></em>. He’s giving it away. I recommend grabbing a copy.</p>
<p class="indent">The implementation in <a href="ch012.xhtml#ch012list02">Listing 12-2</a> isn’t exactly terse. We can do better, as in <a href="ch012.xhtml#ch012list03">Listing 12-3</a>.</p>
<pre class="pre">def Sequential(probs, rng):
    k = 0
    u = rng.random()
    while u &gt; 0:
        u -= probs[k]
        k += 1
    return k-1</pre>
<p class="list" id="ch012list03"><em>Listing 12-3: A more parsimonious implementation of inversion by sequential search</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_330"/>First, we hand the function the PMF as <code>probs</code>, which we expect to be normalized. The second argument is our old friend, an instance of <code>RE</code> configured to return floats in [0, 1).</p>
<p class="indent">The code picks a uniformly distributed value, <code>u</code>, and subtracts the probabilities in <code>probs</code>, in order, until the result is zero or negative. We then return the number of times we subtract, <code>k</code>, as the sampled index into <code>probs</code> after adjusting for indexing from zero.</p>
<p class="indent">We can visualize the sampling process as in <a href="ch012.xhtml#ch012fig03">Figure 12-3</a> using the unnormalized PMF we discussed earlier.</p>
<p class="center"><em>p<sub>X</sub></em>(<em>x</em>) = [1, 1, 3, 4, 5, 1, 7, 4, 3]</p>
<div class="image"><img alt="Image" id="ch012fig03" src="../images/12fig03.jpg"/></div>
<p class="figcap"><em>Figure 12-3: Sequential sampling of a discrete distribution</em></p>
<p class="indent">The Probability row reflects this PMF where the length of each box is in proportion to the other boxes so that the 7 box is seven times longer than the 1 box. To get the probability passed in <code>probs</code>, divide each box label by the sum, 29.</p>
<p class="indent"><a href="ch012.xhtml#ch012fig03">Figure 12-3</a> shows a selected <em>u</em> as a double arrow. This <em>u</em> is about 0.4 because it’s a bit less than half the distance across the entire PMF, which must sum to 1. The vertical line after the box labeled 5 marks the full set of probabilities subtracted from <em>u</em> until <em>u</em> &lt; 0. We subtract five boxes in this order: 1, 1, 3, 4, and 5. Adjust for indexing from 0, and the returned sample is 4—the label on the matched box below <em>u</em> in the Value row. Ignore the Reorder row for the time being.</p>
<p class="indent">This process maps [0, 1) to [0, 8] using the width of the boxes to transform the uniform input to a nonuniform output that will match the desired PMF if we draw enough samples. Try selecting other samples by closing your eyes and placing your finger somewhere on <a href="ch012.xhtml#ch012fig03">Figure 12-3</a>’s Probability row. Then, slide your finger down to the Value row and read off the output, which is the number of boxes covered from the left. After repeating this a few times, you should see that 6 will be chosen most often, followed by 4. Inversion sampling by sequential search is our first discrete sampling algorithm.</p>
<p class="indent">Let’s make one minor improvement. The top row of <a href="ch012.xhtml#ch012fig03">Figure 12-3</a> presents the PMF in order, meaning the probability assigned to 0 is 1/29, while the probability assigned to 6 is 7/29. This makes sense if we use <a href="ch012.xhtml#ch012list03">Listing 12-3</a> to sample from the distribution. However, to get 6 (the most frequent value) <span epub:type="pagebreak" id="page_331"/>as a sample, we need to search from the beginning of the probability vector each time. If we list the probabilities in descending order, we’ll select the most likely outcome after one pass through the <code>while</code> loop of <a href="ch012.xhtml#ch012list03">Listing 12-3</a>. The next most likely outcome requires only two passes, and so on. This notion leads to the Reorder row of <a href="ch012.xhtml#ch012fig03">Figure 12-3</a>.</p>
<p class="indent">The bars of the Reorder row run from left to right in decreasing size order, with the label on each bar listing the value to return should that bar be selected. Notice, the algorithm in <a href="ch012.xhtml#ch012list03">Listing 12-3</a> doesn’t change; it’s still subtracting probabilities from <em>u</em>, but they’re now ordered from greatest to least. Therefore, we must map the index returned by <a href="ch012.xhtml#ch012list03">Listing 12-3</a> to identify the true value selected. For example, if <a href="ch012.xhtml#ch012list03">Listing 12-3</a> returns index 1, the mapping knows that 1 → 4 to return 4 as the selected value. This adjustment should speed things up, depending on the arrangement of probabilities in <code>probs</code>. The reordering tweak is our second discrete sampling algorithm.</p>
<h4 class="h4" id="ch00lev2_99"><em><strong>Fast-Loaded Dice Roller</strong></em></h4>
<p class="noindent">Our final discrete sampling algorithm is relatively new: the <em>Fast Loaded Dice Roller (FLDR)</em>, presented by Saad et al. in their 2020 paper, “The Fast Loaded Dice Roller: A Near-Optimal Exact Sampler for Discrete Probability Distributions.” You’ll find the code and paper on their GitHub site at <em><a href="https://github.com/probcomp/fast-loaded-dice-roller">https://github.com/probcomp/fast-loaded-dice-roller</a></em>. We need only the <em>fldr.py</em> file from the <em>src/python</em> directory. Either copy that file from the GitHub repo via your browser or install the full package with <code>pip</code>:</p>
<pre class="pre">&gt; <span class="codestrong1">pip3 install fldr</span></pre>
<p class="noindent">If you copy <em>fldr.py</em> from GitHub, place it in the folder for this chapter.</p>
<p class="indent">The FLDR paper describes the algorithm and its genesis. It also refers to the Devroye book mentioned earlier, which motivated the algorithm’s design. We won’t discuss the details, as they’re rather involved and mathematical. However, it’s interesting to learn that there are more sophisticated ways of thinking about sampling from a discrete distribution.</p>
<p class="indent">The version of FLDR we’ll use wants PMFs as vectors of integers, precisely as I’ve presented them so far. Using the FLDR requires two steps; the first conditions the algorithm based on the PMF, and the second draws individual samples on demand. We need the <code>fldr_preprocess_int</code> function to configure the sampler and the function <code>fldr_sample</code> to draw a sample. The FLDR code is not NumPy aware, but we can live with that.</p>
<p class="indent">Now that we have our algorithms, we’ll pit them against each other.</p>
<h4 class="h4" id="ch00lev2_100"><em><strong>Runtime Performance</strong></em></h4>
<p class="noindent">Let’s find out whether our algorithms work, and how they compare to each other in terms of runtime performance.</p>
<p class="indent"><span epub:type="pagebreak" id="page_332"/>First, run <em>discrete_test.py</em> without arguments:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 discrete_test.py</span>
discrete_test &lt;N&gt; [&lt;kind&gt; | &lt;kind&gt; &lt;seed&gt;]

  &lt;N&gt;    - number of samples
  &lt;kind&gt; - randomness source
  &lt;seed&gt; - seed</pre>
<p class="noindent">The command line’s form is familiar. The only required argument is the number of samples to draw from the nine-element distribution presented at start of “Discrete Distributions” on <a href="ch012.xhtml#ch00lev1_79">page 328</a>: [1, 1, 3, 4, 5, 1, 7, 4, 3].</p>
<p class="indent">Let’s select some samples:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 discrete_test.py 5000 minstd 476</span>
[157 187 504 722 813 155 1251 693 518] (0.033361 s, sequential)
[164 171 526 674 904 162 1198 702 499] (0.029343 s, reordered)
[165 178 510 702 870 166 1225 683 501] (0.005494 s, FLDR)
[172 172 517 690 862 172 1207 690 517] expected</pre>
<p class="indent">The command line requests 5,000 samples and displays the number of times each possible output was selected by algorithm type. For example, 1 was selected 187 times by the sequential algorithm. As we expect, 6 is the most frequent output. The final line contains the expected number of samples, found by multiplying the probability by the number of samples, rounded to the nearest integer.</p>
<p class="indent">The three algorithms appear to work as expected, with the results close to the expected output. Looking at the runtime on the right, the sequential algorithm is the slowest, the reordered algorithm is slightly faster, and FLDR is nearly an order of magnitude faster still.</p>
<p class="indent">If we ask for 50 samples instead of 5,000</p>
<pre class="pre">&gt; <span class="codestrong1">python3 discrete_test.py 50 minstd 476</span>
[2  0 10  5 13  0 12  4  4] (0.000363 s, sequential)
[2  1  5  7 13  1  8  8  5] (0.000451 s, reordered)
[3  2  6  5  4  2 12  8  8] (0.000101 s, FLDR)
[2  2  5  7  9  2 12  7  5] expected</pre>
<p class="noindent">the output is noisy, as the expected frequency and the sampled frequencies are farther apart; for example, the sequential algorithm picked 2 in 10 instances while the expected frequency is only 5.</p>
<p class="indent"><a href="ch012.xhtml#ch012fig04">Figure 12-4</a> demonstrates this effect visually using FLDR to select 50 versus 5,000 samples.</p>
<div class="image"><img alt="Image" id="ch012fig04" src="../images/12fig04.jpg"/></div>
<p class="figcap"><span epub:type="pagebreak" id="page_333"/><em>Figure 12-4: Sampling from a discrete distribution using 50 samples (left) and 5,000 (right)</em></p>
<p class="indent">The bars are the true distribution and the dots are the samples, both expressed as probabilities.</p>
<p class="indent"><a href="ch012.xhtml#ch012fig05">Figure 12-5</a> displays the runtime performance of our samplers for ⌊<em>N<sup>α</sup></em>⌋ samples with <em>α</em> running from 1 to 6 in 25 steps. Note that the <em>x</em>-axis is in units of 1 million.</p>
<div class="image"><img alt="Image" id="ch012fig05" src="../images/12fig05.jpg"/></div>
<p class="figcap"><em>Figure 12-5: Sample time as a function of the number of samples</em></p>
<p class="indent">We can safely say that all three sampling algorithms run in <img alt="Image" class="inline" src="../images/c0301-01.jpg"/>(<em>n</em>) time. However, <a href="ch012.xhtml#ch012fig05">Figure 12-5</a> is a good practical example for us. Big O notation ignores multiplicative factors, so while all three algorithms run in linear time, in practice we’ll want to use FLDR.</p>
<p class="indent">Let’s walk through <em>discrete_test.py</em>, starting with the setup (<a href="ch012.xhtml#ch012list04">Listing 12-4</a>).</p>
<pre class="pre">from fldr import fldr_preprocess_int, fldr_sample
N = int(sys.argv[1])

if (len(sys.argv) == 4):
    rng = RE(kind=sys.argv[2], seed=int(sys.argv[3]))
elif (len(sys.argv) == 3):
    rng = RE(kind=sys.argv[2])
else:
    rng = RE()

probabilities = [1,1,3,4,5,1,7,4,3]
prob = np.array(probabilities)
prob = prob / prob.sum()
M = len(prob)</pre>
<p class="list" id="ch012list04"><em>Listing 12-4: Setting up</em> discrete_test.py</p>
<p class="indent"><span epub:type="pagebreak" id="page_334"/>We’ll focus on the beginning, where we introduce functions from <code>fldr</code>, and on the end, where we define <code>probabilities</code>.</p>
<p class="indent">FLDR wants integer counts, so we use <code>probabilities</code> in that case. When working with sequential sampling algorithms, which need true probabilities, we use <code>prob</code>.</p>
<p class="indent"><a href="ch012.xhtml#ch012list05">Listing 12-5</a> uses each algorithm to draw the requested number of samples. Each case creates a vector of the samples, <code>z</code>, timing how long it takes. A list comprehension draws the samples.</p>
<pre class="pre">s = time.time()
z = np.array([Sequential(prob,rng) for i in range(N)])
e = time.time() - s
h = np.bincount(z, minlength=M)
print(h, ("(%0.6f s, sequential)" % e))

idx = np.argsort(prob)[::-1]
p = prob[idx]
s = time.time()
z = np.array([Sequential(p,rng) for i in range(N)])
e = time.time() - s
h = np.bincount(idx[z], minlength=M)
print(h, ("(%0.6f s, reordered)" % e))

s = time.time()
x = fldr_preprocess_int(probabilities)
z = np.array([fldr_sample(x) for i in range(N)])
e = time.time() - s
h = np.bincount(z, minlength=M)
print(h, ("(%0.6f s, FLDR)" % e))

print(np.round(prob*N).astype("uint32"), "expected")</pre>
<p class="list" id="ch012list05"><em>Listing 12-5: Sampling with each algorithm</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_335"/>The first code paragraph calls <code>Sequential</code>, which we saw in <a href="ch012.xhtml#ch012list03">Listing 12-3</a>, and then creates the histogram with <code>bincount</code> before displaying the counts and generation time.</p>
<p class="indent">The second paragraph ultimately calls <code>Sequential</code>, but first rearranges <code>prob</code> to be in decreasing sort order. NumPy’s <code>argsort</code> returns the indices that sort <code>prob</code> in ascending order. The <code>[::-1]</code> idiom reverses the list to put <code>idx</code> in decreasing order.</p>
<p class="indent">We then call <code>Sequential</code> with <code>p</code> instead of <code>prob</code>. This means that the values in <code>z</code> are not the proper indices, but indices into <code>idx</code>, which holds the proper indices. In other words, <code>idx</code> is the mapping to get the proper sample values. A call to <code>bincount</code> using <code>idx</code> indexed by <code>z</code> generates the correct sample frequencies. Consider taking a moment to convince yourself that <code>idx[z]</code> makes sense.</p>
<p class="indent">Symmetry tells us that the final code paragraph in <a href="ch012.xhtml#ch012list05">Listing 12-5</a> draws samples using FLDR by repeated calls to <code>fldr_sample</code>. But first, we have to pass the probabilities to <code>fldr_preprocess_int</code> to create the structure <code>fldr_sample</code> uses.</p>
<p class="indent">The final line of <a href="ch012.xhtml#ch012list05">Listing 12-5</a> displays the expected per-value counts by rounding the product of the probability and the number of samples, <code>N</code>.</p>
<p class="indent">What if the distribution we want to sample from is two dimensional? What does that even mean? Let’s find out.</p>
<h4 class="h4" id="ch00lev2_101"><em><strong>Two Dimensions</strong></em></h4>
<p class="noindent">We can store a one-dimensional discrete distribution in a vector. By extension, we might imagine storing a two-dimensional distribution in a matrix. But how do we interpret the distribution?</p>
<p class="indent">Since a one-dimensional distribution tells us how often we should expect to sample each value, then a two-dimensional distribution refers to a <em>pair</em> of values, namely the indices of each dimension.</p>
<p class="indent">Consider this two-dimensional distribution, for example:</p>
<div class="image1"><img alt="Image" src="../images/f0335-01.jpg"/></div>
<p class="noindent">The sum of all elements is 1, so <em>p<sub>X</sub></em>(<em><strong>x</strong></em>) is a PMF. Note that I have replaced <em>x</em> with <em><strong>x</strong></em>, a vector. We can also write <em>p<sub>X</sub></em>(<em>x</em>, <em>y</em>) to emphasize that we have two dimensions.</p>
<p class="indent">The distribution says that <em>P</em>(<em>X</em> = 0, <em>Y</em> = 0) = 0.1 while <em>P</em>(<em>X</em> = 2, <em>Y</em> = 3) = 0.2, that is, the value of the variables are the indices of the rows and columns of the matrix representing the distribution. Two-dimensional probability distributions show up when considering joint distributions—how often a pair of random variables appear together with some combination of values.</p>
<p class="indent"><span epub:type="pagebreak" id="page_336"/>We’ll use our existing sampling techniques to draw samples from a two-dimensional distribution by unraveling the distribution, sampling, and converting the samples back to two-dimensional pairs. For example, unraveling the previous distribution gives us:</p>
<p class="center"><em>p<sub>X</sub></em>(<em>x</em>) = [0.1, 0.0, 0.1, 0.2, 0.0, 0.0, 0.1, 0.1, 0.2, 0.0, 0.0, 0.2]</p>
<p class="indent">If we sample from this distribution using one of the aforementioned algorithms, we’ll get samples in the range [0, 11]. To convert the samples back to pairs, we must undo the raveling, meaning we need to know the number of rows and columns in the original two-dimensional distribution.</p>
<p class="indent">Let’s walk through an example. Run <em>discrete_ravel.py</em> with this command line:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 discrete_ravel.py 1000 mt19937 10101</span></pre>
<p class="indent">The output consists of four sections. The code itself samples from the previous <em>p<sub>X</sub></em>(<em><strong>x</strong></em>) by unraveling it, sampling, then mapping the samples back to (<em>x</em>, <em>y</em>) pairs that represent the frequency with which combinations of <em>x</em> and <em>y</em> appear. If all goes well, one- and two-dimensional histograms of these frequencies should approximate <em>p<sub>X</sub></em>(<em><strong>x</strong></em>).</p>
<p class="indent">The first output line gives us:</p>
<pre class="pre">[0.091 0. 0.1 0.204 0. 0. 0.091 0.104 0.205 0. 0. 0.205]</pre>
<p class="noindent">This is a PMF generated from the samples drawn using the unraveled histogram. The values are all around 0.1 and 0.2, which is encouraging.</p>
<p class="indent">The second output block is the same estimated PMF remapped to two dimensions:</p>
<pre class="pre">[[0.091 0.    0.1   0.204]
 [0.    0.    0.091 0.104]
 [0.205 0.    0.    0.205]]</pre>
<p class="noindent">This looks very much like <em>p<sub>X</sub></em>(<em><strong>x</strong></em>).</p>
<p class="indent">The estimated PMF looks right. As for the sampled values, here are the first eight drawn from the unraveled PMF:</p>
<pre class="pre">[ 3 11 11 7 3 0 7 8]</pre>
<p class="noindent">Mapped back to pairs, these samples become:</p>
<pre class="pre">[(0,3), (2,3), (2,3), (1,3), (0,3), (0,0), (1,3), (2,0)]</pre>
<p class="noindent">The conversion from one-dimensional sample to two-dimensional pair is</p>
<p class="center">(<em>x</em>, <em>y</em>) = (<em>z</em> ÷ 4, <em>z</em> mod 4)</p>
<p class="noindent">where <em>z</em> is the 1D sample value and ÷ means integer division. The 4 comes from the number of columns in the two-dimensional PMF.</p>
<p class="indent"><a href="ch012.xhtml#ch012list06">Listing 12-6</a> shows the unravel, sample, remap process.</p>
<pre class="pre">prob2 = np.array([[0.1, 0.0, 0.1, 0.2], 
                  [0.0, 0.0, 0.1, 0.1], 
                  [0.2, 0.0, 0.0, 0.2]])
prob = prob2.ravel()

z = np.array([Sequential(prob,rng) for i in range(N)])
h = np.bincount(z, minlength=len(prob))
h = h / h.sum()

print(h)
print(h.reshape((3,4)))
print(z[:8])

x,y = np.unravel_index(z[:8], prob2.shape)
print([i for i in zip(x,y)])</pre>
<p class="list" id="ch012list06"><em>Listing 12-6: Sampling a two-dimensional PMF by unraveling</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_337"/>The two-dimensional PMF is in <code>prob2</code>, which unravels to become the one-dimensional PMF <code>prob</code>. The second paragraph samples from <code>prob</code> as we did earlier. Notice <code>rng</code>, an instance of our <code>RE</code> class. I’m ignoring some of the code head of <em>discrete_ravel.py</em>, so make sure to review the file itself. As before, the sample counts come from <code>bincout</code>, which we then turn back into a one-dimensional PMF by dividing <code>h</code> by the sum of the counts.</p>
<p class="indent">Three of the four outputs come next as <code>h</code>, <code>h</code> reshaped as a 3×4 matrix, and the first eight samples from <code>z</code>.</p>
<p class="indent">When mapping samples to pairs, we save time by calling <code>unravel_index</code>, which needs the one-dimensional indices along with the shape of the source array—here 3×4 from <code>prob2</code>. NumPy returns the <em>x</em>- and <em>y</em>-coordinates, so a pair is (<em>x</em><sub>0</sub>, <em>y</em><sub>0</sub>) and so on, as given by the list comprehension using <code>zip</code>.</p>
<p class="indent">We can also use this unraveling approach for distributions of more than two dimensions. If we have three random variables—<em>X</em>, <em>Y</em>, and <em>Z</em>—then samples from a three-dimensional PMF, <em>p<sub>XYZ</sub></em>(<em>x</em>, <em>y</em>, <em>z</em>), are triplets, (<em>x</em>, <em>y</em>, <em>z</em>), according to the probability with which a particular combination of values appears. We unravel, sample in one dimension, and use <code>unravel_index</code> to map back to triplets. Bear in mind that as the dimensionality increases, the number of samples necessary to reasonably approximate the distribution goes up dramatically.</p>
<p class="indent">Suppose every random variable in our system takes on one of 10 possible values. If we have only one variable, we must sample from a probability distribution representable as a vector of 10 elements. With two random variables, we need a matrix to represent the joint distribution, a 10 × 10 = 100-element vector when unraveled. If we have three random variables, we unravel to a vector of 10 × 10 × 10 = 1,000 elements; for four random variables, we need 10,000 elements.</p>
<p class="indent">Fixing the number of values at 10, an <em>n</em>-dimensional PMF unravels into a vector of 10<em><sup>n</sup></em> elements—the distribution size scales exponentially with <span epub:type="pagebreak" id="page_338"/>dimensionality. Therefore, this trick works best for only two or three dimensions.</p>
<h4 class="h4" id="ch00lev2_102"><em><strong>Images</strong></em></h4>
<p class="noindent">Now for a bit of fun. The code in <em>discrete_2d.py</em> knows how to use grayscale versions of images as discrete two-dimensional probability distributions, so we can sample from them. A grayscale image is a matrix of integer values from 0 to 255, making an unraveled grayscale image immediately useful to FLDR as a distribution.</p>
<p class="indent">Samples become pixel locations. The higher the image intensity at a pixel, the more likely it is to be sampled. Therefore, if we draw enough samples, scale them to [0, 1], and multiply by 255, we can transform the estimated distribution back into an image and compare it with the original. That’s a lot of words; let’s look at some code.</p>
<p class="indent">The four paragraphs in <a href="ch012.xhtml#ch012list07">Listing 12-7</a> present the essential code, minus imports and command line processing.</p>
<pre class="pre">image = Image.open(iname).convert("L")
row, col = image.size
row //= 2
col //= 2
image = np.array(image.resize((row,col),Image.BILINEAR))
p = image.ravel()
probabilities = [int(t) for t in p]

x = fldr_preprocess_int(probabilities)
z = np.array([fldr_sample(x) for i in range(N)])

x,y = np.unravel_index(z, (col,row))
im = np.zeros((col,row))
for i in range(len(x)):
    im[x[i],y[i]] += 1
im = im / im.max()

os.system("rm -rf %s; mkdir %s" % (oname,oname))
Image.fromarray(image).save(oname+"/"+os.path.basename(iname))
Image.fromarray((255*im).astype("uint8")).save(oname+"/histogram2d.png")</pre>
<p class="list" id="ch012list07"><em>Listing 12-7: Treating images as two-dimensional distributions and sampling from them</em></p>
<p class="indent">To turn the input image into a one-dimensional distribution, we first load the image, resize it to half its original dimensionality, and then unravel it into a list of pixel intensities, [0, 255]. Using a list comprehension with <code>int</code> is necessary because FLDR doesn’t work with NumPy arrays.</p>
<p class="indent">The next paragraph configures FLDR (<code>x</code>) and then uses it to draw <code>N</code> samples (<code>z</code>), with <code>N</code> given on the command line.</p>
<p class="indent">Samples in hand, <code>unravel_index</code> turns the one-dimensional samples into (<em>x</em>, <em>y</em>) pairs, or pixel locations. We then use the pixel locations to populate <span epub:type="pagebreak" id="page_339"/><code>im</code>, a two-dimensional histogram counting the number of times FLDR selected each pixel. To convert <code>im</code> into an image, we must scale it so that the most often sampled pixel has a value of 1, which we get by dividing by the maximum.</p>
<p class="indent">The final few lines of code create an output directory and dump the original and sampled images into it. We must multiply <code>im</code>, now [0, 1], by 255 and make it an unsigned int before writing it to disk as an image.</p>
<p class="indent">Run <em>discrete_2d.py</em> without arguments to learn the command line options. Try experimenting with the images in <em>test_images</em> and those in <em>images</em>. The latter contains high-contrast images that might make it easier to see where samples are coming from, especially the inverted images (those with “_inv” in their filename). The ramp images present a linear, quadratic, and cubic ramp, from left to right. We’ll sample brighter regions first as they’re more probable.</p>
<p class="indent"><a href="ch012.xhtml#ch012fig06">Figure 12-6</a> shows one of the high-contrast images where white areas are most likely to be sampled. This version of the image prints well. The inverse version requires far fewer samples in general.</p>
<div class="image"><img alt="Image" id="ch012fig06" src="../images/12fig06.jpg"/></div>
<p class="figcap"><em>Figure 12-6: Original hawk image (top left) and sampled images with an increasing number of samples</em></p>
<p class="indent">In <a href="ch012.xhtml#ch012fig06">Figure 12-6</a>, the original image is in the upper left, followed by sampled images using 60,000, 120,000, 240,000, 480,000, and 960,000 samples, left to right and top to bottom. I used this command line</p>
<pre class="pre">&gt; <span class="codestrong1">python3 discrete_2d.py images/hawk.png 120_000 tmp mt19937 19937</span></pre>
<p class="noindent">varying the number of samples as needed.</p>
<p class="indent">This experiment concludes our investigation of sampling from discrete distributions. Let’s move on to the more mathematically relevant case of sampling from continuous distributions and learn some new techniques, culminating in our introduction to the world of Markov Chain Monte Carlo.</p>
<h3 class="h3" id="ch00lev1_80"><strong>Continuous Distributions</strong></h3>
<p class="noindent"><span epub:type="pagebreak" id="page_340"/>Let’s change focus to consider continuous distributions, represented by PDFs that admit any real number input over their range. The techniques of the previous section no longer work in this case—at least not without alteration—but other methods exist, three of which we’ll explore: inverse transform sampling, rejection sampling, and Markov Chain Monte Carlo.</p>
<h4 class="h4" id="ch00lev2_103"><em><strong>Inverse Transform</strong></em></h4>
<p class="noindent">We represent continuous distributions by PDFs. Note the word <em>function</em>, which tells us there’s a mathematical relationship describing the shape of the PDF. The CDF for a given PDF is an integral:</p>
<div class="image1"><img alt="Image" src="../images/f0340-01.jpg"/></div>
<p class="noindent">The integral is the continuous version of summing discrete probabilities. It represents the area under the PDF from –<em>∞</em> to some <em>x</em>. Replace –<em>∞</em> with any value below which the PDF is always zero.</p>
<p class="indent">The CDF runs from 0 up to 1, meaning that a plot of the CDF produces <em>y</em>-axis values that begin with 0 and end with 1; review <a href="ch012.xhtml#ch012fig01">Figure 12-1</a>’s CDFs. If we pick a random value on the <em>y</em>-axis of the CDF plot, slide horizontally from there to the curve, and move down to the <em>x</em>-axis, we’ll have a sample from the PDF. Pick another <em>y</em>-axis starting point and repeat the process to get a new <em>x</em> and yet another sample from the PDF. Uniformly sampling <em>y</em>-axis values in [0, 1] produces <em>x</em> values that, when histogrammed, follow the form of the PDF.</p>
<p class="indent">To express this process mathematically, flip the graph of a function, <em>F</em>(<em>x</em>), along the line <em>y</em> = <em>x</em> (which runs 45 degrees up from the <em>x</em>-axis in the first quadrant), and you have a graph of the inverse of the function, <em>F</em><sup>–1</sup>(<em>x</em>), if it exists. The inverse flips <em>x</em> and <em>y</em> values, meaning inputs to the inverse function act like <em>y</em> values for the function, and the output of the inverse function is the <em>x</em> producing that input for the function itself.</p>
<p class="indent">Therefore, if we know the functional form of the inverse of a function representing a CDF, we can sample from the PDF by selecting random values in [0, 1] as inputs and keeping the outputs of the inverse CDF as the desired samples. This process is <em>inverse transform sampling</em>.</p>
<p class="indent">Let’s work through an example. Suppose we want to draw samples from an <em>exponential distribution</em>, whose PDF is</p>
<p class="center"><em>f</em>(<em>x</em>) = λ<em>e</em><sup>–λ<em>x</em></sup></p>
<p class="noindent">with λ (lambda) being a constant that decides how quickly the PDF decays from a maximum of λ at <em>x</em> = 0. The most probable samples from this PDF are close to zero, with samples farther from zero less likely.</p>
<p class="indent">The CDF for this PDF is an integral:</p>
<div class="image1"><img alt="Image" src="../images/f0340-03.jpg"/></div>
<p class="indent"><span epub:type="pagebreak" id="page_341"/>Therefore, <em>F</em>(<em>x</em>) = 1 – <em>e</em><sup>–λ<em>x</em></sup>. If we find the inverse of this function, we can generate exponentially distributed samples from uniformly distributed inputs. To find the inverse, set the CDF equal to <em>u</em> (for <em>uniform sample</em>) and solve for <em>x</em>:</p>
<div class="image1"><img alt="Image" src="../images/f0341-01.jpg"/></div>
<p class="indent">We now have <em>F</em><sup>–1</sup>(<em>u</em>), a mapping from uniform inputs <em>u</em> in [0, 1], the range of the CDF, to <em>x</em>, a value selected based on the shape of the exponential distribution PDF. Before putting the inverse function to work, let’s make one more observation.</p>
<p class="indent">We don’t care, specifically, about the exact pairing of this <em>u</em> to that <em>x</em> in terms of a sequence of <em>u</em>’s. We plan on picking <em>u</em> values at random. Because <em>u</em> is in [0, 1], 1 – <em>u</em> is also in [0, 1], but “flipped” along the <em>u</em>-axis because it’s the complement of <em>u</em>, giving us two values that sum to 1. So, we can replace 1 – <em>u</em> in <em>F</em><sup>–1</sup>(<em>u</em>) with <em>u</em>, and our samples will still be from the exponential distribution. This step isn’t necessary, but it makes the plot of the inverse function look less strange to us, as we’re used to curves that decay from a high point as <em>x</em> increases to the right.</p>
<p class="indent"><a href="ch012.xhtml#ch012fig07">Figure 12-7</a> shows a plot of <em>F</em><sup>–1</sup>(<em>u</em>) = (–log <em>u</em>)/λ, where specific <em>u</em> values have been mapped to their respective <em>x</em> outputs.</p>
<div class="image"><img alt="Image" id="ch012fig07" src="../images/12fig07.jpg"/></div>
<p class="figcap"><em>Figure 12-7: Inverse transform sampling from</em> e<sup>–λ<em>x</em></sup> <em>using – log(</em>u<em>)/λ</em></p>
<p class="indent">The distribution of the <em>x</em> values—or a properly scaled histogram of many <em>x</em> values from many <em>u</em> inputs—will become a better approximation of λ<em>e</em><sup>–λ<em>x</em></sup> as the number of samples increases.</p>
<p class="indent"><span epub:type="pagebreak" id="page_342"/>The file <em>inverse.py</em> samples from functions supplied as the inverse of their CDF. In other words, we give the code <em>F</em><sup>–1</sup>(<em>u</em>) and the corresponding PDF, <em>f</em>(<em>x</em>), along with the desired number of samples, and it gives us the samples, along with a plot of the PDF and the histogram of the samples.</p>
<p class="indent">Let’s use the code to draw samples from <em>f</em>(<em>x</em>) = 2<em>e</em><sup>–2<em>x</em></sup>. The inverse CDF for this PDF is <em>F</em><sup>–1</sup>(<em>u</em>) = (–log <em>u</em>)/2. To draw 1,000 samples, use a command line like so:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 inverse.py 1000 "-np.log(u)/2" "2*np.exp(-2*x)" tmp minstd 90210</span></pre>
<p class="indent">The first argument is the desired number of samples. The second, enclosed in double quotation marks, is a NumPy-aware version of the code implementing <em>F</em><sup>–1</sup>(<em>u</em>) that uses NumPy functions and <code>u</code> as the independent variable. The next argument, also enclosed in double quotes, is <em>f</em>(<em>x</em>), the PDF. Note that it’s a function of <code>x</code>, not <code>u</code>. The remaining arguments are the output directory and the usual randomness source with an optional seed.</p>
<p class="indent">Figure 12 shows the output of <em>inverse.py</em> for 1,000 (left) and 10,000 (right) samples.</p>
<div class="image"><img alt="Image" id="ch012fig08" src="../images/12fig08.jpg"/></div>
<p class="figcap"><em>Figure 12-8: 1,000 (left) and 10,000 (right) samples from 2</em>e<sup><em>–2</em>x</sup></p>
<p class="indent">The code scales the output so the curve and histogram match. The samples follow the desired distribution, with more samples better representing the PDF. The 10,000 samples are beginning to select <em>x</em> values farther from zero.</p>
<p class="indent">Let’s walk through another example. The Kumaraswamy distribution is like the beta distribution, but the functional forms of the PDF and CDF are conducive to inverse sampling. Specifically:</p>
<div class="image1"><img alt="Image" src="../images/f0342-01.jpg"/></div>
<p class="noindent">Here, <em>a</em> and <em>b</em> are constants that define the shape of the distribution, much like the <em>a</em> and <em>b</em> of the beta distribution. I leave it as an exercise for you to show that <em>F</em><sup>–1</sup>(<em>u</em>) comes from <em>F</em>(<em>x</em>).</p>
<p class="indent"><span epub:type="pagebreak" id="page_343"/>Let’s draw samples from this distribution for <em>a</em> = 2 and <em>b</em> = 5. The command line we need is:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 inverse.py 10000 "(1-(1-u)**(1/5))**(1/2)"</span>
             <span class="codestrong1">"10*x**1*(1-x**2)**4" kumaraswamy pcg64 42</span></pre>
<p class="noindent">The resulting plot is in <a href="ch012.xhtml#ch012fig09">Figure 12-9</a>. As expected, the samples follow the shape of the distribution.</p>
<div class="image"><img alt="Image" id="ch012fig09" src="../images/12fig09.jpg"/></div>
<p class="figcap"><em>Figure 12-9: Sampling Kumaraswamy (2,5)</em></p>
<p class="indent">The primary code in <em>inverse.py</em> is straightforward because we supply the PDF and inverse CDF on the command line in a form that lets us use Python’s <code>eval</code> function:</p>
<pre class="pre">samples = np.zeros(N)

for i in range(N):
    u = rng.random()
    samples[i] = eval(ifunc)</pre>
<p class="noindent">That’s all there is. We create <code>samples</code> to hold the <code>N</code> requested samples, and then loop to generate <code>samples[i]</code> from <code>u</code> by evaluating the inverse CDF function passed from the command line as the <code>ifunc</code> string. The remainder of <em>inverse.py</em> creates the output plot.</p>
<p class="indent">Inverse transform sampling is direct and works from closed-form functions, but it’s of limited applicability because of the two conditions that must be met to allow its use. The PDF must produce a closed-form CDF, and that CDF must be invertible to get <em>F</em><sup>–1</sup>(<em>u</em>). This doesn’t happen too often, especially for arbitrary continuous PDFs. In “Exercises” on <a href="ch012.xhtml#ch00lev1_81">page 358</a>, I suggest another PDF/CDF combination that works with <em>inverse.py</em>, but only if you restrict <em>u</em> to something other than [0, 1).</p>
<p class="indent">Let’s explore the next continuous PDF sampling algorithm, rejection sampling. Unlike inverse transform sampling, rejection sampling works with arbitrary PDFs.</p>
<h4 class="h4" id="ch00lev2_104"><em><strong>Rejection</strong></em></h4>
<p class="noindent"><span epub:type="pagebreak" id="page_344"/>We want to draw samples from a function <em>q</em>(<em>x</em>) so that a histogram of many samples from the function converges on the shape of the function itself. While we don’t know how to sample directly from <em>q</em>(<em>x</em>), we can sample from a <em>proposal function</em> that we’ll call <em>p</em>(<em>x</em>). If we find a constant, <em>c</em>, such that</p>
<p class="center"><em>q</em>(<em>x</em>) <em>≤ cp</em>(<em>x</em>), ∀<em>x</em></p>
<p class="noindent">then we can use samples from <em>p</em>(<em>x</em>) to draw samples from <em>q</em>(<em>x</em>). Recall that ∀ means “for all.”</p>
<p class="indent">First, we draw a sample from the proposal function, <em>x ∼ p</em>(<em>x</em>), where <em>∼</em> means “draw a sample from.” This gives us a candidate <em>x</em> position.</p>
<p class="indent">Next, we pick a <em>y</em> value that’s some fraction of the way up from <em>x</em> but still less than <em>cp</em>(<em>x</em>). In other words, we pick a uniform value in the range [0, <em>cp</em>(<em>x</em>)], or <em>y</em> = <em>ucp</em>(<em>x</em>) for some <em>u</em> in [0, 1].</p>
<p class="indent">If <em>y ≤ q</em>(<em>x</em>), we keep <em>x</em> as a sample from <em>q</em>(<em>x</em>); otherwise, we reject <em>x</em> and repeat with another sample from <em>p</em>(<em>x</em>). We stop when the desired number of samples from <em>q</em>(<em>x</em>) have been kept.</p>
<p class="indent"><a href="ch012.xhtml#ch012fig10">Figure 12-10</a> shows the situation for two candidate <em>x</em> positions.</p>
<div class="image"><img alt="Image" id="ch012fig10" src="../images/12fig10.jpg"/></div>
<p class="figcap"><em>Figure 12-10: Rejection sampling with two candidate</em> x <em>positions</em></p>
<p class="indent">The solid curve is <em>q</em>(<em>x</em>), the function we want to sample from. The dashed curve, here a uniform value over the range of <em>q</em>(<em>x</em>), is <em>cp</em>(<em>x</em>).</p>
<p class="indent">Let’s look at <em>x</em> = <em>x</em><sub>0</sub> first. The algorithm says to sample from <em>p</em>(<em>x</em>), which gives us <em>x</em><sub>0</sub>. Next, we pick a <em>y</em> some fraction of the way up from <em>x</em><sub>0</sub> to <em>cp</em>(<em>x</em><sub>0</sub>). We can write this as <em>y</em><sub>0</sub> = <em>u</em><sub>0</sub><em>cp</em>(<em>x</em><sub>0</sub>). While we know that <em>y</em><sub>0</sub> will always be less than or equal to <em>cp</em>(<em>x</em><sub>0</sub>), we’re wondering whether <em>y</em><sub>0</sub> is less than <em>q</em>(<em>x</em><sub>0</sub>). For <em>x</em><sub>0</sub>, this is the case, so we accept <em>x</em><sub>0</sub> as a valid sample from <em>q</em>(<em>x</em>).</p>
<p class="indent">In <em>x</em><sub>1</sub>, <em>y</em><sub>1</sub> = <em>u</em><sub>1</sub><em>cp</em>(<em>x</em><sub>1</sub>) is greater than <em>q</em>(<em>x</em><sub>1</sub>), so we reject <em>x</em><sub>1</sub> as a valid sample from <em>q</em>(<em>x</em>) and the process repeats.</p>
<p class="indent"><span epub:type="pagebreak" id="page_345"/>Algorithmically, the process boils down to the following:</p>
<ol>
<li class="noindent"><em>x ∼ p</em>(<em>x</em>).</li>
<li class="noindent"><em>u ∼ U</em>[0, 1).</li>
<li class="noindent">If <em>ucp</em>(<em>x</em>) <em>≤ q</em>(<em>x</em>), accept <em>x</em> as a sample; otherwise, reject <em>x</em>.</li>
<li class="noindent">Repeat from step 1 until we’ve accepted <em>N</em> samples.</li>
</ol>
<p class="indent">You might see the condition of step 3 written as</p>
<div class="image1"><img alt="Image" src="../images/f0345-01.jpg"/></div>
<p class="noindent">which we get by dividing by <em>cp</em>(<em>x</em>). In that form, we’re asking whether <em>u</em> is less than the fraction of the way to <em>cp</em>(<em>x</em>) covered by <em>q</em>(<em>x</em>) for the selected <em>x</em>. If not, reject <em>x</em> and try again.</p>
<p class="indent">Think of rejection sampling as randomly throwing darts at the <em>xy</em>-plane. If the <em>y</em>-coordinate of the dart is less than both <em>cp</em>(<em>x</em>) and <em>q</em>(<em>x</em>), we accept the dart’s <em>x</em>-coordinate as a sample from <em>q</em>(<em>x</em>). In effect, we’re keeping all the <em>x</em>-coordinate values for darts that land under the <em>q</em>(<em>x</em>) curve. We did the same in <a href="ch03.xhtml">Chapter 3</a> to estimate <em>π</em>.</p>
<p class="indent">Let’s put this process into practice with <em>rejection.py</em>:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 rejection.py</span>
rejection &lt;N&gt; &lt;proposal&gt; &lt;c&gt; &lt;func&gt; &lt;limits&gt; &lt;outdir&gt; [&lt;kind&gt; | &lt;kind&gt; &lt;seed&gt;]

  &lt;N&gt;         - number of samples
  &lt;proposal&gt;  - uniform|normal_mu_sigma (e.g. normal_0_1)
  &lt;c&gt;         - proposal multiplier (e.g. 1)
  &lt;func&gt;      - function to sample from (e.g. 2*x**2+3)
  &lt;limits&gt;    - lo_hi limit on sampling range (e.g. -3_8.8)
  &lt;outdir&gt;    - output directory name (overwritten)
  &lt;kind&gt;      - randomness source
  &lt;seed&gt;      - seed</pre>
<p class="indent">Rejection sampling works for any proposal function, <em>p</em>(<em>x</em>), so long as we can draw samples from it, but <em>rejection.py</em> restricts us to two options: a uniform distribution, represented by the dashed line in <a href="ch012.xhtml#ch012fig10">Figure 12-10</a>, and a normal distribution with a given mean (<em>µ</em>) and standard deviation (<em>σ</em>). The Box-Muller transform lets us sample from a normal distribution (see <a href="ch01.xhtml">Chapter 1</a>).</p>
<p class="indent">Let’s reproduce the example in <a href="ch012.xhtml#ch012fig10">Figure 12-10</a>. The proposal function is a uniform distribution multiplied by 4.1, as this puts the proposal function just above the highest part of the sampling function, <em>q</em>(<em>x</em>)</p>
<div class="image1"><img alt="Image" src="../images/f0345-02.jpg"/></div>
<p class="noindent">which is the sum of two normal curves centered at ±5, with one being four times higher than the other.</p>
<p class="indent"><span epub:type="pagebreak" id="page_346"/>Now, we sample:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 rejection.py 100000 uniform 4.1</span>
    <span class="codestrong1">"np.exp(-((x-5)/2)**2)+4*np.exp(-((x+5)/2)**2)" -18_18 reject0 pcg64 1313</span>
832745 trials to get 100000 samples (30.7419 s)</pre>
<p class="indent">The output tells us we need over 830,000 candidate samples to get the requested 100,000. That’s a conversion rate of 12 percent, meaning we rejected 88 percent of the candidates. The efficiency of rejection sampling depends critically on the closeness between the proposal function, <em>cp</em>(<em>x</em>), and the sampling function, <em>q</em>(<em>x</em>). The closer the proposal function is to the sampling function, the better.</p>
<p class="indent"><a href="ch012.xhtml#ch012fig11">Figure 12-11</a> shows a histogram of the samples from <em>q</em>(<em>x</em>). The proposal function is in <a href="ch012.xhtml#ch012fig10">Figure 12-10</a>. Note that rejection sampling doesn’t care whether <em>p</em>(<em>x</em>) and <em>q</em>(<em>x</em>) are normalized (in which the area under the curves is 1). So long as <em>cp</em>(<em>x</em>) is above <em>q</em>(<em>x</em>), all will be well (if perhaps slow).</p>
<div class="image"><img alt="Image" id="ch012fig11" src="../images/12fig11.jpg"/></div>
<p class="figcap"><em>Figure 12-11: Sampling with a uniform proposal function</em></p>
<p class="indent">Let’s use a normal curve for the proposal function:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 rejection.py 100000 normal_0_1 4</span>
    <span class="codestrong1">"np.exp(-((x-5)/2)**2)+4*np.exp(-((x+5)/2)**2)" -18_18 reject1 pcg64 1313</span>
1511344 trials to get 100000 samples (62.7675 s)</pre>
<p class="noindent">The proposal function is now a normal curve with a mean of 0 and a standard deviation of 1. The multiplier is 4.</p>
<p class="indent">The output is in <em>reject1</em>. We’re told that we need 1.5 million candidates to get 100,000 samples for a conversion rate of 6.6 percent. <a href="ch012.xhtml#ch012fig12">Figure 12-12</a> shows the histogram (left) and a plot of the proposal and sampling functions (right). The plots might seem strange to you, for good reason.</p>
<div class="image"><img alt="Image" id="ch012fig12" src="../images/12fig12.jpg"/></div>
<p class="figcap"><span epub:type="pagebreak" id="page_347"/><em>Figure 12-12: Using N(0,1) as the proposal function</em></p>
<p class="indent">The proposal function is the dashed curve on the right in <a href="ch012.xhtml#ch012fig12">Figure 12-12</a>. It’s centered between the normal curves making up <em>q</em>(<em>x</em>), and is larger than <em>q</em>(<em>x</em>) over only a small region around zero. The algorithm can’t select samples in areas where <em>p</em>(<em>x</em>) &lt; <em>q</em>(<em>x</em>); therefore, it selects only in the region covering the overlap between the right part of the leftmost normal curve and the left part of the rightmost normal curve.</p>
<p class="indent">In the histogram on the left, the code scales <em>q</em>(<em>x</em>) and the histogram of the samples, so both have 1 as their maximum <em>y</em> value. The histogram peaks at two locations, the left and right maxima of the overlap region. While not what we’re after, the output from this run is correct, given the constraints.</p>
<p class="indent">Let’s try a few more examples. The file <em>run_rejection_examples</em> contains <a href="ch012.xhtml#ch012list08">Listing 12-8</a>.</p>
<pre class="pre">python3 rejection.py 100000 normal_0_20 4.2 
    "np.exp(-((x-5)/2)**2)+4*np.exp(-((x+5)/2)**2)" -18_18 reject2 pcg64 1313
python3 rejection.py 100000 normal_-5_2.4 4 
    "np.exp(-((x-5)/2)**2)+4*np.exp(-((x+5)/2)**2)" -18_18 reject3 pcg64 1313
python3 rejection.py 100000 uniform 4 
    "np.exp(-((x-5)/2)**2)+4*np.exp(-((x+5)/2)**2)" -11_4 reject4 pcg64 1313
python3 rejection.py 100000 uniform 158 
    "2*x**2+3" -3_8.8 reject5 pcg64 1313</pre>
<p class="list" id="ch012list08"><em>Listing 12-8: Additional examples</em></p>
<p class="indent"><a href="ch012.xhtml#ch012fig13">Figure 12-13</a> shows the generated plots for <em>reject2</em> through <em>reject5</em> from top to bottom.</p>
<p class="indent">The topmost plot covers the entire <em>q</em>(<em>x</em>) range, with samples drawn from each peak. The next row shows samples from only the left peak, as the proposal function covers it and a tiny part of the right peak. The third row limits selection to <em>x ∈</em> [–11, 4], restricting the range of samples while still mirroring the shape of <em>q</em>(<em>x</em>). The final row of <a href="ch012.xhtml#ch012list08">Listing 12-8</a> switches to a new function, <em>q</em>(<em>x</em>) = 2<em>x</em><sup>2</sup> + 3, and a uniform proposal function.</p>
<div class="image"><img alt="Image" id="ch012fig13" src="../images/12fig13.jpg"/></div>
<p class="figcap"><span epub:type="pagebreak" id="page_348"/><em>Figure 12-13: Histograms and proposal functions for the command lines in <a href="ch012.xhtml#ch012list08">Listing 12-8</a></em></p>
<p class="indent"><span epub:type="pagebreak" id="page_349"/>Experiment with <em>rejection.py</em> with <em>q</em>(<em>x</em>) functions and proposal functions that either completely or partially cover <em>q</em>(<em>x</em>). Remember to pick a <em>c</em> such that <em>q</em>(<em>x</em>) &lt; <em>cp</em>(<em>x</em>) for the regions from which you want to sample.</p>
<p class="indent">Rejection sampling isn’t restricted to one dimension. For example, if we have <em>q</em>(<em>x</em>, <em>y</em>), we can draw samples as long as we can sample from <em>p</em>(<em>x</em>, <em>y</em>). The uniform function, which is 1 for all (<em>x</em>, <em>y</em>) points, is an easy <em>p</em>(<em>x</em>, <em>y</em>) to use. A multivariate normal distribution will also work, though it’s harder to code and visualize. The algorithm remains the same, but instead of drawing <em>x</em> from <em>p</em>(<em>x</em>), we draw (<em>x</em>, <em>y</em>) from <em>p</em>(<em>x</em>, <em>y</em>)—a random point in 2D space. The test is still <em>ucp</em>(<em>x</em>, <em>y</em>) <em>≤ q</em>(<em>x</em>, <em>y</em>), or:</p>
<div class="image1"><img alt="Image" src="../images/f0349-01.jpg"/></div>
<p class="noindent">If the condition holds, the point (<em>x</em>, <em>y</em>) is a sample from <em>q</em>(<em>x</em>, <em>y</em>).</p>
<p class="indent">The extension to arbitrary dimensions, <em><strong>x</strong></em> = (<em>x</em><sub>0</sub>, <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, . . . ), follows as long as we can sample from <em>p</em>(<em><strong>x</strong></em>). However, as the dimensionality increases, the number of samples rejected tends to increase exponentially (for each new dimension) unless <em>p</em>(<em><strong>x</strong></em>) follows <em>q</em>(<em><strong>x</strong></em>) very closely, which is quite difficult to do while maintaining easy sampling from <em>p</em>(<em><strong>x</strong></em>). This effect, where the utility of rejection sampling decreases with the problem’s dimensionality, is a form of the <em>curse of dimensionality</em> that frequently plagues machine learning models as well.</p>
<p class="indent">The inefficiency of rejection sampling as the dimensionality of the problem increases leads to our final sampling algorithm, which handles high-dimensional problems: Markov Chain Monte Carlo.</p>
<h4 class="h4" id="ch00lev2_105"><em><strong>Markov Chain Monte Carlo</strong></em></h4>
<p class="noindent">Our final sampling algorithm is the most powerful: <em>Markov Chain Monte Carlo (MCMC)</em>. We learned about Monte Carlo algorithms in <a href="ch010.xhtml">Chapter 10</a>. The phrase <em>Markov chain</em>, named after Russian mathematician Andrey Markov (1856–1922), refers to a process where the <em>transition probability</em> of moving from a current state to a new state depends only on the current state and nothing that came before. Markov chains are helpful in simulations because what happens next depends solely on what the system is currently doing, regardless of its history.</p>
<p class="indent">MCMC uses Markov chains to approximate sampling from a complex probability distribution. A <em>stationary distribution</em> in Markov chains, typically denoted as <em><strong>π</strong></em>, is a vector in the discrete case or a PDF in the continuous case. Regardless of the initial distribution, walking the Markov chain eventually reaches the stationary distribution governed solely by the transition probabilities if specific criteria are met.</p>
<p class="indent">We’ll first delve into stationary distributions; then, we’ll explore the Metropolis-Hastings algorithm and use it to walk a continuous Markov chain—only to realize that its stationary distribution is the very PDF we want to sample from.</p>
<h5 class="h5"><span epub:type="pagebreak" id="page_350"/><strong>Walking a Markov Chain</strong></h5>
<p class="noindent">Let’s work through an example. Fezzes are all the rage this year. Everyone’s wearing them, and there are three colors: red, green, or blue. The probability of a person changing their fez color next year depends on the color they wear this year. The probabilities are fixed from year to year. What happens to an initial distribution of fez colors as time passes? Will the distribution of colors change continuously or eventually settle down to a specific, perhaps stationary, distribution?</p>
<p class="indent">We encode transition probabilities in a matrix where the row shows a current state (a fez color) and the columns of that row represent the probability of a transition from the current state to a new state—a new fez color, which may be the same as the current.</p>
<p class="indent">Consider this transition matrix:</p>
<div class="image1"><img alt="Image" src="../images/f0350-01.jpg"/></div>
<p class="indent">The rows are red, green, and blue fezzes, as are the columns. Therefore, if someone is wearing a red fez this year, they have a 53 percent chance of wearing a red fez again next year, a 5 percent chance of changing to a green fez, and a 42 percent chance of donning a blue fez. The row sums to 1, as it must. Similarly, a green fez aficionado has an 83 percent likelihood of continuing to wear a green fez next year, though 13 percent will switch to a red fez, and a rogue 4 percent will go all in on a blue fez.</p>
<p class="indent">To use the transition matrix, we need an initial distribution of fezzes:</p>
<div class="image1"><img alt="Image" src="../images/f0350-02.jpg"/></div>
<p class="noindent">The vector tells us 70 percent of the population owns a red fez, 24 percent a green one, and only 6 percent a blue one.</p>
<p class="indent">To find out what the distribution looks like next year, we need to see what happens to the proportion of the population wearing each fez color when acted on by the transition matrix. Those wearing a red fez transition to new colors according to the transition matrix’s first row, [0.53, 0.05, 0.42]. We multiply the red-fez wearers by the transition probabilities to get the fraction of next year’s fez colors from those currently wearing a red fez:</p>
<div class="image1"><img alt="Image" src="../images/f0350-03.jpg"/></div>
<p class="noindent">For the greens, we multiply the second row of the transition matrix by 0.24, and for the blues we multiply the last row by 0.06. Finally, we sum across to get the new distribution of fez colors.</p>
<p class="indent">In the end, these steps involve nothing more than multiplying the current distribution as a row vector by the transition matrix:</p>
<div class="image1"><img alt="Image" src="../images/f0350-04.jpg"/></div>
<p class="noindent"><span epub:type="pagebreak" id="page_351"/>Next year, 41 percent of the population will wear red fezzes, 25 percent will wear green, and nearly 34 percent blue. The Markov property tells us that the following distribution is this distribution multiplied again on the right by the transition matrix, and so on.</p>
<p class="indent">The file <em>markov_chain.py</em> accepts an initial distribution of fez colors (<em><strong>π</strong></em>) and a transition matrix (<em><strong>P</strong></em>) and generates the Markov chain until the distribution becomes stationary. To make things more interesting, the distribution of red, green, and blue fezzes is treated as an RGB color so that the output file, <em>markov_chain.png</em>, shows the transition from initial to stationary distribution as a color bar running from left to right.</p>
<p class="indent">Run the code with the previous values:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 markov_chain.py 70 24 6 [[53,5,42],[13,83,4],[14,29,57]]</span></pre>
<p class="indent">The first three values are the initial distribution: red, green, and blue fezzes. The final argument, which must not contain spaces, is a Python list representing the transition matrix. The values are not precisely the same as before, but the inputs are scaled by their respective sums so that</p>
<div class="image1"><img alt="Image" src="../images/f0351-01.jpg"/></div>
<p class="noindent">and likewise for the individual rows of the transition matrix.</p>
<p class="indent">We print the Markov chain</p>
<pre class="pre">[0.7  0.24 0.06]
[0.4106 0.2516 0.3378]
[0.297618 0.32732  0.375062]
[0.25279782 0.39532448 0.3518777 ]
[0.23463791 0.44280374 0.32255835]
[0.22708075 0.47280092 0.30011833]
[0.22383348 0.49081312 0.2853534 ]
[0.22238693 0.50131905 0.27629402]
[0.22171771 0.50733942 0.27094286]
[0.22139651 0.51075104 0.26785245]
[0.22123713 0.5126704  0.26609247]
[0.22115578 0.5137451  0.26509912]
[0.2211133  0.51434497 0.26454173]
[0.22109074 0.51467909 0.26423017]
[0.2210786  0.51486493 0.26405647]
[0.221072  0.5149682 0.2639598]
[0.2210684  0.51502555 0.26390605]
[0.22106642 0.51505738 0.2638762 ]
[0.22106533 0.51507504 0.26385963]
[0.22106473 0.51508484 0.26385043]
[0.2210644  0.51509028 0.26384532]</pre>
<p class="noindent">which tells us that the stationary distribution is 22 percent red, 51.5 percent green, and 26.4 percent blue fezzes.</p>
<p class="indent">Try experimenting with the code, changing the input distribution to <code>1 0 0</code> (100 percent red) or <code>0 0 1</code> (100 percent blue). You’ll always end up at <span epub:type="pagebreak" id="page_352"/>the stationary distribution, though the number of links in the chain might differ. Then, alter the transition matrix and see what happens.</p>
<p class="indent">The only portion of the code worth discussing builds the chain:</p>
<pre class="pre">eps = 1e-5
last = np.array([10,10,10])
chain = []

while (np.abs(d-last).sum() &gt; eps):
    print(d)
    chain.append(d)
    last = d
    d = d @ transition</pre>
<p class="indent">The <code>while</code> loop runs until the difference between the new distribution and the <code>last</code> distribution is less than or equal to <code>eps</code>. The <code>chain</code> list holds the sequence of distributions. We use <code>@</code> to perform the matrix multiplication, <em><strong>π</strong> ← <strong>πP</strong></em>.</p>
<p class="indent">The power behind MCMC comes from the fact that the Metropolis-Hastings algorithm, to which we now turn, runs the Markov chain without directly generating it, but as a proxy returns samples from <em><strong>π</strong></em> once the chain is long enough to reach the stationary distribution.</p>
<h5 class="h5"><strong>Exploring Metropolis-Hastings</strong></h5>
<p class="noindent">A paper titled “Equation of State Calculations by Fast Computing Machines” appeared in the June 1953 edition of <em>The Journal of Chemical Physics</em>. The authors were Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Edward Teller. The paper introduced the <em>Metropolis algorithm</em>, named as such because Metropolis’s name is first on the paper. However, as so often happens in the thoroughly human enterprise of science, the process that led to the algorithm is disputed. It appears more likely now that the actual inventors were Marshall and Arianna Rosenbluth, not Metropolis. All five authors have since passed away, so it’s doubtful we’ll ever know the whole story. We’ll refer to the algorithm by its modern name, the Metropolis algorithm, knowing full well that credit may belong elsewhere.</p>
<p class="indent">In 1970, Wilfred Hastings extended the algorithm to the case where the proposal distribution is not symmetric; hence the algorithm is now known as <em>Metropolis-Hastings (MH)</em>. We’ll restrict ourselves to a symmetric normal distribution as the proposal distribution, so, technically, we’re using only the Metropolis part.</p>
<p class="indent">MH generates samples using a proposal distribution in much the same way as rejection sampling; however, in this case, the proposal distribution walks around randomly (we’ll learn what that means soon) and, as a consequence, alters a Markov chain distribution. Run the random walk with proper rejection and acceptance of moves for long enough, and eventually, we’ll reach the Markov chain’s stationary distribution. At that point, the <span epub:type="pagebreak" id="page_353"/>samples MH returns are from the stationary distribution, which is the distribution we want to draw samples from in the first place. How convenient!</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>A full mathematical treatment of MH and what it’s doing under the hood is beyond what we tackle here. Those interested will find a good summary on Gregory Gundersen’s blog:</em> <a href="https://gregorygundersen.com/blog/2019/11/02/metropolis-hastings">https://gregorygundersen.com/blog/2019/11/02/metropolis-hastings</a><em>.</em></p>
</div>
<p class="indent">For our purposes, we’ll accept MH’s claims and instead look at the random walk version of the algorithm. MH requires a function to sample from, the functional form we want our samples to follow when we make a histogram of their distribution. This is the stationary distribution for a Markov chain, so we’ll call this function <em>π</em>(<em>x</em>) (not to be confused with the number, <em>π</em>). MH works well in the multidimensional case, but we’ll limit ourselves to one dimension, so it’s <em>π</em>(<em>x</em>) and not <em><strong>π</strong></em>(<em>x</em>).</p>
<p class="indent">MH also requires a proposal distribution, <em>Q</em>(<em>x</em>). We’ll use a normal distribution because it’s symmetric, and we know how to sample from it efficiently, <em>x′ ∼ N</em>(<em>x</em>, <em>σ</em>) for a user-supplied <em>σ</em> and mean <em>x</em>.</p>
<p class="indent">With <em>π</em>(<em>x</em>) and <em>Q</em>(<em>x</em>) on hand, random walk MH is straightforward:</p>
<ol>
<li class="noindent">Pick an initial sample, <em>x</em>; for example, <em>x</em> = 1.</li>
<li class="noindent">Propose a new sample based on the current: <em>x′ ∼ N</em>(<em>x</em>, <em>σ</em>).</li>
<li class="noindent">Define <img alt="Image" class="inline" src="../images/f0353-01.jpg"/></li>
<li class="noindent">Define <em>ρ</em> = min(1, <em>A</em>).</li>
<li class="noindent">Define <em>u ∼</em> uniform(0, 1).</li>
<li class="noindent">If <em>u</em> &lt; <em>ρ</em>, accept <em>x′</em>, <em>x ← x′</em>.</li>
<li class="noindent">Otherwise, keep <em>x</em>.</li>
<li class="noindent">Output <em>x</em> as a sample.</li>
<li class="noindent">Repeat steps 2–8 until all desired samples are collected.</li>
</ol>
<p class="indent">The acceptance value, <em>A</em>, evaluates the function we want to sample from using the current sample position, <em>x</em>, and the proposed sample position, <em>x′</em>. If this value, passed through <em>ρ</em> (rho) to limit it to a maximum of 1, is less than a random uniform sample, accept the proposal (<em>x′</em>) as a new sample; otherwise, stick with the current sample, <em>x</em>. Before looping, output whatever <em>x</em> is as a sample from the distribution, <em>π</em>(<em>x</em>).</p>
<p class="indent">This algorithm is the simplest way to implement MH. In practice, we can make it even simpler because there’s no need to define <em>ρ</em>; we can use <em>A</em> as it is because <em>u</em> is always in [0, 1).</p>
<p class="indent">In step 2, the new proposal position, <em>x′</em>, comes from the proposal function, a normal distribution centered on <em>x</em>, the current sample. This is the random walk part. In step 6, if <em>x′</em> is ultimately accepted, it becomes the new <em>x</em> we use to pick the next proposal position. In other words, the normal curve jumps to a new position on the <em>x</em>-axis when a proposal is accepted. We’ll soon generate animations showing this behavior.</p>
<p class="indent"><span epub:type="pagebreak" id="page_354"/>We base acceptance or rejection on the value of <em>π</em>(<em>x′</em>) and <em>π</em>(<em>x</em>), that is, the ratio of <em>π</em>’s <em>y</em> value at the proposed new sample position and the current. If <em>π</em> has a high value at the current position, the fraction, <em>A</em>, will be small, meaning the comparison in step 6 is less likely to succeed. If the proposal is rejected, <em>x</em> is output again as a sample from <em>π</em>. We want this because <em>π</em> has a high <em>y</em> value at that <em>x</em>. If <em>π</em>(<em>x</em>) is tiny, <em>π</em>(<em>x′</em>) is more likely greater, meaning <em>A</em> is greater than 1. If <em>A</em> &gt; 1, <em>ρ</em> = 1 and the proposal position will always be selected because <em>u</em> &lt; 1. Therefore, the parts of <em>π</em> less likely to be selected when viewing <em>π</em> as a PDF will be less often sampled.</p>
<p class="indent">Given this behavior, we can imagine that, in time, the random walk based on samples from the normal distribution will wander over <em>π</em> in proportion to <em>π</em>’s value at each position, thereby generating samples in the desired proportions. I haven’t commented on <em>σ</em>, the user-supplied parameter to MH, yet. We’ll experiment with it shortly and understand its effect then.</p>
<p class="indent">As for the definition of <em>A</em>, I’ve written it as the ratio of <em>π</em>(<em>x</em>) evaluated at the current and proposed <em>x</em> positions. This is the Metropolis version of the algorithm, which works with symmetric proposal distributions. If the proposal distribution isn’t symmetric, the numerator and denominator each have an additional multiplicative factor. In the symmetric case, this factor is the same for the numerator and denominator, so it cancels.</p>
<p class="indent"><em>A</em> is a ratio, and Bayes’ theorem writes the posterior as the product of the likelihood and the prior, all divided by a normalizing factor that, in practice, is usually an intractable integral. Since it works with the ratio, MH cancels this integral, so we don’t need to compute it in the first place. MH makes it possible to sample from posterior distributions using only the likelihoods and priors. This makes Bayesians very happy and leads to the dramatic quote earlier in the chapter about Bayes and MCMC.</p>
<p class="indent">Run the algorithm to see that your samples <em>don’t</em> follow <em>π</em>(<em>x</em>). We’ve neglected a key statement about the MH algorithm: it doesn’t claim to immediately generate samples from <em>π</em>(<em>x</em>), but only in the limit, after some period of time. How long a time, and how many samples do we generate before we trust that the samples are coming from <em>π</em>(<em>x</em>)? There is no foolproof answer to that question. Our experiment with fezzes generally converged to the stationary distribution after a dozen or fewer iterations. That might be the case with MH, but it’s generally accepted that complex <em>π</em>(<em>x</em>) functions require many thousands of samples or more before they come from <em>π</em>(<em>x</em>). Therefore, when we implement MH in code, we’ll specify a number of <em>burn-in</em> samples, which we’ll throw away, and keep only those that come after. We did something similar in <a href="ch07.xhtml">Chapter 7</a> when playing the chaos game to generate points on the attractor of an iterated function system.</p>
<p class="indent">This is a random walk algorithm and a Markov algorithm because we randomly draw the next candidate sample, <em>x′</em>, from a distribution with a mean value based on the current sample, <em>x</em>. In a random walk, the next position is relative to the current position. It’s a Markov algorithm because history doesn’t matter; only the current sample position, <em>x</em>, influences any <span epub:type="pagebreak" id="page_355"/>possible new position. Finally, it’s a Monte Carlo algorithm because it depends on randomness and isn’t guaranteed to generate accurate samples from <em>π</em>(<em>x</em>), at least initially.</p>
<p class="indent">Let’s dive into some code and contemplate the <em>mcmc.py</em> file. You’ll find code to parse the command line, sample from a normal distribution, and generate a series of plots using the samples—all of which we’ve seen several times before.</p>
<p class="indent">The heart of <em>mcmc.py</em> is the <code>MH</code> function (<a href="ch012.xhtml#ch012list09">Listing 12-9</a>).</p>
<pre class="pre">def MH(func, nsamples, sigma=1, q=1, burn=1000, limits=None):
    samples = [q]
    while (len(samples) &lt; (burn+nsamples)):
        p = normal(q, sigma)
        if (limits is not None):
            lo,hi = limits
            if (p &lt;= lo) or (p &gt;= hi):
                p = q
        x = p; num = eval(func)
        x = q; den = eval(func)
        if (rng.random() &lt; num/den):
            q = p
        samples.append(q)

    samples = np.array(samples)
    return samples[burn:], samples[:burn]</pre>
<p class="list" id="ch012list09"><em>Listing 12-9: A random walk Metropolis-Hastings sampler</em></p>
<p class="indent">As with rejection sampling, <code>func</code> is a string defining <em>π</em>(<em>x</em>). The rules for its composition are the same as with <em>rejection.py</em>. We ultimately want <code>nsamples</code>’ worth of samples, excluding the first <code>burn</code>’s worth, which we discard. This explains the <code>while</code> loop condition knowing that the list <code>samples</code> holds all the generated samples.</p>
<p class="indent">The body of the <code>while</code> loop is a direct implementation of the MH algorithm, ignoring the explicit definition of <em>A</em> and <em>ρ</em>. First, we sample a proposal position, <code>p</code>, from a normal curve centered on the current sample position, <code>q</code>. Then, if we’ve given <code>MH limits</code>, they restrict the portion of <em>π</em>(<em>x</em>) we sample from in the end. We did the same with rejection sampling.</p>
<p class="indent">We define <code>func</code> with <code>x</code> as the independent variable, so we need to call <code>eval</code> and assign to <code>x</code> to get the numerator (<code>num</code>) and denominator (<code>den</code>). Finally, if <em>u</em> is less than <code>num</code>/<code>den</code>, accept <code>p</code> as the new <code>q</code> before appending <code>q</code> to <code>samples</code>.</p>
<p class="indent">Once we’ve acquired all samples—including those marked as burn-in, for plotting purposes—return <code>samples</code> as a NumPy vector after excluding the burn-in samples.</p>
<p class="indent"><span epub:type="pagebreak" id="page_356"/>Run <em>mcmc.py</em> without arguments to see the command line arguments it expects:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 mcmc.py</span>
mcmc &lt;N&gt; &lt;func&gt; &lt;limits&gt; &lt;q&gt; &lt;sigma&gt; &lt;burn&gt; &lt;outdir&gt; yes|no [&lt;kind&gt; | &lt;kind&gt; &lt;seed&gt;]

  &lt;N&gt;         - number of samples
  &lt;func&gt;      - function to sample from (e.g. 2*x**2+3)
  &lt;limits&gt;    - limits for samples (lo_hi, -18_18) or 'none'
  &lt;q&gt;         - initial sample (e.g. 0)
  &lt;sigma&gt;     - proposal distribution sigma (e.g. 1)
  &lt;burn&gt;      - initial samples to throw away (e.g. N//4)
  &lt;outdir&gt;    - output directory name (overwritten)
  yes|no      - show or don't show the initial proposal distribution
  &lt;kind&gt;      - randomness source
  &lt;seed&gt;      - seed</pre>
<p class="indent">There are a lot of arguments here, but we know what most of them do. We want <code>N</code> samples after ignoring the first <code>burn</code> samples. We know that <code>func</code> is a string defining <em>π</em>(<em>x</em>). If <code>limits</code> isn’t <code>none</code>, it restricts the <em>x</em>-axis range sampled.</p>
<p class="indent">We use <code>q</code> to supply an initial sample position. Finally, the shape of the proposal function, the normal distribution from which <em>x′</em> is drawn, depends on <code>sigma</code>. If <code>sigma</code> is too small, the normal distribution is narrow, and it’s harder to jump to other parts of <em>π</em>(<em>x</em>). On the other hand, if <code>sigma</code> is larger, it’s easier to sample from all of <em>π</em>(<em>x</em>), to a point.</p>
<p class="indent">We understand <code>outdir</code>, <code>kind</code>, and <code>seed</code>. The final argument is the required string, either <code>yes</code> or <code>no</code>. If <code>yes</code>, the output plot showing <em>π</em>(<em>x</em>) and the histogram of samples will also show the normal distribution centered on the initial <code>q</code> with standard deviation <code>sigma</code>. Read through <em>mcmc.py</em> to understand how the output plots are made. Let’s run the code to understand what it produces.</p>
<p class="indent">We begin with this command line:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 mcmc.py 100000 "np.exp(-((x-5)/2)**2)+4*np.exp(-((x+5)/2)**2)" none 0 3 10000 tmp</span>
              <span class="codestrong1">yes pcg64 2256</span>
100000 samples in 6.7056 s</pre>
<p class="noindent">We’re asking for 100,000 samples after 10,000 were thrown away as burn-in. We use the same sum-of-two-normal-curves function for <em>π</em>(<em>x</em>) as with rejection sampling. The <code>none</code> option opens all of the <em>x</em>-axis to sampling, though we’ll end up sampling only where <em>π</em>(<em>x</em>) is nonzero. The initial sample position is 0 and <code>sigma</code> is 3. Finally, we want to see the initial distribution function in the output plot; we’re fixing the pseudorandom generator and seed and dumping all output in <code>tmp</code>.</p>
<p class="indent"><a href="ch012.xhtml#ch012fig14">Figure 12-14</a> shows the plots <em>mcmc.py</em> creates.</p>
<div class="image"><img alt="Image" id="ch012fig14" src="../images/12fig14.jpg"/></div>
<p class="figcap"><span epub:type="pagebreak" id="page_357"/><em>Figure 12-14: Using Metropolis-Hastings to sample from π(</em>x<em>) (top) along with the trace (bottom left) and burn-in plots (bottom right)</em></p>
<p class="indent">The top plot is <em>π</em>(<em>x</em>) along with the histogram of the samples MH produced. Also included, because we said <code>yes</code> on the command line, is the initial proposal distribution, a normal curve centered at <em>x</em> = 0 with <em>σ</em> = 3. Note that the curves are scaled to have 1.0 as their maximum value. As with rejection sampling, we’re looking for the shape of <em>π</em>(<em>x</em>) and the histogram to match.</p>
<p class="indent">The graphs on the bottom of <a href="ch012.xhtml#ch012fig14">Figure 12-14</a> are <em>trace plots</em> that show the sampled <em>x</em> as a function of the sample number. Think of “sample number” as time, so the graphs show how <em>x</em> changes over time. The plot on the left follows samples generated after the burn-in period, while the plot on the right shows the burn-in samples.</p>
<p class="indent">The plots were created by the same command line as the top plot, but the total number of samples was set to 10,000, with 1,000 for burn-in. On the left, most samples are near <em>x</em> = –5, the peak of the larger normal curve from which <em>π</em>(<em>x</em>) is made. The remaining samples center on <em>x</em> = 5, the smaller peak. The burn-in plot on the right, however, jumps around near the respective peaks.</p>
<p class="indent"><span epub:type="pagebreak" id="page_358"/>There are many things to explore with <em>mcmc.py</em>. I’ll offer two suggestions as starting points. I recommend running these command lines, then contemplating the output to see if you fully understand it. Remember to look at the trace plots as well, especially for <em>π</em>(<em>x</em>) = 2<em>x</em><sup>2</sup> + 3:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 mcmc.py 200000 "np.exp(-((x-5)/2)**2)+4*np.exp(-((x+5)/2)**2)"</span>
    <span class="codestrong1">none 3 0.1 100000 tmp yes pcg64 1313</span>
&gt; <span class="codestrong1">python3 mcmc.py 10000 "2*x**2+3" -3_8.8 0 1 1000 tmp yes pcg64 2233</span></pre>
<p class="indent">Earlier, I promised that we’d create a movie showing the random walk inherent in our implementation of MH; I’ll make good on that promise now. Run this command:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 mcmc_movie.py 10000 "np.exp(-((x-5)/2)**2)+4*np.exp(-((x+5)/2)**2)"</span>
    <span class="codestrong1">-18_18 0 3 1000 tmp yes 900 pcg64 66</span>
10000 samples in 181.5245 s</pre>
<p class="indent">The file <em>mcmc_movie.py</em> is very similar to <em>mcmc.py</em>. The output directory, <em>tmp</em>, contains a new directory, <em>frames</em>. This directory contains files running from <em>frame_0000.png</em> to <em>frame_0899.png</em> showing each proposed sample (thin vertical line) along with each accepted sample (thick vertical line) as MH moves through its random walk. Use an image viewer that can page through a directory of files in alphabetical order to view the walk as a movie, or download <em>mcmc_movie.mp4</em> from the book’s GitHub page.</p>
<h3 class="h3" id="ch00lev1_81"><strong>Exercises</strong></h3>
<p class="noindent">Here are some things you may wish to try:</p>
<ul>
<li class="noindent">Update <code>ChooseMap</code> in <em>ifs.py</em> to use <code>Sequential</code> (<a href="ch012.xhtml#ch012list03">Listing 12-3</a>).</li>
<li class="noindent">Use <em>inverse.py</em> with <img alt="Image" class="inline" src="../images/f0358-01.jpg"/> instead of just <em>u</em>. Does anything change about the samples? What does this <em>F</em><sup>–1</sup>(<em>u</em>) look like?</li>
<li class="noindent">The Cauchy distribution is characterized by <em>µ</em> and <em>γ</em>. The PDF is
<div class="image1"><img alt="Image" src="../images/f0358-02.jpg"/></div>
<p class="noindent">with corresponding CDF:</p>
<div class="image1"><img alt="Image" src="../images/f0358-03.jpg"/></div>
<p class="noindent">Try to sample from this function with <em>inverse.py</em>. Set <em>µ</em> = –2 and <em>γ</em> = 1. For example:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 inverse.py 30000 "-2+1*np.tan(np.pi*(u-0.5))"</span>
    <span class="codestrong1">"1/(np.pi*1*(1+((x+2)/1)**2))" cauchy pcg64 42</span></pre>
<p class="noindent"><span epub:type="pagebreak" id="page_359"/>What do you see? Now, replace <em>inverse.py</em> with <em>inverse_cauchy.py</em>. What’s the difference between the two programs? There are times when algorithms need to be tweaked to succeed.</p></li>
<li class="noindent">Execute the shell script <em>run_rejection_c</em> and explain the output in terms of the rejection test for cases when <em>cp</em>(<em>x</em>) ≫ <em>q</em>(<em>x</em>) versus just barely exceeding <em>q</em>(<em>x</em>). Hint: consider the likelihood of picking a <em>y</em> value for a given <em>x</em> when <em>q</em>(<em>x</em>) <em>≈ cp</em>(<em>x</em>).</li>
<li class="noindent">Experiment with <em>mcmc.py</em> using functions that are always positive over some given range. What happens as you make the burn-in larger or smaller? Try changing <em>σ</em>. Do large or small <em>σ</em> values work better? Here’s a function to try:
<p class="center"><em>p<sub>X</sub></em>(<em>x</em>) = sin<sup>3</sup>(<em>x</em>) + 1</p>
<p class="noindent">I suggest a command line like this one:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 mcmc.py 100000 "np.sin(x)**3+1" -9.4248_9.4248 0 3 100000 tmp no pcg64 2256</span></pre>
<p class="noindent">Can you explain the plot and histogram? The limits are, roughly, –3<em>π</em> to 3<em>π</em>.</p></li>
</ul>
<h3 class="h3" id="ch00lev1_82"><strong>Summary</strong></h3>
<p class="noindent">In this chapter, we sampled from arbitrary distributions. First, we introduced terminology and concepts from Bayesian inference, a primary user of sampling techniques. After that, we sampled from discrete distributions, which often appear when working with histograms. We learned about sequential sampling and the FLDR, both of which run in <img alt="Image" class="inline" src="../images/c0301-01.jpg"/>(<em>n</em>) time—though, practically, the dice roller is some five to seven times faster.</p>
<p class="indent">We then experimented with sampling from a two-dimensional discrete distribution by unraveling the two-dimensional distribution to manipulate it as a one-dimensional distribution. As grayscale images are, in effect, two-dimensional discrete distributions, we sampled from them and observed that more intense pixels were sampled most often.</p>
<p class="indent">Continuous distributions, characterized by PDFs, came next. In certain cases, sampling becomes a simple process if the cumulative distribution function is invertible. When such is not the case, we explored two approaches: rejection sampling and MCMC with the MH algorithm.</p>
<p class="indent">Rejection sampling works well in one dimension, but suffers as the dimensionality of the samples increases. We explored how the algorithm behaves for two proposal distributions, the uniform and the normal, to realize that the closer the proposal function is to the actual PDF, the fewer samples are rejected and the more efficient the algorithm becomes.</p>
<p class="indent">When the distribution we want to sample becomes complex or is of high dimensionality, rejection sampling is best replaced by MCMC. We learned about MH in one dimension using a symmetric normal distribution as the proposal distribution. Animated plots showed the progress of the sampling algorithm over time.<span epub:type="pagebreak" id="page_360"/></p>
</body></html>