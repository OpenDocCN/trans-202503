- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Confusing the Computer
  prefs: []
  type: TYPE_NORMAL
- en: '![Alphabet-U](Images/Alphabet-U.png)ntil now, we’ve been focused on the great
    things that we can do using ML, and on the ways that it is being used well in
    real-world applications. But, as you’ve seen throughout this book, ML systems
    are not perfect or all-knowing. Their behavior is determined by the training that
    we give them. The way that we train our ML systems will affect the responses that
    they give, and not always in a positive way. In this chapter, we’ll look at one
    of the most common challenges in creating AI systems: *bias****.***'
  prefs: []
  type: TYPE_NORMAL
- en: '***The project in this chapter is based on an old story, sometimes described
    as the *Russian Tank problem**, that is often told to AI students. It’s probably
    not true, but it illustrates the impact of bias in ML training sets.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Here’s one example of how the story is told:'
  prefs: []
  type: TYPE_NORMAL
- en: Once upon a time, the US Army decided to use ML to recognize tanks hiding behind
    trees in the woods. Researchers trained an ML model using photos of woods without
    tanks, and photos of the same woods with tanks hiding behind trees.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The model seemed to do well with the researchers’ pictures, but when the US
    Army tested their system, it didn’t do any better than random guesses.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It turned out that in the researchers’ training data, the photos of camouflaged
    tanks had been taken on a cloudy day, while photos of the plain forest had been
    taken on a sunny day. The ML model had learned to recognize cloudy days from sunny
    days, instead of recognizing camouflaged tanks.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here’s another version:'
  prefs: []
  type: TYPE_NORMAL
- en: Once upon a time, the US Army tried training a computer to recognize the difference
    between Russian and American tanks. Researchers trained an ML model using photos
    they took of American tanks and spy photos they collected of Russian tanks.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The model seemed to do well with the researchers’ pictures, but when the US
    Army tested their system, the ML model didn’t do any better than random guesses.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It turned out that the researchers’ photos of American tanks were large, high
    resolution, and high quality. But the long-distance spy photos they were able
    to get of Russian tanks were all blurry, low resolution, and grainy.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The ML model had learned to recognize the difference between grainy photos and
    high-quality photos, instead of between Russian and American tanks.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As another example, when researchers at Stanford University were developing
    an ML system to recognize skin cancers from photos, they accidentally created
    an ML model that recognized rulers, because medical photographs of skin cancers
    normally include a ruler to show the size of the lesion or tumor.
  prefs: []
  type: TYPE_NORMAL
- en: The point is that, due to unintentional bias, ML systems can learn to spot patterns
    that their creators might not have been aware of or that weren’t intended to be
    treated as patterns.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you’ll train an image classifier to recognize pictures of objects,
    but you’ll introduce bias to make it get things wrong. We’ll see firsthand what
    sorts of problems can cause an ML model to make mistakes, and then we’ll talk
    about how we can avoid these problems and fix the model.
  prefs: []
  type: TYPE_NORMAL
- en: Build Your Project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Choose two objects that you want to train the computer to recognize photographs
    of. Pick things that are obviously different. Don’t choose anything too personal,
    as you’ll need to upload the photos to the internet to do the project.
  prefs: []
  type: TYPE_NORMAL
- en: For my screenshots, I chose a lemon and a grapefruit that I found in my kitchen.
    You can choose anything you like, though.
  prefs: []
  type: TYPE_NORMAL
- en: Put the first object down somewhere and take 10 similar-looking photographs
    of it. You don’t need the photos to be high resolution. Small photos (under 800
    pixels in width) will work best.
  prefs: []
  type: TYPE_NORMAL
- en: I put my grapefruit down on a wooden floor in a dark room, and took the photos
    shown in [Figure 14-1](#figure14-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![f14001](Images/f14001.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-1:](#figureanchor14-1) Photos of my first object, a grapefruit'
  prefs: []
  type: TYPE_NORMAL
- en: Put the second object down somewhere different and take 10 photographs of it.
  prefs: []
  type: TYPE_NORMAL
- en: I put my lemon down on a cream-colored carpet in a bright, light room and took
    the photos shown in [Figure 14-2](#figure14-2).
  prefs: []
  type: TYPE_NORMAL
- en: '![f14002](Images/f14002.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-2:](#figureanchor14-2) Photos of my second object, a lemon'
  prefs: []
  type: TYPE_NORMAL
- en: Don’t make the object too large in the photos. Try to keep the object in the
    same position in each photo, as shown in Figures [14-1](#figure14-1) and [14-2](#figure14-2).
  prefs: []
  type: TYPE_NORMAL
- en: The aim is to make all 10 photographs very similar *within each set*, but to
    make everything—the object, the background, the lighting—different *between the
    two sets*. For example, if your photos of the first object are on a dark background,
    take your photos of the second object on a light background. But allthe photos
    of the first object should be on the dark background, and all of the photos of
    the second object should be on the light background.
  prefs: []
  type: TYPE_NORMAL
- en: Here are some other ideas for how you could make your two sets of photographs
    different.
  prefs: []
  type: TYPE_NORMAL
- en: '| **If your photos of the first object are all…** | **Take all the photos of
    the second object…** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| on a *dark* background | on a *light* background |'
  prefs: []
  type: TYPE_TB
- en: '| on *tiles* | on *grass* |'
  prefs: []
  type: TYPE_TB
- en: '| *brightly lit* | *somewhere dark* |'
  prefs: []
  type: TYPE_TB
- en: '| *clear*, *crisp*, and *focused* | *fuzzy* and *blurry* |'
  prefs: []
  type: TYPE_TB
- en: '| *outdoors* with a garden in the background | *indoors* with the same room
    in the background |'
  prefs: []
  type: TYPE_TB
- en: Have another look at my photos. The photos in [Figure 14-1](#figure14-1) have
    in common dark lighting, the dark brown surface, and the wooden pattern background.
    The photos in [Figure 14-2](#figure14-2) have in common bright lighting, the cream
    surface, and the speckled carpet background.
  prefs: []
  type: TYPE_NORMAL
- en: You don’t have to copy my photos exactly. Be creative!
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve taken your 20 photos, you need to put them online somewhere to make
    them available for training. Choose any photo hosting web service that will let
    you upload photos to the internet for no charge. (If you already have an account
    with a photo sharing service, you might want to create a new one for this project,
    as your 20 similar photos of a couple of random household objects are probably
    not very interesting to share!)
  prefs: []
  type: TYPE_NORMAL
- en: The most important thing is to upload your photos somewhere they can be accessed
    without a login so that your ML system can access them and learn from them.
  prefs: []
  type: TYPE_NORMAL
- en: Train Your Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Go to *[https://machinelearningforkids.co.uk/](https://machinelearningforkids.co.uk/)*.
    Create a new ML project, name it `Confuse the computer`, and set it to learn to
    recognize images.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Train**, as shown in [Figure 14-3](#figure14-3).![f14003](Images/f14003.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 14-3:](#figureanchor14-3) Click **Train** to prepare your training
    buckets.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Add new label** and create two training buckets, as shown in [Figure
    14-4](#figure14-4). Name them after the two objects that you have chosen. (The
    name you choose won’t have any effect on the training, but it’s useful for you.)
    I named mine grapefruit and lemon.![f14004](Images/f14004.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 14-4:](#figureanchor14-4) Prepare two training buckets for your objects.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Add the training images to your training buckets. To do so, arrange two browser
    windows side by side, as shown in [Figure 14-5](#figure14-5). One should have
    your training buckets, and the other should have the photo sharing website with
    your photographs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag the images from the photo sharing site and drop them into the appropriate
    training bucket.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f14005](Images/f14005.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 14-5:](#figureanchor14-5) Arrange two browser windows side by side
    and drag the photos into your training buckets.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat step 4 until you’ve got all 20 photos in your training buckets, as shown
    in [Figure 14-6](#figure14-6).![f14006](Images/f14006.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 14-6:](#figureanchor14-6) Drag all of your photos into the training
    buckets.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Back to project** in the top-left corner of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Learn & Test**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Train new machine learning model**, as shown in [Figure 14-7](#figure14-7).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![f14007](Images/f14007.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-7:](#figureanchor14-7) Start training an ML model.'
  prefs: []
  type: TYPE_NORMAL
- en: It will take a few minutes for your ML model to train. While you’re waiting,
    continue to the next step to prepare your project.
  prefs: []
  type: TYPE_NORMAL
- en: Prepare Your Project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Take another photograph of each of your two objects, *but this time, switch
    the backgrounds**.*
  prefs: []
  type: TYPE_NORMAL
- en: '*In other words, take a photo of the first object where you took the photos
    of the second object before. Take a photo of the second object where you took
    the photos of the first object before.'
  prefs: []
  type: TYPE_NORMAL
- en: For me, that meant taking a photo of the lemon on a dark wooden floor, and a
    photo of the grapefruit on a brightly lit cream carpet. Compare the test photos
    I took in [Figure 14-8](#figure14-8) with the training photos in Figures [14-1](#figure14-1)
    and [14-2](#figure14-2).
  prefs: []
  type: TYPE_NORMAL
- en: '![f14008](Images/f14008.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-8:](#figureanchor14-8) Swap the backgrounds for your test photos.'
  prefs: []
  type: TYPE_NORMAL
- en: You don’t need to upload these photos anywhere. You just need access to them
    on your computer to be able to use them for testing.
  prefs: []
  type: TYPE_NORMAL
- en: Click **Back to project** and then click **Make**, as shown in [Figure 14-9](#figure14-9).![f14009](Images/f14009.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 14-9:](#figureanchor14-9) Time to make your test!'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Scratch 3**, as shown in [Figure 14-10](#figure14-10).![f14010](Images/f14010.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 14-10:](#figureanchor14-10) Click **Scratch 3** to test your model.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Open in Scratch 3**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Move your mouse pointer over the Choose a Sprite icon (the cat face) in the
    bottom-right corner. Click **Upload Sprite** as shown in [Figure 14-11](#figure14-11).
    Upload one of your two new test photos.![f14011](Images/f14011.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 14-11:](#figureanchor14-11) Upload a new sprite.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Copy the script shown in [Figure 14-12](#figure14-12). This script tries to
    recognize the sprite costume image and displays what your ML model recognizes
    the photo as.![f14012](Images/f14012.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 14-12:](#figureanchor14-12) Write a short test script.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Upload Sprite** again to upload your second test photograph. Create
    the same script as before for your second sprite, as shown in [Figure 14-13](#figure14-13).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![f14013](Images/f14013.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-13:](#figureanchor14-13) Upload a second sprite and add another
    test script.'
  prefs: []
  type: TYPE_NORMAL
- en: Test Your Project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s time to run your test! Your scripts should classify both of your new test
    photos and display what your ML model recognized them as. Click the Green Flag
    to test your ML model.
  prefs: []
  type: TYPE_NORMAL
- en: My results are shown in [Figure 14-14](#figure14-14).
  prefs: []
  type: TYPE_NORMAL
- en: As you may have expected, your ML model probably gave the wrong answer.
  prefs: []
  type: TYPE_NORMAL
- en: '![f14014](Images/f14014.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-14:](#figureanchor14-14) Test results for my ML model'
  prefs: []
  type: TYPE_NORMAL
- en: I trained an ML model with state-of-the-art advanced technology, but it couldn’t
    tell the difference between a lemon and a grapefruit—something that a person can
    do easily.
  prefs: []
  type: TYPE_NORMAL
- en: Why do you think it went so wrong?
  prefs: []
  type: TYPE_NORMAL
- en: Review and Fix Your Project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are several reasons why my ML model gave the wrong answer.
  prefs: []
  type: TYPE_NORMAL
- en: Think about the area taken up in the photos. The object made up about 5 percent
    of the overall area of my photos. About 95 percent of each photo was the background,
    as shown in [Figure 14-15](#figure14-15).
  prefs: []
  type: TYPE_NORMAL
- en: '![f14015](Images/f14015.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-15:](#figureanchor14-15) Most of my photos were background.'
  prefs: []
  type: TYPE_NORMAL
- en: When you collect training examples to create an ML model, you’re asking the
    computer to identify what those examples have in common so that it can recognize
    when it’s given something with similar characteristics in the future.
  prefs: []
  type: TYPE_NORMAL
- en: When I tested my model with the photo of a lemon, 95 percent of the photo was
    very, very similar to 95 percent of all of the training photos of grapefruits
    in [Figure 14-1](#figure14-1). There was nothing in the way that we trained the
    ML model to make it clear that the part we were interested in was just that 5
    percent of the photo in the middle, not the rest.
  prefs: []
  type: TYPE_NORMAL
- en: When you look at the training photos and the test photos side by side, you can
    see why the model made the choice it did.
  prefs: []
  type: TYPE_NORMAL
- en: '![f14016](Images/f14016.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-16:](#figureanchor14-16) Compare the test and training photos to
    understand why the ML model was wrong.'
  prefs: []
  type: TYPE_NORMAL
- en: Taking the photos as a whole, the largest part of my test photo (on the right
    of [Figure 14-16](#figure14-16)) is very similar to the largest part of every
    training photo I had labeled as “grapefruit.”
  prefs: []
  type: TYPE_NORMAL
- en: ML systems are designed to identify and recognize patterns in the examples you
    give them—but *these won’t necessarily be the patterns that you intended or that
    you would’ve recognized*.
  prefs: []
  type: TYPE_NORMAL
- en: Can you think of a way to fix your project?
  prefs: []
  type: TYPE_NORMAL
- en: There are several things you could do. For example, if your object made up a
    much more significant proportion of the overall image, as shown in [Figure 14-17](#figure14-17),
    that might help.
  prefs: []
  type: TYPE_NORMAL
- en: '![f14017](Images/f14017.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-17:](#figureanchor14-17) Try making your object larger in the photos.'
  prefs: []
  type: TYPE_NORMAL
- en: But this solution would be useful only for projects where you could be sure
    that all test images would show a similarly large object.
  prefs: []
  type: TYPE_NORMAL
- en: For this project, the best way to be sure of that is to take lots of photos
    of your two objects with different places, backgrounds, lighting, sizes, angles,
    and orientations. Change everything that you can think of between the training
    examples, so that the only thing they have in common is the object itself.
  prefs: []
  type: TYPE_NORMAL
- en: For example, [Figure 14-18](#figure14-18) shows a much better set of training
    images for my grapefruit.
  prefs: []
  type: TYPE_NORMAL
- en: '![f14018](Images/f14018.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 14-18:](#figureanchor14-18) A better way to train the ML model'
  prefs: []
  type: TYPE_NORMAL
- en: Varying the training images’ backgrounds, lighting, and level of focus is a
    good start toward training the ML model to identify only the grapefruit itself
    as the common factor among the images.
  prefs: []
  type: TYPE_NORMAL
- en: We could make the training even better still. For example, these training images
    all have the grapefruit in the same position and at the same size. That’s fine
    if I can guarantee that objects in my test photos will be at the same size and
    position when I test the model. But for a truly flexible model, I could also add
    photos where the grapefruit is at different sizes and positions.
  prefs: []
  type: TYPE_NORMAL
- en: Try improving your training examples for your two objects and training a new
    ML model.
  prefs: []
  type: TYPE_NORMAL
- en: If you vary the training examples, does the model pass your test?
  prefs: []
  type: TYPE_NORMAL
- en: What You Learned
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you’ve learned how important it is to have variation in your
    training sets. Whether it’s a military project that accidentally recognizes the
    weather instead of camouflaged tanks, a university research project inventing
    a ruler detector instead of a skin cancer classifier, or simply a system that
    can’t tell a grapefruit from a lemon, you’ve seen the impact of having *unintentional
    bias* **in the datasets used to train an ML model.**
  prefs: []
  type: TYPE_NORMAL
- en: '**In the next chapter, you’ll see the risks of introducing *intentional bias*
    in ML projects.*******'
  prefs: []
  type: TYPE_NORMAL
