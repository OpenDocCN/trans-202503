- en: '**8'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TEMPLATE INJECTION**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A *template engine* is code that creates dynamic websites, emails, and other
    media by automatically filling in placeholders in the template when rendering
    it. By using placeholders, the template engine allows developers to separate application
    and business logic. For example, a website might use just one template for user
    profile pages with dynamic placeholders for profile fields, such as the user’s
    name, email address, and age. Template engines also usually provide additional
    benefits, such as user input sanitization features, simplified HTML generation,
    and easy maintenance. But these features don’t make template engines immune to
    vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '*Template injection* vulnerabilities occur when engines render user input without
    properly sanitizing it, sometimes leading to remote code execution. We’ll cover
    remote code execution in more detail in [Chapter 12](ch12.xhtml#ch12).'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two types of template injection vulnerabilities: server side and
    client side.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Server-Side Template Injections**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Server-side template injection (SSTI)* vulnerabilities occur when the injection
    happens in the server-side logic. Because template engines are associated with
    specific programming languages, when an injection occurs, you may sometimes be
    able to execute arbitrary code from that language. Whether or not you can do this
    depends on the security protections the engine provides, as well as the site’s
    preventative measures. The Python Jinja2 engine has allowed arbitrary file access
    and remote code execution, as has the Ruby ERB template engine that Rails uses
    by default. In contrast, Shopify’s Liquid Engine allows access to a limited number
    of Ruby methods in an attempt to prevent full remote code execution. Other popular
    engines include PHP’s Smarty and Twig, Ruby’s Haml, Mustache, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: To test for SSTI vulnerabilities, you submit template expressions using the
    specific syntax for the engine in use. For example, PHP’s Smarty template engine
    uses four braces `{{ }}` to denote expressions, whereas ERB uses a combination
    of angle brackets, percent symbols, and an equal sign `<%= %>`. Typical testing
    for injections on Smarty involves submitting `{{7*7}}` and looking for areas where
    inputs are reflected back on the page (such as in forms, URL parameters, and so
    on). In this case, you’d look for `49` rendered from the code `7*7` executing
    in the expression. If you find `49`, you’ll know that you successfully injected
    your expression and the template evaluated it.
  prefs: []
  type: TYPE_NORMAL
- en: Because the syntax isn’t uniform across all template engines, you must know
    the software used to build the site you’re testing. Tools like Wappalyzer and
    BuiltWith are specifically designed for this purpose. After identifying the software,
    use that template engine’s syntax to submit a simple payload, such as `7*7`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Client-Side Template Injections**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Client-side template injection (CSTI)* vulnerabilities occur in client template
    engines and are written in JavaScript. Popular client template engines include
    Google’s AngularJS and Facebook’s ReactJS.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because CSTIs occur in the user’s browser, you typically can’t use them to
    achieve remote code execution, but you can use them for XSS. However, achieving
    XSS can sometimes be difficult and requires bypassing preventative measures, just
    as with SSTI vulnerabilities. For example, ReactJS does a great job of preventing
    XSS by default. When testing applications using ReactJS, you should search the
    JavaScript files for the function `dangerouslySetInnerHTML`, where you can control
    input provided to the function. This intentionally bypasses ReactJS’s XSS protections.
    With regard to AngularJS, versions earlier than 1.6 include a Sandbox that limits
    access to some JavaScript functions and protects against XSS (to confirm the AngularJS
    version, enter `Angular.version` in the developer console in your browser). But
    ethical hackers routinely found and released AngularJS Sandbox bypasses before
    the version 1.6 release. The following is a popular bypass for Sandbox versions
    1.3.0 to 1.5.7 that you can submit when you find an AngularJS injection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You’ll find other published AngularJS Sandbox escapes at *[https://pastebin.com/xMXwsm0N](https://pastebin.com/xMXwsm0N)*
    and *[https://jsfiddle.net/89aj1n7m/](https://jsfiddle.net/89aj1n7m/)*.
  prefs: []
  type: TYPE_NORMAL
- en: Demonstrating the severity of a CSTI vulnerability requires you to test the
    code you can potentially execute. Although you might be able to evaluate some
    JavaScript code, some sites might have additional security mechanisms to prevent
    exploitation. For example, I found a CSTI vulnerability by using the payload `{{4+4}}`,
    which returned `8` on a site using AngularJS. But when I used `{{4*4}}`, the text
    `{{44}}` was returned because the site sanitized the input by removing the asterisk.
    The field also removed special characters, such as `()` and `[]`, and it allowed
    a maximum of 30 characters. Combined, these preventative measures effectively
    rendered the CSTI useless.
  prefs: []
  type: TYPE_NORMAL
- en: '**Uber AngularJS Template Injection**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Difficulty:** High'
  prefs: []
  type: TYPE_NORMAL
- en: '**URL:** *[https://developer.uber.com/](https://developer.uber.com/)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Source:** *[https://hackerone.com/reports/125027/](https://hackerone.com/reports/125027/)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Date reported:** March 22, 2016'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bounty paid:** $3,000'
  prefs: []
  type: TYPE_NORMAL
- en: In March 2016, James Kettle, the lead security researcher at PortSwigger (creator
    of Burp Suite) found a CSTI vulnerability in an Uber subdomain via the URL *https://developer.uber.com/docs/deep-linking?q=wrtz{{7*7}}*.
    If you viewed the rendered page source after visiting the link, you’d find the
    string `wrtz49`, showing that the template had evaluated the expression `7*7`.
  prefs: []
  type: TYPE_NORMAL
- en: As it turned out, *[developer.uber.com](http://developer.uber.com)* used AngularJS
    to render its web pages. You could confirm this by using a tool such as Wappalyzer
    or BuiltWith or by viewing the page source and looking for `ng-` HTML attributes.
    As mentioned, older versions of AngularJS implemented a Sandbox, but the version
    Uber was using was vulnerable to a Sandbox escape. So in this case, a CSTI vulnerability
    meant you could execute XSS.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the following JavaScript within the Uber URL, Kettle escaped the AngularJS
    Sandbox and executed the `alert` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Deconstructing this payload is beyond the scope of this book, given the publication
    of numerous AngularJS Sandbox bypasses and the removal of the Sandbox in version
    1.6\. But the end result of the payload `alert(1)` is a JavaScript popup. This
    proof of concept demonstrated to Uber that attackers could exploit this CSTI to
    achieve XSS, resulting in potentially compromised developer accounts and associated
    apps.
  prefs: []
  type: TYPE_NORMAL
- en: '***Takeaways***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: After you confirm whether a site is using a client-side template engine, begin
    testing the site by submitting simple payloads using the same syntax as the engine,
    such as `{{7*7}}` for AngularJS, and watching for the rendered result. If the
    payload is executed, check which version of AngularJS the site is using by typing
    *Angular.version* in the browser console. If the version is greater than 1.6,
    you can submit a payload from the aforementioned resources without a Sandbox bypass.
    If it’s less than 1.6, you’ll need to submit a Sandbox bypass like Kettle’s, specific
    to the AngularJS version the application is using.
  prefs: []
  type: TYPE_NORMAL
- en: '**Uber Flask Jinja2 Template Injection**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Difficulty:** Medium'
  prefs: []
  type: TYPE_NORMAL
- en: '**URL:** *[https://riders.uber.com/](https://riders.uber.com/)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Source:** *[https://hackerone.com/reports/125980/](https://hackerone.com/reports/125980/)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Date reported:** March 25, 2016'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bounty paid:** $10,000'
  prefs: []
  type: TYPE_NORMAL
- en: When you’re hacking, it’s important to identify the technologies a company uses.
    When Uber launched its public bug bounty program on HackerOne, it also included
    a “treasure map” on its site at *[https://eng.uber.com/bug-bounty/](https://eng.uber.com/bug-bounty/)*
    (a revised map was published in August 2017 at *[https://medium.com/uber-security-privacy/uber-bug-bounty-treasure-map-17192af85c1a/](https://medium.com/uber-security-privacy/uber-bug-bounty-treasure-map-17192af85c1a/)*).
    The map identified a number of sensitive properties Uber operated, including the
    software each one used.
  prefs: []
  type: TYPE_NORMAL
- en: In its map, Uber disclosed that *[riders.uber.com](http://riders.uber.com)*
    was built with Node.js, Express, and Backbone.js, none of which immediately jumps
    out as a potential SSTI attack vector. But the sites *[vault.uber.com](http://vault.uber.com)*
    and *[partners.uber.com](http://partners.uber.com)* were developed using Flask
    and Jinja2\. Jinja2 is a server-side template engine that can allow remote code
    execution if implemented incorrectly. Although *[riders.uber.com](http://riders.uber.com)*
    didn’t use Jinja2, if the site supplied input to either the *vault* or *partners*
    subdomains and those sites trusted the input without sanitizing it, an attacker
    might be able to exploit an SSTI vulnerability.
  prefs: []
  type: TYPE_NORMAL
- en: Orange Tsai, the hacker who found this vulnerability, entered `{{1+1}}` as his
    name to begin testing for SSTI vulnerabilities. He searched for whether any interaction
    took place between the subdomains.
  prefs: []
  type: TYPE_NORMAL
- en: In his write-up, Orange explained that any change to a profile on *[riders.uber.com](http://riders.uber.com)*
    would result in an email to the account owner notifying them of the change—a common
    security approach. By changing his name on the site to include `{{1+1}}`, he received
    an email with a `2` in his name, as shown in [Figure 8-1](ch08.xhtml#ch08fig01).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/08fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-1: The email Orange received executing the code he had injected into
    his name*'
  prefs: []
  type: TYPE_NORMAL
- en: This behavior immediately raised a red flag because Uber evaluated his expression
    and replaced it with the result of the equation. Orange then tried to submit the
    Python code `{% for c in [1,2,3]%} {{c,c,c}} {% endfor %}` to confirm that a more
    complex operation could be evaluated. This code iterates over the array `[1,2,3]`
    and prints each number three times. The email in [Figure 8-2](ch08.xhtml#ch08fig02)
    shows Orange’s name displayed as nine numbers that resulted from the `for` loop
    executing, which confirmed his finding.
  prefs: []
  type: TYPE_NORMAL
- en: Jinja2 also implements a Sandbox, which limits the ability to execute arbitrary
    code but can occasionally be bypassed. In this case, Orange would have been able
    to do just that.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/08fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-2: The email that resulted from Orange’s injection of more complex
    code*'
  prefs: []
  type: TYPE_NORMAL
- en: Orange only reported the ability to execute code in his write-up, but he could
    have taken the vulnerability even further. In his write-up, he credited nVisium’s
    blog posts with providing the information necessary to find the bug. But these
    posts also contain additional information about the scope of Jinja2 vulnerabilities
    when combined with other concepts. Let’s take a slight detour to see how this
    added information applies to Orange’s vulnerability by looking at nVisium’s blog
    post at *[https://nvisium.com/blog/2016/03/09/exploring-ssti-in-flask-jinja2.html](https://nvisium.com/blog/2016/03/09/exploring-ssti-in-flask-jinja2.html)*.
  prefs: []
  type: TYPE_NORMAL
- en: In the blog post, nVisium walks through exploiting Jinja2 by using *introspection*,
    an object-oriented programming concept. Introspection involves inspecting the
    properties of an object at runtime to see what data is available to it. The details
    of how object-oriented introspection works are beyond the scope of this book.
    In the context of this bug, introspection allowed Orange to execute code and identify
    what properties were available to the template object when the injection occurred.
    Once an attacker knows that information, they could find potentially exploitable
    properties they could use to achieve remote code execution; I’ll cover this vulnerability
    type in [Chapter 12](ch12.xhtml#ch12).
  prefs: []
  type: TYPE_NORMAL
- en: When Orange found this vulnerability, he simply reported the ability to execute
    the code necessary to perform the introspection rather than attempting to take
    the vulnerability further. It’s best to take Orange’s approach because it ensures
    you don’t perform any unintended actions; also, companies can assess the potential
    impact of the vulnerability. If you’re interested in exploring the full severity
    of an issue, ask the company in your report whether you can continue testing.
  prefs: []
  type: TYPE_NORMAL
- en: '***Takeaways***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Note the technologies a site uses; often, these lead to insights into how you
    can exploit the site. Be sure to also consider how the technologies interact with
    each other. In this case, Flask and Jinja2 were great attack vectors, although
    they weren’t directly used on the vulnerable site. As with XSS vulnerabilities,
    check all possible places your input might be used, because a vulnerability might
    not be immediately apparent. In this case, the malicious payload was rendered
    as plaintext on the user’s profile page, and the code was executed when emails
    were sent.
  prefs: []
  type: TYPE_NORMAL
- en: '**Rails Dynamic Render**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Difficulty:** Medium'
  prefs: []
  type: TYPE_NORMAL
- en: '**URL:** N/A'
  prefs: []
  type: TYPE_NORMAL
- en: '**Source:** *https://nvisium.com/blog/2016/01/26/rails-dynamic-render-to-rce-cve-2016-0752/*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Date reported:** February 1, 2015'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bounty paid:** N/A'
  prefs: []
  type: TYPE_NORMAL
- en: In early 2016, the Ruby on Rails team disclosed a potential remote code execution
    vulnerability in the way they handled rendering templates. A member of the nVisium
    team identified the vulnerability and provided a valuable write-up of the issue,
    assigned CVE-2016-0752\. Ruby on Rails uses a *model, view, controller architecture
    (MVC)* design. In this design, the database logic (the model) is separated from
    the presentation logic (the view) and the application logic (the controller).
    MVC is a common design pattern in programming that improves code maintainability.
  prefs: []
  type: TYPE_NORMAL
- en: In its write-up, the nVisium team explains how Rails controllers, which are
    responsible for the application logic, can infer what template file to render
    based on user-controlled parameters. Depending on how the site was developed,
    these user-controlled parameters might be passed directly to the `render` method
    responsible for passing data to the presentation logic. The vulnerability could
    occur from a developer passing the input to the `render` function, such as by
    calling the `render` method and `params[:template]` where the `params[:template]`
    value is the dashboard. In Rails, all parameters from an HTTP request are available
    to the application controller logic via the `params` array. In this case, a parameter
    `template` is submitted in the HTTP request and passed to the `render` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'This behavior is noteworthy because the `render` method provides no specific
    context to Rails; in other words, it doesn’t provide a path or link to a specific
    file and just automagically determines which file should return content to the
    user. It’s able to do this because Rails strongly implements convention over configuration:
    whatever template parameter value is passed to the `render` function is used to
    scan for filenames to render content with. According to the discovery, Rails would
    first recursively search the application root directory */app/views*. This is
    the common default folder for all files used to render content for users. If Rails
    couldn’t find a file using its given name, it scanned the application root directory.
    If it still couldn’t find the file, Rails scanned the server root directory.'
  prefs: []
  type: TYPE_NORMAL
- en: Before CVE-2016-0752, a malicious user could pass `template=%2fetc%2fpasswd`
    and Rails would look for the file */etc/passwd* in the views directory, then the
    application directory, and finally the server root directory. Assuming you were
    using a Linux machine and the file was readable, Rails would print your */etc/passwd*
    file.
  prefs: []
  type: TYPE_NORMAL
- en: According to nVisium’s article, the search sequence Rails uses can also be used
    for arbitrary code execution when a user submits a template injection, such as
    ``<%25%3d`ls`%25>``. If the site uses the default Rails template language ERB,
    this encoded input is interpreted as ``<%= `ls` %>``, or the Linux command to
    list all files in the current directory. While the Rails team has fixed this vulnerability,
    you can still test for SSTI in case a developer passes user-controlled input to
    `render inline:` because `inline:` is used to supply ERB directly to the `render`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: '***Takeaways***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Understanding how the software you’re testing works will help you uncover vulnerabilities.
    In this case, any Rails site was vulnerable if it was passing user-controlled
    input to the `render` function. Understanding the design patterns Rails uses undoubtedly
    helped to uncover this vulnerability. As with the template parameter in this example,
    be on the lookout for opportunities that arise when you control input that might
    be directly related to how content is being rendered.
  prefs: []
  type: TYPE_NORMAL
- en: '**Unikrn Smarty Template Injection**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Difficulty:** Medium'
  prefs: []
  type: TYPE_NORMAL
- en: '**URL:** N/A'
  prefs: []
  type: TYPE_NORMAL
- en: '**Source:** *[https://hackerone.com/reports/164224/](https://hackerone.com/reports/164224/)*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Date reported:** August 29, 2016'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bounty paid:** $400'
  prefs: []
  type: TYPE_NORMAL
- en: On August 29, 2016, I was invited to the then-private bug bounty program for
    Unikrn, an eSports betting site. During my initial site reconnaissance, the Wappalyzer
    tool I was using confirmed that the site was using AngularJS. This discovery raised
    a red flag for me because I’d been successful at finding AngularJS injection vulnerabilities.
    I began looking for CSTI vulnerabilities by submitting `{{7*7}}` and looking for
    the number `49` rendered, beginning with my profile. Although I wasn’t successful
    on the profile page, I noticed you could invite friends to the site, so I also
    tested that functionality.
  prefs: []
  type: TYPE_NORMAL
- en: After submitting an invitation to myself, I received the odd email shown in
    [Figure 8-3](ch08.xhtml#ch08fig03).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/08fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-3: The email I received from Unikrn with a Smarty error*'
  prefs: []
  type: TYPE_NORMAL
- en: The beginning of the email included a stack trace with a Smarty error that showed
    `7*7` was not recognized. It looked as though `{{7*7}}` was being injected into
    the template, and Smarty was trying to evaluate the code but didn’t recognize
    `7*7`.
  prefs: []
  type: TYPE_NORMAL
- en: I immediately consulted James Kettle’s indispensable article on template injection
    (*[http://blog.portswigger.net/2015/08/server-side-template-injection.html](http://blog.portswigger.net/2015/08/server-side-template-injection.html)*)
    to test the Smarty payload he referenced (he also provides a great Black Hat presentation
    available on YouTube). Kettle specifically referenced the payload `{self::getStreamVariable("file:///proc/self/loginuuid")}`,
    which calls the method `getStreamVariable` to read the file */proc/self/loginuuid*.
    I tried the payload he shared but received no output.
  prefs: []
  type: TYPE_NORMAL
- en: Now I was skeptical of my finding. But then I searched the Smarty documentation
    for its reserved variables, which included the `{$smarty.version}` variable that
    returns the version of Smarty being used. I changed my profile name to `{$smarty.version}`
    and reinvited myself to the site. The result was an invitation email that used
    2.6.18 as my name, which was the Smarty version installed on the site. My injection
    was being executed, and my confidence was restored.
  prefs: []
  type: TYPE_NORMAL
- en: When I continued to read the documentation, I learned that you can use the tags
    `{php} {/php}` to execute arbitrary PHP code (Kettle specifically mentions these
    tags in his article, but I had completely missed them). So, I tried the payload
    `{php}print "Hello"{/php}` as my name and submitted the invite again. The resulting
    email stated that Hello had invited me to the site, confirming that I had executed
    PHP’s `print` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final test, I wanted to extract the */etc/passwd* file to demonstrate
    the potential of this vulnerability to the bounty program. Although the */etc/passwd*
    file isn’t critical, accessing it is commonly used as a flag to demonstrate remote
    code execution. So I used the following payload:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This PHP code opens the */etc/passwd* file, reads its contents using `file_get_contents`,
    and assigns the contents to the `$s` variable. Once `$s` is set, I dump the contents
    of that variable using `var_dump`, expecting the email I receive will include
    the contents of */etc/passwd* as the name of the person who invited me to the
    Unikrn site. But strangely enough, the email I received had a blank name.
  prefs: []
  type: TYPE_NORMAL
- en: 'I wondered whether Unikrn was limiting the length of names. This time I searched
    the PHP documentation for `file_get_contents`, which detailed how to limit the
    amount of data read at a time. I changed my payload to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The key parameters in this payload are `'/etc/passwd'`, `0`, and `100`. The
    path refers to the file to read, `0` instructs PHP where to start in the file
    (in this case at the beginning of the file), and `100` denotes the length of data
    to read. I reinvited myself to Unikrn using this payload, which produced the email
    shown in [Figure 8-4](ch08.xhtml#ch08fig04).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/08fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-4: The Unikrn invitation email showing contents of the* /etc/passwd
    *file*'
  prefs: []
  type: TYPE_NORMAL
- en: I successfully executed arbitrary code and, as proof of concept, extracted the
    */etc/passwd* file 100 characters at a time. After I submitted my report, the
    vulnerability was fixed within the hour.
  prefs: []
  type: TYPE_NORMAL
- en: '***Takeaways***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Working on this vulnerability was great fun. The initial stack trace was a red
    flag that something was wrong, and as the saying goes, “Where there’s smoke, there’s
    fire.” If you find a potential SSTI, always read the documentation to determine
    how best to proceed—and be persistent.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When you’re searching for vulnerabilities, it’s best to try to confirm the underlying
    technology (be it a web framework, frontend rendering engine, or something else)
    to identify possible attack vectors and ideas to test. The variety of template
    engines makes it difficult to determine what will and won’t work in all situations,
    but knowing which technology is being used will help you overcome that challenge.
    Be on the lookout for opportunities that arise when text you control is being
    rendered. Also, keep in mind that vulnerabilities might not be immediately apparent
    but could still exist in other functionality, such as in emails.
  prefs: []
  type: TYPE_NORMAL
