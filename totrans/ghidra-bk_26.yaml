- en: '## **21'
  prefs: []
  type: TYPE_NORMAL
- en: OBFUSCATED CODE ANALYSIS**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](Images/com.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Even under ideal circumstances, comprehending a disassembly listing is a difficult
    task. High-quality disassemblies are essential for anyone trying to understand
    the inner workings of a binary, which is precisely why we have spent the last
    20 chapters discussing Ghidra and its associated capabilities. It can be argued
    that Ghidra is so effective at what it does that it has lowered the barrier for
    entry into the binary analysis field. While certainly not attributable to Ghidra
    alone, recent advances in binary reverse engineering are not lost on anyone who
    does not want their software to be analyzed. Thus, over the last several years,
    an arms race of sorts has been taking place between programmers who wish to keep
    their code secret and reverse engineers
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we examine Ghidra’s role in this arms race and discuss some
    of the measures that have been taken to protect code, along with approaches to
    defeating those measures. We wrap up the chapter by introducing Ghidra’s `Emulator`
    class and provide examples of how emulation scripts can give us an edge in this
    arms race.
  prefs: []
  type: TYPE_NORMAL
- en: '### **Anti–Reverse Engineering**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Anti–reverse engineering* is an umbrella topic that covers all techniques
    that software developers might employ to make reverse engineering their products
    more challenging. Many tools and techniques exist to assist developers with this
    goal, with more appearing every day. The RE/anti-RE ecosystem is similar to the
    escalating dynamic that plays out between malware authors and antivirus vendors.'
  prefs: []
  type: TYPE_NORMAL
- en: As a reverse engineer, you are likely to encounter techniques ranging from trivial
    to nearly impossible to defeat. The approaches that you will be required to use
    will also vary depending on the nature of the anti-reversing techniques you encounter,
    and may require some level of comfort with both static and dynamic analysis techniques.
    In the sections that follow, we discuss some of the more common anti-reversing
    techniques, why they are employed, and approaches for defeating them.
  prefs: []
  type: TYPE_NORMAL
- en: '***Obfuscation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Various dictionary definitions will inform you that *obfuscation* is the act
    of making something obscure, perplexing, confusing, or bewildering in order to
    prevent others from understanding the obfuscated item. In the context of this
    book and the use of Ghidra, the items being obfuscated are binary executable files
    (as opposed to source files or silicon chips, for example).
  prefs: []
  type: TYPE_NORMAL
- en: Obfuscation, by itself, is too broad to be considered an anti–reverse engineering
    technique. It also fails to cover all known anti–reverse engineering techniques.
    Specific, individual techniques can often be described as obfuscating or non-obfuscating
    techniques and, where applicable, we point these out in the sections that follow.
    It is important to note that there is no one correct way to categorize techniques,
    as the general categories often overlap in their descriptions. In addition, new
    anti–reverse engineering techniques are under continuous development, and it is
    not possible to provide a single all-inclusive list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because Ghidra is primarily a static analysis tool, we find it more useful
    to divide our discussion of techniques into two, broad categories: *anti–static
    analysis* and *anti–dynamic analysis*. Both categories may contain obfuscating
    techniques, but the former is more likely to confound static tools, while the
    latter generally targets debuggers and other runtime analysis tools.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Anti–Static Analysis Techniques***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Anti–static analysis techniques* aim to prevent an analyst from understanding
    the nature of a program without actually running the program. These are precisely
    the types of techniques that target disassemblers such as Ghidra and are thus
    of greatest concern whenever you are using Ghidra to reverse engineer binaries.
    Several types of anti–static analysis techniques are discussed here.'
  prefs: []
  type: TYPE_NORMAL
- en: '##### **Disassembly Desynchronization**'
  prefs: []
  type: TYPE_NORMAL
- en: One of the older techniques designed to frustrate the disassembly process involves
    the creative use of instructions and data to prevent the disassembler from finding
    the correct starting address for one or more instructions. Forcing the disassembler
    to lose track of itself usually results in a failed or, at a minimum, incorrect
    disassembly listing. [Listing 21-1](ch21.xhtml#exa21_1) shows Ghidra’s efforts
    to disassemble a portion of the Shiva anti–reverse engineering tool.^([1](footnotes.xhtml#ch21fn1))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 21-1: Sample of initial Shiva disassembly*'
  prefs: []
  type: TYPE_NORMAL
- en: This example executes a `CALL` ➊ that is immediately followed by a `POP` ➌.
    This sequence is not uncommon in self-modifying code and is used by the code to
    discover where it is running memory. The return address ➋ for the call instruction
    is `0a04b0d6` and sits on the top of the stack as execution arrives at the `POP`
    instruction. The `POP` instruction removes the return address from the stack and
    loads it into `EAX`, while the `LEA` that follows ➍ immediately adds `0xa` (10)
    to `EAX` so that `EAX` now holds `0a04b0e0` (keep this value handy, as we’ll use
    it in a few moments).
  prefs: []
  type: TYPE_NORMAL
- en: The called function is unlikely to ever return to the original call point, as
    the original return address is no longer on top of the stack (it would need to
    be replaced in order to `RET` to the original return location), and Ghidra cannot
    form an instruction at the return address ➋ because `C7h` is not a valid start
    byte for an instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, the code may be a little unusual or difficult to follow, but Ghidra
    is presenting a correct disassembly. This all changes when the `JMP` ➎ instruction
    is reached. This jump instruction is 2 bytes long, its address is `0a04b0db`,
    and the jump target is `LAB_0a04b0db+1`. The `+1` suffix in the label is new to
    us. The address component of the label is the same as the address of the jump
    itself. The `+1` is telling you that the jump target is 1 byte past `LAB_0a04b0db`.
    In other words, the jump lands right in the middle of the 2-byte jump instruction.
    While the processor doesn’t care about this unusual situation (it will happily
    fetch whatever the instruction pointer points to), Ghidra just can’t make it work.
    Ghidra has no means to concurrently display the byte at `0a04b0db` (`ff`) as both
    the second byte of the jump and the first byte of another instruction. As a result,
    Ghidra is suddenly unable to continue with the disassembly, as indicated by the
    undefined data value at `0a04b0dd` ➏. (This behavior is not restricted to Ghidra:
    virtually all disassemblers, whether they utilize a recursive descent algorithm
    or a linear sweep algorithm, fall victim to this technique.)'
  prefs: []
  type: TYPE_NORMAL
- en: Ghidra makes note of any problems it encounters during disassembly by creating
    *error bookmarks* in the disassembly. [Figure 21-1](ch21.xhtml#fig21_1) shows
    two such bookmarks (X icon to the left of the offending addresses) in the left
    margin of the Listing window. Hovering over an error bookmark displays an associated
    detail message. In addition, you can open a listing of all bookmarks in the current
    binary by using Window ▸ Bookmarks.
  prefs: []
  type: TYPE_NORMAL
- en: Ghidra’s message for the first error is “Unable to resolve constructor at 0a04b0d6
    (flow from 0a04b0d1),” which means roughly “I think an instruction is supposed
    to exist at 0a04b0d6, but I couldn’t create one.” Ghidra’s message for the second
    error is “Failed to disassemble at 0a04b0dc due to conflicting instruction at
    0a04b0db (flow from 0a04b0db),” which means roughly “I cannot disassemble an instruction
    within an existing instruction.”
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig21-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 21-1: Ghidra error bookmarks*'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a Ghidra user, you have no solution for the first error. A byte sequence
    is either a valid instruction or it isn’t. With a bit of effort on your part,
    you can deal with the second error. The proper way to deal with this situation
    is to undefine the instruction that contains the bytes that are the target of
    the call and then define an instruction at the call target address in an attempt
    to resynchronize the disassembly. You will lose the original instruction, but
    you can leave yourself a comment to remind you of what the original instruction
    was. The following portion of the previous listing contains the overlapping instruction
    error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Right-clicking the `JMP` instruction ➊ and selecting Clear Code Bytes (hotkey
    C) from the context menu yields the following listing of undefined bytes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The byte that is the target ➊ of the `JMP` is now accessible for reformatting.
    Raw bytes are changed to code by right-clicking the start byte of an instruction
    and selecting Disassemble (hotkey D). The listing is now updated to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The target of the jump instruction turns out to be yet another jump instruction
    ➊. In this case, however, the jump is impossible for a disassembler (and potentially
    confusing to the human analyst) to follow, as the target of the jump is contained
    in a register (`EAX`) and computed at runtime. This is an example of another type
    of anti–static analysis technique, discussed in the following section, “Dynamically
    Computed Target Addresses.” We previously determined that `EAX` contains the value
    `0a04b0e0` by the time we reach this jump, and this is the address at which we
    must resume the disassembly process. Lather, rinse, repeat.
  prefs: []
  type: TYPE_NORMAL
- en: Referring back to [Listing 21-1](ch21.xhtml#exa21_1), as an alternative to manually
    moving to address `0a04b0e0` to resume the disassembly, you can set the value
    of `EAX` to the known value by right-clicking the address ➌ and selecting Set
    Register Values. Ghidra will then add a special markup called a *register transition*
    around the instruction to indicate the *assumed* value of the `JMP` target, `EAX`.
    Subsequent clearing (hotkey C) and disassembling (hotkey D) from this location
    will restart the recursive descent disassembly process from the `JMP` to the target,
    `0a04b0e0`, and beyond (including creating the XREFs between those code blocks).
  prefs: []
  type: TYPE_NORMAL
- en: 'An advantage of this approach is that the code is annotated to show the target
    of the `JMP`, allowing other analysts to easily follow the effective control flow
    through this section. (This is even clearer when combined with an override to
    the fallthrough for the `LEA` instruction at `0a04b0d8` in [Listing 21-1](ch21.xhtml#exa21_1)).
    This alternative approach results in the following listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Another example of desynchronization taken from a different binary demonstrates
    how processor flags may be utilized to turn conditional jumps into absolute jumps.
    The following disassembly demonstrates the use of the x86 `Z` flag for just such
    a purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the `XOR` instruction ➊ is used to zero the `EAX` register and set the
    x86 `Z` flag. The programmer, knowing that the `Z` flag is set, utilizes a jump-on-zero
    (`JZ`) instruction ➋, which will always be taken, to attain the effect of an unconditional
    jump. As a result, the instructions between the jump ➋ and the jump target ➌ will
    never be executed and serve only to confuse any analyst who fails to realize this
    fact. This example also obscures the actual jump target by jumping into the middle
    of the `CALL` instruction at `00401009` ➍. Properly disassembled, the code should
    read as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The actual target of the jump ➋ has been revealed, as has the extra byte ➊ that
    caused the desynchronization in the first place. It is certainly possible to use
    far more roundabout ways of setting and testing flags prior to executing a conditional
    jump. The level of difficulty for analyzing such code increases with the number
    of operations that may affect the processor flag bits prior to testing their value.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dynamically Computed Target Addresses**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The phrase *dynamically computed* simply means that an address to which execution
    will flow is computed at runtime. In this section, we discuss several ways in
    which such an address can be derived. The intent of such techniques is to hide
    (obfuscate) the actual control flow path that a binary will follow from the prying
    eyes of the static analysis process.
  prefs: []
  type: TYPE_NORMAL
- en: One example of this technique was shown in the preceding section. The example
    used a call instruction to place a return address on the stack. The return address
    was popped directly off the stack into a register, and a constant value was added
    to the register to derive the final target address, which was ultimately reached
    by performing a jump to the location specified by the register contents.
  prefs: []
  type: TYPE_NORMAL
- en: 'An infinite number of similar code sequences can be developed for deriving
    a target address and transferring control to that address. The following code,
    also used in Shiva, demonstrates an alternate method for dynamically computing
    target addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The comments to the right of the semicolons document the changes being made
    to various processor registers at each instruction. The process culminates in
    a derived value being moved into the top position of the stack (`TOS`) ➊, which
    causes the return instruction to transfer control to the computed location (`0A048068`
    in this case). An analyst must essentially run the code by hand to determine the
    actual control flow path taken in the program.
  prefs: []
  type: TYPE_NORMAL
- en: '**Obfuscated Control Flow**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Much more complex methods to hide control flow have been developed and utilized
    in recent years. In the most complex cases, a program will use multiple threads
    or child processes to compute control flow information and receive that information
    via some form of interprocess communication (for child processes) or synchronization
    primitives (for multiple threads).
  prefs: []
  type: TYPE_NORMAL
- en: In such cases, static analysis can become extremely difficult, as it becomes
    necessary to understand not only the behavior of multiple executable entities
    but also the exact manner by which those entities exchange information. For example,
    one thread may wait on a shared semaphore object, while a second thread computes
    values or modifies code that the first thread will make use of after the second
    thread signals its completion via the semaphore.^([2](footnotes.xhtml#ch21fn2))
  prefs: []
  type: TYPE_NORMAL
- en: 'Another technique, frequently used within Windows malware, involves configuring
    an exception handler,^([3](footnotes.xhtml#ch21fn3)) intentionally triggering
    an exception, and then manipulating the state of the process’s registers while
    handling the exception. The following example is used by the tElock anti–reverse
    engineering tool to obscure the program’s actual control flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The sequence begins by using a `CALL` ➊ to the next instruction ➋; the `CALL`
    instruction pushes `0041d07f` onto the stack as a return address, which is promptly
    popped off the stack into the `EBP` register ➋. Next, the `EAX` register ➌ is
    set to the sum of `EBP` and `46h`, or `0041d0c5`, and this address is pushed onto
    the stack ➍ as the address of an exception handler function. The remainder of
    the exception handler setup takes place at ➎ and ➏, which complete the process
    of linking the new exception handler into the existing chain of exception handlers
    referenced by `FS:[0]`.^([4](footnotes.xhtml#ch21fn4))
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to intentionally generate an exception ➐, in this case an `INT
    3`, which is a software trap (interrupt) to the debugger. (In x86 programs, the
    `INT 3` instruction is used by debuggers to implement a software breakpoint.)
    Normally at this point, an attached debugger would gain control, as debuggers
    are given the first opportunity to handle the exception. In this case, the program
    fully expects to handle the exception, so any attached debugger must be instructed
    to pass the exception along to the program. Not allowing the program to handle
    the exception may cause the program to operate incorrectly or crash. Without understanding
    how the `INT 3` exception is handled, it is impossible to know what may happen
    next in this program. If we assume that execution simply resumes following the
    `INT 3`, then it appears that a divide-by-zero exception will eventually be triggered
    by instructions ➑ and ➒.
  prefs: []
  type: TYPE_NORMAL
- en: 'The decompiled version of the exception handler associated with the preceding
    code begins at address `0041d0c5`. The first portion of this function is shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The third argument to the exception handler function ➊ is a pointer to a Windows
    `CONTEXT` structure (defined in the Windows API header file *winnt.h*). The `CONTEXT`
    structure is initialized with the contents of all processor registers as they
    existed at the time of the exception. An exception handler has the opportunity
    to inspect and, if desired, modify the contents of the `CONTEXT` structure. If
    the exception handler feels that it has corrected the problem that led to the
    exception, it can notify the operating system that the offending thread should
    be allowed to continue. At this point, the operating system reloads the processor
    registers for the thread from the `CONTEXT` structure that was provided to the
    exception handler, and execution of the thread resumes as if nothing had ever
    happened.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, the exception handler begins by accessing the thread’s
    `CONTEXT` in order to increment the instruction pointer ➋, to allow execution
    to resume at the instruction following the one that generated the exception. Next,
    the exception’s type code (a field within the provided `EXCEPTION_RECORD`) is
    retrieved ➌ in order to determine the nature of the exception. This portion of
    the exception handler handles the divide-by-zero error ➍, generated in the previous
    example, by zeroing ➎ all of the x86 hardware debugging registers and disabling
    hardware breakpoints.^([5](footnotes.xhtml#ch21fn5)) Without examining the remainder
    of the tElock code, it is not immediately apparent why the debug registers are
    being cleared. In this case, tElock is clearing values from a previous operation
    in which it used the debug registers to set four breakpoints in addition to the
    `INT 3` seen previously. In addition to obfuscating the true flow of the program,
    clearing or modifying the x86 debug registers can wreak havoc for software debuggers
    such as OllyDbg or GDB. Such anti-debugging techniques are discussed in “[Anti–Dynamic
    Analysis Techniques](ch21.xhtml#ch21lev394)” on [page 487](ch21.xhtml#page_487).
  prefs: []
  type: TYPE_NORMAL
- en: '**Opcode Obfuscation**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: While the techniques described to this point may provide—in fact, are intended
    to provide—a hindrance to understanding a program’s control flow, none prevent
    you from observing the correct disassembled form of a program you are analyzing.
    Desynchronization had the greatest impact on the disassembly, but it was easily
    defeated by reformatting the disassembly to reflect the correct instruction flow.
  prefs: []
  type: TYPE_NORMAL
- en: A more effective technique for preventing correct disassembly is to encode or
    encrypt the actual instructions when the executable file is being created. The
    obfuscated instructions must be deobfuscated back to their original form before
    they are fetched for execution by the processor. Therefore, at least some portion
    of the program must remain unencrypted in order to serve as the startup routine,
    which, in the case of an obfuscated program, is usually responsible for deobfuscating
    some or all of the remainder of the program. A very generic overview of the obfuscation
    process is shown in [Figure 21-2](ch21.xhtml#fig21_2).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig21-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 21-2: Generic obfuscation process*'
  prefs: []
  type: TYPE_NORMAL
- en: As shown, the input to the process is a program to be obfuscated. In many cases,
    the input program is written using standard programming languages and build tools
    (editors, compiler, and the like) with little thought required about the obfuscation
    to come. The resulting executable file is fed into an obfuscation utility that
    transforms the binary into a functionally equivalent, yet obfuscated, binary.
    As depicted, the obfuscation utility is responsible for obfuscating the original
    program’s code and data sections and adding additional code (a deobfuscation stub)
    that performs the task of deobfuscating the code and data before the original
    functionality can be accessed at runtime. The obfuscation utility also modifies
    the program headers to redirect the program entry point to the deobfuscation stub,
    ensuring that execution begins with the deobfuscation process. Following deobfuscation,
    execution typically transfers to the entry point of the original program, which
    begins execution as if it had never been obfuscated at all.
  prefs: []
  type: TYPE_NORMAL
- en: This oversimplified process varies widely based on the obfuscation utility that
    is used to create the obfuscated binary. An ever-increasing number of utilities
    are available to handle the obfuscation process. Such utilities offer features
    ranging from compression to anti-disassembly and anti-debugging techniques. Examples
    include programs such as UPX (compressor, also works with ELF; *[https://upx.github.io/](https://upx.github.io/)*),
    ASPack (compressor; *[http://www.aspack.com/](http://www.aspack.com/)*), ASProtect
    (anti–reverse engineering by the makers of ASPack), and tElock (compression and
    anti–reverse engineering; *[http://www.softpedia.com/get/Programming/Packers-Crypters-Protectors/Telock.shtml](http://www.softpedia.com/get/Programming/Packers-Crypters-Protectors/Telock.shtml)*.)
    for Windows PE files. The capabilities of obfuscation utilities have advanced
    to the point that some anti–reverse engineering tools such as VMProtect integrate
    with the entire build process, allowing programmers to integrate anti–reverse
    engineering features at every stage of development, from source code through post-processing
    the compiled binary file (*[https://vmpsoft.com/](https://vmpsoft.com/)*).
  prefs: []
  type: TYPE_NORMAL
- en: '**SANDBOX ENVIRONMENTS**'
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of a *sandbox environment* for reverse engineering is to allow you
    to execute programs in a manner that allows observation of the program’s behavior
    without allowing that behavior to adversely impact critical components of your
    reverse engineering platform or anything it is connected to. Sandbox environments
    are commonly constructed using platform virtualization software, but they may
    be constructed on dedicated systems that are capable of being restored to a known-good
    state following the execution of any malware.
  prefs: []
  type: TYPE_NORMAL
- en: Sandbox systems are typically heavily instrumented in order to observe and collect
    information on the behavior of programs run within the sandbox. Collected data
    may include information on the filesystem activity of a program, the registry
    activity of a (Windows) program, and information about any networking activity
    generated by the program. One example of a complete sandbox environment is Cuckoo
    (*[https://cuckoosandbox.org/](https://cuckoosandbox.org/)*), a popular open source
    sandbox specifically oriented toward malware analysis.
  prefs: []
  type: TYPE_NORMAL
- en: As with any offensive technology, defensive measures have been developed to
    counter many anti–reverse engineering tools. In most cases, the goal of such tools
    is to recover the original, unprotected executable file (or a reasonable facsimile),
    which can then be analyzed using more traditional tools such as disassemblers
    and debuggers.
  prefs: []
  type: TYPE_NORMAL
- en: One such tool designed to deobfuscate Windows executables is called QuickUnpack
    (*[http://qunpack.ahteam.org/?p=458](http://qunpack.ahteam.org/?p=458)*; site
    is in Russian). QuickUnpack, like many other automated unpackers, operates by
    functioning as a debugger and allowing an obfuscated binary to execute through
    its deobfuscation phase and then capturing the process image from memory. Beware
    that this type of tool actually runs potentially malicious programs in the hope
    of intercepting the execution of those programs after they have unpacked or deobfuscated
    themselves but before they have a chance to do anything malicious. Thus, you should
    always execute such programs in a sandbox-type environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a purely static analysis environment to analyze obfuscated code is a
    challenging task. Without being able to execute the deobfuscation stub, the obfuscated
    portions of the binary must be unpacked or decrypted before disassembly can begin.
    The Ghidra Address Type overview bar, at right in [Figure 21-3](ch21.xhtml#fig21_3),
    shows the layout of an executable that has been packed using the UPX packer. Ghidra
    color-codes content in the overview bar to give you an indication of the associated
    content in the binary. The general categories for the overview bar include the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uninitialized
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: External Reference
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instruction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Undefined
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focusing on the overview bar in the figure, we can see Ghidra’s preliminary
    assessment of various parts of the binary. Hovering over any of the sections in
    the overview bar will provide additional information about the corresponding region
    of the binary. The unusual appearance of this particular navigation bar is a tip-off
    that this binary has been obfuscated in some manner. Let’s take a closer look
    at some of the sections in the overview bar.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ghidra has identified a data section ➊ at the start of the file. Examining
    this content reveals the headers for the file along with informative content that
    is indicative of the type of obfuscation used on this file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![image](Images/fig21-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 21-3: Ghidra Listing window and Address Type overview bar for a binary
    packed using UPX*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This section is followed by a block of undefined content ➋ similar to the following,
    which appears in the Listing window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The largest section ➌ contains uninitialized data, which appears as follows
    in the Listing window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: A little farther in the file, Ghidra has identified another block of undefined
    content ➍. At the end of this data is a region that Ghidra has identified as a
    function ➎. This function is easily recognizable as the UPX decompression stub,
    which Ghidra has identified as the entry point for the binary, as shown in the
    Listing window on the left in [Figure 21-3](ch21.xhtml#fig21_3). The undefined
    content segments we observed ➋➍ are the result of the UPX compression process.
    The job of the decompression stub is to unpack that data into the uninitialized
    region ➌ before finally transferring control to the unpacked code.
  prefs: []
  type: TYPE_NORMAL
- en: The information presented by the Address Type overview bar can be correlated
    with the properties of each segment within the binary to determine whether the
    information presented in each display is consistent. The memory map for this binary
    is shown in [Figure 21-4](ch21.xhtml#fig21_4).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig21-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 21-4: Memory map of a UPX packed binary*'
  prefs: []
  type: TYPE_NORMAL
- en: In this particular binary, the entire range of addresses contained in segment
    `UPX0` ➊ and segment `UPX1` ➋ (`00401000`–`00408fff`) is marked as executable
    (the X flag is set). Given this fact, we should expect to see the entire Address
    Type overview bar colorized to represent functions. The fact that we do not, coupled
    with the fact that the entire range of `UPX0` is uninitialized and writable, should
    be considered highly suspicious and provides valuable clues about the binary and
    how we might proceed with analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Techniques for using Ghidra to perform the decompression operation in a static
    context (without actually executing the binary) on files such as this one are
    discussed in “[Static Deobfuscation of Binaries Using Ghidra](ch21.xhtml#ch21lev399)”
    on [page 491](ch21.xhtml#page_491).
  prefs: []
  type: TYPE_NORMAL
- en: '***Imported Function Obfuscation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Anti–static analysis techniques may also hide which shared libraries and library
    functions a binary uses in order to avoid leaking information about potential
    actions that the binary may perform. In most cases, it is possible to render tools
    such as `dumpbin`, `ldd`, and `objdump` ineffective for the purposes of listing
    library dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: The effect of such obfuscations on Ghidra is most obvious in the Symbol Tree.
    The entire Symbol Tree for our earlier tElock example is shown in [Figure 21-5](ch21.xhtml#fig21_5).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig21-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 21-5: Symbol Tree for obfuscated binary*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Only two imported functions are referenced: `GetModulehandleA` (from *kernel32.dll*)
    and `MessageBoxA` (from *user32.dll*). Virtually nothing about the behavior of
    the program can be inferred from this short list. Here again the techniques are
    varied but essentially boil down to the fact that the program itself must load
    any additional libraries that it depends on, and once the libraries are loaded,
    the program must locate any required functions within those libraries. In most
    cases, these tasks are performed by the deobfuscation stub prior to transferring
    control to the deobfuscated program. The end goal is for the program’s import
    table to have been properly initialized, just as if the process had been performed
    by the operating system’s own loader.'
  prefs: []
  type: TYPE_NORMAL
- en: For Windows binaries, a simple approach is to use the `LoadLibrary` function
    to load required libraries by name and then use the `GetProcAddress` function
    to perform function address lookups within each library. To use these functions,
    a program must either be explicitly linked to them or have an alternate means
    of looking them up. The Symbol Tree for the tElock example does not include either
    of these functions, while the Symbol Tree for the UPX example, shown in [Figure
    21-6](ch21.xhtml#fig21_6), includes both.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig21-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 21-6: Symbol Tree for UPX example*'
  prefs: []
  type: TYPE_NORMAL
- en: The actual UPX code responsible for rebuilding the import table is shown in
    [Listing 21-2](ch21.xhtml#exa21_2).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 21-2: Import table reconstruction in UPX*'
  prefs: []
  type: TYPE_NORMAL
- en: This example contains an outer loop responsible for calling `LoadLibrary` ➊
    and an inner loop responsible for calling `GetProcAddress` ➋. Following each successful
    call to `GetProcAddress`, the newly retrieved function address is stored into
    the reconstructed import table ➌.
  prefs: []
  type: TYPE_NORMAL
- en: These loops are executed as the last portion of the UPX deobfuscation stub,
    because each function takes string pointer parameters that point to either a library
    name or a function name, and the associated strings are held within the compressed
    data region to avoid detection by the `strings` utility. As a result, library
    loading in UPX cannot take place until the required strings have been decompressed.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to the tElock example, a different problem presents itself. With only
    two imported functions, neither of which is `LoadLibrary` or `GetProcAddress`,
    how can the tElock utility perform the function-resolution tasks that were performed
    by UPX? All Windows processes depend on *kernel32.dll*, which means that it is
    present in memory for all processes. If a program can locate *kernel32.dll*, a
    relatively straightforward process may be followed to locate any function within
    the DLL, including `LoadLibrary` and `GetProcAddress`. As shown previously, with
    these two functions in hand, it is possible to load any additional libraries required
    by the process and locate all required functions within those libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 'In his paper “Understanding Windows Shellcode,” Skape discusses techniques
    for doing exactly this.^([6](footnotes.xhtml#ch21fn6)) While tElock does not use
    the exact techniques detailed by Skape, there are many parallels, and the net
    effect is to obscure the details of the loading and linking process. Without carefully
    tracing the program’s instructions, it is extremely easy to overlook the loading
    of a library or the lookup of a function address. The following small code fragment
    illustrates the manner in which tElock attempts to locate the address of `LoadLibrary`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: It is immediately obvious that several comparisons are taking place in rapid
    succession. What may not be immediately clear is the purpose of these comparisons.
    Reformatting the operands (right-click and then choose **Convert** ▸ **Char Sequence**)
    used in each comparison sheds a little light on the code, as seen in the following
    listing.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Each hexadecimal constant is actually a sequence of four ASCII characters, which
    Ghidra is capable of displaying as quoted ASCII and, together, spell `LoadLibraryA`.^([7](footnotes.xhtml#ch21fn7))
    If the three comparisons succeed, tElock has located the export table entry for
    `LoadLibraryA` and in a few short operations will obtain the address of this function
    for loading additional libraries. tElock’s approach to function lookup is somewhat
    resistant to string analysis because the 4-byte constants embedded directly in
    the program’s instructions do not look like standard, null-terminated strings
    and thus do not get included in the list of strings generated by Ghidra unless
    you change the defaults (for example, unchecking the Require Null Termination
    option during your string search).
  prefs: []
  type: TYPE_NORMAL
- en: Manually reconstructing a program’s import table through careful analysis of
    the program’s code is made easier in the case of UPX and tElock because, ultimately,
    both contain ASCII character data that you can use to determine exactly which
    libraries and which functions are being referenced. Skape’s paper details a function-resolution
    process in which no strings at all appear within the code. The basic idea discussed
    in the paper is to precompute a unique hash value for the name of each function
    that you need to resolve.^([8](footnotes.xhtml#ch21fn8)) To resolve each function,
    you can search through a library’s exported names table. Each name in the table
    is hashed, and you can compare the resulting hash against the precomputed hash
    value for the desired function. If the hashes match, you have located the desired
    function, and can easily locate its address in the library’s export address table.
  prefs: []
  type: TYPE_NORMAL
- en: 'To statically analyze binaries obfuscated in this manner, you need to understand
    the hashing algorithm used for each function name and apply that algorithm to
    all the names exported by the library the program is searching. With a complete
    table of hashes in hand, you can do a simple lookup of each hash you encounter
    in the program to determine which function the hash references. A portion of such
    a table, generated for *kernel32.dll*, might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note that the hash values are specific to the hash function being used within
    a particular binary and are likely to vary from one binary to another. Using this
    particular table, if the hash value `8A0FB5E2` ➊ were encountered within a program,
    you could quickly determine that the program was attempting to look up the address
    of the `GetProcAddress` function.
  prefs: []
  type: TYPE_NORMAL
- en: Skape’s use of hash values to resolve function names was originally developed
    and documented for use in exploit payloads for Windows vulnerabilities; however,
    they have been adopted for use in obfuscated programs as well.
  prefs: []
  type: TYPE_NORMAL
- en: '***Anti–Dynamic Analysis Techniques***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: None of the anti–static analysis techniques covered in the past few sections
    have any effect whatsoever on whether a program will actually execute. In fact,
    while anti–static analysis techniques may make it difficult for you to comprehend
    the true behavior of a program using static analysis techniques alone, they can’t
    prevent the program from executing, or they would render a program useless from
    the start and therefore eliminate the need to analyze the program at all.
  prefs: []
  type: TYPE_NORMAL
- en: Given that a program must run in order to do any useful work, dynamic analysis
    aims to observe the behavior of a program in motion (while it is running) rather
    than observe the program at rest (using static analysis while the program is not
    running). In this section, we briefly summarize some of the more common anti–dynamic
    analysis techniques. For the most part, these techniques have little effect on
    static analysis tools; however, where there is overlap, we point this out.
  prefs: []
  type: TYPE_NORMAL
- en: '**Detecting Virtualization**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Sandbox environments commonly use virtualization software, such as VMware, to
    provide an execution environment for malicious software (or any other software
    of interest). The advantage of such environments is that they typically offer
    checkpoint and rollback capabilities that facilitate rapid restoration of the
    sandbox to a known-clean state. The primary disadvantage is that malware may be
    able to detect the sandbox. Under the assumption that virtualization equates to
    observation, many programs that want to remain undetected simply shut after once
    they determine that they are running within a virtual machine. Given the widespread
    use of virtualization for production purposes, this assumption is less valid today
    than it has been historically.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following list describes a few of the techniques that have been used by
    programs running in virtualized environments to determine that they are running
    within a virtual machine rather than on native hardware:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Detection of virtualization-specific software**'
  prefs: []
  type: TYPE_NORMAL
- en: Users often install helper applications within virtual machines to facilitate
    communications between a virtual machine and its host operating system or simply
    to improve performance within the virtual machine. The VMware Tools collection
    is one example of this kind of software. The presence of such software is easily
    detected by programs running within the virtual machine. For example, when VMware
    Tools is installed into a Microsoft Windows virtual machine, it creates Windows
    registry keys that can be read by any program. Malware detecting these keys may
    elect to shut down before exhibiting any noteworthy behaviors. On the other hand,
    virtualization is so widely used today that a VMware image found without VMware
    Tools installed might be considered equally suspicious in the eyes of a piece
    of malware.
  prefs: []
  type: TYPE_NORMAL
- en: '**Detection of virtualization-specific hardware**'
  prefs: []
  type: TYPE_NORMAL
- en: Virtual machines use virtual hardware abstraction layers to provide the interface
    between the virtual machine and the host computer’s native hardware. Characteristics
    of the virtual hardware are often easily detectable by software running within
    the virtual machine. For example, VMware has been assigned its own organizationally
    unique identifiers (OUIs) for its virtualized network adapters.^([9](footnotes.xhtml#ch21fn9))
    Observing a VMware-specific OUI is a good indication that a program is running
    within a virtual machine. Software that shuts down for this reason may be coaxed
    into executing by modifying the MAC address assigned to any virtual network adapters
    associated with the virtual machine.
  prefs: []
  type: TYPE_NORMAL
- en: '**Detection of processor-specific behavioral changes**'
  prefs: []
  type: TYPE_NORMAL
- en: Perfect virtualization is difficult to achieve. Ideally, a program should not
    be able to detect any difference between a virtualized environment and native
    hardware. However, this is seldom the case. Joanna Rutkowska developed her Red
    Pill VMware-detection technique after observing behavioral differences between
    the operation of the x86 `sidt` instruction on native hardware and the same instruction
    executed within a virtual machine environment.^([10](footnotes.xhtml#ch21fn10))
  prefs: []
  type: TYPE_NORMAL
- en: '**Detecting Instrumentation**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Following creation of your sandbox environment and prior to executing any program
    you want to observe, you need to ensure that instrumentation is in place to properly
    collect and record information about the behavior of the program you are analyzing.
    A wide variety of tools exist for performing such monitoring tasks. Two widely
    used examples are *Process Monitor* from the Sysinternals group at Microsoft and
    *Wireshark*.^([11](footnotes.xhtml#ch21fn11)) Process Monitor is a utility capable
    of monitoring certain activities associated with any running Windows process,
    including accesses to the Windows registry and filesystem activity. Wireshark
    is a network packet capture and analysis tool often used to analyze network traffic
    generated by malicious software.
  prefs: []
  type: TYPE_NORMAL
- en: Malware authors with a sufficient level of paranoia may program their software
    to search for running instances of such monitoring programs. Techniques that have
    been employed range from scanning the active process list for process names associated
    with such monitoring software to scanning the title bar text for all active Windows
    applications to search for known strings. Deeper searches can be performed, with
    some software going so far as to search for specific characteristics associated
    with Windows GUI components used within certain instrumentation software.
  prefs: []
  type: TYPE_NORMAL
- en: '**Detecting Debuggers**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Moving beyond simple observation of a program, a debugger allows an analyst
    to take complete control of the execution of a program that requires analysis.
    Debuggers are commonly used to run an obfuscated program just long enough to complete
    any decompression or decryption tasks, and then the debuggers’ memory-access features
    are used to extract the deobfuscated process image from memory. In most cases,
    standard static analysis tools and techniques can be used to complete the analysis
    of the extracted process image.
  prefs: []
  type: TYPE_NORMAL
- en: The authors of obfuscation utilities are well aware of such debugger-assisted
    deobfuscation techniques and so have developed measures to attempt to defeat the
    use of debuggers for execution of their obfuscated programs. Programs that detect
    the presence of a debugger often choose to terminate rather than proceed with
    any operations that might allow an analyst to determine the behavior of the program.
  prefs: []
  type: TYPE_NORMAL
- en: Techniques for detecting the presence of debuggers range from simple queries
    to the operating system via well-known API functions such as the Windows `IsDebuggerPresent`
    function, to lower-level checks for memory or processor artifacts resulting from
    the use of a debugger. An example of the latter includes detecting that a processor’s
    trace (single step) flag is set.
  prefs: []
  type: TYPE_NORMAL
- en: As long as you know what to look for, there is nothing terribly tricky about
    trying to detect a debugger, and attempts to do so are easily observed during
    static analysis (unless anti–static analysis techniques are employed simultaneously).
    For more information on debugger detection, please consult the article “Anti Debugging
    Detection Techniques with Examples,” which provides a comprehensive overview of
    Windows anti-debugging techniques.^([12](footnotes.xhtml#ch21fn12))
  prefs: []
  type: TYPE_NORMAL
- en: '**Preventing Debugging**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Even an undetectable debugger can be thwarted using additional techniques that
    attempt to confound the debugger by introducing spurious breakpoints, clearing
    hardware breakpoints, hindering disassembly to make selection of appropriate breakpoint
    addresses difficult, or preventing the debugger from attaching to a process in
    the first place. Many of the techniques discussed in the previously referenced
    anti-debugging article are geared toward preventing debuggers from operating correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Intentionally generating exceptions is one way a program may attempt to hinder
    debugging. In most cases, an attached debugger will catch the exception, and the
    user of the debugger must analyze why the exception occurred and whether to pass
    the exception along to the program being debugged. In the case of a software breakpoint
    such as the x86 `INT 3`, it may be difficult to distinguish a software interrupt
    generated by the underlying program from one that results from an actual debugger
    breakpoint. This confusion is exactly the effect that is desired by the creator
    of the obfuscated program. In such cases, it’s possible, though harder, to understand
    the true program flow by using careful analysis of the disassembly listing.
  prefs: []
  type: TYPE_NORMAL
- en: Encoding portions of a program has the dual effect of hindering static analysis
    because disassembly is not possible and hindering debugging because placing breakpoints
    is difficult. Even if the start of each instruction is known, software breakpoints
    cannot be placed until the instructions have actually been decoded, as altering
    the instructions by inserting a software breakpoint is likely to result in a failed
    decryption of the obfuscated code and then a crash of the program when execution
    reaches the intended breakpoint.
  prefs: []
  type: TYPE_NORMAL
- en: The Shiva ELF obfuscation tool for Linux uses a technique called *mutual ptrace*
    as a means of preventing the use of a debugger in analyzing Shiva’s behavior.
  prefs: []
  type: TYPE_NORMAL
- en: '**PROCESS TRACING**'
  prefs: []
  type: TYPE_NORMAL
- en: The *ptrace*, or process tracing, API available on many Unix-like systems provides
    a mechanism for one process to monitor and control the execution of another process.
    The GNU debugger (`gdb`) is one of the more well-known applications that uses
    the ptrace API. Using the ptrace API, a ptrace parent process may attach to and
    control the execution of a ptrace child process. To begin controlling a process,
    a parent process must first *attach* to the child process that it seeks to control.
    Once the parent process is attached, the child process is stopped anytime it receives
    a signal, and the parent is notified of this fact via the POSIX `wait` function,
    at which point the parent may choose to alter or inspect the state of the child
    process before instructing the child process to continue execution. Once a parent
    process has attached to a child process, no other process may attach to the same
    child process until the tracing parent chooses to detach from the child process.
  prefs: []
  type: TYPE_NORMAL
- en: Shiva takes advantage of the fact that only one other process may be attached
    to a process at any given time. Early in its execution, the Shiva process forks
    to create a copy of itself. The original Shiva process immediately performs a
    ptrace attach operation on the newly forked child. The newly forked child process,
    in turn, immediately attaches to its parent process. If either attach operation
    fails, Shiva terminates under the assumption that a debugger is being used to
    monitor the Shiva process. If both operations succeed, no other debugger can attach
    to the running Shiva pair, and Shiva can continue to run without fear of being
    observed. While operating in this manner, either Shiva process may alter the state
    of the other, making it difficult to determine, using static analysis techniques,
    what the exact control flow path is through the Shiva binary.
  prefs: []
  type: TYPE_NORMAL
- en: '**Static Deobfuscation of Binaries Using Ghidra**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At this point, you may be wondering how, given all of the anti–reverse engineering
    techniques available, it is possible to analyze software that a programmer is
    intent on keeping secret. Given that these techniques target both static analysis
    tools and dynamic analysis tools, what is the best approach to take in revealing
    a program’s hidden behavior? Unfortunately, no single solution fits all cases
    equally well.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, the solution depends on your skill set and the tools available
    to you. If your analysis tool of choice is a debugger, you will need to develop
    strategies for circumventing debugger detection and prevention protections. If
    your preferred analysis tool is a disassembler, you will need to develop strategies
    for obtaining an accurate disassembly and, in cases in which self-modifying code
    is encountered, for mimicking the behavior of that code in order to properly update
    your disassembly listings.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discuss two techniques for dealing with self-modifying code
    in a static analysis environment (that is, without executing the code). Static
    analysis may be your only option when you are unwilling (because of hostile code)
    or unable (because of lack of hardware) to analyze a program while controlling
    it with a debugger. If these concepts make you feel like you are going down a
    rabbit hole, don’t be discouraged. Ghidra has secret (or not-so-secret) weapons
    that we can leverage in the static deobfuscation arms race.
  prefs: []
  type: TYPE_NORMAL
- en: '***Script-Oriented Deobfuscation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Because Ghidra can be used to disassemble binaries for an ever-increasing set
    of processors, it is not uncommon to analyze a binary developed for an entirely
    different platform than the one on which you are running Ghidra. For example,
    you may be asked to analyze a Linux x86 binary even though you happen to be running
    Ghidra on macOS, or you may be asked to analyze a MIPS or ARM binary even though
    you are running Ghidra on an x86 platform.
  prefs: []
  type: TYPE_NORMAL
- en: In such cases, you may not have access to appropriate tools, such as debuggers,
    for dynamically analyzing the binary. When such a binary has been obfuscated by
    encoding portions of the program, you may have no other option than to create
    a Ghidra script that will mimic the deobfuscating stage of the program in order
    to properly decode the program and disassemble the decoded instructions and data.
  prefs: []
  type: TYPE_NORMAL
- en: This may seem like a daunting task; however, in many cases, the decoding stages
    of an obfuscated program use only a small subset of a processor’s instruction
    set, so familiarizing yourself with the necessary operations may not require understanding
    the entire instruction set for the target processor.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 14](ch14.xhtml#ch14) presented an algorithm for developing scripts
    that emulate the behavior of portions of a program. In the following example,
    we will utilize those steps to develop a simple Ghidra script to decode a program
    that has been encrypted with the Burneye ELF encryption tool. In our sample program,
    execution begins with the instructions in [Listing 21-3](ch21.xhtml#exa21_3).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 21-3: Burneye startup sequence and obfuscated code*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The program begins by pushing the contents of memory location `05371008h` onto
    the stack ➊ before pushing the processor flags ➋ and all processor registers ➌.
    The purpose of these instructions is not immediately clear, so we simply file
    this information away for later. Next, the `ECX` register is loaded with the contents
    of memory location `05371000h` ➍. According to the algorithm presented in [Chapter
    14](ch14.xhtml#ch14), we need to declare a variable named `ECX` at this point
    and initialize it from memory by using Ghidra’s `getInt` function, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Following an absolute jump, the program calls function `FUN_05371048` ➎, which
    pushes address `05371087h` (the return address) onto the stack. The disassembled
    instructions that follow the `CALL` instruction begin to make less and less sense.
    The `OUT` instruction ➏ is not generally encountered in user-space code, and Ghidra
    is unable to disassemble an instruction at address `053710B5h` ➐. These are both
    indications that something is not quite right with this binary (that and the fact
    that the Symbol Tree lists only two functions: `entry` and `FUN_05371048`).'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, analysis needs to continue with the call to function `FUN_05371048`,
    which is shown in [Listing 21-4](ch21.xhtml#exa21_4).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 21-4: Main Burneye decoding function*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is not a typical function: it begins by immediately popping the return
    address off the stack into the `ESI` register ➊. Recalling that the saved return
    address was `05371087h`, and taking into account the initialization of `EDI` ➋,
    `EBX` ➌, and `EDX` ➎, our script grows to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Following these initializations, the function performs a test on the value contained
    in the `EBX` register ➍ before entering an outer loop ➏ and an inner loop ➐. The
    remaining logic of the function is captured in the following completed script.
    Within the script, comments are used to relate script actions to the corresponding
    actions in the preceding disassembly listing.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Whenever you are trying to emulate an instruction, you should pay particular
    attention to data sizes and register aliasing. In this example, we need to select
    an appropriate data size and variable to properly implement the x86 `LODSB` (load
    string byte) and `STOSB` (store string byte) instructions. These instructions
    write to (`LODSB`) and read from (`STOSB`) the low-order 8 bits of the `EAX` register,^([13](footnotes.xhtml#ch21fn13))
    leaving the upper 24 bits unchanged. In Java, there is no way to partition a variable
    into bit-sized portions other than using various bitwise operations to mask off
    and recombine portions of the variable. Specifically, in the case of the `LODSB`
    instruction ➊, a more faithful emulation would read as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This example first clears the low 8 bits of the `EAX` variable and then merges
    in the new value for the low 8 bits using an `OR` operation. In the Burneye decoding
    example, the entire `EAX` register is set to 8 at the beginning of each outer
    loop, which has the effect of zeroing the upper 24 bits of `EAX`. As a result,
    we have elected to simplify our implementation of `LODSB` ➊ by ignoring the effect
    of the assignment on the upper 24 bits of `EAX`. No thought need be given to our
    implementation of `STOSB` ➋, as the `setByte` function requires us to cast the
    second argument to a `byte`.
  prefs: []
  type: TYPE_NORMAL
- en: Following execution of the Burneye decoding script, our disassembly would reflect
    all of the changes that would normally not be observable until the obfuscated
    program was executed on a Linux system. If the deobfuscation process was carried
    out properly, we are very likely to see many more legible strings within Ghidra’s
    Search ▸ “For Strings... option” . To observe this fact, you may need to select
    the Refresh icon in the String Search window.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remaining tasks include (1) determining where the decoding function will return
    to, given that it popped its return address in the very first instruction of the
    function, and (2) coaxing Ghidra to properly display the decoded byte values as
    instructions or data as appropriate. The Burneye decoding function ends with the
    following three instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Recall that the function began by popping its own return address, which means
    that the remaining stack values were set up by the caller. The `POPAD` and `POPFD`
    instructions used here are the counterparts to the `PUSHAD` and `PUSHFD` instructions
    used at the beginning of Burneye’s start routine, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The net result is that the only value that remains on the stack is the one that
    was pushed at the first line of `entry` ➊. It is to this location that the Burneye
    decoding routine returns, and it is at this location that further analysis of
    the Burneye protected binary would need to continue.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding example may make it seem like writing a script to decode or unpack
    an obfuscated binary is a relatively easy thing to do. This is true in the case
    of Burneye, which does not use a terribly sophisticated initial obfuscation algorithm.
    The deobfuscation stub of more sophisticated utilities such as ASPack and tElock
    would require somewhat more effort to implement using Ghidra.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages to script-based deobfuscation include that the binary being analyzed
    need never be executed and that it is possible to create a functional script without
    ever developing a complete understanding of the exact algorithm used to deobfuscate
    the binary. This latter statement may seem counterintuitive, as it would seem
    that you would need to have a complete understanding of the deobfuscation before
    you could emulate the algorithm using a script. Using the development process
    described here and in [Chapter 14](ch14.xhtml#ch14), however, all you really need
    is a complete understanding of each processor instruction involved in the deobfuscation
    process. By faithfully implementing each processor action using Ghidra and properly
    sequencing each action according to the disassembly listing, you will have a script
    that mimics the program’s actions even if you do not fully comprehend the higher-level
    algorithm that those actions, as a whole, implement.
  prefs: []
  type: TYPE_NORMAL
- en: Disadvantages of using a script-based approach include that the scripts are
    rather fragile. If a deobfuscation algorithm changes as a result of an upgrade
    to a deobfuscation tool or through the use of alternate command line settings
    supplied to the obfuscation tool, a script that had been effective against that
    tool will likely need to be modified accordingly. For example, it is possible
    to develop generic unpacking scripts for use with binaries packed using UPX, but
    such scripts require constant tuning as UPX evolves.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, scripted deobfuscation suffers from the lack of a one-size-fits-all
    solution to deobfuscation. There is no mega-script capable of deobfuscating all
    binaries. In a sense, scripted deobfuscation suffers from many of the same shortcomings
    as signature-based intrusion detection and antivirus systems. A new script must
    be developed for each new type of packer, and subtle changes in existing packers
    are likely to break existing scripts. Let’s shift focus and look at a more generic
    approach to deobfuscation.
  prefs: []
  type: TYPE_NORMAL
- en: '***Emulation-Oriented Deobfuscation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A recurring theme encountered when creating scripts to perform deobfuscation
    tasks is the need to emulate a processor’s instruction set in order to behave
    identically to the program being deobfuscated. Instruction emulators allow us
    to shift some or all of the work performed by these scripts over to the emulator
    and drastically reduce the amount of time required for Ghidra to deobfuscate.
    Emulators can fill the void between scripts and debuggers and can be more flexible
    than debuggers. An emulator can, for example, emulate a MIPS binary on an x86
    platform or emulate instructions from a Linux ELF binary on a Windows platform.
  prefs: []
  type: TYPE_NORMAL
- en: Emulators vary in capabilities. At a minimum, an emulator requires a stream
    of instruction bytes and sufficient memory to dedicate to stack operations and
    processor registers. More sophisticated emulators may provide access to emulated
    hardware devices and operating system services.
  prefs: []
  type: TYPE_NORMAL
- en: '##### **Ghidra’s Emulator Class**'
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, Ghidra provides a rich `Emulator` class as well as an `EmulatorHelper`,
    which provides a higher-level abstraction of common emulator functionality and
    facilitates the quick-and-easy creation of emulation scripts. In [Chapter 18](ch18.xhtml#ch18),
    we introduced p-code as an intermediate representation of the underlying assembly
    and described how this allows the decompiler to work against a variety of target
    architectures. Similarly, p-code supports emulator functionality as well, and
    Ghidra’s `ghidra.pcode.emulate.Emulate` class provides the ability to emulate
    a single p-code instruction.
  prefs: []
  type: TYPE_NORMAL
- en: We can use Ghidra’s emulator-related classes to build emulators that allow us
    to emulate a wide variety of processors. As with other Ghidra packages and classes,
    this functionality is documented in the Javadoc supplied with Ghidra and can be
    pulled up as a reference by clicking the red plus tool in the Script Manager window.
    If you are interested in writing emulators, we encourage you to check out the
    Javadoc associated with the emulator methods used in the following example.
  prefs: []
  type: TYPE_NORMAL
- en: '**CRACKME, CRACK YOURSELF**'
  prefs: []
  type: TYPE_NORMAL
- en: A *crackme* is a puzzle built by reverse engineers, for reverse engineers. The
    name derives from cracking a piece of software to bypass copy or usage restrictions—one
    of the more nefarious uses of reverse engineering skills. Crackmes provide a legal
    means to practice these skills as well as provide both the author of the crackme
    and the person analyzing the crackme a chance to show off their talent.
  prefs: []
  type: TYPE_NORMAL
- en: A common style of crackme receives a user input, transforms that input in some
    way, and then compares the result of the transformation to a precomputed output.
    When you attempt to solve a crackme, you are generally given only a compiled executable
    that contains both the code that performs the transformation and the final output
    for an unknown input. The crackme is solved when you derive the input that was
    used to generate the output contained in the binary, which typically requires
    understanding the transformation so well that you can derive the inverse transformation
    function.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example: SimpleEmulator**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Assume that we have a binary associated with the following crackme challenge,
    including some encoded content at the start of the file that eventually serves
    as the body of a function. In this example, we build an emulator script to automate
    the process of decoding the information needed to solve the crackme:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Even with the source code available, this crackme would require some effort
    to solve because of the encoded content ➊. Ghidra’s decompiler is frequently an
    awesome partner for solving crackme challenges, but this one has interesting characteristics
    that complicate the process. Ghidra sees only the encoded function body, but we
    need to know the function’s actual purpose before we can solve the challenge.
    At runtime, the `unpack` ➌ function call results in the decoding of the `check_access`
    ➋ function before `check_access` is called ➍. The answer to this crackme is obfuscated,
    and we can build an emulator script in Ghidra to help us attack this challenge.
    Unlike the previous example, this emulator will not just solve the problem for
    this specific case, but will be capable of emulating somewhat arbitrary code.
  prefs: []
  type: TYPE_NORMAL
- en: '***Step 1: Define the Problem***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our task is to design and develop a simple emulator that will allow us to choose
    a region of a disassembly and will emulate the instructions in that region. The
    emulator needs to be added to Ghidra and be available as a script. For example,
    if we select the `unpack` function for the crackme challenge and run the script,
    our emulator should use the key to unpack the `check_access` array and let us
    know the solution to the crackme challenge. The script will write the unpacked
    code bytes into the program’s memory in Ghidra.
  prefs: []
  type: TYPE_NORMAL
- en: '***Step 2: Create the Eclipse Script Project***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We can create a project called *SimpleEmulator* using GhidraDev ▸ New ▸ Ghidra
    Script Project. This gives us a *SimpleEmulator* folder in Eclipse with a folder
    called *Home scripts* (refer to [Figure 15-16](ch15.xhtml#fig15_16) on [page 325](ch15.xhtml#page_325))
    waiting for our new script. We still need to create the actual script and enter
    the associated metadata to ensure that our script is documented and can be catalogued.
    The metadata collected in the script creation dialog is included in the file and,
    as [Figure 21-7](ch21.xhtml#fig21_7) shows, we have only one thing to do: `Add
    script code here`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig21-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 21-7: Script template for* SimpleEmulator'
  prefs: []
  type: TYPE_NORMAL
- en: '***Step 3: Build the Emulator***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We know that Eclipse will recommend imports if we need them as we develop our
    code, so we can jump right into the coding tasks we need to perform and add the
    recommended `import` statements when Eclipse detects that we need them. For functionality,
    we will rely on the following instance variable declarations throughout our `SimpleEmulator`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Comments associated with each declaration describe the purpose of each variable.
    The `executionAddress` will initially be set to the start of the selected range,
    but will also be used to advance through the selection.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3-1: Set Up the Emulator**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The first thing we will do in our script’s `run` method is instantiate our
    emulator helper object and activate the tracking of any memory written in the
    emulator so that we can write updated values back into the current program. The
    instantiation acts as a lock, similar to the lock that the CodeBrowser places
    on an open binary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3-2: Select the Address Range to Be Emulated**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Since we want the user to choose the section of code to be emulated, we need
    to ensure they have selected something in the Listing window. Otherwise, we will
    generate an error message.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3-3: Get Ready to Emulate**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Within the selection, we want to ensure we are looking at an instruction in
    order to establish the initial processor context, initialize the stack pointer,
    and set up a breakpoint at the end of the selected region. The `continuing` flag
    indicates whether we are just starting the emulation or continuing the emulation,
    and determines which version of `emuHelper.run` is called in step 3-4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3-4: Perform Emulation**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In this section, you should recognize the use of some Ghidra API functions
    introduced in [Chapter 14](ch14.xhtml#ch14) (such as `monitor.isCancelled`). We
    need a loop to drive the emulation until a termination condition that we define
    is reached:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: For this example, emulation continues as long as the monitor hasn’t detected
    a user cancellation, we haven’t reached the end of the selected range of instructions,
    or an error condition hasn’t been triggered ➊. When the emulator stops, we need
    to update the current execution address ➋ and then handle the stop condition appropriately
    ➌. The final step is to call the `writeBackMemory()`method ➍.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3-5: Write Memory Back to the Program**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The implementation of `writeBackMemory()` ➍ is shown here. This emulator is
    going to be tested on an unpack routine, which ultimately changes the bytes in
    memory. The memory changes that the emulator has made exist only in its working
    memory. The content needs to be written back to the binary in order to allow the
    listing and other user interfaces to accurately reflect the changes that result
    from executing the instructions in the unpack routine. Ghidra provides functionality
    within its `emulatorHelper` to facilitate this process.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '**Step 3-6: Clean Up Resources**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In this step, we need to clean up resources and release the lock that we have
    on the current program. Both can be accomplished in one easy statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Since this emulator is only for demonstration purposes, we took some liberties
    in what was included in the script. To conserve space, we minimized the comments,
    functionality, error checking, and error handling that we would normally include
    in a production script. All that remains is to confirm that our emulator script
    is able to accomplish our goal.
  prefs: []
  type: TYPE_NORMAL
- en: '***Step 4: Add the Script to Our Ghidra Installation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Adding a script to our Ghidra installation just requires dropping it somewhere
    that Ghidra will find it. If you set up the script project as a linked project,
    Ghidra knows where to find it already. If you did not link your script project
    (or if you created your emulator script in another editor), you need to save it
    in one of Ghidra’s script directories, as discussed in [Chapter 14](ch14.xhtml#ch14).
  prefs: []
  type: TYPE_NORMAL
- en: '***Step 5: Test the Script Within Ghidra***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To test the script, we will load the binary associated with the crackme challenge
    source code. When we load the binary and navigate to the `unpack` function, we
    note that it contains references to the `check_access` label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The code in the Decompiler window contains the following, which does not get
    us any closer to solving our crackme:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Double-clicking `check_access` within the Listing window leads us to address
    `00301010`, which does not look like instructions within a function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: If we chose to disassemble this content, we would receive a bad data error in
    Ghidra. The Decompiler window also provides no help for this location. So let’s
    use our script to see if we can emulate the `unpack` function. We select the instructions
    that make up the `unpack` function and open the Script Manager and run our script.
    We see no observable change in the `unpack` function or in the Decompiler window.
    But if we navigate to `check_access` (`00301010`), the content has changed!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'We can clear these code bytes (hotkey C) and then disassemble (hotkey D) and
    obtain the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the corresponding code in the Decompiler window:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: This was just a proof-of-concept script to demonstrate the use of emulators
    to aid in code deobfuscation, but it does show how a relatively general-purpose
    emulator can be built within Ghidra by using its emulator support classes. There
    are other situations where developing and using emulators are an appropriate course
    of action. An immediate advantage of emulation over debugging is that potentially
    malicious code is never actually executed by an emulator, whereas debugger-assisted
    deobfuscation must allow at least some portion of the malicious program to execute
    in order to obtain the deobfuscated version of the program.
  prefs: []
  type: TYPE_NORMAL
- en: '### **Summary**'
  prefs: []
  type: TYPE_NORMAL
- en: Obfuscated programs are the rule rather than the exception when it comes to
    malware these days. Any attempts to study the internal operations of a malware
    sample are almost certain to require some type of deobfuscation. Whether you take
    a debugger-assisted, dynamic approach to deobfuscation or you prefer not to run
    potentially malicious code and instead choose to use scripts or emulation to deobfuscate
    your binaries, the ultimate goal is to produce a deobfuscated binary that can
    be fully disassembled and properly analyzed.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, this final analysis will be performed using a tool such as Ghidra.
    Given this ultimate goal (of using Ghidra for analysis), it makes sense to attempt
    to use Ghidra from start to finish. The techniques presented in this chapter are
    intended to demonstrate that Ghidra is capable of far more than simply generating
    disassembly listings, and we build on this in the next chapter as we look at how
    we can use Ghidra to patch our disassembly listings.
  prefs: []
  type: TYPE_NORMAL
