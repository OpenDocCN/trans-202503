<html><head></head><body>
<section epub:type="chapter" role="doc-chapter" aria-labelledby="ch5">&#13;
<hgroup>&#13;
<h1 class="CHAPTER" id="ch5">&#13;
<span class="CN"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_95" aria-label="95"/><span class="SANS_Futura_Std_Bold_Condensed_B_11">5</span></span>&#13;
<span class="CT"><span class="SANS_Dogma_OT_Bold_B_11">VULNERABILITY SCANNING AND FUZZING</span></span>&#13;
</h1>&#13;
</hgroup>&#13;
<figure class="opener"><img class="opener" src="../images/opener.jpg" alt=""/></figure>&#13;
<p class="COS">In <span class="chapterintro_Xref"><a href="chapter4.xhtml">Chapter 4</a></span>, we identified hosts on a network and a few running services, including HTTP, FTP, and SSH. Each of these protocols has its own set of tests we could perform. In this chapter, we’ll use specialized tools on the discovered services to find out as much as we can about them.</p>&#13;
<p class="TX">In the process, we’ll use bash to run security testing tools, parse their output, and write custom scripts to scale security testing across many URLs. We’ll fuzz with tools such as ffuf and Wfuzz, write custom security checks using the Nuclei templating system, extract personally identifiable information (PII) from the output of tools, and create our own quick-and-dirty vulnerability scanners.</p>&#13;
<section epub:type="division" aria-labelledby="sec1">&#13;
<h2 class="H1" id="sec1"><span id="h1-34"/><span class="SANS_Futura_Std_Bold_B_11">Scanning Websites with Nikto</span></h2>&#13;
<p class="TNI1"><i>Nikto</i> is a web scanning tool available on Kali. It performs banner grabbing and runs a few basic checks to determine if the web server uses security <span role="doc-pagebreak" epub:type="pagebreak" id="pg_96" aria-label="96"/>headers to mitigate known web vulnerabilities; these vulnerabilities include <i>cross-site scripting (XSS)</i>, which is a client-side injection vulnerability targeting web browsers, and <i>UI redressing</i> (also known as <i>clickjacking</i>), a vulnerability that lets attackers use decoy layers in a web page to hijack user clicks. The security headers indicate to browsers what to do when loading certain resources and opening URLs, protecting the user from falling victim to an attack.</p>&#13;
<p class="TX">After performing these security checks, Nikto also sends requests to possible endpoints on the server by using its built-in wordlist of common paths. The requests can discover interesting endpoints that could be useful for penetration testers. Let’s use Nikto to perform a basic web assessment of the three web servers we’ve identified on the IP addresses 172.16.10.10 (<i>p-web-01</i>), 172.16.10.11 (<i>p-ftp-01</i>), and 172.16.10.12 (<i>p-web-02</i>).</p>&#13;
<p class="TX">We’ll run a Nikto scan against the web ports we found to be open on the three target IP addresses. Open a terminal and run the following commands one at a time so you can dissect the output for each IP address:</p>&#13;
<pre><code>$ <b>nikto -host 172.16.10.10 -port 8081</b>&#13;
$ <b>nikto -host 172.16.10.11 -port 80</b>&#13;
$ <b>nikto -host 172.16.10.12 -port 80</b>&#13;
</code></pre>&#13;
<p class="TX">The output for 172.16.10.10 on port 8081 shouldn’t yield much interesting information about discovered endpoints, but it should indicate that the server doesn’t seem to be hardened, as it doesn’t use security headers:</p>&#13;
<pre><code>+ Server: Werkzeug/2.2.3 Python/3.11.1&#13;
+ The anti-clickjacking X-Frame-Options header is not present.&#13;
+ The X-XSS-Protection header is not defined. This header can hint to the user&#13;
agent to protect against some forms of XSS&#13;
+ The X-Content-Type-Options header is not set. This could allow the user&#13;
agent to render the content of the site in a different fashion to the MIME&#13;
type&#13;
<var>--snip--</var>&#13;
+ Allowed HTTP Methods: OPTIONS, GET, HEAD&#13;
+ 7891 requests: 0 error(s) and 4 item(s) reported on remote host&#13;
</code></pre>&#13;
<p class="TX">Nikto was able to perform a banner grab of the server, as indicated by the line that starts with the word <span class="SANS_TheSansMonoCd_W5Regular_11">Server</span>. It then listed a few missing security headers. These are useful pieces of information but not enough to take over a server just yet.</p>&#13;
<p class="TX">The IP address 172.16.10.11 on port 80 should give you a similar result, though Nikto also discovered a new endpoint, <i>/backup</i>, and that directory indexing mode is enabled:</p>&#13;
<pre><code>+ Server: Apache/2.4.55 (Ubuntu)&#13;
<var>--snip--</var>&#13;
+ OSVDB-3268: /backup/: Directory indexing found.&#13;
+ OSVDB-3092: /backup/: This might be interesting...&#13;
</code></pre>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_97" aria-label="97"/><i>Directory indexing</i> is a server-side setting that, instead of a web page, lists files located at certain web paths. When enabled, the directory indexing setting lists the content of a directory when an index file is missing (such as <i>index.html</i> or <i>index.php</i>). Directory indexing is interesting to find because it could highlight sensitive files in an application, such as configuration files with connection strings, local database files (such as SQLite files), and other environmental files. Open the browser in Kali to <i>http://172.16.10.11/backup</i> to see the content of this endpoint (<a href="chapter5.xhtml#fig5-1">Figure 5-1</a>).</p>&#13;
<figure class="IMG"><img id="fig5-1" class="img7" src="../images/pg97.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_I_11">Figure 5-1: Directory indexing found on</span> <span class="SANS_Futura_Std_Book_11">172.16.10.11/backup</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX">Directory indexing lets you view files in the browser. You can click directories to open them, click files to download them, and so on. On the web page, you should identify two folders: <i>acme-hyper-branding</i> and <i>acme-impact -alliance</i>. The <i>acme-hyper-branding</i> folder appears to contain a file named <i>app.py</i>. Download it to Kali by clicking it so it’s available for later inspection.</p>&#13;
<p class="TX">We’ll explore the third IP address in a moment, but first let’s use bash automation to take advantage of directory indexing.</p>&#13;
<section epub:type="division" aria-labelledby="sec2">&#13;
<h3 class="H2" id="sec2"><span id="h2-71"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Building a Directory Indexing Scanner</span></h3>&#13;
<p class="TNI1">What if we wanted to run a scan against a list of URLs to check whether they enable directory indexing, then download all the files they serve? In <a href="chapter5.xhtml#Lis5-1">Listing 5-1</a>, we use bash to carry out such a task.</p>&#13;
<span id="Lis5-1"/>&#13;
<p class="CodeLabel"><span class="codelabel_Italic">directory _indexing _scanner.sh</span></p>&#13;
<pre class="pre"><code>#!/bin/bash&#13;
FILE="${1}"&#13;
OUTPUT_FOLDER="${2}"&#13;
&#13;
<span class="codeannotated_CodeAnnotation" aria-label="annotation1">❶</span> if [[! -s "${FILE}"]]; then&#13;
  echo "You must provide a non-empty hosts file as an argument."&#13;
  exit 1&#13;
fi&#13;
&#13;
if [[-z "${OUTPUT_FOLDER}"]]; then&#13;
<span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> OUTPUT_FOLDER="data"&#13;
fi&#13;
&#13;
while read -r line; do&#13;
<span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> url=$(echo "${line}" | xargs)&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_98" aria-label="98"/>  if [[-n "${url}"]]; then&#13;
    echo "Testing ${url} for Directory indexing..."&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> if curl -L -s "${url}" | grep -q -e "Index of /" -e "[PARENTDIR]"; then&#13;
      echo -e "\t -!- Found Directory Indexing page at ${url}"&#13;
      echo -e "\t -!- Downloading to the \"${OUTPUT_FOLDER}\" folder..."&#13;
      mkdir -p "${OUTPUT_FOLDER}"&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation5">❺</span> wget -q -r -np -R "index.html*" "${url}" -P "${OUTPUT_FOLDER}"&#13;
    fi&#13;
  fi&#13;
done &lt; &lt;(cat "${FILE}")&#13;
</code></pre>&#13;
<p class="ListingCaption"><span class="Futura_Std_Book_Oblique_I">Listing 5-1: Automatically downloading files available via directory indexing</span></p>&#13;
<p class="TX">In this script, we define the <span class="SANS_TheSansMonoCd_W5Regular_11">FILE</span> and <span class="SANS_TheSansMonoCd_W5Regular_11">OUTPUT_FOLDER</span> variables. Their assigned values are taken from the arguments the user passes on the command line (<span class="SANS_TheSansMonoCd_W5Regular_11">$1</span> and <span class="SANS_TheSansMonoCd_W5Regular_11">$2</span>). We then fail and exit the script (<span class="SANS_TheSansMonoCd_W5Regular_11">exit 1</span>) if the <span class="SANS_TheSansMonoCd_W5Regular_11">FILE</span> variable is not of the file type and of length zero (<span class="SANS_TheSansMonoCd_W5Regular_11">-s</span>) <span class="CodeAnnotation" aria-label="annotation1">❶</span>. If the file has a length of zero, it means the file is empty.</p>&#13;
<p class="TX">We then use a <span class="SANS_TheSansMonoCd_W5Regular_11">while</span> loop to read the file at the path assigned to the <span class="SANS_TheSansMonoCd_W5Regular_11">FILE</span> variable. At <span class="CodeAnnotation" aria-label="annotation3">❸</span>, we ensure that each whitespace character in each line from the file is removed by piping it to the <span class="SANS_TheSansMonoCd_W5Regular_11">xargs</span> command. At <span class="CodeAnnotation" aria-label="annotation4">❹</span>, we use <span class="SANS_TheSansMonoCd_W5Regular_11">curl</span> to make an HTTP GET request and follow any HTTP redirects (using <span class="SANS_TheSansMonoCd_W5Regular_11">-L</span>). We silence verbose output from <span class="SANS_TheSansMonoCd_W5Regular_11">curl</span> (using <span class="SANS_TheSansMonoCd_W5Regular_11">-s</span>) and pipe it to <span class="SANS_TheSansMonoCd_W5Regular_11">grep</span> to find any instances of the strings <span class="SANS_TheSansMonoCd_W5Regular_11">Index of /</span> and <span class="SANS_TheSansMonoCd_W5Regular_11">[PARENTDIR]</span>. These two strings exist in directory indexing pages. You can verify this by viewing the source HTML page at <i>http://172.16.10.11/backup</i>.</p>&#13;
<p class="TX">If we find either string, we call the <span class="SANS_TheSansMonoCd_W5Regular_11">wget</span> command <span class="CodeAnnotation" aria-label="annotation5">❺</span> with the quiet option (<span class="SANS_TheSansMonoCd_W5Regular_11">-q</span>) to silence verbose output, the recursive option (<span class="SANS_TheSansMonoCd_W5Regular_11">-r</span>) to download files recursively from folders, the no-parent option (<span class="SANS_TheSansMonoCd_W5Regular_11">-np</span>) to ensure we download only files at the same level of hierarchy or lower (subfolders), and the reject option (<span class="SANS_TheSansMonoCd_W5Regular_11">-R</span>) to exclude files starting with <i>index.html</i>. We then use the target folder option (<span class="SANS_TheSansMonoCd_W5Regular_11">-P</span>) to download the content to the path specified by the user calling the script (the <span class="SANS_TheSansMonoCd_W5Regular_11">OUTPUT_FOLDER</span> variable). If the user didn’t provide a destination folder, the script will default to using the <i>data</i> folder <span class="CodeAnnotation" aria-label="annotation2">❷</span>.</p>&#13;
<blockquote>&#13;
<p class="Note"><span class="SANS_Dogma_OT_Bold_B_15">NOTE</span></p>&#13;
</blockquote>&#13;
<p class="NOTE-TXT"><i>You can download this chapter’s scripts from</i> <span class="note_LinkURL"><a href="https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05">https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05</a></span>.</p>&#13;
<p class="TX">The <i>acme-impact-alliance</i> folder we downloaded appears to be empty. But is it really? When dealing with web servers, you may run into what seem to be dead ends only to find out that something is hiding there, just not in an obvious place. Take note of the empty folder for now; we’ll resume this exploration in a little bit.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec3">&#13;
<h3 class="H2" id="sec3"><span id="h2-72"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Identifying Suspicious robots.txt Entries</span></h3>&#13;
<p class="TNI1">After scanning the third IP address, 172.16.10.12 (<i>p-web-02</i>), Nikto outputs the following:</p>&#13;
<pre><code><span role="doc-pagebreak" epub:type="pagebreak" id="pg_99" aria-label="99"/>+ Server: Apache/2.4.54 (Debian)&#13;
+ Retrieved x-powered-by header: PHP/8.0.28&#13;
<var>--snip--</var>&#13;
+ Uncommon header 'link' found, with contents: &lt;http://172.16.10.12/wp-json/&gt;;&#13;
rel="https://api.w.org/"&#13;
<var>--snip--</var>&#13;
+ Entry '/wp-admin/' in robots.txt returned a non-forbidden or redirect HTTP&#13;
code (302)&#13;
+ Entry '/donate.php' in robots.txt returned a non-forbidden or redirect HTTP&#13;
code (200)&#13;
+ "robots.txt" contains 17 entries which should be manually viewed.&#13;
+ /wp-login.php: Wordpress login found&#13;
<var>--snip--</var>&#13;
</code></pre>&#13;
<p class="TX">Nikto was able to find a lot more information this time! It caught missing security headers (which is extremely common to see in the wild, unfortunately). Next, Nikto found that the server is running on Apache and Debian and that it is powered by PHP, a backend programming language commonly used in web applications.</p>&#13;
<p class="TX">It also found an uncommon link that points to <i>http://172.16.10.12/wp-json</i> and found two suspicious entries in the <i>robots.txt</i> file—namely, <i>/wp-admin/</i> and <i>/donate.php</i>. The <i>robots.txt</i> file is a special file used to indicate to web crawlers (such as Google’s search engine) which endpoints to index and which to ignore. Nikto hints that the <i>robots.txt</i> file may have more entries than just these two and advises us to inspect it manually.</p>&#13;
<p class="TX">Finally, it also identified another endpoint at <i>/wp-login.php</i>, which is a login page for WordPress, a blog platform. Navigate to the main page at <i>http://172.16.10.12/</i> to confirm you’ve identified a blog.</p>&#13;
<p class="TX">Finding these non-indexed endpoints is useful during a penetration test because you can add them to your list of possible targets to test. When you open this file, you should notice a list of paths:</p>&#13;
<pre><code>User-agent:  *&#13;
&#13;
Disallow: /cgi-bin/&#13;
Disallow: /z/j/&#13;
Disallow: /z/c/&#13;
Disallow: /stats/&#13;
<var>--snip--</var>&#13;
Disallow: /manual/*&#13;
Disallow: /phpmanual/&#13;
Disallow: /category/&#13;
Disallow: /donate.php&#13;
Disallow: /amount_to_donate.txt&#13;
</code></pre>&#13;
<p class="TX">We identified some of these endpoints earlier (such as <i>/donate.php</i> and <i>/wp-admin</i>), but others we didn’t see when scanning with Nikto. In Exercise 5, you’ll use bash to automate your exploration of them.</p>&#13;
<p class="HeadAExercise"><span id="exe-5"/><span role="doc-pagebreak" epub:type="pagebreak" id="pg_100" aria-label="100"/><span class="SANS_Futura_Std_Heavy_B_15">Exercise 5: Exploring Non-indexed Endpoints</span></p>&#13;
<p class="TNI1">Nikto scanning returned a list of non-indexed endpoints. In this exercise, you’ll use bash to see whether they really exist on the server. Put together a script that will make an HTTP request to <i>robots.txt</i>, return the response, and iterate over each line, parsing the output to extract only the paths. Then the script should make an additional HTTP request to each path and check the status code it returns.</p>&#13;
<p class="TX"><a href="chapter5.xhtml#Lis5-2">Listing 5-2</a> is an example script that can get you started. It relies on a useful <span class="SANS_TheSansMonoCd_W5Regular_11">curl</span> feature you’ll find handy in your bash scripts: built-in variables you can reference to extract particular values from HTTP requests and responses, such as the size of the request sent (<span class="SANS_TheSansMonoCd_W5Regular_11">%{size_request}</span>) and the size of the headers returned in bytes (<span class="SANS_TheSansMonoCd_W5Regular_11">%{size_header}</span>).</p>&#13;
<span id="Lis5-2"/>&#13;
<p class="CodeLabel"><span class="codelabel_Italic">curl_fetch _robots_txt.sh</span></p>&#13;
<pre class="pre"><code>#!/bin/bash&#13;
TARGET_URL="http://172.16.10.12"&#13;
ROBOTS_FILE="robots.txt"&#13;
&#13;
<span class="codeannotated_CodeAnnotation" aria-label="annotation1">❶</span> while read -r line; do&#13;
<span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> path=$(echo "${line}" | awk -F'Disallow: ' '{print $2}')&#13;
<span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> if [[-n "${path}"]]; then&#13;
    url="${TARGET_URL}${path}"&#13;
    status_code=$(curl -s -o /dev/null -w "%{http_code}" "${url}")&#13;
    echo "URL: ${url} returned a status code of: ${status_code}"&#13;
  fi&#13;
&#13;
<span class="codeannotated_CodeAnnotation" aria-label="annotation4">❹</span> <span class="SANS_TheSansMonoCd_W5Regular_11">done &lt; &lt;(curl -s "${TARGET_URL}/${ROBOTS_FILE}")</span>&#13;
</code></pre>&#13;
<p class="ListingCaption"><span class="Futura_Std_Book_Oblique_I">Listing 5-2: Reading</span> <span class="SANS_Futura_Std_Book_11">robots.txt</span> <span class="Futura_Std_Book_Oblique_I">and making requests to individual paths</span></p>&#13;
<p class="TX">At <span class="CodeAnnotation" aria-label="annotation1">❶</span>, we read the output from the <span class="SANS_TheSansMonoCd_W5Regular_11">curl</span> command at <span class="CodeAnnotation" aria-label="annotation4">❹</span> line by line. This command makes an HTTP GET request to <i>http://172.16.10.12/robots.txt</i>. We then parse each line and grab the second field (which is separated from the others by a space) to extract the path and assign it to the <span class="SANS_TheSansMonoCd_W5Regular_11">path</span> variable <span class="CodeAnnotation" aria-label="annotation2">❷</span>. We check that the <span class="SANS_TheSansMonoCd_W5Regular_11">path</span> variable length is greater than zero to ensure we were able to properly parse it <span class="CodeAnnotation" aria-label="annotation3">❸</span>.</p>&#13;
<p class="TX">Then we create a <span class="SANS_TheSansMonoCd_W5Regular_11">url</span> variable, which is a string concatenated from the <span class="SANS_TheSansMonoCd_W5Regular_11">TARGET_URL</span> variable plus each path from the <i>robots.txt</i> file, and make an HTTP request to the URL. We use the <span class="SANS_TheSansMonoCd_W5Regular_11">-w</span> (write-out) variable <span class="SANS_TheSansMonoCd_W5Regular_11">%{http_code}</span> to extract only the status code from the response returned by the web server.</p>&#13;
<p class="TX">To go beyond this script, try using other <span class="SANS_TheSansMonoCd_W5Regular_11">curl</span> variables. You can find the full list of variables at <i><a href="https://curl.se/docs/manpage.html">https://curl.se/docs/manpage.html</a></i> or by running the <span class="SANS_TheSansMonoCd_W5Regular_11">man curl</span> command.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec4">&#13;
<h2 class="H1" id="sec4"><span id="h1-35"/><span class="SANS_Futura_Std_Bold_B_11">Brute-Forcing Directories with dirsearch</span></h2>&#13;
<p class="TNI1">The <i>dirsearch</i> fast directory brute-forcing tool is used to find hidden paths and files on web servers. Written in Python by Mauro Soria, dirsearch provides features such as built-in web directory wordlists, bring-your-own-dictionary options, and advanced response filtering. We’ll use it to try to <span role="doc-pagebreak" epub:type="pagebreak" id="pg_101" aria-label="101"/>identify additional attack vectors and verify that Nikto hasn’t missed anything obvious.</p>&#13;
<p class="TX">First, let’s rescan port 8081 on <i>p-web-01</i> (172.16.10.10), which yielded no discovered endpoints when scanned by Nikto. The following dirsearch command uses the <span class="SANS_TheSansMonoCd_W5Regular_11">-u</span> (URL) option to specify a base URL from which to start crawling:</p>&#13;
<pre><code>$ <b>dirsearch -u http://172.16.10.10:8081/</b>&#13;
&#13;
<var>--snip--</var>&#13;
&#13;
Target: http://172.16.10.10:8081/&#13;
&#13;
[00:14:55] Starting:&#13;
[00:15:32] 200 -  371B  - /upload&#13;
[00:15:35] 200 -   44B  - /uploads&#13;
</code></pre>&#13;
<p class="TX">Great! This tool was able to pick up two previously unknown endpoints named <i>/upload</i> and <i>/uploads</i>. This is why it’s important to double- and triple-check your results by using more than one tool and to manually verify the findings; tools sometimes produce false positives or use limited path-list databases. If you navigate to the <i>/upload</i> page, you should see a file-upload form. Take note of this endpoint because we’ll test it in <span class="Xref"><a href="chapter6.xhtml">Chapter 6</a></span>.</p>&#13;
<p class="TX">Let’s also use dirsearch to look for attack vectors in what looked like an empty folder on <i>p-ftp-01</i>, at <i>http://172.16.10.11/backup/acme-impact-alliance</i>:</p>&#13;
<pre><code>$ <b>dirsearch -u http://172.16.10.11/backup/acme-impact-alliance/</b>&#13;
&#13;
<var>--snip--</var>&#13;
Extensions: php, aspx, jsp, html, js | HTTP method: GET | Threads: 30 | Wordlist size: 10927&#13;
Target: http://172.16.10.11/backup/acme-impact-alliance/&#13;
<var>--snip--</var>&#13;
[22:49:53] Starting:&#13;
[22:49:53] 301 -  337B  - /backup/acme-impact-alliance/js  -&gt;  http://172.16.10.11/backup/&#13;
acme-impact-alliance/js/&#13;
[22:49:53] 301 -  339B  - /backup/acme-impact-alliance/.git  -&gt;  http://172.16.10.11/backup/&#13;
acme-impact-alliance/.git/&#13;
<var>--snip--</var>&#13;
[22:49:53] 200 -   92B  - /backup/acme-impact-alliance/.git/config&#13;
<var>--snip--</var>&#13;
</code></pre>&#13;
<p class="TX">dirsearch inspects responses returned from the web server to identify interesting behaviors that could indicate the existence of an asset. For example, the tool might note whether a certain URL redirects to a new location (specified by an HTTP status code 301) and the response size in bytes. Sometimes you can infer information and observe behaviors solely by inspecting this data.</p>&#13;
<p class="TX">This time, we’ve identified a subfolder within the <i>acme-impact-alliance</i> folder named <i>.git</i>. A folder with this name usually indicates the existence of a Git repository on the server. <i>Git</i> is a source code management tool, and in this case, it likely manages code running locally on the remote server.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_102" aria-label="102"/>Use dirsearch again to perform brute forcing against the second directory, <i>/backup/acme-hyper-branding</i>. Save the results into their own folder, then check them. You should find a Git repository there too.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec5">&#13;
<h2 class="H1" id="sec5"><span id="h1-36"/><span class="SANS_Futura_Std_Bold_B_11">Exploring Git Repositories</span></h2>&#13;
<p class="TNI1">When you find a Git repository, it’s often useful to run a specialized Git cloner that pulls the repository and all its associated metadata so you can inspect it locally. For this task, we’ll use Gitjacker.</p>&#13;
<section epub:type="division" aria-labelledby="sec6">&#13;
<h3 class="H2" id="sec6"><span id="h2-73"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Cloning the Repository</span></h3>&#13;
<p class="TNI1">Gitjacker’s command is pretty simple. The first argument is a URL, and the <span class="SANS_TheSansMonoCd_W5Regular_11">-o</span> (output) argument takes a folder name into which the data will be saved if Gitjacker succeeds at pulling the repository:</p>&#13;
<pre><code>$ <b>gitjacker http://172.16.10.11/backup/acme-impact-alliance/ -o acme-impact-alliance-git</b>&#13;
&#13;
<var>--snip--</var>&#13;
Target:     http://172.16.10.11/backup/acme-impact-alliance/&#13;
Output Dir: acme-impact-alliance-git&#13;
Operation complete.&#13;
&#13;
Status:            Success&#13;
Retrieved Objects: 3242&#13;
<var>--snip--</var>&#13;
</code></pre>&#13;
<p class="TX">As you can see, the tool returned a successful status and a few thousand objects. At this point, you should have a folder named <i>acme-impact-alliance-git</i>:</p>&#13;
<pre><code>$ <b>ls -la ./acme-impact-alliance-git</b>&#13;
&#13;
<var>--snip--</var>&#13;
128 -rw-r--r--  1 kali kali 127309 Mar 17 23:15 comment.php&#13;
 96 -rw-r--r--  1 kali kali  96284 Mar 17 23:15 comment-template.php&#13;
 16 -rw-r--r--  1 kali kali  15006 Mar 17 23:15 compat.php&#13;
  4 drwxr-xr-x  2 kali kali   4096 Mar 17 23:15 customize&#13;
<var>--snip--</var>&#13;
 12 -rw-r--r--  1 kali kali  10707 Mar 17 23:15 customize.php&#13;
  4 -rw-r--r--  1 kali kali    705 Mar 17 23:15 <b>donate.php</b>&#13;
  4 -rw-r--r--  1 kali kali    355 Mar 17 23:15 <b>robots.txt</b>&#13;
<var>--snip--</var>&#13;
</code></pre>&#13;
<p class="TX">Notice some familiar filenames in this list? We saw <i>donate.php</i> and <i>robots.txt</i> earlier, when we scanned the 172.16.10.12 (<i>p-web-02</i>) host.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec7">&#13;
<h3 class="H2" id="sec7"><span id="h2-74"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Viewing Commits with git log</span></h3>&#13;
<p class="TNI1">When you run into a Git repository, you should attempt a <span class="SANS_TheSansMonoCd_W5Regular_11">git log</span> command to see the history of Git code commits made to the repository, as they may <span role="doc-pagebreak" epub:type="pagebreak" id="pg_103" aria-label="103"/>include interesting data we could use as attackers. In source code management, a <i>commit</i> is a snapshot of the code’s state that is taken before the code is pushed to the main repository and made permanent. Commit information could include details about who made the commit and a description of the change (such as whether it was a code addition or deletion):</p>&#13;
<pre><code>$ <b>cd acme-impact-alliance-git</b>&#13;
$ <b>git log</b>&#13;
&#13;
commit 3822fd7a063f3890e78051e56bd280f00cc4180c (HEAD -&gt; master)&#13;
Author: Kevin Peterson &lt;kpeterson@acme-impact-alliance.com&gt;&#13;
<var>--snip--</var>&#13;
&#13;
    commit code&#13;
</code></pre>&#13;
<p class="TX">We’ve identified a person who has committed code to the Git repository: Kevin Peterson, at <i>kpeterson@acme-impact-alliance.com</i>. Take note of this information because this account could exist in other places found during the penetration test.</p>&#13;
<p class="TX">Try running Gitjacker again to hijack the Git repository that lives on the second folder, at <i>/backup/acme-hyper-branding</i>. Then execute another <span class="SANS_TheSansMonoCd_W7Bold_B_11">git log</span> command to see who committed code to this repository, as we did before. The log should reveal the identity of a second person: Melissa Rogers, at <i>mrogers@acme-hyper-branding.com</i>.</p>&#13;
<p class="TX">You may sometimes run into Git repositories with many contributors and many commits. We can use Git’s built-in <span class="SANS_TheSansMonoCd_W5Regular_11">--pretty=format</span> option to easily extract all this metadata, like so:</p>&#13;
<pre><code>$ <b>git log --pretty=format:"%an %ae"</b></code></pre>&#13;
<p class="TX">The <span class="SANS_TheSansMonoCd_W5Regular_11">%ae</span> (author name) and <span class="SANS_TheSansMonoCd_W5Regular_11">%ae</span> (email) fields are built-in placeholders in Git that allow you to specify values of interest to include in the output. For the list of all available variables, see <i><a href="https://git-scm.com/docs/pretty-formats#_pretty_formats">https://git-scm.com/docs/pretty-formats#_pretty_formats</a></i>.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec8">&#13;
<h3 class="H2" id="sec8"><span id="h2-75"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Filtering git log Information</span></h3>&#13;
<p class="TNI1">Even without the pretty formatting, bash can filter <span class="SANS_TheSansMonoCd_W5Regular_11">git log</span> output with a single line:</p>&#13;
<pre><code>$ <b>git log | grep Author | grep -oP '(?&lt;=Author:).*' | sort -u | tr -d '&lt;&gt;'</b></code></pre>&#13;
<p class="TX">This bash code runs <span class="SANS_TheSansMonoCd_W5Regular_11">git log</span>, uses <span class="SANS_TheSansMonoCd_W5Regular_11">grep</span> to search for any lines that start with the word <span class="SANS_TheSansMonoCd_W5Regular_11">Author</span>, and then pipes the results to another <span class="SANS_TheSansMonoCd_W5Regular_11">grep</span> command, which uses regular expressions (<span class="SANS_TheSansMonoCd_W5Regular_11">-oP</span>) to filter anything after the word <span class="SANS_TheSansMonoCd_W5Regular_11">Author:</span> and print only the words that matched. This filtering leaves us with the Git commit author’s name and email.</p>&#13;
<p class="TX">Because the same author could have made multiple commits, we use <span class="SANS_TheSansMonoCd_W5Regular_11">sort</span> to sort the list and use the <span class="SANS_TheSansMonoCd_W5Regular_11">-u</span> option to remove any duplicated lines, <span role="doc-pagebreak" epub:type="pagebreak" id="pg_104" aria-label="104"/>leaving us with a list free of duplicated entries. Finally, since the email is surrounded by the characters <span class="SANS_TheSansMonoCd_W5Regular_11">&lt;&gt;</span> by default, we trim these characters by using <span class="SANS_TheSansMonoCd_W5Regular_11">tr -d '&lt;&gt;'</span>.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec9">&#13;
<h3 class="H2" id="sec9"><span id="h2-76"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Inspecting Repository Files</span></h3>&#13;
<p class="TNI1">The repository contains a file called <i>app.py</i>. Let’s inspect its contents by viewing it in a text editor. You should see that the file contains web server code written with Python’s Flask library:</p>&#13;
<pre><code>import os, subprocess&#13;
&#13;
from flask import (&#13;
    Flask,&#13;
    send_from_directory,&#13;
    send_file,&#13;
    render_template,&#13;
    request&#13;
)&#13;
&#13;
@app.route('<b>/</b>')&#13;
&#13;
<var>--snip--</var>&#13;
&#13;
@app.route('<b>/files/&lt;path:path&gt;</b>')&#13;
&#13;
<var>--snip--</var>&#13;
&#13;
@app.route('<b>/upload</b>', methods = ['GET', 'POST'])&#13;
&#13;
<var>--snip--</var>&#13;
&#13;
@app.route('<b>/uploads</b>', methods=['GET'])&#13;
&#13;
<var>--snip--</var>&#13;
&#13;
@app.route('<b>/uploads/&lt;path:file_name&gt;</b>', methods=['GET'])&#13;
&#13;
<var>--snip--</var>&#13;
</code></pre>&#13;
<p class="TX">The interesting parts here are the endpoints that are exposed via <span class="SANS_TheSansMonoCd_W5Regular_11">@app.route()</span>. You can see that the application exposes endpoints such as <i>/</i>, <i>/files</i>, <i>/upload</i>, and <i>/uploads</i>.</p>&#13;
<p class="TX">When we scanned the target IP address range with dirsearch and Nikto, we saw two endpoints, named <i>/upload</i> and <i>/uploads</i>, on <i>p-web-01</i> (172.16.10.10:8081). Because this Python file includes the same endpoints, this source code likely belongs to the application running on the server.</p>&#13;
<p class="TX">You may be asking yourself why we didn’t find the <i>/files</i> endpoint in our scans. Well, web scanners often rely on response status codes returned by <span role="doc-pagebreak" epub:type="pagebreak" id="pg_105" aria-label="105"/>web servers to determine whether certain endpoints exist. If you run the following <span class="SANS_TheSansMonoCd_W5Regular_11">curl</span> command with the <span class="SANS_TheSansMonoCd_W5Regular_11">-I</span> (HEAD request) option, you’ll see that the <i>/files</i> endpoint returns the HTTP status code 404 Not Found:</p>&#13;
<pre><code>$ <b>curl -I http://172.16.10.10:8081/files</b>&#13;
&#13;
HTTP/1.1 404 NOT FOUND&#13;
<var>--snip--</var>&#13;
</code></pre>&#13;
<p class="TX">Web scanners interpret these 404 errors as indicating that an endpoint doesn’t exist. Yet the reason we get 404 errors here is that, when called directly, <i>/files</i> doesn’t serve any requests. Instead, it serves requests for web paths appended to <i>/files</i>, such as <i>/files/abc.jpg</i> or <i>/files/salary.docx</i>.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec10">&#13;
<h2 class="H1" id="sec10"><span id="h1-37"/><span class="SANS_Futura_Std_Bold_B_11">Vulnerability Scanning with Nuclei</span></h2>&#13;
<p class="TNI1"><i>Nuclei</i> is one of the most impressive open source vulnerability scanners released in recent years. Its advantage over other tools stems from its community-powered templating system, which reduces false positives by matching known patterns against responses it receives from network services and files. It also reduces barriers to writing vulnerability checks, as it doesn’t require learning how to code. You can also easily extend it to do custom security checks.</p>&#13;
<p class="TX">Nuclei naturally supports common network services, such as HTTP, DNS, and network sockets, as well as local file scanning. You can use it to send HTTP requests, DNS queries, and raw bytes over the network. Nuclei can even scan files to find credentials (for example, when you’ve identified an open Git repository and want to pull it locally to find secrets).</p>&#13;
<p class="TX">As of this writing, Nuclei has more than 8,000 templates in its database. In this section, we’ll introduce Nuclei and how to use it.</p>&#13;
<section epub:type="division" aria-labelledby="sec11">&#13;
<h3 class="H2" id="sec11"><span id="h2-77"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Understanding Templates</span></h3>&#13;
<p class="TNI1">Nuclei templates are based on YAML files with the following high-level structure:</p>&#13;
<p class="RunInPara1"><b>ID </b>A unique identifier for the template</p>&#13;
<p class="RunInPara"><b>Metadata </b>Information about the template, such as a description, the author, the severity, and tags (arbitrary labels that can group multiple templates, such as <i>injection</i> or <i>denial of service</i>)</p>&#13;
<p class="RunInPara"><b>Protocol </b>The mechanism that the template uses to make its requests; for example, <span class="SANS_TheSansMonoCd_W5Regular_11">http</span> is a protocol type that uses HTTP for web requests</p>&#13;
<p class="RunInPara2"><b>Operators </b>Used for matching patterns against responses received by a template execution (<i>matchers</i>) and extracting data (<i>extractors</i>), similarly to the filtering performed by tools like <span class="SANS_TheSansMonoCd_W5Regular_11">grep</span></p>&#13;
<p class="TX">Here is a simple example of a Nuclei template that uses HTTP to find the default Apache HTML welcome page. Navigate to <i>http://172.16.10.11/</i> to see what this page looks like.</p>&#13;
<pre><code><span role="doc-pagebreak" epub:type="pagebreak" id="pg_106" aria-label="106"/>id: detect-apache-welcome-page&#13;
&#13;
<span class="codeannotated_CodeAnnotation" aria-label="annotation1">❶</span> info:&#13;
  name: Apache2 Ubuntu Default Page&#13;
  author: Dolev Farhi and Nick Aleks&#13;
  severity: info&#13;
  tags: apache&#13;
&#13;
http:&#13;
  - method: GET&#13;
    path:&#13;
    <span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> - '{{BaseURL}}'&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> matchers:&#13;
      - type: word&#13;
        words:&#13;
          - "Apache2 Ubuntu Default Page: It works"&#13;
        part: body&#13;
</code></pre>&#13;
<p class="TX">We define the template metadata, such as the template’s name, author, severity, and so on <span class="CodeAnnotation" aria-label="annotation1">❶</span>. We then instruct Nuclei to use an HTTP client when executing this template <span class="CodeAnnotation" aria-label="annotation2">❷</span>. We also declare that the template should use the GET method. Next, we define a variable that will be swapped with the target URL we’ll provide to Nuclei on the command line at scan time. Then, we define a single matcher of type <span class="SANS_TheSansMonoCd_W5Regular_11">word</span> <span class="CodeAnnotation" aria-label="annotation3">❸</span> and a search pattern to match against the HTTP response body coming back from the server, defined by <span class="SANS_TheSansMonoCd_W5Regular_11">part: body</span>.</p>&#13;
<p class="TX">As a result, when Nuclei performs a scan against an IP address that runs some form of a web server, this template will make a GET request to its base URL (<span class="SANS_TheSansMonoCd_W5Regular_11">/</span>) and look for the string <span class="SANS_TheSansMonoCd_W5Regular_11">Apache2 ubuntu Default Page: It works</span> in the response. If it finds this string in the response’s body, the check will be considered successful because the pattern matched.</p>&#13;
<p class="TX">We encourage you to explore Nuclei’s templating system at <i><a href="https://docs.projectdiscovery.io/introduction">https://docs.projectdiscovery.io/introduction</a></i>, as you can easily use Nuclei with bash to perform continuous assessments.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec12">&#13;
<h3 class="H2" id="sec12"><span id="h2-78"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Writing a Custom Template</span></h3>&#13;
<p class="TNI1">Let’s write a simple template that finds the Git repositories we discovered earlier, on <i>p-ftp-01</i> (172.16.10.11). We’ll define multiple <span class="SANS_TheSansMonoCd_W5Regular_11">BaseURL</span> paths to represent the two paths we’ve identified. Then, using Nuclei’s matchers, we’ll define a string <span class="SANS_TheSansMonoCd_W5Regular_11">ref: refs/heads/master</span> to match the response body returned by the scanned server:</p>&#13;
<p class="CodeLabel"><span class="codelabel_Italic">git-finder.yaml</span></p>&#13;
<pre class="pre"><code>id: detect-git-repository&#13;
&#13;
info:&#13;
  name: Git Repository Finder&#13;
  author: Dolev Farhi and Nick Aleks&#13;
  severity: info&#13;
  tags: git&#13;
&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_107" aria-label="107"/>http:&#13;
  - method: GET&#13;
    path:&#13;
      - '{{BaseURL}}/backup/acme-hyper-branding/.git/HEAD'&#13;
      - '{{BaseURL}}/backup/acme-impact-alliance/.git/HEAD'&#13;
    matchers:&#13;
      - type: word&#13;
        words:&#13;
          - "ref: refs/heads/master"&#13;
        part: body&#13;
</code></pre>&#13;
<p class="TX">This template works just like the one in the previous example, except this time we provide two paths to check against: <i>/backup/acme-hyper-branding/.git/HEAD</i> and <i>/backup/acme-impact-alliance/.git/HEAD</i>. The matcher defines the string we expect to see in the <i>HEAD</i> file. You can confirm the match by making a <span class="SANS_TheSansMonoCd_W5Regular_11">curl</span> request to the Git repository at 172.16.10.11:</p>&#13;
<pre><code>$ <b>curl http://172.16.10.11/backup/acme-hyper-branding/.git/HEAD</b>&#13;
&#13;
ref: refs/heads/master&#13;
</code></pre>&#13;
<p class="TX">Download this custom Nuclei template from the book’s GitHub repository.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec13">&#13;
<h3 class="H2" id="sec13"><span id="h2-79"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Applying the Template</span></h3>&#13;
<p class="TNI1">Let’s run Nuclei against <i>p-ftp-01</i> (172.16.10.11) with the custom template we just wrote. Nuclei stores its built-in templates in the folder <i>~/.local/nuclei-templates</i>. First, run the following command to update Nuclei’s template database:</p>&#13;
<pre><code>$ <b>nuclei -ut</b></code></pre>&#13;
<p class="TX">Next, save the custom template into the folder <i>~/.local/nuclei-templates/custom</i> and give it a name such as <i>git-finder.yaml</i>.</p>&#13;
<p class="TX">In the following command, the <span class="SANS_TheSansMonoCd_W5Regular_11">-u</span> (URL) option specifies the address, and <span class="SANS_TheSansMonoCd_W5Regular_11">-t</span> (template) specifies the path to the template:</p>&#13;
<pre><code>$ <b>nuclei -u 172.16.10.11 -t ~/.local/nuclei-templates/custom/git-finder.yaml</b>&#13;
&#13;
<var>--snip--</var>&#13;
[INF] Targets loaded for scan: 1&#13;
[INF] Running httpx on input host&#13;
[INF] Found 1 URL from httpx&#13;
[detect-git-repository] [http] [info] http://172.16.10.11/backup/acme-hyper-branding/.git/HEAD&#13;
[detect-git-repository] [http] [info] http://172.16.10.11/backup/acme-impact-alliance/.git/HEAD&#13;
</code></pre>&#13;
<p class="TX">As you can see, we were able to identify the two Git repositories with the custom template.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec14">&#13;
<h3 class="H2" id="sec14"><span id="h2-80"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Running a Full Scan</span></h3>&#13;
<p class="TNI1">When not provided with a specific template, Nuclei will use its built-in templates during the scan. Running Nuclei is noisy, so we recommend tailoring <span role="doc-pagebreak" epub:type="pagebreak" id="pg_108" aria-label="108"/>the execution to a specific target. For instance, if you know a server is running Apache, you could select just the Apache-related templates by specifying the <span class="SANS_TheSansMonoCd_W5Regular_11">-tags</span> option:</p>&#13;
<pre><code>$ <b>nuclei -tags apache,git -u 172.16.10.11</b></code></pre>&#13;
<p class="TX">Run <span class="SANS_TheSansMonoCd_W7Bold_B_11">nuclei -tl</span> to get a list of all available templates.</p>&#13;
<p class="TX">Let’s run a full Nuclei scan against the three IP addresses in the 172.16.10.0/24 network by using all its built-in templates:</p>&#13;
<pre><code>$ <b>nuclei -u 172.16.10.10:8081</b>&#13;
$ <b>nuclei -u 172.16.10.11</b>&#13;
$ <b>nuclei -u 172.16.10.12</b>&#13;
&#13;
<var>--snip--</var>&#13;
[tech-detect:google-font-api] [http] [info] http://172.16.10.10:8081&#13;
[tech-detect:python] [http] [info] http://172.16.10.10:8081&#13;
[http-missing-security-headers:access-control-allow-origin] [http] [info]&#13;
http://172.16.10.10:8081&#13;
[http-missing-security-headers:content-security-policy] [http] [info]&#13;
http://172.16.10.10:8081&#13;
<var>--snip--</var>&#13;
</code></pre>&#13;
<p class="TX">Nuclei tries to optimize the number of total requests made by using <i>clustering</i>. When multiple templates call the same web path (such as <i>/backup</i>), Nuclei consolidates these into a single request to reduce network overhead. However, Nuclei could still send thousands of requests during a single scan. You can control the number of requests sent by specifying the rate limit option (<span class="SANS_TheSansMonoCd_W5Regular_11">-rl</span>), followed by an integer indicating the number of allowed requests per second.</p>&#13;
<p class="TX">The full scan results in a lot of findings, so append the output to a file (using <span class="SANS_TheSansMonoCd_W5Regular_11">&gt;&gt;</span>) so that you can examine them one by one. As you’ll see, Nuclei can identify vulnerabilities, but it can also fingerprint the target server and the technologies running on it. Nuclei should have highlighted findings seen previously, as well as a few new ones. Here are some of the issues it detected:</p>&#13;
<ul class="ul">&#13;
<li class="ListBullet">An FTP server with anonymous access enabled on 172.16.10.11 port 21</li>&#13;
<li class="ListBullet">A WordPress login page at <i>172.16.10.12/wp-login.php</i></li>&#13;
<li class="ListBullet">A WordPress user-enumeration vulnerability (CVE-2017-5487) at <i><a href="http://172.16.10.12/?rest_route=/wp/v2/users/">http://172.16.10.12/?rest_route=/wp/v2/users/</a></i></li>&#13;
</ul>&#13;
<p class="TX">Let’s manually confirm these three findings to ensure there are no false positives. Connect to the identified FTP server at 172.16.10.11 by issuing the following <span class="SANS_TheSansMonoCd_W5Regular_11">ftp</span> command. This command will connect to the server by using the <i>anonymous</i> user and an empty password:</p>&#13;
<pre><code>$ <b>ftp ftp://anonymous:@172.16.10.11</b>&#13;
&#13;
Connected to 172.16.10.11.&#13;
220 (vsFTPd 3.0.5)&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_109" aria-label="109"/>331 Please specify the password.&#13;
230 Login successful.&#13;
Remote system type is UNIX.&#13;
Using binary mode to transfer files.&#13;
200 Switching to Binary mode.&#13;
</code></pre>&#13;
<p class="TX">We were able to connect! Let’s issue an <span class="SANS_TheSansMonoCd_W5Regular_11">ls</span> command to verify that we can list files and directories on the server:</p>&#13;
<pre><code>ftp&gt; <b>ls</b>&#13;
229 Entering Extended Passive Mode (|||33817|)&#13;
150 Here comes the directory listing.&#13;
drwxr-xr-x    1 0        0            4096 Mar 11 05:23 backup&#13;
-rw-r--r--    1 0        0           10671 Mar 11 05:22 index.html&#13;
226 Directory send OK.&#13;
</code></pre>&#13;
<p class="TX">We see an <i>index.html</i> file and a <i>backup</i> folder. This is the same folder that stores the two Git repositories we saw earlier, except now we have access to the FTP server where these files actually live.</p>&#13;
<p class="TX">Next, open a browser to <i>http://172.16.10.12/wp-login.php</i> from your Kali machine. You should see the page in <a href="chapter5.xhtml#fig5-2">Figure 5-2</a>.</p>&#13;
<figure class="IMG"><img id="fig5-2" class="img1" src="../images/pg109.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><span class="SANS_Futura_Std_Book_Oblique_I_11">Figure 5-2: The WordPress login page</span></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_110" aria-label="110"/>Finally, verify the third finding: the WordPress user-enumeration vulnerability, which allows you to gather information about WordPress accounts. By default, every WordPress instance exposes an API endpoint that lists WordPress system users. The endpoint usually doesn’t require authentication or authorization, so a simple GET request should return the list of users.</p>&#13;
<p class="TX">We’ll use <span class="SANS_TheSansMonoCd_W5Regular_11">curl</span> to send this request and then pipe the response to jq to prettify the JSON output that comes back. The result should be an array of user data:</p>&#13;
<pre><code>$ <b>curl -s http://172.16.10.12/?rest_route=/wp/v2/users | jq</b>&#13;
&#13;
[&#13;
  {&#13;
    "id": 1,&#13;
    "name": "jtorres",&#13;
    "url": "http://172.16.10.12",&#13;
    "description": "",&#13;
    "link": "http://172.16.10.12/author/jtorres/",&#13;
    "slug": "jtorres",&#13;
  },&#13;
<var>--snip--</var>&#13;
]&#13;
</code></pre>&#13;
<p class="TX">The blog has a single user, <i>jtorres</i>. This can be a good target to brute-force later. If this <span class="SANS_TheSansMonoCd_W5Regular_11">curl</span> command had returned many users, you could have parsed only the usernames with jq (<a href="chapter5.xhtml#Lis5-3">Listing 5-3</a>).</p>&#13;
<span id="Lis5-3"/><pre><code>$ <b>curl -s http://172.16.10.12/?rest_route=/wp/v2/users/ | jq .[].name</b></code></pre>&#13;
<p class="ListingCaption"><span class="Futura_Std_Book_Oblique_I">Listing 5-3: Extracting usernames from an HTTP response</span></p>&#13;
<p class="TX">All three findings were true positives, which is great news for us. <a href="chapter5.xhtml#tab5-1">Table 5-1</a> recaps the users we’ve identified so far.</p>&#13;
<p class="TT" id="tab5-1"><span class="Heavy"><span class="SANS_Futura_Std_Heavy_B_11">Table 5-1:</span></span> <span class="SANS_Futura_Std_Book_11">Identity Information Gathered from Repositories and WordPress</span></p>&#13;
<table class="Basic-Table">&#13;
<thead>&#13;
<tr>&#13;
<th class="TCH" scope="col"><p class="TCH1"><span class="SANS_Futura_Std_Heavy_B_11">Source</span></p></th>&#13;
<th class="TCH" scope="col"><p class="TCH1"><span class="SANS_Futura_Std_Heavy_B_11">Name</span></p></th>&#13;
<th class="TCH" scope="col"><p class="TCH1"><span class="SANS_Futura_Std_Heavy_B_11">Email</span></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td class="TBF"><p class="TB1"><span class="SANS_Futura_Std_Book_Oblique_I_11">acme-impact-alliance</span> <span class="SANS_Futura_Std_Book_11">Git repository</span></p></td>&#13;
<td class="TBF"><p class="TB1"><span class="SANS_Futura_Std_Book_11">Kevin Peterson</span></p></td>&#13;
<td class="TBF"><p class="TB1"><span class="SANS_Futura_Std_Book_Oblique_I_11">kpeterson@acme-impact-alliance.com</span></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="TB"><p class="TB1"><span class="SANS_Futura_Std_Book_Oblique_I_11">acme-hyper-branding</span> <span class="SANS_Futura_Std_Book_11">Git repository</span></p></td>&#13;
<td class="TB"><p class="TB1"><span class="SANS_Futura_Std_Book_11">Melissa Rogers</span></p></td>&#13;
<td class="TB"><p class="TB1"><span class="SANS_Futura_Std_Book_Oblique_I_11">mrogers@acme-hyper-branding.com</span></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="TBL"><p class="TB1"><span class="SANS_Futura_Std_Book_11">WordPress account</span></p></td>&#13;
<td class="TBL"><p class="TB1"><span class="SANS_Futura_Std_Book_11">J. Torres</span></p></td>&#13;
<td class="TBL"><p class="TB1"><span class="SANS_Futura_Std_Book_Oblique_I_11">jtorres@acme-impact-alliance.com</span></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="TX">Because the <i>jtorres</i> account was found on the ACME Impact Alliance website and we already know the email scheme the website uses, it’s pretty safe to assume that the <i>jtorres</i> email is <i>jtorres@acme-impact-alliance.com</i>.</p>&#13;
<p class="HeadAExercise"><span id="exe-6"/><span role="doc-pagebreak" epub:type="pagebreak" id="pg_111" aria-label="111"/><span class="SANS_Futura_Std_Heavy_B_15">Exercise 6: Parsing Nuclei’s Findings</span></p>&#13;
<p class="TNI1">Nuclei’s scan output is a little noisy and can be difficult to parse with bash, but not impossible. Nuclei allows you to pass a <span class="SANS_TheSansMonoCd_W5Regular_11">-silent</span> parameter to show only the findings in the output. Before you write a script to parse it, consider Nuclei’s output format:</p>&#13;
<div class="spc">&#13;
<p class="ListPlain-c"><span class="SANS_TheSansMonoCd_W5Regular_11">[</span><span class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">template</span><span class="SANS_TheSansMonoCd_W5Regular_11">] [</span><span class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">protocol</span><span class="SANS_TheSansMonoCd_W5Regular_11">] [</span><span class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">severity</span><span class="SANS_TheSansMonoCd_W5Regular_11">]</span> <span class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">url</span> <span class="SANS_TheSansMonoCd_W5Regular_11">[</span><span class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">extractor</span><span class="SANS_TheSansMonoCd_W5Regular_11">]</span></p>&#13;
</div>&#13;
<p class="TX">Each field is enclosed in square brackets <span class="SANS_TheSansMonoCd_W5Regular_11">[]</span> and separated by spaces. The <span class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">template</span> field is a template name (taken from the name of the template file); the <span class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">protocol</span> shows the protocol, such as HTTP; and the <span class="SANS_TheSansMonoCd_W5Regular_Italic_I_11">severity</span> shows the severity of the finding (informational, low, medium, high, or critical). The fourth field is the URL or IP address, and the fifth field is metadata extracted by the template’s logic using extractors.</p>&#13;
<p class="TX">Now you should be able to parse this information with bash. <a href="chapter5.xhtml#Lis5-4">Listing 5-4</a> shows an example script that runs Nuclei, filters for a specific severity of interest, parses the interesting parts, and emails you the results.</p>&#13;
<span id="Lis5-4"/>&#13;
<p class="CodeLabel"><span class="codelabel_Italic">nuclei-notifier.sh</span></p>&#13;
<pre class="pre"><code>#!/bin/bash&#13;
EMAIL_TO="security@blackhatbash.com"&#13;
EMAIL_FROM="nuclei-automation@blackhatbash.com"&#13;
&#13;
for ip_address in "$@"; do&#13;
  echo "Testing ${ip_address} with Nuclei..."&#13;
<span class="Code_CodeAnnotation" aria-label="annotation1">❶</span> result=$(nuclei -u "${ip_address}" -silent -severity medium,high,critical)&#13;
  if [[-n "${result}"]]; then&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation2">❷</span> while read -r line; do&#13;
      template=$(echo "${line}" | awk '{print $1}' | tr -d '[]')&#13;
      url=$(echo "${line}" | awk '{print $4}')&#13;
      echo "Sending an email with the findings ${template} ${url}"&#13;
      sendemail -f "${EMAIL_FROM}" \&#13;
              <span class="Code_CodeAnnotation" aria-label="annotation3">❸</span> -t "${EMAIL_TO}" \&#13;
                -u "[Nuclei] Vulnerability Found!" \&#13;
                -m "${template} - ${url}"&#13;
&#13;
  <span class="Code_CodeAnnotation" aria-label="annotation4">❹</span> done &lt;&lt;&lt; "${result}"&#13;
  fi&#13;
done&#13;
</code></pre>&#13;
<p class="ListingCaption"><span class="Futura_Std_Book_Oblique_I">Listing 5-4: Scanning with Nuclei and sending yourself the results</span></p>&#13;
<p class="TX">Let’s dissect the code to better understand what it’s doing. We use a <span class="SANS_TheSansMonoCd_W5Regular_11">for</span> loop to iterate through values in the <span class="SANS_TheSansMonoCd_W5Regular_11">$@</span> variable, a special value you learned about in <span class="Xref"><a href="chapter1.xhtml">Chapter 1</a></span> that contains the arguments passed to the script on the command line. We assign each argument to the <span class="SANS_TheSansMonoCd_W5Regular_11">ip_address</span> variable.</p>&#13;
<p class="TX">Next, we run a Nuclei scan, passing it the <span class="SANS_TheSansMonoCd_W5Regular_11">-severity</span> argument to scan for vulnerabilities categorized as either medium, high, or critical, and save the output to the <span class="SANS_TheSansMonoCd_W5Regular_11">result</span> variable <span class="CodeAnnotation" aria-label="annotation1">❶</span>. At <span class="CodeAnnotation" aria-label="annotation2">❷</span>, we read the output passed to the <span class="SANS_TheSansMonoCd_W5Regular_11">while</span> loop at <span class="CodeAnnotation" aria-label="annotation4">❹</span> line by line. From each line, we extract the first field, using the <span class="SANS_TheSansMonoCd_W5Regular_11">tr -d '[]'</span> command to remove the <span class="SANS_TheSansMonoCd_W5Regular_11">[]</span> characters for a cleaner output. We also extract the fourth field from each line, which is where Nuclei <span role="doc-pagebreak" epub:type="pagebreak" id="pg_112" aria-label="112"/>stores the vulnerable URL. At <span class="CodeAnnotation" aria-label="annotation3">❸</span>, we send an email containing the relevant information.</p>&#13;
<p class="TX">To run this script, save it to a file and pass the IP addresses to scan on the command line:</p>&#13;
<pre><code>$ <b>nuclei-notifier.sh 172.16.10.10:8081 172.16.10.11 172.16.10.12 172.16.10.13</b></code></pre>&#13;
<p class="TX">To make this script your own, try having Nuclei output JSON data by using the <span class="SANS_TheSansMonoCd_W5Regular_11">-j</span> option. Then pipe this output to jq, as shown in <span class="Xref"><a href="chapter4.xhtml">Chapter 4</a></span>.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec15">&#13;
<h2 class="H1" id="sec15"><span id="h1-38"/><span class="SANS_Futura_Std_Bold_B_11">Fuzzing for Hidden Files</span></h2>&#13;
<p class="TNI1">Now that we’ve identified the potential location of files, let’s use fuzzing tools to find hidden files on <i>p-web-01</i> (<i>http://172.16.10.10:8081/files</i>). <i>Fuzzers</i> generate semi-random data to use as part of a payload. When sent to an application, these payloads can trigger anomalous behavior or reveal covert information. You can use fuzzers against web servers to find hidden paths or against local binaries to find vulnerabilities such as buffer overflows or DoS.</p>&#13;
<section epub:type="division" aria-labelledby="sec16">&#13;
<h3 class="H2" id="sec16"><span id="h2-81"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Creating a Wordlist of Possible Filenames</span></h3>&#13;
<p class="TNI1">Fuzzing tools in the context of web application enumeration work best when fed custom wordlists tailored to your target. These lists could contain the name of the company, the individuals you’ve identified, relevant locations, and so on. These tailored wordlists can help you identify user accounts to attack, network and application services, valid domain names, covert files, email addresses, and web paths, for example.</p>&#13;
<p class="TX">Let’s use bash to write a custom wordlist containing potential filenames of interest (<a href="chapter5.xhtml#Lis5-5">Listing 5-5</a>).</p>&#13;
<span id="Lis5-5"/><pre><code>$ <b>echo -e acme-hyper-branding-{0..100}.{txt,csv,pdf,jpg}"\n" | sed 's/ //g' &gt;</b> <b>files_wordlist.txt</b></code></pre>&#13;
<p class="ListingCaption"><span class="Futura_Std_Book_Oblique_I">Listing 5-5: Using brace expansion to create multiple files with various extensions</span></p>&#13;
<p class="TX">This command creates files with probable file extensions tailored to our target’s name, ACME Hyper Branding. It uses <span class="SANS_TheSansMonoCd_W5Regular_11">echo</span> with brace expansion <span class="SANS_TheSansMonoCd_W5Regular_11">{0..100}</span> to create arbitrary strings ranging from 0 to 100 and then appends these to the company name. We also use brace expansion to create multiple file extension types, such as <i>.txt</i>, <i>.csv</i>, <i>.pdf</i>, and <i>.jpg</i>. The <span class="SANS_TheSansMonoCd_W5Regular_11">-e</span> option, for <span class="SANS_TheSansMonoCd_W5Regular_11">echo</span>, enables us to interpret backslash (<span class="SANS_TheSansMonoCd_W5Regular_11">\</span>) escapes. This means that <span class="SANS_TheSansMonoCd_W5Regular_11">\n</span> will be interpreted as a newline. We then pipe this output to the <span class="SANS_TheSansMonoCd_W5Regular_11">sed</span> command to remove all whitespace from the output for a cleaner list.</p>&#13;
<p class="TX">Use <span class="SANS_TheSansMonoCd_W5Regular_11">head</span> to view the created files:</p>&#13;
<pre><code>$ <b>head files_wordlist.txt</b>&#13;
&#13;
acme-hyper-branding-0.txt&#13;
acme-hyper-branding-0.csv&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_113" aria-label="113"/>acme-hyper-branding-0.pdf&#13;
acme-hyper-branding-0.jpg&#13;
acme-hyper-branding-1.txt&#13;
acme-hyper-branding-1.csv&#13;
acme-hyper-branding-1.pdf&#13;
acme-hyper-branding-1.jpg&#13;
acme-hyper-branding-2.txt&#13;
acme-hyper-branding-2.csv&#13;
</code></pre>&#13;
<p class="TX">As you can see, this command’s output follows the format <i>acme-hyper-branding-&lt;some_number&gt;.&lt;some_extension&gt;</i>.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec17">&#13;
<h3 class="H2" id="sec17"><span id="h2-82"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Fuzzing with ffuf</span></h3>&#13;
<p class="TNI1"><i>ffuf</i> (an acronym for <i>Fuzz Faster U Fool</i>) is a versatile and blazing-fast web fuzzing tool. We’ll use ffuf to discover potential files under the <i>/files</i> endpoint that could contain interesting data.</p>&#13;
<p class="TX">The following <span class="SANS_TheSansMonoCd_W5Regular_11">ffuf</span> command uses the <span class="SANS_TheSansMonoCd_W5Regular_11">-c</span> (color) option to highlight the results in the terminal, the <span class="SANS_TheSansMonoCd_W5Regular_11">-w</span> (wordlist) option to specify a custom wordlist, the <span class="SANS_TheSansMonoCd_W5Regular_11">-u</span> (URL) option to specify a path, and the full URL to the endpoint to fuzz. We run ffuf against <i>p-web-01</i> (172.16.10.10):</p>&#13;
<pre><code>$ <b>ffuf -c -w files_wordlist.txt -u http://172.16.10.10:8081/files/FUZZ</b>&#13;
&#13;
:: Method           : GET&#13;
:: URL              : http://172.16.10.10:8081/files/FUZZ&#13;
:: Wordlist         : FUZZ: files_wordlist.txt&#13;
:: Follow redirects : false&#13;
:: Calibration      : false&#13;
:: Timeout          : 10&#13;
:: Threads          : 40&#13;
:: Matcher          : Response status: 200,204,301,302,307,401,403,405,500&#13;
<span aria-hidden="true">_______________________________________________</span>_&#13;
&#13;
acme-hyper-branding-5.csv [Status: 200, Size: 432, Words: 31, Lines: 9, Duration: 32ms]&#13;
:: Progress: [405/405] :: Job [1/1] :: 0 req/sec :: Duration: [0:00:00] :: Errors: 0 ::&#13;
</code></pre>&#13;
<p class="TX">Note that the word <span class="SANS_TheSansMonoCd_W5Regular_11">FUZZ</span> at the end of the URL is a placeholder that tells the tool where to inject the words from the wordlist. In essence, it will swap the word <span class="SANS_TheSansMonoCd_W5Regular_11">FUZZ</span> with each line from our file.</p>&#13;
<p class="TX">According to the output, ffuf identified that the path <i>http://172.16.10.10:8081/files/acme-hyper-branding-5.csv</i> returned a status code of HTTP 200 OK. If you look closely at the output, you should see that the fuzzer sent 405 requests in less than a second, which is pretty impressive.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec18">&#13;
<h3 class="H2" id="sec18"><span id="h2-83"/><span class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Fuzzing with Wfuzz</span></h3>&#13;
<p class="TNI1"><i>Wfuzz</i> is another web fuzzing tool similar to ffuf. In fact, ffuf is based on Wfuzz. Let’s use Wfuzz to perform the same type of wordlist-based scan <span role="doc-pagebreak" epub:type="pagebreak" id="pg_114" aria-label="114"/>(<span class="SANS_TheSansMonoCd_W5Regular_11">-w</span>) and then use its filtering capabilities to show only files that receive a response status code of 200 OK (<span class="SANS_TheSansMonoCd_W5Regular_11">--sc 200</span>):</p>&#13;
<pre><code>$ <b>wfuzz --sc 200 -w files_wordlist.txt http://172.16.10.10:8081/files/FUZZ</b>&#13;
&#13;
<var>--snip--</var>&#13;
Target: http://172.16.10.10:8081/files/FUZZ&#13;
Total requests: 405&#13;
&#13;
=====================================================================&#13;
ID         Response   Lines    Word       Chars       Payload&#13;
=====================================================================&#13;
&#13;
000000022: 200        8 L      37 W       432 Ch      "acme-hyper-branding-5.csv"&#13;
&#13;
Total time: 0&#13;
Processed Requests: 405&#13;
Filtered Requests: 404&#13;
Requests/sec.: 0&#13;
</code></pre>&#13;
<p class="TX">Next, let’s use the <span class="SANS_TheSansMonoCd_W5Regular_11">wget</span> command to download the identified file:</p>&#13;
<pre><code>$ <b>wget http://172.16.10.10:8081/files/acme-hyper-branding-5.csv</b>&#13;
$ <b>cat acme-hyper-branding-5.csv</b>&#13;
&#13;
no, first_name, last_name, designation, email&#13;
1, Jacob, Taylor, Founder, jtayoler@acme-hyper-branding.com&#13;
2, Sarah, Lewis, Executive Assistance, slewis@acme-hyper-branding.com&#13;
3, Nicholas, Young, Influencer, nyoung@acme-hyper-branding.com&#13;
4, Lauren, Scott, Influencer, lscott@acme-hyper-branding.com&#13;
5, Aaron,Peres, Marketing Lead, aperes@acme-hyper-branding.com&#13;
6, Melissa, Rogers, Marketing Lead, mrogers@acme-hyper-branding.com&#13;
</code></pre>&#13;
<p class="TX">We’ve located a table of PII, including first and last names, titles, and email addresses. Take notes of every detail we’ve managed to extract in this chapter; you never know when it will come in handy.</p>&#13;
<p class="TX">Note that fuzzers can cause unintentional DoS conditions, especially if they’re optimized for speed. You may encounter applications running on low-powered servers that will crash if you run a highly capable fuzzer against them, so make sure you have explicit permission from the company you’re working with to perform such activities.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec19">&#13;
<h2 class="H1" id="sec19"><span id="h1-39"/><span class="SANS_Futura_Std_Bold_B_11">Assessing SSH Servers with Nmap’s Scripting Engine</span></h2>&#13;
<p class="TNI1">Nmap contains many NSE scripts to test for vulnerabilities and misconfigurations. All Nmap scripts live in the <i>/usr/share/nmap/scripts</i> path. When you run Nmap with the <span class="SANS_TheSansMonoCd_W5Regular_11">-A</span> flag, it will blast all NSE scripts at the target, as well as enable operating system detection, version detection, script scanning, and traceroute. This is probably the noisiest scan you can do with Nmap, so never use it when you need to be covert.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_115" aria-label="115"/>In <span class="Xref"><a href="chapter4.xhtml">Chapter 4</a></span>, we identified a server running OpenSSH on <i>p-jumpbox-01</i> (172.16.10.13). Let’s use an NSE script tailored to SSH servers to see what we can discover about the supported authentication methods:</p>&#13;
<pre><code>$ <b>nmap --script=ssh-auth-methods 172.16.10.13</b>&#13;
&#13;
Starting Nmap (https://nmap.org) at 03-19 01:53 EDT&#13;
<var>--snip--</var>&#13;
PORT   STATE SERVICE&#13;
22/tcp open  ssh&#13;
| ssh-auth-methods:&#13;
|   Supported authentication methods:&#13;
|     publickey&#13;
|_    password&#13;
&#13;
Nmap done: 1 IP address (1 host up) scanned in 0.26 seconds&#13;
</code></pre>&#13;
<p class="TX">The <i>ssh-auth-methods</i> NSE script enumerates the authentication methods offered by the SSH server. If <i>password</i> is one of them, this means that the server accepts passwords as an authentication mechanism. SSH servers that allow password authentication are prone to brute-force attacks. In <span class="Xref"><a href="chapter7.xhtml">Chapter 7</a></span>, we’ll perform a brute-force attack against SSH servers.</p>&#13;
<p class="HeadAExercise"><span id="exe-7"/><span class="SANS_Futura_Std_Heavy_B_15">Exercise 7: Combining Tools to Find FTP Issues</span></p>&#13;
<p class="TNI1">The goal of this exercise is to write a script that calls several security tools, parses their output, and passes the output to other tools to act on it. Orchestrating multiple tools in this way is a common task in penetration testing, so we encourage you to get comfortable with building such workflows.</p>&#13;
<p class="TX">Your script should do the following:</p>&#13;
<p class="NLF">  1.  Accept one or more IP addresses on the command line.</p>&#13;
<p class="NL">  2.  Run a port scanner against the IP addresses; which port scanner you use is completely up to you.</p>&#13;
<p class="NL">  3.  Identify open ports. If any of them are FTP ports (21/TCP), the script should pass the address to the vulnerability scanner in step 4.</p>&#13;
<p class="NL">  4.  Use Nuclei to scan the IP addresses and ports. Try applying templates dedicated to finding issues in FTP servers. Search the Nuclei templates folder <i>/home/kali/.local/nuclei-templates</i> for FTP-related templates, or use the <span class="SANS_TheSansMonoCd_W5Regular_11">-tags ftp</span> Nuclei flag.</p>&#13;
<p class="NL">  5.  Scan the IP addresses with Nmap. Use NSE scripts that find vulnerabilities in FTP servers, which you can search for in the <i>/usr/share/nmap/scripts</i> folder. For example, try <i>ftp-anon.nse</i>.</p>&#13;
<p class="NLL">  6.  Parse and write the results to a file, in a format of your choice. The file should include a description of the vulnerability, the relevant IP address and port, the timestamp at which it was found, and the name of the tool that detected the issue. There is no hard requirement about <span role="doc-pagebreak" epub:type="pagebreak" id="pg_116" aria-label="116"/>how to present the data; one option is to use an HTML table. If you need an example table, download <i>vulnerability_table.html</i> from the book’s GitHub repository and open it in a browser. Alternatively, you could write the results to a CSV file.</p>&#13;
<p class="TX">As you should know by now, there is more than one way to write such a script. Only the end result matters, so craft the script as you see fit.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec20">&#13;
<h2 class="H1" id="sec20"><span id="h1-40"/><span class="SANS_Futura_Std_Bold_B_11">Summary</span></h2>&#13;
<p class="TNI1">In this chapter, we wrapped up reconnaissance activities by performing vulnerability scanning and fuzzing. We also verified the vulnerabilities we discovered, weeding out potential false positives.</p>&#13;
<p class="TX">Along the way, we used bash scripting to perform several tasks. We scanned for vulnerabilities, wrote custom scripts that can perform recursive downloads from misconfigured web servers, extracted sensitive information from Git repositories, and more. We also created custom wordlists using clever bash scripting and orchestrated the execution of multiple security tools to generate a report.</p>&#13;
<p class="TX">Let’s recap what we’ve identified so far, from a reconnaissance perspective:</p>&#13;
<ul class="ul">&#13;
<li class="ListBullet">Hosts running multiple services (HTTP, FTP, and SSH) and their versions</li>&#13;
<li class="ListBullet">A web server running WordPress with a login page enabled and a few vulnerabilities, such as user enumeration and an absence of HTTP security headers</li>&#13;
<li class="ListBullet">A web server with a revealing <i>robots.txt</i> file containing paths to custom upload forms and a donation page</li>&#13;
<li class="ListBullet">An anonymous, login-enabled FTP server</li>&#13;
<li class="ListBullet">Multiple open Git repositories</li>&#13;
<li class="ListBullet">OpenSSH servers that allow password-based logins</li>&#13;
</ul>&#13;
<p class="TX">In the next chapter, we’ll use the information identified in this chapter to establish an initial foothold by exploiting vulnerabilities and taking over servers.</p>&#13;
</section>&#13;
</section>&#13;
</body></html>