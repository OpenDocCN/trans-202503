- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Neural Networks
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络
- en: '![](Images/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/chapterart.png)'
- en: Deep learning algorithms are based on building a network of connected computational
    elements. The fundamental unit of such networks is a small bundle of computation
    called an *artificial neuron*, though it’s often referred to simply as a *neuron*.
    The artificial neuron was inspired by human neurons, which are the nerve cells
    that make up our brain and central nervous system and are largely responsible
    for our cognitive abilities.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法基于建立一个连接的计算单元网络。这些网络的基本单元是一个小型计算捆绑体，称为*人工神经元*，尽管它通常简称为*神经元*。人工神经元的灵感来自于人类神经元，神经元是构成我们大脑和中枢神经系统的神经细胞，主要负责我们的认知能力。
- en: In this chapter, we see what artificial neurons look like and how to arrange
    them into networks. We then group them into layers, which create deep learning
    networks. We also look at various ways to configure the outputs of these artificial
    neurons so that they produce the most useful results.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将展示人工神经元的样子，并讨论如何将它们安排成网络。接着，我们将它们分组为层，从而形成深度学习网络。我们还会探讨如何配置这些人工神经元的输出，以便它们产生最有用的结果。
- en: Real Neurons
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 真实神经元
- en: In biology, the term *neuron* is applied to a wide variety of complex cells
    distributed throughout every human body. These cells all have similar structure
    and behavior, but they’re specialized for many different tasks. Neurons are sophisticated
    pieces of biology that use a mix of chemistry, physics, electricity, timing, proximity,
    and other means to perform their behaviors and communicate with one another (Julien
    2011; Khanna 2018; Lodish et al. 2000; Purves et al. 2001). A highly simplified
    sketch of a neuron is shown in [Figure 13-1](#figure13-1).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物学中，*神经元*一词适用于分布在人类身体各处的多种复杂细胞。这些细胞都具有相似的结构和行为，但它们被专门化以执行许多不同的任务。神经元是复杂的生物体，利用化学、物理、电学、时间、接近性等多种方式来执行其行为并相互通信（Julien
    2011；Khanna 2018；Lodish 等人 2000；Purves 等人 2001）。图 [13-1](#figure13-1) 显示了神经元的一个高度简化的示意图。
- en: '![F13001](Images/F13001.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![F13001](Images/F13001.png)'
- en: 'Figure 13-1: A sketch of a highly simplified biological neuron (in red) with
    a few major structures identified. This neuron’s outputs are communicated to another
    neuron (in blue), only partially shown (adapted from Wikipedia 2020b).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13-1：一个高度简化的生物神经元示意图（红色），标出了几个主要结构。该神经元的输出信号传递给另一个神经元（蓝色），后者仅部分显示（改编自 Wikipedia
    2020b）。
- en: Neurons are information processing machines. One type of information arrives
    in the form of chemicals called *neurotransmitters* that temporarily *bind*, or
    attach, onto *receptor sites* located on the neuron (Goldberg 2015). Let’s sketch
    out what happens next in the broadest possible terms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元是信息处理机器。信息的一种类型是通过名为*神经递质*的化学物质传递，这些化学物质暂时*结合*或附着在神经元上的*受体位点*（Goldberg 2015）。让我们概述一下接下来会发生什么。
- en: The chemicals that bind to the receptor sites cause electrical signals to travel
    into the body of the neuron. Each of these signals can be either positive or negative.
    All of the electrical signals arriving at the neuron’s body over a short interval
    of time are added together and then compared to a *threshold*. If the total exceeds
    that threshold, a new signal is sent along the axon to another part of the neuron,
    causing specific amounts of neurotransmitters to be released into the environment.
    These molecules then bind with other neurons, and the process repeats.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 结合到受体位点的化学物质会导致电信号进入神经元的主体。每个信号可能是正电或负电。在短时间内到达神经元主体的所有电信号会被加在一起，然后与*阈值*进行比较。如果总和超过该阈值，就会沿着轴突发送一个新信号到神经元的另一部分，导致一定量的神经递质释放到环境中。这些分子随后会与其他神经元结合，过程重复进行。
- en: In this way, information is propagated and modified as it flows through the
    densely connected network of neurons in the brain and central nervous system.
    If two neurons are physically close enough to each other that one can receive
    the neurotransmitters released by the other, we say that the neurons are *connected*,
    even though they may not be actually touching. There is some evidence that the
    particular pattern of connections between neurons is as essential to cognition
    and identity as the neurons themselves (Sporns, Tononi, and Kötter 2005; Seung
    2013). A map of an individual’s neuronal connections is called their *connectome*.
    Connectomes are as unique as fingerprints or iris patterns.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式，信息在大脑和中枢神经系统中通过神经元的密集连接网络传播并被修改。如果两个神经元之间足够接近，以至于一个可以接收到另一个释放的神经递质，我们就说这些神经元是*连接*的，即使它们可能并没有实际接触。有一些证据表明，神经元之间的特定连接模式对认知和身份的形成至关重要，甚至和神经元本身一样重要（Sporns、Tononi
    和 Kötter 2005；Seung 2013）。一个个体神经元连接的地图被称为*连接组*。连接组和指纹或虹膜图案一样独特。
- en: Although real neurons and their surrounding environment are tremendously complex
    and subtle, the basic mechanism described here has an appealing elegance. Responding
    to this, some scientists have attempted to emulate or duplicate the brain by creating
    enormous numbers of simplified neurons and their environment, in hardware or software,
    hoping that interesting behavior will emerge (Furber 2012; Timmer 2014). So far,
    this has not delivered results that most people would call intelligence.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管真实的神经元及其周围环境极其复杂和微妙，但这里描述的基本机制却具有一种迷人的优雅。对此，一些科学家尝试通过创建大量简化的神经元及其环境，使用硬件或软件来模仿或复制大脑，希望能出现有趣的行为（Furber
    2012；Timmer 2014）。到目前为止，这还没有产生大多数人认为是智能的结果。
- en: But we can connect up simplified neurons in specific ways to produce great results
    on a wide range of problems. Those are the types of structures that will be our
    focus in this chapter, and the rest of this book.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们可以以特定的方式连接简化的神经元，从而在广泛的问题上产生显著的结果。这些结构将是本章和本书其余部分的重点。
- en: Artificial Neurons
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工神经元
- en: The “neurons” we use in machine learning are inspired by real neurons in the
    same way that a stick figure drawing is inspired by a human body. There’s a resemblance,
    but only in the most general sense. Almost all of the details are lost along the
    way, and we’re left with something that’s more of a reminder of the original,
    rather than even a simplified copy.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在机器学习中使用的“神经元”受真实神经元的启发，就像木偶画是受人类身体启发一样。它们有相似之处，但仅仅是最一般的层面。几乎所有的细节在这个过程中都丢失了，最终我们得到的更多的是对原始对象的提醒，而不是一个简化的复制品。
- en: This has led to some confusion, particularly in the popular press, where “neural
    network” is sometimes used as a synonym for “electronic brain,” and from there,
    it’s only a short step to general intelligence, consciousness, emotions, and perhaps
    world domination and the elimination of human life. In reality, the neurons we
    use are so abstracted and simplified from real neurons that many people prefer
    instead to call them by the more generic name of *units*. But for better or worse,
    the word *neuron*, the phrase *neural net*, and all the related language are apparently
    here to stay, so we use them in this book as well.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了一些混淆，特别是在大众媒体中，“神经网络”有时被用作“电子大脑”的同义词，从而只需一步之遥就能联想到通用智能、意识、情感，甚至可能是世界统治和消灭人类生命。实际上，我们使用的神经元与真实神经元的抽象和简化程度如此之大，以至于许多人更愿意将它们称为更通用的*单元*。但无论好坏，*神经元*这个词、*神经网络*这个短语以及所有相关的语言显然将会存在，因此我们在本书中也使用它们。
- en: The Perceptron
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 感知机
- en: The history of artificial neurons may be said to begin in 1943, with the publication
    of a paper that presented a massively simplified abstraction of a neuron’s basic
    functions in mathematical form, and described how multiple instances of this object
    could be connected into a *network*, or *net*. The big contribution of this paper
    was that it proved mathematically that such a network could implement any idea
    expressed in the language of mathematical logic (McCulloch and Pitts 1943). Since
    mathematical logic is the basis of machine calculation, that means neurons could
    perform mathematics. This was a big deal, because it provided a bridge between
    the fields of math, logic, computing, and neurobiology.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Building on that insight, in 1957 the *perceptron* was proposed as a simplified
    mathematical model of a neuron (Rosenblatt 1962). [Figure 13-2](#figure13-2) is
    a block diagram of a single perceptron with four inputs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![f13002](Images/f13002.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-2: A four-input perceptron'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Every input to a perceptron is represented by a single floating-point number.
    Each input is multiplied by a corresponding floating-point number called a *weight*.
    The results of these multiplications are all added together. Finally, we compare
    the result to a threshold value. If the result of the summation is greater than
    0, the perceptron produces an output of +1, otherwise it’s −1 (in some versions,
    the outputs are 1 and 0, rather than +1 and −1).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Though the perceptron is a vastly simplified version of a real neuron, it’s
    proven to be a terrific building block for deep learning systems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: The history of the perceptron is an interesting part of the culture of machine
    learning, so let’s look at just a couple of its key events; more complete versions
    may be found online (Estebon 1997; Wikipedia 2020a).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: After the principles of the perceptron had been verified in software, a perceptron-based
    computer was built at Cornell University in 1958\. It was a rack of wire-wrapped
    boards the size of a refrigerator, called the Mark I Perceptron (Wikipedia 2020c).
    The device was built to process images, using a grid of 400 photocells that could
    digitize an image at a resolution of 20 by 20 pixels (the word *pixel* hadn’t
    yet been coined). The weight applied to each input of the perceptron was set by
    turning a knob that controlled an electrical component called a potentiometer.
    To automate the learning process, electric motors were attached to the potentiometers
    so the device could literally turn its own knobs to adjust its weights and thereby
    change its calculations, and thus its output. The theory guaranteed that, with
    the right data, the system could learn to separate two different classes of inputs
    that could be split with a straight line.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, not many interesting problems involve sets of data that are separated
    by a straight line, and it proved hard to generalize the technique to more complicated
    arrangements of data. After a few years of stalled progress, a book proved that
    the original perceptron technique was fundamentally limited (Minsky and Papert
    1969). It showed that the lack of progress wasn’t due to a lack of imagination,
    but the result of theoretical limits built into the structure of a perceptron.
    Most interesting problems, and even some very simple ones, were provably beyond
    the ability of a perceptron to solve.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，并不是很多有趣的问题涉及被一条直线分隔的数据集，而且将这一技术推广到更复杂的数据排列中也证明很困难。在几年的停滞不前之后，一本书证明了原始感知机技术在理论上存在局限性（Minsky
    和 Papert 1969）。它显示出进展停滞并不是因为缺乏想象力，而是感知机结构中固有的理论限制。大多数有趣的问题，甚至一些非常简单的问题，都证明超出了感知机的解决能力。
- en: This result seemed to signal the end of perceptrons for many people, and a popular
    consensus formed that the perceptron approach was a dead end. Enthusiasm, interest,
    and funding all dried up, and most people directed their research to other problems.
    This period, which lasted roughly between the 1970s and 1990s, was called the
    *AI winter*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这一结果似乎标志着许多人对感知机的看法的结束，并形成了一个流行的共识：感知机方法是一条死胡同。热情、兴趣和资金都枯竭，大多数人将他们的研究方向转向了其他问题。这个时期大约从1970年代到1990年代，被称为*人工智能寒冬*。
- en: But despite a widespread interpretation that the perceptron book had closed
    the door on perceptrons in general, in fact it had only shown the limitations
    of how they’d been used up to that time. Some people thought that writing off
    the whole idea was an overreaction and that perhaps the perceptron could still
    be a useful tool if applied in a different way. It took roughly a decade and a
    half, but this point of view eventually bore fruit when researchers combined perceptrons
    into larger structures and showed how to train them (Rumelhart, Hinton, and Williams
    1986). These combinations easily surpassed the limitations of any single unit.
    A series of papers then showed that careful arrangements of multiple perceptrons,
    beefed up with a few minor changes, could solve complex and interesting problems.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管普遍的解释认为感知机的书籍已经为感知机的研究关上了大门，但事实上，它只显示了到那时为止感知机使用的局限性。有些人认为放弃整个想法是过度反应，或许通过不同的方式应用感知机仍然可以是一种有用的工具。这一观点最终在十几年后结出了果实，当时研究人员将感知机组合成更大的结构，并展示了如何训练它们（Rumelhart,
    Hinton, 和 Williams 1986）。这些组合轻松超越了任何单一单元的局限性。随后一系列论文显示，通过精心安排多个感知机，并增加一些小的改动，可以解决复杂且有趣的问题。
- en: This discovery rekindled interest in the field, and soon research with perceptrons
    became a hot topic once again, producing a steady stream of interesting results
    that have led to the deep learning systems we use today. Perceptrons remain a
    core component of many modern deep learning systems.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这一发现重新激发了人们对该领域的兴趣，很快感知机的研究再次成为热门话题，产生了一系列有趣的成果，这些成果最终发展成我们今天使用的深度学习系统。感知机仍然是许多现代深度学习系统的核心组成部分。
- en: Modern Artificial Neurons
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 现代人工神经元
- en: 'The neurons we use in modern neural networks are only slightly generalized
    from the original perceptrons. There are two changes: one at the input, and one
    at the output. These modified structures are still sometimes called perceptrons,
    but there’s rarely any confusion because the new versions are used almost exclusively.
    More commonly, they’re just called *neurons*. Let’s look at these two changes.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在现代神经网络中使用的神经元仅在原始感知机的基础上稍作了推广。这里有两个变化：一个发生在输入端，另一个发生在输出端。这些修改后的结构仍然有时被称为感知机，但通常不会产生混淆，因为新的版本几乎专门使用。更常见的是，它们被称为*神经元*。让我们来看看这两个变化。
- en: The first change to the perceptron of [Figure 13-2](#figure13-2) is to provide
    each neuron with one more input, which we call the *bias*. This is a number that
    doesn’t come from the output of a previous neuron. Instead, it’s a number that’s
    directly added into the sum of all the weighted inputs. Every neuron has its own
    bias. [Figure 13-3](#figure13-3) shows our original perceptron, but with the bias
    term included.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对[图13-2](#figure13-2)中感知机的第一个改动是为每个神经元提供一个额外的输入，我们称之为*偏置*。这是一个不来自前一个神经元输出的数值。相反，它是直接加到所有加权输入总和中的数值。每个神经元都有自己的偏置。[图13-3](#figure13-3)展示了我们原始的感知机，但包括了偏置项。
- en: '![F13003](Images/F13003.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![F13003](Images/F13003.png)'
- en: 'Figure 13-3: The perceptron of [Figure 13-2](#figure13-2), but now with a bias
    term'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图13-3：[图13-2](#figure13-2)中的感知器，但现在加入了偏置项。
- en: Our second change to the perceptron of [Figure 13-2](#figure13-2) is at the
    output. The perceptron in that figure tests the sum against a threshold of 0,
    and then produces either a −1 or 1 (or 0 or 1). We generalize this by replacing
    the testing step with a mathematical function that takes the sum (including the
    bias) as input and returns a new floating-point value as output. Because the output
    of a real neuron is called its *activation*, we call this function that calculates
    the artificial neuron’s output the *activation function*. The little test shown
    in [Figure 13-2](#figure13-2) is an activation function, but one that’s rarely
    used anymore. Later in this chapter we’ll survey a variety of activation functions
    that have proved to be popular and useful in practice.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对[图13-2](#figure13-2)中的感知器进行了第二次修改，修改发生在输出部分。该图中的感知器将总和与阈值0进行比较，然后输出−1或1（或0或1）。我们通过用一个数学函数替换测试步骤来进行概括，该函数将总和（包括偏置）作为输入，并返回一个新的浮动点值作为输出。由于真实神经元的输出被称为其*激活*，因此我们将这个计算人工神经元输出的函数称为*激活函数*。在[图13-2](#figure13-2)中显示的小测试是一个激活函数，但现在已经很少使用了。稍后在本章中，我们将回顾一些在实践中证明既受欢迎又实用的激活函数。
- en: Drawing the Neurons
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绘制神经元
- en: Let’s identify a convention that’s used by most drawings of artificial neurons.
    In [Figure 13-3](#figure13-3) we showed the weights explicitly, and we also included
    the multiplication steps to show how the weights multiply the inputs. This takes
    a lot of room on the page. When we draw diagrams with a lot of neurons, all of
    these details can make for a cluttered and dense figure. So instead, in virtually
    all neural network diagrams, the weights and their multiplications are implied.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个大多数人工神经元图示所使用的约定。在[图13-3](#figure13-3)中，我们显式地显示了权重，并且还包括了乘法步骤，以展示权重是如何乘以输入的。这在页面上占据了大量空间。当我们绘制包含大量神经元的图时，所有这些细节会使得图形显得拥挤和密集。因此，在几乎所有的神经网络图示中，权重及其乘法步骤都是隐含的。
- en: 'This is important, and bears repeating: in neural network diagrams, the weights,
    and the steps where they multiply the inputs, are not drawn. Instead, we’re supposed
    to know that they are there and mentally include them in the diagram. If we show
    the weights at all, we typically label the lines from the inputs with the name
    of the weight. [Figure 13-4](#figure13-4) shows [Figure 13-3](#figure13-3) drawn
    in this style.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点非常重要，需要重复强调：在神经网络图示中，权重及其乘法步骤不会被绘制出来。相反，我们应该知道它们存在并在心里将其包含在图示中。如果我们显示权重，通常会标注从输入到权重的线。[图13-4](#figure13-4)展示了[图13-3](#figure13-3)这种风格的绘制方式。
- en: '![F13004](Images/F13004.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![F13004](Images/F13004.png)'
- en: 'Figure 13-4: A neuron is often drawn with the weights on the arrows.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图13-4：神经元通常会在箭头上标出权重。
- en: In [Figure 13-4](#figure13-4), we also changed the threshold test at the end
    to a little picture. This is a drawing of a function called a *step*, and it’s
    meant to give us a visual reminder that any activation function can go into that
    spot. Basically, a number goes into that step, and a new number comes out, determined
    by whichever function we choose for the job.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图13-4](#figure13-4)中，我们还将末尾的阈值测试改为一个小图形。这是一个名为*阶跃*的函数的图示，目的是给我们一个视觉提示，任何激活函数都可以放在这个位置。基本上，一个数字进入这个阶跃，新的数字输出，具体由我们为此任务选择的函数决定。
- en: We usually simplify things again. This time we omit the bias by pretending it’s
    one of the inputs. This not only makes the diagram simpler, but it makes the math
    simpler as well, which, in this case, also leads to more efficient algorithms.
    This simplification is called the *bias trick* (the word *trick* comes from mathematics,
    where it’s a complimentary term sometimes used for a clever simplification of
    a problem). Rather than change the value of the bias, we set the bias to always
    be 1, and change the weight applied to it before it gets summed up with the other
    inputs. [Figure 13-5](#figure13-5) shows this change in labeling. Though the bias
    term is always 1 and only its weight can change, we usually ignore the distinction
    and just talk about the value of the bias.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常会再次简化问题。这一次，我们通过假装偏置是其中一个输入来省略它。这不仅使得图示更简洁，同时也让数学更简单，而在这种情况下，也能导致更高效的算法。这个简化方法被称为*偏置技巧*（"技巧"这个词来源于数学，通常用于形容一些巧妙的简化问题的方法）。我们并不改变偏置的值，而是将偏置的值固定为
    1，并在与其他输入求和之前，改变应用到它的权重。[图 13-5](#figure13-5)展示了这一标签的变化。虽然偏置项的值始终为 1，且只有它的权重会发生变化，但我们通常忽略这一区分，仅讨论偏置的值。
- en: '![F13005](Images/F13005.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![F13005](Images/F13005.png)'
- en: 'Figure 13-5: The bias trick in action. Rather than show the bias term explicitly,
    as in [Figure 13-4](#figure13-4), we pretend it’s another input with its own weight.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13-5：偏置技巧的实际应用。与[图 13-4](#figure13-4)中显式显示偏置项不同，我们假装偏置是另一个输入，并为其赋予自己的权重。
- en: 'We want our artificial neuron diagrams to be as simple as possible because
    when we start building up networks we’ll be showing lots of neurons at once, so
    most of these diagrams take two additional steps of simplification. First, they
    don’t show the bias at all. We’re supposed to remember that the bias is included
    (along with its weight), but it’s not shown. Second, the weights are often omitted
    as well, as in [Figure 13-6](#figure13-6). This is unfortunate, because the weights
    are the most important part of the neuron for us. The reason for this is that
    they are the only things we can change during training. Despite being left out
    of most drawings, they’re so essential that we repeat the key idea yet again:
    *even though we don’t show the weights explicitly, the weights are always there.*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望我们的人工神经元图示尽可能简洁，因为当我们开始构建网络时，我们会同时展示大量的神经元，因此大多数图示都会进行两个额外的简化步骤。首先，它们完全不显示偏置。我们应该记得偏置是包含在内的（以及它的权重），但它不会显示出来。其次，权重通常也会被省略，就像在[图
    13-6](#figure13-6)中那样。这有点遗憾，因为权重是我们在神经元中最重要的部分。之所以如此，是因为它们是我们在训练过程中唯一能够改变的部分。尽管在大多数图示中没有显示出来，但它们非常关键，我们再次强调这一核心观点：*即使我们没有显式地显示权重，权重始终存在。*
- en: '![F13006](Images/F13006.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![F13006](Images/F13006.png)'
- en: 'Figure 13-6: A typical drawing of an artificial neuron. The bias term and the
    weights are not shown, but they are definitely present.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13-6：典型的人工神经元图示。虽然偏置项和权重未显示，但它们显然是存在的。
- en: Like real neurons, artificial neurons can be wired up in networks, where each
    input comes from the output of another neuron. When we connect neurons together
    into networks, we draw “wires” to connect one neuron’s output to one or more other
    neurons’ inputs. [Figure 13-7](#figure13-7) shows this idea visually.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 像真实神经元一样，人工神经元可以被连接成网络，其中每个输入来自另一个神经元的输出。当我们将神经元连接成网络时，我们画上“连接线”将一个神经元的输出连接到一个或多个其他神经元的输入。[图
    13-7](#figure13-7)直观地展示了这一概念。
- en: '![F13007](Images/F13007.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![F13007](Images/F13007.png)'
- en: 'Figure 13-7: A piece of a larger network of artificial neurons. Each neuron
    receives its inputs from other neurons. The dashed lines show connections to and
    from outside this little cluster.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13-7：一个更大人工神经元网络的一部分。每个神经元的输入来自其他神经元的输出。虚线表示与该小群体之外的连接。
- en: This is a *neural network*. Usually the goal of a network like [Figure 13-7](#figure13-7)
    is to produce one or more values as outputs. We’ll see later how we can interpret
    the numbers at the outputs in meaningful ways.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是*神经网络*。通常，像[图 13-7](#figure13-7)这样的网络的目标是产生一个或多个输出值。稍后我们将看到如何以有意义的方式解读输出的数字。
- en: Even though we’ve said that we usually don’t draw the weights, in discussions,
    sometimes it’s useful to refer to individual weights. Let’s look at a common convention
    for weight names. [Figure 13-8](#figure13-8) shows six neurons. For convenience,
    we’ve labeled each neuron with a letter. Each weight corresponds to how the output
    of one specific neuron is changed on its way to another specific neuron. Each
    of these connections is shown as a line in the figure. To name a weight, we combine
    the name of the output neuron with the input neuron. For example, the weight that
    multiplies the output of A before it’s used by D is called AD.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们已经说过通常不绘制权重，但在讨论中，有时提到单个权重是有用的。让我们来看一下一个常见的权重命名约定。[图13-8](#figure13-8)显示了六个神经元。为了方便，我们用字母标记了每个神经元。每个权重对应的是一个特定神经元的输出在传递到另一个神经元时的变化。图中每一条连接线表示这种联系。为了命名一个权重，我们将输出神经元的名字和输入神经元的名字组合起来。例如，乘以A的输出并由D使用的权重叫做AD。
- en: '![F13008](Images/F13008.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![F13008](Images/F13008.png)'
- en: 'Figure 13-8: The weights are named by combining the names of the output and
    input neurons.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图13-8：权重是通过组合输出神经元和输入神经元的名称来命名的。
- en: From a structural point of view, it makes no difference whether we draw the
    weights inside each neuron, or on the wires that carry values to it. Various authors
    assume one or the other if it makes their discussion easier to follow, but we
    can always take the other viewpoint if we like.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 从结构的角度来看，无论我们将权重绘制在每个神经元内部，还是绘制在传递值到神经元的电线之上，其实并没有区别。如果为了便于讨论，某些作者可能会选择其中一种方式，但如果需要，我们也可以选择另一种视角。
- en: In [Figure 13-8](#figure13-8), we named the weight from neuron A to neuron D
    as AD. Some authors flip this around and write DA, because it’s a more direct
    match to how we often write the equations. It’s always worth a moment to check
    which order is being used in diagrams like this.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图13-8](#figure13-8)中，我们将从神经元A到神经元D的权重命名为AD。有些作者会将其反过来写成DA，因为这种方式更直接地对应我们通常写方程的方式。在查看类似的图示时，花一点时间确认使用的顺序总是值得的。
- en: Feed-Forward Networks
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前馈网络
- en: '[Figure 13-7](#figure13-7) showed a neural network with no apparent structure.
    A key feature of deep learningis that we arrange our neurons into *layers*. Typically,
    the neurons on each layer get their inputs only from the previous layer and send
    their outputs only to the following layer, and neurons do not communicate with
    other neurons on the same layer (there are, as always, exceptions to these rules).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13-7](#figure13-7)展示了一个没有明显结构的神经网络。深度学习的一个关键特点是我们将神经元排列成*层*。通常，每一层的神经元仅从上一层获取输入，并且只将输出传递给下一层，且神经元之间不与同一层的其他神经元进行通信（当然，像往常一样，这些规则也有例外）。'
- en: This organization allows us to process data in stages, with each layer of neurons
    building on the work done by the previous stage. By analogy, consider an office
    tower of many floors. The people on any given floor receive their work only from
    the people on the floor immediately below them, and they pass their work on only
    to the people on the floor immediately above them. In this analogy, each floor
    is a layer, and the people are the neurons on that layer.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这种组织方式允许我们分阶段地处理数据，每一层的神经元都基于前一阶段完成的工作来进行处理。通过类比，可以考虑一栋有多层的办公楼。任何一层的人只会从楼下那一层的人那里获得工作，并且只将工作交给楼上那一层的人。在这个类比中，每一层就是一个层级，楼层上的人就是该层的神经元。
- en: We say that this type of arrangement processes the data *hierarchically*. There
    is some evidence that the human brain is structured to handle some tasks hierarchically,
    including the processing of sensory data like vision and hearing (Meunier et al.
    2009; Serre 2014). But here again, the connection between our computer models
    and real biology is much closer to inspiration than emulation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说这种类型的结构处理数据是*分层的*。有一些证据表明，人类大脑在处理某些任务时是分层组织的，包括处理感官数据如视觉和听觉（Meunier 等，2009；Serre，2014）。但在这里，我们的计算机模型和真实生物学的关系更多的是灵感上的借鉴，而不是模仿。
- en: It’s amazing that hooking up neurons in a series of layers produces anything
    useful. As we saw earlier, a single artificial neuron can hardly manage to do
    anything. It takes a bunch of numerical inputs, weights them, adds the results
    together, and then passes that result through a little function. This process
    can identify a straight line that splits a couple of clumps of data, and not much
    else. But if we assemble many thousands of these little units into layers and
    use some clever ideas to train them, then, working together, they’re capable of
    recognizing speech, identifying faces in photographs, and even beating humans
    at games of logic and skill.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 很难相信，将神经元连接成一系列层次能够产生有用的东西。正如我们之前看到的，一个单一的人工神经元几乎做不了什么。它接受一堆数字输入，对其加权，求和，然后通过一个小函数传递结果。这个过程能够识别出一条将几堆数据分开的直线，仅此而已。但如果我们将成千上万的这些小单元组合成层，并使用一些巧妙的想法来训练它们，那么它们在一起工作时就能识别语音、识别人脸，甚至在逻辑和技能游戏中击败人类。
- en: The key to this is organization. Over time people have developed a number of
    ways to organize layers of neurons, resulting in a collection of common layer
    structures. The most common network structure arranges the neurons so that information
    flows in only one direction. We call this a *feed-forward network* because the
    data is flowing forward, with earlier neurons feeding, or delivering values to,
    later neurons. The art of designing a deep learning system lies in choosing the
    right sequence of layers, and the right hyperparameters, to create the basic architecture.
    To build a useful architecture for any given application, we need to understand
    how the neurons relate to one another. Let’s now look at how collections of neurons
    communicate, and how to set up the initial weights before learning begins.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于组织。随着时间的推移，人们开发了多种方式来组织神经元的层级，形成了常见的层次结构。最常见的网络结构将神经元排列成仅允许信息朝一个方向流动的方式。我们称这种结构为*前馈网络*，因为数据是向前流动的，较早的神经元将值传递给较晚的神经元。设计深度学习系统的艺术在于选择合适的层级顺序和超参数，以构建基本架构。为了为任何给定的应用构建一个有用的架构，我们需要理解神经元之间是如何相互关联的。接下来，让我们看看神经元集合是如何进行通信的，以及如何在学习开始之前设置初始权重。
- en: Neural Network Graphs
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络图
- en: We usually represent neural networks as *graphs*. The study of graphs is so
    large that it is considered a field of mathematics in its own right, called *graph
    theory* (Trudeau 1994). Here, we’re going to stick to the basic ideas of graphs,
    because that’s all we need to organize our neural networks. Though we know we’ll
    usually be working with layers, let’s start out with some general graphs first,
    such as those shown in [Figure 13-9](#figure13-9).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常将神经网络表示为*图*。图的研究非常广泛，以至于它被认为是一个独立的数学领域，叫做*图论*（Trudeau 1994）。在这里，我们将坚持图的基本概念，因为这就是我们组织神经网络所需的全部内容。尽管我们知道通常会处理层级，但让我们先从一些一般性的图开始，例如在[图13-9](#figure13-9)中所示的那些。
- en: A graph is made up of *nodes* (also called *vertices* or *elements*), here shown
    as circles. In this book, nodes are usually neurons, and throughout this book,
    we occasionally refer to one or more neurons in a network like this as nodes.
    The nodes are connected by arrows called *edges* (also called *arcs*, *wires*,
    or simply *lines*). The arrowhead is often left off when the direction of information
    flow is consistent in the drawing, which is almost always left to right or bottom
    to top. Information flows along the edges, carrying the output of one node to
    the inputs of others. Since information flows in only one direction on each edge,
    we sometimes call this kind of graph a *directed graph.*
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个图由*节点*（也叫*顶点*或*元素*）组成，这里用圆圈表示。在本书中，节点通常是神经元，并且在整本书中，我们偶尔会将像这样的网络中的一个或多个神经元称为节点。节点之间通过箭头连接，箭头被称为*边*（也叫*弧*、*电缆*，或者简单地叫*线*）。当图中的信息流方向一致时，箭头的箭头头通常省略，这通常是从左到右或从下到上的方向。信息沿着边缘流动，将一个节点的输出传递给其他节点的输入。由于每条边上的信息流动仅有一个方向，我们有时将这种图称为*有向图*。
- en: The general idea is that we start things off by putting data into the input
    node or nodes, and then it flows through the edges, visiting nodes where it is
    transformed or changed, until it reaches the output node or nodes. No data ever
    returns to a node once it has left. In other words, information only flows forward,
    and there are no loops, or *cycles*. This kind of graph is like a little factory.
    Raw materials come in one end, and pass through machines that manipulate and combine
    them, ultimately producing one or more finished products at the end.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![F13009](Images/F13009.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-9: Two neural networks drawn as graphs. Data flows from node to node
    along the edges, following the arrows. When the edges are not labeled with an
    arrow, data usually flows left-to-right or bottom-to-top. (a) Mostly left-to-right
    flow. (b) Mostly bottom-to-top flow.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: We say that a node near the inputs in [Figure 13-9](#figure13-9)(a) is *before*
    a node nearer to the outputs, which comes *after* it. In [Figure 13-9](#figure13-9)(b),
    we’d say a node near the inputs is *below* a node near the outputs, which is *above*
    it. Sometimes this below/above language is used even when the graph is drawn left
    to right, which can be confusing. It can help to think of *below* as “closer to
    the inputs,” and *above* as “closer to the outputs.”
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: We also sometimes say that if data flows from one node to another (let’s say
    it flows from A to B), then node A is an *ancestor* or *parent* of B, and node
    B is a *descendant* or *child* of A.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: A common rule in neural networks is that there are no loops. This means that
    data coming out of a node can never make its way back into that same node, no
    matter how circuitous a path it follows. The formal name for this kind of graph
    is a *directed acyclic graph* (or *DAG*, pronounced to rhyme with “drag”). The
    word *directed* here means that the edges have arrows (which may only be implied,
    as we mentioned earlier). The word *acyclic* means there are no *cycles*, or loops.
    As always, there are exceptions to the rules, but they’re rare. We’ll see one
    such exception when we discuss recurrent neural networks (RNNs) in Chapter 19.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: DAGs are popular in many fields, including machine learning, because they are
    significantly easier to understand, analyze, and design than arbitrary graphs
    that have loops. Including loops can introduce *feedback*, where a node’s output
    is returned to its input. Anyone who’s moved a live microphone too close to a
    speaker is familiar with how quickly feedback can grow out of control. The acyclic
    nature of a DAG naturally avoids the feedback problem, which saves us from dealing
    with this complex issue.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Recall that a graph or network in which data only flows forward from inputs
    to outputs is called *feed-forward*. In Chapter 14, we’ll see that a key step
    in training neural networks involves temporarily flipping the arrows around, sending
    a particular type of information from the output nodes back to the input nodes.
    Although the normal flow of data is still feed-forward, when we push data through
    it backward, generally we call that a *feed-backward*, *backward-flow*, or *reverse-feed*
    algorithm. We reserve the word *feedback* for situations in which a loop in the
    graph can enable a node to receive its own output as input. As we’ve said, we
    generally avoid feedback in neural networks.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting graphs like those in [Figure 13-9](#figure13-9) usually means picturing
    the information as it flows along the edges, from one node to the next. But this
    picture only makes sense if we make some conventional assumptions. Let’s look
    at those now.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'Though we often use the word *flow* in various forms when referring to how
    data moves through the graph, this isn’t like the flow of water through pipes.
    Water flowing through pipes is a *continuous* process: new molecules of water
    flow through the pipes at every moment. The graphs we work with (and the neural
    networks they represent) are *discrete*: information arrives one chunk at a time,
    like text messages.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Recall from [Figure 13-5](#figure13-5) that we can draw a neural network by
    placing a weight on each edge (rather than inside a neuron). We call this style
    of the network a *weighted graph.* As we saw in [Figure 13-6](#figure13-6), we
    rarely draw the weights explicitly, but they are implied. It is always the case
    that in any neural network graph, even if no weights are explicitly shown, we
    are to understand that a unique weight is on each edge and as a value moves from
    one neuron to another along that edge that value is multiplied by the weight.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the Weights
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Teaching a neural network involves gradually improving the weights. The process
    begins when we assign initial values to the weights. How should we pick these
    starting values? It turns out that, in practice, how we initialize the weights
    can have a big effect on how quickly our network learns.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Researchers have developed theories for good ways to pick the initial values
    for the weights, and the various algorithms that have proved most useful are each
    named after the lead authors on the publications that describe them. The *LeCun
    Uniform*, *Glorot Uniform* (or *Xavier Uniform*), and *He Uniform* algorithms
    are all based on selecting initial values from a uniform distribution (LeCun et
    al. 1998; Glorot and Bengio 2010; He et al. 2015). It probably won’t be much of
    a surprise that the similarly named *LeCun Normal*, *Glorot Normal* (or *Xavier
    Normal*), and *He Normal* initialization methods draw their values from a normal
    distribution.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: We don’t need to get into the math behind these algorithms. Happily, modern
    deep learning libraries offer each of these schemes, plus variations on them.
    Often the technique used by the library by default works great, so we rarely need
    to explicitly choose how to initialize the weights.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要深入了解这些算法背后的数学原理。幸运的是，现代深度学习库提供了这些方案及其变种。通常，库默认使用的技术已经很好地工作，因此我们很少需要显式地选择如何初始化权重。
- en: Deep Networks
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度网络
- en: Of the many possible ways to organize neurons in a network, placing them in
    a series of layers has proven to be both flexible and extremely powerful. Typically,
    neurons within a layer aren’t connected to one another. Their inputs come from
    the previous layer, and their outputs go to the next layer.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在组织神经元的多种方式中，将它们放置在一系列层中已被证明既灵活又极具威力。通常，一个层内的神经元彼此之间不直接连接。它们的输入来自前一层，输出则传递给下一层。
- en: 'In fact, the phrase *deep learning* comes from this structure. If we imagine
    many layers drawn side by side, we might call the network “wide.” If they were
    drawn vertically and we stood at the bottom looking up, we might call it “tall.”
    If we stood at the top and looked down, we might call it “deep.” And that’s all
    that *deep learning* means: a network made of a series of layers that we often
    draw vertically.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，*深度学习*这个术语正来源于这种结构。如果我们将许多层并排绘制，我们可能会称这个网络为“宽”。如果它们是垂直排列的，而我们站在底部向上看，我们可能会称之为“高”。如果我们站在顶部往下看，我们可能会称之为“深”。这就是*深度学习*的全部含义：一个由一系列层构成的网络，我们通常会将其垂直绘制。
- en: A result of organizing neurons in layers is that we can analyze data hierarchically.
    The early layers process the raw input data, and each subsequent layer is able
    to use information from neurons on the previous layer to process larger chunks
    of data. For example, when considering a photograph, the first layer usually looks
    at the individual pixels. The next layer looks at groups of pixels, the one after
    that looks at groups of those groups, and so on. Early layers might notice that
    some pixels are darker than others, whereas later layers might notice that a clump
    of pixels looks like an eye, and a much later layer might notice the collection
    of shapes that reveal that the whole image shows a tiger.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 将神经元按层组织的结果是，我们可以分层次地分析数据。早期的层处理原始输入数据，而每个后续的层能够利用前一层神经元的信息来处理更大块的数据。例如，考虑一张照片，第一层通常查看单个像素。下一层查看像素的组合，再下一层查看那些组合的组合，依此类推。早期的层可能会注意到某些像素比其他像素更暗，而后来的层可能会注意到一簇像素像一个眼睛，甚至更远的层可能会注意到形状的集合，从而揭示整个图像展示了一只老虎。
- en: '[Figure 13-10](#figure13-10) shows an example of a deep learning architecture
    using three layers.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 13-10](#figure13-10)展示了一个使用三层的深度学习架构示例。'
- en: '![F13010](Images/F13010.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![F13010](Images/F13010.png)'
- en: 'Figure 13-10: A deep learning network'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13-10：深度学习网络
- en: When we draw the layers vertically, as in [Figure 13-10](#figure13-10), the
    inputs are almost always drawn at the bottom, and the outputs where we collect
    our results are almost always drawn at the top.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将层垂直绘制时，如同在[图 13-10](#figure13-10)中那样，输入几乎总是绘制在底部，而我们收集结果的输出则几乎总是绘制在顶部。
- en: In [Figure 13-10](#figure13-10), all three layers contain neurons. In practical
    systems, we usually use lots of other kinds of layers, which we might group together
    as *support layers*. We’ll see many such layers in later chapters. When we count
    the number of layers in a network, we usually don’t count these support layers.
    [Figure 13-10](#figure13-10) would be described as a deep network of three layers.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图 13-10](#figure13-10)中，所有三个层都包含神经元。在实际系统中，我们通常会使用许多其他类型的层，通常将这些层归类为*支撑层*。在后续章节中，我们将看到许多这样的层。当我们计算一个网络中的层数时，通常不会计算这些支撑层。[图
    13-10](#figure13-10)会被描述为一个由三层构成的深度网络。
- en: The topmost layer that contains neurons (Layer 3 in [Figure 13-10](#figure13-10))
    is called the *output layer*.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最顶层包含神经元的层（在[图 13-10](#figure13-10)中的第3层）被称为*输出层*。
- en: We would probably expect that Layer 1 in [Figure 13-10](#figure13-10) would
    be called the *input layer*, but it’s not. In a quirk of terminology, the term
    *input layer* is applied to the bottom of the network, labeled “Inputs” in [Figure
    13-10](#figure13-10). There’s no processing in this “layer.” Instead it’s just
    the memory where the input values reside. The input layer is an example of a support
    layer because it has no neurons, and therefore isn’t included when we count the
    layers in a network. The number of layers we count is called the network’s *depth*.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会认为[图13-10](#figure13-10)中的第1层应该被称为*输入层*，但事实并非如此。在术语上的一个小巧妙用法中，*输入层*是指网络的底部，即[图13-10](#figure13-10)中标为“输入”的部分。在这个“层”中并没有进行任何处理。它只是存放输入值的内存。输入层是一个支持层的例子，因为它没有神经元，因此在计算网络层数时不会被包括在内。我们计算的层数被称为网络的*深度*。
- en: If we imagine standing above the top of [Figure 13-10](#figure13-10) and looking
    down, we only see the output layer. If we imagine we are below the bottom and
    looking up, we only see the input layer. The layers in between aren’t visible
    to us. Each of these layers between the input and output is called a *hidden layer*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想象站在[图13-10](#figure13-10)的顶部往下看，我们只能看到输出层。如果我们想象站在底部往上看，我们只能看到输入层。介于两者之间的层对我们来说是不可见的。每一层输入和输出之间的层被称为*隐藏层*。
- en: Sometimes the stack is drawn left to right, as in [Figure 13-11](#figure13-11).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 有时堆叠图是从左到右绘制的，如[图13-11](#figure13-11)所示。
- en: '![F13011](Images/F13011.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![F13011](Images/F13011.png)'
- en: 'Figure 13-11: The same deep network of [Figure 13-10](#figure13-10), but drawn
    with data flowing left to right'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图13-11：[图13-10](#figure13-10)的相同深度网络，但数据从左到右流动。
- en: Even when drawn this way, we still use terms that refer to the vertical orientation.
    Authors might say that Layer 2 is “above” Layer 1, and “below” Layer 3\. We can
    always keep things straight regardless of how the diagram is drawn if we think
    of “above” or “higher” as referring to a layer closer to the outputs, and “below”
    or “lower” as meaning closer to the inputs.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 即使以这种方式绘制，我们仍然使用指代垂直方向的术语。作者可能会说第二层“在”第一层“上方”，而且“在”第三层“下方”。无论图示如何绘制，只要我们将“上方”或“更高”理解为接近输出层的层，将“下方”或“更低”理解为接近输入层的层，我们总能保持清晰。
- en: Fully Connected Layers
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全连接层
- en: A *fully connected layer* (also called an *FC*, *linear*, or *dense* layer)
    is a set of neurons that each receive an input from *every* neuron on the previous
    layer. For example, if there are three neurons in a dense layer, and four neurons
    in the preceding layer, then each neuron in the dense layer has four inputs, one
    from each neuron in the preceding layer, for a total of 3 × 4 = 12 connections,
    each with an associated weight.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*全连接层*（也称为*FC*、*线性层*或*密集层*）是一组神经元，每个神经元都接收来自上一层*每个*神经元的输入。例如，如果在一个密集层中有三个神经元，而前一层有四个神经元，那么密集层中的每个神经元都有四个输入，每个来自前一层的神经元，总共有3
    × 4 = 12个连接，每个连接都有一个相关的权重。'
- en: '[Figure 13-12](#figure13-12)(a) shows a diagram of a fully connected layer
    with three neurons, coming after a layer with four neurons.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13-12](#figure13-12)(a)展示了一个有三个神经元的全连接层图示，它位于一个有四个神经元的层之后。'
- en: '![F13012](Images/F13012.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![F13012](Images/F13012.png)'
- en: 'Figure 13-12: A fully connected layer. (a) The colored neurons make up a fully
    connected layer. Each of the neurons in this layer receives an input from every
    neuron in the previous layer. (b) Our schematic symbol for a fully connected layer.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图13-12：全连接层。(a) 彩色神经元组成了全连接层。这一层中的每个神经元都接收来自前一层每个神经元的输入。(b) 我们为全连接层设计的简化符号。
- en: '[Figure 13-12](#figure13-12)(b) shows a schematic shorthand that we’ll use
    for fully connected layers. The idea is that two neurons are at the top and bottom
    of the symbol, and the vertical and diagonal lines are the four connections between
    them. Next to the symbol, we identify how many neurons are in the layer, as we’ve
    done here with the number 3\. When it’s relevant, this is also where we identify
    that layer’s activation function. If a layer is made up of only dense layers,
    it is sometimes called a *fully connected network*, or, in a throwback to earlier
    terminology, a *multilayer perceptron* *(MLP)*.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13-12](#figure13-12)(b)展示了我们将用于全连接层的简化符号。这个符号的思想是，两个神经元位于符号的顶部和底部，垂直和对角线表示它们之间的四个连接。在符号旁边，我们标识出该层中有多少个神经元，就像这里的数字3一样。当它与层的激活函数相关时，我们也会在这里标识。如果一个层只由密集层组成，它有时被称为*全连接网络*，或者回溯到早期的术语，称为*多层感知机*（*MLP*）。'
- en: In later chapters, we’ll see many other types of layers that help us organize
    our neurons in useful ways. For example, *convolution layers* and *pooling layers*
    have proven very useful for image processing tasks, and we’ll give them a lot
    of attention.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在后面的章节中，我们将看到许多其他类型的层，它们帮助我们以有用的方式组织神经元。例如，*卷积层*和*池化层*已被证明对于图像处理任务非常有用，我们将给予它们很多关注。
- en: Tensors
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量
- en: We’ve seen that a deep learning system is built from a sequence of layers. And
    though the output of any neuron is a single number, we often want to talk about
    the output of an entire layer at once. The key idea that characterizes this collection
    of output numbers is its shape. Let’s see what that means.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，深度学习系统是由一系列层构成的。尽管任何神经元的输出是一个单一的数字，但我们通常想要一次性讨论整个层的输出。表征这一组输出数字的关键概念是其形状。让我们看看这意味着什么。
- en: If the layer contains a single neuron, the layer’s output is just a single number.
    We might describe this as an array, or a list, with one element. Mathematically,
    we can call this a *zero-dimensional array*. The number of dimensions in an array
    tells us how many indices we need to use to identify an element. Since a single
    number needs no indices, that array has zero dimensions.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果某一层包含一个神经元，那么该层的输出就是一个单一的数字。我们可以将其描述为一个包含一个元素的数组或列表。从数学上讲，我们可以称其为*零维数组*。数组的维度数量告诉我们需要多少个索引来识别一个元素。由于单个数字不需要索引，因此该数组是零维的。
- en: If we have multiple neurons in a layer, then we can describe their collective
    output as a list of all the values. Since we need one index to identify a particular
    output value in this list, this is a one-dimensional (1D) array. [Figure 13-13](#figure13-13)(a)
    shows such an array containing 12 elements.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果该层有多个神经元，那么我们可以将它们的集合输出描述为一个包含所有值的列表。由于我们需要一个索引来识别该列表中特定的输出值，因此这是一个一维（1D）数组。[图13-13](#figure13-13)(a)展示了包含12个元素的这种数组。
- en: '![F13013](Images/F13013.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![F13013](Images/F13013.png)'
- en: 'Figure 13-13: Three tensors, each with 12 elements. (a) A 1D tensor is a list.
    (b) A 2D tensor is a grid. (c) A 3D tensor is a volume. In all cases, and in higher-dimensional
    cases as well, there are no holes and no elements stick out from the block.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图13-13：三个张量，每个包含12个元素。(a) 一维张量是一个列表。(b) 二维张量是一个网格。(c) 三维张量是一个体积。在所有情况下，以及更高维度的情况中，都没有空洞，元素也没有突出于块之外。
- en: We frequently organize our data into other box-like shapes. For instance, if
    the input to our system is a black and white image, it can be represented as a
    2D array, as in [Figure 13-13](#figure13-13)(b), indexed by x and y positions.
    If it’s a color image, then it can be represented as a 3D array, indexed by x
    position, y position, and color channel. A 3D shape is shown in [Figure 13-13](#figure13-13)(c).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常将数据组织成其他类似盒子的形状。例如，如果系统的输入是黑白图像，它可以表示为二维数组，如[图13-13](#figure13-13)(b)所示，按x和y位置进行索引。如果是彩色图像，则可以表示为三维数组，按x位置、y位置和颜色通道进行索引。[图13-13](#figure13-13)(c)展示了一个三维形状。
- en: 'We frequently call a 1D shape an *array*, *list*, or *vector*. To describe
    a 2D shape we often use the terms *grid* or *matrix*, and we can describe a 3D
    shape as a *volume* or *block*. We will often use arrays with even more dimensions.
    Rather than create a mountain of new terms, we use a single term for any collection
    of numbers arranged in a box shape with any number of dimensions: a *tensor* (pronounced
    ten′-sir).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常将一维形状称为*数组*、*列表*或*向量*。要描述二维形状，我们通常使用*网格*或*矩阵*这两个术语，而我们可以将三维形状描述为*体积*或*块*。我们经常使用更高维的数组。为了避免创建大量新的术语，我们使用一个术语来表示任何以盒子形状排列的、具有任意维度的数字集合：*张量*（发音：ten′-sir）。
- en: A tensor is merely a block of numbers with a given number of dimensions and
    a size in each dimension. It has no holes and no bits sticking out. The term *tensor*
    has a more complex meaning in some fields of math and physics, but in machine
    learning, we use this word to mean a collection of numbers organized into a multidimensional
    block. Taken together, the number of dimensions and the size in each dimension
    provide the *shape* of the tensor.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 张量只是一个具有给定维度和每个维度大小的数字块。它没有空洞，也没有部分突出。*张量*这个术语在某些数学和物理学领域有更复杂的含义，但在机器学习中，我们用这个词来表示一个组织成多维块的数字集合。综合来看，维度的数量和每个维度的大小提供了张量的*形状*。
- en: We often refer to a network’s *input tensor* (meaning all the input values),
    and its *output tensor* (meaning all the output values). The outputs of internal
    (or hidden) layers have no special name, so we usually say something like “the
    tensor produced by layer 3” to refer to the multidimensional array of numbers
    coming out of the neurons on layer 3.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常称网络的*输入张量*（指所有输入值）和*输出张量*（指所有输出值）。内部（或隐藏）层的输出没有特定名称，因此我们通常会说类似“第 3 层产生的张量”来指代从第
    3 层神经元输出的多维数组。
- en: Preventing Network Collapse
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 防止网络坍缩
- en: Earlier we promised to return to activation functions. Let’s look at them now.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们承诺要回到激活函数的问题。现在让我们来看一下它们。
- en: Each activation function, while a small piece of the overall structure, is critical
    to a successful neural network. Without activation functions, the neurons in a
    network combine, or *collapse*, into the equivalent of a single neuron. And, as
    we saw earlier, one neuron has very little computational power.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 每个激活函数，尽管是整体结构中的一个小部分，但对于成功的神经网络至关重要。如果没有激活函数，网络中的神经元会结合或*坍缩*成一个等效的单一神经元。正如我们之前看到的，一个神经元的计算能力非常有限。
- en: Let’s see how a network collapses when it doesn’t have activation functions.
    [Figure 13-14](#figure13-14) shows a little network with two inputs (A and B),
    and five neurons (E through G) on three layers. Every neuron receives an input
    from every neuron on the previous layer, and each connection has a weight, giving
    us a total of ten weights, shown in red.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下没有激活函数的网络是如何坍缩的。[图13-14](#figure13-14)展示了一个包含两个输入（A 和 B）和五个神经元（E 到 G）的简单网络，共三层。每个神经元接收来自前一层每个神经元的输入，每个连接都有一个权重，总共有十个权重，如红色所示。
- en: '![F13014](Images/F13014.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![F13014](Images/F13014.png)'
- en: 'Figure 13-14: A little network of two inputs, five neurons, and ten weights'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图13-14：一个包含两个输入、五个神经元和十个权重的小网络
- en: Let’s suppose for the moment that these neurons don’t have activation functions.
    Then we can write the output of each neuron as a weighted sum of its inputs, as
    in [Figure 13-15](#figure13-15). In this figure, we’re using the mathematical
    convention of leaving out the multiplication sign when possible, so 2A is shorthand
    for 2 × A.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 假设暂时这些神经元没有激活函数。那么我们可以将每个神经元的输出写成其输入的加权和，如[图13-15](#figure13-15)所示。在这个图中，我们采用了数学惯例，在可能的情况下省略乘号，因此
    2A 代表 2 × A。
- en: '![F13015](Images/F13015.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![F13015](Images/F13015.png)'
- en: 'Figure 13-15: Each neuron is labeled with the value of its output.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图13-15：每个神经元都标出了其输出的值。
- en: The outputs of C and D depend only on A and B. Similarly, the outputs of E and
    F only depend on the outputs of C and D, which means that they, too, ultimately
    depend only on A and B. The same argument holds for G. If we start with the expression
    for G, plug in the values for E and F, and then plug in the values for C and D,
    we get a big expression in terms of A and B. If we do that and simplify, we find
    that the output of G is 78A + 86B. We can write this as a single neuron with two
    new weights, as shown in [Figure 13-16](#figure13-16).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: C 和 D 的输出仅依赖于 A 和 B。同样，E 和 F 的输出仅依赖于 C 和 D 的输出，这意味着它们最终也仅依赖于 A 和 B。G 的情况也是如此。如果我们从
    G 的表达式开始，代入 E 和 F 的值，再代入 C 和 D 的值，我们得到一个关于 A 和 B 的大表达式。经过简化后，我们发现 G 的输出是 78A +
    86B。我们可以将其写成一个带有两个新权重的单一神经元，如[图13-16](#figure13-16)所示。
- en: This output of G in [Figure 13-16](#figure13-16) is exactly the same as the
    output of G in [Figure 13-14](#figure13-14). Our whole network has collapsed into
    a single neuron!
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: G 在[图13-16](#figure13-16)中的输出与 G 在[图13-14](#figure13-14)中的输出完全相同。我们的整个网络已经坍缩成了一个单一的神经元！
- en: No matter how big or complicated our neural network is, if it has no activation
    functions, then it will always be equivalent to a single neuron. This is bad news
    if we want our network to be able to do anything more than what one neuron can
    do.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们的神经网络多么庞大或复杂，如果它没有激活函数，那么它始终等同于一个单一的神经元。如果我们希望网络能做的事情超过一个神经元的能力，这可不是好消息。
- en: '![F13016](Images/F13016.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![F13016](Images/F13016.png)'
- en: 'Figure 13-16: This network’s output is exactly the same as the output in [Figure
    13-14](#figure13-14).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图13-16：该网络的输出与[图13-14](#figure13-14)中的输出完全相同。
- en: In mathematical language, we say that our fully connected network collapsed
    because it only used addition and multiplication, which are in the category of
    *linear functions*. Linear functions can combine as we just saw, but *nonlinear
    functions* are fundamentally different and don’t combine this way. By designing
    activation functions to use *nonlinear* operations, we prevent this kind of collapse.
    We sometimes call an activation function a *nonlinearity*.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: There are many different types of activation functions, each producing different
    results. Generally speaking, the variety is there because in some situations,
    some functions can run into numerical trouble, making training run more slowly
    than it should, or even cease altogether. If that happens, we can substitute an
    alternative activation function that avoids the problem (though of course it has
    its own weak points).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: In practice, a handful of activation functions are all we usually use. When
    reading the literature and looking at other people’s networks, we sometimes see
    the rarer activation function. Let’s survey the functions that by most major libraries
    usually provide and then gather together the most common ones.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Activation Functions
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An *activation function* (sometimes also called a *transfer function*, or a
    *non-linearity*) takes a floating-point number as input and returns a new floating-point
    number as output. We can define these functions by drawing them as little graphs,
    without any equations or code. The horizontal, or X, axis is the input value,
    and the vertical, or Y, axis is the output value. To find the output for any input,
    we locate the input along the X axis, and move directly upward until we hit the
    curve. That’s the output value.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: In theory, we can apply a different activation function to every neuron in our
    network, but in practice, we usually assign the same activation function to all
    the neurons in each layer.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Straight-Line Functions
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s first look at activation functions that are made up of one or more straight
    lines. [Figure 13-17](#figure13-17) shows a few “curves” that are just straight
    lines.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the leftmost example in [Figure 13-17](#figure13-17). If we pick
    any point on the X axis, and go vertically up until we hit the line, the value
    of that intersection on the Y axis is the same as the value on the X axis. The
    output, or y value, of this curve is always the same as the input, or x value.
    We call this the *identity function*.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![F13017](Images/F13017.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-17: Straight-line functions. The leftmost function is called the
    identity function.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: The other curves in [Figure 13-17](#figure13-17) are also straight lines, but
    they’re tilted to different slopes. We call any curve that’s just a single straight
    line a *linear function*, or even (slightly confusingly) a *linear curve*.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: These activation functions do not prevent network collapse. When the activation
    function is a single straight line, then mathematically, it’s only doing multiplication
    and addition, and that means it’s a linear function and the network can collapse.
    These straight-line activation functions usually appear only in two specific situations.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: The first application is on a network’s output neurons. There’s no risk of collapse
    since there are no neurons after the output. The top of [Figure 13-18](#figure13-18)
    shows the idea.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '![F13018](Images/F13018.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-18: Using the identity as an activation function. Top: The identity
    function on an output neuron. Bottom: Using an identity function to insert a step
    of processing between the summation step and a nonlinear activation function for
    any neuron.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: The second situation where we use a straight-line activation function is when
    we want to insert some processing between the summation step in a neuron and its
    activation function. In this case, we apply the identity function to the neuron,
    perform the processing step, and then perform the nonlinear activation function,
    as shown at the bottom of [Figure 13-18](#figure13-18).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Since we generally want nonlinear activation functions, we need to get away
    from a single straight line. All of the following activation functions are nonlinear
    and prevent network collapse.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Step Functions
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We don’t want a straight line, but we can’t pick just any curve. Our curve needs
    to be single-valued. As we discussed in Chapter 5, this means that if we look
    upward from any value of x along the X axis, there’s only one value of y above
    us. An easy variation on a linear function is to start with a straight line and
    break it up into several pieces. They don’t even have to join. In the language
    of Chapter 5, this means that they don’t have to be continuous.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 13-19](#figure13-19) shows an example of this approach. We call this
    a *stair-step function*. In this example, it outputs the value 0 if the input
    is from 0 to just less than 0.2, but then the output is 0.2 if the input value
    is from 0.2 to just less than 0.4, and so on. These abrupt jumps don’t violate
    our rule that the curve has only one y output value for each input x value.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '![F13019](Images/F13019.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-19: This curve is made up of multiple straight lines. A filled circle
    tells us that the y value there is valid, whereas an open circle tells us that
    there is no curve at that point.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest stair-step function has only a single step. This is a frequent
    special case, so it gets its own name: the *step function*. The original perceptron
    of [Figure 13-2](#figure13-2) used a step function as its activation function.
    A step function is usually drawn as in [Figure 13-20](#figure13-20)(a). It has
    one value until some *threshold* and then it has some other value.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Different people have different preferences for what happens when the input
    has precisely the value of the threshold. In [Figure 13-20](#figure13-20)(a) we’re
    showing that the value at the threshold is the value of the right side of the
    step, as shown by the solid dot.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '![F13020](Images/F13020.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-20: A step function has two fixed values, one each to the left and
    right of a threshold value of x.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Often authors are casual about what happens when the input is exactly at the
    transition, and draw the picture as in [Figure 13-20](#figure13-20)(b) in order
    to stress the “step” of the function. This is an ambiguous way to draw the curve
    because we don’t know what value is intended when the input is precisely at the
    threshold, but it’s a common kind of drawing (often we don’t care which value
    is used at the threshold, so we can choose whatever we prefer).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: A couple of popular versions of the step have their own names. The *unit step*
    is 0 to the left of the threshold, and 1 to the right. [Figure 13-21](#figure13-21)
    shows this function.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: If the threshold value of a unit step is 0, then we give it the more specific
    name of the *Heaviside step*, also shown in [Figure 13-21](#figure13-21).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '![F13021](Images/F13021.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-21: Left: The unit step has a value of 0 to the left of the threshold,
    and 1 to the right. Right: The Heaviside step is a unit step where the threshold
    is 0.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if we have a Heaviside step (so the threshold is at 0) but the value
    to the left is −1 rather than 0, we call this the *sign function*, shown in [Figure
    13-22](#figure13-22). There’s a popular variation of the sign function where input
    values that are exactly 0 are assigned an output value of 0\. Both variations
    are commonly called “the sign function,” so when the difference matters, it’s
    worth paying attention to figure out which one is being referred to.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '![F13022](Images/F13022.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-22: Two versions of the sign function. Left: Values less than 0 are
    assigned an output of −1, all others are 1\. Right: Like the left, except that
    an input of exactly 0 gets the value 0.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Piecewise Linear Functions
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If a function is made up of several pieces, each of which is a straight line,
    we call it *piecewise linear*. This is still a nonlinear function as long as the
    pieces, taken together, don’t form a single straight line.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the most popular activation function is a piecewise linear function
    called a *rectifier*, or *rectified linear unit*, which is abbreviated *ReLU*
    (note that the e is lowercase). The name comes from an electronics part called
    a rectifier, which can be used to prevent negative voltages from passing from
    one part of a circuit to another (Kuphaldt 2017). When the voltage goes negative,
    the physical rectifier clamps it to 0, and our rectified linear unit does the
    same thing with the numbers that are fed into it.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: The ReLU’s graph is shown in [Figure 13-23](#figure13-23). It’s made up of two
    straight lines, but thanks to the kink, or bend, this is nota linear function.
    If the input is less than 0, then the output is 0\. Otherwise, the output is the
    same as the input.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![F13023](Images/F13023.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-23: The ReLU, or rectified linear unit. It outputs 0 for all negative
    inputs, otherwise the output is the input.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: The ReLU activation function is popular because it’s a simple and fast way to
    include a nonlinearity at the end of our artificial neurons. But there’s a potential
    problem. As we’ll see in Chapter 14, if changes in the input don’t lead to changes
    in the output, a network can stop learning. And the ReLU has an output of 0 for
    every negative value. If our input changes from, say, –3 to –2, then the output
    of ReLU stays at 0\. Fixing this problem has led to the development of the ReLU
    variations that follow.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Despite this issue, ReLU (or leaky ReLU, which we’ll see next) often performs
    well in practice, and people often use it as their default choice when building
    a new network, particularly for fully connected layers. Beyond the fact that these
    activation functions work well in practice, there are good mathematical reasons
    for wanting to use ReLU (Limmer and Stanczak 2017), though we won’t explore them
    here.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: The *leaky ReLU* changes the response for negative values. Rather than output
    a 0 for any negative value, this functions outputs the input, scaled down by a
    factor of 10\. [Figure 13-24](#figure13-24) shows this function.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![F13024](Images/F13024.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-24: The leaky ReLU is like the ReLU, but it returns a scaled-down
    value of x when x is negative.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there’s no need to always scale down the negative values by a factor
    of 10\. A *parametric ReLU* lets us choose by how much negative amounts are scaled,
    as shown in [Figure 13-25](#figure13-25).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: When using a parametric ReLU, the essential thing is to never select a factor
    of exactly 1.0, because then we lose the kink, the function becomes a straight
    line, and any neuron we apply this to collapses with those that immediately follow
    it.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '![F13025](Images/F13025.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-25: A parametric ReLU is like a leaky ReLU, but the slope for values
    of x that are less than 0 can be specified.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Another variation on the basic ReLU is the *shifted ReLU*, which just moves
    the bend down and left. [Figure 13-26](#figure13-26) shows an example.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![F13026](Images/F13026.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-26: The shifted ReLU moves the bend in the ReLU function down and
    left.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: We can generalize the various flavors of ReLU with an activation function called
    *maxout* (Goodfellow et al. 2013). Maxout allows us to define a set of lines.
    The output of the function at each point is the largest valueamong all the lines,
    evaluated at that point. [Figure 13-27](#figure13-27) shows maxout with just two
    lines, forming a ReLU, as well as two other examples that use more lines to create
    more complex shapes.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '![F13027](Images/F13027.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-27: The maxout function lets us build up a function from multiple
    straight lines. The heavy red line is the output of maxout for each set of lines.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Another variation on the basic ReLU is to add a small random value to the input
    before running it through a standard ReLU. This function is called a *noisy ReLU*.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Smooth Functions
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we’ll see in Chapter 14, a key step in teaching neural networks involves
    computing derivatives for the outputs of neurons, which necessarily involve their
    activation functions.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: The activation functions that we saw in the last section (except for the linear
    functions) create their nonlinearities by using multiple straight lines with at
    least one kink in the collection. Mathematically, there is no derivative at the
    kink between a pair of straight lines, and therefore the function is not linear.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: If these kinks prevent the computation of derivatives, which are necessary for
    teaching a network, why are functions like ReLU useful at all, let alone so popular?
    It turns out that standard mathematical tools can finesse the sharp corners like
    those in ReLU and still produce a derivative (Oppenheim and Nawab 1996). These
    tricks don’t work on all functions, but one of the principles that guided the
    development of the functions we saw earlier is that they allow these methods to
    be used.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: An alternative to using multiple straight lines and then patching up the problems
    is to use smooth functions that inherently have a derivative everywhere. That
    is, they’re smooth everywhere. Let’s look at a few popular and smooth activation
    functions.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: The *softplus* function simply smooths out the ReLU, as shown in [Figure 13-28](#figure13-28).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![F13028](Images/F13028.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-28: The softplus function is a smoothed version of the ReLU.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: We can smooth out the shifted ReLU as well. This is called the *exponential
    ReLU*, or *ELU* (Clevert, Unterthiner, and Hochreiter 2016). It’s shown in [Figure
    13-29](#figure13-29).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '![F13029](Images/F13029.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-29: The exponential ReLU, or ELU'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Another way to smooth out the ReLU is called *swish* (Ramachandran, Zoph, and
    Le 2017). [Figure 13-30](#figure13-30) shows what this looks like. In essence
    it’s a ReLU, but with a small, smooth bump just left of 0, which then flattens
    out.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '![F13030](Images/F13030.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-30: The swish activation function'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Another popular smooth activation function is the *sigmoid*, also called the
    *logistic function* or *logistic curve*. This is a smoothed-out version of the
    Heaviside step. The name *sigmoid* comes from the resemblance of the curve to
    an S shape, while the other names refer to its mathematical interpretation. [Figure
    13-31](#figure13-31) shows this function.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Closely related to the sigmoid is another mathematical function called the *hyperbolic
    tangent*. It’s much like the sigmoid, only negative values are sent to –1 rather
    than to 0\. The name comes from the curve’s origins in trigonometry. It’s a big
    name, so it’s usually written simply as *tanh*. This is shown in [Figure 13-32](#figure13-32).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: We say that the sigmoid and tanh functions both *squash* their entire input
    range from negative to positive infinity into a small range of output values.
    The sigmoid squashes all inputs to the range [0, 1], while tanh squashes them
    to [−1, 1].
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '![F13031](Images/F13031.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-31: The S-shaped sigmoid function is also called the logistic function
    or logistic curve. It has a value of 0 for very negative inputs, and a value of
    1 for very positive inputs. For inputs in the range of about −6 to 6, it smoothly
    transitions between the two.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![F13032](Images/F13032.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-32: The hyperbolic tangent function, written tanh, is S-shaped like
    the sigmoid of [Figure 13-31](#figure13-31). The key differences are that it returns
    a value of −1 for very negative inputs, and the transition zone is a bit narrower.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: The two are shown on top of one another in [Figure 13-33](#figure13-33).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '![F13033](Images/F13033.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-33: The sigmoid function (orange) and tanh function (teal), both
    plotted for the range −8 to 8'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Another smooth activation function uses a sine wave, as shown in [Figure 13-34](#figure13-34)
    (Sitzmann 2020). This squashes the outputs to the range [–1, 1] like tanh, but
    it doesn’t saturate (or stop changing) for inputs that are far from 0.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '![F13034n](Images/F13034n.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-34: A sine wave activation function'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Activation Function Gallery
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Figure 13-35](#figure13-35) summarizes the activation functions we’ve discussed.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '![F13035n](Images/F13035n.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-35: A gallery of popular activation functions'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Comparing Activation Functions
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'ReLU used to be the most popular activation function, but in recent years,
    the leaky ReLU has been gaining in popularity. This is a result of practice: networks
    with leaky ReLU often learn faster.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: The reason is that ReLU has a problem, which we mentioned earlier. When a ReLU’s
    input is negative, its output is 0\. If the input is a large negative number,
    then changing it by a small amount still results in a negative input to ReLU and
    an unchanged output of 0\. This means that the derivative is also zero. As we’ll
    see in Chapter 14, when a neuron’s derivative goes to zero, not only does it stop
    learning, but it also makes it more likely that the neurons that precede it in
    the network will stop learning as well. Because a neuron whose output never changes
    no longer participates in learning, we sometimes use rather drastic language and
    say that the neuron has *died*. The leaky ReLU has been gaining in popularity
    over ReLU because, by providing an output that isn’t the same for every negative
    input, its derivative is not 0, and thus it does not die. The sine wave function
    also has a non-zero derivative almost everywhere (except at the very top and bottom
    of each wave).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: After ReLU and leaky ReLU, sigmoid and tanh are probably the next most popular
    functions. Their appeal is that they’re smooth, and the outputs are bounded to
    [0, 1] or [–1, 1]. Experience has shown that networks learn most efficiently when
    all the values flowing through it are in a limited range.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: There is no firm theory to tell us which activation function works best in a
    specific layer of a specific network. We usually start by making the same choices
    that have worked in other, similar networks that we’ve seen, and then we try alternatives
    if learning goes too slowly.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: A few rules of thumb give us a good starting point in many situations. Generally
    speaking, we often apply ReLU or leaky ReLU to most neurons on hidden layers,
    particularly fully connected layers. For regression networks, we often use no
    activation function on the final layer (or if we must supply one, we use a linear
    activation function, which amounts to the same thing), because we care about the
    specific output value. When we’re classifying with just two classes, we have just
    a single output value. Here we often apply a sigmoid to push the output clearly
    to one class or the other. For classification networks with more than two classes,
    we almost always use a somewhat different kind of activation function, which we’ll
    look at next.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Softmax
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There’s an operation that we typically apply only to the output neurons of a
    classifier neural network, and even then, only if there are two or more output
    neurons. It’s not an activation function in the sense that we’ve been using the
    term because it takes as input the outputs of *all* the output neurons simultaneously.
    It processes them together and then produces a new output value for each neuron.
    Though it’s not quite an activation function, it’s close enough in spirit to activation
    functions to merit including it in this discussion.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: The technique is called *softmax*. The purpose of softmax is to turn the raw
    numbers that come out of a classification network into class probabilities.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that softmax takes the place of any activation function
    we’d otherwise apply to those output neurons. That is, we give them no activation
    function (or, equivalently, apply the linear function) and then run those outputs
    into softmax.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'The mechanics of this process are involved with the mathematics of how the
    network computes its predictions, so we won’t go into those details here. The
    general idea is shown in [Figure 13-36](#figure13-36): *scores* come in, and *probabilities*
    come out.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '![F13036n](Images/F13036n.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-36: The softmax function takes all the network’s outputs and modifies
    them simultaneously. The result is that the scores are turned into probabilities.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Each output neuron presents a value, or score, that corresponds to how much
    the network thinks the input is of that class. In [Figure 13-36](#figure13-36)
    we’re assuming that we have three classes in our data, named A, B, and C, so each
    of the three output neurons gives us a score for its class. The larger the score,
    the more certain the system is that the input belongs to that class.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: If one class has a larger score than some other class, it means the network
    thinks that class is more likely. That’s useful. But the scores aren’t designed
    to be compared in any other convenient way. For instance, if the score for A is
    twice that of B, it doesn’t mean that A is twice as likely as B. It just means
    that A is more likely. Because making comparisons like “twice as likely” is so
    useful, we use softmax to turn the output scores into probabilities. Now, if the
    softmax output of A is twice that of B, then indeed A is twice as probable as
    B. That’s such a useful way to look at the network’s output that we almost always
    use softmax at the end of a classification network.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'Any set of numbers that we want to treat as probabilities must satisfy two
    criteria: the values all lie between 0 and 1, and they add up to 1\. If we just
    modify each output of the network independently, we don’t know the other values,
    so we can’t make sure they added up to anything in particular. When we hand all
    the outputs to softmax, it can simultaneously adjust all the values so that they
    sum to 1\.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at softmax in action. Consider the top-left graph of [Figure 13-37](#figure13-37).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '![F13037](Images/F13037.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-37: The softmax function takes all the network’s outputs and modifies
    them simultaneously. The result is that the scores are turned into probabilities.
    Top row: Scores from a classifier. Bottom row: Results of running the scores in
    the top row through softmax. Note that the graphs in the upper row use different
    vertical scales.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: The top left of [Figure 13-37](#figure13-37) shows the outputs for a classifier
    with six output neurons, which we’ve labeled A through F. In this example, all
    six of these values are between 0 and 1\. From this graph, we can see that the
    value for class B is 0.1 and the value for class C is 0.8\. As we’ve discussed,
    it is a mistake to conclude from this that the input is 8 times more likely to
    be in class C than class B, because these are scores and not probabilities. We
    can say that class C is more likely than class B, but anything more requires some
    math. To usefully compare these outputs to one another, we can apply softmax to
    carry out that math, and change them into probabilities.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: We show the output of softmax in the graph in the lower left. These are the
    probabilities of the input belonging to each of the six classes. It’s interesting
    to note that the big values, like C and F, get scaled down by a lot, but the small
    values, like B, are hardly scaled at all. This is a natural result of how scores
    between 0 and 1 turn into probabilities. But the ordering of the bars by size
    is still the same as it was for the scores (with C the largest, then F, then D,
    and so on). From the probabilities produced by softmax in the lower figure, we
    can see that class C has a probability of about 0.25, and class B has a probability
    of about 0.15\. We can conclude that the input is a little more than 1.5 times
    more probable to be in class C than class B.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: The middle and right columns of [Figure 13-37](#figure13-37) show the outputs
    for two other hypothetical networks and inputs, before and after softmax. The
    three examples show that the output of softmax depends on whether the inputs are
    all less than 1\. The input ranges in [Figure 13-37](#figure13-37), reading left
    to right, are [0, 0.8], [0, 8], and [0, 3]. Softmax always preserves the ordering
    of its inputs (that is, if we sort the inputs from largest to smallest, they match
    a similar sort on the outputs). But when some input values are greater than 1,
    the largest value tends to stand out more. We say that softmax *exaggerates* the
    influence of the output with the largest value. Sometimes we also say that softmax
    *crushes* the other values, making the largest one dominate the others more obviously.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 13-37](#figure13-37) shows that the input range makes a big difference
    in the output of softmax. Softmax also has an interesting behavior depending on
    whether the inputs values are all less than 1, all greater than 1, or mixed.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: At the far left of [Figure 13-37](#figure13-37) all of the inputs are all less
    than 1, in the range [0, 0.8].
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: In the middle column, the inputs are all greater than 1, in the range [0, 8].
    Notice that in the output, the value of D (corresponding to the 8) clearly dominates
    all of the other values. Softmax has exaggerated the differences among the outputs,
    making it easier to pick out D as the largest.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: On the far right of [Figure 13-37](#figure13-37) we have values both less and
    greater than 1, in the range [0, 3]. Here the exaggeration effect is somewhere
    between the left column, where all inputs are less than 1, and the middle column,
    where all inputs are greater than 1.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: In all cases, though, softmax gives us back probabilities that are each between
    0 and 1, and sum up to 1\. The ordering of the inputs is always preserved, so
    the sequence of largest to smallest input is also the largest to smallest output.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Real, biological neurons are sophisticated nerve cells that process information
    using a fabulously complex range of chemical, electrical, and mechanical processes.
    They serve as the inspiration for a simple bit of computation that we call an
    artificial neuron, despite the enormous gulf between the computer version and
    its biological namesake. An artificial neuron multiplies each input value by a
    corresponding weight, adds the results, then passes that through an activation
    function. We can assemble artificial neurons into networks. Typically, those networks
    are DAGs: they are directed (information flows in only one direction), they are
    acyclic (no neuron ever receives its own output as an input), and they are graphs
    (the neurons are connected to one another). Input data enters at one end, and
    the network’s results appear at the other.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: We saw how, if we’re not careful in constructing our network, the entire network
    can collapse into a single neuron. We prevent this by using the activation function,
    a small function that takes each neuron’s output and turns it into a new number.
    These functions are designed to be nonlinear, meaning that they cannot be described
    merely by operations such as addition and multiplication. It is this nonlinearity
    that prevents the network from being equivalent to a single neuron. We concluded
    the chapter by looking at some of the more common activation functions, and how
    softmax can turn the numbers we get from a neural network into class probabilities.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: The only difference between untrained deep learning systems and those that have
    been trained and are ready for deployment is in the value of the weights. The
    goal of training, or learning, is to find values for the weights so that the network’s
    output is correct for as many samples as possible. Since the weights start out
    with random numbers, we need some principled way to find these new, useful values.
    In Chapters 14 and 15, we’ll see how neural networks learn by looking at the two
    key algorithms that gradually improve the starting weights, transforming a network’s
    outputs into accurate, useful results.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
