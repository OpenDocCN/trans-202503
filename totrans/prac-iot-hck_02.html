<html><head></head><body><div id="sbo-rt-content"><section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="3" id="Page_3"/>1</span><br/>
<span class="ChapterTitle">The IoT Security World</span>
</h1>
</header>
<figure class="opener">
<img src="Images/chapterart.png" alt="" width="204" height="204"/>
</figure>
<p class="ChapterIntro">From the roof of your apartment building, you’re probably surrounded by the <em>Internet of Things (IoT)</em>. On the street below, hundreds of “computers on wheels” drive by every hour, each of them made up of sensors, processors, and networking equipment. On the skyline, apartment buildings prickle with an array of antennae and dishes connecting the many personal assistants, smart microwaves, and learning thermostats to the internet. Above, mobile data centers streak through the sky at hundreds of miles per hour, leaving a data trail thicker than their contrails. Walk into a manufacturing plant, a hospital, or an electronics store and you’ll be similarly overwhelmed by the ubiquity of connected devices. </p>
<p>Although definitions differ widely, even among experts, for purposes of this book, the term <em>IoT</em> refers to physical devices that have computing power and can transfer data over networks, yet don’t typically require <span epub:type="pagebreak" title="4" id="Page_4"/>human-to-computer interaction. Some people describe IoT devices by what they almost are: “like computers, but not quite.” We often label specific IoT devices as “smart”—for instance, a smart microwave—although many people have begun questioning the wisdom of doing so. (See Lauren Goode’s 2018 article in <em>The Verge</em>, “Everything is connected, and there’s no going back.”) It’s doubtful that a more authoritative definition of IoT will arrive anytime soon.</p>
<p>For hackers, the IoT ecosystem is a world of opportunities: billions of interconnected devices transferring and sharing data, creating a massive playground for tinkering, crafting, exploiting, and taking these systems to their limits. Before we dive into the technical details of hacking and securing IoT devices, this chapter introduces you to the world of IoT security. We’ll conclude with three case studies about the legal, practical, and personal aspects of securing IoT devices.</p>
<h2 id="h1-500907c01-0001">Why Is IoT Security Important?</h2>
<p class="BodyFirst">You’ve probably heard the statistics: tens of billions of new IoT devices will exist by 2025, increasing global GDP by tens of trillions of dollars. But that’s only if we get things right and the new devices fly off the shelves. Instead, we’ve seen safety, security, privacy, and reliability concerns stifling adoption. Security concerns can be as much of a deterrent as the price of a device.</p>
<p>Slow growth in the IoT industry isn’t just an economic issue. IoT devices in many areas have the potential to improve lives. In 2016, 37,416 people died on American highways. According to the National Highway Traffic Safety Administration, 94 percent of those deaths were caused by human error. Autonomous vehicles can drastically reduce those numbers and make our roads safer, but only if they’re trustworthy.</p>
<p>In other parts of our lives, we also stand to reap benefits from adding greater capabilities to our devices. For instance, in health care, pacemakers that can send data to the doctor daily will significantly reduce death from heart attacks. Yet in a panel discussion at the Cardiac Rhythm Society, a doctor from the Veteran’s Affairs system said that her patients refused to get implanted devices because they were afraid of hacking. Many people in industry, government, and the security research communities fear that a crisis of confidence will delay lifesaving technology by years or decades. </p>
<p>Of course, as these same technologies become increasingly intertwined with our lives, we must know—not just hope—that they’re worthy of the trust we place in them. In a UK government-funded study of consumer beliefs about IoT devices, 72 percent of respondents expected that the security was already built in. Yet for much of the IoT industry, security is an aftermarket afterthought.</p>
<p>In October 2016, the <em>Mirai</em> botnet attacks occurred, and the US federal government, along with others around the world, collectively took notice. This escalating series of attacks co-opted hundreds of thousands of low-cost devices for its own purposes, gaining access through well-known default passwords, such as <code>admin</code>, <code>password</code>, and <code>1234</code>. It culminated <span epub:type="pagebreak" title="5" id="Page_5"/>in a <em>Distributed Denial of Service</em> (<em>DDoS</em>)<em> </em>against Domain Name System (DNS) provider Dyn, part of the internet infrastructure for many American giants, such as Amazon, Netflix, Twitter, the <em>Wall Street Journal</em>, Starbucks, and more. Customers, revenue, and reputations were shaken for more than eight hours. </p>
<p>Many people assumed the attacks had been the work of a foreign national power. Shortly after Mirai, the <em>WannaCry</em> and <em>NotPetya</em> attacks caused trillions of dollars in damage globally, partially because they impacted IoT systems used in critical infrastructure and manufacturing. They also left governments with the distinct impression that they were behind the curve in their duty to protect their citizens. WannaCry and NotPetya were essentially ransomware attacks that weaponized the EternalBlue exploit, which takes advantage of a vulnerability in Microsoft’s implementation of the Server Message Block (SMB) protocol. By December 2017, when it was revealed that Mirai had been designed and executed by a few college-aged kids, governments around the world knew they had to examine the extent of the IoT security problem.</p>
<p>There are three paths forward for IoT security: the status quo can remain, consumers can begin to “bolt” security onto devices that are insecure by default, or manufacturers can build security into the devices at the outset. In the status quo scenario, society would come to accept regular harms from security issues as a necessary part of using IoT devices. In the aftermarket security scenario, new companies would fill the void neglected by device manufacturers, and buyers would end up paying more for security whose capabilities are less fit for purpose. In the third scenario in which manufacturers build security capabilities into their devices, buyers and operators become better equipped to address issues and risk and cost decisions shift toward more efficient points in the supply chain. </p>
<p>We can draw instruction from the past to see how these three scenarios, especially the last two, might work out. For instance, the original fire escapes in New York were frequently bolted to the outside of buildings. As a result, they often increased cost and harm to the occupants overall, according to an <em>Atlantic</em> article titled “How the Fire Escape Became an Ornament.” Today, they’re built into buildings, often the first thing constructed, and residents have never been safer from fires. Much the same as fire escapes in buildings, security built into IoT devices can bring new capabilities not possible in bolted-on approaches, such as updatability, hardening, threat modeling, and component isolation—all of which you’ll read about in this book.</p>
<p>Note that the aforementioned three paths forward aren’t mutually exclusive; the IoT market can support all three scenarios.</p>
<h2 id="h1-500907c01-0002">How Is IoT Security Different than Traditional IT Security?</h2>
<p class="BodyFirst">IoT technology differs from more familiar information technology (IT) in key ways. <em>I Am The Cavalry</em>, a global grassroots initiative in the security research community, has an instructional framework for comparing the two and is outlined here.</p>
<p><span epub:type="pagebreak" title="6" id="Page_6"/><em>Consequences </em>of IoT security failures might cause a direct loss of life. They could also shatter confidence in the firm or the broader industry as well as trust in a government’s ability to safeguard citizens through oversight and regulation. For instance, when WannaCry hit, patients with time-sensitive conditions, such as strokes or heart attacks, undoubtedly went untreated because the attack delayed care delivery for days.</p>
<p>The <em>adversaries</em> who attack these kinds of systems have different goals, motivations, methods, and capabilities. Some adversaries might try to avoid causing harm, whereas others might seek out IoT systems specifically to cause harm. For instance, hospitals are frequently targeted for ransom because the potential harm to patients increases the likelihood and speed of the victims paying.</p>
<p>The <em>composition</em> of IoT devices, including safety systems, creates constraints that aren’t found in typical IT environments. For instance, size and power constraints in a pacemaker create challenges for applying conventional IT security approaches that require high amounts of storage or computing power.</p>
<p>IoT devices often operate in specific <em>contexts </em>and <em>environments</em>, such as homes, where they’re controlled by individuals without the knowledge or resources needed for secure deployment, operation, and maintenance. For instance, we shouldn’t expect the driver of a connected car to install aftermarket security products, such as antivirus protection. Nor should we expect them to have the expertise or capability to respond quickly enough during a security incident. But we would expect this of an enterprise.</p>
<p>The <em>economics</em> of IoT manufacturing drive device costs (and therefore component costs) to a minimum, often making security an expensive afterthought. Also, many of these devices are targeted at price-sensitive customers who lack experience selecting and deploying infrastructure securely. Additionally, the costs of the devices’ insecurity frequently accrue to individuals who aren’t the primary owner or operator of a device. For instance, the Mirai botnet took advantage of hardcoded passwords, embedded in chipset firmware, to spread. Most owners didn’t know that they should change their passwords or didn’t know how to do so. Mirai cost the US economy billions of dollars by targeting a third-party DNS supplier that didn’t own any impacted devices. </p>
<p><em>Timescales </em>for design, development, implementation, operation, and retirement are often measured in decades. Response time might also be extended because of composition, context, and environment. For instance, connected equipment at a power plant is often expected to live for more than 20 years without replacement. But attacks against a Ukrainian energy supplier caused outages mere seconds after the adversaries took action within the industrial control’s infrastructure.</p>
<h3 id="h2-500907c01-0001">What’s Special About IoT Hacking?</h3>
<p class="BodyFirst">Because IoT security differs from traditional IT security in significant ways, hacking IoT systems requires different techniques as well. An IoT ecosystem is typically composed of embedded devices and sensors, mobile <span epub:type="pagebreak" title="7" id="Page_7"/>applications, cloud infrastructure, and network communication protocols. These protocols include those on the TCP/IP network stack (for example, mDNS, DNS-SD, UPnP, WS-Discovery, and DICOM), as well as protocols used in short-range radio (like NFC, RFID, Bluetooth, and BLE), medium-range radio (like Wi-Fi, Wi-Fi Direct, and Zigbee), and long-range radio (like LoRa, LoRaWAN, and Sigfox). </p>
<p>Unlike traditional security tests, IoT security tests require you to inspect and often disassemble the device hardware, work with network protocols that you won’t normally encounter in other environments, analyze device-controlling mobile apps, and examine how devices communicate to web services hosted on the cloud through application programming interfaces (APIs). We explain all of these tasks in detail throughout the following chapters.</p>
<p>Let’s look at an example of a smart door lock. <a id="figureanchor1-1" href="#figure1-1">Figure 1-1</a> shows a common architecture for smart lock systems. The smart lock communicates with the user’s smartphone app using Bluetooth Low Energy (BLE), and the app communicates with the smart lock servers on the cloud (or as some would still say, someone else’s computer) using an API over HTTPS. In this network design, the smart lock relies on the user’s mobile device for connectivity to the internet, which it needs to receive any messages from the server on the cloud. </p>
<figure>
<img src="Images/f01001.png" alt="f01001" width="750" height="325"/>
<figcaption><p><a id="figure1-1">Figure 1-1:</a> Network diagram of a smart lock system</p></figcaption>
</figure>
<p>All three components (the smart lock device, smartphone app, and cloud service) interact and trust each other, making for an IoT system that exposes a large attack surface. Consider what happens when you revoke the digital key to your Airbnb guest using this smart lock system. As the owner of the apartment and the smart lock device, your mobile app is authorized to send a message to the cloud service that cancels the guest user’s key. Of course, you might not be anywhere near the apartment and the lock when you do that. After the server receives your revocation update, it sends a special message to the smart lock to update its access control list (ACL). If a malicious guest simply puts their phone on airplane mode, the smart lock won’t be able to use it as a relay to receive this state update from the server, and they’ll still be able to access your apartment. </p>
<p><span epub:type="pagebreak" title="8" id="Page_8"/>A simple revocation evasion attack like the one we just described is indicative of the types of vulnerabilities you’ll come across when you hack IoT systems. In addition, the constraints imposed by using small, low-power, low-cost embedded devices only increase the insecurity of these systems. For example, instead of using public key cryptography, which is resource intensive, IoT devices usually rely only on symmetric keys to encrypt their communication channels. These cryptographic keys are very often non-unique and hardcoded in the firmware or hardware, which means that attackers can extract them and then reuse them in other devices. </p>
<h3 id="h2-500907c01-0002">Frameworks, Standards, and Guides</h3>
<p class="BodyFirst">The standard approach to dealing with these security issues is to implement, well, standards. In the past few years, many frameworks, guidelines, and other documents have tried to solve different aspects of the security and trust problem in IoT systems. Although standards are meant to consolidate industries around generally accepted best practices, the existence of too many standards creates a fractured landscape, indicating a broad disagreement about how to do something. But we can draw a lot of value from looking at the various standards and frameworks, even as we recognize that there’s no consensus about the best way to secure IoT devices. </p>
<p>First, we can separate those documents that inform <em>design</em> from those that govern <em>operation</em>. The two are interrelated because a device’s designed capabilities are available to operators to secure their environments. The converse is also true: many capabilities absent in the device’s design are impossible to implement in operations, such as secure software updates, forensically sound evidence capture, in-device isolation and segmentation, and secure failure states, among others. Procurement <em>guidance documents</em>, often issued by companies, industry associations, or governments, can help bridge the two documents.</p>
<p>Second, we can distinguish <em>frameworks</em> from <em>standards</em>. The first defines categories of achievable goals, and the second defines processes and specifications for achieving those goals. Both are valuable, yet frameworks are more evergreen and broadly applicable because security standards frequently age quickly and work best when they’re use-case specific. On the other hand, some standards are extremely useful and form core components of IoT technology, such as those for interoperability, like IPv4 and Wi-Fi. As a result, a combination of frameworks and standards can lead to effective governance of a technical landscape. </p>
<p>In this book, we reference frameworks and standards, where appropriate, to give designers and operators guidance on how to fix issues that security researchers identify when they use the tools, techniques, and processes we outline. Here are examples of standards, guidance documents, and frameworks:</p>
<ol class="none">
<li><span class="RunInHead">Standards</span>  The European Telecommunications Standards Institute (ETSI), founded in 1988, creates more than 2,000 standards every year. Its Technical Specification for Cyber Security for Consumer Internet of Things outlines detailed provisions for building IoT devices securely. <span epub:type="pagebreak" title="9" id="Page_9"/>The US National Institute of Standards and Technology (NIST) and the International Organization for Standardization (ISO) publish several standards that support secure IoT devices. </li>
<li><span class="RunInHead">Frameworks</span>  I Am The Cavalry, founded in 2013, is a global grassroots initiative composed of members of the security research community. Its Hippocratic Oath for Connected Medical Devices (<a id="figureanchor1-2" href="#figure1-2">Figure 1-2</a>) describes objectives and capabilities for designing and developing medical devices. Many of these have been adopted into the FDA’s regulatory criteria for approving medical devices. Other frameworks include the NIST Cybersecurity Framework (which applies to owning and operating IoT devices), Cisco’s IoT security framework, and the Cloud Security Alliance IoT Security Controls Framework, among others.</li>
<li><span class="RunInHead">Guidance documents</span>  The Open Web Application Security Project (OWASP), started in 2001, has branched out well beyond the scope of its namesake. Its Top 10 lists have become powerful tools for software developers and IT procurement and are used to increase the level of security across various projects. In 2014, its IoT Project (<a id="figureanchor1-3" href="#figure1-3">Figure 1-3</a>) published its first Top 10 list. The latest version (as of this writing) is from 2018. Other guidance documents include the NIST IoT Core Baseline, the NTIA IoT Security Upgradability and Patching resources, ENISA’s Baseline Security Recommendations for IoT, the GSMA IoT Security Guidelines and Assessment, and the IoT Security Foundation Best Practice Guidelines.</li>
</ol>
<figure>
<img src="Images/f01002.png" alt="f01002" width="720" height="529"/>
<figcaption><p><a id="figure1-2">Figure 1-2:</a> The Hippocratic Oath for Connected Medical Devices, an IoT framework</p></figcaption>
</figure>
<span epub:type="pagebreak" title="10" id="Page_10"/><figure>
<img src="Images/f01003.png" alt="f01003" width="570" height="823"/>
<figcaption><p><a id="figure1-3">Figure 1-3:</a> The OWASP Top 10 Internet of Things risks, a guidance document</p></figcaption>
</figure>
<h2 id="h1-500907c01-0003"><span epub:type="pagebreak" title="11" id="Page_11"/>Case Study: Finding, Reporting, and Disclosing an IoT Security Issue</h2>
<p class="BodyFirst">Although the bulk of this book details technical considerations, you should understand some of the other factors that affect IoT security research. These factors, learned from lifetimes of working in this field, include the trade-offs you must make when disclosing a vulnerability and what researchers, manufacturers, and the general public should take into account when doing so. The following case study outlines an IoT security research project that ended successfully. We highlight how and why. </p>
<p>In 2016, Jay Radcliffe, a security researcher and type I diabetic, discovered and reported three security issues in the Animas OneTouch Ping insulin pump to the manufacturer. His work began in the prior months when he bought devices, built a test lab, and identified threats to test against. In addition, he sought legal advice to ensure that his testing followed national and local laws.</p>
<p>Jay’s primary goal was to protect patients, so he reported the vulnerability through the manufacturer’s coordinated vulnerability disclosure policy. Through email, phone, and in-person conversations, Jay explained the technical details, the impact of the issues, and the steps needed to mitigate them. This process took several months, during which time he demonstrated an exploitation of the vulnerabilities and provided proof-of-concept code. </p>
<p>Later that year, when Jay learned that the manufacturer had no plans to produce any technical fix until it released a new version of the hardware, he published a public disclosure that included the following response: “If any of my children became diabetic and the medical staff recommended putting them on a pump, I would not hesitate to put them on an OneTouch Ping. It is not perfect, but nothing is.” See <a href="https://blog.rapid7.com/2016/10/04/r7-2016-07-multiple-vulnerabilities-in-animas-onetouch-ping-insulin-pump/" class="LinkURL">https://blog.rapid7.com/2016/10/04/r7-2016-07-multiple-vulnerabilities-in-animas-onetouch-ping-insulin-pump/</a> for the full disclosure. <sup> </sup></p>
<p>Jay had been working for nearly a year to find the vulnerability and get it fixed. He was scheduled to present his work at a major conference after the manufacturer had notified the affected patients. Many patients relied on postal mail for these types of communications, and unfortunately, the mail wouldn’t arrive until after his talk. Jay made the difficult decision to cancel his talk at the conference so patients could find out about the issue from their doctor or the company rather than from a news article.</p>
<p>You can learn several lessons from examples set by mature security researchers like Jay: </p>
<ol class="none">
<li><span class="RunInHead">They consider the effect of their discoveries on the people involved. </span>  Jay’s preparation involved not just getting legal perspectives, but also ensuring that his testing wouldn’t impact anyone outside the lab. In addition, he ensured that patients learned about the issues from people they trusted, reducing the chance that they’d panic or stop using the lifesaving technology. </li>
<li><span epub:type="pagebreak" title="12" id="Page_12"/><span class="RunInHead">They inform rather than supplant decision-making. </span>  Jay understood that the manufacturer had dedicated fewer resources to fixing older devices and instead focused on creating newer products to save and improve even more lives. Instead of pushing for the device makers to patch the old vulnerable devices, he deferred to their judgment.</li>
<li><span class="RunInHead">They lead by example. </span>  Jay, as well as many other researchers in health care, have fostered long-term relationships with patients, regulators, doctors, and manufacturers. In many cases, this has meant foregoing public recognition and paid projects, as well as exercising extreme patience. But the results speak for themselves. The leading device makers are producing the most secure medical devices ever while engaging the security research community at events like the Biohacking Village at DEF CON. </li>
<li><span class="RunInHead">They know the law. </span>  Security researchers have been receiving legal threats for decades. Some of them frivolous. Others, not so much. Although experts are still working on standardized language for regulating coordinated disclosure and bug bounty programs, researchers have rarely, if ever, faced legal consequences for disclosing within these programs.</li>
</ol>
<h2 id="h1-500907c01-0004">Expert Perspectives: Navigating the IoT Landscape</h2>
<p class="BodyFirst">We reached out to several recognized experts in law and public policy to help inform readers about topics not traditionally covered in hacking books. Harley Geiger writes on two laws relevant to security researchers in the United States, and David Rogers covers efforts underway in the United Kingdom to improve security of IoT devices.</p>
<h3 id="h2-500907c01-0003">IoT Hacking Laws </h3>
<h4 id="h3-500907c01-0001">Harley Geiger, Director of Public Policy, Rapid7</h4>
<p class="BodyFirst">Arguably, the two most important federal laws affecting IoT research are the Digital Millennium Copyright Act (DMCA) and the Computer Fraud and Abuse Act (CFAA). Let’s take a quick look at these gruesome statutes.</p>
<p>A lot of IoT security research involves working around weak protections to software, but the DMCA normally forbids circumventing <em>technological protection measures</em> (<em>TPMs</em>), such as encryption, authentication requirements, and region coding, to access copyrighted works (like software) without the copyright owner’s permission. This would require researchers to get permission from IoT software manufacturers before performing IoT security research—<em>even for devices you own</em>! Fortunately, there’s a specific exemption for security testing in good faith, enabling security researchers to circumvent TPMs without the copyright owner’s permission. The Librarian of Congress authorized this exemption at the request of the security research <span epub:type="pagebreak" title="13" id="Page_13"/>community and its allies. As of 2019, to obtain legal protection under the DMCA, the research must meet these basic parameters:</p>
<ul>
<li>The research must be on a device that is lawfully acquired (for example, authorized by the computer owner).</li>
<li>The research must be solely for the purpose of testing or correcting security vulnerabilities.</li>
<li>The research must be performed in an environment designed to avoid harm (so, not in a nuclear plant or a congested highway).</li>
<li>The information derived from the research must be used primarily to promote the safety or security of devices, computers, or their users (not primarily for piracy, for example).</li>
<li>The research must not violate other laws, such as (but not limited to) the CFAA.</li>
</ul>
<p>There are two exemptions, but only one provides any real protection. This stronger exemption must be renewed every three years by the Librarian of Congress, and the scope of the protection can change when it’s renewed. Some of the most progressive outcomes for legal protections for security research happen as a result of this process. The most recent, 2018 version of the DMCA security testing exemption appears at <a href="https://www.govinfo.gov/content/pkg/FR-2018-10-26/pdf/2018-23241.pdf#page=17/" class="LinkURL">https://www.govinfo.gov/content/pkg/FR-2018-10-26/pdf/2018-23241.pdf#page=17/</a>.</p>
<p>The CFAA comes up a lot, too; as you just saw, it’s referenced in the security testing protections under the DMCA. The CFAA is the United States’ foremost federal anti-hacking law, and—unlike the DMCA—the law doesn’t presently include direct protections for security testing. But the CFAA generally applies to accessing or damaging other peoples’ computers without the <em>computer owner’s</em> authorization (not, as with the DMCA, the software copyright’s owner). Well, what if you’re authorized to use an IoT device (say, by an employer or a school) but your IoT research would exceed this authorization? Ah, the courts are still arguing over that one. Welcome to one of the legal gray areas of the CFAA, which by the way was enacted more than 30 years ago. Nonetheless, if you’re accessing or damaging an IoT device that you own or are authorized (by the computer owner) to perform research on, you’re more likely in the clear under the DMCA and CFAA. Congrats.</p>
<p>But wait! Many other laws can implicate IoT security research, particularly state anti-hacking laws, which can be even broader and vaguer than the CFAA. (Fun fact: Washington state’s hacking law has a specific legal protection for “white hat hackers.”) The point is, don’t assume your IoT security research is ultralegal just because you’re not violating DMCA or CFAA—although that’s a very good start! </p>
<p>If you find these legal protections confusing or intimidating, you’re not alone. These laws are complex and literally boggle even the keen minds of lawyers and elected officials, but there’s a determined and growing effort to clarify and strengthen legal protections for security research. Your voice and experiences dealing with ambiguous laws that deter valuable IoT security research can be a helpful contribution to the ongoing debate over reforming the DMCA, CFAA, and other laws. </p>
<h3 id="h2-500907c01-0004"><span epub:type="pagebreak" title="14" id="Page_14"/>The Role of Government in IoT Security</h3>
<h4 id="h3-500907c01-0002">David Rogers, CEO of Copper Horse Security, author of UK Code of Practice, and Member of the Order of the British Empire (MBE) for services to Cyber Security</h4>
<p class="BodyFirst">Governments have the unenviable task of protecting a society while enabling the economy to flourish. Although states around the world have been hesitant to weigh in on IoT security for fear of stifling innovation, events like the Mirai botnet, WannaCry, and NotPetya have caused legislatures and regulators to rethink their hands-off approach.</p>
<p>One such government effort is the UK’s Code of Practice. First published in March 2018, it aims to make the United Kingdom the safest place to live and do business online. The state recognized that the IoT ecosystem had huge potential, but also huge risks, because manufacturers were failing to protect consumers and citizens. In 2017, it put an Expert Advisory Group together, composed of people from across industry, government, and academia, which started looking at the problem. In addition, the initiative consulted many members of the security research community, including organizations such as I Am The Cavalry.</p>
<p>The code settled on 13 guidelines that, as a whole, would raise the bar of cybersecurity, not just for devices, but also for the surrounding ecosystem. It applies to mobile application developers, cloud providers, and mobile network operators, as well as retailers. This approach shifts the burden of security from consumers to organizations better equipped and incentivized to address security issues earlier in the device life cycle.</p>
<p>You can read the entire code at <a href="https://www.gov.uk/government/publications/code-of-practice-for-consumer-iot-security/" class="LinkURL">https://www.gov.uk/government/publications/code-of-practice-for-consumer-iot-security/</a>. The most urgent items are the top three: avoiding default passwords, implementing and acting on a vulnerability disclosure policy, and ensuring software updates are available for devices. The author described these guidelines as <em>insecurity canaries</em>; if an IoT product fails to meet these guidelines, the rest of the product is probably flawed as well.</p>
<p>The code took a truly international approach, recognizing the fact that the IoT world and its supply chain are global concerns. The code has drawn support from dozens of companies around the globe, and the ETSI adopted it as ETSI Technical Specification 103 645 in January 2019.</p>
<p>For more information on specific government policies on IoT security, see the I Am The Cavalry IoT Cyber Safety Policy Database at <a href="https://iatc.me/iotcyberpolicydb/" class="LinkURL">https://iatc.me/iotcyberpolicydb/</a>.</p>
<h3 id="h2-500907c01-0005">Patient Perspectives on Medical Device Security</h3>
<p class="BodyFirst">Designing and developing IoT devices can force manufacturers to make some difficult trade-offs. Security researchers who rely on medical devices for their own care, such as Marie Moe and Jay Radcliffe, know these trade-offs well.</p>
<h4 id="h3-500907c01-0003"><span epub:type="pagebreak" title="15" id="Page_15"/>Marie Moe, @mariegmoe, SINTEF</h4>
<p class="BodyFirst">I am a security researcher and I am a patient. Every beat of my heart is generated by a medical device, a pacemaker implanted in my body. Eight years ago, I woke up lying on the floor. I had fallen because my heart had taken a break—long enough to cause unconsciousness. To keep my pulse up and stop my heart from taking pauses, I needed a pacemaker. This little device monitors each heartbeat and sends a small electrical signal directly to my heart via an electrode to keep it beating. But how can I trust my heart when it’s running on proprietary code and there’s no transparency? </p>
<p>When I got the pacemaker, it was an emergency procedure. I needed the device to stay alive, so there was no option to not get the implant. But it was time to ask questions. To the surprise of my doctors, I began asking about the potential security vulnerabilities in the software running on the pacemaker and the possibilities of hacking this life-critical device. The answers were unsatisfying. My health-care providers couldn’t answer my technical questions about computer security; many of them hadn’t even thought about the fact that this machine within me was running computer code and that little technical information was available from the implant’s manufacturer. </p>
<p>So, I started a hacking project; over the last four years I’ve learned more about the security of the device keeping me alive. I discovered that many of my fears about the state of medical device cybersecurity were true. I’ve learned that proprietary software built with a “security by obscurity approach” can hide bad security and privacy implementations. I’ve learned that legacy technology coupled with added connectivity equals an increase in attack surface, and therefore increased risk for cybersecurity issues that might impact patient safety. Security researchers like me aren’t hacking devices with the intention of creating fear or hurting patients. My motivation is to get the discovered flaws fixed. To do this, collaboration among all stakeholders is critical. </p>
<p>My wish is that other researchers and I are taken seriously by the medical device manufacturers when we approach them to report cybersecurity issues, acting in the best interest of patient safety. </p>
<p>First, we need to acknowledge that cybersecurity problems can cause patient safety issues. Keeping quiet about known vulnerabilities or denying their existence won’t make patients safer. Transparency efforts, such as creating open standards for secure wireless communication protocols, publishing a coordinated vulnerability disclosure policy inviting researchers to report issues in good faith, and releasing cybersecurity advisories to patients and doctors gives me confidence the manufacturer is taking these issues seriously and working to mitigate them. This equips my doctor and me with the confidence needed to balance the medical risks and cybersecurity side effects against my personal threat model.</p>
<p>The solution going forward is transparency and better collaboration with understanding and empathy.</p>
<h4 id="h3-500907c01-0004"><span epub:type="pagebreak" title="16" id="Page_16"/>Jay Radcliffe, @jradcliffe02, Thermo Fisher Scientific</h4>
<p class="BodyFirst">I vividly remember the day I was diagnosed with diabetes. It was my 22nd birthday. I had been exhibiting typical symptoms for a type I diabetic: extreme thirst and weight loss. That day changed my life. I’m one of the rare people who can say I’m fortunate for my diabetes diagnosis. Diabetes opened up the world of connected medical devices to me. I already loved to take things apart and rebuild them. This was just a new way to exercise those instincts and skills. Having a device connected to your physical body that controls major life functions is indescribable. Knowing that it has wireless connectivity and vulnerabilities is a different indescribable feeling. I’m thankful for every opportunity to help make medical devices more resilient to a hostile electronic/connected world. These devices are critical to keeping people healthy and alive. Insulin pumps, pacemakers, cardio devices, spinal stimulators, neural stimulators, and countless other devices are changing people’s lives for the better. </p>
<p>These devices often connect to cell phones and then to the internet, where they can keep doctors and caretakers informed about a patient’s health. But connectivity comes with risk. It’s our job as security professionals to help those patients and doctors understand those risks and help manufacturers identify and control those risks. Although the nature of computers, connectivity, and security have changed greatly over the last few decades, the statutory language in the United States hasn’t significantly changed with respect to good-faith security research. (Check your local laws; they might be different.) Fortunately, regulatory language, exemptions, and implementations have changed—for the better—thanks to the work of hackers, academics, companies, and clueful government personnel. A full treatment of legal issues in security research might take up several volumes of dry content written by highly experienced lawyers, so this isn’t the place for that discussion. But in general, if you own a device in the United States, it’s legal to perform security research on it, up to the boundaries of your own network. </p>
<h2 id="h1-500907c01-0005">Conclusion </h2>
<p class="BodyFirst">The IoT landscape is exploding. The number, type, and uses of these “things” changes faster than any publication deadlines. By the time you read these words, there will be some new “thing” that we failed to account for in these pages. Even so, we’re confident this book provides valuable resources and references that allow you to build capabilities regardless of what you find on your test bench in a year or a decade.</p>
</section>
</div></body></html>