<html><head></head><body><section class="chapter" epub:type="chapter" id="bigger_or_trickier_networks" title="Chapter&#xA0;5.&#xA0;Bigger or Trickier Networks"><div class="titlepage"><div><div><h2 class="title">Chapter 5. Bigger or Trickier Networks</h2></div></div></div><div class="mediaobject"><a id="med_id00007"/><img alt="Bigger or Trickier Networks" src="httpatomoreillycomsourcenostarchimages2127149.png.jpg"/></div><p><a class="indexterm" id="iddle1133"/>In this chapter, we’ll build on the material in previous chapters to meet the real-life challenges of both large and small networks with relatively demanding applications or users. The sample configurations in this chapter are based on the assumption that your packet-filtering setups will need to accommodate services you run on your local network. We’ll mainly look at this challenge from a Unix perspective, focusing on SSH, email, and Web services (with some pointers on how to take care of other services).</p><p>This chapter is about the things to do when you need to combine packet filtering with services that must be accessible outside your local network. How much this complicates your rule sets will depend on your network design and, to a certain extent, on the number of routable addresses you have available. We’ll begin with configurations for official, routable IPv4 addresses as well as the generally roomier IPv6 address ranges. Then, we’ll move on to situations with as few as one routable IPv4 address and the PF-based work-arounds that make the services usable even under these restrictions.</p><div class="sect1" title="A Web Server and Mail Server on the Inside: Routable IPv4 Addresses"><div class="titlepage"><div><div><h2 class="title" id="web_server_and_mail_server_on_the_inside" style="clear: both">A Web Server and Mail Server on the Inside: Routable IPv4 Addresses</h2></div></div></div><p><a class="indexterm" id="iddle1148"/><a class="indexterm" id="iddle1154"/><a class="indexterm" id="iddle1202"/><a class="indexterm" id="iddle1244"/><a class="indexterm" id="iddle1394"/><a class="indexterm" id="iddle1478"/><a class="indexterm" id="iddle2034"/>How complicated is your network? How complicated does it need to be?</p><p>We’ll start with the baseline scenario of the sample clients from <a class="xref" href="ch03.html" title="Chapter 3. Into the Real World">Chapter 3</a>. We set up the clients behind a basic PF firewall and give them access to a range of services hosted elsewhere but no services running on the local network. These clients get three new neighbors: a mail server, a Web server, and a file server. In this scenario, we use official, routable IPv4 addresses because it makes life a little easier. Another advantage of this approach is that with routable addresses, we can let two of the new machines run DNS for our <span class="emphasis"><em>example.com</em></span> domain: one as the master and the other as an authoritative slave.<sup>[<a class="footnote" epub:type="noteref" href="#ftn.ch05fn01" id="ch05fn01">25</a>]</sup> And as you’ll see, adding IPv6 addresses and running a dual-stack network won’t necessarily make your rule set noticeably more complicated.</p><div class="note" title="Note"><h3 class="title"><a id="ch05note01"/>Note</h3><p><span class="emphasis"><em>For DNS, it always makes sense to have at least one authoritative slave server somewhere outside your own network (in fact, some top-level domains won’t let you register a domain without it). You may also want to arrange for a backup mail server to be hosted elsewhere. Keep these things in mind as you build your network.</em></span></p></div><p>At this stage, we keep the physical network layout fairly simple. We put the new servers in the same local network as the clients—possibly in a separate server room but certainly on the same network segment or switch as the clients. Conceptually, the new network looks something like <a class="xref" href="ch05.html#basic_network_with_servers_and_clients_o" title="Figure 5-1. A basic network with servers and clients on the inside">Figure 5-1</a>.</p><p>With the basic parameters for the network in place, we can start setting up a sensible rule set for handling the services we need. Once again, we start from the baseline rule set and add a few macros for readability.</p><p>The macros we need come rather naturally from the specifications:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Web server:</p><a id="pro_id00134"/><pre class="programlisting">webserver = "{ 192.0.2.227, 2001:db8::baad:f00d:f17 }"</pre></li><li class="listitem"><p>Web server services:</p><a id="pro_id00135"/><pre class="programlisting">webports = "{ http, https }"</pre></li><li class="listitem"><p>Mail server:</p><a id="pro_id00136"/><pre class="programlisting">emailserver = "{ 192.0.2.225, 2001:db8::baad:f00d:f117 }"</pre></li></ul></div><div class="figure"><a id="basic_network_with_servers_and_clients_o"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00008"/><img alt="A basic network with servers and clients on the inside" src="httpatomoreillycomsourcenostarchimages2127153.png.jpg"/></div></div><div class="figure-title">Figure 5-1. A basic network with servers and clients on the inside</div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><a class="indexterm" id="iddle1149"/><a class="indexterm" id="iddle1405"/>Mail server services:</p><a id="pro_id00137"/><pre class="programlisting">email = "{ smtp, pop3, imap, imap3, imaps, pop3s }"</pre></li><li class="listitem"><p>Name servers:</p><a id="pro_id00138"/><pre class="programlisting">nameservers = "{ 192.0.2.221, 192.0.2.223 , \&#13;
                      2001:db8::baad:f00d:fbaa, 2001:db8::baad:f00d:ff00 }"</pre></li></ul></div><div class="note" title="Note"><h3 class="title"><a id="ch05note02"/>Note</h3><p><span class="emphasis"><em>At this point, you’ve probably noticed that both the IPv4 and IPv6 addresses for our servers are placed fairly close together within their respective address ranges. Some schools of thought hold that in the case of IPv6, each interface should be allocated at least a /64 range if your total allocation can bear it. Others have advocated more modest allocations. The IETF’s current best practice document on the matter is RFC6177, available from the IETF website</em></span> (<a class="ulink" href="http://www.ietf.org" target="_top">http://www.ietf.org</a>).</p></div><p>We assume that the file server doesn’t need to be accessible to the outside world, unless we choose to set it up with a service that needs to be visible outside the local network, such as an authoritative slave name server for our domain. Then, with the macros in hand, we add the <code class="literal">pass</code> rules. Starting with the Web server, we make it accessible to the world with the following:</p><a id="pro_id00139"/><pre class="programlisting">pass proto tcp to $webserver port $webports</pre><div class="sidebar"><a id="is_synprox_y_worth_the_troublequestion_m"/><div class="sidebar-title">Is Synproxy Worth the Trouble?</div><p><a class="indexterm" id="iddle1203"/><a class="indexterm" id="iddle1334"/><a class="indexterm" id="iddle1424"/><a class="indexterm" id="iddle1443"/><a class="indexterm" id="iddle1817"/><a class="indexterm" id="iddle1917"/><a class="indexterm" id="iddle1918"/>Over the years, the <code class="literal">synproxy state</code> option has received a lot of attention as a possible bulwark against ill-intentioned traffic from the outside. Specifically, the <code class="literal">synproxy state</code> option was intended to protect against SYN-flood attacks that could lead to resource exhaustion at the back end.</p><p>It works like this: When a new connection is created, PF normally lets the communication partners handle the connection setup themselves, simply passing the packets on if they match a <code class="literal">pass</code> rule. With <code class="literal">synproxy</code> enabled, PF handles the initial connection setup and hands over the connection to the communication partners only once it’s properly established, essentially creating a buffer between the communication partners. The SYN proxying is slightly more expensive than the default <code class="literal">keep state</code>, but not necessarily noticeably so on reasonably scaled equipment.</p><p>The potential downsides become apparent in load-balancing setups where a SYN-proxying PF could accept connections that the backend isn’t ready to accept, in some cases short-circuiting the redundancy by setting up connections to hosts other than those the load-balancing logic would have selected. The classic example here is a pool of HTTP servers with round-robin DNS. But the problem becomes especially apparent in protocols like SMTP, where the built-in redundancy dictates (by convention, at least—the actual RFC is a bit ambiguous) that if a primary mail exchanger isn’t accepting connections, you should try a secondary instead.</p><p>When considering a setup where <code class="literal">synproxy</code> seems attractive, keep these issues in mind and analyze the potential impact on your setup that would come from adding <code class="literal">synproxy</code> to the mix. If you conclude that SYN proxying is needed, simply tack on <code class="literal">synproxy state</code> at the end of the rules that need the option. The rule of thumb is, if you are under active attack, inserting the <code class="literal">synproxy</code> option may be useful as a temporary measure. Under normal circumstances, it isn’t needed as a permanent part of your configuration.</p></div><p>On a similar note, we let the world talk to the mail server:</p><a id="pro_id00140"/><pre class="programlisting">pass proto tcp to $emailserver port $email</pre><p>This lets clients anywhere have the same access as the ones in your local network, including a few mail-retrieval protocols that may run without encryption. That’s common enough in the real world, but you might want to consider your options if you’re setting up a new network.</p><p>For the mail server to be useful, it needs to be able to send mail to hosts outside the local network, too:</p><a id="pro_id00141"/><pre class="programlisting">pass log proto tcp from $emailserver to port smtp</pre><p><a class="indexterm" id="iddle1083"/><a class="indexterm" id="iddle1221"/>Keep in mind that the rule set starts with a <code class="literal">block all</code> rule, which means that only the mail server is allowed to initiate SMTP traffic from the local network to the rest of the world. If any of the other hosts on the network need to send email to or receive email from the outside world, they need to use the designated mail server. This could be a good way to ensure, for example, that you make it as hard as possible for any spam-sending zombie machines that might turn up in your network to deliver their payloads.</p><p>Finally, the name servers need to be accessible to clients outside our network who look up the information about <span class="emphasis"><em>example.com</em></span> and any other domains for which we answer authoritatively:</p><a id="pro_id00142"/><pre class="programlisting">pass proto { tcp, udp } to $nameservers port domain</pre><p>Having integrated all the services that need to be accessible from the outside world, our rule set ends up looking roughly like this:</p><a id="pro_id00143"/><pre class="programlisting">ext_if = "ep0" # macro for external interface - use tun0 or pppoe0 for PPPoE&#13;
int_if = "ep1" # macro for internal interface&#13;
localnet = $int_if:network&#13;
webserver = "{ 192.0.2.227, 2001:db8::baad:f00d:f17 }"&#13;
webports = "{ http, https }"&#13;
emailserver = "{ 192.0.2.225, 2001:db8::baad:f00d:f117 }"&#13;
email = "{ smtp, pop3, imap, imap3, imaps, pop3s }"&#13;
nameservers = "{ 192.0.2.221, 192.0.2.223, \&#13;
                 2001:db8::baad:f00d:fbaa, 2001:db8::baad:f00d:ff00 }"&#13;
client_out = "{ ssh, domain, pop3, auth, nntp, http,\&#13;
                https, cvspserver, 2628, 5999, 8000, 8080 }"&#13;
udp_services = "{ domain, ntp }"&#13;
icmp_types = "{ echoreq, unreach }"&#13;
icmp6_types = "{ echoreq unreach timex paramprob }"&#13;
block all&#13;
pass quick proto { tcp, udp } from $localnet to port $udp_services&#13;
pass log inet proto icmp all icmp-type $icmp_types&#13;
pass inet6 proto icmp6 icmp6-type $icmp6_types&#13;
pass proto tcp from $localnet to port $client_out&#13;
pass proto { tcp, udp } to $nameservers port domain&#13;
pass proto tcp to $webserver port $webports&#13;
pass log proto tcp to $emailserver port $email&#13;
pass log proto tcp from $emailserver to port smtp</pre><p>This is still a fairly simple setup, but unfortunately, it has one potentially troubling security disadvantage. The way this network is designed, the servers that offer services to the world at large are all <span class="emphasis"><em>in the same local network</em></span> as your clients, and you’d need to restrict any internal services to only local access. In principle, this means that an attacker would need to compromise only one host in your local network to gain access to any resource there, putting the miscreant on equal footing with any user in your local network. Depending on how well each machine and resource are protected from unauthorized access, this could be anything from a minor annoyance to a major headache.</p><p><a class="indexterm" id="iddle1150"/><a class="indexterm" id="iddle1151"/><a class="indexterm" id="iddle1194"/><a class="indexterm" id="iddle1195"/><a class="indexterm" id="iddle1395"/><a class="indexterm" id="iddle2023"/><a class="indexterm" id="iddle2028"/>In the next section, we’ll look at some options for segregating the services that need to interact with the world at large from the local network.</p><div class="sect2" title="A Degree of Separation: Introducing the DMZ"><div class="titlepage"><div><div><h3 class="title" id="degree_of_separation_introducing_the_dmz">A Degree of Separation: Introducing the DMZ</h3></div></div></div><p>In the previous section, you saw how to set up services on your local network and make them selectively available to the outside world through a sensible PF rule set. For more fine-grained control over access to your internal network, as well as the services you need to make it visible to the rest of the world, add a degree of physical separation. Even a separate <span class="emphasis"><em>virtual local area network (VLAN)</em></span> will do nicely.</p><p>Achieving the physical and logical separation is fairly easy: Simply move the machines that run the public services to a separate network that’s attached to a separate interface on the gateway. The net effect is a separate network that isn’t quite part of your local network but isn’t entirely in the public part of the Internet either. Conceptually, the segregated network looks like <a class="xref" href="ch05.html#network_with_the_servers_in_a_dmz" title="Figure 5-2. A network with the servers in a DMZ">Figure 5-2</a>.</p><div class="figure"><a id="network_with_the_servers_in_a_dmz"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00009"/><img alt="A network with the servers in a DMZ" src="httpatomoreillycomsourcenostarchimages2127155.png.jpg"/></div></div><div class="figure-title">Figure 5-2. A network with the servers in a DMZ</div></div><div class="note" title="Note"><h3 class="title"><a id="ch05note03"/>Note</h3><p><span class="emphasis"><em>Think of this little network as a zone of relative calm between the territories of hostile factions. It’s no great surprise that a few years back, someone coined the phrase</em></span> demilitarized zone (DMZ) <span class="emphasis"><em>to describe this type of configuration.</em></span></p></div><p><a class="indexterm" id="iddle1406"/><a class="indexterm" id="iddle1512"/><a class="indexterm" id="iddle1548"/>For address allocation, you can segment off an appropriately sized chunk of your official address space for the new DMZ network. Alternatively, you can move those parts of your network that don’t have a specific need to run with publicly accessible and routable IPv4 addresses into a NAT environment. Either way, you end up with at least one more interface in your filtering configuration. As you’ll see later, if you’re really short of official IPv4 addresses, it’s possible to run a DMZ setup in all-NAT environments as well.</p><p>The adjustments to the rule set itself don’t need to be extensive. If necessary, you can change the configuration for each interface. The basic rule-set logic remains, but you may need to adjust the definitions of the macros (<code class="literal">webserver</code>, <code class="literal">mailserver</code>, <code class="literal">nameservers</code>, and possibly others) to reflect your new network layout.</p><p>In our example, we could choose to segment off the part of our address ranges where we’ve already placed our servers. If we leave some room for growth, we can set up the IPv4 range for the new <code class="literal">dmz_if</code> on a /25 subnet with a network address and netmask of 192.0.2.128/255.255.255.128. This leaves us with 192.0.2.129 through 192.0.2.254 as the usable address range for hosts in the DMZ. As we’ve already placed our servers in the 2001:db8::baad:f00d: 0/112 network (with a measly 65,536 addresses to play with), the easiest way forward for the IPv6 range is to segment off that network, too, and assign the interface facing the network an appropriate IPv6 address, like the one in <a class="xref" href="ch05.html#network_with_the_servers_in_a_dmz" title="Figure 5-2. A network with the servers in a DMZ">Figure 5-2</a>.</p><p>With that configuration and no changes in the IP addresses assigned to the servers, you don’t really need to touch the rule set at all for the packet filtering to work after setting up a physically segregated DMZ. That’s a nice side effect, which could be due to either laziness or excellent long-range planning. Either way, it underlines the importance of having a sensible address-allocation policy in place.</p><p>It might be useful to tighten up your rule set by editing your <code class="literal">pass</code> rules so the traffic to and from your servers is allowed to pass only on the interfaces that are actually relevant to the services:</p><a id="pro_id00144"/><pre class="programlisting">pass in on $ext_if proto { tcp, udp } to $nameservers port domain&#13;
pass in on $int_if proto { tcp, udp } from $localnet to $nameservers \&#13;
     port domain&#13;
pass out on $dmz_if proto { tcp, udp } to $nameservers port domain&#13;
pass in on $ext_if proto tcp to $webserver port $webports&#13;
pass in on $int_if proto tcp from $localnet to $webserver port $webports&#13;
pass out on $dmz_if proto tcp to $webserver port $webports&#13;
pass in log on $ext_if proto tcp to $mailserver port smtp&#13;
pass in log on $int_if proto tcp from $localnet to $mailserver \&#13;
     port $email&#13;
pass out log on $dmz_if proto tcp to $mailserver port smtp&#13;
pass in on $dmz_if from $mailserver to port smtp&#13;
pass out log on $ext_if proto tcp from $mailserver to port smtp</pre><p>You could choose to make the other <code class="literal">pass</code> rules that reference your local network interface-specific, too, but if you leave them intact, they’ll continue to work.</p></div><div class="sect2" title="Sharing the Load: Redirecting to a Pool of Addresses"><div class="titlepage"><div><div><h3 class="title" id="sharing_the_load_redirecting_to_a_pool_o">Sharing the Load: Redirecting to a Pool of Addresses</h3></div></div></div><p><a class="indexterm" id="iddle1152"/><a class="indexterm" id="iddle1397"/><a class="indexterm" id="iddle1441"/><a class="indexterm" id="iddle1735"/><a class="indexterm" id="iddle1750"/><a class="indexterm" id="iddle1774"/><a class="indexterm" id="iddle1909"/><a class="indexterm" id="iddle2035"/>Once you’ve set up services to be accessible to the world at large, one likely scenario is that over time, one or more of your services will grow more sophisticated and resource-hungry or simply attract more traffic than you feel comfortable serving from a single server.</p><p>There are a number of ways to make several machines share the load of running a service, including ways to fine-tune the service itself. For the network-level load balancing, PF offers the basic functionality you need via redirection to tables or address pools. In fact, you can implement a form of load balancing without even touching your <code class="literal">pass</code> rules, at least if your environment is not yet dual-stack.</p><p>Take the Web server in our example. We already have the macro that represents a service, our Web server. For reasons that will become obvious in a moment, we need to reduce that macro to represent only the public IPv4 address (<code class="literal">webserver = "192.0.2.227"</code>), which, in turn, is associated with the hostname that your users have bookmarked, possibly <span class="emphasis"><em><a class="ulink" href="http://www.example.com" target="_top">www.example.com</a></em></span>. When the time comes to share the load, set up the required number of identical, or at least equivalent, servers and then alter your rule set slightly to introduce the redirection. First, define a table that holds the addresses for your Web server pool’s IPv4 addresses:</p><a id="pro_id00145"/><pre class="programlisting">table &lt;webpool&gt; persist { 192.0.2.214, 192.0.2.215, 192.0.2.216, 192.0.2.217 }</pre><p>Then, perform the redirection:</p><a id="pro_id00146"/><pre class="programlisting">match in on $ext_if protp tcp to $webserver port $webports \&#13;
        rdr-to &lt;webpool&gt; round-robin</pre><p>Unlike the redirections in earlier examples, such as the FTP proxy in <a class="xref" href="ch03.html" title="Chapter 3. Into the Real World">Chapter 3</a>, this rule sets up all members of the <code class="literal">webpool</code> table as potential redirection targets for incoming connections intended for the <code class="literal">webports</code> ports on the <code class="literal">webserver</code> address. Each incoming connection that matches this rule is redirected to one of the addresses in the table, spreading the load across several hosts. You may choose to retire the original Web server once the switch to this redirection is complete, or you may let it be absorbed in the new Web server pool.</p><p>On PF versions earlier than OpenBSD 4.7, the equivalent rule is as follows:</p><a id="pro_id00147"/><pre class="programlisting">rdr on $ext_if proto tcp to $webserver port $webports -&gt; &lt;webpool&gt; round-robin</pre><p>In both cases, the <code class="literal">round-robin</code> option means that PF shares the load between the machines in the pool by cycling through the table of redirection addresses sequentially.</p><p>Some applications expect accesses from each individual source address to always go to the same host in the backend (for example, there are services that depend on client- or session-specific parameters that will be lost if new connections hit a different host in the backend). If your configuration needs to cater to such services, you can add the <code class="literal">sticky-address</code> option <a class="indexterm" id="iddle1153"/><a class="indexterm" id="iddle1396"/><a class="indexterm" id="iddle1407"/><a class="indexterm" id="iddle1442"/><a class="indexterm" id="iddle1484"/><a class="indexterm" id="iddle1513"/><a class="indexterm" id="iddle1549"/><a class="indexterm" id="iddle1752"/><a class="indexterm" id="iddle1764"/><a class="indexterm" id="iddle1765"/><a class="indexterm" id="iddle1771"/>to make sure that new connections from a client are always redirected to the same machine behind the redirection as the initial connection. The downside to this option is that PF needs to maintain source-tracking data for each client, and the default value for maximum source nodes tracked is set at 10,000, which may be a limiting factor. (See <a class="xref" href="ch10.html" title="Chapter 10. Getting Your Setup Just Right">Chapter 10</a> for advice on adjusting this and similar limit values.)</p><p>When even load distribution isn’t an absolute requirement, selecting the redirection address at <code class="literal">random</code> may be appropriate:</p><a id="pro_id00148"/><pre class="programlisting">match in on $ext_if proto tcp to $webserver port $webports \&#13;
        rdr-to &lt;webpool&gt; random</pre><div class="note" title="Note"><h3 class="title"><a id="ch05note04"/>Note</h3><p><span class="emphasis"><em>On pre–OpenBSD 4.7 PF versions, the <code class="literal">random</code> option isn’t supported for redirection to tables or lists of addresses.</em></span></p></div><p>Even organizations with large pools of official, routable IPv4 addresses have opted to introduce NAT between their load-balanced server pools and the Internet at large. This technique works equally well in various NAT-based setups, but moving to NAT offers some additional possibilities and challenges.</p><p>In order to accommodate an IPv4 and IPv6 dual-stack environment in this way, you’ll need to set up separate tables for address pools and separate <code class="literal">pass</code> or <code class="literal">match</code> rules with redirections for IPv4 and IPv6. A single table of both IPv4 and IPv6 addresses may sound like an elegant idea at first, but the simple redirection rules outlined here aren’t intelligent enough to make correct redirection decisions based on the address family of individual table entries.</p></div><div class="sect2" title="Getting Load Balancing Right with relayd"><div class="titlepage"><div><div><h3 class="title" id="getting_load_balancing_right_with_relayd">Getting Load Balancing Right with relayd</h3></div></div></div><p>After you’ve been running for a while with load balancing via round-robin redirection, you may notice that the redirection doesn’t automatically adapt to external conditions. For example, unless special steps are taken, if a host in the list of redirection targets goes down, traffic will still be redirected to the IP addresses in the list of possibilities.</p><p>Clearly, a monitoring solution is needed. Fortunately, the OpenBSD base system provides one. The relay daemon <code class="literal">relayd</code><sup>[<a class="footnote" epub:type="noteref" href="#ftn.ch05fn02" id="ch05fn02">26</a>]</sup> interacts with your PF configuration, providing the ability to weed out nonfunctioning hosts from your pool. Introducing <code class="literal">relayd</code> into your setup, however, may require some minor changes to your rule set.</p><p>The <code class="literal">relayd</code> daemon works in terms of two main classes of services that it refers to as <span class="emphasis"><em>redirects</em></span> and <span class="emphasis"><em>relays</em></span>. It expects to be able to add or subtract hosts’ IP addresses to or from the PF tables it controls. The daemon interacts <a class="indexterm" id="iddle1051"/><a class="indexterm" id="iddle1738"/><a class="indexterm" id="iddle2036"/>with your rule set through a special-purpose anchor named <code class="literal">relayd</code> (and in pre–OpenBSD 4.7 versions, also a redirection anchor, <code class="literal">rdr-anchor</code>, with the same name).</p><p>To see how we can make our sample configuration work a little better by using <code class="literal">relayd</code>, we’ll look back at the load-balancing rule set. Starting from the top of your <span class="emphasis"><em>pf.conf</em></span> file, add the anchor for <code class="literal">relayd</code> to insert rules as needed:</p><a id="pro_id00149"/><pre class="programlisting">anchor "relayd/*"</pre><p>On pre–OpenBSD 4.7 versions, you also need the redirection anchor:</p><a id="pro_id00150"/><pre class="programlisting">rdr-anchor "relayd/*" anchor "relayd/*"</pre><p>In the load-balancing rule set, we had the following definition for our Web server pool:</p><a id="pro_id00151"/><pre class="programlisting">table webpool persist { 192.0.2.214, 192.0.2.215, 192.0.2.216, 192.0.2.217 }</pre><p>It has this <code class="literal">match</code> rule to set up the redirection:</p><a id="pro_id00152"/><pre class="programlisting">match in on $ext_if proto tcp to $webserver port $webports \&#13;
         rdr-to &lt;webpool&gt; round-robin</pre><p>Or on pre–OpenBSD 4.7 versions, you’d use the following:</p><a id="pro_id00153"/><pre class="programlisting">rdr on $ext_if proto tcp to $webserver port $webports -&gt; &lt;webpool&gt; round-robin</pre><p>To make this configuration work slightly better, we remove the redirection and the table (remember to take care of both sets in a dual-stack configuration), and we let <code class="literal">relayd</code> handle the redirection or redirections by setting up its own versions inside the anchor. (Don’t remove the <code class="literal">pass</code> rule, however, because your rule set will still need to have a <code class="literal">pass</code> rule that lets traffic flow to the IP addresses in <code class="literal">relayd</code>’s tables. If you had separate rules for your <code class="literal">inet</code> and <code class="literal">inet6</code> traffic, you may be able to merge those rules back into one.)</p><p>Once the <span class="emphasis"><em>pf.conf</em></span> parts have been taken care of, we turn to <code class="literal">relayd</code>’s own <span class="emphasis"><em>relayd.conf</em></span> configuration file. The syntax in this configuration file is similar enough to <span class="emphasis"><em>pf.conf</em></span> to make it fairly easy to read and understand. First, we add the macro definitions we’ll be using later:</p><a id="pro_id00154"/><pre class="programlisting">web1="192.0.2.214"&#13;
web2="192.0.2.215"&#13;
web3="192.0.2.216"&#13;
web4="192.0.2.217"&#13;
webserver="192.0.2.227"&#13;
sorry_server="192.0.2.200"</pre><p><a class="indexterm" id="iddle1335"/><a class="indexterm" id="iddle1408"/><a class="indexterm" id="iddle1740"/><a class="indexterm" id="iddle1768"/><a class="indexterm" id="iddle1910"/>All of these correspond to definitions we could have put in a <span class="emphasis"><em>pf.conf</em></span> file. The default checking interval in <code class="literal">relayd</code> is 10 seconds, which means that a host could be down for almost 10 seconds before it’s taken offline. Being cautious, we’ll set the checking interval to 5 seconds to minimize visible downtime, with the following line:</p><a id="pro_id00155"/><pre class="programlisting">interval 5 # check hosts every 5 seconds</pre><p>Now, we make a table called <code class="literal">webpool</code> that uses most of the macros:</p><a id="pro_id00156"/><pre class="programlisting">table &lt;webpool&gt; { $web1, $web2, $web3, $web4 }</pre><p>For reasons we’ll return to shortly, we define one other table:</p><a id="pro_id00157"/><pre class="programlisting">table &lt;sorry&gt; { $sorry_server }</pre><p>At this point, we’re ready to set up the redirect:</p><a id="pro_id00158"/><pre class="programlisting">redirect www {&#13;
       listen on $webserver port 80 sticky-address&#13;
       tag relayd&#13;
       forward to &lt;webpool&gt; check http "/status.html" code 200 timeout 300&#13;
       forward to &lt;sorry&gt; timeout 300 check icmp&#13;
}</pre><p>This redirect says that connections to port 80 should be redirected to the members of the <code class="literal">webpool</code> table. The <code class="literal">sticky-address</code> option has the same effect here as the <code class="literal">rdr-to</code> in PF rules: New connections from the same source IP address (within the time interval defined by the <code class="literal">timeout</code> value) are redirected to the same host in the backend pool as the previous ones.</p><p>The <code class="literal">relayd</code> daemon should check to see whether a host is available by asking it for the file <span class="emphasis"><em>/status.html</em></span>, using the protocol HTTP, and expecting the return code to be equal to 200. This is the expected result for a client asking a running Web server for a file it has available.</p><p>No big surprises so far, right? The <code class="literal">relayd</code> daemon will take care of excluding hosts from the table if they go down. But what if all the hosts in the <code class="literal">webpool</code> table go down? Fortunately, the developers thought of that, too, and introduced the concept of backup tables for services. This is the last part of the definition for the <code class="literal">www</code> service, with the table <code class="literal">sorry</code> as the backup table: The hosts in the <code class="literal">sorry</code> table take over if the <code class="literal">webpool</code> table becomes empty. This means that you need to configure a service that’s able to offer a “Sorry, we’re down” message in case all the hosts in your <code class="literal">webpool</code> fail.</p><p>If you’re running an IPv6-only service, you should, of course, substitute your IPv6 addresses for the ones given in the example earlier. If you’re running a dual-stack setup, you should probably set up the load-balancing mechanism separately for each protocol, where the configurations differ only in names (append a <code class="literal">4</code> or <code class="literal">6</code>, for example, to the IPv4 and IPv6 sets of names, respectively) and the addresses themselves.</p><p><a class="indexterm" id="iddle1763"/><a class="indexterm" id="iddle1767"/>With all of the elements of a valid <code class="literal">relayd</code> configuration in place, you can enable your new configuration.</p><p>Before you actually start <code class="literal">relayd</code>, add an empty set of <code class="literal">relayd_flags</code> to your <span class="emphasis"><em>/etc/rc.conf.local</em></span> to enable:</p><a id="pro_id00159"/><pre class="programlisting">relayd_flags="" # for normal use: ""</pre><p>Reload your PF rule set and then start <code class="literal">relayd</code>. If you want to check your configuration before actually starting <code class="literal">relayd</code>, you can use the <code class="literal">-n</code> command-line option to <code class="literal">relayd</code>:</p><a id="pro_id00160"/><pre class="programlisting">$ <span class="strong"><strong>sudo relayd -n</strong></span></pre><p>If your configuration is correct, <code class="literal">relayd</code> displays the message <code class="literal">configuration OK</code> and exits.</p><p>To actually start the daemon, you could start <code class="literal">relayd</code> without any command-line flags, but as with most daemons, it’s better to start it via its <code class="literal">rc</code> script wrapper stored in <span class="emphasis"><em>/etc/rc.d/</em></span>, so the following sequence reloads your edited PF configuration and enables <code class="literal">relayd</code>.</p><a id="pro_id00161"/><pre class="programlisting"><span class="strong"><strong>$ sudo pfctl -f /etc/pf.conf</strong></span>&#13;
<span class="strong"><strong>$ sudo sh /etc/rc.d/relayd start</strong></span></pre><p>With a correct configuration, both commands will silently start, without displaying any messages. (If you prefer more verbose messages, both <code class="literal">pfctl</code> and <code class="literal">relayd</code> offer the <code class="literal">-v</code> flag. For <code class="literal">relayd</code>, you may want to add the <code class="literal">-v</code> flag to the <span class="emphasis"><em>rc.conf.local</em></span> entry.) You can check that <code class="literal">relayd</code> is running with <code class="literal">top</code> or <code class="literal">ps</code>. In both cases, you’ll find three <code class="literal">relayd</code> processes, roughly like this:</p><a id="pro_id00162"/><pre class="programlisting"><span class="strong"><strong>$ ps waux | grep relayd</strong></span>&#13;
_relayd   9153  0.0   0.1  776  1424  ??  S   7:28PM   0:00.01 relayd: pf update engine&#13;
(relayd)&#13;
_relayd   6144  0.0   0.1  776  1440  ??  S   7:28PM   0:00.02 relayd: host check engine&#13;
(relayd)&#13;
root      3217  0.0   0.1  776  1416  ??  Is  7:28PM   0:00.01 relayd: parent (relayd)</pre><p>And as we mentioned earlier, with an empty set of <code class="literal">relayd_flags</code> in your <span class="emphasis"><em>rc.conf.local</em></span> file, <code class="literal">relayd</code> is enabled at startup. However, once the configuration is enabled, most of your interaction with <code class="literal">relayd</code> will happen through the <code class="literal">relayctl</code> administration program. In addition to letting you monitor status, <code class="literal">relayctl</code> lets you reload the <code class="literal">relayd</code> configuration and selectively disable or enable hosts, tables, and services. You can even view service status interactively, as follows:</p><a id="pro_id00163"/><pre class="programlisting"><span class="strong"><strong>$ sudo relayctl show summary</strong></span>&#13;
Id      Type            Name                                 Avlblty Status&#13;
1       redirect        www                                          active&#13;
1       table           webpool:80                                   active (2 hosts)&#13;
1       host            192.0.2.214                          100.00% up&#13;
2       host            192.0.2.215                          0.00%   down&#13;
3       host            192.0.2.216                          100.00% up&#13;
4       host            192.0.2.217                          0.00%   down&#13;
2       table           sorry:80                                     active (1 hosts)&#13;
5       host            127.0.0.1                            100.00% up</pre><p><a class="indexterm" id="iddle1131"/><a class="indexterm" id="iddle1336"/><a class="indexterm" id="iddle1340"/><a class="indexterm" id="iddle1769"/><a class="indexterm" id="iddle2037"/>In this example, the <code class="literal">webpool</code> is seriously degraded, with only two of four hosts up and running. Fortunately, the backup table is still functioning, and hopefully it’ll still be up if the last two servers fail as well. For now, all tables are active with at least one host up. For tables that no longer have any members, the <code class="literal">Status</code> column changes to empty. Asking <code class="literal">relayctl</code> for host information shows the status information in a host-centered format:</p><a id="pro_id00164"/><pre class="programlisting"><span class="strong"><strong>$ sudo relayctl show hosts</strong></span>&#13;
Id      Type            Name                              Avlblty Status&#13;
1       table           webpool:80                                active (3 hosts)&#13;
1       host            192.0.2.214                       100.00% up&#13;
                        total: 11340/11340 checks&#13;
2       host            192.0.2.215                       0.00%   down&#13;
                        total: 0/11340 checks, error: tcp connect failed&#13;
3       host            192.0.2.216                       100.00% up&#13;
                        total: 11340/11340 checks&#13;
4       host            192.0.2.217                       0.00%   down&#13;
                        total: 0/11340 checks, error: tcp connect failed&#13;
2       table           sorry:80                                  active (1 hosts)&#13;
5       host            127.0.0.1                         100.00% up&#13;
                        total: 11340/11340 checks</pre><p>If you need to take a host out of the pool for maintenance (or any time-consuming operation), you can use <code class="literal">relayctl</code> to disable it, as follows:</p><a id="pro_id00165"/><pre class="programlisting">$ <span class="strong"><strong>sudo relayctl host disable 192.0.2.217</strong></span></pre><p>In most cases, the operation will display <code class="literal">command succeeded</code> to indicate that the operation completed successfully. Once you’ve completed maintenance and put the machine online, you can reenable it as part of <code class="literal">relayd</code>’s pool with this command:</p><a id="pro_id00166"/><pre class="programlisting">$ <span class="strong"><strong>sudo relayctl host enable 192.0.2.217</strong></span></pre><p>Again, you should see the message <code class="literal">command succeeded</code> almost immediately to indicate that the operation was successful.</p><p>In addition to the basic load balancing demonstrated here, <code class="literal">relayd</code> has been extended in recent OpenBSD versions to offer several features that make it attractive in more complex settings. For example, it can now handle Layer 7 proxying or relaying functions for HTTP and HTTPS, including protocol handling with header append and rewrite, URL-path append and rewrite, and even session and cookie handling. The protocol handling needs to be tailored to your application. For example, the following is a simple HTTPS relay for load balancing the encrypted Web traffic from clients to the Web servers.</p><a id="pro_id00167"/><pre class="programlisting">http protocol "httpssl" {&#13;
          header append "$REMOTE_ADDR" to "X-Forwarded-For"&#13;
          header append "$SERVER_ADDR:$SERVER_PORT" to "X-Forwarded-By"&#13;
          header change "Keep-Alive" to "$TIMEOUT"&#13;
          query hash "sessid"&#13;
          cookie hash "sessid"&#13;
          path filter "*command=*" from "/cgi-bin/index.cgi"&#13;
&#13;
          ssl { sslv2, ciphers "MEDIUM:HIGH" }&#13;
          tcp { nodelay, sack, socket buffer 65536, backlog 128 }&#13;
}</pre><p><a class="indexterm" id="iddle1770"/><a class="indexterm" id="iddle1893"/><a class="indexterm" id="iddle1949"/>This protocol handler definition demonstrates a range of simple operations on the HTTP headers and sets both SSL parameters and specific TCP parameters to optimize connection handling. The header options operate on the protocol headers, inserting the values of the variables by either appending to existing headers (<code class="literal">append</code>) or changing the content to a new value (<code class="literal">change</code>).</p><p>The URL and cookie hashes are used by the load balancer to select to which host in the target pool the request is forwarded. The <code class="literal">path filter</code> specifies that any <code class="literal">get</code> request, including the first quoted string as a substring of the second, is to be dropped. The <code class="literal">ssl</code> options specify that only SSL version 2 ciphers are accepted, with key lengths in the medium-to-high range—in other words, 128 bits or more.<sup>[<a class="footnote" epub:type="noteref" href="#ftn.ch05fn03" id="ch05fn03">27</a>]</sup> Finally, the <code class="literal">tcp</code> options specify <code class="literal">nodelay</code> to minimize delays, specify the use of the selective acknowledgment method (RFC 2018), and set the socket buffer size and the maximum allowed number of pending connections the load balancer keeps track of. These options are examples only; in most cases, your application will perform well with these settings at their default values.</p><p>The relay definition using the protocol handler follows a pattern that should be familiar given the earlier definition of the <code class="literal">www</code> service:</p><a id="pro_id00168"/><pre class="programlisting">relay wwwssl {&#13;
          # Run as a SSL accelerator&#13;
          listen on $webserver port 443 ssl&#13;
          protocol "httpssl"&#13;
          table &lt;webhosts&gt; loadbalance check ssl&#13;
}</pre><p>Still, your SSL-enabled Web applications will likely benefit from a slightly different set of parameters.</p><div class="note" title="Note"><h3 class="title"><a id="ch05note05"/>Note</h3><p><span class="emphasis"><em>We’ve added a <code class="literal">check ssl</code>, assuming that each member of the <code class="literal">webhosts</code> table is properly configured to complete an SSL handshake. Depending on your application, it may be useful to look into keeping all SSL processing in <code class="literal">relayd</code>, thus offloading the encryption-handling tasks from the backends.</em></span></p></div><p><a class="indexterm" id="iddle1115"/><a class="indexterm" id="iddle1132"/><a class="indexterm" id="iddle1140"/><a class="indexterm" id="iddle1176"/><a class="indexterm" id="iddle1228"/><a class="indexterm" id="iddle1243"/><a class="indexterm" id="iddle1341"/><a class="indexterm" id="iddle1477"/><a class="indexterm" id="iddle1485"/><a class="indexterm" id="iddle1514"/><a class="indexterm" id="iddle1550"/><a class="indexterm" id="iddle1766"/><a class="indexterm" id="iddle2033"/>Finally, for CARP-based failover of the hosts running <code class="literal">relayd</code> on your network (see <a class="xref" href="ch08.html" title="Chapter 8. Redundancy and Resource Availability">Chapter 8</a> for information about CARP), <code class="literal">relayd</code> can be configured to support CARP interaction by setting the CARP demotion counter for the specified interface groups at shutdown or startup.</p><p>Like all others parts of the OpenBSD system, <code class="literal">relayd</code> comes with informative man pages. For the angles and options not covered here (there are a few), dive into the man pages for <code class="literal">relayd</code>, <code class="literal">relayd.conf</code>, and <code class="literal">relayctl</code> and start experimenting to find just the configuration you need.</p></div></div><div class="sect1" title="A Web Server and Mail Server on the Inside—The NAT Version"><div class="titlepage"><div><div><h2 class="title" id="web_server_and_mail_server_on_th-id00001" style="clear: both">A Web Server and Mail Server on the Inside—The NAT Version</h2></div></div></div><p>Let’s backtrack a little and begin again with the baseline scenario where the sample clients from <a class="xref" href="ch03.html" title="Chapter 3. Into the Real World">Chapter 3</a> get three new neighbors: a mail server, a Web server, and a file server. This time around, externally visible IPv4 addresses are either not available or too expensive, and running several other services on a machine that’s primarily a firewall isn’t desirable. This means we’re back to the situation where we do our NAT at the gateway. Fortunately, the redirection mechanisms in PF make it relatively easy to keep servers on the inside of a gateway that performs NAT.</p><p>The network specifications are the same as for the <span class="emphasis"><em>example.com</em></span> setup we just worked through: We need to run a Web server that serves up data in cleartext (<code class="literal">http</code>) and encrypted (<code class="literal">https</code>) form, and we want a mail server that sends and receives email while letting clients inside and outside the local network use a number of well-known submission and retrieval protocols. In short, we want pretty much the same features as in the setup from the previous section, but with only one routable address.</p><p>Of the three servers, only the Web server and the mail server need to be visible to the outside world, so we add macros for their IP addresses and services to the <a class="xref" href="ch03.html" title="Chapter 3. Into the Real World">Chapter 3</a> rule set:</p><a id="pro_id00169"/><pre class="programlisting">webserver = "192.168.2.7"&#13;
webports = "{ http, https }"&#13;
emailserver = "192.168.2.5"&#13;
email = "{ smtp, pop3, imap, imap3, imaps, pop3s }"</pre><p>With only one routable address and the servers hidden in NATed address space, we need to set up rules at the gateway that redirect the traffic we want our servers to handle. We could define a set of <code class="literal">match</code> rules to set up the redirection and then address the <code class="literal">block</code> or <code class="literal">pass</code> question in a separate set of rules later, like this:</p><a id="pro_id00170"/><pre class="programlisting">match in on $ext_if proto tcp to $ext_if port $webports rdr-to $webserver&#13;
match in on $ext_if proto tcp to $ext_if port $email rdr-to $emailserver&#13;
&#13;
pass proto tcp to $webserver port $webports&#13;
pass proto tcp to $emailserver port $email&#13;
pass proto tcp from $emailserver to port smtp</pre><p><a class="indexterm" id="iddle1141"/><a class="indexterm" id="iddle1192"/><a class="indexterm" id="iddle1741"/>This combination of <code class="literal">match</code> and <code class="literal">pass</code> rules is very close to the way things were done in pre–OpenBSD 4.7 PF versions, and if you’re upgrading from a previous version, this is the kind of quick edit that could bridge the syntax gap quickly. But you could also opt to go for the new style and write this slightly more compact version instead:</p><a id="pro_id00171"/><pre class="programlisting">pass in on $ext_if inet proto tcp to $ext_if port $webports rdr-to $webserver tag RDR&#13;
pass in on $ext_if inet proto tcp to $ext_if port $email rdr-to $mailserver tag RDR&#13;
pass on $int_if inet tagged RDR</pre><p>Note the use of <code class="literal">pass</code> rules with <code class="literal">rdr-to</code>. This combination of filtering and redirection will help make things easier in a little while, so try this combination for now.</p><p>On pre–OpenBSD 4.7 PF, the rule set will be quite similar, except in the way that we handle the redirections.</p><a id="pro_id00172"/><pre class="programlisting">webserver = "192.168.2.7"&#13;
webports = "{ http, https }"&#13;
emailserver = "192.168.2.5"&#13;
email = "{ smtp, pop3, imap, imap3, imaps, pop3s }"&#13;
&#13;
rdr on $ext_if proto tcp to $ext_if port $webports -&gt; $webserver&#13;
rdr on $ext_if proto tcp to $ext_if port $email -&gt; $emailserver&#13;
&#13;
pass proto tcp to $webserver port $webports&#13;
pass proto tcp to $emailserver port $email&#13;
pass proto tcp from $emailserver to any port smtp</pre><div class="sect2" title="DMZ with NAT"><div class="titlepage"><div><div><h3 class="title" id="dmz_with_nat">DMZ with NAT</h3></div></div></div><p>With an all-NAT setup, the pool of available addresses to allocate for a DMZ is likely to be larger than in our previous example, but the same principles apply. When you move the servers off to a physically separate network, you’ll need to check that your rule set’s macro definitions are sane and adjust the values if necessary.</p><p>Just as in the routable-addresses case, it might be useful to tighten up your rule set by editing your pass rules so the traffic to and from your servers is allowed to pass on only the interfaces that are actually relevant to the services:</p><a id="pro_id00173"/><pre class="programlisting">pass in on $ext_if inet proto tcp to $ext_if port $webports rdr-to $webserver&#13;
pass in on $int_if inet proto tcp from $localnet to $webserver port $webports&#13;
pass out on $dmz_if proto tcp to $webserver port $webports&#13;
pass in log on $ext_if inet proto tcp to $ext_if port $email rdr-to $mailserver&#13;
pass in log on $int_if proto tcp from $localnet to $mailserver port $email&#13;
pass out log on $dmz_if proto tcp to $mailserver port smtp&#13;
pass in on $dmz_if from $mailserver to port smtp&#13;
pass out log on $ext_if proto tcp from $mailserver to port smtp</pre><p><a class="indexterm" id="iddle1142"/><a class="indexterm" id="iddle1143"/><a class="indexterm" id="iddle1409"/><a class="indexterm" id="iddle1440"/><a class="indexterm" id="iddle1523"/><a class="indexterm" id="iddle1749"/>The version for pre–OpenBSD 4.7 PF differs in some details, with the redirection still in separate rules:</p><a id="pro_id00174"/><pre class="programlisting">pass in on $ext_if proto tcp to $webserver port $webports&#13;
pass in on $int_if proto tcp from $localnet to $webserver port $webports&#13;
pass out on $dmz_if proto tcp to $webserver port $webports&#13;
pass in log on $ext_if proto tcp to $mailserver port smtp&#13;
pass in log on $int_if proto tcp from $localnet to $mailserver port $email&#13;
pass out log on $dmz_if proto tcp to $mailserver port smtp&#13;
pass in on $dmz_if from $mailserver to port smtp&#13;
pass out log on $ext_if proto tcp from $mailserver to port smtp</pre><p>You could create specific <code class="literal">pass</code> rules that reference your local network interface, but if you leave the existing <code class="literal">pass</code> rules intact, they’ll continue to work.</p></div><div class="sect2" title="Redirection for Load Balancing"><div class="titlepage"><div><div><h3 class="title" id="redirection_for_load_balancing">Redirection for Load Balancing</h3></div></div></div><p>The redirection-based load-balancing rules from the previous example work equally well in a NAT regime, where the public address is the gateway’s external interface and the redirection addresses are in a private range.</p><p>Here’s the <code class="literal">webpool</code> definition:</p><a id="pro_id00175"/><pre class="programlisting">table &lt;webpool&gt; persist { 192.168.2.7, 192.168.2.8, 192.168.2.9, 192.168.2.10 }</pre><p>The main difference between the routable-address case and the NAT version is that after you’ve added the <code class="literal">webpool</code> definition, you edit the existing <code class="literal">pass</code> rule with redirection, which then becomes this:</p><a id="pro_id00176"/><pre class="programlisting">pass in on $ext_if inet proto tcp to $ext_if port $webports rdr-to &lt;webpool&gt; round-robin</pre><p>Or for pre–OpenBSD 4.7 PF versions, use this:</p><a id="pro_id00177"/><pre class="programlisting">rdr on $ext_if proto tcp to $ext_if port $webports -&gt; &lt;webpool&gt; round-robin</pre><p>From that point on, your NATed DMZ behaves much like the one with official, routable addresses.</p><div class="note" title="Note"><h3 class="title"><a id="ch05note06"/>Note</h3><p><span class="emphasis"><em>You can configure a valid IPv6 setup to coexist with a NATed IPv4 setup like this one, but if you choose to do so, be sure to treat inet and inet6 traffic separately in your PF rules. And contrary to popular belief, rules with nat-to and rdr-to options work in IPv6 configurations the same as in IPv4.</em></span></p></div></div><div class="sect2" title="Back to the Single NATed Network"><div class="titlepage"><div><div><h3 class="title" id="back_to_the_single_nated_network">Back to the Single NATed Network</h3></div></div></div><p>It may surprise you to hear that there are cases where setting up a small network is more difficult than working with a large one. For example, returning to the situation where the servers are on the same physical <a class="indexterm" id="iddle1222"/>network as the clients, the basic NATed configuration works very well—up to a point. In fact, everything works brilliantly as long as all you’re interested in is getting traffic from hosts outside your local network to reach your servers.</p><p>Here’s the full configuration:</p><a id="pro_id00178"/><pre class="programlisting">ext_if = "re0" # macro for external interface - use tun0 or pppoe0 for PPPoE&#13;
int_if = "re1" # macro for internal interface&#13;
localnet = $int_if:network&#13;
# for ftp-proxy&#13;
proxy = "127.0.0.1"&#13;
icmp_types = "{ echoreq, unreach }"&#13;
client_out = "{ ssh, domain, pop3, auth, nntp, http, https, \&#13;
                446, cvspserver, 2628, 5999, 8000, 8080 }"&#13;
udp_services = "{ domain, ntp }"&#13;
webserver = "192.168.2.7"&#13;
webports = "{ http, https }"&#13;
emailserver = "192.168.2.5"&#13;
email = "{ smtp, pop3, imap, imap3, imaps, pop3s }"&#13;
# NAT: ext_if IP address could be dynamic, hence ($ext_if)&#13;
match out on $ext_if from $localnet nat-to ($ext_if)&#13;
block all&#13;
# for ftp-proxy: Remember to put the following line, uncommented, in your&#13;
# /etc/rc.conf.local to enable ftp-proxy:&#13;
# ftpproxy_flags=""&#13;
anchor "ftp-proxy/*"&#13;
pass in quick proto tcp to port ftp rdr-to $proxy port 8021&#13;
pass out proto tcp from $proxy to port ftp&#13;
pass quick inet proto { tcp, udp } to port $udp_services&#13;
pass proto tcp to port $client_out&#13;
# allow out the default range for traceroute(8):&#13;
# "base+nhops*nqueries-1" (33434+64*3-1)&#13;
pass out on $ext_if inet proto udp to port 33433 &gt;&lt; 33626 keep state&#13;
# make sure icmp passes unfettered&#13;
pass inet proto icmp icmp-type $icmp_types from $localnet&#13;
pass inet proto icmp icmp-type $icmp_types to $ext_if&#13;
pass in on $ext_if inet proto tcp to $ext_if port $webports rdr-to $webserver&#13;
pass in on $ext_if inet proto tcp to $ext_if port $email rdr-to $mailserver&#13;
pass on $int_if inet proto tcp to $webserver port $webports&#13;
pass on $int_if inet proto tcp to $mailserver port $email</pre><p>The last four rules here are the ones that interest us the most. If you try to reach the services on the official address from hosts in your own network, you’ll soon see that the requests for the redirected services from machines in your local network most likely never reach the external interface. This is because all the redirection and translation happens on the external interface. The gateway receives the packets from your local network on the internal interface, with the destination address set to the external interface’s address. The gateway recognizes the address as one of its own and tries to handle the request as if it were directed at a local service; as a consequence, the redirections don’t quite work from the inside.</p><p><a class="indexterm" id="iddle1486"/><a class="indexterm" id="iddle1524"/><a class="indexterm" id="iddle1742"/>The equivalent part to those last four lines of the preceding rule set for pre–OpenBSD 4.7 systems looks like this:</p><a id="pro_id00179"/><pre class="programlisting">rdr on $ext_if proto tcp to $ext_if port $webports -&gt; $webserver&#13;
rdr on $ext_if proto tcp to $ext_if port $email -&gt; $emailserver&#13;
&#13;
pass proto tcp to $webserver port $webports&#13;
pass proto tcp to $emailserver port $email&#13;
pass proto tcp from $emailserver to any port smtp</pre><p>Fortunately, several work-arounds for this particular problem are possible. The problem is common enough that the PF User Guide lists four different solutions to the problem,<sup>[<a class="footnote" href="#ftn.ch05fn04" id="ch05fn04">28</a>]</sup> including moving your servers to a DMZ, as described earlier. Because this is a PF book, we’ll concentrate on a PF-based solution (actually a pretty terrible work-around), which consists of treating the local network as a special case for our redirection and NAT rules.</p><p>We need to intercept the network packets originating in the local network and handle those connections correctly, making sure that any return traffic is directed to the communication partner who actually originated the connection. This means that in order for the redirections to work as expected from the local network, we need to add special-case redirection rules that mirror the ones designed to handle requests from the outside. First, here are the <code class="literal">pass</code> rules with redirections for OpenBSD 4.7 and newer:</p><a id="pro_id00180"/><pre class="programlisting">pass in on $ext_if inet proto tcp to $ext_if port $webports rdr-to $webserver&#13;
pass in on $ext_if inet proto tcp to $ext_if port $email rdr-to $mailserver&#13;
pass in log on $int_if inet proto tcp from $int_if:network to $ext_if \&#13;
port $webports rdr-to $webserver&#13;
pass in log on $int_if inet proto tcp from $int_if:network to $ext_if \&#13;
port $email rdr-to $mailserver&#13;
match out log on $int_if proto tcp from $int_if:network to $webserver \&#13;
port $webports nat-to $int_if&#13;
pass on $int_if inet proto tcp to $webserver port $webports&#13;
match out log on $int_if proto tcp from $int_if:network to $mailserver \&#13;
port $email nat-to $int_if&#13;
pass on $int_if inet proto tcp to $mailserver port $email</pre><p>The first two rules are identical to the original ones. The next two intercept the traffic from the local network, and the <code class="literal">rdr-to</code> actions in both rewrite the destination address, much as the corresponding rules do for the traffic that originates elsewhere. The <code class="literal">pass</code> on <code class="literal">$int_if</code> rules serve the same purpose as in the earlier version.</p><p>The <code class="literal">match</code> rules with <code class="literal">nat-to</code> are there as a routing work-around. Without them, the <code class="literal">webserver</code> and <code class="literal">mailserver</code> hosts would route return traffic for the redirected connections directly back to the hosts in the local network, where the traffic wouldn’t match any outgoing connection. With the <code class="literal">nat-to</code> in <a class="indexterm" id="iddle1139"/><a class="indexterm" id="iddle1362"/><a class="indexterm" id="iddle1374"/>place, the servers consider the gateway as the source of the traffic and will direct return traffic back the same path it came originally. The gateway matches the return traffic to the states created by connections from the clients in the local network and applies the appropriate actions to return the traffic to the correct clients.</p><p>The equivalent rules for pre–OpenBSD 4.7 versions are at first sight a bit more confusing, but the end result is the same.</p><a id="pro_id00181"/><pre class="programlisting">rdr on $int_if proto tcp from $localnet to $ext_if port $webports -&gt; $webserver&#13;
rdr on $int_if proto tcp from $localnet to $ext_if port $email -&gt; $emailserver&#13;
no nat on $int_if proto tcp from $int_if to $localnet&#13;
nat on $int_if proto tcp from $localnet to $webserver port $webports -&gt; $int_if&#13;
nat on $int_if proto tcp from $localnet to $emailserver port $email -&gt; $int_if</pre><p>This way, we twist the redirections and the address translation logic to do what we need, and we don’t need to touch the <code class="literal">pass</code> rules at all. (I’ve had the good fortune to witness via email and IRC the reactions of several network admins at the moment when the truth about this five-line reconfiguration sank in.)</p></div></div><div class="sect1" title="Filtering on Interface Groups"><div class="titlepage"><div><div><h2 class="title" id="filtering_on_interface_groups" style="clear: both">Filtering on Interface Groups</h2></div></div></div><p>Your network could have several subnets that may never need to interact with your local network except for some common services, like email, Web, file, and print. How you handle the traffic from and to such subnets depends on how your network is designed. One useful approach is to treat each less-privileged network as a separate local network attached to its own separate interface on a common filtering gateway and then to give it a rule set that allows only the desired direct interaction with the neighboring networks attached to the main gateway.</p><p>You can make your PF configuration more manageable and readable by grouping logically similar interfaces into interface groups and by applying filtering rules to the groups rather than the individual interfaces. Interface groups, as implemented via the <code class="literal">ifconfig</code> <span class="emphasis"><em>group</em></span> option, originally appeared in OpenBSD 3.6 and have been adopted in FreeBSD 7.0 onward.</p><p>All configured network interfaces can be configured to belong to one or more groups. Some interfaces automatically belong to one of the default groups. For example, all IEEE 802.11 wireless network interfaces belong to the <code class="literal">wlan</code> group, while interfaces associated with the default routes belong to the <code class="literal">egress</code> group. Fortunately, an interface can be a member of several groups, and you can add interfaces to interface groups via the appropriate <code class="literal">ifconfig</code> command, as in this example:</p><a id="pro_id00182"/><pre class="programlisting"># ifconfig sis2 group untrusted</pre><p>For a permanent configuration, the equivalent under OpenBSD would be in the <span class="emphasis"><em>hostname.sis2</em></span> file or the <code class="literal">ifconfig_sis2=</code> line in the <span class="emphasis"><em>rc.conf</em></span> file on FreeBSD 7.0 or later.</p><p><a class="indexterm" id="iddle1147"/><a class="indexterm" id="iddle1490"/><a class="indexterm" id="iddle1604"/><a class="indexterm" id="iddle1940"/><a class="indexterm" id="iddle1942"/>Where it makes sense, you can then treat the interface group much the same as you would handle a single interface in filtering rules:</p><a id="pro_id00183"/><pre class="programlisting">pass in on untrusted to any port $webports&#13;
pass out on egress to any port $webports</pre><p>If by now you’re thinking that in most, if not all, the rule-set examples up to this point, it would be possible to filter on the group <code class="literal">egress</code> instead of the macro <code class="literal">$ext_if</code>, you’ve grasped an important point. It could be a useful exercise to go through any existing rule sets you have and see what using interface groups can do to help readability even further. Remember that an interface group can have one or more members.</p><p>Note that filtering on interface groups makes it possible to write essentially hardware-independent rule sets. As long as your <span class="emphasis"><em>hostname.if</em></span> files or <code class="literal">ifconfig_if=</code> lines put the interfaces in the correct groups, rule sets that consistently filter on interface groups will be fully portable between machines that may or may not have identical hardware configurations.</p><p>On systems where the interface group feature isn’t available, you may be able to achieve some of the same effects via creative use of macros, as follows:</p><a id="pro_id00184"/><pre class="programlisting">untrusted = "{ ath0 ath1 wi0 ep0 }"&#13;
egress = "sk0"</pre></div><div class="sect1" title="The Power of Tags"><div class="titlepage"><div><div><h2 class="title" id="power_of_tags" style="clear: both">The Power of Tags</h2></div></div></div><p>In some networks, the decision of where a packet should be allowed to pass can’t be made to map easily to criteria like subnet and service. The fine-grained control the site’s policy demands could make the rule set complicated and potentially hard to maintain.</p><p>Fortunately, PF offers yet another mechanism for classification and filtering in the form of <span class="emphasis"><em>packet tagging</em></span>. The useful way to implement packet tagging is to <code class="literal">tag</code> incoming packets that match a specific <code class="literal">pass</code> rule and then let the packets pass elsewhere based on which identifiers the packet is <code class="literal">tagged</code> with. In OpenBSD 4.6 and later, it’s even possible to have separate <code class="literal">match</code> rules that <code class="literal">tag</code> according to the match criteria, leaving decisions on passing, redirecting, or taking other actions to rules later in the rule set.</p><p>One example could be the wireless access points we set up in <a class="xref" href="ch04.html" title="Chapter 4. Wireless Networks Made Easy">Chapter 4</a>, which we could reasonably expect to inject traffic into the local network with an apparent source address equal to the access point’s <code class="literal">$ext_if</code> address. In that scenario, a useful addition to the rule set of a gateway with several of these access points might be the following (assuming, of course, that definitions of the <code class="literal">wifi_allowed</code> and <code class="literal">wifi_ports</code> macros fit the site’s requirements):</p><a id="pro_id00185"/><pre class="programlisting">wifi = "{ 10.0.0.115, 10.0.0.125, 10.0.0.135, 10.0.0.145 }"&#13;
pass in on $int_if from $wifi to $wifi_allowed port $wifi_ports tag wifigood&#13;
pass out on $ext_if tagged wifigood</pre><p><a class="indexterm" id="iddle1093"/><a class="indexterm" id="iddle1094"/><a class="indexterm" id="iddle1096"/><a class="indexterm" id="iddle1097"/><a class="indexterm" id="iddle1134"/><a class="indexterm" id="iddle1960"/>As the complexity of the rule set grows, consider using <code class="literal">tag</code> in incoming <code class="literal">match</code> and <code class="literal">pass</code> rules to make your rule set readable and easier to maintain.</p><p>Tags are sticky, and once a packet has been tagged by a matching rule, the tag stays, which means that a packet can have a tag even if it wasn’t applied by the last matching rule. However, a packet can have only one tag at any time. If a packet matches several rules that apply tags, the tag will be overwritten with a new one by each new matching <code class="literal">tag</code> rule.</p><p>For example, you could set several tags on incoming traffic via a set of <code class="literal">match</code> or <code class="literal">pass</code> rules, supplemented by a set of <code class="literal">pass</code> rules that determine where packets pass out based on the tags set on the incoming traffic.</p></div><div class="sect1" title="The Bridging Firewall"><div class="titlepage"><div><div><h2 class="title" id="bridging_firewall" style="clear: both">The Bridging Firewall</h2></div></div></div><p>An Ethernet <span class="emphasis"><em>bridge</em></span> consists of two or more interfaces that are configured to forward Ethernet frames transparently and that aren’t directly visible to the upper layers, such as the TCP/IP stack. In a filtering context, the bridge configuration is often considered attractive because it means that the filtering can be performed on a machine that doesn’t have its own IP addresses. If the machine in question runs OpenBSD or a similarly capable operating system, it can still filter and redirect traffic.</p><p>The main advantage of such a setup is that attacking the firewall itself is more difficult.<sup>[<a class="footnote" epub:type="noteref" href="#ftn.ch05fn05" id="ch05fn05">29</a>]</sup> The disadvantage is that all admin tasks must be performed at the firewall’s console, unless you configure a network interface that’s reachable via a secured network of some kind or even a serial console. It also follows that bridges with no IP address configured can’t be set as the gateway for a network and can’t run any services on the bridged interfaces. Rather, you can think of a bridge as an intelligent bulge on the network cable, which can filter and redirect.</p><p>A few general caveats apply to using firewalls implemented as bridges:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The interfaces are placed in promiscuous mode, which means that they’ll receive (and to some extent process) every packet on the network.</p></li><li class="listitem"><p>Bridges operate on the Ethernet level and, by default, forward all types of packets, not just TCP/IP.</p></li><li class="listitem"><p>The lack of IP addresses on the interfaces makes some of the more effective redundancy features, such as CARP, unavailable.</p></li></ul></div><p>The method for configuring bridges differs among operating systems in some details. The following examples are very basic and don’t cover all possible wrinkles, but they should be enough to get you started.</p><div class="sect2" title="Basic Bridge Setup on OpenBSD"><div class="titlepage"><div><div><h3 class="title" id="basic_bridge_setup_on_openbsd">Basic Bridge Setup on OpenBSD</h3></div></div></div><p><a class="indexterm" id="iddle1085"/><a class="indexterm" id="iddle1091"/><a class="indexterm" id="iddle1101"/><a class="indexterm" id="iddle1137"/><a class="indexterm" id="iddle1361"/><a class="indexterm" id="iddle1466"/><a class="indexterm" id="iddle1568"/><a class="indexterm" id="iddle1941"/>The OpenBSD GENERIC kernel contains all the necessary code to configure bridges and filter on them. Unless you’ve compiled a custom kernel without the bridge code, the setup is quite straightforward.</p><div class="note" title="Note"><h3 class="title"><a id="ch05note07"/>Note</h3><p><span class="emphasis"><em>On OpenBSD 4.7 and newer, the brconfig command no longer exists. All bridge configuration and related functionality was merged into ifconfig for the OpenBSD 4.7 release. If you’re running on an OpenBSD release where brconfig is available, you’re running an out-of-date, unsupported configuration. Please upgrade to a more recent version as soon as feasible.</em></span></p></div><p>To set up a bridge with two interfaces on the command line, you first create the bridge device. The first device of a kind is conventionally given the sequence number 0, so we create the <code class="literal">bridge0</code> device with the following command:</p><a id="pro_id00186"/><pre class="programlisting">$ <span class="strong"><strong>sudo ifconfig bridge0 create</strong></span></pre><p>Before the next <code class="literal">ifconfig</code> command, use <code class="literal">ifconfig</code> to check that the prospective member interfaces (in our case, <code class="literal">ep0</code> and <code class="literal">ep1</code>) are up, but not assigned IP addresses. Next, configure the bridge by entering the following:</p><a id="pro_id00187"/><pre class="programlisting">$ <span class="strong"><strong>sudo ifconfig bridge0 add ep0 add ep1 blocknonip ep0 blocknonip ep1 up</strong></span></pre><p>The OpenBSD <code class="literal">ifconfig</code> command contains a fair bit of filtering code itself. In this example, we use the <code class="literal">blocknonip</code> option for each interface to block all non-IP traffic.</p><div class="note" title="Note"><h3 class="title"><a id="ch05note08"/>Note</h3><p><span class="emphasis"><em>The OpenBSD ifconfig command offers its own set of filtering options in addition to other configuration options. The <code class="literal">bridge(4)</code> and <code class="literal">ifconfig(8)</code> man pages provide further information. Because it operates on the Ethernet level, it’s possible to use <code class="literal">ifconfig</code> to specify filtering rules that let the bridge filter on MAC addresses. Using these filtering capabilities, it’s also possible to let the bridge tag packets for further processing in your PF rule set via the <code class="literal">tagged</code> keyword. For tagging purposes, a bridge with one member interface will do.</em></span></p></div><p>To make the configuration permanent, create or edit <span class="emphasis"><em>/etc/hostname.ep0</em></span> and enter the following line:</p><a id="pro_id00188"/><pre class="programlisting">up</pre><p>For the other interface, <span class="emphasis"><em>/etc/hostname.ep1</em></span> should contain the same line:</p><a id="pro_id00189"/><pre class="programlisting">up</pre><p><a class="indexterm" id="iddle1099"/><a class="indexterm" id="iddle1135"/><a class="indexterm" id="iddle1267"/><a class="indexterm" id="iddle1356"/><a class="indexterm" id="iddle1919"/>Finally, enter the bridge setup in <span class="emphasis"><em>/etc/hostname.bridge0</em></span>:</p><a id="pro_id00190"/><pre class="programlisting">add ep0 add ep1 blocknonip ep0 blocknonip ep1 up</pre><p>Your bridge should now be up, and you can go on to create the PF filter rules.</p></div><div class="sect2" title="Basic Bridge Setup on FreeBSD"><div class="titlepage"><div><div><h3 class="title" id="basic_bridge_setup_on_freebsd">Basic Bridge Setup on FreeBSD</h3></div></div></div><p>For FreeBSD, the procedure is a little more involved than on OpenBSD. In order to be able to use bridging, your running kernel must include the <code class="literal">if_bridge</code> module. The default kernel configurations build this module, so under ordinary circumstances, you can go directly to creating the interface. To compile the bridge device into the kernel, add the following line in the kernel configuration file:</p><a id="pro_id00191"/><pre class="programlisting">device if_bridge</pre><p>You can also load the device at boot time by putting the following line in the <span class="emphasis"><em>/etc/loader.conf</em></span> file.</p><a id="pro_id00192"/><pre class="programlisting">if_bridge_load="YES"</pre><p>Create the bridge by entering this:</p><a id="pro_id00193"/><pre class="programlisting">$ <span class="strong"><strong>sudo ifconfig bridge0 create</strong></span></pre><p>Creating the <code class="literal">bridge0</code> interface also creates a set of bridge-related <code class="literal">sysctl</code> values:</p><a id="pro_id00194"/><pre class="programlisting">$ sudo sysctl net.link.bridge&#13;
net.link.bridge.ipfw: 0&#13;
net.link.bridge.pfil_member: 1&#13;
net.link.bridge.pfil_bridge: 1&#13;
net.link.bridge.ipfw_arp: 0&#13;
net.link.bridge.pfil_onlyip: 1</pre><p>It’s worth checking that these <code class="literal">sysctl</code> values are available. If they are, it’s confirmation that the bridge has been enabled. If they’re not, go back and see what went wrong and why.</p><div class="note" title="Note"><h3 class="title"><a id="ch05note09"/>Note</h3><p><span class="emphasis"><em>These values apply to filtering on the bridge interface itself. You don’t need to touch them because IP-level filtering on the member interfaces (the ends of the pipe) is enabled by default.</em></span></p></div><p>Before the next <code class="literal">ifconfig</code> command, check that the prospective member interfaces (in our case, <code class="literal">ep0</code> and <code class="literal">ep1</code>) are up but haven’t been assigned IP addresses. Then configure the bridge by entering this:</p><a id="pro_id00195"/><pre class="programlisting">$ <span class="strong"><strong>sudo ifconfig bridge0 addm ep0 addm ep1 up</strong></span></pre><p><a class="indexterm" id="iddle1092"/><a class="indexterm" id="iddle1100"/><a class="indexterm" id="iddle1136"/><a class="indexterm" id="iddle1531"/>To make the configuration permanent, add the following lines to <span class="emphasis"><em>/etc/ rc.conf</em></span>:</p><a id="pro_id00196"/><pre class="programlisting">ifconfig_ep0="up"&#13;
ifconfig_ep1="up"&#13;
cloned_interfaces="bridge0"&#13;
ifconfig_bridge0="addm ep0 addm ep1 up"</pre><p>This means your bridge is up and you can go on to create the PF filter rules. See the <code class="literal">if_bridge(4)</code> man page for further FreeBSD-specific bridge information.</p></div><div class="sect2" title="Basic Bridge Setup on NetBSD"><div class="titlepage"><div><div><h3 class="title" id="basic_bridge_setup_on_netbsd">Basic Bridge Setup on NetBSD</h3></div></div></div><p>On NetBSD, the default kernel configuration doesn’t have the filtering bridge support compiled in. You need to compile a custom kernel with the following option added to the kernel configuration file. Once you have the new kernel with the bridge code in place, the setup is straightforward.</p><a id="pro_id00197"/><pre class="programlisting">options      BRIDGE_IPF #      bridge uses IP/IPv6 pfil hooks too</pre><p>To create a bridge with two interfaces on the command line, first create the <code class="literal">bridge0</code> device:</p><a id="pro_id00198"/><pre class="programlisting">$ <span class="strong"><strong>sudo ifconfig bridge0 create</strong></span></pre><p>Before the next <code class="literal">brconfig</code> command, use <code class="literal">ifconfig</code> to check that the prospective member interfaces (in our case, <code class="literal">ep0</code> and <code class="literal">ep1</code>) are up but haven’t been assigned IP addresses. Then, configure the bridge by entering this:</p><a id="pro_id00199"/><pre class="programlisting">$ <span class="strong"><strong>sudo brconfig bridge0 add ep0 add ep1 up</strong></span></pre><p>Next, enable the filtering on the <code class="literal">bridge0</code> device:</p><a id="pro_id00200"/><pre class="programlisting">$ <span class="strong"><strong>sudo brconfig bridge0 ipf</strong></span></pre><p>To make the configuration permanent, create or edit <span class="emphasis"><em>/etc/ifconfig.ep0</em></span> and enter the following line:</p><a id="pro_id00201"/><pre class="programlisting">up</pre><p>For the other interface, <span class="emphasis"><em>/etc/ifconfig.ep1</em></span> should contain the same line:</p><a id="pro_id00202"/><pre class="programlisting">up</pre><p>Finally, enter the bridge setup in <span class="emphasis"><em>/etc/ifconfig.bridge0</em></span>:</p><a id="pro_id00203"/><pre class="programlisting">create&#13;
!add ep0 add ep1 up</pre><p><a class="indexterm" id="iddle1095"/><a class="indexterm" id="iddle1098"/><a class="indexterm" id="iddle1138"/><a class="indexterm" id="iddle1223"/><a class="indexterm" id="iddle1782"/>Your bridge should now be up, and you can go on to create the PF filter rules. For further information, see the PF on NetBSD documentation at <span class="emphasis"><em><a class="ulink" href="http://www.netbsd.org/Documentation/network/pf.html" target="_top">http://www.netbsd.org/Documentation/network/pf.html</a></em></span>.</p></div><div class="sect2" title="The Bridge Rule Set"><div class="titlepage"><div><div><h3 class="title" id="bridge_rule_set">The Bridge Rule Set</h3></div></div></div><p><a class="xref" href="ch05.html#network_with_a_bridge_firewall" title="Figure 5-3. A network with a bridge firewall">Figure 5-3</a> shows the <span class="emphasis"><em>pf.conf</em></span> file for a bulge-in-the-wire version of the baseline rule set we started in this chapter. As you can see, the network changes slightly.</p><div class="figure"><a id="network_with_a_bridge_firewall"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00010"/><img alt="A network with a bridge firewall" src="httpatomoreillycomsourcenostarchimages2127157.png.jpg"/></div></div><div class="figure-title">Figure 5-3. A network with a bridge firewall</div></div><p>The machines in the local network share a common default gateway, which isn’t the bridge but could be placed either inside or outside the bridge.</p><a id="pro_id00204"/><pre class="programlisting">ext_if = ep0&#13;
int_if = ep1&#13;
localnet= "192.0.2.0/24"&#13;
webserver = "192.0.2.227"&#13;
webports = "{ http, https }"&#13;
emailserver = "192.0.2.225"&#13;
email = "{ smtp, pop3, imap, imap3, imaps, pop3s }"&#13;
nameservers = "{ 192.0.2.221, 192.0.2.223 }"&#13;
client_out = "{ ssh, domain, pop3, auth, nntp, http, https, \&#13;
                446, cvspserver, 2628, 5999, 8000, 8080 }"&#13;
udp_services = "{ domain, ntp }"&#13;
icmp_types = "{ echoreq, unreach }"&#13;
set skip on $int_if&#13;
block all&#13;
pass quick on $ext_if inet proto { tcp, udp } from $localnet \&#13;
        to port $udp_services&#13;
pass log on $ext_if inet proto icmp all icmp-type $icmp_types&#13;
pass on $ext_if inet proto tcp from $localnet to port $client_out&#13;
pass on $ext_if inet proto { tcp, udp } to $nameservers port domain&#13;
pass on $ext_if proto tcp to $webserver port $webports&#13;
pass log on $ext_if proto tcp to $emailserver port $email&#13;
pass log on $ext_if proto tcp from $emailserver to port smtp</pre><p><a class="indexterm" id="iddle1052"/><a class="indexterm" id="iddle1144"/><a class="indexterm" id="iddle1145"/><a class="indexterm" id="iddle1146"/><a class="indexterm" id="iddle1178"/><a class="indexterm" id="iddle1211"/><a class="indexterm" id="iddle1389"/><a class="indexterm" id="iddle1390"/><a class="indexterm" id="iddle1391"/><a class="indexterm" id="iddle1787"/>Significantly more complicated setups are possible. But remember that while redirections will work, you won’t be able to run services on any of the interfaces without IP addresses.</p></div></div><div class="sect1" title="Handling Nonroutable IPv4 Addresses from Elsewhere"><div class="titlepage"><div><div><h2 class="title" id="handling_nonroutable_ipv4_addresses_from" style="clear: both">Handling Nonroutable IPv4 Addresses from Elsewhere</h2></div></div></div><p>Even with a properly configured gateway to handle filtering and potentially NAT for your own network, you may find yourself in the unenviable position of needing to compensate for other people’s misconfigurations.</p><div class="sect2" title="Establishing Global Rules"><div class="titlepage"><div><div><h3 class="title" id="establishing_global_rules">Establishing Global Rules</h3></div></div></div><p>One depressingly common class of misconfigurations is the kind that lets traffic with nonroutable addresses out to the Internet. Traffic from nonroutable IPv4 addresses plays a part in several <span class="emphasis"><em>denial-of-service (DoS)</em></span> attack techniques, so it’s worth considering explicitly blocking traffic from nonroutable addresses from entering your network. One possible solution is outlined here. For good measure, it also blocks any attempt to initiate contact to nonroutable addresses through the gateway’s external interface.</p><a id="pro_id00205"/><pre class="programlisting">martians = "{ 127.0.0.0/8, 192.168.0.0/16, 172.16.0.0/12, \&#13;
              10.0.0.0/8, 169.254.0.0/16, 192.0.2.0/24, \&#13;
              0.0.0.0/8, 240.0.0.0/4 }"&#13;
&#13;
block in quick on $ext_if from $martians to any&#13;
block out quick on $ext_if from any to $martians</pre><p>Here, the <code class="literal">martians</code> macro denotes the RFC 1918 addresses and a few other ranges mandated by various RFCs not to be in circulation on the open Internet. Traffic to and from such addresses is quietly dropped on the gateway’s external interface.</p><div class="note" title="Note"><h3 class="title"><a id="ch05note10"/>Note</h3><p><span class="emphasis"><em>The martians macro could easily be implemented as a table instead, with all of the table advantages as an added bonus for your rule set. In fact, if you view the loaded rules in a rule set that contains this combination of macro and rules, you’ll see that macro expansion and rule-set optimization most likely replaced your list with one table per rule. However, if you roll your own table, you’ll get to pick a nicer name for it yourself.</em></span></p></div><p>The specific details of how to implement this kind of protection will vary according to your network configuration and may be part of a wider set of network security measures. Your network design might also dictate that you include or exclude address ranges other than these.</p></div><div class="sect2" title="Restructuring Your Rule Set with Anchors"><div class="titlepage"><div><div><h3 class="title" id="restructuring_your_rule_set_with_anchors">Restructuring Your Rule Set with Anchors</h3></div></div></div><p>We’ve mentioned anchors a few times already, in the context of applications such as FTP-proxy or <code class="literal">relayd</code> that use anchors to interact with a running PF configuration. Anchors are named sub–rule sets where it’s possible to insert or remove rules as needed without reloading the whole rule set.</p><p><a class="indexterm" id="iddle1048"/><a class="indexterm" id="iddle1049"/><a class="indexterm" id="iddle1050"/><a class="indexterm" id="iddle1224"/><a class="indexterm" id="iddle1648"/><a class="indexterm" id="iddle1649"/><a class="indexterm" id="iddle1650"/>Once you have a rule set where an otherwise unused anchor is defined, you can even manipulate anchor contents from the command line using <code class="literal">pfctl</code>’s <code class="literal">-a</code> switch, like this:</p><a id="pro_id00206"/><pre class="programlisting">echo "block drop all" | pfctl -a baddies -f -</pre><p>Here, a rule is inserted into the existing anchor <code class="literal">baddies</code>, overwriting any previous content.</p><p>You can even load rules from a separate file into an anchor:</p><a id="pro_id00207"/><pre class="programlisting">pfctl -a baddies -f /etc/anchor-baddies</pre><p>Or you can list the current contents of an anchor:</p><a id="pro_id00208"/><pre class="programlisting">pfctl -a baddies -s rules</pre><div class="note" title="Note"><h3 class="title"><a id="ch05note11"/>Note</h3><p><span class="emphasis"><em>There are a few more pfctl options that you’ll find useful for handling anchors. See the pfctl man page for inspiration.</em></span></p></div><p>You can also split your configuration by putting the contents of anchors into separate files to be loaded at rule-set load time. That way it becomes possible to edit the rules in the anchors separately, reload the edited anchor, and, of course, do any other manipulation like the ones described above. To do this, first add a line like this to <span class="emphasis"><em>pf.conf</em></span>:</p><a id="pro_id00209"/><pre class="programlisting">anchor ssh-good load anchor ssh-good from "/etc/anchor-ssh-good"</pre><p>This references the file <span class="emphasis"><em>/etc/anchor-ssh-good</em></span>, which could look like this:</p><a id="pro_id00210"/><pre class="programlisting">table &lt;sshbuddies&gt; file "/etc/sshbuddies"&#13;
     pass inet proto tcp from &lt;sshbuddies&gt; to any port ssh</pre><p>Perhaps simply to make it possible to delegate the responsibility for the table <code class="literal">sshbuddies</code> to a junior admin, the anchor loads the table from the file <span class="emphasis"><em>/etc/sshbuddies</em></span>, which could look like this:</p><a id="pro_id00211"/><pre class="programlisting">192.168.103.84&#13;
10.11.12.13</pre><p>This way, you can manipulate the contents of the anchor in the following ways: Add rules by editing the file and reloading the anchor, replace the rules by feeding other rules from the command line via standard input (as shown in the earlier example), or change the behavior of the rules inside the anchor by manipulating the contents of the table they reference.</p><div class="note" title="Note"><h3 class="title"><a id="ch05note12"/>Note</h3><p><span class="emphasis"><em>For more extensive anchors, like the ones discussed in the following paragraphs, it’s probably more useful to use include clauses in your</em></span> pf.conf <span class="emphasis"><em>if you want to maintain the anchors as separate files.</em></span></p></div><p><a class="indexterm" id="iddle1053"/>The concept hinted at previously (specifying a set of common criteria that apply to all actions within an anchor) is appealing in situations where your configuration is large enough to need a few extra structuring aids. For example, “on interface” could be a useful common criterion for traffic arriving on a specific interface because that traffic tends to have certain similarities. For example, look at the following:</p><a id="pro_id00212"/><pre class="programlisting">anchor "dmz" on $dmz_if {&#13;
    pass in proto { tcp udp } to $nameservers port domain&#13;
    pass in proto tcp to $webservers port { www https }&#13;
    pass in proto tcp to $mailserver port smtp&#13;
    pass in log (all, to pflog1) in proto tcp from $mailserver \&#13;
                 to any port smtp&#13;
}</pre><p>A separate anchor <code class="literal">ext</code> would serve the <code class="literal">egress</code> interface group:</p><a id="pro_id00213"/><pre class="programlisting">anchor ext on egress {&#13;
    match out proto tcp to port { www https } set queue (qweb, qpri) set prio (5,6)&#13;
    match out proto { tcp udp } to port domain set queue (qdns, qpri) set prio (6,7)&#13;
    match out proto icmp set queue (q_dns, q_pri) set prio (7,6)&#13;
    pass in log proto tcp to port smtp rdr-to 127.0.0.1 port spamd queue spamd&#13;
    pass in log proto tcp from &lt;nospamd&gt; to port smtp&#13;
    pass in log proto tcp from &lt;spamd-white&gt; to port smtp&#13;
    pass out log proto tcp to port smtp&#13;
    pass log (all) proto { tcp, udp } to port ssh keep state (max-src-conn 15, \&#13;
        max-src-conn-rate 7/3, overload &lt;bruteforce&gt; flush global)&#13;
}</pre><p>Another obvious logical optimization if you group rules in anchors based on interface affinity is to lump in tags to help policy-routing decisions. A simple but effective example could look like this:</p><a id="pro_id00214"/><pre class="programlisting">anchor "dmz" on $dmz_if {&#13;
    pass in proto { tcp udp } to $nameservers port domain tag GOOD&#13;
    pass in proto tcp to $webservers port { www https } tag GOOD&#13;
    pass in proto tcp to $mailserver port smtp tag GOOD&#13;
    pass in log (all, to pflog1) in proto tcp from $mailserver&#13;
                 to any port smtp tag GOOD&#13;
    block log quick ! tagged GOOD&#13;
}</pre><p>Even if the anchor examples here have all included a blocking decision inside the anchor, the decision to block or pass based on tag information doesn’t have to happen inside the anchor.</p><p>After this whirlwind tour of anchors as a structuring tool, it may be tempting to try to convert your entire rule set to an anchors-based structure. If you try to do so, you’ll probably find ways to make the internal logic clearer. But don’t be surprised if certain rules need to be global, outside of anchors tied to common criteria. And you’ll almost certainly find that what turns out to be useful in your environment is at least a little different from what inspired the scenarios I’ve presented here.</p></div></div><div class="sect1" title="How Complicated Is Your Network?—Revisited"><div class="titlepage"><div><div><h2 class="title" id="how_complicated_is_your_networkquestion" style="clear: both">How Complicated Is Your Network?—Revisited</h2></div></div></div><p>Early on in this chapter, we posed the questions “How complicated is your network?” and “How complicated does it need to be?” Over the subsections of this chapter, we’ve presented a number of tools and techniques that make it possible to build complex infrastructure with PF and related tools and that help manage that complexity while keeping the network administrator sane.</p><p>If you’re in charge of one site where you need to apply all or most of the techniques we’ve mentioned in this chapter, I feel your pain. On the other hand, if you’re in charge of a network that diverse, the subsequent chapters on traffic shaping and managing resource availability are likely to be useful to you as well.</p><p>The rest of this book deals mainly with optimizing your setup for performance and resource availability, with the exception of one chapter where we deviate slightly and take on a lighter tone. Before we dive into how to optimize performance and ensure high availability, it’s time to take a look at how to make your infrastructure unavailable or hard to reach for selected groups or individuals. The next chapter deals exclusively with making life harder for the unwashed masses—or perhaps even well-organized criminals—who try to abuse services in your care.</p></div><div class="footnotes" epub:type="footnotes"><br/><hr style="width: 100; align: left;"/><div class="footnote" epub:type="footnote" id="ftn.ch05fn01"><p><sup>[<a class="para" href="#ch05fn01">25</a>] </sup>In fact, the <span class="emphasis"><em>example.com</em></span> network here lives in the 192.0.2.0/24 block, which is reserved in RFC 3330 for example and documentation use. We use this address range mainly to differentiate from the NAT examples elsewhere in this book, which use addresses in the “private” RFC 1918 address space.</p></div><div class="footnote" epub:type="footnote" id="ftn.ch05fn02"><p><sup>[<a class="para" href="#ch05fn02">26</a>] </sup>Originally introduced in OpenBSD 4.1 under the name <code class="literal">hoststated</code>, the daemon has seen active development (mainly by Reyk Floeter and Pierre-Yves Ritschard) over several years, including a few important changes to the configuration syntax, and it was renamed <code class="literal">relayd</code> in time for the OpenBSD 4.3 release.</p></div><div class="footnote" epub:type="footnote" id="ftn.ch05fn03"><p><sup>[<a class="para" href="#ch05fn03">27</a>] </sup>See the OpenSSL man page for further explanation of cipher-related options.</p></div><div class="footnote" id="ftn.ch05fn04"><p><sup>[<a class="para" href="#ch05fn04">28</a>] </sup>See the “Redirection and Reflection” section in the PF User Guide (<span class="emphasis"><em><a class="ulink" href="http://www.openbsd.org/faq/pf/rdr.html#reflect" target="_top">http://www.openbsd.org/faq/pf/rdr.html#reflect</a></em></span>).</p></div><div class="footnote" epub:type="footnote" id="ftn.ch05fn05"><p><sup>[<a class="para" href="#ch05fn05">29</a>] </sup>How much security this actually adds is a matter of occasional heated debate on mailing lists such as <span class="emphasis"><em>openbsd-misc</em></span> and other networking-oriented lists. Reading up on the pros and cons as perceived by core OpenBSD developers can be entertaining as well as enlightening.</p></div></div></section></body></html>