- en: Chapter 2. DATA REPRESENTATION
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![DATA REPRESENTATION](tagoreillycom20100401nostarchimages577853.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A major stumbling block many beginners encounter when attempting to learn assembly
    language is the common use of the binary and hexadecimal numbering systems. Although
    hexadecimal numbers are a little strange, their advantages outweigh their disadvantages
    by a large margin. Understanding the binary and hexadecimal numbering systems
    is important because their use simplifies the discussion of other topics, including
    bit operations, signed numeric representation, character codes, and packed data.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter discusses several important concepts, including:'
  prefs: []
  type: TYPE_NORMAL
- en: The binary and hexadecimal numbering systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary data organization (bits, nibbles, bytes, words, and double words)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Signed and unsigned numbering systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arithmetic, logical, shift, and rotate operations on binary values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bit fields and packed data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is basic material, and the remainder of this text depends on your understanding
    these concepts. If you are already familiar with these terms from other courses
    or study, you should at least skim this material before proceeding to the next
    chapter. If you are unfamiliar with this material, or only vaguely familiar with
    it, you should study it carefully before proceeding. *All of the material in this
    chapter is important!* Do not skip over any material.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Numbering Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most modern computer systems do not represent numeric values using the decimal
    (base-10) system. Instead, they typically use a binary or two's complement numbering
    system.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.1 A Review of the Decimal System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You''ve been using the decimal numbering system for so long that you probably
    take it for granted. When you see a number like *123*, you don''t think about
    the value 123; rather, you generate a mental image of how many items this value
    represents. In reality, however, the number 123 represents:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1*10² + 2*10¹ + 3*10⁰ |'
  prefs: []
  type: TYPE_TB
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '| 100 + 20 + 3 |'
  prefs: []
  type: TYPE_TB
- en: 'In a decimal positional numbering system, each digit appearing to the left
    of the decimal point represents a value between 0 and 9 times an increasing power
    of 10\. Digits appearing to the right of the decimal point represent a value between
    0 and 9 times an increasing negative power of 10\. For example, the value 123.456
    means:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1*10² + 2*10¹ + 3*10⁰ + 4*10^(−1) + 5*10^(−2) + 6*10^(−3) |'
  prefs: []
  type: TYPE_TB
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '| 100 + 20 + 3 + 0.4 + 0.05 + 0.006 |'
  prefs: []
  type: TYPE_TB
- en: 2.1.2 The Binary Numbering System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most modern computer systems operate using binary logic. The computer represents
    values using two voltage levels (usually 0v and +2.4..5v). Two such levels can
    represent exactly two unique values. These could be any two different values,
    but they typically represent the values 0 and 1\. These values, coincidentally,
    correspond to the two digits in the binary numbering system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The binary numbering system works just like the decimal numbering system, with
    two exceptions: Binary allows only the digits 0 and 1 (rather than 0..9), and
    binary uses powers of 2 rather than powers of 10\. Therefore, it is very easy
    to convert a binary number to decimal. For each `1` in the binary string, add
    in `2`*`^n`* where *n* is the zero-based position of the binary digit. For example,
    the binary value 11001010[2] represents:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1*2⁷ + 1*2⁶ + 0*2⁵ + 0*2⁴ + 1*2³ + 0*2² + 1*2¹ + 0*2⁰ |'
  prefs: []
  type: TYPE_TB
- en: '| = |'
  prefs: []
  type: TYPE_TB
- en: '| 128 + 64 + 8 + 2 |'
  prefs: []
  type: TYPE_TB
- en: '| = |'
  prefs: []
  type: TYPE_TB
- en: '| 202[10] |'
  prefs: []
  type: TYPE_TB
- en: To convert decimal to binary is slightly more difficult. You must find those
    powers of 2 that, when added together, produce the decimal result.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple way to convert decimal to binary is the *even/odd - divide by two*
    algorithm. This algorithm uses the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: If the number is even, emit a 0\. If the number is odd, emit a 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Divide the number by 2 and throw away any fractional component or remainder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the quotient is 0, the algorithm is complete.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the quotient is not 0 and is odd, insert a 1 before the current string; if
    the number is even, prefix your binary string with 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go back to step 2 and repeat.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Binary numbers, although they have little importance in high-level languages,
    appear everywhere in assembly language programs. So you should be somewhat comfortable
    with them.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.3 Binary Formats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the purest sense, every binary number contains an infinite number of digits
    (or *bits*, which is short for *binary digits*). For example, we can represent
    the number 5 by any of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 101 00000101 0000000000101 ...000000000000101 |'
  prefs: []
  type: TYPE_TB
- en: Any number of leading zero digits may precede the binary number without changing
    its value.
  prefs: []
  type: TYPE_NORMAL
- en: We will adopt the convention of ignoring any leading zeros present in a value.
    For example, 101[2] represents the number 5 but because the 80x86 typically works
    with groups of 8 bits, we'll find it much easier to zero extend all binary numbers
    to some multiple of 4 or 8 bits. Therefore, following this convention, we'd represent
    the number 5 as 0101[2] or 00000101[2].
  prefs: []
  type: TYPE_NORMAL
- en: In the United States, most people separate every three digits with a comma to
    make larger numbers easier to read. For example, 1,023,435,208 is much easier
    to read and comprehend than 1023435208\. We'll adopt a similar convention in this
    text for binary numbers. We will separate each group of four binary bits with
    an underscore. For example, we will write the binary value 1010111110110010 as
    1010_1111_1011_0010.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll number each bit as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The rightmost bit in a binary number is bit position 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each bit to the left is given the next successive bit number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'An 8-bit binary value uses bits 0..7:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| X[7] X[6] X[5] X[4] X[3] X[2] X[1] X[0] |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: 'A 16-bit binary value uses bit positions 0..15:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| X[15] X[14] X[13] X[12] X[11] X[10] X[9] X[8] X[7] X[6] X[5] X[4] X[3] X[2]
    X[1] X[0] |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: A 32-bit binary value uses bit positions 0..31, and so on.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Bit 0 is the *low-order (L.O.)* bit (some refer to this as the *least significant
    bit*). The leftmost bit is called the *high-order (H.O.)* bit (or the *most significant
    bit*). We'll refer to the intermediate bits by their respective bit numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 The Hexadecimal Numbering System
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Unfortunately, binary numbers are verbose. To represent the value 202[10] requires
    eight binary digits. The decimal version requires only three decimal digits and
    thus represents numbers much more compactly than in binary. This fact is not lost
    on the engineers who design binary computer systems. When dealing with large values,
    binary numbers quickly become unwieldy. Unfortunately, the computer "thinks" in
    binary, so most of the time it is convenient to use the binary numbering system.
    Although we can convert between decimal and binary, the conversion is not a trivial
    task. The hexadecimal (base 16) numbering system solves many of the problems inherent
    in the binary system. Hexadecimal numbers offer the two features we''re looking
    for: They''re very compact, and it''s simple to convert them to binary and vice
    versa. For this reason, most engineers use the hexadecimal numbering system.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the radix (base) of a hexadecimal number is 16, each hexadecimal digit
    to the left of the hexadecimal point represents some value times a successive
    power of 16\. For example, the number 1234[16] is equal to:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1*16³ + 2*16² + 3*16¹ + 4*16⁰ |'
  prefs: []
  type: TYPE_TB
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '| 4096 + 512 + 48 + 4 = 4660[10] |'
  prefs: []
  type: TYPE_TB
- en: 'Each hexadecimal digit can represent one of 16 values between 0 and 15[10].
    Because there are only 10 decimal digits, we need to invent 6 additional digits
    to represent the values in the range 10[10]..15[10]. Rather than create new symbols
    for these digits, we''ll use the letters A..F. The following are all examples
    of valid hexadecimal numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1234[16] DEAD[16] BEEF[16] 0AFB[16] FEED[16] DEAF[16] |'
  prefs: []
  type: TYPE_TB
- en: 'Because we''ll often need to enter hexadecimal numbers into the computer system,
    we''ll need a different mechanism for representing hexadecimal numbers. After
    all, on most computer systems you cannot enter a subscript to denote the radix
    of the associated value. We''ll adopt the following conventions:'
  prefs: []
  type: TYPE_NORMAL
- en: All hexadecimal values begin with a $ character; for example, $123A4.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All binary values begin with a percent sign (%).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decimal numbers do not have a prefix character.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the radix is clear from the context, this book may drop the leading $ or
    % character.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some examples of valid hexadecimal numbers:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| $1234 $DEAD $BEEF $AFB $FEED $DEAF |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: As you can see, hexadecimal numbers are compact and easy to read. In addition,
    you can easily convert between hexadecimal and binary. Consider [Table 2-1](ch02s02.html#binary_solidus_hexadecimal_conversion
    "Table 2-1. Binary/Hexadecimal Conversion"). This table provides all the information
    you'll ever need to convert any hexadecimal number into a binary number or vice
    versa.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-1. Binary/Hexadecimal Conversion
  prefs: []
  type: TYPE_NORMAL
- en: '| Binary | Hexadecimal |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| %0000 | $0 |'
  prefs: []
  type: TYPE_TB
- en: '| %0001 | $1 |'
  prefs: []
  type: TYPE_TB
- en: '| %0010 | $2 |'
  prefs: []
  type: TYPE_TB
- en: '| %0011 | $3 |'
  prefs: []
  type: TYPE_TB
- en: '| %0100 | $4 |'
  prefs: []
  type: TYPE_TB
- en: '| %0101 | $5 |'
  prefs: []
  type: TYPE_TB
- en: '| %0110 | $6 |'
  prefs: []
  type: TYPE_TB
- en: '| %0111 | $7 |'
  prefs: []
  type: TYPE_TB
- en: '| %1000 | $8 |'
  prefs: []
  type: TYPE_TB
- en: '| %1001 | $9 |'
  prefs: []
  type: TYPE_TB
- en: '| %1010 | $A |'
  prefs: []
  type: TYPE_TB
- en: '| %1011 | $B |'
  prefs: []
  type: TYPE_TB
- en: '| %1100 | $C |'
  prefs: []
  type: TYPE_TB
- en: '| %1101 | $D |'
  prefs: []
  type: TYPE_TB
- en: '| %1110 | $E |'
  prefs: []
  type: TYPE_TB
- en: '| %1111 | $F |'
  prefs: []
  type: TYPE_TB
- en: 'To convert a hexadecimal number into a binary number, simply substitute the
    corresponding 4 bits for each hexadecimal digit in the number. For example, to
    convert $ABCD into a binary value, simply convert each hexadecimal digit according
    to [Table 2-1](ch02s02.html#binary_solidus_hexadecimal_conversion "Table 2-1. Binary/Hexadecimal
    Conversion"), as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '| A | B | C | D | Hexadecimal |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1010 | 1011 | 1100 | 1101 | Binary |'
  prefs: []
  type: TYPE_TB
- en: To convert a binary number into hexadecimal format is almost as easy. The first
    step is to pad the binary number with zeros to make sure that there is a multiple
    of 4 bits in the number. For example, given the binary number 1011001010, the
    first step would be to add 2 bits to the left of the number so that it contains
    12 bits. The converted binary value is 001011001010\. The next step is to separate
    the binary value into groups of 4 bits, for example, 0010_1100_1010\. Finally,
    look up these binary values in [Table 2-1](ch02s02.html#binary_solidus_hexadecimal_conversion
    "Table 2-1. Binary/Hexadecimal Conversion") and substitute the appropriate hexadecimal
    digits, that is, $2CA. Contrast this with the difficulty of conversion between
    decimal and binary or decimal and hexadecimal!
  prefs: []
  type: TYPE_NORMAL
- en: Because converting between hexadecimal and binary is an operation you will need
    to perform over and over again, you should take a few minutes and memorize the
    conversion table. Even if you have a calculator that will do the conversion for
    you, you'll find manual conversion to be a lot faster and more convenient when
    converting between binary and hex.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Data Organization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In pure mathematics a value's representation may take require an arbitrary number
    of bits. Computers, on the other hand, generally work with some specific number
    of bits. Common collections are single bits, groups of 4 bits (called *nibbles*),
    groups of 8 bits (*bytes*), groups of 16 bits (*words*), groups of 32 bits (*double
    words* or *dwords*), groups of 64 bits (*quad words* or *qwords*), groups of 128
    bits (*long words* or *lwords*), and more. The sizes are not arbitrary. There
    is a good reason for these particular values. This section will describe the bit
    groups commonly used on the Intel 80x86 chips.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Bits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The smallest unit of data on a binary computer is a single bit. With a single
    bit, you can represent any two distinct items. Examples include 0 or 1, true or
    false, on or off, male or female, and right or wrong. However, you are *not* limited
    to representing binary data types (that is, those objects that have only two distinct
    values). You could use a single bit to represent the numbers 723 and 1,245 or,
    perhaps, the values 6,254 and 5\. You could also use a single bit to represent
    the colors red and blue. You could even represent two unrelated objects with a
    single bit. For example, you could represent the color red and the number 3,256
    with a single bit. You can represent *any two* different values with a single
    bit. However, you can represent *only two* different values with a single bit.
  prefs: []
  type: TYPE_NORMAL
- en: 'To confuse things even more, different bits can represent different things.
    For example, you could use one bit to represent the values 0 and 1, while a different
    bit could represent the values true and false. How can you tell by looking at
    the bits? The answer, of course, is that you can''t. But this illustrates the
    whole idea behind computer data structures: *data is what you define it to be*.
    If you use a bit to represent a boolean (true/false) value, then that bit (by
    your definition) represents true or false. For the bit to have any real meaning,
    you must be consistent. If you''re using a bit to represent true or false at one
    point in your program, you shouldn''t use that value to represent red or blue
    later.'
  prefs: []
  type: TYPE_NORMAL
- en: Because most items you'll be trying to model require more than two different
    values, single-bit values aren't the most popular data type you'll use. However,
    because everything else consists of groups of bits, bits will play an important
    role in your programs. Of course, there are several data types that require two
    distinct values, so it would seem that bits are important by themselves. However,
    you will soon see that individual bits are difficult to manipulate, so we'll often
    use other data types to represent two-state values.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 Nibbles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A *nibble* is a collection of 4 bits. It wouldn''t be a particularly interesting
    data structure except for two facts: *binary-coded decimal (BCD)* numbers^([[21](#ftn.CHP-2-FN-1)])
    and hexadecimal numbers. It takes 4 bits to represent a single BCD or hexadecimal
    digit. With a nibble, we can represent up to 16 distinct values because there
    are 16 unique combinations of a string of 4 bits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the case of hexadecimal numbers, the values 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,
    A, B, C, D, E, and F are represented with 4 bits. BCD uses 10 different digits
    (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) and requires also 4 bits (because we can only represent
    8 different values with 3 bits, the additional 6 values we can represent with
    4 bits are never used in BCD representation). In fact, any 16 distinct values
    can be represented with a nibble, though hexadecimal and BCD digits are the primary
    items we can represent with a single nibble.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.3 Bytes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Without question, the most important data structure used by the 80x86 microprocessor
    is the byte, which consists of 8 bits. Main memory and I/O addresses on the 80x86
    are all byte addresses. This means that the smallest item that can be individually
    accessed by an 80x86 program is an 8-bit value. To access anything smaller requires
    that we read the byte containing the data and eliminate the unwanted bits. The
    bits in a byte are normally numbered from 0 to 7, as shown in [Figure 2-1](ch02s03.html#bit_numbering
    "Figure 2-1. Bit numbering").
  prefs: []
  type: TYPE_NORMAL
- en: '![Bit numbering](tagoreillycom20100401nostarchimages577885.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1. Bit numbering
  prefs: []
  type: TYPE_NORMAL
- en: Bit 0 is the *low-order bit* or *least significant bit*, and bit 7 is the *high-order
    bit* or *most significant bit* of the byte. We'll refer to all other bits by their
    number.
  prefs: []
  type: TYPE_NORMAL
- en: Note that a byte also contains exactly two nibbles (see [Figure 2-2](ch02s03.html#the_two_nibbles_in_a_byte
    "Figure 2-2. The two nibbles in a byte")).
  prefs: []
  type: TYPE_NORMAL
- en: '![The two nibbles in a byte](tagoreillycom20100401nostarchimages577887.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2. The two nibbles in a byte
  prefs: []
  type: TYPE_NORMAL
- en: Bits 0..3 compose the *low-order nibble*, and bits 4..7 form the *high-order
    nibble*. Because a byte contains exactly two nibbles, byte values require two
    hexadecimal digits.
  prefs: []
  type: TYPE_NORMAL
- en: Because a byte contains 8 bits, it can represent 2⁸ (256) different values.
    Generally, we'll use a byte to represent numeric values in the range 0..255, signed
    numbers in the range −128..+127 (see [2.8 Signed and Unsigned Numbers](ch02s08.html
    "2.8 Signed and Unsigned Numbers")), ASCII/IBM character codes, and other special
    data types requiring no more than 256 different values. Many data types have fewer
    than 256 items, so 8 bits is usually sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: Because the 80x86 is a byte-addressable machine, it turns out to be more efficient
    to manipulate a whole byte than an individual bit or nibble. For this reason,
    most programmers use a whole byte to represent data types that require no more
    than 256 items, even if fewer than 8 bits would suffice. For example, we'll often
    represent the boolean values true and false by 00000001[2] and 00000000[2], respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Probably the most important use for a byte is holding a character value. Characters
    typed at the keyboard, displayed on the screen, and printed on the printer all
    have numeric values. To communicate with the rest of the world, PCs typically
    use a variant of the *ASCII character set*. There are 128 defined codes in the
    ASCII character set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because bytes are the smallest unit of storage in the 80x86 memory space, bytes
    also happen to be the smallest variable you can create in an HLA program. As you
    saw in the last chapter, you can declare an 8-bit signed integer variable using
    the `int8` data type. Because `int8` objects are signed, you can represent values
    in the range −128..+127 using an `int8` variable. You should only store signed
    values into `int8` variables; if you want to create an arbitrary byte variable,
    you should use the `byte` data type, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `byte` data type is a partially untyped data type. The only type information
    associated with a `byte` object is its size (1 byte). You may store any 8-bit
    value (small signed integers, small unsigned integers, characters, and the like)
    into a byte variable. It is up to you to keep track of the type of object you've
    put into a byte variable.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.4 Words
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A word is a group of 16 bits. We'll number the bits in a word from 0 to 15,
    as [Figure 2-3](ch02s03.html#bit_numbers_in_a_word "Figure 2-3. Bit numbers in
    a word") shows. Like the byte, bit 0 is the low-order bit. For words, bit 15 is
    the high-order bit. When referencing the other bits in a word, we'll use their
    bit position number.
  prefs: []
  type: TYPE_NORMAL
- en: '![Bit numbers in a word](tagoreillycom20100401nostarchimages577889.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-3. Bit numbers in a word
  prefs: []
  type: TYPE_NORMAL
- en: Notice that a word contains exactly 2 bytes. Bits 0..7 form the low-order byte,
    and bits 8..15 form the high-order byte (see [Figure 2-4](ch02s03.html#the_two_bytes_in_a_word
    "Figure 2-4. The two bytes in a word")).
  prefs: []
  type: TYPE_NORMAL
- en: '![The two bytes in a word](tagoreillycom20100401nostarchimages577891.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-4. The two bytes in a word
  prefs: []
  type: TYPE_NORMAL
- en: Of course, a word may be further broken down into four nibbles, as shown in
    [Figure 2-5](ch02s03.html#nibbles_in_a_word "Figure 2-5. Nibbles in a word").
    Nibble 0 is the low-order nibble in the word, and nibble 3 is the high-order nibble
    of the word. We'll simply refer to the other two nibbles as *nibble 1* or *nibble
    2*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Nibbles in a word](tagoreillycom20100401nostarchimages577893.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-5. Nibbles in a word
  prefs: []
  type: TYPE_NORMAL
- en: With 16 bits, you can represent 2^(16) (65,536) different values. These could
    be the values in the range 0..65,535 or, as is usually the case, the signed values
    −32,768..+32,767, or any other data type with no more than 65,536 values. The
    three major uses for words are short signed integer values, short unsigned integer
    values, and Unicode characters.
  prefs: []
  type: TYPE_NORMAL
- en: Words can represent integer values in the range 0..65,535 or −32,768..32,767\.
    Unsigned numeric values are represented by the binary value corresponding to the
    bits in the word. Signed numeric values use the two's complement form for numeric
    values (see [2.8 Signed and Unsigned Numbers](ch02s08.html "2.8 Signed and Unsigned
    Numbers")). As Unicode characters, words can represent up to 65,536 different
    characters, allowing the use of non-Roman character sets in a computer program.
    Unicode is an international standard, like ASCII, that allows computers to process
    non-Roman characters such as Asian, Greek, and Russian characters.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with bytes, you can also create word variables in an HLA program. Of course,
    in the last chapter you saw how to create 16-bit signed integer variables using
    the `int16` data type. To create an arbitrary word variable, just use the `word`
    data type, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 2.3.5 Double Words
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A double word is exactly what its name implies, a pair of words. Therefore,
    a double-word quantity is 32 bits long, as shown in [Figure 2-6](ch02s03.html#bit_numbers_in_a_double_word
    "Figure 2-6. Bit numbers in a double word").
  prefs: []
  type: TYPE_NORMAL
- en: '![Bit numbers in a double word](tagoreillycom20100401nostarchimages577895.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-6. Bit numbers in a double word
  prefs: []
  type: TYPE_NORMAL
- en: Naturally, this double word can be divided into a high-order word and a low-order
    word, four different bytes, or eight different nibbles (see [Figure 2-7](ch02s03.html#nibbles_comma_bytes_comma_and_words_in_a
    "Figure 2-7. Nibbles, bytes, and words in a double word")).
  prefs: []
  type: TYPE_NORMAL
- en: Double words (dwords) can represent all kinds of different things. A common
    item you will represent with a double word is a 32-bit integer value (that allows
    unsigned numbers in the range 0..4,294,967,295 or signed numbers in the range
    −2,147,483,648..2,147,483,647). 32-bit floating-point values also fit into a double
    word. Another common use for double-word objects is to store pointer values.
  prefs: []
  type: TYPE_NORMAL
- en: '![Nibbles, bytes, and words in a double word](tagoreillycom20100401nostarchimages577897.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-7. Nibbles, bytes, and words in a double word
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Chapter 1](ch01.html "Chapter 1. HELLO, WORLD OF ASSEMBLY LANGUAGE"), you
    saw how to create 32-bit signed integer variables using the `int32` data type.
    You can also create an arbitrary double-word variable using the `dword` data type,
    as the following example demonstrates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 2.3.6 Quad Words and Long Words
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Obviously, we can keep on defining larger and larger word sizes. However, the
    80x86 supports only certain native sizes, so there is little reason to keep on
    defining terms for larger and larger objects. Although bytes, words, and double
    words are the most common sizes you''ll find in 80x86 programs, quad word (64-bit)
    values are also important because certain floating-point data types require 64
    bits. Likewise, the SSE/MMX instruction set of modern 80x86 processors can manipulate
    64-bit values. In a similar vein, long-word (128-bit) values are also important
    because the SSE instruction set on later 80x86 processors can manipulate 128-bit
    values. HLA allows the declaration of 64- and 128-bit values using the `qword`
    and `lword` types, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that you may also define 64-bit and 128-bit integer values using HLA declarations
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: However, you may not directly manipulate 64-bit and 128-bit integer objects
    using standard instructions like `mov`, `add`, and `sub` because the standard
    80x86 integer registers process only 32 bits at a time. In [Chapter 8](ch08.html
    "Chapter 8. ADVANCED ARITHMETIC"), you will see how to manipulate these *extended-precision*
    values.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ^([[21](#CHP-2-FN-1)]) Binary-coded decimal is a numeric scheme used to represent
    decimal numbers using 4 bits for each decimal digit.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Arithmetic Operations on Binary and Hexadecimal Numbers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are several operations we can perform on binary and hexadecimal numbers.
    For example, we can add, subtract, multiply, divide, and perform other arithmetic
    operations. Although you needn''t become an expert at it, you should be able to,
    in a pinch, perform these operations manually using a piece of paper and a pencil.
    Having just said that you should be able to perform these operations manually,
    the correct way to perform such arithmetic operations is to have a calculator
    that does them for you. There are several such calculators on the market; the
    following list shows some of the manufacturers of hexadecimal calculators (in
    2010):'
  prefs: []
  type: TYPE_NORMAL
- en: Casio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hewlett-Packard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharp
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Texas Instruments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This list is by no means exhaustive. Other calculator manufacturers probably
    produce these devices as well. The Hewlett-Packard devices are arguably the best
    of the bunch. However, they are more expensive than the others. Sharp and Casio
    produce units that sell for well under fifty dollars. If you plan on doing any
    assembly language programming at all, owning one of these calculators is essential.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand why you should spend the money on a calculator, consider the
    following arithmetic problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You''re probably tempted to write in the answer $10 as the solution to this
    problem. But that is not correct! The correct answer is 10, which is $A, not 16,
    which is $10\. A similar problem exists with the following subtraction problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You're probably tempted to answer $9 even though the correct answer is $F. Remember,
    this problem is asking, "What is the difference between 16 and 1?" The answer,
    of course, is 15, which is $F.
  prefs: []
  type: TYPE_NORMAL
- en: Even if these two problems don't bother you, in a stressful situation your brain
    will switch back into decimal while you're thinking about something else and you'll
    produce the incorrect result. Moral of the story—if you must do an arithmetic
    computation using hexadecimal numbers by hand, take your time and be careful about
    it. Either that, or convert the numbers to decimal, perform the operation in decimal,
    and convert them back to hexadecimal.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5 A Note About Numbers vs. Representation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many people confuse numbers and their representation. A common question beginning
    assembly language students ask is, "I have a binary number in the EAX register;
    how do I convert that to a hexadecimal number in the EAX register?" The answer
    is, " You don't." Although a strong argument could be made that numbers in memory
    or in registers are represented in binary, it's best to view values in memory
    or in a register as *abstract numeric quantities*. Strings of symbols like 128,
    $80, or %1000_0000 are not different numbers; they are simply different representations
    for the same abstract quantity that we refer to as "one hundred twenty-eight."
    Inside the computer, a number is a number regardless of representation; the only
    time representation matters is when you input or output the value in a human-readable
    form.
  prefs: []
  type: TYPE_NORMAL
- en: Human-readable forms of numeric quantities are always strings of characters.
    To print the value 128 in human-readable form, you must convert the numeric value
    128 to the three-character sequence 1 followed by 2 followed by 8\. This would
    provide the decimal representation of the numeric quantity. If you prefer, you
    could convert the numeric value 128 to the three-character sequence $80\. It's
    the same number, but we've converted it to a different sequence of characters
    because (presumably) we wanted to view the number using hexadecimal representation
    rather than decimal. Likewise, if we want to see the number in binary, then we
    must convert this numeric value to a string containing a 1 followed by seven 0s.
  prefs: []
  type: TYPE_NORMAL
- en: By default, HLA displays all `byte`, `word`, `dword`, `qword`, and `lword` variables
    using the hexadecimal numbering system when using the `stdout.put` routine. Likewise,
    HLA's `stdout.put` routine will display all register values in hexadecimal form.
    Consider the program in [Example 2-1](ch02s05.html#decimal-to-hexadecimal_conversion_progra
    "Example 2-1. Decimal-to-hexadecimal conversion program"), which converts values
    input as decimal numbers to their hexadecimal equivalents.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-1. Decimal-to-hexadecimal conversion program
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In a similar fashion, the default input base is also hexadecimal for registers
    and `byte`, `word`, `dword`, `qword`, or `lword` variables. The program in [Example 2-2](ch02s05.html#hexadecimal-to-decimal_conversion_progra
    "Example 2-2. Hexadecimal-to-decimal conversion program") is the converse of the
    one in [Example 2-1](ch02s05.html#decimal-to-hexadecimal_conversion_progra "Example 2-1. Decimal-to-hexadecimal
    conversion program"); it inputs a hexadecimal value and outputs it as decimal.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-2. Hexadecimal-to-decimal conversion program
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Just because the HLA `stdout.put` routine chooses decimal as the default output
    base for `int8`, `int16`, and `int32` variables doesn't mean that these variables
    hold decimal numbers. Remember, memory and registers hold numeric values, not
    hexadecimal or decimal values. The `stdout.put` routine converts these numeric
    values to strings and prints the resulting strings. The choice of hexadecimal
    versus decimal output was a design choice in the HLA language, nothing more. You
    could very easily modify HLA so that it outputs registers and `byte`, `word`,
    `dword`, `qword`, or `lword` variables as decimal values rather than as hexadecimal.
    If you need to print the value of a register or `byte`, `word`, or `dword` variable
    as a decimal value, simply call one of the `putiX` routines to do this. The `stdout.puti8`
    routine will output its parameter as an 8-bit signed integer. Any 8-bit parameter
    will work. So you could pass an 8-bit register, an `int8` variable, or a `byte`
    variable as the parameter to `stdout.puti8` and the result will always be decimal.
    The `stdout.puti16` and `stdout.puti32` routines provide the same capabilities
    for 16-bit and 32-bit objects. The program in [Example 2-3](ch02s05.html#variable-less_hexadecimal-to-decimal_con
    "Example 2-3. Variable-less hexadecimal-to-decimal converter") demonstrates the
    decimal conversion program ([Example 2-2](ch02s05.html#hexadecimal-to-decimal_conversion_progra
    "Example 2-2. Hexadecimal-to-decimal conversion program")) using only the EBX
    register (that is, it does not use the variable `iValue`).
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-3. Variable-less hexadecimal-to-decimal converter
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note that HLA's `stdin.get` routine uses the same default base for input as
    `stdout.put` uses for output. That is, if you attempt to read an `int8`, `int16`,
    or `int32` variable, the default input base is decimal. If you attempt to read
    a register or `byte`, `word`, `dword`, `qword`, or `lword` variable, the default
    input base is hexadecimal. If you want to change the default input base to decimal
    when reading a register or a `byte`, `word`, `dword`, `qword`, or `lword` variable,
    then you can use `stdin.geti8`, `stdin.geti16`, `stdin.geti32`, `stdin.geti64`,
    or `stdin.geti128`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to go in the opposite direction, that is you want to input or output
    an `int8`, `int16`, `int32`, `int64`, or `int128` variable as a hexadecimal value,
    you can call the `stdout.puth8`, `stdout.puth16`, `stdout.puth32`, `stdout.puth64`,
    `stdout.puth128`, `stdin.geth8`, `stdin.geth16`, `stdin.geth32`, `stdin.geth64`,
    or `stdin.geth128` routines. The `stdout.puth8`, `stdout.puth16`, `stdout.puth32`,
    `stdout.puth64`, and `stdout.puth128` routines write 8-bit, 16-bit, 32-bit, 64-bit,
    or 128-bit objects as hexadecimal values. The `stdin.geth8`, `stdin.geth16`, `stdin.geth32`,
    `stdin.geth64`, and `stdin.geth128` routines read 8-, 16-, 32-, 64-, and 128-bit
    values, respectively; they return their results in the AL, AX, or EAX registers
    (or in a parameter location for 64-bit and 128-bit values). The program in [Example 2-4](ch02s05.html#demonstration_of_stdin.geth32_and_stdout
    "Example 2-4. Demonstration of stdin.geth32 and stdout.puth32") demonstrates the
    use of a few of these routines:'
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-4. Demonstration of `stdin.geth32` and `stdout.puth32`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 2.6 Logical Operations on Bits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are four primary logical operations we''ll do with hexadecimal and binary
    numbers: `and`, `or`, `xor` (exclusive-or), and `not`. Unlike for the arithmetic
    operations, a hexadecimal calculator isn''t necessary to perform these operations.
    It is often easier to do them by hand than to use an electronic device to compute
    them. The logical `and` operation is a dyadic^([[22](#ftn.CHP-2-FN-2)]) operation
    (meaning it accepts exactly two operands). These operands are individual binary
    bits. The `and` operation is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: A compact way to represent the logical `and` operation is with a truth table.
    A truth table takes the form shown in [Table 2-2](ch02s06.html#and_truth_table
    "Table 2-2. and Truth Table").
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-2. `and` Truth Table
  prefs: []
  type: TYPE_NORMAL
- en: '| **`and`** | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: This is just like the multiplication tables you've encountered in school. The
    values in the left column correspond to the leftmost operand of the `and` operation.
    The values in the top row correspond to the rightmost operand of the `and` operation.
    The value located at the intersection of the row and column (for a particular
    pair of input values) is the result of logically `and`ing those two values together.
  prefs: []
  type: TYPE_NORMAL
- en: In English, the logical `and` operation is, "If the first operand is 1 and the
    second operand is 1, the result is 1; otherwise the result is 0." We could also
    state this as, "If either or both operands are 0, the result is 0."
  prefs: []
  type: TYPE_NORMAL
- en: One important fact to note about the logical `and` operation is that you can
    use it to force a 0 result. If one of the operands is 0, the result is always
    0 regardless of the other operand. In the truth table above, for example, the
    row labeled with a 0 input contains only 0s, and the column labeled with a 0 contains
    only 0 results. Conversely, if one operand contains a 1, the result is exactly
    the value of the second operand. These results of the `and` operation are very
    important, particularly when we want to force bits to 0\. We will investigate
    these uses of the logical `and` operation in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logical `or` operation is also a dyadic operation. Its definition is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The truth table for the `or` operation takes the form appearing in [Table 2-3](ch02s06.html#or_truth_table
    "Table 2-3. or Truth Table").
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-3. `or` Truth Table
  prefs: []
  type: TYPE_NORMAL
- en: '| **`or`** | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Colloquially, the logical `or` operation is, "If the first operand or the second
    operand (or both) is 1, the result is 1; otherwise the result is 0." This is also
    known as the *inclusive-or* operation.
  prefs: []
  type: TYPE_NORMAL
- en: If one of the operands to the logical `or` operation is a 1, the result is always
    1 regardless of the second operand's value. If one operand is 0, the result is
    always the value of the second operand. Like the logical `and` operation, this
    is an important side effect of the logical `or` operation that will prove quite
    useful.
  prefs: []
  type: TYPE_NORMAL
- en: Note that there is a difference between this form of the inclusive logical `or`
    operation and the standard English meaning. Consider the phrase "I am going to
    the store *or* I am going to the park." Such a statement implies that the speaker
    is going to the store or to the park but not to both places. Therefore, the English
    version of logical `or` is slightly different from the inclusive-or operation;
    indeed, this is the definition of the *exclusive-or* operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logical `xor` (exclusive-or) operation is also a dyadic operation. Its
    definition follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The truth table for the `xor` operation takes the form shown in [Table 2-4](ch02s06.html#xor_truth_table
    "Table 2-4. xor Truth Table").
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-4. `xor` Truth Table
  prefs: []
  type: TYPE_NORMAL
- en: '| **`xor`** | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: In English, the logical `xor` operation is, "If the first operand or the second
    operand, but not both, is 1, the result is 1; otherwise the result is 0." Note
    that the exclusive-or operation is closer to the English meaning of the word *or*
    than is the logical `or` operation.
  prefs: []
  type: TYPE_NORMAL
- en: If one of the operands to the logical exclusive-or operation is a 1, the result
    is always the *inverse* of the other operand; that is, if one operand is 1, the
    result is 0 if the other operand is 1, and the result is 1 if the other operand
    is 0\. If the first operand contains a 0, then the result is exactly the value
    of the second operand. This feature lets you selectively invert bits in a bit
    string.
  prefs: []
  type: TYPE_NORMAL
- en: 'The logical `not` operation is a monadic operation (meaning it accepts only
    one operand):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The truth table for the `not` operation appears in [Table 2-5](ch02s06.html#not_truth_table
    "Table 2-5. not Truth Table").
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-5. `not` Truth Table
  prefs: []
  type: TYPE_NORMAL
- en: '| **`not`** | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|   | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ^([[22](#CHP-2-FN-2)]) Many texts call this a binary operation. The term *dyadic*
    means the same thing and avoids the confusion with the binary numbering system.
  prefs: []
  type: TYPE_NORMAL
- en: 2.7 Logical Operations on Binary Numbers and Bit Strings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The previous section defines the logical functions for single-bit operands.
    Because the 80x86 uses groups of 8, 16, or 32 bits, we need to extend the definition
    of these functions to deal with more than 2 bits. Logical functions on the 80x86
    operate on a *bit-by-bit* (or *bitwise*) basis. Given two values, these functions
    operate on bit 0, producing bit 0 of the result. They operate on bit 1 of the
    input values, producing bit 1 of the result, and so on. For example, if you want
    to compute the logical `and` of the following two 8-bit numbers, you would perform
    the logical `and` operation on each column independently of the others:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: You may apply this bit-by-bit calculation to the other logical functions as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: Because we've defined logical operations in terms of binary values, you'll find
    it much easier to perform logical operations on binary values than on other representations.
    Therefore, if you want to perform a logical operation on two hexadecimal numbers,
    you should convert them to binary first. This applies to most of the basic logical
    operations on binary numbers (e.g., `and`, `or`, `xor`, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: The ability to force bits to 0 or 1 using the logical `and`/`or` operations
    and the ability to invert bits using the logical `xor` operation are very important
    when working with strings of bits (e.g., binary numbers). These operations let
    you selectively manipulate certain bits within some bit string while leaving other
    bits unaffected. For example, if you have an 8-bit binary value *X* and you want
    to guarantee that bits 4..7 contain 0s, you could logically `and` the value *X*
    with the binary value %0000_1111\. This bitwise logical `and` operation would
    force the H.O. 4 bits to 0 and pass the L.O. 4 bits of *X* unchanged. Likewise,
    you could force the L.O. bit of *X* to 1 and invert bit 2 of *X* by logically
    `or`ing *X* with %0000_0001 and logically exclusive-`or`ing *X* with %0000_0100,
    respectively. Using the logical `and`, `or`, and `xor` operations to manipulate
    bit strings in this fashion is known as *masking* bit strings. We use the term
    *masking* because we can use certain values (1 for `and`, 0 for `or`/`xor`) to
    mask out or mask in certain bits from the operation when forcing bits to 0, 1,
    or their inverse.
  prefs: []
  type: TYPE_NORMAL
- en: 'The 80x86 CPUs support four instructions that apply these bitwise logical operations
    to their operands. The instructions are `and`, `or`, `xor`, and `not`. The `and`,
    `or`, and `xor` instructions use the same syntax as the `add` and `sub` instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'These operands have the same limitations as the `add` operands. Specifically,
    the *`source`* operand has to be a constant, memory, or register operand, and
    the *`dest`* operand must be a memory or register operand. Also, the operands
    must be the same size and they cannot both be memory operands. These instructions
    compute the obvious bitwise logical operation via the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The 80x86 logical `not` instruction, because it has only a single operand,
    uses a slightly different syntax. This instruction takes the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction computes the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The *`dest`* operand must be a register or memory operand. This instruction
    inverts all the bits in the specified destination operand.
  prefs: []
  type: TYPE_NORMAL
- en: 'The program in [Example 2-5](ch02s07.html#and_comma_or_comma_xor_comma_and_not_exa
    "Example 2-5. and, or, xor, and not example") inputs two hexadecimal values from
    the user and calculates their logical `and`, `or`, `xor`, and `not`:'
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-5. `and`, `or`, `xor`, and `not` example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 2.8 Signed and Unsigned Numbers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thus far, we've treated binary numbers as unsigned values. The binary number
    ...00000 represents 0, ...00001 represents 1, ...00010 represents 2, and so on
    toward infinity. What about negative numbers? Signed values have been tossed around
    in previous sections, and we've mentioned the two's complement numbering system,
    but we haven't discussed how to represent negative numbers using the binary numbering
    system. Now it is time to describe the two's complement numbering system.
  prefs: []
  type: TYPE_NORMAL
- en: 'To represent signed numbers using the binary numbering system, we have to place
    a restriction on our numbers: They must have a finite and fixed number of bits.
    For our purposes, we''re going to severely limit the number of bits to 8, 16,
    32, 64, 128, or some other small number of bits.'
  prefs: []
  type: TYPE_NORMAL
- en: With a fixed number of bits we can represent only a certain number of objects.
    For example, with 8 bits we can represent only 256 different values. Negative
    values are objects in their own right, just like positive numbers and 0; therefore,
    we'll have to use some of the 256 different 8-bit values to represent negative
    numbers. In other words, we have to use up some of the bit combinations to represent
    negative numbers. To make things fair, we'll assign half of the possible combinations
    to the negative values and half to the positive values and 0\. So we can represent
    the negative values −128..−1 and the nonnegative values 0..127 with a single 8-bit
    byte. With a 16-bit word we can represent values in the range −32,768..+32,767\.
    With a 32-bit double word we can represent values in the range −2,147,483,648..+2,147,483,647\.
    In general, with *n* bits we can represent the signed values in the range −2^(*n*−1)
    to +2^(*n*−1)−1.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, so we can represent negative values. Exactly how do we do it? Well, there
    are many possible ways, but the 80x86 microprocessor uses the two's complement
    notation, so it makes sense to study that method. In the two's complement system,
    the H.O. bit of a number is a *sign bit*. If the H.O. bit is 0, the number is
    positive; if the H.O. bit is 1, the number is negative. Following are some examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'For 16-bit numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'If the H.O. bit is 0, then the number is positive and uses the standard binary
    format. If the H.O. bit is 1, then the number is negative and uses the two''s
    complement form. To convert a positive number to its negative, two''s complement
    form, you use the following algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Invert all the bits in the number; that is, apply the logical `not` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add 1 to the inverted result and ignore any overflow out of the H.O. bit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For example, to compute the 8-bit equivalent of −5:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we take −5 and perform the two''s complement operation on it, we get our
    original value, %0000_0101, back again, just as we expect:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following examples provide some positive and negative 16-bit signed values:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To convert the numbers above to their negative counterpart (that is, to negate
    them), do the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $8000 inverted becomes $7FFF. After adding 1 we obtain $8000! Wait, what's going
    on here? −(−32,768) is −32,768? Of course not. But the value +32,768 cannot be
    represented with a 16-bit signed number, so we cannot negate the smallest negative
    value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Why bother with such a miserable numbering system? Why not use the H.O. bit
    as a sign flag, storing the positive equivalent of the number in the remaining
    bits? (This, by the way, is known as the *one''s complement numbering system*.)
    The answer lies in the hardware. As it turns out, negating values is the only
    tedious job. With the two''s complement system, most other operations are as easy
    as the binary system. For example, suppose you were to perform the addition 5
    + (−5). The result is 0\. Consider what happens when we add these two values in
    the two''s complement system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We end up with a carry into the ninth bit, and all other bits are 0\. As it
    turns out, if we ignore the carry out of the H.O. bit, adding two signed values
    always produces the correct result when using the two's complement numbering system.
    This means we can use the same hardware for signed and unsigned addition and subtraction.
    This wouldn't be the case with other numbering systems.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, you will not need to perform the two's complement operation by hand.
    The 80x86 microprocessor provides an instruction, `neg` (negate), that performs
    this operation for you. Furthermore, hexadecimal calculators perform this operation
    by pressing the change sign key (+/− or CHS). Nevertheless, manually computing
    the two's complement is easy, and you should know how to do it.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the data represented by a set of binary bits depends entirely
    on the context. The 8-bit binary value %1100_0000 could represent a character,
    it could represent the unsigned decimal value 192, or it could represent the signed
    decimal value −64\. As the programmer, it is your responsibility to define the
    data's format and then use the data consistently.
  prefs: []
  type: TYPE_NORMAL
- en: 'The 80x86 negate instruction, `neg`, uses the same syntax as the `not` instruction;
    that is, it takes a single destination operand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction computes *`dest`* `= -`*`dest`*`;` and the operand has the
    same limitations as for `not` (it must be a memory location or a register). `neg`
    operates on byte-, word-, and dword-sized objects. Because this is a signed integer
    operation, it only makes sense to operate on signed integer values. The program
    in [Example 2-6](ch02s08.html#twoscomplement_example "Example 2-6. twosComplement
    example") demonstrates the two''s complement operation by using the `neg` instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-6. `twosComplement` example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: As you've seen previously, you use the `int8`, `int16`, `int32`, `int64`, and
    `int128` data types to reserve storage for signed integer variables. You've also
    seen routines like `stdout.puti8` and `stdin.geti32` that read and write signed
    integer values. Because this section has made it abundantly clear that you must
    differentiate signed and unsigned calculations in your programs, you should probably
    be asking yourself, "How do I declare and use unsigned integer variables?"
  prefs: []
  type: TYPE_NORMAL
- en: 'The first part of the question, "How do I declare unsigned integer variables,"
    is the easiest to answer. You simply use the `uns8`, `uns16`, `uns32`, `uns64`,
    and `uns128` data types when declaring the variables. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: As for using these unsigned variables, the HLA Standard Library provides a complementary
    set of input/output routines for reading and displaying unsigned variables. As
    you can probably guess, these routines include `stdout.putu8`, `stdout.putu16`,
    `stdout.putu32`, `stdout.putu64`, `stdout.putu128`, `stdout.putu8Size`, `stdout.putu16Size`,
    `stdout.putu32Size`, `stdout.putu64Size`, `stdout.putu128Size`, `stdin.getu8`,
    `stdin.getu16`, `stdin.getu32`, `stdin.getu64`, and `stdin.getu128`. You use these
    routines just as you would use their signed integer counterparts except you get
    to use the full range of the unsigned values with these routines. The source code
    in [Example 2-7](ch02s08.html#unsigned_i_solidus_o "Example 2-7. Unsigned I/O")
    demonstrates unsigned I/O as well as demonstrates what can happen if you mix signed
    and unsigned operations in the same calculation.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-7. Unsigned I/O
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 2.9 Sign Extension, Zero Extension, Contraction, and Saturation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Because two's complement format integers have a fixed length, a small problem
    develops. What happens if you need to convert an 8-bit two's complement value
    to 16 bits? This problem and its converse (converting a 16-bit value to 8 bits)
    can be accomplished via *sign extension* and *contraction* operations.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the value −64\. The 8-bit two's complement value for this number is
    $C0\. The 16-bit equivalent of this number is $FFC0\. Now consider the value +64\.
    The 8- and 16-bit versions of this value are $40 and $0040, respectively. The
    difference between the 8- and 16-bit numbers can be described by the rule, "If
    the number is negative, the H.O. byte of the 16-bit number contains $FF; if the
    number is positive, the H.O. byte of the 16-bit quantity is 0."
  prefs: []
  type: TYPE_NORMAL
- en: To extend a signed value from some number of bits to a greater number of bits
    is easy; just copy the sign bit into all the additional bits in the new format.
    For example, to sign extend an 8-bit number to a 16-bit number, simply copy bit
    7 of the 8-bit number into bits 8..15 of the 16-bit number. To sign extend a 16-bit
    number to a double word, simply copy bit 15 into bits 16..31 of the double word.
  prefs: []
  type: TYPE_NORMAL
- en: 'You must use sign extension when manipulating signed values of varying lengths.
    Often you''ll need to add a byte quantity to a word quantity. You must sign extend
    the byte quantity to a word before the operation takes place. Other operations
    (multiplication and division, in particular) may require a sign extension to 32
    bits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: To extend an unsigned value to a larger one, you must zero extend the value.
    Zero extension is very easy—just store a 0 into the H.O. byte(s) of the larger
    operand. For example, to zero extend the 8-bit value $82 to 16 bits, you simply
    add a 0 to the H.O. byte, yielding $0082.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The 80x86 provides several instructions that will let you sign or zero extend
    a smaller number to a larger number. [Table 2-6](ch02s09.html#instructions_for_extending_al_comma_ax_c
    "Table 2-6. Instructions for Extending AL, AX, and EAX") lists a group of instructions
    that will sign extend the AL, AX, or EAX register.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-6. Instructions for Extending AL, AX, and EAX
  prefs: []
  type: TYPE_NORMAL
- en: '| Instruction | Explanation |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `cbw();` | Converts the byte in AL to a word in AX via sign extension. |'
  prefs: []
  type: TYPE_TB
- en: '| `cwd();` | Converts the word in AX to a double word in DX:AX via sign extension.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `cdq();` | Converts the double word in EAX to the quad word in EDX:EAX via
    sign extension. |'
  prefs: []
  type: TYPE_TB
- en: '| `cwde();` | Converts the word in AX to a double word in EAX via sign extension.
    |'
  prefs: []
  type: TYPE_TB
- en: Note that the `cwd` (convert word to double word) instruction does not sign
    extend the word in AX to the double word in EAX. Instead, it stores the H.O. word
    of the sign extension into the DX register (the notation DX:AX tells you that
    you have a double-word value with DX containing the upper 16 bits and AX containing
    the lower 16 bits of the value). If you want the sign extension of AX to go into
    EAX, you should use the `cwde` (convert word to double word, extended) instruction.
  prefs: []
  type: TYPE_NORMAL
- en: The four instructions above are unusual in the sense that these are the first
    instructions you've seen that do not have any operands. These instructions' operands
    are *implied* by the instructions themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Within a few chapters you will discover just how important these instructions
    are and why the `cwd` and `cdq` instructions involve the DX and EDX registers.
    However, for simple sign extension operations, these instructions have a few major
    drawbacks—you do not get to specify the source and destination operands, and the
    operands must be registers.
  prefs: []
  type: TYPE_NORMAL
- en: 'For general sign extension operations, the 80x86 provides an extension of the
    `mov` instruction, `movsx` (move with sign extension), that copies data and sign
    extends the data while copying it. The `movsx` instruction''s syntax is very similar
    to the `mov` instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The big difference in syntax between this instruction and the `mov` instruction
    is the fact that the destination operand must be larger than the source operand.
    That is, if the source operand is a byte, the destination operand must be a word
    or a double word. Likewise, if the source operand is a word, the destination operand
    must be a double word. Another difference is that the destination operand has
    to be a register; the source operand, however, can be a memory location.^([[23](#ftn.CHP-2-FN-3)])
    The `movsx` instruction does not allow constant operands.
  prefs: []
  type: TYPE_NORMAL
- en: To zero extend a value, you can use the `movzx` instruction. It has the same
    syntax and restrictions as the `movsx` instruction. Zero extending certain 8-bit
    registers (AL, BL, CL, and DL) into their corresponding 16-bit registers is easily
    accomplished without using `movzx` by loading the complementary H.O. register
    (AH, BH, CH, or DH) with 0\. Obviously, to zero extend AX into DX:AX or EAX into
    EDX:EAX, all you need to do is load DX or EDX with 0.^([[24](#ftn.CHP-2-FN-4)])
  prefs: []
  type: TYPE_NORMAL
- en: The sample program in [Example 2-8](ch02s09.html#sign_extension_instructions
    "Example 2-8. Sign extension instructions") demonstrates the use of the sign extension
    instructions.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-8. Sign extension instructions
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Sign *contraction*, converting a value with some number of bits to the identical
    value with a fewer number of bits, is a little more troublesome. Sign extension
    never fails. Given an *m*-bit signed value, you can always convert it to an *n*-bit
    number (where *n* > *m*) using sign extension. Unfortunately, given an *n*-bit
    number, you cannot always convert it to an *m*-bit number if *m* < *n*. For example,
    consider the value −448\. As a 16-bit signed number, its hexadecimal representation
    is $FE40\. Unfortunately, the magnitude of this number is too large for an 8-bit
    value, so you cannot sign contract it to 8 bits. This is an example of an overflow
    condition that occurs upon conversion.
  prefs: []
  type: TYPE_NORMAL
- en: 'To properly sign contract a value, you must look at the H.O. byte(s) that you
    want to discard. The H.O. bytes must all contain either 0 or $FF. If you encounter
    any other values, you cannot contract it without overflow. Finally, the H.O. bit
    of your resulting value must match *every* bit you''ve removed from the number.
    Here are some examples (16 bits to 8 bits):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Another way to reduce the size of an integer is by *saturation*. Saturation
    is useful in situations where you must convert a larger object to a smaller object,
    and you're willing to live with possible loss of precision. To convert a value
    via saturation you simply copy the larger value to the smaller value if it is
    not outside the range of the smaller object. If the larger value is outside the
    range of the smaller value, then you *clip* the value by setting it to the largest
    (or smallest) value within the range of the smaller object.
  prefs: []
  type: TYPE_NORMAL
- en: For example, when converting a 16-bit signed integer to an 8-bit signed integer,
    if the 16-bit value is in the range −128..+127, you simply copy the L.O. byte
    of the 16-bit object to the 8-bit object. If the 16-bit signed value is greater
    than +127, then you clip the value to +127 and store +127 into the 8-bit object.
    Likewise, if the value is less than −128, you clip the final 8-bit object to −128\.
    Saturation works the same way when clipping 32-bit values to smaller values. If
    the larger value is outside the range of the smaller value, then you simply set
    the smaller value to the value closest to the out-of-range value that you can
    represent with the smaller value.
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, if the larger value is outside the range of the smaller value, then
    there will be a loss of precision during the conversion. While clipping the value
    to the limits the smaller object imposes is never desirable, sometimes this is
    acceptable because the alternative is to raise an exception or otherwise reject
    the calculation. For many applications, such as audio or video processing, the
    clipped result is still recognizable, so this is a reasonable conversion.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ^([[23](#CHP-2-FN-3)]) This doesn't turn out to be much of a limitation because
    sign extension almost always precedes an arithmetic operation that must take place
    in a register.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[24](#CHP-2-FN-4)]) Zero extending into DX:AX or EDX:EAX is just as necessary
    as the CWD and CDQ instructions, as you will eventually see.
  prefs: []
  type: TYPE_NORMAL
- en: 2.10 Shifts and Rotates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another set of logical operations that apply to bit strings is the *shift* and
    *rotate* operations. These two categories can be further broken down into *left
    shifts, left rotates, right shifts*, and *right rotates*. These operations turn
    out to be extremely useful.
  prefs: []
  type: TYPE_NORMAL
- en: The left-shift operation moves each bit in a bit string one position to the
    left ([Figure 2-8](ch02s10.html#shift-left_operation "Figure 2-8. Shift-left operation")
    provides an example of an 8-bit shift).
  prefs: []
  type: TYPE_NORMAL
- en: '![Shift-left operation](tagoreillycom20100401nostarchimages577899.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-8. Shift-left operation
  prefs: []
  type: TYPE_NORMAL
- en: 'Bit 0 moves into bit position 1, the previous value in bit position 1 moves
    into bit position 2, and so on. There are, of course, two questions that naturally
    arise: "What goes into bit 0?" and "Where does the high-order bit go?" We''ll
    shift a 0 into bit 0, and the previous value of the high-order bit will become
    the *carry* out of this operation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The 80x86 provides a shift-left instruction, `shl`, that performs this useful
    operation. The syntax for the `shl` instruction is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The *`count`* operand is either CL or a constant in the range 0..*n*, where
    *n* is one less than the number of bits in the destination operand (for example,
    *n* = 7 for 8-bit operands, *n* = 15 for 16-bit operands, and *n* = 31 for 32-bit
    operands). The *`dest`* operand is a typical destination operand. It can be either
    a memory location or a register.
  prefs: []
  type: TYPE_NORMAL
- en: When the *`count`* operand is the constant 1, the `shl` instruction does the
    operation shown in [Figure 2-9](ch02s10.html#shift-left_operation-id1 "Figure 2-9. Shift-left
    operation").
  prefs: []
  type: TYPE_NORMAL
- en: '![Shift-left operation](tagoreillycom20100401nostarchimages577901.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-9. Shift-left operation
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 2-9](ch02s10.html#shift-left_operation-id1 "Figure 2-9. Shift-left
    operation"), the *C* represents the carry flag. That is, the H.O. bit shifted
    out of the operand moves into the carry flag. Therefore, you can test for overflow
    after a `shl( 1`, *`dest`* `);` instruction by testing the carry flag immediately
    after executing the instruction (e.g., by using `if( @c ) then...` or `if( @nc
    ) then...`).
  prefs: []
  type: TYPE_NORMAL
- en: Intel's literature suggests that the state of the carry flag is undefined if
    the shift count is a value other than 1\. Usually, the carry flag contains the
    last bit shifted out of the destination operand, but Intel doesn't seem to guarantee
    this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that shifting a value to the left is the same thing as multiplying it
    by its radix. For example, shifting a decimal number one position to the left
    (adding a 0 to the right of the number) effectively multiplies it by 10 (the radix):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: (`shl 1` means shift one digit position to the left.)
  prefs: []
  type: TYPE_NORMAL
- en: Because the radix of a binary number is 2, shifting it left multiplies it by
    2\. If you shift a binary value to the left twice, you multiply it by 2 twice
    (that is, you multiply it by 4). If you shift a binary value to the left three
    times, you multiply it by 8 (2*2*2). In general, if you shift a value to the left
    *n* times, you multiply that value by 2^(*n*).
  prefs: []
  type: TYPE_NORMAL
- en: A right-shift operation works the same way, except we're moving the data in
    the opposite direction. For a byte value, bit 7 moves into bit 6, bit 6 moves
    into bit 5, bit 5 moves into bit 4, and so on. During a right shift, we'll move
    a 0 into bit 7, and bit 0 will be the carry out of the operation (see [Figure 2-10](ch02s10.html#shift-right_operation
    "Figure 2-10. Shift-right operation")).
  prefs: []
  type: TYPE_NORMAL
- en: '![Shift-right operation](tagoreillycom20100401nostarchimages577903.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-10. Shift-right operation
  prefs: []
  type: TYPE_NORMAL
- en: 'As you would probably expect, the 80x86 provides a `shr` instruction that will
    shift the bits to the right in a destination operand. The syntax is the same as
    the `shl` instruction except, of course, you specify `shr` rather than `shl`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This instruction shifts a 0 into the H.O. bit of the destination operand, it
    shifts the other bits one place to the right (that is, from a higher bit number
    to a lower bit number). Finally, bit 0 is shifted into the carry flag. If you
    specify a count of 1, the `shr` instruction does the operation shown in [Figure 2-11](ch02s10.html#shift-right_operation-id1
    "Figure 2-11. Shift-right operation").
  prefs: []
  type: TYPE_NORMAL
- en: '![Shift-right operation](tagoreillycom20100401nostarchimages577905.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-11. Shift-right operation
  prefs: []
  type: TYPE_NORMAL
- en: Once again, Intel's documents suggest that shifts of more than 1 bit leave the
    carry in an undefined state.
  prefs: []
  type: TYPE_NORMAL
- en: Because a left shift is equivalent to a multiplication by 2, it should come
    as no surprise that a right shift is roughly comparable to a division by 2 (or,
    in general, a division by the radix of the number). If you perform *n* right shifts,
    you will divide that number by 2^(*n*).
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one problem with shift rights with respect to division: A shift right
    is only equivalent to an *unsigned* division by 2\. For example, if you shift
    the unsigned representation of 254 ($FE) one place to the right, you get 127 ($7F),
    exactly what you would expect. However, if you shift the binary representation
    of −2 ($FE) to the right one position, you get 127 ($7F), which is *not* correct.
    This problem occurs because we''re shifting a 0 into bit 7\. If bit 7 previously
    contained a 1, we''re changing it from a negative to a positive number. Not a
    good thing to do when dividing by 2.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To use the shift right as a division operator, we must define a third shift
    operation: arithmetic shift right.^([[25](#ftn.CHP-2-FN-5)]) An arithmetic shift
    right works just like the normal shift-right operation (a logical shift right)
    with one exception: Instead of shifting a 0 into the high-order bit, an arithmetic
    shift-right operation copies the high-order bit back into itself; that is, during
    the shift operation it does not modify the high-order bit, as [Figure 2-12](ch02s10.html#arithmetic_shift-right_operation
    "Figure 2-12. Arithmetic shift-right operation") shows.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Arithmetic shift-right operation](tagoreillycom20100401nostarchimages577907.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-12. Arithmetic shift-right operation
  prefs: []
  type: TYPE_NORMAL
- en: An arithmetic shift right generally produces the result you expect. For example,
    if you perform the arithmetic shift-right operation on −2 ($FE), you get −1 ($FF).
    Keep one thing in mind about arithmetic shift right, however. This operation always
    rounds the numbers to the closest integer that is *less than or equal to the actual
    result*. Based on experiences with high-level programming languages and the standard
    rules of integer truncation, most people assume this means that a division always
    truncates toward 0\. But this simply isn't the case. For example, if you apply
    the arithmetic shift-right operation on −1 ($FF), the result is −1, not 0\. Because
    −1 is less than 0, the arithmetic shift-right operation rounds toward −1\. This
    is not a bug in the arithmetic shift-right operation; it just uses a different
    (though valid) definition of integer division.
  prefs: []
  type: TYPE_NORMAL
- en: 'The 80x86 provides an arithmetic shift-right instruction, `sar` (shift arithmetic
    right). This instruction''s syntax is nearly identical to `shl` and `shr`. The
    syntax is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The usual limitations on the count and destination operands apply. This instruction
    operates as shown in [Figure 2-13](ch02s10.html#sar_open_parenthesis_1_comma_dest_close
    "Figure 2-13. sar( 1, dest ) operation") if the count is 1.
  prefs: []
  type: TYPE_NORMAL
- en: '![sar( 1, dest ) operation](tagoreillycom20100401nostarchimages577909.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-13. `sar( 1, dest )` operation
  prefs: []
  type: TYPE_NORMAL
- en: Once again, Intel's documents suggest that shifts of more than 1 bit leave the
    carry in an undefined state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another pair of useful operations are *rotate left* and *rotate right*. These
    operations behave like the shift-left and shift-right operations with one major
    difference: The bit shifted out from one end is shifted back in at the other end.
    [Figure 2-14](ch02s10.html#rotate-left_and_rotate-right_operations "Figure 2-14. Rotate-left
    and rotate-right operations") diagrams these operations.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Rotate-left and rotate-right operations](tagoreillycom20100401nostarchimages577911.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-14. Rotate-left and rotate-right operations
  prefs: []
  type: TYPE_NORMAL
- en: 'The 80x86 provides `rol` (rotate left) and `ror` (rotate right) instructions
    that do these basic operations on their operands. The syntax for these two instructions
    is similar to the shift instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Once again, these instructions provide a special behavior if the shift count
    is 1\. Under this condition these two instructions also copy the bit shifted out
    of the destination operand into the carry flag as [Figure 2-15](ch02s10.html#rol_open_parenthesis_1_comma_dest_close
    "Figure 2-15. rol( 1, dest ) operation") and [Figure 2-16](ch02s10.html#ror_open_parenthesis_1_comma_dest_close
    "Figure 2-16. ror( 1, dest ) operation") show.
  prefs: []
  type: TYPE_NORMAL
- en: '![rol( 1, dest ) operation](tagoreillycom20100401nostarchimages577913.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-15. `rol( 1, dest )` operation
  prefs: []
  type: TYPE_NORMAL
- en: Note that Intel's documents suggest that rotates of more than 1 bit leave the
    carry in an undefined state.
  prefs: []
  type: TYPE_NORMAL
- en: '![ror( 1, dest ) operation](tagoreillycom20100401nostarchimages577915.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-16. `ror( 1, dest )` operation
  prefs: []
  type: TYPE_NORMAL
- en: 'It is often more convenient for the rotate operation to shift the output bit
    through the carry and shift the previous carry value back into the input bit of
    the shift operation. The 80x86 `rcl` (rotate through carry left) and `rcr` (rotate
    through carry right) instructions achieve this for you. These instructions use
    the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: As is true for the other shift and rotate instructions, the *`count`* operand
    is either a constant or the CL register, and the *`dest`* operand is a memory
    location or register. The *`count`* operand must be a value that is less than
    the number of bits in the *`dest`* operand. For a count value of 1, these two
    instructions do the rotation shown in [Figure 2-17](ch02s10.html#rcl_open_parenthesis_1_comma_dest_close
    "Figure 2-17. rcl( 1, dest ) and rcr( 1, dest ) operations").
  prefs: []
  type: TYPE_NORMAL
- en: '![rcl( 1, dest ) and rcr( 1, dest ) operations](tagoreillycom20100401nostarchimages577917.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-17. `rcl( 1, dest )` and `rcr( 1, dest )` operations
  prefs: []
  type: TYPE_NORMAL
- en: Again, Intel's documents suggest that rotates of more than 1 bit leave the carry
    in an undefined state.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ^([[25](#CHP-2-FN-5)]) There is no need for an arithmetic shift left. The standard
    shift-left operation works for both signed and unsigned numbers, assuming no overflow
    occurs.
  prefs: []
  type: TYPE_NORMAL
- en: 2.11 Bit Fields and Packed Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although the 80x86 operates most efficiently on `byte`, `word`, and `dword`
    data types, occasionally you''ll need to work with a data type that uses some
    number of bits other than 8, 16, or 32\. For example, consider a date of the form
    04/02/01\. It takes three numeric values to represent this date: month, day, and
    year values. Months, of course, take on the values 1..12\. It will require at
    least 4 bits (maximum of 16 different values) to represent the month. Days range
    between 1 and 31\. So it will take 5 bits (maximum of 32 different values) to
    represent the day entry. The year value, assuming that we''re working with values
    in the range 0..99, requires 7 bits (that can be used to represent up to 128 different
    values). 4 + 5 + 7 = 16 bits, or 2 bytes. In other words, we can pack our date
    data into 2 bytes rather than the 3 that would be required if we used a separate
    byte for each of the month, day, and year values. This saves 1 byte of memory
    for each date stored, which could be a substantial saving if you need to store
    many dates. The bits could be arranged as shown in [Figure 2-18](ch02s11.html#short_packed_date_format_open_parenthesi
    "Figure 2-18. Short packed date format (2 bytes)").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Short packed date format (2 bytes)](tagoreillycom20100401nostarchimages577919.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-18. Short packed date format (2 bytes)
  prefs: []
  type: TYPE_NORMAL
- en: 'MMMM represents the 4 bits making up the month value, DDDDD represents the
    5 bits making up the day, and YYYYYYY is the 7 bits composing the year. Each collection
    of bits representing a data item is a *bit field*. For example, April 2, 2001,
    would be represented as $4101:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Although packed values are *space efficient* (that is, very efficient in terms
    of memory usage), they are computationally *inefficient* (slow!). The reason?
    It takes extra instructions to unpack the data packed into the various bit fields.
    These extra instructions take additional time to execute (and additional bytes
    to hold the instructions); hence, you must carefully consider whether packed data
    fields will save you anything. The sample program in [Example 2-9](ch02s11.html#packing_and_unpacking_date_data
    "Example 2-9. Packing and unpacking date data") demonstrates the effort that must
    go into packing and unpacking this 16-bit date format.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-9. Packing and unpacking date data
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Of course, having gone through the problems with Y2K (Year 2000), you know that
    using a date format that limits you to 100 years (or even 127 years) would be
    quite foolish at this time. If you are concerned about your software running 100
    years from now, perhaps it would be wise to use a 3-byte date format rather than
    a 2-byte format. As you will see in the chapter on arrays, however, you should
    always try to create data objects whose length is an even power of 2 (1 byte,
    2 bytes, 4 bytes, 8 bytes, and so on) or you will pay a performance penalty. Hence,
    it is probably wise to go ahead and use 4 bytes and pack this data into a double-word
    variable. [Figure 2-19](ch02s11.html#long_packed_date_format_open_parenthesis
    "Figure 2-19. Long packed date format (4 bytes)") shows one possible data organization
    for a 4-byte date.
  prefs: []
  type: TYPE_NORMAL
- en: '![Long packed date format (4 bytes)](tagoreillycom20100401nostarchimages577921.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-19. Long packed date format (4 bytes)
  prefs: []
  type: TYPE_NORMAL
- en: In this long packed date format we made several changes beyond simply extending
    the number of bits associated with the year. First, because there are extra bits
    in a 32-bit double-word variable, this format allocates extra bits to the month
    and day fields. Because these two fields now consist of 8 bits each, they can
    be easily extracted as a byte object from the double word. This leaves fewer bits
    for the year, but 65,536 years is probably sufficient; you can probably assume
    without too much concern that your software will not still be in use 63,000 years
    from now when this date format will no longer work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, you could argue that this is no longer a packed date format. After
    all, we needed three numeric values, two of which fit just nicely into 1 byte
    each and one that should probably have at least 2 bytes. Because this "packed"
    date format consumes the same 4 bytes as the unpacked version, what is so special
    about this format? Well, another difference you will note between this long packed
    date format and the short date format appearing in [Figure 2-18](ch02s11.html#short_packed_date_format_open_parenthesi
    "Figure 2-18. Short packed date format (2 bytes)") is the fact that this long
    date format rearranges the bits so the `Year` field is in the H.O. bit positions,
    the `Month` field is in the middle bit positions, and the `Day` field is in the
    L.O. bit positions. This is important because it allows you to very easily compare
    two dates to see if one date is less than, equal to, or greater than another date.
    Consider the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Had you kept the different date fields in separate variables, or organized the
    fields differently, you would not have been able to compare *`Date1`* and *`Date2`*
    in such an easy fashion. Therefore, this example demonstrates another reason for
    packing data even if you don't realize any space savings—it can make certain computations
    more convenient or even more efficient (contrary to what normally happens when
    you pack data).
  prefs: []
  type: TYPE_NORMAL
- en: Examples of practical packed data types abound. You could pack eight boolean
    values into a single byte, you could pack two BCD digits into a byte, and so on.
    Of course, a classic example of packed data is the EFLAGS register (see [Figure 2-20](ch02s11.html#eflags_register_as_packed_boolean_data
    "Figure 2-20. EFLAGS register as packed boolean data")). This register packs nine
    important boolean objects (along with seven important system flags) into a single
    16-bit register. You will commonly need to access many of these flags. For this
    reason, the 80x86 instruction set provides many ways to manipulate the individual
    bits in the EFLAGS register. Of course, you can test many of the condition code
    flags using the HLA pseudo-boolean variables such as `@c`, `@nc`, `@z`, and `@nz`
    in an `if` statement or other statement using a boolean expression.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the condition codes, the 80x86 provides instructions that directly
    affect certain flags ([Table 2-7](ch02s11.html#instructions_that_affect_certain_flags
    "Table 2-7. Instructions That Affect Certain Flags")).
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-7. Instructions That Affect Certain Flags
  prefs: []
  type: TYPE_NORMAL
- en: '| Instruction | Explanation |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `cld();` | Clears (sets to 0) the direction flag. |'
  prefs: []
  type: TYPE_TB
- en: '| `std();` | Sets (to 1) the direction flag. |'
  prefs: []
  type: TYPE_TB
- en: '| `cli();` | Clears the interrupt disable flag. |'
  prefs: []
  type: TYPE_TB
- en: '| `sti();` | Sets the interrupt disable flag. |'
  prefs: []
  type: TYPE_TB
- en: '| `clc();` | Clears the carry flag. |'
  prefs: []
  type: TYPE_TB
- en: '| `stc();` | Sets the carry flag. |'
  prefs: []
  type: TYPE_TB
- en: '| `cmc();` | Complements (inverts) the carry flag. |'
  prefs: []
  type: TYPE_TB
- en: '| `sahf();` | Stores the AH register into the L.O. 8 bits of the EFLAGS register.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `lahf();` | Loads AH from the L.O. 8 bits of the EFLAGS register. |'
  prefs: []
  type: TYPE_TB
- en: There are other instructions that affect the EFLAGS register as well; these
    instructions, however, demonstrate how to access several of the packed boolean
    values in the EFLAGS register. The `lahf` and `sahf` instructions, in particular,
    provide a convenient way to access the L.O. 8 bits of the EFLAGS register as an
    8-bit byte (rather than as eight separate 1-bit values). See [Figure 2-20](ch02s11.html#eflags_register_as_packed_boolean_data
    "Figure 2-20. EFLAGS register as packed boolean data") for a layout of the EFLAGS
    register.
  prefs: []
  type: TYPE_NORMAL
- en: '![EFLAGS register as packed boolean data](tagoreillycom20100401nostarchimages577923.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-20. EFLAGS register as packed boolean data
  prefs: []
  type: TYPE_NORMAL
- en: 'The `lahf` (load AH with the L.O. 8 bits of the EFLAGS register) and the `sahf`
    (store AH into the L.O. byte of the EFLAGS register) use the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 2.12 An Introduction to Floating-Point Arithmetic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Integer arithmetic does not let you represent fractional numeric values. Therefore,
    modern CPUs support an approximation of *real* arithmetic: floating-point arithmetic.
    A big problem with floating-point arithmetic is that it does not follow the standard
    rules of algebra. Nevertheless, many programmers apply normal algebraic rules
    when using floating-point arithmetic. This is a source of defects in many programs.
    One of the primary goals of this section is to describe the limitations of floating-point
    arithmetic so you will understand how to use it properly.'
  prefs: []
  type: TYPE_NORMAL
- en: Normal algebraic rules apply only to *infinite precision* arithmetic. Consider
    the simple statement *x* := *x* + 1, where *x* is an integer. On any modern computer
    this statement follows the normal rules of algebra *as long as overflow does not
    occur*. That is, this statement is valid only for certain values of *x* (*minint*
    <= *x* < *maxint*). Most programmers do not have a problem with this because they
    are well aware of the fact that integers in a program do not follow the standard
    algebraic rules (e.g., 5/2 does not equal 2.5).
  prefs: []
  type: TYPE_NORMAL
- en: Integers do not follow the standard rules of algebra because the computer represents
    them with a finite number of bits. You cannot represent any of the (integer) values
    above the maximum integer or below the minimum integer. Floating-point values
    suffer from this same problem, only worse. After all, the integers are a subset
    of the real numbers. Therefore, the floating-point values must represent the same
    infinite set of integers. However, there are an infinite number of real values
    between any two integer values, so this problem is infinitely worse. Therefore,
    as well as having to limit your values between a maximum and minimum range, you
    cannot represent all the values between those two ranges either.
  prefs: []
  type: TYPE_NORMAL
- en: To represent real numbers, most floating-point formats employ scientific notation
    and use some number of bits to represent a *mantissa* and a smaller number of
    bits to represent an *exponent*. The end result is that floating-point numbers
    can only represent numbers with a specific number of *significant* digits. This
    has a big impact on how floating-point arithmetic operates. To easily see the
    impact of limited precision arithmetic, we will adopt a simplified decimal floating-point
    format for our examples. Our floating-point format will provide a mantissa with
    three significant digits and a decimal exponent with two digits. The mantissa
    and exponents are both signed values, as shown in [Figure 2-21](ch02s12.html#a_floating-point_format
    "Figure 2-21. A floating-point format").
  prefs: []
  type: TYPE_NORMAL
- en: '![A floating-point format](tagoreillycom20100401nostarchimages577925.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-21. A floating-point format
  prefs: []
  type: TYPE_NORMAL
- en: When adding and subtracting two numbers in scientific notation, we must adjust
    the two values so that their exponents are the same. For example, when adding
    1.23e1 and 4.56e0, we must adjust the values so they have the same exponent. One
    way to do this is to convert 4.56e0 to 0.456e1 and then add. This produces 1.686e1\.
    Unfortunately, the result does not fit into three significant digits, so we must
    either *round* or *truncate* the result to three significant digits. Rounding
    generally produces the most accurate result, so let's round the result to obtain
    1.69e1\. As you can see, the lack of *precision* (the number of digits or bits
    we maintain in a computation) affects the accuracy (the correctness of the computation).
  prefs: []
  type: TYPE_NORMAL
- en: In the previous example, we were able to round the result because we maintained
    *four* significant digits *during* the calculation. If our floating-point calculation
    had been limited to three significant digits *during* computation, we would have
    had to truncate the last digit of the smaller number, obtaining 1.68e1, a value
    that is even less accurate. To improve the accuracy of floating-point calculations,
    it is necessary to add extra digits for use during the calculation. Extra digits
    available during a computation are known as *guard digits* (or *guard bits* in
    the case of a binary format). They greatly enhance accuracy during a long chain
    of computations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The accuracy loss during a single computation usually isn''t enough to worry
    about unless you are greatly concerned about the accuracy of your computations.
    However, if you compute a value that is the result of a sequence of floating-point
    operations, the error can *accumulate* and greatly affect the computation itself.
    For example, suppose we were to add 1.23e3 to 1.00e0\. Adjusting the numbers so
    their exponents are the same before the addition produces 1.23e3 + 0.001e3\. The
    sum of these two values, even after rounding, is 1.23e3\. This might seem perfectly
    reasonable to you; after all, we can maintain only three significant digits, so
    adding in a small value shouldn''t affect the result at all. However, suppose
    we were to add 1.00e0 to 1.23e3 *ten times*. The first time we add 1.00e0 to 1.23e3
    we get 1.23e3\. Likewise, we get this same result the second, third, fourth .
    . . and tenth times we add 1.00e0 to 1.23e3\. On the other hand, had we added
    1.00e0 to itself 10 times, then added the result (1.00e1) to 1.23e3, we would
    have gotten a different result, 1.24e3\. This is an important thing to know about
    limited-precision arithmetic:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The order of evaluation can affect the accuracy of the result**.'
  prefs: []
  type: TYPE_NORMAL
- en: You will get more accurate results if the relative magnitudes (that is, the
    exponents) are close to one another when adding and subtracting floating-point
    values. If you are performing a chain calculation involving addition and subtraction,
    you should attempt to group the values appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: '| Another problem with addition and subtraction is that you can wind up with
    *false precision*. Consider the computation 1.23e0 − 1.22e0\. This produces 0.01e0\.
    Although this is mathematically equivalent to 1.00e − 2, this latter form suggests
    that the last two digits are exactly 0\. Unfortunately, we have only a single
    significant digit at this time. Indeed, some floating-point unit (FPU) software
    packages might actually insert random digits (or bits) into the L.O. positions.
    This brings up a second important rule concerning limited precision arithmetic:
    |'
  prefs: []
  type: TYPE_TB
- en: '**When subtracting two numbers with the same signs or adding two numbers with
    different signs, the accuracy of the result may be less than the precision available
    in the floating-point format**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiplication and division do not suffer from the same problems as addition
    and subtraction because you do not have to adjust the exponents before the operation;
    all you need to do is add the exponents and multiply the mantissas (or subtract
    the exponents and divide the mantissas). By themselves, multiplication and division
    do not produce particularly poor results. However, they tend to multiply any error
    that already exists in a value. For example, if you multiply 1.23e0 by 2, when
    you should be multiplying 1.24e0 by 2, the result is even less accurate. This
    brings up a third important rule when working with limited-precision arithmetic:'
  prefs: []
  type: TYPE_NORMAL
- en: '**When performing a chain of calculations involving addition, subtraction,
    multiplication, and division, try to perform the multiplication and division operations
    first**.'
  prefs: []
  type: TYPE_NORMAL
- en: Often, by applying normal algebraic transformations, you can arrange a calculation
    so the multiply and divide operations occur first. For example, suppose you want
    to compute *x* * ( *y* + *z* ). Normally you would add *y* and *z* together and
    multiply their sum by *x*. However, you will get a little more accuracy if you
    transform *x* * ( *y* + *z* ) to get *x* * *y* + *x* * *z* and compute the result
    by performing the multiplications first.^([[26](#ftn.CHP-2-FN-6)])
  prefs: []
  type: TYPE_NORMAL
- en: '| Multiplication and division are not without their own problems. When multiplying
    two very large or very small numbers, it is quite possible for *overflow* or *underflow*
    to occur. The same situation occurs when dividing a small number by a large number
    or dividing a large number by a small number. This brings up a fourth rule you
    should attempt to follow when multiplying or dividing values: |'
  prefs: []
  type: TYPE_TB
- en: '**When multiplying and dividing sets of numbers, try to arrange the multiplications
    so that they multiply large and small numbers together; likewise, try to divide
    numbers that have the same relative magnitudes**.'
  prefs: []
  type: TYPE_NORMAL
- en: Comparing floating-point numbers is very dangerous. Given the inaccuracies present
    in any computation (including converting an input string to a floating-point value),
    you should *never* compare two floating-point values to see if they are equal.
    In a binary floating-point format, different computations that produce the same
    (mathematical) result may differ in their least significant bits. For example,
    1.31e0 + 1.69e0 should produce 3.00e0\. Likewise, 1.50e0 + 1.50e0 should produce
    3.00e0\. However, if you were to compare (1.31e0 + 1.69e0) against (1.50e0 + 1.50e0),
    you might find out that these sums are *not* equal to one another. The test for
    equality succeeds if and only if all bits (or digits) in the two operands are
    exactly the same. Because this is not necessarily true after two different floating-point
    computations that should produce the same result, a straight test for equality
    may not work.
  prefs: []
  type: TYPE_NORMAL
- en: '| The standard way to test for equality between floating-point numbers is to
    determine how much error (or tolerance) you will allow in a comparison and check
    to see if one value is within this error range of the other. The usual way to
    do this is to use a test like the following: |'
  prefs: []
  type: TYPE_TB
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '| Another common way to handle this same comparison is to use a statement of
    the form |'
  prefs: []
  type: TYPE_TB
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '| You must exercise care when choosing the value for *`error`*. This should
    be a value slightly greater than the largest amount of error that will creep into
    your computations. The exact value will depend upon the particular floating-point
    format you use, but more on that a little later. Here is the final rule we will
    state in this section: |'
  prefs: []
  type: TYPE_TB
- en: '**When comparing two floating-point numbers, always compare one value to see
    if it is in the range given by the second value plus or minus some small error
    value**.'
  prefs: []
  type: TYPE_NORMAL
- en: There are many other little problems that can occur when using floating-point
    values. This text can only point out some of the major problems and make you aware
    of the fact that you cannot treat floating-point arithmetic like real arithmetic—the
    inaccuracies present in limited-precision arithmetic can get you into trouble
    if you are not careful. A good text on numerical analysis or even scientific computing
    can help fill in the details that are beyond the scope of this text. If you are
    going to be working with floating-point arithmetic, *in any language*, you should
    take the time to study the effects of limited-precision arithmetic on your computations.
  prefs: []
  type: TYPE_NORMAL
- en: '| HLA''s `if` statement does not support boolean expressions involving floating-point
    operands. Therefore, you cannot use statements like `if( x < 3.141) then...` in
    your programs. [Chapter 6](ch06.html "Chapter 6. ARITHMETIC") will teach you how
    to do floating-point comparisons. |'
  prefs: []
  type: TYPE_TB
- en: 2.12.1 IEEE Floating-Point Formats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When Intel planned to introduce a floating-point unit for its new 8086 microprocessor,
    it was smart enough to realize that the electrical engineers and solid-state physicists
    who design chips were probably not the best people to pick the best possible binary
    representation for a floating-point format. So Intel went out and hired the best
    numerical analyst it could find to design a floating-point format for its 8087
    FPU. That person then hired two other experts in the field, and the three of them
    (Kahn, Coonan, and Stone) designed Intel's floating-point format. They did such
    a good job designing the KCS Floating-Point Standard that the IEEE organization
    adopted this format for the IEEE floating-point format.^([[27](#ftn.CHP-2-FN-7)])
  prefs: []
  type: TYPE_NORMAL
- en: 'To handle a wide range of performance and accuracy requirements, Intel actually
    introduced *three* floating-point formats: single-precision, double-precision,
    and extended-precision. The single- and double-precision formats corresponded
    to C''s float and double types or FORTRAN''s real and double-precision types.
    Intel intended to use extended-precision for long chains of computations. Extended-precision
    contains 16 extra bits that the calculations could use as guard bits before rounding
    down to a double-precision value when storing the result.'
  prefs: []
  type: TYPE_NORMAL
- en: The single-precision format uses a *one's complement 24-bit mantissa* and an
    *8-bit excess-127 exponent*. The mantissa usually represents a value from 1.0
    to just under 2.0\. The H.O. bit of the mantissa is always assumed to be 1 and
    represents a value just to the left of the *binary point*.^([[28](#ftn.CHP-2-FN-8)])
    The remaining 23 mantissa bits appear to the right of the binary point. Therefore,
    the mantissa represents the value
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The `mmmm` characters represent the 23 bits of the mantissa. Keep in mind that
    we are working with binary numbers here. Therefore, each position to the right
    of the binary point represents a value (0 or 1) times a successive negative power
    of 2\. The implied 1 bit is always multiplied by 2⁰, which is 1\. This is why
    the mantissa is always greater than or equal to 1\. Even if the other mantissa
    bits are all 0, the implied 1 bit always gives us the value 1^([[29](#ftn.CHP-2-FN-9)]).
    Of course, even if we had an almost infinite number of 1 bits after the binary
    point, they still would not add up to 2\. This is why the mantissa can represent
    values in the range 1 to just under 2.
  prefs: []
  type: TYPE_NORMAL
- en: Although there are an infinite number of values between 1 and 2, we can only
    represent 8 million of them because we use a 23-bit mantissa (the 24th bit is
    always 1). This is the reason for inaccuracy in floating-point arithmetic—we are
    limited to 23 bits of precision in computations involving single-precision floating-point
    values.
  prefs: []
  type: TYPE_NORMAL
- en: The mantissa uses a one's complement format rather than two's complement. This
    means that the 24-bit value of the mantissa is simply an unsigned binary number,
    and the sign bit determines whether that value is positive or negative. One's
    complement numbers have the unusual property that there are two representations
    for 0 (with the sign bit set or clear). Generally, this is important only to the
    person designing the floating-point software or hardware system. We will assume
    that the value 0 always has the sign bit clear.
  prefs: []
  type: TYPE_NORMAL
- en: To represent values outside the range 1.0 to just under 2.0, the exponent portion
    of the floating-point format comes into play. The floating-point format raises
    2 to the power specified by the exponent and then multiplies the mantissa by this
    value. The exponent is 8 bits and is stored in an *excess-127* format. In excess-127
    format, the exponent 2⁰ is represented by the value 127 ($7F ). Therefore, to
    convert an exponent to excess-127 format, simply add 127 to the exponent value.
    The use of excess-127 format makes it easier to compare floating-point values.
    The single-precision floating-point format takes the form shown in [Figure 2-22](ch02s12.html#single-precision_open_parenthesis_32-bit
    "Figure 2-22. Single-precision (32-bit) floating-point format").
  prefs: []
  type: TYPE_NORMAL
- en: '![Single-precision (32-bit) floating-point format](tagoreillycom20100401nostarchimages577927.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-22. Single-precision (32-bit) floating-point format
  prefs: []
  type: TYPE_NORMAL
- en: With a 24-bit mantissa, you will get approximately 6 ½ digits of precision (½
    digit of precision means that the first six digits can all be in the range 0..9,
    but the seventh digit can only be in the range 0..*x*, where *x* < 9 and is generally
    close to 5). With an 8-bit excess-127 exponent, the dynamic range of single-precision
    floating-point numbers is approximately 2 ± 128 or about 10 ± 38.
  prefs: []
  type: TYPE_NORMAL
- en: Although single-precision floating-point numbers are perfectly suitable for
    many applications, the dynamic range is somewhat limited and is unsuitable for
    many financial, scientific, and other applications. Furthermore, during long chains
    of computations, the limited accuracy of the single-precision format may introduce
    serious error.
  prefs: []
  type: TYPE_NORMAL
- en: The double-precision format helps overcome the problems of single-precision
    floating-point. Using twice the space, the double-precision format has an 11-bit
    excess-1023 exponent and a 53-bit mantissa (with an implied H.O. bit of 1) plus
    a sign bit. This provides a dynamic range of about 10^(±308) and 14 ½ digits of
    precision, sufficient for most applications. Double-precision floating-point values
    take the form shown in [Figure 2-23](ch02s12.html#bit_double-precision_floating-point_for
    "Figure 2-23. 64-bit double-precision floating-point format").
  prefs: []
  type: TYPE_NORMAL
- en: '![64-bit double-precision floating-point format](tagoreillycom20100401nostarchimages577929.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-23. 64-bit double-precision floating-point format
  prefs: []
  type: TYPE_NORMAL
- en: In order to help ensure accuracy during long chains of computations involving
    double-precision floating-point numbers, Intel designed the extended-precision
    format. The extended-precision format uses 80 bits. Twelve of the additional 16
    bits are appended to the mantissa and four of the additional bits are appended
    to the end of the exponent. Unlike the single- and double-precision values, the
    extended-precision format's mantissa does not have an implied H.O. bit, which
    is always 1\. Therefore, the extended-precision format provides a 64-bit mantissa,
    a 15-bit excess-16383 exponent, and a 1-bit sign. The format for the extended-precision
    floating-point value is shown in [Figure 2-24](ch02s12.html#bit_extended-precision_floating-point_f
    "Figure 2-24. 80-bit extended-precision floating-point format").
  prefs: []
  type: TYPE_NORMAL
- en: '![80-bit extended-precision floating-point format](tagoreillycom20100401nostarchimages577931.png.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-24. 80-bit extended-precision floating-point format
  prefs: []
  type: TYPE_NORMAL
- en: On the FPUs all computations are done using the extended-precision format. Whenever
    you load a single or double-precision value, the FPU automatically converts it
    to an extended-precision value. Likewise, when you store a single or double-precision
    value to memory, the FPU automatically rounds the value down to the appropriate
    size before storing it. By always working with the extended-precision format,
    Intel guarantees a large number of guard bits are present to ensure the accuracy
    of your computations.
  prefs: []
  type: TYPE_NORMAL
- en: To maintain maximum precision during computation, most computations use *normalized*
    values. A normalized floating-point value is one whose H.O. mantissa bit contains
    1\. Almost any nonnormalized value can be normalized; shift the mantissa bits
    to the left and decrement the exponent until a 1 appears in the H.O. bit of the
    mantissa. Remember, the exponent is a binary exponent. Each time you increment
    the exponent, you multiply the floating-point value by 2\. Likewise, whenever
    you decrement the exponent, you divide the floating-point value by 2\. By the
    same token, shifting the mantissa to the left one bit position multiplies the
    floating-point value by 2; likewise, shifting the mantissa to the right divides
    the floating-point value by 2\. Therefore, shifting the mantissa to the left one
    position *and* decrementing the exponent does not change the value of the floating-point
    number at all.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping floating-point numbers normalized is beneficial because it maintains
    the maximum number of bits of precision for a computation. If the H.O. bits of
    the mantissa are all 0, the mantissa has that many fewer bits of precision available
    for computation. Therefore, a floating-point computation will be more accurate
    if it involves only normalized values.
  prefs: []
  type: TYPE_NORMAL
- en: There are two important cases where a floating-point number cannot be normalized.
    Zero is one of these special cases. Obviously it cannot be normalized because
    the floating-point representation for 0 has no 1 bits in the mantissa. This, however,
    is not a problem because we can exactly represent the value 0 with only a single
    bit.
  prefs: []
  type: TYPE_NORMAL
- en: The second case is when we have some H.O. bits in the mantissa that are 0 but
    the biased exponent is also 0 (and we cannot decrement it to normalize the mantissa).
    Rather than disallow certain small values, whose H.O. mantissa bits and biased
    exponent are 0 (the most negative exponent possible), the IEEE standard allows
    special *denormalized* values to represent these smaller values.^([[30](#ftn.CHP-2-FN-10)])
    Although the use of denormalized values allows IEEE floating-point computations
    to produce better results than if underflow occurred, keep in mind that denormalized
    values offer less bits of precision.
  prefs: []
  type: TYPE_NORMAL
- en: 2.12.2 HLA Support for Floating-Point Values
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: HLA provides several data types and library routines to support the use of floating-point
    data in your assembly language programs. These include built-in types to declare
    floating-point variables as well as routines that provide floating-point input,
    output, and conversion.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps the best place to start when discussing HLA''s floating-point facilities
    is with a description of floating-point literal constants. HLA floating-point
    constants allow the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: An optional `+` or `−` symbol, denoting the sign of the mantissa (if this is
    not present, HLA assumes that the mantissa is positive)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Followed by one or more decimal digits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optionally followed by a decimal point and one or more decimal digits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optionally followed by an `e` or `E`, optionally followed by a sign (`+` or
    `−`) and one or more decimal digits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note that the decimal point or the `e`/`E` must be present in order to differentiate
    this value from an integer or unsigned literal constant. Here are some examples
    of legal literal floating-point constants:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Notice that a floating-point literal constant cannot begin with a decimal point;
    it must begin with a decimal digit, so you must use 0.1 to represent .1 in your
    programs.
  prefs: []
  type: TYPE_NORMAL
- en: 'HLA also allows you to place an underscore character (`_`) between any two
    consecutive decimal digits in a floating-point literal constant. You may use the
    underscore character in place of a comma (or other language-specific separator
    character) to help make your large floating-point numbers easier to read. Here
    are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'To declare a floating-point variable you use the `real32`, `real64`, or `real80`
    data types. Like their integer and unsigned brethren, the number at the end of
    these data type declarations specifies the number of bits used for each type''s
    binary representation. Therefore, you use `real32` to declare single-precision
    real values, `real64` to declare double-precision floating-point values, and `real80`
    to declare extended-precision floating-point values. Other than the fact that
    you use these types to declare floating-point variables rather than integers,
    their use is nearly identical to that for `int8`, `int16`, `int32`*,* and so on.
    The following examples demonstrate these declarations and their syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'To output a floating-point variable in ASCII form, you would use one of the
    `stdout.putr32`*,* `stdout.putr64`, or `stdout.putr80` routines. These procedures
    display a number in decimal notation, that is, a string of digits, an optional
    decimal point, and a closing string of digits. Other than their names, these three
    routines use exactly the same calling sequence. Here are the calls and parameters
    for each of these routines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The first parameter to these procedures is the floating-point value you wish
    to print. The size of this parameter must match the procedure''s name (e.g., the
    `r` parameter must be an 80-bit extended-precision floating-point variable when
    calling the `stdout.putr80` routine). The second parameter specifies the field
    width for the output text; this is the number of print positions the number will
    require when the procedure displays it. Note that this width must include print
    positions for the sign of the number and the decimal point. The third parameter
    specifies the number of print positions after the decimal point. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: displays the value
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: (underscores represent leading spaces in this example).
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, if the number is very large or very small, you will want to use
    scientific notation rather than decimal notation for your floating-point numeric
    output. The HLA Standard Library `stdout.pute32`, `stdout.pute64`, and `stdout.pute80`
    routines provide this facility. These routines use the following procedure prototypes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike the decimal output routines, these scientific notation output routines
    do not require a third parameter specifying the number of digits after the decimal
    point to display. The `width` parameter indirectly specifies this value because
    all but one of the mantissa digits always appear to the right of the decimal point.
    These routines output their values in decimal notation, similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also output floating-point values using the HLA Standard Library `stdout.put`
    routine. If you specify the name of a floating-point variable in the `stdout.put`
    parameter list, the `stdout.put` code will output the value using scientific notation.
    The actual field width varies depending on the size of the floating-point variable
    (the `stdout.put` routine attempts to output as many significant digits as possible,
    in this case). Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: If you specify a field width, by using a colon followed by a signed integer
    value, then the `stdout.put` routine will use the appropriate `stdout.puteXX`
    routine to display the value. That is, the number will still appear in scientific
    notation, but you get to control the field width of the output value. Like the
    field width for integer and unsigned values, a positive field width right justifies
    the number in the specified field, and a negative number left justifies the value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example that prints the `XPVar2` variable using 10 print positions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'If you wish to use `stdout.put` to print a floating-point value in decimal
    notation, you need to use the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Note that the *`DecPts`* field must be a nonnegative integer value.
  prefs: []
  type: TYPE_NORMAL
- en: 'When `stdout.put` contains a parameter of this form, it calls the corresponding
    `stdout.putr`*`XX`* routine to display the specified floating-point value. As
    an example, consider the following call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding output is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: The HLA Standard Library provides several other useful routines you can use
    when outputting floating-point values. Consult the HLA Standard Library reference
    manual for more information on these routines.
  prefs: []
  type: TYPE_NORMAL
- en: 'The HLA Standard Library provides several routines to let you display floating-point
    values in a wide variety of formats. In contrast, the HLA Standard Library provides
    only two routines to support floating-point input: `stdin.getf()` and `stdin.get()`.
    The `stdin.getf()` routine requires the use of the 80x86 FPU stack, a hardware
    component that this chapter doesn''t cover. Therefore, we''ll defer the discussion
    of the `stdin.getf()` routine until [Chapter 6](ch06.html "Chapter 6. ARITHMETIC").
    Because the `stdin.get()` routine provides all the capabilities of the `stdin.getf()`
    routine, this deferral will not be a problem.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You''ve already seen the syntax for the `stdin.get()` routine; its parameter
    list simply contains a list of variable names. The `stdin.get()` function reads
    appropriate values for the user for each of the variables appearing in the parameter
    list. If you specify the name of a floating-point variable, the `stdin.get()`
    routine automatically reads a floating-point value from the user and stores the
    result into the specified variable. The following example demonstrates the use
    of this routine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Warning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section discussed how you would declare floating-point variables and how
    you would input and output them. It did not discuss arithmetic. Floating-point
    arithmetic is different from integer arithmetic; you cannot use the 80x86 *`add`*
    and *`sub`* instructions to operate on floating-point values. Floating-point arithmetic
    will be the subject of [Chapter 6](ch06.html "Chapter 6. ARITHMETIC").
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ^([[26](#CHP-2-FN-6)]) Of course, the drawback is that you must now perform
    two multiplications rather than one, so the result may be slower.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[27](#CHP-2-FN-7)]) There were some minor changes to the way certain degenerate
    operations were handled, but the bit representation remained essentially unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[28](#CHP-2-FN-8)]) The binary point is the same thing as the decimal point
    except it appears in binary numbers rather than decimal numbers.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[29](#CHP-2-FN-9)]) Actually, this isn't necessarily true. The IEEE floating-point
    format supports *denormalized* values where the H.O. bit is not 0\. However, we
    will ignore denormalized values in our discussion.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[30](#CHP-2-FN-10)]) The alternative would be to underflow the values to
    0.
  prefs: []
  type: TYPE_NORMAL
- en: 2.13 Binary-Coded Decimal Representation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the integer and floating-point formats cover most of the numeric needs
    of an average program, there are some special cases where other numeric representations
    are convenient. In this section we'll discuss the binary-coded decimal format
    because the 80x86 CPU provides a small amount of hardware support for this data
    representation.
  prefs: []
  type: TYPE_NORMAL
- en: BCD values are a sequence of nibbles, with each nibble representing a value
    in the range 0..9\. Of course you can represent values in the range 0..15 using
    a nibble; the BCD format, however, uses only 10 of the possible 16 different values
    for each nibble.
  prefs: []
  type: TYPE_NORMAL
- en: Each nibble in a BCD value represents a single decimal digit. Therefore, with
    a single byte (i.e., two digits) we can represent values containing two decimal
    digits, or values in the range 0..99 (see [Figure 2-25](ch02s13.html#cd_data_representation_in_memory
    "Figure 2-25. CD data representation in memory")). With a word, we can represent
    values having four decimal digits, or values in the range 0..9,999\. Likewise,
    with a double word we can represent values with up to eight decimal digits (because
    there are eight nibbles in a double-word value).
  prefs: []
  type: TYPE_NORMAL
- en: '![CD data representation in memory](tagoreillycom20100401nostarchimages577933.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-25. CD data representation in memory
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, BCD storage isn't particularly memory efficient. For example,
    an 8-bit BCD variable can represent values in the range 0..99 while that same
    8 bits, when holding a binary value, can represent values in the range 0..255\.
    Likewise, a 16-bit binary value can represent values in the range 0..65,535, while
    a 16-bit BCD value can represent only about one-sixth of those values (0..9,999).
    Inefficient storage isn't the only problem. BCD calculations tend to be slower
    than binary calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you''re probably wondering why anyone would ever use the BCD
    format. The BCD format does have two saving graces: It''s very easy to convert
    BCD values between the internal numeric representation and their string representation;
    also, it''s very easy to encode multidigit decimal values in hardware (e.g., using
    a thumb wheel or dial) using BCD. For these two reasons, you''re likely to see
    people using BCD in embedded systems (such as toaster ovens, alarm clocks, and
    nuclear reactors) but rarely in general-purpose computer software.'
  prefs: []
  type: TYPE_NORMAL
- en: A few decades ago people mistakenly thought that calculations involving BCD
    (or just decimal) arithmetic were more accurate than binary calculations. Therefore,
    they would often perform important calculations, like those involving dollars
    and cents (or other monetary units) using decimal-based arithmetic. While it is
    true that certain calculations can produce more accurate results in BCD, this
    statement is not true in general. Indeed, for most calculations (even those involving
    fixed-point decimal arithmetic), the binary representation is more accurate. For
    this reason, most modern computer programs represent all values in a binary form.
    For example, the Intel 80x86 floating-point unit supports a pair of instructions
    for loading and storing BCD values. Internally, however, the FPU converts these
    BCD values to binary and performs all calculations in binary. It uses BCD only
    as an external data format (external to the FPU, that is). This generally produces
    more accurate results and requires far less silicon than having a separate coprocessor
    that supports decimal arithmetic.
  prefs: []
  type: TYPE_NORMAL
- en: 2.14 Characters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Perhaps the most important data type on a personal computer is the character
    data type. The term *character* refers to a human or machine-readable symbol that
    is typically a nonnumeric entity. In general, the term *character* refers to any
    symbol that you can normally type on a keyboard (including some symbols that may
    require multiple key presses to produce) or display on a video display. Many beginners
    often confuse the terms *character* and *alphabetic character*. These terms are
    not the same. Punctuation symbols, numeric digits, spaces, tabs, carriage returns
    (enter), other control characters, and other special symbols are also characters.
    When this text uses the term *character* it refers to any of these characters,
    not just the alphabetic characters. When this text refers to alphabetic characters,
    it will use phrases like "alphabetic characters," "uppercase characters," or "lowercase
    characters."
  prefs: []
  type: TYPE_NORMAL
- en: Another common problem beginners have when they first encounter the character
    data type is differentiating between numeric characters and numbers. The character
    `1` is different from the value 1\. The computer (generally) uses two different
    internal representations for numeric characters (`0`, `1`, ..., `9`) versus the
    numeric values 0..9\. You must take care not to confuse the two.
  prefs: []
  type: TYPE_NORMAL
- en: Most computer systems use a 1- or 2-byte sequence to encode the various characters
    in binary form. Windows, Mac OS X, FreeBSD, and Linux certainly fall into this
    category, using either the ASCII or Unicode encodings for characters. This section
    will discuss the ASCII character set and the character declaration facilities
    that HLA provides.
  prefs: []
  type: TYPE_NORMAL
- en: 2.14.1 The ASCII Character Encoding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ASCII (American Standard Code for Information Interchange) character set
    maps 128 textual characters to the unsigned integer values 0..127 ($0..$7F). Internally,
    of course, the computer represents everything using binary numbers, so it should
    come as no surprise that the computer also uses binary values to represent nonnumeric
    entities such as characters. Although the exact mapping of characters to numeric
    values is arbitrary and unimportant, it is important to use a standardized code
    for this mapping because you will need to communicate with other programs and
    peripheral devices and you need to talk the same "language" as these other programs
    and devices. This is where the ASCII code comes into play; it is a standardized
    code that nearly everyone has agreed on. Therefore, if you use the ASCII code
    65 to represent the character `'A'`, then you know that some peripheral device
    (such as a printer) will correctly interpret this value as the character `'A'`
    whenever you transmit data to that device.
  prefs: []
  type: TYPE_NORMAL
- en: You should not get the impression that ASCII is the only character set in use
    on computer systems. IBM uses the EBCDIC character set family on many of its mainframe
    computer systems. Another common character set in use is the Unicode character
    set. Unicode is an extension to the ASCII character set that uses 16 bits rather
    than 7 bits to represent characters. This allows the use of 65,536 different characters
    in the character set, allowing the inclusion of most symbols in the world's different
    languages into a single unified character set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the ASCII character set provides only 128 different characters and
    a byte can represent 256 different values, an interesting question arises: "What
    do we do with the values 128..255 that one could store into a byte?" One answer
    is to ignore those extra values. That will be the primary approach of this text.
    Another possibility is to extend the ASCII character set and add an additional
    128 characters to it. Of course, this would tend to defeat the whole purpose of
    having a standardized character set unless you could get everyone to agree on
    the extensions. That is a difficult task.'
  prefs: []
  type: TYPE_NORMAL
- en: When IBM first created its IBM-PC, it defined these extra 128 character codes
    to contain various non-English alphabetic characters, some line-drawing graphics
    characters, some mathematical symbols, and several other special characters. Because
    IBM's PC was the foundation for what we typically call a PC today, that character
    set has become a pseudo-standard on all IBM-PC compatible machines. Even on modern
    machines, which are not IBM-PC compatible and cannot run early PC software, the
    IBM extended character set survives. Note, however, that this PC character set
    (an extension of the ASCII character set) is not universal. Most printers will
    not print the extended characters when using native fonts, and many programs (particularly
    in non-English-speaking countries) do not use those characters for the upper 128
    codes in an 8-bit value. For these reasons, this text will generally stick to
    the standard 128-character ASCII character set.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the fact that it is a standard, simply encoding your data using standard
    ASCII characters does not guarantee compatibility across systems. While it's true
    that an `'A'` on one machine is most likely an `'A'` on another machine, there
    is very little standardization across machines with respect to the use of the
    control characters. Indeed, of the 32 control codes plus delete, there are only
    four control codes commonly supported—backspace (BS), tab, carriage return (CR),
    and line feed (LF). Worse still, different machines often use these control codes
    in different ways. *End of line* is a particularly troublesome example. Windows,
    MS-DOS, CP/M, and other systems mark end of line by the two-character sequence
    CR/LF. Older Apple Macintosh computers (Mac OS 9 and earlier) and many other systems
    mark the end of a line by a single CR character. Linux, Mac OS X, FreeBSD, and
    other Unix systems mark the end of a line with a single LF character. Needless
    to say, attempting to exchange simple text files between such systems can be an
    experience in frustration. Even if you use standard ASCII characters in all your
    files on these systems, you will still need to convert the data when exchanging
    files between them. Fortunately, such conversions are rather simple.
  prefs: []
  type: TYPE_NORMAL
- en: Despite some major shortcomings, ASCII data is *the* standard for data interchange
    across computer systems and programs. Most programs can accept ASCII data; likewise
    most programs can produce ASCII data. Because you will be dealing with ASCII characters
    in assembly language, it would be wise to study the layout of the character set
    and memorize a few key ASCII codes (e.g., for `'0'`, `'A'`, `'a'`, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: The ASCII character set is divided into four groups of 32 characters. The first
    32 characters, ASCII codes 0..$1F (31), form a special set of nonprinting characters,
    the *control characters*. We call them control characters because they perform
    various printer/display control operations rather than display symbols. Examples
    include *carriage return*, which positions the cursor to the left side of the
    current line of characters;^([[31](#ftn.CHP-2-FN-11)]) line feed, which moves
    the cursor down one line on the output device; and backspace, which moves the
    cursor back one position to the left. Unfortunately, different control characters
    perform different operations on different output devices. There is very little
    standardization among output devices. To find out exactly how a control character
    affects a particular device, you will need to consult its manual.
  prefs: []
  type: TYPE_NORMAL
- en: The second group of 32 ASCII character codes contains various punctuation symbols,
    special characters, and the numeric digits. The most notable characters in this
    group include the space character (ASCII code $20) and the numeric digits (ASCII
    codes $30..$39).
  prefs: []
  type: TYPE_NORMAL
- en: The third group of 32 ASCII characters contains the uppercase alphabetic characters.
    The ASCII codes for the characters `'A'`..`'Z'` lie in the range $41..$5A (65..90).
    Because there are only 26 different alphabetic characters, the remaining 6 codes
    hold various special symbols.
  prefs: []
  type: TYPE_NORMAL
- en: The fourth, and final, group of 32 ASCII character codes represents the lowercase
    alphabetic symbols, 5 additional special symbols, and another control character
    (delete). Note that the lowercase character symbols use the ASCII codes $61..$7A.
    If you convert the codes for the upper- and lowercase characters to binary, you
    will notice that the uppercase symbols differ from their lowercase equivalents
    in exactly one bit position. For example, consider the character codes for `'E'`
    and `'e'` appearing in [Figure 2-26](ch02s14.html#ascii_codes_for_e_and_e "Figure 2-26. ASCII
    codes for E and e").
  prefs: []
  type: TYPE_NORMAL
- en: '![ASCII codes for E and e](tagoreillycom20100401nostarchimages577935.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-26. ASCII codes for E and e
  prefs: []
  type: TYPE_NORMAL
- en: The only place these two codes differ is in bit 5\. Uppercase characters always
    contain a 0 in bit 5; lowercase alphabetic characters always contain a 1 in bit
    5\. You can use this fact to quickly convert between upper- and lowercase. If
    you have an uppercase character, you can force it to lowercase by setting bit
    5 to 1\. If you have a lowercase character and you wish to force it to uppercase,
    you can do so by setting bit 5 to 0\. You can toggle an alphabetic character between
    upper- and lowercase by simply inverting bit 5.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, bits 5 and 6 determine which of the four groups in the ASCII character
    set you're in, as [Table 2-8](ch02s14.html#ascii_groups "Table 2-8. ASCII Groups")
    shows.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-8. ASCII Groups
  prefs: []
  type: TYPE_NORMAL
- en: '| Bit 6 | Bit 5 | Group |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0 | Control characters |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1 | Digits and punctuation |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0 | Uppercase and special |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 1 | Lowercase and special |'
  prefs: []
  type: TYPE_TB
- en: So you could, for instance, convert any upper- or lowercase (or corresponding
    special) character to its equivalent control character by setting bits 5 and 6
    to 0.
  prefs: []
  type: TYPE_NORMAL
- en: Consider, for a moment, the ASCII codes of the numeric digit characters appearing
    in [Table 2-9](ch02s14.html#ascii_codes_for_numeric_digits "Table 2-9. ASCII Codes
    for Numeric Digits").
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-9. ASCII Codes for Numeric Digits
  prefs: []
  type: TYPE_NORMAL
- en: '| Character | Decimal | Hexadecimal |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 48 | $30 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 49 | $31 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 50 | $32 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 51 | $33 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 52 | $34 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 53 | $35 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 54 | $36 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 55 | $37 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 56 | $38 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 57 | $39 |'
  prefs: []
  type: TYPE_TB
- en: The decimal representations of these ASCII codes are not very enlightening.
    However, the hexadecimal representation of these ASCII codes reveals something
    very important—the L.O. nibble of the ASCII code is the binary equivalent of the
    represented number. By stripping away (i.e., setting to 0) the H.O. nibble of
    a numeric character, you can convert that character code to the corresponding
    binary representation. Conversely, you can convert a binary value in the range
    0..9 to its ASCII character representation by simply setting the H.O. nibble to
    3\. Note that you can use the logical `and` operation to force the H.O. bits to
    0; likewise, you can use the logical `or` operation to force the H.O. bits to
    %0011 (3).
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that you *cannot* convert a string of numeric characters to their equivalent
    binary representation by simply stripping the H.O. nibble from each digit in the
    string. Converting 123 ($31 $32 $33) in this fashion yields 3 bytes: $010203;
    the correct value for 123 is $7B. Converting a string of digits to an integer
    requires more sophistication than this; the conversion above works only for single
    digits.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.14.2 HLA Support for ASCII Characters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although you could easily store character values in `byte` variables and use
    the corresponding numeric equivalent ASCII code when using a character literal
    in your program, such agony is unnecessary. HLA provides support for character
    variables and literals in your assembly language programs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Character literal constants in HLA take one of two forms: a single character
    surrounded by apostrophes or a hash mark (`#`) followed by a numeric constant
    in the range 0..127 (specifying the ASCII code of the character). Here are some
    examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Note that these examples all represent the same character (`'A'`) because the
    ASCII code of `'A'` is 65.
  prefs: []
  type: TYPE_NORMAL
- en: 'With one exception, only a single character may appear between the apostrophes
    in a literal character constant. That single exception is the apostrophe character
    itself. If you wish to create an apostrophe literal constant, place four apostrophes
    in a row (i.e., double up the apostrophe inside the surrounding apostrophes):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The hash mark operator (`#`) must precede a legal HLA numeric constant (either
    decimal, hexadecimal, or binary, as the examples above indicate). In particular,
    the hash mark is not a generic character conversion function; it cannot precede
    registers or variable names, only constants.
  prefs: []
  type: TYPE_NORMAL
- en: As a general rule, you should always use the apostrophe form of the character
    literal constant for graphic characters (that is, those that are printable or
    displayable). Use the hash mark form for control characters (that are invisible
    or do funny things when you print them) or for extended ASCII characters that
    may not display or print properly within your source code.
  prefs: []
  type: TYPE_NORMAL
- en: Notice the difference between a character literal constant and a string literal
    constant in your programs. Strings are sequences of zero or more characters surrounded
    by quotation marks; characters are surrounded by apostrophes.
  prefs: []
  type: TYPE_NORMAL
- en: It is especially important to realize that
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The character constant `'A'` and the string containing the single character
    `A` have two completely different internal representations. If you attempt to
    use a string containing a single character where HLA expects a character constant,
    HLA will report an error. Strings and string constants are the subject of [Chapter 4](ch04.html
    "Chapter 4. CONSTANTS, VARIABLES, AND DATA TYPES").
  prefs: []
  type: TYPE_NORMAL
- en: 'To declare a character variable in an HLA program, you use the `char` data
    type. For example, the following declaration demonstrates how to declare a variable
    named `UserInput`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'This declaration reserves 1 byte of storage that you could use to store any
    character value (including 8-bit extended ASCII characters). You can also initialize
    character variables as the following example demonstrates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Because character variables are 8-bit objects, you can manipulate them using
    8-bit registers. You can move character variables into 8-bit registers, and you
    can store the value of an 8-bit register into a character variable.
  prefs: []
  type: TYPE_NORMAL
- en: The HLA Standard Library provides a handful of routines that you can use for
    character I/O and manipulation; these include `stdout.putc`, `stdout.putcSize`,
    `stdout.put`*,* `stdin.getc`*,* and `stdin.get`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `stdout.putc` routine uses the following calling sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: This procedure outputs the single-character parameter passed to it as a character
    to the standard output device. The parameter may be any `char` constant or variable,
    or a `byte` variable or register.^([[32](#ftn.CHP-2-FN-12)])
  prefs: []
  type: TYPE_NORMAL
- en: The `stdout.putcSize` routine provides output width control when displaying
    character variables. The calling sequence for this procedure is
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: This routine prints the specified character (parameter `c`) using at least *`widthInt32`*
    print positions.^([[33](#ftn.CHP-2-FN-13)]) If the absolute value of *`widthInt32`*
    is greater than 1, then `stdout.putcSize` prints the *`fillchar`* character as
    padding. If the value of *`widthInt32`* is positive, then `stdout.putcSize` prints
    the character right justified in the print field; if *`widthInt32`* is negative,
    then `stdout.putcSize` prints the character left justified in the print field.
    Because character output is usually left justified in a field, the *`widthInt32`*
    value will normally be negative for this call. The space character is the most
    common *`fillchar`* value.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also print character values using the generic `stdout.put` routine.
    If a character variable appears in the `stdout.put` parameter list, then `stdout.put`
    will automatically print it as a character value. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: You can read characters from the standard input using the `stdin.getc` and `stdin.get`
    routines. The `stdin.getc` routine does not have any parameters. It reads a single
    character from the standard input buffer and returns this character in the AL
    register. You may then store the character value away or otherwise manipulate
    the character in the AL register. The program in [Example 2-10](ch02s14.html#character_input_sample
    "Example 2-10. Character input sample") reads a single character from the user,
    converts it to uppercase if it is a lowercase character, and then displays the
    character.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-10. Character input sample
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: You can also use the generic `stdin.get` routine to read character variables
    from the user. If a `stdin.get` parameter is a character variable, then the `stdin.get`
    routine will read a character from the user and store the character value into
    the specified variable. [Example 2-11](ch02s14.html#stdin.get_character_input_sample
    "Example 2-11. stdin.get character input sample") is a rewrite of [Example 2-10](ch02s14.html#character_input_sample
    "Example 2-10. Character input sample") using the `stdin.get` routine.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-11. `stdin.get` character input sample
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: As you may recall from the last chapter, the HLA Standard Library buffers its
    input. Whenever you read a character from the standard input using `stdin.getc`
    or `stdin.get`, the library routines read the next available character from the
    buffer; if the buffer is empty, then the program reads a new line of text from
    the user and returns the first character from that line. If you want to guarantee
    that the program reads a new line of text from the user when you read a character
    variable, you should call the `stdin.flushInput` routine before attempting to
    read the character. This will flush the current input buffer and force the input
    of a new line of text on the next input (probably a `stdin.getc` or `stdin.get`
    call).
  prefs: []
  type: TYPE_NORMAL
- en: The end of line is problematic. Different operating systems handle the end of
    line differently on output versus input. From the console device, pressing the
    **enter** key signals the end of a line; however, when reading data from a file,
    you get an end-of-line sequence that is a linefeed or a carriage return/line feed
    pair (under Windows) or just a line feed (under Linux/Mac OS X/FreeBSD). To help
    solve this problem, HLA's Standard Library provides an "end of line" function.
    This procedure returns true (1) in the AL register if all the current input characters
    have been exhausted; it returns false (0) otherwise. The sample program in [Example 2-12](ch02s14.html#testing_for_end_of_line_using_stdin.eoln
    "Example 2-12. Testing for end of line using stdin.eoln") demonstrates the `stdin.eoln`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-12. Testing for end of line using `stdin.eoln`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: The HLA language and the HLA Standard Library provide many other procedures
    and additional support for character objects. [Chapter 4](ch04.html "Chapter 4. CONSTANTS,
    VARIABLES, AND DATA TYPES") and [Chapter 11](ch11.html "Chapter 11. THE STRING
    INSTRUCTIONS"), as well as the HLA reference documentation, describe how to use
    these features.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ^([[31](#CHP-2-FN-11)]) Historically, carriage return refers to the *paper carriage*
    used on typewriters. A carriage return consisted of physically moving the carriage
    all the way to the right so that the next character typed would appear at the
    left-hand side of the paper.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[32](#CHP-2-FN-12)]) If you specify a byte variable or a byte-sized register
    as the parameter, the `stdout.putc` routine will output the character whose ASCII
    code appears in the variable or register.
  prefs: []
  type: TYPE_NORMAL
- en: ^([[33](#CHP-2-FN-13)]) The only time `stdout.putcSize` uses more print positions
    than you specify is when you specify 0 as the width; then this routine uses exactly
    one print position.
  prefs: []
  type: TYPE_NORMAL
- en: 2.15 The Unicode Character Set
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although the ASCII character set is, unquestionably, the most popular character
    representation on computers, it is certainly not the only format around. For example,
    IBM uses the EBCDIC code on many of its mainframe and minicomputer lines. Because
    EBCDIC appears mainly on IBM''s big iron and you''ll rarely encounter it on personal
    computer systems, we will not consider that character set in this text. Another
    character representation that is becoming popular on small computer systems (and
    large ones, for that matter) is the Unicode character set. Unicode overcomes two
    of ASCII''s greatest limitations: the limited character space (i.e., a maximum
    of 128/256 characters in an 8-bit byte) and the lack of international (beyond
    the United States) characters.'
  prefs: []
  type: TYPE_NORMAL
- en: Unicode uses a 16-bit word to represent a single character. Therefore, Unicode
    supports up to 65,536 different character codes. This is obviously a huge advance
    over the 256 possible codes we can represent with an 8-bit byte. Unicode is upward
    compatible from ASCII. Specifically, if the H.O. 9 bits of a Unicode character
    contain 0, then the L.O. 7 bits represent the same character as the ASCII character
    with the same character code. If the H.O. 9 bits contain some nonzero value, then
    the character represents some other value. If you're wondering why so many different
    character codes are necessary, simply note that certain Asian character sets contain
    4,096 characters (at least their Unicode subset does).
  prefs: []
  type: TYPE_NORMAL
- en: This text will stick to the ASCII character set except for a few brief mentions
    of Unicode here and there. Eventually, this text may have to eliminate the discussion
    of ASCII in favor of Unicode because many new operating systems are using Unicode
    internally (and converting to ASCII as necessary). Unfortunately, many string
    algorithms are not as conveniently written for Unicode as for ASCII (especially
    character set functions), so we'll stick with ASCII in this text as long as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 2.16 For More Information
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The electronic edition of this book (on Webster at [http://webster.cs.ucr.edu/](http://webster.cs.ucr.edu/)
    or [http://artofasm.com/](http://artofasm.com/)) contains some additional information
    on data representation you may find useful. For general information about data
    representation, you should consider reading my book *Write Great Code, Volume
    1* (No Starch Press, 2004), or a textbook on data structures and algorithms (available
    at any bookstore).
  prefs: []
  type: TYPE_NORMAL
