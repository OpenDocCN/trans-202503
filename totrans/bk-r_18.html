<html><head></head><body>
<h2 class="h2" id="ch15"><span epub:type="pagebreak" id="page_309"/><span class="big"><strong>15</strong></span><br/><strong>PROBABILITY</strong></h2>&#13;
<div class="image"><img src="../images/common-01.jpg" alt="image"/></div>&#13;
<p class="noindent">The concept of <em>probability</em> is central to statistical reasoning. Even the most complicated statistical techniques and models usually have the ultimate goal of making a probabilistic statement about a phenomenon. In this chapter, I’ll use simple, everyday examples to illustrate this key idea in preparation for the remaining chapters. If you’re already familiar with the basics of probability and random variables and the associated terminology, you may want to skip ahead to <a href="ch16.xhtml#ch16">Chapter 16</a>, where R functionality begins to feature more prominently.</p>&#13;
<h3 class="h3" id="ch15lev1sec48"><strong>15.1 What Is a Probability?</strong></h3>&#13;
<p class="noindent">A <em>probability</em> is a number that describes the “magnitude of chance” associated with making a particular observation or statement. It’s always a number between 0 and 1 (inclusive) and is often expressed as a fraction. Exactly how you calculate a probability depends on the definition of an <em>event</em>.</p>&#13;
<h4 class="h4" id="ch15lev2sec128"><span epub:type="pagebreak" id="page_310"/><strong><em>15.1.1 Events and Probability</em></strong></h4>&#13;
<p class="noindent">In statistics, an <em>event</em> typically refers to a specific outcome that can occur. To describe the chance of event <em>A</em> actually occurring, you use a probability, denoted by Pr(<em>A</em>). At the extremes, Pr(<em>A</em>) = 0 suggests <em>A</em> cannot occur, and Pr(<em>A</em>) = 1 suggests that <em>A</em> occurs with complete certainty.</p>&#13;
<p class="indent">Let’s say you roll a six-sided, fair die. Let <em>A</em> be the event “you roll a 5 or a 6.” You can assume that each outcome on a standard die has a probability of occurring 1/6 in any given roll. Under these conditions, you have this:</p>&#13;
<div class="imagec"><img src="../images/f0310-01.jpg" alt="image"/></div>&#13;
<p class="indent">This is what’s known as a <em>frequentist</em>, or <em>classical</em>, probability, and it is assumed to be the relative frequency with which an event occurs over many identical, objective trials.</p>&#13;
<p class="indent">As another example, say you’re married and arrive home much later than usual. Let <em>B</em> be the event “your significant other is angry” because of your tardiness. It’s a relatively straightforward process to observe <em>A</em> in a mathematical sense, but <em>B</em> isn’t so objectively observed, and the quantity can’t be easily computed. Instead, you might assign a number to Pr(<em>B</em>) given your own past experience. For example, you might say “I think Pr(<em>B</em>) = 0.5” if you think there’s a 50-50 chance your partner will be mad, but this would be based on your personal impressions of the situation and knowledge of your spouse’s temperament or mood, not on an impartial experiment that could be easily reproduced for any two individuals. This is known as a <em>Bayesian</em> probability, which uses prior knowledge or subjective belief to inform the calculations.</p>&#13;
<p class="indent">Owing to its naturally implied objectivity, the frequentist interpretation is the generally assumed definition of probability; you’ll focus on this kind of probability in this book. If you are interested in getting to grips with Bayesian analyses using R, Kruschke (<a href="ref.xhtml#ref36">2010</a>) represents a well-received text on the subject.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>Though it is tempting to define the concept of probability in terms of</em> likelihood <em>(and colloquially, many do), likelihood is taken to mean something slightly different in statistical theory, so I’ll avoid this term for now.</em></p>&#13;
</div>&#13;
<p class="indent">The way in which you compute probabilities when considering multiple events is determined by several important rules. These are similar in nature to the concepts of AND and OR that are key to comparing the logical values <code>TRUE</code> and <code>FALSE</code> in R via <code>&amp;&amp;</code> and <code>||</code> (refer to <a href="ch04.xhtml#ch04lev2sec39">Section 4.1.3</a>). Just like these logical comparisons, calculation of probabilities based on several defined events can usually be broken down into a specific calculation concerning two distinct events. To serve as a simple running example over the next few sections, assume you roll a standard die and define event <em>A</em> to be “you roll a 4 or more” and event <em>B</em> to be “you roll an even number.” You can therefore conclude that both <img class="middle" src="../images/f0310-02.jpg" alt="image"/> and <img class="middle" src="../images/f0310-03.jpg" alt="image"/>.</p>&#13;
<h4 class="h4" id="ch15lev2sec129"><span epub:type="pagebreak" id="page_311"/><strong><em>15.1.2 Conditional Probability</em></strong></h4>&#13;
<p class="noindent">A <em>conditional</em> probability is the probability of one event occurring after taking into account the occurrence of another event. The quantity Pr(<em>A</em>|<em>B</em>) represents “the probability that <em>A</em> occurs, <em>given</em> that <em>B</em> has already occurred,” and vice versa if you write Pr(<em>B</em>| <em>A</em>).</p>&#13;
<p class="indent">If Pr(<em>A</em>|<em>B</em>) = Pr(<em>A</em>), then the two events are <em>independent</em>; if Pr(<em>A</em>|<em>B</em>) ≠ Pr(<em>A</em>), then the two events are <em>dependent</em>. Generally, you can’t assume that Pr(<em>A</em>|<em>B</em>) is equal to Pr(<em>B</em>| <em>A</em>).</p>&#13;
<p class="indent">Turn to <em>A</em> and <em>B</em> as defined previously for a roll of a die. You already know that <img class="middle" src="../images/f0310-02.jpg" alt="image"/>. Now think of Pr(<em>A</em>|<em>B</em>). What is the probability your outcome is a 4 or more, <em>given</em> an even number has occurred? Since there are three even numbers, 2, 4, and 6, the probability that you roll a 4 or more, assuming an even number had occurred, is <img class="middle" src="../images/2by3.jpg" alt="image"/>. Thus, Pr(<em>A</em>|<em>B</em>) ≠ Pr(<em>A</em>) in this context, and the two events are therefore not independent.</p>&#13;
<h4 class="h4" id="ch15lev2sec130"><strong><em>15.1.3 Intersection</em></strong></h4>&#13;
<p class="noindent">The <em>intersection</em> of two events is written as Pr(<em>A</em> ∩ <em>B</em>) and is read as “the probability that both <em>A</em> and <em>B</em> occur simultaneously.” It is common to represent this as a Venn diagram, as shown here:</p>&#13;
<div class="imagec"><img src="../images/f0311-01.jpg" alt="image"/></div>&#13;
<p class="indent">Here, the disc labeled <em>A</em> represents the outcome (or outcomes) that satisfies <em>A</em>, and disc <em>B</em> represents the outcomes for <em>B</em>. The shaded area represents the specific outcome (or outcomes) that satisfies both <em>A</em> and <em>B</em>, and the area outside both discs represents the outcome (or outcomes) that satisfies neither <em>A</em> nor <em>B</em>. Theoretically, you have this:</p>&#13;
<div class="imagec"><a id="ch15eq1"/><img src="../images/e15-1.jpg" alt="image"/></div>&#13;
<p class="indent">If Pr(<em>A</em> ∩ <em>B</em>) = 0, then you say the two events are <em>mutually exclusive</em>. In other words, they cannot occur simultaneously. Also note that if the two events are independent, then <a href="ch15.xhtml#ch15eq1">Equation (15.1)</a> simplifies to Pr(<em>A</em> ∩ <em>B</em>) = Pr(<em>A</em>) × Pr(<em>B</em>).</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_312"/>Returning to the die example, what is the probability that on a single toss you roll an even number <em>and</em> it’s a 4 or more? Using the fact that <img class="middle" src="../images/f0312-02.jpg" alt="image"/> and that <img class="middle" src="../images/f0310-03.jpg" alt="image"/>, it is easy to compute <img class="middle" src="../images/f0312-03.jpg" alt="image"/> and confirm this in R if you really want to.</p>&#13;
<pre>R&gt; (2/3)*(1/2)<br/>[1] 0.3333333</pre>&#13;
<p class="indent">You can see that the two events are not mutually exclusive because Pr(<em>A</em> ∩ <em>B</em>) ≠ 0. This makes sense—it’s perfectly possible in a die roll to observe a number that’s both even and at least 4.</p>&#13;
<h4 class="h4" id="ch15lev2sec131"><strong><em>15.1.4 Union</em></strong></h4>&#13;
<p class="noindent">The <em>union</em> of two events is written as Pr(<em>A</em> ∪ <em>B</em>) and is read as “the probability that <em>A</em> or <em>B</em> occurs.” Here is the representation of a union as a Venn diagram:</p>&#13;
<div class="imagec"><img src="../images/f0312-04.jpg" alt="image"/></div>&#13;
<p class="indent">Theoretically, you have this:</p>&#13;
<div class="imagec"><a id="ch15eq2"/><img src="../images/e15-2.jpg" alt="image"/></div>&#13;
<p class="indent">The reason you need to subtract the intersection in this diagram is that in summing Pr(<em>A</em>) and Pr(<em>B</em>) alone, you’d be incorrectly counting Pr(<em>A</em> ∩ <em>B</em>) twice. Note, though, that if the two events are mutually exclusive, then <a href="ch15.xhtml#ch15eq2">Equation (15.2)</a> does simplify to Pr(<em>A</em> ∪ <em>B</em>) = Pr(<em>A</em>) + Pr(<em>B</em>).</p>&#13;
<p class="indent">So, in rolling the die, what’s the probability that you observe an even number <em>or</em> one that’s at least 4? Using (15.2), it’s easy to find that <img class="middle" src="../images/f0312-06.jpg" alt="image"/>. The following confirms this in R:</p>&#13;
<pre>R&gt; (1/2)+(1/2)-(1/3)<br/>[1] 0.6666667</pre>&#13;
<h4 class="h4" id="ch15lev2sec132"><strong><em>15.1.5 Complement</em></strong></h4>&#13;
<p class="noindent">Lastly, the probability of the <em>complement</em> of an event is written as Pr(<em><span class="ent">Ā</span></em>) and is read as “the probability that <em>A</em> does <em>not</em> occur.”</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_313"/>Here it is as a Venn diagram:</p>&#13;
<div class="imagec"><img src="../images/f0313-01.jpg" alt="image"/></div>&#13;
<p class="indent">From this diagram, you can see the following:</p>&#13;
<p class="center">Pr(<em><span class="ent">Ā</span></em>) = 1 − Pr(<em>A</em>)</p>&#13;
<p class="indent">Wrapping up the running example, it’s straightforward to find the probability that you do not roll a 4 or greater: <img class="middle" src="../images/f0313-02.jpg" alt="image"/>. Naturally, if a 4, 5, or 6 is not obtained, then you must’ve rolled a 1, 2, or 3, so there are three possible outcomes left out of the six.</p>&#13;
<p class="indent">Sure, the die-rolling example may not represent the most pressing need facing statistical researchers today, but it has provided some clear illustrations of the behavior and terminology associated with the very real rules of probability. These rules apply across the board and play an important role in the interpretation of arguably more pressing endeavors in statistical modeling.</p>&#13;
<div class="ex">&#13;
<p class="ext"><a id="ch15exc1"/><strong>Exercise 15.1</strong></p>&#13;
<p class="noindentz">You have a standard deck of 52 playing cards. There are two colors (black and red) and four suits (spades are black, clubs are black, hearts are red, and diamonds are red). Each suit has 13 cards, in which there is an ace, numbered cards from 2 to 10, and three face cards (jack, queen, and king).</p>&#13;
<ol type="a">&#13;
<li><p class="noindents">You randomly draw and then replace a card. What’s the probability it’s an ace? What’s the probability it’s the 4 of spades?</p></li>&#13;
<li><p class="noindents">You randomly draw a card, and after replacing it, you draw another. Let <em>A</em> be the event that the card is a club; let <em>B</em> be the event that the card is red. What is Pr(<em>A</em>|<em>B</em>)? That is, what is the probability the second card is a club, <em>given</em> the first one was a red card? Are the two events independent?</p></li>&#13;
<li><p class="noindents">Repeat (b), this time assuming that when the first (club) card is drawn, it is not replaced. Would this change your answer to (b) in terms of independence?</p></li>&#13;
<li><p class="noindents"><span epub:type="pagebreak" id="page_314"/>Let <em>C</em> be the event a card is a face card, and let <em>D</em> be the event a card is black. You draw a single card. Evaluate Pr(<em>C</em> ∩ <em>D</em>). Are the two events mutually exclusive?</p></li>&#13;
</ol>&#13;
</div>&#13;
<h3 class="h3" id="ch15lev1sec49"><strong>15.2 Random Variables and Probability Distributions</strong></h3>&#13;
<p class="noindent">A <em>random variable</em> is a variable whose specific outcomes are assumed to arise by chance or according to some random or <em>stochastic</em> mechanism.</p>&#13;
<p class="indent">You’ve already encountered <em>variables</em>—characteristics that describe an individual entity based on data you’ve observed (<a href="ch13.xhtml#ch13lev1sec42">Section 13.1</a>). When you’re considering random variables, however, assume you have not yet made an observation. The chances of observing a specific value, or one within a specific interval, for that random variable has associated with it a probability.</p>&#13;
<p class="indent">It therefore makes sense to think of random variables as being tied to a function that defines these probabilities, which is referred to as a <em>probability distribution</em>. In this section, you’ll look at some elementary ways in which random variables are summarized and how their corresponding probability distributions are dealt with statistically.</p>&#13;
<h4 class="h4" id="ch15lev2sec133"><strong><em>15.2.1 Realizations</em></strong></h4>&#13;
<p class="noindent">So, the concept of a random variable revolves around the consideration of the possible outcomes of a variable in a probabilistic fashion. When you’ve actually made observations of a random variable, these are referred to as <em>realizations</em>.</p>&#13;
<p class="indent">Consider the following—suppose you roll your beloved die. Define the random variable <em>Y</em> to be the result. The possible realizations are <em>Y</em> = 1, <em>Y</em> = 2, <em>Y</em> = 3, <em>Y</em> = 4, <em>Y</em> = 5, and <em>Y</em> = 6.</p>&#13;
<p class="indent">Now, let’s say you’re planning to go on a picnic and monitor the maximum daily temperature at your preferred spot. Let the random variable <em>W</em> be the temperature in degrees Fahrenheit you observe there. Technically, you might say that the possible realizations of <em>W</em> lie in the interval −∞ &lt; <em>W</em> &lt; ∞.</p>&#13;
<p class="indent">These examples serve to illustrate two types of random variables. <em>Y</em> is a <em>discrete random variable</em>; <em>W</em> is a <em>continuous random variable</em>. Whether any given random variable is discrete or continuous has consequences for the way in which you think about, and may utilize, the probabilities associated with making realizations.</p>&#13;
<h4 class="h4" id="ch15lev2sec134"><span epub:type="pagebreak" id="page_315"/><strong><em>15.2.2 Discrete Random Variables</em></strong></h4>&#13;
<p class="noindent">A discrete random variable follows the same definitions as the variables covered in <a href="ch13.xhtml#ch13">Chapter 13</a>. Its realizations can take on only certain precise values, for which no other degree of measurement accuracy is possible or interpretable. Rolling a standard die can result in only those six distinct possibilities described previously by <em>Y</em>, and it would make no sense to observe, for example, “5.91.”</p>&#13;
<p class="indent">From <a href="ch15.xhtml#ch15lev2sec128">Section 15.1.1</a>, you know a probability is directly tied to defined outcomes known as <em>events</em>. When discussing a discrete random variable, events are therefore defined with respect to the distinct possible values the variable can take, and the corresponding probability distribution is formed when you consider the range of all the probabilities associated with all possible realizations.</p>&#13;
<p class="indent">Probability distributions tied to discrete random variables are called <em>probability mass functions</em>. Since these define the probabilities of all possible outcomes, the sum of the probabilities in any complete probability mass function must always equal exactly 1.</p>&#13;
<p class="indent">For example, suppose you go into a casino and play a simple gambling game. At each turn, you can either lose $4 with probability 0.32, break even (win or lose nothing) with probability 0.48, win $1 with probability 0.15, or win $8 with probability 0.05. Because these are the only four possible outcomes, the probabilities sum to 1. Let the discrete random variable <em>X</em> be defined as the “amount earned” at each turn you have. The distribution of these probabilities is expressed in <a href="ch15.xhtml#ch15tab1">Table 15-1</a>; note that the loss of $4 is represented as a negative earning as per the definition of <em>X</em>.</p>&#13;
<p class="tabt"><strong><a id="ch15tab1"/>Table 15-1:</strong> Probabilities and Cumulative Probabilities for the Amount Won, <em>X</em>, in a Hypothetical Gambling Game</p>&#13;
<table class="topbotr">&#13;
<thead>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table1r"><p class="table"><strong><em>x</em></strong></p></td>&#13;
<td style="vertical-align: top;" class="table2r"><p class="table"><strong>–4</strong></p></td>&#13;
<td style="vertical-align: top;" class="table2r"><p class="table"><strong>0</strong></p></td>&#13;
<td style="vertical-align: top;" class="table2r"><p class="table"><strong>1</strong></p></td>&#13;
<td style="vertical-align: top;" class="table2r"><p class="table"><strong>8</strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table3r"><p class="table">Pr(<em>X</em> = <em>x</em>)</p></td>&#13;
<td style="vertical-align: top;"><p class="table">0.32</p></td>&#13;
<td style="vertical-align: top;"><p class="table">0.48</p></td>&#13;
<td style="vertical-align: top;"><p class="table">0.15</p></td>&#13;
<td style="vertical-align: top;"><p class="table">0.05</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table3r"><p class="table">Pr(<em>X</em> ≤ <em>x</em>)</p></td>&#13;
<td style="vertical-align: top;"><p class="table">0.32</p></td>&#13;
<td style="vertical-align: top;"><p class="table">0.80</p></td>&#13;
<td style="vertical-align: top;"><p class="table">0.95</p></td>&#13;
<td style="vertical-align: top;"><p class="table">1.00</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<h5 class="h5" id="ch15lev3sec39"><strong>Cumulative Probability Distributions of Discrete Random Variables</strong></h5>&#13;
<p class="noindent">The <em>cumulative probability</em> is also an important part of the general idea of a probability distribution. A cumulative probability for a random variable <em>X</em> is “the probability of observing less than or equal to <em>x</em>” and written as Pr(<em>X</em> ≤ <em>x</em>). In the discrete case, you obtain the distribution of cumulative probabilities by summing the individual probabilities of the mass function up to and including any given value of <em>x</em>. This is shown in the bottom row of <a href="ch15.xhtml#ch15tab1">Table 15-1</a>. For example, though Pr(<em>X</em> = 0) is 0.48, Pr(<em>X</em> ≤ 0) = 0.32 + 0.48 = 0.80.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_316"/>Visualizing probability distributions is always useful, and because of the discrete nature of <em>X</em>, it’s easy to use the <code>barplot</code> function for this. Using skills from <a href="ch14.xhtml#ch14lev1sec44">Section 14.1</a>, the following code first stores vectors of the possible outcomes and corresponding probabilities (<code>X.outcomes</code> and <code>X.prob</code> respectively) and then produces the left image in <a href="ch15.xhtml#ch15fig1">Figure 15-1</a>:</p>&#13;
<pre>R&gt; X.outcomes &lt;- c(-4,0,1,8)<br/>R&gt; X.prob &lt;- c(0.32,0.48,0.15,0.05)<br/>R&gt; barplot(X.prob,ylim=c(0,0.5),names.arg=X.outcomes,space=0,<br/>           xlab="x",ylab="Pr(X = x)")</pre>&#13;
<p class="indent">The optional argument <code>space=0</code> eliminates the gaps between the bars.</p>&#13;
<p class="indent">Next, you can use the built-in <code>cumsum</code> function to progressively sum the entries in <code>X.prob</code>, as shown next, giving you the cumulative probabilities:</p>&#13;
<pre>R&gt; X.cumul &lt;- cumsum(X.prob)<br/>R&gt; X.cumul<br/>[1] 0.32 0.80 0.95 1.00</pre>&#13;
<p class="indent">Lastly, using <code>X.cumul</code>, the cumulative probability distribution can be plotted in the same way as earlier; the following line generates the right panel of <a href="ch15.xhtml#ch15fig1">Figure 15-1</a>:</p>&#13;
<pre>R&gt; barplot(X.cumul,names.arg=X.outcomes,space=0,xlab="x",ylab="Pr(X &lt;= x)")</pre>&#13;
<div class="image"><img src="../images/f15-01.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch15fig1"/>Figure 15-1: Visualizing the probability distribution associated with event-specific probabilities of a hypothetical gambling game (left) and the corresponding cumulative probability distribution (right)</em></p>&#13;
<p class="indentb"><span epub:type="pagebreak" id="page_317"/>Generally, it’s important to remember the following for any probability mass function based on a discrete random variable <em>X</em>:</p>&#13;
<p class="bull">• There are <em>k</em> distinct outcomes <em>x</em><sub>1</sub>,. . . , <em>x</em><sub>k</sub>.</p>&#13;
<p class="bull">• For each <em>x</em><sub>i</sub>, where <em>i</em> = {1,. . . , <em>k</em>}, 0 ≤ Pr(<em>X</em> = <em>x<sub>i</sub></em>) ≤ 1.</p>&#13;
<p class="bull">• <img class="middle" src="../images/f0317-01.jpg" alt="image"/>.</p>&#13;
<h5 class="h5" id="ch15lev3sec40"><strong>Mean and Variance of a Discrete Random Variable</strong></h5>&#13;
<p class="noindent">It’s useful to be able describe or summarize properties of a random variable of interest as you would for raw data. The most useful two properties are the mean and variance, both of which depend upon the relevant distribution of probabilities associated with that random variable.</p>&#13;
<p class="indent">For some discrete random variable <em>X</em>, the <em>mean</em> <em>μ<sub>X</sub></em> (also referred to as the <em>expectation</em> or the <em>expected value</em> <img class="middle" src="../images/common-01a.jpg" alt="image"/>[<em>X</em>]) is the “average outcome” that you can expect over many realizations. Say <em>X</em> has <em>k</em> possible outcomes, labeled <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, ..., <em>x<sub>k</sub></em>. Then, you have the following:</p>&#13;
<div class="imagec"><a id="ch15eq3"/><img src="../images/e15-3.jpg" alt="image"/></div>&#13;
<p class="indent">To find the mean, simply multiply the numeric value of each outcome by its corresponding probability and sum the results.</p>&#13;
<p class="indent">For a discrete random variable <em>X</em>, the <em>variance</em> <img class="middle" src="../images/f0317-03.jpg" alt="image"/>, also written as Var[<em>X</em>], quantifies the variability in the possible realizations of <em>X</em>. Theoretically, in terms of expectations, it can be shown that <img class="middle" src="../images/f0317-04.jpg" alt="image"/>. As you can see, calculation of the discrete random variable variance depends upon its mean <em>μ<sub>X</sub></em> and is given as follows:</p>&#13;
<div class="imagec"><a id="ch15eq4"/><img src="../images/e15-4.jpg" alt="image"/></div>&#13;
<p class="indent">Again, the procedure is straightforward—the variance is computed by squaring the differences between each realization and mean and then multiplying by the corresponding probability of the occurrence before summing these products.</p>&#13;
<p class="indent">In practice, the probabilities associated with each outcome are often unknown and are estimated from observed data. Following that step, you apply the formulas in (15.3) and (15.4) to obtain <em>estimates</em> of the respective properties. Also, note that the general descriptions of mean and variance <span epub:type="pagebreak" id="page_318"/>are the same as in <a href="ch13.xhtml#ch13lev1sec43">Section 13.2</a>—only you’re now quantifying centrality and spread with respect to a random phenomenon.</p>&#13;
<p class="indent">Let’s consider the gambling game with the possible realizations of the amount earned, <em>X</em>, and the associated probabilities as specified in <a href="ch15.xhtml#ch15tab1">Table 15-1</a>. With vector-oriented behavior (refer to <a href="ch02.xhtml#ch02lev2sec23">Section 2.3.4</a>), using R to calculate the mean and variance of <em>X</em> is easy. With the objects <code>X.outcomes</code> and <code>X.prob</code> from earlier, you can get the mean of <em>X</em> from the element-wise multiplication in the following:</p>&#13;
<pre>R&gt; mu.X &lt;- sum(X.outcomes*X.prob)<br/>R&gt; mu.X<br/>[1] -0.73</pre>&#13;
<p class="indent">So, <em>μ<sub>X</sub></em> = −0.73. By the same token, the following provides the variance of <em>X</em>:</p>&#13;
<pre>R&gt; var.X &lt;- sum((X.outcomes-mu.X)^2*X.prob)<br/>R&gt; var.X<br/>[1] 7.9371</pre>&#13;
<p class="indent">You can also compute the standard deviation by taking the square root of the variance (recall the definitions in <a href="ch13.xhtml#ch13lev2sec119">Section 13.2.4</a>). This is done with the built-in <code>sqrt</code> command.</p>&#13;
<pre>R&gt; sd.X &lt;- sqrt(var.X)<br/>R&gt; sd.X<br/>[1] 2.817286</pre>&#13;
<p class="indent">Based on these results, you can make several comments on the gambling game and its outcomes. The expected outcome of −0.73 suggests that, on average, you’ll lose $0.73 per turn, with a standard deviation of about $2.82. These quantities are not, and need not be, one of the specifically defined outcomes. They describe the behavior of the random mechanism over the long run.</p>&#13;
<h4 class="h4" id="ch15lev2sec135"><strong><em>15.2.3 Continuous Random Variables</em></strong></h4>&#13;
<p class="noindent">Again following from the definitions of variables from <a href="ch13.xhtml#ch13">Chapter 13</a>, a continuous random variable has no limit to the number of possible realizations. For a discrete random variable, it is natural to think of a specific outcome as an event and assign it a corresponding probability. Things are a little different when you’re dealing with a continuous random variable, however. If you take the picnic example in <a href="ch15.xhtml#ch15lev2sec133">Section 15.2.1</a>, you can see that even if you restrict the range of possible values of temperature measurement that you assume <em>W</em> could take, say, to between 40 and 90 degrees Fahrenheit (or, expressed more formally, 40 ≤ <em>W</em> ≤ 90), there are still an infinite number of distinct values on that continuum. Measuring 59.1 degrees makes as much sense as observing something like 59.16742 degrees. <span epub:type="pagebreak" id="page_319"/>As such, it isn’t possible to assign probabilities to specific, single temperatures; instead, you assign a probability to <em>intervals</em> of values. For example, based on <em>W</em>, asking Pr(<em>W</em> = 55.2)—“What is the probability the temperature is <em>exactly</em> 55.2 degrees Fahrenheit?”—is not a valid question. However, asking Pr(<em>W</em> ≤ 55.2)—“What is the probability it’s <em>less than or equal to</em> 55.2 degrees?”—is answerable because it defines an interval.</p>&#13;
<p class="indent">This is easier to understand if you again think about precisely how the probabilities will be distributed. With a discrete random variable, you can straightforwardly envisage its mass function as discrete, namely, something like <a href="ch15.xhtml#ch15tab1">Table 15-1</a>, which can be plotted like <a href="ch15.xhtml#ch15fig1">Figure 15-1</a>. However, with continuous random variables, the function that describes the distribution of probabilities must now therefore be <em>continuous</em> on the range of possible values. Probabilities are computed as “areas underneath” that continuous function, and, as with discrete random variables, the “total area” underneath a continuous probability distribution must evaluate to exactly 1. A probability distribution tied to a continuous random variable is called a <em>probability density function</em>.</p>&#13;
<p class="indent">These facts will become clearer when considering the following example. Suppose you’re told the probabilities associated with the picnic temperature random variable 40 ≤ <em>W</em> ≤ 90 follow the density function <em>f</em>(<em>w</em>), where the following is true:</p>&#13;
<div class="imagec"><a id="ch15eq5"/><img src="../images/e15-5.jpg" alt="image"/></div>&#13;
<p class="indent">The division by 625 is needed in this particular function to ensure a total probability of 1. This will make more sense in a visualization. To plot this density function, first consider the following code:</p>&#13;
<pre>R&gt; w &lt;- seq(35,95,by=5)<br/>R&gt; w<br/> [1] 35 40 45 50 55 60 65 70 75 80 85 90 95<br/>R&gt; lower.w &lt;- w&gt;=40 &amp; w&lt;=65<br/>R&gt; lower.w<br/> [1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE<br/>[11] FALSE FALSE FALSE<br/>R&gt; upper.w &lt;- w&gt;65 &amp; w&lt;=90<br/>R&gt; upper.w<br/> [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE<br/>[11]  TRUE  TRUE FALSE</pre>&#13;
<p class="indent">The first assignment sets up an even sequence of values to represent certain realizations of <em>w</em> simply called <code>w</code>; the second assignment uses relational operators and the element-wise logical operator <code>&amp;</code> to create a logical flag vector identifying those elements of <code>w</code> that form the “lower half” of values for <em>f</em> (<em>w</em>) as defined by <a href="ch15.xhtml#ch15eq5">Equation (15.5)</a>; the third assignment does the same for the “upper half” of values.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_320"/>The next lines make use of <code>lower.w</code> and <code>upper.w</code> to evaluate the correct result of <em>f</em> (<em>w</em>) for the entries in <code>w</code>.</p>&#13;
<pre>R&gt; fw &lt;- rep(0,length(w))<br/>R&gt; fw[lower.w] &lt;- (w[lower.w]-40)/625<br/>R&gt; fw[upper.w] &lt;- (90-w[upper.w])/625<br/>R&gt; fw<br/> [1] 0.000 0.000 0.008 0.016 0.024 0.032 0.040 0.032 0.024 0.016<br/>[11] 0.008 0.000 0.000</pre>&#13;
<p class="indent">This doesn’t mean you’ve just written an R-coded function to return <em>f</em> (<em>w</em>) for any <em>w</em>. You’ve merely created the vector <code>w</code> and obtained the corresponding values of the <em>mathematical</em> function as the vector <code>fw</code>. However, these two vectors are sufficient for plotting. Using skills from <a href="ch07.xhtml#ch07">Chapter 7</a>, you can plot a line representing the continuous density function <em>f</em>(<em>w</em>) for 35 ≤ <em>w</em> ≤ 95.</p>&#13;
<pre>R&gt; plot(w,fw,type="l",ylab="f(w)")<br/>R&gt; abline(h=0,col="gray",lty=2)</pre>&#13;
<p class="indent">The plot is given in <a href="ch15.xhtml#ch15fig2">Figure 15-2</a>; note the addition of a dashed horizontal line at <em>f</em>(<em>w</em>) = 0 using <code>abline</code>.</p>&#13;
<div class="image"><img src="../images/f15-02.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch15fig2"/>Figure 15-2: Visualizing the probability density function as defined by <a href="ch15.xhtml#ch15eq5">Equation (15.5)</a> for the picnic temperature random variable</em> W <em>(left) and illustrating the computation of a specific probability from the text (right)</em></p>&#13;
<p class="indent">You can see that the continuous function defined by <a href="ch15.xhtml#ch15eq5">Equation (15.5)</a> yields a triangular shape, with an apex at <em>w</em> = 65. The increasing line from <em>w</em> = 40 to <em>w</em> = 65 represents the first of the three components of (15.5), the decreasing line represents the second component, and for all <em>w</em> &lt; 40 and <em>w</em> &gt; 90, the line sits at zero, which is the third and final component of (15.5).</p>&#13;
<p class="indentb"><span epub:type="pagebreak" id="page_321"/>Generally, any function <em>f</em> (<em>w</em>) that defines a probability density for a random variable <em>W</em> must possess the following properties:</p>&#13;
<p class="bull">• <em>f</em> (<em>w</em>) ≥ 0 for all −∞ &lt; <em>w</em> &lt; ∞; and</p>&#13;
<p class="bull">• <img class="middle" src="../images/f0321-01.jpg" alt="image"/> (the total area underneath the function must be 1).</p>&#13;
<p class="indentt">In terms of the temperature example, you can see from (15.5) that <em>f</em> (<em>w</em>) ≥ 0 for any value of <em>w</em>. To calculate the total area underneath the function, you need be concerned only with the function evaluated at 40 ≤ <em>w</em> ≤ 90 since it’s zero everywhere else.</p>&#13;
<p class="indent">You can do this geometrically by working out the area of the triangle formed by the function and the horizontal line at zero. For this triangle, you can use the standard “half base times height” rule. The base of the triangle is 90 − 40 = 50, and the apex is at a value of 0.04. So, in R, half the base width times the height can be given with the following:</p>&#13;
<pre>R&gt; 0.5*50*0.04<br/>[1] 1</pre>&#13;
<p class="indent">This confirms it is indeed equal to 1; you can now see the reason behind my specific definition in (15.5).</p>&#13;
<p class="indent">Let’s return to the question of obtaining the probability that the temperature is less than or equal to 55.2 degrees Fahrenheit. For this you must find the area underneath <em>f</em>(<em>w</em>), the probability density function, bounded by the horizontal line at zero and an imaginary vertical line at 55.2. This particular area forms another triangle, for which it is again appropriate to use the “half base times height rule.” In Cartesian coordinates, this is the triangle formed by the vertices at (40,0), (55.2,0), and (55.2, <em>f</em> (55.2)), as shown in the right panel of <a href="ch15.xhtml#ch15fig2">Figure 15-2</a>—you’ll see how this is plotted in a moment.</p>&#13;
<p class="indent">Therefore, you should first work out the value <em>f</em> (55.2). From <a href="ch15.xhtml#ch15eq5">Equation (15.5)</a>, this is provided by creating the following object:</p>&#13;
<pre>R&gt; fw.specific &lt;- (55.2-40)/625<br/>R&gt; fw.specific<br/>[1] 0.02432</pre>&#13;
<p class="indent">Note that this isn’t a probability; it cannot be assigned to specific realizations. It’s just the height value of the triangle on the continuous density function that you’re going to need in order to calculate the interval-based probability Pr(<em>W</em> ≤ 55.2).</p>&#13;
<p class="indent">You can easily determine that the base of the triangle of interest in this particular setting is 55.2 − 40 = 15.2. Then, along with <code>fw.specific</code>, note that “half base times height” gives the following:</p>&#13;
<pre>R&gt; fw.specific.area &lt;- 0.5*15.2*fw.specific<br/>R&gt; fw.specific.area<br/>[1] 0.184832</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_322"/>The answer is reached. You’ve shown geometrically, using <em>f</em>(<em>w</em>), that Pr(<em>W</em> ≤ 55.2) = 0.185 (when rounded to three decimal places). In other words, you can say that there is roughly an 18.5 percent chance that the maximum temperature at the picnic spot will be less than or equal to 55.2 degrees Fahrenheit.</p>&#13;
<p class="indent">Again, all this is easier to digest visually. The following R code replots the density function <em>f</em> (<em>w</em>) and marks off and shades the area of interest:</p>&#13;
<pre>R&gt; fw.specific.vertices &lt;- rbind(c(40,0),c(55.2,0),c(55.2,fw.specific))<br/>R&gt; fw.specific.vertices<br/>     [,1]    [,2]<br/>[1,] 40.0 0.00000<br/>[2,] 55.2 0.00000<br/>[3,] 55.2 0.02432<br/>R&gt; plot(w,fw,type="l",ylab="f(w)")<br/>R&gt; abline(h=0,col="gray",lty=2)<br/>R&gt; polygon(fw.specific.vertices,col="gray",border=NA)<br/>R&gt; abline(v=55.2,lty=3)<br/>R&gt; text(50,0.005,labels=fw.specific.area)</pre>&#13;
<p class="indent">The result is the right panel of <a href="ch15.xhtml#ch15fig2">Figure 15-2</a>. The plotting commands should be familiar from <a href="ch07.xhtml#ch07">Chapter 7</a>, barring <code>polygon</code>. The built-in <code>polygon</code> function allows you to supply custom vertices in order to draw or shade a polygon upon an existing plot. Here, a matrix with two columns is defined using <code>rbind</code>, providing the <em>x</em> and <em>y</em> locations (first and second columns, respectively) of the three corners of the triangle to shade. Note that creation of <code>fw.specific.vertices</code> has made use of <code>fw.specific</code>, the value of <em>f</em> (<em>w</em>) at <em>w</em> = 55.2; this is the topmost vertex of the shaded triangle. Further arguments to <code>polygon</code> control the shading (<code>col="gray"</code>) and whether to draw a border around the defined polygon (<code>border=NA</code> requests no border).</p>&#13;
<p class="indent">Not all density functions can be appraised in this simple geometric fashion. Formally, <em>integration</em> is the mathematical operation used to find areas under a continuous function, denoted with the ∫ symbol. That is, the mathematically inclined familiar with this technique should find it straightforward to show that “the area under <em>f</em> (<em>w</em>) from <em>w</em> = 40 to <em>w</em> = 55.2, providing Pr(<em>W</em> ≤ 55.2)” is yielded by the following:</p>&#13;
<div class="imagec"><img src="../images/f0322-01.jpg" alt="image"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_323"/>In R, the third line of this calculation looks like this:</p>&#13;
<pre>R&gt; (55.2^2-80*55.2-40^2+80*40)/1250<br/>[1] 0.184832</pre>&#13;
<p class="indent">R finds the correct result. I’ll leave the mathematical details aside, but it’s nice to confirm that the more general integral does match the intuitive geometric solution based on the area of the triangle, computed earlier as <code>fw.specific.area</code>.</p>&#13;
<p class="indent">It’s now becoming clearer why it doesn’t make sense to assign probabilities to single, specific realizations associated with continuous random variables. For example, evaluating the “area under the function <em>f</em> (<em>w</em>)” at a single value is the same as finding the area of a polygon with a base width of <em>zero</em>, and hence, the probability itself is technically zero for <em>any</em> Pr(<em>W</em> = <em>w</em>). Furthermore, in the continuous setting, it makes no difference to your calculations if you use &lt; or ≤, or &gt; or ≥. So although you found Pr(<em>W</em> ≤ 55.2) earlier, if you had been tasked to find Pr(<em>W</em> &lt; 55.2), you would have gotten the same answer of 0.185. It may all seem a little unnatural at first, but it all comes down to the idea of an infinite number of possible realizations so that there’s no meaningful interpretation of “equality” to a specific value.</p>&#13;
<h5 class="h5" id="ch15lev3sec41"><strong>Cumulative Probability Distributions of Continuous Random Variables</strong></h5>&#13;
<p class="noindent">The cumulative probability distribution for a continuous variable is interpreted in the same way as for a discrete variable. Given a certain value <em>w</em>, the cumulative distribution function provides the probability of observing <em>w</em> or less. This may seem familiar; the probability you worked out earlier, Pr(<em>W</em> ≤ 55.2), based on the shaded triangle on the right of <a href="ch15.xhtml#ch15fig2">Figure 15-2</a> or using analytical methods, is itself a cumulative probability. More generally, you find a cumulative probability for a continuous random variable by calculating the area under the density function of interest from −∞ to <em>w</em>. This general treatment therefore requires mathematical integration of the relevant probability density function. Looking at <a href="ch15.xhtml#ch15fig2">Figure 15-2</a>, you should imagine a vertical line moving from left to right of the density plot and, at every location, evaluating the area under the density function to the left of that line.</p>&#13;
<p class="indent">For the picnic temperature example, it can be shown that the cumulative distribution function <em>F</em> is given with the following:</p>&#13;
<div class="imagec"><a id="ch15eq6"/><img src="../images/e15-6.jpg" alt="image"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_324"/>Making use of the sequence <code>w</code> and the logical flag vectors <code>lower.w</code> and <code>upper.w</code> from earlier, you can use the same vector subset-and-overwrite approach to plot <em>F</em>(<em>w</em>); the following code creates the required vector <code>Fw</code> and produces <a href="ch15.xhtml#ch15fig3">Figure 15-3</a>:</p>&#13;
<pre>R&gt; Fw &lt;- rep(0,length(w))<br/>R&gt; Fw[lower.w] &lt;- (w[lower.w]^2-80*w[lower.w]+1600)/1250<br/>R&gt; Fw[upper.w] &lt;- (180*w[upper.w]-w[upper.w]^2-6850)/1250<br/>R&gt; Fw[w&gt;90] &lt;- 1<br/>R&gt; plot(w,Fw,type="l",ylab="F(w)")<br/>R&gt; abline(h=c(0,1),col="gray",lty=2)</pre>&#13;
<div class="image"><img src="../images/f15-03.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch15fig3"/>Figure 15-3: Plotting the cumulative distribution function of the picnic temperature example, which is given as <a href="ch15.xhtml#ch15eq6">Equation (15.6)</a>. The cumulative probability of observing a temperature less than (or equal to) 55.2 is marked off.</em></p>&#13;
<p class="indent">Including these extra two lines following creation of this plot clearly identifies the fact that at <em>w</em> = 55.2, the cumulative probability is located precisely on the curve of <em>F</em>:</p>&#13;
<pre>R&gt; abline(v=55.2,lty=3)<br/>R&gt; abline(h=fw.specific.area,lty=3)</pre>&#13;
<h5 class="h5" id="ch15lev3sec42"><strong>Mean and Variance of a Continuous Random Variable</strong></h5>&#13;
<p class="noindent">Naturally, it’s also possible, and useful, to determine the mean and variance of a continuous random variable.</p>&#13;
<p class="indent">For a continuous random variable <em>W</em> with density <em>f</em>, the mean <em>μ<sub>W</sub></em> (or <em>expectation</em> or <em>expected value</em> <img class="middle" src="../images/common-01a.jpg" alt="image"/>) is again interpreted as the “average <span epub:type="pagebreak" id="page_325"/>outcome” that you can expect over many realizations. This is expressed mathematically as follows:</p>&#13;
<div class="imagec"><a id="ch15eq7"/><img src="../images/e15-7.jpg" alt="image"/></div>&#13;
<p class="indent">This equation represents the continuous analogue of <a href="ch15.xhtml#ch15eq3">Equation (15.3)</a> and can be read as “the total area underneath the function given by multiplication of the density <em>f</em>(<em>w</em>) with the value of <em>w</em> itself.”</p>&#13;
<p class="indent">For <em>W</em>, the variance <img class="middle" src="../images/f0317-03.jpg" alt="image"/>, also written as Var[<em>W</em>], quantifies the variability inherent in realizations of <em>W</em>. Calculation of the continuous random variable variance depends upon its mean <em>μ<sub>W</sub></em> and is given as follows:</p>&#13;
<div class="imagec"><a id="ch15eq8"/><img src="../images/e15-8.jpg" alt="image"/></div>&#13;
<p class="indent">Again, the procedure is to find the area under the density function multiplied by a certain quantity—in this case, the squared difference of the value of <em>w</em> with the overall expected value <em>μ<sub>W</sub></em>.</p>&#13;
<p class="indent">Evaluation of the mean and variance of the picnic temperature random variable must follow (15.7) and (15.8), respectively. These calculations become rather complex, so I won’t reproduce them here. However, <a href="ch15.xhtml#ch15fig2">Figure 15-2</a> shows that the mean of <em>W</em> must be <em>μ<sub>W</sub></em> = 65; it is the perfect center of the symmetric density function <em>f</em> (<em>w</em>).</p>&#13;
<p class="indent">In terms of the required integrals, you can therefore use the previously stored <code>w</code> and <code>fw</code> objects to view the two functions, <em>w f</em> (<em>w</em>) and (<em>w</em> − <em>μ<sub>W</sub></em>)<sup>2</sup> <em>f</em> (<em>w</em>), by executing the following, which produces the two images in <a href="ch15.xhtml#ch15fig4">Figure 15-4</a>:</p>&#13;
<pre>R&gt; plot(w,w*fw,type="l",ylab="wf(w)")<br/>R&gt; plot(w,(w-65)^2*fw,type="l",ylab="(w-65)^2 f(w)")</pre>&#13;
<div class="image"><img src="../images/f15-04.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch15fig4"/>Figure 15-4: Integrands for the expected value (left) and variance (right) of the probability density function for the temperature example</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_326"/>Rest assured that the following can be shown mathematically using <a href="ch15.xhtml#ch15eq7">Equations (15.7)</a> and <a href="ch15.xhtml#ch15eq8">(15.8)</a>.</p>&#13;
<div class="imagec"><img src="../images/f0326-01.jpg" alt="image"/></div>&#13;
<p class="indent">By visually approximating the area underneath each of the images in <a href="ch15.xhtml#ch15fig4">Figure 15-4</a>, you find these results are consistent. As earlier, the standard deviation of the distribution of <em>W</em> is given with the square root of the variance, and the following readily provides this value:</p>&#13;
<pre>R&gt; sqrt(104.1667)<br/>[1] 10.20621</pre>&#13;
<h4 class="h4" id="ch15lev2sec136"><strong><em>15.2.4 Shape, Skew, and Modality</em></strong></h4>&#13;
<p class="noindent">At this point, you’re familiar with both continuous and discrete random variables and their natural pairings with a distribution of probabilities, and you’ve had a look at visualizations of distributions of probability mass and density functions. In this section, I’ll define some terminology used to describe the appearance of these distributions—being able to describe your visual impressions is just as important as being able to readily compute them.</p>&#13;
<p class="indentb">You’ll often hear or read about the following descriptors:</p>&#13;
<p class="noindenth"><strong>Symmetry</strong> A distribution is <em>symmetric</em> if you can draw a vertical line down the center, and it is equally reflected with 0.5 probability falling on either side of this center line (see <a href="ch15.xhtml#ch15fig2">Figure 15-2</a>). A symmetric probability distribution implies that the mean and the median of the distribution are identical.</p>&#13;
<p class="noindenth"><strong>Skew</strong> If a distribution is <em>asymmetric</em>, you can qualify your description further by discussing <em>skew</em>. When the “tail” of a distribution (in other words, moving away from its measures of centrality) tapers off longer in one direction than the other, it is in this direction that the distribution is said to be skewed. <em>Positive</em> or <em>right</em> skew indicates a tail extending longer to the right of center; <em>negative</em> or <em>left</em> skew refers to a tail extending longer to the left of center. You could also qualify the strength or prominence of the skew.</p>&#13;
<p class="noindenth"><strong>Modality</strong> A probability distribution doesn’t always necessarily have a single peak. <em>Modality</em> describes the number of easily identifiable peaks in the distribution of interest. <em>Unimodal</em>, <em>bimodal</em>, and <em>trimodal</em>, for example, are the terms used to describe distributions with one, two, and three peaks, respectively.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_327"/><a href="ch15.xhtml#ch15fig5">Figure 15-5</a> provides some visual interpretations of symmetry, asymmetry, skew, and modality. (Note that although they are drawn with a continuous line, you can assume they represent the general shape of either a discrete probability mass function <em>or</em> a continuous density function.)</p>&#13;
<div class="image"><img src="../images/f15-05.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch15fig5"/>Figure 15-5: General examples of the terms used to describe probability distributions. The top three images are unimodal and highlight the notion of symmetry versus asymmetric skew; the bottom two images emphasize the reference to modality.</em></p>&#13;
<p class="indent">You can use these descriptors when discussing the probability distributions for the gambling game and picnic temperature examples. The mass function for <em>X</em>, on the left in <a href="ch15.xhtml#ch15fig1">Figure 15-1</a>, is unimodal and asymmetric—it appears to have a mild but noticeable right skew. The density function for <em>W</em>, given in <a href="ch15.xhtml#ch15fig2">Figure 15-2</a>, is also unimodal, though as noted earlier is perfectly symmetric.</p>&#13;
<div class="ex">&#13;
<p class="ext"><a id="ch15exc2"/><strong>Exercise 15.2</strong></p>&#13;
<ol type="a">&#13;
<li><p class="noindents">For each of the following definitions, identify whether it’s best described as a random variable or as a <em>realization</em> of a random variable. Furthermore, identify whether each statement describes a continuous or a discrete quantity.</p>&#13;
<ol type="i">&#13;
<li><p class="noindents">The number of coffees <em>x</em> made by your local shop on June 3, 2016</p></li>&#13;
<li><p class="noindents"><span epub:type="pagebreak" id="page_328"/>The number of coffees <em>X</em> made by your local shop on any given day</p></li>&#13;
<li><p class="noindents"><em>Y</em>, whether or not it rains tomorrow</p></li>&#13;
<li><p class="noindents"><em>Z</em>, the amount of rain that falls tomorrow</p></li>&#13;
<li><p class="noindents">How many crumbs <em>k</em> on your desk right now</p></li>&#13;
<li><p class="noindents">Total collective weight <em>W</em> of the crumbs on your desk at any specified time</p></li>&#13;
</ol></li>&#13;
<li><p class="noindents">Suppose you construct the following table providing probabilities associated with the random variable <em>S</em>, the total stars given to any movie in a particular genre by a certain critic:</p>&#13;
<table class="all1">&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table1"><p class="table"><strong><em>s</em></strong></p></td>&#13;
<td style="vertical-align: top;" class="table1"><p class="tablec"><strong>1</strong></p></td>&#13;
<td style="vertical-align: top;" class="table1"><p class="tablec"><strong>2</strong></p></td>&#13;
<td style="vertical-align: top;" class="table1"><p class="tablec"><strong>3</strong></p></td>&#13;
<td style="vertical-align: top;" class="table1"><p class="tablec"><strong>4</strong></p></td>&#13;
<td style="vertical-align: top;" class="table2"><p class="tablec"><strong>5</strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table3"><p class="table"><strong>Pr(<em>S</em> = <em>s</em>)</strong></p></td>&#13;
<td style="vertical-align: top;" class="table3"><p class="tablec">0.10</p></td>&#13;
<td style="vertical-align: top;" class="table3"><p class="tablec">0.13</p></td>&#13;
<td style="vertical-align: top;" class="table3"><p class="tablec">0.21</p></td>&#13;
<td style="vertical-align: top;" class="table3"><p class="tablec">???</p></td>&#13;
<td style="vertical-align: top;"><p class="tablec">0.15</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<ol type="i">&#13;
<li><p class="noindents">Assuming this table describes the complete set of outcomes, evaluate the missing probability Pr(<em>S</em> = 4).</p></li>&#13;
<li><p class="noindents">Obtain the cumulative probabilities.</p></li>&#13;
<li><p class="noindents">What is the mean of <em>S</em>, the expected number of stars this critic will award any given movie in this genre?</p></li>&#13;
<li><p class="noindents">What is the standard deviation of <em>S</em>?</p></li>&#13;
<li><p class="noindents">What is the probability that any given movie in this genre will be given at least three stars?</p></li>&#13;
<li><p class="noindents">Visualize, and briefly comment on the appearance of, the probability mass function.</p></li>&#13;
</ol></li>&#13;
<li><p class="noindents">Return to the picnic temperature example based on the random variable <em>W</em> defined in <a href="ch15.xhtml#ch15lev2sec135">Section 15.2.3</a>.</p>&#13;
<ol type="i">&#13;
<li><p class="noindents">Write an R function to return <em>f</em>(<em>w</em>) as per <a href="ch15.xhtml#ch15eq5">Equation (15.5)</a> for any numeric vector of values supplied as <em>w</em>. Try to avoid using a loop in favor of vector-oriented operations.</p></li>&#13;
<li><p class="noindents">Write an R function to return <em>F</em>(<em>w</em>) as per <a href="ch15.xhtml#ch15eq6">Equation (15.6)</a> for any numeric vector of values supplied as <em>w</em>. Again, try to avoid using a loop, either explicit or implicit.</p></li>&#13;
<li><p class="noindents">Use your functions from (i) and (ii) to confirm the results from the text, in other words, that <em>f</em> (55.2) = 0.02432 and that <em>F</em>(55.2) = 0.184832.</p></li>&#13;
<li><p class="noindents">Make use of your function for <em>F</em>(<em>w</em>) to compute Pr(<em>W</em> &gt; 60). Hint: Note that because the total area underneath <em>f</em> (<em>w</em>) is one, Pr(<em>W</em> &gt; 60) = 1 − Pr(<em>W</em> ≤ 60).</p></li>&#13;
<li><p class="noindents">Find Pr(60.3 &lt; <em>W</em> &lt; 76.89).</p></li>&#13;
</ol></li>&#13;
<li><p class="noindents"><span epub:type="pagebreak" id="page_329"/>Assume each of the following plots labeled (i)–(iv) shows the general appearance of a probability distribution. Use terminology from <a href="ch15.xhtml#ch15lev2sec136">Section 15.2.4</a> to describe the shape of each.</p></li>&#13;
</ol>&#13;
<div class="imagec"><img src="../images/f0329-01.jpg" alt="image"/></div>&#13;
</div>&#13;
<h5 class="h5" id="ch15lev3sec43"><strong>Important Code in This Chapter</strong></h5>&#13;
<table class="topbot">&#13;
<thead>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_th"><p class="table"><strong>Function/operator</strong></p></td>&#13;
<td style="vertical-align: top;" class="table_th"><p class="table"><strong>Brief description</strong></p></td>&#13;
<td style="vertical-align: top;" class="table_th"><p class="table"><strong>First occurrence</strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>polygon</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Add shaded polygon to plot</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch15.xhtml#ch15lev2sec135">Section 15.2.3</a>, <a href="ch15.xhtml#page_322">p. 322</a><span epub:type="pagebreak" id="page_330"/></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</body></html>