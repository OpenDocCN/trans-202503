<html><head></head><body><div id="sbo-rt-content"><section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="141" id="Page_141"/>9</span><br/>
<span class="ChapterTitle">Unsafe Code</span></h1>
</header>
<figure class="opener">
<img src="Images/chapterart.png" alt="" width="206" height="206"/>
</figure>
<p class="ChapterIntro">The mere mention of unsafe code often elicits strong responses from many in the Rust community, and from many of those watching Rust from the sidelines. While some maintain it’s “no big deal,” others decry it as “the reason all of Rust’s promises are a lie.” In this chapter, I hope to pull back the curtain a bit to explain what <code>unsafe</code> is, what it isn’t, and how you should go about using it safely. At the time of writing, and likely also when you read this, Rust’s precise requirements for unsafe code are still being determined, and even if they were all nailed down, the complete description would be beyond the scope of this book. Instead, I’ll do my best to arm you with the building blocks, intuition, and tooling you’ll need to navigate your way through most unsafe code.</p>
<p>Your main takeaway from this chapter should be this: unsafe code is the mechanism Rust gives developers for taking advantage of invariants that, for whatever reason, the compiler cannot check. We’ll look at the ways in which <code>unsafe</code> does that, what those invariants may be, and what we can do with it as a result.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="box">
<h2><span epub:type="pagebreak" title="142" id="Page_142"/>Invariants</h2>
<p class="BoxBodyFirst">Throughout this chapter, I’ll be talking a lot about invariants. <em>I</em><em>nvariant</em> is just a fancy way of saying “something that must be true for your program to be correct.” For example, in Rust, one invariant is that references, using <code>&amp;</code> and <code>&amp;mut</code>, do not dangle—they always point to valid values. You can also have application- or library-specific invariants, like “the head pointer is always ahead of the tail pointer” or “the capacity is always a power of two.” Ultimately, invariants represent all the assumptions required for your code to be correct. However, you may not always be aware of all the invariants that your code uses, and that’s where bugs creep in.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Crucially, unsafe code is not a way to skirt the various rules of Rust, like borrow checking, but rather a way to enforce those rules using reasoning that is beyond the compiler. When you write unsafe code, the onus is on you to ensure that the resulting code is safe. In a way, <code>unsafe</code> is misleading as a keyword when it is used to allow unsafe operations through <code>unsafe {}</code>; it’s not that the contained code <em>is</em> unsafe, it’s that the code is allowed to perform otherwise unsafe operations because in this particular context, those operations <em>are</em> safe.</p>
<p>The rest of this chapter is split into four sections. We’ll start with a brief examination of how the keyword itself is used, then explore what <code>unsafe</code> allows you to do. Next, we’ll look at the rules you must follow in order to write safe unsafe code. Finally, I’ll give you some advice about how to actually go about writing unsafe code safely.</p>
<h2 id="h1--0001">The unsafe Keyword</h2>
<p class="BodyFirst">Before we discuss the powers that <code>unsafe</code> grants you, we need to talk about its two different meanings. The <code>unsafe</code> keyword serves a dual purpose in Rust: it marks a particular function as unsafe to call <em>and </em>it enables you to invoke unsafe functionality in a particular code block. For example, the method in <a href="#listing9-1" id="listinganchor9-1">Listing 9-1</a> is marked as unsafe, even though it contains no unsafe code. Here, the <code>unsafe</code> keyword serves as a warning to the caller that there are additional guarantees that someone who writes code that invokes <code>decr</code> must manually check.</p>
<pre><code>impl&lt;T&gt; SomeType&lt;T&gt; {
    pub unsafe fn decr(&amp;self) {
        self.some_usize -= 1;
    }
}</code></pre>
<p class="CodeListingCaption"><a id="listing9-1">Listing 9-1</a>: An unsafe method that contains only safe code</p>
<p><span epub:type="pagebreak" title="143" id="Page_143"/><a href="#listing9-2" id="listinganchor9-2">Listing 9-2</a> illustrates the second usage. Here, the method itself is not marked as unsafe, even though it contains unsafe code.</p>
<pre><code>impl&lt;T&gt; SomeType&lt;T&gt; {
    pub fn as_ref(&amp;self) -&gt; &amp;T {
        unsafe { &amp;*self.ptr }
    }
}</code></pre>
<p class="CodeListingCaption"><a id="listing9-2">Listing 9-2</a>: A safe method that contains unsafe code</p>
<p>These two listings differ in their use of <code>unsafe</code> because they embody different contracts. <code>decr</code> requires the caller to be careful when they call the method, whereas <code>as_ref</code> assumes that the caller <em>was</em> careful when invoking other unsafe methods (like <code>decr</code>). To see why, imagine that <code>SomeType</code> is really a reference-counted type like <code>Rc</code>. Even though <code>decr</code> only decrements a number, that decrement may in turn trigger undefined behavior through the safe method <code>as_ref</code>. If you call <code>decr</code> and then drop the second-to-last <code>Rc</code> of a given <code>T</code>, the reference count drops to zero and the <code>T</code> will be dropped—but the program might still call <code>as_ref</code> on the last <code>Rc</code>, and end up with a dangling reference.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	<em>Undefined behavior </em>describes the consequences of a program that violates invariants of the language at runtime. In general, if a program triggers undefined behavior, the outcome is entirely unpredictable. We’ll cover undefined behavior in greater detail later in this chapter.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>Conversely, as long as there is no way to corrupt the <code>Rc</code> reference count using safe code, it is always safe to dereference the pointer inside the <code>Rc</code> the way the code for <code>as_ref</code> does—the fact that <code>&amp;self</code> exists is proof that the pointer must still be valid. We can use this to give the caller a safe API to an otherwise unsafe operation, which is a core piece of how to use <code>unsafe</code> responsibly.</p>
<p>For historical reasons, every <code>unsafe fn</code> contains an implicit unsafe block in Rust today. That is, if you declare an <code>unsafe fn</code>, you can always invoke any unsafe methods or primitive operations inside that <code>fn</code>. However, that decision is now considered a mistake, and it’s currently being reverted through the already accepted and implemented RFC 2585. This RFC warns about having an <code>unsafe fn</code> that performs unsafe operations without an explicit unsafe block inside it. The lint will also likely become a hard error in future editions of Rust. The idea is to reduce the “footgun radius”—if every <code>unsafe fn</code> is one giant unsafe block, then you might accidentally perform unsafe operations without realizing it! For example, in <code>decr</code> in <a href="#listing9-1">Listing 9-1</a>, under the current rules you could also have added <code>*std::ptr::null()</code> without any <code>unsafe</code> annotation.</p>
<p>The distinction between <code>unsafe</code> as a marker and unsafe blocks as a mechanism to enable unsafe operations is important, because you must think about them differently. An <code>unsafe fn</code> indicates to the caller that they have to be careful when calling the <code>fn</code> in question and that they must ensure that the function’s documented safety invariants hold.</p>
<p><span epub:type="pagebreak" title="144" id="Page_144"/>Meanwhile, an unsafe block implies that whoever wrote that block carefully checked that the safety invariants for any unsafe operations performed inside it hold. If you want an approximate real-world analogy, <code>unsafe fn</code> is an unsigned contract that asks the author of calling code to “solemnly swear X, Y, and Z.” Meanwhile, <code>unsafe {}</code> is the calling code’s author signing off on all the unsafe contracts contained within the block. Keep that in mind as we go through the rest of this chapter.</p>
<h2 id="h1--0002">Great Power</h2>
<p class="BodyFirst">So, once you sign the unsafe contract with <code>unsafe {}</code>, what are you allowed to do? Honestly, not that much. Or rather, it doesn’t enable that many new features. Inside an unsafe block, you are allowed to dereference raw pointers and call <code>unsafe fn</code>s.</p>
<p>That’s it. Technically, there are a few other things you can do, like accessing mutable and external static variables and accessing fields of unions, but those don’t change the discussion much. And honestly, that’s enough. Together, these powers allow you to wreak all sorts of havoc, like turning types into one another with <code>mem::transmute</code>, dereferencing raw pointers that point to who knows where, casting <code>&amp;'a</code> to <code>&amp;'static</code>, or making types shareable across thread boundaries even though they’re not thread-safe.</p>
<p>In this section, we won’t worry too much about what can go wrong with these powers. We’ll leave that for the boring, responsible, grown-up section that comes after. Instead, we’ll look at these neat shiny new toys and what we can do with them.</p>
<h3 id="h2--0001">Juggling Raw Pointers</h3>
<p class="BodyFirst">One of the most fundamental reasons to use <code>unsafe</code> is to deal with Rust’s raw pointer types: <code>*const T</code> and <code>*mut T</code>. You should think of these as more or less analogous to <code>&amp;T</code> and <code>&amp;mut T</code>, except that they don’t have lifetimes and are not subject to the same validity rules as their <code>&amp;</code> counterparts, which we’ll discuss later in the chapter. These types are interchangeably referred to as <em>pointers </em>and <em>raw pointers</em>,<em> </em>mostly because many developers instinctively refer to references as pointers, and calling them raw pointers makes the distinction clearer.</p>
<p>Since fewer rules apply to <code>*</code> than <code>&amp;</code>, you can cast a reference to a pointer even outside an unsafe block. Only if you want to go the other way, from <code>*</code> to <code>&amp;</code>, do you need <code>unsafe</code>. You’ll generally turn a pointer back into a reference to do useful things with the pointed-to data, such as reading or modifying its value. For that reason, a common operation to use on pointers is <code>unsafe { &amp;*ptr }</code> (or <code>&amp;mut *</code>). The <code>*</code> there may look strange as the code is just constructing a reference, not dereferencing the pointer, but it makes sense if you look at the types; if you have a <code>*mut T</code> and want a <code>&amp;mut T</code>, then <code>&amp;mut ptr</code> would just give you a <code>&amp;mut *mut T</code>. You need the <code>*</code> to indicate that you want the mutable reference to what <code>ptr</code> is a pointer <em>to</em>.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="box">
<h2><span epub:type="pagebreak" title="145" id="Page_145"/>Pointer Types</h2>
<p class="BoxBodyFirst">You may be wondering what the difference is between <code>*mut T</code> and <code>*const T</code> and <code>std::ptr::NonNull&lt;T&gt;</code>. Well, the exact specification is still being worked out, but the primary practical difference between <code>*mut T</code> and <code>*const T/NonNull&lt;T&gt;</code> is that <code>*mut T</code> is invariant in <code>T</code> (see “Lifetime Variance” in <span class="xref" itemid="xref_target_Chapter 1">Chapter 1</span>), whereas the other two are covariant. As the names imply, <code>*const T</code> and <code>NonNull&lt;T&gt;</code> differ primarily in that <code>NonNull&lt;T&gt;</code> is not allowed to be a null pointer, whereas <code>*const T</code> is.</p>
<p>My best advice in choosing among these types is to use your intuition about whether you would have written <code>&amp;mut</code> or <code>&amp;</code> if you were able to name the relevant lifetime. If you would have written <code>&amp;</code>, and you know that the pointer is never null, use <code>NonNull&lt;T&gt;</code>. It benefits from a cool optimization called the <em>niche optimization</em>: basically, since the compiler knows that the type can never be null, it can use that information to represent types like <code>Option&lt;NonNull&lt;T&gt;&gt;</code> without any extra overhead, since the <code>None</code> case can be represented by setting the <code>NonNull</code> to be a null pointer! The null pointer value is a niche in the <code>NonNull&lt;T&gt;</code> type. If the pointer might be null, use <code>*const T</code>. And if you would have written <code>&amp;mut T</code>, use <code>*mut T</code>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h4 id="h3--0001">Unrepresentable Lifetimes</h4>
<p class="BodyFirst">As raw pointers do not have lifetimes, they can be used in circumstances where the liveness of the value being pointed to cannot be expressed statically within Rust’s lifetime system, such as a self-pointer in a self-referential struct like the generators we discussed in <span class="xref" itemid="xref_target_Chapter 8">Chapter 8</span>. A pointer that points into <code>self</code> is valid for as long as <code>self</code> is around (and doesn’t move, which is what <code>Pin</code> is for), but that isn’t a lifetime you can generally name. And while the entire self-referential type may be <code>'static</code>, the self-pointer isn’t—if it were static, then even if you gave away that pointer to someone else, they could continue to use it forever, even after <code>self</code> was gone! Take the type in <a href="#listing9-3" id="listinganchor9-3">Listing 9-3</a> as an example; here we attempt to store the raw bytes that make up a value alongside its stored representation.</p>
<pre><code>struct Person&lt;'a&gt; {
    name: &amp;'a str,
    age: usize,
}
struct Parsed {
    bytes: [u8; 1024],
    parsed: Person&lt;'???&gt;,
}</code></pre>
<p class="CodeListingCaption"><a id="listing9-3">Listing 9-3</a>: Trying, and failing, to name the lifetime of a self-referential reference</p>
<p><span epub:type="pagebreak" title="146" id="Page_146"/>The reference inside <code>Person</code> wants to refer to data stored in <code>bytes</code> in <code>Parsed</code>, but there is no lifetime we can assign to that reference from <code>Parsed</code>. It’s not <code>'static</code> or something like <code>'self</code> (which doesn’t exist), because if <code>Parsed</code> is moved, the reference is no longer valid.</p>
<p>Since pointers do not have lifetimes, they circumvent this problem because you don’t have to be able to name the lifetime. Instead, you just have to make sure that when you do use the pointer, it’s still valid, which is what you sign off on when you write <code>unsafe { &amp;*ptr }</code>. In the example in <a href="#listing9-3">Listing 9-3</a>, <code>Person</code> would instead store a <code>*const str</code> and then unsafely turn that into a <code>&amp;str</code> at the appropriate times when it can guarantee that the pointer is still valid.</p>
<p>A similar issue arises with a type like <code>Arc</code>, which has a pointer to a value that’s shared for some duration, but that duration is known only at runtime when the last <code>Arc</code> is dropped. The pointer is kind-of, sort-of <code>'static</code>, but not really—like in the self-referential case, the pointer is no longer valid when the last <code>Arc</code> reference goes away, so the lifetime is more like <code>'self</code>. In <code>Arc</code>’s cousin, <code>Weak</code>, the lifetime is also “when the last <code>Arc</code> goes away,” but since a <code>Weak</code> isn’t an <code>Arc</code>, the lifetime isn’t even tied to <code>self</code>. So, <code>Arc</code> and <code>Weak</code> both use raw pointers internally.</p>
<h4 id="h3--0002">Pointer Arithmetic</h4>
<p class="BodyFirst">With raw pointers, you can do arbitrary pointer arithmetic, just like you can in C, by using <code>.offset()</code>, <code>.add()</code>, and <code>.sub()</code> to move the pointer to any byte that lives within the same allocation. This is most often used in highly space-optimized data structures, like hash tables, where storing an extra pointer for each element would add too much overhead and using slices isn’t possible. Those are fairly niche use cases, and we won’t be talking more about them in this book, but I encourage you to read the code for <code>hashbrown::RawTable</code> (<a href="https://github.com/rust-lang/hashbrown/" class="LinkURL">https://github.com/rust-lang/hashbrown/</a>) if you want to learn more!</p>
<p>The pointer arithmetic methods are unsafe to call even if you don’t want to turn the pointer into a reference afterwards. There are a couple of reasons for this, but the main one is that it is illegal to make a pointer point beyond the end of the allocation that it originally pointed to. Doing so triggers undefined behavior, and the compiler is allowed to decide to eat your code and replace it with arbitrary nonsense that only a compiler could understand. If you do use these methods, read the documentation carefully!</p>
<h4 id="h3--0003">To Pointer and Back Again</h4>
<p class="BodyFirst">Often when you need to use pointers, it’s because you have some normal Rust type, like a reference, a slice, or a string, and you have to move to the world of pointers for a bit and then go back to the original normal type. Some of the key standard library types therefore provide you with a way to turn them into their raw constituent parts, such as a pointer and a length for a slice, and a way to turn them back into the whole using those same parts. For example, you can get a slice’s data pointer with <code>as_ptr</code> and its length with <code>[]::len</code>. You can then reconstruct the slice by providing those <span epub:type="pagebreak" title="147" id="Page_147"/>same values to <code>std::slice::from_raw_parts</code>. <code>Vec</code>, <code>Arc</code>, and <code>String</code> have similar methods that return a raw pointer to the underlying allocation, and <code>Box</code> has <code>Box::into_raw</code> and <code>Box::from_raw</code>, which do the same thing.</p>
<h4 id="h3--0004">Playing Fast and Loose with Types</h4>
<p class="BodyFirst">Sometimes, you have a type <code>T</code> and want to treat it as some other type <code>U</code>. Whether that’s because you need to do lightning-fast zero-copy parsing or because you need to fiddle with some lifetimes, Rust provides you with some (very unsafe) tools to do so.</p>
<p>The first and by far most widely used of these is pointer casting: you can cast a <code>*const T</code> to any other <code>*const U</code> (and the same for <code>mut</code>), and you don’t even need <code>unsafe</code> to do it. The unsafety comes into play only when you later try to use the cast pointer as a reference, as you have to assert that the raw pointer can in fact be used as a reference to the type it’s pointing to.</p>
<p>This kind of pointer type casting comes in particularly handy when working with foreign function interfaces (FFI)—you can cast any Rust pointer to a <code>*const std::ffi::c_void</code> or <code>*mut std::ffi::c_void</code>, and then pass that to a C function that expects a void pointer. Similarly, if you get a void pointer from C that you previously passed in, you can trivially cast it back into its original type.</p>
<p>Pointer casts are also useful when you want to interpret a sequence of bytes as plain old data—types like integers, Booleans, characters, and arrays, or <code>#[repr(C)]</code> structs of these—or write such types directly out as a byte stream without serialization. There are a lot of safety invariants to keep in mind if you want to try to do that, but we’ll leave that for later.</p>
<h3 id="h2--0002">Calling Unsafe Functions</h3>
<p class="BodyFirst">Arguably <code>unsafe</code>’s most commonly used feature is that it enables you to call unsafe functions. Deeper down the stack, most of those functions are unsafe because they operate on raw pointers at some fundamental level, but higher up the stack you tend to interact with unsafety primarily through function calls.</p>
<p>There’s really no limit to what calling an unsafe function might enable, as it is entirely up to the libraries you interact with. But <em>in general</em>, unsafe functions can be divided into three camps: those that interact with non-Rust interfaces, those that skip safety checks, and those that have custom invariants.</p>
<h4 id="h3--0005">Foreign Function Interfaces</h4>
<p class="BodyFirst">Rust lets you declare functions and static variables that are defined in a language other than Rust using <code>extern</code> blocks (which we’ll discuss at length in <span class="xref" itemid="xref_target_Chapter 11">Chapter 11</span>). When you declare such a block, you’re telling Rust that the items appearing within it will be implemented by some external source when the final program binary is linked, such as a C library you are integrating with. Since <code>extern</code>s exist outside of Rust’s control, they are inherently unsafe to access. If you call a C function from Rust, all bets are off—it might overwrite your entire memory contents and clobber all your neatly arranged <span epub:type="pagebreak" title="148" id="Page_148"/>references into random pointers into the kernel somewhere. Similarly, an <code>extern</code> static variable could be modified by external code at any time, and could be filled with all sorts of bad bytes that don’t reflect its declared type at all. In an unsafe block, though, you can access <code>extern</code>s to your heart’s delight, as long as you’re willing to vouch for the other side of the extern behaving according to Rust’s rules.</p>
<h4 id="h3--0006">I’ll Pass on Safety Checks</h4>
<p class="BodyFirst">Some unsafe operations can be made entirely safe by introducing additional runtime checks. For example, accessing an item in a slice is unsafe since you might try to access an item beyond the length of the slice. But, given how common the operation is, it’d be unfortunate if indexing into a slice was unsafe. Instead, the safe implementation includes bounds checks that (depending on the method you use) either panic or return an <code>Option</code> if the index you provide is out of bounds. That way, there is no way to cause undefined behavior even if you pass in an index beyond the slice’s length. Another example is in hash tables, which hash the key you provide rather than letting you provide the hash yourself; this ensures that you’ll never try to access a key using the wrong hash.</p>
<p>However, in the endless pursuit of ultimate performance, some developers may find these safety checks add just a little too much overhead in their tightest loops. To cater to situations where peak performance is paramount and the caller knows that the indexes are in bounds, many data structures provide alternate versions of particular methods without these safety checks. Such methods usually include the word <code>unchecked</code> in the name to indicate that they blindly trust the provided arguments to be safe and that they do not do any of those pesky, slow safety checks. Some examples are <code>NonNull::new_unchecked</code>, <code>slice::get_unchecked</code>, <code>NonZero::new_unchecked</code>, <code>Arc::get_mut_unchecked</code>, and <code>str::from_utf8_unchecked</code>.</p>
<p>In practice, the safety and performance trade-off for<em> </em>unchecked methods is rarely worth it. As always with performance optimization, measure first, then optimize.</p>
<h4 id="h3--0007">Custom Invariants</h4>
<p class="BodyFirst">Most uses of <code>unsafe</code> rely on custom invariants to some degree. That is, they rely on invariants beyond those provided by Rust itself, which are specific to the particular application or library. Since so many functions fall into this category, it’s hard to give a good general summary of this class of unsafe functions. Instead, I’ll give some examples of unsafe functions with custom invariants that you may come across in practice and want to use:</p>
<p class="ListHead"><b><code class="bold">MaybeUninit::assume_init</code></b></p>
<ol class="none">
<li>The <code>MaybeUninit</code> type is one of the few ways in which you can store values that are not valid for their type in Rust. You can think of a <code>MaybeUninit&lt;T&gt;</code> as a <code>T</code> that may not be legal to use as a <code>T</code> at the moment. For example, a <code>MaybeUninit&lt;NonNull&gt;</code> is allowed to hold a null pointer, a <code>MaybeUninit&lt;Box&gt;</code> is allowed to hold a dangling heap pointer, and a <code/><span epub:type="pagebreak" title="149" id="Page_149"/>MaybeUninit&lt;bool&gt; is allowed to hold the bit pattern for the number 3 (normally it must be 0 or 1). This comes in handy if you are constructing a value bit by bit or are dealing with zeroed or uninitialized memory that will eventually be made valid (such as by being filled through a call to <code>std::io::Read::read</code>). The <code>assume_init</code> function asserts that the <code>MaybeUninit</code> now holds a valid value for the type <code>T</code> and can therefore be used as a <code>T</code>.</li>
</ol>
<p class="ListHead"><b><code class="bold">ManuallyDrop::drop</code></b></p>
<ol class="none">
<li>The <code>ManuallyDrop</code> type is a wrapper type around a type <code>T</code> that does not drop that <code>T</code> when the <code>ManuallyDrop</code> is dropped. Or, phrased differently, it decouples the dropping of the outer type (<code>ManuallyDrop</code>) from the dropping of the inner type (<code>T</code>). It implements safe access to the <code>T</code> through <code>DerefMut&lt;Target = T&gt;</code> but also provides a <code>drop</code> method (separately from the <code>drop</code> method of the <code>Drop</code> trait) to drop the wrapped <code>T</code> <em>without</em> dropping the <code>ManuallyDrop</code>. That is, the <code>drop</code> function takes <code>&amp;mut self</code> despite dropping the <code>T</code>, and so leaves the <code>ManuallyDrop</code> behind. This comes in handy if you have to explicitly drop a value that you cannot move, such as in implementations of the <code>Drop</code> trait. Once that value is dropped, it is no longer safe to try to access the <code>T</code>, which is why the call to <code>drop</code> is unsafe—it asserts that the <code>T</code> will never be accessed again.</li>
</ol>
<p class="ListHead"><b><code class="bold">std::ptr::drop_in_place</code></b></p>
<ol class="none">
<li><code>drop_in_place</code> lets you call a value’s destructor directly through a pointer to that value. This is unsafe because the pointee will be left behind after the call, so if some code then tries to dereference the pointer, it’ll be in for a bad time! This method is particularly useful when you may want to reuse memory, such as in an arena allocator, and need to drop an old value in place without reclaiming the surrounding memory.</li>
</ol>
<p class="ListHead"><b><code class="bold">Waker::from_raw</code></b></p>
<ol class="none">
<li>In <span class="xref" itemid="xref_target_Chapter 8">Chapter 8</span> we talked about the <code>Waker</code> type and how it is made up of a data pointer and a <code>RawWaker</code> that holds a manually implemented vtable. Once a <code>Waker</code> has been constructed, the raw function pointers in the vtable, such as <code>wake</code> and <code>drop</code>, can be called from safe code (through <code>Waker::wake</code> and <code>drop(waker)</code>, respectively). <code>Waker::from_raw </code>is where the asynchronous executor asserts that all the pointers in its vtable are in fact valid function pointers that follow the contract set forth in the documentation of <code>RawWakerVTable</code>.</li>
</ol>
<p class="ListHead"><b><code class="bold">std::hint::unreachable_unchecked</code></b></p>
<ol class="none">
<li>The <code>hint</code> module holds functions that give hints to the compiler about the surrounding code but do not actually produce any machine code. The <code>unreachable_unchecked</code> function in particular tells the compiler that it is impossible for the program to reach a section of the code at runtime. This in turn allows the compiler to make optimizations based on that <span epub:type="pagebreak" title="150" id="Page_150"/>knowledge, such as eliminating conditional branches to that location. Unlike the <code>unreachable!</code> macro, which panics if the code does reach the line in question, the effects of an erroneous <code>unreachable_unchecked</code> are hard to predict. The compiler optimizations may cause peculiar and hard-to-debug behavior, not to mention that your program will continue running when something it believed to be true was not!</li>
</ol>
<p class="ListHead"><b><code class="bold">std::ptr::{read,write}_{unaligned,volatile}</code></b></p>
<ol class="none">
<li>The <code>ptr</code> module holds a number of functions that let you work with <em>odd</em> pointers—those that do not meet the assumptions that Rust generally makes about pointers. The first of these functions are <code>read_unaligned</code> and <code>write_unaligned</code>, which let you access pointers that point to a <code>T</code> even if that <code>T</code> is not stored according to <code>T</code>’s alignment (see the section on alignment in <span class="xref" itemid="xref_target_Chapter 2">Chapter 2</span>). This might happen if the <code>T</code> is contained directly in a byte array or is otherwise packed in with other values without proper padding. The second notable pair of functions is <code>read_volatile</code> and <code>write_volatile</code>, which let you operate on pointers that don’t point to normal memory. Concretely, these functions will always access the given pointer (they won’t be cached in a register, for example, even if you read the same pointer twice in a row), and the compiler won’t reorder the volatile accesses relative to other volatile accesses. Volatile operations come in handy when working with pointers that aren’t backed by normal DRAM memory—we’ll discuss this further in <span class="xref" itemid="xref_target_Chapter 11">Chapter 11</span>. Ultimately, these methods are unsafe because they dereference the given pointer (and to an owned <code>T</code>, at that), so you as the caller need to sign off on all the contracts associated with doing so.</li>
</ol>
<p class="ListHead"><b><code class="bold">std::thread::Builder::spawn_unchecked</code></b></p>
<ol class="none">
<li>The normal <code>thread::spawn</code> that we know and love requires that the provided closure is <code>'static</code>. That bound stems from the fact that the spawned thread might run for an indeterminate amount of time; if we were allowed to use a reference to, say, the caller’s stack, the caller might return well before the spawned thread exits, rendering the reference invalid. Sometimes, however, you know that some non-<code>'static</code> value in the caller will outlive the spawned thread. This might happen if you join the thread before dropping the value in question, or if the value is dropped only strictly after you know the spawned thread will no longer use it. That’s where <code>spawn_unchecked</code> comes in—it does not have the <code>'static</code> bound and thus lets you implement those use cases as long as you’re willing to sign the contract saying that no unsafe accesses will happen as a result. Be careful of panics, though; if the caller panics, it might drop values earlier than you planned and cause undefined behavior in the spawned thread!</li>
</ol>
<p>Note that all of these methods (and indeed all unsafe methods in the standard library) provide explicit documentation for their safety invariants, as should be the case for any unsafe method.</p>
<h3 id="h2--0003"><span epub:type="pagebreak" title="151" id="Page_151"/>Implementing Unsafe Traits</h3>
<p class="BodyFirst">Unsafe traits aren’t unsafe to <em>use</em>, but unsafe to <em>implement</em>. This is because unsafe code is allowed to rely on the correctness (defined by the trait’s documentation) of the implementation of unsafe traits. For example, to implement the unsafe trait <code>Send</code>, you need to write <code>unsafe impl Send for ...</code>. Like unsafe functions, unsafe traits generally have custom invariants that are (or at least should be) specified in the documentation for the trait. Thus, it’s difficult to cover unsafe traits as a group, so here too I’ll give some common examples from the standard library that are worth going over.</p>
<h4 id="h3--0008">Send and Sync</h4>
<p class="BodyFirst">The <code>Send</code> and <code>Sync</code> traits denote that a type is safe to send or share across thread boundaries, respectively. We’ll talk more about these traits in <span class="xref" itemid="xref_target_Chapter 10">Chapter 10</span>, but for now what you need to know is that they are auto-traits, and so they’ll usually be implemented for most types for you by the compiler. But, as tends to be the case with auto-traits, <code>Send</code> and <code>Sync</code> will not be implemented if any members of the type in question are not themselves <code>Send</code> or <code>Sync</code>.</p>
<p>In the context of unsafe code, this problem occurs primarily due to raw pointers, which are neither <code>Send</code> nor <code>Sync</code>. At first glance, this might seem reasonable: the compiler has no way to know who else may have a raw pointer to the same value or how they may be using it at the moment, so how can the type be safe to send across threads? Now that we’re seasoned unsafe developers though, that argument seems weak—after all, dereferencing a raw pointer is already unsafe, so why should handling the invariants of <code>Send</code> and <code>Sync</code> be any different?</p>
<p>Strictly speaking, raw pointers could be both <code>Send</code> and <code>Sync</code>. The problem is that if they were, the types that contain raw pointers would automatically be <code>Send</code> and <code>Sync</code> themselves, even though their author might not realize that was the case. The developer might then unsafely dereference the raw pointers without ever thinking about what would happen if those types were sent or shared across thread boundaries, and thus inadvertently introduce undefined behavior. Instead, the raw pointer types block these automatic implementations as an additional safeguard to unsafe code to make authors explicitly sign the contract that they have also followed the <code>Send</code> and <code>Sync</code> invariants.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	A common mistake with unsafe implementations of <code>Send</code> and <code>Sync</code> is to forget to add bounds to generic parameters: <code>unsafe impl&lt;T: Send&gt; Send for </code><code>MyUnsafeType&lt;T&gt; {}</code>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h4 id="h3--0009">GlobalAlloc</h4>
<p class="BodyFirst">The <code>GlobalAlloc</code> trait is how you implement a custom memory allocator in Rust. We won’t talk too much about that topic in this book, but the trait itself is interesting. <a href="#listing9-4" id="listinganchor9-4">Listing 9-4</a> gives the required methods for the <code>GlobalAlloc</code> trait.</p>
<pre><code><span epub:type="pagebreak" title="152" id="Page_152"/>pub unsafe trait GlobalAlloc {
    pub unsafe fn alloc(&amp;self, layout: Layout) -&gt; *mut u8;
    pub unsafe fn dealloc(&amp;self, ptr: *mut u8, layout: Layout);
}</code></pre>
<p class="CodeListingCaption"><a id="listing9-4">Listing 9-4</a>: The <code>GlobalAlloc</code> trait with its required methods</p>
<p>At its core, the trait has one method for allocating a new chunk of memory, <code>alloc</code>, and one for deallocating a chunk of memory, <code>dealloc</code>. The <code>Layout</code> argument describes the type’s size and alignment, as we discussed in <span class="xref" itemid="xref_target_Chapter 2">Chapter 2</span>. Each of those methods is unsafe and carries a number of safety invariants that its callers must uphold.</p>
<p> <code>GlobalAlloc</code> itself is also unsafe because it places restrictions on the implementer of the trait, not the caller of its methods. Only the unsafety of the trait ensures that implementers agree to uphold the invariants that Rust itself assumes of its memory allocator, such as in the standard library’s implementation of <code>Box</code>. If the trait was not unsafe, an implementer could safely implement <code>GlobalAlloc</code> in a way that produced unaligned pointers or incorrectly sized allocations, which would trigger unsafety in otherwise safe code that assumes that allocations are sane. This would break the rule that safe code should not be able to trigger memory unsafety in other safe code, and thus cause all sorts of mayhem.</p>
<h4 id="h3--0010">Surprisingly Not Unpin</h4>
<p class="BodyFirst">The <code>Unpin</code> trait is not unsafe, which comes as a surprise to many Rust developers. It may even come as a surprise to you after reading <span class="xref" itemid="xref_target_Chapter 8">Chapter 8</span>. After all, the trait is supposed to ensure that self-referential types aren’t invalidated if they’re moved after they have established internal pointers (that is, after they’ve been placed in a <code>Pin</code>). It seems strange, then, that <code>Unpin</code> can be used to safely remove a type from a <code>Pin</code>.</p>
<p>There are two main reasons why <code>Unpin</code> isn’t an unsafe trait. First, it’s unnecessary. Implementing <code>Unpin</code> for a type that you control does not grant you the ability to safely pin or unpin a <code>!Unpin</code> type; that still requires unsafety in the form of a call to <code>Pin::new_unchecked</code> or <code>Pin::get_unchecked_mut</code>. Second, there is already a safe way for you to unpin any type you control: the <code>Drop</code> trait! When you implement <code>Drop</code> for a type, you’re passed <code>&amp;mut self</code>, even if your type was previously stored in a <code>Pin</code> and is <code>!Unpin</code>, all without any unsafety. That potential for unsafety is covered by the invariants of <code>Pin::new_unchecked</code>, which must be upheld to create a <code>Pin</code> of such an <code>!Unpin</code> type in the first place.</p>
<h4 id="h3--0011">When to Make a Trait Unsafe</h4>
<p class="BodyFirst">Few traits in the wild are unsafe, but those that are all follow the same pattern. A trait should be unsafe if safe code that assumes that trait is implemented correctly can exhibit memory unsafety if the trait is <em>not</em> implemented correctly.</p>
<p>The <code>Send</code> trait is a good example to keep in mind here—safe code can easily spawn a thread and pass a value to that spawned thread, but if <code>Rc</code> were <code/><span epub:type="pagebreak" title="153" id="Page_153"/>Send, that sequence of operations could trivially lead to memory unsafety. Consider what would happen if you cloned an <code>Rc&lt;Box&gt;</code> and sent it to another thread: the two threads could easily both try to deallocate the <code>Box</code> since they do not correctly synchronize access to the <code>Rc</code>’s reference count.</p>
<p>The <code>Unpin</code> trait is a good counterexample. While it is possible to write unsafe code that triggers memory unsafety if <code>Unpin</code> is implemented incorrectly, no entirely safe code can trigger memory unsafety due to an implementation of <code>Unpin</code>. It’s not always easy to determine that a trait can be safe (indeed, the <code>Unpin</code> trait was unsafe throughout most of the RFC process), but you can always err on the side of making the trait unsafe, and then make it safe later on if you realize that is the case! Just keep in mind that that is a backward incompatible change.</p>
<p>Also keep in mind that just because it feels like an incorrect (or even malicious) implementation of a trait would cause a lot of havoc, that’s not necessarily a good reason to make it unsafe. The <code>unsafe</code> marker should first and foremost be used to highlight cases of <em>memory</em> unsafety, not just something that can trigger errors in business logic. For example, the <code>Eq</code>, <code>Ord</code>, <code>Deref</code>, and <code>Hash</code> traits are all safe, even though there is likely much code out in the world that would go haywire if faced with a malicious implementation of, say, <code>Hash</code> that returned a different random hash each time it was called. This extends to unsafe code too—there is almost certainly unsafe code out there that would be memory-unsafe in the presence of such an implementation of <code>Hash</code>—but that does not mean <code>Hash</code> should be unsafe. The same is true for an implementation of <code>Deref</code> that dereferenced to a different (but valid) target each time. Such unsafe code would be relying on a contract of <code>Hash</code> or <code>Deref</code> that does not actually hold; <code>Hash</code> never claimed that it was deterministic, and neither did <code>Deref</code>. Or rather, the authors of those implementations never used the <code>unsafe</code> keyword to make that claim!</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	An important implication of traits like <code>Eq</code>, <code>Hash</code>, and <code>Deref</code> being safe is that unsafe code can rely only on the <em>safety</em><em> </em>of safe code, not its correctness. This applies not only to traits, but to all unsafe/safe code interactions.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1--0003">Great Responsibility</h2>
<p class="BodyFirst">So far, we’ve looked mainly at the various things that you are allowed to do with unsafe code. But unsafe code is allowed to do those things only if it does so safely. Even though unsafe code can, say, dereference a raw pointer, it must do so only if it knows that pointer is valid as a reference to its pointee at that moment in time, subject to all of Rust’s normal requirements of references. In other words, unsafe code is given access to tools that could be used to do unsafe things, but it must do only safe things using those tools.</p>
<p>That, then, raises the question of what <em>safe</em> even means in the first place. When is it safe to dereference a pointer? When is it safe to transmute between two different types? In this section, we’ll explore some of the key <span epub:type="pagebreak" title="154" id="Page_154"/>invariants to keep in mind when wielding the power of <code>unsafe</code>, look at some common gotchas, and get familiar with some of the tools that help you write safer unsafe code.</p>
<p>The exact rules around what it means for Rust code to be safe are still being worked out. At the time of writing, the Unsafe Code Guidelines Working Group is hard at work nailing down all the dos and don’ts, but many questions remain unanswered. Most of the advice in this section is more or less settled, but I’ll make sure to call out any that isn’t. If anything, I’m hoping that this section will teach you to be careful about making assumptions when you write unsafe code, and prompt you to double-check the Rust reference before you declare your code production-ready.</p>
<h3 id="h2--0004">What Can Go Wrong?</h3>
<p class="BodyFirst">We can’t really get into the rules unsafe code must abide by without talking about what happens if you violate those rules. Let’s say you do mutably access a value from multiple threads concurrently, construct an unaligned reference, or dereference a dangling pointer—now what?</p>
<p>Unsafe code that is not ultimately safe is referred to as having <em>undefined behavior</em>. Undefined behavior generally manifests in one of three ways: not at all, through visible errors, or through invisible corruption. The first is the happy case—you wrote some code that is truly not safe, but the compiler generated sane code that the computer you’re running the code on executes in a sane way. Unfortunately, the happiness here is very brittle. Should a new and slightly smarter version of the compiler come along, or some surrounding code cause the compiler to apply another optimization, the code may no longer do something sane and tip over into one of the worse cases. Even if the same code is compiled by the same compiler, if it runs on a different platform or host, the program might act differently! This is why it is important to avoid undefined behavior even if everything currently seems to work fine. Not to do so is like playing a second round of Russian roulette just because you survived the first.</p>
<p>Visible errors are the easiest undefined behavior to catch. If you dereference a null pointer, for example, your program will (in all likelihood) crash with an error, which you can then debug back to the root cause. That debugging may itself be difficult, but at least you have a notification that something is wrong. Visible errors can also manifest in less severe ways, such as deadlocks, garbled output, or panics that are printed but don’t trigger a program exit, all of which tell you that there is a bug in your code that you have to go fix.</p>
<p>The worst manifestation of undefined behavior is when there is no immediate visible effect, but the program state is invisibly corrupted. Transaction amounts might be slightly off from what they should be, backups might be silently corrupted, or random bits of internal memory could be exposed to external clients. The undefined behavior could cause ongoing corruption, or extremely infrequent outages. Part of the challenge with undefined behavior is that, as the name implies, the behavior of the non-safe unsafe code is not defined—the compiler might eliminate it entirely, <span epub:type="pagebreak" title="155" id="Page_155"/>dramatically change the semantics of the code, or even miscompile surrounding code. What that does to your program is entirely dependent on what the code in question does. The unpredictable impact of undefined behavior is the reason why <em>all</em> undefined behavior should be considered a serious bug, no matter how it <em>currently</em> manifests.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="box">
<h2>Why Undefined Behavior?</h2>
<p class="BoxBodyFirst">An argument that often comes up in conversations about undefined behavior is that the compiler should emit an error if code exhibits undefined behavior instead of doing something weird and unpredictable. That way, it would be near-impossible to write bad unsafe code!</p>
<p>Unfortunately, that would be impossible because undefined behavior is rarely explicit or obvious. Instead, what usually happens is that the compiler simply applies optimizations under the assumption that the code follows the specification. Should that turn out to not be the case—which is rarely clear until runtime—it’s difficult to predict what the effect might be. Maybe the optimization is still valid, and nothing bad happens; but maybe it’s not, and the semantics of the code end up slightly different from that of the unoptimized version.</p>
<p>If we were to tell compiler developers that they aren’t allowed to assume anything about the underlying code, what we’d really be telling them is that they cannot perform a wide range of the optimizations that they implement with great success today. Nearly all sophisticated optimizations make assumptions about what the code in question can and cannot do according to the language specification.</p>
<p>If you want a good illustration of how specifications and compiler optimizations interact in strange ways where it’s hard to assign blame, I recommend reading through Ralf Jung’s blog post “We Need Better Language Specs” (<a href="https://www.ralfj.de/blog/2020/12/14/provenance.html" class="LinkURL">https://www.ralfj.de/blog/2020/12/14/provenance.html</a>).</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2--0005">Validity</h3>
<p class="BodyFirst">Perhaps the most important concept to understand before writing unsafe code is <em>validity</em>, which dictates the rules for what values inhabit a given type—or, less formally, the rules for a type’s values. The concept is simpler than it sounds, so let’s dive into some concrete examples.</p>
<h4 id="h3--0012">Reference Types</h4>
<p class="BodyFirst">Rust is very strict about what values its reference types can hold. Specifically, references must never dangle, must always be aligned, and must always point to a valid value for their target type. In addition, a shared and an exclusive reference to a given memory location can never exist at the same time, and neither can multiple exclusive references to a location. These <span epub:type="pagebreak" title="156" id="Page_156"/>rules apply regardless of whether your code uses the references or not—you are not allowed to create a null reference even if you then immediately discard it!</p>
<p>Shared references have the additional constraint that the pointee is not allowed to change during the reference’s lifetime. That is, any value the pointee contains must remain exactly the same over its lifetime. This applies transitively, so if you have an <code>&amp;</code> to a type that contains a <code>*mut T</code>, you are not allowed to ever mutate the <code>T</code> through that <code>*mut</code> even though you could write code to do so using <code>unsafe</code>. The <em>only</em> exception to this rule is a value wrapped by the <code>UnsafeCell</code> type. All other types that provide interior mutability, like <code>Cell</code>, <code>RefCell</code>, and <code>Mutex</code>, internally use an <code>UnsafeCell</code>.</p>
<p>An interesting result of Rust’s strict rules for references is that for many years, it was impossible to safely take a reference to a field of a packed or partially uninitialized struct that used <code>repr(Rust)</code>. Since <code>repr(Rust)</code> leaves a type’s layout undefined, the only way to get the address of a field was by writing <code>&amp;some_struct.field as *const _</code>. However, if <code>some_struct</code> is packed, then <code>some_struct.field</code> may not be aligned, and thus creating an <code>&amp;</code> to it is illegal! Further, if <code>some_struct</code> isn’t fully initialized, then the <code>some_struct</code> reference itself cannot exist! In Rust 1.51.0, the <code>ptr::addr_of!</code> macro was stabilized, which added a mechanism for directly obtaining a reference to a field without first creating a reference, fixing this particular problem. Internally, it is implemented using something called <em>raw references</em> (not to be confused with raw pointers), which directly create pointers to their operands rather than going via a reference. Raw references were introduced in RFC 2582 but haven’t been stabilized themselves yet at the time of writing.</p>
<h4 id="h3--0013">Primitive Types</h4>
<p class="BodyFirst">Some of Rust’s primitive types have restrictions on what values they can hold. For example, a <code>bool</code> is defined as being 1 byte large but is only allowed to hold the value <code>0x00</code> or the value <code>0x01</code>, and a <code>char</code> is not allowed to hold a surrogate or a value above <code>char::MAX</code>. Most of Rust’s primitive types, and indeed most of Rust’s types overall, also cannot be constructed from uninitialized memory. These restrictions may seem arbitrary, but again often stem from the need to enable optimizations that wouldn’t be possible otherwise.</p>
<p>A good illustration of this is the niche optimization, which we discussed briefly when talking about pointer types earlier in this chapter. To recap, the niche optimization tucks away the enum discriminant value in the wrapped type in certain cases. For example, since a reference cannot ever be all zeros, an <code>Option&lt;&amp;T&gt;</code> can use all zeros to represent <code>None</code>, and thus avoid spending an extra byte (plus padding) to store the discriminator byte. The compiler can optimize Booleans in the same way and potentially take it even further. Consider the type <code>Option&lt;Option&lt;bool&gt;&gt;&gt;</code>. Since the compiler knows that the <code>bool</code> is either <code>0x00</code> or <code>0x01</code>, it’s free to use <code>0x02</code> to represent <code>Some(None)</code> and <code>0x03</code> to represent <code>None</code>. Very nice and tidy! But if someone were to come along and treat the byte <code>0x03</code> as a <code>bool</code>, and then place that value in an <code>Option&lt;Option&lt;bool&gt;&gt;</code> optimized in this way, bad things would happen.</p>
<p><span epub:type="pagebreak" title="157" id="Page_157"/>It bears repeating that it’s not important whether the Rust compiler currently implements this optimization or not. The point is that it is allowed to, and therefore any unsafe code you write must conform to that contract or risk hitting a bug later on should the behavior change.</p>
<h4 id="h3--0014">Owned Pointer Types</h4>
<p class="BodyFirst">Types that point to memory they own, like <code>Box</code> and <code>Vec</code>, are generally subject to the same optimizations as if they held an exclusive reference to the pointed-to memory unless they’re explicitly accessed through a shared reference. Specifically, the compiler assumes that the pointed-to memory is not shared or aliased elsewhere, and makes optimizations based on that assumption. For example, if you extracted the pointer from a <code>Box</code> and then constructed two <code>Box</code>es from that same pointer and wrapped them in <code>ManuallyDrop</code> to prevent a double-free, you’d likely be entering undefined behavior territory. That’s the case even if you only ever access the inner type through shared references. (I say “likely” because this isn’t fully settled in the language reference yet, but a rough consensus has arisen.)</p>
<h4 id="h3--0015">Storing Invalid Values</h4>
<p class="BodyFirst">Sometimes you need to store a value that isn’t currently valid for its type. The most common example of this is if you want to allocate a chunk of memory for some type <code>T</code> and then read in the bytes from, say, the network. Until all the bytes have been read in, the memory isn’t going to be a valid <code>T</code>. Even if you just tried to read the bytes into a slice of <code>u8</code>, you would have to zero those <code>u8</code>s first, because constructing a <code>u8</code> from uninitialized memory is also undefined behavior.</p>
<p>The <code>MaybeUninit&lt;T&gt;</code> type is Rust’s mechanism for working with values that aren’t valid. A <code>MaybeUninit&lt;T&gt;</code> stores exactly a <code>T</code> (it is <code>#[repr(transparent)]</code>), but the compiler knows to make no assumptions about the validity of that <code>T</code>. It won’t assume that references are non-null, that a <code>Box&lt;T&gt;</code> isn’t dangling, or that a <code>bool</code> is either 0 or 1. This means it’s safe to hold a <code>T</code> backed by uninitialized memory inside a <code>MaybeUninit</code> (as the name implies). <code>MaybeUninit</code> is also a very useful tool in other unsafe code where you have to temporarily store a value that may be invalid. Maybe you have to store an aliased <code>Box&lt;T&gt;</code> or stash a <code>char</code> surrogate for a second—<code>MaybeUninit</code> is your friend.</p>
<p>You will generally do only three things with a <code>MaybeUninit</code>: create it using the <code>MaybeUninit::uninit</code> method, write to its contents using <code>MaybeUninit::as_mut_ptr</code>, or take the inner <code>T</code> once it is valid again with <code>MaybeUninit::assume_init</code>. As its name implies, <code>uninit</code> creates a new <code>MaybeUninit&lt;T&gt;</code> of the same size as a <code>T</code> that initially holds uninitialized memory. The <code>as_mut_ptr</code> method gives you a raw pointer to the inner <code>T</code> that you can then write to; nothing stops you from reading from it, but reading from any of the uninitialized bits is undefined behavior. And finally, the unsafe <code>assume_init</code> method consumes the <code>MaybeUninit&lt;T&gt;</code> and returns its contents as a <code>T</code> following the assertion that the backing memory now makes up a valid <code>T</code>.</p>
<p><a href="#listing9-5" id="listinganchor9-5">Listing 9-5</a> shows an example of how we might use <code>MaybeUninit</code> to safely initialize a byte array without explicitly zeroing it.</p>
<pre><code><span epub:type="pagebreak" title="158" id="Page_158"/>fn fill(gen: impl FnMut() -&gt; Option&lt;u8&gt;) {
    let mut buf = [MaybeUninit::&lt;u8&gt;::uninit(); 4096];
    let mut last = 0;
    for (i, g) in std::iter::from_fn(gen).take(4096).enumerate() {
        buf[i] = MaybeUninit::new(g);
        last = i + 1;
    }
    <span class="LiteralGray">// Safety: all the u8s up to last are initialized.</span>
    let init: &amp;[u8] = unsafe {
       MaybeUninit::slice_assume_init_ref(&amp;buf[..last])
};
    <span class="LiteralGray">// ... do something with init ...</span>
}</code></pre>
<p class="CodeListingCaption"><a id="listing9-5">Listing 9-5</a>: Using <code>MaybeUninit</code> to safely initialize an array</p>
<p>While we could have declared <code>buf</code> as <code>[0; 4096]</code> instead, that would require the function to first write out all those zeros to the stack before executing, even if it’s going to overwrite them all again shortly thereafter. Normally that wouldn’t have a noticeable impact on performance, but if this was in a sufficiently hot loop, it might! Here, we instead allow the array to keep whatever values happened to be on the stack when the function was called, and then overwrite only what we end up needing.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Be careful with dropping partially initialized memory. If a panic causes an unexpected early drop before the <code>MaybeUninit&lt;T&gt;</code> has been fully initialized, you’ll have to take care to drop only the parts of <code>T</code> that are now valid, if any. You <em>can</em><em> </em>just drop the <code>MaybeUninit</code> and have the backing memory forgotten, but if it holds, say, a <code>Box</code>, you might end up with a memory leak!</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2--0006">Panics</h3>
<p class="BodyFirst">An important and often overlooked aspect of ensuring that code using unsafe operations is safe is that the code must also be prepared to handle panics. In particular, as we discussed briefly in <span class="xref" itemid="xref_target_Chapter 5">Chapter 5</span>, Rust’s default panic handler on most platforms will not crash your program on a panic but will instead <em>unwind</em> the current thread. An unwinding panic effectively drops everything in the current scope, returns from the current function, drops everything in the scope that enclosed the function, and so on, all the way down the stack until it hits the first stack frame for the current thread. If you don’t take unwinding into account in your unsafe code, you may be in for trouble. For example, consider the code in <a href="#listing9-6" id="listinganchor9-6">Listing 9-6</a>, which tries to efficiently push many values into a <code>Vec</code> at once.</p>
<pre><code>impl&lt;T: Default&gt; Vec&lt;T&gt; {
    pub fn fill_default(&amp;mut self) {
        let fill = self.capacity() - self.len();
        if fill == 0 { return; }
        let start = self.len();
        unsafe {
            self.set_len(start + fill);
<span epub:type="pagebreak" title="159" id="Page_159"/>            for i in 0..fill {
                *self.get_unchecked_mut(start + i) = T::default();
            }
        }
    }
}</code></pre>
<p class="CodeListingCaption"><a id="listing9-6">Listing 9-6</a>: A seemingly safe method for filling a vector with <code>Default</code> values</p>
<p>Consider what happens to this code if a call to <code>T::default</code> panics. First, <code>fill_default</code> will drop all its local values (which are just integers) and then return. The caller will then do the same. At some point up the stack, we get to the owner of the <code>Vec</code>. When the owner drops the vector, we have a problem: the length of the vector now indicates that we own more <code>T</code>s than we actually produced due to the call to <code>set_len</code>. For example, if the very first call to <code>T::default</code> panicked when we aimed to fill eight elements, that means <code>Vec::drop</code> will call <code>drop</code> on eight <code>T</code>s that actually contain uninitialized memory!</p>
<p>The fix in this case is simple: the code must update the length <em>after</em> writing all the elements. We wouldn’t have realized there was a problem if we didn’t carefully consider the effect of unwinding panics on the correctness of our unsafe code.</p>
<p>When you’re combing through your code for these kinds of problems, you’ll want to look out for any statements that may panic, and consider whether your code is safe if they do. Alternatively, check whether you can convince yourself that the code in question will never panic. Pay particular attention to anything that calls user-provided code—in those cases, you have no control over the panics and should assume that the user code will panic.</p>
<p>A similar situation arises when you use the <code>?</code> operator to return early from a function. If you do this, make sure that your code is still safe if it does not execute the remainder of the code in the function. It’s rarer for <code>?</code> to catch you off guard since you opted into it explicitly, but it’s worth keeping an eye out for.</p>
<h3 id="h2--0007">Casting</h3>
<p class="BodyFirst">As we discussed in <span class="xref" itemid="xref_target_Chapter 2">Chapter 2</span>, two different types that are both <code>#[repr(Rust)]</code> may be represented differently in memory even if they have fields of the same type and in the same order. This in turn means that it’s not always obvious whether it is safe to cast between two different types. In fact, Rust doesn’t even guarantee that two instances of a single type with generic arguments that are themselves laid out the same way are represented the same way. For example, in <a href="#listing9-7" id="listinganchor9-7">Listing 9-7</a>, <code>A</code> and <code>B</code> are not guaranteed to have the same in-memory representation.</p>
<pre><code>struct Foo&lt;T&gt; {
    one: bool,
    two: PhantomData&lt;T&gt;,
}
struct Bar;
struct Baz;
<span epub:type="pagebreak" title="160" id="Page_160"/>type A = Foo&lt;Bar&gt;;
type B = Foo&lt;Baz&gt;;</code></pre>
<p class="CodeListingCaption"><a id="listing9-7">Listing 9-7</a>: Type layout is not predictable.</p>
<p>The lack of guarantees for <code>repr(Rust)</code> is important to keep in mind when you do type casting in unsafe code—just because two types feel like they should be interchangeable, that is not necessarily the case. Casting between two types that have different representations is a quick path to undefined behavior. At the time of writing, the Rust community is actively working out the exact rules for how types are represented, but for now, very few guarantees are given, so that’s what we have to work with.</p>
<p>Even if identical types were guaranteed to have the same in-memory representation, you’d still run into the same problem when types are nested. For example, while <code>UnsafeCell&lt;T&gt;</code>, <code>MaybeUninit&lt;T&gt;</code>, and <code>T</code> all really just hold a <code>T</code>, and you can cast between them to your heart’s delight, that goes out the window once you have, for example, an <code>Option&lt;MaybeUninit&lt;T&gt;&gt;</code>. Though <code>Option&lt;T&gt;</code> may be able to take advantage of the niche optimization (using some invalid value of <code>T</code> to represent <code>None</code> for the <code>Option</code>), <code>MaybeUninit&lt;T&gt;</code> can hold any bit pattern, so that optimization does not apply, and an extra byte must be kept for the <code>Option</code> discriminator.</p>
<p>It’s not just optimizations that can cause layouts to diverge once wrapper types come into play. As an example, take the code in <a href="#listing9-8" id="listinganchor9-8">Listing 9-8</a>; here, the layout of <code>Wrapper&lt;PhantomData&lt;u8&gt;&gt;</code> and <code>Wrapper&lt;PhantomData&lt;i8&gt;&gt;</code> is completely different even though the provided types are both empty!</p>
<pre><code>struct Wrapper&lt;T: SneakyTrait&gt; {
    item: T::Sneaky,
    iter: PhantomData&lt;T&gt;,
}
trait SneakyTrait {
    type Sneaky;
}
impl SneakyTrait for PhantomData&lt;u8&gt; {
    type Sneaky = ();
}
impl SneakyTrait for PhantomData&lt;i8&gt; {
    type Sneaky = [u8; 1024];
}</code></pre>
<p class="CodeListingCaption"><a id="listing9-8">Listing 9-8</a>: Wrapper types make casting hard to get right.</p>
<p>All of this isn’t to say that you can never cast types in Rust. Things get a lot easier, for example, when you control all of the types involved and their trait implementations, or if types are <code>#[repr(C)]</code>. You just need to be aware that Rust gives very few guarantees about in-memory representations, and write your code accordingly!</p>
<h3 id="h2--0008">The Drop Check</h3>
<p class="BodyFirst">The Rust borrow checker is, in essence, a sophisticated tool for ensuring the soundness of code at compile time, which is in turn what gives Rust a <span epub:type="pagebreak" title="161" id="Page_161"/>way to express code being “safe.” How exactly the borrow checker does its job is beyond the scope of this book, but one check, the <em>drop check</em>, is worth going through in some detail since it has some direct implications for unsafe code. To understand drop checking, let’s put ourselves in the Rust compiler’s shoes for a second and look at two code snippets. First, take a look at the little three-liner in <a href="#listing9-9" id="listinganchor9-9">Listing 9-9</a> that takes a mutable reference to a variable and then mutates that same variable right after.</p>
<pre><code>let mut x = true;
let foo = Foo(&amp;mut x);
x = false;</code></pre>
<p class="CodeListingCaption"><a id="listing9-9">Listing 9-9</a>: The implementation of <code>Foo</code> dictates whether this code should compile</p>
<p>Without knowing the definition of <code>Foo</code>, can you say whether this code should compile or not? When we set <code>x = false</code>, there is still a <code>foo</code> hanging around that will be dropped at the end of the scope. We know that <code>foo</code> contains a mutable borrow of <code>x</code>, which would indicate that the mutable borrow that’s necessary to modify <code>x</code> is illegal. But what’s the harm in allowing it? It turns out that allowing the mutation of <code>x</code> is problematic only if <code>Foo</code> implements <code>Drop</code>—if <code>Foo</code> doesn’t implement <code>Drop</code>, then we know that <code>Foo</code> won’t touch the reference to <code>x</code> after its last use. Since that last use is before we need the exclusive reference for the assignment, we can allow the code! On the other hand, if <code>Foo</code> does implement <code>Drop</code>, we can’t allow this code, since the <code>Drop</code> implementation may use the reference to <code>x</code>.</p>
<p>Now that you’re warmed up, take a look at <a href="#listing9-10" id="listinganchor9-10">Listing 9-10</a>. In this not-so-straightforward code snippet, the mutable reference is buried even deeper.</p>
<pre><code>fn barify&lt;’a&gt;(_: &amp;’a mut i32) -&gt; Bar&lt;Foo&lt;’a&gt;&gt; { .. }
let mut x = true;
let foo = barify(&amp;mut x);
x = false;</code></pre>
<p class="CodeListingCaption"><a id="listing9-10">Listing 9-10</a>: The implementations of both <code>Foo</code> and <code>Bar</code> dictate whether this code should compile</p>
<p>Again, without knowing the definitions of <code>Foo</code> and <code>Bar</code>, can you say whether this code should compile or not? Let’s consider what happens if <code>Foo</code> implements <code>Drop</code> but <code>Bar</code> does not, since that’s the most interesting case. Usually, when a <code>Bar</code> goes out of scope, or otherwise gets dropped, it’ll still have to drop <code>Foo</code>, which in turn means that the code should be rejected for the same reason as before: <code>Foo::drop</code> might access the reference to <code>x</code>. However, <code>Bar</code> may not contain a <code>Foo</code> directly at all, but instead just a <code>PhantomData&lt;Foo&lt;'a&gt;&gt;</code> or a <code>&amp;'static Foo&lt;'a&gt;</code>, in which case the code is actually okay—even though the <code>Bar</code> is dropped, <code>Foo::drop</code> is never invoked, and the reference to <code>x</code> is never accessed. This is the kind of code we want the compiler to accept because a human will be able to identify that it’s okay, even if the compiler finds it difficult to detect that this is the case.</p>
<p>The logic we’ve just walked through is the drop check. Normally it doesn’t affect unsafe code too much as its default behavior matches user expectations, with one major exception: dangling generic parameters. <span epub:type="pagebreak" title="162" id="Page_162"/>Imagine that you’re implementing your own <code>Box&lt;T&gt;</code> type, and someone places a <code>&amp;mut x</code> into it as we did in <a href="#listing9-9">Listing 9-9</a>. Your <code>Box</code> type needs to implement <code>Drop</code> to free memory, but it doesn’t access <code>T</code> beyond dropping it. Since dropping a <code>&amp;mut</code> does nothing, it should be entirely fine for code to access <code>&amp;mut x</code> again after the last time the <code>Box</code> is accessed but before it’s dropped! To support types like this, Rust has an unstable feature called <code>dropck_eyepatch</code> (because it makes the drop check partially blind). The feature is likely to remain unstable forever and is intended to serve only as a temporary escape hatch until a proper mechanism is devised. The <code>dropck_eyepatch</code> feature adds a <code>#[may_dangle]</code> attribute, which you can add as a prefix for generic lifetimes and types in a type’s <code>Drop</code> implementation to tell the drop check machinery that you won’t use the annotated lifetime or type beyond dropping it. You use it by writing:</p>
<pre><code>unsafe impl&lt;#[may_dangle] T&gt; Drop for ..</code></pre>
<p>This escape hatch allows a type to declare that a given generic parameter isn’t used in <code>Drop</code>, which enables use cases like <code>Box&lt;&amp;mut T&gt;</code>. However, it also introduces a new problem if your <code>Box&lt;T&gt;</code> holds a raw heap pointer, <code>*mut T</code>, and allows <code>T</code> to dangle using <code>#[may_dangle]</code>. Specifically, the <code>*mut T</code> makes Rust’s drop check think that your <code>Box&lt;T&gt;</code> doesn’t own a <code>T</code>, and thus that it doesn’t call <code>T::drop</code> either. Combined with the <code>may_dangle</code> assertion that we don’t access <code>T</code> when the <code>Box&lt;T&gt;</code> is dropped, the drop check now concludes that it’s fine to have a <code>Box&lt;T&gt;</code> where the <code>T</code> doesn’t live until the <code>Box</code> is dropped (like our shortened <code>&amp;mut x</code> in <a href="#listing9-10">Listing 9-10</a>). But that’s not true, since we <em>do</em> call <code>T::drop</code>, which may itself access, say, a reference to said <code>x</code>.</p>
<p>Luckily, the fix is simple: we add a <code>PhantomData&lt;T&gt;</code> to tell the drop check that even though the <code>Box&lt;T&gt;</code> doesn’t hold any <code>T</code>, and won’t access <code>T</code> on drop, it does still own a <code>T</code> and will drop one when the <code>Box</code> is dropped. <a href="#listing9-11" id="listinganchor9-11">Listing 9-11</a> shows what our hypothetical <code>Box</code> type would look like.</p>
<pre><code>struct Box&lt;T&gt; {
  t: NonNull&lt;T&gt;, <span class="LiteralGray">// NonNull not *mut for covariance (Chapter 1)</span>
  _owned: PhantomData&lt;T&gt;, <span class="LiteralGray">// For drop check to realize we drop a T</span>
}
unsafe impl&lt;#[may_dangle] T&gt;  Drop for Box&lt;T&gt; { /* ... */ }</code></pre>
<p class="CodeListingCaption"><a id="listing9-11">Listing 9-11</a>: A definition for <code>Box</code> that is maximally flexible in terms of the drop check</p>
<p>This interaction is subtle and easy to miss, but it arises only when you use the unstable <code>#[may_dangle]</code> attribute. Hopefully this subsection will serve as a warning so that when you see <code>unsafe impl Drop</code> in the wild in the future, you’ll know to look for a <code>PhantomData&lt;T&gt;</code> as well!</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Another consideration for unsafe code concerning <code>Drop</code> is to make sure that you have a <code>Type&lt;T&gt;</code> that lets <code>T</code> continue to live after <code>self</code> is dropped. For example, if you’re implementing delayed garbage collection, you need to also add <code>T: 'static</code>. Otherwise, if <code>T = WriteOnDrop&lt;&amp;mut U&gt;</code>, the later access or drop of <code>T</code> could trigger undefined behavior!</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1--0004"><span epub:type="pagebreak" title="163" id="Page_163"/>Coping with Fear</h2>
<p class="BodyFirst">With this chapter mostly behind you, you may now be more afraid of unsafe code than you were before you started. While that is understandable, it’s important to stress that it’s not only <em>possible</em> to write safe unsafe code, but most of the time it’s not even that difficult. The key is to make sure that you handle unsafe code with care; that’s half the struggle. And be really sure that there isn’t a safe implementation you can use instead before resorting to <code>unsafe</code>.</p>
<p>In the remainder of this chapter, we’ll look at some techniques and tools that can help you be more confident in the correctness of your unsafe code when there’s no way around it.</p>
<h3 id="h2--0009">Manage Unsafe Boundaries</h3>
<p class="BodyFirst">It’s tempting to reason about unsafety <em>locally</em>; that is, to consider whether the code in the unsafe block you just wrote is safe without thinking too much about its interaction with the rest of the codebase. Unfortunately, that kind of local reasoning often comes back to bite you. A good example of this is the <code>Unpin</code> trait—you may write some code for your type that uses <code>Pin::new_unchecked</code> to produce a pinned reference to a field of the type, and that code may be entirely safe when you write it. But then at some later point in time, you (or someone else) might add a safe implementation of <code>Unpin</code> for said type, and suddenly the unsafe code is no longer safe, even though it’s nowhere near the new <code>impl</code>!</p>
<p>Safety is a property that can be checked only at the privacy boundary of all code that relates to the unsafe block. <em>Privacy boundary </em>here isn’t so much a formal term as an attempt at describing “any part of your code that can fiddle with the unsafe bits.” For example, if you declare a public type <code>Foo</code> in a module <code>bar</code> that is marked <code>pub</code> or <code>pub(crate)</code>, then any other code in the same crate can implement methods on and traits for <code>Foo</code>. So, if the safety of your unsafe code depends on <code>Foo</code> not implementing particular traits or methods with particular signatures, you need to remember to recheck the safety of that unsafe block any time you add an <code>impl</code> for <code>Foo</code>. If, on the other hand, <code>Foo</code> is not visible to the entire crate, then a much smaller set of scopes is able to add problematic implementations, and thus, the risk of accidentally adding an implementation that breaks the safety invariants goes down accordingly. If <code>Foo</code> is private, then only the current module and any submodules can add such implementations.</p>
<p>The same rule applies to access to fields: if the safety of an unsafe block depends on certain invariants over a type’s fields, then any code that can touch those fields (including safe code) falls within the privacy boundary of the unsafe block. Here, too, minimizing the privacy boundary is the best approach—code that cannot get to the fields cannot mess up your invariants!</p>
<p>Because unsafe code often requires this wide-reaching reasoning, it’s best practice to encapsulate the unsafety in your code as best you can. Provide the unsafety in the form of a single module, and strive to give that <span epub:type="pagebreak" title="164" id="Page_164"/>module an interface that is entirely safe. That way you only need to audit the internals of that module for your invariants. Or better yet, stick the unsafe bits in their own crate so that you can’t leave any holes open by accident!</p>
<p>It’s not always possible to fully encapsulate complex unsafe interactions to a single, safe interface, however. When that’s the case, try to narrow down the parts of the public interface that have to be unsafe so that you have only a very small number of them, give them names that clearly communicate that care is needed, and then document them rigorously.</p>
<p>It is sometimes tempting to remove the <code>unsafe</code> marker on internal APIs so that you don’t have to stick <code>unsafe {}</code> throughout your code. After all, inside your code you know never to invoke <code>frobnify</code> if you’ve previously called <code>bazzify</code>, right? Removing the <code>unsafe</code> annotation can lead to cleaner code but is usually a bad decision in the long run. A year from now, when your codebase has grown, you’ve paged out some of the safety invariants, and you “just want to hack together this one feature real quick,” chances are that you’ll inadvertently violate one of those invariants. And since you don’t have to type <code>unsafe</code>, you won’t even think to check. Plus, even if you never make mistakes, what about other contributors to your code? Ultimately, cleaner code is not a good enough argument to remove the intentionally noisy <code>unsafe</code> marker.</p>
<h3 id="h2--0010">Read and Write Documentation</h3>
<p class="BodyFirst">It goes without saying that if you write an unsafe function, you must document the conditions under which that function is safe to call. Here, both clarity and completeness are important. Don’t leave any invariants out, even if you’ve already written them somewhere else. If you have a type or module that requires certain global invariants—invariants that must always hold for all uses of the type—then remind the reader that they must also uphold the global invariants in every unsafe function’s documentation too. Developers often read documentation in an ad hoc, on-demand manner, so you can assume they have probably not read your carefully written module-level documentation and need to be given a nudge to do so.</p>
<p>What may be less obvious is that you should also document all unsafe implementations and blocks—think of this as providing proof that you do indeed uphold the contract the operation in question requires. For example, <code>slice::get_unchecked</code> requires that the provided index is within the bounds of the slice; when you call that method, put a comment just above it explaining how you know that the index is in fact guaranteed to be in bounds. In some cases, the invariants that the unsafe block requires are extensive, and your comments may get long. That’s a good thing. I have caught mistakes many times by trying to write the safety comment for an unsafe block and realizing halfway through that I actually don’t uphold a key invariant. You’ll also thank yourself a year down the road when you have to modify this code and ensure it’s still safe. And so will the contributor to your project who just stumbled across this unsafe call and wants to understand what’s going on.</p>
<p><span epub:type="pagebreak" title="165" id="Page_165"/>Before you get too deep into writing unsafe code, I also highly recommend that you go read the Rustonomicon (<a href="https://doc.rust-lang.org/nomicon/" class="LinkURL">https://doc.rust-lang.org/nomicon/</a>) cover to cover. There are so many details that are easy to miss, and will come back to bite you if you’re not aware of them. We’ve covered many of them in this chapter, but it never hurts to be more aware. You should also make liberal use of the Rust reference whenever you’re in doubt. It’s added to regularly, and chances are that if you’re even slightly unsure about whether some assumption you have is right, the reference will call it out. If it doesn’t, consider opening an issue so that it’ll be added!</p>
<h3 id="h2--0011">Check Your Work</h3>
<p class="BodyFirst">Okay, so you’ve written some unsafe code, you’ve double- and triple-checked all the invariants, and you think it’s ready to go. Before you put it into production, there are some automated tools that you should run your test suite through (you have a test suite, right?).</p>
<p>The first of these is Miri, the mid-level intermediate representation interpreter. Miri doesn’t compile your code into machine code but instead interprets the Rust code directly. This provides Miri with far more visibility into what your program is doing, which in turn allows it to check that your program doesn’t do anything obviously bad, like read from uninitialized memory. Miri can catch a lot of very subtle and Rust-specific bugs and is a lifesaver for anyone writing unsafe code.</p>
<p>Unfortunately, because Miri has to interpret the code to execute it, code run under Miri often runs orders of magnitude slower than its compiled counterpart. For that reason, Miri should really be used only to execute your test suite. It can also check only the code that actually runs, and thus won’t catch issues in code paths that your test suite doesn’t reach. You should think of Miri as an extension of your test suite, not a replacement for it.</p>
<p>There are also tools known as <em>sanitizers</em>, which instrument machine code to detect erroneous behavior at runtime. The overhead and fidelity of these tools vary greatly, but one widely loved tool is Google’s AddressSanitizer. It detects a large number of memory errors, such as use-after-free, buffer overflows, and memory leaks, all of which are common symptoms of incorrect unsafe code. Unlike Miri, these tools operate on machine code and thus tend to be fairly fast—usually within the same order of magnitude. But like Miri, they are constrained to analyzing the code that actually runs, so here too a solid test suite is vital.</p>
<p>The key to using these tools effectively is to automate them through your continuous integration pipeline so they’re run for every change, and to ensure that you add regression tests over time as you discover errors. The tools get better at catching problems as the quality of your test suite improves, so by incorporating new tests as you fix known bugs, you’re earning double points back, so to speak!</p>
<p>Finally, don’t forget to sprinkle assertions generously through unsafe code. A panic is always better than triggering undefined behavior! Check all of your assumptions with assertions if you can—even things like the size <span epub:type="pagebreak" title="166" id="Page_166"/>of a <code>usize</code> if you rely on that for safety. If you’re concerned about runtime cost, make use of the <code>debug_assert*</code> macros and the <code>if cfg!(debug_assertions) || cfg!(test)</code> construct to execute them only in debug and test contexts.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="box">
<h2>A House of Cards?</h2>
<p class="BoxBodyFirst">Unsafe code can violate all of Rust’s safety guarantees, and this is often touted as a reason why Rust’s whole safety argument is a charade. The concern is that it takes only one bit of incorrect unsafe code for the whole house to come crashing down and all safety to be lost. Proponents of this argument then sometimes argue that at the very least only unsafe code should be able to call unsafe code, so that the unsafety is visible all the way to the highest level of the application.</p>
<p>The argument is understandable—it is true that the safety of Rust code relies on the safety of all the transitive unsafe code it ends up invoking. And indeed, if some of that unsafe code is incorrect, it may have implications for the safety of the program overall. However, what this argument misses is that <em>all</em> successful safe languages provide a facility for language extensions that are not expressible in the (safe) surface language, usually in the form of code written in C or assembly. Just as Rust relies on the correctness of its unsafe code, the safety of those languages relies on the correctness of those extensions.</p>
<p>Rust is different in that it doesn’t have a separate extension language, but instead allows extensions to be written in what amounts to a dialect of Rust (unsafe Rust). This allows much closer integration between the safe and unsafe code, which in turn reduces the likelihood of errors due to impedance mismatches at the interface between the two, or due to developers being familiar with one but not the other. The closer integration also makes it easier to write tools that analyze the correctness of the unsafe code’s interaction with the safe code, as exemplified by tools like Miri. And since unsafe Rust continues to be subject to the borrow checker for any operation that isn’t explicitly unsafe, there remain many safety checks in place that aren’t present when developers must drop down to a language like C.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1--0005">Summary</h2>
<p class="BodyFirst">In this chapter, we’ve walked through the powers that come with the <code>unsafe</code> keyword and the responsibilities we accept by leveraging those powers. We also talked about the consequences of writing unsafe unsafe code, and how you really should be thinking about <code>unsafe</code> as a way to swear to the compiler that you’ve manually checked that the indicated code is still safe. In the next chapter, we’ll jump into concurrency in Rust and see how you can get all those cores on your shiny new computer to pull in the same direction!</p>
</section>
</div></body></html>