["```\n---\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: iperf-server\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: iperf-server\n  template:\n    metadata:\n      labels:\n        app: iperf-server\n    spec:\n   ➊ affinity:\n        podAntiAffinity:\n       ➋ requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - iperf-server\n         ➌ topologyKey: \"kubernetes.io/hostname\"\n containers:\n      - name: iperf\n        image: bookofkubernetes/iperf3:stable\n        env:\n        - name: IPERF_SERVER\n          value: \"1\"\n```", "```\nroot@host01:~# kubectl apply -f /opt/ipf-server.yaml \ndeployment.apps/iperf-server created\n```", "```\nroot@host01:~# kubectl get po -o wide\nNAME                            READY   STATUS    ... NODE     ...\niperf-server-7666fb76d8-7rz8j   1/1     Running   ... host01   ...\niperf-server-7666fb76d8-cljkh   1/1     Running   ... host02   ...\niperf-server-7666fb76d8-ktk92   1/1     Running   ... host03   ...\n```", "```\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: iperf-server\nspec:\n  selector:\n    app: iperf-server\n  ports:\n  - protocol: TCP\n    port: 5201\n    targetPort: 5201\n```", "```\nroot@host01:~# kubectl apply -f /opt/ipf-svc.yaml \nservice/iperf-server created\n```", "```\nroot@host01:~# kubectl get ep iperf-server\nNAME           ENDPOINTS                                                 ...\niperf-server   172.31.239.207:5201,172.31.25.214:5201,172.31.89.206:5201 ...\n```", "```\n---\nkind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: iperf\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: iperf\n  template:\n    metadata:\n      labels:\n app: iperf\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - iperf\n            topologyKey: \"kubernetes.io/hostname\"\n        ➊ podAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - iperf-server\n            topologyKey: \"kubernetes.io/hostname\"\n      containers:\n      - name: iperf\n        image: bookofkubernetes/iperf3:stable\n```", "```\nroot@host01:~# kubectl apply -f /opt/ipf-client.yaml \ndeployment.apps/iperf created\n```", "```\nroot@host01:~# kubectl get po -o wide\nNAME                            READY   STATUS    ... NODE     ... \niperf-c8d4566f-btppf            1/1     Running   ... host02   ... \niperf-c8d4566f-s6rpn            1/1     Running   ... host03   ... \niperf-c8d4566f-v9v8m            1/1     Running   ... host01   ... \n...\n```", "```\nroot@host01:~# kubectl logs iperf-c8d4566f-v9v8m\niperf3: error - the server is busy running a test. try again later\niperf3 error - exiting\n```", "```\nroot@host01:~# iptables-save | grep iperf-server\n...\n-A KUBE-SVC-KN2SIRYEH2IFQNHK -m comment --comment \"default/iperf-server\" \n  -m statistic --mode random --probability 0.33333333349 -j KUBE-SEP-IGBNNG5F5VCPRRWI\n-A KUBE-SVC-KN2SIRYEH2IFQNHK -m comment --comment \"default/iperf-server\" \n  -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-FDPADR4LUNHDJSPL\n-A KUBE-SVC-KN2SIRYEH2IFQNHK -m comment --comment \"default/iperf-server\" \n  -j KUBE-SEP-TZDPKVKUEZYBFM3V\n```", "```\nroot@host01:~# kubectl patch svc iperf-server -p '{\"spec\":{\"internalTrafficPolicy\":\"Local\"}}'\nservice/iperf-server patched\n```", "```\nroot@host01:~# iptables-save | grep iperf-server\n...\n-A KUBE-SVC-KN2SIRYEH2IFQNHK -m comment --comment \"default/iperf-server\" \\\n  -j KUBE-SEP-IGBNNG5F5VCPRRWI\n```", "```\nroot@host01:~# kubectl logs iperf-c8d4566f-btppf\nConnecting to host iperf-server, port 5201\n...\n[ ID] Interval           Transfer     Bitrate         Retr\n[  5]   0.00-10.00  sec  8.67 GBytes  7.45 Gbits/sec  1250             sender\n[  5]   0.00-10.00  sec  8.67 GBytes  7.45 Gbits/sec                  receiver\n...\n```", "```\nroot@host01:~# kubectl delete svc/iperf-server deploy/iperf deploy/iperf-server\nservice \"iperf-server\" deleted\ndeployment.apps \"iperf\" deleted\ndeployment.apps \"iperf-server\" deleted\n```", "```\n#!/bin/bash\n...\npatch='\n[\n  {\n    \"op\": \"add\", \n    \"path\": \"/status/capacity/bookofkubernetes.com~1special-hw\", \n    \"value\": \"3\"\n  }\n]\n'\ncurl --cacert $ca --cert $cert --key $key \\\n  -H \"Content-Type: application/json-patch+json\" \\\n  -X PATCH -d \"$patch\" \\\n  https://192.168.61.10:6443/api/v1/nodes/host02/status\n...\n```", "```\nroot@host01:~# /opt/add-hw.sh \n...\n```", "```\nroot@host01:~# kubectl get node host02 -o json | jq .status.capacity\n{\n  \"bookofkubernetes.com/special-hw\": \"3\",\n  \"cpu\": \"2\",\n  \"ephemeral-storage\": \"40593612Ki\",\n  \"hugepages-2Mi\": \"0\",\n  \"memory\": \"2035228Ki\",\n  \"pods\": \"110\"\n}\n```", "```\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sleep\nspec:\n  containers:\n  - name: sleep\n    image: busybox\n    command: [\"/bin/sleep\", \"infinity\"]\n    resources:\n      limits:\n        bookofkubernetes.com/special-hw: 1\n```", "```\nroot@host01:~# kubectl apply -f /opt/hw.yaml \npod/sleep created\n```", "```\nroot@host01:~# kubectl get po -o wide\nNAME    READY   STATUS    ... NODE     ...\nsleep   1/1     Running   ... host02   ...\n```", "```\nroot@host01:~# kubectl describe node host02\nName:               host02\n...\nAllocated resources:\n...\n  Resource                         Requests     Limits\n  --------                         --------     ------\n...\n  bookofkubernetes.com/special-hw  1            1\n...\n```", "```\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sleep3\nspec:\n  containers:\n  - name: sleep\n    image: busybox\n    command: [\"/bin/sleep\", \"infinity\"]\n    resources:\n limits:\n        bookofkubernetes.com/special-hw: 3\n```", "```\nroot@host01:~# kubectl apply -f /opt/hw3.yaml \npod/sleep created\n```", "```\nroot@host01:~# kubectl get po -o wide\nNAME    READY   STATUS    ... NODE     ...\nsleep   1/1     Running   ... host02   ...\nsleep3  0/1     Pending   ... <none>   ...\n```", "```\nroot@host01:~# kubectl delete pod sleep \npod/sleep deleted\n```", "```\nroot@host01:~# kubectl get po -o wide\nNAME    READY   STATUS    ... NODE     ...\nsleep3  1/1     Running   ... host02   ...\n```"]