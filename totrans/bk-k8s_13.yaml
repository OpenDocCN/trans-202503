- en: '11'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '11'
- en: CONTROL PLANE AND ACCESS CONTROL
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面和访问控制
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/common01.jpg)'
- en: The control plane manages the Kubernetes cluster, storing the desired state
    of applications, monitoring the current state to detect and recover from any issues,
    scheduling new containers, and configuring network routing. In this chapter, we’ll
    look closely at the API server, the primary interface for the control plane and
    the entry point for any status retrieval and changes made to the entire cluster.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面管理 Kubernetes 集群，存储应用程序的期望状态，监视当前状态以检测和恢复任何问题，调度新容器，并配置网络路由。在本章中，我们将仔细研究
    API 服务器，这是控制平面的主要接口，也是检索任何状态和对整个集群进行更改的入口点。
- en: 'Although we will focus on the API server, the control plane includes multiple
    other services, each with a role to play. The other control plane services act
    as clients to the API server, watching cluster changes and taking appropriate
    action to update the state of the cluster. The following list describes the other
    control plane components:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们将重点放在 API 服务器上，但控制平面包括多个其他服务，每个服务都有各自的角色。其他控制平面服务作为 API 服务器的客户端，监视集群变化，并采取适当措施来更新集群的状态。以下列表描述了其他控制平面组件：
- en: '**Scheduler** Assigns each new Pod to a node.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**调度程序** 将每个新 Pod 分配给一个节点。'
- en: '**Controller manager** Has multiple responsibilities, including creating Pods
    for Deployments, monitoring nodes, and reacting to outages.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**控制器管理器** 具有多种责任，包括为部署创建 Pod、监视节点并对故障做出反应。'
- en: '**Cloud controller manager** This optional component interfaces with an underlying
    cloud provider to check on nodes and configure network traffic routing.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**云控制器管理器** 这是一个可选组件，与底层云提供程序接口，检查节点并配置网络流量路由。'
- en: As we demonstrate the workings of the API server, we’ll also see how Kubernetes
    manages security to ensure that only authorized users and services can query the
    cluster and make changes. The purpose of a container orchestration environment
    like Kubernetes is to provide a platform for any kind of containerized application
    we might need to run, so this security is critically important to ensure that
    the cluster is used only as intended.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们演示 API 服务器的工作原理时，我们还将看到 Kubernetes 如何管理安全性，以确保只有授权的用户和服务可以查询集群并进行更改。像 Kubernetes
    这样的容器编排环境的目的是为我们可能需要运行的任何类型的容器化应用程序提供平台，因此这种安全性至关重要，以确保集群仅按预期使用。
- en: API Server
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API 服务器
- en: Despite its centrality to the Kubernetes architecture, the API server’s purpose
    is simple. It exposes an interface using HTTP and representational state transfer
    (REST) to perform basic creation, retrieval, update, and deletion of resources
    in the cluster. It performs authentication to identify clients, authorization
    to ensure that clients have permission for the specific request, and validation
    to ensure that any created or updated resources match the corresponding specification.
    It also reads from and writes to a data store based on the commands it receives
    from clients.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它在 Kubernetes 架构中的核心地位，API 服务器的目的很简单。它使用 HTTP 和表征状态转移（REST）暴露接口，用于执行集群中资源的基本创建、检索、更新和删除。它执行身份验证以识别客户端，授权以确保客户端对特定请求有权限，并验证以确保任何创建或更新的资源与相应的规范匹配。它还根据从客户端接收到的命令读取和写入数据存储。
- en: However, the API server is not responsible for actually updating the current
    state of the cluster to match the desired state. That is the responsibility of
    other control plane and node components. For example, if a client creates a new
    Kubernetes Deployment, the API server’s job is solely to update the data store
    with the resource information. It is then the job of the scheduler to decide where
    the Pods will run, and the job of the `kubelet` service on the assigned nodes
    to create and monitor the containers and to configure networking to route traffic
    to the containers.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，API 服务器并不负责实际更新集群的当前状态以匹配期望状态。这是其他控制平面和节点组件的责任。例如，如果客户端创建一个新的 Kubernetes
    部署，API 服务器的工作仅仅是更新数据存储中的资源信息。然后，调度程序负责决定 Pod 将在哪里运行，分配给节点上的 kubelet 服务负责创建和监视容器，并配置网络以将流量路由到容器。
- en: For this chapter, we have a three-node Kubernetes cluster configured by our
    automation scripts. Each of the three nodes acts as a control plane node, so three
    copies of the API server are running. We can communicate with any of these three
    because they all share the same backend database. The API server is listening
    for secure HTTP connections on port 6443, the default port.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们有一个由自动化脚本配置的三节点Kubernetes集群。三台节点都充当控制平面节点，因此有三份API服务器在运行。我们可以与其中任意一台进行通信，因为它们共享同一个后端数据库。API服务器正在端口6443上监听安全HTTP连接，这是默认端口。
- en: '**NOTE**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*The example repository for this book is at* [https://github.com/book-of-kubernetes/examples](https://github.com/book-of-kubernetes/examples).
    *See “Running Examples” on [page xx](ch00.xhtml#ch00lev1sec2) for details on getting
    set up.*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*本书的示例仓库位于* [https://github.com/book-of-kubernetes/examples](https://github.com/book-of-kubernetes/examples)。*有关设置的详细信息，请参见[第xx页](ch00.xhtml#ch00lev1sec2)中的“运行示例”。*'
- en: We’ve been using `kubectl` to communicate with the API server to create and
    delete resources and retrieve status, and `kubectl` has been using secure HTTP
    on port 6443 to talk to the cluster. It knows to do this because of a Kubernetes
    configuration file that was installed into */etc/kubernetes* by `kubeadm` when
    the cluster was initialized. This configuration file also contains authentication
    information that gives us permission to read cluster status and make changes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在使用`kubectl`与API服务器通信，创建和删除资源并获取状态，且`kubectl`一直通过端口6443使用安全HTTP与集群通信。它之所以这样做，是因为在集群初始化时，`kubeadm`将一个Kubernetes配置文件安装到*/etc/kubernetes*中。这个配置文件还包含认证信息，使我们能够读取集群状态并进行更改。
- en: 'Because the API server is expecting secure HTTP, we can use `curl` to communicate
    directly with the Kubernetes API. This will give us a better feel for how the
    communication actually works. Let’s begin with a simple `curl` command:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因为API服务器期待安全HTTP连接，我们可以使用`curl`直接与Kubernetes API通信。这将帮助我们更好地理解通信是如何工作的。我们从一个简单的`curl`命令开始：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This error message shows that `curl` does not trust the certificate that the
    API server is offering. We can use `curl` to see this certificate:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个错误信息表明`curl`不信任API服务器提供的证书。我们可以使用`curl`查看这个证书：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `-k` option tells `curl` to ignore any certificate issues, whereas `-v`
    tells `curl` to provide us with extra logging information about the connection.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`-k`选项告诉`curl`忽略任何证书问题，而`-v`选项则告诉`curl`提供更多的连接日志信息。'
- en: 'For `curl` to trust this certificate, it will need to trust the `issuer`, as
    the issuer is the signer of the certificate. Let’s fetch the certificate from
    our Kubernetes installation so that we can point `curl` to it:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让`curl`信任这个证书，它需要信任`issuer`，因为issuer是证书的签署者。我们来从Kubernetes安装中提取证书，这样我们就可以将`curl`指向它：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Be sure to add the `.` at the end to copy this file to the current directory.
    We’re doing this solely to make the following commands easier to type.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在文件名末尾加上`.`，将该文件复制到当前目录。我们这么做完全是为了方便后面命令的输入。
- en: 'Let’s examine this certificate before we use it:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用证书之前，让我们先查看一下它：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `Issuer` and the `Subject` are the same, so this is a *self-signed* certificate.
    It was created by `kubeadm` when we initialized this cluster. Using a generated
    certificate allows `kubeadm` to adapt to our particular cluster networking configuration
    and allows our cluster to have a unique certificate and key without requiring
    an external certificate authority (CA). However, it does mean that we need to
    configure `kubectl` to trust this certificate on any system for which we need
    to communicate with this API server.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`Issuer`和`Subject`是相同的，因此这是一个*自签名*证书。它是通过`kubeadm`在初始化集群时创建的。使用生成的证书使得`kubeadm`能够适应我们特定的集群网络配置，并且允许我们的集群拥有唯一的证书和密钥，而无需外部证书机构（CA）。然而，这意味着我们需要配置`kubectl`以信任此证书，以便在任何需要与API服务器通信的系统上使用。'
- en: 'We can now tell `curl` to use this certificate to verify the API server:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以告诉`curl`使用这个证书来验证API服务器：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now that we’re providing `curl` with the correct root certificate, `curl` can
    validate the API server certificate and we can successfully connect to the API
    server. However, the API server responds with a 403 error, indicating that we
    are not authorized. This is because at the moment we are not providing any authentication
    information for `curl` to pass to the API server, so the API server sees us as
    an anonymous user.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为 `curl` 提供了正确的根证书，`curl` 可以验证 API 服务器证书，我们也能成功连接到 API 服务器。然而，API 服务器返回403错误，表示我们没有授权。这是因为目前我们没有为
    `curl` 提供任何身份验证信息，导致 API 服务器将我们视为匿名用户。
- en: 'One final note: for this `curl` command to work, we need to be selective in
    the hostname or IP address we use. The API server is listening on all network
    interfaces, so we could connect to it using `localhost` or `127.0.0.1`. However,
    those are not listed in the `kube-apiserver` certificate and cannot be used for
    secure HTTP because `curl` will not trust the connection.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点：为了使此 `curl` 命令生效，我们需要选择性地使用主机名或 IP 地址。API 服务器监听所有网络接口，因此我们可以使用 `localhost`
    或 `127.0.0.1` 连接它。然而，这些并未列在 `kube-apiserver` 证书中，且由于 `curl` 不会信任连接，因此无法用于安全的 HTTP。
- en: API Server Authentication
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API 服务器身份验证
- en: We need to provide authentication information before the API server will accept
    our requests, so let’s understand the API server’s process for authentication.
    Authentication is handled through a set of plug-ins, each of which looks at the
    request to determine whether it can identify the client. The first plug-in that
    successfully identifies the client provides identity information to the API server.
    This identity is then used with authorization to determine what the client is
    allowed to do.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要提供身份验证信息，API 服务器才会接受我们的请求，因此让我们了解一下 API 服务器的身份验证过程。身份验证是通过一组插件来处理的，每个插件会查看请求，以确定它是否能够识别客户端。第一个成功识别客户端的插件将身份信息提供给
    API 服务器。然后，这个身份与授权一起使用，以确定客户端被允许执行的操作。
- en: Because authentication is based on plug-ins, it’s possible to have as many different
    ways of authenticating clients as needed. It’s even possible to add a proxy in
    front of the API server that performs custom authentication logic and passes the
    user’s identity to the API server in an HTTP header.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由于身份验证是基于插件的，因此可以根据需要使用多种不同的客户端身份验证方式。甚至可以在 API 服务器前添加一个代理，执行自定义身份验证逻辑，并通过 HTTP
    头将用户的身份传递给 API 服务器。
- en: 'For our purposes, we’ll focus on three authentication primary plug-ins that
    are used within the cluster itself or as part of the cluster setup process: *client
    certificates*, *bootstrap tokens*, and *service accounts*.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的，我们将关注集群内部或集群设置过程中使用的三种主要身份验证插件：*客户端证书*、*启动令牌* 和 *服务账户*。
- en: Client Certificates
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 客户端证书
- en: As mentioned previously, an HTTP client like `curl` validates the server’s identity
    by comparing the server’s hostname to its certificate and also by checking the
    certificate’s signature against a list of trusted CAs. In addition to checking
    the server identity, secure HTTP also allows a client to submit a certificate
    to the server. The server checks the signature against its list of trusted authorities
    and then uses the subject of the certificate as the client’s identity.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，像 `curl` 这样的 HTTP 客户端通过将服务器的主机名与其证书进行比较，来验证服务器的身份，同时还会检查证书的签名是否与受信任的 CA
    列表一致。除了检查服务器身份外，安全的 HTTP 还允许客户端向服务器提交证书。服务器将签名与其受信任的机构列表进行比对，然后使用证书的主题作为客户端的身份。
- en: 'Kubernetes uses HTTP client certificate authentication extensively to enable
    cluster services to authenticate with the API server. This includes control plane
    components as well as the `kubelet` service running on each node. We can use `kubeadm`
    to list the certificates used by the control plane:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 广泛使用 HTTP 客户端证书身份验证，以便集群服务能够与 API 服务器进行身份验证。这包括控制平面组件以及每个节点上运行的 `kubelet`
    服务。我们可以使用 `kubeadm` 列出控制平面使用的证书：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `RESIDUAL TIME` column shows how much time is left before these certificates
    expire; by default, they expire after one year. Use `kubeadm certs renew` to renew
    them, passing the name of the certificate as a parameter.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`RESIDUAL TIME` 列显示证书过期前剩余的时间；默认情况下，它们在一年后过期。使用 `kubeadm certs renew` 来续订证书，传递证书的名称作为参数。'
- en: 'The first item in the list, `admin.conf`, is how we’ve been authenticating
    ourselves to the cluster in the past few chapters. During initialization, `kubeadm`
    created this certificate and stored its information in the */etc/kubernetes/admin.conf*
    file. Every `kubectl` command we’ve run has been using this file because our automation
    scripts are setting the `KUBECONFIG` environment variable:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 列表中的第一个项目 `admin.conf` 是我们在过去几章中用于验证自己身份的方式。在初始化过程中，`kubeadm` 创建了这个证书，并将其信息存储在
    */etc/kubernetes/admin.conf* 文件中。我们运行的每个 `kubectl` 命令都在使用这个文件，因为我们的自动化脚本设置了 `KUBECONFIG`
    环境变量：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If we had not set `KUBECONFIG`, `kubectl` would be using the default, which
    is a file called *.kube/config* in the user’s home directory.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有设置 `KUBECONFIG`，`kubectl` 将使用默认文件，即用户主目录下的 *.kube/config* 文件。
- en: The *admin.conf* credentials are designed to provide emergency access to the
    cluster, bypassing authorization. In a production cluster, we would avoid using
    these credentials directly for everyday operations. Instead, the best practice
    for a production cluster is to integrate a separate identity manager for administrators
    and normal users. For our example, because we don’t have a separate identity manager,
    we’ll instead create an additional certificate for a regular user. This kind of
    certificate may be useful for an automated process that runs outside the cluster,
    but it can’t integrate with the identity manager.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*admin.conf* 凭据旨在提供紧急访问集群的权限，绕过授权。在生产集群中，我们会避免直接使用这些凭据进行日常操作。相反，生产集群的最佳做法是为管理员和普通用户集成一个单独的身份管理器。对于我们的示例，由于没有单独的身份管理器，我们将为普通用户创建一个额外的证书。这种证书可能对在集群外部运行的自动化进程有用，但它无法与身份管理器集成。'
- en: 'We can create a new client certificate using `kubeadm`:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `kubeadm` 创建一个新的客户端证书：
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `kubeadm kubeconfig user` command asks the API server to generate a new
    client certificate. Because this certificate is signed by the cluster’s CA, it
    is valid for authentication. The certificate is saved into the *kubeconfig* file
    along with the necessary configuration to connect to the API server:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubeadm kubeconfig user` 命令请求 API 服务器生成一个新的客户端证书。由于这个证书是由集群的 CA 签名的，因此它可以用于身份验证。证书与连接
    API 服务器所需的配置一起保存在 *kubeconfig* 文件中：'
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `clusters` section defines the information needed to connect to the API
    server, including the load-balanced address shared by all three API servers in
    our highly available configuration. The `users` section defines the new user we
    created along with its client certificate.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`clusters` 部分定义了连接到 API 服务器所需的信息，包括在我们高可用配置中，所有三个 API 服务器共享的负载均衡地址。`users`
    部分定义了我们创建的新用户及其客户端证书。'
- en: 'Thus far, we’ve successfully created a new user, but we haven’t given that
    user any permissions yet, so we won’t be very successful using these credentials:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们成功创建了一个新用户，但尚未赋予该用户任何权限，因此我们用这些凭据的操作不会非常成功：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Later in the chapter, we’ll see how to give permissions to this user.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 本章稍后我们将看到如何为这个用户授予权限。
- en: Bootstrap Tokens
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 引导令牌
- en: Initializing a distributed system like a Kubernetes cluster is challenging.
    The `kubelet` service running on each node must be added to the cluster. To do
    this, `kubelet` must connect to the API server and obtain a client certificate
    signed by the cluster’s CA. The `kubelet` service then uses this client certificate
    to authenticate to the cluster.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化一个分布式系统，如 Kubernetes 集群，是一项具有挑战性的任务。每个节点上运行的 `kubelet` 服务必须被添加到集群中。为此，`kubelet`
    必须连接到 API 服务器并获取由集群的 CA 签名的客户端证书。然后，`kubelet` 服务使用该客户端证书进行集群认证。
- en: This certificate generation must be done securely so that we eliminate the possibility
    of adding rogue nodes to the cluster and eliminate the possibility of a rogue
    process being able to impersonate a real node. For this reason, the API server
    cannot provide a certificate for just any node that asks to be added to the cluster.
    Instead, the node must generate its own private key, submit a certificate signing
    request (CSR) to the API server, and receive a signed certificate.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 证书的生成必须安全进行，以消除将恶意节点添加到集群的可能性，并防止恶意进程冒充真实节点。因此，API 服务器不能为任何请求加入集群的节点提供证书。相反，节点必须生成自己的私钥，向
    API 服务器提交证书签名请求（CSR），并接收签名证书。
- en: To keep this process secure, we need to ensure that a node is authorized to
    submit a certificate signing request. But this submission must happen before the
    node has the client certificate that it uses for more permanent authentication—we
    have a chicken-or-egg problem! Kubernetes solves this via time-limited tokens,
    known as *Bootstrap Tokens*. The bootstrap token becomes a preshared secret that
    is known to the API server and the new nodes. Making this token time limited reduces
    the risk to the cluster if it is exposed. The Kubernetes controller manager has
    the task of automatically cleaning up bootstrap tokens when they expire.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保这个过程的安全性，我们需要确保一个节点被授权提交证书签名请求。但这个提交必须在节点获得用于更长期身份验证的客户端证书之前进行——我们面临一个先有鸡还是先有蛋的问题！Kubernetes
    通过时间限制令牌来解决这个问题，这些令牌被称为*引导令牌*。引导令牌成为一个预共享的秘密，API 服务器和新节点都知道它。使这个令牌具有时间限制可以降低它暴露时对集群的风险。Kubernetes
    控制器管理器负责在引导令牌过期时自动清理它们。
- en: 'When we initialized our cluster, `kubeadm` created a bootstrap token, but it
    was configured to expire after two hours. If we need to join additional nodes
    to the cluster after that, we can use `kubeadm` to generate a new bootstrap token:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们初始化集群时，`kubeadm` 创建了一个引导令牌，但它配置为两小时后过期。如果我们在此之后需要将额外的节点加入集群，我们可以使用 `kubeadm`
    生成一个新的引导令牌：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This token is added as a Kubernetes *Secret* in the `kube-system` Namespace.
    We look at secrets in more detail in [Chapter 16](ch16.xhtml#ch16). For now, let’s
    just verify that it exists:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个令牌作为 Kubernetes *Secret* 被添加到`kube-system`命名空间。我们将在[第 16 章](ch16.xhtml#ch16)中更详细地讨论
    Secrets。现在，我们只需要验证它是否存在：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can use this token to make requests of the API server by using HTTP Bearer
    authentication. This means that we provide the token in an HTTP header called
    `Authorization`, prefaced with the word `Bearer`. When the bootstrap token authentication
    plug-in sees that header and matches the provided token against the corresponding
    secret, it authenticates us to the API server and allows us access to the API.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个令牌通过 HTTP Bearer 身份验证向 API 服务器发出请求。这意味着我们在 HTTP 头中提供令牌，头部的名称为`Authorization`，并以`Bearer`为前缀。当引导令牌认证插件看到该头并将提供的令牌与相应的密钥进行匹配时，它会验证我们的身份并允许我们访问
    API。
- en: For security reasons, bootstrap tokens have access only to the certificate signing
    request functionality of the API server, so that’s all our token will be allowed
    to do.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 出于安全原因，引导令牌仅能访问 API 服务器的证书签名请求功能，因此我们的令牌只能执行这个操作。
- en: 'Let’s use our bootstrap token to list all of the certificate signing requests:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用引导令牌列出所有证书签名请求：
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: It’s important to know how bootstrap tokens work, given that they’re essential
    to adding nodes to the cluster. However, as the name implies, that’s really the
    only purpose for a bootstrap token; it’s not typical to use them for normal API
    server access. For normal API server access, especially from inside the cluster,
    we need a *ServiceAccount*.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 了解引导令牌的工作原理非常重要，因为它们对于将节点添加到集群至关重要。然而，正如其名称所示，引导令牌实际上只有这个目的；通常不会用于正常的 API 服务器访问。对于正常的
    API 服务器访问，尤其是在集群内部，我们需要一个*服务账户*。
- en: Service Accounts
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 服务账户
- en: Containers running in the Kubernetes cluster often need to communicate with
    the API server. For example, all of the various components we deployed on top
    of our cluster in [Chapter 6](ch06.xhtml#ch06), including the Calico network plug-in,
    the Longhorn storage driver, and the metrics server, communicate with the API
    server to watch and modify the cluster state. To support this, Kubernetes automatically
    injects credentials into every running container.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 集群中运行的容器通常需要与 API 服务器进行通信。例如，在我们在[第 6 章](ch06.xhtml#ch06)中部署的所有组件，包括
    Calico 网络插件、Longhorn 存储驱动程序和指标服务器，都会与 API 服务器通信，以观察和修改集群状态。为了支持这一点，Kubernetes
    会自动将凭证注入每个运行中的容器。
- en: Of course, for security reasons, giving each container only the API server permissions
    it requires is important, so we should create a separate ServiceAccount for each
    application or cluster component to do that. The information for these ServiceAccounts
    is then added to the Deployment or other controller so that Kubernetes will inject
    the correct credentials. In some cases, we may use multiple ServiceAccount with
    a single application, restricting each application component to only the access
    it needs.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，出于安全原因，仅授予每个容器所需的 API 服务器权限非常重要，因此我们应该为每个应用或集群组件创建一个单独的 ServiceAccount。然后，将这些
    ServiceAccount 的信息添加到 Deployment 或其他控制器中，以便 Kubernetes 会注入正确的凭据。在某些情况下，我们可能会为一个应用使用多个
    ServiceAccount，限制每个应用组件只能访问其所需的权限。
- en: 'In addition to using a separate ServiceAccount per application or component,
    it’s also good practice to use a separate Namespace per application. As we’ll
    see in a moment, permissions can be limited to a single Namespace. Let’s start
    by creating the Namespace:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 除了为每个应用或组件使用单独的 ServiceAccount 外，最好为每个应用使用单独的命名空间。正如我们稍后将看到的，权限可以限制在单一命名空间内。让我们首先创建命名空间：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'A ServiceAccount uses a bearer token, which is stored in a secret automatically
    generated by Kubernetes when the ServiceAccount is created. Let’s make a ServiceAccount
    for a Deployment that we’ll create in this chapter:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ServiceAccount 使用承载令牌，该令牌存储在 Kubernetes 创建 ServiceAccount 时自动生成的 Secret 中。让我们为本章中将要创建的
    Deployment 创建一个 ServiceAccount：
- en: '*read-pods-sa.yaml*'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*read-pods-sa.yaml*'
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Note that we use the metadata to place this ServiceAccount in the `sample`
    Namespace we just created. We could also use the `-n` flag with `kubectl` to specify
    the Namespace. We’ll use the usual `kubectl apply` to create this ServiceAccount:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们使用元数据将这个 ServiceAccount 放入我们刚刚创建的`sample`命名空间中。我们也可以使用 `-n` 标志与 `kubectl`
    一起指定命名空间。我们将使用常规的 `kubectl apply` 来创建这个 ServiceAccount：
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'When the ServiceAccount is created, the controller manager detects this and
    automatically creates a Secret with the credentials:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建 ServiceAccount 时，控制器管理器会检测到这一点，并自动创建一个包含凭证的 Secret：
- en: '[PRE16]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note that in addition to the `read-pods` ServiceAccount we just created, there
    is already a `default` ServiceAccount. This account was created automatically
    when the Namespace was created; it will be used if we don’t specify to Kubernetes
    which ServiceAccount to use for a Pod.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，除了我们刚刚创建的`read-pods` ServiceAccount外，还有一个已经存在的`default` ServiceAccount。这个账户是在创建命名空间时自动创建的；如果我们没有指定使用哪个
    ServiceAccount 来为 Pod 提供服务，Kubernetes 将使用它。
- en: The newly created ServiceAccount does not have any permissions yet. To start
    adding permissions, we need to take a look at *role-based access control* (RBAC).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 新创建的 ServiceAccount 还没有任何权限。为了开始添加权限，我们需要了解一下 *基于角色的访问控制*（RBAC）。
- en: Role-Based Access Controls
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于角色的访问控制
- en: After the API server has found an authentication plug-in that can identify the
    client, it uses the identity to determine whether the client has permissions to
    perform the desired action, which is done by assembling a list of roles that belong
    to the user. Roles can be associated directly with a user or with a group in which
    the user is a member. Group membership is part of the identity. For example, client
    certificates can specify a user’s groups by including organization fields as part
    of the certificate’s subject.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 API 服务器找到能够识别客户端的认证插件之后，它会使用该身份来判断客户端是否有权限执行所需的操作，这通过组合属于用户的角色列表来完成。角色可以直接与用户关联，也可以与用户所在的组关联。组成员资格是身份的一部分。例如，客户端证书可以通过在证书主题中包含组织字段来指定用户的组。
- en: Roles and Cluster Roles
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 角色和集群角色
- en: Each role has a set of permissions. A permission allows a client to perform
    one or more actions on one or more types of resources.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 每个角色都有一组权限。权限允许客户端对一种或多种资源类型执行一个或多个操作。
- en: 'As an example, let’s define a role that will give a client permission to read
    Pod status. We have two choices: we can create a *Role* or a *ClusterRole*. A
    Role is visible and usable within a single Namespace, whereas a ClusterRole is
    visible and usable across all Namespaces. This difference allows administrators
    to define common roles across the cluster that are immediately available when
    new Namespaces are created, while also allowing the delegation of access control
    for a specific Namespace.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，让我们定义一个角色，授予客户端读取Pod状态的权限。我们有两个选择：可以创建一个*Role*或*ClusterRole*。Role仅在单个命名空间内可见和可用，而ClusterRole在所有命名空间中都可见和可用。这一差异允许管理员在整个集群中定义通用角色，这些角色在新命名空间创建时立即可用，同时也允许为特定命名空间委派访问控制。
- en: 'Here’s an example definition of a ClusterRole. This role only has the ability
    to read data about Pods; it cannot change Pods or access any other cluster information:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是ClusterRole的示例定义。该角色仅具备读取Pods数据的权限；不能修改Pods或访问其他集群信息：
- en: '*pod-reader.yaml*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*pod-reader.yaml*'
- en: '[PRE17]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Because this is a cluster-wide role, it doesn’t make sense to assign it to a
    Namespace, so we don’t specify one.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这是一个集群范围的角色，将其分配给某个命名空间是没有意义的，因此我们不指定命名空间。
- en: The critical part of this definition is the list of rules. Each ClusterRole
    or Role can have as many rules as necessary. Each rule has a list of `verbs` that
    define what actions are allowed. In this case, we identified `get`, `watch`, and
    `list` as the verbs, with the effect that the role allows reading Pods but not
    any actions that would modify them.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义的关键部分是规则列表。每个ClusterRole或Role可以有任意数量的规则。每条规则都有一组`verbs`，定义了允许的操作。在此案例中，我们将`get`、`watch`和`list`作为动词，这意味着该角色允许读取Pods，但不允许进行任何修改操作。
- en: 'Each rule applies to one or more resource types, based on the combination of
    `apiGroups` and `resources` identified. Each rule gives permissions for the actions
    listed as `verbs`. In this case, the empty string `""` is used to refer to the
    default API group, which is where Pods are located. If we wanted to also include
    Deployments and StatefulSets, we would need to define our rule as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 每条规则适用于一个或多个资源类型，这取决于`apiGroups`和`resources`的组合。每条规则为列出的`verbs`（动词）操作提供权限。在这种情况下，空字符串`""`用于引用默认的API组，即Pods所在的地方。如果我们想要同时包括Deployments和StatefulSets，我们需要将规则定义如下：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We need to add `"apps"` to the `apiGroups` field because Deployment and StatefulSet
    are part of that group (as identified in the `apiVersion` when we declare the
    resource). When we declare a Role or ClusterRole, the API server will accept any
    strings in the `apiGroups` and `resources` fields, regardless of whether the combination
    actually identifies any resource types, so it’s important to pay attention to
    which group a resource is in.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将`"apps"`添加到`apiGroups`字段中，因为Deployment和StatefulSet属于该组（在声明资源时，可以在`apiVersion`中识别）。当我们声明Role或ClusterRole时，API服务器会接受`apiGroups`和`resources`字段中的任何字符串，无论该组合是否确实识别出任何资源类型，因此，必须注意资源属于哪个组。
- en: 'Let’s define our `pod-reader` ClusterRole:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义我们的`pod-reader` ClusterRole：
- en: '[PRE19]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now that the ClusterRole exists, we can apply it. To do that, we need to create
    a role binding.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在ClusterRole已经存在，我们可以应用它。为此，我们需要创建一个角色绑定。
- en: Role Bindings and Cluster Role Bindings
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 角色绑定和集群角色绑定
- en: 'Let’s apply this `pod-reader` ClusterRole to the `read-pods` ServiceAccount
    we created earlier. We have two options: we can create a *RoleBinding*, which
    will assign the permissions in a specific Namespace, or a *ClusterRoleBinding*,
    which will assign the permissions across all Namespaces. This feature is beneficial
    because it means we can create a ClusterRole such as `pod-reader` once and have
    it visible across the cluster, but create the binding in an individual Namespace
    so that users and ServiceAccount are restricted to only the Namespaces they should
    be allowed to access. This helps us apply the pattern we saw earlier of having
    a Namespace per application, while at the same time it keeps non-administrators
    away from key infrastructure components such as the components running in the
    `kube-system` Namespace.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个`pod-reader` ClusterRole应用到我们之前创建的`read-pods` ServiceAccount。我们有两个选择：可以创建一个*RoleBinding*，它会将权限分配到特定的命名空间，或者创建一个*ClusterRoleBinding*，它会将权限分配到所有命名空间。这一特性非常有用，因为它意味着我们可以创建一个像`pod-reader`这样的ClusterRole，并使其在整个集群中可见，但只在特定命名空间内创建绑定，以便用户和ServiceAccount仅能访问他们被允许访问的命名空间。这帮助我们应用之前提到的每个应用有一个命名空间的模式，同时确保非管理员用户无法接触到关键的基础设施组件，如在`kube-system`命名空间中运行的组件。
- en: 'In keeping with this practice, we’ll create a RoleBinding so that our ServiceAccount
    has permissions to read Pods only in the `sample` Namespace:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这个做法，我们将创建一个 RoleBinding，以便我们的 ServiceAccount 仅有权在 `sample` 命名空间中读取 Pods：
- en: '*read-pods-bind.yaml*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*read-pods-bind.yaml*'
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Not surprisingly, a RoleBinding ties together a Role or a ClusterRole and a
    subject. The RoleBinding can contain multiple subjects, so we can bind the same
    role to multiple users or groups with a single binding.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，RoleBinding 将一个 Role 或 ClusterRole 与一个主体关联起来。RoleBinding 可以包含多个主体，因此我们可以通过单个绑定将相同的角色绑定到多个用户或组。
- en: We define a Namespace in both the metadata and where we identify the subject.
    In this case, these are both `sample`, as we want to grant the ServiceAccount
    the ability to read Pod status in its own Namespace. However, these could be different
    to allow a ServiceAccount in one Namespace to have specific permissions in another
    Namespace. And of course we could also use a ClusterRoleBinding to give out permissions
    across all Namespaces.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在元数据中定义了一个命名空间，并且在标识主体的地方也定义了命名空间。在这种情况下，两个地方都是 `sample`，因为我们希望授予 ServiceAccount
    在其自己的命名空间中读取 Pod 状态的权限。然而，这两个命名空间也可以不同，以允许一个命名空间中的 ServiceAccount 在另一个命名空间中具有特定权限。当然，我们也可以使用
    ClusterRoleBinding 来授予跨所有命名空间的权限。
- en: 'We can now create the RoleBinding:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建 RoleBinding 了：
- en: '[PRE21]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We’ve now given permission for the `read-pods` ServiceAccount to read Pods in
    the `sample` Namespace. To demonstrate how it works, we need to create a Pod that
    is assigned to the `read-pods` ServiceAccount.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已授予 `read-pods` ServiceAccount 在 `sample` 命名空间中读取 Pods 的权限。为了演示其工作原理，我们需要创建一个分配给
    `read-pods` ServiceAccount 的 Pod。
- en: Assigning a Service Account to Pods
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将 Service Account 分配给 Pods
- en: 'To assign a ServiceAccount to a Pod, just add the `serviceAccountName` field
    to the Pod spec:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 ServiceAccount 分配给 Pod，只需将 `serviceAccountName` 字段添加到 Pod 的 spec 中：
- en: '*read-pods-deploy.yaml*'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*read-pods-deploy.yaml*'
- en: '[PRE22]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The ServiceAccount identified must exist in the Namespace that the Pod is created
    in. Kubernetes will inject the Pod’s containers with the Service-Account token
    so that the containers can authenticate to the API server.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 所标识的 ServiceAccount 必须存在于创建 Pod 的命名空间中。Kubernetes 会将 Pod 的容器注入 Service-Account
    令牌，以便容器可以认证到 API 服务器。
- en: 'Let’s walk through an example to show how this works and how the authorization
    is applied. Start by creating this Deployment:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个示例来展示这个过程，并说明授权是如何应用的。首先创建这个 Deployment：
- en: '[PRE23]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This creates an Alpine container running `sleep` that we can use as a base for
    shell commands.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这会创建一个运行 `sleep` 的 Alpine 容器，我们可以将其用作 shell 命令的基础。
- en: 'To get to a shell prompt, we’ll first get the generated name of the Pod and
    then use `kubectl exec` to create the shell:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 要进入 shell 提示符，我们首先获取 Pod 的生成名称，然后使用 `kubectl exec` 创建 shell：
- en: '[PRE24]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The ServiceAccount token is mounted in the directory */run/secrets/kubernetes.io/serviceaccount*,
    so change to that directory and list its contents:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ServiceAccount 令牌挂载在目录 */run/secrets/kubernetes.io/serviceaccount* 中，因此切换到该目录并列出其内容：
- en: '[PRE25]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: These files show up as odd looking symbolic links, but the contents are there
    as expected. The *ca.crt* file is the root certificate for the cluster, which
    is needed to trust the connection to the API server.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文件看起来像是奇怪的符号链接，但内容如预期所示。*ca.crt* 文件是集群的根证书，它用于信任与 API 服务器的连接。
- en: 'Let’s save the token in a variable so that we can use it:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将令牌保存在一个变量中，以便使用：
- en: '[PRE26]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can now use this token with `curl` to connect to the API server. First,
    though, we need to install `curl` into our Alpine container:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用这个令牌与 `curl` 连接到 API 服务器。但首先，我们需要将 `curl` 安装到 Alpine 容器中：
- en: '[PRE27]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Our ServiceAccount is allowed to perform `get`, `list`, and `watch` operations
    on Pods. Let’s list all Pods in the `sample` Namespace:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 ServiceAccount 被允许对 Pods 执行 `get`、`list` 和 `watch` 操作。让我们列出 `sample` 命名空间中的所有
    Pods：
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As with the bootstrap token, we use HTTP Bearer authentication to pass the ServiceAccount
    token to the API server. Because we’re operating from inside a container, we can
    use the standard address `kubernetes.default.svc` to find the API server. This
    works because a Kubernetes cluster always has a service in the `default` Namespace
    that routes traffic to API server instances using the Service networking we saw
    in [Chapter 9](ch09.xhtml#ch09).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 与引导令牌一样，我们使用 HTTP Bearer 身份验证将 ServiceAccount 令牌传递给 API 服务器。由于我们在容器内部操作，我们可以使用标准地址
    `kubernetes.default.svc` 来查找 API 服务器。这是可行的，因为 Kubernetes 集群始终在 `default` 命名空间中拥有一个服务，使用我们在[第
    9 章](ch09.xhtml#ch09)中看到的服务网络将流量路由到 API 服务器实例。
- en: 'The `curl` command is successful because our ServiceAccount is bound to the
    `pod-reader` Role we created. However, the RoleBinding is limited to the `sample`
    Namespace, and as a result, we aren’t allowed to list Pods in a different Namespace:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We can use the error message to be certain that our ServiceAccount assignment
    and authentication worked as expected because the API server recognizes us as
    the `read-pods` ServiceAccount. However, we don’t have a RoleBinding with the
    right permissions to read Pods in the `kube-system` Namespace, so the request
    is rejected.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, because we have permission only for Pods, we can’t list our Deployment,
    even though it is also in the `sample` Namespace:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The slightly different path scheme for the URL, starting with */apis/apps/v1*
    instead of */api/v1*, is needed because Deployments are in the `apps` API group
    rather than the default group. This command fails in a similar way because we
    don’t have the necessary permissions to list Deployments.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re finished with this shell session, so let’s exit it:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Before we leave the RBAC topic, though, let’s illustrate an easy way to grant
    normal user permissions for a Namespace without allowing any administrator functions.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Binding Roles to Users
  id: totrans-134
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To grant normal user permissions, we’ll leverage an existing ClusterRole called
    `edit` that’s already set up to grant view and edit permissions for most of the
    resource types users need.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a quick look at the `edit` ClusterRole to see what permissions it
    has:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The full list has a large number of different rules, each with its own set of
    permissions. The subset in this example shows just one rule, used to provide edit
    permission for Pods.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Some commands related to Pods, such as `exec`, are listed separately to allow
    for more granular control. For example, for a production system, it can be useful
    to allow some individuals the ability to create and delete Pods and see logs,
    but not provide the ability to use `exec`, because that might be used to access
    sensitive production data.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Previously, we created a user called *me* and saved the client certificate to
    a file called *kubeconfig*. However, we didn’t bind any roles to that user yet,
    so the user has only the very limited permissions that come with automatic membership
    in the *system:authenticated* group.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: As a result, as we saw earlier, our normal user can’t even list Pods in the
    `default` Namespace. Let’s bind this user to the edit role. As before, we’ll use
    a regular RoleBinding, scoped to the `sample` Namespace, so this user won’t be
    able to access our cluster infrastructure components in the `kube-system` Namespace.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 11-1](ch11.xhtml#ch11list1) presents the RoleBinding we need.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '*edit-bind.yaml*'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '*Listing 11-1: Bind the edit role to a user*'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we apply this RoleBinding to add permissions to our user:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We’re now able to use this user to view and modify Pods, Deployments, and many
    other resources:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'However, because we used a RoleBinding and not a ClusterRoleBinding, this user
    has no visibility into other Namespaces:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于我们使用的是 RoleBinding 而不是 ClusterRoleBinding，因此该用户无法查看其他命名空间：
- en: '[PRE36]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The error message displayed by `kubectl` is identical in form to the `message`
    field that is part of the API server’s JSON response. This is not a coincidence;
    `kubectl` is a friendly command line interface in front of the API server’s REST
    API.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl` 显示的错误消息与 API 服务器 JSON 响应中的 `message` 字段形式相同。这并非巧合；`kubectl` 是 API
    服务器 REST API 前的友好命令行界面。'
- en: Final Thoughts
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后的想法
- en: The API server is an essential component in the Kubernetes control plane. Every
    other service in the cluster is continuously connected to the API server, watching
    the cluster for changes, so it can take appropriate action. Users also use the
    API server to deploy and configure applications and to monitor state. In this
    chapter, we saw the underlying REST API that the API server provides to create,
    retrieve, update, and delete resources. We also saw the extensive authentication
    and authorization capabilities built in to the API server to ensure that only
    authorized users and services can access and modify the cluster state.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器是 Kubernetes 控制平面中的一个核心组件。集群中的每个其他服务都会持续连接到 API 服务器，监视集群中的变化，以便采取适当的行动。用户也使用
    API 服务器来部署和配置应用程序以及监控状态。在这一章中，我们看到了 API 服务器提供的底层 REST API，用于创建、检索、更新和删除资源。我们还看到了
    API 服务器内置的广泛认证和授权功能，确保只有授权的用户和服务可以访问和修改集群状态。
- en: 'In the next chapter, we’ll examine the other side of our cluster’s infrastructure:
    the node components. We’ll see how the `kubelet` Service hides any differences
    between container engines and how it uses the container capabilities we saw in
    [Part I](part01.xhtml#part01) to create, start, and configure containers in the
    cluster.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨集群基础设施的另一面：节点组件。我们将看到 `kubelet` 服务如何隐藏容器引擎之间的差异，以及它如何使用我们在[第一部分](part01.xhtml#part01)中看到的容器功能来创建、启动和配置集群中的容器。
