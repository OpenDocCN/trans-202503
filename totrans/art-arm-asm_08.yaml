- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: 6 ARITHMETIC
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/opener.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This chapter discusses arithmetic computation in assembly language, including
    floating-point arithmetic on the ARM processor and architectural support for real
    arithmetic. By the end of this chapter, you should be able to translate arithmetic
    expressions and assignment statements from HLLs like Pascal, Swift, and C/C++
    into ARM assembly language. You’ll learn to pass floating-point values as parameters
    to procedures and return real values as function results.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Additional ARM Arithmetic Instructions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before learning to encode arithmetic expressions in assembly language, you should
    learn the rest of the arithmetic instructions in the ARM instruction set. Previous
    chapters have covered most of the arithmetic and logical instructions, so this
    section covers the remaining few.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.1 Multiplication
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Chapter 4](chapter4.xhtml) provided a brief introduction to multiplication
    with the mul and madd instructions. As a reminder, those instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As long as overflow doesn’t occur, these instructions produce correct results
    for both unsigned and signed multiplications.
  prefs: []
  type: TYPE_NORMAL
- en: These instructions multiply two 64-bit integers and produce a 64-bit result.
    The multiplication of two *n*-bit numbers can actually produce a 2 × *n*–bit result,
    meaning that multiplying two 64-bit registers could produce up to a 128-bit result.
    These instructions ignore any overflow and keep only the LO 64 bits of the product
    ([Chapter 8](chapter8.xhtml) discusses how to produce a full 128-bit result, if
    you require that).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also specify 32-bit registers for these two instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'These instructions produce 32-bit results, ignoring any overflow. There are
    two additional multiplication instructions: multiply and subtract, and multiply
    and negate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As with the previous instructions, these multiplications ignore any overflow
    beyond 32 or 64 bits.
  prefs: []
  type: TYPE_NORMAL
- en: The ARM does not provide multiplication instructions that affect the condition
    code flags. These instructions have no s-suffix versions.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.2 Division and Modulo
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The ARM64 CPU provides only two division instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Unlike with multiplication, you must use separate instructions for signed and
    unsigned integer values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Division has two special cases that you must consider: division by 0 and dividing
    the smallest negative number by –1 (which would, mathematically, produce an overflow).
    A division by 0 produces 0 as the result, with no indication of the problem. A
    signed division (sdiv) of 0x8000000000000000 (the smallest 64-bit negative number)
    by 0xFFFFFFFFFFFFFFFF (–1) will produce the result 0x8000000000000000, also without
    indication of an error. You’ll get similar results for the 32-bit division: 0x80000000
    / 0xFFFFFFFF. You must explicitly test for these operands before the division
    to catch these errors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s no single instruction to compute the remainder after a division operation
    on the ARM64 CPU. You can compute the remainder by combining a division and a
    multiplication operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can compute the same result by using the following two instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: After this sequence, X2 and X3 hold the following values
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: thus providing the modulo in X3.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.3 cmp Revisited
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As noted in section 2.10.4, “cmp and Corresponding Conditional Branches,” on
    [page 78](chapter2.xhtml#pg_78), the cmp instruction updates the ARM’s flags according
    to the result of the subtraction operation (LeftOperand - RightOperand). Based
    on the way the ARM sets the flags, you can read this instruction as “compare LeftOperand
    to RightOperand.” You can test the result of the comparison by using conditional
    branch instructions (see [Chapter 2](chapter2.xhtml) for the conditional branches
    or [Chapter 7](chapter7.xhtml) for more on control structure implementations).
  prefs: []
  type: TYPE_NORMAL
- en: 'A good place to start when exploring cmp is to look at exactly how it affects
    the flags. Consider the following cmp instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This instruction performs the computation W0 – W1 and sets the flags depending
    on the result of the computation. The flags are set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Z**    The zero flag is set if and only if W0 = W1\. This is the only time
    W0 – W1 produces a zero result. Hence, you can use the zero flag to test for equality
    or inequality.'
  prefs: []
  type: TYPE_NORMAL
- en: '**N**    The negative (sign) flag is set to 1 if the result is negative. You
    might think this flag would be set if W0 is less than W1, but this isn’t always
    the case. If W0 = 0x7FFFFFFFh and W1 = –1 (0xFFFFFFFF), then subtracting W1 from
    W0 produces 0x80000000, which is negative (so the negative flag will be set).
    For signed comparisons, at least, the negative flag doesn’t contain the proper
    status. For unsigned operands, consider W0 = 0xFFFFFFFF and W1 = 1\. Here, W0
    is greater than W1, but their difference is 0xFFFFFFFEh, which is still negative.
    As it turns out, the negative flag and the overflow flag, taken together, can
    be used for comparing two signed values.'
  prefs: []
  type: TYPE_NORMAL
- en: '**V**    The overflow flag is set after a cmp operation if the difference of
    W0 and W1 produces a signed overflow or underflow. As mentioned previously, the
    sign and overflow flags are both used when performing signed comparisons.'
  prefs: []
  type: TYPE_NORMAL
- en: '**C**    The carry flag is set after a cmp operation if subtracting W1 from
    W0 requires a borrow (unsigned overflow or underflow). This occurs only when W0
    is less than W1, where W0 and W1 are both unsigned values.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 6-1](chapter6.xhtml#tab6-1) shows how the cmp instruction affects the
    flags after comparing to unsigned or signed values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-1: Condition Code Settings After cmp'
  prefs: []
  type: TYPE_NORMAL
- en: '| Flag | Unsigned result | Signed result |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Zero (Z) | Equality/inequality | Equality/inequality |'
  prefs: []
  type: TYPE_TB
- en: '| Carry (C) | Left ≥ right (C = 1) Left < right (C = 0) | No meaning |'
  prefs: []
  type: TYPE_TB
- en: '| Overflow (V) | No meaning | See discussion in this section |'
  prefs: []
  type: TYPE_TB
- en: '| Sign (N) | No meaning | See discussion in this section |'
  prefs: []
  type: TYPE_TB
- en: 'Given that the cmp instruction sets the flags in this fashion, you can test
    the comparison of the two signed operands with the following flags:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'For signed comparisons, the N and V flags, taken together, have the following
    meanings:'
  prefs: []
  type: TYPE_NORMAL
- en: If [N != V], then Left < Right for a signed comparison.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If [N == V], then Left ≥ Right for a signed comparison.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand why these flags are set in this manner, consider the 32-bit examples
    in [Table 6-2](chapter6.xhtml#tab6-2). The values easily sign-extend to 64 bits,
    and the results are the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-2: Sign and Overflow Flag Settings After Subtraction (32-Bit Values)'
  prefs: []
  type: TYPE_NORMAL
- en: '| Left | Minus | Right | N | V |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0xFFFFFFFF (–1) | – | 0xFFFFFFFE (–2) | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 0x80000000 (–2 billion+) | – | 0x000000001 | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 0xFFFFFFFE (–2) | – | 0xFFFFFFFF (–1) | 1 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| 0x7FFFFFFF (2 billion+) | – | 0xFFFFFFFF (–1) | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: Remember, the cmp operation is really a subtraction; therefore, the first example
    in [Table 6-2](chapter6.xhtml#tab6-2) computes (–1) – (–2), which is +1\. The
    result is positive, and an overflow did not occur, so both the N and V flags are
    0\. Because (N == V), Left is greater than or equal to Right.
  prefs: []
  type: TYPE_NORMAL
- en: The cmp instruction would compute (–2,147,483,648) – (+1), which is (–2,147,483,649),
    in the second example. Because a 32-bit signed integer cannot represent this value,
    the value wraps around to 0x7FFFFFFF (+2,147,483,647) and sets the overflow flag.
    The result is positive (at least as a 32-bit value), so the CPU clears the negative
    flag. Because (N == V) here, Left is less than Right.
  prefs: []
  type: TYPE_NORMAL
- en: In the third example, cmp computes (–2) – (–1), which produces (–1). No overflow
    occurred, so the V is 0; the result is negative, so N is 1\. Because (N != V),
    Left is less than Right.
  prefs: []
  type: TYPE_NORMAL
- en: In the final example, cmp computes (+2,147,483,647) – (–1). This produces (+2,147,483,648),
    setting the overflow flag. Furthermore, the value wraps around to 0x80000000 (−2,147,483,648),
    so the negative flag is set as well. Because (N == V) is 0, Left is greater than
    or equal to Right.
  prefs: []
  type: TYPE_NORMAL
- en: 'The cmn (compare negative) instruction compares its first source operand against
    a negated second operand; like cmp, it sets the flags and ignores the result.
    It is also, like cmp, an alias for a different instruction, add:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This is because cmp is equivalent to a sub instruction, using WZR/XZR as the
    destination register; when comparing a negated value, you get the expression left
    – (–right), which is mathematically equivalent to left + right.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using add as a synonym for cmn has one issue: add doesn’t set the carry flag
    properly if the second (right) operand is 0\. As a result, you cannot use the
    unsigned condition codes (hs, hi, ls, or lo) after a cmn instruction if there
    is any possibility that the right operand is 0\. This shouldn’t generally be a
    problem because, by definition, you are using cmn to compare signed values and
    you should be using signed conditionals after the use of the instruction.'
  prefs: []
  type: TYPE_NORMAL
- en: Arguably the main reason for the existence of cmn is that Operand2 immediate
    values must be in the range 0 to 4,095\. You cannot compare a register against
    a negative immediate value by using the cmp instruction. The cmn instruction is
    also limited to constants in the range 0 to 4,095, but it will negate the immediate
    value before the comparison, allowing negative constants in the range –1 to –4,095
    (–0 is still 0).
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.4 Conditional Instructions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the original, 32-bit ARM architecture, most of the data manipulation instructions
    were conditional. You could execute an instruction, such as add, conditionally,
    based on PSTATE condition code flag settings. Alas, the 4 bits required to test
    the 16 possible conditions (same as the conditional branch instructions) were
    needed for other encodings in 64-bit mode. Nevertheless, condition instruction
    execution is useful, so the ARM64 kept a few of the more commonly used condition
    instructions.
  prefs: []
  type: TYPE_NORMAL
- en: The first condition instruction is csel (conditional select)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: where cond is one of the following condition specifications
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: which have the same meanings as for the conditional branch instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *aoaa.inc* include file provides definitions for the following opposite
    conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: These are synonyms for lo, ls, hi, hs, le, lt, ge, and gt, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: As its name suggests, the csel instruction selects one of the two source operands
    to copy into the destination register, based on the current flag settings. For
    example, the following instruction
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: copies X1 into X0 if the zero flag is set; otherwise, it copies X2 into X0.
  prefs: []
  type: TYPE_NORMAL
- en: 'The csinc instruction allows for a conditional select (if true condition) or
    increment (if false condition) operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the predefined macro cinc is sometimes more convenient:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: That is, cinc increments and copies the source into the destination if the condition
    is true; otherwise, it just copies the source without incrementing it. Of course,
    the source and destination registers can be the same if you simply want to conditionally
    increment a specific register. Note that the conditions for the cinc macros are
    reversed from the csinc instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next two conditional instructions are csinv and csneg, which conditionally
    invert or negate values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'There are also cinv and cneg macros that take only a single source operand
    (like cinc). The cset and csetm macros are variants of csinc and cinv:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The cset macro is equivalent to cinc with WZR or XZR as both source operands,
    and csetm is equivalent to cinv with WZR or XZR as the source operands. These
    macros are useful for setting a register to a Boolean value (either true/–1 or
    false/0) based on the condition codes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the ARM also supports two conditional compare instructions, ccmp and
    ccmn (conditional compare negative), each with a few forms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Whereas ccmp compares by subtracting the second operand from the first, ccmn
    compares by adding the second operand to the first. These instructions test the
    provided condition (cond). If it is false, these instructions copy the 4-bit immediate
    value #nzcv4 directly into the condition codes (bit 3 to N, bit 2 to Z, bit 1
    to C, and bit 0 to V).'
  prefs: []
  type: TYPE_NORMAL
- en: If the condition specified by cond is true, these instructions compare the destination
    register to the source operand (register or 5-bit unsigned immediate value) and
    set the condition code bits based on the comparison. As you’ll see later in this
    chapter, the conditional comparisons are useful for evaluating complex Boolean
    expressions.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Memory Variables vs. Registers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before jumping into converting arithmetic expressions into assembly language
    statements, let’s also wrap up the discussion of variables from the last five
    chapters. As I’ve pointed out many times, the ARM is based on a load/store architecture.
    The ARM has been blessed with many general-purpose registers that you can use
    in lieu of memory locations for your more commonly used variables. With careful
    planning, you should be able to keep most of your often-used variables in registers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following C/C++ statement and its conversion to ARM assembly language:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: If you keep x, y, and z in registers W19, W20, and W21, respectively, the translation
    of that expression into assembly language would be
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: which is one-tenth the size and much faster than the conversion just given.
  prefs: []
  type: TYPE_NORMAL
- en: On RISC CPUs like the ARM, it’s a much better idea to keep variables in registers
    rather than in memory. Your job as an assembly language programmer is to carefully
    choose the variables you keep in registers versus the (less often used) values
    you will have to maintain in memory. You can do this by counting the number of
    times you access a variable during execution and keep the most-frequently accessed
    variables in registers, leaving the least-frequently accessed variables in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1 Volatile vs. Nonvolatile Register Usage
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If you are adhering to the ARM ABI in your assembly code, you must also be
    cognizant of the difference between volatile and nonvolatile registers in your
    procedures. Using nonvolatile registers has a cost: if you modify a nonvolatile
    register’s value, you must preserve the register’s original value within a procedure.
    This generally involves allocating storage in the procedure’s activation record,
    storing the nonvolatile register’s value on entry to the procedure, and restoring
    the register’s value before returning.'
  prefs: []
  type: TYPE_NORMAL
- en: Using volatile registers means you’re spared the expense and storage required
    to preserve them. However, volatile registers may have their contents disturbed
    if you make calls to other procedures, which aren’t known to explicitly preserve
    the volatile registers. Because it is the caller’s responsibility to preserve
    any volatile register contents across other function calls, you may as well use
    a nonvolatile register (assuming one is available) if you’re making calls to other
    functions within your procedures.
  prefs: []
  type: TYPE_NORMAL
- en: This assumes, of course, that the functions you’re calling adhere to the ARM
    ABI conventions. If, for example, you’re calling assembly language functions that
    preserve all register values they modify, you don’t have to worry about preserving
    those registers, even if the ARM ABI considers them volatile.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2 Global vs. Local Variables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you have to use memory—because you don’t have sufficient register resources
    available or because you have a large data structure to manipulate that won’t
    fit in registers—you can locate the variables you must maintain in memory. You
    can put them in either a global, static data section (such as .data, .bss, and
    so on) or in an activation record you’ve created for your current procedure.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you learned to program in an HLL, you were probably taught to avoid using
    global variables in your programs. That advice applies even more in ARM assembly
    language, especially when programming under macOS. Under macOS, as you’ve seen
    many times, accessing global data is more expensive than accessing local data
    in an activation record. To fetch a 32-bit variable from global (.data) memory
    requires code such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Fetching data from a local variable takes only a single instruction (assuming
    the variable’s offset into the activation record is relatively small):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: That means accessing local variables takes one-third the number of instructions
    it takes to access global variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, if you’re running under Linux and don’t need your assembly code
    to run under macOS as well, you can also access global variables by using a single
    instruction and the PC-relative addressing mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Just keep in mind that the data must sit within ±1MB of this instruction. Blowing
    past this limit is pretty easy when writing larger applications.
  prefs: []
  type: TYPE_NORMAL
- en: Local variables are not without their own limitations. In general, the activation
    record has a limit of about ±256 bytes of storage, a little more if you can use
    the scaled-indirect-plus-offset addressing mode with half-word, word, and double-word
    variables. Fortunately, you’ll rarely surpass that number of bytes of scalar (non-array/nonstructure)
    variables in a single procedure. If you do require more space, you’ll have to
    compute the effective address of the variable within the activation record, which
    winds up taking as many instructions as accessing global variables.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3 Easy Access to Global Variables
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To make it just as easy to access global variables in a .data or .bss section
    as it is to access local variables within an activation record, you can create
    a static activation record. Local variables are easy to access because you use
    the indirect-plus-offset (or scaled indirect-plus-offset) addressing mode to index
    off the FP register. What if you had the equivalent of FP pointing into a static
    data section? Although the ARM doesn’t provide an SB (static base) register, nothing
    is stopping you from creating your own:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: I chose to use X28 in this example, since it’s a nonvolatile register in the
    ARM ABI and is right below the FP (X29) register.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6-1 demonstrates using the SB register (X28) to efficiently access global
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Keep in mind that the [sb, #offset] addressing mode is limited to ±256 bytes
    (or up to 1KB when using the scaled indirect-plus-offset modes), so it’s best
    to keep nonscalar (composite) variables outside the static record.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As written, the globals record in Listing 6-1 provides access to only 256 bytes
    of storage (because all the struct field offsets are positive or 0). The following
    declaration starts the offsets at –256, providing an additional 256 bytes of storage
    in the static record:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: However, if you do this, you must adjust the value you load into SB appropriately,
    as shown here
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: so that SB will point into the correct place in the globals_t structure.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Arithmetic Expressions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The biggest shock to beginners facing assembly language for the first time
    will likely be the lack of familiar arithmetic expressions. Arithmetic expressions
    in most HLLs look similar to their algebraic equivalents. For example, in C you
    could write the following algebraic-like statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'In assembly language, you’ll need several statements to accomplish this same
    task if these variables are sitting in memory locations (assume they’re local
    variables):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Obviously, the HLL version is much easier to type, read, and understand. Although
    a lot of typing is involved, converting an arithmetic expression into assembly
    language isn’t difficult. By attacking the problem in steps, the same way you
    would solve the problem by hand, you can easily break any arithmetic expression
    into an equivalent sequence of assembly language statements.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1 Simple Assignments
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The easiest expressions to convert to assembly language are *simple assignments*,
    which copy a single value into a variable and take one of two forms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'If your variables are sitting in registers, converting these statements to
    assembly language is simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This mov instruction copies the source constant or register into the destination
    register.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the constant is too large, you’ll either have to use the movk sequence (see
    section 2.20.2, “movk,” on [page 112](chapter2.xhtml#pg_112)) or the constant
    form of ldr:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'If the source variable is in memory, you must use the ldr instruction to fetch
    the data from memory, as shown in the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'If the destination is a memory variable, you must first load the source variable
    or constant into a register (if it isn’t already in a register) and use the str
    instruction to store the value into the memory variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Clearly, the most efficient code occurs when both variables are in a register
    or the destination is a register and the source value is a small constant, in
    which case a single mov instruction suffices.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2 Simple Expressions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The next level of complexity is a *simple expression*, which takes the form
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: where var1 is a variable, term1 and term2 are variables or constants, and op
    is an arithmetic operator (addition, subtraction, multiplication, and so on).
    Most expressions take this form. It should come as no surprise, then, that the
    ARM architecture was optimized for just this type of expression.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming var1, term1, and term2 are all in registers, a typical conversion for
    this type of expression takes the form
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: where op is the mnemonic that corresponds to the specified operation (for example,
    + is add, – is sub, and so forth).
  prefs: []
  type: TYPE_NORMAL
- en: Note that the simple expression
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: is easily handled with a compile-time expression and a single mov instruction.
    For example, to compute
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'you would use the single instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'If term2 is a (small enough) constant, you can typically use an instruction
    of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Exceptions exist, however. Certain instructions, such as mul and udiv/sdiv,
    do not allow immediate operands. In such cases, you’ll need to use the two instructions
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: where someReg is an available temporary register.
  prefs: []
  type: TYPE_NORMAL
- en: If term1 is a constant and term2 is a register, you can get away with simply
    swapping the two source operands in the instruction for commutative operations.
    For example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'becomes this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: For noncommutative operations, such as subtraction and division, this scheme
    doesn’t work. You may have to load the constant into a register prior to the operation.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, if the constant is too large (generally 12 bits for arithmetic instructions),
    you’ll have to first load that constant into a register by using the mov, movk,
    or ldr instructions.
  prefs: []
  type: TYPE_NORMAL
- en: If your terms are memory variables rather than registers (or constants), you
    will need to use the ldr instruction to move the memory variable(s) into register(s)
    prior to the operation. Likewise, if the destination variable is in memory, you
    will have to use a str instruction to store the value after the operation is complete.
    For example
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'becomes this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some examples of common simple expressions (assume x, y, and z are
    in W0, W1, and W2):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: If any of the operands are memory variables, you will first have to load them
    into registers by using the ldr instruction. If any operands are constants, follow
    the guidelines from the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.3 Complex Expressions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A *complex expression* is any arithmetic expression involving more than two
    terms and one operator. Such expressions are commonly found in programs written
    in an HLL. Complex expressions may include parentheses to override operator precedence,
    function calls, array accesses, and so on. This section outlines the rules for
    converting such expressions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Complex expressions that are easy to convert to assembly language involve three
    terms and two operators. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Clearly, the straightforward assembly language conversion of this statement
    requires two sub instructions. However, even with an expression as simple as this,
    the conversion is not trivial. You can convert the preceding statement into assembly
    language in two ways (assume w is in W0, y is in W1, and z is in W2):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Both methods can produce different results, with the first conversion largely
    adhering to C language semantics. The problem is associativity. The second sequence
    in the preceding example computes w = w - (y - z), which is not the same as w
    = (w - y) - z. The placement of the parentheses around the subexpressions can
    affect the result.
  prefs: []
  type: TYPE_NORMAL
- en: '*Precedence*, the order in which operations occur, is another issue. Consider
    this expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, you can evaluate this expression in one of two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: By now, you’re probably thinking that this explanation is crazy—everyone knows
    the correct way to evaluate these expressions is to use the former form. However,
    this isn’t always correct. The APL programming language, for example, evaluates
    expressions solely from right to left and does not give one operator precedence
    over another. The “correct” method depends entirely on how you define precedence
    in your arithmetic system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: If op1 takes precedence over op2, this evaluates to (x op1 y) op2 z*.* Otherwise,
    if op2 takes precedence over op1, the expression evaluates to x op1 (y op2 z).
    Depending on the operators and operands involved, these two computations could
    produce different results.
  prefs: []
  type: TYPE_NORMAL
- en: Most HLLs use a fixed set of precedence rules to describe the order of evaluation
    in an expression involving two or more different operators. Such programming languages
    usually compute multiplication and division before addition and subtraction. Those
    that support exponentiation (for example, FORTRAN and BASIC) usually compute that
    before multiplication and division. These rules are intuitive because most people
    learn them before high school.
  prefs: []
  type: TYPE_NORMAL
- en: 'When converting expressions into assembly language, you must be sure to compute
    the subexpression with the highest precedence first. The following example demonstrates
    this technique (assuming multiplication has higher precedence than addition):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'If two operators appearing within an expression have the same precedence, use
    the associativity rules to determine the order of evaluation. Most operators are
    *left-associative*, meaning that they evaluate from left to right. Addition, subtraction,
    multiplication, and division are all left-associative. A *right-associative* operator
    evaluates from right to left. The exponentiation operator in FORTRAN is a good
    example of a right-associative operator. For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: is equal to
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: not
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The precedence and associativity rules determine the order of evaluation. Indirectly,
    these rules tell you where to place parentheses in an expression to determine
    the order of evaluation. Of course, you can always use parentheses to override
    the default precedence and associativity. However, the ultimate point is that
    your assembly code must complete certain operations before others to correctly
    compute the value of a given expression. The following examples demonstrate this
    principle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: or, even better
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The associativity rule has one exception: if an expression involves multiplication
    and division, it is generally better to perform the multiplication first. For
    example, given an expression of the form'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: it is usually better to compute x * z and then divide the result by y, rather
    than dividing x by y and multiplying the quotient by z. Doing the multiplication
    first increases the accuracy of the computation. Remember, (integer) division
    often produces an inexact result. For example, if you compute 5 / 2, you will
    get the value 2, not 2.5\. Computing (5 / 2) × 3 produces 6\. However, computing
    (5 × 3) / 2 gives you the value 7, which is a little closer to the real quotient
    (7.5).
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, if you encounter an expression of the form
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'you can usually convert it to the following assembly code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: If the multiplication will likely produce an overflow, computing the division
    operation first may be better.
  prefs: []
  type: TYPE_NORMAL
- en: If the algorithm you’re encoding depends on the truncation effect of the division
    operation, you cannot use this trick to improve the algorithm. The moral of the
    story is that you should always make sure you fully understand any expression
    you are converting to assembly language. If the semantics dictate that you must
    perform the division first, do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Because subtraction is not commutative, you cannot compute y * x and then subtract
    x from this result. Rather than use a straightforward multiplication-and-subtraction
    sequence, you’ll have to use a temporary register to hold the product. For example,
    the following two instructions use W4 as a temporary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'As your expressions increase in complexity, the need for temporaries grows.
    Consider the following C statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Following the normal rules of algebraic evaluation, compute the subexpressions
    inside the parentheses first (that is, the two subexpressions with the highest
    precedence) and set their values aside. When you’ve computed the values for both
    subexpressions, you can compute their product. One way to deal with a complex
    expression like this is to reduce it to a sequence of simple expressions whose
    results wind up in temporary variables. For example, you can convert the preceding
    single expression into the following sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Since converting simple expressions to assembly language is easy, it’s now
    a snap to compute the former complex expression in assembly, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s yet another example of a complex arithmetic conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'You can convert this to a set of four simple expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'You can convert these four expressions into the following assembly language
    statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Most important, make sure you keep temporary values in registers for efficiency.
    Use memory locations to hold temporaries only if you’ve run out of registers.
  prefs: []
  type: TYPE_NORMAL
- en: In short, as you’ve seen, converting a complex expression to assembly language
    is a little different from solving the expression by hand. Instead of computing
    the result at each stage of the computation, you write the assembly code that
    computes the result.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4 Commutative Operators
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If op represents an operator, that operator is *commutative* if the following
    relationship is always true:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: As you learned in the previous section, commutative operators are easy to translate
    because the order of their operands is immaterial, which lets you rearrange a
    computation, often making it easier or more efficient. Often, rearranging a computation
    allows you to use fewer temporary variables. Whenever you encounter a commutative
    operator in an expression, check whether you can use a better sequence to improve
    the size or speed of your code.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 6-3](chapter6.xhtml#tab6-3) lists the commutative operators typically
    found in HLLs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-3: Commutative Dyadic (Two-Operand) Operators'
  prefs: []
  type: TYPE_NORMAL
- en: '| Pascal | C/C++ and similar | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| + | + | Addition |'
  prefs: []
  type: TYPE_TB
- en: '| * | * | Multiplication |'
  prefs: []
  type: TYPE_TB
- en: '| and | && or & | Logical or bitwise AND |'
  prefs: []
  type: TYPE_TB
- en: '| or | &#124;&#124; or &#124; | Logical or bitwise OR |'
  prefs: []
  type: TYPE_TB
- en: '| xor | ^ | Logical or bitwise exclusive-OR |'
  prefs: []
  type: TYPE_TB
- en: '| = | == | Equality |'
  prefs: []
  type: TYPE_TB
- en: '| <> | != | Inequality |'
  prefs: []
  type: TYPE_TB
- en: '[Table 6-4](chapter6.xhtml#tab6-4) lists many of the noncommutative operators.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-4: Noncommutative Dyadic Operators'
  prefs: []
  type: TYPE_NORMAL
- en: '| Pascal | C/C++ and similar | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| - | - | Subtraction |'
  prefs: []
  type: TYPE_TB
- en: '| / or div | / | Division |'
  prefs: []
  type: TYPE_TB
- en: '| mod | % | Remainder (modulo) |'
  prefs: []
  type: TYPE_TB
- en: '| < | < | Less than |'
  prefs: []
  type: TYPE_TB
- en: '| <= | <= | Less than or equal |'
  prefs: []
  type: TYPE_TB
- en: '| > | > | Greater than |'
  prefs: []
  type: TYPE_TB
- en: '| >= | >= | Greater than or equal |'
  prefs: []
  type: TYPE_TB
- en: If you encounter any other operator types, check the associated HLL definition
    for the operators to determine whether they are commutative or noncommutative
    and determine their precedence and associativity.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4 Logical Expressions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Consider the following logical (Boolean) expression from a C/C++ program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Here, bb is a Boolean variable, and the remaining variables are all integers.
  prefs: []
  type: TYPE_NORMAL
- en: Though it takes only a single bit to represent a Boolean value, most assembly
    language programmers allocate a whole byte or even a word to represent Boolean
    variables. Most programmers (and, indeed, some programming languages like C) choose
    0 to represent *false* and anything else to represent *true*. Some people prefer
    to represent true and false with 1 and 0, respectively, and not allow any other
    values. Others select all 1 bits (0xFFFF_FFFF_FFFF_FFFF, 0xFFFF_FFFF, 0xFFFF,
    or 0xFF) for true and 0 for false. You could also use a positive value for true
    and a negative value for false.
  prefs: []
  type: TYPE_NORMAL
- en: 'All these mechanisms have their advantages and drawbacks. Using only 0 and
    1 to represent false and true offers two big advantages. First, the cset instruction
    produces this result, so this scheme is compatible with that instruction. Second,
    the ARM logical instructions (and, orr, eor, and, to a lesser extent, mvn) operate
    on these values exactly as you would expect. If you have two Boolean variables
    a and bb, the following instructions perform the basic logical operations on these
    two variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: The mvn instruction will not properly compute logical negation. The bitwise
    NOT of 0 is 0xFF (assuming a byte value), and the bitwise NOT of 1 is 0FEh. Neither
    result is 0 or 1\. However, ANDing the result with 1 gives you the proper result.
    You can implement the NOT operation more efficiently by using the eor instruction
    (as shown in the last eor example just given) because it affects only the LO bit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using 0 for false and anything else for true has a lot of subtle advantages.
    The test for true or false is often implicit in the execution of any logical instruction.
    However, this mechanism has a major downside: you cannot always use the ARM and,
    orr, eor, and mvn instructions to implement the Boolean operations of the same
    name. Consider the two values 0x55 and 0xAA. They’re both nonzero, so they both
    represent the value true. However, if you logically AND 0x55 and 0xAA together
    using the ARM and instruction, the result is 0\. True AND true should produce
    true, not false. Although you can account for situations like this, it usually
    requires a few extra instructions and is somewhat less efficient when computing
    Boolean operations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A system that uses nonzero values to represent true and 0 to represent false
    is an *arithmetic logical system*. A system that uses two distinct values like
    0 and 1 to represent false and true is called a *Boolean logical system*, or simply
    a Boolean system. You can use either system as convenient. Consider this Boolean
    expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting simple expressions might be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: When working with Boolean expressions, don’t forget that you might be able to
    optimize your code by simplifying it with algebraic transformations. In [Chapter
    7](chapter7.xhtml), you’ll also see how to use control flow to calculate a Boolean
    result, which can be a bit more efficient than using the methods taught by the
    examples in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 6.5 Conditional Comparisons and Boolean Expressions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The conditional comparison instruction, ccmp, is quite useful for encoding
    complex Boolean expressions in assembly language. Consider the following Boolean
    expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the logic from the previous section, you could translate this into the
    following assembly language code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'By using the conditional comparison instruction, you can keep the temporary
    values in the condition code flags to shorten your code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: The first cmp instruction sets the Z flag if x is equal to y. If that condition
    is false, the whole logical expression must return false. If it’s true, this code
    has to test whether a is less than or equal to d.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming that x does not equal y, the Z flag will be clear after the first cmp
    instruction. In that case, the ccmp instruction will not compare W3 (a) to W4
    (d) but will load the flags with 0b0000 instead (because the ccmp instruction
    compares only the first two operands if the condition, eq, is true; at this point,
    it is not). Because all the flags are clear (meaning N == V and Z != 1), the le
    condition for the cset is false; therefore, that instruction will store a 0 into
    W0 (bb), exactly what you want.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if x is equal to y, the eq condition for the ccmp instruction
    will be true and will compare the value of W3 (a) to W4 (d). If a is less than
    or equal to d, the N, V, and Z flags will be set in such a way that the cset instruction
    moves a 1 into W0\. Otherwise, cset will move a 0 into W0, which is again exactly
    what you want. This sequence with only three instructions does the work of the
    earlier sequence with five instructions, a huge win.
  prefs: []
  type: TYPE_NORMAL
- en: 6.5.1 Implementing Conjunction Using ccmp
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Consider this C/C++ logical expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'In general, to convert this expression containing the logical conjunction operator
    (&&) into ARM assembly using conditional comparison instructions, you would use
    the following five steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.  Compare the operands on the left-hand side of the conjunction operator,
    cc1 (see [Table 6-5](chapter6.xhtml#tab6-5)).
  prefs: []
  type: TYPE_NORMAL
- en: 2.  Immediately after the first comparison, execute a ccmp instruction, supplying
    cc1 as the conditional field.
  prefs: []
  type: TYPE_NORMAL
- en: '3.  Choose the corresponding #nzcv encoding from the opposite column in [Table
    6-5](chapter6.xhtml#tab6-5) to match cc2. The full ccmp instruction should be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '4.  The last instruction in the sequence should test cc2, as in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '5.  If cc1 fails, the ccmp instruction will set the flags to the #nzcvop value
    and not compare c against d. Since you want the Boolean expression to yield false
    in this situation, choose an #nzcvop value that is the opposite of cc2 so that
    the following test (for example, cset) produces a false result. If cc1 is true
    upon executing the ccmp instruction, ccmp will compare c and d and set the flags.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-5: Conditional Operators, Opposites, and NZCV Settings'
  prefs: []
  type: TYPE_NORMAL
- en: '| C/C++ | Operator | #nzcv | Opposite | #nzcvop |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| == | eq | 0b0100 | ne | 0b0000 |'
  prefs: []
  type: TYPE_TB
- en: '| != | ne | 0b0000 | eq | 0b0100 |'
  prefs: []
  type: TYPE_TB
- en: '| > (unsigned) | hi | 0b0010 | ls | 0b0100 |'
  prefs: []
  type: TYPE_TB
- en: '| >= (unsigned) | hs | 0b0110 | lo | 0b0000 |'
  prefs: []
  type: TYPE_TB
- en: '| < (unsigned) | lo | 0b0000 | hs | 0b0110 |'
  prefs: []
  type: TYPE_TB
- en: '| <= (unsigned) | ls | 0b0100 | hi | 0b0010 |'
  prefs: []
  type: TYPE_TB
- en: '| > (signed) | gt | 0b0000 | le | 0b0101 |'
  prefs: []
  type: TYPE_TB
- en: '| >= (signed) | ge | 0b0100 | lt | 0b0001 |'
  prefs: []
  type: TYPE_TB
- en: '| < (signed) | lt | 0b0001 | ge | 0b0100 |'
  prefs: []
  type: TYPE_TB
- en: '| <= (signed) | le | 0b0101 | gt | 0b0000 |'
  prefs: []
  type: TYPE_TB
- en: '| Same as hs | cs | 0b0010 | cc | 0b0000 |'
  prefs: []
  type: TYPE_TB
- en: '| Same as lo | cc | 0b0000 | cs | 0b0010 |'
  prefs: []
  type: TYPE_TB
- en: '| N/A | vs | 0b0001 | vc | 0b0000 |'
  prefs: []
  type: TYPE_TB
- en: '| N/A | vc | 0b0000 | vs | 0b0001 |'
  prefs: []
  type: TYPE_TB
- en: '| N/A | mi | 0b1000 | pl | 0b0000 |'
  prefs: []
  type: TYPE_TB
- en: '| N/A | pl | 0b0000 | mi | 0b1000 |'
  prefs: []
  type: TYPE_TB
- en: Because keeping the flag settings for the third ccmp operand straight in your
    mind is difficult and error-prone, the *aoaa.inc* include file contains several
    defines to make it easy to choose these values, as well as some defines for opposite
    conditions. [Table 6-6](chapter6.xhtml#tab6-6) lists these defines and their values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-6: NZCV Constant Defines'
  prefs: []
  type: TYPE_NORMAL
- en: '| Condition | Define | Value |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| eq | cceq | 0b0100 (nZcv) |'
  prefs: []
  type: TYPE_TB
- en: '| ne | ccne | 0b0000 (nzcv) |'
  prefs: []
  type: TYPE_TB
- en: '| hi | cchi | 0b0010 (nzCv) |'
  prefs: []
  type: TYPE_TB
- en: '| hs | cchs | 0b0110 (nZCv) |'
  prefs: []
  type: TYPE_TB
- en: '| lo | cclo | 0b0000 (nzcv) |'
  prefs: []
  type: TYPE_TB
- en: '| ls | ccls | 0b0100 (nZcv) |'
  prefs: []
  type: TYPE_TB
- en: '| gt | ccgt | 0b0000 (nzcv) |'
  prefs: []
  type: TYPE_TB
- en: '| ge | ccge | 0b0100 (nZcv) |'
  prefs: []
  type: TYPE_TB
- en: '| lt | cclt | 0b0001 (nzcV) |'
  prefs: []
  type: TYPE_TB
- en: '| le | ccle | 0b0101 (nZcV) |'
  prefs: []
  type: TYPE_TB
- en: '| cs | cccs | 0b0010 (nzCv) |'
  prefs: []
  type: TYPE_TB
- en: '| cc | cccc | 0b0000 (nzcv) |'
  prefs: []
  type: TYPE_TB
- en: '| vs | ccvs | 0b0001 (nzcV) |'
  prefs: []
  type: TYPE_TB
- en: '| vc | ccvc | 0b0000 (nzcV) |'
  prefs: []
  type: TYPE_TB
- en: '| mi | ccmi | 0b1000 (Nzcv) |'
  prefs: []
  type: TYPE_TB
- en: '| pl | ccpl | 0b0000 (nzcv) |'
  prefs: []
  type: TYPE_TB
- en: '[Table 6-7](chapter6.xhtml#tab6-7) lists some common antonyms (opposite conditions).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-7: NZCV Antonym Constants'
  prefs: []
  type: TYPE_NORMAL
- en: '| Condition | Define | Same as |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Not hi | ccnhi | ccls |'
  prefs: []
  type: TYPE_TB
- en: '| Not hs | ccnhs | cclo |'
  prefs: []
  type: TYPE_TB
- en: '| Not lo | ccnlo | cchs |'
  prefs: []
  type: TYPE_TB
- en: '| Not ls | ccnls | cchi |'
  prefs: []
  type: TYPE_TB
- en: '| Not gt | ccngt | ccle |'
  prefs: []
  type: TYPE_TB
- en: '| Not ge | ccnge | cclt |'
  prefs: []
  type: TYPE_TB
- en: '| Not lt | ccnlt | ccge |'
  prefs: []
  type: TYPE_TB
- en: '| Not le | ccnle | ccgt |'
  prefs: []
  type: TYPE_TB
- en: Using these symbols instead of constants for the immediate ccmp instruction
    operand can make your code easier to read and understand.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes specifying the opposite condition in one of the conditional instructions
    can create confusion. It’s easy to think that the opposite of “less than” is “greater
    than” when it’s actually “greater than or equal,” for example. To help reduce
    this confusion, the *aoaa.inc* include file also provides defines for several
    opposite conditions, as listed in [Table 6-8](chapter6.xhtml#tab6-8).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-8: Opposite Condition Defines'
  prefs: []
  type: TYPE_NORMAL
- en: '| Condition | Opposite define |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| lo | nlo (same as hs) |'
  prefs: []
  type: TYPE_TB
- en: '| ls | nls (same as hi) |'
  prefs: []
  type: TYPE_TB
- en: '| hi | nhi (same as ls) |'
  prefs: []
  type: TYPE_TB
- en: '| hs | nhs (same as lo) |'
  prefs: []
  type: TYPE_TB
- en: '| gt | ngt (same as le) |'
  prefs: []
  type: TYPE_TB
- en: '| ge | nge (same as lt) |'
  prefs: []
  type: TYPE_TB
- en: '| lt | nlt (same as ge) |'
  prefs: []
  type: TYPE_TB
- en: '| le | nle (same as gt) |'
  prefs: []
  type: TYPE_TB
- en: By using the *aoaa.inc* definitions, you can make your code easier to read and
    understand.
  prefs: []
  type: TYPE_NORMAL
- en: 6.5.2 Implementing Disjunction Using ccmp
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The conditional comparison can also be used to simulate disjunction (logical
    OR). Consider the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the translation of this expression to assembly language:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the conditional compare instruction tests for the not equal condition.
    If x is equal to y, you don’t need to do this comparison. In that case, the ccmp
    instruction will load 0b0100 into the condition codes, which sets Z to 1 and clears
    all the other flags. When the cset instruction tests for less than or equal, the
    equal condition (Z = 1) exists, setting W0 (bb) to 1\. Comparing a and d plays
    no role in the computation of bb’s value.
  prefs: []
  type: TYPE_NORMAL
- en: If x does not equal y, the ne condition will exist when the program executes
    the ccmp instruction. Therefore, ccmp will compare a and d and set the condition
    code bits on the basis of that comparison. At that point, the cset instruction
    will set bb’s value based on the comparison of a and d.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following algorithm describes how to convert an expression containing disjunction
    into ARM assembly language using a conditional comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the four steps to follow for this conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.  Compare the operands on the left-hand side of the disjunction operator (operator
    is cc1).
  prefs: []
  type: TYPE_NORMAL
- en: 2.  Immediately after the first cmp instruction, execute a ccmp instruction,
    supplying the opposite of cc1 as the conditional field (return to [Table 6-5](chapter6.xhtml#tab6-5)
    to find the opposite conditions).
  prefs: []
  type: TYPE_NORMAL
- en: '3.  Choose the corresponding #nzcv encoding from the regular column in [Table
    6-5](chapter6.xhtml#tab6-5) to match cc2. The full ccmp instruction should be
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '4.  The last instruction in the sequence should test cc2. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'If cc1 succeeds, the ccmp instruction will set the flags to the #nzcvop value
    and not compare c against d, because you’ve chosen the opposite of cc1 for the
    ccmp condition. As you want the Boolean expression to yield true in this situation,
    choose an #nzcvop value that is the same as cc2 so that the following test (for
    example, cset) produces a true result. If cc1 is false upon executing the ccmp
    instruction, ccmp will compare c and d and set the flags appropriate for the following
    test.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.5.3 Handling Complex Boolean Expressions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You can extend the Boolean expressions by adding additional ccmp instructions
    to the sequence. Just keep in mind that, at least in C/C++, conjunction has higher
    precedence than disjunction, so you must modify your order of evaluation to handle
    conjunction first when expressions contain both operators.
  prefs: []
  type: TYPE_NORMAL
- en: Also note that the ccmp scheme uses *complete Boolean evaluation* (meaning it
    evaluates every subterm of the Boolean expression), whereas the C++ programming
    language uses *short-circuit Boolean evaluation* (which may not compute all subterms).
    [Chapter 7](chapter7.xhtml) covers these two forms in greater detail, but for
    now, just know that the two forms may produce different results.
  prefs: []
  type: TYPE_NORMAL
- en: 6.6 Machine and Arithmetic Idioms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An *idiom* is an idiosyncrasy (a peculiarity). Several arithmetic operations
    and ARM instructions have idiosyncrasies that you can take advantage of when writing
    assembly language code. Some people refer to the use of machine and arithmetic
    idioms as *tricky programming* that you should always avoid in well-written programs.
    While it is wise to avoid tricks just for the sake of tricks, many machine and
    arithmetic idioms are well known and commonly found in assembly language programs.
    This section provides an overview of the idioms you’ll see most often.
  prefs: []
  type: TYPE_NORMAL
- en: 6.6.1 Multiplying Without mul
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When multiplying by a constant, you can sometimes write equivalent code by using
    shifts, additions, and subtractions in place of multiplication instructions. Although
    performance differs little between using a mul instruction and other arithmetic
    instructions, some addressing mode variants involving shifts can spare you an
    extra multiply instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember, a lsl instruction computes the same result as multiplying the specified
    operand by 2\. Shifting to the left two bit positions multiplies the operand by
    4\. Shifting to the left three bit positions multiplies the operand by 8\. In
    general, shifting an operand to the left *n* bits multiplies it by 2*^n*. You
    can multiply any value by a constant by using a series of shifts and additions
    or shifts and subtractions. For example, to multiply the W0 register by 10, you
    need only multiply it by 8 and then add 2 times the original value. That is, 10
    × W0 = 8 × W0 + 2 × W0\. Use the following code to accomplish this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: The first instruction multiplies W0 by 2, so when the second instruction shifts
    W0 2 bits to the left, it’s actually shifting the original W0 value to the left
    by 3 bits.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the instruction timings, you’ll see that the multiply instruction
    executes at the same speed as the lsl or add instructions, so this second sequence
    isn’t faster. However, if you have to load the constant 10 into a register to
    do the multiplication by 10, this sequence is no slower. If you’ve already done
    the shift as part of another calculation, this sequence could turn out to be faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also use subtraction with shifts to perform a multiplication operation.
    Consider the following multiplication by 7:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Beginning assembly language programmers commonly make the error of subtracting
    or adding 1 or 2 rather than W0 × 1 or W0 × 2\. The following does not compute
    W0 × 7:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: Rather, this code computes (8 × W0) – 1, which is entirely different (unless,
    of course, W0 = 1). Beware of this pitfall when using shifts, additions, and subtractions
    to perform multiplication operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Operand2 addressing mode variations, particularly those involving lsl,
    are quite useful for combining shifts along with other arithmetic operations.
    For example, consider the following pair of instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'You can easily replace this by a single instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: Because RISC CPUs, such as the ARM, tend to execute most instructions in a single
    CPU clock cycle, using *strength-reduction optimizations* like substituting shifts
    and adds for multiplication rarely pays off. Generally, a single shift instruction
    (for a multiplication by a power of 2) may produce better results than mul; beyond
    that, it’s unlikely to improve the speed, unless you need those shifts and adds
    for other calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 6.6.2 Dividing Without sdiv or udiv
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Just as the lsl instruction is useful for simulating a multiplication by a power
    of 2, the lsr and asr instructions can simulate a division by a power of 2\. Unfortunately,
    you cannot easily use shifts, additions, and subtractions to perform division
    by an arbitrary constant. Therefore, this trick is useful only when dividing by
    powers of 2\. Also, don’t forget that the asr instruction rounds toward negative
    infinity, unlike the sdiv instruction, which rounds toward 0.
  prefs: []
  type: TYPE_NORMAL
- en: On the ARM64 CPU, the division instructions tend to take about twice as long
    as other instructions to execute. Therefore, if you can simulate a division by
    a power of 2 by using a single shift-right instruction, your code will run a little
    faster. You can also divide by a value by multiplying by its reciprocal. This
    is usually faster than division, since the multiply instruction is faster than
    the divide instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'To multiply by a reciprocal when dealing with integers, you must cheat. If
    you want to multiply by 1/10, there is no way you can load the value 1/10 into
    an ARM integer register prior to performing the multiplication. It won’t work
    to multiply 1/10 by 10, perform the multiplication, and divide the result by 10
    to get the final result. In fact, this would make performance worse, because you’re
    now doing a multiplication by 10 as well as a division by 10\. However, suppose
    you multiply 1/10 by 65,536 (6,554), perform the multiplication, and then divide
    by 65,536\. Consider the following code that divides W0 by 10:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: This code leaves W0 / 10 in the W0 register. To understand how this works, consider
    what happens when you use the mul instruction to multiply W0 by 65,536 (0x1_0000).
    This moves the LO half word of W0 into the HO half word and sets the LO half word
    to 0 (a multiplication by 0x1_0000 is equivalent to a shift left by 16 bits).
    Multiplying by 6,554 (65,536 divided by 10) puts W0 divided by 10 into the HO
    half word of the W0 register.
  prefs: []
  type: TYPE_NORMAL
- en: Multiplying by a reciprocal works well only when dividing by a constant, such
    as 10\. While you could coerce the calculation with multiple instructions to divide
    a register by a nonconstant value, the udiv/sdiv instructions would certainly
    be faster by that point; it’s questionable whether multiplying by a reciprocal
    is faster than a division.
  prefs: []
  type: TYPE_NORMAL
- en: 6.6.3 Implementing Modulo-N Counters with AND
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To implement a counter variable that counts up to 2*^n* – 1 and then resets
    to 0, use the following code
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'where nBits is a binary value containing *n* bits of 1s right-justified in
    the number. For example, to create a counter that cycles from 0 to 15 (2⁴ – 1),
    you could use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 6.6.4 Avoiding Needlessly Complex Machine Idioms
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The machine idioms you’ve just learned work well to improve performance on older
    complex instruction set computers (CISCs) that typically take a varying number
    of CPU clock cycles to execute each instruction. Complex instructions like division
    can take upward of 50 clock cycles on an x86 CPU, for example. RISC CPUs, such
    as the ARM, try to execute instructions in one clock cycle. While the ARM doesn’t
    always achieve this (sdiv and udiv are a little slower, for example), the additional
    time required doesn’t justify replacing the instruction with a long sequence of
    other instructions.
  prefs: []
  type: TYPE_NORMAL
- en: Using machine idioms makes your code harder to read and understand. If using
    a machine idiom offers no clear performance benefit, stick with using easier-to-understand
    code. Those who work on your project afterward (including yourself, in the future)
    will thank you.
  prefs: []
  type: TYPE_NORMAL
- en: 6.7 Floating-Point and Finite-Precision Arithmetic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before discussing how the ARM CPU implements floating-point arithmetic, it is
    worthwhile to first describe the mathematical theory behind floating-point arithmetic
    and the problems you will encounter when using it. This section presents a simplified
    model to explain floating-point arithmetic and why you cannot apply standard algebraic
    rules to calculations involving it.
  prefs: []
  type: TYPE_NORMAL
- en: 6.7.1 Basic Floating-Point Terminology
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Integer arithmetic does not let you represent fractional numeric values. Therefore,
    modern CPUs support an approximation of *real* arithmetic: *floating-point arithmetic*.
    To represent real numbers, most floating-point formats employ scientific notation
    and use a certain number of bits to represent a mantissa and a smaller number
    of bits to represent an exponent.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, in the number 3.456e+12, the mantissa consists of 3.456, and the
    exponent digits are 12\. Because the number of bits is fixed in computer-based
    representations, computers can represent only a certain number of digits (known
    as *significant digits*) in the mantissa. For example, if a floating-point representation
    could handle only three significant digits, then the fourth digit in 3.456e+12
    (the 6) could not be accurately represented with that format, as three significant
    digits can represent only 3.45e+12 or 3.46e+12 correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Because computer-based floating-point representations also use a finite number
    of bits to represent the exponent, that exponent also has a limited range of values,
    approximately ranging from 10 ^(± 38) for the single-precision format to about
    10 ^(± 308) for the double-precision format. This is known as the *dynamic range*
    of the value. Denormalized numbers (which I’ll define shortly) can represent values
    as small as ±4.94066 × 10^(–324).
  prefs: []
  type: TYPE_NORMAL
- en: 6.7.2 Limited-Precision Arithmetic and Accuracy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A big problem with floating-point arithmetic is that it does not follow the
    standard rules of algebra. Normal algebraic rules apply only to *infinite-precision*
    arithmetic. Therefore, if you translate an algebraic formula into code, that code
    might produce different results from what you would (mathematically) expect. This
    can introduce defects in your software.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the simple statement *x* = *x* + 1, where *x* is an integer. On any
    modern computer, this statement follows the normal rules of algebra *as long as
    overflow does not occur.* That is, this statement is valid only for certain values
    of *x* (*minint* ≤ *x* < *maxint*). Most programmers do not have a problem with
    this because they are well aware that integers in a program do not follow the
    standard algebraic rules (for example, 5 / 2 does not equal 2.5).
  prefs: []
  type: TYPE_NORMAL
- en: Integers do not follow the standard rules of algebra because the computer represents
    them with a finite number of bits. You cannot represent any of the (integer) values
    above the maximum integer or below the minimum integer. Floating-point values
    suffer from this same problem, only worse. After all, integers are a subset of
    real numbers. Therefore, the floating-point values must represent the same infinite
    set of integers. However, an infinite number of real values exist between any
    two integer values. In addition to having to limit your values between a maximum
    and minimum range, you cannot represent all the values between any pair of integers
    either.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the impact of limited-precision arithmetic, this chapter adopts
    a simplified decimal floating-point format for our examples. This format provides
    a mantissa with three significant digits and a decimal exponent with two digits.
    The mantissa and exponents are both signed values, as shown in [Figure 6-1](chapter6.xhtml#fig6-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-1: A floating-point format'
  prefs: []
  type: TYPE_NORMAL
- en: When adding and subtracting two numbers in scientific notation, you must adjust
    the two values so that their exponents are the same. Multiplication and division
    don’t require the exponents to be the same; instead, the exponent after a multiplication
    is the sum of the two operand exponents, and the exponent after a division is
    the difference of the dividend and divisor’s exponents.
  prefs: []
  type: TYPE_NORMAL
- en: For example, when adding 1.2e1 and 4.5e0, you must adjust the values so that
    they have the same exponent. One way to do this is to convert 4.5e0 to 0.45e1
    and then add, producing 1.65e1\. Because the computation and result require only
    three significant digits, you can compute the correct result via the representation
    shown in [Figure 6-1](chapter6.xhtml#fig6-1).
  prefs: []
  type: TYPE_NORMAL
- en: However, suppose you want to add the two values 1.23e1 and 4.56e0\. Although
    both values can be represented using the three-significant-digit format, the computation
    and result do not fit into three significant digits. That is, 1.23e1 + 0.456e1
    requires four digits of precision in order to compute the correct result of 1.686,
    so you must either *round* or *truncate* the result to three significant digits.
    Rounding generally produces the most accurate result, so round the result to obtain
    1.69e1.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, the rounding does not occur after adding the two values together (that
    is, producing the sum 1.686e1 and then rounding this to 1.69e1), but rather when
    converting 4.56e0 to 0.456e1, because four digits of precision are required to
    maintain the value 0.456e1\. Therefore, during the conversion, you have to round
    0.456e1 to 0.46e1 so that the result fits into three significant digits. The sum
    of 1.23e1 and 0.46e1 then produces the final rounded sum of 1.69e1.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the lack of *precision* (the number of digits or bits maintained
    in a computation) affects the *accuracy* (the correctness of the computation).
    In the addition/subtraction example, you could round the result because you maintained
    four significant digits *during* the calculation (specifically, when converting
    4.56e0 to 0.456e1). If your floating-point calculation had been limited to three
    significant digits during computation, you would have had to truncate the last
    digit of the smaller number, obtaining 0.45e1 and producing a sum of 1.68e1, a
    value that is even less accurate.
  prefs: []
  type: TYPE_NORMAL
- en: To improve the accuracy of floating-point calculations, it is useful to maintain
    one or more extra digits for use during the calculation, such as the extra digit
    used to convert 4.56e0 to 0.456e1\. Extra digits available during a computation
    are known as *guard digits* (or *guard bits* in the case of a binary format).
    They greatly enhance accuracy during a long chain of computations.
  prefs: []
  type: TYPE_NORMAL
- en: 6.7.3 Errors in Floating-Point Calculations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In a sequence of floating-point operations, errors can accumulate and greatly
    affect the computation itself. For example, suppose you were to add 1.23e3 to
    1.00e0\. Adjusting the numbers so their exponents are the same before the addition
    produces 1.23e3 + 0.001e3\. The sum of these two values, even after rounding,
    is 1.23e3\. This might seem perfectly reasonable; after all, you can maintain
    only three significant digits, so adding in a small value shouldn’t affect the
    result at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, suppose you were to add 1.00e0 to 1.23e3 *ten times* (though not in
    the same calculation, where guard digits could maintain the fourth digit during
    the calculation). The first time you add 1.00e0 to 1.23e3, you get 1.23e3\. You
    get this same result the second, third, fourth ... and tenth times you add 1.00e0
    to 1.23e3\. On the other hand, had you added 1.00e0 to itself 10 times, then added
    the result (1.00e1) to 1.23e3, you would have gotten a different result, 1.24e3\.
    Keep in mind this important guideline for limited-precision arithmetic:'
  prefs: []
  type: TYPE_NORMAL
- en: When performing complex operations, watch the order of evaluation, as it can
    affect the accuracy of the result.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You’ll get more accurate results if the relative magnitudes (the exponents)
    are close to one another when adding and subtracting floating-point values. If
    you’re performing a chain calculation involving addition and subtraction, attempt
    to group the values appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: 'When computing addition and subtraction, you can also wind up with *false precision*.
    Consider the computation 1.23e0 – 1.22e0, which produces 0.01e0\. Although the
    result is mathematically equivalent to 1.00e – 2, this latter form suggests that
    the last two digits are exactly 0\. Unfortunately, you have only a single significant
    digit at this time (remember, the original result was 0.01e0, and those two leading
    0s were significant digits). Indeed, some floating-point unit (FPU) or software
    packages might actually insert random digits (or bits) into the LO positions.
    This highlights a second important rule concerning limited-precision arithmetic:'
  prefs: []
  type: TYPE_NORMAL
- en: When subtracting two numbers with the same signs (or adding two numbers with
    different signs), be aware that the result may contain high-order significant
    digits (bits) that are 0\. This reduces the number of significant digits (bits)
    by a like amount in the final result. If possible, try to arrange your calculations
    to avoid this.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'By themselves, multiplication and division do not produce particularly poor
    results. However, they tend to multiply any error that already exists in a value.
    For example, if you multiply 1.23e0 by 2 when you should be multiplying 1.24e0
    by 2, the result is even less accurate. This leads to a third important rule for
    working with limited-precision arithmetic:'
  prefs: []
  type: TYPE_NORMAL
- en: When performing a chain of calculations involving addition, subtraction, multiplication,
    and division, try to perform the multiplication and division operations first.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Often, by applying normal algebraic transformations, you can arrange a calculation
    so the multiply and divide operations occur first. For example, suppose you want
    to compute *x* * (*y* + *z*). Normally, you would add *y* and *z* together and
    multiply their sum by *x*. However, your results will be a little more accurate
    if you transform *x* * (*y* + *z*) to get *x* * *y* + *x* * z and compute the
    result by performing the multiplications first. Of course, the drawback is that
    you must now perform two multiplications rather than one, so the result may be
    slower.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiplication and division have their own problems. When multiplying two very
    large or very small numbers, it is quite possible for *overflow* or *underflow*
    to occur. The same situation occurs when dividing a small number by a large number,
    or dividing a large number by a small (fractional) number. This brings us to a
    fourth rule to follow when multiplying or dividing values:'
  prefs: []
  type: TYPE_NORMAL
- en: When multiplying and dividing sets of numbers, try to arrange the multiplications
    so that they multiply large and small numbers together; likewise, try to divide
    numbers that have the same relative magnitudes.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 6.7.4 Floating-Point Value Comparisons
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Given the inaccuracies present in any computation (including converting an input
    string to a floating-point value), you should *never* compare two floating-point
    values to see if they are equal. In a binary floating-point format, different
    computations that produce the same (mathematical) result may differ in their least
    significant bits. For example, 1.31e0 + 1.69e0 should produce 3.00e0\. Likewise,
    1.50e0 + 1.50e0 should also produce 3.00e0\. However, if you were to compare (1.31e0
    + 1.69e0) against (1.50e0 + 1.50e0), you might find out that these sums are *not*
    equal to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test for equality succeeds if and only if all bits (or digits) in the two
    operands are exactly the same. Because this is not necessarily true after two
    different floating-point computations that should produce the same result, a straight
    test for equality may not work. Instead, use the following test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Another common way to handle this same comparison is to use a statement of
    this form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'In these statements, error should be a value slightly greater than the largest
    amount of error that will creep into your computations. The exact value will depend
    on the particular floating-point format you use. In short, follow this final rule:'
  prefs: []
  type: TYPE_NORMAL
- en: When comparing two floating-point numbers, always compare one value to see whether
    it is in the range given by the second value plus or minus a small error value.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Many other little problems can occur when using floating-point values. This
    book points out only some of the major problems and will make you aware that you
    cannot treat floating-point arithmetic like real arithmetic because of the inaccuracies
    present in limited-precision arithmetic. A good text on numerical analysis or
    even scientific computing can help fill in the details. If you plan to work with
    floating-point arithmetic in any language, take the time to study the effects
    of limited-precision arithmetic on your computations (see section 6.13, “For More
    Information,” on [page 352](chapter6.xhtml#pg_352)).
  prefs: []
  type: TYPE_NORMAL
- en: Now that you’ve seen the theory behind floating-point arithmetic, we’ll review
    the ARM’s implementation of floating-point.
  prefs: []
  type: TYPE_NORMAL
- en: 6.8 Floating-Point Arithmetic on the ARM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When the ARM CPU was first designed, floating-point arithmetic was among the
    set of “complex” instructions that RISC CPUs avoided. Those who required floating-point
    arithmetic were forced to implement it in software. As time passed, it became
    clear that high-performance systems required fast floating-point arithmetic, so
    it was added to the ARM’s instruction set.
  prefs: []
  type: TYPE_NORMAL
- en: The ARM64 supports the IEEE single- and double-precision floating-point formats
    (see section 2.13, “IEEE Floating-Point Formats,” on [page 93](chapter2.xhtml#pg_93)),
    as well as a 16-bit half-precision floating-point format that appeared in later
    revisions of the IEEE standard. To support floating-point arithmetic, the ARM
    provides an extra set of registers and augments the instruction set with suitable
    floating-point instructions. Originally, these types of instructions were handled
    by coprocessors—separate chips that handled floating-point instructions (while
    the main CPU handled integer operations). In the ARM64 architecture, the FPU is
    built into the main CPU’s integrated circuit.
  prefs: []
  type: TYPE_NORMAL
- en: The following subsections introduce the floating-point register set, the floating-point
    status register, and the floating-point control register. These are the programmer-visible
    components of the floating-point hardware on the ARM CPU.
  prefs: []
  type: TYPE_NORMAL
- en: 6.8.1 Neon Registers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To support floating-point arithmetic, the ARM64 provides a second set of 32
    registers specifically tailored to hold floating-point and other values. These
    are known as the *Neon registers* because, in addition to supporting scalar floating-point
    (FP) arithmetic, they also support vector arithmetic using the Neon instruction
    set extensions, covered in [Chapter 11](chapter11.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: 'The 32 main FP/Neon registers are 128 bits each. Just as the general-purpose
    registers are divided into two sets based on their size (W*n* and X*n*), the FP/Neon
    registers are broken into five groups based on their size:'
  prefs: []
  type: TYPE_NORMAL
- en: '**V0 to V31**    The 128-bit *vector* registers (for Neon instructions), also
    referenced as Q0 to Q31, the qword registers. The V*n* names support special syntax
    for vector operations.'
  prefs: []
  type: TYPE_NORMAL
- en: '**D0 to D31**    The 64-bit *double-precision* floating-point registers.'
  prefs: []
  type: TYPE_NORMAL
- en: '**S0 to S31**     The 32-bit *single-precision* floating-point registers.'
  prefs: []
  type: TYPE_NORMAL
- en: '**H0 to H31**    The 16-bit *half-precision* floating-point registers.'
  prefs: []
  type: TYPE_NORMAL
- en: '**B0 to B31**    The 8-bit *byte* registers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the 32 main registers, this set includes two special-purpose
    floating-point registers: the floating-point status register (FPSR) and the floating-point
    control register (FPCR), shown in [Figure 6-2](chapter6.xhtml#fig6-2). You’ll
    learn more about these registers in the following subsections.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-2: The FP/Neon registers'
  prefs: []
  type: TYPE_NORMAL
- en: The B*n*, H*n*, S*n*, D*n*, and V*n* registers overlay one another, as shown
    in [Figure 6-3](chapter6.xhtml#fig6-3).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-3: The FP/Neon register overlays'
  prefs: []
  type: TYPE_NORMAL
- en: For historical reasons, the even-numbered single-precision registers (S0, S2,
    ..., S30) are mapped to bits 0 through 31 in D0 through D15, and the odd-numbered
    single-precision registers are mapped to bits 32 through 64\. No S*n* registers
    are mapped to D16 through D31 (see [Figure 6-4](chapter6.xhtml#fig6-4)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-4: How Sn registers overlay Dn registers'
  prefs: []
  type: TYPE_NORMAL
- en: The following sections concentrate mainly on the D*n* and S*n* register sets.
    This book doesn’t discuss half-precision floating-point arithmetic in depth, as
    it’s used mainly by graphics processing units (GPUs) and certain graphics routines.
    The floating-point hardware doesn’t actually work with half-precision values—it
    only allows you to convert between half- and single- or double-precision values.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the ARM floating-point instructions operate on the D*n* or S*n* registers.
    This chapter collectively refers to these registers as F*n*, meaning you can substitute
    any double- or single-precision register for F*n*. I will also note exceptions
    as needed. Vector registers (V*n*) are the subject of [Chapter 11](chapter11.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: 6.8.2 Control Register
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *floating-point control register (FPCR)* specifies how certain floating-point
    operations take place. Although this register is 32 bits, only 6 bits are used,
    as you can see in [Figure 6-5](chapter6.xhtml#fig6-5).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-5: The FPCR layout'
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 6-9](chapter6.xhtml#tab6-9) describes the meaning of each of these bits.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-9: FPCR Bits'
  prefs: []
  type: TYPE_NORMAL
- en: '| Bit(s) | Name | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 19 | FZ16 | Flush-to-zero mode for half-precision arithmetic. 0 = disabled,
    1 = enabled. This replaces denormalized values with 0\. The result may not be
    as precise, but the instructions may execute faster. |'
  prefs: []
  type: TYPE_TB
- en: '| 22, 23 | Rmode | Rounding mode: 00 = round to nearest, 01 = round to +infinity,
    10 = round to –infinity, 11 = truncate (round toward 0). |'
  prefs: []
  type: TYPE_TB
- en: '| 24 | FZ | Flush-to-zero mode for single- and double-precision arithmetic.
    |'
  prefs: []
  type: TYPE_TB
- en: '| 25 | DN | Default NaN (not a number) mode. 0 = disable default NaN mode,
    1 = enable. When disabled, NaNs propagate through arithmetic operations; when
    enabled, invalid operations return the default NaN. |'
  prefs: []
  type: TYPE_TB
- en: '| 26 | AHP | Alternate half-precision bit. Enables (1) alternate half-precision
    mode or (0) IEEE half-precision mode. |'
  prefs: []
  type: TYPE_TB
- en: For the most part, you’ll leave all these bits set to 0\. Setting Rmode to 0b11
    is a reasonable change when you want to truncate rather than round a floating-point
    calculation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To manipulate the FPCR register, use the mrs (move system to register) and
    msr (move register to system) instructions, specifying FPCR as the system register:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'For example, to clear all the (defined) bits in the FPCR, you’d use the following
    instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'Set the rounding mode to truncate with the following instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: The default FPCR settings are unknown on a warm reset, so you should always
    initialize this register before performing floating-point operations.
  prefs: []
  type: TYPE_NORMAL
- en: 6.8.3 Status Register
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The FPSR holds status information about ARM floating-point hardware. Reading
    this register provides the current floating-point status, while writing to it
    allows you to clear exception conditions. Although this is a 32-bit register,
    only 11 bits are defined and, in fact, only 7 of those are used in 64-bit mode
    (see [Figure 6-6](chapter6.xhtml#fig6-6)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure6-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-6: The FPSR layout'
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 6-10](chapter6.xhtml#tab6-10) describes the purpose of each of the bits
    in the FPSR.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-10: FPSR Bits'
  prefs: []
  type: TYPE_NORMAL
- en: '| Bit(s) | Name | Definition |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | IOC | Invalid operation cumulative flag. This bit is set when the result
    of an operation has no mathematical value or cannot be represented. |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | DZC | Division by zero cumulative flag. This bit is set when a division
    by zero occurs. |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | OFC | Overflow cumulative flag. This bit is set when a floating-point
    operation causes an overflow situation. |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | UFC | Underflow cumulative flag. This bit is set when underflow occurs
    during an arithmetic operation. |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | IXC | Inexact cumulative flag. This bit is set (often!) when a floating-point
    operation produces an inexact result. |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | IDC | Input denormal cumulative flag. This bit is set when a denormalized
    input operand is replaced in the computation by a zero. |'
  prefs: []
  type: TYPE_TB
- en: '| 27 | QC | Saturation cumulative flag. This flag is set when a saturation
    instruction clips a value. See [Chapter 11](chapter11.xhtml) for a discussion
    of the saturating instructions. |'
  prefs: []
  type: TYPE_TB
- en: '| 28–31 | N, C, Z, V | These flags are used only in 32-bit mode. In 64-bit
    mode, the floating-point comparisons and other instructions directly set the N,
    Z, C, and V flags in the PSTATE register. |'
  prefs: []
  type: TYPE_TB
- en: 'You can read and write the FPSR with the mrs and msr instructions, using FPSR
    as the system register name. Read the FPSR to determine if any floating-point
    exceptions have occurred, and write the FPSR to clear the exception bits (by writing
    0s to the affected bits in the register). For example the following code clears
    the Invalid Operation Cumulative flag in the FPSR:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 6.9 Floating-Point Instructions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The FPU adds many instructions to the ARM instruction set. I will classify these
    as data movement instructions, conversions, arithmetic instructions, comparisons,
    and miscellaneous instructions. This section describes each instruction in these
    categories.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.1 FPU Data Movement Instructions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *data movement instructions* transfer data between the internal FPU registers
    and memory. The instructions in this category are ldr/ldur, str/stur, ldp/ldnp,
    stp/stnp, and fmov.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.1.1 ldr/ldur and str/stur
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The ldr and str instructions load one of the FPU registers from a memory location,
    using the normal memory addressing modes. The ldur/stur instructions force an
    unscaled load or store operation, for cases where the assembler might choose a
    scaled indirect-plus-offset mode. Generally, rather than using ldur/stur, you’d
    let the assembler pick the appropriate underlying machine coding for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can specify any of the FPU register names when using this instruction.
    For example, the following code loads the specified floating-point registers from
    memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 6.9.1.2 ldp/ldnp and stp/stnp
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The ldp and stp instructions work similarly to their integer counterparts with
    floating-point registers: they load or store a pair of registers at a time. These
    instructions do not support the H*n* or B*n* registers; you can load only word,
    dword, or qword FPU registers using these instructions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following examples demonstrate loading 256, 128, and 64 bits from memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: The ldnp and stnp instructions do nontemporal loads and stores. This informs
    the CPU that you don’t intend to access the specified memory location again in
    the near future, so the CPU won’t copy the data into its cache (a convenient example
    of what you can do in assembly and not in an HLL). This can improve performance
    by helping to prevent a situation known as *thrashing*, in which the CPU constantly
    moves data in and out of the cache memory.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.1.3 fmov
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The fmov instruction transfers data between two like-sized floating-point registers
    (where both registers are either 32 or 64 bits), or between a 32- or 64-bit general-purpose
    (GP) register and a like-sized floating-point register. Here is the allowable
    syntax for this instruction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: Moving a general-purpose register into a floating-point register does not convert
    an integer value in the GP register to a floating-point value; such an fmov operation
    assumes that the GP register contains the bit pattern for a floating-point number.
    Likewise, moving a floating-point register into a general-purpose register does
    not convert the floating-point value into an integer.
  prefs: []
  type: TYPE_NORMAL
- en: '##### 6.9.1.4 fmov with Immediate Operand'
  prefs: []
  type: TYPE_NORMAL
- en: The ARM provides an fmov instruction that allows a very limited immediate operand.
    The syntax is as follows
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: where fimm is a floating-point constant from a very small set of possible values.
    The allowable values are ±*n* / 16 × 2*^m*, where 16 ≤ *n* ≤ 31 and –3 ≤ *m* ≤
    4\. This means you can represent values such as 1.0 or –2.0 but cannot represent
    1.2345e5.
  prefs: []
  type: TYPE_NORMAL
- en: 'You cannot represent the value 0.0 with this immediate form. However, you can
    load 0.0 into a floating-point register by using one of the following two instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to load an arbitrary floating-point constant into a register, you
    will have to stick that constant into a memory location, using the .single or
    .double directive, and load the register from that location. Unfortunately, the
    ldr instruction doesn’t accept floating-point immediate operands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Fortunately, the PC-relative addressing mode does work, so you can access memory
    locations you’ve initialized in your .text section (preferably in the .pool area),
    as the following example demonstrates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: By adding the .pool directive, Gas can embed other assembler-generated constants
    in this area too.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.2 FPU Arithmetic Instructions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The ARM CPU provides a large set of floating-point instructions that operate
    on single-precision and double-precision floating-point values. As for the integer
    operations, most of these instructions require three (floating-point) register
    operands: a destination, a left source, and a right source.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 6-11](chapter6.xhtml#tab6-11) lists the syntax for the arithmetic instructions.
    In this table, Fd, Fn, Fm, and Fa represent floating-point registers and can be
    S*n* or D*n* (*n* = 0 to 31), depending on the precision of the instruction. For
    a given instruction, all registers must be the same size (32 or 64 bits).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-11: Floating-Point Arithmetic Instructions'
  prefs: []
  type: TYPE_NORMAL
- en: '| Instruction | Operands | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| fadd | Fd, Fn, Fm | Fd = Fn + Fm |'
  prefs: []
  type: TYPE_TB
- en: '| fsub | Fd, Fn, Fm | Fd = Fn – Fm |'
  prefs: []
  type: TYPE_TB
- en: '| fmul | Fd, Fn, Fm | Fd = Fn × Fm |'
  prefs: []
  type: TYPE_TB
- en: '| fnmul | Fd, Fn, Fm | Fd = –(Fn × Fm) |'
  prefs: []
  type: TYPE_TB
- en: '| fmadd | Fd, Fn, Fm, Fa | Fd = Fa + Fn × Fm |'
  prefs: []
  type: TYPE_TB
- en: '| fmsub | Fd, Fn, Fm, Fa | Fd = Fa – Fn × Fm |'
  prefs: []
  type: TYPE_TB
- en: '| fnmadd | Fd, Fn, Fm, Fa | Fd = –(Fa + Fn × Fm) |'
  prefs: []
  type: TYPE_TB
- en: '| fnmsub | Fd, Fn, Fm, Fa | Fd = –(Fa – Fn × Fm) |'
  prefs: []
  type: TYPE_TB
- en: '| fdiv | Fd, Fn, Fm | Fd = Fn / Fm |'
  prefs: []
  type: TYPE_TB
- en: '| fmax | Fd, Fn, Fm | Fd = max(Fn, Fm), NaN if either operand is NaN |'
  prefs: []
  type: TYPE_TB
- en: '| fmaxnm | Fd, Fn, Fm | Fd = max(Fn, Fm), number if other operand is (quiet)
    NaN |'
  prefs: []
  type: TYPE_TB
- en: '| fmin | Fd, Fn, Fm | Fd = min(Fn, Fm), NaN if either operand is NaN |'
  prefs: []
  type: TYPE_TB
- en: '| fminnm | Fd, Fn, Fm | Fd = min(Fn, Fm), number if other operand is (quiet)
    NaN |'
  prefs: []
  type: TYPE_TB
- en: '| fabs | Fd, Fn | Fd = fabs(Fn), absolute value |'
  prefs: []
  type: TYPE_TB
- en: '| fneg | Fd, Fn | Fd = –Fn |'
  prefs: []
  type: TYPE_TB
- en: '| fsqrt | Fd, Fn | Fd = sqrt(Fn) |'
  prefs: []
  type: TYPE_TB
- en: Many operations can raise an exception of one sort or another. For example,
    fdiv can set the DZC flag in the FPSR if a division by 0 occurs. Some operations,
    such as fsqrt, can produce an invalid result—for example, when trying to take
    the square root of a negative number. After a sequence of floating-point instructions,
    check the FPSR to see if the result obtained is valid. The FPSR bits are sticky
    and will remain set once an exception occurs; this allows you to check for an
    error at the end of a chain of calculations, rather than after each floating-point
    instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.3 Floating-Point Comparisons
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The ARM provides a floating-point compare and a conditional compare instruction.
    Both have a couple of forms
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: where nzcv and cond have the same meanings they did with the ccmp instruction.
  prefs: []
  type: TYPE_NORMAL
- en: The instructions with the e suffix raise an exception if either operand is NaN
    during the comparison. Dealing with exceptions raised by these instructions is
    beyond the scope of this book, so subsequent example code uses just the forms
    without the e suffix.
  prefs: []
  type: TYPE_NORMAL
- en: The fcmp instruction will compare an FPU register against either another FPU
    register or the immediate constant 0.0. If you need to compare against any other
    floating-point constant, you’ll have to first load that into a register. Note
    that fccmp doesn’t provide a form that allows a comparison against 0.0 (although
    you can copy XZR or WZR into another FPU register and compare against that).
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.3.1 Comparison Logic
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The fcmp instruction sets the (PSR, not FPSR) condition code bits N, Z, C, and
    V in response to the comparison, allowing you to use the conditional branches
    and other conditional instructions to test the result of the comparison. However,
    the behavior of the settings is a bit different from integer comparisons. First
    of all, there aren’t unsigned and signed comparisons (floating-point values are
    always signed); second, floating-point comparisons can be unordered.
  prefs: []
  type: TYPE_NORMAL
- en: '*Unordered comparisons* occur when one or both of two values you’re comparing
    are NaN, since two values are incomparable under those circumstances. At best,
    you can say they are not equal to each other; it’s safer simply to say the result
    is unordered and leave it at that. Generally, if the result of a comparison is
    unordered, something is seriously wrong and you’ll want to take corrective action.'
  prefs: []
  type: TYPE_NORMAL
- en: One way to avoid this issue is to use the fcmpe form, which can generate an
    exception, and leave it up to the exception handler to deal with unordered values.
    However, as noted earlier, dealing with those exceptions is beyond the scope of
    this book, so I recommend sticking with fcmp.
  prefs: []
  type: TYPE_NORMAL
- en: The fcmp instruction sets the N, Z, V, and C flags in such a way that you can
    test them for ordered and unordered results after a comparison. The good news
    is that you can handle unordered and ordered comparisons by using normal conditional
    branch and other instructions. The bad news is that the fcmp results slightly
    change the definition of those conditional branch instructions. [Table 6-12](chapter6.xhtml#tab6-12)
    describes how fcmp sets the flags.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-12: Flags Set by fcmp'
  prefs: []
  type: TYPE_NORMAL
- en: '| Condition | Meaning |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| EQ | Equal |'
  prefs: []
  type: TYPE_TB
- en: '| NE | Not equal, or unordered |'
  prefs: []
  type: TYPE_TB
- en: '| GE | Greater than or equal |'
  prefs: []
  type: TYPE_TB
- en: '| LT | Less than, or unordered |'
  prefs: []
  type: TYPE_TB
- en: '| GT | Greater than |'
  prefs: []
  type: TYPE_TB
- en: '| LE | Less than or equal, or unordered |'
  prefs: []
  type: TYPE_TB
- en: '| HI | Greater than, or unordered |'
  prefs: []
  type: TYPE_TB
- en: '| HS/CS | Greater than or equal, or unordered |'
  prefs: []
  type: TYPE_TB
- en: '| LO/CC | Less than |'
  prefs: []
  type: TYPE_TB
- en: '| LS | Less than or equal |'
  prefs: []
  type: TYPE_TB
- en: '| MI | Less than |'
  prefs: []
  type: TYPE_TB
- en: '| PL | Greater than or equal, or unordered |'
  prefs: []
  type: TYPE_TB
- en: '| VS | Unordered |'
  prefs: []
  type: TYPE_TB
- en: '| VC | Ordered |'
  prefs: []
  type: TYPE_TB
- en: 'Two points in [Table 6-12](chapter6.xhtml#tab6-12) are easy to miss:'
  prefs: []
  type: TYPE_NORMAL
- en: The fcmp instruction sets the V flag if the comparison is unordered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both signed and unsigned tests are used for floating-point comparisons, which
    are intrinsically signed values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You’ll notice that GE and GT are ordered comparisons, while LE and LT handle
    unordered comparisons. Likewise, LS and LO are ordered comparisons, while HI and
    HS also handle unordered comparisons. At first glance, this might seem weird;
    why not make one set (signed or unsigned) ordered and the other set unordered?
  prefs: []
  type: TYPE_NORMAL
- en: However, you want the two opposite tests (for example, LE and GT, or LT and
    GE) to handle all possible outcomes. One of the outcomes is unordered. Therefore,
    one of the opposite comparisons needs to handle unordered so that the two tests
    in each pair provide total coverage of the conditionals (the same logic applies
    to HI-LS and HS-LO). You can always test the overflow flag (V) to see whether
    a comparison is ordered or unordered.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.3.2 Conditional Comparisons
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The conditional floating-point comparison instruction, fccmp, is the floating-point
    analog to the integer conditional comparison instruction. You can use it to reduce
    complex Boolean expressions involving conjunction (AND) and disjunction (OR),
    as noted earlier (see section 6.5, “Conditional Comparisons and Boolean Expressions,”
    on [page 314](chapter6.xhtml#pg_314)).
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.3.3 Comparison for Equality
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As discussed in section 6.7, “Floating-Point and Finite-Precision Arithmetic,”
    on [page 322](chapter6.xhtml#pg_322), you should be very careful about comparing
    two floating-point values (especially for equality). Minor inaccuracies in two
    calculations that would produce the same result using infinite-precision real
    arithmetic may yield different results when using limited-precision floating-point
    arithmetic. If you want to compare two values for equality, compute their difference
    and determine whether the absolute value of their difference is within an acceptable
    error range.
  prefs: []
  type: TYPE_NORMAL
- en: The real question is how to determine an acceptable range for the error. Because
    the difference between these (presumably equal) floating-point values will manifest
    itself in the LO bits of the mantissa, the error value should be something corresponding
    to a 1 bit in one of those positions.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6-2 demonstrates how to calculate this error value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: The mask 0x7FF0_0000_0000_0000 ❶, when ANDed with a double-precision floating-point
    value, will strip out the mantissa and sign bits, leaving the exponent in bit
    positions 52 to 62 (11-bit exponent).
  prefs: []
  type: TYPE_NORMAL
- en: The bits constant ❷ in this listing determines the number of LO bits in the
    mantissa that the code will eliminate when generating the error value (this is
    currently 4 bits, so the 4 LO bits of the mantissa become insignificant, but in
    most cases it should be 2 to 3 bits for single-precision and 3 to 4 bits for double-precision
    comparisons). Once the computeError function generates the error value, the main
    program uses that error to compare a couple of floating-point numbers and report
    whether they should be treated as equal (their difference is less than the error
    value) or not equal (their difference is greater). The bitMask value is just a
    string of 1 bits (4 in Listing 6-2).
  prefs: []
  type: TYPE_NORMAL
- en: The procedure computeError ❸ is passed a floating-point value in D0\. This function
    computes an error value for that floating-point number such that if it is compared
    with a second number, their difference will be less than the error value if they
    should be considered equal. This function returns the error value in the D0 register.
  prefs: []
  type: TYPE_NORMAL
- en: To compute the error value, computeError begins by shifting the exponent down
    to bits 0 to 10 so that it is easier to work with ❹. If the exponent is less than
    52 – 5 bits, the error value will turn out to be a subnormal (denormalized) number.
    The code determines whether the error value will be normalized or subnormal ❺.
  prefs: []
  type: TYPE_NORMAL
- en: If the result will be a normalized number, the code generates the error value
    by 52 bits (47 if bits is 4) and then shifts the exponent back into its proper
    location ❻. The mantissa and sign bits will all be 0; however, the implied bit
    for double-precision numbers will be 1, because the exponent is not 0.
  prefs: []
  type: TYPE_NORMAL
- en: If the error value will turn out to be subnormal, the code sets the exponent
    to 0, denoting a denormalized value, and shifts the bitMask value to the left
    the number of bit positions specified by the exponent minus the bits value ❼.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the build command and sample output for Listing 6-2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: This demonstrates that the difference between Value1 and Value2 is definitely
    outside the error range allowed for this comparison.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.3.4 Conditional Select Instruction
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Although the ARM does not support all the conditional instructions present
    in the integer instruction set, it does support the most often used conditional
    instruction: conditional select, or fcsel. The fcsel instruction has the following
    syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: This instruction will test the condition and copy Ft to Fd if the condition
    is true, or it will copy Ff to Fd if the condition is false.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.4 Floating-Point Conversion Instructions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The ARM instruction set includes a wide variety of instructions that convert
    between various floating-point formats and between signed/unsigned integers and
    floating-point formats. Certain CPUs even support conversions between floating-point
    and fixed-point formats. This section describes these conversions.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.4.1 fcvt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The fcvt instruction converts between the three supported floating-point formats
    (half-, single-, and double-precision). This is one of the few instructions that
    supports the H*n* registers (ldr and str are the others). The syntax for this
    instruction is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'These instructions convert their source operand to the type of the destination
    operand and copy the converted data into that operand. Of course, not all conversions
    can happen without error—be aware that converting a larger-size format to a smaller-size
    format can produce underflow and underflow exceptions. You might want to consider
    checking the FPSR after such an operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: This code demonstrates checking the UFC, OFC, and IDC bits to see if an error
    occurred after the conversion.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.4.2 Conversion Between Floating-Point and Integer
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The instructions in [Table 6-13](chapter6.xhtml#tab6-13) convert between various
    floating-point (single- and double-precision) and integer formats. The syntax
    for these instructions is as follows
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: where m is a, m, n, p, or z that specifies a rounding mode (see [Table 6-13](chapter6.xhtml#tab6-13),
    where FP = floating-point, SI = signed integer, and UI = unsigned integer). Fn
    represents any single- or double-precision floating-point register, and Rd represents
    any general-purpose register (W*d* or X*d*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-13: The fcvt{m}{s|u} Conversion Instructions'
  prefs: []
  type: TYPE_NORMAL
- en: '| Instruction | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtas | Convert FP to SI; round away from 0. |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtau | Convert FP to UI; round away from 0. |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtms | Convert FP to SI; round toward –infinity (floor function). |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtmu | Convert FP to UI; round toward –infinity (floor function). |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtns | Convert FP to SI; round to even (standard IEEE rounding). |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtnu | Convert FP to UI; round to even (standard IEEE rounding). |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtps | Convert FP to SI; round toward +infinity (ceil function). |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtpu | Convert FP to UI; round toward +infinity (ceil function). |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtzs | Convert FP to SI; round toward 0 (truncation). |'
  prefs: []
  type: TYPE_TB
- en: '| fcvtzu | Convert FP to SI; round toward 0 (truncation). |'
  prefs: []
  type: TYPE_TB
- en: 'In addition to converting floating-point values to integers, the ARM provides
    two instructions that convert integers to floating-point values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: The scvtf instruction converts a signed integer to a floating-point value, and
    the ucvtf instruction converts an unsigned integer to floating-point. Note that
    some integer values cannot be exactly represented by a single- or double-precision
    value. For example, a double-precision floating-point value has a 56-bit mantissa,
    so it cannot precisely represent all 64-bit integers.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.4.3 Fixed-Point Conversions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Some 64-bit ARM CPUs support conversion between a fixed-point binary value
    and a floating-point value. These instructions take the following forms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: Here, bits is the number of bits to the right of the binary point in the general-purpose
    register. It is a constant from 0 to one less than the size of the general-purpose
    register. For example, in a 64-bit register, a value of 32 would provide you with
    32 bits to the left and right of the binary point in the fixed-point number.
  prefs: []
  type: TYPE_NORMAL
- en: 6.9.4.4 Rounding
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The ARM provides several floating-point rounding instructions. They are similar
    in nature to the floating-point-to-integer conversion insofar as they round a
    real number to an integral value. However, these instructions produce not binary
    integer values but rather floating-point results that just happen to be integer
    numbers (or, rather, the floating-point representation of those integer numbers).
  prefs: []
  type: TYPE_NORMAL
- en: 'These instructions all take a pair of floating-point registers as operands.
    Both registers must be the same size (single- or double-precision). The generic
    syntax is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: The instruction descriptions appear in [Table 6-14](chapter6.xhtml#tab6-14).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-14: The frint{m} Instructions'
  prefs: []
  type: TYPE_NORMAL
- en: '| Instruction | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| frinta | Round away from 0. |'
  prefs: []
  type: TYPE_TB
- en: '| frinti | Round using the Rmode setting in the FPCR. |'
  prefs: []
  type: TYPE_TB
- en: '| frintm | Round toward –infinity. |'
  prefs: []
  type: TYPE_TB
- en: '| frintn | Normal rounding, exactly 0.5 rounds to nearest even value. |'
  prefs: []
  type: TYPE_TB
- en: '| frintp | Round toward +infinity. |'
  prefs: []
  type: TYPE_TB
- en: '| frintx | Round using FPCR mode; raise an exception if value was not originally
    an integer. |'
  prefs: []
  type: TYPE_TB
- en: '| frintz | Round toward 0. |'
  prefs: []
  type: TYPE_TB
- en: Now that you’ve reviewed the floating-point conversion instructions, I’ll show
    you how to use floating-point instructions in code that interfaces with other
    programs.
  prefs: []
  type: TYPE_NORMAL
- en: '### 6.10 The ARM ABI and Floating-Point Registers'
  prefs: []
  type: TYPE_NORMAL
- en: The ARM ABI considers V0 through V7 and V16 through V31 to be volatile. The
    caller must preserve these registers across procedure calls if it requires that
    they retain their values across a call.
  prefs: []
  type: TYPE_NORMAL
- en: Registers V8 through V15 are nonvolatile. A callee must preserve these registers
    within a procedure if it modifies their values. Of course, the advantage of these
    registers is that once a procedure preserves them (for its caller), it does not
    have to worry about modification to these registers by any functions it calls.
  prefs: []
  type: TYPE_NORMAL
- en: Callers pass the first eight floating-point parameters in registers to a procedure.
    When passing a combination of integer and floating-point parameters, the caller
    passes the non-floating-point parameters in the general- purpose registers (X0
    to X7) and the floating-point arguments in the floating-point registers. If the
    number of floating-point parameters exceeds eight, the caller passes the floating-point
    parameters on the stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters are assigned the next available register, not a register number
    based on the parameter’s position in the parameter list. Consider the following
    C function prototype:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'The ARM ABI would associate the registers in [Table 6-15](chapter6.xhtml#tab6-15)
    with these formal parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6-15: Parameter Assignments to Registers'
  prefs: []
  type: TYPE_NORMAL
- en: '| Register | Parameter |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| X0 | i |'
  prefs: []
  type: TYPE_TB
- en: '| D0 | d |'
  prefs: []
  type: TYPE_TB
- en: '| X1 | j |'
  prefs: []
  type: TYPE_TB
- en: '| X2 | k |'
  prefs: []
  type: TYPE_TB
- en: '| D1 | e |'
  prefs: []
  type: TYPE_TB
- en: '| X3 | l |'
  prefs: []
  type: TYPE_TB
- en: '| D2 | f |'
  prefs: []
  type: TYPE_TB
- en: '| D3 | g |'
  prefs: []
  type: TYPE_TB
- en: '| D4 | h |'
  prefs: []
  type: TYPE_TB
- en: If a function passes a floating-point parameter by reference, the address of
    that floating-point value is passed in the next available general-purpose register
    (no floating-point registers for pass-by-reference parameters).
  prefs: []
  type: TYPE_NORMAL
- en: 'If a function returns a floating-point result, it returns that value in D0
    (or S0, if the language supports returning single-precision floats as function
    return results). See [Chapter 11](chapter11.xhtml) for details on returning vectors
    (multiple floating-point values) as function results (hint: V0). If a function
    returns an array of floating-point values, the caller must allocate storage for
    that array and pass a pointer to that array in X8\. The function will store the
    results into that storage before returning.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.11 Using C Standard Library Math Functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Although the ARM instruction set provides a set of machine instructions that
    compute basic arithmetic operations, it does not have instructions for computing
    complex mathematical functions such as sine, cosine, and tangent. You could (with
    the appropriate knowledge) write these functions yourself in assembly language,
    but a much simpler solution is available: call functions that are already written
    for you. In particular, the C stdlib contains many useful mathematical functions
    you can use. This section describes how to call several of them.'
  prefs: []
  type: TYPE_NORMAL
- en: As a sample program that demonstrates passing floating-point values to functions,
    Listing 6-3 makes calls to various C stdlib <math.h> functions (specifically sin(),
    cos(), and tan()). Each of these functions accepts a double-precision parameter
    and returns a double-precision result.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: This program calls the sin(), cos(), and tan() functions indirectly—the address
    of the particular function is passed as a parameter to the doPi procedure. Unfortunately,
    macOS’s PIE functionality prevents you from taking the address of such a function
    by using the lea macro, because there is no telling where the OS will load the
    dynamically linked (shared) library at runtime; it could be farther away than
    the ±4GB allowed by lea. Therefore, this code creates trampolines for these functions
    that the OS can patch to transfer control to wherever the functions are sitting
    in memory ❶. These trampolines are necessary only for macOS; though they will
    work with Linux code, Linux allows you to take the address of the C stdlib functions
    with lea.
  prefs: []
  type: TYPE_NORMAL
- en: The doPi function ❷ saves the values of X0, X1, and X19 in the activation record.
    Preserving X19 is necessary because this is a nonvolatile register. Saving X0
    and X1 is necessary because the procedure needs their values across calls to printf(),
    and these registers are volatile.
  prefs: []
  type: TYPE_NORMAL
- en: The body of the doPi calls the appropriate function (sin(), cos(), or tan())
    four times with the values π, π/2, π/4, and π/8, and it then displays the result
    these functions return ❸. Note how doPi calls the function indirectly by using
    the blr instruction—the address of the function was originally passed to doPi
    in the X0 register.
  prefs: []
  type: TYPE_NORMAL
- en: The main procedure loads the address of the trampoline (veneer) function into
    X0, along with a string pointer, and calls doPi to compute the values and print
    the results ❹. (Trampolines and veneers are explained further in [Chapter 7](chapter7.xhtml).)
    Loading the address of the trampoline functions into X0 is necessary only under
    macOS; with Linux, you can load the address of the sin(), cos(), or tan() function
    directly and spare the minor inefficiency of having to jump through the trampoline
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the build command and sample output for Listing 6-3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'You’ll notice one difference between this build command and most of the others
    in the book: the -math argument. This tells Linux to link in the C stdlib math
    library functions (macOS automatically links this in). Without the -math option,
    you’ll get a linker error when you try to build the program.'
  prefs: []
  type: TYPE_NORMAL
- en: The C stdlib contains many double-precision functions you might find useful.
    Check them out online for more details. Many of these functions are unnecessary
    in assembly language, as they correspond to one or two machine instructions. Nevertheless,
    the library contains complex functions that you wouldn’t want to write yourself.
  prefs: []
  type: TYPE_NORMAL
- en: You may find various functions online that purport to be faster than those in
    the C stdlib. Be careful about using them because they tend to be notoriously
    inaccurate. Unless you’re well grounded in numerical analysis, don’t try to write
    these functions yourself.
  prefs: []
  type: TYPE_NORMAL
- en: 6.12 Moving On
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This chapter covered a lot of material: the remaining arithmetic instructions
    (including multiplication, division, and remainder, as well as cmp and the various
    conditional instructions), maintaining variables in registers rather than memory
    locations, and the proper use of volatile and nonvolatile registers. It also discussed
    creating structures to provide efficient access to global variables, converting
    arithmetic and logical expressions (integer and floating-point) to their machine
    instruction equivalents, and calling functions written in C/C++.'
  prefs: []
  type: TYPE_NORMAL
- en: Armed with this information, you can now convert arithmetic expressions in an
    HLL such as C/C++ to ARM assembly language. The only basic skill missing from
    your programming repertoire is a good understanding of control structures in assembly
    language, which you’ll learn in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 6.13 For More Information
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: My book *Write Great Code*, Volume 1 (No Starch Press, 2020), includes sections
    on the cache and thrashing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reference Wikipedia for details on fixed-point arithmetic: *[https://<wbr>en<wbr>.wikipedia<wbr>.org<wbr>/wiki<wbr>/Fixed<wbr>-point<wbr>_arithmetic](https://en.wikipedia.org/wiki/Fixed-point_arithmetic)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can learn more about limited-precision arithmetic from the following resources:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A Central Connecticut State University tutorial in the form of an interactive
    questionnaire: *[https://<wbr>chortle<wbr>.ccsu<wbr>.edu<wbr>/assemblytutorial<wbr>/Chapter<wbr>-29<wbr>/ass29<wbr>_10<wbr>.html](https://chortle.ccsu.edu/assemblytutorial/Chapter-29/ass29_10.html)*.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Python documentation on the topic: *[https://<wbr>docs<wbr>.python<wbr>.org<wbr>/3<wbr>/tutorial<wbr>/floatingpoint<wbr>.html](https://docs.python.org/3/tutorial/floatingpoint.html)*.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For more information on writing better code using floating-point arithmetic,
    see the following post on the Society of Actuaries website: *[https://<wbr>www<wbr>.soa<wbr>.org<wbr>/news<wbr>-and<wbr>-publications<wbr>/newsletters<wbr>/compact<wbr>/2014<wbr>/may<wbr>/com<wbr>-2014<wbr>-iss51<wbr>/losing<wbr>-my<wbr>-precision<wbr>-tips<wbr>-for<wbr>-handling<wbr>-tricky<wbr>-floating<wbr>-point<wbr>-arithmetic](https://www.soa.org/news-and-publications/newsletters/compact/2014/may/com-2014-iss51/losing-my-precision-tips-for-handling-tricky-floating-point-arithmetic)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wikipedia documents the C stdlib math functions at *[https://<wbr>en<wbr>.wikipedia<wbr>.org<wbr>/wiki<wbr>/C<wbr>_mathematical<wbr>_functions](https://en.wikipedia.org/wiki/C_mathematical_functions)*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you insist on writing your own transcendental functions, you might try to
    locate a copy of the following book (long out of print), the “bible” of transcendental
    functions: *Computer Approximations,* by John F. Hart, E.W. Cheney, and Charles
    L. Lawson (Krieger Publishing, 1978).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
