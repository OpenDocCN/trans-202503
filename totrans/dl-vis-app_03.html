<html><head></head><body><div id="sbo-rt-content"><section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="15" id="Page_15"/>2</span><br/>
<span class="ChapterTitle">Essential Statistics</span></h1>
</header>
<figure class="opener">
<img src="Images/chapterart.png" alt="" width="206" height="206"/>
</figure>
<p class="ChapterIntro">The better we understand our data, the better we can design a deep learning system that can make the most of that data. </p>
<p>By studying and analyzing the data we’re starting with, we can pick the best algorithms for learning from it. The ideas and tools that let us do this analysis are generally bundled together under the heading of <em>statistics</em>. Statistical ideas and language appear everywhere in machine learning, from papers and source code comments to library documentation.</p>
<p>In this chapter, we’ll cover the key statistical ideas essential to doing deep learning without delving into the math or details. The ideas fall roughly into two categories. The first category involves random numbers and how to describe them in ways that are of the most value in machine learning. The second category involves the ways in which we can choose objects (like numbers) from a collection and how to measure how well such selections represent the collection as a whole. Our goal here is to develop enough understanding and intuition to help us make good decisions when we do machine learning.</p>
<p><span epub:type="pagebreak" title="16" id="Page_16"/>If you’re already familiar with statistics and random values, at least skim the chapter. That way you’ll know the language we use in this book, and you’ll know where to come back to later if you want to brush up.</p>
<h2 id="h1-500723c02-0001">Describing Randomness </h2>
<p class="BodyFirst">Random numbers play an important role in many machine learning algorithms. We use them to initialize our systems, to control steps during the learning process, and sometimes even to influence output. Picking random numbers properly is important: doing so can mean the difference between a system that learns from our data and produces useful results and a system that stubbornly refuses to learn anything. Rather than simply picking some arbitrary numbers out of thin air, we use a variety of tools to control what kinds of numbers we want to use and how we select them. </p>
<p>We typically select a random number between a given minimum and maximum, such as when someone has us “pick a number from 1 to 10.” In this example, it’s implied that our choice is limited to a finite number of options (the integers from 1 to 10). We’ll frequently work with <em>real</em> numbers, which may lie between the integers. There are 10 integers from 1 to 10 (including the endpoints), but there is an infinite quantity of real numbers in that range.</p>
<p>When we talk about collections of numbers, random or otherwise, we often also talk about their <em>average</em>. This is a useful way to quickly characterize the collection of values. There are three different common ways to compute an average, and they come up frequently, so we’ll identify them here. As a running example, let’s work with a list of five numbers: 1, 3, 4, 4, 13.</p>
<p>The <em>mean</em> is the value usually meant in everyday language when we say <em>average</em>. It’s the sum of all the entries divided by the number of entries in the list. In our example, adding together all the list elements gives us 1 + 3 + 4 + 4 + 13 = 25. There are five elements, so the mean is 25 / 5, or 5.</p>
<p>The <em>mode</em><b> </b>is the value that occurs the most often in the list. In our example, 4 appears twice, and the other three values each appear only once, so 4 is the mode. If no value occurs more often than any other, we say the list has no mode.</p>
<p>Finally, the <em>median</em> is the number in the middle of the list when we write the values sorted from the smallest to the largest. In our list, which is already sorted, 1 and 3 make up the left side, 4 and 13 make up the right side, and another 4 is in the middle. So 4 is the median. If a list has an even number of entries, then the median is the mean of the two middle entries. For the list 1, 3, 4, 8, the median would be the average of 3 and 4, which is 3.5. </p>
<p>Averages are useful, but they don’t tell us much about how the numbers in a collection are distributed. For example, they might be spread out equally across their range, or grouped into one or more clusters. We’ll now look at the techniques that let us describe how numbers are distributed.</p>
<h2 id="h1-500723c02-0002"><span epub:type="pagebreak" title="17" id="Page_17"/>Random Variables and Probability Distributions </h2>
<p class="BodyFirst">Before getting into details, let’s build up our intuition with a running analogy. Suppose we’re photographers who have been assigned to support an article on auto junkyards by taking lots of pictures of broken-down trucks and cars. Feeling adventurous, we go to a junkyard that contains many broken-down vehicles. We talk to the owner, and we agree that the best way to get great photos is for us to pay her to bring us vehicles to photograph, one by one. She makes it fun by using an old carnival wheel she has in her office. It has one equally sized slot for each car on the lot, as in <a href="#figure2-1" id="figureanchor2-1">Figure 2-1</a>. Both the slots and the cars are numbered starting at 1.</p>
<figure>
<img src="Images/F02001.png" alt="F02001" width="450" height="485"/>
<figcaption><p><a id="figure2-1">Figure 2-1</a>: The junkyard owner’s carnival wheel. Each equally sized sliver represents one car in her lot. </p></figcaption>
</figure>
<p>Once we pay her, she spins the wheel. When the wheel stops, she notes the number at the top, goes out with her tow truck, and drags the vehicle with the corresponding number back to us. We take some pictures, and she returns the vehicle to the lot. If we want to photograph another vehicle, we pay again, she spins the wheel again, and the process repeats.</p>
<p>Suppose that our assignment calls for us to get pictures of five different types of cars: a sedan, a pickup, a minivan, an SUV, and a wagon. For each type of car, we would like to know the chance that if she spins the wheel, we’ll get that type. To work that out, let’s suppose that we go into the lot to examine every vehicle, and we assign each one to one of these five categories. Our results are shown in <a href="#figure2-2" id="figureanchor2-2">Figure 2-2</a>. </p>
<span epub:type="pagebreak" title="18" id="Page_18"/><figure>
<img src="Images/F02002.png" alt="F02002" width="564" height="408"/>
<figcaption><p><a id="figure2-2">Figure 2-2</a>: Our junkyard has five different types of cars in it. Each bar tells us how many cars we have of that type.</p></figcaption>
</figure>
<p>Of the almost 950 cars on her lot, the largest population is minivans, followed by pickups, wagons, sedans, and SUVs, in that order. Since every vehicle on her lot has an equal chance of being selected, on each spin of the wheel, we’re most likely to get a minivan. </p>
<p>But specifically how<em> much</em> more likely are we to get a minivan? To determine how likely it is that we’ll get each kind of vehicle, we can divide the height of each bar in <a href="#figure2-2">Figure 2-2</a> by the total number of vehicles. This value gives us the probability that we’ll get that given type of car, as shown in <a href="#figure2-3" id="figureanchor2-3">Figure 2-3</a>.</p>
<figure>
<img src="Images/F02003.png" alt="F02003" width="564" height="412"/>
<figcaption><p><a id="figure2-3">Figure 2-3</a>: The probability of getting each type of car in the junkyard</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="19" id="Page_19"/>To convert the numbers in <a href="#figure2-3">Figure 2-3</a> into percentages, we multiply them by 100. For example, the height of the minivan bar is about 0.34, so we say that there’s a 34 percent chance of getting a minivan. We say that the height of each bar is the <em>probability</em> that we’ll get that kind of vehicle. If we add up the heights of all five bars, we’ll find that the sum is 1.0. This illustrates the rules that turn any list of numbers into probabilities: the values must all be between 0 and 1, and add up to 1.  </p>
<p>We call <a href="#figure2-3">Figure 2-3</a> a <em>probability distribution</em> because it’s distributing the 100 percent probability of getting some vehicle among the available options. We also sometimes say that <a href="#figure2-3">Figure 2-3</a> is a <em>normalized</em> version of <a href="#figure2-2">Figure 2-2</a>, which means that the values all add up to 1.</p>
<p>We can use our probability distribution to draw a simplified carnival wheel, as in <a href="#figure2-4" id="figureanchor2-4">Figure 2-4</a>. </p>
<figure>
<img src="Images/F02004.png" alt="F02004" width="450" height="485"/>
<figcaption><p><a id="figure2-4">Figure 2-4</a>: A simplified carnival wheel that tells us what kind of vehicle we’ll get if the owner spins the big wheel of <a href="#figure2-1">Figure 2-1</a></p></figcaption>
</figure>
<p>The chance that the wheel will end up with the pointer in a given region is given by the portion of the wheel’s circumference taken up by that region, which we’ve drawn with the same proportions as those shown in <a href="#figure2-3">Figure 2-3</a>.</p>
<p>Most of the time we don’t have carnival wheels around when we generate random numbers on the computer. Instead, we rely on software to simulate the process. For instance, we might give a library function a list of values, like the heights of the bars in <a href="#figure2-3">Figure 2-3</a>, and ask it to return a value. We expect that we’ll get back <span class="CustomCharStyle">minivan</span> about 34 percent of the time, <span class="CustomCharStyle">pickup</span> about 26 percent of the time, and so on.</p>
<p><span epub:type="pagebreak" title="20" id="Page_20"/>The job of picking a value at random from a list of options, each with its own probability, takes a bit of work. For convenience, we package up this selection process into its own conceptual procedure called a <em>random variable</em>.</p>
<p>This term can create confusion for programmers, because programmers think of a variable as being a named piece of storage that can hold data. In this context, rather than a piece of storage, a random variable is a <em>function</em> (Wikipedia 2017b), which takes a probability distribution as an input and produces a single value as an output. The process of selecting a value from a distribution is called <em>drawing</em> a value from the random variable.</p>
<p>We called <a href="#figure2-3">Figure 2-3</a> a probability distribution, but we can also think of it as a function. We call the function, and it returns one of the types of vehicles, given these probabilities. This idea leads us to two more formal names for a distribution. When there are only a finite number of possible return values, like the five values in <a href="#figure2-3">Figure 2-3</a>, we sometimes use the oblique name <em>probability mass function</em> or <em>pmf</em> (this acronym is usually written in lowercase).<em> </em>A pmf is also sometimes called a <em>discrete probability distribution</em> (adding <em>function</em> at the end of this term is optional). These terms are meant to remind us that there are only a fixed number of possible outputs. </p>
<p>We can easily create probability distributions that are continuous. We use approximations of such functions when we initialize the values in a neural network. As an analogy, let’s suppose that we want to know how much oil is left in each car that our junkyard dealer brings us. The amount of oil is a continuous variable, because it can take on any real number. <a href="#figure2-5" id="figureanchor2-5">Figure 2-5</a> shows a continuous graph for our oil measurements. This graph shows us the probability of getting back not just a few specific values, but any real value at all, here between 0 (empty) and 1 (full).</p>
<figure>
<img src="Images/F02005.png" alt="F02005" width="694" height="470"/>
<figcaption><p><a id="figure2-5">Figure 2-5</a>: A distribution of probabilities for a continuous range of values</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="21" id="Page_21"/>A distribution like <a href="#figure2-5">Figure 2-5</a> is called a <em>continuous probability distribution</em> (or <em>cpd</em>), or a <em>probability density function</em> (or <em>pdf</em>). Sometimes people casually use the term probability density function, or pdf, to refer to discrete distributions, rather than continuous ones. The context usually makes it clear which interpretation is intended.</p>
<p>Recall that for the discrete case, all the possible return values need to add up to 1. In the continuous case, as in <a href="#figure2-5">Figure 2-5</a>, that means that the area under the curve is 1.  </p>
<p>Most of the time, we obtain random numbers by selecting a distribution and then calling a library function to produce a value from that distribution (that is, it draws a random variable from our given distribution). We can make our own distributions when we want them, but most libraries provide a handful of distributions that have been found to cover most situations. That way we can just use one of these prebuilt distributions when we choose our random numbers. Let’s take a look at some of these distributions.</p>
<h2 id="h1-500723c02-0003">Some Common Distributions</h2>
<p class="BodyFirst">We’ve mentioned that we can draw a random variable from a distribution. Each time we draw a random variable, it takes on a number in accordance with the distribution: numbers with a large corresponding value in the distribution are more likely than those with a smaller value in the distribution. This makes distributions of great practical value, since different algorithms will want to use random variables that take on different values with particular probabilities. To achieve this, we merely need to pick an appropriate distribution.</p>
<h3 id="h2-500723c02-0001">Continuous Distributions</h3>
<p class="BodyFirst">Most of the following distributions are offered as built-in routines by major libraries, so they’re easy to specify and use. For simplicity, we’ll demonstrate the following two distributions in their continuous forms. Most libraries offer us a choice between continuous and discrete versions, or they may offer a general-purpose routine to turn any continuous distribution into a discrete one on demand, or vice versa. We’ll look at some discrete distributions later in the section.</p>
<h4 id="h3-500723c02-0001">The Uniform Distribution</h4>
<p class="BodyFirst"><a href="#figure2-6" id="figureanchor2-6">Figure 2-6</a> shows the <em>uniform distribution</em>. The basic uniform distribution is 0 everywhere except between 0 and 1, where it has the value 1.</p>
<p>In <a href="#figure2-6">Figure 2-6</a>, it may appear that there are two values at 0 and two values at 1, but there aren’t. Our convention is that an open circle (as on the lower line) means “this point is not part of the line,” and a closed circle (as on the upper line) means “this point is part of the line.” So, at the input values 0 and 1, our graph has an output of 1. This is a common way to define <span epub:type="pagebreak" title="22" id="Page_22"/>this function, but some implementations make either or both of those outputs 0. It always pays to check.</p>
<figure>
<img src="Images/F02006.png" alt="F02006" width="638" height="431"/>
<figcaption><p><a id="figure2-6">Figure 2-6</a>: An example of a uniform distribution</p></figcaption>
</figure>
<p>This distribution has two key features. First, we can only get back values between 0 and 1, because the probability of all other values is 0. Second, every value in the range 0 to 1 is equally probable. It’s just as likely we’d get 0.25 as 0.33 or 0.793718. We say that <a href="#figure2-6">Figure 2-6</a> is <em>uniform</em>, or <em>constant</em>, or <em>flat</em>, in the range 0 to 1, all of which tell us that all the values in that range are equally probable. We also say that it’s <em>finite</em>, meaning that all the nonzero values are within some specific range (that is, we can say with certainty that 0 and 1 are the smallest and largest values it can return). </p>
<p>Library functions that create uniform distributions for us often let us choose to start and end the nonzero region where we like. Probably the most popular choice, after the default of 0 to 1, is the range −1 to 1. The library takes care of details like adjusting the height of the function so that the area is always 1.0 (recall that this is required if a graph is to represent a probability distribution). </p>
<h4 id="h3-500723c02-0002">The Normal Distribution</h4>
<p class="BodyFirst">Another frequently used distribution is the <em>normal distribution</em>, also called the <em>Gaussian distribution</em>, or simply the <em>bell curve</em>. Unlike the uniform distribution, it’s smooth and has no sharp corners or abrupt jumps.</p>
<p><a href="#figure2-7" id="figureanchor2-7">Figure 2-7</a> shows a few typical normal distributions.</p>
<p>All four curves in <a href="#figure2-7">Figure 2-7</a> have the same basic shape. The shapes only vary because we scaled the curve, moved it horizontally, or both. For these illustrations, we didn’t scale the curve so that the area under it sums to 1.</p>
<span epub:type="pagebreak" title="23" id="Page_23"/><figure>
<img src="Images/F02007.png" alt="F02007" width="694" height="420"/>
<figcaption><p><a id="figure2-7">Figure 2-7</a>: A few normal distributions </p></figcaption>
</figure>
<p><a href="#figure2-8" id="figureanchor2-8">Figure 2-8</a> shows some representative samples that we’d get by drawing values from each distribution. They bunch up where the distribution’s value is high (that is, getting a sample at that value has a high probability), and they are sparser where the distribution’s value is low (where getting back a sample has a low probability). The vertical locations of the red dots representing the samples are jittered only to make the samples easier to see, and have no meaning.</p>
<figure>
<img src="Images/F02008.png" alt="F02008" width="694" height="424"/>
<figcaption><p><a id="figure2-8">Figure 2-8</a>: Each red circle shows the value of a sample resulting from drawing a value from its normal distribution. </p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="24" id="Page_24"/>The normal distribution is nearly 0 almost everywhere, except for the region where it rises up in a smooth bump. Though the values drop off ever closer to 0 to the sides of the bump, they never quite reach 0. So we say that the width of this distribution is <em>infinite</em>. In practice, we usually treat any value that’s very nearly 0 as actually 0, giving us a finite distribution. A few other terms sometimes come up when people discuss normal distributions. The values produced by random variables from a normal distribution are sometimes called <em>normal deviates</em>, and are said to be <em>normally distributed</em>. We also say these values <em>fit</em>, or follow, a normal distribution. </p>
<p>Each normal distribution is defined by two numbers: the <em>mean</em> and the <em>standard deviation</em>. The mean tells us the location of the center of the bump. <a href="#figure2-9" id="figureanchor2-9">Figure 2-9</a> shows our four Gaussians from <a href="#figure2-7">Figure 2-7</a>, with their means. Here’s one of the many nice properties of a normal distribution: its mean is also its median and its mode.</p>
<figure>
<img src="Images/F02009.png" alt="F02009" width="694" height="421"/>
<figcaption><p><a id="figure2-9">Figure 2-9</a>: The mean of a normal distribution is the center of the bump, here shown with a red line.</p></figcaption>
</figure>
<p>The <em>standard deviation</em> is also a number, often represented by the lower-case Greek letter σ (sigma), which tells us the width of the bump. Imagine starting at the center of the bump and moving symmetrically outward until we’re enclosing about 68 percent of the total area under the curve. The distance from the center of the bump to either of these ends is called <em>one standard deviation</em> for that curve. <a href="#figure2-10" id="figureanchor2-10">Figure 2-10</a> shows our four Gaussians, with the area inside one standard deviation shaded in green.</p>
<p>We can use the standard deviation to characterize a bump: when the standard deviation is small, it means the bump is narrow. As the standard deviation increases, the bump becomes more spread out horizontally.</p>
<span epub:type="pagebreak" title="25" id="Page_25"/><figure>
<img src="Images/F02010.png" alt="F02010" width="694" height="416"/>
<figcaption><p><a id="figure2-10">Figure 2-10</a>: Some normal distributions with the area within one standard deviation shaded in green</p></figcaption>
</figure>
<p>If we go out symmetrically from the center by another standard deviation (that is, the same distance again), then we’ve enclosed about 95 percent of the area under the curve, as shown in <a href="#figure2-11" id="figureanchor2-11">Figure 2-11</a>. And if we go out one more standard deviation, we’ve enclosed about 99.7 percent of the area under the curve, also shown in <a href="#figure2-11">Figure 2-11</a>. This property is sometimes called the <em>three-sigma rule</em>, because of the use of σ for the standard deviation. It also sometimes goes by the catchy name of the <em>68-95-99.7 rule</em>.</p>
<figure>
<img src="Images/F02011.png" alt="F02011" width="694" height="464"/>
<figcaption><p><a id="figure2-11">Figure 2-11</a>: The three-sigma, or 68-95-99.7 rule</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="26" id="Page_26"/>Suppose we look at 1,000 samples drawn from any normal distribution. We would find that about 680 of them are no more than one standard deviation from that distribution’s mean, or in the range −σ to σ; about 950 of them are within two standard deviations, or in the range −2σ to 2σ; and about 997 of them are within three standard deviations, or in the range −3σ to 3σ. </p>
<p>To summarize, the mean tells us where the center of the curve is, and the standard deviation tells us how spread out the curve is. The larger the standard deviation, the broader the curve, because that 68 percent cutoff is farther away.</p>
<p>Sometimes instead of the standard deviation, people use a different but related value called the <em>variance</em>. The variance is just the standard deviation multiplied by itself (that is, the standard deviation squared). This value is sometimes more convenient in calculations. The general interpretation is the same, though: curves with big variances are more spread out than curves with small variances.</p>
<p>The normal distribution appears frequently in machine learning and in other fields, because it naturally describes many real-world observations. If we measure the height of adult male horses in some region, or the size of sunflowers, or the lifespans of fruit flies, we’ll find that these all tend to take on the shape of a normal distribution.</p>
<h3 id="h2-500723c02-0002">Discrete Distributions</h3>
<p class="BodyFirst">Now let’s look at two discrete distributions. </p>
<h4 id="h3-500723c02-0003">The Bernoulli Distribution</h4>
<p class="BodyFirst">A useful, but special, discrete distribution is the <em>Bernoulli distribution</em> (pronounced ber-noo′-lee). This distribution returns just two possible values: 0 and 1. A common example of a Bernoulli distribution is the probability of getting heads and tails from flipping a coin. We usually use the letter <em>p </em>to describe the probability of getting back a 1 (let’s say that means heads). If we ignore weird cases like when the coin lands sideways, the two probabilities of heads and tails must add up to 1, which means that the probability of getting back a 0 (or tails) is 1 − <em>p</em>. <a href="#figure2-12" id="figureanchor2-12">Figure 2-12</a> shows this graphically for a fair coin and a weighted coin. Because we have just two values, we can draw the Bernoulli distribution as a bar chart, rather than the lines and curves we saw for the continuous distributions.</p>
<p>It may seem like overkill to use the language of distributions for such a simple situation, but the payoff is that we can use it with our library routines that produce values from distributions. We can hand our routine a uniform distribution, or a Gaussian, or a Bernoulli, and it will return a value drawn from that distribution according to its probabilities. This makes programming easier. </p>
<span epub:type="pagebreak" title="27" id="Page_27"/><figure>
<img src="Images/F02012.png" alt="F02012" width="705" height="380"/>
<figcaption><p><a id="figure2-12">Figure 2-12</a>: The Bernoulli distribution tells us the chance of drawing either a 0 or 1. Left: A fair coin. Right: An unfair coin. </p></figcaption>
</figure>
<h4 id="h3-500723c02-0004">The Multinoulli Distribution</h4>
<p class="BodyFirst">The Bernoulli distribution only returns one of two possible values. But suppose we are running an experiment that can return any one of a larger number or possibilities. For instance, instead of flipping a coin that can come up either heads or tails, we might roll a 20-sided die that can come up with any of 20 values.</p>
<p>To simulate the result of rolling this die, our random variable could return an integer from 1 to 20. But in other situations, it’s useful to have a list of possible values where all the entries have a corresponding probability of 0 except for the one entry we drew, which is set to 1. Such a list is useful when we build machine learning systems to classify inputs into different categories—for example, to describe which of 10 different animals appears in a photograph.</p>
<p>Let’s suppose that we have a photo of an alligator, and that’s entry five in our list. If our algorithm wasn’t sure what the image was, we might get back something like the left of <a href="#figure2-13" id="figureanchor2-13">Figure 2-13</a>, where three animals are identified as possibilities. We’d want the system to produce the output on the right, where every entry is 0 except for the alligator, which is 1. </p>
<p>This way of representing a single choice from a list is a key step in training classifiers with more than two possible classes. We’ll return to this idea in Chapter 6, as a component of an idea called <em>cross entropy</em>. </p>
<p>Because each distribution in <a href="#figure2-13">Figure 2-13</a> is a generalization of the two-outcome Bernoulli distribution into multiple outcomes, we could call it a “multiple-Bernoulli distribution,” but instead we mush the words together into a portmanteau and call it a <em>multinoulli distribution</em><b> </b>(or sometimes the less colorful <em>categorical distribution</em>).</p>
<span epub:type="pagebreak" title="28" id="Page_28"/><figure>
<img src="Images/F02013.png" alt="F02013" width="685" height="307"/>
<figcaption><p><a id="figure2-13">Figure 2-13</a>: Left: Possible predicted probabilities for a picture of an alligator. Right: The probabilities we want.  </p></figcaption>
</figure>
<h2 id="h1-500723c02-0004">Collections of Random Values</h2>
<p class="BodyFirst">We’ve seen how to generate random values from a distribution. We draw a value from a random variable using the probabilities of that distribution to tell us which return values are more likely to be selected than others.</p>
<p>When we have lots of values drawn from one or more random variables, it’s useful to characterize the collection so that we can speak of it as a group. Let’s look at three such ideas that show up frequently in machine learning.</p>
<h3 id="h2-500723c02-0003">Expected Value</h3>
<p class="BodyFirst">If we pick a value from any probability distribution, and then we pick another, and another, over time we build up a long list of values.</p>
<p>If these values are numbers, their mean is called the <em>expected value</em>. This is useful information for many applications. For a simple example, we might have a need for random numbers between –1 and 1, with a roughly equal number of positive and negative values. If the expected value of the random variable is 0, then we know we’re getting a balanced set of values. </p>
<p>Note that the expected value might not be one of the values ever drawn from the distribution! For example, if the values 1, 3, 5, and 7 are the only ones available, and they are all equally likely, then the expected value of the random variable that we use to draw a value from this list would be (1 + 3 + 5 + 7) / 4 = 4, a value that we’d never get back from the distribution.</p>
<h3 id="h2-500723c02-0004"><span epub:type="pagebreak" title="29" id="Page_29"/>Dependence</h3>
<p class="BodyFirst">The random variables we’ve seen so far have been completely disconnected from one another. When we draw a value from a distribution, it doesn’t matter if we’ve drawn other values before. Each time we draw a new random variable, it’s a whole new world.</p>
<p>We call these <em>independent</em> variables, because they don’t depend on each other in any way. These are the easiest kind of random variable to work with, because we don’t have to worry about managing how two or more random variables might influence one another.</p>
<p>By contrast, there are <em>dependent</em> variables, which do depend on each other. For example, suppose we have several distributions for the fur length of different animals: dogs, cats, hamsters, and so on. We might first pick an animal at random from a list of animals, and then use that to select the appropriate fur length distribution. We’d then draw a value from that distribution to find a value for the animal’s fur. The choice of animal depends on nothing else, so it’s an independent variable. But the length of the fur depends on the distribution we use, which in turn depends on which animal we chose, so fur length is a dependent variable.</p>
<h3 id="h2-500723c02-0005">Independent and Identically Distributed Variables</h3>
<p class="BodyFirst">The math and algorithms of many machine-learning techniques are designed to work with multiple values that are drawn from random variables with the same distribution and are also independent of each other. That is, we draw values from the same distribution over and over, and there is no relationship between successive values. In fact, some algorithms require<em> </em>that we generate our random values this way, while others work best when we do.</p>
<p>This requirement is common enough that such variables have a special name: <em>i.i.d.</em>, which stands for <em>independent and identically distributed</em> (the acronym is unusual because it’s usually written in lowercase, with periods between the letters). We might see, for example, the arguments for a library function described this way: “Make sure successive inputs are i.i.d.”</p>
<p>The phrase <em>identically distributed</em> is just a compact way of saying “selected from the same distribution.”</p>
<h2 id="h1-500723c02-0005">Sampling and Replacement</h2>
<p class="BodyFirst">In machine learning it’s often useful to build new datasets from existing ones by randomly selecting some of the elements of the existing set. We’ll do just this in the next section, when we look for the mean value of a set of samples. Let’s look at two ways of creating a list of selections, chosen from a starting pool of objects.</p>
<h3 id="h2-500723c02-0006"><span epub:type="pagebreak" title="30" id="Page_30"/>Selection with Replacement</h3>
<p class="BodyFirst">Let’s first look at an approach where we make a copy of each selected item, so the original stays in place, as in <a href="#figure2-14" id="figureanchor2-14">Figure 2-14</a>. We call this approach <em>selection with replacement</em>, or <em>SWR</em>, because we can think of it as removing the object, making a copy for ourselves, and replacing the original.</p>
<figure>
<img src="Images/f02014.png" alt="f02014" width="843" height="187"/>
<figcaption><p><a id="figure2-14">Figure 2-14</a>: Selection with replacement </p></figcaption>
</figure>
<p>One implication of selection with replacement is that we might end up with the same object more than once. In an extreme case, our entire new dataset might be nothing more than multiple copies of the same object. A second implication is that we can make a new dataset that is smaller than the original, or the same size, or even much bigger. Since the original dataset is never altered, we can continue picking elements as long as we like.</p>
<p>A statistical implication of this process is that our selections are <em>independent</em> of one another. There is no history, so our selections are not at all affected by previous choices, nor do they influence future choices. To see this, note that the pool (or starting dataset) in <a href="#figure2-14">Figure 2-14</a> always has eight objects, so the odds of picking each one are 1 in 8. In the figure, we first picked element C. Now our new dataset has element C inside of it, but we’ve replaced that element back into the pool after selecting it. When we look again at the pool, all eight items are still there, and if we choose again, each still has a 1 in 8 chance of being picked. </p>
<p>An everyday approximation of sampling with replacement is ordering at a well-stocked coffee shop. If we order a vanilla latte, it’s not removed from the menu but remains available to the next customer. </p>
<h3 id="h2-500723c02-0007">Selection Without Replacement</h3>
<p class="BodyFirst">The other way to randomly choose our new dataset is to remove our choice from the original dataset and place it in our new one. We don’t make a copy, so the original dataset has just lost one element. This approach is called <em>selection without replacement</em>, or <em>SWOR</em>, and is shown in <a href="#figure2-15" id="figureanchor2-15">Figure 2-15</a>.</p>
<p>An everyday example of sampling without replacement is playing a card game like poker. Each time a card is dealt, it’s gone from the pack and cannot be dealt again (until the cards are recollected and shuffled).</p>
<span epub:type="pagebreak" title="31" id="Page_31"/><figure>
<img src="Images/F02015.png" alt="F02015" width="844" height="188"/>
<figcaption><p><a id="figure2-15">Figure 2-15</a>: Selection without replacement </p></figcaption>
</figure>
<p>Let’s compare the implications of SWOR with those of SWR. First, in SWOR, no object can be selected more than once, because we remove it from the original dataset. Second, our new dataset can be smaller than the original, or the same size, but it can never be larger. Third, our choices are now dependent. In <a href="#figure2-15">Figure 2-15</a>, each element originally had the same 1 in 8 chance of being picked the first time. When we selected item C, we did not<em> </em>replace it. When we go to make another selection, there are only seven elements available to us, each now with a 1 in 7 chance of being selected. The odds of selecting any one of those elements have gone up, simply because there are fewer elements competing for selection. If we select another item, the remaining elements each have a 1 in 6 chance of being picked, and so on. And after we’ve selected seven items, the last one is 100 percent sure to be selected the next time.</p>
<p>Continuing the comparison, suppose that we want to make a new dataset that’s smaller than the original pool. We could build it with or without replacement. But sampling with replacement can generate many more possible<em> </em>new collections than sampling without. To see this, suppose we had just three objects in our original pool (let’s call them A, B, and C), and we want a new collection of two objects. Sampling without replacement gives us only three possible new collections: (A,B), (A,C), and (B,C). Sampling with replacement gives us those three, and also (A,A), (B,B), and (C,C). Generally speaking, sampling with replacement always gives us a larger set of possible new collections.</p>
<h2 id="h1-500723c02-0006">Bootstrapping</h2>
<p class="BodyFirst">Let’s look at a useful application for the SWR and SWOR algorithms we just covered.  </p>
<p>Sometimes we want to know some statistics about a dataset that’s much too large for us to work with in practice. For example, suppose we want to know the mean height of all people alive in the world right now. There’s just no practical way to measure everyone. Usually we try to answer this kind of question by extracting a representative piece of the dataset, and then measuring that. We might find the height of a few thousand people, and hope that the mean of those measurements is close to what we’d get if we were able to measure everyone.</p>
<p><span epub:type="pagebreak" title="32" id="Page_32"/>Let’s call every person in the world our <em>population</em>. Since that’s too many people to work with, we’ll gather a reasonably sized group of people that we hope are representative of the population. We call that smaller group a <em>sample set</em>. We’ll build this sample set without replacement, so each time we select a value from the population (that is, a person’s height), it’s removed from the population, placed into the sample set, and cannot be chosen again.</p>
<p>We hope that by building our sample set carefully, we are making it a reasonable proxy for the whole population with respect to the properties we want to measure. <a href="#figure2-16" id="figureanchor2-16">Figure 2-16</a> shows the idea for a population of 21 circled numbers. The sample set contains 12 elements from the population.</p>
<figure>
<img src="Images/F02016.png" alt="F02016" width="694" height="368"/>
<figcaption><p><a id="figure2-16">Figure 2-16</a>: Creating a sample set from a population by sampling without replacement</p></figcaption>
</figure>
<p>Now we’ll measure the mean of the sample set, and use that as our estimate of the mean of the population. In this little example, we can compute the mean of the population, which comes out to about 4.3. The mean of our sample set is about 3.8. This match isn’t great, but it’s not wildly wrong.</p>
<p>Most of the time we won’t be able to measure the population (that’s why we’re building the sample set in the first place). By finding the mean of the sample set, we’ve come up with an approximation, but how good is it? Is this a number we ought to rely on as a good estimate for the whole population? It’s hard to say. Things would be better if we could express our result in terms of a <em>confidence interval</em>. This lets us make a statement of the form, “We are 98 percent certain that the mean of the population is between 3.1 and 4.5.” To make such a statement, we need to know the upper and lower bounds of the range (here, 3.1 and 4.5) and have a measure of how confident we are that the value is in that range (here, 98 percent). Typically, we pick the confidence we need for whatever task we have at hand, and from that, we find the lower and upper values of the corresponding range.</p>
<p>We’d like to be able to make this kind of statement about the mean, or any other statistical measure we’re interested in. We can do this with the technique of <em>bootstrapping</em> (Efron and Tibshirani 1993; Teknomo 2015), which involves two basic steps. The first is the step we saw in <a href="#figure2-16">Figure 2-16</a>, <span epub:type="pagebreak" title="33" id="Page_33"/>where we create a sample set from the original population using SWOR. The second step involves resampling that sample set to make new sets, this time using SWR. Each of these new sets is called a <em>bootstrap</em>. The bootstraps are the key to coming up with our confidence statement.</p>
<p>To create a bootstrap, we first decide how many elements we want to pick out of the starting sample set. We can pick any number up to the number of elements in the set, though we often use far fewer. Once we’ve picked that number, we randomly extract that many elements from the sample set with replacement, so it’s possible that we’ll pick the same element more than once. The process is illustrated in <a href="#figure2-17" id="figureanchor2-17">Figure 2-17</a>.</p>
<figure>
<img src="Images/F02017.png" alt="F02017" width="840" height="537"/>
<figcaption><p><a id="figure2-17">Figure 2-17</a>: Creating three bootstraps using SWR and finding their means</p></figcaption>
</figure>
<p>To recap, we start with a population. We make a sample set from the population using sampling without replacement. Then we make bootstraps from that sample set using sampling <em>with </em>replacement. We need to select with replacement in this last step because we might want to build bootstraps that have the same size as the sample set. In our example, we might want our bootstraps to hold 12 values. If we didn’t sample with replacement, then every bootstrap would be identical to the sample set.</p>
<p>If we really hope to find the average height of everyone in the world, we need a lot more than 21 measurements. Let’s scale up the number of samples and zoom way down on their range. For convenience, let’s focus on the size of two-month-old babies. They are typically about 500 centimeters long, so we created a simulated population of 5,000 measurements with lengths from 0 to 1,000 millimeters (that’s 1 meter, or about 3.2 feet). From this <span epub:type="pagebreak" title="34" id="Page_34"/>population, we drew 500 measurements at random to make a sample set, and then we created 1,000 bootstraps, each with 20 elements. <a href="#figure2-18" id="figureanchor2-18">Figure 2-18</a> shows the number of bootstraps that had a mean value in each of about 100 different bins across the range from 0 to 1,000 (there were almost no means below 200 or above 800). Graphs like this take the form of an approximate bell curve almost every time, because the nature of the bootstraps causes more of them to have a mean around the true mean, and fewer with mean values farther away.</p>
<figure>
<img src="Images/F02018.png" alt="F02018" width="694" height="503"/>
<figcaption><p><a id="figure2-18">Figure 2-18</a>: The histogram shows how many bootstraps have a mean of the given value. The blue bar at about 490 is the mean of the sample set. The red bar at about 500 is the mean of the population.</p></figcaption>
</figure>
<p>Since we created the data, we know the mean of the population is 500. The mean of our sample set is close to this, at about 490. The purpose of bootstrapping is to help us determine how much we should trust this value of 490. Without going into the math, the approximate bell curve of the mean values of the bootstraps tells us everything we need to know. Let’s say we want to find the values that we’re 80 percent confident brackets the mean of the population. Then we only need to slice off the lowest and highest 10 percent of the bootstrap values, leaving the middle 80 percent (Brownlee 2017). <a href="#figure2-19" id="figureanchor2-19">Figure 2-19</a> shows a box that does just this, enclosing the values that we are 80 percent confident contain the real value, which we know is 500. Reading from the graph, we could now say, “We are 80 percent confident that the mean of the original population is between about 410 and 560.”</p>
<span epub:type="pagebreak" title="35" id="Page_35"/><figure>
<img src="Images/F02019.png" alt="F02019" width="694" height="503"/>
<figcaption><p><a id="figure2-19">Figure 2-19</a>: We are 80 percent confident that the box contains the population’s mean.</p></figcaption>
</figure>
<p>Bootstrapping is appealing because often we can use small bootstraps, perhaps only 10 or 20 elements each, even with huge populations of millions of measurements. Because each bootstrap is small, it’s typically fast to build and process. To compensate for their small size, we often create thousands of bootstraps. The more bootstraps we build, the more the results look like a Gaussian bump, and the more precise we can be with our confidence intervals.</p>
<h2 id="h1-500723c02-0007">Covariance and Correlation</h2>
<p class="BodyFirst">Sometimes variables can be related to one another. For example, one variable might give us the temperature outside, and the other the chance of snow. When the temperature is very high, there’s no chance of snow, so knowledge of one of the variables tells us something about the other. In this case, the relationship is <em>negative</em>: as the temperature goes up, the chance of snow goes down, and vice versa. On the other hand, our second variable might tell us the number of people we expect to find swimming in the local lake. The connection between the temperature and the number of people swimming is <em>positive</em>, because on warmer days we see more swimmers, and vice versa.</p>
<p>It’s useful to be able to find these relationships, and measure their strength. For instance, suppose we’re planning to teach an algorithm to extract information from a dataset. If we find that two of the values in the <span epub:type="pagebreak" title="36" id="Page_36"/>data are strongly related (like temperature and chance of snow), we might be able to remove one of them from the data, since it’s redundant. This can improve our training speed and can even improve our results.</p>
<p>In this section, we’ll look at a measurement called <em>covariance,</em> developed by mathematicians to let us determine the strengths of these relationships. We’ll also see a variation called <em>correlation,</em> which is often more useful because it doesn’t depend on the sizes of the number involved. </p>
<h3 id="h2-500723c02-0008">Covariance</h3>
<p class="BodyFirst">Suppose that we have two variables and we notice a specific numerical pattern involving them. When either variable’s value increases, the other increases by a fixed multiple of that amount, and the same thing happens when either variable decreases. For example, suppose variable A goes up by 3, and variable B goes up by 6. Then later, B goes up by 4, and A goes up by 2. Then A decreases by 4, and B decreases by 8. In every example, B goes up or down by twice the amount A went up or down, so our <em>fixed multiple</em> is 2.</p>
<p>If we see such a relationship (for any multiple, not just 2), we say that the two variables <em>covary</em>. We measure the strength of the connection between the two variables, or the consistency with which they covary, with a number called the <em>covariance</em>. If we find that when one value increases or decreases the other does the same by a predictable amount, then the covariance is a positive number, and we say that the two variables are demonstrating <em>positive covariance</em>. </p>
<p>The classic way to talk about covariance is to draw points in 2D, as in <a href="#figure2-20" id="figureanchor2-20">Figure 2-20</a>. Here we see two different sets of covariant points. Each point has coordinates x and y, but those are just stand-ins for whatever two variables we are interested in comparing. The more consistently the change in y tracks the change in x, the stronger the covariance.</p>
<figure>
<img src="Images/F02020.png" alt="F02020" width="447" height="203"/>
<figcaption><p><a id="figure2-20">Figure 2-20</a>: Each diagram shows a different set of points with positive covariance. </p></figcaption>
</figure>
<p>In the left-hand side of <a href="#figure2-20">Figure 2-20</a>, the change in y between each pair of horizontally neighboring points is roughly the same. This is positive covariance. On the right side, the change in y is a little more variable between each pair of points, indicating weaker positive covariance. A very strong positive covariance tells us that the two variables move together, so every time one of them changes by a given amount, the other changes by a consistent, predictable amount.</p>
<p><span epub:type="pagebreak" title="37" id="Page_37"/>If one value decreases<em> </em>whenever the other increases, we say the variables have <em>negative covariance</em>. <a href="#figure2-21" id="figureanchor2-21">Figure 2-21</a> shows two different sets of negatively covariant points.</p>
<figure>
<img src="Images/F02021.png" alt="F02021" width="425" height="168"/>
<figcaption><p><a id="figure2-21">Figure 2-21</a>: Each diagram shows a different set of points with negative covariance. </p></figcaption>
</figure>
<p>If the two variables have no such consistently matched motion, then the covariance is zero. <a href="#figure2-22" id="figureanchor2-22">Figure 2-22</a> shows some examples.</p>
<figure>
<img src="Images/F02022.png" alt="F02022" width="419" height="176"/>
<figcaption><p><a id="figure2-22">Figure 2-22</a>: Each of these sets of data points has zero covariance. </p></figcaption>
</figure>
<p>Our idea of covariance only captures relationships between variables when their changes are multiples of each other. The graph on the right of <a href="#figure2-22">Figure 2-22</a> shows that there can be a clear pattern among the data (here the dots form part of a circle), but the covariance is still zero because the relationships are so inconsistent.</p>
<h3 id="h2-500723c02-0009">Correlation</h3>
<p class="BodyFirst">Covariance is a useful concept, but it has a problem. Because of the way it’s defined mathematically, it doesn’t take into account relationships between the units of the two variables, which makes it hard for us to compare the strengths of different covariances. For example, suppose we measured a dozen variables describing a guitar: the thickness of the wood, the length of the neck, the time that a note resonates, the tension on the strings, and so on. We might find the covariance between various pairs of these measurements, but we are not able to meaningfully compare the amount of covariance to find which pairs have the strongest and weakest relationships. Even the scale matters: if we find the covariance for a pair of measurements in centimeters and the covariance for another pair of measurements in inches, we can’t compare those values to say which pair is more strongly covariant. </p>
<p><span epub:type="pagebreak" title="38" id="Page_38"/>The <em>sign </em>of the covariance is all we learn: a positive value means a positive relationship, a negative value means a negative relationship, and zero means no relationship. Having only the sign is a problem, because we really want to compare different sets of variables. Then we can find out useful information such as which variables are the most and the least strongly positively and negatively correlated. We can use that information to then prune the size of our dataset, for example, by removing one of the measurements in one or more strongly related pairs.</p>
<p>To get a measure that lets us make these comparisons, we can compute a slightly different number called the <em>correlation coefficient</em>, or just the <em>correlation</em>. This value starts with the covariance but includes one extra step of computation. The result is a number that does not depend on the units that were chosen for the variables. We can think of the correlation as a scaled version of the covariance, always giving us back a value between −1 and 1. A value of +1 tells us we have a <em>perfect positive correlation</em>, while a value of −1 tells us we have a <em>perfect negative correlation</em>.</p>
<p>Perfect positive correlation is easy to spot: all the dots fall along a straight line that moves northeast-southwest, as in <a href="#figure2-23" id="figureanchor2-23">Figure 2-23</a>.</p>
<figure>
<img src="Images/F02023.png" alt="F02023" width="425" height="176"/>
<figcaption><p><a id="figure2-23">Figure 2-23</a>: Plots showing perfect positive correlation, or a correlation of +1</p></figcaption>
</figure>
<p>What kind of relationship between points gives us a positive correlation, but somewhere in the range between 0 and 1? It’s one where the y value continues to increase with x, but the proportion won’t be constant. We might not be able to predict how much it changes, but we know that increases in x cause increases in y, and decreases in x cause decreases in y. <a href="#figure2-24" id="figureanchor2-24">Figure 2-24</a> shows dot diagrams for some of positive values of correlation between 0 and 1. The closer the dots are to falling on a straight line, the closer the correlation value is to 1. We say that if the value is near zero the correlation is <em>weak </em>(or <em>low</em>), if it’s around 0.5 it’s <em>moderate</em>, and if it’s near 1 it’s <em>strong </em>(or <em>high</em>).</p>
<figure>
<img src="Images/F02024.png" alt="F02024" width="687" height="146"/>
<figcaption><p><a id="figure2-24">Figure 2-24</a>: Examples of decreasing positive correlation from left to right</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="39" id="Page_39"/>Let’s now look at a correlation value of zero. A zero correlation means that there is no relationship between a change in one variable and a change in the other. We can’t predict what’s going to happen. Recall that the correlation is just a scaled version of the covariance, so when the covariance is zero, so is the correlation. <a href="#figure2-25" id="figureanchor2-25">Figure 2-25</a> shows some data with zero correlation.</p>
<figure>
<img src="Images/F02025.png" alt="F02025" width="409" height="172"/>
<figcaption><p><a id="figure2-25">Figure 2-25</a>: These patterns have zero correlation. </p></figcaption>
</figure>
<p>Negative correlations are just like positive ones, only the variables move in opposite directions: as x increases, y decreases. Some examples of negative correlations are shown in <a href="#figure2-26" id="figureanchor2-26">Figure 2-26</a>. Just like with positive correlation, if the value is near zero the correlation is <em>weak </em>(or <em>low</em>), if it’s around −0.5 it’s <em>moderate</em>, and if it’s near −1 it’s strong (or <em>high</em>).</p>
<figure>
<img src="Images/F02026.png" alt="F02026" width="687" height="146"/>
<figcaption><p><a id="figure2-26">Figure 2-26</a>: Examples of decreasing negative correlation, left to right</p></figcaption>
</figure>
<p>Finally, <a href="#figure2-27" id="figureanchor2-27">Figure 2-27</a> shows perfect negative correlation, or a correlation of −1.</p>
<figure>
<img src="Images/F02027.png" alt="F02027" width="409" height="170"/>
<figcaption><p><a id="figure2-27">Figure 2-27</a>: These patterns have a perfect negative correlation, or a correlation of −1.</p></figcaption>
</figure>
<p>A few other terms are worth mentioning because they pop up in documentation and literature from time to time. Our preceding discussion of two variables is usually called <em>simple correlation</em>. We can find the relationship between more variables, however, and this is called <em>multiple correlation</em>. If we have a bunch of variables but we’re only studying how two of them affect each other, that’s called <em>partial correlation</em>.</p>
<p><span epub:type="pagebreak" title="40" id="Page_40"/>When two variables have a perfect positive or negative correlation (that is, a value of +1 and −1), we say that the variables are <em>linearly correlated</em>, because (as we’ve seen) the points lie on a line. Variables described by any other values of the correlation are said to be <em>nonlinearly correlated</em>.</p>
<p><a href="#figure2-28" id="figureanchor2-28">Figure 2-28</a> summarizes the meanings of different values of linear correlation.</p>
<figure>
<img src="Images/F02028.png" alt="F02028" width="836" height="179"/>
<figcaption><p><a id="figure2-28">Figure 2-28</a>: Summarizing the meanings of different values of linear correlation</p></figcaption>
</figure>
<h2 id="h1-500723c02-0008">Statistics Don’t Tell Us Everything </h2>
<p class="BodyFirst">The statistics we’ve seen in this chapter tell us a lot about a set of data. But we shouldn’t assume that the statistics tell us everything. A famous example of how we can be fooled by statistics is composed of four different sets of 2D points. These sets look nothing like one another, yet they all have the same mean, variance, correlation, and straight-line fit. The data is known as <em>Anscombe’s quartet</em>, after the mathematician who invented these values (Anscombe 1973). The values of the four datasets are widely available online (Wikipedia 2017a).</p>
<p><a href="#figure2-29" id="figureanchor2-29">Figure 2-29</a> shows the four datasets in this quartet, along with the straight line that best fits each set.</p>
<p>The amazing thing about these four different sets of data is that they share many of the same statistics. The mean of the x values in each dataset is 9.0. The mean of the y values in each dataset is 7.5. The standard deviation of each set of x values is 3.16, and the standard deviation of each set of y values is 1.94. The correlation between x and y in each dataset is 0.82. And the best straight line through each dataset has a Y axis intercept of 3 and a slope of 0.5.</p>
<p>In other words, all seven of these statistical measures have almost the same values for all four sets of points (some of the statistics differ from one another when we look farther out into more digits). If we just went by the statistics, we’d assume that these four datasets were identical.</p>
<span epub:type="pagebreak" title="41" id="Page_41"/><figure>
<img src="Images/F02029.png" alt="F02029" width="694" height="472"/>
<figcaption><p><a id="figure2-29">Figure 2-29</a>: The four datasets in Anscombe’s quartet and the straight lines that fit them best</p></figcaption>
</figure>
<p><a href="#figure2-30" id="figureanchor2-30">Figure 2-30</a> superimposes all four sets of points, and their best straight-line approximations. All four lines are the same, so we only see one line in the plot.</p>
<figure>
<img src="Images/F02030.png" alt="F02030" width="694" height="491"/>
<figcaption><p><a id="figure2-30">Figure 2-30</a>: The four datasets of Anscombe’s quartet and their best straight-line fits, superimposed</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="42" id="Page_42"/>These four sets of data, while famous, are not special. If we want to make more sets of different data that have identical (or near-identical) statistics, we can make as many as we want (Matejka and Fitzmaurice 2017). The moral is that we shouldn’t assume that statistics tell us the whole story about any set of data.</p>
<p>Any time we work with a new set of data, it’s always worth spending time to get to know it. This can include computing statistics, but the investigative process usually also includes drawing plots and other visualizations. Generally speaking, the better we understand our data, the better we can design and train algorithms to learn from that data. </p>
<h2 id="h1-500723c02-0009">High-Dimensional Spaces</h2>
<p class="BodyFirst">Let’s visit one more topic dealing with numbers. It’s more of a concept than a statistical tool, but it influences how we think about our data when we do statistics, or machine learning, or almost anything else with large datasets.</p>
<p>In machine learning, we often bundle up many numbers into a single <em>sample</em>, or piece of data. For example, we might describe a piece of fruit by its weight, color, and size. We call each number a <em>feature </em>of the sample. A photograph would be described as a sample whose features are the numbers that describe the color of each pixel.</p>
<p>We often talk about how each sample is a point in some enormous <em>space</em>. If a sample has two features, we can plot the sample as a point, or dot, on a page by associating one feature with the X axis, and the other with the Y axis. If the sample has three features, we can place a dot in 3D space. But we often have samples with far more features. For example, a grayscale photograph that is 1,000 pixels wide by 1,000 pixels high is described by 1,000 × 1,000 pixel values. That’s a million numbers. We can’t draw a picture of a dot in a space with a million dimensions, and we can’t even imagine what such a space might look like, but we can reason about it by analogy with the 2D and 3D spaces we’re familiar with. This is an important mental tool for working with real data, so let’s get a feeling for the spaces occupied by samples with huge numbers of features.</p>
<p>The general idea is that each dimension, or axis, of a space corresponds to a single feature in our sample. It’s useful to think of all the features (that is, all the numbers) in our sample as making up a list. If we have a piece of data that has just one feature (say, a temperature), then we can represent that feature with a list that is only one number long. Visually, we need only show the length of a line to show the size of that measurement, as in <a href="#figure2-31" id="figureanchor2-31">Figure 2-31</a>. We call this line a <em>one-dimensional space</em>, because from any point on the line, we can only move in one dimension, or direction. In <a href="#figure2-31">Figure 2-31</a>, that one choice is horizontally.</p>
<figure>
<img src="Images/F02031.png" alt="F02031" width="532" height="62"/>
<figcaption><p><a id="figure2-31">Figure 2-31</a>: A piece of data with a single value requires only one axis, or dimension, to plot its value. Left: The X axis. Right: Some pieces of data represented by either dots on the X axis, or line segments of different lengths.</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="43" id="Page_43"/>If we have two pieces of information in a sample, say the temperature and wind speed, then we need a list that is two items long. To draw it, we need two dimensions, one for each measurement. Graphically, we usually use two perpendicular axes, as in <a href="#figure2-32" id="figureanchor2-32">Figure 2-32</a>. The location of a point is given by moving along the X axis by an amount given by the first measurement, and then along the Y axis by an amount given by the second measurement. We say that this is a <em>two-dimensional space</em>.</p>
<figure>
<img src="Images/F02032.png" alt="F02032" width="523" height="241"/>
<figcaption><p><a id="figure2-32">Figure 2-32</a>: If our data has two values, we need two dimensions, or axes, to plot that data. </p></figcaption>
</figure>
<p>If we have three values in our sample, then we use a list of three values. As before, each value has a corresponding dimension in the space we’re going to plot it. These three dimensions can be represented using three axes, as in <a href="#figure2-33" id="figureanchor2-33">Figure 2-33</a>. We call this a <em>three-dimensional space</em>.</p>
<figure>
<img src="Images/F02033.png" alt="F02033" width="692" height="323"/>
<figcaption><p><a id="figure2-33">Figure 2-33</a>: When each piece of data has three values, we need three dimensions, or axes, to draw it. </p></figcaption>
</figure>
<p>What if we have four measurements? Despite some valiant efforts, there’s no generally accepted way to draw a four-dimensional space, particularly on a two-dimensional page (Banchoff 1990; Norton 2014; ten Bosch 2020). And once we start getting up to five, ten, or a million dimensions, drawing a picture of the space is pretty much a lost cause.</p>
<p><span epub:type="pagebreak" title="44" id="Page_44"/>It might seem that these high-dimensional spaces are esoteric and rare, but in fact they’re common and we see them every day. As we saw, a grayscale picture that’s 1,000 pixels on a side has a million values, corresponding to 1,000,000 dimensions. A color picture of the same size has 3,000,000 values, so it’s a point (or a dot) in a space of three million dimensions. There’s no way we can draw a picture with that many dimensions. There’s no way we can even picture one in our minds. Yet our machine learning algorithms can handle such a space as easily as if it had two or three dimensions. The mathematics and algorithms don’t care how many dimensions there are. </p>
<p>The key thing to keep in mind is that each piece of data can be interpreted as a single point in some vast space. Just as a two-dimensional (2D) point uses two numbers to tell us where it is on the plane, a 750,000-dimensional point uses 750,000 numbers to tell us where it’s located in that enormous space. We often name spaces so that we can keep track of what they describe, so we might say that our image is represented by a single point in a <em>picture space</em>. </p>
<p>We call spaces that have lots of dimensions <em>high-dimensional spaces</em>. There’s no formal agreement on just when “high” begins, but the phrase is often used for spaces that have more than the three dimensions we can reasonably draw. Certainly, dozens or hundreds of dimensions would qualify as high for most people. </p>
<p>One of the great strengths of the algorithms we’ll be using in this book is that they can handle data with any number of dimensions. Computations take more time when more data is involved, but in theory, we can handle data with 2,000 dimensions the same way as data with 2 dimensions (in practice, we usually tune our algorithms and data structures to be most efficient with the dimensionality of the dataset they’ll be working with). </p>
<p>We’ll frequently work with data that can be thought of as points in abstract, high-dimensional spaces. Rather than dive into the math, we’ll rely on an intuitive generalization of the ideas we’ve just seen, thinking of our spaces as giant (and unvisualizable) analogies of our line, square, and cube, where each piece of data is represented by a point in some vast, abstract space where each direction, or dimension, corresponds to a single value in the sample. We need to be careful about relying on our intuition too much, though. In Chapter 7, we’ll see that high-dimensional spaces don’t always behave like the 2D and 3D spaces we’re used to.</p>
<h2 id="h1-500723c02-0010">Summary</h2>
<p class="BodyFirst">We often need to characterize collections of numbers. The field of statistics is devoted to finding useful ways to describe such collections. In this chapter, we looked at basic statistical measurements that will be useful to us throughout the book. We saw that a convenient way to control the kinds of numbers we need in machine learning is to use a distribution, and we saw some useful distributions.</p>
<p><span epub:type="pagebreak" title="45" id="Page_45"/>We saw that we can choose elements from a population with or without replacement, giving us different kinds of collections. We can use the statistics of many such collections, or bootstraps, to estimate the statistics of the starting population. We looked at the ideas of covariance and correlation, which give us a way to measure the amount by which a change in one variable predicts the change in another. And we saw that we can think of lists of numbers as points in spaces of any number of dimensions.</p>
<p>In the next chapter, we’ll turn to the ideas of probability, in which we take random events and try to describe how likely they are to happen, and how likely one event is to be followed by another, or occur at the same time as another. </p>
</section>
</div></body></html>