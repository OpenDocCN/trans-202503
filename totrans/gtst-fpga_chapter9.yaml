- en: <samp class="SANS_Futura_Std_Bold_Condensed_B_11">9</samp> <samp class="SANS_Dogma_OT_Bold_B_11">USEFUL
    FPGA PRIMITIVES</samp>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../images/opener-img.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So far, you’ve learned about the two most fundamental FPGA components: the
    LUT and the flip-flop. These general-purpose components are the main workhorses
    in your FPGA, but there are also other dedicated components that are commonly
    used in FPGA designs for more specialized tasks. These components are usually
    called *primitives*, but they’re also sometimes referred to as *hard IP* or *cores*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Working with primitives helps you get the most out of your FPGA. In fact, a
    lot of modern FPGA development revolves around linking together these pre-existing
    primitives, with custom code added as needed for application-specific logic. In
    this chapter, we’ll explore three important primitives: the block RAM (BRAM),
    the digital signal processor (DSP) block, and the phase-locked loop (PLL). You’ll
    learn what role each one plays within an FPGA and see how to create them through
    your Verilog or VHDL code, or with assistance from your build tools.'
  prefs: []
  type: TYPE_NORMAL
- en: The primitives we’ll discuss are especially important on higher-end FPGAs, more
    advanced than the iCE40 FPGAs we’ve focused on so far. With these feature-rich
    FPGAs, the companion GUI software has become a critical piece of the build process.
    These GUIs are more complicated than the iCEcube2 tool we’ve been working with,
    and a large part of the complexity stems from the creation and wiring up of these
    primitives. Once you have an understanding of how the primitives work, however,
    you’ll be better equipped to start working with these more advanced tools and
    to take full advantage of the common built-in features of professional-grade FPGAs.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">How to Create Primitives</samp>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a few different ways to create an FPGA primitive. Up to this point,
    we’ve been writing Verilog or VHDL and letting the synthesis tools decide for
    us how to translate that code into primitives. We trust the tools to understand
    when we want to create a flip-flop or a LUT. This is called *inference*, since
    we’re letting the tools infer (or make an educated guess about) what we want based
    on our code.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, the tools are able to understand our intentions quite well. However,
    there are some primitives that the synthesis tools won’t be able to infer. To
    create those, you need to use another method: you can either explicitly instantiate
    the primitive in your code or use the GUI built into most synthesis tools to automate
    the creation process.'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Instantiation</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Instantiation* is the creation of a primitive from a code template written
    by the FPGA manufacturer. When you instantiate a primitive component, it looks
    like you’re instantiating a Verilog or VHDL module—but in this case, the module
    you’re instantiating isn’t one you’ve created. Rather, it’s built into the tools
    for your specific FPGA. The actual module code behind these primitives is often
    unavailable to view; it’s part of the secret sauce that the FPGA vendors like
    to keep to themselves.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example of how to instantiate a block RAM (we’ll talk more
    about these primitives later in the chapter):'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Oblique_BI_11">Verilog</samp>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: <samp class="SANS_Futura_Std_Bold_Oblique_BI_11">VHDL</samp>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This code is an example of instantiation of a RAMB18E1 component (a type of
    block RAM) from an AMD FPGA. The code makes the block RAM available for use by
    wiring its internal signals to signals external to the block RAM: for example,
    it wires the block RAM’s internal <samp class="SANS_TheSansMonoCd_W5Regular_11">DOADO</samp>
    signal, a 16-bit output, to an external signal of the same name ❶. I’ve omitted
    many more lines of code that make similar connections. It’s not important that
    you understand the details of this code; it’s just to demonstrate what instantiation
    looks like. Clearly a block RAM is a complicated component, with many bells and
    whistles available to you. Instantiation specifies every single input and output
    of the primitive and allows you to set them exactly as you want. However, it also
    requires that you have a deep knowledge of the primitive being instantiated. If
    you connect it improperly, it won’t work as intended.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wanted to, it would be possible to instantiate, rather than infer, even
    a simple component like a flip-flop. Here’s what AMD’s Verilog template looks
    like for instantiating a single flip-flop (which AMD calls an FDSE):'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Oblique_BI_11">Verilog</samp>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: <samp class="SANS_Futura_Std_Bold_Oblique_BI_11">VHDL</samp>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Notice that this primitive has the normal connections we’d expect from a flip-flop,
    including the data output (<samp class="SANS_TheSansMonoCd_W5Regular_11">Q</samp>),
    the clock input (<samp class="SANS_TheSansMonoCd_W5Regular_11">C</samp>), the
    clock enable (<samp class="SANS_TheSansMonoCd_W5Regular_11">CE</samp>), and the
    data input (<samp class="SANS_TheSansMonoCd_W5Regular_11">D</samp>). After instantiating
    this flip-flop, you could then make use of these connections in your code. If
    you had to instantiate every single flip-flop in your entire FPGA, however, it
    would take quite a lot of code!
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp>
  prefs: []
  type: TYPE_NORMAL
- en: '*I found the templates for the RAM18E1 block RAM and the FDSE flip-flop in
    AMD’s online Libraries Guide, which contains the templates for all primitives
    throughout AMD FPGAs. Every FPGA manufacturer has a similar resource where you’ll
    find the instantiation templates for its primitives.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The benefit of instantiating a primitive is that it gives you exactly what
    you want. You don’t need to trust the synthesis tools to guess at what you’re
    trying to do. However, there are clearly some downsides. As you’ve just seen,
    instantiation takes more code than inference. It also requires you to wire up
    every connection correctly, or the design won’t function as intended. This means
    you need to understand the primitive at a deep level. Finally, each primitive
    needs to be instantiated using a dedicated template specific to your FPGA vendor,
    or sometimes specific to just a subset of devices within a family of FPGAs. For
    example, the RAMB18E1 block RAM component we instantiated earlier only exists
    on AMD FPGAs; Intel and Lattice FPGAs have their own block RAMs. Therefore, instantiation
    makes your code less portable than writing more generic Verilog or VHDL where
    the tools can just infer the primitive based on which FPGA you’re targeting. Next,
    we’ll look at the alternative: using the GUI.'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">The GUI Approach</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Every FPGA vendor has its own GUI or IDE for FPGA development, and that GUI
    will have a section allowing you to view the library of available primitives for
    your FPGA. You can select a primitive that you want to add to your project, and
    the tool will walk you through the process. Additionally, the GUI explains how
    the primitive works and what each setting controls. [Figure 9-1](#fig9-1) shows
    an example of creating a block RAM using the Lattice Diamond GUI. As mentioned
    in [Chapter 2](chapter2.xhtml), this is Lattice’s IDE for working with higher-end
    FPGAs with features like the primitives discussed in this chapter. (The iCEcube2
    IDE doesn’t have a GUI for creating primitives, since it’s designed to work primarily
    with simpler FPGAs.)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-1.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-1: Instantiating a
    block RAM with a GUI</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The block diagram on the left side of the window visually demonstrates the block
    RAM’s inputs and outputs. In the configuration section on the right, it’s clear
    which selections for the primitive are mutually exclusive. These are represented
    with radio buttons, like Initialize to All 0’s or Initialize to All 1’s. We can
    also tell which options can be enabled or disabled. These are represented by checkboxes,
    like Enable Output Register or Enable Output ClockEn. In addition, there’s a convenient
    Help button in the bottom-right corner that can guide you through some of these
    decisions if you’re unsure what to pick.
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve configured a primitive with a GUI, you’ll get an instantiation template
    that you can drop into your Verilog or VHDL code, much like the one we looked
    at in the previous section. The template will be customized to the exact settings
    that you picked in the GUI so you can wire up your primitive without having to
    make any guesses about how to configure it.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to direct instantiation, the GUI method is more approachable for beginners.
    You’re much less likely to make a mistake using the GUI, since you have the menus
    to guide you, but you can still control exactly what you get, just like with instantiation.
    There is an important downside to this approach, however. If you need to change
    a setting in your primitive, then you need to open the GUI and run through the
    whole process again. This might not sound like a big deal, but if your design
    features many primitives created using a GUI, making adjustments can become quite
    tedious and time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">The Block RAM</samp>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *block RAM (BRAM)* is a dedicated memory storage component built into your
    FPGA. Next to LUTs and flip-flops, block RAMs are the third most common FPGA primitive.
    We touched briefly on block RAMs in [Chapter 6](chapter6.xhtml), when we discussed
    common memory modules like RAMs and FIFOs. As I mentioned in that chapter, when
    you need a memory over a certain size, it will be created using a block RAM instead
    of flip-flops.
  prefs: []
  type: TYPE_NORMAL
- en: Creating memory for storing data is an incredibly common task in FPGAs. You
    might use a block RAM for storing read-only data, like calibration values, or
    you might regularly write data to a block RAM from an off-chip device like an
    analog-to-digital converter (ADC) and then read from it later. Block RAMs are
    also commonly used to buffer data between a producer and a consumer, including
    when sending data between clock domains. In this case, the block RAM can be configured
    as a FIFO, with features specially designed to handle the metastability issues
    that arise when crossing between domains (we discussed how you can transmit data
    across cross clock domains back in [Chapter 7](chapter7.xhtml)).
  prefs: []
  type: TYPE_NORMAL
- en: The number of block RAMs available, and the specific features of each block
    RAM, will vary from FPGA to FPGA and vendor to vendor. You should always consult
    your FPGA’s datasheet and memory guide for details particular to your model. As
    an example, [Figure 9-2](#fig9-2) shows a datasheet highlighting the block RAMs
    on Intel’s Cyclone V line of FPGAs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-2.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-2: Block RAMs on the
    Cyclone V product line</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Intel refers to block RAMs as *memory blocks*. The first of the highlighted
    lines in the datasheet is telling us how many of these memory blocks are available
    on each of three FPGA models: 176 on the 5CEA2 FPGA, 308 on the 5CEA4, and 446
    on the 5CEA5 part. The next line on the datasheet shows the total number of kilobits
    (Kb) of block RAM storage available. Each memory block holds 10Kb (hence the *M10K*
    in the name), so there are 1,760Kb of BRAM storage on the 5CEA2 FPGA, 3,080Kb
    on the 5CEA4, and 4,460Kb on the 5CEA5.'
  prefs: []
  type: TYPE_NORMAL
- en: You might be surprised by how little storage that really is. Even the largest
    amount, 4,460Kb, is less than a megabyte! Consider the fact that you can get a
    32-gigabyte MicroSD card, which has thousands of times more storage space, for
    around $10, and you’ll start to appreciate that FPGAs aren’t designed for storing
    data in any significant quantity. Rather, block RAMs are there to buffer data
    on the FPGA for temporary usage. If you need to store large amounts of data, you’ll
    have to use an external chip to do that. MicroSD cards, DDR memory, SRAM, and
    flash memory are common examples of chips that an FPGA might interface to in order
    to expand its memory storage and retrieval capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: You should also notice in [Figure 9-2](#fig9-2) that block RAMs are the fourth
    item in the Cyclone V datasheet’s list of FPGA resources, after LEs, ALMs, and
    registers. Those are the terms that Intel uses to describe LUTs and flip-flops
    (LE stands for logic element and ALM for Adaptive Logic Module). While you may
    not always need many block RAMs for your application, this prime position in the
    datasheet highlights that block RAMs are often one of the most significant primitive
    components to take into consideration when choosing an FPGA.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Features and Limitations</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are some common features and some limitations that are helpful to keep
    in mind when working with block RAMs. First, block RAMs usually come in only one
    size on an FPGA; 16Kb per block RAM is common. This one-size-fits-all approach
    means that if you only need to use 4Kb out of the 16Kb, you’ll still use up an
    entire block RAM primitive. There’s no way to divide a single block RAM component
    into multiple memories, and in that way, block RAMs can be limiting.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other ways, however, block RAMs can be quite flexible. You can store data
    in whatever width you like: for example, with a 16Kb block RAM you can store data
    that’s 1 bit wide and 16,384 bits (2^(14)) deep, or 8 bits wide and 2,048 deep,
    or 32 bits wide and 512 deep, among other possibilities. It’s also possible to
    create memories that are larger than a single block RAM. For example, if you needed
    to store 16 kilobytes (KB) of data, that would use up eight individual block RAMs
    (16Kb × 8 = 16KB). The tools are smart enough to cascade the block RAMs and make
    them look like one large memory, rather than eight individual components that
    you need to index into individually.'
  prefs: []
  type: TYPE_NORMAL
- en: Other common features include error detection and correction, where the block
    RAM has some extra bits reserved to detect and correct any errors that might occur
    within the memory itself (that is, when a 1 changes to a 0, or vice versa). If
    that happens in your memory, a value could be completely corrupted and produce
    very strange behavior when the FPGA tries to analyze it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Error detection and correction are two separate but related processes: the
    FPGA can *detect* some number of bit errors and notify you about their presence,
    and, separately, it can automatically *correct* some number of bit errors. The
    number of bit errors that can be corrected is usually less than the number of
    bit errors that can be detected. The important thing here is that error detection
    and correction within a block RAM are performed automatically, without you having
    to do anything.'
  prefs: []
  type: TYPE_NORMAL
- en: Many block RAMs can also be initialized to default values. This can be a useful
    feature if you need to store a large number of initial values or if you want to
    create read-only memory (ROM). Pushing those values to a block RAM rather than
    taking up flip-flops for data storage can be a valuable way to save resources.
    We touched on this idea back in [Chapter 7](chapter7.xhtml), when we were looking
    at parts of Verilog and VHDL that are synthesizable and not synthesizable. Even
    though reading from a file is normally not synthesizable—remember that there’s
    no filesystem on an FPGA unless you create it yourself—we can read data from files
    as part of the synthesis process to preload a block RAM with default values. Again,
    I recommend consulting the memory guide for your particular FPGA to find out which
    features it supports.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Creation</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When using a block RAM in your design, I generally recommend inferring it.
    As you saw in [Chapter 6](chapter6.xhtml), when we create a two-dimensional memory
    element, the tools will easily recognize it. Whether or not this memory gets pushed
    to a block RAM depends on its size. Again, the synthesis tool is smart about this:
    it knows how many bits of memory you’re creating, and if it’s above some threshold,
    then it will be pushed to a block RAM. Otherwise, the tool will just use flip-flops.
    For example, if you’re creating a memory that holds 16 bytes, it will likely be
    pushed to flip-flops. You only need 16 × 8 = 128 bits of memory, so it doesn’t
    make much sense to use an entire 16Kb block RAM for this small quantity of data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'At which point the tools will start pushing memory to block RAMs instead of
    using flip-flops is highly dependent on the situation. To find out what your tool
    decided for a particular design, consult your utilization report after synthesis.
    Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The utilization report lists the number of block RAMs required ❶, just as it
    lists the number of flip-flops (registers) and LUTs (LUT4s, or four-input LUTs
    in this case). If you see that no block RAMs are being used, then your memory
    was inferred as flip-flops instead. As a reminder, I always recommend double-checking
    your utilization report to make sure the tools are inferring what you expect.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re wary of trying to infer large memory elements, or you’re confused
    about which features you may or may not want to take advantage of in your block
    RAM, then creating it with a GUI is your best option. The GUI will guide you through
    the process, so for beginners it’s very helpful. Using the GUI is also the best
    way to ensure that you’re using a FIFO correctly when crossing clock domains,
    as it can help you handle the complexities involved.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">The Digital Signal Processing Block</samp>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Digital signal processing (DSP)* is a catch-all term for performing math-based
    operations on signals within a digital system. Often these math operations need
    to happen very fast and in parallel, which makes FPGAs an excellent tool for the
    job. Since DSP is such a common FPGA application, another kind of FPGA primitive,
    the *DSP block*, exists for this purpose. DSP blocks (also known as *DSP tiles*)
    specialize in performing mathematical operations, in particular *multiply–accumulate
    (MAC)*, which is an operation where a multiplication is followed by an addition.
    Before we look more closely at these primitives, however, it’s worth taking a
    step back to discuss the difference between analog and digital signals.'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Analog vs. Digital
    Signals</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An *analog signal* is a continuous signal representing some physical measurement.
    A common example is the audio signal stored on a vinyl record (a big black shiny
    thing that has music on it, sometimes seen in old movies or new hipster bars).
    The record is etched with a continuous groove that mirrors the continuous waveform
    of the audio. Then a record player reads that waveform with a needle and amplifies
    the resulting signal to play back the sound. The information is always analog;
    no conversion is needed.
  prefs: []
  type: TYPE_NORMAL
- en: '*Digital signals*, on the other hand, aren’t continuous. Rather, they consist
    of discrete measurements at individual points in time, with gaps in between. A
    common example is the audio signal stored on a CD, where the sound is represented
    as a series of 1s and 0s. If you have enough discrete measurements, you can fill
    in the gaps to create a reasonably accurate approximation of an analog signal
    from those digital values. A CD player reads those digital values and rebuilds
    an analog waveform from them. The result is always an approximation of the original
    analog signal, however, which is why some audiophiles prefer the true analog signal
    of a record to digital media like CDs and MP3s.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Within your common FPGA fabric, like LUTs and flip-flops, data is represented
    digitally. So what do you do if you have some analog signal that you need to bring
    into your FPGA? This is the purpose of an ADC: it converts an analog signal into
    a digital one by *sampling* it, or recording its value, at discrete points in
    time. [Figure 9-3](#fig9-3) shows how this works.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-3.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-3: Digital sampling
    of an analog signal</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: 'The undulating line moving from left to right in the figure represents a continuous
    analog signal, and the dark points along that line represent the individual samples
    taken of that signal to convert it into a digital form. Notice that the samples
    are taken at regular time intervals. The frequency at which the analog signal
    is sampled is called the *sampling frequency* or *sampling rate*. The higher the
    sampling rate, the more accurately we can represent an analog signal, because
    it’s easier to connect the discrete dots into something that looks like the original
    waveform. However, a higher sampling rate also means that we have more data that
    we have to process: each dot represents some number of bits of digital data, so
    the more dots you have, the more bits you’re working with.'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Common DSP Tasks</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'FPGAs commonly take an analog signal as input, digitize it, and then do some
    math to process that digital data. As an example, let’s say we have an audio signal
    that we’ve sampled within our FPGA. Let’s furthermore assume that the recorded
    data was too quiet, so when it’s played back it’s hard to hear. How can we manipulate
    the digital signal such that the output volume is louder? One simple thing we
    can do is multiply every digital value by some constant, say 1.6\. This is called
    applying *gain* to a signal. How would we accomplish this within an FPGA? It’s
    quite simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We take the <samp class="SANS_TheSansMonoCd_W5Regular_11">input_signal</samp>,
    multiply every discrete digital value in that signal by <samp class="SANS_TheSansMonoCd_W5Regular_11">1.6</samp>,
    and store the result in the <samp class="SANS_TheSansMonoCd_W5Regular_11">gain_adjusted</samp>
    output. Here is where the DSP primitive comes into play. When we write code like
    this, the synthesis tools will see that we’re performing a multiplication operation
    and infer a DSP block for us automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Applying gain to an input signal doesn’t require parallel processing. There’s
    only one multiplication operation per data sample, and the data samples can be
    processed one after the other. Often, however, you’ll need to perform many mathematical
    operations in parallel by running several DSP blocks simultaneously. A common
    example is creating a *filter*, a system that performs mathematical operations
    on a signal to reduce or enhance certain features of the input signal. A *low-pass
    filter (LPF)*, for instance, keeps the frequency components of a signal that are
    below some cutoff while reducing the frequencies that are above that cutoff, which
    can be useful for removing high-frequency noise from an input signal. Lowering
    the treble slider on your audio system is a real-world example of applying a low-pass
    filter, since it will reduce high frequencies within the audio. The details of
    implementing a digital LPF are beyond the scope of this book, but since it requires
    many multiplication and addition operations all occurring at the same time, FPGAs
    are well suited for the task.
  prefs: []
  type: TYPE_NORMAL
- en: Another example of parallel math that might be performed in an FPGA is processing
    video data to create a blur effect. Blurring video involves replacing individual
    pixel values with the average value of a group of neighboring pixels. This requires
    performing math on the many pixels in an image at the same time, and this must
    happen quickly since the video data consists of many images per second. An FPGA
    is very capable of performing these parallel mathematical operations using DSP
    blocks.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Features</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: DSP blocks are versatile primitives, providing many features that facilitate
    different math operations. You won’t always need every feature for your application—most
    often, you’ll just be performing a multiplication or addition operation—but for
    more complicated scenarios, the DSP block can be set up to solve a wide range
    of problems. [Figure 9-4](#fig9-4) provides a detailed look at a DSP block in
    an FPGA from AMD. Each manufacturer’s DSP primitive is a bit different, but this
    example is representative of the typical features available.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-4.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-4: Block diagram of
    a DSP primitive</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: 'This diagram actually shows a simplified version of the DSP block. It’s not
    critical to understand the complete anatomy of the primitive, but it’s worth pointing
    out a few things. First, notice that this DSP block can take up to four inputs
    and has two outputs. This allows for more applications than simply multiplying
    two numbers together: for example, MAC, where the result of a multiplication is
    fed back into the input at the next clock cycle for an addition operation.'
  prefs: []
  type: TYPE_NORMAL
- en: Toward the left-hand side of the block diagram, you can see a *pre-adder* block.
    This can be enabled if an addition operation is requested prior to another mathematical
    operation. To the right of this, near the middle of the diagram, is a circle with
    an X in it. This is the *multiplier*, which is the heart of the DSP block. It
    performs multiplication operations at very high speeds. To its right is a circle
    labeled ALU, short for *arithmetic logic unit*, which can perform more operations,
    like addition and subtraction. Finally, there are built-in output registers that
    can be enabled to sample the outputs and help meet timing at fast data rates.
  prefs: []
  type: TYPE_NORMAL
- en: Like the number of block RAMs, the number of DSP blocks available to you will
    vary from FPGA to FPGA. Some higher-end FPGAs have thousands of DSP blocks inside
    them; again, you should consult your FPGA’s datasheet for details specific to
    your model. As an example, [Figure 9-5](#fig9-5) highlights the information on
    DSP blocks in the datasheet for Intel’s Cyclone V product line.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-5.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-5: DSP blocks on Cyclone
    V FPGAs</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the DSP block information comes just below the block RAM information,
    again pointing to the importance of these primitives in FPGA development. The
    5CEA2 FPGA has 25 DSP blocks, but that increases to 66 for the 5CEA4 and 150 for
    the 5CEA5\. Each DSP block has two multipliers, so on the second highlighted line
    we can see that there are twice as many 18 × 18 multipliers (where 18 is the width
    of the inputs) as there are DSP blocks.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp>
  prefs: []
  type: TYPE_NORMAL
- en: '*If there aren’t any DSP blocks available on your FPGA, that doesn’t mean you
    can’t perform these types of operations. Multiplication and addition operations
    will just be implemented with LUTs, rather than with dedicated DSP blocks. We’ll
    discuss this further in [Chapter 10](chapter10.xhtml).*'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Creation</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As with block RAMs, I generally recommend using inference to create DSP blocks.
    Most of the multiplication operations you’ll need to do will require two inputs
    and one output, as you saw earlier when we applied gain to a signal. It’s simple
    enough to write the relevant code in Verilog or VHDL and let the tools handle
    the rest. Remember to check your synthesis report to ensure that you’re getting
    what you expect, but I’ve had good luck with the synthesis tools understanding
    my intent with addition and multiplication and pushing those operations to DSPs
    where relevant. The user guides for your particular FPGA will also provide you
    with suggestions on how to write your Verilog or VHDL code to help ensure the
    tools understand your intentions.
  prefs: []
  type: TYPE_NORMAL
- en: If you have more complicated needs for your DSP blocks, or if you want to explore
    all of the features and capabilities internal to them, then you should probably
    create them using a GUI to ensure you get what you want. [Figure 9-6](#fig9-6)
    shows an example of creating a multiplier within the Lattice Diamond GUI.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-6.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-6: Creating a DSP
    block with a GUI</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: One thing to highlight here is the Block Implementation drop-down menu. You
    can change this from DSP to LUT to use look-up tables rather than a DSP block
    to perform this multiplication operation. As mentioned previously, LUTs and DSPs
    are both capable of performing math operations, including multiplication. With
    the DSP block, however, you’ll save LUT resources, and you’ll be able to run the
    math operation at much faster clock rates, since you’ll be using a dedicated primitive
    highly optimized for math.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">The Phase-Locked Loop</samp>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *phase-locked loop (PLL)* is a primitive commonly used as the main clock
    generator for your entire FPGA. Very often, you’ll have an external clock chip
    that runs at some frequency. On some FPGAs, you can simply use that input clock
    to feed all of your synchronous logic directly, as we’ve done in this book’s projects.
    In this case, your logic frequency will be fixed at the frequency of whatever
    external clock you picked. But what happens if you need to change that frequency?
    Without a PLL, you would need to physically remove the external clock chip and
    replace it with a different component that generates the clock frequency you want
    to switch to. With a PLL, however, you can generate a different clock frequency
    inside your FPGA by changing a few lines of code, without requiring a new external
    component.
  prefs: []
  type: TYPE_NORMAL
- en: PLLs also make it easy to have multiple clock domains in your FPGA design. Say
    you have some external memory that runs at 100 MHz, but you want your main logic
    to run at 25 MHz. You *could* purchase a second external clock and feed that into
    your FPGA, but a better solution is to use a PLL, since this primitive can generate
    multiple clock frequencies simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Not all FPGAs have a PLL, but many have at least one, and some have several.
    The datasheet will tell you what’s available. As an example, [Figure 9-7](#fig9-7)
    highlights the PLLs available on Intel’s Cyclone V product line.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-7.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-7: PLLs on the Cyclone
    V product line</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The 5CEA2 and 5CEA4 FPGAs both have four PLLs, while the 5CEA5 has six. Given
    that each PLL can generate multiple clocks, that should be more than enough for
    all your clocking needs.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">How It Works</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A PLL serves as the source of your clock distribution throughout your FPGA by
    taking a single clock input, often called the *reference clock*, and generating
    one or more clock outputs from it. The input clock comes from a dedicated external
    component, and the outputs can run at completely different frequencies from the
    input clock and from one another. The block diagram in [Figure 9-8](#fig9-8) shows
    the most common signals on a PLL.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-8.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-8: Common PLL signals</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: 'The PLL typically takes two inputs: a clock signal and a reset. The reset input
    will stop the PLL from running when it’s asserted.'
  prefs: []
  type: TYPE_NORMAL
- en: On the output side, the PLL has some number of output clocks in the range 1
    to *N*, with the maximum number depending on the FPGA. The output clocks can be
    of different frequencies, depending on what you need for your design. These frequencies
    are achieved by taking the input reference clock and multiplying and/or dividing
    it to get the desired value. For example, say you have a 10 MHz input reference
    clock, and you want a 15 MHz output clock. The PLL would multiply the reference
    clock by 3 (giving you 30 MHz), then divide it by 2 to get down to 15 MHz. The
    multiplication and division terms must be integers, so it’s important to realize
    that you can’t get any arbitrary frequency out of the PLL. It isn’t possible to
    get a π MHz clock output from a 10 MHz clock input, for example, since π is an
    irrational number that can’t be expressed as the ratio of two integers.
  prefs: []
  type: TYPE_NORMAL
- en: Besides varying the frequency of the output clock(s), a PLL can also vary their
    phase. A signal’s *phase* is its current position along the repeating waveform
    of the signal, measured as an angle from 0 to 360 degrees. It’s easiest to picture
    what this means by comparing two signals that share a frequency but aren’t aligned
    in time. [Figure 9-9](#fig9-9) demonstrates some common phase shifts of a clock
    signal.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-9.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-9: Common phase shifts</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: As this figure shows, shifting the phase of a clock signal results in moving
    the location of its rising edges. Compare the first rising edge of <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp>
    (which has no phase shift) with the first rising edge of <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">+</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">90°</samp>
    (which is phase-shifted by 90 degrees). The rising edge of <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">+</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">90°</samp>
    is delayed by one-quarter of a clock period relative to <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp>.
    Each increment of 90 degrees shifts the signal by another quarter period. Continuing
    the example in the figure, we have <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">+</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">180°</samp>,
    which is delayed by 90 degrees from <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">+</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">90°</samp>
    and 180 degrees from <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp>.
    Notice that <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">+</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">180°</samp> is actually the same waveform
    that you would get if you took the <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp>
    signal and inverted it by swapping the highs and lows. Finally, <samp class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp><samp
    class="SANS_TheSansMonoCd_W5Regular_11">+</samp><samp class="SANS_TheSansMonoCd_W5Regular_11">270°</samp>
    is delayed by three-quarters of a clock period relative to the original <samp
    class="SANS_TheSansMonoCd_W5Regular_11">Clk</samp> signal. If you went a full
    360 degrees, you’d be back to your original signal. This example has demonstrated
    positive phase shifts, but phase can also be negative, meaning the signal is shifted
    backward in time compared to the other. Of course, you can shift the phase by
    any arbitrary angle, not just in 90-degree steps.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Dogma_OT_Bold_B_21">NOTE</samp>
  prefs: []
  type: TYPE_NORMAL
- en: '*Creating clocks with phase shifts isn’t very common in simple designs, but
    it can be useful in some applications. For example, it might be important for
    interfacing to external components, like some off-FPGA memory.*'
  prefs: []
  type: TYPE_NORMAL
- en: Returning to the block diagram in [Figure 9-8](#fig9-8), a PLL also typically
    has a *locked* output signal, which tells any module downstream that the PLL is
    operating and you can “trust” the clocks. It’s a common design practice to use
    this locked signal as a reset to other modules relying on the PLL’s clocks. When
    the PLL isn’t locked, the modules downstream of the PLL are held in a reset state
    until the PLL is locked and ready, meaning the output clocks can be used by other
    modules in your FPGA design. When the PLL’s reset input is driven high its locked
    output will go low, putting the downstream modules back into a reset condition.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re going to use a PLL in your design, it’s a good idea to use *only*
    the PLL’s outputs for all your clocking needs. Even if part of your design runs
    at the same clock frequency as the external reference clock, you shouldn’t use
    the external clock directly to drive that part of the design. Instead, have the
    PLL output a clock signal at the same frequency as the external reference. By
    only using the PLL’s outputs, you can tightly control the relationships between
    the output clocks. Additionally, you can confidently use the locked output of
    the PLL for your reset circuitry, knowing it reflects the state that *all* clocks
    in your design are operational.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Creation</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The PLL is one primitive that I recommend using a GUI to create, since the synthesis
    tools won’t be able to infer a PLL. Instantiation is also possible, but it’s prone
    to errors. You need to choose PLL settings that are compatible with one another
    for the PLL to work successfully, and during instantiation it’s easy to pick settings
    that won’t work. If you had a 10 MHz reference clock and you wanted to generate
    one 15 MHz output and a separate 89 MHz output, for example, that simply might
    not be possible, but you might miss that fact during instantiation.
  prefs: []
  type: TYPE_NORMAL
- en: When you create a PLL using the GUI, you tell it your input reference clock
    and desired output clock frequencies, and the tool will tell you if it can find
    a solution that works. Continuing the 10/15/89 MHz example, the GUI might tell
    you that the closest value to 89 MHz that it can give you is 90 MHz (since 90
    MHz is a multiple of both 10 MHz and 15 MHz, this is likely to work). Then it’s
    up to you to decide whether 90 MHz will work for your design or if you really
    need 89 MHz, in which case you might need to use a separate PLL or change your
    reference clock. [Figure 9-10](#fig9-10) shows an example of the PLL GUI within
    Lattice Diamond.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-10.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-10: Creating a PLL
    with a GUI</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the GUI helps guide us through the PLL creation process. In
    this case, we have a 30 MHz reference on <samp class="SANS_TheSansMonoCd_W5Regular_11">CLKI</samp>,
    and we’re setting the desired output frequencies to 30 MHz on <samp class="SANS_TheSansMonoCd_W5Regular_11">CLKOP</samp>,
    60 MHz on <samp class="SANS_TheSansMonoCd_W5Regular_11">CLKOS</samp>, 15 MHz on
    <samp class="SANS_TheSansMonoCd_W5Regular_11">CLKOS2</samp>, and 89 MHz on <samp
    class="SANS_TheSansMonoCd_W5Regular_11">CLKOS3</samp>. Notice that for each clock
    except <samp class="SANS_TheSansMonoCd_W5Regular_11">CLKOS3</samp>, the actual
    frequency on the far right matches the desired frequency. For <samp class="SANS_TheSansMonoCd_W5Regular_11">CLKOS3</samp>,
    when I first tried to create an 89 MHz clock with 0.0 percent tolerance, I got
    the error message shown in [Figure 9-11](#fig9-11).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-11.png)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-11: Actionable feedback
    from invalid PLL settings</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: Not until I changed the tolerance to 2.0 percent did the error message go away;
    the tool had selected an actual frequency of 90 MHz, which is within 2.0 percent
    of the requested frequency. This type of guidance isn’t provided if you try to
    instantiate your PLL directly.
  prefs: []
  type: TYPE_NORMAL
- en: Another helpful feature of the GUI is the PLL block diagram, shown in the left
    half of [Figure 9-10](#fig9-10). This diagram will be updated if you modify the
    inputs or outputs. For example, if we disabled <samp class="SANS_TheSansMonoCd_W5Regular_11">CLKOS3</samp>,
    that output would disappear from the block diagram to reflect that we only want
    to output three clock signals. This is useful to ensure you’re creating what you
    expect. Notice that there’s also a separate Phase tab near the top of the window,
    which allows us to specify phase shifts on our output clocks.
  prefs: []
  type: TYPE_NORMAL
- en: 'After designing a PLL in the GUI, you can run your design through the normal
    synthesis process. The utilization report will confirm you’re getting a PLL, as
    it’s one of the main primitives highlighted in the report. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This indicates one PLL is being used out of four available on this particular
    FPGA.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Summary</samp>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The majority of your Verilog and VHDL code will be dedicated to creating LUTs
    and flip-flops, which are the two most fundamental FPGA components. However, as
    you’ve seen in this chapter, FPGAs also contain other primitive components, such
    as block RAMs, DSP blocks, and PLLs, that add specialized functionality. Block
    RAMs add dedicated memory, DSP blocks enable high-speed parallel math operations,
    and PLLs allow you to generate different internal clock frequencies. With a combination
    of these FPGA building blocks, you’ll be able to solve a wide range of problems
    efficiently.
  prefs: []
  type: TYPE_NORMAL
