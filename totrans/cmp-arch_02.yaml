- en: '**1**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**HISTORICAL ARCHITECTURES**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Image](../images/f0003-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Computer science is a much older subject than many people think. This chapter
    will begin 40,000 years ago and progress to the present day. A modern microchip
    may seem impenetrable and alien at first sight, but if you know the history, you
    can understand its smaller components in terms of structures that have developed
    gradually over thousands of years.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of other reasons to study the history of the field. Seeing
    the deep history of computer science gives us more credibility and authority as
    a field distinct from, say, mathematics or engineering. Seeing how ideas have
    evolved gradually by building on one another can also protect us from myths of
    the “lone genius” and reveal how such people were perhaps just like ourselves.
    Finally, following the general trends through “the arc of history” not only explains
    how we got to where we are but can also suggest where we’re headed next, to help
    us predict, or create, the future.
  prefs: []
  type: TYPE_NORMAL
- en: What Is a Computer?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we imagine “a computer” today, we probably think of a device such as a
    desktop PC, game console, or smartphone. But those aren’t the only machines humans
    have used for calculating and computing. To trace the history of computers, we
    first need to decide what counts as a computer and how computers are different
    from mere calculators or calculating machines. This is a surprisingly difficult
    question, one that is still argued over. My own rule of thumb for deciding if
    something is a computer is, Can you program *Space Invaders* on it? A simple calculator
    can’t do this, so it isn’t a computer; a programmable calculator usually can,
    so it is a computer.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some further concepts that are often suggested for defining computers.
    Some sources—including the *Oxford English Dictionary*—require computers to be
    electronic. But similar machines can be made out of other substrates, such as
    water. Consider *MONIAC*, which stands for Monetary National Income Analogue Computer,
    a pun on the earlier ENIAC computer that we’ll examine later in the chapter. Built
    in 1949, and shown in [Figure 1-1](ch01.xhtml#ch01fig1), MONIAC was an analog
    water computer used to simulate the flow of money through the economy and to illustrate
    the effects of economic interventions on an economic model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0004-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-1: The MONIAC water computer and its creator, Bill Phillips*'
  prefs: []
  type: TYPE_NORMAL
- en: MONIAC allowed you to increase the interest rate and observe the effects on
    unemployment. Tanks of water showed the positions of money in sectors of the economy
    such as the central bank, savings, and investment, according to the theory of
    economics built into the machine.
  prefs: []
  type: TYPE_NORMAL
- en: Some people argue computers must be *digital*, as opposed to *analog*. A digital
    machine is one that represents data using *digits*, discrete sets of symbols such
    as the binary digits 0 and 1\. In contrast, an analog machine has an infinite,
    continuous set of possible states, such as the amounts of water in MONIAC’s tanks,
    making MONIAC an analog machine.
  prefs: []
  type: TYPE_NORMAL
- en: Where does MONIAC stand regarding my original *Space Invaders* test? It only
    computes results for a single economic model, although it might be able to run
    other economic models if we were able to reconfigure some of the tubes and reservoirs
    to have different sizes and connections. By extension, perhaps MONIAC could implement
    *any* computation, such as running *Space Invaders*, through more severe reconfigurations
    of this nature. But would we then have the same computer in a new configuration,
    or would we have a new, different machine that still only computes one other,
    different, thing? In other words, is MONIAC *reprogrammable*?
  prefs: []
  type: TYPE_NORMAL
- en: I’ve been using *Space Invaders* as a test program, but it’s tempting to say
    that for something to be a computer, you must be able to reprogram it to do *anything*.
    However, computation theory shows that this can’t be used as a definition. Given
    any candidate computer, it’s always possible to find problems it can’t solve.
    These are usually problems about predicting the candidate computer’s own future
    behavior, which can lead it into an infinite loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Diving a little deeper into computation theory, we get *Church’s thesis*, a
    more rigorous definition of a computer that most modern computer scientists agree
    with. It can be paraphrased as:'
  prefs: []
  type: TYPE_NORMAL
- en: A computer is a machine that can simulate any other machine, given as much memory
    as it asks for.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll call machines that satisfy Church’s thesis *Church computers*. In particular,
    machines clearly exist that can do the following, so a Church computer must also
    be able to perform these tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Read, write, and process data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read, write, and execute programs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add (and hence do arithmetic)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jump (`goto` statements)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Branch (`if` statements)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can now see that the *Space Invaders* definition is a reasonable approximation
    of Church’s thesis in many cases: while *Space Invaders* is a simplistic video
    game, it happens to require all of the above tasks, which are also the basic ingredients
    of many other computational tasks and machines. Hence, a machine that can be *reprogrammed*
    (rather than hardwired) to play *Space Invaders* is usually powerful enough to
    simulate any other machine, too (as long as we provide as much extra memory as
    it asks for).'
  prefs: []
  type: TYPE_NORMAL
- en: The rest of this chapter traces the history of computers and computerlike devices
    in chronological order, starting in the Stone Age. As you read, ask yourself who
    invented the first computer, and note the point where you think the computer was
    invented. People often argue for drawing this line in different places, based
    on their own definitions of what counts as a computer. Where will *you* draw the
    line, and why?
  prefs: []
  type: TYPE_NORMAL
- en: Before the Industrial Revolution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we’ll take a look at the various preindustrial machines we
    may or may not consider to be computers. In doing so, we’ll see that humans have
    been using mechanisms resembling computers for longer than we might have thought.
  prefs: []
  type: TYPE_NORMAL
- en: '*The Stone Age*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our anatomical species, *Homo sapiens*, is around 200,000 years old, but it’s
    widely believed that we lacked modern intelligence until the cognitive revolution
    of around 40,000 BCE. We don’t know exactly how this happened. One current theory
    is that a single genetic mutation in the FOXP2 gene occurred and was selected
    by the extreme evolutionary pressures of the Ice Age. This suddenly enabled the
    brain to form arbitrary new hierarchical concepts, in turn giving rise to language
    and technology. According to this theory, from then on humans were as intelligent
    as we are now. They would have been capable of learning, say, quantum computing,
    had they been given access to modern facilities and information.
  prefs: []
  type: TYPE_NORMAL
- en: One marker of this shift may be the *Lebombo bone*, shown in [Figure 1-2](ch01.xhtml#ch01fig2)—a
    bone with carved notches that may have been used as a tally stick around 40,000
    BCE. In a tally, one mark represents one physical thing. Perhaps these notches
    signified animals, items of food, favors owed by one person to another, or days
    to time some hunting or social project.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0006-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-2: The Lebombo bone*'
  prefs: []
  type: TYPE_NORMAL
- en: The *Ishango bone*, shown in [Figure 1-3](ch01.xhtml#ch01fig3), is another bone
    containing human-made tally-like marks, dating to later in the Ice Age, around
    20,000 BCE. Unlike the Lebombo bone, the Ishango bone marks appear to be grouped
    into tally-like clusters of mostly prime numbers between 3 and 19, and these clusters
    are grouped into three lines that sum to 60 or 48.
  prefs: []
  type: TYPE_NORMAL
- en: As with the Lebombo bone, it’s possible that the marks in the Ishango bone are
    at purely random locations and were made for some physical purpose, such as to
    improve hand grip. But several authors have studied the Ishango bone’s patterns
    and argued that they functioned as a tally, an aid for calculation, a lunar agricultural
    calendar or menstrual cycle calendar, or most speculatively, a table of prime
    numbers. The totals of 60 and 48 are multiples of 12, and 12 is known to have
    been the original base for arithmetic in later civilizations, before we shifted
    to base 10.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0007-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-3: The Ishango bone, argued by some to extend from tallying to calculation*'
  prefs: []
  type: TYPE_NORMAL
- en: The Lebombo bone appears to be an example of data representation. Arguably,
    it may have been used for a simple form of calculation such as adding one to its
    total each time a new mark was made. Some interpretations of the Ishango bone
    suggest its use in more advanced calculations, perhaps interactively, like using
    a pen and paper to perform and keep track of multiple steps of a math problem.
  prefs: []
  type: TYPE_NORMAL
- en: Could you program a bone to play *Space Invaders*? You could devise a set of
    rules for a human to follow, telling them to make scratches to update representations
    of the game characters. Gameplay would be quite slow, and the human would have
    to be there to perform the updates. There’s no evidence that humans ever used
    bones in this programmable way—though maybe one day another bone could be found
    and its scratches decoded as instructions for a human operator to follow.
  prefs: []
  type: TYPE_NORMAL
- en: '*The Bronze Age*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The ice melted around 4000 BCE, enabling the first cities to grow. Cities required
    new and larger forms of organization, such as keeping track of trading and taxes.
    To enable this, by 3000 BCE the Sumerian city culture in Mesopotamia (modern-day
    Iraq) developed the first writing system, and by 2500 BCE it possessed the first
    indisputable calculating machine, the abacus ([Figure 1-4](ch01.xhtml#ch01fig4)).
    The word *abacus* means “sand box,” which suggests that before this date the same
    machinery was implemented using simple rocks in the sand. The oldest abaci we
    find in archaeology are the more advanced ones made from wood and beads.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0008-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-4: An abacus*'
  prefs: []
  type: TYPE_NORMAL
- en: In its usual usage, the state of the abacus in [Figure 1-4](ch01.xhtml#ch01fig4)
    represents the (decimal, natural) number 070710678\. There are nine columns, each
    representing one of the digits in this number. Each column is split into a lower
    box containing five beads and an upper box containing two beads. The default position
    for the beads in the lower box is down, and the default position for beads in
    the upper box is up. In this state, a column represents the digit 0\. Each bead
    pushed up from the bottom to the top of the lower box is worth 1\. Each bead pushed
    down from the top to the bottom of the upper box is worth 5.
  prefs: []
  type: TYPE_NORMAL
- en: To add 1 to a number on the abacus (that is, *increment* it), you raise one
    bead from the lower box of the rightmost column. If all five beads in a column’s
    lower box are raised, you push them all back down and replace them by lowering
    one of the beads in the upper box in the same column. If both upper beads are
    lowered, you push them back up and replace them by raising one bead from the lower
    box in the column on its left. Moving data from a column to the one on its left
    is known as a *carry* operation.
  prefs: []
  type: TYPE_NORMAL
- en: To add two numbers, *a* + *b*, you first set up the abacus to represent the
    digits of *a*. You then perform *b* increments as above. The state of the abacus
    then represents the result.
  prefs: []
  type: TYPE_NORMAL
- en: This style of calculation—where the first number is “loaded onto” the device
    and the second is “added into” it, leaving only the final result as the state
    of the system—is known as an *accumulator architecture*, and it’s still in common
    use today. It “accumulates” the result of a series of calculations; for example,
    we can add a list of many numbers together by adding each of them in turn into
    the state and seeing the latest accumulated total after each addition.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*The abacus in this example uses decimal digits for familiarity. The original
    Sumerian version used base 12.*'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of the algorithm dates from this time. Calculations written on clay
    tablets, such as those in [Figure 1-5](ch01.xhtml#ch01fig5), show that number-literate
    people at this time thought in terms of computation rather than mathematics, being
    taught to perform algorithms for arithmetic operations and carrying them out for
    practice, as opposed to doing proofs.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0009-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-5: A tablet showing the steps of a long division algorithm*'
  prefs: []
  type: TYPE_NORMAL
- en: The clay tablets show lines of step-by-step arithmetic that may have been performed
    using the tablets themselves as data storage. Or the tablets may have been used
    to notate the states of an abacus for teaching purposes.
  prefs: []
  type: TYPE_NORMAL
- en: The abacus was—and in a few places still is—most often used for adding numbers,
    such as summing the prices of items in a shopping basket, but other ancient abacus
    arithmetic algorithms are also known, including for subtraction, multiplication,
    and long division. These were performed similarly to their modern pen-and-paper
    equivalents. Modern enthusiasts (you can search for them on YouTube) have also
    shown how to use the abacus for more advanced algorithms such as finding square
    roots and computing the digits of *π*. As these algorithms get more complex, the
    memory of the abacus often needs to be extended with extra columns. Like the Stone
    Age bones, the abacus could be used as the data store for *any* algorithm if a
    human is instructed what actions to perform on it. If you want to argue that it’s
    a computer, you may again need to consider the role of the human.
  prefs: []
  type: TYPE_NORMAL
- en: '*The Iron Age*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Bronze Age city civilizations of Mesopotamia and its neighbors collapsed,
    mysteriously, around 1200 BCE. They were followed by a “dark age” period, until
    classical ancient Greece arose around 500 BCE to 300 BCE: the time of Pythagoras,
    Plato, and Aristotle. Greek power was gradually replaced by the Roman Republic
    and Roman Empire from around 300 BCE to 400 CE.'
  prefs: []
  type: TYPE_NORMAL
- en: The Antikythera mechanism ([Figure 1-6](ch01.xhtml#ch01fig6)) dates from this
    period, around 100 BCE. It was found in 1901 in a Mediterranean shipwreck; the
    sunken ship appeared to be on its way from Greece to Rome, with the mechanism
    for sale or as tribute. The mechanism was only understood and reverse engineered
    in 2008\. We now know that it was a mechanical, clockwork analog machine used
    to predict astronomical (and likely astrological) events, including five planet
    positions, moon phases, and the timings of eclipses and the Olympic Games. It
    consisted of 37 bronze gears, and the user turned a handle to simulate the future
    course of their states. The results were displayed on clock faces, computed by
    the ratios of mechanical gears. Enthusiasts recently rebuilt a functioning version
    using LEGO ([Figure 1-6](ch01.xhtml#ch01fig6)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0010-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-6: The Antikythera mechanism remains, as found in a Mediterranean
    shipwreck (left), and a reconstructed Antikythera mechanism using LEGO (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Odometers* were long-range distance-measuring machines that the Greeks and
    Romans used to survey and map their empires. There is indirect evidence of their
    use from around 300 BCE due to the existence of very accurate distance measurements
    that would have been hard to obtain any other way. The reconstruction in [Figure
    1-7](ch01.xhtml#ch01fig7) is based on direct archaeological remains from around
    50 CE.'
  prefs: []
  type: TYPE_NORMAL
- en: This type of odometer worked similarly to the measuring wheels you might have
    used in elementary school that clicked each time they were pushed a certain distance,
    typically 1 yard or 1 meter. It is also related to modern odometers used in cars
    and robotics.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0011-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-7: A Roman odometry cart*'
  prefs: []
  type: TYPE_NORMAL
- en: The odometer is pulled by a horse, like a cart. There are a number of metal
    balls stored in cavities in a circular wooden gear. One of the wheels has a peg
    attached so that once per rotation it taps and rotates the gear by a small fixed
    angle. A ball-sized hole under one position of the gear allows a ball above it
    to fall out of its cavity and into a collecting box below. The total distance
    traveled is thus logged by the number of balls in the counting box at the end
    of the trip.
  prefs: []
  type: TYPE_NORMAL
- en: 'Are these machines computers? There are clearly notions of data being used
    to represent objects in the world, as well as forms of automation and calculation.
    But like MONIAC, each machine does only one thing: predict eclipses or measure
    distance. You couldn’t easily reprogram either to play *Space Invaders*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like MONIAC, the Antikythera mechanism is an analog machine: its gears rotate
    continuously and can be in any position. The odometer, in contrast, is digital,
    like the abacus. Its gear advances only by a discrete amount with each “click”
    as the peg passes it, and the collecting box always holds a discrete number of
    balls. Unlike the abacus, however, the odometer is automatic; it doesn’t require
    a human operator, only a horse as a source of power.'
  prefs: []
  type: TYPE_NORMAL
- en: You might be able to reprogram the Antikythera mechanism—and with some creativity,
    the odometer—if you were allowed to completely reconfigure all the gears, including
    adding and removing gears of arbitrary sizes in arbitrary locations. Then you
    could try to represent and simulate other physical systems or perform other calculations.
    As with MONIAC, some consider physically reconfiguring the hardware in this way
    to be cheating. They would argue that this creates a new, different machine, rather
    than a different program running on the original machine.
  prefs: []
  type: TYPE_NORMAL
- en: '*The Islamic Golden Age*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: After the fall of Rome in 476 CE, western Europe entered the so-called Dark
    Ages for a thousand years, and the history of computing in western Europe records
    basically no progress during this time.
  prefs: []
  type: TYPE_NORMAL
- en: However, the Roman Empire continued to operate from its new eastern capital,
    Byzantium (now Istanbul, Turkey). There was a flow of ideas between Byzantium,
    Greece, and the Islamic world, the latter becoming the new intellectual center
    of the time. A particular musical idea from this culture introduces the important
    concept of programming.
  prefs: []
  type: TYPE_NORMAL
- en: The ancient Greeks previously had a portable *hydraulis* instrument, related
    to modern church organs. It was composed of a set of pipes, played by a keyboard
    and powered from an air reservoir pumped by a servant. The Greeks clearly possessed
    the technology needed to make self-playing versions of the hydraulis, but there’s
    no evidence of them doing so.
  prefs: []
  type: TYPE_NORMAL
- en: 'It was Islamic scholars, the Banu Musa brothers, who built the first known
    automated musical instrument: the automated flute player of Baghdad, around 900
    CE, shown in [Figure 1-8](ch01.xhtml#ch01fig8).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0012-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-8: A Greek hydraulis (left) and a sketch of the Baghdad automated
    flute player (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The innovation was to use a slowly rotating barrel with movable pins around
    its edge to indicate the positions of musical notes. As the barrel rotates, the
    pins make contact with levers that allow air to flow into the instrument to sound
    a note. The movable nature of the pins allows different compositions to be programmed
    into the device, making it the first known *programmable* automatic machine. The
    pins may be viewed today as a binary code: at each time and pitch, there is either
    a note (1) or no note (0).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Is this a computer? Unlike the Iron Age machines, it can clearly run multiple
    programs. However, there’s no notion of calculation or of decisionmaking: once
    a program begins, it will play through and can’t change its behavior in response
    to any input or even to its own state.'
  prefs: []
  type: TYPE_NORMAL
- en: '*The Renaissance and Enlightenment*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Byzantium fell in 1453, sending many scholars and their books back to western
    Europe and helping it wake from the Dark Ages. Leonardo da Vinci was the definitive
    “renaissance man” of this time: a prolific scientist, artist, and engineer. He
    possessed many of these old books and looked to them for inspiration. He was probably
    familiar with Antikythera-like systems thanks to these books. One of his manuscripts
    from around 1502, the *Codex Madrid*, contains an unbuilt design ([Figure 1-9](ch01.xhtml#ch01fig9))
    for a mechanical analog calculator based on Antikythera-like principles.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0013-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-9: The da Vinci calculator’s original manuscript*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The design was rediscovered and successfully constructed in 1968\. There are
    13 wheels, each representing the columns of a decimal number. Their possible positions
    are *continuous*: rather than switching abruptly from one decimal digit to another,
    they move smoothly by means of gearing. The gear ratio is 1:10 between each pair
    of columns, so each column’s wheel rotates at one-tenth the speed of the column
    on its right.'
  prefs: []
  type: TYPE_NORMAL
- en: Like the abacus, the calculator is an accumulator whose state at any point in
    time represents a single number, again as digits in columns. One number *a* can
    be added to another *b*. The first number *a* could be loaded onto the machine
    by advancing the mechanism to represent its digits. Then it would be turned an
    additional amount *b* to advance the total to *a* + *b*.
  prefs: []
  type: TYPE_NORMAL
- en: For example, to calculate 2,130 + 1,234, we first load 2,130 onto the device,
    then advance by 1,234 to get 3,364\. The numbers wouldn’t be precisely aligned
    at the end of the computation due to the continuous rotation of the wheels. For
    example, the 6 in the tens place would be almost halfway between showing 6 and
    7 because the digit after it is a 4, which is almost halfway to the next carry.
    In a sense it is a “weaker” machine than the Roman odometer, because the odometer
    has a notion of converting from continuous wheel positions to discrete symbols
    using its pin-and-ball mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Da Vinci’s concept was extended by Blaise Pascal in 1642\. [Figure 1-10](ch01.xhtml#ch01fig10)
    shows Pascal’s calculator design and a modern build of it. (It has recently been
    argued that Pascal’s calculator was invented earlier, in 1623, by Wilhelm Schickard.)
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0014-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-10: Pascal’s calculator: the original design and a 2016 LEGO rebuild*'
  prefs: []
  type: TYPE_NORMAL
- en: Pascal’s calculator includes a digital mechanism similar to the odometer (rather
    than da Vinci’s analog gearing) to implement its carry mechanism. When a column
    reaches the number 9 and another unit is added to it, it triggers a unit turn
    of the next column as it returns itself to the number 0.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the Antikythera mechanism, which represented the states of physical (astronomical)
    objects, da Vinci’s and Pascal’s machines operate on pure numbers. You could argue
    this gives them more general-purpose roles than the Antikythera mechanism. That
    said, the range of their calculations is limited to addition, which in a sense
    makes them less powerful than the abacus, which had algorithms for other arithmetic
    operations. On the other hand, like the Antikythera mechanism, these calculators
    require less human work than an abacus.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some see the move from da Vinci’s analog to Pascal’s digital operation as very
    important. Digital operation appears to involve a simple concept of the machine
    making a “decision”: a carry is either made or not made at each step. Decision-making
    is certainly important for some tasks, but clearly not so much for addition because
    both calculators can do it equally well.'
  prefs: []
  type: TYPE_NORMAL
- en: The Steam Age
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Steam power had been known to the Greeks and Romans as a curiosity, and anyone
    who has ever boiled water with a lid will have noticed that steam can move the
    lid around. But it was only from around 1700 in Britain that steam was harnessed
    in earnest, to power the industrial revolution. Seeded by Enlightenment ideas,
    especially Newton’s physics, this was a positive feedback cycle in which machines
    and coal were used to produce more machines and extract more coal. Coal was burned
    to heat water into steam, and steam was first used to pump water from coal mines.
    In time, steam came to power many other machines, some with computer-like characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: '*The Jacquard Loom*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The production of textiles was a major application of new machines during the
    Steam Age. But unlike plain cotton clothes, traditional weaving patterns were
    highly complex. Thus they were considered to be more valuable because they were
    rarer and more expensive.
  prefs: []
  type: TYPE_NORMAL
- en: In 1804, Joseph Jacquard created a variant of the weaving machines of the time
    that employed replaceable punched cards to guide the positions of the hooks and
    needles used in the weave ([Figure 1-11](ch01.xhtml#ch01fig11)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0015-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-11: A Jacquard loom*'
  prefs: []
  type: TYPE_NORMAL
- en: The punched cards could be “chained” together into long tapes to make complex,
    reusable patterns at a lower price.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*“Chain” became the standard command to load the next program from magnetic
    tapes in later electronic devices, used until the 1990s. Weaving concepts like
    “thread” and “warp” are also used as metaphors in modern multithreaded programming
    and in parallel GPUs.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Victorian Barrel Organs and Music Boxes*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Barrel-based musical instruments, similar in technology to the Baghdad automatic
    flute player and shown in [Figure 1-12](ch01.xhtml#ch01fig12), were popular during
    the 19th century. The job of an “organ grinder” was to push a portable barrel
    organ onto a main street, then manually turn its handle to provide power. A rotating
    barrel with pins marking the positions of notes would then allow air into the
    organ pipes, as in the Baghdad version.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0016-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-12: Two Victorian-style barrel organs (left and center) and a music
    box (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: The same mechanism was (and still is) used in the music box from this period,
    in which a spring is wound up to store energy and then released to power a smaller
    pinned barrel, whose pins strike small xylophone-like metal bars directly to play
    a few bars of music such as a famous theme from a ballet. The rotating barrel
    is often topped with a small sculpture, such as a ballerina, that rotates along
    with the music.
  prefs: []
  type: TYPE_NORMAL
- en: Charles Babbage hated organ grinders playing outside his house and led a public
    campaign to rid them from the streets of London. But their barrel organs were
    to form a fundamental influence on his work.
  prefs: []
  type: TYPE_NORMAL
- en: '*Babbage’s Difference Engine*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Babbage designed two different machines, the Difference Engine and the Analytical
    Engine. The former ([Figure 1-13](ch01.xhtml#ch01fig13)) was first; it was successfully
    built and commercialized by Georg Scheutz and others from 1855 and widely used
    in industry until the 1930s. Recent LEGO rebuilds also exist.
  prefs: []
  type: TYPE_NORMAL
- en: The Difference Engine was designed to produce tables of values of arbitrary
    polynomial functions. Most mathematical functions can be well approximated by
    polynomials via Taylor series expansion, so the machine could be used to make
    tables of values for any such function. You may have used similar tables in modern
    exams to look up values of trigonometric or statistical functions when a calculator
    isn’t allowed. In Babbage’s time, the killer application of these tables was in
    shipping, for navigation purposes. Tables had previously been computed by hand
    and contained many expensive errors, so there was a large economic demand to perfect
    them by machine.
  prefs: []
  type: TYPE_NORMAL
- en: The machine can be powered either by steam or by a human cranking the handle.
    Like Pascal’s calculator, the Difference Engine represents decimal digits by discretized
    rotations of gears. Numbers are represented by a vertical column of such digits
    (like Pascal’s calculator turned on its side). The Difference Engine then extends
    this to a 2D parallel architecture, with multiple vertical columns arranged horizontally.
    Each of these columns represents a different number.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0017-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-13: A metal rebuild of Babbage’s Difference Engine*'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two dimensions of parallelization in the Difference Engine: digit-wise
    and term-wise. Digit-wise addition, for example, is a different algorithm from
    the sequential high school method of addition. Instead of starting from the rightmost
    column and moving left and applying carries, it adds each pair of digits at the
    same time, then handles any carrying afterward. For example, to add 364 + 152,
    the three additions 3 + 1, 6 + 5, and 4 + 2 are all performed at the same time
    to give 416\. The carry from 6 + 5 = 11 is then added to give 516\. Carrying is
    a difficult operation to get right in this context, and Babbage devoted most of
    his engineering time to it. The visual effect of carries can be seen on YouTube
    videos of the Difference Engine as a visible ripple of information propagating
    across the 2D surface of the machine. Such ripples are also seen in computations
    on modern parallel GPUs.'
  prefs: []
  type: TYPE_NORMAL
- en: Is the Difference Engine a computer? It can run different “programs” to calculate
    different equations, but these equations have no obvious concept of changing their
    behavior during a calculation; there’s nothing like an if statement to test intermediate
    results and do something different based on them. It’s more like a modern media
    streaming device in which numbers flow smoothly through a processing pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '*Babbage’s Analytical Engine*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Difference Engine was limited to computing tables of polynomial functions,
    but Babbage’s second project, the Analytical Engine ([Figure 1-14](ch01.xhtml#ch01fig14)),
    was designed as a completely general-purpose, programmable machine.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0018-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-14: A modern partial rebuild of Babbage’s Analytical Engine*'
  prefs: []
  type: TYPE_NORMAL
- en: To obtain this generality, the Analytical Engine provides a range of arithmetic
    and other operations as simple machines, together with a memory for storing data
    and the ability to read in programs from punch cards. The programs dictate a sequence
    of memory reads and writes and arithmetic operations, and allow branching depending
    on the state of the calculation—an if statement.
  prefs: []
  type: TYPE_NORMAL
- en: Babbage went through many variations of the Analytical Engine’s design on paper,
    but physically built only a tiny part of it just before he died. He got very sidetracked
    with the fine details of the carry mechanism and was obsessed with constantly
    redesigning components rather than sticking with one version and getting them
    integrated to actually work. (Today this style of project management would be
    known as *yak shaving*.) This annoyed the research funding agencies of the time,
    making it hard for Babbage to get money to build anything. Thus, unlike with the
    Difference Engine, we don’t have a working version or even a single final design
    document of the Analytical Engine. However, components have recently been reconstructed
    from Babbage’s plans using modern manufacturing technologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'With more moving parts than the Difference Engine, the Analytical Engine would
    have required more power; this would have had to come from a steam engine rather
    than a manual crank. It would have also required more precisely machined gears,
    as computations would need to work their way through a longer series of gears.
    Like the factory machines and steam locomotives of the period, it would have smelled
    of oil, smoke, and steam, and gleamed in polished brass: Babbage was the original
    steampunk.'
  prefs: []
  type: TYPE_NORMAL
- en: The core of the Analytical Engine contained many independent simple machines
    that each performed some function, such as adding numbers and testing if one number
    equaled another. The adding machine was roughly a copy of Pascal’s calculator,
    and the other simple machines were variations of it.
  prefs: []
  type: TYPE_NORMAL
- en: The Analytical Engine introduced the modern concept of computer memory. Its
    “store” would have consisted of a large number of copies of a simple machine,
    again similar to a Pascal calculator, each of which could retain a different number.
    Each machine would be given a numerical identifier or “address” to specify the
    correct one to read from or write to.
  prefs: []
  type: TYPE_NORMAL
- en: A sequence of *instructions* would have been coded in binary and punched onto
    paper tape, using a mechanism taken from the Jacquard loom. Each instruction would
    tell the engine to activate one of the simple machines. Usually, after each instruction,
    the machine would have line-fed the punched paper along to load the next one (a
    bit like a typewriter). However, the machine also would have had the ability to
    check the result of the latest simple machine and, depending on its value, could
    jump to a different line in the paper. This would give programs the ability to
    alter their behavior in response to intermediate results.
  prefs: []
  type: TYPE_NORMAL
- en: A program could also be made to run forever by gluing the bottom of the punched
    paper to its top, making a physical loop, as in the (later) paper tape machine
    shown in [Figure 1-15](ch01.xhtml#ch01fig15).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0019-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-15: A punch tape program loop*'
  prefs: []
  type: TYPE_NORMAL
- en: We don’t have any examples of actual programs written for the Analytical Engine.
    Rather, Babbage and his collaborator Ada Lovelace wrote down example *states*
    and *outputs* from imaginary runs as long tables, showing them at each step of
    program execution. This is similar to the notations on the Babylonians’ clay tablets,
    which illustrate algorithms by showing the effects rather than the instructions
    used to generate them. From these execution traces, modern readers can infer roughly
    what the programs and the machine’s instruction set used to build them would have
    been.
  prefs: []
  type: TYPE_NORMAL
- en: Babbage wrote the first of these example traces for small, almost trivial mathematical
    functions, which illustrate roughly the full set of instructions in use. But Babbage
    was the hardware person, more concerned with designing the machine itself, and
    never wrote anything longer, thinking that programming would be relatively trivial
    compared to designing the architecture. Lovelace was the software person, and
    she wrote much longer traces for complex functions. She also wrote speculations
    about what larger programs could achieve, including ideas about AI. If Babbage
    is claimed as “the first programmer,” then Lovelace might be “the first software
    engineer” for thinking about programming more seriously and at scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'Was the Analytical Engine a Church computer? Its design contains all the basic
    features of a modern computer: CPU, memory, a bus, registers, a control unit,
    and an arithmetic unit. It can read, write, and process data. It can do arithmetic.
    Unlike the purely calculating machines before it, it can jump (goto) and branch
    (if), moving to different instructions in the program according to the state of
    its calculations.'
  prefs: []
  type: TYPE_NORMAL
- en: However, to be able to simulate any other machine, it would need to be able
    to read, write, and execute programs as well as read, write, and process data.
    But its programs were fixed on the punched paper, rather than held in memory like
    in a modern PC. This kind of architecture, where the data and program are stored
    separately, often with the program fixed as firmware, is called a *Harvard architecture*,
    as opposed to a *von Neumann architecture*, where the program and data are stored
    together.
  prefs: []
  type: TYPE_NORMAL
- en: Today, Harvard architectures are used in embedded systems, especially in digital
    signal processing chips. It’s possible to set up a Harvard architecture that can
    simulate other computers, including those that modify their own programs. This
    can be done by writing a single *virtual machine (VM)* program on the fixed program
    punch cards (or modern firmware). The VM reads, executes, and writes further programs
    in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lovelace or Babbage could have written a VM program for the Analytical Engine,
    but they didn’t consider it. The same could be said about many other machines,
    however. For example, a VM could be written for and executed on a Sumerian abacus
    if a programmer chose to do so. Church’s thesis is about the *potential* for a
    machine to simulate any other machine, not the actualization of it doing so. But
    it depends on what “level” of machine we consider: the underlying hardware or
    virtual machines running at higher software levels.'
  prefs: []
  type: TYPE_NORMAL
- en: And, of course, the Analytical Engine was never built or tested in full—does
    this need to be done to justify “being a computer,” or is the basic design sufficient
    by itself?
  prefs: []
  type: TYPE_NORMAL
- en: '*Mechanical Differential Analyzers*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The industrial revolution largely progressed through practical hackers building
    machines based on their intuitions, then testing whether they worked. But over
    time, mathematical theories were adapted or invented to describe and predict the
    behavior of many engineering systems, giving rise to academic engineering. Most
    of these theories made use of calculus. Developed earlier by Gottfried Wilhelm
    Leibniz and (independently) Sir Isaac Newton for different purposes, calculus
    quickly took off as a general tool for modeling how all kinds of systems, including
    industrial machinery, change over continuous time, through equations such as
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0021-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *x* is part of the state of the world being modeled, *f* is some function
    of it, and *dx*/*dt* is the rate of change of *x*. This type of equation can numerically
    simulate the state of the world over time by iteratively computing *dx*/*dt* and
    using it to update *x*. Like making the Difference Engine’s tables of polynomials,
    this is a highly repetitive and error-prone process ripe for mechanical automation.
  prefs: []
  type: TYPE_NORMAL
- en: In 1836, the same year that the Analytical Engine was developed, Gaspard-Gustave
    de Coriolis realized that since the behavior of a mechanical device could be *described*
    by a differential equation, the same device could be viewed as computing the solution
    to that equation. So, to solve a new equation, a physical device could be designed
    that matched it, and that device could then be run for a period of time to give
    the required answer.
  prefs: []
  type: TYPE_NORMAL
- en: More general differential equations can involve acceleration and higher derivatives,
    and multiple variables. Coriolis’s idea was extended by others, including Lord
    Kelvin in 1872 and James Thomson in 1876, to solve these systems, again by constructing
    analog mechanical devices to match them. The key component of these machines was
    the ball and disc integrator ([Figure 1-16](ch01.xhtml#ch01fig16)), in which a
    movable ball transfers motion from a spinning disc to an output shaft.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0021-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-16: A ball and disc integrator from Kelvin’s differential analyzer*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like the Difference Engine, these machines were built only to solve a single
    class of problems: differential equations. But much, or perhaps all, of the world
    and its problems can be modeled by differential equations. As inherently analog
    machines, they can be viewed as continuing the tradition of da Vinci’s analog
    calculator, while Babbage’s machine built on Pascal’s digital calculator.'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of using the physical properties of the world to model itself has
    recently been revived in quantum computing, where simulating physical and chemical
    quantum systems appears to be a major application with a particularly good fit
    to the way quantum machines compute.
  prefs: []
  type: TYPE_NORMAL
- en: The Diesel Age
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Between the purely mechanical machines of the industrial revolution and later
    electronic machines, there was a hybrid period in which electricity was combined
    with mechanical motion to build electromechanical machines.
  prefs: []
  type: TYPE_NORMAL
- en: The key electromechanical technology is the *relay*, a mechanical switch in
    an electrical circuit whose physical position is controlled using a magnet, which,
    in turn, is controlled by another electrical signal. Relays are a special type
    of *solenoid*, a coil of wire that generates a linear magnetic field when a current
    flows through it. This magnetic field can be used to physically move a magnet
    (called the *armature*) inside the coil, and that motion can be used, for example,
    to open and close a valve in a water pipe or to start a car engine. Replace the
    water pipe with a second electrical circuit, and the valve with an electrical
    switch, and you have yourself a relay.
  prefs: []
  type: TYPE_NORMAL
- en: Relays are still used today ([Figure 1-17](ch01.xhtml#ch01fig17)). For example,
    in robotics safety systems, we often need to physically connect and disconnect
    the main battery to and from the robot’s motors. A safety monitor checks if everything
    is okay and makes the physical relay connection if so, but disconnects it if anything
    seems wrong. You can hear these relays click when the current changes and the
    armature physically moves.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0022-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-17: A relay showing a wire coil*'
  prefs: []
  type: TYPE_NORMAL
- en: Electromechanical machines were more efficient than purely mechanical ones,
    and found widespread commercial and military use in the period around the turn
    of the 20th century and the two World Wars. Some of the machines you’ll see in
    the next section were still in use in the 1980s. Others have uncertain fates due
    to ongoing government secrecy, as this period includes the cryptology machines
    of World War II.
  prefs: []
  type: TYPE_NORMAL
- en: '*The IBM Hollerith Tabulating Machine*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The US Constitution requires that a census be taken and processed every 10 years,
    and by 1890 the population had grown to a size where human processing of its statistics
    was impossible. This created an embarrassing backlog of work for the government
    and a strong demand for an automated solution.
  prefs: []
  type: TYPE_NORMAL
- en: Herman Hollerith designed a machine to automate data processing and used it
    successfully in the 1890 census to do big data analytics on information from 62
    million citizens. Each citizen’s data was transferred from a written census form
    to a punch card by a human clerk. This seems to have been inspired not by Jacquard’s
    and Babbage’s machines, but independently by inspectors punching holes in train
    tickets to represent different journeys or times. Each question on the census
    was multiple choice, and was encoded on the punch card by punching out one of
    the several options. [Figure 1-18](ch01.xhtml#ch01fig18) shows an example of this.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0023-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-18: A replica of the IBM Hollerith machine (left) and a punched card
    (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Stacks of cards could be read into the machine, which would check for the presence
    or absence of certain features or combinations of features, then use an electrical
    analog of a Pascal calculator to accumulate the total count of cards having these
    features. As Hollerith (1894) explained:'
  prefs: []
  type: TYPE_NORMAL
- en: It is not sufficient to know simply the number of males and females, but we
    must know, for example, how many males there are at each age-period, as well as
    how many females at each age-period; or, in other words, we must count age and
    sex in combination. By a simple use of the well-known electrical relay we can
    secure this or any other possible combination. It must not be understood that
    only two items can be combined; in this way any number of items can be combined.
    We are only limited by the number of counters and relays.
  prefs: []
  type: TYPE_NORMAL
- en: This means that the machine is roughly capable of modern SQL queries, including
    `SELECT, WHERE, GROUP BY`, and `ORDER BY`.
  prefs: []
  type: TYPE_NORMAL
- en: Following the machine’s widely reported success in the 1890 census, Hollerith
    incorporated the Tabulating Machine Company in 1896\. It became the Computing-Tabulating-Recording
    Company in 1911, then International Business Machines (IBM) in 1924\. IBM was
    described as doing “super-computing” by the *New York World* newspaper in 1931
    and performed similar commercial big data analytics for many governments and companies
    before 1936\. It continues to do so today.
  prefs: []
  type: TYPE_NORMAL
- en: '*Electromechanical Differential Analyzers*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Analog mechanical differential analyzers reached widespread practical use when
    it became possible to power them using electricity. Electrical circuits also provided
    a major new application for differential analyzers, as they are often described
    using the same kinds of differential equations as used in mechanics. Hazen and
    Bush’s 1928 system, built at MIT, is often credited for the mass popularization
    of electromechanical differential analyzers, and its concept quickly spread to
    research teams at the universities of Manchester and Cambridge ([Figure 1-19](ch01.xhtml#ch01fig19))
    in the UK. Some of these British research machines were built using Meccano (similar
    to an Erector Set) on smaller budgets than the American versions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0024-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-19: Maurice Wilkes (right) with the mechanical Cambridge Differential
    Analyzer, 1937*'
  prefs: []
  type: TYPE_NORMAL
- en: Similar machines were used heavily throughout World War II to solve differential
    equations, such as when calculating projectile trajectories. By attaching pens
    to the machines’ moving parts, some teams added analog plotters to draw graphs
    on paper. Versions of these machines were still used in the 1970s as onboard missile
    guidance systems.
  prefs: []
  type: TYPE_NORMAL
- en: '*Electromechanical Machines of World War II*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Many popular histories focus on machines used during World War II for *cryptography*,
    the enciphering and deciphering of messages by a transmitter and receiver, and
    *cryptanalysis*, the cracking of ciphers. Together, these fields are known as
    *cryptology*. Cracking ciphers is harder than encrypting and decrypting them.
    Thus, cryptanalysis machines are the larger, more interesting ones. Should any
    of the machines from either or both categories qualify as “computers”? Their history
    has been concealed by government secrecy, and we’re still learning more as documents
    are made public. This uncertainty has been useful for some biased historians and
    filmmakers who want their own country or community to have invented the computer.
  prefs: []
  type: TYPE_NORMAL
- en: The original Enigma ([Figure 1-20](ch01.xhtml#ch01fig20)) was a 1923 electromechanical
    German commercial cryptography product sold to banks and governments in many countries,
    including America and Britain.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0025-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-20: The German Enigma wiring, showing four input keys (2), four output
    lamps (9), three rotors (5, 5, 5), a plugboard (8), and a reflector (6)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Enigma consists of a typewriter keyboard, output letter lamps, three rotors,
    and electric wiring. Each rotor acts to substitute a letter for each other letter.
    The input letter *a* is passed through the three rotors in sequence, then “reflected”
    (substituted for 26 – *a*) and passed backward through the three rotors again.
    Each time this is done, the end rotor advances by 1, with carries between rotors,
    as in Pascal’s calculator. Each configuration of a rotor produces a particular
    set of substitutions. All Enigma operations were symmetric: the same machine state
    would perform decryption on its own encrypted text. Several versions of the machine
    were used in the war.'
  prefs: []
  type: TYPE_NORMAL
- en: The German military M3 Enigma added a stage swapping pairs of letters using
    a plugboard. Seven years before the war, the Polish, led by Marian Rejewski, broke
    its encryption by designing and using a singlepurpose electromechanical machine,
    the *Bomba*. This incorporated physical Enigma rotors to brute-force all possible
    encodings of known message headers in advance. The daily keys were then looked
    up in a reverse-index filecard database. The Polish gave this system to the British
    at Bletchley Park (which later became GCHQ).
  prefs: []
  type: TYPE_NORMAL
- en: In 1938, the Germans changed protocol—not hardware—to remove the known message
    headers. The Polish mathematician and cryptologist Henryk Zygalski then broke
    the Enigma again, using optical computing. Information was transferred to punch
    cards, and the cards were stacked and held up to a light to very quickly find
    the locations where the light passes through the whole stack.
  prefs: []
  type: TYPE_NORMAL
- en: In 1939, the Germans increased the number of possible rotors to insert into
    the three slots from three to five. This increased the complexity beyond what
    Zygalski’s method could break. To break this version, the British switched to
    IBM Hollerith machines to perform similar computations at higher speeds.
  prefs: []
  type: TYPE_NORMAL
- en: '*Dolphin* was a stronger M3 protocol used by U-boats, including more swappable
    rotors and different headers. The *British Bombe* was designed based on the Polish
    Bomba and updated for the new task. The additional cryptology was done by Alan
    Turing, Gordon Welchman, and others, then the machine was designed and manufactured
    by Harold Keen of IBM.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Typex* was the British version of Enigma. Like the Germans, they made their
    own modifications to the commercial Enigma for their military communications.
    Typex was broken frequently by the B-Dienst—the German equivalent of Bletchley
    Park—using IBM Hollerith machines.'
  prefs: []
  type: TYPE_NORMAL
- en: In 1937, IBM president Thomas Watson met Hitler and received an award for the
    Hollerith machines’ “services to the Reich.” Hollerith machines were later leased
    from IBM by German concentration camps to enable the Holocaust’s precision—“timing
    so precise the victims were able to walk right out of the boxcar and into a waiting
    gas chamber.” They were used to merge big data sources such as census and medical
    records to produce lists of names and statuses of victims. IBM provided IT consultants
    to help with the software design, and to make monthly visits to service the machines
    on site.
  prefs: []
  type: TYPE_NORMAL
- en: '*The Zuse Z3*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Konrad Zuse was a German engineer who collaborated with the Nazi Party to build
    the Z3 machine for its military in 1941\. The *Z3* was an electromechanical machine
    using 2,000 electromechanical relay switches and a mechanical binary memory with
    64 addresses of 22 bits. It could run up to 10 instructions per second.
  prefs: []
  type: TYPE_NORMAL
- en: In 1998, the Z3 was shown to be theoretically a Church computer, but only via
    a very obscure and impractical technicality. It could also potentially have very
    slowly simulated a von Neumann machine, but it was not used to do this.
  prefs: []
  type: TYPE_NORMAL
- en: The Electrical Age
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Vacuum tubes* (aka *valves*) were invented in 1904 by John Fleming as an efficient
    replacement for relays. Unlike relays, they have no moving parts; they’re purely
    electrical, meaning they can switch faster than their electromechanical counterparts.
    They’re still used today in analog audio amplification, such as in tube or valve
    guitar amplifiers ([Figure 1-21](ch01.xhtml#ch01fig21)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0027-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-21: A guitar amplifier made with vacuum tubes*'
  prefs: []
  type: TYPE_NORMAL
- en: 'A vacuum tube looks and works like an Edison light bulb. A vacuum is created
    in a sealed glass tube. Inside the tube are three components: an anode, a cathode,
    and a heater. The anode and cathode are the terminals of the electrical circuit
    that is being switched on and off, so they have positive and negative voltages,
    respectively. The heater is the switch. When the heater is turned on, the heat
    allows electrons to escape from the cathode and travel through the vacuum to the
    anode, enabling current to flow and switching on the circuit. When the heater
    is turned off, electrons no longer have enough energy to do this, so the circuit
    is switched off.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When we restrict the heater to being either on or off, we have a digital switch
    that functions like a relay, forming a basic unit of purely electrical computation.
    (Alternatively, for audio and other signals amplification, we may allow the heater
    to have a continuum of heat levels, which cause a continuum of current sizes to
    flow in the main circuit, creating an analog amplification effect: the small heater
    control current turns a much larger main circuit current up and down.)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Pure Electronic Cryptology of World War II*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pure electronic machines appeared later in World War II than the more famous
    electromechanical ones. They have also been shrouded in secrecy but are sometimes
    argued to be the “first computers.”
  prefs: []
  type: TYPE_NORMAL
- en: In 1942, the German naval Enigma was upgraded to use four instead of three rotor
    slots (called the “M4 model” by the Germans; its traffic was called “Shark” by
    the Allies). Brute-force cracking this level of cryptographic complexity required
    the American approach of throwing money at computing power by paying IBM to produce
    hundreds of new, fast, fully electronic and vacuum tube-based *American Bombes*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Fish* was a cipher produced by a different German cryptography machine, the
    Lorenz SZ42; this was not an Enigma, but it used similar rotors. It was discovered
    by the Allies later in the war than Enigma because its traffic was initially sent
    only over landline telegraph wires rather than radio, making it harder to intercept.
    It was broken by a Bletchley team led by Max Newman, using the *Colossus* machine
    designed and built by Tommy Flowers and his team in 1944, shown in [Figure 1-22](ch01.xhtml#ch01fig22).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0028-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-22: Colossus, Bletchley Park, 1943, with operators Dorothy Du Boisson
    and Elsie Booker*'
  prefs: []
  type: TYPE_NORMAL
- en: Colossus was a fully electronic, vacuum tube-based machine, like the American
    Bombes, but it was also able to perform different functionalities if physically
    rewired for them. The British continued to use Colossus to break Russian codes
    up to the 1960s. Like the Z3, Colossus was only recently shown to be theoretically
    a Church computer, but only in a convoluted, speculative configuration requiring
    10 machines wired together and programmed with a novel virtual machine (VM), which
    was not done at the time.
  prefs: []
  type: TYPE_NORMAL
- en: '*ENIAC*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*ENIAC (Electronic Numerical Integrator and Computer)* was an American vacuum
    tube machine developed by John Mauchly and J. Presper Eckert in the final years
    of World War II. It was completed in 1945 and used by the US military for ballistics
    calculations. It remained in service after the war, doing hydrogen bomb calculations.'
  prefs: []
  type: TYPE_NORMAL
- en: Mauchly and Eckert were explicit in basing their design on Babbage’s Analytical
    Engine, translating each of its mechanical components into equivalent vacuum tubes.
    Like the Analytical Engine, this gives a fully general-purpose machine that can
    be programmed to execute arbitrary programs of instructions.
  prefs: []
  type: TYPE_NORMAL
- en: ENIAC was programmed by physically patching cables into sockets on its panels,
    as is sometimes still done today to “program” electronic synthesizer “patches.”
    Original photographs of its programmers writing programs in this way ([Figure
    1-23](ch01.xhtml#ch01fig23)) were sometimes mistaken for technicians simply maintaining
    the machine or setting it up to run programs written by other people. We now understand
    that this is how the actual programming itself was done and that these pictures
    show the actual programmers at work. As in Lovelace and Babbage’s time, and Bletchley’s,
    it was assumed that programming was “women’s work” and hardware was “men’s work.”
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0029-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-23: ENIAC and programmers Betty Jean Jennings and Frances Bilas at
    work in the 1940s*'
  prefs: []
  type: TYPE_NORMAL
- en: ENIAC can run any program (given enough memory), but like the Analytical Engine,
    it has a Harvard architecture; some might argue that the need to physically patch
    programs limits its claim to being the first computer. As with many other machines,
    we could reply that, in theory, someone could have programmed a VM to work around
    this problem. It was only recently that computer historians rediscovered that
    someone actually did this for ENIAC!
  prefs: []
  type: TYPE_NORMAL
- en: '*Virtual Machine ENIAC*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The ENIAC programmers Betty Jean Jennings, Marlyn Wescoff, Ruth Lichterman,
    Betty Snyder, Frances Bilas, and Kay McNulty eventually got tired of programming
    ENIAC by physically rewiring cables for each new program. So, as a quick hack,
    they designed a program with these wires that allowed the client program to be
    read from a panel of switches instead. This created a virtual machine in which
    a single fixed hardware program emulated a computer that could read higher-level
    programs from the switches.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some people argue that “the first computer” was created at this moment, as
    a software rather than a hardware creation. This would be a beautiful story, but
    there’s still a problem: the architecture is still a Harvard architecture because
    the user program is stored in the physical switches and not in the computer’s
    main memory. This means that a program couldn’t modify its own code, which some
    people see as a requirement for the “first computer.”'
  prefs: []
  type: TYPE_NORMAL
- en: The ability for a program to modify its own code is a fairly obscure requirement,
    rarely necessary outside of a few unsavory security applications and obfuscated
    coding contests. In theory, the ENIAC programmers *could* have continued to create
    a second layer of VM, which could have represented higher-level programs in the
    data rather than program memory. That would have created a von Neumann architecture,
    with programs capable of modifying their own code using the same VM idea the programmers
    had already invented. But they never felt the need to do this. Detractors argue
    that the *potential* for the ENIAC programmers to have done this is no more of
    a claim of “first computer” status than the potential for a Z3 programmer to have
    built VMs, and so they assert the virtual ENIAC missed being the first computer
    by a gnat’s whisker.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Speaking of gnats, the world’s first computer “bug”—and the origin of the
    modern use of the word—was caught and logged in 1947 by the programmers of another
    machine, the Harvard Mark II. It was a moth that had gotten stuck inside the machine,
    causing it to malfunction.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The Manchester Baby*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In 1948, Frederic Williams, Tom Kilburn, and Geoff Tootill demonstrated the
    first “electronic stored-program computer” at what is now the University of Manchester.
    *Stored program* means what we now call a von Neumann architecture. The machine
    was officially named the Small-Scale Experimental Machine and nicknamed “the Baby”
    ([Figure 1-24](ch01.xhtml#ch01fig24)).
  prefs: []
  type: TYPE_NORMAL
- en: The Baby’s CPU used around 500 vacuum tubes, together with diodes and other
    components. It implemented an instruction set of seven instructions. In modern
    terms, the Baby was a 32-bit machine, with 32 addresses each storing one 32-bit
    word.
  prefs: []
  type: TYPE_NORMAL
- en: The Baby was built from parts including the then broken-up Bletchley Colossus
    machines; it was quickly scrapped and cannibalized itself to provide parts for
    the later Manchester Mark I machine. A replica of the Baby can be seen today in
    Manchester’s Science and Industry Museum. This museum is especially interesting,
    as it also contains textile processing machines from the industrial revolution,
    which began in Manchester. These machines form a cultural connection between the
    Jacquard loom and the Manchester computers.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0031-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-24: The Manchester Baby rebuilt in Manchester’s Science and Industry
    Museum, UK. Note the CRT memory in the center, also used as a display.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Baby can probably be programmed to play *Space Invaders* on its green CRT
    screen: since the modern rebuild, similar games have been demonstrated for it
    both in emulation and on the real machine in what is perhaps the most extreme
    example of retro gaming.'
  prefs: []
  type: TYPE_NORMAL
- en: Having a von Neumann architecture, the Baby is also able to run programs that
    modify their own code. Thus, by the time we reach the Baby, we appear to have
    an indisputable Church computer, as long as we’re happy that it could be “given
    as much memory as it asks for.” It’s not trivial to wonder how that could be done,
    though, as the Baby’s architecture is so specific to the 32×32-bit memory design.
    You *could* redesign it with a larger memory, but would that really be the same
    Baby, or a different machine?
  prefs: []
  type: TYPE_NORMAL
- en: '*The 1950s and Commercial Computing*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: UNIVAC (Universal Automatic Computer; [Figure 1-25](ch01.xhtml#ch01fig25)) was
    delivered to its first customer in March 1951\. It was Mauchly and Eckert’s commercialized
    version of their previous ENIAC, making it the first *commercial* general-purpose
    stored-program computer. Like ENIAC, UNIVAC was vacuum tube-based. CBS used one
    to make a successful statistical prediction of the US presidential election of
    1952, which brought fame and sales. Mauchly and Eckert’s company still exists
    as the modern Unisys Corporation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0032-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-25: UNIVAC*'
  prefs: []
  type: TYPE_NORMAL
- en: 'IBM was slow to understand that UNIVAC and other electronic computers would
    destroy their still-profitable tabulating machines business, with CEO Thomas Watson
    making the worst futurology prediction in human history in 1948: “I think there
    is a world market for about five computers.” After waking up to the new technology,
    IBM produced its own first commercial electronic computer in 1952, the IBM 701.'
  prefs: []
  type: TYPE_NORMAL
- en: The Transistor Age
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *transistor* performs the same function as a vacuum tube, but it’s smaller,
    faster, and cheaper, and it consumes less power and is more reliable. Like tubes,
    transistors can be used for both analog and digital tasks (they’re found in analog
    audio amplifiers such as transistor radios and guitar amps), but for computing,
    they’re used only for their digital properties.
  prefs: []
  type: TYPE_NORMAL
- en: William Shockley, John Bardeen, and Walter Brattain discovered the transistor
    effect in 1947 and were awarded the Nobel Prize in Physics for it in 1956\. Work
    to commercialize transistors began in the 1950s in what is now Silicon Valley,
    and the technology became mainstream in the 1960s. Transistors remain the basic
    technology of computers today.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0032-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-26: A big transistor*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The 1960s and Big Transistors*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The transistor “minicomputers” of the 1960s didn’t use microchips, but instead
    were made from the “big” kinds of transistors, about 1 cm long, that you would
    put in a breadboard circuit today ([Figure 1-26](ch01.xhtml#ch01fig26)). It’s
    still possible to make a CPU out of such transistors, and a few hobbyists do it
    for fun (for example, the MOnSter 6502 project by Eric Schlaepfer and Evil Mad
    Scientist Laboratories).
  prefs: []
  type: TYPE_NORMAL
- en: These computers filled a rack and included the classic PDP machines ([Figure
    1-27](ch01.xhtml#ch01fig27)) used heavily in early AI research. This was also
    the time when Seymour Cray began building Cray supercomputers, aiming to make
    the biggest and fastest machines for high-end users.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0033-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-27: A transistor-based 1960s PDP-11 mini-computer*'
  prefs: []
  type: TYPE_NORMAL
- en: Uses of transistor computers in the 1960s included powering ARPANET, the predecessor
    of today’s TCP/IP-based internet, and Margaret Hamilton’s 1969 programming of
    the Apollo moon landing code in assembly language ([Figure 1-28](ch01.xhtml#ch01fig28)).
    The latter was actual rocket science, and required her to create the modern field
    of software engineering while searching for ways to make this highly critical
    code more correct.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0033-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-28: Hamilton with a printout of her complete assembly program for
    Apollo 11*'
  prefs: []
  type: TYPE_NORMAL
- en: In 1965, Gordon Moore, the CEO of Intel, made an observation known since as
    Moore’s law. As you saw in the introduction, depending on who you ask and how
    you count, this law says that either the speed of computers or the number of transistors
    per area doubles every 18 months or every 2 years.
  prefs: []
  type: TYPE_NORMAL
- en: '*The 1970s and Integrated Circuits*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The 1970s saw the widespread commercialization of *integrated circuits* (also
    called *ICs*, *microchips*, or *chips*). ICs had been theorized in 1952 in Britain
    by Geoffrey Dummer, though the 2000 Nobel Prize in Physics was awarded to Jack
    Kilby—who had heard Dummer talk about them in 1952—for his invention and patent
    of a practical version in 1958 at Texas Instruments.
  prefs: []
  type: TYPE_NORMAL
- en: IC technology allows electric transistor-based circuits to be miniaturized,
    so that the same wiring that filled a 1960s rack cabinet can fit on a “chip” of
    silicon the size of a fingernail. From an architectural view, chips are not very
    exciting—if you take the wiring diagram from a 1940s vacuum tube machine and just
    miniaturize it, then you get a chip. If you look at a chip through a microscope,
    you’ll see similar wiring patterns to, say, the wires on the back of a 1940s,
    1950s, or 1960s rack. The silicon chip is then “packaged” inside a larger, usually
    black lump of plastic, with larger metal pins connecting the fine inputs and outputs
    of the chip to the outside world, usually a printed circuit board ([Figure 1-29](ch01.xhtml#ch01fig29)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0034-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-29: An Intel 4004 chip in its packaging*'
  prefs: []
  type: TYPE_NORMAL
- en: The 1970s saw the birth of some of the oldest software that is still in use
    today. The UNIX operating system was built by Kenneth Thompson and Dennis Ritchie
    in this time ([Figure 1-30](ch01.xhtml#ch01fig30)) and has evolved into current
    Linux, FreeBSD, and macOS systems.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0034-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-30: Thompson and Ritchie creating UNIX on a teletype terminal*'
  prefs: []
  type: TYPE_NORMAL
- en: UNIX terminals of the time used typewriter-style print heads on paper rolls—like
    Babbage’s Difference Engine—and programmers would interact with the machine by
    typing commands on a keyboard; these commands were printed as they typed, along
    with their resulting outputs. This teletype system is the origin of the x-terminals
    used today in UNIX-like systems.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to terminal-based interaction, Xerox (the photocopier company) researched
    graphical user interfaces at its Palo Alto Research Center, Xerox PARC. This included
    developing the first mouse, as well as the “desktop” metaphor, including files
    and folders based on physical filing cabinets.
  prefs: []
  type: TYPE_NORMAL
- en: This choice to base the interface with a computer on a middle management office,
    with its desks and filing cabinets—rather than on, say, a school, art gallery,
    or shop—has been with us, and making computing more boring than it should be,
    ever since. This may be starting to change, with the rise of handheld interfaces
    such as Android and TV-based “10-foot” interfaces such as Kodi, which provide
    feasible alternatives based on “apps.”
  prefs: []
  type: TYPE_NORMAL
- en: '*The 1980s Golden Age*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Any author covering computer history eventually reaches a point where the story
    overlaps with their own lifetime, and from then on, they may become somewhat biased.
    For this author, it occurs here, so you might want to find alternative accounts
    from others to balance mine out.
  prefs: []
  type: TYPE_NORMAL
- en: 'The 1980s was the golden age of computer architecture: for the first time,
    electronic computers became cheap and small enough to be mass-produced and bought
    by normal people to use in their homes. As shown in [Figure 1-31](ch01.xhtml#ch01fig31),
    this may have been the best time in human history to be a kid interested in computers
    because you would get a proper computer for Christmas, with direct access to its
    architecture, at a time before operating systems hid the architecture away from
    the user.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0035-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-31: Home computing in the 1980s: a happy child with their first computer*'
  prefs: []
  type: TYPE_NORMAL
- en: These machines were based initially on 8-bit CPUs, such as the 6502 used in
    the Commodore 64 and Apple II, and then based on 16-bit CPUs, such as the Motorola
    68000 used in the Amiga and Atari ST. This period—especially in retro gaming—is
    known as the 8-bit era and then later the 16-bit era; it’s looked back on with
    fondness and nostalgia by many who were there, and by many who weren’t.
  prefs: []
  type: TYPE_NORMAL
- en: The IBM 5150 PC launched in 1981, based on the Intel 8088 chip. IBM and others
    sold this and other PCs during the 1980s for use in business offices. The PC concept
    is the polar opposite of the heterogeneous, architecture-driven home computer
    market for two reasons. First, it enforces a standardized architecture on the
    computer components so that multiple manufacturers can produce them to be compatible
    with one another. Second, it wraps all the hardware under a strict operating system,
    which controls all access to it via a standardized interface. IBM could use its
    market clout to enforce standards on components, so it could buy them from the
    cheapest suppliers and make money by stamping its brand on assembled PCs.
  prefs: []
  type: TYPE_NORMAL
- en: In a reaction to the proprietary operating systems being installed on PCs and
    larger computers, the GNU (recursively standing for “GNU’s Not Unix”) project
    and Free Software movement were created in this decade by Richard Stallman—this
    later led to the Linux-based systems and philosophies that we use today.
  prefs: []
  type: TYPE_NORMAL
- en: We will study this period in more detail in [Chapter 11](ch11.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: '*The Bland 1990s*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The 1990s was a bland, boring, beige decade. It was driven by a commercial focus
    in the industry that switched from treating users as programmers and community
    members to users as customers and consumers of software products, such as word
    processors and spreadsheets. During this time, schools stopped teaching computer
    science and (under the heavy influence of corporate lobbying by their creators)
    taught the use of commercial office software.
  prefs: []
  type: TYPE_NORMAL
- en: Computer architecture became dominated by the personal computer (PC) standard
    architecture, which had been used in office computing during the 1980s but was
    now pushed everywhere by the PC corporations, including on homes and schools.
    Closed source operating systems were pushed as part of the PC package, making
    it hard for users to see anything “under the hood” of their machines.
  prefs: []
  type: TYPE_NORMAL
- en: Physically, these machines appeared as nearly identical “beige boxes,” as in
    [Figure 1-32](ch01.xhtml#ch01fig32), and the general drabness of this middle management-style
    computing culture was later caricatured through Apple’s “I’m a PC” TV commercials,
    which portrayed the PC as a generic middle manager with a boring beige outfit.
  prefs: []
  type: TYPE_NORMAL
- en: As Moore’s law reliably predicted, processor speeds doubled every 18 months;
    this was the standard measure of how good your computer was, and many would build
    a new one every couple of years to take advantage of the new speed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0036-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-32: A 1990s desktop*'
  prefs: []
  type: TYPE_NORMAL
- en: Related to the move to operating systems was the move from programming in assembly
    and interpreted languages, such as BASIC, to compiled languages. When languages
    are compiled, their authors can choose to conceal the source code so that users
    can no longer see how they work or learn from them by changing them. Compilers
    had been developed since Grace Hopper’s work in the 1950s, and were used in high-end
    computing, but this was the first time they and their generated code arrived in
    homes.
  prefs: []
  type: TYPE_NORMAL
- en: The computer games industry similarly became professionalized, separating consumers,
    who could only buy and play dedicated consoles and games, from commercial developers
    with the money to access specialist programming tools. Games were sometimes fun
    to play, but not as much fun as they used to be to write.
  prefs: []
  type: TYPE_NORMAL
- en: The World Wide Web went online at CERN in 1990 and grew in popularity, leading
    to the dot-com investment craze at the end of the decade. As more hackers and
    eventually consumers joined the web, dedicated rackmounted server computer designs
    became popular, beginning with the Compaq ProLiant in 1993\. Like the Manchester
    Baby and 1960s minicomputers, these were designed to be stacked in 19-inch rack
    units, but to be always on with high reliability.
  prefs: []
  type: TYPE_NORMAL
- en: For the early modem-connected elite, 1993 also saw the birth of Linux and the
    beginnings of its GNU-inspired international authors figuring out how to communicate
    and code with one another at the level of architecture and systems programming.
  prefs: []
  type: TYPE_NORMAL
- en: '*The 2000s and Reconnecting the Community*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The PC architecture of commodity components plus operating system continued
    throughout the 2000s. Moore’s law, and the consequent building or buying of a
    new doubled-speed computer every couple of years, continued. Machines used the
    same basic PC computer design, with various interfaces and components getting
    upgraded for speed. Internet speeds also increased, enabling streaming of videos
    as well as the transfer of text and images. Servers were reduced in size to *blades*,
    many of which could be packed together in a single rack unit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enabled by these advances, Linux matured into a realistic alternative system
    to the proprietary operating systems previously bundled with PCs. Many of the
    people involved in older computing communities returned and joined the Linux movement.
    We realized that things had to go via the operating system route rather than raw
    architecture; for free software advocates, this was a good thing: it removed any
    dependency we had on any particular hardware companies. This was now okay because
    the operating system was free software and thus no one had to be locked in to
    buying anyone’s specific products. With this hindsight, the 1980s was perhaps
    not so great because everyone was forced to develop on some non-free architecture
    platform and was thus utterly dependent on their corporate owners. The 1990s saw
    a reduction in freedom as a multitude of these corporations and platforms were
    replaced by a single dominant PC operating system corporation and platform, but
    since then, Linux life has become even better than the 1980s and 1990s, as we
    have an open platform and many competing hardware suppliers implementing it.'
  prefs: []
  type: TYPE_NORMAL
- en: Much of the other open source software we use today developed rapidly alongside
    Linux, such as Firefox, Python, MySQL, and Apache. In many cases, these tools
    have older origins, but they only grew to a critical mass of developers and users
    in the 2000s.
  prefs: []
  type: TYPE_NORMAL
- en: The programmers working on the Linux operating system itself got to see and
    work with the underlying architecture, but for everyone else, architecture was
    generally still under the hood, as in the 1990s.
  prefs: []
  type: TYPE_NORMAL
- en: '*The 2010s and the End of Moore’s Law*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: During the 1990s and 2000s we happily assumed that the clock speeds of our processors
    would double every couple of years—and they did. Moore’s law became a self-fulfilling
    prophecy as Silicon Valley chipmakers used it as a target to be reached.
  prefs: []
  type: TYPE_NORMAL
- en: However, this all fell apart in the 2010s. Transistor manufacturing technology
    did continue to double the number of transistors per area, but clock speeds maxed
    out by 2010, at around 3.5 GHz. Suddenly, processors weren’t getting faster anymore.
    This is due to the fundamental laws of physics around computation speed and heat.
    During the Moore’s law period, the temperature of processors had also been rising
    along with speed; larger and more powerful fans and other cooling systems such
    as water cooling were needed. The transistors got smaller, but the fans got bigger.
    If this trend had continued through the 2010s, we would now have processors hotter
    than the surface of the sun.
  prefs: []
  type: TYPE_NORMAL
- en: A closely linked concept is power consumption. As chips give off more heat,
    they consume more power, and this decade also saw the beginnings of a push toward
    lower-power, more portable computing, especially in the form of smartphones. This
    was the decade when we switched from looking up to the sky to looking down at
    screens in our hands.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in the introduction, the end of Moore’s law has created what Turing
    Award winners John Hennessy and David Patterson have described as “a new golden
    age of architecture.” Where the previous two decades saw computer architecture
    stagnate as a field, relying on advances in fabrication technologies to create
    regular gains, the field is now wide open again for radically new ideas. We can’t
    make computers faster via the speed form of Moore’s law, but we can still fit
    more and more transistors onto chips with its density form. We can now consider
    making everything parallel, performing many operations at once, rather than one
    at a time.
  prefs: []
  type: TYPE_NORMAL
- en: As you might expect, the 2010s were characterized by an explosion of new ideas,
    architectures, hardware, and software, all to enable parallelization. A key computer
    science question of our time is how much programmers need to worry about this.
    In one possible future, programmers will continue to write sequential programs,
    and new kinds of parallel compilers will figure out how to turn step-by-step instructions
    into parallel executions. In another future, we might find this is not possible,
    and programmers will have to write explicitly parallel programs themselves. This
    will completely change the nature of programming and the kinds of skills and thought
    processes that programmers need.
  prefs: []
  type: TYPE_NORMAL
- en: While there remain many parallel architectures still to be explored—and hundreds
    of university researchers and startup companies now trying to explore and exploit
    them—the 2010s saw three major new types of parallel architecture succeeding in
    the real world.
  prefs: []
  type: TYPE_NORMAL
- en: First, and most basically, *multicore* processors are simply chips manufactured
    to contain more than one copy of a CPU design. The decade began with duo-core
    systems and progressed through quad, eight, and even more cores. If you were to
    run just a single program on these machines, then the programmer would have to
    care about parallelism. But most current computers run an operating system program
    that in turn enables many programs to run concurrently, sharing the computer’s
    resources between them. A typical desktop machine might run 10 to 20 processes
    concurrently during normal operation through this arrangement, so adding *N* multicores
    gives a factor *N* speed up, but only up to this number of processes. Multicores
    will not scale very well beyond this if they are asked to run ordinary programs.
  prefs: []
  type: TYPE_NORMAL
- en: Second, cluster computing, shown in [Figure 1-33](ch01.xhtml#ch01fig33), is
    another form of parallelism in which many conventional single-core or multicore
    machines are weakly linked together. Computing work is then split into many independent
    chunks that can each be assigned to a machine. This requires programs to be written
    in a specific style, based around the split into independent jobs, and works only
    for certain types of tasks where such splits are possible.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0039-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-33: A 2010s parallel supercomputing cluster*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cluster computing has been especially useful for “big data” tasks where we
    usually want to repeat the same processing independently on many data items, and
    then collate the results (this is known as *map-reduce*). The Search for Extraterrestrial
    Intelligence project (SETI@home) pioneered this approach in the 1990s, using compute
    time on millions of home computers donated by their users to run in the background,
    analyzing big data from radio telescopes to look for alien messages. The method
    is also used by search engine companies: for example, a company might assign one
    commodity Dell PC out of many in a large warehouse to be responsible for storing
    all the locations on the web containing one particular word, and handling queries
    about that word. During the 2010s, the underlying map-reduce process was abstracted
    and open sourced by the Hadoop and Spark projects, which enabled everyone to easily
    set up and use similar clusters.'
  prefs: []
  type: TYPE_NORMAL
- en: The third approach, and most interesting architecturally, has been the evolution
    of graphics cards (also called graphics processing units, or GPUs) into general-purpose
    parallel computing devices. This presents a completely new silicon-level design
    concept that also requires a new style of programming, somewhat similar to cluster
    programming. Now that its graphical roots have been left behind, the concept is
    continually evolving into many novel architectures, such as recent tensor and
    neural processing units found on mobile phones.
  prefs: []
  type: TYPE_NORMAL
- en: It’s not clear whether the concept of a “programmer” will survive if some of
    these new parallel architectures become dominant; for example, we might “program”
    machines by creating specific parallel circuits in hardware, where everything
    happens at the same time, rather than thinking of a “program” as a set of instructions
    to be run in series.
  prefs: []
  type: TYPE_NORMAL
- en: '*The 2020s, the Cloud, and the Internet of Things*'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This is the current decade at the time of writing, so any trends identified
    are somewhat speculative. With that said, the systems that we can see in development
    labs today suggest that the present decade will see a fundamental split of architectures
    into two main types.
  prefs: []
  type: TYPE_NORMAL
- en: First, increasingly small and cheap devices will be embedded into more and more
    objects in the real world. This concept, known as the *Internet of Things (IoT)*,
    promises to see smart sensors and computers in cities, factories, farms, homes,
    and pretty much everywhere else.
  prefs: []
  type: TYPE_NORMAL
- en: “Smart cities” will be covered in these devices to enable the monitoring of
    every individual vehicle and pedestrian, to make traffic control and use of city
    facilities more efficient. “Smart factories” will have tiny devices attached to
    every item of stock and track them through the manufacturing process. Smart transport,
    retail, and homes will track the same items right through their supply chains,
    “from farm to fork” in the case of food. For example, your fridge will sense that
    you’re running out of cheese, using either the weight of your cheesebox or machine
    vision looking for cheese, and automatically place an order to your local supermarket
    to replenish it. The supermarket will aggregate these orders and balance the demand
    with orders from their distribution centers. Small autonomous robots will then
    deliver your cheese from the supermarket to your doorstep.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second trend is in the opposite direction. The low-power IoT devices won’t
    do much computing, but will instead exist primarily to collect and act upon “big
    data” in the world. This data will then be processed on massive scales in dedicated
    computing centers: buildings the size of warehouses that are packed with computing
    power.'
  prefs: []
  type: TYPE_NORMAL
- en: Computing centers are related to *data centers*, similar-looking buildings already
    in existence that exist primarily to *store* data and make it available over the
    web, rather than to perform heavy computation on it. This type of computing appeared
    first at search engine companies, which used many cheap commodity PCs running
    together to process web crawls and searches. Search companies, and their online
    shopping peers, discovered they could make a profit by hiring out the spare machines
    that were sitting idle for general computing use by customers. This style of computing
    is quite like the big machines of the 1960s and 1970s, whose users would dial
    in from terminals and share time on them. (Perhaps Thomas Watson’s guess that
    there is a world market for only five computers will actually turn out to be true
    if we count each of these cloud computing centers as one computer and ignore the
    IoT devices.)
  prefs: []
  type: TYPE_NORMAL
- en: The IoT devices create a particular interest in low-energy design, but related
    energy issues also occur in huge cloud computing centers. These buildings can
    use as much power as factories, give off significant heat, and cost a significant
    amount to run. Computing centers powered most of the world’s video calls and collaboration
    tools during the COVID-19 pandemic, enabling many jobs to switch to remote work
    for the first time. Some computing centers saw shutdowns in 2022 due to an extreme
    heatwave. Recently, some computing centers have been deliberately located in places
    such as the Arctic to make use of the natural cooling.
  prefs: []
  type: TYPE_NORMAL
- en: So, like Moses, in this decade we will download from the cloud onto our tablets.
    The two trends of the IoT and the cloud are likely to continue and become more
    extreme during the 2020s, pulling architecture in two opposite directions. Medium-sized
    desktop computers seem likely to fall in importance.
  prefs: []
  type: TYPE_NORMAL
- en: Already we’re getting used to computing on physically small devices such as
    tablet computers and the Nintendo Switch, which are starting to make larger desktop
    machines look a bit silly. “A computer on every desk” was the aim in the 1990s,
    but these are disappearing and being replaced by a mix of computers in our pockets,
    streets, and cloud centers. Similar setups have been suggested previously from
    time to time, including 1950s dial-in mainframes and 1990s “thin clients,” but
    in the 2020s they seem to be taking off via mobile phones, Amazon Echo, Nest home
    automation, and Arduinos, as well as cloud providers such as Amazon Web Services,
    Microsoft Azure, and Google Cloud Platform.
  prefs: []
  type: TYPE_NORMAL
- en: So Who Invented the Computer?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The modern concept of computation was defined by Church. Commercial electronic
    machines of the 1950s, beginning with UNIVAC, through 1960s minicomputers and
    1970s microchips up to the present day seem clearly recognizable as computers.
    But should anything before them be credited as “the first computer”?
  prefs: []
  type: TYPE_NORMAL
- en: The Manchester Baby is a Church computer if you are happy that it could be “given
    as much memory as it asks for,” but it’s not very clear how this would be done.
    Looking at later commercial machines gives more of a feeling that they could easily
    be extended with more memory, for example, by plugging in extra circuit boards
    or hard disks. But in principle they all still have the same problem as the Baby.
  prefs: []
  type: TYPE_NORMAL
- en: ENIAC-initial has the potential to be a Church computer if programmed in a certain
    VM way. ENIAC-VM actually *was* programmed that way, but was still a Harvard architecture.
    It needed another layer of unrealized VM to get to RAM programs. Colossus and
    Zuse Z3 programmers could theoretically have done all of this, too—but didn’t.
    The same goes for Analytical Engine programmers.
  prefs: []
  type: TYPE_NORMAL
- en: IBM has been doing big data analytics on machines described by the media as
    “supercomputers” since the 1890s, but data analytics isn’t general Church computation
    unless you can find a way to make any problem look like an SQL query.
  prefs: []
  type: TYPE_NORMAL
- en: People have probably been calculating since 40,000 BCE, with abaci, mechanical
    calculators, paper, pens, clay tablets, bones, rocks, their fingers, and natural
    numbers in their heads. All the above are theoretically Church computers because
    they can simulate any machine if programmed in a certain way. So perhaps we have
    always had computers—and Church was just the first to notice them.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we took a whirlwind tour through the history of computing.
    Beginning with bones and ending in the cloud, we considered a number of inventions
    that might, or might not, be called a computer. We also saw a few hypotheses for
    what makes a computer. Initially we suggested that a computer was anything that
    could be programmed to play *Space Invaders*. We then formalized this hypothesis
    by looking at Church’s thesis, which argues that a computer is a machine that
    can simulate any other machine, given as much memory as it asks for.
  prefs: []
  type: TYPE_NORMAL
- en: Our survey of the history of computing has briefly introduced the big ideas
    of architecture. In the next chapters, we’ll dive into the details of data representation
    and CPU computation to see how some of the historical systems work in more detail.
    This will set us up for [Part II](part02.xhtml)’s study of modern electronic hierarchy
    and the many particular modern architectures of [Part III](part03.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Calculating with an Abacus Simulator**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Use an abacus simulator (or a real abacus if you have one) and a tutorial to
    understand abacus arithmetic. These operations are still the basis for some modern
    CPU operations, and learning to do them on the abacus will help you understand
    them in CPUs. A simulator can be found here: *[https://www.mathematik.uni-marburg.de/~thormae/lectures/ti1/code/abacus/soroban.html](https://www.mathematik.uni-marburg.de/~thormae/lectures/ti1/code/abacus/soroban.html)*
    and a tutorial for using it at *[https://www.wikihow.com/Use-an-Abacus](https://www.wikihow.com/Use-an-Abacus)*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take the last three digits of your phone number as one number and the preceding
    three digits as a second number, and add them together on the abacus.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take the same pair of numbers and subtract the smaller one from the larger one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take the last two digits of your phone number as a two-digit number and the
    preceding two digits as a second two-digit number, and multiply them using the
    abacus.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Speculative History**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: How do you think world history could have been different if the Antikythera
    mechanism had arrived safely in Rome and inspired the Roman Empire to use similar
    machines?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you think world history could have been different if the Analytical Engine
    had been fully constructed and commercialized in the British Empire?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Challenging**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Search the internet for examples of advanced operations using an abacus, such
    as square roots or prime factorization, and try to run them. You may need to use
    more than one abacus to provide enough columns for some of them.
  prefs: []
  type: TYPE_NORMAL
- en: '**More Challenging**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Write a speculative fiction short story or novel based on one of the premises
    raised by the “Speculative History” exercises.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How could you implement a Church computer using an abacus?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Research the SQL-like functions available on the Hollerith machine. Can a Church
    computer be made from them?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further Reading
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For details of the Hollerith machine, see H. Hollerith, “The Electrical Tabulating
    Machine,” *Journal of the Royal Statistical Society* 57, no. 4 (1894): 678–689,
    *[https://www.jstor.org/stable/2979610](https://www.jstor.org/stable/2979610)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For details of Hollerith machines’ role in World War II, see Edwin Black, *IBM
    and the Holocaust: The Strategic Alliance Between Nazi Germany and America’s Most
    Powerful Corporation* (Washington, DC: Dialog Press, 2012).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To learn more about 2020s IoT computing, see S. Madakam, R. Ramaswamy, and
    S. Tripathi, “Internet of Things (IoT): A Literature Review,” *Journal of Computer
    and Communications* 3, no. 5 (2015), *[http://dx.doi.org/10.4236/jcc.2015.35021](http://dx.doi.org/10.4236/jcc.2015.35021)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To learn more about 2020s cloud computing, see I. Hashem, I. Yaqoob, N.B. Anuar,
    et al., “The Rise of ‘Big Data’ on Cloud Computing: Review and Open Research Issues,”
    *Information Systems* 47 (2015): 98–115.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a dieselpunk novel featuring World War II cryptography, see Neal Stephenson,
    *Cryptonomicon* (New York: Avon, 1999).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
