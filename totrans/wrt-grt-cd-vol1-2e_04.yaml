- en: '**5'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**5'
- en: CHARACTER REPRESENTATION**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 字符表示**
- en: '![Image](../images/comm1.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/comm1.jpg)'
- en: Although computers are famous for their “number-crunching” capabilities, the
    truth is that most computer systems process character data far more often than
    numbers. The term *character* refers to a human- or machine-readable symbol that
    is typically a non-numeric entity. In general, a character is any symbol that
    you can type on a keyboard or show on a video display. In addition to alphabetic
    characters, character data includes punctuation marks, numeric digits, spaces,
    tabs, carriage returns (the ENTER key), other control characters, and other special
    symbols.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管计算机以“数字运算”能力而闻名，但事实是，大多数计算机系统处理字符数据的频率远高于数字数据。*字符*一词指的是一种人类或机器可读的符号，通常是非数字实体。一般来说，字符是你可以在键盘上输入或在显示器上显示的任何符号。除了字母字符外，字符数据还包括标点符号、数字、空格、制表符、回车符（回车键）、其他控制字符和其他特殊符号。
- en: This chapter looks at how to represent characters, strings, and character sets
    within a computer system. It also discusses various operations on these data types.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了如何在计算机系统中表示字符、字符串和字符集，并讨论了对这些数据类型的各种操作。
- en: '**5.1 Character Data**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**5.1 字符数据**'
- en: Most computer systems use a 1-byte or multibyte binary sequence to encode the
    various characters. Windows, macOS, and Linux fall into this category, using the
    ASCII or Unicode character sets, whose members can all be represented with 1-
    or multibyte binary sequences. The EBCDIC character set, in use on IBM mainframes
    and minicomputers, is another example of a single-byte character code.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数计算机系统使用 1 字节或多字节的二进制序列来编码各种字符。Windows、macOS 和 Linux 都属于这一类别，使用 ASCII 或 Unicode
    字符集，其成员可以通过 1 字节或多字节的二进制序列表示。EBCDIC 字符集在 IBM 大型机和小型计算机上使用，也是单字节字符编码的另一个例子。
- en: This chapter will discuss all three of these character sets and their internal
    representations, as well as how to create your own character sets.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将讨论这三种字符集及其内部表示方式，并介绍如何创建自己的字符集。
- en: '***5.1.1 The ASCII Character Set***'
  id: totrans-8
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.1 ASCII 字符集***'
- en: The ASCII (American Standard Code for Information Interchange) character set
    maps 128 characters to the unsigned integer values 0 through 127 (`$0` through
    `$7F`). Although the exact mapping of characters to numeric values is arbitrary
    and unimportant, a standardized mapping allows you to communicate between programs
    and peripheral devices. The standard ASCII codes are useful because nearly everyone
    uses them. If you use the ASCII code `65` to represent the character *A*, for
    example, you can be confident that some peripheral device (such as a printer)
    will correctly interpret this value as an *A*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ASCII（美国信息交换标准代码）字符集将 128 个字符映射到无符号整数值 0 到 127（`$0` 到 `$7F`）。尽管字符与数字值的精确映射是任意的并且并不重要，但标准化的映射使得你能够在程序和外部设备之间进行通信。标准
    ASCII 代码很有用，因为几乎每个人都使用它们。例如，如果你使用 ASCII 代码 `65` 来表示字符 *A*，你可以放心，某些外部设备（如打印机）会正确地将这个值解释为
    *A*。
- en: 'Because the ASCII character set provides only 128 different characters, you
    might be wondering: “What do we do with the additional 128 values (`$80..$FF`)
    that we can represent with a byte?” One option is to ignore those extra values,
    and that’s the primary approach of this book. Another possibility is to extend
    the ASCII character set by an additional 128 characters. Of course, unless you
    can get everyone to agree upon a particular extension of the character set^([1](footnotes.xhtml#fn5_1a))
    (a difficult task indeed), the whole purpose of having a standardized character
    set will be defeated.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 ASCII 字符集只提供 128 个不同的字符，你可能会问：“我们该如何处理额外的 128 个值（`$80..$FF`），这些值可以用一个字节表示？”一个选项是忽略这些额外的值，这也是本书的主要做法。另一种可能性是通过添加
    128 个字符来扩展 ASCII 字符集。当然，除非你能让每个人都同意某个特定的字符集扩展^([1](footnotes.xhtml#fn5_1a))（这确实是一个困难的任务），否则拥有标准化字符集的整个目的将会失效。
- en: Despite some major shortcomings, such as the inability to represent all characters
    and alphabets in use today, ASCII data is *the* standard for data interchange
    across computer systems and programs. Most programs can accept ASCII data, and
    most programs can produce it. Because you’ll probably be dealing with ASCII characters
    in your programs, it would be wise to study the layout of the character set and
    memorize a few key ASCII codes (such as those for *0*, *A*, and *a*).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在一些重大缺点，如无法表示今天使用的所有字符和字母，但ASCII数据仍然是跨计算机系统和程序数据交换的*标准*。大多数程序都能接受ASCII数据，也能生成ASCII数据。因为你可能会在程序中处理ASCII字符，所以研究字符集的布局并记住一些关键的ASCII代码（如*0*、*A*和*a*的代码）是明智的。
- en: '**NOTE**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Table A-1 in [Appendix A](app01.xhtml#app01) lists all the characters in the
    standard ASCII character set.*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*[附录 A](app01.xhtml#app01)中的表 A-1列出了标准ASCII字符集中的所有字符。*'
- en: The ASCII character set is divided into four groups of 32 characters. The first
    32 characters, ASCII codes `$0` through `$1F` (0 through 31), form a special set
    of nonprinting characters called the *[control characters](gloss01.xhtml#gloss01_59)*.
    As their name implies, these characters perform various printer and display control
    operations rather than displaying symbols. Examples of control characters include
    the carriage return, which positions the cursor at the beginning of the current
    line of characters;^([2](footnotes.xhtml#fn5_2a)) line feed, which moves the cursor
    down one line on the output device; and backspace, which moves the cursor back
    one position to the left. Unfortunately, because there’s very little standardization
    among output devices, different control characters perform different operations
    on different output devices. To find out exactly how a particular control character
    affects a certain device, consult the device’s manual.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ASCII字符集被分为四组32个字符。前32个字符，ASCII代码`$0`到`$1F`（0到31），形成了一组特殊的非打印字符，称为*[控制字符](gloss01.xhtml#gloss01_59)*。顾名思义，这些字符执行各种打印机和显示控制操作，而不是显示符号。控制字符的示例包括回车符，它将光标定位到当前行的开头；^([2](footnotes.xhtml#fn5_2a))
    换行符，它将光标向下移动一行；以及退格符，它将光标向左移动一个位置。不幸的是，由于输出设备之间几乎没有标准化，不同的控制字符在不同的输出设备上执行不同的操作。要准确了解某个控制字符如何影响某个设备，请查阅该设备的手册。
- en: The second group of 32 ASCII character codes comprises various punctuation symbols,
    special characters, and the numeric digits. The most notable characters in this
    group include the space character (ASCII code `$20`) and the numeric digits (ASCII
    codes `$30..$39`).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第二组32个ASCII字符代码包括各种标点符号、特殊字符和数字字符。该组中最显著的字符包括空格字符（ASCII代码`$20`）和数字字符（ASCII代码`$30..$39`）。
- en: The third group of 32 ASCII characters contains the uppercase alphabetic characters.
    The ASCII codes for the characters *A* through *Z* lie in the range `$41` through
    `$5A`. Because there are only 26 different alphabetic characters, the remaining
    six codes hold various special symbols.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 第三组32个ASCII字符包含大写字母字符。字符*A*到*Z*的ASCII代码范围为`$41`到`$5A`。因为只有26个不同的字母字符，其余六个代码用于表示各种特殊符号。
- en: The fourth and final group of 32 ASCII character codes represents the lowercase
    alphabetic symbols, five additional special symbols, and another control character
    (delete). The lowercase character symbols use the ASCII codes `$61` through `$7A`.
    If you convert the codes for the upper- and lowercase characters to binary, you’ll
    notice that the uppercase symbols differ from their lowercase equivalents in exactly
    one bit position. For example, consider the character codes for *E* and *e* in
    [Figure 5-1](ch05.xhtml#ch05fig01).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 第四组也是最后一组32个ASCII字符代码表示小写字母符号、五个额外的特殊符号和另一个控制字符（删除）。小写字母符号使用ASCII代码`$61`到`$7A`。如果你将大写和小写字符的代码转换为二进制，你会发现大写字母与其小写字母之间仅在一个比特位置上有所不同。例如，考虑[图
    5-1](ch05.xhtml#ch05fig01)中*E*和*e*的字符代码。
- en: '![image](../images/05fig01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/05fig01.jpg)'
- en: '*Figure 5-1: ASCII codes for E and e*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-1：E 和 e 的 ASCII 代码*'
- en: These two codes differ only in bit 5\. Uppercase alphabetic characters always
    contain a `0` in bit 5; lowercase alphabetic characters always contain a `1` in
    bit 5\. To quickly convert an alphabetic character between upper- and lowercase,
    simply invert bit 5\. To force an uppercase character to lowercase, set bit 5
    to `1`. Likewise, you can force a lowercase character to uppercase by setting
    bit 5 to `0`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个代码仅在位 5 上有所不同。大写字母字符的位 5 总是为 `0`；小写字母字符的位 5 总是为 `1`。要快速将字母字符在大写和小写之间转换，只需反转位
    5。要将大写字母转换为小写字母，只需将位 5 设置为 `1`。同样，你可以通过将位 5 设置为 `0` 将小写字母转换为大写字母。
- en: Bits 5 and 6 determine the character’s group (see [Table 5-1](ch05.xhtml#ch05tab01)).
    Therefore, you can convert any upper- or lowercase (or special) character to its
    corresponding control character by setting bits 5 and 6 to `0` (for example, *A*
    becomes CTRL-A when you set bits 5 and 6 to `0`; that is, `0x41` becomes `0x01`).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 位 5 和位 6 决定了字符的组（见 [表 5-1](ch05.xhtml#ch05tab01)）。因此，你可以通过将位 5 和位 6 设置为 `0`
    来将任何大写或小写字母（或特殊字符）转换为其对应的控制字符（例如，当你将位 5 和位 6 设置为 `0` 时，*A* 变为 CTRL-A；也就是说，`0x41`
    变为 `0x01`）。
- en: '**Table 5-1:** ASCII Character Groups Determined by Bits 5 and 6'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-1：** 由位 5 和位 6 决定的 ASCII 字符组'
- en: '| **Bit 6** | **Bit 5** | **Group** |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| **位 6** | **位 5** | **组** |'
- en: '| `0` | `0` | Control characters |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| `0` | `0` | 控制字符 |'
- en: '| `0` | `1` | Digits and punctuation |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| `0` | `1` | 数字和标点符号 |'
- en: '| `1` | `0` | Uppercase and special |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 1 | `0` | 大写字母和特殊字符 |'
- en: '| `1` | `1` | Lowercase and special |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 1 | `1` | 小写字母和特殊字符 |'
- en: Bits 5 and 6 aren’t the only bits that encode useful information. Consider,
    for a moment, the ASCII codes of the numeric digit characters in [Table 5-2](ch05.xhtml#ch05tab02).
    The decimal representations of these ASCII codes are not very enlightening. However,
    the hexadecimal representation reveals something very important—the LO nibble
    is the binary equivalent of the represented number. By stripping away (setting
    to `0`) the HO nibble of the ASCII code, you obtain the binary representation
    of that digit. Conversely, you can convert a binary value in the range `0` through
    `9` to its ASCII character representation by simply setting the HO nibble to `%0011`,
    or the decimal value `3`. You can use the logical AND operation to force the HO
    bits to `0`; likewise, you can use the logical OR operation to force the HO bits
    to `%0011`. For more information on string-to-numeric conversions, see [Chapter
    2](ch02.xhtml#ch02).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 位 5 和位 6 不是唯一编码有用信息的位。请考虑一下 [表 5-2](ch05.xhtml#ch05tab02) 中数字字符的 ASCII 码。这些
    ASCII 码的十进制表示并不太能提供直观的信息。然而，十六进制表示却揭示了非常重要的内容——低阶 nibble 是所表示数字的二进制等价物。通过去除（设置为
    `0`）ASCII 码的高阶 nibble，你就能得到该数字的二进制表示。反之，你可以通过简单地将高阶 nibble 设置为 `%0011`，即十进制值 `3`，将
    `0` 到 `9` 范围内的二进制值转换为其对应的 ASCII 字符表示。你可以使用逻辑与操作来强制将高阶位设置为 `0`；同样，你也可以使用逻辑或操作将高阶位强制设置为
    `%0011`。有关字符串到数字转换的更多信息，请参见 [第 2 章](ch02.xhtml#ch02)。
- en: '**Table 5-2:** ASCII Codes for the Numeric Digits'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-2：** 数字字符的 ASCII 码'
- en: '| **Character** | **Decimal** | **Hexadecimal** |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **字符** | **十进制** | **十六进制** |'
- en: '| 0 | `48` | `$30` |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 0 | `48` | `$30` |'
- en: '| 1 | `49` | `$31` |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 1 | `49` | `$31` |'
- en: '| 2 | `50` | `$32` |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 2 | `50` | `$32` |'
- en: '| 3 | `51` | `$33` |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 3 | `51` | `$33` |'
- en: '| 4 | `52` | `$34` |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 4 | `52` | `$34` |'
- en: '| 5 | `53` | `$35` |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 5 | `53` | `$35` |'
- en: '| 6 | `54` | `$36` |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 6 | `54` | `$36` |'
- en: '| 7 | `55` | `$37` |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 7 | `55` | `$37` |'
- en: '| 8 | `56` | `$38` |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 8 | `56` | `$38` |'
- en: '| 9 | `57` | `$39` |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 9 | `57` | `$39` |'
- en: Despite the fact that it is a “standard,” simply encoding your data using ASCII
    characters does not guarantee compatibility across systems. An *A* on one machine
    is most likely an *A* on another system; but, of the 32 control codes in the first
    group of ASCII codes, plus the delete code in the last group, only 4 control codes
    are commonly supported by most devices and applications—backspace (BS), tab, carriage
    return (CR), and line feed (LF). Worse still, different machines often use these
    “supported” control codes in different ways. End-of-line is a particularly troublesome
    example. Windows, MS-DOS, CP/M, and other systems mark end-of-line by the two-character
    sequence CR/LF. The original Apple Macintosh OS and many other systems mark end-of-line
    by a single CR character. Linux, BeOS, macOS, and other Unix systems mark end-of-line
    with a single LF character.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它是一个“标准”，但仅仅使用 ASCII 字符编码数据并不能保证在不同系统之间的兼容性。一个系统上的*A*字符在另一个系统上很可能仍然是*A*；然而，在
    ASCII 代码的第一组 32 个控制码中，加上最后一组的删除码，只有 4 个控制码在大多数设备和应用程序中得到普遍支持——退格（BS）、制表符、回车（CR）和换行符（LF）。更糟糕的是，不同的机器往往以不同的方式使用这些“支持的”控制码。行尾就是一个特别棘手的例子。Windows、MS-DOS、CP/M
    和其他系统使用两个字符的序列 CR/LF 来标记行尾。原版 Apple Macintosh 操作系统和许多其他系统通过单一的 CR 字符来标记行尾。Linux、BeOS、macOS
    和其他 Unix 系统则通过单一的 LF 字符来标记行尾。
- en: Exchanging simple text files between different systems can be an exercise in
    frustration. Even if you use standard ASCII characters in all your files, you
    still need to convert the data when exchanging files between systems. Fortunately,
    many text editors automatically handle files with different line endings (many
    available freeware utilities will also do this conversion for you). If you have
    to do this in your own software, simply copy all characters except the end-of-line
    sequence from one file to another, and then emit the new end-of-line sequence
    whenever you encounter an old end-of-line sequence in the input file.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同系统之间交换简单文本文件可能会让人感到沮丧。即使你在所有文件中都使用标准的 ASCII 字符，在不同系统之间交换文件时，你仍然需要转换数据。幸运的是，许多文本编辑器会自动处理具有不同换行符的文件（许多免费的实用工具也可以为你执行此转换）。如果你必须在自己的软件中进行此操作，只需将除行尾序列外的所有字符从一个文件复制到另一个文件，然后在遇到旧的行尾序列时，发出新的行尾序列。
- en: '***5.1.2 The EBCDIC Character Set***'
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.2 EBCDIC 字符集***'
- en: Although the ASCII character set is, unquestionably, the most popular character
    representation, it’s certainly not the only one available. For example, IBM uses
    the *[EBCDIC](gloss01.xhtml#gloss01_86)* code on many of its mainframe and mini-computer
    lines. However, you’ll rarely encounter it on personal computer systems, so we’ll
    consider it only briefly in this book.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 ASCII 字符集无疑是最流行的字符表示法，但它并不是唯一可用的。例如，IBM 在许多大型机和小型计算机产品线中使用 *[EBCDIC](gloss01.xhtml#gloss01_86)*
    码。然而，在个人计算机系统中，你很少会遇到它，因此在本书中我们仅简要讨论它。
- en: EBCDIC (pronounced “Eb-suh-dic”) stands for *Extended Binary Coded Decimal Interchange
    Code*. If you’re wondering whether there was an unextended version of this character
    code, the answer is yes. Earlier IBM systems and keypunch machines used *BCDIC
    (Binary Coded Decimal Interchange Code)*, a character set based on punched cards
    and decimal representation (for IBM’s older decimal machines).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: EBCDIC（发音为“Eb-suh-dic”）代表*扩展二进制编码十进制交换码*。如果你在想是否有这个字符编码的未扩展版本，答案是有的。早期的 IBM
    系统和打孔机使用的是*BCDIC（二进制编码十进制交换码）*，这是一个基于打孔卡和十进制表示法的字符集（用于 IBM 的老旧十进制机器）。
- en: BCDIC existed long before modern digital computers; it was born on old-fashioned
    IBM keypunches and tabulator machines. EBCDIC extended that encoding to provide
    a character set for IBM’s computers. However, EBCDIC inherited several traits
    from BCDIC that seem strange in the context of modern computers. For example,
    the encodings of the alphabetic characters are not contiguous. Originally, the
    alphabetic characters probably did have a sequential encoding; however, when IBM
    expanded the character set, it used some binary combinations that aren’t present
    in the BCD format (like `%1010..%1111`). These binary values appear between two
    otherwise sequential BCD values, which explains why certain character sequences
    (such as the alphabetic characters) aren’t contiguous in the EBCDIC encoding.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: BCDIC 在现代数字计算机出现之前就已经存在；它诞生于旧式的 IBM 打孔机和制表机。EBCDIC 扩展了这种编码，以便为 IBM 的计算机提供一个字符集。然而，EBCDIC
    继承了 BCDIC 的几个特性，这些特性在现代计算机的背景下显得有些奇怪。例如，字母字符的编码不是连续的。最初，字母字符可能确实有一个顺序编码；然而，当 IBM
    扩展字符集时，它使用了一些在 BCD 格式中不存在的二进制组合（如 `%1010..%1111`）。这些二进制值出现在两个原本连续的 BCD 值之间，这也解释了为什么某些字符序列（如字母字符）在
    EBCDIC 编码中不连续。
- en: EBCDIC is not a single character set; rather, it is a family of character sets.
    While the EBCDIC character sets have a common core (for example, the encodings
    for the alphabetic characters are usually the same), different versions, known
    as *[code pages](gloss01.xhtml#gloss01_51)*, have different encodings for punctuation
    and special characters. Because of the limited number of encodings available in
    a single byte, different code pages reuse some of the character encodings for
    their own special set of characters. So, if you’re given a file that contains
    EBCDIC characters and someone asks you to translate it to ASCII, you’ll quickly
    discover that it’s not a trivial task.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: EBCDIC 不是单一的字符集；它是一个字符集家族。虽然 EBCDIC 字符集有一个共同的核心（例如，字母字符的编码通常是相同的），不同的版本被称为 *[代码页](gloss01.xhtml#gloss01_51)*，它们对标点符号和特殊字符有不同的编码。由于单个字节中可用的编码数量有限，不同的代码页会重用一些字符编码来表示它们自己特殊的字符集。因此，如果你得到一个包含
    EBCDIC 字符的文件，有人让你将其翻译为 ASCII，你很快会发现这并不是一项简单的任务。
- en: Because of the weirdness of the EBCDIC character set, many common algorithms
    that work well on ASCII characters simply don’t work with EBCDIC. However, keep
    in mind that EBCDIC functional equivalents exist for most ASCII characters. Check
    out the IBM literature for more details.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 EBCDIC 字符集的奇特性，许多在 ASCII 字符上效果良好的常见算法在 EBCDIC 上根本无法使用。然而，请记住，大多数 ASCII 字符都有对应的
    EBCDIC 功能等价物。有关更多细节，请查阅 IBM 的文献。
- en: '***5.1.3 Double-Byte Character Sets***'
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.3 双字节字符集***'
- en: Because a byte can represent a maximum of 256 characters, some computer systems
    use *double-byte character sets (DBCSs)* to represent more than 256 characters.
    DBCSs do not encode every character using 16 bits; instead, they use a single
    byte for most character encodings and use double-byte codes only for certain characters.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 因为一个字节最多可以表示 256 个字符，一些计算机系统使用*双字节字符集（DBCSs）*来表示超过 256 个字符。DBCSs 并不是使用 16 位对每个字符进行编码；相反，它们对大多数字符编码使用一个字节，仅对某些字符使用双字节编码。
- en: 'A typical double-byte character set uses the standard ASCII character set along
    with several additional characters in the range `$80` through `$FF`. Certain values
    in this range are used as extension codes that tell the software that a second
    byte immediately follows. Each extension byte allows the DBCS to support another
    256 different character codes. With three extension values, for example, the DBCS
    can support up to 1,021 different characters: 256 characters for each of the extension
    bytes, and 253 (256 – 3) characters for the standard single-byte set (we subtract
    3 because the three extension byte values each consume one of the 256 combinations,
    and they don’t count as characters).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的双字节字符集使用标准的 ASCII 字符集以及 `$80` 到 `$FF` 范围内的几个额外字符。该范围内的某些值用作扩展码，告诉软件紧跟其后的是第二个字节。每个扩展字节使
    DBCS 能够支持另外 256 个不同的字符编码。例如，通过三个扩展值，DBCS 可以支持最多 1,021 个不同的字符：每个扩展字节支持 256 个字符，而标准单字节集支持
    253 个字符（256 – 3），我们减去 3 是因为这三个扩展字节的值每个都占用了 256 种组合中的一个，它们不算作字符。
- en: Back in the days when terminals and computers used memory-mapped character displays,
    double-byte character sets weren’t very practical. Hardware character generators
    really want each character to be the same size, and they want to process a limited
    number of characters. However, as bitmapped displays with software character generators
    became prevalent (such as Windows, Macintosh, Unix/XWindows machines, tablets,
    and smartphones), it became possible to process DBCSs.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端和计算机使用内存映射字符显示的年代，双字节字符集并不是很实用。硬件字符生成器确实希望每个字符的大小相同，并且希望处理有限数量的字符。然而，随着位图显示和软件字符生成器的普及（如
    Windows、Macintosh、Unix/XWindows 机器、平板电脑和智能手机），处理 DBCS 成为可能。
- en: Although DBCSs can compactly represent a large number of characters, more computing
    resources are required to process text in a DBCS format. For example, determining
    the length of a zero-terminated string containing DBCS characters (typical in
    the C/C++ languages) can be considerable work. Some characters in the string consume
    2 bytes, while most others consume only 1 byte, so a string length function has
    to scan the string byte-by-byte to locate any extension values indicating that
    a single character consumes 2 bytes. This process more than doubles the time a
    high-performance string length function takes to execute.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 DBCS 可以紧凑地表示大量字符，但处理 DBCS 格式的文本需要更多的计算资源。例如，确定一个包含 DBCS 字符的零终止字符串的长度（在 C/C++
    语言中很常见）可能需要相当大的工作量。字符串中的某些字符占用 2 个字节，而大多数其他字符只占用 1 个字节，因此字符串长度函数必须逐字节扫描字符串，定位任何扩展值，这些值指示一个字符占用
    2 个字节。这个过程使得高性能的字符串长度函数的执行时间增加了两倍以上。
- en: Worse still, many common algorithms used to manipulate string data fail when
    applied to DBCSs. For example, a common C/C++ trick to step through characters
    in a string is to either increment or decrement a pointer to the string using
    expressions like `++ptrChar` or `--ptrChar`. This won’t work with DBCSs. While
    someone using a DBCS probably has a set of standard C library routines that work
    on DBCSs, it’s also quite likely that other character functions they or others
    have written don’t work properly with the extended characters.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 更糟糕的是，许多用于操作字符串数据的常见算法在应用于双字节字符集（DBCS）时会失败。例如，一种常见的 C/C++ 技巧是通过使用 `++ptrChar`
    或 `--ptrChar` 等表达式递增或递减指向字符串的指针。这在 DBCS 中不起作用。虽然使用 DBCS 的人可能有一套可以在 DBCS 上工作的标准
    C 库例程，但其他他们或他人编写的字符函数也很可能无法正确处理扩展字符。
- en: The other big problem with DBCSs is the lack of consistent standard. Different
    DBCSs use the same exact encoding for different characters. For these reasons,
    if you need a standardized character set that supports more than 256 characters,
    you’re far better off using the Unicode character set.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: DBCS 的另一个大问题是缺乏一致的标准。不同的 DBCS 对不同的字符使用相同的编码。因此，如果你需要一个支持超过 256 个字符的标准化字符集，使用
    Unicode 字符集无疑是更好的选择。
- en: '***5.1.4 The Unicode Character Set***'
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.4 Unicode 字符集***'
- en: A few decades back, engineers at Aldus, NeXT, Sun, Apple Computer, IBM, Microsoft,
    the Research Library Group, and Xerox realized that their new computer systems
    with bitmaps and user-selectable fonts could display far more than 256 different
    characters at one time. At the time, DBCSs were the most common solution, but—as
    just noted—they had a couple of compatibility problems. So, the engineers sought
    a different route.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 几十年前，Aldus、NeXT、Sun、Apple Computer、IBM、Microsoft、Research Library Group 和 Xerox
    的工程师们意识到，他们的新计算机系统配备位图和用户可选字体，可以同时显示远超过 256 个不同的字符。当时，DBCS 是最常见的解决方案，但正如刚才所提到的，它们存在一些兼容性问题。因此，工程师们寻求了一条不同的道路。
- en: The solution they came up with was the Unicode character set. The engineers
    who originally developed Unicode chose a 2-byte character size. Like DBCSs, this
    approach still required special library code (existing single-byte string functions
    would not always work with double-byte characters), but other than changing the
    size of a character, most existing string algorithms would still work with 2-byte
    characters. The Unicode definition included all of the (known/living) character
    sets at the time, giving each character a unique encoding, to avoid the consistency
    problems that plagued differing DBCSs.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 他们提出的解决方案是 Unicode 字符集。最初开发 Unicode 的工程师选择了 2 字节字符大小。与 DBCS 一样，这种方法仍然需要特定的库代码（现有的单字节字符串函数并不总是适用于双字节字符），但除了改变字符的大小外，大多数现有的字符串算法仍然能够与
    2 字节字符一起工作。Unicode 的定义包括了当时所有（已知/现存的）字符集，为每个字符分配了唯一的编码，以避免困扰不同 DBCS 的一致性问题。
- en: The original Unicode standard used a 16-bit word to represent each character.
    Therefore, Unicode supported up to 65,536 different character codes—a huge advance
    over the 256 possible codes that are representable with an 8-bit byte. Furthermore,
    Unicode is upward compatible from ASCII. If the HO 9 bits^([3](footnotes.xhtml#fn5_3a))
    of a Unicode character’s binary representation contain `0`, then the LO 7 bits
    use the standard ASCII code. If the HO 9 bits contain some nonzero value, then
    the 16 bits form an extended character code (extended from ASCII, that is). If
    you’re wondering why so many different character codes are necessary, note that,
    at the time, certain Asian character sets contained 4,096 characters. The Unicode
    character set even provided a set of codes you could use to create an application-defined
    character set. Approximately half of the 65,536 possible character codes have
    been defined, and the remaining character encodings are reserved for future expansion.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最初的 Unicode 标准使用 16 位字来表示每个字符。因此，Unicode 支持最多 65,536 个不同的字符代码——这比 8 位字节能够表示的
    256 个代码要大大提升。此外，Unicode 还与 ASCII 向后兼容。如果 Unicode 字符的二进制表示的高 9 位^([3](footnotes.xhtml#fn5_3a))
    为 `0`，则低 7 位使用标准的 ASCII 代码。如果高 9 位包含非零值，则这 16 位组成扩展字符代码（即扩展自 ASCII）。如果你想知道为什么需要如此多不同的字符代码，请注意，当时某些亚洲字符集包含了
    4,096 个字符。Unicode 字符集甚至提供了一组代码，可以用来创建应用程序定义的字符集。大约一半的 65,536 个可能字符代码已经被定义，剩余的字符编码则保留用于未来扩展。
- en: Today, Unicode is a universal character set, long replacing ASCII and older
    DBCSs. All modern operating systems (including macOS, Windows, Linux, iOS, Android,
    and Unix), web browsers, and most modern applications provide Unicode support.
    Unicode Consortium, a nonprofit corporation, maintains the Unicode standard. By
    maintaining the standard, Unicode, Inc. (*[https://home.unicode.org/](https://home.unicode.org/)*),
    helps guarantee that a character you write on one system will display as you expect
    on a different system or application.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，Unicode 是一个通用字符集，已经长期取代了 ASCII 和旧的 DBCS（双字节字符集）。所有现代操作系统（包括 macOS、Windows、Linux、iOS、Android
    和 Unix）、网页浏览器和大多数现代应用程序都提供 Unicode 支持。Unicode 联盟是一个非营利性公司，负责维护 Unicode 标准。通过维护该标准，Unicode,
    Inc. (*[https://home.unicode.org/](https://home.unicode.org/)*), 帮助确保你在一个系统中编写的字符会在不同的系统或应用程序中按照预期显示。
- en: '***5.1.5 Unicode Code Points***'
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.5 Unicode 码点***'
- en: Alas, as well thought-out as the original Unicode standard was, it couldn’t
    have anticipated the explosion in characters that would occur. Emojis, astrological
    symbols, arrows, pointers, and a wide variety of symbols introduced for the internet,
    mobile devices, and web browsers have greatly expanded the Unicode symbol repertoire
    (along with a desire to support historic, obsolete, and rare scripts). In 1996,
    systems engineers discovered that 65,536 symbols were insufficient. Rather than
    require 3 or 4 bytes for each Unicode character, those in charge of the Unicode
    definition gave up on trying to create a fixed-size representation of characters
    and allowed for opaque (and multiple) encodings of Unicode characters. Today,
    Unicode defines 1,112,064 code points, far exceeding the 2-byte capacity originally
    set aside for Unicode characters.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 可惜的是，尽管最初的 Unicode 标准考虑得非常周全，但它未能预见到字符数量的爆炸性增长。表情符号、星座符号、箭头、指示符号以及为互联网、移动设备和网页浏览器引入的各种符号大大扩展了
    Unicode 符号库（同时也包含了对历史、过时和罕见文字的支持）。1996 年，系统工程师发现 65,536 个符号不足以满足需求。为了避免每个 Unicode
    字符需要 3 或 4 个字节，Unicode 定义者放弃了创建固定大小字符表示的方法，允许使用不透明的（且可多重）编码来表示 Unicode 字符。今天，Unicode
    定义了 1,112,064 个码点，远远超过了最初为 Unicode 字符分配的 2 字节容量。
- en: A Unicode *[code point](gloss01.xhtml#gloss01_53)* is simply an integer value
    that Unicode associates with a particular character symbol; you can think of it
    as the Unicode equivalent of the ASCII code for a character. The convention for
    Unicode code points is to specify the value in hexadecimal with a `U+` prefix;
    for example, `U+0041` is the Unicode code point for the letter *A*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 Unicode *[码点](gloss01.xhtml#gloss01_53)* 只是一个整数值，Unicode 将其与特定的字符符号关联；你可以把它当作字符的
    ASCII 代码的 Unicode 等价物。Unicode 码点的约定是以十六进制表示，并以 `U+` 为前缀；例如，`U+0041` 是字母 *A* 的
    Unicode 码点。
- en: '**NOTE**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*See* [https://en.wikipedia.org/wiki/Unicode#General_Category_property](https://en.wikipedia.org/wiki/Unicode#General_Category_property)
    *for more details on code points.*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*详情请见* [https://en.wikipedia.org/wiki/Unicode#General_Category_property](https://en.wikipedia.org/wiki/Unicode#General_Category_property)
    *了解更多关于码点的信息。*'
- en: '***5.1.6 Unicode Code Planes***'
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.6 Unicode 编码平面***'
- en: Because of its history, blocks of 65,536 characters are special in Unicode—they
    are known as a *multilingual plane*. The first multilingual plane, `U+000000`
    to `U+00FFFF`, roughly corresponds to the original 16-bit Unicode definition;
    the Unicode standard calls this the *[Basic Multilingual Plane (BMP)](gloss01.xhtml#gloss01_24)*.
    Planes 1 (`U+010000` to `U+01FFFF`), 2 (`U+020000` to `U+02FFFF`), and 14 (`U+0E0000`
    to `U+0EFFFF`) are supplementary planes. Unicode reserves planes 3 through 13
    for future expansion and planes 15 and 16 for user-defined character sets.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其历史原因，Unicode 中的 65,536 字符块是特殊的——它们被称为 *多语言平面*。第一个多语言平面，`U+000000` 到 `U+00FFFF`，大致对应于原始的
    16 位 Unicode 定义；Unicode 标准将其称为 *[基本多语言平面（BMP）](gloss01.xhtml#gloss01_24)*。平面 1（`U+010000`
    到 `U+01FFFF`）、平面 2（`U+020000` 到 `U+02FFFF`）和平面 14（`U+0E0000` 到 `U+0EFFFF`）是补充平面。Unicode
    保留了平面 3 到 13 供未来扩展使用，而平面 15 和 16 则为用户定义字符集保留。
- en: 'The Unicode standard defines code points in the range `U+000000` to `U+10FFFF`.
    Note that `0x10ffff` is 1,114,111, which is where most of the 1,112,064 characters
    in the Unicode character set come from; the remaining 2,048 code points are reserved
    for use as *surrogates*, which are Unicode extensions. *Unicode scalar*, another
    term you might hear, is a value from the set of all Unicode code points *except*
    the 2,048 surrogate code points. The HO two hexadecimal digits of the six-digit
    code point value specify the multilingual plane. Why 17 planes? The reason, as
    you’ll see in a moment, is that Unicode uses special multiword entries to encode
    code points beyond `U+FFFF`. Each of the two possible extensions encodes 10 bits,
    for a total of 20 bits; 20 bits gives you 16 multilingual planes, which, plus
    the original BMP, produces 17 multilingual planes. This is also why code points
    fall in the range `U+000000` to `U+10FFFF`: it takes 21 bits to encode the 16
    multilingual planes plus the BMP.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Unicode 标准定义了范围为 `U+000000` 到 `U+10FFFF` 的码点。请注意，`0x10ffff` 是 1,114,111，这也是
    Unicode 字符集中的大多数 1,112,064 个字符的来源；剩余的 2,048 个码点被保留作为 *代理*，即 Unicode 扩展。你可能听说过的另一个术语
    *Unicode 标量*，是指所有 Unicode 码点的集合中的值，*除了* 2,048 个代理码点。六位码点值的 HO 两个十六进制数字指定了多语言平面。为什么是
    17 个平面？原因如你将看到的那样，Unicode 使用特殊的多字词条目来编码超出 `U+FFFF` 的码点。每个扩展编码 10 位，总共 20 位；20
    位可以表示 16 个多语言平面，再加上原始的 BMP，就得到了 17 个多语言平面。这也是为什么码点范围是 `U+000000` 到 `U+10FFFF`：编码这
    16 个多语言平面加上 BMP 需要 21 位。
- en: '***5.1.7 Surrogate Code Points***'
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.1.7 代理码点***'
- en: As noted earlier, Unicode began life as a 16-bit (2-byte) character set encoding.
    When it became apparent that 16 bits were insufficient to handle all the possible
    characters that existed at the time, an expansion was necessary. As of Unicode
    v2.0, the Unicode, Inc., organization extended the definition of Unicode to include
    multiword characters. Now Unicode uses surrogate code points (`U+D800` through
    `U+DFFF`) to encode values larger than `U+FFFF`. [Figure 5-2](ch05.xhtml#ch05fig02)
    shows the encoding.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Unicode 最初是作为一个 16 位（2 字节）字符集编码的。当显然 16 位不足以处理当时所有可能存在的字符时，扩展变得必要。从 Unicode
    v2.0 开始，Unicode, Inc. 组织扩展了 Unicode 的定义，包含了多字词字符。现在，Unicode 使用代理码点（`U+D800` 到
    `U+DFFF`）来编码大于 `U+FFFF` 的值。[图 5-2](ch05.xhtml#ch05fig02) 显示了这种编码方式。
- en: '![image](../images/05fig02.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/05fig02.jpg)'
- en: '*Figure 5-2: Surrogate code point encoding for Unicode planes 1–16*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-2：Unicode 平面 1-16 的代理码点编码*'
- en: Note that the two words (unit 1/high surrogate and unit 2/low surrogate) always
    appear together. The unit 1 value (with HO bits `%110110`) specifies the upper
    10 bits (`b`[`10`]..`b`[`19`]) of the Unicode scalar, and the unit 2 value (with
    HO bits `%110111`) specifies the lower 10 bits (`b`[`0`]..`b`[`9`]) of the Unicode
    scalar. Therefore, the value of bits `b`[`16`] through `b`[`19`] plus 1 specifies
    Unicode plane 1 through 16\. Bits `b`[`0`] through `b`[`15`] specify the Unicode
    scalar value within the plane.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，两个单元（单元 1/高代理和单元 2/低代理）总是一起出现。单元 1 的值（具有 HO 位 `%110110`）指定 Unicode 标量的高
    10 位（`b`[`10`]..`b`[`19`]），而单元 2 的值（具有 HO 位 `%110111`）指定 Unicode 标量的低 10 位（`b`[`0`]..`b`[`9`]）。因此，`b`[`16`]
    到 `b`[`19`] 位的值加 1 指定了 Unicode 平面 1 到 16，`b`[`0`] 到 `b`[`15`] 位则指定了该平面内的 Unicode
    标量值。
- en: Note that surrogate codes appear only in the BMP. None of the other multilingual
    planes contain surrogate codes. Bits `b`[`0`] through `b`[`19`], extracted from
    the unit 1 and 2 values, always specify a Unicode scalar value (even if the values
    fall in the range `U+D800` through `U+DFFF`).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '***5.1.8 Glyphs, Characters, and Grapheme Clusters***'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Each Unicode code point has a unique name. For example, `U+0045` has the name
    “LATIN CAPITAL LETTER A.” Note that the symbol *A* is *not* the name of the character.
    *A* is a *glyph*—a series of strokes (one horizontal and two slanted strokes)
    that a device draws in order to represent the character.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: There are many different glyphs for the single Unicode character “LATIN CAPITAL
    LETTER A.” For example, a Times Roman letter A and a Times Roman Italic letter
    *A* have different glyphs, but Unicode doesn’t differentiate between them (or
    between *A* characters in any two different fonts). The character “LATIN CAPITAL
    LETTER A” remains `U+0045` regardless of the font or style you use to draw it.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'As an interesting side note, if you have access to the Swift programming language,
    you can print the name of any Unicode character using the following code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'So, what exactly is a character in Unicode? Unicode scalars are Unicode characters,
    but there’s a difference between what you’d normally call a character and the
    definition of a scalar. For example, is *©* one character or two? Consider the
    following Swift code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`"\u{301}"` is the Swift syntax for specifying a Unicode scalar value within
    a string; in this particular case `301` is the hexadecimal code for the *combining
    acute accent* character.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: 'The first `print` statement:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: prints the character (producing `©` on the output, as we expect).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'The second `print` statement prints the number of characters Swift determines
    are present in the string:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This prints `1` to the standard output.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'The third `print` statement prints the number of elements (UTF-16 elements^([4](footnotes.xhtml#fn5_4a)))
    in the string:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This prints `2` on the standard output, because the string holds two words of
    UTF-16 data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: So, again, is this one character or two? Internally (assuming UTF-16 encoding),
    the computer sets aside 4 bytes of memory for this single character (two 16-bit
    Unicode scalar values).^([5](footnotes.xhtml#fn5_5a)) On the screen, however,
    the output takes only one character position and looks like a single character
    to the user. When this character appears within a text editor and the cursor is
    immediately to the right of the character, the user expects that pressing the
    backspace key will delete it. From the user’s perspective, then, this is a single
    character (as Swift reports when you print the `count` attribute of the string).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: In Unicode, however, a character is largely equivalent to a code point. This
    is not what people normally think of as a character. In Unicode terminology, a
    *grapheme cluster* is what people commonly call a character—it’s a sequence of
    one or more Unicode code points that combine to form a single language element
    (that is, a single character). So, when we talk about characters with respect
    to symbols that an application displays to an end user, we’re really talking about
    grapheme clusters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: 'Grapheme clusters can make life miserable for software developers. Consider
    the following Swift code (a modification of the earlier example):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This code produces the same `©` and `1` outputs from the first two `print`
    statements. The following produces `©`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: and this `print` statement produces `1`.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'However, the third `print` statement:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: displays `3` rather than `2` (as in the original example).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: There are definitely three Unicode scalar values in this string (`U+0065`, `U+0301`,
    and `U+0301`). When printing, the operating system combines the `e` and the two
    acute accent combining characters to form the single character `©` and then outputs
    the character to the standard output device. Swift is smart enough to know that
    this combination creates a single output symbol on the display, so printing the
    result of the `count` attribute continues to output `1`. However, there are (undeniably)
    three Unicode code points in this string, so printing `utf16.count` produces `3`
    on output.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '***5.1.9 Unicode Normals and Canonical Equivalence***'
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Unicode character *©* actually existed on personal computers long before
    Unicode came along. It’s part of the original IBM PC character set and also part
    of the Latin-1 character set (used, for example, on old DEC terminals). As it
    turns out, Unicode uses the Latin-1 character set for the code points in the range
    `U+00A0` to `U+00FF`, and `U+00E9` just happens to correspond to the *©* character.
    Therefore, we can modify the earlier program as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The outputs from this program are:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Ouch! Three different strings all producing `©` but containing a different number
    of code points. Imagine how this complicates programming strings containing Unicode
    characters. For example, if you have the following three strings (Swift syntax)
    and you try to compare them, what will the result be?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: To the user, all three strings look the same on the screen. However, they clearly
    contain different values. If you compare them to see if they are equal, will the
    result be `true` or `false`?
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, that depends upon whose string libraries you’re using. Most current
    string libraries would return `false` if you compared these strings for equality.
    Interestingly enough, Swift will claim that `eAccent1` is equal to `eAccent2`,
    but it isn’t smart enough to report that `eAccent1` is equal to `eAccent3` or
    that `eAccent2` is equal to `eAccent3`—despite the fact that it displays the same
    symbol for all three strings. Many languages’ string libraries simply report that
    all three strings are unequal.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: The three Unicode/Swift strings `"\{E9}"`, `"e\{301}"`, and `"e\{301}\{301}"`
    all produce the same output on the display; therefore, they are canonically equivalent
    according to the Unicode standard. Some string libraries won’t report any of these
    strings as being equivalent, however. Others, like the one for Swift, will handle
    small canonical equivalences (such as `"\{E9}" == "e\{301}"`) but not arbitrary
    sequences that should be equivalent.^([6](footnotes.xhtml#fn5_6a))
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Unicode defines *normal forms* for Unicode strings. One aspect of normal form
    is to replace canonically equivalent sequences with an equivalent sequence—for
    example, replace `"e\u{309}"` by `"\u{E9}"` or replace `"\u{E9}"` by `"e\u{309}"`
    (usually, the shorter form is preferable). Some Unicode sequences allow multiple
    combining characters. Often, the order of the combining characters is irrelevant
    to producing the desired grapheme cluster. However, it’s easier to compare two
    such strings if the combining characters are in a specified order. Normalizing
    Unicode strings may also produce results whose combining characters always appear
    in a fixed order (thereby improving efficiency of string comparisons).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '***5.1.10 Unicode Encodings***'
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As of Unicode v2.0, the standard supports a 21-bit character space capable of
    handling over a million characters (though most of the code points remain reserved
    for future use). Rather than use a fixed-size 3-byte (or worse, 4-byte) encoding
    to allow the larger character set, Unicode, Inc., allows different encodings—UTF-32,
    UTF-16, and UTF-8—each with its own advantages and disadvantages.^([7](footnotes.xhtml#fn5_7a))
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: UTF-32 uses 32-bit integers to hold Unicode scalars. The advantage to this scheme
    is that a 32-bit integer can represent every Unicode scalar value (which requires
    only 21 bits). Programs that require random access to characters in strings—without
    having to search for surrogate pairs—and other constant-time operations are (mostly)
    possible with UTF-32\. The obvious drawback to UTF-32 is that each Unicode scalar
    value requires 4 bytes of storage—twice that of the original Unicode definition
    and four times that of ASCII characters. It may seem that using two or four times
    as much storage (over ASCII and the original Unicode) is a small price to pay.
    After all, modern machines have several orders of magnitude more storage than
    they did when Unicode first appeared. However, that extra storage has a huge impact
    on performance, because those additional bytes quickly consume cache storage.
    Furthermore, modern string processing libraries often operate on character strings
    8 bytes at a time (on 64-bit machines). With ASCII characters, that means a given
    string function can process up to eight characters concurrently; with UTF-32,
    that same string function can operate on only two characters concurrently. As
    a result, the UTF-32 version will run four times slower than the ASCII version.
    Ultimately, even Unicode scalar values are insufficient to represent all Unicode
    characters (that is, many Unicode characters require a sequence of Unicode scalars),
    so using UTF-32 doesn’t solve the problem.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: UTF-32 使用 32 位整数来存储 Unicode 标量值。该方案的优点是，32 位整数可以表示每一个 Unicode 标量值（该值只需要 21 位）。需要随机访问字符串中字符的程序——而不必查找代理对——以及其他常数时间操作（大部分情况下）都可以使用
    UTF-32 来实现。UTF-32 的明显缺点是每个 Unicode 标量值需要 4 个字节的存储——是原始 Unicode 定义的两倍，是 ASCII 字符的四倍。看起来，使用比
    ASCII 和原始 Unicode 多两倍或四倍的存储空间似乎是一个小代价。毕竟，现代计算机的存储空间比 Unicode 最初出现时要大几个数量级。然而，这额外的存储空间对性能有巨大影响，因为这些额外的字节很快就会消耗掉缓存存储。此外，现代字符串处理库通常一次处理
    8 个字节（在 64 位机器上）。对于 ASCII 字符，这意味着一个给定的字符串函数可以并行处理多达八个字符；而对于 UTF-32，相同的字符串函数只能并行处理两个字符。因此，UTF-32
    版本的执行速度将比 ASCII 版本慢四倍。最终，即便是 Unicode 标量值也不足以表示所有 Unicode 字符（即，许多 Unicode 字符需要一系列的
    Unicode 标量值），所以使用 UTF-32 并不能解决这个问题。
- en: The second encoding format the Unicode supports is UTF-16\. As the name suggests,
    UTF-16 uses 16-bit (unsigned) integers to represent Unicode values. To handle
    scalar values greater than `0xFFFF`, UTF-16 uses the surrogate pair scheme to
    represent values in the range `0x010000` to `0x10FFFF` (see “[Surrogate Code Points](#sec5_1_7)”
    on page [102](#sec5_1_7)). Because the vast majority of useful characters fit
    into 16 bits, most UTF-16 characters require only 2 bytes. For those rare cases
    where surrogates are necessary, UTF-16 requires 2 words (32 bits) to represent
    the character.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Unicode 支持的第二种编码格式是 UTF-16。顾名思义，UTF-16 使用 16 位（无符号）整数来表示 Unicode 值。为了处理大于 `0xFFFF`
    的标量值，UTF-16 使用代理对方案来表示 `0x010000` 到 `0x10FFFF` 范围内的值（参见页面 [102](#sec5_1_7) 中的
    “[代理码点](#sec5_1_7)”）。因为绝大多数有用的字符适合 16 位表示，所以大多数 UTF-16 字符只需要 2 个字节。对于那些需要代理的罕见情况，UTF-16
    需要 2 个字（32 位）来表示该字符。
- en: The last encoding, and unquestionably the most popular, is UTF-8\. The UTF-8
    encoding is forward compatible from the ASCII character set. In particular, all
    ASCII characters have a single-byte representation (their original ASCII code,
    where the HO bit of the byte containing the character contains a `0` bit). If
    the UTF-8 HO bit is `1`, then UTF-8 requires between 1 and 3 additional bytes
    to represent the Unicode code point. [Table 5-3](ch05.xhtml#ch05tab03) provides
    the UTF-8 encoding schema.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的编码格式，毫无疑问是最流行的编码格式，是 UTF-8。UTF-8 编码与 ASCII 字符集向前兼容。特别地，所有 ASCII 字符都有一个单字节表示（它们原本的
    ASCII 码，其中包含该字符的字节的高位包含 `0` 位）。如果 UTF-8 的高位是 `1`，则 UTF-8 需要额外的 1 到 3 个字节来表示 Unicode
    码点。[表 5-3](ch05.xhtml#ch05tab03) 提供了 UTF-8 编码方案。
- en: '**Table 5-3:** UTF Encoding'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 5-3：** UTF 编码'
- en: '| **Bytes** | **Bits for code point** | **First code point** | **Last code
    point** | **Byte 1** | **Byte 2** | **Byte 3** | **Byte 4** |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| **字节** | **码点位数** | **第一个码点** | **最后一个码点** | **字节 1** | **字节 2** | **字节 3**
    | **字节 4** |'
- en: '| `1` | `7` | `U+00` | `U+7F` | `0`xxxxxxx |  |  |  |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `1` | `7` | `U+00` | `U+7F` | `0`xxxxxxx |  |  |  |'
- en: '| `2` | `11` | `U+80` | `U+7FF` | `110`xxxxx | `10`xxxxxx |  |  |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `2` | `11` | `U+80` | `U+7FF` | `110`xxxxx | `10`xxxxxx |  |  |'
- en: '| `3` | `16` | `U+800` | `U+FFFF` | `1110`xxxx | `10`xxxxxx | `10`xxxxxx |  |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `3` | `16` | `U+800` | `U+FFFF` | `1110`xxxx | `10`xxxxxx | `10`xxxxxx |  |'
- en: '| `4` | `21` | `U+10000` | `U+10FFFF` | `11110`xxx | `10`xxxxxx | `10`xxxxxx
    | `10`xxxxxx |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
- en: The “xxx . . .” bits are the Unicode code point bits. For multibyte sequences,
    byte 1 contains the HO bits, byte 2 contains the next HO bits (LO bits compared
    to byte 1), and so on. For example, the 2-byte sequence (`%11011111`, `%10000001`)
    corresponds to the Unicode scalar `%0000_0111_1100_0001` (`U+07C1`).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: UTF-8 encoding is probably the most common encoding in use. Most web pages use
    it. Most C standard library string functions will operate on UTF-8 text without
    modification (although some C standard library functions can produce malformed
    UTF-8 strings if the programmer isn’t careful with them).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Different languages and operating systems use different encodings as their default.
    For example, macOS and Windows tend to use UTF-16 encoding, whereas most Unix
    systems use UTF-8\. Some variants of Python use UTF-32 as their native character
    format. By and large, though, most programming languages use UTF-8 because they
    can continue to use older ASCII-based character processing libraries to process
    UTF-8 characters. Apple’s Swift is one of the first programming languages that
    attempts to do Unicode right (though there is a huge performance hit for doing
    so).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '***5.1.11 Unicode Combining Characters***'
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although UTF-8 and UTF-16 encodings are much more compact than UTF-32, the CPU
    overhead and algorithmic complexities of dealing with multibyte (or multiword)
    characters sets complicates their use, introducing bugs and performance issues.
    Despite the issues of wasting memory (especially in the cache), why not simply
    define characters as 32-bit entities and be done with it? This seems like it would
    simplify string processing algorithms, improving performance and reducing the
    likelihood of defects in the code.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem with this theory is that you cannot represent all possible grapheme
    clusters with only 21 bits (or even 32 bits) of storage. Many grapheme clusters
    consist of several concatenated Unicode code points. Here’s an example from Chris
    Eidhof and Ole Begemann’s *Advanced Swift* (CreateSpace, 2017):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Each of these Unicode grapheme clusters produces an identical character: an
    `ó` with a dot underneath the character (this is a character from the Yoruba character
    set). The character sequence (`U+1ECD`, `U+300`) is an `o` with a dot under it
    followed by a combining acute. The character sequence (`U+F2`, `U+323`) is an
    `ó` followed by a combining dot. The character sequence (`U+6F`, `U+323`, `U+300`)
    is an `o` followed by a combining dot, followed by a combining acute. Finally,
    the character sequence (`U+6F`, `U+300`, `U+323`) is an `o` followed by a combining
    acute, followed by a combining dot. All four strings produce the same output.
    Indeed, the Swift string comparisons treat all four strings as equal:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that there is not a single Unicode scalar value that will produce this
    character. You must combine at least two Unicode scalars (or as many as three)
    to produce this grapheme cluster on the output device. Even if you used UTF-32
    encoding, it would still require two (32-bit) scalars to produce this particular
    output.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Emojis present another challenge that can’t be solved using UTF-32\. Consider
    the Unicode scalar `U+1F471`. This prints an emoji of a person with blond hair.
    If we add a skin color modifier to this, we obtain (`U+1F471`, `U+1F3FF`), which
    produces a person with a dark skin tone (and blond hair). In both cases we have
    a single character displaying on the screen. The first example uses a single Unicode
    scalar value, but the second example requires two. There is no way to encode this
    with a single UTF-32 value.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: The bottom line is that certain Unicode grapheme clusters will require multiple
    scalars, no matter how many bits we assign to the scalar (it’s possible to combine
    30 or 40 scalars into a single grapheme cluster, for example). That means we’re
    stuck dealing with multiword sequences to represent a single “character” regardless
    of how hard we try to avoid it. This is why UTF-32 has never really taken off.
    It doesn’t solve the problem of random access into a string of Unicode characters.
    If you’ve got to deal with normalizing and combining Unicode scalars, it’s more
    efficient to use UTF-8 or UTF-16 encodings.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Again, most languages and operating systems today support Unicode in one form
    or another (typically using UTF-8 or UTF-16 encoding). Despite the obvious problems
    with dealing with multibyte character sets, modern programs need to deal with
    Unicode strings rather than simple ASCII strings. Swift, which is almost “pure
    Unicode,” doesn’t even offer much in the way of standard ASCII character support.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2 Character Strings**'
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After integers, character strings are probably the most common type in use
    in modern programs. In general, a *[character string](gloss01.xhtml#gloss01_47)*
    is a sequence of characters with two main attributes: a *length* and the *character
    data*.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Character strings may also possess other attributes, such as the *maximum length*
    allowable for that particular variable or a *reference count* specifying how many
    different string variables refer to the same character string. We’ll look at these
    attributes and how programs can use them in this section, which describes various
    string formats and some of the possible string operations.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '***5.2.1 Character String Formats***'
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Different languages use different data structures to represent strings. Some
    string formats use less memory, others allow faster processing, some are more
    convenient to use, and still others provide additional functionality for the programmer
    and operating system. To help you better understand the reasoning behind the design
    of character strings, let’s look at some common string representations popularized
    by various high-level languages.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.1.1 Zero-Terminated Strings**'
  id: totrans-144
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Without question, *[zero-terminated strings](gloss01.xhtml#gloss01_271)* are
    the most common string representation in use today, because this is the native
    string format for C, C++, and several other languages. In addition, you’ll find
    zero-terminated strings in programs written in languages that don’t have a specific
    native string format, such as assembly language.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 'A zero-terminated ASCII string is a sequence containing zero or more 8-bit
    character codes ending with a byte containing `0` (or, in the case of UTF-16,
    a sequence containing zero or more 16-bit character codes and ending with a 16-bit
    word containing `0`). For example, in C/C++, the ASCII string `"abc"` requires
    4 bytes: 1 byte for each of the three characters `a`, `b`, and `c`, and a `0`
    byte.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Zero-terminated strings have a few advantages over other string formats:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Zero-terminated strings can represent strings of any practical length with only
    one byte of overhead (2 bytes in UTF-16, 4 in UTF-32).
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given the popularity of the C/C++ programming languages, high-performance string
    processing libraries are available that work well with zero-terminated strings.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-terminated strings are easy to implement. As far as the C and C++ languages
    are concerned, strings are just arrays of characters. That’s probably why C’s
    designers chose this format in the first place—so they wouldn’t have to clutter
    up the language with string operators.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can easily represent zero-terminated strings in any language able to create
    an array of characters.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, zero-terminated strings also have disadvantages that mean they are
    not always the best choice for representing character string data:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: String functions that need to know the length of a string before working on
    the string data often aren’t very efficient when operating on zero-terminated
    strings. The only reasonable way to compute the length of a zero-terminated string
    is to scan the string from the beginning to the end. The longer your strings are,
    the slower this function runs, so the zero-terminated string format isn’t the
    best choice if you need to process long strings.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although it’s a minor problem, you cannot easily represent the character code
    `0` (such as the NUL character in ASCII and Unicode) with the zero-terminated
    string format.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero-terminated strings don’t contain any information that tells you how long
    the string can grow beyond the terminating `0` byte. Therefore, some string functions,
    like concatenation, can only extend the length of an existing string variable
    and check for overflow if the caller explicitly passes the maximum length.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**5.2.1.2 Length-Prefixed Strings**'
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'A second string format, *[length-prefixed strings](gloss01.xhtml#gloss01_135)*,
    overcomes some of the problems with zero-terminated strings. Length-prefixed strings
    are common in languages like Pascal; they generally consist of a single byte that
    specifies the length of the string, followed by zero or more 8-bit character codes.
    In a length-prefixed scheme, the string `"abc"` consists of 4 bytes: the length
    byte (`$03`), followed by `a`, `b`, and `c`.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'Length-prefixed strings solve two of the problems associated with zero-terminated
    strings: they allow you to represent the NUL character, and string operations
    are more efficient. Another advantage to length-prefixed strings is that the length
    is usually located at position `0` in the string (if we view the string as an
    array of characters), so the first character of the string begins at index `1`
    in the array representation of the string. For many string functions, having a
    `1`-based index into the character data is much more convenient than a `0`-based
    index (which zero-terminated strings use).'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: The principal drawback of length-prefixed strings that they are limited to a
    maximum of 255 characters in length (assuming a 1-byte length prefix). You can
    remove this limitation by using a 2- or 4-byte length value, but doing so increases
    the amount of overhead data from 1 to 2 or 4 bytes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.1.3 Seven-Bit Strings**'
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The 7-bit string format is an interesting option that works for 7-bit encodings
    like ASCII. It uses the (normally unused) higher-order bit of the characters in
    the string to indicate the end of the string. All but the last character code
    in the string has its HO bit clear, and the last character in the string has its
    HO bit set.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'This 7-bit string format has several disadvantages:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: You have to scan the entire string in order to determine the length of the string.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You cannot have zero-length strings.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Few languages provide literal string constants for 7-bit strings.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You’re limited to a maximum of 128 character codes, though this is fine when
    you’re using plain ASCII.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, a big advantage of 7-bit strings is that they don’t require any overhead
    bytes to encode the length. Assembly language (using a macro to create literal
    string constants) is probably the best language to use when dealing with 7-bit
    strings. Because the benefit of 7-bit strings is that they’re compact and assembly
    language programmers tend to worry most about compactness, this is a good match.
    Here’s an HLA macro that converts a literal string constant to a 7-bit string:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**5.2.1.4 HLA Strings**'
  id: totrans-169
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As long as you’re not too concerned about a few extra bytes of overhead per
    string, you can create a string format that combines the advantages of both length-prefixed
    and zero-terminated strings without their respective disadvantages. The High-Level
    Assembly language has done this with its native string format.^([8](footnotes.xhtml#fn5_8a))
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'The biggest drawback to the HLA character string format is the amount of overhead
    required for each string: 9 bytes per string,^([9](footnotes.xhtml#fn5_9a)) which
    can be significant, percentage-wise, if you’re in a memory-constrained environment
    and you process many small strings.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: The HLA string format uses a 4-byte length prefix, allowing character strings
    to be just over four billion characters long (obviously, this is far more than
    any practical HLA application will use). HLA also appends a `0` byte to the character
    string data. The additional 4 bytes of overhead contain the maximum legal length
    for that string. Having this extra field allows HLA string functions to check
    for string overflow, if necessary. In memory, HLA strings take the form shown
    in [Figure 5-3](ch05.xhtml#ch05fig03).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/05fig03.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-3: HLA string format*'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: The 4 bytes immediately before the first character of the string contain the
    current string length. The 4 bytes preceding the current string length contain
    the maximum string length. Immediately following the character data is a `0` byte.
    Finally, HLA always ensures that the string data structure’s length is a multiple
    of 4 bytes long (for performance reasons), so there may be up to 3 additional
    bytes of padding at the end of the object in memory. (Note that the string in
    [Figure 5-3](ch05.xhtml#ch05fig03) requires only 1 byte of padding to ensure that
    the data structure is a multiple of 4 bytes in length.)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'HLA string variables are pointers that contain the byte address of the first
    character in the string. To access the length fields, you load the value of the
    string pointer into a 32-bit register, then access the `Length` field at offset
    –4 from the base register and the `MaxLength` field at offset –8 from the base
    register. Here’s an example:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As read-only objects, HLA strings are compatible with zero-terminated strings.
    For example, if you have a function written in C that’s expecting you to pass
    it a zero-terminated string, you can call that function and pass it an HLA string
    variable, like this:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The only catch is that the C function must not make any changes to the string
    that would affect its length (because the C code won’t update the `Length` field
    of the HLA string). Of course, you can always call a C `strlen()` function upon
    returning to update the length field yourself, but generally, it’s best not to
    pass HLA strings to a function that modifies zero-terminated strings.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.1.5 Descriptor-Based Strings**'
  id: totrans-181
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The string formats we’ve considered up to this point have kept the attribute
    information (that is, the lengths and terminating bytes) for a string in memory
    along with the character data. A slightly more flexible scheme is to maintain
    such information in a record structure, known as a *[descriptor](gloss01.xhtml#gloss01_73)*,
    that also contains a pointer to the character data. Consider the following Pascal/Delphi
    data structure:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note that this data structure does not hold the actual character data. Instead,
    the `strData` pointer contains the address of the first character of the string.
    The `curLength` field specifies the current length of the string. You could add
    any other fields you like to this record, like a maximum length field, though
    a maximum length isn’t usually necessary because most string formats employing
    a descriptor are *dynamic* (as the next section will discuss). Most string formats
    employing a descriptor just maintain the `Length` field.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: An interesting attribute of a descriptor-based string system is that the actual
    character data associated with a string could be part of a larger string. Because
    there are no length or terminating bytes within the actual character data, it’s
    possible to have the character data for two strings overlap (see [Figure 5-4](ch05.xhtml#ch05fig04)).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/05fig04.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-4: Overlapping strings using descriptors*'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: In this example, there are two strings—`"Hello World"` and `"World"`—that overlap.
    This can save memory and make certain functions, like `substring()`, very efficient.
    Of course, when strings overlap like this, you can’t modify the string data because
    that could wipe out part of some other string.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.1.6 Java Strings**'
  id: totrans-189
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Java uses a descriptor-based string form. The actual `String` data type (that
    is, the structure/class that defines the internal representation of a Java string)
    is *opaque*, which means you really aren’t supposed to know about or mess with
    it. It’s a very bad idea to attempt to manipulate Java strings other than via
    the Java String API, because the Java standard has changed their internal representation
    on a couple of occasions.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, Java originally defined the `String` type as a descriptor with
    four items: a pointer to an array of 16-bit (original) Unicode characters (no
    extension beyond 16 bits), a count field, an offset field, and a hash code field.
    The offset and count fields allowed efficient substring operations, since all
    substrings into a larger string would share the same array of characters. Unfortunately,
    this format produced memory leaks in some degenerate cases, so Java’s designers
    changed the format and eliminated these fields. If you had code that used the
    offset and count fields (again, a bad idea), your code was broken by this change.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'Java also switched from the original Unicode 2-byte definition to UTF-16 encoding
    once it became apparent that 16-bit characters were insufficient. However, after
    a bit of research into a wide variety of Java programs on the internet, Oracle
    (Java’s owner) discovered that most programs use only the Latin-1 character set
    (basically, ASCII). In Oracle’s own words:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Data from different applications suggests that strings are a major component
    of Java heap usage and that most `java.lang.String` objects contain only Latin-1
    characters. Such characters require only one byte of storage. As a result, half
    of the space in the internal character arrays of `java.lang.String` objects are
    not used. The compact strings feature, introduced in Java SE 9, reduces the memory
    footprint, and reduces garbage collection activity.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: This change was largely transparent to Java users and their programs. Oracle
    added a new field to the `String` descriptor to specify whether the encoding was
    UTF-16 or Latin-1\. Once again, if your programs depended on the internal representation,
    they broke.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Always assume that Java `String`s are proper Unicode strings (typically using
    UTF-16 encoding). Java does not try to hide the ugliness of multiword characters.
    As a Java programmer, you must be aware of the difference between the number of
    characters, code points, and grapheme clusters in a string. Java provides functions—for
    example, `String.length()`, `String.codePointCount()`, and `BreakIterator.getCharacterInstance()`—to
    compute all these values for you, but your code must explicitly call them.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.1.7 Swift Strings**'
  id: totrans-196
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Like Java, the Swift programming language uses Unicode characters in its strings.
    Swift 4.x and earlier used a UTF-16 encoding, which is native to macOS (on which
    Apple developed Swift); with Swift v5.0, Apple switched to UTF-8 as the native
    encoding for Swift strings. As with Java, Swift’s `String` type is opaque, so
    you shouldn’t attempt to mess with (or otherwise use) its internal representation.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.1.8 C# Strings**'
  id: totrans-198
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The C# programming language uses UTF-16 encoding for characters in its strings.
    As with Java and Swift, C#’s `string` type is opaque and you shouldn’t attempt
    to mess with (or otherwise use) its internal representation. That being said,
    the Microsoft documentation does claim that C# strings are an array of (Unicode)
    characters.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.1.9 Python Strings**'
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The Python programming language originally used UCS-2 (original 16-bit Unicode,
    BMP-only) encoding for strings. Then Python was modified to support UTF-16 or
    UTF-32 encodings (the language was compiled in “narrow” or “wide” versions for
    16- or 32-bit characters). Today, modern versions of Python use a special string
    format that tracks the characters in strings and stores them as ASCII, UTF-8,
    UTF-16, or UTF-32, based on the most compact representation. You can’t really
    access the internal string representation directly within Python, so the caveats
    of opaque types aren’t relevant.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '***5.2.2 Types of Strings: Static, Pseudo-Dynamic, and Dynamic***'
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Based on the various string formats covered thus far, we can now define three
    string types according to when the system allocates storage for the string. There
    are static, pseudo-dynamic, and dynamic strings.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.2.1 Static Strings**'
  id: totrans-204
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Pure *static strings* are those whose maximum size a programmer chooses when
    writing the program. Pascal strings and Delphi “short” strings fall into this
    category. Arrays of characters that you use to hold zero-terminated strings in
    C/C++ also fall into this category. Consider the following declaration in Pascal:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'And here’s an example in C/C++:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: While the program is running, there’s no way to increase the maximum sizes of
    these static strings. Nor is there any way to reduce the storage they will use;
    these string objects will consume 256 bytes at runtime, period. One advantage
    to pure static strings is that the compiler can determine their maximum length
    at compile time and implicitly pass this information to a string function so it
    can test for bounds violations at runtime.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.2.2 Pseudo-Dynamic Strings**'
  id: totrans-210
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A pseudo-dynamic string is one whose length the system sets at runtime by calling
    a memory management function like `malloc()` to allocate storage for it. However,
    once the system allocates storage for the string, the maximum length of the string
    is fixed. HLA strings generally fall into this category.^([10](footnotes.xhtml#fn5_10a))
    An HLA programmer typically calls the `stralloc()` function to allocate storage
    for a string variable, after which that particular string object has a fixed length
    that cannot change.^([11](footnotes.xhtml#fn5_11a))
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '**5.2.2.3 Dynamic Strings**'
  id: totrans-212
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Dynamic string systems, which typically use a descriptor-based format, automatically
    allocate sufficient storage for a string object whenever you create a new string
    or otherwise do something that affects an existing string. Operations like string
    assignment and substring are relatively trivial in dynamic string systems—generally
    they copy only the string descriptor data, so these operations are fast. However,
    as noted in the section “[Descriptor-Based Strings](#sec5_2_1_5)” on page [114](#sec5_2_1_5),
    when using strings this way, you cannot store data back into a string object,
    because it could modify data that is part of other string objects in the system.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this problem is to use the copy-on-write technique. Whenever
    a string function needs to change characters in a dynamic string, the function
    first makes a copy of the string and then makes the necessary modifications to
    that copy. Research suggests that copy-on-write semantics can improve the performance
    of many typical applications, because operations like string assignment and substring
    extraction (which is just a partial string assignment) are far more common than
    the modification of character data within strings. The only drawback to this approach
    is that after several modifications to string data in memory, there may be sections
    of the string heap area that contain character data that’s no longer in use. To
    avoid a *[memory leak](gloss01.xhtml#gloss01_152)*, dynamic string systems employing
    copy on write usually provide *[garbage collection](gloss01.xhtml#gloss01_103)*
    code, which scans the string heap area looking for *stale* character data in order
    to recover that memory for other purposes. Unfortunately, depending on the algorithms
    in use, garbage collection can be quite slow.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '***5.2.3 Reference Counting for Strings***'
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider the case where you have two string descriptors (or pointers) pointing
    at the same string data in memory. Clearly, you can’t *deallocate* (that is, reuse
    for a different purpose) the storage associated with one pointer while the program
    is still using the other pointer to access the same data. One common solution
    is to make the programmer responsible for keeping track of such details. Unfortunately,
    as applications become more complex, this approach often leads to dangling pointers,
    memory leaks, and other pointer-related problems in the software. A better solution
    is to allow the programmer to deallocate the storage for the character data in
    the string and to have the actual deallocation process hold off until the programmer
    releases the last pointer referencing that data. To accomplish this, a string
    system can use reference counters, which track the pointers and their associated
    data.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: A *[reference counter](gloss01.xhtml#gloss01_214)* is an integer that counts
    the number of pointers that reference a string’s character data in memory. Every
    time you assign the address of the string to some pointer, you increment the reference
    counter by 1\. Likewise, whenever you wish to deallocate the storage associated
    with the character data for the string, you decrement the reference counter. Deallocation
    of the storage for the character data doesn’t happen until the reference counter
    decrements to 0.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Reference counting works great when the language handles the details of string
    assignment automatically for you. If you try to implement reference counting manually,
    you must be sure to always increment the reference counter when you assign a string
    pointer to some other pointer variable. The best way to do this is to never assign
    pointers directly, but rather to handle all string assignments via some function
    (or macro) call that updates the reference counters in addition to copying the
    pointer data. If your code fails to update the reference counter properly, you’ll
    wind up with dangling pointers or memory leaks.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '***5.2.4 Delphi Strings***'
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although Delphi provides a “short string” format that is compatible with the
    length-prefixed strings in earlier versions of Delphi, later versions of Delphi
    (4.0 and later) use dynamic strings. While this string format is unpublished (and,
    therefore, subject to change), indications are that Delphi’s string format is
    very similar to HLA’s. Delphi uses a zero-terminated sequence of characters with
    a leading string length and a reference counter (rather than a maximum length
    as HLA uses). [Figure 5-5](ch05.xhtml#ch05fig05) shows the layout of a Delphi
    string in memory.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/05fig05.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-5: Delphi string data format*'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: As with HLA, Delphi string variables are pointers that point to the first character
    of the actual string data. To access the length and reference counter fields,
    the Delphi string routines use a negative offset of – 4 and –8 from the character
    data’s base address. However, because this string format is not published, applications
    should never access the length or reference counter fields directly. Delphi provides
    a length function that extracts the string length for you, and there’s really
    no need for your applications to access the reference counter field because the
    Delphi string functions maintain it automatically.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '***5.2.5 Custom String Formats***'
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Typically, you’ll use the string format your language provides, unless you have
    special requirements. If that’s the case, you’ll find that most languages provide
    user-defined data-structuring capabilities that enable you to create your own
    custom string formats.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Note that the language will probably insist on a single string format for literal
    string constants. However, you can usually write a short conversion function that
    will translate the literal strings in your language to whatever format you choose.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '**5.3 Character Set Data Types**'
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Like strings, character set data types (or just *character sets*) are a composite
    data type built upon the character data type. A *character set* is a mathematical
    set of characters. Membership in a set is a binary relation: a character is either
    in the set or not, and you can’t have multiple copies of the same character in
    a character set. Furthermore, the concept of sequence (whether one character comes
    before another, as in a string) is foreign to a character set. If two characters
    are members of a set, their order in the set is irrelevant.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 5-4](ch05.xhtml#ch05tab04) lists some common operations that applications
    perform on character sets.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 5-4:** Common Character Set Functions'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '| **Function/operator** | **Description** |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
- en: '| Membership (in) | Checks to see if a character is a member of a character
    set (returns `true`/`false`). |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
- en: '| Intersection | Returns the intersection of two character sets (that is, the
    set of characters that are members of both sets). |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
- en: '| Union | Returns the union of two character sets (that is, all the characters
    that are members of either set or both sets). |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
- en: '| Difference | Returns the difference of two sets (that is, those characters
    in one set that are not in the other). |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
- en: '| Extraction | Extracts a single character from a set. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
- en: '| Subset | Returns `true` if one character set is a subset of another. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
- en: '| Proper subset | Returns `true` if one character set is a proper subset of
    another. |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
- en: '| Superset | Returns `true` if one character set is a superset of another.
    |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
- en: '| Proper superset | Returns `true` if one character set is a proper superset
    of another. |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
- en: '| Equality | Returns `true` if one character set is equal to another. |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
- en: '| Inequality | Returns `true` if one character set is not equal to another.
    |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
- en: '***5.3.1 Powerset Representation of Character Sets***'
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are many different ways to represent character sets. Several languages
    implement them using an array of Boolean values (one Boolean value for each possible
    character code). Each Boolean value determines whether its corresponding character
    is (`true`) or is not (`false`) a member of the character set. To conserve memory,
    most character set implementations allocate only a single bit for each character
    in the set; therefore, they consume 16 bytes (128 bits) of memory when supporting
    128 characters, or 32 bytes (256 bits) when supporting up to 256 possible characters.
    This representation of a character set is known as a *[powerset](gloss01.xhtml#gloss01_199)*.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The HLA language uses an array of 16 bytes to represent the 128 possible ASCII
    characters, which is organized in memory as shown in [Figure 5-6](ch05.xhtml#ch05fig06).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/05fig06.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
- en: '*Figure 5-6: HLA character set representation*'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Bit 0 of byte 0 corresponds to ASCII code `0` (the NUL character). If this bit
    is `1`, then the character set contains the NUL character; if this bit is `0`,
    then the character set does not contain the NUL character. Likewise, bit 1 of
    byte 8 corresponds to ASCII code `65`, an uppercase *A*. Bit 65 will contain a
    `1` if *A* is a current member of the character set, and `0` if it is not.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Pascal (for example, Delphi) uses a similar scheme to represent character sets.
    Delphi allows up to 256 characters in a character set, so Delphi character sets
    consume 256 bits (or 32 bytes) of memory.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: While there are other ways to implement character sets, this bit vector (array)
    implementation makes it very easy to perform set operations like union, intersection,
    difference comparison, and membership tests.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '***5.3.2 List Representation of Character Sets***'
  id: totrans-251
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Sometimes a powerset bitmap just isn’t the right representation for a character
    set. For example, if your sets are always very small (no more than three or four
    members), using 16 or 32 bytes to represent each of them can be overkill. In this
    case, you’d be better off using a character string to represent a list of characters.^([12](footnotes.xhtml#fn5_12a))
    If you rarely have more than a few characters in a set, scanning through a string
    to locate a particular character is probably efficient enough for most applications.
    Likewise, if your character set has a large number of possible characters, then
    the powerset representation could become huge (for example, implementing the original
    Unicode UCS-2 character set as a powerset would require 8,192 bytes of memory,
    even if there was only a single character in the set). In this situation, a list
    or character string representation could be more appropriate than a powerset,
    as you don’t need to reserve memory for all possible members of the set (only
    those that are actually present).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '**5.4 Designing Your Own Character Set**'
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Very little is sacred about the ASCII, EBCDIC, and Unicode character sets. Their
    primary advantage is that they are international standards to which many systems
    adhere. If you stick with one of these standards, chances are good you’ll be able
    to exchange information with other people, which is what these codes were designed
    for.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: However, they were not designed to make various character computations easy.
    ASCII and EBCDIC were developed with now-antiquated hardware in mind—mechanical
    teletypewriters’ keyboards and punched-card systems, respectively. Given that
    such equipment is found mainly in museums today, the layout of the codes in these
    character sets has almost no benefit in modern computer systems. If we could design
    our own character sets today, they’d be considerably different from ASCII or EBCDIC.
    They’d probably be based on modern keyboards (so they’d include codes for common
    keys, like LEFT ARROW, RIGHT ARROW, page up, and page down). They’d also be laid
    out to make various common computations a whole lot easier.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Although the ASCII and EBCDIC character sets are not going away any time soon,
    there’s nothing stopping you from defining your own application-specific character
    set. Of course, such a set is, well, application-specific, and you won’t be able
    to share text files containing characters encoded in your custom character set
    with applications that are ignorant of your private encoding. But it’s fairly
    easy to translate between different character sets using a lookup table, so you
    can convert between your application’s internal character set and an external
    character set (like ASCII) when performing I/O operations. Assuming you pick a
    reasonable encoding that makes your programs more efficient overall, the loss
    of efficiency during I/O can be worthwhile. But how do you choose an encoding?
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: The first question you have to ask yourself is, “How many characters do I want
    to support in my character set?” Obviously, the number of characters you choose
    will directly affect the size of your character data. An easy choice is 256 possible
    characters, because bytes are the most common primitive data type that software
    uses to represent character data. Keep in mind, however, that if you don’t really
    need 256 characters, you probably shouldn’t try to define that many in your character
    set. For example, if you can get by with 128, or even 64, characters in your custom
    character set, then “text files” you create with it will compress better. Likewise,
    data transmissions using it will be faster if you only have to transmit 6 or 7
    bits for each character instead of 8\. If you need more than 256 characters, you’ll
    have to weigh the advantages and disadvantages of using multiple code pages, double-byte
    character sets, or 16-bit characters. And keep in mind that Unicode provides support
    for user-defined characters. So, if you need more than 256 characters in your
    character set, you might consider inserting it into Unicode to remain “somewhat
    standard” with the rest of the world.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll define a character set containing 128 characters using
    an 8-bit byte. For the most part, we’ll simply rearrange the codes in the ASCII
    character set to make them more convenient for several calculations, and we’ll
    rename a few of the control codes so they make sense on modern systems instead
    of the old mainframes and teletypes for which they were created. We’ll also add
    a few new characters beyond those defined by the ASCII standard. Again, the main
    purpose of this exercise is to make various computations more efficient, not create
    new characters. We’ll call this the *HyCode* character set.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '*This point bears repeating: the use of HyCode in this chapter is not an attempt
    to create some new character set standard. It’s simply a demonstration of how
    you can create a custom, application-specific character set to improve your programs.*'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '***5.4.1 Designing an Efficient Character Set***'
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We should think about several things when designing a new character set. For
    example, do we need to be able to represent strings of characters using an existing
    string format? This can influence the encoding of our strings—if you want to use
    function libraries that operate on zero-terminated strings, then you need to reserve
    encoding `0` in your custom character set for use as an end-of-string marker.
    Keep in mind, however, that a fair number of string functions won’t work with
    your new character set, no matter what you do. Functions like `stricmp()` work
    only if you use the same representation for alphabetic characters as ASCII (or
    some other common character set). Therefore, you shouldn’t feel hampered by the
    requirements of some particular string representation, because you’re going to
    have to write many of your own string functions to process your custom characters
    anyway. The HyCode character set doesn’t reserve code `0` for an end-of-string
    marker, and that’s okay because zero-terminated strings are not very efficient.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look at programs that use character functions, you’ll see that certain
    functions occur frequently, such as:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Check a character to see if it is a digit.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert a digit character to its numeric equivalent.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert a numeric digit to its character equivalent.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is alphabetic.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is a lowercase character.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is an uppercase character.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compare two characters (or strings) using a *case-insensitive* comparison.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sort a set of alphabetic strings (case-sensitive and case-insensitive sorting).
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is alphanumeric.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is legal in an identifier.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is a common arithmetic or logical operator.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is a bracketing character (that is, one of *(*,
    *)*, *[*, *]*, *{*, *}*, *<*, or *>*).
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is a punctuation character.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is a *whitespace* character (such as a space,
    tab, or newline).
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is a cursor control character.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is a scroll control key (such as PGUP, PGDN,
    HOME, and END).
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check a character to see if it is a function key.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll design the HyCode character set to make these types of operations as efficient
    and easy as possible. One huge improvement we can make over the ASCII character
    set is to assign contiguous character codes to characters belonging to the same
    type, such as alphabetic characters and control characters, so we can do any of
    the preceding tests by using a pair of comparisons. For example, it would be nice
    if we could determine that a particular character is some sort of punctuation
    mark by comparing against two values that represent upper and lower bounds of
    the entire range of such characters, which we can’t do in ASCII because the punctuation
    marks are spread throughout the character set. While it’s not possible to satisfy
    every conceivable range comparison this way, we can design our character set to
    accommodate the most common tests with as few comparisons as possible.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '***5.4.2 Grouping the Character Codes for Numeric Digits***'
  id: totrans-282
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We can achieve the first three functions in the previous list by reserving the
    character codes `0` through `9` for the characters 0 through 9\. First, by using
    a single unsigned comparison to check if a character code is less than or equal
    to `9`, we can see if a character is a digit. Next, converting between characters
    and their numeric representations is trivial, because the character code and the
    numeric representation are one and the same.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '***5.4.3 Grouping Alphabetic Characters***'
  id: totrans-284
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The ASCII character set, though nowhere near as bad as EBCDIC, just isn’t well
    designed for dealing with alphabetic character tests and operations. Here are
    some problems with ASCII that we’ll solve with HyCode:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: The alphabetic characters lie in two disjoint ranges. Tests for an alphabetic
    character require four comparisons.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The lowercase characters have ASCII codes that are greater than the uppercase
    characters. If we’re going to do a case-sensitive comparison, it’s more intuitive
    to treat lowercase characters as being less than uppercase characters.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All lowercase characters have a greater value than any individual uppercase
    character. This leads to counterintuitive results, such as *a* being greater than
    *B*.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'HyCode solves these problems in a couple of interesting ways. First, HyCode
    uses encodings `$4C` through `$7F` to represent the 52 alphabetic characters.
    Because HyCode uses only 128 character codes (`$00..$7F`), the alphabetic codes
    consume the last 52 character codes. This means that we can test a character to
    see if it is alphabetic by comparing whether the code is greater than or equal
    to `$4C`. In a high-level language, you’d write the comparison like this:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Or, if your compiler supports the HyCode character set, like this:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In assembly language, you could use a pair of instructions like the following:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'HyCode interleaves the lowercase and uppercase characters (that is, the sequential
    encodings are for the characters *a*, *A*, *b*, *B*, *c*, *C*, and so on). This
    makes sorting and comparing strings very easy, regardless of whether you’re doing
    a case-sensitive or case-insensitive search. The interleaving uses the LO bit
    of the character code to determine whether the character code is lowercase (LO
    bit is `0`) or uppercase (LO bit is `1`). HyCode uses the following encodings
    for alphabetic characters:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Checking for an uppercase or lowercase alphabetic using HyCode is more work
    than checking whether a character is alphabetic, but in assembly it’s still less
    work than the equivalent ASCII comparison. To test a character to see if it’s
    a member of a single case, you need two comparisons—first to see if it’s alphabetic,
    then to determine its case. In C/C++ you can use statements like the following:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The subexpression `(c & 1)` evaluates `true` (`1`) if the LO bit of `c` is
    `1`, meaning we have an uppercase character if `c` is alphabetic. Likewise, `!(c
    & 1)` evaluates `true` if the LO bit of `c` is `0`, meaning we have a lowercase
    character. If you’re working in 80x86 assembly language, you can test a character
    to see if it’s uppercase or lowercase by using three machine instructions:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Very few languages provide the equivalent of an `ror()` operation, and only
    a few allow you to (easily) treat character values as signed and unsigned within
    the same code sequence. Therefore, this sequence is probably limited to assembly
    language programs.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '***5.4.4 Comparing Alphabetic Characters***'
  id: totrans-302
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The HyCode grouping of alphabetic characters means that lexicographical ordering
    (“dictionary ordering”) is almost free. Sorting your strings by comparing the
    HyCode character values gives you lexicographical order, because HyCode defines
    the following relations on the alphabetic characters:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This is exactly the relationship you want for lexicographical ordering, and
    it’s also the one most people would intuitively expect. To do a case-insensitive
    comparison, you simply mask out the LO bits (or force them both to `1`) of the
    alphabetic characters.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the benefit of the HyCode character set when doing case-insensitive
    comparisons, let’s first take a look at what the standard case-insensitive character
    comparison would look like in C/C++ for two ASCII characters:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: This code doesn’t look too bad, but consider what the `toupper()` function (or,
    usually, macro) expands to:^([13](footnotes.xhtml#fn5_13a))
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'With this macro, you wind up with the following once the C preprocessor expands
    the previous `if` statement:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This expands to 80x86 code similar to this:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In HyCode, case-insensitive comparisons are much simpler. Here’s what the HLA
    assembly code would look like:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As you can see, the HyCode sequence uses half the instructions for a case-insensitive
    comparison of two characters.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '***5.4.5 Grouping Other Characters***'
  id: totrans-317
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Because alphabetic characters are at one end of the character code range and
    numeric characters are at the other, it takes two comparisons to check a character
    to see if it’s alphanumeric (which is still better than the four comparisons necessary
    in ASCII). Here’s the Pascal/Delphi code you’d use to see if a character is alphanumeric:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Several programs (beyond compilers) need to efficiently process strings of characters
    that represent program identifiers. Most languages allow alphanumeric characters
    in identifiers, and, as you just saw, we can check a character to see if it’s
    alphanumeric using only two comparisons.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: Many languages also allow underscores within identifiers, and some languages,
    such as MASM, allow other characters like the “at” character (`@`) and dollar
    sign (`$`) to appear within identifiers. Therefore, by assigning the underscore
    character the value `75`, and by assigning the `$` and `@` characters the respective
    codes `73` and `74`, we can still test for an identifier character using only
    two comparisons.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: For similar reasons, HyCode groups together the cursor control keys, the whitespace
    characters, the bracketing characters (parentheses, brackets, braces, and angle
    brackets), the arithmetic operators, the punctuation characters, and so on. [Table
    5-5](ch05.xhtml#ch05tab05) lists the complete HyCode character set. If you study
    the numeric codes assigned to each character, you’ll see that they allow for efficient
    computation of most of the character operations described earlier.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 5-5:** The HyCode Character Set'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '| **Binary** | **Hex** | **Decimal** | **Character** | **Binary** | **Hex**
    | **Decimal** | **Character** |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
- en: '| `0000_0000` | `00` | `0` | `0` | `0001_1110` | `1E` | `30` | End |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
- en: '| `0000_0001` | `01` | `1` | `1` | `0001_1111` | `1F` | `31` | Home |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
- en: '| `0000_0010` | `02` | `2` | `2` | `0010_0000` | `20` | `32` | PgDn |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
- en: '| `0000_0011` | `03` | `3` | `3` | `0010_0001` | `21` | `33` | PgUp |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
- en: '| `0000_0100` | `04` | `4` | `4` | `0010_0010` | `22` | `34` | Left |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
- en: '| `0000_0101` | `05` | `5` | `5` | `0010_0011` | `23` | `35` | Right |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
- en: '| `0000_0110` | `06` | `6` | `6` | `0010_0100` | `24` | `36` | Up |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
- en: '| `0000_0111` | `07` | `7` | `7` | `0010_0101` | `25` | `37` | Down/linefeed
    |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
- en: '| `0000_1000` | `08` | `8` | `8` | `0010_0110` | `26` | `38` | Nonbreaking
    space |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
- en: '| `0000_1001` | `09` | `9` | `9` | `0010_0111` | `27` | `39` | Paragraph |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
- en: '| `0000_1010` | `0A` | `10` | Keypad | `0010_1000` | `28` | `40` | Carriage
    return |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
- en: '| `0000_1011` | `0B` | `11` | Cursor | `0010_1001` | `29` | `41` | Newline/enter
    |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
- en: '| `0000_1100` | `0C` | `12` | Function | `0010_1010` | `2A` | `42` | Tab |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
- en: '| `0000_1101` | `0D` | `13` | Alt | `0010_1011` | `2B` | `43` | Space |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
- en: '| `0000_1110` | `0E` | `14` | Control | `0010_1100` | `2C` | `44` | `(` |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
- en: '| `0000_1111` | `0F` | `15` | Command | `0010_1101` | `2D` | `45` | `)` |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
- en: '| `0001_0000` | `10` | `16` | Len | `0010_1110` | `2E` | `46` | `[` |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
- en: '| `0001_0001` | `11` | `17` | Len128 | `0010_1111` | `2F` | `47` | `]` |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
- en: '| `0001_0010` | `12` | `18` | Bin128 | `0011_0000` | `30` | `48` | `{` |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
- en: '| `0001_0011` | `13` | `19` | Eos | `0011_0001` | `31` | `49` | `}` |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
- en: '| `0001_0100` | `14` | `20` | Eof | `0011_0010` | `32` | `50` | `<` |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
- en: '| `0001_0101` | `15` | `21` | Sentinel | `0011_0011` | `33` | `51` | `>` |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
- en: '| `0001_0110` | `16` | `22` | Break/interrupt | `0011_0100` | `34` | `52` |
    `=` |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
- en: '| `0001_0111` | `17` | `23` | Escape/cancel | `0011_0101` | `35` | `53` | `^`
    |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
- en: '| `0001_1000` | `18` | `24` | Pause | `0011_0110` | `36` | `54` | `&#124;`
    |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
- en: '| `0001_1001` | `19` | `25` | Bell | `0011_0111` | `37` | `55` | `&` |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
- en: '| `0001_1010` | `1A` | `26` | Back tab | `0011_1000` | `38` | `56` | `-` |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
- en: '| `0001_1011` | `1B` | `27` | Backspace | `0011_1001` | `39` | `57` | `+` |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
- en: '| `0001_1100` | `1C` | `28` | Delete |  |  |  |  |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
- en: '| `0001_1101` | `1D` | `29` | Insert |  |  |  |  |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
- en: '| `0011_1010` | `3A` | `58` | `*` | `0101_1101` | `5D` | `93` | `I` |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
- en: '| `0011_1011` | `3B` | `59` | `/` | `0101_1110` | `5E` | `94` | `j` |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
- en: '| `0011_1100` | `3C` | `60` | `%` | `0101_1111` | `5F` | `95` | `J` |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
- en: '| `0011_1101` | `3D` | `61` | `~` | `0110_0000` | `60` | `96` | `k` |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
- en: '| `0011_1110` | `3E` | `62` | `!` | `0110_0001` | `61` | `97` | `K` |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
- en: '| `0011_1111` | `3F` | `63` | `?` | `0110_0010` | `62` | `98` | `l` |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
- en: '| `0100_0000` | `40` | `64` | `,` | `0110_0011` | `63` | `99` | `L` |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
- en: '| `0100_0001` | `41` | `65` | `.` | `0110_0100` | `64` | `100` | `m` |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
- en: '| `0100_0010` | `42` | `66` | `:` | `0110_0101` | `65` | `101` | `M` |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
- en: '| `0100_0011` | `43` | `67` | `;` | `0110_0110` | `66` | `102` | `n` |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
- en: '| `0100_0100` | `44` | `68` | `"` | `0110_0111` | `67` | `103` | `N` |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
- en: '| `0100_0101` | `45` | `69` | `''` | `0110_1000` | `68` | `104` | `o` |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
- en: '| `0100_0110` | `46` | `70` | `` ` `` | `0110_1001` | `69` | `105` | `O` |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
- en: '| `0100_0111` | `47` | `71` | `\` | `0110_1010` | `6A` | `106` | `p` |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
- en: '| `0100_1000` | `48` | `72` | `#` | `0110_1011` | `6B` | `107` | `P` |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
- en: '| `0100_1001` | `49` | `73` | `$` | `0110_1100` | `6C` | `108` | `q` |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
- en: '| `0100_1010` | `4A` | `74` | `@` | `0110_1101` | `6D` | `109` | `Q` |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
- en: '| `0100_1011` | `4B` | `75` | `_` | `0110_1110` | `6E` | `110` | `r` |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
- en: '| `0100_1100` | `4C` | `76` | `a` | `0110_1111` | `6F` | `111` | `R` |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
- en: '| `0100_1101` | `4D` | `77` | `A` | `0111_0000` | `70` | `112` | `s` |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
- en: '| `0100_1110` | `4E` | `78` | `b` | `0111_0001` | `71` | `113` | `S` |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
- en: '| `0100_1111` | `4F` | `79` | `B` | `0111_0010` | `72` | `114` | `t` |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
- en: '| `0101_0000` | `50` | `80` | `c` | `0111_0011` | `73` | `115` | `T` |'
  id: totrans-378
  prefs: []
  type: TYPE_TB
- en: '| `0101_0001` | `51` | `81` | `C` | `0111_0100` | `74` | `116` | `u` |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
- en: '| `0101_0010` | `52` | `82` | `d` | `0111_0101` | `75` | `117` | `U` |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
- en: '| `0101_0011` | `53` | `83` | `D` | `0111_0110` | `76` | `118` | `v` |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
- en: '| `0101_0100` | `54` | `84` | `e` | `0111_0111` | `77` | `119` | `V` |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
- en: '| `0101_0101` | `55` | `85` | `E` | `0111_1000` | `78` | `120` | `w` |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
- en: '| `0101_0110` | `56` | `86` | `f` | `0111_1001` | `79` | `121` | `W` |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
- en: '| `0101_0111` | `57` | `87` | `F` | `0111_1010` | `7A` | `122` | `x` |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
- en: '| `0101_1000` | `58` | `88` | `g` | `0111_1011` | `7B` | `123` | `X` |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
- en: '| `0101_1001` | `59` | `89` | `G` | `0111_1100` | `7C` | `124` | `y` |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
- en: '| `0101_1010` | `5A` | `90` | `h` | `0111_1101` | `7D` | `125` | `Y` |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
- en: '| `0101_1011` | `5B` | `91` | `H` | `0111_1110` | `7E` | `126` | `z` |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
- en: '| `0101_1100` | `5C` | `92` | `i` | `0111_1111` | `7F` | `127` | `Z` |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
- en: '**5.5 For More Information**'
  id: totrans-391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hyde, Randall. “HLA Standard Library Reference Manual.” n.d. *[http://www.plantation-productions.com/Webster/HighLevelAsm/HLADoc/](http://www.plantation-productions.com/Webster/HighLevelAsm/HLADoc/)*
    or *[https://bit.ly/2W5G1or](https://bit.ly/2W5G1or).*
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: IBM. “ASCII and EBCDIC Character Sets.” n.d. *[https://ibm.co/33aPn3t](https://ibm.co/33aPn3t)*.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Unicode, Inc. “Unicode Technical Site.” Last updated March 4, 2020\. *[https://www.unicode.org/](https://www.unicode.org/)*.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
