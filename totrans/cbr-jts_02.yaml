- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Guarding with Special Care
  prefs: []
  type: TYPE_NORMAL
- en: Even castles with strong fortifications should be guarded, paying particular
    attention to the recessed corners.
  prefs: []
  type: TYPE_NORMAL
- en: What shinobi should keep in mind when stealing into a castle or camp are the
    naturally fortified and difficult directions, the woods, and blind spots.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '—Yoshimori Hyakushu #10'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Shinobi were historically proficient infiltrators. The ancient scrolls describe
    how to quickly identify and brutally exploit weak spots in an enemy’s fortifications.
    The scrolls also stress that shinobi should use higher-order thinking to creatively
    apply their knowledge when building their own defenses. *Bansenshūkai* advises
    commanders tasked with defending a camp or castle to identify, inspect, and guard
    with special care the areas where shinobi are most likely to attempt entry, such
    as the recessed corners of a castle’s stone walls, rubbish disposal areas, water
    pipes, and nearby woods or bushes.^([1](b01.xhtml#endnote-28))
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Attack Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider the castle’s wall an *attack surface* and weak points in the castle’s
    wall (for example, the water pipe or poorly placed stones in the wall that provide
    footholds) *attack vectors*. The term *attack surface* refers to all the software,
    networks, and systems that the adversary has the opportunity to attack. Any point
    within the attack surface can be an attack vector, or the means an attacker uses
    to gain access. In cybersecurity, it’s always advisable to reduce your attack
    surface. That said, while reducing the castle footprint would shrink the attack
    surface that needs to be defended, it wouldn’t mitigate the amount of damage the
    adversary could inflict or prevent any given attack vector from being exploited.
    Nonetheless, attack surface reduction can make guarding the target easier.
  prefs: []
  type: TYPE_NORMAL
- en: '*Bansenshūkai*’s volume on hidden infiltration includes a list of well-intentioned
    defensive techniques, weapons, and modes of thought that can actually expose a
    camp to risk. It implores commanders to consider how everything in their environment
    could be used against them. For example, the scroll instructs infiltrators to
    look for *shinobi-gaeshi*, spikes set up around an enemy’s encampment to deter
    would-be attackers.^([2](b01.xhtml#endnote-29)) Because defenders placed these
    spikes in locations they considered vulnerable, the spikes’ presence told enemy
    shinobi where the defenses were inadequate; defenders were essentially broadcasting
    their insecurities. Shinobi knew they could remove these spikes—doing so was relatively
    easy, as they were almost always attached as an afterthought—and gain passage
    through the weakest spot in the target’s perimeter.^([3](b01.xhtml#endnote-30))'
  prefs: []
  type: TYPE_NORMAL
- en: A succinct example of such security that is “bolted on” as an afterthought is
    found in Microsoft Windows’ PowerShell. The multitude of security features added
    on top of the .NET framework with each new version of PowerShell do not address
    the product’s core flaws and, in fact, have allowed threat actors to create an
    armory of tools and weapons that can be used to infiltrate systems that support
    PowerShell. This is an excellent case study for any security researcher wishing
    to examine *shinobi-gaeshi* more closely.
  prefs: []
  type: TYPE_NORMAL
- en: The ancient castles still standing in Japan are not typically adorned with spikes,
    but they do tend to have water pipes that are too small for a human to climb through,
    perimeters cleared of vegetation, and no recessed corners in the outer walls—all
    of which suggest that emperors, taking their cues from shinobi, made efforts over
    time to eliminate these vulnerabilities. However, while it is ideal to eliminate
    weaknesses so they do not require guarding, it is not always possible.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll discuss the concept of guarding and its proposed place
    within the five functions of cybersecurity. We will then discuss how to identify
    the vulnerable areas that may require guarding with threat modeling.
  prefs: []
  type: TYPE_NORMAL
- en: The Concept of Guarding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Guarding* is the act of exercising protective control over assets by observing
    the environment, detecting threats, and taking preventative action. For example,
    the lord of a castle identifies a fairly large water drainage pipe in the castle
    wall as a weak point. The lord retains the pipe, which performs an important function
    in allowing water to exit, but requires a guard to stand nearby, preventing attackers
    from using the pipe as a means of access.'
  prefs: []
  type: TYPE_NORMAL
- en: In general, organizations tend to keep cybersecurity staff in the dark about
    weak systems, network blind spots, or vulnerable attack vectors that should be
    guarded with special care. Some organizations assume it’s entirely the cybersecurity
    staff’s responsibility to discover security flaws in the network. Many stakeholders
    have not identified these attack vectors in the first place, or if no commercial
    solution exists or no commonly accepted countermeasure can be applied easily,
    they simply ignore the weaknesses and hope they will not be exploited.
  prefs: []
  type: TYPE_NORMAL
- en: In some instances, management directs security personnel *not* to perform basic
    logging, scanning, or patching of legacy systems for fear that touching them will
    disrupt business operations. In more political organizations, it’s common for
    a threat to not be recognized as a valid concern unless it’s identified through
    a formal documentation process. Imagine seeing that a castle is missing its west
    wall, reporting this obvious vulnerability to the king, and having the king dismiss
    your concerns because his guards have not mentioned it in their official reports.
  prefs: []
  type: TYPE_NORMAL
- en: Guarding Within a Cybersecurity Framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *National Institute of Standards and Technology (NIST) Cybersecurity Framework*^([4](b01.xhtml#endnote-31))
    seeks to prevent these common missteps and improve organizations’ resilience to
    cyber threats through five core cybersecurity functions: identify, protect, detect,
    respond, and recover. These functions help identify vulnerabilities in networks
    and systems by using common information security tools and processes.'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, most organizations begin the process of identifying weaknesses
    by conducting vulnerability or application scans of systems on their network—this
    is the *identify* function. Effective and reliable, these scans identify obvious
    security issues such as unpatched software, active accounts with blank passwords,
    default factory credentials, unparameterized input, and SSH ports open to the
    internet. Next comes the *protect* function. Upon discovery of an unsecured system,
    the scanner documents the problem, and then security staff fixes or mitigates
    the vulnerability with patches; configuration changes; or long-term architectural,
    security system, or software implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the security staff is unable to protect a system that has been identified
    as an attack vector, I believe they should *guard* it through human controls.
    However, a guard function is missing from the NIST framework. Instead, we move
    straight to the *detect* function: the security staff attempts to detect an adversary
    by monitoring and investigating anomalous events. Once the security staff detects
    infiltration, only then do they execute the *respond* function by containing the
    threat, neutralizing the threat, and reporting it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Last is the *recovery* function: restoring the systems and data to operational
    status, as well as improving their ability to resist future attacks.'
  prefs: []
  type: TYPE_NORMAL
- en: While essential to a robust security profile, these safeguards are prevention-,
    protection-, or response-based functions. The cybersecurity industry rarely applies
    the concept of guarding—using human controls and protection—to information systems,
    because it’s not feasible for a human defender to manually inspect and approve
    every email, web page, file, or packet that leaves or enters the environment in
    the way that a gate guard could watch people or packages entering a building.
  prefs: []
  type: TYPE_NORMAL
- en: For example, computers with 1GB network connections can process more than 100,000
    packets per second, far more than any human could inspect. Instead of using human
    guards, defenders either rely heavily on automated security controls or simply
    accept/ignore risk as part of doing business. Guarding can still be feasible within
    a modern digital network, however, if guards are inserted only into areas that
    need special care and attention, such as the most likely attack vectors. This
    is why threat modeling to identify these areas in your organization will be useful.
  prefs: []
  type: TYPE_NORMAL
- en: Threat Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The closest thing to guarding in cybersecurity is *threat hunting*, which involves
    vigorously seeking out indicators of infiltration in logs, forensic data, and
    other observable evidence. Few organizations perform threat hunting, and even
    in those that do, a hunter’s job is to detect, not guard.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, it’s important that cyber defenders go beyond the conventional
    framework, continually imagining new ways in which networks and information systems
    could be attacked, and implement the necessary defenses. To this end, defenders
    can use threat modeling to implement information flow controls and design safeguards
    against threats rather than simply react to them.
  prefs: []
  type: TYPE_NORMAL
- en: Typically performed only by cyber-mature organizations, threat modeling involves
    documenting a *data flow diagram (DFD)*, which describes the flow of data and
    processes inside systems. DFDs are typically documented as a type of flowchart,
    but can be roughly represented by a detailed network map. A DFD can be used as
    a tool for structured analysis of your attack surface that allows you to think
    of attack scenarios within the parameters of the documented information systems.
    It doesn’t require vulnerability scanning, proving of the attack scenario by red
    teams, or validation from a compliance framework, and organizations don’t need
    to wait for a security incident to prove a threat model before acting to guard
    against the vulnerability.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the modern cyber equivalents to “recessed corners of a castle’s
    stone walls, rubbish disposal areas, water pipes, and nearby woods or bushes”
    of your environment could help you identify attack vectors that may need guarding
    with special care.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this example: as part of their nightly duties, a security guard pulls
    on every doorknob in an office to make sure the doors are locked. If they find
    an unlocked door, they lock it, secure the keys, and file a security incident
    ticket.'
  prefs: []
  type: TYPE_NORMAL
- en: It is later determined that a security incident occurred because door keys were
    copied or stolen, so the organization adds a second-level authenticator control
    (such as a keypad or badge reader) to the doors, changes the locks, and issues
    new keys. These new preventive security controls satisfy compliance auditors,
    and the ticket reporting the unsecured doors is closed. The chief information
    security officer (CISO) even hires a red team to perform a narrow-scope physical
    penetration test of the new door-locking mechanisms, and the team confirms that
    they were denied access because of the enhanced security measures.
  prefs: []
  type: TYPE_NORMAL
- en: However, once we conduct threat-modeling exercises, we identify that it’s possible
    to push moveable ceiling tiles out of the way and climb over the office wall,
    bypassing the new security measures altogether. To counteract this, we could add
    controls, such as security cameras or motion detectors in the ceiling crawl space,
    or we could install solid, tunnel-resistant ceilings and floors. Guards could
    even be hired and trained to look for evidence of disturbed ceiling tiles, ceiling
    particulate on the floor, or footprints on the walls. Guarding against this threat
    would require that guards be posted inside the room or stationed within the ceiling
    crawl space, armed with the authority and tools to protect the room from intruders.
  prefs: []
  type: TYPE_NORMAL
- en: The feasibility of implementing such countermeasures is low—you might be laughed
    out of your manager’s office for even suggesting them. It’s easy to see why organizations
    are more likely to accept or ignore certain threats than attempt to repel them,
    and this is likely why the NIST Cybersecurity Framework doesn’t include a guard
    function. If thoughtfully informed by detailed threat modeling and carefully implemented
    in a creative and deliberate manner, however, this guard-centric mode of thinking
    can bolster the security of information systems and networks.
  prefs: []
  type: TYPE_NORMAL
- en: An example of a scenario suitable for the implementation of the guard function
    is in *jump boxes*. Jump boxes are systems that span two or more network boundaries,
    allowing administrators to log in remotely to the jump box from one network and
    “jump” to another network to gain access to it. The conventional cybersecurity
    framework advises hardening jump box systems by patching all known vulnerabilities,
    restricting access with various firewall rules, and monitoring audit logs for
    anomalous events such as unauthorized access. However, such technical controls
    are often attacked or bypassed. A guard, on the other hand, could physically disconnect
    the internal network cable from the other network and connect it directly only
    after verifying with the administrator that they have approval to execute remote
    commands against these systems. The guard could also actively monitor actions
    on the machine in real time and forcibly terminate the session anytime they observe
    malicious or unauthorized actions. Implementing the guard function in this way
    might mean hiring a human guard to sit in the data center to protect both physical
    and remote access to these sensitive systems.
  prefs: []
  type: TYPE_NORMAL
- en: Using Threat Modeling to Find Potential Attack Vectors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The basic steps for identifying attack vectors are to follow the guidelines
    for threat modeling, starting with creating a DFD. Once potential attack vectors
    are identified from the DFD, the shinobi scrolls recommend inspecting them to
    determine what technical security controls can be implemented to protect them.
    Then, as a last resort, use guards to defend these areas as well. You can use
    the network map you made in the previous chapter to help create the DFD or use
    it as a rough substitute.
  prefs: []
  type: TYPE_NORMAL
- en: '*Model your information systems.* Create an accurate DFD with the help of your
    organization’s network, security, development, business, and other IT system owners
    and experts. It does not need to use Unified Modeling Language (UML) or other
    advanced concepts—it simply needs to accurately represent your systems and the
    information within them. Note that large, complex systems can easily take a team
    more than six months to diagram.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*STRIDE and guard.* STRIDE is a threat-modeling methodology developed by Microsoft^([5](b01.xhtml#endnote-32))
    to describe what could go wrong in an information system. The acronym comes from
    the ways in which an attacker could violate six properties of the system:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **S**poofing Identity | = | Authentication |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **T**ampering with Data | = | Integrity |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **R**epudiation/Deniability | = | Nonrepudiation |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **I**nformation Disclosure | = | Confidentiality |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **D**enial of Service | = | Availability |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **E**levation of Privilege | = | Authorization |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: To use STRIDE, you will review your DFD and, at every point where there is data
    input, data processing, data output, or other data flows/rules, hypothesize how
    an adversary may threaten it. For example, if a system requires a thumbprint to
    verify a user’s identity before allowing access to the system, you might consider
    how they could spoof the thumbprint to impersonate a different user. Similarly,
    you could think about ways they could tamper with the fingerprint database to
    insert their print, or you could explore a scenario in which the attacker causes
    the fingerprint scanner to go down, allowing unauthorized access through a weaker
    authentication process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After learning this framework, you can use it to challenge any imagined threat
    models that do not accurately represent your systems or scenarios that do not
    describe how a plausible threat impacts a specific component, surface, or vector.
    This may require inviting technical subject matter experts to threat-modeling
    sessions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Suppose, for example, that an organizational threat-modeling session produces
    the following scenario: “The threat of malware compromises the integrity of internal
    databases.”'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This threat is not properly modeled. Among other pieces of critical information,
    the scenario does not describe how malware could be delivered and installed. Nor
    does it describe how the malware would compromise the integrity of the database:
    does it encrypt, delete, or corrupt data? It does not describe which vectors allow
    the threat to impact the system, and it doesn’t consider the information flow
    and controls currently in place or provide realistic countermeasures. If, for
    example, we determined that the most plausible way to infect an internal business
    database with malware would be through a malicious USB drive, then security may
    need to draft policies detailing how staff must use USB drives or install cameras
    to monitor access to USB ports. The organization might decide to grant security
    the ability to turn USBs on or off, dictate which drives can interface with USBs,
    control the information flow and direction of USB ports, inspect the files on
    USB drives before granting access to the requestor, control access with hardware
    or software locks, or even hot-glue the USB ports shut. Such measures, resulting
    from thorough threat modeling, allow security personnel to guard against specific
    threats with special care, rather than having to accept the risk or being limited
    to protect and detect functions.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Do not advertise bolted-on security.* Threat modeling is an iterative, infinite
    process of evaluating new threats and developing protective countermeasures. In
    your haste to protect your systems, avoid the use of *shinobi-gaeshi* security
    controls—defensive efforts that may backfire by drawing attention to your vulnerable
    areas. Often because of time, resource, or operational restrictions, you may have
    taken only half measures that a motivated, sophisticated threat actor can defeat.
    For example, hot glue in a USB port can be removed with isopropyl alcohol. Where
    possible, assess the viability of a pure security-first defense approach.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the USB threat example, the USB interacts with the hardware abstraction layer
    (HAL) that sits below the OS kernel. It cannot be fully protected or mitigated
    with software and policy controls, as those exist above the kernel and can be
    bypassed. Therefore, a more complete solution might be to implement a motherboard
    and chassis configuration in which USB ports do not even exist. In contrast, hot
    glue in the USB port advertises to motivated threat actors that you have not properly
    addressed the security of USBs, and it will likely be a successful attack vector
    for them should they be able to pull it free—just as the shinobi pulled out the
    spikes bolted onto pipes and walls in ancient times.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Recommended Security Controls and Mitigations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Where relevant, each recommendation is presented with an applicable security
    control from the NIST 800-53 standard, and it should be evaluated through the
    lens of guarding with special care.
  prefs: []
  type: TYPE_NORMAL
- en: 'Review the results of auditors, red team assessments, vulnerability scans,
    and incident reports to find vulnerabilities in your environment that cannot be
    easily patched or mitigated with controls (that is, those that require special
    guarding). [CA-2: Security Assessments; CA-8: Penetration Testing; IR-6: Incident
    Reporting | (2) Vulnerabilities Related to Incidents; RA-5: Vulnerability Scanning]'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Perform threat modeling of your environment to identify vulnerabilities. Then
    determine which ones can be designed out of your environment. Explore the concept
    of guarding security functions and apply those controls to threats that cannot
    be easily purged. [SA-8: Security Engineering Principles; SA-14: Criticality Analysis;
    SA-15: Development Process, Standards, and Tools | (4) Threat Modeling/Vulnerability
    Analysis; SA-17: Developer Security Architecture and Design]'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To deter, protect against, and ensure rapid response to threats, hire real-time
    security personnel as guards and integrate them into vulnerable areas of business
    operations. [IR-10: Integrated Information Security Analysis Team]'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Debrief
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter has helped you think about the places in a network environment
    that an adversary is likely to target for infiltration. You have also been introduced
    to the concept of guarding with direct human interaction between information systems
    and processes. You may have utilized your network map from the previous chapter
    or created your own data flow diagram (DFD) as a representation of your environment
    to identify likely attack vectors and potential STRIDE threats that could be mitigated
    with guards.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll explore a “xenophobic” security concept used by the
    ancient ninja that may hinder adversaries from finding any common ground or footholds
    in your environment to even start their attack vector process.
  prefs: []
  type: TYPE_NORMAL
