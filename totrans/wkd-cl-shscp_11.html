<html><head></head><body>
<h2 class="h2" id="ch10"><span epub:type="pagebreak" id="page_235"/><span class="big"><strong>10</strong></span><br/><strong>INTERNET SERVER ADMINISTRATION</strong></h2>&#13;
<div class="imagec"><img src="../images/common4.jpg" alt="image"/></div>&#13;
<p class="noindent">The job of managing a web server and service is often completely separate from the job of designing and managing content on the website. While the previous chapter offered tools geared primarily toward web developers and other content managers, this chapter shows how to analyze web server log files, mirror websites, and monitor network health.</p>&#13;
<h3 class="h3" id="ch10lev1sec01"><strong>#73 Exploring the Apache access_log</strong></h3>&#13;
<p class="noindenta">If you’re running Apache or a similar web server that uses the <em>Common Log Format</em>, you can do quite a bit of quick statistical analysis with a shell script. In a standard configuration, the server writes <em>access_log</em> and <em>error_log</em> files for the site (generally in <em>/var/log</em>, but this can be system dependent). If you’ve got your own server, you should definitely be archiving this valuable information.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_236"/><a href="ch10.xhtml#ch10table1">Table 10-1</a> lists the fields in an <em>access_log</em> file.</p>&#13;
<p class="tablecap"><a id="ch10table1"/><strong>Table 10-1:</strong> Field Values in the <em>access_log</em> File</p>&#13;
<table class="topbot">&#13;
<thead>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_th"><p class="table"><strong>Column</strong></p></td>&#13;
<td style="vertical-align: top;" class="table_th"><p class="table"><strong>Value</strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">1</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">IP of host accessing the server</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">2–3</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">Security information for HTTPS/SSL connections</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">4</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">Date and time zone offset of the specific request</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">5</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">Method invoked</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">6</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">URL requested</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">7</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">Protocol used</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">8</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">Result code</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">9</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">Number of bytes transferred</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">10</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">Referrer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">11</p></td>&#13;
<td style="vertical-align: top;" class="table_3a"><p class="table">Browser identification string</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">A typical line in <em>access_log</em> looks like this:</p>&#13;
<pre class="programs">65.55.219.126 - - [04/Jul/2016:14:07:23 +0000] "GET /index.rdf HTTP/1.0" 301&#13;
310 "-" "msnbot-UDiscovery/2.0b (+http://search.msn.com/msnbot.htm)""</pre>&#13;
<p class="indent">The result code (field 8) of <code>301</code> indicates that the request was considered a success. The referrer (field 10) indicates the URL of the page that the user was visiting immediately before the page request. Ten years ago, this would have been the URL of the previous page; now it’s generally <code>"-"</code>, as you see here, for privacy reasons.</p>&#13;
<p class="indent">The number of hits to the site can be determined by doing a line count on the log file, and the date range of entries in the file can be ascertained by comparing the first and last lines.</p>&#13;
<pre class="programs">$ <span class="codestrong">wc -l access_log</span>&#13;
   7836 access_log&#13;
$ <span class="codestrong">head -1 access_log ; tail -1 access_log</span>&#13;
69.195.124.69 - - [29/Jun/2016:03:35:37 +0000] ...&#13;
65.55.219.126 - - [04/Jul/2016:14:07:23 +0000] ...</pre>&#13;
<p class="indent">With these points in mind, the script in <a href="ch10.xhtml#ch10ex1">Listing 10-1</a> produces a number of useful statistics from an Apache-format <em>access_log</em> file. This script expects the <code>scriptbc</code> and <code>nicenumber</code> scripts we wrote in <a href="ch01.xhtml#ch01">Chapter 1</a> to be in the <code>PATH</code>.</p>&#13;
<h4 class="h4" id="ch10lev2sec01"><em><strong>The Code</strong></em></h4>&#13;
<pre class="programs">   #!/bin/bash&#13;
   # webaccess--Analyzes an Apache-format access_log file, extracting&#13;
   #   useful and interesting statistics&#13;
&#13;
   bytes_in_gb=1048576&#13;
&#13;
<span epub:type="pagebreak" id="page_237"/>   # You will want to change the following to match your own hostname&#13;
   #   to help weed out internally referred hits in the referrer analysis.&#13;
   host="intuitive.com"&#13;
&#13;
   if [ $# -eq 0 ] ; then&#13;
     echo "Usage: $(basename $0) logfile" &gt;&amp;2&#13;
     exit 1&#13;
   fi&#13;
&#13;
   if [ ! -r "$1" ] ; then&#13;
     echo "Error: log file $1 not found." &gt;&amp;2&#13;
     exit 1&#13;
   fi&#13;
&#13;
<span class="ent">➊</span> firstdate="$(head -1 "$1" | awk '{print $4}' | sed 's/\[//')"&#13;
   lastdate="$(tail -1 "$1" | awk '{print $4}' | sed 's/\[//')"&#13;
&#13;
   echo "Results of analyzing log file $1"&#13;
   echo ""&#13;
   echo "  Start date: $(echo $firstdate|sed 's/:/ at /')"&#13;
   echo "    End date: $(echo $lastdate|sed 's/:/ at /')"&#13;
&#13;
<span class="ent">➋</span> hits="$(wc -l &lt; "$1" | sed 's/[^[:digit:]]//g')"&#13;
&#13;
   echo "        Hits: $(nicenumber $hits) (total accesses)"&#13;
&#13;
<span class="ent">➌</span> pages="$(grep -ivE '(.gif|.jpg|.png)' "$1" | wc -l | sed 's/[^[:digit:]]//g')"&#13;
&#13;
   echo "   Pageviews: $(nicenumber $pages) (hits minus graphics)"&#13;
&#13;
   totalbytes="$(awk '{sum+=$10} END {print sum}' "$1")"&#13;
&#13;
   /bin/echo -n " Transferred: $(nicenumber $totalbytes) bytes "&#13;
&#13;
   if [ $totalbytes -gt $bytes_in_gb ] ; then&#13;
     echo "($(scriptbc $totalbytes / $bytes_in_gb) GB)"&#13;
   elif [ $totalbytes -gt 1024 ] ; then&#13;
     echo "($(scriptbc $totalbytes / 1024) MB)"&#13;
   else&#13;
     echo ""&#13;
   fi&#13;
&#13;
   # Now let's scrape the log file for some useful data.&#13;
&#13;
   echo ""&#13;
   echo "The 10 most popular pages were:"&#13;
&#13;
<span class="ent">➍</span> awk '{print $7}' "$1" | grep -ivE '(.gif|.jpg|.png)' | \&#13;
     sed 's/\/$//g' | sort | \&#13;
     uniq -c | sort -rn | head -10&#13;
&#13;
   echo ""&#13;
&#13;
   echo "The 10 most common referrer URLs were:"&#13;
&#13;
<span class="ent">➎</span> awk '{print $11}' "$1" | \&#13;
     grep -vE "(^\"-\"$|/www.$host|/$host)" | \&#13;
     sort | uniq -c | sort -rn | head -10&#13;
&#13;
   echo ""&#13;
   exit 0</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_238"/><a id="ch10ex1"/><em>Listing 10-1: The</em> <code><em>webaccess</em></code> <em>script</em></p>&#13;
<h4 class="h4" id="ch10lev2sec02"><em><strong>How It Works</strong></em></h4>&#13;
<p class="noindenta">Let’s consider each block as a separate little script. For example, the first few lines extract the <code>firstdate</code> and <code>lastdate</code> <span class="ent">➊</span> by simply grabbing the fourth field of the first and last lines of the file. The number of hits is calculated by counting lines in the file using <code>wc</code> <span class="ent">➋</span>, and the number of page views is calculated by simply subtracting requests for image files (that is, files with <em>.gif</em>, <em>.jpg</em>, or <em>.png</em> as their extension) from the hits. Total bytes transferred are calculated by summing up the value of the 10th field in each line and then invoking <code>nicenumber</code> to present it attractively.</p>&#13;
<p class="indent">To calculate the most popular pages, first we extract just the pages requested from the log file, and then we screen out any image files <span class="ent">➌</span>. Next we use <code>uniq -c</code> to sort and calculate the number of occurrences of each unique line. Finally, we sort one more time to ensure that the most commonly occurring lines are presented first. In the code, this whole process is at <span class="ent">➍</span>.</p>&#13;
<p class="indent">Notice that we do normalize things a little bit: the <code>sed</code> invocation strips out any trailing slashes to ensure that <code>/subdir/</code> and <code>/subdir</code> are counted as the same request.</p>&#13;
<p class="indent">Similar to the section that retrieves the 10 most requested pages, the section at <span class="ent">➎</span> pulls out the referrer information.</p>&#13;
<p class="indent">This extracts field 11 from the log file, screening out entries that were referred from the current host as well as entries that are <code>"-"</code>, the value sent when the web browser is blocking referrer data. Then the code feeds the result to the same sequence of <code>sort|uniq -c|sort -rn|head -10</code> to get the 10 most common referrers.</p>&#13;
<h4 class="h4" id="ch10lev2sec03"><em><strong>Running the Script</strong></em></h4>&#13;
<p class="noindenta">To run this script, specify the name of an Apache (or other Common Log Format) log file as its only argument.</p>&#13;
<h4 class="h4" id="ch10lev2sec04"><em><strong>The Results</strong></em></h4>&#13;
<p class="noindenta">The result of running this script on a typical log file is quite informative, as <a href="ch10.xhtml#ch10ex2">Listing 10-2</a> shows.</p>&#13;
<div class="imagec"><img src="../images/f0238-01.jpg" alt="image"/></div>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_239"/><a id="ch10ex2"/><em>Listing 10-2: Running the</em> <code><em>webaccess</em></code> <em>script on an Apache access log</em></p>&#13;
<h4 class="h4" id="ch10lev2sec05"><em><strong>Hacking the Script</strong></em></h4>&#13;
<p class="noindenta">One challenge of analyzing Apache log files is that there are situations in which two different URLs refer to the same page; for example, <em>/custer/</em> and <em>/custer/index.html</em> are the same page. Calculating the 10 most popular pages should take this into account. The conversion performed by the <code>sed</code> invocation already ensures that <em>/custer</em> and <em>/custer/</em> aren’t treated separately, but knowing the default filename for a given directory might be a bit trickier (especially since this can be a special configuration on the web server).</p>&#13;
<p class="indent">You can make the 10 most popular referrers more useful by trimming referrer URLs to just the base domain name (e.g., <em>slashdot.org</em>). <a href="ch10.xhtml#ch10lev1sec02">Script #74</a>, coming up next, explores additional information available from the referrer field. The next time your website gets “slashdotted,” you should have no excuse for not knowing!</p>&#13;
<h3 class="h3" id="ch10lev1sec02"><strong>#74 Understanding Search Engine Traffic</strong></h3>&#13;
<p class="noindenta"><a href="ch10.xhtml#ch10lev1sec01">Script #73</a> can offer a broad overview of some of the search engine queries that point to your site, but further analysis can reveal not only which search engines are delivering traffic but also what keywords were entered by users who arrived at your site via search engines. This <span epub:type="pagebreak" id="page_240"/>information can be invaluable for understanding whether your site has been properly indexed by the search engines. Moreover, it can provide the starting point for improving the rank and relevancy of your search engine listings, though, as we mentioned earlier, this additional information is slowly being deprecated by Apache and web browser developers. <a href="ch10.xhtml#ch10ex3">Listing 10-3</a> details the shell script for retrieving this information from your Apache logs.</p>&#13;
<h4 class="h4" id="ch10lev2sec06"><em><strong>The Code</strong></em></h4>&#13;
<pre class="programs">   #!/bin/bash&#13;
   # searchinfo--Extracts and analyzes search engine traffic indicated in the&#13;
   #   referrer field of a Common Log Format access log&#13;
&#13;
   host="intuitive.com"    # Change to your domain, as desired.&#13;
   maxmatches=20&#13;
   count=0&#13;
   temp="/tmp/$(basename $0).$$"&#13;
&#13;
   trap "$(which rm) -f $temp" 0&#13;
&#13;
   if [ $# -eq 0 ] ; then&#13;
     echo "Usage: $(basename $0) logfile"  &gt;&amp;2&#13;
     exit 1&#13;
   fi&#13;
   if [ ! -r "$1" ] ; then&#13;
     echo "Error: can't open file $1 for analysis." &gt;&amp;2&#13;
     exit 1&#13;
   fi&#13;
&#13;
<span class="ent">➊</span> for URL in $(awk '{ if (length($11) &gt; 4) { print $11 } }' "$1" | \&#13;
     grep -vE "(/www.$host|/$host)" | grep '?')&#13;
   do&#13;
<span class="ent">➋</span>   searchengine="$(echo $URL | cut -d/ -f3 | rev | cut -d. -f1-2 | rev)"&#13;
     args="$(echo $URL | cut -d\? -f2 | tr '&amp;' '\n' | \&#13;
        grep -E '(^q=|^sid=|^p=|query=|item=|ask=|name=|topic=)' | \&#13;
<span class="ent">➌</span>      sed -e 's/+/ /g' -e 's/%20/ /g' -e 's/"//g' | cut -d= -f2)"&#13;
     if [ ! -z "$args" ] ; then&#13;
       echo "${searchengine}:      $args" &gt;&gt; $temp&#13;
<span class="ent">➍</span>   else&#13;
       # No well-known match, show entire GET string instead...&#13;
       echo "${searchengine}       $(echo $URL | cut -d\? -f2)" &gt;&gt; $temp&#13;
     fi&#13;
     count="$(( $count + 1 ))"&#13;
   done&#13;
&#13;
   echo "Search engine referrer info extracted from ${1}:"&#13;
&#13;
   sort $temp | uniq -c | sort -rn | head -$maxmatches | sed 's/^/ /g'&#13;
&#13;
   echo ""&#13;
&#13;
   echo Scanned $count entries in log file out of $(wc -l &lt; "$1") total.&#13;
&#13;
   exit 0</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_241"/><a id="ch10ex3"/><em>Listing 10-3: The</em> <code><em>searchinfo</em></code> <em>script</em></p>&#13;
<h4 class="h4" id="ch10lev2sec07"><em><strong>How It Works</strong></em></h4>&#13;
<p class="noindenta">The main <code>for</code> loop <span class="ent">➊</span> of this script extracts all entries in the log file that have a valid referrer with a string length greater than 4, a referrer domain that does not match the <code>$host</code> variable, and a <code>?</code> in the referrer string, indicating that a user search was performed.</p>&#13;
<p class="indent">The script then tries to identify the domain name of the referrer and the search value entered by the user <span class="ent">➋</span>. An examination of hundreds of search queries shows that common search sites use a small number of common variable names. For example, search on Yahoo! and your search string is <code>p=pattern</code>. Google and MSN use <code>q</code> as the search variable name. The <code>grep</code> invocation contains <code>p</code>, <code>q</code>, and the other most common search variable names.</p>&#13;
<p class="indent">The invocation of <code>sed</code> <span class="ent">➌</span> cleans up the resultant search patterns, replacing <code>+</code> and <code>%20</code> sequences with spaces and chopping out quotes, and the <code>cut</code> command returns everything that occurs after the first equal sign. In other words, the code returns just the search terms.</p>&#13;
<p class="indent">The conditional immediately following these lines tests whether the <code>args</code> variable is empty. If it is (that is, if the query format isn’t a known format), then it’s a search engine we haven’t seen, so we output the entire pattern rather than a cleaned-up, pattern-only value.</p>&#13;
<h4 class="h4" id="ch10lev2sec08"><em><strong>Running the Script</strong></em></h4>&#13;
<p class="noindenta">To run this script, simply specify the name of an Apache or other Common Log Format log file on the command line (see <a href="ch10.xhtml#ch10ex4">Listing 10-4</a>).</p>&#13;
<div class="note">&#13;
<p class="notet"><span class="noteg"><strong>NOTE</strong></span></p>&#13;
<p class="notep"><em>This is one of the slowest scripts in this book because it’s spawning lots of subshells to perform various tasks, so don’t be surprised if it takes a while to run.</em></p>&#13;
</div>&#13;
<h4 class="h4" id="ch10lev2sec09"><em><strong>The Results</strong></em></h4>&#13;
<pre class="programs">$ <span class="codestrong">searchinfo /web/logs/intuitive/access_log</span>&#13;
Search engine referrer info extracted from access_log:&#13;
      771&#13;
        4 online reputation management akado&#13;
        4 Names Hawaiian Flowers&#13;
        3 norvegian star&#13;
        3 disneyland pirates of the caribbean&#13;
        3 disney california adventure&#13;
        3 colorado railroad&#13;
        3 Cirque Du Soleil Masks&#13;
        2 www.baskerballcamp.com&#13;
        2 o logo&#13;
        2 hawaiian flowers&#13;
        2 disneyland pictures pirates of the caribbean&#13;
        2 cirque&#13;
        2 cirqu&#13;
        2 Voil%C3%A0 le %3Cb%3Elogo du Cirque du Soleil%3C%2Fb%3E%21&#13;
        2 Tropical Flowers Pictures and Names&#13;
        2 Hawaiian Flowers&#13;
        2 Hawaii Waterfalls&#13;
        2 Downtown Disney Map Anaheim&#13;
&#13;
Scanned 983 entries in log file out of 7839 total.</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_242"/><a id="ch10ex4"/><em>Listing 10-4: Running the</em> <code><em>searchinfo</em></code> <em>script on Apache logs</em></p>&#13;
<h4 class="h4" id="ch10lev2sec10"><em><strong>Hacking the Script</strong></em></h4>&#13;
<p class="noindenta">One way to tweak this script is to skip the referrer URLs that are most likely not from search engines. To do so, simply comment out the <code>else</code> clause at <span class="ent">➍</span>.</p>&#13;
<p class="indent">Another way to approach this task would be to search for all hits coming from a specific search engine, entered as the second command argument, and then compare the search strings specified. The core <code>for</code> loop would change, like so:</p>&#13;
<pre class="programs">for URL in $(awk '{ if (length($11) &gt; 4) { print $11 } }' "$1" | \&#13;
  <span class="codestrong">grep $2</span>)&#13;
do&#13;
  args="$(echo $URL | cut -d\? -f2 | tr '&amp;' '\n' | \&#13;
     grep -E '(^q=|^sid=|^p=|query=|item=|ask=|name=|topic=)' | \&#13;
     <span class="codestrong">cut -d= -f2</span>)"&#13;
  <span class="codestrong">echo $args  | sed -e 's/+/ /g' -e 's/"//g' &gt;&gt; $temp</span>&#13;
  count="$(( $count + 1 ))"&#13;
done</pre>&#13;
<p class="indent">You’ll also want to tweak the usage message so that it mentions the new second argument. Again, this script is going to eventually just report blank data due to changes in how web browsers—and Google in particular— report the Referer info. As you can see, of the matching entries in this log file, 771 reported no referrer and therefore no useful information about keyword usage.</p>&#13;
<h3 class="h3" id="ch10lev1sec03"><strong>#75 Exploring the Apache error_log</strong></h3>&#13;
<p class="noindenta">Just as <a href="ch10.xhtml#ch10lev1sec01">Script #73</a> on <a href="ch10.xhtml#page_235">page 235</a> reveals the interesting and useful statistical information found in the regular access log of an Apache or Apache-compatible web server, this script extracts the critical information from the <em>error_log</em> file.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_243"/>For those web servers that don’t automatically split their logs into separate <em>access_log</em> and <em>error_log</em> components, you can sometimes split a central log file into these components by filtering based on the return code (field 9) of each entry in the log:</p>&#13;
<pre class="programs">awk '{if (substr($9,0,1) &lt;= "3") { print $0 } }' apache.log &gt; access_log&#13;
awk '{if (substr($9,0,1)  &gt; "3") { print $0 } }' apache.log &gt; error_log</pre>&#13;
<p class="indent">A return code that begins with a 4 or a 5 is a failure (the 400s are client errors and the 500s are server errors), and a return code beginning with a 2 or a 3 is a success (the 200s are success messages and the 300s are redirects).</p>&#13;
<p class="indent">Other servers that produce a single central log file containing both successes and errors denote the error message entries with an <code>[error]</code> field value. In that case, the split can be done with a <code>grep '[error]'</code> to create the error log and a <code>grep -v '[error]'</code> to create the access log.</p>&#13;
<p class="indent">Whether your server automatically creates an error log or you have to create your own error log by searching for entries with the <code>'[error]'</code> string, just about everything in the error log is different from the content of the access log, including the way the date is specified.</p>&#13;
<pre class="programs">$ <span class="codestrong">head -1 error_log</span>&#13;
[Mon Jun 06 08:08:35 2016] [error] [client 54.204.131.75] File does not exist:&#13;
/var/www/vhosts/default/htdocs/clientaccesspolicy.xml</pre>&#13;
<p class="indent">In the access log, dates are specified as a compact one-field value with no spaces; the error log takes five fields instead. Furthermore, rather than a consistent scheme in which the word/string position in a space-delimited entry consistently identifies a particular field, entries in the error log have a meaningful error description that varies in length. An examination of just those description values reveals surprising variation, as shown here:</p>&#13;
<pre class="programs">$ <span class="codestrong">awk '{print $9" "$10" "$11" "$12 }' error_log | sort -u</span>&#13;
File does not exist:&#13;
Invalid error redirection directive:&#13;
Premature end of script&#13;
execution failure for parameter&#13;
premature EOF in parsed&#13;
script not found or&#13;
malformed header from script</pre>&#13;
<p class="indent">Some of these errors should be examined by hand because they can be difficult to track backward to the offending web page.</p>&#13;
<p class="indent">The script in <a href="ch10.xhtml#ch10ex5">Listing 10-5</a> focuses on the most common problems—in particular, <code>File does not exist</code> errors—and then produces a dump of all other error log entries that don’t match well-known error situations.</p>&#13;
<h4 class="h4" id="ch10lev2sec11"><span epub:type="pagebreak" id="page_244"/><em><strong>The Code</strong></em></h4>&#13;
<pre class="programs">   #!/bin/bash&#13;
   # weberrors--Scans through an Apache error_log file, reports the&#13;
   #   most important errors, and then lists additional entries&#13;
&#13;
   temp="/tmp/$(basename $0).$$"&#13;
&#13;
   # For this script to work best, customize the following three lines for&#13;
   #   your own installation.&#13;
&#13;
   htdocs="/usr/local/etc/httpd/htdocs/"&#13;
   myhome="/usr/home/taylor/"&#13;
   cgibin="/usr/local/etc/httpd/cgi-bin/"&#13;
&#13;
   sedstr="s/^/  /g;s|$htdocs|[htdocs]  |;s|$myhome|[homedir] "&#13;
   sedstr=$sedstr"|;s|$cgibin|[cgi-bin] |"&#13;
&#13;
   screen="(File does not exist|Invalid error redirect|premature EOF"&#13;
   screen=$screen"|Premature end of script|script not found)"&#13;
&#13;
   length=5                # Entries per category to display&#13;
&#13;
   checkfor()&#13;
   {&#13;
     grep "${2}:" "$1" | awk '{print $NF}' \&#13;
       | sort | uniq -c | sort -rn | head -$length | sed "$sedstr" &gt; $temp&#13;
&#13;
     if [ $(wc -l &lt; $temp) -gt 0 ] ; then&#13;
       echo ""&#13;
       echo "$2 errors:"&#13;
       cat $temp&#13;
     fi&#13;
   }&#13;
&#13;
   trap "$(which rm) -f $temp" 0&#13;
&#13;
   if [ "$1" = "-l" ] ; then&#13;
     length=$2; shift 2&#13;
   fi&#13;
&#13;
   if [ $# -ne 1 -o ! -r "$1" ] ; then&#13;
     echo "Usage: $(basename $0) [-l len] error_log" &gt;&amp;2&#13;
     exit 1&#13;
   fi&#13;
&#13;
   echo Input file $1 has $(wc -l &lt; "$1") entries.&#13;
&#13;
   start="$(grep -E '\[.*:.*:.*\]' "$1" | head -1 \&#13;
      | awk '{print $1" "$2" "$3" "$4" "$5 }')"&#13;
   end="$(grep -E '\[.*:.*:.*\]' "$1" | tail -1 \&#13;
      | awk '{print $1" "$2" "$3" "$4" "$5 }')"&#13;
&#13;
   /bin/echo -n "Entries from $start to $end"&#13;
&#13;
   echo ""&#13;
&#13;
   ### Check for various common and well-known errors:&#13;
&#13;
   checkfor "$1" "File does not exist"&#13;
   checkfor "$1" "Invalid error redirection directive"&#13;
   checkfor "$1" "Premature EOF"&#13;
   checkfor "$1" "Script not found or unable to stat"&#13;
   checkfor "$1" "Premature end of script headers"&#13;
&#13;
<span class="ent">➊</span> grep -vE "$screen" "$1" | grep "\[error\]" | grep "\[client " \&#13;
     | sed 's/\[error\]/\`/' | cut -d\` -f2 | cut -d\ -f4- \&#13;
<span class="ent">➋</span>   | sort | uniq -c | sort -rn | sed 's/^/ /' | head -$length &gt; $temp&#13;
&#13;
   if [ $(wc -l &lt; $temp) -gt 0 ] ; then&#13;
     echo ""&#13;
     echo "Additional error messages in log file:"&#13;
     cat $temp&#13;
   fi&#13;
&#13;
   echo ""&#13;
   echo "And non-error messages occurring in the log file:"&#13;
&#13;
<span class="ent">➌</span> grep -vE "$screen" "$1" | grep -v "\[error\]" \&#13;
     | sort | uniq -c | sort -rn \&#13;
     | sed 's/^/  /' | head -$length&#13;
&#13;
   exit 0</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_245"/><a id="ch10ex5"/><em>Listing 10-5: The</em> <code><em>weberrors</em></code> <em>script</em></p>&#13;
<h4 class="h4" id="ch10lev2sec12"><em><strong>How It Works</strong></em></h4>&#13;
<p class="noindenta">This script works by scanning the error log for the five errors specified in the calls to the <code>checkfor</code> function, extracting the last field on each error line with an <code>awk</code> call for <code>$NF</code> (which represents the number of fields in that particular input line). This output is then fed through <code>sort | uniq -c | sort -rn</code> <span class="ent">➋</span> to make it easy to extract the most commonly occurring errors for that category of problem.</p>&#13;
<p class="indent">To ensure that only those error types with matches are shown, each specific error search is saved to the temporary file, which is then tested to make sure it isn’t empty before a message is output. This is all neatly done with the <code>checkfor()</code> function that appears near the top of the script.</p>&#13;
<p class="indent">The last few lines of the script identify the most common errors not otherwise checked for by the script but that are still in standard Apache error log format. The <code>grep</code> invocations at <span class="ent">➊</span> are part of a longer pipe.</p>&#13;
<p class="indent">Then the script identifies the most common errors not otherwise checked for by the script that <em>don’t</em> occur in standard Apache error log format. Again, the <code>grep</code> invocations at <span class="ent">➌</span> are part of a longer pipe.</p>&#13;
<h4 class="h4" id="ch10lev2sec13"><span epub:type="pagebreak" id="page_246"/><em><strong>Running the Script</strong></em></h4>&#13;
<p class="noindenta">This script should be passed the path to a standard Apache-format error log as its only argument, shown in <a href="ch10.xhtml#ch10ex6">Listing 10-6</a>. If invoked with a <code>-l length</code> argument, it will display <code>length</code> number of matches per error type checked rather than the default of five entries per error type.</p>&#13;
<h4 class="h4" id="ch10lev2sec14"><em><strong>The Results</strong></em></h4>&#13;
<pre class="programs">$ <span class="codestrong">weberrors error_log</span>&#13;
Input file error_log has 768 entries.&#13;
Entries from [Mon Jun 05 03:35:34 2017] to [Fri Jun 09 13:22:58 2017]&#13;
&#13;
File does not exist errors:&#13;
       94 /var/www/vhosts/default/htdocs/mnews.htm&#13;
       36 /var/www/vhosts/default/htdocs/robots.txt&#13;
       15 /var/www/vhosts/default/htdocs/index.rdf&#13;
       10 /var/www/vhosts/default/htdocs/clientaccesspolicy.xml&#13;
        5 /var/www/vhosts/default/htdocs/phpMyAdmin&#13;
&#13;
Script not found or unable to stat errors:&#13;
        1 /var/www/vhosts/default/cgi-binphp5&#13;
        1 /var/www/vhosts/default/cgi-binphp4&#13;
        1 /var/www/vhosts/default/cgi-binphp.cgi&#13;
        1 /var/www/vhosts/default/cgi-binphp-cgi&#13;
        1 /var/www/vhosts/default/cgi-binphp&#13;
&#13;
Additional error messages in log file:&#13;
        1 script '/var/www/vhosts/default/htdocs/wp-trackback.php' not found&#13;
or unable to stat&#13;
        1 script '/var/www/vhosts/default/htdocs/sprawdza.php' not found or&#13;
unable to stat&#13;
        1 script '/var/www/vhosts/default/htdocs/phpmyadmintting.php' not&#13;
found or unable to stat&#13;
&#13;
And non-error messages occurring in the log file:&#13;
        6 /usr/lib64/python2.6/site-packages/mod_python/importer.py:32:&#13;
DeprecationWarning: the md5 module is deprecated; use hashlib instead&#13;
        6   import md5&#13;
        3 [Sun Jun 25 03:35:34 2017] [warn] RSA server certificate CommonName&#13;
(CN) `Parallels Panel' does NOT match server name!?&#13;
        1 sh: /usr/local/bin/zip: No such file or directory&#13;
        1 sh: /usr/local/bin/unzip: No such file or directory</pre>&#13;
<p class="listcap"><a id="ch10ex6"/><em>Listing 10-6: Running the</em> <code><em>weberrors</em></code> <em>script on Apache error logs</em></p>&#13;
<h3 class="h3" id="ch10lev1sec04"><strong>#76 Avoiding Disaster with a Remote Archive</strong></h3>&#13;
<p class="noindenta">Whether or not you have a comprehensive backup strategy, it’s a nice insurance policy to back up a few critical files with a separate off-site archive system. Even if it’s just that one key file with all your customer addresses, your <span epub:type="pagebreak" id="page_247"/>invoices, or even emails from your sweetheart, having an occasional off-site archive can save your proverbial bacon when you least expect it.</p>&#13;
<p class="indent">This sounds more complex than it really is, because as you’ll see in <a href="ch10.xhtml#ch10ex7">Listing 10-7</a>, the “archive” is just a file emailed to a remote mailbox, which could even be a Yahoo! or Gmail mailbox. The list of files is kept in a separate data file, with shell wildcards allowed. Filenames can contain spaces, something that rather complicates the script, as you’ll see.</p>&#13;
<h4 class="h4" id="ch10lev2sec15"><em><strong>The Code</strong></em></h4>&#13;
<pre class="programs">   #!/bin/bash&#13;
   # remotebackup--Takes a list of files and directories, builds a single&#13;
   #   compressed archive, and then emails it off to a remote archive site&#13;
   #   for safekeeping. It's intended to be run every night for critical&#13;
   #   user files but not intended to replace a more rigorous backup scheme.&#13;
&#13;
   outfile="/tmp/rb.$$.tgz"&#13;
   outfname="backup.$(date +%y%m%d).tgz"&#13;
   infile="/tmp/rb.$$.in"&#13;
&#13;
   trap "$(which rm) -f $outfile $infile" 0&#13;
&#13;
   if [ $# -ne 2 -a $# -ne 3 ] ; then&#13;
     echo "Usage: $(basename $0) backup-file-list remoteaddr {targetdir}" &gt;&amp;2&#13;
     exit 1&#13;
   fi&#13;
&#13;
   if [ ! -s "$1" ] ; then&#13;
     echo "Error: backup list $1 is empty or missing" &gt;&amp;2&#13;
     exit 1&#13;
   fi&#13;
&#13;
   # Scan entries and build fixed infile list. This expands wildcards&#13;
   #   and escapes spaces in filenames with a backslash, producing a&#13;
   #   change: "this file" becomes this\ file, so quotes are not needed.&#13;
&#13;
<span class="ent">➊</span> while read entry; do&#13;
     echo "$entry" | sed -e 's/ /\\ /g' &gt;&gt; $infile&#13;
   done &lt; "$1"&#13;
&#13;
   # The actual work of building the archive, encoding it, and sending it&#13;
&#13;
<span class="ent">➋</span> tar czf - $(cat $infile) | \&#13;
     uuencode $outfname | \&#13;
     mail -s "${3:-Backup archive for $(date)}" "$2"&#13;
&#13;
   echo "Done. $(basename $0) backed up the following files:"&#13;
   sed 's/^/   /' $infile&#13;
   /bin/echo -n "and mailed them to $2 "&#13;
&#13;
   if [ ! -z "$3" ] ; then&#13;
     echo "with requested target directory $3"&#13;
   else&#13;
     echo ""&#13;
   fi&#13;
&#13;
   exit 0</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_248"/><a id="ch10ex7"/><em>Listing 10-7: The</em> <code><em>remotebackup</em></code> <em>script</em></p>&#13;
<h4 class="h4" id="ch10lev2sec16"><em><strong>How It Works</strong></em></h4>&#13;
<p class="noindenta">After the basic validity checks, the script processes the file containing the list of critical files, which is supplied as the first command line argument, to ensure that spaces embedded in its filenames will work in the <code>while</code> loop <span class="ent">➊</span>. It does this by prefacing every space with a backslash. Then it builds the archive with the <code>tar</code> command <span class="ent">➋</span>, which lacks the ability to read standard input for its file list and thus must be fed the filenames via a <code>cat</code> invocation.</p>&#13;
<p class="indent">The <code>tar</code> invocation automatically compresses the archive, and <code>uuencode</code> is then utilized to ensure that the resultant archive data file can be successfully emailed without corruption. The end result is that the remote address receives an email message with the uuencoded <code>tar</code> archive as an attachment.</p>&#13;
<div class="note">&#13;
<p class="notet"><span class="noteg"><strong>NOTE</strong></span></p>&#13;
<p class="notep"><em>The</em> <code><em>uuencode</em></code> <em>program wraps up binary data so that it can safely travel through the email system without being corrupted. See</em> <code><em>man uuencode</em></code> <em>for more information.</em></p>&#13;
</div>&#13;
<h4 class="h4" id="ch10lev2sec17"><em><strong>Running the Script</strong></em></h4>&#13;
<p class="noindenta">This script expects two arguments: the name of a file that contains a list of files to archive and back up and the destination email address for the compressed, <code>uuencoded</code> archive file. The file list can be as simple as this:</p>&#13;
<pre class="programs">$ <span class="codestrong">cat filelist</span>&#13;
*.sh&#13;
*.html</pre>&#13;
<h4 class="h4" id="ch10lev2sec18"><em><strong>The Results</strong></em></h4>&#13;
<p class="noindenta"><a href="ch10.xhtml#ch10ex8">Listing 10-8</a> details running the <code>remotebackup</code> shell script to back up all HTML and shell script files in the current directory, and then printing the results.</p>&#13;
<pre class="programs">$ <span class="codestrong">remotebackup filelist taylor@intuitive.com</span>&#13;
Done. remotebackup backed up the following files:&#13;
   *.sh&#13;
   *.html&#13;
and mailed them to taylor@intuitive.com&#13;
$ <span class="codestrong">cd /web</span>&#13;
$ <span class="codestrong">remotebackup backuplist taylor@intuitive.com mirror</span>&#13;
Done. remotebackup backed up the following files:&#13;
   ourecopass&#13;
and mailed them to taylor@intuitive.com with requested target directory mirror</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_249"/><a id="ch10ex8"/><em>Listing 10-8: Running the</em> <code><em>remotebackup</em></code> <em>script to back up HTML and shell script files</em></p>&#13;
<h4 class="h4" id="ch10lev2sec19"><em><strong>Hacking the Script</strong></em></h4>&#13;
<p class="noindenta">First off, if you have a modern version of <code>tar</code>, you might find that it has the ability to read a list of files from <code>stdin</code> (for example, GNU’s <code>tar</code> has a <code>-T</code> flag to have the file list read from standard input). In this case, the script can be shortened by updating how the file list is given to <code>tar</code>.</p>&#13;
<p class="indent">The file archive can then be unpacked or simply saved, with a mailbox trimmer script run weekly to ensure that the mailbox doesn’t get too big. <a href="ch10.xhtml#ch10ex9">Listing 10-9</a> details a sample trimmer script.</p>&#13;
<pre class="programs">#!/bin/bash&#13;
# trimmailbox--A simple script to ensure that only the four most recent&#13;
#   messages remain in the user's mailbox. Works with Berkeley Mail&#13;
#   (aka Mailx or mail)--will need modifications for other mailers!&#13;
&#13;
keep=4  # By default, let's just keep around the four most recent messages.&#13;
&#13;
totalmsgs="$(echo 'x' | mail | sed -n '2p' | awk '{print $2}')"&#13;
&#13;
if [ $totalmsgs -lt $keep ] ; then&#13;
  exit 0          # Nothing to do&#13;
fi&#13;
&#13;
topmsg="$(( $totalmsgs - $keep ))"&#13;
&#13;
mail &gt; /dev/null &lt;&lt; EOF&#13;
d1-$topmsg&#13;
q&#13;
EOF&#13;
&#13;
exit 0</pre>&#13;
<p class="listcap"><a id="ch10ex9"/><em>Listing 10-9: The</em> <code><em>trimmailbox</em></code> <em>script, to be used in conjunction with the</em> <code><em>remotebackup</em></code> <em>script</em></p>&#13;
<p class="indent">This succinct script deletes all messages in the mailbox other than the most recent ones (<code>$keep</code>). Obviously, if you’re using something like Hotmail or Yahoo! Mail for your archive storage, this script won’t work and you’ll have to log in occasionally to trim things.</p>&#13;
<h3 class="h3" id="ch10lev1sec05"><strong>#77 Monitoring Network Status</strong></h3>&#13;
<p class="noindenta">One of the most puzzling administrative utilities in Unix is <code>netstat</code>, which is too bad, because it offers quite a bit of useful information about network throughput and performance. With the <code>-s</code> flag, <code>netstat</code> outputs volumes of information about each of the protocols supported on your computer, <span epub:type="pagebreak" id="page_250"/>including TCP, UDP, IPv4/v6, ICMP, IPsec, and more. Most of those protocols are irrelevant for a typical configuration; usually the protocol you want to examine is TCP. This script analyzes TCP protocol traffic, determining the percentage of packet transmission failure and including a warning if any values are out of bounds.</p>&#13;
<p class="indent">Analyzing network performance as a snapshot of long-term performance is useful, but a much better way to analyze data is with trends. If your system regularly has 1.5 percent packet loss in transmission, and in the last three days the rate has jumped up to 7.8 percent, a problem is brewing and needs to be analyzed in more detail.</p>&#13;
<p class="indent">As a result, this script is two parts. The first part, shown in <a href="ch10.xhtml#ch10ex10">Listing 10-10</a>, is a short script that is intended to run every 10 to 30 minutes, recording key statistics in a log file. The second script (<a href="ch10.xhtml#ch10ex11">Listing 10-11</a>) parses the log file, reporting typical performance and any anomalies or other values that are increasing over time.</p>&#13;
<div class="note">&#13;
<p class="notet"><span class="noteg"><strong>WARNING</strong></span></p>&#13;
<p class="notep"><em>Some flavors of Unix can’t run this code as is (though we’ve confirmed it’s working on OS X as is)! It turns out that there is quite a variation in the output format (many subtle whitespace changes or slight spelling) of the</em> <code><em>netstat</em></code> <em>command between Linux and Unix versions. Normalizing</em> <code><em>netstat</em></code> <em>output would be a nice script unto itself.</em></p>&#13;
</div>&#13;
<h4 class="h4" id="ch10lev2sec20"><em><strong>The Code</strong></em></h4>&#13;
<pre class="programs">   #!/bin/bash&#13;
   # getstats--Every 'n' minutes, grabs netstats values (via crontab)&#13;
&#13;
   logfile="/Users/taylor/.netstatlog"   # Change for your configuration.&#13;
   temp="/tmp/getstats.$$.tmp"&#13;
&#13;
   trap "$(which rm) -f $temp" 0&#13;
&#13;
   if [ ! -e $logfile ] ; then     # First time run?&#13;
     touch $logfile&#13;
   fi&#13;
   ( netstat -s -p tcp &gt; $temp&#13;
&#13;
   # Check your log file the first time this is run: some versions of netstat&#13;
   #   report more than one line, which is why the "| head -1" is used here.&#13;
<span class="ent">➊</span> sent="$(grep 'packets sent' $temp | cut -d\  -f1 | sed \&#13;
   's/[^[:digit:]]//g' | head -1)"&#13;
   resent="$(grep 'retransmitted' $temp | cut -d\  -f1 | sed \&#13;
   's/[^[:digit:]]//g')"&#13;
   received="$(grep 'packets received$' $temp | cut -d\  -f1 | \&#13;
     sed 's/[^[:digit:]]//g')"&#13;
   dupacks="$(grep 'duplicate acks' $temp | cut -d\  -f1 | \&#13;
     sed 's/[^[:digit:]]//g')"&#13;
   outoforder="$(grep 'out-of-order packets' $temp | cut -d\  -f1 | \&#13;
     sed 's/[^[:digit:]]//g')"&#13;
   connectreq="$(grep 'connection requests' $temp | cut -d\  -f1 | \&#13;
     sed 's/[^[:digit:]]//g')"&#13;
   connectacc="$(grep 'connection accepts' $temp | cut -d\  -f1 | \&#13;
     sed 's/[^[:digit:]]//g')"&#13;
   retmout="$(grep 'retransmit timeouts' $temp | cut -d\  -f1 | \&#13;
     sed 's/[^[:digit:]]//g')"&#13;
&#13;
   /bin/echo -n "time=$(date +%s);"&#13;
<span class="ent">➋</span> /bin/echo -n "snt=$sent;re=$resent;rec=$received;dup=$dupacks;"&#13;
   /bin/echo -n "oo=$outoforder;creq=$connectreq;cacc=$connectacc;"&#13;
   echo "reto=$retmout"&#13;
&#13;
   ) &gt;&gt; $logfile&#13;
&#13;
   exit 0</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_251"/><a id="ch10ex10"/><em>Listing 10-10: The</em> <code><em>getstats</em></code> <em>script</em></p>&#13;
<p class="indent">The second script, shown in <a href="ch10.xhtml#ch10ex11">Listing 10-11</a>, analyzes the <code>netstat</code> historical log file.</p>&#13;
<pre class="programs">   #!/bin/bash&#13;
   # netperf--Analyzes the netstat running performance log, identifying&#13;
   #   important results and trends&#13;
&#13;
   log="/Users/taylor/.netstatlog"     # Change for your configuration.&#13;
   stats="/tmp/netperf.stats.$$"&#13;
   awktmp="/tmp/netperf.awk.$$"&#13;
&#13;
   trap "$(which rm) -f $awktmp $stats" 0&#13;
&#13;
   if [ ! -r $log ] ; then&#13;
     echo "Error: can't read netstat log file $log" &gt;&amp;2&#13;
     exit 1&#13;
   fi&#13;
&#13;
   # First, report the basic statistics of the latest entry in the log file...&#13;
&#13;
   eval $(tail -1 $log)    # All values turn into shell variables.&#13;
&#13;
<span class="ent">➌</span> rep="$(scriptbc -p 3 $re/$snt\*100)"&#13;
   repn="$(scriptbc -p 4 $re/$snt\*10000 | cut -d. -f1)"&#13;
   repn="$(( $repn / 100 ))"&#13;
   retop="$(scriptbc -p 3 $reto/$snt\*100)";&#13;
   retopn="$(scriptbc -p 4 $reto/$snt\*10000 | cut -d. -f1)"&#13;
   retopn="$(( $retopn / 100 ))"&#13;
   dupp="$(scriptbc -p 3 $dup/$rec\*100)";&#13;
   duppn="$(scriptbc -p 4 $dup/$rec\*10000 | cut -d. -f1)"&#13;
   duppn="$(( $duppn / 100 ))"&#13;
   oop="$(scriptbc -p 3 $oo/$rec\*100)";&#13;
   oopn="$(scriptbc -p 4 $oo/$rec\*10000 | cut -d. -f1)"&#13;
   oopn="$(( $oopn / 100 ))"&#13;
&#13;
   echo "Netstat is currently reporting the following:"&#13;
&#13;
   /bin/echo -n "  $snt packets sent, with $re retransmits ($rep%) "&#13;
   echo "and $reto retransmit timeouts ($retop%)"&#13;
&#13;
<span epub:type="pagebreak" id="page_252"/>   /bin/echo -n "  $rec packets received, with $dup dupes ($dupp%)"&#13;
   echo " and $oo out of order ($oop%)"&#13;
   echo "   $creq total connection requests, of which $cacc were accepted"&#13;
   echo ""&#13;
&#13;
   ## Now let's see if there are any important problems to flag.&#13;
&#13;
   if [ $repn -ge 5 ] ; then&#13;
     echo "*** Warning: Retransmits of &gt;= 5% indicates a problem "&#13;
     echo "(gateway or router flooded?)"&#13;
   fi&#13;
   if [ $retopn -ge 5 ] ; then&#13;
     echo "*** Warning: Transmit timeouts of &gt;= 5% indicates a problem "&#13;
     echo "(gateway or router flooded?)"&#13;
   fi&#13;
   if [ $duppn -ge 5 ] ; then&#13;
     echo "*** Warning: Duplicate receives of &gt;= 5% indicates a problem "&#13;
     echo "(probably on the other end)"&#13;
   fi&#13;
   if [ $oopn -ge 5 ] ; then&#13;
     echo "*** Warning: Out of orders of &gt;= 5% indicates a problem "&#13;
     echo "(busy network or router/gateway flood)"&#13;
   fi&#13;
&#13;
   # Now let's look at some historical trends...&#13;
&#13;
   echo "Analyzing trends..."&#13;
&#13;
   while read logline ; do&#13;
       eval "$logline"&#13;
       rep2="$(scriptbc -p 4 $re / $snt \* 10000 | cut -d. -f1)"&#13;
       retop2="$(scriptbc -p 4 $reto / $snt \* 10000 | cut -d. -f1)"&#13;
       dupp2="$(scriptbc -p 4 $dup / $rec \* 10000 | cut -d. -f1)"&#13;
       oop2="$(scriptbc -p 4 $oo / $rec \* 10000 | cut -d. -f1)"&#13;
       echo "$rep2 $retop2 $dupp2 $oop2" &gt;&gt; $stats&#13;
     done &lt; $log&#13;
&#13;
   echo ""&#13;
&#13;
   # Now calculate some statistics and compare them to the current values.&#13;
&#13;
   cat &lt;&lt; "EOF" &gt; $awktmp&#13;
       { rep += $1; retop += $2; dupp += $3; oop += $4 }&#13;
   END { rep /= 100; retop /= 100; dupp /= 100; oop /= 100;&#13;
         print "reps="int(rep/NR) ";retops=" int(retop/NR) \&#13;
            ";dupps=" int(dupp/NR) ";oops="int(oop/NR) }&#13;
   EOF&#13;
&#13;
<span class="ent">➍</span> eval $(awk -f $awktmp &lt; $stats)&#13;
&#13;
   if [ $repn -gt $reps ] ; then&#13;
     echo "*** Warning: Retransmit rate is currently higher than average."&#13;
     echo "    (average is $reps% and current is $repn%)"&#13;
   fi&#13;
&#13;
   if [ $retopn -gt $retops ] ; then&#13;
     echo "*** Warning: Transmit timeouts are currently higher than average."&#13;
     echo "    (average is $retops% and current is $retopn%)"&#13;
   fi&#13;
   if [ $duppn -gt $dupps ] ; then&#13;
     echo "*** Warning: Duplicate receives are currently higher than average."&#13;
     echo "    (average is $dupps% and current is $duppn%)"&#13;
   fi&#13;
   if [ $oopn -gt $oops ] ; then&#13;
     echo "*** Warning: Out of orders are currently higher than average."&#13;
     echo "    (average is $oops% and current is $oopn%)"&#13;
   fi&#13;
   echo \(Analyzed $(wc -l &lt; $stats) netstat log entries for calculations\)&#13;
   exit 0</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_253"/><a id="ch10ex11"/><em>Listing 10-11: The</em> <code><em>netperf</em></code> <em>script, to be used with the</em> <code><em>getstats</em></code> <em>script</em></p>&#13;
<h4 class="h4" id="ch10lev2sec21"><em><strong>How It Works</strong></em></h4>&#13;
<p class="noindenta">The <code>netstat</code> program is tremendously useful, but its output can be intimidating. <a href="ch10.xhtml#ch10ex12">Listing 10-12</a> shows just the first 10 lines of output.</p>&#13;
<pre class="programs">$ <span class="codestrong">netstat -s -p tcp | head</span>&#13;
tcp:&#13;
    51848278 packets sent&#13;
        46007627 data packets (3984696233 bytes)&#13;
        16916 data packets (21095873 bytes) retransmitted&#13;
        0 resends initiated by MTU discovery&#13;
        5539099 ack-only packets (2343 delayed)&#13;
        0 URG only packets&#13;
        0 window probe packets&#13;
        210727 window update packets&#13;
        74107 control packets</pre>&#13;
<p class="listcap"><a id="ch10ex12"/><em>Listing 10-12: Running</em> <code><em>netstat</em></code> <em>to get TCP information</em></p>&#13;
<p class="indent">The first step is to extract just those entries that contain interesting and important network performance statistics. That’s the main job of <code>getstats</code>, and it does this by saving the output of the <code>netstat</code> command into the temp file <em>$temp</em> and going through <em>$temp</em> to calculate key values, such as total packets sent and received. The line at <span class="ent">➊</span>, for example, gets the number of packets sent.</p>&#13;
<p class="indent">The <code>sed</code> invocation removes any nondigit values to ensure that no tabs or spaces end up as part of the resulting value. Then all of the extracted values are written to the <em>netstat.log</em> log file in the format <code>var1Name=var1Value; var2Name=var2Value;</code> and so forth. This format will let us later use <code>eval</code> on each line in <em>netstat.log</em> and have all the variables instantiated in the shell:</p>&#13;
<div class="imagec"><img src="../images/f0253-01.jpg" alt="image"/></div>&#13;
<p class="indent">The <code>netperf</code> script does the heavy lifting, parsing <em>netstat.log</em> and reporting both the most recent performance numbers and any anomalies or other <span epub:type="pagebreak" id="page_254"/>values that are increasing over time. The <code>netperf</code> script calculates the current percentage of retransmits by dividing retransmits by packets sent and multiplying this result by 100. An integer-only version of the retransmission percentage is calculated by taking the result of dividing retransmissions by total packets sent, multiplying it by 10,000, and then dividing by 100 <span class="ent">➌</span>.</p>&#13;
<p class="indent">As you can see, the naming scheme for variables within the script begins with the abbreviations assigned to the various <code>netstat</code> values, which are stored in <em>netstat.log</em> at the end of the <code>getstats</code> script <span class="ent">➋</span>. The abbreviations are <code>snt</code>, <code>re</code>, <code>rec</code>, <code>dup</code>, <code>oo</code>, <code>creq</code>, <code>cacc</code>, and <code>reto</code>. In the <code>netperf</code> script, the <code>p</code> suffix is added to any of these abbreviations for variables that represent decimal percentages of total packets sent or received. The <code>pn</code> suffix is added to any of the abbreviations for variables that represent integer-only percentages of total packets sent or received. Later in the <code>netperf</code> script, the <code>ps</code> suffix denotes a variable that represents the percentage summaries (averages) used in the final calculations.</p>&#13;
<p class="indent">The <code>while</code> loop steps through each entry of <em>netstat.log</em>, calculating the four key percentile variables (<code>re</code>, <code>retr</code>, <code>dup</code>, and <code>oo</code>, which are retransmits, transmit timeouts, duplicates, and out of order, respectively). All are written to the <code>$stats</code> temp file, and then the <code>awk</code> script sums each column in <code>$stats</code> and calculates average column values by dividing the sums by the number of records in the file (<code>NR</code>).</p>&#13;
<p class="indent">The <code>eval</code> line at <span class="ent">➍</span> ties things together. The <code>awk</code> invocation is fed the set of summary statistics (<code>$stats</code>) produced by the <code>while</code> loop and utilizes the calculations saved in the <code>$awktmp</code> file to output <code>variable=value</code> sequences. These <code>variable=value</code> sequences are then incorporated into the shell with the <code>eval</code> statement, instantiating the variables <code>reps</code>, <code>retops</code>, <code>dupps</code>, and <code>oops</code>, which are average retransmit, average retransmit timeouts, average duplicate packets, and average out-of-order packets, respectively. The current percentile values can then be compared to these average values to spot problematic trends.</p>&#13;
<h4 class="h4" id="ch10lev2sec22"><em><strong>Running the Script</strong></em></h4>&#13;
<p class="noindenta">For the <code>netperf</code> script to work, it needs information in the <em>netstat.log</em> file. That information is generated by having a <code>crontab</code> entry that invokes <code>getstats</code> with some level of frequency. On a modern OS X, Unix, or Linux system, the following <code>crontab</code> entry will work fine, with the correct path to the script for your system of course:</p>&#13;
<pre class="programs">*/15 * * * *       /home/taylor/bin/getstats</pre>&#13;
<p class="indent">It will produce a log file entry every 15 minutes. To ensure the necessary file permissions, it’s best to actually create an empty log file by hand before running <code>getstats</code> for the first time.</p>&#13;
<pre class="programs">$ <span class="codestrong">sudo touch /Users/taylor/.netstatlog</span>&#13;
$ <span class="codestrong">sudo chmod a+rw /Users/taylor/.netstatlog</span></pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_255"/>Now the <code>getstats</code> program should chug along happily, building a historical picture of the network performance of your system. To analyze the contents of the log file, run <code>netperf</code> without any arguments.</p>&#13;
<h4 class="h4" id="ch10lev2sec23"><em><strong>The Results</strong></em></h4>&#13;
<p class="noindenta">First off, let’s check on the <em>.netstatlog</em> file, shown in <a href="ch10.xhtml#ch10ex13">Listing 10-13</a>.</p>&#13;
<div class="imagec"><img src="../images/f0255-01.jpg" alt="image"/></div>&#13;
<p class="listcap"><a id="ch10ex13"/><em>Listing 10-13: The last three lines of the</em> .netstatlog <em>that results from a</em> <code><em>crontab</em></code> <em>entry running the</em> <code><em>getstats</em></code> <em>script on a regular interval</em></p>&#13;
<p class="indent">It looks good. <a href="ch10.xhtml#ch10ex14">Listing 10-14</a> shows the results of running <code>netperf</code> and what it has to report.</p>&#13;
<pre class="programs">$ <span class="codestrong">netperf</span>&#13;
Netstat is currently reporting the following:&#13;
  52170128 packets sent, with 16927 retransmits (0%) and 2722 retransmit timeouts (0%)&#13;
  20290926 packets received, with 129910 dupes (.600%) and 18064 out of order (0%)&#13;
   39841 total connection requests, of which 123 were accepted&#13;
&#13;
Analyzing trends...&#13;
&#13;
(Analyzed 6 netstat log entries for calculations)</pre>&#13;
<p class="listcap"><a id="ch10ex14"/><em>Listing 10-14: Running the</em> <code><em>netperf</em></code> <em>script to analyze the</em> .netstatlog <em>file</em></p>&#13;
<h4 class="h4" id="ch10lev2sec24"><em><strong>Hacking the Script</strong></em></h4>&#13;
<p class="noindenta">You’ve likely already noticed that rather than using a human-readable date format, the <code>getstats</code> script saves entries in the <em>.netstatlog</em> file using epoch time, which represents the number of seconds that have elapsed since January 1, 1970. For example, 1,063,983,000 seconds represents a day in late September 2003. The use of epoch time will make it easier to enhance this script by enabling it to calculate the time elapsed between readings.</p>&#13;
<h3 class="h3" id="ch10lev1sec06"><strong>#78 Renicing Tasks by Process Name</strong></h3>&#13;
<p class="noindenta">There are many times when it’s useful to change the priority of a task, whether a chat server is supposed to use only “spare” cycles, an MP3 player app is not that important, a file download has become less important, or a real-time CPU monitor needs an increase in priority. You can change a process’s priority with the <code>renice</code> command; however, it requires you to specify the process ID, which can be a hassle. A much more useful approach is to have a script like the one in <a href="ch10.xhtml#ch10ex15">Listing 10-15</a> that matches process name to process ID and automatically renices the specified application.</p>&#13;
<h4 class="h4" id="ch10lev2sec25"><span epub:type="pagebreak" id="page_256"/><em><strong>The Code</strong></em></h4>&#13;
<pre class="programs">#!/bin/bash&#13;
# renicename--Renices the job that matches the specified name&#13;
&#13;
user=""; tty=""; showpid=0; niceval="+1"        # Initialize&#13;
&#13;
while getopts "n:u:t:p" opt; do&#13;
  case $opt in&#13;
   n ) niceval="$OPTARG";               ;;&#13;
   u ) if [ ! -z "$tty" ] ; then&#13;
         echo "$0: error: -u and -t are mutually exclusive." &gt;&amp;2&#13;
         exit 1&#13;
       fi&#13;
       user=$OPTARG                     ;;&#13;
   t ) if [ ! -z "$user" ] ; then&#13;
         echo "$0: error: -u and -t are mutually exclusive." &gt;&amp;2&#13;
         exit 1&#13;
       fi&#13;
       tty=$OPTARG                      ;;&#13;
   p ) showpid=1;                       ;;&#13;
   ? ) echo "Usage: $0 [-n niceval] [-u user|-t tty] [-p] pattern" &gt;&amp;2&#13;
       echo "Default niceval change is \"$niceval\" (plus is lower" &gt;&amp;2&#13;
       echo "priority, minus is higher, but only root can go below 0)" &gt;&amp;2&#13;
       exit 1&#13;
  esac&#13;
done&#13;
shift $(($OPTIND - 1))  # Eat all the parsed arguments.&#13;
&#13;
if [ $# -eq 0 ] ; then&#13;
  echo "Usage: $0 [-n niceval] [-u user|-t tty] [-p] pattern" &gt;&amp;2&#13;
  exit 1&#13;
fi&#13;
&#13;
if [ ! -z "$tty" ] ; then&#13;
  pid=$(ps cu -t $tty | awk "/ $1/ { print \\$2 }")&#13;
elif [ ! -z "$user" ] ; then&#13;
  pid=$(ps cu -U $user | awk "/ $1/ { print \\$2 }")&#13;
else&#13;
  pid=$(ps cu -U ${USER:-LOGNAME} | awk "/ $1/ { print \$2 }")&#13;
fi&#13;
&#13;
if [ -z "$pid" ] ; then&#13;
  echo "$0: no processes match pattern $1" &gt;&amp;2&#13;
  exit 1&#13;
elif [ ! -z "$(echo $pid | grep ' ')" ] ; then&#13;
  echo "$0: more than one process matches pattern ${1}:"&#13;
  if [ ! -z "$tty" ] ; then&#13;
    runme="ps cu -t $tty"&#13;
  elif [ ! -z "$user" ] ; then&#13;
    runme="ps cu -U $user"&#13;
  else&#13;
    runme="ps cu -U ${USER:-LOGNAME}"&#13;
  fi&#13;
  eval $runme | \&#13;
      awk "/ $1/ { printf \"  user %-8.8s pid %-6.6s job %s\n\", \&#13;
      \$1,\$2,\$11 }"&#13;
  echo "Use -u user or -t tty to narrow down your selection criteria."&#13;
elif [ $showpid -eq 1 ] ; then&#13;
  echo $pid&#13;
else&#13;
  # Ready to go. Let's do it!&#13;
  /bin/echo -n "Renicing job \""&#13;
  /bin/echo -n $(ps cp $pid | sed 's/ [ ]*/ /g' | tail -1 |  cut -d\  -f6-)&#13;
  echo "\" ($pid)"&#13;
  renice $niceval $pid&#13;
fi&#13;
&#13;
exit 0</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_257"/><a id="ch10ex15"/><em>Listing 10-15: The</em> <code><em>renicename</em></code> <em>script</em></p>&#13;
<h4 class="h4" id="ch10lev2sec26"><em><strong>How It Works</strong></em></h4>&#13;
<p class="noindenta">This script borrows liberally from <a href="ch06.xhtml#ch06lev1sec03">Script #47</a> on <a href="ch06.xhtml#page_150">page 150</a>, which does a similar mapping of process name to process ID—but that script kills the jobs rather than just lowering their priority.</p>&#13;
<p class="indent">In this situation, you don’t want to accidentally renice a number of matching processes (imagine <code>renicename -n 10 "*"</code>, for example), so the script fails if more than one process matches. Otherwise, it makes the change specified and lets the actual <code>renice</code> program report any errors that may have been encountered.</p>&#13;
<h4 class="h4" id="ch10lev2sec27"><em><strong>Running the Script</strong></em></h4>&#13;
<p class="noindenta">You have a number of possible options when running this script: <code>-n val</code> allows you to specify the desired <code>nice</code> (job priority) value. The default is specified as <code>niceval=1</code>. The <code>-u user</code> flag allows matching processes to be limited by user, while <code>-t tty</code> allows a similar filter by terminal name. To see just the matching process ID and not actually renice the application, use the <code>-p</code> flag. In addition to one or more flags, <code>renicename</code> requires a command pattern, which will be compared to the running process names on the system to ascertain which of the processes match.</p>&#13;
<h4 class="h4" id="ch10lev2sec28"><em><strong>The Results</strong></em></h4>&#13;
<p class="noindenta">First off, <a href="ch10.xhtml#ch10ex16">Listing 10-16</a> shows what happens when there is more than one matching process.</p>&#13;
<pre class="programs">$ <span class="codestrong">renicename "vi"</span>&#13;
renicename: more than one process matches pattern vi:&#13;
  user taylor    pid 6584    job vi&#13;
  user taylor    pid 10949   job vi&#13;
Use -u user or -t tty to narrow down your selection criteria.</pre>&#13;
<p class="listcap"><a id="ch10ex16"/><em>Listing 10-16: Running the</em> <code><em>renicename</em></code> <em>script with a process name with multiple process IDs</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_258"/>We subsequently quit one of these processes and ran the same command.</p>&#13;
<pre class="programs">$ <span class="codestrong">renicename "vi"</span>&#13;
Renicing job "vi" (6584)</pre>&#13;
<p class="indent">We can confirm that this worked and our <code>vi</code> process was prioritized by using the <code>-l</code> flag to <code>ps</code> with the process ID specified, shown in <a href="ch10.xhtml#ch10ex17">Listing 10-17</a>.</p>&#13;
<pre class="programs">$ <span class="codestrong">ps –l 6584</span>&#13;
UID   PID  PPID     F CPU PRI NI        SZ   RSS WCHAN    S   ADDR TTY                 TIME CMD&#13;
501  6584  1193  4006   0  30  1<span class="ent">➊</span>  2453832  1732     -  SN+  0 ttys000  0:00.01 vi wasting.time</pre>&#13;
<p class="listcap"><a id="ch10ex17"/><em>Listing 10-17: Confirming the process has been niced appropriately</em></p>&#13;
<p class="indent">It’s hard to read this super-wide output format from the <code>ps</code> command, but notice that field 7 is <code>NI</code> and that for this process its value is 1 <span class="ent">➊</span>. Check any other process you’re running, and you’ll see they’re all priority 0, the standard user priority level.</p>&#13;
<h4 class="h4" id="ch10lev2sec29"><em><strong>Hacking the Script</strong></em></h4>&#13;
<p class="noindenta">An interesting addendum to this script would be another script that watches for any time-critical programs that are launched and automatically renices them to a set priority. This could be helpful if certain internet services or applications tend to consume a lot of CPU resources, for example. <a href="ch10.xhtml#ch10ex18">Listing 10-18</a> uses <code>renicename</code> to map process name to process ID and then checks the process’s current nice level. It issues a <code>renice</code> if the nice level specified as a command argument is higher (a lesser priority) than the current level.</p>&#13;
<pre class="programs">#!/bin/bash&#13;
# watch_and_nice--Watches for the specified process name and renices it&#13;
#   to the desired value when seen.&#13;
&#13;
if [ $# -ne 2 ] ; then&#13;
  echo "Usage: $(basename $0) desirednice jobname" &gt;&amp;2&#13;
  exit 1&#13;
fi&#13;
&#13;
pid="$(renicename -p "$2")"&#13;
&#13;
if [ "$pid" == "" ] ; then&#13;
  echo "No process found for $2"&#13;
  exit 1&#13;
fi&#13;
&#13;
if [ ! -z "$(echo $pid | sed 's/[0-9]*//g')" ] ; then&#13;
  echo "Failed to make a unique match in the process table for $2" &gt;&amp;2&#13;
  exit 1&#13;
fi&#13;
&#13;
currentnice="$(ps -lp $pid | tail -1 | awk '{print $6}')"&#13;
&#13;
if [ $1 -gt $currentnice ] ; then&#13;
  echo "Adjusting priority of $2 to $1"&#13;
  renice $1 $pid&#13;
fi&#13;
&#13;
exit 0</pre>&#13;
<p class="listcap"><span epub:type="pagebreak" id="page_259"/><a id="ch10ex18"/><em>Listing 10-18: The</em> <code><em>watch_and_nice</em></code> <em>script</em></p>&#13;
<p class="indent">Within a <code>cron</code> job, this script could be used to ensure that certain apps are pushed to the desired priority within a few minutes of being launched.<span epub:type="pagebreak" id="page_260"/></p>&#13;
</body></html>