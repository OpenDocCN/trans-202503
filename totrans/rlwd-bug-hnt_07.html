<html><head></head><body>
<h2 class="h2" id="ch07"><span epub:type="pagebreak" id="page_55"/><strong><span class="big">7</span><br/>CROSS-SITE SCRIPTING</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">One of the most famous examples of a <em>cross-site scripting (XSS)</em> vulnerability is the Myspace Samy Worm created by Samy Kamkar. In October 2005, Kamkar exploited a vulnerability on Myspace that allowed him to store a JavaScript payload on his profile. Whenever a logged-in user would visit his Myspace profile, the payload code would execute, making the viewer Kamkar’s friend on Myspace and updating the viewer’s profile to display the text “but most of all, samy is my hero.” Then the code would copy itself to the viewer’s profile and continue infecting other Myspace user pages.</p>&#13;
<p class="indent">Although Kamkar didn’t create the worm with malicious intent, the government raided Kamkar’s residence as a result. Kamkar was arrested for releasing the worm and pleaded guilty to a felony charge.</p>&#13;
<p class="indent">Kamkar’s worm is an extreme example, but his exploit shows the broad impact an XSS vulnerability could have on a website. Similar to other vulnerabilities I’ve covered so far, XSS occurs when websites render <span epub:type="pagebreak" id="page_56"/>certain characters unsanitized, causing browsers to execute malicious JavaScript. Characters that allow an XSS vulnerability to occur include double quotes (<code>"</code>), single quotes (<code>'</code>), and angle brackets (<code>&lt; &gt;</code>).</p>&#13;
<p class="indent">If a site properly sanitizes characters, the characters render as HTML entities. For example, the page source for a web page would show these characters as follows:</p>&#13;
<ul>&#13;
<li class="noindent">A double quote (<code>"</code>) as <code>&amp;quot;</code> or <code>&amp;#34;</code></li>&#13;
<li class="noindent">A single quote (<code>'</code>) as <code>&amp;apos;</code> or <code>&amp;#39;</code></li>&#13;
<li class="noindent">An opening angle bracket (<code>&lt;</code>) as <code>&amp;lt;</code> or <code>&amp;#60;</code></li>&#13;
<li class="noindent">A closing angle bracket (<code>&gt;</code>) as <code>&amp;gt;</code> or <code>&amp;#62;</code></li>&#13;
</ul>&#13;
<p class="indent">These special characters, when unsanitized, define a web page’s structure in HTML and JavaScript. For example, if a site doesn’t sanitize angle brackets, you could insert <code>&lt;script&gt;&lt;/script&gt;</code> to inject a payload, like this:</p>&#13;
<pre>&lt;script&gt;alert(document.domain);&lt;/script&gt;</pre>&#13;
<p class="indent">When you submit this payload to a website that renders it unsanitized, the <code>&lt;script&gt;&lt;/script&gt;</code> tags instruct the browser to execute the JavaScript between them. The payload executes the <code>alert</code> function, creating a pop-up dialog that displays the information passed to <code>alert</code>. The reference to <code>document</code> inside the parentheses is the DOM, which returns the domain name of the site. For example, if the payload executes on <em>https://www.&lt;example&gt;.com/foo/bar/</em>, the pop-up dialog displays <em>www.&lt;example&gt;.com</em>.</p>&#13;
<p class="indent">When you’ve found an XSS vulnerability, confirm its impact because not all XSS vulnerabilities are the same. Confirming the impact of a bug and including this analysis improves your report, helps triagers validate your bug, and might raise your bounty.</p>&#13;
<p class="indent">For example, an XSS vulnerability on a site that doesn’t use the <code>httponly</code> flag on sensitive cookies is different from an XSS vulnerability that does. When a site has no <code>httponly</code> flag, your XSS can read cookie values; if those values include session-identifying cookies, you could steal a target’s session and access their account. You can alert <code>document.cookie</code> to confirm that you can read sensitive cookies (knowing which cookies a site considers sensitive requires trial and error on each site). Even when you can’t access sensitive cookies, you can alert <code>document.domain</code> to confirm whether you can access sensitive user information from the DOM and perform actions on behalf of the target.</p>&#13;
<p class="indent">But the XSS might not be a vulnerability for the site if you don’t alert the correct domain. For example, if you alert <code>document.domain</code> from a sandboxed iFrame, your JavaScript could be harmless because it can’t access cookies, perform actions on the user’s account, or access sensitive user information from the DOM.</p>&#13;
<p class="indent">The JavaScript is rendered harmless because browsers implement a <em>Same Origin Policy (SOP)</em> as a security mechanism. The SOP restricts how documents (the D in DOM) can interact with resources loaded from <span epub:type="pagebreak" id="page_57"/>another origin. The SOP protects innocent websites from malicious sites attempting to exploit the website through the user. For example, if you visited <em>www.&lt;malicious&gt;.com</em> and it invoked a <code>GET</code> request to <em>www.&lt;example&gt;.com/profile</em> in your browser, the SOP would prevent <em>www.&lt;malicious&gt;.com</em> from reading the <em>www.&lt;example&gt;.com/profile</em> response. The <em>www.&lt;example&gt;.com</em> site might allow sites from a different origin to interact with it, but usually those interactions are limited to specific websites <em>www.&lt;example&gt;.com</em> trusts.</p>&#13;
<p class="indent">A website’s protocol (e.g., HTTP or HTTPS), host (e.g., <em>www.&lt;example&gt;.com</em>), and port determine a site’s origin. Internet Explorer is an exception to this rule. It doesn’t consider the port to be part of the origin. <a href="ch07.xhtml#ch07tab01">Table 7-1</a> shows examples of origins and whether they would be considered the same as <em>http://www.&lt;example&gt;.com/</em>.</p>&#13;
<p class="tabcap"><a id="ch07tab01"/><strong>Table 7-1:</strong> Examples of SOP</p>&#13;
<table class="topbot-d">&#13;
<colgroup>&#13;
<col style="width:60%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:20%"/>&#13;
</colgroup>&#13;
<tbody>&#13;
<tr>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>URL</strong></p></td>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Same origin?</strong></p></td>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Reason</strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b1" style="vertical-align: top;"><p class="taba"><em>http://www.&lt;example&gt;.com/countries</em></p></td>&#13;
<td class="table-b1" style="vertical-align: top;"><p class="taba">Yes</p></td>&#13;
<td class="table-b1" style="vertical-align: top;"><p class="taba">N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba"><em>http://www.&lt;example&gt;.com/countries/Canada</em></p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">Yes</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">N/A</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b1" style="vertical-align: top;"><p class="taba"><em>https://www.&lt;example&gt;.com/countries</em></p></td>&#13;
<td class="table-b1" style="vertical-align: top;"><p class="taba">No</p></td>&#13;
<td class="table-b1" style="vertical-align: top;"><p class="taba">Different protocol</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba"><em>http://store.&lt;example&gt;.com/countries</em></p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">No</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">Different host</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba"><em>http://www.&lt;example&gt;.com:8080/countries</em></p></td>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba">No</p></td>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba">Different port</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">In some situations, the URL won’t match the origin. For example, <code>about:blank</code> and <code>javascript:</code> schemes inherit the origin of the document opening them. The <code>about:blank</code> context accesses information from or interacts with the browser, whereas <code>javascript:</code> executes JavaScript. The URL doesn’t provide information about its origin, so browsers handle these two contexts differently. When you find an XSS vulnerability, using <code>alert(document.domain)</code> in your proof of concept is helpful: it confirms the origin where the XSS executes, especially when the URL shown in the browser is different from the origin the XSS executes against. This is exactly what happens when a website opens a <code>javascript:</code> URL. If <em>www.&lt;example&gt;.com</em> opened a <code>javascript:alert(document.domain)</code> URL, the browser address would show <code>javascript:alert(document.domain)</code>. But the alert box would show <em>www.&lt;example&gt;.com</em> because the alert inherits the origin of the previous document.</p>&#13;
<p class="indent">Although I’ve only covered an example that uses the HTML <code>&lt;script&gt;</code> tag to achieve XSS, you can’t always submit HTML tags when you find a potential injection. In those cases, you might be able to submit single or double quotes to inject an XSS payload. The XSS could be significant depending on where your injection occurs. For example, let’s say you can access the following code’s <code>value</code> attribute:</p>&#13;
<pre>&lt;input type="text" name="username" value="hacker" width=50px&gt;</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_58"/>By injecting a double quote in the <code>value</code> attribute, you could close the existing quote and inject a malicious XSS payload into the tag. You might do this by changing the <code>value</code> attribute to <code>hacker" onfocus=alert(document.cookie) autofocus "</code>, which would result in the following:</p>&#13;
<pre>&lt;input type="text" name="username" value="hacker"<br/>&#13;
 onfocus=alert(document.cookie) autofocus "" width=50px&gt;</pre>&#13;
<p class="indent">The <code>autofocus</code> attribute instructs the browser to place the cursor focus on the input text box as soon as the page loads. The <code>onfocus</code> JavaScript attribute tells the browser to execute JavaScript when the input text box is the focus (without <code>autofocus</code>, the <code>onfocus</code> would occur when a person clicks the text box). But these two attributes have limits: you can’t autofocus on a hidden field. Also, if multiple fields are on a page with autofocus, either the first or last element will be the focus depending on the browser. When the payload runs, it would alert on <code>document.cookie</code>.</p>&#13;
<p class="indent">Similarly, let’s say you had access to a variable within a <code>&lt;script&gt;</code> tag. If you could inject single quotes into the value for the <code>name</code> variable in the following code, you could close the variable and execute your own JavaScript:</p>&#13;
<pre>&lt;script&gt;<br/>&#13;
    var name = 'hacker';<br/>&#13;
&lt;/script&gt;</pre>&#13;
<p class="indent">Because we control the value <code>hacker</code>, changing the <code>name</code> variable to <code>hacker';alert(document.cookie);'</code> would result in the following:</p>&#13;
<pre>&lt;script&gt;<br/>&#13;
    var name = 'hacker';alert(document.cookie);'';<br/>&#13;
&lt;/script&gt;</pre>&#13;
<p class="indent">Injecting a single quote and semicolon closes the variable <code>name</code>. Because we’re using a <code>&lt;script&gt;</code> tag, the JavaScript function <code>alert(document.cookie)</code>, which we also injected, will execute. We add an additional <code>;'</code> to end our function call and ensure the JavaScript is syntactically correct because the site includes a <code>';</code> to close the <code>name</code> variable. Without the <code>';</code> syntax at the end, there would be a dangling single quote, which could break the page syntax.</p>&#13;
<p class="indent">As you now know, you can execute XSS using several methods. The website <em><a href="http://html5sec.org/">http://html5sec.org/</a></em>, which the penetration testing experts at Cure53 maintain, is a great reference for XSS payloads.</p>&#13;
<h3 class="h3" id="ch07lev1sec1"><strong>Types of XSS</strong></h3>&#13;
<p class="noindent">There are two main types of XSS: reflected and stored. <em>Reflected XSS</em> occurs when a single HTTP request that isn’t stored anywhere on the site delivers and executes the XSS payload. Browsers, including Chrome, Internet Explorer, and Safari, try to prevent this type of vulnerability by introducing <em>XSS Auditors</em> (in July 2018, Microsoft announced they are retiring the XSS <span epub:type="pagebreak" id="page_59"/>Auditor in the Edge browser due to other security mechanisms available to prevent XSS). XSS Auditors attempt to protect users from malicious links that execute JavaScript. When an XSS attempt occurs, the browser shows a broken page with a message stating the page has been blocked to protect users. <a href="ch07.xhtml#ch07fig01">Figure 7-1</a> shows an example in Google Chrome.</p>&#13;
<div class="image"><a id="ch07fig01"/><img alt="image" src="../images/07fig01.jpg"/></div>&#13;
<p class="figcap"><em>Figure 7-1: A page blocked by the XSS Auditor in Google Chrome</em></p>&#13;
<p class="indent">Despite browser developers’ best efforts, attackers frequently bypass XSS Auditors because JavaScript can execute in complex ways on a site. Because these methods of bypassing XSS Auditors often change, they’re beyond the scope of this book. But two great resources to learn more are FileDescriptor’s blog post at <em><a href="https://blog.innerht.ml/the-misunderstood-x-xss-protection/">https://blog.innerht.ml/the-misunderstood-x-xss-protection/</a></em> and Masato Kinugawa’s filter bypass cheat sheet at <em>https://github.com/masatokinugawa/filterbypass/wiki/Browser’s-XSS-Filter-Bypass-Cheat-Sheet/</em>.</p>&#13;
<p class="indent">In contrast, <em>stored XSS</em> occurs when a site saves a malicious payload and renders it unsanitized. Sites might also render the inputted payload in various locations. The payload might not execute immediately after submission, but it could execute when another page is accessed. For example, if you create a profile on a website with an XSS payload as your name, the XSS might not execute when you view your profile; instead, it might execute when someone searches for your name or sends you a message.</p>&#13;
<p class="indent">You can also sort XSS attacks into the following three subcategories: DOM-based, blind, and self. <em>DOM-based XSS</em> attacks involve manipulating a website’s existing JavaScript code to execute malicious JavaScript; it can be either stored or reflected. For example, let’s say the web page <em>www.&lt;example&gt;.com/hi/</em> used the following HTML to replace its page contents with a value from a URL without checking for malicious input. It might be possible to execute XSS.</p>&#13;
<pre>&lt;html&gt;<br/>&#13;
  &lt;body&gt;<br/>&#13;
    &lt;h1&gt;Hi &lt;span id="name"&gt;&lt;/span&gt;&lt;/h1&gt;<br/>&#13;
    &lt;script&gt;document.getElementById('name').innerHTML=location.hash.split('#')<br/>&#13;
      [1]&lt;/script&gt;<br/>&#13;
  &lt;/body&gt;<br/>&#13;
&lt;/html&gt;</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_60"/>In this example web page, the script tag calls the document object’s <code>getElementById</code> method to find the HTML element with the ID <code>'name'</code>. The call returns a reference to the span element in the <code>&lt;h1&gt;</code> tag. Next, the script tag modifies the text between the <code>&lt;span id="name"&gt;&lt;/span&gt;</code> tags using the <code>innerHTML</code> method. The script sets the text between <code>&lt;span&gt;&lt;/span&gt;</code> to the value from the <code>location.hash</code>, which is any text that occurs after a <code>#</code> in the URL (<code>location</code> is another browser API, similar to the DOM; it provides access to information about the current URL).</p>&#13;
<p class="indent">Thus, visiting <em>www.&lt;example&gt;.com/hi#Peter/</em> would result in the page’s HTML dynamically being updated to <code>&lt;h1&gt;&lt;span id="name"&gt;Peter&lt;/span&gt;&lt;/h1&gt;</code>. But this page doesn’t sanitize the <code>#</code> value in the URL before updating the <code>&lt;span&gt;</code> element. So if a user visited <em>www.&lt;example&gt;.com/h1#&lt;img src=x onerror=alert(document.domain)&gt;</em>, a JavaScript alert box would pop up and display <em>www.&lt;example&gt;.com</em> (assuming no image <code>x</code> was returned to the browser). The resulting HTML from the page would look like this:</p>&#13;
<pre>&lt;html&gt;<br/>&#13;
  &lt;body&gt;<br/>&#13;
    &lt;h1&gt;Hi &lt;span id="name"&gt;&lt;img src=x onerror=alert(document.domain)&gt;&lt;/span&gt;<br/>&#13;
      &lt;/h1&gt;<br/>&#13;
    &lt;script&gt;document.getElementById('name').innerHTML=location.hash.split('#')<br/>&#13;
      [1]&lt;/script&gt;<br/>&#13;
  &lt;/body&gt;<br/>&#13;
&lt;/html&gt;</pre>&#13;
<p class="indent">This time, instead of rendering Peter between <code>&lt;h1&gt;</code> tags, the webpage would display a JavaScript alert box with the <code>document.domain</code> name. An attacker could use this because, to execute any JavaScript, they provide the JavaScript attribute of the <code>&lt;img&gt;</code> tag to the <code>onerror</code>.</p>&#13;
<p class="indent"><em>Blind XSS</em> is a stored XSS attack in which another user renders the XSS payload from a location of the website a hacker can’t access. For example, this might happen if you could add XSS as your first and last name when you create a personal profile on a site. Those values can be escaped when regular users view your profile. But when an administrator visits an administrative page listing all new users on the site, the values might not be sanitized and the XSS might execute. The tool XSSHunter (<em><a href="https://xsshunter.com/">https://xsshunter.com/</a></em>) by Matthew Bryant is ideal for detecting blind XSS. The payloads Bryant designed execute JavaScript, which loads a remote script. When the script executes, it reads the DOM, browser information, cookies, and other information the payload sends back to your XSSHunter account.</p>&#13;
<p class="indent"><em>Self XSS</em> vulnerabilities are those that can impact only the user entering the payload. Because an attacker can attack only themselves, self XSS is considered low severity and doesn’t qualify for a reward in most bug bounty programs. For example, it can occur when the XSS is submitted via a <code>POST</code> request. But because the request is protected by CSRF, only the target can submit the XSS payload. Self XSS may or may not be stored.</p>&#13;
<p class="indent">If you find a self XSS, look for opportunities to combine it with another vulnerability that can affect other users, such as <em>login/logout CSRF</em>. In this type of attack, a target is logged out of their account and logged into the attacker’s <span epub:type="pagebreak" id="page_61"/>account to execute the malicious JavaScript. Typically, a login/logout CSRF attack requires the ability to log the target back into an account using malicious JavaScript. We won’t look at a bug that uses login/logout CSRF, but a great example is one that Jack Whitton found on an Uber site, which you can read about at <em>https://whitton.io/articles/uber-turning-self-xss-into-good-xss/</em>.</p>&#13;
<p class="indent">XSS’s impact depends on a variety of factors: whether it’s stored or reflected, whether cookies are accessible, where the payload executes, and so on. Despite the potential damage XSS can cause on a site, fixing XSS vulnerabilities is often easy, requiring only that software developers sanitize user input (just as with HTML injection) before rendering it.</p>&#13;
<h3 class="h3" id="ch07lev1sec2"><strong>Shopify Wholesale</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Low</p>&#13;
<p class="hang"><strong>URL:</strong> <em><a href="http://wholesale.shopify.com/">wholesale.shopify.com/</a></em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/106293/">https://hackerone.com/reports/106293/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> December 21, 2015</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $500</p>&#13;
<p class="noindent">XSS payloads don’t have to be complicated, but you do need to tailor them to the location where they’ll be rendered and whether they’ll be contained in HTML or JavaScript tags. In December 2015, Shopify’s wholesale website was a simple web page with a distinct search box at the top. The XSS vulnerability on this page was simple but easily missed: text input into the search box was being reflected unsanitized within existing JavaScript tags.</p>&#13;
<p class="indent">People overlooked this bug because the XSS payload wasn’t exploiting unsanitized HTML. When XSS exploits how HTML is rendered, attackers can see the effect of the payload because HTML defines the look and feel of a site. In contrast, JavaScript code can <em>change</em> the look and feel of a site or perform another action, but it doesn’t <em>define</em> the site’s look and feel.</p>&#13;
<p class="indent">In this case, entering <code>"&gt;&lt;script&gt;alert('XSS')&lt;/script&gt;</code> wouldn’t execute the XSS payload <code>alert('XSS')</code> because Shopify was encoding the HTML tags <code>&lt;&gt;</code>. These characters would have been rendered harmlessly as <code>&amp;lt;</code> and <code>&amp;gt;</code>. A hacker realized the input was being rendered unsanitized within <code>&lt;script&gt;&lt;/script&gt;</code> tags on the web page. Most likely, the hacker reached this conclusion by viewing the page’s source, which contains the HTML and JavaScript for the page. You can view the source for any web page by entering <em>view-source:URL</em> in a browser address bar. As an example, <a href="ch07.xhtml#ch07fig02">Figure 7-2</a> shows part of the <em><a href="https://nostarch.com/">https://nostarch.com/</a></em> site’s page source.</p>&#13;
<p class="indent">After realizing the input was rendered unsanitized, the hacker entered <code>test';alert('XSS');'</code> into Shopify’s search box, creating a JavaScript alert box with the text <code>'XSS'</code> in it when rendered. Although it’s unclear in the report, it’s likely that Shopify was rendering the searched term in a JavaScript statement, like <code>var search_term = '</code><span class="codeitalic">&lt;INJECTION&gt;</span><code>'</code>. The first part of the injection, <code>test';</code>, would have closed that tag and inserted the <code>alert('XSS');</code> as a separate statement. The final <code>'</code> would have ensured the JavaScript syntax was correct. The result would presumably have looked like <code>var search_term = 'test';alert('xss'); '';</code>.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_62"/><a id="ch07fig02"/><img alt="image" src="../images/07fig02.jpg"/></div>&#13;
<p class="figcap"><em>Figure 7-2: The page source for</em> <a href="https://nostarch.com/">https://nostarch.com/</a></p>&#13;
<h4 class="h4" id="ch07lev2sec1"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">XSS vulnerabilities don’t have to be intricate. The Shopify vulnerability wasn’t complex: it was just a simple input text field that didn’t sanitize user input. When you’re testing for XSS, be sure to view the page source and confirm whether your payloads are being rendered in HTML or JavaScript tags.</p>&#13;
<h3 class="h3" id="ch07lev1sec3"><strong>Shopify Currency Formatting</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Low</p>&#13;
<p class="hang"><strong>URL:</strong> <em>&lt;YOURSITE&gt;.myshopify.com/admin/settings/general/</em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://hackerone.com/reports/104359/">https://hackerone.com/reports/104359/</a></em></p>&#13;
<p class="hang"><strong>Report date:</strong> December 9, 2015</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $1,000</p>&#13;
<p class="noindent">XSS payloads don’t always execute immediately. Because of this, hackers should make sure the payload is properly sanitized in all the places it might be rendered. In this example, Shopify’s store settings allowed users to change currency formatting. In December 2015, the values from those input boxes weren’t properly sanitized when setting up social media pages. A malicious user could set up a store and inject an XSS payload in a store’s currency settings field, as shown in <a href="ch07.xhtml#ch07fig03">Figure 7-3</a>. The payload was rendered in the store’s social media sales channel. The malicious user could configure the store to execute the payload when another store administrator visited the sales channel.</p>&#13;
<p class="indent">Shopify uses the Liquid template engine to dynamically render content on shop pages. For example, <code>${{ }}</code> is the syntax for Liquid; the variable to be rendered is entered inside the inner set of braces. In <a href="ch07.xhtml#ch07fig03">Figure 7-3</a>, <code>${{amount}}</code> is a legitimate value but is appended with the value <code>"&gt;&lt;img src=x onerror=alert(document.domain)&gt;</code>, which is the XSS payload. The <code>"&gt;</code> closes the HTML tag that the payload is being injected into. When the HTML tag is closed, the browser renders the image tag and looks for an image <code>x</code> indicated in the <code>src</code> attribute. Because an image with this value is unlikely to exist on Shopify’s website, the browser encounters an error and calls the JavaScript event handler <code>onerror</code>. The event handler executes the JavaScript defined in the handler. In this case, it’s the function <code>alert(document.domain)</code>.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_63"/><a id="ch07fig03"/><img alt="image" src="../images/07fig03.jpg"/></div>&#13;
<p class="figcap"><em>Figure 7-3: Shopify’s currency settings page at the time of the report</em></p>&#13;
<p class="indent">While the JavaScript wouldn’t execute when a user visited the currency page, the payload also appeared in the Shopify store’s social media sales channel. When other store administrators clicked the vulnerable sales channel tab, the malicious XSS would be rendered unsanitized and execute the JavaScript.</p>&#13;
<h4 class="h4" id="ch07lev2sec2"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">XSS payloads don’t always execute immediately after they’re submitted. Because a payload could be used in multiple locations on a site, be sure to visit each location. In this case, simply submitting the malicious payload on the currency page didn’t execute the XSS. The bug reporter had to configure another website feature to cause the XSS to execute.</p>&#13;
<h3 class="h3" id="ch07lev1sec4"><strong>Yahoo! Mail Stored XSS</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> Yahoo! Mail</p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://klikki.fi/adv/yahoo.html">https://klikki.fi/adv/yahoo.html</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> December 26, 2015</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $10,000</p>&#13;
<p class="noindent">Sanitizing user input by modifying the inputted text can sometimes lead to problems if done incorrectly. In this example, Yahoo! Mail’s editor allowed people to embed images in an email via HTML using an <code>&lt;img&gt;</code> tag. The <span epub:type="pagebreak" id="page_64"/>editor sanitized the data by removing any JavaScript attributes, such as <code>onload</code>, <code>onerror</code>, and so on, to avoid XSS vulnerabilities. However, it failed to avoid vulnerabilities that occurred when a user intentionally submitted malformed <code>&lt;img&gt;</code> tags.</p>&#13;
<p class="indent">Most HTML tags accept attributes, which are additional information about the HTML tag. For example, the <code>&lt;img&gt;</code> tag requires a <code>src</code> attribute pointing to the address of the image to render. The tag also allows for <code>width</code> and <code>height</code> attributes to define the image’s size.</p>&#13;
<p class="indent">Some HTML attributes are Boolean attributes: when they’re included in the HTML tag, they’re considered true, and when they’re omitted, they’re considered false.</p>&#13;
<p class="indent">With this vulnerability, Jouko Pynnonen found that if he added Boolean attributes to HTML tags with a value, Yahoo! Mail would remove the value but leave the attribute’s equal sign. Here is one of Pynnonen’s examples:</p>&#13;
<pre>&lt;INPUT TYPE="checkbox" CHECKED="hello" NAME="check box"&gt;</pre>&#13;
<p class="indent">Here, the HTML input tag might include a <code>CHECKED</code> attribute denoting whether a check box should be rendered as checked off. Based on Yahoo’s tag parsing, the line would become this:</p>&#13;
<pre>&lt;INPUT TYPE="checkbox" CHECKED= NAME="check box"&gt;</pre>&#13;
<p class="indent">This may look harmless, but HTML allows zero or more space characters around the equal sign in an unquoted attribute value. So browsers read this as <code>CHECKED</code> having the value of <code>NAME="check</code> and the input tag having a third attribute named <code>box</code>, which doesn’t have a value.</p>&#13;
<p class="indent">To exploit this, Pynnonen submitted the following <code>&lt;img&gt;</code> tag:</p>&#13;
<pre>&lt;img ismap='xxx' itemtype='yyy style=width:100%;height:100%;position:fixed;<br/>&#13;
  left:0px;top:0px; onmouseover=alert(/XSS/)//'&gt;</pre>&#13;
<p class="indent">Yahoo! Mail filtering would change this to the following:</p>&#13;
<pre>&lt;img ismap= itemtype='yyy' style=width:100%;height:100%;position:fixed;left:<br/>&#13;
  0px;top:0px; onmouseover=alert(/XSS/)//&gt;</pre>&#13;
<p class="indent">The <code>ismap</code> value is a Boolean <code>&lt;img&gt;</code> tag attribute that indicates whether an image has clickable areas. In this case, Yahoo! removed <code>'xxx'</code>, and the single quote from the end of the string was moved to the end of the <code>yyy</code>.</p>&#13;
<p class="indent">Sometimes, the backend of a site will be a black box and you won’t know how code is being processed, as in this case. We don’t know why the <code>'xxx'</code> was removed or why the single quote was moved to the end of <code>yyy</code>. Yahoo’s parsing engine or the way the browser handled whatever Yahoo! returned could have made these changes. Still, you can use these oddities to find vulnerabilities.</p>&#13;
<p class="indent">Because of the way the code was processed, an <code>&lt;img&gt;</code> tag with a height and width of 100 percent was rendered, making the image take up the <span epub:type="pagebreak" id="page_65"/>entire browser window. When a user moved their mouse over the web page, the XSS payload would execute because of the <code>onmouseover=alert(/XSS/)</code> part of the injection.</p>&#13;
<h4 class="h4" id="ch07lev2sec3"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">When sites sanitize user input by modifying it instead of encoding or escaping values, you should continue testing the site’s server-side logic. Think about how a developer might have coded their solution and what assumptions they’ve made. For example, check whether the developer considered what happens if two <code>src</code> attributes are submitted or if spaces are replaced with slashes. In this case, the bug reporter checked what would happen when Boolean attributes were submitted with values.</p>&#13;
<h3 class="h3" id="ch07lev1sec5"><strong>Google Image Search</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> <em><a href="http://images.google.com/">images.google.com/</a></em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://mahmoudsec.blogspot.com/2015/09/how-i-found-xss-vulnerability-in-google.html">https://mahmoudsec.blogspot.com/2015/09/how-i-found-xss-vulnerability-in-google.html</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> September 12, 2015</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> Undisclosed</p>&#13;
<p class="noindent">Depending on where your input is being rendered, you don’t always need to use special characters to exploit XSS vulnerabilities. In September 2015, Mahmoud Jamal was using Google Images to find an image for his HackerOne profile. While browsing, he noticed the image URL <em><a href="http://www.google.com/imgres?imgurl=https://lh3.googleuser.com/">http://www.google.com/imgres?imgurl=https://lh3.googleuser.com/</a></em>... from Google.</p>&#13;
<p class="indent">Noting the reference to <code>imgurl</code> in the URL, Jamal realized he could control the parameter’s value; it would likely be rendered on the page as a link. When hovering over the thumbnail image for his profile, Jamal confirmed that the <code>&lt;a&gt;</code> tag <code>href</code> attribute included the same URL. He tried changing the <code>imgurl</code> parameter to <code>javascript:alert(1)</code> and noticed that the <code>href</code> attribute also changed to the same value.</p>&#13;
<p class="indent">This <code>javascript:alert(1)</code> payload is useful when special characters are sanitized because the payload doesn’t contain special characters for the website to encode. When clicking a link to <code>javascript:alert(1)</code>, a new browser window opens and the <code>alert</code> function executes. In addition, because the JavaScript executes in the context of the initial web page, which contains the link, the JavaScript can access the DOM of that page. In other words, a link to <code>javascript:alert(1)</code> would execute the <code>alert</code> function against Google. This result shows that a malicious attacker could potentially access information on the web page. If clicking a link to the JavaScript protocol didn’t inherit the context of the initial site rendering the link, the XSS would be harmless: attackers couldn’t access the vulnerable web page’s DOM.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_66"/>Excited, Jamal clicked what he thought would be his malicious link, but no JavaScript executed. Google had sanitized the URL address when the mouse button was clicked via the anchor tag’s <code>onmousedown</code> JavaScript attribute.</p>&#13;
<p class="indent">As a workaround, Jamal tried tabbing through the page. When he got to the View Image button, he pressed <small>ENTER</small>. The JavaScript was triggered because he could visit the link without clicking the mouse button.</p>&#13;
<h4 class="h4" id="ch07lev2sec4"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Always be on the lookout for URL parameters that might be reflected on the page because you have control over those values. If you find any URL parameters that are rendered on a page, consider their context as well. URL parameters might present opportunities to get around filters that remove special characters. In this example, Jamal didn’t need to submit any special characters because the value was rendered as the <code>href</code> attribute in an anchor tag.</p>&#13;
<p class="indent">Additionally, look for vulnerabilities even on Google and other major sites. It’s easy to assume that just because a company is huge, all its vulnerabilities have been discovered. Clearly, that isn’t always the case.</p>&#13;
<h3 class="h3" id="ch07lev1sec6"><strong>Google Tag Manager Stored XSS</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Medium</p>&#13;
<p class="hang"><strong>URL:</strong> <em><a href="http://tagmanager.google.com/">tagmanager.google.com/</a></em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="https://blog.it-securityguard.com/bugbounty-the-5000-google-xss/">https://blog.it-securityguard.com/bugbounty-the-5000-google-xss/</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> October 31, 2014</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> $5,000</p>&#13;
<p class="noindent">A common best practice of websites is to sanitize user input when rendering it instead of when it’s being saved on submission. The reason is that it’s easy to introduce new ways to submit data to a site (like a file upload) and to forget to sanitize the input. In some cases, however, companies don’t follow this practice: Patrik Fehrenbach of HackerOne discovered this lapse in October 2014 when he was testing Google for XSS vulnerabilities.</p>&#13;
<p class="indent">Google Tag Manager is an SEO tool that makes it easy for marketers to add and update website tags. To do this, the tool has a number of web forms that users interact with. Fehrenbach began by finding available form fields and entering XSS payloads, such as <code>#"&gt;&lt;img src=/ onerror=alert(3)&gt;</code>. If the payload was accepted by the form field, the payload would close the existing HTML tag and then try to load a nonexistent image. Because the image wouldn’t be found, the website would execute the <code>onerror</code> JavaScript function <code>alert(3)</code>.</p>&#13;
<p class="indent">But Fehrenbach’s payload didn’t work. Google was properly sanitizing his input. Fehrenbach noticed an alternative way to submit his payload. In <span epub:type="pagebreak" id="page_67"/>addition to the form fields, Google provides the ability to upload a JSON file with multiple tags. So Fehrenbach uploaded the following JSON file to Google’s service:</p>&#13;
<pre>"data": {<br/>&#13;
  "name": "#"&gt;&lt;img src=/ onerror=alert(3)&gt;",<br/>&#13;
  "type": "AUTO_EVENT_VAR",<br/>&#13;
  "autoEventVarMacro": {<br/>&#13;
    "varType": "HISTORY_NEW_URL_FRAGMENT"<br/>&#13;
  }<br/>&#13;
}</pre>&#13;
<p class="indent">Notice that the value of the <code>name</code> attribute is the same XSS payload Fehrenbach tried previously. Google wasn’t following best practices and was sanitizing input from the web form on submission instead of at the time of rendering. As a result, Google forgot to sanitize input from the file upload, so Fehrenbach’s payload executed.</p>&#13;
<h4 class="h4" id="ch07lev2sec5"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Two details are worth noting in Fehrenbach’s report. First, Fehrenbach found an alternative input method for his XSS payload. You should look for an alternative input method as well. Be sure to test all methods a target provides to enter input, because the way each input is processed might be different. Second, Google was attempting to sanitize on input instead of at the time of rendering. Google could have prevented this vulnerability by following best practices. Even when you know website developers typically use common countermeasures against certain attacks, check for vulnerabilities. Developers can make mistakes.</p>&#13;
<h3 class="h3" id="ch07lev1sec7"><strong>United Airlines XSS</strong></h3>&#13;
<p class="hangt"><strong>Difficulty:</strong> Hard</p>&#13;
<p class="hang"><strong>URL:</strong> <em><a href="http://checkin.united.com/">checkin.united.com/</a></em></p>&#13;
<p class="hang"><strong>Source:</strong> <em><a href="http://strukt93.blogspot.jp/2016/07/united-to-xss-united.html">http://strukt93.blogspot.jp/2016/07/united-to-xss-united.html</a></em></p>&#13;
<p class="hang"><strong>Date reported:</strong> July 2016</p>&#13;
<p class="hangb"><strong>Bounty paid:</strong> Undisclosed</p>&#13;
<p class="noindent">In July 2016, while searching for cheap flights, Mustafa Hasan began looking for bugs on United Airlines sites. He found that visiting the subdomain <em><a href="http://checkin.united.com">checkin.united.com</a></em> redirected to a URL that included an <code>SID</code> parameter. Noticing that any value passed to the parameter was rendered in the page HTML, he tested <code>"&gt;&lt;svg onload=confirm(1)&gt;</code>. If rendered improperly, the tag would close the existing HTML tag and inject Hasan’s <code>&lt;svg&gt;</code> tag, resulting in a JavaScript pop-up courtesy of the <code>onload</code> event.</p>&#13;
<p class="indent">But when he submitted his HTTP request, nothing happened, although his payload was rendered as is, unsanitized. Rather than giving up, Hasan opened the site’s JavaScript files, likely with the browser’s development tools. <span epub:type="pagebreak" id="page_68"/>He found the following code, which overrides JavaScript attributes that might lead to XSS, such as the attributes <code>alert</code>, <code>confirm</code>, <code>prompt</code>, and <code>write</code>:</p>&#13;
<pre>   [function () {<br/>&#13;
   /*<br/>&#13;
   XSS prevention via JavaScript<br/>&#13;
   */<br/>&#13;
   var XSSObject = new Object();<br/>&#13;
   XSSObject.lockdown = function(obj,name) {<br/>&#13;
       if (!String.prototype.startsWith) {<br/>&#13;
           try {<br/>&#13;
               if (Object.defineProperty) {<br/>&#13;
                   Object.defineProperty(obj, name, {<br/>&#13;
                       configurable: false<br/>&#13;
                   });<br/>&#13;
               }<br/>&#13;
           } catch (e)  { };<br/>&#13;
       }<br/>&#13;
   }<br/>&#13;
   XSSObject.proxy = function (obj, name, report_function_name, <span class="ent">➊</span>exec_original)<br/>&#13;
   {<br/>&#13;
       var proxy = obj[name];<br/>&#13;
       obj[name] = function () {<br/>&#13;
           if (exec_original) {<br/>&#13;
               return proxy.apply(this, arguments);<br/>&#13;
           }<br/>&#13;
       };<br/>&#13;
       XSSObject.lockdown(obj, name);<br/>&#13;
   };<br/>&#13;
<span class="ent">➋</span> XSSObject.proxy(window, 'alert', 'window.alert', false);<br/>&#13;
   XSSObject.proxy(window, 'confirm', 'window.confirm', false);<br/>&#13;
   XSSObject.proxy(window, 'prompt', 'window.prompt', false);<br/>&#13;
   XSSObject.proxy(window, 'unescape', 'unescape', false);<br/>&#13;
   XSSObject.proxy(document, 'write', 'document.write', false);<br/>&#13;
   XSSObject.proxy(String, 'fromCharCode', 'String.fromCharCode', true);<br/>&#13;
   }]();</pre>&#13;
<p class="indent">Even if you don’t know JavaScript, you might guess what’s happening via the use of certain words. For example, the <code>exec_original</code> parameter name <span class="ent">➊</span> in the <code>XSSObject proxy</code> definition implies a relationship that executes something. Immediately below the parameter is a list of all our interesting functions and the value <code>false</code> being passed (except in the last instance) <span class="ent">➋</span>. We can assume the site is trying to protect itself by disallowing the execution of the JavaScript attributes passed into <code>XSSObject proxy</code>.</p>&#13;
<p class="indent">Notably, JavaScript allows you to override existing functions. So Hasan first tried to restore the <code>document.write</code> function by adding the following value in the <code>SID</code>:</p>&#13;
<pre>javascript:document.write=HTMLDocument.prototype.write;document.write('STRUKT');</pre>&#13;
<p class="indent">This value sets the document’s <code>write</code> function to its original functionality by using the <code>write</code> function’s prototype. Because JavaScript is object <span epub:type="pagebreak" id="page_69"/>oriented, all objects have a prototype. By calling on the <code>HTMLDocument</code>, Hasan set the current document’s <code>write</code> function back to the original implementation from <code>HTMLDocument</code>. He then called <code>document.write('STRUKT')</code> to add his name in plaintext to the page.</p>&#13;
<p class="indent">But when Hasan tried to exploit this vulnerability, he got stuck again. He reached out to Rodolfo Assis for help. Working together, they realized that United’s XSS filter was missing the override for a function similar to <code>write</code>: the <code>writeln</code> function. The difference between these two functions is that <code>writeln</code> adds a newline after writing its text, whereas <code>write</code> doesn’t.</p>&#13;
<p class="indent">Assis believed he could use the <code>writeln</code> function to write content to the HTML document. Doing so would allow him to bypass one piece of United’s XSS filter. He did this with the following payload:</p>&#13;
<pre>";}{document.writeln(decodeURI(location.hash))-"#&lt;img src=1 onerror=alert(1)&gt;</pre>&#13;
<p class="indent">But his JavaScript still didn’t execute because the XSS filter was still being loaded and overriding the <code>alert</code> function: Assis needed to use a different method. Before we look at the final payload and how Assis worked around the <code>alert</code> override, let’s break down his initial payload.</p>&#13;
<p class="indent">The first piece, <code>";}</code>, closes the existing JavaScript being injected into. Next, <code>{</code> opens the JavaScript payload, and <code>document.writeln</code> calls the JavaScript document object’s <code>writeln</code> function to write content to the DOM. The <code>decodeURI</code> function passed to <code>writeln</code> decodes encoded entities in a URL (for example, <code>%22</code> will become <code>"</code>). The <code>location.hash</code> code passed to <code>decodeURI</code> returns all parameters after the <code>#</code> in the URL, which is defined later. After this initial setup is done, <code>-"</code> replaces the quote at the start of the payload to ensure proper JavaScript syntax.</p>&#13;
<p class="indent">The last piece, <code>#&lt;img src=1 onerror=alert(1)&gt;</code>, adds a parameter that is never sent to the server. This last piece is a defined, optional part of a URL, called a <em>fragment</em>, and it’s meant to refer to a part of the document. But in this case, Assis used a fragment to take advantage of the hash (<code>#</code>) that defines the start of the fragment. The reference to <code>location.hash</code> returns all content after the <code>#</code>. But the returned content will be URL encoded, so the input <code>&lt;img src=1 onerror=alert(1)&gt;</code> will be returned as <code>%3Cimg%20src%3D1%20onerror%3Dalert%281%29%3E%20</code>. To address the encoding, the function <code>decodeURI</code> decodes the content back to the HTML <code>&lt;img src=1 onerror=alert(1)&gt;</code>. This is important because the decoded value is passed to the <code>writeln</code> function, which writes the HTML <code>&lt;img&gt;</code> tag to the DOM. The HTML tag executes the XSS when the site can’t find the image <code>1</code> referenced in the <code>src</code> attribute of the tag. If the payload is successful, a JavaScript alert box would pop up with the number <code>1</code> in it. But it didn’t.</p>&#13;
<p class="indent">Assis and Hasan realized they needed a fresh HTML document within the context of the United site: they needed a page that didn’t have the XSS filter JavaScript loaded but still had access to the United web page information, cookies, and so on. So they used an iFrame with the following payload:</p>&#13;
<pre>";}{document.writeln(decodeURI(location.hash))-"#&lt;iframe<br/>&#13;
src=javascript:alert(document.domain)&gt;&lt;iframe&gt;</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_70"/>This payload behaved just like the original URL with the <code>&lt;img&gt;</code> tag. But in this one they wrote an <code>&lt;iframe&gt;</code> to the DOM and changed the <code>src</code> attribute to use the JavaScript scheme to <code>alert(document.domain)</code>. This payload is similar to the XSS vulnerability discussed in “<a href="ch07.xhtml#ch07lev1sec5">Google Image Search</a>” on <a href="ch07.xhtml#page_65">page 65</a>, because the JavaScript scheme inherits the context of the parent DOM. Now the XSS could access the United DOM, so <code>document.domain</code> printed <em><a href="http://www.united.com">www.united.com</a></em>. The vulnerability was confirmed when the site rendered a pop-up alert.</p>&#13;
<p class="indent">An iFrame can take a source attribute to pull in remote HTML. As a result, Assis could set the source to be JavaScript, which immediately called the <code>alert</code> function with the document domain.</p>&#13;
<h4 class="h4" id="ch07lev2sec6"><strong><em>Takeaways</em></strong></h4>&#13;
<p class="noindent">Note three important details about this vulnerability. First, Hasan was persistent. Rather than giving up when his payload wouldn’t fire, he dug into the JavaScript to find out why. Second, the use of a JavaScript attribute blacklist should tip off hackers that XSS bugs might exist in the code because they’re opportunities for developer mistakes. Third, having JavaScript knowledge is essential for successfully confirming more complex vulnerabilities.</p>&#13;
<h3 class="h3" id="ch07lev1sec8"><strong>Summary</strong></h3>&#13;
<p class="noindent">XSS vulnerabilities represent real risk for site developers and are still prevalent on sites, often in plain sight. By submitting a malicious payload, like <code>&lt;img src=x onerror=alert(document.domain)&gt;</code>, you can check whether an input field is vulnerable. But this isn’t the only way to test for XSS vulnerabilities. Any time a site sanitizes input through modification (by removing characters, attributes, and so on), you should thoroughly test the sanitization functionality. Look for opportunities where sites are sanitizing input on submission rather than when rendering the input, and test all methods of input. Also, look for URL parameters you control being reflected on the page; these might allow you to find an XSS exploit that can bypass encoding, such as adding <code>javascript:alert(document.domain)</code> to the <code>href</code> value in an anchor tag.</p>&#13;
<p class="indent">It’s important to consider all places that a site is rendering your input and whether it’s in HTML or JavaScript. Keep in mind that XSS payloads might not execute immediately.</p>&#13;
</body></html>