<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><h2 class="h2" id="ch08"><span epub:type="pagebreak" id="page_151"/><strong><span class="big">8</span><br/>MEMORY</strong></h2>&#13;
<div class="image1"><img src="../images/pg23_Image_2.jpg" alt="Image" width="191" height="190"/></div>&#13;
<p class="noindentz">In the previous three chapters, you learned about some of the hardware used to implement logical functions. Now, we’ll look at how this functionality can be used to implement the subsystems that make up a computer, starting with memory.</p>&#13;
<p class="indent">Every computer user wants lots of memory and fast computing. However, faster memory costs more money, so there are some trade-offs. I’ll begin this chapter with a discussion of how different types of memory are used to provide a reasonable compromise between speed and cost. Then, I’ll describe a few different ways of implementing memory in hardware.</p>&#13;
<h3 class="h3" id="ch08lev1sec1"><strong>The Memory Hierarchy</strong></h3>&#13;
<p class="noindent">In general, the closer memory is to the CPU, the faster and more expensive it is. The slowest memory is memory in the cloud. It’s also the least expensive. My email account provides 15GB of storage in the cloud and doesn’t cost me any money (if I ignore the “cost” of seeing a few advertisements), but its speed is limited by my internet connection. At the other extreme, the memory within the CPU runs at the same speed as the CPU but is relatively <span epub:type="pagebreak" id="page_152"/>expensive. The Raspberry Pi has a little over 500 bytes of memory in the CPU available for us to use in our programs.</p>&#13;
<p class="indent"><a href="ch08.xhtml#ch8fig1">Figure 8-1</a> shows this general hierarchy. As we get closer to the CPU (at the top of the figure), memory is faster and costs more money, so there’s less of it.</p>&#13;
<div class="image"><img id="ch8fig1" src="../images/pg180_Image_230.jpg" alt="Image" width="355" height="294"/></div>&#13;
<p class="figcap"><em>Figure 8-1: The computer memory hierarchy</em></p>&#13;
<p class="indent">The top three layers in <a href="ch08.xhtml#ch8fig1">Figure 8-1</a> are typically included in the CPU chip in modern computers. There may be one or two more levels of cache before getting to main memory. Main memory and a disk or solid-state drive (SSD), or both, are usually within the same enclosure as the CPU.</p>&#13;
<p class="indent">The next layer away from the CPU represents offline data storage devices, of which DVDs and memory sticks are only two examples. You may also have an external USB disk, a tape drive, and so forth. To make these devices available to the computer, you usually need to take some physical action, such as inserting a DVD in the drive or plugging a memory stick into a USB port.</p>&#13;
<p class="indent">The final layer in this hierarchy is storage in the cloud. Although most of us set up our computers to log on to the cloud automatically, it may not always be available.</p>&#13;
<p class="indent">In this chapter, I’ll start with the two layers just above the cloud layer, offline storage and disk/SSD, and work toward the CPU registers. Then, I’ll describe the hardware used to build registers and work back out toward main memory. We’ll leave discussion of implementation of the three outermost layers to other books.</p>&#13;
<h4 class="h4" id="ch08lev2sec1"><em><strong>Mass Storage</strong></em></h4>&#13;
<p class="noindent">Collectively, the two layers above the cloud layer in <a href="ch08.xhtml#ch8fig1">Figure 8-1</a> are known as <em>mass storage</em>. Mass storage devices store large amounts of data, and the data persists when the power to the device is turned off.</p>&#13;
<p class="indent">Let’s take another look at the major subsystems of a computer, introduced in <a href="ch01.xhtml">Chapter 1</a>. As shown in <a href="ch08.xhtml#ch8fig2">Figure 8-2</a>, the three subsystems communicate with one another via the data, control, and address buses. In addition, <span epub:type="pagebreak" id="page_153"/>the input/output (I/O) block includes specialized circuitry that interfaces with mass storage devices.</p>&#13;
<div class="image"><img id="ch8fig2" src="../images/pg181_Image_231.jpg" alt="Image" width="456" height="176"/></div>&#13;
<p class="figcap"><em>Figure 8-2: The subsystems of a computer</em></p>&#13;
<p class="indent">The Raspberry Pi, for example, has circuitry that implements the SD bus protocol and uses a micro SD card as its SSD. The operating system includes software (a <em>device driver</em>) that applications call to access the data and applications on the micro SD card through the SD port. I’ll discuss I/O programming in <a href="ch20.xhtml">Chapter 20</a>, but the specifics of device drivers are beyond the scope of this book.</p>&#13;
<p class="indent">In the rest of this chapter, I’ll cover <em>volatile memory</em>, which loses its contents when the power is turned off.</p>&#13;
<h4 class="h4" id="ch08lev2sec2"><em><strong>Main Memory</strong></em></h4>&#13;
<p class="noindent"><em>Main memory</em> is the random-access memory (RAM) that you see in the specifications when you buy a computer. Main memory is synchronized in the hardware with the CPU via the bus interface, which I’ll discuss in <a href="ch09.xhtml">Chapters 9</a> and <a href="ch20.xhtml">20</a>. Thus, a programmer can access items in memory by simply specifying the address and whether to load the item from memory or to store a new value there.</p>&#13;
<p class="indent">The amount of memory in your Raspberry Pi depends on the model. The Raspberry Pi 3 A+ has 512MB and the 3 B and 3 B+ each have 1GB. The Raspberry Pi 4 B can have 2, 4, or 8GB. The Raspberry Pi 5 can have 4 or 8GB. Other memory configurations may be available.</p>&#13;
<p class="indent">Usually, the entire program and dataset are not loaded into main memory. Instead, the operating system loads only the portion currently being worked on from mass storage into main memory. Most mass storage devices in modern computers can be accessed only in <em>blocks</em> of predetermined size. For example, the Raspberry Pi OS uses a disk block size of 4KB. When a needed instruction or data item is loaded into main memory, the computer loads the whole block of instructions or data that includes the needed item. The chances are good that the nearby parts of the program (instructions or data) will be needed soon. Since they’re already in main memory, the operating system doesn’t need to access the mass storage device again, thus speeding up program execution.</p>&#13;
<p class="indent">The most common organization of main memory is to store both the program instructions and data in main memory. This is referred to as the <em>von Neumann architecture</em> as it was initially described by John von Neumann <span epub:type="pagebreak" id="page_154"/>(“First Draft of a Report on the EDVAC,” Moore School of Electrical Engineering, University of Pennsylvania, 1945), although other computer science pioneers of the day were working on the same concepts.</p>&#13;
<p class="indent">One downside of the von Neumann architecture is that if an instruction calls for reading data from (or writing data to) memory, the next instruction in the program sequence cannot be read from (or written to) memory over the same bus until the current instruction has completed the data transfer. This is known as the <em>von Neumann bottleneck</em>. This conflict slows program execution, and it gave rise to another stored program architecture: the <em>Harvard architecture</em>, in which the program and data are stored in different memories, each with its own bus connected to the CPU. This makes it possible for the CPU to access program instructions and data simultaneously. This specialization reduces memory usage flexibility, which generally increases the total amount of memory needed. It also requires additional memory access hardware. The additional memory and access hardware increase the cost. It’s common for the Level 1 cache to have a Harvard architecture, thus providing separate paths to the CPU for the instructions and the data.</p>&#13;
<p class="indent">Another downside of the von Neumann architecture is that a program can be written to view itself as data, thus enabling self-modification, which is generally a bad idea. Linux, like most modern, general-purpose operating systems, prohibits applications from modifying themselves.</p>&#13;
<h4 class="h4" id="ch08lev2sec3"><em><strong>Cache Memory</strong></em></h4>&#13;
<p class="noindent">Most of the programs I use take up tens or hundreds of megabytes in main memory, but most of the execution time is taken up by loops, which execute the same few instructions repeatedly, access the same few variables, and occupy only tens or hundreds of bytes. Most modern computers include very fast <em>cache memory</em> between the main memory and the CPU, which provides a much faster location for the instructions and variables currently being processed by the program.</p>&#13;
<p class="indent">Cache memory is organized in levels, with Level 1 being the closest to the CPU and also the smallest. Cache sizes of the Raspberry Pi vary, as shown in <a href="ch08.xhtml#ch8tab1">Table 8-1</a>.</p>&#13;
<p class="tabcap" id="ch8tab1"><strong>Table 8-1:</strong> The Raspberry Pi’s Cache Sizes</p>&#13;
<table class="table-h">&#13;
<colgroup>&#13;
<col style="width:20%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th class="tab_th_2"/>&#13;
<th class="tab_th_2" colspan="2"><p class="noindentc"><strong>Level 1</strong></p></th>&#13;
<th class="tab_th_2"><strong>Level 2</strong></th>&#13;
<th class="tab_th_2"><strong>Level 3</strong></th>&#13;
</tr>&#13;
<tr>&#13;
<th class="tab_th"><strong>Model</strong></th>&#13;
<th class="tab_th"><strong>Instruction</strong></th>&#13;
<th class="tab_th"><strong>Data</strong></th>&#13;
<th class="tab_th"><strong>Unified</strong></th>&#13;
<th class="tab_th"><strong>Unified</strong></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td class="bg1">3 A+, B, B+</td>&#13;
<td class="bg1">4 <em>×</em> 32KB</td>&#13;
<td class="bg1">4 <em>×</em> 32KB</td>&#13;
<td class="bg1">512KB</td>&#13;
<td class="bg1">n/a</td>&#13;
</tr>&#13;
<tr>&#13;
<td class="bg">4 B</td>&#13;
<td class="bg">4 <em>×</em> 48KB</td>&#13;
<td class="bg">4 <em>×</em> 32KB</td>&#13;
<td class="bg">1MB</td>&#13;
<td class="bg">n/a</td>&#13;
</tr>&#13;
<tr>&#13;
<td class="bg1">5</td>&#13;
<td class="bg1">4 <em>×</em> 64KB</td>&#13;
<td class="bg1">4 <em>×</em> 64KB</td>&#13;
<td class="bg1">4 <em>×</em> 512KB</td>&#13;
<td class="bg1">2MB</td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>I have seen conflicting information about cache sizes on the various Raspberry Pi models, so I don’t guarantee the accuracy of the sizes in <a href="ch08.xhtml#ch8tab1">Table 8-1</a>, but they are close enough to illustrate how caches work.</em></p>&#13;
</div>&#13;
<span epub:type="pagebreak" id="page_155"/>&#13;
<p class="indent">The portion of the CPU that performs the computations is called the <em>processor core</em>, or simply the <em>core</em>. The CPUs in all the Raspberry Pi models in <a href="ch08.xhtml#ch8tab1">Table 8-1</a> have four processor cores. The notation 4 × prefacing a memory size in this table means that each processor core has that amount of cache memory.</p>&#13;
<p class="indent">The Raspberry Pi 3 and 4 have two cache levels, and the Raspberry Pi 5 has three. Level 1 on all models uses a Harvard architecture. The Level 2 and 3 caches are all unified caches that hold both instructions and data. Cache memory in the Raspberry Pi is organized in 64-byte blocks called <em>lines</em>. Instructions and data are transferred to and from main memory one line at a time on a 64-byte address boundary.</p>&#13;
<p class="indent">When a program needs to access an instruction or data item, the hardware first checks to see if it’s located in the Level 1 cache. If not, it checks the Level 2 cache. If it’s in the Level 2 cache, the hardware copies the cache line that includes the needed instruction or data into the Level 1 cache and then into the CPU, where it stays until the program needs it again or the Level 1 cache needs to reuse that location for other instructions or data from the Level 2 cache. The hardware continues this process to subsequent cache levels until it either finds the needed item in a cache or reaches main memory.</p>&#13;
<p class="indent">When data is written to main memory, it’s first written to the Level 1 cache, then the next cache levels. There are many schemes for using caches, which can become rather complex. I’ll leave further discussion of caches for more advanced treatments, such as the Wikibooks article on microprocessor design and caches at <em><a href="https://en.wikibooks.org/wiki/Microprocessor_Design/Cache">https://en.wikibooks.org/wiki/Microprocessor_Design/Cache</a></em>.</p>&#13;
<p class="indent">The time taken to access the Level 1 cache is close to the speed of the CPU. Level 2 is about 10 times slower, Level 3 about 100 times slower, and main memory about 1,000 times slower. These values are approximate and differ widely among implementations. Modern processors include cache memory in the same chip as the CPU, and some have more than three levels of cache.</p>&#13;
<p class="indent">Computer performance is usually limited by the time it takes for the CPU to read instructions and data into the CPU, not by the speed of the CPU itself. Having the instructions and data in the Level 1 cache reduces this time. Of course, if they are not in the Level 1 cache and the hardware needs to copy other instructions or data from Level 2 or Level 3, or from main memory into Level 3, then Level 2, and finally Level 1, access will take longer than simply getting the instructions or data directly from main memory. The effectiveness of caches depends on the <em>locality of reference</em>, which is the tendency of a program to reference nearby memory addresses in a short period of time. This is one of the reasons good programmers break a program, especially repetitive sections, into small units. A small program unit is more likely to fit within a few lines of a cache, where it will be available for successive repetitions.</p>&#13;
<span epub:type="pagebreak" id="page_156"/>&#13;
<div class="box">&#13;
<p class="box-title"><strong>YOUR TURN</strong></p>&#13;
<p class="box-list" id="ch8exe1">8.1     Determine the cache size(s) on your Raspberry Pi. The <span class="literal">lscpu</span> command will show you the model name of your CPU.</p>&#13;
<p class="box-list" id="ch8exe2">8.2     Determine the line size of each of the caches on your Raspberry Pi. You can use the <span class="literal">getconf -a| grep CACHE</span> command.</p>&#13;
</div>&#13;
<h4 class="h4" id="ch08lev2sec4"><em><strong>Registers</strong></em></h4>&#13;
<p class="noindent">The fastest memory is within the CPU itself: the <em>registers</em>. Registers typically provide a few hundred bytes of storage and are accessed at the same speed as the CPU. They’re mainly used for numerical computations, logical operations, temporary data storage, holding addresses, and similar short-term operations—somewhat like how we use scratch paper when doing computations by hand.</p>&#13;
<p class="indent">Many registers are directly accessible by the programmer, while others are hidden. Some are used in the hardware that serves to interface between the CPU and I/O devices. The organization of registers in the CPU is specific to the particular CPU architecture, and it’s one of the most important aspects of programming a computer at the assembly language level.</p>&#13;
<p class="indent">In the next chapter, you’ll learn about the main registers in the ARM CPU that we’ll be using for our programming in this book. But before we get to that, let’s look at how memory can be implemented in hardware using the logic devices discussed in previous chapters.</p>&#13;
<h3 class="h3" id="ch08lev1sec2"><strong>Implementing Memory in Hardware</strong></h3>&#13;
<p class="noindent">Starting at the top of the hierarchy shown in <a href="ch08.xhtml#ch8fig1">Figure 8-1</a>, we’ll first see how we can implement the memory in the CPU registers. We will then work our way back down from the CPU, and you’ll see some of the limitations that arise when applying these designs to larger memory systems, such as cache and main memory. We’ll explore designs for the memory in these larger systems, but I won’t cover the implementation of mass storage systems in this book.</p>&#13;
<h4 class="h4" id="ch08lev2sec5"><em><strong>Four-Bit Registers</strong></em></h4>&#13;
<p class="noindent">Let’s begin with a design for a simple <em>4-bit register</em>, which might be found in inexpensive CPUs used in price-sensitive consumer products, such as coffee makers and remote controls. <a href="ch08.xhtml#ch8fig3">Figure 8-3</a> shows a design for implementing a 4-bit register using a D flip-flop for each bit. Each time the clock does a positive transition, the state (contents) of the register, <em>r</em> = <em>r</em><sub>3</sub><em>r</em><sub>2</sub><em>r</em><sub>1</sub><em>r</em><sub>0</sub>, is set to the input, <em>d</em> = <em>d</em><sub>3</sub><em>d</em><sub>2</sub><em>d</em><sub>1</sub><em>d</em><sub>0</sub>.</p>&#13;
<span epub:type="pagebreak" id="page_157"/>&#13;
<div class="image"><img id="ch8fig3" src="../images/pg185_Image_232.jpg" alt="Image" width="255" height="579"/></div>&#13;
<p class="figcap"><em>Figure 8-3: A 4-bit register using a D flip-flop for each bit</em></p>&#13;
<p class="indent">The problem with this circuit is that any changes in any <em>d<sub>i</sub></em> will change the state of the corresponding stored bit, <em>r<sub>i</sub></em>, in the next clock cycle, so the contents of the register are essentially valid for only one clock cycle. One-cycle buffering of a bit pattern is fine for some applications, but we also need registers that will store a value until it is explicitly changed, perhaps billions of clock cycles later. Let’s add a <em>Store</em> signal and feedback from the output, <em>r<sub>i</sub></em>, of each bit. We want each <em>r<sub>i</sub></em> to remain unchanged when <em>Store</em> = <span class="literal">0</span> and to follow the input, <em>d<sub>i</sub></em>, when <em>Store</em> = <span class="literal">1</span>, as shown in <a href="ch08.xhtml#ch8tab2">Table 8-2</a>.</p>&#13;
<p class="tabcap" id="ch8tab2"><strong>Table 8-2:</strong> Storing One Bit in a D Flip-Flop</p>&#13;
<table class="table-h">&#13;
<colgroup>&#13;
<col style="width:30%"/>&#13;
<col style="width:30%"/>&#13;
<col style="width:20%"/>&#13;
<col style="width:10%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th class="tab_th"><em><strong>Store</strong></em></th>&#13;
<th class="tab_th"><strong><em>d</em></strong><em><strong><sub>i</sub></strong></em></th>&#13;
<th class="tab_th"><em><strong>r</strong><strong><sub>i</sub></strong></em></th>&#13;
<th class="tab_th"><em><strong>Q</strong></em></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="bg"><span class="literal">0</span></td>&#13;
<td class="bg"><span class="literal">0</span></td>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
<td class="bg1"><span class="literal">1</span></td>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="bg"><span class="literal">0</span></td>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="bg1"><span class="literal">1</span></td>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
<td class="bg"><span class="literal">0</span></td>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
<td class="bg"><span class="literal">0</span></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="bg1"><span class="literal">1</span></td>&#13;
<td class="bg1"><span class="literal">1</span></td>&#13;
<td class="bg1"><span class="literal">0</span></td>&#13;
<td class="bg1"><span class="literal">1</span></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
<td class="bg"><span class="literal">1</span></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<span epub:type="pagebreak" id="page_158"/>&#13;
<p class="indent"><a href="ch08.xhtml#ch8tab2">Table 8-2</a> leads to the Boolean equation for <em>Q</em>, the new output of each D flip-flop:</p>&#13;
<div class="image1"><img src="../images/pg186_Image_233.jpg" alt="Image" width="417" height="20"/></div>&#13;
<p class="indent">This equation can be implemented with three NAND gates at the input of each D flip-flop, as shown in <a href="ch08.xhtml#ch8fig4">Figure 8-4</a>.</p>&#13;
<div class="image"><img id="ch8fig4" src="../images/pg186_Image_234.jpg" alt="Image" width="614" height="776"/></div>&#13;
<p class="figcap"><em>Figure 8-4: A 4-bit register with</em> Store <em>signal</em></p>&#13;
<p class="indent">There’s another important feature of this design that follows from the primary/secondary property of the D flip-flops. The state of the secondary portion does not change until the second half of the clock cycle. So, the circuit connected to the output of this register can read the current state during the first half of the clock cycle, while the primary portion is preparing to possibly change the state to the new contents.</p>&#13;
<p class="indent">We now have a way to store, for example, the results from an adder circuit. The output from the register could be used as the input to another circuit that performs arithmetic or logical operations on the data.</p>&#13;
<span epub:type="pagebreak" id="page_159"/>&#13;
<p class="indent">Registers can also be designed to perform simple operations on the data stored in them. Next, we’ll look at a register design that can convert serial data to a parallel format.</p>&#13;
<h4 class="h4" id="ch08lev2sec6"><em><strong>Shift Registers</strong></em></h4>&#13;
<p class="noindent">A <em>shift register</em> uses a sequence of D flip-flops, like the simple storage register in <a href="ch08.xhtml#ch8fig4">Figure 8-4</a>, but the output of each flip-flop is connected to the input of the next flip-flop in the sequence, as shown in <a href="ch08.xhtml#ch8fig5">Figure 8-5</a>. We can use a shift register as a <em>serial-in parallel-out (SIPO)</em> device.</p>&#13;
<div class="image"><img id="ch8fig5" src="../images/pg187_Image_235.jpg" alt="Image" width="243" height="601"/></div>&#13;
<p class="figcap"><em>Figure 8-5: A 4-bit serial-to-parallel shift register</em></p>&#13;
<p class="indent">In the shift register in <a href="ch08.xhtml#ch8fig5">Figure 8-5</a>, a serial stream of bits is input at <em>s<sub>i</sub></em>. At each clock tick, the output of Q0 is applied to the input of Q1, thus copying the previous value of <em>r</em><sub>0</sub> to the new <em>r</em><sub>1</sub>. The state of Q0 changes to the value of the new <em>s<sub>i</sub></em>, thus copying this to be the new value of <em>r</em><sub>0</sub>. The serial stream of bits continues to ripple through the 4 bits of the shift register. At any time, the last 4 bits in the serial stream are available in parallel at the four outputs, <em>r</em><sub>3</sub>, <em>r</em><sub>2</sub>, <em>r</em><sub>1</sub>, <em>r</em><sub>0</sub>, with <em>r</em><sub>3</sub> being the oldest in time.</p>&#13;
<p class="indent">The same circuit could be used to provide a time delay of four clock ticks in a serial bit stream; simply use <em>r</em><sub>3</sub> as the serial output.</p>&#13;
<span epub:type="pagebreak" id="page_160"/>&#13;
<h4 class="h4" id="ch08lev2sec7"><em><strong>The Register File</strong></em></h4>&#13;
<p class="noindent">The registers in the CPU that are used for similar operations are grouped together into a <em>register file</em>. For example, as you’ll see in the next chapter, the CPU in the Raspberry Pi we’ll be programming includes 31 64-bit general-purpose registers that are used for integer computations, temporary storage of addresses, and so forth. We need a mechanism for addressing each of the registers in the register file.</p>&#13;
<p class="indent">Consider a register file composed of eight of the 4-bit registers shown in <a href="ch08.xhtml#ch8fig4">Figure 8-4</a>. We’ll name the outputs from the eight registers <em>r</em>0 through <em>r</em>7. Thus, the <em>i</em>th bits from the eight registers are <em>r</em>0<em><sub>i</sub></em> through <em>r</em>7<em><sub>i</sub></em>. To read the 4 bits of data in one of these eight registers (for example, <em>r</em>5<sub>3</sub>, <em>r</em>5<sub>2</sub>, <em>r</em>5<sub>1</sub>, and <em>r</em>5<sub>0</sub> in register <em>r</em>5), we need to specify one of the eight registers using 3 bits. You learned in <a href="ch06.xhtml">Chapter 6</a> that a multiplexer can select one of several inputs. We can connect an 8 × 1 multiplexer to each corresponding bit of the eight registers, as shown in <a href="ch08.xhtml#ch8fig6">Figure 8-6</a>.</p>&#13;
<div class="image"><img id="ch8fig6" src="../images/pg188_Image_236.jpg" alt="Image" width="277" height="241"/></div>&#13;
<p class="figcap"><em>Figure 8-6: An eight-way multiplexer used to select the output of the register file</em></p>&#13;
<p class="indent">The inputs to the multiplexer, <em>r</em>0<em><sub>i</sub></em>–<em>r</em>7<em><sub>i</sub></em>, are the <em>i</em>th bits from each of eight registers, <em>r</em>0–<em>r</em>7. The slash through the <em>RegSel</em> line with a 3 next to it is the notation used to show there are three lines here.</p>&#13;
<p class="indent"><a href="ch08.xhtml#ch8fig6">Figure 8-6</a> shows only the output of the <em>i</em>th bit; <em>n</em> multiplexers are required for <em>n</em>-bit registers, so a 4-bit register would need four of these multiplexer output circuits. The same <em>RegSel</em> would be applied simultaneously to all four multiplexers to output all 4 bits of the same register. Larger registers would require correspondingly more multiplexers.</p>&#13;
<h4 class="h4" id="ch08lev2sec8"><em><strong>Read/Write Memory</strong></em></h4>&#13;
<p class="noindent">You saw how to build a 4-bit register to store values from D flip-flops in <a href="ch08.xhtml#ch8fig3">Figure 8-3</a>. We now need to be able to select when to read the value that’s stored in the register and disconnect the output when we’re not reading it. A tristate buffer (introduced in <a href="ch06.xhtml">Chapter 6</a>) allows us to do that, as shown in <a href="ch08.xhtml#ch8fig7">Figure 8-7</a>. This circuit is for only one 4-bit register. We need one of these for each register in the computer. The addr <em><sub>j</sub></em> line comes from a decoder and selects one of the registers.</p>&#13;
<span epub:type="pagebreak" id="page_161"/>&#13;
<div class="image"><img id="ch8fig7" src="../images/pg189_Image_237.jpg" alt="Image" width="811" height="783"/></div>&#13;
<p class="figcap"><em>Figure 8-7: A 4-bit read/write register</em></p>&#13;
<p class="indent"><em>Write</em> = <span class="literal">1</span> causes the 4-bit data <em>d</em><sub>3</sub><em>d</em><sub>2</sub><em>d</em><sub>1</sub><em>d</em><sub>0</sub> to be stored in the D flip-flops Q3, Q2, Q1, and Q0. The 4-bit output, <em>r</em><sub>3</sub><em>r</em><sub>2</sub><em>r</em><sub>1</sub><em>r</em><sub>0</sub>, remains disconnected from the D flip-flops when <em>Read</em> = <span class="literal">0</span>. Setting <em>Read</em> = <span class="literal">1</span> connects the outputs.</p>&#13;
<p class="indent">Let’s continue down the memory hierarchy in <a href="ch08.xhtml#ch8fig1">Figure 8-1</a> to cache memory, which is typically constructed from flip-flops, similar to a register file.</p>&#13;
<h4 class="h4" id="ch08lev2sec9"><em><strong>Static Random-Access Memory</strong></em></h4>&#13;
<p class="noindent">The memory we have been discussing that uses flip-flops is called <em>static random-access memory (SRAM)</em>. It’s called <em>static</em> because it maintains its values as long as power is maintained. As you learned in <a href="ch02.xhtml">Chapter 2</a>, it’s called <em>random</em> because it takes the same amount of time to access any (random) byte in this memory.</p>&#13;
<span epub:type="pagebreak" id="page_162"/>&#13;
<p class="indent">SRAM is commonly used for cache memory. As shown in <a href="ch08.xhtml#ch8tab1">Table 8-1</a>, the cache on a Raspberry Pi can range in size from 32KB to 2MB. Each bit in SRAM requires about six transistors to implement.</p>&#13;
<p class="indent">Continuing down the memory hierarchy, we get to main memory, the largest memory unit that is internal to the computer. The amount of main memory in a Raspberry Pi ranges from 1GB to 8GB, depending on the model, so using SRAM for main memory would be quite expensive. Next, we’ll look at a less expensive type of memory that’s suitable for large main memory systems.</p>&#13;
<h4 class="h4" id="ch08lev2sec10"><em><strong>Dynamic Random-Access Memory</strong></em></h4>&#13;
<p class="noindent"><em>Dynamic random-access memory (DRAM)</em> is commonly implemented by charging a capacitor to one of two voltages for storing one bit. The circuit requires only one transistor to charge the capacitor, as shown in <a href="ch08.xhtml#ch8fig8">Figure 8-8</a>. These circuits are arranged in a rectangular array.</p>&#13;
<div class="image"><img id="ch8fig8" src="../images/pg190_Image_238.jpg" alt="Image" width="294" height="363"/></div>&#13;
<p class="figcap"><em>Figure 8-8: One DRAM bit</em></p>&#13;
<p class="indent">When the <em>row select</em> line is set to <span class="literal">1</span>, all the transistors in that row are turned on, thus connecting the respective capacitor to the sense amplifier/ latch. The value stored in the capacitor—high voltage or low voltage—is amplified and stored in the latch. There, it’s available to be read. Since this action tends to discharge the capacitors, they must be refreshed from the values stored in the latch. Separate circuitry is provided to do the refresh.</p>&#13;
<p class="indent">When data is to be stored in DRAM, the new bit value, <span class="literal">0</span> or <span class="literal">1</span>, is first stored in the latch. <em>Row select</em> is then set to <span class="literal">1</span>, and the sense amplifier/latch circuitry applies the voltage corresponding to the logical <span class="literal">0</span> or <span class="literal">1</span> to the capacitor. The capacitor is either charged or discharged appropriately.</p>&#13;
<span epub:type="pagebreak" id="page_163"/>&#13;
<p class="indent">These operations take more time than simply switching flip-flops, so DRAM is appreciably slower than SRAM. In addition, each row of capacitors must be read and refreshed on the order of every 60 ms. This further slows memory access.</p>&#13;
<p class="indent">In addition to the memory itself, the amount of hardware required to address the individual bytes in a large memory system can be substantial. Let’s look at a way to reduce the number of gates needed for addressing memory.</p>&#13;
<p class="indent">As an example, selecting 1 byte in 1MB of memory requires a 20-bit address. This in turn requires a 20×2<sup>20</sup> address decoder, as shown in <a href="ch08.xhtml#ch8fig9">Figure 8-9</a>.</p>&#13;
<div class="image"><img id="ch8fig9" src="../images/pg191_Image_239.jpg" alt="Image" width="522" height="381"/></div>&#13;
<p class="figcap"><em>Figure 8-9: Addressing 1MB of memory with one 20 ×2<sup>20</sup> address decoder</em></p>&#13;
<p class="indent">Recall that an <em>n</em>×2<em><sup>n</sup></em> decoder requires 2<em><sup>n</sup></em> AND gates. So, a 20×2<sup>20</sup> decoder requires 1,048,576 AND gates. We can simplify the circuitry by organizing memory into a grid of 1,024 rows and 1,024 columns, as shown in <a href="ch08.xhtml#ch8fig10">Figure 8-10</a>. We can then select a byte by selecting a row and a column, each using a 10×2<sup>10</sup> decoder.</p>&#13;
<p class="indent">Although two decoders are required, each requires only 2<sup>10</sup> AND gates, for a total of 2×2<sup>10</sup> = 2,048 AND gates for each of the two decoders. Of course, accessing individual bytes in memory is slightly more complex, and some complexity is added to split the 20-bit address into two 10-bit portions. Still, this example should give you an idea of how engineers can simplify designs.</p>&#13;
<span epub:type="pagebreak" id="page_164"/>&#13;
<div class="image"><img id="ch8fig10" src="../images/pg192_Image_240.jpg" alt="Image" width="673" height="532"/></div>&#13;
<p class="figcap"><em>Figure 8-10: Addressing 1MB of memory with two 10</em> × <em>2</em><sup>10</sup> <em>address decoders</em></p>&#13;
<p class="indent">You now have a clear picture of how the hierarchical arrangement of memory in a modern computer allows fast program execution while keeping hardware costs at a reasonable level. Although DRAM is much slower than the CPU, its low cost per bit makes it a good choice for main memory. As we move closer to the CPU in the memory hierarchy, the much faster SRAM is used for the cache(s). Since cache memory is much smaller than main memory, the higher cost per bit of SRAM is tolerable here, and since the instructions and data needed by the program being executed by the CPU are often in the cache, we see the benefits of the higher speed of SRAM in program execution.</p>&#13;
<div class="box">&#13;
<p class="box-title"><strong>YOUR TURN</strong></p>&#13;
<p class="box-list" id="ch8exe3">8.3     Derive the equation for <em>D(Store, d<sub>i</sub>, r<sub>i</sub>)</em> from <a href="ch08.xhtml#ch8tab2">Table 8-2</a>.</p>&#13;
</div>&#13;
<h3 class="h3" id="ch08lev1sec3"><strong>What You’ve Learned</strong></h3>&#13;
<p class="noindentin"><strong>Memory hierarchy</strong>   Computer storage is organized such that smaller amounts of faster, more costly memory are located closer to the CPU. Smaller amounts of program instructions and data are copied to the successively faster memory levels as a program executes. This works <span epub:type="pagebreak" id="page_165"/>because there is a very high probability that the next memory location needed by a program will be at an address close to the current one.</p>&#13;
<p class="noindentin"><strong>Registers</strong>   A few thousand bytes of memory located in the CPU that are accessed at the same speed as the CPU. Implemented in flip-flops.</p>&#13;
<p class="noindentin"><strong>Cache</strong>   Thousands to millions of bytes of memory outside the CPU, but often on the same chip. Cache memory is slower than the CPU but is synchronized with it. It is often organized in levels, with faster, smaller amounts closer to the CPU. The cache is usually implemented using SRAM.</p>&#13;
<p class="noindentin"><strong>Main memory</strong>   Hundreds of millions to billions of bytes of memory separate from the CPU. Main memory is much slower than the CPU but is synchronized with it. It is usually implemented using DRAM.</p>&#13;
<p class="noindentin"><strong>Static random-access memory (SRAM)</strong>   Uses flip-flops to store bits. SRAM is fast but expensive.</p>&#13;
<p class="noindentin"><strong>Dynamic random-access memory (DRAM)</strong>   Uses capacitors to store bits. DRAM is slow but has a much lower cost than SRAM.</p>&#13;
<p class="indenta">In the next chapter, you will learn how the CPU in the Raspberry Pi is organized from a programmer’s point of view.<span epub:type="pagebreak" id="page_166"/></p>&#13;
</div>
</div>
</body></html>