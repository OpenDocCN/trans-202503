- en: Part I
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一部分
- en: Concepts
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概念
- en: '1'
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Foundations
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 基础
- en: Honesty is a foundation, and it’s usually a solid foundation. Even if I do get
    in trouble for what I said, it’s something that I can stand on.
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 诚实是一种基础，通常是一个坚实的基础。即使因我所说的话惹上麻烦，那也是我能够站得住脚的东西。
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Charlamagne tha God
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: —查尔马涅·撒·神
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: Software security is at once a logical practice and an art, one based on intuitive
    decision making. It requires an understanding of modern digital systems, but also
    a sensitivity to the humans interacting with, and affected by, those systems.
    If that sounds daunting, then you have a good sense of the fundamental challenge
    this book endeavors to explain. This perspective also sheds light on why software
    security has continued to challenge the field for so long, and why the solid progress
    made so far has taken so much effort, even if it has only chipped away at some
    of the problems. Yet there is very good news in this state of affairs, because
    it means that all of us can make a real difference by increasing our awareness
    of, and participation in, better security at every stage of the process.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 软件安全既是一种逻辑实践，也是一种艺术，基于直觉决策。它需要理解现代数字系统，但也需要对与这些系统互动并受其影响的人们保持敏感。如果这听起来令人生畏，那么你对本书所要解释的基本挑战有了很好的认识。这个视角也能解释为什么软件安全长久以来一直挑战这一领域，以及即使取得了一些进展，所付出的努力依然巨大，尽管它只解决了部分问题。然而，在这种情况下有一个好消息，因为这意味着我们所有人都可以通过提高对更好安全性的意识和参与，真正地在过程的每个阶段产生影响。
- en: 'We begin by considering what security exactly is. Given security’s subjective
    nature, it’s critical to think clearly about its foundations. This book represents
    my understanding of the best thinking out there, based on my own experience. Trust
    undergirds all of security, because nobody works in a vacuum, and modern digital
    systems are far too complicated to be built single-handedly from the silicon up;
    you have to trust others to provide everything (starting with the hardware, firmware,
    operating system, and compilers) that you don’t create yourself. Building on this
    base, next I present the six classic principles of security: the three components
    of classic information security and the three-part “Gold Standard” used to enforce
    it. Finally, the section on information privacy adds important human and societal
    factors necessary to consider as digital products and services become increasingly
    integrated into the most sensitive realms of modern life.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从考虑安全到底是什么开始。鉴于安全的主观性质，清楚地思考其基础至关重要。本书代表了我基于自己经验的最佳思考理解。信任是所有安全的基础，因为没有人能在真空中工作，现代数字系统复杂得无法单独从硅开始构建；你必须信任他人提供你没有自己创造的一切（从硬件、固件、操作系统到编译器）。在此基础上，我接下来介绍六个经典的安全原则：经典信息安全的三个组成部分和用于实施它的三部分“黄金标准”。最后，关于信息隐私的部分增加了重要的人类和社会因素，这些因素在数字产品和服务越来越多地融入现代生活的最敏感领域时必须考虑。
- en: Though readers doubtlessly have good intuitions about what words such as *security*,
    *trust*, or *confidentiality* mean, in this book these words take on specific
    technical meanings worth teasing out carefully, so I suggest reading this chapter
    closely. As a challenge to more advanced readers, I invite you to attempt to write
    better descriptions yourself—no doubt it will be an educational exercise for everyone.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管读者无疑对*安全*、*信任*或*保密性*等词汇有良好的直觉理解，但在本书中，这些词汇有特定的技术含义，值得仔细探讨，因此建议认真阅读本章。作为对更高级读者的挑战，我邀请你们尝试自己写出更好的描述——无疑这将是一个对大家都有教育意义的练习。
- en: Understanding Security
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解安全
- en: All organisms have natural instincts to chart a course away from danger, defend
    against attacks, and aim toward whatever sanctuary they can find.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所有生物都有本能，能够避开危险，防御攻击，并朝向任何可以找到的避难所前进。
- en: It is important to appreciate just how remarkable our innate sense of physical
    security is, when it works. By contrast, we have few genuine signals to work with
    in the virtual world—and fake signals are easily fabricated. Before we approach
    security from a technical perspective, let’s consider a real-world story as an
    illustration of what humans are capable of. (As we’ll see later, in the digital
    domain we need a whole new set of skills.)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须意识到，当我们的天生物理安全感正常工作时，它是多么出色。相比之下，在虚拟世界中，我们很少有真正的信号可以依赖——而假信号很容易被伪造。在从技术角度考虑安全之前，让我们通过一个真实的故事来说明人类能做些什么。（正如我们稍后将看到的，在数字领域，我们需要一整套全新的技能。）
- en: 'The following is a true story from an auto salesman. After conducting a customer
    test drive, the salesman and customer returned to the lot. The salesman got out
    of the car and continued to chat with the customer while walking around to the
    front of the car. “When I looked him in the eyes,” the salesman recounted, “That’s
    when I said, ‘Oh no. This guy’s gonna try and steal this car.’” Events accelerated:
    the customer-turned-thief put the car in gear and sped away while the salesman
    hung on for the ride of his life *on the hood of the car*. The perpetrator drove
    violently in an unsuccessful attempt to throw him from the vehicle. (Fortunately,
    the salesman sustained no major injuries and the criminal was soon arrested, convicted,
    and ordered to pay restitution.)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个来自汽车销售员的真实故事。在进行了一次客户试驾后，销售员和客户返回了停车场。销售员下车并继续与客户交谈，同时绕到车前。“当我与他对视时，”销售员回忆道，“那一刻我意识到，‘哦不，这家伙要偷这辆车。’”
    事件加速发展：那位变成小偷的客户将车挂档并飞驰而去，而销售员则紧紧抓住车头，经历了人生中最惊险的“车顶之旅”。犯罪分子驾车猛烈加速，企图把他甩下车外。（幸运的是，销售员没有受到严重伤害，犯罪嫌疑人很快被逮捕、定罪并被要求赔偿。）
- en: A subtle risk calculation took place when those men locked eyes. Within fractions
    of a second, the salesman had processed complex visual signals, derived from the
    customer’s facial expression and body language, distilling into a clear intention
    of a hostile action. Now imagine that the same salesman was the target of a *spear
    phishing* attack (a fraudulent email designed to fool a specific target, as opposed
    to a mass audience). In the digital realm, without the signals he detected when
    face-to-face with his attacker, he’d be much more easily tricked.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当那两个人对视时，一种微妙的风险计算已经发生。在短短几分之一秒的时间里，那位销售员处理了复杂的视觉信号，这些信号来自客户的面部表情和肢体语言，最终提炼出了一个明确的敌对行为意图。现在，假设这位销售员成了*鱼叉式网络钓鱼*攻击的目标（这种欺诈性电子邮件旨在愚弄特定目标，而不是大众）。在数字世界里，没有了面对面与攻击者互动时所能感知到的信号，他会更容易上当受骗。
- en: When it comes to information security, computers, networks, and software, we
    need to think analytically to assess the risks we face if we want to have any
    hope of securing digital systems. And we must do this despite being unable to
    directly see, smell, or hear bits or code. Whenever you’re examining data online,
    you’re using software to display information in human-readable fonts, and typically,
    there’s a lot of code between you and the actual bits; in fact, it’s potentially
    a hall of mirrors. So you must trust your tools and trust that you really are
    examining the data you think you are.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到信息安全、计算机、网络和软件时，我们需要进行分析性思考，评估我们所面临的风险，如果我们想要确保数字系统的安全，必须如此。即使我们无法直接看到、闻到或听到比特或代码，我们也必须这样做。每当你在网上检查数据时，你是在使用软件将信息以人类可读的字体显示出来，通常，你和实际的比特之间有大量的代码；事实上，它可能是一面镜子迷宫。所以，你必须信任你的工具，并相信你真的在检查你认为自己在检查的数据。
- en: Software security centers on the protection of digital assets against an array
    of threats, an effort largely driven by a basic set of security principles that
    the rest of this chapter will discuss. By analyzing a system from these first
    principles, we can learn how vulnerabilities slip into software, as well as how
    to proactively avoid and mitigate problems. These foundational principles, along
    with other design techniques covered in subsequent chapters, apply not only to
    software but also to designing and operating bicycle locks, bank vaults, or prisons.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 软件安全的核心在于保护数字资产免受各种威胁，这一努力在很大程度上是由一组基本的安全原则驱动的，本章的其余部分将讨论这些原则。通过从这些基本原理出发分析系统，我们可以了解漏洞是如何进入软件的，并且如何主动避免和减轻问题。这些基础原则，以及后续章节中涉及的其他设计技术，适用于不仅仅是软件，还适用于自行车锁、银行金库或监狱的设计和运营。
- en: The term *information security* refers specifically to the protection of data
    and how access is granted. *Software security* is a broader term that focuses
    on the design, implementation, and operation of software systems that are trustworthy,
    including the reliable enforcement of information security.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*信息安全*一词专指数据保护及其访问权限的授予。*软件安全*是一个更广泛的术语，侧重于可信的软件系统的设计、实现和操作，包括对信息安全的可靠执行。'
- en: Trust
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信任
- en: Trust is equally critical in the digital realm, yet too often taken for granted.
    Software security ultimately depends on trust, because you cannot control every
    part of a system, write all of your own software, or vet all suppliers of dependencies.
    Modern digital systems are so complex that not even the major tech giants can
    build a complete technology stack from scratch. From the silicon to the operating
    systems, networking, peripherals, and the numerous software layers that make it
    all work, the systems we rely on routinely are remarkable technical accomplishments
    of immense size and complexity. Since nobody can build these systems all by themselves,
    organizations rely on hardware and software products often chosen based on features
    or pricing—but it’s important to remember that each dependency also involves a
    *trust decision*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在数字领域，信任同样至关重要，但往往被视为理所当然。软件安全最终依赖于信任，因为你无法控制系统的每个部分，无法编写所有自己的软件，也无法审查所有依赖的供应商。现代数字系统复杂到即便是大型科技巨头也无法从零开始构建完整的技术栈。从硅芯片到操作系统、网络、外设，以及使这一切运作的众多软件层，构成我们日常依赖的系统是巨大的技术成就，规模庞大且复杂。由于没有人能够独自构建这些系统，组织依赖于硬件和软件产品，这些产品通常是根据特性或价格来选择的——但重要的是要记住，每一个依赖也都涉及一个*信任决策*。
- en: 'Security demands that we examine these trust relationships closely, even though
    nobody has the time or resources to investigate and verify everything. Failing
    to trust enough means doing a lot of needless work to protect a system when no
    real threat is likely. On the other hand, trusting too freely could mean getting
    blindsided later. Put bluntly, when you fully trust an entity, they are free to
    fail without consequences. Trust can be violated in two fundamentally different
    ways: by malice (cheating, lying, subterfuge) and by incompetence (mistakes, misunderstandings,
    negligence).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性要求我们仔细审视这些信任关系，尽管没有人有足够的时间或资源去调查和验证每一件事。不足够信任意味着在没有真实威胁的情况下，为保护系统做大量无谓的工作。另一方面，过度信任可能意味着之后被突然击中。直白地说，当你完全信任一个实体时，他们可以在没有后果的情况下失败。信任可以通过两种根本不同的方式被破坏：恶意（欺骗、撒谎、诡计）和无能（错误、误解、疏忽）。
- en: The need to make critical decisions in the face of incomplete information is
    precisely what trust is best suited for. But our innate sense of trust relies
    on subtle sensory inputs wholly unsuited to the digital realm. The following discussion
    begins with the concept of trust itself, dissects what trust as we experience
    it is, and then shifts to trust as it relates to software. As you read along,
    try to find the common threads and connect how you think about software to your
    intuitions about trust. Tapping into your existing trust skills is a powerful
    technique that over time gives you a gut feel for software security that is more
    effective than any amount of technical analysis.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在面对不完全信息时做出关键决策正是信任最适用的领域。但我们天生的信任感依赖于微妙的感官输入，这些输入完全不适用于数字领域。以下讨论从信任本身的概念开始，剖析我们体验中的信任是什么，然后转向信任与软件的关系。当你阅读时，试着找到其中的共通点，并将你对软件的理解与对信任的直觉联系起来。利用你现有的信任技能是一种强大的技巧，随着时间的推移，它将为你提供对软件安全的直觉感知，这比任何技术分析都更加有效。
- en: Feeling Trust
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 体验信任
- en: The best way to understand trust is to pay attention while experiencing what
    relying on trust actually feels like. Here’s a thought experiment—or an exercise
    to try for real, with someone you *really trust*—that brings home exactly what
    trust means. Imagine walking along a busy thoroughfare with a friend, with traffic
    streaming by only a few feet away. Sighting a crosswalk up ahead, you explain
    that you would like them to guide you across the road, that you are relying on
    them to cross safely, and that you are closing your eyes and will obediently follow
    them. Holding hands, you and your friend proceed to the crosswalk, where they
    gently turn you to face the road, gesturing by touch that you should wait. Listening
    to the sounds of speeding cars, you know well that your friend (and now, guardian)
    is waiting until it is safe to cross, but your heartbeat has most likely also
    increased noticeably, and you may find yourself listening attentively for any
    sound of impending danger.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 理解信任的最佳方式是留意在依赖信任时真实的感受。这里有一个思维实验——或者一个真实的练习，可以和你*真正信任*的人一起尝试——它能真正帮助你理解信任的意义。想象一下，你和朋友一起走在繁忙的马路上，车流从几英尺远的地方呼啸而过。你们前方看到一个人行横道，你告诉朋友你希望他们带你安全过马路，你会闭上眼睛，完全依赖他们。你和朋友牵手走到人行横道，朋友轻轻地转你面向马路，用触碰的方式示意你等一等。你能听到快速行驶的车辆声，你清楚知道你的朋友（现在是你的保护者）会等到安全时才会带你过马路，但你的心跳可能也明显加速了，你可能会专心聆听任何即将来临的危险声。
- en: Now your friend unmistakably leads you forward, guiding you to step down from
    the curb. If you decide to step into the road with your eyes closed, what you
    are feeling is pure trust—or perhaps some degree of the lack thereof. Your mind
    keenly senses palpable risk, your senses strain to confirm safety directly, and
    something deep down is warning you not to do it. Your own internal security monitoring
    system has insufficient evidence and wants you to open your eyes before moving;
    what if your friend somehow misjudges the situation, or worse, is playing a deadly
    evil trick on you? Ultimately, it’s the trust you have invested in your friend
    that allows you to override those instincts and cross the road.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你的朋友毫不犹豫地引导你前进，带你从路缘下去。如果你决定闭着眼睛走进马路，你所感受到的是纯粹的信任——或者说，某种程度的缺乏信任。你的大脑敏锐地感知到明显的风险，你的感官竭力确认安全，内心深处有某种东西在警告你不要这么做。你自己的内部安全监控系统没有足够的证据，并希望你在行动前睁开眼睛；如果你的朋友误判了情况，或者更糟的是，正在对你施展一个致命的恶作剧，你该怎么办？最终，正是你对朋友的信任，让你能够超越这些本能，穿过马路。
- en: Raise your own awareness of digital trust decisions, and help others see how
    important their impact is on security. Ideally, when you select a component or
    choose a vendor for a critical service, you’ll be able to tap into the very same
    intuitions that guide trust decisions like in the exercise just described.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 提高你对数字信任决策的意识，并帮助他人意识到它们对安全的重要影响。理想情况下，当你选择一个组件或为关键服务选择供应商时，你将能够依赖于像刚才描述的练习中所使用的那些直觉来指导信任决策。
- en: You Cannot See Bits
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你看不见比特
- en: All of this discussion is to emphasize the fact that when you think you are
    “looking directly at the data,” you are actually looking at a distant representation.
    In fact, you are looking at pixels on a screen that you believe represent the
    contents of certain bytes whose physical location you don’t know with any precision,
    and many millions of instructions were likely executed in order to map the data
    into the human-legible form on your display. Digital technology makes trust especially
    tricky, because it’s so abstract, lightning fast, and hidden from direct view.
    Whenever you examine data, remember that there is a lot of software and hardware
    between the actual data in memory and the pixels that form characters that we
    interpret as the data value. If something in there were maliciously misrepresenting
    the actual data, how would you possibly know? Ground truth about digital information
    is extremely difficult to observe directly.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些讨论旨在强调这样一个事实：当你认为自己是在“直接查看数据”时，实际上你是在查看一个远程的表示。事实上，你看到的是屏幕上的像素，你相信它们代表了某些字节的内容，而这些字节的物理位置你并不知道，可能在映射数据到你显示器上可读形式的过程中执行了数百万条指令。数字技术使得信任特别棘手，因为它如此抽象、快速，并且对直接观察来说是隐藏的。每当你检查数据时，记住，实际的数据在内存中与形成字符的像素之间，有大量的软件和硬件。如果其中有什么恶意地错误地表现出实际数据，你怎么可能知道呢？关于数字信息的实际真相是极其难以直接观察到的。
- en: 'Consider the lock icon in the address bar of a web browser indicating a secure
    connection to the website. The appearance or absence of these distinctive pixels
    communicates a single bit to the user: safe or unsafe. Behind the scenes, there
    is a lot of data and considerable computation, as will be detailed in Chapter
    11, all rolling up into a binary yes/no security indication. Even an expert developer
    would face a Herculean task attempting to manually confirm the validity of just
    one instance. So all we can do is trust the software—and there is every reason
    that we should trust it. The point here is to recognize how deep and pervasive
    that trust is, not just take it for granted.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 想一想网页浏览器地址栏中的锁形图标，它表示与网站的安全连接。这个标志的出现或缺失向用户传达了一个简单的信息：安全或不安全。在幕后，存在大量的数据和相当复杂的计算，正如第11章将详细说明的那样，所有这些都汇总成一个二进制的“是/否”安全指示。即使是专家开发者也会面临一项艰巨的任务，试图手动确认仅仅一个实例的有效性。所以我们能做的只是信任软件——而且我们完全有理由信任它。这里的关键是要认识到这种信任有多么深远和普遍，而不是理所当然地接受它。
- en: Competence and Imperfection
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 能力与不完美
- en: Most attacks begin by exploiting a software flaw or misconfiguration that resulted
    from the honest, good faith efforts of programmers and IT staff, who happen to
    be human, and hence imperfect. Since licenses routinely disavow essentially all
    liability, all software is used on a *caveat emptor* basis. If, as is routinely
    claimed, “all software has bugs,” then a subset of those bugs will be exploitable,
    and eventually the attackers will find a few of those bugs and have an opportunity
    to use them maliciously. It’s relatively rare for software professionals to fall
    victim to an attack due to misplaced trust in malicious software, enabling a direct
    attack.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数攻击开始时会利用软件缺陷或配置错误，而这些缺陷或错误通常是出于程序员和 IT 员工的诚意和善意努力所导致的，而他们也是人类，因此不完美。由于许可证通常明确声明几乎所有的责任，因此所有软件都是基于*买者自负其责*的原则使用的。如果，正如人们常说的，“所有软件都有漏洞”，那么其中一部分漏洞就会被利用，最终攻击者会找到一些漏洞并有机会恶意使用它们。软件专业人员因对恶意软件的错误信任而成为攻击受害者并进行直接攻击的情况相对较少。
- en: Fortunately, making big trust decisions about operating systems and programming
    languages is usually easy. Many large corporations have extensive track records
    of providing and supporting quality hardware and software products, and it’s quite
    reasonable to trust them. Trusting others with less of a track record might be
    riskier. While they likely have many skilled and motivated people working diligently,
    the industry’s lack of transparency makes the security of their products difficult
    to judge. Open source provides transparency, but depends on the degree of supervision
    the project owners provide as a hedge against contributors slipping in code that
    is buggy or even outright malicious. Remarkably, no software company even attempts
    to distinguish itself by promising higher levels of security or indemnification
    in the event of an attack, so as customers we have no such options. Legal, regulatory,
    and business agreements all provide additional ways of mitigating the uncertainty
    around trust decisions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，关于操作系统和编程语言做出重大信任决策通常是容易的。许多大公司在提供和支持优质硬件和软件产品方面有着丰富的业绩记录，信任它们是非常合理的。信任那些缺乏业绩记录的公司可能会更有风险。虽然他们可能有很多熟练且积极的人员在努力工作，但行业缺乏透明度使得评估其产品安全性变得困难。开源提供了透明度，但依赖于项目所有者提供的监督程度，以防止贡献者插入有缺陷甚至是恶意的代码。值得注意的是，没有任何软件公司尝试通过承诺更高的安全性或在攻击事件中提供赔偿来与众不同，因此作为客户，我们没有这样的选择。法律、监管和商业协议为我们提供了额外的方式来减轻信任决策中的不确定性。
- en: Take trust decisions seriously, but recognize that nobody gets it right 100
    percent of the time. The bad news is that these decisions will always be imperfect,
    because, as the US Securities and Exchange Commission warns us, “past performance
    does not guarantee future results.” The good news is that people are highly evolved
    to gauge trust—though it works best face-to-face, decidedly not via digital media—and
    in the vast majority of cases we do make the right trust decisions, provided we
    have accurate information and act with intention.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 认真对待信任决策，但要认识到没有人能够 100% 准确地做出判断。坏消息是，这些决策永远不完美，因为正如美国证券交易委员会警告我们的那样，“过去的表现不能保证未来的结果”。好消息是，人类在判断信任方面高度进化——尽管这种判断在面对面交流时效果最佳，而绝非通过数字媒介——在绝大多数情况下，只要我们拥有准确信息并有意识地采取行动，我们通常能够做出正确的信任决策。
- en: Trust Is a Spectrum
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 信任是一个光谱
- en: 'Trust is always granted in degrees, and trust assessments always have some
    uncertainty. At the far end of the spectrum, such as when undergoing major surgery,
    we may literally entrust our lives to medical professionals, willingly ceding
    not just control over our bodies but our very consciousness and ability to monitor
    the operation. In the worst case scenario, if they should fail us and we do not
    survive, we literally have no recourse whatsoever (legal rights of our estate
    aside). Everyday trust is much more limited: credit cards have limits to cap the
    bank’s potential loss on nonpayment, while cars have valet keys so we can limit
    access to the trunk.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 信任总是以不同程度授予的，且信任评估总是存在一定的不确定性。在信任的最远端，比如在进行重大手术时，我们可能会将我们的生命字面意思地交给医疗专业人员，甘愿放弃对我们身体的控制，不仅仅是身体控制，还有对手术过程的意识和监控能力。在最坏的情况下，如果他们未能帮助我们，且我们没有幸存下来，我们实际上没有任何救济途径（法律上的遗产权除外）。日常信任则要有限得多：信用卡有额度限制，以防止银行因未付款而承担过大损失，而汽车则有代客钥匙，以便我们限制对后备箱的访问。
- en: Since trust is a spectrum, a “trust but verify” policy is a useful tool that
    bridges the gap between full trust and complete distrust. In software, you can
    achieve this through the combination of authorization and diligent auditing. Typically,
    this involves a combination of *automated auditing* (to accurately check a large
    volume of mostly repetitive activity logs) and *manual auditing* (spot checking,
    handling exceptional cases, and having a human in the loop to make final decisions).
    We’ll cover auditing in more detail later in this chapter.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于信任是一个连续体，“信任但验证”的政策是一个有用的工具，它弥合了完全信任和完全不信任之间的鸿沟。在软件中，你可以通过授权和严格审计的结合来实现这一点。通常，这涉及到*自动化审计*（准确检查大量大部分重复的活动日志）和*手动审计*（抽查、处理例外情况，并有人工参与做出最终决策）。我们将在本章稍后部分详细讨论审计。
- en: Trust Decisions
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 信任决策
- en: 'In software, you have a binary choice: to trust, or not to trust? While some
    systems do enforce a variety of permissions on applications, you still need to
    either allow or disallow each given permission. When in doubt, you can safely
    err on the side of distrusting, so long as at least one candidate solution reasonably
    gains your trust. If you are too demanding in your assessments, and no product
    can gain your trust, then you are stuck with the prospect of building the component
    yourself.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件中，你面临一个二选一的决定：信任，还是不信任？虽然一些系统确实会对应用程序施加多种权限限制，但你仍然需要决定是否允许或拒绝每个特定权限。在犹豫时，你可以安全地选择不信任，只要至少有一个候选方案能够合理地赢得你的信任。如果你对评估要求过高，没有任何产品能够获得你的信任，那么你只能面对自己构建组件的前景。
- en: 'Think of making trust decisions as cutting branches off a decision tree that
    otherwise would be effectively infinite. When you can trust a service or computer
    to be secure, that saves you the effort of doing deeper analysis. On the other
    hand, if you are reluctant to trust, then you need to build and secure more parts
    of the system, including all subcomponents. [Figure 1-1](#figure1-1) illustrates
    an example of making a trust decision. If there is no available cloud storage
    service you would fully trust to store your data, then you must operate the service
    yourself, and this entails further trust decisions: to use a trusted hosting service
    or do it yourself, and to use existing database software that you trust or write
    it yourself. Note that when you don’t trust a provider then more trust decisions
    are sure to follow since you cannot do everything.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 将信任决策视为从决策树上剪掉分支，否则决策树会变得几乎无穷大。当你可以信任一个服务或计算机是安全的时，你就节省了进行更深入分析的精力。另一方面，如果你不愿意信任，那么你需要构建并保护更多的系统部分，包括所有子组件。[图1-1](#figure1-1)展示了一个做出信任决策的示例。如果没有一个你完全信任的云存储服务来存储你的数据，那么你必须自己运营这个服务，这涉及到更多的信任决策：选择一个你信任的托管服务，还是自己做，以及选择一个你信任的现有数据库软件，还是自己编写。请注意，当你不信任一个提供商时，更多的信任决策一定会随之而来，因为你无法做到所有事情。
- en: For explicitly distrusted inputs—which should include virtually all inputs,
    especially anything from the public internet or any client—treat that data with
    suspicion and the highest levels of care (for more on this, see “Reluctance to
    Trust” on page 68 in Chapter 4). Even for trusted inputs, it can be risky to assume
    they are perfectly reliable. Consider opportunistically adding safety checks when
    it’s easy to do so, if only to reduce the fragility of the overall system and
    to prevent the propagation of errors in the event of an innocent bug.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于明确不信任的输入——这应包括几乎所有输入，特别是来自公共互联网或任何客户端的内容——应当以怀疑态度和最高的谨慎度来处理这些数据（关于这一点，详见第4章第68页的“对信任的犹豫”）。即使是可信的输入，也不能假设它们是完全可靠的。考虑在容易实现的情况下，适时添加安全检查，即使只是为了减少整体系统的脆弱性，并在遇到无意的错误时防止错误的传播。
- en: '![f01001](image_fi/501928c01/f01001.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![f01001](image_fi/501928c01/f01001.png)'
- en: 'Figure 1-1: An example of a decision tree with trust decisions'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图1-1：一个关于信任决策的决策树示例
- en: Implicitly Trusted Components
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 隐式信任的组件
- en: Every software project relies on an extensive stack of technology that is *implicitly
    trusted*, including hardware, operating systems, development tools, libraries,
    and other dependencies that are impractical to vet, so we trust them based on
    the reputation of the vendor. Nonetheless, you should maintain some sense of what
    is implicitly trusted, and give these decisions due consideration, especially
    before greatly expanding the scope of implicit trust.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 每个软件项目都依赖于一个庞大的技术栈，这些技术栈是*隐式信任*的，包括硬件、操作系统、开发工具、库和其他难以验证的依赖项，因此我们基于供应商的声誉来信任它们。然而，你应当保持对什么是隐式信任的基本理解，并在大规模扩大隐式信任的范围之前，认真考虑这些决策。
- en: 'There are no simple techniques for managing implicit trust, but here is an
    idea that can help: minimize the number of parties you trust. For example, if
    you are already committed to using Microsoft (or Apple, and so forth) operating
    systems, lean toward using their compilers, libraries, applications, and other
    products and services, so as to minimize your exposure. The reasoning is roughly
    that trusting additional companies increases the opportunities for any of these
    companies to let you down. Additionally, there is the practical aspect that one
    company’s line of products tend to be more compatible and better tested when used
    together.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 没有简单的方法可以管理隐式信任，但这里有一个有帮助的想法：最小化你信任的各方数量。例如，如果你已经决定使用微软（或苹果等）操作系统，倾向于使用它们的编译器、库、应用程序和其他产品与服务，以最小化暴露的风险。其大致原理是，信任更多公司会增加这些公司让你失望的机会。此外，实际上，一家公司的一系列产品往往在一起使用时更加兼容且经过更好的测试。
- en: Being Trustworthy
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 值得信赖
- en: Finally, don’t forget the flip side of making trust decisions, which is to *promote*
    trust when you offer products and services. Every software product must convince
    end users that it’s trustworthy. Often, just presenting a solid professional image
    is all it takes, but if the product is fulfilling critical functions, it’s crucial
    to give customers a solid basis for that trust.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，不要忘记做出信任决策的另一面，即在提供产品和服务时，*促进*信任。每个软件产品必须说服最终用户它是值得信任的。通常，仅仅展示一个扎实的专业形象就足够了，但如果该产品履行的是关键功能，那么为客户提供一个扎实的信任基础至关重要。
- en: 'Here are some suggestions of basic ways to enhance trust in your work:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些增强工作中信任的基本建议：
- en: Transparency engenders trust. Working openly allows customers to assess the
    product.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 透明度能够培养信任。公开工作使客户能够评估产品。
- en: Involving a third party builds trust through their independence (for example,
    using hired auditors).
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入第三方通过其独立性来建立信任（例如，使用雇佣的审计员）。
- en: Sometimes your product is the third party that integrates with other products.
    Trust grows because it’s difficult for two parties with an arm’s-length relationship
    to collude.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时你的产品是与其他产品集成的第三方。信任逐渐建立，因为两个具有独立关系的各方之间很难串通。
- en: When problems do arise, be open to feedback, act decisively, and publicly disclose
    the results of any investigation and steps taken to prevent recurrences.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当问题出现时，要虚心接受反馈，果断行动，并公开披露任何调查结果以及为防止问题再次发生所采取的措施。
- en: Specific features or design elements can make trust visible—for example, an
    archive solution that shows in real time how many backups have been saved and
    verified at distributed locations.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特定的功能或设计元素可以使信任变得可见——例如，实时显示已保存并验证的备份数量的归档解决方案，展示分布式位置的备份情况。
- en: Actions beget trust, while empty claims, if anything, erode trust for savvy
    customers. Provide tangible evidence of being trustworthy, ideally in a way that
    customers can potentially verify for themselves. Even though few will actually
    vet the quality of open source code, knowing that they could (and assuming others
    likely are doing so) is nearly as convincing.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 行动产生信任，而空洞的声明则会削弱精明客户的信任。提供可以验证的可信证据，理想情况下以客户自己可以验证的方式。尽管很少有人会真正审核开源代码的质量，但知道他们可以审核（并且假设其他人也在这么做）几乎同样有说服力。
- en: Classic Principles
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 经典原则
- en: 'The guiding principles of information security originated in the early days
    of computing, when computers were emerging from special locked, air-conditioned,
    raised-floor rooms and starting to be connected in networks. These traditional
    models are the “Newtonian physics” of modern information security: a good and
    simple guide for many applications, but not the be-all and end-all. For example,
    information privacy is one of the more nuanced considerations for modern data
    protection and stewardship that traditional information security principles do
    not cover.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 信息安全的指导原则起源于计算机发展的初期，当时计算机刚从特殊的锁闭、空调、架空地板的房间中出来，开始连接到网络。这些传统模型是现代信息安全的“牛顿物理学”：适用于许多应用的良好且简明的指南，但并不是万能的。例如，信息隐私是现代数据保护和管理中一个更为细致的考虑，而传统的信息安全原则并未涵盖这一点。
- en: The foundational principles group nicely into two sets of three. The first three
    principles, which I will call *C-I-A*, define data access requirements; the other
    three, in turn, concern how access is controlled and monitored. We call these
    the *Gold Standard*. The two sets of principles are interdependent, and only as
    a whole do they protect data assets.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 基本原则可以很好地分为两组，每组三条。前三条原则，我称之为*C-I-A*，定义了数据访问的要求；另外三条则涉及如何控制和监控访问。我们将这三条原则称为*黄金标准*。这两组原则是相互依赖的，只有整体考虑，才能保护数据资产。
- en: Beyond the prevention of unauthorized data access lies the question of who or
    what components and systems should be entrusted with access. This is a harder
    question of trust, and ultimately beyond the scope of information security, even
    though confronting it is unavoidable in order to secure any digital system.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 除了防止未经授权的数据访问外，还存在一个问题，即应该信任谁或哪些组件和系统可以访问数据。这是一个更复杂的信任问题，最终超出了信息安全的范围，尽管面对这个问题是确保任何数字系统安全不可避免的部分。
- en: Information Security’s C-I-A
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 信息安全的C-I-A
- en: 'We traditionally build software security on three basic principles of information
    security: *confidentiality*, *integrity*, and *availability*. Formulated around
    the fundamentals of data protection, the individual meanings of the three pillars
    are intuitive:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传统上建立软件安全是基于信息安全的三个基本原则：*保密性*、*完整性*和*可用性*。这三大支柱围绕数据保护的基本原则制定，它们的含义直观易懂：
- en: '**Confidentiality**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**保密性**'
- en: Allow only authorized data access—don’t leak information.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅允许授权的数据访问——不泄露信息。
- en: '**Integrity**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**完整性**'
- en: Maintain data accurately—don’t allow unauthorized modification or deletion.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准确维护数据——不允许未经授权的修改或删除。
- en: '**Availability**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**可用性**'
- en: Preserve the availability of data—don’t allow significant delays or unauthorized
    shutdowns.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 维护数据的可用性——不允许显著的延迟或未经授权的关停。
- en: Each of these brief definitions describes the goal and defenses against its
    subversion. In reviewing designs, it’s often helpful to think of ways one might
    undermine security, and work back to defensive measures.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 每个简短的定义都描述了目标和防御措施，以防止其被破坏。在审查设计时，常常有助于考虑可能破坏安全的方式，并从中找到防御措施。
- en: All three components of C-I-A represent ideals, and it’s crucial to avoid insisting
    on perfection. For example, an analysis of even solidly encrypted network traffic
    could allow a determined eavesdropper to deduce something about the communications
    between two endpoints, like the volume of data exchanged. Technically, this exchange
    of data weakens the confidentiality of interaction between the endpoints; but
    for practical purposes, we can’t fix it without taking extreme measures, and usually
    the risk is minor enough to be safely ignored. (One way to conceal the fact of
    communication is for endpoints to always exchange a constant volume of data, adding
    dummy packets as needed when actual traffic is lower.) What activity corresponds
    to the traffic, and how might an adversary use that knowledge? The next chapter
    explains similar threat assessments in detail.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: C-I-A的三个组成部分代表了理想，避免坚持完美至关重要。例如，甚至对加密的网络流量进行分析，决心的窃听者也可能推断出关于两个端点之间通信的某些信息，比如交换的数据量。从技术上讲，这种数据交换削弱了端点之间交互的机密性；但出于实际考虑，我们无法在不采取极端措施的情况下修复这个问题，而且通常这种风险足够小，可以安全地忽略。（一种隐藏通信事实的方法是让端点始终交换恒定量的数据，根据需要在实际流量较低时添加虚拟数据包。）流量对应的活动是什么？对手可能如何利用这些知识？下一章将详细解释类似的威胁评估。
- en: Notice that authorization is inherent in each component of C-I-A, which mandates
    only the right disclosures, modifications of data, or controls of availability.
    What constitutes “right” is an important detail, and an authorization policy needs
    to specify that, but it isn’t part of these fundamental data protection primitive
    concepts. That part of the story will be discussed in “The Gold Standard” starting
    on page 14.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，授权是C-I-A（机密性、完整性、可用性）每个组件的内在部分，它要求只有正确的披露、数据修改或可用性控制。什么构成“正确”是一个重要的细节，授权策略需要明确这一点，但它不是这些基本数据保护原语概念的一部分。有关这一部分的内容将在第14页的《黄金标准》中讨论。
- en: Confidentiality
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 机密性
- en: Maintaining confidentiality means disclosing private information in only an
    authorized manner. This sounds simple, but in practice it involves a number of
    complexities.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 保持机密性意味着以授权的方式披露私人信息。这听起来简单，但在实际操作中涉及许多复杂因素。
- en: First, it’s important to carefully identify what information to consider private.
    Design documents should make this distinction clear. While what counts as sensitive
    might sometimes seem obvious, it’s actually surprising how people’s opinions vary,
    and without an explicit specification, we risk misunderstanding. The safest assumption
    is to treat all externally collected information as private by default, until
    declared otherwise by an explicit policy that explains how and why the designation
    can be relaxed.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，重要的是仔细识别哪些信息应被视为私密。设计文档应明确这一区别。尽管什么算作敏感信息有时看起来似乎很明显，但实际上人们的看法差异很大，若没有明确的说明，我们可能会产生误解。最安全的假设是将所有外部收集的信息默认为私密，直到通过明确的政策声明并解释如何以及为什么放宽这一规定。
- en: 'Here are some oft-overlooked reasons to treat data as private:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了一些常常被忽视的将数据视为私密的原因：
- en: An end user might naturally expect their data to be private, unless informed
    otherwise, even if revealing it isn’t harmful.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 终端用户可能自然期望他们的数据是私密的，除非另行通知，即使披露这些数据并不会造成危害。
- en: People might enter sensitive information into a text field intended for a different
    use.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人们可能会在为不同用途设计的文本框中输入敏感信息。
- en: Information collection, handling, and storage might be subject to laws and regulations
    that many are unaware of. (For example, if Europeans browse your website, it may
    be subject to EU law, such as the General Data Protection Regulation.)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息的收集、处理和存储可能受到许多不为人知的法律和规定的约束。（例如，如果欧洲人浏览您的网站，可能需要遵循欧盟的法律，例如《通用数据保护条例》。）
- en: When handling private information, determine what constitutes proper access.
    Deciding when and how to disclose information is ultimately a trust decision,
    and it’s worth not only spelling out the rules, but also explaining the subjective
    choices behind those rules.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理私人信息时，需确定什么构成适当的访问权限。决定何时以及如何披露信息，最终是一个信任决策，这不仅需要明确规定规则，还需要解释这些规则背后的主观选择。
- en: 'Compromises of confidentiality happen on a spectrum. In a complete disclosure,
    attackers acquire an entire dataset, including metadata. At the lower end of the
    spectrum might be a minor disclosure of information, such as an internal error
    message or similar leak of no real consequence. As an example of a partial disclosure,
    consider the practice of assigning sequential numbers to new customers: a wily
    competitor can sign up as a new customer and get a new customer number from time
    to time, then compute the successive differences to learn the numbers of customers
    acquired during each interval. Any leakage of details about protected data is
    to some degree a confidentiality compromise.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 保密性妥协是一个连续的过程。在完全披露的情况下，攻击者会获取整个数据集，包括元数据。在该连续性较低的一端，可能是信息的轻微泄露，例如一个内部错误信息或类似的泄漏，实际上并不造成重大影响。作为部分泄露的例子，考虑将连续编号分配给新客户的做法：一个狡猾的竞争对手可以注册为新客户，并不时获得新的客户编号，然后计算相邻的差异，从而了解每个时间段内获得的客户数量。任何有关受保护数据的详细信息泄露，都会在某种程度上构成保密性的妥协。
- en: 'It’s so easy to underestimate the potential value of minor disclosures. Attackers
    might put data to use in a completely different way than the developers originally
    intended, and combining tiny bits of information can provide more powerful insights
    than any of the individual parts on their own. Learning someone’s ZIP code might
    not tell you much, but if you also know their approximate age and that they’re
    an MD, you could perhaps combine this information to identify the individual in
    a sparsely populated area—a process known as *deanonymization* or *reidentification*.
    By analyzing a supposedly anonymized dataset published by Netflix, researchers
    were able to match numerous user accounts to IMDb accounts: it turns out that
    your favorite movies are an effective means of unique personal identification.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易低估轻微泄露的潜在价值。攻击者可能会以与开发者最初意图完全不同的方式使用数据，且将小部分信息结合起来，往往能提供比任何单独部分更有力的洞察。知道某人的邮政编码可能并不能告诉你太多，但如果你还知道他们的近似年龄，并且他们是医学博士（MD），你也许可以将这些信息结合起来，识别出这个居住在稀疏地区的个人——这一过程被称为*去匿名化*或*重新识别*。通过分析Netflix发布的一个假定已匿名的数据集，研究人员能够将许多用户账户与IMDb账户匹配：事实证明，你最喜欢的电影是一个有效的独特个人身份标识手段。
- en: Integrity
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 完整性
- en: Integrity, used in an information security context, is simply the authenticity
    and accuracy of data, kept safe from unauthorized tampering or removal. In addition
    to protecting against unauthorized modification, an accurate record of the *provenance*
    of data—the original source, and any authorized changes made—can be an important,
    and stronger, assurance of integrity.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息安全的语境中，完整性只是指数据的真实性和准确性，防止未经授权的篡改或删除。除了防止未经授权的修改外，数据的*来源*记录——即原始来源和任何经过授权的修改——也是完整性的一个重要且更强的保证。
- en: One classic defense against many tampering attacks is to preserve versions of
    critical data and record their provenance. Simply put, keep good backups. Incremental
    backups can be excellent mitigations because they’re simple and efficient to put
    in place and provide a series of snapshots that detail exactly what data changed,
    and when. However, the need for integrity goes far beyond the protection of data,
    and often includes ensuring the integrity of components, server logs, software
    source code and versions, and other forensic information necessary to determine
    the original source of tampering when problems occur. In addition to limited administrative
    access controls, secure digests (similar to checksums) and digital signatures
    are also strong integrity checks, as explained in Chapter 5.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对许多篡改攻击的经典防御方法是保留关键数据的多个版本并记录它们的来源。简而言之，保持良好的备份。增量备份是非常有效的缓解措施，因为它们简单高效，能够提供一系列快照，详细记录数据发生变化的时间和内容。然而，完整性的需求远不止于数据的保护，通常还包括确保组件、服务器日志、软件源代码和版本的完整性，以及其他法医信息，以便在出现问题时确定篡改的原始来源。除了有限的管理员访问控制外，安全摘要（类似于校验和）和数字签名也是强有力的完整性检查方法，如第5章所述。
- en: Bear in mind that tampering can happen in many different ways, not necessarily
    by modifying data in storage. For instance, in a web application, tampering might
    happen on the client side, on the wire between the client and server, by tricking
    an authorized party into making a change, by modifying a script on the page, or
    in many other ways.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，篡改可以通过许多不同的方式发生，不一定只是修改存储中的数据。例如，在Web应用程序中，篡改可能发生在客户端、客户端和服务器之间的传输过程中、通过欺骗授权方进行更改、修改页面中的脚本，或以其他多种方式发生。
- en: Availability
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 可用性
- en: Attacks on availability are a sad reality of the internet-connected world and
    can be among the most difficult to defend against. In the simplest cases, the
    attacker may just send an exceptionally heavy load of traffic to the server, overwhelming
    it with what looks like valid uses of the service. This principle implies that
    information is *temporarily* unavailable; while data that is permanently lost
    is also unavailable, this is generally considered to be fundamentally a compromise
    of integrity.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对可用性的攻击是互联网连接世界中的一种悲哀现实，而且可能是最难防御的攻击之一。在最简单的情况下，攻击者可能仅仅是向服务器发送异常重的流量负载，用看似有效的服务请求淹没服务器。这一原则意味着信息是*暂时*不可用的；虽然永久丢失的数据也不可用，但通常被视为对完整性的根本妥协。
- en: Anonymous denial-of-service (DoS) attacks, often for ransom, threaten any internet
    service, posing a difficult challenge. To best defend against these attacks, host
    on large-scale services with infrastructure that stands up to heavy loads, and
    maintain the flexibility to move infrastructure quickly in the event of problems.
    Nobody knows how common or costly DoS attacks really are, since many victims resolve
    these incidents privately. But without a doubt, you should create detailed plans
    in advance to prepare for such incidents.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 匿名的拒绝服务（DoS）攻击，通常是为了勒索，威胁任何互联网服务，构成了一个巨大的挑战。为了最佳地防御这些攻击，应选择在大型服务平台上托管，拥有可以承受重负载的基础设施，并保持灵活性，在出现问题时迅速迁移基础设施。没有人知道DoS攻击的实际发生频率或代价，因为许多受害者会私下解决这些事件。但毫无疑问，你应该提前制定详细的应急计划来应对这种情况。
- en: Many other kinds of availability threats are possible as well. For a web server,
    a malformed request that triggers a bug, causing a crash or infinite loop, can
    devastate its service. Other attacks can also overload the storage, computation,
    or communication capacity of an application, or perhaps use patterns that break
    the effectiveness of caching, all of which pose serious issues. Unauthorized destruction
    of software, configuration, or data (even with backup, delays can result) also
    can adversely impact availability.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他类型的可用性威胁也是可能的。例如，对于一个网络服务器，一个格式错误的请求可能触发一个漏洞，导致崩溃或无限循环，从而使其服务无法正常运行。其他攻击还可能使应用程序的存储、计算或通信能力超负荷，或者利用破坏缓存有效性的模式，这些都会带来严重的问题。未经授权的软件、配置或数据破坏（即便有备份，也可能造成延迟）同样可能对可用性产生不利影响。
- en: The Gold Standard
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 金标准
- en: 'If C-I-A is the goal of secure systems, the Gold Standard describes the means
    to that end. *Aurum* is Latin for gold, hence the chemical symbol “Au,” and it
    just so happens that the three important principles of security enforcement start
    with those same two letters:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果C-I-A是安全系统的目标，那么金标准描述了实现这一目标的方法。*Aurum*是拉丁语中的“黄金”之意，因此其化学符号为“Au”，恰好安全执行的三个重要原则也都以这两个字母开头：
- en: '**Authentication**'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**认证**'
- en: High-assurance determination of the identity of a principal
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高保障地确定主体的身份
- en: '**Authorization**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**授权**'
- en: Reliably only allowing an action by an authenticated principal
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可靠地仅允许经过认证的主体执行操作
- en: '**Auditing**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**审计**'
- en: Maintaining a reliable record of actions by principals for inspection
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持对主体行为的可靠记录以供检查
- en: 'A *principal* is any reliably authenticated entity: a person, business or organization,
    government entity, application, service, device, or any other agent with the power
    to act.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*主体*是指任何经过可靠认证的实体：一个人、企业或组织、政府实体、应用程序、服务、设备，或任何其他具有执行能力的代理。'
- en: '*Authentication* is the process of reliably establishing the validity of the
    principal’s credentials. Systems commonly allow registered users to authenticate
    by proving that they know the password associated with their user account, but
    authentication can be much broader. Credentials may be something the principal
    knows (a password) or possesses (a smart card), or something they are (biometric
    data); we’ll talk more about credentials in the next section.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*身份验证*是可靠地确认主体凭证有效性的过程。系统通常允许注册用户通过证明他们知道与其账户相关联的密码来进行身份验证，但身份验证的范围可以更广泛。凭证可能是主体知道的某些信息（如密码）、拥有的某些物品（如智能卡），或者是主体的某些特征（如生物特征数据）；我们将在下一节中进一步讨论凭证。'
- en: Data access for authenticated principals is subject to *authorization* decisions,
    either allowing or denying their actions according to prescribed rules. For example,
    filesystems with access control settings may make certain files read-only for
    specific users. In a banking system, clerks may record transactions up to a certain
    amount, but might require a manager to approve larger transactions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 经过身份验证的主体的数据访问受到*授权*决策的约束，依据规定的规则，允许或拒绝其行为。例如，具有访问控制设置的文件系统可能会将某些文件设置为特定用户的只读文件。在银行系统中，职员可以记录一定金额以内的交易，但对于更大金额的交易，可能需要经理审批。
- en: If a service keeps a secure log that accurately records what principals do,
    including any failed attempts at performing some action, the administrators can
    perform a subsequent *audit* to inspect how the system performed and ensure that
    all actions are proper. Accurate audit logs are an important component of strong
    security, because they provide a reliable report of actual events. Detailed logs
    provide a record of what happened, shedding light on exactly what transpired when
    an unusual or suspicious event takes place. For example, if you discover that
    an important file is gone, the log should ideally provide details of who deleted
    it and when, providing a starting point for further investigation.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个服务保存了一个准确记录主体行为的安全日志，包括任何执行某些操作时的失败尝试，管理员可以进行随后的*审计*，检查系统的表现，确保所有操作都是正当的。准确的审计日志是强大安全性的重要组成部分，因为它们提供了实际事件的可靠报告。详细的日志提供了发生了什么的记录，能清晰地揭示在出现异常或可疑事件时发生的具体情况。例如，如果你发现一个重要的文件丢失，日志应该理想地提供删除该文件的人员及其时间的详细信息，为进一步调查提供起点。
- en: The Gold Standard acts as the enforcement mechanism that protects C-I-A. We
    defined confidentiality and integrity as protection against *unauthorized* disclosure
    or tampering, and availability is also subject to control by an authorized administrator.
    The only way to truly enforce authorization decisions is if the principals using
    the system are properly authenticated. Auditing completes the picture by providing
    a reliable log of who did what and when, subject to regular review for irregularities,
    and holding the acting parties responsible.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 黄金标准充当保护C-I-A的执行机制。我们定义了保密性和完整性为防止*未经授权*的泄露或篡改，而可用性也受到授权管理员的控制。真正执行授权决策的唯一方式是确保使用该系统的主体已被正确验证。审计通过提供可靠的谁做了什么、何时做的日志来完善整个过程，定期审查异常情况，并追究相关方的责任。
- en: 'Secure designs should always explicitly separate authentication from authorization,
    because combining them leads to confusion, and audit trails are clearer when these
    stages are cleanly divided. These two real-world examples illustrate why the separation
    is important:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 安全设计应始终明确区分身份验证和授权，因为将二者结合会导致混乱，而当这些阶段清晰分开时，审计轨迹会更加明确。这两个现实生活中的例子说明了为什么这种区分很重要：
- en: “Why did you let that guy into the vault?” “I have no idea, but he looked legit!”
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “你为什么让那个人进了金库？” “我不知道，但他看起来很合法！”
- en: “Why did you let that guy into the vault?” “His ID was valid for ‘Sam Smith’
    and he had a written note from the branch manager.”
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “你为什么让那个人进了金库？” “他的身份证明是‘Sam Smith’，并且他有分行经理的书面证明。”
- en: 'The second response is much more complete than the first, which is of no help
    at all, other than proving that the guard is a nitwit. If the vault was compromised,
    the second response would give clear details to investigate: Did the branch manager
    have authority to grant vault access and write the note? If the guard retained
    a copy of the ID, then that information helps identify and find Sam Smith. By
    contrast, if the branch manager’s note had just said, “let the bearer into the
    vault”—authorization without authentication—investigators would have had little
    idea what happened or who the intruder was after security was breached.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个回应比第一个更为完整，后者完全没有帮助，除了证明保安是个傻瓜。如果保险库被入侵，第二个回应会提供明确的调查细节：分行经理是否有权限授予进入保险库的权限并写下便条？如果保安保留了身份证复印件，那么这些信息有助于确认并找到Sam
    Smith。相比之下，如果分行经理的便条上只写了“让持票人进入保险库”——没有认证的授权——调查人员在安全被突破后几乎无法了解发生了什么或入侵者是谁。
- en: Authentication
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 身份验证
- en: An authentication process tests a principal’s claims of identity based on credentials
    that demonstrate they really are who they claim to be. Or the service might use
    a stronger form of credentials, such as a digital signature or a challenge, which
    proves that the principal possesses a private key associated with the identity,
    which is how browsers authenticate web servers via HTTPS. The digital signature
    is a better form of authentication because the principal can prove they know the
    secret without divulging it.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 身份验证过程基于凭证来验证主体的身份声明，凭证表明他们确实是他们所声称的身份。或者服务可能使用更强的凭证形式，如数字签名或挑战，证明主体拥有与该身份关联的私钥，这也是浏览器通过HTTPS验证Web服务器身份的方式。数字签名是一种更好的身份验证形式，因为主体可以证明他们知道秘密而不泄露它。
- en: 'Evidence suitable for authentication falls into the following categories:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于身份验证的证据可分为以下几类：
- en: '*Something you know*, like a password'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你知道的东西*，比如密码'
- en: '*Something you have*, like a secure token, or in the analog world some kind
    of certificate, passport, or signed document that is unforgeable'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你拥有的东西*，比如一个安全令牌，或者在模拟世界中某种无法伪造的证书、护照或签署的文件'
- en: '*Something you are*—that is, biometrics (fingerprint, iris pattern, and such)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你是的东西*——即生物特征（指纹、虹膜图案等）'
- en: '*Somewhere you are*—your verified location, such as a connection to a private
    network in a secure facility'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你所在的地方*——你的验证位置，比如连接到一个安全设施中的私人网络'
- en: Many of these methods are quite fallible. Something you know can be revealed,
    something you have can be stolen or copied, your location can be manipulated in
    various ways, and even something you are can potentially be faked (and if it’s
    compromised, you can’t later change what you are). On top of those concerns, in
    today’s networked world, authentication almost always happens across a network,
    making the task more difficult than in-person authentication. On the web, for
    instance, the browser serves as a trust intermediary, locally authenticating and,
    only if successful, then passing along cryptographic credentials to the server.
    Systems commonly use multiple authentication factors to mitigate these concerns,
    and auditing these frequently is another important backstop. Two weak authentication
    factors are better than one (but not a lot better).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法中的许多是相当不可靠的。你所知道的东西可能会被揭示，你拥有的东西可能会被盗取或复制，你的位置可以通过各种方式被操控，甚至你所“是”的东西也可能会被伪造（如果被泄露，你以后就无法改变你“是”的东西）。除此之外，在当今的网络化世界中，身份验证几乎总是发生在网络上，这使得任务比面对面的身份验证更为困难。例如，在互联网上，浏览器充当信任中介，首先进行本地身份验证，只有验证成功后，才将加密凭证传递给服务器。系统通常使用多重身份验证因素来减轻这些问题，定期审计这些因素也是另一个重要的防线。两个较弱的身份验证因素比一个要好（但没有好很多）。
- en: Before an organization can assign someone credentials, however, it has to address
    the gnarly question of how to determine a person’s true identity when they join
    a company, sign up for an account, or call the helpdesk to reinstate access after
    forgetting their password.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在组织可以为某人分配凭证之前，它必须解决一个棘手的问题：如何确定一个人在加入公司、注册账户或因忘记密码而联系帮助台恢复访问权限时的真实身份。
- en: For example, when I joined Google, all of us new employees gathered on a Monday
    morning opposite several IT admin folks, who checked our passports or other ID
    against a new employee roster. Only then did they give us our badges and company-issued
    laptops and have us establish our login passwords.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当我加入谷歌时，所有新员工在一个周一早晨与几位 IT 管理员汇合，管理员们核对我们的护照或其他身份证明与新员工名单，然后才发放我们的员工卡和公司发放的笔记本电脑，并让我们设置登录密码。
- en: By checking whether the credentials we provided (our IDs) correctly identified
    us as the people we purported to be, the IT team confirmed our identities. The
    security of this identification depended on the integrity of the government-issued
    IDs and supporting documents (for example, birth certificates) we provided. How
    accurately were those issued? How difficult would they be to forge, or obtain
    fraudulently? Ideally, a chain of association from registration at birth would
    remain intact throughout our lifetimes to uniquely identify each of us authentically.
    Securely identifying people is challenging largely because the most effective
    techniques reek of authoritarianism and are socially unacceptable, so to preserve
    some privacy and freedom, we opt for weaker methods in daily life. The issue of
    how to determine a person’s true identity is out of scope for this book, which
    will focus on the Gold Standard, not this harder problem of *identity management*.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查我们提供的凭证（我们的身份证明）是否正确地确认了我们作为所声明之人的身份，IT 团队验证了我们的身份。身份验证的安全性取决于我们提供的政府颁发的身份证明和支持文件（例如出生证明）的完整性。这些身份证明的发行有多准确？它们被伪造或欺诈获得的难度有多大？理想情况下，从出生注册开始的身份链应在我们一生中始终保持完整，以便独特而真实地识别每个人。安全识别个人是一个挑战，主要是因为最有效的技术往往带有专制色彩，且在社会上不可接受，因此为了保持一定的隐私和自由，我们在日常生活中选择较弱的方法。本书的重点是金标准，而不是这一更难的*身份管理*问题，因此不在本书讨论范围之内。
- en: Whenever feasible, rely on existing trustworthy authentication services, and
    do not reinvent the wheel unnecessarily. Even simple password authentication is
    quite difficult to do securely, and dealing securely with forgotten passwords
    is even harder. Generally speaking, the authentication process should examine
    credentials and provide either a pass or fail response. Avoid indicating partial
    success, since this could aid an attacker zeroing in on the credentials by trial
    and error. To mitigate the threat of brute-force guessing, a common strategy is
    to make authentication inherently computationally heavyweight, or to introduce
    increasing delay into the process (also see “Avoid Predictability” on page 61
    in Chapter 4).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在可行的情况下，依赖现有的可信认证服务，不要不必要地重复发明轮子。即使是简单的密码认证也很难做到安全，处理遗忘密码的安全性更是困难。通常来说，认证过程应检查凭证并提供通过或失败的响应。避免显示部分成功，因为这可能帮助攻击者通过试错逐步锁定凭证。为了缓解暴力破解的威胁，一种常见策略是使认证过程本身计算量大，或在过程中引入逐步延迟（另见第
    4 章第 61 页中的“避免可预测性”）。
- en: After authenticating the user, the system must find a way to securely bind the
    identity to the principal. Typically, an authentication module issues a token
    to the principal that they can use in lieu of full authentication for subsequent
    requests. The idea is that the principal, via an agent such as a web browser,
    presents the authentication token as shorthand assurance of who they claim to
    be, creating a *secure context* for future requests. This context binds the stored
    token for presentation with future requests on behalf of the authenticated principal.
    Websites often do this with a secure cookie associated with the browsing session,
    but there are many different techniques for other kinds of principals and interfaces.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证用户身份后，系统必须找到一种安全地将身份绑定到主体的方法。通常，认证模块会向主体发放一个令牌，主体可以使用这个令牌代替完整的身份验证，用于后续的请求。其目的是，主体通过代理（如网页浏览器）呈现认证令牌，作为其身份的简要证明，从而为未来的请求创建一个*安全上下文*。这个上下文将存储的令牌与后续请求进行绑定，以代表已认证的主体。网站通常通过与浏览会话相关联的安全
    cookie 来实现这一点，但对于其他类型的主体和接口，还有许多不同的技术。
- en: The secure binding of an authenticated identity can be compromised in two fundamentally
    different ways. The obvious one is where an attacker usurps the victim’s identity.
    Alternatively, the authenticated principal may collude and try to give away their
    identity or even foist it off on someone else. An example of the latter case is
    the sharing of a paid streaming subscription. The web does not afford very good
    ways of defending against this because the binding is loose and depends on the
    cooperation of the principal.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 已认证身份的安全绑定可能会以两种根本不同的方式受到破坏。一个明显的方式是攻击者篡夺受害者的身份。另一种方式是已认证的主体可能会串通并试图泄露他们的身份，甚至将其转嫁给他人。后者的例子包括共享付费流媒体订阅。由于绑定较为松散且依赖主体的合作，网络防御此类行为的手段并不十分有效。
- en: Authorization
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 授权
- en: A decision to allow or deny critical actions should be based on the identity
    of the principal as established by authentication. Systems implement authorization
    in business logic, an access control list, or some other formal access policy.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 允许或拒绝关键操作的决策应基于通过认证确认的主体身份。系统通过业务逻辑、访问控制列表或其他正式的访问策略来实施授权。
- en: Anonymous authorization (that is, authorization without authentication) can
    be useful in rare circumstances; a real-world example might be possession of the
    key to a public locker in a busy station. Access restrictions based on time (for
    example, database access restricted to business hours) are another common example.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 匿名授权（即无认证的授权）在某些罕见的情况下是有用的；一个现实世界的例子可能是拥有繁忙车站公共储物柜的钥匙。基于时间的访问限制（例如，将数据库访问限制在营业时间内）是另一个常见的例子。
- en: A single guard should enforce authorization on a given resource. Authorization
    code scattered throughout a codebase is a nightmare to maintain and audit. Instead,
    authorization should rely on a common framework that grants access uniformly.
    A well-structured design can help the developers get it right. Use one of the
    many standard authorization models rather than confusing ad hoc logic wherever
    possible.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一个单独的保安应该对特定资源执行授权。分散在代码库中的授权代码会让维护和审计变得非常困难。相反，授权应依赖于一个统一的框架来授予访问权限。良好的结构化设计能够帮助开发人员做到这一点。在可能的情况下，尽量使用标准的授权模型，而不是混乱的临时逻辑。
- en: '*Role-based access control (RBAC)* bridges the connection between authentication
    and authorization. RBAC grants access based on roles assigned to authenticated
    principals, simplifying access control with a uniform framework. For example,
    roles in a bank might include a clerk, manager, loan officer, security guard,
    financial auditor, and IT administrator. Instead of choosing access privileges
    for each person individually, RBAC designates one or more roles based on each
    person’s responsibilities to automatically and uniformly assign them associated
    privileges. In more advanced models, one person might have multiple roles and
    explicitly select which role they choose to apply for a given access.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*基于角色的访问控制（RBAC）*桥接了认证和授权之间的联系。RBAC基于分配给已认证主体的角色授予访问权限，通过统一的框架简化了访问控制。例如，银行中的角色可能包括职员、经理、贷款专员、安全员、财务审计员和IT管理员。RBAC并不是为每个人单独选择访问权限，而是根据每个人的职责指定一个或多个角色，并自动且统一地分配相关权限。在更高级的模型中，一个人可能拥有多个角色，并明确选择在特定访问场景下应用哪个角色。'
- en: Authorization mechanisms can be much more granular than the simple read/write
    access control that operating systems traditionally provide. By designing more
    robust authorization mechanisms, you can strengthen security by limiting access
    without losing useful functionality. These more advanced authorization models
    include *attribute-based access control (ABAC),* *policy-based access control
    (PBAC)*, and many more.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 授权机制可以比操作系统传统提供的简单读/写访问控制更加细化。通过设计更强大的授权机制，你可以在不丧失有用功能的情况下，通过限制访问来增强安全性。这些更先进的授权模型包括*基于属性的访问控制（ABAC）*、*基于策略的访问控制（PBAC）*等。
- en: 'Consider a simple bank teller example to see how fine-grained authorization
    might tighten up policy:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个简单的银行出纳员示例来观察如何通过细粒度授权来收紧政策：
- en: '**Rate-limited**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**限速**'
- en: Tellers may do up to 20 transactions per hour, but more would be considered
    suspicious.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 出纳员每小时最多可以进行20笔交易，但超过这个数量将被视为可疑。
- en: '**Time of day**'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间限制**'
- en: Teller transactions must occur during business hours, when clocked in.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 出纳员交易必须在营业时间内进行，且需打卡上班。
- en: '**No self-service**'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**禁止自助服务**'
- en: Tellers are forbidden to do transactions with their personal accounts.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 出纳员禁止与其个人账户进行交易。
- en: '**Multiple principals**'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**多个主体**'
- en: Teller transactions over $10,000 require separate manager approval (eliminating
    the risk of one bad actor moving a lot of money at once).
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 超过$10,000的出纳交易需要单独的经理批准（避免了单一恶意行为者一次性转移大量资金的风险）。
- en: Finally, even read-only access may be too high a level for certain data, like
    passwords. Systems usually check login passwords by comparing digests, which avoids
    any possibility of leaking the actual plaintext password. The username and password
    go to a frontend server that computes the digest of the password and passes it
    to an authentication service, quickly destroying any trace of the plaintext password.
    The authentication service cannot read the plaintext password from the credentials
    database, but it can read the digest, which it compares to what the frontend server
    provided. In this way, it checks the credentials, but the authentication service
    never has access to any passwords, so even if compromised, the service cannot
    leak them. Unless the design of interfaces affords these alternatives, they will
    miss these opportunities to mitigate the possibility of data leakage. We’ll explore
    this further when we discuss the pattern of “Least Information” on page 57 in
    Chapter 4.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，即使是只读访问，对于某些数据（如密码）来说，也可能是过高的权限。系统通常通过比较摘要值来检查登录密码，这样就避免了泄露明文密码的任何可能性。用户名和密码会传送到前端服务器，前端服务器计算密码的摘要并将其传递给身份验证服务，迅速销毁任何明文密码的痕迹。身份验证服务无法从凭据数据库中读取明文密码，但可以读取摘要，并将其与前端服务器提供的摘要进行比较。通过这种方式，系统检查凭据，但身份验证服务永远无法访问任何密码，因此即使被攻破，该服务也无法泄露密码。除非接口设计提供了这些替代方案，否则它们将错失这些减少数据泄漏可能性的机会。我们将在第4章第57页讨论“最小信息”模式时进一步探讨这一点。
- en: Auditing
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 审计
- en: In order for an organization to audit system activity, the system must produce
    a reliable log of all events that are critical to maintaining security. These
    include authentication and authorization events, system startup and shutdown,
    software updates, administrative accesses, and so forth. Audit logs must also
    be tamper-resistant, and ideally even difficult for administrators to meddle with,
    to be considered fully reliable records. Auditing is a critical leg of the Gold
    Standard, because incidents do happen, and authentication and authorization policies
    can be flawed. Auditing can also provide necessary oversight to mitigate the risk
    of inside jobs in which authorized principals betray their trust.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让组织能够审计系统活动，系统必须生成所有对维护安全至关重要的事件的可靠日志。这些事件包括身份验证和授权事件、系统启动和关闭、软件更新、管理访问等。审计日志还必须具备防篡改能力，理想情况下，即便是管理员也难以干预，才能被视为完全可靠的记录。审计是黄金标准的一个关键组成部分，因为事件是会发生的，身份验证和授权政策可能存在缺陷。审计还可以提供必要的监督，减少内部人员背叛信任的风险。
- en: If done properly, audit logs are essential for routine monitoring, measuring
    system activity level, detecting errors and suspicious activity, and, after an
    incident, determining when and how an attack actually happened and gauging the
    extent of the damage. Remember that completely protecting a digital system is
    not simply a matter of correctly enforcing policies; it’s about being a responsible
    steward of information assets. Auditing ensures that trusted principals acted
    properly within the broad range of their authority.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果操作得当，审计日志对日常监控、衡量系统活动水平、检测错误和可疑活动至关重要，并且在发生事件后，能帮助确定攻击发生的时间和方式，以及评估损害程度。请记住，完全保护数字系统不仅仅是正确执行政策的问题；它更关乎如何负责地管理信息资产。审计确保了信任的主体在其广泛权限范围内正确行事。
- en: 'In May 2018, Twitter disclosed an embarrassing bug: they had discovered that
    a code change had inadvertently caused raw login passwords to appear in internal
    logs. It’s unlikely that this resulted in any abuse, but it certainly hurt customer
    confidence and should never have happened. Logs should record operational details
    but not store any actual private information so as to minimize the risk of disclosure,
    since many members of the technical staff may routinely view the logs. For a detailed
    treatment of this requirement, see the sample design document in Appendix A detailing
    a logging tool that addresses just this problem.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: The system must also prevent anyone from tampering with the logs to conceal
    bad acts. If the attacker can modify logs, they’ll just clean out all traces of
    their activity. For especially sensitive logs at high risk, an independent system
    under different administrative and operational controls should manage audit logs
    in order to prevent the perpetrators of inside jobs from covering their own tracks.
    This is difficult to do completely, but the mere presence of independent oversight
    often serves as a powerful disincentive to any funny business, just as a modest
    fence and conspicuous video surveillance camera can be an effective deterrent
    to trespassing.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, any attempt to circumvent the system would seem highly suspicious,
    and any false move would result in serious repercussions for the offender. Once
    caught, they would have a hard time repudiating their guilt.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '*Non-repudiability* is an important property of audit logs; if the log shows
    that a named administrator ran a certain command at a certain time and the system
    crashed immediately, it’s hard to point fingers at others. By contrast, if an
    organization allowed multiple administrators to share the same account (a terrible
    idea), it would have no way of definitively knowing who actually did anything,
    providing plausible deniability to all.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, audit logs are useful only if you monitor them, analyze unusual
    events carefully, and follow up, taking appropriate actions when necessary. To
    this end, it’s important to log the right amount of detail by following the *Goldilocks
    principle*. Too much logging bloats the volume of data to oversee, and excessively
    noisy or disorganized logs make it difficult to glean useful information. On the
    other hand, sparse logging with insufficient detail might omit critical information,
    so finding the right balance is an ongoing challenge.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Privacy
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to the foundations of information security—C-I-A and the Gold Standard—another
    fundamental topic I want to introduce is the related field of information privacy.
    The boundaries between security and privacy are difficult to clearly define, and
    they are at once closely related and quite different. In this book I would like
    to focus on the common points of intersection, not to attempt to unify them, but
    to incorporate both security and privacy into the process of building software.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'To respect people’s digital information privacy, we must extend the principle
    of confidentiality by taking into account additional human factors, including:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尊重人们的数字信息隐私，我们必须通过考虑额外的人为因素来扩展保密原则，包括：
- en: Customer expectations regarding information collection and use
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户对信息收集和使用的期望
- en: Clear policies regarding appropriate information use and disclosure
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于适当的信息使用和披露的明确政策
- en: Legal and regulatory issues relating to the collection and use of various classes
    of information
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与收集和使用各种类别信息相关的法律和监管问题
- en: Political, cultural, and psychological aspects of processing personal information
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理个人信息时的政治、文化和心理层面
- en: As software becomes more pervasive in modern life, people use it in more intimate
    ways involving sensitive areas of their lives, resulting in many complex issues.
    Past accidents and abuses have raised the visibility of the risks, and as society
    grapples with new challenges through political and legal means, handling private
    information properly has become challenging.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 随着软件在现代生活中变得越来越普及，人们在生活中使用软件的方式变得更加亲密，涉及到生活中许多敏感领域，导致了许多复杂的问题。过去的事故和滥用事件提高了对这些风险的关注，随着社会通过政治和法律手段应对新挑战，妥善处理私人信息变得越来越具有挑战性。
- en: 'In the context of software security, this means:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件安全的背景下，这意味着：
- en: Considering the customer and stakeholder consequences of all data collection
    and sharing
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑所有数据收集和共享可能对客户和利益相关者产生的后果
- en: Flagging all potential issues, and getting expert advice where necessary
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标明所有潜在问题，并在必要时寻求专家建议
- en: Establishing and following clear policies and guidelines regarding private information
    use
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立并遵循有关私人信息使用的明确政策和指南
- en: Translating policy and guidance into software-enforced checks and balances
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将政策和指导转化为软件执行的检查和制衡
- en: Maintaining accurate records of data acquisition, use, sharing, and deletion
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持准确的数据获取、使用、共享和删除记录
- en: Auditing data access authorizations and extraordinary access for compliance
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审计数据访问授权和特别访问以确保合规
- en: Privacy work tends to be less well-defined than the relatively cut-and-dried
    security work of maintaining proper control of systems and providing appropriate
    access. Also, we’re still working out privacy expectations and norms as society
    ventures deeper into a future with more data collection. Given these challenges,
    you would be wise to consider maximal transparency about data use, including keeping
    your policies simple enough to be understood by all, and to collect minimal data,
    especially personally identifiable information.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 隐私工作往往比维护系统适当控制和提供适当访问权限的相对明确的安全工作更难界定。而且，随着社会在更多数据收集的未来中不断前进，我们仍在逐步明确隐私的期望和规范。鉴于这些挑战，您明智的做法是考虑最大限度的透明度，关于数据使用的政策应简明易懂，并且尽量收集最少的数据，特别是个人身份信息。
- en: 'Collect information for a specific purpose only, and retain it only as long
    as it’s useful. Unless the design envisions an authorized use, avoid collection
    in the first place. Frivolously collecting data for use “someday” is risky, and
    almost never a good idea. When the last authorized use of some data becomes unnecessary,
    the best protection is secure deletion. For especially sensitive data, or for
    maximal privacy protection, make that even stronger: delete data when the potential
    risk of disclosure exceeds the potential value of retaining it. Retaining many
    years’ worth of emails might occasionally be handy for something, but probably
    not for any clear business need. Yet internal emails could represent a liability
    if leaked or disclosed, such as by power of subpoena. Rather than hang onto all
    that data indefinitely “just in case,” the best policy is usually to delete it.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 仅为特定目的收集信息，并仅在有用时保留。除非设计中设想了授权使用，否则应避免首次收集。为了“某天”使用而轻率收集数据是有风险的，几乎从来不是一个好主意。当某些数据的最后一次授权使用变得不再必要时，最好的保护方法是安全删除。对于特别敏感的数据，或者为了最大化隐私保护，可以采取更强的措施：当披露的潜在风险超过保留数据的潜在价值时，就删除数据。保留多年的电子邮件有时可能对某些事情有用，但通常没有明确的商业需求。然而，内部邮件如果泄露或披露（例如通过传票的方式）可能会带来法律责任。因此，与其为了“以防万一”无限期保存所有数据，通常最好的做法是删除它。
- en: A complete treatment of information privacy is outside the scope of this book,
    but privacy and security are tightly bound facets of the design of any system
    that collects data about people—and people interact with almost all digital systems,
    in one way or another. Strong privacy protection is only possible when security
    is solid, so these words are an appeal for awareness to consider and incorporate
    privacy considerations into software by design.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 对信息隐私的完整讨论超出了本书的范围，但隐私与安全性是任何收集个人数据的系统设计中紧密相连的两个方面——而且几乎所有数字系统都以某种方式与人互动。只有在安全性得到保障的情况下，才能实现强有力的隐私保护，因此这些话是呼吁大家在软件设计中通过设计来考虑并融入隐私保护。
- en: 'For all its complexity, one best practice for privacy is well known: the necessity
    of clearly communicating privacy expectations. In contrast to security, a privacy
    policy potentially affords a lot of leeway as to how much an information service
    does or does not want to leverage the use of customer data. “We will reuse and
    sell your data” is one extreme of the privacy spectrum, but “some days we may
    not protect your data” is not a viable stance on security. Privacy failures arise
    when user expectations are out of joint with actual privacy policy, or when there
    is a clear policy and it is somehow violated. The former problem stems from not
    proactively explaining data handling to the user. The latter happens when the
    policy is unclear, or ignored by responsible staff, or subverted in a security
    breakdown.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管其复杂性，隐私的最佳实践之一是众所周知的：必须清楚地传达隐私期望。与安全性不同，隐私政策在信息服务是否以及如何使用客户数据上，通常留有很大的余地。“我们将重用并出售您的数据”是隐私光谱的一端，但“有些时候我们可能不会保护您的数据”则不是安全性上的可行立场。隐私失败通常发生在用户的期望与实际隐私政策不一致，或当隐私政策明确却被违反时。前者问题的根源在于未能主动向用户解释数据处理方式。后者则发生在政策不明确，或负责人忽视了政策，或在安全漏洞中被破坏。
- en: '2'
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Threats
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 威胁
- en: The threat is usually more terrifying than the thing itself.
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 威胁通常比本身更可怕。
- en: ''
  id: totrans-165
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Saul Alinsky
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ——索尔·阿林斯基
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: 'Threats are omnipresent, but you can live with them if you manage them. Software
    is no different, except that you don’t have the benefit of millions of years of
    evolution to prepare yourself. That is why you need to adopt a software security
    mindset, which requires you to flip from the builder’s perspective to that of
    the attackers. Understanding the potential threats to a system is the essential
    starting point in order to bake solid defenses and mitigations into your software
    designs. But to perceive these threats in the first place, you’ll have to stop
    thinking about typical use cases and using the software as intended. Instead,
    you must simply see it for what it is: a bunch of code and components, with data
    flowing around and getting stored here and there.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 威胁无处不在，但如果管理得当，你是可以与它们共存的。软件也不例外，唯一不同的是你没有数百万年的进化来准备自己。这就是为什么你需要培养一种软件安全的思维方式，它要求你从开发者的视角转变为攻击者的视角。理解系统可能面临的威胁是将坚固的防御措施和缓解方案融入软件设计的基本起点。但是，要首先察觉这些威胁，你必须停止考虑典型的使用案例和按预期使用软件。相反，你必须把它看作它真正的面貌：一堆代码和组件，数据在其中流动并在各处存储。
- en: 'For example, consider the paperclip: it’s cleverly designed to hold sheets
    of paper together, but if you bend a paperclip just right, it’s easily refashioned
    into a stiff wire. A security mindset discerns that you could insert this wire
    into the keyhole of a lock to manipulate the tumblers and open it without the
    key.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一下回形针：它巧妙地设计用来将纸张固定在一起，但如果你适当弯曲回形针，它很容易被重新塑造成一根硬线。安全思维能够辨认出，你可以将这根线插入锁的钥匙孔，通过操控锁芯来打开锁，而无需钥匙。
- en: It’s worth emphasizing that threats include all manner of ways in which harm
    occurs. Adversarial attacks conducted with intention are an important focus of
    the discussion, but this does not mean that you should exclude other threats due
    to software bugs, human error, accidents, hardware failures, and so on.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 值得强调的是，威胁包括所有可能造成伤害的方式。恶意攻击是讨论中的重要焦点，但这并不意味着你应当排除由于软件缺陷、人为错误、事故、硬件故障等带来的其他威胁。
- en: Threat modeling provides a perspective with which to guide any decisions that
    impact security throughout the software development process. The following treatment
    focuses on concepts and principles, rather than any of the many specific methodologies
    for doing threat modeling. Early threat modeling as first practiced at Microsoft
    in the early 2000s proved effective, but it required extensive training, as well
    as a considerable investment of effort. Fortunately, you can do threat modeling
    in any number of ways, and once you understand the concepts, it’s easy to tailor
    your process to fit the time and effort available while still producing meaningful
    results.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 威胁建模提供了一种视角，可以指导在整个软件开发过程中影响安全性的任何决策。以下内容侧重于概念和原则，而不是执行威胁建模的许多具体方法论。微软在2000年代初期首次实践的早期威胁建模被证明是有效的，但它需要大量的培训，并且投入了相当大的精力。幸运的是，你可以通过多种方式进行威胁建模，一旦理解了概念，便容易根据可用的时间和精力调整流程，同时仍能产生有意义的结果。
- en: 'Setting out to enumerate all the threats and identify all the points of vulnerability
    in a large software system is a daunting task. However, smart security work targets
    incrementally raising the bar, not shooting for perfection. Your first efforts
    may only find a fraction of all the potential issues, and only mitigate some of
    those: even so, that’s a substantial improvement. Such an effort may just possibly
    avert a major security incident—a real accomplishment. Unfortunately, you almost
    never know about foiled attacks, and that absence of feedback can feel disappointing.
    The more you flex your security mindset muscles, the better you’ll become at seeing
    threats.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 列举所有威胁并识别大型软件系统中所有的漏洞点是一项艰巨的任务。然而，聪明的安全工作目标是逐步提高标准，而不是追求完美。你的第一次努力可能只发现所有潜在问题的一部分，并且只能缓解其中一些：即便如此，这也是一次实质性的改进。这种努力或许能避免一次重大安全事件——这本身就是一项真正的成就。不幸的是，你几乎永远不知道被挫败的攻击，缺乏反馈可能会让人感到失望。你越是锻炼你的安全思维肌肉，就越能更好地识别威胁。
- en: Finally, it’s important to understand that threat modeling can provide new levels
    of understanding of the target system beyond the scope of security. Through the
    process of examining the software in new ways, you may gain insights that suggest
    various improvements, efficiencies, simplifications, and new features unrelated
    to security.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，重要的是要理解，威胁建模可以提供超出安全范围的对目标系统的新层次的理解。通过以新的方式审视软件，你可能会获得一些见解，这些见解建议了各种改进、效率、简化以及与安全无关的新功能。
- en: The Adversarial Perspective
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对抗性视角
- en: 'Exploits are the closest thing to “magic spells” we experience in the real
    world: Construct the right incantation, gain remote control over device.'
  id: totrans-175
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 漏洞利用是我们在现实世界中体验到的最接近“魔法咒语”的东西：构建正确的咒语，便能远程控制设备。
- en: ''
  id: totrans-176
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Halvar Flake
  id: totrans-177
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: —Halvar Flake
- en: Human perpetrators are the ultimate threat; security incidents don’t just happen
    by themselves. Any concerted analysis of software security includes considering
    what hypothetical adversaries might try in order to anticipate and defend against
    potential attacks. Attackers are a motley group, from *script kiddies* (criminals
    without tech skills using automated malware) to sophisticated nation-state actors,
    and everything in between. To the extent you can think from an adversary’s perspective,
    that’s great, but don’t fool yourself into believing you can accurately predict
    their every move or spend too much time trying to get inside their heads, like
    a master sleuth outsmarting a wily foe. It’s helpful to understand the attacker’s
    mindset, but for our purposes of building secure software, the details of actual
    techniques they might use to probe, penetrate, and exfiltrate data are unimportant.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 人类行为者是终极威胁；安全事件不会自动发生。对软件安全的任何深入分析都包括考虑假设的对手可能会尝试的行为，以预测和防御潜在的攻击。攻击者是一个杂乱无章的群体，从*脚本小子*（没有技术技能的罪犯使用自动化恶意软件）到复杂的国家级行为者，及其中的一切。只要你能从对手的角度思考，那是很好的，但不要自欺欺人地相信你能准确预测他们的每一步，也不要花太多时间试图进入他们的思维，就像一个高手侦探智胜一个狡猾的敌人一样。理解攻击者的思维方式很有帮助，但就我们构建安全软件的目的而言，实际技术细节——他们可能用来探测、渗透和窃取数据的手段——并不重要。
- en: Consider what the obvious targets within a system might be (sometimes, what’s
    valuable to an adversary is less valuable to you, or vice versa) and ensure that
    those assets are robustly secured, but don’t waste time attempting to read the
    minds of hypothetical attackers. Rather than expend unnecessary effort, they’ll
    often focus on the weakest link to accomplish their goal (or they might be poking
    around aimlessly, which can be very hard to defend against since their actions
    will seem undirected and arbitrary). Bugs definitely attract attention because
    they suggest weakness, and attackers who stumble onto an apparent bug will try
    creative variations to see if they can really bust something. Errors or side effects
    that disclose details of the insides of the system (for example, detailed stack
    dumps) are prime fodder for attackers to jump on and run with.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Once attackers find a weakness, they’re likely to focus more effort on it, because
    some small flaws have a way of expanding to produce larger consequences under
    concerted attack (as we shall see in Chapter 8 in detail). Often, it’s possible
    to combine two tiny flaws that are of no concern individually to produce a major
    attack, so it’s wise to take all vulnerabilities seriously. Skilled attackers
    definitely know about threat modeling, though they are working without inside
    information (at least until they manage some degree of penetration).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'Even though we can never really anticipate what our adversaries will spend
    time on, it does make sense to consider the motivation of hypothetical attackers
    as a measure of the likelihood of diligent attacks. Basically, this amounts to
    a famous criminal’s explanation of why he robbed banks: “Because that’s where
    the money is.” The point is, the greater the prospective gain from attacking a
    system, the higher the level of skill and resources you can expect potential attackers
    to apply. Speculative as this might be, the analysis is useful as a relative guide:
    powerful corporations and government, military, and financial institutions are
    big targets. Your cat photos are not.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'In the end, as with all forms of violence, it’s always far easier to attack
    and cause harm than to defend. Attackers get to choose their point of entry, and
    with determination they can try as many exploits as they like, because they only
    need to succeed once. All this amounts to more reasons why it’s important to prioritize
    security work: the defenders need every advantage available.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: The Four Questions
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Adam Shostack, who carried the threat modeling torch at Microsoft for years,
    boils the methodology down to Four Questions:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: What are we working on?
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What can go wrong?
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are we going to do about it?
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Did we do a good job?
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first question aims to establish the project’s context and scope. Answering
    it includes describing the project’s requirements and design, its components and
    their interactions, as well as considering operational issues and use cases. Next,
    at the core of the method, the second question attempts to anticipate potential
    problems, while the third question explores mitigations to those problems we identify.
    (We’ll look more closely at mitigations in Chapter 3, but first we will examine
    how they relate to threats.) Finally, the last question asks us to reflect on
    the entire process—what the software does, how it can go wrong, and how well we’ve
    mitigated the threats—in order to assess the risk reduction and confirm that the
    system will be sufficiently secure. Should unresolved issues remain, we go through
    the questions again to fill in the remaining gaps.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: There is much more to threat modeling than this, but it’s surprising how far
    simply working from the Four Questions can take you. Armed with these concepts,
    in conjunction with the other ideas and techniques in this book, you can significantly
    raise the security bar for the systems you build and operate.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Threat Modeling
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: “What could possibly go wrong?”
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: We often ask this question to make a cynical joke. But when asked unironically,
    it succinctly expresses the point of departure for threat modeling. Responding
    to this question requires us to identify and assess threats; we can then prioritize
    these and work on mitigations that reduce the risk of the important threats.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s unpack that previous sentence. The following steps outline the basic
    threat modeling process:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Work from a model of the system to ensure that we consider everything in scope.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify *assets* (valuable data and resources) within the system that need
    protection.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scour the system model for potential threats, component by component, identifying
    *attack surface**s* (places where an attack could originate), *trust boundaries*
    (interfaces bridging more-trusted parts of the system with the less-trusted parts),
    and different types of threats.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyze these potential threats, from the most concrete to the hypothetical.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rank the threats, working from the most to least critical.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Propose mitigations to reduce risk for the most critical threats.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add mitigations, starting from the most impactful and easiest, and working up
    to the point of diminishing returns.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test the efficacy of the mitigations, starting with those for the most critical
    threats.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For complex systems, a complete inventory of all potential threats will be enormous,
    and a full analysis is almost certainly infeasible (just as enumerating every
    conceivable way of doing anything would never end if you got imaginative, which
    attackers often do). In practice, the first threat modeling pass should focus
    on the biggest and most likely threats to the high-value assets only. Once you’ve
    understood those threats and put first-line mitigations in place, you can evaluate
    the remaining risk by iteratively considering the remaining lesser threats that
    you’ve already identified. From that point, you can perform one or more additional
    threat modeling passes as needed, casting a wider net each time to include additional
    assets, deeper analysis, and more of the less likely or minor threats. The process
    stops when you’ve achieved a sufficiently thorough understanding of the most important
    threats, planned the necessary mitigations, and deemed the remaining known risk
    acceptable.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: People intuitively do something akin to threat modeling in daily life, taking
    what we call common-sense precautions. To send a private message in a public place,
    most people type it instead of dictating it aloud to their phones. Using the language
    of threat modeling, we’d say the message content is the information asset, and
    disclosure is the threat. Speaking within earshot of others is the attack surface,
    and using a silent, alternative input method is a good mitigation. If a nosy stranger
    is watching, you could add an additional mitigation, like cupping the phone with
    your other hand to shield the screen from view. But while we do this sort of thing
    all the time quite naturally in the real world, applying these same techniques
    to complex software systems, where our familiar physical intuitions don’t apply,
    requires much more discipline.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Work from a Model
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ll need a rigorous approach in order to thoroughly identify threats. Traditionally,
    threat modeling uses data flow diagrams (DFDs) or Unified Modeling Language (UML)
    descriptions of the system, but you can use whatever model you like. Whatever
    high-level description of the system you choose, be it a DFD, UML, a design document,
    or an informal “whiteboard session,” the idea is to look at an abstraction of
    the system, so long as it has enough granularity to capture the detail you need
    for analysis.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: More formalized approaches tend to be more rigorous and produce more accurate
    results, but at the cost of additional time and effort. Over the years, the security
    community has invented a number of alternative methodologies that offer different
    trade-offs, in no small part because the full-blown threat modeling method (involving
    formal models like DFDs) is so costly and effort-intensive. Today, you can use
    specialized software to help with the process. The best ones automate significant
    parts of the work, although interpreting the results and making risk assessments
    will always require human judgment. This book tells you all you need to know in
    order to threat model on your own, without special diagrams or tools, so long
    as you understand the system well enough to thoroughly answer the Four Questions.
    You can work toward more advanced forms from there as you like.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'Whatever model you work from, thoroughly cover the target system at the appropriate
    resolution. Choose the appropriate level of detail for the analysis by the Goldilocks
    principle: don’t attempt too much detail or the work will be endless, and don’t
    go too high-level or you’ll omit important details. Completing the process quickly
    with little to show for it is a sure sign of insufficient granularity, just as
    making little headway after hours of work indicates your model may be too granular.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider what the right level of granularity would be for a generic web
    server. You’re handed a model consisting of a block diagram showing “the internet”
    on the left, connected to a “frontend server” in the center, with a third component,
    “database,” on the right. This isn’t helpful, because nearly every web application
    ever devised fits this model. All the assets are presumably in the database, but
    what exactly are they? There must be a trust boundary between the system and the
    internet, but is that the only one? Clearly, this model operates at too high a
    level. At the other extreme would be a model showing a detailed breakdown of every
    library, all the dependencies of the framework, and the relationships of components
    far below the level of the application you want to analyze.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'The Goldilocks version would fall somewhere between these extremes. The data
    stored in the database (assets) would be clumped into categories, each of which
    you could treat as a whole: say, customer data, inventory data, and system logs.
    The server component would be broken into parts granular enough to reveal multiple
    processes, including what privilege each runs at, perhaps an internal cache on
    the host machine, and descriptions of the communication channels and network used
    to talk to the internet and the database.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Identify Assets
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Working methodically through the model, identify assets and the potential threats
    to them. Assets are the entities in the system that you must protect. Most assets
    are data, but they could also include hardware, communication bandwidth, computational
    capacity, and physical resources, such as electricity.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'Beginners at threat modeling naturally want to protect everything, which would
    be great in a perfect world. But in practice, you’ll need to prioritize your assets.
    For example, consider any web application: anyone on the internet can access it
    using browsers or other software that you have no control over, so it’s impossible
    to fully protect the client side. Also, you should always keep internal system
    logs private, but if the logs contain harmless details of no value to outsiders,
    it doesn’t make sense to invest much energy in protecting them. This doesn’t mean
    that you ignore such risks completely; just make sure that less important mitigations
    don’t take away effort needed elsewhere. For example, it literally takes a minute
    to protect non-sensitive logs by setting permissions so that only administrators
    can read the contents, so that’s effort well spent.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, you could effectively treat data representing financial transactions
    as real money and prioritize it accordingly. Personal information is another increasingly
    sensitive category of asset, because knowledge of a person’s location or other
    identifying details can compromise their privacy or even put them at risk.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Also, I generally advise against attempting to perform complex risk-assessment
    calculations. For example, avoid attempting to assign dollar values for the purpose
    of risk ranking. To do this, you would have to somehow come up with probabilities
    for many unknowables. How many attackers will target you, and how hard will they
    try, and to do what? How often will they succeed, and to what degree? How much
    money is the customer database even worth? (Note that its value to the company
    and the amount an attacker could sell it for often differ, as might the value
    that users would assign to their own data.) How many hours of work and other expenses
    will a hypothetical security incident incur?
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Instead, a simple way to prioritize assets that’s surprisingly effective is
    to rank them by “T-shirt sizes”—a simplification that I find useful, though it’s
    not a standard industry practice. Assign “Large” to major assets you definitely
    protect, “Medium” to valuable assets that are less critical, and “Small” to lesser
    ones of minor consequence (usually not even listed). High-value systems may have
    “Extra-Large” assets that deserve extraordinary levels of protection, such as
    bank account balances at a financial institution, or private encryption keys that
    anchor the security of communications. In this simple scheme, protection and mitigation
    efforts focus first on Large assets, and then *opportunistically* on Medium ones.
    Opportunistic protection consists of low-effort work that has little downside.
    But even if you can secure Small assets very opportunistically, defend all Large
    assets before spending any time on these. Chapter 13 discusses ranking vulnerabilities
    in detail, and much of that is applicable to threat assessment as well.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: The assets you choose to prioritize should probably include data such as customer
    resources, personal information, business documents, operational logs, and software
    internals, to name just a few possibilities. Prioritizing protection of data assets
    considers many factors, including information security (the C-I-A triad discussed
    in Chapter 1), because the harms of leaking, modification, and destruction of
    data may differ greatly. Information leaks, including partial disclosures of information
    (for example, the last four digits of a credit card number), are tricky to evaluate,
    because you must consider what an attacker could do with the information. Analysis
    becomes harder still when an attacker could join multiple shards of information
    into an approximation of the complete dataset.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: If you lump assets together, you can simplify the analysis considerably, but
    beware of losing resolution in the process. For example, if you administer several
    of your databases together, grant access similarly, use them for data that originates
    from similar sources, and store them in the same location, treating them as one
    makes good sense. However, if any of these factors differs significantly, you
    would have sufficient reason to handle them separately. Make sure to consider
    these distinctions in your risk analysis, as well as for mitigation purposes.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, always consider the value of assets from the perspectives of all parties
    involved. For instance, social media services manage all kinds of data: internal
    company plans, advertising data, and customer data. The value of each of these
    assets differs depending on if you are the company’s CEO, an advertiser, a customer,
    or perhaps an attacker seeking financial gain or pursuing a political agenda.
    In fact, even among customers you’ll likely find great differences in how they
    perceive the importance of privacy in their communications, or the value they
    place on their data. Good data stewardship principles suggest that your protection
    of customer and partner data should arguably exceed that of the company’s own
    proprietary data (and I have heard of company executives actually stating this
    as policy).'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Not all companies take this approach. Facebook’s Beacon feature automatically
    posted the details of users’ purchases to their news feeds, then quickly shut
    down following an immediate outpouring of customer outrage and some lawsuits.
    While Beacon never endangered Facebook (except by damaging the brand’s reputation),
    it posed a real danger to customers. Threat modeling the consequences of information
    disclosure for customers would have quickly revealed that the unintended disclosure
    of purchases of Christmas or birthday presents, or worse, engagement rings, was
    likely to prove problematic.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Identify Attack Surfaces
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Pay special attention to attack surfaces, because these are the attacker’s first
    point of entry. You should consider any opportunity to minimize the attack surface
    a big win, because doing so shuts off a potential source of trouble entirely.
    Many attacks potentially fan out across the system, so stopping them early can
    be a great defense. This is why secure government buildings have checkpoints with
    metal detectors just inside the single public entrance.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Software design is typically much more complex than the design of a physical
    building, so identifying the entire attack surface is not so simple. Unless you
    can embed a system in a trusted, secure environment, having some attack surface
    is inevitable. The internet always provides a huge point of exposure, since literally
    anyone anywhere can anonymously connect through it. While it might be tempting
    to consider an *intranet* (a private network) as trusted, you probably shouldn’t,
    unless it has very high standards of both physical and IT security. At the very
    least, treat it as an attack surface with reduced risk. For devices or kiosk applications,
    consider the outside portion of the box, including screens and user interface
    buttons, an attack surface.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that attack surfaces exist outside the digital realm. Consider the kiosk,
    for example: a display in a public area could leak information via “shoulder surfing.”
    An attacker could also perform even subtler *side-channel attacks* to deduce information
    about the internal state of a system by monitoring its electromagnetic emissions,
    heat, power consumption, keyboard sounds, and so forth.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Identify Trust Boundaries
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, identify the system’s trust boundaries. Since trust and privilege are
    almost always paired, you can think in terms of privilege boundaries if that makes
    more sense. Human analogs of trust boundaries might be the interface between a
    manager (who is privy to more internal information) and an employee, or the door
    of your house, where you choose whom to let inside.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider a classic example of a trust boundary: an operating system’s kernel-userland
    interface. This architecture became popular in a time when mainframe computers
    were the norm and machines were often shared by many users. The system booted
    up the kernel, which isolated applications in different userland process instances
    (corresponding to different user accounts) from interfering with each other or
    crashing the whole system. Whenever userland code calls into the kernel, execution
    crosses a trust boundary. Trust boundaries are important, because the transition
    into higher-privilege execution is an opportunity for bigger trouble.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: The SSH secure shell daemon (`sshd(8)`) is a great example of secure design
    with trust boundaries. The SSH protocol allows authorized users to remotely log
    in to a host, then run a shell via a secure network channel over the internet.
    But the SSH daemon, which persistently listens for connections to initiate the
    protocol, requires very careful design because it crosses a trust boundary. The
    listener process typically needs superuser privileges, because when an authorized
    user presents valid credentials, it must be able to create processes for any user.
    Yet it must also listen to the public internet, exposing it to the world for attack.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: To accept SSH login requests, the daemon must generate a secure channel for
    communication that’s impervious to snooping or tampering, then handle and validate
    sensitive credentials. Only then can it instantiate a shell process on the host
    computer with the right privileges. This entire process involves a lot of code,
    running with the highest level of privilege (so it can create a process for any
    user account), that must operate perfectly or risk deeply compromising the system.
    Incoming requests can come from anywhere on the internet and are initially indistinguishable
    from attacks, so it’s hard to imagine a more attractive target with higher stakes.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Given the large attack surface and the severity of any vulnerability, extensive
    efforts to mitigate risk are justified for the daemon process. [Figure 2-1](#figure2-1)
    shows a simplified view of how it is designed to protect this critical trust boundary.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '![f02001](image_fi/501928c02/f02001.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2-1: How the design of the SSH daemon protects critical trust boundaries'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Working from the top, each incoming connection forks a low-privilege child process,
    which listens on the socket and communicates with the parent (superuser) process.
    This child process also sets up the protocol’s complex secure-channel encryption
    and accepts login credentials that it passes to the privileged parent, which decides
    whether or not to trust the incoming request and grant it a shell. Forking a new
    child process for each request provides a strategic protection on the trust boundary;
    it isolates as much of the work as possible, and also minimizes the risk of unintentional
    side effects building up within the main daemon process. When a user successfully
    logs in, the daemon creates a new shell process with the privileges of the authenticated
    user account. When a login attempt fails to authenticate, the child process that
    handled the request terminates, so it can’t adversely affect the system in the
    future.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: As with assets, you’ll decide when to lump together or split trust levels. In
    an operating system, the superuser is, of course, the highest level of trust,
    and some other administrative users may be close enough that you should consider
    them to be just as privileged. Authorized users typically rank next on the totem
    pole of trust. Some users may form a more trusted group with special privileges,
    but usually, there is no need to decide who you trust a little or more or less
    among them. Guest accounts typically rank lowest in trust, and you should probably
    emphasize protecting the system from them, rather than protecting their resources.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Web services need to resist malicious client users, so web frontend systems
    may validate incoming traffic and only forward well-formed requests for service,
    in effect straddling the trust boundary to the internet. Web servers often connect
    to more trusted databases and microservices behind a firewall. If money is involved
    (say, in a credit card processing service), a dedicated high-trust system should
    handle payments, ideally isolated in a fenced-off area of the datacenter. Authenticated
    users should be trusted to access their own account data, but you should treat
    them as very much untrusted beyond that, since anyone can typically create a login.
    Anonymous public web access represents an even lower trust level, and static public
    content could be served by machines unconnected to any private data services.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Always conduct transitions across trust boundaries through well-defined interfaces
    and protocols. You can think of these as analogous to checkpoints staffed by armed
    guards at international frontiers and ports of entry. Just as the border control
    agents ask for your passport (a form of authentication) and inspect your belongings
    (a form of input validation), you should treat the trust boundary as a rich opportunity
    to mitigate potential attacks.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: The biggest risks usually hide in low-to-high trust transitions, like the SSH
    listener example, for obvious reasons. However, this doesn’t mean you should ignore
    high-to-low trust transitions. Any time your system passes data to a less-trusted
    component, it’s worth considering if you’re disclosing information, and if doing
    so might be a problem. For example, even low-privilege processes can read the
    hostname of the computer they are running in, so don’t name machines using sensitive
    information that might give attackers a hint if they attain a beachhead and get
    code running on the system. Additionally, whenever high-trust services work on
    behalf of low-trust requests, you risk a DoS attack if the userland requester
    manages to overtax the kernel.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Identify Threats
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now we begin the work at the heart of threat modeling: identifying potential
    threats. Working from your model, pore over the parts of the system. The threats
    tend to cluster around assets and at trust boundaries, but could potentially lurk
    anywhere.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: I recommend starting with a rough pass (say, from a 10,000-foot view of the
    system), then coming back later for a more thorough examination (at 1,000 feet)
    of the more fruitful or interesting parts. Keep an open mind, and be sure to include
    possibilities even if you cannot yet see exactly how to exploit them.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Identifying direct threats to your assets should be easy, as well as threats
    at trust boundaries, where attackers might easily trick trusted components into
    doing their bidding. Many examples of such threats in specific situations are
    given throughout this book. Yet you might also find threats that are indirect,
    perhaps because there is no asset immediately available to harm, or a trust boundary
    to cross. Don’t immediately disregard these without considering how such threats
    might work as part of a chain of events—think of them as bank shots in billiards,
    or stepping stones that form a path. In order to do damage, an attacker would
    have to combine multiple indirect threats; or perhaps, paired with bugs or poorly
    designed functionality, the indirect threats afford openings that give attackers
    a foot in the door. Even lesser threats might be worth mitigating, depending on
    how promising they look and how critical the asset at risk may be.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: A Bank Vault Example
  id: totrans-242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: So far, these concepts may still seem rather abstract, so let’s look at them
    in context by threat modeling an imaginary bank vault. While reading this walkthrough,
    focus on the concepts, and if you are paying attention, you should be able to
    expand on the points I raise (which, intentionally, are not exhaustive).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'Picture a bank office in your hometown. Say it’s an older building, with impressive
    Roman columns framing the heavy solid oak double doors in front. Built back when
    labor and materials were inexpensive, the thick, reinforced concrete walls appear
    impenetrable. For the purpose of this example, let’s focus solely on the large
    stock of gold stored in the secure vault at the heart of the bank building: this
    is the major asset we want to protect. We’ll use the building’s architectural
    drawings as the model, working from a floor plan with a 10-foot to 1-inch scale
    that provides an overview of the entire building’s layout.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The major trust boundary is clearly at the vault door, but there’s another one
    at the locked door to the employee-only area behind the counter, and a third at
    the bank’s front door that separates the customer lobby from the exterior. For
    simplicity, we’ll omit the back door from the model because it’s very securely
    locked at all times and only opened rarely, when guards are present. This leaves
    the front door and easily-accessible customer lobby areas as the only significant
    attack surfaces.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'All of this sets the stage for the real work of finding potential threats.
    Obviously, having the gold stolen is the top threat, but that’s too vague to provide
    much insight into how to prevent it, so we continue looking for specifics. The
    attackers would need to gain unauthorized access to the vault in order to steal
    the gold. In order to do that, they’d need unauthorized access to the employee-only
    area where the vault is located. So far, we don’t know *how* such abstract threats
    could occur, but we can break them down and get more specific. Here are just a
    few potential threats:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Observe the vault combination covertly.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guess the vault combination.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Impersonate the bank’s president with makeup and a wig.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Admittedly, these made-up threats are fairly silly, but notice how we developed
    them from a model, and how we transitioned from abstract threats to concrete ones.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'In a more detailed second pass, we now use a model that includes full architectural
    drawings, the electrical and plumbing layout, and vault design specifications.
    Armed with more detail, we can imagine specific attacks more easily. Take the
    first threat we just listed: the attacker observing the vault combination. This
    could happen in several ways. Let’s look at three of them:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: An eagle-eyed robber loiters in the lobby to observe the opening of the vault.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The vault combination is on a sticky note, visible to a customer at the counter.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A confederate across the street can watch the vault combination dial through
    a scope.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naturally, just knowing the vault combination does not get the intruders any
    gold. An outsider learning the combination is a major threat, but it’s just one
    part of a complete attack that must include entering the employee-only area, entering
    the vault, and then escaping with the gold.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can prioritize the enumerated threats and propose mitigations. Here
    are some straightforward mitigations to each potential attack we’ve identified:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'Lobby loiterer: put an opaque screen in front of the vault.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sticky-note leak: institute a policy prohibiting unsecured written copies.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scope spy: install opaque, translucent glass windows.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just a few of the many possible defensive mitigations. If these types
    of attacks had been considered during the building’s design, perhaps the layout
    could have eliminated some of these threats in the first place (for example, by
    ensuring there was no direct line of sight from any exterior window to the vault
    area, avoiding the need to retrofit opaque glass).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Real bank security and financial risk management are of course far more complex,
    but this simplified example shows how the threat modeling process works, including
    how it propels analysis forward. Gold in a vault is about as simple an asset as
    it gets, but now you should be wondering, how exactly does one examine a model
    of a complex software system to be able to see the threats it faces?
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Categorizing Threats with STRIDE
  id: totrans-262
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In the late 1990s, Microsoft Windows dominated the personal computing landscape.
    As PCs became essential tools for both businesses and homes, many believed the
    company’s sales would grow endlessly. But Microsoft had only begun to figure out
    how networking should work. The Internet (back then still usually spelled with
    a capital I) and this new thing called the World Wide Web were rapidly gaining
    popularity, and Microsoft’s Internet Explorer web browser had aggressively gained
    market share from the pioneering Netscape Navigator. Now the company faced this
    new problem of security: Who knew what can of worms connecting all the world’s
    computers might open up?'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: While a team of Microsoft testers worked creatively to find security flaws,
    the rest of the world appeared to be finding these flaws much faster. After a
    couple of years of reactive behavior, issuing patches for vulnerabilities that
    exposed customers over the network, the company formed a task force to get ahead
    of the curve. As part of this effort, I co-authored a paper with Praerit Garg
    that described a simple methodology to help developers see security flaws in their
    own products. Threat modeling based on the *STRIDE* *threat taxonomy* drove a
    massive education effort across all the company’s product groups. More than 20
    years later, researchers across the industry continue to use STRIDE and many independent
    derivatives to enumerate threats.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'STRIDE focuses the process of identifying threats by giving you a checklist
    of specific kinds of threats to consider: What can be *spoofed (S)*, *tampered
    (T)* with, or *repudiated (R)*? What *information (I)* can be disclosed? How could
    a *denial of service (D)* or *elevation of privilege (E)* happen? These categories
    are specific enough to focus your analysis, yet general enough that you can mentally
    flesh out details relevant to a particular design and dig in from there.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Though members of the security community often refer to STRIDE as a threat modeling
    methodology, this is a misuse of the term (to my mind, at least, as the one who
    concocted the acronym). STRIDE is simply a taxonomy of threats to software. The
    acronym provides an easy and memorable mnemonic to ensure that you haven’t overlooked
    any category of threat. It’s not a complete threat modeling methodology, which
    would have to include the many other components we’ve already explored in this
    chapter.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: To see how STRIDE works, let’s start with spoofing. Looking through the model,
    component by component, consider how secure operation depends on the identity
    of the user (or machine, or digital signature on code, and so on). What advantages
    might an attacker gain if they could spoof identity here? This thinking should
    give you lots of possible threads to pull on. By approaching each component in
    the context of the model from a threat perspective, you can more easily set aside
    thoughts of how it should work, and instead begin to perceive how it might be
    abused.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a great technique I’ve used successfully many times: start your threat
    modeling session by writing the six threat names on a whiteboard. To get rolling,
    brainstorm a few of these abstract threats before digging into the details. The
    term “brainstorm” can mean different things, but the idea here is to move quickly,
    covering a lot of area, without overthinking it too much or judging ideas yet
    (you can skip the duds later on). This warm-up routine primes you for what to
    look out for, and also helps you switch into the necessary mindset. Even if you’re
    familiar with these categories of threat, it’s worth going through them all, and
    a couple that are less familiar and more technical bear careful explanation.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 2-1](#table2-1) lists six security objectives, their corresponding threat
    categories, and several examples of threats in each category. The security objective
    and threat category are two sides of the same coin, and sometimes it’s easier
    to work from one or the other—on the defense (the objective) or the offense (the
    threat).'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2-1: Summary of STRIDE Threat Categories'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '| **Objective** | **STRIDE threats** | **Examples** |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: '| Authenticity | Spoofing | Phishing, stolen password, impersonation, replay
    attack, [BGP hijacking](https://www.cloudflare.com/learning/security/glossary/bgp-hijacking/)
    |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
- en: '| Integrity | Tampering | Unauthorized data modification and deletion, [Superfish
    ad injection](https://us-cert.cisa.gov/ncas/alerts/TA15-051A) |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
- en: '| Non-repudiability | Repudiation | Plausible deniability, insufficient logging,
    destruction of logs |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
- en: '| Confidentiality | Information disclosure | Data leak, side channel attack,
    weak encryption, residual cached data, [Spectre/Meltdown](https://meltdownattack.com/
    ) |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
- en: '| Availability | Denial of service | Simultaneous requests swamp a web server,
    ransomware, [memcrashed](https://blog.cloudflare.com/memcrashed-major-amplification-attacks-from-port-11211/
    ) |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
- en: '| Authorization | Elevation of privilege | SQL injection, xkcd’s “[Exploits
    of a Mom](https://xkcd.com/327/)” |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
- en: 'Half of the STRIDE menagerie are direct threats to the information security
    fundamentals you learned about in Chapter 1: information disclosure is the enemy
    of confidentiality, tampering is the enemy of integrity, and denial of service
    compromises availability. The other half of STRIDE targets the Gold Standard.
    Spoofing subverts authenticity by assuming a false identity. Elevation of privilege
    subverts proper authorization. That leaves repudiation as the threat to auditing,
    which may not be immediately obvious and so is worth a closer look.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: According to the Gold Standard, we should maintain accurate records of critical
    actions taken within the system and then audit those actions. Repudiation occurs
    when someone credibly denies that they took some action. In my years working in
    software security, I have never seen anyone directly repudiate anything (nobody
    has ever yelled “did so!” and “did not!” at each other in front of me). But what
    does happen is, say, a database suddenly disappears, and nobody knows why, because
    nothing was logged, and the lost data is gone without a trace. The organization
    might suspect that an intrusion occurred. Or it could have been a rogue insider,
    or possibly a regrettable blunder by an administrator. But without any evidence,
    nobody knows. That’s a big problem, because if you cannot explain what happened
    after an incident, it’s very hard to prevent it from happening again. In the physical
    world, such perfect crimes are rare because activities such as robbing a bank
    involve physical presence, which inherently leaves all kinds of traces. Software
    is different; unless you provide a means to reliably collect evidence and log
    events, no fingerprints or muddy boot tracks remain as evidence.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Typically, we mitigate the threat of repudiation by running systems in which
    administrators and users understand they are responsible for their actions, because
    they know an accurate audit trail exists. This is also one more good reason to
    avoid having admin passwords written on a sticky note that everyone shares. If
    you do that, when trouble happens, everyone can credibly claim someone else must
    have done it. This applies even if you fully trust everyone, because accidents
    happen, and the more evidence you have available when trouble arises, the easier
    it is to recover and remediate.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: STRIDE at the Movies
  id: totrans-282
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Just for fun (and to solidify these concepts), consider the STRIDE threats applied
    to the plot of the film *Ocean’s Eleven*. This classic heist story nicely demonstrates
    threat modeling concepts, including the full complement of STRIDE categories,
    from the perspectives of both attacker and defender. Apologies for the simplification
    of the plot, which I’ve done for brevity and focus, as well as for spoilers.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Danny Ocean violates parole (an *elevation of privilege*), flies out to meet
    his old partner in crime, and heads for Vegas. He pitches an audacious heist to
    a wealthy casino insider, who fills him in on the casino’s operational details
    (*information disclosure*), then gathers his gang of ex-cons. They plan their
    operation using a full-scale replica vault built for practice. On the fateful
    night, Danny appears at the casino and is predictably apprehended by security,
    creating the perfect alibi (*repudiation* of guilt). Soon he slips away through
    an air duct, and through various intrigues he and his accomplices extract half
    the money from the vault (*tampering* with its integrity), exfiltrating their
    haul with a remote-control van.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Threatening to blow up the remaining millions in the vault (a very expensive
    *denial of service*), the gang negotiates to keep the money in the van. The casino
    owner refuses and calls in the SWAT team, and in the ensuing chaos the gang destroys
    the vault’s contents and gets away. After the smoke clears, the casino owner checks
    the vault, lamenting his total loss, then notices a minor detail that seems amiss.
    The owner confronts Danny—who is back in lockup, as if he had never left—and we
    learn that the SWAT team was, in fact, the gang (*spoofing* by impersonating the
    police), who walked out with the money hidden in their tactical equipment bags
    after the fake battle. The practice vault mock-up had provided video to make it
    only appear (*spoofing* of the location) that the real vault had been compromised,
    which didn’t actually happen until the casino granted full access to the fake
    SWAT team (an *elevation of privilege* for the gang). Danny and the gang make
    a clean getaway with the money—a happy ending for the perpetrators that might
    have turned out quite differently had the casino hired a threat modeling consultant!
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Mitigate Threats
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At this stage, you should have a collection of potential threats. Now you need
    to assess and prioritize them to best guide an effective defense. Since threats
    are, at best, educated guesses about future events, all of your assessments will
    contain some degree of subjectivity.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: What exactly does it mean to understand threats? There is no easy answer to
    this question, but it involves refining what we know, and maintaining a healthy
    skepticism to avoid falling into the trap of thinking that we have it all figured
    out. In practice, this means quickly scanning to collect a bunch of mostly abstract
    threats, then poking into each one a little further to learn more. Perhaps we
    will see one or two fairly clear-cut attacks, or parts of what could constitute
    an attack. We elaborate until we run up against a wall of diminishing returns.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we can deal with the threats we’ve identified in one of four
    ways:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '*Mitigate* the risk by either redesigning or adding defenses to reduce its
    occurrence or lower the degree of harm to an acceptable level.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Remove* a threatened asset if it isn’t necessary, or, if removal isn’t possible,
    seek to reduce its exposure or limit optional features that increase the threat.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Transfer* the risk by offloading responsibility to a third party, usually
    in exchange for compensation. (Insurance, for example, is a common form of risk
    transfer, or the processing of sensitive data could be outsourced to a service
    with a duty to protect confidentiality.)'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Accept* the risk, once it is well understood, as reasonable to incur.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Always attempt to mitigate any significant threats, but recognize that results
    are often mixed. In practice, the best possible solution isn’t always feasible,
    for many reasons: a major change might be too costly, or you may be stuck using
    an external dependency beyond your control. Other code might also depend on vulnerable
    functionality, such that a fix might break things. In these cases, mitigation
    means doing anything that reduces the threat. Any kind of edge for defense helps,
    even a small one.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some examples of ways to do partial mitigation:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '**Make harm less likely to occur**'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: Make it so the attack only works a fraction of the time.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Make harm less severe**'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Make it so only a small part of the data can be destroyed.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Make it possible to undo the harm**'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that you can easily restore any lost data from a backup.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Make it obvious that harm occurred**'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Use tamper-evident packaging that makes it easy to detect a modified product,
    protecting consumers. (In software, good logging helps here.)
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Much of the remainder of the book is about mitigation: how to design software
    to minimize threats, and what strategies and secure software patterns are useful
    for devising mitigations of various sorts.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Privacy Considerations
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Privacy threats are just as real as security threats, and they require separate
    consideration in a full assessment of threats to a system, because they add a
    human element to the risk of information disclosure. In addition to possible regulatory
    and legal considerations, personal information handling may involve ethical concerns,
    and it’s important to honor stakeholder expectations.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: If you’re collecting personal data of any kind, you should take privacy seriously
    as a baseline stance. Think of yourself as a steward of people’s private information.
    Strive to stay mindful of your users’ perspectives, including careful consideration
    of the wide range of privacy concerns they might have, and err on the side of
    care. It’s easy for builders of software to discount how sensitive personal data
    can be when they’re immersed in the logic of system building. What in code looks
    like yet another field in a database schema could be information that, if leaked,
    has real consequences for an actual person. As modern life increasingly goes digital,
    and mobile computing becomes ubiquitous, privacy will depend more and more on
    code, potentially in new ways that are difficult to imagine. All this is to say
    that you would be smart to stay well ahead of the curve by exercising extreme
    vigilance now.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'A few very general considerations for minimizing privacy threats include the
    following:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Assess privacy by modeling scenarios of actual use cases, not thinking in the
    abstract.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn what privacy policies or legal requirements apply, and follow the terms
    rigorously.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restrict the collection of data to only what is necessary.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be sensitive to the possibility of seeming creepy.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Never collect or store private information without a clear intention for its
    use.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When information already collected is no longer used or useful, proactively
    delete it.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize information sharing with third parties (which, if it occurs, should
    be well documented).
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize disclosure of sensitive information—ideally this should be done only
    on a need-to-know basis.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be transparent, and help end users understand your data protection practices.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threat Modeling Everywhere
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The threat modeling process described here is a formalization of how we navigate
    in the world; we manage risk by balancing it against opportunities. In a dangerous
    environment, all living organisms make decisions based on these same basic principles.
    Once you start looking for it, you can find instances of threat modeling everywhere.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: 'When expecting a visit from friends with a young child, we always take a few
    minutes to make special preparations. Alex, an active three-year-old, has an inquisitive
    mind, so we go through the house “child-proofing.” This is pure threat modeling,
    as we imagine the threats by categories—what could hurt Alex, what might get broken,
    what’s better kept out of view of a youngster—then look for assets that fit these
    patterns. Typical threats include a metal letter opener, which he could stick
    in a wall socket; a fragile antique vase that he might easily break; or perhaps
    a coffee table book of photography that contains images inappropriate for children.
    The attack surface is any place reachable by an active toddler. Mitigations generally
    consist of removing, reducing, or eliminating points of exposure or vulnerability:
    we could replace the fragile vase with a plastic one that contains just dried
    flowers, or move it up onto a mantlepiece. People with children know how difficult
    it is to anticipate what they might do. For instance, did we anticipate Alex might
    stack up enough books to climb up and reach a shelf that we thought was out of
    reach? This is what threat modeling looks like outside of software, and it illustrates
    why preemptive mitigation can be well worth the effort.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few other examples of threat modeling you may have noticed in daily
    life:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: Stores design return policies specifically to mitigate abuses such as shoplifting
    and then returning the product for store credit, or wearing new apparel once and
    then returning it for a refund.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Website terms of use agreements attempt to prevent various ways that users might
    maliciously abuse the site.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traffic safety laws, speed limits, driver licensing, and mandatory auto insurance
    requirements are all mitigation mechanisms to make driving safer.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Libraries design loan policies to mitigate theft, hoarding, and damage to the
    collection.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can probably think of lots of ways that you apply these techniques, too.
    For most of us, when we can draw on our physical intuitions about the world, threat
    modeling is remarkably easy to do. Once you recognize that software threat modeling
    works the same way as your already well-honed skills in other contexts, you can
    begin to apply your natural capabilities to software security analysis, and quickly
    raise your skills to the next level.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '3'
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mitigation
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: Everything is possible to mitigate through art and diligence.
  id: totrans-329
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-330
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Gaius Plinius Caecilius Secundus (Pliny the Younger)
  id: totrans-331
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
- en: 'This chapter focuses on the third of the Four Questions from Chapter 2: “What
    are we going to do about it?” Anticipating threats, then protecting against potential
    vulnerabilities, is how security thinking turns into effective action. This proactive
    response is called *mitigation*—reducing the severity, extent, or impact of problems—and
    as you saw in the previous chapter, it’s something we all do all the time. Bibs
    to catch the inevitable spills when feeding an infant, seat belts, speed limits,
    fire alarms, food safety practices, public health measures, and industrial safety
    regulations are just a few examples of mitigations. The common thread among these
    is that they take proactive measures to avoid, or lessen, anticipated harms in
    the face of risk. This is much of what we do to make software more secure.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to bear in mind that mitigations reduce risk but don’t eliminate
    it. To be clear, if you can eliminate a risk somehow—say, by removing a legacy
    feature that is known to be insecure—by all means do that, but I would not call
    it a mitigation. Instead, mitigations focus on making attacks less likely, more
    difficult, or less harmful when they do occur. Even measures that make exploits
    more detectable are mitigations, analogous to tamper-evident packaging, if they
    lead to a faster response and remediation. Every small effort ratchets up the
    security of the system as a whole, and even modest wins can collectively add up
    to significantly better protection.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: This chapter begins with a conceptual discussion of mitigation, and from there
    presents a number of general techniques. The focus here is on structural mitigations
    based on the perspective gained through threat modeling that can be useful for
    securing almost any system design. Subsequent chapters will build on these ideas
    to provide more detailed methods, drilling down into specific technologies and
    threats.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the chapter provides guidance for recurrent security challenges
    encountered in software design: instituting an access policy and access controls,
    designing interfaces, and protecting communications and storage. Together, these
    discussions form a playbook for addressing common security needs that will be
    fleshed out over the remainder of the book.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: Addressing Threats
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Threat modeling reveals what can go wrong, and in doing so, focuses our security
    attention where it counts. But believing we can always eliminate vulnerabilities
    would be naive. Points of risk—critical events or decision thresholds—are great
    opportunities for mitigation.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: 'As you learned in the previous chapter, you should always address the biggest
    threats first, limiting them as best you can. For systems that process sensitive
    personal information, as one example, the threat of unauthorized disclosure inevitably
    looms large. For this major risk, consider any or all of the following: minimizing
    access to the data, reducing the amount of information collected, actively deleting
    old data when no longer needed, auditing for early detection in the event of compromise,
    and taking measures to reduce an attacker’s ability to exfiltrate data. After
    securing the highest-priority risks, opportunistically mitigate lesser risks where
    it is easy to do so without adding much overhead or complexity to the design.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: A good example of a smart mitigation is the best practice of checking the password
    submitted with each login attempt against a salted hash, instead of the actual
    password in plaintext. Protecting passwords is critical because disclosure threatens
    the fundamental authentication mechanism. Comparing hashes only requires slightly
    more work than comparing directly, yet it’s a big win as it eliminates the need
    to store plaintext passwords. This means that even if attackers somehow breach
    the system, they won’t learn actual passwords as easily.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: This example illustrates the idea of harm reduction but is quite specific to
    password checking. Now let’s consider mitigation strategies that are more widely
    applicable.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: Structural Mitigation Strategies
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Mitigations often amount to common sense: reducing risk where there are opportunities
    to do so. Threat modeling helps us see potential vulnerabilities in terms of attack
    surfaces, trust boundaries, and assets (targets needing protection). *Structural
    mitigations* generally apply to these very features of the model, but their realization
    depends on the specifics of the design. The subsections that follow discuss techniques
    that should be widely applicable because they operate at the model level of abstraction.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: Minimize Attack Surfaces
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once you have identified the attack surfaces of a system, you know where exploits
    are most likely to originate, so anything you can do to harden the system’s “outer
    shell” will be a significant win. A good way to think about attack surface reduction
    is in terms of how much code and data are touched downstream of each point of
    entry. Systems that provide multiple interfaces to perform the same function may
    benefit from unifying these interfaces because that means less code that might
    contain vulnerabilities. Here are a few examples of this commonly used technique:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: In a client/server system, you can reduce the attack surface of the server by
    pushing functionality out to the client. Any operation that requires a server
    request represents an additional attack surface that a malformed request or forged
    credentials might be able to exploit. By contrast, if the necessary information
    and compute power exist on the client side, that reduces both the load on and
    the attack surface of the server.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving functionality from a publicly exposed API that anyone can invoke anonymously
    to an authenticated API can effectively reduce your attack surface. The added
    friction of account creation slows down attacks, and also helps trace attackers
    and enforce rate limiting.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Libraries and drivers that use kernel services can reduce the attack surface
    by minimizing interfaces to, and code within, the kernel. Not only are there fewer
    kernel transitions to attack that way, but userland code will be incapable of
    doing as much damage even if an attack is successful.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment and operations offer many attack surface reduction opportunities.
    For an enterprise network, moving anything you can behind a firewall is an easy
    win.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A configuration setting that enables remote administration over the network
    is another good example: this feature may be convenient, but if it’s rarely used,
    consider disabling it and use wired access instead when necessary.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just some of the most common scenarios where attack surface reduction
    works. For particular systems, you might find much more creative customized opportunities.
    Keep thinking of ways to reduce external access, minimize functionality and interfaces,
    and protect any services that are needlessly exposed. The better you understand
    where and how a feature is actually used, the more of these mitigations you’ll
    be able to find.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Narrow Windows of Vulnerability
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This mitigation technique is similar to attack surface reduction, but instead
    of metaphorical surface area, it reduces the effective time interval in which
    a vulnerability can occur. Also based on common sense, this is why hunters only
    disengage the safety just before firing and reengage it soon after.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: We usually apply this mitigation to trust boundaries, where low-trust data or
    requests interact with high-trust code. To best isolate the high-trust code, minimize
    the processing that it needs to do. For example, when possible, perform error
    checking ahead of invoking the high-trust code so it can do its work and exit
    quickly.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '*[Code Access Security](https://docs.microsoft.com/en-us/dotnet/framework/misc/code-access-security)**(CAS)*,
    a security model that is rarely used today, is a perfect illustration of this
    mitigation because it provides fine-grained control over code’s effective privileges.
    (Full disclosure: I was the program manager for security in .NET Framework version
    1.0, which prominently featured CAS as a major security feature.)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: 'The CAS runtime grants different permissions to different units of code based
    on trust. The following pseudocode example illustrates a common idiom for a generic
    `permission`, which could grant access to certain files, to the clipboard, and
    so on. In effect, CAS ensures that high-trust code inherits the lower privileges
    of the code invoking it, but when necessary, it can temporarily assert its higher
    privileges. Here’s how such an assertion of privilege works:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The code in this example has powerful privileges, but it may be called by less-trusted
    code. When invoked by low-trust code, this code initially runs with the reduced
    privileges of the caller. Technically, the effective privileges are the intersection
    (that is, the minimum) of the privileges granted to the code, its caller, and
    its caller’s caller, and so on all the way up the stack. Some of what the `Worker`
    method does requires higher privileges than its callers may have, so after doing
    the setup, it asserts the necessary permission before invoking `DoWorkRequiringPrivilege`,
    which must also have that permission. Having done that portion of its work, it
    immediately drops the special permission by calling `RevertAssert`, before doing
    whatever is left that needs no special permissions and returning. In the CAS model,
    time window minimization provides for such assertions of privilege to be used
    when necessary and reverted as soon as they are no longer needed.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: Consider this application of narrowing windows of vulnerability in a different
    way. Online banking offers convenience and speed, and mobile devices allow us
    to bank from anywhere. But storing your banking credentials in your phone is risky—you
    don’t want someone emptying out your bank account if you lose it, which is much
    more likely with a mobile device. A great mitigation that I would like to see
    implemented across the banking industry would be the ability to configure the
    privilege level you are comfortable with for each device. A cautious customer
    might restrict the mobile app to checking balances and a modest daily transaction
    dollar limit. The customer would then be able to bank by phone with confidence.
    Further useful limits might include windows of time, geolocation, domestic currency
    only, and so on. All of these mitigations help because they limit the worst-case
    scenario in the event of any kind of compromise.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: Minimize Data Exposure
  id: totrans-360
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another structural mitigation to data disclosure risk is limiting the lifetime
    of sensitive data in memory. This is much like the preceding technique, but here
    you’re minimizing the duration for which sensitive data is accessible and potentially
    exposed instead of the duration for which code is running at high privilege. Recall
    that intraprocess access is hard to control, so the mere presence of data in memory
    puts it at risk. When the stakes are high, such as handling extremely sensitive
    data, you can think of it as “the meter is running.” For the most critical information—data
    such as private encryption keys, or authentication credentials such as passwords—it
    may be worth overwriting any in-memory copies as soon as they are no longer needed.
    This reduces the time during which a leak is conceivably possible through any
    means. As we shall see in Chapter 9, the Heartbleed vulnerability threatened security
    for much of the web, exposing all kinds of sensitive data lying around in memory.
    Limiting how long such data was retained probably would have been a useful mitigation
    (“stanching the blood flow,” if you will), even without foreknowledge of the exploit.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: 'You can apply this technique to data storage design as well. When a user deletes
    their account in the system, that typically causes their data to be destroyed,
    but the system often offers a provision for a manual restore of the account in
    case of accidental or malicious closure. The easy way to implement this is to
    mark closed accounts as to-be-deleted but keep the data in place for, say, 30
    days (after the manual restore period has passed) before the system finally deletes
    everything. To make this work, lots of code needs to check if the account is scheduled
    for deletion, lest it accidentally access the account data that the user directed
    to be destroyed. If a bulk mail job forgets to check, it could errantly send the
    user some notice that, to the user, would appear to be a violation of their intentions
    after they closed the account. This mitigation suggests a better option: after
    the user deletes the account, the system should push its contents to an offline
    backup and promptly delete the data. The rare case where a manual restore is needed
    can still be accomplished using the backup data, and now there is no way for a
    bug to possibly result in that kind of error.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, proactively wiping copies of data is an extreme measure
    that’s appropriate only for the most sensitive data, or important actions such
    as account closure. Some languages and libraries help do this automatically, and
    except where performance is a concern, a simple wrapper function can wipe the
    contents of memory clean before it is recycled.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: Access Policy and Access Controls
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Standard operating system permissions provide very rudimentary file access controls.
    These control *read* (confidentiality) or *write* (integrity) access on an all-or-nothing
    basis for individual files based on the user and group ownership of a process.
    Given this functionality, it’s all too easy to think in the same limited terms
    when designing protections for assets and resources—but the right access policy
    might be more granular and depend on many other factors.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: First, consider how ill-suited traditional access controls are for many modern
    systems. Web services and microservices are designed to work on behalf of principals
    that usually do not correspond to the process owner. In this case, one process
    services all authenticated requests, requiring permission to access all client
    data all the time. This means that in the presence of a vulnerability, all client
    data is potentially at risk.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: 'Defining an efficacious access policy is an important mitigation, as it closes
    the gap between what accesses should be allowed and what access controls the system
    happens to offer. Rather than start with the available operating system access
    controls, think through the needs of the various principals acting through the
    system and define an ideal access policy that expresses an accurate description
    of what constitutes proper access. A granular access policy potentially offers
    a wealth of options: you can cap the number of accesses per minute or hour or
    day, or enforce a maximum data volume, time-based limits corresponding to working
    hours, or variable access limits based on activity by peers or historical rates
    (to name a few obvious mechanisms).'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: Determining safe access limitations is hard work but worthwhile because it helps
    you understand the application’s security requirements. Even if the policy is
    not fully implemented in code, it will at least provide guidance for effective
    auditing. Given the right set of controls, you can start with lenient restrictions
    to gauge what real usage looks like and then, over time, narrow the policy as
    you learn how the system is used in practice.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider a hypothetical system that serves a team of customer service
    agents. Agents need access to the records of any customer who might contact them,
    but they only interact with a limited number of customers on a given day. A reasonable
    access policy might limit each agent to no more than 100 different customer records
    in one shift. With access to all records all the time, a dishonest agent could
    leak a copy of all customer data, whereas the limited policy greatly limits the
    worst-case daily damage.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: Once you have a fine-grained access policy, you face the challenge of setting
    the right limits. This can be difficult when you must avoid impeding rightful
    use in extreme edge cases. In the customer service example, for instance, you
    might restrict agents to accessing the records of up to 100 customers per shift
    as a way of accommodating seasonal peak demand, even though, on most days, needing
    even 50 records would be unusual. Why? It would be impractical to adjust the policy
    configuration throughout the year, and you want to allow for leeway so the limit
    never impedes work. Also, defining a more specific and detailed policy based on
    fixed dates might not work well, as there could be unexpected surges in activity
    at any time.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: But is there a way to narrow the gap between normal circumstances and the rare
    highest-demand case that the system should allow? One great tool to handle this
    tricky situation is a policy provision for self-declared exceptions to be used
    in extraordinary circumstances. Such an option allows individual agents to bump
    up their own limits for a short period of time by providing a rationale. With
    this kind of “relief valve” in place, the basic access policy can be tightly constrained.
    When needed, once agents hit the access limit, they can file a quick notice—stating,
    for example, “high call volume today, I’m working late to finish up”—and receive
    additional access authorization. Such notices can be audited, and if they become
    commonplace, management could bump the policy up with the knowledge that demand
    has legitimately grown and an understanding of why. Such flexible techniques enable
    you to create access policies with softer limits, rather than hard-and-fast restrictions
    that tend to be arbitrary.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: Interfaces
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Software designs consist of components that correspond to functional parts of
    the system. You can visualize these designs as block diagrams, with lines representing
    the connections between the parts. These connections denote *interfaces*, which
    are a major focus of security analysis—not only because they reveal data and control
    flows, but also because they serve as well-defined chokepoints where you can add
    mitigations. In particular, where there is a trust boundary, the main security
    focus is on the flow of data and control from the lower- to the higher-trust component,
    so that is where defensive measures are often needed.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: In large systems, there are typically interfaces between networks, between processes,
    and within processes. Network interfaces provide the strongest isolation because
    it’s virtually certain that any interactions between the endpoints will occur
    over the wire, but with the other kinds of interfaces it’s more complicated. Operating
    systems provide strong isolation at process boundaries, so interprocess communication
    interfaces are nearly as trustworthy as network interfaces. In both of these cases,
    it’s generally impossible to go around these channels and interact in some other
    way. The attack surface is cleanly constrained, and hence this is where most of
    the important trust boundaries are. As a consequence, interprocess communication
    and network interfaces are the major focal points of threat modeling.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: 'Interfaces also exist within processes, where interaction is relatively unconstrained.
    Well-written software can still create meaningful security boundaries within a
    process, but these are only effective if all the code plays together well and
    stays within the lines. From the attacker’s perspective, intraprocess boundaries
    are much easier to penetrate. However, since attackers may only gain a limited
    degree of control via a given vulnerability, any protection you can provide is
    better than none. By analogy, think of a robber who only has a few seconds to
    act: even a weak precaution might be enough to prevent a loss.'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: Any large software design faces the delicate task of structuring components
    to minimize regions of highly privileged access, as well as restricting sensitive
    information flow in order to reduce security risk. To the extent that the design
    restricts information access to a minimal set of components that are well isolated,
    attackers will have a much harder time getting access to sensitive data. By contrast,
    in weaker designs, all kinds of data flow all over the place, resulting in greater
    exposure from a vulnerability anywhere within the component. The architecture
    of interfaces is a major factor that determines the success systems have at protecting
    assets.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: Communication
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Modern networked systems are so common that standalone computers, detached from
    any network, have become rare exceptions. The cloud computing model, combined
    with mobile connectivity, makes network access ubiquitous. As a result, communication
    is fundamental to almost every software system in use today, be it through internet
    connections, private networks, or peripheral connections via Bluetooth, USB, and
    the like.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: In order to protect these communications, the channel must be physically secured
    against wiretapping and snooping, or else the data must be encrypted to ensure
    its integrity and confidentiality. Reliance on physical security is typically
    fragile in the sense that if attackers bypass it, they usually gain access to
    the full data flow, and such incursions are difficult to detect. Modern processors
    are fast enough that the computational overhead of encryption is usually acceptable,
    so there is rarely a good reason not to encrypt communications. I cover basic
    encryption in Chapter 5, and HTTPS for the web specifically in Chapter 11.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: Even the best encryption is not a magic bullet, though. One remaining threat
    is that encryption cannot conceal the *fact of communication*. In other words,
    if attackers can read the raw data in the channel, even if they’re unable to decipher
    its contents, they can still see that data is being sent and received on the wire,
    and roughly estimate the amount of data flow. Furthermore, if attackers can tamper
    with the communication channel, they might be able to delay or block the transmission
    entirely.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: Storage
  id: totrans-381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The security of data storage is much like the security of communications, because
    storing data is analogous to sending it into the future, at which point you will
    retrieve it for some purpose. Viewed in this way, just as data that is being communicated
    is vulnerable on the wire, stored data is vulnerable at rest on the storage medium.
    Protecting data at rest from potential tampering or disclosure requires either
    physical security or encryption. Likewise, availability depends on the existence
    of backup copies or successful physical protection.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: Storage is so ubiquitous in system designs that it’s easy to defer the details
    of data security for operations to deal with, but doing so misses good opportunities
    for proactively mitigating data loss in the design. For instance, data backup
    requirements are an important part of software designs, because the demands are
    by no means obvious, and there are many trade-offs. You could plan for redundant
    storage systems, designed to protect against data loss in the event of failure,
    but these can be expensive and incur performance costs. Your backups might be
    copies of the whole dataset, or they could be incremental, recording transactions
    that, cumulatively, can be used to rebuild an accurate copy. Either way, they
    should be reliably stored independently and with specific frequency, within acceptable
    limits of latency. Cloud architectures can provide redundant data replication
    in near real-time for perhaps the best continuous backup solution, but at a cost.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: All data at rest, including backup copies, is at risk of exposure to unauthorized
    access, so you must physically secure or encrypt it for protection. The more backup
    copies you make, the greater the risk is of a leak due to having so many copies.
    Considering the potential extremes makes this point clear. Photographs are precious
    memories and irreplaceable pieces of every family’s history, so keeping multiple
    backup copies is wise—if you don’t have any copies and the original files are
    lost, damaged, or corrupted, the loss could be devastating. To guard against this,
    you might send copies of your family photos to as many relatives as possible for
    safekeeping. But this has a downside too, as it raises the chances that one of
    them might have the data stolen (via malware, or perhaps a stolen laptop). This
    could also be catastrophic, as these are private memories, and it would be a violation
    of privacy to see all those photos publicly spread all over the web (and potentially
    a greater threat if it allowed strangers to identify children in a way that could
    lead to exploitation). This is a fundamental trade-off that requires you to weigh
    the risks of data loss against the risk of leaks—you cannot minimize both at once,
    but you can balance these concerns to a degree in a few ways.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: As a compromise between these threats, you could send your relatives encrypted
    photos. (This means they would not be able to view them, of course.) However,
    now you are responsible for keeping the key that you chose not to entrust them
    with, and if you lose the key, the encrypted copies are worthless.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: Preserving photos also raises an important aspect of backing up data, which
    is the problem of media lifetime and obsolescence. Physical media (such as hard
    disks or DVDs) inevitably degrade over time, and support for legacy media fades
    away as new hardware evolves (this author recalls long ago personally moving data
    from dozens of floppy disks, which only antiquated computers can use, onto one
    USB memory stick, now copied to the cloud). Even if the media and devices still
    work, new software tends to drop support for older data formats. The choice of
    data format is thus important, with widely used open standards highly preferred,
    because proprietary formats must be reverse-engineered once they are officially
    retired. Over longer time spans, it might be necessary to convert file formats,
    as software standards evolve and application support for older formats becomes
    deprecated.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: The examples mentioned throughout this chapter have been simplified for explanatory
    purposes, and while we’ve covered many techniques that can be used to mitigate
    identified threats, these are just the tip of the iceberg of possibilities. Adapt
    specific mitigations to the needs of each application, ideally by making them
    integral to the design. While this sounds simple, effective mitigations are challenging
    in practice because a panoply of threats must be considered in the context of
    each system, and you can only do so much. The next chapter presents major patterns
    with useful security properties, as well as anti-patterns to watch out for, that
    are useful in crafting these mitigations as part of secure design.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '4'
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Patterns
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: Art is pattern informed by sensibility.
  id: totrans-390
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-391
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Herbert Read
  id: totrans-392
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
- en: Architects have long used design patterns to envision new buildings, an approach
    just as useful for guiding software design. This chapter introduces many of the
    most useful patterns promoting secure design. Several of these patterns derive
    from ancient wisdom; the trick is knowing how to apply them to software and how
    they enhance security.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: These patterns either mitigate or avoid various security vulnerabilities, forming
    an important toolbox to address potential threats. Many are simple, but others
    are harder to understand and best explained by example. Don’t underestimate the
    simpler ones, as they can be widely applicable and are among the most effective.
    Still, other concepts may be easier to grasp as anti-patterns describing what
    *not* to do. I present these patterns in groups based on shared characteristics
    that you can think of as sections of the toolbox ([Figure 4-1](#figure4-1)).
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '![f04001](image_fi/501928c04/f04001.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4-1: Groupings of secure software patterns this chapter covers'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: When and where to apply these patterns requires judgment. Let necessity and
    simplicity guide your design decisions. As powerful as these patterns are, don’t
    overdo it; just as you don’t need seven deadbolts and chains on your doors, you
    don’t need to apply every possible design pattern to fix a problem. Where several
    patterns are applicable, choose the best one or two, or maybe more for critical
    security demands. Overuse can be counterproductive because the diminishing returns
    of increased complexity and overhead quickly outweigh additional security gains.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: Design Attributes
  id: totrans-399
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first group of patterns describe at a high level what secure design looks
    like: simple and transparent. These derive from the adages “keep it simple” and
    “you should have nothing to hide.” As basic and perhaps obvious as these patterns
    may be, they can be applied widely and are very powerful.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: Economy of Design
  id: totrans-401
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Designs should be as simple as possible.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '*Economy of Design* raises the security bar because simpler designs likely
    have fewer bugs, and thus fewer undetected vulnerabilities. Though developers
    claim that “all software has bugs,” we know that simple programs certainly can
    be bug-free. Prefer the simplest of competing designs for security mechanisms,
    and be wary of complicated designs that perform critical security functions.'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: LEGO bricks are a great example of this pattern. Once the design and manufacture
    of the standard building element is perfected, it enables building a countless
    array of creative designs. A similar system composed of a number of less universally
    useful pieces would be more difficult to build with; any particular design would
    require a larger inventory of parts and involve other technical challenges.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: You can find many examples of Economy of Design in the system architecture of
    large web services built to run in massive datacenters. For reliability at scale,
    these designs decompose functionality into smaller, self-contained components
    that collectively perform complicated operations. Often, a basic frontend terminates
    the HTTPS request, parsing and validating the incoming data into an internal data
    structure. That data structure gets sent on for processing by a number of subservices,
    which in turn use microservices to perform various functions.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: In the case of an application such as web search, different machines may independently
    build different parts of the response in parallel, then yet another machine blends
    them into the complete response. It’s much easier to build many small services
    to do separate parts of the whole task—query parsing, spelling correction, text
    search, image search, results ranking, and page layout—than to do everything in
    one massive program.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: Economy of Design is not an absolute mandate that everything must always be
    simple. Rather, it highlights the great advantages of simplicity, and says that
    you should only embrace complexity when it adds significant value. Consider the
    differences between the design of access control lists (ACLs) in *nix and Windows.
    The former is simple, specifying read/write/execute permissions by user or user
    group, or for everybody. The latter is much more involved, including an arbitrary
    number of both allow and deny access control entries as well as an inheritance
    feature; notably, evaluation is dependent on the ordering of entries within the
    list. (These simplified descriptions are to make a point about design, and are
    not intended as complete.) This pattern correctly shows that the simpler *nix
    permissions are easier to correctly enforce, and beyond that, it’s easier for
    users of the system to correctly understand how ACLs work and therefore to use
    them correctly. However, if the Windows ACL provides just the right protection
    for a given application and can be accurately configured, then it may be a fine
    solution.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: The Economy of Design pattern does not say that the simpler option is unequivocally
    better, or that the more complex one is necessarily problematic. In this example,
    *nix ACLs are not inherently better, and Windows ACLs are not necessarily buggy.
    However, Windows ACLs do represent more of a learning curve for developers and
    users, and using their more complicated features can easily confuse people as
    well as invite unintended consequences. The key design choice here, which I will
    not weigh in on, is to what extent the ACL designs best fit the needs of users.
    Perhaps *nix ACLs are too simplistic and fail to meet real demands; on the other
    hand, perhaps Windows ACLs are overly feature-bound and cumbersome in typical
    use patterns. These are difficult questions we must each answer for our own purposes,
    but for which this design pattern provides insight.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: Transparent Design
  id: totrans-409
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Strong protection should never rely on secrecy.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps the most famous example of a design that failed to follow the pattern
    of *Transparent Design* is the Death Star in *Star Wars*, whose thermal exhaust
    port afforded a straight shot at the heart of the battle station. Had Darth Vader
    held his architects accountable to this principle as severely as he did Admiral
    Motti, the story would have turned out very differently. Revealing the design
    of a well-built system should have the effect of dissuading attackers by showing
    its invincibility. It shouldn’t make the task easier for them. The corresponding
    anti-pattern may be better known: we call it *Security by Obscurity*.'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: 'This pattern specifically warns against a *reliance* on the secrecy of a design.
    It doesn’t mean that publicly disclosing designs is mandatory, or that there is
    anything wrong with secret information. If full transparency about a design weakens
    it, you should fix the design, not rely on keeping it secret. This in no way applies
    to legitimately secret information, such as cryptographic keys or user identities,
    which actually would compromise security if leaked. That’s why the name of the
    pattern is Transparent *Design*, not Absolute Transparency. Full disclosure of
    the design of an encryption method—the key size, message format, cryptographic
    algorithms, and so forth—shouldn’t weaken security at all. The anti-pattern should
    be a big red flag: for instance, distrust any self-anointed “experts” who claim
    to invent amazing encryption algorithms that are so great that they cannot publish
    the details. Without exception, these are bogus.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem with Security by Obscurity is that while it may help forestall
    adversaries temporarily, it’s extremely fragile. For example, imagine that a design
    used an outdated cryptographic algorithm: if the attackers ever found out that
    the software was still using, say, DES (a legacy symmetric encryption algorithm
    from the 1970s), they could easily crack it within a day. Instead, do the work
    necessary to get to a solid security footing so that there is nothing to hide,
    whether or not the design details are public.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: Exposure Minimization
  id: totrans-414
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The largest group of patterns call for caution: think “err on the safe side.”
    These are expressions of basic risk/reward strategies where you play it safe unless
    there is an important reason to do otherwise.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: Least Privilege
  id: totrans-416
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s always safest to use just enough privilege for the job.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: Never clean a loaded gun. Unplug power saws when changing blades. These commonplace
    safety practices are examples of the *Least Privilege* pattern, which aims to
    reduce the risk of making mistakes when performing a task. This pattern is the
    reason that administrators of important systems should not be randomly browsing
    the internet while logged in at work; if they visit a malicious website and get
    compromised, the attack could easily do serious harm.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: The *nix `sudo(1)` command performs exactly this purpose. User accounts with
    high privilege (known as *sudoers*) need to be careful not to inadvertently use
    their extraordinary power by accident or if compromised. To provide this protection,
    the user must prefix superuser commands with `sudo`, which may prompt the user
    for a password, in order to run them. Under this system, most commands (those
    that do not require `sudo`) will affect only the user’s own account, and cannot
    impact the entire system. This is akin to the “IN CASE OF EMERGENCY BREAK GLASS”
    cover on a fire alarm switch to prevent accidental activation, in that this forces
    an explicit step (corresponding to the `sudo` prefix) before activating the switch.
    With the glass cover, nobody can claim to have accidentally pulled the fire alarm,
    just as a competent administrator would never type `sudo` and a command that breaks
    the system all by accident.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: This pattern is important for the simple reason that when vulnerabilities are
    exploited, it’s better for the attacker to have minimal privileges to use as leverage.
    Use all-powerful authorizations such as superuser privileges only when strictly
    necessary, and for the minimum possible duration. Even Superman practiced Least
    Privilege by only wearing his uniform when there was a job to do, and then, after
    saving the world, immediately changing back into his Clark Kent persona.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: In practice, it does take more effort to selectively and sparingly use elevated
    privileges. Just as unplugging power tools to work on them requires more effort,
    discretion when using permissions requires discipline, but doing it right is always
    safer. In the case of an exploit, it means the difference between a minor incursion
    and total system compromise. Practicing Least Privilege can also mitigate damage
    done by bugs and human error.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: Like all rules of thumb, use this pattern with a sense of balance to avoid overcomplication.
    Least Privilege does not mean the system should always grant literally the minimum
    level of authorization (for instance, creating code that, in order to write file
    X, is given write access to only that one file). You may wonder, why not always
    apply this excellent pattern to the max? In addition to maintaining a general
    sense of balance and recognizing diminishing returns for any mitigation, a big
    factor here is the granularity of the mechanism that controls authorization, and
    the cost incurred while adjusting privileges up and down. For instance, in a *nix
    process, permissions are conferred based on user and group ID access control lists.
    Beyond the flexibility of changing between effective and real IDs (which is what
    `sudo` does), there is no easy way to temporarily drop unneeded privileges without
    forking a process. Code should operate with lower ambient privileges where it
    can, using higher privileges in the necessary sections and transitioning at natural
    decision points.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: Least Information
  id: totrans-423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s always safest to collect and access the minimum amount of private information
    needed for the job.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: The *Least Information* pattern, the data privacy analog of Least Privilege,
    helps to minimize unintended disclosure risks. Avoid providing more private information
    than necessary when calling a subroutine, requesting a service, or responding
    to a request, and at every opportunity curtail unnecessary information flow. Implementing
    this pattern can be challenging in practice because software tends to pass data
    around in standard containers not optimized for purpose, so extra data often is
    included that isn’t really needed.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: All too often, software fails this pattern because the design of interfaces
    evolves over time to serve a number of purposes, and it’s convenient to reuse
    the same parameters or data structure for consistency. As a result, data that
    isn’t strictly necessary gets sent along as extra baggage that seems harmless
    enough. The problem arises, of course, when this needless data flowing through
    the system creates additional opportunities for attack.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, imagine a large customer relationship management (CRM) system
    used by various workers in an enterprise. Different workers use the system for
    a wide variety of purposes, including sales, production, shipping, support, maintenance,
    R&D, and accounting. Depending on their roles, each has a different authorization
    for access to subsets of this information. To practice Least Information, the
    applications in this enterprise should request only the minimum amount of data
    needed to perform a specific task. Consider a customer support representative
    responding to a phone call: if the system uses Caller ID to look up the customer
    record, the support person doesn’t need to know their phone number, just their
    purchase history. Contrast this with a more basic design that either allows or
    disallows the lookup of customer records that include all data fields. Ideally,
    even if the representative has more access, they should be able to request the
    minimum needed for a given task and work with that, thereby minimizing the risk
    of disclosure.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: At the implementation level, Least Information design includes wiping locally
    cached information when no longer needed, or perhaps displaying a subset of available
    data on the screen until the user explicitly requests to see certain details.
    The common practice of displaying passwords as `********` uses this pattern to
    mitigate the risk of shoulder surfing.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: It’s particularly important to apply this pattern at design time, as it can
    be extremely difficult to implement later on because both sides of the interface
    need to change together. If you design independent components suited to specific
    tasks that require different sets of data, you’re more likely to get this right.
    APIs handling sensitive data should provide flexibility to allow callers to specify
    subsets of data they need in order to minimize information exposure ([Table 4-1](#table4-1)).
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4-1: How Least Information Changes API Design'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '| **Least Information non-compliant API** | **Least Information compliant API**
    |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
- en: '| `RequestCustomerData(id=''12345'')` | `RequestCustomerData(id=''12345'',
    items=[''name'', ''zip''])` |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
- en: '| `{''id'': ''12345'', ''name'': ''Jane Doe'', ''phone'': ''888-555-1212'',
    ''zip'': ''01010'', ...}` | `{''name'': ''Jane Doe'', ''zip'': ''01010''}` |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
- en: The `RequestCustomerData` API in the left column ignores the Least Information
    pattern because the caller has no option but to request the complete data record
    by ID. They don’t need the phone number, so there is no need to request it, and
    even ignoring it still expands the attack surface for an attacker trying to get
    it. The right column has a version of the same API that allows callers to specify
    what fields they need and delivers only those, which minimizes the flow of private
    information.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: Considering the Secure by Default pattern as well, the default for the `items`
    parameter should be a minimal set of fields, provided that callers can request
    exactly what they need to minimize information flow.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: Secure by Default
  id: totrans-437
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Software should always be secure “out of the box.”
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: Design your software to be *Secure by Default*, including in its initial state,
    so that inaction by the operator does not represent a risk. This applies to the
    overall system configuration, as well as configuration options for components
    and API parameters. Databases or routers with default passwords notoriously violate
    this pattern, and to this day, this design flaw remains surprisingly widespread.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: If you are serious about security, never configure an insecure state with the
    intention of making it secure later, because this creates an interval of vulnerability
    and is too often forgotten. If you must use equipment with a default password,
    for example, first configure it safely on a private network behind a firewall
    before deploying it in the network. A pioneer in this area, the state of California
    has mandated this pattern by law; its [Senate Bill No. 327 (2018)](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB327)
    outlaws default passwords on connected devices.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: Secure by Default applies to any setting or configuration that could have a
    detrimental security impact, not just to default passwords. Permissions should
    default to more restrictive settings; users should have to explicitly change them
    to less restrictive ones if needed, and only if it’s safe to do so. Disable all
    potentially dangerous options by default. Conversely, enable features that provide
    security protection by default so they are functioning from the start. And of
    course, keeping the software fully up-to-date is important; don’t start out with
    an old version (possibly one with known vulnerabilities) and hope that, at some
    point, it gets updated.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, you shouldn’t ever need to have insecure options. Carefully consider
    proposed configurable options, because it may be simple to provide an insecure
    option that will become a booby trap for others thereafter. Also remember that
    each new option increases the number of possible combinations, and the task of
    ensuring that all of those combinations of settings are actually useful and safe
    becomes more difficult as the number of options increases. Whenever you must provide
    unsafe configurations, make a point of proactively explaining the risk to the
    administrator.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: Secure by Default applies much more broadly than to configuration options, though.
    Defaults for unspecified API parameters should be secure choices. A browser accepting
    a URL entered into the address bar without any protocol specified should assume
    the site uses HTTPS, and fall back to HTTP only if the former fails to connect.
    Two peers negotiating a new HTTPS connection should default to accepting the more
    secure cipher suite choices first.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: Allowlists over Blocklists
  id: totrans-444
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Prefer allowlists over blocklists when designing a security mechanism. *Allowlists*
    are enumerations of what’s safe, so they are inherently finite. By contrast, *blocklists*
    attempt to enumerate all that isn’t safe, and in doing so implicitly allow an
    infinite set of things you *hope* are safe. It’s clear which approach is riskier.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: 'First, here’s a non-software example to make sure you understand what the allowlist
    versus blocklist alternative means, and why allowlists are always the way to go.
    During the early months of the COVID-19 stay-at-home emergency order, the governor
    of my state ordered the beaches closed with the following provisos, presented
    here in simplified form:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: No person shall sit, stand, lie down, lounge, sunbathe, or loiter on any beach
    except when “running, jogging, or walking on the beach, so long as social distancing
    requirements are maintained” (crossing the beach to surf is also allowed).
  id: totrans-447
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The first clause is a blocklist, because it lists what activities are not allowed,
    and the second exception clause is an allowlist, because it grants permission
    to the activities listed. Due to legal issues, there may well be good reasons
    for this language, but from a strictly logical perspective, I think it leaves
    much to be desired.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: 'First let’s consider the blocklist: I’m confident that there are other risky
    activities people could do at the beach that the first clause fails to prohibit.
    If the intention of the order was to keep people moving, it omitted many—kneeling,
    for example, as well as yoga and living statue performances. The problem with
    blocklists is that any omissions become flaws, so unless you can completely enumerate
    every possible bad case, it’s an insecure system.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: Now consider the allowlist of allowable beach activities. While it, too, is
    incomplete—who would contest that skipping is also fine?—this won’t cause a big
    security problem. Perhaps a fraction of a percent of beach skippers will be unfairly
    punished, but the harm is minor, and more importantly, an incomplete enumeration
    doesn’t open up a hole that allows a risky activity. Additional safe items initially
    omitted can easily be added to the allowlist as needed.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: 'More generally, think of a continuum, ranging from disallowed on the left,
    then shading to allowed on the right. Somewhere in the middle is a dividing line.
    The goal is to allow the good stuff on the right of the line while disallowing
    the bad on the left. Allowlists draw the line from the right side, then gradually
    move it to the left, including more parts of the continuum as the list of what
    to allow grows. If you omit something good from the allowlist, you’re still on
    the safe side of the elusive line that’s the true divide. You may never get to
    the precise point that allows all safe actions, at which point any addition to
    the list would be too much, but using this technique makes it easy to stay on
    the safe side. Contrast that to the blocklist approach: unless you enumerate everything
    to the left of the true divide, you’re allowing something you shouldn’t. The safest
    blocklist will be one that includes just about everything, and that’s likely to
    be overly restrictive, so it doesn’t work well either way.'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: Often, the use of an allowlist is so glaringly obvious we don’t notice it as
    a pattern. For example, a bank would reasonably authorize a small set of trusted
    managers to approve high-value transactions. Nobody would dream of maintaining
    a blocklist of all the employees *not* authorized, tacitly allowing any other
    employee such privilege. Yet sloppy coders might attempt to do input validation
    by checking that the value did not contain any of a list of invalid characters,
    and in the process easily forget about characters like NUL (ASCII 0) or perhaps
    DEL (ASCII 127).
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: Ironically, perhaps the biggest-selling consumer security product, antivirus
    software, attempts to block all known malware. Modern antivirus products are much
    more sophisticated than the old-school versions, which relied on comparing a digest
    against a database of known malware, but still, they all appear to work based
    on a blocklist to some extent. (A great example of Security by Obscurity, most
    commercial antivirus software is proprietary, so we can only speculate.) It makes
    sense that they’re stuck with blocklist techniques because they know how to collect
    examples of malware, and the prospect of somehow allowlisting all good software
    in the world before it’s released seems to be a nonstarter. My point isn’t about
    any particular product or an assessment of its worth, but about the design choice
    of protection by virtue of a blocklist, and why that’s inevitably risky.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: Avoid Predictability
  id: totrans-454
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Any data (or behavior) that is predictable cannot be kept private, since attackers
    can learn it by guessing.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: Predictability of data in software design can lead to serious flaws because
    it can result in the leakage of information. For instance, consider the simple
    example of assigning new customer account IDs. When a new customer signs up on
    a website, the system needs a unique ID to designate the account. One obvious
    and easy way to do this is to name the first account 1, the second account 2,
    and so on. This works, but from the point of view of an attacker, what does it
    give away?
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: New account IDs now provide an attacker an easy way of learning the number of
    user accounts created so far. For example, if the attacker periodically creates
    a new, throwaway account, they have an accurate metric for how many customer accounts
    the website has at a given time—information that most businesses would be loathe
    to disclose to a competitor. Many other pitfalls are possible, depending on the
    specifics of the system. Another consequence of this poor design is that attackers
    can easily guess the account ID assigned to the next new account created, and
    armed with this knowledge, they might be able to interfere with the new account
    setup by claiming to be the new account and confusing the registration system.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: The problem of predictability takes many guises, and different types of leakage
    can occur with different designs. For example, an account ID that includes several
    letters of the account holder’s name or ZIP code would needlessly leak clues about
    the account owner’s identity. Of course, this same problem applies to IDs for
    web pages, events, and more. The simplest mitigation against these issues is that
    if the purpose of an ID is to be a unique handle, you should make it just that—never
    a count of users, the email of the user, or based on other identifying information.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: 'The easy way to avoid these problems is to use *securely random* IDs. Truly
    random values cannot be guessed, so they do not leak information. (Strictly speaking,
    the length of IDs leaks the maximum number of possible IDs, but this usually isn’t
    sensitive information.) A standard system facility, random number generators come
    in two flavors: pseudorandom number generators and secure random number generators.
    You should use the secure option, which is slower, unless you’re certain that
    predictability is harmless. See Chapter 5 for more about secure random number
    generators.'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: Fail Securely
  id: totrans-460
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If a problem occurs, be sure to end up in a secure state.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: 'In the physical world, this pattern is common sense itself. An old-fashioned
    electric fuse is a great example: if too much current flows through it, the heat
    melts the metal, opening the circuit. The laws of physics make it impossible to
    fail in a way that maintains excessive current flow. This pattern perhaps may
    seem like the most obvious one, but software being what it is (we don’t have the
    laws of physics on our side), it’s easily disregarded.'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: Many software coding tasks that at first seem almost trivial often grow in complexity
    due to error handling. The normal program flow can be simple, but when a connection
    is broken, memory allocation fails, inputs are invalid, or any number of other
    potential problems arise, the code needs to proceed if possible, or back out gracefully
    if not. When writing code, you might feel as though you spend more time dealing
    with all these distractions than with the task at hand, and it’s easy to quickly
    dismiss error-handling code as unimportant, making this a common source of vulnerabilities.
    Attackers will intentionally trigger these error cases if they can, in hopes that
    there is a vulnerability they can exploit.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: Error cases are often tedious to test thoroughly, especially when combinations
    of multiple errors can compound into new code paths, so this can be fertile ground
    for attack. Ensure that each error is either safely handled, or leads to full
    rejection of the request. For example, when someone uploads an image to a photo
    sharing service, immediately check that it is well formed (because malformed images
    are often used maliciously), and if not, then promptly remove the data from storage
    to prevent its further use.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: Strong Enforcement
  id: totrans-465
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: These patterns concern how to ensure that code behaves by enforcing the rules
    thoroughly. Loopholes are the bane of any laws and regulations, so these patterns
    show how to avoid creating ways of gaming the system. Rather than write code and
    reason that you don’t think it will do something, it’s better to structurally
    design it so that forbidden operations cannot possibly occur.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: Complete Mediation
  id: totrans-467
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Protect all access paths, enforcing the same access, without exception.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: An obscure term for an obvious idea, *Complete Mediation* means securely checking
    all accesses to a protected asset consistently. If there are multiple access methods
    to a resource, they must all be subject to the same authorization check, with
    no shortcuts that afford a free pass or looser policy.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, suppose a financial investment firm’s information system policy
    declares that regular employees cannot look up the tax IDs of customers without
    manager approval, so the system provides them with a reduced view of customer
    records omitting that field. Managers can access the full record, and in the rare
    instance that a non-manager has a legitimate need, they can ask a manager to look
    it up. Employees help customers in many ways, one of which is providing replacement
    tax documents if, for some reason, customers did not receive theirs in the mail.
    After confirming the customer’s identity, the employee requests a duplicate form
    (a PDF), which they print out and mail to the customer. The problem with this
    system is that the customer’s tax ID, which the employee should not have access
    to, appears on the tax form: that’s a failure of Complete Mediation. A dishonest
    employee could request any customer’s tax form, as if for a replacement, just
    to learn their tax ID, defeating the policy preventing disclosure to employees.'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: The best way to honor this pattern is, wherever possible, to have a single point
    where a particular security decision occurs. This is often known as a *guard*
    or, informally, a *bottleneck*. The idea is that all accesses to a given asset
    must go through one gate. Alternatively, if that is infeasible and multiple pathways
    need guards, then all checks for the same access should be functionally equivalent
    and ideally implemented as identical code.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, this pattern can be challenging to accomplish consistently. There
    are different degrees of compliance, depending on the guards in place:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: '**High compliance**'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: Resource access only allowed via one common routine (bottleneck guard)
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Medium compliance**'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: Resource access in various places, each guarded by an identical authorization
    check (common multiple guards)
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Low compliance**'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: Resource access in various places, variously guarded by inconsistent authorization
    checks (incomplete mediation)
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A counter-example demonstrates why designs with simple authorization policies
    that concentrate authorization checks in a single bottleneck code path for a given
    resource are the best way to get this pattern right. A Reddit user recently reported
    a case of how easy it is to get it wrong:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: I saw that my 8-year-old sister was on her iPhone 6 on iOS 12.4.6 using YouTube
    past her screen time limit. Turns out, she discovered a bug with screen time in
    messages that allows the user to use apps that are available in the iMessage App
    Store.
  id: totrans-480
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Apple designed iMessage to include its own apps, making it possible to invoke
    the YouTube app in multiple ways, but it didn’t implement the screen-time check
    on this alternate path to video watching—a classic failure of Complete Mediation.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: Avoid having multiple paths for accessing the same resource, each with custom
    code that potentially works slightly differently, because any discrepancies could
    mean weaker guards on some paths than on others. Multiple guards would require
    implementing the same essential check multiple times, and would be more difficult
    to maintain because you’d need to make matching changes in several places. The
    use of multiple guards incurs more chances of making an error and more work to
    thoroughly test.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: Least Common Mechanism
  id: totrans-483
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Maintain isolation between independent processes by minimizing shared mechanisms.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: To best appreciate what this means and how it helps, let’s consider an example.
    The kernel of a multiuser operating system manages system resources for processes
    running in different user contexts. The design of the kernel fundamentally ensures
    the isolation of processes unless they explicitly share a resource or a communication
    channel. Under the covers, the kernel maintains various data structures necessary
    to service requests from all user processes. This pattern points out that the
    common mechanism of these structures could inadvertently bridge processes, and
    therefore it’s best to minimize such opportunities. For example, if some functionality
    can be implemented in userland code, where the process boundary necessarily isolates
    it to the process, the functionality will be less likely to somehow bridge user
    processes. Here, the term *bridge* specifically means either leaking information,
    or allowing one process to influence another without authorization.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: If that still feels abstract, consider this non-software analogy. You visit
    your accountant to review your tax return the day before the filing deadline.
    Piles of papers and folders cover the accountant’s desk like miniature skyscrapers.
    After shuffling through the chaotic mess, they pull out your paperwork and start
    the meeting. While waiting, you can see tax forms and bank statements with other
    people’s names and tax IDs in plain sight. Perhaps your accountant accidentally
    jots a quick note about your taxes in someone else’s file by mistake. This is
    exactly the kind of bridge between independent parties, created because the accountant
    uses the desktop as a common workspace, that the Least Common Mechanism strives
    to avoid.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: Next year, you hire a different accountant, and when you meet with them, they
    pull your file out of a cabinet. They open it on their desk, which is neat, with
    no other clients’ paperwork in sight. That’s how to do Least Common Mechanism
    right, with minimal risk of mix-ups or nosy clients seeing other documents.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: In the realm of software, apply this pattern by designing services that interface
    to independent processes or different users. Instead of a monolithic database
    with everyone’s data in it, can you provide each user with a separate database
    or otherwise scope access according to the context? There may be good reasons
    to put all the data in one place, but when you choose not to follow this pattern,
    be alert to the added risk and explicitly enforce the necessary separation. Web
    cookies are a great example of using this pattern because each client stores its
    own cookie data independently.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: Redundancy
  id: totrans-489
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Redundancy* is a core strategy for safety in engineering that’s reflected
    in many common-sense practices, such as spare tires for cars. These patterns show
    how to apply it to make software more secure.'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: Defense in Depth
  id: totrans-491
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Combining independent layers of protection makes for a stronger overall defense
    that is often synergistically far more effective than any single layer.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: This powerful technique is one of the most important patterns we have for making
    inevitably bug-ridden software systems more secure than their components. Visualize
    a room that you want to convert to a darkroom by putting plywood over the window.
    You have plenty of plywood, but somebody has randomly drilled several small holes
    in every sheet. Nail up just one sheet, and numerous pinholes ruin the darkness.
    Nail a second sheet on top of that, and unless two holes just happen to align,
    you now have a completely dark room. A security checkpoint that utilizes both
    a metal detector and a pat-down is another example of this pattern.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: In the realm of software design, deploy *Defense in Depth* by layering two or
    more independent protection mechanisms to enforce a particularly critical security
    decision. Like the holey plywood, there might be flaws in each of the implementations,
    but the likelihood that any given attack will penetrate both is minuscule, akin
    to having two plywood holes just happen to line up and let light through. Since
    two independent checks require double the effort and take twice as long, you should
    use this technique sparingly.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: A great example of this technique that balances the effort and overhead against
    the benefit is the implementation of a *sandbox*, a container in which untrusted
    arbitrary code can run safely. (Modern web browsers run [WebAssembly in a secure
    sandbox](https://webassembly.org/).) Running untrusted code in your system could
    have disastrous consequences if anything goes wrong, justifying the overhead of
    multiple layers of protection ([Figure 4-2](#figure4-2)).
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: '![f04002](image_fi/501928c04/f04002.png)'
  id: totrans-496
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4-2: An example of a sandbox as the Defense in Depth pattern'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: Code for sandbox execution first gets scanned by an analyzer (defense layer
    one), which examines it against a set of rules. If any violation occurs, the system
    rejects the code completely. For example, one rule might forbid the use of calls
    into the kernel; another rule might forbid the use of specific privileged machine
    instructions. If and only if the code passes the scanner, it then gets loaded
    into an interpreter that runs the code while also enforcing a number of restrictions
    intended to prevent the same kinds of overprivileged operations. For an attacker
    to break this system, they must first get past the scanner’s rule checking and
    also trick the interpreter into executing the forbidden operation. This example
    is especially effective because code scanning and interpretation are fundamentally
    different, so the chances of the same flaw appearing in both layers is low, especially
    if they’re developed independently. Even if there is a one-in-a-million chance
    that the scanner misses a particular attack technique, and the same goes for the
    interpreter, once they’re combined, the total system has about a one-in-a-trillion
    chance of actually failing. That’s the power of this pattern.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
- en: Separation of Privilege
  id: totrans-499
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Two parties are more trustworthy than one.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: Also known as *Separation of Duty*, the *Separation of Privilege* pattern refers
    to the indisputable fact that two locks are stronger than one when those locks
    have different keys entrusted to two different people. While it’s possible that
    those two people may be in cahoots, that rarely happens; plus, there are good
    ways to minimize that risk, and in any case it’s way better than relying entirely
    on one individual.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: For example, safe deposit boxes are designed such that a bank maintains the
    security of the vault that contains all the boxes, and each box holder has a separate
    key that opens their box. Bankers cannot get into any of the boxes without brute-forcing
    them, such as by drilling the locks, yet no customer knows the combination that
    opens the vault. Only when a customer gains access from the bank and then uses
    their own key can their box be opened.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply this pattern when there are distinct overlapping responsibilities for
    a protected resource. Securing a datacenter is a classic case: the datacenter
    has a system administrator (or a team of them for a big operation) responsible
    for operating the machines with superuser access. In addition, security guards
    control physical access to the facility. These separate duties, paired with corresponding
    controls of the respective credentials and access keys, should belong to employees
    who report to different executives in the organization, making collusion less
    likely and preventing one boss from ordering an extraordinary action in violation
    of protocol. Specifically, the admins who work remotely shouldn’t have physical
    access to the machines in the datacenter, and the people physically in the datacenter
    shouldn’t know any of the access codes to log in to the machines, or the keys
    needed to decrypt any of the storage units. It would take two people colluding,
    one from each domain of control, to gain both physical and admin access in order
    to fully compromise security. In large organizations, different groups might be
    responsible for various datasets managed within the datacenter as an additional
    degree of separation.'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
- en: The other use of this pattern, typically reserved for the most critical functions,
    is to split one responsibility into multiple duties to avoid any serious consequences
    as a result of a single actor’s mistake or malicious intent. As extra protection
    against a backup copy of data possibly leaking, you could encrypt it twice with
    different keys entrusted separately, so that it can be used only with the help
    of both parties. An extreme example, triggering a nuclear missile launch, requires
    two keys turned simultaneously in locks 10 feet apart, ensuring that no individual
    acting alone could possibly actuate it.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: Secure your audit logs by Separation of Privilege, with one team responsible
    for the recording and reviewing of events and another for initiating the events.
    This means that the admins can audit user activity, but a separate group needs
    to audit the admins. Otherwise, a bad actor could block the recording of their
    own corrupt activity or tamper with the audit log to cover their tracks.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: You can’t achieve Separation of Privilege within a single computer because an
    administrator with superuser rights has full control, but there are still many
    ways to approximate it to good effect. Implementing a design with multiple independent
    components can still be valuable as a mitigation, even though an administrator
    can ultimately defeat it, because it makes subversion more complicated; any attack
    will take longer and the attacker is more likely to make mistakes in the process,
    increasing their likelihood of being caught. Strong Separation of Privilege for
    administrators could be designed by forcing the admin to work via a special `ssh`
    gateway under separate control that logged their session in full detail and possibly
    imposed other restrictions.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
- en: 'Insider threats are difficult, or in some cases impossible, to eliminate, but
    that doesn’t mean mitigations are a waste of time. Simply knowing that somebody
    is watching is, in itself, a large deterrent. Such precautions are not just about
    distrust: honest staff should welcome any Separation of Privilege that adds accountability
    and reduces the risk posed by their own mistakes. Forcing a rogue insider to work
    hard to cleanly cover their tracks slows them down and raises the odds of their
    being caught red-handed. Fortunately, human beings have well-evolved trust systems
    for face-to-face encounters with coworkers, and as a result, insider duplicity
    is extremely rare in practice.'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: Trust and Responsibility
  id: totrans-508
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Trust and responsibility are the glue that makes cooperation work. Software
    systems are increasingly interconnected and interdependent, so these patterns
    are important guideposts.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: Reluctance to Trust
  id: totrans-510
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Trust should be always be an explicit choice, informed by solid evidence.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
- en: This pattern acknowledges that trust is precious, and so urges skepticism. Before
    there was software, criminals exploited people’s natural inclination to trust
    others, dressing up as workmen to gain access, selling snake oil, or perpetrating
    an endless variety of other scams. *Reluctance to Trust* tells us not to assume
    that a person in a uniform is necessarily legit, and to consider that the caller
    who says they’re with the FBI may be a trickster. In software, this pattern applies
    to checking the authenticity of code before installing it, and requiring strong
    authentication before authorization.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: The use of HTTP cookies is a great example of this pattern, as Chapter 11 explains
    in detail. Web servers set cookies in their response to the client, expecting
    clients to send back those cookies with future requests. But since clients are
    under no actual obligation to comply, servers should always take cookies with
    a grain of salt, and it’s a huge risk to absolutely trust that clients will always
    faithfully perform this task.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: Reluctance to Trust is important even in the absence of malice. For example,
    in a critical system, it’s vital to ensure that all components are up to the same
    high standards of quality and security so as not to compromise the whole. Poor
    trust decisions, such using code from an anonymous developer (which might contain
    malware, or simply be buggy) for a critical function quickly undermines security.
    This pattern is straightforward and rational, yet can be challenging in practice
    because people are naturally trusting and it can feel paranoid to withhold trust.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
- en: Accept Security Responsibility
  id: totrans-515
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All software professionals have a clear duty to take responsibility for security;
    they should reflect that attitude in the software they produce.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: For example, a designer should include security requirements when vetting external
    components to incorporate into the system. And at the interface between two systems,
    both sides should explicitly take on certain responsibilities they will honor,
    as well as confirm any guarantees they depend on the caller to uphold.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: The anti-pattern that you don’t want is to someday encounter a problem and have
    two developers say to each other, “I thought you were handling security, so I
    didn’t have to.” In a large system, both sides can easily find themselves pointing
    the finger at the other. Consider a situation where component A accepts untrusted
    input (for example, a web frontend server receiving an anonymous internet request)
    and passes it through, possibly with some processing or reformatting, to business
    logic in component B. Component A could take no security responsibility at all
    and blindly pass through all inputs, assuming B will handle the untrusted input
    safely with suitable validation and error checking. From component B’s perspective,
    it’s easy to assume that the frontend validates all requests and only passes safe
    requests on to B, so there is no need for B to worry about this. The right way
    to handle this situation is by explicit agreement; decide who validates requests
    and what guarantees to provide downstream, if any. For maximum safety, use Defense
    in Depth, where both components independently validate the input.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider another all-too-common case, where the responsibility gap occurs between
    the designer and user of the software. Recall the example of configuration settings
    from our discussion of the Secure by Default pattern, specifically when an insecure
    option is given. If the designer knows a configurable option to be less secure,
    they should carefully consider whether providing that option is truly necessary.
    That is, don’t just give users an option because it’s easy to do, or because “someone,
    someday, might want this.” That’s tantamount to setting a trap that someone will
    eventually fall into unwittingly. When valid reasons for a potentially risky configuration
    exist, first consider methods of changing the design to allow a safe way of solving
    the problem. Barring that, if the requirement is inherently unsafe, the designer
    should advise the user and protect them from configuring the option when unaware
    of the consequences. Not only is it important to document the risks and suggest
    possible mitigations to offset the vulnerability, but users should also receive
    clear feedback—ideally, something better than the responsibility-ditching “Are
    you sure? (Learn more: *<link>*)” dialog.'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: Anti-Patterns
  id: totrans-520
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Learn to see in another’s calamity the ills which you should avoid.
  id: totrans-521
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-522
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Publilius Syrus
  id: totrans-523
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Some skills are best learned by observing how a master works, but another important
    kind of learning comes from avoiding the past mistakes of others. Beginning chemists
    learn to always dilute acid by adding the acid to a container of water—never the
    reverse, because in the presence of a large amount of acid, the first drop of
    water reacts suddenly, producing a lot of heat that could instantly boil the water,
    expelling water and acid explosively. Nobody wants to learn this lesson by imitation,
    and in that spirit, I present here several anti-patterns best avoided in the interests
    of security.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
- en: The following short sections list a few software security anti-patterns. These
    patterns may generally carry security risks, so they are best avoided, but they
    are not actual vulnerabilities. In contrast to the named patterns covered in the
    previous sections, which are generally recognizable terms, some of these don’t
    have well-established names, so I have chosen descriptive monikers here for convenience.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: Confused Deputy
  id: totrans-526
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *Confused Deputy* problem is a fundamental security challenge that is at
    the core of many software vulnerabilities. One could say that this is the mother
    of all anti-patterns. To explain the name and what it means, a short story is
    a good starting point. Suppose a judge issues a warrant, instructing their deputy
    to arrest Norman Bates. The deputy looks up Norman’s address, and arrests the
    man living there. The man insists there is a mistake, but the deputy has heard
    that excuse before. The plot twist of our story (which has nothing to do with
    *Psycho*) is that Norman anticipated getting caught and for years has used a false
    address. The deputy, confused by this subterfuge, used their arrest authority
    wrongly; you could say that Norman played them, managing to direct the deputy’s
    duly granted authority to his own malevolent purposes. (The despicable crime of
    swatting—falsely reporting an emergency to direct police forces against innocent
    victims—is a perfect example of the Confused Deputy problem, but I didn’t want
    to tell one of those sad stories in detail.)
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
- en: Common examples of confused deputies include the kernel when called by userland
    code, or a web server when invoked from the internet. The callee is a *deputy*
    because the higher-privilege code is invoked to do things on behalf of the lower-privilege
    caller. This risk derives directly from the trust boundary crossing, which is
    why those are of such acute interest in threat modeling. In later chapters, numerous
    ways of confusing a deputy will be covered, including buffer overflows, poor input
    validation, and cross-site request forgery (CSRF) attacks, just to name a few.
    Unlike human deputies, who can rely on instinct, past experience, and other cues
    (including common sense), software is trivially tricked into doing things it wasn’t
    intended to, unless it’s designed and implemented with all necessary precautions
    fully anticipated.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: Intention and Malice
  id: totrans-529
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To recap from Chapter 1, for software to be trustworthy, there are two requirements:
    it must be built by people you can trust are both honest and competent to deliver
    a quality product. The difference between the two conditions is intention. The
    problem with arresting Norman Bates wasn’t that the deputy was crooked; it was
    failing to properly ID the arrestee. Of course, code doesn’t disobey or get lazy,
    but poorly-written code can easily work in ways other than how it was intended.
    While many gullible computer users and occasionally even technically adept software
    professionals do get tricked into trusting malicious software, many attacks work
    by exploiting a Confused Deputy in software that is duly trusted but happens to
    be flawed.'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: Often, Confused Deputy vulnerabilities arise when the context of the original
    request gets lost earlier in the code—for example, if the requester’s identity
    is no longer available. This sort of confusion is especially likely in common
    code shared by both high- and low-privilege invocations. [Figure 4-3](#figure4-3)
    shows what such an invocation looks like.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
- en: '![f04003](image_fi/501928c04/f04003.png)'
  id: totrans-532
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4-3: An example of the Confused Deputy anti-pattern'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: The `Deputy` code in the center performs work for both low- and high-privilege
    code. When invoked from High on the right, it may do potentially dangerous operations
    in service of its trusted caller. Invocation from Low represents a trust boundary
    crossing, so `Deputy` should only do safe operations appropriate for low-privilege
    callers. Within the implementation, `Deputy` uses a subcomponent, `Utility`, to
    do its work. Code within `Utility` has no notion of high- and low-privilege callers,
    and hence is liable to mistakenly do potentially dangerous operations on behalf
    of `Deputy` that low-privilege callers should not be able to do.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
- en: Trustworthy Deputy
  id: totrans-535
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s break down how to be a trustworthy deputy, beginning with a consideration
    of where the danger lies. Recall that trust boundaries are where the potential
    for confusion begins, because the goal in attacking a Confused Deputy is to leverage
    its higher privilege. So long as the deputy understands the request and who is
    requesting it, and the appropriate authorization checks happen, everything should
    be fine.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
- en: Recall the previous example involving the `Deputy` code, where the problem occurred
    in the underlying `Utility` code that did not contend with the trust boundary
    when called from Low. In a sense, `Deputy` unwittingly made `Utility` a Confused
    Deputy. If `Utility` was not intended to defend against low-privilege callers,
    then either `Deputy` needs to thoroughly shield it from being tricked, or `Utility`
    may require modification to be aware of low-privilege invocations.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
- en: Another common Confused Deputy failing occurs in the actions taken on behalf
    of the request. *Data hiding* is a fundamental design pattern where the implementation
    hides the mechanisms it uses behind an abstraction, and the deputy works directly
    on the mechanism though the requester cannot. For example, the deputy might log
    information as a side effect of a request, but the requester has no access to
    the log. By causing the deputy to write the log, the requester is leveraging the
    deputy’s privilege, so it’s important to beware of unintended side effects. If
    the requester can present a malformed string to the deputy that flows into the
    log with the effect of damaging the data and making it illegible, that’s a Confused
    Deputy attack that effectively wipes the log. In this case, the defense begins
    by noting that a string from the requester can flow into the log and, considering
    the potential impact that might have, requiring input validation, for example.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
- en: The Code Access Security model, mentioned in Chapter 3, is designed specifically
    to prevent Confused Deputy vulnerabilities from arising. When low-privilege code
    calls high-privilege deputy code, the effective permissions are reduced accordingly.
    When the deputy needs its greater privileges, it must assert them explicitly,
    acknowledging that it is working at the behest of lower-privilege code.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
- en: In summary, at trust boundaries, handle lower-trust data and lower-privilege
    invocations with care so as not to become a Confused Deputy. Keep the context
    associated with requests throughout the process of performing the task so that
    authorization can be fully checked as needed. Beware that side effects do not
    allow requesters to exceed their authority.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
- en: Backflow of Trust
  id: totrans-541
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Backflow of Trust* is present whenever a lower-trust component controls a
    higher-trust component. An example of this is when a system administrator uses
    their personal computer to remotely administer an enterprise system. While the
    person is duly authorized and trusted, their home computer isn’t within the enterprise
    regime and shouldn’t be hosting sessions using admin rights. In essence, you can
    think of this as a structural Elevation of Privilege just waiting to happen.'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
- en: While nobody in their right mind would fall into this anti-pattern in real life,
    it’s surprisingly easy to miss in an information system. Remember that what counts
    here is not the trust you *give* components, but how much trust the components
    *merit*. Threat modeling can surface potential problems of this variety through
    an explicit look at trust boundaries.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
- en: Third-Party Hooks
  id: totrans-544
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another form of the Backflow of Trust anti-pattern is when hooks in a component
    within your system provide a third party undue access. Consider a critical business
    system that includes a proprietary component performing some specialized process
    within the system. Perhaps it uses advanced AI to predict future business trends,
    consuming confidential sales metrics and updating forecasts daily. The AI component
    is cutting-edge, and so the company that makes it must tend to it daily. To make
    it work like a turnkey system, it needs a direct tunnel through the firewall to
    access the administrative interface.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
- en: This also is a perverse trust relationship because this third party has direct
    access into the heart of the enterprise system, completely outside the purview
    of the administrators. If the AI provider were dishonest, or compromised, they
    could easily exfiltrate internal company data, or worse, and there would be no
    way of knowing. Note that a limited type of hook may not have this problem and
    would be acceptable. For example, if the hook implements an auto-update mechanism
    and is only capable of downloading and installing new versions of the software,
    it may be fine, given a suitable level of trust.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
- en: Unpatchable Components
  id: totrans-547
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s almost invariably a matter of when, not if, someone will discover a vulnerability
    in any given popular component. Once such a vulnerability becomes public knowledge,
    unless it is completely disconnected from any attack surface, it needs patching
    promptly. Any component in a system that you cannot patch will eventually become
    a permanent liability.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: 'Hardware components with preinstalled software are often unpatchable, but for
    all intents and purposes, so is any software whose publisher has ceased supporting
    it or gone out of business. In practice, there are many other categories of effectively
    unpatchable software: unsupported software provided in binary form only; code
    built with an obsolete compiler or other dependency; code retired by a management
    decision; code that becomes embroiled in a lawsuit; code lost to ransomware compromise;
    and, remarkably enough, code written in a language such as COBOL that is so old
    that, these days, experienced programmers are in short supply. Major operating
    system providers typically provide support and upgrades for a certain time period,
    after which the software becomes effectively unpatchable. Even software that is
    updatable may effectively be no better if the maker fails to provide timely releases.
    Don’t tempt fate by using anything you are not confident you can update quickly
    when needed.'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
- en: '5'
  id: totrans-550
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cryptography
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
- en: Cryptography is typically bypassed, not penetrated.
  id: totrans-552
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-553
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Adi Shamir
  id: totrans-554
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-555
  prefs: []
  type: TYPE_IMG
- en: Back in high school, I nearly failed driver’s education. This was long ago,
    when public schools had funding to teach driving and when gasoline contained lead
    (nobody had threat modeled that brilliant idea). My first attempts at driving
    had not gone well. I specifically recall the day I first got behind the wheel
    of the Volkswagen Beetle, a manual transmission car, and the considerable trepidation
    on the stony face of the PE coach riding shotgun. I soon learned that pushing
    in the clutch while going downhill caused the car to speed up, not slow down as
    I’d intended. But from that mistake onward, something clicked, and suddenly I
    could drive. The coach expressed unguarded surprise, and relief, at this unlikely
    turn of events. With hindsight, I believe that my breakthrough was due to the
    hands-on feel of driving stick, which gave me a more direct connection to the
    vehicle, enabling me to drive by instinct for the first time.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
- en: Just as driver’s ed teaches students how to drive a car safely, but not how
    to design or do major repairs, this chapter introduces the basic toolset of cryptography
    by discussing how to use it properly, without going into the nuts and bolts of
    how it works. To make crypto comprehensible to the less mathematically inclined,
    this chapter eschews the math, except in one instance, whose inclusion I couldn’t
    resist because it’s so clever.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
- en: This is an unconventional approach to the topic, but also an important one.
    Crypto tools are underutilized precisely because cryptography has come to be seen
    as the domain of experts with a high barrier of entry. Modern libraries provide
    cryptographic functionality, but developers need to know how to use these (and
    how to use them correctly) for them to be effective. I hope that this chapter
    serves as a springboard to provide useful intuitions about the potential uses
    of crypto. You should supplement this with further research as needed for your
    specific uses.
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
- en: Crypto Tools
  id: totrans-559
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At its core, much of modern crypto derives from pure mathematics, so when used
    properly, it really works. This doesn’t mean the algorithms are provably impenetrable,
    but that it will take major breakthroughs in mathematics to crack them.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
- en: Crypto provides a rich array of security tools, but for them to be effective,
    you must use them thoughtfully. As this book repeatedly recommends, rely on high-quality
    libraries of code that provide complete solutions. It’s important to choose a
    library that provides an interface at the right level of abstraction, so you fully
    understand what it is doing.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
- en: 'The history of cryptography and the mathematics behind it are fascinating,
    but for the purposes of creating secure software, the modern toolbox consists
    of a modest collection of basic tools. The following list enumerates the basic
    crypto security functions and describes what each does, as well as what the security
    of each depends on:'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
- en: '*Random numbers* are useful as padding and nonces, but only if they are unpredictable.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Message digests* (or *hash functions*) serve as a fingerprint of data, but
    only if impervious to collisions.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Symmetric encryption* conceals data based on a secret key the parties share.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Asymmetric encryption* conceals data based on a secret the recipient knows.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Digital signatures* authenticate data based on a secret only the signer knows.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Digital certificates* authenticate signers based on trust in a root certificate.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Key exchange* allows two parties to establish a shared secret over an open
    channel, despite eavesdropping.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rest of this chapter will cover these tools and their uses in more detail.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
- en: Random Numbers
  id: totrans-571
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Human minds struggle to grasp the concept of randomness. For security purposes,
    we can focus on *unpredictability* as the most important attribute of random numbers.
    As we shall see, these are critical in cases where we must prevent attackers from
    guessing correctly, in the same way that a predictable password would be weak.
    Applications for random numbers include authentication, hashing, encryption, and
    key generation, each of which depends on unpredictability. The following subsections
    describe the two classes of random numbers available to software, how they differ
    in predictability, and when to use which kind.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
- en: Pseudo-Random Numbers
  id: totrans-573
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Pseudo-random number generators (PRNGs)* use deterministic computations to
    produce what looks like an infinite sequence of random numbers. The outputs they
    generate can easily exceed our human capacity for pattern detection, but analysis
    and adversarial software may easily learn to mimic a PRNG, disqualifying these
    from use in security contexts because they are predictable.'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
- en: However, since calculating pseudo-random numbers is very fast, they’re ideal
    for a broad range of non-security uses. If you want to run a Monte Carlo simulation
    or randomly assign variant web page designs for A/B testing, for example, a PRNG
    is the way to go, because even in the unlikely event that someone predicts the
    algorithm, there’s no real threat.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking a look at an example of a pseudo-random number may help solidify your
    understanding of why it is not truly random. Consider this digit sequence:'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-577
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Is this sequence random? There happen to be relatively few 1s and 3s, and disproportionally
    many 2s, but it wouldn’t be unreasonable to find these deviations from a flat
    distribution in a truly random number. Yet as random as this sequence appears,
    it’s easy to predict the next digits if you know the trick. And as the pattern
    of Transparent Design cautions us, it’s risky to assume we can keep our methods
    secret. In fact, if you entered this string of digits in a simple web search,
    you would learn that they are the digits of pi 200 decimals out, and that the
    next few digits will be `0147`.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
- en: As the decimals of an irrational number, the digits of pi have a statistically
    normal distribution and are, in a colloquial sense, entirely random. On the other
    hand, as an easily computed and well-known number, this sequence is completely
    predictable, and hence unsuitable for security purposes.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
- en: Cryptographically Secure Pseudo-Random Numbers
  id: totrans-580
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Modern operating systems provide *cryptographically secure* *pseudo-random number
    generator (CSPRNG)* functions to address the shortcomings of PRNGs when you need
    random bits for security. You may also see this written as CSRNG or CRNG; the
    important part is the “C,” which means it’s secure for crypto. The inclusion of
    “pseudo” is an admission that these, too, may fall short of perfect randomness,
    but experts have deemed them unpredictable enough to be secure for all practical
    purposes.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
- en: Use this kind of random number generator when security is at stake. In other
    words, if the hypothetical ability to predict the value of a supposedly random
    number weakens your security, use a CSPRNG. This applies to every security use
    of random numbers mentioned in this book.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
- en: Truly random data, by definition, isn’t generated by an algorithm, but comes
    from an unpredictable physical process. A Geiger counter could be such a *hardware
    random number generator (HRNG)*, also known as an *entropy source*, because the
    timing of radioactive decay events is random. HRNGs are built into many modern
    processors, or you can buy a hardware add-on. Software can also contribute entropy,
    usually by deriving it from the timing of events such as disk accesses, keyboard
    and mouse input events, and network transmissions that depend on complex interactions
    with external entities.
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
- en: 'One major internet tech company uses an array of lava lamps to colorfully generate
    random inputs. But consider a threat model of this technique: because the company
    chooses to display these lava lamps in its corporate office, and in the reception
    area no less, potential attackers might be able to observe the state of this input
    and make an educated guess about the entropy source. In practice, however, the
    lava lamps merely add entropy to a (presumably) more conventional entropy source
    behind the scenes, mitigating the risk that this display will lead to an easy
    compromise of the company’s systems.'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
- en: Entropy sources need time to produce randomness, and a CSPRNG will slow down
    to a crawl if you demand too many bits too fast. This is the cost of secure randomness,
    and why PRNGs have an important purpose as a reliably fast alternative. Use CSPRNGs
    sparingly unless you have a fast HRNG, and where throughput is an issue, test
    that it won’t become a bottleneck.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
- en: Message Authentication Codes
  id: totrans-586
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A message *digest* (also called a *hash*) is a fixed-length value computed from
    a message using a one-way function. This means that each unique message will have
    a specific digest, and any tampering will result in a different digest value.
    Being one-way is important because it means the digest computation is irreversible,
    so it won’t be possible for an attacker to find a different message that happens
    to have the same digest result. If you know that the digest matches, then you
    know that the message content has not been tampered with.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
- en: If two different messages produce the same digest, we call this a *collision*.
    Since digests map large chunks of data to fixed-length values, collisions are
    inevitable because there are more possible messages than there are digest values.
    The defining feature of a good digest function is that collisions are extremely
    difficult to find. A *collision attack* succeeds if an attacker finds two different
    inputs that produce the same digest value. The most devastating kind of attack
    on a digest function is a *preimage attack*, where, given a specific digest value,
    the attacker can find an input that produces it.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
- en: Cryptographically secure digest algorithms are strong one-way functions that
    make collisions so unlikely that you can assume they never happen. This assumption
    is necessary to leverage the power of digests because it means that by comparing
    two digests for equality, you are essentially comparing the full messages. Think
    of this as comparing two fingerprints (which is also an informal term for a digest)
    to determine if they were made by the same finger.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
- en: If everyone used the same digest function for everything, then attackers could
    intensively study and analyze it, and they might eventually find a few collisions
    or other weaknesses. One way to guard against this is to use *keyed hash functions*,
    which take an extra secret key parameter that transforms the digest computation.
    In effect, a keyed hash function that takes a 256-bit key is a class of 2^(256)
    different functions. These functions are also called *message authentication codes
    (MACs)*, because so long as the hash function key is secret, attackers cannot
    forge them. That is, by using a unique key, you get a customized digest function
    of your very own.
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
- en: Using MACs to Prevent Tampering
  id: totrans-591
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MACs are often used to prevent attackers from tampering with data. Suppose Alice
    wants to send a message to Bob over a public channel. The two of them have privately
    shared a certain secret key; they don’t care about eavesdropping, so they don’t
    need to encrypt their data, but fake messages would be a problem if undetected.
    Say the evil Mallory is able to tamper with communications on the wire, but she
    does not know the key. Alice uses the key to compute and send a MAC along with
    each message. When Bob receives a communication, he computes the MAC of the received
    message and compares it to the accompanying MAC that Alice sent; if they don’t
    match, he ignores it as bogus.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
- en: 'How secure is this arrangement at defending against the clever Mallory? First,
    let’s consider the obvious attacks:'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
- en: If Mallory tampers with the message, its MAC will not match the message digest
    (and Bob will ignore it).
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If Mallory tampers with the MAC, it won’t match the message digest (and Bob
    will ignore it).
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If Mallory concocts a brand-new message, she will have no way to compute the
    MAC (and Bob will ignore it).
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, there is one more case that we need to protect against. Can you spot
    another opening for Mallory, and how you might defend against it?
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
- en: Replay Attacks
  id: totrans-598
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is a remaining problem with the MAC communication scheme described previously,
    and it should give you an idea of how tricky using crypto tools against a determined
    attacker is. Suppose that Alice sends daily orders to Bob indicating how many
    widgets she wants delivered the next day. Mallory observes this traffic and collects
    message and MAC pairs that Alice sends: she orders three widgets the first day,
    then five the next. On the third day, Alice orders 10 widgets. At this point,
    Mallory gets an idea of how to tamper with Alice’s messages. Mallory intercepts
    Alice’s message and replaces it with a copy of the first day’s message (specifying
    three widgets), complete with the corresponding MAC that Alice has helpfully computed
    already and which Mallory recorded earlier. Of course, this fools Bob.'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
- en: This is a *replay attack*, and secure communications protocols need to address
    it. The problem isn’t that the cryptography is weak, it’s that it wasn’t used
    properly. In this case, the root problem is that authentic messages ordering three
    widgets are identical, which is fundamentally a predictability problem.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
- en: Secure MAC Communications
  id: totrans-601
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are a number of ways to fix Alice and Bob’s protocol and defeat replay
    attacks, and they all depend on ensuring that messages are always unique and unpredictable.
    A simple fix might be for Alice to include a timestamp in the message, with the
    understanding that Bob should ignore messages with old timestamps. Now if Mallory
    replays Monday’s order of three widgets on Wednesday, Bob will notice when he
    compares the timestamps and detect the fraud. However, if the messages are frequent
    or there’s a lot of network latency, then timestamps might not work well.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
- en: A more secure solution to the threat of replay attacks would be for Bob to send
    Alice a *nonce*—a random number for one-time use—before Alice sends each message.
    Then Alice can send back a message along with Bob’s nonce and a MAC of the message
    and nonce combined. This shuts down replay attacks because the nonce varies with
    every exchange. Mallory could intercept and change the nonce Bob sends, but Bob
    would notice if a different nonce came back.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
- en: Another problem with this simple example is that the messages are short, consisting
    of just a number of widgets. Setting aside the danger of replay attacks, very
    short messages are vulnerable to brute-force attacks. The time required to compute
    a keyed hash function is typically proportional to the message data length, and
    for just a few bits that computation is going to be fast. The faster Mallory can
    try different possible hash function keys, the easier it is to guess the right
    key to match the MAC of an authentic message. Knowing the key, Mallory can now
    impersonate Alice sending messages.
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
- en: You can mitigate short message vulnerabilities by padding the messages with
    random bits until they reach a suitable minimum length. Computing the MACs for
    these longer messages takes time, but that’s good as it slows down Mallory’s brute-force
    attack to the point of being infeasible. In fact, it’s desirable for hash functions
    to be expensive computations for just this reason. This is a situation where it’s
    important for the padding to be random (as opposed to predictably pseudo-random)
    to make Mallory work as hard as possible.
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
- en: Symmetric Encryption
  id: totrans-606
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All encryption conceals messages by transforming the *plaintext*, or original
    message, into an unrecognizable form called the *ciphertext*. Symmetric encryption
    algorithms use a secret key to customize the message’s transformation for the
    private use of the communicants, who must agree on a key in advance. The decryption
    algorithm uses the same secret key to convert ciphertext back to plaintext. We
    call this reversible transformation *symmetric cryptography* because knowledge
    of the secret key allows you to both encrypt and decrypt.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
- en: This section introduces a couple of these symmetric encryption algorithms to
    illustrate their security properties, and explains some of the precautions necessary
    to use them safely.
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
- en: One-Time Pad
  id: totrans-609
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cryptographers long ago discovered the ideal encryption algorithm, and even
    though, as we shall see, it is almost never actually used, it’s a great starting
    point for discussing encryption due to its utter simplicity. Known as the *one-time
    pad*, this algorithm requires the communicants to agree on a secret, random string
    of bits as the encryption key in advance. In order to encrypt a message, the sender
    exclusive-ors the message with the key, creating the ciphertext. The recipient
    then exclusive-ors the ciphertext with the same corresponding key bits to recover
    the plaintext message. Recall that in the exclusive-or (⊕) operation, if the key
    bit is a zero, then the corresponding message bit is unchanged; if the key bit
    is a one, then the message bit is inverted. [Figure 5-1](#figure5-1) graphically
    illustrates a simple example of one-time pad encryption and decryption.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
- en: '![f05001](image_fi/501928c05/f05001.png)'
  id: totrans-611
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-1: Alice and Bob using one-time pad encryption'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
- en: 'Subsequent messages are encrypted using bits further along in the secret key
    bit string. When the key is exhausted, the communicants need to somehow agree
    on a new secret key. There are good reasons it’s a *one-time* key, as I will explain
    shortly. Assuming that the key is random, the message bits either randomly invert
    or stay the same, so there is no way for attackers to discern the original message
    without knowing the key. Flipping half the bits randomly is the perfect disguise
    for a message, since either showing or inverting a large majority of the bits
    would partially reveal the plaintext. Impervious to attack by analysis as this
    may be, it’s easy to see why this method is rarely used: the key length limits
    the message length.'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider the prohibition against reusing one-time pad keys. Suppose that
    Alice and Bob use the same secret key `K` to encrypt two distinct plaintext messages,
    `M1` and `M2`. Mallory intercepts both ciphertexts: `M1 ⊕ K` and `M2 ⊕ K`. If
    Mallory exclusive-ors the two encrypted ciphertexts, the key cancels out, because
    when you exclusive-or any number with itself the result is zero (the ones invert
    to zeros, while the zeros are unchanged). The result is a weakly encrypted version
    of the two messages:'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-615
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: While this doesn’t directly disclose the plaintext, it begins to leak information.
    Having stripped away the key bits, analysis could reveal clues about patterns
    within the messages. For example, if either message contains a sequence of zero
    bits, then the corresponding bits of the other message will leak through.
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
- en: 'The one-time key use limitation is a showstopper for most applications: Alice
    and Bob may not know how much data they want to encrypt in advance, making it
    infeasible to decide on how long the key will need to be.'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
- en: Advanced Encryption Standard
  id: totrans-618
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *Advanced Encryption Standard* *(AES)* is a frequently used modern symmetric
    encryption block cipheralgorithm. In a *block cipher*, long messages are broken
    up into block-sized chunks, and shorter messages are padded with random bits to
    fill out the remainder of the block. AES encrypts 128-bit blocks of data using
    a secret key that is typically 256 bits long. Alice uses the same agreed-upon
    secret key to encrypt data that Bob uses to decrypt.
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider some possible weaknesses. If Alice sends identical message blocks
    to Bob over time, these will result in identical ciphertext, and clever Mallory
    will notice these repetitions. Even if Mallory can’t decipher the meaning of these
    messages, this represents a significant information leak that requires mitigation.
    The communication is also vulnerable to a replay attack because if Alice can resend
    the same ciphertext to convey the same plaintext message, then Mallory could do
    that, too.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
- en: Encrypting the same message in the same way is known as *electronic code book
    (ECB) mode*. Because of the vulnerability to replay attacks, this is usually a
    poor choice. To avoid this problem, you can use other modes that introduce feedback
    or other differences into subsequent blocks, so that the resulting ciphertext
    depends on the contents of preceding blocks or the position in the sequence. This
    ensures that even if the plaintext blocks are identical, the ciphertext results
    will be completely different. However, while chained encryption of data streams
    in blocks is advantageous, it does impose obligations on the communicants to maintain
    context of the ordering to encrypt and decrypt correctly. The choice of encryption
    modes thus often depends on the particular needs of the application.
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
- en: Using Symmetric Cryptography
  id: totrans-622
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Symmetric crypto is the workhorse for modern encryption because it’s fast and
    secure when applied properly. Encryption protects data communicated over an insecure
    channel, as well as data at rest in storage. When using symmetric crypto, it’s
    important to consider some fundamental limitations:'
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
- en: '**Key establishment**'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
- en: Crypto algorithms depend on the prearrangement of secret keys, but do not specify
    how these keys should be established.
  id: totrans-625
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Key secrecy**'
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
- en: The effectiveness of the encryption entirely depends on maintaining the secrecy
    of the keys while still having the keys available when needed.
  id: totrans-627
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Key size**'
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
- en: Larger secret keys are stronger (with a one-time pad being the ideal in theory),
    but managing large keys becomes costly and unwieldy.
  id: totrans-629
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Symmetric encryption inherently depends on shared secret keys, and unless Alice
    and Bob can meet directly for a trusted exchange, it’s challenging to set up.
    To address this limitation, *asymmetric encryption* offers some surprisingly useful
    new capabilities that fit the needs of an internet-connected world.
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
- en: Asymmetric Encryption
  id: totrans-631
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Asymmetric cryptography is a deeply counterintuitive form of encryption, and
    therein lies its power. With symmetric encryption Alice and Bob can both encrypt
    and decrypt messages using the same key, but with asymmetric encryption Bob can
    send secret messages to Alice that he is unable to decrypt. Thus, for Bob encryption
    is a one-way function, while only Alice knows the secret that enables her to invert
    the function (that is, to decrypt the message).
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
- en: 'Asymmetric cryptography uses a pair of keys: a *public key* for encryption
    and a *private key* for decryption. I will describe how Bob, or anyone in the
    world for that matter, sends encrypted messages to Alice; for a two-way conversation,
    Alice would reply using the same process with Bob’s entirely separate key pair.
    The transformations made using the two keys are inverse functions, yet knowing
    only one of the keys does not help to figure out the other; so if you keep one
    key secret, then only you can perform that computation. As a result of this asymmetry,
    Alice can create a key pair and then publish one key for the world to see (her
    public key), enabling anyone to encrypt messages that only she can decrypt using
    her corresponding private key. This is revolutionary, because it grants Alice
    a unique capability based on knowing a secret. We shall see in the following pages
    all that this makes possible.'
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
- en: There are many asymmetric encryption algorithms, but the mathematical details
    of these are unimportant to understanding using them as crypto tools—what’s important
    is that you understand the security implications. We’ll focus on RSA, as it’s
    the least mathematically complicated progenitor.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
- en: The RSA Cryptosystem
  id: totrans-635
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At MIT, I had the great fortune of working with two of the inventors of the
    RSA cryptosystem, and my bachelor’s thesis explored how asymmetric cryptography
    could improve security. The following simplified discussion follows the [original
    RSA paper](https://people.csail.mit.edu/rivest/Rsapaper.pdf), though (for various
    technical reasons that we don’t need to go into here) modern implementations are
    more involved.
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
- en: The core idea of RSA is that it’s easy to multiply two large prime numbers together,
    but given that product, it’s infeasible to factor it into the constituent primes.
    To get started, choose a pair of random large prime numbers, which you will keep
    secret. Next, multiply the pair of primes together. From the result, which we’ll
    call N, you can compute a unique key pair. Each of these keys, together with N,
    allows you compute two functions D and E that are inverse functions. That is,
    for any positive integer *x* < N, D(E(*x*)) is *x*, and E(D(*x*)) is also *x*.
    Finally, choose one of the keys of the key pair as your private key, and publicize
    to the world the other as the corresponding public key, along with N. So long
    as you keep the private key and the original two primes secret, only you can efficiently
    compute the function D.
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how Bob encrypts a message for Alice, and how she decrypts it. Here
    the functions E[A] and D[A] are based on Alice’s public and private keys, respectively,
    along with N:'
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
- en: 'Bob encrypts a ciphertext C from message M for Alice using her public key:
    C = E[A](M).'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alice decrypts message M from Bob’s ciphertext C using her private key: M =
    D[A](C).'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the public key is not a secret, we assume that the attacker Mallory knows
    it, and this does raise a new concern particular to public key crypto. If an eavesdropper
    can guess a predictable message, they can encrypt various likely messages themselves
    using the public key and compare the results to the ciphertext transmitted on
    the wire. If they ever see matching ciphertext transmitted, they know the plaintext
    that produced it. Such a *chosen plaintext attack* is easily foiled by padding
    messages with a suitable number of random bits to make guessing impractical.
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
- en: RSA was not the first published asymmetric cryptosystem, but it made a big splash
    because cracking it (that is, deducing someone’s private key from their public
    key) requires solving the well-known hard problem of factoring the product of
    large prime numbers. Since I was collaborating in a modest way with the inventors
    of RSA at the time of its public debut, I can offer a historical note that may
    be of interest about its significance then versus now. The algorithm was too compute-intensive
    for the computers of its day, so its use required expensive custom hardware. As
    a result, we envisioned it being used only by large financial institutions or
    military intelligence agencies. We knew about Moore’s law, which proposed that
    computational power increases exponentially over time—but nobody imagined then
    that 40 years later everyday people would routinely use connected mobile smartphones
    with processors capable of doing the necessary number crunching!
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
- en: Today, RSA is being replaced by newer methods such as *elliptic curve algorithms*.
    These algorithms, which rely on different mathematics to achieve similar capabilities,
    offer more “bang for the buck,” producing strong encryption with less computation.
    Since asymmetric crypto is typically more computationally expensive than symmetric
    crypto, encryption is usually handled by choosing a random secret key, asymmetrically
    encrypting that, and then symmetrically encrypting the message itself.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
- en: Digital Signatures
  id: totrans-644
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Public key cryptography can also be used to create digital signatures, giving
    the receiving party assurance of authenticity. Independent of message encryption,
    Alice’s signature assures Bob that a message is really from her. It also serves
    as evidence of the communication, should Alice deny having sent it. As you’ll
    recall from Chapter 2, authenticity and non-repudiability are two of the most
    important security properties for communication, after confidentiality.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s walk through an example to illustrate exactly how this works. Alice creates
    digital signatures using the same key pair that makes public key encryption possible.
    Because only Alice knows the private key, only she can compute the signature function
    S[A]. Bob, or anyone with the public key (and N), can verify Alice’s signature
    by checking it using the function V[A]. In other words:'
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
- en: Alice signs message M to produce a signature S = S[A](M).
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bob verifies that the message M is from Alice by checking if M = V[A](S).
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are a few more details to explain so you fully understand how digital
    signatures work. Since verification only relies on the public key, Bob can prove
    to a third party that Alice signed a message without compromising Alice’s private
    key. Also, signing and encrypting messages are independent: you can do one, the
    other, or both as appropriate for the application. We won’t tackle the underlying
    math of RSA in this book, but you should know that the signature and decryption
    functions (both require the private key) are in fact the same computation, as
    are the verification and encryption functions (using the public key). To avoid
    confusion, it’s best to call them by different names according to their purpose.'
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 5-2](#figure5-2) summarizes the fundamental differences between symmetric
    encryption on the left, and asymmetric on the right. With symmetric encryption,
    signing isn’t possible because both communicants know the secret key. The security
    of asymmetric encryption depends on a private key known only to one communicant,
    so they alone can use it for signatures. Since verification only requires the
    public key, no secrets are disclosed in the process.'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
- en: '![f05002](image_fi/501928c05/f05002.png)'
  id: totrans-651
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-2: A comparison of symmetric and asymmetric cryptography'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
- en: Digital signatures are widely used to sign digital certificates (the subject
    of the next section), emails, application code, and legal documents, and to secure
    cryptocurrencies such as Bitcoin. By convention, digests of messages are signed
    as a convenience so that one signing operation covers an entire document. Now
    you can appreciate why a successful preimage attack on a digest function is very
    bad. If Mallory can concoct a payment agreement with the same message digest,
    Bob’s promissory note also serves as a valid signature for it.
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
- en: Digital Certificates
  id: totrans-654
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When I was first learning about the RSA algorithm from the inventors, we brainstormed
    at MIT about possible future applications. The defining advantage of public key
    crypto was the convenience it offered. It let you use one key for all of your
    correspondence, rather than managing separate keys for each correspondent, so
    long as you could announce your public key to the world for anyone to use. But
    how would one do that?
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
- en: I came up with an answer in my thesis research and the idea has since been widely
    implemented. To promote the new phenomenon of digital public key crypto, we needed
    a new kind of organization, called a *certificate authority* *(CA)*. To get started,
    a new CA would widely publish its public key. In time, operating systems and browsers
    would preinstall a trustworthy set of CA *root certificates*, which are self-signed
    with their respective public keys.
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
- en: The CAs collect public keys from applicants, usually for a fee, and then publish
    a digital certificate for each that lists their name (such as “Alice”) and other
    details about them, along with their public key. The CA signs a digest of the
    digital certificate to ensure its authenticity. In theory, an important part of
    the CA’s service would involve reviewing the application to ensure that it really
    came from Alice, and people would choose to trust a CA only if it performed this
    reliably. In practice, it’s very hard to verify identities, especially over the
    internet, and this has proven problematic.
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
- en: Once Alice has a digital certificate, she can send people a copy of it whenever
    she wants to communicate with them. If they trust the CA that issued it, then
    they have its public key and can validate the digital certificate signature that
    provides the public key that belongs to “Alice.” The digital certificate is basically
    a signed message from the CA stating that “Alice’s public key is X.” At that point,
    the recipient can immediately start encrypting messages for Alice, typically by
    first sending their own digital certificate in a signed message to assure Alice
    that her message got to the right person.
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
- en: This simplified explanation of digital certificates focuses on how trusted CAs
    authenticate the association of a name with a public key. In practice, there is
    more to it; people do not always have unique names, names change, corporations
    in different states may have the same name, and so on. (Chapter 11 digs into some
    of these complicating issues in the context of web security.) Today, digital certificates
    are used to bind keys to various identities, including web server domain names
    and email addresses, and for a number of specific purposes, such as code signing.
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
- en: Key Exchange
  id: totrans-660
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Whitfield Diffie and Martin Hellman developed a practical key exchange algorithm
    shortly before the invention of RSA. To understand the miracle of key exchange,
    imagine that Alice and Bob have somehow established a communication channel, but
    they have no prior arrangement of a secret key, or even a CA to trust as a source
    of public keys. Incredibly, key exchange allows them to establish a secret over
    an open channel while Mallory observes everything. The fact that this is possible
    is so counterintuitive that in this case I want to show the math so you can see
    for yourself how it works.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, the math is simple enough and, for small numbers, easy to compute.
    The only notation that might be unfamiliar to some readers is the suffix *(mod
    p)*, which means to divide by the integer *p* to yield the remainder of division.
    For example, 2⁷ (mod 103) is 25, because 128 – 103 = 25\.
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the basis of the Diffie–Hellman key exchange algorithm:'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
- en: Alice and Bob openly agree on a prime number *p* and a random number *g (1 <
    g < p)*.
  id: totrans-664
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alice picks a random natural number *a (1 < a < p)*, and sends *g*^(*a*) *(mod
    p)* to Bob.
  id: totrans-665
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bob picks a random natural number *b (1 < b < p)*, and sends *g*^(*b*) *(mod
    p)* to Alice.
  id: totrans-666
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alice computes *S = (g*^(*b*)*)*^(*a*) *(mod p)* as their shared secret *S*.
  id: totrans-667
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bob computes *S = (g*^(*a*)*)*^(*b*) *(mod p)*, getting the same shared secret
    *S* as Alice.
  id: totrans-668
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 5-3](#figure5-3) illustrates a toy example using small numbers to show
    that this actually works. This example isn’t secure, because an exhaustive search
    of about 60 possibilities is easy to do. However, the same math works for big
    numbers, and at the scale of a few hundred digits, it’s wildly infeasible to do
    such an exhaustive search.'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
- en: '![f05003](image_fi/501928c05/f05003.png)'
  id: totrans-670
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-3: Alice and Bob securely choosing a shared secret via key exchange'
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
- en: In this example, chosen to keep the numbers small, by coincidence Alice chooses
    6, which happens to equal Bob’s result (*g*^(*b*)). That wouldn’t happen in practice,
    but of course the algorithm still works and only Alice would notice the coincidence.
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
- en: It’s important that both parties actually choose secure random numbers from
    a CSPRNG in order to prevent Mallory from possibly guessing their choices. For
    example, if Bob used a formula to compute his choice from *p* and *g*, Mallory
    might deduce that by observing many key exchanges and eventually mimic it, breaking
    the secrecy of the key exchange.
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
- en: Key exchange is basically a magic trick that doesn’t require any deception.
    Alice and Bob walk in from the wings of the stage with Mallory standing right
    in the middle. Alice calls out numbers, Bob answers, and after two back-and-forth
    exchanges Mallory is still clueless. Alice and Bob write their shared secret numbers
    on large cards, and at a signal hold up their cards to reveal identical numbers
    representing the agreed secret.
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
- en: Today, key exchange is critical to establishing a secure communication channel
    over the internet between any two endpoints. Most applications use elliptic curve
    key exchange because those algorithms are more performant, but the concept is
    much the same. Key exchange is particularly handy in setting up secure communication
    channels (such as with the TLS protocol) on the internet. The two endpoints first
    use a TCP channel—traffic that Mallory may be observing—then do key exchange to
    negotiate a secret with the as-yet-unconfirmed opposite communicant. Once they
    have a shared secret, encrypted communication enables a secure private channel.
    This is how any pair of communicants can bootstrap a secure channel without a
    prearranged secret.
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
- en: Using Crypto
  id: totrans-676
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter explained the tools in the crypto toolbox at the “driver’s ed”
    level. Cryptographically secure random numbers add unpredictability to thwart
    attacks based on guessing. Digests are a secure way of distilling the uniqueness
    of data to a corresponding token for integrity checking. Encryption, available
    in both symmetric and asymmetric forms, protects confidentiality. Digital signatures
    are a way of authenticating messages. Digital certificates make it easy to share
    authentic public keys by leveraging trust in CAs. And key exchange rounds out
    the crypto toolbox, allowing remote parties to securely agree on a secret key
    via a public network connection.
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
- en: 'The comic in [Figure 5-4](#figure5-4) illustrates the point made by the epigraph
    that opens this chapter: that well-built cryptography is so strong, the major
    threat is that it will be circumvented. Perhaps the most important takeaway from
    this chapter is that it’s crucial to use crypto correctly so you don’t inadvertently
    provide just such an opening for attack.'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
- en: Crypto can help with many security challenges that arise in the design of your
    software, or which you identify by threat modeling. If your system must send data
    over the internet to a partner datacenter, encrypt it (for confidentiality) and
    digitally sign it (for integrity)—or you could do it the easy way with a TLS secure
    channel that authenticates the endpoints. Secure digests provide a nifty way to
    test for data equality, including as MACs, without you needing to store a complete
    copy of the data. Typically, you will use existing crypto services rather than
    building your own, and this chapter gives you an idea of when and how to use them,
    as well as some of the challenges involved in using the technology securely.
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
- en: '![f05004](image_fi/501928c05/f05004.png)'
  id: totrans-680
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-4: Security versus the $5 wrench (courtesy of Randall Munroe, [xkcd.com/538](http://xkcd.com/538))'
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
- en: Financial account balances and credit card information are clear examples of
    data you absolutely must protect. This kind of sensitive data flows through a
    larger distributed system, and even with limited access to the facility, you don’t
    want someone to be able to physically plug in a network tap and siphon off sensitive
    data. One powerful mitigation would be to encrypt all incoming sensitive data
    immediately when it first hits the frontend web servers. Immediately encrypting
    credit card numbers with a public key enables you to pass around the encrypted
    data as opaque blobs while processing the transaction. Eventually, this data reaches
    the highly protected financial processing machine, which knows the private key
    and can decrypt the data and reconcile the transaction with the banking system.
    This approach allows most application code to safely pass along sensitive data
    for subsequent processing without risking disclosure itself.
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
- en: Another common technique is storing symmetrically encrypted data and the secret
    key in separate locations. For example, consider an enterprise that wants to outsource
    long-term data storage for backup to a third party. They would hand over encrypted
    data for safekeeping while keeping the key in their own vault for use, should
    they need to restore from a backup. In terms of threats, the data storage service
    is being entrusted to protect integrity (because they could lose the data), but
    as long as the key is safe and the crypto was done right, there is no risk to
    confidentiality.
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
- en: These are just a few common usages, and you will find many more ways to use
    these tools. (Cryptocurrency is one particularly clever application.) Modern operating
    systems and libraries provide mature implementations of a number of currently
    viable algorithms so you never have to even think about implementing the actual
    computations yourself.
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
- en: Encryption is not a panacea, however, and if attackers can observe the frequency
    and volume of encrypted data or other metadata, you may disclose some information
    to them. For example, consider a cloud-based security camera system that captures
    images when it detects motion in the house. When the family is away, there is
    no motion, and hence no transmission from the cameras. Even if the images were
    encrypted, an attacker able to monitor the home network could easily infer the
    family’s daily patterns and confirm when the house was unoccupied by the drop
    in camera traffic.
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
- en: The security of cryptography rests on the known limits of mathematics and the
    state of the art of digital hardware technology, and both of these are inexorably
    progressing. Great fame awaits the mathematician who may someday find more efficient
    computational methods that undermine modern algorithms. Additionally, the prospect
    of a different kind of computing technology, such as quantum physics, is another
    potential threat. It is even possible that some powerful nation-state has already
    achieved such a breakthrough, and is currently using it discreetly, so as not
    to tip their hand. Like all mitigations, crypto inherently includes trade-offs
    and unknown risks, but it’s still a great set of tools well worth using.
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
