- en: '2'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: THE ESSENTIALS OF PROGRAMMING LANGUAGES
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](Images/common01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Attempting to compress the essentials of programming languages into a single
    chapter is an impossible task, but I’ll do my best to convey what is essential
    about programming languages as background for the rest of the book. In reality
    though, this chapter should be either a book or a semester-long undergraduate
    course.
  prefs: []
  type: TYPE_NORMAL
- en: The vignettes of [Chapter 1](ch01.xhtml#ch01) were meant to give you an introduction
    to a few programming language concepts, but they left some big questions unanswered.
    For example, what exactly *is* a programming language? How are programming languages
    structured and implemented? What are programming paradigms? And so on. Potential
    questions abound. In this chapter, I’ll provide sufficient answers to these questions,
    and others, to give us what we need to work through the languages we’ll encounter
    and implement later in the book.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll begin this chapter with a working definition of *programming language*.
    Then we’ll cover syntax and semantics—how to speak in a programming language and
    what the speech means. After that, we’ll briefly review the ways programming languages
    are implemented, or made real. We’ll implement several esolangs in this book,
    so basic knowledge in this area will be useful.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll then explore data types and data structures, what sort of data the language
    works with, and how it organizes that data. We’ll also explore variables and *scope*,
    which is the part of the language telling us what information can be seen and
    in what context.
  prefs: []
  type: TYPE_NORMAL
- en: All programming languages implement some form of *flow control*, that is, some
    way to do more than execute instruction after instruction in a linear fashion.
    We’ll explore that before ending the chapter with a discussion of *programming
    language paradigms*, or the different ways programming languages approach coding.
    We encountered several different programming paradigms in [Chapter 1](ch01.xhtml#ch01).
    Here, we’ll put names to the paradigms and discuss their characteristics. The
    paradigm, or paradigms, a language supports directly influence how we think in
    that language.
  prefs: []
  type: TYPE_NORMAL
- en: '**Defining Programming Language**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A book about programming languages should include a definition of its subject.
    Therefore, let’s be explicit about what we mean when we write the words *programming
    language*.
  prefs: []
  type: TYPE_NORMAL
- en: 'A programming language is a vehicle that expresses thought and actualizes it
    as an algorithm to control a computer. A programming language consists of two
    things: *a set of instructions* and *rules for organizing those instructions*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'All of the languages in [Chapter 1](ch01.xhtml#ch01) meet our definition. Clearly,
    Short Code and everything created after it does: there are instructions and rules
    for organizing those instructions. Zuse’s Plankalkül and even Ada’s “diagram of
    development” meet this definition. Ada’s diagram encodes an algorithm in a manner
    useful for the Analytical Engine. Some might quibble that the Analytical Engine
    would not have been able to use the diagram directly, but a modern computer can’t
    use C, ALGOL, or Prolog source code directly, either. A programming language is
    abstract; it needs an interface between itself and the machine it seeks to control.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Syntax and Semantics**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Syntax* refers to how language elements can be combined to form valid statements
    in the grammar of a language. This is true for both human languages and programming
    languages. Most programming languages intended for real-world use have a formal
    grammar, that is, a specification of what is and isn’t allowed as a statement
    in the language. These grammars guide the development of interpreters and compilers
    for the language.'
  prefs: []
  type: TYPE_NORMAL
- en: The word *semantics* refers to the meaning of a syntactically correct statement.
    Syntax is concrete; a statement either is or isn’t valid for the language. Semantics,
    on the other hand, is harder to pin down; it depends on what the programmer (speaker)
    intends, which may differ from the effective meaning. In a human language context,
    this is a misunderstanding; in a programming language context, this is often a
    bug.
  prefs: []
  type: TYPE_NORMAL
- en: 'To help understand the difference between syntax and semantics, let’s consider
    a `while` statement in Pascal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This is an expression of the `while` statement’s syntax. Pascal’s formal grammar
    must define <boolean-expression> and <statements>. A <boolean-expression> is an
    expression that returns a value that is true or false and <statements> is a single
    statement or a sequence of statements with `begin` and `end` around them (a block
    statement).
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, syntactically, this is a correct Pascal statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: However, semantically, this statement is unlikely to be correct. Its meaning
    is likely not what the programmer intended. If `i` is greater than or equal to
    10, the `while` loop never executes because the condition is false. If `i` is
    less than 10, the `while` loop does execute, but would never end because `i` is
    less than 10 and is only getting smaller. In practice, the `while` loop will eventually
    end when `i` wraps around from the largest negative to the largest positive supported
    by the integer data type. In Pascal, the largest negative integer is *–*32,768
    and the largest positive is 32,767\. In Pascal, an integer is signed and 16 bits
    wide. This statement is, at best, a highly inefficient way to do `i := 32767`,
    and is likely not at all what the programmer intended.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember: syntax refers to grammatically correct statements and semantics refers
    to the meaning of a statement.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Implementing Programming Languages**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Konrad Zuse’s Plankalkül was a programming language, but he didn’t implement
    it. Zuse expressed thought through it, but he couldn’t actualize the thought encoded
    because there was no interface, that is, no implementation of the language for
    a physical machine. Programming languages can exist without a computer to run
    them, but to control a machine, there must be an implementation. In this section,
    we’ll discuss the ways programming languages are implemented.
  prefs: []
  type: TYPE_NORMAL
- en: There are two main methods for implementing a programming language. An *interpreter*
    takes the program text, breaks it up into pieces called statements—that is, sets
    of instructions with meaning—and performs the actions implied by the instructions.
    On the other hand, a *compiler* takes the program text, breaks it up into pieces
    with meaning, and translates those pieces into another language, often the computer’s
    machine language.
  prefs: []
  type: TYPE_NORMAL
- en: The output of a compiler is a set of machine instructions that the computer
    can execute directly. Compilers are programs that translate one programming language
    into another. Interpreters are programs that implement the meaning of the instructions
    implied by the program text.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreters are like work crews. They get the work order and make it happen.
    Compilers are like translators. They map meaning from one programming language
    to another. Interpreters run programs; compilers produce programs to run later.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a clear conceptual break between what an interpreter does and what
    a compiler does. Unfortunately, in practice, this line isn’t as distinct as we
    might hope. For example, many new languages are both interpreted and compiled
    at the same time. This includes Python and Java, among others. There is a good
    reason for this: namely, portability between different hardware platforms. Languages
    that do this make use of *bytecode compilers*, which are compilers that translate
    from the high-level source language (like Python) to a low-level target language
    that can be interpreted very quickly. The compiler portion does the hard work
    of extracting the meaning of the program text while the interpreter concentrates
    on performance. The net result is a language implementation that is portable—just
    rewrite the interpreter part for a new target machine—and much faster than an
    old-style interpreter that mindlessly re-derived the meaning of the code, over
    and over, as it was executed.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Tokens, Lexers, and Parsers***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Neither interpreters nor compilers work with source code text as typed. The
    text is first processed by a *lexer* to split the text into *tokens*, which are
    strings representing the elements of the programming language. The lexer often
    attaches extra information to the tokens, such as whether the token is a number
    or a keyword of the language.
  prefs: []
  type: TYPE_NORMAL
- en: The output of the lexer is usually passed to a *parser*, which groups the tokens
    into meaningful language statements, often in the form of a tree. The interpreter
    or compiler then uses that tree to evaluate the statement (interpreter) or transform
    the statement into the target language (compiler).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider this Pascal statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The lexer splits the statement into tokens and then adds the associated information.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Token** | **Associated information** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `y` | Variable, type real |'
  prefs: []
  type: TYPE_TB
- en: '| `:=` | Assignment |'
  prefs: []
  type: TYPE_TB
- en: '| m | Variable, type real |'
  prefs: []
  type: TYPE_TB
- en: '| `*` | Multiplication |'
  prefs: []
  type: TYPE_TB
- en: '| × | Variable, type real |'
  prefs: []
  type: TYPE_TB
- en: '| `+` | Addition |'
  prefs: []
  type: TYPE_TB
- en: '| b | Variable, type real |'
  prefs: []
  type: TYPE_TB
- en: '| `;` | End of statement |'
  prefs: []
  type: TYPE_TB
- en: The parser uses this to construct an *abstract syntax tree* (see [Figure 2-1](ch02.xhtml#ch02fig1)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](Images/02fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 2-1: An abstract syntax tree for y := m*x + b*'
  prefs: []
  type: TYPE_NORMAL
- en: The tree is a representation of the statement in a form the interpreter or compiler
    can process. An interpreter would evaluate the right side of the tree using the
    current value of the variables `m`, `x`, and `b` to assign a new value to the
    variable `y`. A compiler would use the tree to generate a series of assembly language
    or machine code instructions that, when executed, implement the assignment.
  prefs: []
  type: TYPE_NORMAL
- en: Lexers and parsers for real programming languages can be quite complex. Most
    people use parser generators like flex/bison or ANTLR to automatically generate
    code from the language specifications. Fortunately for us, the esolangs we’ll
    explore are often so simple that lexing is removing whitespace and comments and
    parsing is examining the next character in the string output by the lexer. For
    example, this is precisely how the ABC language of [Chapter 7](ch07.xhtml#ch07)
    is processed by its interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: '***Interpreters***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Interpreters are usually easier to write than compilers. Computer scientists
    spent decades learning how to write optimizing compilers that produce highly efficient
    and fast code. The downside of an interpreter is that it’s often slow compared
    to the machine code generated by a compiler. All of the esolangs we’ll work with
    in this book are interpreted, though compilers do exist for some of them (for
    example Brainfuck; see *[https://github.com/Wilfred/bfc/](https://github.com/Wilfred/bfc/)*).
  prefs: []
  type: TYPE_NORMAL
- en: Later in the book, we’ll write interpreters in Python for simple esolangs like
    ABC, FRACTRAN, Filska, and Firefly. By design, their syntax is simple enough that
    complex lexing and parsing are not necessary.
  prefs: []
  type: TYPE_NORMAL
- en: A complete example of an interpreter, with a specified language grammar and
    a complete lexer and parser, is beyond what we can present here. However, I do
    recommend attempting to do that yourself at some point. If you do, think clearly
    and be prepared for some level of frustration before you succeed. For now, let’s
    look at what an old BASIC interpreter does to parse a simple program.
  prefs: []
  type: TYPE_NORMAL
- en: The Apple II computer came with BASIC in ROM. BASIC was both the command line
    and the programming language of the machine. Users entered a line of the program,
    which BASIC immediately parsed and stored in memory. Programs were stored in memory
    as a linked list, which is why every line needed a line number. It was so BASIC
    knew where to insert the line in the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this simple program entered line by line at the prompt (`]`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If this program is `RUN`, it produces a table of squares.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The tokenized representation of this program occupies 30 bytes of the Apple
    II’s memory ([Listing 2-1](ch02.xhtml#ch02list1)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 2-1: A tokenized Applesoft BASIC program*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The program begins at memory location 0x0801, with the link to the next line
    beginning at 0x080D. The line number is stored as a 16-bit unsigned integer, with
    the low-order byte first: `0A 00` = 0 × 256 + 10 = 10\. The parsed line of code
    comes next, where known BASIC commands like `FOR` have been replaced by a single-byte
    token (0x81). Interestingly, the numbers, like 1 and 10 for the `FOR` loop limits,
    are not stored as numbers but rather as ASCII characters. The `PRINT` statement
    is also stored as ASCII characters, including the name of the variable, `X`.'
  prefs: []
  type: TYPE_NORMAL
- en: BASIC must do a significant amount of work to interpret a line, and do so repeatedly
    in this case because a loop is involved. Because of this, BASIC was notoriously
    slow. However, to be fair, the Apple II’s BASIC interpreter was written in assembly
    language for a simple 8-bit microprocessor to run on a machine with as little
    as 16KB of RAM. We’ll use Python to implement our languages, so our task will
    be significantly easier and proportionately less impressive.
  prefs: []
  type: TYPE_NORMAL
- en: '***Compilers***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One of the best books about compilers is the classic “Dragon Book” by Aho,
    Lam, Sethi, and Ullman: *Compilers: Principles, Techniques, and Tools*, 2nd edition
    (Addison Wesley, 2006). It’s called the Dragon Book because of the cover illustration.
    If you are at all curious about compiler design, I recommend this book.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Section 1.2 of the Dragon Book enumerates the phases of a compiler:'
  prefs: []
  type: TYPE_NORMAL
- en: Lexical analyzer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Syntax analyzer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Semantic analyzer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Intermediate code generator
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code optimizer
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Code generator
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Interpreters perform at least phases 1 through 3, and possibly some form of
    phase 4, and then execute the program. Compilers perform all or most of the phases
    to produce machine code output.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the code produced by a simple compiler called `pic0`. It compiles
    a simple stack-based language to assembly code for Microchip 10F2xx series microcontrollers.
    The 10F2xx series are perhaps the cheapest microcontrollers on the market. As
    of this writing, a single 10F200 can be yours for a mere 0.66 USD.
  prefs: []
  type: TYPE_NORMAL
- en: The compiler is in the file *pic0.py*, and implements phases 1 through 5 above.
    Phase 6, final code generation, uses the `gpasm` assembler (see *[https://gputils.sourceforge.io/](https://gputils.sourceforge.io/)*).
  prefs: []
  type: TYPE_NORMAL
- en: The file *timer.pic0* ([Listing 2-2](ch02.xhtml#ch02list2)) contains a PIC0
    program to toggle an LED attached to the microcontroller.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 2-2: A PIC0 program to toggle an LED*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The compiler takes this file as input producing *timer.asm* as output ([Listing
    2-3](ch02.xhtml#ch02list3)). For the final compilation phase, `gpasm` takes *timer.asm*
    as input to produce several output files: *timer.cod*, *timer.lst*, and *timer.hex*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 2-3: PIC0 compiler output*'
  prefs: []
  type: TYPE_NORMAL
- en: The file *timer.hex* contains code actually loaded onto the microcontroller.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[Listing 2-2](ch02.xhtml#ch02list2) may seem somewhat cryptic, but it’s likely
    more readable than [Listing 2-3](ch02.xhtml#ch02list3) even though both programs
    achieve the same goal. To learn more about PIC0, see *PIC0_Manual.pdf* in the
    same directory as *timer.pic0*.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Bytecode Compilers***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Modern interpreters blur the line between interpreter and compiler by compiling
    the high-level language to a low-level language that can be interpreted quickly.
    In essence, these languages produce code for a machine that doesn’t exist: a machine
    simulated via an interpreter. To muddy the waters still further, some bytecode
    compilers perform *just-in-time compilation* (JIT) to produce actual machine code
    instead of interpreting the bytecode itself. Do we still call those languages
    interpreted?'
  prefs: []
  type: TYPE_NORMAL
- en: Bytecode compilers are not new, though they may not have been called that at
    first. For example, the UCSD Pascal system used in the late 1970s produced *p-code*,
    a bytecode that was then interpreted by programs written for a specific system.
    This made the output portable as only the interpreter needed to be rewritten for
    a new system. The Pascal system, including the compiler, was written in Pascal
    and already compiled to p-code.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned above, Python is also bytecode compiled. Python supplies a module,
    `dis`, showing us the bytecode for any function. For example, this function generates
    factorials recursively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: To see the bytecode Python actually runs, we can add
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This produces
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Again, even without studying the meaning of each part of the disassembly, we
    can follow the flow of the function by examining the tokens on the far right and
    the names of the instructions in the middle. For example, `POP_JUMP_IF_FALSE`
    must examine the result of applying `==`, and if not true, jumps to 12, which
    clearly implements the `else` portion of the function.
  prefs: []
  type: TYPE_NORMAL
- en: Notice the final two lines of the disassembly? They return `None`, which is
    the default value Python returns from a function. To us, it is obvious that the
    function never ends by exiting the `if`, as both branches use `return`, but the
    Python compiler must not detect this, so it adds code to handle leaving the function
    without executing `return`.
  prefs: []
  type: TYPE_NORMAL
- en: Programming languages, both compiled and interpreted, must operate on data.
    Let’s now explore how languages manipulate and store data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data Types**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The phrase *data type* refers to the organization of data in a programming language.
    Is the data element a number? A character? A structure made up of other data pooled
    together? How data is processed and stored depends on the data type.
  prefs: []
  type: TYPE_NORMAL
- en: Programming languages fall into different categories based on how they deal
    with data types. A language may be strongly typed or weakly typed. Similarly,
    a language might be statically typed or dynamically typed.
  prefs: []
  type: TYPE_NORMAL
- en: In a *strongly typed language*, the type of a variable will not, at a minimum,
    be automatically changed behind the scenes for a particular use of the variable.
    Python is a strongly typed language, as is Java. For example, in Python, adding
    an integer and string will result in a runtime error, even if the string is actually
    a number. You can see this by running `1 + '2'`, which should generate a `TypeError`.
  prefs: []
  type: TYPE_NORMAL
- en: A *weakly typed language* will change data types implicitly in different situations.
    In [Chapter 5](ch05.xhtml#ch05), we’ll explore SNOBOL. In SNOBOL, for some string
    operations, a numeric value is implicitly converted into a string. Similarly,
    a string that represents a number will be implicitly converted into a number if
    the expression expects a number. In SNOBOL, the expression `1 + '2'` isn’t an
    error. It correctly evaluates to `3` by quietly converting `'2'` into a number
    behind the scenes. Therefore, SNOBOL is a weakly typed language.
  prefs: []
  type: TYPE_NORMAL
- en: A *dynamically typed language* does not require the programmer to declare the
    type of data a variable holds before using it. Python is a dynamically typed language.
    If the variable contains a number, it can be assigned a string at any time, for
    example. Therefore, Python is both strongly and dynamically typed. Smalltalk variables
    are not given a type before use, so Smalltalk is also a dynamically typed language.
  prefs: []
  type: TYPE_NORMAL
- en: A *statically typed language* forces the programmer to declare what kind of
    data a variable will hold. C, C++, Java, Pascal, ALGOL, and FORTRAN are all statically
    typed languages. FORTRAN still supports implicit variable typing, which superficially
    looks like dynamic typing, but it isn’t. Unless otherwise instructed via `implicit
    none`, FORTRAN automatically treats variables beginning with the letters *I* through
    *N* as integers and all other variables as reals (floating-point). The type is
    still specified indirectly. Therefore, FORTRAN is statically typed as well.
  prefs: []
  type: TYPE_NORMAL
- en: As with many things in programming languages, absolute statements are fraught
    with peril. Nonetheless, for pedagogical purposes only, let’s categorize languages
    by whether they are dynamic or static and strongly or weakly typed. The result
    is [Table 2-1](ch02.xhtml#ch02tab1).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 2-1:** Languages by Strong/Weak and Dynamic/Static Typing'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Dynamic** | **Static** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Weak** | JavaScript, Perl, SNOBOL | C, C++, Pascal |'
  prefs: []
  type: TYPE_TB
- en: '| **Strong** | Python, Ruby, Smalltalk, APL | Scala, Java, Ada, ALGOL, FORTRAN,
    COBOL, Simula |'
  prefs: []
  type: TYPE_TB
- en: Some languages don’t have a place in [Table 2-1](ch02.xhtml#ch02tab1). For example,
    in [Chapter 4](ch04.xhtml#ch04) we’ll explore Forth, which is a stack-based language.
  prefs: []
  type: TYPE_NORMAL
- en: Forth has no concept of data type beyond the number of bits used by the values
    on its stack; however, some Forth systems have a separate floating-point data
    stack. The stack value might be a number, or it might be the address of a structure,
    which in Forth is only an agreed upon partitioning of some amount of memory. Forth
    is an *untyped* language and enforces nothing related to types.
  prefs: []
  type: TYPE_NORMAL
- en: Data types and their study are an important part of theoretical computer science.
    Please see the reference material at the back of the book for information on where
    you can go to dive as deeply into the world of data types as you wish. Here, we’ll
    only concern ourselves with primitive data types and *records*, which are user-defined
    collections of other data types.
  prefs: []
  type: TYPE_NORMAL
- en: '***Primitive Data Types***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Primitive data types* are the atoms of a programming language. They are what
    you expect languages to work with: numbers, both integers and floating-point values,
    along with characters (C) and strings (Python). C doesn’t have strings as a primitive
    data type. Instead, it uses arrays of characters to represent strings. In Python,
    strings are primitive, along with Booleans (True or False). Additionally, Python
    supports complex numbers, which are usually represented internally as pairs of
    floating-point values, one for the real part and another for the imaginary part.
    Some languages, like Scheme, support fractions as a primitive data type. We’ll
    use this to good effect in [Chapter 8](ch08.xhtml#ch08) when we implement FRACTRAN
    in Scheme.'
  prefs: []
  type: TYPE_NORMAL
- en: Computers use multiple methods for representing numbers in memory. Depending
    on the language, a programmer might need to know explicit details of how a number
    is stored. This is often true for C when used in an embedded setting, such as
    on a microcontroller or single-board computer. In [Listing 2-1](ch02.xhtml#ch02list1),
    we saw how the Apple II stored the 16-bit integer used to represent the line number
    with its lowest-order byte first followed by the higher-order byte.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Storing integers with the lowest-order byte first is known as little-endian.
    As you might guess, the reverse is known as big-endian (or sometimes network order).
    For a detailed presentation of how computers store and operate on numbers, please
    see my book* Numbers and Computers *(Springer, 2017). To understand the origin
    of “little-endian” and “big-endian,” read* Gulliver’s Travels *by Jonathan Swift.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Records***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you use a programming language for any length of time, you’ll eventually
    want to group different data types into a meaningful unit. A *record*, also known
    as a *structure*, is just that. Languages supporting records include the ALGOL
    family, both the Pascal and C branches ([Figure 1-3](ch01.xhtml#ch01fig3)), along
    with many others, like SML. Exactly how a language supports this concept varies,
    and in some cases, the words *record* and *structure* are not synonymous. This
    is the case with C#, where a record is immutable but a structure is not. Let’s
    look at how Pascal and C implement records.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pascal Records**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'A program to store information on people for later reference would benefit
    from a record grouping a person’s name, birthday, address, and phone number into
    a single unit. We might then define an array of these records to hold the same
    set of information for many different people. In Pascal, such declarations might
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The type `PersonType` combines several strings along with instances of `PhoneNumberType`
    and `BirthdayType`. A variable of type `PersonType` is a single variable with
    multiple fields.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Fields are accessed by name using dot notation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The nested `BirthdayType` is referenced first by accessing `bday`, and then
    by field of `bday`.
  prefs: []
  type: TYPE_NORMAL
- en: A simple example using `PersonType` is in the file *lbb.pas*. To compile it,
    use the Free Pascal compiler (*[https://www.freepascal.org/](https://www.freepascal.org/)*),
    which is easy to install on Ubuntu.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: See the website for macOS and Windows versions. Once installed, compile *lbb.pas*
    with `fpc lbb.pas`. The program generates a random database of 100 different people.
    We’ll skip listing *lbb.pas* to save space, but do read through the file to understand
    what is going on.
  prefs: []
  type: TYPE_NORMAL
- en: '**C Structures**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'C structures are similar to Pascal records. The person structures look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As C has no primitive string type, we first define one using a fixed array of
    32 characters called `string`. The declarations use `typedef` to create a named
    type for each structure (`struct`). The names follow the C convention of using
    underscores and `_t` at the end to denote a type.
  prefs: []
  type: TYPE_NORMAL
- en: Some languages allow a structure to use the same region of memory to represent
    multiple fields with different types. I suspect the original motivation for this
    was to save memory for cases where fields were mutually exclusive. A C `union`
    works this way. For example, the following code defines a union where the same
    memory location is sometimes interpreted as a 32-bit float or a 32-bit unsigned
    integer.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Which interpretation is used depends on which field is accessed, `f` or `d`.
    The code below declares a variable `fp` to be of type `fp_t`, and then assigns
    the floating-point field the value of *π* before referencing the same memory as
    an unsigned 32-bit integer.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '**Data Structures**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *data structure* is a way to organize data in memory. A record is a data structure,
    but the term is usually used to describe more complex ways of managing data. Data
    structures are necessary but somewhat masked by modern programming languages,
    as their intrinsic data structures, like Python’s lists and dictionaries, are
    so powerful that more elaborate data structures are not necessary as often as
    they used to be. Still, for C and C++ programmers, understanding data structures
    is critical. Data structures are a book in their own right, like many topics in
    this chapter. Sadly, we must give data structures short shrift by providing only
    quick summaries.
  prefs: []
  type: TYPE_NORMAL
- en: '***Arrays***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At its simplest, an *array* is nothing more than a block of contiguous memory
    partitioned into chunks of equal size. An array of 100 32-bit integers occupies
    a block of 100 × 4 = 400 bytes because each integer is 4 bytes long. For example,
    in C, `int A[100]` declares `A` to be such an array. The C `sizeof` operator reports
    that `A` uses 400 bytes of memory, as expected.
  prefs: []
  type: TYPE_NORMAL
- en: The variable `A` refers to the first 4-byte block of memory allocated for the
    array. As C knows the size of each element of the array, finding the address of
    any index of the array is as simple as multiplying the index by four and adding
    that number to the base address of the array. This is why many programming languages
    index arrays from 0\. That way the offset to the first array element is 0 bytes
    from the base address.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multidimensional arrays are still stored as a single block of memory. For example,
    Pascal defines a 2D array like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The array `A` is an 8×8 array, or matrix, of integers (think of a chessboard).
    In memory, it’s still a contiguous block of memory, this time using 8 × 8 × 2
    = 128 bytes. To index the array, we use two indices, `A[i,j]`, and calculate the
    address of the desired element as `8 * i + j` added to the base memory address.
    The eight is the number of elements in one row of the array, that is, the number
    of columns. Indexing basic arrays, even multidimensional arrays, is trivial and
    fast as long as the array is stored as a contiguous block of memory.
  prefs: []
  type: TYPE_NORMAL
- en: '***Linked Lists***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Linked lists* are the next simplest data structure. They are a collection
    of nodes, usually allocated on the heap, holding the data of interest along with
    a pointer to the following link in the chain. A *doubly linked* list also keeps
    a pointer to the previous node.'
  prefs: []
  type: TYPE_NORMAL
- en: Inserting and removing elements of a linked list is easy once the proper node
    has been located. Locating a node in the first place is relatively slow by comparison
    because, in the simplest version of a linked list, the list must be traversed
    node by node from the beginning to find the target. Because of their conceptual
    simplicity, linked lists are a favorite homework assignment for introductory programming
    courses.
  prefs: []
  type: TYPE_NORMAL
- en: It might be tempting to wonder if Python lists are sophisticated instances of
    a linked list. However, this is not the case. Python lists are dynamic arrays
    of pointers to the objects they contain. Python lists can deliver good performance
    when indexing by cleverly managing how the arrays grow when new elements are added.
    They use the simple equations above to locate elements, bypassing the slow, node-by-node
    traversal of a linked list. That said, dynamic arrays of object pointers are still
    too slow for many scientific applications, which was the motivation behind powerful
    array-processing libraries for Python, like NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: '***Trees***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Trees* are elaborate hierarchical data structures, usually built dynamically
    in heap memory. There are many different kinds of trees, and they offer excellent
    performance in terms of inserting or removing information and locating information
    quickly. We saw an example of a tree earlier in the chapter in [Figure 2-1](ch02.xhtml#ch02fig1),
    where the parser for a programming language builds trees representing the structure
    of program statements.'
  prefs: []
  type: TYPE_NORMAL
- en: Recursive algorithms exist for quickly traversing trees. Trees are ubiquitous
    in computer science, but again, they are now less often used in day-to-day scenarios
    because modern languages support robust data structures implicitly or via libraries.
    Thus, programmers are freed from implementing their own trees except in the most
    demanding of cases.
  prefs: []
  type: TYPE_NORMAL
- en: '***Hash Tables***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In a *hash table*, a *hash*, the output of a *hash function*, is used to map
    a block of data to a single value. The idea behind a hash function is to map the
    data to a unique value, an integer in a specified range. For example, under the
    hood, Python dictionaries are hash tables. The key is given to the hash function
    to calculate a unique integer representing the key. Then, the table is indexed
    by the hash value to return the data associated with the key.
  prefs: []
  type: TYPE_NORMAL
- en: If two different keys generate the same hash value, a *collision* has occurred.
    There are different options for handling collisions. Python dictionaries randomly
    probe the table to locate an open position for the key in case of a collision.
    A good hash function, plus a thorough knowledge of the probabilities behind hash
    collisions for a specified table size, lets Python manage hashes efficiently to
    minimize collisions while not wasting memory.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there are many more types of data structures. The references at the
    end of the book will point you toward resources where you can explore data structures
    in more depth. For now, let’s learn about how programming languages decide which
    variable to access when referenced in a program.
  prefs: []
  type: TYPE_NORMAL
- en: '**Variables and Scope**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Variables exist in some context, in a relationship to other variables and regions
    of the code. The region of code where a variable is visible is known as the variable’s
    *scope*. Programming languages fall into two main camps when it comes to scope:
    lexical scoping and dynamic scoping. The majority of programming languages use
    lexical scoping. A smaller subset uses dynamic scoping, and a few, like Perl,
    use both. Each language has its own, sometimes rather complex, scoping rules.
    In this section, we’ll restrict ourselves to the difference between lexical and
    dynamic scoping and leave the minutiae of a particular language’s scoping rules
    out of the discussion.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Lexical Scope***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In *lexical scoping* (also called *static scoping*), a variable reference is
    tied back to a declaration or assignment based on the structure of the program
    when the program was written, that is, the structure seen by a compiler. In this
    case, the relationships between variable references and which variable is used
    are static and fixed by the source code’s structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'For lexical scoping, the variable corresponding to a reference follows a simple
    resolution algorithm: local block or function, next outer block or function, next
    outer, and so forth to the global level. Python is statically scoped. Consider
    the following example.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The output of this program is
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Python allows nested function declarations, so the function `a` contains `b`,
    which contains `c`, which in turn contains `d`. The outermost level, global scope,
    defines `x=10`, as the first `print` informs us. We then call `a`, which sets
    `x=15` locally, as `a`’s `print` tells us. Then we call `b`, which does not define
    `x` locally. Therefore, to understand the reference to `x` ➌, Python must search
    for `x` in an enclosing scope. Python finds `x` in `a`, so `b` uses `a`’s value,
    15\. When `c` is called by `b`, `c` must search for an `x` as well ➋. Python doesn’t
    find `x` in `b`, so it searches the next higher enclosing scope, that of `a`,
    where it does find `x=15`. Lastly, `c` calls `d` which defines `x=20` locally,
    as `d` reports ➊.
  prefs: []
  type: TYPE_NORMAL
- en: Lexical scoping makes sense without excessive tracing of the program to understand
    which value is used for which reference. That’s why most languages, especially
    newer or more widely used commercial languages, use it.
  prefs: []
  type: TYPE_NORMAL
- en: '***Dynamic Scope***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Dynamic scoping* uses the current state of the program to decide which value
    goes with which reference. This means it isn’t always easy to see which value
    of a variable will be used by a function, as it depends on the context in which
    the function is used.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do a little experiment. We’ll write what is, more or less, the same program
    in four different languages: lexically scoped Python and C, dynamically scoped
    SNOBOL, and Perl, which, as we’ll see, is both lexically and dynamically scoped.
    We’ll then see if we can explain the output in each case. The presentation below
    lists the source code on the left and the program’s output on the right.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Python***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We know that Python is lexically scoped, as we demonstrated it above. Therefore,
    let’s use Python as our base case, the one that shouldn’t surprise us in any way.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Code** | **Output** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| x = 10 def f():'
  prefs: []
  type: TYPE_NORMAL
- en: return x
  prefs: []
  type: TYPE_NORMAL
- en: 'def g():'
  prefs: []
  type: TYPE_NORMAL
- en: x = 20
  prefs: []
  type: TYPE_NORMAL
- en: return f()
  prefs: []
  type: TYPE_NORMAL
- en: print(g()) | 10 |
  prefs: []
  type: TYPE_NORMAL
- en: The code first defines `x` globally, then `f`, which does nothing more than
    return `x`. Next, the code defines the function `g`, which defines `x=20` locally,
    within the scope of `g`, and then returns whatever `f` returns. The main part
    of the code prints whatever `g` returns.
  prefs: []
  type: TYPE_NORMAL
- en: Look at the definition of `g`. There is a local `x` defined before the call
    to `f`. So why wasn’t the output 20? After all, that’s what `x` is set to immediately
    before the call to `f`. The output isn’t 20 because when `f` is defined (compiled),
    `x` exists globally as 10\. Therefore, that’s the value used for `f`, regardless
    of any local `x` defined by `g`.
  prefs: []
  type: TYPE_NORMAL
- en: Review this example, if necessary, to make sure you follow it. When you are
    ready, read on.
  prefs: []
  type: TYPE_NORMAL
- en: '***C***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: C, like Python, is also lexically scoped. Therefore, this example should be
    much like the example above. Let’s take a look.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Code** | **Output** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| int x = 10; int f() {  return x;  }'
  prefs: []
  type: TYPE_NORMAL
- en: int g() {
  prefs: []
  type: TYPE_NORMAL
- en: x = 20;
  prefs: []
  type: TYPE_NORMAL
- en: return f();
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: int h() {
  prefs: []
  type: TYPE_NORMAL
- en: int x = 15;
  prefs: []
  type: TYPE_NORMAL
- en: return f();
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: void main() {
  prefs: []
  type: TYPE_NORMAL
- en: printf("h() = %d\n", h());
  prefs: []
  type: TYPE_NORMAL
- en: printf("g() = %d\n", g());
  prefs: []
  type: TYPE_NORMAL
- en: '} | h() = 10 g() = 20 |'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, begin at the bottom, with the function `main`. In C, `main`
    must exist and is the entry point for all programs. The function `main` prints
    two values: whatever `h` returns followed by whatever `g` returns.'
  prefs: []
  type: TYPE_NORMAL
- en: The function `h` defines a local `x=15` and then calls `f` to return whatever
    `f` returns. The function `f` can only see the global `x=10`, so that’s what it
    returns. The first output line makes sense.
  prefs: []
  type: TYPE_NORMAL
- en: 'What about the output of `g`? Does that make sense? The function `g` is much
    like `h`, but the assignment to `x=20` doesn’t have an `int` type in front of
    it. When compiling this function, C realizes there is no locally defined `x` in
    `g`, so it goes up one level in scope to find `x` (in this case at global scope)
    and updates that `x`. So `g` has a side effect: it alters the value of `x` globally.
    This is why `f` now returns 20 instead of 10.'
  prefs: []
  type: TYPE_NORMAL
- en: '***SNOBOL***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'SNOBOL, the subject of [Chapter 5](ch05.xhtml#ch05), is a text-processing language
    from the 1970s. SNOBOL is dynamically scoped. Its syntax is strange, which is
    fitting for such a quirky language. For now, we need know only a few things about
    SNOBOL:'
  prefs: []
  type: TYPE_NORMAL
- en: Functions are declared with `define` and return whatever value is assigned to
    their name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variables are declared as local to a function by adding them after the name
    and arguments in the `define` statement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Printing in SNOBOL is assigning to `output`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code we’ll consider is
  prefs: []
  type: TYPE_NORMAL
- en: '| **Code** | **Output** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|       x = 10       define(''f()'')     :(ef)'
  prefs: []
  type: TYPE_NORMAL
- en: f     f = x             :(return)
  prefs: []
  type: TYPE_NORMAL
- en: ef
  prefs: []
  type: TYPE_NORMAL
- en: define('g()x')    :(eg)
  prefs: []
  type: TYPE_NORMAL
- en: g     x = 20
  prefs: []
  type: TYPE_NORMAL
- en: g = f()           :(return)
  prefs: []
  type: TYPE_NORMAL
- en: eg
  prefs: []
  type: TYPE_NORMAL
- en: output = 'global x = ' f()
  prefs: []
  type: TYPE_NORMAL
- en: output = 'local  x = ' g()
  prefs: []
  type: TYPE_NORMAL
- en: output = 'global x = ' x
  prefs: []
  type: TYPE_NORMAL
- en: end | global x = 10 local  x = 20
  prefs: []
  type: TYPE_NORMAL
- en: global x = 10 |
  prefs: []
  type: TYPE_NORMAL
- en: 'This program defines two functions: `f` and `g`. The first returns whatever
    `x` is, and the second, which defines `x` as local to `g`, returns `f`’s return
    value. The main program begins with `x = 10`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first line of the output is much like we saw earlier: `x` is global and
    `f` returns its value. The second line isn’t what we saw earlier. Instead of `f`
    using the value of `x` that existed when `f` was defined, it uses the value of
    `x` set by `g`, even though `g`’s `x` is local to `g`. The function `f` uses the
    context in which it is called, at runtime, to locate the value corresponding to
    `x`. This is dynamic scoping.'
  prefs: []
  type: TYPE_NORMAL
- en: The final line is there to show that `x` has not been updated by `g`, so this
    isn’t the situation we encountered with C where, in that case, `g` did update
    the global value of `x`.
  prefs: []
  type: TYPE_NORMAL
- en: '***Perl***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our final scoping example uses Perl. Perl is known for flexibility, so Perl
    supports both static and dynamic scoping, whichever suits the programmer’s fancy.
    Let’s see how.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Code** | **Output** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| $x = 10; sub f { return $x; }'
  prefs: []
  type: TYPE_NORMAL
- en: sub g {
  prefs: []
  type: TYPE_NORMAL
- en: local $x = 20;
  prefs: []
  type: TYPE_NORMAL
- en: return f()
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: sub h {
  prefs: []
  type: TYPE_NORMAL
- en: my $x = 15;
  prefs: []
  type: TYPE_NORMAL
- en: return f()
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: print g()."\n";
  prefs: []
  type: TYPE_NORMAL
- en: print h()."\n"; |  20  10 |
  prefs: []
  type: TYPE_NORMAL
- en: The form of this program is familiar. We see `f`, `g`, and `h`, just like the
    C example above. The program prints the output of `g` followed by `h`’s output.
    The only difference between `g` and `h`, besides the value assigned to `x`, is
    that `g` uses `local` and `h` uses `my`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Both `local` and `my` define a variable local to a function. The difference
    lies in which type of scoping is applied to the variable. When `my` is used, scoping
    is static, so `h` returns what `f` sees via static scoping, namely, `x=10`. However,
    for `g`, Perl has been told, via `local`, to use dynamic scoping with `x`, so
    the call to `f` from `g` uses `g`’s context to figure out which `x` to use, that
    is, the `x` local to `g`, thereby returning `x=20`. The lesson is clear: read
    Perl source code carefully.'
  prefs: []
  type: TYPE_NORMAL
- en: Variable scoping is intimately linked with program flow. Investigating how programming
    languages implement and manipulate program flow is next on our list.
  prefs: []
  type: TYPE_NORMAL
- en: '**Controlling Program Flow**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'All programming languages implement some form of *flow control*, which is some
    means for modifying the sequence of instructions executed in response to different
    conditions. The discussion in this section focuses on *control structures* commonly
    encountered in programming languages. We’ll divide languages into two main groups:
    unstructured and structured. Let’s learn something about the characteristics of
    each.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Unstructured Languages***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Unstructured languages* use goto, in some form, as the only way to modify
    program flow. Along with goto, these languages have some mechanism for testing
    different conditions. The combination of goto and conditional testing is sufficient
    to implement any algorithm, but that doesn’t mean doing so will be clear or easy
    to debug or verify.'
  prefs: []
  type: TYPE_NORMAL
- en: Old-style BASIC, like the example in [Listing 1-3](ch01.xhtml#ch01list3), is
    unstructured. There are `if` statements and a `goto` statement (of potentially
    different kinds). Likewise, assembly language is unstructured. Review [Listing
    2-3](ch02.xhtml#ch02list3), which includes instructions to test different conditions
    (`btfss`) and gotos.
  prefs: []
  type: TYPE_NORMAL
- en: SNOBOL is also unstructured. Every line in SNOBOL either succeeds or fails,
    and a label can be given to instruct SNOBOL where to go in either case. SNOBOL
    does not have a structured `if` statement, but instead has predicates that either
    succeed or fail, allowing a goto to handle either case.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the esolangs we’ll explore in later chapters are unstructured languages.
    Most use simple tests and branching or goto, like machine code. Some, like the
    Firefly language we’ll develop in [Chapter 15](ch15.xhtml#ch15), or [Chapter 8](ch08.xhtml#ch08)’s
    FRACTRAN, lack any form of goto beyond restarting the program from the beginning.
  prefs: []
  type: TYPE_NORMAL
- en: '***Structured Languages***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Edsger Dijkstra’s famous 1968 letter “Go To Statement Considered Harmful” sounded
    the alarm on how goto as a flow control option is generally a bad idea. In the
    decades since, unstructured languages have faded and have largely been replaced
    by languages that implement *structured programming*, meaning languages that use
    the now-familiar control structures and eschew goto and the like.
  prefs: []
  type: TYPE_NORMAL
- en: '**Selection**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Selection* refers to using the result of a Boolean expression, or the equivalent,
    to alter program flow. The most common selection structure is the `if-then-else`
    construct. For example, in Pascal, and most modern languages, the syntax is virtually
    the same.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `<condition>` returns a Boolean value. If `<condition>` is true, `<statements1>`
    are executed; otherwise, `<statements2>`, if present, are executed. Variations
    on `if` statements exist, like `elif` in Python to combine a nested `if`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Many languages support `case` or `switch` statements. Pascal uses `case` and
    C uses `switch`. For example, in C, a `switch` statement to check on the value
    of an integer, `x`, might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The `break` is necessary, as execution falls through to the next `case` if
    not present. The same construct in Pascal might look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Scheme uses a `cond` statement in much the same way.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Here, each sublist of `cond` is `(<condition> <statements>)` and the statements
    are executed if the condition is true. The `cond` statement tests each condition
    in order until one of them is true.
  prefs: []
  type: TYPE_NORMAL
- en: '**Repetition**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'By *repetition*, I mean any form of looping structure. Specifically, we’ll
    discuss four kinds of loops: top-tested, bottom-tested, counted, and infinite.
    We’ll use Modula-2 for [Listing 2-4](ch02.xhtml#ch02list4), as it supports all
    four kinds. Modula-2 is a successor of Pascal.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 2-4: Loops in Modula-2*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 2-4](ch02.xhtml#ch02list4) presents all four kinds of structured programming
    loops. The preamble loads required functions from the standard library. A single
    variable, `i`, is all we need ➊. Modula-2 distinguishes between integers and cardinals,
    which are positive integers.'
  prefs: []
  type: TYPE_NORMAL
- en: The first loop is a *top-tested* `WHILE` loop ➋. The loop executes while the
    condition is true. Because the test on the condition is at the top of the loop,
    there is the possibility that the loop will never execute.
  prefs: []
  type: TYPE_NORMAL
- en: The second loop ➌ is a *bottom-tested* loop. The test on whether to continue
    the loop happens after the body of the loop; therefore, this loop executes the
    body at least once, regardless of `i`’s initial value. Modula-2 uses `UNTIL` for
    the bottom test, meaning the loop body repeats until the condition is true. Some
    languages, like C, use a `while` for the bottom test, so the loop executes while
    the condition is true.
  prefs: []
  type: TYPE_NORMAL
- en: Modula-2 is one of the few high-level languages with an explicit *infinite*
    loop structure ➍. A `LOOP` executes the body forever, or until `EXIT` is executed.
    A `while` loop that is always true has the same effect.
  prefs: []
  type: TYPE_NORMAL
- en: The last example is a `FOR` loop ➎. Modula-2’s `FOR` is virtually identical
    to that of many other languages. The loop index has an initial value and continues
    incrementing until it reaches its ending value. There are many variants of this
    kind of loop, called the *counted loop*. In this category, I’m including loops
    like Python’s `for` that iterate over any object supporting iteration.
  prefs: []
  type: TYPE_NORMAL
- en: Program flow is influenced by the way the programming language is structured
    and its approach to coding. Let’s conclude the chapter with a review of important
    coding paradigms used by programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: '**Programming Paradigms**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *programming paradigm* is the way a language approaches the act of coding.
    The most important paradigms are imperative, object-oriented, and declarative,
    to which we’ll add my personal favorite, array processing. Let’s discuss the high-level
    characteristics of a few paradigms and give some examples of languages supporting
    each paradigm. Many practical languages support more than one paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: '***Imperative***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Imperative* programming languages instruct the computer step by step. Almost
    all languages, especially those you’ll encounter as a professional developer,
    use this paradigm, or at least support it somewhat. And that makes sense: this
    is the most natural way to think about coding. To achieve a goal, certain things
    must happen in a specific order. That’s imperative programming: the programmer
    issues commands to the computer via the programming language.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Think of a popular programming language. It’s almost undoubtedly imperative:
    Java, Python, C/C++, C#, JavaScript, and so on. All of the languages we encountered
    in [Chapter 1](ch01.xhtml#ch01), except for Prolog and SML, are imperative languages.'
  prefs: []
  type: TYPE_NORMAL
- en: Imperative languages are often further subdivided into structured and unstructured.
    A structured imperative language uses structured programming, which we just discussed
    in the previous section. Therefore, Pascal, C, Modula-2, and so on, are all structured
    imperative programming languages. An unstructured imperative language does not
    use structured programming. This includes assembly, but also higher-level languages
    like SNOBOL.
  prefs: []
  type: TYPE_NORMAL
- en: All the esolangs we’ll encounter and develop are imperative languages. It’s
    the most obvious way to do things.
  prefs: []
  type: TYPE_NORMAL
- en: '***Object-Oriented***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Object-oriented* languages employ encapsulation, polymorphism, and inheritance.
    In a sense, object-oriented languages are imperative languages plus a higher level
    of organization. The leap from imperative programming to object-oriented is relatively
    straightforward.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Encapsulation* means that objects are both data and methods—they have their
    own data, separate from other objects, and their own methods for operating on
    that data. This hides information from outside of the object. This separation
    between objects adds security and reliability to programs. It is less likely that
    changes in one part of the program will adversely and subtly affect another part
    of the program in an object-oriented language.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Polymorphism* is perhaps best understood by example. Imagine a class called
    `Shape` that has a method called `draw`. Now imagine subclasses of `Shape`, such
    as `Rectangle`, `Square`, and `Circle`. Each of these subclasses supplies a `draw`
    method appropriate for its particular shape. This creates an object hierarchy
    (see [Figure 2-2](ch02.xhtml#ch02fig2)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](Images/02fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 2-2: Hierarchy of objects in an object-oriented language*'
  prefs: []
  type: TYPE_NORMAL
- en: In this diagram, `Rectangle`, `Square`, and `Circle` are all children (subclasses)
    of `Shape`. If we now make a function accepting a `Shape` argument, and call the
    `draw` method of that `Shape`, we can pass any subclass of `Shape` to the function
    and the proper `draw` method will be called. This is polymorphism.
  prefs: []
  type: TYPE_NORMAL
- en: '**FUNCTION OVERLOADING**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Polymorphism also happens during *function overloading*, a situation where
    multiple functions using the same name are defined, but each accepts a different
    type of argument. For example, consider this C++ code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The function `CtoF` is defined twice. The first definition accepts an integer
    and returns a double. The second definition accepts a double (64-bit float) and
    returns a double. The `main` function then calls `CtoF`, first with an integer
    argument, and then again with a floating-point argument. The C++ compiler uses
    the argument type to match which function is called.
  prefs: []
  type: TYPE_NORMAL
- en: The program outputs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The first line is from the integer version of `CtoF` and the second is from
    the double version. Note that in C++, if the only `CtoF` available to the compiler
    is the double version, both calls will return 98.6, as the compiler is smart enough
    to know it can automatically change the integer to a double to make the call succeed.
    This is not the case in general and is an example of weak typing in C++. Function
    overloading is an example of *compile-time polymorphism* because the compiler
    selects which function is evaluated while building the output executable.
  prefs: []
  type: TYPE_NORMAL
- en: The final hallmark of an object-oriented language is *inheritance*. This means
    a class can inherit, or acquire, the methods of another class. We saw this above
    with `Shape` and `Circle`, which is a subclass of `Shape`. The class `Circle`
    will inherit any methods `Shape` shares, gaining that functionality for free.
    We also saw inheritance at work in the Simula example of [Chapter 1](ch01.xhtml#ch01),
    where the class `Pal` inherited the member variables of its parent class, `Person`.
  prefs: []
  type: TYPE_NORMAL
- en: '***Declarative***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Declarative* programming, in which the programmer states *what* instead of
    explicitly *how*, comes in several flavors. We already explored one flavor in
    [Chapter 1](ch01.xhtml#ch01)—logic programming—when we discussed Prolog. In Prolog,
    the goal is presented as what needs to happen without explicit step-by-step instructions
    as to how to make it happen.'
  prefs: []
  type: TYPE_NORMAL
- en: Functional programming languages, like SML, also from [Chapter 1](ch01.xhtml#ch01),
    fall under the declarative category as well. SML is a good example of how difficult
    it can be to assign a language to just one paradigm. Functional languages use
    functions and recursion to express the what of a program rather than imperative
    control structures like `while` loops. However, SML supports `while` loops, a
    concession to imperative programming. Other languages that are often called “functional”
    include Lisp and Scheme, and, sometimes, even Python. However, it seems better
    to say Python includes functional programming elements but isn’t a functional
    language.
  prefs: []
  type: TYPE_NORMAL
- en: Hallmarks of functional programming include treating functions as *first-class
    objects*, meaning they can be assigned to variables, and *higher-order functions*,
    functions that accept functions as arguments or return functions. Let’s review
    two examples with Python.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 1](ch01.xhtml#ch01), we saw an example of currying in SML. Now,
    let’s see how currying works in Python.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: First, we define a function called `factory`, which takes an argument and returns
    a function. Look carefully at `factory`. The function, `mult`, is defined within
    `factory` and accepts one argument, `y`. However, the body of `mult` returns `x*y`,
    with `x` being the argument to `factory`. The value of `x` used by `mult` is the
    value of `x` passed to `factory` when `factory` is called.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now look at the return value of `factory` ➊: it is the function, `mult`. Moreover,
    it is `mult` in the environment of `factory`, which means `mult` is using the
    value for `x` passed to `factory`. Now we see why I chose the name: `factory`
    is a generator of functions where one argument, `x`, is fixed. Returning a nested
    function creates a *closure*, a function with a specific environment bound to
    it—namely, the value of `x`.'
  prefs: []
  type: TYPE_NORMAL
- en: The variable `mult2` is assigned whatever `factory(2)` returns ➋. However, `factory(2)`
    returns a function, `mult`, with `x=2`. The variable `mult2` holds a function
    that multiplies its argument by 2\. Likewise, `mult11` holds a function multiplying
    its argument by 11\. Therefore, the code prints `8` and `33` as output.
  prefs: []
  type: TYPE_NORMAL
- en: Our second functional example involves decorators, Python syntactic sugar for
    a higher-order function that wraps another function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This example defines four functions: `mydecorator`, `afunc`, `bfunc`, and `dfunc`.
    The first function ➊ accepts a function, `f`, and returns a new function, `decorate`,
    that wraps the result of `f`. Much like how the `factory` example above created
    a closure binding the value of `x`, `decorate` binds `f` to the function passed
    to `mydecorator`. Using `*args` and `**kwargs` is Python-speak for an arbitrary
    collection of positional and keyword arguments. Therefore, `mydecorator` is a
    higher-order function because it accepts a function as an argument and returns
    a function (a closure).'
  prefs: []
  type: TYPE_NORMAL
- en: The definition of `afunc` ➋ is preceded by `@mydecorator`. This is the syntactic
    sugar part, a readable way to use `mydecorator` with `afunc`. To show this is
    so, ➌ defines `bfunc` identical to `afunc` and then assigns the output of `mydecorator`
    `(bfunc)` to `dfunc`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, consider how `afunc` and `dfunc` work, assuming the code to be in the file
    *decorator.py*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Both calls return the expected value wrapped by the string `'Per your` `request...'`,
    demonstrating that the decorator `@` syntax is, in reality, a function application.
    Decorators enable adding new functionality to a function without altering the
    original function or altering source code that uses the function. Any code depending
    on `afunc` would still work as expected, assuming the decorator did something
    more valuable than intercepting the return value and printing.
  prefs: []
  type: TYPE_NORMAL
- en: Many modern languages have adopted elements of functional programming. Pure
    functional languages—those that are only function calls without side effects like
    updating variable values directly—have yet to make much of a dent outside of academic
    circles. Computer scientists like pure functional languages because they are friendly
    to proving a program to be correct. In contrast, software engineers like some
    aspects of functional languages but still need the ability to easily and more
    directly implement in code thinking that conforms to how we operate—executing
    an algorithm, step by step, to reach a desired outcome.
  prefs: []
  type: TYPE_NORMAL
- en: '***Array Processing***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Scientific programming makes frequent use of numerical data, which is often
    most easily organized as some form of array, be it a vector, matrix, or higher-order
    tensor. For example, image processing and deep learning with convolutional neural
    networks use 2D, 3D, and even 4D data.
  prefs: []
  type: TYPE_NORMAL
- en: Given this, it would make sense for programming languages to process entire
    arrays en masse without explicit loops. Such languages are known as *array-processing*
    languages. In [Chapter 1](ch01.xhtml#ch01), we briefly explored the first one,
    APL. Since APL, many array-processing languages have been developed.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose I’m a deep learning researcher with a dataset of images I need to work
    with. If the images are each 512 rows by 512 columns, I can store the images in
    an array. If the image is grayscale, meaning each pixel is represented by a single
    integer, often in the byte range of [0,255], then I can use a 2D array. If I have
    a stack of images, all the same size, I can store them one on top of the other
    in a 3D array. If the images are color, I need an extra dimension for the channels,
    implying a 4D array.
  prefs: []
  type: TYPE_NORMAL
- en: A common operation with deep neural networks is scaling the input so it lies
    in the range [0,1]. If I have 100 images, each 512 rows by 512 columns, I can
    store the stack in an array that is 100 by 512 by 512\. In that case, the scaling
    operation in a language like Pascal becomes
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In order to access every element of the array, we need a triple loop over the
    indices of the array. It would be nice to write `A := A / 255.0;` and have the
    language just “know” that `A` is an array and automatically apply the scaling
    operation to every element of it. This is precisely what an array-processing language
    provides.
  prefs: []
  type: TYPE_NORMAL
- en: Most deep learning researchers use Python with the NumPy library. NumPy adds
    high-speed array processing to Python. Native array-processing languages are in
    widespread use as well. For example, IDL and Matlab, or their respective open
    source counterparts, GDL and Octave, were built from the ground up for array processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use GDL to see array processing in action. On Ubuntu, install GDL with
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: If using macOS or Windows, see the Github page for installation instructions
    at *[https://github.com/gnudatalanguage/gdl/](https://github.com/gnudatalanguage/gdl/)*.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 2-5](ch02.xhtml#ch02list5) contains GDL code to manipulate a small
    collection of public domain test images.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 2-5: Image processing in GDL*'
  prefs: []
  type: TYPE_NORMAL
- en: The code above is in *arraydemo.pro*. To run it, enter
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The `-quiet` command line argument suppresses GDL’s startup message. Use CTRL-D
    to exit GDL.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 2-5](ch02.xhtml#ch02list5) shows two procedures, `display` and `arraydemo`.
    The procedure `display` ➊ uses GDL commands to show two images, `a` and `b`, side
    by side before writing them to disk as one image. The `tvscl` command displays
    an image with scaling to [0, 255]. The `tvrd` function returns the image in the
    current window.'
  prefs: []
  type: TYPE_NORMAL
- en: All the action is in `arraydemo`. First, we read the test images into 512×512
    pixel arrays ➋. We then take the cameraman image and invert it by subtracting
    it from 255, the largest value in a byte image ➌. The expression `255-i2` returns
    a new 512×512 array in which each element is the difference between 255 and the
    corresponding element of `i2`. The entire image has been processed with no explicit
    loops.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we alpha-blend the test images ➍. Alpha-blending is a technique that merges
    two images into one, like the image on the right in [Figure 2-3](ch02.xhtml#ch02fig3).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](Images/02fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 2-3: The test images (left) and a sample alpha-blend (right)*'
  prefs: []
  type: TYPE_NORMAL
- en: The variable `m03` holds the merged *barbara.png* and *zelda.png* images. Note
    that GDL respects data types, so we first multiply one of the images by the floating-point
    value 1.0 to convert the entire expression to floating-point, thereby avoiding
    the overflow that would happen if we left everything in the byte range. The `bytscl`
    function maps its input to [0,255] to make the result fit as a grayscale image.
  prefs: []
  type: TYPE_NORMAL
- en: The next bit of code merges the cameraman and boat images. Unlike the previous
    blend, the images are given unequal weighting, making the cameraman image twice
    as intense as the boat image. Do review the output images created by `arraydemo`
    to see the full effect.
  prefs: []
  type: TYPE_NORMAL
- en: For ➎, we apply a mathematical expression to the *zelda.png* image. The image
    is first scaled to [0, 1], and then each output pixel is assigned via ![Image](Images/f0075.jpg)
    for all array elements (*i*, *j* = 0, 1, *…*511). The indices are not needed because
    GDL knows to apply the same operation to every array element. In a non-array processing
    language, the expression would be a double loop over *i* and *j*.
  prefs: []
  type: TYPE_NORMAL
- en: A standard image processing technique involves convolving a kernel over an image.
    Convolution means sliding a smaller array (the kernel) over the larger array (the
    image), where for each position of the kernel, the output value is the sum of
    the product of the kernel with the currently overlapped image region for all elements
    in the kernel. Convolution produces an output image showing how the image responds
    to the kernel. In ➏, we apply three kernels. The first detects edges, the second
    sharpens the image, and the last is randomly generated, so each run of *arraydemo.pro*
    produces a different output. The actual convolution uses GDL’s `convol` library
    routine. The random kernel comes from `randomu`, which returns a random array
    in [0,1).
  prefs: []
  type: TYPE_NORMAL
- en: Array processing is a powerful paradigm, especially for scientific applications.
    Without array processing, writing code, especially research code not meant for
    long-term use, would be exceedingly tedious and error prone.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this whirlwind chapter, we presented cherry-picked essentials related to
    programming languages meant as background for the remainder of the book. We discussed
    syntax and semantics and how programming languages are implemented, both interpreters
    and compilers. We then explored data types, including primitive types and records/structures,
    after which we followed a summary of more complex data structures like lists,
    trees, and hash tables. Next, we covered variable scope and learned the difference
    between lexical and dynamic scope. We then reviewed control structures, which
    are ways of controlling and modifying program flow. The chapter then reviewed
    several important programming paradigms, including imperative, object-oriented,
    declarative, and array processing.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s move on and explore a bit of computer science theory related to
    what “computability” means.
  prefs: []
  type: TYPE_NORMAL
