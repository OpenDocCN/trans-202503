<html><head></head><body>
<section>&#13;
<header>&#13;
<h1 class="chapter">&#13;
<span class="ChapterNumber"><span epub:type="pagebreak" title="129" id="Page_129"/>7</span><br/>&#13;
<span class="ChapterTitle">Design as Destiny</span>&#13;
</h1>&#13;
</header>&#13;
<p class="ChapterIntro"><span class="DropCap">D</span>esign is not about making things look pretty.</p>&#13;
<p>Many software engineers I’ve worked with have never considered this fact before it was pointed out to them. It’s an easy mistake to make. The most noticeable output of design thinking is packaging—how we speak about things, how something looks, what features go where, and how features behave. When we consider the end results, designers seem most effective when relegated to polishing up a product in the final stages. We do ourselves and our teams a disservice when we dismiss the toolkit of a designer in this way. Design is critical to making good technical decisions. <em>The US Army/Marine Corps</em><em>Counterinsurgency Field Manual</em><sup class="FootnoteReference"><a id="c07-footnoteref-1" href="#c07-footnote-1">1</a></sup> put it best when it advised soldiers: </p>&#13;
<p>“Planning is problem solving, while design is problem setting.”</p>&#13;
<p><span epub:type="pagebreak" title="130" id="Page_130"/>Problem-<em>solving</em> versus problem-<em>setting</em> is the difference between being <em>reactive</em> and being <em>responsive</em>. Reactive teams jump around aimlessly. Setbacks whittle away their confidence and their ability to coordinate. Momentum is hard to maintain. Responsive teams, on the other hand, are calmer and more thoughtful. They’re able to sort new information as it becomes available into different scopes and contexts. They’re able to change approaches without affecting their confidence, because design thinking gives them insight into why the change happened in the first place.</p>&#13;
<p>With any large, complex project, odds of success are improved if a team can frame the problem and adjust to new information. When done well, problem-setting frees up all members of the team to act autonomously, using their intuition and judgment. At a minimum, problem-setting keeps everybody on the same page about the project’s goals and what success looks like. Legacy projects that maximize the impact of design thinking don’t just modernize, they innovate.</p>&#13;
<p>If those statements sound familiar, it’s because I’ve already described several design exercises for problem-setting in earlier chapters. In Chapter 2, I discussed how working from familiar interfaces increases the likelihood of technology being adopted. In Chapter 3, I explained how to map a system in terms of complexity and coupling. In Chapter 5, I introduced troubleshooting difficult technical conversations with scoping. All of these were design exercises. Now it’s time to dive deeper and explore some variations on the problem setting approaches I’ve already covered.</p>&#13;
<p>The first part of this chapter focuses on applying design techniques to technical decision-making: how to structure technical conversations, scope problems, and come to a consensus.</p>&#13;
<p>The second part of this chapter focuses on using design techniques to align incentives. In the previous chapter, I mentioned how conflicting incentives can doom projects and demoralize teams; this chapter describes how to figure out what the incentives are within the organization and how to position teams for success given that information.</p>&#13;
<h2 id="h1-501188c07-0001"><span epub:type="pagebreak" title="131" id="Page_131"/>Designing Technical Conversations</h2>&#13;
<p class="BodyFirst">Chapter 5 introduced the concept of scope as a solution to avoid unproductive meetings, but in reality, the process of managing a major modernization is all about manipulating scope.</p>&#13;
<p>Scope is determined by what problem you want solve, but few problems exist completely independent from other factors. Deciding which factors actually have influence over the success or failure of that marquee problem and which do not requires thorough and regular feedback. You will have to become adept at collecting data because the factors that can complicate a modernization project are many. They include the historical context, the technical constraints, the skills available through human capital, and internal politics.</p>&#13;
<p>On top of that, some of the information delivered to you by those feedback loops will be incorrect, or you will interpret them incorrectly. The simplest form of design exercise is to talk to your user. Doing that is better than doing nothing, but in unstructured conversations, the quality of the feedback can vary. Sometimes users don’t know what they want. Sometimes the user and the researcher use the same words to mean different things. Sometimes the power dynamics between the user and the person conducting the interview are so great, the user tells the interviewer what he or she wants to hear.</p>&#13;
<p>Design thinking changes the way we address that challenge. It highlights how we ask, who we ask, and who does the asking as determining factors in what information comes to the surface and gets discussed in the first place.</p>&#13;
<p>Don’t underestimate the role social dynamics have in skewing the accuracy of your information. We know that people behave differently when they are being observed. We know that people tend to be conflict-averse and go along with crowds. We know that not every voice on an engineering team carries the same weight. Design exercises can succeed where normal technical conversations fail because they account for those influences.</p>&#13;
<p><span epub:type="pagebreak" title="132" id="Page_132"/>If we think of the average technical conversation as being adversarial in nature with individuals either proposing solutions or challenging the ideas of others, team members have plenty of opportunities to engage in unproductive behavior. What makes them look smart in front of the group won’t necessarily translate to good technical strategy.</p>&#13;
<p>But with design, we can change the path to winning the argument. During a normal team conversation, individual members are looking either to increase or to maintain their status among the group. And, what increases their status? Shooting down the ideas of others. Demonstrating their ability to see some critical flaw everyone else has missed. Developing a brilliant solution. Of those options, developing a brilliant solution is the most difficult to accomplish. Shooting down other people’s ideas is usually much easier. So, environments where team members are jockeying for status can overselect for this behavior.</p>&#13;
<p>Now, imagine that we started the conversation by telling the team we would give them points for coming up with solutions that used a specific piece of technology. The amount of time spent shooting down ideas would plummet as everyone focused on curating the longest list of potential solutions.</p>&#13;
<p>That’s the value of design. When we design our conversations, we turn them into games. We redirect the energy of team members into providing more and better answers instead of simply being right and their colleagues wrong.</p>&#13;
<h2 id="h1-501188c07-0002">How to Run a Design Exercise</h2>&#13;
<p class="BodyFirst">My goal in including a chapter on design in this book is not to turn software engineers into designers. I’m skeptical of the habit of technical people to assume they can pick up disciplines on the fly that others have spent years cultivating and studying. I believe that technical people should focus on bringing technical expertise to the table and seek out other experts to complement their skills. Therefore, I encourage you to <span epub:type="pagebreak" title="133" id="Page_133"/>incorporate design thinking into your process by hiring a designer or, even better, consulting the designers you already employ.</p>&#13;
<p>That being said, it is useful to understand how design thinking works. Design exercises come in various shapes and sizes, but they share these four distinct phases:</p>&#13;
<ol class="none">&#13;
<li><span class="RunInHead"><span class="Caps">Warm-up</span></span>  The warm-up creates a break from the distractions of everyday life so that the participants in the exercise are focused on the task at hand. The simplest warm-ups are listing a few sentences introducing your topic/goal/intention, but more active and complicated exercises might devote more time and energy to warming up. Posing a simple question for group discussions, pair work, or polling people for experiences all can be used as warm-ups.</li>&#13;
<li><span class="RunInHead"><span class="Caps">Research questions</span></span>  When we do a design exercise, we do it with a specific research question in mind. We have a problem or a decision to make, and we want to hear other perspectives. Or, we’re about to invest in a new product, and we want to know if the users will like it. The most common design exercise for engineering teams is observing potential users interacting with a product. A good researcher will be careful not to lead users, not to teach them how to use the product, but let them interact with it organically and use carefully worded questions to direct them to functions relevant to the research objective.</li>&#13;
<li><span class="RunInHead"><span class="Caps">Follow-ups</span></span>  People often say things we don’t expect in design exercises, requiring us to divert from the structure we’ve set out for a moment to understand this new piece of information. Follow-up questions or activities are used to go deeper on individual issues as they appear.</li>&#13;
<li><span class="RunInHead"><span class="Caps">Aggregation</span></span>  At some point—maybe after a single exercise or after a series of interviews—we need to look at all the data and draw a conclusion. Just like engineering, design is often an iterative process. The conclusion of one exercise may create the research question for the next. For example, if a user research session reveals that users <span epub:type="pagebreak" title="134" id="Page_134"/>don’t understand how to interact with the product, future research sessions will test alternative interfaces until the organization has found something that works for users.</li>&#13;
</ol>&#13;
<h2 id="h1-501188c07-0003">More About Follow-ups: Why vs. How</h2>&#13;
<p class="BodyFirst">Creating effective follow-up questions is an art form unto itself. As with research questions, be careful that they don’t suggest their own answers or create ambiguities that might bias the data, but unlike with devising research questions, it is nearly impossible to anticipate everything you might want to follow up on ahead of time. You need to write the questions on the fly.</p>&#13;
<p>A good rule of thumb is questions that begin with <em>why</em> produce more abstract statements, while questions that begin with <em>how</em> generate answers that are more specific and actionable. Think about how your answer would be different if the follow-up were “What are the best tools for the job?” versus “How do you know these tools are the best for the job?” You might list a bunch of common solutions in the answer to the first question, convinced that they are good because they are popular. You are more likely to describe your various experiences with the tools you actually use when asked the second question.</p>&#13;
<p>Both <em>why</em> questions and <em>how</em> questions can be useful. <em>Why</em> questions broaden the boundaries of the research field by allowing unseen factors and forces to be introduced into the data. <em>How</em> questions put you in the minds of users so you can see those factors as they understand them. <em>Why</em> questions often lead to <em>how</em> questions.</p>&#13;
<h2 id="h1-501188c07-0004">Some Useful Design Exercises for Engineering Teams</h2>&#13;
<p class="BodyFirst">Design is a rich industry full of interesting approaches and philosophies, more than what a single chapter can capture. To get you started, I’ve <span epub:type="pagebreak" title="135" id="Page_135"/>provided a few of my favorite exercises for technical conversations. Think of this as a toolkit. Some of these exercises are loosely adapted from <em>The Surprising Power of Liberating Structures: Simple Rules to Unleash a Culture of Innovation</em> by Henri Lipmanowicz and Keith McCandless, which is a great resource for further learning.<sup class="FootnoteReference"><a id="c07-footnoteref-2" href="#c07-footnote-2">2</a></sup></p>&#13;
<h3 id="h2-501188c07-0001">Exercise: Critical Factors<sup class="FootnoteReference"><a id="c07-footnoteref-3" href="#c07-footnote-3">3</a></sup></h3>&#13;
<p class="BodyFirst">This is a brainstorming exercise to do with a team to help prioritize conversations around the early stages of a modernization activity. What must happen for the project goals to be successful? What must not happen? After everyone has had their say and recorded their ideas, the team edits the list to make sure everything on it really deserves to be there. A good way to do that is for the team to discuss each item in terms of whether the project could succeed if everything else on the list of critical factors went favorably. The only items that should remain on the list are the factors that have the ability to take down the entire project by themselves.</p>&#13;
<p><b>After actions:</b> Early technical conversations should focus on achieving or maintaining good outcomes for these critical factors. In-scope issues move outcomes along these critical factors in a positive direction. Out-of-scope issues do not affect these outcomes.</p>&#13;
<h3 id="h2-501188c07-0002">Exercise: The Saboteur<sup class="FootnoteReference"><a id="c07-footnoteref-4" href="#c07-footnote-4">4</a></sup></h3>&#13;
<p class="BodyFirst">A similar but inverse brainstorming exercise to the critical factors exercise is asking your team to play saboteur. If you wanted to guarantee that <span epub:type="pagebreak" title="136" id="Page_136"/>the project fails, what would you do? How can you achieve the worst possible outcome? Once this list is generated, the team discusses if there are any behaviors either internally or from external partners that are close to items on the saboteur list.</p>&#13;
<p><b>After actions:</b> Some of the behaviors on the saboteur list will be habits or ineffective processes that need to be changed. Depending on your results, these items might be worth handling as critical factors. More likely, though, the saboteur list will show you where the fault lines are in your team. What distractions are they the most vulnerable to? How well do they understand their true threats? How do internal politics manifest among team members? The saboteur exercise should help you anticipate out-of-scope issues that are likely to be brought up and who they are likely to come from. Having a sense of that from the beginning helps keep technical conversations on track. If you’re able to open your meetings by defining what is and is not in scope, it is much easier to hold everyone accountable.</p>&#13;
<h3 id="h2-501188c07-0003">Exercise: Shared Uncertainties<sup class="FootnoteReference"><a id="c07-footnoteref-5" href="#c07-footnote-5">5</a></sup></h3>&#13;
<p class="BodyFirst">This exercise also starts by asking team members to identify potential risks and challenges to a project’s success, but this time, you’re looking for differences in how such risks are perceived. Give each team member a four-quadrant map with the following axes:</p>&#13;
<ol class="none">&#13;
<li><span class="RunInHead"><span class="Caps">Simple to complex</span></span>  Problems are simple if they are well defined and understood. They are complicated if their causes are unknown or if solving them means giving up something else of value.</li>&#13;
<li><span class="RunInHead"><span class="Caps">Orderly to chaotic</span></span>  Problems are orderly when there isn’t much debate about the correct way to solve them, although those solutions <span epub:type="pagebreak" title="137" id="Page_137"/>might be long and tedious. They are chaotic when their solutions could accidentally make the situation worse.</li>&#13;
</ol>&#13;
<p>Each team member places challenges somewhere on this map. Then as a group they compare results. How far apart are they? Where are the shared anxieties? Is anyone completely out of sync with everyone else? Depending on your team’s composition, you might want to agree on the challenges to be mapped in advance or let individuals come up with the challenges to map as a group. The advantage to not getting everyone on the same page before mapping is if your team draws from different organizational units or functions, you can better see knowledge gaps by not requiring them all to use the same challenges.</p>&#13;
<p><b>After actions:</b> By far the biggest benefit of this exercise is that it introduces alternative perspectives and priorities in a way that is not confrontational. In open discussions, different perspectives are often presented as responses to other people sharing their own perspectives. This makes the contribution feel like a counterargument and encourages people not to empathize with or listen to each other.</p>&#13;
<p>There’s also an inherent sense of prioritization when overlap and consensus are high on the team. If a certain challenge is thought to be orderly and simple by everyone, the team might prefer to consider it out of scope until strategies are developed around harder problems.</p>&#13;
<p>Regarding simple/chaotic and orderly/complex problems, if you have any of those, they are good issues to focus early conversations around. They are often the most intimidating and anxiety-inducing.</p>&#13;
<h3 id="h2-501188c07-0004">Exercise: The 15 Percent<sup class="FootnoteReference"><a id="c07-footnoteref-6" href="#c07-footnote-6">6</a></sup></h3>&#13;
<p class="BodyFirst">In Chapter 3, I talked about the value of making something 5 percent, 10 percent, or 20 percent better. This exercise asks team members to map out how <span epub:type="pagebreak" title="138" id="Page_138"/>much they can do on their own to move the project toward achieving its goals. What are they empowered to do? What blockers do they foresee, and when do they think they become relevant? How far can they go without approval, and who needs to grant that approval when the time comes?</p>&#13;
<p>Have each team member brainstorm an ordered list of actions they can take right now to make the situation 15 percent better. The number 15 is arbitrary; don’t quibble over whether the impact of actions would really be only an 8 percent improvement. The point is these actions don’t need to come close to solving the problem; they just need to move things forward.</p>&#13;
<p>When each team member has a list, the team should discuss the items, refine them as needed, and make a commitment to execute.</p>&#13;
<p><b>After actions:</b> The best technical conversations are the ones you don’t need to have. This exercise helps teams figure out where they need to make decisions versus where they need only advise and support other team members. Discussing potential blockers and approvers helps focus the invite lists of whatever conversations do need to be scheduled to the most relevant people. Nothing produces out-of-scope digressions more effectively than having people in meetings who don’t need to be there.</p>&#13;
<h2 id="h1-501188c07-0005">Exercises Specifically for Decisions</h2>&#13;
<p class="BodyFirst">The exercises described previously all assume that once information is collected and exposed to the team, the right decisions are self-evident. It doesn’t always work that way. When you’ve collected all the data as a team and had a good, thorough discussion about it, here are two additional exercises that focus on decision-making.</p>&#13;
<h3 id="h2-501188c07-0005">Exercise: Probabilistic Outcome-Based Decision-Making</h3>&#13;
<p class="BodyFirst"><em>Probabilistic outcome-based decision-making</em> is better known as <em>betting.</em> It’s a great technique for decisions that are hard to undo, have potentially serious impacts, and are vulnerable to confirmation bias. I tend to use it a lot to run hiring committees, for example. Firing people is difficult; <span epub:type="pagebreak" title="139" id="Page_139"/>making a wrong hire can destroy a team’s productivity, and people often see what they want to see in potential candidates.</p>&#13;
<p>This is how it works: as a group, we make a list of potential outcomes from the decision that needs to be made. Outcomes like “We’re able to scale 2× by doing this” or “We will implement this new feature by this date.” You can mix both positive and negative outcomes if you like, but I find the conversation usually goes better if the list of outcomes is either positive or negative.</p>&#13;
<p>Then team members place bets as to whether the outcome will come true. Traditionally, this exercise is run with imaginary money. Depending on the specific decision to be made, I sometimes ask them to bet with hours of their time instead of money.</p>&#13;
<p>The mechanics of the bet work the same way they do in any other context. If you bet a lot and win, you gain a lot. If you bet a lot and lose, you lose a lot. Therefore, just asking someone to put a unit value next to an outcome is forcing them to articulate a confidence level. The wondrous thing about this design is that if you ask people to rate their confidence level between 1 and 10, most of them would struggle to answer. It’s the unit itself, the knowledge of how much a dollar or an hour means to them, and what it means to lose a certain amount of dollars or time that helps research subjects articulate their feelings. It doesn’t matter that they will not lose what they’ve bet, just imagining <em>this much money</em> or <em>that much time</em> is enough to help people place where their feelings are on a spectrum.</p>&#13;
<p>You can do this exercise alone when struggling with your own decisions. When I do it with teams, I like to put everyone’s bets for each outcome in a shared document or on a whiteboard. Then we discuss how confident the team feels that the positive outcomes would be reached by making the decision one way or the other. By this point, the right decision is usually much more obvious.</p>&#13;
<h3 id="h2-501188c07-0006">Exercise: Affinity Mapping</h3>&#13;
<p class="BodyFirst"><em>Affinity mapping</em> is a common design exercise involving clustering ideas and statements from individuals together visually. This involves a large <span epub:type="pagebreak" title="140" id="Page_140"/>empty surface, usually a wall or a whiteboard, and generally some markers and Post-it Notes. You’ve probably done affinity mapping before. Everyone writes down their thoughts, one per Post-it Note, and puts it on the wall. Meanwhile, a moderator moves the Post-it Notes around, assembling them into groups of common ideas or feelings.</p>&#13;
<p>Affinity mapping works well for category building, but it can also reveal the specific circumstances that make reaching a consensus on a particular decision so difficult. Often in open discussions, people will talk past one another or assume they mean the same thing when expressing different concepts. Affinity mapping can reveal how far apart from one another the group really is and where the biggest points of disagreement actually are.</p>&#13;
<h2 id="h1-501188c07-0006">Team Structure, Organization Structure, and Incentives</h2>&#13;
<p class="BodyFirst">In 1968, Melvin Conway published a paper titled “How Do Committees Invent?”<sup class="FootnoteReference"><a id="c07-footnoteref-7" href="#c07-footnote-7">7</a></sup> This paper, originally intended for <em>Harvard Business Review</em><em> </em>but rejected for being too speculative in nature, outlined the ways the structure and incentives of an organization influenced the software product it produced. It received little response but eventually made its way to the chair of the University of North Carolina at Chapel Hill’s computer science department, Fred Brooks. At the time, Brooks had been pondering a question from his exit interview at IBM: Why is it so much harder to manage software projects than hardware projects? Conway’s insight linking the structure of software to the structure of the committees that invented it seemed significant enough for Brooks to repackage the thesis as “Conway’s law” when he published his guide on effectively managing software teams, titled <em>The Mythical Man-Month</em>, in 1975.<sup class="FootnoteReference"><a id="c07-footnoteref-8" href="#c07-footnote-8">8</a></sup></p>&#13;
<p><span epub:type="pagebreak" title="141" id="Page_141"/>Yet, this was not the only useful observation in Conway’s paper. As it has subsequently been referenced by hundreds of computer science texts since Brooks’s adoption of it as a universal truth, the more nuanced observations that supported Conway’s argument have largely been omitted from the conversation. Conway’s law has become a voodoo curse—something that people believe only in retrospect. Few engineers attribute their architecture successes to the structures of their organizations, but when a product is malformed, the explanation of Conway’s law is easily accepted.</p>&#13;
<p>Conway’s original paper outlined not just how organizational structure influenced technology but also how human factors contributed to its evolution. Some of his other observations include the following:</p>&#13;
<ul>&#13;
<li>Individual incentives have a role in design choices. People will make design decisions based on how a specific choice—using a shiny new tool or process—will shape their future.</li>&#13;
<li>Minor adjustments and rework are unflattering. They make the organization and its future look uncertain and highlight mistakes. To save face, reorgs and full rewrites become preferable solutions, even though they are more expensive and often less effective.</li>&#13;
<li>An organization’s size affects the flexibility and tolerance of its communication structure.</li>&#13;
<li>When a manager’s prestige is determined by the number of people reporting up to her and the size of her budget, the manager will be incentivized to subdivide design tasks that in turn will be reflected in the efficiency of the technical design—or as Conway put it: “The greatest single common factor behind many poorly designed systems now in existence has been the availability of a design organization in need of work.”</li>&#13;
</ul>&#13;
<p>Conway’s observations are more important in the maintaining of existing systems than they are in the building of new systems. <span epub:type="pagebreak" title="142" id="Page_142"/>Organizations and products both change, but they do not always change at the same pace. Figuring out whether to change the organization or change the design of the technology is just another scaling challenge.</p>&#13;
<h2 id="h1-501188c07-0007">Individual Incentives</h2>&#13;
<p class="BodyFirst">How do software engineers get ahead? What does an engineer on one level need to accomplish for an organization to be promoted to another level? Such questions are usually delegated to the world of engineering managers and not incorporated into technical decisions. And yet, the answers absolutely have technical impacts.</p>&#13;
<p>Most of us have encountered this in the wild: a service, a library, or a piece of a system that is inexplicably different from the rest of the applications it connects to. Sometimes this is an older component of the system reimplemented using a different set of tools. Sometimes this is a new feature. It’s always technology that was trendy at the time the code was introduced.</p>&#13;
<p>When an organization has no clear career pathway for software engineers, they grow their careers by building their reputations externally. This means getting drawn into the race of being one of the first to prove the production-scale benefits of a new paradigm, language, or technical product. While it’s good for engineering teams to experiment with different approaches as they iterate, introducing and supporting new tools, databases, languages, or infrastructures increases the complexity of maintaining the system over time. One organization I worked for had an entire stable of custom-built solutions for things such as caching, routing, and message handling. Senior management hated this but felt their complaints—even their instructions that it stop—did little to course-correct. Culturally, the engineering organization was flat, with teams formed on an ad hoc basis. Opportunities to work on interesting technical challenges were awarded based on personal relationships, so the organization’s regular hack days became <span epub:type="pagebreak" title="143" id="Page_143"/>critical networking events. Engineering wanted to build difficult and complex solutions to advertise their skills to the lead engineers who were assembling teams.</p>&#13;
<p>Stern lectures about the importance of choosing the right technology for the job did not stop this behavior. It stopped when the organization hired engineering managers who developed a career ladder. By defining what the expectations were for every experience level of engineering and hiring managers who would coach and advocate for their engineers, engineers could earn promotions and opportunities without the need to show off.</p>&#13;
<p>Organizations end up with patchwork solutions because the tech community rewards explorers. Being among the first with tales of documenting, experimenting, or destroying a piece of technology builds an individual’s prestige. Pushing the boundaries of performance by adopting something new and innovative builds it even more so.</p>&#13;
<p>Software engineers are incentivized to forego tried and true approaches in favor of new frontiers. Left to their own devices, software engineers will proliferate tools, ignoring feature overlaps for the sake of that one thing tool X does better than tool Y that is relevant only in that specific situation.</p>&#13;
<p>Well-integrated, high-functioning software that is easy to understand usually blends in. Simple solutions do not do much to enhance one’s personal brand. They are rarely worth talking about. Therefore, when an organization provides no pathway to promotion for software engineers, they are incentivized to make technical decisions that emphasize their individual contribution over integrating well into an existing system.</p>&#13;
<p>Typically, this manifests itself in one of three different patterns:</p>&#13;
<ul>&#13;
<li>Creating frameworks, tooling, and other abstraction layers to make code that is unlikely to have more than one use case theoretically “reusable”</li>&#13;
<li>Breaking off functions into new services, particularly middleware</li>&#13;
<li><span epub:type="pagebreak" title="144" id="Page_144"/>Introducing new languages or tools to optimize performance for the sake of optimizing performance (in other words, without any need to improve an SLO or existing benchmark)</li>&#13;
</ul>&#13;
<p>Essentially, engineers are motivated to create named things. If something can be named, it can have a creator. If the named thing turns out to be popular, the engineer’s prestige increases, and her career will advance.</p>&#13;
<p>This is not to say that good software engineers should never break off a new service or introduce a new tool or try a new language on a production system. There just needs to be a compelling reason why those actions benefit the system versus benefit the prospects of the individual engineer.</p>&#13;
<p>Most of the systems I work on rescuing are not badly built. They are badly maintained. Technical decisions that highlight individuals’ unique contributions are not always comprehensible to the rest of the team. For example, switching from language X to language Z may in fact boost memory performance significantly, but if no one else on the team understands the new language well enough to continue developing the code, the gains realized will be whittled away over time by technical debt that no one knows how to fix.</p>&#13;
<p>The folly of engineering culture is that we are often ashamed of signing up our organization for a future rewrite by picking the right architecture for right now, but we have no misgivings about producing systems that are difficult for others to understand and therefore impossible to maintain. This was a constant problem for software engineers answering the call to public service from organizations like US Digital Service and 18F. When modernizing a critical government system, when should the team build it using common private sector tools and train the government owners on said tools, and when should the solution be built with the tools the government worker already knew? Wasn’t the newest, greatest web application stack always the best option? Conway argued against aspiring for a universally correct architecture. He wrote in 1968, “It is an article of faith among experienced system designers that given any <span epub:type="pagebreak" title="145" id="Page_145"/>system design, someone someday will find a better one to do the same job. In other words, it is misleading and incorrect to speak of the design for a specific job, unless this is understood in the context of space, time, knowledge, and technology.”</p>&#13;
<h2 id="h1-501188c07-0008">Minor Adjustments as Uncertainty</h2>&#13;
<p class="BodyFirst">Joel Spolsky once described rewriting software as the single worst strategic mistake any organization could make, but he attributed its nearly universal appeal to a clever maxim that <em>code is easier to write than read</em>.<sup class="FootnoteReference"><a id="c07-footnoteref-9" href="#c07-footnote-9">9</a></sup></p>&#13;
<p>And it’s true; code is easier to write than read. Nearly every software engineer has had the experience of pulling up an old project and finding code that she wrote virtually incomprehensible.</p>&#13;
<p>But that doesn’t explain why we see the same behaviors with infrastructure, data storage, and other products that do not involve writing code.</p>&#13;
<p>One of the major themes that influences how systems degrade over time is how terrible human beings are at probability. We tend to overestimate the likelihood of events recurring once we have already seen them and underestimate the likelihood of events that have not yet happened. Sidney Dekker, a professor of human factors and system safety, called the outcome of this cognition problem on system safety <em>drift</em>.<sup class="FootnoteReference"><a id="c07-footnoteref-10" href="#c07-footnote-10">10</a></sup> Systems do not generally fail all at once; they “drift” into failure via feedback loops caused by a desire to prevent failure. Let’s suppose a worker is given a set of checklists with necessary steps to maintain the system in good working order. If she misses a step and the system doesn’t fail immediately, her perception of risk changes. Skipping that <span epub:type="pagebreak" title="146" id="Page_146"/>step becomes not such a big deal, unlikely to cause failure. The more she skips the step, the more convinced of the safety of her action she becomes. She overlooks the possibility that she could have just gotten lucky. The more corners she cuts, the more prone to failure the system becomes.</p>&#13;
<p>At the same time, if the system fails for a reason not represented in her checklist, she overestimates the odds of such a failure happening again. The system could have failed because there was a significant flaw, or it could have failed because of a random series of events unlikely to recur. Her ability to respond appropriately is determined by her ability to assess the probability of what has just happened correctly. If she overestimates, she will find new steps to add to the checklist to ensure that an unlikely failure does not recur. Over time, the checklists become more and more cumbersome and increase the likelihood that either she or one of her colleagues will skip a step.</p>&#13;
<p>The systems we like to rewrite from scratch are usually the systems we have been ignoring. We don’t know how likely failure is because we pay attention to them only when they fail and forget about them otherwise. A hundred errors on a legacy system is not failure-prone if it handles two million requests over that period. When looking at legacy systems, we tend to overrepresent failures.</p>&#13;
<p>The systems we like to rewrite from scratch also tend to be complex with many layers of abstraction and integrations. When we change something on them, it doesn’t always go smoothly, particularly if we’ve slipped up in our test coverage. The more problems we have making changes, the more we overestimate future failures. The more a system seems brittle, failure-prone, and just impossible to save, the more a full rewrite feels like an easier solution.</p>&#13;
<p>Our perception of risk cues up another cognitive bias that makes rewrites more appealing than incremental improvements on a working system: whether we are trying to ensure success or avoid failure. When success seems certain, we gravitate toward more conservative, risk-averse <span epub:type="pagebreak" title="147" id="Page_147"/>solutions. When failure seems more likely, we switch mentalities completely. We go bold, take more risks.<sup class="FootnoteReference"><a id="c07-footnoteref-11" href="#c07-footnote-11">11</a></sup></p>&#13;
<p>If we are judging odds correctly, this behavior makes sense. Why not authorize that multimillion-dollar rewrite if the existing system is doomed?</p>&#13;
<p>The problem is we’re most likely not judging the odds correctly. We’re overemphasizing failure that may be rare and underestimating both the time it will take to complete the rewrite and the performance gains of the rewrite itself. We are swapping a system that works and needs to be adjusted for an expensive and difficult migration to something unproven.</p>&#13;
<p>It’s the minor adjustments to systems that have not been actively developed in a while that create the impression that failure is inevitable and push otherwise rational engineers toward doing rewrites when rewrites are not necessary.</p>&#13;
<h2 id="h1-501188c07-0009">Organization Size and Communication</h2>&#13;
<p class="BodyFirst">Every working person has experienced how an organization’s size affects its patterns of communication. When small, an organization communicates in an open and fluid manner. It is possible for everyone in the organization to build a relationship with one another. As the organization grows, knowing everyone else becomes less and less feasible. Coordination requires trust. Given a choice, we prefer to base our trust on the character of people we know, but when we scale to a size where that is not possible anymore, we gradually replace social bonds with process. Typically this happens when the organization has reached the size of around 100 to 150 people.</p>&#13;
<p><span epub:type="pagebreak" title="148" id="Page_148"/>One of the benefits of microservices, for example, is that it allows many teams to contribute to the same system independently from one another. Whereas a monolith would require coordination in the form of code reviews—a personal, direct interaction between colleagues—service-oriented architecture scales the same guarantees with process. Engineers document contracts and protocols; automation is applied to ensure that those contracts are not violated, and it prescribes a course of action if they are.</p>&#13;
<p>For that reason, engineers who want to “jump ahead” and build something with microservices from the beginning often struggle. The level of complexity and abstraction is out of sync with the communication patterns of the organization.</p>&#13;
<h2 id="h1-501188c07-0010">Manager Incentives</h2>&#13;
<p class="BodyFirst">An engineering manager is a strange creature in a technical organization. How should we judge a good one from a bad one? Unfortunately, far too often managers advance in their careers by managing more people. And if the organization isn’t properly controlling for that, system design will be overcomplicated by the need to broadcast importance.</p>&#13;
<p>Opportunities to go from being an engineering manager to a senior engineering manager come up from time to time as an organization grows and changes. It’s the difference between handling one team and handling many. Managers leave, new teams form, and existing teams grow past their ideal sizes. A good manager could easily earn those opportunities in the normal course of business. Going from senior manager to director, though, is more difficult. Going from director to vice president or higher is even more so. It takes a long time for an organization to reach that level of growth organically.</p>&#13;
<p>Organizations that are unprepared to grow talent end up with managers who are incentivized to subdivide their teams into more specialized units before there are either enough people or enough work to maintain <span epub:type="pagebreak" title="149" id="Page_149"/>such a unit. The manager gets to check off the career-building experience of running multiple teams, hiring more engineers, and taking on more ambitious projects, and the needs of the overall architecture are ignored.</p>&#13;
<p>Scaling an organization before it needs to be scaled has similar consequences to scaling technology before it needs to be scaled. It restricts your future technical choices. A complex architecture means the organization must successfully anticipate a number of future requirements and determine how code should be best abstracted to create shared services based on those predictions. Rarely are all of those predictions right, but once a shared service is deployed, changing it is difficult.</p>&#13;
<p>In the same way, managers sometimes subdivide their team before there is need to do so. When this happens, they are making predictions about future needs that may or may not come true. In my last role, our director of engineering decided the new platform we were building needed a dedicated team to manage data storage. Predictions about future scaling challenges supported her conclusions, but to get the head count for this new team, she had to cut it from teams that were working on the organization’s existing scaling challenges. Suddenly, new abstractions around data storage that we didn’t need yet were being developed, while systems that affected our SLAs had maintenance and updates deferred.</p>&#13;
<p>Carrying existing initiatives to completion was not as attractive of an accomplishment as breaking new ground. But the problem with designing team structure around the desired future state of the technology is if it doesn’t come true, the team is thrown into the chaos of a reorganization.</p>&#13;
<h2 id="h1-501188c07-0011">Designing a Team: Applications of Conway’s Law</h2>&#13;
<p class="BodyFirst">The challenge of applying Conway’s law in a proactive and positive manner is that divisions of work on technical projects can shift depending on the technical challenge being addressed.</p>&#13;
<p><span epub:type="pagebreak" title="150" id="Page_150"/>Let’s say we have an organization building a system that is composed of three web services. Each service has its own repository of code, its own machine images, and its own deployment schedule. Each has a three-tier structure: an application layer, a data access layer, and a frontend. In the beginning, the frontend and the application are logically separate but hosted in the same code repository for convenience. The frontend is just HTML and some CSS and JavaScript files.</p>&#13;
<p>Our engineering teams probably reflect this structure. For each service, we have a frontend person and some backend people. We want the look and feel of these services to be the same because they are one system, so we have a design org that is separate from the three development teams, but it produces style guides and assets used by all of them. Maybe we assign a specific point of contact on the design team for each engineering team. We do the same thing for our operations and security groups. Their work is overarching and common to all teams, and we want consistent implementation. We don’t want each engineering silo to reinvent the wheel.</p>&#13;
<p>Now let’s say we want to start using a frontend framework like React, Angular, or Vue.js. We still want each service to have the same look and feel, but we also want to minimize duplicate efforts. They should reuse UI components. Who writes that code? Where does that code live? Do we move the frontend engineers out of the product engineering groups and into a separate group like the designers, security engineers, and operations people, or do we keep them where they are and establish a matrix division to handle the shared development work?</p>&#13;
<p>The problem with seeing Conway’s law as prescriptive is that technology is filled with little shifts in perception like this. The technology in our example has not fundamentally changed, but our groupings of what belongs with what have changed. We could tell the same story in reverse: what if we want to transition away from a traditional operations team to a DevOps model? Do our operations people now get moved to <span epub:type="pagebreak" title="151" id="Page_151"/>the product engineering teams? Do backend engineers learn the DevOps tools with operations acting as an oversight authority? Do we keep operations where it is and just ask them to automate?</p>&#13;
<h2 id="h1-501188c07-0012">Reorgs Are Traumatic</h2>&#13;
<p class="BodyFirst">The reorg is the matching misused tool of the full rewrite. As the software engineer gravitates toward throwing everything out and starting over to project confidence and certainty, so too does the software engineers’ manager gravitate toward the reorg to fix all manner of institutional ills.</p>&#13;
<p>And like a full rewrite, sometimes this is the appropriate strategy, but it is not nearly the right strategy as often as it is used. Reorgs are incredibly disruptive. They are demoralizing. They send the message to rank and file engineers that something is wrong—they built the wrong thing or the product they built doesn’t work or the company is struggling. It increases workplace anxiety and decreases productivity. The fact that reorgs almost always end up with a few odd people out who are subsequently let go exacerbates the issue.</p>&#13;
<p>They are also easy to get wrong, creating new silos where information once flowed freely. Organizations are almost always a little behind in capturing and documenting the state of things in flight. Reorgs orphan in-progress initiatives, particularly the ones focused on long-term maintenance, resulting in information loss and follow-ups dropped.</p>&#13;
<p>I think of reorgs as major surgery. If something is seriously wrong, it’s worthwhile to risk it, but you wouldn’t trust a doctor who wanted to open you up because a kidney was just an inch too far to the right. Similarly, you shouldn’t hire managers who want to reorg because they read a blog post that said engineering teams work better when structured this particular way or that particular way.</p>&#13;
<p>Sometimes an organization doesn’t grow in an orderly fashion, and as a result, teams end up owning a combination of things that don’t go <span epub:type="pagebreak" title="152" id="Page_152"/>together or sharing ownership of things that more properly should have one owner. These are the sorts of situations where reorgs make sense.</p>&#13;
<p>Conway’s law is a tendency, not a commandment. Large, complex organizations can develop fluid and resilient communication pathways; it just requires the right leadership and the right tooling. Reorgs should be undertaken only in situations where an organization’s structure is completely and totally out of alignment with its implementation.</p>&#13;
<h2 id="h1-501188c07-0013">Finding the Right Leadership</h2>&#13;
<p class="BodyFirst">Modernization projects are ultimately about transitions. You are moving resources, adjusting processes, and reimagining implementation. The teams that make sense in the beginning do not always make sense at the end.</p>&#13;
<p>To find the right leadership, look for people who have been successful in a wide variety of different contexts—old systems, new systems, big bureaucracies, and small startups. Do not hire aspirationally. Do not hire people whose only experiences are working in companies that reflect your desired end state. Do not hire based on what you wish were true about your organization. This is a pretty common mistake. Organizations that want to grow big recruit executives from big organizations. Organizations that want to migrate to the cloud recruit executives who supervised cloud products.</p>&#13;
<p>Transitions are inherently ambiguous, and the most important characteristic of any leader who steps into a transition is the ability to adapt to the changing conditions that ambiguity opens up. You can assess those skills in interviews, but the best indicator is usually a candidate’s career path. Candidates who are good at adapting have experiences of different sizes and industries on their résumés. They might have done nonprofit or government work. They might have dipped their toes into different careers or roles. They might have left the working world for a few years and then successfully come back.</p>&#13;
<p><span epub:type="pagebreak" title="153" id="Page_153"/>Candidates who have spent seven or eight years essentially in the same type of organization may bring a lot to the table, but they might also be too attached to one way of doing things. They might not understand why certain approaches work in this situation but not that situation. They might be bureaucratic, risk-averse, and not willing to rise to the challenge of a different environment.</p>&#13;
<p>Transitions are all about change, but determining <em>what</em> should change and <em>when</em> it should change are significant questions. We didn’t get where we are all at once. Why should we get anywhere else that way? Leaders who are comfortable with ambiguity have a higher likelihood of figuring out where all the interim phases are between the starting point and the end state.</p>&#13;
<h3 id="h2-501188c07-0007">Exercise: The Smallest Testable Unit</h3>&#13;
<p class="BodyFirst">I developed this exercise for planning failure drills (better known to some software engineers as chaos experiments). I eventually ended up repurposing it as an interview question to assess a candidate’s ability to design a road map for a transition.</p>&#13;
<p>We start with a large goal we want to reach. For example, suppose we have a web application where secrets are kept in a plaintext configuration file. Three decades ago, that would have been the right way to build an application, but now it’s not secure enough. Any number of solutions will improve security, but the organization may not be able to use all of them. This is a typical problem with legacy modernizations: the ideal solution is dependent on conditions that are either not present or not possible. Leaders have to decide whether to compromise on another solution or invest time and energy resolving the dependencies of the preferred solution.</p>&#13;
<p>You might be familiar with the expression <em>yak shaving</em>. It’s when every problem has another problem that must be solved before it can be addressed. In a way, the smallest testable unit exercise is a yak-shaving exercise. You advance through each stage by asking the question “What <span epub:type="pagebreak" title="154" id="Page_154"/>do we need to do this, and how can we test that we have it?” For the previous example, the road map might look like this:</p>&#13;
<ul>&#13;
<li>We need to move secrets to a secure secret management solution. To do that, we need to know how many secrets we have, where they are in code, and who or what needs to use them.</li>&#13;
<li>We can figure out who needs to use our current secrets by carefully logging access to them. To do that, we need a way to aggregate logs and search them. We should take care not to log actual secrets, just the request for them.</li>&#13;
<li>We can test whether we have the ability to aggregate and search logs by having various parts of the application write distinctive messages to the logs and check where those messages end up. To do that, we need access to the application source code.</li>&#13;
<li>We can test whether we have access to the source code by finding the repository, reading the code, and attempting to submit a change to it. To do that, we need some kind of version control solution.</li>&#13;
</ul>&#13;
<p>And so on, and so forth.</p>&#13;
<p>Done well, the candidate plans the roadmap out backward, starting at the end state and identifying smaller and smaller units of change. With each step, we are designing tests to find weaknesses in the organization’s operational excellence that we can resolve. It’s important that our roadmap is structured around proving we have something with a simple test, rather than steps that assert we do. On large projects, it’s easy for people to become confused or misreport the ground truth. It is useful to know how a leader would construct a test to verify information.</p>&#13;
<p>A leader with low tolerance for ambiguity either doesn’t see these blockers or will not acknowledge them, so she sends a top-down directive mandating the new solution. Engineering whips up a hack or a workaround to handle the blockers or else just ignores the top-down directive, and efforts to improve the legacy system stall.</p>&#13;
<h2 id="h1-501188c07-0014"><span epub:type="pagebreak" title="155" id="Page_155"/>Structuring the Team to Account for Past Failure</h2>&#13;
<p class="BodyFirst">Legacy modernizations are never about just one team or one leader. Legacy systems survive because they are important; processes tend to grow around important systems, and organizations tend to grow around those processes. Even if you chose to run one team specifically for the modernization itself, the work of that one team will rely on and influence other teams.</p>&#13;
<p>The three effective structures for modernization are as follows:</p>&#13;
<p><b>Teams that mirror existing components</b>. If there’s a short history of failure, you may be able to trust the current division of labor to carry the day. The teams consist of either all or parts of existing teams, so coordination between them takes the form of a cross-functional meeting group populated by either the leads of each existing component or someone appointed by the component to represent them. More than any other structure, this option relies heavily on interpersonal connections. If cliques and rivalries have begun to form in the organization, it will be hard to keep the group focused.</p>&#13;
<p><b>Lead team and subgroups</b>. With this model, a lead team shapes the high-level view of the modernization effort and then dispatches tasks to the subgroups who are empowered to make any and all decisions on the details of how they implement those instructions. The more a particular modernization project has a track record of failure, the more I like to form a distinction between our effort and business as usual. That means this structure can take the shape of an architecture group advising business components (which we might already have set up), or we can pull people off their normal teams for a short period of time. It is better to avoid slotting the same people into the same roles, and you will likely see an immediate boost of motivation provided the shuffling of roles is made in good faith and the objectives are clear.</p>&#13;
<p>As I mentioned in Chapter 6, nothing says you’re serious about accomplishing something more effectively than changing people’s scenery. <span epub:type="pagebreak" title="156" id="Page_156"/>Consult the “Solution: Code Yellow” on page 116 for more information on how this structure can work.</p>&#13;
<p><b>One embedded team</b>. When the history of failure is long, sometimes the best option is to embed people within existing teams for the sole purpose of implementing solutions. In this model, one team decides on the plan and then dispatches its members to different components around the organization to work on the solution. The trick to getting this right is identity. The members of the embedded team must have strong bonds of camaraderie with each other. They must feel like one team. They should treat their host teams with compassion and empathy, but they also should consider the host teams more like clients or customers rather than as peers.</p>&#13;
<p>This is not the same as pulling representatives from every team into a joint committee. In the committee solution, the individual is bonded to her home team, while having no particular attachment to her colleagues on the committee. With an embedded team, the dynamic should be reversed.</p>&#13;
<p>Implementing these three structures is an exercise in itself to help figure out organically how the organization should self-organize around the new system once completed. Conway’s law is ultimately about communication and incentives. The incentive side can be covered by giving people a pathway to prestige and career advancement that complements the modernization effort. The only way to design communication pathways is actually to give people something to communicate about. In each case, we allow the vision for the new organization to reveal itself by designing structures that encourage new communication pathways to form in response to our modernization challenges. As the work continues, those communication pathways begin to solidify, and we can begin documentation and formalizing new teams or roles. In this way, we sidestep the anxiety of reorganizing. The workers determine where they belong based on how they adapt to problems; workers typically left out are given time and space to learn new skills or prove themselves in different roles, and by <span epub:type="pagebreak" title="157" id="Page_157"/>the time the new organization structure is ratified by leadership, everyone already has been working that way for a couple months.</p>&#13;
<p>Choose your modernization team structure based on how much organizational change you think will be needed to make the new system maintainable.</p>&#13;
<p>Leaving teams as they are supposes that the abstractions of the new system will match those of the old system. There will not be new responsibilities; there will not be new roles. The only things that change from the old system to the new are implementation details like language or tool selection. Many migrations will look like this.</p>&#13;
<p>Having a lead team with subgroups assumes that there will be overarching problems that no one existing team is empowered to fix or has all the necessary information to fix. By the time the new system is completed, new teams may have developed around those issues. For example, the organization might realize that new services need to be developed or that to enforce good practices across the engineering organization, they need internal tooling. With this structure, we know some parts of our engineering group will remain the same, and some parts of it will change, but we don’t know exactly how.</p>&#13;
<p>Finally, the embedded team sets the precedent of injecting expertise as needed into other teams. I use this structure when the goal state of the new system is significantly different from the old system. When there’s that much change, technology and practices that are completely foreign to existing engineers usually are being introduced. Moving off mainframes, shutting down a data center in favor of the cloud, rolling out SRE, or incorporating orchestration are all examples of modernization challenges where there is likely to be a skills gap on the existing teams. The expert being injected to advise and assist will start the process of forming new teams by figuring out how the work the old team needs to do gets split up. For example, if the modernization effort involves a new piece of technology, not everyone on the team will need to reach the same proficiency level with it. Rather than a senior manager deciding who will go <span epub:type="pagebreak" title="158" id="Page_158"/>where, the organization lets the existing team work on it and sees who develops an aptitude.</p>&#13;
<p>What you don’t want to do is draw a new organization chart based on your vision for how teams will be arranged with the new system. You don’t want to do this for the same reason that you don’t want to start product development with everything designed up front. Your concept of what the new system will look like will be wrong in some minor ways you can’t possibly foresee. You don’t want to lock in your team to a structure that will not fit their needs.</p>&#13;
<p>Instead, ask yourself who needs to collaborate with whom for various stages of the modernization project to work, and pick a structure that makes this communication easy.</p>&#13;
<h3 id="h2-501188c07-0008">Exercise: In-Group/Out-Group</h3>&#13;
<p class="BodyFirst">Who needs to communicate with whom may not be clear when you get started. This is an exercise I use to help reveal where the communication pathways are or should be. I give everyone a piece of paper with a circle drawn on it. The instructions are to write down the names of the people whose work they are dependent on inside the circle (in other words, “If this person fell behind schedule, would you be blocked?”) and the names of people who give them advice outside the circle. If there’s no one specific person, they can write a group or team name or a specific role, like frontend engineer, instead.</p>&#13;
<p>Then I compare the results across each team. In theory, those inside the circle are people with whom the engineer needs to collaborate closely. Each result should resemble that engineer’s actual team with perhaps a few additions or deletions based on current issues playing out. Outside the circle should be all the other teams. Experts not on the team should be seen as interchangeable with other experts in the same field.</p>&#13;
<p>Small variations will exist from person to person, but if the visualizations that people produce don’t look like their current teams, <span epub:type="pagebreak" title="159" id="Page_159"/>you know your existing structure does not meet your communication needs.</p>&#13;
<p>You can modify this exercise to look at the communication needs of the new system instead of the existing one by focusing the research question on a future work stream. Instead of which people might be blockers or advisors generally, ask people to visualize the in-group and out-group in terms of a specific modernization task.</p>&#13;
<h2 id="h1-501188c07-0015">Takeaways</h2>&#13;
<p class="BodyFirst">This chapter covers a lot of ground. Design thinking is a rich landscape with lots of insight and strategy of value to the task of legacy modernization. I have tried to demonstrate enough of that value to encourage you to bring a designer into your fold if you don’t already have one. To review, here are the takeaways you should have from this chapter:</p>&#13;
<ul>&#13;
<li>Design is problem setting. Incorporating it into your process will help your teams become more resilient.</li>&#13;
<li>By themselves, technical conversations tend to incentivize people to maintain status by criticizing ideas. Design can help mitigate those effects by giving conversations the structure of a game and a path to winning.</li>&#13;
<li>Legacy modernizations are ultimately transitions and require leaders with high tolerance for ambiguity.</li>&#13;
<li>Conway’s law doesn’t mean you should design your organization to look like the technology you want. It means you should pay attention to how the organization structure incentivizes people to behave. These forces will determine what the technology looks like.</li>&#13;
<li>Don’t design the organization; let the organization design itself by choosing a structure that facilitates the communication teams will need to get the job done.</li>&#13;
</ul>&#13;
<p><span epub:type="pagebreak" title="160" id="Page_160"/>In the next chapter, I’ll continue to explore the concept of communication by tackling the issue of breaking changes and how to keep them from blocking progress forward.</p>&#13;
</section>&#13;
<section class="footnotes">&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-1" href="#c07-footnoteref-1">1.</a></sup> 	<em>The U.S. Army/Marine Corps Counterinsurgency Field Manual</em> (Chicago: University of Chicago Press, 2007).</p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-2" href="#c07-footnoteref-2">2.</a></sup> Henri Lipmanowicz and Keith McCandless, <em>The Surprising Power of Liberating Structures: Simple Rules to Unleash a Culture of Innovation</em> (Seattle: Liberating Structures Press, 2016).</p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-3" href="#c07-footnoteref-3">3.</a></sup> “Min Specs: Specify Only the Absolute ‘Must Dos’ and ‘Must Not Dos’ for Achieving a Purpose,” Liberating Structures, accessed February 2020, <a href="http://www.liberatingstructures.com/14-min-specs/" class="LinkURL">http://www.liberatingstructures.com/14-min-specs/</a><em>.</em></p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-4" href="#c07-footnoteref-4">4.</a></sup> “Making Space with TRIZ: Stop Counterproductive Activities and Behaviors to Make Space for Innovation,” Liberating Structures, accessed February 2020, <a href="http://www.liberatingstructures.com/6-making-space-with-triz/" class="LinkURL">http://www.liberatingstructures.com/6-making-space-with-triz/</a>.</p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-5" href="#c07-footnoteref-5">5.</a></sup> “Critical Uncertainties: Develop Strategies for Operating in a Range of Plausible Yet Unpredictable Futures,” Liberating Structures, accessed February 2020, <a href="http://www.liberatingstructures.com/30-critical-uncertainties/" class="LinkURL">http://www.liberatingstructures.com/30-critical-uncertainties/</a>.</p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-6" href="#c07-footnoteref-6">6.</a></sup> “15% Solutions: Discover and Focus on What Each Person Has the Freedom and Resources to Do Now,” Liberating Structures, accessed February 2020, <a href="http://www.liberatingstructures.com/7-15-solutions/" class="LinkURL">http://www.liberatingstructures.com/7-15-solutions/</a>.</p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-7" href="#c07-footnoteref-7">7.</a></sup> Melvin E. Conway, “How Do Committees Invent?,” <em>Datamation</em>, April 1968, 28–31.</p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-8" href="#c07-footnoteref-8">8.</a></sup> Frederick Brooks, <em>The Mythical Man-Month</em> (Reading, MA: Addison-Wesley, 1995).</p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-9" href="#c07-footnoteref-9">9.</a></sup> Joel Spolsky, “Things You Should Never Do, Part I,” Joel on Software, April 6, 2000, <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/" class="LinkURL">https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/</a>.</p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-10" href="#c07-footnoteref-10">10.</a></sup> Sidney Dekker, <em>Drift into Failure</em> (Abingdon-on-Thames, UK: Routledge, 2018).</p>&#13;
</aside>&#13;
<aside class="FootnoteEntry">&#13;
<p><sup class="FootnoteReference"><a id="c07-footnote-11" href="#c07-footnoteref-11">11.</a></sup> See the work of Daniel Kahneman and Amos Tversky on the pseudocertainty effect for more detail, as well as their bestseller book <em>Thinking, Fast and Slow </em>(New York: Farrar, Straus and Giroux 2011).</p>&#13;
</aside>&#13;
</section>&#13;
</body></html>