- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: 17 GRAPHS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/opener.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the previous chapters we discussed several data structures, and in this chapter
    we’ll consider a new topic, how to represent graphs*.* We’ll also look at several
    algorithms related to graphs, such as finding the shortest paths, calculating
    distances, checking software dependencies, and more.
  prefs: []
  type: TYPE_NORMAL
- en: What Are Graphs?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An abstract definition might be that a graph is a set of objects in which pairs
    of those objects are somehow related. The objects are called *vertices* (plural
    of *vertex*), but they’re also called *points* and *nodes*. The relationships
    between pairs of vertices are graphically represented with lines joining the pairs.
    These lines are called *edges*, *arcs*, *arrows*, or just plain *links*. The number
    of arcs connected to a point is called its *degree*. Points linked in this fashion
    are sometimes called *neighbors* or are considered to be *adjacent* to each other.
    The same word is used in a similar sense: edges are considered to be adjacent
    if they share a common vertex.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These definitions may sound vague or rather “mathematical” (in fact, a branch
    of mathematics that specifically studies graphs and their properties is called
    *graph theory*), so this chapter will explore some practical examples. (We’ve
    actually already studied graphs. Trees are graphs; indeed, the definition fits
    them.) Some use cases for graphs include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Relationships among people, where you can have people (nodes) and friendships
    (arcs), so that if two people are friends, they are linked
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dependencies in code, with modules (nodes) that import components (arcs) exported
    from other modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Projects with tasks (nodes) that can’t be started until some other tasks have
    been finished (arcs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maps, as in GPS-based applications, with cities (nodes) and roads (arcs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 17-1](chapter17.xhtml#fig17-1) shows an example of the latter, using
    a graph to represent a part of a city or a country.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-1: A graph representing some cities and roads linking them'
  prefs: []
  type: TYPE_NORMAL
- en: In this graphical map, vertices represent cities (or street corners, or countries),
    and the edges represent roads (or street blocks, or flights). In [Figure 17-1](chapter17.xhtml#fig17-1),
    the edges are *undirected*, meaning that one may travel any direction—for example,
    from A to E or from E to A.
  prefs: []
  type: TYPE_NORMAL
- en: In a city map, where streets may be one-way only, we’d need a *directed* graph
    instead, as shown in [Figure 17-2](chapter17.xhtml#fig17-2). In these graphs,
    we can speak of the *outdegree* of a node (how many arcs lead out from it) or
    the *indegree* of a node (how many arcs lead into it).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-2: A directed graph where you can travel the roads in only one direction'
  prefs: []
  type: TYPE_NORMAL
- en: Edges usually have values associated with them, like time or cost, making them
    *weighted* graphs. *Unweighted* graphs with no values associated with edges are
    also possible; the association itself is all that matters. Don’t assume that symmetry
    or any other rules apply to directed graphs. For instance, in the graph in [Figure
    17-2](chapter17.xhtml#fig17-2), you can go from B to C directly, but you can’t
    go back from C to B in one step. Also, going from A to B doesn’t cost the same
    as going from B to A. Finally, going from G to D via F could be cheaper than going
    directly from G to F. In some cases weights could be negative, but we’re always
    working here with non-negative values.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Graphs can also have multiple edges between any pair of vertices, but we’re
    not going to consider those. For all the algorithms in the chapter, it’ll be enough
    to just use the shortest edge and simply ignore the others. Another possibility
    we’ll ignore here is edges from a vertex to itself, which are called loops.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll consider the following kinds of processes:'
  prefs: []
  type: TYPE_NORMAL
- en: Given two vertices, you may want to know whether there’s a path from the first
    to the second. As an extension to this, you might want to find the path with the
    minimum cost (the *shortest path*) from one vertex to another one or to all other
    vertices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A directed graph may represent a project with tasks and dependencies between
    them: you might want to find an ordering so that no task can start until all previous
    tasks have been finished; this is called a *topological sort*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building on this example of tasks and dependencies, you may worry that some
    kind of cycle (A before B before C before A) would make sorting impossible. A
    related problem to topological sorting is *cycle detection*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An undirected graph may represent geographic points with the edges showing the
    cost of joining them with, say, electrical lines or communication cables. A *minimum
    spanning tree* shows how to choose edges so all points are connected to each other
    at the lowest total cost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Along the same lines, given the previous graph, you could ask whether it’s connected
    (meaning that it’s possible to reach every point from any other point) or unconnected.
    In that case, you want to implement *connectivity detection*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This list of procedures isn’t complete, but it covers the most important algorithms.
    Let’s start by considering how to represent graphs and then move on to the necessary
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 'One final note: when discussing the performance of algorithms, we’ll use *v*
    to stand for the number of vertices and *e* for the number of edges. Take care
    not to confuse this with the mathematical constant *e*, the basis for natural
    logarithms, 2.718281728 ...!'
  prefs: []
  type: TYPE_NORMAL
- en: Representing Graphs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are several ways to represent graphs, and we’ll consider the three most
    used methods: adjacency matrix, adjacency list, and adjacency set.'
  prefs: []
  type: TYPE_NORMAL
- en: Adjacency Matrix Representation for Graphs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The *adjacency matrix* representation is the simplest and basically shows which
    nodes are adjacent to each other. This type of graph is represented by a square
    matrix, with a row and column for each vertex. If there’s a link from vertex *i*
    to vertex *j*, the matrix has a value at position [i][j]: this is just a true
    value for unweighted graphs or the associated edge’s cost for weighted graphs.
    If there’s no link between those vertices, the matrix has false or a special value
    (zero or +infinity) at the corresponding position. For undirected graphs, note
    that position [i][j] will always be equal to position [j][i]; the matrix will
    be symmetrical with regard to its main diagonal.'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the directed graph from the previous section again ([Figure 17-2](chapter17.xhtml#fig17-2)).
    The matrix representation for that graph could be as [Figure 17-3](chapter17.xhtml#fig17-3)
    shows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-3: The adjacency matrix representation for the graph in [Figure 17-2](chapter17.xhtml#fig17-2)'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve used the option of representing missing edges with zero; an equally valid
    solution is to represent those with +infinity. No matter how you represent missing
    edges, in both cases, the diagonal of the matrix is zero. There’s no cost involved
    in going from a point to itself; you’re already there.
  prefs: []
  type: TYPE_NORMAL
- en: This representation is quite easy to work with, but it requires a lot of space
    for large graphs. As to performance, operations like checking whether two vertices
    are adjacent or adding or removing edges are *O*(1), which is as fast as possible.
    On the other hand, processing the list of edges of a vertex is *O*(*v*) no matter
    how many neighbors a node actually has.
  prefs: []
  type: TYPE_NORMAL
- en: If nodes have only a few neighbors, most of the matrix will be marked as empty
    (making it a *sparse* matrix), which means you’re wasting space. For those cases,
    you can choose adjacency list representations.
  prefs: []
  type: TYPE_NORMAL
- en: Adjacency List Representation for Graphs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The matrix shown in [Figure 17-3](chapter17.xhtml#fig17-3) wastes too much space
    and causes all procedures that need the list of arcs out of a point to be *O*(*v*).
    You can use lists so that for each vertex, you’ll have all the points to which
    it connects and also all of the points that connect to it.
  prefs: []
  type: TYPE_NORMAL
- en: For the same directed graph shown in [Figure 17-2](chapter17.xhtml#fig17-2),
    the *adjacency lists* representation is as shown in [Figure 17-4](chapter17.xhtml#fig17-4)
    (compare this with the matrix representation in [Figure 17-3](chapter17.xhtml#fig17-3)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-4: The adjacency list representation is an alternative to the adjacency
    matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For each vertex, you have two lists: one with outgoing edges (shown horizontally,
    as rows) and one with incoming edges (shown vertically, as columns). For example,
    in the first row, you see that from A, one may reach B (at a cost of 4) or E (at
    a cost of 11). Looking at the first column, you see that you can reach A from
    B (at a cost of 3) or D (at a cost of 5). Each element in the structure would
    have a pointer to the next in the same row and another to the next in the same
    column. You could also work with doubly linked lists for easier updates. Nodes
    also have to carry the identities of both endpoints.'
  prefs: []
  type: TYPE_NORMAL
- en: With this structure, it’s easy to process all edges that start or end at a given
    vertex quickly, and that will speed up several algorithms. However, things become
    slower if you just want to know whether two given points are directly connected;
    with this structure, it would be an *O*(*e*) operation. You may opt for using
    sets instead of lists, as shown later.
  prefs: []
  type: TYPE_NORMAL
- en: Adjacency Set Representation for Graphs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The more complex solution we can propose involves using sets (as in [Chapter
    11](chapter11.xhtml)) or trees (as in [Chapter 12](chapter12.xhtml)) instead of
    lists. For instance, when working with balanced search trees, checking whether
    two points are connected is a *O*(log *e*) operation. (You could consider an average
    degree of *e*/*v* edges per node, and then it would be *O*(log *e/v*) instead.)
    With this structure, each vertex is associated with two maps: one for outgoing
    edges and one for incoming edges. The key for both maps would be the “other” point
    in the edge. Adding and removing edges are both *O*(log *e*) operations, so performance
    is better. Processing all arcs out of a node is as fast as with lists.'
  prefs: []
  type: TYPE_NORMAL
- en: Finding the Shortest Paths
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A common problem is as follows: given two points in a graph, find a path from
    the first to the second. A path is a sequence of adjacent edges (each starting
    where the previous ends) that begins at the first point and ends at the second
    one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We already considered this kind of problem when you found a path through a
    maze in [Chapter 5](chapter5.xhtml), so instead solve a more complex problem:
    finding the *shortest* path from a node to another node, or even more generally,
    finding the shortest path for a node to all other nodes. These algorithms will
    not only find whether a path exists, but they’ll also find the best one (cheapest,
    shortest) among all possibilities. If you just want to find a path, any path,
    you can simply stop searching as soon as you reach the destination point.'
  prefs: []
  type: TYPE_NORMAL
- en: Floyd-Warshall’s “All Paths” Algorithm
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This first algorithm is interesting because it applies dynamic programming,
    which you explored in [Chapter 5](chapter5.xhtml). The *Floyd-Warshall algorithm*
    doesn’t have the best possible performance (you’ll see other options for that),
    but it’s definitely the simplest. There’s another difference: here, you’ll find
    the shortest distance between all pairs of nodes, while in other cases you may
    just want to find the distance between a specific pair. This stipulation will
    have an impact on the performance, but in some cases, having the whole table of
    distances may be exactly what’s required.'
  prefs: []
  type: TYPE_NORMAL
- en: Assume the existence of a function *distance*(*i,j,k*) that returns the length
    of the shortest path from point *i* to point *j* using, at most, the first *k*
    nodes in the graph for the path. (In other words, you’re not considering any path
    through the rest of the nodes.) You want to calculate *distance*(*i,j,n*) for
    all values of *i* and *j*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The value of *distance*(*i,j,k*) must be either a path that doesn’t include
    the *k*th node or else a path that goes from *i* to *k* and then from *k* to *j*,
    whichever is shortest. In other words, *distance*(*i,j,k*) is the minimum of *distance*(*i,j,k*
    – 1) and *distance*(*i,k,k* – 1) + *distance*(*k,j,k* – 1). This formula is key;
    be sure you totally agree with it. The definition is recursive, but the base case
    is simple: *distance*(*i,i,*0) is 0 for all points, and for *i ≠ j*, *distance*(*i,j,*0)
    is the edge from *i* to *j*, if it exists, or +infinity instead. (What about finding
    the actual paths and not just the distances? See question 17.1.)'
  prefs: []
  type: TYPE_NORMAL
- en: As an example, work with the graph in [Figure 17-5](chapter17.xhtml#fig17-5).
    It’s undirected for simplicity, but the algorithm works with directed graphs as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-5: A graph for which you want to find minimum distances between any
    pair of points'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 17-6](chapter17.xhtml#fig17-6) shows the initial array of distances
    in [Figure 17-5](chapter17.xhtml#fig17-5).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-6: The adjacency matrix for the graph in [Figure 17-5](chapter17.xhtml#fig17-5),
    using infinity values for missing edges'
  prefs: []
  type: TYPE_NORMAL
- en: The diagonal in [Figure 17-6](chapter17.xhtml#fig17-6) is all zeros, and everything
    is +infinity except for the existing edges. (This is just the adjacency matrix
    using +infinity instead of zero for missing edges, as mentioned earlier in the
    chapter.) In the first iteration, check whether adding the first point (A) as
    an intermediate shortens some distances. In effect, you find that now you can
    go from B to D at a cost of 9, as shown in [Figure 17-7](chapter17.xhtml#fig17-7).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-7: When you try adding A as an intermediate point, you find a shorter
    distance between B and D.'
  prefs: []
  type: TYPE_NORMAL
- en: The second iteration checks whether adding B as an intermediate makes for shorter
    routes. You find that you can now go from A to C at a cost of 13 and from C to
    D (C to B and then B to D via A) at a cost of 18, as shown in [Figure 17-8](chapter17.xhtml#fig17-8).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-8: When you try adding B as an intermediate, you find two other shorter
    routes.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next iteration you’ll check whether adding C as an intermediate helps;
    then, you’ll try D, E, and so on. You keep iterating until all the nodes have
    been considered and the final result (check it out) provides all the distances
    between nodes (see [Figure 17-9](chapter17.xhtml#fig17-9)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-9: After trying out all possible intermediate points, you compute
    the final distances matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is short:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The n variable ❶ helps shorten the code; it’s just the number of nodes in the
    graph. The distance array of arrays ❷ includes the distances from every node to
    every other node. Initially, set all distances to +infinity ❸ and then correct
    ❹. The distance from a point to itself is zero ❺, and the distance from a point
    to another, if connected, is the edge’s length ❻. The distance array now has all
    distances with no intermediate points as described previously. The three nested
    loops systematically apply the dynamic programming calculation described earlier
    ❼, and if you find a better (smaller) distance ❽, update the table. In this case,
    you’re keeping only the last table; the values for the *k*th iteration replace
    those of the previous one, because you won’t need them any more. The final result
    ❾ is the table of distances between all pairs of points, as described.
  prefs: []
  type: TYPE_NORMAL
- en: 'What’s the runtime order of this algorithm? The three nested loops, each *O*(*v*),
    provide the answer: *O*(*v*³). This is steep, as mentioned, but it produces all
    distances among all pairs. For just the distance from one node to all the others,
    or even more specifically from one given node to another, you’ll see better algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: Bellman-Ford Algorithm
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Now consider a different problem: find the distance from a given node to all
    the others. The idea of the *Bellman-Ford algorithm* is to see whether you can
    find a better path between two nodes by following a given edge, and repeat this
    process until no more alternatives are possible. Start by considering paths that
    are one edge long, and then check whether a shorter path is available when using
    two edges, then three edges, then four, and so on. If a graph has *n* nodes, the
    longest path can have *n* – 1 edges, so that’s a limit for iterating.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s work with the same graph and calculate minimum distances from F to all
    the other nodes. (The algorithm works equally well with directed graphs, but you’re
    using an undirected one for simplicity.) The initial situation is shown in [Figure
    17-10](chapter17.xhtml#fig17-10). Without processing any edges (not taking any
    routes), only F can (trivially!) be reached from F, and you cannot reach other
    nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-10: Apply the Bellman-Ford algorithm to find the minimum distances
    from F to all other points.'
  prefs: []
  type: TYPE_NORMAL
- en: Assume that nodes are processed in alphabetical order. When you process the
    edges from A, B, or C, you cannot calculate distances because you don’t know how
    to reach those nodes. When you process the (F,D) edge, you are now able to reach
    node D, and you have the first step in the paths, as shown in [Figure 17-11](chapter17.xhtml#fig17-11).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-11: Processing nodes in order, the first other node you can reach
    from F is D.'
  prefs: []
  type: TYPE_NORMAL
- en: You now know that you can reach D with a cost of 3\. Now process the next edge,
    (F,G), and you can reach another node, as shown in [Figure 17-12](chapter17.xhtml#fig17-12).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-12: The other node you can reach from F is G; you’ll reprocess D
    at a later iteration.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can then process the edges out of G, because now you know that you can
    reach G. Processing edges (G,C) and (G,E) marks two other nodes as reachable.
    (Don’t forget: any paths or distances you find may change later if better alternatives
    appear.) [Figure 17-13](chapter17.xhtml#fig17-13) shows the new situation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-13: When processing G, which was reached from F, you can reach C
    and E as well.'
  prefs: []
  type: TYPE_NORMAL
- en: The first pass is done. So far, you know you can reach five of the seven nodes,
    and you have possible (but maybe not optimal) paths for each.
  prefs: []
  type: TYPE_NORMAL
- en: Now start a new pass. You still can’t do anything with edges out of A or B,
    because you still haven’t gotten to those nodes, but you can process edge (C,B)
    and add a new path, as shown in [Figure 17-14](chapter17.xhtml#fig17-14).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-14: A second iteration now finds that B is reachable from the previously
    reached C.'
  prefs: []
  type: TYPE_NORMAL
- en: The (C,E) and (C,G) edges don’t represent shorter distances, so you do nothing.
    (For example, you can go from F to E at a cost of 23; going through C would cost
    26, so it’s no good.) When considering the (D,A) and (D,E) edges, things get interesting.
    You can now reach A, and you find a better path to E through D (see [Figure 17-15](chapter17.xhtml#fig17-15)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-15: A second look at D finds a shorter path to E. The previous way
    was from F to G to E, which was longer than from F to D to E.'
  prefs: []
  type: TYPE_NORMAL
- en: The previous best path from F to E was through G, at a cost of 23, but now you
    find you can go through D at a cost of 10\. No more changes are possible, so start
    a third pass. One further enhancement is that it’s a shorter route to B by going
    through A than through E (see [Figure 17-16](chapter17.xhtml#fig17-16)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-16: A third pass finds a better way from A to B, but no further changes.'
  prefs: []
  type: TYPE_NORMAL
- en: The third pass doesn’t add any more changes, and further passes won’t either,
    so you’re done. You know the shortest paths from the starting point F to all other
    points, and you know what edges to follow to achieve that cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can code this algorithm as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Use a previous array ❶ to learn from which node you arrived at the corresponding
    node; if previous[j] is i, the shortest path from the start to j passed through
    i right before going to j. The distance array ❷ keeps track of the distances from
    the start to every node; initialize all distances to +infinity, except the distance
    from the start to itself ❸, which is obviously zero. In order to process all edges
    without having to go through the whole matrix, create an edges array ❹; iterating
    with this array will be faster. Now iterate n – 1 times ❺: for each edge ❻, see
    whether using it provides a shorter way between its two endpoints ❼; if so, update
    the distance to the second node ❽ and record from which node you came ❾. (Can
    you do better with fewer passes? See question 17.2.) The results of this algorithm
    are an array with distances and an array showing indirectly how to reach the start
    ❿ from any node.'
  prefs: []
  type: TYPE_NORMAL
- en: What’s the order of this algorithm? Given that the loop runs *O*(*v*) times
    and each time it goes through all edges, the result is *O*(*ve*). This is better
    than Floyd-Warshall’s algorithm, but it finds all distances from a single origin
    to all the rest. You can do even better, as you’ll see in a final algorithm for
    that problem.
  prefs: []
  type: TYPE_NORMAL
- en: Dijkstra’s Algorithm
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If you want to find the shortest path from one point to all others (or to a
    specific point in particular), Dijkstra’s algorithm is quite efficient. It proceeds
    by starting at the first point (considered to be *visited*, at distance zero from
    itself), which becomes the initial *current* point. All other points are considered
    to be *unvisited* and at distance +infinity. From then on, it does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 1. Studies all as yet unvisited neighbors of the current node, and if there’s
    a shorter path to the neighbor, it chooses that path and updates the distance
    to the unvisited node.
  prefs: []
  type: TYPE_NORMAL
- en: 2. After having processed all the unvisited neighbors of the current node, mark
    that node as visited, and you’re done with it.
  prefs: []
  type: TYPE_NORMAL
- en: 3. If any unvisited points remain, choose the one with the shortest distance,
    make it the current node, and repeat the process.
  prefs: []
  type: TYPE_NORMAL
- en: 4. The algorithm ends when no unvisited points remain (if you want the distances
    from the origin to all other points) or when the destination point has been marked
    as visited (if you just want that particular distance).
  prefs: []
  type: TYPE_NORMAL
- en: Consider an example and then the implementation. For simplicity, you’ll work
    with the same undirected graph as before, but Dijkstra’s algorithm works equally
    well with directed graphs. [Figure 17-17](chapter17.xhtml#fig17-17) shows the
    initial configuration, with the origin point marked as visited.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-17: The initial setup for Dijkstra’s algorithm: the distance from
    A to itself is zero, and distances from A to other nodes are set to +infinity.'
  prefs: []
  type: TYPE_NORMAL
- en: Considering adjacencies from the current point (A), you know you can reach B,
    D, and E (see [Figure 17-18](chapter17.xhtml#fig17-18)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-18: Considering the edges from A to its neighbors, you can tentatively
    update the distances to B, D, and E.'
  prefs: []
  type: TYPE_NORMAL
- en: You’ve updated the distances to those three nodes, but they’re strictly tentative
    at this point, as you may find better paths later—and you will, as there’s a shorter
    way from A to E, for example.
  prefs: []
  type: TYPE_NORMAL
- en: The next step marks B as the current point, because it’s the closest unvisited
    one (see [Figure 17-19](chapter17.xhtml#fig17-19)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-19: Repeat the procedure starting from B, the closest unvisited node,
    and find better distances to C and E.'
  prefs: []
  type: TYPE_NORMAL
- en: You found a way to C with a distance of 13, because B was at a distance of 4,
    and the (B,C) edge costs 9\. You also found a shorter way to E, so update those
    distances. Point B now is marked as visited, and you turn to D as the new current
    node (see [Figure 17-20](chapter17.xhtml#fig17-20)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-20: You now start from D, the next closest but not yet visited node,
    and find better distances to F and G.'
  prefs: []
  type: TYPE_NORMAL
- en: Working from D allows you to update the distances and paths to F and G. The
    distance to E wasn’t modified, because going through D would have required a distance
    of 12, and you already found a shorter path. Now, F becomes the current node,
    and the process will go quickly, because it allows only one path out, as shown
    in [Figure 17-21](chapter17.xhtml#fig17-21).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-21: Processing F finds a better way to G.'
  prefs: []
  type: TYPE_NORMAL
- en: You’ve updated the best (as of yet) path to G, which now is 21, going from A
    to D to F first. You’re close to finishing, and E is the next node to process
    (see [Figure 17-22](chapter17.xhtml#fig17-22)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-22: E is processed next and allows you to update distances to C and
    G.'
  prefs: []
  type: TYPE_NORMAL
- en: Going through E makes the distances to C and G shorter, so update them. The
    next steps choose C and then G, and you don’t need any further changes. [Figure
    17-23](chapter17.xhtml#fig17-23) shows the final result with the selected paths
    and calculated distances from A.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-23: When you’re done with all nodes, you get optimum distances from
    A to all other nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To achieve good performance, it’s important to be able to determine the next
    node (the one with shortest distance) to process quickly. A straightforward loop
    would be an *O*(*v*) algorithm, but you’ve already seen an appropriate structure
    for that: a heap. Using that structure allows you to find the next node to process
    in *O*(1) time, and updating the heap is then *O*(log *v*), which is better.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main algorithm is as follows, but you’ll look at a portion of it related
    to the heap later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The points array ❶ contains the distances from the starting point (from) to
    all others. The i attribute identifies the point; done marks whether you’ve finished
    processing it; dist is the distance, initialized to +infinity for all points except
    the initial; and prev shows from which point you arrived at the current one ❷.
    The index attribute requires explanation. As mentioned, you’ll be keeping the
    distances in a heap and updating them, which may cause them to bubble up. However,
    you need to know where each point is in the heap, and that’s what the index indicates.
    This way, whenever you update the distance for a point p you know that points[p].index
    is the corresponding place in the heap.
  prefs: []
  type: TYPE_NORMAL
- en: Push every point in the heap starting with from ❸ and update all the index values
    ❹. (Because there’s a single zero distance in the points array and all others
    are +infinity, you’ve created a heap without needing any comparisons.) While the
    heap isn’t empty ❺, you remove the top point ❻ and mark it as done and proceed
    to update the distances to all the nodes that it can reach ❼. If a distance gets
    updated with a lower value ❽, check whether it should bubble up in the heap. The
    final result ❾ is the updated points array with distances from the initial node
    to all others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now consider the heap code, directly based on what we saw in [Chapter 14](chapter14.xhtml):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The swap(...) function just exchanges two values in the heap ❶ and also updates
    the corresponding index attributes in the points array, so you can keep track
    of where each node is in the heap. The sinkDown(...) function ❷ works as you saw
    in [Chapter 14](chapter14.xhtml). Notice that you don’t compare the heap values
    ❸, but rather compare the distances from the points array using the heap values
    as indices. (In the sorting code in [Chapter 14](chapter14.xhtml), we directly
    compared the heap values.) The same change applies in the bubbleUp(...) function
    ❹ ❺.
  prefs: []
  type: TYPE_NORMAL
- en: What’s the performance of this algorithm? As is, each point is processed once,
    and for each point you check whether you need to update the distances to all the
    others, so it’s *O*(*v*²). You can enhance it by having a list of adjacent points,
    as with the adjacency list representation for graphs, and then the performance
    becomes *O*(*v* log *v*) because of the heap usage.
  prefs: []
  type: TYPE_NORMAL
- en: Sorting a Graph
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At the beginning of this chapter we mentioned some real-life applications of
    graphs, like tracking dependencies in code (modules that import from other modules)
    or project management (showing tasks that rely on the completion of other tasks).
    In that situation, we may want to find whether a certain ordering of nodes will
    make everything work out smoothly. Conversely, we may want to check whether code
    has circular dependencies or whether completing a given task will be impossible.
    We want to be able detect such issues with graphs.
  prefs: []
  type: TYPE_NORMAL
- en: 'This type of task is called *topological sorting*, and it implies that given
    a graph, we sort its nodes in order so that all links “go forward” and there’s
    never a link from a vertex to a previous node. We’ll consider two algorithms for
    such a sort: Kahn’s algorithm, which is based on a simple procedure involving
    counting, and Tarjan’s algorithm, which applies depth-first searching to produce
    the order we want in a backward fashion where the last vertices are output first.'
  prefs: []
  type: TYPE_NORMAL
- en: Kahn’s Algorithm
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Consider a basic argument: if a graph has topological ordering, there must
    be at least one node with no incoming edges, and *Kahn’s algorithm* is based on
    that. (This is similar to saying that in any set of numbers, there must be one
    that is less than the rest.) You can select each of these nodes with no problems.
    If you then discard all the edges that start from those nodes, you should be left
    with nodes that have no incoming edges, and you can repeat the procedure. If at
    some point you’ve still got nodes to consider but all have at least one incoming
    edge, no topological sort is possible.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 17-24](chapter17.xhtml#fig17-24) illustrates the procedure with the
    same directed graph we’ve been using for all the examples in this chapter. After
    first doing a count of incoming edges, the numbers in the nodes are the calculated
    counts.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-24: A graph is set up for topological sorting where the numbers show
    how many incoming edges are there at each point.'
  prefs: []
  type: TYPE_NORMAL
- en: Given that you found at least one node with zero incoming edges, you can proceed.
    Points E and F can be output in any order, and you then reduce the counts of the
    nodes that you can reach from those two points (see [Figure 17-25](chapter17.xhtml#fig17-25)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-25: Points E and F can be output because they had no incoming edges,
    and you “forget” the outgoing edges from those two points.'
  prefs: []
  type: TYPE_NORMAL
- en: Points E and F were output, which are in positions 0 and 1 of the output array.
    (The nodes in black show index values.) Again, you find at least one node with
    no incoming edges, so B is at position 2 of the output array, and you decrease
    the counts of nodes A and C (see [Figure 17-26](chapter17.xhtml#fig17-26)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-26: Point B now has no predecessors, so its output and edges are
    removed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now repeat the process: points A and C are output, reduce the counts, and you
    get to the situation shown in [Figure 17-27](chapter17.xhtml#fig17-27).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-27: Point A is next, then D, and G will be last.'
  prefs: []
  type: TYPE_NORMAL
- en: The last two steps output D first and then G. [Figure 17-28](chapter17.xhtml#fig17-28)
    shows the final status, and the topological order you want is E, F, B, A, C, D,
    and G.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-28: The final result, where the numbers show in which order the points
    were output.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can code the algorithm as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Put nodes to be processed in a queue ❶, and from there place them in the output
    sorted array ❷. The incoming array will count the number of incoming edges for
    every node ❸, adding 1 for every such edge. Every node with no incoming edges
    is pushed into the queue for processing ❹, and then you can start the sort itself.
    While there still are nodes to process ❺, you remove them from the queue ❻ and
    push them into the output list ❼. For every node you output ❽, discard its connections
    to other nodes, decreasing the incoming counts ❾. When there are no more nodes
    to process, if all were sorted, you succeeded ❿; otherwise, you failed. The remaining
    nodes have at least one incoming edge, which means no topological sort is possible.
  prefs: []
  type: TYPE_NORMAL
- en: Tarjan’s Algorithm
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We’ll apply a depth-first search algorithm for another way to produce a topological
    sort. The idea is to start *traveling* from a node, marking the way at each node
    you pass (Hansel and Gretel style) and seeing how far you can get before arriving
    at a dead end or returning to a node that you already marked, which means you
    found a cycle and no topological sort is possible. You can mark the nodes from
    which no more movement is possible as *done* and output them and then ignore them
    from then on. In this fashion, you’ll produce the topological sort in reverse
    order: you’ll output the last nodes in the sort first, and the first nodes will
    be last.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 17-29](chapter17.xhtml#fig17-29) shows an example with the same graph
    we’ve used throughout the chapter. Start at point A, mark it as *in progress*
    (in gray), and consider all the edges out of it. There’s only one. If in future
    steps you get back to node A and it’s gray, you’ll have found a cycle.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-29: The same graph as in the previous section set up for Tarjan’s
    algorithm. You started at A and reached D; A is grayed out.'
  prefs: []
  type: TYPE_NORMAL
- en: You’re now at point D, which hasn’t been visited. Mark it gray as well and check
    which nodes you can reach from it. In this case, you can reach only G (see [Figure
    17-30](chapter17.xhtml#fig17-30)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-30: After D, you reach G; D is grayed out.'
  prefs: []
  type: TYPE_NORMAL
- en: Repeat the process at G, and no edges come out of it, so mark it as *done* and
    output it. The sorted list starts as shown in [Figure 17-31](chapter17.xhtml#fig17-31).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-31: From G you can’t reach any other point, so output G to the sorted
    list.'
  prefs: []
  type: TYPE_NORMAL
- en: Having dealt with G, you can mark D as *done* (and output it) and then do the
    same with A (see [Figure 17-32](chapter17.xhtml#fig17-32)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-32: D has no further connections to other nodes, so it may be output,
    and then A is output too.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When you’re done with A, start from B. The link from B to A goes to a node
    marked *done*, so you ignore it. The link from B to C needs processing, though:
    B is marked *in progress*, and you go to C (see [Figure 17-33](chapter17.xhtml#fig17-33)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-33: Starting at B, you can reach only one point that has not yet
    been output: C.'
  prefs: []
  type: TYPE_NORMAL
- en: Mark C as *in progress*, but its only edge goes to a node marked *done* (G),
    so mark C as *done* and add it to the output. After that, you’re done with B as
    well, which also is output (see [Figure 17-34](chapter17.xhtml#fig17-34)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-34: C is linked only to an already output point, so you can output
    C and, after that, output B.'
  prefs: []
  type: TYPE_NORMAL
- en: The final steps are similar. From E all the links lead to nodes marked as *done*,
    so E becomes marked as *done* and is output; the same happens to F, and you’re
    finished, having visited all nodes and produced a topological sort, as shown in
    [Figure 17-35](chapter17.xhtml#fig17-35).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-35: When all points have been output, the algorithm ends.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this algorithm follows. The *in-progress* nodes are marked with
    a 1 (a temporary mark) and the *done* nodes are marked with a 2 (a final mark):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The marks array ❶ keeps track of visited and unvisited nodes. A 0 means the
    node hasn’t been visited yet. A 1 means it was visited and you’re going through
    all its reachable nodes, and a 2 means that the node has been dealt with and output
    already. The sorted array ❷ gets the output of the algorithm. You define a recursive
    function ❸ to visit all nodes that a p starting node can reach. If the node was
    marked with a 1 ❹, it means that, when starting from there, you eventually returned
    to it. In other words, there’s a cycle, so no topological sort is possible. If
    the node is marked with a 0 ❺, temporarily mark it with a 1 and visit all the
    unvisited nodes that are reachable from it ❻; skip visiting any nodes marked with
    2 ❼ because those were already analyzed. After all the visiting is finished, change
    the 1 to 2 ❽ and output the current node p ❾; use unshift() to get the right order.
    To produce the topological sort ❿, all you have to do is start from every possible
    node and apply the visiting logic.
  prefs: []
  type: TYPE_NORMAL
- en: What’s the performance of this algorithm? Each node is visited once, and all
    its links are processed, but for each node, it checks the whole row for possible
    links to traverse, making this implementation *O*(*v*²). The algorithm would benefit
    from an adjacency list representation, because then you would be able to process
    the edges from a node directly, producing *O*(*ve*).
  prefs: []
  type: TYPE_NORMAL
- en: Detecting Cycles
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another question to consider is whether a graph includes any cycles. (In other
    words, is the graph a tree or a forest or not?) For example, when programming,
    if there’s a cycle in a list of dependencies among modules, something is seriously
    wrong! A cycle-detection algorithm just needs to check whether it can find at
    least one cycle in a given graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, we’ve already seen an algorithm that does this type of detection:
    Tarjan’s topological sort includes the logic to detect when a cycle is found,
    so we’ve already got what we need. The following code is directly extracted from
    that algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: All the code is the same; the only differences here are that you don’t define
    a sorted array for the output ❶. You obviously don’t add anything when marking
    a node as totally visited ❷, and you return a boolean value instead of an array
    or null ❸.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting Connectivity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now consider a different problem: How can you determine whether a given graph
    is fully connected? An undirected graph is connected if there’s a path between
    every pair of points in the graph; there’s no point you can’t reach from any other
    point. (A border case is that a graph with only one vertex is also considered
    to be connected.) If a graph doesn’t satisfy this condition, we can split it into
    two or more connected subgraphs.'
  prefs: []
  type: TYPE_NORMAL
- en: Several algorithms can detect whether a given graph is connected; we’ll consider
    two here. One algorithm introduces another data structure that allows merging
    sets, and the other uses a recursive traversal of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: '#### Detecting Connectivity with Sets'
  prefs: []
  type: TYPE_NORMAL
- en: There’s a rather simple way to find how many connected parts a graph has. Start
    by forming different sets, each with a single vertex. Then, go through all the
    edges in the graph, and if an edge links vertices that appear in different sets,
    join them so that they form a new, larger set. After going through all the edges,
    if you’re left with a single set, the graph was connected; if you’re left with
    several sets, the graph was unconnected.
  prefs: []
  type: TYPE_NORMAL
- en: The question is how to implement these sets. You need to be able to determine
    whether any two points are in the same set and be able to join two sets. There’s
    an efficient way of doing this by working with a forest of trees, as we explored
    in [Chapter 13](chapter13.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: Consider how this concept works. Each set is represented by an *upward* tree
    with pointers that go up from the leaves to the root (the opposite of what you
    did in previous chapters). The leaves of the tree are its elements, and intermediate
    nodes are added as needed. To see whether two values are in the same set, follow
    the path up to the root from each leaf. If you reach the same root, the values
    are in the same set. Finally, to join two sets, just add a new root and make the
    roots of the two sets point to it. [Figure 17-36](chapter17.xhtml#fig17-36) shows
    an initial setup with six values, each in a separate set. Note that all pointers
    are implied to go up, which is a big difference from previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-36: Start with each node in its individual tree.'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to check whether, say, D and E are in the same set, follow the pointers
    up, and upon arriving at different roots, you can conclude that they aren’t.
  prefs: []
  type: TYPE_NORMAL
- en: To make them part of a single set, just add a new root, and you get the situation
    shown in [Figure 17-37](chapter17.xhtml#fig17-37).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-37: Putting D and E in the same set requires adding a new root; now
    D and E are in the same tree.'
  prefs: []
  type: TYPE_NORMAL
- en: If you now check whether D and E are in the same set, the answer is yes, because
    following pointers up, you’d arrive at the same root. If you ask whether F and
    D (or F and E) are in the same set, the answer is no, and joining the sets produces
    the situation shown in [Figure 17-38](chapter17.xhtml#fig17-38).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-38: Adding F to the previous (D,E) set again adds a new root, and
    now the three original trees are joined.'
  prefs: []
  type: TYPE_NORMAL
- en: You can handle all of this with simple pointer manipulation and end up with
    an upside-down forest. Joining A with C and then A with E produces a new configuration
    (see [Figure 17-39](chapter17.xhtml#fig17-39)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-39: In this final scheme, you find that (A,C,D,E,F) are a set and
    (B) is a separate set.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Figure 17-39](chapter17.xhtml#fig17-39), you have only two sets: a singleton
    (with just B) and another set that contains all the other values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The algorithm is short:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Start by defining all groups with just a single element ❶, and the count variable
    tracks how many groups exist at any moment ❷. The findParent(...) auxiliary function
    goes up from each vertex to find the root of its group ❸. The rest is straightforward:
    go through all edges ❹ and check whether both endpoints of edges ❺ are in the
    same group; if not ❻, join the groups by creating a new, common root for both
    trees and decrease the group count by one ❼. After processing all the edges, if
    you’re left with a single group ❽, the graph was connected. If you want to know
    how many subgraphs it has, you could check the count instead.'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting Connectivity with Searches
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The second algorithm we’ll consider is based on starting from any point and
    applying a systematic, recursive search. Check which points you can reach, and
    then which points you can reach from those, and so on, until you’ve considered
    all the edges. Every time you start visiting from a certain point, mark it as
    *visited* to avoid trying it again.
  prefs: []
  type: TYPE_NORMAL
- en: Given the same graph you’ve been using, shown in [Figure 17-40](chapter17.xhtml#fig17-40),
    and arbitrarily starting at A, which would be the first node to visit?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-40: To check connectivity, start at any point, in this case A, and
    mark it.'
  prefs: []
  type: TYPE_NORMAL
- en: From A, you reach B, D, and E, and none of them have been visited already. Mark
    them and start searching from B, as shown in [Figure 17-41](chapter17.xhtml#fig17-41).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-41: From A you can reach unmarked points B, D, and E, which you mark.'
  prefs: []
  type: TYPE_NORMAL
- en: From B, you can reach A or E, but those are already marked as visited, so just
    add C to your search (see [Figure 17-42](chapter17.xhtml#fig17-42)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-42: From B you can add the still-unmarked C, and from D you add the
    unmarked F and G.'
  prefs: []
  type: TYPE_NORMAL
- en: From D, you can reach A, E, F, and G, but A and E are already marked, so just
    add F and G to the process (see [Figure 17-43](chapter17.xhtml#fig17-43)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-43.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-43: All points have been marked, so the graph is connected.'
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the algorithm is quick, because no unmarked nodes remain to be reached
    from E, C, F, or G (in the order you checked them), so you’re done, and since
    all vertices ended up marked, the graph was connected. If there had been a separate
    subgraph, you wouldn’t have been able to reach it, so its nodes would have been
    left unmarked and the algorithm would have returned false.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also do the search in depth-first style, which is actually simpler
    to code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Start by marking all points as unvisited ❶. The auxiliary visit(...) recursive
    function ❷ does the search. Given a point, it goes through all of its outgoing
    edges ❸. If it finds an unvisited point ❹, it marks it ❺ and visits it ❻. To run
    the algorithm, start by marking any point (the first in this case) as visited
    ❼, and call the visit function ❽ to do the search. If you finish the algorithm
    with every point marked as visited ❾, you’ve succeeded.
  prefs: []
  type: TYPE_NORMAL
- en: Finding a Minimum Spanning Tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This problem applies to weighted undirected graphs. Imagine we want to connect
    people to the electrical grid or some other similar service and we know the cost
    of linking a given pair of points together. We don’t need to build *all* possible
    connections between points; rather, we want to choose a set that, at minimum cost,
    allows all the vertices to connect to each other. Several algorithms solve this
    problem, and we’ll consider the two best known here: *Prim’s algorithm* and *Kruskal’s
    algorithm*. If those algorithms are applied to connected graphs, the output will
    be a tree linking all of its nodes. If a graph is not connected, we’ll find a
    forest of trees instead for each independent group of nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: '#### Prim’s Algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: 'The description for *Prim’s algorithm* is simple: to build the tree, start
    with any node and keep adding the closest node (meaning, minimum link cost) not
    yet connected to the tree until no more nodes are left. It can be proven that
    this will produce the desired minimum tree, but we won’t go into that proof here.'
  prefs: []
  type: TYPE_NORMAL
- en: Start with the same undirected graph we’ve been using (see [Figure 17-44](chapter17.xhtml#fig17-44))
    and arbitrarily choose A as the starting node.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-44: Prim’s algorithm starts by choosing any node. In this case, start
    with A.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, all of the points still aren’t selected, so choose the closest one, which
    is B in this case (see [Figure 17-45](chapter17.xhtml#fig17-45)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-45.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-45: Out of all the points adjacent to A, choose the closest, which
    is B.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ve got two nodes in the spanning tree. Repeat the selection: the closest
    point to either A or B not yet selected is D, so add that one (see [Figure 17-46](chapter17.xhtml#fig17-46)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-46.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-46: Out of the points adjacent to A or B, you again choose the closest,
    which is D.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The upcoming steps are easy to predict: first, add F (which is only three units
    away from the selected nodes), then E, C, and finally G, for a total cost of 30
    units, as shown in [Figure 17-47](chapter17.xhtml#fig17-47).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-47.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-47: After finishing with all nodes, you get a spanning tree.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Coding this is straightforward. In order to know which is the closest remaining
    unchosen point, you again use a heap. The implementation is a tad different: this
    time, you’ll have objects in the heap with attributes from (a point), to (the
    closest already selected point), and dist (the distance to the closest point,
    which is the length of the edge between those two points). First explore the heap
    algorithms, which were coded iteratively instead of recursively just for variety:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: When bubbling up a value, check whether you’re not already at the top ❶. If
    not, calculate the position of its parent and compare distances; if the parent
    is lower ❷, you’re done. If not, exchange heap positions ❸ and repeat the procedure
    at the parent’s position ❹. To sink down a value, set up an endless loop ❺ that
    exits when the value cannot sink any lower ❻ because it’s smaller than its children.
    If the value has to sink down, do an exchange ❼ and loop again at the child’s
    position ❽.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for Prim’s algorithm is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Start by setting up the newGraph matrix for the output graph ❶ and the heap
    with all points in it: the from attribute is the point itself, the to attribute
    is the closest already selected point, and the dist attribute is the minimum distance
    from the point to an already selected point of the spanning tree ❷. While the
    heap isn’t empty (implying you haven’t yet considered all vertices), consider
    the top ❸, which is the closest point to the already chosen ones that hasn’t been
    chosen itself yet. The path linking points from ❹ and to ❺ corresponds to the
    shortest pending distance, so add it to newGraph ❻. Then pop the node from the
    heap ❼ and proceed to adjust the distances between the from point and all the
    remaining heap points ❽. Then take each heap element ❾ and consider the distance
    from it to the from point; if there’s a shorter (cheaper) edge ❿, record the edge
    that allows this better path and the corresponding distance and make the node
    bubble up if needed. (So the heap points will always have the shortest distance
    from them to the already chosen points.) When the heap is empty, you’ll have the
    spanning tree in the newGraph matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: Kruskal’s Algorithm
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Kruskal’s algorithm* also finds the minimum spanning tree for an undirected
    graph. Instead of adding points one at a time as Prim’s does, this algorithm works
    by adding edges to an initially empty graph. The idea is to sort the edges in
    ascending order and attempt to add each edge unless it would cause a cycle. (We
    won’t give the proof that this algorithm is correct either, but rest assured it
    can be done.) How do we detect cycles? Initially, you have all the points in separate,
    disjointed sets, and every time you add an edge linking two nodes, join the corresponding
    sets (it’s similar to the process in the section “Detecting Connectivity with
    Sets” on [page 454](chapter17.xhtml#pg_454)). Never add an edge whose extremes
    are both in the same set.'
  prefs: []
  type: TYPE_NORMAL
- en: Now explore how the algorithm works with the same example graph (see [Figure
    17-48](chapter17.xhtml#fig17-48)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-48.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-48: The same graph used for Prim’s algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: Add edges one at the time, starting with the lowest, so the first step adds
    the (C,E) edge; now points C and E are in the same set, as shown in [Figure 17-49](chapter17.xhtml#fig17-49).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-49.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-49: Add the smallest edge (C,E) to start.'
  prefs: []
  type: TYPE_NORMAL
- en: The next two steps add edges (D,F) and (A,B); no cycles occur anywhere, as shown
    in [Figure 17-50](chapter17.xhtml#fig17-50).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-50.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-50: Keep adding edges, in ascending size, if they do not create cycles.
    First (D,F) was added and then (A,B).'
  prefs: []
  type: TYPE_NORMAL
- en: The next steps add (A,D), so A, B, D, and F all end up belonging to the same
    set, and then add (B,E), which makes a big set with all points from A to F (see
    [Figure 17-51](chapter17.xhtml#fig17-51)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-51.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-51: Repeating the procedure now adds (A,D).'
  prefs: []
  type: TYPE_NORMAL
- en: Now things get interesting! The next edge in order is (D,E), but D and E already
    are in the same set, so don’t add that edge. The next step adds (E,G), and you
    get the final tree, as shown in [Figure 17-52](chapter17.xhtml#fig17-52).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-52.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-52: You should add (D,E), but it would create a cycle, so skip it
    and add (E,G) instead.'
  prefs: []
  type: TYPE_NORMAL
- en: Future steps won’t add anything, because the edges will always link points that
    are already in the same set, so you’ve got your spanning tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kruskal’s algorithm is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Start by creating an empty matrix for the new tree ❶. Then generate a list
    of all edges in the graph ❷ and sort it ❸ with the simplest method, which is JavaScript’s
    own. (For a better way, check out question 17.8.) You now need to initialize all
    disjointed sets ❹, as you did earlier when detecting connectivity. The groups
    array will have a pointer to the root of each set, all of which will start with
    a single element. You’ll use an iterative version of the earlier recursive findParent(...)
    function ❺ to find to which set a node belongs. The rest of the algorithm is as
    follows: go through the sorted list of edges ❻, and for each one, find the parents
    of both of its extremes ❼. If they don’t match ❽, join both sets by creating a
    new root ❾ and add the edge to the output graph, which you return at the end ❿.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The performance of the algorithm can be shown to be *O*(*e* log *e*), basically
    because you have to sort all the edges and then go through the list possibly joining
    sets, which also produces the same result. The only disadvantage in this implementation
    is that getting the list of the nodes is *O*(*v*²) due to having to go through
    the whole matrix, but you can enhance it if you adopt another representation for
    the graph using adjacency lists, as we’ve seen.  ### Summary'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter introduced the concept of graphs. We considered representations
    for them and studied many algorithms for common requirements, such as finding
    paths or distances, sorting nodes, detecting cycles, and minimizing costs. These
    algorithms have also benefited from previous algorithms (like sorting and searching)
    and data structures (heaps, bitmaps, trees, forests, and lists), providing a way
    to apply the previous knowledge you’ve gained in various ways.
  prefs: []
  type: TYPE_NORMAL
- en: In the next and final chapter of the book, we’ll move on to specific considerations
    for data structures that are meant for a fully functional programming style of
    work, which entails some advantages but also some challenging disadvantages.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**17.1  Where’s the Path?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Floyd-Warshall’s algorithm finds the shortest distances between every pair
    of points, but what do you do if you also want to know which path to take? Modify
    the algorithm so that finding paths is simple. Hint: whenever you find that going
    from *i* to *j* is better by passing through *k*, make a note so that later, when
    trying to find the actual path, you’ll know to go to *k*.'
  prefs: []
  type: TYPE_NORMAL
- en: '**17.2  Stop Searching Sooner**'
  prefs: []
  type: TYPE_NORMAL
- en: 'When considering the Bellman-Ford algorithm, we mentioned that a certain number
    of passes ensured finding the shortest paths, but can you do better? Hint: in
    the example we showed in that section, fewer passes were actually needed.'
  prefs: []
  type: TYPE_NORMAL
- en: '**17.3  Just One Will Do**'
  prefs: []
  type: TYPE_NORMAL
- en: How would you modify Dijkstra’s algorithm if you care only about finding the
    shortest path to a single point?
  prefs: []
  type: TYPE_NORMAL
- en: '**17.4  The Wrong Way**'
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you take a directed graph, reverse all of its edges, and then apply
    Kahn’s topological sort algorithm to it. What will be the output of this algorithm?
  prefs: []
  type: TYPE_NORMAL
- en: '**17.5  Joining Sets Faster**'
  prefs: []
  type: TYPE_NORMAL
- en: When joining two distinct sets in the section “Detecting Connectivity with Sets”
    on page 454, you always add a new root, but doing so isn’t necessary, because
    you could just have one root point at the other one. Consider adding a size attribute
    in each root (with the number of nodes in the corresponding subtree) and join
    the smallest tree as a subtree of the largest one. Can you implement these changes?
  prefs: []
  type: TYPE_NORMAL
- en: '**17.6  Take a Shortcut**'
  prefs: []
  type: TYPE_NORMAL
- en: When joining sets, doing a little work up-front can save time later. Look again
    at [Figure 17-39](chapter17.xhtml#fig17-39) from the section “Detecting Connectivity
    with Sets” on page 454. Suppose you want to know whether C and D are in the same
    group. You would need to walk from both nodes up to the root before finding the
    answer. However, if you are later asked again about C or D, you’d have to redo
    the path, unless you modify some links, as shown in [Figure 17-53](chapter17.xhtml#fig17-53).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure17-53.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17-53: An optimized algorithm for joining sets'
  prefs: []
  type: TYPE_NORMAL
- en: Three links were changed to point to the root directly, so you can get there
    more quickly. (From C or D, it’s just one step to the root, and from E, it’s one
    step shorter than before.) Make a change in the findParent(...) function so it
    creates “shortcut” paths that’ll make future processes faster.
  prefs: []
  type: TYPE_NORMAL
- en: '**17.7  A Spanning Tree for a Tree?**'
  prefs: []
  type: TYPE_NORMAL
- en: What happens if you apply a spanning tree algorithm to a tree?
  prefs: []
  type: TYPE_NORMAL
- en: '**17.8  A Heap of Edges**'
  prefs: []
  type: TYPE_NORMAL
- en: Can you replace JavaScript’s sort with heapsort, quicksort, or any other method
    discussed in the book?
  prefs: []
  type: TYPE_NORMAL
