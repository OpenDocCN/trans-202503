["```\npsql -d `database_name` -U `user_name`\n```", "```\npsql -d analysis -U postgres\n```", "```\npsql -d analysis -U postgres -h example.com\n```", "```\npsql (13.3)\nType \"help\" for help.\n\nanalysis=#\n```", "```\nanalysis=# **CREATE DATABASE test;**\n```", "```\nanalysis=# **\\c test**\n```", "```\nYou are now connected to database \"test\" as user \"postgres\".\ntest=#\n```", "```\nanalysis-# **\\c test anthony**\n```", "```\nYou are now connected to database \"test\" as user \"anthony\".\ntest=#\n```", "```\n`hostname`:`port`:`database`:`username`:`password`\n```", "```\nlocalhost:5432:analysis:postgres:`password`\n```", "```\nlocalhost:5432:*:postgres:`password`\n```", "```\nanalysis=# **SELECT county_name FROM us_counties_pop_est_2019 ORDER BY county_name LIMIT 3;**\n```", "```\n county_name\n------------------\n Abbeville County\n Acadia Parish\n Accomack County\n(3 rows)\n\nanalysis=#\n```", "```\nanalysis=# SELECT county_name\nanalysis-# FROM us_counties_pop_est_2019\nanalysis-# ORDER BY county_name\nanalysis-# LIMIT 3;\n```", "```\nanalysis=# CREATE TABLE wineries (\nanalysis(# id bigint,\nanalysis(# winery_name text\nanalysis(# );\nCREATE TABLE\n```", "```\nanalysis=# **SELECT county_name FROM us_counties_pop_est_2019 ORDER BY county_name;**\n\n            county_name\n-----------------------------------\n Abbeville County\n Acadia Parish\n Accomack County\n Ada County\n Adair County\n Adair County\n Adair County\n Adair County\n Adams County\n Adams County\n Adams County\n Adams County\n-- More --\n```", "```\n `--snip--`\n York County\n York County\n York County\n York County\n Young County\n Yuba County\n Yukon-Koyukuk Census Area\n Yuma County\n Yuma County\n Zapata County\n Zavala County\n Ziebach County\n(3142 rows)\n\nanalysis=#\n```", "```\nanalysis=# SELECT * FROM grades ORDER BY student_id, course_id;\n student_id | course_id |      course       | grade\n------------+-----------+-------------------+-------\n          1 |         1 | Biology 2         | C\n          1 |         2 | English 11B       | D\n          1 |         3 | World History 11B | C\n          1 |         4 | Trig 2            | B\n(4 rows)\n```", "```\nanalysis=# SELECT * FROM grades ORDER BY student_id, course_id;\n-[ RECORD 1 ]-----------------\nstudent_id | 1\ncourse_id  | 1\ncourse     | Biology 2\ngrade      | C\n-[ RECORD 2 ]-----------------\nstudent_id | 1\ncourse_id  | 2\ncourse     | English 11B\ngrade      | D\n-[ RECORD 3 ]-----------------\nstudent_id | 1\ncourse_id  | 3\ncourse     | World History 11B\ngrade      | C\n-[ RECORD 4 ]-----------------\nstudent_id | 1\ncourse_id  | 4\ncourse     | Trig 2\ngrade      | B\n```", "```` ```  List of relations   Schema |                  Name                  | Type  |   Owner  --------+----------------------------------------+-------+-----------   public | acs_2014_2018_stats                    | table | anthony   public | cbp_naics_72_establishments            | table | anthony   public | char_data_types                        | table | anthony   public | check_constraint_example               | table | anthony   public | crime_reports                          | table | anthony   `--snip--` ```    This result lists all tables in the current database alphabetically.    You can filter the output by adding a pattern the database object name must match. For example, use `\\dt us*` to show only tables whose names begin with `us` (the asterisk acts as a wildcard). The results should look like this:    ```  List of relations   Schema |           Name           | Type  |   Owner  --------+--------------------------+-------+-----------   public | us_counties_2019_shp     | table | anthony   public | us_counties_2019_top10   | table | anthony   public | us_counties_pop_est_2010 | table | anthony   public | us_counties_pop_est_2019 | table | anthony   public | us_exports               | table | anthony ```    [Table 18-4](#table18-4) shows several additional commands you might find helpful, including `\\l`, which lists the databases on your server. Adding a plus sign to each command, as in `\\dt+`, adds more information to the output, including object sizes.      Table 18-4: Example of `psql` `\\d` Commands       | **Command** | **Displays** | | --- | --- | | `\\d [pattern]` | Columns, data types, plus other information on objects | | `\\di [pattern]` | Indexes and their associated tables | | `\\dt [pattern]` | Tables and the account that owns them | | `\\du [pattern]` | User accounts and their attributes | | `\\dv [pattern]` | Views and the account that owns them | | `\\dx [pattern]` | Installed extensions | | `\\l [pattern]` | Databases |    The entire list of commands is available in the PostgreSQL documentation at [https://www.postgresql.org/docs/current/app-psql.html](https://www.postgresql.org/docs/current/app-psql.html), or you can see details by using the `\\?` command noted earlier.    ### Importing, Exporting, and Using Files    In this section, we’ll explore how to use `psql` to import and export data from the command line, which can be necessary when you’re connected to remote servers, such as Amazon Web Services instances of PostgreSQL. We’ll also use `psql` to read and execute SQL commands stored in a file and learn the syntax for sending `psql` output to a file.    #### Using \\copy for Import and Export    In Chapter 5, you learned how to use the PostgreSQL `COPY` command to import and export data. It’s a straightforward process, but it has one significant limitation: the file you’re importing or exporting must be on the same machine as the PostgreSQL server. That’s fine if you’re working on your local machine, as you’ve been doing with these exercises. But if you’re connecting to a database on a remote computer, you might not have access to its file system. You can get around this restriction by using the `\\copy` meta-command in `psql`.    The `\\copy` meta-command works just like the PostgreSQL `COPY`, except when you execute it at the `psql` prompt, it will route data from your machine to the server you’re connected to, whether local or remote. We won’t actually connect to a remote server to try this since it’s rare to find a public remote server we could connect to, but you can still learn the syntax by using the commands on our local `analysis` database.    In [Listing 18-7](#listing18-7), at the `psql` prompt we use a `DELETE` statement to remove all the rows from the small `state_regions` table you created in Chapter 10 and then import data using `\\copy`. You’ll need to change the file path to match the location of the file on your computer.    ``` analysis=# DELETE FROM state_regions;  DELETE 56  analysis=# \\copy state_regions FROM '`C:\\YourDirectory\\`state_regions.csv' WITH (FORMAT CSV, HEADER);  COPY 56 ```    Listing 18-7: Importing data using `\\copy`    Next, to import the data, we use `\\copy` with the same syntax used with PostgreSQL `COPY`, including a `FROM` clause with the file path on your machine, and a `WITH` clause that specifies the file is a CSV and has a header row. When you execute the statement, the server should respond with `COPY 56`, letting you know the rows have been successfully imported.    If you’re connected to a remote server via `psql`, you would use the same `\\copy` syntax, and the command would route your local file to the remote server for importing. In this example, we used `\\copy FROM` to import a file. We could also use `\\copy TO` for exporting. Let’s look at an alternate way to import or export data (or run other SQL commands) via `psql`.    #### Passing SQL Commands to psql    By placing a command in quotes after the `-c` argument, we can send it to our connected server, local or remote. The command can be a single SQL statement, multiple SQL statements separated by semicolons, or a meta-command. This can allow us to run `psql`, connect to a server, and execute a command in a single command line statement—handy if we want to incorporate `psql` statements into shell scripts to automate tasks.    For example, we can import data to the `state_regions` table with the statement in [Listing 18-8](#listing18-8), which must be entered on one line at your command prompt (and not inside `psql`).    ``` psql -d analysis -U postgres -c1 'COPY state_regions FROM STDIN2 WITH (FORMAT CSV, HEADER);' <3 `C:\\YourDirectory\\`state_regions.csv ```    Listing 18-8: Importing data using `psql` with `COPY`    To try it, you’ll need to first run `DELETE FROM state_regions;` inside `psql` to clear the table. Then exit `psql` by typing the meta-command `\\q`.    At your command prompt, enter the statement in [Listing 18-8](#listing18-8). We first use `psql` and the `-d` and `-U` commands to connect to your `analysis` database. Then comes the `-c` command 1, which we follow with the PostgreSQL statement for importing the data. The statement is similar to `COPY` statements we’ve used with one exception: after `FROM`, we use the keyword `STDIN` 2 instead of the complete file path and filename. `STDIN` means “standard input,” which is a stream of input data that can come from a device, a keyboard, or in this case the file *state_regions.csv*, which we direct 3 to `psql` using the less-than (`<`) symbol. You’ll need to supply the full path to the file.    Running this entire command at your command prompt should import the CSV file and generate the message `COPY 56`.    #### Saving Query Output to a File    It’s sometimes helpful to save the query results and messages generated during a `psql` session to a file, such as to keep a history of your work or to use the output in a spreadsheet or other application. To send query output to a file, you can use the `\\o` meta-command along with the full path and name of an output file that `psql` will create.    For example, in [Listing 18-9](#listing18-9) we change the `psql` format style from a table to CSV and then output query results directly to a file.    ``` 1 analysis=# \\pset format csv  Output format is csv.    analysis=# SELECT * FROM grades ORDER BY student_id, course_id;  2 student_id,course_id,course,grade  1,1,Biology 2,F  1,2,English 11B,D  1,3,World History 11B,C  1,4,Trig 2,B    3 analysis=# \\o '`C:/YourDirectory/`query_output.csv'    analysis=# SELECT * FROM grades ORDER BY student_id, course_id;  4 analysis=# ```    Listing 18-9: Saving query output to a file    First, we set the output format 1 using the meta-command `\\pset format csv`. When you run a simple `SELECT` on the `grades` table, the output 2 should return as values separated by commas. Next, to send that data to a file the next time you run the query, use the `\\o` meta-command and then provide a complete path to a file called `query_output.csv` 3. When you run the `SELECT` query again, there should be no output to the screen 4. Instead, you’ll find a file with the contents of the query in the directory specified at 3.    Note that every time you run a query from this point, the output is appended to the same file specified after the `\\o` (for *output*) command. To stop saving output to that file, you can either specify a new file or enter `\\o` with no filename to resume having results output to the screen.    #### Reading and Executing SQL Stored in a File    To run SQL stored in a text file, you execute `psql` on the command line and supply the filename after an `-f` (for file) argument. This syntax lets you quickly run a query or table update from the command line or in conjunction with a system scheduler to run a job at regular intervals.    Let’s say you saved the `SELECT` query from [Listing 18-9](#listing18-9) in a file called *display-grades.sql*. To run the saved query, use the following `psql` syntax at your command line:    ``` psql -d analysis -U postgres -f `C:\\YourDirectory\\`display-grades.sql ```    When you press enter, `psql` should launch, run the stored query in the file, display the results, and exit. For repetitive tasks, this workflow can save considerable time because you avoid launching pgAdmin or rewriting a query. You also can stack multiple queries in the file so they run in succession, which, for example, you might do if you want to run several updates on your database.    ## Additional Command Line Utilities to Expedite Tasks    PostgreSQL also has its own set of command line utilities that you can enter in your command line interface without launching `psql`. A listing is available at [https://www.postgresql.org/docs/current/reference-client.html](https://www.postgresql.org/docs/current/reference-client.html), and I’ll explain several in Chapter 19 that are specific to database maintenance. Here I’ll cover two that are particularly useful: creating a database at the command line with the `createdb` utility and loading shapefiles into a PostGIS database via the `shp2pgsql` utility.    ### Adding a Database with createdb    Earlier in the chapter, you used `CREATE DATABASE` to add the database `test` to your PostgreSQL server. We can achieve the same thing using `createdb` at the command line. For example, to create a new database on your server named `box_office`, run the following at your command line:    ``` createdb -U postgres -e box_office ```    The `-U` argument tells the command to connect to the PostgreSQL server using the `postgres` account. The `-e` argument (for *echo*) prints the commands generated by `createdb` as output. Running this command creates the database and prints output to the screen ending with `CREATE DATABASE box_office;`. You can then connect to the new database via `psql` using the following line:    ``` psql -d box_office -U postgres ```    The `createdb` command accepts arguments to connect to a remote server (just like `psql` does) and to set options for the new database. A full list of arguments is available at[https://www.postgresql.org/docs/current/app-createdb.html](https://www.postgresql.org/docs/current/app-createdb.html). Again, the `createdb` command is a time-saver that comes in handy when you don’t have access to a GUI.    ### Loading Shapefiles with shp2pgsql    In Chapter 15, you learned about shapefiles, which contain data describing spatial objects. On Windows and some Linux distributions, you can import shapefiles into a PostGIS-enabled database using the Shapefile Import/Export Manager GUI tool (generally) included with PostGIS. However, the Shapefile Import/Export Manager is not always included with PostGIS on macOS or some flavors of Linux. In those cases (or if you’d rather work at the command line), you can import a shapefile using the PostGIS command line tool `shp2pgsql`.    To import a shapefile into a new table from the command line, use the following syntax:    ``` shp2pgsql -I -s `SRID` -W `encoding shapefile_name` `table_name` | psql -d `database` -U `user` ```    A lot is happening in this single line. Here’s a breakdown of the arguments (if you skipped Chapter 15, you might need to review it now):    1.  `-I` Uses GiST to add an index on the new table’s geometry column. 2.  `-s` Lets you specify an SRID for the geometric data. 3.  `-W` Lets you specify encoding. (Recall that we used `Latin1` for census shapefiles.) 4.  `shapefile_name` The name (including full path) of the file ending with the *.shp* extension. 5.  `table_name` The name of the table the shapefile is imported to.    Following these arguments, you place a pipe symbol (`|`) to direct the output of `shp2pgsql` to `psql`, which has the arguments for naming the database and user. For example, to load the *tl_2019_us_county.shp* shapefile into a `us_counties_2019_shp` table in the `analysis` database, you can run the following command. Note that although this command wraps onto two lines here, it should be entered as one line in the command line:    ``` shp2pgsql -I -s 4269 -W Latin1 tl_2019_us_county.shp us_counties_2019_shp | psql -d analysis -U postgres ```    The server should respond with a number of SQL `INSERT` statements before creating the index and returning you to the command line. It might take some time to construct the entire set of arguments the first time around, but after you’ve done one, subsequent imports should take less time. You can simply substitute file and table names into the syntax you already wrote.    ## Wrapping Up    Feeling mysterious and powerful yet? Indeed, when you delve into a command line interface and make the computer do your bidding using text commands, you enter a world of computing that resembles a sci-fi movie sequence. Not only does working from the command line save you time, it also helps you overcome barriers you might hit when working in environments that don’t support graphical tools. In this chapter, you learned the basics of working with the command line plus PostgreSQL specifics. You discovered your operating system’s command line application and set it up to work with `psql`. Then you connected `psql` to a database and learned how to run SQL queries via the command line. Many experienced computer users prefer to use the command line for its simplicity and speed once they become familiar with using it. You might, too.    In Chapter 19, we’ll review common database maintenance tasks including backing up data, changing server settings, and managing the growth of your database. These tasks will give you more control over your working environment and help you better manage your data analysis projects. ````"]