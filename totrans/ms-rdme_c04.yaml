- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Writing Operable Code
  prefs: []
  type: TYPE_NORMAL
- en: Code does weird things when exposed to “the real world.” Users are unpredictable.
    Networks are unreliable. Things go wrong. Production software has to keep working.
    Writing operable code helps you deal with the unforeseen. Operable code has built-in
    protection, diagnostics, and controls. Protect your system by programming defensively
    with safe and resilient coding practices. Safe code prevents many failures, and
    resilient code recovers when failures do occur. You also need to be able to see
    what’s going on so you can diagnose failures. Expose logging, metrics, and call
    trace information for easy diagnostics. Finally, you need to control systems without
    rewriting code. An operable system has configuration parameters and system tools.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter describes some best practices that will make your code easier to
    run in production. There’s a lot of ground to cover, so we kept things dense.
    By the end, you’ll be familiar with key concepts and tools you need to make your
    software operable. Moreover, operability comments are common in code reviews;
    this information will help you give and receive better feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Defensive Programming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Well-defended code is an act of compassion for anyone who runs your code (including
    you!). Defensive code fails less often, and when it does, it is more likely to
    recover. Make your code safe and resilient. *Safe code* takes advantage of compile-time
    validation to avoid runtime failures. Use immutable variables, access modifiers
    to restrict scope, and static type-checkers to prevent bugs. At runtime, validate
    input to avoid surprises. *Resilient code* uses exception-handling best practices
    and handles failures gracefully.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid Null Values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In many languages, variables without a value default to `null` (or `nil`, `None`,
    or some other variant thereof). Null pointer exceptions are a common occurrence.
    Stack traces prompt head-scratching and a “how could this variable not have been
    set?” investigation. Avoid null pointer exceptions by checking that variables
    aren’t null, by using the null object pattern, and by using option types.
  prefs: []
  type: TYPE_NORMAL
- en: Perform null checks at the beginning of methods. Use `NotNull` annotations and
    similar language features when available. Validating up front that variables aren’t
    null means that later code can safely assume that it’s dealing with real values;
    this will keep your code cleaner and more legible.
  prefs: []
  type: TYPE_NORMAL
- en: The *null object pattern* uses objects in lieu of null values. An example of
    this pattern is a search method that returns an empty list instead of `null` when
    no objects are found. Returning an empty list allows callers to safely iterate
    over the results, without special code to handle empty result sets.
  prefs: []
  type: TYPE_NORMAL
- en: Some languages have built-in *option types*—`Optional` or `Maybe`—that force
    developers to think about how empty responses are handled. Take advantage of option
    types if they’re available.
  prefs: []
  type: TYPE_NORMAL
- en: Make Variables Immutable
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Immutable variables can’t be changed once they’re set. If your language has
    a way to explicitly declare variables as immutable (`final` in Java, `val` rather
    than `var` in Scala, `let` instead of `let mut` in Rust), do so whenever possible.
    Immutable variables prevent unexpected modifications. Many more variables can
    be made immutable than you might expect at first blush. As a bonus, using immutable
    variables makes parallel programming simpler, and a compiler or runtime that knows
    a variable is not going to change can be more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Use Type Hinting and Static Type Checking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Constrain the values that variables can take. For example, variables with only
    a few valid string values should be an `Enum` rather than a `String`. Constraining
    variables will ensure that unexpected values will immediately fail (or might not
    even compile) rather than cause bugs. Use the most specific type possible when
    defining variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Dynamic languages such as Python (starting with Python 3.5), Ruby via Sorbet
    (slated to be part of Ruby 3), and JavaScript (via TypeScript) all now have increasingly
    robust support for *type hinting* and *static type checkers*. Type hinting lets
    you specify a variable’s type in a language that’s normally dynamically typed.
    For example, the following Python 3.5 method uses type hinting to receive and
    return a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Best of all, type hinting can be added gradually to existing codebases. When
    combined with a static type checker, which uses type hints to find bugs before
    code is executed, you can prevent runtime failures.
  prefs: []
  type: TYPE_NORMAL
- en: Validate Inputs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Never trust the input your code receives. Developers, faulty hardware, and human
    error can mangle input data. Protect your code by validating that its input is
    well formed. Use preconditions, checksum and validate data, use security best
    practices, and use tools to find common errors. Reject bad input as early as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Validate method input variables using preconditions and postconditions. Use
    libraries and frameworks that validate preconditions when the type you use does
    not fully capture valid variable values. Most languages have libraries with methods
    like `checkNotNull` or annotations like `@Size(min=0, max=100)`. Be as constrained
    as possible. Check that input strings match expected formats, and remember to
    deal with leading or trailing whitespace. Validate that all numbers are in appropriate
    ranges: if a parameter should be greater than zero, ensure that it is; if a parameter
    is an IP address, check that it’s a valid IP.'
  prefs: []
  type: TYPE_NORMAL
- en: Computer hardware isn’t always trustworthy. Networks and disks can corrupt data.
    If you need strong durability guarantees, use checksums to validate that data
    hasn’t changed unexpectedly.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t overlook security, either. External inputs are dangerous. Malicious users
    might try to inject code or SQL into inputs, or overrun buffers to gain control
    of your application. Use mature libraries and frameworks to prevent cross-site
    scripting. Always escape inputs to prevent SQL injection attacks. Explicitly set
    size parameters when manipulating memory with commands like `strcpy` (specifically
    use `strncpy`) to prevent buffer overflows. Use widely adopted security and cryptography
    libraries or protocols instead of writing your own. Familiarize yourself with
    the Open Web Application Security Project (OWASP) Top 10 security report ([https://owasp.org/www-project-top-ten/](https://owasp.org/www-project-top-ten/))
    to quickly bootstrap your security knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Use Exceptions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Don’t use special return values (`null`, `0`, `–1`, and so on) to signal an
    error. All modern languages support exceptions or have a standard exception-handling
    pattern (like Go’s `error` type). Special values aren’t obviously visible from
    a method signature. Developers won’t know that error conditions are returned and
    need to be handled. It’s also difficult to remember which return value corresponds
    to which failure state. Exceptions carry more information than a `null` or `–1`;
    they’re named and have stack traces, line numbers, and messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in Python a `ZeroDivisionError` returns a lot more information
    than a `None` return value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In many languages, checked exceptions are visible from method signatures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: An error declaration in Go and an exception declaration in Java clearly signal
    that the open methods can raise errors that need to be handled.
  prefs: []
  type: TYPE_NORMAL
- en: Be Precise with Exceptions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Precise exceptions make code easier to use. Use built-in exceptions when possible
    and avoid creating generic exceptions. Use exceptions for failures, not to control
    application logic.
  prefs: []
  type: TYPE_NORMAL
- en: Most languages have built-in exception types (`FileNotFoundException`, `AssertionError`,
    `NullPointerException`, and so on). Don’t create custom exceptions if a built-in
    type can describe the problem. Developers have experience with existing exception
    types and will know what they mean.
  prefs: []
  type: TYPE_NORMAL
- en: When creating your own exceptions, don’t make them too generic. Generic exceptions
    are difficult to handle because developers don’t know what kind of problem they’re
    dealing with. If developers don’t get a precise signal of the error that occurred,
    they’ll be forced to fail the application—a significant action. Be as specific
    as possible about the exception types you raise so developers can react to failures
    appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t use exceptions for application logic, either. You want your code to be
    unsurprising, not clever. Using exceptions to break out of a method is confusing
    and makes code hard to debug.
  prefs: []
  type: TYPE_NORMAL
- en: 'This Python example uses `FoundNodeException` rather than directly returning
    the node that was found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Don’t do this. Just return the node.
  prefs: []
  type: TYPE_NORMAL
- en: Throw Exceptions Early, Catch Exceptions Late
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Follow the “throw early, catch late” principle. *Throwing early* means raising
    exceptions as close to the error as possible so developers can quickly find the
    relevant code. Waiting to throw an exception makes it harder to find where the
    failure actually happened. When an error occurs but other code is executed before
    the exception is thrown, you risk the possibility of a second error being triggered.
    If an exception is thrown for the second error, you don’t know that the first
    error happened. Tracking down this kind of bug is maddening. You fix a bug only
    to discover that the real problem was something upstream.
  prefs: []
  type: TYPE_NORMAL
- en: '*Catching exceptions late* means propagating exceptions up the call stack until
    you reach the level of the program that is capable of handling the exception.
    Consider an application that tries to write to a full disk. There are many possible
    next steps: blocking and retrying, retrying asynchronously, writing to a different
    disk, alerting a human user, or even crashing. The appropriate reaction depends
    on application specifics. A database write-ahead log must be written, while a
    word processor’s background save can be delayed. The piece of code that can make
    this decision is likely several layers removed from the low-level library that
    encounters a full disk. All the intermediate layers need to propagate the exception
    upward and not attempt premature remediation. The worst of premature remediation
    is “swallowing” an exception you can’t address, usually by ignoring it in a `catch`
    block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This exception will not get logged or rethrown, nor will any other action be
    taken; it’s completely ignored. The failure gets hidden, possibly to disastrous
    effect. When calling code that might throw exceptions, either handle them completely
    or propagate them up the stack.
  prefs: []
  type: TYPE_NORMAL
- en: Retry Intelligently
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The appropriate reaction to an error is often to simply try again. Plan on
    occasionally having to try multiple times when calling remote systems. Retrying
    an operation sounds easy: catch the exception and retry the operation. In practice,
    when and how often to retry requires some know-how.'
  prefs: []
  type: TYPE_NORMAL
- en: The most naïve retry approach is simply to catch an exception and retry the
    operation immediately. But what if the operation fails again? If a disk runs out
    of space, it’s likely to be out of space 10 milliseconds later, and 10 milliseconds
    after that. Banging away over and over slows things down and makes it harder for
    the system to recover.
  prefs: []
  type: TYPE_NORMAL
- en: It’s prudent to use a strategy called *backoff*. Backoff increases sleep time
    nonlinearly (usually using an exponential backoff, such as `(retry number)^2`).
    If you use this approach, make sure to cap the backoff at some maximum so it doesn’t
    get too large. However, if a network server has a blip and all clients experience
    that blip simultaneously, then back off using the same algorithm; they will all
    reissue their requests at the same time. This is called a *thundering herd*; many
    clients issuing retry requests simultaneously can bring a recovering service back
    down. To handle this, add *jitter* to the backoff strategy. With jitter, clients
    add a random, bounded amount of time to the backoff. Introducing randomness spreads
    out the requests, reducing the likelihood of a stampede.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t blindly retry all failed calls, particularly ones that write data or cause
    some business process to execute. It is better to let the application crash when
    it encounters an error it was not designed to handle; this is called *failing
    fast*. If you fail fast, no further damage will be done, and a human can figure
    out the correct course of action. Make sure to fail not only fast but also loudly.
    Relevant information should be visible so that debugging is easy.
  prefs: []
  type: TYPE_NORMAL
- en: Write Idempotent Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It’s not always obvious what state the system was left in after a failure.
    If the network fails during a remote write request, did the request succeed before
    the failure or not? This leaves you in a pickle: Do you retry and risk double-writing
    the request, or do you give up and risk losing the data? In a billing system,
    a retry might double-charge the customer, while not retrying might mean not charging
    them at all. Sometimes you can read the remote system to check, but not always.
    Local state mutations can suffer from similar problems. Nontransactional in-memory
    data structure mutations can leave your system in an inconsistent state.'
  prefs: []
  type: TYPE_NORMAL
- en: The best way to deal with retries is to build idempotent systems. An *idempotent*
    operation is one that can be applied multiple times and still yield the same outcome.
    Adding a value to a set is idempotent. No matter how many times the value is added,
    it exists in the set once. Remote APIs can be made idempotent by allowing clients
    to supply a unique ID for each request. When a client retries, it supplies the
    same unique ID as its failed attempt; the server can then de-duplicate the request
    if it’s already been processed. Making all your operations idempotent greatly
    simplifies system interactions and eliminates a large class of possible errors.
  prefs: []
  type: TYPE_NORMAL
- en: Clean Up Resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Be sure to clean all resources when a failure occurs. Release memory, data
    structures, network sockets, and file handles that you no longer need. Operating
    systems have a fixed amount of space for file handles and network sockets; once
    exceeded, all new handles and sockets fail to open. Leaking network sockets—failing
    to close them after use—will keep useless connections alive, which will fill connection
    pools. The following code is dangerous:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Any failures that happen before `f.close()` will prevent the file pointer from
    being closed. If your language doesn’t support auto-closing, wrap your code in
    a `try`/`finally` block to safely close file handles even if an exception occurs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many modern languages have features that automatically close resources. Rust
    will automatically close resources by invoking a destructor method when objects
    leave scope. Python’s `with` statement automatically closes handles when the call
    path leaves the block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first time you wrote “Hello, world!” to a terminal, you were logging. Printing
    log messages is simple and convenient for understanding code or debugging a small
    program. For complex applications, languages have sophisticated logging libraries
    to give operators more control over what’s logged and when. Operators can modulate
    log volume through logging levels and control log formats. Frameworks also inject
    contextual information—thread names, hostnames, IDs—that you can use when debugging.
    Logging frameworks work well with log management systems, which aggregate log
    messages so operators can filter and search them.
  prefs: []
  type: TYPE_NORMAL
- en: Use a logging framework to make your code easier to operate and debug. Set log
    levels so your operators can control your application’s log volume. Keep logs
    atomic, fast, and secure.
  prefs: []
  type: TYPE_NORMAL
- en: Use Log Levels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logging frameworks have *log levels*, which let operators filter messages based
    on importance. When an operator sets a log level, all logs at or above the level
    will be emitted, while messages from lower levels will be silenced. Levels are
    usually controlled through both a global setting and package or class-level overrides.
    Log levels let operators adjust log volume as befits a given situation, from extremely
    detailed debugging logs to a steady background hum of normal operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, here’s a Java `log4j.properties` snippet that defines an ERROR-level
    root verbosity and a package-specific INFO-level verbosity for logs coming from
    the `com.foo.bar` package space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You must use the appropriate criticality for each log message for log levels
    to be useful. While log levels are not completely standard, the following levels
    are common:'
  prefs: []
  type: TYPE_NORMAL
- en: TRACE This is an extremely fine level of detail that only gets turned on for
    specific packages or classes. This is rarely used outside of development. If you
    need line-by-line logs or data structure dumps, this level is for you. If you
    find yourself using TRACE frequently, you should consider using a debugger to
    step through code instead.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: DEBUG This is used when the message will be useful during a production issue
    but not during normal operations. Don’t use debug-level logging so much that the
    output is unusable when debugging; save that for TRACE.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: INFO This is nice-to-have information about the state of the application but
    not indicative of any problems. Application state messages like “Service started”
    and “Listening on port 5050” go here. INFO is the default log level. Don’t emit
    frivolous logs with INFO—“just in case” logging goes into TRACE or DEBUG. INFO
    logging should tell us something useful during normal operations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: WARN These are messages about potentially problematic situations. A resource
    nearing its capacity merits a warning. Whenever you log a warning, there should
    be a concrete action you want the person seeing the message to take. If the warning
    is not actionable, log it to INFO.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ERROR These messages indicate that an error that needs attention is occurring.
    An unwritable database usually merits an ERROR log. ERROR logs should be detailed
    enough to diagnose problems. Log explicit details, including relevant stack traces
    and the resulting actions the software is performing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: FATAL These are the “last gasp” log messages. If the program encounters a condition
    so severe that it must exit immediately, a message about the cause of the problem
    can be logged at the FATAL level. Include relevant context about the program’s
    state; locations of recovery or diagnostic-related data should be logged.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s an INFO-level log emitted in Rust:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The log line includes the error that causes the request to fail. The INFO level
    is used because the application is automatically retrying; no operator action
    is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Keep Logs Atomic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If information is useful only when coupled with other data, log it all *atomically*
    in one message. Atomic logs, which have all relevant information in one line,
    work better with log aggregators. Don’t assume that logs will be seen in a specific
    order; many operational tools reorder or even drop messages. Don’t rely on system
    clock timestamps for ordering: system clocks can get reset or drift between hosts.
    Avoid newlines in log messages; many log aggregators treat each new line as a
    separate message. Make extra sure that stack traces are logged in a single message,
    as they often include newlines when printed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of nonatomic log messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The WARNING log message has a newline in it, which makes it hard to read. Subsequent
    lines from the WARNING have no timestamp and are intermingled with other INFO
    messages coming from another thread. The WARNING should have been written atomically
    as one line.
  prefs: []
  type: TYPE_NORMAL
- en: If log messages can’t be output atomically, include a unique ID in the messages
    so they can be stitched together later.
  prefs: []
  type: TYPE_NORMAL
- en: Keep Logs Fast
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Excessive logging will hurt performance. Logs must be written somewhere—to disk,
    to a console, or to a remote system. Strings must be concatenated and formatted
    before they’re written. Use parameterized logging and asynchronous appenders to
    keep logging fast.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll find string concatenation is very slow and can be devastating in performance-sensitive
    loops. When a concatenated string is passed into a log method, the concatenation
    happens regardless of the verbosity level because arguments are evaluated before
    they’re passed into a method. Log frameworks provide mechanisms to delay string
    concatenation until it’s actually needed. Some frameworks force log messages into
    closures that aren’t evaluated unless a log line is invoked, while others provide
    support parameterized messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, Java has three ways to concatenate strings in log calls, two of
    which concatenate the string parameter before calling the `trace` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The final call uses a parameterized string that will be evaluated only if the
    log line is actually written.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also manage performance impact using *appenders*. Appenders route logs
    to different locations: the console, a file, or a remote log aggregator. Default
    log appenders usually operate in the caller’s thread, the same way a call to `print`
    would. *Asynchronous* appenders write log messages without blocking execution
    threads. This improves performance since application code doesn’t need to wait
    for logs to be written. *Batching* appenders buffer log messages in-memory before
    writing to disk, thus improving write throughput. The operating system’s page
    cache helps log throughput by acting as a buffer as well. While asynchronous and
    batching writes improve performance, they can result in lost log messages if an
    application crashes, since not all logs are guaranteed to be flushed to disk.'
  prefs: []
  type: TYPE_NORMAL
- en: Beware that changing log verbosity and configuration can eliminate race conditions
    and bugs because it slows down the application. If you enable verbose logging
    to debug an issue and discover a bug disappears, the logging change itself might
    be the reason.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t Log Sensitive Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Be careful when dealing with sensitive data. Log messages shouldn’t include
    private data like passwords, security tokens, credit card numbers, or emails.
    This might seem obvious, but it’s easy to get wrong—simply logging a URL or HTTP
    response can expose information that log aggregators are not set up to safeguard.
    Most frameworks support rule-based string replacement and redaction; configure
    them, but do not rely on them as your only defense. Be paranoid; logging sensitive
    data can create security risks and violate privacy regulations.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instrument your application with metrics to see what it is doing. Metrics are
    the numerical equivalent of logs; they measure application behavior. How long
    did a query take? How many elements are in a queue? How much data was written
    to disk? Measuring application behavior helps detect problems and is useful for
    debugging.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three common metric types: counters, gauges, and histograms. These
    names are similar, but not consistent, across different monitoring systems. *Counters*
    measure the number of times an event happens. Using a cache hit counter and a
    request counter, you can calculate cache hit rates. Counters only increase in
    value or reset to 0 when a process restarts (they are *monotonically increasing*).
    *Gauges* are point-in-time measurements that can go up or down; think of a speedometer
    or a gas volume indicator in a car. Gauges expose statistics such as the size
    of a queue, stack, or map. *Histograms* break events into ranges based on their
    magnitude. Each range has a counter that is incremented whenever an event value
    falls into its range. Histograms commonly measure the amount of time requests
    take, or data payload sizes.'
  prefs: []
  type: TYPE_NORMAL
- en: System performance is often measured in terms of metric values at threshold
    percentiles—for example, the 99th percentile, referred to as *P99*. A system with
    a 2-millisecond P99 latency takes 2 milliseconds or less to respond to 99 percent
    of the requests it receives. Percentiles are derived from histograms. To cut down
    on the data that needs to be tracked, some systems require you to configure which
    percentiles you care about; if a system tracks P95 by default but you have a P99
    service level objective (SLO*)*, make sure to change settings accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Application metrics are aggregated into centralized *observability* *systems*
    like Datadog, LogicMonitor, or Prometheus. Observability is a concept from control
    theory that defines how easy it is to determine the state of a system by looking
    at its outputs. Observability systems try to make it easier to determine a running
    application’s state by providing dashboards and monitoring tools on top of aggregated
    metrics. Dashboards show operators what’s going on in the system, and monitoring
    tools trigger alerts based on metric values.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics are also used to automatically scale a system up or down. *Autoscaling*
    is common in environments that provide dynamic resource allocation. For example,
    cloud hosts may automatically adjust the number of running instances by monitoring
    load metrics. Autoscaling increases server capacity when it is needed and reduces
    server capacity to save money later.
  prefs: []
  type: TYPE_NORMAL
- en: To track SLOs, use observability systems, and take advantage of autoscaling
    features, you must measure everything. Metrics are tracked using a standard metrics
    library; most application frameworks provide these. As a developer, it is your
    job to ensure that important metrics are exposed to observability systems.
  prefs: []
  type: TYPE_NORMAL
- en: Use Standard Metrics Libraries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While counters, gauges, and histograms are pretty easy to calculate, don’t roll
    your own metrics library. Nonstandard libraries are a maintenance nightmare. Standard
    libraries will integrate with everything out of the box. Your company probably
    has a metrics library that they prefer. If they do, use it. If they don’t, start
    a discussion to adopt one.
  prefs: []
  type: TYPE_NORMAL
- en: Most observability systems offer metric client libraries in a range of languages.
    We’ll use a StatsD client in a simple Python web application to show what metrics
    look like. Metrics libraries all look pretty similar, so our example should translate
    nearly verbatim to whichever library you use.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Python web application in [Listing 4-1](#listing4-1) has four methods:
    `set`, `get`, `unset`, and `dump`. The methods `set` and `get` simply set and
    retrieve values in a map stored in the service. The `unset` method deletes key-value
    pairs from the map and `dump` JSON-encodes the map and returns it.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 4-1: An example Python Flask application using the StatsD client metrics
    library'
  prefs: []
  type: TYPE_NORMAL
- en: This example uses counters `key_hit` and `key_miss` to track hits and misses
    in `get` with `statsd.incr`. A timer (`statsd.timer`) measures how long it takes
    to encode the map into JSON, which will be added to a timing histogram. Serialization
    is a costly, CPU-intensive operation, so it should be measured. A gauge (`statsd.gauge`)
    measures the current size of the map. We could have used increment and decrement
    methods on a counter to track the map size, but using a gauge is less error prone.
  prefs: []
  type: TYPE_NORMAL
- en: Web application frameworks like Flask usually do a lot of metric calculations
    for you. Most will count all HTTP status codes for every method invocation in
    the web service and time all HTTP requests. Framework metrics are a great way
    to get a ton of metrics for free; just configure the framework to output to your
    observability system. Plus, your code will be cleaner since measurement happens
    underneath.
  prefs: []
  type: TYPE_NORMAL
- en: Measure Everything
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Measurements are cheap; you should use them extensively. Measure all of the
    following data structures, operations, and behaviors:'
  prefs: []
  type: TYPE_NORMAL
- en: Resource pools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data structures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CPU-intensive operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I/O-intensive operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exceptions and errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote requests and responses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use gauges to measure the size of resource pools. Pay special attention to thread
    pools and connection pools. Large pools are an indication that the system is stuck
    or unable to keep up.
  prefs: []
  type: TYPE_NORMAL
- en: Count cache hits and misses. Shifts in the hit-to-miss ratio impact application
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: Measure the size of key data structures with gauges. Abnormal data structure
    size is an indication that something strange is going on.
  prefs: []
  type: TYPE_NORMAL
- en: Time CPU-intensive operations. Pay special attention to data serialization operations,
    which are surprisingly expensive. A simple JSON-encode of a data structure is
    often the costliest operation in code.
  prefs: []
  type: TYPE_NORMAL
- en: Disk and network I/O operations are slow and unpredictable. Use timers to measure
    how long they take. Measure the size of the data that your code deals with. Track
    the size of *remote procedure call* *(RPC**)* payloads. Track the size of data
    generated for I/O using histograms (similar to timers) so you can see 99th percentile
    data sizes. Large data has an impact on memory footprint, I/O speed, and disk
    usage.
  prefs: []
  type: TYPE_NORMAL
- en: Count every exception, error response code, and bad input. Measuring errors
    makes it easy to trigger an alert when things go wrong.
  prefs: []
  type: TYPE_NORMAL
- en: Measure any requests to your application. An abnormally high or low request
    count is a sign that something is amiss. Users want your systems to respond quickly,
    so you need to measure latency. Time all responses so you know when your system
    is slow.
  prefs: []
  type: TYPE_NORMAL
- en: Take time to understand how your metrics library works. It’s not always obvious
    how a library calculates a metric; many libraries will sample measurements. Sampling
    keeps performance fast and reduces disk and memory usage, but it also makes measurements
    less accurate.
  prefs: []
  type: TYPE_NORMAL
- en: Traces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Developers all know about stack traces, but there’s a less familiar kind of
    trace: a *distributed call trace*. A single call to a frontend API might result
    in hundreds of downstream RPC calls to different services. Distributed call traces
    stitch all of these downstream calls together into one graph. Distributed traces
    are useful for debugging errors, measuring performance, understanding dependencies,
    and analyzing system cost (which APIs are the most expensive to serve, which customers
    cost the most, and so on).'
  prefs: []
  type: TYPE_NORMAL
- en: RPC clients use a tracing library to attach a call-trace ID to their request.
    Subsequent RPC calls by downstream services attach the same call-trace ID. Services
    then report the invocations that they receive along with the call-trace ID and
    other data, such as metadata tags and processing time. A dedicated system records
    all these reports and stitches call traces back together by call-trace ID. With
    this knowledge, the tracing system can present full distributed call graphs.
  prefs: []
  type: TYPE_NORMAL
- en: Call-trace IDs are usually propagated for you automatically through RPC client
    wrappers and service meshes. Verify that you’re propagating any required state
    as you make calls to other services.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Applications and services should expose settings that allow developers or site
    reliability engineers (SREs) to configure runtime behavior. Applying configuration
    best practices will make your code easier to run. Don’t get too creative; use
    a standard configuration format, provide sensible defaults, validate configuration
    inputs, and avoid dynamic configuration when possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Configuration can be expressed in many ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Files in plain, human-readable formats such as INI, JSON, or YAML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Environment variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Command line flags
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A custom *domain-specific language* *(DSL**)*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The language the application is written in
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Human-readable config files, environment variables, and command line flags are
    the most common approaches. Files are used when there are many values to set or
    there’s a desire to version control the configurations. Environment variables
    are easy to set in scripts, and environments can be easily examined and logged.
    Command line flags are easy to set and are visible in process lists like `ps`.
  prefs: []
  type: TYPE_NORMAL
- en: DSLs are helpful when configuration needs programmable logic, like `for` loops
    or `if` statements. DSL-based configuration is commonly used when an application
    is written in a DSL-friendly language (like Scala). Using a DSL rather than a
    full-blown programming language, authors can provide shortcuts for complex operations
    and limit configurations to safe values and types—an important consideration for
    security and startup performance. But DSLs are hard to parse using standard tools,
    which makes interoperability with other tools difficult.
  prefs: []
  type: TYPE_NORMAL
- en: Expressing configuration in the application’s language usually happens when
    the application is written in a scripting language like Python. Using code to
    generate configuration is powerful but also dangerous. Customizable logic obscures
    the configuration the application is seeing.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t Get Creative with Configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Configuration systems should be boring. An operator paged at 3 AM shouldn’t
    need to remember Tcl syntax to change a timeout value.
  prefs: []
  type: TYPE_NORMAL
- en: Innovating on a configuration system is tempting. Configuration is familiar
    to everyone, and simple configuration systems seem to miss useful features—variable
    substitution, `if` statements, and so on. Many creative and well-meaning people
    have spent incredible amounts of time making fancy configuration systems. Sadly,
    the cleverer your configuration scheme is, the more bizarre your bugs will be.
    Do not get creative with configuration—use the simplest possible approach that
    will work. A static configuration file in a single standard format is ideal.
  prefs: []
  type: TYPE_NORMAL
- en: Most applications are configured through a static configuration file. Changing
    the file while the application is running won’t affect the application; to pick
    up changes, the application needs to be restarted. Dynamic configuration systems
    are used when an application needs to be reconfigured without restarting. Dynamic
    configuration is typically stored in a dedicated configuration service, which
    gets polled or pushed by the application when values change. Alternatively, dynamic
    configuration is refreshed by periodically checking a local config file for updates.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic configuration is usually not worth the complexity it introduces. You
    need to think through all the implications of various configurations changing
    midflight. It also makes it harder to track when configuration was changed, who
    changed it, and what the value used to be—information that can be critical when
    debugging operational issues. It can also add external dependencies on other distributed
    systems. It sounds rudimentary, but restarting a process to pick up a new configuration
    is usually operationally and architecturally superior.
  prefs: []
  type: TYPE_NORMAL
- en: There are some common use cases that do warrant dynamic configuration, though.
    Log verbosity is frequently a dynamic setting. Operators can change the log level
    to a higher verbosity like DEBUG when something strange is going on. Restarting
    a process when odd behavior surfaces might change the behavior that you’re trying
    to observe. Flipping a running process’s log level lets you peek into its behavior
    without restarting.
  prefs: []
  type: TYPE_NORMAL
- en: Log and Validate All Configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Log all (nonsecret) configuration immediately upon startup to show what the
    application is seeing. Developers and operators occasionally misunderstand where
    a configuration file is supposed to be placed or how multiple configuration files
    get merged. Logging config values shows users whether the application is seeing
    the expected configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Always validate configuration values when they’re loaded. Do the validation
    only once, as early as possible (right after the configuration is loaded). Make
    sure that the values are set to the proper types, such as an integer for a port,
    and check that values make logical sense: check boundaries, string length, valid
    enum values, and so on. `–200` is an integer but not a valid port. Take advantage
    of configuration systems that have robust type systems to express acceptable configuration
    values.'
  prefs: []
  type: TYPE_NORMAL
- en: Provide Defaults
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If a user has to set a large number of configuration parameters, your system
    will be hard to run. Set good defaults so your application will work well for
    most users out of the box. Default to network ports greater than 1024 (lower ports
    are restricted) if no port is configured. Use the system’s temporary directory
    or the user’s home directory if directory paths are unspecified.
  prefs: []
  type: TYPE_NORMAL
- en: Group Related Configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s easy for application configuration to grow unmanageable, especially key-value
    formats that don’t support nested configuration. Use a standard format like YAML
    that allows for nesting. Grouping related properties makes configuration easier
    to organize and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Combine tightly coupled parameters (like timeout duration and unit) in a single
    structure so the relationship is clear, and force the operator to declare the
    values atomically. Rather than defining `timeout_duration=10` and `timeout_units=second`,
    use `timeout=10s` or `timeout: { duration: 10, units = second }`.'
  prefs: []
  type: TYPE_NORMAL
- en: Treat Configuration as Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *configuration as code (CAC)* philosophy says that configuration should
    be subjected to the same rigor as code. Configuration mistakes can be disastrous.
    A single incorrect integer or missing parameter can break an application.
  prefs: []
  type: TYPE_NORMAL
- en: To keep configuration changes safe, configuration should be version controlled,
    reviewed, tested, built, and published. Keep configuration in a VCS like Git so
    you have a history of changes. Review configuration changes just like code reviews.
    Validate that configuration is properly formatted and conforms to expected types
    and value bounds. Build and publish configuration packages. We cover more on config
    delivery in Chapter 8.
  prefs: []
  type: TYPE_NORMAL
- en: Keep Configuration Files Clean
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Clean configuration is easier for others to understand and change. Delete unused
    configuration, use standard formatting and spacing, and don’t blindly copy configuration
    from other files (an example of *cargo culting*: copying things without actually
    understanding what they do or how they work). Tidy configuration is hard to maintain
    when you’re iterating quickly, but misconfiguration causes production outages.'
  prefs: []
  type: TYPE_NORMAL
- en: Don’t Edit Deployed Configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Avoid hand-editing configuration on a specific machine. One-off config changes
    are overwritten on subsequent deployments, it’s unclear who made the changes,
    and machines with similar configuration end up diverging.
  prefs: []
  type: TYPE_NORMAL
- en: As with keeping configuration files clean, resisting the temptation to hand-edit
    a config file in production is difficult, and in some cases unavoidable. If you
    edit configuration manually during a production incident, make sure changes get
    committed to the source of truth (the VCS) later.
  prefs: []
  type: TYPE_NORMAL
- en: Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Operable systems come with tools that help operators run the application. Operators
    might need to bulk-load data, run a recovery, reset database state, trigger a
    leadership election, or shift a partition assignment from one machine to another.
    Systems should come with tools to help operators deal with common operations.
  prefs: []
  type: TYPE_NORMAL
- en: Tool writing is collaborative. In some cases, you will be expected to write
    and supply operations tools. Organizations with strong SRE teams might also write
    tools for your systems. Regardless, work with your operations team to understand
    what they need.
  prefs: []
  type: TYPE_NORMAL
- en: 'SREs will usually prefer CLI-based tools and self-describing APIs since they
    are easily scriptable. Scriptable tools are easy to automate. If you plan on building
    UI-based tools, abstract the logic into a shared library or service that CLI-based
    tools can use as well. And treat your system’s tools as code like any other: follow
    clean coding standards and test rigorously.'
  prefs: []
  type: TYPE_NORMAL
- en: Your company might already have an existing toolset; it’s common to have a standard
    internal web tools framework, for example. Integrate your tools with the standard
    frameworks available to you. Look for *single panes of glass* (unified management
    consoles). Companies with unified management consoles will expect all tools to
    be integrated with it. If your company has existing CLI-based tools, ask if it
    makes sense to integrate your tools with them. Everyone is used to the existing
    tool interfaces; integrating with them will make your tools easier to work with.
  prefs: []
  type: TYPE_NORMAL
- en: Do’s and Don’ts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| **Do’s** | **Don’ts** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **DO** prefer compilation errors to runtime errors.  | **DON’T** use exceptions
    for application logic.  |'
  prefs: []
  type: TYPE_TB
- en: '| **DO** make things immutable whenever possible.  | **DON’T** use return codes
    for exception handling.  |'
  prefs: []
  type: TYPE_TB
- en: '| **DO** validate inputs and outputs.  | **DON’T** catch exceptions that you
    can’t handle.  |'
  prefs: []
  type: TYPE_TB
- en: '| **DO** study the OWASP Top 10.  | **DON’T** write multiline logs.  |'
  prefs: []
  type: TYPE_TB
- en: '| **DO** use bug-checking tools and types or type hinting.  | **DON’T** write
    secrets or sensitive data to logs.  |'
  prefs: []
  type: TYPE_TB
- en: '| **DO** clean up resources after exceptions (especially sockets, file pointers,
    and memory).  | **DON’T** manually edit configuration on a machine.  |'
  prefs: []
  type: TYPE_TB
- en: '| **DO** instrument your code with metrics.  | **DON’T** store passwords or
    secrets in configuration files.  |'
  prefs: []
  type: TYPE_TB
- en: '| **DO** make your application configurable.  | **DON’T** write custom configuration
    formats.  |'
  prefs: []
  type: TYPE_TB
- en: '| **DO** validate and log all configuration.  | **DON’T** use dynamic configuration
    if you can avoid it.  |'
  prefs: []
  type: TYPE_TB
- en: Level Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There aren’t many books dedicated to writing operable code. Instead, these subjects
    appear in chapters throughout many software engineering books. Chapter 8 of Steve
    McConnell’s *Code Complete* (Microsoft Press, 2004) covers defensive programming.
    Chapters 7 and 8 of *Clean Code* by Robert C. Martin (Pearson, 2008) cover error
    handling and boundaries. These are good places to start.
  prefs: []
  type: TYPE_NORMAL
- en: The web also has a lot of writing on defensive programming, exceptions, logging,
    configuration, and tooling. The *Amazon Builders’ Library* ([https://aws.amazon.com/builders-library/](https://aws.amazon.com/builders-library/))
    from Amazon is a particularly useful resource.
  prefs: []
  type: TYPE_NORMAL
- en: Google SRE group’s *Building Secure & Reliable Systems* (O’Reilly Media, 2020)
    is a treasure trove of sound advice, particularly from a security point of view.
    Google’s *Site Reliability Engineering* (O’Reilly Media, 2016) is the canonical
    book on all things site reliability related. It’s less focused on *writing* operable
    code, but it’s still a must-read. It will give you a glimpse into the complex
    world of running production software. Both are available for free online, as well
    as in print.
  prefs: []
  type: TYPE_NORMAL
