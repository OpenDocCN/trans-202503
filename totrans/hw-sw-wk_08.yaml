- en: '**8**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Concurrency**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/common-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Usually we can tell when software is doing something interesting, even if we
    don’t know how it’s done. We know that computers make graphics, encrypt our transmissions,
    and stream our videos. What we miss, though, is that these tasks often involve
    multiple programs, multiple processors, or even multiple computers connected via
    a network, accessing the same data at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: This overlapping access of data, known as *concurrency*, is a vital part of
    modern technology. High-performance tasks like graphics and shared resources like
    websites wouldn’t be possible without it. But concurrency causes big problems
    when it’s not carefully managed. In this chapter, we’ll see how results can become
    scrambled when multiple processors access the same data. Then we’ll look at the
    clever software (and hardware) techniques that keep processors from getting in
    each other’s way.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why Concurrency Is Needed**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Situations that require concurrency fall into three basic categories: performance,
    multiuser environments, and multitasking.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Performance***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Concurrency is needed when there’s more work to do than a single processor can
    handle. Until recently, the number of instructions a processor could execute in
    a second was steadily increasing, but now the pace of improvement has slowed.
    In order to execute more instructions in the same amount of time, a processor
    has to run faster. The faster it runs, the more power courses through it and the
    hotter it gets, which can eventually damage the components.
  prefs: []
  type: TYPE_NORMAL
- en: To mitigate that problem, the size of the components in the processor keeps
    getting smaller so that they draw less current and remain relatively cool. But
    it’s getting difficult to make processor components any smaller, which in turn
    makes it difficult to make them run any faster. When a single processor can’t
    get the job done, the only solution is to use multiple processing cores. We saw
    this with video game graphics in [Chapter 5](ch05.html#ch05), but it’s not just
    high-end game graphics that need multiple processors. Even today’s basic graphics
    tasks may require multiple processor cores.
  prefs: []
  type: TYPE_NORMAL
- en: '***Multiuser Environments***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Concurrency also allows networked computer systems to work together. Suppose
    you are playing an online game such as *World of Warcraft*. The game tracks each
    player’s actions as well as those of the computer-controlled monsters. The game’s
    servers tally every spell and axe swing, and calculate the damage done, the monsters
    slain, and the loot dropped.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency is required here because the processor in every player’s computer
    must share the data of nearby players and computer-controlled creatures.
  prefs: []
  type: TYPE_NORMAL
- en: '***Multitasking***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Concurrency can occur even in situations where only one processor is involved.
    Modern computers *multitask*, which means they are constantly switching between
    different programs, even when we think we’re doing only one thing on the computer
    at a time. For example, multitasking is what allows your email client to receive
    a new message while you surf the Web. In these cases, whether or not the computer
    has multiple processor cores, it’s definitely running multiple *processes*—different
    programs with overlapping executions.
  prefs: []
  type: TYPE_NORMAL
- en: Printing is another typical example. When you print a recipe from a website,
    the software that manages the printer, known as the driver, collects the print
    data in an orderly queue and then passes it on to the printer as needed. This
    is called *print spooling*. Without print spooling, the browser could send the
    data only as fast as the printer processed it, which means that you would have
    to wait for the print job to finish before you could do anything else with the
    browser.
  prefs: []
  type: TYPE_NORMAL
- en: Print spooling can’t work without concurrency. You can think of a print spool
    as one of those carousels that sit in the window between the front counter and
    the kitchen in a short-order restaurant, like the one shown in [Figure 8-1](ch08.html#ch8fig1).
    Someone in the front puts new orders on the carousel, and someone in the back
    takes down the orders as they are fulfilled. The shared data storage of the carousel
    allows the order takers and the cooks to work independently.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f08-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-1: An order-ticket carousel*'
  prefs: []
  type: TYPE_NORMAL
- en: This arrangement is known as a *shared buffer* and is frequently used behind
    the scenes in software. For example, suppose you are typing an email, but your
    computer momentarily slows down so that nothing you typed appears on screen. Then
    the system catches up, and everything you typed is now in the email. That happens
    because the keyboard doesn’t communicate directly with the email program, but
    uses the operating system as an intermediary. The operating system queues the
    keystrokes in a shared buffer so the email program can access them when ready.
  prefs: []
  type: TYPE_NORMAL
- en: Multitasking also allows programs to sit in the background and interrupt you
    when something significant happens. When a new email alert appears in the corner
    of your desktop’s screen while you are working in a word processor, or your phone
    signals a newly received text message while you’re playing a game, that’s multitasking
    at work.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the performance benefits of multiple processors and distributed processing,
    the importance of multitasking means some form of concurrency is required to provide
    the basic computing functionality we rely on daily.
  prefs: []
  type: TYPE_NORMAL
- en: '**How Concurrency Can Fail**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although concurrency is a vital part of everyday computing, it creates enormous
    headaches for software and can produce serious problems if proper safeguards aren’t
    in place to prevent them.
  prefs: []
  type: TYPE_NORMAL
- en: The underlying issue is how data is copied when it’s used in calculations. Essentially,
    all a computer processor does is retrieve numbers from storage and either perform
    math with them or compare them. To do these tasks, though, it must copy the numbers
    from wherever they are stored to locations inside the processor. Stored data isn’t
    changed directly. Instead, the computer fetches the value from main memory, or
    a hard drive, or across a network, and delivers it to the innermost part of the
    processor. The processor performs the math on this internal copy, and then sends
    the updated value back to storage to replace the original data.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you’re playing a first-person shooter game. You have 300 bullets in
    reserve when you run over an ammo clip, picking up 20 more bullets. [Figure 8-2](ch08.html#ch8fig2)
    shows the steps involved. To update your bullet count, the processor first retrieves
    your current bullet count and the number of bullets in the clip from their places
    in storage, shown in step 1\. These values are fed into the inputs of an “adder”
    circuit in the processor, as shown in step 2, which performs the actual math.
    Then the result is sent back to main memory, replacing the old value in the bullet
    count storage location, as shown in step 3.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f08-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-2: Three steps to update a number from 300 to 320*'
  prefs: []
  type: TYPE_NORMAL
- en: This update sequence causes problems when multiple processes attempt to make
    alterations to the same storage location. Take, for example, a *massively multiplayer
    online game (MMO)*. Trina Orcslayer and Skylar Rockguardian are two players. They
    are both officers of the same “guild,” and this game allows guilds to hold shared
    bank accounts across multiple game servers. On Friday morning, the balance of
    the guild account is exactly 10,000 gold, and Skylar and Trina each have 500 gold
    in their personal accounts. Sometime that day, Skylar withdraws 300 gold from
    the guild account while Trina deposits 200 gold into it. If these are the only
    transactions that happen, the final balance should be 9,900 in the guild account
    (10,000 – 300 + 200), 800 in Skylar’s account (500 + 300), and 300 in Trina’s
    account (500 – 200).
  prefs: []
  type: TYPE_NORMAL
- en: 'And that’s what will happen if the transactions are kept separate. Suppose
    Skylar makes the withdrawal in the morning, and Trina makes her deposit that afternoon.
    We won’t get into programming here, but let’s consider the steps that the game
    software will take to carry out these transactions. Let’s start with Skylar’s
    withdrawal:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   Retrieve the balance of the guild account. Call this **Skylar’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   Subtract 300 gold from **Skylar’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   Add 300 gold to Skylar’s personal stash.
  prefs: []
  type: TYPE_NORMAL
- en: 4.   Update the guild bank balance to **Skylar’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now suppose Trina makes the deposit in the afternoon. The steps of her transaction
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   Retrieve the balance of the guild account. Call this **Trina’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   Subtract 200 gold from Trina’s personal stash.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   Add 200 gold to **Trina’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 4.   Update the guild bank balance to **Trina’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: In this example everything works fine. But what happens if Skylar and Trina
    perform their transactions at the same time? In that case, the final balance of
    the guild account could be incorrect. This happens if the original guild balance
    of 10,000 gold is retrieved for calculation by both processes before either of
    them completes the transaction.
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at the details shown in [Table 8-1](ch08.html#ch8tab1). When Trina
    and Skylar initiate transactions at the same time, the same 10,000 balance is
    retrieved into their separate copies of the balance. Trina’s copy is increased
    to 10,200, while Skylar’s copy is decreased to 9,700\. Then both of the updated
    figures overwrite the guild account balance. In the example shown in the table,
    Skylar’s updated number arrives last, which means 9,700 is the new account balance
    and 200 gold has simply vanished.
  prefs: []
  type: TYPE_NORMAL
- en: It could have worked out the other way—Trina’s copy could have arrived after
    Skylar’s, increasing the guild’s gold balance, but of course neither result is
    correct. The only correct final balance is 9,900 gold, the balance that corresponds
    to the two transactions occurring separately.
  prefs: []
  type: TYPE_NORMAL
- en: Situations similar to this example are possible whenever two or more processes
    use the same data simultaneously. The general term for this situation is a *race
    condition*, since all the processes involved are racing to complete their task
    first. In this case the process that finishes last “wins,” because it determines
    the final value of the data.
  prefs: []
  type: TYPE_NORMAL
- en: While this example features two different processors, Trina’s and Skyler’s,
    it’s important to note that race conditions can happen even with a single processor.
    Because multitasking involves switching the processor to a different program many
    times a second, multiple processes operating on the same data could interleave,
    creating a race condition.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 8-1:** The Danger of Overlapping Bank Transactions'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Step** | **Description** | **Skylar’s copy** | **Trina’s copy** | **Guild
    balance** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Trina 1 | Retrieve the guild balance from the bank. |  | 10,000 | 10,000
    |'
  prefs: []
  type: TYPE_TB
- en: '| Skylar 1 | Retrieve the guild balance from the bank. | 10,000 |  | 10,000
    |'
  prefs: []
  type: TYPE_TB
- en: '| Trina 2 | Subtract 200 gold from Trina’s stash. |  | 10,000 | 10,000 |'
  prefs: []
  type: TYPE_TB
- en: '| Trina 3 | Add 200 gold to Trina’s copy of the guild balance. |  | 10,200
    | 10,000 |'
  prefs: []
  type: TYPE_TB
- en: '| Skylar 2 | Subtract 300 gold from Skylar’s copy of the guild balance. | 9,700
    |  | 10,000 |'
  prefs: []
  type: TYPE_TB
- en: '| Skylar 3 | Add 300 gold to Skylar’s stash. | 9,700 |  | 10,000 |'
  prefs: []
  type: TYPE_TB
- en: '| Trina 4 | Send Trina’s copy of the guild balance to the bank. |  | 10,200
    | 10,200 |'
  prefs: []
  type: TYPE_TB
- en: '| Skylar 4 | Send Skylar’s copy of the guild balance to the bank. | 9,700 |  |
    9,700 |'
  prefs: []
  type: TYPE_TB
- en: '**Making Concurrency Safe**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to make concurrency useful, then, we need to prevent race conditions.
    This requires enforcing rules on how processes can access data. The tighter the
    restrictions, the easier it is to prevent problems from occurring, but these restrictions
    can have an adverse effect on performance.
  prefs: []
  type: TYPE_NORMAL
- en: '***Read-Only Data***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One possible restriction is to allow processes to retrieve data simultaneously,
    but prohibit them from changing it; this is known as *read-only* data. This eliminates
    the possibility of a race condition but at an enormous cost. Most applications
    that require shared data access simply can’t work without the ability to change
    the data. So this method is rarely considered. However, as we’ll see later, distinguishing
    which processes want to change data from those that merely want to read data can
    improve the performance of concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: '***Transaction-Based Processing***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Another straightforward, comprehensive solution eliminates simultaneous data
    access entirely. The race condition occurs in the example because Skylar’s and
    Trina’s transactions overlap. What if we prevent overlapping transactions? To
    enforce this rule, once any bank transaction begins, we wait for it to signal
    its completion before any other transaction may start. For example, the steps
    in Skylar’s process now might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   Signal **Start Transaction** to the bank server.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   Retrieve the balance of the guild account. Call this **Skylar’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   Subtract 300 gold from **Skylar’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 4.   Add 300 gold to Skylar’s personal stash.
  prefs: []
  type: TYPE_NORMAL
- en: 5.   Update the guild bank balance to **Skylar’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 6.   Signal **End Transaction** to the bank server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps in Trina’s process would be likewise bracketed:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   Signal **Start Transaction** to the bank server.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   Retrieve the balance of the guild account. Call this **Trina’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   Subtract 200 gold from Trina’s personal stash.
  prefs: []
  type: TYPE_NORMAL
- en: 4.   Add 200 gold to **Trina’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 5.   Update the guild bank balance to **Trina’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 6.   Signal **End Transaction** to the bank server.
  prefs: []
  type: TYPE_NORMAL
- en: The bank server process enforces the transaction rules. When no transaction
    is under way, a signal to start a new transaction is immediately accepted. So
    if Trina’s transaction began during an idle period, it would continue. If, however,
    the *start transaction* signal from Skylar’s process arrived while Trina’s transaction
    was being processed, Skylar’s transaction would have to wait until Trina’s transaction
    finished. And if other transactions arrived during this time, the bank server
    would put them in a queue, to process them in the order in which they arrived.
  prefs: []
  type: TYPE_NORMAL
- en: This rule transforms the guild bank into the equivalent of a lobby with a single
    teller. If a customer arrives and the teller is available, the customer gets immediate
    service; otherwise, the customer must wait until the teller is free. This prevents
    race conditions but robs the system of the performance benefit of having multiple
    processors. Just as having one teller in a busy bank means a long wait for each
    customer, allowing only one transaction through the bank server at a time means
    a relatively long wait for each transaction.
  prefs: []
  type: TYPE_NORMAL
- en: The rule is much too strict. At any given time, the bank may be handling a large
    number of transactions, and few (if any) of them involve the same accounts. This
    rule prevents race conditions by preventing all overlapping transactions, even
    when the overlap is harmless.
  prefs: []
  type: TYPE_NORMAL
- en: '***Semaphores***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another idea takes advantage of the fact that most of the transactions are not
    interacting with the same data. If the transaction rule is like a bank with a
    single teller, a better rule would be like a bank where every account has its
    own personal teller. Two or more customers attempting to access the same account
    at the same time will form a queue, but customers accessing different accounts
    won’t slow each other down at all.
  prefs: []
  type: TYPE_NORMAL
- en: The secret ingredient behind this technique is a special type of data called
    a *semaphore*. In nautical language, semaphores are flags that ships hoist to
    signal other ships; in software, semaphores are the numerical equivalent of flags,
    signaling whether or not logically connected data is in use. The simplest type
    of semaphore has just two possible values, 0 or 1, and is called a *binary semaphore*.
  prefs: []
  type: TYPE_NORMAL
- en: '**How Semaphores Prevent Race Conditions**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Returning to our guild bank account, we can avoid the race condition by creating
    semaphores on the bank server for each of the account balances. Each semaphore
    begins with a value of 1.
  prefs: []
  type: TYPE_NORMAL
- en: Before requesting an account balance, a process must first *acquire* the semaphore
    associated with that account. This acquire operation will check the value of the
    semaphore. If the semaphore is 1, it means no other process is using the associated
    balance; in this case, the semaphore changes to 0, and the process will be allowed
    to continue.
  prefs: []
  type: TYPE_NORMAL
- en: If the semaphore is already 0, though, it means another process is currently
    accessing the associated balance. In this case, the software will have to wait.
  prefs: []
  type: TYPE_NORMAL
- en: When a process completes its transaction, it *releases* the semaphore, which
    immediately sets its value back to 1\. This allows one of the processes waiting
    for the semaphore to continue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using semaphores, Skylar’s process would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   **Acquire** the semaphore for the guild account.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   Retrieve the balance of the guild account. Call this **Skylar’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   Subtract 300 gold from **Skylar’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 4.   Add 300 gold to Skylar’s personal stash.
  prefs: []
  type: TYPE_NORMAL
- en: 5.   Update the guild bank balance to **Skylar’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 6.   **Release** the semaphore for the guild account.
  prefs: []
  type: TYPE_NORMAL
- en: 'And Trina’s:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   **Acquire** the semaphore for the guild account.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   Retrieve the balance of the guild account. Call this **Trina’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   Subtract 200 gold from Trina’s personal stash.
  prefs: []
  type: TYPE_NORMAL
- en: 4.   Add 200 gold to **Trina’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 5.   Update the guild bank balance to **Trina’s copy**.
  prefs: []
  type: TYPE_NORMAL
- en: 6.   **Release** the semaphore for the guild account.
  prefs: []
  type: TYPE_NORMAL
- en: In this way, Skylar and Trina are prevented from accessing the guild balance
    at the same time, preventing the race condition. Additionally, neither transaction
    will affect any other transaction that doesn’t deal with this particular account.
  prefs: []
  type: TYPE_NORMAL
- en: '**How Semaphores Are Made**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Now let’s look at how semaphores are actually made. If semaphores aren’t implemented
    with care, they can produce the very race conditions they are intended to prevent.
    Although the acquire operation is just one step for Skylar’s and Trina’s processes,
    in reality, it takes several steps itself:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   Retrieve the value of the semaphore.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   If the value is 0, go back to step 1 and try again.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   Set the semaphore to 0.
  prefs: []
  type: TYPE_NORMAL
- en: Now consider what happens if both Skylar’s and Trina’s processes attempt to
    acquire the guild account semaphore at the same time. If the semaphore had a value
    of 1, both processes could retrieve this initial value (in step 1) before either
    had a chance to check the value and set it to 0\. In this case, both processes
    would think that they were the only process that had acquired the semaphore, and
    were therefore free to do whatever they wanted with the accompanying bank balance.
    We’re right back where we started.
  prefs: []
  type: TYPE_NORMAL
- en: To make a semaphore, then, software needs some help from hardware. The processor
    on the bank server must be able to implement the acquire and release operations
    in such a way that nothing can interrupt them. This is known as making the operations
    *atomic*, which in this sense means indivisible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Modern processors implement a hardware operation known as *test-andset*. This
    sets a byte in main memory to a particular value, while retrieving the previous
    value for inspection. Test-and-set makes semaphores possible. In the list of semaphore
    steps, the problem is the potential interruption between steps 1 and 3\. If two
    different processes execute the first step before either reaches the third step,
    both will be able to alter the data that the semaphore is supposed to protect.
    Using the atomic test-and-set operation, though, a semaphore acquire operation
    can be implemented like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   Using test-and-set, set the semaphore to 0 and retrieve the old value.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   If the old value was 0, go back to step 1 and try again.
  prefs: []
  type: TYPE_NORMAL
- en: Now the race condition cannot happen. If two processes attempt to acquire the
    same semaphore at the same time, they will each execute the test-and-set in step
    1\. Both operations will set the semaphore value to 0, but only the semaphore
    that tests-and-sets first will retrieve a 1\. The other process will retrieve
    a 0\. One process will immediately continue, while the other will have to wait.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Problem of Indefinite Waits**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A process acquiring a semaphore using this two-step plan—continuously checking
    the semaphore’s value until it changes back to 1—is said to be in a *spin lock*.
    This is the simplest way to wait for a semaphore to become available, but it has
    two major problems. First, it wastes processor time. A process in a spin lock
    is continuously executing code, but the code isn’t doing anything useful. Secondly,
    spin locks can be unfair. In some cases, some processes cannot check the semaphore
    as fast as others. Perhaps the process is executing on a slower processor, or
    perhaps the process is communicating with a server across a slower network. Regardless
    of the reason, if a semaphore’s resource is so popular that multiple processes
    are always waiting, a slower-checking process might never be able to snag the
    semaphore. This is known as *starvation*; picture the least-assertive person at
    a busy restaurant with only one waiter, and you’ll get the idea.
  prefs: []
  type: TYPE_NORMAL
- en: '***Orderly Queues***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Avoiding starvation requires a more organized approach to waiting. Banks organize
    the wait in their lobbies with cordons, forming groups of waiting customers into
    orderly queues. Semaphores can be designed to do the same thing. Rather than waste
    time continually checking the value of the semaphore, many acquire operations
    written so that when they do not succeed immediately, they put their process to
    sleep, so to speak. Putting a computer or phone to sleep means suspending all
    running applications in a way that allows the applications to be restored quickly.
    In the same way, if a process cannot immediately acquire a semaphore, it will
    be suspended and flushed out of the processor, but its internal data will remain
    in storage.
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish this, the computer’s operating system assigns each process a unique
    identification number. When an acquire operation has to wait, the process identifier
    is placed at the end of that semaphore’s wait list. When the process currently
    holding that semaphore releases it, the first process on the list is awakened.
    In this way, processes acquire the semaphore in the same order they request it.
    A process may have to wait to acquire a popular semaphore, but will eventually
    get to the top of the list— it won’t starve.
  prefs: []
  type: TYPE_NORMAL
- en: '***Starvation from Circular Waits***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although semaphores prevent race conditions when implemented and used correctly,
    they can cause starvation when processes need to access multiple pieces of data
    that are protected by semaphores.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose Skylar and Trina’s guild opens a second account that is accessible to
    lower-ranked guild officers, so now the guild has a main account and a secondary
    account. The banking system has implemented semaphores for each individual account,
    eliminating the chance of a race condition on any guild transactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'But on a particular day, Skylar and Trina are each transferring 200 gold from
    one account to the other in opposite directions. Both transactions involve debiting
    one account and crediting the other. Skylar’s transaction would have these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   **Acquire** the semaphore of the main account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   Retrieve the balance of the main account.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   **Acquire** the semaphore of the secondary account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 4.   Retrieve the balance of the secondary account.
  prefs: []
  type: TYPE_NORMAL
- en: 5.   Add 200 gold to the secondary account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 6.   Subtract 200 gold from the main account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 7.   Update the secondary account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 8.   Update the main account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 9.   **Release** the semaphore of the secondary account.
  prefs: []
  type: TYPE_NORMAL
- en: 10\. **Release** the semaphore of the main account.
  prefs: []
  type: TYPE_NORMAL
- en: 'Trina’s transaction would run like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.   **Acquire** the semaphore of the secondary account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 2.   Retrieve the balance of the secondary account.
  prefs: []
  type: TYPE_NORMAL
- en: 3.   **Acquire** the semaphore of the main account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 4.   Retrieve the balance of the main account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 5.   Add 200 gold to the main account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 6.   Subtract 200 gold from the secondary account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 7.   Update the main account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 8.   Update the secondary account balance.
  prefs: []
  type: TYPE_NORMAL
- en: 9.   **Release** the semaphore of the main account.
  prefs: []
  type: TYPE_NORMAL
- en: 10\. **Release** the semaphore of the secondary account.
  prefs: []
  type: TYPE_NORMAL
- en: Because all shared value access is properly bracketed by the acquisition and
    release of associated semaphores, no race conditions can occur from the overlapping
    execution of these transactions. However, suppose both transactions begin around
    the same time and the first few steps interleave as shown in [Table 8-2](ch08.html#ch8tab2).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 8-2:** Multiple Semaphores Leading to Indefinite Waiting'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Step** | **Description** | **Main account semaphore** | **Secondary account
    semaphore** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  | Initial state. | 1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Skylar 1 | Acquire the semaphore of the main account balance. | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Skylar 2 | Retrieve the balance of the main account. | 0 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Trina 1 | Acquire the semaphore of the secondary account balance. | 0 | 0
    |'
  prefs: []
  type: TYPE_TB
- en: '| Trina 2 | Retrieve the balance of the secondary account. | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Skylar 3 | Acquire the semaphore of the secondary account balance. | 0 |
    0 |'
  prefs: []
  type: TYPE_TB
- en: '| Trina 3 | Acquire the semaphore of the main account balance. | 0 | 0 |'
  prefs: []
  type: TYPE_TB
- en: I’ve shown only these steps because these are the only steps that would occur.
    Both Skylar’s and Trina’s processes would halt at step 3, because both are trying
    to acquire semaphores that aren’t available. What’s worse is that they can never
    become available, because each is being held by the other process. This is like
    waiting for traffic to clear so you can turn left on a two-lane road, but someone
    going the other way wants to turn left behind you, as shown in [Figure 8-3](ch08.html#ch8fig3).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f08-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-3: If both white cars are waiting to turn left, traffic is stopped.*'
  prefs: []
  type: TYPE_NORMAL
- en: Because neither process in this example can continue until the other process
    completes, this situation is known as a *circular wait*. In this case, the circular
    wait involves only two processes, but circular waits sometimes involve many processes,
    and is therefore difficult to detect or foresee. A circular wait is one form of
    *deadlock*, which describes a situation in which a process cannot be expected
    to continue. Circular waits are one way that concurrency can cause deadlocks,
    and unless precautions are taken, a circular wait can occur whenever processes
    hold multiple semaphores at once. Fortunately, such precautions can be easy to
    implement.
  prefs: []
  type: TYPE_NORMAL
- en: One solution is a rule by which semaphores must be acquired in some specified
    order. In our example, the game’s bank management system can internally assign
    each account a number, and require processes to acquire account semaphores in
    numerical order. Or, put more broadly, a process can acquire an account’s semaphore
    only when it does not currently hold a semaphore for an account with a higher
    number. This rule prevents the circular wait in the previous example. Let’s suppose
    the main account is 39785 and the secondary account is 87685\. Because the main
    account number is lower, both Skylar’s and Trina’s processes would attempt to
    acquire its semaphore first. If both processes tried at the same time, only one
    process would succeed. That process would then acquire the semaphore for the secondary
    account and complete the transaction, at which point both account semaphores would
    be released, allowing the other process to continue through completion.
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance Issues of Semaphores**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the proper rules in place, semaphores enable concurrency without fear of
    race conditions, deadlock, or starvation. However, in situations where we are
    trying to boost performance by having multiple processors work together on the
    same job, enforcing these semaphore rules can limit the performance benefit we
    hoped to create. Instead of lots of processors working together, we are left instead
    with lots of processors waiting in line for an opportunity to work. Concurrent
    software can mitigate these performance issues by creating additional rules.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes a process needs access to a piece of data but doesn’t need to change
    it. In our running guild bank example, suppose Skylar and Trina are both inspecting
    the main guild account at the same time—that is, neither player is depositing
    or withdrawing, but is merely checking the balance. In this case, no danger arises
    from the simultaneous access of the account. Even though the processes would have
    potentially overlapping retrieval operations, as long as neither one of them updated
    the balance, everything would be fine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Allowing simultaneous access during “read-only” situations greatly improves
    multiprocessor performance, and requires only a modification of the semaphore
    concept. Instead of having one semaphore for each piece of data to be shared,
    we’ll have two: a *read* semaphore and a *write* semaphore, subject to the following
    rules:'
  prefs: []
  type: TYPE_NORMAL
- en: • Acquiring the associated *write* semaphore allows data to be retrieved or
    updated, just like how the semaphores worked in previous examples.
  prefs: []
  type: TYPE_NORMAL
- en: • Acquiring the associated *read* semaphore allows data to be retrieved, but
    not updated.
  prefs: []
  type: TYPE_NORMAL
- en: • A *write* semaphore can be acquired only when no process holds a semaphore
    (of either type) for that data.
  prefs: []
  type: TYPE_NORMAL
- en: • A *read* semaphore can be acquired only when no process holds a *write* semaphore
    for that data.
  prefs: []
  type: TYPE_NORMAL
- en: Following these rules means that at any given time, either one process will
    have acquired the write semaphore for a piece of data or one or more processes
    will have acquired read semaphores for that data. At first, this appears to be
    what we want. So long as processes are merely looking at, but not changing data,
    they can share access. Once a process needs to change the data, all other processes
    are locked out until the updating process completes its work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, these rules potentially reintroduce the starvation problem.
    As long as read-only processes keep arriving, a process that needs a write semaphore
    might wait indefinitely. To prevent this from happening, we can modify the last
    rule as follows: “a read semaphore can be acquired only when no process is holding
    or waiting for a write semaphore.” In other words, once a process attempts to
    acquire a write semaphore, all processes arriving later must wait behind it.'
  prefs: []
  type: TYPE_NORMAL
- en: Another potential concern for performance is known as *granularity*, which in
    this context refers to whether we lock up individual pieces or collections of
    data. For example, the bank system could use semaphores to protect individual
    data elements, such as the balance of the main guild account, or it could apply
    a single read/write pair for all data related to a particular guild’s finances,
    such as the balances of all guild accounts, the list of guild officers who are
    allowed to access that account, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Protecting data as a group can cause more waiting, because a process that may
    need only one or two numbers in a data group will have to lock up all the data
    in the group, potentially blocking another process that needs other, nonoverlapping
    data from the group. Very fine granularity can also hinder performance. Acquiring
    and releasing semaphores takes time, and with lots of semaphores, it’s possible
    for processes to spend most of their time dealing with them. Developers must therefore
    carefully determine the best granularity for a particular application.
  prefs: []
  type: TYPE_NORMAL
- en: '**What’s Next for Concurrency**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For several reasons, we can expect concurrency to be an even greater concern
    for the future.
  prefs: []
  type: TYPE_NORMAL
- en: These days, multiple processing cores can be found even in our simplest computing
    devices. The push for more processing power will continue, and until the arrival
    of a new processing paradigm like quantum computing, more processing power will
    mean more processor cores.
  prefs: []
  type: TYPE_NORMAL
- en: Multitasking is now the norm. We expect our computing devices to run multiple
    applications at the same time, and to interrupt our foreground tasks when something
    interesting happens in the background.
  prefs: []
  type: TYPE_NORMAL
- en: Data and devices are becoming more connected than ever. Data and processing
    are increasingly being moved from client devices onto servers or clouds of interconnected
    servers. In computer gaming, socialization is the new paradigm, and in some games,
    even single-player game modes require an Internet connection.
  prefs: []
  type: TYPE_NORMAL
- en: In short, properly handling concurrency is becoming essential in everyday computing.
    What looks like a single computer running a single-user application may contain
    a multiprocessor that provides a multitasking environment with shared cloud storage
    for data. The vital power of concurrency is thus often invisible. As the trend
    toward even greater concurrency continues, we may take for granted the way in
    which so many processes work together without running into one another. But future
    improvements in computing depend upon further advancements in concurrency control.
    We don’t know yet whether current methods of preventing deadlock, starvation,
    and race conditions will be sufficient as concurrency increases. If current methods
    are inadequate for solving future challenges, they will become the bottleneck
    until better methods are developed.
  prefs: []
  type: TYPE_NORMAL
