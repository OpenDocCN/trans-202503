- en: '**1'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1'
- en: 'AND AWAY WE GO: AN AI OVERVIEW**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'AND AWAY WE GO: AN AI OVERVIEW**'
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: '[*Artificial intelligence*](glossary.xhtml#glo5) attempts to coax a machine,
    typically a computer, to behave in ways humans judge to be intelligent. The phrase
    was coined in the 1950s by prominent computer scientist John McCarthy (1927–2011).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[*人工智能*](glossary.xhtml#glo5)试图让机器，通常是计算机，按人类认为智能的方式进行行为。这个词汇是在1950年代由著名计算机科学家约翰·麦卡锡（John
    McCarthy，1927–2011）创造的。'
- en: This chapter aims to clarify what AI is and its relationship to [*machine learning*](glossary.xhtml#glo64)
    and [*deep learning*](glossary.xhtml#glo29), two terms you may have heard in recent
    years. We’ll dive in with an example of machine learning in action. Think of this
    chapter as an overview of AI as a whole. Later chapters will build on and review
    the concepts introduced here.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在阐明什么是AI，以及它与[*机器学习*](glossary.xhtml#glo64)和[*深度学习*](glossary.xhtml#glo29)的关系，这两个术语你可能在近年来听说过。我们将通过一个机器学习实例来深入探讨。可以把本章看作是AI的概述，后续章节将进一步扩展并复习这里介绍的概念。
- en: '****'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: Computers are *programmed* to carry out a particular task by giving them a sequence
    of instructions, a *program*, which embodies an [*algorithm*](glossary.xhtml#glo2),
    or the recipe that the program causes the computer to execute.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机被*编程*以执行特定的任务，方法是给它们一系列指令，即*程序*，程序体现了[*算法*](glossary.xhtml#glo2)，或者说程序让计算机执行的“配方”。
- en: The word [*algorithm*](glossary.xhtml#glo2) is cast about often these days,
    though it isn’t new; it’s a corruption of *Al-Khwarizmi*, referring to ninth-century
    Persian mathematician Muhammad ibn Musa al-Khwarizmi, whose primary gift to the
    world was the mathematics we call *algebra*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，“[*算法*](glossary.xhtml#glo2)”这个词常常被提及，尽管它并不新鲜；它源自阿尔·花拉子米（Al-Khwarizmi），这是指9世纪波斯数学家穆罕默德·伊本·穆萨·阿尔·花拉子米，他对世界的主要贡献就是我们今天所称的*代数*。
- en: '****'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: Let’s begin with a story.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个故事开始。
- en: Tonya owns a successful hot sauce factory. The hot sauce recipe is Tonya’s own,
    and she guards it carefully. It’s literally her secret sauce, and only she understands
    the process of making it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 托尼娅拥有一家成功的辣酱工厂。辣酱的配方是托尼娅自己创造的，她小心翼翼地保守这个秘密。它确实是她的“秘密酱”，只有她知道制作它的全过程。
- en: Tonya employs one worker for each step of the hot sauce–making process. These
    are human workers, but Tonya treats them as if they were machines because she’s
    worried they’ll steal her hot sauce recipe—and because Tonya is a bit of a monster.
    In truth, the workers don’t mind much because she pays them well, and they laugh
    at her behind her back.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 托尼娅为每一步辣酱制作过程雇佣了一名工人。这些工人是人类，但托尼娅把他们当作机器看待，因为她担心他们会偷走她的辣酱配方——而且托尼娅有点怪。在事实上，工人们并不介意，因为她支付的报酬丰厚，而且他们在背后偷偷嘲笑她。
- en: 'Tonya’s recipe is an algorithm; it’s the set of steps that must be followed
    to create the hot sauce. The collection of instructions Tonya uses to tell her
    workers how to make the hot sauce is a program. The program embodies the algorithm
    in a way that the workers (the machine) can follow step by step. Tonya has programmed
    her workers to implement her algorithm to create hot sauce. The sequence looks
    something like this:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 托尼娅的配方就是一个算法；它是制作辣酱所必须遵循的一系列步骤。托尼娅用来告诉工人如何制作辣酱的指令集合就是程序。程序以一种方式体现了算法，使得工人（即机器）可以一步步地执行。托尼娅已经将自己的算法编程成工人能够遵循的流程来制作辣酱。这个顺序大致如下：
- en: '![Image](../images/ch01fig00.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch01fig00.jpg)'
- en: There are a few things to note about this scenario. First, Tonya is definitely
    a monster for treating human beings as machines. Second, at no point in the process
    of making hot sauce does any worker need to understand why they do what they do.
    Third, the programmer (Tonya) knows why the machine (the workers) does what it
    does, even if the machine doesn’t.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个方面需要注意。首先，托尼娅把人类当作机器对待，显然是个怪物。其次，在制作辣酱的过程中，任何工人都不需要理解自己为什么要做某件事。第三，程序员（托尼娅）知道机器（工人）做某事的原因，即便机器自己并不清楚。
- en: '****'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: What I’ve just described is how we’ve controlled virtually all computers, going
    back to the first conceptual machines envisioned by Alan Turing in the 1930s and
    even earlier to the 19th-century Analytical Engine of Charles Babbage. A human
    conceives an algorithm, then translates that algorithm into a sequence of steps
    (a program). The machine executes the program, thereby implementing the algorithm.
    The machine doesn’t understand what it’s doing; it’s simply performing a series
    of primitive instructions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我刚才描述的是我们如何控制几乎所有的计算机，这可以追溯到艾伦·图灵在 1930 年代构思的第一台概念性机器，甚至更早，可以追溯到19世纪查尔斯·巴贝奇的分析引擎。一个人设计出一个算法，然后将该算法翻译成一系列步骤（一个程序）。计算机执行该程序，从而实现算法。计算机并不理解它在做什么；它只是执行一系列原始的指令。
- en: The genius of Babbage and Turing lay in the realization that there could be
    a general-purpose machine capable of executing arbitrary algorithms via programs.
    However, I would argue that it was Ada Lovelace, a friend of Babbage’s often regarded
    as the world’s first programmer, who initially understood the far-reaching possibilities
    of what we now call a computer. We’ll talk more about Turing, Babbage, and Lovelace
    in [Chapter 2](ch02.xhtml).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 巴贝奇和图灵的天才在于意识到，可以有一台通用的计算机，通过程序执行任意的算法。然而，我认为是巴贝奇的朋友，常被认为是世界上第一位程序员的阿达·洛夫莱斯，最初理解了我们现在所说的计算机的深远可能性。我们将在[第2章](ch02.xhtml)中详细讨论图灵、巴贝奇和洛夫莱斯。
- en: '**NOTE**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**备注**'
- en: '*In Lovelace’s day, a “computer” was not a machine but a human being who calculated
    by hand. Hence, Babbage’s Engine was a mechanical computer.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*在洛夫莱斯时代，“计算机”不是一台机器，而是一个通过手工计算的人工智能。因此，巴贝奇的引擎是一台机械计算机。*'
- en: Let’s take a moment to explore the relationship between the terms *AI*, [*machine
    learning*](glossary.xhtml#glo64), and [*deep learning*](glossary.xhtml#glo29).
    On the one hand, all three have become synonymous as referring to modern AI. This
    is wrong, but convenient. [Figure 1-1](ch01.xhtml#ch01fig01) shows the proper
    relationship between the terms.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花一点时间探讨一下*AI*、[*机器学习*](glossary.xhtml#glo64)和[*深度学习*](glossary.xhtml#glo29)这几个术语之间的关系。一方面，三者已成为现代AI的代名词。这是错误的，但很方便。[图
    1-1](ch01.xhtml#ch01fig01)显示了这些术语之间的正确关系。
- en: '![Image](../images/ch01fig01.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../images/ch01fig01.jpg)'
- en: '*Figure 1-1: The relationship between artificial intelligence, machine learning,
    and deep learning*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1-1：人工智能、机器学习和深度学习之间的关系*'
- en: Deep learning is a subfield of machine learning, which is a subfield of artificial
    intelligence. This relationship implies that AI involves concepts that are neither
    machine learning nor deep learning. We’ll call those concepts *old-school AI*,
    which includes the algorithms and approaches developed from the 1950s onward.
    Old-school AI is not what people currently mean when discussing AI. Going forward,
    we’ll entirely (and unfairly) ignore this portion of the AI universe.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子领域，而机器学习是人工智能的一个子领域。这种关系意味着AI涉及的概念既不属于机器学习，也不属于深度学习。我们将这些概念称为*传统AI*，它包括自1950年代以来发展起来的算法和方法。传统AI并不是人们当前讨论AI时所指的内容。接下来，我们将完全（且不公平地）忽视AI领域的这一部分。
- en: '[*Machine learning*](glossary.xhtml#glo64) builds models from data. For us,
    a [*model*](glossary.xhtml#glo69) is an abstract notion of something that accepts
    inputs and generates outputs, where the inputs and outputs are related in some
    meaningful way. The primary goal of machine learning is to condition a model using
    *known* data so that the model produces meaningful output when given *unknown*
    data. That’s about as clear as muddy water, but bear with me; the mud will settle
    in time.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[*机器学习*](glossary.xhtml#glo64)从数据中构建模型。对我们来说，[*模型*](glossary.xhtml#glo69)是一个抽象的概念，它接受输入并生成输出，其中输入和输出以某种有意义的方式相关联。机器学习的主要目标是利用*已知*数据来训练模型，使得当模型接收到*未知*数据时能够生成有意义的输出。听起来有点模糊，但请耐心等待；这些模糊的部分会随着时间的推移得到澄清。'
- en: '[*Deep learning*](glossary.xhtml#glo29) uses large models of the kind previously
    too big to make useful. More muddy water, but I’m going to argue that there’s
    no strict definition of deep learning other than that it involves neural networks
    with many layers. [Chapter 4](ch04.xhtml) will clarify.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[*深度学习*](glossary.xhtml#glo29)使用以前过于庞大而无法实用的大型模型。更多的模糊水，但我将辩称，深度学习没有严格的定义，除了它涉及到有许多层的神经网络。[第4章](ch04.xhtml)将进一步澄清。'
- en: In this book, we’ll be sloppy but in accord with popular usage, even by experts,
    and take “deep learning” to mean large neural networks (yet to be formally defined),
    “machine learning” to mean models conditioned by data, and “AI” to be a catchall
    for both machine learning and deep learning—remembering that there is more to
    AI than what we discuss here.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将随意使用，但与大众的习惯一致，甚至专家也常这么做，把“深度学习”理解为大型神经网络（尚未正式定义），把“机器学习”理解为由数据条件化的模型，把“人工智能”视为机器学习和深度学习的统称——记住，人工智能不仅仅是我们在这里讨论的内容。
- en: Data is everything in AI. I can’t emphasize this enough. Models are blank slates
    that data must condition to make them suitable for a task. If the data is bad,
    the model is bad. Throughout the book, we’ll return to this notion of “good” and
    “bad” data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据在人工智能中至关重要。我无法强调这一点的重要性。模型是空白的画布，必须通过数据来条件化，以使其适用于某个任务。如果数据不好，模型就不好。在本书中，我们将不断回到“好”数据和“坏”数据这一概念。
- en: For now, let’s focus on what a model is, how it’s made useful by conditioning,
    and how it’s used after conditioning. All this talk of conditioning and using
    sounds dark and sinister, if not altogether evil, but, I assure you, it’s not,
    even though we have ways of making the model talk.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们聚焦于模型是什么、如何通过条件化使它变得有用，以及在条件化后如何使用它。所有关于条件化和使用的讨论听起来都阴暗而邪恶，甚至可以说充满了威胁，但我向你保证，它并非如此，尽管我们确实有一些方法让模型“说话”。
- en: '****'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: A machine learning model is a black box that accepts an input, usually a collection
    of numbers, and produces an output, typically a label like “dog” or “cat,” or
    a continuous value like the probability of being a “dog” or the value of a house
    with the characteristics given to the model (size, number of bathrooms, ZIP code,
    and so on).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型是一个黑箱，它接受一个输入，通常是一组数字，然后产生一个输出，通常是一个标签，比如“狗”或“猫”，或者是一个连续值，如“狗”的概率，或者给定特征（大小、浴室数量、邮政编码等）后房子的价值。
- en: The model has [*parameters*](glossary.xhtml#glo80), which control the model’s
    output. Conditioning a model, known as [*training*](glossary.xhtml#glo96), seeks
    to set the model’s parameters in such a way that they produce the correct output
    for a given input.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 模型有[*参数*](glossary.xhtml#glo80)，它们控制着模型的输出。条件化模型，也叫做[*训练*](glossary.xhtml#glo96)，旨在设置模型的参数，使其在给定输入时产生正确的输出。
- en: 'Training implies that we have a collection of inputs, and the outputs the model
    should produce when given those inputs. At first blush, this seems a bit silly;
    why do we want the model to give us an output we already have? The answer is that
    we will, at some future point, have inputs for which we don’t already have the
    output. This is the entire point of making the model: to use it with unknown inputs
    and to believe the model when it gives us an output.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 训练意味着我们有一组输入，以及当给定这些输入时，模型应该产生的输出。乍一看，这似乎有点傻；为什么我们要让模型给出我们已经拥有的输出呢？答案是，在未来某个时刻，我们会有一些输入，而我们并没有已有的输出。这正是构建模型的全部意义：使用它来处理未知的输入，并相信它在给出输出时的可靠性。
- en: Training uses the collection of known inputs and outputs to adjust the model’s
    parameters to minimize mistakes. If we can do that, we begin to believe the model’s
    outputs when given new, unknown inputs.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 训练使用已知的输入和输出集合来调整模型的参数，以最小化错误。如果我们能够做到这一点，我们就能在给定新的、未知的输入时开始相信模型的输出。
- en: Training a model is fundamentally different from programming. In programming,
    we implement the algorithm we want by instructing the computer step by step. In
    training, we use data to teach the model to adjust its parameters to produce correct
    output. There is no programming because, most of the time, we have no idea what
    the algorithm should be. We only know or believe a relationship exists between
    the inputs and the desired outputs. We hope a model can approximate that relationship
    well enough to be useful.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 训练一个模型与编程是根本不同的。在编程中，我们通过逐步指示计算机来实现我们想要的算法。而在训练中，我们使用数据教模型调整其参数，以产生正确的输出。没有编程，因为大多数时候我们根本不知道算法应该是什么。我们只知道或相信输入和期望输出之间存在某种关系。我们希望模型能够足够好地逼近这种关系，使其变得有用。
- en: It’s worth remembering the sage words of British statistician George Box, who
    said that all models are wrong, but some are useful. At the time, he was referring
    to other kinds of mathematical models, but the wisdom applies to machine learning.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 值得记住英国统计学家乔治·博克斯的名言：“所有模型都是错误的，但有些是有用的。”当时他指的是其他类型的数学模型，但这一智慧同样适用于机器学习。
- en: 'Now we understand why the field is called machine learning: we teach the machine
    (model) by giving it data. We don’t program the machine; we instruct it.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们明白了为什么这个领域叫做机器学习：我们通过给机器（模型）提供数据来教它。我们不是在编程机器，而是在指示它。
- en: 'Here, then, is the machine learning algorithm:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这就是机器学习算法：
- en: Gather a training dataset consisting of a collection of inputs to the model
    and the outputs we expect from the model for those inputs.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集一个训练数据集，包含一组模型的输入和我们期望模型针对这些输入产生的输出。
- en: Select the type of model we want to train.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择我们想要训练的模型类型。
- en: Train the model by presenting the training inputs and adjusting the model’s
    parameters when it gets the outputs wrong.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过呈现训练输入并在模型输出错误时调整模型的参数来训练模型。
- en: Repeat step 3 until we are satisfied with the model’s performance.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤3，直到我们对模型的表现满意为止。
- en: Use the now-trained model to produce outputs for new, unknown inputs.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用现在训练好的模型为新的、未知的输入产生输出。
- en: 'Most of machine learning follows this algorithm. Since we’re using known *labeled
    data* to train the model, this approach is called *supervised learning*: we supervise
    the model while it learns to produce correct output. In a sense, we punish the
    model until it gets it right. This is a dark enterprise, after all.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习遵循这一算法。由于我们使用已知的 *标签数据* 来训练模型，这种方法被称为 *监督学习*：我们在模型学习如何产生正确输出时进行监督。从某种意义上讲，我们会惩罚模型，直到它做对为止。毕竟，这是一项黑暗的事业。
- en: We’re ready for an example, but let’s first summarize the story so far. We want
    a system where, for an unknown input, we get a meaningful output. To make the
    system, we train a machine learning model using a collection of inputs and their
    known outputs. Training conditions the model by modifying its parameters to minimize
    the mistakes it makes on the training data. When we’re satisfied with the model’s
    performance, we use the model with unknown inputs because we now believe the model
    when it gives us an output (at least, most of the time).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好进行一个示例，但让我们先总结一下目前为止的内容。我们希望构建一个系统，对于一个未知输入，能够得到一个有意义的输出。为了构建这个系统，我们通过一组已知输出的输入数据来训练一个机器学习模型。训练通过调整模型的参数，减少它在训练数据上所犯的错误，从而使模型得到调教。当我们对模型的表现满意时，我们就可以使用这个模型来处理未知输入，因为我们现在相信模型在给出输出时是可靠的（至少，大部分时间是这样）。
- en: Our first example comes from a famous dataset consisting of measurements of
    the parts of iris flowers. This dataset is from the 1930s, indicating how long
    people have contemplated what we now call machine learning.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个示例来自一个著名的数据集，包含了鸢尾花部位的测量数据。这个数据集来自1930年代，表明人们早在很久以前就开始思考我们现在所称之为机器学习的领域。
- en: 'The goal is a model that, for an input collection of measurements, outputs
    the specific species of iris flower. The full dataset has four measurements for
    three iris species. We’ll keep it simple and use two measurements and two species:
    petal length and width in centimeters (cm) for *I. setosa* versus *I. versicolor*.
    Therefore, we want the model to accept two measurements as input and give us an
    output we can interpret as *I. setosa* or *I. versicolor*. *Binary models* like
    this decide between two possible outputs and are common in AI. If the model decides
    between more than two categories, it’s a *multiclass* model.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是得到一个模型，该模型对于一组测量值的输入，能够输出特定种类的鸢尾花。完整的数据集包含了三种鸢尾花的四个测量值。为了简化，我们只使用两个测量值和两种花种：*I.
    setosa* 和 *I. versicolor* 的花瓣长度和宽度（单位：厘米）。因此，我们希望模型接受两个测量值作为输入，并给出我们可以解释为 *I.
    setosa* 或 *I. versicolor* 的输出。像这样的 *二分类模型* 会在两个可能的输出之间做出选择，并且在人工智能中很常见。如果模型在多个类别之间做出选择，那么它就是
    *多类模型*。
- en: 'We have 100 samples in our dataset: 100 pairs of petal measurements, and the
    corresponding iris flower types. We’ll call *I. setosa* class 0 and *I. versicolor*
    class 1, where *class* labels the input categories.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集包含100个样本：100对花瓣测量值以及对应的鸢尾花类型。我们将 *I. setosa* 称为类别0，将 *I. versicolor* 称为类别1，其中
    *类别* 用来标记输入的类别。
- en: Models often want numeric class labels, which tells us that models don’t know
    what their inputs and outputs mean; they only make associations between sets of
    inputs and outputs. Models don’t “think” using any commonly accepted definition
    of the word. (The models of [Chapter 7](ch07.xhtml) might beg to differ, but more
    on that then.)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 模型通常需要数字类别标签，这告诉我们模型并不知道它的输入和输出意味着什么；它们只是对一组输入和输出之间的关联进行建模。模型并不“思考”，按照任何常见的定义。（[第七章](ch07.xhtml)的模型可能会有不同的看法，但我们会在那时讨论更多内容。）
- en: '****'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: Here we must pause to introduce some critical terminology. I know, not what
    you want to read, but it’s essential to all that follows. Artificial intelligence
    makes frequent use of vectors and matrices (singular “matrix”). A *vector* is
    a string of numbers treated as a single entity. For example, the four measurements
    of each iris flower mean we can represent the flower as a string of four numbers,
    say, (4.5, 2.3, 1.3, 0.3). The flower described by this vector has a sepal length
    of 4.5 cm, sepal width of 2.3 cm, petal length of 1.3 cm, and petal width of 0.3
    cm. By grouping these measurements together, we can refer to them as a single
    entity.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们必须暂停一下，介绍一些关键术语。我知道，这不是你想阅读的内容，但它对接下来的内容至关重要。人工智能经常使用向量和矩阵（单数形式为“矩阵”）。*向量*是一个作为单一实体处理的数字串。例如，每朵鸢尾花的四个测量值意味着我们可以用四个数字来表示这朵花，例如（4.5，2.3，1.3，0.3）。通过这个向量描述的花朵，其花萼长度为4.5厘米，花萼宽度为2.3厘米，花瓣长度为1.3厘米，花瓣宽度为0.3厘米。通过将这些测量值组合在一起，我们可以将它们视为一个单一实体。
- en: 'The number of elements in a vector determines its dimensionality; for example,
    the iris dataset uses four-dimensional vectors, the four measurements of the flower.
    AI often works with inputs that have hundreds or even thousands of dimensions.
    If the input is an image, every pixel of that image is one dimension, meaning
    a small 28-pixel-square image becomes an input vector of 28×28, or 784 dimensions.
    The concept is the same in 3 dimensions or 33,000 dimensions: it remains a string
    of numbers treated as a single entity. But an image has rows and columns, making
    it a two-dimensional array of numbers, not a string. Two-dimensional arrays of
    numbers are *matrices*. In machine learning, we often represent datasets as matrices,
    where the rows are vectors representing the elements of the dataset, like an iris
    flower, and the columns are the measurements. For example, the first five flowers
    in the iris dataset form the following matrix:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 向量中元素的数量决定了它的维度；例如，鸢尾花数据集使用四维向量，表示花朵的四个测量值。人工智能通常处理具有数百甚至数千维的输入。如果输入是图像，那么图像的每个像素就是一个维度，这意味着一个小的28×28像素的图像将成为一个28×28或784维的输入向量。这个概念在三维或33,000维中都是一样的：它仍然是一个作为单一实体处理的数字串。但图像有行和列，使得它成为一个二维数组，而不是一个字符串。二维数字数组就是*矩阵*。在机器学习中，我们通常将数据集表示为矩阵，其中行是表示数据集元素的向量，如一朵鸢尾花，而列是各个测量值。例如，鸢尾花数据集中的前五朵花形成如下矩阵：
- en: '![Image](../images/math10.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/math10.jpg)'
- en: Each row is a flower. Notice that the first row matches the vector example.
    The remaining rows list the measurements for other flowers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行代表一朵花。请注意，第一行与向量示例相匹配。其余的行列出了其他花朵的测量值。
- en: 'While you’re reading, keep these thoughts in the back of your mind:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在你阅读时，请将以下想法记在心里：
- en: Vectors are strings of numbers often representing measurements in a dataset.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量是数字的串，通常表示数据集中的测量值。
- en: Matrices are two-dimensional arrays of numbers often representing datasets (stacks
    of vectors).
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵是二维数字数组，通常表示数据集（向量堆叠）。
- en: As we continue our exploration of AI, the differences between vectors and matrices
    will come into focus. Now, let’s return to our story.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续探索人工智能，向量和矩阵之间的差异将逐渐显现。现在，让我们回到我们的故事。
- en: '****'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: The inputs to a model are its [*features*](glossary.xhtml#glo42). Our iris flower
    dataset has two features, the petal’s length and width, which are grouped into
    [*feature vectors*](glossary.xhtml#glo43) (or *samples*). A single feature vector
    serves as the model’s input. A binary model’s output is typically a number relating
    to the model’s belief that the input belongs to class 1\. For our example, we’ll
    give the model a feature vector consisting of two features and expect an output
    that lets us decide whether we should call the input *I. versicolor*. If not,
    we declare the input to be *I. setosa* because we *assume* that inputs will always
    be one or the other.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的输入是其[*特征*](glossary.xhtml#glo42)。我们的鸢尾花数据集有两个特征，花瓣的长度和宽度，这些特征被归类为[*特征向量*](glossary.xhtml#glo43)（或*样本*）。一个特征向量作为模型的输入。二分类模型的输出通常是一个数字，表示模型认为输入属于类别1的概率。对于我们的示例，我们将向模型提供一个由两个特征组成的特征向量，并期望得到一个输出，帮助我们决定是否应将输入标记为*I.
    versicolor*。如果不是，我们就将输入标记为*I. setosa*，因为我们*假设*输入总是属于其中之一。
- en: Machine learning etiquette states that we should test our model; otherwise,
    how will we know it’s working? You might think it’s working when it gets all the
    training samples right, but experience has taught practitioners this isn’t always
    the case. The proper way to test a model is to keep some of the labeled training
    data to use after training. The model’s performance on this held-out test dataset
    better indicates how well the model has learned. We’ll use 80 labeled samples
    for training and keep 20 of them for testing, making sure that both the training
    and test sets contain an approximately even mix of both classes (flower types).
    This is also essential in practice, as far as possible. If we never show the model
    examples of a particular class of input, how can it learn to distinguish that
    class from others?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的礼仪规定，我们应该测试我们的模型；否则，怎么知道它是否有效呢？你可能会认为当模型把所有训练样本都预测正确时，它就有效，但经验告诉我们，这并不总是如此。正确的测试模型的方法是保留一些标注过的训练数据，用于训练后测试。模型在这些保留的测试数据集上的表现，能更好地反映模型学习的效果。我们将使用80个标注样本进行训练，保留20个用于测试，确保训练集和测试集大致包含相同比例的两类（花的种类）。在实践中，这一点也是至关重要的。若我们从未向模型展示某类输入数据，它又怎能学会区分该类和其他类呢？
- en: 'Using a held-out test set to judge the performance of a model isn’t just etiquette.
    It addresses a foundational issue in machine learning: generalization. Some machine
    learning models follow a process quite similar to a widely used approach known
    as *optimization*. Scientists and engineers use optimization to fit measured data
    to known functions; machine learning models also use optimization to condition
    their parameters, but the goal is different. Fitting data to a function, like
    a line, seeks to create the best possible *fit*, or the line that best explains
    the measured data. In machine learning, we instead want a model that learns the
    general characteristics of the training data to *generalize* to new data. That’s
    why we evaluate the model with the held-out test set. To the model, the test set
    contains new, unseen data it didn’t use to modify its parameters. The model’s
    performance on the test set is a clue to its generalization abilities.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用保留的测试集来判断模型的表现不仅仅是礼仪问题，它还涉及机器学习中的一个基础问题：泛化。一些机器学习模型遵循的过程与一个广泛使用的方法——*优化*——非常相似。科学家和工程师使用优化方法将测量数据拟合到已知的函数；机器学习模型也使用优化方法来调节其参数，但目标不同。拟合数据到一个函数，如拟合一条线，目的是创造最佳的*拟合*，即最能解释测量数据的那条线。而在机器学习中，我们的目标是训练一个模型，让它学会训练数据的一般特征，以便能够*泛化*到新的数据上。这就是为什么我们使用保留的测试集来评估模型的原因。对模型而言，测试集包含了它未曾使用过的、未知的数据，模型没有用这些数据来调整其参数。模型在测试集上的表现，是它泛化能力的线索。
- en: Our example has two input features, meaning the feature vectors are two-dimensional.
    Since we have two dimensions, we can opt to make a plot of the training dataset.
    (If we have two or three features in a feature vector, we can plot the feature
    vectors. However, most feature vectors have hundreds to thousands of features.
    I don’t know about you, but I can’t visualize a thousand-dimensional space.)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例有两个输入特征，这意味着特征向量是二维的。由于只有两个维度，我们可以选择绘制训练数据集的图形。（如果特征向量有两个或三个特征，我们可以绘制这些特征向量。然而，大多数特征向量有成百上千个特征。我不知道你怎么样，但我无法可视化一个千维的空间。）
- en: '[Figure 1-2](ch01.xhtml#ch01fig02) displays the two-dimensional iris training
    data; the *x*-axis is petal length, and the *y*-axis is petal width. The circles
    correspond to instances of *I. setosa* and the squares *I. versicolor*. Each circle
    or square represents a single training sample, the petal length and width for
    a specific flower. To place each point, find the petal length on the *x*-axis
    and the petal width on the *y*-axis. Then, move up from the *x*-axis and to the
    right from the *y*-axis. Where your fingers meet is the point representing that
    flower. If the flower is *I. setosa*, make the point a circle; otherwise, make
    it a square.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-2](ch01.xhtml#ch01fig02)展示了二维鸢尾花训练数据；*x*轴为花瓣长度，*y*轴为花瓣宽度。圆圈表示*I. setosa*的实例，方块表示*I.
    versicolor*的实例。每个圆圈或方块代表一个单独的训练样本，即某一朵花的花瓣长度和花瓣宽度。为了定位每个点，首先找到花瓣长度在*x*轴的位置，再找到花瓣宽度在*y*轴的位置。然后，从*x*轴向上移动，从*y*轴向右移动。手指相遇的地方即为代表该花朵的点。如果该花是*I.
    setosa*，则用圆圈表示该点；否则，用方块表示该点。'
- en: '![Image](../images/ch01fig02.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/ch01fig02.jpg)'
- en: '*Figure 1-2: The iris training data*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1-2：鸢尾花训练数据*'
- en: The plot in [Figure 1-2](ch01.xhtml#ch01fig02) shows the *feature space* of
    the training set. In this case, we can visualize the training set directly, because
    we only have two features. When that’s not possible, all is not lost. Advanced
    algorithms exist that allow us to make plots like [Figure 1-2](ch01.xhtml#ch01fig02)
    where the points in two or three dimensions reflect the distribution of the samples
    in the much higher-dimensional space. Here, the word *space* means much the same
    as it does in everyday parlance.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-2](ch01.xhtml#ch01fig02)中的图示展示了训练集的*特征空间*。在这种情况下，我们可以直接可视化训练集，因为我们只有两个特征。当不可行时，也并非毫无办法。存在一些先进的算法，允许我们制作像[图
    1-2](ch01.xhtml#ch01fig02)那样的图，其中二维或三维中的点反映了样本在更高维空间中的分布。在这里，*空间*一词与日常语言中的含义几乎相同。'
- en: Look carefully at [Figure 1-2](ch01.xhtml#ch01fig02). Does anything jump out
    at you? Are the different classes mixed or well separated? Every circle inhabits
    the lower-left corner of the plot, while all of the squares are in the upper right.
    There is no overlap between the classes, meaning they are entirely separate in
    the feature space.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细看看[图 1-2](ch01.xhtml#ch01fig02)。你看到什么了吗？不同的类别是混杂在一起还是分得很清楚？每个圆圈都位于图示的左下角，而所有方块都在右上角。类别之间没有重叠，这意味着它们在特征空间中完全分开。
- en: How can we use this fact to make a [*classifier*](glossary.xhtml#glo15), a model
    that classifies iris flowers? (While [*model*](glossary.xhtml#glo69) is the more
    general term, as not all models place their inputs into categories, when they
    do, use the term *classifier*.)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何利用这一事实来构建一个[*分类器*](glossary.xhtml#glo15)，一个分类鸢尾花的模型呢？（虽然[*模型*](glossary.xhtml#glo69)是更为通用的术语，因为并非所有模型都会将输入分到类别中，但当它们这样做时，我们使用术语*分类器*。）
- en: We have many model types to choose from for our classifier, including [*decision
    trees*](glossary.xhtml#glo28), which generate a series of yes/no questions related
    to the features used to decide the class label to output for a given input. When
    the questions are laid out visually, they form a structure reminiscent of an upside-down
    tree. Think of a decision tree as a computer-generated version of the game *20
    Questions*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有许多模型类型可以选择作为我们的分类器，包括[*决策树*](glossary.xhtml#glo28)，它们生成一系列与特征相关的“是/否”问题，用于决定针对给定输入输出的类别标签。当这些问题以视觉形式展示时，它们形成了一种类似倒置树形的结构。可以把决策树看作是计算机生成版的“*20个问题*”游戏。
- en: 'Even though we have two features, petal length and petal width, we can classify
    new iris flowers by asking a single question: is the petal length less than 2.5
    cm? If the answer is “yes,” then return class 0, *I. setosa*; otherwise, return
    class 1, *I. versicolor*. To classify the training data correctly, we need only
    the answer to this simple question.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们有两个特征，花瓣长度和花瓣宽度，但我们可以通过询问一个简单的问题来分类新的鸢尾花：花瓣长度是否小于2.5厘米？如果答案是“是”，则返回类别0，*I.
    setosa*；否则，返回类别1，*I. versicolor*。为了正确分类训练数据，我们只需要这个简单问题的答案。
- en: Did you catch what I did just now? I said that the question correctly classifies
    all the *training* data. What about the 20 test samples we didn’t use? Is our
    single-question classifier sufficient to give each of them the correct label?
    In practice, that’s what we want to know, and that is what we would report as
    the classifier’s performance.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你明白我刚才做了什么吗？我说问题正确地对所有*训练*数据进行了分类。那么我们没有使用的那20个测试样本呢？我们的单问题分类器足够为每一个测试样本分配正确的标签吗？实际上，这正是我们想要了解的内容，这也是我们会报告的分类器的表现。
- en: '[Figure 1-3](ch01.xhtml#ch01fig03) shows the training data again, along with
    the test data we didn’t use to make our single-question classifier. The solid
    circles and squares represent the test data.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-3](ch01.xhtml#ch01fig03)再次展示了训练数据，以及我们没有用于构建单问题分类器的测试数据。实心圆圈和方块表示测试数据。'
- en: '![Image](../images/ch01fig03.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch01fig03.jpg)'
- en: '*Figure 1-3: The iris training data with the held-out test data (solid)*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1-3：包含保留的测试数据（实心）的鸢尾花训练数据*'
- en: None of the test data violates our rule; we still get correct class labels by
    asking if the petal length is less than 2.5 cm. Therefore, our model is perfect;
    it makes no mistakes. Congratulations, you just created your first machine learning
    model!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何测试数据违反我们的规则；我们仍然通过询问花瓣长度是否小于2.5厘米来获得正确的类别标签。因此，我们的模型是完美的；它没有犯任何错误。恭喜你，你刚刚创建了你的第一个机器学习模型！
- en: We should be happy, but not too happy. Let’s repeat this exercise, replacing
    *I. setosa* with the remaining iris species, *I. virginica*. This leads to [Figure
    1-4](ch01.xhtml#ch01fig04), where the triangles are instances of *I. virginica*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该感到高兴，但不要太高兴。让我们重复这个练习，将*I. setosa*替换为剩余的鸢尾花种类，*I. virginica*。这将导致[图1-4](ch01.xhtml#ch01fig04)，其中三角形表示*I.
    virginica*的实例。
- en: '![Image](../images/ch01fig04.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/ch01fig04.jpg)'
- en: '*Figure 1-4: The new iris training data*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1-4：新的鸢尾花训练数据*'
- en: Hmm, things are not as clear-cut now. The obvious gap between the classes is
    gone, and they overlap.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，现在情况变得不那么清晰了。类别之间的明显差距消失了，它们开始重叠。
- en: I trained a decision tree using this new iris dataset. As before, there were
    80 samples for training and 20 held back for testing. This time, the model wasn’t
    perfect. It correctly labeled 18 of the 20 samples, for an accuracy of 9 out of
    10, or 90 percent. This roughly means that when this model assigns a flower to
    a particular class, there is a 90 percent chance it’s correct. The previous sentence,
    to be rigorous, needs careful clarification, but for now, you get the idea—machine
    learning models are not always perfect; they (quite frequently) make mistakes.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用这个新的鸢尾花数据集训练了一个决策树。像之前一样，有80个样本用于训练，20个样本被留作测试。这次，模型并不完美。它正确标记了20个样本中的18个，准确率为9/10，即90%。这大致意味着，当该模型将花卉分配到特定类别时，正确的概率是90%。为了严谨起见，上一句话需要仔细澄清，但现在你明白了——机器学习模型并不总是完美的；它们（相当频繁地）会犯错误。
- en: '[Figure 1-5](ch01.xhtml#ch01fig05) shows the learned decision tree. Begin at
    the top, which is the root, and answer the question in that box. If the answer
    is “yes,” move to the box on the left; otherwise, move to the right. Keep answering
    and moving in this way until you arrive at a leaf: a box with no arrows. The label
    in this box is assigned to the input.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-5](ch01.xhtml#ch01fig05)显示了学习到的决策树。从顶部开始，那是根节点，并回答该框中的问题。如果答案是“是”，则移到左侧的框；否则，移到右侧。继续以这种方式回答问题并移动，直到到达一个叶节点：没有箭头的框。该框中的标签被分配给输入。'
- en: '![Image](../images/ch01fig05.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/ch01fig05.jpg)'
- en: '*Figure 1-5: The decision tree for* I. virginica *versus* I. versicolor'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1-5：I. virginica与I. versicolor的决策树*'
- en: The first decision tree classifier was trivial, as the answer to a single question
    was sufficient to decide class membership. The second decision tree classifier
    is more common. Most machine learning models are not particularly simple. Though
    their operation is comprehensible, understanding why they act as they do is an
    entirely different matter. Decision trees are among the few model types that readily
    explain themselves. For any input, the path traversed from root to leaf in [Figure
    1-5](ch01.xhtml#ch01fig05) explains in detail why the input received a particular
    label. The neural networks behind modern AI are not so transparent.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个决策树分类器是微不足道的，因为回答一个简单的问题就足以决定类别成员身份。第二个决策树分类器则更为常见。大多数机器学习模型并不特别简单。虽然它们的运作是可以理解的，但理解它们为何如此运作是完全不同的事情。决策树是少数几种可以自我解释的模型类型之一。对于任何输入，路径从根节点到叶节点的过程在[图1-5](ch01.xhtml#ch01fig05)中详细解释了为什么该输入被分配了特定的标签。而现代AI背后的神经网络则不那么透明。
- en: '****'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: For a model to perform well “in the wild,” meaning when used in the real world,
    the data used to train the model must cover the entire range of inputs that the
    model might encounter. For example, say we want a model to identify pictures of
    dogs, and our training set contains images of only dogs and parrots. While the
    model performs well on our held-out test set, which also includes pictures of
    dogs and parrots, what might happen when we deploy the model and it comes across
    a picture of a wolf? Intuitively, we might expect the model to say “it’s a dog,”
    just as a small child might before they learn what a wolf is. This is precisely
    what most machine learning models would do.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让模型在“实际环境”中表现良好，即在现实世界中使用时，训练模型所使用的数据必须覆盖模型可能遇到的所有输入范围。例如，假设我们想要一个模型来识别狗的图片，而我们的训练集只包含狗和鹦鹉的图片。虽然模型在我们的保留测试集上表现良好，该测试集也包含狗和鹦鹉的图片，但当我们部署模型并遇到一张狼的图片时会发生什么呢？直观上，我们可能期望模型会说“这是只狗”，就像一个小孩子在他们学习到狼是什么之前可能会这么说。这正是大多数机器学习模型会做的事情。
- en: To illustrate this, let’s try an experiment. A popular dataset used by all AI
    researchers consists of tens of thousands of small images containing handwritten
    digits, 0 through 9\. It goes by the uninspiring name of MNIST (Modified NIST)
    because it was derived in the late 1990s from a dataset constructed by the National
    Institute of Standards and Technology (NIST), the division of the United States
    Department of Commerce tasked with implementing all manner of standards for just
    about everything in the commercial and industrial realm.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，让我们做一个实验。所有AI研究人员都使用的一个流行数据集包含了成千上万张包含手写数字（0到9）的图像。它有一个不太吸引人的名字——MNIST（修改版的NIST），因为它是在1990年代末期从美国国家标准与技术研究院（NIST）构建的数据集中派生出来的，NIST是美国商务部下设的一个部门，负责为商业和工业领域几乎所有事物制定标准。
- en: '[Figure 1-6](ch01.xhtml#ch01fig06) presents some typical MNIST digit samples.
    Our goal is to build a neural network that learns to identify the digits 0, 1,
    3, and 9\. We can train neural networks without knowing how they work because
    of powerful, open source toolkits like scikit-learn that are available to everyone.
    On the one hand, this democratizes AI; on the other, a little knowledge is often
    a dangerous thing. Models may appear to be good when they’re flawed in reality,
    and lack of knowledge about how the models work might prevent us from realizing
    that fact before it’s too late.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-6](ch01.xhtml#ch01fig06)展示了一些典型的MNIST数字样本。我们的目标是构建一个神经网络，能够识别数字0、1、3和9。我们可以在不知道神经网络具体工作原理的情况下进行训练，因为有像scikit-learn这样的强大开源工具包可以供大家使用。一方面，这使得AI变得更加民主化；另一方面，缺乏知识往往会带来危险。模型可能看起来表现良好，实际上却存在缺陷，而如果不了解模型的工作原理，可能无法在为时已晚之前意识到这个问题。'
- en: '![Image](../images/ch01fig06.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/ch01fig06.jpg)'
- en: '*Figure 1-6: Sample MNIST digits*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1-6：典型的MNIST数字样本*'
- en: After the classifier is trained, we’ll throw it a few curveballs by handing
    it images of fours and sevens—inputs the AI never saw during training. What might
    the model do with such inputs?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类器训练完成后，我们将通过向其输入一些从未在训练中出现过的四和七的图像来给它设置一些“难题”。这个模型会如何处理这些输入呢？
- en: I trained the digits model using an open source toolkit. For now, all we need
    to know about the dataset is that the input feature vectors are unraveled digit
    images; the first row of pixels is followed by the second row, then the third
    row, and so on, until the entire image is unraveled into one long vector, a string
    of numbers. The digit images are 28×28 pixels, making the feature vector 784 numbers
    long. We’re asking the neural network to learn about things in a 784-dimensional
    space, rather than the simple 2-dimensional space we used previously, but machine
    learning is up to the challenge.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用开源工具包训练了数字分类模型。现在，我们只需要了解数据集的情况：输入特征向量是展开的数字图像；第一行像素之后是第二行，然后是第三行，依此类推，直到整个图像被展开成一个长向量，即一串数字。这些数字图像是28×28像素，特征向量的长度为784个数字。我们要求神经网络在一个784维的空间中进行学习，而不是我们之前使用的简单二维空间，但机器学习能够应对这个挑战。
- en: The training set used to condition the neural network model contained 24,745
    samples, roughly 6,000 of each digit type (0, 1, 3, and 9). This is likely enough
    to fairly represent the types of digits the model might encounter when used, but
    we need to try it to know. AI is a largely empirical science.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 用来训练神经网络模型的训练集包含了24,745个样本，每种数字类型（0、1、3、9）大约有6,000个样本。这应该足够公平地代表模型在使用过程中可能遇到的数字类型，但我们需要实际尝试才能知道。AI是一个高度经验性的学科。
- en: The held-out test set, also containing the digits 0, 1, 3, and 9, had 4,134
    samples (about 1,000 for each digit).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 保留的测试集也包含数字0、1、3和9，共有4,134个样本（每个数字大约1,000个样本）。
- en: We’ll use a [*confusion matrix*](glossary.xhtml#glo19), a two-dimensional table
    of numbers, to evaluate the model. Confusion matrices are the most common way
    to evaluate a model because they show how it behaves on the test data.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个[*混淆矩阵*](glossary.xhtml#glo19)，它是一个二维的数字表格，用来评估模型。混淆矩阵是最常见的评估模型的方法，因为它能展示模型在测试数据上的表现。
- en: In this case, the confusion matrix for our digit classifier is shown in [Table
    1-1](ch01.xhtml#ch01tab1).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们的数字分类器的混淆矩阵如[表1-1](ch01.xhtml#ch01tab1)所示。
- en: '**Table 1-1:** The Digit Classifier Confusion Matrix'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**表1-1：**数字分类器混淆矩阵'
- en: '|  | **0** | **1** | **3** | **9** |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|  | **0** | **1** | **3** | **9** |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **0** | 978 | 0 | 1 | 1 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 978 | 0 | 1 | 1 |'
- en: '| **1** | 2 | 1,128 | 3 | 2 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 2 | 1,128 | 3 | 2 |'
- en: '| **3** | 5 | 0 | 997 | 8 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| **3** | 5 | 0 | 997 | 8 |'
- en: '| **9** | 5 | 1 | 8 | 995 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| **9** | 5 | 1 | 8 | 995 |'
- en: The matrix rows represent the true labels for the samples given to the model.
    The columns are the model’s responses. The values in the table are counts, the
    number of times each possible combination of input class and model-assigned label
    happened.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵的行表示提供给模型的样本的真实标签。列则是模型的响应。表格中的数值表示每种可能的输入类别和模型分配标签组合的出现次数。
- en: For example, the first row represents the zeros in the test set. Of those 980
    inputs, the model returned a label of zero for 978 of them, but it said the input
    was a three once and a nine another time. Therefore, when zero was the input,
    the model’s output was correct 978 out of 980 times. That’s encouraging.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，第一行表示测试集中的零。在这980个输入中，模型对978个返回了零标签，但有一次它将输入标记为三，另一次标记为九。因此，当输入为零时，模型输出正确的次数是980次中的978次。这是值得鼓舞的。
- en: Similarly, when the input was a one, the model returned the correct label 1,128
    times. It was right 997 times for threes and 995 times for nines. When a classifier
    is good, the numbers along the diagonal of the confusion matrix from upper left
    to lower right are high, and there are almost no numbers off that diagonal. Off-diagonal
    numbers are errors made by the model.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，当输入为1时，模型正确地返回了1128次标签。对于3，模型正确了997次，针对9，模型正确了995次。当一个分类器表现好时，从左上到右下的混淆矩阵对角线上的数字会很高，且几乎没有偏离对角线的数字。偏离对角线的数字表示模型的错误。
- en: Overall, the digits model is 99 percent accurate. We have a solid, well-performing
    model—that is, if we can ensure that all inputs to the model are indeed a 0, 1,
    3, or 9\. But what if they aren’t?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，数字模型的准确率达到了99%。我们有一个稳定且表现良好的模型——前提是我们能确保模型的输入确实是0、1、3或9。可是如果输入不是这些呢？
- en: 'I handed the model 982 fours. The model replied like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我输入了982个数字4，模型是这么回复的：
- en: '| **0** | **1** | **3** | **9** |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| **0** | **1** | **3** | **9** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 48 | 9 | 8 | 917 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 48 | 9 | 8 | 917 |'
- en: In other words, the model returned a label of 9 for 917 of the 982 fours, a
    label of 1 for 48 fours, and labels of 1 or 3 for the rest. How about sevens?
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，模型对982个数字4中的917个返回了标签9，对48个数字4返回了标签1，其他的则返回了标签1或3。那对于7呢？
- en: '| **0** | **1** | **3** | **9** |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| **0** | **1** | **3** | **9** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 19 | 20 | 227 | 762 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 19 | 20 | 227 | 762 |'
- en: The model still favored calling sevens nines, but it often called them threes
    as well. Neural networks are loath to give up their secrets when explaining their
    actions, but in this case, of the 227 sevens labeled as threes, 47 of them were
    European-style sevens with a slash. A random sample of 227 sevens from the entire
    dataset turned up only 24 European-style sevens. The comparison isn’t rigorous
    mathematically, but it hints that sevens with a slash are often close enough to
    a three to fool the model.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 模型仍然倾向于把7当成9，但它也常常把7当成3。神经网络在解释其行为时不愿意透露过多信息，但在这个案例中，227个被标记为三的7中，有47个是带有斜线的欧洲风格7。从整个数据集中随机抽取的227个7中，只有24个是带有斜线的欧洲风格7。这个比较在数学上不严谨，但它暗示了带斜线的7通常足够像3，容易让模型误判。
- en: The model was never taught to recognize fours or sevens, so it did the next
    best thing and placed them in a nearby category. Depending on how they’re written,
    people might sometimes confuse fours and sevens for nines, for example. The model
    is making the kind of mistakes people make, which is interesting—but, more significantly,
    the model is poor because it wasn’t trained on the full range of inputs it might
    encounter. It has no way of saying “I don’t know,” and getting a model to reliably
    say this can be tricky.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 模型从未被训练去识别数字4或7，因此它做了最好的尝试，把它们放入了相邻的类别中。根据写法的不同，人们有时会把数字4和7误认为是9。例如，模型犯了人们常犯的错误，这很有趣——但更重要的是，模型的表现较差，因为它没有在可能遇到的所有输入上进行训练。它没有办法说“我不知道”，而且让模型可靠地做出这样的判断可能是棘手的。
- en: This is a simple exercise, but the implications are profound. Instead of digits,
    what if the model was looking for cancer in medical images but was never trained
    to recognize an important category of lesion or all the forms that lesion might
    take? A properly constructed and comprehensive dataset might mean the difference
    between life and death.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的练习，但其含义深远。假设模型不是在识别数字，而是在医学图像中寻找癌症，但它从未被训练去识别一种重要的病变类型或该病变可能呈现的所有形式呢？一个构建合理且全面的数据集可能意味着生死之间的差异。
- en: '****'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: We can also think about the digits example in terms of interpolation and extrapolation.
    *Interpolation* approximates within the range of known data, and *extrapolation*
    goes beyond known data.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以从插值和外推的角度来思考数字示例。*插值*是在已知数据范围内进行近似，而*外推*则超出了已知数据的范围。
- en: For the digits example, interpolation might refer to encountering a tilted zero
    in the wild when none of the zeros in the training set were particularly tilted.
    The model must interpolate, in a sense, to respond correctly. Extrapolation is
    more like classifying a zero with a slash through it, which is something unseen
    during training time. To better understand these terms, let’s model the world
    population from 1950 through 2020.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数字示例，插值可能是指在实际中遇到一个倾斜的零，而训练集中的零并没有特别倾斜。模型必须进行插值，在某种意义上，才能正确响应。外推更像是对一个有斜杠的零进行分类，这是训练时从未见过的情况。为了更好地理解这些术语，我们来模拟1950年到2020年的世界人口。
- en: 'First, we’ll fit a line to the data from 1950 through 1970\. Fitting a line
    is a form of curve fitting; think of it as machine learning’s less sophisticated
    cousin. To fit a line, find two numbers: the slope and the intercept. The slope
    tells us how steep the line is. If the slope is positive, the line is increasing
    as we move from left to right along the *x*-axis of a graph. A negative slope
    means the line decreases as we move along the *x*-axis. The intercept is where
    the line intersects the *y*-axis; that is, the value when the input is zero.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将对1950年到1970年的数据进行线性拟合。拟合一条直线是一种曲线拟合的形式；可以把它看作是机器学习中不那么复杂的“表亲”。要拟合一条直线，需要找出两个数字：斜率和截距。斜率告诉我们直线的陡峭程度。如果斜率是正的，直线就会随着我们从左到右沿着图表的*x*轴移动而上升。负斜率意味着直线会随着我们沿着*x*轴移动而下降。截距是直线与*y*轴交点的位置；也就是输入为零时的值。
- en: To fit a line, we use an algorithm to find the slope and intercept that best
    characterize the data (here, world population from 1950 through 1970). [Figure
    1-7](ch01.xhtml#ch01fig07) shows a plot of the line and the actual populations
    by year, denoted by plus signs. The line passes through or near to most of the
    plus signs, so the fit is reasonable. Notice that the population is in billions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要拟合一条直线，我们使用一个算法来找到最能描述数据（这里是1950年到1970年世界人口）的斜率和截距。[图1-7](ch01.xhtml#ch01fig07)展示了这条直线的图表，以及每年的实际人口，用加号表示。直线穿过或接近大多数加号，因此拟合是合理的。请注意，人口单位是以十亿为单位的。
- en: '![Image](../images/ch01fig07.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch01fig07.jpg)'
- en: '*Figure 1-7: World population from 1950 through 1970*'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1-7：1950年至1970年世界人口*'
- en: Once we have the line, we can use the slope and intercept to estimate the population
    for any year. Estimating for years between 1950 and 1970 is interpolating, because
    we used data from that range of years to create the line. If we estimate populations
    for years before 1950 or after 1970, we are extrapolating. [Table 1-2](ch01.xhtml#ch01tab2)
    shows our results when interpolating.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们得到这条直线，就可以利用斜率和截距来估算任何年份的人口。对1950年到1970年之间的年份进行估算是插值，因为我们用了这个时间段的数据来创建直线。如果我们估算1950年之前或1970年之后的人口，那就是外推。[表1-2](ch01.xhtml#ch01tab2)展示了我们进行插值时的结果。
- en: '**Table 1-2:** Interpolating the Population Between 1950 and 1970'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**表1-2：** 1950年到1970年之间的插值人口'
- en: '| **Year** | **Interpolated** | **Actual** |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| **年份** | **插值人口** | **实际人口** |'
- en: '| --- | --- | --- |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1954 | 2.71 | 2.72 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 1954 | 2.71 | 2.72 |'
- en: '| 1960 | 3.06 | 3.03 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 1960 | 3.06 | 3.03 |'
- en: '| 1966 | 3.41 | 3.41 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 1966 | 3.41 | 3.41 |'
- en: The interpolated population values are quite close to the actual population
    values, meaning the model (here the line fit to the data) is doing well. Now,
    let’s extrapolate to dates outside the fit range, as shown in [Table 1-3](ch01.xhtml#ch01tab3).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 插值后的人口值与实际人口值非常接近，这意味着模型（这里是拟合到数据的直线）表现良好。现在，让我们进行外推，估算拟合范围之外的日期，如[表1-3](ch01.xhtml#ch01tab3)所示。
- en: '**Table 1-3:** Extrapolating the Population After 1970'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**表1-3：** 1970年之后的外推人口'
- en: '| **Year** | **Extrapolated** | **Actual** |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| **年份** | **外推人口** | **实际人口** |'
- en: '| --- | --- | --- |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1995 | 5.10 | 5.74 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 1995 | 5.10 | 5.74 |'
- en: '| 2010 | 5.98 | 6.96 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 2010 | 5.98 | 6.96 |'
- en: '| 2020 | 6.56 | 7.79 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 2020 | 6.56 | 7.79 |'
- en: The difference between the extrapolated population values and the actual population
    is increasing with each year. The model isn’t doing well. Plotting the full range
    from 1950 through 2020 reveals the problem; see [Figure 1-8](ch01.xhtml#ch01fig08).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 外推人口值与实际人口值之间的差距逐年增加。模型的表现不佳。绘制1950年到2020年整个范围的数据，揭示了问题所在；见[图1-8](ch01.xhtml#ch01fig08)。
- en: '![Image](../images/ch01fig08.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch01fig08.jpg)'
- en: '*Figure 1-8: World population from 1950 through 2020*'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1-8：1950年至2020年世界人口*'
- en: As time goes by, the fit line becomes increasingly wrong because the data is
    not linear after all. That is, the rate of growth is not constant and doesn’t
    follow a straight line.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，拟合线变得越来越不准确，因为数据毕竟不是线性的。也就是说，增长速率不是恒定的，并且不遵循直线。
- en: When extrapolating, we might have reason to believe that the data will continue
    to fit the line; if that’s a valid assumption, then the line will continue to
    be a good fit. However, in the real world, we usually have no such assurance.
    So, as a slogan, we might say interpolation good, extrapolation bad.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行外推时，我们可能会有理由相信数据将继续符合这条线；如果这是一个有效的假设，那么这条线将继续是一个很好的拟合。然而，在现实世界中，我们通常无法获得这样的保证。因此，我们可以把它作为口号：插值好，外推坏。
- en: Fitting a line to some data is an example of *curve fitting*. What is true for
    curve fitting is also true for AI. The handwritten digits model did well when
    given inputs close to the data it was trained to recognize. The digits in the
    test data were all instances of 0, 1, 3, and 9, so the test data was like the
    training data. The two datasets are from the same *distribution*, and the same
    data-generating process created both. We can therefore claim that the model was,
    in a way, interpolating in those cases. However, when we forced the model to make
    decisions about fours and sevens, we were extrapolating by having the model make
    decisions about data it never saw during training.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为一些数据拟合一条线是*曲线拟合*的一个例子。曲线拟合的规律同样适用于人工智能。当手写数字模型接收到与它训练时识别的数据相似的输入时，它的表现不错。测试数据中的数字都是0、1、3和9，因此测试数据与训练数据相似。两个数据集来自相同的*分布*，并且是由相同的数据生成过程生成的。因此，我们可以说，在这些情况下，模型实际上是在进行插值。然而，当我们强迫模型做出关于4和7的决策时，我们是在进行外推，让模型对它在训练过程中从未见过的数据做出决策。
- en: 'It bears repeating: interpolation good, extrapolation bad. Bad datasets lead
    to bad models; good datasets lead to good models, which behave badly when forced
    to extrapolate. And, for good measure: all models are wrong, but some are useful.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 需要重复强调的是：插值好，外推坏。糟糕的数据集导致糟糕的模型；好的数据集导致好的模型，但当强迫它们进行外推时，它们会表现得很差。而且，再补充一句：所有的模型都是错误的，但有些是有用的。
- en: '****'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: Along the same lines of Hilaire Belloc’s 1907 book *Cautionary Tales for Children*—an
    amusing and somewhat horrifying look at foolish things children do that could
    lead to an unfortunate end—let’s examine some cautionary tales that AI practitioners
    should be aware of when training, testing, and, most of all, deploying models.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 跟Hilaire Belloc在1907年出版的《儿童警示故事》一书中的思路一样——这本书以一种有趣且略显恐怖的方式讲述了孩子们做出愚蠢行为可能导致不幸结局的故事——让我们来看看一些AI从业者在训练、测试，尤其是在部署模型时应该警惕的警示故事。
- en: In 2016, I attended a conference talk where the presenter demonstrated research
    into understanding why a neural network chooses the way it does. This is not yet
    a solved problem, but progress has been made. In this case, the research marked
    parts of the input images that influenced the model’s decision.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在2016年，我参加了一场会议演讲，演讲者展示了关于理解神经网络为何选择某种方式的研究。这仍然是一个未解决的问题，但已有进展。在这种情况下，研究标记了影响模型决策的输入图像部分。
- en: The speaker displayed pictures of huskies and wolves and discussed his classifier
    for differentiating between the two. He showed how well it performed on a test
    set and asked the audience of machine learning researchers if this was a good
    model. Many people said yes, but with hesitation because they expected a trap.
    They were right to be hesitant. The speaker then marked the images to show the
    parts that the neural network focused on when making its decisions. The model
    wasn’t paying attention to the dogs or the wolves. Instead, the model noticed
    that all the wolf training images had snow in the background, while none of the
    dog images contained snow. The model learned nothing about dogs and wolves but
    only about snow and no snow. Careless acceptance of the model’s behavior wouldn’t
    have revealed that fact, and the model might have been deployed only to fail in
    the wild.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 演讲者展示了哈士奇犬和狼的图片，并讨论了他用来区分这两者的分类器。他展示了该分类器在测试集上的表现，并问在场的机器学习研究人员这个模型是否是一个好模型。很多人说是，但有所犹豫，因为他们预期会有陷阱。他们的犹豫是对的。随后，演讲者标记了图像，展示了神经网络在做出决策时关注的部分。模型并没有关注狗或狼。相反，模型注意到所有狼的训练图像背景中都有雪，而狗的图像中没有雪。模型并没有学习狗和狼的特征，而是学会了雪和没有雪的区别。如果不小心接受模型的行为，可能就无法发现这个问题，模型可能会被部署后在实际环境中失败。
- en: A similar tale is told of a very early machine learning system from the 1950s
    or 1960s. This one is likely apocryphal, though I have read a paper from that
    period that might be the origin of the urban legend. In this case, the images
    were bird’s-eye views of forests. Some images contained a tank, while others did
    not.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 关于上世纪五六十年代非常早期的机器学习系统，也有类似的故事。这个故事可能是虚构的，尽管我曾读过一篇来自那个时期的论文，可能就是这个都市传说的来源。在这个例子中，图像是森林的鸟瞰图。有些图像中包含了坦克，而有些则没有。
- en: A model trained to detect tanks seemed to work well on the training data but
    failed miserably when set loose in the wild. It was eventually realized that one
    set of training images had been taken on a sunny day and the other on a cloudy
    day. The model had learned nothing that its creators assumed it had.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经过训练来检测坦克的模型在训练数据上似乎效果很好，但在实际环境中却惨败。最终人们意识到，一组训练图像是在阳光明媚的日子拍摄的，另一组则是在多云的日子拍摄的。该模型并没有学到它的创造者所假设的内容。
- en: More recent examples of this phenomenon exist with more advanced machine learning
    models. Some have even fooled experts into believing the model had learned something
    fundamental about language or the like when, instead, it had learned extremely
    subtle correlations in the training data that no human could (easily) detect.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在更先进的机器学习模型中，类似的现象依然存在。有些模型甚至让专家误以为它学到了关于语言或类似内容的基本知识，而实际上，它只是学到了训练数据中一些极为细微的相关性，是人类（或机器）难以察觉的。
- en: The word *correlation* has a strict mathematical meaning, but we capture its
    essence with the phrase “correlation does not imply causation.” Correlation is
    when two things are linked so that the occurrence of one implies the occurrence
    of the other, often in a particular order. More concretely, correlation measures
    how strongly a change in one thing is associated with a change in another. If
    both increase, they are positively correlated. If one increases while the other
    decreases, they are negatively correlated.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '*相关性* 这个词有严格的数学意义，但我们用“相关性并不意味着因果关系”这一说法来捕捉它的本质。相关性是指两件事物之间存在联系，以至于一个的发生意味着另一个的发生，通常是按特定的顺序。更具体地说，相关性衡量的是一件事物变化与另一件事物变化的关联强度。如果两者都增加，它们是正相关的。如果一个增加而另一个减少，它们是负相关的。'
- en: 'For example, a rooster crows, and the sun comes up. The two events are time-dependent:
    the rooster first, then the sun. This correlation does not imply causation, as
    the rooster crowing doesn’t cause the sun to rise, but if such a correlation is
    observed often enough, the human mind begins to see one as causing the other,
    even when there is no real evidence of this. Why humans act this way isn’t hard
    to understand. Evolution favored early humans who made such associations because,
    sometimes, the associations led to behavior beneficial for survival.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一只公鸡打鸣，太阳升起。这两个事件是时间相关的：先是公鸡，然后是太阳。这种相关性并不意味着因果关系，因为公鸡打鸣并不导致太阳升起，但如果这种相关性被观察得足够频繁，人类大脑就会开始认为一个是导致另一个的原因，即使没有真实证据表明如此。为什么人类会这样反应并不难理解。进化青睐那些能够做出这种关联的早期人类，因为有时这些关联促成了对生存有利的行为。
- en: “Correlation does not imply causation” also applies to AI. The aforementioned
    models learned to detect things in the training data that correlated with the
    intended targets (dogs, wolves, tanks) but didn’t learn about the targets themselves.
    Savvy machine learning practitioners are always on the lookout for such spurious
    correlations. Using a large and highly diverse dataset for training and testing
    can defend against this effect, though this isn’t always possible in practice.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: “相关性并不意味着因果关系”同样适用于人工智能。上述的模型学会了检测与目标（狗、狼、坦克）相关的训练数据中的东西，但并没有学到目标本身。精明的机器学习从业者总是警惕这种虚假的相关性。使用大规模且高度多样化的训练和测试数据集可以防止这种现象，尽管在实践中这并不总是可能的。
- en: We must ask whether our models have learned what we assume they have. And, as
    we saw with the MNIST digits, we must ensure that our models have seen all the
    kinds of inputs they will encounter in the wild—they should interpolate, not extrapolate.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须问自己，模型是否学到了我们假设它们已经学到的东西。正如我们在 MNIST 数字例子中看到的那样，我们必须确保模型已经看到了它们在实际环境中可能遇到的所有类型的输入——它们应该进行插值，而不是外推。
- en: This matters more than it might initially appear. Google learned this lesson
    in 2015 when it deployed a feature for Google Photos, wherein the model was insufficiently
    trained on human faces and made incorrect and inappropriate associations. Bias,
    in both the generic and social senses, is a real issue in AI.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这比最初看起来更重要。谷歌在2015年通过Google照片的一个功能学到了这一课，模型在训练人脸时不足，导致做出了错误和不适当的关联。偏见，无论是泛指的还是社会层面的，都是人工智能中的一个真实问题。
- en: 'Let’s perform another experiment with MNIST digits. This time, the model has
    a seemingly simple decision to make: is the input digit a nine? The model is the
    same neural network used previously. If trained on a dataset where every image
    is either a nine or any other digit except four or seven (that is, no fours or
    sevens are in the training data), then the model is 99 percent accurate, as the
    confusion matrix shows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行另一个实验，使用MNIST数字。此次，模型需要做出一个看似简单的决定：输入的数字是否是9？该模型与之前使用的神经网络相同。如果在一个数据集中训练，其中每张图片要么是9，要么是除4和7以外的其他任何数字（即，训练数据中没有4或7），那么模型的准确率是99%，正如混淆矩阵所示：
- en: '|  | **Not 9** | **9** |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '|  | **不是9** | **9** |'
- en: '| --- | --- | --- |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Not 9** |   9,754 | 23 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| **不是9** |   9,754 | 23 |'
- en: '|         **9** |   38 | 1,362 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '|         **9** |   38 | 1,362 |'
- en: The confusion matrix tells us that the model correctly labeled 9,754 out of
    9,777 test images that were not a nine. The model’s label was also correct for
    1,362 of the 1,400 nines. While the model performs well on the test set, the set
    does not contain fours or sevens.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵告诉我们，模型正确标记了9,777张测试图片中除9以外的9,754张图片。对于1,400张数字9，模型的标签也正确标记了其中的1,362张。虽然模型在测试集上表现良好，但该测试集并不包含数字4或7。
- en: 'In this case, the confusion matrix is small because the model has only two
    classes: nine or not nine. In other words, this is a binary model.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，混淆矩阵较小，因为模型只有两个类别：9或非9。换句话说，这是一个二元模型。
- en: The 23 in the upper-right corner of the matrix represents 23 times when the
    input wasn’t a nine, but the model said it was. For a binary model, class 1 is
    usually considered the class of interest, or the positive class. Therefore, these
    23 inputs represent [*false positives*](glossary.xhtml#glo41), because the model
    said “it’s a nine” when it wasn’t. Similarly, the 38 samples at the lower left
    are [*false negatives*](glossary.xhtml#glo40) because the model said “it’s not
    a nine” when the input actually was. We want models with no false positives or
    negatives, but sometimes it’s more important to minimize one than the other.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵右上角的23代表23次输入不是9，但模型却说它是9。对于一个二元模型，通常将类别1视为感兴趣的类别，即正类。因此，这23个输入代表了[*假阳性*](glossary.xhtml#glo41)，因为模型说“它是9”，但实际上不是。同样，左下角的38个样本是[*假阴性*](glossary.xhtml#glo40)，因为模型说“它不是9”，但输入实际上是9。我们希望模型没有假阳性或假阴性，但有时最重要的是最小化其中一个。
- en: For example, if a model is to detect breast cancer in mammograms, a false positive
    represents a case where the model says, “it might be cancer,” even though it isn’t.
    That’s scary to hear, but further testing will show that the model was wrong.
    However, a false negative represents a missed cancer. We might tolerate a model
    with more false positives if it also has virtually no false negatives, as a false
    positive is less catastrophic than a false negative. We’re beginning to appreciate
    how important it is to fully train, characterize, test, and *understand* our machine
    learning models.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果一个模型用于检测乳腺X光片中的乳腺癌，假阳性代表模型说“可能是癌症”，即使它不是。听到这个可能会让人害怕，但进一步的测试会显示模型是错误的。然而，假阴性代表漏诊癌症。如果一个模型几乎没有假阴性，我们可能会容忍更多的假阳性，因为假阳性比假阴性更不致命。我们开始意识到，全面训练、表征、测试并*理解*我们的机器学习模型是多么重要。
- en: '****'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: 'All right, back to our experiment. The “is it a nine” classifier, like our
    earlier MNIST model, knows nothing about fours or sevens. When shown fours and
    sevens, the MNIST model typically called them nines. Will this model do the same?
    Here’s what I received when I gave the model fours and sevens:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，回到我们的实验。像我们之前的MNIST模型一样，“这是9吗”分类器对数字4或7一无所知。当它看到数字4和7时，MNIST模型通常会将它们误认为是9。这个模型会做出相同的判断吗？这是我在给模型输入数字4和7时得到的结果：
- en: '|  | **Not 9** | **9** |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | **不是9** | **9** |'
- en: '| --- | --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Not 9** |   5,014 | 9,103 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| **不是9** |   5,014 | 9,103 |'
- en: The model marked 9,103 of the 14,117 fours and sevens as nines. That’s slightly
    more than 65 percent, or roughly two out of every three. This mimics the case
    where we present the model with inputs of a type it was never trained to detect.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 模型将14,117个四和七中的9,103个标记为九。这略高于65%，大约是每三个中有两个。这模拟了我们将模型输入它从未接受过训练的类型的情况。
- en: 'Let’s help the model by adding fours and sevens to the training set. Hopefully,
    providing examples that say, “It looks like a nine, but it isn’t,” formally known
    as *hard negatives*, will improve the model. I made 3 percent of the training
    data fours and sevens. The overall model was just as accurate as before, 99 percent,
    and here’s what happened when I gave it fours and sevens it had never seen before:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将四和七添加到训练集中来帮助模型。希望提供一些例子，告诉模型：“它看起来像九，但它不是”，正式称为*困难负样本*，能够改进模型。我将3%的训练数据设为四和七。整体模型的准确度与之前一样，99%，而当我给它一些它从未见过的四和七时，结果如下：
- en: '|  | **Not 9** | **9** |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '|  | **不是9** | **9** |'
- en: '| --- | --- | --- |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Not 9** |   9,385 | 3,321 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| **不是9** | 9,385 | 3,321 |'
- en: That’s better. Instead of calling two-thirds of four or seven inputs a nine,
    the model labeled only one in four as a nine. Even a few examples of things that
    look like the positive class but aren’t can help. If I boost the proportion of
    fours and sevens in the training set to 18 percent, the model misclassifies fours
    and sevens less than 1 percent of the time. Because models learn from data, we
    *must* use datasets that are as complete as possible so our models interpolate
    and do not extrapolate.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就好多了。模型不再将三分之二的四或七标记为九，而是只将四分之一标记为九。即使是一些看起来像正类但不是的例子也能有所帮助。如果我将训练集中四和七的比例提高到18%，模型将误分类四和七的情况低于1%。因为模型是从数据中学习的，我们*必须*使用尽可能完整的数据集，以便模型能够插值而不是外推。
- en: '**NOTE**'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*To be completely accurate, recent research shows that modern deep learning
    models are almost always extrapolating, but the more similar the inputs are to
    the data on which the model was trained, the better the performance, so I feel
    justified in using the analogy.*'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '*为了完全准确，最近的研究表明，现代深度学习模型几乎总是在进行外推，但输入与模型训练数据越相似，性能越好，因此我觉得使用这个类比是合理的。*'
- en: Everyone who seeks to understand, let alone work with, AI must take the warnings
    about the quality of the data used to train AI models to heart. A 2021 research
    article published in the journal *Nature Machine Intelligence* by Michael Roberts
    et al., “Common Pitfalls and Recommendations for Using Machine Learning to Detect
    and Prognosticate for COVID-19 Using Chest Radiographs and CT Scans,” is a sobering
    example. The authors assessed the performance of machine learning models designed
    to detect COVID-19 in chest X-rays and CT scans, reducing the initial candidate
    pool of over 2,000 studies (models) to 62 for rigorous testing. In the end, the
    authors declared *none* of the models fit for clinical use because of flaws in
    construction, bias in the datasets, or both.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 每个想要理解并且与AI打交道的人都必须认真对待有关用于训练AI模型数据质量的警告。2021年由迈克尔·罗伯茨等人发表在《自然机器智能》期刊上的一篇研究文章《利用胸部X光片和CT扫描检测和预测COVID-19的机器学习常见陷阱及建议》是一个令人警醒的例子。作者评估了用于检测胸部X光片和CT扫描中的COVID-19的机器学习模型的表现，并将最初的超过2,000个研究（模型）筛选到62个进行严格测试。最终，作者宣称*没有*一个模型适合临床使用，因为模型构建存在缺陷，数据集存在偏差，或两者兼有。
- en: Results like these have led to the creation of [*explainable AI*](glossary.xhtml#glo39),
    a subfield that seeks to give models the ability to explain themselves.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的结果促成了[*可解释的人工智能*](glossary.xhtml#glo39)这一子领域的诞生，旨在让模型具备自我解释的能力。
- en: Look at your data and try to understand, as far as humanly possible, what your
    model is doing and *why*.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 看看你的数据，并尽可能地理解你的模型在做什么，以及*为什么*。
- en: '****'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '****'
- en: This chapter’s title, “And Away We Go,” was comedian Jackie Gleason’s tagline.
    It’s often good to dive into a subject to get an overview before coming back to
    understand things at a deeper level. In other words, we rush in to get a feel
    for the topic before exploring more methodically.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 本章标题“我们出发了”是喜剧演员杰基·格里森的口头禅。通常，在深入了解之前先快速浏览一遍主题是很好的，这样可以帮助我们在更深入地理解时拥有一个整体的视角。换句话说，我们快速进入主题，先了解一下，再更加有条理地进行探索。
- en: You’ll find the many new terms and concepts introduced in this chapter in the
    glossary at the end of the book. My goal isn’t for you to understand them all
    now, let alone retain them, but to plant seeds so that the next time you encounter
    one of these terms or concepts, you’ll be more likely to think, “Ah, I know that
    one.” Later chapters reinforce them, and you’ll learn the important ones via repeated
    exposure.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中引入的许多新术语和概念可以在书本末尾的词汇表中找到。我的目标并不是让你现在就理解它们，更不要说记住它们，而是播下种子，以便下次你遇到这些术语或概念时，你更有可能想到：“啊，我知道这个。”
    后续章节会加深这些概念，你将通过反复接触学习到重要的内容。
- en: There are two categories of takeaways from this chapter. The first has to do
    with what AI is and its essential pieces. The second is about building intuition
    about what AI offers and how we should respond.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 本章有两个要点需要记住。第一个是关于人工智能是什么以及它的基本构成。第二个是关于建立直觉，理解人工智能的功能以及我们应如何回应。
- en: 'AI involves models, as yet nebulous entities we can condition with data to
    perform some desired task. There are many types of AI models, and this chapter
    introduced two: decision trees and neural networks. I won’t say much more about
    decision trees, but neural networks occupy most of the remainder of the book.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能涉及模型，这些模型尚未完全明确，但我们可以通过数据对其进行条件化，以执行某些期望的任务。人工智能有很多类型的模型，本章介绍了其中两种：决策树和神经网络。关于决策树我不会再多说，但神经网络占据了书籍的大部分内容。
- en: 'Models are often best thought of as functions, like the mathematical functions
    you may remember from school or the functions that form the core of most computer
    programs. Both can be considered black boxes, where something goes in (the input)
    and something comes out (the output). In AI, the input is a feature vector, a
    collection of whatever is appropriate for the task at hand. In this chapter, we
    used two feature vectors: measurements of a flower and images of a handwritten
    digit.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 模型通常最好被视为函数，就像你在学校里可能记得的数学函数，或者构成大多数计算机程序核心的函数。它们都可以被看作是黑箱，其中有东西输入（输入），然后有东西输出（输出）。在人工智能中，输入是特征向量，它是根据当前任务所需的内容的集合。在本章中，我们使用了两个特征向量：花朵的测量值和手写数字的图像。
- en: Training conditions the model by altering its parameters to make it as accurate
    as possible. It’s necessary to exercise caution when training most models to learn
    the general features of the data and not spurious correlations or the minute details
    of the training set (a concept known as [*overfitting*](glossary.xhtml#glo79),
    which we’ll discuss in [Chapter 4](ch04.xhtml)).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 训练通过调整模型的参数来使其尽可能准确。这要求在训练大多数模型时要小心，以确保它学习到数据的通用特征，而不是虚假的关联或训练集的微小细节（这一概念称为[*过拟合*](glossary.xhtml#glo79)，我们将在[第4章](ch04.xhtml)讨论）。
- en: Proper development of machine learning models means we must have a test set,
    a collection of known input and output pairs that we do not use when training.
    We use this set after training to evaluate the model. If the dataset is constructed
    correctly, the test set provides an idea of how well we can expect the model to
    perform in the wild.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 正确开发机器学习模型意味着我们必须拥有一个测试集，它是已知输入和输出对的集合，在训练时不会使用该数据集。我们在训练后使用这个数据集来评估模型。如果数据集构建得当，测试集可以为我们提供模型在实际应用中表现如何的预期。
- en: The second takeaway relates to what AI offers and how we should respond to it.
    While AI is powerful, it doesn’t think as we do (though the models of [Chapter
    7](ch07.xhtml) might disagree). AI lives and dies by data and is only as good
    as the data we feed to it. If the dataset is biased, the AI is biased. If the
    dataset neglects to include examples of the types of inputs it will encounter
    when used, the AI will fail to handle such inputs properly.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个要点与人工智能的优势及我们应如何应对有关。尽管人工智能强大，但它并不像我们一样思考（尽管[第七章](ch07.xhtml)的模型可能会不同意）。人工智能的生死由数据决定，只有我们提供给它的数据好，它才好。如果数据集有偏差，人工智能就有偏差。如果数据集未能包括它在实际使用中可能遇到的输入类型的例子，人工智能将无法正确处理这些输入。
- en: The chapter’s examples warn us to be careful when assuming AI operates as intended.
    Did the model learn what we wanted it to learn? Was it influenced by correlations
    in the data that we didn’t notice or, worse still, that we are too limited to
    discern? Think back to the huskies versus wolves example.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的示例提醒我们，在假设人工智能按预期操作时要小心。模型是否学到了我们希望它学到的内容？它是否受到数据中我们未注意到的关联性影响，或者更糟糕的是，受到我们有限能力所无法察觉的影响？回想一下哈士奇与狼的例子。
- en: Because AI is only as good as the data fed to it, it’s on us to make datasets
    fair and unbiased and to understand what the AI has truly learned without assumptions.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 因为AI的效果取决于输入给它的数据，我们有责任使数据集公平且无偏，并理解AI真正学到了什么，而不是做出假设。
- en: AI first appeared in the 1950s, so why is it now suddenly everywhere we look?
    The next chapter answers this question.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: AI首次出现在1950年代，那么为什么它现在突然无处不在？下一章将回答这个问题。
- en: '**KEY TERMS**'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键术语**'
- en: algorithm, artificial intelligence, classifier, class label, confusion matrix,
    dataset, decision tree, deep learning, explainable AI, feature, feature vector,
    machine learning, model, neural network, parameters, testing, training
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 算法、人工智能、分类器、类别标签、混淆矩阵、数据集、决策树、深度学习、可解释AI、特征、特征向量、机器学习、模型、神经网络、参数、测试、训练
