- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finding an Object in a Picture
  prefs: []
  type: TYPE_NORMAL
- en: '![Alphabet-I](Images/Alphabet-I.png)n earlier chapters, you learned that you
    can train an ML system so that if you give it a picture, it can recognize the
    object in that picture. That’s useful when the whole picture is of something that
    you’re interested in, as it was when you made the Rock, Paper, Scissors game in
    Chapter 4. For that game, your hand filled the photo. But sometimes we want the
    computer to learn to find something that’s only a small part of a much bigger
    picture. In this chapter, you’ll see how to break up a complex job into separate
    simpler parts and then use ML for each part.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, imagine that you want to use ML to find where the tree is in [Figure
    9-1](#figure9-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09001](Images/f09001.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-1:](#figureanchor9-1) Where is the tree?'
  prefs: []
  type: TYPE_NORMAL
- en: The basic idea is that you train an ML model to recognize pictures of trees,
    in the same way that you trained it to recognize pictures of certain animals in
    Chapter 3. Then, you chop up this new photo into smaller pieces and use that ML
    model to check which piece looks like a picture of a tree.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the top-left piece of [Figure 9-1](#figure9-1) is shown in [Figure
    9-2](#figure9-2). The ML model wouldn’t recognize this picture as a tree, so we
    can say that the tree isn’t in the top left of the picture.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09002](Images/f09002.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-2:](#figureanchor9-2) Top left of [Figure 9-1](#figure9-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Or, we could try the bottom-right piece shown in [Figure 9-3](#figure9-3). The
    ML model wouldn’t recognize this picture as a tree either, so we can say that
    the tree isn’t in the bottom right of the picture.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09003](Images/f09003.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-3:](#figureanchor9-3) Bottom right of [Figure 9-1](#figure9-1)'
  prefs: []
  type: TYPE_NORMAL
- en: We keep going until we try testing a picture like [Figure 9-4](#figure9-4).
    When we get a piece that the ML model has high confidence looks like a picture
    of a tree, we know that we’ve found the location of the tree.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09004](Images/f09004.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-4:](#figureanchor9-4) Bottom left of [Figure 9-1](#figure9-1)'
  prefs: []
  type: TYPE_NORMAL
- en: A good way to think of it is that you’re breaking the picture up into tiles
    and testing each tile separately. In this chapter, you’ll see for yourself how
    this method works as you train an ML model to find where something is in randomly
    generated scenes.
  prefs: []
  type: TYPE_NORMAL
- en: Build Your Project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this chapter, we’ll use a Scratch project that chooses a random backdrop
    and then randomly distributes a dozen sprites around the Stage. One of the sprites
    is a duck. The aim of this project is to find the duck only by looking at the
    Stage, without cheating by using the coordinates of the sprite (see [Figure 9-5](#figure9-5)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09005](Images/f09005.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-5:](#figureanchor9-5) The objective of this project is to find the
    duck.'
  prefs: []
  type: TYPE_NORMAL
- en: Train Your Model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Create a new ML project, name it `Find the duck`, and set it to learn to recognize
    images.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Train**, as shown in [Figure 9-6](#figure9-6).![f09006](Images/f09006.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-6:](#figureanchor9-6) Train is the first phase of an ML project.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Add new label**, as shown in [Figure 9-7](#figure9-7). Then enter `Duck`.![f09007](Images/f09007.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-7:](#figureanchor9-7) Create a training bucket for examples of duck
    pictures.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Add new label** again and name this bucket `Not the Duck`, as shown
    in [Figure 9-8](#figure9-8). (The underscores will be added automatically.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This bucket will be used to store *negative training examples*, which are examples
    of things that *aren’t* what you want the computer to learn to recognize.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f09008](Images/f09008.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 9-8:](#figureanchor9-8) Create a training bucket for examples of pictures
    not of the duck.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Back to project** in the top-left corner of the screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Make**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Scratch 3**, as shown in [Figure 9-9](#figure9-9).![f09009](Images/f09009.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-9:](#figureanchor9-9) Click **Scratch 3**.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You’ll see a warning that you don’t have an ML model yet. That’s fine, as you’ll
    be using Scratch to collect the training examples.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **straight into Scratch**, as shown in [Figure 9-10](#figure9-10).![f09010](Images/f09010.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-10:](#figureanchor9-10) Open Scratch without an ML model by clicking
    **straight into Scratch**.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Project templates** in the top menu. Then click **Find the duck** in
    the list of templates displayed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The project has 12 sprites arranged on the Stage into a 3×4 grid of tiles. The
    sprites are hidden when you first load the template, but they’re named as shown
    in [Figure 9-11](#figure9-11).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f09011](Images/f09011.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 9-11:](#figureanchor9-11) The sprites in the Find the duck template.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **0,0** sprite in the sprites list at the bottom right. At the top
    left of the Code Area, under the yellow TRAINING comment, find the `store training
    data example of the duck` and the `store training data example of NOT the duck`
    blocks, as shown in [Figure 9-12](#figure9-12).![f09012](Images/f09012.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-12:](#figureanchor9-12) Find the script blocks for the **0,0** sprite.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **Find the duck** group in the Toolbox on the left, and add an `add
    training data` block to both of the scripts. Then, from the **Images** group,
    drag a `backdrop image` block into both `add training data` blocks, as shown in
    [Figure 9-13](#figure9-13).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set the first script to add the backdrop to the Duck training bucket, and the
    second script to add the backdrop to the Not the Duck training bucket.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f09013](Images/f09013.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 9-13:](#figureanchor9-13) Add training examples to the two training
    buckets.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat step 11 for all 12 sprites (see [Figure 9-14](#figure9-14)). Once you’ve
    done that, any of the tiles you click can be used to add an example to your training
    data.![f09014](Images/f09014.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-14:](#figureanchor9-14) Add the script blocks to all 12 sprites.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It’s time to collect your training examples! Click the Green Flag to start.
    When the project asks if you want to Train or Test, click **Train**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **OK** when you’re asked to click the duck, and then click the tile with
    the duck in it. The tile you click will be added to your Duck training bucket,
    as shown in [Figure 9-15](#figure9-15).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **OK** when you’re asked to click a tile that doesn’t have the duck in
    it. Make sure to click a tile that doesn’t show *any* part of the duck.![f09015](Images/f09015.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-15:](#figureanchor9-15) Adding an example of the duck to the training
    data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the Machine Learning for Kids site, click **Back to project** and then click
    **Train** to make sure that everything is working. You should see both of the
    tiles you clicked, as shown in [Figure 9-16](#figure9-16). Check that they’re
    in the correct buckets.![f09016](Images/f09016.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-16:](#figureanchor9-16) Training examples should show up in the correct
    buckets back in the Train phase.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat steps 13 through 15 in Scratch until you’ve got 10 examples in each bucket,
    as shown in [Figure 9-17](#figure9-17).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here are two tips for your **Not the Duck** training examples:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Make sure you don’t click the same character every time for your **Not the Duck**
    bucket. You don’t want that to become a training set for recognizing the parrot,
    for example. The best way to make a good **Not the Duck** training set is to click
    an even mix of the other characters.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, try to include some tiles with no characters at all. You want the computer
    to learn that empty tiles are also *not the duck*.![f09017](Images/f09017.png)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 9-17:](#figureanchor9-17) *Training data for finding the duck*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Back to project** and then **Learn & Test**. Click **Train new machine
    learning model**, as shown in [Figure 9-18](#figure9-18).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Wait for the model to finish training. This might take a few minutes.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f09018](Images/f09018.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 9-18:](#figureanchor9-18) Train an ML model using the examples that
    you collected.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Prepare Your Project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, you need to modify your Scratch project to finish the test scripts.
  prefs: []
  type: TYPE_NORMAL
- en: Click the **0,0** sprite in the sprites list at the bottom right and find the
    `when I receive test-0,0` script in the Code Area. It’s to the right of the scripts
    you worked on before, as shown in [Figure 9-19](#figure9-19).![f09019](Images/f09019.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-19:](#figureanchor9-19) Find the test script in the **0,0** sprite.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the `when I receive test-0,0` script, drag in a `recognise image (label)`
    block from the **Find the duck** group and update it as shown in [Figure 9-20](#figure9-20).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This script will use your ML model to test whether the bottom-left tile contains
    the duck and display the message “Is the duck here?” if it does.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f09020](Images/f09020.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 9-20:](#figureanchor9-20) Update the test script to use your ML model.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat step 2 for all 12 sprites (see [Figure 9-21](#figure9-21)). Once you’ve
    done this, your ML model can check all of the tiles to look for the duck.![f09021](Images/f09021.png)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 9-21:](#figureanchor9-21) Add the test blocks to all 12 sprites.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Test Your Project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s time to test your ML model!
  prefs: []
  type: TYPE_NORMAL
- en: Click the Green Flag and then click **Test** in the Scratch project on the Stage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your project will use your ML model to test every tile and highlight any it
    recognizes as the duck, as shown in [Figure 9-22](#figure9-22).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f09022](Images/f09022.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 9-22:](#figureanchor9-22) Testing your ML model'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Try it a few times and see how often your model gets it right. Finding a small
    image inside of a large scene is a complex job, so with only 10 training examples,
    it will probably make a few mistakes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add another 10 training examples to each bucket by clicking the Green Flag and
    clicking **Train** as you did earlier. You can check your new training examples
    back in the Train phase, as shown in [Figure 9-23](#figure9-23).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Back to project** and then **Learn & Test** to train a new ML model
    with your larger set of training examples.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f09023](Images/f09023.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 9-23:](#figureanchor9-23) Try training a new ML model using 20 examples
    of each group.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Test again as you did before. Is your new ML model better at finding the duck?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review and Improve Your Project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How can you describe how well the ML model is doing?
  prefs: []
  type: TYPE_NORMAL
- en: 'In Chapter 8, you learned that you can keep a count of the number of times
    the computer gets things right and wrong:'
  prefs: []
  type: TYPE_NORMAL
- en: True positive  Tiles the computer thought included the duck, and did
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False positive  Tiles the computer thought included the duck, but didn’t
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: True negative  Tiles the computer thought didn’t include the duck, and didn’t
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False negative  Tiles the computer thought didn’t include the duck, but did
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can use this count to draw up a confusion matrix and calculate the accuracy,
    recall, and precision of your ML model.
  prefs: []
  type: TYPE_NORMAL
- en: For example, look at the test image in [Figure 9-24](#figure9-24).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09024](Images/f09024.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-24:](#figureanchor9-24) A test image with the two bottom-right tiles
    recognized as a match'
  prefs: []
  type: TYPE_NORMAL
- en: 'The duck was present in the four tiles in the bottom right of the board. Two
    of them were recognized by my ML model. Two were missed. So, my confusion matrix
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **True positives** 2 | **False positives** 0 |'
  prefs: []
  type: TYPE_TB
- en: '| **False negatives** 2 | **True negatives** 8 |'
  prefs: []
  type: TYPE_TB
- en: 'This confusion matrix gives me:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Precision: 100%'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (Every time my ML model thought it saw a duck, there was a duck there.)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Recall: 50%'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (My ML model found half of the tiles that contained a duck.)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Accuracy: 83%'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: (My ML model gave 10 correct answers out of 12 total answers.)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You need a larger sample size, including several different backgrounds, to really
    trust these numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'I ran this test five times, and my overall results were as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **True positives** 9 | **False positives** 0 |'
  prefs: []
  type: TYPE_TB
- en: '| **False negatives** 6 | **True negatives** 45 |'
  prefs: []
  type: TYPE_TB
- en: 'Precision: 100%'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Recall: 60%'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Accuracy: 90%'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These numbers give us a more meaningful way of describing the performance of
    the ML model.
  prefs: []
  type: TYPE_NORMAL
- en: My model, which was trained with only a small number of examples, seems to be
    very precise (when it recognizes a duck, it is always correct). However, it misses
    things sometimes.
  prefs: []
  type: TYPE_NORMAL
- en: We describe a precise model that sometimes misses things as *favoring precision
    over recall*. This is a good approach for projects where it is important not to
    falsely recognize things.
  prefs: []
  type: TYPE_NORMAL
- en: For projects where it is more important to not miss anything, and where it is
    okay to make the occasional mistake, you would aim to train ML models in a way
    that *favors recall over precision* instead.
  prefs: []
  type: TYPE_NORMAL
- en: How is your project performing?
  prefs: []
  type: TYPE_NORMAL
- en: Real-World Applications for Complex Image Recognition Systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might have trained an image recognition ML model like this before. Have
    you ever been asked by a website to prove that you’re a human by clicking pictures
    of street signs as in [Figure 9-25](#figure9-25)? Or bicycles? Or taxis?
  prefs: []
  type: TYPE_NORMAL
- en: '![f09025](Images/f09025.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-25:](#figureanchor9-25) Helping to train an ML model'
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully you can see how this kind of image recognition application, known
    as a *CAPTCHA**, would be a great way to collect a large number of training examples
    for an image recognition system that can find different things on the street.
    Do you think this would be useful in the development of self-driving cars?*
  prefs: []
  type: TYPE_NORMAL
- en: '*The basic idea here is described in the chapter’s introduction. If we want
    to find something small in a larger picture, we chop the picture up into smaller
    tiles and test each tile individually with an ML model trained to recognize pictures
    of that object.'
  prefs: []
  type: TYPE_NORMAL
- en: You probably have a feel for the sorts of challenges of this technique from
    training it yourself. For example, one of the biggest problems is deciding what
    size tiles to use. Remember the example of finding the tree in [Figure 9-1](#figure9-1)?
  prefs: []
  type: TYPE_NORMAL
- en: If you make your tiles too small, you might only ever see a small section of
    the object you’re trying to find and never recognize it. For example, your ML
    model might not recognize [Figure 9-26](#figure9-26) as a tree.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09026](Images/f09026.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-26:](#figureanchor9-26) A tile that includes only part of the tree'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if you make your tiles too big, as in [Figure 9-27](#figure9-27),
    you still have the problem of there being too much in the picture that *isn’t*
    the tree, which will challenge an ML model trained to recognize pictures of trees.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09027](Images/f09027.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-27:](#figureanchor9-27) A tile that is too large to focus on the
    tree'
  prefs: []
  type: TYPE_NORMAL
- en: If you know the likely size of the object you’re looking for in the picture,
    you can make a sensible estimate for the right tile size to use. Some systems
    even ask users to specify the tile size to use.
  prefs: []
  type: TYPE_NORMAL
- en: If neither of these solutions is an option, you can try a wide variety of tile
    sizes and use the result that gives your model the highest confidence, as shown
    in [Figure 9-28](#figure9-28).
  prefs: []
  type: TYPE_NORMAL
- en: Even if you get the grid size right, the object you’re looking for won’t always
    fit neatly in the middle of a tile (as you probably noticed with the duck).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09028](Images/f09028.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Figure 9-28:](#figureanchor9-28) Try a variety of tile sizes if you have no
    way to know the best size.'
  prefs: []
  type: TYPE_NORMAL
- en: To improve your chance of finding a tile with the object you want in the middle,
    you also need to try different starting positions.
  prefs: []
  type: TYPE_NORMAL
- en: Systems that use a combination of these techniques can be very effective. For
    example, in 2015, during a state of emergency caused by a drought in California,
    an ML model was used to find lawns, swimming pools, and other features that affect
    water usage.
  prefs: []
  type: TYPE_NORMAL
- en: Cutting the satellite images for the whole state into tiles, just as you’ve
    done in your project, meant each tile could be individually classified. The main
    difference was that the California ML model was trained to recognize not just
    one thing, but several different things, that impact water usage. (You saw in
    Chapter 3 how you can train an ML model to recognize pictures of different objects.)
    Combining image recognition with a map meant California officials could quickly
    understand the impact of water usage across the state.
  prefs: []
  type: TYPE_NORMAL
- en: California is a huge state, and to manually perform such a census or survey
    would have taken a long time. ML was a fast and efficient way to come up with
    a useful estimate, and in times of emergency, speed and efficiency are very important.
  prefs: []
  type: TYPE_NORMAL
- en: ML image recognition techniques are also regularly used in businesses. For example,
    drones can take high-resolution photos while flying over buildings, roofs, bridges,
    solar panels, pipes, and much more. These photos are then chopped into tiles and
    tested by an ML model trained to recognize signs of damage or poor maintenance
    and repair. Automated image recognition systems based on the same principles as
    this chapter’s project are used in a variety of fields, such as civil engineering
    (for inspecting bridges and buildings), agriculture (for recognizing healthy or
    diseased plants and crops), or even public safety (such as in Australia, where
    ML is used in lifesaver drones that can recognize sharks from the air).
  prefs: []
  type: TYPE_NORMAL
- en: What You Learned
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you trained an ML model to recognize objects that are part
    of a larger scene. This is the most complicated project you’ve done so far, but
    hopefully you now have a good understanding of how complex image recognition systems
    are built. You learned some of the challenges of training such systems, like knowing
    how to break up the complex task into simpler tasks (such as by choosing the correct
    tile size), and you got some tips for solving them. You also saw some real-world
    applications for these kinds of complex ML systems and examples of the fields
    where they’re used.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we’ll look at another common use of ML: smart assistants.*'
  prefs: []
  type: TYPE_NORMAL
