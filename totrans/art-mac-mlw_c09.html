<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="index: http://www.index.com/" lang="en" xml:lang="en">
<head>
<title>Chapter 9: Anti-Analysis</title>
<link href="NSTemplate_v1.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:a248aa67-aa2c-49b1-a34e-c916914c0e30" name="Adept.expected.resource"/>
</head>
<body epub:type="bodymatter chapter">
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" id="Page_187" title="187"/>9</span><br/>
<span class="ChapterTitle">Anti-Analysis</span></h1>
</header>
<figure class="opener">
<img alt="" src="image_fi/book_art/chapterart.png"/>
</figure>
<p class="ChapterIntro">In the previous chapters, we leveraged both static and dynamic analysis methods to uncover malware’s persistence mechanisms, core capabilities, and most closely held secrets. Of course, malware authors are not happy about their creations being laid bare for the world to see. Thus, they often seek to complicate analysis by writing anti-analysis logic or other protection schemes. In order to successfully analyze such malware, we must first identify these protections and then circumvent them.</p>
<p>In this chapter we’ll discuss anti-analysis approaches common among macOS malware authors. Generally speaking, there are two kinds of anti-analysis measures: those that aim to thwart static analysis and those that seek to thwart dynamic analysis. Let’s take a look at both.</p>
<h2 id="h1-501942c09-0001"><span epub:type="pagebreak" id="Page_188" title="188"/>Anti-Static-Analysis Approaches</h2>
<p class="BodyFirst">Malware authors use several common approaches to complicate static analysis efforts: </p>
<ul>
<li><b>String-based obfuscation/encryption</b>: During analysis, malware analysts are often trying to answer questions such as “How does the malware persist?” or “What is the address of its command and control server?” Malware that contains plaintext strings related to its persistence, like filepaths or the URL of its command and control server, makes analysis almost too easy. As such, malware authors often obfuscate or encrypt these sensitive strings. </li>
<li><b>Code obfuscation</b>: In order to complicate the static analysis of their code (and sometimes dynamic analysis as well), malware authors can obfuscate the code itself. Various obfuscator tools are available for nonbinary malware specimens like scripts. For Mach-O binaries, malware authors can use executable packers or encryptors to protect the binary’s code. </li>
</ul>
<p>Let’s look at a few examples of anti-static-analysis methods and then discuss how to bypass them. As you’ll see, it’s often easier to overcome anti-static-analysis approaches with dynamic analysis techniques. In some cases, the opposite holds as well; static analysis techniques can reveal anti-dynamic-analysis tactics.</p>
<h3 id="h2-501942c09-0001">Sensitive Strings Disguised as Constants</h3>
<p class="BodyFirst">One of the most basic string-based obfuscations involves splitting sensitive strings into chunks so that they are inlined directly into assembly instructions as constants. Depending on the chunk size, the <code>strings</code> command may miss these strings, while a disassembler, by default, will rather unhelpfully display the chunks as hexadecimal numbers. We find an example of this string obfuscation in Dacls (<a href="#listing9-1" id="listinganchor9-1">Listing 9-1</a>):</p>
<pre><code>main:<br/>...<br/>0x000000010000b5fa    movabs     rcx, <b>0x7473696c702e74</b><br/>0x000000010000b604    mov        qword [rbp+rax+var_209], rcx<br/>0x000000010000b60c    movabs     rcx, <b>0x746e6567612e706f</b><br/>0x000000010000b616    mov        qword [rbp+rax+var_210], rcx<br/>0x000000010000b61e    movabs     rcx, <b>0x6f6c2d7865612e6d</b><br/>0x000000010000b628    mov        qword [rbp+rax+var_218], rcx<br/>0x000000010000b630    movabs     rcx, <b>0x6f632f73746e6567</b><br/>0x000000010000b63a    mov        qword [rbp+rax+var_220], rcx<br/>0x000000010000b642    movabs     rcx, <b>0x4168636e75614c2f</b><br/>0x000000010000b64c    mov        qword [rbp+rax+var_228], rcx<br/>0x000000010000b654    movabs     rcx, <b>0x7972617262694c2f</b><br/>0x000000010000b65e    mov        qword [rbp+rax+var_230], rcx</code></pre>
<p class="CodeListingCaption"><a id="listing9-1">Listing 9-1</a>: Basic string obfuscation (Dacls)</p>
<p>As you can see, six 64-bit values are moved first into the <code>RCX</code> register, then into adjacent stack-based variables. The astute reader will notice that each byte of these values falls within the range of printable ASCII <span epub:type="pagebreak" id="Page_189" title="189"/>characters. We can overcome this basic obfuscation using a disassembler. Simply instruct the disassembler to decode the constants as characters instead of the default, hexadecimal. In the Hopper disassembler, you can simply <span class="KeyCaps">CTRL</span>-click the constant and select <b>Characters</b> to use the <span class="KeyCaps">shift</span>-<span class="KeyCaps">r</span> keyboard shortcut (<a href="#listing9-2" id="listinganchor9-2">Listing 9-2</a>):</p>
<pre><code>main:<br/>...<br/>0x000000010000b5fa    movabs     rcx, '<b>t.plist</b>'<br/>0x000000010000b604    mov        qword [rbp+rax+var_209], rcx<br/>0x000000010000b60c    movabs     rcx, '<b>op.agent</b>'<br/>0x000000010000b616    mov        qword [rbp+rax+var_210], rcx<br/>0x000000010000b61e    movabs     rcx, '<b>m.aex-lo</b>'<br/>0x000000010000b628    mov        qword [rbp+rax+var_218], rcx<br/>0x000000010000b630    movabs     rcx, '<b>gents/co</b>'<br/>0x000000010000b63a    mov        qword [rbp+rax+var_220], rcx<br/>0x000000010000b642    movabs     rcx, '<b>/LaunchA</b>'<br/>0x000000010000b64c    mov        qword [rbp+rax+var_228], rcx<br/>0x000000010000b654    movabs     rcx, '<b>/Library</b>'<br/>0x000000010000b65e    mov        qword [rbp+rax+var_230], rcx</code></pre>
<p class="CodeListingCaption"><a id="listing9-2">Listing 9-2</a>: Deobfuscated strings (Dacls)</p>
<p>If we reconstitute the split string (noting the slight overlap of the first two string components), this deobfuscated disassembly now reveals the path of the malware’s persistent launch item: <em>/Library/LaunchAgents/com.aex-loop.agent.plist</em>.</p>
<h3 id="h2-501942c09-0002">Encrypted Strings</h3>
<p class="BodyFirst">In previous chapters, we looked at several more complex examples of string-based obfuscations. For example, in <span class="xref" itemid="xref_target_Chapter 7">Chapter 7</span> we noted that WindTail contains various embedded base64-encoded and AES-encrypted strings, including the address of its command and control server. The encryption key needed to decrypt the string is hardcoded within the malware, meaning it would be possible to manually decode and decrypt the server’s address. However, this would involve some legwork, such as finding (or scripting up) an AES decryptor. Moreover, if the malware used a custom (or nonstandard) algorithm to encrypt the strings, even more work would be involved. Of course, at some point the malware will have to decode and decrypt the protected strings so that it can use them, such as to connect to a command and control server for tasking. As such, it’s often far more efficient to simply allow the malware to run, which should trigger the decryption of its strings. If you’re monitoring the execution of the malware, the decrypted strings can be easily recovered. </p>
<p>In <span class="xref" itemid="xref_target_Chapter 7">Chapter 7</span>, I showed one technique for doing this: using a network monitor, which allowed us to passively recover the (previously encrypted) address of the malware’s command and control server as the malware beaconed out for tasking. We can accomplish the same thing using a debugger, as you’ll see here. First, we locate WindTail’s decryption logic, a method named <code>yoop:</code>. (In a subsequent section, I’ll describe how to locate such methods.) Looking at cross-references to this method, we can see it’s invoked any time the malware needs to decrypt one of its strings prior to use. For example, <span epub:type="pagebreak" id="Page_190" title="190"/><a href="#listing9-3" id="listinganchor9-3">Listing 9-3</a> shows a snippet of disassembly that invokes the <code>yoop:</code> method <span aria-label="annotation1" class="CodeAnnotation">1</span> to decrypt the malware’s primary command and control server.</p>
<pre><code>0x0000000100001fe5    mov        r13, qword [objc_msgSend]<br/>...<br/>0x0000000100002034    mov        rsi, @selector(<b>yoop:</b>)<br/>0x000000010000203b    lea        rdx, @"F5Ur0CCFMOfWHjecxEqGLy...OLs="<br/>0x0000000100002042    mov        rdi, self<br/><span aria-label="annotation1" class="CodeAnnotationHang">1</span> 0x0000000100002045    call       r13 <br/><br/><span aria-label="annotation2" class="CodeAnnotationHang">2</span> 0x0000000100002048    mov        rcx, rax </code></pre>
<p class="CodeListingCaption"><a id="listing9-3">Listing 9-3</a>: Decryption of a command and control server (WindTail)</p>
<p>We can set a debugger breakpoint at <code>0x100002048</code>, which is the address of the instruction immediately after the call to <code>yoop:</code> <span aria-label="annotation2" class="CodeAnnotation">2</span>. Because the <code>yoop:</code> method returns a plaintext string, we can print this string when we hit this breakpoint. (Recall that a method’s return value can be found in the <code>RAX</code> register.) This reveals the malware’s primary command and control server, <em>flux2key.com</em>, as shown in <a href="#listing9-4" id="listinganchor9-4">Listing 9-4</a>:</p>
<pre><code>% <b>lldb Final_Presentation.app</b> <br/><br/>(lldb) <b>target create "Final_Presentation.app"</b><br/>Current executable set to 'Final_Presentation.app' (x86_64).<br/><br/>(lldb) <b>b 0x100002048</b><br/>(lldb) <b>run</b><br/><br/>Process 826 stopped<br/>* thread #5, stop reason = breakpoint 1.1<br/><br/>(lldb) <b>po $rax</b><br/>http://flux2key.com/liaROelcOeVvfjN/fsfSQNrIyxeRvXH.php?very=%@&amp;xnvk=%@</code></pre>
<p class="CodeListingCaption"><a id="listing9-4">Listing 9-4</a>: A decrypted command and control address (WindTail)</p>
<p>It’s worth noting that you could also set a breakpoint on the return instruction (<code>retn</code>) within the decryption function. When the breakpoint is hit, you’ll once again find the decrypted string in the <code>RAX</code> register. A benefit of this approach is that you only have to set a single breakpoint, instead of several at the locations from which the decryption method is invoked. This means that any time the malware decrypts, not just its command and control server but any string, you’ll be able to recover the plaintext of that as well. However, it would become rather tedious to manually manage this breakpoint, as it will be invoked many times to decrypt each of the malware’s strings. A more efficient approach would be to add additional debugger commands (via <code>breakpoint command add</code>) to the breakpoint. Then, once the breakpoint is hit, your breakpoint commands will be automatically executed and could just print out the register holding the decrypted string and then allow the process to automatically continue. If you’re interested in the caller, perhaps to locate where a specific decrypted string is used, consider printing out the stack backtrace as well. </p>
<p><span epub:type="pagebreak" id="Page_191" title="191"/>Note that this breakpoint-based approach can be applied to most string obfuscation or encryption methods, as it is agnostic to the algorithm used. That is to say, it generally does not matter what technique the malware is using to protect strings or data. If you’re able to locate the deobfuscation or decryption routine during static analysis, all you’ll need in order to read the string is a well-placed debugger breakpoint.</p>
<h3 id="h2-501942c09-0003">Locating Obfuscated Strings</h3>
<p class="BodyFirst">Of course, this begs the question: How can you determine that malware has obfuscated sensitive strings and data? And how can you locate the routines within the malware responsible for returning their plaintext values?</p>
<p>While there are no foolproof methods for the latter, it’s generally straightforward to ascertain if a malicious specimen has something to hide. Take, for example, the output of the <code>strings</code> command, which usually produces a significant number of extracted strings. If its output is rather limited or contains a large number of nonsensical strings (especially of significant length), this is a good indication that some type of string obfuscation is in play. For example, if we run <code>strings</code> on WindTail, we’ll find various plaintext strings alongside what appear to be obfuscated strings (<a href="#listing9-5" id="listinganchor9-5">Listing 9-5</a>):</p>
<pre><code>% <b>strings - Final_Presentation.app/Contents/MacOS/usrnode</b><br/><br/>/bin/sh<br/>open -a<br/>Song.dat<br/>KEY_PATH<br/>oX0s4Qj3GiAzAnOmzGqjOA==<br/>ie8DGq3HZ82UqV9N4cpuVw==<br/>F5Ur0CCFMO/fWHjecxEqGLy/xq5gE98ZviUSLrtFPmHE6gRZGU7ZmXiW+/gzAouX<br/>aagHdDG+YP9BEmHLCg9PVXOuIlMB12oTVPlb8CHvda6TWtptKmqJVvI4o63iQ36Shy9Y9hPtlh+kcrCL0uj+tQ==</code></pre>
<p class="CodeListingCaption"><a id="listing9-5">Listing 9-5</a>: Obfuscated strings (WindTail)</p>
<p>Of course, this method is not foolproof. For example, if the obfuscation method, such as an encryption algorithm, produces non-ASCII characters, the obfuscated content may not show up in the <code>strings</code> output. </p>
<p>However, poking around in a disassembler may reveal many or large chunks of obfuscated or high entropy data that are cross-referenced elsewhere in the binary code. For example, malware called NetWire (which installs a malicious application named <em>Finder.app</em>) contains what appears to be a blob of encrypted data near the start of the <code>__data</code> section (<a href="#figure9-1" id="figureanchor9-1">Figure 9-1</a>).</p>
<figure>
<img alt="NetWire contains a giant section of obfuscated data" class="keyline" src="image_fi/501942c09/f09001.png"/>
<figcaption><p><a id="figure9-1">Figure 9-1</a>: Embedded obfuscated data (NetWire)</p></figcaption>
</figure>
<p><span epub:type="pagebreak" id="Page_192" title="192"/>A continued triage of the malware’s <code>main</code> function reveals multiple calls to a function at <code>0x00009502</code>. Each call to this function passes in an address that falls within the block of encrypted data, which starts around <code>0x0000e2f0</code> in memory:</p>
<pre><code>0x00007364    push       esi<br/>0x00007365    push       0xe555<br/>0x0000736b    call       <b>sub_9502</b><br/>...<br/>0x00007380    push       0xe5d6 <br/>0x00007385    push       eax<br/>0x00007386    call       <b>sub_9502</b><br/>...<br/>0x000073fd    push       0xe6b6<br/>0x00007402    push       edi<br/>0x00007403    call       <b>sub_9502</b></code></pre>
<p>It seems reasonable to assume that this function is responsible for decrypting the contents of the blob of encrypted data. As noted previously, you can usually set a breakpoint after code that references the encrypted data and then dump the decrypted data. In the case of NetWire, we can set a breakpoint immediately after the final call to the decryption function, and then we can examine the decrypted data in memory. As it decrypts to a sequence of printable strings, we can display it via the <code>x/s</code> debugger command, as in <a href="#listing9-6" id="listinganchor9-6">Listing 9-6</a>:</p>
<pre><code>% <b>lldb Finder.app</b><br/><br/>(lldb) <b>process launch --stop-at-entry</b><br/>(lldb) <b>b 0x00007408</b><br/>Breakpoint 1: where = Finder`Finder[0x00007408], address = 0x00007408<br/><br/>(lldb) <b>c</b><br/>Process 1130 resuming<br/>Process 1130 stopped * thread #1, queue = 'com.apple.main-thread', stop reason = breakpoint 1.1<br/><br/>(lldb) <b>x/20s 0x0000e2f0</b><br/><span aria-label="annotation1" class="CodeAnnotationHang">1</span> 0x0000e2f8: "89.34.111.113:443;" <br/>0x0000e4f8: "Password"<br/>0x0000e52a: "HostId-%Rand%"<br/>0x0000e53b: "Default Group"<br/>0x0000e549: "NC"<br/>0x0000e54c: "-"<br/><span aria-label="annotation2" class="CodeAnnotationHang">2</span> 0x0000e555: "%home%/.defaults/Finder" <br/>0x0000e5d6: "com.mac.host"<br/>0x0000e607: "{0Q44F73L-1XD5-6N1H-53K4-I28DQ30QB8Q1}"<br/>...</code></pre>
<p class="CodeListingCaption"><a id="listing9-6">Listing 9-6</a>: Dumping now-decrypted configuration parameters (NetWire)</p>
<p>The contents turn out to be configuration parameters that include the address of the malware’s command and control server <span aria-label="annotation1" class="CodeAnnotation">1</span>, as well as its installation path <span aria-label="annotation2" class="CodeAnnotation">2</span>. Recovering these configuration parameters greatly expedites our analysis.</p>
<h3 id="h2-501942c09-0004"><span epub:type="pagebreak" id="Page_193" title="193"/>Finding the Deobfuscation Code</h3>
<p class="BodyFirst">When we encounter obfuscated or encrypted data in a malicious sample, it’s important to locate the code that deobfuscates or decrypts this data. Once we’ve done so, we can set a debugging breakpoint and recover the plaintext. This raises the question of how we can locate that code within the malware. </p>
<p>Usually, the best approach is to use a disassembler or decompiler to identify code that references the encrypted data. These references generally indicate either the code responsible for decryption or code that later references the data in a decrypted state. </p>
<p>For example, in the case of WindTail, we noted various strings that appeared to be obfuscated. If we select one such string (<code>"BouCfWujdfbAUfCos/iIOg=="</code>), we find it is referenced in the following disassembly (<a href="#listing9-7" id="listinganchor9-7">Listing 9-7</a>):</p>
<pre><code>0x000000010000239f    mov        rsi, @selector(yoop:)<br/><b>0x00000001000023a6</b>    lea        rdx, @"BouCfWujdfbAUfCos/iIOg=="<br/>0x00000001000023ad    mov        r15, qword [_objc_msgSend] <br/>0x00000001000023b4    call       r15</code></pre>
<p class="CodeListingCaption"><a id="listing9-7">Listing 9-7</a>: Possible string deobfuscation (WindTail)</p>
<p>Recall that the <code>objc_msgSend</code> function is used to invoke Objective-C methods, that the <code>RSI</code> register will hold the name of the method being invoked, and that the <code>RDI</code> register will hold its first parameter. From the disassembly that references the obfuscated string, we can see that the malware is invoking the <code>yoop:</code> method with the obfuscated string as its parameter. Enumerating cross-references to the <code>yoop:</code> selector (found at <code>0x100015448</code>) reveals that the method is invoked once for each string that needs to be decoded and decrypted (<a href="#figure9-2" id="figureanchor9-2">Figure 9-2</a>).</p>
<figure>
<img alt="The cross-references to 0x100015448 contain multiple addresses, all of which have the Value “mov rsi, qword [0x100015448].”" class="keyline" src="image_fi/501942c09/f09002.png"/>
<figcaption><p><a id="figure9-2">Figure 9-2</a>: Cross-references to <span class="LiteralInCaption"><code>@</code></span><span class="LiteralInCaption"><code>selector(</code></span><span class="LiteralInCaption"><code>yoop:)</code></span> (WindTail)</p></figcaption>
</figure>
<p>Taking a closer look at the actual <code>yoop:</code> method reveals calls to methods named <code>decode:</code> and <code>AESDecryptWithPassphrase:</code>, confirming it is indeed a decoding and decryption routine (<a href="#listing9-8" id="listinganchor9-8">Listing 9-8</a>). </p>
<pre><code><span epub:type="pagebreak" id="Page_194" title="194"/>-(void *)yoop:(void *)string {<br/><br/>  rax = [[[NSString alloc] initWithData:[[yu decode:string]<br/>         AESDecryptWithPassphrase:key] encoding:0x1] <br/>         stringByTrimmingCharactersInSet:[NSCharacterSet whitespaceCharacterSet]];<br/><br/>  return rax;<br/>}</code></pre>
<p class="CodeListingCaption"><a id="listing9-8">Listing 9-8</a>: The <code>yoop:</code> method (WindTail)</p>
<p>Another approach to locating decryption routines is to peruse the disassembly for calls into system crypto routines (like <code>CCCrypt</code>) and well-known crypto constants (such as AES’s <code>s-boxes</code>). In certain disassemblers, third-party plug-ins such as FindCrypt<sup class="endnote"><a href="#c09-endnote-1" id="c09-noteref-1">1</a></sup> can automate this crypto discovery process.</p>
<h3 id="h2-501942c09-0005">String Deobfuscation via a Hopper Script</h3>
<p class="BodyFirst">The downside to the breakpoint-based approach is that it only allows you to recover specific decrypted strings. If an encrypted string is exclusively referenced in a block of code that isn’t executed, you’ll never encounter its decrypted value. A more comprehensive approach is to re-implement the malware’s decryption routine and then pass in all the malware’s encrypted strings to recover their plaintext values. </p>
<p>In <span class="xref" itemid="xref_target_Chapter 6">Chapter 6</span>, we introduced disassemblers, highlighting how they can be leveraged to statically analyze compiled binaries. Such disassemblers also generally support external third-party scripts or plug-ins that can directly interact with a binary’s disassembly. This capability is extremely useful and can extend the functionality of a disassembler, especially in the context of overcoming malware’s anti-static-analysis efforts. As an example of this, we’ll create a Python-based Hopper script capable of decrypting all the embedded strings in a sophisticated malware sample. </p>
<p>DoubleFantasy is the notorious Equation APT Group’s first-stage implant, capable of surveying an infected host and installing a persistent second-stage implant on systems of interest. The majority of its strings are encrypted, and many remain encrypted even while the malware is executed unless certain prerequisites, such as specific tasking, are met. However, as the embedded string decryption algorithm is fairly simple, we can re-implement it in a Hopper Python script to decrypt all of the malware’s strings.</p>
<p>Looking at the disassembly of the DoubleFantasy malware, we can see what appears to be an encrypted string and its length (<code>0x38</code>) being stored to the stack prior to a call into an unnamed subroutine (<a href="#listing9-9" id="listinganchor9-9">Listing 9-9</a>):</p>
<pre><code>0x00007a93    mov        dword [esp+0x8], 0x38<br/>0x00007a9b    lea        eax, dword [ebx+0x105a7]    ;"\xDA\xB3\...\x14"<br/>0x00007aa1    mov        dword [esp+0x4], eax<br/>0x00007aa5    call       sub_d900 </code></pre>
<p class="CodeListingCaption"><a id="listing9-9">Listing 9-9</a>: An encrypted string, and a call to a possible string-decryption function (DoubleFantasy)</p>
<p><span epub:type="pagebreak" id="Page_195" title="195"/>An examination of this subroutine reveals it decrypts a passed-in string by running it through a simple XOR algorithm. As shown in the following snippet of disassembly (<a href="#listing9-10" id="listinganchor9-10">Listing 9-10</a>), the algorithm uses two keys:</p>
<pre><code>0x0000d908    mov        eax, dword [ebp+arg_4]<br/><span aria-label="annotation1" class="CodeAnnotationHang">1</span> 0x0000d90b    movzx      edi, byte [eax]<br/>...<br/>0x0000d930    movzx      edx, byte [esi]<br/>0x0000d933    inc        esi<br/>0x0000d934    mov        byte [ebp+var_D], dl<br/>0x0000d937    mov        eax, edx<br/>0x0000d939    mov        edx, dword [ebp+arg_0]<br/>0x0000d93c    xor        eax, edi 1<br/>0x0000d93e    xor        eax, ecx<br/><span aria-label="annotation2" class="CodeAnnotationHang">2</span> 0x0000d940    xor        eax, 0x47<br/>0x0000d943    mov        byte [edx+ecx-1], al<br/>0x0000d947    movzx      eax, byte [ebp+var_D]<br/>0x0000d94b    inc        ecx<br/>0x0000d94c    add        edi, eax<br/>0x0000d94e    cmp        ecx, dword [ebp+var_C]<br/>0x0000d951    jne        loc_d930</code></pre>
<p class="CodeListingCaption"><a id="listing9-10">Listing 9-10</a>: A simple string-decryption algorithm (DoubleFantasy)</p>
<p>The first key is based on the values of the encrypted string itself <span aria-label="annotation1" class="CodeAnnotation">1</span>, while the second is hardcoded to <code>0x47</code> <span aria-label="annotation2" class="CodeAnnotation">2</span>. With this understanding of the malware’s string decryption algorithm, we can trivially re-implement it in Python (<a href="#listing9-11" id="listinganchor9-11">Listing 9-11</a>):</p>
<pre><code>def decrypt(encryptedStr):<br/>   ...<br/> <span aria-label="annotation1" class="CodeAnnotationCode2">1</span> key_1 = encryptedStr[0]<br/>   key_2 = 0x47   <br/><br/>   for i in range(1, len(encryptedStr)): <br/>   <span aria-label="annotation2" class="CodeAnnotationCode2">2</span> byte = (encryptedStr[i] ^ key_1 ^ i ^ key_2) &amp; 0xFF <br/>     decryptedStr.append(chr(byte)) <br/> <br/>     key_1 = encryptedStr[i] + key_1<br/><br/> <span aria-label="annotation3" class="CodeAnnotationCode2">3</span> return ''.join(decryptedStr) </code></pre>
<p class="CodeListingCaption"><a id="listing9-11">Listing 9-11</a>: A re-implementation of DoubleFantasy’s string decryption algorithm in Python</p>
<p>In our Python re-implementation of the malware’s decryption routine, we first initialize both XOR keys <span aria-label="annotation1" class="CodeAnnotation">1</span>. Then we simply iterate over each byte of the encrypted string, de-XORing each with both keys <span aria-label="annotation2" class="CodeAnnotation">2</span>. The decrypted string is then returned <span aria-label="annotation3" class="CodeAnnotation">3</span>.</p>
<p>With the malware’s decryption algorithm re-implemented, we now need to invoke it on all of the malware’s embedded encrypted strings. Luckily, Hopper makes this fairly straightforward. DoubleFantasy’s encrypted strings are all stored in its <code>_cstring</code> segment. Using the Hopper APIs made available to any Hopper script, we programmatically iterate through this segment, <span epub:type="pagebreak" id="Page_196" title="196"/>invoking the re-implemented decryption algorithm on each string. We add the logic in <a href="#listing9-12" id="listinganchor9-12">Listing 9-12</a> to our Python code to accomplish this. </p>
<pre><code>#from start to end of cString segment<br/>#extract/decrypt all strings<br/>i = cSectionStart<br/>while i &lt; cSectionEnd:<br/><br/>   #skip if item is just a 0x0<br/>   if 0 == cSegment.readByte(i):<br/>      i += 1<br/>      continue<br/><br/>   stringStart = i<br/>   encryptedString = []<br/>   while (0 != cSegment.readByte(i)): <span aria-label="annotation1" class="CodeAnnotationCode">1</span><br/>      encryptedString.append(cSegment.readByte(i))<br/>      i += 1<br/><br/>      decryptedString = decryptStr(encryptedString) <span aria-label="annotation2" class="CodeAnnotationCode">2</span><br/>      if decryptedString.isascii(): <span aria-label="annotation3" class="CodeAnnotationCode">3</span><br/><br/>         print(decryptedString)<br/> <br/>         #add as inline comment and to all references <span aria-label="annotation4" class="CodeAnnotationCode">4</span><br/>         doc.getCurrentSegment().setInlineCommentAtAddress(stringStart, decryptedString)<br/> <br/>         for reference in cSegment.getReferencesOfAddress(stringStart):<br/>            doc.getCurrentSegment().setInlineCommentAtAddress(reference, decryptedString)</code></pre>
<p class="CodeListingCaption"><a id="listing9-12">Listing 9-12</a>: Leveraging the Hopper API to decrypt embedded strings (DoubleFantasy)</p>
<p>In this listing, we iterate through the <code>_cstring</code> segment and find any null-terminated items, which includes the malware’s embedded encrypted strings <span aria-label="annotation1" class="CodeAnnotation">1</span>. For each of these items, we invoke our decryption function on it <span aria-label="annotation2" class="CodeAnnotation">2</span>. Finally, we check if the item decrypted to a printable ASCII string <span aria-label="annotation3" class="CodeAnnotation">3</span>. This check ensures we ignore other items found within the <code>_cstring</code> segment that are not encrypted strings. The decrypted string is then added as an inline comment directly into the disassembly, both at the location of the encrypted string and at any location where it is referenced in code to facilitate continuing analysis <span aria-label="annotation4" class="CodeAnnotation">4</span>. </p>
<p>After executing our decryption script in Hopper’s Script menu, the strings are decrypted and the disassembly is annotated. For example, as you can see in <a href="#listing9-13" id="listinganchor9-13">Listing 9-13</a>, the string <code>"\xDA\xB3\...\x14"</code> decrypts to <em>/Library/Caches/com.apple.LaunchServices-02300.csstore</em>, which turns out to be the hardcoded path of the malware’s configuration file. </p>
<pre><code>0x00007a93    mov        dword [esp+0x8], 0x38<br/>0x00007a9b    lea        eax, dword [ebx+0x105a7] ; "/Library/Caches/com.apple.LaunchServices<br/>                                                     -02300.csstore, \xDA\xB3\...\x14"<br/>0x00007aa1    mov        dword [esp+0x4], eax<br/>0x00007aa5    call       sub_d900</code></pre>
<p class="CodeListingCaption"><a id="listing9-13">Listing 9-13</a>: Disassembly, now annotated with the decrypted string (DoubleFantasy)</p>
<h3 id="h2-501942c09-0006"><span epub:type="pagebreak" id="Page_197" title="197"/>Forcing the Malware to Execute Its Decryption Routine</h3>
<p class="BodyFirst">Creating disassembly scripts to facilitate analysis is a powerful approach. However, in the context of string decryptions, it requires that you both fully understand the decryption algorithm and are capable of re-implementing it. This can often be a time-consuming endeavor. In this section we’ll look at a potentially more efficient approach, especially for samples that implement complex decryption algorithms. </p>
<p>A malware specimen is almost certainly designed to decrypt all its strings; we just need a way to convince the malware to do so. Turns out this isn’t too hard. In fact, if we create a dynamic library and inject it into the malware, this library can then directly invoke the malware’s string decryption routine for all encrypted strings, all without having to understand the internals of the decryption algorithm. Let’s walk through this process using the EvilQuest malware as our target. </p>
<p>First, we note that EvilQuest’s binary, named <em>patch</em>, appears to contain many obfuscated strings (<a href="#listing9-14" id="listinganchor9-14">Listing 9-14</a>):</p>
<pre><code>% <b>strings - EvilQuest/patch</b><br/>Host: %s<br/>ERROR: %s<br/>1PnYz01rdaiC0000013<br/>1MNsh21anlz906WugB2zwfjn0000083<br/>2Uy5DI3hMp7o0cq|T|14vHRz0000013<br/>3mTqdG3tFoV51KYxgy38orxy0000083<br/>0JVurl1WtxB53WxvoP18ouUM2Qo51c3v5dDi0000083<br/>2WVZmB2oRkhr1Y7s1D2asm{v1Al5AT33Xn3X0000053<br/>3iHMvK0RFo0r3KGWvD28URSu06OhV61tdk0t22nizO3nao1q0000033<br/>...</code></pre>
<p class="CodeListingCaption"><a id="listing9-14">Listing 9-14</a>: Obfuscated strings (EvilQuest)</p>
<p>Statically analyzing EvilQuest for a function that takes the obfuscated strings as input quickly reveals the malware’s deobfuscation (decryption) logic, found in a function named <code>ei_str</code> (<a href="#listing9-15" id="listinganchor9-15">Listing 9-15</a>):</p>
<pre><code>lea     rdi, "0hC|h71FgtPJ32afft3EzOyU3xFA7q0{LBxN3vZ"...<br/>call    <b>ei_str</b><br/>...<br/>lea     rdi, "0hC|h71FgtPJ19|69c0m4GZL1xMqqS3kmZbz3FW"...<br/>call    <b>ei_str</b></code></pre>
<p class="CodeListingCaption"><a id="listing9-15">Listing 9-15</a>: Invocation of a deobfuscation function, <code>ei_str</code> (EvilQuest)</p>
<p>The <code>ei_str</code> function is rather long and complicated, so instead of trying to decrypt the strings solely via a static analysis approach, we’ll opt for a dynamic approach. Moreover, as many of the strings are only deobfuscated at runtime under certain circumstances, such as when a specific command is received, we’ll inject a custom library into the code instead of leveraging a debugger. </p>
<p><span epub:type="pagebreak" id="Page_198" title="198"/>Our custom injectable library will perform two tasks. First, within a running instance of the malware, it will resolve the address of the deobfuscation function, <code>ei_str</code>. Then it will invoke the <code>ei_str</code> function for all encrypted strings found embedded within the malware’s binary. Because we place this logic in the constructor of the dynamic library, it will be executed when the library is loaded, well before the malware’s own code is run.</p>
<p><a href="#listing9-16" id="listinganchor9-16">Listing 9-16</a> shows the code we’ll write for the constructor of the injectable dynamic decryptor library:</p>
<pre><code>//library constructor<br/>//1. resolves address of malware's `ei_str` function<br/>//2. invokes it for all embedded encrypted strings<br/>__attribute__((constructor)) static void decrypt() {<br/><br/>    //define &amp; resolve the malware's ei_str function<br/>    typedef char* (*ei_str)(char* str);<br/>    ei_str ei_strFP = dlsym(RTLD_MAIN_ONLY, "ei_str");<br/> <br/>    //init pointers<br/>    //the __cstring segment starts 0xF98D after ei_str and is 0x29E9 long<br/>    char* start = (char*)ei_strFP + 0xF98D;<br/>    char* end = start + 0x29E9;<br/>    char* current = start;<br/> <br/>    //decrypt all strings<br/>    while(current &lt; end) {<br/><br/>      //decrypt and print out<br/>      char* string = ei_strFP(current);<br/>      printf("decrypted string (%#lx): %s\n", (unsigned long)current, string);<br/><br/>      //skip to next string<br/>      current += strlen(current);<br/>    }<br/><br/>    //bye!<br/>    exit(0);<br/>}</code></pre>
<p class="CodeListingCaption"><a id="listing9-16">Listing 9-16</a>: Our dynamic string deobfuscator library (EvilQuest)</p>
<p>The library code scans over the malware’s entire <code>__cstring</code> segment, which contains all the obfuscated strings. For each string, it invokes the malware’s own <code>ei_str</code> function to deobfuscate the string. Once it’s compiled (<code>% clang decryptor.m -dynamiclib -framework Foundation -o decryptor.dylib</code>), we can coerce the malware to load our decryptor library via the <code>DYLD_INSERT_LIBRARIES </code>environment variable. In the terminal of a virtual machine, we can execute the following command:</p>
<pre><code>% <b>DYLD_INSERT_LIBRARIES=</b><var>&lt;path to dylib&gt;</var> <var>&lt;path to EvilQuest&gt;</var></code></pre>
<p><span epub:type="pagebreak" id="Page_199" title="199"/>Once loaded, the library’s code is automatically invoked and coerces the malware to decrypt all its strings (<a href="#listing9-17" id="listinganchor9-17">Listing 9-17</a>):</p>
<pre><code>% <b>DYLD_INSERT_LIBRARIES=/tmp/decryptor.dylib EvilQuest/patch</b><br/><br/>decrypted string (0x10eb675ec): andrewka6.pythonanywhere.com<br/><br/>decrypted string (0x10eb67a95): *id_rsa*/i<br/>decrypted string (0x10eb67c15): *key*.png/i<br/>decrypted string (0x10eb67c35): *wallet*.png/i<br/>decrypted string (0x10eb67c55): *key*.jpg/i<br/><br/>decrypted string (0x10eb67d12): [Memory Based Bundle]<br/>decrypted string (0x10eb67d6b): ei_run_memory_hrd<br/><br/>decrypted string (0x10eb681ad): <br/>&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;<br/>&lt;plist version="1.0"&gt;<br/>&lt;dict&gt;<br/>&lt;key&gt;Label&lt;/key&gt;<br/>&lt;string&gt;%s&lt;/string&gt;<br/><br/>&lt;key&gt;ProgramArguments&lt;/key&gt;<br/>&lt;array&gt;</code></pre>
<p class="CodeListingCaption"><a id="listing9-17">Listing 9-17</a>: Deobfuscated strings (EvilQuest)</p>
<p>The decrypted output (abridged) reveals informative strings that appear to show a potential command and control server, files of interest, and a template for launch item persistence.</p>
<p>If the malware is compiled with a hardened runtime, the dynamic loader will ignore the <code>DYLD_INSERT_LIBRARIES</code> variable and fail to load our deobfuscator. To bypass this protection, you can first disable System Integrity Protection (SIP) and then execute the following command to set the <code>amfi_get_out_of_my_way</code> boot argument and then reboot your analysis system (or virtual machine):</p>
<pre><code># <b>nvram boot-args="amfi_get_out_of_my_way=0x1"</b></code></pre>
<p>For more information on this topic, see “How to Inject Code into Mach-O Apps, Part II.”<sup class="endnote"><a href="#c09-endnote-2" id="c09-noteref-2">2</a></sup> </p>
<h3 id="h2-501942c09-0007">Code-Level Obfuscations </h3>
<p class="BodyFirst">To further protect their creations from analysis, malware authors may also turn toward broader code-level obfuscations. For malicious scripts, which are otherwise easy to analyze, as they are not compiled into binary code, this sort of obfuscation is quite common. As we discussed in <span class="xref" itemid="xref_target_Chapter 4">Chapter 4</span>, we can often leverage tools such as beautifiers to improve the readability of obfuscated scripts. Obfuscated Mach-O binaries are somewhat less common, but we’ll look at several examples of this technique. </p>
<p><span epub:type="pagebreak" id="Page_200" title="200"/>One such obfuscation method involves adding <em>spurious</em>, or <em>garbage</em>, instructions at compile time. These instructions are essentially non-operations (NOPs) and have no impact on the core functionality of the malware. However, when spread effectively throughout the binary, they can mask the malware’s real instructions. The prolific Pirrit malware provides an example of such binary obfuscation. To hinder static analysis and hide other logic aimed at preventing dynamic analysis, its authors added large amounts of garbage instructions. In the case of Pirrit, these instructions make up either calls into system APIs (whose results are ignored), bogus control flow blocks, or inconsequential modifications to unused memory. The following is an example of the former, in which we see the <code>dlsym</code> API being invoked. This API is normally invoked to dynamically resolve the address of a function by name. In <a href="#listing9-18" id="listinganchor9-18">Listing 9-18</a>, the decompiler has determined the results are unused:</p>
<pre><code>dlsym(dlopen(0x0, 0xa), 0x100058a91);<br/>dlsym(dlopen(0x0, 0xa), 0x100058a80);<br/>dlsym(dlopen(0x0, 0xa), 0x100058a64);<br/>dlsym(dlopen(0x0, 0xa), 0x100058a50);<br/>dlsym(dlopen(0x0, 0xa), 0x100058a30);<br/>dlsym(dlopen(0x0, 0xa), 0x100058a10);<br/>dlsym(dlopen(0x0, 0xa), 0x1000589f0); </code></pre>
<p class="CodeListingCaption"><a id="listing9-18">Listing 9-18</a>: Spurious function calls (Pirrit)</p>
<p>Elsewhere in Pirrit’s decompilation, we find spurious code control blocks whose logic is not relevant to the core functionality of the malware. Take, for instance, <a href="#listing9-19" id="listinganchor9-19">Listing 9-19</a>, which contains several pointless comparisons of the <code>RAX</code> register. (The final check can only evaluate to true if <code>RAX</code> is equal to <code>0x6b1464f0</code>, so the first two checks are entirely unnecessary.) Following this is a large sequence of instructions that modify a section of the binary’s memory, which is otherwise unused: </p>
<pre><code>if (rax != 0x6956b086) {<br/>   if (rax != 0x6ad066c0) {<br/>       if (rax == 0x6b1464f0) {<br/>       *(int8_t *)byte_1000589fa = var_29 ^ 0x37;<br/>       *(int8_t *)byte_1000589fb = *(int8_t *)byte_1000589fb ^ 0x9a;<br/>       *(int8_t *)byte_1000589fc = *(int8_t *)byte_1000589fc ^ 0xc8;<br/>       *(int8_t *)byte_1000589fd = *(int8_t *)byte_1000589fd ^ 0xb2;<br/>       *(int8_t *)byte_1000589fe = *(int8_t *)byte_1000589fe ^ 0x15;<br/>       *(int8_t *)byte_1000589ff = *(int8_t *)byte_1000589ff ^ 0x78;<br/>       *(int8_t *)byte_100058a00 = *(int8_t *)byte_100058a00 ^ 0x1d;<br/>       ...<br/>       *(int8_t *)byte_100058a20 = *(int8_t *)byte_100058a20 ^ 0x69;<br/>       *(int8_t *)byte_100058a21 = *(int8_t *)byte_100058a21 ^ 0xab;<br/>       *(int8_t *)byte_100058a22 = *(int8_t *)byte_100058a22 ^ 0x02;<br/>       *(int8_t *)byte_100058a23 = *(int8_t *)byte_100058a23 ^ 0x46;</code></pre>
<p class="CodeListingCaption"><a id="listing9-19">Listing 9-19</a>: Spurious instructions (Pirrit)</p>
<p><span epub:type="pagebreak" id="Page_201" title="201"/>In almost every subroutine in Pirrit’s disassembly, we find massive amounts of such garbage instructions. Though they do slow down our analysis and initially mask the malware’s true logic, once we understand their purpose, we can simply ignore them and scroll past. For more information on this and other similar obfuscation schemes, you can read “Using LLVM to Obfuscate Your Code During Compilation.”<sup class="endnote"><a href="#c09-endnote-3" id="c09-noteref-3">3</a></sup></p>
<h3 id="h2-501942c09-0008">Bypassing Packed Binary Code</h3>
<p class="BodyFirst">Another common way to obfuscate binary code is with a packer. In a nutshell, a <em>packer</em> compresses binary code to prevent its static analysis while also inserting a small unpacker stub at the entry point of the binary. As the unpacker stub is automatically executed when the packed program is launched, the original code is restored in memory and then executed, retaining the binary’s original functionality.</p>
<p>Packers are payload-agnostic and thus can generally pack any binary. This means that legitimate software can also be packed, as software developers occasionally seek to thwart analysis of their proprietary code. Thus, we can’t assume any packed binary is malicious without further analysis.</p>
<p>The well-known UPX packer is a favorite among both Windows and macOS malware authors.<sup class="endnote"><a href="#c09-endnote-4" id="c09-noteref-4">4</a></sup> Luckily, unpacking UPX-packed files is easy. You can simply execute UPX with the <code>-d</code> command line flag (<a href="#listing9-20" id="listinganchor9-20">Listing 9-20</a>). If you’d like to write the unpacked binary to a new file, use the <code>-o</code> flag as well. </p>
<pre><code>% <b>upx -d ColdRoot.app/Contents/MacOS/com.apple.audio.driver </b><br/><br/>                       Ultimate Packer for eXecutables<br/>                          Copyright (C) 1996 - 2013<br/><br/>  With LZMA support, Compiled by Mounir IDRASSI (mounir@idrix.fr)<br/><br/>        File size         Ratio      Format               Name<br/>   --------------------   ------   -----------   ----------------------<br/>   3292828   &lt;-  983040   29.85%    Mach/i386    com.apple.audio.driver<br/><br/>  Unpacked 1 file.</code></pre>
<p class="CodeListingCaption"><a id="listing9-20">Listing 9-20</a>: Unpacking via UPX (ColdRoot)</p>
<p>As you can see, we’ve unpacked a UPX-packed variant: the malware known as ColdRoot. Once it’s unpacked and decompressed, we can commence static and dynamic analysis.</p>
<p>Here is a valid question: How did we know the sample was packed? And how did we know it was packed with UPX specifically? One semiformal approach to figuring out which binaries are packed is to calculate the <em>entropy</em> (amount of randomness) of the binary to detect the packed segments, which will have a much higher level of randomness than normal binary instructions. I’ve added code to the Objective-See TaskExplorer utility to generically detect packed binaries in this manner.<sup class="endnote"><a href="#c09-endnote-5" id="c09-noteref-5">5</a></sup></p>
<p><span epub:type="pagebreak" id="Page_202" title="202"/>A less formal approach is to leverage the <code>strings</code> command or load the binary in your disassembler of choice and peruse the code. With experience, you’ll be able to infer that a binary is packed if you observe the following: </p>
<ul>
<li>Unusual section names </li>
<li>A majority of strings obfuscated </li>
<li>Large chunks of executable code that cannot be disassembled </li>
<li>A low number of imports (references to external APIs) </li>
</ul>
<p>Unusual section names are an especially good indicator, as they can also help identify the packer used to compress the binary. For example, UPX adds a section named <code>__XHDR</code>, which you can see in the output of the <code>strings</code> command or in a Mach-O viewer (<a href="#figure9-3" id="figureanchor9-3">Figure 9-3</a>). </p>
<figure>
<img alt="In com.apple.audio.driver, Executable (x86) contains Mach Header, Load Commands, Section (_XHDR,_xhdr), and Section (_TEXT,_text)." class="keyline" src="image_fi/501942c09/f09003.png"/>
<figcaption><p><a id="figure9-3">Figure 9-3</a>: UPX section header (ColdRoot)</p></figcaption>
</figure>
<p>It is worth noting that UPX is an exception among packers in the sense that it can unpack any UPX-packed binary. More sophisticated malware may leverage custom packers, which may mean that you have no unpacking utility available. Not to worry: if you encounter a packed binary and have no utility to unpack it, a debugger may be your best bet. The idea is simple: run the packed sample under the watchful eye of a debugger, and once the unpacker stub has executed, dump the unprotected binary from memory with the <code>memory read</code> LLDB command. </p>
<p>For another thorough discussion of both analyzing other packers (such as MPRESS) and the process of dumping a packed binary from memory, see Pedro Vilaça’s informative 2014 talk, “F*ck You HackingTeam.”<sup class="endnote"><a href="#c09-endnote-6" id="c09-noteref-6">6</a></sup></p>
<h3 id="h2-501942c09-0009">Decrypting Encrypted Binaries</h3>
<p class="BodyFirst">Similar to packers are <em>binary encryptors</em>, which encrypt the original malware code at the binary level. To automatically decrypt the malware at runtime, the encryptor will often insert a decryptor stub and keying information at the start of the binary unless the operating system natively <span epub:type="pagebreak" id="Page_203" title="203"/>supports encrypted binaries, which macOS does. As noted, the infamous HackingTeam is fond of packers and encryptors. In the blog post “HackingTeam Reborn . . .” I noted that the installer for the HackingTeam’s macOS implant, RCS, leveraged Apple’s proprietary and undocumented Mach-O encryption scheme in an attempt to thwart static analysis.<sup class="endnote"><a href="#c09-endnote-7" id="c09-noteref-7">7</a></sup> </p>
<p>Let’s take a closer look at how to decrypt binaries, such as HackingTeam’s installer, that have been protected via this method. In macOS’s open source Mach-O loader, we find an <code>LC_SEGMENT</code> flag value named <code>SG_PROTECTED_VERSION_1</code> whose value is <code>0x8</code>:<sup class="endnote"><a href="#c09-endnote-8" id="c09-noteref-8">8</a></sup></p>
<pre><code>#define SG_PROTECTED_VERSION_1	0x8 /* This segment is protected.  If the<br/>                                       segment starts at file offset 0, the<br/>                                       first page of the segment is not<br/>                                       protected.  All other pages of the<br/>                                       segment are protected. */</code></pre>
<p>Comments show that this flag specifies that a Mach-O segment is encrypted (or “protected,” in Apple parlance). Via <code>otool</code>, we can parse the embedded Mach-O loader commands in HackingTeam’s installer and note that, indeed, the flag’s value within the <code>__TEXT</code> segment (the segment that contains the binary’s executable instructions) is set to the value of <code>SG_PROTECTED_VERSION_1</code> (<a href="#listing9-21" id="listinganchor9-21">Listing 9-21</a>): </p>
<pre><code>% <b>otool -l HackingTeam/installer</b><br/>...<br/><br/>Load command 1<br/>  cmd LC_SEGMENT<br/>  cmdsize 328<br/>  segname __TEXT<br/>  vmaddr 0x00001000<br/>  vmsize 0x00004000<br/>  fileoff 0<br/>  filesize 16384<br/>  maxprot 0x00000007<br/>  initprot 0x00000005<br/>  nsects 4<br/>  flags <b>0x8</b></code></pre>
<p class="CodeListingCaption"><a id="listing9-21">Listing 9-21</a>: An encrypted installer; note that the <code>flags</code> field is set to <code>0x8</code>, <code>SG_PROTECTED_VERSION_1</code> (HackingTeam)</p>
<p>From the macOS loader’s source code, we can see that the <code>load_segment</code> function checks the value of this flag.<sup class="endnote"><a href="#c09-endnote-9" id="c09-noteref-9">9</a></sup> If the flag is set, the loader will invoke a function named <code>unprotect_dsmos_segment</code> to decrypt the segment, as in <a href="#listing9-22" id="listinganchor9-22">Listing 9-22</a>:</p>
<pre><code>static load_return_t load_segment( ... )<br/>{<br/>  ...<br/><br/>  if (scp-&gt;flags &amp; SG_PROTECTED_VERSION_1) {<br/>    ret = unprotect_dsmos_segment(file_start,<br/><span epub:type="pagebreak" id="Page_204" title="204"/>            file_end - file_start,<br/>            vp,<br/>            pager_offset,<br/>            map,<br/>            vm_start,<br/>            vm_end - vm_start);<br/>            if (ret != LOAD_SUCCESS) {<br/>                     return ret;<br/>            }<br/>  }</code></pre>
<p class="CodeListingCaption"><a id="listing9-22">Listing 9-22</a>: macOS’s support of encrypted Mach-O binaries</p>
<p>Continued analysis reveals that the encryption scheme is symmetric (either Blowfish or AES) and uses a static key that is stored within the Mac’s System Management Controller. As such, we can write a utility to decrypt any binary protected in this manner. For more discussion of this macOS encryption scheme, see Erik Pistelli’s blog post “Creating undetected malware for OS X.”<sup class="endnote"><a href="#c09-endnote-10" id="c09-noteref-10">10</a></sup></p>
<p>Another option for recovering the malware’s unencrypted instructions is to dump the unprotected binary code from memory once the decryption code has executed. For this specific malware specimen, its unencrypted code can be found from address <code>0x7000</code> to <code>0xbffff</code>. The following debugger command will save its unencrypted code to disk for static analysis: </p>
<pre><code>(lldb) <b>memory read --binary --outfile /tmp/dumped.bin 0x7000 0xbffff --force </b></code></pre>
<p>Note that due to the large memory range, the <code>--force</code> flag must be specified as well.</p>
<p>I’ve shown that dynamic analysis environments and tools are generally quite successful against anti-static-analysis approaches. As a result, malware authors also seek to detect and thwart dynamic analysis.</p>
<h2 id="h1-501942c09-0002">Anti-Dynamic-Analysis Approaches</h2>
<p class="BodyFirst">Malware authors are well aware that analysts often turn to dynamic analysis as an effective means to bypass anti-analysis logic. Thus, malware often contains code that attempts to detect whether it is executing in a dynamic analysis environment like a virtual machine or within a dynamic analysis tool like a debugger. </p>
<p>Malware may leverage several common approaches to detecting dynamic analysis environments and tools: </p>
<ul>
<li><b>Virtual machine detection</b>: Often, malware analysts will execute the suspected malicious code within an isolated virtual machine in order to monitor it or perform dynamic analysis. Malware, therefore, is probably right to assume that if it finds itself executing within a virtual machine, it is likely being closely watched or dynamically analyzed. Thus, malware often seeks to detect if it’s running in a virtualized environment. Generally, if it detects such an environment, it simply exits. </li>
<li><span epub:type="pagebreak" id="Page_205" title="205"/><b>Analysis tool detection/prevention</b>: Malware may query its execution environment in an attempt to detect dynamic analysis tools, such as a debugger. If a malware specimen detects itself running in a debugging session, it can conclude with a high likelihood that it is being closely analyzed by a malware analyst. In an attempt to prevent analysis, it will likely prematurely exit. Alternatively, it might attempt to prevent debugging in the first place.</li>
</ul>
<p>How can we figure out whether a malicious specimen contains anti-analysis logic to thwart dynamic analysis? Well, if you’re attempting to dynamically analyze a malicious sample in a virtual machine or debugger, and the sample prematurely exits, this may be a sign that it implements anti-analysis logic. (Of course, there are other reasons malware might exit; for example, it might detect that its command and control server is offline.) </p>
<p>If you suspect that the malware contains such logic, the first goal should be to uncover the specific code that is responsible for this behavior. Once you’ve identified it, you can bypass this code by patching it out or simply skipping it in a debugger session. One effective way to uncover a sample’s anti-analysis code is using static analysis, which means you have to know what this anti-analysis logic might look like. The following sections describe various programmatic methods that malware can leverage to detect if it is executing within a virtual machine or a debugger. Recognizing these approaches is important, as many are widespread and found within unrelated Mac malware specimens. </p>
<h3 id="h2-501942c09-0010">Checking the System Model Name</h3>
<p class="BodyFirst">Malware may check if it’s running within a virtual machine by querying the machine’s name. The macOS ransomware named MacRansom performs such a check. Take a look at the following snippet of decompiled code, which corresponds to the malware’s anti-virtual-machine check. Here, after decoding a command, the malware invokes the <code>system</code> API to execute it. If the API returns a nonzero value, the malware will prematurely exit (<a href="#listing9-23" id="listinganchor9-23">Listing 9-23</a>): </p>
<pre><code>rax = decodeString(&amp;encodedString);<br/>if (system(rax) != 0x0) goto leave;<br/><br/>leave:<br/>    rax = exit(0xffffffffffffffff);<br/>    return rax;<br/>}</code></pre>
<p class="CodeListingCaption"><a id="listing9-23">Listing 9-23</a>: Obfuscated anti-VM logic (MacRansom)</p>
<p>To uncover the command executed by the malware, we can leverage a debugger. Specifically, by setting a breakpoint on the <code>system</code> API function, we can dump the decoded command. As it is passed as an argument to <code>system</code><span epub:type="pagebreak" id="Page_206" title="206"/>, as shown in the debugger output in <a href="#listing9-24" id="listinganchor9-24">Listing 9-24</a>, this command can be found in the <code>RDI</code> register:</p>
<pre><code>(lldb) b system<br/>Breakpoint 1: where = libsystem_c.dylib`system, address = 0x00007fff67848fdd<br/>(lldb) c<br/><br/>Process 1253 stopped<br/>* thread #1, queue = 'com.apple.main-thread', stop reason = breakpoint 1.1<br/>    frame #0: 0x00007fff67848fdd libsystem_c.dylib`system<br/>libsystem_c.dylib`system:<br/>-&gt;  0x7fff67848fdd &lt;+0&gt;: pushq  %rbp<br/><br/>(lldb) x/s $rdi<br/>0x100205350: "sysctl hw.model|grep Mac &gt; /dev/null" <span aria-label="annotation1" class="CodeAnnotationCode">1</span></code></pre>
<p class="CodeListingCaption"><a id="listing9-24">Listing 9-24</a>: Deobfuscated anti-VM command (MacRansom)</p>
<p>Turns out the command <span aria-label="annotation1" class="CodeAnnotation">1</span> first retrieves the system’s model name from <code>hw.model</code> and then checks to see if it contains the string <code>Mac</code>. In a virtual machine, this command will return a nonzero value, as the value for <code>hw.model</code> will not contain <code>Mac</code> but rather something similar to <code>VMware7,1</code> (<a href="#listing9-25" id="listinganchor9-25">Listing 9-25</a>):</p>
<pre><code>% <b>sysctl hw.model</b><br/>hw.model: VMware7,1</code></pre>
<p class="CodeListingCaption"><a id="listing9-25">Listing 9-25</a>: System’s hardware model (in a virtual machine)</p>
<p>On native hardware (outside of a virtual machine), the <code>sysctl hw.model</code> command will return a string containing <code>Mac</code> and the malware will not exit (<a href="#listing9-26" id="listinganchor9-26">Listing 9-26</a>): </p>
<pre><code>% <b>sysctl hw.model</b><br/>hw.model: MacBookAir7,2</code></pre>
<p class="CodeListingCaption"><a id="listing9-26">Listing 9-26</a>: System’s hardware model (on native hardware)</p>
<h3 id="h2-501942c09-0011">Counting the System’s Logical and Physical CPUs</h3>
<p class="BodyFirst">MacRansom contains another check to see if it is running in a virtual machine. Again, the malware decodes a command, executes it via the <code>system</code> API, and prematurely exits if the return value is nonzero. Here is the command it executes: </p>
<pre><code>echo $((`sysctl -n hw.logicalcpu`/`sysctl -n hw.physicalcpu`))|grep 2 &gt; /dev/null</code></pre>
<p>This command checks the number of logical CPUs divided by the number of physical CPUs on the system where the malware is executing. On a virtual machine, this value is often just <code>1</code>. If it isn’t <code>2</code>, the malware will exit. On native hardware, dividing the number of logical CPUs by the number of physical CPUs will often (but not always!) result in a value of 2, in which case the malware will happily continue executing. </p>
<h3 id="h2-501942c09-0012"><span epub:type="pagebreak" id="Page_207" title="207"/>Checking the System’s MAC Address</h3>
<p class="BodyFirst">Another Mac malware sample that contains code to detect if it is running in a virtual machine is Mughthesec, which masquerades as an Adobe Flash installer. If it detects that it is running within a virtual machine, the installer doesn’t do anything malicious; it merely installs a legitimate copy of Flash. Security researcher Thomas Reed noted that this virtual machine detection is done by examining the system’s MAC address. </p>
<p>If we disassemble the malicious installer, we find the snippet of code responsible for retrieving the system’s MAC address via the I/O registry (<a href="#listing9-27" id="listinganchor9-27">Listing 9-27</a>):</p>
<pre><code><span aria-label="annotation1" class="CodeAnnotationHang">1</span> r14 = IOServiceMatching("IOEthernetInterface");<br/>if (r14 != 0x0) {<br/>  rbx = CFDictionaryCreateMutable(...);<br/>  if (rbx != 0x0) {<br/>    CFDictionarySetValue(rbx, @"IOPrimaryInterface", **_kCFBooleanTrue);<br/>    CFDictionarySetValue(r14, @"IOPropertyMatch", rbx);<br/>    CFRelease(rbx);<br/>  }<br/>}<br/>...<br/>rdx = &amp;var_5C0;<br/>if (IOServiceGetMatchingServices(r15, r14, rdx) == 0x0) {<br/>  ...<br/>  r12 = var_5C0;<br/>  rbx = IOIteratorNext(r12);<br/>  r14 = IORegistryEntryGetParentEntry(rbx, "IOService", rdx); <br/>  if (r14 == 0x0) {<br/>    rdx = **_kCFAllocatorDefault;<br/>  <span aria-label="annotation2" class="CodeAnnotationCode">2</span> r15 = IORegistryEntryCreateCFProperty(var_35C, @"IOMACAddress", rdx, 0x0);</code></pre>
<p class="CodeListingCaption"><a id="listing9-27">Listing 9-27</a>: Retrieving the primary MAC address (Mughthesec)</p>
<p>The malware first creates an iterator containing the primary Ethernet interface by invoking APIs such as <code>IOServiceMatching</code> with the string <code>"IOEthernetInterface"</code> <span aria-label="annotation1" class="CodeAnnotation">1</span>. Using this iterator, it then retrieves the MAC address <span aria-label="annotation2" class="CodeAnnotation">2</span>. Note that this code is rather similar to Apple’s “GetPrimaryMACAddress” sample code, which demonstrates how to programmatically retrieve the device’s primary MAC address.<sup class="endnote"><a href="#c09-endnote-11" id="c09-noteref-11">11</a></sup> This is not surprising, as malware authors often consult (or even copy and paste) Apple’s sample code. </p>
<p>MAC addresses contain an <em>organizationally unique identifier (OUI)</em> that maps to a specific vendor. If malware detects a MAC address with an OUI matching a virtual machine vendor such as VMware, it knows it is running within a virtual machine. Vendors’ OUIs can be found online, such as on company websites. For example, online documentation found at <a class="LinkURL" href="https://docs.vmware.com/">https://docs.vmware.com/</a> notes that VMware’s OUI ranges include <code>00:50:56</code> and <code>00:0C:29</code>, meaning that for the former, VMware VMs will contain MAC addresses in the following format: <code>00:50:56:XX:YY:ZZ</code>.<sup class="endnote"><a href="#c09-endnote-12" id="c09-noteref-12">12</a></sup></p>
<p>Of course, there are a myriad of other ways for malware to programmatically detect if it is executing within a virtual machine. For a fairly comprehensive list of such methods, see “Evasions: macOS.”<sup class="endnote"><a href="#c09-endnote-13" id="c09-noteref-13">13</a></sup></p>
<h3 id="h2-501942c09-0013"><span epub:type="pagebreak" id="Page_208" title="208"/>Checking System Integrity Protection Status</h3>
<p class="BodyFirst">Of course, not all analysis is done within virtual machines. Many malware analysts leverage dedicated analysis machines to dynamically analyze malicious code. In this scenario, as the analysis is performed on native hardware, anti-analysis logic that is based on detecting virtual machines is useless. Instead, malware must look for other indicators to determine if it’s running within an analysis environment. One such approach is to check the status of <em>System Integrity Protection (SIP)</em>. </p>
<p>SIP is a built-in macOS protection mechanism that, among other things, may prevent the debugging of processes. Malware analysts, who often require the ability to debug any and all processes, will often disable SIP on their analysis machines. The prolific Pirrit malware leverages this fact to check whether it’s likely running on an analysis system. Specifically, it will execute macOS’s <code>csrutil</code> command to determine the status of SIP. We can observe this passively via a process monitor, or more directly in a debugger. In the case of the latter, we can break on a call to the <code>NSConcreteTask</code>’s <code>launch</code> method and dump the launch path and arguments of the task object (found in the <code>RDI</code> register), as shown in <a href="#listing9-28" id="listinganchor9-28">Listing 9-28</a>: </p>
<pre><code>(lldb) <b>po</b><b> </b>[$rdi launchPath]<br/>/bin/sh<br/><br/>(lldb) <b>po</b><b> </b>[$rdi arguments]<br/>&lt;__NSArrayI 0x10580dfd0&gt;(<br/> -c, <br/> command -v csrutil &gt; /dev/null &amp;&amp; csrutil status | grep -v "enabled" &gt; /dev/null &amp;&amp; echo 1 || echo 0 <br/>)</code></pre>
<p class="CodeListingCaption"><a id="listing9-28">Listing 9-28</a>: Retrieving the System Integrity Protection status (Pirrit)</p>
<p>From the debugger output, we can confirm that indeed the malware is executing the <code>csrutil</code> command (via the shell, <code>/bin/sh</code>) with the <code>status</code> flag. The output of this command is passed to <code>grep</code> to check if SIP is still enabled. If SIP has been disabled, the malware will prematurely exit in an attempt to prevent continued dynamic analysis. </p>
<h3 id="h2-501942c09-0014">Detecting or Killing Specific Tools </h3>
<p class="BodyFirst">Malware might also contain anti-analysis code to detect and thwart dynamic analysis tools. As you’ll see, this code usually focuses on debugger detection, but some malware specimens will also take into account other analysis or security tools that might detect the malware and alert the user, which is something malware often seeks to avoid at all costs. </p>
<p>A variant of the malware known as Proton looks for specific security tools. When executed, the Proton installer will query the system to see if any third-party firewall products are installed. If any are found, the malware chooses not to infect the system and simply exits. This is illustrated <span epub:type="pagebreak" id="Page_209" title="209"/>in the following snippet of decompiled code extracted from the installer (<a href="#listing9-29" id="listinganchor9-29">Listing 9-29</a>): </p>
<pre><code><span aria-label="annotation1" class="CodeAnnotationHang">1</span> rax = [*0x10006c4a0 objectAtIndexedSubscript:0x51]; <br/><br/>rdx = rax;<br/><span aria-label="annotation2" class="CodeAnnotationHang">2</span> if ([rbx fileExistsAtPath:rdx] != 0x0) goto fileExists; <br/><br/>fileExists:<br/>rax = <b>exit(0x0);</b></code></pre>
<p class="CodeListingCaption"><a id="listing9-29">Listing 9-29</a>: Basic firewall detection (Proton)</p>
<p>The installer first extracts a filepath from a decrypted array <span aria-label="annotation1" class="CodeAnnotation">1</span>. Dynamic analysis reveals that this extracted path points to the kernel extension of Little Snitch, a popular third-party firewall: <em>/Library/Extensions/LittleSnitch.kext</em>. If this file is found on the system the malware is about to infect, installation is aborted <span aria-label="annotation2" class="CodeAnnotation">2</span>. </p>
<p>The Proton installer has other tricks up its sleeve. For example, in an attempt to thwart dynamic analysis, it will terminate tools such as the macOS’s log message collector (the Console application) and the popular network monitor Wireshark. To terminate these applications, it simply invokes the built-in macOS utility, <code>killall</code>. Though rather primitive and quite noticeable, this technique will prevent the analysis tools from running alongside the malware. (Of course, the tools can simply be restarted, or even just renamed.)</p>
<h3 id="h2-501942c09-0015">Detecting a Debugger</h3>
<p class="BodyFirst">The debugger is arguably the most powerful tool in the malware analyst’s arsenal, so most malware that contains anti-analysis code seeks to detect whether it is running in a debugger session. The most common way for a program to determine if it is being debugged is to simply ask the system. As described in Apple’s developer documentation, a process should first invoke the <code>sysctl</code> API with <code>CTL_KERN</code>, <code>KERN_PROC</code>, <code>KERN_PROC_PID</code>, and its process identifier (<code>pid</code>), as parameters. Also, a <code>kinfo_proc</code> structure should be provided.<sup class="endnote"><a href="#c09-endnote-14" id="c09-noteref-14">14</a></sup> The <code>sysctl</code> function will then populate the structure with information about the process, including a <code>P_TRACED</code> flag. If set, this flag means the process is currently being debugged. <a href="#listing9-30" id="listinganchor9-30">Listing 9-30</a>, taken directly from Apple’s documentation, checks for the presence of a debugger in this manner:</p>
<pre><code>static bool AmIBeingDebugged(void)<br/>    // Returns true if the current process is being debugged (either <br/>    // running under the debugger or has a debugger attached post facto).<br/>{<br/>    int                 junk;<br/>    int                 mib[4];<br/>    struct kinfo_proc   info;<br/>    size_t              size;<br/><br/>    // Initialize the flags so that, if sysctl fails for some bizarre <br/>    // reason, we get a predictable result.<br/><br/><span epub:type="pagebreak" id="Page_210" title="210"/>    info.kp_proc.p_flag = 0;<br/><br/>    // Initialize mib, which tells sysctl the info we want, in this case<br/>    // we're looking for information about a specific process ID.<br/><br/>    mib[0] = CTL_KERN;<br/>    mib[1] = KERN_PROC;<br/>    mib[2] = KERN_PROC_PID;<br/>    mib[3] = getpid();<br/><br/>    // Call sysctl.<br/><br/>    size = sizeof(info);<br/>    junk = sysctl(mib, sizeof(mib) / sizeof(*mib), &amp;info, &amp;size, NULL, 0);<br/>    assert(junk == 0);<br/><br/>    // We're being debugged if the P_TRACED flag is set.<br/><br/>    return ( (info.kp_proc.p_flag &amp; P_TRACED) != 0 );<br/>}</code></pre>
<p class="CodeListingCaption"><a id="listing9-30">Listing 9-30</a>: Debugger detection (via the <code>P_TRACED</code> flag)</p>
<p>Malware will often use this same technique, in some cases copying Apple’s code verbatim. This was the case with the Russian malware known as Komplex. Looking at a decompilation of Komplex’s main function, you can see that it invokes a function named <code>AmIBeingDebugged</code> (<a href="#listing9-31" id="listinganchor9-31">Listing 9-31</a>):</p>
<pre><code>int main(int argc, char *argv[]) {<br/>...<br/>   if ((AmIBeingDebugged() &amp; 0x1) == 0x0) { <br/> <br/>   //core malicious logic <br/><br/>   }<br/>   else {<br/>    remove(argv[0]); <br/>}<br/><br/>return 0;</code></pre>
<p class="CodeListingCaption"><a id="listing9-31">Listing 9-31</a>: Debugger detection (Komplex)</p>
<p>If the <code>AmIBeingDebugged</code> function returns a nonzero value, the malware will execute the logic in the <code>else</code> block, which causes the malware to delete itself in an attempt to prevent continued analysis. And as expected, if we examine the code of the malware’s <code>AmIBeingDebugged</code> function, it is logically equivalent to Apple’s debugger detection function. </p>
<h3 id="h2-501942c09-0016">Preventing Debugging with ptrace</h3>
<p class="BodyFirst">Another anti-debugging approach is attempting to prevent debugging altogether. Malware can accomplish this by invoking the <code>ptrace</code> system call with the <code>PT_DENY_ATTACH</code> flag. This Apple-specific flag prevents a debugger from <span epub:type="pagebreak" id="Page_211" title="211"/>attaching and tracing the malware. Attempting to debug a process that invokes <code>ptrace</code> with the <code>PT_DENY_ATTACH</code> flag will fail (<a href="#listing9-32" id="listinganchor9-32">Listing 9-32</a>): </p>
<pre><code>% <b>lldb proton</b><br/>...<br/><br/>(lldb) <b>r</b><br/>Process 666 exited with status = 45 (0x0000002d)</code></pre>
<p class="CodeListingCaption"><a id="listing9-32">Listing 9-32</a>: A premature exit due to <code>ptrace</code> with the <code>PT_DENY_ATTACH</code> flag (Proton)</p>
<p>You can tell the malware has the <code>PT_DENY_ATTACH</code> flag set because it prematurely exits with a status of <code>45</code>.</p>
<p>Calls to the <code>ptrace</code> function with the <code>PT_DENY_ATTACH</code> flag are fairly easy to spot (for example, by examining the binary’s imports). Thus, malware may attempt to obfuscate the <code>ptrace</code> call. For example, Proton dynamically resolves the <code>ptrace</code> function by name, preventing it from showing up as an import, as you can see in the following snippet (<a href="#listing9-33" id="listinganchor9-33">Listing 9-33</a>): </p>
<pre><code>0x000000010001e6b8    xor        edi, edi<br/>0x000000010001e6ba    mov        esi, 0xa<br/>0x000000010001e6bf    call     <span aria-label="annotation1" class="CodeAnnotationCode">1</span> dlopen <br/>0x000000010001e6c4    mov        rbx, rax<br/>0x000000010001e6c7    lea        rsi, qword [ptrace]<br/>0x000000010001e6ce    mov        rdi, rbx<br/>0x000000010001e6d1    call     <span aria-label="annotation2" class="CodeAnnotationCode">2</span> dlsym <br/>0x000000010001e6d6    mov        edi, <span aria-label="annotation3" class="CodeAnnotationCode">3</span> 0x1f<br/>0x000000010001e6db    xor        esi, esi<br/>0x000000010001e6dd    xor        edx, edx<br/>0x000000010001e6df    xor        ecx, ecx<br/>0x000000010001e6e1    call       rax</code></pre>
<p class="CodeListingCaption"><a id="listing9-33">Listing 9-33</a>: Obfuscated anti-debugger logic via <code>ptrace</code>, <code>PT_DENY_ATTACH</code> (Proton)</p>
<p>After invoking the <code>dlopen</code> function <span aria-label="annotation1" class="CodeAnnotation">1</span>, the malware calls <code>dlsym</code> <span aria-label="annotation2" class="CodeAnnotation">2</span> to dynamically resolve the address of the <code>ptrace</code> function. As the <code>dlsym</code> function takes a pointer to the string of the function to resolve, such as <code>[ptrace]</code>, that function won’t show up as a dependency of the binary. The return value from <code>dlsym</code>, stored in the <code>RAX</code> register, is the address of <code>ptrace</code>. Once the address is resolved, the malware promptly invokes it, passing in <code>0x1F</code>, which is the hexadecimal value of <code>PT_DENY_ATTACH</code> <span aria-label="annotation3" class="CodeAnnotation">3</span>. If the malware is being debugged, the call to <code>ptrace</code> will cause the debugging session to forcefully terminate and the malware to exit.</p>
<h2 id="h1-501942c09-0003">Bypassing Anti-Dynamic-Analysis Logic</h2>
<p class="BodyFirst">Luckily, the anti-dynamic-analysis methods covered thus far are all fairly trivial to bypass. Overcoming most of these tactics involves two steps: identifying the location of the anti-analysis logic and then preventing its execution. Of these two steps, the first is usually the most challenging, but <span epub:type="pagebreak" id="Page_212" title="212"/>it becomes far easier once you’re familiar with the anti-analysis methods discussed in this chapter. </p>
<p>It’s wise to first statically triage a binary before diving into a full-blown debugging session. During this triage, keep an eye out for telltale signs that may reveal dynamic-analysis-thwarting logic. For example, if a binary imports the <code>ptrace</code> API, there is a good chance it will attempt to prevent debugging with the <code>PT_DENY_ATTACH</code> flag. </p>
<p>Strings or function and method names may also reveal a malware’s distaste for analysis. For example, running the <code>nm</code> command, used to dump symbols, against EvilQuest reveals functions named <code>is_debugging</code> and <code>is_virtual_mchn</code> (<a href="#listing9-34" id="listinganchor9-34">Listing 9-34</a>):</p>
<pre><code>% <b>nm EvilQuest/patch</b><br/>...<br/><br/>0000000100007aa0 T _is_debugging<br/>0000000100007bc0 T _is_virtual_mchn</code></pre>
<p class="CodeListingCaption"><a id="listing9-34">Listing 9-34</a>: Anti-analysis functions? (EvilQuest)</p>
<p>Unsurprisingly, continued analysis reveals that both functions are related to the malware’s anti-analysis logic. For example, examining the code that invokes the <code>is_debugging</code> function reveals that EvilQuest will prematurely exit if the function returns a nonzero value; that is, if a debugger is detected (<a href="#listing9-35" id="listinganchor9-35">Listing 9-35</a>):</p>
<pre><code>0x000000010000b89a    call       <b>is_debugging</b><br/>0x000000010000b89f    cmp        eax, 0x0<br/>0x000000010000b8a2    je         continue<br/>0x000000010000b8a8    mov        edi, 0x1<br/>0x000000010000b8ad    call       exit</code></pre>
<p class="CodeListingCaption"><a id="listing9-35">Listing 9-35</a>: Anti-debugging logic (EvilQuest)</p>
<p>However, if the malware also implements anti-static-analysis logic, such as string or code obfuscation, locating logic that seeks to detect a virtual machine or a debugger may be difficult to accomplish with static analysis methods. In this case, you can use a methodical debugging session, starting at the entry point of the malware (or any initialization routines). Specifically, you can single-step through to the code, observing API and system calls that may be related to the anti-analysis logic. If you step over a function and the malware immediately exits, it’s likely that some anti-analysis logic was triggered. If this occurs, simply restart the debugging session and step into the function to examine the code more closely. </p>
<p>This trial and error approach could be conducted in the following manner: </p>
<ol class="decimal">
<li value="1">Start a debugger session that executes the malicious sample. It is important to start the debugging session at the very beginning rather than attaching it to the already running process. This ensures that the malware has not had a chance to execute any of its anti-analysis logic. </li>
<li value="2"><span epub:type="pagebreak" id="Page_213" title="213"/>Set breakpoints on APIs that may be invoked by the malware to detect a virtual machine or debugging session. Examples include <code>sysctl</code> and <code>ptrace</code>.</li>
<li value="3">Instead of allowing the malware to run uninhibited, manually step through its code, perhaps stepping over any function calls. If any of the breakpoints are hit, examine their arguments to ascertain if they are being invoked for anti-analysis reasons. For example, check for <code>ptrace</code> invoked with the <code>PT_DENY_ATTACH</code> flag, or perhaps <code>sysctl</code> attempting to retrieve the number of CPUs or setting the <code>P_TRACED</code> flag. A backtrace should reveal the address of the code within the malware that invoked these APIs. </li>
<li value="4">If stepping over a function call causes the malware to exit (a sign it likely detected either the virtual machine or the debugger), restart the debugging session and, this time, step into this function. Repeat this process until you’ve identified the location of the anti-analysis logic. </li>
</ol>
<p>Armed with the locations of the anti-analysis logic, you can now bypass it by modifying the execution environment, patching the on-disk binary image, modifying program control flow in a debugger, or modifying the register or variable value in a debugger. Let’s briefly look at each of these methods. </p>
<h3 id="h2-501942c09-0017">Modifying the Execution Environment</h3>
<p class="BodyFirst">It may be possible to modify the execution environment such that the anti-analysis logic no longer triggers. Recall that Mughthesec contains logic to detect if it’s running within a virtual machine by examining the system’s MAC address. If the malware detects a MAC address with an OUI matching a virtual machine vendor such as VMware, it won’t execute. Luckily, we can modify our MAC address in the virtual machine’s settings, choosing an address that falls outside the range of any virtual machine provider’s OUI. For example, set it to the OUI of your base macOS machine, like <code>F0:18:98</code>, which belongs to Apple. Once the MAC address has been changed, Mughthesec will no longer detect the environment as a virtual machine and so will happily execute its malicious logic, allowing our dynamic analysis to continue.</p>
<h3 id="h2-501942c09-0018">Patching the Binary Image</h3>
<p class="BodyFirst">Another more permanent approach to bypassing anti-analysis logic involves patching the malware’s on-disk binary image. The Mac ransomware KeRanger is a good candidate for this approach, as it may sleep for several days before executing its malicious payload, perhaps in an effort to impede automated or dynamic analysis.</p>
<p>Though the malware is packed, it leverages the UPX packer, which we can fully unpack using the <code>upx -d</code> command. Next, static analysis can identify the function aptly named <code>waitOrExit</code> that is responsible for implementing the wait delay. It is invoked by the <code>startEncrypt</code> function, which begins the process of ransoming users’ files:</p>
<pre><code>startEncrypt:<br/>...<br/><span epub:type="pagebreak" id="Page_214" title="214"/>0x000000010000238b    call       waitOrExit<br/>0x0000000100002390    test       eax, eax<br/>0x0000000100002392    je         leave</code></pre>
<p>To bypass the delay logic so that the malware will immediately continue execution, we can modify the malware’s binary code to skip the call to the <code>waitOrExit</code> function. </p>
<p>In a hex editor, we change the bytes of the malware’s executable instructions from a <code>call</code> to a <code>nop</code>. Short for “no operation,” a <code>nop</code> is an instruction (<code>0x90</code> on Intel platforms) that instructs the CPU to do, well, nothing. It is useful when patching out anti-analysis logic in malware, overwriting the problematic instructions with benign ones. We also <code>nop</code>-out the instructions that would cause the malware to terminate if the overwritten call failed (<a href="#listing9-36" id="listinganchor9-36">Listing 9-36</a>):</p>
<pre><code>startEncrypt:<br/>...<br/>0x000000010000238b    nop<br/>0x000000010000238c    nop<br/>0x000000010000238d    nop<br/>...<br/>0x0000000100002396    nop<br/>0x0000000100002397    nop</code></pre>
<p class="CodeListingCaption"><a id="listing9-36">Listing 9-36</a>: Anti-analysis logic, now <code>nop</code>’d out (KeRanger)</p>
<p>Now whenever this modified version of KeRanger is executed, the <code>nop</code> instructions will do nothing and the malware will happily continue executing, allowing our dynamic analysis session to progress. </p>
<p>Though patching the malware’s on-disk binary image is a permanent solution, it may not always be the best approach. First, if the malware is packed with a non-UPX packer that is difficult to unpack, it may not be possible to patch the target instructions, as they are only unpacked or decrypted in memory. Moreover, on-disk patches involve more work than less permanent methods, such as modifications to the malware’s in-memory code during a debugging session. Finally, any modification to a binary will invalidate any of its cryptographic signatures. This could prevent the malware from executing successfully. Thus, it’s more common for malware analysts to use a debugger or other runtime method, such as injecting a custom library, to circumvent anti-dynamic-analysis logic. </p>
<h3 id="h2-501942c09-0019">Modifying the Malware’s Instruction Pointer</h3>
<p class="BodyFirst">One of the more powerful capabilities of a debugger is its ability to directly modify the entire state of the malware. This capability proves especially useful when you need to bypass dynamic-analysis-thwarting logic. </p>
<p>Perhaps the simplest way to do so involves manipulating the program’s instruction pointer, which points to the next instruction that the CPU will execute. This value is stored in the program counter register, which <span epub:type="pagebreak" id="Page_215" title="215"/>on 64-bit Intel systems is the <code>RIP</code> register. You can set a breakpoint on the anti-analysis logic, and when the breakpoint is hit, modify the instruction pointer to, for example, skip over problematic logic. If done correctly, the malware will be none the wiser. </p>
<p>Let’s return to KeRanger. After setting a breakpoint on the call instruction that invokes the function that sleeps for three days, we can allow the malware to continue until that breakpoint is hit. At this point, we can simply modify the instruction pointer to point to the instructions after the call. As the function call is never made, the malware never sleeps, and our dynamic analysis session can continue. </p>
<p>Recall that in a debugger session, you can change the value of any register via the <code>reg write</code> debugger command. To specifically modify the value of the instruction pointer, execute this command on the <code>RIP</code> register.</p>
<pre><code>(lldb) <b>reg write $rip</b> <var>&lt;new value&gt;</var> </code></pre>
<p>Let’s walk through another example. The EvilQuest malware contains a function named <code>prevent_trace</code> that invokes the <code>ptrace</code> API with the <code>PT_DENY_ATTACH</code> flag. Code at address <code>0x000000010000b8b2</code> invokes this function. If we allow this function to execute during a debugging session, the system will detect the debugger and immediately terminate the session. To bypass this logic, we can avoid the call to <code>prevent_trace</code> altogether by setting a breakpoint at <code>0x000000010000b8b2</code>. Once the breakpoint is hit, we modify the value of the instruction pointer to skip the call, as in <a href="#listing9-37" id="listinganchor9-37">Listing 9-37</a>: </p>
<pre><code>% (lldb) <b>b 0x10000b8b2</b><br/>Breakpoint 1: where = patch[0x000000010000b8b2]<br/><br/>(lldb)<b> </b><b>c</b><br/>Process 683 resuming<br/>Process 683 stopped<br/>* thread #1, queue = 'com.apple.main-thread', stop reason = breakpoint 1.1<br/><br/>-&gt;  0x10000b8b2: callq  0x100007c20<br/>    0x10000b8b7: leaq   0x7de2(%rip), %rdi<br/>    0x10000b8be: movl   $0x8, %esi<br/>    0x10000b8c3: movl   %eax, -0x38(%rbp)<br/><br/>(lldb) <b>reg write $rip 0x10000b8b7</b><br/>(lldb)<b> </b><b>c</b></code></pre>
<p class="CodeListingCaption"><a id="listing9-37">Listing 9-37</a>: Skipping anti-debugger logic (EvilQuest)</p>
<p>Now the <code>prevent_trace</code> function is never invoked, and our debugging session can continue. </p>
<p>Note that manipulating the instruction pointer of a program can have serious side effects if not done correctly. For example, if a manipulation causes an unbalanced or misaligned stack, that program may crash. Sometimes, a simpler approach can be taken to avoid manipulating the instruction pointer and modify other registers instead. </p>
<h3 id="h2-501942c09-0020"><span epub:type="pagebreak" id="Page_216" title="216"/>Modifying a Register Value</h3>
<p class="BodyFirst">Note that EvilQuest contains a function named <code>is_debugging</code>. Recall that the function returns a nonzero value if it detects a debugging session, which will cause the malware to abruptly terminate. Of course, if no debugging session is detected because <code>is_debugging</code> returns zero, the malware will happily continue. </p>
<p>Instead of manipulating the instruction pointer, we can set a breakpoint on the instruction that performs the check of the value returned by the <code>is_debugging</code> function. Once this breakpoint is hit, the <code>EAX</code> register will contain a nonzero value, as the malware will have detected our debugger. However, via the debugger, we can surreptitiously toggle the value in <code>EAX</code> to 0 (<a href="#listing9-38" id="listinganchor9-38">Listing 9-38</a>):</p>
<pre><code>* thread #1, queue = 'com.apple.main-thread', stop reason = breakpoint 1.1<br/>-&gt;  0x10000b89f: cmpl   $0x0, %eax<br/>    0x10000b8a2: je     0x10000b8b2<br/>    0x10000b8a8: movl   $0x1, %edi<br/>    0x10000b8ad: callq  exit<br/><br/>(lldb) <b>reg read $eax</b><br/>       rax = 0x00000001<br/><br/>(lldb) <b>reg write $eax 0</b></code></pre>
<p class="CodeListingCaption"><a id="listing9-38">Listing 9-38</a>: Modifying register values to bypass anti-debugging logic</p>
<p>Changing the value of the <code>EAX</code> register to 0 (via <code>reg write $eax 0</code>) ensures the comparison instruction will now result in the zero flag being set. Thus, the <code>je</code> instruction will take the branch to address <code>0x10000b8b2</code>, avoiding the call to <code>exit</code> at <code>0x10000b8ad</code>. Note that we only needed to modify the lower 32 bits of the <code>RAX</code> register (<code>EAX</code>), as this is all that is checked by the compare instruction (<code>cmp</code>).</p>
<h2 id="h1-501942c09-0004">A Remaining Challenge: Environmentally Generated Keys</h2>
<p class="BodyFirst">At this point, it may seem that malware analysts have the upper hand; after all, no anti-analysis measures can stop us, right? Not so fast. Sophisticated malware authors employ protection encryption schemes that use <em>environmentally generated keys</em>. These keys are generated on the victim’s system and are thus unique to a specific instance of an infection. </p>
<p>The implications of this are rather profound. If the malware finds itself outside the environment for which it was keyed, it will be unable to decrypt itself. This also means that attempts to analyze the malware will likely fail, as it will remain encrypted. If this environmental protection mechanism is implemented correctly and the keying information is not externally recoverable, the only way to analyze the malware is either by performing the analysis directly on the infected system or by performing it on a memory dump of the malware captured on the infected system.</p>
<p><span epub:type="pagebreak" id="Page_217" title="217"/>We’ve seen this protection mechanism in Windows malware written by the infamous Equation Group, as well as more recently on macOS by the Lazarus Group.<sup class="endnote"><a href="#c09-endnote-15" id="c09-noteref-15">15</a></sup> The latter encrypted all second-stage payloads with the serial number of the infected systems. For more on the intriguing topic of environmental key generation, see my 2015 Black Hat talk “Writing Bad @$$ Malware for OS X.”<sup class="endnote"><a href="#c09-endnote-16" id="c09-noteref-16">16</a></sup> Also check out James Riordan and Bruce Schneier’s seminal paper on the topic, “Environmental Key Generation Towards Clueless Agents.”<sup class="endnote"><a href="#c09-endnote-17" id="c09-noteref-17">17</a></sup></p>
<h2 id="h1-501942c09-0005">Up Next</h2>
<p class="BodyFirst">In this chapter, we discussed common anti-analysis approaches that malware may leverage in an attempt to thwart our analysis efforts. After discussing how to identify this logic, I illustrated how to use static and dynamic approaches in order to bypass it. Armed with the knowledge presented in this book thus far, you’re now ready to analyze a sophisticated piece of Mac malware. In the next chapter we’ll uncover the malware’s viral infection capabilities, persistence mechanism, and goals.</p>
<h2 id="h1-501942c09-0006">Endnotes</h2>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-1" id="c09-endnote-1">1</a></sup>	Ilfak Guilfanov, “FindCrypt2,” <em>Hex-Rays</em>, February 7, 2006, <a class="LinkURL" href="https://www.hex-rays.com/blog/findcrypt2/">https://www.hex-rays.com/blog/findcrypt2/</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-2" id="c09-endnote-2">2</a></sup>	Jon Gabilondo, “How to Inject Code into Mach-O Apps, Part II,” <em>Jon Gabilondo</em> (blog), September 22, 2019, <a class="LinkURL" href="https://medium.com/@jon.gabilondo.angulo_7635/how-to-inject-code-into-mach-o-apps-part-ii-ddb13ebc8191/">https://medium.com/@jon.gabilondo.angulo_7635/how-to-inject-code-into-mach-o-apps-part-ii-ddb13ebc8191/</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-3" id="c09-endnote-3">3</a></sup>	Yakov Matvienko, “Using LLVM to Obfuscate Your Code During Compilation,” <em>Apriorit Dev Blog</em>, June 25, 2020, <a class="LinkURL" href="https://www.apriorit.com/dev-blog/687-reverse-engineering-llvm-obfuscation/">https://www.apriorit.com/dev-blog/687-reverse-engineering-llvm-obfuscation/</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-4" id="c09-endnote-4">4</a></sup>	UPX, <a class="LinkURL" href="https://upx.github.io/">https://upx.github.io/</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-5" id="c09-endnote-5">5</a></sup>	TaskExplorer, <a class="LinkURL" href="https://objective-see.com/products/taskexplorer.html">https://objective-see.com/products/taskexplorer.html</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-6" id="c09-endnote-6">6</a></sup>	Pedro Vilaça, “F*ck You HackingTeam,” <a class="LinkURL" href="https://papers.put.as/papers/macosx/2014/SyScan360-FuckYouHackingTeam.pdf">https://papers.put.as/papers/macosx/2014/SyScan360-FuckYouHackingTeam.pdf</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-7" id="c09-endnote-7">7</a></sup>	Patrick Wardle, “HackingTeam Reborn: A Brief Analysis of an RCS Implant Installer,” <em>Objective-See</em>, February 26, 2016, <a class="LinkURL" href="https://objective-see.com/blog/blog_0x0D.html">https://objective-see.com/blog/blog_0x0D.html</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-8" id="c09-endnote-8">8</a></sup>	“mach-o/loader.h,” <em>Apple</em>, <a class="LinkURL" href="https://opensource.apple.com/source/xnu/xnu-7195.141.2/EXTERNAL_HEADERS/mach-o/loader.h.auto.html">https://opensource.apple.com/source/xnu/xnu-7195.141.2/EXTERNAL_HEADERS/mach-o/loader.h.auto.html</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-9" id="c09-endnote-9">9</a></sup>	“kern/mach_loader.c,” <em>Apple</em>, <a class="LinkURL" href="https://opensource.apple.com/source/xnu/xnu-7195.141.2/bsd/kern/mach_loader.c">https://opensource.apple.com/source/xnu/xnu-7195.141.2/bsd/kern/mach_loader.c</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-10" id="c09-endnote-10">10</a></sup>	Erik Pistelli, “Creating undetected malware for OS X,” <em>NTCore</em>, October 7, 2013, <a class="LinkURL" href="https://ntcore.com/?p=436/">https://ntcore.com/?p=436/</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p><span epub:type="pagebreak" id="Page_218" title="218"/>	<sup class="endnote"><a href="#c09-noteref-11" id="c09-endnote-11">11</a></sup>	“GetPrimaryMACAddress,” <em>Apple Developer Documentation Archive</em>, <a class="LinkURL" href="https://developer.apple.com/library/archive/samplecode/GetPrimaryMACAddress/Introduction/Intro.html">https://developer.apple.com/library/archive/samplecode/GetPrimaryMACAddress/Introduction/Intro.html</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-12" id="c09-endnote-12">12</a></sup>	“VMware OUI in Static MAC Addresses,” <em>VMware</em>, May 31, 2019, <a class="LinkURL" href="https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.networking.doc/GUID-ADFECCE5-19E7-4A81-B706-171E279ACBCD.html">https://docs.vmware.com/en/VMware-vSphere/7.0/com.vmware.vsphere.networking.doc/GUID-ADFECCE5-19E7-4A81-B706-171E279ACBCD.html</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-13" id="c09-endnote-13">13</a></sup>	“Evasions: macOS,” <em>Check Point Research</em>, <a class="LinkURL" href="https://evasions.checkpoint.com/techniques/macos.html">https://evasions.checkpoint.com/techniques/macos.html</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-14" id="c09-endnote-14">14</a></sup>	“Technical Q&amp;A QA1361: Detecting the Debugger,” <em>Apple Developer Documentation Archive</em>, <a class="LinkURL" href="https://developer.apple.com/library/archive/qa/qa1361/_index.html">https://developer.apple.com/library/archive/qa/qa1361/_index.html</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-15" id="c09-endnote-15">15</a></sup>	“Equation Group: Questions and Answers,” <em>Kaspersky Lab</em>, February 2015, <a class="LinkURL" href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2018/03/08064459/Equation_group_questions_and_answers.pdf">https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2018/03/08064459/Equation_group_questions_and_answers.pdf</a>; Patrick Wardle, “Weaponizing a Lazarus Group Implant,” <em>Objective-See</em>, February 22, 2020, <a class="LinkURL" href="https://objective-see.com/blog/blog_0x54.html">https://objective-see.com/blog/blog_0x54.html</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-16" id="c09-endnote-16">16</a></sup>	Patrick Wardle, “Writing Bad @$$ Malware for OS X,” <a class="LinkURL" href="https://www.blackhat.com/docs/us-15/materials/us-15-Wardle-Writing-Bad-A-Malware-For-OS-X.pdf">https://www.blackhat.com/docs/us-15/materials/us-15-Wardle-Writing-Bad-A-Malware-For-OS-X.pdf</a>.</p></aside>
<aside class="endnote" epub:type="rearnote"><p>	<sup class="endnote"><a href="#c09-noteref-17" id="c09-endnote-17">17</a></sup>	James Riordan and Bruce Schneier, “Environmental Key Generation Towards Clueless Agents,” <em>Schneier on Security</em>, <a class="LinkURL" href="https://www.schneier.com/wp-content/uploads/2016/02/paper-clueless-agents.pdf">https://www.schneier.com/wp-content/uploads/2016/02/paper-clueless-agents.pdf</a>.</p></aside>
</section>
</body>
</html>