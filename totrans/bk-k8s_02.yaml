- en: '1'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '1'
- en: WHY CONTAINERS MATTER
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么容器很重要
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common01.jpg)'
- en: It’s a great time to be a software developer. Creating a brand-new application
    and making it available to millions of people has never been easier. Modern programming
    languages, open source libraries, and application platforms make it possible to
    write a small amount of code and end up with lots of functionality. However, although
    it’s easy to get started and create a new application quickly, the best application
    developers are those who move beyond treating the application platform as a “black
    box” and really understand how it works. Creating a reliable, resilient, and scalable
    application requires more than just knowing how to create a Deployment in the
    browser or on the command line.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是做软件开发的好时机。创建一个全新的应用并使其能被数百万用户使用，从未如此简单。现代编程语言、开源库和应用平台使得编写少量代码并实现大量功能成为可能。然而，尽管开始并快速创建一个新应用很容易，但最优秀的应用开发者是那些不仅仅将应用平台视为一个“黑匣子”，而是能够真正理解它如何工作的开发者。创建一个可靠、具有韧性和可扩展的应用需要的不仅仅是知道如何在浏览器或命令行中创建部署。
- en: In this chapter, we’ll look at application architecture in a scalable, cloud
    native world. We will show why containers are the preferred way to package and
    deploy application components, and how container orchestration addresses key needs
    for containerized applications. We’ll finish with an example application deployed
    to Kubernetes to give you an introductory glimpse into the power of these technologies.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨在一个可扩展、云原生的世界中的应用架构。我们将展示为什么容器是打包和部署应用组件的首选方式，以及容器编排如何满足容器化应用的关键需求。最后，我们将展示一个部署到
    Kubernetes 的示例应用，给你一个关于这些技术的初步了解。
- en: Modern Application Architecture
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 现代应用架构
- en: The main theme of modern software applications is *scale*. We live in a world
    of applications with millions of simultaneous users. What is remarkable is the
    ability of these applications to achieve not only this scale but also a level
    of stability such that an outage makes headlines and serves as fodder for weeks
    or months of technical analysis.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 现代软件应用的主要主题是*规模*。我们生活在一个拥有数百万同时在线用户的应用世界。值得注意的是，这些应用不仅能够实现这种规模，还能够保持一定的稳定性，以至于任何一次停机事件都能成为头条新闻，并成为数周或数月技术分析的素材。
- en: With so many modern applications running at large scale, it can be easy to forget
    that a lot of hard work goes into architecting, building, deploying, and maintaining
    applications of this caliber, whether the scale they’re designed for is thousands,
    millions, or billions of users. Our job in this chapter is to identify what we
    need from our application platform to run a scalable, reliable application, and
    to see how containerization and Kubernetes meet those requirements. We’ll start
    by looking at three key attributes of modern application architecture. Then we’ll
    move on to looking at three key benefits these attributes bring.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 随着如此多现代应用在大规模运行，往往很容易忘记，架构设计、构建、部署和维护这种高水平的应用需要付出大量的努力，无论它们设计的规模是面向数千、数百万还是数十亿用户。本章的任务是识别我们需要从应用平台中得到什么，以便运行一个可扩展、可靠的应用，并了解容器化和
    Kubernetes 如何满足这些需求。我们将从看现代应用架构的三个关键特性开始，然后探讨这些特性带来的三个主要好处。
- en: 'Attribute: Cloud Native'
  id: totrans-8
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 特性：云原生
- en: There are lots of ways to define *cloud native* technologies (and a good place
    to start is the Cloud Native Computing Foundation at *[https://cncf.io](https://cncf.io)*).
    I like to start with an idea of what “the cloud” is and what it enables so that
    we can understand what kind of architecture can make best use of it.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多方法可以定义*云原生*技术（一个好的起点是云原生计算基金会，[https://cncf.io](https://cncf.io)）。我喜欢从“云”是什么以及它能实现什么的角度出发，这样我们就能理解什么样的架构可以最好地利用它。
- en: At its heart, the cloud is an abstraction. We talked about abstractions in the
    introduction, so you know that abstractions are essential to computing, but we
    also need a deep understanding of our abstractions to use them properly. In the
    case of the cloud, the provider is abstracting away the real physical processors,
    memory, storage, and networking, allowing cloud users to simply declare a need
    for these resources and have them provisioned on demand. To have a “cloud native”
    application, then, we need an application that can take advantage of that abstraction.
    As much as possible, the application shouldn’t be tied to a specific host or a
    specific network layout, because we don’t want to constrain our flexibility in
    how application components are divided among hosts.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，云是一种抽象。在介绍中我们已经讨论了抽象，因此您知道抽象对于计算是至关重要的，但我们也需要深入了解我们的抽象才能正确地使用它们。在云的情况下，提供商正在抽象真实的物理处理器、内存、存储和网络，使得云用户可以简单地声明对这些资源的需求，并且按需分配它们。因此，要拥有“云原生”应用程序，我们需要一个能够利用该抽象的应用程序。在可能的情况下，应用程序不应绑定到特定的主机或特定的网络布局，因为我们不希望限制应用程序组件在主机之间的分布灵活性。
- en: 'Attribute: Modular'
  id: totrans-11
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 属性：模块化
- en: '*Modularity* is nothing new to application architecture. The goal has always
    been *high cohesion*, where everything within a module relates to a single purpose,
    and *low coupling*, where modules are organized to minimize intermodule communication.
    However, even though modularity remains a key design goal, the definition of what
    makes a module is different. Rather than just treat modularity as a way of organizing
    the code, modern application architecture today prefers to carry modularity into
    the runtime, providing each module with a separate operating system process and
    discouraging the use of a shared filesystem or shared memory for communication.
    Because modules are separate processes, communication between modules is standard
    network (socket) communication.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*模块化* 对应用架构并不是什么新鲜事物。其目标始终是*高内聚*，即模块内的一切都与单一目的相关，并且*低耦合*，即组织模块以最小化模块间通信。然而，尽管模块化仍然是一个关键的设计目标，但定义模块的方式已经有所不同。现代应用架构更倾向于将模块化带入运行时，而不仅仅是将其视为组织代码的一种方式，为每个模块提供独立的操作系统进程，并且不鼓励使用共享文件系统或共享内存进行通信。由于模块是独立的进程，模块间的通信是标准的网络（套接字）通信。'
- en: This approach seems wasteful of hardware resources. It is more compact and faster
    to share memory than it is to copy data over a socket. But there are two good
    reasons to prefer separate processes. First, modern hardware is fast and getting
    faster, and it would be a form of premature optimization to imagine that sockets
    are not fast enough for our application. Second, no matter how large a server
    we have, there is going to be a limit to how many processes we can fit on it,
    so a shared memory model ultimately limits our ability to grow.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法似乎对硬件资源的利用有些浪费。与其通过套接字复制数据，不如共享内存更为紧凑和快速。但是有两个很好的理由支持使用独立进程。首先，现代硬件速度很快，而且越来越快，想象套接字对我们的应用来说不够快速将是一种过早优化的形式。其次，无论我们有多大的服务器，能容纳的进程数量总是有限的，因此共享内存模型最终会限制我们的扩展能力。
- en: 'Attribute: Microservice-Based'
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 属性：基于微服务
- en: Modern application architecture is based on modules in the form of separate
    processes—and these individual modules tend to be very small. In theory, a cloud
    can provide us with virtual servers that are as powerful as we need; however,
    in practice, using a few powerful servers is more expensive and less flexible
    than many small servers. If our modules are small enough, they can be deployed
    to cheap commodity servers, which means that we can leverage our cloud provider’s
    hardware to best advantage. Although there is no single answer as to how small
    a module needs to be in order to be a *microservice*, “small enough that we can
    be flexible regarding where it is deployed” is a good first rule.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现代应用架构基于形式各异的独立进程模块化，这些个体模块往往非常小。理论上，云可以为我们提供所需的强大虚拟服务器；然而实际上，使用少量强大的服务器比使用许多小型服务器更昂贵且不够灵活。如果我们的模块足够小，它们可以部署到廉价的通用服务器上，这意味着我们可以最大限度地利用云服务提供商的硬件优势。虽然没有一个单一的答案来说明模块需要多小才能成为*微服务*，但“足够小以便可以灵活地部署它”是一个很好的首要规则。
- en: A microservice architecture also has practical advantages for organizing teams.
    Ever since Fred Brooks wrote *The Mythical Man-Month*, architects have understood
    that organizing people is one of the biggest challenges to developing large, complex
    systems. Building a system from many small pieces reduces the complexity of testing
    but also makes it possible to organize a large team of people without everyone
    getting in everyone else’s way.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构在组织团队方面也具有实际的优势。自从弗雷德·布鲁克斯（Fred Brooks）写了《人月神话》（*The Mythical Man-Month*）以来，架构师们就意识到，组织人员是开发大型复杂系统的最大挑战之一。从许多小模块构建系统减少了测试的复杂性，同时也使得组织一个大团队变得可能，而不会让每个人都互相干扰。
- en: '**WHAT ABOUT APPLICATION SERVERS?**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**那么应用服务器呢？**'
- en: The idea of modular services has a long history, and one popular way to implement
    it was building modules to run in an application server, such as a Java Enterprise
    environment. Why not then just continue to follow that pattern for applications?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 模块化服务的概念有着悠久的历史，其中一种流行的实现方式是构建模块并在应用服务器中运行，例如 Java 企业环境。那么，为什么不继续沿用这种应用程序的模式呢？
- en: Although application servers were successful for many uses, they don’t have
    the same degree of isolation that a microservice architecture has. As a result,
    there are more issues with interdependency, leading to more complex testing and
    reduced team independence. Additionally, the typical model of having a single
    application server per host, with many applications deployed to it and sharing
    the same process space, is much less flexible than the containerized approaches
    you will see in this book.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管应用服务器在许多场景中取得了成功，但它们并不像微服务架构那样具有相同程度的隔离性。因此，应用服务器存在更多的相互依赖问题，导致测试变得更加复杂，团队的独立性也有所降低。此外，通常每个主机上部署一个应用服务器，多个应用共享同一进程空间的模式，远没有容器化的方式灵活，而容器化方法将在本书中详细介绍。
- en: This is not to say that you should immediately throw away your application server
    architecture to use containers. There are lots of benefits to containerization
    for any architecture. But as you adopt a containerized architecture, over time
    it will make sense for you to move your code toward a true microservice architecture
    to take best advantage of what containers and Kubernetes offer.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是说你应该立即抛弃应用服务器架构，而转向使用容器。容器化对于任何架构都有很多好处。但是，随着你逐步采用容器化架构，随着时间的推移，向真正的微服务架构迁移将会使你能够充分利用容器和
    Kubernetes 所提供的优势。
- en: We’ve looked at three key attributes of modern architecture. Now, let’s look
    at three key benefits that result.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过了现代架构的三个关键属性。现在，让我们来看三个由此产生的关键好处。
- en: 'Benefit: Scalability'
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 好处：可扩展性
- en: Let’s begin by envisioning the simplest application possible. We create a single
    executable that runs on a single machine and interacts with only a single user
    at a time. Now, suppose that we want to grow this application so that it can interact
    with thousands or millions of users at once. Obviously, no matter how powerful
    a server we use, eventually some computing resource will become a bottleneck.
    It doesn’t matter whether the bottleneck is processing, or memory, or storage,
    or network bandwidth; the moment we hit that bottleneck, our application cannot
    handle any additional users without hurting performance for others.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从构建最简单的应用程序开始。我们创建一个只在单台机器上运行、并且一次只与一个用户交互的可执行文件。现在，假设我们希望将该应用程序扩展，以便能够同时与成千上万的用户交互。显然，无论我们使用多么强大的服务器，最终某些计算资源都会成为瓶颈。不管瓶颈是处理能力、内存、存储还是网络带宽；一旦我们遇到瓶颈，我们的应用程序将无法处理更多的用户，并且会影响其他用户的性能。
- en: The only possible way to solve this issue is to stop sharing the resource that
    caused the bottleneck. This means that we need to find a way to distribute our
    application across multiple servers. But if we’re really scaling up, we can’t
    stop there. We need to distribute across multiple networks as well, or we’ll hit
    the limit of what one network switch can do. And eventually, we will even need
    to distribute geographically, or we’ll saturate the broader network.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的唯一方法是停止共享导致瓶颈的资源。这意味着我们需要找到一种方法，将应用程序分布到多个服务器上。但如果我们要真正扩展，不能仅此为止。我们还需要在多个网络间进行分布，否则会遇到单个网络交换机的限制。最终，我们甚至需要进行地理分布，否则整个广域网络将达到饱和。
- en: To build applications with no limit to scalability, we need an architecture
    that can run additional application instances at will. And because an application
    is only as slow as its slowest component, we need to find a way to scale *everything*,
    including our data stores. It’s obvious that the only way to do this effectively
    is to create our application from many independent pieces that are not tied to
    specific hardware. In other words, cloud native microservices.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建无可扩展性限制的应用程序，我们需要一种能够根据需要运行额外应用实例的架构。而且，由于应用程序的速度只受限于最慢的组件，我们需要找到一种方法来扩展*所有*组件，包括我们的数据存储。显而易见，唯一有效的方式就是将应用程序从许多独立的组件构建而成，这些组件不依赖于特定的硬件。换句话说，云原生微服务。
- en: 'Benefit: Reliability'
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优势：可靠性
- en: Let’s go back to our simplest possible application. In addition to scalability
    limits, it has another flaw. It runs on one server, and if that server fails,
    the entire application fails. Our application is lacking reliability. As before,
    the only possible way to solve this issue is to stop sharing the resource that
    could potentially fail. Fortunately, when we start distributing our application
    across many servers, we have the opportunity to avoid a single point of failure
    in the hardware that would bring down our application. And as an application is
    only as reliable as its least reliable component, we need to find a way to distribute
    everything, including storage and networks. Again, we need cloud native microservices
    that are flexible about where they are run and about how many instances are running
    at once.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到最简单的应用程序。除了可扩展性限制外，它还有另一个缺陷。它运行在一台服务器上，如果这台服务器发生故障，整个应用程序就会失败。我们的应用程序缺乏可靠性。如同之前所说，解决这个问题的唯一方法就是停止共享可能发生故障的资源。幸运的是，当我们开始将应用程序分布到多台服务器时，我们有机会避免硬件中的单点故障，这样就不会导致整个应用程序的崩溃。而且，由于应用程序的可靠性取决于其最不可靠的组件，我们需要找到一种方法来分发所有内容，包括存储和网络。同样，我们需要云原生微服务，它们在运行位置和实例数量上都具有灵活性。
- en: 'Benefit: Resilience'
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 优势：弹性
- en: There is a third, subtler advantage to cloud native microservice architecture.
    This time, imagine an application that runs on a single server, but it can easily
    be installed as a single package on as many servers as we like. Each instance
    can serve a new user. In theory, this application would have good scalability,
    given that we can always install it on another server. And overall, the application
    could be said to be reliable because a failure of a single server is going to
    affect only that one user, whereas the others can keep running as normal.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生微服务架构还有第三个、更微妙的优势。这一次，假设有一个运行在单个服务器上的应用程序，但它可以轻松地作为一个单独的包安装到任意数量的服务器上。每个实例都可以为一个新用户提供服务。理论上，由于我们可以随时将其安装到另一台服务器上，这个应用程序应该具有良好的可扩展性。总体来说，应用程序可以说是可靠的，因为单一服务器的故障只会影响到一个用户，而其他用户可以照常运行。
- en: What is missing from this approach is the concept of resilience, or the ability
    of an application to respond meaningfully to failure. A truly resilient application
    can handle a hardware or software failure somewhere in the application without
    an end user noticing at all. And although separate, unrelated instances of this
    application keep running when one instance fails, we can’t really say that the
    application exhibits resilience, at least not from the perspective of the unlucky
    user with the failed system.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法所缺失的是弹性的概念，或者说应用程序对故障的有意义响应能力。一个真正具有弹性的应用程序可以在应用程序中的某个硬件或软件发生故障时，确保最终用户根本不会注意到故障的存在。尽管如此，分离的、互不相关的实例在其中一个实例发生故障时仍然能够继续运行，但我们不能真正说这个应用程序表现出了弹性，至少从那个遭遇故障的用户的角度来看是这样。
- en: On the other hand, if we construct our application out of separate microservices,
    each of which has the ability to communicate over a network with other microservices
    on any server, the loss of a single server might cost us several microservice
    instances, but end users can be moved to other instances on other servers transparently,
    such that they don’t even notice the failure.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们将应用程序构建为多个独立的微服务，每个微服务都能够通过网络与其他微服务进行通信，那么单个服务器的丧失可能会导致多个微服务实例的损失，但最终用户可以透明地切换到其他服务器上的实例，这样他们甚至不会注意到故障的发生。
- en: Why Containers
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么选择容器
- en: I’ve made modern application architecture with its fancy cloud native microservices
    sound pretty appealing. Engineering is full of trade-offs, however, so experienced
    engineers will suspect that there must be some pretty significant trade-offs,
    and, of course, there are.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经让现代应用架构和它那炫酷的云原生微服务听起来非常有吸引力了。然而，工程中充满了权衡，经验丰富的工程师会怀疑一定会有一些非常重大的权衡，当然，确实如此。
- en: It’s *very difficult* to build an application from lots of small pieces. Organizing
    teams around microservices so that they can work independently from one another
    might be great, but when it comes time to put those together into a working application,
    the sheer number of pieces means worrying about how to package them up, how to
    deliver them to the runtime environment, how to configure them, how to provide
    them with (potentially conflicting) dependencies, how to update them, and how
    to monitor them to make sure they are working.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从许多小的组件构建一个应用程序是*非常困难*的。围绕微服务组织团队，使得它们能够独立工作可能是很好的，但当需要将这些组件组合成一个可以运行的应用程序时，组件数量庞大意味着我们必须担心如何打包它们，如何将它们交付到运行环境中，如何配置它们，如何为它们提供（可能存在冲突的）依赖项，如何更新它们，以及如何监控它们以确保它们正常工作。
- en: This problem only grows worse when we consider the need to run multiple instances
    of each microservice. Now, we need a microservice to be able to find a working
    instance of another microservice, balancing the load across all of the working
    instances. We need that load balancing to reconfigure itself immediately if we
    have a hardware or software failure. We need to fail over seamlessly and retry
    failed work in order to hide that failure from the end user. And we need to monitor
    not just each individual service, but how all of them are working together to
    get the job done. After all, our users don’t care if 99 percent of our microservices
    are working correctly if the 1 percent failure prevents them from using our application.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑到需要运行每个微服务的多个实例时，这个问题变得更加严重。现在，我们需要一个微服务能够找到另一个微服务的工作实例，并在所有工作实例之间均衡负载。我们需要负载均衡在发生硬件或软件故障时立即重新配置自己。我们需要无缝切换并重试失败的工作，以便将故障对终端用户隐藏起来。而且我们不仅需要监控每个单独的服务，还需要监控所有服务如何协同工作以完成任务。毕竟，如果我们有99%的微服务正常工作，而1%的故障使得用户无法使用我们的应用程序，我们的用户是不会在乎其他微服务是否正常工作的。
- en: 'We have lots of problems to solve if we want to build an application out of
    many individual microservices, and we do not want each of our microservice teams
    working those problems, or they would never have time to write code! We need a
    common way to manage the packaging, deployment, configuration, and maintenance
    of our microservices. Let’s look at two categories of required attributes: those
    that apply to a single microservice, and those that apply to multiple microservices
    working together.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想从许多独立的微服务中构建一个应用程序，我们面临许多问题需要解决，并且我们不希望每个微服务团队都去解决这些问题，否则他们就永远没有时间写代码！我们需要一种共同的方式来管理微服务的打包、部署、配置和维护。我们来看一下所需属性的两类：适用于单个微服务的属性和适用于多个微服务共同工作的属性。
- en: Requirements for Containers
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 容器的需求
- en: 'For a single microservice, we need the following:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单个微服务，我们需要以下内容：
- en: '**Packaging** Bundle the application for delivery, which needs to include dependencies
    so that the package is portable and we avoid conflicts between microservices.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**打包** 将应用程序打包以便交付，打包中需要包括依赖项，以便包是可移植的，并且我们避免微服务之间的冲突。'
- en: '**Versioning** Uniquely identify a version. We need to update microservices
    over time, and we need to know what version is running.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**版本控制** 唯一标识一个版本。我们需要随时间更新微服务，并且我们需要知道哪个版本正在运行。'
- en: '**Isolation** Keep microservices from interfering with one another. This allows
    us to be flexible about what microservices are deployed together.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**隔离性** 防止微服务相互干扰。这使得我们能够灵活地部署微服务。'
- en: '**Fast startup** Start new instances rapidly. We need this to scale and respond
    to failures.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**快速启动** 快速启动新的实例。我们需要这个来扩展和应对故障。'
- en: '**Low overhead** Minimize required resources to run a microservice in order
    to avoid limits on how small a microservice can be.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**低开销** 最小化运行微服务所需的资源，以避免对微服务大小的限制。'
- en: '*Containers* are designed to address exactly these needs. Containers provide
    isolation together with low overhead and fast startup. And, as we’ll see in [Chapter
    5](ch05.xhtml#ch05), a container runs from a container image, which provides a
    way to package an application with its dependencies and to uniquely identify the
    version of that package.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*容器* 正是为了解决这些需求而设计的。容器提供隔离，同时具有低开销和快速启动的特点。正如我们将在[第5章](ch05.xhtml#ch05)中看到的，容器是从容器镜像中运行的，容器镜像为我们提供了一种将应用程序及其依赖项打包并唯一标识该包版本的方式。'
- en: Requirements for Orchestration
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 编排的需求
- en: 'For multiple microservices working together, we need:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多个微服务协同工作，我们需要：
- en: '**Clustering** Provide processing, memory, and storage for containers across
    multiple servers.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**集群** 提供跨多个服务器的容器处理、内存和存储。'
- en: '**Discovery** Provide a way for one microservice to find another. Our microservices
    might run anywhere on the cluster, and they might move around.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**发现** 为一个微服务提供查找另一个微服务的方法。我们的微服务可能在集群中的任何地方运行，而且它们可能会移动。'
- en: '**Configuration** Separate configuration from runtime, allowing us to reconfigure
    our application without rebuilding and redeploying our microservices.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**配置** 将配置与运行时分离，允许我们在不重新构建和重新部署微服务的情况下重新配置应用程序。'
- en: '**Access control** Manage authorization to create containers. This ensures
    that the right containers run, and the wrong ones don’t.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**访问控制** 管理创建容器的授权。这确保了正确的容器运行，错误的容器不会运行。'
- en: '**Load balancing** Spread requests among working instances in order to avoid
    the need for end users or other microservices to track all microservice instances
    and balance the load themselves.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**负载均衡** 在工作实例之间分配请求，以避免最终用户或其他微服务自行跟踪所有微服务实例并平衡负载。'
- en: '**Monitoring** Identify failed microservice instances. Load balancing won’t
    work well if traffic is going to failed instances.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**监控** 识别失败的微服务实例。如果流量指向失败的实例，负载均衡将无法正常工作。'
- en: '**Resilience** Automatically recover from failures. If we don’t have this ability,
    a chain of failures could kill our application.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**弹性** 自动从故障中恢复。如果没有这个能力，故障链可能会致使我们的应用程序崩溃。'
- en: These requirements come into play only when we are running containers on multiple
    servers. It’s a different problem from just packaging up and running a single
    container. To address these needs, we require a *container orchestration* environment.
    A container orchestration environment such as Kubernetes allows us to treat multiple
    servers as a single set of resources to run containers, dynamically allocating
    containers to available servers and providing distributed communication and storage.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这些需求仅在我们在多个服务器上运行容器时才会发挥作用。这与仅打包并运行单个容器是不同的问题。为了解决这些需求，我们需要一个*容器编排*环境。像 Kubernetes
    这样的容器编排环境使我们能够将多个服务器视为一组资源来运行容器，动态地将容器分配到可用的服务器，并提供分布式通信和存储。
- en: Running Containers
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行容器
- en: By now, hopefully you’re excited by the possibilities of building an application
    using containerized microservices and Kubernetes. Let’s walk through the basics
    so that you can see what these ideas look like in practice, providing a foundation
    for the deeper dive into container technology that you’ll find in the rest of
    this book.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，希望你已经对使用容器化微服务和 Kubernetes 构建应用程序的可能性感到兴奋。让我们先了解一些基础知识，这样你就可以看到这些想法在实践中的应用，并为本书后续深入研究容器技术奠定基础。
- en: What Containers Look Like
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 容器的样子
- en: In [Chapter 2](ch02.xhtml#ch02), we’ll look at the difference between a container
    platform and a container runtime, and we’ll run containers using multiple container
    runtimes. For now, let’s begin with a simple example running in the most popular
    container platform, *Docker*. Our goal is to learn the basic Docker commands,
    which align to universal container concepts.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](ch02.xhtml#ch02)，我们将研究容器平台与容器运行时之间的区别，并使用多个容器运行时来运行容器。目前，我们从一个简单的例子开始，在最流行的容器平台*Docker*上运行。我们的目标是学习基本的
    Docker 命令，这些命令与通用的容器概念相一致。
- en: Running a Container
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 运行一个容器
- en: The first command is `run`, which creates a container and runs a command inside
    it. We will tell Docker the name of the container image to use. We discuss container
    images more in [Chapter 5](ch05.xhtml#ch05); for now, it’s enough to know that
    it provides a unique name and version so that Docker knows exactly what to run.
    Let’s get started using the example for this chapter.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令是`run`，它会创建一个容器并在其中运行一个命令。我们将告诉Docker使用哪个容器镜像的名称。关于容器镜像的详细内容，我们将在[第5章](ch05.xhtml#ch05)中讨论；目前，知道它提供一个独特的名称和版本号就足够了，这样Docker就能准确知道运行什么。让我们开始使用本章的示例。
- en: '**NOTE**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*The example repository for this book is at* [https://github.com/book-of-kubernetes/examples](https://github.com/book-of-kubernetes/examples).
    *See “Running Examples” on [page xx](ch00.xhtml#ch00lev1sec2) for details on getting
    set up.*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*本书的示例代码库位于* [https://github.com/book-of-kubernetes/examples](https://github.com/book-of-kubernetes/examples)。*有关设置的详细信息，请参见[第xx页](ch00.xhtml#ch00lev1sec2)中的“运行示例”部分。*'
- en: 'A key idea for this section is that containers look like a completely separate
    system. To illustrate this, before we run a container, let’s look at the host
    system:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的一个关键概念是容器看起来像是一个完全独立的系统。为了说明这一点，在我们运行容器之前，让我们先看一下主机系统：
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The first command looks at a file called */etc/os-release*, which has information
    about the installed Linux distribution. In this case, our example virtual machine
    is running Ubuntu. That matches the output of the next command, in which we see
    an Ubuntu-based Linux kernel. Finally, we list network interfaces and see an IP
    address of `192.168.61.11`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令查看一个名为*/etc/os-release*的文件，里面包含有关已安装Linux发行版的信息。在这个例子中，我们的虚拟机正在运行Ubuntu。这与接下来命令的输出相匹配，在该命令中我们看到一个基于Ubuntu的Linux内核。最后，我们列出网络接口，并看到一个IP地址`192.168.61.11`。
- en: 'The example setup steps automatically installed Docker, so we have it ready
    to go. First, let’s download and start a Rocky Linux container with a single command:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 示例的设置步骤已自动安装Docker，因此我们可以直接使用它。首先，让我们用一个命令下载并启动一个Rocky Linux容器：
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We use `-ti` in our `docker run` command to tell Docker that we need an interactive
    terminal to run commands. The only other parameter to `docker run` is the container
    image, `rockylinux:8`, which specifies the name `rockylinux` and the version `8`.
    Because we don’t provide a command to run, the default `bash` command for that
    container image is used.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`docker run`命令中使用`-ti`参数，告诉Docker我们需要一个交互式终端来运行命令。`docker run`的唯一其他参数是容器镜像`rockylinux:8`，它指定了名称`rockylinux`和版本`8`。由于我们没有提供要运行的命令，因此默认使用该容器镜像的`bash`命令。
- en: 'Now that we have a shell prompt inside the container, we can run a few commands
    and then use `exit` to leave the shell and stop the container:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在容器内有了一个shell提示符，可以运行一些命令，然后使用`exit`退出shell并停止容器：
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'When we run commands within our container, it looks like we are running in
    a Rocky Linux system. Compared to the host system, there are multiple differences:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在容器内运行命令时，看起来就像是在一个Rocky Linux系统中运行。与主机系统相比，有多个差异：
- en: A different hostname in the shell prompt ➊ (`18f20e2d7e49` for mine, though
    yours will be different)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: shell提示符中不同的主机名 ➊（我的主机名是`18f20e2d7e49`，但你的会不同）
- en: Different filesystem contents ➋, including basic files like */etc/os-release*
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的文件系统内容 ➋，包括像*/etc/os-release*这样的基础文件
- en: The use of `yum` ➌ to install packages, and the need to install packages even
    for basic commands
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`yum` ➌安装包，甚至基础命令也需要安装包
- en: A limited set of running processes, with no base system services and our bash
    shell ➍ as process ID (PID) 1
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制的运行进程集，没有基础系统服务，我们的bash shell ➍作为进程ID（PID）1
- en: Different network devices ➎, including a different MAC address and IP address
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的网络设备 ➎，包括不同的MAC地址和IP地址
- en: Strangely, however, when we run `uname -v`, we see the exact same Ubuntu Linux
    kernel ➏ as when we were on the host. Clearly, a container is not a wholly separate
    system as we might otherwise believe.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，奇怪的是，当我们运行`uname -v`时，我们看到的与主机上完全相同的Ubuntu Linux内核 ➏。显然，容器并不是我们想象的那样是一个完全独立的系统。
- en: Images and Volume Mounts
  id: totrans-78
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 镜像和卷挂载
- en: 'At first glance, a container looks like a mix between a regular process and
    a virtual machine. And the way we interact with Docker only deepens that impression.
    Let’s illustrate that by running an Alpine Linux container. We’ll start by “pulling”
    the container image, which feels a lot like downloading a virtual machine image:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，容器看起来像是常规进程和虚拟机的混合体。我们与Docker的交互方式更深刻地加强了这一印象。让我们通过运行一个Alpine Linux容器来说明这一点。我们将首先“拉取”容器镜像，这与下载虚拟机镜像非常相似：
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we’ll run a container from the image. We’ll use a *volume mount* to see
    files from the host, a common task with a virtual machine. However, we’ll also
    tell Docker to specify an environment variable, which is the kind of thing we
    would do when running a regular process:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将从镜像运行一个容器。我们将使用*卷挂载*来查看主机上的文件，这在虚拟机中是一个常见任务。我们还会告诉Docker指定一个环境变量，这就是我们在运行常规进程时会做的事情：
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can print the contents of */etc/os-release* inside the container, as before
    with Rocky Linux:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像之前在Rocky Linux中一样打印容器内的*/etc/os-release*文件内容：
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'However, this time we can also print the host’s */etc/os-release* file because
    the host filesystem is mounted at */host*:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这次我们还可以打印主机的*/etc/os-release*文件，因为主机文件系统已挂载到*/host*：
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And finally, within the container we also have access to the environment variable
    we passed in:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在容器内我们也可以访问传入的环境变量：
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This mix of ideas from virtual machines and regular processes sometimes leads
    new container users to ask questions like, “Why can’t I SSH into my container?”
    A major goal of the next few chapters is to make clear what containers really
    are.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这种混合虚拟机和常规进程的概念有时会导致新容器用户提出类似“为什么我不能通过SSH连接到我的容器？”的问题。接下来几章的一个主要目标是阐明容器到底是什么。
- en: What Containers Really Are
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 容器究竟是什么
- en: Despite what a container looks like, with its own hostname, filesystem, process
    space, and networking, a container is not a virtual machine. It does not have
    a separate kernel, so it cannot have separate kernel modules or device drivers.
    A container can have multiple processes, but they must be started explicitly by
    the first process (PID 1). So a container will not have an SSH server in it by
    default, and most containers do not have any system services running.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管容器看起来像有自己的主机名、文件系统、进程空间和网络，但容器并不是虚拟机。它没有独立的内核，因此不能有独立的内核模块或设备驱动程序。一个容器可以有多个进程，但它们必须由第一个进程（PID
    1）显式启动。所以，容器默认不会有SSH服务器，大多数容器也不会运行任何系统服务。
- en: In the next several chapters, we’ll look at how a container manages to look
    like a separate system while being a group of processes. For now, let’s try one
    more Docker example to see what a container looks like from the host system.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几章中，我们将看看容器如何在看似是一个独立系统的同时，实际上只是一组进程。现在，让我们再试一个Docker示例，看看从主机系统看容器是什么样的。
- en: 'First, we’ll download and run NGINX with a single command:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将下载并运行NGINX，只需一个命令：
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This example illustrates a couple of additional useful Docker commands. And
    again, we are mixing ideas from virtual machines and regular processes. By using
    the `-d` flag, we tell Docker to run this container in *daemon mode* (in the background),
    which is the kind of thing we would do for a regular process. Using `-p 8080:80`,
    however, brings in another concept from virtual machines, as it instructs Docker
    to forward port 8080 on the host to port 80 in the container, letting us connect
    to NGINX from the host even though the container has its own network interfaces.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例演示了几个额外有用的Docker命令。再次提醒，我们正在混合虚拟机和常规进程的概念。通过使用`-d`标志，我们告诉Docker以*守护进程模式*（后台模式）运行容器，这正是我们为常规进程所做的事情。然而，使用`-p
    8080:80`带来了另一个虚拟机的概念，因为它指示Docker将主机上的8080端口转发到容器内的80端口，从而让我们即使容器有自己的网络接口，也能从主机连接到NGINX。
- en: 'NGINX is now running in the background in a Docker container. To see it, run
    the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX现在在Docker容器中后台运行。要查看它，请运行以下命令：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Because of the port forwarding, we can connect to it from our host system using
    `curl`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 由于端口转发，我们可以通过`curl`从主机系统连接到它：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With this example, we’re starting to see how containerization meets some of
    the needs we identified earlier in this chapter. Because NGINX is packaged into
    a container image, we can download and run it with a single command, with no concern
    for any conflict with anything else that might be installed on our host.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个示例，我们开始看到容器化如何满足我们在本章前面提到的一些需求。因为NGINX被打包成一个容器镜像，我们可以通过一个命令下载并运行它，而不必担心与主机上可能安装的其他内容产生冲突。
- en: 'Let’s run one more command to explore our NGINX server:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再运行一个命令来探索我们的NGINX服务器：
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If NGINX were running in a virtual machine, we would not see it in a `ps` listing
    on the host system. Clearly, NGINX in a container is running as a regular process.
    At the same time, we didn’t need to install NGINX onto our host system to get
    it working. In other words, we are getting the benefits of a virtual machine approach
    without the overhead of a virtual machine.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 NGINX 运行在虚拟机中，我们在主机系统的 `ps` 列表中是看不到它的。显然，NGINX 在容器中作为一个常规进程运行。同时，我们并不需要将
    NGINX 安装到主机系统中就能让它工作。换句话说，我们可以享受虚拟机方法的好处，而无需承受虚拟机的开销。
- en: Deploying Containers to Kubernetes
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将容器部署到 Kubernetes
- en: To have load balancing and resilience in our containerized applications, we
    need a container orchestration framework like Kubernetes. Our example system also
    has a Kubernetes cluster automatically installed, with a web application and database
    deployed to it. As a preparation for our deep dive into Kubernetes in [Part II](part02.xhtml#part02),
    let’s look at that application.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在容器化应用程序中实现负载均衡和弹性，我们需要像 Kubernetes 这样的容器编排框架。我们的示例系统还自动安装了一个 Kubernetes 集群，并将
    Web 应用程序和数据库部署到了其中。作为我们深入探讨 Kubernetes 的准备，在[第二部分](part02.xhtml#part02)中，让我们来看一下这个应用程序。
- en: There are many different options for installing and configuring a Kubernetes
    cluster, with distributions available from many companies. We discuss multiple
    options for Kubernetes distributions in [Chapter 6](ch06.xhtml#ch06). For this
    chapter, we’ll use a lightweight distribution called “K3s” from a company called
    Rancher.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多不同的安装和配置 Kubernetes 集群的选项，许多公司都提供了不同的发行版。在[第 6 章](ch06.xhtml#ch06)中，我们讨论了多种
    Kubernetes 发行版的选择。本章中，我们将使用来自 Rancher 公司的轻量级发行版“K3s”。
- en: To use a container orchestration environment like Kubernetes, we have to give
    up some control over our containers. Rather than executing commands directly to
    run containers, we’ll tell Kubernetes what containers we want it to run, and it
    will decide where to run each container. Kubernetes will then monitor our containers
    for us and handle automatic restart, failover, updates to new versions, and even
    autoscaling based on load. This style of configuration is called *declarative*.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用像 Kubernetes 这样的容器编排环境，我们必须放弃对容器的部分控制。我们不再直接执行命令来运行容器，而是告诉 Kubernetes 我们希望它运行哪些容器，Kubernetes
    会决定在哪个节点上运行每个容器。Kubernetes 会为我们监控容器，并处理自动重启、故障转移、版本更新，甚至根据负载进行自动扩缩容。这种配置方式被称为*声明式*。
- en: Talking to the Kubernetes Cluster
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 与 Kubernetes 集群交互
- en: 'A Kubernetes cluster has an API server that we can use to get status and change
    the cluster configuration. We interact with the API server using the `kubectl`
    client application. K3s comes with its own embedded `kubectl` command that we’ll
    use. Let’s begin by getting some basic information about the Kubernetes cluster:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群有一个 API 服务器，我们可以用它来获取状态并更改集群配置。我们通过 `kubectl` 客户端应用程序与 API 服务器交互。K3s
    附带了它自己的内嵌 `kubectl` 命令，我们将使用它。让我们先获取一些关于 Kubernetes 集群的基本信息：
- en: '[PRE12]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, we’re working with a single-node Kubernetes cluster. Of course,
    this would not meet our needs for high availability. Most Kubernetes distributions,
    including K3s, support a multinode, highly available cluster, and we will look
    at how that works in detail in [Part II](part02.xhtml#part02).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们正在使用一个单节点 Kubernetes 集群。当然，这并不能满足我们对高可用性的需求。大多数 Kubernetes 发行版，包括 K3s，都支持多节点、高可用性集群，我们将在[第二部分](part02.xhtml#part02)中详细介绍这种方式。
- en: Application Overview
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 应用程序概述
- en: Our example application provides a “to-do” list with a web interface, persistent
    storage, and tracking of item state. It will take several minutes for this to
    be running in Kubernetes, even after the automated scripts are finished. After
    it’s running, we can access it in a browser and should see something like [Figure
    1-1](ch01.xhtml#ch01fig1).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例应用程序提供一个带有 Web 界面的“待办事项”列表、持久化存储以及条目状态跟踪。即使自动化脚本完成后，这个应用程序在 Kubernetes
    中运行也需要几分钟时间。运行后，我们可以在浏览器中访问它，并应该看到类似[图 1-1](ch01.xhtml#ch01fig1)的内容。
- en: '![Image](../images/f0015-01.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/f0015-01.jpg)'
- en: '*Figure 1-1: An example application in Kubernetes*'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1-1：Kubernetes 中的示例应用程序*'
- en: 'This application is divided into two types of containers, one for each application
    component. A Node.js application serves files to the browser and provides a REST
    API. The Node.js application communicates with a PostgreSQL database. The Node.js
    component is stateless, so it is easy to scale up to as many instances as we need
    based on the number of users. In this case, our application’s Deployment asked
    Kubernetes for three Node.js containers:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这个应用程序被分为两种类型的容器，每种类型负责一个应用组件。Node.js 应用程序向浏览器提供文件并提供 REST API。Node.js 应用程序与
    PostgreSQL 数据库通信。Node.js 组件是无状态的，因此可以根据用户数量轻松扩展到所需的多个实例。在这种情况下，我们的应用程序的 Deployment
    向 Kubernetes 请求了三个 Node.js 容器：
- en: '[PRE13]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The command `get pods` tells Kubernetes to list *Pods*. A Pod is a group of
    one or more containers that Kubernetes treats as a single unit for scheduling
    and monitoring. We look at Pods more closely throughout [Part II](part02.xhtml#part02).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 命令 `get pods` 告诉 Kubernetes 列出 *Pods*。Pod 是一个包含一个或多个容器的组，Kubernetes 将其视为一个单元进行调度和监控。我们将在[第二部分](part02.xhtml#part02)中更详细地查看
    Pods。
- en: Here, we have one Pod whose name starts with `todo-db`, which is our PostgreSQL
    database. The other three Pods, with names starting with `todo`, are the Node.js
    containers. (We’ll explain later why the names have random characters after them;
    you can ignore that for now.)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有一个以 `todo-db` 开头的 Pod，它是我们的 PostgreSQL 数据库。其他三个以 `todo` 开头的 Pods 是 Node.js
    容器。（稍后我们会解释为什么名称后面会有随机字符；你现在可以忽略这一点。）
- en: According to Kubernetes, our application component containers are running, so
    we should be able to access our application in a browser. How you do this depends
    on whether you are running in AWS or Vagrant; the example setup scripts will print
    out what URL you should use in your browser. If you visit that URL, you should
    see something like [Figure 1-1](ch01.xhtml#ch01fig1).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Kubernetes 的说法，我们的应用组件容器正在运行，所以我们应该能够在浏览器中访问我们的应用。如何操作取决于你是在 AWS 还是 Vagrant
    中运行；示例设置脚本会打印出你在浏览器中应该使用的 URL。如果你访问那个 URL，你应该能看到类似于[图 1-1](ch01.xhtml#ch01fig1)的内容。
- en: Kubernetes Features
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Kubernetes 特性
- en: If our only goal were to run four containers, we could have done that just using
    the Docker commands described earlier. Kubernetes is providing a lot more functionality,
    though. Let’s take a quick tour of the most important features.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的唯一目标是运行四个容器，我们可以仅使用之前描述的 Docker 命令来完成。然而，Kubernetes 提供了更多的功能。让我们快速了解一下最重要的功能。
- en: 'In addition to running our containers, Kubernetes is also monitoring them.
    Because we asked for three instances, Kubernetes will work to keep three instances
    running. Let’s destroy one and watch Kubernetes automatically recover:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 除了运行我们的容器，Kubernetes 还在监控它们。因为我们要求有三个实例，Kubernetes 会确保始终保持三个实例运行。让我们销毁一个并观察
    Kubernetes 如何自动恢复：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: To run this command, you will need to copy and paste the full name of one of
    your three Pods. The name will be a little different from mine. When you delete
    a Pod, you should see that Kubernetes immediately creates a new one. (You can
    identify which one is brand new by the `AGE` field.)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行这个命令，你需要复制并粘贴你三个 Pods 之一的完整名称。这个名称会与你的稍微不同。当你删除一个 Pod 时，你应该会看到 Kubernetes
    立即创建一个新的 Pod。（你可以通过 `AGE` 字段来识别哪个是新创建的。）
- en: 'Next let’s explore how Kubernetes can automatically scale our application.
    Later, we’ll see how to make Kubernetes do this automatically, but for now, we
    will do it manually. Suppose that we decide we need five Pods instead of three.
    We can do this with one command:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探讨一下 Kubernetes 如何自动扩展我们的应用程序。稍后我们将看到如何让 Kubernetes 自动执行此操作，但现在我们将手动进行。假设我们决定需要五个
    Pods，而不是三个。我们可以通过一条命令来做到这一点：
- en: '[PRE15]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We tell Kubernetes to scale the *Deployment* that manages our Pods. For now,
    you can think of the Deployment as the “owner” of the Pods; it monitors them and
    controls how many there are. Here, two extra Pods are immediately created. We
    just scaled up our application.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们告诉 Kubernetes 扩展管理我们 Pods 的 *Deployment*。现在，你可以把 Deployment 看作是 Pods 的“所有者”；它监控它们并控制
    Pods 的数量。这里，两个额外的 Pods 被立即创建。我们刚刚扩展了我们的应用程序。
- en: 'Before we close, let’s look at one more critically important Kubernetes feature.
    When you load the application in your web browser, Kubernetes is sending your
    browser’s request to one of the available Pods. Each time you reload, the request
    might be routed to a different Pod because Kubernetes is automatically balancing
    the application’s load. To make this happen, when we deploy our application to
    Kubernetes, the application configuration includes a *Service*:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束之前，让我们再来看一个至关重要的Kubernetes功能。当你在浏览器中加载应用程序时，Kubernetes会将你的浏览器请求发送到可用的Pod之一。每次重新加载时，请求可能会被路由到不同的Pod，因为Kubernetes会自动平衡应用程序的负载。为了实现这一点，当我们将应用程序部署到Kubernetes时，应用程序的配置包括一个*Service*：
- en: '[PRE16]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: A Service has its own IP address and routes traffic to one or more endpoints.
    In this case, because we scaled up to five Pods, the Service is balancing traffic
    across all five endpoints.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 每个服务都有自己的IP地址，并将流量路由到一个或多个端点。在这种情况下，由于我们将Pod数量扩展到五个，服务正在对所有五个端点的流量进行负载均衡。
- en: Final Thoughts
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后的思考
- en: Modern applications achieve scalability and reliability through an architecture
    based on microservices that can be deployed independently and dynamically to available
    hardware, including cloud resources. By using containers and container orchestration
    to run our microservices, we achieve a common approach for packaging, scaling,
    monitoring, and maintaining microservices, enabling our development teams to focus
    on the hard work of actually building the application.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现代应用程序通过基于微服务的架构实现可扩展性和可靠性，微服务可以独立部署并动态分配到可用的硬件上，包括云资源。通过使用容器和容器编排来运行我们的微服务，我们实现了一种通用的方法来打包、扩展、监控和维护微服务，使我们的开发团队可以专注于实际构建应用程序的艰苦工作。
- en: In this chapter, we saw how containerization can create the appearance of a
    separate system while really being a regular process run in an isolated way. We
    also saw how we can use Kubernetes to deploy an entire application as a set of
    containers, with scalability and self-healing. Of course, Kubernetes has a lot
    more important features than what we’ve mentioned here, enough that it will take
    the whole book for us to cover them all! With this brief overview, I hope you
    are excited to dive more deeply into containers and Kubernetes in order to understand
    how to build applications that perform well and are reliable.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到容器化如何创造出一个独立系统的外观，而实际上它只是一个以隔离方式运行的常规进程。我们还看到如何使用Kubernetes将整个应用程序作为一组容器进行部署，具备可扩展性和自愈性。当然，Kubernetes的功能远不止我们在这里提到的这些，足够让我们用整本书来详细讲解！通过这一简要概述，我希望你能对容器和Kubernetes产生兴趣，深入了解如何构建高性能且可靠的应用程序。
- en: We’ll come back to Kubernetes in [Part II](part02.xhtml#part02) of this book.
    For now, let’s look closely at how containers create the illusion of a separate
    system. We’ll start by looking at process isolation using Linux namespaces.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的[第二部分](part02.xhtml#part02)再次讨论Kubernetes。现在，让我们仔细看看容器是如何创建出一个独立系统的假象的。我们将从使用Linux命名空间来实现进程隔离开始。
