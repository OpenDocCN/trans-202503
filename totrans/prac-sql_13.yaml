- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Advanced Query Techniques
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: Sometimes data analysis requires advanced SQL techniques that go beyond a table
    join or basic `SELECT` query. In this chapter, we’ll cover techniques that include
    writing a query that uses the results of other queries as inputs and reclassifying
    numerical values into categories before counting them.
  prefs: []
  type: TYPE_NORMAL
- en: For the exercises, I’ll introduce a dataset of temperatures recorded in select
    US cities, and we’ll revisit datasets you’ve created in previous chapters. The
    code for the exercises is available, along with all the book’s resources, at [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/).
    You’ll continue to use the `analysis` database you’ve already built. Let’s get
    started.
  prefs: []
  type: TYPE_NORMAL
- en: Using Subqueries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A *subquery* is a query nested inside another query. Typically, it performs
    a calculation or a logical test or generates rows to be passed into the main outer
    query. Subqueries are part of standard ANSI SQL, and the syntax is not unusual:
    we just enclose a query in parentheses. For example, we can write a subquery that
    returns multiple rows and treat those results as a table in the `FROM` clause
    of the main outer query. Or we can create a *scalar subquery* that returns a single
    value and use it as part of an *expression* to filter rows via `WHERE`, `IN`,
    and `HAVING` clauses. A *correlated subquery* is one that depends on a value or
    table name from the outer query to execute. Conversely, an *uncorrelated subquery*
    has no reference to objects in the main query.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s easier to understand these concepts by working with data, so let’s revisit
    several datasets from earlier chapters, including the census county-level population
    estimates table `us_counties_pop_est_2019` and the business patterns table `cbp_naics_72_establishments`.
  prefs: []
  type: TYPE_NORMAL
- en: Filtering with Subqueries in a WHERE Clause
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A `WHERE` clause lets you filter query results based on criteria you provide,
    using an expression such as `WHERE quantity > 1000`. But this requires that you
    already know the value to use for comparison. What if you don’t? That’s one way
    a subquery comes in handy: it lets you write a query that generates one or more
    values to use as part of an expression in a `WHERE` clause.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating Values for a Query Expression
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Say you wanted to write a query to show which US counties are at or above the
    90th percentile, or top 10 percent, for population. Rather than writing two separate
    queries—one to calculate the 90th percentile and another to find counties with
    populations at or higher—you can do both at once using a subquery as part of a
    `WHERE` clause, as shown in [Listing 13-1](#listing13-1).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-1: Using a subquery in a `WHERE` clause'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `WHERE` clause 1, which filters by the total population column `pop_est_2019`,
    doesn’t include a value as it normally would. Instead, after the `>=` comparison
    operators, we provide a subquery in parentheses. This subquery uses the `percentile_cont()`
    function to generate one value: the 90th percentile cutoff point in the `pop_est_2019`
    column.'
  prefs: []
  type: TYPE_NORMAL
- en: This is an example of an uncorrelated subquery. It does not depend on any values
    in the outer query, and it will be executed just once to generate the requested
    value. If you run the subquery portion only, by highlighting it in pgAdmin, it
    will execute, and you should see a result of `213707.3`. But you won’t see that
    number when you run the entire query in [Listing 13-1](#listing13-1), because
    the subquery result is passed directly to the outer query’s `WHERE` clause.
  prefs: []
  type: TYPE_NORMAL
- en: The entire query should return 315 rows, or about 10 percent of the 3,142 rows
    in `us_counties_pop_est_2019`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The result includes all counties with a population greater than or equal to
    `213707.3`, the value the subquery generated.
  prefs: []
  type: TYPE_NORMAL
- en: Using a Subquery to Identify Rows to Delete
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We can use the same subquery in a `DELETE` statement to specify what to remove
    from a table. In [Listing 13-2](#listing13-2), we make a copy of the census table
    using the method you learned in Chapter 10 and then delete everything from that
    backup except the 315 counties in the top 10 percent of population.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-2: Using a subquery in a `WHERE` clause with `DELETE`'
  prefs: []
  type: TYPE_NORMAL
- en: Run the code in [Listing 13-2](#listing13-2), and then execute `SELECT count(*)
    FROM us_counties_2019_top10;` to count the remaining rows. The result should be
    315 rows, which is the original 3,142 minus the 2,827 below the value identified
    by the subquery.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Derived Tables with Subqueries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If your subquery returns rows and columns, you can place it in a `FROM` clause
    to create a new table known as a *derived table* that you can query or join with
    other tables, just as you would a regular table. It’s another example of an uncorrelated
    subquery.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at a simple example. In Chapter 6, you learned the difference between
    average and median. A median often better indicates a dataset’s central value
    because a few very large or small values (or outliers) can skew an average. For
    that reason, I often compare the two. If they’re close, the data more likely falls
    in a *normal distribution* (the familiar bell curve), and the average is a good
    representation of the central value. If the average and median are far apart,
    some outliers might be having an effect or the distribution is skewed, not normal.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the average and median population of US counties as well as the difference
    between them is a two-step process. We need to calculate the average and the median
    and then subtract the two. We can do both operations in one fell swoop with a
    subquery in the `FROM` clause, as shown in [Listing 13-3](#listing13-3).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-3: Subquery as a derived table in a `FROM` clause'
  prefs: []
  type: TYPE_NORMAL
- en: The subquery 1 that produces a derived table is straightforward. We use the
    `avg()` and `percentile_cont()` functions to find the average and median of the
    census table’s `pop_est_2019` column and name each column with an alias. Then
    we name the derived table `calcs` 2 so we can reference it in the main query.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the main query, we subtract the `median` from the `average`, both of which
    are returned by the subquery. The result is rounded and labeled with the alias
    `median_average_diff`. Run the query, and the result should be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The difference between the median and average, 78,742, is nearly three times
    the size of the median. That indicates we have some high-population counties inflating
    the average.
  prefs: []
  type: TYPE_NORMAL
- en: Joining Derived Tables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Joining multiple derived tables lets you perform several preprocessing steps
    before final calculations in a main query. For example, in Chapter 11, we calculated
    the rate of tourism-related businesses per 1,000 population in each county. Let’s
    say we want to do the same at the state level. Before we can calculate that rate,
    we need to know the number of tourism businesses in each state and the population
    of each state. [Listing 13-4](#listing13-4) shows how to write subqueries for
    both tasks and join them to calculate the overall rate.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-4: Joining two derived tables'
  prefs: []
  type: TYPE_NORMAL
- en: You learned how to calculate rates in Chapter 11, so the math and syntax in
    the outer query for finding `estabs_per_thousand` 1 should be familiar. We divide
    the number of establishments by the population and then multiply that quotient
    by a thousand. For the inputs, we use the values generated from two derived tables.
  prefs: []
  type: TYPE_NORMAL
- en: The first 2 finds the number of establishments in each state using the `sum()`
    aggregate function. We give this derived table the alias `est` for reference in
    the main part of the query. The second 3 finds the 2018 estimated population by
    state by using `sum()` on the `pop_est_2018` column. We alias this derived table
    as `census`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we join the derived tables 4 by linking the `st` column in `est` to the
    `state_name` column in `census`. We then list the results in descending order
    based on the rate. Here’s a sample of the 51 rows showing the highest and lowest
    rates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: At the top is Washington, DC, unsurprising given the tourist activity generated
    by the museums, monuments, and other attractions in the nation’s capital. Montana
    may seem like a surprise in second place, but it’s a low-population state with
    major tourist destinations including Glacier and Yellowstone national parks. Mississippi
    and Kentucky are among those states with the fewest tourism-related businesses
    per 1,000 population.
  prefs: []
  type: TYPE_NORMAL
- en: Generating Columns with Subqueries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also place a subquery in the column list after `SELECT` to generate
    a value for that column in the query result. The subquery must generate only a
    single row. For example, the query in [Listing 13-5](#listing13-5) selects the
    geography and population information from `us_counties_pop_est_2019` and then
    adds an uncorrelated subquery to add the median of all counties to each row in
    the new column `us_median`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-5: Adding a subquery to a column list'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first rows of the result set should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: On its own, that repeating `us_median` value isn’t very helpful. It would be
    more interesting and useful to generate values that indicate how much each county’s
    population deviates from the median value. Let’s look at how we can use the same
    subquery technique to do that. [Listing 13-6](#listing13-6) builds on [Listing
    13-5](#listing13-5) by substituting a subquery after `SELECT` that calculates
    the difference between the population and the median for each county.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-6: Using a subquery in a calculation'
  prefs: []
  type: TYPE_NORMAL
- en: The subquery 1 is now part of a calculation that subtracts the subquery’s result
    from `pop_est_2019`, the total population, giving the column an alias of `diff_from_median`.
    To make this query even more useful, we can filter results to show counties whose
    population is close to the median. To do this, we repeat the calculation with
    the subquery in the `WHERE` clause 2 and filter results using the `BETWEEN -1000
    AND 1000` expression.
  prefs: []
  type: TYPE_NORMAL
- en: 'The outcome should reveal 78 counties. Here are the first five rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Bear in mind that subqueries can add to overall query execution time. In [Listing
    13-6](#listing13-6), I removed the subquery from [Listing 13-5](#listing13-5)
    that displays the column `us_median` to avoid repeating the subquery a third time.
    With our data set, the impact is minimal; if we were working with millions of
    rows, winnowing some unneeded subqueries might provide a significant speed boost.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Subquery Expressions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also use subqueries to filter rows by evaluating whether a condition
    evaluates as `true` or `false`. For this, we can use *subquery expressions*, which
    are a combination of a keyword with a subquery and are generally used in `WHERE`
    clauses to filter rows based on the existence of values in another table.
  prefs: []
  type: TYPE_NORMAL
- en: 'The PostgreSQL documentation at [https://www.postgresql.org/docs/current/functions-subquery.html](https://www.postgresql.org/docs/current/functions-subquery.html)
    lists available subquery expressions, but here we’ll examine the syntax for two
    that tend to be used most often: `IN` and `EXISTS`. To prep, run the code in [Listing
    13-7](#listing13-7) to create a small table called `retirees` that we’ll query
    along with the `employees` table you built in Chapter 7. We’ll imagine that we’ve
    received this data from a vendor listing people who’ve applied for retirement
    benefits.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-7: Creating and filling a `retirees` table'
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s use this table in some subquery expressions.
  prefs: []
  type: TYPE_NORMAL
- en: Generating Values for the IN Operator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The subquery expression `IN (``subquery``)` works like the `IN` operator example
    in Chapter 3 except we employ a subquery to provide the list of values to check
    against rather than manually entering one. In [Listing 13-8](#listing13-8), we
    use an uncorrelated subquery, which will be executed one time, to generate `id`
    values from the `retirees` table. The values it returns become the list for the
    `IN` operator in the `WHERE` clause. This lets us find employees who are also
    present in the table of retirees.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-8: Generating values for the `IN` operator'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the query, and the output shows the two people in `employees` whose `emp_id`
    have a matching `id` in the `retirees` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Checking Whether Values Exist
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The subquery expression `EXISTS (``subquery``)` returns a value of `true` if
    the subquery in parentheses returns at least one row. If it returns no rows, `EXISTS`
    evaluates to `false`.
  prefs: []
  type: TYPE_NORMAL
- en: The `EXISTS` subquery expression in [Listing 13-9](#listing13-9) shows an example
    of a correlated subquery—it includes an expression in its `WHERE` clause that
    requires data from the outer query. Also, because the subquery is correlated,
    it will execute once for each row returned by the outer query, each time checking
    whether there’s an `id` in `retirees` that matches `emp_id` in `employees`. If
    there is a match, the `EXISTS` expression returns `true`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-9: Using a correlated subquery with `WHERE EXISTS`'
  prefs: []
  type: TYPE_NORMAL
- en: When you run the code, it should return the same result as it did in [Listing
    13-8](#listing13-8). Using this approach is particularly helpful if you need to
    join on more than one column, which you can’t do with the `IN` expression. You
    also can add the `NOT` keyword with `EXISTS` to perform the opposite function
    and find rows in the employees table with no corresponding record in `retirees`,
    as in [Listing 13-10](#listing13-10).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-10: Using a correlated subquery with `WHERE NOT EXISTS`'
  prefs: []
  type: TYPE_NORMAL
- en: 'That should produce these results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The technique of using `NOT` with `EXISTS` is helpful for finding missing values
    or assessing whether a dataset is complete.
  prefs: []
  type: TYPE_NORMAL
- en: Using Subqueries with LATERAL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Placing the keyword `LATERAL` before subqueries in a `FROM` clause adds several
    bits of functionality that help simplify otherwise complicated queries.
  prefs: []
  type: TYPE_NORMAL
- en: LATERAL with FROM
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: First, a subquery preceded by `LATERAL` can reference tables and other subqueries
    that appear before it in the `FROM` clause, which can reduce redundant code by
    making it easy to reuse calculations.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 13-11](#listing13-11) calculates the change in county population from
    2018 to 2019 two ways: raw change in numbers and percent change.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-11: Using `LATERAL` subqueries in the `FROM` clause'
  prefs: []
  type: TYPE_NORMAL
- en: In the `FROM` clause, after naming the `us_counties_pop_est_2019` table, we
    add the first `LATERAL` subquery 1. In parentheses, we place a query that subtracts
    the 2018 population estimate from the 2019 estimate and alias the result as `raw_chg`.
    Because a `LATERAL` subquery can reference a table listed before it in the `FROM`
    clause without needing to specify its name, we can omit the `us_counties_pop_est_2019`
    table from the subquery. Subqueries in `FROM` must have an alias, so we label
    this one `rc`.
  prefs: []
  type: TYPE_NORMAL
- en: The second `LATERAL` subquery 2 calculates the percent change in population
    from 2018 to 2019\. To find percent change, we must know the raw change. Rather
    than re-calculate it, we can reference the `raw_chg` value from the previous subquery.
    That helps make our code shorter and easier to read.
  prefs: []
  type: TYPE_NORMAL
- en: 'The query results should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: LATERAL with JOIN
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Combining `LATERAL` with `JOIN` creates functionality similar to a *for loop*
    in a programming language: for each row generated by the query in front of the
    `LATERAL` join, a subquery or function after the `LATERAL` join will be evaluated
    once.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll reuse the `teachers` table from Chapter 2 and create a new table to record
    each time a teacher swipes a badge to unlock a lab door. Our task is to find the
    two most recent times a teacher accessed a lab. [Listing 13-12](#listing13-12)
    shows the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-12: Using a subquery with a `LATERAL` join'
  prefs: []
  type: TYPE_NORMAL
- en: First, we add a primary key 1 to the `teachers` table using `ALTER TABLE` (we
    didn’t place a constraint on this table in Chapter 2 because we were just covering
    the basics about creating tables). Next, we make a simple `teachers_lab_access`
    table 2 with columns to record the lab name and access timestamp. The table has
    a surrogate primary key `access_id` and a foreign key `teacher_id` that references
    `id` in `teachers`. Finally, we add six rows to the table using an `INSERT` 3
    statement.
  prefs: []
  type: TYPE_NORMAL
- en: Now we’re ready to query the data. In our `SELECT` statement, we join `teachers`
    to a subquery using `LEFT JOIN`. We add the `LATERAL` 4 keyword, which means for
    each row returned from `teachers`, the subquery will execute, returning the two
    most recent labs accessed by that particular teacher and the times they were accessed.
    Using `LEFT JOIN` will return all rows from `teachers` regardless of whether the
    subquery finds a matching teacher in `teachers_lab_access`.
  prefs: []
  type: TYPE_NORMAL
- en: In the `WHERE` 5 clause, the subquery references the outer query using the foreign
    key of `teacher_lab_access`. This `LATERAL` join syntax requires that the subquery
    have an alias 6, which here is `a`, and the value `true` in the `ON` portion 7
    of the `JOIN` clause. In this case, `true` lets us create the join without naming
    specific columns to join upon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the query, and the results should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The two teachers with IDs in the access table have their two most recent lab
    access times shown. Teachers who didn’t access a lab display `NULL` values; if
    we want to remove those from the results, we could substitute `INNER JOIN` (or
    just `JOIN`) for `LEFT JOIN`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s explore another syntax for working with subqueries.
  prefs: []
  type: TYPE_NORMAL
- en: Using Common Table Expressions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *common table expression* *(CTE)*, a relatively recent addition to standard
    SQL, allows you to use one or more `SELECT` queries to predefine temporary tables
    that you can reference as often as needed in your main query. CTEs are informally
    called `WITH` queries because you define them using a `WITH ... AS` statement.
    The following examples show some advantages of using them, including cleaner code
    and less redundancy.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 13-13](#listing13-13) shows a simple CTE based on our census estimates
    data. The code determines how many counties in each state have 100,000 people
    or more. Let’s walk through the example.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-13: Using a simple CTE to count large counties'
  prefs: []
  type: TYPE_NORMAL
- en: The `WITH ... AS` statement 1 defines the temporary table `large_counties`.
    After `WITH`, we name the table and list its column names in parentheses. Unlike
    column definitions in a `CREATE TABLE` statement, we don’t need to provide data
    types, because the temporary table inherits those from the subquery 2, which is
    enclosed in parentheses after `AS`. The subquery must return the same number of
    columns as defined in the temporary table, but the column names don’t need to
    match. The column list is optional if you’re not renaming columns; I’ve included
    it here so you can see the syntax.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main query 3 counts and groups the rows in `large_counties` by `state_name`
    and then orders by the count in descending order. The top six rows of the results
    should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Texas, Florida, and California are among the states that had the most counties
    with a 2019 population of 100,000 or more.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 13-14](#listing13-14) uses a CTE to rewrite the join of derived tables
    in [Listing 13-4](#listing13-4) (finding the rate of tourism-related businesses
    per 1,000 population in each state) into a more readable format.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-14: Using CTEs in a table join'
  prefs: []
  type: TYPE_NORMAL
- en: Following the `WITH` keyword, we define two tables using subqueries. The first
    subquery, `counties` 1, returns the 2018 population of each state. The second,
    `establishments` 2, returns the number of tourism-related businesses per state.
    With those tables defined, we join them 3 on the `st` column in each table and
    calculate the rate per thousand. The results are identical to the joined derived
    tables in [Listing 13-4](#listing13-4), but [Listing 13-14](#listing13-14) is
    easier to comprehend.
  prefs: []
  type: TYPE_NORMAL
- en: As another example, you can use a CTE to simplify queries that have redundant
    code. For example, in [Listing 13-6](#listing13-6), we used a subquery with the
    `percentile_cont()` function in two locations to find median county population.
    In [Listing 13-15](#listing13-15), we can write that subquery just once as a CTE.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-15: Using CTEs to minimize redundant code'
  prefs: []
  type: TYPE_NORMAL
- en: After the `WITH` keyword, we define `us_median` 1 as the result of the same
    subquery used in [Listing 13-6](#listing13-6), which finds the median population
    using `percentile_cont()`. Then we reference the `us_median_pop` column on its
    own 2, as part of a calculated column 3, and in a `WHERE` clause 5. To make the
    value available to every row in the `us_counties_pop_est_2019` table during `SELECT`,
    we use the `CROSS JOIN` 4 you learned in Chapter 7.
  prefs: []
  type: TYPE_NORMAL
- en: This query provides identical results to those in [Listing 13-6](#listing13-6),
    but we had to write the subquery that finds the median only once. Another bonus
    is that you can more easily revise the query. For example, to find counties whose
    population is close to the 90th percentile, you need to substitute `.9` for `.5`
    as input to `percentile_cont()` in only one place.
  prefs: []
  type: TYPE_NORMAL
- en: Readable code, less redundancy, and easier modifications are often-cited reasons
    for using CTEs. Another, beyond the scope of this book, is the ability to add
    a `RECURSIVE` keyword that lets a CTE loop through query results within the CTE
    itself—a task useful when dealing with data organized in a hierarchy. An example
    is a company’s personnel listing, where you might want to find all the people
    who report to a particular executive. The recursive CTE will start with the executive
    and then loop down through rows finding her direct reports and then the people
    who report to those people. You can learn more about recursive query syntax via
    the PostgreSQL documentation at [https://www.postgresql.org/docs/current/queries-with.html](https://www.postgresql.org/docs/current/queries-with.html).
  prefs: []
  type: TYPE_NORMAL
- en: Performing Cross Tabulations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Cross tabulations* provide a simple way to summarize and compare variables
    by displaying them in a table layout, or matrix. Rows in the matrix represent
    one variable, columns represent another variable, and each cell where a row and
    column intersect holds a value, such as a count or percentage.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll often see cross tabulations, also called *pivot tables* or *crosstabs*,
    used to report summaries of survey results or to compare pairs of variables. A
    frequent example happens during elections when candidates’ votes are tallied by
    geography:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the candidates’ names are one variable, the wards (or city districts)
    are another variable, and the cells at the intersection of the two hold the vote
    totals for that candidate in that ward. Let’s look at how to generate cross tabulations.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the crosstab() Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Standard ANSI SQL doesn’t have a crosstab function, but PostgreSQL does as part
    of a *module* you can install easily. Modules are PostgreSQL extras that aren’t
    part of the core application; they include functions related to security, text
    search, and more. You can find a list of PostgreSQL modules at [https://www.postgresql.org/docs/current/contrib.html](https://www.postgresql.org/docs/current/contrib.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'PostgreSQL’s `crosstab()` function is part of the `tablefunc` module. To install
    `tablefunc`, execute this command in pgAdmin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: PostgreSQL should return the message `CREATE EXTENSION`. (If you’re working
    with another database management system, check its documentation for a similar
    functionality. For example, Microsoft SQL Server has the `PIVOT` command.)
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll create a basic crosstab so you can learn the syntax, and then we’ll
    handle a more complex case.
  prefs: []
  type: TYPE_NORMAL
- en: Tabulating Survey Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s say your company needs a fun employee activity so you coordinate an ice
    cream social at each of your three offices. The trouble is that people are particular
    about ice cream flavors. To choose flavors people will like in each office, you
    decide to conduct a survey.
  prefs: []
  type: TYPE_NORMAL
- en: The CSV file *ice_cream_survey.csv* contains 200 responses to your survey. You
    can download this file, along with all the book’s resources, at [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/).
    Each row includes a `response_id`, `office`, and `flavor`. You’ll need to count
    how many people chose each flavor at each office and share the results in a readable
    way.
  prefs: []
  type: TYPE_NORMAL
- en: In your `analysis` database, use the code in [Listing 13-16](#listing13-16)
    to create a table and load the data. Make sure you change the file path to the
    location on your computer where you saved the CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-16: Creating and filling the `ice_cream_survey` table'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to inspect the data, run the following to view the first five rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The data should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: It looks like chocolate is in the lead! But let’s confirm this choice by using
    the code in [Listing 13-17](#listing13-17) to generate a crosstab.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-17: Generating the ice cream survey crosstab'
  prefs: []
  type: TYPE_NORMAL
- en: The query begins with a `SELECT *` statement that selects everything from the
    contents of the `crosstab()` function 1. We supply two queries as parameters to
    the `crosstab()` function; note that because these queries are parameters, we
    place them inside single quotes. The first query generates the data for the crosstab
    and has three required columns. The first column, `office` 2, supplies the row
    names for the crosstab. The second column, `flavor` 3, supplies the category (or
    column) name to be associated with the value provided in the third column. Those
    values will display in each cell where a row and a column intersect in the table.
    In this case, we want the intersecting cells to show a `count()` 4 of each flavor
    selected at each office. This first query on its own creates a simple aggregated
    list.
  prefs: []
  type: TYPE_NORMAL
- en: The second query parameter 5 produces the category names for the columns. The
    `crosstab()` function requires that the second subquery returns only one column,
    so we use `SELECT` to retrieve `flavor` and `GROUP BY` to return that column’s
    unique values.
  prefs: []
  type: TYPE_NORMAL
- en: Then we specify the names and data types of the crosstab’s output columns following
    the `AS` keyword 6. The list must match the row and column names in the order
    the queries generate them. For example, because the second query that supplies
    the category columns orders the flavors alphabetically, the output column list
    must as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we run the code, our data displays in a clean, readable crosstab:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: It’s easy to see at a glance that the Midtown office favors chocolate but has
    no interest in strawberry, which is represented by a `NULL` value showing that
    strawberry received no votes. But strawberry is the top choice Downtown, and the
    Uptown office is more evenly split among the three flavors.
  prefs: []
  type: TYPE_NORMAL
- en: Tabulating City Temperature Readings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s create another crosstab, but this time we’ll use real data. The *temperature_readings.csv*
    file, also available with all the book’s resources at [https://nostarch.com/practical-sql-2nd-edition/](https://nostarch.com/practical-sql-2nd-edition/),
    contains a year’s worth of daily temperature readings from three observation stations
    around the United States: Chicago, Seattle, and Waikiki, a neighborhood on the
    south shore of the city of Honolulu. The data come from the US National Oceanic
    and Atmospheric Administration (NOAA) at [https://www.ncdc.noaa.gov/cdo-web/datatools/findstation/](https://www.ncdc.noaa.gov/cdo-web/datatools/findstation/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each row in the CSV file contains four values: the station name, the date,
    and the day’s maximum and minimum temperatures. All temperatures are in Fahrenheit.
    For each month in each city, we want to compare climates using the median high
    temperature. [Listing 13-18](#listing13-18) has the code to create the `temperature_readings`
    table and import the CSV file.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-18: Creating and filling a `temperature_readings` table'
  prefs: []
  type: TYPE_NORMAL
- en: The table contains the four columns from the CSV file; we add a natural primary
    key using the station name and observation date. A quick count should return 1,077
    rows. Now, let’s see what cross tabulating the data does using [Listing 13-19](#listing13-19).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-19: Generating the temperature readings crosstab'
  prefs: []
  type: TYPE_NORMAL
- en: The crosstab structure is the same as in [Listing 13-18](#listing13-18). The
    first subquery inside `crosstab()` generates the data for the crosstab, finding
    the median maximum temperature for each month. It supplies three required columns.
    The first, `station_name` 1, names the rows. The second column uses the `date_part()`
    function 2 from Chapter 12 to extract the month from `observation_date`, which
    provides the crosstab columns. Then we use `percentile_cont(.5)` 3 to find the
    50th percentile, or the median, of the `max_temp`. We group by station name and
    month so we have a median `max_temp` for each month at each station.
  prefs: []
  type: TYPE_NORMAL
- en: As in [Listing 13-18](#listing13-18), the second subquery produces the set of
    category names for the columns. I’m using a function called `generate_series()`
    4 in a manner noted in the official PostgreSQL documentation to create a list
    of numbers from 1 to 12 that match the month numbers `date_part()` extracts from
    `observation_date`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following `AS`, we provide the names and data types for the crosstab’s output
    columns. Each is a `numeric` type, matching the output of the percentile function.
    The following output is practically poetry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We’ve transformed a raw set of daily readings into a compact table showing the
    median maximum temperature each month for each station. At a glance, we can see
    that the temperature in Waikiki is consistently balmy, whereas Chicago’s median
    high temperatures vary from just above freezing to downright pleasant. Seattle
    falls between the two.
  prefs: []
  type: TYPE_NORMAL
- en: Crosstabs do take time to set up, but viewing datasets in a matrix often makes
    comparisons easier than viewing the same data in a vertical list. Keep in mind
    that the `crosstab()` function is resource-intensive, so tread carefully when
    querying sets that have millions or billions of rows.
  prefs: []
  type: TYPE_NORMAL
- en: Reclassifying Values with CASE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ANSI Standard SQL `CASE` statement is a *conditional expression*, meaning
    it lets you add some “if this, then . . .” logic to a query. You can use `CASE`
    in multiple ways, but for data analysis, it’s handy for reclassifying values into
    categories. You can create categories based on ranges in your data and classify
    values according to those categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `CASE` syntax follows this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: We give the `CASE` keyword 1 and then provide at least one `WHEN` `condition`
    `THEN` `result` clause, where `condition` is any expression the database can evaluate
    as `true` or `false`, such as `county = 'Dutchess County'` or `date > '1995-08-09'`.
    If the condition is `true`, the `CASE` statement returns the `result` and stops
    checking any further conditions. The result can be any valid data type. If the
    condition is `false`, the database moves on to evaluate the next condition.
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate more conditions, we can add optional `WHEN ... THEN` clauses 2.
    We can also provide an optional `ELSE` clause 3 to return a result in case no
    condition evaluates as `true`. Without an `ELSE` clause, the statement would return
    a `NULL` when no conditions are `true`. The statement finishes with an `END` keyword
    4.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 13-20](#listing13-20) shows how to use the `CASE` statement to reclassify
    the temperature readings into descriptive groups (named according to my own bias
    against cold weather).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-20: Reclassifying temperature data with `CASE`'
  prefs: []
  type: TYPE_NORMAL
- en: We create six ranges for the `max_temp` column in `temperature_readings`, which
    we define using comparison operators. The `CASE` statement evaluates each value
    to find whether any of the six expressions are `true`. If so, the statement outputs
    the appropriate text. Note that the ranges account for all possible values in
    the column, leaving no gaps. If none of the statements is `true`, then the `ELSE`
    clause assigns the value to the category `No reading`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the code; the first five rows of output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Now that we’ve collapsed the dataset into six categories, let’s use those categories
    to compare climate among the three cities in the table.
  prefs: []
  type: TYPE_NORMAL
- en: Using CASE in a Common Table Expression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The operation we performed with `CASE` on the temperature data in the previous
    section is a good example of a preprocessing step you could use in a CTE. Now
    that we’ve grouped the temperatures in categories, let’s count the groups by city
    in a CTE to see how many days of the year fall into each temperature category.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 13-21](#listing13-21) shows the code for reclassifying the daily maximum
    temperatures recast to generate a `temps_collapsed` CTE and then use it for an
    analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 13-21: Using `CASE` in a CTE'
  prefs: []
  type: TYPE_NORMAL
- en: 'This code reclassifies the temperatures and then counts and groups by station
    name to find general climate classifications of each city. The `WITH` keyword
    defines the CTE of `temps_collapsed` 1, which has two columns: `station_name`
    and `max_temperature_group`. We then run a `SELECT` query on the CTE 2, performing
    straightforward `count(*)` and `GROUP BY` operations on both columns. The results
    should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Using this classification scheme, the amazingly consistent Waikiki weather,
    with `Warm` maximum temperatures 361 days of the year, confirms its appeal as
    a vacation destination. From a temperature standpoint, Seattle looks good too,
    with nearly 300 days of `Pleasant` or `Warm` high temps (although this belies
    Seattle’s legendary rainfall). Chicago, with 30 days of `Frigid` max temps and
    8 days `Inhumane`, probably isn’t for me.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you learned to make queries work harder for you. You can now
    add subqueries in multiple locations to provide finer control over filtering or
    preprocessing data before analyzing it in a main query. You also can visualize
    data in a matrix using cross tabulations and reclassify data into groups; both
    techniques give you more ways to find and tell stories using your data. Great
    work!
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the next chapters, we’ll dive into SQL techniques that are more specific
    to PostgreSQL. We’ll begin by working with and searching text and strings.
  prefs: []
  type: TYPE_NORMAL
