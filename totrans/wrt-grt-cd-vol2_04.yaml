- en: '**4**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**4**'
- en: '**COMPILER OPERATION AND CODE GENERATION**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**编译器操作与代码生成**'
- en: '![image](../images/common01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common01.jpg)'
- en: 'In order to write HLL code that produces efficient machine code, you must first
    understand how compilers and linkers translate high-level source statements into
    executable machine code. Complete coverage of compiler theory is beyond the scope
    of this book; however, this chapter explains the basics of the translation process
    so you can understand and work within the limitations of HLL compilers. We’ll
    cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了编写生成高效机器代码的高级语言代码，首先必须理解编译器和链接器如何将高级源语句翻译成可执行的机器代码。完整的编译器理论涵盖超出了本书的范围；然而，本章将解释翻译过程的基础知识，帮助你理解并在高级语言编译器的局限性内工作。我们将涵盖以下主题：
- en: The different types of input files programming languages use
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编程语言使用的不同类型的输入文件
- en: Differences between compilers and interpreters
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器与解释器的区别
- en: How typical compilers process source files to produce executable programs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 典型编译器如何处理源文件以生成可执行程序
- en: The process of optimization and why compilers cannot produce the best possible
    code for a given source file
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化过程以及为什么编译器无法为给定的源文件生成最佳代码
- en: Different types of output files that compilers produce
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器生成的不同类型的输出文件
- en: Common object file formats, such as COFF and ELF
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的目标文件格式，如 COFF 和 ELF
- en: Memory organization and alignment issues that affect the size and efficiency
    of executable files a compiler produces
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 影响编译器生成的可执行文件大小和效率的内存组织和对齐问题
- en: How linker options can affect the efficiency of your code
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链接器选项如何影响代码的效率
- en: This material provides the foundation for all the chapters that follow, and
    is crucial to helping a compiler produce the best possible code. We’ll begin with
    a discussion of file formats used by programming languages.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本材料为后续各章奠定了基础，对于帮助编译器生成最佳代码至关重要。我们将从编程语言使用的文件格式开始讨论。
- en: '**4.1 File Types That Programming Languages Use**'
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**4.1 编程语言使用的文件类型**'
- en: A typical program can take many forms. A *source file* is a human-readable form
    that a programmer creates and supplies to a language translator (such as a compiler).
    A typical compiler translates the source file or files into an *object code* file.
    A *linker program* combines separate object modules to produce a relocatable or
    executable file. Finally, a *loader* (usually the operating system) loads the
    executable file into memory and makes the final modifications to the object code
    prior to execution. Note that the modifications are made to the object code that
    is now in memory; the actual file on the disk does not get modified. These are
    not the only types of files that language processing systems manipulate, but they
    are typical. To fully understand compiler limitations, it’s important to know
    how the language processor deals with each of these file types. We’ll look at
    source files first.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的程序可以有多种形式。*源文件*是程序员创建并提供给语言翻译器（如编译器）的可读文本形式。典型的编译器将源文件或多个源文件翻译成*目标代码*文件。*链接程序*将多个独立的目标模块合并，生成可重定位或可执行文件。最后，*加载程序*（通常是操作系统）将可执行文件加载到内存中，并在执行之前对目标代码进行最终修改。请注意，修改是针对现在在内存中的目标代码进行的；磁盘上的实际文件不会被修改。这些并不是语言处理系统操作的唯一文件类型，但它们是典型的。要充分理解编译器的局限性，了解语言处理器如何处理这些文件类型是非常重要的。我们首先来看源文件。
- en: '**4.2 Source Files**'
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**4.2 源文件**'
- en: Traditionally, source files contain pure ASCII or Unicode text (or some other
    character set) that a programmer has created with a text editor. One advantage
    to using pure text files is that a programmer can manipulate a source file using
    any program that processes text files. For example, a program that counts the
    number of lines in an arbitrary text file will also count the number of source
    lines in a program. Because there are hundreds of little filter programs that
    manipulate text files, maintaining source files in a pure text format is a good
    approach. This format is sometimes called *plain vanilla text*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，源文件包含程序员使用文本编辑器创建的纯 ASCII 或 Unicode 文本（或其他字符集）。使用纯文本文件的一个优点是，程序员可以使用任何处理文本文件的程序来操作源文件。例如，一个计算任意文本文件中行数的程序也会计算程序中的源行数。由于有成百上千个小型过滤程序可以操作文本文件，因此以纯文本格式维护源文件是一种不错的方法。这种格式有时称为*纯原生文本*。
- en: '**4.2.1 Tokenized Source Files**'
  id: totrans-17
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.2.1 标记化源文件**'
- en: Some language processing systems (especially interpreters) maintain their source
    files in a *tokenized* form. Tokenized source files generally use special single-byte
    *token* values to compress reserved words and other lexical elements in the source
    language, and thus they are often smaller than text source files. Furthermore,
    interpreters that operate on tokenized code are generally an order of magnitude
    faster than interpreters that operate on pure text, because processing strings
    of single-byte tokens is far more efficient than recognizing reserved word strings.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一些语言处理系统（尤其是解释器）将源文件以*标记化*形式存储。标记化源文件通常使用特殊的单字节*标记*值来压缩源语言中的保留字和其他词法元素，因此它们通常比文本源文件小。此外，处理标记化代码的解释器通常比处理纯文本的解释器要快一个数量级，因为处理单字节标记的字符串比识别保留字字符串要高效得多。
- en: Generally, the tokenized file from the interpreter consists of a sequence of
    bytes that map directly to strings such as `if` and `print` in the source file.
    So, by using a table of strings and a little extra logic, you can decipher a tokenized
    program to produce the original source code. (Usually, you lose any extra whitespace
    you inserted into the source file, but that’s about the only difference.) Many
    of the original BASIC interpreters found on early PC systems worked this way.
    You’d type a line of BASIC source code into the interpreter, and the interpreter
    would immediately tokenize that line and store the tokenized form in memory. Later,
    when you executed the `LIST` command, the interpreter would *detokenize* the source
    code in memory to produce the listing.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，解释器的标记化文件由一系列字节组成，这些字节直接映射到源文件中的字符串，如`if`和`print`。因此，通过使用一个字符串表和一些额外的逻辑，你可以解码一个标记化的程序，恢复出原始的源代码。（通常，你会失去插入到源文件中的额外空白，但这几乎是唯一的区别。）许多早期PC系统上的BASIC解释器都是这样工作的。你在解释器中输入一行BASIC源代码，解释器会立即将该行进行标记化，并将标记化后的形式存储在内存中。稍后，当你执行`LIST`命令时，解释器会*去标记化*内存中的源代码，生成源代码列表。
- en: On the flip side, tokenized source files often use a proprietary format. This
    means they can’t take advantage of general-purpose text-manipulation tools like
    `wc` (word count), `entab`, and `detab` (which count the number of lines, words,
    and characters in a text file; replace spaces with tabs; and replace tabs with
    spaces, respectively).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，标记化的源文件通常使用专有格式。这意味着它们不能利用像`wc`（单词计数）、`entab`和`detab`（分别用来计算文本文件中的行数、单词数和字符数；用制表符替换空格；用空格替换制表符）这样的通用文本处理工具。
- en: To overcome this limitation, most languages that operate on tokenized files
    enable you to detokenize a source file to produce a standard text file. (They
    also allow you to retokenize a source file, given an input text file.) You then
    run the resulting text file through some filter program, and retokenize the output
    of the filter program to produce a new tokenized source file. Although this takes
    considerable work, it allows language translators that work with tokenized files
    to take advantage of various text-based utility programs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这一限制，大多数使用标记化文件的语言都允许你去标记化源文件，生成标准的文本文件。（它们也允许你根据输入文本文件重新标记化源文件。）然后，你将生成的文本文件通过某个过滤程序处理，并重新标记化过滤程序的输出，以生成一个新的标记化源文件。虽然这需要相当大的工作量，但它允许与标记化文件一起工作的语言翻译器利用各种基于文本的实用程序。
- en: '**4.2.2 Specialized Source Files**'
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.2.2 专用源文件**'
- en: Some programming languages, such as Embarcadero’s Delphi and Free Pascal’s comparable
    Lazarus program, do not use a traditional text-based file format at all. Instead,
    they often use graphical elements like flowcharts and forms to represent the instructions
    the program is to perform. Other examples are the Scratch programming language,
    which allows you to write simple programs using graphical elements on a bitmapped
    display, and the Microsoft Visual Studio and Apple Xcode integrated development
    environments (IDEs), which both allow you to specify a screen layout using graphical
    operations rather than a text-based source file.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一些编程语言，例如Embarcadero的Delphi和Free Pascal的类似Lazarus程序，根本不使用传统的基于文本的文件格式。相反，它们通常使用图形元素，如流程图和表单，来表示程序要执行的指令。其他例子包括Scratch编程语言，它允许你使用位图显示上的图形元素编写简单程序，以及Microsoft
    Visual Studio和Apple Xcode集成开发环境（IDE），这两个IDE都允许你使用图形操作来指定屏幕布局，而不是基于文本的源文件。
- en: '**4.3 Types of Computer Language Processors**'
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**4.3 计算机语言处理器的类型**'
- en: 'Computer language processing systems generally fall into one of four categories:
    pure interpreters, interpreters, compilers, and incremental compilers. These systems
    differ in how they process the source program and execute the result, which affects
    their respective efficiency.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机语言处理系统通常分为四类：纯解释器、解释器、编译器和增量编译器。这些系统在处理源程序和执行结果的方式上有所不同，进而影响它们各自的效率。
- en: '**4.3.1 Pure Interpreters**'
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.3.1 纯解释器**'
- en: '*Pure interpreters* operate directly on a text source file and tend to be very
    inefficient. They continuously scan the source file (usually an ASCII text file),
    processing it as string data. Recognizing *lexemes* (language components such
    as reserved words, literal constants, and the like) consumes time. Indeed, many
    pure interpreters spend more time processing the lexemes (that is, performing
    *lexical analysis*) than they do actually executing the program. Because the actual
    on-the-fly execution of the lexeme takes only a little additional effort beyond
    the lexical analysis, pure interpreters tend to be the smallest of the computer
    language processing programs. For this reason, pure interpreters are popular when
    you need a very compact language processor. They are also popular for scripting
    languages and very high-level languages that let you manipulate the language’s
    source code as string data during program execution.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*纯解释器*直接作用于文本源文件，通常效率非常低。它们不断扫描源文件（通常是ASCII文本文件），将其处理为字符串数据。识别*词素*（如保留字、字面常量等语言成分）是一个耗时的过程。实际上，许多纯解释器花费更多的时间来处理词素（即执行*词法分析*）而不是执行程序。因为词素的实际即时执行只需要比词法分析稍多的努力，纯解释器通常是计算机语言处理程序中最小的。这也是为什么当需要一个非常紧凑的语言处理器时，纯解释器非常流行。它们也广泛用于脚本语言和允许在程序执行期间将语言源代码作为字符串数据操作的高级语言。'
- en: '**4.3.2 Interpreters**'
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.3.2 解释器**'
- en: An *interpreter* executes some representation of a program’s source file at
    runtime. This representation isn’t necessarily a text file in human-readable form.
    As noted in the previous section, many interpreters operate on tokenized source
    files in order to avoid lexical analysis during execution. Some interpreters read
    a text source file as input and translate the input file to a tokenized form prior
    to execution. This allows programmers to work with text files in their favorite
    editor while enjoying the fast execution of a tokenized format. The only costs
    are an initial delay to tokenize the source file (which is unnoticeable on most
    modern machines) and the fact that it may not be possible to execute strings containing
    program statements.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*解释器*在运行时执行程序源文件的某种表示形式。这个表示形式不一定是人类可读的文本文件。如前一节所述，许多解释器处理的是标记化的源文件，以避免在执行过程中进行词法分析。一些解释器会将文本源文件作为输入，并在执行前将输入文件转换为标记化格式。这使得程序员可以在他们喜欢的编辑器中使用文本文件，同时享受标记化格式带来的快速执行。唯一的成本是标记化源文件的初始延迟（在大多数现代机器上这一延迟几乎不被察觉），以及可能无法执行包含程序语句的字符串这一事实。'
- en: '**4.3.3 Compilers**'
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.3.3 编译器**'
- en: A *compiler* translates a source program in text form into executable machine
    code. This is a complex process, particularly in optimizing compilers. There are
    a couple of things to note about the code a compiler produces. First, a compiler
    produces machine instructions that the underlying CPU can execute directly. Therefore,
    the CPU doesn’t waste any cycles decoding the source file while executing the
    program—all of the CPU’s resources are dedicated to executing the machine code.
    Thus, the resulting program generally runs many times faster than an interpreted
    version does. Of course, some compilers do a better job of translating HLL source
    code into machine code than other compilers, but even low-quality compilers do
    a better job than most interpreters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*编译器*将文本形式的源程序转换为可执行的机器代码。这是一个复杂的过程，特别是在优化编译器中。关于编译器生成的代码，有几点需要注意。首先，编译器生成的是底层CPU可以直接执行的机器指令。因此，CPU在执行程序时无需解码源文件，所有的CPU资源都用于执行机器代码。因此，生成的程序通常比解释执行的版本运行得要快得多。当然，一些编译器在将高级语言源代码转换为机器代码时比其他编译器做得更好，但即使是低质量的编译器也比大多数解释器做得要好。'
- en: A compiler’s translation from source code to machine code is a one-way function.
    In contrast to interpreters, it is very difficult, if not impossible, to reconstruct
    the original source file if you’re given only the machine code output from a program.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器从源代码到机器代码的翻译是一个单向函数。与解释器不同，如果只给出程序的机器代码输出，通常很难，甚至不可能，重建原始源文件。
- en: '**4.3.4 Incremental Compilers**'
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.3.4 增量编译器**'
- en: An *incremental compiler* is a cross between a compiler and an interpreter.
    There are many different types of incremental compilers, but in general, they
    operate like an interpreter in that they do not compile the source file directly
    into machine code; instead, they translate the source code into an intermediate
    form. Unlike the tokenized code from interpreters, however, this intermediate
    form usually is not strongly correlated to the original source file. The intermediate
    form is generally the machine code for a *virtual machine language*—“virtual”
    in that there is no real CPU that can execute this code. However, it is easy to
    write an interpreter that can execute it. Because interpreters for virtual machines
    (VMs) are usually much more efficient than interpreters for tokenized code, executing
    VM code is usually much faster than executing a list of tokens in an interpreter.
    Languages like Java use this compilation technique, along with a *Java bytecode
    engine* (an interpreter program), to interpretively execute the Java “machine
    code” (see [Figure 4-1](ch04.xhtml#ch4fig1)). The big advantage to VM execution
    is that the VM code is portable; that is, programs running on the virtual machine
    can execute anywhere an interpreter is available. True machine code, by contrast,
    executes only on the CPU (family) for which it was written. Generally, interpreted
    VM code runs about 2 to 10 times faster than interpreted code (tokenized), and
    pure machine code runs about 2 to 10 times faster than interpreted VM code.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*增量编译器* 是编译器和解释器之间的结合体。增量编译器有许多不同的类型，但通常，它们像解释器一样工作，即不直接将源文件编译成机器代码；而是将源代码翻译成一种中间形式。然而，与解释器的标记化代码不同，这种中间形式通常与原始源文件没有强相关性。中间形式通常是*虚拟机语言*的机器代码——“虚拟”是因为没有实际的
    CPU 可以执行这些代码。然而，编写一个可以执行它的解释器是很容易的。因为虚拟机（VM）的解释器通常比标记化代码的解释器高效得多，所以执行 VM 代码通常比执行解释器中的标记列表要快。像
    Java 这样的语言采用这种编译技术，并结合*Java 字节码引擎*（一种解释程序），来解释执行 Java 的“机器代码”（参见[图 4-1](ch04.xhtml#ch4fig1)）。虚拟机执行的最大优势是
    VM 代码是可移植的；也就是说，运行在虚拟机上的程序可以在任何有解释器的地方执行。相比之下，真正的机器代码只能在为其编写的 CPU（系列）上执行。通常，解释执行的
    VM 代码比解释执行的标记化代码快约 2 到 10 倍，而纯机器代码比解释执行的 VM 代码快约 2 到 10 倍。'
- en: '![Image](../images/04fig01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/04fig01.jpg)'
- en: '*Figure 4-1: The JBC interpreter*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4-1：JBC 解释器*'
- en: In an attempt to improve the performance of programs compiled via an incremental
    compiler, many vendors (particularly Java systems vendors) have turned to a technique
    known as *just-in-time (JIT) compilation*. The concept is based on the fact that
    the time spent in interpretation is largely consumed by fetching and deciphering
    the VM code at runtime. This interpretation occurs repeatedly as the program executes.
    JIT compilation translates the VM code to actual machine code whenever it encounters
    a VM instruction for the first time. This spares the interpreter from repeating
    the interpretation process the next time it encounters the same statement in the
    program (for example, in a loop). Although JIT compilation is nowhere near as
    good as a true compiler, it can typically improve the performance of a program
    by a factor of two to five.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高通过增量编译器编译的程序的性能，许多供应商（特别是 Java 系统供应商）采用了一种称为*即时编译（JIT）*的技术。这个概念基于这样的事实：解释所花费的时间大部分被运行时获取和解码
    VM 代码所消耗。随着程序的执行，这种解释会反复发生。JIT 编译在首次遇到 VM 指令时将其翻译成实际的机器代码。这样可以避免每次遇到相同的语句（例如在循环中）时都重复解释过程。尽管
    JIT 编译远不如真正的编译器，但通常可以将程序的性能提高 2 到 5 倍。
- en: '**NOTE**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Older compilers and some freely available compilers compile the source code
    to assembly language, and then a separate compiler, known as an* assembler, *assembles
    this output to the desired machine code. Most modern and highly efficient compilers
    skip this step altogether. See “Compiler Output” on [page 67](ch04.xhtml#page_67)
    for more on this subject.*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*较旧的编译器和一些免费提供的编译器将源代码编译成汇编语言，然后由另一个被称为*汇编器*的编译器将该输出汇编成所需的机器代码。大多数现代且高效的编译器完全跳过这一步骤。有关此主题的更多信息，请参见
    [第67页](ch04.xhtml#page_67)的“编译器输出”。*'
- en: Of the four categories of computer language processors just described, this
    chapter will focus on compilers. By understanding how a compiler generates machine
    code, you can choose appropriate HLL statements to generate better, more efficient
    machine code. If you want to improve the performance of programs written with
    an interpreter or incremental compiler instead, the best approach is to use an
    optimizing compiler to process your application. For example, GNU provides a compiler
    for Java that produces optimized machine code rather than interpreted Java bytecode
    (JBC); the resulting executable files run much faster than interpreted JBC or
    even JIT-compiled bytecode.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在刚才描述的四种计算机语言处理器类别中，本章将重点讨论编译器。通过理解编译器如何生成机器代码，你可以选择合适的高级语言（HLL）语句来生成更好、更高效的机器代码。如果你想提高用解释器或增量编译器编写的程序的性能，最好的方法是使用优化编译器来处理你的应用程序。例如，GNU
    提供了一个 Java 编译器，它生成优化后的机器代码，而不是解释执行的 Java 字节码（JBC）；生成的可执行文件运行速度比解释执行的 JBC 或 JIT
    编译的字节码快得多。
- en: '**4.4 The Translation Process**'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**4.4 翻译过程**'
- en: A typical compiler is broken down into several logical components called *phases*.
    Although their exact number and names may vary somewhat among different compilers,
    the five most common phases are *lexical analysis*, *syntax analysis*, *intermediate
    code generation*, *native code generation*, and, for compilers that support it,
    *optimization*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的编译器被分解成多个逻辑组件，称为*阶段*。尽管不同编译器之间这些阶段的确切数量和名称可能会有所不同，但最常见的五个阶段是*词法分析*、*语法分析*、*中间代码生成*、*本地代码生成*，以及对于支持优化的编译器，*优化*。
- en: '[Figure 4-2](ch04.xhtml#ch4fig2) shows how the compiler logically arranges
    these phases to translate source code in the HLL into machine (object) code.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-2](ch04.xhtml#ch4fig2) 展示了编译器如何逻辑性地安排这些阶段，将高级语言（HLL）源代码翻译成机器（目标）代码。'
- en: '![Image](../images/04fig02.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/04fig02.jpg)'
- en: '*Figure 4-2: Phases of compilation*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4-2：编译阶段*'
- en: Although [Figure 4-2](ch04.xhtml#ch4fig2) suggests that the compiler executes
    these phases sequentially, most compilers do not. Instead, the phases tend to
    execute in parallel, with each phase doing a small amount of work, passing its
    output to the next phase, and then waiting for input from the previous phase.
    In a typical compiler, the *parser* (the syntax analysis phase) is probably the
    closest thing you’ll find to the main program or the master process. The parser
    usually drives the compilation process in that it calls the *scanner* (lexical
    analysis phase) to obtain input and calls the intermediate code generator to process
    its own output. The intermediate code generator may (optionally) call the optimizer
    and then call the native code generator. The native code generator may (optionally)
    call the optimizer as well. The output from the native code generation phase is
    the executable code. After the native code generator/optimizer emits some code,
    execution returns to the intermediate code generator, then to the parser, which
    requests more input from the scanner, starting the whole process over.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 [图 4-2](ch04.xhtml#ch4fig2) 建议编译器按顺序执行这些阶段，但大多数编译器并非如此。相反，这些阶段通常并行执行，每个阶段完成一小部分工作，将输出传递给下一个阶段，然后等待前一个阶段的输入。在典型的编译器中，*解析器*（语法分析阶段）可能是最接近主程序或主进程的部分。解析器通常主导整个编译过程，它调用*扫描器*（词法分析阶段）获取输入，并调用中间代码生成器处理其输出。中间代码生成器可能（可选）调用优化器，然后调用本地代码生成器。本地代码生成器也可能（可选）调用优化器。来自本地代码生成阶段的输出是可执行代码。在本地代码生成器/优化器生成一些代码后，执行将返回到中间代码生成器，然后到解析器，解析器请求扫描器提供更多输入，整个过程重新开始。
- en: '**NOTE**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Other compiler organizations are possible. Some compilers, for example, allow
    the user to choose whether the compiler runs the optimization phase, while others
    don’t have an optimization phase at all. Similarly, some compilers dispense with
    intermediate code generation and directly call a native code generator. Some compilers
    include additional phases that process object modules compiled at different times.*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*其他编译器的组织形式是可能的。例如，一些编译器允许用户选择是否运行优化阶段，而其他编译器则根本没有优化阶段。类似地，一些编译器省略了中间代码生成，直接调用本地代码生成器。一些编译器还包括其他阶段，处理不同时间编译的目标模块。*'
- en: Thus, although [Figure 4-2](ch04.xhtml#ch4fig2) doesn’t accurately depict the
    typical (parallel) execution path, the *data flow* it shows is correct. The scanner
    reads the source file, translates it to a different form, and then passes this
    translated data on to the parser. The parser accepts its input from the scanner,
    translates that input to a different form, and then passes this new data to the
    intermediate code generator. Similarly, the remaining phases read their input
    from the previous phase, translate the input to a (possibly) different form, and
    then pass that input on to the next phase. The compiler writes the output of its
    last phase to the executable object file.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管[图 4-2](ch04.xhtml#ch4fig2)未能准确描绘典型（并行）执行路径，但它展示的*数据流*是正确的。扫描器读取源文件，将其转换为另一种形式，然后将这些转换后的数据传递给解析器。解析器接受来自扫描器的输入，将其转换为另一种形式，然后将新的数据传递给中间代码生成器。同样，其他阶段也从前一个阶段读取输入，将输入转换为（可能的）不同形式，然后将该输入传递给下一个阶段。编译器将其最后一个阶段的输出写入可执行对象文件。
- en: Let’s take a closer look at each phase of the code translation process.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看一下代码翻译过程的每个阶段。
- en: '**4.4.1 Scanning (Lexical Analysis)**'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.4.1 扫描（词法分析）**'
- en: 'The scanner (aka the *lexical analyzer*, or *lexer*) is responsible for reading
    the character/string data found in the source file and breaking up this data into
    tokens that represent the lexical items, or lexemes, in the source file. As mentioned
    previously, lexemes are the character sequences in the source file that we would
    recognize as atomic components of the language. For example, a scanner for the
    C language would recognize substrings like `if` and `while` as C reserved words.
    The scanner would not, however, pick out the “if ” within the identifier `ifReady`
    and treat it as a reserved word. Instead, the scanner considers the context in
    which a reserved word is used so that it can differentiate between reserved words
    and identifiers. For each lexeme, the scanner creates a small data package—a token—and
    passes it on to the parser. A token typically contains several values:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描器（也叫*词法分析器*或*词法分析器*）负责读取源文件中的字符/字符串数据，并将这些数据分解为表示源文件中词法项或词素的标记。如前所述，词素是我们在源文件中会识别为语言的原子组件的字符序列。例如，C语言的扫描器会将`if`和`while`这样的子字符串识别为C语言保留字。然而，扫描器不会将标识符`ifReady`中的“if”提取出来并视为保留字。相反，扫描器会考虑保留字使用的上下文，以便区分保留字和标识符。对于每个词素，扫描器会创建一个小的数据包——标记——并将其传递给解析器。标记通常包含几个值：
- en: A small integer that uniquely identifies the token’s class (whether it’s a reserved
    word, identifier, integer constant, operator, or character string literal)
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个小整数，用于唯一标识符的类别（无论是保留字、标识符、整数常量、运算符还是字符字符串字面量）
- en: Another value that differentiates the token within a class (for example, this
    value would indicate which reserved word the scanner has processed)
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分同一类别中标记的另一个值（例如，这个值将指示扫描器已经处理的保留字）
- en: Any other attributes the scanner might associate with the lexeme
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扫描器可能与词素关联的任何其他属性
- en: '**NOTE**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Do not confuse this reference to a token with the compressed-style tokens
    in an interpreter discussed previously. In this context, tokens are simply a variable-sized
    data structure that holds information associated with a lexeme for the interpreter/compiler.*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*不要将此对标记的引用与前面讨论的解释器中的压缩式标记混淆。在此上下文中，标记仅仅是一个可变大小的数据结构，包含与词素相关的信息供解释器/编译器使用。*'
- en: When the scanner sees the character string `12345` in the source file, for example,
    it might identify the token’s class as a literal constant, the token’s second
    value as an integer typed constant, and the token’s attribute as the numeric equivalent
    of the string (that is, twelve thousand, three hundred, forty-five). [Figure 4-3](ch04.xhtml#ch4fig3)
    demonstrates what this token might look like in memory.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当扫描器在源文件中看到字符字符串 `12345` 时，例如，它可能将标记的类识别为字面常量，标记的第二个值为整数类型常量，标记的属性为字符串的数字等价物（即一万二千三百四十五）。[图
    4-3](ch04.xhtml#ch4fig3) 演示了这个标记在内存中的表现。
- en: '![Image](../images/04fig03.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/04fig03.jpg)'
- en: '*Figure 4-3: A token for the lexeme "12345"*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4-3：词法单元“12345”的标记*'
- en: The token’s enumerated value is `345` (indicating an integer constant), the
    token class’s value is `5` (indicating a literal constant), the token’s attribute
    value is `12345` (the numeric form of the lexeme), and the lexeme string is `"12345"`
    as returned by the scanner. Different code sequences in the compiler can refer
    to this token data structure as appropriate.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该标记的枚举值为 `345`（表示整数常量），标记类的值为 `5`（表示字面常量），标记的属性值为 `12345`（词法单元的数字形式），词法单元字符串为扫描器返回的
    `"12345"`。编译器中的不同代码序列可以根据需要引用此标记数据结构。
- en: Strictly speaking, the lexical analysis phase is optional. A parser could work
    directly with the source file. However, tokenization makes the compilation process
    more efficient, because it allows the parser to deal with tokens as integer values
    rather than as string data. Because most CPUs can handle small integer values
    much more efficiently than string data, and because the parser has to refer to
    the token data multiple times during processing, lexical analysis saves considerable
    time during compilation. Generally, pure interpreters are the only language processors
    that rescan each token during parsing, and this is one major reason why they are
    so slow (compared to, say, an interpreter that stores the source file in a tokenized
    form to avoid constantly processing a pure-text source file).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 严格来说，词法分析阶段是可选的。语法分析器可以直接处理源文件。然而，标记化使得编译过程更加高效，因为它允许语法分析器将标记视为整数值而不是字符串数据。由于大多数
    CPU 可以比处理字符串数据更高效地处理小的整数值，而且因为语法分析器在处理过程中必须多次引用标记数据，词法分析在编译期间节省了大量时间。通常，纯解释器是唯一在语法分析时重新扫描每个标记的语言处理器，这也是它们速度如此慢的一个主要原因（与例如将源文件以标记化形式存储的解释器相比，以避免不断处理纯文本源文件）。
- en: '**4.4.2 Parsing (Syntax Analysis)**'
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.4.2 语法分析（语法分析）**'
- en: The parser is the part of the compiler that is responsible for checking whether
    the source program is syntactically (and semantically) correct. If there’s an
    error in the source file, it’s usually the parser that discovers and reports it.
    The parser is also responsible for reorganizing the token stream (that is, the
    source code) into a more complex data structure that represents the meaning or
    semantics of the program. The scanner and parser generally process the source
    file in a linear fashion from the beginning to the end of the file, and the compiler
    usually reads the source file only once. Later phases, however, need to refer
    to the body of the source program in a more ad hoc way. By building up a data
    structure representation of the source code (often called an *abstract syntax
    tree*, or *AST*), the parser enables the code generation and optimization phases
    to easily reference different parts of the program.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 语法分析器是编译器的一部分，负责检查源程序在语法（和语义）上的正确性。如果源文件中有错误，通常是语法分析器发现并报告该错误。语法分析器还负责将标记流（即源代码）重新组织成一个更复杂的数据结构，以表示程序的意义或语义。扫描器和语法分析器通常按顺序从源文件的开始到结束处理源文件，编译器通常只读取源文件一次。然而，后续阶段需要以更临时的方式引用源程序的主体。通过构建源代码的数据结构表示（通常称为*抽象语法树*，或*AST*），语法分析器使得代码生成和优化阶段能够轻松地引用程序的不同部分。
- en: '[Figure 4-4](ch04.xhtml#ch4fig4) shows how a compiler might represent the expression
    `12345+6` using three nodes in an AST (`43` is the value for the addition operator
    and `7` is the subclass representing arithmetic operators).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-4](ch04.xhtml#ch4fig4) 显示了编译器如何使用 AST 中的三个节点来表示表达式 `12345+6`（`43` 是加法运算符的值，`7`
    是表示算术运算符的子类）。'
- en: '![Image](../images/04fig04.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/04fig04.jpg)'
- en: '*Figure 4-4: A portion of an abstract syntax tree*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4-4：抽象语法树的一部分*'
- en: '**4.4.3 Intermediate Code Generation**'
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.4.3 中间代码生成**'
- en: The intermediate code generation phase is responsible for translating the AST
    representation of the source file into a quasi–machine code form. There are two
    reasons compilers typically translate a program into an intermediate form rather
    than converting it directly to native machine code.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 中间代码生成阶段负责将源文件的AST表示转换为一种准机器代码形式。编译器通常将程序翻译成中间形式而不是直接转换为本地机器代码，有两个原因。
- en: First, the compiler’s optimization phase can do certain types of optimizations,
    such as common subexpression elimination, much more easily on this intermediate
    form.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，编译器的优化阶段可以在这种中间形式上更轻松地进行某些类型的优化，如公共子表达式消除。
- en: 'Second, many compilers, known as *cross-compilers*, generate executable machine
    code for several different CPUs. By breaking the code generation phase into two
    pieces—the intermediate code generator and the native code generator—the compiler
    writer can move all the CPU-independent activities into the intermediate code
    generation phase and write this code only once. This simplifies the native code
    generation phase. That is, because the compiler needs only one intermediate code
    generation phase but may need separate native code generation phases for each
    CPU the compiler supports, moving as much of the CPU-independent code as possible
    into the intermediate code generator will reduce the size of the native code generators.
    For the same reason, the optimization phase is often broken into two components
    (refer back to [Figure 4-2](ch04.xhtml#ch4fig2)): a CPU-independent component
    (the part following the intermediate code generator) and a CPU-dependent component.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，许多编译器，称为*交叉编译器*，为多种不同的CPU生成可执行的机器代码。通过将代码生成阶段分为两部分——中间代码生成器和本地代码生成器——编译器开发者可以将所有与CPU无关的活动放入中间代码生成阶段，并且只需要编写一次此代码。这简化了本地代码生成阶段。也就是说，由于编译器只需要一个中间代码生成阶段，但可能需要为每个编译器支持的CPU分别进行本地代码生成阶段，将尽可能多的与CPU无关的代码放入中间代码生成器将减少本地代码生成器的体积。出于同样的原因，优化阶段通常也被分为两个部分（参见[图
    4-2](ch04.xhtml#ch4fig2)）：一个与CPU无关的部分（位于中间代码生成器之后）和一个与CPU相关的部分。
- en: Some language systems, such as Microsoft’s VB.NET and C#, actually emit the
    intermediate code as the output of the compiler (in the .NET system, Microsoft
    calls this code *Common Intermediate Language*, or *CIL*). Native code generation
    and optimization are actually handled by the Microsoft *Common Language Runtime
    (CLR)* system, which performs JIT compilation on the CIL code the .NET compilers
    produce.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一些语言系统，如微软的VB.NET和C#，实际上将中间代码作为编译器的输出（在.NET系统中，微软称这种代码为*公共中间语言*，或*CIL*）。本地代码生成和优化实际上是由微软的*公共语言运行时（CLR）*系统处理的，该系统对.NET编译器生成的CIL代码进行即时编译（JIT）。
- en: '**4.4.4 Optimization**'
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.4.4 优化**'
- en: 'The optimization phase, which follows intermediate code generation, translates
    the intermediate code into a more efficient form. This generally involves eliminating
    unnecessary entries from the AST. For example, the compiler’s optimizer might
    transform the following intermediate code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 优化阶段，在中间代码生成之后，将中间代码转换为更高效的形式。这通常涉及从AST中消除不必要的条目。例如，编译器的优化器可能会将以下中间代码转换为：
- en: '[PRE0]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'to something like:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 转换成如下形式：
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If there are no more references to `i` and `j`, the optimizer can eliminate
    all references to them. Indeed, if `k` is never used again, the optimizer can
    replace these two instructions with the single instruction `add 5 to m`. Note
    that this type of transformation is valid on nearly all CPUs. Therefore, this
    type of transformation/optimization is perfect for the first optimization phase.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有更多对`i`和`j`的引用，优化器可以消除对它们的所有引用。事实上，如果`k`再也没有被使用，优化器可以将这两条指令替换为单条指令`add 5
    to m`。请注意，这种类型的转换几乎在所有CPU上都是有效的。因此，这种类型的转换/优化非常适合第一阶段的优化。
- en: '**4.4.4.1 The Problem with Optimization**'
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**4.4.4.1 优化的问题**'
- en: Transforming intermediate code “into a more efficient form” is not a well-defined
    process—what makes one form of a program more efficient than another? The primary
    definition of efficiency is that the program minimizes the use of some system
    resource, usually memory (space) or CPU cycles (speed). A compiler’s optimizer
    could manage other resources, but space and speed are the principal considerations
    for programmers. But even if we consider only these two facets of optimization,
    describing the “optimal” result is difficult. The problem is that optimizing for
    one goal (say, better performance) may create conflicts with another optimization
    goal (such as reduced memory usage). For this reason, the optimization process
    is usually a matter of compromise, where you make trade-offs and sacrifice certain
    subgoals (for example, running certain sections of the code a little slower) in
    order to create a reasonable result (like creating a program that doesn’t consume
    too much memory).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 将中间代码“转换为更高效的形式”不是一个明确的过程——是什么使得某种程序形式比另一种更高效呢？效率的主要定义是程序尽量减少某种系统资源的使用，通常是内存（空间）或CPU周期（速度）。编译器的优化器可能会管理其他资源，但空间和速度是程序员最关心的主要因素。但是，即使我们仅仅考虑这两方面的优化，描述“最优”结果也是困难的。问题在于，优化一个目标（比如更好的性能）可能会与另一个优化目标（比如减少内存使用）发生冲突。因此，优化过程通常是一个妥协的过程，你需要进行权衡，牺牲某些子目标（例如，让某些代码部分运行得稍慢一些），以便生成一个合理的结果（比如生成一个不消耗太多内存的程序）。
- en: '**4.4.4.2 Optimization’s Effect on Compile Time**'
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**4.4.4.2 优化对编译时间的影响**'
- en: You might think that it’s possible to set a single goal (for example, highest
    possible performance) and optimize strictly for that. However, the compiler must
    also be capable of producing an executable result in a reasonable amount of time.
    The optimization process is an example of what complexity theory calls an *NP-complete
    problem*. These are problems that are, as far as we know, intractable; that is,
    you cannot produce a guaranteed correct result (for example, an optimal version
    of a program) without first computing all possibilities and choosing from among
    them. Unfortunately, the time generally required to solve an NP-complete problem
    increases exponentially with the size of the input, which in the case of compiler
    optimization means roughly the number of lines of source code.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能认为可以设定一个单一的目标（例如，最高的性能），并严格地为此进行优化。然而，编译器还必须能够在合理的时间内生成可执行的结果。优化过程是复杂性理论所称的*NP完全问题*的一个例子。这些问题是，至少就目前所知，是无法解决的；也就是说，你不能在不先计算所有可能性并从中选择的情况下，产生一个保证正确的结果（例如，一个程序的最优版本）。不幸的是，解决一个NP完全问题所需的时间通常会随着输入大小的增加呈指数级增长，在编译器优化的情况下，这意味着大致是源代码的行数。
- en: This means that in the worst case, producing a truly optimal program would take
    longer than it was worth. Adding one line of source code could approximately *double*
    the amount of time it takes to compile and optimize the code. Adding two lines
    could *quadruple* the amount of time. In fact, a full guaranteed optimization
    of a modern application could take longer than the known lifetime of the universe.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在最坏的情况下，生成一个真正最优的程序可能需要比它所值的时间还要长。增加一行源代码可能会大约*翻倍*编译和优化代码所需的时间。增加两行可能会*四倍*增加所需的时间。实际上，一个现代应用程序的完整保证优化可能需要的时间，甚至可能超过已知宇宙的生命周期。
- en: For all but the smallest source files (a few dozen lines), a perfect optimizer
    would take far too long to be of any practical value (and such optimizers have
    been written; search online for “superoptimizers” for details). For this reason,
    compiler optimizers rarely produce a truly optimal program. They simply produce
    the best result they can, given the limited amount of CPU time the user is willing
    to allow for the process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 除了最小的源文件（几十行）之外，一个完美的优化器将花费过长的时间，无法在实际应用中发挥任何价值（事实上，这样的优化器已经被编写出来了；可以在线搜索“超优化器”以了解更多细节）。因此，编译器优化器很少能生成一个真正最优的程序。它们只会在用户愿意为该过程分配的有限CPU时间内，生成它们能做到的最佳结果。
- en: '**NOTE**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*Languages that rely on JIT compilation (such as Java, C#, and VB.Net) move
    part of the optimization phase to runtime. Therefore, the optimizer’s performance
    has a direct impact on the application’s runtime. Because the JIT compiler system
    is running concurrently with the application, it cannot spend considerable time
    optimizing the code without having a huge impact on runtime. This is why languages
    such as Java and C#, even when ultimately compiled to low-level machine code,
    rarely perform as well as highly optimized code compiled by traditional languages
    such as C/C++ and Pascal.*'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*依赖即时编译（JIT）的语言（如Java、C#和VB.Net）将部分优化阶段推迟到运行时。因此，优化器的性能直接影响到应用程序的运行时。由于JIT编译器系统与应用程序同时运行，它无法花费大量时间进行代码优化，而不对运行时产生巨大影响。这就是为什么像Java和C#这样的语言，即使最终编译成低级机器代码，也往往无法像传统语言（如C/C++和Pascal）编译的高度优化代码那样表现得更好。*'
- en: Rather than trying all possibilities and choosing the best result, modern optimizers
    use heuristics and case-based algorithms to determine the transformations they
    will apply to the machine code they produce. You need to be aware of these techniques
    so you can write your HLL code in a manner that allows an optimizer to easily
    process it and produce better machine code.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现代优化器不会尝试所有可能性并选择最佳结果，而是使用启发式方法和基于案例的算法来确定它们将应用于所生成机器代码的转换。你需要了解这些技术，这样你才能以一种允许优化器轻松处理并生成更好机器代码的方式编写你的高级语言代码。
- en: '**4.4.4.3 Basic Blocks, Reducible Code, and Optimization**'
  id: totrans-88
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**4.4.4.3 基本块、可化简代码与优化**'
- en: 'Understanding how the compiler organizes the intermediate code (to output better
    machine code in later phases) is very important if you want to be able to help
    the optimizer do its job more efficiently. As control flows through the program,
    the optimizer keeps track of variable values in a process known as *data flow
    analysis (DFA)*. After careful DFA, a compiler can determine where a variable
    is uninitialized, when the variable contains certain values, when the program
    no longer uses the variable, and (just as importantly) when the compiler simply
    doesn’t know anything about the variable’s value. For example, consider the following
    Pascal code:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想更高效地帮助优化器完成工作，理解编译器如何组织中间代码（以便在后续阶段输出更好的机器代码）是非常重要的。随着控制流在程序中流动，优化器通过一种被称为*数据流分析（DFA）*的过程来追踪变量值。在仔细进行数据流分析后，编译器可以确定变量何时未初始化、变量何时包含某些值、程序何时不再使用该变量，以及（同样重要的是）编译器何时根本不知道变量的值。例如，考虑以下Pascal代码：
- en: '[PRE2]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'A good optimizer will replace this code with something like the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的优化器会将这段代码替换为如下内容：
- en: '[PRE3]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In fact, the compiler probably would not generate code for the last two statements;
    instead, it would substitute the value `0` for `i` and `6` for `path` in later
    references. If this seems impressive to you, note that some compilers can even
    track constant assignments and expressions through nested function calls and complex
    expressions.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，编译器可能根本不会为最后两条语句生成代码；相反，它会在后续引用中将`i`替换为值`0`，将`path`替换为值`6`。如果这让你觉得很了不起，请注意，某些编译器甚至可以通过嵌套函数调用和复杂表达式跟踪常量赋值和表达式。
- en: Although a complete description of how a compiler analyzes data flow is beyond
    the scope of this book, you should have a basic understanding of the process,
    because a sloppily written program can thwart the compiler’s optimization abilities.
    Great code works synergistically with the compiler, not against it.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管编译器如何分析数据流的完整描述超出了本书的范围，但你应该对这一过程有基本的理解，因为写得不够规范的程序可能会妨碍编译器的优化能力。优秀的代码与编译器是协同工作的，而不是与之对抗的。
- en: Some compilers can do some truly amazing things when it comes to optimizing
    high-level code. However, optimization is an inherently slow process. As noted
    earlier, it is an intractable problem. Fortunately, most programs don’t require
    full optimization. Even if it runs a little slower than the optimal program, a
    good approximation is an acceptable compromise when compared to intractable compilation
    times.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一些编译器在优化高级代码方面能做出一些非常惊人的事情。然而，优化本身是一个固有的慢过程。正如前面所提到的，这是一个无法解决的问题。幸运的是，大多数程序并不需要完全优化。即使程序运行略慢于最佳程序，当与不可解决的编译时间相比时，一个好的近似是一个可以接受的折中方案。
- en: The major concession to compilation time that compilers make during optimization
    is that they search for only so many possible improvements to a section of code
    before they move on. Therefore, if your programming style confuses the compiler,
    it may not be able to generate an optimal (or even close to optimal) executable
    because it has too many possibilities to consider. The trick, then, is to learn
    how compilers optimize the source file so you can accommodate them.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器在优化过程中对编译时间的主要妥协是，它们仅在一定数量的可能改进之后才会继续处理代码的某个部分。因此，如果你的编程风格让编译器感到困惑，它可能无法生成一个优化的（甚至接近优化的）可执行文件，因为它需要考虑的可能性太多。诀窍是学习编译器如何优化源文件，这样你就能适应它们。
- en: 'To analyze data flow, compilers divide the source code into sequences known
    as *basic blocks*—machine instructions into and out of which there are no branches
    except at the beginning and end. For example, consider the following C code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析数据流，编译器将源代码划分为称为*基本块*的序列——进入和离开基本块的机器指令之间没有分支，除了在开始和结束时。例如，考虑以下C代码：
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This code snippet contains five basic blocks. Basic block 1 starts with the
    beginning of the source code. A basic block ends at the point where there is a
    jump into or out of the sequence of instructions. Basic block 1 ends at the call
    to the `f()` function. Basic block 2 starts with the statement following the call
    to the `f()` function, then ends at the beginning of the `if` statement because
    the `if` can transfer control to either of two locations. The `else` clause terminates
    basic block 3\. It also marks the beginning of basic block 4 because there is
    a jump (from the `if`’s `then` clause) to the first statement following the `else`
    clause. Basic block 4 ends not because the code transfers control somewhere else,
    but because there is a jump from basic block 2 to the first statement that begins
    basic block 5 (from the `if`’s `then` section). Basic block 5 ends with a call
    to the C `printf()` function.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码包含五个基本块。基本块1从源代码的开始处开始。一个基本块在存在跳转进入或离开指令序列的地方结束。基本块1在调用`f()`函数时结束。基本块2从调用`f()`函数后的语句开始，然后在`if`语句的开头结束，因为`if`语句可以将控制转移到两个不同的地方。`else`子句终止了基本块3，并且标志着基本块4的开始，因为从`if`的`then`子句存在一个跳转到`else`子句后面第一个语句。基本块4的结束不是因为代码将控制转移到别处，而是因为从基本块2到基本块5开始的第一条语句有一个跳转（来自`if`的`then`部分）。基本块5在调用C语言的`printf()`函数时结束。
- en: The easiest way to determine where the basic blocks begin and end is to consider
    the assembly code that the compiler will generate. Wherever there is a conditional
    branch/jump, unconditional jump, or call instruction, a basic block will end.
    Note, however, that the basic block includes the instruction that transfers control
    to a new location. A new basic block begins immediately after the instruction
    that transfers control to a new location. Also note that the target label of any
    conditional branch, unconditional jump, or call instruction begins a basic block.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 确定基本块开始和结束位置的最简单方法是考虑编译器将生成的汇编代码。每当出现条件分支/跳转、无条件跳转或调用指令时，一个基本块就会结束。然而，请注意，基本块包括转移控制到新位置的指令。新的基本块将在转移控制到新位置的指令后立即开始。还需要注意的是，任何条件分支、无条件跳转或调用指令的目标标签开始一个基本块。
- en: Basic blocks make it easy for the compiler to track what’s happening to variables
    and other program objects. As the compiler processes each statement, it can (symbolically)
    track the values that a variable will hold based upon their initial values and
    the computations on them within the basic block.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 基本块使得编译器能够轻松跟踪变量和其他程序对象的变化。当编译器处理每条语句时，它可以（象征性地）跟踪一个变量将持有的值，这些值是基于其初始值以及在基本块内的计算得出的。
- en: A problem occurs when the paths from two basic blocks join into a single code
    stream. For example, at the end of basic block 3 in the current example, the compiler
    could easily determine that the variable `j` contains zero because code in the
    basic block assigns the value `0` to `j` and then makes no other assignments to
    `j`. Similarly, at the end of basic block 3, the program knows that `j` contains
    the value `j0 + x0` (assuming `j0` represents the initial value of `j` upon entry
    into the basic block and `x0` represents the initial value of `x` upon entry into
    the block). But when the paths merge at the beginning of basic block 4, the compiler
    probably can’t determine whether `j` will contain zero or the value `j0 + x0`.
    This means the compiler has to note that `j`’s value could be either of two different
    values at this point.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个基本块的路径汇聚成一个单一的代码流时，会出现问题。例如，在当前示例中的基本块3的末尾，编译器可以轻松确定变量`j`的值为零，因为基本块中的代码将`0`赋值给`j`，并且之后没有对`j`进行其他赋值。同样，在基本块3的末尾，程序知道`j`的值为`j0
    + x0`（假设`j0`表示`j`进入基本块时的初始值，`x0`表示`x`进入基本块时的初始值）。但是，当路径在基本块4的开始汇合时，编译器可能无法确定`j`的值是零还是`j0
    + x0`。这意味着编译器必须注意到此时`j`的值可能是两个不同的值之一。
- en: While keeping track of two possible values that a variable might contain at
    a given point is easy for a decent optimizer, it’s not hard to imagine a situation
    where the compiler would have to keep track of many different possible values.
    In fact, if you have several `if` statements that the code executes sequentially,
    and each path through these `if` statements modifies a given variable, then the
    number of possible values for each variable doubles with each `if` statement.
    In other words, the number of possibilities increases exponentially with the number
    of `if` statements in a code sequence. At some point, the compiler cannot keep
    track of all the possible values a variable might contain, so it has to stop monitoring
    that information for the given variable. When this happens, there are fewer optimization
    possibilities that the compiler can consider.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然追踪一个变量在给定点可能包含的两个值对一个合适的优化器来说不算困难，但不难想象，编译器需要追踪许多不同可能值的情况。事实上，如果你有几个`if`语句代码按顺序执行，并且每个路径都修改了某个变量的值，那么每个变量的可能值数量会随着每个`if`语句的增加而翻倍。换句话说，随着代码序列中`if`语句的增多，可能性数目呈指数增长。到某个时候，编译器无法跟踪一个变量可能包含的所有值，因此必须停止对该变量的信息监控。发生这种情况时，编译器能考虑的优化可能性就会减少。
- en: Fortunately, although loops, conditional statements, `switch/case` statements,
    and procedure/function calls can increase the number of possible paths through
    the code exponentially, in practice compilers have few problems with typical well-written
    programs. This is because as paths from basic blocks converge, programs often
    make new assignments to their variables (thereby eliminating the old values the
    compiler was tracking). Compilers generally assume that programs rarely assign
    a different value to a variable along every distinct path in the program, and
    their internal data structures reflect this. Keep in mind that if you violate
    this assumption, the compiler may lose track of variable values and generate inferior
    code as a result.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，尽管循环、条件语句、`switch/case`语句和过程/函数调用可能会使代码的路径数呈指数级增长，但实际上编译器在处理典型的良好编写的程序时很少遇到问题。这是因为随着基本块路径的汇合，程序通常会对其变量进行新的赋值（从而消除编译器所追踪的旧值）。编译器通常假设程序在每个不同的路径上不会为变量赋予不同的值，并且它们的内部数据结构反映了这一点。请记住，如果违反了这个假设，编译器可能会失去对变量值的跟踪，从而生成较差的代码。
- en: Poorly structured programs can create control flow paths that confuse the compiler,
    reducing the opportunities for optimization. Good programs produce *reducible
    flow graphs*, pictorial depictions of the control flow path. [Figure 4-5](ch04.xhtml#ch4fig5)
    is a flow graph for the previous code fragment.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 结构不良的程序会产生控制流路径，使编译器感到困惑，从而减少优化的机会。良好的程序会生成*可简化的控制流图*，即控制流路径的图示。[图4-5](ch04.xhtml#ch4fig5)是之前代码片段的控制流图。
- en: '![Image](../images/04fig05.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/04fig05.jpg)'
- en: '*Figure 4-5: An example flow graph*'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4-5：一个示例控制流图*'
- en: 'As you can see, arrows connect the end of each basic block with the beginning
    of the basic block into which they transfer control. In this particular example,
    all of the arrows flow downward, but this isn’t always the case. Loops, for example,
    transfer control backward in the flow graph. As another example, consider the
    following Pascal code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，箭头将每个基本块的结尾与它们控制流转移的下一个基本块的开头连接起来。在这个特定的例子中，所有的箭头都指向下方，但并非总是如此。例如，循环会在流图中将控制转移回头。再举个例子，考虑以下
    Pascal 代码：
- en: '[PRE5]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[Figure 4-6](ch04.xhtml#ch4fig6) shows the flow graph for this simple code
    fragment.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-6](ch04.xhtml#ch4fig6)展示了这个简单代码片段的流图。'
- en: '![Image](../images/04fig06.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/04fig06.jpg)'
- en: '*Figure 4-6: Flow graph for a while loop*'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4-6：while 循环的流图*'
- en: As mentioned, flow graphs in well-structured programs are *reducible*. Although
    a complete description of what constitutes a reducible flow graph is beyond the
    scope of this book, any program that consists only of structured control statements
    (`if`, `while`, `repeat..until`, and so on) and avoids `goto` statements will
    be reducible. This is an important point because compiler optimizers generally
    do a much better job when working on reducible programs. In contrast, programs
    that are not reducible tend to confuse them.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，结构良好的程序中的流图是*可简化的*。尽管完整描述可简化流图的定义超出了本书的范围，但任何只包含结构化控制语句（如`if`、`while`、`repeat..until`等）并避免使用`goto`语句的程序都将是可简化的。这是一个重要的点，因为编译器优化器通常在处理可简化程序时表现更好。相比之下，无法简化的程序往往会使它们感到困惑。
- en: What makes reducible programs easier for optimizers to deal with is that their
    basic blocks can be collapsed in an outline fashion, with enclosing blocks inheriting
    properties (for example, which variables the block modifies) from the enclosed
    blocks. By processing the source file this way, the optimizer can deal with a
    small number of basic blocks rather than a large number of statements. This hierarchical
    approach to optimization is more efficient and allows the optimizer to maintain
    more information about the program’s state. Furthermore, the exponential time
    complexity of the optimization problem works for us in this case. By reducing
    the number of blocks the code has to deal with, you dramatically decrease the
    amount of work the optimizer must do. Again, the exact details of how the compiler
    achieves this are not important here. The takeaway is that making your programs
    reducible enables the optimizer to do its job more effectively. Attempts to “optimize”
    your code by sticking in lots of `goto` statements—to avoid duplicating code and
    executing unnecessary tests—may actually work against you. While you may save
    a few bytes or a few cycles in the immediate area you’re working on, the end result
    might confuse the compiler enough that it cannot optimize as well, causing an
    overall loss of efficiency.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使优化器更容易处理可简化程序的是，它们的基本块可以以大纲的方式进行合并，封闭的基本块将继承一些属性（例如，修改了哪些变量）。通过这种方式处理源文件，优化器可以处理较少的基本块，而不是大量的语句。这种层次化的优化方法更加高效，并且使优化器能够保持关于程序状态的更多信息。此外，优化问题的指数时间复杂度在此情况下对我们有利。通过减少代码需要处理的块数量，显著减少了优化器需要做的工作。再次强调，编译器如何实现这一点的具体细节在此并不重要。关键是，使程序可简化能够让优化器更有效地完成其工作。试图通过加入大量`goto`语句来“优化”代码——以避免重复代码和执行不必要的测试——实际上可能适得其反。虽然你可能在当前工作区域节省了一些字节或周期，但最终结果可能会让编译器迷惑，从而无法有效优化，导致整体效率下降。
- en: '**4.4.4.4 Common Compiler Optimizations**'
  id: totrans-115
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**4.4.4.4 常见的编译器优化**'
- en: '[Chapter 12](ch12.xhtml#ch12) will provide complete definitions and examples
    of common compiler optimizations in programming contexts where compilers typically
    use them. But for now, here’s a quick preview of the basic types:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[第12章](ch12.xhtml#ch12)将提供常见编译器优化的完整定义和示例，适用于编译器通常使用这些优化的编程环境。但现在，先简要预览一下基本类型：'
- en: '**Constant folding**'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**常量折叠**'
- en: Constant folding computes the value of constant expressions or subexpressions
    at compile time rather than at runtime. See “Constant Folding” on [page 397](ch12.xhtml#page_397)
    for more information.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 常量折叠在编译时计算常量表达式或子表达式的值，而不是在运行时计算。有关更多信息，请参见[第397页](ch12.xhtml#page_397)的“常量折叠”。
- en: '**Constant propagation**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**常量传播**'
- en: Constant propagation replaces a variable with a constant value if the compiler
    determines that the program assigned that constant to the variable earlier in
    the code. See “Constant Propagation” on [page 400](ch12.xhtml#page_400) for more
    information.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 常量传播将一个变量替换为常量值，如果编译器确定程序在代码的早期已经将常量赋值给该变量。更多信息请参见[第400页](ch12.xhtml#page_400)的“常量传播”。
- en: '**Dead code elimination**'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**死代码消除**'
- en: Dead code elimination removes the object code associated with a particular source
    code statement when the program will never use the result of that statement, or
    when a conditional block will never be `true`. See “Dead Code Elimination” on
    [page 404](ch12.xhtml#page_404) for more information.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 死代码消除移除与特定源代码语句相关的目标代码，当程序永远不会使用该语句的结果，或者当条件块永远不会为`true`时。更多信息请参见[第404页](ch12.xhtml#page_404)的“死代码消除”。
- en: '**Common subexpression elimination**'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**公共子表达式消除**'
- en: Frequently, part of an expression will appear elsewhere in the current function;
    this is known as a *subexpression*. If the values of the variables in a subexpression
    haven’t changed, the program does not need to recompute them everywhere the subexpression
    appears. The program can simply save the subexpression’s value on the first evaluation
    and then use it for every other occurrence of the subexpression. See “Common Subexpression
    Elimination” on [page 410](ch12.xhtml#page_410) for more information.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，一个表达式的部分会在当前函数的其他地方出现；这称为*子表达式*。如果子表达式中变量的值没有变化，程序就不需要在子表达式出现的每个地方重新计算它们。程序可以简单地在第一次计算时保存子表达式的值，然后在子表达式的每个其他出现处使用它。更多信息请参见[第410页](ch12.xhtml#page_410)的“公共子表达式消除”。
- en: '**Strength reduction**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**强度缩减**'
- en: Often, the CPU can directly compute a value using a different operator than
    the source code specifies. For example, a `shift` instruction can implement multiplication
    or division by a constant that is a power of 2, and a bitwise `and` instruction
    can compute certain modulo (remainder) operations (the `shift` and `and` instructions
    generally execute much faster than the multiply and divide instructions). Most
    compiler optimizers are good at recognizing such operations and replacing the
    more expensive computation with a less expensive sequence of machine instructions.
    See “Strength Reduction” on [page 417](ch12.xhtml#page_417) for more information.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，CPU可以使用与源代码指定的不同操作符直接计算一个值。例如，`shift`指令可以实现乘法或除法，乘除的常数是2的幂，而按位`and`指令可以计算某些模（余数）运算（`shift`和`and`指令通常比乘法和除法指令执行得更快）。大多数编译器优化器善于识别这种操作，并将成本较高的计算替换为一系列成本较低的机器指令。更多信息请参见[第417页](ch12.xhtml#page_417)的“强度缩减”。
- en: '**Induction**'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**归纳**'
- en: In many expressions, particularly those appearing within a loop, the value of
    one variable in the expression is completely dependent upon some other variable.
    Frequently, the compiler can eliminate the computation of the new value or merge
    the two computations into one for the duration of that loop. See “Induction” on
    [page 422](ch12.xhtml#page_422) for more information.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多表达式中，特别是在循环中出现的表达式，某个变量的值完全依赖于其他变量。通常，编译器可以消除新值的计算，或者在该循环期间将两次计算合并为一次。更多信息请参见[第422页](ch12.xhtml#page_422)的“归纳”。
- en: '**Loop invariants**'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**循环不变式**'
- en: The optimizations so far have all been techniques a compiler can use to improve
    code that is already well written. Handling loop invariants, by contrast, is a
    compiler optimization for fixing bad code. A *loop invariant* is an expression
    that does not change on each iteration of some loop. An optimizer can compute
    the result of such a calculation just once, outside the loop, and then use the
    computed value within the loop’s body. Many optimizers are smart enough to discover
    loop invariant calculations and can use *code motion* to move the invariant calculation
    outside the loop. See “Loop Invariants” on [page 427](ch12.xhtml#page_427) for
    more information.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 目前为止的优化方法都是编译器用来改进已经编写得较好的代码的技术。与此相比，处理循环不变式是一种用于修复糟糕代码的编译器优化。*循环不变式*是指在某个循环的每次迭代中都不会变化的表达式。优化器可以在循环外部仅计算一次该计算的结果，然后在循环体内使用计算出的值。许多优化器足够聪明，可以发现循环不变式的计算，并使用*代码移动*将不变式计算移到循环外部。更多信息请参见[第427页](ch12.xhtml#page_427)的“循环不变式”。
- en: Good compilers can perform many other optimizations, but these are the standard
    optimizations that any decent compiler should be able to do.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 优秀的编译器可以执行许多其他优化，但这些是任何一个合格编译器都应该能够做的标准优化。
- en: '**4.4.4.5 Compiler Optimization Control**'
  id: totrans-132
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**4.4.4.5 编译器优化控制**'
- en: By default, most compilers do very little or no optimization unless you explicitly
    tell them to. This might seem counterintuitive; after all, we generally want compilers
    to produce the best possible code for us. However, there are many definitions
    of “optimal,” and no single compiler output is going to satisfy every possible
    one.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，大多数编译器不会做太多或任何优化，除非你明确告诉它们。这可能看起来有些反直觉；毕竟，我们通常希望编译器为我们生成最好的代码。然而，“最优”有很多种定义，没有任何一种编译器输出能满足所有可能的需求。
- en: 'You might argue that some sort of optimization, even if it’s not the particular
    type you’re interested in, is better than none at all. However, there are a few
    reasons why no optimization is a compiler’s default state:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会争辩说，某种优化，即使它不是你感兴趣的那种，至少比没有优化要好。然而，有一些原因解释了为什么没有优化是编译器的默认状态：
- en: Optimization is a slow process. You get quicker turnaround times on compiles
    when you have the optimizer turned off. This can be a big help during rapid edit-compile-test
    cycles.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化是一个缓慢的过程。当你关闭优化时，编译的周转时间会更快。这在快速编辑-编译-测试循环中非常有帮助。
- en: Many debuggers don’t work properly with optimized code, and you have to turn
    off optimization in order to use a debugger on your application (this also makes
    analyzing the compiler output much easier).
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多调试器在优化后的代码中无法正常工作，因此你需要关闭优化才能在应用程序中使用调试器（这也使得分析编译器输出更加容易）。
- en: Most compiler defects occur in the optimizer. By emitting unoptimized code,
    you’re less likely to encounter defects in the compiler (then again, the compiler’s
    author is less likely to be notified about defects in the compiler, too).
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数编译器缺陷发生在优化器中。通过生成未优化的代码，你更不容易遇到编译器缺陷（不过，编译器的作者也更不容易收到有关编译器缺陷的反馈）。
- en: Most compilers provide command-line options that let you control the types of
    optimization the compiler performs. Early C compilers under Unix used command-line
    arguments like `-O`, `-O1`, and `-O2`. Many later compilers (C and otherwise)
    have adopted this strategy, if not exactly the same command-line options.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数编译器提供命令行选项，让你控制编译器执行的优化类型。早期的Unix C编译器使用了像`-O`、`-O1`和`-O2`这样的命令行参数。许多后来的编译器（包括C编译器及其他语言编译器）也采用了这一策略，尽管它们的命令行选项可能不完全相同。
- en: If you’re wondering why a compiler might offer multiple options to control optimization
    rather than just a single option (optimization or no optimization), remember that
    “optimal” means different things to different people. Some people might want code
    that is optimized for space; others might want code that is optimized for speed
    (and those two optimizations could be mutually exclusive in a given situation).
    Some people might want to optimize their files but don’t want the compiler to
    take forever to process them, so they’d be willing to compromise with a small
    set of fast optimizations. Others might want to control optimization for a specific
    member of a CPU family (such as the Core i9 processor in the 80x86 family). Furthermore,
    some optimizations are “safe” (that is, they always produce correct code) only
    if the program is written in a certain way. You certainly don’t want to enable
    such optimizations unless the programmer guarantees that they’ve written their
    code accordingly. Finally, for programmers who are writing their HLL code carefully,
    some optimizations the compiler performs may actually produce *inferior* code,
    in which case the ability to specify optimizations is very handy. For these reasons
    and more, most modern compilers provide considerable flexibility over the types
    of optimizations they perform.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在想为什么编译器会提供多个选项来控制优化，而不仅仅是一个选项（优化与否），请记住，“最优”对不同的人有不同的定义。有些人可能希望代码在空间上得到优化；而其他人可能更关注代码的速度优化（在某些情况下，这两种优化可能是互斥的）。有些人可能希望优化他们的文件，但又不希望编译器花费过多时间来处理它们，因此他们愿意通过一组小而快速的优化来妥协。其他人可能希望针对特定的CPU系列（例如80x86系列中的Core
    i9处理器）控制优化。此外，某些优化只有在程序以特定方式编写时才是“安全”的（即，它们总是生成正确的代码）。你肯定不希望启用这些优化，除非程序员保证他们已经按照要求编写了代码。最后，对于那些精心编写HLL代码的程序员来说，编译器执行的某些优化实际上可能会生成*较差*的代码，在这种情况下，能够指定优化就非常有用。基于这些原因以及更多原因，大多数现代编译器在执行优化时提供了相当大的灵活性。
- en: 'Consider the Microsoft Visual C++ compiler. It provides the following command-line
    options to control optimization:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: GCC has a comparable—though much longer—list, which you can view by specifying
    `-v --help` on the GCC command line. Most of the individual optimization flags
    begin with `-f`. You can also use `-On`, where n is a single digit integer value,
    to specify different levels of optimization. Take care when using `-O3` (or higher),
    as doing so may perform some unsafe optimizations in certain cases.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '**4.4.5 Compiler Benchmarking**'
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One real-world constraint on our ability to produce great code is that different
    compilers provide a wildly varying set of optimizations. Even the same optimizations
    performed by two different compilers can differ greatly in effectiveness.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, several websites have benchmarked various compilers. (One good
    example is Willus.com.) Simply search online for a topic like “compiler benchmarks”
    or “compiler comparisons” and have fun.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '**4.4.6 Native Code Generation**'
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The native code generation phase is responsible for translating the intermediate
    code into machine code for the target CPU. An 80x86 native code generator, for
    example, might translate the intermediate code sequence given previously into
    something like the following:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The second optimization phase, which takes place after native code generation,
    handles machine idiosyncrasies that don’t exist on all machines. For example,
    an optimizer for a Pentium II processor might replace an instruction of the form
    `add(1, eax);` with the instruction `inc(eax);`. Optimizers for later CPUs might
    do just the opposite. Optimizers for certain 80x86 processors might arrange the
    sequence of instructions one way to maximize parallel execution of the instructions
    in a superscalar CPU, while an optimizer targeting a different (80x86) CPU might
    arrange the instructions differently.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '**4.5 Compiler Output**'
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The previous section stated that compilers typically produce machine code as
    their output. Strictly speaking, this is neither necessary nor even that common.
    Most compiler output is not code that a given CPU can directly execute. Some compilers
    emit assembly language source code, which requires further processing by an assembler
    prior to execution. Other compilers produce an object file, which is similar to
    executable code but is not directly executable. Still other compilers actually
    produce source code output that requires further processing by a different HLL
    compiler. I’ll discuss these different output formats and their advantages and
    disadvantages in this section.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '**4.5.1 Emitting HLL Code as Compiler Output**'
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Some compilers actually emit output that is source code for a different high-level
    programming language (see [Figure 4-7](ch04.xhtml#ch4fig7)). For example, many
    compilers (including the original C++ compiler) emit C code as their output. Indeed,
    compiler writers who emit some high-level source code from their compiler frequently
    choose the C programming language.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Emitting HLL code as compiler output offers several advantages. The output is
    human-readable and generally easy to verify. The HLL code emitted is often portable
    across various platforms; for example, if a compiler emits C code, you can usually
    compile that output on several different machines because C compilers exist for
    most platforms. Finally, by emitting HLL code, a translator can rely on the optimizer
    of the target language’s compiler, thereby saving the effort of writing its own
    optimizer. In other words, emitting HLL code allows a compiler writer to create
    a less complex code generator module and rely on the robustness of some other
    compiler for the most complex part of the compilation process.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 HLL 代码作为编译器输出有几个优点。输出是人类可读的，通常容易验证。输出的 HLL 代码通常可以跨多个平台移植；例如，如果编译器输出 C 代码，你通常可以在不同的机器上编译该输出，因为大多数平台都有
    C 编译器。最后，通过输出 HLL 代码，翻译器可以依赖目标语言编译器的优化器，从而节省编写自己优化器的工作。换句话说，输出 HLL 代码使得编译器开发者可以创建一个较简单的代码生成模块，并依赖其他编译器的强大功能来处理编译过程中的最复杂部分。
- en: '![Image](../images/04fig07.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/04fig07.jpg)'
- en: '*Figure 4-7: Emission of HLL code by a compiler*'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4-7：编译器输出 HLL 代码*'
- en: Emitting HLL code has several disadvantages, too. First and foremost, this approach
    usually takes more processing time than directly generating executable code. To
    produce an executable file, a second, otherwise unnecessary, compiler might be
    needed. Worse, the output of that second compiler might need to be processed further
    by another compiler or assembler, exacerbating the problem. Another disadvantage
    is that in HLL code it’s difficult to embed debugging information that a debugger
    program can use. Perhaps the most fundamental problem with this approach, however,
    is that HLLs are usually an abstraction of the underlying machine. Therefore,
    it could be quite difficult for a compiler to emit statements in an HLL that efficiently
    map to low-level machine code.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 HLL 代码也有几个缺点。首先，这种方法通常比直接生成可执行代码需要更多的处理时间。为了生成可执行文件，可能需要一个第二个、本不必要的编译器。更糟糕的是，这个第二个编译器的输出可能需要通过另一个编译器或汇编器进一步处理，问题因此更加严重。另一个缺点是，在
    HLL 代码中很难嵌入调试信息，供调试程序使用。然而，这种方法的最根本问题是，HLL 通常是对底层机器的抽象。因此，编译器在 HLL 中生成与低级机器代码高效对应的语句可能相当困难。
- en: Generally, compilers that emit HLL statements as their output are translating
    a *very high-level language (VHLL)* into a lower-level language. For example,
    C is often considered to be a fairly low-level HLL, which is one reason why it’s
    a popular output format for many compilers. Projects that have attempted to create
    a special, portable, low-level language specifically for this purpose have never
    been enormously popular. Check out any of the “C- -” projects on the internet
    for examples of such systems.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，输出 HLL 语句作为编译器输出的编译器是将*非常高级语言（VHLL）*转换为较低级语言。例如，C 通常被认为是相对较低级的 HLL，这也是它成为许多编译器流行输出格式的原因之一。尝试创建专门用于此目的的特殊便携式低级语言的项目从未获得过广泛的流行。你可以查看互联网中的任何“C--”项目，了解这类系统的示例。
- en: If you want to write efficient code by analyzing compiler output, you’ll probably
    find it more difficult to work with compilers that output HLL code. With a standard
    compiler, all you have to learn is the particular machine code statements that
    your compiler produces. However, when a compiler emits HLL statements as its output,
    learning to write great code with that compiler is more difficult. You need to
    understand both how the main language emits the HLL statements and how the second
    compiler translates the code into machine code.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想通过分析编译器输出编写高效的代码，你可能会发现处理输出 HLL 代码的编译器更为困难。使用标准编译器，你只需要学习编译器生成的特定机器代码语句。然而，当编译器输出
    HLL 语句时，学习如何用该编译器编写优秀的代码就变得更加困难。你需要理解主语言如何生成 HLL 语句，以及第二个编译器如何将代码转换为机器代码。
- en: Generally, compilers that produce HLL code as their output are either experimental
    compilers for VHLLs, or compilers that attempt to translate legacy code in an
    older language to a more modern language (for example, FORTRAN to C). As a result,
    expecting those compilers to emit efficient code is generally asking too much.
    Thus, you’d probably be wise to avoid a compiler that emits HLL statements. A
    compiler that directly generates machine code (or assembly language code) is more
    likely to produce smaller and faster-running executables.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '**4.5.2 Emitting Assembly Language as Compiler Output**'
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Many compilers will emit human-readable assembly language source files rather
    than binary machine code files (see [Figure 4-8](ch04.xhtml#ch4fig8)). Probably
    the most famous example is the FSF/GNU GCC compiler suite, which emits assembly
    language output for the FSF/GNU assembler Gas. Like compilers that emit HLL source
    code, emitting assembly language has some advantages and disadvantages.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig08.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-8: Emission of assembly code by a compiler*'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: The principal disadvantages to emitting assembly code are similar to the downsides
    of emitting HLL source output. First, you have to run a second language translator
    (namely the assembler) to produce the actual object code for execution. Second,
    some assemblers may not allow the embedding of debugging metadata that allows
    a debugger to work with the original source code (though many assemblers do support
    this capability). These two disadvantages turn out to be minimal if a compiler
    emits code for an appropriate assembler. For example, Gas is very fast and supports
    the insertion of debug information for use by source-level debuggers. Therefore,
    the FSF/GNU compilers don’t suffer as a result of emitting Gas output.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of assembly language output, particularly for our purposes, is
    that it’s easy to read the compiler’s output and determine which machine instructions
    the compiler emits. Indeed, this book uses this compiler facility to analyze compiler
    output. Emitting assembly code frees the compiler writer from having to worry
    about several different object code output formats—the underlying assembler handles
    that—which allows the compiler writer to create a more portable compiler. True,
    the assembler has to be capable of generating code for different operating systems,
    but you only need to repeat this exercise once for each object file format, rather
    than once for each format multiplied by the number of compilers you write. The
    FSF/GNU compiler suite has taken good advantage of the Unix philosophy of using
    small tools that chain together to accomplish larger, more complicated tasks—that
    is, minimize redundancy.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of compilers that can emit assembly language output is that
    they generally allow you to embed *inline assembly language* statements in the
    HLL code. This lets you insert a few machine instructions directly into time-critical
    sections of your code without the hassle of having to create a separate assembly
    language program and link its output to your HLL program.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 能够输出汇编语言的编译器的另一个优点是，它们通常允许你在高级语言代码中嵌入*内联汇编语言*语句。这样，你可以将一些机器指令直接插入到代码中对时间要求严格的部分，而不需要麻烦地创建一个单独的汇编语言程序并将其输出与高级语言程序链接。
- en: '**4.5.3 Emitting Object Files as Compiler Output**'
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.5.3 作为编译器输出生成目标文件**'
- en: Most compilers translate the source language into an object file format, an
    intermediate file format that contains machine instructions and binary runtime
    data along with certain metadata. This metadata allows a linker/loader program
    to combine various object modules to produce a complete executable. This in turn
    allows programmers to link *library modules* and other object modules that they’ve
    written and compiled separately from their main application module.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数编译器将源语言翻译成目标文件格式，这是一种包含机器指令和二进制运行时数据以及某些元数据的中间文件格式。这些元数据允许链接器/加载程序将不同的目标模块组合在一起，生成一个完整的可执行文件。这使得程序员能够链接*库模块*和他们自己编写并单独编译的其他目标模块与主应用程序模块。
- en: The advantage of object file output is that you don’t need a separate compiler
    or assembler to convert the compiler’s output to object code form, which saves
    a little time during compilation. Note, however, that a linker program must still
    process the object file output, which consumes a little time after compilation.
    Nevertheless, linkers are generally quite fast, so it’s usually more cost-effective
    to compile a single module and link it with several previously compiled modules
    than it is to compile all the modules together to form an executable file.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 输出目标文件的优点是，你不需要单独的编译器或汇编器将编译器的输出转换为目标代码格式，这在编译过程中节省了一些时间。然而，需要注意的是，链接器程序仍然必须处理目标文件输出，这会在编译后消耗一些时间。尽管如此，链接器通常非常快速，因此将单个模块编译并与多个之前编译的模块链接在一起，通常比将所有模块一起编译生成可执行文件更具成本效益。
- en: Object modules are binary files and do not contain human-readable data, so it’s
    a bit more difficult to analyze compiler output in this format than in the others
    we’ve discussed. Fortunately, there are utility programs that will disassemble
    the output of an object module into a human-readable form. The result isn’t as
    easy to read as straight assembly compiler output, but you can still do a reasonably
    good job.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 目标模块是二进制文件，不包含可供人类阅读的数据，因此分析这种格式的编译器输出比我们讨论的其他格式更困难。幸运的是，有一些实用程序可以将目标模块的输出反汇编成易于人类阅读的形式。虽然结果不如直接的汇编编译器输出那样容易读取，但你仍然可以进行合理的分析。
- en: Because object files are challenging to analyze, many compiler writers provide
    an option to emit assembly code instead of object code. This handy feature makes
    analysis much easier, so we’ll use it with various compilers throughout this book.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 由于目标文件难以分析，许多编译器作者提供了一个选项，允许输出汇编代码而不是目标代码。这个实用功能使分析变得更加容易，因此我们将在本书中使用它与各种编译器一起工作。
- en: '**NOTE**'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*The section “Object File Formats” on [page 71](ch04.xhtml#page_71) provides
    a detailed look at the elements of an object file, focusing on COFF (Common Object
    File Format).*'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*“目标文件格式”部分在[第71页](ch04.xhtml#page_71)详细介绍了目标文件的元素，重点讲解了COFF（通用目标文件格式）。*'
- en: '**4.5.4 Emitting Executable Files as Compiler Output**'
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**4.5.4 作为编译器输出生成可执行文件**'
- en: Some compilers directly emit an executable output file. These compilers are
    often very fast, producing almost instantaneous turnaround during the edit-compile-run-test-debug
    cycle. Unfortunately, their output is often the most difficult to read and analyze,
    requiring the use of a debugger or disassembler program and a lot of manual work.
    Nevertheless, the fast turnaround makes these compilers popular, so later in this
    book, we’ll look at how to analyze the executable files they produce.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一些编译器直接输出可执行文件。这些编译器通常非常快速，在编辑-编译-运行-测试-调试循环中几乎能即时完成。不过，遗憾的是，它们的输出通常是最难以阅读和分析的，需要使用调试器或反汇编程序，并且需要大量的手动工作。尽管如此，快速的编译周期使得这些编译器非常受欢迎，因此在本书后面，我们将探讨如何分析它们生成的可执行文件。
- en: '**4.6 Object File Formats**'
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**4.6 目标文件格式**'
- en: 'As previously noted, object files are among the most popular forms of compiler
    output. Even though it is possible to create a proprietary object file format—one
    that only a single compiler and its associated tools can use—most compilers emit
    code using one or more standardized object file formats. This allows different
    compilers to share the same set of object file utilities, including linkers, librarians,
    dump utilities, and disassemblers. Examples of common object file formats include:
    OMF (Object Module Format), COFF (Common Object File Format), PE/COFF (Microsoft’s
    Portable Executable variant on COFF), and ELF (Executable and Linkable Format).
    There are several variants of these file formats, as well as many altogether different
    object file formats.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Most programmers understand that object files represent the machine code that
    an application executes, but they often don’t realize the impact of the object
    file’s organization on their application’s performance and size. Although you
    don’t need to have detailed knowledge of an object file’s internal representation
    to write great code, having a basic understanding will help you organize your
    source files to better take advantage of the way compilers and assemblers generate
    code for your applications.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: An object file usually begins with a header that comprises the first few bytes
    of the file. This header contains certain *signature information* that identifies
    the file as a valid object file, along with several other values that define the
    location of various data structures in the file. Beyond the header, an object
    file is usually divided into several sections, each containing application data,
    machine instructions, symbol table entries, relocation data, and other metadata
    (data about the program). In some cases, the actual code and data represent only
    a small part of the entire object code file.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: To get a feeling for how object files are structured, it’s worthwhile to look
    at a specific object file format in detail. I’ll use COFF in the following discussion
    because most object file formats (for example, ELF and PE/COFF) are based on,
    or very similar to, COFF. The basic layout of a COFF file is shown in [Figure
    4-9](ch04.xhtml#ch4fig9), after which I’ll describe each section in turn.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig09.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-9: Layout of a COFF file*'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '**4.6.1 The COFF File Header**'
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'At the beginning of every COFF file is a *COFF file header*. Here are the definitions
    that Microsoft Windows and Linux use for the COFF header structure:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The Linux *coff.h* header file uses traditional Unix names for these fields;
    the Microsoft *winnt.h* header file uses (arguably) more readable names. Here’s
    a summary of each field in the header, with Unix names to the left of the slash
    and Microsoft equivalents to the right:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: f_magic/Machine
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Identifies the system for which this COFF file was created. In the original
    Unix definition, this value identified the particular Unix port for which the
    code was created. Today’s operating systems define this value somewhat differently,
    but the bottom line is that this value is a signature that specifies whether the
    COFF file contains data or machine instructions that are appropriate for the current
    operating system and CPU.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 4-1](ch04.xhtml#ch4tab1) provides the encodings for the `f_magic/Machine`
    field.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 4-1:** `f_magic/Machine` Field Encoding'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '| **Value** | **Description** |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
- en: '| 0x14c | Intel 386 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
- en: '| 0x8664 | x86-64 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
- en: '| 0x162 | MIPS R3000 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
- en: '| 0x168 | MIPS R10000 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
- en: '| 0x169 | MIPS little endian WCI v2 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
- en: '| 0x183 | old Alpha AXP |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
- en: '| 0x184 | Alpha AXP |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
- en: '| 0x1a2 | Hitachi SH3 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
- en: '| 0x1a3 | Hitachi SH3 DSP |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
- en: '| 0x1a6 | Hitachi SH4 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
- en: '| 0x1a8 | Hitachi SH5 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
- en: '| 0x1c0 | ARM little endian |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
- en: '| 0x1c2 | Thumb |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
- en: '| 0x1c4 | ARMv7 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
- en: '| 0x1d3 | Matsushita AM33 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
- en: '| 0x1f0 | PowerPC little endian |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
- en: '| 0x1f1 | PowerPC with floating-point support |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
- en: '| 0x200 | Intel IA64 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
- en: '| 0x266 | MIPS16 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
- en: '| 0x268 | Motorola 68000 series |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
- en: '| 0x284 | Alpha AXP 64-bit |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
- en: '| 0x366 | MIPS with FPU |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
- en: '| 0x466 | MIPS16 with FPU |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
- en: '| 0xebc | EFI bytecode |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
- en: '| 0x8664 | AMD AMD64 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
- en: '| 0x9041 | Mitsubishi M32R little endian |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
- en: '| 0xaa64 | ARM64 little endian |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
- en: '| 0xc0ee | CLR pure MSIL |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
- en: f_nscns/NumberOfSections
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Specifies how many segments (sections) are present in the COFF file. A linker
    program can iterate through a set of section headers (described a little later)
    using this value.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: f_timdat/TimeDateStamp
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Contains a Unix-style timestamp (number of seconds since January 1, 1970) value
    specifying the file’s creation date and time.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: f_symptr/PointerToSymbolTable
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Contains a file offset value (that is, the number of bytes from the beginning
    of the file) that specifies where the *symbol table* begins in the file. The symbol
    table is a data structure that specifies the names and other information about
    all external, global, and other symbols used by the code in the COFF file. Linkers
    use the symbol table to resolve external references. This symbol table information
    may also appear in the final executable file for use by a symbolic debugger.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: f_nsyms/NumberOfSymbols
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: The number of entries in the symbol table.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: f_opthdr/SizeOfOptionalHeader
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the size of the optional header that immediately follows the file
    header (that is, the first byte of the optional header immediately follows the
    `f_flags/Characteristics` field in the file header structure). A linker or other
    object code manipulation program would use the value in this field to determine
    where the optional header ends and the section headers begin in the file. The
    section headers immediately follow the optional header, but the optional header’s
    size isn’t fixed. Different implementations of a COFF file can have different
    optional header structures. If the optional header is not present in a COFF file,
    the `f_opthdr/SizeOfOptionalHeader` field will contain zero, and the first section
    header will immediately follow the file header.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: f_flags/Characteristics
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: A small bitmap that specifies certain Boolean flags, such as whether the file
    is executable, whether it contains symbol information, and whether it contains
    line number information (for use by debuggers).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '**4.6.2 The COFF Optional Header**'
  id: totrans-233
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The COFF optional header contains information pertinent to executable files.
    This header may not be present if the file contains object code that is not executable
    (because of unresolved references). Note, however, that this optional header is
    always present in Linux COFF and Microsoft PE/COFF files, even when the file is
    not executable. The Windows and Linux structures for this optional file header
    take the following forms in C.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The first thing to notice is that these structures are not identical. The Microsoft
    version has considerably more information than the Linux version. The `f_opthdr/SizeOfOptionalHeader`
    field exists in the file header to determine the actual size of the optional header.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: magic/Magic
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Provides yet another signature value for the COFF file. This signature value
    identifies the file type (that is, COFF) rather than the system under which it
    was created. Linkers use the value of this field to determine if they are truly
    operating on a COFF file (instead of some arbitrary file that would confuse the
    linker).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: vstamp/MajorLinkerVersion/MinorLinkerVersion
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the version number of the COFF format so that a linker written for
    an older version of the file format won’t try to process files intended for newer
    linkers.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: tsize/SizeOfCode
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Attempts to specify the size of the code section found in the file. If the COFF
    file contains more than one code section, the value of this field is undefined,
    although it usually specifies the size of the first code/text section in the COFF
    file.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: dsize/SizeOfInitializedData
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the size of the data segment appearing in this COFF file. Once again,
    this field is undefined if there are two or more data sections in the file. Usually,
    this field specifies the size of the first data section if there are multiple
    data sections.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: bsize/SizeOfUninitializedData
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the size of the *block started by symbol (BSS)* section—the uninitialized
    data section—in the COFF file. As for the text and data sections, this field is
    undefined if there are two or more BSS sections; in such cases this field usually
    specifies the size of the first BSS section in the file.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '*See “Pages, Segments, and File Size” on [page 81](ch04.xhtml#page_81) for
    more on BSS sections.*'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: entry/AddressOfEntryPoint
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Contains the starting address of the executable program. Like other pointers
    in the COFF file header, this field is actually an offset into the file; it is
    not an actual memory address.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: text_start/BaseOfCode
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: Specifies a file offset into the COFF file where the code section begins. If
    there are two or more code sections, this field is undefined, but it generally
    specifies the offset to the first code section in the COFF file.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: data_start/BaseOfData
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Specifies a file offset into the COFF file where the data section begins. If
    there are two or more data sections, this field is undefined, but it generally
    specifies the offset to the first data section in the COFF file.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: There is no need for a `bss_start/StartOfUninitializedData` field. The COFF
    file format assumes that the operating system’s program loader will automatically
    allocate storage for a BSS section when the program loads into memory. There is
    no need to consume space in the COFF file for uninitialized data (however, “Executable
    File Formats” on [page 80](ch04.xhtml#page_80) describes how some compilers actually
    merge BSS and DATA sections together for performance reasons).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: The optional file header structure is actually a throwback to the *a.out* format,
    an older object file format used in Unix systems. This is why it doesn’t handle
    multiple text/code and data sections, even though COFF allows them.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: The remaining fields in the Windows variant of the optional header hold values
    that Windows linkers allow programmers to specify. While their purposes will likely
    be clear to anyone who has manually run Microsoft’s linker from a command line,
    those are not important here. What is important is that COFF does not require
    a specific data structure for the optional header. Different implementations of
    COFF (such as Microsoft’s) may freely extend the definition of the optional header.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '**4.6.3 COFF Section Headers**'
  id: totrans-258
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The section headers follow the optional header in a COFF file. Unlike the file
    and optional headers, a COFF file may contain multiple section headers. The `f_nscns/NumberOfSections`
    field in the file header specifies the exact number of section headers (and, therefore,
    sections) found in the COFF file. Keep in mind that the first section header does
    not begin at a fixed offset in the file. Because the optional header’s size is
    variable (and, in fact, could even be 0 if it isn’t present), you have to add
    the `f_opthdr/SizeOfOptionalHeader` field in the file header to the size of the
    file header to get the starting offset of the first section header. Section headers
    are a fixed size, so once you have the address of the first section header you
    can easily compute the address of any other by multiplying the desired section
    header number by the section header size and adding the result to the base offset
    of the first section header.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the C struct definitions for Windows and Linux section headers:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you inspect these two structures closely, you’ll find that they are roughly
    equivalent (the only structural difference is that Windows overloads the physical
    address field, which in Linux is always equivalent to the `VirtualAddress` field,
    to hold a `VirtualSize` field).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a summary of each field:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: s_name/Name
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the name of the section. As is apparent in the Linux definition, this
    field is limited to eight characters and, accordingly, section names will be a
    maximum of eight characters long. (Usually, if a source file specifies a longer
    name, the compiler/assembler will truncate it to 8 characters when creating the
    COFF file.) If the section name is exactly eight characters long, those eight
    characters will consume all 8 bytes of this field and there will be no zero-terminating
    byte. If the section name is shorter than eight characters, a zero-terminating
    byte will follow the name. The value of this field is often something like `.text`,
    `CODE`, `.data`, or `DATA`. Note, however, that the name does not define the segment’s
    type. You could create a code/text section and name it `DATA`; you could also
    create a data section and name it `.text` or `CODE`. The `s_flags/Characteristics`
    field determines the actual type of this section.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: s_paddr/PhysicalAddress/VirtualSize
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Not used by most tools. Under Unix-like operating systems (such as Linux), this
    field is usually set to the same value as the `VirtualAddress` field. Different
    Windows tools set this field to different values (including zero); the linker/loader
    seems to ignore whatever value appears here.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: s_vaddr/VirtualAddress
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the section’s loading address in memory (that is, its virtual memory
    address). Note that this is a runtime memory address, not an offset into the file.
    The program loader uses this value to determine where to load the section into
    memory.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: s_size/SizeOfRawData
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the size, in bytes, of the section.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: s_scnptr/PointerToRawData
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: Provides the file offset to the start of the section’s data in the COFF file.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: s_relptr/PointerToRelocations
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Provides a file offset to the relocation list for this particular section.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: s_lnnoptr/PointerToLinenumbers
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: Contains a file offset to the line number records for the current section.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: s_nreloc/NumberOfRelocations
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the number of *relocation entries* found at that file offset. Relocation
    entries are small structures that provide file offsets to address data in the
    section’s data area that must be patched when the file is loaded into memory.
    We won’t discuss these relocation entries in this book, but if you’re interested
    in more details, see the references at the end of this chapter.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: s_nlnno/NumberOfLinenumbers
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Specifies how many line number records can be found at that offset. Line number
    information is used by debuggers and is beyond the scope of this chapter. Again,
    see the references at the end of this chapter if you’re interested in more information
    about the line number entries.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: s_flags/Characteristics
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: A bitmap that specifies the characteristics of this section. In particular,
    this field will tell you whether the section requires relocation, whether it contains
    code, whether it is read-only, and so on.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '**4.6.4 COFF Sections**'
  id: totrans-284
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The section headers provide a directory that describes the actual data and code
    found in the object file. The `s_scnptr/PointerToRawData` field contains a file
    offset to where the raw binary data or code is sitting in the file, and the `s_size/SizeOfRawData`
    field specifies the length of the section’s data. Due to relocation requirements,
    the data actually appearing in the section block may not be an exact representation
    of the data that the operating system loads into memory. This is because many
    instruction operand addresses and pointer values appearing in the section may
    need to be *patched* to relocate the file based on where the OS loads it into
    memory. The relocation list (which is separate from the section’s data) contains
    offsets into the section where the OS must patch the relocatable addresses. The
    OS performs this patching when loading the section’s data from disk.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Although the bytes in a COFF section may not be an exact representation of the
    data in memory at runtime, the COFF format requires that all of the bytes in the
    section *map* to the corresponding address in memory. This allows the loader to
    copy the section’s data directly from the file into sequential memory locations.
    The relocation operation never inserts or deletes bytes in a section; it only
    changes the values of certain bytes in the section. This requirement helps simplify
    the system loader and improves application performance because the operating system
    doesn’t have to move large blocks of memory around when loading the application
    into memory. The drawback to this scheme is that the COFF format misses the opportunity
    to compress redundant data appearing in the section’s data area. The COFF designers
    felt it was more important to emphasize performance over space in their design.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '**4.6.5 The Relocation Section**'
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The relocation section in the COFF file contains the offsets to the pointers
    in the COFF sections that must be relocated when the system loads those sections’
    code or data into memory.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '**4.6.6 Debugging and Symbolic Information**'
  id: totrans-289
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The last three sections shown in [Figure 4-9](ch04.xhtml#ch4fig9) contain information
    that debuggers and linkers use. One section contains line number information that
    a debugger uses to correlate lines of source code with the executable machine
    code instructions. The symbol table and string table sections hold the public
    and external symbols for the COFF file. Linkers use this information to resolve
    external references between object modules; debuggers use this information to
    display symbolic variable and function names during debugging.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '*This book doesn’t provide a complete description of the COFF file format,
    but you’ll definitely want to dig deeper into it and other object code formats
    (ELF, MACH-O, OMF, and so on) if you’re interested in writing applications such
    as assemblers, compilers, and linkers. To study this area further, see the references
    at the end of this chapter.*'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '**4.7 Executable File Formats**'
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most operating systems use a special file format for executable files. Often,
    the executable file format is similar to the object file format, the principal
    difference being that there are usually no unresolved external references in the
    executable file.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: In addition to machine code and binary data, executable files contain other
    metadata, including debugging information, linkage information for dynamically
    linked libraries, and details about how the operating system should load different
    sections of the file into memory. Depending on the CPU and OS, the executable
    files may also contain relocation information so that the OS can patch absolute
    addresses when it loads the file into memory. Object code files contain the same
    information, so it’s no surprise that the executable file formats used by many
    operating systems are similar to their object file formats.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: The Executable and Linkable Format (ELF), employed by Linux, QNX, and other
    Unix-like operating systems, is very typical of a combined object file format
    and executable format. Indeed, the name of the format suggests its dual nature.
    As another example, Microsoft’s PE file format is a straightforward variant of
    the COFF format. The similarity between the object and executable file formats
    allows the OS designer to share code between the loader (responsible for executing
    the program) and linker applications. Given this similarity, there’s little reason
    to discuss the specific data structures found in an executable file, as doing
    so would largely repeat the information from the previous sections.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: However, there’s one very practical difference in the layout of these two types
    of files worth mentioning. Object files are usually designed to be as small as
    possible, while executable files are usually designed to load into memory as fast
    as possible, even if this means that they’re larger than absolutely necessary.
    It may seem paradoxical that a larger file could load into memory faster than
    a smaller file; however, the OS might load only a small part of the executable
    file into memory at one time if it supports virtual memory. As we’ll discuss next,
    a well-designed executable file format can take advantage of this fact by laying
    out the data and machine instructions in the file to reduce virtual memory overhead.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '**4.7.1 Pages, Segments, and File Size**'
  id: totrans-298
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Virtual memory subsystems and memory protection schemes generally operate on
    *pages* in memory. A page on a typical processor is usually between 1KB and 64KB
    in size. Whatever the size, a page is the smallest unit of memory to which you
    can apply discrete protection features (such as whether the data in that page
    is read-only, read/write, or executable). In particular, you cannot mix read-only/executable
    code with read/write data in the same page—the two must appear in separate pages
    in memory. Using the 80x86 CPU family as an example, pages in memory are 4KB each.
    Therefore, the minimum amount of code space and the minimum amount of data space
    we can allocate to a process is 8KB if we have read/write data and we want to
    place the machine instructions in read-only memory. In fact, most programs contain
    several segments or sections (as you saw previously with object files) to which
    we can apply individual protection rights, and each section will require a unique
    set of one or more pages in memory that are not shared with any of the other sections.
    A typical program has four or more sections in memory: code or text, static data,
    uninitialized data, and stack are the most common. In addition, many compilers
    also generate heap segments, linkage segments, read-only segments, constant data
    segments, and application-named data segments (see [Figure 4-10](ch04.xhtml#ch4fig10)).'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig10.jpg)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-10: Typical segments found in memory*'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Because operating systems map segments to pages, a segment will always require
    some number of bytes that is a multiple of the page size. For example, if a program
    has a segment that contains only a single byte of data, that segment will still
    consume 4,096 bytes on an 80x86 processor. Similarly, if an 80x86 application
    consists of six different segments, that application will consume at least 24KB
    in memory, regardless of the number of machine instructions and data bytes the
    program uses and regardless of the executable file’s size.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Many executable file formats (such as ELF and PE/COFF) provide an option in
    memory for a BSS section where a programmer can place uninitialized static variables.
    Because the values are uninitialized, there is no need to clutter the executable
    file with random data values for each of these variables. Therefore, the BSS section
    in some executable file formats is just a small stub that tells the OS loader
    the size of the BSS section. This way, you can add new uninitialized static variables
    to your application without affecting the executable file’s size. When you increase
    the amount of BSS data, the compiler simply adjusts a value to tell the loader
    how many bytes to reserve for the uninitialized variables. Were you to add those
    same variables to an initialized data section, the size of the executable file
    would grow with each byte of data that you added. Obviously, saving space on your
    mass storage device is a good thing to do, so using BSS sections to reduce your
    executable file sizes is a useful optimization.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: The one thing that many people tend to forget, however, is that a BSS section
    still requires main memory at runtime. Even though the executable file size may
    be smaller, each byte of data you declare in your program translates to 1 byte
    of data in memory. Some programmers have the mistaken impression that the executable’s
    file size is indicative of the amount of memory that the program consumes. This,
    however, isn’t necessarily true, as our BSS example shows. A given application’s
    executable file might consist of only 600 bytes, but if that program uses four
    different sections, with each section consuming a 4KB page in memory, the program
    will require 16,384 bytes of memory when the OS loads it into memory. This is
    because the underlying memory protection hardware requires the OS to allocate
    whole pages of memory to a given process.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '**4.7.2 Internal Fragmentation**'
  id: totrans-305
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another reason an executable file might be smaller than an application’s *execution
    memory footprint* (the amount of memory the application consumes at runtime) is
    *internal fragmentation*. Internal fragmentation occurs when you must allocate
    sections of memory in fixed-sized chunks even though you might need only a portion
    of each chunk (see [Figure 4-11](ch04.xhtml#ch4fig11)).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig11.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-11: Internal fragmentation*'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Remember that each section in memory consumes an integral number of pages, even
    if that section’s data size is not a multiple of the page size. All bytes from
    the last data/code byte in a section to the end of the page holding that byte
    are wasted; this is internal fragmentation. Some executable file formats allow
    you to pack each section without padding it to some multiple of the page size.
    However, as you’ll soon see, there may be a performance penalty for packing sections
    together in this fashion, so some executable formats don’t do it.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Finally, don’t forget that an executable file’s size does not include any data
    (including data objects on the heap and values placed on the CPU’s stack) allocated
    dynamically at runtime. As you can see, an application can actually consume much
    more memory than the executable file’s size.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Programmers commonly compete to see who can write the smallest “Hello World”
    program using their favorite language. Assembly language programmers are especially
    guilty of bragging about how much smaller they can write this program in assembly
    than they can in C or some other HLL. This is a fun mental challenge, but whether
    the program’s executable file is 600 or 16,000 bytes long, the chances are pretty
    good that the program will consume exactly the same amount of memory at runtime
    once the operating system allocates four or five pages for the program’s different
    sections. While writing the world’s shortest “Hello World” application might win
    bragging rights, in real-world terms such an application saves almost nothing
    at runtime due to internal fragmentation.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '**4.7.3 Reasons to Optimize for Space**'
  id: totrans-312
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This is not to suggest that optimizing for space isn’t worthwhile. Programmers
    who write great code consider all the machine resources their application uses,
    and they avoid wasting those resources. However, attempting to take this process
    to an extreme is a waste of effort. Once you’ve gotten a given section below 4,096
    bytes (on an 80x86 or other CPU with a 4KB page size), additional optimizations
    save you nothing. Remember, the *allocation granularity*—that is, the minimum
    allocation block size—is 4,096 bytes. If you have a section with 4,097 bytes of
    data, it’s going to consume 8,192 bytes at runtime. In that case, it would behoove
    you to reduce that section by 1 byte (thereby saving 4,096 bytes at runtime).
    However, if you have a data section that consumes 16,380 bytes, attempting to
    reduce its size by 4,092 bytes in order to reduce the file size is going to be
    difficult unless the data organization was very bad to begin with.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Note that most operating systems allocate disk space in clusters (or blocks)
    that are often comparable to (or even larger than) the page size for the memory
    management unit in the CPU. Therefore, if you shrink an executable’s file size
    down to 700 bytes in an attempt to save disk space (an admirable goal, even given
    the gargantuan size of modern disk drive subsystems), the savings won’t be as
    great as you’d expect. That 700-byte application, for example, is still going
    to consume a minimum of one block on the disk’s surface. All you achieve by reducing
    your application’s code or data size is to waste that much more space in the disk
    file—subject, of course, to section/block allocation granularity.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: For larger executable files, those larger than the disk block size, internal
    fragmentation has less impact with respect to wasted space. If an executable file
    packs the data and code sections without any wasted space between the sections,
    then internal fragmentation occurs only at the end of the file, in the very last
    disk block. Assuming that file sizes are random (even distribution), then internal
    fragmentation will waste approximately one-half of a disk block per file (that
    is, an average of 2KB per file when the disk block size is 4KB). For a very small
    file, one that is less than 4KB in size, this might represent a significant amount
    of the file’s space. For larger applications, however, the wasted space becomes
    insignificant. So it would seem that as long as an executable file packs all the
    sections of the program sequentially in the file, the file will be as small as
    possible. But is this really desirable?
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: Assuming all things are equal, having smaller executable files is a good thing.
    However, all things aren’t always equal, so sometimes creating the smallest possible
    executable file isn’t really best. To understand why, recall the earlier discussion
    of the operating system’s virtual memory subsystem. When an OS loads an application
    into memory for execution, it doesn’t actually have to read the entire file. Instead,
    the operating system’s paging system can load only those pages needed to start
    the application. This usually consists of the first page of executable code, a
    page of memory to hold stack-based data, and, possibly, some data pages. In theory,
    an application could begin execution with as few as two or three pages of memory
    and bring in the remaining pages of code and data *on demand* (as the application
    requests the data or code found in those pages). This is known as *demand-paged
    memory management*. In practice, most operating systems actually preload pages
    for efficiency reasons (maintaining a working set of pages in memory). However,
    operating systems generally don’t load the entire executable file into memory;
    instead, they load various blocks as the application requires them. As a result,
    the effort needed to load a page of memory from a file can dramatically affect
    a program’s performance. Is there some way, then, to organize the executable file
    to improve performance when the OS uses demand-paged memory management? Yes—if
    you make the file a little larger.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: The trick to improving performance is to organize the executable file’s blocks
    to match the memory page layout. This means that sections in memory should be
    aligned on page-sized boundaries in the executable file. It also means that disk
    blocks should be the size of, or a multiple of the size of, a disk sector or block.
    This being the case, the virtual memory management system can rapidly copy a single
    block on the disk into a single page of memory, update any necessary relocation
    values, and continue program execution. On the other hand, if a page of data is
    spread across two blocks on the disk and is not aligned on a disk block boundary,
    the OS has to read two blocks (rather than one) from disk into an internal buffer
    and then copy the page of data from that buffer to the destination page where
    it belongs. This extra work can be very time-consuming and hamper application
    performance.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, some compilers will actually pad the executable file to ensure
    that each section in the executable file begins on a block boundary that the virtual
    memory management subsystem can map directly to a page in memory. Compilers that
    employ this technique often produce much larger executable file sizes than those
    that don’t. This is especially true if the executable file contains a large amount
    of BSS (uninitialized) data that a packed file format can represent very compactly.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Because some compilers produce packed files at the expense of execution time,
    while others produce expanded files that load and run faster, it’s dangerous to
    compare the quality of compilers based on the size of the executable files they
    produce. The best way to determine the quality of a compiler’s output is by directly
    analyzing that output, not by using a weak metric such as output file size.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '*Analyzing compiler output is the subject of the very next chapter, so if you’re
    interested in the topic, keep reading.*'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '**4.8 Data and Code Alignment in an Object File**'
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As I pointed out in *WGC1*, aligning data objects on an address boundary that
    is “natural” for that object’s size can improve performance. It’s also true that
    aligning the start of a procedure’s code or the starting instruction of a loop
    on some nice boundary can improve performance. Compiler writers are well aware
    of this fact and will often emit *padding bytes* in the data or code stream to
    align data or code sequences on an appropriate boundary. However, note that the
    linker is free to move sections of code around when linking two object files to
    produce a single executable result.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Sections are generally aligned to a page boundary in memory. For a typical application,
    the text/code section will begin on a page boundary, the data section will begin
    on a different page boundary, the BSS section (if it exists) will begin on its
    own page boundary, and so on. However, this doesn’t imply that each and every
    section associated with a section header in the object files starts on its own
    page in memory. The linker program will combine sections that have the same name
    into a single section in the executable file. So, for example, if two different
    object files both contain a `.text` segment, the linker will combine them into
    a single `.text` section in the final executable file. By combining sections that
    have the same name, the linker avoids wasting a large amount of memory to internal
    fragmentation.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: How does the linker respect the alignment requirements of each of the sections
    it combines? The answer, of course, depends on exactly what object file format
    and OS you’re using, but it’s usually found in the object file format itself.
    For example, in a Windows PE/COFF file the `IMAGE_OPTIONAL_HEADER32` structure
    contains a field named `SectionAlignment`. This field specifies the address boundary
    that the linker and OS must respect when combining sections and loading the section
    into memory. Under Windows, the `SectionAlignment` field in the PE/COFF optional
    header will usually contain 32 or 4,096 bytes. The 4KB value, of course, will
    align a section to a 4KB page boundary in memory. The alignment value of 32 was
    probably chosen because this is a reasonable cache line value (see *WGC1* for
    a discussion of cache lines). Other values are certainly possible—an application
    programmer can usually specify section alignment values by using linker (or compiler)
    command-line parameters.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '**4.8.1 Choosing a Section Alignment Size**'
  id: totrans-326
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Within each section, a compiler, assembler, or other code-generation tool can
    guarantee any alignment that is a submultiple of the section’s alignment. For
    example, if the section’s alignment value is 32, then alignments of 1, 2, 4, 8,
    16, and 32 are possible within that section. Larger alignment values are not possible.
    If a section’s alignment value is 32 bytes, you cannot guarantee alignment within
    that section on a 64-byte boundary, because the OS or linker will respect only
    the section’s alignment value and it can place that section on any boundary that
    is a multiple of 32 bytes. And about half of those won’t be 64-byte boundaries.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps less obvious, but just as true, is the fact that you cannot align an
    object within a section on a boundary that is not a submultiple of the section’s
    alignment. For example, a section with a 32-byte alignment value will not allow
    an alignment of 5 bytes. True, you could guarantee that the offset of some object
    within the section would be a multiple of 5; however, if the starting memory address
    of the section is not a multiple of 5, then the address of the object you attempted
    to align might not fall on a multiple of 5 bytes. The only solution is to pick
    a section alignment value that is some multiple of 5.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: Because memory addresses are binary values, most language translators and linkers
    limit alignment values to a power of 2 that is less than or equal to some maximum
    value, usually the memory management unit’s page size. Many languages restrict
    the alignment value to a small power of 2 (such as 32, 64, or 256).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '**4.8.2 Combining Sections**'
  id: totrans-330
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When a linker combines two sections, it has to respect the alignment values
    associated with each section because the application may depend on that alignment
    for correct operation. Therefore, a linker or other program that combines sections
    in object files can’t simply concatenate the data for the two sections when building
    the combined section.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: When combining two sections, a linker might have to add padding bytes between
    the sections if one or both of the lengths is not a multiple of the sections’
    alignment. For example, if two sections have an alignment value of 32, and one
    section is 37 bytes long and the other section is 50 bytes long, the linker will
    have to add 27 bytes of padding between the first and second sections, or it will
    have to add 14 bytes of padding between the second section and the first (the
    linker usually gets to choose in which order it places the sections in the combined
    file).
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: The situation gets a bit more complicated if the alignment values are not the
    same for the two sections. When a linker combines two sections, it has to ensure
    that the alignment requests are met for the data in both sections. If the alignment
    value of one section is a multiple of the other section’s alignment value, then
    the linker can simply choose the larger of the two alignment values. For example,
    if the alignment values are always powers of 2 (as most linkers require), then
    the linker can simply choose the larger of the two alignment values for the combined
    section.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: If one section’s alignment value is not a multiple of the other’s, then the
    only way to guarantee the alignment requirements of both sections when combining
    them is to use an alignment value that is a product of the two values (or, better
    yet, the *least common multiple* of the two values). For example, combining a
    section aligned on a 32-byte boundary with one aligned on a 5-byte boundary requires
    an alignment value of 160 bytes (5 × 32). Because of the complexities of combining
    two such sections, most linkers require section sizes to be small powers of 2,
    which guarantees that the larger segment alignment value is always a multiple
    of the smaller alignment value.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '**4.8.3 Controlling the Section Alignment**'
  id: totrans-335
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You typically use linker options to control the section alignment within your
    programs. For example, with the Microsoft *link.exe* program, the `/ALIGN:value`
    command-line parameter tells the linker to align all sections in the output file
    to the specified boundary (which must be a power of 2). GNU’s *ld* linker program
    lets you specify a section alignment by using the `BLOCK(value)` option in a linker
    script file. The macOS linker (`ld`) provides a `-segalign value` command-line
    option you can use to specify section alignment. The exact command and possible
    values are specific to the linker; however, almost every modern linker allows
    you to specify the section alignment properties. See your linker’s documentation
    for details.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: 'One word of caution about setting the section alignment: more often than not,
    a linker will require that all sections in a given file be aligned on the same
    boundary (a power of 2). Therefore, if you have different alignment requirements
    for all your sections, then you’ll need to choose the largest alignment value
    for all the sections in your object file.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '**4.8.4 Aligning Sections Within Library Modules**'
  id: totrans-338
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Section alignment can have a very big impact on the size of your executable
    files if you use a lot of short library routines. Suppose, for example, that you’ve
    specified an alignment size of 16 bytes for the sections associated with the object
    files appearing in a library. Each library function that the linker processes
    will be placed on a 16-byte boundary. If the functions are small (fewer than 16
    bytes in length), the space between the functions will be unused when the linker
    creates the final executable. This is another form of internal fragmentation.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: To understand why you would want to align the code (or data) in a section on
    a given boundary, think about how cache lines work (see *WGC1* for a refresher).
    By aligning the start of a function on a cache line, you may be able to slightly
    increase the execution speed of that function, as it may generate fewer cache
    misses during execution. For this reason, many programmers like to align all their
    functions at the start of a cache line. Although the size of a cache line varies
    from CPU to CPU, a typical cache line is 16 to 64 bytes long, so many compilers,
    assemblers, and linkers will attempt to align code and data to one of these boundaries.
    On the 80x86 processor, there are some other benefits to 16-byte alignment, so
    many 80x86-based tools default to a 16-byte section alignment for object files.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider, for example, the following short HLA (High-Level Assembly) program,
    processed by Microsoft tools, that calls two relatively small library routines:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here is the source code for the `bits.reverse32()` library function. Note that
    this source file also includes the `bits.reverse16()` and `bits.reverse8()` functions
    (to conserve space, the bodies of these functions do not appear below). Although
    their operation is not pertinent to our discussion, note that these functions
    swap the values in the HO (high-order) and LO (low-order) bit positions. Because
    these three functions appear in a single source file, any program that includes
    one of these functions will automatically include all three (because of the way
    compilers, assemblers, and linkers work).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The Microsoft *dumpbin.exe* tool allows you to examine the various fields of
    an *.obj* or *.exe* file. Running `dumpbin` with the `/headers` command-line option
    on the *bitcnt.obj* and *reverse.obj* files (produced for the HLA standard library)
    tells us that each of the sections is aligned to a 16-byte boundary. Therefore,
    when the linker combines the *bitcnt.obj* and *reverse.obj* data with the sample
    program given earlier, it will align the `bits.cnt()` function in the *bitcnt.obj*
    file on a 16-byte boundary, and the three functions in the *reverse.obj* file
    on a 16-byte boundary. (Note that it will not align each function in the file
    on a 16-byte boundary. That task is the responsibility of the tool that created
    the object file, if such alignment is desired.) By using the *dumpbin.exe* program
    with the `/disasm` command-line option on the executable file, you can see that
    the linker has honored these alignment requests (note that an address that is
    aligned on a 16-byte boundary will have a `0` in the LO hexadecimal digit):'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The exact operation of this program really isn’t important (after all, it doesn’t
    actually do anything useful). The takeaway is how the linker inserts extra bytes
    (`$cc`, the `int 3` instruction) before a group of one or more functions appearing
    in a source file to ensure that they are aligned on the specified boundary.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: In this particular example, the `bits.cnt()` function is actually 64 bytes long,
    and the linker inserted only 3 bytes in order to align it to a 16-byte boundary.
    This percentage of waste—the number of padding bytes compared to the size of the
    function—is quite low. However, if you have a large number of small functions,
    the wasted space can become significant (as with the default exception handler
    in this example that has only two instructions). When creating your own library
    modules, you’ll need to weigh the inefficiencies of extra space for padding against
    the small performance gains you’ll obtain by using aligned code.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Object code dump utilities (like *dumpbin.exe*) are quite useful for analyzing
    object code and executable files in order to determine attributes such as section
    size and alignment. Linux (and most Unix-like systems) provides the comparable
    `objdump` utility. I’ll discuss these tools in the next chapter, as they are great
    for analyzing compiler output.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '**4.9 How Linkers Affect Code**'
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The limitations of object file formats such as COFF and ELF have a big impact
    on the quality of code that compilers can generate. Because of how object file
    formats are designed, linkers and compilers often have to inject extra code into
    an executable file that wouldn’t be necessary otherwise. In this section we’ll
    explore some of the problems that generic object code formats like COFF and ELF
    inflict on the executable code.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: One problem with generic object file formats like COFF and ELF is that they
    were not designed to produce efficient executable files for specific CPUs. Instead,
    they were created to support a wide variety of CPUs and to make it easy to link
    together object modules. Unfortunately, their versatility often prevents them
    from creating the best possible object files.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps the biggest problem with the COFF and ELF formats is that relocation
    values in the object file must apply to 32- and 64-bit pointers in the object
    code. This creates problems, for example, when an instruction encodes a displacement
    or address value with less than 32 (64) bits. On some processors, such as the
    80x86, displacements smaller than 32 bits are so small (for example, the 80x86’s
    8-bit displacement) that you would never use them to refer to code outside the
    current object module. However, on some RISC processors, such as the PowerPC or
    ARM, displacements are much larger (26 bits in the case of the PowerPC branch
    instruction). This can lead to code kludges like the function stub generation
    that GCC produces for external function calls. Consider the following C program
    and the PowerPC code that GCC emits for it:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The compiler must generate the `L_printf$stub` stub because it doesn’t know
    how far away the actual `printf()` routine will be when the linker adds it to
    the final executable file. It’s unlikely that `printf()` would be sitting outside
    the ±32MB range that the PowerPC’s 24-bit branch displacement supports (extended
    to 26 bits), but it’s not guaranteed. If `printf()` is part of a shared library
    that is dynamically linked in at runtime, it very well could be outside this range.
    Therefore, the compiler has to make the safe choice and use a 32-bit displacement
    for the address of the `printf()` function. Unfortunately, PowerPC instructions
    don’t support a 32-bit displacement, because all PowerPC instructions are 32 bits
    long. A 32-bit displacement would leave no room for the instruction’s opcode.
    Therefore, the compiler has to store a 32-bit pointer to the `printf()` routine
    in a variable and jump indirect through that variable. Accessing a 32-bit memory
    pointer on the PowerPC takes quite a bit of code if you don’t already have the
    pointer’s address in a register, hence all the extra code following the `L_printf$stub`
    label.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: If the linker were able to adjust 26-bit displacements rather than just 32-bit
    values, there would be no need for the `L_printf$stub` routine or the `L_printf$lazy_ptr`
    pointer variable. Instead, the `bl L_printf$stub` instruction would be able to
    branch directly to the `printf()` routine (assuming it’s not more than ±32MB away).
    Because single program files generally don’t contain more than 32MB of machine
    instructions, there would rarely be the need to go through the gymnastics this
    code does in order to call an external routine.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, there is nothing you can do about the object file format; you’re
    stuck with whatever format the OS specifies (which is usually a variant of COFF
    or ELF on modern 32-bit and 64-bit machines). However, you can work within those
    limitations.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: If you expect your code to run on a CPU like the PowerPC or ARM (or some other
    RISC processor) that cannot encode 32-bit displacements directly within instructions,
    you can optimize by avoiding cross-module calls as much as possible. While it’s
    not good programming practice to create monolithic applications, where all the
    source code appears in one source file (or is processed by a single compilation),
    there’s really no need to place all of your own functions in separate source modules
    and compile each one separately from the others—particularly if these routines
    make calls to one another. By placing a set of common routines your code uses
    into a single compilation unit (source file), you allow the compiler to optimize
    the calls among these functions and avoid all the stub generation on processors
    like the PowerPC. This is not a suggestion to simply move all of your external
    functions into a single source file. The code is better only if the functions
    in a module call one another or share other global objects. If the functions are
    completely independent of one another and are called only by code external to
    the compilation unit, then you’ve saved nothing because the compiler may still
    need to generate stub routines in the external code.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '**4.10 For More Information**'
  id: totrans-359
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Aho, Alfred V., Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman. *Compilers:
    Principles, Techniques, and Tools*. 2nd ed. Essex, UK: Pearson Education Limited,
    1986.'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: 'Gircys, Gintaras. *Understanding and Using COFF*. Sebastopol, CA: O’Reilly
    Media, 1988.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: 'Levine, John R. *Linkers and Loaders*. San Diego: Academic Press, 2000.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
