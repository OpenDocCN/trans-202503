["```\nroot@host01:~# ps -e -o pid,class,rtprio,ni,comm\n PID CLS RTPRIO  NI COMMAND\n   1 TS       -   0 systemd\n...\n   6 TS       - -20 kworker/0:0H-kblockd\n...\n  11 FF      99   - migration/0\n  12 FF      50   - idle_inject/0\n...\n  85 FF      99   - watchdogd\n...\n 484 RR      99   - multipathd\n...\n7967 TS       -   0 ps\n```", "```\n---\nmetadata:\n  name: stress\n  namespace: crio\nlinux:\n  security_context:\n    namespace_options:\n      network: 2\n```", "```\n---\nmetadata:\n  name: stress\nimage:\n  image: docker.io/bookofkubernetes/stress:stable\nargs:\n  - \"--cpu\"\n  - \"1\"\n  - \"-v\"\n```", "```\nroot@host01:/opt# crictl pull docker.io/bookofkubernetes/stress:stable\nImage is up to date for docker.io/bookofkubernetes/stress...\n```", "```\nroot@host01:~# cd /opt\nroot@host01:/opt# PUL_ID=$(crictl runp po-nolim.yaml)\nroot@host01:/opt# CUL_ID=$(crictl create $PUL_ID co-nolim.yaml po-nolim.yaml)\nroot@host01:/opt# crictl start $CUL_ID\n...\nroot@host01:/opt# crictl ps\nCONTAINER      IMAGE                                    ...\n971e83927329e  docker.io/bookofkubernetes/stress:stable ...\n```", "```\nroot@host01:/opt# top -b -n 1 -p $(pgrep -d , stress)\ntop - 18:01:58 up  1:39,  1 user,  load average: 1.01, 0.40, 0.16\nTasks:   2 total,   1 running,   1 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 34.8 us, 0.0 sy, 0.0 ni, 65.2 id, 0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nMiB Mem :   1987.5 total,   1024.5 free,    195.8 used,    767.3 buff/cache\nMiB Swap:      0.0 total,      0.0 free,      0.0 used.   1643.7 avail Mem \n\n  PID   USER  PR  NI  ...  %CPU  %MEM    TIME+ COMMAND\n  13459 root  20   0  ... 100.0   0.2  0:29.78 stress-ng\n  13435 root  20   0  ...   0.0   0.2  0:00.01 stress-ng\n```", "```\nroot@host01:/opt# renice -n 19 -p $(pgrep -d ' ' stress)\n13435 (process ID) old priority 0, new priority 19\n13459 (process ID) old priority 0, new priority 19\n```", "```\nroot@host01:/opt# top -b -n 1 -p $(pgrep -d , stress)\ntop - 18:11:04 up  1:48,  1 user,  load average: 1.07, 0.95, 0.57\nTasks:   2 total,   1 running,   1 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 0.0 us, 0.0 sy, 28.6 ni, 71.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nMiB Mem :   1987.5 total,   1035.6 free,    182.2 used,    769.7 buff/cache\nMiB Swap:      0.0 total,      0.0 free,      0.0 used.   1657.2 avail Mem \n\n  PID   USER  PR  NI  ...  %CPU  %MEM     TIME+ COMMAND\n  13459 root  39  19  ... 100.0   0.2   9:35.50 stress-ng\n  13435 root  39  19  ...   0.0   0.2   0:00.01 stress-ng\n```", "```\nroot@host01:~# ls /sys/fs/cgroup\nblkio        cpuacct  freezer  net_cls           perf_event  systemd\ncpu          cpuset   hugetlb  net_cls,net_prio  pids        unified\ncpu,cpuacct  devices  memory   net_prio          rdma\n```", "```\nroot@host01:~# cd /sys/fs/cgroup/cpu\nroot@host01:/sys/fs/cgroup/cpu# ls -F\ncgroup.clone_children  cpuacct.stat               cpuacct.usage_user\ncgroup.procs           cpuacct.usage              init.scope/\ncgroup.sane_behavior   cpuacct.usage_all          notify_on_release\ncpu.cfs_period_us      cpuacct.usage_percpu       release_agent\ncpu.cfs_quota_us       cpuacct.usage_percpu_sys   system.slice/\ncpu.shares             cpuacct.usage_percpu_user  tasks\ncpu.stat               cpuacct.usage_sys          user.slice/\n```", "```\nroot@host01:/sys/fs/cgroup/cpu# top -b -n 1 -p $(pgrep -d , stress)\ntop - 22:40:12 up 12 min,  1 user,  load average: 0.81, 0.35, 0.21\nTasks:   2 total,   1 running,   1 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 37.0 us, 0.0 sy, 0.0 ni, 63.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nMiB Mem :   1987.5 total,   1075.1 free,    179.4 used,    733.0 buff/cache\nMiB Swap:      0.0 total,      0.0 free,      0.0 used.   1646.3 avail Mem \n\n  PID USER   PR  NI ...  %CPU  %MEM     TIME+ COMMAND\n  5964 root  20  19 ...  100.0  0.2   1:19.72 stress-ng\n  5932 root  20  19 ...  0.0    0.2   0:00.02 stress-ng\n```", "```\nroot@host01:/sys/fs/cgroup/cpu# grep -R $(pgrep stress-ng-cpu)\nsystem.slice/runc-050c.../cgroup.procs:5964\nsystem.slice/runc-050c.../tasks:5964\n```", "```\nroot@host01:/sys/fs/cgroup/cpu# cd system.slice/runc-${CUL_ID}.scope\n```", "```\nroot@host01:/sys/fs/...07.scope# ls\ncgroup.clone_children  cpu.uclamp.max        cpuacct.usage_percpu_sys\ncgroup.procs           cpu.uclamp.min        cpuacct.usage_percpu_user\ncpu.cfs_period_us      cpuacct.stat          cpuacct.usage_sys\ncpu.cfs_quota_us       cpuacct.usage         cpuacct.usage_user\ncpu.shares             cpuacct.usage_all     notify_on_release\ncpu.stat               cpuacct.usage_percpu  tasks\n```", "```\nroot@host01:/sys/fs/...07.scope# cat cgroup.procs\n5932\n5964\n```", "```\nroot@host01:/sys/fs/...07.scope# cat cpu.cfs_period_us\n100000\n```", "```\nroot@host01:/sys/fs/...07.scope# cat cpu.cfs_quota_us\n-1\n```", "```\nroot@host01:/sys/fs/...07.scope# echo \"50000\" > cpu.cfs_quota_us\n```", "```\nroot@host01:/sys/fs/...07.scope# top -b -n 1 -p $(pgrep -d , stress)\ntop - 23:53:05 up  1:24,  1 user,  load average: 0.71, 0.93, 0.98\nTasks:   2 total,   1 running,   1 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  0.0 us, 3.6 sy, 7.1 ni, 89.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nMiB Mem :   1987.5 total,   1064.9 free,    174.6 used,    748.0 buff/cache\nMiB Swap:      0.0 total,      0.0 free,      0.0 used.   1663.9 avail Mem \n\n  PID USER   PR  NI  ...  %CPU  %MEM     TIME+ COMMAND\n  5964 root  39  19  ...  50.0   0.2  73:45.68 stress-ng-cpu\n  5932 root  39  19  ...   0.0   0.2   0:00.02 stress-ng\n```", "```\nroot@host01:/sys/fs/...07.scope# cd\nroot@host01:/opt# crictl stop $CUL_ID\n...\nroot@host01:/opt# crictl rm $CUL_ID\n...\nroot@host01:/opt# crictl stopp $PUL_ID\nStopped sandbox ...\nroot@host01:/opt# crictl rmp $PUL_ID\nRemoved sandbox ...\n```", "```\n---\nmetadata:\n  name: stress-clim\n  namespace: crio\nlinux:\n  cgroup_parent: pod.slice\n  security_context:\n    namespace_options:\n      network: 2\n```", "```\n---\n---\nmetadata:\n  name: stress-clim\nimage:\n  image: docker.io/bookofkubernetes/stress:stable\nargs:\n  - \"--cpu\"\n  - \"1\"\n  - \"-v\"\nlinux:\n  resources:\n    cpu_period: 100000\n    cpu_quota: 10000\n```", "```\nroot@host01:~# cd /opt\nroot@host01:/opt# PCL_ID=$(crictl runp po-clim.yaml)\nroot@host01:/opt# CCL_ID=$(crictl create $PCL_ID co-clim.yaml po-clim.yaml)\nroot@host01:/opt# crictl start $CCL_ID\n...\nroot@host01:/opt# crictl ps\nCONTAINER      IMAGE                                    ...\nea8bccd711b86  docker.io/bookofkubernetes/stress:stable ...\n```", "```\nroot@host01:/opt# top -b -n 1 -p $(pgrep -d , stress)\ntop - 17:26:55 up 19 min,  1 user,  load average: 0.27, 0.16, 0.13\nTasks:   4 total,   2 running,   2 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 10.3 us, 0.0 sy, 0.0 ni, 89.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nMiB Mem :   1987.5 total,   1053.4 free,    189.3 used,    744.9 buff/cache\nMiB Swap:      0.0 total,      0.0 free,      0.0 used.   1640.4 avail Mem \n\n  PID USER   PR  NI ... %CPU  %MEM     TIME+ COMMAND\n  8349 root  20   0 ... 10.0   0.2   0:22.67 stress-ng\n  8202 root  20   0 ...  0.0   0.2   0:00.02 stress-ng\n```", "```\nroot@host01:/opt# cd /sys/fs/cgroup/cpu/pod.slice\nroot@host01:...pod.slice# cat crio-$CCL_ID.scope/cpu.cfs_quota_us\n10000\n```", "```\nroot@host01:/sys/fs/cgroupcpu/pod.slice# cd\nroot@host01:~# crictl stop $CCL_ID\n...\nroot@host01:~# crictl rm $CCL_ID\n...\nroot@host01:~# crictl stopp $PCL_ID\nStopped sandbox ...\nroot@host01:~# crictl rmp $PCL_ID\nRemoved sandbox ...\n```", "```\nroot@host01:~# ulimit -v 262144\n```", "```\nroot@host01:~# cat /dev/zero | head -c 500m | tail\ntail: memory exhausted\n```", "```\n---\nmetadata:\n  name: stress2\n  namespace: crio\nlinux:\n  cgroup_parent: pod.slice\n  security_context:\n    namespace_options:\n      network: 2\n```", "```\n ---\n ---\n metadata:\n   name: stress2\n image:\n   image: docker.io/bookofkubernetes/stress:stable\n args:\n   - \"--vm\"\n   - \"1\"\n   - \"--vm-bytes\"\n➊ - \"512M\"\n   - \"-v\"\n linux:\n   resources:\n  ➋ memory_limit_in_bytes: 268435456\n     cpu_period: 100000 \n  ➌ cpu_quota: 10000\n```", "```\nroot@host01:~# cd /opt \nroot@host01:/opt# PML_ID=$(crictl runp po-mlim.yaml)\nroot@host01:/opt# CML_ID=$(crictl create $PML_ID co-mlim.yaml po-mlim.yaml)\nroot@host01:/opt# crictl start $CML_ID\n...\n```", "```\nroot@host01:/opt# crictl ps\nCONTAINER     IMAGE                                    ... STATE   ...\n31025f098a6c9 docker.io/bookofkubernetes/stress:stable ... Running ...\n```", "```\nroot@host01:/opt# crictl logs $CML_ID\n...\nstress-ng: info:  [6] dispatching hogs: 1 vm\n...\nstress-ng: debug: [11] stress-ng-vm: started [11] (instance 0)\nstress-ng: debug: [11] stress-ng-vm using method 'all'\nstress-ng: debug: [11] stress-ng-vm: child died: signal 9 'SIGKILL' (instance 0)\nstress-ng: debug: [11] stress-ng-vm: assuming killed by OOM killer, restarting again...\nstress-ng: debug: [11] stress-ng-vm: child died: signal 9 'SIGKILL' (instance 0)\nstress-ng: debug: [11] stress-ng-vm: assuming killed by OOM killer, restarting again...\n```", "```\nroot@host01:/opt# dmesg | grep -i oom_reaper | tail -n 1\n[  696.651056] oom_reaper: reaped process 8756 (stress-ng-vm)...\n```", "```\nroot@host01:/opt# crictl stop $CML_ID\n...\nroot@host01:/opt# crictl rm $CML_ID\n...\nroot@host01:/opt# crictl stopp $PML_ID\nStopped sandbox ...\nroot@host01:/opt# crictl rmp $PML_ID\nRemoved sandbox ...\nroot@host01:/opt# cd\n```", "```\nroot@host01:~# iperf3 -c 192.168.61.12\nConnecting to host 192.168.61.12, port 5201\n[  5] local 192.168.61.11 port 49044 connected to 192.168.61.12 port 5201\n...\n[ ID] Interval           Transfer     Bitrate         Retr\n[  5]   0.00-10.00  sec  2.18 GBytes  1.87 Gbits/sec  13184             sender\n[  5]   0.00-10.00  sec  2.18 GBytes  1.87 Gbits/sec                  receiver\n...\n```", "```\nroot@host01:~# IFACE=$(ip -o addr | grep 192.168.61.11 | awk '{print $2}')\nroot@host01:~# tc qdisc add dev $IFACE root tbf rate 100mbit \\\n  burst 256kbit latency 400ms\n```", "```\nroot@host01:~# iperf3 -c 192.168.61.12\nConnecting to host 192.168.61.12, port 5201\n[  5] local 192.168.61.11 port 49048 connected to 192.168.61.12 port 5201\n...\n[ ID] Interval           Transfer     Bitrate         Retr\n[  5]   0.00-10.00  sec   114 MBytes  95.7 Mbits/sec    0             sender\n[  5]   0.00-10.01  sec   113 MBytes  94.5 Mbits/sec                  receiver\n...\n```"]