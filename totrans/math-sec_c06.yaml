- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Analyzing Social Networks to Prevent Security Incidents
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: In the last three chapters on graph theory, we’ve built graphs from a snapshot
    of a network at a particular moment in time; that is, we’ve worked from fixed,
    historical data. But finding and responding to events in the past always leaves
    the white hats one step behind the black hats. If we want to know more about what
    happened before or after the time captured in the data, we need new analytic techniques.
    The future requires *predictive analytics*, a branch of mathematics that aims
    to statistically determine the probability of future or past events given some
    set of known observations. The goal is to stop the security incident before it
    ever gets started. To achieve this, though, we need a way to predict how things
    will change over time. We’ll use a specific algorithm, the Monte Carlo simulation,
    to model network activity that hasn’t occurred yet. While this chapter presents
    the topic in the context of social network analysis, Monte Carlo simulations are
    suited to a wide variety of topics and network types. For example, I’ve used Monte
    Carlo simulations to predict which machine an adversary would attack next.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we’ll attempt to predict the answers to the following questions about
    a social network:'
  prefs: []
  type: TYPE_NORMAL
- en: How far is information likely to spread from a given node?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which nodes are being influenced by other nodes?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What links could be severed to disrupt the flow of information between two nodes?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From a security perspective, these questions assess the resilience of a social
    network in the face of adversarial behavior. They ask, “How easy would it be to
    break up an association of people?” Companies ask these questions about themselves
    to determine if they could withstand losing key employees, facilities, or vendors.
    Law enforcement asks them when they assess a criminal syndicate.^([1](b01.xhtml#c06-endnote-001))
    Criminals also ask these questions about an organization when they want to select
    the targets for spear phishing and other social engineering attacks.^([2](b01.xhtml#c06-endnote-002))
  prefs: []
  type: TYPE_NORMAL
- en: We’ll begin this chapter by looking at how to define and construct a Monte Carlo
    simulation. We’ll discuss how different levels of randomness can be applied to
    replace unknowns. Then we’ll use the Monte Carlo simulation we’ve built to predict
    the way a piece of information might move through the social network from [Chapter
    5](c05.xhtml), given previous observations. Finally, in the proof of concept for
    this chapter, we’ll see how to modify our simulation to account for adversarial
    behavior. By the end of this chapter, you’ll be able to use your knowledge of
    graph theory and apply Monte Carlo simulations to predict the outcome of different
    scenarios on your own social networks.
  prefs: []
  type: TYPE_NORMAL
- en: Using Monte Carlo Simulations to Predict Attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the rest of this chapter to make sense, we need a little bit more theory
    on top of the graph theory we’ve already covered. Specifically, I’ve been throwing
    around the word *simulation* without really defining it. Generally speaking, a
    simulation is a controlled imitation of a real-world process. Simulations rely
    on models to describe the key characteristics and behaviors present in the simulated
    environment. The simulation code acts as the manager of the model, choosing various
    actions and applying them to evolve the model at each step. Modern models and
    simulations are most often designed using a combination of programming languages
    like C and Python, where C is used for critical functions and user-friendly Python
    syntax is used for the rest. Luckily, all the underlying C code has already been
    handled for us, so we can focus on the Python interface.
  prefs: []
  type: TYPE_NORMAL
- en: In theory, any phenomenon that can be reduced to data and equations can be simulated
    on a computer. In practice, however, simulation is difficult because most real-world
    processes are subject to a practically infinite number of influences, and it’s
    impossible to account for them all.
  prefs: []
  type: TYPE_NORMAL
- en: A Monte Carlo simulation is a way of quickly gathering statistics about some
    seemingly random (or at least hard to predict) variable, given a set of constraints.
    Unlike other forecasting methods, which work with a set of fixed input values,
    a Monte Carlo simulation predicts a set of outcomes based on an estimated range
    of values. You’ve probably seen the results of a Monte Carlo simulation in the
    form of a storm path map (sometimes called a *spaghetti model*). Monte Carlo simulations
    are most useful when the probability of varying outcomes can’t be determined because
    of random variable interference. A Monte Carlo simulation focuses on repeating
    the test with random samples to achieve certain results. It also helps to explain
    the impact of risk and uncertainty in prediction and forecasting models because
    the values for the random variables are chosen using the distribution of previously
    recorded values. The larger the variance in the random value, the more variance
    in the different results of the simulation. In principle, Monte Carlo methods
    can be used to investigate any problem with a probabilistic interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: In a security context, I’ve used Monte Carlo simulations to predict and interrupt
    attacks. To do so, I programmed some rules that mimicked the previous decisions
    of the attacker and ran thousands of simulations to predict where the attacker
    would end up. My team created a network graph (similar to the one from the previous
    chapter) in which we weighed the ease of access along with the machine’s attractiveness
    to the attacker (in terms of data or lateral movement). We then ran simulations
    with the attacker starting from random machines we knew had been exploited and
    using a stochastic process to determine if the attacker could successfully move
    from one machine to another.
  prefs: []
  type: TYPE_NORMAL
- en: 'We had additional rules to define how the attacker selected machines and so
    forth, but the question we were trying to answer was simple: After six days of
    active exploitation, which machines had the highest probability of being infected?
    In math terms, the law of large numbers tells us that integrals described by the
    expected value of some random variable can be approximated by taking the empirical
    mean (sometimes called the *sample mean*) of independent samples of the variable.
    In lay terms, the machines with the highest probability in our network simulation
    tests were likely those with the actual highest probability. And there’s our definition
    for “predicting” the future: we can state, with some degree of confidence, the
    statistical probability of each outcome. Unfortunately, that means things won’t
    always turn out as predicted.'
  prefs: []
  type: TYPE_NORMAL
- en: Modeling changes requires that we first have a way to describe what can and
    can’t happen. We’ll use a mathematical construct known as a finite state machine
    to handle this task. We then need to create a fake world for our simulation to
    inhabit. NetworkX will fill this role by providing the graph of our social network.
    Finally, we need some way of recording the different events so that we can analyze
    them. This is where the Monte Carlo algorithm really starts to take shape. Let’s
    start by defining each piece, and then we can tie it all together with some different
    simulations.
  prefs: []
  type: TYPE_NORMAL
- en: Finite State Machines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *finite state machine* (*FSM* or simply *state machine*) is a hypothetical
    machine that can be in exactly one of a finite number of states at a given moment
    in time, where a *state* is a unique configuration of variables. If you think
    of a board with three switches on it, each possible switch configuration represents
    a possible state for the board. It’s called a *finite* state machine because you
    can count the number of possible states. In the example switchboard, if each switch
    can be in one of two possible positions, there’s a total of eight possible configurations,
    or states, the switchboard could be in. If you think of these switches like bits
    in binary, you could represent the values between 000 and 111, or 0 through 7
    in base 10\. The state machine can change from one state to another in response
    to some external *input*, or decision (such as flipping one of the switches on
    the board). Changes from one state to another are called *transitions*.
  prefs: []
  type: TYPE_NORMAL
- en: Formally, a state machine *M* is defined by a quintuple *M* = (Ξ, *S*, *S*[0],
    δ) comprising a finite number of possible inputs (Ξ, the *input alphabet*), a
    set of all possible states (*S*), an initialization state (*S*[0]) where *S*[0]
    ∈ *S*, and finally the conditions for each valid transition between states, δ.
    We can represent a state machine as a directed graph wherein each node is a potential
    state of the machine, and each edge is the required input to transition from state
    *u* to state *v*. [Figure 6-1](#figure6-1) shows a simple FSM graph with five
    states and four transition inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/f06001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-1: A simple finite state machine'
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at this graph, you might be confused; after all, I just said there
    were four transitions, but there are nine edges here (the bidirectional edges
    between *S*[0] and *S*[1] and *S*[3] and *S*[4] count as two each). This is because
    the same input may be used in multiple transitions. The inputs Ξ[3] and Ξ[2] in
    [Figure 6-1](#figure6-1) are both examples of this: Ξ[2] is used to transition
    between *S*[0] and *S*[1] as well as between *S*[4] and *S*[2], while Ξ[3] can
    be used to transition from *S3 to *S*[1] or from *S*[1] to *S*[2]. Think of the
    input Ξ[2] as an action, like flipping a particular switch. Depending on what
    state you’re in currently, the action of flipping the switch may take you to a
    different state. If you’re in *S*[0] and flip the switch, you end up in *S*[1].
    If you’re in *S*[4] and flip the switch, you’ll end up in *S*[2]. The input hasn’t
    changed—it’s still Ξ[2]—which illustrates an important relationship between inputs
    and states. The same input may result in arriving at a different state, depending
    on the current state.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*FSMs are either *deterministic*, meaning each transition has a single guaranteed
    outcome, or *stochastic*, meaning the outcome of an input is influenced by randomness
    and not guaranteed to produce the same result every time. To illustrate the difference
    between the two types of FSMs, imagine picking up a pencil. In a deterministic
    world, attempting to pick up the pencil will always result in successfully picking
    up the pencil—or transitioning to the state where you have the pencil, in FSM
    parlance. In a stochastic world, you may fail to pick up the pencil with some
    probability 0 < *p* < 1\. If you fail to pick up the pencil, you transition to
    a different state than if you’d succeeded. Perhaps you dropped the pencil on the
    floor and you’re now in that state instead. This is a very simplistic example,
    but the point is that stochastic FSMs allow randomness to influence the results.
    This is powerful for generalizing the description of complex interactions because
    you don’t have to understand the mechanisms at work, you only need to measure
    the statistical distribution of possible outcomes and you can approximate the
    same phenomenon.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll often see a mix of deterministic and stochastic inputs in the same FSM.
    For example, in the FSM from [Figure 6-1](#figure6-1), Ξ[4] is deterministic.
    If you’re at *S*[2], the input Ξ[4] is guaranteed to transition you to *S*[3]
    and there’s no other possible outcome. On the other hand, Ξ[1] is stochastic:
    if you’re at *S*[4] and select action Ξ[1], you might end up at *S*[1] or at *S*[3].
    If no probabilities are given for these outcomes, it’s assumed to be uniformly
    random. If probabilities are given, the probability distribution is used in a
    weighted-random selection function. NetworkX has parameters for labeling the edges,
    which can be useful when showing the probabilities or, as I’ve done here, the
    transition names. You can see examples of this code in the accompanying Jupyter
    notebook. For more detailed examples of using FSMs, I highly recommend checking
    Wolfram Alpha.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you understand FSM structure a bit better, let’s move on to how we
    can leverage it using an algorithmic gem known as random walks. Random walks allow
    us to repeatedly choose random inputs for our FSM to automate the simulation of
    these choices based on the rules we define.
  prefs: []
  type: TYPE_NORMAL
- en: Network Modeling with Random Walks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In math terms, a *random walk* is a series of randomly chosen steps (or transitions)
    within a system that result in a random final state after some number of steps.
    I like the analogy of a tourist wandering in an unfamiliar city. They may walk
    up the street a bit, decide to turn left, go a few blocks, and then decide to
    turn around and go back the other way. These walks are erratic and unpredictable
    by definition. Versions of the random walk model have been applied to research
    topics from economics to neurology, and now information security!
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re going to apply this methodology to model how people pass information
    to one another and ultimately utilize the network. We can then use this information
    to explore what might happen if we change some of the parameters (such as an attacker
    taking over one or more lines of communication) without risking actual disruption
    to the network. Randomly selecting a series of transitions within a state machine
    over *n* steps (*T*(*n*)) updates the state of the system with the result of the
    input. The subsequent decision must be based on the new state, and all actions
    may not be valid in all states. The set of valid transitions from a given state
    is denoted Ξ[(][*S*][)]. At each step a transition is selected from Ξ[(][*S*][)]
    and appended to *T*(*n*). We can write this as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06001.png)'
  prefs: []
  type: TYPE_IMG
- en: The state is updated and the process is repeated until all *n* steps have been
    taken, or no valid state transitions are left. The resulting *terminal state*
    is the product of applying the random walk defined in *T*(*n*) to the state machine
    *M* (*M* × *T*(*n*) *= S(Tn*)).
  prefs: []
  type: TYPE_NORMAL
- en: As a concrete example, let’s define a simple state machine. Imagine you’re standing
    in the center of a large empty room. This is the initial state, *S*[0]. On the
    floor is a 7×7 grid of squares, and positions in the room can be expressed as
    location tuples (*x*, *y*) on the Cartesian plane (your position is *S*[0] = (4,
    4)). You can move forward, backward, left, or right one square with each step.
    Given an arbitrary set of instructions, you may end up standing on any square
    in the room; therefore, each square can be viewed as a potential state in *S*.
    The inputs [*forward*, *backward*, *left*, *right*] form the input alphabet Ξ.
    The two diagrams in [Figure 6-2](#figure6-2) show the same uniformly random walk
    for *n* = 10 in two dimensions on the left and three dimensions on the right.
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/f06002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-2: A 2D and 3D random walk example'
  prefs: []
  type: TYPE_NORMAL
- en: In the 3D example, the third dimension is time (you wouldn’t actually start
    to levitate as you moved around the room).
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast to a uniformly random walk, where each input is equally likely,
    in a *biased random walk* (or just *biased walk*), one or more of the inputs is
    likely to occur more than the rest. In a biased walk, we extend Ξ to a set of
    tuples: (*input*, *probability*).^([3](b01.xhtml#c06-endnote-003)) At each step
    we select one of the inputs from the list using a weighted random selection function—that
    is, one that respects the probability distribution we pass to it. We’ll construct
    a version of this later, but for now the key takeaway is that biased walks allow
    you to add any a priori information you have about behavior probabilities to your
    modeling. For example, if you know there’s a malicious actor who’s looking for
    financial information, you may choose to bias your model of their behavior toward
    nodes in the network that have access to such information.'
  prefs: []
  type: TYPE_NORMAL
- en: Up until now we’ve covered what a state machine is and how we can use one to
    simulate a series of choices. Because a random walk represents a single set of
    choices made within a stochastic FSM, you could rerun the simulation and the results
    would likely be different. Even with a biased random walk, the results on each
    iteration may be a little more predictable but still not the same. If the result
    were always the same, the system would be deterministic and no fun to analyze.
    It’s the differences between simulation results that we’re interested in analyzing.
    Repeated stochastic simulation is the defining characteristic of a Monte Carlo
    simulation, so in the next section, we’ll complete our algorithm by defining how
    we want to run each test and collect the results in a meaningful way. Once we
    have the final piece to the puzzle, we’ll start using our Monte Carlo simulation
    to predict some possible future states for our social network.
  prefs: []
  type: TYPE_NORMAL
- en: Monte Carlo Simulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can illustrate the relationship between random walks and Monte Carlo simulations
    with the simple example of flipping a coin. If we flip a coin and it lands on
    heads, what have we learned about the coin? Well, we’ve learned that with an extremely
    small sample size of 1, the coin lands on heads. Now, how useful do you think
    this information is for making predictions about the result of future coin flips?
    Could you predict if this is a fair coin or a trick coin? The answer is no, you
    couldn’t. This single result is not very useful—not yet, anyway. To get a clearer
    picture, we’d need to repeat this test a reasonably large number of times and
    record each outcome. Suppose we flip the coin 99 more times and it always lands
    on heads. This is way outside the expected result of roughly 50 percent, so we
    could state the coin is definitely not fair.
  prefs: []
  type: TYPE_NORMAL
- en: This situation is similar to the relationship between random walks and Monte
    Carlo simulations. Monte Carlo simulations are a subset of *repeated-sampling
    algorithms, which repeat a test some large number of times to gather statistical
    distributions. What makes a Monte Carlo simulation different from other repeated
    sampling algorithms is that it uses repeated random walks to simplify simulating
    complex interactions within a state machine over time. The random walk through
    the FSM acts like a single test—a coin flip, a space walk, or some other singular
    occurrence. The Monte Carlo algorithm then adds a layer to repeat this test over
    and over to collect the large sample size needed to make accurate predictions
    about future outcomes.*
  prefs: []
  type: TYPE_NORMAL
- en: '*One predominant use for Monte Carlo simulations is in the field of General
    Game Playing (GGP). The goal for GGP researchers is to find a generalized algorithm
    that can play any arbitrary but well-defined game. Think about a system like Deep
    Blue or the more recent Alpha Go, but designed to play chess and *Go*, as well
    as backgammon, tic-tac-toe, *Risk*, *Battleship*, and so on. This realm of study
    extends to single-player games (so-called puzzle games) like *Tower of Hanoi*
    as well. The automated system, called the *player*, needs to decide on the next
    valid move from a list of potential moves. This process is known as *goal-oriented
    planning*. In a state machine with a large number of potential states (chess matches,
    for example), it’s prohibitive to exhaustively search the options to conclusion.
    Instead, a player needs a strategy to quickly weigh possible options to identify
    advantageous ones. Monte Carlo simulations are one option that researchers have
    used with some success^([4](b01.xhtml#c06-endnote-004)) by reducing each game
    to a limited-length random walk through potential game states, then repeatedly
    testing the outcome of these walks for some goal condition.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As I’ve mentioned, security often comes down to one researcher’s offensive
    knowledge against another’s defensive knowledge. Game theory would label this
    a zero-sum multiplayer scenario. The term *zero-sum* refers to the case that,
    for one player to win points, the other player must lose an equal amount of points.
    Simply put: if you win, I must lose, and vice versa. Chess is the most famous
    example of zero-sum games, but we also see these conditions in a lot of adversarial
    interactions like security. For me to bypass your security, your security must
    get bypassed. For your security controls to block me, my attacks must fail. There
    are already schools like Stanford University that teach game theory as a way for
    humans to analyze their security posture. There are also researchers using game
    theory to model attack and defense scenarios.^([5](b01.xhtml#c06-endnote-005))
    It seems to me that programmatically applying game theory within information security
    research is a natural progression from the tools available today, and the simplest
    place to start that process is with Monte Carlo simulations.'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this simplicity can come at a cost. Monte Carlo simulations can miss
    obvious advantageous decisions due to the random nature of selection. You can
    tune the accuracy of the model a bit by adjusting the number of random walks,
    as well as the maximum length of each random walk. [Figure 6-3](#figure6-3) shows
    an example Monte Carlo simulation of random walks like the one in [Figure 6-2](#figure6-2).
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/f06003.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-3: A random walk Monte Carlo simulation'
  prefs: []
  type: TYPE_NORMAL
- en: Each walk is shaded differently so you can tell where they overlap. They all
    start from the same location but then take unpredictable paths.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Monte Carlo simulation we’ll look at is an algorithm that relies on *k*
    random walks of length *n*, through a state machine *M*, to obtain the result
    list ζ*R*. The result is a list of terminal states from each random walk performed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For convenience, I also output the path traversed by each random walk:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06003.png)'
  prefs: []
  type: TYPE_IMG
- en: Choosing values for *n* and *k* is an equal mix of domain knowledge, statistical
    theory, and art. For *n*, we need to choose a value large enough to allow our
    model to reach interesting outcome states without creating a bunch of repetitive
    data. For state machines with a large number of potential transitions and states,
    you may need to pick a value for *n* that balances long enough paths with a reasonable
    program runtime. Our state machine has a small number of potential transitions
    and will tend to reach a terminal state fairly quickly, so a small value between
    10 and 20 steps will suffice.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a good value for *k* is largely related to the number of potential
    states in the machine. You want to run the simulation as many times as it takes
    to collect statistical data to support a claim about the outcome, so the more
    possible outcomes there are, the more times you’ll want to run the simulation.
    When you move a project like this into production, you can use statistical methods
    to calculate the exact sample size required to justify an empirical claim, called
    *sample size determination*. Here, our simulation has a relatively small number
    of terminal states and we’re only trying to prove out the system, so somewhere
    between 10 and 25 runs will suffice for testing purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Simulating Social Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To answer our research questions about a social network, we’re going to write
    our own *Matrix*-like world, where simulated users live out their digital lives
    according to the rules of the system we put in place. The rules we choose represent
    all the decisions a user can make in our simulated world. I base the rules I use
    on the observations already present in the data (for example, which users have
    communicated in the past, and on what topics), as well as a simplified version
    of some link prediction theory published in 2009.^([6](b01.xhtml#c06-endnote-006))
    *Link prediction theory* attempts to describe how edges in a graph have formed
    previously and use that information to predict how they’ll form in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Our goal in designing the rules for the FSM is to accurately simulate which
    users might form connections, dissolve their association with other users, or
    pass information along to their connections. We’ll then look at how we can enhance
    the simulation by adding an adversary who is working to disrupt the network. This
    allows us to move into the realm of “what if” simulations. What if the head of
    HR suddenly leaves the company? What if the router in the office crashes? You’ll
    start seeing chances to apply simulations everywhere. After reading through this
    implementation, think about the rules and assumptions we’ve built up and how you
    might improve the simulation with more realistic constraints and behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling User Interaction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To answer the question “How far is information likely to spread from a given
    node?” we can simulate a message *q* propagating through the network by being
    transmitted from one user to another, and determine how many users are likely
    to receive the message. We’ll model the user interactions by generating biased
    random walks for the message to move from node to node. Assume, for the moment,
    that only one copy of the message can exist at a time. (See “[Modeling Information
    Flow](#h2-502567c06-0006)” for handling multiple copies of a message.) Think of
    this like a budget report making its way around an office. As each employee reads
    the report, they decide whether to forward it on to one of their coworkers. Because
    the report is sensitive, no one is allowed to make copies, so only one person
    can be holding the information at any given time. By selecting a starting node
    and allowing the message to propagate probabilistically, we can simulate possible
    paths the report is likely to follow, then count the unique nodes that eventually
    received the message. The average count of unique nodes after all the walks have
    been completed can be seen as the number of nodes likely to receive the information
    originating from the selected starting node.
  prefs: []
  type: TYPE_NORMAL
- en: For a Monte Carlo simulation, you must define the state machine that will act
    as the core of the system. The social network graph nodes (the users) represent
    states the message can occupy in the FSM. Edges indicate potential transitions
    between states (which is based on past communications between users). In the beginning
    of our simulations these will remain static, and we’ll be examining the network
    as it exists at the current point in time. (In the proof of concept for this chapter,
    the edges will change to simulate users making and severing connections within
    the network.) Finally, the input alphabet, which defines valid actions for the
    available transitions, models interactions between nodes (for example, one user
    passing the message to another). Defining inputs and transitions for the FSM is
    similar to defining what are valid choices and when. For the first question, which
    deals with information transmitted between nodes, the input alphabet is [*Send*,
    *Pass*], representing the two actions a user may take when they receive a piece
    of information.
  prefs: []
  type: TYPE_NORMAL
- en: To start, we’ll define the initial state *S*[0] as the node with the highest
    out-degree holding the message, so the simulation has the best chance of reaching
    a large number of unique nodes on different simulations. Later, we’ll measure
    the effect of starting from different nodes. The node holding the message at any
    given moment is *u*(*q*).
  prefs: []
  type: TYPE_NORMAL
- en: 'At each step in a random walk, the node *u*(*q*) uniformly selects one of two
    possible inputs Ξ = [*Send*, *Pass*]. The a priori probability of an input being
    selected is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06004.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Pr* (Ξ[*(Send)*]) denotes the probability of *Send*. If *u*(*q*) chooses *Send*,
    *q* is passed to a uniformly selected neighbor of *u*(*q*) (I still denote the
    neighbors of a node as Γ[*(u)*]). If *Pass* is chosen, *u*(*q*) does nothing for
    that step.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The a priori probability of a given neighbor *v* being selected is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06005.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here v ∈ Γ(u(q ) ). Simply put, this means the starting probability for each
    neighbor is equal. The larger the number of neighbors a node has, the lower the
    probability of any one neighbor receiving the message next. For example, if *u*(*q*)
    has three neighbors (|Γ(u(q))| = 3), then ![m06006r](image_fi/502567c06/m06006r.png).
    You could also write this as a conditional probability (*Pr*(*A*|*B*)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06007.png)'
  prefs: []
  type: TYPE_IMG
- en: The formula states that the probability of a particular neighbor receiving the
    message, given the input is *Send*, is 0.33, or 33 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The overall probability of a message propagating without presuming that *Send*
    is the selected input is defined in the numerator of the previous equation. Intuitively,
    you can think of this as the probability of each event occurring in isolation.
    More properly, the independent probability of a message propagating forward to
    a given neighbor of *u*(*q*) (assuming three neighbors) is:'
  prefs: []
  type: TYPE_NORMAL
- en: Pr (u(q) → v ) = Pr ( Ξ( Send ) ∧ v(q) ) = 0.5 × 0.33 = 0.165
  prefs: []
  type: TYPE_NORMAL
- en: Before we generate random walks, we need to set up the simulation, as shown
    in [Listing 6-1](#listing6-1).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-1: The initialization code for the Monte Carlo simulation'
  prefs: []
  type: TYPE_NORMAL
- en: The code relies on the graph *G* being populated using the method back in Listings
    5-2 and 5-4. Assuming the graph *G* has already been populated, we start with
    the input alphabet `XI`, which represents *Send* as expected and *Pass* using
    `None` ❶; the number of simulations, `k` ❷; and the number of steps in each simulation,
    `n`. To set the start state `S0` ❸, we select the node with the highest out-degree.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing from [Listing 6-1](#listing6-1), [Listing 6-2](#listing6-2) shows
    a deterministic, uniformly random implementation of the message-passing Monte
    Carlo simulation algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-2: A deterministic message-passing Monte Carlo simulation'
  prefs: []
  type: TYPE_NORMAL
- en: First, we initialize the results list `R` ❶, and then we use nested `for` loops
    24 to perform `k` random walks with up to `n` steps in each.
  prefs: []
  type: TYPE_NORMAL
- en: Each walk begins with the message at the node `S0` ❸. At each step, we gather
    the neighbors for the currently selected node ❺. If exactly one neighbor exists,
    this neighbor is automatically selected. However, if more than one neighbor exists
    ❻, we select one uniformly at random using the `choice` function, then update
    the `message_at` variable. If the message ever reaches a node with no out-degree
    ❼, we record the node as the result and conclude the walk with `break`. At the
    end of each walk, we append the terminating node `Tn` to the results list ❽.
  prefs: []
  type: TYPE_NORMAL
- en: We summarize the likely *information flow distance*, or *IFD* (![m06008](image_fi/502567c06/m06008.png)),
    as the mean number of unique nodes (disregarding the starting node) in each path
    ❾, then normalize the IFD by the total number of nodes in `G` (again, disregarding
    the starting node) ❿ and print it out to the screen. The `unique` function simply
    takes the path and reduces it to only unique entries. (You can see how I implemented
    it in the 2nd cell of the *MonteCarloSimulations.ipynb* notebook in the chapter’s
    supplemental materials. You can also choose to use one of the library’s versions
    of the code, such as NumPy’s `unique`.)
  prefs: []
  type: TYPE_NORMAL
- en: If you run the code in [Listing 6-2](#listing6-2) a few times, you’ll notice
    the output isn’t consistent. While *S*[*0*] is deterministic, the route from there
    is stochastic. You could edit this model to be entirely deterministic by replacing
    the `vq = choice(gamma_uq)` call with a deterministic selection method, such as
    always passing *q* to the neighbor of *u*(*q*) with the highest out-degree. This
    would be a good option to model a specific behavior pattern that’s known in advance.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement the simulation with a biased walk instead of a uniformly random
    walk, you can add another element to `XI` that is the same as one already present.
    By doing so, you change the relative probabilities of each input variable being
    selected. For example, adding another `"send"` to the list will weight *Send*
    to twice as likely as *Pass*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06009.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For more fine-tuned control over the probability (bias) of each input, switch
    out the simple `choice` function for one that can process a dictionary of `{action:
    probability}` definitions. (See the proof of concept at the end of the chapter
    for an example.)'
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations, you’ve now defined your first predictive model using Monte
    Carlo simulations! This is a simplistic model where we rely on uniform selection
    for randomness and some basic actions, like send and pass, to describe what might
    occur to some arbitrary message on our network. Try starting the message from
    different users and see how it impacts the number of steps the message travels
    and where it ends up. We refer to this as a *naive model*, because we didn’t include
    any specific information about the history of the network, message contents, or
    user preferences. We assume each node is equally likely to send any message to
    any other node it can contact. While simplifying assumptions like this make the
    code easier to write and interpret, they do so at the expense of accuracy. In
    the next section, we’ll extend our model to incorporate more details about the
    message and users to more accurately predict the probable flow of information
    given what we’ve already witnessed about data flow in the network.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling Topic-Based Influence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To answer the question “Which nodes are being influenced by other nodes?” we’ll
    extend the investigation of topic-based influence from [Chapter 5](c05.xhtml).
    Recall that we previously weighed each user’s potential interest in a topic by
    measuring their interaction with other messages containing the same topic, using
    the Hyperlink-Induced Topic Search algorithm (HITS). If we reframe our current
    model with respect to a given message topic, like the environment, we can incorporate
    hub and authority information into our state machine model to control the information
    exchange probability. In this case, we’ll use a user’s HITS score to determine
    the probability of a message being reblogged based on the message’s content, instead
    of just blindly assuming all messages have the same probability for all users
    all the time.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling message propagation in this fashion assumes that a user is more likely
    to reblog a message similar to a message they have reblogged previously. Users
    who have reblogged posts involving a given topic get a higher authority score
    for that topic than those who haven’t, which translates to a higher probability
    of receiving a message about that topic. If you think about the content you see
    on people’s social network feeds, you’ll probably see a fairly common theme among
    the information they share and reshare (this is one of those assumptions you may
    want to challenge later). Some people choose to share business news; others, arts
    and entertainment; and still others, security.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s update the previous implementation to compare the spread of different
    message types (*qx*) so we can examine the interests of different users and predict
    what messages they’re most likely to reblog in the future. If you were designing
    a viral message attack for this network, it would make sense for you to examine
    different topics and choose the one with the highest probability of propagating
    farthest through the network. From a defensive perspective, you can flip this
    analysis and track a malicious message back to the probable source. We’ll be keeping
    the same definition of influence between users (so a user reblogging a message
    is influenced by that message to some degree), but instead of using the *Send*
    action, our nodes will be selecting messages to reblog. Nothing about the action
    changes, so I’ve opted to keep the name, but renaming it might help to keep the
    direction of influence clear in your model.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 6-3](#listing6-3) shows the code to run a topic-based message-passing
    Monte Carlo simulation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-3: A topic-based message-passing Monte Carlo simulation'
  prefs: []
  type: TYPE_NORMAL
- en: 'This code prints a tuple of `(S0, {node: termination_count})`, using the same
    values for `k` and `n` defined in [Listing 6-1](#listing6-1), as well as the `term_subgraph`
    function ❶, which is based on code you’ll see later in [Listing 6-5](#listing6-5).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this simulation, *S*[0] ❷ is the node with the highest hub score for the
    selected topic (*S*[0] = *max*(*hub*(*qx*)(*G*))), and *Pr* (Ξ[*(Send)*]) is the
    hub score of *u*(*q*) for the message type *x*: *Pr* (Ξ[*(Send)*]) = *hub*[*(qx)*](*u*).
    The `hub_send` function (defined in the *graph_funcs.py* file, provided in the
    book’s supplementary materials) takes the hub score of `uq` and returns whether
    `uq` passes the message on ❸. The `hub_send` function is based on another function,
    `weighted_choice`, which is also included in the *graph_funcs.py* file. There
    are still only two possible actions in Ξ, so the probability of *Pass* is equal
    to 1 minus the probability of *Send*: *Pr* (Ξ[*(Pass)*]) = 1 – *Pr* (Ξ[*(Send)*]).
    The probability for selecting a given neighbor is the normalized authority score
    for that neighbor, given the message type *qx* (*Pr*(*v*(*qx*)) = *auth*(*qx*)(*v*)).'
  prefs: []
  type: TYPE_NORMAL
- en: If the message is sent, we select the neighbor using the `scored_neighbor_select`
    function (also defined in the *graph_funcs.py* file and based on the `weighted_choice`
    function) ❹. If a neighbor is returned, we add the edge between the sender and
    recipient to the path `Tn` and update the message location ❺; otherwise, we terminate
    the simulation with the `break` statement.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we assume a message ending at a node imparts some influence, we can count
    how many times a message ends at a particular user and claim that the node with
    the highest count is most likely to be influenced by the given message type from
    the given user. This intuitively means that the user would likely end up reblogging
    the message at some point. All roads lead home, so to speak. To find this node,
    we loop over the ending locations and tally the results to build the `{node: termination_count}`
    dictionary ❻, then print the results. This constitutes one run of the Monte Carlo
    simulation.'
  prefs: []
  type: TYPE_NORMAL
- en: We want to collect several runs and average the results for the most accurate
    predictions, so we wrap the code in a function definition called `run_sim_2`,
    which will take in the topic list and the Mastodon post data as parameters. (You
    can see the `run_sim_2` function in the 4th cell of the *MonteCarloSimulation.ipynb*
    notebook.) Finally, we return the source node and the dictionary containing the
    users at whom the message terminated, so we can collect the results until we’re
    ready to analyze them. Let’s call this newly defined function in a loop to collect
    a reasonable sample size. [Listing 6-4](#listing6-4) shows how to collect the
    samples and average them for the final output.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-4: Averaging the Monte Carlo simulation results'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the results from averaging 10 runs of the simulation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Using these results, we could claim that the user `gutierrezjamie` is most likely
    to influence `hartmanmatthew` on the topic of environment. What’s important here
    isn’t the numbers themselves but the relative sizes of the numbers, so you might
    also conclude that `shannon42` is three times more likely than `grosslinda` to
    end up reblogging the message. Of course, this is just the result of one small
    group of simulations. Ten simulations on a topic as complex as information flow
    and influence is hardly definitive. To strengthen this claim of influence, repeat
    the simulations some large number of times by increasing *k* (using the statistical
    method mentioned earlier) and average those results. In general, the more possible
    outcomes for the simulation, the more times it should be run. There’s a point
    of diminishing returns to this, though. You’ll want to experiment with different
    simulation counts and lengths by updating the values for *k* and *n*, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The last part of the code we’re going to examine is the `term_subgraph` function,
    which we called in [Listing 6-3](#listing6-3). The function in [Listing 6-5](#listing6-5)
    takes in a term of interest and searches the underlying data to find all relevant
    posts.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-5: Defining the subgraph based on terms'
  prefs: []
  type: TYPE_NORMAL
- en: The function takes in the term we’re interested in searching for and the `post_df`
    `DataFrame` object we defined previously. Using the `str.contains` function, we
    filter the data down to only rows whose text column contains the search term.
    We then collect the replies to these posts by searching the `in_reply_to_id` column
    for any relevant post IDs, storing them in a `DataFrame` called `dat_replies`.
    Next, we define the `DiGraph` object that will hold the resulting graph data and
    store it in a variable named `hG`. We loop over the `dat_replies` index list,
    and, for each entry, we look up the row associated with the index. We use the
    row’s `in_reply_to_screen_name` and `user_screen_name` to create an edge in the
    graph, showing the direction of influence on the topic of interest. Once we’ve
    completed the loop, we return the completed subgraph.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve defined all the basic code we’ll need, we can start to improve
    upon our simple model. In the next section, we’ll cover how to make our message
    behave more realistically through resource allocation.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling Information Flow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So far, our simulation treats the message like a single object moving from
    node to node, like a package being delivered to an address. But what about the
    cases where a message may be transferred to multiple users simultaneously? Our
    model is fine for single copies of messages, but it’d be nice if we could find
    a way to model the information more intuitively as flowing through the network
    instead. Think about it like this: you don’t send one birthday party invitation
    and ask each invitee to pass the message on to the next person on the list; you
    send multiple invitations to the people you want to attend. Each invitee may then
    invite another person to go to the party with them, so the message spreads even
    further along the network simultaneously. To model this type of information flow,
    we need to improve our state machine to treat the message as if multiple copies
    exist.'
  prefs: []
  type: TYPE_NORMAL
- en: To simulate the case where more than one copy of *q* can exist, we can reformulate
    message passing as a question of resource flow within the network. By doing so,
    we can figure out how much information two people have communicated in the past
    and use that as an indicator of how much they may communicate in the future. *Resource
    allocation (RA)* is a model that was first posed to describe the nonlinear correlation
    between airport connectivity and travel capacity.^([7](b01.xhtml#c06-endnote-007))
    We’ll be using the same principle as a way to quantify the quality of information
    exchange as the message spreads through the network.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally speaking, RA describes the potential flow of resources between two
    nodes (*u*, *v*) where *v* is not a neighbor of *u*, but they’re connected by
    a directed path (*v* ∉ *Γ*[(][*u*][)] ∧ ρ(*u*→*v*) ∈ *E*). Supposing a node *u*
    in a directed graph has one unit of resources to distribute evenly among all its
    direct neighbors, the resources allocated to any member of the network is the
    sum of the resources at the end of each path between *u* and *v*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06010.png)'
  prefs: []
  type: TYPE_IMG
- en: You can think of this value as the importance of node *v* in the case of distribution
    for node *u*. If |ρ(*u*, *v*)| > 2, this process is repeated for all nodes between,
    until some amount of resource reaches *v*. Therefore, you might instead wish to
    think of this value as the amount of resources *u* provides to *v* through the
    distribution network.
  prefs: []
  type: TYPE_NORMAL
- en: As a concrete example, suppose you’re investigating a criminal organization
    that sells counterfeit goods it purchases from a forger. The boss of this hypothetical
    organization buys 100 boxes of knock-off handbags (the initial amount of resources
    at *S*[0]). He then distributes the merchandise to his top 4 lieutenants by dividing
    the 100 boxes into 25 boxes for each. Finally, each lieutenant divides their 25
    boxes among their street corner shops. If each lieutenant has connections to 5
    storefronts, each store would get 5 boxes. If the crime boss were to lose one
    of these stores, the loss would account for only 5 percent of his inventory. This
    is a very simplistic model that assumes each node and path can evenly carry the
    resource in question. However, that’s not always the case.
  prefs: []
  type: TYPE_NORMAL
- en: Formally, the ![m06011](image_fi/502567c06/m06011.png) portion of the previous
    formula is known as the *flow function*, which models a specific type of behavior
    for passing or receiving resources. Using this flow function, the resource gets
    divided evenly among all the neighbors of the node *u*, the same as the boxes
    of counterfeit goods. There are a few different flow functions built into NetworkX.
    Unfortunately, they’re not implemented for directed graphs as defined here. As
    you shift from research to applications, you’ll often be responsible for extending
    your code libraries with missing definitions like this. The *graph_funcs.py* file
    includes the code for directed resource allocation, so you can use it to experiment.
  prefs: []
  type: TYPE_NORMAL
- en: By combining the historical analysis of the HITS algorithm with the simultaneous
    flow of resource allocation, we can create a respectable model, capable of simulating
    user behavior based on previous observations. You should be able to build on this
    framework of state machines and Monte Carlo simulation to model all sorts of interesting
    phenomena, not just in social networks but throughout the topic of information
    security as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll move on to a proof-of-concept application that will
    take us deeper into applied game theory and Monte Carlo simulation by simulating
    an adversarial face-off on our social network platform. Let’s get ready to rumble!
  prefs: []
  type: TYPE_NORMAL
- en: 'The Proof of Concept: Disrupting the Flow of Information'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The final question for this chapter—“What links could be severed to disrupt
    the flow of information between two nodes?”—is a very interesting security topic.
    There are many scenarios in which disrupting the flow of information to a particular
    subset of nodes could be catastrophic. Imagine a hospital tied to a single source
    of electricity. To disconnect any outlet in the hospital from electricity, you’d
    only need to sever the single link between the hospital and its power source.
    This is a *single point of failure*, and to avoid it hospitals deploy multipoint
    connections to the power grid and install backup generators for more severe disruptions.
    Many home networks suffer from this design flaw as well. To sever all the connected
    devices behind the router, you simply need to sever the connection forward of
    the router. In social networks, like businesses, failure points like these occur
    regularly. Companies often have people known as “linchpin employees”^([8](b01.xhtml#c06-endnote-008))
    who fill roles no other employees can, or possess arcane knowledge the company
    needs to operate. Linchpin employees inspired the proof of concept for this chapter:
    Monte Carlo simulations to model the potential to disrupt information flow within
    an evolving social network.'
  prefs: []
  type: TYPE_NORMAL
- en: For the rest of this chapter, we’ll be building a simulation where our social
    network is under attack from a nefarious outsider. We’ll use some of the same
    analysis techniques that gave birth to the modern internet to see how difficult
    it would be to disrupt our social network. Sometimes it’s fun to be the bad guy!
  prefs: []
  type: TYPE_NORMAL
- en: Modeling an Evolving Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In a static network, you could find the set of edges that, when removed, would
    separate two nodes (you’ll see a method for producing this list in a moment),
    but that doesn’t account for network adaptations, like cross-training another
    employee in the linchpin employee’s arcane knowledge to alleviate a single point
    of failure. To model an evolving network, we’ll mimic a two-player, turn-based
    game scenario, wherein one player tries to get a message through from a starting
    user to an end user as their adversary tries to stop the message from reaching
    the end. To make the game more complex, the network itself evolves on each turn
    as users reblog messages from other users or disconnect from people who were previous
    connections. Player 1 acts on the part of the network and all its users, while
    player 2 acts as the adversarial force. Player 1’s goal is to send a message *u*
    from a source node (*u*A) to a sink node (*v*[Ω]). Player 2 seeks to keep this
    message from reaching the sink node by selectively removing paths from the network.
    The game play is broken up into three phases: network adaptations, message movement,
    and finally adversarial movement (in that order).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The game is over if *q* reaches *v*[Ω], or when no path exists to complete
    the transmission:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06012.png)'
  prefs: []
  type: TYPE_IMG
- en: This equation can be translated into the convenient helper function in [Listing
    6-6](#listing6-6).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-6: Checking for terminal conditions'
  prefs: []
  type: TYPE_NORMAL
- en: This function takes in the graph object, the ID of the node currently holding
    the message, and the ID of the goal node. If these two nodes aren’t the same and
    there’s a path between them ❶, the game isn’t over, so the code returns `None`
    (as in no winner). If the two nodes aren’t equal and there’s no path between the
    current node and the goal node ❸, player 2 has succeeded in isolating the message,
    and the function returns `-1`. If the two IDs match ❷, the message has reached
    the goal node, so the function returns `1`.
  prefs: []
  type: TYPE_NORMAL
- en: Moving the Message Through the Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The second helper function, `weighted_choice`, shown in [Listing 6-7](#listing6-7),
    will be used for weighted random selection of the next node to a receive the message.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-7: Weighted random selection function for biased walks'
  prefs: []
  type: TYPE_NORMAL
- en: 'The input parameter `scores` is a dictionary of `{item: weight}`, giving each
    item that may be selected and its weight. (The weights do not need to sum to 1;
    only the relative size of the values matters.) The `totals` list partitions the
    real number space between 0 and the sum of the weights (![m06013](image_fi/502567c06/m06013.png))
    into bins proportional in size to the weight of the item they represent, by adding
    each item to a `running_total`, then recording the running total after each item
    is added ❶. The sum of all the weights then scales a random value ❷ to fall into
    one of the bins, and the bin determines which item is selected ❸. Items with larger
    weights map to larger bins, meaning the items are more likely to be selected,
    hence “weighted random selection.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a concrete example, take an input dictionary `{"A":1,"B":2,"C":3}`. After
    the first loop executes, the `totals` list contains `[1,3,6]` and the `running_total`
    is `6`. The random real value `rnd` (between 0 and 1) is selected using the `random`
    function, then multiplied by `running_total` ❷ to produce the percentage of the
    weight randomly selected. The random value `1.0` means the maximum weight, in
    this case:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06014.png)'
  prefs: []
  type: TYPE_IMG
- en: We can verify that the break points accurately reflect our input weights by
    calculating the amount of space on the number line assigned to the key, called
    its *key space*. These should equate to 1 / 6 = 0.166, 2 / 6 = 0.333, and 3 /
    6 = 0.5 for keys `A`, `B`, and `C`, respectively. We find the key space by subtracting
    the key’s lower selection boundary from its upper selection boundary. To select
    key `A`, `rnd` must be lower than or equal to approximately 0.166 (0.166 × 6 =
    0.996). To select key `B`, `rnd` needs to be between 0.166 and 0.5 (0.5 × 6 =
    3), which means the key space for `B` is (0.5 – 0.166 = 0.333). We can divide
    `B`’s key space by `A`’s to get a relative size comparison (0.333 / 0.166 = 2.006),
    which means the key space for `B` is twice the size of the one for `A`, just as
    we requested. Finally, `rnd` needs to be greater than 0.5 and less than or equal
    to 1.0 for key `C` to be selected. The key space for `C` is (1 – 0.5 = 0.5). You
    can continue the key space logic to prove that the space provided to `C` is three
    times the space provided for `A` (0.5 / 0.166 = 3.0) and one and a half times
    larger than the key space for `B` (0.5 / 0.333 = 1.5). I hope this helps to illustrate
    how the values in our input dictionary control the size of the key space created
    during the random selection process. We’ll be relying heavily on the `weighted_choice`
    function during our proof, so it’s worth taking the time to understand it in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the Amount of Information Flow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some connections between nodes in a network may be capable of carrying more
    information than others. In a social network, for example, some members may be
    more effective at spreading information, like a linchpin employee at a company.
    The amount of information flow between two nodes in a social network isn’t straightforward
    to measure, and depends on your research question. For the purposes of our simulation
    game, the edge capacity is the number of characters in a given post (maximum 500,
    at the time of writing).
  prefs: []
  type: TYPE_NORMAL
- en: By adding an attribute named *capacity*, which represents the maximum amount
    of information that can be transmitted along the particular edge in one unit of
    time, to the edges in *E*, we can compare the effect of removing different subsets
    of edges on the overall flow and capacitance of the network using the *max-flow,
    min-cut theorem*.^([9](b01.xhtml#c06-endnote-009)) We’ll take a deeper look at
    this theorem when we improve player 2, but for the moment just know that it allows
    us to model a resource that gets spread out across a network, rather than moving
    from point to point as we’ve seen previously.
  prefs: []
  type: TYPE_NORMAL
- en: Now is a good time to step back and remember why this matters to us. Our ultimate
    goal is to test how difficult it would be for an adversary to significantly disrupt
    the communication of the network. The max-flow, min-cut theorem gives us the information
    needed to test if two nodes can still communicate (because there’s still a path
    between the two nodes). It also helps us determine what cuts are more or less
    advantageous for the adversary, as well as giving them a way to quickly judge
    their options. An attacker who knows the max-flow, min-cut theory will likely
    have a much higher chance at sabotaging the network than one who attacks random
    communication channels. We’ll examine this hypothesis by implementing two versions
    of the adversary in the following game and comparing the damage they can achieve.
  prefs: []
  type: TYPE_NORMAL
- en: How the Game Works
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The game is actually very simple. The objective for player 1, the white hat,
    is to get a message from a node on one side of the network to a node on the other
    side. To achieve this they have the entire network at their disposal. On each
    turn, they will move the message around the network trying to reach the sink node.
    They win if the message successfully traverses the network from the source node
    to the sink node. On the other side of the virtual table is player 2, the black
    hat. Their job is stop that message, at any cost. On each turn, they’ll select
    an edge to remove from the network. Player 2 wins if they successfully disconnect
    the network so that there’s no way the message can reach the sink node.
  prefs: []
  type: TYPE_NORMAL
- en: Evolving the Network
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Social networks rarely have a static topography: the links and membership are
    changing even as you try to measure them. The network adaptation phase models
    the evolving topography by allowing edges to be created or removed probabilistically.
    This means that new routes may open up suddenly and old paths may disappear on
    their own. Neither player can fully trust the network to do what they expect it
    to. I chose to implement this as part of player 1’s turn since they’re the network
    administrator in this scenario. On each turn, player 1 chooses an input action
    from the input alphabet for every node that’s not holding the message (∀*u*^((¬)^(*q*)^)
    ∈*V wrs*(Ξ), where *wrs*(Ξ) is the weighted random selection function defined
    previously). [Listing 6-8](#listing6-8) shows the weighted input alphabet, which
    includes the creation and dissolution of edges with `connect` and `disconnect`,
    or the option to `pass` as before.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-8: Weighted inputs for nodes without the message'
  prefs: []
  type: TYPE_NORMAL
- en: The weights in `XI` describe the tendency of the network over time. These values
    create a scenario where the network is likely to grow over time since `connect`
    and `pass` both have an individual weight of 40 percent (2 / 5 = 0.4), a combined
    80 percent of the selection space, while `disconnect` has only 20 percent. If
    `connect` is chosen, the node forms a new edge with (meaning it receives a reply
    from) another node in the graph, which means we need a way to select the user
    they connect to. I’ve chosen to implement this based on *preferential attachment*,
    the idea that users with many connections are more likely to form new connections
    than those with fewer connections. In our network, this means that nodes that
    receive replies from many other users (large out-degrees) are more likely to receive
    a reply from users who reply to many users (high in-degrees). (Even if the current
    node doesn’t tend to receive many replies, it’s still more likely to get a reply
    from a more active user.)^([10](b01.xhtml#c06-endnote-010))
  prefs: []
  type: TYPE_NORMAL
- en: 'Formally, the *undirected preferential attachment (UPA)* score for two nodes
    (*u*, *v*) is the product of the length of their neighbors:'
  prefs: []
  type: TYPE_NORMAL
- en: UPA( u, v ) = |Γ( u )| × |Γ( v )|
  prefs: []
  type: TYPE_NORMAL
- en: 'To account for the directionality of our network graph, we can define *directed
    preferential attachment (DPA)* using outgoing neighbors of *u* and incoming neighbors
    of *v*:'
  prefs: []
  type: TYPE_NORMAL
- en: DPA( u → v ) = |Γ( u → )| × |Γ( v ←)|
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 6-9](#listing6-9) shows the weighted random connection function, which
    will be called from the player 1 logic shown in [Listing 6-12](#listing6-12).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-9: A directed preferential attachment weighted random selection'
  prefs: []
  type: TYPE_NORMAL
- en: 'The function `wrs_connect` takes the graph and the connecting node as input
    and loops over each ID in the graph ❶ to calculate the DPA score ❷ between the
    input node and each other node (skipping the input node with `continue`). The
    `weighted_choice` function uses the `scores` dictionary to pick a node to connect
    to ❸:'
  prefs: []
  type: TYPE_NORMAL
- en: vconn = wrs( [ DPA( u( ¬ q ), ¬ u )] ∀ ¬ u ∈ V )
  prefs: []
  type: TYPE_NORMAL
- en: If `disconnect` is chosen, the user disassociates from another user who sends
    them the least information (as measured by the definition of capacity given previously).
    The `capacity` attribute of each edge in `G.in_edges` is used in the weighted
    random selection process to choose a neighbor to disassociate from. [Listing 6-10](#listing6-10)
    shows the code to calculate the capacity and selection weight for a given node.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-10: Capacity weighting for a node'
  prefs: []
  type: TYPE_NORMAL
- en: 'We start by looping over the neighbor data from the set of inbound edges for
    the node ❶ and collecting these into the `n_capacity` dictionary. If we hadn’t
    condensed the multiple edges previously (by using a `DiGraph` instead of a `MultiDiGraph`),
    we’d need to sum up the capacity of each in-edge incident to the node first:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06015.png)'
  prefs: []
  type: TYPE_IMG
- en: We weight edges with lower *N*[*capacity*] entries more heavily in the selection
    process, then invert the capacities by subtracting them from a modifier *Q* =
    1 + *max*(*N*[*capacity*] ) ❷, which results in the weighting formula ![m06016](image_fi/502567c06/m06016.png)
    ❸.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if *max*(*N*[*capacity*]) = 10 ⇔ *Q* = 11, an edge with ![m06017](image_fi/502567c06/m06017.png)
    will get a weight of `1` (![m06018](image_fi/502567c06/m06018.png)), while an
    edge with ![m06019](image_fi/502567c06/m06019.png) will get a weight of `10` (![m06020](image_fi/502567c06/m06020.png)).
  prefs: []
  type: TYPE_NORMAL
- en: We’ll set the return value for a given node to the tuple (*N*[*capacity*] ,
    *N*[*weight*] ). Both `n_capacity` and `n_weight` are dictionaries keyed off of
    the neighboring node’s ID. The `wrs_disconnect` function in [Listing 6-11](#listing6-11)
    uses the `n_weight` dictionary to select the least informative neighbor to disconnect
    `u` from.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-11: A weighted random disconnection function'
  prefs: []
  type: TYPE_NORMAL
- en: If there are no inbound edges for the node `u` (meaning it has no in-degree
    neighbors to disconnect from) the function returns `None` ❶, resulting in the
    same outcome as `pass`. If more than one edge is found, the capacity scores for
    all the inbound neighbors are calculated using the function from [Listing 6-10](#listing6-10)
    ❷. The key returned from this function is the neighbor to disassociate from (*v*[*disconn*]
    = *wrs*(*N*[*weight*] )) ❸. The edge (*u*^((¬)^(*q*)^) ← *v*[*disconn*] ) is then
    removed from the graph in the player 1 logic in [Listing 6-12](#listing6-12).
  prefs: []
  type: TYPE_NORMAL
- en: Moving the Message
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: After the network evolution phase, the game moves into the message movement
    phase, where the only possible input is `send`. If an edge exists between the
    node currently holding the message, *u*(*q*), and the goal node, *v*[Ω], the message
    passes along that edge and player 1 wins the game. Otherwise, the paths between
    *u*(*q*) and *v*[Ω] are calculated, and the message is passed to the next node
    along one of these paths, selected uniformly at random.
  prefs: []
  type: TYPE_NORMAL
- en: The code in [Listing 6-12](#listing6-12) handles player 1’s turn, which includes
    both the network adaptations and message movement phases. The function `player_one_turn`
    takes the graph, the node holding the message, and the goal node as parameters
    and returns the node that receives the message and the new state of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-12: The logic defining player 1’s turn'
  prefs: []
  type: TYPE_NORMAL
- en: If an edge exists between `uq` and the goal node `omega` ❶, we pass the message
    to `omega`. This will end the turn (and game) with a victory for player 1! Otherwise,
    we calculate the average capacity of the graph ❷, which will be used as the capacity
    of any new edges added during network adaptation. This allows the average to change
    from turn to turn, depending on which edges (if any) were removed during the previous
    network adaptation phase.
  prefs: []
  type: TYPE_NORMAL
- en: To perform network adaption and message passing, we loop over each node in the
    graph ❸. For *u*(*q*), we attempt to find valid paths between it and the goal
    node ❹ (the message movement phase). If this attempt fails with an `nx.exception.NetworkXNoPath`,
    the function returns and the round ends with a victory for player 2, since the
    message can’t reach the destination. Otherwise, we randomly select a path using
    the `choice` function ❺ and pass the message to the first node in this path.
  prefs: []
  type: TYPE_NORMAL
- en: For all other nodes, we select an action using the weighted random function
    and the `XI` dictionary defined in [Listing 6-8](#listing6-8) ❻. If `pass` is
    chosen, the code jumps to the next node using the `continue` keyword ❼. If `connect`
    is returned, we use the `wrs_connect` function shown in [Listing 6-9](#listing6-9)
    to form a new edge ❽. Otherwise, `disconnect` was chosen, so we use the `wrs_disconnect`
    function from [Listing 6-11](#listing6-11) to remove an edge from the graph ❾.
    Finally, we return the receiving node and the updated graph ❿.
  prefs: []
  type: TYPE_NORMAL
- en: Disrupting the Network
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Player 2 then gets to select an edge to remove from the network to try to disrupt
    the flow of the message. One of the strengths of Monte Carlo simulation is in
    its ability to compare different strategies over time. To illustrate this, let’s
    compare two strategies for player 2 to achieve their goal. In the first strategy
    ([Listing 6-13](#listing6-13)), player 2 selects an edge from *E* uniformly at
    random:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-13: The player 2 random implementation'
  prefs: []
  type: TYPE_NORMAL
- en: This will act as a good baseline, since it most closely resembles a truly random
    walk. The code randomly selects ❶ and then removes ❷ an edge from the graph; we
    then return the updated graph ❸.
  prefs: []
  type: TYPE_NORMAL
- en: The results of such a strategy can be seen as a null control, as if an adversary
    just blindly started removing things with no real concept of what they were impacting.
    We’ll look at the second strategy, where player 2 selects their moves to inflict
    the most damage using the flow information of the network, after we demonstrate
    the simulation using this simple strategy and gather our baseline network performance.
  prefs: []
  type: TYPE_NORMAL
- en: Once player 2 has finished selecting the edge to disrupt, the round is complete.
    If neither player has won, the next round starts and gameplay continues in this
    fashion until one of the players succeeds in reaching their objective.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll cover how to select the start and end nodes. In much
    larger networks (like the ones you’re likely to see in the wild), having methods
    for automating tasks like finding data will save you a lot of manual exploration
    before running your first simulation.
  prefs: []
  type: TYPE_NORMAL
- en: The Game Objective
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we tie this all together into a functional simulation, let’s look at
    the `shortest_path_scores` helper function, shown in [Listing 6-14](#listing6-14),
    which returns a list of average path lengths for all pairs of nodes that are not
    directly connected.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-14: Creating an average-length score for weighted selection'
  prefs: []
  type: TYPE_NORMAL
- en: The `for` loop ❶ calls the NetworkX function `nx.non_edges` to get a list of
    all possible node combinations not directly connected by an edge, checks that
    the two nodes *u* and *v* are different, and checks that one or more paths exist
    between the nodes. If any condition fails, we skip that pair of nodes with the
    `continue` keyword. Otherwise, we use the `nx.all_shortest_paths` function to
    make a list of all potential paths between the source and sink nodes at the start
    of the game ❷, then calculate the average path length ❸ and append it to the `pairs`
    list. Once all the pairs have been processed, we sort the results in descending
    order, based on the average path length first, then the ID of the node *u*, and
    finally the ID of the node *v* ❹.
  prefs: []
  type: TYPE_NORMAL
- en: In [Listing 6-15](#listing6-15) we’ll combine these scores with the `weighted_choice`
    function to randomly select the source and sink pair while favoring pairs that
    have more, or longer, paths than those with fewer, shorter ones. I chose this
    method so the simulation has enough routes to make it interesting. You may choose
    the source and sink nodes based on other parameters in your simulation. You might
    even extend your simulation to test all possible combinations of source and sink
    node.
  prefs: []
  type: TYPE_NORMAL
- en: The Game Simulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, it’s time to tie all these functions together into a single cohesive
    game with the code in [Listing 6-15](#listing6-15). We’ll run the game simulation
    25 times, each with a different pair of source and sink nodes. Each run will generate
    *k* random walks, representing one game between player 1 and player 2 per walk,
    and tally the number of wins for each player. The average of the *k* scores is
    the score for the run overall. Using different source and sink nodes, instead
    of running the same scenario over and over, will give us a better sense of the
    network as a whole. The code in [Listing 6-15](#listing6-15) assumes you’ve already
    built the graph (using code similar to [Listing 6-3](#listing6-3)).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-15: The main game simulation function'
  prefs: []
  type: TYPE_NORMAL
- en: Before running the group of simulations, we get the list of average path lengths
    between nodes with `shortest_path_scores` ([Listing 6-14](#listing6-14)) ❶, convert
    the average path lengths returned into a list of `path_weights` (meaning nodes
    with longer average shorter path lengths get weighted higher), and select a pair
    of nodes (which is the key returned from `path_weights`) ❷. If that pair of nodes
    and associated paths have already been used in a simulation (tracked by the `played`
    list), we select another. From the selected pair and path, we set the source and
    sink nodes, `alpha` and `omega`.
  prefs: []
  type: TYPE_NORMAL
- en: Once we’ve found a valid source and sink pair, we perform the *k* random walks.
    Each iteration of the `for` loop ❸ constitutes one complete game, played on a
    copy of the graph (`newG`) to maintain the original topology between matches.
    Each *n*-step random walk ❹ generates up to *n* turns for both players 68 and
    checks the win condition at each phase 57. The result of each game is appended
    to `game_res`. Each iteration of this loop counts as one complete turn cycle within
    a game.
  prefs: []
  type: TYPE_NORMAL
- en: Once the *k* walks are complete, we tally the wins (1 point for a win by player
    1 and –1 point for a win by player 2) ❾ by summing `game_res`, then take the average
    `tally` as the overall score for the *k* walks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the code in [Listing 6-15](#listing6-15) to see the result of 25 simulations.
    The averages produced by each test (the outermost `for` loop) may vary wildly,
    as you can see from this snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: A score of `0.0` means both players won the same number of matches. Positive
    averages indicate player 1 won more often than player 2\. The closer to `+1` this
    gets, the more heavily the matches favored player 1\. The opposite is true as
    the score moves below 0\. An average score of `-1` indicates player 2 won every
    match.
  prefs: []
  type: TYPE_NORMAL
- en: The final step is to summarize the result from all the tests. We can do so by
    summing the individual averages and then dividing by the number of tests. We’ll
    call this the *population mean*. The benefit of the population mean is twofold.
    First, it summarizes all the tests into a single number you can interpret, rather
    than a list of test results. Second, the population mean should be relatively
    stable compared to the values observed between individual run results. If we rerun
    the code, we’ll get different individual test results. The population mean should
    be relatively stable, though.
  prefs: []
  type: TYPE_NORMAL
- en: When analyzing the model three times, I got the population averages 0.2160,
    0.2320, and 0.1808\. Of course in statistics we deal with uncertainty, so a better
    measure of the population mean is the numeric range we believe the actual population
    mean will fall between, given some desired level of confidence. To do this, we
    use the `scipy.stats.t.interval` function and pass in the results from our simulations
    and our desired confidence interval (called the *alpha parameter*) as a float.
    The result is a tuple containing the lower and upper bounds within which we can
    predict the true population mean will fall. For example, I ran the simulation
    6,250 times and I can say with 95 percent confidence the true population mean
    for the simulation (as it’s currently configured) will be between 0.1078 and 0.2225,
    which means there is a slight advantage to player 1\. The current design seems
    to slightly favor the defender because of its growth and the lack of intelligence
    from the adversary.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve established a baseline performance for our network, let’s see
    if we can improve the adversary’s chances by letting them observe the network
    and pick which routes to sever. We can then compare the results of the two simulations
    (in terms of predicted population means) and see if our changes significantly
    impact player 2’s chance at disrupting the network.
  prefs: []
  type: TYPE_NORMAL
- en: Improvements to Player 2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s see what happens if we give player 2 a little more intelligence. In this
    version, player 2 uses the updated graph and current message position to remove
    an edge that’s important to the path between the message position and the goal
    (a relatively intuitive strategy for human players).
  prefs: []
  type: TYPE_NORMAL
- en: To codify this strategy, player 2 will use the max-flow, min-cut theorem. A
    max-flow, min-cut analysis was one of the driving forces behind the creation of
    the modern TCP/IP internet. The protocol breaks messages into little chunks called
    *packets* and then chooses different routes for different parts of the transmission
    based on response times and carrying capacity. The basic idea of the design is
    that someone would have to take out a large percentage of the network before they
    could disconnect two distant nodes from each other. The list of nodes that would
    need to be removed is known as the *cutset*. The adversary in our simulation game
    will take advantage of the cutset information to carry out the exact type of attack
    Paul Baran, the inventor of packet-switching networks, was concerned with in his
    research ([https://www.rand.org/about/history/baran.list.html](https://www.rand.org/about/history/baran.list.html))—that
    is, the selective targeting and removal of communication channels to disrupt the
    network.
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, the max-flow, min-cut theorem tells us two key pieces of information.
    First, the max-flow portion describes the maximum amount of resources that can
    flow along all paths between two nodes (*u*, *v*). The min-cut section describes
    the minimum number of edges someone would need to remove from the network to sever
    all paths between the two nodes. More formally: given two nodes (*u, v*), the
    max-flow, min-cut theorem tells you the total capacity for the fewest set of edges
    you need to remove so there’s no path between the two nodes (the cutset). A cut
    is a graph partitioning *G*(*S*, *T*) such that *u* is in *S* and *v* is in *T*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The *capacity constraint* defined in the max-flow, min-cut theorem limits the
    volume flowing through each edge, per simulation step, to less than or equal to
    the maximum capacity of the edge:'
  prefs: []
  type: TYPE_NORMAL
- en: (u → v) flow ≤ (u → v) capacity
  prefs: []
  type: TYPE_NORMAL
- en: 'The *conservation constraint* of the theorem states the amount that flows into
    each node is equal to the amount flowing out:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/m06021.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once again, this can be restated more simply: every node sends out all the
    resources it receives; it doesn’t keep any for itself. This constraint applies
    to all nodes except *u*α and *v*[Ω] . In terms of our simulation, this means that
    any user who reblogs the message receives as much information as the post contains,
    and if someone then reblogs the message from them, that person also receives the
    same amount of information. The source and sink nodes are treated specially due
    to their position in the flow. The source node is like a faucet capable of adding
    a certain amount of resource to the network, so nothing flows into the source,
    only out. In our graph this is synonymous with a user who is likely to receive
    a lot of reblogs, but isn’t likely to reblog a lot themselves (nodes with high
    out-degree and low in-degree). Conversely, the sink node is like a sponge that
    absorbs some amount of information from the network without passing any on. Whatever
    information hits the sink node is absorbed there.'
  prefs: []
  type: TYPE_NORMAL
- en: The `nx.minimum_cut` function in [Listing 6-16](#listing6-16) uses the max-flow,
    min-cut theorem to determine the minimum cut value between two nodes (*u*, *v*)
    and the partition created by the cut, returned as a tuple (`cut_value`, `partition`).
    The `partition` is a tuple of (`reachable`, `unreachable`) nodes that indicates
    which nodes would be reachable and unreachable from *u*. Recall from the previous
    definition that a cut partitions the graph so that the two nodes are in separate,
    disconnected components if the cutset is removed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 6-16: Updating player 2 with more intelligence'
  prefs: []
  type: TYPE_NORMAL
- en: We start by computing the `cutset` between *u*(*q*) and *v*[Ω] ❶. To convert
    the `partition` tuple into the `cutset`, we loop over the pairs of neighbors in
    the `reachable` set ❷. For each node in the set, we loop over all their neighbors
    in the graph. If one of their neighbors is found in the `unreachable` set, then
    the edge(s) between the node in the `reachable` set and the node in the `unreachable`
    set belong to the cutset. Once we’ve processed all the nodes this way, we’ll have
    the list of all edges required to disconnect the two nodes. If there’s only one
    edge in the set, player 2 chooses this edge for removal ❹. Otherwise, player 2
    chooses an edge from the `cutset` uniformly at random, again relying on the `choice`
    function ❸.
  prefs: []
  type: TYPE_NORMAL
- en: 'This output shows the result of rerunning the simulation with the new strategy
    for player 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: After analyzing the modified player 2 in 6,250 simulations, I got a population
    mean of –0.8144 and can say with 95 percent confidence that the population mean
    for simulations with the modified player 2 is between –0.9484 and –0.6803\. When
    you run the code on your machine, you might see slightly different results (remember,
    we’re dealing with a lot of randomness), but the overall trend should remain consistent.
    It seems that this simple strategy changes the simulation to heavily favor player
    2, even with the network growth still favoring player 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s always a chance we’re erroneously claiming that we’ve improved player
    2’s chances. Since we can’t simulate every possible outcome, we can never be 100
    percent sure our population means are accurate. How, then, can we be sure this
    result isn’t due to some random fluke? The truth is, we can be sure only up to
    a certain point. We have to accept that we can’t know for certain. This brings
    up an important point: we need to think about how much risk we’re willing to accept
    of coming to an incorrect conclusion. When you perform an analysis in the wild,
    there are often real-world consequences for acting on incorrect conclusions. You
    should pick a confidence level that complements the amount of risk in the event
    that you’re wrong. The higher the risk, the higher confidence you should require.
    Once you’ve chosen your desired level of confidence, you can convert it into your
    t-test threshold by subtracting the desired confidence level from 100\. For example,
    I want to be very certain our result is not a fluke, so I’ll set the confidence
    level to 99 percent, which means we’re willing to accept a 1 percent probability
    of coming to an incorrect conclusion. We can now use this threshold to test our
    claim that we’ve improved player 2’s chance of winning.'
  prefs: []
  type: TYPE_NORMAL
- en: More formally, we can state the hypothesis that changing player 2’s logic has
    created a significant reduction in the population mean (*h*[1] = μ[0] > μ[1]).
    The null hypothesis, then, is that the random sample’s mean will be equal to or
    less than that of the modified player (*h*[1] = μ[0] ≥ μ[1]). We can compare the
    population mean of this set of results using a statistical method known as the
    *two-sample t-test*. This t-test quantifies the difference between the arithmetic
    means of the two samples. A common application is to test if a new process or
    treatment is superior to a current process or treatment. In our case, we’ll use
    it to determine if the difference between the two population means is significant
    enough to claim that our changed strategy for player 2 has in fact improved their
    chance of winning.
  prefs: []
  type: TYPE_NORMAL
- en: The proof of concept uses the `scipy.stats.ttest_ind` function to run this test.
    The result is an object with an attribute named `pvalue`. The p-value quantifies
    the probability of observing a value as or more extreme than the tested value,
    assuming the null hypothesis is true. We compare this number against our threshold
    of 1 percent to determine if we’re confident enough in the result to reject the
    null hypothesis. In this case I’ve run the test over a dozen times and every time
    the improved player 2 score is significantly low enough to support the claim that
    we are 99 percent sure the change we made to player 2 improved their chance of
    winning. We can visualize the two probability distributions as in [Figure 6-4](#figure6-4)
    to see just how big of an impact the change has had.
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/502567c06/f06004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6-4: Comparing probability distributions'
  prefs: []
  type: TYPE_NORMAL
- en: This graph shows the likelihood of all possible test outcomes for both the random
    and improved player 2 models. The light gray dotted line represents the baseline
    performance of the random player model. The dark gray continuous line is the performance
    of the improved player model. The large peak and steep drop-off around –0.8 shows
    that the improved player performed more consistently and could win most series
    by a large margin. In fact, it would be incredibly unlikely for any series of
    tests to average as high as –0.25 using the improved player 2 code. We can interpret
    this as an indication that the ability to selectively remove edges has the potential
    to highly disrupt the information flow within this network.
  prefs: []
  type: TYPE_NORMAL
- en: You can run the proof of concept using the command `python mcs_multiplayer.py`
    in the *Chapter 6* directory in the book’s supplemental materials. On each execution,
    the code runs a group of simulations for both player 2 types, then calculates
    the population means and compares them using the one-tailed t-test. It will output
    a line telling us whether or not we can reject the null hypothesis, and finally
    it generates a graph like the one in [Figure 6-4](#figure6-4) for analysis. As
    an exercise, try adjusting the weights in `XI` to more heavily favor new connections
    and see if this impacts the result to player 1’s benefit. What other changes could
    you make to player 1 to improve their ability to defend the network?
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The concepts introduced in this chapter—Monte Carlo simulations, finite state
    machines, random walks, weighted choice—combined with the foundational graph theory
    from the last three chapters make up an extremely flexible set of tools that go
    far beyond social network analysis. By defining finite state machines for simulations,
    analyzing repeated simulations to determine the likelihood of a particular outcome,
    modifying simulations to get different results and insights, and modeling how
    graphs may evolve over time, you can quantitatively assess security risks by modeling
    potential changes to the environment.
  prefs: []
  type: TYPE_NORMAL
- en: One scenario where I constantly find myself applying Monte Carlo simulations
    is in crowd flow dynamics. Predicting how people will move through an area, where
    they’ll gather, and how they might change that movement in response to different
    types of obstructions is one of the keys to planning effective physical security
    controls. We’ll discuss this a bit more in the context of the art gallery problem
    in [Part III](p03.xhtml), but you may already have some idea of how you could
    approach this task using what we’ve covered here.
  prefs: []
  type: TYPE_NORMAL
- en: This is just the beginning of Monte Carlo simulations, though. By changing the
    logic at each simulation step, you can model all kinds of unique behaviors in
    the network. Designing an appropriate simulation is as much an art as it is a
    science, so don’t be afraid to branch out and explore some wild simulation ideas.
  prefs: []
  type: TYPE_NORMAL
- en: To help you as you go forth, the Jupyter notebook that accompanies this chapter
    has code to display random walks in 2D and 3D, which you can use to visualize
    the simulations you develop. Often, seeing the results distributed visually can
    lead to interesting discoveries (like paths that always cross a single point).
    By combining the random walk display code with the animation code from the supplemental
    materials, you can even create a video of the simulation.
  prefs: []
  type: TYPE_NORMAL
- en: As you explore the related literature, you’ll find numerous advanced discussions
    of how to select a “best move” within the Monte Carlo simulation. As you saw in
    the proof of concept, small changes to parameters can have a drastic impact on
    the result. It’s important to be aware of the rationale and implications of each
    change to the model so that you can formulate more accurate assessments and draw
    well-founded conclusions about the networks you simulate.
  prefs: []
  type: TYPE_NORMAL
- en: You can learn more about GGP theory and algorithms from Stanford University’s
    online course ([http://ggp.stanford.edu](http://ggp.stanford.edu)). Several of
    these models lend themselves well to various information security tasks, such
    as risk analysis, budget planning, and incident response. If you’d like to learn
    more about information flow, check out the research paper “An Information Flow
    Model for Conflict and Fission in Small Groups,”^([11](b01.xhtml#c06-endnote-011))
    which describes a formal process for measuring information flow and detecting
    unbalanced sentiment in a social network.**
  prefs: []
  type: TYPE_NORMAL
