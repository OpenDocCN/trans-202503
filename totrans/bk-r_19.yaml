- en: '**16**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**COMMON PROBABILITY DISTRIBUTIONS**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/common-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In this chapter, you’ll look at a number of standard probability distributions
    that exist for dealing with commonly occurring random phenomena in statistical
    modeling. These distributions follow the same natural rules as the examples presented
    in [Chapter 15](ch15.xhtml#ch15), and they’re useful because their properties
    are well understood and documented. In fact, they are so ubiquitous that most
    statistical software packages have corresponding built-in functionality for their
    evaluation, and R is no exception. Several of these distributions represent an
    essential ingredient in traditional statistical hypothesis testing, which is explored
    in [Chapters 17](ch17.xhtml#ch17) and [18](ch18.xhtml#ch18).
  prefs: []
  type: TYPE_NORMAL
- en: Just like the random variables they model, the common distributions you’ll examine
    here are broadly categorized as either discrete or continuous. Each distribution
    has four core R functions tied to it—a `d`-function, providing specific mass or
    density function values; a `p`-function, providing cumulative distribution probabilities;
    a `q`-function, providing quantiles; and an `r`-function, providing random variate
    generation.
  prefs: []
  type: TYPE_NORMAL
- en: '**16.1 Common Probability Mass Functions**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ll start here by looking at definitions and examples of some common probability
    mass functions for discrete random variables. Continuous distributions will be
    explored in in [Section 16.2](ch16.xhtml#ch16lev1sec51).
  prefs: []
  type: TYPE_NORMAL
- en: '***16.1.1 Bernoulli Distribution***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *Bernoulli* distribution is the probability distribution of a discrete random
    variable that has only two possible outcomes, such as success or failure. This
    type of variable can be referred to as *binary* or *dichotomous*.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you’ve defined a binary random variable *X* for the success or failure
    of an event, where *X* = 0 is failure, *X* = 1 is success, and *p* is the known
    probability of success. [Table 16-1](ch16.xhtml#ch16tab1) shows the probability
    mass function for *X*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 16-1:** The Bernoulli Probability Mass Function'
  prefs: []
  type: TYPE_NORMAL
- en: '| ***x*** | **0** | **1** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Pr(*X* = *x*) | 1 – *p* | *p* |'
  prefs: []
  type: TYPE_TB
- en: From [Section 15.2.2](ch15.xhtml#ch15lev2sec134) you know that the probabilities
    associated with all possible outcomes must sum to 1\. Therefore, if the probability
    of success is *p* for a binary random variable, the only other alternative outcome,
    failure, must occur with probability 1 − *p*.
  prefs: []
  type: TYPE_NORMAL
- en: In mathematical terms, for a discrete random variable *X* = *x*, the Bernoulli
    mass function *f* is
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e16-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *p* is a parameter of the distribution. The notation
  prefs: []
  type: TYPE_NORMAL
- en: '*X* ∼ BERN(*p*)'
  prefs: []
  type: TYPE_NORMAL
- en: is often used to indicate that “*X* follows a Bernoulli distribution with parameter
    *p*.”
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the key points to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: • *X* is dichotomous and can take only the values 1 (“success”) or 0 (“failure”).
  prefs: []
  type: TYPE_NORMAL
- en: • *p* should be interpreted as “the probability of success,” and therefore 0
    ≤ *p* ≤ 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean and variance are defined as follows, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0332-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Say you use the common example of rolling a die, with success defined as getting
    a 4, and you roll once. You therefore have a binary random variable *X* that can
    be modeled using the Bernoulli distribution, with the probability of success ![image](../images/f0333-01.jpg).
    For this example, ![image](../images/f0333-02.jpg). You can easily determine,
    using (16.1), that
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0333-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and, in much the same way, that ![image](../images/f0333-04.jpg). Furthermore,
    you’d have ![image](../images/f0333-05.jpg) and ![image](../images/f0333-06.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: '***16.1.2 Binomial Distribution***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *binomial distribution* is the distribution of successes in *n* number of
    trials involving binary discrete random variables. The role of the Bernoulli distribution
    is typically one of a “building block” for more complicated distributions, like
    the binomial, that give you more interesting results.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose you define a random variable ![image](../images/f0333-07.jpg),
    where *Y*[1], *Y*[2], ..., *Y[n]* are each Bernoulli random variables corresponding
    to the same event, in other words, the die roll with success defined as rolling
    a 4\. The new random variable *X*, a sum of Bernoulli random variables, now describes
    *the number of successes in n trials* of the defined action. Providing that certain
    reasonable assumptions are satisfied, the probability distribution that describes
    this success count is the binomial distribution.
  prefs: []
  type: TYPE_NORMAL
- en: In mathematical terms, for a discrete random variable and a realization *X*
    = *x*, the binomial mass function *f* is
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e16-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e16-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: is known as the *binomial coefficient*. (Recall the use of the integer factorial
    operator !, as first discussed in [Exercise 10.4](ch10.xhtml#ch10exc4) on [page
    203](ch10.xhtml#page_203).) This coefficient, also referred to as a *combination*,
    accounts for all different orders in which you might observe *x* successes throughout
    *n* trials.
  prefs: []
  type: TYPE_NORMAL
- en: The parameters of the binomial distribution are *n* and *p*, and the notation
  prefs: []
  type: TYPE_NORMAL
- en: '*X* ∼ BIN(*n*, *p*)'
  prefs: []
  type: TYPE_NORMAL
- en: is often used to indicate that *X* follows a binomial distribution for *n* trials
    with parameter *p*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the key points to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: • *X* can take only the values 0, 1, ..., *n* and represents the total number
    of successes.
  prefs: []
  type: TYPE_NORMAL
- en: • *p* should be interpreted as “the probability of success at each trial.” Therefore,
    0 ≤ *p* ≤ 1, and *n* > 0 is an integer interpreted as “the number of trials.”
  prefs: []
  type: TYPE_NORMAL
- en: • Each of the *n* trials is a Bernoulli success and failure event, the trials
    are independent (in other words, the outcome of one doesn’t affect the outcome
    of any other), and *p* is constant.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean and variance are defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0334-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Counting the number of successes of repeated trials of a binary-valued test
    is one of the common random phenomena mentioned at the start of this section.
    Consider the specific situation in which there’s only one “trial,” that is, *n*
    = 1\. Examining [Equations (16.2)](ch16.xhtml#ch16eq2) and [(16.3)](ch16.xhtml#ch16eq3),
    it should become clear that (16.2) simplifies to (16.1). In other words, the Bernoulli
    distribution is just a special case of the binomial. Clearly, this makes sense
    with respect to the definition of a binomial random variable as a sum of *n* Bernoulli
    random variables. In turn, R provides functionality for the binomial distribution
    though not explicitly for the Bernoulli.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate this, I’ll return to the example of rolling a die with success
    defined as getting a 4\. If you roll the die independently eight times, what is
    the probability of observing exactly five successes (five 4s) in total? Well,
    you’d have ![image](../images/f0334-03.jpg), and this probability can be worked
    through mathematically using (16.2).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0334-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The result tells you there is approximately a 0.4 percent chance that you’ll
    observe exactly five 4s in eight rolls of the die. This is small and makes sense—it’s
    far more probable that you might observe zero to two 4s in eight rolls of a die.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, R functions will handle the arithmetic in these situations. The
    built-in functions `dbinom`, `pbinom`, `qbinom`, and `rbinom` are all relevant
    to the binomial and Bernoulli distributions and are summarized in one help file
    indexed by each of these function names.
  prefs: []
  type: TYPE_NORMAL
- en: • `dbinom` directly provides the mass function probabilities Pr(*X* = *x*) for
    any valid *x*—that is, 0 ≤ *x* ≤ *n*.
  prefs: []
  type: TYPE_NORMAL
- en: • `pbinom` provides the cumulative probability distribution—given a valid *x*,
    it yields Pr(*X* ≤ *x*).
  prefs: []
  type: TYPE_NORMAL
- en: • `qbinom` provides the *inverse* cumulative probability distribution (also
    known as the *quantile function* of the distribution)—given a valid probability
    0 ≤ *p* ≤ 1, it yields the value of *x* that satisfies Pr(*X* ≤ *x*) = *p*.
  prefs: []
  type: TYPE_NORMAL
- en: • `rbinom` is used to generate any number of realizations of *X* given a specific
    binomial distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '**The dbinom Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: With this knowledge, you can use R to confirm the result of Pr(*X* = 5) for
    the die-roll example described a moment ago.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: To the `dbinom` function, you provide the specific value of interest as `x`;
    the total number of trials, *n*, as `size`; and the probability of success at
    each trial, *p*, as `prob`. True to R, a vector argument is possible for `x`.
    If you want the full probability mass function table for *X* for this example,
    you can supply the vector `0:8` to `x`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: These can be confirmed to sum to 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The resulting vector of probabilities, which corresponds to the specific outcomes
    *x* = {0, 1, ..., 8}, is returned using e-notation (refer to [Section 2.1.3](ch02.xhtml#ch02lev2sec19)).
    You can tidy this up by rounding the results using the `round` function introduced
    in [Section 13.2.2](ch13.xhtml#ch13lev2sec117). Rounding to three decimal places,
    the results are easier to read.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The achievement of one success in eight trials has the highest probability,
    at approximately 0.372\. Furthermore, the mean (expected value) and variance of
    *X* in this example are ![image](../images/f0335-01.jpg) and ![image](../images/f0335-02.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You can plot the corresponding probability mass function in the same way as
    for the example in [Section 15.2.2](ch15.xhtml#ch15lev2sec134); the following
    line produces [Figure 16-1](ch16.xhtml#ch16fig1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![image](../images/f16-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-1: The probability mass function associated with the binomial distribution
    of the die-rolling example*'
  prefs: []
  type: TYPE_NORMAL
- en: '**The pbinom Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The other R functions for the binomial distribution work in much the same way.
    The first argument is always the value (or values) of interest; *n* is supplied
    as `size` and *p* as `prob`. To find, for example, the probability that you observe
    three or fewer 4s, Pr(*X* ≤ 3), you either sum the relevant individual entries
    from `dbinom` as earlier or use `pbinom`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the pivotal argument to `pbinom` is tagged `q`, not `x`; this is
    because, in a cumulative sense, you are searching for a probability based on a
    quantile. The cumulative distribution results from `pbinom` can be used in the
    same way to search for “upper-tail” probabilities (probabilities to the right
    of a given value) since you know that the total probability mass is always 1\.
    To find the probability that you observe *at least* three 4s in eight rolls of
    the die, Pr(*X* ≥ 3) (which is equivalent to Pr(*X* > 2) in the context of this
    discrete random variable), note that the following finds the correct result because
    it’s the complement of Pr(*X* ≤ 2) that you’re looking for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**The qbinom Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Less frequently used is the `qbinom` function, which is the inverse of `pbinom`.
    Where `pbinom` provides a cumulative probability when given a quantile value `q`,
    the function `qbinom` provides a quantile value when given a cumulative probability
    `p`. The discrete nature of a binomial random variable means `qbinom` will return
    the nearest value of *x* below which `p` lies. For example, note that
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: provides 3 as the quantile value, even though you know from earlier that the
    exact probability that lies at or below 3, Pr(*X* ≤ 3), is 0.9693436\. You’ll
    look at `p`- and `q`-functions more when dealing with continuous probability distributions;
    see [Section 16.2](ch16.xhtml#ch16lev1sec51).
  prefs: []
  type: TYPE_NORMAL
- en: '**The rbinom Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Lastly, the random generation of realizations of a binomially distributed variable
    is retrieved using the `rbinom` function. Again, going with the ![image](../images/f0337-01.jpg)
    distribution, note the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The initial argument `n` doesn’t refer to the number of trials. The number of
    trials is still provided to `size` with *p* given to `prob`. Here, `n` requests
    the number of realizations you want to generate for the random variable ![image](../images/f0337-02.jpg).
    The first three lines each request a single realization—in the first eight rolls,
    you observe zero successes (4s), and in the second and third sets of eight rolls,
    you observe two and two 4s, respectively. The fourth line highlights the fact
    that multiple realizations of *X* are easily obtained and stored as a vector by
    increasing `n`. As these are *randomly generated realizations*, if you run these
    lines now, you’ll probably observe some different values.
  prefs: []
  type: TYPE_NORMAL
- en: Though not used often in standard statistical testing methods, the `r-`functions
    for probability distributions, either discrete or continuous, play an important
    role when it comes to simulation and various advanced numeric algorithms in computational
    statistics.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 16.1**'
  prefs: []
  type: TYPE_NORMAL
- en: A forested nature reserve has 13 bird-viewing platforms scattered throughout
    a large block of land. The naturalists claim that at any point in time, there
    is a 75 percent chance of seeing birds at each platform. Suppose you walk through
    the reserve and visit every platform. If you assume that all relevant conditions
    are satisfied, let *X* be a binomial random variable representing the total number
    of platforms at which you see birds.
  prefs: []
  type: TYPE_NORMAL
- en: Visualize the probability mass function of the binomial distribution of interest.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the probability you see birds at all sites?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the probability you see birds at more than 9 platforms?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the probability of seeing birds at between 8 and 11 platforms (inclusive)?
    Confirm your answer by using only the `d`-function and then again using only the
    `p`-function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Say that, before your visit, you decide that if you see birds at fewer than
    9 sites, you’ll make a scene and demand your entry fee back. What’s the probability
    of your embarrassing yourself in this way?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Simulate realizations of *X* that represent 10 different visits to the reserve;
    store your resulting vector as an object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute the mean and standard deviation of the distribution of interest.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***16.1.3 Poisson Distribution***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this section, you’ll use the *Poisson* distribution to model a slightly more
    general, but just as important, discrete random variable—a *count*. For example,
    the variable of interest might be the number of seismic tremors detected by a
    certain station in a given year or the number of imperfections found on square-foot
    pieces of sheet metal coming off a factory production line.
  prefs: []
  type: TYPE_NORMAL
- en: 'Importantly, the events or items being counted are assumed to manifest independently
    of one another. In mathematical terms, for a discrete random variable and a realization
    *X* = *x*, the Poisson mass function *f* is given as follows, where *λ*[p] is
    a parameter of the distribution (this will be explained further momentarily):'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e16-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The notation
  prefs: []
  type: TYPE_NORMAL
- en: '*X* ∼ POIS(*λ*[p])'
  prefs: []
  type: TYPE_NORMAL
- en: is often used to indicate that “*X* follows a Poisson distribution with parameter
    *λ*[p].”
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the keys points to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: • The entities, features, or events being counted occur independently in a well-defined
    interval at a constant rate.
  prefs: []
  type: TYPE_NORMAL
- en: '• *X* can take only non-negative integers: 0,1,. . ..'
  prefs: []
  type: TYPE_NORMAL
- en: • *λ*[p] should be interpreted as the “mean number of occurrences” and must
    therefore be finite and strictly positive; that is, 0 < *λ*[p] < ∞.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean and variance are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0339-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Like the binomial random variable, the values taken by a Poisson random variable
    are discrete, non-negative integers. Unlike the binomial, however, there’s typically
    no upper limit on a Poisson count. While this implies that an “infinite count”
    is allowed to occur, it’s a distinct feature of the Poisson distribution that
    the probability mass associated with some value *x* goes to zero as *x* itself
    goes to infinity.
  prefs: []
  type: TYPE_NORMAL
- en: As noted in [Equation (16.4)](ch16.xhtml#ch16eq4), any Poisson distribution
    depends upon the specification of a single parameter, denoted here with *λ*[p].
    This parameter describes the mean number of occurrences, which impacts the overall
    shape of the mass function, as shown in [Figure 16-2](ch16.xhtml#ch16fig2).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f16-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-2: Three examples of the Poisson probability mass function, plotted
    for 0* ≤ x ≤ *30\. The “expected count” parameter* *λ*[p] *is altered from 3.00
    (left) to 6.89 (middle) and to 17.20 (right).*'
  prefs: []
  type: TYPE_NORMAL
- en: Again, it’s worth noting that the total probability mass over all possible outcomes
    is 1, no matter what the value of *λ*[p] is and regardless of the fact that possible
    outcomes can, technically, range from 0 to infinity.
  prefs: []
  type: TYPE_NORMAL
- en: By definition, it’s easy to understand why the mean of *X*, *μ[X]*, is equal
    to *λ*[p]; in fact, it turns out that the variance of a Poisson distributed random
    variable is also equal to *λ*[p].
  prefs: []
  type: TYPE_NORMAL
- en: Consider the example of blemishes on 1-foot-square sheets of metal coming off
    a production line, mentioned in the opening of this section. Suppose you’re told
    that the number of blemishes found, *X*, is thought to follow a Poisson distribution
    with *λ*[p] = 3.22, as in *X* ∼ POIS(3.22). In other words, you’d expect to see
    an average of 3.22 blemishes on your 1-foot sheets.
  prefs: []
  type: TYPE_NORMAL
- en: '**The dpois and ppois Functions**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The R `dpois` function provides the individual Poisson mass function probabilities
    Pr(*X* = *x*) for the Poisson distribution. The `ppois` function provides the
    left cumulative probabilities, as in Pr(*X* ≤ *x*). Consider the following lines
    of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The first call finds that Pr(*X* = 3) = 0.22 (to 2 d.p.); in other words, the
    probability that you observe exactly three blemishes on a randomly selected piece
    of sheet metal is equal to about 0.22\. The second call indicates a less than
    4 percent chance that the piece is flawless. The third line returns a rounded
    version of the relevant mass function for the values 0 ≤ *x* ≤ 10\. By hand you
    can confirm the first result like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You create a visualization of the mass function with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This is shown on the left of [Figure 16-3](ch16.xhtml#ch16fig3).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f16-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-3: The Poisson probability mass function (left) and cumulative distribution
    function (right) for* *λ[p] = 3.22 plotted for the integers 0* ≤ x ≤ *10, with
    reference to the sheet metal example*'
  prefs: []
  type: TYPE_NORMAL
- en: To calculate cumulative results, you use `ppois`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: These lines find that the probability you observe at most two imperfections,
    Pr(*X* ≤ 2), is about 0.38, and the probability you observe strictly more than
    five blemishes, Pr(*X* ≥ 6), is roughly 0.11.
  prefs: []
  type: TYPE_NORMAL
- en: 'A visualization of the cumulative mass function is given on the right of [Figure
    16-3](ch16.xhtml#ch16fig3), created with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '**The qpois Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The `q`-function for the Poisson distribution, `qpois`, provides the inverse
    of `ppois`, in the same way as `qbinom` in [Section 16.1.2](ch16.xhtml#ch16lev2sec138)
    provides the inverse of `pbinom`.
  prefs: []
  type: TYPE_NORMAL
- en: '**The rpois Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To produce random variates, you use `rpois`; you supply the number of variates
    you want as `n` and supply the all-important parameter as `lambda`. You can imagine
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: as selecting fifteen 1-foot-square metal sheets from the production line at
    random and counting the number of blemishes on each. Note again that this is random
    generation; your specific results are likely to vary.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 16.2**'
  prefs: []
  type: TYPE_NORMAL
- en: Every Saturday, at the same time, an individual stands by the side of a road
    and tallies the number of cars going by within a 120-minute window. Based on previous
    knowledge, she believes that the mean number of cars going by during this time
    is exactly 107\. Let *X* represent the appropriate Poisson random variable of
    the number of cars passing her position in each Saturday session.
  prefs: []
  type: TYPE_NORMAL
- en: What is the probability that more than 100 cars pass her on any given Saturday?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine the probability that no cars pass.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the relevant Poisson mass function over the values in 60 ≤ *x* ≤ 150.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Simulate 260 results from this distribution (about five years of weekly Saturday
    monitoring sessions). Plot the simulated results using `hist`; use `xlim` to set
    the horizontal limits from 60 to 150\. Compare your histogram to the shape of
    your mass function from (c).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***16.1.4 Other Mass Functions***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are many other well-defined probability mass functions in R’s built-in
    suite of statistical calculations. All model a discrete random variable in a certain
    way under certain conditions and are defined with at least one parameter, and
    most are represented by their own set of `d`-, `p`-, `q`-, and `r`-functions.
    Here I summarize a few more:'
  prefs: []
  type: TYPE_NORMAL
- en: • The *geometric* distribution counts the number of failures before a success
    is recorded and is dependent on a “probability of success parameter” `prob`. Its
    functions are `dgeom`, `pgeom`, `qgeom`, and `rgeom`.
  prefs: []
  type: TYPE_NORMAL
- en: • The *negative binomial* distribution is a generalization of the geometric
    distribution, dependent upon parameters `size` (number of trials) and `prob`.
    Its functions are `dnbinom`, `pnbinom`, `qnbinom`, and `rnbinom`.
  prefs: []
  type: TYPE_NORMAL
- en: • The *hypergeometric* distribution is used to model sampling without replacement
    (in other words, a “success” can change the probabilities associated with further
    successes), dependent upon parameters `m`, `n`, and `k` describing the nature
    of sampled items. Its functions are `dhyper`, `phyper`, `qhyper`, and `rhyper`.
  prefs: []
  type: TYPE_NORMAL
- en: • The *multinomial* distribution is a generalization of the binomial, where
    a success can occur in one of multiple categories at each trial, with parameters
    `size` and `prob` (this time, `prob` must be a vector of probabilities corresponding
    to the multiple categories). Its built-in functions are limited to `dmultinom`
    and `rmultinom`.
  prefs: []
  type: TYPE_NORMAL
- en: As noted earlier, some familiar probability distributions are just simplifications
    or special cases of functions that describe a more general class of distributions.
  prefs: []
  type: TYPE_NORMAL
- en: '**16.2 Common Probability Density Functions**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When considering continuous random variables, you need to deal with probability
    density functions. There are a number of common continuous probability distributions
    frequently used over many different types of problems. In this section, you’ll
    be familiarized with some of these and R’s accompanying `d`-, `p`-, `q`-, and
    `r`-functions.
  prefs: []
  type: TYPE_NORMAL
- en: '***16.2.1 Uniform***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *uniform* distribution is a simple density function that describes a continuous
    random variable whose interval of possible values offers no fluctuations in probability.
    This will become clear in a moment when you plot [Figure 16-4](ch16.xhtml#ch16fig4).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f16-04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-4: Two uniform distributions plotted on the same scale for comparability.
    Left:* X ∼ *UNIF(*−*0.4,1.1); right:* X ∼ *UNIF(0.223,0.410). The total area underneath
    each density function is, as always, 1.*'
  prefs: []
  type: TYPE_NORMAL
- en: For a continuous random variable *a* ≤ *X* ≤ *b*, the uniform density function
    *f* is
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e16-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *a* and *b* are parameters of the distribution defining the limits of
    the possible values *X* can take. The notation
  prefs: []
  type: TYPE_NORMAL
- en: '*X* ∼ UNIF(*a*, *b*)'
  prefs: []
  type: TYPE_NORMAL
- en: is often used to indicate that “*X* follows a uniform distribution with limits
    *a* and *b*.”
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the key points to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: • *X* can take any value in the interval bounded by *a* and *b*.
  prefs: []
  type: TYPE_NORMAL
- en: • *a* and *b* can be any values, provided that *a* < *b*, and they represent
    the lower and upper limits, respectively, of the interval of possible values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean and variance are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0343-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For the more complicated densities in this section, it’s especially useful to
    visualize the functions in order to understand the probabilistic structure associated
    with a continuous random variable. For the uniform distribution, given [Equation
    (16.5)](ch16.xhtml#ch16eq5), you can recognize the two different uniform distributions
    shown in [Figure 16-4](ch16.xhtml#ch16fig4). I’ll provide the code to produce
    these types of plots shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the left plot in [Figure 16-4](ch16.xhtml#ch16fig4), you can confirm the
    exact height of the *X* ∼ UNIF(−0.4,1.1) density by hand: ![image](../images/f0344-01.jpg).
    For the plot on the right, based on *X* ∼ UNIF(0.223,0.410), you can use R to
    find that its height is roughly 5.35.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '**The dunif Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You can use the built-in `d`-function for the uniform distribution, `dunif`,
    to return these heights for any value within the defined interval. The `dunif`
    command returns zero for values outside of the interval. The parameters of the
    distribution, *a* and *b*, are provided as the arguments `min` and `max`, respectively.
    For example, the line
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: evaluates the uniform density function of *X* ∼ UNIF(−0.4,1.1) at the values
    given in the vector passed to `x`. You’ll notice that the first and last values
    fall outside the bounds defined by `min` and `max`, and so they are zero. All
    others evaluate to the height value of ![image](../images/2by3.jpg), as previously
    calculated.
  prefs: []
  type: TYPE_NORMAL
- en: As a second example, the line
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: confirms the correct density values for the *X* ∼ UNIF(0.223,0.410) distribution,
    with the second value, zero, falling outside the defined interval.
  prefs: []
  type: TYPE_NORMAL
- en: This most recent example in particular should remind you that probability density
    functions for continuous random variables, unlike mass functions for discrete
    variables, *do not* directly provide probabilities, as mentioned in [Section 15.2.3](ch15.xhtml#ch15lev2sec135).
    In other words, the results just returned by `dunif` represent the respective
    density functions themselves and not any notion of chance attached to the specific
    values of *x* at which they were evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: 'To calculate some probabilities based on the uniform density function, use
    the example of a faulty drill press. In a woodworker’s shop, imagine there’s a
    drill press that cannot keep to a constant alignment when in use; instead, it
    randomly hits the intended target at up to 0.4 cm to the left or 1.1 cm to the
    right. Let the random variable *X* ∼ UNIF(−0.4,1.1) represent where the drill
    hits the material relative to the target at 0\. [Figure 16-5](ch16.xhtml#ch16fig5)
    replots the left image of [Figure 16-4](ch16.xhtml#ch16fig4) on a more detailed
    scale. You have three versions, each marking off a different area under the density
    function: Pr(*X* ≤ −0.21), Pr(−0.21 ≤ *X* ≤ 0.6), and Pr(*X* ≥ 0.6).'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f16-05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-5: Three areas underneath the* X ∼ *UNIF(*−*0.4,1.1) density function
    for the drill press example. Left: Pr(*X ≤ −*0.21); middle: Pr(*−*0.21* ≤ X ≤
    *0.6); right: Pr(*X ≥ *0.6).*'
  prefs: []
  type: TYPE_NORMAL
- en: 'These plots are created using the coordinate-based plotting skills covered
    in [Chapter 7](ch07.xhtml#ch07). The density itself is presented with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: You can use much of the same code to produce the plots in [Figure 16-4](ch16.xhtml#ch16fig4)
    by modifying the `xlim` and `ylim` arguments to adjust the scale of the axes.
  prefs: []
  type: TYPE_NORMAL
- en: You add the vertical lines denoting *f* (−0.21) and *f* (0.6) in [Figure 16-5](ch16.xhtml#ch16fig5)
    with another call to `segments`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, you can shade the areas using the `polygon` function, which was first
    explored in [Section 15.2.3](ch15.xhtml#ch15lev2sec135). For example, in the leftmost
    plot in [Figure 16-5](ch16.xhtml#ch16fig5), use the previous plotting code followed
    by this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As mentioned earlier, the three shaded areas in [Figure 16-5](ch16.xhtml#ch16fig5)
    represent, from left to right, Pr(*X* < −0.21), Pr(−0.21 < *X* < 0.6), and Pr(*X*
    > 0.6), respectively. In terms of the drill press example, you can interpret these
    as the probability that the drill hits the target 0.21 cm to the left or more,
    the probability that the drill hits the target between 0.21 cm to the left and
    0.6 cm to the right, and the probability that the drill hits the target 0.6 cm
    to the right or more, respectively. (Remember from [Section 15.2.3](ch15.xhtml#ch15lev2sec135)
    that it makes no difference if you use ≤ or < (or ≥ or >) for probabilities associated
    with continuous random variables.) Though you could evaluate these probabilities
    geometrically for such a simple density function, it’s still faster to use R.
  prefs: []
  type: TYPE_NORMAL
- en: '**The punif Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Remember that probabilities associated with continuous random variables are
    defined as *areas under the function*, and therefore your study focuses on the
    appropriate intervals of *X* rather than any specific value. The `p`-function
    for densities, just like the `p`-function for discrete random variables, provides
    the cumulative probability distribution Pr(*X* ≤ *x*). In the context of the uniform
    density, this means that given a specific value of *x* (supplied as a “quantile”
    argument `q`), `punif` will provide the left-directional area underneath the function
    from that specific value.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing `punif`, the line
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: tells you that the leftmost area in [Figure 16-5](ch16.xhtml#ch16fig5) represents
    a probability of about 0.127\. The line
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: tells you that ![image](../images/f0346-01.jpg). The final result for Pr(−0.21
    < *X* < 0.6), giving a 54 percent chance, is found with
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: since the first call provides the area under the density from 0.6 all the way
    left and the second call provides the area from −0.21 all the way left. Therefore,
    this difference is the middle area as defined.
  prefs: []
  type: TYPE_NORMAL
- en: It’s essential to be able to manipulate cumulative probability results like
    this when working with probability distributions in R, and the beginner might
    find it useful to sketch out the desired area before using `p`-functions, especially
    with respect to density functions.
  prefs: []
  type: TYPE_NORMAL
- en: '**The qunif Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The `q`-functions for densities are used more often than they are for mass functions
    because the continuous nature of the variable means that a unique quantile value
    can be found for any valid probability `p`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `qunif` function is the inverse of `punif`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: These lines confirm the values of *X* used earlier to get the lower- and upper-tail
    probabilities Pr(*X* < −0.21) and Pr(*X* > 0.6), respectively. Any `q`-function
    expects a *cumulative* (in other words, left-hand) probability as its first argument,
    which is why you need to supply `1-1/3` in the second line to recover `0.6`. (The
    total area is 1\. You know that you want the area to the *right* of 0.6 to be
    ![image](../images/1by3.jpg); thus, the area on the left must be ![image](../images/f0347-01.jpg).)
  prefs: []
  type: TYPE_NORMAL
- en: '**The runif Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Lastly, to generate random realizations of a specific uniform distribution,
    you use `runif`. Let’s say the woodworker drills 10 separate holes using the faulty
    press; you can simulate one instance of the position of each of these holes relative
    to their target with the following call.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Again, note that the specific values of `r`-function calls like `runif` will
    be different each time they are run.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 16.3**'
  prefs: []
  type: TYPE_NORMAL
- en: You visit a national park and are informed that the height of a certain species
    of tree found in the forest is uniformly distributed between 3 and 70 feet.
  prefs: []
  type: TYPE_NORMAL
- en: What is the probability you encounter a tree shorter than ![image](../images/f0347-02.jpg)
    feet?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For this probability density function, what is the height that marks the cutoff
    point of the tallest 15 percent of trees?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the mean and standard deviation of the tree height distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using (c), confirm that the chance that you encounter a tree with a height that
    is within half a standard deviation (that is, below or above) of the mean height
    is roughly 28.9 percent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At what height is the density function itself? Show it in a plot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Simulate 10 observed tree heights. Based on these data, use `quantile` (refer
    to [Section 13.2.3](ch13.xhtml#ch13lev2sec118)) to estimate the answer you arrived
    at in (b). Repeat your simulation, this time generating 1,000 variates, and estimate
    (b) again. Do this a handful of times, taking a mental note of your two estimates
    each time. Overall, what do you notice of your two estimates (one based on 10
    variates at a time and the other based on 1,000) with respect to the “true” value
    in (b)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***16.2.2 Normal***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *normal distribution* is one of the most well-known and commonly applied
    probability distributions in modeling continuous random variables. Characterized
    by a distinctive “bell-shaped” curve, it’s also referred to as the *Gaussian*
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: For a continuous random variable −∞ < *X* < ∞, the normal density function *f*
    is
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e16-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *μ* and *σ* are parameters of the distribution, *π* is the familiar geometric
    value 3.1415 ..., and exp{·} is the exponential function (refer to [Section 2.1.2](ch02.xhtml#ch02lev2sec18)).
    The notation
  prefs: []
  type: TYPE_NORMAL
- en: '*X* ∼ N(*μ*, *σ*)'
  prefs: []
  type: TYPE_NORMAL
- en: is often used to indicate that “*X* follows a normal distribution with mean
    *μ* and standard deviation *σ*.”
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the key points to remember:'
  prefs: []
  type: TYPE_NORMAL
- en: • Theoretically, *X* can take any value from −∞ to ∞.
  prefs: []
  type: TYPE_NORMAL
- en: • As hinted at earlier, the parameters *μ* and *σ* directly describe the mean
    and the standard deviation of the distribution, with the square of the latter,
    *σ*², being the variance.
  prefs: []
  type: TYPE_NORMAL
- en: • In practice, the mean parameter is finite −∞ < *μ* < ∞, and the standard deviation
    parameter is strictly positive and finite 0 < *σ* < ∞.
  prefs: []
  type: TYPE_NORMAL
- en: • If you have a random variable *X* ∼ N(*μ*, *σ*), then you can create a new
    random variable *Z* = (*X* − *μ*)/σ, which means *Z* ∼ N(0,1). This is known as
    *standardization* of *X*.
  prefs: []
  type: TYPE_NORMAL
- en: The two parameters noted earlier fully define a particular normal distribution.
    These are always perfectly symmetric, unimodal, and centered on the mean *μ*,
    and they have a degree of “spread” defined using the standard deviation *σ*.
  prefs: []
  type: TYPE_NORMAL
- en: The top image of [Figure 16-6](ch16.xhtml#ch16fig6) provides the density functions
    for four specific normal distributions. You can see that altering the mean results
    in a translation, where the center of the distribution is simply shifted to sit
    on the specific value of *μ*. The effect of a smaller standard deviation is to
    reduce the spread, resulting in a taller, skinnier appearance of the density.
    Increasing *σ* flattens the density out around the mean.
  prefs: []
  type: TYPE_NORMAL
- en: The bottom image zooms in on the N(0,1) distribution when you have a normal
    density centered on *μ* = 0 and with a standard deviation of *σ* = 1\. This distribution,
    known as the *standard normal*, is frequently used as a standard reference to
    compare different normally distributed random variables with one another on the
    same scale of probabilities. It’s common practice to rescale, or *standardize*,
    some variable *X* ∼ N(*μ[X]* ,σ[*X*]) to a new variable *Z* such that *Z* ∼ N(0,1)
    (you’ll see this practiced in [Chapter 18](ch18.xhtml#ch18)). Vertical lines in
    the plot show plus or minus one, two, and three times the standard deviation away
    from the mean of zero. This serves to highlight the fact that for *any* normal
    distribution, a probability of exactly 0.5 lies either above or below the mean.
    Furthermore, note that there’s a probability of approximately 0.683 of a value
    falling within one standard deviation of the mean, approximately 0.954 probability
    under the curve from −2*σ* to +2σ, and approximately 0.997 probability between
    −3*σ* and +3σ.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f16-06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-6: Illustrating the normal distribution. Top: Four different instances
    of the density achieved by varying the mean* *μ* *and standard deviation* *σ.
    Bottom: The “standard normal” distribution, N(0,1), marking off the mean* ±*1*σ,
    ±*2*σ*, and* ±*3*σ.'
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*The mathematical definition of the normal density means that as you move further
    away from the mean, the value of the density function itself will approach zero.
    In actual fact, any normal density function never actually touches the horizontal
    line at zero; it just gets closer and closer as you move to positive or negative
    infinity. This behavior is formally referred to as* asymptotic*; in this case,
    you’d say that the normal distribution f* (*x*) *has a* horizontal asymptote *at
    f* (*x*) *= 0\. In discussing probabilities as areas under the curve, you’d refer
    to the fact that “the total area under the curve from negative to positive infinity”
    is 1, in other words, ![image](../images/f0349-01.jpg).*'
  prefs: []
  type: TYPE_NORMAL
- en: '**The dnorm Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Being a probability density function, the `dnorm` function itself doesn’t provide
    probabilities—merely the value of the desired normal function curve *f* (*x*)
    at any *x*. To plot a normal density, you’d therefore be able to use `seq` (refer
    to [Section 2.3.2](ch02.xhtml#ch02lev2sec21)) to create a fine sequence of values
    for *x*, evaluate the density at these values with `dnorm`, and then plot the
    result as a line. For example, to produce an image of the standard normal distribution
    curve similar to that in the bottom image of [Figure 16-6](ch16.xhtml#ch16fig6),
    the following code will create the desired *x* values as `xvals`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Then `dnorm`, which includes specification of *μ* as `mean` and *σ* as `sigma`,
    produces the precise values of *f*(*x*) at those `xvals`. Finally, a call such
    as `plot(xvals,fx,type="l")` achieves the bare bones of a density plot, which
    you can easily enhance by adding titles and using commands such as `abline` and
    `segments` to mark locations off (I’ll produce another plot in a moment, so this
    basic one isn’t shown here).
  prefs: []
  type: TYPE_NORMAL
- en: Note that if you don’t supply any values to `mean` and `sd`, the default behavior
    of R is to implement the standard normal distribution; the object `fx` shown earlier
    could have been created with an even shorter call using just `dnorm(xvals)`.
  prefs: []
  type: TYPE_NORMAL
- en: '**The pnorm Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The `pnorm` function obtains left-side probabilities under the specified normal
    density. As with `dnorm`, if no parameter values are supplied, R automatically
    sets `mean=0` and `sd=1`. In the same way you used `punif` in [Section 16.2.1](ch16.xhtml#ch16lev2sec141),
    you can find differences of results from `pnorm` to find any areas you want when
    you provide the function with the desired values in the argument `q`.
  prefs: []
  type: TYPE_NORMAL
- en: For example, it was mentioned earlier that a probability of approximately 0.683
    lies within one standard deviation of the mean. You can confirm this using `pnorm`
    for the standard normal.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The first call to `pnorm` evaluates the area under the curve from positive
    1 left (in other words, all the way to −∞) and then finds the difference between
    that and the area from −1 left. The result reflects the proportion between the
    two dashed lines in the bottom of [Figure 16-6](ch16.xhtml#ch16fig6). These kinds
    of probabilities will be the same for *any* normal distribution. Consider the
    distribution where *μ* = −3.42 and *σ* = 0.2\. Then the following provides the
    same value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'It takes a little more work to specify the distribution of interest since it’s
    not standard, but the principle is the same: plus and minus one standard deviation
    away from the mean.'
  prefs: []
  type: TYPE_NORMAL
- en: The symmetry of the normal distribution is also useful when it comes to calculating
    probabilities. Sticking with the N(3.42,0.2) distribution, you can see that the
    probability you make an observation greater than *μ* + *σ* = −3.42 + 0.2 = −3.22
    (an *upper-tail* probability) is identical to the probability of making an observation
    less than *μ* − *σ* = −3.42 − 0.2 = −3.62 (a *lower-tail* probability).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also evaluate these values by hand, given the result you computed earlier
    that says Pr(μ − *σ* < *X* < *μ* + *σ*) = 0.6826895\. The remaining probability
    *outside* of this middle area must be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'So, in each of the lower- and upper-tail areas marked off by *μ* − *σ* and
    *μ* + *σ*, respectively, there must be a probability of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This is what was just found using `pnorm` (note that there can be some minor
    rounding errors in these types of calculations). You can see this in [Figure 16-7](ch16.xhtml#ch16fig7),
    which is, initially, plotted with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '![image](../images/f16-07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-7: Illustrating the example in the text, where the symmetry of the
    normal distribution is used to point out features of probabilities under the curve.
    Note that the total area under the density is 1, which in conjunction with symmetry
    is useful for making calculations.*'
  prefs: []
  type: TYPE_NORMAL
- en: To add the shaded area between *μ* ± *σ*, you can use `polygon`, for which you
    need the vertices of the shape of interest. To get a smooth curve, make use of
    the fine sequence `xvals` and corresponding `fx` as defined in the code, and use
    logical vector subsetting to restrict attention to those locations of *x* such
    that −3.62 ≤ *x* ≤ −3.22.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: You can then sandwich these between the two corners at the bottom of the shaded
    polygon using the matrix structure that the `polygon` function expects.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Finally, `arrows` and `text` indicate the areas discussed in the text.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '**The qnorm Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s turn to `qnorm`. To find the quantile value that will give you a lower-tail
    probability of 0.159, you use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Given the earlier results and what you already know about previous `q-`functions,
    it should be clear why the result is a value of approximately −3.62\. You find
    the upper quartile (the value *above which* you’d find a probability of 0.25)
    with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Remember that the `q`-function will operate based on the (left) lower-tail probability,
    so to find a quantile based on an upper-tail probability, you must first subtract
    it from the total probability of 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some methods and models used in frequentist statistics, it’s common to assume
    that your observed data are normal. You can test the validity of this assumption
    by using your knowledge of the theoretical quantiles of the normal distribution,
    found in the results of `qnorm`: calculate a range of sample quantile values for
    your observed data and plot these against the same quantiles for a correspondingly
    standardized normal distribution. This visual tool is referred to as a normal
    *quantile-quantile* or *QQ* plot and is useful when viewed alongside a histogram.
    If the plotted points don’t lie on a straight line, then the quantiles from your
    data do not match the appearance of those from a normal curve, and the assumption
    that your data are normal may not be valid.'
  prefs: []
  type: TYPE_NORMAL
- en: The built-in `qqnorm` function takes in your raw data and produces the corresponding
    plot. Go back once more to the ready-to-use `chickwts` data set. Let’s say you
    want to find out whether it’s reasonable to assume the weights are normally distributed.
    To that end, you use
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: to produce the histogram of the 71 weights and the normal QQ plot given in [Figure
    16-8](ch16.xhtml#ch16fig8). The additional `qqline` command adds the “optimal”
    line that the coordinates would lie along if the data were perfectly normal.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f16-08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-8: Histogram (left) and normal QQ plot (right) of the weights of
    chicks in the* `chickwts` *data set. Are the data normally distributed?*'
  prefs: []
  type: TYPE_NORMAL
- en: If you inspect the histogram of the weights, you can see that the data match
    the general appearance of a normal distribution, with a roughly symmetric unimodal
    appearance. That said, it doesn’t quite achieve the smoothness and naturally decaying
    height that produces the familiar normal bell shape. This is reflected in the
    QQ plot on the right; the central quantile values appear to lie on the line relatively
    well, except for some relatively minor “wiggles.” There are some clear discrepancies
    in the outer tails, but note that it is typical to observe discrepancies in these
    extreme quantiles in any QQ plot because fewer data points naturally occur there.
    Taking all of this into consideration, for this example the assumption of normality
    isn’t completely unreasonable.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*It’s important to consider the sample size when assessing the validity of
    these kinds of assumptions; the larger the sample size, the less random variability
    will creep into the histogram and QQ plot, and you can more confidently reach
    a conclusion about whether your data are normal. For instance, the assumption
    of normality in this example may be complicated by the fact there’s a relatively
    small sample size of only 71.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**The rnorm Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Random variates of any given normal distribution are generated with `rnorm`;
    for example, the line
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: produces seven normally distributed values arising from N(−3.42,0.2). In contrast
    to the QQ plot produced for the chick weights in [Figure 16-8](ch16.xhtml#ch16fig8),
    you can use `rnorm`, `qqnorm`, and `qqline` to examine the degree to which hypothetically
    observed data sets that are truly normal vary in the context of a QQ plot.
  prefs: []
  type: TYPE_NORMAL
- en: The following code generates 71 standard normal values and produces a corresponding
    normal QQ plot and then does the same for a separate data set of *n* = 710; these
    are displayed in [Figure 16-9](ch16.xhtml#ch16fig9).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '![image](../images/f16-09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-9: Normal QQ plots of 71 (left) and 710 (right) observations randomly
    generated from the standard normal distribution*'
  prefs: []
  type: TYPE_NORMAL
- en: You can see that the QQ plot for the simulated data set of size *n* = 71 shows
    similar deviation from the optimal line as does the chick weights data set. Bumping
    the sample size up by a factor of 10 shows that the QQ plot for the *n* = 710
    normal observations offers up far less random variation, although visible discrepancies
    in the tails do still occur. A good way to get used to assessing these effects
    is to rerun these lines of code several times (in other words, generating new
    data sets each time) and examine how each new QQ plot varies.
  prefs: []
  type: TYPE_NORMAL
- en: '**Normal Functions in Action: A Quick Example**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s finish this section with one more working problem. Assume the manufacturer
    of a certain type of snack knows that the total net weight of the snacks in its
    80-gram advertised package, *X*, is normally distributed with a mean of 80.2 grams
    and a standard deviation of 1.1 grams. The manufacturer weighs the contents of
    randomly selected individual packets. The probability a randomly selected packet
    is less than 78 grams (that is, Pr(*X* < 78)) is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The probability a packet is found to weigh between 80.5 and 81.5 grams is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The weight below which the lightest 20 percent of packets lie is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'A simulation of five randomly selected packets can be found with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '**Exercise 16.4**'
  prefs: []
  type: TYPE_NORMAL
- en: A tutor knows that the length of time taken to complete a certain statistics
    question by first-year undergraduate students, *X*, is normally distributed with
    a mean of 17 minutes and a standard deviation of 4.5 minutes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the probability a randomly selected undergraduate takes more than 20
    minutes to complete the question?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What’s the chance that a student takes between 5 and 10 minutes to finish the
    question?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the time that marks off the slowest 10 percent of students.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the normal distribution of interest between ±4*σ* and shade in the probability
    area of (iii), the slowest 10 percent of students.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Generate a realization of times based on a class of 10 students completing the
    question.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A meticulous gardener is interested in the length of blades of grass on his
    lawn. He believes that blade length *X* follows a normal distribution centered
    on 10 mm with a variance of 2 mm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the probability that a blade of grass is between 9.5 and 11 mm long.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the standardized values of 9.5 and 11 in the context of this distribution?
    Using the standardized values, confirm that you can obtain the same probability
    you found in (i) with the standard normal density.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Below which value are the shortest 2.5 percent of blade lengths found?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Standardize your answer from (iii).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '***16.2.3 Student’s t-distribution***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *Student’s t-distribution* is a continuous probability distribution generally
    used when dealing with statistics estimated from a sample of data. It will become
    particularly relevant in the next two chapters, so I’ll briefly explain it here
    first.
  prefs: []
  type: TYPE_NORMAL
- en: Any particular *t*-distribution looks a lot like the standard normal distribution—it’s
    bell-shaped, symmetric, and unimodal, and it’s centered on zero. The difference
    is that while a normal distribution is typically used to deal with a population,
    the *t*-distribution deals with *sample* from a population.
  prefs: []
  type: TYPE_NORMAL
- en: For the *t*-distribution you don’t have to define any parameters per se, but
    you must choose the appropriate *t*-distribution by way of a strictly positive
    integer *ν* > 0; this is referred to as the *degrees of freedom* (df), called
    so because it represents the number of individual components in the calculation
    of a given statistic that are “free to change.” You’ll see in the upcoming chapters
    that this quantity is usually directly related to sample sizes.
  prefs: []
  type: TYPE_NORMAL
- en: For the moment, though, you should just loosely think of the *t-*distribution
    as the representation of a family of curves and think of the degrees of freedom
    as the “selector” you use to tell you which particular version of the density
    to use. The precise equation for the density of the *t-*distribution is also not
    especially useful in an introductory setting, though it is useful to remember
    that the total probability underneath any *t* curve is naturally 1.
  prefs: []
  type: TYPE_NORMAL
- en: For a *t*-distribution, the `dt`, `pt`, `qt`, and `rt` functions represent the
    R implementation of the density, the cumulative distribution (left probabilities),
    the quantile, and the random variate generation functions, respectively. The first
    arguments, `x`, `q`, `p`, and `n`, respectively, provide the relevant value (or
    values) of interest to these functions; the second argument in all of these is
    `df`, to which you must specify the degrees of freedom *ν*.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to get an impression of the *t* family is through a visualization.
    [Figure 16-10](ch16.xhtml#ch16fig10) plots the standard normal distribution, as
    well as the *t-*distribution curve with *ν* = 1, *ν* = 6, and *ν* = 20 df.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f16-10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-10: Comparing the standard normal distribution with three instances
    of the* t*-distribution. Note that the higher the degrees of freedom, the closer
    the* t*-distribution approximation becomes to the normal.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The one important note to take away from [Figure 16-10](ch16.xhtml#ch16fig10),
    and indeed from this section, is the way in which the *t* density function changes
    with respect to the N(0,1) distribution as you increase the df. For small values
    of *ν* close to 1, the *t*-distribution is shorter, in terms of its mode, with
    more probability occurring in noticeably fatter tails. It turns out that the *t*
    density approaches the standard normal density as *ν* → ∞. As a case in point,
    note that the upper 5 percent tail of the standard normal distribution is delineated
    by the following value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The same upper tail of the *t*-distribution is provided with df values of *ν*
    = 1, *ν* = 6, and *ν* = 20, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: In direct comparison with the standard normal, the heavier weight in the tails
    of the *t* density leads naturally to more extreme quantile values given a specific
    probability. Notice that this extremity, however, is reduced as the df is increased—fitting
    in with the aforementioned fact that the *t-*distribution continues to improve
    in terms of its approximation to the standard normal as you raise the df.
  prefs: []
  type: TYPE_NORMAL
- en: '***16.2.4 Exponential***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Of course, probability density functions don’t have to be symmetrical like those
    you’ve encountered so far, nor do they need to allow for the random variable to
    be able to take values from negative infinity to positive infinity (like the normal
    or *t*-distributions). A good example of this is the *exponential distribution*,
    for which realizations of a random variable *X* are valid only on a 0 ≤ *X* <
    ∞ domain.
  prefs: []
  type: TYPE_NORMAL
- en: For a continuous random variable 0 ≤ *X* < ∞, the exponential density function
    *f* is
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e16-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *λ*[e] is a parameter of the distribution and exp{·} is the exponential
    function. The notation
  prefs: []
  type: TYPE_NORMAL
- en: '*X* ∼ EXP(*λ*[e])'
  prefs: []
  type: TYPE_NORMAL
- en: is often used to indicate that “*X* follows an exponential distribution with
    rate *λ*[e].”
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the key points to note:'
  prefs: []
  type: TYPE_NORMAL
- en: • Theoretically, *X* can take any value in the range 0 to ∞, and *f* (*x*) decreases
    as *x* increases.
  prefs: []
  type: TYPE_NORMAL
- en: • The “rate” parameter must be strictly positive; in other words, *λ*[e] > 0\.
    It defines *f* (0) and the rate of decay of the function to the horizontal asymptote
    at zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mean and variance are as follows, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f0359-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '**The dexp Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The density function for the exponential distribution is a steadily decreasing
    line beginning at *f* (0) = *λ*; the rate of this decay ensures a total area of
    1 underneath the curve. You create [Figure 16-11](ch16.xhtml#ch16fig11) with the
    relevant `d`-function in the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '![image](../images/f16-11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 16-11: Three different exponential density functions. Decreasing* *λ*[e]
    *lowers the mode and extends the tail.*'
  prefs: []
  type: TYPE_NORMAL
- en: The parameter *λ*[e] is provided to `rate` in `dexp`, which is evaluated at
    *x*, provided to the first argument `x` (via the `xvals` object in this example).
    You can see that a distinct feature of the exponential density function is that
    aforementioned decay to zero, with larger values of *λ*[e] translating to a taller
    (yet sharper and more rapid) drop.
  prefs: []
  type: TYPE_NORMAL
- en: This naturally decreasing behavior helps identify the role the exponential distribution
    often plays in applications—one of a “time-until-event” nature. In fact, there’s
    a special relationship between the exponential distribution and the Poisson distribution
    introduced in [Section 16.1.3](ch16.xhtml#ch16lev2sec139). When the Poisson distribution
    is used to model the count of a certain event through time, you use the exponential
    distribution to model the time between these events. In such a setting, the exponential
    parameter *λ*[e] defines the mean *rate* at which the events occur over time.
  prefs: []
  type: TYPE_NORMAL
- en: '**The pexp Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s revisit the example from [Exercise 16.2](ch16.xhtml#ch16exc2), where the
    average number of cars passing an individual within a 120-minute window was said
    to be 107\. Define the random variable *X* to be the waiting time between two
    consecutive cars passing and, using an exponential distribution for *X* on a minute
    time scale, set *λ*[e] = 107/120 ≈ 0.89 (rounded to 2 d.p.). If 107 cars are typically
    observed in a two-hour window, then you see cars at an average rate of 0.89 per
    minute.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, you interpret *λ*[e] as the “per-unit-time” measure of the *λ*[p] parameter
    from the Poisson mass function. The interpretation of the mean as the reciprocal
    of the rate, *μ[X]* = 1/λ[e], is also intuitive. For example, when observing cars
    at a rate of about 0.89 per minute, note that the average waiting time between
    cars is roughly 1/0.89 ≈ 1.12 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: So, in the current example, you want to examine the density ![image](../images/f0361-01.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Say a car has just passed the individual’s location and you want to find the
    probability that they must wait more than two and a half minutes before seeing
    another car, in other words, Pr(*X* > 2.5). You can do so using `pexp`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This indicates that you have just over a 10 percent chance of observing at
    least a 2-minute 30-second gap before the next car appears. Remember that the
    default behavior of the `p`-function is to find the cumulative, left-hand probability
    from the provided value, so you need to subtract the result from 1 to find an
    upper-tail probability. You find the probability of waiting less than 25 seconds
    with the following, which gives a result of roughly 0.31:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Note the need to first convert the value of interest from seconds to minutes
    since you’ve defined *f* (*x*) via *λ*[e] ≈ 0.89 on the scale of the latter.
  prefs: []
  type: TYPE_NORMAL
- en: '**The qexp Function**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Use the appropriate quantile function `qexp` to find, say, the cutoff point
    for the shortest 15 percent of waits.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: This indicates that the value of interest is about 0.182 minutes, in other words,
    roughly 0.182 × 60 = 10.9 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: As usual, you can use `rexp` to generate random variates of any specific exponential
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*It is important to distinguish between the “exponential distribution,” the
    “exponential* family *of distributions,” and the “exponential* function*.” The
    first refers to the density function that’s just been studied, whereas the second
    refers to a general class of probability distributions, including the Poisson,
    the normal, and the exponential itself. The third is just the standard mathematical
    exponential function upon which the exponential family members depend and is directly
    accessible in R via* `exp`.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 16.5**'
  prefs: []
  type: TYPE_NORMAL
- en: Situated in the central north island of New Zealand, the Pohutu geyser is said
    to be the largest active geyser in the southern hemisphere. Suppose that it erupts
    an average of 3,500 times every year.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With the intention of modeling a random variable *X* as the time between consecutive
    eruptions, evaluate the parameter value *λ*[e] with respect to a time scale in
    days (assume 365.25 days per year to account for leap years).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot the density function of interest. What’s the mean wait in days between
    eruptions?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What’s the probability of waiting less than 30 minutes for the next eruption?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What waiting time defines the longest 10 percent of waits? Convert your answer
    to hours.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You can also use the exponential distribution to model certain product survival
    times, or “time-to-failure” type of variables. Say a manufacturer of a particular
    air conditioning unit knows that the product has an average life of 11 years before
    it needs any type of repair callout. Let the random variable *X* represent the
    time until the necessary repair of one of these units and assume *X* follows an
    exponential distribution with *λ*[e] = 1/11.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The company offers a five-year full repair warranty on this unit. What’s the
    probability that a randomly selected air conditioner owner makes use of the warranty?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A rival company offers a six-year guarantee on its competing air conditioning
    unit but knows that its units last, on average, only nine years before requiring
    some kind of repair. What are the chances of making use of that warranty?
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine the probabilities that the units in (i) and the units in (ii) last
    more than 15 years.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '***16.2.5 Other Density Functions***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are a number of other common probability density functions used for a
    wide variety of tasks involving continuous random variables. I’ll summarize a
    few here:'
  prefs: []
  type: TYPE_NORMAL
- en: • The *chi-squared distribution* models sums of squared normal variates and
    is thus often related to operations concerning sample variances of normally distributed
    data. Its functions are `dchisq`, `pchisq`, `qchisq`, and `rchisq`, and like the
    *t*-distribution ([Section 16.2.3](ch16.xhtml#ch16lev2sec143)), it’s dependent
    upon specification of a degrees of freedom provided as the argument `df`.
  prefs: []
  type: TYPE_NORMAL
- en: • The *F-distribution* is used to model ratios of two chi-squared random variables
    and is useful in, for example, regression problems (see [Chapter 20](ch20.xhtml#ch20)).
    Its functions are `df`, `pf`, `qf`, and `rf`, and as it involves two chi-squared
    values, it’s dependent upon the specification of a *pair* of degrees of freedom
    values supplied as the arguments `df1` and `df2`.
  prefs: []
  type: TYPE_NORMAL
- en: • The *gamma distribution* is a generalization of both the exponential and chi-squared
    distributions. Its functions are `dgamma`, `pgamma`, `qgamma`, and `rgamma`, and
    it’s dependent upon “shape” and “scale” parameters provided as the arguments `shape`
    and `scale`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: • The *beta distribution* is often used in Bayesian modeling, and it has implemented
    functions `dbeta`, `pbeta`, `qbeta`, and `rbeta`. It’s defined by two “shape”
    parameters *α* and *β*, supplied as `shape1` and `shape2`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, you’ll encounter the chi-squared and *F*-distributions over the
    next couple of chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*In all of the common probability distributions you’ve examined over the past
    couple of sections, I’ve emphasized the need to perform “one-minus” operations
    to find probabilities or quantiles with respect to an upper- or right-tailed area.
    This is because of the cumulative nature of the* `p`*- and* `q`*-functions—by
    definition, it’s the lower tail that is dealt with. However, most* `p`*- and*
    `q`*-functions in R include an optional logical argument,* `lower.tail`*, which
    defaults to* `FALSE`*. Therefore, an alternative is to set* `lower.tail=TRUE`
    *in any relevant function call, in which case R will expect or return upper-tail
    areas specifically.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Code in This Chapter**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| **Function/operator** | **Brief description** | **First occurrence** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `dbinom` | Binomial mass function | [Section 16.1.2](ch16.xhtml#ch16lev2sec138),
    [p. 335](ch16.xhtml#page_335) |'
  prefs: []
  type: TYPE_TB
- en: '| `pbinom` | Binomial cumulative problems | [Section 16.1.2](ch16.xhtml#ch16lev2sec138),
    [p. 336](ch16.xhtml#page_336) |'
  prefs: []
  type: TYPE_TB
- en: '| `qbinom` | Binomial quantiles function | [Section 16.1.2](ch16.xhtml#ch16lev2sec138),
    [p. 337](ch16.xhtml#page_337) |'
  prefs: []
  type: TYPE_TB
- en: '| `rbinom` | Binomial random realizations | [Section 16.1.2](ch16.xhtml#ch16lev2sec138),
    [p. 337](ch16.xhtml#page_337) |'
  prefs: []
  type: TYPE_TB
- en: '| `dpois` | Poisson mass function | [Section 16.1.3](ch16.xhtml#ch16lev2sec139),
    [p. 340](ch16.xhtml#page_340) |'
  prefs: []
  type: TYPE_TB
- en: '| `ppois` | Poisson cumulative problems | [Section 16.1.3](ch16.xhtml#ch16lev2sec139),
    [p. 341](ch16.xhtml#page_341) |'
  prefs: []
  type: TYPE_TB
- en: '| `rpois` | Poisson random realizations | [Section 16.1.3](ch16.xhtml#ch16lev2sec139),
    [p. 341](ch16.xhtml#page_341) |'
  prefs: []
  type: TYPE_TB
- en: '| `dunif` | Uniform density function | [Section 16.2.1](ch16.xhtml#ch16lev2sec141),
    [p. 344](ch16.xhtml#page_344) |'
  prefs: []
  type: TYPE_TB
- en: '| `punif` | Uniform cumulative problems | [Section 16.2.1](ch16.xhtml#ch16lev2sec141),
    [p. 346](ch16.xhtml#page_346) |'
  prefs: []
  type: TYPE_TB
- en: '| `qunif` | Uniform quantiles | [Section 16.2.1](ch16.xhtml#ch16lev2sec141),
    [p. 346](ch16.xhtml#page_346) |'
  prefs: []
  type: TYPE_TB
- en: '| `runif` | Uniform random realizations | [Section 16.2.1](ch16.xhtml#ch16lev2sec141),
    [p. 347](ch16.xhtml#page_347) |'
  prefs: []
  type: TYPE_TB
- en: '| `dnorm` | Normal density function | [Section 16.2.2](ch16.xhtml#ch16lev2sec142),
    [p. 350](ch16.xhtml#page_350) |'
  prefs: []
  type: TYPE_TB
- en: '| `pnorm` | Normal cumulative problems | [Section 16.2.2](ch16.xhtml#ch16lev2sec142),
    [p. 350](ch16.xhtml#page_350) |'
  prefs: []
  type: TYPE_TB
- en: '| `qnorm` | Normal quantiles | [Section 16.2.2](ch16.xhtml#ch16lev2sec142),
    [p. 353](ch16.xhtml#page_353) |'
  prefs: []
  type: TYPE_TB
- en: '| `rnorm` | Normal random realizations | [Section 16.2.2](ch16.xhtml#ch16lev2sec142),
    [p. 355](ch16.xhtml#page_355) |'
  prefs: []
  type: TYPE_TB
- en: '| `qt` | Student’s *t* quantiles | [Section 16.2.3](ch16.xhtml#ch16lev2sec143),
    [p. 358](ch16.xhtml#page_358) |'
  prefs: []
  type: TYPE_TB
- en: '| `dexp` | Exponential density function | [Section 16.2.4](ch16.xhtml#ch16lev2sec144),
    [p. 359](ch16.xhtml#page_359) |'
  prefs: []
  type: TYPE_TB
- en: '| `pexp` | Exponential cumulative problems | [Section 16.2.4](ch16.xhtml#ch16lev2sec144),
    [p. 361](ch16.xhtml#page_361) |'
  prefs: []
  type: TYPE_TB
- en: '| `qexp` | Exponential quantiles | [Section 16.2.4](ch16.xhtml#ch16lev2sec144),
    [p. 361](ch16.xhtml#page_361) |'
  prefs: []
  type: TYPE_TB
