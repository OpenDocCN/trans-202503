<html><head></head><body>
<section epub:type="chapter" role="doc-chapter" aria-labelledby="ch9">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_151" aria-label="151"/>&#13;
<hgroup>&#13;
&#13;
<h2 class="CHAPTER" id="ch9">&#13;
<span class="CN"><samp class="SANS_Futura_Std_Bold_Condensed_B_11">9</samp></span>&#13;
<span class="CT"><samp class="SANS_Dogma_OT_Bold_B_11">ANTI-DISASSEMBLY</samp></span>&#13;
</h2>&#13;
</hgroup>&#13;
<figure class="opener"><img class="opener" src="../images/opener.jpg" alt=""/></figure>&#13;
<p class="TNI2">Because disassemblers break down binary files into assembly code based on their own (often very complex) algorithms, there’s some room for error. Malware authors are aware of this vulnerability and can actively exploit it. They may also attempt to obfuscate the malware’s control flow or string and API function call references, making the code especially difficult to navigate statically. These are examples of <i>anti-disassembly</i> techniques, or ways in which malware complicates the process of reverse engineering code with a disassembler. In this chapter, we’ll look at these tactics in depth and what malware analysts can do to address them.</p>&#13;
<section epub:type="division" aria-labelledby="sec1">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_152" aria-label="152"/>&#13;
<h3 class="H1" id="sec1"><span id="h-127"/><samp class="SANS_Futura_Std_Bold_B_11">Breaking Disassemblers</samp></h3>&#13;
<p class="TNI1">Disassemblers interpret a file based on their own hardcoded logic and assumptions, which means that they can interpret bytes in different and sometimes problematic ways. Code could be incorrectly disassembled into data, or vice versa, and bytes might be added to the wrong instructions, producing completely new and erroneous instructions.</p>&#13;
<p class="TX">As an example, the bytes <samp class="SANS_TheSansMonoCd_W5Regular_11">e8 8c 45 0a 90</samp> can be dissembled into a call instruction. Removing the first byte (<samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp>) would result in a completely different disassembled instruction. In this common anti-disassembly approach, known as the <i>rogue byte</i> technique, rogue bytes are inserted into the malware to confuse the disassembly process. Consider, for example, the following code snippet:</p>&#13;
<pre class="pre-65"><code><var>--snip--</var>&#13;
00402100      b8 00 00 00 00  mov eax, 0x00&#13;
00402105...   85 c0           test eax, eax&#13;
00402107...   74 01           jz loc_402109 + 1&#13;
&#13;
loc_402109:&#13;
00402109      e8 8b 45 0a 90  call 0x900a4590&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">Here you can see several disassembled instructions in the right column, the bytes that make up those instructions in the middle column, and the address offset in the left column. These disassembled instructions don’t make much sense. For example, there’s a jump-if-zero (<samp class="SANS_TheSansMonoCd_W5Regular_11">jz</samp>) instruction with a target of <samp class="SANS_TheSansMonoCd_W5Regular_11">loc_402109</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">+ 1</samp>. This jump will always occur because the <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp> instruction prior to the <samp class="SANS_TheSansMonoCd_W5Regular_11">jz</samp> instruction sets <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp> to <samp class="SANS_TheSansMonoCd_W5Regular_11">0</samp>, but the code jumps to the <i>second</i> byte of the next instruction (byte <samp class="SANS_TheSansMonoCd_W5Regular_11">8b</samp>). The code also includes a call instruction to an address that doesn’t even exist in this executable, since our executable is in the <samp class="SANS_TheSansMonoCd_W5Regular_11">0x00402xxx</samp> address range, not the <samp class="SANS_TheSansMonoCd_W5Regular_11">0x900xxxxx</samp> range. Let’s take a closer look.</p>&#13;
<p class="TX">As <span class="Xref"><a href="chapter3.xhtml">Chapter 3</a></span> explained, a disassembler doesn’t always know how to differentiate code from data. This means that when it converts bytes to code, that code may in reality be data, or vice versa. The bytes that make up the <samp class="SANS_TheSansMonoCd_W5Regular_11">call 0x900a4590</samp> instruction are <samp class="SANS_TheSansMonoCd_W5Regular_11">e8 8b 45 0a 90</samp>. The first byte, <samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp>, represents the call instruction in the x86 assembly instruction set. If we take out this byte, we’re left with <samp class="SANS_TheSansMonoCd_W5Regular_11">8b 45 0a 90</samp>. This series of bytes in x86 assembly is equivalent to the following code:</p>&#13;
<pre class="pre-66"><code>mov eax, [ebp+10]&#13;
nop</code></pre>&#13;
<p class="TX">Here we have a <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp> instruction (to move the value stored on the stack at <samp class="SANS_TheSansMonoCd_W5Regular_11">ebp+10</samp> to <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp>), followed by a <samp class="SANS_TheSansMonoCd_W5Regular_11">nop</samp> instruction. This code makes a lot more sense than our original call instruction (<samp class="SANS_TheSansMonoCd_W5Regular_11">call 0x900a4590</samp>). Thus, it seems that the first byte (<samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp>) is a rogue byte, added to the code simply to confuse disassemblers.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_153" aria-label="153"/>You can deal with this by overriding incorrect code or data. In IDA, you can hit the C and D keys (C for converting data to code and D for converting code to data). In Ghidra, it’s the opposite, confusingly enough; press C for converting code to data (C stands for “clear code bytes,” in this case) and D for converting data to code (D stands for “disassemble”).</p>&#13;
<p class="TX">If you select the bogus call instruction in IDA and press D, the instruction is broken into data, as shown here:</p>&#13;
<pre class="pre-67"><code><var>--snip--</var>&#13;
00402100 mov eax, 0x00&#13;
00402105 test eax, eax&#13;
00402107 jz loc_402109 + 1&#13;
&#13;
00402109 loc_402109:&#13;
<span class="CodeAnnotationHang">1</span> 00402109 db E8h&#13;
0040210A db 8Bh&#13;
0040210B db 45h&#13;
0040210C db 0Ah&#13;
0040210D db 90h&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">Notice that what once was code is now data bytes, starting at <span class="CodeAnnotation" aria-label="annotation1">❶</span>. Now, if you select the byte values starting at offset <samp class="SANS_TheSansMonoCd_W5Regular_11">0040210A</samp> (taking care not to select the <samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp> byte) and continuing until <samp class="SANS_TheSansMonoCd_W5Regular_11">0040210D</samp>, then press C to convert this to code, you get the following:</p>&#13;
<pre class="pre-68"><code><var>--snip--</var>&#13;
00402100 mov eax, 0x00&#13;
00402105 test eax, eax&#13;
00402107 jz loc_402109 + 1&#13;
&#13;
00402109 loc_402109:&#13;
00402109 db E8h&#13;
0040210A mov eax, [ebp+10]&#13;
0040210D nop&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">The malware moves <samp class="SANS_TheSansMonoCd_W5Regular_11">0x00</samp> into <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp> (in order to zero-out <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp>) and then uses a condition jump (<samp class="SANS_TheSansMonoCd_W5Regular_11">jz</samp>); as noted earlier, the code will always take this jump. However, now the code jumps right over the rogue byte (<samp class="SANS_TheSansMonoCd_W5Regular_11">e8</samp>) and executes the <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">nop</samp> instructions instead. This malware sample cleverly inserted the rogue byte in order to trick the disassembler into thinking that it was part of the original call instruction!</p>&#13;
<p class="TX">This is a fairly simple example of an anti-disassembly method, but it’s a common one. This presents a challenge for both disassemblers and reverse engineers. When you encounter situations like this, in which code is simply incorrect or doesn’t make sense, try manually converting the code to data bytes or some of the bytes into code. It may help you fix up the code so that you can better understand it.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec2">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_154" aria-label="154"/>&#13;
<h3 class="H1" id="sec2"><span id="h-128"/><samp class="SANS_Futura_Std_Bold_B_11">Control Flow Obfuscation</samp></h3>&#13;
<p class="TNI1">The next anti-disassembly method we’ll look at is <i>control flow obfuscation</i>, or adding unnecessary complexity to the malware code, making it much more difficult to analyze statically. This type of obfuscation can also flummox disassemblers, which may fail to properly disassemble the code.</p>&#13;
<p class="TX">To add this type of obfuscation, malware authors use specialized code obfuscators designed specifically for this purpose or malware packers, which we’ll discuss in detail in <span class="Xref"><a href="chapter17.xhtml">Chapter 17</a></span>. Let’s dig into some of the common methods used to obfuscate control flow. At the end of this section, we’ll discuss a few general strategies to deal with these tactics.</p>&#13;
<section epub:type="division" aria-labelledby="sec3">&#13;
&#13;
<h4 class="H2" id="sec3"><span id="h-129"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Unnecessary Jumps</samp></h4>&#13;
<p class="TNI1">Malware authors may add unnecessary jump statements to break up the malware’s code into smaller blocks (see <a href="chapter9.xhtml#fig9-1">Figure 9-1</a>).</p>&#13;
<figure class="IMG"><img class="img60" id="fig9-1" src="../images/fig9-1.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-1: Unnecessary jump instructions</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">The code in <a href="chapter9.xhtml#fig9-1">Figure 9-1</a> was once a single block, but an obfuscator has broken it into chunks, with each block connecting to the next with a jump statement. Functionally, the code is the same, but now reverse engineers will have more difficulty understanding and following it. This example is quite basic, but obfuscators can add a nearly infinite amount of complexity to code, as you’ll see in the next few sections.</p>&#13;
<p class="TX">Obfuscators can also make code jump forward and backward frequently in order to make it harder to follow sequentially, as in this example:</p>&#13;
<pre class="pre-69"><code><span role="doc-pagebreak" epub:type="pagebreak" id="pg_155" aria-label="155"/><var>--snip--</var>&#13;
push 300h&#13;
jmp loc_402B20&#13;
<var>--snip--</var>&#13;
loc_402A30:&#13;
call Sleep&#13;
jmp loc_402B65&#13;
<var>--snip--</var>&#13;
loc_402B20:&#13;
pop ebx&#13;
jmp loc_402A30&#13;
<var>--snip--</var>&#13;
loc_402B65:&#13;
push ecx&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">This code jumps around to different areas simply for the sake of confusion. It first jumps to <samp class="SANS_TheSansMonoCd_W5Regular_11">loc_402B20</samp>, then back up to <samp class="SANS_TheSansMonoCd_W5Regular_11">loc_402A30</samp>, and then back down to <samp class="SANS_TheSansMonoCd_W5Regular_11">loc_402B65</samp>, creating a hard-to-follow code flow logic.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec4">&#13;
&#13;
<h4 class="H2" id="sec4"><span id="h-130"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Unnecessary Code</samp></h4>&#13;
<p class="TNI1">Malware authors can add other types of unnecessary code to their malware. For example, they might create copies of code blocks or functions that are effectively the same, or at least very similar, so that the code can then be executed interchangeably, leading to the same final block of code, as shown in <a href="chapter9.xhtml#fig9-2">Figure 9-2</a>.</p>&#13;
<figure class="IMG"><img class="img60" id="fig9-2" src="../images/fig9-2.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-2: Interchangeable code blocks</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">This doesn’t affect the malware’s behavior but creates complexity for reverse engineers.</p>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_156" aria-label="156"/>Alternatively, malware authors and obfuscators can add dummy code that will never be executed and exists only to confuse analysts, waste CPU cycles, and slow down the analysis process. This code could be anything, so it’s difficult to provide concrete examples of what it might look like, but this snippet demonstrates the technique:</p>&#13;
<pre class="pre-70"><code><var>--snip--</var>&#13;
inc ecx&#13;
push ecx&#13;
dec ecx&#13;
push ecx&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">This code is simply incrementing the <samp class="SANS_TheSansMonoCd_W5Regular_11">ecx</samp> register by 1, pushing this value to the stack, decrementing it by 1, and then pushing that value to the stack. It quite obviously serves no valid purpose.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec5">&#13;
&#13;
<h4 class="H2" id="sec5"><span id="h-131"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Control Flow Flattening</samp></h4>&#13;
<p class="TNI1"><i>Control flow flattening</i> is a method of obfuscating control flow by compressing a sequence of conditional code blocks into a single block. This is usually accomplished via switch statements that direct control flow. <a href="chapter9.xhtml#fig9-3">Figure 9-3</a> shows a program before control flattening has occurred.</p>&#13;
<figure class="IMG"><img class="img60" id="fig9-3" src="../images/fig9-3.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-3: A program before control flow flattening is applied</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">This program represents normal, unobfuscated code. In the code block labeled <span class="CodeAnnotation" aria-label="annotation1">❶</span>, there’s a conditional statement that will jump to one of two locations (code block <span class="CodeAnnotation" aria-label="annotation2">❷</span> or <span class="CodeAnnotation" aria-label="annotation3">❸</span>). If this program were run through a control flow–flattening algorithm, it might end up looking more like <a href="chapter9.xhtml#fig9-4">Figure 9-4</a>.</p>&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_157" aria-label="157"/>&#13;
<figure class="IMG"><img class="img100" id="fig9-4" src="../images/fig9-4.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-4: A program after control flow flattening is applied</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">In <a href="chapter9.xhtml#fig9-3">Figure 9-3</a>, code block <span class="CodeAnnotation" aria-label="annotation1">❶</span> was responsible for the conditional statement that led to the jump to either code block <span class="CodeAnnotation" aria-label="annotation2">❷</span> or <span class="CodeAnnotation" aria-label="annotation3">❸</span>. In the flattened code, a <i>central dispatch</i> code block <span class="CodeAnnotation" aria-label="annotation1">❶</span> is responsible for the conditional statement but also keeps track of where the code should “flow” next. After the dispatcher directs the control flow to a block of code, control is returned to the dispatcher, which directs the control flow further. The dispatcher adds complexity to the disassembled code, making it more difficult for an analyst to understand its purpose and where execution will flow next.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec6">&#13;
&#13;
<h4 class="H2" id="sec6"><span id="h-132"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Opaque Predicates</samp></h4>&#13;
<p class="TNI1">An <i>opaque predicate</i> (see <a href="chapter9.xhtml#fig9-5">Figure 9-5</a>) is a value that is known to the program’s author but not to the program or disassembler at runtime. The program’s creator (in our case, the malware author) knows that a certain expression will result in a specific value, for example, but neither we as reverse engineers nor our disassembler tools know this.</p>&#13;
<figure class="IMG"><img class="img60" id="fig9-5" src="../images/fig9-5.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-5: An opaque predicate in action</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX">This code can take one of two paths, determined by the expression <samp class="SANS_TheSansMonoCd_W5Regular_11">1</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">==</samp> <samp class="SANS_TheSansMonoCd_W5Regular_11">2</samp> (the opaque predicate). The malware author already knows that the <span role="doc-pagebreak" epub:type="pagebreak" id="pg_158" aria-label="158"/>program will take the branch to the right, but the analyst and the disassembler must manually analyze the logic to learn this. Obviously, this is a simplified example that almost anyone could decipher. However, malware authors can make an opaque predicate infinitely complex, for example, by calculating complicated mathematical functions at runtime.</p>&#13;
<p class="TX">This technique can also be combined with those previously mentioned, such as adding unnecessary code. The malware author could include a large amount of garbage code in the left branch that will never be executed. The reverse engineer must understand the opaque predicate before analyzing the rest of the program to avoid wasting time on the garbage code. Opaque predicates are difficult to deal with and, as mentioned, can be as basic or complex as the malware author wishes. Often the best way to deal with them is to step through the malware in a debugger that will help reveal the true control flow.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec7">&#13;
&#13;
<h4 class="H2" id="sec7"><span id="h-133"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Return Pointer Abuse</samp></h4>&#13;
<p class="TNI1">Another way to obfuscate control flow is with return (<samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp>) instructions. For example, if a program executes Function B, once it reaches the end of that function, Function B will issue a <samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp> instruction to return to its parent function (Function A). Before Function B can return, though, the program needs to know where to return to. Therefore, the return address is pushed to the stack before Function B executes and is popped off the stack once the <samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp> instruction is executed. The following assembly code demonstrates this:</p>&#13;
<pre class="pre-71"><code>push returnAddress&#13;
<var>--snip--</var>&#13;
ret</code></pre>&#13;
<p class="TX">This code issues a <samp class="SANS_TheSansMonoCd_W5Regular_11">push</samp> instruction to push <samp class="SANS_TheSansMonoCd_W5Regular_11">returnAddress</samp> and then executes the <samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp> instruction, which will pop <samp class="SANS_TheSansMonoCd_W5Regular_11">returnAddress</samp> off the stack to return the program’s control flow to the parent function.</p>&#13;
<p class="TX">Malware can abuse the way return pointers work to replicate a <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp> or <samp class="SANS_TheSansMonoCd_W5Regular_11">jmp</samp> instruction. By pushing an address to the stack and then executing a <samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp> instruction, the malware will force the control flow to execute the code at the new return address. This can confuse some disassemblers and generally makes following the code more difficult for the analyst as well.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec8">&#13;
&#13;
<h4 class="H2" id="sec8"><span id="h-134"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">SEH Handler Abuse</samp></h4>&#13;
<p class="TNI1">Malware can also take advantage of the <i>structured exception handler (SEH)</i>, which stores a series of addresses for the pieces of code responsible for handling exceptions in Windows applications. When the application raises an exception, its control flow transfers to one of the addresses stored in the SEH.</p>&#13;
<p class="TX">Malware can abuse the SEH by creating a new exception handler that points to malicious code. When the malware purposefully causes an exception in its code, the control flow will be transferred to code referenced in the exception handler. As a result, the analyst will need to know where the malware established the exception handler, as well as where the exception <span role="doc-pagebreak" epub:type="pagebreak" id="pg_159" aria-label="159"/>handler is pointing, in order to properly reverse engineer the code. Consider the following example:</p>&#13;
<pre class="pre-72"><code><var>--snip--</var>&#13;
mov eax, evil.429D8C&#13;
push eax&#13;
push dword ptr fs:[0]&#13;
mov dword ptr fs:[0], esp&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">The focus of this code block is <samp class="SANS_TheSansMonoCd_W5Regular_11">fs:[0]</samp>, which essentially points to the current exception handler. The malware replaces the default exception handler code with a pointer to malicious code (<samp class="SANS_TheSansMonoCd_W5Regular_11">evil.429D8C</samp>). Once the malware triggers an exception, the code’s control flow will be transferred to the address <samp class="SANS_TheSansMonoCd_W5Regular_11">evil.429D8C</samp>. As there are no <samp class="SANS_TheSansMonoCd_W5Regular_11">jmp</samp>, <samp class="SANS_TheSansMonoCd_W5Regular_11">ret</samp>, or <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp> instructions in use here, this control flow transfer can be difficult for the untrained eye to follow, so be on the lookout for code referencing <samp class="SANS_TheSansMonoCd_W5Regular_11">fs:[0]</samp>. It’s also common to see this followed by a <samp class="SANS_TheSansMonoCd_W5Regular_11">div</samp> instruction, which might indicate that the malware is attempting to cause a division-by-zero exception. We’ll discuss SEH and this specific code block further in <span class="Xref"><a href="chapter11.xhtml">Chapter 11</a></span>.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec9">&#13;
&#13;
<h4 class="H2" id="sec9"><span id="h-135"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Function Pointer Abuse</samp></h4>&#13;
<p class="TNI1">As you’ve seen, a typical control flow transfer to a new function will involve a jump or call instruction. However, crafty malware can obscure these instructions by introducing function pointers like so:</p>&#13;
<pre class="pre-73"><code><var>--snip--</var>&#13;
mov [ebp+var_26], offset sub_4511D5&#13;
call [ebp+var_26]&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">This malware sample moves the offset address of the function <samp class="SANS_TheSansMonoCd_W5Regular_11">sub_4511D5</samp> into a variable on the stack, <samp class="SANS_TheSansMonoCd_W5Regular_11">var_26</samp>. Then, it uses a call instruction and references the <samp class="SANS_TheSansMonoCd_W5Regular_11">var_26</samp> variable, which contains the address of the target function it wishes to call (<samp class="SANS_TheSansMonoCd_W5Regular_11">sub_4511D5</samp>).</p>&#13;
<p class="TX">This is a simple technique, but you can likely see how it might cause confusion during static analysis. To overcome this technique, you’d have to pinpoint the suspect call instruction and look backward through the code until you could identify what is stored in the referenced function pointer. Malware authors can make this obfuscation technique much more complex, however. For example, it can pass function offsets between different variables, which would make it very difficult for the analyst to identify the call’s target function. Analyzing code such as this in a debugger can better help you understand what is going on.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec10">&#13;
&#13;
<h4 class="H2" id="sec10"><span id="h-136"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Control Flow Obfuscation Countermeasures</samp></h4>&#13;
<p class="TNI1">This chapter has outlined only a few of the most common control flow obfuscation techniques, but you can overcome most of them with a few <span role="doc-pagebreak" epub:type="pagebreak" id="pg_160" aria-label="160"/>methods. First, you can use the same approach described in <span class="Xref">“Breaking Disassemblers”</span> on <span class="Xref"><a href="chapter9.xhtml#pg_152">page 152</a></span>. If you spot code that is impossible or simply doesn’t make sense, try converting it into data. This may help you spot anomalies such as rogue bytes. The inverse is also true: if you spot data abnormalities or large sections of data in between code, try converting the data into code and reassessing it. This small tip may help you get around many simple anti-disassembly techniques.</p>&#13;
<p class="TX">Second, stepping through the code in a debugger can make a world of difference; it usually makes understanding the code and control flow much easier. The debugger can be used alongside the disassembler, and you can set a debugger breakpoint on the addresses of code that you don’t entirely understand. If you spot a rogue byte in the code, for example, the debugger can help you understand what may be occurring. Some malware analysts like to use a disassembler with a built-in debugger (such as IDA Pro) for this very reason, but a separate disassembler and debugger will do just fine. I typically pair x64dbg with Ghidra or IDA.</p>&#13;
<p class="TX">Third, you can try to identify the obfuscator that was used on the malware. For example, tools such as Detect It Easy (DIE) and Exeinfo PE will attempt to identify possible obfuscators and packers (covered in <span class="Xref"><a href="chapter17.xhtml">Chapter 17</a></span>). Once you’ve identified the obfuscator or packer, doing a bit of research on how it works may give you some insight into how you can reverse it, or there may even be a public deobfuscator available! Some tools attempt to generically deobfuscate code and remove some of the complexity, but in my experience they tend to not work very well and can leave holes in the code or misinterpret it. Finally, different disassemblers tend to disassemble code a bit differently. If you primarily use IDA, for example, give Ghidra or another disassembler a try and see if you get a result that’s easier to understand.</p>&#13;
<p class="TX">Ultimately, dealing with anti-disassembly requires knowledge and experience of the assembly language, and there’s no substitute for that. Learning assembly (x86, x64, or for whatever type of malware you’re reversing) and continuing to build that skill set will help you more quickly identify the anti-disassembly and code obfuscation techniques being employed by malware.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec11">&#13;
&#13;
<h3 class="H1" id="sec11"><span id="h-137"/><samp class="SANS_Futura_Std_Bold_B_11">API Call and String Obfuscation</samp></h3>&#13;
<p class="TNI1">In this section, you’ll learn how malware can obfuscate its Windows API function calls and strings to hide its intentions from analysts.</p>&#13;
<blockquote>&#13;
<p class="Note"><span class="NoteHead"><samp class="SANS_Dogma_OT_Bold_B_15">NOTE</samp></span></p>&#13;
</blockquote>&#13;
<p class="NOTE-TXT"><i>This section outlines obfuscation techniques that are specifically applicable to anti-disassembly and protection against static analysis, but <a href="chapter16.xhtml">Chapter 16</a> covers more generic obfuscation techniques. API call and string obfuscation can also be used for endpoint defense evasion, such as sidestepping anti-malware software, but <a href="part4.xhtml">Part IV</a> will discuss this topic in more depth.</i></p>&#13;
<section epub:type="division" aria-labelledby="sec12">&#13;
<span role="doc-pagebreak" epub:type="pagebreak" id="pg_161" aria-label="161"/>&#13;
<h4 class="H2" id="sec12"><span id="h-138"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Dynamic API Function Resolution</samp></h4>&#13;
<p class="TNI1"><i>Dynamic API function resolution</i> is when a program dynamically obtains the address of a function it wishes to call, rather than including the function in its import address table (IAT). The Windows API function <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp> can assist with this. <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp> retrieves the procedural address of a function inside a given module, and it takes two parameters: a handle to the module where the target function resides, and the name of the target function itself. Sometimes <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp> is preceded by a call to <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibrary</samp>, which will load the module that contains the target function. Let’s take a look at this in practice:</p>&#13;
<pre class="pre-74"><code><var>--snip--</var>&#13;
push ecx ; "kernel32.dll"&#13;
call LoadLibraryA&#13;
push eax&#13;
push edx ; "IsDebuggerPresent"&#13;
call GetProcAddress&#13;
call eax&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">This malware sample first pushes the name of the module that contains the target function (in this case, <i>kernel32.dll</i>) to the stack and invokes <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp>, which loads this library into the address space of the process. <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp> returns a handle to the <i>kernel32.dll</i> module, which is stored in <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp> and is then pushed to the stack (<samp class="SANS_TheSansMonoCd_W5Regular_11">push eax</samp>). Next, the code pushes the name of the target function <samp class="SANS_TheSansMonoCd_W5Regular_11">IsDebuggerPresent</samp> to the stack and calls <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>. The call to <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp> returns the address of the target function and stores it in <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp>. Finally, the malware executes a call instruction with the target of <samp class="SANS_TheSansMonoCd_W5Regular_11">eax</samp>, which will subsequently invoke <samp class="SANS_TheSansMonoCd_W5Regular_11">IsDebuggerPresent</samp>. As you can see, this technique adds a layer of obfuscation to the function call.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec13">&#13;
&#13;
<h4 class="H2" id="sec13"><span id="h-139"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Jump Tables and Indirect API Calls</samp></h4>&#13;
<p class="TNI1">API calls can be obfuscated with <i>jump tables</i>, data structures that map addresses of external libraries. Jump tables can serve as a method both to obfuscate control flow and to hamper static code analysis. <a href="chapter9.xhtml#fig9-6">Figure 9-6</a> shows what a jump table might look like in action.</p>&#13;
<figure class="IMG"><img class="img100" id="fig9-6" src="../images/fig9-6.jpg" alt=""/>&#13;
<figcaption><p class="CAP"><samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 9-6: A jump table in action</samp></p></figcaption>&#13;
</figure>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_162" aria-label="162"/>In this simplified example, the malware’s main code makes <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp> instructions to different addresses representing the Windows API function the malware wishes to call. The malware’s code then transfers control flow to the jump table, which in this case is essentially a list of further <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp> instructions that use <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp> to get the procedure address of the target Windows API function, and subsequently invokes that function. When the malware wishes to call <samp class="SANS_TheSansMonoCd_W5Regular_11">WriteFile</samp>, for example, it makes a call to <samp class="SANS_TheSansMonoCd_W5Regular_11">sub_2082A2B0</samp>, which jumps to the jump table, which in turn gets the address of <samp class="SANS_TheSansMonoCd_W5Regular_11">WriteFile</samp> in the <i>kernel32.dll</i> library.</p>&#13;
<p class="TX">Jump tables can be as simple as a list of <samp class="SANS_TheSansMonoCd_W5Regular_11">call</samp> instructions, as shown here:</p>&#13;
<pre class="pre-75"><code>sub_JumpTable:&#13;
call sub_2052B2A0 ; jumps to code that further invokes WriteFile&#13;
call sub_2052B2B0 ; jumps to code that further invokes ReadFile&#13;
call sub_2052B2C0 ; jumps to code that further invokes IsDebuggerPresent&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">API functions in the jump table can be dynamically resolved upon the malware’s initial execution (thus building the table dynamically) or can be invoked by the malware as needed, meaning the function addresses are resolved on demand. This adds further complexity to the jump table, making the code more difficult for the reverser to follow.</p>&#13;
<p class="TX">Malware may also use indirect API calls. Similar to jump tables, API function addresses are dynamically resolved and stored in memory or in CPU registers for later use. Then, the malware invokes the function by issuing a call instruction for the address of the function rather than by function name. You can see this in the following 64-bit simplified code example:</p>&#13;
<pre class="pre-76"><code><var>--snip--</var>&#13;
mov  rcx, hModule ; "advapi32.dll"&#13;
mov  rdx, "CryptEncrypt"&#13;
call GetProcAddress&#13;
mov  [rbp-39], rax&#13;
mov  rcx, hModule ; "advapi32.dll"&#13;
mov  rdx, "CryptDecrypt"&#13;
call GetProcAddress&#13;
mov  [rbp-35], rax&#13;
mov  rcx, hModule ; "kernel32.dll"&#13;
mov  rdx, "WriteFile"&#13;
call GetProcAddress&#13;
mov  [rbp-31], rax&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">This code is using indirect calls to obfuscate its function calls. First, it moves the name of the target function it wishes to call (<samp class="SANS_TheSansMonoCd_W5Regular_11">CryptEncrypt</samp>) into <samp class="SANS_TheSansMonoCd_W5Regular_11">rdx</samp>, as well as the associated module name (<samp class="SANS_TheSansMonoCd_W5Regular_11">hModule</samp>), which, in the case of these functions, resides in <i>kernel32.dll</i>. Next, the code calls <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp> to get the address of the <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptEncrypt</samp> function. Then, the code moves this address onto the stack (<samp class="SANS_TheSansMonoCd_W5Regular_11">mov [rbp-39], rax</samp>), which will be used later. The code runs this procedure twice more, for the functions <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptDecrypt</samp> and <span role="doc-pagebreak" epub:type="pagebreak" id="pg_163" aria-label="163"/><samp class="SANS_TheSansMonoCd_W5Regular_11">WriteFile</samp>. After storing the addresses of its target functions on the stack, the code can later invoke these functions by their addresses like so:</p>&#13;
<pre class="pre-77"><code>call [rbp-39]</code></pre>&#13;
<p class="TX">This call instruction will invoke the function stored on the stack at <samp class="SANS_TheSansMonoCd_W5Regular_11">rbp-39</samp>, which happens to be <samp class="SANS_TheSansMonoCd_W5Regular_11">CryptEncrypt</samp>, a function used for encrypting data. Calling functions this way provides a layer of obfuscation for researchers who are manually reverse engineering the code.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec14">&#13;
&#13;
<h4 class="H2" id="sec14"><span id="h-140"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Stack Strings</samp></h4>&#13;
<p class="TNI1"><i>Stack strings</i> refer to strings that are built on the stack dynamically in memory by the malware. They add a layer of obfuscation to a malware executable, making static analysis a bit more time-consuming, as shown here:</p>&#13;
<pre class="pre-78"><code><var>--snip--</var>&#13;
mov   [ebp+file], 65h&#13;
mov   [ebp+file+1], 76h&#13;
mov   [ebp+file+2], 69h&#13;
mov   [ebp+file+3], 6Ch&#13;
mov   [ebp+file+4], 2Eh&#13;
mov   [ebp+file+5], 64h&#13;
mov   [ebp+file+6], 6Ch&#13;
mov   [ebp+file+7], 6Ch&#13;
lea   eax, [ebp+file]&#13;
push  eax&#13;
call LoadLibraryA&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX">This code snippet contains several <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp> instructions, representing the code moving data onto the stack. What’s interesting about them is that they’re moving hex values, byte by byte, into a buffer (<samp class="SANS_TheSansMonoCd_W5Regular_11">ebp+file</samp>). If you convert these hex values into ASCII (using the R key in IDA or selecting <b>Right-click</b><span class="MenuArrow"></span><b>Convert</b><span class="MenuArrow"></span><b>Char</b> in Ghidra), you can deobfuscate this stack string like so:</p>&#13;
<pre class="pre-79"><code><var>--snip--</var>&#13;
mov   [ebp+file], 'e'&#13;
mov   [ebp+file+1], 'v'&#13;
mov   [ebp+file+2], 'i'&#13;
mov   [ebp+file+3], 'l'&#13;
mov   [ebp+file+4], '.'&#13;
mov   [ebp+file+5], 'd'&#13;
mov   [ebp+file+6], 'l'&#13;
mov   [ebp+file+7], 'l'&#13;
lea   eax, [ebp+file]&#13;
push  eax&#13;
call LoadLibraryA&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_164" aria-label="164"/>Now you can make a more educated guess about what the malware is doing with this data. It’s creating a string (<samp class="SANS_TheSansMonoCd_W5Regular_11">evil.dll</samp>) on the stack and calling <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp>, which will load this malicious DLL file into the malware’s process. This is a form of <i>process injection</i>, a technique <span class="Xref"><a href="part4.xhtml">Part IV</a></span> will cover in depth.</p>&#13;
<p class="TX">There are some great tools malware analysts can use for automating stack string deobfuscation. Running a malware sample through FLOSS (discussed in <span class="Xref"><a href="chapter2.xhtml">Chapter 2</a></span>), for example, can deobfuscate some basic string obfuscation and build an IDA script file so that you can easily load this data back into your IDA database. Here’s an example of FLOSS output:</p>&#13;
<pre class="pre-80"><code>&gt; FLOSS extracted 55 stackstrings&#13;
GetWindowsDirectoryA&#13;
VirtualAllocEx&#13;
GetSystemDirectoryA&#13;
Software\Microsoft\Windows NT\CurrentVersion\Windows&#13;
DeleteFileA&#13;
WriteFile&#13;
RegDeleteValueA&#13;
RegDeleteKeyA&#13;
ineIntel&#13;
GetUserNameA&#13;
CreateProcessA&#13;
recv&#13;
FindExecutableA&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX"><i>Pestr</i> (<a href="https://pev.sourceforge.io"><i>https://<wbr/>pev<wbr/>.sourceforge<wbr/>.io</i></a>), another tool for stack string deobfuscation, can be run nearly the same way. Both tools are easy enough to quickly run before starting your reverse engineering process and may save you some time when analyzing malware code that has implemented basic string obfuscation.</p>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec15">&#13;
&#13;
<h4 class="H2" id="sec15"><span id="h-141"/><samp class="SANS_Futura_Std_Bold_Condensed_Oblique_I_11">Data Hashing</samp></h4>&#13;
<p class="TNI1">Malware authors can obfuscate malware functionalities by using data <i>hashing</i>, which is a kind of one-way data encoding; that is, it takes some data and encodes it into something else that can’t be reversed. The ransomware family Maze uses the well-known <i>ROR-13</i> hashing algorithm to obfuscate Windows API function calls, as shown in the following code:</p>&#13;
<pre class="pre-81"><code><var>--snip--</var>&#13;
mov  [esp+38h+var_38], eax&#13;
mov  [esp+38h+var_34], 7C0DFCAAh ; GetProcAddress&#13;
call sub_4011A0&#13;
sub  esp, 8&#13;
mov  [ebp+var_24], eax&#13;
mov  eax, [ebp+var_4]&#13;
mov  [esp+38h+var_38], eax&#13;
mov  [esp+38h+var_34], 0EC0E4E8Eh ; LoadLibraryA&#13;
call sub_4011A0&#13;
<var>--snip--</var></code></pre>&#13;
<p class="TX"><span role="doc-pagebreak" epub:type="pagebreak" id="pg_165" aria-label="165"/>The <samp class="SANS_TheSansMonoCd_W5Regular_11">mov</samp> instruction in the second line moves the ROR-13 hash <samp class="SANS_TheSansMonoCd_W5Regular_11">7C0DFCAAh</samp>, the value of <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp>, onto the stack. Similarly, the hash <samp class="SANS_TheSansMonoCd_W5Regular_11">0EC0E4E8Eh</samp> represents the <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp> function, which moved to the stack in line 8. This malware is obfuscating its calls to the <samp class="SANS_TheSansMonoCd_W5Regular_11">GetProcAddress</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">LoadLibraryA</samp> functions using hashes in place of the function name. There must be a function that is responsible for interpreting these hashes and loading the address of the target functions (in this case, function <samp class="SANS_TheSansMonoCd_W5Regular_11">sub_4011A0</samp>), but this is not shown in the preceding code and the specifics of this are outside the scope of this chapter. However, this is well documented, such as in the blog post “Windows API Hashing in Malware” at <a href="https://www.ired.team/offensive-security/defense-evasion/windows-api-hashing-in-malware"><i>https://<wbr/>www<wbr/>.ired<wbr/>.team<wbr/>/offensive<wbr/>-security<wbr/>/defense<wbr/>-evasion<wbr/>/windows<wbr/>-api<wbr/>-hashing<wbr/>-in<wbr/>-malware</i></a>.</p>&#13;
<p class="TX">It’s difficult to understand what’s happening here simply by reviewing the code, since the function names are hashed and therefore unreadable. Luckily, many disassemblers have special features or plug-ins that can automatically identify potential hashed function names. In my case, the IDA plug-in <i>apihashes</i> was able to correctly identify and annotate the ROR-13–hashed data. Hashing will be discussed in greater detail in <span class="Xref"><a href="chapter16.xhtml">Chapter 16</a></span>.</p>&#13;
</section>&#13;
</section>&#13;
<section epub:type="division" aria-labelledby="sec16">&#13;
&#13;
<h3 class="H1" id="sec16"><span id="h-142"/><samp class="SANS_Futura_Std_Bold_B_11">Summary</samp></h3>&#13;
<p class="TNI1">In this chapter, you learned about several anti-disassembly techniques malware might employ to protect itself from malware analysts and their tools. Deobfuscating assembly code is a challenging task that requires a high level of technical skill and knowledge of a malware’s behavior and characteristics. Compounding this challenge is the fact that many of these techniques are very simple for malware authors to implement, thanks to special code compilers, obfuscators, and tools such as packers. It’s often much easier for malware authors to implement anti-disassembly measures than it is for reverse engineers to circumvent them, but fighting back against such techniques is crucial to understanding the malware’s behavior and functionality. As an analyst, you should use the range of tools and techniques at your disposal to deobfuscate malware code and reveal its true intentions.</p>&#13;
<p class="TX">In the next chapter, we’ll discuss another anti-reversing technique that some malware implements to thwart dynamic code analysis: anti-debugging.</p>&#13;
</section>&#13;
</section>&#13;
</body></html>