- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_B_11">13</samp> <samp class="SANS_Dogma_OT_Bold_B_11">RANDOM
    WALKS</samp>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/opener.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'So far, this book has introduced a variety of algorithms focused on achieving
    specific goals. This chapter considers algorithms that seek to do something a
    bit different: inducing *random behavior* on graphs. Analyzing random movement
    through a graph allows us to model and study systems with nondeterministic behavior
    such as randomized network routing or real-world social interactions.'
  prefs: []
  type: TYPE_NORMAL
- en: Random walks on graphs have a rich mathematical history that extends well beyond
    the scope of this book. This chapter provides an overview of random walks, an
    introduction of how to analyze them with Markov chains, and code for implementing
    a random walk over a graph. We consider the types of questions we can investigate
    and systems we can model with random walks, such as gambling and luck-based board
    games. Finally, we consider how we can reconstruct underlying graphs from sample
    observations.
  prefs: []
  type: TYPE_NORMAL
- en: '### <samp class="SANS_Futura_Std_Bold_B_11">Introducing Random Walks</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: 'A *random walk* on a graph is a sequence of nodes where the next node in the
    sequence is chosen randomly based on some probability distribution. We denote
    the *transition probability* from node *u* to node *v* as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(*u* → *v*) where 0 ≤ *p*(*u* → *v*) ≤ 1'
  prefs: []
  type: TYPE_NORMAL
- en: This means that whenever we are at a node *u*, we select the next node from
    *u*’s neighbors using the given probability distribution.
  prefs: []
  type: TYPE_NORMAL
- en: We can visualize a random walk as a tourist who absolutely refuses to plan ahead.
    Convinced that serendipity produces the best vacations, they set out to explore
    the city with neither a map nor a clue as to where they are going. When they reach
    an intersection, they consider possible routes and choose one at random. The tourist
    makes each decision in isolation, without thought to past or future transitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the graph structure to restrict probabilities in a few ways. First,
    we limit movement to nodes that are connected to the current node by an edge.
    In the case of directed graphs, this must be an edge in the correct direction:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(*u* → *v*) = 0 if (*u*, *v*) ∉ *E*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, our tourist has no chance of traversing from point *u* to point
    *v* unless there is a road connecting them. For the sake of clarity, in this chapter
    we also require the probability to be greater than zero if the edge exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(*u* → *v*) > 0 if (*u*, *v*) ∈ *E*'
  prefs: []
  type: TYPE_NORMAL
- en: This means that our tourist can, in theory, traverse all the roads in the city.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, transition probabilities must sum to 1.0 over all outgoing adjacent
    edges:'
  prefs: []
  type: TYPE_NORMAL
- en: ∑v *p*(*u* → *v*) = 1 for every *u* ∈ *V*
  prefs: []
  type: TYPE_NORMAL
- en: This restricts the probabilities to form a valid distribution. Every node must
    include at least one outgoing edge. In directed graphs, we can use self-loops
    *p*(*u* → *u*) > 0 to model cases where the walk does not proceed to a new node.
    This constraint corresponds to the tourist always having at least one path along
    which to proceed, even if that path loops back to the current location.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Probabilities in
    Random Walks</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The simplest random walk is one where we choose among the outgoing edges with
    equal probability. In this case, our hypothetical tourist chooses from the current
    intersection’s streets completely at random. If the intersection has two outgoing
    edges, the tourist chooses either with a 50 percent probability. If the intersection
    has four outgoing edges, they each get a probability of 25 percent. [Figure 13-1](#fig13-1)
    shows an undirected and unweighted graph (a) and the corresponding transition
    probabilities out of each node (b).
  prefs: []
  type: TYPE_NORMAL
- en: '![(A) shows an undirected graph with 4 nodes and 5 edges. Node 0 is adjacent
    to two edges (0, 1) and (0, 2). (B) shows a directed graph with 4 nodes and 10
    edges. Each edge is labeled with a fraction. Node 0 has outgoing edges (0, 1)
    and (0, 2) with labels of a half.](../images/f13001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-1: An undirected
    graph (a) and its random walk probabilities (b)</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: 'While we discuss random walks on both directed and undirected graphs, we always
    model these systems as directed graphs because, in many cases, the transition
    probabilities between two nodes will not be symmetric. In formal terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(*u* → *v*) ≠ *p*(*v* → *u*)'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 13-1(b)](#fig13-1), for example, the probability of moving from node
    0 to node 1 is 1/2, while the probability of moving in the reverse direction is
    only 1/3\. For our wandering tourist, the probability of traveling between two
    intersections depends on how many roads branch out from the current intersection.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use weighted graphs to model more realistic scenarios by assigning different
    probabilities to each edge and storing them in the edge weights. We constrain
    these probabilities (the edge weights) such that the sum of probabilities over
    all outgoing edges equals 1.0\. [Figure 13-2](#fig13-2) shows an example as a
    directed, weighted graph. A random walk at node 3 has three possible next states:
    it can move to node 1 with a probability of 0.2 or to node 2 with a probability
    of 0.6, or it can stay at node 3 (via a self-loop) with a probability of 0.2.'
  prefs: []
  type: TYPE_NORMAL
- en: '![a directed graph with 4 nodes and 10 edges. Each edge is labeled with a number
    between 0 and 1.](../images/f13002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-2: A directed graph
    with transition probabilities</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: These more general graphs correspond to a tourist who is probabilistically influenced
    by factors beyond the number of roads. They tend to head toward areas with more
    interesting architecture or follow the smell of coffee. When arriving at a particular
    four-way intersection, they have a surprising 90 percent chance of taking a left
    toward a street of cafés.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Random Walks as Markov
    Chains</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Random walks over a graph’s edges are one example of a *Markov chain* or *Markov
    model*, a system for which the probability of the next state depends solely on
    the current state. Each step is taken without consideration to the previous path,
    a property known as *time invariance*. We draw the connection to Markov chains
    to allow us to tap into the vast amount of related analysis. The full breadth
    of research into analyzing different types of Markov chains far exceeds the scope
    of this book. In this chapter, we will only briefly touch upon a few concepts
    and terminology that help analyze random walks and demonstrate their modeling
    power.
  prefs: []
  type: TYPE_NORMAL
- en: The time invariance property corresponds to our wandering tourist’s habit of
    considering only the paths open in front of them. They do not consider pesky details
    such as where they have already been, how many steps they have taken, or even
    what time of day it is. While this is not optimal for conventionally regular activities
    such as eating and sleeping, the tourist resolutely adheres to their randomized
    vacationing principles.
  prefs: []
  type: TYPE_NORMAL
- en: 'In probability and statistics references, these transition probabilities are
    often written as *p*(*X*t | *X*t [– 1]) to indicate the probability of being in
    state *X*t at timestep *t* given that the system was in state *X*t [– 1] at time
    *t* – 1\. Combining this shorthand with the graph-based notation, we get the following
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(*u* → *v*) = *p*(*X*t = *v* | *X*t [– 1] = *u*)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the independence of each transition, we can compute the probability of
    an entire path [*v*[0], *v*[1], *v*[2], . . . , *v*k] from a fixed starting node
    *v*[0] by multiplying the probability of each transition:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*([*v*[0], *v*[1], *v*[2], . . . , *v*k]) = ∏i [= 1 to] k *p*(*X*t = *v*i
    | *X*t [– 1] = *v*i [– 1])'
  prefs: []
  type: TYPE_NORMAL
- en: Markov chains are useful for a wide variety of tasks for which transitions are
    independent of previous paths. Artificial intelligence uses a variety of (more
    powerful) Markov models to simulate or reason about a range of real phenomena,
    from understanding speech to decision-making with autonomous agents. For example,
    the *hidden Markov model* is a staple of machine learning that uses random transitions
    over unseen states, where each state produces noisy output. Efficient algorithms
    exist for estimating the underlying states from the output or even learning both
    the transition probabilities and output distributions from sample data.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, the random walks we consider in this chapter represent a particularly
    simple Markov model. The current state (node) is visible at each state and the
    decisions are fully random. As we will see, however, even these seemingly simple
    models can provide a wealth of simulative and analytical power.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Transition Probabilities</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When modeling a random walk on a graph using the edge weights, we require the
    weights out of each node to form a valid probability distribution. We can test
    whether the edge weights of our <samp class="SANS_TheSansMonoCd_W5Regular_11">Graph</samp>
    data structure form a valid probability distribution by iterating over each node
    and checking that the sum of outgoing edge weights is 1.0, as shown in [Listing
    13-1](#list13-1).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 13-1: Checking the
    validity of probabilities stored in the edge weights</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The code uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop
    to iterate over each node and check that the weights of its outgoing edges form
    a valid probability distribution. First, it extracts the node’s edge list and
    checks whether it is empty ❶. If so, there is nowhere to go from that node and
    the code returns <samp class="SANS_TheSansMonoCd_W5Regular_11">False</samp>. The
    constraint that the sum probabilities out of a node equal 1 requires that every
    node must have at least one outgoing edge with a nonzero weight, even if it is
    a self-loop.
  prefs: []
  type: TYPE_NORMAL
- en: The code uses a second <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>
    loop to iterate over the outgoing edges. It checks that each edge has a valid
    probability between 0.0 and 1.0, immediately returning <samp class="SANS_TheSansMonoCd_W5Regular_11">False</samp>
    if not ❷, then adds the current the edge weight to the total. After reviewing
    all edges, the code checks if the total weight is 1.0, allowing for a small accumulation
    of floating-point errors ❸. It returns <samp class="SANS_TheSansMonoCd_W5Regular_11">True</samp>
    only if all these conditions pass for all nodes and edges.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Matrix Formulation</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The matrix representation of a graph is useful when analyzing properties of
    a random walk on the graph and is commonly used in statistics and machine learning
    texts to describe random walks. In the matrix representation, transition probabilities
    are often specified using a *transition matrix* (*M*) where the value in row *i*
    and column *j* of the matrix corresponds to the probability of moving to node
    *j* given that the walk is at node *i*:'
  prefs: []
  type: TYPE_NORMAL
- en: M[*i*][*j*] = *p*(*i* → *j*)
  prefs: []
  type: TYPE_NORMAL
- en: 'We can even reuse the <samp class="SANS_TheSansMonoCd_W5Regular_11">GraphMatrix</samp>
    data structure from [Chapter 1](chapter1.xhtml) to store these values. Because
    we restrict the entries to be probabilities, we impose additional restrictions
    to the values in <samp class="SANS_TheSansMonoCd_W5Regular_11">GraphMatrix</samp>’s
    <samp class="SANS_TheSansMonoCd_W5Regular_11">connection</samp> list:'
  prefs: []
  type: TYPE_NORMAL
- en: 0 ≤ <samp class="SANS_TheSansMonoCd_W5Regular_11">connections[i][j]</samp> ≤
    1 for all <samp class="SANS_TheSansMonoCd_W5Regular_11">i</samp> and <samp class="SANS_TheSansMonoCd_W5Regular_11">j</samp>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ∑j <samp class="SANS_TheSansMonoCd_W5Regular_11">connections[i][j]</samp> =
    1 for all <samp class="SANS_TheSansMonoCd_W5Regular_11">i</samp>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These constraints mirror the restrictions placed on edge weights earlier.
  prefs: []
  type: TYPE_NORMAL
- en: We can use matrix math to model the effect of taking a random step. We let *V*t
    be a vector of probabilities such that *V*t [*u*] is the probability that our
    random walk is at node *u* (so 0 ≤ *V*t [*u*] ≤ 1 for each *u* and ∑u *V*t [*u*]
    = 1) at time step *t*. For example, we would use *V*t = [0.5, 0.4, 0.0, 0.1] to
    represent the probability that our walk is at each of the four nodes in [Figure
    13-2](#fig13-2). The vector indicates there is a 50 percent chance of being at
    node 0, a 40 percent chance of being at node 1, a 0 percent chance of being at
    node 2, and a 10 percent chance of being at node 4.
  prefs: []
  type: TYPE_NORMAL
- en: The vector *V*[0] gives the probability of starting the walk at each of the
    nodes. For example, *V*[0] = [1.0, 0.0, 0.0, 0.0] indicates a deterministic start
    at node 0, while *V*[0] = [0.5, 0.5, 0.0, 0.0] indicates an equal chance of starting
    from either node 0 or node 1\. The vector *V*[1] then gives the probability of
    being at each node after randomly starting the walk according to *V*[0] and taking
    a single additional random step. *V*[2] indicates the probability after two steps
    of the random walk and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use matrix algebra with the transition matrix *M* to compute subsequent
    probability distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*V*t [+ 1] = *V*t *M*'
  prefs: []
  type: TYPE_NORMAL
- en: Each entry *V*t [+ 1] [*u*] gives us the probability that our random walk is
    at node *u* at the following time step *t* + 1\. We can even add a method to the
    <samp class="SANS_TheSansMonoCd_W5Regular_11">GraphMatrix</samp> class that performs
    this computation, as shown in [Listing 13-2](#list13-2).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 13-2: Simulating a
    single step of a random walk on a graph</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The code starts by checking that the incoming vector <samp class="SANS_TheSansMonoCd_W5Regular_11">Vt</samp>
    has the correct length and, if not, raising an error. It then creates a result
    vector <samp class="SANS_TheSansMonoCd_W5Regular_11">Vnext</samp> and uses a pair
    of nested <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loops to perform
    the computation. It returns the new vector of probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '> <samp class="SANS_Dogma_OT_Bold_B_15">NOTE</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: '*As mentioned in [Chapter 1](chapter1.xhtml), the code in this book uses a
    list of lists to represent matrices for the purposes of illustration. For the
    sake of efficiency, production code for this computation should use a library
    that supports efficient matrix operations, such as* <samp class="SANS_TheSansMonoCd_W7Italic">numpy</samp>*.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The computation for simulating a random step also works from a deterministic
    state: *V*[*u*] = 1 for exactly one node *u*. By then multiplying *V*t [+ 1] =
    *V*t *M*, we get the probability distribution of where our random walk will be
    after exactly one step away from *u*. We can repeat this process by multiplying
    by *M* again as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*V*t [+ 2] = *V*t *M M*'
  prefs: []
  type: TYPE_NORMAL
- en: This gives us the probability distribution of nodes that are reached in exactly
    two steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, we can extend our matrix notation such that *M*t is the transition
    matrix for a random walk of exactly *t* steps, so *M*t [*u*][*v*] is the probability
    of transitioning from node *u* to node *v* in exactly *t* steps. We can compute
    this matrix directly using matrix multiplication:'
  prefs: []
  type: TYPE_NORMAL
- en: '*M*t = ∏I [= 1 to] t *M*'
  prefs: []
  type: TYPE_NORMAL
- en: While the matrix formulation is useful for describing and analyzing the properties
    of a random walk, the code in the remainder of the chapter uses the adjacency
    list representation of our <samp class="SANS_TheSansMonoCd_W5Regular_11">Graph</samp>
    class for consistency with the other chapters. All the functions can be adapted
    to work with the <samp class="SANS_TheSansMonoCd_W5Regular_11">GraphMatrix</samp>
    class.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Use Cases</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Random walks are used to model and analyze problems that involve non-deterministic
    behavior. Random behavior shows up in a wide range of real-world systems, from
    human interaction to the explicit randomness in some computer algorithms. In this
    section, we look at three example use cases: social networks, randomized explorations,
    and games of chance.'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Information Chains
    in Social Networks</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We can use random walks to model how a rumor spreads through a social network
    where the interactions have a random component. Determined not to gossip excessively,
    each person in the network resolves to pass information to only a single other
    person when they hear a rumor. However, they are bursting to share the latest
    gossip as soon as they hear it, so they share the news with the first person they
    come across. This is inherently a probabilistic selection, as they don’t know
    which friend they’ll run into first. After sharing their news, they are temporarily
    satisfied and hold off on discussing the rumor until it is shared with them again.
  prefs: []
  type: TYPE_NORMAL
- en: We could model the social network as a graph where the edges represent the probability
    that each neighbor is the person with whom the rumor is shared. The rumor itself
    randomly walks the graph, getting passed from person to person.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Exploration</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Previous chapters discussed numerous algorithms for deterministically exploring
    graphs, such as depth-first search or A* search. However, many real-world explorations
    involve a randomized element, such as weather-based path closures. Random walks
    allow us to model systems with such constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the explorer from [Chapter 8](chapter8.xhtml) searching for a best
    path to an archeological site. The current conditions might add a random element
    to their exploration. When faced with a fork in the path, the northern route might
    have a 50 percent chance of being flooded out, while the southern route has a
    10 percent chance of being blocked by an angry swarm of hornets. Taking these
    probabilities into account, we could model their unpleasant journey through the
    jungle as a random walk.
  prefs: []
  type: TYPE_NORMAL
- en: We can use a similar approach to analyze robot path planning in dynamic environments.
    A search-and-rescue robot exploring a damaged building may run into different
    obstacles at different times, such as fires or flooded passages, and need to reroute.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Games of Chance</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We can also use a random walk to simulate the outcomes of games of chance. Graph
    nodes represent different game states, and the edges indicate the possible (probabilistic)
    changes in those states. For example, we can use the Markov chain shown in [Figure
    13-3](#fig13-3) to represent a gambler playing a one-dollar slot machine.
  prefs: []
  type: TYPE_NORMAL
- en: '![A linear chain of nodes. Each node has a directed edge to the left with probability
    0.99 and an edge 9 nodes to the right with a probability of 0.01.](../images/f13003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-3: A subset of nodes
    for a gambler’s graph</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: Each state represents the number of dollars in the gambler’s possession. Each
    pull of the slot machine decides the next state without regard to previous pulls
    or the gambler’s current financial situation. Maybe the machine has a 1 in 100
    chance of paying out 10 dollars, moving the gambler from state *k* to state *k*
    + 9, and a 99 in 100 of chance of paying out nothing, moving the gambler from
    state *k* to *k* – 1.
  prefs: []
  type: TYPE_NORMAL
- en: As we model more complex games of chance, we need correspondingly more complex
    graphs. Later in this chapter we show how to use graphs to model luck-based board
    games. We discuss nodes that simultaneously represent multiple players’ states
    and the transitions among them.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Simulating Random Walks</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One powerful approach to understanding random walks and their underlying graph
    is to *repeatedly simulate* a random walk over the graph and analyze the paths
    taken. We simulate a random walk on a graph by repeatedly selecting the next state
    based on the probability distribution over the neighbors of the current state.
    As a prerequisite, we need a function to sample from a finite set of options with
    pre-specified probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: We provide a simple algorithm for illustration purposes that draws a random
    number uniformly within [0, 1) and checks to which neighbor it corresponds by
    iterating over each outgoing edge and accumulating the cumulative probability
    of the previous nodes. We are effectively breaking the range [0, 1) into regions
    for each option where the size of the region corresponds to the probability of
    that option. [Figure 13-4](#fig13-4) shows an example where 50 percent of the
    range leads to node 0, 20 percent leads to node 1, and 30 percent leads to node
    3.
  prefs: []
  type: TYPE_NORMAL
- en: By tracking the cumulative probability seen so far while iterating over the
    options, we are tracking the start and end of each region and comparing it to
    the selected value. We want to find the bin whose region brackets our randomly
    selected value. As soon as we cross the bin edge where the cumulative value exceeds
    the randomly selected value, we know we have gone too far.
  prefs: []
  type: TYPE_NORMAL
- en: '![A bar from 0.0 to 1.0 divided into three sections. The first section spans
    0.0 to 0.5 and is labeled node 0.](../images/f13004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-4: The transition
    probability to three nodes and the corresponding cumulative probability</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The code for a random walk on a graph consists of a random number generation
    followed by a single <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>
    loop that iterates over the outgoing edges, as shown in [Listing 13-3](#list13-3).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 13-3: Choosing the
    next node in a random walk</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The code starts by drawing a random number from [0, 1) using Python’s <samp
    class="SANS_TheSansMonoCd_W5Regular_11">random</samp> library ❶. It then uses
    a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop over each outgoing
    edge to compute the total (cumulative) probability seen so far. The selected edge
    is the first one whose weight causes this cumulative probability to exceed the
    selected random number ❷. If the code makes it to the end of the list (due to
    imprecisions in how floating-point numbers are stored), the code simply returns
    the last edge ❸.
  prefs: []
  type: TYPE_NORMAL
- en: The <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_next_node()</samp>
    function in [Listing 13-3](#list13-3) does not perform any validity checks on
    the probability distribution leaving each node. This is intentional so as not
    to pay the cost of performing the check each time the function is called. Instead,
    I recommend checking the distributions for all nodes once using the <samp class="SANS_TheSansMonoCd_W5Regular_11">is_valid_probability_graph()</samp>
    function from [Listing 13-1](#list13-1).
  prefs: []
  type: TYPE_NORMAL
- en: 'Given this helper function, the code to perform the random walk from a given
    starting node (<samp class="SANS_TheSansMonoCd_W5Regular_11">start</samp>) is
    relatively short:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The function starts by confirming that the graph’s weights represent a valid
    probability distribution and raising an error if not ❶. It then allocates a list
    <samp class="SANS_TheSansMonoCd_W5Regular_11">walk</samp> to store the results,
    sets the current node to the start node, and sets the first step in the walk to
    the start node. The code uses a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>
    loop to iterate through each step, using the <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_next_node()</samp>
    function from [Listing 13-3](#list13-3) to continually select the next node from
    the current one ❷. The code adds the new node to the <samp class="SANS_TheSansMonoCd_W5Regular_11">walk</samp>
    list, which it returns after taking all the steps.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Statistical Measures</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Random walks are a powerful tool for understanding randomized systems and computing
    a variety of practical statistics measures. For example, we might want to find
    the probability of reaching a particular node or determine how many steps it will
    take to get there. These measures are useful in answering questions such as “What
    is the probability a gambler will lose all their money?” or “How long (on average)
    will it take a rumor to reach me?” or “If a tourist randomly wanders the city
    for years, how long will they spend at each location?”
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we briefly consider how such questions apply to the case of
    our wandering tourist and outline how to compute the answers. After considering
    the probability of reaching specific nodes and the average number of steps to
    do so, we analyze the long-term behavior of random walks.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Hitting and Absorption
    Time</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *hitting time* of a set of nodes *A* ⊂ *V* is the average number of steps
    a random walk must take before it first hits a node in *A* from a given starting
    node. For example, if *A* is the set of all intersections with cafés in the town
    our tourist is exploring, they might want to calculate the hitting time of that
    set to find out when they are likely to get their next cup of coffee.
  prefs: []
  type: TYPE_NORMAL
- en: If a random walk cannot leave the nodes in *A*, we refer to these hitting times
    as *absorption times* because the walk is absorbed into *A*. For example, in [Figure
    13-5](#fig13-5), node *k* forms an absorbing set. Once a walk arrives at node
    *k*, it stays there forever.
  prefs: []
  type: TYPE_NORMAL
- en: '![A node with multiple incoming edges and a single outgoing edge labeled 1.0
    that forms a self-loop.](../images/f13005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-5: An absorbing set
    consisting of a single node in a graph</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: Absorbing nodes can also be used to represent the termination of a random walk.
    As a concrete example, the tourist could decide to stop their random walk when
    they hit their hotel.
  prefs: []
  type: TYPE_NORMAL
- en: 'When analyzing random walks on graphs, we often consider two statistical quantities
    related to hitting times: the probability the walk will reach the subset and the
    expected time to do so.'
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_B_11">Hitting Probability and Absorption
    Probability</samp>
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The *hitting probability* for a subset of nodes *A* ⊆ *V* is the probability
    that a random walk from node *u* will hit a node *v* ∈ *A* in that subset. We
    can use this measure to answer questions like “What is the probability that our
    tourist will encounter a coffee shop?” Similarly, the *absorption probability*
    for a subset of nodes *A* is the probability that a random walk from node *u*
    will be absorbed by that subset. This allows us to ask questions like “What is
    the probability the tourist will return to the hotel and stop their random walk?”
  prefs: []
  type: TYPE_NORMAL
- en: Absorbing subsets of nodes can impact the hitting probability of non-absorbing
    nodes. For example, consider the weighted graph in [Figure 13-6](#fig13-6), which
    shows a graph with three nodes and an absorbing subset of {0, 1}.
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph with three nodes. Node 0 has a self-loop with weight 0.25 and an
    edge to node 1 with weight 0.75\. Node 1 has a single edge to node 0 with a weight
    of 1.0\. Node 2 has a self-loop with weight 0.5 and an edge to node 1 with weight
    0.5.](../images/f13006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-6: A graph with three
    nodes and transition probabilities</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The probability that a walk starting from node 2 will hit node 0 is 1.0 given
    a potentially infinite number of steps. In contrast, once the walk hits the nodes
    *A* = {0, 1}, it can never travel to node 2, as it will be stuck in an endless
    set of steps connected to nodes 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_B_11">Expected Hitting Time</samp>
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The *expected hitting time* is the expected number of steps a random walk takes
    (on average) before it first hits a node in *A*. This allows us to determine how
    long on average it will take our tourist to get their next coffee. The *absorption
    time* is similar, quantifying the expected time until the random walk reaches
    the absorbing set. For our tourist, this would be how long their walk will be
    on average (before they reach their hotel and stop for the day).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the expected hitting time of node 1 from node 0 (denoted *h*[01])
    in [Figure 13-6](#fig13-6) is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*h*[01] = 1 × *p*(first hit node 1 after 1 step)'
  prefs: []
  type: TYPE_NORMAL
- en: + 2 × *p*(first hit node 1 after 2 steps)
  prefs: []
  type: TYPE_NORMAL
- en: + 3 × *p*(first hit node 1 after 3 steps) + . . .
  prefs: []
  type: TYPE_NORMAL
- en: '*h*[01] = 1 × ¾ + 2 × ¼ × ¾ + 3 × (¼)² × ¾ + 4 × (¼)³ × ¾ + . . .'
  prefs: []
  type: TYPE_NORMAL
- en: '*h*[01] = 4/3'
  prefs: []
  type: TYPE_NORMAL
- en: This is because the possible walks from node 0 include walks that start [0,
    1], [0, 0, 1], [0, 0, 0, 1], and so forth. If we have the full transition matrix,
    we can use a set of equations to solve for the expected hitting times.
  prefs: []
  type: TYPE_NORMAL
- en: The expected hitting time may be infinite, like that from node 0 to node 2 (*h*[02])
    in [Figure 13-6](#fig13-6). No matter how long of a walk we consider, we can never
    hit node 2 from node 0.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Stationary Distribution</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Stationary distribution* represents the distribution of visits to each state
    if we keep wandering a strongly connected graph forever. This distribution provides
    insight into how likely we are to spend time at each node. For example, we could
    ask, “After our tourist has been wandering for days, what is the probability that
    they are currently at the café on Fifth Street?” We can also use stationary distribution
    to predict the probable locations of millions of wandering tourists all following
    the same randomized rules as they traverse a city.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Returning to the matrix notation introduced earlier in the chapter (where *M*
    is the transition matrix and *V*t is a vector of probabilities such that *V*t
    [*u*] is the probability that our random walk is at node *u* at time step *t*),
    the stationary distribution is a vector *V*^* where:'
  prefs: []
  type: TYPE_NORMAL
- en: '*V*^* = *V* ^**M*'
  prefs: []
  type: TYPE_NORMAL
- en: In other words, adding one more step to the random walk will not change the
    distribution of the possible locations.
  prefs: []
  type: TYPE_NORMAL
- en: We can derive stationary distributions from the structure of the graph. Consider
    the two-node graph in [Figure 13-7](#fig13-7), where *M* = [[0.25, 0.75], [0.5,
    0.5]].
  prefs: []
  type: TYPE_NORMAL
- en: '![The graph has two nodes. Node 0 has a self-loop with weight 0.25 and an edge
    to node 1 with weight 0.75\. Node 1 has a self-loop with weight 0.5 and an edge
    to node 0 with a weight of 0.5.](../images/f13007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-7: A graph with two
    nodes and four transition probabilities</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The structure of the graph in [Figure 13-7](#fig13-7) indicates that over the
    long term, random walks will tend to spend more time at node 1 than at node 0\.
    The probability of staying at node 0, due to a self-loop, is only 0.25, while
    the probability of staying at node 1 is 0.5\. We can quantify that difference
    in time spent at each node by using the stationary distribution, which for this
    graph is *V*^* = [0.4, 0.6].
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Luck-Based Board Games</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can bring together the topics in this section to consider one of the most
    entertaining applications of random walks: analyzing luck-based board games for
    children. These games involve no actual choices, but instead rely on random numbers
    generated by spinners or dice to decide the moves. After hours spent spinning
    dials that determine whether a plastic piece moves ahead one, two, or three spaces,
    even non-statistically minded people might inquire about the expected absorption
    time of the goal state by asking, “How much longer do I have to play this game?”
    We can answer such questions by modeling the game as a random walk on a graph.'
  prefs: []
  type: TYPE_NORMAL
- en: Consider the simple example of a game where the goal is to be the first player
    to complete a circuit of the board. During their turn, each player uses a small
    spinner labeled with 1, 2, and 3 that indicates how many steps to take. [Figure
    13-8](#fig13-8) shows a graphical representation of several states in this game.
    The nodes’ numbers correspond to the squares on the board, where the player is
    currently at square *k*. Based on the random spinner, they could move to squares
    *k* + 1, *k* + 2, or *k* + 3, each with a 1/3 probability.
  prefs: []
  type: TYPE_NORMAL
- en: '![A line of graph nodes. Each node k has three outgoing edges, to node k +
    1, k + 2, and k + 3.](../images/f13008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-8: A graph representing
    sample states of a spinner-based game</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: In an attempt to make the game more exciting (or possibly to cause more children
    to cry in frustration), the creators label some of the squares “Go back X spaces.”
    These represent traps that should be avoided at all costs. We can incorporate
    this behavior directly into our graph.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 13-9](#fig13-9) shows the state graph where square *k* + 2 contains
    the instructions “Move back one space.” This effectively removes node *k* + 2
    from the graph (represented in the figure by graying out the node). It is not
    possible to finish a turn in that state. The transition probabilities of the neighboring
    nodes change correspondingly. The probability of going from node *k* to *k* +
    1 increases from 1/3 to 2/3, because now spins of both 1 and 2 will end on square
    *k* + 1\. Similarly, a spin of 1 from node *k* + 1 will land the player back on
    node *k* + 1\. We model this as a self-loop with probability 1/3.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A line of graph nodes. Nodes have edges to themselves and to nodes further
    right.](../images/f13009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-9: A graph representing
    the movements from state</samp> <samp class="SANS_Futura_Std_Book_11">k</samp>
    <samp class="SANS_Futura_Std_Book_Oblique_I_11">in a spinner-based game</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: While we can add more edges to capture square-based and spinner-based transitions,
    significantly more complexity is required to capture aspects such as player-player
    interactions. The graph model presented so far in this section captures only the
    dynamics of a single random walk through the board game. This works fine if all
    players are independent. However, if the game provides the ability to knock a
    player back two squares when someone lands on their square, we need a model that
    incorporates both players’ positions.
  prefs: []
  type: TYPE_NORMAL
- en: We can create such models by increasing the number of nodes to match the available
    states of the board game. Instead of *N* nodes for *N* squares, we could use 2*N*²
    nodes by modeling the game state as a tuple of Alice’s location (player 1’s state),
    Bob’s location (player 2’s state), and a Boolean indicating whether it is Alice’s
    turn. For example, the tuple <samp class="SANS_TheSansMonoCd_W5Regular_11">(5,
    4, False)</samp> indicates that Alice is on square 5, Bob is on square 4, and
    it is Bob’s turn. If we combine the three-option spinner with the new “knock-back”
    rule, there is a 1/3 probability that Bob will spin a 1, move forward a square,
    and knock Alice back two squares. More formally, *p*(<samp class="SANS_TheSansMonoCd_W5Regular_11">(5,
    4, False)</samp> → <samp class="SANS_TheSansMonoCd_W5Regular_11">(3, 5, True)</samp>)
    = 1/3.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Transition Probabilities</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Beyond analyzing given graphs, we can extend the concepts in this chapter to
    *estimating* the graphs themselves from observed data. Imagine that we’ve found
    the logbook of a tourist who spent the last year randomly wandering the streets
    of an unknown city. Each entry lists at least a location and a time. Eager to
    understand their journey, we consider their long sequence of visited locations.
  prefs: []
  type: TYPE_NORMAL
- en: We can easily reconstruct individual nodes from the location names, such as
    Integer Square and Floating Point Harbor. With a little reasoning, we can also
    identify the existence of edges; for example, the transition from Integer Square
    to If-Then Intersection implies an edge connects them. After hours of studying
    the tourist’s agonizingly looping path, we step back and try to reconstruct their
    transition matrix.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Maximum Likelihood
    Estimations</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We can estimate a transition matrix using a sequence of observations that result
    from one or more walks to statistically estimate transition probabilities. A *maximum
    likelihood estimation* allows us to find the model parameters (transition probabilities)
    that maximize the chance that we will see the sampled data given those parameters.
    We won’t discuss the mathematical details of this approach here, but in short,
    a maximum likelihood estimation uses the independence of each step to compute
    the transition probability from node *u* to node *v* by counting the following
    two quantities:'
  prefs: []
  type: TYPE_NORMAL
- en: '***N***uThe number of times node *u* appears in the data at the start of a
    move (not the last node in the path)'
  prefs: []
  type: TYPE_NORMAL
- en: '***N***u [→] vThe number of times node *v* appears immediately after node *u*
    in the data'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given this information, we compute the probability of a transition as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(*u* → *v*) ≈ *N*u [→] v / *N*u'
  prefs: []
  type: TYPE_NORMAL
- en: If we have departed 100 times from node 1, and 30 of those times we moved directly
    to node 3, we estimate *p*(1 → 3) = 30 / 100 = 0.3.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">A Transition Matrix
    Estimation Algorithm</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The algorithm to estimate an underlying graph from observational data consists
    of three phrases. In the first phase, we use the nodes visited along the walks
    to compute the number of nodes for the graph. This corresponds to scanning through
    the tourist’s logbook and determining how many intersections we will need to track.
    Second, we construct the count array for the number of times the tourist visited
    each node (*N*u) and the count matrix for the node-to-node transitions (*N*u [→]
    v). We compute the counts by iterating over the steps in the walk, effectively
    retracing the tourist’s journey. Finally, we build the graph by inserting edges
    for all nonzero node-to-node transitions.
  prefs: []
  type: TYPE_NORMAL
- en: Because we are constructing the graph from nodes in the walk, we include only
    those nodes that the algorithm visits at least once. This means that, given a
    disconnected graph, we would capture only the graph that is reachable from the
    initial starting node(s). If the tourist is frightened of water and refuses to
    cross bridges, we might miss all of the locations on the other side of the river.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 13-4](#list13-4) reflects these three phases.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Listing 13-4: Estimating a
    transition matrix from observed data</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: The function takes in a list of lists (<samp class="SANS_TheSansMonoCd_W5Regular_11">walks</samp>)
    that contain the nodes visited on multiple random walks. The code starts by using
    a pair of nested <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loops
    to iterate over each walk and each node in that walk and records the highest index
    seen ❶. It then allocates data structures for the two sets of counts (<samp class="SANS_TheSansMonoCd_W5Regular_11">counts</samp>
    and <samp class="SANS_TheSansMonoCd_W5Regular_11">move_counts</samp>) and fills
    these using a <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp> loop to
    iterate over each step in the path ❷. Once it has completed the counts, the code
    creates a graph (<samp class="SANS_TheSansMonoCd_W5Regular_11">g</samp>) and iterates
    over each pair of nodes with two nested <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>
    loops ❸. If the transition count between the two nodes is nonzero ❹, it computes
    the probability and inserts the corresponding edge into the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that using the highest index seen has the downside that if the
    underlying graph consists of multiple disconnected components, the re-created
    graph will include indices that we will never visit. Since these indices have
    a count of zero, they will not be given any outgoing edges, and the resulting
    graph will fail the <samp class="SANS_TheSansMonoCd_W5Regular_11">is_valid_probability_graph()</samp>
    check. We use the maximum index approach in [Listing 13-4](#list13-4) for simplicity
    and consistency with previous chapters, but a more robust approach is to use a
    *node name* to index mapping, as described in [Appendix A](appendix_A.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example of estimating the graph, consider a travel journal that consists
    of two paths and contains visits to numbered buildings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We can feed these paths into our estimation function to learn about our tourist’s
    vacation behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: A few points immediately jump out when looking at the paths. First, the tourist
    always started from node 0\. Second, they visited only two buildings, 0 and 1\.
    In this case, building 0 is the hotel with a café in the lobby, while building
    1 is the coffee shop across the street.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we compute the maximum likelihood estimate, we accumulate the following
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '*N*[0] = 8, *N*[1] = 4'
  prefs: []
  type: TYPE_NORMAL
- en: '*N*[0 → 0] = 4, *N*[0 → 1] = 4, *N*[1 → 0] = 4, *N*[1 → 1] = 0'
  prefs: []
  type: TYPE_NORMAL
- en: The tourist started a move from node 0 eight times (*N*[0] = 8). Four of those
    times they stayed at node 0 (*N*[0 → 0] = 4), and four times they went to node
    1 (*N*[0 → 1] = 4). They started moves from node 1 four times, always going to
    node 0 (*N*[1 → 0] = 4) and never to node 1 (*N*[1 → 1] = 0).
  prefs: []
  type: TYPE_NORMAL
- en: 'We use these statistics to estimate the pairwise transition probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(0 → 0) = 4 / 8 = 0.5'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(0 → 1) = 4 / 8 = 0.5'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(1 → 0) = 4 / 4 = 1.0'
  prefs: []
  type: TYPE_NORMAL
- en: '*p*(1 → 1) = 0 / 4 = 0.0'
  prefs: []
  type: TYPE_NORMAL
- en: These probabilities provide the edge weights for the estimated graph, as shown
    in [Figure 13-10](#fig13-10). Note that we do not include the edge (1, 1) because
    it has a weight of 0.
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph with two nodes and three edges. Node 0 has a self-loop with a weight
    0.5 and an edge to node 1 with a weight 0.5\. Node 1 has a single edge back to
    node 0 with a weight 1.0.](../images/f13010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '<samp class="SANS_Futura_Std_Book_Oblique_I_11">Figure 13-10: A graph with
    edge transition probabilities estimated from data</samp>'
  prefs: []
  type: TYPE_NORMAL
- en: When at the hotel, the tourist has a 50 percent chance of staying at the hotel
    and a 50 percent chance of going across the street to the coffee shop. However,
    when at the coffee shop, they always return directly to the hotel.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Limitations of Working
    with Finite Data</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Of course, our estimates of transition probability are likely to be very noisy
    until we accumulate significant observations. If we have a big enough graph, we
    might never have a chance to observe certain nodes or low-probability edges. This
    is a fundamental problem of working with random data. If our tourist has a 5 percent
    chance of turning down a narrow alley, they might reasonably skip it each of the
    10 times we see them at its entrance.
  prefs: []
  type: TYPE_NORMAL
- en: Using statistics, we can analyze not only the maximum likelihood values but
    also their error bars and our confidence levels. These analyses are outside the
    scope of this book. For now, we just give a word of caution against trying to
    draw rigorous conclusions from a small amount of random data.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Random Starting Nodes</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can extend both our model and its estimation to account for cases where the
    random walk starts at different nodes. The idea of a *random starting node* may
    not seem intuitive since physical walks start at a single location such as the
    tourist’s hotel. However, randomized starts can represent a variety of real-world
    phenomena, such as the tourist randomly leaving one of many hotels or a rumor
    starting at a random point in a social network.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s label the vector of starting probabilities *S* where *S*[*u*] indicates
    the probability that we start our random walk at node *u*. Since *S* contains
    probabilities, we restrict 0 ≤ *S*[*u*] ≤ 1 and ∑u *S*[*u*] = 1.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Choosing a Random
    Starting Node</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We can directly sample the starting node with the same approach we used for
    <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_next_node()</samp> in [Listing
    13-3](#list13-3):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_start()</samp> function
    draws a random number from [0, 1) using Python’s <samp class="SANS_TheSansMonoCd_W5Regular_11">random</samp>
    library ❶. Instead of iterating over a node’s edges as in <samp class="SANS_TheSansMonoCd_W5Regular_11">choose_next_node()</samp>,
    the function iterates over the values in *S* until it finds the correct one ❷.
  prefs: []
  type: TYPE_NORMAL
- en: As a more detailed example, imagine an evil wizard who creates dungeons that
    use randomized entryways to prevent former adventurers from writing strategy guides
    (thereby messing with the adventurers’ retirement plans). The wizard teleports
    each new arrival to a random location using a carefully chosen distribution *S*.
    They restrict adventurers from ever starting their quest in the treasure room
    by setting that room’s starting probability to zero, *S*[*treasure*] = 0\. To
    reduce the ability for adventurers to share information, the wizard also enforces
    *S*[*room*] < 0.1 for all rooms, meaning that there is less than a 10 percent
    chance the adventurers will start in any particular room.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_Condensed_Oblique_BI_11">Estimating the Probability
    Distribution for Starting Nodes</samp>
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If we run many random walks, we might be interested in estimating the distribution
    over starting states. We can use a similar approach to that of the transition
    probabilities to estimate the starting probabilities. If *N*[0][*u*] is the number
    of walks that start at node *u*, then we define the probability of starting at
    node *u* as the fraction of times a walk started from that node:'
  prefs: []
  type: TYPE_NORMAL
- en: S[*u*] = *N*[0][*u*] / ∑v *N*[0][*v*]
  prefs: []
  type: TYPE_NORMAL
- en: 'We can implement this estimation in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Like the code for estimating the transition probabilities, the code to estimate
    the starting probabilities starts by computing the maximum node index and creating
    a data structure to track occurrences ❶. In this case, however, the code looks
    only at the first node in the walk. It uses a single <samp class="SANS_TheSansMonoCd_W5Regular_11">for</samp>
    loop over the different walks to count how many of the walks start at each node
    ❷. It then computes the empirical probability of starting at each node.
  prefs: []
  type: TYPE_NORMAL
- en: Our adventurer could theoretically use this approach to gather information for
    their upcoming strategy guide. They enter the dungeon a few hundred times, carefully
    tracking where they land each time. It is up to them to decide whether the payoff
    of writing a comprehensive guide to this dungeon is worth the hassle of navigating
    through the same dungeon over and over again.
  prefs: []
  type: TYPE_NORMAL
- en: <samp class="SANS_Futura_Std_Bold_B_11">Why This Matters</samp>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Analyzing random walks on graphs is useful for both understanding the structure
    of a graph and analyzing its underlying system. More importantly, however, the
    concept of random walks extends the range of real-world problems we can model
    with graph algorithms. We can move beyond deterministic questions, such as how
    to find the shortest path between two nodes, to account for more realistic behaviors.
    For example, to model path planning with occasional wrong turns, we could use
    a random walk that takes the optimal path most of the time but makes a random
    error at some intersections.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we switch topics and consider the graphs from a perspective
    of overall capacity, finding the maximum flow through a network to model systems
    from plumbing to transportation.
  prefs: []
  type: TYPE_NORMAL
