- en: '**1'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: REGRESSION MODELS**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In this chapter, we’ll introduce *regression functions*. Such functions give
    the mean of one variable in terms of one or more others—for instance, the mean
    weight of children in terms of their age. All ML methods are *regression methods*
    in some form, meaning that they use the data we provide to estimate regression
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll present our first ML method, k-nearest neighbors (k-NN), and apply it
    to real data. We’ll also weave in concepts that will recur throughout the book,
    such as dummy variables, overfitting, p-hacking, “dirty” data, and so on. We’ll
    introduce many of these concepts only briefly for the time being in order to give
    you a bird’s-eye view of what we’ll return to in detail later: ML is intuitive
    and coherent but easier to master if taken in stages. Reader, please be prepared
    for frequent statements like “We’ll cover one aspect for now, with further details
    later.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you begin, make sure you have R and the `qeML` and `regtools` packages,
    version 1.7 or newer for the latter, installed on your computer. (Run packageVersion(''regtools'')
    to check.) All code displays in this book assume that the user has already made
    the calls to load the packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: So, let’s look at our first example dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '1.1 Example: The Bike Sharing Dataset'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we introduce k-NN, we’ll need to have some data to work with. Let’s start
    with this dataset from the UC Irvine Machine Learning Repository, which contains
    the Capital Bikeshare system’s hourly and daily count of bike rentals between
    2011 and 2012, with corresponding information on weather and other quantities.
    A more detailed description of the data is available at the UC Irvine Machine
    Learning Repository.[¹](footnote.xhtml#ch1fn1)
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is included as the `day` dataset in `regtools` by permission of
    the data curator. Note, though, that we will use a slightly modified version,
    `day1` (also included in `regtools`), in which the numeric weather variables are
    given in their original scale rather than transformed to the interval [0,1].
  prefs: []
  type: TYPE_NORMAL
- en: Our main interest will be in predicting total ridership for a day.
  prefs: []
  type: TYPE_NORMAL
- en: SOME TERMINOLOGY
  prefs: []
  type: TYPE_NORMAL
- en: Say we wish to predict ridership from temperature and humidity. Standard ML
    parlance refers to the variables used for prediction—in this case, temperature
    and humidity—as *features.*
  prefs: []
  type: TYPE_NORMAL
- en: If the variable to be predicted is numeric, say, ridership, there is no standard
    ML term for it. We’ll just refer to it as the *outcome* variable. But if the variable
    to be predicted is an R factor—that is, a categorical variable—it is called a
    *label*.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, later in this book we will analyze a dataset on diseases of human
    vertebrae. There are three possible outcomes or categories: normal (NO), disk
    hernia (DH), or spondylolisthesis (SL). The column in our dataset showing the
    class of each patient, NO, DH, or SL, would be the labels column.'
  prefs: []
  type: TYPE_NORMAL
- en: Our dataset, say, `day1` here, is called the *training set*. We use it to make
    predictions in future cases, in which the features are known but the outcome variable
    is unknown. We are predicting the latter.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.1 Loading the Data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The data comes in hourly and daily forms, with the latter being the one in
    the `regtools` package. Load the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'With any dataset, it’s always a good idea to first take a look around. What
    variables are included in this data? What types are they, say, numeric or R factor?
    What are their typical values? One way to do this is to use R’s `head()` function
    to view the top of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We see there are 731 rows (that is, 731 different days), with data on the date,
    nature of the date (such as `weekday`), and weather conditions (such as the temperature,
    `temp`, and humidity, `hum`). The last three columns measure ridership from casual
    users, registered users, and the total.
  prefs: []
  type: TYPE_NORMAL
- en: You can find more information on the dataset with the `?day1` command.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.2 A Look Ahead
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We will get to actual analysis of this data shortly. For now, here is a preview.
    Say we wish to predict total ridership for tomorrow, based on specific weather
    conditions and so on. How will we do that with k-NN?
  prefs: []
  type: TYPE_NORMAL
- en: We will search through our data, looking for data points that match or nearly
    match those same weather conditions and other variables. We will then average
    the ridership values among those data points, and that will be our predicted ridership
    for this new day.
  prefs: []
  type: TYPE_NORMAL
- en: Too simple to be true? No, not really; the above description is accurate. Of
    course, the old saying “The devil is in the details” applies, but the process
    is indeed simple. But first, let’s address some general issues.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 Machine Learning and Prediction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ML is fundamentally about prediction. Before we get into the details of our
    first ML method, we should be sure we know what “prediction” means.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the bike sharing dataset. Early in the morning, the manager of the
    bike sharing service might want to predict the total number of riders for the
    day. The manager can do so by analyzing the relations between the features—the
    various weather conditions, the work status of the day (weekday, holiday), and
    so on. Of course, predictions are not perfect, but if they are in the ballpark
    of what turns out to be the actual number, they can be quite helpful. For instance,
    they can help the manager decide how many bikes to make available, with pumped-up
    tires and so on. (An advanced version would be to predict the demand for bikes
    at each station so that bikes could be reallocated accordingly.)
  prefs: []
  type: TYPE_NORMAL
- en: 1.2.1 Predicting Past, Present, and Future
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The famous baseball player and malapropist Yogi Berra once said, “Prediction
    is hard, especially about the future.” Amusing as this is, he had a point; in
    ML, prediction can refer not only to the future but also to the present or even
    the past. For example, a researcher may wish to estimate the mean wages workers
    made back in the 1700s. Or a physician may wish to make a diagnosis as to whether
    a patient has a particular disease, based on blood tests, symptoms, and so on,
    guessing their condition in the present, not the future. So when we in the ML
    field talk of “prediction,” don’t take the “pre-” too literally.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2.2 Statistics vs. Machine Learning in Prediction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A common misconception is that ML is concerned with prediction, while statisticians
    do *inference*—that is, confidence intervals and testing for quantities of interest—but
    prediction is definitely an integral part of the field of statistics.
  prefs: []
  type: TYPE_NORMAL
- en: There is sometimes a friendly rivalry between the statistics and ML communities,
    even down to a separate terminology for each (see [Appendix B](app02.xhtml)).
    Indeed, statisticians sometimes use the term *statistical learning* to refer to
    the same methods known in the ML world as machine learning!
  prefs: []
  type: TYPE_NORMAL
- en: As a former statistics professor who has spent most of his career in a computer
    science department, I have a foot in both camps. I will present ML methods in
    computational terms, but with some insights informed by statistical principles.
  prefs: []
  type: TYPE_NORMAL
- en: HISTORICAL NOTE
  prefs: []
  type: TYPE_NORMAL
- en: Many of the methods treated in this book, which compose part of the backbone
    of ML, were originally developed in the statistics community. These include k-NN,
    decision trees or random forests, logistic regression, and L1/L2 shrinkage. These
    evolved from the linear models formulated way back in the 19th century, but which
    later statisticians felt were inadequate for some applications. The latter consideration
    sparked interest in methods that had less restrictive assumptions, leading to
    the invention first of k-NN and later of other techniques.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, two other prominent ML methods, support vector machines (SVMs)
    and neural networks, have been developed almost entirely outside of statistics,
    notably in university computer science departments. (Another method, *boosting*,
    began in computer science but has had major contributions from both factions.)
    Their impetus was not statistical at all. Neural networks, as we often hear in
    the media, were studied originally as a means to understand the workings of the
    human brain. SVMs were viewed simply in computer science algorithmic terms—given
    a set of data points of two classes, how can we compute the best line or plane
    separating them?
  prefs: []
  type: TYPE_NORMAL
- en: 1.3 Introducing the k-Nearest Neighbors Method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our featured method in this chapter will be *k-nearest neighbors*, or *k-NN*.
    It’s arguably the oldest ML method, going back to the early 1950s, but it is still
    widely used today, especially in applications in which the number of features
    is small (for reasons that will become clear later). It’s also simple to explain
    and easy to implement—the perfect choice for this introductory chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.1 Predicting Bike Ridership with k-NN
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s first look at using k-NN to predict bike ridership from a single feature:
    temperature. Say the day’s temperature is forecast to be 28 degrees centigrade.
    How should we predict ridership for the day, using the 28 figure and our historical
    ridership dataset (our training set)? A person without a background in ML might
    suggest looking at all the days in our data, culling out those of temperature
    closest to 28 (there may be few or none with a temperature of exactly 28), and
    then finding the average ridership on those days. We would use that number as
    our predicted ridership for this day.'
  prefs: []
  type: TYPE_NORMAL
- en: Actually, this intuition is correct! This, in fact, is the basis for many common
    ML methods, as we’ll discuss further in [Section 1.6](ch01.xhtml#ch01lev6) on
    the regression function. For now, just know that k-NN takes the form of simply
    averaging over the similar cases—that is, over the neighboring data points. The
    quantity *k* is the number of neighbors we use. We could, say, take the 5 historical
    days with temperatures closest to 28, average the numbers for those days, and
    use the result to predict ridership on a new 28-degree day.
  prefs: []
  type: TYPE_NORMAL
- en: Later in this chapter, we will learn to use the `qe*`-series implementation
    of k-NN, `qeKNN()`. For now, though, let’s perform k-NN “manually,” so as to get
    a better understanding of the method.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, ready to go! In this section we will make our first predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.1.1 R Subsetting Review
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Before presenting the code, let’s review a few aspects of the R language. Recall
    that in R, the `#` symbol is for comments; that is, it is not part of the code
    itself but is for explanatory purposes. The comments in the code below and throughout
    the book are used as inline explanations of what the code is doing.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the upcoming example, you’ll also need to remember how subsetting works
    in R. Take this snippet, for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The expression `x[c(2,4,5)]` extracts the 2nd, 4th, and 5th elements from the
    vector `x`. Also recall that here we refer to 2, 4, and 5 as *subscripts* or *indices*.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.1.2 A First Prediction
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Here, then, is our small, manually performed k-NN example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The distance between any two numbers is the absolute value of their difference:
    |25 − 32| = 7, so 25 is a distance 7 from 32\. This is why we made the call to
    R’s `abs()` (absolute value) function. R’s `order()` function is like `sort()`,
    except that it shows us the indices of the sorted numbers. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The values 2, 3, and so on are saying, “The first-smallest number in `x` was
    `x[2]`, the second-smallest was `x[3]`, and so on.” The line
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: will place in `do5` the indices of rows in `day1` that have the 5-closest temperatures
    to 28\. In this case, the temperatures are quite close to 28; the furthest is
    only 0.08 distant.
  prefs: []
  type: TYPE_NORMAL
- en: What were the ridership values on those days?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We then take the average of those values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We can now predict that on a day with a temperature of 28 degrees, about 5,200
    riders will use the bike sharing service.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some issues left hanging, notably: Why take the 5 days nearest in
    temperature to 28? Is 5 too small a sample, or is it sufficient to make an accurate
    prediction? This is a central issue in ML, to which we’ll return in [Section 1.7](ch01.xhtml#ch01lev7).'
  prefs: []
  type: TYPE_NORMAL
- en: 1.4 Dummy Variables and Categorical Variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To work with this dataset, and do ML in general, you’ll need to be able to understand
    the several columns in the data that represent *dummy variables*. Dummy variables
    take on values 1 and 0 only, depending on whether they satisfy a particular condition.
    For instance, in the `workingday` column, 0 stands for “No” (the date in question
    is not a working day) and 1 stands for “Yes” (the date is a working day). The
    date 2011-01-05 has a 1 in the `workingday` column, meaning yes, this was a working
    day.
  prefs: []
  type: TYPE_NORMAL
- en: Dummy variables are sometimes more formally called *indicator variables* because
    they *indicate* whether a certain condition holds (code 1) or not (code 0). An
    alternative term popular in ML circles is *one-hot coding*.
  prefs: []
  type: TYPE_NORMAL
- en: Our bike sharing data also includes the categorical variables `mnth` and `weekday`.
    There is also a feature `weathersit` consisting of four categories (1 = clear,
    2 = mist or cloudy, 3 = light snow or light rain, 4 = heavy rain or ice pellets
    or thunderstorm). That variable could be considered categorical as well.
  prefs: []
  type: TYPE_NORMAL
- en: One very common usage of dummy variables is coding of categorical data. In a
    marketing study, for instance, a factor of interest might be type of region of
    residence, say, Urban, Suburban, or Rural. Our original data might code these
    as 1, 2, or 3\. However, those are just arbitrary codes, so, for example, there
    is no implication that Rural is 3 times as good as Urban. Yet ML algorithms may
    take it that way, which is not what we want.
  prefs: []
  type: TYPE_NORMAL
- en: The solution, used throughout this book and throughout the ML field, is to use
    dummy variables. We could have a dummy variable for Urban (1 = yes, 0 = no) and
    one for Suburban. Rural-ness would then be coded by having both Urban and Suburban
    set to 0, so we don’t need a third dummy variable (having one might cause technical
    problems beyond the scope of this book). Of course, there is nothing special about
    using the first two values as dummies; we could have, say, one for Urban and one
    for Rural, without Suburban; the latter would then be indicated by 0 values in
    Urban and Rural.
  prefs: []
  type: TYPE_NORMAL
- en: In the current chapter, we focus on applications in which our outcome variable
    is numeric, such as total ridership in the bike sharing data. But in many applications,
    the outcome variable is categorical, such as our earlier example of predicting
    vertebral disease. In such settings, termed *classification applications*, the
    *Y* variable is categorical and must be converted to dummies.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, most ML packages, including `qeML`, do conversions to dummies automatically,
    as we will see shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 1.5 Analysis with qeKNN()
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have a better sense of what’s going on under the hood, let’s try
    using the `qeKNN()` function to perform some k-NN analysis. As noted in the introduction,
    this book uses the `qe*`-series wrapper functions. For k-NN, this means `qeKNN()`.
    The latter *wraps*, or provides a simple interface for, `regtools`’s basic k-NN
    function, `kNN()`. In other words, `qeKNN()` calls `kNN()` but in a simpler, more
    convenient manner.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start our analysis, we’ll introduce some “X” and “Y” notation to help
    us keep track of what we’re doing. Take notes—this will be important to remember
    for all subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '**FEATURES X AND OUTCOMES Y**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following informal shorthand used to refer to features and outcomes is
    pretty standard in both the ML and statistics fields:'
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, one collectively refers to the features as *X* and the outcome
    to be predicted as *Y*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*X* is a set of columns in a data frame or matrix. If we are predicting ridership
    from temperature and humidity, *X* consists of those latter two columns in our
    data. *Y* here is the ridership column.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In 2-class classification applications, *Y* will typically be a dummy variable,
    a column of 1s and 0s. However, in multiclass classification applications, *Y*
    is a set of columns, one for each dummy variable. Equivalently, *Y* could be an
    R factor, stored in a single column.
  prefs: []
  type: TYPE_NORMAL
- en: 'One more bit of standard notation:'
  prefs: []
  type: TYPE_NORMAL
- en: The number of rows in *X*—that is, the number of data points—is typically denoted
    by *n*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of columns in *X*—that is, the number of features—is typically denoted
    by *p*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is just a convenient shorthand. It’s easier, for instance, to say “X” rather
    than the more cumbersome “our feature set.” Again, *X*, *Y*, *n*, and *p* will
    appear throughout this book (and elsewhere, as they are standard in the ML field),
    so be sure to commit them to memory.
  prefs: []
  type: TYPE_NORMAL
- en: 1.5.1 Predicting Bike Ridership with qeKNN()
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the bike sharing example, we’ll predict total ridership on any given day.
    Let’s start out using as features just the dummy for working day and the numeric
    weather variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s extract those columns of the `day1` data frame. As we saw in [Section
    1.1.1](ch01.xhtml#ch01lev1sec1), they are in columns 8 and 10 through 13, with
    column 16 containing the outcome variable, the total ridership (`tot`). Thus we
    can obtain them via the following expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This extracts the desired columns.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Alternatively, you may prefer to use column names rather than numbers*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '*in base R, or use the tidyverse or data.table, each of which works fine. Numeric
    data frame indexing is much easier to type, but use of column names may be clearer.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*As pointed out in the introduction, this is a book about ML that happens to
    use R as its vehicle of instruction rather than a book about R in ML. The way
    that individual readers handle data manipulation in R is not the focus of this
    book, so feel free to use your own preferred way to achieve the same results.*'
  prefs: []
  type: TYPE_NORMAL
- en: So, we form the sub-data frame, and as usual, take a look.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now let’s try a prediction. Say you are the manager this morning, and the day
    is a working day, with temperature 12.0, atemp 11.8, humidity 23 percent, and
    wind at 5 miles per hour. What is your prediction for the ridership?
  prefs: []
  type: TYPE_NORMAL
- en: 'All the `qe*`-series functions have a very simple call form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The option used in this example will be *k*, the number of nearest neighbors,
    which we’ll take to be 5\. (If we do not specify *k* in the call, the default
    value is 25.)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We are applying the k-NN method, taking our “Y” (or “outcome,” as you’ll recall)
    to be the variable `tot` in the data frame `day1`, with 5 neighbors. We’ll discuss
    the holdout set shortly, but put that aside for now.
  prefs: []
  type: TYPE_NORMAL
- en: We saved the return value of `qeKNN()` in `knnout`. (Of course, you can use
    whatever name you wish.) It contains lots of information, but we won’t consider
    it at this point. The function `qeKNN()` did the prep work, enabling us to use
    `knnout` to do future predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, how exactly is that done? The general form for the `qe*`-series functions
    is likewise extremely simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s say, as manager of the bike sharing business, we know that today is a
    workday, and the temperature, atemp, humidity, and wind speed will be 12.8, 11.8,
    0.23, and 5, respectively. Here is our prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We fed `knnout` into the `predict()` function, along with our specified prediction
    point, `today`, yielding the predicted number of riders: about 6,300\. Observe
    that the argument `today` was a data frame with the same column names as in the
    original dataset `day1`. This is needed, both here and in many R ML packages,
    in order to match up the names in the prediction point with the names of the training
    set.'
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you run the above code yourself, you will likely get different output,
    due to randomness of the holdout set. There is a way to standardize the result
    so that different people obtain the same result; this will be explained in [Section
    1.12.3](ch01.xhtml#ch01lev12sec3).*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do another prediction, say, the same as above but with wind speed at
    18:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: People don’t seem to want to ride as much in the wind.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second argument, such as `anotherday` above, can be any data frame with
    the same column names. For instance, we could have asked for both predictions
    together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In [Section 1.8](#ch01lev8), we will deepen our insight into k-NN by analyzing
    another dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'TECHNICAL NOTE: PREDICT() AND GENERIC FUNCTIONS'
  prefs: []
  type: TYPE_NORMAL
- en: We saw that `qeKNN()` is paired with a `predict()` function. All functions in
    the `qe*`-series are similarly paired, which is a very common technique in R.
  prefs: []
  type: TYPE_NORMAL
- en: While all these functions appear to share the same `predict()`, each one actually
    has its own separate prediction function, such as `predict.qeKNN()` in the case
    of `qeKNN()`. The function `predict()` itself is called a *generic function* in
    R. It simply *dispatches* calls, meaning it relays the original call to a function
    specific to the type of analysis we are doing. Thus a call to `predict()` on an
    object created by `qeKNN()` will actually be relayed to `predict.qeKNN()`, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: R has various generic functions, some of which you’ve probably already been
    using, perhaps without knowing it. Examples are `print()`, `plot()`, and `summary()`.
    We’ll see an example of `plot()` in [Section 9.6](ch09.xhtml#ch09lev6).
  prefs: []
  type: TYPE_NORMAL
- en: '1.6 The Regression Function: The Basis of ML'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To understand machine learning methods, you need to know *what* is being “learned.”
    The answer is something called the *regression function*. Directly or indirectly
    (often the latter), it is the basis for ML methods. It gives the mean value of
    one variable, holding another variable fixed. Let’s make this concrete.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: Regression function *is a general statistical and ML term, much broader than
    the concept of linear regression that some readers may have learned in a statistics
    course.*
  prefs: []
  type: TYPE_NORMAL
- en: Recall our example above, where we took as our predicted value for a 28-degree
    day the mean ridership of days near that temperature. If we were to predict the
    ridership on a 15-degree day, we would use for our prediction the mean ridership
    of all days with a temperature of 15, or near 15, and so on. Denoting the regression
    function by *r*(), the quantities of interest are *r*(28), *r*(15), and so on.
  prefs: []
  type: TYPE_NORMAL
- en: We say *r*() is the regression function of ridership on temperature. It is indeed
    a function; for every input (a temperature), we get an output (the associated
    mean ridership). And we use the function as our predictions; for instance, to
    predict ridership on a 15-degree day, we use an estimate of *r*(15).
  prefs: []
  type: TYPE_NORMAL
- en: But it’s an unknown function, not something familiar like `sqrt()`. So, we need
    to use our training data to infer values of the function. In ML parlance, we say
    that we “learn” this function, using our data, showing you where the L comes from
    in ML. (The M just means we use a computer or algorithm to do the learning.) For
    instance, in the above example, we *learn r*(28) by averaging the ridership values
    over the days with a temperature close to 28\. The word *learn* is thus reflected
    in *train*, in the term *training data*.
  prefs: []
  type: TYPE_NORMAL
- en: It is customary to use the “hat” notation for “estimate of.” Thus we denote
    our estimate of *r*() by ![Images](../images/rcap.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: The regression function is also known as the *conditional mean*. In predicting
    ridership from temperature, *r*(28) is the mean ridership, subject to the *condition*
    that temperature is 28\. That’s a subpopulation mean, which is quite different
    from the overall population mean ridership.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s summarize these important points:'
  prefs: []
  type: TYPE_NORMAL
- en: The regression function *r*() gives the mean of our outcome variable as a function
    of our features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We estimate *r*() from our training data. We call the estimate ![Images](../images/rcap.jpg).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use ![Images](../images/rcap1.jpg) as the basis of our predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any function has arguments. A regression function has as many arguments as we
    have features. Let’s take humidity as a second feature, for instance. To predict
    ridership for a day with temperature 28 and humidity 0.51, we would use the mean
    ridership in our dataset among days in which temperature and humidity are approximately
    28 and 0.51\. In regression function notation, that’s *r*(28, 0.51). In the example
    on [page 12](ch01.xhtml#page_12), the value of interest was *r*(1, 12.8, 11.8,
    0.23, 5).
  prefs: []
  type: TYPE_NORMAL
- en: As previously noted, the regression function forms the basis, directly or indirectly,
    in all predictive ML methods. It will come up repeatedly throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 1.7 The Bias-Variance Trade-off
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the introduction, specifically in [Section 0.8](introduction.xhtml#ch00lev8),
    we implored the reader:'
  prefs: []
  type: TYPE_NORMAL
- en: A page that is all prose—no math, no graphs, and no code—may be one of the most
    important pages in the book.
  prefs: []
  type: TYPE_NORMAL
- en: The pages in this current section are prime examples of this, as the *Bias-Variance
    Trade-off* is one of the most famous topics in the field. My Google query yielded
    18,400,000 results! It is an absolutely central issue in ML, which we will treat
    in depth in [Chapter 3](ch03.xhtml). However, you should be aware of it from the
    beginning, so let’s give an overview.
  prefs: []
  type: TYPE_NORMAL
- en: The issue is, for example, the choice between greater or smaller values of *k*.
    Larger values of *k* have smaller variance but larger bias, and smaller values
    of *k* have the opposite effect. Let’s see how this works.
  prefs: []
  type: TYPE_NORMAL
- en: 1.7.1 Analogy to Election Polls
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: First consider an analogy to election surveys. During an election campaign,
    voter polls will be taken to estimate the popularity of the various candidates.
    An analyst takes a random sample of the set of all telephone numbers and solicits
    opinions from those who pick up the phone.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we are interested in *p*, the proportion of the entire population that
    favors Candidate C. Since we just have a sample from that population, we can only
    estimate the value of *p* using the proportion ![Images](../images/pcap.jpg) who
    like Candidate C in our sample. Accordingly, the poll results are accompanied
    by a *margin of error*, to recognize that the reported proportion ![Images](../images/pcap.jpg)
    is only an estimate of *p*. (Those who have studied statistics may know that the
    margin of error is the radius of a 95 percent confidence interval.)
  prefs: []
  type: TYPE_NORMAL
- en: The margin of error gives an indication of the accuracy of our estimate. It
    measures sampling variability. A large value means that our estimate of *p* varies
    a lot from one sample to another; if the pollster were to call a new random sample
    of phone numbers, the value of our estimated *p* likely would be rather different,
    possibly quite different if the sample size is small. Of course, the pollster
    is not going to take a second sample, but the amount of sampling variability from
    one sample to the next tells us how reliable ![Images](../images/pcap.jpg) is
    an estimate of *p*. The margin of error reflects that sampling variability, and
    if it is large, then our sample size was too small.
  prefs: []
  type: TYPE_NORMAL
- en: The key issue, then, is sampling variability, which is called the *variance*
    of ![Images](../images/pcap.jpg). It can be computed in the polling example from
    the margin of error.
  prefs: []
  type: TYPE_NORMAL
- en: A bias issue may also arise. Suppose the pollster has a list of landline phones
    but not cell phones. Many people, especially younger ones, don’t have a landline,
    so calling only those with landlines may bias our results.
  prefs: []
  type: TYPE_NORMAL
- en: 1.7.2 Back to ML
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Returning to ML, consider the bike sharing example in [Section 1.5.1](#ch01lev5sec1),
    where we wished to have the value of *r*(1, 12.8, 11.8, 0.23, 5), which we wish
    to use as our predicted value. We will obtain an estimate, ![Images](../images/rcap1.jpg)(1,
    12.8, 11.8, 0.23, 5), as the actual predicted value.
  prefs: []
  type: TYPE_NORMAL
- en: We treat the data on the number of riders per day as a sample from the (rather
    conceptual) population of all days, past, present, and future. Using the k-NN
    method (or any other ML method), we are only obtaining an estimate ![Images](../images/rcap1.jpg)
    of the true population regression function *r*(). Forming a prediction from just
    the closest *k* = 5 neighbors works from a very small sample. Imagine the pollster
    sampling only 5 voters! In another sample, the closest days to our point to be
    predicted would be different, with different ridership values. *In other words,
    this is a variance issue.*
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, using just *k* = 5, we found in [Section 1.3.1.2](ch01.xhtml#ch01lev3sec1sec2)
    that the 5 neighbors were all quite close to the prediction point. Suppose we
    look at the nearest *k* = 50 neighbors. In that case, we risk using data points
    far from the prediction point, which are thus not very similar to it. *This would
    create a bias problem.*
  prefs: []
  type: TYPE_NORMAL
- en: In sum, larger values of *k* reduce variance but at the expense of increasing
    bias. We want to find a “Goldilocks” value for *k*—that is, one not too small
    and not too large.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, note that computation time and the amount of memory the method requires
    are also important factors: if the best method takes too long to run or uses too
    much memory, we may end up choosing a different method.'
  prefs: []
  type: TYPE_NORMAL
- en: '1.8 Example: The mlb Dataset'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To cement your understanding of `qeKNN()` and introduce another example that
    we can refer to throughout the rest of the book, let’s try a similar operation
    on the `mlb` dataset. This dataset, provided courtesy of the UCLA Statistics Department,
    records the heights and weights of Major League Baseball players in inches and
    pounds, respectively. It’s included in `regtools`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s glance at the data first so we know what we’re working with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Let’s predict the weight of a new player for whom it is only known that height
    and age are 72 and 24, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note again that we needed to specify the prediction point (72,24) in the same
    data frame form as `mlb`, the dataset on which we had fit the model.
  prefs: []
  type: TYPE_NORMAL
- en: 1.9 k-NN and Categorical Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous baseball player example, both of the features, height and age,
    were numeric. But what if we were to add a third feature, `Position`, a categorical
    variable? Since k-NN is distance-based, the features need to be numeric in order
    to compute distances between data points. How can we use k-NN with non-numeric
    features?
  prefs: []
  type: TYPE_NORMAL
- en: The answer, of course, is that the categorical variables (that is, R factors)
    should be converted to dummy variables. We could do this here via the `regtools`
    function `factorToDummies()`. However, as the `qe*`-series functions do this conversion
    internally when needed, we need not convert `Position` to dummies on our own.
    The `qeKNN()` function will also make a note in its output for later use by `predict()`,
    to make the same conversions when predicting.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, suppose we want to calculate another new player’s weight, using
    the categorical `Position` feature, in addition to height and age:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In our first prediction, not using `Position`, our predicted value was about
    183 pounds. But if we know that the new player is a catcher, we see that, at least
    in this case, our predicted value increases to 197\. This makes sense; catchers
    do tend to be heavyset so they can guard home plate.
  prefs: []
  type: TYPE_NORMAL
- en: The `qe*`-series functions identify categorical features by their status as
    R factors. In the example here, `Position` is indeed an R factor. As noted, the
    internals of `qeKNN()` and `predict.qeKNN()` will automatically do the conversion
    to dummies for us, which is a major convenience.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, categorical features will already be expressed as factors in data
    frames. In some cases, a feature will be categorical but expressed in terms of
    numeric codes. If so, apply `as.factor()` to the feature to convert it to factor
    form.
  prefs: []
  type: TYPE_NORMAL
- en: 1.10 Scaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A theme encountered in many ML methods is that of *scaling* our data. In your
    future ML projects, it’s good practice to keep scaling in mind. It’s used in many
    ML methods and may produce better results even if a method doesn’t require it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go back to the baseball player data. Consider two players, one of height
    70 and age 24 and one of height 72 and age 30\. Taking these two pairs of numbers
    in an algebra context, the distance between them is the distance between the points
    (70,24) and (72,30) in the plane:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch1eq1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Distances like this would be computed in k-NN. But what if height were converted
    to, say, meters, and age to months? The heights would be divided by 39.37, while
    age would be multiplied by 12:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: That creates a problem in that age would dominate the computation, with height
    playing only a small role. Since height obviously is a major factor in predicting
    weight, the change in units would probably reduce our prediction ability.
  prefs: []
  type: TYPE_NORMAL
- en: The solution is to do away with units like inches, meters, and so on, which
    is called *scaling*. To scale our data, we first subtract the mean, giving everything
    mean 0, called *centering*. Then we divide each feature by its standard deviation,
    *scaling*. This gives everything a standard deviation of 1\. Now all the features
    are unitless and commensurate. (Usually, when doing scaling, we also do centering,
    and the combined process is simply called scaling.)
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this more concrete, as a former or current student, you may recall
    one of your professors converting examination scores in this way: “To get an A,
    you needed to be 1.5 standard deviations above the mean.” That professor was subtracting
    the mean exam score, then dividing by the standard deviation. The R function `scale()`
    performs this operation for us, but to illustrate, here is how we would do it
    on our own:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The `qeKNN()` function has an argument `scaleX` for this purpose. Its default
    value is `TRUE`, so scaling was done by default in our above k-NN examples. In
    each *X* column (recall this means feature column) of our data, `qeKNN()` will
    transform that column by calling `scale()`. (Actually, we can scale all the *X*
    variables with a single `scale()` call.)
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we must remember to do the same scaling—dividing by the same standard
    deviations—in the *X* values of new cases that we predict, such as new days in
    our bike sharing example. The `qe*`-series functions make a note of this, which
    is then used by the paired `predict()` functions.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Keep in mind that scale() won’t work on a vector in which all values are identical,
    as the standard deviation would be 0\. We can check for this by calling the regtools
    function constCols(), which will report all constant columns in our data frame.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the bike sharing data, `day1` uses unscaled data, for instructional purposes.
    The “official” version of the data, `day`, does scale. It does so in a different
    manner, though: it is scaled such that the values of the variables lie in the
    interval [0,1]. One way to do that is to transform by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch01eq02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This has an advantage over `scale()` by producing *bounded variables*—that is,
    numbers bounded by 0 and 1\. By contrast, `scale()` produces variables in the
    interval (*–∞*, *∞*), and a variable with a small standard deviation will likely
    have very large scaled values, giving that variable undue influence in the analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `regtools` function `mmscale()` does the above mapping to [0,1]. Here is
    a small example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The `u` column had a mean of 4, with a minimum and maximum of 3 and 5, respectively.
    Therefore, the 4 in the second row was replaced by (4 – 3) / (5 – 3) = 1/2, for
    example. As you can see, all the resulting values are in [0,1] and are unitless—that
    is, no inches or months.
  prefs: []
  type: TYPE_NORMAL
- en: 1.11 Choosing Hyperparameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the introduction, we mentioned that the number of nearest neighbors *k* is
    a *hyperparameter* or *tuning parameter*, a value chosen by the user that affects
    the predictive ability of the model. As noted in [Section 1.7](ch01.xhtml#ch01lev7),
    *k* is a “Goldilocks” quantity that needs to be carefully set for best performance—not
    too small and not too large.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the best *k* can be a challenge. Luckily, k-NN has only one hyperparameter,
    but as you will find later in the book, most ML methods have several; in some
    advanced methods outside the scope of the book, there may even be a dozen or more.
    Choosing the “right” combination of values for several hyperparameters is especially
    difficult, but even choosing a good value for a single hyperparameter is nontrivial.
  prefs: []
  type: TYPE_NORMAL
- en: We take our first look below at ways to tackle the challenging problem of picking
    hyperparameters and then go into more details in [Chapter 3](ch03.xhtml). Spend
    a little extra time on this section, since this issue will arise repeatedly in
    this book and throughout your ML career.
  prefs: []
  type: TYPE_NORMAL
- en: 1.11.1 Predicting the Training Data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Almost all methods for choosing hyperparameters involve testing our model by
    predicting new cases. In the most basic form, we go back and predict our original
    training data. This sounds odd—we know the ridership values in the data, so why
    predict them? The idea is to try various values of *k* and see which one predicts
    our known data the best. That then would be the value of *k* that we use for predicting
    new *X* data in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is not ideal, and in practice a slight modification of this approach is
    used. We will use it too, but before presenting it, let’s go through an illustration
    of what can go wrong. Let’s predict the third data point in `day1` using the smallest
    possible value of *k*: 1.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We predicted exactly correctly! But wait a minute . . . that seems suspicious,
    and it is. The closest neighbor to data point 3 (the third row in our data) is
    itself! The distance from that point to itself is 0\. Similarly, row 8 is the
    closest data point to row 8, row 56 is the closest data point to row 56, and so
    on. Of course we were 100 percent correct; we took the average of the 1-closest
    neighbor, thus just duplicating the *Y* value. The same analysis shows that even,
    say, *k* = 5 would give us overly optimistic prediction accuracy. One of the 5
    neighbors would still be the original data point, thus biasing our prediction.
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway is that when we evaluate the prediction accuracy of a given value
    of *k*, we should predict on a different dataset than the one to which we fit
    the k-NN method. But, you protest, we only have one dataset. How can we get another
    for properly assessing prediction accuracy? That’s the topic of the following
    section on holdout sets.
  prefs: []
  type: TYPE_NORMAL
- en: 1.12 Holdout Sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Again, as noted in the previous section, to assess the predictive accuracy of
    our model, we need to try it out on “fresh” data, not the data it was fit on.
    But we don’t have any new data, so what can be done? Key to solving this conundrum
    are the notions of *holdout sets* and *cross-validation* covered in this section.
    They are central to ML and will recur throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: In the 731 data points in `day1`, we could randomly cull out, say, 100 of them.
    These will serve as our *holdout set*, or *test set*. The remaining 631 will temporarily
    be our training set. We fit the model to this training set, then see how well
    it predicts on the holdout set, which serves as “fresh” data not biased by training.
    (In examples here, the holdout size is 73, as the default size is 10 percent of
    the dataset size.)
  prefs: []
  type: TYPE_NORMAL
- en: Technically, our accuracy in future predictions will be best if we fit our model
    on the entire dataset, in which case we set `holdout=NULL`. However, in preliminary
    exploration, it’s important to have some idea as to how well our model works on
    new data. Thus it’s best to have a holdout set during the exploration phase, then
    refit the model on the entire data once we’ve chosen hyperparameters and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Before we select our holdout set, if we are to evaluate quality of prediction,
    we need a criterion for evaluating prediction accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 1.12.1 Loss Functions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For a data point in the holdout set, we could take the absolute difference between
    the actual value and predicted value, then average those absolute differences
    over all holdout points to get the Mean Absolute Prediction Error (MAPE). This
    is an example of a *loss function*, which is simply a criterion for goodness of
    prediction. We could take MAPE as that criterion, with smaller values being better.
  prefs: []
  type: TYPE_NORMAL
- en: Another popular loss function is Mean Squared Prediction Error, or MSPE, where
    we average the squares of the prediction errors rather than their absolute values.
    MSPE is the more common of the two, but I prefer to use MAPE, as MSPE overly accentuates
    large errors. Say we are predicting weight in the MLB data. Consider two cases
    in which we are in error by 12 and 15 pounds. Those two numbers are fairly similar,
    but their squares, 144 and 225, are quite different.
  prefs: []
  type: TYPE_NORMAL
- en: For classification applications, the most commonly used loss function is simply
    the overall probability of misclassification. We predict each *Y* in the holdout
    set, tally the number of times we are wrong, and divide by the size of the holdout
    set.
  prefs: []
  type: TYPE_NORMAL
- en: 1.12.2 Holdout Sets in the qe*-Series
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The `qe*`-series functions will automatically perform the above process of finding
    the MAPE, or overall probability of misclassification, then report the result
    in the output component `testAcc`. These functions will sense whether our application
    is a classification problem according to whether we specify *Y* (second argument
    in any `qe*`-series call) as an R factor. If so, then the misclassification probability
    will be computed instead of MAPE.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll turn again to the bike sharing dataset for an example of finding `qeKNN`’s
    automatically generated MAPE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Using 5 nearest neighbors, we make an average prediction error of about 1,200
    riders. That’s not great, but better than the alternative, as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we had no access to weather conditions and so on. How could we predict
    ridership? One natural idea would be to just use the overall mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In other words, every day, including the one at hand, we would predict about
    4,500 riders. How well would we fare using this strategy?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If we were to always predict ridership using the overall mean riders per day,
    our average prediction error would be nearly 1,600\. Using the weather variables
    and `workingday` as predictors does help bring MAPE down to 1,200.
  prefs: []
  type: TYPE_NORMAL
- en: 'Can we find a better value for *k* than 5? Let’s try, say, 10 and 25:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Of the values we’ve tried, *k* = 10 seems to work best, though we must keep
    in mind the randomness of the holdout sets. Indeed, it is better to try several
    holdout sets for each candidate value of *k*, the topic of our next section.
  prefs: []
  type: TYPE_NORMAL
- en: 1.12.3 Motivating Cross-Validation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When using `qeKNN`’s automatically generated MAPEs, it is important to remember
    that the software is choosing the holdout set at random. The holdout set size
    is only 73, a somewhat small sample—imagine our election pollster above sampling
    only 73 voters. Thus there will be considerable *sampling variation* between MAPE
    in one holdout set and another. We can solve this problem through performing *cross-validation*—that
    is, averaging the values of MAPE over multiple holdout sets.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate sampling variation, let’s try running the same code a couple
    more times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We can see that we cannot rely too much on that one MAPE value; the sample size
    of 73 is too small. There is a lot more to say on this issue, and as noted, we
    will resume this discussion in [Chapter 3](ch03.xhtml). Suffice it to say now
    that we should look at many holdout sets and then perform cross-validation by
    averaging the resulting `testAcc` values.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the way, we can control R’s random number generator by using the `set.seed()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We will often do this in the book. It sets a certain sequence of random numbers,
    in case the reader wishes to run the code and check the results. By using the
    same seed, 9999 here, the same training and holdout sets will be generated as
    what I had here. (I just chose 9999 as a favorite; there is nothing special about
    it.)
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, we will obtain more accurate results by generating several holdout
    sets, thus averaging the resulting MAPE values. This is called *cross-validation*,
    which will be discussed in detail in [Chapter 3](ch03.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: 1.12.4 Hyperparameters, Dataset Size, and Number of Features
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Recall the discussion in [Section 1.7.2](ch01.xhtml#ch01lev7sec2) regarding
    a trade-off involving the choice of the number of nearest neighbors *k*:'
  prefs: []
  type: TYPE_NORMAL
- en: If we set *k* = 5, we will be averaging just 5 data points, which seems too
    few. This is a variance problem; averages of 5 *Y* values at a given *X* will
    vary a lot from one sample to another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On the other hand, setting *k* = 50, we would likely have some points in the
    neighborhood that are far away from the point to be predicted and thus unrepresentative.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, in the bike data, say we are predicting ridership on a 20-degree
    day, which is rather comfortable. Points in our training set with an uncomfortable
    temperature like 40 are not very relevant to the prediction at hand and would
    tend to make our prediction too low. This is a bias problem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'So, we have a trade-off. We want to make *k* large to achieve low variance,
    but setting a large *k* incurs the risk of substantial bias. But . . . what if
    our bike sharing dataset were to have, say, *n* = 73000 data points rather than
    731? In that case, the 50th-nearest neighbor might actually be pretty close to
    the prediction point, solving our bias problem. Then we could afford to use a
    larger *k* so as to hold down variance. In other words:'
  prefs: []
  type: TYPE_NORMAL
- en: All else being equal, the larger *n* is, the larger we can make *k*.
  prefs: []
  type: TYPE_NORMAL
- en: This still doesn’t tell us what specific *k* to choose. We’ll return to this
    issue in [Chapters 3](ch03.xhtml) and [4](ch04.xhtml), but it is something to
    at least be aware of at this early stage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The corresponding statement concerning the number of features *p* is:'
  prefs: []
  type: TYPE_NORMAL
- en: All else being equal, the larger *p* is, the larger we must make *k*.
  prefs: []
  type: TYPE_NORMAL
- en: This is less intuitive than the previous statement involving *n*, but roughly
    this is the issue. Having more features means more variability in interpoint distances,
    thus increasing variance in predictions. To counter this, we need a larger *k*.
  prefs: []
  type: TYPE_NORMAL
- en: '1.13 Pitfall: p-Hacking and Hyperparameter Selection'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In non-ML settings, *p-hacking* refers to the following pitfall in analyses
    of large studies. Say one is studying genetic impacts on some outcome, with very
    large numbers of genes involved. Even if no gene has a real impact, due to sampling
    variation, one of them will likely appear to have a “significant” impact just
    by accident. Though we won’t go into detail on how to solve this just yet, you
    should be aware of it from the beginning.
  prefs: []
  type: TYPE_NORMAL
- en: p-hacking also has major implications for the setting of hyperparameters in
    ML. Let’s say we have four tuning parameters in an ML method, and we try 10 values
    of each. That’s 10⁴ = 10000 possible combinations. Even if all of them are equally
    effective, the odds are that one of them will accidentally have a much better
    MAPE value. What seems to be the “best” setting for the hyperparameters may be
    illusory.
  prefs: []
  type: TYPE_NORMAL
- en: The `regtools` function `fineTuning()` takes steps to counter the possibility
    of p-hacking in searches for the best tuning parameter combination. We’ll cover
    more on this in [Chapter 7](ch07.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: '1.14 Pitfall: Long-Term Time Trends'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before we move on to the next chapter, let’s cover three major pitfalls you
    may encounter while working with the methods introduced here that may influence
    the quality of your predictions: dirty data, missing data, and longterm trends
    in the data. We will deal with the last pitfall first.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the few experiments we did with the MLB data, we found that the best MAPE
    value might be around 1,100\. This seems rather large, but recall we are not using
    all of our data. Look again at the bike dataset in [Section 1.1.1](ch01.xhtml#ch01lev1sec1).
    There are several variables involving timing of the observation: date, season,
    year, and month. To investigate whether the timing data can improve our MAPE value,
    let’s graph ridership against time. (The data is in chronological order.)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The result is in [Figure 1-1](ch01.xhtml#ch01fig01). Clearly, there is both
    a seasonal trend (the dips are about a year apart) and an overall upward trend.
    The bike sharing service seems to have gotten much more popular over time. Statistical
    techniques that analyze data over the course of time are known as *time series
    methods*. They arise a lot in ML in various contexts. We’ll investigate this in
    [Chapter 13](ch13.xhtml), but let’s give it a try here without new tools.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch01fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 1-1: Time trends, bike data*'
  prefs: []
  type: TYPE_NORMAL
- en: Column 1 in the bike sharing data, `instant`, is the day number, with the first
    day of the dataset having value 1, the second day with value 2, and so on, through
    the last day, 731.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s add `instant` to our feature set. Recall our earlier selection of columns
    in [Section 1.5.1](ch01.xhtml#ch01lev5sec1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The features we decided to explore at that time were in columns 8, 10 through
    13, and 16\. Now we want to also use `instant`, which is in column 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Ah, much better! Our MAPE is down to about 663.
  prefs: []
  type: TYPE_NORMAL
- en: When using k-NN and the other methods covered in this book, keep in mind that
    conditions in the phenomena under study may vary through time, possibly becoming
    a major factor. In some cases, the time variable may not even be explicit but
    implied in the ordering of the records. Failure to explore this may result in
    a substantial deterioration in the quality of prediction, so keep an eye out for
    places where you may run into this pitfall.
  prefs: []
  type: TYPE_NORMAL
- en: '1.15 Pitfall: Dirty Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Beyond accounting for long-term time trends, you may also encounter problems
    caused by dirty data. For an example of this, look at the entry in the bike sharing
    data for January 1, 2011.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in the `holiday` column, the dataset claims this is not a holiday.
    But of course January 1 is a federal holiday in the United States. Also, although
    the documentation for the dataset states there are 4 values for the categorical
    variable `weathersit`, there actually are just values 1, 2, and 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Errors in data are quite common and, of course, an obstacle to good analysis.
    For instance, consider the New York City taxi data that will be discussed in depth
    in [Chapter 5](ch05.xhtml), which contains pickup and dropoff locations, trip
    times, and so on. One of the dropoff locations, if one believes the numbers, is
    in Antarctica! (You can take a look at [*https://data.cityofnewyork.us/Transportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq*](https://data.cityofnewyork.us/Transportation/2018-Yellow-Taxi-Trip-Data/t29m-gskq).)
  prefs: []
  type: TYPE_NORMAL
- en: Whenever working with a new dataset, the analyst should do quite a bit of exploring—for
    example, with `hist()` and `table()`, as we’ve seen here. You should also be wary
    of *multivariate outliers*, meaning data points that are not extreme in any one
    of their components but, when viewed collectively, are unusual. For instance,
    suppose a person is recorded as having height 74 inches (29.1 cm) and age 6\.
    Neither that height nor that age would be cause for concern individually (assume
    we have people of all ages in our data), but in combination it seems quite suspicious.
    In this case, k-NN is a useful tool! A data point like the 74-inch six-year-old
    described above would be unusually distant from the other points and might be
    exposed that way.
  prefs: []
  type: TYPE_NORMAL
- en: Alas, there is no formulaic way to detect anomalous data points. This mirrors
    the nature of ML in general, as we’ve emphasized. There is no magic “recipe.”
    This is an advanced topic in statistics and beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: '1.16 Pitfall: Missing Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In R, the value NA means the data is not available—that is, missing. Datasets
    commonly include NAs, maybe many. How should we deal with this?
  prefs: []
  type: TYPE_NORMAL
- en: There are entire books devoted to the study of missing value analysis. We cannot
    cover the topic in any depth here, but we will briefly discuss one common method,
    *listwise deletion*, to at least introduce the issues at stake.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say our data consists of people, and we have variables Age, Gender, Years of
    Education, and so on. If, for a particular person, Age is missing but the other
    variables are intact, this method would simply skip over that case. But there
    are two problems with this:'
  prefs: []
  type: TYPE_NORMAL
- en: If we have a large number of features, odds are that many cases will have at
    least one NA. This would mean throwing out a lot of precious data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Skipping over cases with NAs may induce a bias. In survey data, for instance,
    the people who decline to respond to a certain question may be different from
    those who do respond to it, and this may affect the accuracy of our predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that when we find missing values are coded numerically rather than as NAs,
    we should change such values to NAs.
  prefs: []
  type: TYPE_NORMAL
- en: As with dirty data, developing one’s personal approach to handling missing values
    comes with experience. Learn some tools and gradually develop your approach, which
    will largely be different for each person. The CRAN Task View series includes
    one on missing data.
  prefs: []
  type: TYPE_NORMAL
- en: 1.17 Direct Access to the regtools k-NN Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned in the introduction, most of the code in this book uses popular
    R packages that are specific to each different ML method. We use the `qe*`-series
    of wrappers to interface those packages as a uniform, simple convenience, but
    of course one can also choose direct access.
  prefs: []
  type: TYPE_NORMAL
- en: One reason for doing so is that the functions in those standard R packages contain
    many advanced options not available via the wrappers. In the particular case of
    `qeKNN()`, but *not* for the other `qe*`-series functions, direct access may also
    be faster if one is doing just a single prediction.
  prefs: []
  type: TYPE_NORMAL
- en: In most applications, such specialized usage will not be necessary, but our
    book will show how to use the functions directly if the reader is interested.
    Note that we will not be able to demonstrate how to use those advanced options,
    as they are numerous and frequently involve advanced concepts. Instead, we will
    simply show how to use one of our existing examples with a direct call.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the particulars for our k-NN code. The `qeKNN()` function wraps `regtools::kNN()`,
    which has arguments as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Here `x` and `y` are our *X* and *Y*, `newx` is the *X* at which we wish to
    predict, and `kmax` is *k*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s retrace our steps from [Section 1.8](#ch01lev8):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Note that the model fitting and prediction are combined into one step, though
    the latter can be postponed if desired.
  prefs: []
  type: TYPE_NORMAL
- en: 'The prediction here is slightly different from the earlier one, as the latter
    had a holdout set. If we suppress formation of a holdout set, we obtain the same
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: More information on `kNN()` is available by typing ?kNN (not `?knn`).
  prefs: []
  type: TYPE_NORMAL
- en: 1.18 Conclusions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We are off to a good start! You should now have a good idea of both the k-NN
    method and several general ML concepts: the regression function, how k-NN estimates
    it, the general concept of the Bias-Variance Trade-off, how hyperparameters affect
    it, and how to use holdout sets to find a good point on that trade-off spectrum.'
  prefs: []
  type: TYPE_NORMAL
- en: You are already armed with enough tools to experiment with some data analysis
    of your own. Please do!
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will introduce the issues in classification applications.
  prefs: []
  type: TYPE_NORMAL
