<html><head></head><body>
		<h2 class="h2" id="ch15"><span epub:type="pagebreak" id="page_535"/><strong><span class="big">15</span></strong><br/><strong>FUNCTIONS AND PROCEDURES</strong></h2>&#13;
		<div class="image1">&#13;
			<img alt="image" src="../images/common01.jpg"/>&#13;
		</div>&#13;
		<p class="noindent">Since the beginning of the structured programming revolution in the 1970s, subroutines (procedures and functions) have been one of the primary tools software engineers use to organize, modularize, and otherwise structure their programs. Because procedure and function calls are used so frequently in code, CPU manufacturers have attempted to make them as efficient as possible. Nevertheless, these calls—and their associated returns—have costs that many programmers don’t consider when creating functions, and using them inappropriately can greatly increase a program’s size and execution time. This chapter discusses those costs and how to avoid them, covering the following subjects:</p>&#13;
		<ul>&#13;
			<li>&#13;
				<p class="noindent">Function and procedure calls</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">Macros and inline functions</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">Parameter passing and calling conventions</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">Activation records and local variables</p>&#13;
				</li>&#13;
			<li><span epub:type="pagebreak" id="page_536"/>&#13;
			<p class="noindent">Parameter-passing mechanisms</p>&#13;
			</li>&#13;
			<li>&#13;
				<p class="noindent">Function return results</p>&#13;
				</li>&#13;
		</ul>&#13;
		<p class="indent">By understanding these topics, you can avoid the efficiency pitfalls that are common in modern programs that make heavy use of procedures and functions.</p>&#13;
		<h3 class="h3" id="ch00lev1sec120"><strong>15.1 Simple Function and Procedure Calls</strong></h3>&#13;
		<p class="noindent">Let’s begin with some definitions. A <em>function</em> is a section of code that computes and returns some value—the function result. A <em>procedure</em> (or <em>void function</em>, in C/C++/Java/Swift terminology) simply accomplishes some action. Function calls generally appear within an arithmetic or logical expression, while procedure calls look like statements in the programming language. For the purpose of this discussion, you can generally assume that a procedure call and a function call are the same, and use the terms <em>function</em> and <em>procedure</em> interchangeably. For the most part, a compiler implements procedure and function calls identically.</p>&#13;
		<div class="note">&#13;
			<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
			<p class="notep"><em>Functions and procedures do have some differences, however. Namely, there are some efficiency issues related to function results, which we’ll consider in “Function Return Values” on <a href="ch15.xhtml#page_590">page 590</a>.</em></p>&#13;
		</div>&#13;
		<p class="indent">With most CPUs, you invoke procedures via an instruction similar to the 80x86 <span class="literal">call</span> (<span class="literal">branch</span> and <span class="literal">link</span> on the ARM and PowerPC) and return to the caller using the <span class="literal">ret</span> (return) instruction. The <span class="literal">call</span> instruction performs three discrete operations:</p>&#13;
		<ol>&#13;
			<li>&#13;
				<p class="noindent">It determines the address of the instruction to execute upon returning from the procedure (this is usually the instruction immediately following <span class="literal">call</span>).</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">It saves this address (commonly known as the <em>return address</em> or <em>link address</em>) into a known location.</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">It transfers control (via a jump mechanism) to the first instruction of the procedure.</p>&#13;
				</li>&#13;
		</ol>&#13;
		<p class="indent">Execution starts with the first instruction of the procedure and continues until the CPU encounters a <span class="literal">ret</span> instruction, which fetches the return address and transfers control to the machine instruction at that address. Consider the following C function:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>void func( void )<br/>{<br/>    return;<br/>}<br/><span epub:type="pagebreak" id="page_537"/>int main( void )<br/>{<br/>    func();<br/>    return( 0 );<br/>}</pre>&#13;
		<p class="indent">Here’s the conversion to PowerPC code by GCC:</p>&#13;
		<pre class="programs">&#13;
			_func:<br/>        ; Set up activation record for function.<br/>        ; Note R1 is used as the stack pointer by<br/>        ; the PowerPC ABI (application binary<br/>        ; interface, defined by IBM).<br/><br/>        stmw r30,-8(r1)<br/>        stwu r1,-48(r1)<br/>        mr r30,r1<br/><br/>        ; Clean up activation record prior to the return<br/><br/>        lwz r1,0(r1)<br/>        lmw r30,-8(r1)<br/><br/>        ; Return to caller (branch to address<br/>        ; in the link register):<br/><br/>        blr<br/><br/>_main:<br/>        ; Save return address from<br/>        ; main program (so we can<br/>        ; return to the OS):<br/><br/>        mflr r0<br/>        stmw r30,-8(r1) ; Preserve r30/31<br/>        stw r0,8(r1)    ; Save rtn adrs<br/>        stwu r1,-80(r1) ; Update stack for func()<br/>        mr r30,r1       ; Set up frame pointer<br/><br/>        ; Call func:<br/><br/>        bl _func<br/><br/>        ; Return 0 as the main<br/>        ; function result:<br/><br/>        li r0,0<br/>        mr r3,r0<br/>        lwz r1,0(r1)<br/>        lwz r0,8(r1)<br/>        mtlr r0<br/>        lmw r30,-8(r1)<br/>        blr</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_538"/>Here’s the 32-bit ARM version of this source code compiled by GCC:</p>&#13;
		<pre class="programs">&#13;
			func:<br/>    @ args = 0, pretend = 0, frame = 0<br/>    @ frame_needed = 1, uses_anonymous_args = 0<br/>    @ link register save eliminated.<br/><br/>    str fp, [sp, #-4]!  @ Save frame pointer on stack<br/>    add fp, sp, #0<br/>    nop<br/>    add sp, fp, #0<br/>    @ sp needed<br/>    ldr fp, [sp], #4    @ Load FP from stack.<br/>    bx  lr              @ Return from subroutine<br/><br/>main:<br/>    @ args = 0, pretend = 0, frame = 0<br/>    @ frame_needed = 1, uses_anonymous_args = 0<br/><br/>    push    {fp, lr}    @ Save FP and return address<br/><br/>    add fp, sp, #4      @ Set up FP<br/>    bl  func            @ Call func<br/>    mov r3, #0          @ main return value = 0<br/>    mov r0, r3<br/><br/>    @ Note that popping PC returns to Linux<br/>    pop {fp, pc}</pre>&#13;
		<p class="indent">And here’s the conversion of the same source code to 80x86 code by GCC:</p>&#13;
		<pre class="programs">&#13;
			func:<br/>.LFB0:<br/>    pushq   %rbp<br/>    movq    %rsp, %rbp<br/>    nop<br/>    popq    %rbp<br/>    ret<br/><br/>main:<br/>.LFB1:<br/>    pushq   %rbp<br/>    movq    %rsp, %rbp<br/>    call    func<br/>    movl    $0, %eax<br/>    popq    %rbp<br/>    ret</pre>&#13;
		<p class="indent">As you can see, the 80x86, ARM, and PowerPC devote considerable effort to building and managing activation records (see “The Stack Section” on <a href="ch07.xhtml#page_179">page 179</a>). The important things to see in these two assembly <span epub:type="pagebreak" id="page_539"/>language sequences are the <span class="literal">bl _func</span> and <span class="literal">blr</span> instructions in the PowerPC code; <span class="literal">bl func</span> and <span class="literal">bx lr</span> instructions in the ARM code; and the <span class="literal">call func</span> and <span class="literal">ret</span> instructions in the 80x86 code. These are the instructions that call the function and return from it.</p>&#13;
		<h4 class="h4" id="ch00lev2sec182"><strong>15.1.1 Return Address Storage</strong></h4>&#13;
		<p class="noindent">But where, exactly, does the CPU store the return address? In the absence of recursion and certain other program control constructs, the CPU could store the return address in any location that is large enough to hold the address and that will still contain that address when the procedure returns to its caller. For example, the program could choose to store the return address in a machine register (in which case the return operation would consist of an indirect jump to the address contained in that register). One problem with using registers, however, is that CPUs generally have a limited number of them. This means every register that holds a return address is unavailable for other purposes. For this reason, on CPUs that save the return address in a register, the applications usually move the return address to memory so they can reuse that register.</p>&#13;
		<p class="indent">Consider the PowerPC and ARM <span class="literal">bl</span> (branch and link) instruction. This instruction transfers control to the target address specified by its operand and copies the address of the instruction following <span class="literal">bl</span> into the LINK register. Inside a procedure, if no code modifies the value of the LINK register, the procedure can return to its caller by executing a PowerPC <span class="literal">blr</span> (branch to LINK register) or ARM <span class="literal">bx</span> (branch and exchange) instruction. In our trivial example, the <span class="literal">func()</span> function does not execute any code that modifies the value of the LINK register, so this is exactly how <span class="literal">func()</span> returns to its caller. However, if this function had used the LINK register for some other purpose, it would have been the procedure’s responsibility to save the return address so that it could restore the value prior to returning via a <span class="literal">blr</span> instruction at the end of the function call.</p>&#13;
		<p class="indent">A more common place to keep return addresses is in memory. Although accessing memory on most modern processors is much slower than accessing a CPU register, keeping return addresses in memory allows a program to have a large number of nested procedure calls. Most CPUs actually use a <em>stack</em> to hold return addresses. For example, the 80x86 <span class="literal">call</span> instruction <em>pushes</em> the return address onto a stack data structure in memory, and the <span class="literal">ret</span> instruction <em>pops</em> this return address off the stack. Using a stack of memory locations to hold return addresses offers several advantages:</p>&#13;
		<ul>&#13;
			<li>&#13;
				<p class="noindent">Stacks, because of their <em>last-in, first-out (LIFO)</em> organization, fully support nested procedure calls and returns as well as recursive procedure calls and returns.</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">Stacks are memory efficient because they reuse the same memory locations for different procedure return addresses (rather than requiring a separate memory location to hold each procedure’s return address).</p>&#13;
				</li>&#13;
			<li><span epub:type="pagebreak" id="page_540"/>&#13;
			<p class="noindent">Even though stack access is slower than register access, the CPU can generally access memory locations on the stack faster than separate return addresses elsewhere, because the CPU frequently accesses the stack and the stack contents tend to remain in the cache.</p>&#13;
			</li>&#13;
			<li>&#13;
				<p class="noindent">As discussed in <a href="ch07.xhtml#ch07">Chapter 7</a>, stacks are also great places to store activation records (such as parameters, local variables, and other procedure state information).</p>&#13;
				</li>&#13;
		</ul>&#13;
		<p class="indent">Using a stack also incurs a few penalties, though. Most importantly, maintaining a stack generally requires dedicating a CPU register to keep track of it in memory. This could be a register that the CPU explicitly dedicates for this purpose (for example, the RSP register on the x86-64 or R14/SP on the ARM) or a general-purpose register on a CPU that doesn’t provide explicit hardware stack support (for example, applications running on the PowerPC processor family typically use R1 for this purpose).</p>&#13;
		<p class="indent">On CPUs that provide a hardware stack implementation and a <span class="literal">call</span>/<span class="literal">ret</span> instruction pair, making a procedure call is easy. As shown earlier in the 80x86 GCC example output, the program simply executes a <span class="literal">call</span> instruction to transfer control to the beginning of the procedure and then executes a <span class="literal">ret</span> instruction to return from the procedure.</p>&#13;
		<p class="indent">The PowerPC/ARM approach, using a “branch and link” instruction might seem less efficient than the <span class="literal">call</span>/<span class="literal">ret</span> mechanism. While it’s certainly true that the “branch and link” approach requires a little more code, it isn’t so clear that it’s slower than the <span class="literal">call</span>/<span class="literal">ret</span> approach. A <span class="literal">call</span> instruction is a complex instruction (accomplishing several independent tasks with a single instruction) and, as a result, typically requires several CPU clock cycles to execute. The execution of the <span class="literal">ret</span> instruction is similar. Whether the extra overhead is costlier than maintaining a software stack varies by CPU and compiler. However, a “branch and link” instruction and an indirect jump through the link address, without the overhead of maintaining the software stack, is usually faster than the corresponding <span class="literal">call</span>/<span class="literal">ret</span> instruction pair. If a procedure doesn’t call any other procedures and can maintain parameters and local variables in machine registers, it’s possible to skip the software stack maintenance instructions altogether. For example, the call to <span class="literal">func()</span> in the previous example is probably more efficient on the PowerPC and ARM than on the 80x86, because <span class="literal">func()</span> doesn’t need to save the LINK register’s value into memory—it simply leaves that value in LINK throughout the execution of the function.</p>&#13;
		<p class="indent">Because many procedures are short and have few parameters and local variables, a good RISC compiler can often dispense with the software stack maintenance entirely. Therefore, for many common procedures, this RISC approach is faster than the CISC (<span class="literal">call</span>/<span class="literal">ret</span>) approach; however, that’s not to imply that it’s always better. The brief example in this section is a very special case. In our simple demonstration program, the function that this code calls—via the <span class="literal">bl</span> instruction—is near the <span class="literal">bl</span> instruction. In a complete application, <span class="literal">func()</span> might be <em>very</em> far away, and the compiler wouldn’t be able to encode the target address as part of the instruction. That’s because RISC processors (like the PowerPC and ARM) must encode <span epub:type="pagebreak" id="page_541"/>their entire instruction within a single 32-bit value (which must include both the opcode and the displacement to the function). If <span class="literal">func()</span> is farther away than can be encoded in the remaining displacement bits (24, in the case of the PowerPC and ARM <span class="literal">bl</span> instructions), the compiler has to emit a sequence of instructions that will compute the address of the target routine and indirectly transfer control through that address. Most of the time, this shouldn’t be a problem. After all, few programs are so large that the functions would be outside this range (64MB, in the case of the PowerPC, ±32MB for the ARM). However, there’s a very common case where GCC (and other compilers, presumably) must generate this type of code: when the compiler doesn’t know the target address of the function, because it’s an external symbol that the linker must merge in after compilation is complete. Because the compiler doesn’t know where the routine will be sitting in memory (and also because most linkers work only with 32-bit addresses, not 24-bit displacement fields), the compiler must assume that the function’s address is out of range and emit the long version of the function call. Consider the following slight modification to the earlier example:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>extern void func( void );<br/><br/>int main( void )<br/>{<br/>    func();<br/><br/>    return( 0 );<br/>}</pre>&#13;
		<p class="indent">This code declares <span class="literal">func()</span> as an external function. Now look at the PowerPC code that GCC produces and compare it with the earlier code:</p>&#13;
		<pre class="programs">&#13;
			.text<br/>        .align 2<br/>        .globl _main<br/>_main:<br/>        ; Set up main's activation record:<br/><br/>        mflr r0<br/>        stw r0,8(r1)<br/>        stwu r1,-80(r1)<br/><br/>        ; Call a "stub" routine that will<br/>        ; do the real call to func():<br/><br/>        bl L_func$stub<br/><br/>        ; Return 0 as Main's function<br/>        ; result:<br/><br/>        lwz r0,88(r1)<br/>        li r3,0<br/><span epub:type="pagebreak" id="page_542"/>        addi r1,r1,80<br/>        mtlr r0<br/>        blr<br/><br/><br/>; The following is a stub that calls the<br/>; real func() function, wherever it is in<br/>; memory.<br/><br/>        .data<br/>        .picsymbol_stub<br/>L_func$stub:<br/>        .indirect_symbol _func<br/><br/>        ; Begin by saving the LINK register<br/>        ; value in R0 so we can restore it<br/>        ; later.<br/><br/>        mflr r0<br/><br/>        ; The following code sequence gets<br/>        ; the address of the L_func$lazy_ptr<br/>        ; pointer object into R12:<br/><br/>        bcl 20,31,L0$_func      ; R11&lt;-adrs(L0$func)<br/>L0$_func:<br/>        mflr r11<br/>        addis r11,r11,ha16(L_func$lazy_ptr-L0$_func)<br/><br/>        ; Restore the LINK register (used by the<br/>        ; preceding code) from R0:<br/><br/>        mtlr r0<br/><br/>        ; Compute the address of func() and move it<br/>        ; into the PowerPC COUNT register:<br/><br/>        lwz r12,lo16(L_func$lazy_ptr-L0$_func)(r11)<br/>        mtctr r12<br/><br/>        ; Set up R11 with an environment pointer:<br/><br/>        addi r11,r11,lo16(L_func$lazy_ptr-L0$_func)<br/><br/>        ; Branch to address held in the COUNT<br/>        ; register (that is, to func):<br/><br/>        bctr<br/><br/>; The linker will initialize the following<br/>; dword (.long) value with the address of<br/>; the actual func() function:<br/><br/>        .data<br/>        .lazy_symbol_pointer<br/><span epub:type="pagebreak" id="page_543"/>L_func$lazy_ptr:<br/>        .indirect_symbol _func<br/>        .long dyld_stub_binding_helper</pre>&#13;
		<p class="indent">This code effectively winds up calling two functions in order to call <span class="literal">func()</span>. First, it calls a <em>stub</em> function (<span class="literal">L_func$stub</span>), which then transfers control to the actual <span class="literal">func()</span> routine. Clearly there is considerable overhead here. Without actually benchmarking the PowerPC code against the 80x86 code, it’s probably a safe bet that the 80x86 solution is a bit more efficient. (The 80x86 version of the GCC compiler emits the same code for the main program as in the earlier example, even when compiling in the external reference.) You’ll soon see that the PowerPC also generates stub functions for things other than external functions. Therefore, the CISC solution often is more efficient than the RISC solution (presumably, RISC CPUs make up the difference in performance in other areas).</p>&#13;
		<p class="indent">The Microsoft CLR also provides generic call and return functionality. Consider the following C# program with a static function <span class="literal">f()</span>:</p>&#13;
		<pre class="programs">&#13;
			using System;<br/><br/>namespace Calls_f<br/>{<br/>     class program<br/>      {<br/>        static void f()<br/>        {<br/>            return;<br/>        }<br/>        static void Main( string[] args)<br/>        {<br/>            f();<br/>        }<br/>      }<br/>}</pre>&#13;
		<p class="indent">Here’s the CIL code that the Microsoft C# compiler emits for functions <span class="literal">f()</span> and <span class="literal">Main()</span>:</p>&#13;
		<pre class="programs">&#13;
			.method private hidebysig static void  f() cil managed<br/>{<br/>  // Code size       4 (0x4)<br/>  .maxstack  8<br/>  IL_0000:  nop<br/>  IL_0001:  br.s       IL_0003<br/>  IL_0003:  ret<br/>} // end of method program::f<br/><br/><br/>.method private hidebysig static void  Main(string[] args) cil managed<br/>{<br/>  .entrypoint<br/>  // Code size       8 (0x8)<br/><span epub:type="pagebreak" id="page_544"/>  .maxstack  8<br/>  IL_0000:  nop<br/>  IL_0001:  call       void Calls_f.program::f()<br/>  IL_0006:  nop<br/>  IL_0007:  ret<br/>} // end of method program::Main</pre>&#13;
		<p class="indent">As one last example, here’s a comparable Java program:</p>&#13;
		<pre class="programs">&#13;
			public class Calls_f<br/>{<br/>    public static void f()<br/>    {<br/>        return;<br/>    }<br/><br/>    public static void main( String[] args )<br/>    {<br/>        f();<br/>    }<br/>}</pre>&#13;
		<p class="indent">Here’s the Java bytecode (JBC) output:</p>&#13;
		<pre class="programs">&#13;
			Compiled from "Calls_f.java"<br/>public class Calls_f extends java.lang.Object{<br/>public Calls_f();<br/>  Code:<br/>   0:   aload_0<br/>        //call Method java/lang/Object."&lt;init&gt;":()<br/>   1:   invokespecial   #1;<br/>   4:   return<br/><br/>public static void f();<br/>  Code:<br/>   0:   return<br/><br/>public static void main(java.lang.String[]);<br/>  Code:<br/>   0:   invokestatic    #2; //Method f:()<br/>   3:   return<br/><br/>}</pre>&#13;
		<p class="indent">Note that the Microsoft CLR and Java VM both have several variants of call and invoke instructions. These simple examples demonstrate calls to static methods.</p>&#13;
		<h4 class="h4" id="ch00lev2sec183"><strong>15.1.2 Other Sources of Overhead</strong></h4>&#13;
		<p class="noindent">Of course, a typical procedure call and return involve overhead beyond the execution of the actual procedure <span class="literal">call</span> and <span class="literal">return</span> instructions. Prior to calling the procedure, the calling code must compute and pass any <span epub:type="pagebreak" id="page_545"/>parameters to it. Upon entry into the procedure, the calling code may also need to complete the construction of the <em>activation record</em> (that is, allocate space for local variables). The costs of these operations vary by CPU and compiler. For example, if the calling code can pass parameters in registers rather than on the stack (or some other memory location), this is usually more efficient. Similarly, if the procedure can keep all its local variables in registers rather than in the activation record on the stack, accessing those local variables is much more efficient. This is one area where RISC processors have a considerable advantage over CISC processors. A typical RISC compiler can reserve several registers for passing parameters and local variables. (RISC processors typically have 16, 32, or more general-purpose registers, so setting aside several registers for this purpose is not outrageous.) For procedures that don’t call any other procedures (discussed in the next section), there’s no need to preserve these register values, so parameter and local variable access is very efficient. Even on CPUs with a limited number of registers (such as the 32-bit 80x86), it’s still possible to pass a small number of parameters, or maintain a few local variables, in registers. Many 80x86 compilers, for example, will keep up to three values (parameters or local variables) in the registers. Clearly, though, the RISC processors have an advantage here.<sup><a id="ch15fn_1"/><a href="footnotes.xhtml#ch15fn1">1</a></sup></p>&#13;
		<p class="indent">Armed with this knowledge, along with the background on activation records and stack frames from earlier in this book (see “The Stack Section” on <a href="ch07.xhtml#page_179">page 179</a>), we can now discuss how to write procedures and functions that operate as efficiently as possible. The exact rules are highly dependent upon your CPU and the compiler you’re using, but some of the concepts are generic enough to apply to all programs. The following sections assume that you’re writing for an 80x86 or ARM CPU (as most of the world’s software runs on one of these two CPUs).</p>&#13;
		<h3 class="h3" id="ch00lev1sec121"><strong>15.2 Leaf Functions and Procedures</strong></h3>&#13;
		<p class="noindent">Compilers can often generate better code for <em>leaf</em> procedures and functions—that is, those that don’t call other procedures or functions. The metaphor comes from a graphical representation of procedure/function invocations known as a <em>call tree</em>. A call tree consists of a set of circles (<em>nodes</em>) that represent the functions and procedures in a program. An arrow from one node to another implies that the first node contains a call to the second. <a href="ch15.xhtml#ch15fig1">Figure 15-1</a> illustrates a typical call tree.</p>&#13;
		<p class="indent">In this example, the main program directly calls procedure <span class="literal">prc1()</span> and functions <span class="literal">fnc1()</span> and <span class="literal">fnc2()</span>. Function <span class="literal">fnc1()</span> directly calls procedure <span class="literal">prc2()</span>. Function <span class="literal">fnc2()</span> directly calls procedures <span class="literal">prc2()</span> and <span class="literal">prc3()</span> as well <span epub:type="pagebreak" id="page_546"/>as function <span class="literal">fnc3()</span>. The leaf procedures and functions in this call tree are <span class="literal">prc1()</span>, <span class="literal">prc2()</span>, <span class="literal">fnc3()</span>, and <span class="literal">prc3()</span>, which do not call any other procedures or functions.</p>&#13;
		<div class="image" id="ch15fig1">&#13;
			<img alt="Image" src="../images/15fig01.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 15-1: A call tree</em></p>&#13;
		<p class="indent">Working with leaf procedures and functions has an advantage: they do not need to save parameters passed to them in registers or preserve the values of local variables they maintain in registers. For example, if <span class="literal">main()</span> passes two parameters to <span class="literal">fnc1()</span> in the EAX and EDX registers, and <span class="literal">fnc1()</span> passes a different pair of parameters to <span class="literal">prc2()</span> in EAX and EDX, then <span class="literal">fnc1()</span> must first save the values it found in EAX and EDX before calling <span class="literal">prc2()</span>. The <span class="literal">prc2()</span> procedure, on the other hand, doesn’t have to save the values in EAX and EDX prior to some procedure or function call, because it doesn’t make such calls. In a similar vein, if <span class="literal">fnc1()</span> allocates any local variables in registers, then it will need to preserve those registers across a call to <span class="literal">prc2()</span>, because <span class="literal">prc2()</span> can use the registers for its own purposes. By contrast, if <span class="literal">prc2()</span> uses a register for a local variable, it never has to preserve the variable’s value, because it never calls any subroutines. Therefore, good compilers tend to generate better code for leaf procedures and functions because they don’t have to preserve the register values.</p>&#13;
		<p class="indent">One way to <em>flatten</em> the call tree is to take the code associated with procedures and functions in interior nodes and inline it into functions higher in the call tree. In <a href="ch15.xhtml#ch15fig1">Figure 15-1</a>, for example, if it is practical to move the code for <span class="literal">fnc1()</span> into <span class="literal">main()</span>, you don’t need to save and restore registers (among other operations). However, be sure you’re not sacrificing readability and maintainability when flattening the call tree. You want to avoid writing procedures and functions that simply call other procedures and functions without doing any work on their own, but you don’t want to destroy the modularity of your application’s design by expanding function and procedure calls throughout your code.</p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_547"/>You’ve already seen that having a leaf function is handy when you’re using a RISC processor, like the PowerPC or ARM, that uses a “branch and link” instruction to make a subroutine call. The PowerPC and ARM LINK registers are good examples of registers that you have to preserve across procedure calls. Because a leaf procedure does not (normally) modify the value in the LINK register, no extra code is necessary in a leaf procedure to preserve that register’s value. To see the benefits of calling leaf functions on a RISC CPU, consider the following C code:</p>&#13;
		<pre class="programs">&#13;
			void g( void )<br/>{<br/>    return;<br/>}<br/><br/>void f( void )<br/>{<br/>    g();<br/>    g();<br/>    return;<br/>}<br/><br/>int main( void )<br/>{<br/>    f();<br/>    return( 0 );<br/>}</pre>&#13;
		<p class="indent">GCC emits the following PowerPC assembly code:</p>&#13;
		<pre class="programs">&#13;
			; g's function code:<br/><br/>_g:<br/>        ; Set up g's environment<br/>        ; (set up activation record):<br/><br/>        stmw r30,-8(r1)<br/>        stwu r1,-48(r1)<br/>        mr r30,r1<br/><br/>        ; Tear down the activation<br/>        ; record.<br/><br/>        lwz r1,0(r1)<br/>        lmw r30,-8(r1)<br/><br/>        ; Return to caller via LINK:<br/><br/>        blr<br/><br/>; f's function code:<br/><br/>_f:<br/><span epub:type="pagebreak" id="page_548"/>        ; Set up activation record,<br/>        ; including saving the value<br/>        ; of the LINK register:<br/><br/>        mflr r0         ; R0 = LINK<br/>        stmw r30,-8(r1)<br/>        stw r0,8(r1)    ; Save LINK<br/>        stwu r1,-80(r1)<br/>        mr r30,r1<br/><br/>        ; Call g (twice):<br/><br/>        bl _g<br/>        bl _g<br/><br/>        ; Restore LINK from the<br/>        ; activation record and<br/>        ; then clean up activation<br/>        ; record:<br/><br/>        lwz r1,0(r1)<br/>        lwz r0,8(r1)    ; R0 = saved adrs<br/>        mtlr r0         ; LINK = RO<br/>        lmw r30,-8(r1)<br/><br/>        ; Return to main function:<br/><br/>        blr<br/><br/>; Main function code:<br/><br/>_main:<br/>        ; Save main's return<br/>        ; address into main's<br/>        ; activation record:<br/><br/>        mflr r0<br/>        stmw r30,-8(r1)<br/>        stw r0,8(r1)<br/>        stwu r1,-80(r1)<br/>        mr r30,r1<br/><br/>        ; Call the f function:<br/><br/>        bl _f<br/><br/>        ; Return 0 to whomever<br/>        ; called main:<br/><br/>        li r0,0<br/>        mr r3,r0<br/>        lwz r1,0(r1)<br/>        lwz r0,8(r1)    ; Move saved return<br/>        mtlr r0         ; address to LINK<br/>        lmw r30,-8(r1)<br/><span epub:type="pagebreak" id="page_549"/>        ; Return to caller:<br/><br/>        blr</pre>&#13;
		<p class="indent">There’s an important difference between the implementations of the <span class="literal">f()</span> and <span class="literal">g()</span> functions in this PowerPC code—<span class="literal">f()</span> has to preserve the value of the LINK register, whereas <span class="literal">g()</span> does not. Not only does this involve extra instructions, but it also involves accessing memory, which can be slow.</p>&#13;
		<p class="indent">Another advantage to using leaf procedures, which isn’t obvious from the call tree, is that constructing their activation record requires less work. On the 80x86, for example, a good compiler doesn’t have to preserve the value of the EBP register, load EBP with the activation record address, and then restore the original value by accessing local objects via the stack pointer register (ESP). On RISC processors, which maintain the stack manually, the savings can be significant. For such procedures, the overhead of the procedure call and return and activation record maintenance is greater than the actual work done by the procedure. Therefore, eliminating the activation record maintenance code could nearly double the speed of the procedure. For these and other reasons, you should try to keep your call trees as shallow as possible. The more leaf procedures your program uses, the more efficient it may become when you compile it with a decent compiler.</p>&#13;
		<h3 class="h3" id="ch00lev1sec122"><strong>15.3 Macros and Inline Functions</strong></h3>&#13;
		<p class="noindent">One offshoot of the structured programming revolution was that computer programmers were taught to write small, modular, and logically coherent functions.<sup><a id="ch15fn_2"/><a href="footnotes.xhtml#ch15fn2">2</a></sup> A function that is logically coherent does one thing well. All of the statements in such a procedure or function are dedicated to doing the task at hand without producing any side computations or doing any extraneous operations. Years of software engineering research indicate that decomposing a problem into small components, and then implementing those, produces programs that are easier to read, maintain, and modify. Unfortunately, it’s easy to get carried away with this process and produce functions like the following Pascal example:</p>&#13;
		<pre class="programs">&#13;
			function sum( a:integer; b:integer ):integer;<br/>begin<br/><br/>       (* returns sum of a &amp; b as function result *)<br/><br/>        sum := a + b;<br/><br/>end;<br/>      .<br/>      .<br/>      .<br/>sum( aParam, bParam );</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_550"/>On the 80x86, it would probably take about three instructions to compute the sum of two values and store that sum into a memory variable. For example:</p>&#13;
		<pre class="programs">&#13;
			mov( aParam, eax );<br/>add( bParam, eax );<br/>mov( eax, destVariable );</pre>&#13;
		<p class="indent">Contrast this with the code necessary to simply <em>call</em> the function <span class="literal">sum()</span>:</p>&#13;
		<pre class="programs">&#13;
			push( aParam );<br/>push( bParam );<br/>call sum;</pre>&#13;
		<p class="indent">Within the procedure <span class="literal">sum</span> (assuming a mediocre compiler), you might expect to find code like the following HLA sequence:</p>&#13;
		<pre class="programs">&#13;
			// Construct the activation record<br/><br/>push( ebp );<br/>mov( esp, ebp );<br/><br/>// Get aParam's value<br/><br/>mov( [ebp+12], eax );<br/><br/>// Compute their sum and return in EAX<br/><br/>add( [ebp+8], eax );<br/><br/>// Restore EBP's value<br/><br/>pop( ebp );<br/><br/>// Return to caller, cleaning up<br/>// the activation record.<br/><br/>ret( 8 );</pre>&#13;
		<p class="indent">As you can see, using a function takes three times as many instructions to compute the sum of these two objects as the straight-line (no function call) code. Worse still, these nine instructions are generally slower than the three that make up the inline code. The inline code could run 5 to 10 times faster than the code with the function call.</p>&#13;
		<p class="indent">The one redeeming quality about the overhead associated with a function or procedure call is that it’s fixed. It takes the same number of instructions to set up the parameters and the activation record whether the procedure or function body contains 1 or 1,000 machine instructions. Although the overhead of a procedure call is huge when the procedure’s <span epub:type="pagebreak" id="page_551"/>body is small, it’s inconsequential when the procedure’s body is large. Therefore, to reduce the impact of procedure/function call overhead in your programs, try to place larger procedures and functions and write shorter sequences as inline code.</p>&#13;
		<p class="indent">Finding the optimum balance between the benefits of modular structure and the cost of too-frequent procedure calls can be difficult. Unfortunately, good program design often prevents us from increasing the size of our procedures and functions enough that the overhead of the call and return becomes insignificant. Sure, we could combine several functions and procedure calls into a single procedure or function, but this would violate several rules of programming style, and great code usually avoids such tactics. (One problem with the resulting programs is that few people can figure out how they work in order to optimize them.) However, if you can’t sufficiently lower the overhead of a procedure’s body by increasing the procedure’s size, you can still improve overall performance by reducing the overhead in other ways. As you’ve seen, one option is to use leaf procedures and functions. Good compilers emit fewer instructions for leaf nodes in the call tree, thereby reducing the call/return overhead. However, if the procedure’s body is short, you need a way to completely eliminate the procedure call/return overhead. Some languages accomplish this with <em>macros</em>.</p>&#13;
		<p class="indent">A <em>pure</em> macro expands the body of a procedure or function in place of its invocation. Because there’s no call/return to code elsewhere in the program, a macro expansion avoids the overhead associated with those instructions. Furthermore, macros also save considerable expense by using textual substitution for parameters rather than pushing the parameter data onto the stack or moving it into registers. The drawback to a macro is that the compiler expands the macro’s body for each invocation of the macro. If the macro body is large and you invoke it in many different places, the executable program can grow by a fair amount. Macros represent the classic time/space tradeoff: faster code at the expense of greater size. For this reason, you should use macros only to replace procedures and functions that have a small number of statements (say, between one and five), except in some rare cases where speed is paramount.</p>&#13;
		<p class="indent">A few languages (like C/C++) provide <em>inline</em> functions and procedures, which are a cross between a true function (or procedure) and a pure macro. Most languages that support inline functions and procedures do not guarantee that the compiler will expand the code inline. <em>Inline expansion</em>, or a call to an actual function in memory, is done at the compiler’s discretion. Most compilers won’t expand an inline function if its body is too large or if it has an excessive number of parameters. Furthermore, unlike pure macros, which don’t have any associated procedure call overhead, inline functions may still need to build an activation record in order to handle local variables, temporaries, and other requirements. Thus, even if the compiler does expand such a function inline, there may still be some overhead that you wouldn’t get with a pure macro.</p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_552"/>To see the result of function inlining, consider the following C source file prepared for compilation by Microsoft Visual C++:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>// Make geti and getj external functions<br/>// to thwart constant propagation so we<br/>// can see the effects of the following<br/>// code.<br/><br/>extern int geti( void );<br/>extern int getj( void );<br/><br/>// Inline function demonstration. Note<br/>// that "_inline" is the legacy MSVC++ "C" way<br/>// of specifying an inline function (the<br/>// actual "inline" keyword was a C++/C99 feature,<br/>// which this code avoids in order to make<br/>// the assembly output a little more readable).<br/>//<br/>//<br/>// "inlineFunc" is a simple inline function<br/>// that demonstrates how the C/C++ compiler<br/>// does a simple inline macro expansion of<br/>// the function:<br/><br/>_inline int inlineFunc( int a, int b )<br/>{<br/>    return a + b;<br/>}<br/><br/>_inline int ilf2( int a, int b )<br/>{<br/>    // Declare some variable that will require<br/>    // an activation record to be built (that is,<br/>    // register allocation won't be sufficient):<br/><br/>    int m;<br/>    int c[4];<br/>    int d;<br/><br/>    // Make sure we use the "c" array so that<br/>    // the optimizer doesn't ignore its<br/>    // declaration:<br/><br/>    for( m = 0; m &lt; 4; ++m )<br/>    {<br/>        c[m] = geti();<br/>    }<br/>    d = getj();<br/>    for( m = 0; m &lt; 4; ++m )<br/>    {<br/>        d += c[m];<br/>    }<br/><span epub:type="pagebreak" id="page_553"/>    // Return a result to the calling program:<br/><br/>    return (a + d) - b;<br/>}<br/><br/><br/>int main( int argc, char **argv )<br/>{<br/>    int i;<br/>    int j;<br/>    int sum;<br/>    int result;<br/><br/>    i = geti();<br/>    j = getj();<br/>    sum = inlineFunc( i, j );<br/>    result = ilf2( i, j );<br/>    printf( "i+j=%d, result=%d\n", sum, result );<br/>    return 0;<br/>}</pre>&#13;
		<p class="indent">Here’s the MASM-compatible assembly language code that MSVC emits when you specify a C compilation (versus a C++ compilation, which produces messier output):</p>&#13;
		<pre class="programs">&#13;
			_main      PROC NEAR<br/>main    PROC<br/>;<br/>; Create the activation record:<br/>;<br/>$LN6:<br/>        mov     QWORD PTR [rsp+8], rbx<br/>        push    rdi<br/>        sub     rsp, 32        ; 00000020H<br/>; Line 66<br/>;<br/>; i = geti();<br/>;<br/>        call    ?geti@@YAHXZ   ; geti -- returns result in EAX<br/>        mov     edi, eax       ; Save i in edi<br/><br/>; Line 67<br/>;<br/>; j = getj();<br/>;<br/>        call    ?getj@@YAHXZ   ; getj -- Returns result in EAX<br/>; Line 69<br/>;<br/>; Inline expansion of inlineFunc()<br/>;<br/>        mov     edx, eax       ; Pass j in EDX<br/>        mov     ecx, edi       ; Pass i in ECX<br/><span epub:type="pagebreak" id="page_554"/>        mov     ebx, eax       ; Use EBX as "sum" local<br/>        call    ?ilf2@@YAHHH@Z ; ilf2<br/><br/>;       Computes sum = i+j (inline)<br/><br/>        lea     edx, DWORD PTR [rbx+rdi]<br/><br/>; Line 70<br/>;<br/>; Call to printf function:<br/><br/>        mov     r8d, eax<br/>        lea     rcx, OFFSET FLAT:??_C@_0BD@INCDFJPK@i?$CLj?$DN?$CFd?0?5result?$DN?$CFd?6?$AA@<br/>        call    printf<br/>; Line 72<br/>;<br/>; Return from main function<br/>;<br/>        mov     rbx, QWORD PTR [rsp+48]<br/>        xor     eax, eax<br/>        add     rsp, 32        ; 00000020H<br/>        pop     rdi<br/>        ret     0<br/>main    ENDP<br/><br/>?ilf2@@YAHHH@Z PROC            ; ilf2, COMDAT<br/>; File v:\t.cpp<br/>; Line 30<br/>$LN24:<br/>        mov     QWORD PTR [rsp+8], rbx<br/>        mov     QWORD PTR [rsp+16], rsi<br/>        push    rdi<br/>        sub     rsp, 64        ; 00000040H<br/>;<br/>; Extra code to help prevent hacks from messing with<br/>; stack data (clears array data to prevent observing old<br/>; memory data).<br/><br/>        mov     rax, QWORD PTR __security_cookie<br/>        xor     rax, rsp<br/>        mov     QWORD PTR __$ArrayPad$[rsp], rax<br/>        mov     edi, edx<br/>        mov     esi, ecx<br/>; Line 43<br/>; Loop to fill "v" array:<br/>;<br/>        xor     ebx, ebx<br/>$LL4@ilf2:<br/>; Line 45<br/>        call    ?geti@@YAHXZ   ; geti<br/>        mov     DWORD PTR c$[rsp+rbx*4], eax<br/>        inc     rbx<br/>        cmp     rbx, 4<br/><span epub:type="pagebreak" id="page_555"/>        jl      SHORT $LL4@ilf2<br/><br/>; Line 47<br/>;<br/>; d = getj();<br/>;<br/>        call    ?getj@@YAHXZ   ; getj<br/>; Line 50<br/>;<br/>; Second for loop is unrolled and expanded inline:<br/>;<br/>; d += c[m];<br/><br/>        mov     r8d, DWORD PTR c$[rsp+8]<br/>        add     r8d, DWORD PTR c$[rsp+12]<br/>        add     r8d, DWORD PTR c$[rsp]<br/>        add     r8d, DWORD PTR c$[rsp+4]<br/>;<br/>; return (a+d) - b<br/>;<br/>        add     eax, r8d<br/>; Line 55<br/>        sub     eax, edi<br/>        add     eax, esi<br/>; Line 56<br/>;<br/>; Verify code did not mess with stack before leaving<br/>; (array overflow):<br/>;<br/>        mov     rcx, QWORD PTR __$ArrayPad$[rsp]<br/>        xor     rcx, rsp<br/>        call    __security_check_cookie<br/>        mov     rbx, QWORD PTR [rsp+80]<br/>        mov     rsi, QWORD PTR [rsp+88]<br/>        add     rsp, 64        ; 00000040H<br/>        pop     rdi<br/>        ret     0<br/>?ilf2@@YAHHH@Z ENDP            ; ilf2<br/><br/>?inlineFunc@@YAHHH@Z PROC      ; inlineFunc, COMDAT<br/>; File v:\t.cpp<br/>; Line 26<br/>        lea     eax, DWORD PTR [rcx+rdx]<br/>; Line 27<br/>        ret     0<br/>?inlineFunc@@YAHHH@Z ENDP      ; inlineFunc</pre>&#13;
		<p class="indent">As you can see in this assembly output, there are no function calls to the <span class="literal">inlineFunc()</span> function. Instead, the compiler expanded this function in place in the <span class="literal">main()</span> function, at the point where the main program calls it. Although the <span class="literal">ilf2()</span> function was also declared inline, the compiler refused to expand it inline and treated it like a normal function (probably because of its size).</p>&#13;
		<h3 class="h3" id="ch00lev1sec123"><span epub:type="pagebreak" id="page_556"/><strong>15.4 Passing Parameters to a Function or Procedure</strong></h3>&#13;
		<p class="noindent">The number and type of parameters can also have a big impact on the efficiency of the code a compiler generates for your procedures and functions. Simply put, the more parameter data you pass, the more expensive the procedure or function call becomes. Often, programmers call generic functions (or design generic functions) that require you to pass several optional parameters whose values the function won’t use. This scheme can make functions more generally applicable to different applications, but—as you’ll see in this section—there’s a cost associated with that generality, so you might want to consider using a version of the function specific to your application if space or speed is an issue.</p>&#13;
		<p class="indent">The parameter-passing mechanism (for example, pass-by-reference or pass-by-value) also has an impact on the overhead associated with a procedure call and return. Some languages allow you to pass large data objects by value. (Pascal lets you pass strings, arrays, and records by value, and C/C++ allows you to pass structures by value; other languages vary depending on their design.) Whenever you pass a large data object by value, the compiler must emit machine code that makes a copy of that data into the procedure’s activation record. This can be time-consuming (especially when copying large arrays or structures). Furthermore, large objects probably won’t fit in the CPU’s register set, so accessing such data within a procedure or function is expensive. It’s usually more efficient to pass large data objects such as arrays and structures by reference than by value. The extra cost of accessing the data indirectly is usually saved many times over by not having to copy the data into the activation record. Consider the following C code, which passes a large structure by value to a C function:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>typedef struct<br/>{<br/>    int array[256];<br/>} a_t;<br/><br/>void f( a_t a )<br/>{<br/>    a.array[0] = 0;<br/>    return;<br/>}<br/><br/>int main( void )<br/>{<br/>    a_t b;<br/><br/>    f( b );<br/>    return( 0 );<br/>}</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_557"/>Here’s the PowerPC code that GCC emits:</p>&#13;
		<pre class="programs">&#13;
			_f:<br/>        li r0,0 ; To set a.array[0] = 0<br/><br/>        ; Note: the PowerPC ABI passes the<br/>        ; first eight dwords of data in<br/>        ; R3..R10. We need to put that<br/>        ; data back into the memory array<br/>        ; here:<br/><br/>        stw r4,28(r1)<br/>        stw r5,32(r1)<br/>        stw r6,36(r1)<br/>        stw r7,40(r1)<br/>        stw r8,44(r1)<br/>        stw r9,48(r1)<br/>        stw r10,52(r1)<br/><br/>        ; Okay, store 0 into a.array[0]:<br/><br/>        stw r0,24(r1)<br/><br/>        ; Return to caller:<br/><br/>        blr<br/><br/>; main function:<br/><br/>_main:<br/><br/>        ; Set up main's activation record:<br/><br/>        mflr r0<br/>        li r5,992<br/>        stw r0,8(r1)<br/><br/>        ; Allocate storage for a:<br/><br/>        stwu r1,-2096(r1)<br/><br/>        ; Copy all but the first<br/>        ; eight dwords to the<br/>        ; activation record for f:<br/><br/>        addi r3,r1,56<br/>        addi r4,r1,1088<br/>        bl L_memcpy$stub<br/><br/>        ; Load the first eight dwords<br/>        ; into registers (as per the<br/>        ; PowerPC ABI):<br/><br/>        lwz r9,1080(r1)<br/>        lwz r3,1056(r1)<br/><span epub:type="pagebreak" id="page_558"/>        lwz r10,1084(r1)<br/>        lwz r4,1060(r1)<br/>        lwz r5,1064(r1)<br/>        lwz r6,1068(r1)<br/>        lwz r7,1072(r1)<br/>        lwz r8,1076(r1)<br/><br/>        ; Call the f function:<br/><br/>        bl _f<br/><br/>        ; Clean up the activation record<br/>        ; and return 0 to main's caller:<br/><br/>        lwz r0,2104(r1)<br/>        li r3,0<br/>        addi r1,r1,2096<br/>        mtlr r0<br/>        blr<br/><br/>; Stub function that copies the structure<br/>; data to the activation record for the<br/>; main function (this calls the C standard<br/>; library memcpy function to do the actual copy):<br/><br/>        .data<br/>        .picsymbol_stub<br/>L_memcpy$stub:<br/>        .indirect_symbol _memcpy<br/>        mflr r0<br/>        bcl 20,31,L0$_memcpy<br/>L0$_memcpy:<br/>        mflr r11<br/>        addis r11,r11,ha16(L_memcpy$lazy_ptr-L0$_memcpy)<br/>        mtlr r0<br/>        lwz r12,lo16(L_memcpy$lazy_ptr-L0$_memcpy)(r11)<br/>        mtctr r12<br/>        addi r11,r11,lo16(L_memcpy$lazy_ptr-L0$_memcpy)<br/>        bctr<br/>.data<br/>.lazy_symbol_pointer<br/>L_memcpy$lazy_ptr:<br/>        .indirect_symbol _memcpy<br/>        .long dyld_stub_binding_helper</pre>&#13;
		<p class="indent">As you can see, the call to function <span class="literal">f()</span> calls <span class="literal">memcpy</span> to transfer a copy of the data from the <span class="literal">main()</span> function’s local array to the <span class="literal">f()</span> function’s activation record. Again, copying memory is a slow process, and this code amply demonstrates that you should avoid passing large objects by value. Consider the same code when you pass the structure by reference:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>typedef struct<br/><span epub:type="pagebreak" id="page_559"/>{<br/>    int array[256];<br/>} a_t;<br/><br/>void f( a_t *a )<br/>{<br/>    a-&gt;array[0] = 0;<br/>    return;<br/>}<br/><br/>int main( void )<br/>{<br/>    a_t b;<br/>    f( &amp;b );<br/>    return( 0 );<br/>}</pre>&#13;
		<p class="indent">Here’s the conversion of this C source code to 32-bit ARM assembly by GCC:</p>&#13;
		<pre class="programs">&#13;
			f:<br/>    @ Build activation record:<br/><br/>    str fp, [sp, #-4]!  @ Push old FP on stack<br/>    add fp, sp, #0      @ FP = SP<br/>    sub sp, sp, #12     @ Reserve storage for locals<br/>    str r0, [fp, #-8]   @ Save pointer to 'a'<br/>    ldr r3, [fp, #-8]   @ r3 = a<br/><br/>    @ a-&gt;array[0] = 0;<br/><br/>    mov r2, #0<br/>    str r2, [r3]<br/>    nop<br/><br/>    @ Remove locals from stack.<br/><br/>    add sp, fp, #0<br/><br/>    @ Pop FP from stack:<br/><br/>    ldr fp, [sp], #4<br/><br/>    @ Return to main function:<br/><br/>    bx  lr<br/><br/>main:<br/>    @ Save Linux return address and FP:<br/><br/>    push    {fp, lr}<br/><span epub:type="pagebreak" id="page_560"/><br/>    @ Set up activation record:<br/><br/>    add fp, sp, #4<br/>    sub sp, sp, #1024   @ Reserve storage for b<br/>    sub r3, fp, #1024   @ R3 = &amp;b<br/>    sub r3, r3, #4<br/><br/>    mov r0, r3          @ Pass &amp;b to f in R0<br/>    bl  f               @ Call f<br/><br/>    @ Return 0 result to Linux:<br/><br/>    mov r3, #0<br/>    mov r0, r3<br/>    sub sp, fp, #4      @ Clean up stack frame<br/>    pop {fp, pc}        @ Returns to Linux</pre>&#13;
		<p class="indent">Depending on your CPU and compiler, it may be slightly more efficient to pass small (scalar) data objects by value rather than by reference. For example, if you’re using an 80x86 compiler that passes parameters on the stack, you’ll need two instructions to pass a memory object by reference, but only a single instruction to pass that same object by value. So, although trying to pass large objects by reference is a good idea, the reverse is generally true for small objects. However, this is not a hard and fast rule; its validity varies based on the CPU and compiler you’re using.</p>&#13;
		<p class="indent">Some programmers may feel that it’s more efficient to pass data to a procedure or function via global variables. After all, if the data is already sitting in a global variable that’s accessible to the procedure or function, a call to that procedure or function won’t require any extra instructions to pass the data to the subroutine, therefore reducing the call overhead. While this seems like a big win, keep in mind that compilers have a difficult time optimizing programs that make excessive use of global variables. Although using globals may reduce the function/procedure call overhead, it may also prevent the compiler from handling other optimizations that would have been otherwise possible. Here’s a simple example using Microsoft Visual C++ that demonstrates this problem:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>// Make geti an external function<br/>// to thwart constant propagation so we<br/>// can see the effects of the following<br/>// code.<br/><br/>extern int geti( void );<br/><br/>// globalValue is a global variable that<br/>// we use to pass data to the "usesGlobal"<br/>// function:<br/><br/>int globalValue = 0;<br/><span epub:type="pagebreak" id="page_561"/><br/>// Inline function demonstration. Note<br/>// that "_inline" is the legacy MSVC++ "C" way<br/>// of specifying an inline function (the<br/>// actual "inline" keyword is a C99/C++ feature,<br/>// which this code avoids in order to make<br/>// the assembly output a little more readable).<br/><br/><br/>_inline int usesGlobal( int plusThis )<br/>{<br/>    return globalValue+plusThis;<br/>}<br/><br/>_inline int usesParm( int plusThis, int globalValue )<br/>{<br/>    return globalValue+plusThis;<br/>}<br/><br/><br/>int main( int argc, char **argv )<br/>{<br/>    int i;<br/>    int sumLocal;<br/>    int sumGlobal;<br/><br/>    // Note: the call to geti in between setting globalValue<br/>    // and calling usesGlobal is intentional. The compiler<br/>    // doesn't know that geti doesn't modify the value of<br/>    // globalValue (and neither do we, frankly), and so<br/>    // the compiler cannot use constant propagation here.<br/><br/>    globalValue = 1;<br/>    i = geti();<br/>    sumGlobal = usesGlobal( 5 );<br/><br/>    // If we pass the "globalValue" as a parameter rather<br/>    // than setting a global variable, then the compiler<br/>    // can optimize the code away:<br/><br/>    sumLocal = usesParm( 5, 1 );<br/>    printf( "sumGlobal=%d, sumLocal=%d\n", sumGlobal, sumLocal );<br/>    return 0;<br/>}</pre>&#13;
		<p class="indent">Here’s the 32-bit MASM source code (with manual annotations) that the MSVC++ compiler generates for this code:</p>&#13;
		<pre class="programs">&#13;
			_main      PROC NEAR<br/>;   globalValue = 1;<br/><br/>    mov    DWORD PTR _globalValue, 1<br/><br/>;   i = geti();<br/><span epub:type="pagebreak" id="page_562"/>;<br/>; Note that because of dead code elimination,<br/>; MSVC++ doesn't actually store the result<br/>; away into i, but it must still call geti()<br/>; because geti() could produce side effects<br/>; (such as modifying globalValue's value).<br/><br/>    call   _geti<br/><br/>;   sumGlobal = usesGlobal( 5 );<br/>;<br/>; Expanded inline to:<br/>;<br/>; globalValue+plusThis<br/><br/>    mov    eax, DWORD PTR _globalValue<br/>    add    eax, 5          ; plusThis = 5<br/><br/>; The compiler uses constant propagation<br/>; to compute:<br/>;   sumLocal = usesParm( 5, 1 );<br/>; at compile time. The result is 6, which<br/>; the compiler directly passes to print here:<br/><br/>    push   6<br/><br/>; Here's the result for the usesGlobal expansion,<br/>; computed above:<br/><br/>    push   eax<br/>    push   OFFSET FLAT:formatString ; 'string'<br/>    call   _printf<br/>    add    esp, 12                  ; Remove printf parameters<br/><br/>; return 0;<br/><br/>    xor    eax, eax<br/>    ret    0<br/>_main      ENDP<br/>_TEXT      ENDS<br/>           END</pre>&#13;
		<p class="indent">As you can see, the compiler’s ability to optimize around global variables can be easily thwarted by the presence of some seemingly unrelated code. In this example, the compiler cannot determine that the call to the external <span class="literal">geti()</span> function doesn’t modify the value of the <span class="literal">globalValue</span> variable. Therefore, the compiler can’t assume that <span class="literal">globalValue</span> still has the value <span class="literal">1</span> when it computes the inline function result for <span class="literal">usesGlobal()</span>. Exercise extreme caution when using global variables to communicate information between a procedure or function and its caller. Code that’s unrelated to the task at hand (such as the call to <span class="literal">geti()</span>, which probably doesn’t affect <span class="literal">globalValue</span>’s value) can prevent the compiler from optimizing code that uses global variables.</p>&#13;
		<h3 class="h3" id="ch00lev1sec124"><span epub:type="pagebreak" id="page_563"/><strong>15.5 Activation Records and the Stack</strong></h3>&#13;
		<p class="noindent">Because of how a stack works, the last procedure activation record the software creates will be the first activation record that the system deallocates. Since activation records hold procedure parameters and local variables, a <em>last-in, first-out (LIFO)</em> organization is a very intuitive way of implementing activation records. To see how it works, consider the following (trivial) Pascal program:</p>&#13;
		<pre class="programs">&#13;
			program ActivationRecordDemo;<br/><br/>    procedure C;<br/>    begin<br/><br/>        (* Stack Snapshot here *)<br/><br/>    end;<br/><br/>    procedure B;<br/>    begin<br/><br/>        C;<br/><br/>    end;<br/><br/>    procedure A;<br/>    begin<br/><br/>        B;<br/><br/>    end;<br/><br/>begin (* Main program *)<br/><br/>    A;<br/><br/>end.</pre>&#13;
		<p class="indent"><a href="ch15.xhtml#ch15fig2">Figure 15-2</a> shows the stack layout as this program executes.</p>&#13;
		<p class="indent">When the program begins execution, it first creates an activation record for the main program. The main program calls the <span class="literal">A</span> procedure (<span class="ent">①</span>). Upon entry into the <span class="literal">A</span> procedure, the code completes the construction of the activation record for <span class="literal">A</span>, effectively pushing it onto the stack. Once inside procedure <span class="literal">A</span>, the code calls procedure <span class="literal">B</span> (<span class="ent">②</span>). Note that <span class="literal">A</span> is still active while the code calls <span class="literal">B</span>, so <span class="literal">A</span>’s activation record remains on the stack. Upon entry into <span class="literal">B</span>, the system builds <span class="literal">B</span>’s activation record and pushes it onto the top of the stack (<span class="ent">③</span>). Once inside <span class="literal">B</span>, the code calls procedure <span class="literal">C</span>, and <span class="literal">C</span> builds its activation record on the stack and arrives at the comment <span class="literal">(* Stack snapshot here *)</span> (<span class="ent">④</span>).</p>&#13;
		<div class="image" id="ch15fig2">&#13;
			<span epub:type="pagebreak" id="page_564"/>&#13;
			<img alt="Image" src="../images/15fig02.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 15-2: Stack layout after three nested procedure calls</em></p>&#13;
		<p class="indent">Because procedures keep their local variables and parameter values in their activation record, the lifetime of these variables extends from the point the system first creates the activation record until the system deallocates it when the procedure returns to its caller. In <a href="ch15.xhtml#ch15fig2">Figure 15-2</a>, notice that <span class="literal">A</span>’s activation record remains on the stack during the execution of the <span class="literal">B</span> and <span class="literal">C</span> procedures. Therefore, the lifetime of <span class="literal">A</span>’s parameters and local variables completely brackets the lifetimes of <span class="literal">B</span>’s and <span class="literal">C</span>’s activation records.</p>&#13;
		<p class="indent">Now consider the following C/C++ code with a recursive function:</p>&#13;
		<pre class="programs">&#13;
			void recursive( int cnt )<br/>{<br/>    if( cnt != 0 )<br/>    {<br/>        recursive( cnt - 1 );<br/>    }<br/>}<br/><br/>int main( int argc, char **argv )<br/>{<br/>    recursive( 2 );<br/>}</pre>&#13;
		<p class="indent">This program calls the <span class="literal">recursive()</span> function three times before it begins returning (the main program calls <span class="literal">recursive()</span> once with the parameter value <span class="literal">2</span>, and <span class="literal">recursive()</span> calls itself twice with the parameter values <span class="literal">1</span> and <span class="literal">0</span>). Because each recursive call to <span class="literal">recursive()</span> pushes another activation record before the current call returns, when this program finally hits the <span class="literal">if</span> statement in this code with <span class="literal">cnt</span> equal to <span class="literal">0</span>, the stack looks something like <a href="ch15.xhtml#ch15fig3">Figure 15-3</a>.</p>&#13;
		<div class="image" id="ch15fig3">&#13;
			<span epub:type="pagebreak" id="page_565"/>&#13;
			<img alt="Image" src="../images/15fig03.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 15-3: Stack layout after three recursive procedure calls</em></p>&#13;
		<p class="indent">Because each procedure invocation has a separate activation record, each activation of the procedure will have its own copy of the parameters and local variables. While the code for a procedure or function is executing, it will access only those local variables and parameters in the activation record it has most recently created,<sup><a id="ch15fn_3"/><a href="footnotes.xhtml#ch15fn3">3</a></sup> thereby preserving the values from previous calls.</p>&#13;
		<h4 class="h4" id="ch00lev2sec184"><strong>15.5.1 Breaking Down the Activation Record</strong></h4>&#13;
		<p class="noindent">Now that you’ve seen how procedures manipulate activation records on the stack, it’s time to take a look at the internal composition of a typical activation record. In this section we’ll use a typical activation record layout that you’ll see when executing code on an 80x86. Although different languages, different compilers, and different CPUs lay out the activation record differently, these differences, if they exist at all, will be minor.</p>&#13;
		<p class="indent">The 80x86 maintains the stack and activation records using two registers: ESP/RSP (the stack pointer) and EBP/RBP (the frame pointer, which Intel calls the <em>base pointer</em>). The ESP/RSP register points at the current top of stack, and the EBP register points at the base address of an activation record.<sup><a id="ch15fn_4"/><a href="footnotes.xhtml#ch15fn4">4</a></sup> A procedure can access objects within its activation record by using the indexed addressing mode (see “Indexed Addressing Mode” on <a href="ch03.xhtml#page_34">page 34</a>) and supplying a positive or negative offset from the value in the EBP/RBP register. Generally, a procedure allocates memory storage for <span epub:type="pagebreak" id="page_566"/>local variables at negative offsets from EBP/RBP’s value, and for parameters at positive offsets from EBP/RBP. Consider the following Pascal procedure, which has both parameters and local variables:</p>&#13;
		<pre class="programs">&#13;
			procedure HasBoth( i:integer; j:integer; k:integer );<br/>var<br/>    a  :integer;<br/>    r  :integer;<br/>    c  :char;<br/>    b  :char;<br/>    w  :smallint;  (* smallints are 16 bits *)<br/>begin<br/>        .<br/>        .<br/>        .<br/>end;</pre>&#13;
		<p class="indent"><a href="ch15.xhtml#ch15fig4">Figure 15-4</a> shows a typical activation record for this Pascal procedure (remember that the stack grows toward lower memory on the 32-bit 80x86).</p>&#13;
		<div class="image" id="ch15fig4">&#13;
			<img alt="Image" src="../images/15fig04.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 15-4: A typical activation record</em></p>&#13;
		<p class="indent">When you see the term <em>base</em> associated with a memory object, you might think that the base address is the lowest address of that object in memory. However, there’s no such requirement. The base address is simply the address in memory on which you base the offsets to particular fields of that object. As this activation record demonstrates, 80x86 activation record base addresses are actually in the middle of the record.</p>&#13;
		<p class="indent">The activation record is constructed in two phases. The first phase begins when the code calling the procedure pushes the parameters for the call onto the stack. For example, consider the following call to <span class="literal">HasBoth()</span> in the previous example:</p>&#13;
		<pre class="programs">HasBoth( 5, x, y + 2 );</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_567"/>Here’s the HLA/x86 assembly code that might correspond to this call:</p>&#13;
		<pre class="programs">&#13;
			pushd( 5 );<br/>push( x );<br/>mov( y, eax );<br/>add( 2, eax );<br/>push( eax );<br/>call HasBoth;</pre>&#13;
		<p class="indent">The three <span class="literal">push</span> instructions in this code sequence build the first three double words of the activation record, and the <span class="literal">call</span> instruction pushes a <em>return address</em> onto the stack, creating the fourth double word in the activation record. After the call, execution continues in the <span class="literal">HasBoth()</span> procedure itself, where the program continues to build the activation record.</p>&#13;
		<p class="indent">The first few instructions of the <span class="literal">HasBoth()</span> procedure are responsible for finishing the construction of the activation record. Immediately upon entry into <span class="literal">HasBoth()</span>, the stack takes the form shown in <a href="ch15.xhtml#ch15fig5">Figure 15-5</a>.<sup><a id="ch15fn_5"/><a href="footnotes.xhtml#ch15fn5">5</a></sup></p>&#13;
		<div class="image" id="ch15fig5">&#13;
			<img alt="Image" src="../images/15fig05.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 15-5: Activation record upon entry to <span class="codeitalic">HasBoth()</span></em></p>&#13;
		<p class="indent">The first thing the procedure’s code should do is to preserve the value in the 80x86 EBP register. On entry, EBP probably points at the base address of the caller’s activation record. On exit from <span class="literal">HasBoth()</span>, EBP needs to contain its original value. Therefore, upon entry, <span class="literal">HasBoth()</span> needs to push the current value of EBP on the stack in order to preserve EBP’s value. Next, the <span class="literal">HasBoth()</span> procedure needs to change EBP so that it points at the base address of the <span class="literal">HasBoth()</span> activation record. The following HLA/x86 code takes care of these two operations:</p>&#13;
		<pre class="programs">&#13;
			// Preserve caller's base address.<br/><br/>        push( ebp );<br/><br/>        // ESP points at the value we just saved. Use its address<br/>        // as the activation record's base address.<br/><br/>        mov( esp, ebp );</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_568"/>Finally, the code at the beginning of <span class="literal">HasBoth()</span> needs to allocate storage for its local (automatic) variables. As you saw in <a href="ch15.xhtml#ch15fig4">Figure 15-4</a>, those variables sit below the frame pointer in the activation record. To prevent future pushes from wiping out the values in those local variables, the code has to set ESP to the address of the last double word of local variables in the activation record. To accomplish this, it simply subtracts the number of bytes of local variables from ESP via the following machine instruction:</p>&#13;
		<pre class="programs">sub( 12, esp );</pre>&#13;
		<p class="indent">The <em>standard entry sequence</em> for a procedure like <span class="literal">HasBoth()</span> consists of the three machine instructions just considered—<span class="literal">push(ebp);</span>, <span class="literal">mov(esp, ebp);</span>, and <span class="literal">sub(12, esp);</span>—which complete the construction of the activation record inside the procedure. Just before returning, the Pascal procedure is responsible for deallocating the storage associated with the activation record. The <em>standard exit sequence</em> usually takes the following form (in HLA) for a Pascal procedure:</p>&#13;
		<pre class="programs">&#13;
			// Deallocates the local variables<br/>// by copying EBP to ESP.<br/><br/>mov( ebp, esp );<br/><br/>// Restore original EBP value.<br/><br/>pop( ebp );<br/><br/>// Pops return address and<br/>//  12 parameter bytes (3 dwords)<br/><br/>ret( 12 );</pre>&#13;
		<p class="indent">The first instruction deallocates storage for the local variables shown in <a href="ch15.xhtml#ch15fig4">Figure 15-4</a>. Note that EBP is pointing at the old value of EBP; this value is stored at the memory address just above all the local variables. By copying the value in EBP to ESP, we move the stack pointer past all the local variables, effectively deallocating them. Now, the stack pointer points at the old value of EBP on the stack; therefore, the <span class="literal">pop</span> instruction in this sequence restores EBP’s original value and leaves ESP pointing at the return address on the stack. The <span class="literal">ret</span> instruction in the standard exit sequence does two things: it pops the return address from the stack (and, of course, transfers control to this address), and it removes 12 bytes of parameters from the stack. Because <span class="literal">HasBoth()</span> has three double-word parameters, popping 12 bytes from the stack removes those parameters.</p>&#13;
		<h4 class="h4" id="ch00lev2sec185"><strong>15.5.2 Assigning Offsets to Local Variables</strong></h4>&#13;
		<p class="noindent">This <span class="literal">HasBoth()</span> example allocates local (automatic) variables in the order the compiler encounters them. A typical compiler maintains a <em>current offset</em> (the initial value of which will be 0) into the activation record for local variables. <span epub:type="pagebreak" id="page_569"/>Whenever the compiler encounters a local variable, it subtracts the variable’s size from the current offset and then uses the result as the offset of the local variable (from EBP/RBP) in the activation record. For example, upon encountering the declaration for variable <span class="literal">a</span>, the compiler subtracts the size of <span class="literal">a</span> (4 bytes, assuming <span class="literal">a</span> is a 32-bit integer) from the current offset (0) and uses the result (–4) as the offset for <span class="literal">a</span>. Next, the compiler encounters variable <span class="literal">r</span> (which is also 4 bytes), sets the current offset to –8, and assigns this offset to <span class="literal">r</span>. This process repeats for each of the local variables in the procedure.</p>&#13;
		<p class="indent">Although this is a typical way that compilers assign offsets to local variables, most languages give compiler implementers free rein to allocate local objects as they see fit. A compiler can rearrange the objects in the activation record if doing so is more convenient. This means you should avoid designing algorithms that depend on the previously mentioned allocation scheme, because some compilers do it differently.</p>&#13;
		<p class="indent">Many compilers try to ensure that all local variables you declare have an offset that is a multiple of the object’s size. For example, suppose you have the following two declarations in a C function:</p>&#13;
		<pre class="programs">&#13;
			char c;<br/>int  i;</pre>&#13;
		<p class="indent">Normally, you’d expect that the compiler would attach an offset like –1 to the <span class="literal">c</span> variable and –5 to the (4-byte) <span class="literal">int</span> variable <span class="literal">i</span>. However, some CPUs (such as RISC CPUs) require the compiler to allocate double-word objects on a double-word boundary. Even on CPUs that don’t require this (for example, the 80x86), it may be faster to access a double-word variable if the compiler aligns it on a double-word boundary. For this reason (and as previous chapters have described), many compilers automatically add padding bytes between local variables so that each variable resides at a <em>natural</em> offset in the activation record. In general, bytes may appear at any offset, words are happiest on even address boundaries, and double words should have a memory address that is a multiple of 4.</p>&#13;
		<p class="indent">Although an optimizing compiler might automatically handle this alignment for you, that comes with a cost—those extra padding bytes. As explained earlier, compilers are usually free to rearrange the variables in an activation record, but they don’t always do so. Therefore, if you intertwine the definitions for several byte, word, double-word, and other-sized objects in your local variable declarations, the compiler may wind up inserting several bytes of padding into the activation record. You can minimize this problem by attempting to group as many like-sized objects together as is reasonable in your procedures and functions. Consider the following C/C++ code on a 32-bit machine:</p>&#13;
		<pre class="programs">&#13;
			char c0;<br/>int  i0;<br/>char c1;<br/>int  i1;<br/>char c2;<br/><span epub:type="pagebreak" id="page_570"/>int  i2;<br/>char c3;<br/>int  i3;</pre>&#13;
		<p class="indent">An optimizing compiler may elect to insert 3 bytes of padding between each of these character variables and the (4-byte) integer variable that immediately follows. This means that the preceding code will have about 12 bytes of wasted space (3 bytes for each of the character variables). Now consider the following declarations in the same C code:</p>&#13;
		<pre class="programs">&#13;
			char c0;<br/>char c1;<br/>char c2;<br/>char c3;<br/>int  i0;<br/>int  i1;<br/>int  i2;<br/>int  i3;</pre>&#13;
		<p class="indent">In this example, the compiler won’t emit any extra padding bytes to the code. Why? Because characters (being 1 byte each) may begin at any address in memory.<sup><a id="ch15fn_6"/><a href="footnotes.xhtml#ch15fn6">6</a></sup> Therefore, the compiler can place these character variables at offsets –1, –2, –3, and –4 within the activation record. Because the last character variable appears at an address that is a multiple of 4, the compiler doesn’t need to insert any padding bytes between <span class="literal">c3</span> and <span class="literal">i0</span> (<span class="literal">i0</span> will naturally appear at offset –8 in the preceding declarations).</p>&#13;
		<p class="indent">As you can see, arranging your declarations so that all like-sized objects are next to one another can help your compiler produce better code. Don’t take this suggestion to an extreme, though. If a rearrangement would make your program more difficult to read or maintain, you should carefully consider whether it’s worthwhile in your program.</p>&#13;
		<h4 class="h4" id="ch00lev2sec186"><strong>15.5.3 Associating Offsets with Parameters</strong></h4>&#13;
		<p class="noindent">As noted, compilers are given considerable leeway with respect to how they assign offsets to local (automatic) variables within a procedure. As long as the compiler uses these offsets consistently, the exact allocation algorithm it applies is almost irrelevant; in fact, it could use a different allocation scheme in different procedures of the same program. However, a compiler <em>doesn’t</em> have free rein when assigning offsets to parameters. It has to live with certain restrictions, because other code outside the procedure accesses those parameters. Specifically, the procedure and the calling code must agree on the layout of the parameters in the activation record so the calling code can build the parameter list. Note that the calling code might not be in the same source file, or even in the same programming language, as the procedure. To ensure interoperability between a procedure and whatever <span epub:type="pagebreak" id="page_571"/>code calls that procedure, then, compilers must adhere to certain <em>calling conventions</em>. This section will explore the three common calling conventions for Pascal/Delphi and C/C++.</p>&#13;
		<h5 class="h5" id="ch00lev3sec83"><strong>15.5.3.1 The Pascal Calling Convention</strong></h5>&#13;
		<p class="noindent">In Pascal (including Delphi) the standard parameter-passing convention is to push the parameters on the stack in the order of their appearance in the parameter list. Consider the following call to the <span class="literal">HasBoth()</span> procedure from the earlier example:</p>&#13;
		<pre class="programs">HasBoth( 5, x, y + 2 );</pre>&#13;
		<p class="indent">The following assembly code implements this call:</p>&#13;
		<pre class="programs">&#13;
			// Push the value for parameter i:<br/><br/>pushd( 5 );<br/><br/>// Push x's value for parameter j:<br/><br/>push( x );<br/><br/>// Compute y + 2 in EAX and push this as the value<br/>// for parameter k:<br/><br/>mov( y, eax );<br/>add( 2, eax );<br/>push( eax );<br/><br/>// Call the HasBoth procedure with these<br/>// three parameter values:<br/><br/>call HasBoth;</pre>&#13;
		<p class="indent">When assigning offsets to a procedure’s formal parameters, the compiler assigns the highest offset to the first parameter and the lowest offset to the last parameter. Because the old value of EBP is at offset 0 in the activation record and the return address is at offset 4, the last parameter in the activation record (when using the Pascal calling convention on the 80x86 CPU) will reside at offset 8 from EBP. Looking back at <a href="ch15.xhtml#ch15fig4">Figure 15-4</a>, you can see that parameter <span class="literal">k</span> is at offset +8, parameter <span class="literal">j</span> is at offset +12, and parameter <span class="literal">i</span> (the first parameter) is at offset +16 in the activation record.</p>&#13;
		<p class="indent">The Pascal calling convention also stipulates that it is the procedure’s responsibility to remove the parameters the caller pushes when the procedure returns to its caller. As you saw earlier, the 80x86 CPU provides a variant of the <span class="literal">ret</span> instruction that lets you specify how many bytes of parameters to remove from the stack upon return. Therefore, a procedure that uses the Pascal calling convention will typically supply the number of parameter bytes as an operand to the <span class="literal">ret</span> instruction when returning to its caller.</p>&#13;
		<h5 class="h5" id="ch00lev3sec84"><span epub:type="pagebreak" id="page_572"/><strong>15.5.3.2 The C Calling Convention</strong></h5>&#13;
		<p class="noindent">The C/C++/Java languages employ another very popular calling convention, generally known as the <em>cdecl calling convention</em> (or, simply, the <em>C calling convention</em>). There are two major differences between the C and Pascal calling conventions. First, calls to functions in C must push their parameters on the stack in the reverse order. That is, the first parameter must appear at the lowest address on the stack (assuming the stack grows downward), and the last parameter must appear at the highest address in memory. The second difference is that C requires the caller, rather than the function, to remove all parameters from the stack.</p>&#13;
		<p class="indent">Consider the following version of <span class="literal">HasBoth()</span> written in C instead of Pascal:</p>&#13;
		<pre class="programs">&#13;
			void HasBoth( int i, int j, int k )<br/>{<br/>    int a;<br/>    int r;<br/>    char c;<br/>    char b;<br/>    short w;  /* assumption: short ints are 16 bits */<br/>        .<br/>        .<br/>        .<br/>}</pre>&#13;
		<p class="indent"><a href="ch15.xhtml#ch15fig6">Figure 15-6</a> provides the layout for a typical <span class="literal">HasBoth</span> activation record (written in C on a 32-bit 80x86 processor).</p>&#13;
		<div class="image" id="ch15fig6">&#13;
			<img alt="Image" src="../images/15fig06.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 15-6: <span class="codeitalic">HasBoth()</span> activation record in C</em></p>&#13;
		<p class="indent">Looking closely, you’ll see the difference between this figure and <a href="ch15.xhtml#ch15fig4">Figure 15-4</a>. The positions of the <span class="literal">i</span> and <span class="literal">k</span> variables are reversed in this activation record (it’s only a coincidence that <span class="literal">j</span> appears at the same offset in both).</p>&#13;
		<p class="indent">Because the C calling convention reverses the order of the parameters and it’s the caller’s responsibility to remove all parameter values from the <span epub:type="pagebreak" id="page_573"/>stack, the calling sequence for <span class="literal">HasBoth()</span> is a little different in C than in Pascal. Consider the following call to <span class="literal">HasBoth()</span>:</p>&#13;
		<pre class="programs">HasBoth( 5, x, y + 2 );</pre>&#13;
		<p class="indent">Here’s the HLA assembly code for this call:</p>&#13;
		<pre class="programs">&#13;
			// Compute y + 2 in EAX and push this<br/>// as the value for parameter k<br/><br/>mov( y, eax );<br/>add( 2, eax );<br/>push( eax );<br/><br/>// Push x's value for parameter j<br/><br/>push( x );<br/><br/>// Push the value for parameter i<br/><br/>pushd( 5 );<br/><br/>// Call the HasBoth procedure with<br/>// these three parameter values<br/><br/>call HasBoth;<br/><br/>// Remove parameters from the stack.<br/><br/>add( 12, esp );</pre>&#13;
		<p class="indent">As a result of using the C calling convention, this code differs in two ways from the assembly code for the Pascal implementation. First, this example pushes the values of the actual parameters in the opposite order of the Pascal code; that is, it first computes <span class="literal">y+2</span> and pushes that value, then it pushes <span class="literal">x</span>, and finally it pushes the value <span class="literal">5</span>. The second difference is the inclusion of the <span class="literal">add(12,esp);</span> instruction immediately after the call. This instruction removes 12 bytes of parameters from the stack upon return. The return from <span class="literal">HasBoth()</span> will use only the <span class="literal">ret</span> instruction, not the <span class="literal">ret n</span> instruction.</p>&#13;
		<h5 class="h5" id="ch00lev3sec85"><strong>15.5.3.3 Conventions for Passing Parameters in Registers</strong></h5>&#13;
		<p class="noindent">As you’ve seen in these examples, passing parameters on the stack between two procedures or functions requires a fair amount of code. Good assembly language programmers have long known that it’s better to pass parameters in registers. Therefore, several 80x86 compilers following Intel’s ABI (application binary interface) rules may attempt to pass as many as three parameters in the EAX, EDX, and ECX registers.<sup><a id="ch15fn_7"/><a href="footnotes.xhtml#ch15fn7">7</a></sup> Most RISC processors <span epub:type="pagebreak" id="page_574"/>specifically set aside a set of registers for passing parameters between functions and procedures. See “Registers to the Rescue” on <a href="ch15.xhtml#page_585">page 585</a> for more information.</p>&#13;
		<p class="indent">Most CPUs require that the stack pointer remain aligned on some reasonable boundary (for example, a double-word boundary), and CPUs that don’t absolutely require this may still benefit from it. Furthermore, many CPUs (the 80x86 included) can’t easily push certain small-sized objects, like bytes, onto the stack. Therefore, most compilers reserve a minimum number of bytes for a parameter (typically 4), regardless of its actual size. As an example, consider the following HLA procedure fragment:</p>&#13;
		<pre class="programs">&#13;
			procedure OneByteParm( b:byte ); @nodisplay;<br/>    // local variable declarations<br/>begin OneByteParm;<br/>    .<br/>    .<br/>    .<br/>end OneByteParm;</pre>&#13;
		<p class="indent">The activation record for this procedure appears in <a href="ch15.xhtml#ch15fig7">Figure 15-7</a>.</p>&#13;
		<div class="image" id="ch15fig7">&#13;
			<img alt="Image" src="../images/15fig07.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 15-7: <span class="codeitalic">OneByteParm()</span> activation record</em></p>&#13;
		<p class="indent">As you can see, the HLA compiler reserves 4 bytes for the <span class="literal">b</span> parameter even though <span class="literal">b</span> is only a single-byte variable. This extra padding ensures that the ESP register will remain aligned on a double-word boundary.<sup><a id="ch15fn_8"/><a href="footnotes.xhtml#ch15fn8">8</a></sup> We can easily push the value of <span class="literal">b</span> onto the stack in the code that calls <span class="literal">OneByteParm()</span> using a 4-byte <span class="literal">push</span> instruction.<sup><a id="ch15fn_9"/><a href="footnotes.xhtml#ch15fn9">9</a></sup></p>&#13;
		<p class="indent">Even if your program could access the extra bytes of padding associated with the <span class="literal">b</span> parameter, doing so is never a good idea. Unless you’ve explicitly pushed the parameter onto the stack (for example, using assembly <span epub:type="pagebreak" id="page_575"/>language code), there’s no guarantee about the data values that appear in the padding bytes. In particular, they may not contain 0. Nor should your code assume that the padding is present or that the compiler pads such variables out to 4 bytes. Some 16-bit processors may require only a single byte of padding. Some 64-bit processors may require 7 bytes of padding. Some compilers on the 80x86 may use 1 byte of padding, while others use 3 bytes. Unless you’re willing to live with code that only one compiler can compile (and code that could break when the next version of the compiler comes along), it’s best to ignore these padding bytes.</p>&#13;
		<h4 class="h4" id="ch00lev2sec187"><strong>15.5.4 Accessing Parameters and Local Variables</strong></h4>&#13;
		<p class="noindent">Once a subroutine sets up the activation record, accessing local (automatic) variables and parameters is easy. The machine code simply uses the indexed addressing mode to access such objects. Consider again the activation record in <a href="ch15.xhtml#ch15fig4">Figure 15-4</a>. The variables in the <span class="literal">HasBoth()</span> procedure have the offsets found in <a href="ch15.xhtml#ch15tab1">Table 15-1</a>.</p>&#13;
		<p class="tabcap" id="ch15tab1"><strong>Table 15-1:</strong> Offsets to Local Variables and Parameters in <span class="literal">HasBoth()</span> (Pascal Version)</p>&#13;
		<table class="all">&#13;
			<colgroup>&#13;
				<col style="width:25%"/>&#13;
				<col style="width:25%"/>&#13;
				<col style="width:50%"/>&#13;
			</colgroup>&#13;
			<tbody>&#13;
				<tr>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>Variable</strong></p>&#13;
					</td>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>Offset</strong></p>&#13;
					</td>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>Addressing mode example</strong></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">i</span></p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">+16</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">mov( [ebp+16], eax );</span></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">j</span></p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">+12</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">mov( [ebp+12], eax );</span></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">k</span></p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">+8</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">mov( [ebp+8], eax );</span></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">a</span></p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">–4</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">mov( [ebp-4], eax );</span></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">r</span></p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">–8</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">mov( [ebp-8], eax );</span></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">c</span></p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">–9</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">mov( [ebp-9], al );</span></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">b</span></p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">–10</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">mov( [ebp-10], al );</span></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">w</span></p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">–12</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><span class="literal">mov( [ebp-12], ax );</span></p>&#13;
					</td>&#13;
				</tr>&#13;
			</tbody>&#13;
		</table>&#13;
		<p class="indent">The compiler allocates static local variables in a procedure at a fixed address in memory. Static variables do not appear in the activation record, so the CPU accesses static objects using the direct addressing mode.<sup><a id="ch15fn_10"/><a href="footnotes.xhtml#ch15fn10">10</a></sup> As <a href="ch03.xhtml#ch03">Chapter 3</a> discussed, in 80x86 assembly language instructions that use the direct addressing mode need to encode the full 32-bit address as part of the machine instruction. Therefore, instructions that use the direct addressing mode are usually at least 5 bytes long (and often longer). On the 80x86, if the offset from EBP is –128 through +127, then a compiler can encode an instruction of the form <span class="literal">[ebp + <span class="codeitalic1">constant</span>]</span> in as few as 2 or 3 bytes. Such instructions will be more efficient than those that encode a full 32-bit address. The same principle applies on other processors, even if those CPUs provide different addressing modes, address sizes, and so on. Specifically, <span epub:type="pagebreak" id="page_576"/>accessing local variables whose offset is relatively small is generally more efficient than accessing static variables or variables with larger offsets.</p>&#13;
		<p class="indent">Because most compilers allocate offsets for local (automatic) variables as the compiler encounters them, the first 128 bytes of local variables will be the ones with the shortest offsets (at least, on the 80x86; this value may be different for other processors).</p>&#13;
		<p class="indent">Consider the following two sets of local variable declarations (presumably appearing with some C function):</p>&#13;
		<pre class="programs">&#13;
			// Declaration set #1:<br/><br/>char string[256];<br/>int i;<br/>int j;<br/>char c;</pre>&#13;
		<p class="indent">Here’s a second version of these declarations:</p>&#13;
		<pre class="programs">&#13;
			// Declaration set #2<br/><br/>int i;<br/>int j;<br/>char c;<br/>char string[256];</pre>&#13;
		<p class="indent">Although these two declaration sections are semantically identical, there is a big difference in the code a compiler for the 32-bit 80x86 generates to access these variables. In the first declaration, the variable <span class="literal">string</span> appears at offset –256 within the activation record, <span class="literal">i</span> appears at offset –260, <span class="literal">j</span> appears at offset –264, and <span class="literal">c</span> appears at offset –265. Because these offsets are outside the range –128 through +127, the compiler will have to emit machine instructions that encode a 4-byte offset constant rather than a 1-byte constant. Accordingly, the code associated with these declarations will be larger and may run slower.</p>&#13;
		<p class="indent">Now consider the second declaration. In this example the programmer declares the scalar (non-array) objects first. Therefore, the variables have the following offsets: <span class="literal">i</span> at –4, <span class="literal">j</span> at –8, <span class="literal">c</span> at –9, and <span class="literal">string</span> at –265. This turns out to be the optimal configuration for these variables (<span class="literal">i</span>, <span class="literal">j</span>, and <span class="literal">c</span> will use 1-byte offsets; <span class="literal">string</span> will require a 4-byte offset).</p>&#13;
		<p class="indent">This example demonstrates another rule you should try to follow when declaring local (automatic) variables: declare smaller, scalar objects first within a procedure, followed by all the arrays, structures/records, and other large objects.</p>&#13;
		<p class="indent">As explained in “Associating Offsets with Parameters” on <a href="ch15.xhtml#page_570">page 570</a>, if you declare several local objects with differing sizes adjacent to one another, the compiler may need to insert padding bytes to keep the larger objects aligned at an appropriate memory address. While worrying about a few wasted bytes here and there may seem ridiculous on machines with a gigabyte (or more) of RAM, those few padding bytes could be just enough <span epub:type="pagebreak" id="page_577"/>to push the offsets of certain local variables beyond –128, causing the compiler to emit 4-byte offsets rather than 1-byte offsets for those variables. This is one more reason you should try to declare like-sized local variables adjacent to one another.</p>&#13;
		<p class="indent">On RISC processors, such as the PowerPC or ARM, the range of possible offsets is usually much greater than ±128. This is a good thing, because once you exceed the range of the activation record offset that a RISC CPU can encode directly into an instruction, parameter and local variable access gets very expensive. Consider the following C program:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/>int main( int argc, char **argv )<br/>{<br/>    int a;<br/>    int b[256];<br/>    int c;<br/>    int d[16*1024*1024];<br/>    int e;<br/>    int f;<br/><br/>    a = argc;<br/>    b[0] = argc + argc;<br/>    b[255] = a + b[0];<br/>    c = argc + b[1];<br/>    d[0] = argc + a;<br/>    d[4095] = argc + b[255];<br/>    e = a + c;<br/>    printf<br/>    (<br/>        "%d %d %d %d %d ",<br/>        a,<br/>        b[0],<br/>        c,<br/>        d[0],<br/>        e<br/>    );<br/>    return( 0 );<br/>}</pre>&#13;
		<p class="indent">Here’s the PowerPC assembly output from GCC:</p>&#13;
		<pre class="programs">&#13;
			.data<br/>        .cstring<br/>        .align 2<br/>        LC0:<br/>        .ascii "%d %d %d %d %d \0"<br/>        .text<br/><br/>; main function:<br/><br/>        .align 2<br/>        .globl _main<br/><span epub:type="pagebreak" id="page_578"/>_main:<br/>        ; Set up main's activation record:<br/><br/>        mflr r0<br/>        stmw r30,-8(r1)<br/>        stw r0,8(r1)<br/>        lis r0,0xfbff<br/>        ori r0,r0,64384<br/>        stwux r1,r1,r0<br/>        mr r30,r1<br/>        bcl 20,31,L1$pb<br/>L1$pb:<br/>        mflr r31<br/><br/>        ; The following allocates<br/>        ; 16MB of storage on the<br/>        ; stack (R30 is the stack<br/>        ; pointer here).<br/><br/>        addis r9,r30,0x400<br/>        stw r3,1176(r9)<br/><br/>        ; Fetch the value of argc<br/>        ; into the R0 register:<br/><br/>        addis r11,r30,0x400<br/>        lwz r0,1176(r11)<br/>        stw r0,64(r30)      ; a = argc<br/><br/>        ; Fetch the value of argc<br/>        ; into r9<br/><br/>        addis r11,r30,0x400<br/>        lwz r9,1176(r11)<br/><br/>        ; Fetch the value of argc<br/>        ; into R0:<br/><br/>        addis r11,r30,0x400<br/>        lwz r0,1176(r11)<br/><br/>        ; Compute argc + argc and<br/>        ; store it into b[0]:<br/><br/>        add r0,r9,r0<br/>        stw r0,80(r30)<br/><br/>        ; Add a + b[0] and<br/>        ; store into c:<br/><br/>        lwz r9,64(r30)<br/>        lwz r0,80(r30)<br/>        add r0,r9,r0<br/>        stw r0,1100(r30)<br/><span epub:type="pagebreak" id="page_579"/>        ; Get argc's value, add in<br/>        ; b[1], and store into c:<br/><br/>        addis r11,r30,0x400<br/>        lwz r9,1176(r11)<br/>        lwz r0,84(r30)<br/>        add r0,r9,r0<br/>        stw r0,1104(r30)<br/><br/>        ; Compute argc + a and<br/>        ; store into d[0]:<br/><br/>        addis r11,r30,0x400<br/>        lwz r9,1176(r11)<br/>        lwz r0,64(r30)<br/>        add r0,r9,r0<br/>        stw r0,1120(r30)<br/><br/>        ; Compute argc + b[255] and<br/>        ; store into d[4095]:<br/><br/>        addis r11,r30,0x400<br/>        lwz r9,1176(r11)<br/>        lwz r0,1100(r30)<br/>        add r0,r9,r0<br/>        stw r0,17500(r30)<br/><br/>        ; Compute argc + b[255]:<br/><br/>        lwz r9,64(r30)<br/>        lwz r0,1104(r30)<br/>        add r9,r9,r0<br/><br/>; ************************************************<br/>        ; Okay, here's where it starts<br/>        ; to get ugly. We need to compute<br/>        ; the address of e so we can store<br/>        ; the result currently held in r9<br/>        ; into e. But e's offset exceeds<br/>        ; what we can encode into a single<br/>        ; instruction, so we have to use<br/>        ; the following sequence rather<br/>        ; than a single instruction.<br/><br/>        lis r0,0x400<br/>        ori r0,r0,1120<br/>        stwx r9,r30,r0<br/><br/>; ************************************************<br/>        ; The following sets up the<br/>        ; call to printf and calls printf:<br/><br/>        addis r3,r31,ha16(LC0-L1$pb)<br/>        la r3,lo16(LC0-L1$pb)(r3)<br/>        lwz r4,64(r30)<br/><span epub:type="pagebreak" id="page_580"/>        lwz r5,80(r30)<br/>        lwz r6,1104(r30)<br/>        lwz r7,1120(r30)<br/>        lis r0,0x400<br/>        ori r0,r0,1120<br/>        lwzx r8,r30,r0<br/>        bl L_printf$stub<br/>        li r0,0<br/>        mr r3,r0<br/>        lwz r1,0(r1)<br/>        lwz r0,8(r1)<br/>        mtlr r0<br/>        lmw r30,-8(r1)<br/>        blr<br/><br/><br/>; Stub, to call the external printf function:<br/><br/>        .data<br/>        .picsymbol_stub<br/>L_printf$stub:<br/>        .indirect_symbol _printf<br/>        mflr r0<br/>        bcl 20,31,L0$_printf<br/>L0$_printf:<br/>        mflr r11<br/>        addis r11,r11,ha16(L_printf$lazy_ptr-L0$_printf)<br/>        mtlr r0<br/>        lwz r12,lo16(L_printf$lazy_ptr-L0$_printf)(r11)<br/>        mtctr r12<br/>        addi r11,r11,lo16(L_printf$lazy_ptr-L0$_printf)<br/>        bctr<br/>.data<br/>.lazy_symbol_pointer<br/>L_printf$lazy_ptr:<br/>        .indirect_symbol _printf<br/>        .long dyld_stub_binding_helper</pre>&#13;
		<p class="indent">This compilation was done under GCC without optimization to show what happens when your activation record grows to the point you can no longer encode activation record offsets into the instruction.</p>&#13;
		<p class="indent">To encode the address of <span class="literal">e</span>, whose offset is too large, we need these three instructions:</p>&#13;
		<pre class="programs">&#13;
			lis r0,0x400<br/>ori r0,r0,1120<br/>stwx r9,r30,r0</pre>&#13;
		<p class="noindent">instead of a single instruction that stores <span class="literal">R0</span> into the <span class="literal">a</span> variable, such as:</p>&#13;
		<pre class="programs">stw r0,64(r30)      ; a = argc</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_581"/>While two extra instructions in a program of this size might seem insignificant, keep in mind that the compiler will generate these extra instructions for each such access. If you frequently access a local variable with a huge offset, the compiler may generate a significant number of extra instructions throughout your function or procedure.</p>&#13;
		<p class="indent">Of course, in a standard application running on a RISC, this problem seldom occurs because we rarely allocate local storage beyond the range that a single instruction can encode. Also, RISC compilers generally allocate scalar (non-array/non-structure) objects in registers rather than blindly allocating them at the next memory address in the activation record. For example, if you turn on GCC’s optimization with the <span class="literal">-O2</span> command-line switch, you’ll get the following PowerPC output:</p>&#13;
		<pre class="programs">&#13;
			.globl _main<br/>_main:<br/><br/>; Build main's activation record:<br/><br/>        mflr r0<br/>        stw r31,-4(r1)<br/>        stw r0,8(r1)<br/>        bcl 20,31,L1$pb<br/>L1$pb:<br/>        ; Compute values, set up parameters,<br/>        ; and call printf:<br/><br/>        lis r0,0xfbff<br/>        slwi r9,r3,1<br/>        ori r0,r0,64432<br/>        mflr r31<br/>        stwux r1,r1,r0<br/>        add r11,r3,r9<br/>        mr r4,r3<br/>        mr r0,r3<br/>        lwz r6,68(r1)<br/>        add r0,r0,r11 ;c = argc + b[1]<br/>        stw r0,17468(r1)<br/>        mr r5,r9<br/>        add r6,r3,r6<br/>        stw r9,64(r1)<br/>        addis r3,r31,ha16(LC0-L1$pb)<br/>        stw r11,1084(r1)<br/>        stw r9,1088(r1)<br/>        la r3,lo16(LC0-L1$pb)(r3)<br/>        mr r7,r9<br/>        add r8,r4,r6<br/>        bl L_printf$stub<br/><br/>; Clean up main's activation<br/>; record and return 0:<br/><br/>        lwz r1,0(r1)<br/>        li r3,0<br/><span epub:type="pagebreak" id="page_582"/>        lwz r0,8(r1)<br/>        lwz r31,-4(r1)<br/>        mtlr r0<br/>        blr</pre>&#13;
		<p class="indent">One thing that you’ll notice in this version with optimization enabled is that GCC did not allocate variables in the activation record as they were encountered. Instead, it placed most of the objects in registers (even array elements). Keep in mind that an optimizing compiler may very well rearrange all the local variables you declare.</p>&#13;
		<p class="indent">The ARM processor has similar limitations based on the size of the instruction opcode (32 bits). Here’s the (unoptimized) ARM output from GCC:</p>&#13;
		<pre class="programs">&#13;
			.LC0:<br/>    .ascii  "%d %d %d %d %d \000"<br/><br/>main:<br/><br/>    @ Set up activation record<br/><br/>    push    {fp, lr}<br/>    add fp, sp, #4<br/><br/>    @ Reserve storage for locals.<br/>    @ (2 instructions due to instruction<br/>    @ size limitations).<br/><br/>    add sp, sp, #-67108864<br/>    sub sp, sp, #1056<br/><br/>    @ Store argc (passed in R0)<br/>    @ into a. Three additions<br/>    @ (-67108864, 4, and -1044)<br/>    @ are needed because of ARM<br/>    @ 32-bit instruction encoding<br/>    @ limitations<br/><br/>    add r3, fp, #-67108864<br/>    sub r3, r3, #4<br/>    str r0, [r3, #-1044]<br/><br/>    @ a = argc<br/><br/>    add r3, fp, #-67108864<br/>    sub r3, r3, #4<br/>    ldr r3, [r3, #-1044]    @ r3 = argc<br/>    str r3, [fp, #-8]       @ a = argc<br/><br/>    @ b[0] = argc + argc<br/><br/>    add r3, fp, #-67108864<br/>    sub r3, r3, #4<br/>    ldr r2, [r3, #-1044]    @ R2 = argc<br/><span epub:type="pagebreak" id="page_583"/>    ldr r3, [r3, #-1044]    @ R3 = argc<br/>    add r3, r2, r3          @ R3 = argc + argc<br/>    str r3, [fp, #-1040]    @ b[0] = argc+argc<br/><br/>    ldr r2, [fp, #-1040]    @ R2 = b[0]<br/>    ldr r3, [fp, #-8]       @ R3 = a<br/>    add r3, r2, r3          @ a + b[0]<br/>    str r3, [fp, #-20]      @ b[255] = a  +b[0]<br/><br/>    ldr r2, [fp, #-1036]    @ R2 = b[1]<br/>    add r3, fp, #-67108864<br/>    sub r3, r3, #4<br/>    ldr r3, [r3, #-1044]    @ R3 = argc<br/>    add r3, r2, r3          @ argc + b[1]<br/>    str r3, [fp, #-12]      @ c = argc + b[1]<br/><br/>    add r3, fp, #-67108864<br/>    sub r3, r3, #4<br/>    ldr r2, [r3, #-1044]    @ R2 = argc<br/>    ldr r3, [fp, #-8]       @ R3 = a<br/>    add r3, r2, r3          @ R3 = argc + a<br/>    add r2, fp, #-67108864<br/>    sub r2, r2, #4<br/>    str r3, [r2, #-1036]    @ d[0] = argc + a<br/><br/>    ldr r2, [fp, #-20]      @ R2 = b[255]<br/>    add r3, fp, #-67108864<br/>    sub r3, r3, #4<br/>    ldr r3, [r3, #-1044]    @ R3 = argc<br/>    add r3, r2, r3          @ R3 = argc + b[255]<br/>    add r2, fp, #-67108864<br/>    sub r2, r2, #4<br/>    add r2, r2, #12288<br/>    str r3, [r2, #3056]     @ d[4095] = argc + b[255]<br/><br/>    ldr r2, [fp, #-8]       @ R2 = a<br/>    ldr r3, [fp, #-12]      @ R3 = c<br/>    add r3, r2, r3          @ R3 = a + c<br/>    str r3, [fp, #-16]      @ e = a + c<br/><br/>    @ printf function call:<br/><br/>    ldr r1, [fp, #-1040]<br/>    add r3, fp, #-67108864<br/>    sub r3, r3, #4<br/>    ldr r3, [r3, #-1036]<br/>    ldr r2, [fp, #-16]<br/>    str r2, [sp, #4]<br/>    str r3, [sp]<br/>    ldr r3, [fp, #-12]<br/>    mov r2, r1<br/>    ldr r1, [fp, #-8]<br/>    ldr r0, .L3<br/>    bl  printf<br/><span epub:type="pagebreak" id="page_584"/>    @ return to Linux from function<br/>    mov r3, #0<br/>    mov r0, r3<br/>    sub sp, fp, #4<br/><br/>    pop {fp, pc}<br/><br/>.L3:<br/>    .word   .LC0</pre>&#13;
		<p class="indent">While this is arguably better than the PowerPC code, there’s still considerable ugliness in the address computations because the ARM CPU cannot encode 32-bit constants as part of the instruction opcode. To understand why GCC emits such bizarre constants to compute offsets into the activation record, see the discussion of the ARM immediate operands in the section “The Immediate Addressing Mode” in Appendix C online.</p>&#13;
		<p class="indent">If you find the optimized PowerPC or ARM code a bit hard to follow, consider the following 80x86 GCC output for the same C program:</p>&#13;
		<pre class="programs">&#13;
			.file   "t.c"<br/>        .section        .rodata.str1.1,"aMS",@progbits,1<br/>.LC0:<br/>        .string "%d %d %d %d %d "<br/>        .text<br/>        .p2align 2,,3<br/>        .globl main<br/>        .type   main,@function<br/>main:<br/>        ; Build main's activation record:<br/><br/>        pushl   %ebp<br/>        movl    %esp, %ebp<br/>        pushl   %ebx<br/>        subl    $67109892, %esp<br/><br/>        ; Fetch ARGC into ECX:<br/><br/>        movl    8(%ebp), %ecx<br/><br/>        ; EDX = 2*argc:<br/><br/>        leal    (%ecx,%ecx), %edx<br/><br/>        ; EAX = a (ECX) + b[0] (EDX):<br/><br/>        leal    (%edx,%ecx), %eax<br/><br/>        ; c (ebx) = argc (ecx) + b[1]:<br/><br/>        movl    %ecx, %ebx<br/>        addl    -1028(%ebp), %ebx<br/>        movl    %eax, -12(%ebp)<br/><span epub:type="pagebreak" id="page_585"/><br/>        ; Align stack for printf call:<br/><br/>        andl    $-16, %esp<br/><br/>        ;d[0] (eax) = argc (ecx) + a (eax);<br/><br/>        leal    (%eax,%ecx), %eax<br/><br/>        ; Make room for printf parameters:<br/><br/>        subl    $8, %esp<br/>        movl    %eax, -67093516(%ebp)<br/><br/>        ; e = a + c<br/><br/>        leal    (%ebx,%ecx), %eax<br/><br/><br/>        pushl   %eax    ;e<br/>        pushl   %edx    ;d[0]<br/>        pushl   %ebx    ;c<br/>        pushl   %edx    ;b[0]<br/>        pushl   %ecx    ;a<br/>        pushl   $.LC0<br/>        movl    %edx, -1032(%ebp)<br/>        movl    %edx, -67109896(%ebp)<br/>        call    printf<br/>        xorl    %eax, %eax<br/>        movl    -4(%ebp), %ebx<br/>        leave<br/>        ret</pre>&#13;
		<p class="indent">Of course, the 80x86 doesn’t have as many registers to use for passing parameters and holding local variables, so the 80x86 code has to allocate more locals in the activation record. Also, the 80x86 provides an offset range of –128 to +127 bytes only around the EBP register, so a larger number of instructions have to use the 4-byte offset rather than the 1-byte offset. Fortunately, the 80x86 does allow you to encode a full 32-bit address as part of the instructions that access memory, so you don’t have to execute multiple instructions in order to access a variable stored a long distance away from where EBP points in the stack frame.</p>&#13;
		<h4 class="h4" id="ch00lev2sec188"><strong>15.5.5 Registers to the Rescue</strong></h4>&#13;
		<p class="noindent">As the examples in the previous section demonstrate, RISC code suffers greatly when it has to deal with parameters and local variables whose offsets are not easy to represent within the confines of the instruction opcode. In real code, however, the situation is not so dire. Compilers are smart enough to use machine registers to pass parameters and hold local variables providing immediate access to those values. This dramatically reduces the number of instructions in typical functions.</p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_586"/>Consider the (register-starved) 32-bit 80x86 CPU. As there are only eight general-purpose registers, two of which (ESP and EBP) have special purposes that limit their use, there aren’t a lot of registers available for passing parameters or holding local variables. Typical C compilers use EAX, ECX, and EDX to pass up to three parameters to a function. Functions return their result in the EAX register. The function must preserve the values of any other registers (EBX, ESI, EDI, and EBP) it uses. It’s fortunate that memory access to local variables and parameters inside the function is very efficient—given the limited register set, the 32-bit 80x86 will need to use memory often for this purpose.</p>&#13;
		<p class="indent">For most applications, the largest architectural improvement to the 64-bit x86-64 over the 32-bit 80x86 was not 64-bit registers (or even addresses), but that the x86-64 added eight new general-purpose registers and eight new XMM registers that compilers could use for passing parameters and holding local variables. The Intel/AMD ABI for the x86-64 allows a compiler to pass up to six different arguments in registers to a function (without the caller explicitly saving those register values before using them). <a href="ch15.xhtml#ch15tab2">Table 15-2</a> lists the available registers.</p>&#13;
		<p class="tabcap" id="ch15tab2"><strong>Table 15-2:</strong> Ix86-64 Argument Passing via Registers</p>&#13;
		<table class="all">&#13;
			<colgroup>&#13;
				<col style="width:40%"/>&#13;
				<col style="width:60%"/>&#13;
			</colgroup>&#13;
			<tbody>&#13;
				<tr>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>Register</strong></p>&#13;
					</td>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>Usage</strong></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">RDI</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">1st argument</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">RSI</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">2nd argument</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">RDX</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">3rd argument</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">RCX</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">4th argument</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">R8</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">5th argument</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">R9</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">6th argument</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">XMM0–XMM7</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Used to pass floating-point arguments</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">R10</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">Can be used to pass static chain pointer</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">RAX</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Used to pass argument count if there are a variable number of parameters</p>&#13;
					</td>&#13;
				</tr>&#13;
			</tbody>&#13;
		</table>&#13;
		<p class="indent">The 32-bit ARM (A32) ABI specifies up to four arguments appearing in registers R0 through R3. As the A64 architecture has twice as many registers (32), the A64 ABI is a bit more generous, passing up to eight 64-bit integer/pointer arguments in R0 through R7 and up to eight additional floating-point parameters in V0 through V7.</p>&#13;
		<p class="indent">The PowerPC ABI, which has 32 general-purpose registers, sets aside R3 through R10 to pass up to eight arguments to a function. It also sets aside the F1 through F8 floating-point registers to pass floating-point arguments to a function.</p>&#13;
		<p class="indent">In addition to setting aside registers to hold function arguments, the various ABIs typically define various registers that a function can use to hold local variables or temporary values (without explicitly preserving the <span epub:type="pagebreak" id="page_587"/>values held in those registers upon entry to the function). For example, the Windows ABI sets aside R11, XMM8 through XMM15, MMX0 through MMX7, the FPU registers, and RAX for temporary/local use. The ARM A32 ABI sets aside R4 through R8 and R10 through R11 for use as locals. The A64 ABI sets aside R9 through R15 for locals and temporaries. The PowerPC sets aside R14 through R30 and F14 through F31 for local variables. Once a compiler exhausts the registers the ABI defines for argument passing, most ABIs expect the calling code to pass additional parameters on the stack. Similarly, once a function uses all the registers set aside for local variables, additional local variable allocation occurs on the stack.</p>&#13;
		<p class="indent">Of course, a compiler can use other registers for local and temporary values as well as those set aside by the CPU’s or OS’s ABI. However, it’s the compiler’s responsibility to preserve those register values across the function call.</p>&#13;
		<div class="note">&#13;
			<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
			<p class="notep"><em>An ABI is a</em> convention, <em>not a requirement by the underlying OS or hardware. Compiler writers (and assembly language programmers) who stick to a given ABI can expect that their object code modules will be able to interact with code written in other languages that adhere to that ABI. However, nothing stops a compiler writer from using whatever mechanism they choose.</em></p>&#13;
		</div>&#13;
		<h4 class="h4" id="ch00lev2sec189"><strong>15.5.6 Java VM and Microsoft CLR Parameters and Locals</strong></h4>&#13;
		<p class="noindent">Because the Java VM and Microsoft CLR are both virtual stack machines, programs compiled to those two architectures always push function arguments onto the stack. Beyond that, the two virtual machine architectures diverge. The reason for the divergence is that the Java VM’s design supports efficient interpretation of Java bytecodes with JIT compilation improving performance as needed. The Microsoft CLR, on the other hand, does not support interpretation; instead, the CLR code (CIL) design supports efficient JIT compilation to optimized machine code.</p>&#13;
		<p class="indent">The Java VM is a traditional stack architecture, with parameters, locals, and temporaries sitting on the stack. Other than the fact that there are no registers to use for such objects, Java’s memory organization is very similar to that of the 80x86/x86-64, PowerPC, and ARM CPUs. During JIT compilation, it can be difficult to figure out which values on the stack can be moved into registers and which local variables the Java compiler allocates on the stack can be allocated in registers. Optimizing such stack allocations to use registers can be very time-consuming, so it’s doubtful that the Java JIT compiler does this while the application is running (as doing so would greatly diminish the application’s runtime performance).</p>&#13;
		<p class="indent">Microsoft’s CLR operates under a different philosophy. CIL is always JIT-compiled into native machine code. Furthermore, Microsoft’s intent is to have the JIT compiler produce <em>optimized</em> native machine code. While the JIT compiler rarely does as good a job as a traditional C/C++ compiler, it generally does a much better job than the Java JIT compiler. This is because the Microsoft CLR definition explicitly singles out parameter argument and <span epub:type="pagebreak" id="page_588"/>local variable memory accesses. When the JIT compiler sees these special instructions, it can allocate those variables to registers rather than memory locations. As a result, CLR JIT-compiled code is often shorter and faster than Java VM JIT-compiled code (especially on RISC architectures).</p>&#13;
		<h3 class="h3" id="ch00lev1sec125"><strong>15.6 Parameter-Passing Mechanisms</strong></h3>&#13;
		<p class="noindent">Most high-level languages provide at least two mechanisms for passing actual parameter data to a subroutine: pass-by-value and pass-by-reference.<sup><a id="ch15fn_11"/><a href="footnotes.xhtml#ch15fn11">11</a></sup> In languages like Visual Basic, Pascal, and C++, declaring and using both types of parameters is so easy that a programmer may conclude that there’s little difference in efficiency between the two mechanisms. That’s a myth this section intends to dispel.</p>&#13;
		<div class="note">&#13;
			<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
			<p class="notep"><em>There are other parameter-passing mechanisms besides pass-by-value and pass-by-reference. FORTRAN and HLA, for example, support a mechanism known as pass-by-value/result (or pass-by-value/returned). Ada and HLA support pass-by-result. HLA and Algol support pass-by-name. This book won’t discuss these alternative parameter-passing mechanisms further, because you probably won’t see them very often. If you’d like more information, consult a good book on programming language design or the HLA documentation.</em></p>&#13;
		</div>&#13;
		<h4 class="h4" id="ch00lev2sec190"><strong>15.6.1 Pass-by-Value</strong></h4>&#13;
		<p class="noindent">Pass-by-value is the easiest parameter-passing mechanism to understand. The code that calls a procedure makes a copy of the parameter’s data and passes this copy to the procedure. For small values, passing a parameter by value generally requires little more than a <span class="literal">push</span> instruction (or, when passing parameters in the registers, an instruction that moves the value into a register). Therefore, this mechanism is often very efficient.</p>&#13;
		<p class="indent">One big advantage of pass-by-value parameters is that the CPU treats them just like a local variable within the activation record. Because you’ll rarely have more than 120 bytes of parameter data that you pass to a procedure, CPUs that provide a shortened displacement with the indexed addressing mode will be able to access most parameter values using a shorter (and, therefore, more efficient) instruction.</p>&#13;
		<p class="indent">The one case where passing a parameter by value can be inefficient is when you need to pass a large data structure, such as an array or record. The calling code needs to make a byte-for-byte copy of the actual parameter into the procedure’s activation record, as you saw in an earlier example. This can be a very slow process, say, if you decide to pass a million-element array to a subroutine by value. Therefore, you should avoid passing large objects by value unless absolutely necessary.</p>&#13;
		<h4 class="h4" id="ch00lev2sec191"><span epub:type="pagebreak" id="page_589"/><strong>15.6.2 Pass-by-Reference</strong></h4>&#13;
		<p class="noindent">The pass-by-reference mechanism passes the address of an object rather than its value. This has a couple of distinct advantages over pass-by-value. First, regardless of the parameter’s size, pass-by-reference parameters always consume the same amount of memory—the size of a pointer (which typically fits in a machine register). Second, pass-by-reference parameters allow you to modify the value of the actual parameter—which is impossible with pass-by-value parameters.</p>&#13;
		<p class="indent">Pass-by-reference parameters are not without their drawbacks, though. Usually, accessing a reference parameter within a procedure is more expensive than accessing a value parameter, because the subroutine needs to dereference that address on each access of the object. This generally involves loading a register with the pointer in order to dereference the pointer using a register indirect addressing mode.</p>&#13;
		<p class="indent">For example, consider the following Pascal code:</p>&#13;
		<pre class="programs">&#13;
			procedure RefValue<br/> (<br/>    var dest:integer;<br/>    var passedByRef:integer;<br/>        passedByValue:integer<br/>);<br/>begin<br/><br/>    dest := passedByRef + passedByValue;<br/><br/>end;</pre>&#13;
		<p class="indent">Here’s the equivalent HLA/x86 assembly code:</p>&#13;
		<pre class="programs">&#13;
			procedure RefValue<br/>(<br/>var     dest:int32;<br/>var     passedByRef:int32;<br/>            passedByValue:int32<br/>); @noframe;<br/>begin RefValue;<br/><br/>    // Standard entry sequence (needed because of @noframe).<br/>    // Set up base pointer.<br/>    // Note: don't need SUB(nn,esp) because<br/>    // we don't have any local variables.<br/><br/>    push( ebp );<br/>    mov( esp, ebp );<br/><br/>    // Get pointer to actual value.<br/><br/>    mov( passedByRef, edx );<br/><br/>    // Fetch value pointed at by passedByRef.<br/><span epub:type="pagebreak" id="page_590"/><br/>    mov( [edx], eax );<br/><br/>    // Add in the value parameter.<br/><br/>    add( passedByValue, eax );<br/><br/>    // Get address of destination reference parameter.<br/><br/>    mov( dest, edx );<br/><br/>    // Store sum away into dest.<br/><br/>    mov( eax, [edx] );<br/><br/>    // Exit sequence doesn't need to deallocate any local<br/>    // variables because there are none.<br/><br/>    pop( ebp );<br/>    ret( 12 );<br/><br/>end RefValue;</pre>&#13;
		<p class="indent">Notice that this code requires two more instructions than a version that uses pass-by-value—specifically, the two instructions that load the addresses of <span class="literal">dest</span> and <span class="literal">passedByRef</span> into the EDX register. In general, only a single instruction is needed to access the value of a pass-by-value parameter. However, two instructions are needed to manipulate the value of a parameter when you pass it by reference (one instruction to fetch the address, and one to manipulate the data at that address). So, unless you need the semantics of pass-by-reference, try to use pass-by-value instead.</p>&#13;
		<p class="indent">The issues with pass-by-reference tend to diminish when your CPU has lots of available registers that it can use to maintain the pointer values. In that situation, the CPU can use a single instruction to fetch or store a value via a pointer maintained in the register.</p>&#13;
		<h3 class="h3" id="ch00lev1sec126"><strong>15.7 Function Return Values</strong></h3>&#13;
		<p class="noindent">Most HLLs return function results in one or more CPU registers. Exactly which register the compiler uses depends on the data type, CPU, and compiler. For the most part, however, functions return their results in registers (assuming the return data fits in a machine register).</p>&#13;
		<p class="indent">On the 32-bit 80x86, most functions that return ordinal (integer) values return their function results in the AL, AX, or EAX register. Functions that return 64-bit values (<span class="literal">long long int</span>) generally return the function result in the EDX:EAX register pair (with EDX containing the HO double word of the 64-bit value). On 64-bit variants of the 80x86 family, 64-bit compilers return 64-bit results in the RAX register. On the PowerPC, most compilers follow the IBM ABI and return 8-, 16-, and 32-bit values in the R3 register. <span epub:type="pagebreak" id="page_591"/>Compilers for the 32-bit versions of the PowerPC return 64-bit ordinal values in the R4:R3 register pair (with R4 containing the HO word of the function result). Presumably, compilers running on 64-bit variants of the PowerPC can return 64-bit ordinal results directly in R3.</p>&#13;
		<p class="indent">Generally, compilers return floating-point results in one of the CPU’s (or FPU’s) floating-point registers. On 32-bit variants of the 80x86 CPU family, most compilers return a floating-point result in the 80-bit ST0 floating-point register. Although the 64-bit versions of the 80x86 family also provide the same FPU registers as the 32-bit members, some operating systems, such as Windows64, typically use one of the SSE registers (XMM0) to return floating-point values. PowerPC systems generally return floating-point function results in the F1 floating-point register. Other CPUs return floating-point results in comparable locations.</p>&#13;
		<p class="indent">Some languages allow a function to return a nonscalar (aggregate) value. The exact mechanism that compilers use to return large function return results varies from compiler to compiler. However, a typical solution is to pass a function the address of some storage where the function can place the return result. As an example, consider the following short C++ program whose <span class="literal">func()</span> function returns a structure object:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>typedef struct<br/>{<br/>    int a;<br/>    char b;<br/>    short c;<br/>    char d;<br/>} s_t;<br/><br/>s_t func( void )<br/>{<br/>    s_t s;<br/><br/>    s.a = 0;<br/>    s.b = 1;<br/>    s.c = 2;<br/>    s.d = 3;<br/>    return s;<br/>}<br/><br/>int main( void )<br/>{<br/>    s_t t;<br/><br/>    t = func();<br/>    printf( "%d %d", t.a, func().a );<br/>    return( 0 );<br/>}</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_592"/>Here’s the PowerPC code that GCC emits for this C++ program:</p>&#13;
		<pre class="programs">&#13;
			.text<br/>        .align 2<br/>        .globl _func<br/><br/>; func() -- Note: upon entry, this<br/>;           code assumes that R3<br/>;           points at the storage<br/>;           to hold the return result.<br/><br/>_func:<br/>        li r0,1<br/>        li r9,2<br/>        stb r0,-28(r1) ; s.b = 1<br/>        li r0,3<br/>        stb r0,-24(r1) ; s.d = 3<br/>        sth r9,-26(r1) ; s.c = 2<br/>        li r9,0        ; s.a = 0<br/><br/>        ; Okay, set up the return<br/>        ; result.<br/><br/>        lwz r0,-24(r1) ; r0 = d::c<br/>        stw r9,0(r3)   ; result.a = s.a<br/>        stw r0,8(r3)   ; result.d/c = s.d/c<br/>        lwz r9,-28(r1)<br/>        stw r9,4(r3)   ; result.b = s.b<br/><br/><br/>        blr<br/>        .data<br/>        .cstring<br/>        .align 2<br/>LC0:<br/>        .ascii "%d %d\0"<br/>        .text<br/>        .align 2<br/>        .globl _main<br/>_main:<br/>        mflr r0<br/>        stw r31,-4(r1)<br/>        stw r0,8(r1)<br/>        bcl 20,31,L1$pb<br/>L1$pb:<br/>        ; Allocate storage for t and<br/>        ; temporary storage for second<br/>        ; call to func:<br/><br/>        stwu r1,-112(r1)<br/><br/>        ; Restore LINK from above:<br/><br/>        mflr r31<br/><span epub:type="pagebreak" id="page_593"/>        ; Get pointer to destination<br/>        ; storage (t) into R3 and call func:<br/><br/>        addi r3,r1,64<br/>        bl _func<br/><br/>        ; Compute "func().a"<br/><br/>        addi r3,r1,80<br/>        bl _func<br/><br/>        ; Get t.a and func().a values<br/>        ; and print them:<br/><br/>        lwz r4,64(r1)<br/>        lwz r5,80(r1)<br/>        addis r3,r31,ha16(LC0-L1$pb)<br/>        la r3,lo16(LC0-L1$pb)(r3)<br/>        bl L_printf$stub<br/>        lwz r0,120(r1)<br/>        addi r1,r1,112<br/>        li r3,0<br/>        mtlr r0<br/>        lwz r31,-4(r1)<br/>        blr<br/><br/>; stub for printf function:<br/><br/>        .data<br/>        .picsymbol_stub<br/>L_printf$stub:<br/>        .indirect_symbol _printf<br/>        mflr r0<br/>        bcl 20,31,L0$_printf<br/>L0$_printf:<br/>        mflr r11<br/>        addis r11,r11,ha16(L_printf$lazy_ptr-L0$_printf)<br/>        mtlr r0<br/>        lwz r12,lo16(L_printf$lazy_ptr-L0$_printf)(r11)<br/>        mtctr r12<br/>        addi r11,r11,lo16(L_printf$lazy_ptr-L0$_printf)<br/>        bctr<br/>        .data<br/>        .lazy_symbol_pointer<br/>L_printf$lazy_ptr:<br/>        .indirect_symbol _printf<br/>        .long dyld_stub_binding_helper</pre>&#13;
		<p class="indent">Here’s the 32-bit 80x86 code that GCC emits for this same function:</p>&#13;
		<pre class="programs">&#13;
			.file   "t.c"<br/>        .text<br/>        .p2align 2,,3<br/>        .globl func<br/><span epub:type="pagebreak" id="page_594"/>        .type   func,@function<br/><br/>; On entry, assume that the address<br/>; of the storage that will hold the<br/>; function's return result is passed<br/>; on the stack immediately above the<br/>; return address.<br/><br/>func:<br/>        pushl   %ebp<br/>        movl    %esp, %ebp<br/>        subl    $24, %esp       ; Allocate storage for s.<br/><br/>        movl    8(%ebp), %eax   ; Get address of result<br/>        movb    $1, -20(%ebp)   ; s.b = 1<br/>        movw    $2, -18(%ebp)   ; s.c = 2<br/>        movb    $3, -16(%ebp)   ; s.d = 3<br/>        movl    $0, (%eax)      ; result.a = 0;<br/>        movl    -20(%ebp), %edx ; Copy the rest of s<br/>        movl    %edx, 4(%eax)   ; to the storage for<br/>        movl    -16(%ebp), %edx ; the return result.<br/>        movl    %edx, 8(%eax)<br/>        leave<br/>        ret     $4<br/>.Lfe1:<br/>        .size   func,.Lfe1-func<br/>        .section        .rodata.str1.1,"aMS",@progbits,1<br/>.LC0:<br/>        .string "%d %d"<br/><br/>        .text<br/>        .p2align 2,,3<br/>        .globl main<br/>        .type   main,@function<br/>main:<br/>        pushl   %ebp<br/>        movl    %esp, %ebp<br/>        subl    $40, %esp       ; Allocate storage for<br/>        andl    $-16, %esp      ; t and temp result.<br/><br/>        ; Pass the address of t to func:<br/><br/>        leal    -24(%ebp), %eax<br/>        subl    $12, %esp<br/>        pushl   %eax<br/>        call    func<br/><br/>        ; Pass the address of some temporary storage<br/>        ; to func:<br/><br/>        leal    -40(%ebp), %eax<br/>        pushl   %eax<br/>        call    func<br/><span epub:type="pagebreak" id="page_595"/>        ; Remove junk from stack:<br/><br/>        popl    %eax<br/>        popl    %edx<br/><br/>        ; Call printf to print the two values:<br/><br/>        pushl   -40(%ebp)<br/>        pushl   -24(%ebp)<br/>        pushl   $.LC0<br/>        call    printf<br/>        xorl    %eax, %eax<br/>        leave<br/>        ret</pre>&#13;
		<p class="indent">The takeaway from these 80x86 and PowerPC examples is that functions returning large objects often copy the function result data just prior to returning. This extra copying can take considerable time, especially if the return result is large. Instead of returning a large structure as a function result, as shown here, it’s usually better to explicitly pass a pointer to some destination storage to a function that returns a large result and then let the function do whatever copying is necessary. This often saves some time and code. Consider the following C code, which implements this policy:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>typedef struct<br/>{<br/>    int a;<br/>    char b;<br/>    short c;<br/>    char d;<br/>} s_t;<br/><br/>void func( s_t *s )<br/>{<br/>    s-&gt;a = 0;<br/>    s-&gt;b = 1;<br/>    s-&gt;c = 2;<br/>    s-&gt;d = 3;<br/>    return;<br/>}<br/><br/>int main( void )<br/>{<br/>    s_t s,t;<br/>    func( &amp;s );<br/>    func( &amp;t );<br/>    printf( "%d %d", s.a, t.a );<br/>    return( 0 );<br/>}</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_596"/>Here’s the conversion to 80x86 code by GCC:</p>&#13;
		<pre class="programs">&#13;
			        .file   "t.c"<br/>        .text<br/>        .p2align 2,,3<br/>        .globl func<br/>        .type   func,@function<br/>func:<br/>        pushl   %ebp<br/>        movl    %esp, %ebp<br/>        movl    8(%ebp), %eax<br/>        movl    $0, (%eax)      ; s-&gt;a = 0<br/>        movb    $1, 4(%eax)     ; s-&gt;b = 1<br/>        movw    $2, 6(%eax)     ; s-&gt;c = 2<br/>        movb    $3, 8(%eax)     ; s-&gt;d = 3<br/>        leave<br/>        ret<br/>.Lfe1:<br/>        .size   func,.Lfe1-func<br/>        .section        .rodata.str1.1,"aMS",@progbits,1<br/>.LC0:<br/>        .string "%d %d"<br/>        .text<br/>        .p2align 2,,3<br/>        .globl main<br/>        .type   main,@function<br/>main:<br/>        ; Build activation record and allocate<br/>        ; storage for s and t:<br/><br/>        pushl   %ebp<br/>        movl    %esp, %ebp<br/>        subl    $40, %esp<br/>        andl    $-16, %esp<br/>        subl    $12, %esp<br/><br/>        ; Pass address of s to func and<br/>        ; call func:<br/><br/>        leal    -24(%ebp), %eax<br/>        pushl   %eax<br/>        call    func<br/><br/>        ; Pass address of t to func and<br/>        ; call func:<br/><br/>        leal    -40(%ebp), %eax<br/>        movl    %eax, (%esp)<br/>        call    func<br/><br/>        ; Remove junk from stack:<br/><br/>        addl    $12, %esp<br/><span epub:type="pagebreak" id="page_597"/>        ; Print the results:<br/><br/>        pushl   -40(%ebp)<br/>        pushl   -24(%ebp)<br/>        pushl   $.LC0<br/>        call    printf<br/>        xorl    %eax, %eax<br/>        leave<br/>        ret</pre>&#13;
		<p class="indent">As you can see, this approach is more efficient because the code doesn’t have to copy the data twice, once to a local copy of the data and once to the final destination variable.</p>&#13;
		<h3 class="h3" id="ch00lev1sec127"><strong>15.8 For More Information</strong></h3>&#13;
		<p class="bib">Aho, Alfred V., Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman. <em>Compilers: Principles, Techniques, and Tools</em>. 2nd ed. Essex, UK: Pearson Education Limited, 1986.</p>&#13;
		<p class="bib">Barrett, William, and John Couch. <em>Compiler Construction: Theory and Practice</em>. Chicago: SRA, 1986.</p>&#13;
		<p class="bib">Dershem, Herbert, and Michael Jipping. <em>Programming Languages, Structures and Models</em>. Belmont, CA: Wadsworth, 1990.</p>&#13;
		<p class="bib">Duntemann, Jeff. <em>Assembly Language Step-by-Step</em>. 3rd ed. Indianapolis: Wiley, 2009.</p>&#13;
		<p class="bib">Fraser, Christopher, and David Hansen. <em>A Retargetable C Compiler: Design and Implementation</em>. Boston: Addison-Wesley Professional, 1995.</p>&#13;
		<p class="bib">Ghezzi, Carlo, and Jehdi Jazayeri. <em>Programming Language Concepts</em>. 3rd ed. New York: Wiley, 2008.</p>&#13;
		<p class="bib">Hoxey, Steve, Faraydon Karim, Bill Hay, and Hank Warren, eds. <em>The PowerPC Compiler Writer’s Guide</em>. Palo Alto, CA: Warthman Associates for IBM, 1996.</p>&#13;
		<p class="bib">Hyde, Randall. <em>The Art of Assembly Language</em>. 2nd ed. San Francisco: No Starch Press, 2010.</p>&#13;
		<p class="bib">———. “Webster: The Place on the Internet to Learn Assembly.” <em><a href="http://plantation-productions.com/Webster/index.html">http://plantation-productions.com/Webster/index.html</a></em>.</p>&#13;
		<p class="bib">Intel. “Intel 64 and IA-32 Architectures Software Developer Manuals.” Updated November 11, 2019. <em><a href="https://software.intel.com/en-us/articles/intel-sdm">https://software.intel.com/en-us/articles/intel-sdm</a></em>.</p>&#13;
		<p class="bib">Ledgard, Henry, and Michael Marcotty. <em>The Programming Language Landscape</em>. Chicago: SRA, 1986.</p>&#13;
		<p class="bib">Louden, Kenneth C. <em>Compiler Construction: Principles and Practice</em>. Boston: Cengage, 1997.</p>&#13;
		<p class="bib"><span epub:type="pagebreak" id="page_598"/>Louden, Kenneth C., and Kenneth A. Lambert. <em>Programming Languages: Principles and Practice</em>. 3rd ed. Boston: Course Technology, 2012.</p>&#13;
		<p class="bib">Parsons, Thomas W. <em>Introduction to Compiler Construction</em>. New York: W. H. Freeman, 1992.</p>&#13;
		<p class="bib">Pratt, Terrence W., and Marvin V. Zelkowitz. <em>Programming Languages, Design and Implementation</em>. 4th ed. Upper Saddle River, NJ: Prentice Hall, 2001.</p>&#13;
		<p class="bib">Sebesta, Robert. <em>Concepts of Programming Languages</em>. 11th ed. Boston: Pearson, 2016.</p>&#13;
	</body></html>