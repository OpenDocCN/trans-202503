- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Optimizing Performance
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: This chapter is aimed squarely at developers who want lightning-fast applications
    and are willing to take the time to make that happen. We’ll first discuss profiler
    tools to evaluate WebAssembly module performance and investigate how to compare
    the performance of WebAssembly with similar JavaScript code. We’ll spend some
    time looking at strategies to improve the performance of our WebAssembly, including
    inlining functions, replacing multiplication and division with bit-shifts, combining
    constants, and removing code using Dead Code Elimination (DCE).
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll also delve into other methods for determining a module’s performance:
    we’ll use `console.log` and `Date.now` to measure our application’s performance
    and use the testing suite *benchmark.js* to gather detailed performance data for
    an application. Then, just for fun, we’ll print the Chrome JavaScript V8 engine’s
    Intermediate Representation (IR) bytecode for a JavaScript function. JavaScript
    IR bytecode can give you insight into the work a JavaScript function does, which
    is helpful for evaluating whether to write a function in WebAssembly or JavaScript.'
  prefs: []
  type: TYPE_NORMAL
- en: Using a Profiler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Profilers* are tools that analyze different aspects of an application’s performance,
    including the app’s memory usage and execution time. This can help you make decisions
    about where to optimize and what to optimize for. You’ll often need to make trade-offs
    between different types of optimizations. For example, you’ll need to decide whether
    to focus on improving your time to interactive (TTI) so users can begin using
    your application as soon as possible or focusing on peak performance once your
    application is up and running. If you’re writing a game, it’s worth having a long
    load time to ensure the game will run more smoothly once it finishes downloading.
    However, an online store might prefer to ensure the user can interact with the
    website as soon as possible. In most cases, you’ll need to balance between the
    two, and using a profiler can help.'
  prefs: []
  type: TYPE_NORMAL
- en: Profilers are also efficient at finding bottlenecks in your code, allowing you
    to focus your time and effort in those locations. We’ll look at the Chrome and
    Firefox profilers, because they currently have the best support for WebAssembly.
    We’ll be profiling the collision detection app from Chapter 8.
  prefs: []
  type: TYPE_NORMAL
- en: Chrome Profiler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ll want to use a new incognito browser window with the Chrome profiler.
    Incognito windows don’t load website caches, cookies, or Chrome plug-ins, which
    cause problems when profiling because they run additional JavaScript code and
    affect the performance of the site you want to profile. The caches and cookies
    are usually less problematic, but can clutter your environment with data unrelated
    to the code you’re profiling. You can open an incognito window from the menu on
    the top right of your web browser by clicking **New incognito window**, as shown
    in [Figure 9-1](#figure9-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09001](Images/f09001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-1: Open an incognito window in Chrome.'
  prefs: []
  type: TYPE_NORMAL
- en: After opening an incognito browser window, make sure you’re running a web server
    using the command `node server.js` from your command line and enter **localhost:8080/collide.html**
    into your web browser. Click **More Tools**▶**Developer tools** from the menu
    in the top right, as shown in [Figure 9-2](#figure9-2).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09002](Images/f09002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-2: Open the Developer tools in Chrome.'
  prefs: []
  type: TYPE_NORMAL
- en: You should see several tabs across the top of the Developer tools. To see the
    profiler, click **Performance**, as shown in [Figure 9-3](#figure9-3).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09003](Images/f09003.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-3: Open the Performance tab in Chrome.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Performance tab offers two options when you initially open it: Record and
    Reload. The Record button begins recording a profile without reloading the application.
    This kind of profiling is most important when you’re less concerned about the
    startup time of your application and more concerned with peak performance. Before
    we profile, make sure the Memory checkbox at the top of the Performance tab is
    selected. If it isn’t, the memory heap won’t be profiled. If you want to profile
    your application from initialization, you would click the Reload button. Click
    **Record** to continue. Once you’ve recorded for about five seconds, click **Stop**
    as shown in [Figure 9-4](#figure9-4).'
  prefs: []
  type: TYPE_NORMAL
- en: '![f09004](Images/f09004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-4: Recording a profile in Chrome'
  prefs: []
  type: TYPE_NORMAL
- en: When recording stops, the profiler will open and show a recording of every frame
    rendered by your application. A Summary tab in the bottom half shows that the
    vast majority of this application’s execution time is tied up in Scripting ([Figure
    9-5](#figure9-5)), which includes JavaScript and WebAssembly time.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09005](Images/f09005.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-5: Chrome Performance tab after recording the profile'
  prefs: []
  type: TYPE_NORMAL
- en: On this main Performance page, a pie chart shows the processing time spent Scripting,
    Rendering, Painting, System, and Idle. Above the pie chart is a series of tabs,
    including Summary, Bottom-Up, Call Tree, and Event Log,all of which we’ll explore
    in this chapter. The section above these tabs shows the JS Heap memory allocated,
    and above that, the rendered frames, CPU, and FPS information. Let’s take a quick
    look at the JavaScript heap memory in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: JavaScript Heap Memory
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The profile in [Figure 9-5](#figure9-5) shows that there’s been a growth in
    heap memory. We’ll spend a little time investigating why this is happening. First,
    we’ll check how much memory is allocated before it’s garbage collected. Some developers
    believe that because JavaScript is a garbage collected language, they don’t need
    to be concerned about memory. Unfortunately, that’s not the case; it’s still possible
    for your code to create objects faster than they can be garbage collected. It’s
    also possible to hold on to references to objects longer than they’re needed,
    leaving JavaScript unable to know if it should delete them. If an application
    is growing in memory size as quickly as this one is, it makes sense to watch how
    much memory is allocated before garbage collection. Then try to understand where
    the application allocates memory. Right now, the heap size is about 1MB.
  prefs: []
  type: TYPE_NORMAL
- en: After some additional profiling, we can see that the JS Heap grows to 2.2MB,
    and after the garbage collector runs, the heap size drops back down to 1.2MB.
    It might take several minutes before the garbage collector runs, so please be
    patient. [Figure 9-6](#figure9-6) shows the profile of the JS Heap during garbage
    collection. As you can see, on the right side of the graph, the size of the heap
    takes a sudden significant drop in size of 1MB.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09006](Images/f09006.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-6: Memory drop during garbage collection'
  prefs: []
  type: TYPE_NORMAL
- en: It’s best to determine precisely where this memory allocation is happening,
    because if we could slow the growth of the heap, it would potentially reduce the
    burden on the garbage collector.
  prefs: []
  type: TYPE_NORMAL
- en: Following the Memory Allocation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Because the growth of the heap is consistent, we can deduce that memory allocation
    is likely happening every frame render. The majority of the work this application
    does is in the WebAssembly module, so we first comment out the WebAssembly call
    to see whether the memory continues to show the same JS Heap growth profile. Open
    *collide.html* and comment out the call to `animation_wasm()` inside the `animate`
    function, as shown in [Listing 9-1](#listing9-1).
  prefs: []
  type: TYPE_NORMAL
- en: '**collide.html**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-1: Commenting out the `animation_wasm` function call'
  prefs: []
  type: TYPE_NORMAL
- en: Now reload the page and record a new profile. [Figure 9-7](#figure9-7) shows
    the new JS Heap profile without the `animation_wasm` function call.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09007](Images/f09007.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-7: Heap memory allocation graph after the `animation_wasm`function
    is removed'
  prefs: []
  type: TYPE_NORMAL
- en: Without the call to the WebAssembly module, the app no longer functions properly.
    However, you can still see the same JS Heap growth profile, so the growth in memory
    doesn’t appear to be coming from the WebAssembly module. Let’s uncomment the call
    to the WebAssembly module; then comment out the call to `ctx.putImageData` and
    create another profile, as shown in [Listing 9-2](#listing9-2).
  prefs: []
  type: TYPE_NORMAL
- en: '**collide.html**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-2: The `animation_wasm` function is back in; `putImageData` is removed.'
  prefs: []
  type: TYPE_NORMAL
- en: With the call to `ctx.putImageData` commented out, we can now create a new profile
    to check the memory growth ([Figure 9-8](#figure9-8)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09008](Images/f09008.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-8: Memory growth is slower when the `putImageData` call is removed.'
  prefs: []
  type: TYPE_NORMAL
- en: Without the call to `ctx.putImageData`, the memory growth slowed tremendously.
    Growth is still occurring, but it has a slower stair step growth pattern rather
    than an almost straight vertical line up. It appears that the call to `ctx.putImageData`
    is internally creating large objects that the garbage collector will eventually
    need to remove. Now we know how that memory is being allocated. Because `ctx.putImageData`
    is a built-in function, there isn’t anything we can do to optimize it. If memory
    allocation had been the problem, we would need to look into an alternative means
    to render to the canvas.
  prefs: []
  type: TYPE_NORMAL
- en: Frames
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the Profiler window is an area above the heap memory that provides more performance
    information, including the frames per second (fps) rendered. It also shows a graph
    that displays CPU usage. And there are small thumbnails of each frame rendered.
    When you move your mouse over these frames, you can watch how your application
    rendered its animation ([Figure 9-9](#figure9-9)), which can be very helpful if
    your application isn’t working as expected.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09009](Images/f09009.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-9: Viewing the individual frame render in the profiler'
  prefs: []
  type: TYPE_NORMAL
- en: You can hover your mouse over the green *Frames* boxes to see the fps at any
    point in the profile ([Figure 9-10](#figure9-10)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09010](Images/f09010.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-10: Viewing fps in the profiler'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the frame rate at this point in the application’s execution
    is 18 fps. When we scrub over the frames, the number hovers between 17 and 20\.
    Frames per second is the primary measure of performance for the collision detection
    app, so we’ll need to remember the profile showing us roughly 18 fps to compare
    it with later results. Keep in mind that running the profiler appears to harm
    the app’s performance, so although the results are useful relative to each other,
    they might not be totally accurate on how the app runs in the wild.
  prefs: []
  type: TYPE_NORMAL
- en: Bottom-Up
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Bottom-Up tab shows the functions called within the application, the total
    time they ran, and the Self Time, which is the amount of time the function ran
    excluding the time spent in the functions they call. Self Time is very useful
    because functions that call other functions that take a long time to run will
    always show a longer Total Time, as you can see in [Figure 9-11](#figure9-11).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09011](Images/f09011.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-11: Chrome’s Bottom-Up tab window'
  prefs: []
  type: TYPE_NORMAL
- en: The Self Time for `<wasm-unnamed>` is by far the longest. The Total Time is
    longer in several functions, such as `animate`, because the `animate` function
    calls the WebAssembly module. It’s a bit disappointing that Chrome doesn’t indicate
    which function it calls inside the WebAssembly module, but we can determine at
    a glance that the application spends more than 90 percent of its processing time
    executing WebAssembly.
  prefs: []
  type: TYPE_NORMAL
- en: Firefox Profiler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using the Firefox profiler is another excellent way to gather performance data
    on your application. I recommend opening a private window when you run the Firefox
    profiler. Do this by opening the menu in the top right of the browser and clicking
    **New Private Window** ([Figure 9-12](#figure9-12)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09012](Images/f09012.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-12: Open a New Private Window in Firefox.'
  prefs: []
  type: TYPE_NORMAL
- en: Open the profiler by clicking **Web Developer**▶**Performance** ([Figure 9-13](#figure9-13)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09013](Images/f09013.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-13: Click **Web Developer**▶**Performance** in the Firefox menu.'
  prefs: []
  type: TYPE_NORMAL
- en: In the Performance menu, click the **Start Recording Performance** button to
    record performance data. After a few seconds, stop recording. [Figure 9-14](#figure9-14)
    shows something similar to what you should see in the Performance tab. The Waterfall
    tab (which is the default view after recording) shows the top-level function calls
    and how long they take to execute.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09014](Images/f09014.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-14: Firefox Performance window Waterfall tab'
  prefs: []
  type: TYPE_NORMAL
- en: Scroll down to see where the garbage collection takes place and how long it
    takes to run. This report is a bit boring for our application, which primarily
    executes `requestAnimationFrame`. The three tabs across the top of the window
    provide more information. The Waterfall tab gives you a general idea of where
    tasks are running long. We won’t go into detail about the Waterfall tab, because
    it’s more of a *runtime at a glance* summary. Instead we’ll look at the Call Tree
    and JS Flame Chart tabs.
  prefs: []
  type: TYPE_NORMAL
- en: Call Tree
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Call Tree tab shows the function calls in which the application spends most
    of its time. The interface allows you to drill down into each of the functions
    and see the calls they make. [Figure 9-15](#figure9-15) shows a screenshot of
    the Call Tree tab.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09015](Images/f09015.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-15: Firefox Call Tree tab'
  prefs: []
  type: TYPE_NORMAL
- en: One nice feature is that you can click the name of your WebAssembly file, and
    the link will take you to the proper function in your WebAssembly code. The function
    names are lost, but an index showing the function number in WAT follows the `wasm-function`
    label. That makes it a little easier to determine what the function calls.
  prefs: []
  type: TYPE_NORMAL
- en: JS Flame Chart
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The JS Flame Chart tab is pretty much the same information you see in the Call
    Tree tab, but it’s organized along a timeline instead of as a summary. You can
    zoom in on a specific portion of the chart to see which functions are running
    at that point in the profile ([Figure 9-16](#figure9-16)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09016](Images/f09016.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-16: Firefox JS Flame Chart tab'
  prefs: []
  type: TYPE_NORMAL
- en: Here is the call to the JavaScript `animate` function. The `animate` function
    spends most of its time running `wasm-function[6]`, which is the seventh function
    in our WAT code, called `$main`. The `$main` function calls `wasm-function[5]`,
    which is the sixth function (`$get_obj_attr`) and `wasm-function[1]` (`$abs`).
  prefs: []
  type: TYPE_NORMAL
- en: Each one of these tabs shows the minimum and maximum fps on the left side and
    the average fps on the right side. The left side of the profiler looks something
    like [Figure 9-17](#figure9-17).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09017](Images/f09017.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-17: Firefox max and min fps'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the maximum fps is a bit more than 22, and the minimum is a
    little less than 5 fps. As mentioned earlier, running the profiler might impact
    the fps. The average fps is on the right side of the profiler ([Figure 9-18](#figure9-18)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09018](Images/f09018.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-18: Firefox average fps'
  prefs: []
  type: TYPE_NORMAL
- en: The average fps for this profile was approximately 14 fps. In the next section,
    we’ll look at how to improve the app’s performance using `wasm-opt`.
  prefs: []
  type: TYPE_NORMAL
- en: wasm-opt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We use the `wasm-opt` command line tool to run performance optimizations on
    a WebAssembly file. It comes with `wat-wasm` and *Binaryen.js*. If you’ve installed
    `wat-wasm` to use for the `wat2wasm` tool, you should already have a version and
    can skip the next section. If not, install *Binaryen.js*, which is a JavaScript
    version of the Binaryen WebAssembly tool for converting an Intermediate Representation
    (IR) into WebAssembly code. It has some helpful options for optimizing WebAssembly
    code.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Binaryen
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are several options for installing Binaryen. I recommend using *Binaryen.js*,
    which you can install using `npm` with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: For those interested in building it from the source, it’s available on GitHub
    at [https://github.com/WebAssembly/binaryen](https://github.com/WebAssembly/binaryen).
    There is also an `npm` package called `wasm-opt` that will install the platform-specific
    binaries for *Binaryen*, but I would recommend installing `wat-wasm` or *binaryen.js*
    using `npm` instead.
  prefs: []
  type: TYPE_NORMAL
- en: Running wasm-opt
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `wasm-opt` tool has a number of flags you can use to minimize the download
    size and optimize the execution of your WebAssembly module. You use these flags
    to tell the optimizer whether to focus on performance or download size. If a change
    can be made to reduce the file size without affecting performance, that change
    will be made in either case. The same is true if a change can be made to improve
    the performance without affecting download size. These flags tell the compiler
    which optimization to prefer when there is a trade-off to consider.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll run `wasm-opt` against our *collide.wasm* file with both types of flags,
    starting with the size optimization preference and then compiling it again with
    a performance preference. These flags will be the same with any toolchain that
    uses Binaryen, such as Emscripten or AssemblyScript. The first two flags we’ll
    look at will optimize the WAT file for size.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing for Download Size
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The `wasm-opt` command has two flags that optimize your WebAssembly file for
    download size: `-Oz` and `-Os`. The O is a capital letter O, not a zero. The `-Oz`
    flag creates a smaller WebAssembly file but takes longer to reduce the size of
    the file. The `-Os` file creates a slightly larger WebAssembly file but takes
    less time to execute. Our application is small, so the time it takes to run either
    optimization will also be minimal. You might use `-Os` if you’re creating a sizeable
    Emscripten project that takes a long time to compile. For our purposes, we don’t
    need to use `-Os`. [Listing 9-3](#listing9-3) shows how to optimize our *collide.wasm*
    file to reduce its size using the `-Oz` flag.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-3: Running `wasm-opt` to optimize the *collide.wasm* file for download
    size'
  prefs: []
  type: TYPE_NORMAL
- en: When you run this optimization, the size of the WebAssembly file shrinks from
    709 bytes to 666 bytes. That’s only about a 6 percent reduction, but we didn’t
    have to do any work to get there. Typically, you’ll get better size reductions
    when you use this flag with a toolchain.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing for Execution Time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When you’re writing a game, you’ll be more interested in improving the fps
    than the download time. There are three optimization flags: `-O1`, `-O2`, and
    `-O3`. Again, the O is a letter o, not a zero. The `-O3` flag provides the highest
    level of optimization but takes the longest to execute. The `-O1` flag executes
    in the shortest time but provides the least optimization. The `-O2` flag is somewhere
    in between the two. Because our app is so small there isn’t a significant difference
    between the time it takes to run `-O1` and `-O3`. In [Listing 9-4](#listing9-4),
    we use the `-O3` flag to get the most from our optimization of the *collide.wasm*
    file.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-4: Using `wasm-opt` to optimize performance of the *collide.wasm*
    file'
  prefs: []
  type: TYPE_NORMAL
- en: Once you have the new version of the *collide.wasm* file, modify the *collide.html*
    file to run the optimized version. Now when we run it through a profiler, we can
    get an idea of the performance improvement. Profiling with Chrome shows the app
    now running at 35 fps ([Figure 9-19](#figure9-19)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09019](Images/f09019.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-19: New fps in Chrome for the optimized *collide-3.wasm* file'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 9-10](#figure9-10) showed that the original frame rate was 18 fps.
    Just running `wasm-opt` can double the frame rate of your application in Chrome.
    Let’s see what happens when we run our profiler in Firefox ([Figure 9-20](#figure9-20)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![f09020](Images/f09020.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-20: New fps in Firefox for the optimized *collide-3.wasm* file'
  prefs: []
  type: TYPE_NORMAL
- en: Looking back at [Figure 9-18](#figure9-18), we were only running at an average
    of 14 fps in our initial run, so the frame rate more than doubled in Firefox.
    In the next section, we’ll look at the disassembled optimized WAT code to see
    the kinds of optimizations `wasm-opt` made.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at Optimized WAT Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You should have the WebAssembly extension for VS Code installed (we did this
    in Chapter 1)*.* In Visual Studio, you can right-click a WebAssembly file and
    select Show WebAssembly to view the WAT for a given WebAssembly file. In [Listing
    9-5](#listing9-5), we use `wasm2wat` at the command line to convert the optimized
    *collide-3.wasm* file into a WAT file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-5: Run `wasm2wat` to disassemble *collide-3.wasm* to WAT.'
  prefs: []
  type: TYPE_NORMAL
- en: Open *collide.wat* next to *collide-3.wat* in VS Code, and look at the updates
    `wasm-opt` made to the WebAssembly file, as shown in [Figure 9-21](#figure9-21).
  prefs: []
  type: TYPE_NORMAL
- en: In the optimized code, all the function and variable names are gone. I’ve added
    a few comments to help you follow along. You can quickly see that the optimization
    has reduced the number of functions from seven to three. The optimization achieved
    this by expanding many of the small functions into inline code. In one of the
    remaining functions, the optimization removed a variable. You might create two
    different variables when, technically, you need only one because it makes the
    code more straightforward to read. The optimizer can detect this and reduce the
    number of variables. Also notice that the optimizer replaces multiplication by
    powers of 2 with left shifts. For example, in the code in [Figure 9-21](#figure9-21),
    the optimizer has replaced a multiplication by 4 with a left shift of 2\. In the
    next section, we’ll take a closer look at how some of these strategies improve
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09021](Images/f09021.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-21: Comparing an optimized and an unoptimized version of *collide.wat*'
  prefs: []
  type: TYPE_NORMAL
- en: Strategies for Improving Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we’ll look into some of the strategies you can use to improve your WebAssembly
    application’s performance. The optimizer uses some of these techniques, and you
    can code your application in such a way that you make the optimizer’s job easier.
    Sometimes you might want to look at the WAT code generated by the optimizer to
    obtain tips on ways you can improve code. Let’s look at a few common optimization
    techniques you can use with WAT.
  prefs: []
  type: TYPE_NORMAL
- en: Inlining Functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Calling a function has a tiny bit of overhead. That overhead is not typically
    a big problem unless the function is called thousands or millions of times a second.
    Inlining a function is the process of replacing a function call with an inline
    copy of the same code. Doing this removes the additional processing overhead required
    to make the function call but increases the size of the WebAssembly module, because
    it duplicates the code wherever the function was called. When we ran the optimizer
    on the *collide.wasm* module, it inlined four of the seven functions. Let’s look
    at a quick example of inlining a function. The following WAT code isn’t a part
    of an application; it’s just a demonstration. In [Listing 9-6](#listing9-6), we
    create a function that adds three numbers together and then create another function
    to call `$add_three` a few times.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-6: Demonstration code for us to inline'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll focus on inlining as the optimization for this section. To inline these
    functions, we cut and paste the contents of the function in every place where
    it’s called. In [Listing 9-7](#listing9-7), the grayed-out code is the original
    function call, and the code that follows is the inlined function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-7: Example of hand-inlined code'
  prefs: []
  type: TYPE_NORMAL
- en: Inlining the function calls might expose other optimization opportunities. For
    example, you can see that we’re adding `2` and later adding `13`. Because both
    of these values are constants, the code would perform better if we just added
    `15`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s write a little module that could potentially be inlined, compile and
    optimize it, and then look at the code generated by `wasm-opt`. We’ll create a
    module with three functions: `$add_three`, `$square`, and `$inline_test`. Create
    a WAT file named *inline.wat* and add the code in [Listing 9-8](#listing9-8).'
  prefs: []
  type: TYPE_NORMAL
- en: '**inline.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-8: We’ll use `wasm-opt` to inline this code'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `$add_three` function is the same function we inlined by hand in [Listing
    9-7](#listing9-7). The `$square` function multiplies the value on the top of the
    stack against itself, and the `$inline_test` function is the calling function.
    Let’s compile the `$inline_test` function using `wat2wasm`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can optimize it using `wasm-opt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s convert it back to WAT using `wasm2wat`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now we can open *inline-opt.wat* and see what our optimized code looks like
    ([Listing 9-9](#listing9-9)).
  prefs: []
  type: TYPE_NORMAL
- en: '**inline-opt.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-9: The optimized version of *inline.wat*, *inline-opt.wat*, inlines
    both functions.'
  prefs: []
  type: TYPE_NORMAL
- en: The optimizer removed the two functions `$add_three` and `$square`, and placed
    that code inline in the `inline_test` function.
  prefs: []
  type: TYPE_NORMAL
- en: Multiply and Divide vs. Shift
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Chapter 8 showed how to shift integer bits to the right as a faster way to multiply
    by powers of 2\. For example, a shift left of 3 is the same as multiplying by
    2³, which is 8\. Similarly, shifting an integer to the right is the same as dividing
    by that power of 2\. For example, a right shift of 4 is the same as dividing by
    2⁴, which is 16\. Let’s see how `wasm-opt` deals with power-of-2 multiplication
    and division. Create a new WAT file named *pow2_mul.wat* and add the code in [Listing
    9-10](#listing9-10), which creates a module to multiply and divide by powers of
    2.
  prefs: []
  type: TYPE_NORMAL
- en: '**pow2_mul.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-10: A function to multiply and divide by powers of 2'
  prefs: []
  type: TYPE_NORMAL
- en: Compile this code using `wat2wasm`, use `wasm-opt` to optimize the WebAssembly
    file, and then disassemble the WebAssembly file back into a WAT file using `wasm2wat`.
    Then open the optimized version of *pow2_mul.wat* in VS Code, as shown in [Listing
    9-11](#listing9-11).
  prefs: []
  type: TYPE_NORMAL
- en: '**pow2_mul_optimized.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-11: Optimized version of the `pow2_mul` function from [Listing 9-10](#listing9-10)'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the optimized code performs the division on the second parameter
    before performing the multiplication on the first parameter. When you multiply
    by a power-of-2 constant, `wasm-opt` will convert this into a left shift. However,
    `wasm-opt` doesn’t always replace a power-of-2 division with a right shift. Later
    in this chapter, we’ll spend some time running different versions of this code
    through *benchmark.js* to see how they perform. We’ll compare the optimized code
    generated by `wasm-opt` to code we optimize by hand to see if we can do better.
  prefs: []
  type: TYPE_NORMAL
- en: Combining Constants
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Often, optimizations will combine constants to improve performance. For example,
    say you have two constant offsets you need to add together. Your original code
    has *x* = 3 + 8, but this code would perform better if you just set *x* = 11 at
    the start. Cases like this aren’t always obvious to the human eye, but `wasm-opt`
    is efficient at hunting down these situations for you. As an example, create a
    WAT file named *combine_constants.wat* and add the code in [Listing 9-12](#listing9-12),
    which simply combines three constants.
  prefs: []
  type: TYPE_NORMAL
- en: '**combine_constants.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-12: A function that adds three constants together'
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the value returned by `$combine_constants` will always be 85\. The
    `wasm-opt` tool is smart enough to figure that out. When you run the code through
    `wat2wasm`, `wasm-opt`, and then `wasm2wat`, you’ll see the code in [Listing 9-13](#listing9-13).
  prefs: []
  type: TYPE_NORMAL
- en: '**combine_constants_optimized.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-13: The addition of three constants is combined into a single constant.'
  prefs: []
  type: TYPE_NORMAL
- en: The function in [Listing 9-13](#listing9-13) returns `85` 1 and doesn’t bother
    to perform the two additions.
  prefs: []
  type: TYPE_NORMAL
- en: DCE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Dead Code Elimination (DCE)* is an optimization technique that removes any
    code not being called or exported by your module. This is a straightforward optimization
    that doesn’t improve the execution time but does reduce the size of the download.
    DCE happens no matter which optimization flag you use. Let’s look at a quick example.
    Open a new file named *dce_test.wat* and add the code in [Listing 9-14](#listing9-14),
    which creates a module with two functions that are never used.'
  prefs: []
  type: TYPE_NORMAL
- en: '**dce_test.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-14: This module has two unused functions.'
  prefs: []
  type: TYPE_NORMAL
- en: The first two functions, `$dead_code_1` 1 and `$dead_code_2` 2, aren’t called
    and aren’t exported. Any optimization we run will remove these functions. Run
    `wat2wasm` to generate the code, `wasm-opt` with the `-O3` flag to optimize it,
    and `wasm2wat` to convert it back into a WAT file. Open that new file to view
    the code after the optimization has run, as shown in [Listing 9-15](#listing9-15).
  prefs: []
  type: TYPE_NORMAL
- en: '**dce_test_optimized.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-15: Two functions are removed by DCE.'
  prefs: []
  type: TYPE_NORMAL
- en: The only function that remains is `"dce_test"`. Using DCE has reduced the size
    of the module from 79 bytes to 46 bytes.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing the Collision Detection App with JavaScript
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve seen how our WebAssembly collision detection app performs. Let’s write
    that code in JavaScript relatively quickly and compare how it performs to the
    WebAssembly version. Create a new web page named *collidejs.html*. Begin by adding
    a header and a canvas element to the *collide.html* page and resaving it as *collidejs.html*,
    as shown in [Listing 9-16](#listing9-16).
  prefs: []
  type: TYPE_NORMAL
- en: '**collidejs.html (part 1 of 2)**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-16: HTML header and canvas element in *collidejs.html*'
  prefs: []
  type: TYPE_NORMAL
- en: This code is similar to the WebAssembly version of the app. The main difference
    will be in the `script` tag, shown in [Listing 9-17](#listing9-17). Add the following
    JavaScript in the `script` tag.
  prefs: []
  type: TYPE_NORMAL
- en: '**collidejs.html (part 2 of 2)**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-17: JavaScript version of our collision detection application'
  prefs: []
  type: TYPE_NORMAL
- en: I won’t go into detail about the code in [Listing 9-17](#listing9-17) because
    its purpose is just to provide a comparison with the WebAssembly code in Chapter
    8. Now we can run *collidejs.html* in the Chrome and Firefox profilers to see
    how they perform. [Figure 9-22](#figure9-22) shows the frame rate for *collidejs.html*
    inside the Chrome profiler.
  prefs: []
  type: TYPE_NORMAL
- en: '![f09022](Images/f09022.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-22: The frame rate of our JavaScript app running in the Chrome profiler'
  prefs: []
  type: TYPE_NORMAL
- en: Chrome ran the JavaScript version of the app at about 9 fps, slower than both
    the unoptimized WebAssembly version, which ran at about 18 fps in Chrome, and
    the optimized version, which ran at 35 fps. The optimized version of the WebAssembly
    code was almost four times as fast in Chrome.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s look at how our JavaScript performed in Firefox ([Figure 9-23](#figure9-23)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09023](Images/f09023.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-23: The frame rate of our JavaScript app running in the Firefox profiler'
  prefs: []
  type: TYPE_NORMAL
- en: Firefox performed quite a bit better than Chrome for this application (almost
    twice as fast). It even managed to outperform the unoptimized version of the WebAssembly
    app on Firefox, which ran at around 14 fps. This was only a little more than half
    as fast as the optimized version of the WebAssembly app on Firefox, which ran
    at about 31 fps.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you learned how to compare your WebAssembly code with similar
    JavaScript code using the Firefox and Chrome profilers. You should now be able
    to use this knowledge to compare different versions of your application on different
    browsers to get a feel for the kind of code that is best done in WebAssembly and
    what is best to do in JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: Hand Optimizing WAT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I spent some time hand optimizing my WebAssembly collider app and was able to
    improve my fps number even more. There were more changes than I can describe in
    this book. However, I want to point out the kinds of performance gains you might
    achieve if you want to take the time to optimize by hand. I was able to get the
    collider app to perform up to 36 fps in the Chrome profiler ([Figure 9-24](#figure9-24)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09024](Images/f09024.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-24: Hand optimized collider app running in Chrome'
  prefs: []
  type: TYPE_NORMAL
- en: Firefox had an even higher frame rate of 52 fps ([Figure 9-25](#figure9-25)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f09025](Images/f09025.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-25: Hand optimized collider app running in Firefox'
  prefs: []
  type: TYPE_NORMAL
- en: You can see the product of my hand optimization efforts at [https://wasmbook.com/collide.html](https://wasmbook.com/collide.html)and
    the WAT code at [https://wasmbook.com/collide.wat](https://wasmbook.com/collide.wat).
    I ran the Binaryen optimizer on my finely tuned code, and it actually slowed it
    down by a few fps. Binaryen is constantly improving their optimized output. Results
    may be different by the time you read this.
  prefs: []
  type: TYPE_NORMAL
- en: Logging Performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the simplest ways to log performance from a JavaScript app is by using
    the `Date` class and the `console.log` function. WebAssembly can’t write to the
    console without using JavaScript. For this reason, we’ll need to use JavaScript
    to log the performance of our WebAssembly and JavaScript code to the console.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the overhead involved in making many calls from our JavaScript
    into the WebAssembly module. We’ll create a WebAssembly module with a few small
    functions that we can call repeatedly from JavaScript. Create a file named *mod_and.wat*
    file and add the code in [Listing 9-18](#listing9-18).
  prefs: []
  type: TYPE_NORMAL
- en: '**mod_and.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-18: Compare performance of remainder versus bitwise AND'
  prefs: []
  type: TYPE_NORMAL
- en: There are two functions in this module, a `$mod` function that finds the remainder
    of a division by `1000` and a `$and` function that uses a bitwise AND mask. Compile
    the *mod_and.wat* file using `wat2wasm`, and optimize it using `wasm-opt`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to create a JavaScript function to run this WAT module and test
    it against the equivalent JavaScript code. Create a new file named *mod_and.js*
    and add the code in [Listing 9-19](#listing9-19).
  prefs: []
  type: TYPE_NORMAL
- en: '**mod_and.js**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-19: Recording the runtime with `Date.now` and `console.log`'
  prefs: []
  type: TYPE_NORMAL
- en: Before running each block of code, we set a variable `start_time` to `Date.now()`.
    Doing so sets the `start_time` variable to the current time in milliseconds. When
    we complete the code, we log `Date.now``() - start_time`, which gives us the runtime
    of our test in milliseconds. We’ll do this for our WebAssembly module and our
    JavaScript code to compare the two.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have our *mod_and.js* function, we can run it using the following
    `node` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[Listing 9-20](#listing9-20) shows the output after running *mod_and.js*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-20: Output from *mod_and.js*'
  prefs: []
  type: TYPE_NORMAL
- en: The `mod` function took 29 milliseconds to run four million times. The `and`
    function took 23 milliseconds to run four million times. The JavaScript version
    only took 4 milliseconds to run four million times. So if WebAssembly is so fast,
    why did it take between five and seven times as long to run those functions? The
    problem is that calls between JavaScript and WebAssembly have some overhead. Calling
    a small function four million times also incurs the cost of that overhead four
    million times. Let’s rewrite our code to execute our functions a few million times
    from within the WebAssembly rather than from a loop in the JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: First, we’ll rewrite our WebAssembly module to include the loop inside the module
    instead of inside the JavaScript. Create a new WAT file named *mod_and_loop.wat*
    and add the code in [Listing 9-21](#listing9-21).
  prefs: []
  type: TYPE_NORMAL
- en: '**mod_and_loop.wat**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-21: Looping version of the bitwise AND/modulo functions'
  prefs: []
  type: TYPE_NORMAL
- en: These functions do the same tasks as the functions in the original, but the
    program runs them 100 million times. We’ll need to change the JavaScript file
    to call these functions once and to run the JavaScript 100 million times. That
    way, we can compare the performance with the WebAssembly module, which we earlier
    changed to execute our function 100 million times. Create a new function named
    *mod_and_loop.js* and add the code in [Listing 9-22](#listing9-22).
  prefs: []
  type: TYPE_NORMAL
- en: '**mod_and_loop.js**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-22: JavaScript that runs the `and_loop`, `mod_loop`, and comparable
    JavaScript'
  prefs: []
  type: TYPE_NORMAL
- en: We call the `mod_loop` and the `and_loop` functions, recording the time each
    loop took to execute. Next, we run our loop where we perform a modulo 100 million
    times and record how long that took. If we compile and optimize our WebAssembly
    module and then run *mod_and_loop.js* using `node`, we should see something like
    the output in [Listing 9-23](#listing9-23).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-23: Output from *mod_and_loop.js*'
  prefs: []
  type: TYPE_NORMAL
- en: Now the WebAssembly is 67 percent faster than the same JavaScript code. It was
    somewhat disappointing that the bitwise AND didn’t perform much better than a
    modulo, as I had hoped it would. However, we now know how to do the simplest performance
    test using `console.log` in conjunction with `Date.now()`.
  prefs: []
  type: TYPE_NORMAL
- en: More Sophisticated Testing with benchmark.js
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you want to make your testing a bit more sophisticated than just using logs
    and `Date.now`, you can install a performance testing module, such as *benchmark.js*.
    Earlier in [Listing 9-10](#listing9-10), we created a WebAssembly function that
    multiplied by 16 and then divided by 8, and ran it through `wasm-opt` to see how
    Binaryen would optimize the code for us. The optimizer swapped the multiplication
    actions with a shift but didn’t swap in a shift for the divide. It also rearranged
    the division and the multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s test several versions of this WebAssembly module, including the original
    and the version generated by the optimizer, to see whether it’s possible to outdo
    the optimizer with a bit of effort. We’ll use *benchmark.js* to test the performance
    of all of these functions. Create a new WAT file named *pow2_test.wat* and add
    the code in [Listing 9-24](#listing9-24).
  prefs: []
  type: TYPE_NORMAL
- en: '**pow2_test.wat (part 1 of 5)**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-24: The beginning of the module with the original function'
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 9-24](#listing9-24) shows the original version of our power-of-2 test,
    where we multiplied by 16 and divided by 8\.'
  prefs: []
  type: TYPE_NORMAL
- en: The next function, in [Listing 9-25](#listing9-25), runs the division before
    the multiplication. I wanted to test this because `wasm-opt` swapped the multiplication
    and division functions, and I was curious to know whether that had a positive
    effect on the function’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: '**pow2_test.wat (part 2 of 5)**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-25: Swap the division and multiplication'
  prefs: []
  type: TYPE_NORMAL
- en: The next function, in [Listing 9-26](#listing9-26), uses a shift for both power-of-2
    multiplication and division. We also use the order inserted by the optimizer,
    where the division happens before the multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: '**pow2_test.wat (part 3 of 5)**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-26: Change the multiply and divide expressions to binary shifts'
  prefs: []
  type: TYPE_NORMAL
- en: Next, in [Listing 9-27](#listing9-27), we use a shift for both division and
    multiplication, but this time we don’t change the order of the division and multiplication
    from the original code.
  prefs: []
  type: TYPE_NORMAL
- en: '**pow2_test.wat (part 4 of 5)**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-27: The original order with multiply before divide'
  prefs: []
  type: TYPE_NORMAL
- en: This next function, in [Listing 9-28](#listing9-28), is the version of the code
    produced by `wasm-opt` with the `-O3` flag.
  prefs: []
  type: TYPE_NORMAL
- en: '**pow2_test.wat (part 5 of 5)**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-28: The `wasm-opt` optimized version of the function'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can compile this module with `wat2wasm`, but we should *not* optimize
    it, because we’re trying to test the WAT code as it is without modifications from
    the optimizer. Next, we need to create our *benchmark.js* code. First, we’ll need
    to install the *benchmark.js* module using `npm`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Now we can write a JavaScript program to test the WebAssembly functions using
    *benchmark.js*. Let’s break this program into several chunks and walk through
    them a piece at a time. Add the code in [Listing 9-29](#listing9-29) to *benchmark_test.js*.
  prefs: []
  type: TYPE_NORMAL
- en: '**benchmark_test.js**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-29: The first part of the *benchmark_test.js* JavaScript file'
  prefs: []
  type: TYPE_NORMAL
- en: First, we require 1 the `benchmark` module, and then create a new `suite` 2
    object from that module. We require the `fs` 3 module and use that to load the
    WebAssembly module into a `byte` array. We then define a series of variables to
    hold the functions in the WebAssembly module. We log out a `rainbow` 4 color separator
    that displays `RUNNING BENCHMARK` to make it easier to spot where the benchmark
    begins as we scroll back up through our stats. If you’re like me, you might change
    the module as you benchmark it, in which case, it can be helpful to have a conspicuous
    place where the benchmarking begins.
  prefs: []
  type: TYPE_NORMAL
- en: In [Listing 9-30](#listing9-30), we’ll add a function we can call to initialize
    and run the benchmark suite. Add the following function to *benchmark_test.js*.
  prefs: []
  type: TYPE_NORMAL
- en: '**benchmark_test.js**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-30: The `init_benchmark` function'
  prefs: []
  type: TYPE_NORMAL
- en: We define the `init_benchmark()` 1 function, which calls `suite.add`2 from the
    benchmark module for each of the functions in our WebAssembly module. Using `suite.add`
    tells the benchmark suite to test that function and log the results with the string
    passed as the second parameter. The `suite.on` function sets an event callback
    for different events that occur during a benchmark test. The first call to `suite.on`
    3 sets the callback for each cycle, which will output the function we tested and
    the stats for that test. The next call to `suite.on` 4 sets the callback for the
    completion of the benchmark test, which will use the `filter` 5 method to `log`
    6 the fastest and slowest functions. We then filter on `'successful'` 7 to get
    an array of all the functions that ran successfully. We `sort` 8 that array by
    the `mean` (average) runtime for that cycle. That sorts the cycles from the fastest
    to the slowest runtime. We can then loop 9 through each of those cycles, printing
    them from fastest to slowest. At the end of this function, we `run` a the `suite`.
  prefs: []
  type: TYPE_NORMAL
- en: With the `init_benchmark` function defined, in [Listing 9-31](#listing9-31)
    we create the asynchronous IIFE to instantiate our WebAssembly module and call
    `init_benchmark`.
  prefs: []
  type: TYPE_NORMAL
- en: '**benchmark_test.js**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-31: Asynchronous IIFE instantiates WebAssembly and runs *benchmark**.js**.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we `instantiate` 1 our WebAssembly module and set all of the functions
    2 we’ll be calling from *benchmark.js*. We then run *benchmark.js* by calling
    `init_benchmark()` 3. Now we can run our application using `node` with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 9-26](#figure9-26) shows the output.'
  prefs: []
  type: TYPE_NORMAL
- en: '![f09026](Images/f09026.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-26: Output from *benchmark_test.js*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Interestingly, the slowest of these functions was the `wasm-opt` optimized
    version: the original version and the `wasm-opt` optimized version executed in
    about the same time. The fastest run was the code where we replaced the `i32.mul`
    and `i32.div_u` operations with shifts, and reordered the calls in the way that
    the `wasm-opt` tool rearranged them. This illustrates that you can’t assume that
    `wasm-opt` (or any programmatic optimizer) will always give you the highest-performing
    code. Running performance tests on your application is always advisable.'
  prefs: []
  type: TYPE_NORMAL
- en: Comparing WebAssembly and JavaScript with --print-bytecode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we’ll geek out on low-level bytecode. It’s fun and interesting
    to look at what the JavaScript JIT generates. It’s also fascinating to compare
    with WebAssembly and intriguing to think about how to improve performance. If
    this topic doesn’t interest you, feel free to skip ahead to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s briefly look at how to make a better comparison between WebAssembly code
    and JavaScript. V8 compiles JavaScript into an IR bytecode, which looks a lot
    like an assembly language or WAT. IR uses registers and an accumulator but isn’t
    machine specific. We can use IR to compare the JavaScript code after it runs through
    the JIT compiler with our WebAssembly code. Because they’re both low-level bytecodes,
    it gives us a better *apples to apples* comparison to look at. But keep in mind
    that the JavaScript code will need to be parsed and compiled into this bytecode
    at runtime, whereas WebAssembly is compiled ahead of time.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s create a small JavaScript program and use the `node --print-bytecode`
    flag to look at the bytecode generated from that JavaScript. Create a JavaScript
    file named *print_bytecode.js* and add the code in [Listing 9-32](#listing9-32).
  prefs: []
  type: TYPE_NORMAL
- en: '**print_bytecode.js**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: // if we don't call this, the function is removed in dce check
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-32: The `bytecode_test` function that we’ll execute with the `--print-bytecode`
    flag'
  prefs: []
  type: TYPE_NORMAL
- en: This `bytecode_test` function is similar to the code that we performance tested
    in [Listing 9-22](#listing9-22). It’s a simple `for`loop that takes the modulo
    of the `i` counter, stores it in `x`, and then returns `99`. It doesn’t really
    do anything useful, but I wanted to work with a function that is easy to understand,
    so we can compile it into bytecode.
  prefs: []
  type: TYPE_NORMAL
- en: We then call the function in addition to defining it; otherwise, V8 will remove
    it as a part of DCE. We can then run the `node` command in [Listing 9-33](#listing9-33)
    to print the bytecode.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-33: Run `node` with the `--print-bytecode` flag'
  prefs: []
  type: TYPE_NORMAL
- en: We pass the `--print-bytecode` flag to `node` to instruct it to print the bytecode.
    We also pass in the `--print-bytecode-filter` flag, setting it to the name of
    our function to print that function’s bytecode. If we don’t include the filter
    flag, the output will be way more bytecode than we want to look at. Finally, we
    pass `node` the name of the JavaScript file. Run *print_bytecode.js* with the
    flags from [Listing 9-33](#listing9-33), and you should get the output in [Listing
    9-34](#listing9-34).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-34: Bytecode output from *print_bytecode.js*'
  prefs: []
  type: TYPE_NORMAL
- en: The right side of the output in [Listing 9-34](#listing9-34) has the opcodes
    for the IR. Here I’ve listed those opcodes and added WAT-style comments on the
    right side. Instead of a stack machine, the bytecode that the V8 engine generated
    is for a virtual register machine with an accumulator register. The *accumulator*
    is where this virtual machine performs its calculations. Take a quick look at
    the code in [Listing 9-35](#listing9-35), which V8 generated.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Listing 9-35: Opcodes with an explanation after the *;;* characters'
  prefs: []
  type: TYPE_NORMAL
- en: The IR for V8 uses an accumulator. Accumulator machines have one general-purpose
    register where the accumulator does all of the math instead of doing it in the
    other registers. The opcodes with the letter `a` in them usually refer to the
    accumulator, and `r` usually refers to a register. For example, the first opcode
    after `StackCheck` is `LdaZero`, which loads (`Ld`) the accumulator (`a`) with
    0 (`Zero`). Then the line `Star` `r0` stores (`St`) the value in the accumulator
    (`a`) into a register (`r`) and then passes in `r0` to define that register. It
    does this because the IR can’t set `Register0` to a value of 0 directly; instead,
    it needs to load that value into the accumulator and then move the value in the
    accumulator into `Register0`. Later in the code, you see `LdaSmi.ExtraWide`. This
    loads (`Ld`) the accumulator (`a`) with a small integer (`Smi`) that uses all
    32 bits (`ExtraWide`). If you loaded a number that used 16 bits, it would have
    displayed `Wide` instead of `ExtraWide`, and 8 bits wouldn’t have anything following
    `LdaSmi`. The `TestLessThan` opcode compares the value in the register specified
    (`r1`) with the value in the accumulator. The line `JumpIfFalse` `[22]` checks
    whether the `TestLessThan` resulted in false, and if so, jumps 22 bytes forward.
  prefs: []
  type: TYPE_NORMAL
- en: The `--print-bytecode` flag can be a useful tool to help performance tune your
    JavaScript. If you’re familiar with WAT or assembly, it’s not difficult to understand.
    It can also be useful in comparing your WAT code with JavaScript for performance
    tuning reasons in both parts of your WebAssembly application.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we discussed several tools for evaluating the performance of
    our WAT code. We also compared our code to the performance of equivalent JavaScript.
    Then we explored several strategies for improving the performance of our WebAssembly
    module.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at the profiler in the Chrome web browser and discussed the Summary
    page and the JS Heap Memory section, which provided information about memory spikes
    and garbage collection. We also looked at the fps in our profile, which is an
    excellent way to determine the performance of a game or UI heavy application.
  prefs: []
  type: TYPE_NORMAL
- en: We used the Firefox profiler to investigate our collision detection application.
    The Firefox profiler offers a few extra tools, including the Call Tree and the
    JS Flame Chart. We tracked down the WAT function that was called by using the
    `wasm-function[index]` listed in the profiler.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we installed *Binaryen.js* and used the `wasm-opt` tool to optimize our
    WebAssembly module for either download size or peak performance. We also disassembled
    it back into WAT code, so we could view the changes the optimizer made.
  prefs: []
  type: TYPE_NORMAL
- en: We then looked into a variety of strategies for improving the peak performance
    of our application, including inlining functions, replacing multiplication and
    division with bit-shifts, and combining constants. We discussed DCE, which the
    optimizer performs to remove any unused functions from our module.
  prefs: []
  type: TYPE_NORMAL
- en: We created a JavaScript version of our application to compare the performance
    of JavaScript against that of the WebAssembly module.
  prefs: []
  type: TYPE_NORMAL
- en: After using the profiler throughout most of this chapter, we looked at other
    methods for determining our module’s performance. Using `console.log` and `Date.now`
    is the simplest method of measuring performance in an application, and the testing
    suite *benchmark.js* provides more detailed information for evaluating the performance
    of different functions. Just for fun, we printed the V8 IR bytecode to evaluate
    JavaScript code further and compared it with WebAssembly. In the next chapter,
    you’ll learn about debugging the WebAssembly modules.
  prefs: []
  type: TYPE_NORMAL
