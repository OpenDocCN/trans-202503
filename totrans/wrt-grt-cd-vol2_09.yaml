- en: '**9**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**POINTER DATA TYPES**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/common01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Pointers are the data type equivalent of a `goto` statement. Used carelessly,
    they can turn a robust and efficient program into a buggy and inefficient junk
    pile. Unlike `goto` statements, however, pointers can be difficult to avoid in
    many common programming languages. There are no “pointers considered harmful”
    papers in academic journals like Dijkstra’s “Go To Statement Considered Harmful”
    letter.^([1](footnotes.xhtml#ch9fn1)) Many languages, like Java and Swift, attempt
    to restrict pointers, but several popular languages still use them, so great programmers
    need to be able to deal with them. To that end, this chapter will discuss:'
  prefs: []
  type: TYPE_NORMAL
- en: The memory representation of pointers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How high-level languages implement pointers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamic memory allocation and its relationship to pointers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pointer arithmetic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How memory allocators work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Garbage collection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common pointer problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By understanding the low-level implementation and use of pointers, you’ll be
    able to write high-level code that is more efficient, safer, and more readable.
    This chapter will provide the information you need to use pointers appropriately
    and avoid the problems normally associated with them.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.1 The Definition of a Pointer**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A pointer is simply a variable whose value refers to some other object. High-level
    languages like Pascal and C/C++ hide the simplicity of pointers behind a wall
    of abstraction. HLL programmers generally rely on the high degree of abstraction
    provided by the language because they don’t want to know what’s going on behind
    the scenes. They just want a “black box” that produces predictable results. In
    the case of pointers, though, the abstraction may be *too* effective; pointers
    seem intimidating and opaque to many programmers. Well, fear not! Pointers are
    actually easy to deal with.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand how pointers work, I’ll use the array data type as an example.
    Consider the following array declaration in Pascal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Even if you don’t know Pascal, the concept here is easy to understand. `M` is
    an array of 1,024 integers, indexed from `M[0]` to `M[1023]`. Each array element
    can hold an independent integer value. In other words, this array gives you 1,024
    different integer variables, each of which you access via an array index (the
    variable’s sequential position within the array) rather than by name.
  prefs: []
  type: TYPE_NORMAL
- en: 'The statement `M[0] := 100;` stores the value `100` into the first element
    of the array `M`. Now consider the following two statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'These two statements do the same thing as `M[0] := 100;`. In fact, you can
    use any integer expression producing a value in the range `0..1023` as an index
    into this array. The following statements still perform the same operation as
    our earlier statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'But now look at the following statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: At first glance, these statements might seem confusing; however, they perform
    the same operation as in the previous examples. The first statement stores `0`
    into array element `M[1]`. The second statement fetches the value of `M[1]`, which
    is `0`, and uses that value to determine where to store the value `100`.
  prefs: []
  type: TYPE_NORMAL
- en: If you think this example is reasonable—perhaps bizarre, but usable nonetheless—then
    you’ll have no problems with pointers, because `M[1]` is a pointer! Well, not
    really, but if you were to change `M` to “memory” and treat each element of this
    array as a separate memory location, then it would meet the definition of a pointer—that
    is, a memory variable whose value is the address of some other memory object.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.2 Pointer Implementation in High-Level Languages**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although most languages implement pointers using memory addresses, a pointer
    is actually an abstraction of a memory address. Therefore, a language could define
    a pointer using any mechanism that maps the value of the pointer to the address
    of some object in memory. Some implementations of Pascal, for example, use offsets
    from a fixed memory address as pointer values. Some languages (including dynamic
    languages like Lisp) might actually implement pointers by using *double indirection*;
    that is, the pointer object contains the address of some memory variable whose
    value is the address of the object to access. This approach may seem somewhat
    convoluted, but it offers certain advantages in a complex memory management system,
    making it easier and more efficient to reuse blocks of memory. However, for simplicity’s
    sake we’ll assume that, as defined earlier, a pointer is a variable whose value
    is the address of some other object in memory. This is a safe assumption for many
    of the high-performance HLLs you’re likely to encounter, such as C, C++, and Delphi.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can indirectly access an object using a pointer with two 80x86 machine
    instructions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now consider the double-indirect pointer implementation described earlier.
    Access to data via double indirection is less efficient than the straight pointer
    implementation because it takes an extra machine instruction to fetch the data
    from memory. This isn’t obvious even in an HLL like C/C++ or Pascal, where using
    double indirection is explicit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This is syntactically similar to single indirection. In assembly language,
    however, you’ll see the extra work involved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Contrast this with the two earlier assembly instructions to access an object
    using single indirection. Because double indirection requires 50 percent more
    code (and twice as many slow memory accesses) than single indirection, you can
    see why many languages implement pointers using single indirection. To verify
    this, consider the machine code produced by a couple of different compilers when
    processing the following C code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the GCC output for the PowerPC processor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in this PowerPC example, fetching the value using double indirection
    takes one more instruction than it does using single indirection. Of course, the
    total number of instructions is rather large here, so this extra instruction doesn’t
    contribute as much to the execution time as it does on the 80x86 where fewer instructions
    are involved. Consider the following GCC code output for the 32-bit 80x86:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we saw with the PowerPC code, double indirection requires extra machine instructions,
    so programs using double indirection will be larger and slower.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that the PowerPC instruction sequences are twice as long as the 80x86
    instruction sequences.^([2](footnotes.xhtml#ch9fn2)) One positive way of viewing
    this is that double indirection has less of an impact on the execution time of
    the PowerPC code than it does on the 80x86 code. That is, the extra instruction
    represents only 13 percent of the total in the PowerPC code, versus 25 percent
    of the total in the 80x86 code.^([3](footnotes.xhtml#ch9fn3)) This brief example
    should demonstrate that execution time and code space are not processor independent.
    Bad coding practices (such as using double indirection when it’s not required)
    can have more impact on some processors than others.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.3 Pointers and Dynamic Memory Allocation**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Pointers typically reference anonymous variables that you allocate on the heap
    using memory allocation/deallocation functions like `malloc()`/`free()`, `new()`/`dispose()`,
    and `new()`/`delete()` (`std::make_unique` in C++17). Objects that you allocate
    on the heap are known as *anonymous variables* because you refer to them by their
    address rather than by name. While the pointer variable may have a name, that
    name applies to the pointer’s data (an address), not the object referenced by
    this address.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*The heap, as [Chapter 7](ch07.xhtml#ch07) explained, is a region in memory
    reserved for dynamic storage allocation.*'
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic languages handle memory allocation and deallocation operations in a
    transparent, automatic fashion. The application simply uses the dynamic data and
    leaves it up to the runtime system to allocate memory as needed and reuse storage
    for a different purpose when it is no longer needed. Without the need to explicitly
    allocate and deallocate memory for pointer variables, applications written in
    dynamic languages (such as AWK or Perl) are usually much easier to program and
    often contain far fewer errors. But this comes at the cost of efficiency, as they
    often run much slower than programs written in other languages. Conversely, traditional
    languages (such as C/C++) that require programmers to explicitly manage memory
    often produce more efficient applications, although the memory management code
    is prone to a higher percentage of defects due to its additional complexity.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.4 Pointer Operations and Pointer Arithmetic**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most HLLs that provide a pointer data type let you assign addresses to pointer
    variables, compare pointer values for equality or inequality, and indirectly reference
    an object via a pointer. Some languages also allow additional operations, as you’ll
    see in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many programming languages enable you to do limited arithmetic with pointers.
    At the very least, these languages allow you to add an integer constant to, or
    subtract one from, a pointer. To understand the purpose of these two arithmetic
    operations, recall the syntax of the `malloc()` function in the C standard library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The parameter you pass `malloc()` specifies the number of bytes of storage
    to allocate. A good C programmer generally supplies an expression like `sizeof(int)`
    as this parameter. The `sizeof()` function returns the number of bytes needed
    by its single parameter. Therefore, `sizeof(int)` tells `malloc()` to allocate
    at least enough storage for an `int` variable. Now consider the following call
    to `malloc()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If the size of an integer is 4 bytes, this call to `malloc()` will allocate
    storage for 32 bytes, at consecutive addresses in memory (see [Figure 9-1](ch09.xhtml#ch9fig1)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/09fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 9-1: Memory allocation via malloc(sizeof(int) * 8 )*'
  prefs: []
  type: TYPE_NORMAL
- en: The pointer that `malloc()` returns contains the address of the first integer
    in this set, so the C program can directly access only the very first of these
    eight integers. To access the individual addresses of the other seven integers,
    you need to add an integer offset to that *base* address. On machines that support
    byte-addressable memory (such as the 80x86), the address of each successive integer
    in memory is the address of the previous integer plus the integer size. For example,
    if a call to the C standard library `malloc()` routine returns the memory address
    `$0300_1000`, then the eight integers that `malloc()` allocates will reside at
    the memory addresses shown in [Table 9-1](ch09.xhtml#ch9tab1).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 9-1:** Integer Addresses Allocated for Base Address `$0300_1000`'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Integer** | **Memory address** |'
  prefs: []
  type: TYPE_TB
- en: '| First | `$0300_1000..$0300_1003` |'
  prefs: []
  type: TYPE_TB
- en: '| Second | `$0300_1004..$0300..1007` |'
  prefs: []
  type: TYPE_TB
- en: '| Third | `$0300_1008..$0300_100b` |'
  prefs: []
  type: TYPE_TB
- en: '| Fourth | `$0300_100c..$0300_100f` |'
  prefs: []
  type: TYPE_TB
- en: '| Fifth | `$0300_1010..$0300_1013` |'
  prefs: []
  type: TYPE_TB
- en: '| Sixth | `$0300_1014..$0300..1017` |'
  prefs: []
  type: TYPE_TB
- en: '| Seventh | `$0300_1018..$0300_101b` |'
  prefs: []
  type: TYPE_TB
- en: '| Eighth | `$0300_101c..$0300_101f` |'
  prefs: []
  type: TYPE_TB
- en: '**9.4.1 Adding an Integer to a Pointer**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Because the eight integers in the previous section are exactly 4 bytes apart,
    you add 4 to the address of the first integer to obtain the address of the second
    integer. Likewise, the address of the third integer is the address of the second
    integer plus 4 bytes, and so on. In assembly language, you could access these
    eight integers using code like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Notice the use of the 80x86 indexed addressing mode to access the eight integers
    that `malloc()` allocates. The EAX register maintains the base (first) address
    of the eight integers that this code allocates, and the constant in the addressing
    mode of the `mov()` instruction indicates the offset of the specific integer from
    this base address.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most CPUs use byte addresses for memory objects. Therefore, when a program
    allocates multiple copies of some *n*-byte object in memory, the objects won’t
    begin at consecutive memory addresses; instead, they’ll appear in memory at addresses
    that are *n* bytes apart. Some machines, however, don’t allow a program to access
    memory at any arbitrary address; they require it to access data on address boundaries
    that are a multiple of a word, a double word, or even a quad word. Any attempt
    to access memory on some other boundary will raise an exception and potentially
    halt the application. If an HLL supports pointer arithmetic, it must take this
    fact into consideration and provide a generic pointer arithmetic scheme that’s
    portable across different CPU architectures. The most common solution that HLLs
    use when adding an integer offset to a pointer is to multiply that offset by the
    size of the object that the pointer references. That is, if you have a pointer
    `p` to a 16-byte object in memory, then `p + 1` points 16 bytes beyond where `p`
    points. Likewise, `p + 2` points 32 bytes beyond the address contained in `p`.
    As long as the size of the data object is a multiple of the required alignment
    size (which the compiler can enforce by adding padding bytes, if necessary), this
    scheme avoids problems on architectures that require aligned data access. Consider,
    for example, the following C/C++ code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This example demonstrates how C/C++ uses pointer arithmetic to specify an integer-sized
    offset from the base pointer address.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that the addition operator only makes sense between a
    pointer and an integer value. For example, in C/C++ you can indirectly access
    objects in memory using an expression like `*(p + i)` (where `p` is a pointer
    to an object and `i` is an integer value). It doesn’t make sense to add two pointers
    together. Similarly, it isn’t logical to add other data types with a pointer—for
    example, adding a floating-point value to a pointer. (What does it mean to reference
    the data at some base address plus 1.5612?) Operations on pointers involving strings,
    characters, and other data types don’t make much sense, either. Integers (signed
    and unsigned) are the only reasonable values to add to a pointer.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, not only can you add an integer to a pointer, but you can
    also add a pointer to an integer and the result is still a pointer (both `p +
    i` and `i + p` are legal). This is because addition is *commutative*—the order
    of the operands does not affect the result.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.4.2 Subtracting an Integer from a Pointer**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Subtracting an integer from a pointer references a memory location immediately
    before the base address held in the pointer. However, subtraction is not commutative,
    and subtracting a pointer from an integer is not a legal operation (`p - i` is
    legal, but `i - p` is not).
  prefs: []
  type: TYPE_NORMAL
- en: 'In C/C++, `*(p - i)` accesses the `i`th object immediately before the object
    at which `p` points. In 80x86 assembly language, as in assembly on many processors,
    you can also specify a negative constant offset when using an indexed addressing
    mode. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind, 80x86 assembly language uses byte offsets, not object offsets
    (as C/C++ does). Therefore, this statement loads into EAX the double word in memory
    immediately preceding the memory address in EBX.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.4.3 Subtracting a Pointer from a Pointer**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In contrast to addition, it makes sense to subtract the value of one pointer
    variable from another. Consider the following C/C++ code, which proceeds through
    a string of characters looking for the first `e` character that follows the first
    `a` that it finds (you could use the result of such a calculation, for example,
    to extract a substring):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Subtracting one pointer from the other produces the number of data objects that
    exist between them (in this case, `ePtr` and `aPtr` point at characters, so this
    subtraction produces the number of characters, or bytes if 1-byte characters,
    between the two pointers).
  prefs: []
  type: TYPE_NORMAL
- en: The subtraction of two pointer values makes sense only if they both reference
    the same data structure (for example, an array, string, or record) in memory.
    Although assembly language will allow you to subtract two pointers that point
    at completely different objects in memory, their difference will probably have
    very little meaning.
  prefs: []
  type: TYPE_NORMAL
- en: For pointer subtraction in C/C++, the base types of the two pointers must be
    identical (that is, the two pointers must contain the address of two objects whose
    types are identical). This restriction exists because pointer subtraction in C/C++
    produces the number of objects, not the number of bytes, between the two pointers.
    Computing the number of objects between a byte in memory and a double word in
    memory wouldn’t make any sense. The result would be neither a byte count nor a
    double-word count.
  prefs: []
  type: TYPE_NORMAL
- en: The subtraction of two pointers can return a negative number if the left pointer
    operand is at a lower memory address than the right pointer operand. Depending
    on your language and its implementation, you might need to take the absolute value
    of the result if you’re interested only in the distance between the two pointers
    and you don’t care which pointer contains the greater address.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.4.4 Comparing Pointers**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Comparisons are another set of operations that make sense for pointers. Almost
    every language that supports pointers allows you to compare two pointers to see
    whether or not they are equal. A pointer comparison tells you whether the pointers
    reference the same object in memory. Some languages (such as assembly and C/C++)
    also let you compare two pointers to see if one pointer is less than or greater
    than the other. Like subtracting two pointers, comparing two pointers makes sense
    only if they have the same base type and point into the same data structure. If
    one pointer is less than another, this tells you that the pointer references an
    object within the data structure that appears before the object whose address
    the second pointer contains. The converse is true for the greater-than comparison.
    This short example in C demonstrates pointer comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'At the (x86-64) machine language level, addresses are simply 64-bit quantities,
    so the machine code can compare these pointers as though they’re 64-bit integer
    values. Here’s the x86-64 assembly code that Visual C++ emits for this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Other than the trickery behind computing `true` (`1`) or `false` (`0`) after
    comparing the two addresses, this code is a very straightforward compilation to
    machine code.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.4.5 Using Logical AND/OR Operations with Pointers**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'On byte-addressable machines, it makes sense to logically AND an address with
    a bit string value, because masking off the low-order (LO) bits in an address
    is an easy way to align it on a boundary that is a power of 2\. For example, if
    the 32-bit 80x86 EBX register contains an arbitrary address, the following assembly
    language statement rounds the pointer in EBX down to an address that is a multiple
    of 4 bytes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This operation is very useful when you want to ensure that memory is accessed
    on a nice memory boundary. For example, suppose you have a memory allocation function
    that can return a pointer to a block of memory that begins at an arbitrary byte
    boundary. To ensure that the data structure the pointer points to begins on a
    double word (`dword`) boundary, you can use assembly code like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This code allocates an extra 3 bytes when calling `malloc()` so that it can
    add 0, 1, 2, or 3 to the address that `malloc()` returns in order to align the
    object on a `dword` address. On return from `malloc()`, the code adds 3 to the
    address and, if it wasn’t already a multiple of 4, the address will cross the
    next `dword` boundary. Using the AND instruction reduces the address back to the
    previous `dword` boundary (either the next `dword` boundary, or the original address
    if it was already `dword`-aligned).
  prefs: []
  type: TYPE_NORMAL
- en: '**9.4.6 Using Other Operations with Pointers**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Beyond addition, subtraction, comparison, and possibly AND or OR operations,
    very few arithmetic operations make sense with pointer operands. What does it
    mean to multiply a pointer by some integer value (or another pointer)? What does
    division of pointers mean? What do you get when you shift a pointer to the left
    by one bit position? You could make up some sort of definition for these operations,
    but considering the original arithmetic definitions, these operations just aren’t
    reasonable for pointers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several languages (including C/C++ and Pascal) restrict other pointer operations.
    There are several good reasons for limiting what a programmer can do with a pointer,
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Code involving pointers is notoriously difficult to optimize. By limiting the
    number of pointer operations, the compiler can make assumptions about the code
    that it could not otherwise. This allows the compiler (in theory) to produce better
    machine code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Code containing pointer manipulations is more likely to be defective. Limiting
    programmers’ options in this area helps prevent pointer abuse, and leads to more
    robust code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*The section “Common Pointer Problems” on [page 286](ch09.xhtml#page_286) describes
    the most serious of these errors and ways to avoid them in your code.*'
  prefs: []
  type: TYPE_NORMAL
- en: Some pointer operations—particularly certain arithmetic operations—are not portable
    across CPU architectures. For example, on some segmented architectures (such as
    the original 16-bit 80x86), subtracting the values of two pointers may not produce
    an expected result.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The proper use of pointers can help create efficient programs, but the converse
    is also true: the improper use of pointers can destroy program efficiency. By
    limiting the number of pointer operations it supports, a language can prevent
    the kinds of code inefficiencies that often result from the gratuitous use of
    pointers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The major problem with these justifications for limiting pointer operations
    is that most exist to protect programmers from themselves, and indeed, many programmers
    (especially beginners) benefit from the discipline these restrictions enforce.
    However, for careful programmers who do not abuse pointers, these restrictions
    may eliminate some opportunities for writing great code. Therefore, languages
    that provide a rich set of pointer operations, like C/C++ and assembly, are popular
    with advanced programmers who prefer absolute control over the use of pointers
    in their programs.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.5 A Simple Memory Allocator Example**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To demonstrate the performance and memory costs of using dynamically allocated
    memory and pointers to it, this section presents a simple memory allocation/deallocation
    system. By considering the operations associated with memory allocation and deallocation,
    you’ll be more aware of their costs and better equipped to use them in an appropriate
    way.
  prefs: []
  type: TYPE_NORMAL
- en: An extremely simple (and fast) memory allocation scheme would maintain a single
    variable that forms a pointer into the heap region of memory. Whenever a memory
    allocation request comes along, the system makes a copy of this heap pointer to
    return to the application. The heap management routines add the size of the memory
    request to the address held in the pointer variable and verify that the memory
    request won’t try to use more memory than is available in the heap. (Some memory
    managers return an error indication, like a `NULL` pointer, when the memory request
    is too great; others raise an exception.) The problem with this simple memory
    management scheme is that it wastes memory because there’s no *garbage collection*
    mechanism for the application to free the memory so it can be reused later. Garbage
    collection is one of the main purposes of a heap management system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only catch is that supporting garbage collection requires some overhead.
    The memory management code will need to be more sophisticated, will take longer
    to execute, and will require some additional memory to maintain the internal data
    structures the heap management system uses. Consider an easy implementation of
    a heap manager that supports garbage collection on a 32-bit system. This simple
    system maintains a (linked) list of free memory blocks. Each free memory block
    in the list requires two `dword` values: one specifying the size of the free block,
    and the other containing the address of the next free block in the list (that
    is, the link); see [Figure 9-2](ch09.xhtml#ch9fig2).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/09fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 9-2: Heap management using a list of free memory blocks*'
  prefs: []
  type: TYPE_NORMAL
- en: The system initializes the heap with a `NULL` link pointer, and the size field
    contains the size of the heap’s entire free space. When a memory allocation request
    comes along, the heap manager searches through the list to find a free block with
    enough memory to satisfy the request. This search process is one of the defining
    characteristics of a heap manager. Some common search algorithms are first-fit
    search and best-fit search. A *first-fit search*, as its name suggests, scans
    the list of blocks until it finds the *first* block of memory large enough to
    satisfy the allocation request. A *best-fit search* scans the entire list and
    finds the *smallest* block large enough to satisfy the request. The advantage
    of the best-fit algorithm is that it tends to preserve larger blocks better than
    the first-fit algorithm, so the system is still able to satisfy larger subsequent
    allocation requests when they arrive. The first-fit algorithm, on the other hand,
    just grabs the first suitably large block it finds, even if there’s a smaller
    block that would suffice, which may limit the system’s ability to handle future
    large memory requests.
  prefs: []
  type: TYPE_NORMAL
- en: That said, the first-fit algorithm does have a couple of advantages over the
    best-fit algorithm. The most obvious is that it is usually faster. The best-fit
    algorithm has to scan through every block in the free block list in order to find
    the smallest one large enough to satisfy the allocation request (unless, of course,
    it finds a perfectly sized block along the way). The first-fit algorithm, on the
    other hand, can stop once it finds a block large enough to satisfy the request.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage to the first-fit algorithm is that it tends to suffer less
    from a degenerate condition known as *external fragmentation*. Fragmentation occurs
    after a long sequence of allocation and deallocation requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember, when the heap manager satisfies a memory allocation request, it usually
    creates two blocks of memory: one in-use block for the request, and one free block
    that contains the remaining bytes from the original block (assuming the request
    did not exactly match the block size). After operating for a while, the best-fit
    algorithm may have produced lots of leftover blocks of memory that are too small
    to satisfy an average memory request, making them effectively unusable. As these
    small fragments accumulate throughout the heap, they can end up consuming a fair
    amount of memory. This can lead to a situation where the heap doesn’t have a sufficiently
    large block to satisfy a memory allocation request even though there is enough
    total free memory available (spread throughout the heap). See [Figure 9-3](ch09.xhtml#ch9fig3)
    for an example of this condition.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/09fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 9-3: Memory fragmentation*'
  prefs: []
  type: TYPE_NORMAL
- en: There are other memory allocation strategies in addition to the first-fit and
    best-fit search algorithms. Some of these execute faster, some have less memory
    overhead, some are easy to understand (and some are very complex), some produce
    less fragmentation, and some can combine and use noncontiguous blocks of free
    memory. Memory/heap management is one of the more heavily studied subjects in
    computer science, and there’s a considerable amount of literature explaining the
    benefits of one scheme over another. For more information on memory allocation
    strategies, check out a good book on OS design.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.6 Garbage Collection**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Memory allocation is only half of the story. As mentioned earlier, the heap
    manager also has to provide a call that allows an application to free memory it
    no longer needs for future reuse—a process known as garbage collection. In C and
    HLA, for example, an application accomplishes this by calling the `free()` function.
    At first blush, `free()` might seem to be a very simple function to write. All
    it has to do is append the previously allocated and now unused block to the end
    of the free list, right? The problem with this trivial implementation of `free()`
    is that it almost guarantees that the heap will become fragmented and unusable
    in very short order. Consider the situation in [Figure 9-4](ch09.xhtml#ch9fig4).
  prefs: []
  type: TYPE_NORMAL
- en: If `free()` simply takes the block to be freed and appends it to the free list,
    the memory organization in [Figure 9-4](ch09.xhtml#ch9fig4) produces three free
    blocks. However, because these three blocks are contiguous, the heap manager should
    really combine them into a single free block, so that it will be able to satisfy
    a larger request. Unfortunately, this operation would require it to scan the free
    block list to determine if there are any free blocks adjacent to the block the
    system is freeing. While you could come up with a data structure that makes it
    easier to combine adjacent free blocks, such schemes generally add 8 or more bytes
    of overhead with each block on the heap. Whether this is a reasonable tradeoff
    depends on the average size of a memory allocation. If the applications that use
    the heap manager tend to allocate small objects, the extra overhead for each memory
    block could wind up consuming a large percentage of the heap space. However, if
    most allocations are large, the few bytes of overhead won’t matter much.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/09fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 9-4: Freeing a memory block*'
  prefs: []
  type: TYPE_NORMAL
- en: '**9.7 The OS and Memory Allocation**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The performance of the algorithms and data structures used by the heap manager
    is only one piece of the performance puzzle. The heap manager ultimately needs
    to request blocks of memory from the operating system. At one extreme, the OS
    handles all memory allocation requests directly. At the other extreme, the heap
    manager is a runtime library routine that links with your application, first requesting
    large blocks of memory from the OS and then doling out pieces of them as allocation
    requests arrive from the application.
  prefs: []
  type: TYPE_NORMAL
- en: The problem with making direct memory allocation requests to the operating system
    is that OS API calls are often very slow. This is because they generally involve
    switching between kernel mode and user mode on the CPU (which is not fast). Therefore,
    a heap manager that the OS implements directly will not perform well if your application
    makes frequent calls to the memory allocation and deallocation routines.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the high overhead of an OS call, most languages implement their own
    versions of the `malloc()` and `free()` functions within their runtime library.
    On the very first memory allocation, the `malloc()` routine requests a large block
    of memory from the OS, and the application’s `malloc()` and `free()` routines
    manage this block of memory themselves. If an allocation request comes along that
    the `malloc()` function cannot fulfill in the block it originally created, `malloc()`
    will request another large block (generally much larger than the request) from
    the OS and add that block to the end of its free list. Because the application’s
    `malloc()` and `free()` routines call the OS only occasionally, the application
    doesn’t suffer the performance hit associated with frequent OS calls.
  prefs: []
  type: TYPE_NORMAL
- en: However, keep in mind that this procedure is very implementation- and language-specific;
    it’s dangerous to assume that `malloc()` and `free()` are relatively efficient
    when writing software that requires high-performance components. The only portable
    way to ensure a high-performance heap manager is to develop your own application-specific
    set of allocation/deallocation routines. Writing such routines is beyond the scope
    of this book (and most standard heap management functions perform well for a typical
    program), but you should know you have this option.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.8 Heap Memory Overhead**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A heap manager often exhibits two types of overhead: performance (speed) and
    memory (space). Until now, this discussion has mainly dealt with the performance
    aspects, but now we’ll turn our attention to memory.'
  prefs: []
  type: TYPE_NORMAL
- en: Each block the system allocates requires some amount of overhead beyond the
    storage the application requests; at the very least, this overhead is a few bytes
    to keep track of the block’s size. Fancier (higher-performance) schemes may require
    additional bytes, but typically the overhead is between 8 and 64 bytes. The heap
    manager can keep this information in a separate internal table, or it can attach
    the block size and other memory management information directly to the block it
    allocates.
  prefs: []
  type: TYPE_NORMAL
- en: Saving this information in an internal table has a couple of advantages. First,
    it is difficult for the application to accidentally overwrite the information
    stored there; attaching the data to the heap memory blocks themselves doesn’t
    provide as much protection against this possibility. Second, putting memory management
    information in an internal data structure allows the memory manager to easily
    determine if a given pointer is valid (that is, points at some block of memory
    that the heap manager believes it has allocated).
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of attaching the control information directly to each block that
    the heap manager allocates is that it’s very easy to locate this information,
    whereas storing the information in an internal table might require a search operation.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue that affects the overhead associated with the heap manager is
    the *allocation granularity*—the minimum number of bytes the heap manager supports.
    Although most heap managers allow you to request an allocation as small as 1 byte,
    they may actually allocate some minimum number of bytes greater than 1\. Generally,
    the engineer designing the memory allocation functions chooses a granularity guaranteeing
    that any object allocated on the heap will begin at a reasonably aligned memory
    address for that object. Thus, most heap managers allocate memory blocks on a
    4-, 8-, or 16-byte boundary. For performance reasons, many heap managers begin
    each allocation on a cache line boundary, usually 16, 32, or 64 bytes. Whatever
    the granularity, if the application requests some number of bytes that is less
    than or not a multiple of the heap manager’s granularity, the heap manager will
    allocate extra bytes of storage (see [Figure 9-5](ch09.xhtml#ch9fig5)). This amount
    varies by heap manager (and possibly even by version of a specific heap manager),
    so programmers should never assume that their application has more memory available
    than they request; if they’re tempted to do so, they should request more memory
    upfront.
  prefs: []
  type: TYPE_NORMAL
- en: The extra memory the heap manager allocates results in another form of fragmentation
    called *internal fragmentation* (also shown in [Figure 9-5](ch09.xhtml#ch9fig5)).
    Like external fragmentation, internal fragmentation produces small amounts of
    leftover memory throughout the system that cannot satisfy future allocation requests.
    Assuming random-sized memory allocations, the average amount of internal fragmentation
    that occurs on each allocation is one-half the granularity size. Fortunately,
    the granularity size is quite small for most memory managers (typically 16 bytes
    or less), so after thousands and thousands of memory allocations you’ll lose only
    a couple dozen or so kilobytes to internal fragmentation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/09fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 9-5: Allocation granularity and internal fragmentation*'
  prefs: []
  type: TYPE_NORMAL
- en: Between the costs associated with allocation granularity and the memory control
    information, a typical memory request may require between 8 and 64 bytes plus
    whatever the application requests. If you’re making large memory allocation requests
    (hundreds or thousands of bytes), the overhead bytes won’t consume a large percentage
    of memory on the heap. However, if you allocate lots of small objects, the memory
    consumed by internal fragmentation and memory control information may represent
    a significant portion of your heap area. For example, consider a simple memory
    manager that always allocates blocks of data on 4-byte boundaries and requires
    a single 4-byte length value that it attaches to each allocation request for memory
    storage. This means that the minimum amount of storage the heap manager requires
    for each allocation is 8 bytes. If you make a series of `malloc()` calls to allocate
    a single byte, the application won’t be able to use almost 88 percent of the memory
    it allocates. Even if you allocate 4-byte values on each allocation request, the
    heap manager consumes two-thirds of the memory for overhead purposes. However,
    if your average allocation is a block of 256 bytes, the overhead requires only
    about 2 percent of the total memory allocation. In short, the larger your allocation
    request, the less impact the control information and internal fragmentation will
    have on your heap.
  prefs: []
  type: TYPE_NORMAL
- en: Many software engineering studies in computer science journals have found that
    memory allocation/deallocation requests cause a significant loss of performance.
    In such studies, the authors often obtained performance improvements of 100 percent
    or better by simply implementing their own simplified, application-specific, memory
    management algorithms rather than calling the standard runtime library or OS kernel
    memory allocation code. Hopefully, this section has made you aware of this potential
    problem in your own code.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.9 Common Pointer Problems**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Programmers make six common mistakes when using pointers. Some of these mistakes
    immediately stop a program with a diagnostic message. Others are subtler, yielding
    incorrect results without otherwise reporting an error. Still others simply negatively
    affect the program’s performance. Great programmers are always aware of the risks
    of using pointers and avoid these mistakes:'
  prefs: []
  type: TYPE_NORMAL
- en: Using an uninitialized pointer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a pointer that contains an illegal value such as `NULL`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuing to use storage after it has been freed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Failing to free storage once the program is done using it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessing indirect data using the wrong data type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing invalid pointer operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**9.9.1 Using an Uninitialized Pointer**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Using a pointer variable before you’ve assigned a valid memory address to the
    pointer is a very common error. Beginning programmers often don’t realize that
    declaring a pointer variable reserves storage only for the pointer itself, not
    for the data that the pointer references. The following short C/C++ program demonstrates
    this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Although static variables you declare are, technically, initialized with `0`
    (that is, `NULL`), static initialization doesn’t initialize the pointer with a
    valid address. Therefore, when this program executes, the variable pointer won’t
    contain a valid address, and the program will fail. To avoid this problem, ensure
    that all pointer variables contain a valid address prior to dereferencing those
    pointers. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, there’s no such thing as a truly uninitialized variable on most
    CPUs. Variables are initialized in two different ways:'
  prefs: []
  type: TYPE_NORMAL
- en: The programmer explicitly gives them an initial value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They inherit whatever bit pattern happens to be in memory when the system binds
    storage to them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Much of the time, garbage bit patterns laying around in memory don’t correspond
    to a valid memory address. Attempting to *dereference* such an invalid pointer
    (that is, to access the data in memory at which it points) raises a Memory Access
    Violation exception, if your OS is capable of trapping this exception.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, however, those random bits in memory just happen to correspond to
    a valid memory location you can access. In this situation, the CPU accesses the
    specified memory location without aborting the program. A novice programmer might
    think that accessing random memory is preferable to aborting a program. However,
    ignoring the error is far worse because your defective program continues to run
    without alerting you. If you store data using an uninitialized pointer, you may
    very well overwrite the values of other important variables in memory. This can
    produce some problems that are very difficult to locate.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.9.2 Using a Pointer That Contains an Illegal Value**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The second common mistake programmers make with pointers is assigning them invalid
    values (“invalid” in the sense of not containing the address of an actual object
    in memory). This can be considered a more general case of the first problem; without
    initialization, the garbage bits in memory supply the invalid address. The effects
    are the same. If you attempt to dereference a pointer containing an invalid address,
    you will either get a Memory Access Violation exception or access an unexpected
    memory location. Take care when dereferencing a pointer variable and make sure
    that you’ve assigned a valid address to the pointer before using it.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.9.3 Continuing to Use Storage After It Has Been Freed**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The third mistake is known as the *dangling pointer problem*. To understand
    it, consider the following Pascal code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This program allocates some storage and saves the address of that storage in
    the `p` variable. The code uses the storage for a while and then frees it, returning
    it to the system for other uses. Note that calling `dispose()` doesn’t change
    any data in the allocated memory. It doesn’t change the value of `p` in any way;
    `p` still points at the block of memory allocated earlier by `new()`. However,
    calling `dispose()` does tell the system that the program no longer needs this
    block of memory so that the system can use the memory for other purposes. The
    `dispose()` function cannot enforce the fact that you’ll never access this data
    again, however. You’re simply promising that you won’t. Of course, this code fragment
    breaks that promise: the last statement stores the value `5` at the address pointed
    to by `p` in memory.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The biggest problem with dangling pointers is that sometimes you can get away
    with using them, so you won’t immediately know there’s a problem. As long as the
    system doesn’t reuse the storage you’ve freed, using a dangling pointer produces
    no ill effects in your program. However, with each additional call to `new()`,
    the system may decide to reuse the memory released by that previous call to `dispose()`.
    When it does reuse the memory, any subsequent attempt to dereference the dangling
    pointer may produce some unintended consequences. The problems can include reading
    data that has been overwritten, overwriting the new data, and (in the worst case)
    overwriting system heap management pointers (which will probably cause your program
    to crash). The solution is clear: never use a pointer value once you free the
    storage associated with that pointer.'
  prefs: []
  type: TYPE_NORMAL
- en: '**9.9.4 Failing to Free Storage After Using It**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Of all these mistakes, failing to free allocated storage probably has the least
    impact on the proper operation of your program. The following C code fragment
    demonstrates this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the program allocates 256 bytes of storage and references this
    storage using the `ptr` variable. Later, the program allocates another block of
    512 bytes and overwrites the value in `ptr` with the address of this new block.
    The former address value in `ptr` is lost. And because the program has overwritten
    this former value, there’s no way to pass the address of the first 256 bytes to
    the `free()` function. As a result, these 256 bytes of memory are no longer available
    to your program.
  prefs: []
  type: TYPE_NORMAL
- en: While making 256 bytes of memory inaccessible to your program might not seem
    like a big deal, imagine that this code executes within a loop. With each iteration
    of the loop, the program loses another 256 bytes of memory. After a sufficient
    number of repetitions, the program exhausts the memory available on the heap.
    This problem is often called a *memory leak* because the effect is as if the memory
    bits were leaking out of your computer during program execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Memory leaks are less of a problem than dangling pointers. Indeed, there are
    only two problems with memory leaks:'
  prefs: []
  type: TYPE_NORMAL
- en: The danger of running out of heap space (which, ultimately, may cause the program
    to abort, though this is rare)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance problems due to virtual memory page swapping (*thrashing*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nevertheless, freeing all of the storage you allocate is a good habit to develop.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*When your program quits, the OS will reclaim all of the storage, including
    the data lost via memory leaks. Therefore, memory lost via a leak is lost only
    to your program, not the whole system.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**9.9.5 Accessing Indirect Data Using the Wrong Data Type**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Another problem with pointers is that their lack of type-safe access makes
    it easy to accidentally use the wrong data type. Some languages, like assembly,
    cannot and do not enforce pointer type checking. Others, like C/C++, make it very
    easy to override the type of the object a pointer references. For example, consider
    the following C/C++ program fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Generally, if you attempt to assign the value `5000` to the object pointed to
    by `pc`, the compiler will complain bitterly. The value `5000` won’t fit in the
    amount of storage associated with a character (`char`) object, which is 1 byte.
    This example, however, uses *type casting* (or *coercion*) to tell the compiler
    that `pc` really contains a pointer to an integer rather than a pointer to a character.
    Therefore, the compiler will assume that this assignment is legal.
  prefs: []
  type: TYPE_NORMAL
- en: However, if `pc` doesn’t actually point at an integer object, the last statement
    in this sequence can be disastrous. Characters are 1 byte long, and integers are
    usually larger. If the integer is larger than 1 byte, this assignment will overwrite
    some number of bytes beyond the 1 byte of storage that `malloc()` allocated. Whether
    or not this is catastrophic depends upon what data immediately follows the character
    object in memory.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.9.6 Performing Illegal Operations on Pointers**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The last category of common pointer mistakes has to do with operations on the
    pointers themselves. Arbitrary pointer arithmetic can lead to a pointer that points
    outside the range of the data originally allocated. By doing some crazy arithmetic,
    you can even modify a pointer so that it doesn’t point at a correct object. Consider
    the following (really nasty) C code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This example casts `p` as a pointer to a `char`. Then it adds `1` to the value
    in `p`. As the compiler thinks that `p` is pointing at a character (because of
    the cast), it actually adds the value `1` to the address held in `p`. The last
    instruction in this sequence stores the value `5` into the memory address pointed
    at by `p`, which is now 1 byte into the 4 bytes set aside for the `i[0]` element.
    On some machines, this will cause a fault; on others, it will store a bizarre
    value into `i[0]` and `i[1]`.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing two pointers for less than or greater than when the two pointers do
    not point to the same object (typically an array or struct) is another example
    of an illegal operation on a pointer, as is casting a pointer as an integer and
    assigning an integer value to that pointer, which can produce unexpected results.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.10 Pointers in Modern Languages**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because of the problems described in the previous section, modern HLLs (like
    Java, C#, Swift, and C++11/C++14) try to eliminate manual memory allocation and
    deallocation. These languages let you create new objects on the heap (typically
    using a `new()` function) but don’t provide any facilities for explicitly deallocating
    that storage. Instead, the language’s runtime system tracks memory usage and automatically
    recovers the storage, via garbage collection, once the program is no longer using
    it. This eliminates most (but not all) of the problems with uninitialized and
    dangling pointers. It also lowers the likelihood of memory leaks. These new languages
    dramatically reduce the number of problems related to errant pointer use.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, ceding control over memory allocation and deallocation introduces
    some problems of its own. In particular, you give up the ability to control the
    memory allocation lifetime. Now, the runtime system determines when to garbage-collect
    unused data, so large chunks of data could still be reserved for some time after
    you’ve finished using them.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.11 Managed Pointers**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some programming languages provide very limited pointer capabilities. For example,
    standard Pascal allows only a few operations on pointers: assignment (copy), comparison
    (for equality/inequality), and dereferencing. It does not support pointer arithmetic,
    meaning many types of mistakes with pointers are impossible.^([4](footnotes.xhtml#ch9fn4))
    At the other extreme is C/C++, which allows different arithmetic operations on
    pointers that make the language very powerful but introduce the likelihood of
    defects in the code.'
  prefs: []
  type: TYPE_NORMAL
- en: Modern language systems (for example, C# and the Microsoft Common Language Runtime
    system) introduce *managed pointers*, which allow various arithmetic operations
    on pointers, providing greater flexibility than a language like standard Pascal,
    but with restrictions that help avoid many common pointer pitfalls. For example,
    in these languages you cannot add an arbitrary integer to an arbitrary pointer
    (as is possible in C/C++). If you want to add an integer to a pointer and obtain
    a legal result, the pointer must contain the address of an array object (or other
    collection of like elements in memory). Furthermore, the integer’s value must
    be limited to a value that does not exceed the size of the data type (that is,
    the runtime system enforces array bounds checking).
  prefs: []
  type: TYPE_NORMAL
- en: While using managed pointers won’t eliminate all pointer problems, it does prevent
    wiping out data outside the range of a data object referenced by a pointer. It
    also helps prevent security issues in software, such as attempts to break into
    a system by providing illegal offsets in pointer arithmetic.
  prefs: []
  type: TYPE_NORMAL
- en: '**9.12 For More Information**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Duntemann, Jeff. *Assembly Language Step-by-Step*. 3rd ed. Indianapolis: Wiley,
    2009.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hyde, Randall. *The Art of Assembly Language*. 2nd ed. San Francisco: No Starch
    Press, 2010.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Oualline, Steve. *How Not to Program in C++*. San Francisco: No Starch Press,
    2003.'
  prefs: []
  type: TYPE_NORMAL
