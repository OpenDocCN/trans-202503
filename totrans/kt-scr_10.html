<html><head></head><body>
<div id="sbo-rt-content" class="calibre1"><section aria-labelledby="ch7" epub:type="chapter" role="doc-chapter">
<span aria-label="265" epub:type="pagebreak" id="pg_265" role="doc-pagebreak"/>
<hgroup>
<h2 class="title" id="ch7">
<span class="tpt"><span class="sans_dogma_ot_bold_b_">7</span></span>
<span class="ct"><span class="sans_dogma_ot_bold_b_">SORTING AND SEARCHING</span></span>
</h2>
</hgroup>
<figure class="opener"><img alt="" class="opener1" height="380" src="../images/icon.jpg" width="381"/>
</figure>
<p class="chapterintro">One of the fundamental skills that any serious developer needs to learn is how to efficiently sort and search through a given dataset. This skill is invaluable for transforming raw data into actionable insights, whether you’re working with a simple array or with complex data structures spanning terabytes of multifield information extracted from the vast expanse of the internet.</p>
<p class="tx">Sorting and searching are a dynamic duo that work hand in hand. <i class="calibre9">Sorting</i> organizes data into a specific order, which enables meaningful analysis of the dataset as a whole. Once the data is sorted, it becomes easier to identify patterns, trends, and outliers. Sorting also improves the speed and ease of <i class="calibre9">searching</i> for desired items within the dataset, especially when working with large volumes of data. Indeed, many search algorithms, such as binary search, interpolation search, and tree-based searches, rely on the organization achieved through sorting. Searching further complements <span aria-label="266" epub:type="pagebreak" id="pg_266" role="doc-pagebreak"/>sorting by enabling targeted analysis, allowing for the quick location of specific data points or subsets within the dataset. Together, sorting and searching streamline data exploration, optimize retrieval efficiency, and empower decision-making processes.</p>
<p class="tx">A wide array of sorting and search algorithms are available. In this chapter’s projects, we’ll focus on a selected group of algorithms that have broad applications in fields that require working with large datasets. By mastering these algorithms, you’ll be better equipped to tackle complex data challenges and make the most of sorting and searching capabilities.</p>
<section aria-labelledby="sec1" epub:type="division">
<h3 class="h"><span id="sec1"/><span id="h1-45"/><span class="sans_futura_std_bold_b_">Sorting Algorithms</span></h3>
<p class="tni">Sorting algorithms allow us to rearrange a collection of data elements into a specific order, such as numerical or alphabetical or based on any other desired criteria. We can sort various types of data, including numbers, strings, records (lines of data in a database), and complex objects. Sorting is a fundamental building block for a variety of operations, such as merging, joining, and aggregating datasets. It paves the way for efficient data manipulation, which is crucial in domains like database management, algorithms, and programming. By organizing data structures, sorting provides a structured framework that promotes clarity, consistency, and ease of use. This streamlined approach enhances data management and maintenance, particularly in scenarios where data must be updated or modified frequently.</p>
<p class="tx">Each sorting algorithm has its own advantages and disadvantages in terms of time complexity, space complexity, and stability. Before we get into specific algorithms, it’s important to review these concepts, as they’ll assist us in selecting the appropriate algorithm for a given problem.</p>
<p class="tx"><i class="calibre9">Time complexity</i> refers to the estimation of the algorithm’s running time based on the input size, which is denoted by <i class="calibre9">n</i>. It provides insight into how the algorithm’s performance scales with larger datasets. Common notations like <i class="calibre9">O</i>(1), <i class="calibre9">O</i>(log <i class="calibre9">n</i>), <i class="calibre9">O</i>(<i class="calibre9">n</i>), <i class="calibre9">O</i>(<i class="calibre9">n</i> log <i class="calibre9">n</i>), <i class="calibre9">O</i>(<i class="calibre9">n</i><sup class="calibre8">2</sup>), and <i class="calibre9">O</i>(2<i class="calibre9"><sup class="calibre8">n</sup></i>) indicate different growth rates of time complexity in increasing order. The smaller the growth rate, the quicker the algorithm is in sorting a collection of data.</p>
<aside aria-label="box-35" class="box">
<p class="boxtitle" id="box-35"><span class="sans_futura_std_bold_b_">BIG O NOTATION</span></p>
<p class="boxfirst"><span class="sans_futura_std_book_">Big O notation is a mathematical notation that describes how a function behaves when its argument approaches a specific value or tends toward infinity. In computer science, it’s used to describe the performance or complexity of an algorithm.</span></p>
<p class="box1"><span class="sans_futura_std_book_">In the context of sorting algorithms, big O notation indicates how the time or space complexity of an algorithm grows as the size of the input array grows. For example, the merge sort algorithm has a time complexity of</span> <span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">).</span> <span aria-label="267" epub:type="pagebreak" id="pg_267" role="doc-pagebreak"/><span class="sans_futura_std_book_">For an array size of 1,000, its time complexity would be</span> <span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(1,000 log 1,000), or approximately 9,966 (using a base of 2 for the logarithm). If the array size doubles to 2,000, the time complexity increases to</span> <span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(2,000 log 2,000), which is approximately 21,932. This means that doubling the array size would, on average, increase the time needed to sort the array with the merge sort algorithm by a factor of 21,932/9,966 ≈ 2.2.</span></p>
<p class="box1"><span class="sans_futura_std_book_">By contrast, the insertion sort algorithm has an average time complexity of</span> <span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_sup_">2</span><span class="sans_futura_std_book_">). Increasing the input array size from 1,000 to 2,000 therefore means going from a time complexity of 1,000</span><span class="sans_futura_std_book_sup_">2</span> <span class="sans_futura_std_book_">= 1 million to one of 2,000</span><span class="sans_futura_std_book_sup_">2</span> <span class="sans_futura_std_book_">= 4 million. In other words, doubling the size of the dataset quadruples the time complexity.</span></p>
<p class="boxlast"><span class="sans_futura_std_book_">In practice, the actual runtime for merge sort, insertion sort, or any other algorithm will depend on many other factors, such as the implementation details, the hardware and software environment, and the specific input data.</span></p>
</aside>
<p class="tx"><i class="calibre9">Space complexity</i>, on the other hand, describes the amount of additional memory an algorithm requires to perform the sorting operation, beyond the memory it needs to store the data being sorted. Some algorithms may operate with minimal extra space, where the swapping of data elements happens <i class="calibre9">in place</i>. Others may require significant auxiliary memory to perform sorting operations efficiently. This is also called <i class="calibre9">out-of-place</i> sorting, where full or partial copies of the original dataset are needed to carry out the sorting operation. The smaller the space complexity, the more efficient (and scalable) that algorithm is in terms of memory requirements.</p>
<p class="tx"><i class="calibre9">Stability</i> is another important consideration. A sorting algorithm is stable if it maintains the relative order of elements with equal values. In certain situations, preserving the initial order of equal elements is required, and a stable algorithm becomes essential.</p>
<p class="tx"><a href="chapter7.xhtml#tab7-1" class="calibre2">Table 7-1</a> shows these properties for a selected group of sorting algorithms that we’ll discuss in this chapter.</p>
<p class="tt" id="tab7-1"><span class="sans_futura_std_bold_b_"><span class="sans_futura_std_bold_b_">Table 7-1:</span></span> <span class="sans_futura_std_book_">Key Features of Selected Sorting Algorithms</span></p>
<table class="basic-table">
<thead class="calibre13">
<tr class="calibre14">
<th class="tch" rowspan="2" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Algorithm</span></p></th>
<th class="tch" colspan="3" scope="colgroup"><p class="tableheaderc"><span class="sans_futura_std_bold_b_">Time complexity</span></p></th>
<td class="tch1"/>
<th class="tch" rowspan="2" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Space complexity</span></p></th>
<th class="tch" rowspan="2" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Stability</span></p></th>
</tr>
<tr class="calibre14">
<th class="tch" scope="col"><p class="tb1"><span class="sans_futura_std_bold_b_">Best</span></p></th>
<th class="tch" scope="col"><p class="tb1"><span class="sans_futura_std_bold_b_">Average</span></p></th>
<th class="tch" scope="col"><p class="tb1"><span class="sans_futura_std_bold_b_">Worst</span></p></th>
<td class="tch1"/>
</tr>
</thead>
<tbody class="calibre15">
<tr class="calibre16">
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_">Insertion sort</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_sup_">2</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_sup_">2</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"/>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(1)</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_">Stable</span></p></td>
</tr>
<tr class="calibre14">
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_">Merge sort</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"/>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_">Stable</span></p></td>
</tr>
<tr class="calibre16">
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_">Quick sort</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_sup_">2</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbf"/>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)*</span></p></td>
<td class="tbf"><p class="tb1"><span class="sans_futura_std_book_">Unstable</span></p></td>
</tr>
<tr class="calibre14">
<td class="tbl"><p class="tableheader"><span class="sans_futura_std_book_">Heap sort</span></p></td>
<td class="tbl"><p class="tableheader"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbl"><p class="tableheader"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbl"><p class="tableheader"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">)</span></p></td>
<td class="tbl"/>
<td class="tbl"><p class="tableheader"><span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(1)</span></p></td>
<td class="tbl"><p class="tableheader"><span class="sans_futura_std_book_">Unstable</span></p></td>
</tr>
</tbody>
<tfoot class="calibre20">
<tr class="calibre14">
<td class="tb" colspan="7"><p class="tableheader"><span class="sans_futura_std_book_">*The worst case can be</span> <span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">).</span></p></td>
</tr>
</tfoot>
</table>
<p class="tx">Of the sorting algorithms listed in <a href="chapter7.xhtml#tab7-1" class="calibre2">Table 7-1</a>, insertion sort is the simplest and most intuitive, but it isn’t the most efficient in terms of average time complexity. It tends to be slower than the other algorithms for larger <span aria-label="268" epub:type="pagebreak" id="pg_268" role="doc-pagebreak"/>datasets. Due to this limitation, insertion sort generally isn’t used as a standalone algorithm, but rather as part of a hybrid sorting scheme that combines multiple methods, depending on the characteristics of the data.</p>
<p class="tx">Both merge sort and heap sort have similar time complexities, typically <i class="calibre9">O</i>(<i class="calibre9">n</i> log <i class="calibre9">n</i>). However, heap sort has an advantage in terms of space complexity because it’s an in-place algorithm, meaning it requires minimal additional memory beyond the input array. On the other hand, merge sort requires additional space proportional to the input size. If stability is a desired property, then merge sort becomes the preferred choice over heap sort. It’s a stable sorting algorithm, ensuring that elements with equal values maintain their original order.</p>
<p class="tx">In practice, quick sort often performs better than other sorting algorithms, except when the data is already sorted or nearly sorted. Quick sort benefits from lower space complexity, and it has smaller overhead, or fewer hidden operations that don’t depend on the size of the input data. Many programming language libraries provide built-in functions for quick sort, making it easily accessible and widely used.</p>
<p class="headaexercise" id="pre-27"><span class="sans_dogma_ot_bold_b_15-n">Project 27: Space-Efficient Sorting with Insertion Sort</span></p>
<p class="tni">Insertion sort is a simple and intuitive sorting algorithm that works by building a sorted array one element at a time. The algorithm maintains a sorted subarray within the given array and extends it by inserting elements from the unsorted part of the array into the correct position in the sorted part. At the beginning, the first element of the array is considered to be a sorted subarray of size 1. The algorithm then iterates through the remaining elements, one at a time, and inserts each element into its appropriate position within the sorted subarray.</p>
<p class="tx">To insert an element, the algorithm compares it with the elements in the sorted subarray from right to left. It shifts any larger elements one position to the right until it finds the correct position for the current element. Once the correct position is found, the element is inserted into that position. This process continues until all the elements in the array are processed, resulting in a fully sorted array.</p>
<p class="tx">Say we have the unsorted array [8, 3, 4, 5, 1, 2]. Here’s how the insertion sort algorithm would process it:</p>
<p class="listnumber">  1.  Imagine that the given array is made up of two subarrays—a sorted array, which initially holds only the first element (8), and an unsorted array made up of the remaining elements.</p>
<p class="listnumber1">  2.  Compare the second element of the array (index 1) with its preceding element (index 0) as follows:</p>
<p class="listnumbersub">a.  Compare 3 with 8. Since 3 is smaller, swap the elements.</p>
<p class="listnumbersub">b.  The array after the first pass is [3, 8, 4, 5, 1, 2].  </p>
<p class="listnumber1"><span aria-label="269" epub:type="pagebreak" id="pg_269" role="doc-pagebreak"/>  3.  Move to the next element (index 2) and compare it with the previous elements.</p>
<p class="listnumbersub">a.  Compare 4 with 8. Since 4 is smaller, swap the elements.</p>
<p class="listnumbersub">b.  Compare 4 with 3. Since 4 is greater, stop comparing.</p>
<p class="listnumbersub">c.  The array after the second pass is [3, 4, 8, 5, 1, 2].</p>
<p class="listnumber2">  4.  Repeat this process for the remaining elements of the array. In the end, the array will be sorted in ascending order: [1, 2, 3, 4, 5, 8].</p>
<p class="tx">As indicated in <a href="chapter7.xhtml#tab7-1" class="calibre2">Table 7-1</a>, insertion sort has an average and worst-case time complexity of <i class="calibre9">O</i>(<i class="calibre9">n</i><sup class="calibre8">2</sup>), where <i class="calibre9">n</i> is the number of elements in the array. However, it performs well for small lists or nearly sorted lists. It’s an in-place sorting algorithm with space complexity of <i class="calibre9">O</i>(1) for all cases, meaning it doesn’t require additional memory to perform the sorting.</p>
<section aria-labelledby="sec2" epub:type="division">
<h4 class="h1"><span id="sec2"/><span id="h2-113"/><span class="sans_futura_std_bold_condensed_oblique_">The Code</span></h4>
<p class="tni">Implementing the insertion sort algorithm in Kotlin takes only a few lines of code. We’ll create a dedicated function called <span class="sans_thesansmonocd_w5regular_">insertionSort()</span> to handle all the necessary steps for sorting an array and call this function from <span class="sans_thesansmonocd_w5regular_">main()</span> to get the job done.</p>
<pre class="calibre10"><code class="calibre11">fun main() {
    // Define an array to be sorted.
    val arr = intArrayOf(8, 3, 4, 5, 1, 2)

    println("\n*** Sorting an Array Using Insertion Sort ***\n")
    println("original array:\n${arr.contentToString()}")
    // Call the insertion sort function.
    insertionSort(arr)
    println("sorted array:\n${arr.contentToString()}")
}

fun insertionSort(A: IntArray) {
    // Sorting happens in place.
  <span aria-label="annotation1" class="code_codeannotation">❶</span> for (i in 1 until A.size) {
        val key = A[i]
        var j = i
      <span aria-label="annotation2" class="code_codeannotation">❷</span> while(j &gt; 0 &amp;&amp; A[j-1] &gt; key) {
            A[j] = A[j-1]
            j -= 1
        }
      <span aria-label="annotation3" class="code_codeannotation">❸</span> A[j] = key
    }
}</code></pre>
<p class="tx">This code snippet implements the insertion sort algorithm to sort an array of numbers (in this case, integers) in ascending order. We create an array called <span class="sans_thesansmonocd_w5regular_">arr</span> that holds the initial unsorted array elements. The content of this array is printed to the console, allowing us to see the original order of the numbers. We then call the <span class="sans_thesansmonocd_w5regular_">insertionSort()</span> function to perform the <span aria-label="270" epub:type="pagebreak" id="pg_270" role="doc-pagebreak"/>sorting operation. It takes the array as input and modifies it in place, so you don’t have to return the sorted array to the calling function.</p>
<p class="tx">Within the <span class="sans_thesansmonocd_w5regular_">insertionSort()</span> function, we iterate through the unsorted portion of the array by using a <span class="sans_thesansmonocd_w5regular_">for</span> loop <span aria-label="annotation1" class="codeannotation">❶</span>, starting from the second element (index <span class="sans_thesansmonocd_w5regular_">1</span>) and continuing to the last element. For each element, we temporarily store the value in a variable called <span class="sans_thesansmonocd_w5regular_">key</span>. Next, we use a <span class="sans_thesansmonocd_w5regular_">while</span> loop <span aria-label="annotation2" class="codeannotation">❷</span> to move from right to left through the sorted portion of the array, comparing <span class="sans_thesansmonocd_w5regular_">key</span> with each element. The <span class="sans_thesansmonocd_w5regular_">while</span> loop continues as long as two conditions are met: more elements remain to the left (checked using <span class="sans_thesansmonocd_w5regular_">j &gt; 0</span>), and the current element is greater than <span class="sans_thesansmonocd_w5regular_">key</span> (checked using <span class="sans_thesansmonocd_w5regular_">A[j-1] &gt; key</span>). Inside the <span class="sans_thesansmonocd_w5regular_">while</span> loop, if an element is greater than <span class="sans_thesansmonocd_w5regular_">key</span>, it’s shifted one position to the right. This makes space for <span class="sans_thesansmonocd_w5regular_">key</span> to be inserted at the correct sorted position.</p>
<p class="tx">When the <span class="sans_thesansmonocd_w5regular_">while</span> loop ends, we assign the value of <span class="sans_thesansmonocd_w5regular_">key</span> to the current position in the array <span aria-label="annotation3" class="codeannotation">❸</span>, effectively inserting the element into the sorted portion of the array at the correct position. The <span class="sans_thesansmonocd_w5regular_">for</span> loop then moves to the next element, and the process repeats for all the elements in the array. Once the sorting is complete, the code prints the sorted array to the console, displaying the numbers in ascending order.</p>
</section>
<section aria-labelledby="sec3" epub:type="division">
<h4 class="h1"><span id="sec3"/><span id="h2-114"/><span class="sans_futura_std_bold_condensed_oblique_">The Result</span></h4>
<p class="tni">If you run the code without changing the given unsorted array, the output should look like this:</p>
<pre class="calibre10"><code class="calibre11">*** Sorting an Array Using Insertion Sort ***

original array:
[8, 3, 4, 5, 1, 2]
sorted array:
[1, 2, 3, 4, 5, 8]</code></pre>
<p class="tx">The code can easily be tweaked to sort floating-point numbers by assembling an array of either <span class="sans_thesansmonocd_w5regular_">Float</span> or <span class="sans_thesansmonocd_w5regular_">Double</span> data types. I encourage you to modify the code to accept user input regarding the preferred sorting order—either ascending or descending. After that, you can implement a suitable function based on the user’s choice. Alternatively, you can use the same function with two subfunctions, which can be implemented using <span class="sans_thesansmonocd_w5regular_">when(choice)</span>, one for sorting an array in ascending order and one for doing the opposite.</p>
<p class="headaexercise" id="pre-28"><span class="sans_dogma_ot_bold_b_15-n">Project 28: Faster Sorting with Merge Sort</span></p>
<p class="tni"><i class="calibre9">Merge sort</i> is a popular sorting algorithm that follows a divide-and-conquer approach. It works by recursively dividing an array into smaller subarrays until each subarray contains only one element. The subarrays are then merged back into longer arrays, placing the elements in the correct order in the process, eventually resulting in a fully sorted array. <a href="chapter7.xhtml#fig7-1" class="calibre2">Figure 7-1</a> illustrates this process for the same [8, 3, 4, 5, 1, 2] array we used in <span><a href="chapter7.xhtml#pre-27" class="calibre2">Project 27</a></span>.</p>
<span aria-label="271" epub:type="pagebreak" id="pg_271" role="doc-pagebreak"/>
<figure class="img"><img alt="" class="img2" height="967" id="fig7-1" src="../images/Figure7-1.jpg" width="893"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 7-1: Visualizing the merge sort algorithm</span></p></figcaption>
</figure>
<p class="tx">Notice how the given array is initially divided into two subarrays, and then notice how each of those subarrays is further divided into two subarrays, and so on. The subarrays are then sorted and merged. When we implement the algorithm by using a recursive function, we’ll first process entirely the left subarray of the first pair of subarrays—in this example, [8, 3, 4]—before moving on to the right subarray, [5, 1, 2]. Within each branch, we’ll divide the subarrays into individual elements and then reassemble the sorted subarrays. Eventually, the final pair of sorted left and right subarrays will be merged to generate the final sorted array.</p>
<p class="tx">Merge sort guarantees a consistent time complexity of <i class="calibre9">O</i>(<i class="calibre9">n</i> log <i class="calibre9">n</i>) in all cases, making it efficient for large datasets. It’s also a stable sorting algorithm, preserving the relative order of equal elements. However, it needs additional space for the merging step, making its space complexity <i class="calibre9">O</i>(<i class="calibre9">n</i>). Nonetheless, merge sort’s efficiency and stability make it a popular choice for sorting in various applications.</p>
</section>
<section aria-labelledby="sec4" epub:type="division">
<h4 class="h1"><span id="sec4"/><span id="h2-115"/><span class="sans_futura_std_bold_condensed_oblique_">The Code</span></h4>
<p class="tni">We’ll follow a similar structure for the merge sort code as we did for the insertion sort: a <span class="sans_thesansmonocd_w5regular_">main()</span> function that kicks off the sorting process by passing an array to a <span class="sans_thesansmonocd_w5regular_">mergeSort()</span> function. This time, however, <span class="sans_thesansmonocd_w5regular_">mergeSort()</span> will recursively call itself until it reaches a stopping condition (when each subarray has only one element). To put everything back together, we’ll use a helper function called <span class="sans_thesansmonocd_w5regular_">merge()</span>, which handles the task of sorting and merging the subarrays.</p>
<pre class="calibre10"><code class="calibre11"><span aria-label="272" epub:type="pagebreak" id="pg_272" role="doc-pagebreak"/>fun main() {
    val arr = intArrayOf(8, 3, 4, 5, 1, 2)

    println("\n*** Sorting an Array Using Merge Sort ***\n")
    println("original array:\n${arr.contentToString()}")
    // Call the recursive function.
  <span aria-label="annotation1" class="code_codeannotation">❶</span> mergeSort(arr)
    println("\nsorted array:\n${arr.contentToString()}")
}

fun mergeSort(arr: IntArray) {
    val length = arr.size
    if (length &lt; 2) return // done splitting subarrays

  <span aria-label="annotation2" class="code_codeannotation">❷</span> val middle = length / 2
    val leftArray = arr.copyOfRange(0, middle)
    val rightArray = arr.copyOfRange(middle, length)

  <span aria-label="annotation3" class="code_codeannotation">❸</span> mergeSort(leftArray)
    mergeSort(rightArray)
    merge(leftArray, rightArray, arr)
}

fun merge(leftArray: IntArray, rightArray: IntArray,
          arr: IntArray) {

    val leftSize = leftArray.size
    val rightSize = rightArray.size
    var i = 0   // for original array
    var l = 0   // for left array
    var r = 0   // for right array

    // Compare, sort, and merge.
  <span aria-label="annotation4" class="code_codeannotation">❹</span> while(l &lt; leftSize &amp;&amp; r &lt; rightSize) {
        if (leftArray[l] &lt; rightArray[r]) {
            arr[i] = leftArray[l]
            l++
        } else {
            arr[i] = rightArray[r]
            r++
        }
      <span aria-label="annotation5" class="code_codeannotation">❺</span> i++
    }

    // If all elements of a subarray are assigned, assign the
    // remaining elements of the nonempty array to "arr".
    while (l &lt; leftSize) {
        arr[i] = leftArray[l]
        l++
        i++
    }

    while (r &lt; rightSize) {
        arr[i] = rightArray[r]
        r++
<span aria-label="273" epub:type="pagebreak" id="pg_273" role="doc-pagebreak"/>        i++
    }
}</code></pre>
<p class="tx">In the <span class="sans_thesansmonocd_w5regular_">main()</span> function, we begin by initializing an array called <span class="sans_thesansmonocd_w5regular_">arr</span> with a set of integer values. We also print the given array before proceeding so that we’ll be able to compare this with the sorted array once it’s generated. We then call the <span class="sans_thesansmonocd_w5regular_">mergeSort()</span> function <span aria-label="annotation1" class="codeannotation">❶</span>, which is responsible for carrying out the sorting process. This function takes an array <span class="sans_thesansmonocd_w5regular_">arr</span> as an argument.</p>
<p class="tx">Within <span class="sans_thesansmonocd_w5regular_">mergeSort()</span>, we first check the length of the incoming array. If it’s less than <span class="sans_thesansmonocd_w5regular_">2</span>, the subarray has a length of <span class="sans_thesansmonocd_w5regular_">1</span>, so the function simply returns, and the splitting process stops. This is the all-important stopping condition that any recursive function needs. Next, we calculate the <span class="sans_thesansmonocd_w5regular_">middle</span> index of the array <span aria-label="annotation2" class="codeannotation">❷</span> and create two subarrays: <span class="sans_thesansmonocd_w5regular_">leftArray</span> and <span class="sans_thesansmonocd_w5regular_">rightArray</span>. The former contains elements from index <span class="sans_thesansmonocd_w5regular_">0</span> up to but not including <span class="sans_thesansmonocd_w5regular_">middle</span>, while the latter contains elements from <span class="sans_thesansmonocd_w5regular_">middle</span> to the end of the array. To continue the process, the <span class="sans_thesansmonocd_w5regular_">mergeSort()</span> function recursively calls itself on both <span class="sans_thesansmonocd_w5regular_">leftArray</span> and <span class="sans_thesansmonocd_w5regular_">rightArray</span> <span aria-label="annotation3" class="codeannotation">❸</span>. As mentioned, this recursive step continues until the base case is reached—that is, when the length of the subarrays becomes <span class="sans_thesansmonocd_w5regular_">1</span>. Finally, we call <span class="sans_thesansmonocd_w5regular_">merge()</span> to reassemble <span class="sans_thesansmonocd_w5regular_">leftArray</span> and <span class="sans_thesansmonocd_w5regular_">rightArray</span> into a single, sorted array.</p>
<p class="tx">The <span class="sans_thesansmonocd_w5regular_">merge()</span> function accepts three parameters, <span class="sans_thesansmonocd_w5regular_">leftArray</span>, <span class="sans_thesansmonocd_w5regular_">rightArray</span>, and <span class="sans_thesansmonocd_w5regular_">arr</span>, representing the two subarrays to be merged and the original array that will be modified during the merging process. We start the function by initializing variables to keep track of the indices within the arrays; <span class="sans_thesansmonocd_w5regular_">i</span> is for traversing the original <span class="sans_thesansmonocd_w5regular_">arr</span>, <span class="sans_thesansmonocd_w5regular_">l</span> for the <span class="sans_thesansmonocd_w5regular_">leftArray</span>, and <span class="sans_thesansmonocd_w5regular_">r</span> for the <span class="sans_thesansmonocd_w5regular_">rightArray</span>. The actual merging and sorting occur within a <span class="sans_thesansmonocd_w5regular_">while</span> loop <span aria-label="annotation4" class="codeannotation">❹</span> that continues as long as elements remain in both <span class="sans_thesansmonocd_w5regular_">leftArray</span> and <span class="sans_thesansmonocd_w5regular_">rightArray</span> to compare. During each iteration, the function compares the values at indices <span class="sans_thesansmonocd_w5regular_">l</span> and <span class="sans_thesansmonocd_w5regular_">r</span> in <span class="sans_thesansmonocd_w5regular_">leftArray</span> and <span class="sans_thesansmonocd_w5regular_">rightArray</span>, respectively. If the value in <span class="sans_thesansmonocd_w5regular_">leftArray</span> is smaller, it’s assigned to <span class="sans_thesansmonocd_w5regular_">arr</span> at index <span class="sans_thesansmonocd_w5regular_">i</span>, and the <span class="sans_thesansmonocd_w5regular_">l</span> index is incremented. Conversely, if the value in <span class="sans_thesansmonocd_w5regular_">rightArray</span> is smaller, it’s assigned to <span class="sans_thesansmonocd_w5regular_">arr</span> at index <span class="sans_thesansmonocd_w5regular_">i</span>, and the <span class="sans_thesansmonocd_w5regular_">r</span> index is incremented. Following each assignment, the <span class="sans_thesansmonocd_w5regular_">i</span> index is also incremented <span aria-label="annotation5" class="codeannotation">❺</span>.</p>
<p class="tx">The <span class="sans_thesansmonocd_w5regular_">while</span> loop concludes when either <span class="sans_thesansmonocd_w5regular_">leftArray</span> or <span class="sans_thesansmonocd_w5regular_">rightArray</span> has been fully processed. The remaining elements from the nonempty array are then assigned to <span class="sans_thesansmonocd_w5regular_">arr</span> to complete the merging process. We use two separate <span class="sans_thesansmonocd_w5regular_">while</span> loops for this task—one for <span class="sans_thesansmonocd_w5regular_">leftArray</span> and one for <span class="sans_thesansmonocd_w5regular_">rightArray</span>. Only one of these loops will actually execute.</p>
</section>
<section aria-labelledby="sec5" epub:type="division">
<h4 class="h1"><span id="sec5"/><span id="h2-116"/><span class="sans_futura_std_bold_condensed_oblique_">The Result</span></h4>
<p class="tni">When you run the merge sort code for the given input array, it should produce the following output:</p>
<pre class="calibre10"><code class="calibre11">*** Sorting an Array Using Merge Sort ***

original array:
[8, 3, 4, 5, 1, 2]

sorted array:
[1, 2, 3, 4, 5, 8]</code></pre>
<p class="tx"><span aria-label="274" epub:type="pagebreak" id="pg_274" role="doc-pagebreak"/>I encourage you to repeat the same exercise you did with insertion sort, allowing the user to choose the order of sorting (ascending or descending) and then modifying the code to sort accordingly. I also recommend that you think about arrays containing both positive and negative numbers. You might soon realize that by selectively multiplying the entire array by –1 before and after sorting, you can use the same code to sort an array in ascending or descending order instead of writing two separate functions!</p>
<p class="headaexercise" id="pre-29"><span class="sans_dogma_ot_bold_b_15-n">Project 29: High-Efficiency Sorting with Quick Sort</span></p>
<p class="tni"><i class="calibre9">Quick sort</i> is a well-known and highly efficient in-place sorting algorithm that’s widely used in various real-world applications. It involves selecting a pivot element from the array and dividing the remaining elements into two subarrays, one for values less than the pivot and the other for values greater than the pivot. This mechanism places the pivot element itself in the correct position in the final sorted array, while the remaining elements end up on the appropriate side of the pivot. The process repeats recursively for the subarrays, selecting new pivot elements and further portioning the array, until everything is sorted.</p>
<p class="tx">Here’s a step-by-step example of how quick sort works, using the array [8, 3, 4, 5, 1, 2]:</p>
<p class="listnumber">  1.  Choose a pivot element, which can be any element from the array. In this example, we’ll choose the last element, 2.</p>
<p class="listnumber1">  2.  Partition the array into two subarrays, the left subarray with elements less than the pivot and the right subarray with elements greater than the pivot. In this case, the left subarray becomes [1], and the right becomes [4, 5, 8, 3]. I’ll explain where this order comes from later in the project.</p>
<p class="listnumber1">  3.  Recursively apply quick sort to the subarrays. For the left subarray, no further action is needed: it has only one element, so it’s already in its final position. For the right subarray, we now pick 3 as the pivot. This creates an empty left subarray as 3 is the smallest number. The right subarray now has [5, 8, 4].</p>
<p class="listnumber1">  4.  Repeat step 3 until all subarrays are sorted, meaning each subarray has only one element or is empty.</p>
<p class="listnumber2">  5.  Combine the sorted subarrays to get the final sorted array: [1, 2, 3, 4, 5, 8].</p>
<p class="tx">In this example, we always chose the last element of the array or subarray as the pivot element. Another option could have been to choose the first element as the pivot. For a wide range of inputs, choosing the first or last element as the pivot will work well, especially if the input data is randomly or uniformly distributed. However, if the array is already sorted or nearly sorted, pivoting around the first or last element will yield the <span aria-label="275" epub:type="pagebreak" id="pg_275" role="doc-pagebreak"/>worst-case time complexity of <i class="calibre9">O</i>(<i class="calibre9">n</i><sup class="calibre8">2</sup>). To avoid this, you can use one of the following alternative techniques for choosing a pivot:</p>
<p class="listhead"><b class="calibre6">Choose a random element</b></p>
<p class="listplainfirst">Randomly selecting a pivot element helps mitigate the inefficiency of choosing the first or the last element when the array is already mostly sorted. This approach can provide a good average-case performance since the pivot’s position is less predictable. It reduces the likelihood of encountering worst-case scenarios, resulting in better overall efficiency.</p>
<p class="listhead"><b class="calibre6">Choose the median of three</b></p>
<p class="listplainfirst">This strategy involves using the median value among the first, middle, and last elements of the array as the pivot. This approach aims to balance the pivot selection by choosing a value closer to the true median of the dataset. It helps improve the algorithm’s performance on a wide range of inputs, reducing the chance of worst-case behavior.</p>
<p class="tx">Compared to other sorting algorithms, quick sort is highly efficient for large datasets, and its average and worst-case time complexity are <i class="calibre9">O</i>(<i class="calibre9">n</i> log <i class="calibre9">n</i>) and <i class="calibre9">O</i>(<i class="calibre9">n</i><sup class="calibre8">2</sup>), respectively. Quick sort has an average space complexity of <i class="calibre9">O</i>(log <i class="calibre9">n</i>), which can degenerate to <i class="calibre9">O</i>(<i class="calibre9">n</i>) when the input array is already sorted or nearly sorted and the first or the last element is chosen as the pivot (worst case).</p>
</section>
<section aria-labelledby="sec6" epub:type="division">
<h4 class="h1"><span id="sec6"/><span id="h2-117"/><span class="sans_futura_std_bold_condensed_oblique_">The Code</span></h4>
<p class="tni">The code for quick sort is quite similar to that of merge sort in structure, as both algorithms rely on a divide-and-conquer approach. In the code, the <span class="sans_thesansmonocd_w5regular_">main()</span> function accepts an input array and passes it to the <span class="sans_thesansmonocd_w5regular_">quickSort()</span> function. Within <span class="sans_thesansmonocd_w5regular_">quickSort()</span>, we invoke a <span class="sans_thesansmonocd_w5regular_">partition()</span> helper function to determine the correct position for the pivot element. This allows us to divide the original array into a left array containing elements less than the pivot and a right array containing elements greater than or equal to the pivot. Finally, <span class="sans_thesansmonocd_w5regular_">quickSort()</span> is recursively called on these subarrays as long as <span class="sans_thesansmonocd_w5regular_">start</span> is less than <span class="sans_thesansmonocd_w5regular_">end</span>, which means at least two elements remain in the subarray.</p>
<pre class="calibre10"><code class="calibre11">fun main() {
    val arr = intArrayOf(8, 3, 4, 5, 1, 2)

    println("\n*** Sorting an Array Using Quick Sort ***\n")
    println("original array:\n${arr.contentToString()}")
    // Call the recursive function.
  <span aria-label="annotation1" class="code_codeannotation">❶</span> quickSort(arr, start = 0, end = arr.size -1)
    println("\nsorted array:\n${arr.contentToString()}")
}

fun quickSort(arr: IntArray, start: Int, end: Int) {
    // Check that the termination condition for recursion
    // base case is when start = end.
  <span aria-label="annotation2" class="code_codeannotation">❷</span> if (start &lt; end) {
<span aria-label="276" epub:type="pagebreak" id="pg_276" role="doc-pagebreak"/>        val pivotIndex = partition(arr, start, end)
        quickSort(arr = arr, start = start, end = pivotIndex - 1)
        quickSort(arr = arr, start = pivotIndex + 1, end = end)
    }
}

fun partition(arr: IntArray, start: Int, end: Int): Int {
    val pivot = arr[end]
    var i = start

    for (j in start until end) {
      <span aria-label="annotation3" class="code_codeannotation">❸</span> if (arr[j] &lt; pivot) {
            swap(arr, i, j)
            i++
        }
    }
  <span aria-label="annotation4" class="code_codeannotation">❹</span> swap(arr, i, end)
    return i
}

fun swap(arr: IntArray, i: Int, j: Int) {
    val temp = arr[i]
    arr[i] = arr[j]
    arr[j] = temp
}</code></pre>
<p class="tx">In the <span class="sans_thesansmonocd_w5regular_">main()</span> function, we call the <span class="sans_thesansmonocd_w5regular_">quickSort()</span> function by passing three parameter values: the array to be sorted (<span class="sans_thesansmonocd_w5regular_">arr</span>) and the indices for its first and last elements (<span class="sans_thesansmonocd_w5regular_">start</span> and <span class="sans_thesansmonocd_w5regular_">end</span>) <span aria-label="annotation1" class="codeannotation">❶</span>. As before, we print the array before and after sorting.</p>
<p class="tx">In the <span class="sans_thesansmonocd_w5regular_">quickSort()</span> function, we start by checking whether the starting index of the incoming subarray is less than the ending index <span aria-label="annotation2" class="codeannotation">❷</span>. When this is no longer true, the subarray will have only one element, so the recursion of that branch will stop. Otherwise, we call the <span class="sans_thesansmonocd_w5regular_">partition()</span> helper function, which returns the final (sorted) position of the pivot element. We store this position as <span class="sans_thesansmonocd_w5regular_">pivotIndex</span> and use it to divide the original array into left and right subarrays. We then recursively call <span class="sans_thesansmonocd_w5regular_">quicksort()</span> on the left and right subarrays until the stopping condition is met.</p>
<p class="tx">The real sorting work happens inside the <span class="sans_thesansmonocd_w5regular_">partition()</span> function. After setting <span class="sans_thesansmonocd_w5regular_">pivot</span> to the value of the last element in the subarray, we use two index variables, <span class="sans_thesansmonocd_w5regular_">i</span> and <span class="sans_thesansmonocd_w5regular_">j</span>, to swap the positions of the elements inside a <span class="sans_thesansmonocd_w5regular_">for</span> loop. Both start at the beginning of the subarray, and then <span class="sans_thesansmonocd_w5regular_">j</span> steps through the subarray looking for elements with values less than <span class="sans_thesansmonocd_w5regular_">pivot</span> <span aria-label="annotation3" class="codeannotation">❸</span>. Each time one is found, the values at <span class="sans_thesansmonocd_w5regular_">i</span> and <span class="sans_thesansmonocd_w5regular_">j</span> are swapped, and then <span class="sans_thesansmonocd_w5regular_">i</span> is incremented. In effect, this moves elements less than the pivot to earlier in the array, and elements greater than the pivot to later in the array. Once the <span class="sans_thesansmonocd_w5regular_">for</span> loop is done, the pivot itself is swapped with the element at <span class="sans_thesansmonocd_w5regular_">i</span> <span aria-label="annotation4" class="codeannotation">❹</span>, which puts the pivot element into its final sorted position. Then the final value of <span class="sans_thesansmonocd_w5regular_">i</span> is returned so that two new subarrays can be formed on both sides of the final position of the last pivot element. The swaps themselves are relegated to a <span aria-label="277" epub:type="pagebreak" id="pg_277" role="doc-pagebreak"/><span class="sans_thesansmonocd_w5regular_">swap()</span> helper function, which uses the <span class="sans_thesansmonocd_w5regular_">temp</span> variable to avoid overwriting the value at <span class="sans_thesansmonocd_w5regular_">i</span>. Apart from this one extra variable, the sorting happens in place.</p>
</section>
<section aria-labelledby="sec7" epub:type="division">
<h4 class="h1"><span id="sec7"/><span id="h2-118"/><span class="sans_futura_std_bold_condensed_oblique_">The Result</span></h4>
<p class="tni">If you run the code with the example array, the output should look like this:</p>
<pre class="calibre10"><code class="calibre11">*** Sorting an Array Using Quick Sort ***

original array:
[8, 3, 4, 5, 1, 2]

sorted array:
[1, 2, 3, 4, 5, 8]</code></pre>
<p class="tx">I mentioned earlier that I would explain how the order of the subarray elements is determined. This has to do with the swapping algorithm in the <span class="sans_thesansmonocd_w5regular_">partition()</span> function. During the first round of processing the [8, 3, 4, 5, 1, 2] array, for example, 2 is the pivot, and the first element in the array less than the pivot is 1. This element gets swapped with the 8 at the start of the array (accessed using index variable <span class="sans_thesansmonocd_w5regular_">i</span>), yielding an array of [1, 3, 4, 5, 8, 2]. Then the pivot itself (2) is swapped with the next element of the array (3—again accessed via <span class="sans_thesansmonocd_w5regular_">i</span>), yielding [1, 2, 4, 5, 8, 3].</p>
<p class="tx">I encourage you to manually step through the entire process of sorting the array with quick sort. You can refer to <a href="chapter7.xhtml#fig7-2" class="calibre2">Figure 7-2</a>, which shows the original input array, the intermediate subarrays after each round of processing, and the final sorted array. By going through the comparisons and swaps yourself, you can visualize the partitioning and sorting process in a more tangible way.</p>
<figure class="img"><img alt="" class="img2" height="436" id="fig7-2" src="../images/Figure7-2.jpg" width="896"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 7-2: The quick sort steps for [8, 3, 4, 5, 1, 2]</span></p></figcaption>
</figure>
<p class="tx">You can also autogenerate the subarrays at each stage by printing the left and right arrays from inside the <span class="sans_thesansmonocd_w5regular_">quicksort()</span> function, just after the position of the pivot is determined.</p>
<span aria-label="278" epub:type="pagebreak" id="pg_278" role="doc-pagebreak"/>
<aside aria-label="box-36" class="box2">
<p class="boxtitle" id="box-36"><span class="sans_futura_std_bold_b_">EXERCISE</span></p>
<p class="boxfirst"><span class="sans_futura_std_book_oblique_">Heap sort</span> <span class="sans_futura_std_book_">is an algorithm that sorts an array in ascending or descending order by first converting it into a</span> <span class="sans_futura_std_book_oblique_">binary heap</span><span class="sans_futura_std_book_">, a structure that organizes data in a tree-like fashion. A binary heap has two main properties:</span></p>
<ul class="ul">
<li class="boxlistbullet"><span class="sans_futura_std_book_">It’s a complete binary tree: every node in the tree has at most two child nodes, and all levels of the tree are fully filled, except possibly the last level, where the nodes are as far to the left as possible.</span></li>
<li class="boxlistbullet"><span class="sans_futura_std_book_">It satisfies either the</span> <span class="sans_futura_std_book_oblique_">max heap</span> <span class="sans_futura_std_book_">or the</span> <span class="sans_futura_std_book_oblique_">min heap</span> <span class="sans_futura_std_book_">property. For max heap, the value of each node must be greater than or equal to the values of its children. For min heap, the value of each node must be less than or equal to the values of its children.</span></li>
</ul>
<p class="box1"><span class="sans_futura_std_book_">Heap sort involves building a heap from the input array, repeatedly extracting the maximum (or minimum) element from the heap and placing it in the sorted portion of the array. Heap sort has a time complexity of</span> <span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(</span><span class="sans_futura_std_book_oblique_">n</span> <span class="sans_futura_std_book_">log</span> <span class="sans_futura_std_book_oblique_">n</span><span class="sans_futura_std_book_">) on average and in the worst case. And as an in-place sorting algorithm, it has a space complexity of</span> <span class="sans_futura_std_book_oblique_">O</span><span class="sans_futura_std_book_">(1). Although it isn’t stable, heap sort is used for its efficiency and minimal memory requirements.</span></p>
<p class="boxlast"><span class="sans_futura_std_book_">Do some research to learn more about the heap sort algorithm. Then write a Kotlin program to implement the algorithm.</span></p>
</aside>
</section>
</section>
<section aria-labelledby="sec8" epub:type="division">
<h3 class="h"><span id="sec8"/><span id="h1-46"/><span class="sans_futura_std_bold_b_">Search Algorithms</span></h3>
<p class="tni">Searching through a data structure is a fundamental operation in computer science. It helps us track down specific elements or retrieve information stored within a collection of data. While this task may seem trivial for a small amount of data, as the volume of data increases—up to large databases, filesystems, or even the whole internet—knowing how to choose the right search algorithm becomes paramount to keeping our digital life humming.</p>
<p class="tx">Search algorithms are intimately connected to the data structures they’re designed to search, since how the data is organized affects how efficiently a particular item can be found and accessed. For the purposes of the coming projects, we’ll focus on several algorithms that are used to search a graph, which is a type of data structure. Before we get to the algorithms themselves, however, it’s important to establish how graphs are structured.</p>
<section aria-labelledby="sec9" epub:type="division">
<h4 class="h1"><span id="sec9"/><span id="h2-119"/><span class="sans_futura_std_bold_condensed_oblique_">What Is a Graph?</span></h4>
<p class="tni">In the field of graph theory, a graph is a mathematical structure consisting of a set of vertices (also known as <i class="calibre9">nodes</i>) and a set of edges (also known as <i class="calibre9">arcs</i> or <i class="calibre9">links</i>) that connect pairs of vertices. Vertices can represent any kind <span aria-label="279" epub:type="pagebreak" id="pg_279" role="doc-pagebreak"/>of objects, such as cities, people, or even more abstract concepts. Edges represent relationships or connections between the vertices. Mathematically, a graph is denoted by <i class="calibre9">G</i> and defined as <i class="calibre9">G</i> = (<b class="calibre6"><i class="calibre9">V</i></b>, <b class="calibre6"><i class="calibre9">E</i></b>), where <b class="calibre6"><i class="calibre9">V</i></b> is a set of vertices or nodes, and <b class="calibre6"><i class="calibre9">E</i></b> is a set of edges or links.</p>
<p class="tx"><a href="chapter7.xhtml#fig7-3" class="calibre2">Figure 7-3</a> depicts a simple graph consisting of five nodes and five edges. Each circle in the figure represents a vertex, and each line represents an edge. The nodes are named with sequential numbers for convenience. In real-world cases, most nodes would be names with strings, however. When node names are designated by whole numbers, we can treat them as either of type <span class="sans_thesansmonocd_w5regular_">Int</span> or of type <span class="sans_thesansmonocd_w5regular_">String</span> in the code.</p>
<figure class="img"><img alt="" class="img5" height="331" id="fig7-3" src="../images/Figure7-3.jpg" width="316"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 7-3: A simple graph with five nodes and five edges</span></p></figcaption>
</figure>
<p class="tx">Graphs can be categorized into two main groups: undirected and directed. In an <i class="calibre9">undirected graph</i>, the edges allow movement between vertices in both directions. This type of graph is often used to represent scenarios like a road network, where traffic can flow both ways. By contrast, each edge in a <i class="calibre9">directed graph</i> has a specific direction associated with it, restricting the way you can move between vertices. For example, a directed graph can represent a water or power distribution network, where the flow always moves from areas of high pressure to areas of low pressure or from high voltage to low voltage, respectively.</p>
<p class="tx">When the edges of a graph have weights associated with them, the graph is called a <i class="calibre9">weighted graph</i>. The weight in this case could be a proxy for cost, distance, or any other edge-related property. Weighted graphs can be either directed or undirected.</p>
</section>
<section aria-labelledby="sec10" epub:type="division">
<h4 class="h1"><span id="sec10"/><span id="h2-120"/><span class="sans_futura_std_bold_condensed_oblique_">How to Search a Graph</span></h4>
<p class="tni">In the coming projects, we’ll consider three different algorithms for searching a graph. The first, <i class="calibre9">depth-first search (DFS)</i>, is a technique that starts at a particular node and explores as far (or “as deep”) as possible along one branch before backtracking and exploring the next. In this way, it traverses the depth of a data structure before exploring its breadth. DFS is often implemented by using a <i class="calibre9">stack</i> data structure (we explored stacks in <span><a href="chapter6.xhtml" class="calibre2">Chapter 6</a></span> while developing the L-system simulator). This way, DFS can use the youngest node in the stack to extend the branch and explore each adjacent node at the end of a branch before backtracking and moving to the next branch. DFS is useful in many applications, including scheduling <span aria-label="280" epub:type="pagebreak" id="pg_280" role="doc-pagebreak"/>problems, detecting cycles in graphs, and solving puzzles with only one solution, such as a maze or a sudoku puzzle.</p>
<p class="tx">The next algorithm, <i class="calibre9">breadth-first search (BFS)</i>, takes the opposite approach of DFS, exploring the data structure level by level. It starts at a given node and visits all its immediate neighbors. Then it moves on to the next level, visiting all the neighbors’ neighbors, and so on. In this way, BFS prioritizes exploring the breadth of the entire data structure over the depth of any individual branch. As we’ll discuss in <span><a href="chapter7.xhtml#pre-31" class="calibre2">Project 31</a></span>, BFS typically uses a queue data structure, allowing it to visit each level in order. It’s useful for finding the shortest path, web crawling, analyzing social networks, and exploring all reachable nodes in a graph while using the smallest number of iterations.</p>
<p class="tx">The choice between DFS and BFS depends on the specific problem and the characteristics of the data structure being searched. DFS is typically used when we want to conduct a deep exploration and potentially find a target item more quickly, while BFS is suitable for situations where we want to visit all nodes at a certain distance from the starting point or find the shortest path between nodes.</p>
<p class="tx">The final algorithm we’ll explore is called <i class="calibre9">A* search</i> (pronounced “A-star search”). It excels in finding the shortest path in a graph or a maze by combining heuristic decision-making with real-time exploration to guide the search. The term <i class="calibre9">heuristic</i> refers to general decision-making strategies that rely on intuition, educated guesses, or common sense to arrive at a plausible solution or direction to explore. While heuristics can’t guarantee an optimal or perfect outcome, they often provide an advantage in situations where constraints such as limited information, time, or resources exist.</p>
<p class="tx">The A* algorithm’s heuristic is to consider both the cost of reaching a specific node and an estimate of the remaining effort required to reach the destination. In this way, A* is able to intelligently prioritize the most promising paths. This strategic approach, similar to having a GPS in a labyrinth, helps save time and effort in the search process. Due to its versatility, A* is frequently applied in fields such as pathfinding in video games, robotics, navigation systems, and various optimization problems.</p>
<p class="headaexercise" id="pre-30"><span class="sans_dogma_ot_bold_b_15-n">Project 30: Stack-Based Searching with Depth-First Search</span></p>
<p class="tni">In this project, we’ll explore the core steps of depth-first search and implement them in Kotlin. We’ll employ the stack data structure in the code, although it’s worth noting the existence of other viable methods for implementing the core DFS algorithm. Later on, I’ll share some hints on an alternative approach.</p>
<p class="tx">For a given graph (a network of nodes and edges), here are the steps to perform a DFS by using a stack:</p>
<p class="listnumber">  1.  Start by selecting a node as the starting node (it can be any node).</p>
<p class="listnumber1">  2.  Push the starting node onto the stack.</p>
<p class="listnumber1">  3.  While the stack is not empty, pop a node from the stack.</p>
<p class="listnumber1"><span aria-label="281" epub:type="pagebreak" id="pg_281" role="doc-pagebreak"/>  4.  If the popped node is not yet visited, mark it as visited and push its neighbors to the stack; or else pop the next node from the stack.</p>
<p class="listnumber2">  5.  Repeat steps 3 and 4 until the stack is empty.</p>
<p class="tx">Recall from <span><a href="chapter6.xhtml" class="calibre2">Chapter 6</a></span> that a stack follows the LIFO principle, whereby items are removed from the stack in the reverse order in which they were added. The LIFO principle allows the DFS algorithm to backtrack from the end of one branch before starting on a new, unvisited branch. This ensures an exhaustive search of the entire graph, although it would also be beneficial to include a stopping condition. When each node is visited, this condition would check if the desired goal of the search has been achieved, such as finding a specific object or completing a particular task. Once the goal is met, the search can be terminated early. For this project, we’ll use the graph shown in <a href="chapter7.xhtml#fig7-3" class="calibre2">Figure 7-3</a>.</p>
<p class="tx">The time complexity of the DFS algorithm is <i class="calibre9">O</i>(<i class="calibre9">V</i> + <i class="calibre9">E</i>), where <i class="calibre9">V</i> is the number of vertices and <i class="calibre9">E</i> is the number of edges in the graph. The space complexity of DFS depends on the implementation (a stack versus a recursive function); the worst-case space complexity is <i class="calibre9">O</i>(<i class="calibre9">V</i>).</p>
</section>
<section aria-labelledby="sec11" epub:type="division">
<h4 class="h1"><span id="sec11"/><span id="h2-121"/><span class="sans_futura_std_bold_condensed_oblique_">The Code</span></h4>
<p class="tni">Let’s now examine the code that implements the core steps of DFS. We’ll use the code to traverse the entire example graph shown earlier in <a href="chapter7.xhtml#fig7-3" class="calibre2">Figure 7-3</a>.</p>
<pre class="calibre10"><code class="calibre11">import java.util.ArrayDeque

fun main() {
  <span aria-label="annotation1" class="code_codeannotation">❶</span> val graph = mapOf(
        "0" to setOf("1", "2", "3"),
        "1" to setOf("0", "2"),
        "2" to setOf("0", "1", "4"),
        "3" to setOf("0"),
        "4" to setOf("2")
    )
    println("\n*** Depth-First Search of a Graph ***\n")
    println("Graph to search:")
    for ((key,value) in graph)
        println("Node: $key,  Neighbors: $value")

  <span aria-label="annotation2" class="code_codeannotation">❷</span> val visited = dfsStack(graph, "0")
    println("\nVisited nodes:\n$visited")
}

fun dfsStack(graph: Map&lt;String, Set&lt;String&gt;&gt;, start: String):
             Set&lt;String&gt; {

    val visited = mutableSetOf&lt;String&gt;()
    val stack = ArrayDeque&lt;String&gt;()
    stack.push(start)

  <span aria-label="annotation3" class="code_codeannotation">❸</span> while (stack.isNotEmpty()) {
        val node = stack.pop()
<span aria-label="282" epub:type="pagebreak" id="pg_282" role="doc-pagebreak"/>        if (node !in visited) {
            // Do something as needed.
            visited.add(node)
          <span aria-label="annotation4" class="code_codeannotation">❹</span> for (next in graph[node]!!) {
                 stack.push(next)
            }
        }
    }
    return visited
}</code></pre>
<p class="tx">First, we import the <span class="sans_thesansmonocd_w5regular_">ArrayDeque</span> class from <span class="sans_thesansmonocd_w5regular_">java.util</span>, which we’ll use to implement the stack. Next, we declare the <span class="sans_thesansmonocd_w5regular_">main()</span> function, which serves as the entry point of the program. It defines the graph as a <span class="sans_thesansmonocd_w5regular_">map</span> pairing each node (<span class="sans_thesansmonocd_w5regular_">"0"</span> through <span class="sans_thesansmonocd_w5regular_">"4"</span>) with a set of all its neighboring nodes <span aria-label="annotation1" class="codeannotation">❶</span>. For example, node <span class="sans_thesansmonocd_w5regular_">"2"</span> is paired with the set <span class="sans_thesansmonocd_w5regular_">["0", "1", "4"]</span>, since it’s connected to those nodes. We print the graph to the console, then call the <span class="sans_thesansmonocd_w5regular_">dfsStack()</span> function to perform the search, passing the graph and a starting node as arguments <span aria-label="annotation2" class="codeannotation">❷</span>. Upon completion of the search, the list of visited nodes is returned, which is printed as the program’s final output.</p>
<p class="tx">Inside the <span class="sans_thesansmonocd_w5regular_">dfsStack()</span> function, we create a mutable set called <span class="sans_thesansmonocd_w5regular_">visited</span> to keep track of the visited nodes and an <span class="sans_thesansmonocd_w5regular_">ArrayDeque</span> named <span class="sans_thesansmonocd_w5regular_">stack</span> to store the nodes during traversal. We push the starting node to the stack, then enter a <span class="sans_thesansmonocd_w5regular_">while</span> loop that iterates for as long as the stack is not empty <span aria-label="annotation3" class="codeannotation">❸</span>. In each iteration, the last node from the stack is removed by using <span class="sans_thesansmonocd_w5regular_">pop()</span> and assigned to the variable <span class="sans_thesansmonocd_w5regular_">node</span>. If the node hasn’t been visited before, we could perform additional operations or processing specific to the application at this point—for example, checking if the node matches our search criteria and breaking from the loop if it does. The node is then added to the <span class="sans_thesansmonocd_w5regular_">visited</span> set by using the <span class="sans_thesansmonocd_w5regular_">add()</span> function.</p>
<p class="tx">Next, we add all neighboring nodes, retrieved from <span class="sans_thesansmonocd_w5regular_">graph</span> by using <span class="sans_thesansmonocd_w5regular_">node</span> as the key, to the stack via the <span class="sans_thesansmonocd_w5regular_">push()</span> function <span aria-label="annotation4" class="codeannotation">❹</span>. We use the nonnull assertion operator (<span class="sans_thesansmonocd_w5regular_">!!</span>) while adding <span class="sans_thesansmonocd_w5regular_">graph[node]</span> to the stack to avoid additional null safety checks that aren’t required for undirected graphs (every node will have at least one link or edge). The <span class="sans_thesansmonocd_w5regular_">while</span> loop terminates once the stack is empty, at which point the set of visited nodes is returned to <span class="sans_thesansmonocd_w5regular_">main()</span>.</p>
<p class="tx">Note that we could have used the <span class="sans_thesansmonocd_w5regular_">ArrayDeque</span> class from <span class="sans_thesansmonocd_w5regular_">kotlin.collections</span> (as we did in <span><a href="chapter6.xhtml" class="calibre2">Chapter 6</a></span>) instead of <span class="sans_thesansmonocd_w5regular_">ArrayDeque</span> from <span class="sans_thesansmonocd_w5regular_">java.util</span> to implement the stack. In that case, we would replace <span class="sans_thesansmonocd_w5regular_">push()</span> with <span class="sans_thesansmonocd_w5regular_">addLast()</span> and <span class="sans_thesansmonocd_w5regular_">pop()</span> with the <span class="sans_thesansmonocd_w5regular_">removeLast()</span> function. I’ve chosen to use the Java version in part to illustrate an alternative stack implementation and in part because the <span class="sans_thesansmonocd_w5regular_">ArrayDeque</span> method names like <span class="sans_thesansmonocd_w5regular_">push()</span> and <span class="sans_thesansmonocd_w5regular_">pop()</span> fit naturally with the stack architecture. Both techniques follow the LIFO principle, meaning that the last element added to the stack is the first one removed.</p>
</section>
<section aria-labelledby="sec12" epub:type="division">
<h4 class="h1"><span id="sec12"/><span id="h2-122"/><span class="sans_futura_std_bold_condensed_oblique_">The Result</span></h4>
<p class="tni">If you run the code with the given graph, you should get the following output:</p>
<pre class="calibre10"><code class="calibre11"><span aria-label="283" epub:type="pagebreak" id="pg_283" role="doc-pagebreak"/>*** Depth-First Search of a Graph ***

Graph to search:
Node: 0,  Neighbors: [1, 2, 3]
Node: 1,  Neighbors: [0, 2]
Node: 2,  Neighbors: [0, 1, 4]
Node: 3,  Neighbors: [0]
Node: 4,  Neighbors: [2]

Visited nodes:
[0, 3, 2, 4, 1]</code></pre>
<p class="tx">The list of visited nodes <span class="sans_thesansmonocd_w5regular_">[0, 3, 2, 4, 1]</span> indicates the algorithm has traversed the entire graph. To see where this order comes from, and to better understand how the stack facilitates the DFS process, consider <a href="chapter7.xhtml#tab7-2" class="calibre2">Table 7-2</a>, which shows the intermediate values at each step of the algorithm.</p>
<p class="tt" id="tab7-2"><span class="sans_futura_std_bold_b_"><span class="sans_futura_std_bold_b_">Table 7-2:</span></span> <span class="sans_futura_std_book_">Anatomy of the Depth-First Search Using Stack</span></p>
<table class="basic-table">
<thead class="calibre13">
<tr class="calibre14">
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Stage</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Node</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Node not visited?</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Visited nodes</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Neighbor nodes</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Nodes on stack</span></p></th>
</tr>
</thead>
<tbody class="calibre15">
<tr class="calibre16">
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">Initialization, with</span> <span class="sans_thesansmonocd_w5regular_">start</span> <span class="sans_futura_std_book_">of 0</span></p></td>
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">N/A</span></p></td>
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">N/A</span></p></td>
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">[] (empty)</span></p></td>
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">N/A</span></p></td>
<td class="tbf"><p class="tableheader"><span class="sans_futura_std_book_">[0] (</span><span class="sans_thesansmonocd_w5regular_">start</span> <span class="sans_futura_std_book_">pushed to stack)</span></p></td>
</tr>
<tr class="calibre14">
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">Inside the</span> <span class="sans_thesansmonocd_w5regular_">while</span> <span class="sans_futura_std_book_">loop</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">0</span></p>
<p class="tb1"><span class="sans_futura_std_book_">3</span></p>
<p class="tb1"><span class="sans_futura_std_book_">0</span></p>
<p class="tb1"><span class="sans_futura_std_book_">2</span></p>
<p class="tb1"><span class="sans_futura_std_book_">4</span></p>
<p class="tb1"><span class="sans_futura_std_book_">2</span></p>
<p class="tb1"><span class="sans_futura_std_book_">1</span></p>
<p class="tb1"><span class="sans_futura_std_book_">2</span></p>
<p class="tb1"><span class="sans_futura_std_book_">0</span></p>
<p class="tb1"><span class="sans_futura_std_book_">0</span></p>
<p class="tb1"><span class="sans_futura_std_book_">1</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">true</span></p>
<p class="tb1"><span class="sans_futura_std_book_">true</span></p>
<p class="tb1"><span class="sans_futura_std_book_">false</span></p>
<p class="tb1"><span class="sans_futura_std_book_">true</span></p>
<p class="tb1"><span class="sans_futura_std_book_">true</span></p>
<p class="tb1"><span class="sans_futura_std_book_">false</span></p>
<p class="tb1"><span class="sans_futura_std_book_">true</span></p>
<p class="tb1"><span class="sans_futura_std_book_">false</span></p>
<p class="tb1"><span class="sans_futura_std_book_">false</span></p>
<p class="tb1"><span class="sans_futura_std_book_">false</span></p>
<p class="tb1"><span class="sans_futura_std_book_">false</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">[0]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0, 3]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">no change</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0, 3, 2]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0, 3, 2, 4]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">no change</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0, 3, 2, 4, 1]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">no change</span></p>
<p class="tb1"><span class="sans_futura_std_book_">no change</span></p>
<p class="tb1"><span class="sans_futura_std_book_">no change</span></p>
<p class="tb1"><span class="sans_futura_std_book_">no change</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">[1, 2, 3]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">N/A</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0, 1, 4]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[2]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">N/A</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0, 2]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">N/A</span></p>
<p class="tb1"><span class="sans_futura_std_book_">N/A</span></p>
<p class="tb1"><span class="sans_futura_std_book_">N/A</span></p>
<p class="tb1"><span class="sans_futura_std_book_">N/A</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">[1, 2, 3]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 2, 0]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 2]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 0, 1, 4]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 0, 1, 2]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 0, 1]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 0, 0, 2]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 0, 0]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 0]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[] (empty;</span> <span class="sans_thesansmonocd_w5regular_">while</span> <span class="sans_futura_std_book_">loop terminates)</span></p></td>
</tr>
</tbody>
</table>
<p class="tx">Let’s take a look at a few rows from <a href="chapter7.xhtml#tab7-2" class="calibre2">Table 7-2</a> to understand how DFS works. In the first row, we see what happens during the initialization phase, before entering the <span class="sans_thesansmonocd_w5regular_">while</span> loop. We set the starting node to <span class="sans_thesansmonocd_w5regular_">"0"</span> and push it onto the stack. At this stage, node <span class="sans_thesansmonocd_w5regular_">"0"</span> hasn’t been marked as visited yet. Next, we move inside the <span class="sans_thesansmonocd_w5regular_">while</span> loop, where the rest of the processing happens. First, we pop the last node from the stack, which is <span class="sans_thesansmonocd_w5regular_">"0"</span> (this makes the stack momentarily empty). Since this node isn’t yet marked as visited, we add it to the list of visited nodes, which goes from <span class="sans_thesansmonocd_w5regular_">[]</span> to <span class="sans_thesansmonocd_w5regular_">[0]</span>. We then add all this node’s neighbors (accessed with <span class="sans_thesansmonocd_w5regular_">graph["0"]</span>) to the stack, which goes from <span class="sans_thesansmonocd_w5regular_">[]</span> to <span class="sans_thesansmonocd_w5regular_">[1, 2, 3]</span>.</p>
<p class="tx"><span aria-label="284" epub:type="pagebreak" id="pg_284" role="doc-pagebreak"/>The next time through the loop, <span class="sans_thesansmonocd_w5regular_">"3"</span> is popped from the stack, since it’s the last element. It hasn’t been visited yet, so it’s added to <span class="sans_thesansmonocd_w5regular_">visited</span>, and its only neighbor <span class="sans_thesansmonocd_w5regular_">"0"</span> is pushed to the stack. The process continues until the stack is found to be empty at the start of a <span class="sans_thesansmonocd_w5regular_">while</span> loop iteration. I strongly encourage you to go over the remaining rows of the table to get a hands-on feel for how the DFS algorithm works in practice.</p>
<aside aria-label="box-37" class="box2">
<p class="boxtitle" id="box-37"><span class="sans_futura_std_bold_b_">EXERCISE</span></p>
<p class="boxfirst"><span class="sans_futura_std_book_">In <a href="chapter7.xhtml#pre-30" class="calibre2">Project 30</a></span><span class="sans_futura_std_book_">, we used a stack to search a graph. This process can be simplified by using recursion, which repeats a few key steps until a stopping condition is met. A recursive function can make the DFS process shorter and clearer. To implement DFS by using recursion, do the following:</span></p>
<div class="spc">
<p class="boxlistnumber"><span class="sans_futura_std_book_">1.  Write a recursive function for DFS called</span> <span class="sans_thesansmonocd_w5regular_">dfsRecursion()</span> <span class="sans_futura_std_book_">that replaces the</span> <span class="sans_thesansmonocd_w5regular_">dfsStack()</span> <span class="sans_futura_std_book_">function. The function would have the three parameters:</span> <span class="sans_thesansmonocd_w5regular_">graph</span><span class="sans_futura_std_book_">,</span> <span class="sans_thesansmonocd_w5regular_">start</span><span class="sans_futura_std_book_">, and</span> <span class="sans_thesansmonocd_w5regular_">visited</span> <span class="sans_futura_std_book_">(as a mutable list). The recursive part of the function could look like this:</span></p>
<pre class="calibre10"><code class="calibre11">for (next in (graph[start]!! – visited)) {
    dfsRecursion(graph, next, visited)
}</code></pre>
<p class="boxlist"><span class="sans_futura_std_book_">The recursion will stop when no more unvisited nodes that are connected to the current node remain. Notice that</span> <span class="sans_thesansmonocd_w5regular_">graph[start]!! - visited</span> <span class="sans_futura_std_book_">is a set operation, not a regular subtraction operation.</span></p>
<p class="boxlistnumber"><span class="sans_futura_std_book_">2.  In <a href="chapter7.xhtml#pre-30" class="calibre2">Project 30</a>, we defined the graph as a</span> <span class="sans_thesansmonocd_w5regular_">Map</span> <span class="sans_futura_std_book_">object. We could also define it by using instances of Kotlin’s</span> <span class="sans_thesansmonocd_w5regular_">Pair</span> <span class="sans_futura_std_book_">data class, one pair for each node and its neighbors. Make this change.</span></p>
<p class="boxlistnumber"><span class="sans_futura_std_book_">3.  Use integers instead of strings to denote each node in the graph.</span></p>
<p class="boxlistnumber"><span class="sans_futura_std_book_">4.  Run the code after each change and compare your results with the original output from the stack version of the code.</span></p>
</div>
</aside>
<p class="headaexercise" id="pre-31"><span class="sans_dogma_ot_bold_b_15-n">Project 31: Queue-Based Searching with Breadth-First Search</span></p>
<p class="tni">In this project we’ll continue our exploration of search algorithms by implementing breadth-first search. BFS guarantees that all nodes at the same level are visited before moving on to the next level. This process continues until all nodes in the graph have been visited. As in <span><a href="chapter7.xhtml#pre-30" class="calibre2">Project 30</a></span>, we’ll use the <span class="sans_thesansmonocd_w5regular_">ArrayDeque</span> class from <span class="sans_thesansmonocd_w5regular_">java.util</span> to implement the BFS algorithm. This time, however, we’ll use the class as a <i class="calibre9">queue</i>, a data structure that adheres to the <i class="calibre9">first in, first out (FIFO)</i> principle. Whereas items are always added (“pushed”) or removed (“popped”) from the end of a stack, items are added <span aria-label="285" epub:type="pagebreak" id="pg_285" role="doc-pagebreak"/>(“enqueued”) at the end of a queue and removed (“dequeued”) from the beginning of the queue. This ensures that items are processed in the order in which they were added to the queue.</p>
<p class="tx">To perform a BFS, we’ll follow these steps:</p>
<div class="spc">
<p class="listnumber">  1.  Select a node as the starting node (it can be any node).</p>
<p class="listnumber1">  2.  Create a mutable list called <span class="sans_thesansmonocd_w5regular_">visited</span> and add the starting node to it.</p>
<p class="listnumber1">  3.  Create an empty queue and enqueue (add) the starting node.</p>
<p class="listnumber1">  4.  While the queue is not empty, perform the following steps:</p>
<p class="listnumbersub">a.  Dequeue the front node from the queue.</p>
<p class="listnumbersub">b.  Process the dequeued node as needed (perhaps printing its value or performing some operation).</p>
<p class="listnumbersub">c.  Enqueue all the unvisited neighbors of the dequeued node and mark them as visited.</p>
</div>
<p class="tni">We’ll use the graph shown in <a href="chapter7.xhtml#fig7-3" class="calibre2">Figure 7-3</a> for this project as well.</p>
<p class="tx">The time complexity of the BFS algorithm is <i class="calibre9">O</i>(<i class="calibre9">V</i> + <i class="calibre9">E</i>), where <i class="calibre9">V</i> is the number of vertices and <i class="calibre9">E</i> is the number of edges in the graph. The space complexity of the BFS algorithm is typically <i class="calibre9">O</i>(<i class="calibre9">V</i>). Both DFS and BFS therefore have the same time complexity, but their space complexity can vary depending on the implementation and the structure of the graph.</p>
</section>
<section aria-labelledby="sec13" epub:type="division">
<h4 class="h1"><span id="sec13"/><span id="h2-123"/><span class="sans_futura_std_bold_condensed_oblique_">The Code</span></h4>
<p class="tni">The code for BFS closely resembles that of DFS, but I’ll highlight a few important distinctions as we discuss the program.</p>
<pre class="calibre10"><code class="calibre11">import java.util.ArrayDeque

fun main() {
    // Define the graph to be searched.
    val graph = mapOf(
        "0" to setOf("1", "2", "3"),
        "1" to setOf("0", "2"),
        "2" to setOf("0", "1", "4"),
        "3" to setOf("0"),
        "4" to setOf("2")
    )
    println("\n*** Breadth-First Search of a Graph ***\n")
    println("Graph to search:")
    for ((key,value) in graph)
        println("Node: $key,  Neighbors: $value")

  <span aria-label="annotation1" class="code_codeannotation">❶</span> val visited = bfsQueue(graph, "0")
    println("\nVisited nodes:\n$visited")
}

fun bfsQueue(graph: Map&lt;String, Set&lt;String&gt;&gt;, start: String): Set&lt;String&gt; {
    val visited = mutableSetOf&lt;String&gt;()
<span aria-label="286" epub:type="pagebreak" id="pg_286" role="doc-pagebreak"/>    visited.add(start)
    val queue = ArrayDeque&lt;String&gt;()
    queue.offer(start)

  <span aria-label="annotation2" class="code_codeannotation">❷</span> while (queue.isNotEmpty()) {
        val node = queue.poll()
        for (next in graph[node]!!) {
          <span aria-label="annotation3" class="code_codeannotation">❸</span> if (next !in visited) {
                queue.offer(next)
                visited.add(next)
            }
        }
    }
    return visited
}</code></pre>
<p class="tx">The <span class="sans_thesansmonocd_w5regular_">main()</span> function is essentially the same as that of the previous project. We define the input graph by using a <span class="sans_thesansmonocd_w5regular_">map</span> data structure and print the graph, displaying each node and its neighbors. We then call the <span class="sans_thesansmonocd_w5regular_">bfsQueue()</span> search function, passing the graph and the starting node as arguments <span aria-label="annotation1" class="codeannotation">❶</span>. The function returns the visited nodes, which are printed as the final output of the program.</p>
<p class="tx">Inside the <span class="sans_thesansmonocd_w5regular_">bfsQueue()</span> function, we initialize a mutable list called <span class="sans_thesansmonocd_w5regular_">visited</span> to keep track of visited nodes as before, along with an <span class="sans_thesansmonocd_w5regular_">ArrayDeque</span> called <span class="sans_thesansmonocd_w5regular_">queue</span> to store the nodes to be visited. We then add the starting node to both the visited set and the queue, using the <span class="sans_thesansmonocd_w5regular_">offer()</span> method for the latter. Next, we initiate a <span class="sans_thesansmonocd_w5regular_">while</span> loop that continues until the queue becomes empty <span aria-label="annotation2" class="codeannotation">❷</span>. Within the loop, we dequeue a node from the front of the queue by using the <span class="sans_thesansmonocd_w5regular_">poll()</span> method, placing it in the <span class="sans_thesansmonocd_w5regular_">node</span> variable. We then iterate over each neighbor of the current node, obtained from the graph. If a neighbor hasn’t been visited (meaning it isn’t present in the <span class="sans_thesansmonocd_w5regular_">visited</span> set), it’s enqueued by using the <span class="sans_thesansmonocd_w5regular_">offer()</span> method and added to the <span class="sans_thesansmonocd_w5regular_">visited</span> set <span aria-label="annotation3" class="codeannotation">❸</span>. After processing all the neighbors, the loop continues until the queue becomes empty. The <span class="sans_thesansmonocd_w5regular_">visited</span> set is then returned, containing all the nodes visited during the search.</p>
</section>
<section aria-labelledby="sec14" epub:type="division">
<h4 class="h1"><span id="sec14"/><span id="h2-124"/><span class="sans_futura_std_bold_condensed_oblique_">The Result</span></h4>
<p class="tni">For the given graph, if you run the code without any changes, the code will produce the following output:</p>
<pre class="calibre10"><code class="calibre11">*** Breadth-First Search of a Graph ***

Graph to search:
Node: 0,  Neighbors: [1, 2, 3]
Node: 1,  Neighbors: [0, 2]
Node: 2,  Neighbors: [0, 1, 4]
Node: 3,  Neighbors: [0]
Node: 4,  Neighbors: [2]

Visited nodes:
[0, 1, 2, 3, 4]</code></pre>
<p class="tx"><span aria-label="287" epub:type="pagebreak" id="pg_287" role="doc-pagebreak"/>Again, the list of visited nodes <span class="sans_thesansmonocd_w5regular_">[0, 1, 2, 3, 4]</span> indicates the algorithm has successfully traversed the entire graph. This time, the nodes are marked as visited in numerical order, a function of the FIFO principle of the queue. <a href="chapter7.xhtml#tab7-3" class="calibre2">Table 7-3</a> shows the intermediate values of the key variables as the process unfolds and how the BFS algorithm works.</p>
<p class="tt" id="tab7-3"><span class="sans_futura_std_bold_b_"><span class="sans_futura_std_bold_b_">Table 7-3:</span></span> <span class="sans_futura_std_book_">Anatomy of the Breadth-First Search Using a Queue</span></p>
<table class="basic-table">
<thead class="calibre13">
<tr class="calibre14">
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Stage</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Node</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Neighbor nodes</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_thesansmonocd_w7bold_">next</span> <span class="sans_futura_std_bold_b_">node</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Node not visited?</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Nodes on queue</span></p></th>
<th class="tch" scope="col"><p class="tableheader"><span class="sans_futura_std_bold_b_">Visited nodes</span></p></th>
</tr>
</thead>
<tbody class="calibre15">
<tr class="calibre14">
<td class="tbf1"><p class="tableheader"><span class="sans_futura_std_book_">Initialization, with</span> <span class="sans_thesansmonocd_w5regular_">start</span> <span class="sans_futura_std_book_">of 0</span></p></td>
<td class="tbf1"><p class="tableheader"><span class="sans_futura_std_book_">N/A</span></p></td>
<td class="tbf1"><p class="tableheader"><span class="sans_futura_std_book_">N/A</span></p></td>
<td class="tbf1"><p class="tableheader"><span class="sans_futura_std_book_">N/A</span></p></td>
<td class="tbf1"><p class="tableheader"><span class="sans_futura_std_book_">N/A</span></p></td>
<td class="tbf1"><p class="tableheader"><span class="sans_futura_std_book_">[0]</span></p></td>
<td class="tbf1"><p class="tableheader"><span class="sans_futura_std_book_">[0]</span></p></td>
</tr>
<tr class="calibre14">
<td class="tbl" rowspan="5"><p class="tb1"><span class="sans_futura_std_book_">Inside the</span> <span class="sans_thesansmonocd_w5regular_">while</span> <span class="sans_futura_std_book_">loop</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">0</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">[1, 2, 3]</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">1</span></p>
<p class="tb1"><span class="sans_futura_std_book_">2</span></p>
<p class="tb1"><span class="sans_futura_std_book_">3</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">true</span></p>
<p class="tb1"><span class="sans_futura_std_book_">true</span></p>
<p class="tb1"><span class="sans_futura_std_book_">true</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">[1]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 2]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[1, 2, 3]</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">[0, 1]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0, 1, 2]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0, 1, 2, 3]</span></p></td>
</tr>
<tr class="calibre14">
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">1</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">[0, 2]</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">0</span></p>
<p class="tb1"><span class="sans_futura_std_book_">2</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">false</span></p>
<p class="tb1"><span class="sans_futura_std_book_">false</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">[2, 3]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[2, 3]</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">no change</span></p>
<p class="tb1"><span class="sans_futura_std_book_">no change</span></p></td>
</tr>
<tr class="calibre14">
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">2</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">[0, 1, 4]</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">0</span></p>
<p class="tb1"><span class="sans_futura_std_book_">1</span></p>
<p class="tb1"><span class="sans_futura_std_book_">4</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">false</span></p>
<p class="tb1"><span class="sans_futura_std_book_">false</span></p>
<p class="tb1"><span class="sans_futura_std_book_">true</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">[3]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[3]</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[3, 4]</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">no change</span></p>
<p class="tb1"><span class="sans_futura_std_book_">no change</span></p>
<p class="tb1"><span class="sans_futura_std_book_">[0, 1, 2, 3, 4]</span></p></td>
</tr>
<tr class="calibre14">
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">3</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">[0]</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">0</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">false</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">[4]</span></p></td>
<td class="tb"><p class="tb1"><span class="sans_futura_std_book_">no change</span></p></td>
</tr>
<tr class="calibre14">
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">4</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">[2]</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">2</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">false</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">[] (empty;</span> <span class="sans_thesansmonocd_w5regular_">while</span> <span class="sans_futura_std_book_">loop terminates)</span></p></td>
<td class="tbl"><p class="tb1"><span class="sans_futura_std_book_">no change</span></p></td>
</tr>
</tbody>
</table>
<p class="tx">Let’s go over a few of the rows in <a href="chapter7.xhtml#tab7-3" class="calibre2">Table 7-3</a> to gain a better understanding of how the BFS algorithm is implemented. At the initialization stage, we identify node <span class="sans_thesansmonocd_w5regular_">"0"</span> as the start node and add it to both the <span class="sans_thesansmonocd_w5regular_">visited</span> list and the queue. Both of these lists now contain <span class="sans_thesansmonocd_w5regular_">"0"</span> (see the first row).</p>
<p class="tx">Next, we move inside the <span class="sans_thesansmonocd_w5regular_">while</span> loop, which runs as long as <span class="sans_thesansmonocd_w5regular_">queue</span> is not empty. We start with the front node <span class="sans_thesansmonocd_w5regular_">"0"</span> and fetch its neighboring nodes, <span class="sans_thesansmonocd_w5regular_">"1"</span>, <span class="sans_thesansmonocd_w5regular_">"2"</span>, and <span class="sans_thesansmonocd_w5regular_">"3"</span>. For each, we check that it hasn’t been visited before; when this is true, we add that node to both <span class="sans_thesansmonocd_w5regular_">queue</span> and <span class="sans_thesansmonocd_w5regular_">visited</span>. Since none of these nodes were visited, they’re all added to <span class="sans_thesansmonocd_w5regular_">queue</span> and <span class="sans_thesansmonocd_w5regular_">visited</span> when we’re done with node <span class="sans_thesansmonocd_w5regular_">"0"</span>.</p>
<p class="tx">The process continues by pulling the next front node, <span class="sans_thesansmonocd_w5regular_">"1"</span>. This time both its neighbors, <span class="sans_thesansmonocd_w5regular_">"0"</span> and <span class="sans_thesansmonocd_w5regular_">"2"</span>, show up in the visited list, so nothing is added to <span class="sans_thesansmonocd_w5regular_">queue</span> or <span class="sans_thesansmonocd_w5regular_">visited</span>. Each time we remove a node from <span class="sans_thesansmonocd_w5regular_">queue</span>, the queue shrinks in size. In the final step, node <span class="sans_thesansmonocd_w5regular_">"4"</span> is pulled out, making <span class="sans_thesansmonocd_w5regular_">queue</span> empty, which breaks the <span class="sans_thesansmonocd_w5regular_">while</span> loop. The code returns the <span class="sans_thesansmonocd_w5regular_">visited</span> list as the final output.</p>
<p class="tx">Comparing <a href="chapter7.xhtml#tab7-2" class="calibre2">Tables 7-2</a> and <a href="chapter7.xhtml#tab7-3" class="calibre2">7-3</a> will help you gain a deeper understanding of the unique features of the DFS and BFS algorithms.</p>
<p class="headaexercise" id="pre-32"><span aria-label="288" epub:type="pagebreak" id="pg_288" role="doc-pagebreak"/><span class="sans_dogma_ot_bold_b_15-n">Project 32: Heuristic Searching with A*</span></p>
<p class="tni">In this project, we’ll explore the A* search algorithm, an informed search algorithm that uses a heuristic function to guide the search. Its primary objective is to find the optimal path between two nodes in a graph by considering the cost of each path. To that end, it’s best suited for working with weighted graphs, where each edge has an associated score. <a href="chapter7.xhtml#fig7-4" class="calibre2">Figure 7-4</a> shows the graph we’ll use for the project.</p>
<figure class="img"><img alt="" class="img3" height="591" id="fig7-4" src="../images/Figure7-4.jpg" width="780"/>
<figcaption><p class="cap"><span class="sans_futura_std_book_oblique_">Figure 7-4: An example graph for <a href="chapter7.xhtml#pre-32" class="calibre2">Project 32</a> (start node = A, target node = J)</span></p></figcaption>
</figure>
<p class="tx">The graph in the figure has 13 nodes (A through M) and 20 edges, making it significantly more substantial than the example graph we used in the previous projects. The values along the edges represent the cost of traveling between the two nodes connected by that edge. We’re assuming that the graph is undirected, so travel along an edge can go in either direction, and that the cost for each edge is <i class="calibre9">symmetric</i>, meaning it’s the same no matter the direction of travel. For this project, we’re interested in determining the lowest-cost route from node A (the start) to node J (the target).</p>
<p class="tx">As the A* algorithm traverses a graph, it uses two distinct functions to help make decisions. One calculates the <i class="calibre9">g-score</i>, the actual cost of traveling from the start node to the current node. The other calculates the <i class="calibre9">h-score</i>, the estimated or heuristic cost of traveling from the current node to the target node. Added together, these two scores give the <i class="calibre9">f-score</i>, the estimated total cost of the path:</p>
<p class="equation"><i class="calibre9">  f-score</i> = <i class="calibre9">g-score</i> + <i class="calibre9">h-score</i></p>
<p class="tx">One of the key strengths of the A* algorithm is its efficiency in finding the shortest path based on this informed approach. But for this to work, we need a good heuristic function.</p>
</section>
<section aria-labelledby="sec15" epub:type="division">
<span aria-label="289" epub:type="pagebreak" id="pg_289" role="doc-pagebreak"/>
<h4 class="h1"><span id="sec15"/><span id="h2-125"/><span class="sans_futura_std_bold_condensed_oblique_">The Heuristic Function</span></h4>
<p class="tni">In the context of the A* search algorithm, a heuristic function, denoted as <i class="calibre9">h</i>(<i class="calibre9">n</i>), is a function that estimates the cost from the current node to the target node in a graph. The purpose of the heuristic function is to guide the search algorithm by providing an informed estimate of how far a node is from the target, which helps A* make more efficient decisions about which nodes to explore next.</p>
<p class="tx">An <i class="calibre9">admissible</i> heuristic function for the A* algorithm is a function that never overestimates the cost of reaching the goal from any node. With an admissible set of h-scores, A* is guaranteed to find the shortest or least costly path. However, not all sets of admissible h-scores are equally good. The algorithm’s performance depends on how close the h-scores are to the true costs. The more accurate the h-scores are, the faster the algorithm will find the optimal path.</p>
<p class="tx">Another desirable property of the heuristic function is consistency. A <i class="calibre9">consistent</i> function satisfies this condition: the cost of reaching the goal from a node is always less than or equal to the cost of reaching the goal from any neighbor of that node, plus the cost of moving to that neighbor. Consistency implies admissibility but not vice versa. A consistent set of h-scores can make the A* algorithm more efficient, as it will expand fewer nodes and converge to the optimal solution very quickly.</p>
<p class="tx">Consistent h-scores may be hard or impossible to obtain for large and complex real-world problems. However, we can still estimate admissible h-scores that are of high quality by using various techniques, depending on the problem type. Here are some common approaches for generating heuristic functions:</p>
<p class="listhead"><b class="calibre6">Ad hoc selection of h-scores</b></p>
<p class="listplainfirst">This method will work when the graph is small and it’s possible to make conservative guesses about the h-scores depending on the depth of a node. For example, one can set all h-scores to some arbitrary small value that’s guaranteed to be both admissible and consistent.</p>
<p class="listhead"><b class="calibre6">Domain knowledge</b></p>
<p class="listplainfirst">In some cases, domain-specific knowledge can be used to craft heuristic functions. This requires an understanding of the problem and what makes a good heuristic based on expert insights. For example, in the case of solving an eight-piece sliding puzzle with a 3×3 grid, a practical heuristic is the Manhattan distance, determined by adding the horizontal and vertical distances between each tile’s current position and its target location.</p>
<p class="listhead"><b class="calibre6">Relaxation heuristics</b></p>
<p class="listplainfirst">This method involves simplifying a problem by temporarily ignoring certain constraints. Relaxation frequently results in an admissible heuristic because it tends to underestimate the actual cost. Take, for example, pathfinding problems, where one can use the Euclidean <span aria-label="290" epub:type="pagebreak" id="pg_290" role="doc-pagebreak"/>distance between two points as a heuristic, ignoring any obstacles that may lengthen the path.</p>
<p class="listhead"><b class="calibre6">Abstraction</b></p>
<p class="listplainfirst">This method involves simplifying the problem representation by grouping or abstracting specific elements within it. Abstraction can lead to admissible and consistent heuristics. Consider, for example, a navigation problem, where you could choose to abstract the map by representing cities as nodes and major highways as edges, while ignoring smaller streets.</p>
<p class="listhead"><b class="calibre6">Pattern databases</b></p>
<p class="listplainfirst">In problems with large state spaces, where the graph includes numerous nodes and links (such as puzzle games), pattern databases can be employed to precompute heuristic values for subsets of the state space. These databases store the cost-to-goal for small subsets of the problem, and the heuristic for a given state is estimated as the sum of the costs associated with the relevant subsets.</p>
<p class="tx">In the context of the graph shown in <a href="chapter7.xhtml#fig7-4" class="calibre2">Figure 7-4</a>, we’ll employ a combination of abstraction and ad hoc heuristic approaches to estimate a set of h-scores that are both admissible and consistent. Since we lack additional information about the nodes, such as their coordinates, we’ll begin with a simplifying assumption (abstraction): all edges or links within the graph have the same weight or cost. Furthermore, we’ll assume this weight equals the smallest weight found within the graph (ad hoc). Our approach can be summarized as a three-step process:</p>
<p class="listnumber">  1.  Edge weight assumption: Assume that all edges within the graph have an identical weight, and set this value to the smallest weight found within the graph.</p>
<p class="listnumber1">  2.  Minimum links count: For each node, determine the minimum number of edges or links needed to traverse from that node to the target node.</p>
<p class="listnumber2">  3.  H-score estimation: The h-score for each node is estimated by multiplying the smallest weight determined in step 1 with the minimum number of links needed to reach the target node, as found in step 2.</p>
<p class="tx">Given the relatively modest size of the graph, using this process to calculate h-scores is straightforward and quick. A brief examination of the weights reveals that the smallest one within the graph is 2 (for the link connecting nodes B and C). Now let’s consider nodes I and K, immediate neighbors of the target node J. Their h-scores will be 2 × 1 = 2, since both I and K are only one link away from the target. Similarly, h-scores for nodes E, F, G, H, and L, which are two links away from the target, can be estimated as 2 × 2 = 4. Following this logical progression, the h-score for the starting node A, located farthest from the target, is estimated to be 2 × 4 = 8 because at least four links must be traversed to reach the target. Once these heuristic values are computed, you can easily incorporate them into <span aria-label="291" epub:type="pagebreak" id="pg_291" role="doc-pagebreak"/>the application’s <span class="sans_thesansmonocd_w5regular_">getHScore()</span> function, a lookup function that retrieves the h-score for a given node. (We’ll discuss this function later, along with the rest of the code.)</p>
<p class="tx">Given our approach of utilizing the minimum number of links necessary to traverse from a given node to the target, along with our use of the smallest weight present in the graph for h-score calculation, the resulting h-scores meet the criterion of admissibility. They never overestimate the cost of reaching the target. I invite you to verify that these h-scores also meet the criterion of consistency as defined earlier in the section. You can do this either manually or by writing a few lines of code.</p>
</section>
<section aria-labelledby="sec16" epub:type="division">
<h4 class="h1"><span id="sec16"/><span id="h2-126"/><span class="sans_futura_std_bold_condensed_oblique_">The Algorithm</span></h4>
<p class="tni">Given our heuristic function, here are the steps we’ll take to find the optimal path between two nodes by using the A* algorithm. This method assumes that at least one valid route exists between the starting node and the target:</p>
<p class="listnumber">  1.  Initialize two mutable maps to keep track of the visited and the unvisited nodes, respectively. The visited map starts empty; the unvisited map starts with all nodes in the graph.</p>
<p class="listnumber1">  2.  Initialize each unvisited node’s g-score and f-score to infinity (or the maximum possible value of the corresponding type) and its previous node property to “none.”</p>
<p class="listnumber1">  3.  Set the starting node’s g-score to 0 (as the journey starts here, no previous node exists to come from), calculate or look up its h-score, and set its f-score equal to its h-score (since g-score = 0). Leave its previous node property set to “none.”</p>
<p class="listnumber1">  4.  While the unvisited map is not empty:</p>
<p class="listnumbersub">a.  Select the node with the lowest f-score from the unvisited nodes and designate that as the current node. (The starting node will be the first current node.)</p>
<p class="listnumbersub">b.  If the current node is the target node, add the current node to the visited map and terminate the loop (the target has been reached).</p>
<p class="listnumbersub">c.  Otherwise (when the current node is not the target node), retrieve the current node’s neighbors from the graph.</p>
<p class="listnumbersub">d.  For each neighbor that has not already been visited, calculate a new g-score by adding the weight of the edge between the current node and the neighbor to the g-score of the current node. If this new g-score is lower than the neighbor’s existing g-score, update the neighbor’s attributes (g-score, f-score, previous node).</p>
<p class="listnumbersub">e.  Add the current node to the visited map and remove it from the unvisited map.</p>
<p class="listnumber1"><span aria-label="292" epub:type="pagebreak" id="pg_292" role="doc-pagebreak"/>  5.  Once the loop ends, the visited map is returned, which contains information about the nodes explored during the search, their directional relationship (as captured in the “previous node” property), and the associated costs (g-scores and f-scores).</p>
<p class="listnumber2">  6.  Use the information contained in the visited map to reconstruct the entire optimal path.</p>
<p class="tx">These steps outline the essence of the A* algorithm. They involve maintaining an open set of nodes to be explored and a closed set of nodes that have been visited, and calculating the cost of each node based on the actual cost from the starting node (g-score) and the estimated cost to the target node (h-score). By iteratively selecting the node with the lowest total cost (f-score), the algorithm efficiently finds the shortest path from the starting node to the target node.</p>
<p class="tx">The time complexity of the A* search algorithm depends on the nature of the problem and the quality of the heuristic function used. In the worst case, the time complexity of A* is <i class="calibre9">O</i>(<i class="calibre9">b</i><i class="calibre9"><sup class="calibre8">d</sup></i>), where <i class="calibre9">b</i> is the branching factor (the average number of edges per node) and <i class="calibre9">d</i> is the depth of the shallowest target node (the minimum number of edges or steps needed to reach the target from the starting node). The space complexity of the standard A* algorithm depends on the data structure used for the open and closed lists (for example, this could be implemented by using priority queues). In the worst case, the space complexity can be very high, also up to <i class="calibre9">O</i>(<i class="calibre9">b</i><i class="calibre9"><sup class="calibre8">d</sup></i>), due to the storage of nodes in the open and closed lists.</p>
<p class="tx">A well-chosen (admissible and consistent) heuristic can significantly improve the performance of A*, however, by efficiently guiding the algorithm to the target node, reducing the search space, and potentially making the actual time and space complexities much lower in practice. In the best-case scenario, when the heuristic function is perfect and the algorithm efficiently explores the most promising paths first, for example, A* can have a time complexity of <i class="calibre9">O</i>(<i class="calibre9">d</i>).</p>
</section>
<section aria-labelledby="sec17" epub:type="division">
<h4 class="h1"><span id="sec17"/><span id="h2-127"/><span class="sans_futura_std_bold_condensed_oblique_">The Code</span></h4>
<p class="tni">The code for A* search is more involved than the code for DFS and BFS. For this reason, I’ll break it down into a number of segments, starting with the global declarations and the <span class="sans_thesansmonocd_w5regular_">main()</span> function.</p>
<pre class="calibre10"><code class="calibre11">// no import block

data class Node(
    var gScore: Int,
    var fScore: Int,
    var previousNode: String
)

fun main() {
    // Define the graph to be searched.
  <span aria-label="annotation1" class="code_codeannotation">❶</span> val graph = mapOf(
<span aria-label="293" epub:type="pagebreak" id="pg_293" role="doc-pagebreak"/>        "A" to mapOf("B" to 4, "C" to 6, "D" to 5),
        "B" to mapOf("A" to 4, "C" to 2, "E" to 4, "F" to 4),
        "C" to mapOf("A" to 6, "B" to 2, "D" to 3, "F" to 3),
        "D" to mapOf("A" to 5, "C" to 3, "G" to 6, "H" to 4),
        "E" to mapOf("B" to 4, "I" to 6),
        "F" to mapOf("B" to 4, "C" to 3, "G" to 4, "I" to 5),
        "G" to mapOf("D" to 6, "F" to 4, "I" to 6, "K" to 3),
        "H" to mapOf("D" to 4, "K" to 3),
        "I" to mapOf("E" to 6, "F" to 5, "G" to 6, "J" to 6),
        "J" to mapOf("I" to 6, "K" to 5),
        "K" to mapOf("G" to 3, "H" to 3, "J" to 5, "L" to 3),
        "L" to mapOf("K" to 3, "M" to 5),
        "M" to mapOf("L" to 5)
    )

    println("### A* algorithm ###")
    println("\nDisplay graph:")
    displayGraph(graph)

    val startNode  = "A"
    val targetNode = "J"    // Also, ensure its h-score is 0.
  <span aria-label="annotation2" class="code_codeannotation">❷</span> val visitedList = aStar(graph, startNode, targetNode)

    println("\n--- Final Visited List ---")
    displayList(visitedList)
    displayShortestPath(visitedList, startNode, targetNode)
}</code></pre>
<p class="tx">This application doesn’t require an import block, as the search algorithm can be implemented without relying on any specialized library functions. The sole global component is a data class that holds three key attributes of a node: its g-score, its f-score, and the previous node along the optimal path.</p>
<p class="tx">In the <span class="sans_thesansmonocd_w5regular_">main()</span> function, we first define the graph shown in <a href="chapter7.xhtml#fig7-4" class="calibre2">Figure 7-4</a> as a <span class="sans_thesansmonocd_w5regular_">Map</span> <span aria-label="annotation1" class="codeannotation">❶</span>. Each node is specified in terms of its name (<span class="sans_thesansmonocd_w5regular_">"A"</span>, <span class="sans_thesansmonocd_w5regular_">"B"</span>, <span class="sans_thesansmonocd_w5regular_">"C"</span>, and so on) along with an inner <span class="sans_thesansmonocd_w5regular_">Map</span> pairing each of the node’s neighbors with the weight of the edge leading to that neighbor. You can think of <span class="sans_thesansmonocd_w5regular_">graph</span> as a map of maps (similar to a list of lists) encapsulating all nodes in the network and their interconnections. Once the graph is defined, it’s printed by calling the <span class="sans_thesansmonocd_w5regular_">displayGraph()</span> function.</p>
<p class="tx">We next define the start and target nodes (<span class="sans_thesansmonocd_w5regular_">"A"</span> and <span class="sans_thesansmonocd_w5regular_">"J"</span> in this example) and call the <span class="sans_thesansmonocd_w5regular_">aStar()</span> function by passing the start and target nodes and the graph to be searched as arguments <span aria-label="annotation2" class="codeannotation">❷</span>. A call to this function returns a list of visited nodes (<span class="sans_thesansmonocd_w5regular_">visitedList</span>) as a <span class="sans_thesansmonocd_w5regular_">Map</span> of type <span class="sans_thesansmonocd_w5regular_">&lt;String, List&lt;Any&gt;&gt;</span>. This list represents a subset of nodes that the algorithm explored while trying to locate the optimal path. Crucially, A* search doesn’t need to visit all nodes in the graph, as it relies on heuristic information to zoom in on the region that includes the optimal solution. We use the <span class="sans_thesansmonocd_w5regular_">displayList()</span> function to print this visited list and then call the <span class="sans_thesansmonocd_w5regular_">displayShortestPath()</span> function, which reconstructs and displays the optimal path.</p>
<section aria-labelledby="sec18" epub:type="division">
<span aria-label="294" epub:type="pagebreak" id="pg_294" role="doc-pagebreak"/>
<h5 class="h2"><span id="sec18"/><span id="h3-55"/><span class="sans_futura_std_bold_b_">The Display Functions</span></h5>
<p class="tni">Let’s take a closer look at the various display helper functions called from the <span class="sans_thesansmonocd_w5regular_">main()</span> function, starting with the <span class="sans_thesansmonocd_w5regular_">displayGraph()</span> function, which prints the whole graph.</p>
<pre class="calibre10"><code class="calibre11">fun displayGraph(graph: Map&lt;String, Map&lt;String, Int&gt;&gt;) {
    for ((node, neighbors) in graph) {
        println("Node: $node")
        print("Neighbors: ")

        for ((nNode, cost) in neighbors) {
            print("$nNode:$cost ")
        }
        println()
    }
    println()
}</code></pre>
<p class="tx">This function takes in <span class="sans_thesansmonocd_w5regular_">graph</span> as its sole argument, which as we’ve seen is a <span class="sans_thesansmonocd_w5regular_">Map</span> of type <span class="sans_thesansmonocd_w5regular_">&lt;String, Map&lt;String, Int&gt;&gt;</span>. It uses two <span class="sans_thesansmonocd_w5regular_">for</span> loops to print the elements of <span class="sans_thesansmonocd_w5regular_">graph</span>. The outer loop cycles through the nodes, one at a time, printing each one. The inner loop extracts and prints each of the current node’s neighbors, along with the associated edge weights (labeled as <span class="sans_thesansmonocd_w5regular_">Cost</span> in the output). You’ll see how the output looks later when we examine the results.</p>
<p class="tx">Now we’ll consider the <span class="sans_thesansmonocd_w5regular_">displayList()</span> function, which prints the characteristics of each visited node after the A* search is complete.</p>
<pre class="calibre10"><code class="calibre11">fun displayList(mapList: Map&lt;String, Node&gt;) {
    println("   (g-score, f-score, previous)")

    for ((node, attributes) in mapList) {
        println("$node: $attributes")
    }
    println()
}</code></pre>
<p class="tx">This simple function uses a <span class="sans_thesansmonocd_w5regular_">for</span> loop to extract and print the collection of visited nodes and their attributes. Each element in this list, which is presented as a <span class="sans_thesansmonocd_w5regular_">Map</span> object, has two components: the name of the visited node and a <span class="sans_thesansmonocd_w5regular_">Node</span> object with three data points linked to the node—its g-score (<span class="sans_thesansmonocd_w5regular_">Int</span>), f-score (<span class="sans_thesansmonocd_w5regular_">Int</span>), and the previous node (<span class="sans_thesansmonocd_w5regular_">String</span>). The latter is the node from which we would have departed to reach the current node, ensuring the minimum f-score for the current node.</p>
<p class="tx">Finally, here’s the <span class="sans_thesansmonocd_w5regular_">displayShortestPath()</span> function, which takes in the list of visited nodes, the start node, and the target node, and identifies the optimal path:</p>
<pre class="calibre10"><code class="calibre11">fun displayShortestPath(visited: Map&lt;String, Node&gt;,
                        startNode: String, targetNode: String) {

<span aria-label="295" epub:type="pagebreak" id="pg_295" role="doc-pagebreak"/>    var currentNode = targetNode
    var path = targetNode
    println("path initialized from target: $path")

    while (currentNode != startNode) {
      <span aria-label="annotation1" class="code_codeannotation">❶</span> val previousNode = visited[currentNode]!!.previousNode
        // previousNode is placed before "path" so no need to reorder.
      <span aria-label="annotation2" class="code_codeannotation">❷</span> path = previousNode + path
        println("previousNode: $previousNode")
        println("path updated: $path")
        currentNode = previousNode
    }

    val cost = visited[targetNode]!!.gScore
    println("\nThe shortest path from $startNode to $targetNode is:")
    println("Path: $path")
    println("Cost: $cost")
}</code></pre>
<p class="tx">The function reconstructs the path in reverse, working backward from the target to the starting node. We start by initializing two variables to <span class="sans_thesansmonocd_w5regular_">targetNode</span>: <span class="sans_thesansmonocd_w5regular_">currentNode</span>, representing the current position in the path, and <span class="sans_thesansmonocd_w5regular_">path</span>, where the entire path is built up node by node. We then enter a <span class="sans_thesansmonocd_w5regular_">while</span> loop that iterates until <span class="sans_thesansmonocd_w5regular_">currentNode</span> becomes <span class="sans_thesansmonocd_w5regular_">startNode</span>. In the loop, we access <span class="sans_thesansmonocd_w5regular_">currentNode</span> from the list of visited nodes (supplied as a <span class="sans_thesansmonocd_w5regular_">Map</span> of type <span class="sans_thesansmonocd_w5regular_">&lt;String, Node&gt;</span>) and use its <span class="sans_thesansmonocd_w5regular_">previousNode</span> property to look up its previous node <span aria-label="annotation1" class="codeannotation">❶</span>. Next, we concatenate <span class="sans_thesansmonocd_w5regular_">previousNode</span> with the current value of <span class="sans_thesansmonocd_w5regular_">path</span> <span aria-label="annotation2" class="codeannotation">❷</span> and update <span class="sans_thesansmonocd_w5regular_">currentNode</span> to <span class="sans_thesansmonocd_w5regular_">previousNode</span> for the next iteration.</p>
<p class="tx">After the loop ends, we retrieve <span class="sans_thesansmonocd_w5regular_">cost</span>, the g-score of the target node, from the list of visited nodes, using <span class="sans_thesansmonocd_w5regular_">targetNode</span> as the key. We then print the reconstructed optimal path and its cost.</p>
</section>
<section aria-labelledby="sec19" epub:type="division">
<h5 class="h2"><span id="sec19"/><span id="h3-56"/><span class="sans_futura_std_bold_b_">The aStar() Function and Its Helpers</span></h5>
<p class="tni">Let’s now dive into the core of the A* algorithm implemented in <span class="sans_thesansmonocd_w5regular_">aStar()</span> and its helper functions. This code very closely follows the steps outlined earlier for implementing the A* algorithm.</p>
<pre class="calibre10"><code class="calibre11">fun aStar(graph: Map&lt;String, Map&lt;String, Int&gt;&gt;,
          startNode: String, targetNode: String):
          Map&lt;String, Node&gt; {

    // Define two mutable maps.
    val visited = mutableMapOf&lt;String, Node&gt;()
    val unvisited = mutableMapOf&lt;String, Node&gt;()

    // Initialize all unvisited nodes.
    for (node in graph.keys) {
        // The list is made of g-score, f-score, and previous node.
      <span aria-label="annotation1" class="code_codeannotation">❶</span> unvisited[node] = Node(Int.MAX_VALUE, Int.MAX_VALUE, "none")
    }

<span aria-label="296" epub:type="pagebreak" id="pg_296" role="doc-pagebreak"/>    // Update the start node attributes in the unvisited list.
    val hScore = getHScore(startNode)

    // for startNode: g-score = 0, f-score = 10, previous node = none
  <span aria-label="annotation2" class="code_codeannotation">❷</span> unvisited[startNode] = Node(0, hScore, "none")

    println("--- Initialized state of unvisited list ---")
    displayList(unvisited)

  <span aria-label="annotation3" class="code_codeannotation">❸</span> while (unvisited.isNotEmpty()) {
        // Set the node with minimum f-score to current node.
      <span aria-label="annotation4" class="code_codeannotation">❹</span> val currentNode = getCurrentNode(unvisited)

      <span aria-label="annotation5" class="code_codeannotation">❺</span> if (currentNode == targetNode) {
            // Add the targetNode to visited.
            visited[currentNode] = unvisited[currentNode]!!
            println("--- Target node:$currentNode reached ---")
            break
        }

        val neighbors = graph[currentNode]!!

        for (node in neighbors.keys) {
          <span aria-label="annotation6" class="code_codeannotation">❻</span> if (node !in visited) {
                val newGScore =
                    unvisited[currentNode]!!.gScore + neighbors[node]!!

              <span aria-label="annotation7" class="code_codeannotation">❼</span> if (newGScore &lt; unvisited[node]!!.gScore) {
                    unvisited[node] = Node(
                        newGScore,
                        newGScore + getHScore(node),
                        currentNode)
                }
            }
        }

        // Add currentNode to visited.
        visited[currentNode] = unvisited[currentNode]!!

        // Remove currentNode from unvisited.
        unvisited.remove(currentNode)
    }
    return visited
}</code></pre>
<p class="tx">The algorithm begins by creating two mutable maps: <span class="sans_thesansmonocd_w5regular_">visited</span> and <span class="sans_thesansmonocd_w5regular_">unvisited</span>. At first, <span class="sans_thesansmonocd_w5regular_">unvisited</span> contains all the nodes in the graph, each initialized with the maximum possible g-score and f-score, and with a previous node of <span class="sans_thesansmonocd_w5regular_">"none"</span> <span aria-label="annotation1" class="codeannotation">❶</span>. The <span class="sans_thesansmonocd_w5regular_">visited</span> map, which is initially empty, keeps track of the nodes that have been visited. Next, the <span class="sans_thesansmonocd_w5regular_">startNode</span> in the <span class="sans_thesansmonocd_w5regular_">unvisited</span> map is updated to have a g-score of <span class="sans_thesansmonocd_w5regular_">0</span> and an f-score equivalent to its h-score <span aria-label="annotation2" class="codeannotation">❷</span>, <span aria-label="297" epub:type="pagebreak" id="pg_297" role="doc-pagebreak"/>which is retrieved with the <span class="sans_thesansmonocd_w5regular_">getHScore()</span> helper function. As shown here, this helper is implemented as a simple lookup function:</p>
<pre class="calibre10"><code class="calibre11">fun getHScore(node: String) = when (node) {
    "A" -&gt; 8   // start node
    "B" -&gt; 6
    "C" -&gt; 6
    "D" -&gt; 6
    "E" -&gt; 4
    "F" -&gt; 4
    "G" -&gt; 4
    "H" -&gt; 4
    "I" -&gt; 2
    "J" -&gt; 0   // target node
    "K" -&gt; 2
    "L" -&gt; 4
    "M" -&gt; 6
    else -&gt; 0
}</code></pre>
<p class="tx">These scores were estimated by using the hybrid three-step process explained earlier. Note that the h-score for the target node <span class="sans_thesansmonocd_w5regular_">"J"</span> is <span class="sans_thesansmonocd_w5regular_">0</span>.</p>
<p class="tx">Returning to the <span class="sans_thesansmonocd_w5regular_">aStar()</span> function, we next display the list of unvisited nodes and enter a <span class="sans_thesansmonocd_w5regular_">while</span> loop that continues until the <span class="sans_thesansmonocd_w5regular_">unvisited</span> map is empty or the target node is reached <span aria-label="annotation3" class="codeannotation">❸</span>. Within the loop, <span class="sans_thesansmonocd_w5regular_">currentNode</span> is set to the unvisited node with the minimum f-score by using the <span class="sans_thesansmonocd_w5regular_">getCurrentNode()</span> helper function <span aria-label="annotation4" class="codeannotation">❹</span>. Here’s how that helper function is implemented by using Kotlin’s built-in <span class="sans_thesansmonocd_w5regular_">.minByOrNull</span> method:</p>
<pre class="calibre10"><code class="calibre11">fun getCurrentNode(unvisited: Map&lt;String, Node&gt;) =
    unvisited.minByOrNull {it.value.fScore}!!.key</code></pre>
<p class="tx">Back in <span class="sans_thesansmonocd_w5regular_">aStar()</span>, we check if <span class="sans_thesansmonocd_w5regular_">currentNode</span> is the same as <span class="sans_thesansmonocd_w5regular_">targetNode</span> <span aria-label="annotation5" class="codeannotation">❺</span>. If it is, we add the current node to the <span class="sans_thesansmonocd_w5regular_">visited</span> map and break the loop. Otherwise, for each neighbor of the current node not already in the <span class="sans_thesansmonocd_w5regular_">visited</span> map <span aria-label="annotation6" class="codeannotation">❻</span>, we calculate a new g-score by adding the edge weight to the current node’s g-score. If the new g-score is lower than the neighbor’s current g-score <span aria-label="annotation7" class="codeannotation">❼</span>, the neighbor’s attributes in the <span class="sans_thesansmonocd_w5regular_">unvisited</span> map are updated: its g-score is set to <span class="sans_thesansmonocd_w5regular_">newGScore</span>, its f-score is set to its new g-score, plus its h-score (again retrieved with the <span class="sans_thesansmonocd_w5regular_">getHScore()</span> function), and its previous node is set to <span class="sans_thesansmonocd_w5regular_">currentNode</span>.</p>
<p class="tx">After processing all neighbors, the <span class="sans_thesansmonocd_w5regular_">currentNode</span> is added to the <span class="sans_thesansmonocd_w5regular_">visited</span> map and removed from the <span class="sans_thesansmonocd_w5regular_">unvisited</span> map. When the <span class="sans_thesansmonocd_w5regular_">while</span> loop terminates, the <span class="sans_thesansmonocd_w5regular_">visited</span> map is returned with all the information needed to reconstitute the optimal path.</p>
<span aria-label="298" epub:type="pagebreak" id="pg_298" role="doc-pagebreak"/>
<aside aria-label="box-38" class="box">
<p class="boxtitle" id="box-38"><span class="sans_futura_std_bold_b_">USING NOT-NULL ASSERTION</span></p>
<p class="boxfirst"><span class="sans_futura_std_book_">The implementation of the A* algorithm in this chapter uses the not-null assertion operator (</span><span class="sans_thesansmonocd_w5regular_">!!</span><span class="sans_futura_std_book_">) multiple times. However, this is generally discouraged in favor of the Elvis operator (</span><span class="sans_thesansmonocd_w5regular_">?:</span><span class="sans_futura_std_book_">), which allows for more graceful handling of null exceptions. For</span> <span class="sans_futura_std_book_"><a href="chapter7.xhtml#pre-32" class="calibre2">Project 32</a>’s undirected graph problem, we can represent the graph by using a map of maps data structure. This approach is straightforward, intuitive, and particularly well suited for educational purposes. In real-world code, though, using the not-null assertion operator can be risky because it can lead to a</span> <span class="sans_thesansmonocd_w5regular_">NullPointerException</span> <span class="sans_futura_std_book_">if the value is</span> <span class="sans_thesansmonocd_w5regular_">null</span><span class="sans_futura_std_book_">.</span></p>
<p class="box1"><span class="sans_futura_std_book_">Therefore, in production-ready code that is expected to be used by other users, you should use safer options such as null-safe calls or the Elvis operator. For example, you could replace</span></p>
<pre class="calibre10"><code class="calibre11">val neighbors = graph[currentNode]!!</code></pre>
<p class="boxfirst"><span class="sans_futura_std_book_">with:</span></p>
<pre class="calibre10"><code class="calibre11">val neighbors = graph[currentNode] ?:
                error("No neighbors found for $currentNode")</code></pre>
<p class="boxfirst"><span class="sans_futura_std_book_">Using this approach, you can replace all code segments using</span> <span class="sans_thesansmonocd_w5regular_">!!</span> <span class="sans_futura_std_book_">with code to generate appropriate error messages.</span></p>
</aside>
</section>
</section>
<section aria-labelledby="sec20" epub:type="division">
<h4 class="h1"><span id="sec20"/><span id="h2-128"/><span class="sans_futura_std_bold_condensed_oblique_">The Result</span></h4>
<p class="tni">We’re now ready to run the code and have a look at its console output.</p>
<pre class="calibre10"><code class="calibre11">*** A-star algorithm ***

Display graph:
Node: A
Neighbors: B:4 C:6 D:5
Node: B
Neighbors: A:4 C:2 E:4 F:4
Node: C
<var class="calibre18">--snip--</var>
Node: L
Neighbors: K:3 M:5
Node: M
Neighbors: L:5

--- Initialized state of unvisited list ---
   (g-score, f-score, previous)
A: Node(gScore=0, fScore=8, previousNode=none)
B: Node(gScore=2147483647, fScore=2147483647, previousNode=none)
C: Node(gScore=2147483647, fScore=2147483647, previousNode=none)
<var class="calibre18">--snip--</var>
<span aria-label="299" epub:type="pagebreak" id="pg_299" role="doc-pagebreak"/>L: Node(gScore=2147483647, fScore=2147483647, previousNode=none)
M: Node(gScore=2147483647, fScore=2147483647, previousNode=none)

--- Target node:J reached ---

--- Final Visited List ---
   (g-score, f-score, previous)
A: Node(gScore=0, fScore=8, previousNode=none)
B: Node(gScore=4, fScore=10, previousNode=A)
D: Node(gScore=5, fScore=11, previousNode=A)
C: Node(gScore=6, fScore=12, previousNode=A)
E: Node(gScore=8, fScore=12, previousNode=B)
F: Node(gScore=8, fScore=12, previousNode=B)
H: Node(gScore=9, fScore=13, previousNode=D)
K: Node(gScore=12, fScore=14, previousNode=H)
G: Node(gScore=11, fScore=15, previousNode=D)
I: Node(gScore=13, fScore=15, previousNode=F)
J: Node(gScore=17, fScore=17, previousNode=K)

path initialized from target: J
previousNode: K
path updated: KJ
previousNode: H
path updated: HKJ
previousNode: D
path updated: DHKJ
previousNode: A
path updated: ADHKJ

The shortest path from A to J is:
Path: ADHKJ
Cost: 17</code></pre>
<p class="tx">The output starts by printing the entire graph, node by node, along with each node’s neighbors and edge weights. Next, the initial state of the <span class="sans_thesansmonocd_w5regular_">unvisited</span> map is shown after updating the starting node’s attributes. Apart from node <span class="sans_thesansmonocd_w5regular_">"A"</span>, each node should have the maximum possible g- and f-scores (<span class="sans_thesansmonocd_w5regular_">2147483647</span>) and a previous node of <span class="sans_thesansmonocd_w5regular_">"none"</span>. Once the target node is reached, a message is printed before exiting the <span class="sans_thesansmonocd_w5regular_">while</span> loop. Then the final list of all visited nodes is printed. Looking over the list, we can see that not every node as been visited—nodes <span class="sans_thesansmonocd_w5regular_">"L"</span> and <span class="sans_thesansmonocd_w5regular_">"M"</span>, representing a dead end, were skipped. Notice also that the target node’s g-score is the same as its f-score because its h-score is 0. Also, as expected, all g-scores are less than or equal to their corresponding f-scores. This is because the f-score is the sum of the g-score and the h-score, and the latter is assumed to be greater than or equal to 0.</p>
<p class="tx">Finally, the terminal output shows the step-by-step process of reconstructing the optimal path, followed by the full path and its total associated cost.</p>
<span aria-label="300" epub:type="pagebreak" id="pg_300" role="doc-pagebreak"/>
<aside aria-label="box-39" class="box2">
<p class="boxtitle" id="box-39"><span class="sans_futura_std_bold_b_">EXERCISES</span></p>
<p class="boxfirst"><span class="sans_futura_std_book_"><a href="chapter7.xhtml#pre-32" class="calibre2">Project 32</a> demonstrated a basic implementation of the A* algorithm, but you can add or experiment with many more features. The following four challenges outline different ways you could modify the program. For each challenge, you’ll have to do additional online research to learn more about the key concept and possible implementation schemes.</span></p>
<div class="spc">
<p class="boxlistnumber"><span class="sans_futura_std_book_">1.  Implement and experiment with different custom heuristic functions (h-scores) for a shortest-pathfinding problem, where each node represents a geographic location and the weights are actual distances between the connected nodes. Assume that the x- and y-coordinates for all nodes are also available. Compare the different heuristic functions’ performance and accuracy in finding optimal paths.</span></p>
<p class="boxlistnumber"><span class="sans_futura_std_book_">2.  Modify the A* algorithm to allow dynamic weighting of the heuristic function (h-score) relative to the cost so far (g-score). You can introduce a parameter (for example, a weight,</span> <span class="sans_futura_std_book_oblique_">w</span><span class="sans_futura_std_book_">) that can be adjusted to change the relative importance of h- and g-scores. Typically,</span> <span class="sans_futura_std_book_oblique_">w</span> <span class="sans_futura_std_book_">&gt; 1 increases the importance of h-scores over g-scores (speed over optimality), whereas</span> <span class="sans_futura_std_book_oblique_">w</span> <span class="sans_futura_std_book_">&lt; 1 implies assigning more importance to g-scores and exploring a broader search space at the cost of speed of convergence. The default scheme used in <a href="chapter7.xhtml#pre-32" class="calibre2">Project 32</a> is equivalent to</span> <span class="sans_futura_std_book_oblique_">w</span> <span class="sans_futura_std_book_">= 1, where the g-score and h-score are considered equally important.</span></p>
<p class="boxlistnumber"><span class="sans_futura_std_book_">3.  Implement A* by using different data structures for the unvisited and visited sets of nodes, such as priority queues, Fibonacci heaps, or even custom data structures. Measure the impact on the algorithm’s efficiency.</span></p>
<p class="boxlistnumber"><span class="sans_futura_std_book_">4.  Explore memory-efficient variations of A*, such as memory-bounded A* (MA*) or simplified versions like recursive best-first search (RBFS). Compare their memory usage and computational efficiency.</span></p>
</div>
</aside>
</section>
</section>
<section aria-labelledby="sec21" epub:type="division">
<h3 class="h"><span id="sec21"/><span id="h1-47"/><span class="sans_futura_std_bold_b_">Summary</span></h3>
<p class="tni">In this chapter, we explored some representative concepts and algorithms from two related domains: sorting and searching. These essential concepts and tools have extensive use in the realms of computer and data science, particularly in the context of information retrieval from databases, search engine performance optimization, data visualization, data mining, machine learning, and network routing.</p>
<p class="tx">Within the domain of sorting, we implemented the insertion sort, merge sort, and quick sort algorithms and gained insight into their respective strengths, weaknesses, time and space complexities, and stability characteristics. In the searching domain, our projects revolved around <span aria-label="301" epub:type="pagebreak" id="pg_301" role="doc-pagebreak"/>navigating graph data structures. We implemented the depth-first search (DFS), breadth-first search (BFS), and A* algorithms.</p>
<p class="tx">Throughout these projects, we harnessed the power of various Kotlin features, including both stack and queue data structures, as well as lists, maps, and more intricate constructs like maps of maps. Last but not least, by tackling the exercises, you’ll not only solidify your grasp of these core concepts but also raise your sorting and searching skills to a professional level.</p>
</section>
<section aria-labelledby="sec22" epub:type="division">
<h3 class="h"><span id="sec22"/><span id="h1-48"/><span class="sans_futura_std_bold_b_">Resources</span></h3>
<p class="reference">Bhargava, Aditya Y. <i class="calibre9">Grokking Algorithms</i>. 2nd ed. Shelter Island, NY: Manning, 2024.</p>
<p class="reference">Cormen, Thomas H., Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. <i class="calibre9">Introduction to Algorithms</i>. 4th ed. Cambridge, MA: MIT Press, 2022.</p>
<p class="reference">Even, Shimon. <i class="calibre9">Graph Algorithms</i>. 2nd ed., edited by Guy Even. New York: Cambridge University Press, 2012.</p>
<p class="reference">Heineman, George, Gary Pollice, and Stanley Selkow. <i class="calibre9">Algorithms in a Nutshell</i>. 2nd ed. Sebastopol, CA: O’Reilly, 2016.</p>
<p class="reference">Kopec, David. <i class="calibre9">Classic Computer Science Problems in Python</i>. Shelter Island, NY: Manning, 2019.</p>
<p class="reference">Skiena, Steven. <i class="calibre9">The Algorithm Design Manual</i>. 3rd ed. Cham, Switzerland: Springer Nature, 2020.</p>
<p class="reference">Wengrow, Jay. <i class="calibre9">A Common-Sense Guide to Data Structures and Algorithms</i>. 2nd ed. Raleigh, NC: The Pragmatic Bookshelf, 2020.</p>
</section>
</section>
</div></body></html>