- en: '**12'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: THE NORMAL DISTRIBUTION**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the previous two chapters, you learned about two very important concepts:
    mean (μ), which allows us to estimate a measurement from various observations,
    and standard deviation (σ), which allows us to measure the spread of our observations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On its own, each concept is useful, but together, they are even more powerful:
    we can use them as parameters for the most famous probability distribution of
    all, the *normal distribution*.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter you’ll learn how to use the normal distribution to determine
    an exact probability for your degree of certainty about one estimate proving true
    compared to others. The true goal of parameter estimation isn’t simply to estimate
    a value, but rather to assign a probability for a *range* of possible values.
    This allows us to perform more sophisticated reasoning with uncertain values.
  prefs: []
  type: TYPE_NORMAL
- en: We established in the preceding chapter that the mean is a solid method of estimating
    an unknown value based on existing data, and that the standard deviation can be
    used to measure the spread of that data. By measuring the spread of our observations,
    we can determine how confidently we believe in our mean. It makes sense that the
    more spread out our observations, the less sure we are in our mean. The normal
    distribution allows us to precisely quantify *how* certain we are in various beliefs
    when taking our observations into account.
  prefs: []
  type: TYPE_NORMAL
- en: '**Measuring Fuses for Dastardly Deeds**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Imagine a mustachioed cartoon villain wants to set off a bomb to blow a hole
    in a bank vault. Unfortunately, he has only one bomb, and it’s rather large. He
    knows that if he gets 200 feet away from the bomb, he can escape to safety. It
    takes him 18 seconds to make it that far. If he’s any closer to the bomb, he risks
    death.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although the villain has only one bomb, he has six fuses of equal size, so
    he decides to test out five of the six fuses, saving the last one for the bomb.
    The fuses are all the same size and should take the same amount of time to burn
    through. He sets off each fuse and measures how long it takes to burn through
    to make sure he has the 18 seconds he needs to get away. Of course, being in a
    rush leads to some inconsistent measurements. Here are the times he recorded (in
    seconds) for each fuse to burn through: 19, 22, 20, 19, 23.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So far so good: none of the fuses takes less than 18 seconds to burn. Calculating
    the mean gives us μ = 20.6, and calculating the standard deviation gives us σ
    = 1.62.'
  prefs: []
  type: TYPE_NORMAL
- en: But now we want to determine a concrete probability for how likely it is that,
    given the data we have observed, a fuse will go off in *less* than 18 seconds.
    Since our villain values his life even more than the money, he wants to be 99.9
    percent sure he’ll survive the blast, or he won’t attempt the heist.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 10](ch10.xhtml#ch10), you learned that the mean is a good estimate
    for the true value given a set of measurements, but we haven’t yet come up with
    any way to express how *strongly* we believe this value to be true.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 11](ch11.xhtml#ch11), you learned that you can quantify how spread
    out your observations are by calculating the standard deviation. It seems rational
    that this might also help us figure out how likely the alternatives to our mean
    might be. For example, suppose you drop a glass on the floor and it shatters.
    When you’re cleaning up, you might search adjacent rooms based on how dispersed
    the pieces of glass are. If, as shown in [Figure 12-1](ch12.xhtml#ch12fig01),
    the pieces are very close together, you would feel more confident that you don’t
    need to check for glass in the next room.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-1: When the broken pieces are closer together, you’re more sure
    of where to clean up.*'
  prefs: []
  type: TYPE_NORMAL
- en: However, if the glass pieces are widely dispersed, as in [Figure 12-2](ch12.xhtml#ch12fig02),
    you’ll likely want to sweep around the entrance of the next room, even if you
    don’t immediately see broken glass there. Likewise, if the villain’s fuse timings
    are very spread out, even if he didn’t observe any fuses lasting less than 18
    seconds, it’s possible that the real fuse could still burn through in less than
    18 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-2: When the pieces are spread out, you’re less sure of where they
    might be.*'
  prefs: []
  type: TYPE_NORMAL
- en: When observations are scattered visually, we intuitively feel that there might
    be other observations at the extreme limits of what we can see. We are also less
    confident in exactly where the center is. In the glass example, it’s harder to
    be sure of where the glass fell if you weren’t there to witness the fall and the
    glass fragments are dispersed widely.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can quantify this intuition with the most studied and well-known probability
    distribution: the normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Normal Distribution**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The normal distribution is a continuous probability distribution (like the beta
    distribution in [Chapter 5](ch05.xhtml#ch05)) that best describes the strength
    of possible beliefs in the value of an uncertain measurement, given a known mean
    and standard deviation. It takes μ and σ (the mean and standard deviation, respectively)
    as its only two parameters. A normal distribution with μ = 0 and σ = 1 has a bell
    shape, as shown in [Figure 12-3](ch12.xhtml#ch12fig03).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-3: A normal distribution with μ = 0 and σ = 1*'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the center of the normal distribution is its mean. The width
    of a normal distribution is determined by its standard deviation. [Figures 12-4](ch12.xhtml#ch12fig04)
    and [12-5](ch12.xhtml#ch12fig05) show normal distributions with μ = 0 and σ =
    0.5 and 2, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-4: A normal distribution with μ = 0 and σ = 0.5*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-5: A normal distribution with μ = 0 and σ = 2*'
  prefs: []
  type: TYPE_NORMAL
- en: As the standard deviation shrinks, so does the width of the normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The normal distribution, as we’ve discussed, reflects how strongly we believe
    in our mean. So, if our observations are more scattered, we believe in a wider
    range of possible values and have less confidence in the central mean. Conversely,
    if all of our observations are more or less the same (meaning a small σ), we believe
    our estimate is pretty accurate.
  prefs: []
  type: TYPE_NORMAL
- en: When the *only* thing we know about a problem is the mean and standard deviation
    of the data we have observed, the normal distribution is the most honest representation
    of our state of beliefs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Solving the Fuse Problem**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Going back to our original problem, we have a normal distribution with μ = 20.6
    and σ = 1.62\. We don’t really know anything else about the properties of the
    fuses beyond the recorded burn times, so we can model the data with a normal distribution
    using the observed mean and standard deviation (see [Figure 12-6](ch12.xhtml#ch12fig06)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-6: A normal distribution with μ = 20.6 and σ = 1.62*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The question we want to answer is: what is the probability, given the data
    observed, that the fuse will run for 18 seconds or less? To solve this problem,
    we need to use the probability density function (PDF), a concept you first learned
    about in [Chapter 5](ch05.xhtml#ch05). The PDF for the normal distribution is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0116-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'And to get the probability, we need to *integrate* this function over values
    less than 18:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0117-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You can imagine integration as simply taking the area under the curve for the
    region you’re interested in, as shown in [Figure 12-7](ch12.xhtml#ch12fig07).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-7: The area under the curve that we’re interested in*'
  prefs: []
  type: TYPE_NORMAL
- en: The area of the shaded region represents the probability of the fuse lasting
    18 seconds or less given the observations. Notice that even though none of the
    observed values was less than 18, because of the spread of the observations, the
    normal distribution in [Figure 12-6](ch12.xhtml#ch12fig06) shows that a value
    of 18 or less is still possible. By integrating over all values less than 18,
    we can calculate the probability that the fuse will *not* last as long as our
    villain needs it to.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating this function by hand is not an easy task. Thankfully, we have R
    to do the integration for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we do this, though, we need to determine what number to start integrating
    from. The normal distribution is defined on the range of all possible values from
    negative infinity (–∞) to infinity (∞). So in theory what we want is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0117-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: But obviously we cannot integrate our function from negative infinity on a computer!
    Luckily, as you can see in [Figures 12-6](ch12.xhtml#ch12fig06) and [12-7](ch12.xhtml#ch12fig07),
    the probability density function becomes an incredibly small value very quickly.
    We can see that the line in the PDF is nearly flat at 10, meaning there is virtually
    no probability in this region, so we can just integrate from 10 to 18\. We could
    also choose a lower value, like 0, but because there’s effectively no probability
    in this region, it won’t change our result in any meaningful way. In the next
    section, we’ll discuss a heuristic that makes choosing a lower or upper bound
    easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll integrate this function using R’s `integrate()` function and the `dnorm()`
    function (which is just R’s function for the normal distribution PDF), calculating
    the PDF of the normal distribution as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Rounding the value, we can see that *P*(fuse time < 18) = 0.05, telling us there
    is a 5 percent chance that the fuse will last 18 seconds or less. Even villains
    value their own lives, and in this case our villain will attempt the bank robbery
    only if he is 99.9 percent sure that he can safely escape the blast. For today
    then, the bank is safe!
  prefs: []
  type: TYPE_NORMAL
- en: The power of the normal distribution is that we can reason probabilistically
    about a wide range of possible alternatives to our mean, giving us an idea of
    how realistic our mean is. We can use the normal distribution any time we want
    to reason about data for which we know only the mean and standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is also the danger of the normal distribution. In practice, if
    you have information about your problem besides the mean and standard deviation,
    it is usually best to make use of that. We’ll see an example of this in a later
    section.
  prefs: []
  type: TYPE_NORMAL
- en: '**Some Tricks and Intuitions**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While R makes integrating the normal distribution significantly easier than
    trying to solve the integral by hand, there’s a very useful trick that can simplify
    things even further when you’re working with the normal distribution. For *any*
    normal distribution with a known mean and standard deviation, you can estimate
    the area under the curve around μ in terms of σ.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the area under the curve for the range from μ – σ (one standard
    deviation less than the mean) to μ + σ (one standard deviation greater than the
    mean) holds 68 percent of the mass of the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: This means that 68 percent of the possible values fall within ± one standard
    deviation of the mean, as shown in [Figure 12-8](ch12.xhtml#ch12fig08).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-8: Sixty-eight percent of the probability density (area under the
    curve) lies between one standard deviation of the mean in either direction.*'
  prefs: []
  type: TYPE_NORMAL
- en: We can continue by increasing our distance from the mean by multiples of σ.
    [Table 12-1](ch12.xhtml#ch12tab01) gives probabilities for these other areas.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 12-1:** Areas Under the Curve for Different Means'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Distance from the mean** | **Probability** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| σ | 68 percent |'
  prefs: []
  type: TYPE_TB
- en: '| 2σ | 95 percent |'
  prefs: []
  type: TYPE_TB
- en: '| 3σ | 99.7 percent |'
  prefs: []
  type: TYPE_TB
- en: This little trick is very useful for quickly assessing the likelihood of a value
    given even a small sample. All you need is a calculator to easily figure out the
    μ and σ, which means you can do some pretty accurate estimations even in the middle
    of a meeting!
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, when measuring snowfall in [Chapter 10](ch10.xhtml#ch10) we
    had the following measurements: 6.2, 4.5, 5.7, 7.6, 5.3, 8.0, 6.9\. For these
    measurements, the mean is 6.31 and the standard deviation is 1.17\. This means
    that we can be 95 percent sure that the true value of the snowfall was somewhere
    between 3.97 inches (6.31 – 2 × 1.17) and 8.65 inches (6.31 + 2 × 1.17). No need
    to manually calculate an integral or boot up a computer to use R!'
  prefs: []
  type: TYPE_NORMAL
- en: Even when we *do* want to use R to integrate, this trick can be useful for determining
    a minimum or maximum value to integrate from or to. For example, if we want to
    know the probability that the villain’s bomb fuse will last longer than 21 seconds,
    we don’t want to have to integrate from 21 to infinity. What can we use for our
    upper bound? We can integrate from 21 to 25.46 (which is 20.6 + 3 × 1.62), which
    is 3 standard deviations from our mean. Being three standard deviations from the
    mean will account for 99.7 percent of our total probability. The remaining 0.3
    percent lies on either side of the distribution, so only half of that, 0.15 percent
    of our probability density, lies in the region greater than 25.46\. So if we integrate
    from 21 to 25.46, we’ll only be missing a tiny amount of probability in our result.
    Clearly, we could easily use R to integrate from 21 to something really safe such
    as 30, but this trick allows us to figure out what “really safe” means.
  prefs: []
  type: TYPE_NORMAL
- en: '**“N Sigma” Events**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You may have heard an event being described in terms of *sigma events*, such
    as “the fall of the stock price was an eight-sigma event.” What this expression
    means is that the observed data is eight standard deviations from the mean. We
    saw the progression of one, two, and three standard deviations from the mean in
    [Table 12-1](ch12.xhtml#ch12tab01), which were values at 68, 95, and 99.7 percent,
    respectively. You can easily intuit from this that an eight-sigma event must be
    extremely unlikely. In fact, if you ever observe data that is five standard deviations
    from the mean, it’s likely a good sign that your normal distribution is not modeling
    the underlying data accurately.
  prefs: []
  type: TYPE_NORMAL
- en: To show the growing rarity of an event as it increases by *n* sigma, say you
    are looking at events you might observe on a given day. Some are very common,
    such as waking up to the sunrise. Others are less common, such as waking up and
    it being your birthday. [Table 12-2](ch12.xhtml#ch12tab02) shows how many days
    it would take to expect the event to happen per one sigma increase.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 12-2:** Rarity of an Event as It Increases by *n* Sigma'
  prefs: []
  type: TYPE_NORMAL
- en: '| **(–/+) Distance from the mean** | **Expected every . . .** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| σ | 3 days |'
  prefs: []
  type: TYPE_TB
- en: '| 2σ | 3 weeks |'
  prefs: []
  type: TYPE_TB
- en: '| 3σ | 1 year |'
  prefs: []
  type: TYPE_TB
- en: '| 4σ | 4 decades |'
  prefs: []
  type: TYPE_TB
- en: '| 5σ | 5 millennia |'
  prefs: []
  type: TYPE_TB
- en: '| 6σ | 1.4 million years |'
  prefs: []
  type: TYPE_TB
- en: So a three-sigma event is like waking up and realizing it’s your birthday, but
    a six-sigma event is like waking up and realizing that a giant asteroid is crashing
    toward earth!
  prefs: []
  type: TYPE_NORMAL
- en: '**The Beta Distribution and the Normal Distribution**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You may remember from [Chapter 5](ch05.xhtml#ch05) that the beta distribution
    allows us to estimate the true probability given that we have observed α desired
    outcomes and β undesired outcomes, where the total number of outcomes is α + β.
    Based on that, you might take some issue with the notion that the normal distribution
    is truly the best method to model parameter estimation given that we know only
    the mean and standard deviation of any given data set. After all, we could describe
    a situation where α = 3 and β = 4 by simply observing three values of 1 and four
    values of 0\. This would give us μ = 0.43 and σ = 0.53\. We can then compare the
    beta distribution with α = 3 and β = 4 to a normal distribution with μ = 0.43
    and σ = 0.53, as shown in [Figure 12-9](ch12.xhtml#ch12fig09).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/12fig09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 12-9: Comparing the beta distribution to the normal distribution*'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s clear that these distributions are quite different. We can see that for
    both distributions the center of mass appears in roughly the same place, but the
    bounds for the normal distribution extend way beyond the limits of our graph.
    This demonstrates a key point: only when you know nothing about the data other
    than its mean and variance is it safe to assume a normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: For the beta distribution, we know that the value we’re looking for must lie
    in the range 0 to 1\. The normal distribution is defined from –∞ to ∞, which often
    includes values that cannot possibly exist. However, in most cases this is not
    practically important because measurements out that far are essentially impossible
    in probabilistic terms. But for our example of measuring the probability of an
    event happening, this missing information is important for modeling our problem.
  prefs: []
  type: TYPE_NORMAL
- en: So, while the normal distribution is a very powerful tool, it is no substitute
    for having more information about a problem.
  prefs: []
  type: TYPE_NORMAL
- en: '**Wrapping Up**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The normal distribution is an extension of using the mean for estimating a value
    from observations. The normal distribution combines the mean and the standard
    deviation to model how spread out our observations are from the mean. This is
    important because it allows us to reason about the error in our measurements in
    a probabilistic way. Not only can we use the mean to make our best guess, but
    we can also make probabilistic statements about ranges of possible values for
    our estimate.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Try answering the following questions to see how well you understand the normal
    distribution. The solutions can be found at *[https://nostarch.com/learnbayes/](https://nostarch.com/learnbayes/)*.
  prefs: []
  type: TYPE_NORMAL
- en: What is the probability of observing a value five sigma greater than the mean
    or more?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A fever is any temperature greater than 100.4 degrees Fahrenheit. Given the
    following measurements, what is the probability that the patient has a fever?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 100.0, 99.8, 101.0, 100.5, 99.7
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Suppose in [Chapter 11](ch11.xhtml#ch11) we tried to measure the depth of a
    well by timing coin drops and got the following values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 2.5, 3, 3.5, 4, 2
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The distance an object falls can be calculated (in meters) with the following
    formula:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: distance = 1/2 × G × time²
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: where G is 9.8 m/s/s. What is the probability that the well is over 500 meters
    deep?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What is the probability there is no well (i.e., the well is really 0 meters
    deep)? You’ll notice that probability is higher than you might expect, given your
    observation that there *is* a well. There are two good explanations for this probability
    being higher than it should. The first is that the normal distribution is a poor
    model for our measurements; the second is that, when making up numbers for an
    example, I chose values that you likely wouldn’t see in real life. Which is more
    likely to you?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
