<html><head></head><body><div class="chapter" title="Chapter&#xA0;3.&#xA0;Pseudoreplication: Choose Your Data Wisely"><div class="titlepage"><div><div><h1 class="title"><a id="pseudoreplication_choose_your_data_wisel"/>Chapter 3. Pseudoreplication: Choose Your Data Wisely</h1></div></div></div><p><a class="indexterm" id="iddle1303"/><a class="indexterm" id="iddle1317"/><a class="indexterm" id="iddle1320"/>In a randomized controlled trial, test subjects are assigned to either experimental or control groups randomly, rather than for any systematic reason. Though the word <span class="emphasis"><em>random</em></span> makes such studies sound slightly unscientific, a medical trial is not usually considered definitive unless it is a randomized controlled trial. Why? What’s so important about randomization?</p><p>Randomization prevents researchers from introducing systematic biases between test groups. Otherwise, they might assign frail patients to a less risky or less demanding treatment or assign wealthier patients to the new treatment because their insurance companies will pay for it. But randomization has no hidden biases, and it guarantees that each group has roughly the same demographics; any confounding factors—even ones <a class="indexterm" id="iddle1037"/><a class="indexterm" id="iddle1040"/><a class="indexterm" id="iddle1274"/><a class="indexterm" id="iddle1351"/><a class="indexterm" id="iddle1374"/>you don’t know about—can’t affect your results. When you obtain a statistically significant result, you know that the only possible cause is your medication or intervention.</p><div class="sect1" title="Pseudoreplication in Action"><div class="titlepage"><div><div><h1 class="title"><a id="pseudoreplication_in_action"/>Pseudoreplication in Action</h1></div></div></div><p>Let me return to a medical example. I want to compare two blood pressure medications, so I recruit 2,000 patients and randomly split them into two groups. Then I administer the medications. After waiting a month for the medication to take effect, I measure each patient’s blood pressure and compare the groups to find which has the lower average blood pressure. I can do an ordinary hypothesis test and get an ordinary <span class="emphasis"><em>p</em></span> value; with my sample size of 1,000 patients per group, I will have good statistical power to detect differences between the medications.</p><p>Now imagine an alternative experimental design. Instead of 1,000 patients per group, I recruit only 10, but I measure each patient’s blood pressure 100 times over the course of a few months. This way I can get a more accurate fix on their individual blood pressures, which may vary from day to day. Or perhaps I’m worried that my sphygmomanometers are not perfectly calibrated, so I measure with a different one each day.<sup>[<a class="footnote" href="#ftn.ch03fn01a" id="ch03fn01a">8</a>]</sup> I still have 1,000 data points per group but only 10 unique patients. I can perform the same hypothesis tests with the same statistical power since I seem to have the same sample size.</p><p>But do I really? A large sample size is <span class="emphasis"><em>supposed</em></span> to ensure that any differences between groups are a result of my treatment, not genetics or preexisting conditions. But in this new design, I’m not recruiting new patients. I’m just counting the genetics of each existing patient 100 times.</p><p>This problem is known as <span class="emphasis"><em>pseudoreplication</em></span>, and it is quite common.<sup><a class="link" href="apa.html#ch03en1"><a id="ch03en1_a"/>1</a></sup> For instance, after testing cells from a culture, a biologist might “replicate” his results by testing more cells from the same culture. Or a neuroscientist might test multiple neurons from the same animal, claiming to have a large sample size of hundreds of neurons from just two rats. A marine biologist might experiment on fish kept in aquariums, forgetting that fish sharing a single aquarium are not independent: their conditions may be affected by one another, as well as the tested treatment.<sup><a class="link" href="apa.html#ch03en2"><a id="ch03en2_a"/>2</a></sup> If these experiments are meant to reveal trends in rats or fish in general, their results will be misleading.</p><p><a class="indexterm" id="iddle1016"/><a class="indexterm" id="iddle1038"/><a class="indexterm" id="iddle1304"/><a class="indexterm" id="iddle1318"/><a class="indexterm" id="iddle1429"/>You can think of pseudoreplication as collecting data that answers the wrong question. Animal behaviorists frequently try to understand bird calls, for example, by playing different calls to birds and evaluating their reactions. Bird calls can vary between geographical regions, just like human accents, and these dialects can be compared. Prior to the 1990s, a common procedure for these experiments was to record one representative bird song from each dialect and then play these songs to 10 or 20 birds and record their reactions.<sup><a class="link" href="apa.html#ch03en3"><a id="ch03en3_a"/>3</a></sup> The more birds that were observed, the larger the sample size.</p><p>But the research question was about the different song dialects, not individual songs. No matter how “representative” any given song may have been, playing it to more birds couldn’t provide evidence that Dialect A was more attractive to male yellow-bellied sapsuckers than Dialect B was; it was only evidence for <span class="emphasis"><em>that specific song or recording</em></span>. A proper answer to the research question would have required many samples of songs from both dialects.</p><p>Pseudoreplication can also be caused by taking separate measurements of the same subject over time (<span class="emphasis"><em>autocorrelation</em></span>), like in my blood pressure experiment. Blood pressure measurements of the same patient from day to day are autocorrelated, as are revenue figures for a corporation from year to year. The mathematical structure of these autocorrelations can be complicated and vary from patient to patient or from business to business. The unwitting scientist who treats this data as though each measurement is independent of the others will obtain pseudoreplicated—and hence misleading—results.</p></div><div class="sect1" title="Accounting for Pseudoreplication"><div class="titlepage"><div><div><h1 class="title"><a id="accounting_for_pseudoreplication"/>Accounting for Pseudoreplication</h1></div></div></div><p>Careful experimental design can break the dependence between measurements. An agricultural field experiment might compare growth rates of different strains of a crop in each field. But if soil or irrigation quality varies from field to field, you won’t be able to separate variations due to crop variety from variations in soil conditions, no matter how many plants you measure in each field. A better design would be to divide each field into small blocks and randomly assign a crop variety to each block. With a large enough selection of blocks, soil variations can’t systematically benefit one crop more than the others.</p><p>Alternatively, if you can’t alter your experimental design, statistical analysis can help account for pseudoreplication. Statistical techniques do not magically eliminate dependence <a class="indexterm" id="iddle1056"/><a class="indexterm" id="iddle1070"/><a class="indexterm" id="iddle1084"/><a class="indexterm" id="iddle1167"/><a class="indexterm" id="iddle1178"/><a class="indexterm" id="iddle1224"/><a class="indexterm" id="iddle1306"/><a class="indexterm" id="iddle1333"/>between measurements or allow you to obtain good results with poor experimental design. They merely provide ways to quantify dependence so you can correctly interpret your data. (This means they usually give wider confidence intervals and larger <span class="emphasis"><em>p</em></span> values than the naive analysis.) Here are some options:<sup><a class="link" href="apa.html#ch03en4"><a id="ch03en4_a"/>4</a></sup></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p title="Average the dependent data points."><span class="title"><strong><span class="strong"><strong>Average the dependent data points.</strong></span></strong></span> For example, average all the blood pressure measurements taken from a single person and treat the average as a single data point. This isn’t perfect: if you measured some patients more frequently than others, this fact won’t be reflected in the averaged number. To make your results reflect the level of certainty in your measurements, which increases as you take more, you’d perform a weighted analysis, weighting the better-measured patients more strongly.</p></li><li class="listitem"><p title="Analyze each dependent data point separately."><span class="title"><strong><span class="strong"><strong>Analyze each dependent data point separately.</strong></span></strong></span> Instead of combining all the patient’s blood pressure measurements, analyze every patient’s blood pressure from, say, just day five, ignoring all other data points. But be careful: if you repeat this for each day of measurements, you’ll have problems with multiple comparisons, which I will discuss in the next chapter.</p></li><li class="listitem"><p title="Correct for the dependence by adjusting your p values and confidence intervals."><span class="title"><strong><span class="strong"><strong>Correct for the dependence by adjusting your <span class="emphasis"><em>p</em></span> values and confidence intervals.</strong></span></strong></span> Many procedures exist to estimate the size of the dependence between data points and account for it, including clustered standard errors, repeated measures tests, and hierarchical models.<sup><a class="link" href="apa.html#ch03en5"><a id="ch03en5_a"/>5</a></sup>,<sup><a class="link" href="apa.html#ch03en6"><a id="ch03en6_a"/>6</a></sup>,<sup><a class="link" href="apa.html#ch03en7"><a id="ch03en7_a"/>7</a></sup></p></li></ul></div></div><div class="sect1" title="Batch Biology"><div class="titlepage"><div><div><h1 class="title"><a id="batch_biology"/>Batch Biology</h1></div></div></div><p>New technology has led to an explosion of data in biology. Inexpensive labs-on-a-chip called microarrays allow biologists to track the activities of thousands of proteins or genes simultaneously. Microarrays contain thousands of <span class="emphasis"><em>probes</em></span>, which chemically bind to different proteins or genes; fluorescent dyes allow a scanner to detect the quantity of material bound to each probe. Cancer research in particular has benefited from these new technologies: researchers can track the expression of thousands of genes in both cancerous and healthy cells, which might lead to new targeted cancer treatments that leave healthy tissue unharmed.</p><p>Microarrays are usually processed in batches on machines that detect the fluorescent dyes. In a large study, different microarrays may be processed by different laboratories using <a class="indexterm" id="iddle1220"/><a class="indexterm" id="iddle1301"/><a class="indexterm" id="iddle1305"/>different equipment. A naive experimental setup might be to collect a dozen cancerous samples and a dozen healthy samples, inject them into microarrays, and then run all the cancerous samples through the processing machine on Tuesday and the healthy samples on Wednesday.</p><p>You can probably see where this is going. Microarray results vary strongly between processing batches: machine calibrations might change, differences in laboratory temperature can affect chemical reactions, and different bottles of chemical reagents might be used while processing the microarrays. Sometimes the largest source of variation in an experiment’s data is simply what day the microarrays were processed. Worse, these problems do not affect the entire microarray in the same way—in fact, correlations between the activity of pairs of genes can entirely <span class="emphasis"><em>reverse</em></span> when processed in a different batch.<sup><a class="link" href="apa.html#ch03en8"><a id="ch03en8_a"/>8</a></sup> As a result, additional samples don’t necessarily add data points to a biological experiment. If the new samples are processed in the same batch as the old, they just measure systematic error introduced by the equipment—not anything about cancerous cells in general.</p><p>Again, careful experimental design can mitigate this problem. If two different biological groups are being tested, you can split each group evenly between batches so systematic differences do not affect the groups in different ways. Also, be sure to record how each batch was processed, how each sample was stored, and what chemical reagents were used during processing; make this information available to the statisticians analyzing the data so they use it to detect problems.</p><p>For example, a statistician could perform principal components analysis on the data to determine whether different batches gave wildly different results. Principal components analysis determines which combinations of variables in the data account for the most variation in the results. If it indicates that the batch number is highly influential, the data can be analyzed taking batch number into account as a confounding variable.</p></div><div class="sect1" title="Synchronized Pseudoreplication"><div class="titlepage"><div><div><h1 class="title"><a id="synchronized_pseudoreplication"/>Synchronized Pseudoreplication</h1></div></div></div><p>Pseudoreplication can occur through less obvious routes. Consider one example in an article reviewing the prevalence of pseudoreplication in the ecological literature.<sup><a class="link" href="apa.html#ch03en9"><a id="ch03en9_a"/>9</a></sup> Suppose you want to see whether chemicals in the growing shoots of grasses are responsible for the start of the reproductive season in cute furry rodents: your hypothesis is that when the grasses sprout in springtime, the rodents eat them and begin their mating <a class="indexterm" id="iddle1213"/>season. To test this, you try putting some animals in a lab, feed half of them ordinary food and the other half food mixed with the grasses, and wait to see when their reproductive cycles start.</p><p>But wait: you vaguely recall having read a paper suggesting that the reproductive cycles of mammals living in groups can synchronize—something about their pheromones. So maybe the animals in each group aren’t actually independent of each other. After all, they’re all in the same lab, exposed to the same pheromones. As soon as one goes into estrus, its pheromones could cause others to follow, no matter what they’ve been eating. Your sample size will be effectively one.</p><p>The research you’re thinking of is a famous paper from the early 1970s, published in <span class="emphasis"><em>Nature</em></span> by Martha McClintock, which suggested that women’s menstrual cycles can synchronize if they live in close contact.<sup><a class="link" href="apa.html#ch03en10"><a id="ch03en10_a"/>10</a></sup> Other studies found similar results in golden hamsters, Norway rats, and chimpanzees. These results seem to suggest that synchronization could cause pseudoreplication in your study. Great. So does this mean you’ll have to build pheromone-proof cages to keep your rodents isolated from each other?</p><p>Not quite. You might wonder how you prove that menstrual or estrous cycles synchronize. Well, as it turns out, you can’t. The studies “proving” synchronization in various animals were themselves pseudoreplicated in an insidious way.</p><p>McClintock’s study of human menstrual cycles went something like this:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Find groups of women who live together in close contact—for instance, college students in dormitories.</p></li><li class="listitem"><p>Every month or so, ask each woman when her last menstrual period began and to list the other women with whom she spent the most time.</p></li><li class="listitem"><p>Use these lists to split the women into groups that tend to spend time together.</p></li><li class="listitem"><p>For each group of women, see how far the average woman’s period start date deviates from the average.</p></li></ol></div><p>Small deviations would mean the women’s cycles were aligned, all starting at around the same time. Then the researchers tested whether the deviations decreased over time, which would indicate that the women were synchronizing. To do this, they checked the mean deviation at five different points throughout the study, testing whether the deviation decreased more than could be expected by chance.</p><p><a class="indexterm" id="iddle1412"/>Unfortunately, the statistical test they used assumed that if there was no synchronization, the deviations would <span class="emphasis"><em>randomly</em></span> increase and decrease from one period to another. But imagine two women in the study who start with aligned cycles. One has an average gap of 28 days between periods and the other a gap of roughly 30 days. Their cycles will diverge <span class="emphasis"><em>consistently</em></span> over the course of the study, starting two days apart, then four days, and so on, with only a bit of random variation because periods are not perfectly timed. Similarly, two women can start the study <span class="emphasis"><em>not</em></span> aligned but gradually align.</p><p>For comparison, if you’ve ever been stuck in traffic, you’ve probably seen how two turn signals blinking at different rates will gradually synchronize and then go out of phase again. If you’re stuck at the intersection long enough, you’ll see this happen multiple times. But to the best of my knowledge, there are no turn signal pheromones.</p><p>So we would actually <span class="emphasis"><em>expect</em></span> two unaligned menstrual cycles to fall into alignment, at least temporarily. The researchers failed to account for this effect in their statistical tests.</p><p>They also made an error calculating synchronization at the beginning of the study: if one woman’s period started four days before the study began and another’s started four days <span class="emphasis"><em>after</em></span>, the difference is only eight days. But periods before the beginning of the study were not counted, so the recorded difference was between the fourth day and the first woman’s next period, as much as three weeks later.</p><p>These two errors combined meant that the scientists were able to obtain statistically significant results even when there was no synchronization effect outside what would occur without pheromones.<sup><a class="link" href="apa.html#ch03en11"><a id="ch03en11_a"/>11</a></sup>,<sup><a class="link" href="apa.html#ch03en12"><a id="ch03en12_a"/>12</a></sup></p><p>The additional data points the researchers took as they followed subjects through more menstrual cycles did not provide evidence of synchronization at all. It was merely more statistical evidence of the synchronization that would’ve happened by chance, regardless of pheromones. The statistical test addressed a different question than the scientists intended to ask.</p><p>Similar problems exist with studies claiming that small furry mammals or chimpanzees synchronize their estrous cycles. Subsequent research using corrected statistical methods has failed to find any evidence of estrous or menstrual synchronization (though this is controversial).<sup><a class="link" href="apa.html#ch03en13"><a id="ch03en13_a"/>13</a></sup> We only thought our rodent experiment could have pseudoreplication because we believed a pseudoreplicated study.</p><p>Don’t scoff at your friends if they complain about synchronized periods, though. If the average cycle lasts 28 days, then two average women can have periods which start at most 14 days apart. (If your period starts 20 days after your friend’s, it’s only eight days before her next period.) That’s the maximum, so the average will be seven days, and since periods can last for five to seven days, they will frequently overlap even as cycles converge and diverge over time.</p><div class="sidebar"><a id="tips-id00001"/><p class="title">Tips</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Ensure that your statistical analysis really answers your research question. Additional measurements that are highly dependent on previous data do not prove that your results generalize to a wider population—they merely increase your certainty about the specific sample you studied.</p></li><li class="listitem"><p>Use statistical methods such as hierarchical models and clustered standard errors to account for a strong dependence between your measurements.</p></li><li class="listitem"><p>Design experiments to eliminate hidden sources of correlation between variables. If that’s not possible, record confounding factors so they can be adjusted for statistically. But if you don’t consider the dependence from the beginning, you may find there is no way to save your data.</p></li></ul></div></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#ch03fn01a" id="ftn.ch03fn01a">8</a>] </sup>I just wanted an excuse to use the word <span class="emphasis"><em>sphygmomanometer</em></span>.</p></div></div></div></body></html>