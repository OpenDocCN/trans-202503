<html><head></head><body>
<h2 class="h2" id="ch13"><span epub:type="pagebreak" id="page_261"/><span class="big"><strong>13</strong></span><br/><strong>ELEMENTARY STATISTICS</strong></h2>&#13;
<div class="image"><img src="../images/common-01.jpg" alt="image"/></div>&#13;
<p class="noindent">Statistics is the practice of turning <em>data</em> into <em>information</em> to identify trends and understand features of populations. This chapter will cover some basic definitions and use R to demonstrate their application.</p>&#13;
<h3 class="h3" id="ch13lev1sec42"><strong>13.1 Describing Raw Data</strong></h3>&#13;
<p class="noindent">Often, the first thing statistical analysts are faced with is raw data—in other words, the records or observations that make up a sample. Depending on the nature of the intended analysis, these data could be stored in a specialized R object, often a data frame (<a href="ch05.xhtml#ch05">Chapter 5</a>), possibly read in from an external file using techniques from <a href="ch08.xhtml#ch08">Chapter 8</a>. Before you can begin summarizing or modeling your data, however, it is important to clearly identify your available variables.</p>&#13;
<p class="indent">A <em>variable</em> is a characteristic of an individual in a population, the value of which can differ between entities within that population. For example, in <a href="ch05.xhtml#ch05lev1sec20">Section 5.2</a>, you experimented with an illustrative data frame <code>mydata</code>. <span epub:type="pagebreak" id="page_262"/>You recorded the age, sex, and humor level for a sample of people. These characteristics are your variables; the values measured will differ between the individuals.</p>&#13;
<p class="indent">Variables can take on a number of forms, determined by the nature of the values they may take. Before jumping into R, you’ll look at some standard ways in which variables are described.</p>&#13;
<h4 class="h4" id="ch13lev2sec112"><strong><em>13.1.1 Numeric Variables</em></strong></h4>&#13;
<p class="noindent">A <em>numeric</em> variable is one whose observations are naturally recorded as numbers. There are two types of numeric variables: continuous and discrete.</p>&#13;
<p class="indent">A <em>continuous</em> variable can be recorded as any value in some interval, up to any number of decimals (which technically gives an infinite number of possible values, even if the continuum is restricted in range). For example, if you were observing rainfall amount, a value of 15 mm would make sense, but so would a value of 15.42135 mm. Any degree of measurement precision gives a valid observation.</p>&#13;
<p class="indent">A <em>discrete</em> variable, on the other hand, may take on only distinct numeric values—and if the range is restricted, then the number of possible values is finite. For example, if you were observing the number of heads in 20 flips of a coin, only whole numbers would make sense. It would not make sense to observe 15.42135 heads; the possible outcomes are restricted to the integers from 0 to 20 (inclusive).</p>&#13;
<h4 class="h4" id="ch13lev2sec113"><strong><em>13.1.2 Categorical Variables</em></strong></h4>&#13;
<p class="noindent">Though numeric observations are common for many variables, it’s also important to consider <em>categorical</em> variables. Like some discrete variables, categorical variables may take only one of a finite number of possibilities. Unlike discrete variables, however, categorical observations are not always recorded as numeric values.</p>&#13;
<p class="indent">There are two types of categorical variables. Those that cannot be logically ranked are called <em>nominal</em>. A good example of a categorical-nominal variable is sex. In most data sets, it has two fixed possible values, male and female, and the order of these categories is irrelevant. Categorical variables that can be naturally ranked are called <em>ordinal</em>. An example of a categorical-ordinal variable would be the dose of a drug, with the possible values low, medium, and high. These values can be ordered in either increasing or decreasing amounts, and the ordering might be relevant to the research.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>Some statistical texts blur the definitions of discrete and categorical variables or even use them interchangeably. While this practice is not necessarily incorrect, I prefer to keep the definitions separate, for clarity. That is, I’ll say “discrete” when referring to a naturally numeric variable that cannot be expressed on a continuous scale (such as a count), and I’ll say “categorical” when the possible outcomes for a given individual are not necessarily numeric and the number of possible values is always finite.</em></p>&#13;
</div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_263"/>Once you know what to look for, identifying the types of variables in a given data set is straightforward. Take the data frame <code>chickwts</code>, which is available in the automatically loaded <code>datasets</code> package. At the prompt, directly entering the following gives you the first five records of this data set.</p>&#13;
<pre>R&gt; chickwts[1:5,]<br/>  weight      feed<br/>1    179 horsebean<br/>2    160 horsebean<br/>3    136 horsebean<br/>4    227 horsebean<br/>5    217 horsebean</pre>&#13;
<p class="indent">R’s help file (<code>?chickwts</code>) describes these data as comprising the weights of 71 chicks (in grams) after six weeks, based on the type of food provided to them. Now let’s take a look at the two columns in their entirety as vectors:</p>&#13;
<pre>R&gt; chickwts$weight<br/> [1] 179 160 136 227 217 168 108 124 143 140 309 229 181 141 260 203 148 169<br/>[19] 213 257 244 271 243 230 248 327 329 250 193 271 316 267 199 171 158 248<br/>[37] 423 340 392 339 341 226 320 295 334 322 297 318 325 257 303 315 380 153<br/>[55] 263 242 206 344 258 368 390 379 260 404 318 352 359 216 222 283 332<br/>R&gt; chickwts$feed<br/> [1] horsebean horsebean horsebean horsebean horsebean horsebean horsebean<br/> [8] horsebean horsebean horsebean linseed   linseed   linseed   linseed<br/>[15] linseed   linseed   linseed   linseed   linseed   linseed   linseed<br/>[22] linseed   soybean   soybean   soybean   soybean   soybean   soybean<br/>[29] soybean   soybean   soybean   soybean   soybean   soybean   soybean<br/>[36] soybean   sunflower sunflower sunflower sunflower sunflower sunflower<br/>[43] sunflower sunflower sunflower sunflower sunflower sunflower meatmeal<br/>[50] meatmeal  meatmeal  meatmeal  meatmeal  meatmeal  meatmeal  meatmeal<br/>[57] meatmeal  meatmeal  meatmeal  casein    casein    casein    casein<br/>[64] casein    casein    casein    casein    casein    casein    casein<br/>[71] casein<br/>Levels: casein horsebean linseed meatmeal soybean sunflower</pre>&#13;
<p class="indent"><code>weight</code> is a numeric measurement that can fall anywhere on a continuum, so this is a numeric-continuous variable. The fact that the chick weights appear to have been rounded or recorded to the nearest gram does not affect this definition because in reality the weights can be any figure (within reason). <code>feed</code> is clearly a categorical variable because it has only six possible outcomes, which aren’t numeric. The absence of any natural or easily identifiable ordering leads to the conclusion that <code>feed</code> is a categorical-nominal variable.</p>&#13;
<h4 class="h4" id="ch13lev2sec114"><span epub:type="pagebreak" id="page_264"/><strong><em>13.1.3 Univariate and Multivariate Data</em></strong></h4>&#13;
<p class="noindent">When discussing or analyzing data related to only one dimension, you’re dealing with <em>univariate</em> data. For example, the <code>weight</code> variable in the earlier example is univariate since each measurement can be expressed with one component—a single number.</p>&#13;
<p class="indent">When it’s necessary to consider data with respect to variables that exist in more than one dimension (in other words, with more than one component or measurement associated with each observation), your data are considered <em>multivariate</em>. Multivariate measurements are arguably most relevant when the individual components aren’t as useful when considered on their own (in other words, as univariate quantities) in any given statistical analysis.</p>&#13;
<p class="indent">An ideal example is that of spatial coordinates, which must be considered in terms of at least two components—a horizontal <em>x</em>-coordinate and a vertical <em>y</em>-coordinate. The univariate data alone—for example, the <em>x</em>-axis values only—aren’t especially useful. Consider the <code>quakes</code> data set (like <code>chickwts</code>, this is automatically available through the <code>datasets</code> package), which contains observations on 1,000 seismic events recorded off the coast of Fiji. If you look at the first five records and read the descriptions in the help file <code>?quakes</code>, you quickly get a good understanding of what’s presented.</p>&#13;
<pre>R&gt; quakes[1:5,]<br/>     lat   long depth mag stations<br/>1 -20.42 181.62   562 4.8       41<br/>2 -20.62 181.03   650 4.2       15<br/>3 -26.00 184.10    42 5.4       43<br/>4 -17.97 181.66   626 4.1       19<br/>5 -20.42 181.96   649 4.0       11</pre>&#13;
<p class="indent">The columns <code>lat</code> and <code>long</code> provide the latitude and longitude of the event, <code>depth</code> provides the depth of the event (in kilometers), <code>mag</code> provides the magnitude on the Richter scale, and <code>stations</code> provides the number of observation stations that detected the event. If you’re interested in the spatial dispersion of these earthquakes, then examining only the latitude or the longitude is rather uninformative. The location of each event is described with two components: a latitude <em>and</em> a longitude value. You can easily plot these 1,000 events; <a href="ch13.xhtml#ch13fig1">Figure 13-1</a> shows the result of the following code:</p>&#13;
<pre>R&gt; plot(quakes$long,quakes$lat,xlab="Longitude",ylab="Latitude")</pre>&#13;
<div class="image"><span epub:type="pagebreak" id="page_265"/><img src="../images/f13-01.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch13fig1"/>Figure 13-1: Plotting the spatial locations of earthquakes using a bivariate (multivariate with two components) variable</em></p>&#13;
<h4 class="h4" id="ch13lev2sec115"><strong><em>13.1.4 Parameter or Statistic?</em></strong></h4>&#13;
<p class="noindent">As already noted, statistics as a discipline is concerned with understanding features of an overall <em>population</em>, defined as the entire collection of individuals or entities of interest. The characteristics of that population are referred to as <em>parameters</em>. Because researchers are rarely able to access relevant data on every single member of the population of interest, they typically collect a <em>sample</em> of entities to represent the population and record relevant data from these entities. They may then estimate the parameters of interest using the sample data—and those estimates are the <em>statistics</em>.</p>&#13;
<p class="indent">For example, if you were interested in the average age of women in the United States who own cats, the population of interest would be all women residing in the United States who own at least one cat. The parameter of interest is the true mean age of women in the United States who own at least one cat. Of course, obtaining the age of every single female American with a cat would be a difficult feat. A more feasible approach would be to randomly identify a smaller number of cat-owning American women and take data from them—this is your sample, and the mean age of the women in the sample is your statistic.</p>&#13;
<p class="indent">Thus, the key difference between a statistic and a parameter is whether the characteristic refers to the sample you drew your data from or the wider population. <a href="ch13.xhtml#ch13fig2">Figure 13-2</a> illustrates this, with the mean <em>μ</em> of a measure for individuals in a population as the parameter and with the mean <em><span class="ent">x̄</span></em> of a sample of individuals taken from that population as the statistic.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_266"/><img src="../images/f13-02.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch13fig2"/>Figure 13-2: A conceptualization of statistical practice to illustrate the definitions of</em> parameter <em>and</em> statistic<em>, using the mean as an example</em></p>&#13;
<div class="ex">&#13;
<p class="ext"><a id="ch13exc1"/><strong>Exercise 13.1</strong></p>&#13;
<ol type="a">&#13;
<li><p class="noindents">For each of the following, identify the type of variable described: numeric-continuous, numeric-discrete, categorical-nominal, or categorical-ordinal:</p>&#13;
<ol type="i">&#13;
<li><p class="noindents">The number of blemishes on the hood of a car coming off a production line</p></li>&#13;
<li><p class="noindents">A survey question that asks the participant to select from Strongly agree, Agree, Neutral, Disagree, and Strongly disagree</p></li>&#13;
<li><p class="noindents">The noise level (in decibels) at a concert</p></li>&#13;
<li><p class="noindents">The noise level out of three possible choices: high, medium, low</p></li>&#13;
<li><p class="noindents">A choice of primary color</p></li>&#13;
<li><p class="noindents">The distance between a cat and a mouse</p></li>&#13;
</ol></li>&#13;
<li><p class="noindents">For each of the following, identify whether the quantity discussed is a population parameter or a sample statistic. If the latter, also identify what the corresponding population parameter is.</p>&#13;
<ol type="i">&#13;
<li><p class="noindents">The percentage of 50 New Zealanders who own a gaming console</p></li>&#13;
<li><p class="noindents">The average number of blemishes found on the hoods of three cars in the No Dodgy Carz yard</p></li>&#13;
<li><p class="noindents">The proportion of domestic cats in the United States that wear a collar</p></li>&#13;
<li><p class="noindents">The average number of times per day a vending machine is used in a year</p></li>&#13;
<li><p class="noindents">The average number of times per day a vending machine is used in a year, based on data collected on three distinct days in that year</p></li>&#13;
</ol></li>&#13;
</ol>&#13;
</div>&#13;
<h3 class="h3" id="ch13lev1sec43"><span epub:type="pagebreak" id="page_267"/><strong>13.2 Summary Statistics</strong></h3>&#13;
<p class="noindent">Now that you’ve learned the basic terminology, you’re ready to calculate some statistics with R. In this section, you’ll look at the most common types of statistics used to summarize the different types of variables I’ve discussed.</p>&#13;
<h4 class="h4" id="ch13lev2sec116"><strong><em>13.2.1 Centrality: Mean, Median, Mode</em></strong></h4>&#13;
<p class="noindent"><em>Measures of centrality</em> are commonly used to explain large collections of data by describing where numeric observations are centered. One of the most common measures of centrality is of course the arithmetic <em>mean</em>. It’s considered to be the central “balance point” of a collection of observations.</p>&#13;
<p class="indent">For a set of <em>n</em> numeric measurements labeled <em>x</em> = {<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, . . . , <em>x</em><sub>n</sub>}, you find the sample mean <em><span class="ent">x̄</span></em> as follows:</p>&#13;
<div class="imagec"><a id="ch13eq1"/><img src="../images/e13-1.jpg" alt="image"/></div>&#13;
<p class="indent">So, for example, if you observe the data 2,4.4,3,3,2,2.2,2,4, the mean is calculated like this:</p>&#13;
<div class="imagec"><img src="../images/f0267-01.jpg" alt="image"/></div>&#13;
<p class="indentb">The <em>median</em> is the “middle magnitude” of your observations, so if you place your observations in order from smallest to largest, you can find the median by either taking the middle value (if there’s an odd number of observations) or finding the mean of the two middle values (if there’s an even number of observations). Using the notation for <em>n</em> measurements labeled <em>x</em> = {<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, . . . , <em>x</em><sub>n</sub>}, you find the sample median <img class="middle" src="../images/mx.jpg" alt="image"/> as follows:</p>&#13;
<p class="bull">• Sort the observations from smallest to largest to give the “order statistics” <img class="middle" src="../images/f0267-02.jpg" alt="image"/>,<img src="../images/f0267-02a.jpg" alt="image"/>,...,<img src="../images/f0267-03.jpg" alt="image"/>, where <img class="middle" src="../images/f0267-04.jpg" alt="image"/> denotes the <em>t</em>th smallest observation, regardless of observation number <em>i</em>, <em>j</em>, <em>k</em>, . . . .</p>&#13;
<p class="bull">• Then, do the following:</p>&#13;
<div class="imagec"><a id="ch13eq2"/><img src="../images/e13-2.jpg" alt="image"/></div>&#13;
<p class="indent">For the same data, sorting them from smallest to largest yields 2, 2, 2, 2.2, 3, 3, 4, 4.4. With <em>n</em> = 8 observations, you have <em>n</em>/2 = 4. The median is therefore as follows:</p>&#13;
<div class="imagec"><img src="../images/f0267-03a.jpg" alt="image"/></div>&#13;
<p class="indent">The <em>mode</em> is simply the “most common” observation. This statistic is more often used with numeric-discrete data than with numeric-continuous, though it is used with reference to <em>intervals</em> of the latter (commonly when <span epub:type="pagebreak" id="page_268"/>discussing probability density functions—see <a href="ch15.xhtml#ch15">Chapters 15</a> and <a href="ch16.xhtml#ch16">16</a>). It’s possible for a collection of <em>n</em> numeric measurements <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, . . . , <em>x<sub>n</sub></em> to have no mode (where each observation is unique) or to have more than one mode (where more than one particular value occurs the largest number of times). To find the mode <img class="middle" src="../images/dx.jpg" alt="image"/>, simply tabulate the frequency of each measurement.</p>&#13;
<p class="indent">Again using the eight observations from the example, you can see the frequencies here:</p>&#13;
<table>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table1"><p class="table"><strong>Observation</strong></p></td>&#13;
<td style="vertical-align: top;" class="table1"><p class="tablec">2</p></td>&#13;
<td style="vertical-align: top;" class="table1"><p class="tablec">2.2</p></td>&#13;
<td style="vertical-align: top;" class="table1"><p class="tablec">3</p></td>&#13;
<td style="vertical-align: top;" class="table1"><p class="tablec">4</p></td>&#13;
<td style="vertical-align: top;" class="table2"><p class="tablec">4.4</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table3"><p class="table"><strong>Frequency</strong></p></td>&#13;
<td style="vertical-align: top;" class="table3"><p class="tablec">3</p></td>&#13;
<td style="vertical-align: top;" class="table3"><p class="tablec">1</p></td>&#13;
<td style="vertical-align: top;" class="table3"><p class="tablec">2</p></td>&#13;
<td style="vertical-align: top;" class="table3"><p class="tablec">1</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="tablec">1</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">The value 2 occurs three times, which is more frequent than any other value, so the single mode for these data is the value 2.</p>&#13;
<p class="indent">In R, it’s easy to compute the arithmetic mean and the median with built-in functions of the same names. First, store the eight observations as the numeric vector <code>xdata</code>.</p>&#13;
<pre>R&gt; xdata &lt;- c(2,4.4,3,3,2,2.2,2,4)</pre>&#13;
<p class="indent">Then compute the statistics.</p>&#13;
<pre>R&gt; x.bar &lt;- mean(xdata)<br/>R&gt; x.bar<br/>[1] 2.825<br/>R&gt; m.bar &lt;- median(xdata)<br/>R&gt; m.bar<br/>[1] 2.6</pre>&#13;
<p class="indent">Finding a mode is perhaps most easily achieved by using R’s <code>table</code> function, which gives you the frequencies you need.</p>&#13;
<pre>R&gt; xtab &lt;- table(xdata)<br/>R&gt; xtab<br/>xdata<br/>  2 2.2   3   4 4.4<br/>  3   1   2   1   1</pre>&#13;
<p class="indent">Though this clearly shows the mode for a small data set, it’s good practice to write code that can automatically identify the most frequent observations for any <code>table</code>. The <code>min</code> and <code>max</code> functions will report the smallest and largest values, with <code>range</code> returning both in a vector of length 2.</p>&#13;
<pre>R&gt; min(xdata)<br/>[1] 2<br/>R&gt; max(xdata)<br/>[1] 4.4<br/>R&gt; range(xdata)<br/>[1] 2.0 4.4</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_269"/>When applied to a <code>table</code>, these commands operate on the reported frequencies.</p>&#13;
<pre>R&gt; max(xtab)<br/>[1] 3</pre>&#13;
<p class="indent">Finally, therefore, you can construct a logical flag vector to get the mode from <code>table</code>.</p>&#13;
<pre>R&gt; d.bar &lt;- xtab[xtab==max(xtab)]<br/>R&gt; d.bar<br/>2<br/>3</pre>&#13;
<p class="indent">Here, 2 is the value and 3 is the frequency of that value.</p>&#13;
<p class="indent">Let’s return to the <code>chickwts</code> data set explored earlier in <a href="ch13.xhtml#ch13lev2sec113">Section 13.1.2</a>. The mean and median weights of the chicks are as follows:</p>&#13;
<pre>R&gt; mean(chickwts$weight)<br/>[1] 261.3099<br/>R&gt; median(chickwts$weight)<br/>[1] 258</pre>&#13;
<p class="indent">You can also look at the <code>quakes</code> data set explored in <a href="ch13.xhtml#ch13lev2sec114">Section 13.1.3</a>. The most common magnitude of earthquake in the data set is identified with the following, which indicates that there were 107 occurrences of a 4.5 magnitude event:</p>&#13;
<pre>R&gt; Qtab &lt;- table(quakes$mag)<br/>R&gt; Qtab[Qtab==max(Qtab)]<br/>4.5<br/>107</pre>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>Several methods are available to compute medians, though the impact on results is usually negligible for most practical purposes. Here I’ve simply used the default “sample” version used by R.</em></p>&#13;
</div>&#13;
<p class="indent">Many of the functions R uses to compute statistics from a numeric structure will not run if the data set includes missing or undefined values (<code>NA</code>s or <code>NaN</code>s). Here’s an example:</p>&#13;
<pre>R&gt; mean(c(1,4,NA))<br/>[1] NA<br/>R&gt; mean(c(1,4,NaN))<br/>[1] NaN</pre>&#13;
<p class="indent">To prevent unintended <code>NaN</code>s or forgotten <code>NA</code>s being ignored without the user’s knowledge, R does not by default ignore these special values when <span epub:type="pagebreak" id="page_270"/>running functions such as <code>mean</code>—and therefore will not return the intended numeric results. You can, however, set an optional argument <code>na.rm</code> to <code>TRUE</code>, which will force the function to operate only on the numeric values that are present.</p>&#13;
<pre>R&gt; mean(c(1,4,NA),na.rm=TRUE)<br/>[1] 2.5<br/>R&gt; mean(c(1,4,NaN),na.rm=TRUE)<br/>[1] 2.5</pre>&#13;
<p class="indent">You should use this argument only if you’re aware there might be missing values and that the result will be computed based on only those values that <em>have</em> been observed. Functions that I’ve discussed already such as <code>sum</code>, <code>prod</code>, <code>mean</code>, <code>median</code>, <code>max</code>, <code>min</code>, and <code>range</code>—essentially anything that calculates a numeric statistic based on a numeric vector—all have the <code>na.rm</code> argument available to them.</p>&#13;
<p class="indent">Lastly, in calculating simple summary statistics, it’s useful to remind yourself of the <code>tapply</code> function (see <a href="ch10.xhtml#ch10lev2sec94">Section 10.2.3</a>), used to compute statistics grouped by a specific categorical variable. Suppose, for example, you wanted to find the mean weight of the chicks grouped by feed type. One solution would be to use the <code>mean</code> function on each specific subset.</p>&#13;
<pre>R&gt; mean(chickwts$weight[chickwts$feed=="casein"])<br/>[1] 323.5833<br/>R&gt; mean(chickwts$weight[chickwts$feed=="horsebean"])<br/>[1] 160.2<br/>R&gt; mean(chickwts$weight[chickwts$feed=="linseed"])<br/>[1] 218.75<br/>R&gt; mean(chickwts$weight[chickwts$feed=="meatmeal"])<br/>[1] 276.9091<br/>R&gt; mean(chickwts$weight[chickwts$feed=="soybean"])<br/>[1] 246.4286<br/>R&gt; mean(chickwts$weight[chickwts$feed=="sunflower"])<br/>[1] 328.9167</pre>&#13;
<p class="indent">This is cumbersome and lengthy. Using <code>tapply</code>, however, you can calculate the same values by category using just one line of code.</p>&#13;
<pre>R&gt; tapply(chickwts$weight,INDEX=chickwts$feed,FUN=mean)<br/>   casein horsebean   linseed  meatmeal   soybean sunflower<br/>323.5833   160.2000  218.7500  276.9091  246.4286  328.9167</pre>&#13;
<p class="indent">Here, the first argument is the numeric vector upon which to operate, the <code>INDEX</code> argument specifies the grouping variable, and the <code>FUN</code> argument gives the name of the function to be performed on the data in the first argument as per the subsets defined by <code>INDEX</code>. Like other functions you’ve seen that request the user to specify <em>another</em> function to govern operations, <code>tapply</code> <span epub:type="pagebreak" id="page_271"/>includes an ellipsis (see <a href="ch09.xhtml#ch09lev2sec86">Sections 9.2.5</a> and <a href="ch11.xhtml#ch11lev2sec102">11.2.4</a>) to allow the user to supply further arguments directly to <code>FUN</code> if required.</p>&#13;
<h4 class="h4" id="ch13lev2sec117"><strong><em>13.2.2 Counts, Percentages, and Proportions</em></strong></h4>&#13;
<p class="noindent">In this section, you’ll look at the summary of data that aren’t necessarily numeric. It makes little sense, for example, to ask R to compute the mean of a categorical variable, but it is sometimes useful to count the number of observations that fall within each category—these <em>counts</em> or <em>frequencies</em> represent the most elementary summary statistic of categorical data.</p>&#13;
<p class="indent">This uses the same count summary that was necessary for the mode calculation in <a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a>, so again you can use the <code>table</code> command to obtain frequencies. Recall there are six feed types making up the diet of the chicks in the <code>chickwts</code> data frame. Getting these factor-level counts is as straightforward as this:</p>&#13;
<pre>R&gt; table(chickwts$feed)<br/><br/>   casein horsebean   linseed  meatmeal   soybean  sunflower<br/>       12        10        12        11        14         12</pre>&#13;
<p class="indent">You can gather more information from these counts by identifying the <em>proportion</em> of observations that fall into each category. This will give you comparable measures across multiple data sets. Proportions represent the fraction of observations in each category, usually expressed as a decimal (floating-point) number between 0 and 1 (inclusive). To calculate proportions, you only need to modify the previous count function by dividing the count (or frequency) by the overall sample size (obtained here by using <code>nrow</code> on the appropriate data frame object; see <a href="ch05.xhtml#ch05lev1sec20">Section 5.2</a>).</p>&#13;
<pre>R&gt; table(chickwts$feed)/nrow(chickwts)<br/><br/>   casein horsebean   linseed  meatmeal   soybean sunflower<br/>0.1690141 0.1408451 0.1690141 0.1549296 0.1971831 0.1690141</pre>&#13;
<p class="indent">Of course, you needn’t do everything associated with counts via <code>table</code>. A simple <code>sum</code> of an appropriate logical flag vector can be just as useful—recall that <code>TRUE</code>s are automatically treated as <code>1</code> and <code>FALSE</code>s as <code>0</code> in any arithmetic treatment of logical structures in R (refer to <a href="ch04.xhtml#ch04lev2sec40">Section 4.1.4</a>). Such a <code>sum</code> will provide you with the desired frequency, but to get a proportion, you still need to divide by the total sample size. Furthermore, this is actually equivalent to finding the <code>mean</code> of a logical flag vector. For example, to find the proportion of chicks fed soybean, note that the following two calculations give identical results of around 0.197:</p>&#13;
<pre>R&gt; sum(chickwts$feed=="soybean")/nrow(chickwts)<br/>[1] 0.1971831<br/>R&gt; mean(chickwts$feed=="soybean")<br/>[1] 0.1971831</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_272"/>You can also use this approach to calculate the proportion of entities in combined groups, achieved easily through logical operators (see <a href="ch04.xhtml#ch04lev2sec39">Section 4.1.3</a>). The proportion of chicks fed either soybean <em>or</em> horsebean is as follows:</p>&#13;
<pre>R&gt; mean(chickwts$feed=="soybean"|chickwts$feed=="horsebean")<br/>[1] 0.3380282</pre>&#13;
<p class="indent">Yet again, the <code>tapply</code> function can prove useful. This time, to get the proportions of chicks on each diet, you’ll define the <code>FUN</code> argument to be an anonymous function (refer to <a href="ch11.xhtml#ch11lev2sec104">Section 11.3.2</a>) that performs the required calculation.</p>&#13;
<pre>R&gt; tapply(chickwts$weight,INDEX=chickwts$feed,<br/>          FUN=function(x) length(x)/nrow(chickwts))<br/>   casein horsebean   linseed  meatmeal   soybean sunflower<br/>0.1690141 0.1408451 0.1690141 0.1549296 0.1971831 0.1690141</pre>&#13;
<p class="indent">The disposable function here is defined with a dummy argument <code>x</code>, which you’re using to represent the vector of weights in each feed group to which <code>FUN</code> applies. Finding the desired proportion is therefore a case of dividing the number of observations in <code>x</code> by the total number of observations.</p>&#13;
<p class="indent">The last function to note is the <code>round</code> function, which rounds numeric data output to a certain number of decimal places. You need only supply to <code>round</code> your numeric vector (or matrix or any other appropriate data structure) and however many decimal places (as the argument <code>digits</code>) you want your figures rounded to.</p>&#13;
<pre>R&gt; round(table(chickwts$feed)/nrow(chickwts),digits=3)<br/><br/>   casein horsebean   linseed  meatmeal   soybean sunflower<br/>    0.169     0.141     0.169     0.155     0.197     0.169</pre>&#13;
<p class="indent">This provides output that’s easier to read at a glance. If you set <code>digits=0</code> (the default), output is rounded to the nearest integer.</p>&#13;
<p class="indent">Before the next exercise, it’s worth briefly remarking on the relationship between a proportion and a percentage. The two represent the same thing. The only difference is the scale; the <em>percentage</em> is merely the proportion multiplied by 100. The percentage of chicks on a soybean diet is therefore approximately 19.7 percent.</p>&#13;
<pre>R&gt; round(mean(chickwts$feed=="soybean")*100,1)<br/>[1] 19.7</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_273"/>Since proportions always lie in the interval [0,1], percentages always lie within [0,100].</p>&#13;
<p class="indent">Most statisticians use proportions over percentages because of the role proportions play in the direct representation of <em>probabilities</em> (discussed in <a href="ch15.xhtml#ch15">Chapter 15</a>). However, there are situations in which percentages are preferred, such as basic data summaries or in the definition of <em>percentiles</em>, which will be detailed in <a href="ch13.xhtml#ch13lev2sec118">Section 13.2.3</a>.</p>&#13;
<div class="ex">&#13;
<p class="ext"><a id="ch13exc2"/><strong>Exercise 13.2</strong></p>&#13;
<ol type="a">&#13;
<li><p class="noindents">Obtain, rounded to two decimal places, the proportion of seismic events in the <code>quakes</code> data frame that occurred at a depth of 300 km or deeper.</p></li>&#13;
<li><p class="noindents">Remaining with the <code>quakes</code> data set, calculate the mean and median magnitudes of the events that occurred at a depth of 300 km or deeper.</p></li>&#13;
<li><p class="noindents">Using the <code>chickwts</code> data set, write a <code>for</code> loop that gives you the mean weight of chicks for each feed type—the same as the results given by the <code>tapply</code> function in <a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a>. Display the results rounded to one decimal place and, when printing, ensure each mean is labeled with the appropriate feed type.</p></li>&#13;
</ol>&#13;
<p class="noindentz">Another ready-to-use data set (in the automatically loaded <code>datasets</code> package) is <code>InsectSprays</code>. It contains data on the number of insects found on various agricultural units, as well as the type of insect spray that was used on each unit. Ensure you can access the data frame at the prompt; then study the help file <code>?InsectSprays</code> to get an idea of R’s representation of the two variables.</p>&#13;
<ol type="a" start="4">&#13;
<li><p class="noindents">Identify the two variable types in <code>InsectSprays</code> (as per the definitions in <a href="ch13.xhtml#ch13lev2sec112">Section 13.1.1</a> and <a href="ch13.xhtml#ch13lev2sec113">Section 13.1.2</a>).</p></li>&#13;
<li><p class="noindents">Calculate the modes of the distribution of insect counts, regardless of spray type.</p></li>&#13;
<li><p class="noindents">Use <code>tapply</code> to report the total insect counts by each spray type.</p></li>&#13;
<li><p class="noindents">Using the same kind of <code>for</code> loop as in (c), compute the percentage of agricultural units in each spray type group that had at least five bugs on them. When printing to the screen, round the percentages to the nearest whole number.</p></li>&#13;
<li><p class="noindents">Obtain the same numeric results as in (g), with rounding, but use <code>tapply</code> and a disposable function.</p></li>&#13;
</ol>&#13;
</div>&#13;
<h4 class="h4" id="ch13lev2sec118"><span epub:type="pagebreak" id="page_274"/><strong><em>13.2.3 Quantiles, Percentiles, and the Five-Number Summary</em></strong></h4>&#13;
<p class="noindent">Let’s return, once more, to thinking about raw numeric observations. An understanding of how observations are <em>distributed</em> is an important statistical concept, and this will form a key feature of discussions in <a href="ch15.xhtml#ch15">Chapter 15</a> onward.</p>&#13;
<p class="indent">You can gain more insight into the distribution of a set of observations by examining quantiles. A <em>quantile</em> is a value computed from a collection of numeric measurements that indicates an observation’s rank when compared to all the other present observations. For example, the median (<a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a>) is itself a quantile—it gives you a value below which half of the measurements lie—it’s the 0.5th quantile. Alternatively, quantiles can be expressed as a <em>percentile</em>—this is identical but on a “percent scale” of 0 to 100. In other words, the <em>p</em>th quantile is equivalent to the 100 × <em>p</em>th percentile. The median, therefore, is the 50th percentile.</p>&#13;
<p class="indent">There are a number of different algorithms that can be used to compute quantiles and percentiles. They all work by sorting the observations from smallest to largest and using some form of weighted average to find the numeric value that corresponds to <em>p</em>, but results may vary slightly in other statistical software.</p>&#13;
<p class="indent">Obtaining quantiles and percentiles in R is done with the <code>quantile</code> function. Using the eight observations stored as the vector <code>xdata</code>, the 0.8th quantile (or 80th percentile) is confirmed as 3.6:</p>&#13;
<pre>R&gt; xdata &lt;- c(2,4.4,3,3,2,2.2,2,4)<br/>R&gt; quantile(xdata,prob=0.8)<br/>80%<br/>3.6</pre>&#13;
<p class="indent">As you can see, <code>quantile</code> takes the data vector of interest as its first argument, followed by a numeric value supplied to <code>prob</code>, giving the quantile of interest. In fact, <code>prob</code> can take a numeric vector of quantile values. This is convenient when multiple quantiles are desired.</p>&#13;
<pre>R&gt; quantile(xdata,prob=c(0,0.25,0.5,0.75,1))<br/>  0%  25%  50%  75% 100%<br/>2.00 2.00 2.60 3.25 4.40</pre>&#13;
<p class="indent">Here, you’ve used <code>quantile</code> to obtain what’s called the <em>five-number summary</em> of <code>xdata</code>, comprised of the 0th percentile (the minimum), the 25th percentile, the 50th percentile, the 75th percentile, and the 100th percentile (the maximum). The 0.25th quantile is referred to as the <em>first</em> or <em>lower quartile</em>, and the 0.75th quantile is referred to as the <em>third</em> or <em>upper quartile</em>. Also note that the 0.5th quantile of <code>xdata</code> is equivalent to the median (2.6, calculated in <a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a> using <code>median</code>). The median is the second quartile, with the maximum value being the fourth quartile.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_275"/>There are ways to obtain the five-number summary other than using <code>quantile</code>; when applied to a numeric vector, the <code>summary</code> function also provides these statistics, along with the mean, automatically.</p>&#13;
<pre>R&gt; summary(xdata)<br/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br/>  2.000   2.000   2.600   2.825   3.250   4.400</pre>&#13;
<p class="indent">To look at some examples using real data, let’s compute the lower and upper quartiles of the weights of the chicks in the <code>chickwts</code>.</p>&#13;
<pre>R&gt; quantile(chickwts$weight,prob=c(0.25,0.75))<br/>  25%   75%<br/>204.5 323.5</pre>&#13;
<p class="indent">This indicates that 25 percent of the weights lie at or below 204.5 grams and that 75 percent of the weights lie at or below 323.5 grams.</p>&#13;
<p class="indent">Let’s also compute the five-number summary (along with the mean) of the magnitude of the seismic events off the coast of Fiji that occurred at a depth of less than 400 km, using the <code>quakes</code> data frame.</p>&#13;
<pre>R&gt; summary(quakes$mag[quakes$depth&lt;400])<br/>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.<br/>   4.00    4.40    4.60    4.67    4.90    6.40</pre>&#13;
<p class="indent">This begins to highlight how useful quantiles are for interpreting the distribution of numeric measurements. From these results, you can see that most of the magnitudes of events at a depth of less than 400 km lie around 4.6, the median, and the first and third quartiles are just 4.4 and 4.9, respectively. But you can also see that the maximum value is much further away from the upper quartile than the minimum is from the lower quartile, suggesting a <em>skewed</em> distribution, one that stretches more positively (in other words, to the right) from its center than negatively (in other words, to the left). This notion is also supported by the fact that the mean is greater than the median—the mean is being “dragged upward” by the larger values.</p>&#13;
<p class="indent">You’ll explore this further in <a href="ch14.xhtml#ch14">Chapter 14</a> when you investigate data sets using basic statistical plots, and some of the associated terminology will be formalized in <a href="ch15.xhtml#ch15">Chapter 15</a>.</p>&#13;
<h4 class="h4" id="ch13lev2sec119"><strong><em>13.2.4 Spread: Variance, Standard Deviation, and the Interquartile Range</em></strong></h4>&#13;
<p class="noindent">The measures of centrality explored in <a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a> offer a good indication of where your numeric measurements are massed, but the mean, median, and mode do nothing to describe how <em>dispersed</em> your data are. For this, measures of <em>spread</em> are needed.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_276"/>In addition to your vector of eight hypothetical observations, given again here,</p>&#13;
<pre>R&gt; xdata &lt;- c(2,4.4,3,3,2,2.2,2,4)</pre>&#13;
<p class="noindent">you’ll also look at another eight observations stored as follows:</p>&#13;
<pre>R&gt; ydata &lt;- c(1,4.4,1,3,2,2.2,2,7)</pre>&#13;
<p class="indent">Although these are two different collections of numbers, note that they have an identical arithmetic mean.</p>&#13;
<pre>R&gt; mean(xdata)<br/>[1] 2.825<br/>R&gt; mean(ydata)<br/>[1] 2.825</pre>&#13;
<p class="indent">Now let’s plot these two data vectors side by side, each one on a horizontal line, by executing the following:</p>&#13;
<pre>R&gt; plot(xdata,type="n",xlab="",ylab="data vector",yaxt="n",bty="n")<br/>R&gt; abline(h=c(3,3.5),lty=2,col="gray")<br/>R&gt; abline(v=2.825,lwd=2,lty=3)<br/>R&gt; text(c(0.8,0.8),c(3,3.5),labels=c("x","y"))<br/>R&gt; points(jitter(c(xdata,ydata)),c(rep(3,length(xdata)),<br/>                                   rep(3.5,length(ydata))))</pre>&#13;
<p class="indent">You saw how to use these base R graphics functions in <a href="ch07.xhtml#ch07">Chapter 7</a>, though it should be explained that because some of the observations in <code>xdata</code> and in <code>ydata</code> occur more than once, you can randomly alter them slightly to prevent overplotting, which aids in the visual interpretation. This step is known as <em>jittering</em> and is achieved by passing the numeric vector of interest to the <code>jitter</code> function prior to plotting with <code>points</code>. Additionally, note that you can use <code>yaxt="n"</code> in any call to <code>plot</code> to suppress the <em>y</em>-axis; similarly, <code>bty="n"</code> removes the typical box that’s placed around a plot (you’ll focus more on this type of plot customization in <a href="ch23.xhtml#ch23">Chapter 23</a>).</p>&#13;
<p class="indent">The result, shown in <a href="ch13.xhtml#ch13fig3">Figure 13-3</a>, provides you with valuable information. Though the mean is the same for both <code>xdata</code> and <code>ydata</code>, you can easily see that the observations in <code>ydata</code> are more “spread out” around the measure of centrality than the observations in <code>xdata</code>. To quantify spread, you use values such as the variance, the standard deviation, and the interquartile range.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_277"/><img src="../images/f13-03.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch13fig3"/>Figure 13-3: Comparing two hypothetical data vectors that share an identical arithmetic mean (marked by the vertical dotted line) but have different magnitudes of spread. Identical observations are jittered slightly.</em></p>&#13;
<p class="indent">The sample <em>variance</em> measures the degree of the spread of numeric observations around their arithmetic mean. The variance is a particular representation of the <em>average squared distance</em> of each observation when compared to the mean. For a set of <em>n</em> numeric measurements labeled <em>x</em> = {<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, . . . , <em>x</em><sub>n</sub>}, the sample variance <img class="middle" src="../images/common-05.jpg" alt="image"/> is given by the following, where <em><span class="ent">x̄</span></em> is the sample mean described in <a href="ch13.xhtml#ch13eq1">Equation (13.1)</a>:</p>&#13;
<div class="imagec"><a id="ch13eq3"/><img src="../images/e13-3.jpg" alt="image"/></div>&#13;
<p class="indent">For example, if you take the eight illustrative observations 2, 4.4, 3, 3, 2, 2.2, 2, 4, their sample variance is as follows when rounded to three decimal places (some terms are hidden with ... for readability):</p>&#13;
<div class="imagec"><img src="../images/f0277-02.jpg" alt="image"/></div>&#13;
<p class="indent">The <em>standard deviation</em> is simply the square root of the variance. Since the variance is a representation of the average squared distance, the standard deviation provides a value interpretable with respect to the scale of the original observations. With the same notation for a sample of <em>n</em> observations, the sample standard deviation <em>s</em> is found by taking the square root of <a href="ch13.xhtml#ch13eq3">Equation (13.3)</a>.</p>&#13;
<div class="imagec"><a id="ch13eq4"/><img src="../images/e13-4.jpg" alt="image"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_278"/>For example, based on the sample variance calculated earlier, the standard deviation of the eight hypothetical observations is as follows (to three decimal places):</p>&#13;
<div class="imagec"><img src="../images/f0278-01.jpg" alt="image"/></div>&#13;
<p class="indent">Thus, a rough way to interpret this is that 0.953 represents the average distance of each observation from the mean.</p>&#13;
<p class="indent">Unlike the variance and standard deviation, the <em>interquartile range (IQR)</em> is not computed with respect to the sample mean. The IQR measures the width of the “middle 50 percent” of the data, that is, the range of values that lie within a 25 percent quartile on either side of the median. As such, the IQR is computed as the difference between the upper and lower quartiles of your data. Formally, where <em>Q<sub>x</sub></em> ( · ) denotes the quantile function (as defined in <a href="ch13.xhtml#ch13lev2sec118">Section 13.2.3</a>), the IQR is given as</p>&#13;
<div class="imagec"><a id="ch13eq5"/><img src="../images/e13-5.jpg" alt="image"/></div>&#13;
<p class="indent">The direct R commands for computing these measures of spread are <code>var</code> (variance), <code>sd</code> (standard deviation), and <code>IQR</code> (interquartile range).</p>&#13;
<pre>R&gt; var(xdata)<br/>[1] 0.9078571<br/>R&gt; sd(xdata)<br/>[1] 0.9528154<br/>R&gt; IQR(xdata)<br/>[1] 1.25</pre>&#13;
<p class="indent">You can confirm the relationship between the sample variance and standard deviation using the square root function <code>sqrt</code> on the result from <code>var</code>, and you can reproduce the IQR by calculating the difference between the third and first quartiles.</p>&#13;
<pre>R&gt; sqrt(var(xdata))<br/>[1] 0.9528154<br/>R&gt; as.numeric(quantile(xdata,0.75)-quantile(xdata,0.25))<br/>[1] 1.25</pre>&#13;
<p class="indent">Note that <code>as.numeric</code> (see <a href="ch06.xhtml#ch06lev2sec62">Section 6.2.4</a>) strips away the percentile annotations (that label the results by default) from the returned object of <code>quantile</code>.</p>&#13;
<p class="indent">Now, do the same with the <code>ydata</code> observations that had the same arithmetic mean as <code>xdata</code>. The calculations give you the following:</p>&#13;
<pre>R&gt; sd(ydata)<br/>[1] 2.012639<br/>R&gt; IQR(ydata)<br/>[1] 1.6</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_279"/><code>ydata</code> is on the same scale as <code>xdata</code>, so the results confirm what you can see in <a href="ch13.xhtml#ch13fig3">Figure 13-3</a>—that the observations in the former are more spread out than in the latter.</p>&#13;
<p class="indent">For two quick final examples, let’s return again to the <code>chickwts</code> and <code>quakes</code> data sets. In <a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a>, you saw that the mean weight of all the chicks is 261.3099 grams. You can now find that the standard deviation of the weights is as follows:</p>&#13;
<pre>R&gt; sd(chickwts$weight)<br/>[1] 78.0737</pre>&#13;
<p class="indent">Informally, this implies that the weight of each chick is, on average, around 78.1 grams away from the mean weight (technically, though, remember it is merely the square root of a function of the squared distances—see the following note).</p>&#13;
<p class="indent">In <a href="ch13.xhtml#ch13lev2sec118">Section 13.2.3</a>, you used <code>summary</code> to obtain the five-number summary of the magnitudes of some of the earthquakes in the <code>quakes</code> data set. Looking at the first and third quartiles in these earlier results (4.4 and 4.9, respectively), you can quickly determine that the IQR of this subset of the events is 0.5. This can be confirmed using <code>IQR</code>.</p>&#13;
<pre>R&gt; IQR(quakes$mag[quakes$depth&lt;400])<br/>[1] 0.5</pre>&#13;
<p class="indent">This gives you the width, in units of the Richter scale, of the middle 50 percent of the observations.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>The definition of the variance (and hence the standard deviation) here has referred exclusively to the “sample estimator,” the default in R, which uses the divisor of n</em> − <em>1 in the formula. This is the formula used when the observations at hand represent a sample of an assumed larger population. In these cases, use of the divisor n</em> − <em>1 is more accurate, providing what’s known as an</em> unbiased <em>estimate of the true population value. Thus, you aren’t exactly calculating the “average squared distance,” though it can loosely be thought of as such and does indeed approach this as the sample size n increases.</em></p>&#13;
</div>&#13;
<div class="ex">&#13;
<p class="ext"><a id="ch13exc3"/><strong>Exercise 13.3</strong></p>&#13;
<ol type="a">&#13;
<li><p class="noindents">Using the <code>chickwts</code> data frame, compute the 10th, 30th, and 90th percentiles of all the chick weights and then use <code>tapply</code> to determine which feed type is associated with the highest sample variance of weights.</p></li>&#13;
<li><p class="noindents"><span epub:type="pagebreak" id="page_280"/>Turn to the seismic event data in <code>quakes</code> and complete the following tasks:</p>&#13;
<ol type="i">&#13;
<li><p class="noindents">Find the IQR of the recorded depths.</p></li>&#13;
<li><p class="noindents">Find the five-number summary of all magnitudes of seismic events that occur at a depth of 400 km <em>or deeper</em>. Compare this to the summary values found in <a href="ch13.xhtml#ch13lev2sec118">Section 13.2.3</a> of those events occurring at less than 400 km and briefly comment on what you notice.</p></li>&#13;
<li><p class="noindents">Use your knowledge of <code>cut</code> (<a href="ch04.xhtml#ch04lev2sec48">Section 4.3.3</a>) to create a new factor vector called <code>depthcat</code> that identifies four evenly spaced categories of <code>quakes$depth</code> so that when you use <code>levels(depthcat)</code>, it gives the following:</p>&#13;
<pre>R&gt; levels(depthcat)<br/>[1] "[40,200)"  "[200,360)" "[360,520)" "[520,680]"</pre></li>&#13;
<li><p class="noindents">Find the sample mean and standard deviation of the magnitudes of the events associated with each category of depth according to <code>depthcat</code>.</p></li>&#13;
<li><p class="noindents">Use <code>tapply</code> to compute the 0.8th quantile of the magnitudes of the seismic events in <code>quakes</code>, split by <code>depthcat</code>.</p></li>&#13;
</ol></li>&#13;
</ol>&#13;
</div>&#13;
<h4 class="h4" id="ch13lev2sec120"><strong><em>13.2.5 Covariance and Correlation</em></strong></h4>&#13;
<p class="noindent">When analyzing data, it’s often useful to be able to investigate the <em>relationship</em> between two numeric variables to assess trends. For example, you might expect height and weight observations to have a noticeable positive relationship—taller people tend to weigh more. Conversely, you might imagine that handspan and length of hair would have less of an association. One of the simplest and most common ways such associations are quantified and compared is through the idea of correlation, for which you need the covariance.</p>&#13;
<p class="indent">The <em>covariance</em> expresses how much two numeric variables “change together” and the nature of that relationship, whether it is positive or negative. Suppose for <em>n</em> individuals you have a sample of observations for two variables, labeled <em>x</em> = {<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, . . . , <em>x</em><sub>n</sub>} and <em>y</em> = {<em>y</em><sub>1</sub>, <em>y</em><sub>2</sub>, . . . , <em>y</em><sub>n</sub>}, where <em>x<sub>i</sub></em> corresponds to <em>y<sub>i</sub></em> for <em>i</em> = 1, . . . , <em>n</em>. The sample covariance <em>r<sub>xy</sub></em> is computed with the following, where <span class="ent">x̄</span> and <img class="middle" src="../images/y2.jpg" alt="image"/> represent the respective sample means of both sets of observations:</p>&#13;
<div class="imagec"><a id="ch13eq6"/><img src="../images/e13-6.jpg" alt="image"/></div>&#13;
<p class="indent">When you get a positive result for <em>r</em><sub>xy</sub>, it shows that there is a positive linear relationship—as <em>x</em> increases, <em>y</em> increases. When you get a negative result, it shows a negative linear relationship—as <em>x</em> increases, <em>y</em> decreases, and vice versa. When <em>r<sub>xy</sub></em> = 0, this indicates that there is no linear relationship <span epub:type="pagebreak" id="page_281"/>between the values of <em>x</em> and <em>y</em>. It is useful to note that the order of the variables in the formula itself doesn’t matter; in other words, <em>r<sub>xy</sub></em> ≡ <em>r</em><sub>yx</sub>.</p>&#13;
<p class="indent">To demonstrate, let’s use the original eight illustrative observations, which I’ll denote here with <em>x</em> = {2,4.4,3,3,2,2.2,2,4}, and the additional eight observations denoted with <em>y</em> = {1,4.4,1,3,2,2.2,2,7}. Remember that both <em>x</em> and <em>y</em> have sample means of 2.825. The sample covariance of these two sets of observations is as follows (rounded to three decimal places):</p>&#13;
<div class="imagec"><img src="../images/f0281-01.jpg" alt="image"/></div>&#13;
<p class="indent">The figure is a positive number, so this suggests there is a positive relationship based on the observations in <em>x</em> and <em>y</em>.</p>&#13;
<p class="indent"><em>Correlation</em> allows you to interpret the covariance further by identifying both the direction and the strength of any association. There are different types of correlation coefficients, but the most common of these is <em>Pearson’s product-moment correlation coefficient</em>, the default implemented by R (this is the estimator I will use in this chapter). Pearson’s sample correlation coefficient <em>ρ</em><sub>xy</sub> is computed by dividing the sample covariance by the product of the standard deviation of each data set. Formally, where <em>r<sub>xy</sub></em> corresponds to <a href="ch13.xhtml#ch13eq6">Equation (13.6)</a> and <em>s<sub>x</sub></em> and <em>s<sub>y</sub></em> to <a href="ch13.xhtml#ch13eq4">Equation (13.4)</a>,</p>&#13;
<div class="imagec"><a id="ch13eq7"/><img src="../images/e13-7.jpg" alt="image"/></div>&#13;
<p class="noindent">which ensures that −1 ≤ <em>ρ</em><sub>xy</sub> ≤ 1.</p>&#13;
<p class="indent">When <em>ρ</em><sub>xy</sub> = −1, a perfect negative linear relationship exists. Any result less than zero shows a negative relationship, and the relationship gets weaker the nearer to zero the coefficient gets, until <em>ρ</em><sub>xy</sub> = 0, showing no relationship at all. As the coefficient increases above zero, a positive relationship is shown, until <em>ρ</em><sub>xy</sub> = 1, which is a perfect positive linear relationship.</p>&#13;
<p class="indent">If you take the standard deviations already computed for <em>x</em> and <em>y</em> in <a href="ch13.xhtml#ch13lev2sec119">Section 13.2.4</a> (<em>s</em><sub>x</sub> = 0.953 and <em>s<sub>y</sub></em> = 2.013 to three decimal places), you find the following to three decimal places:</p>&#13;
<div class="imagec"><img src="../images/f0281-02.jpg" alt="image"/></div>&#13;
<p class="indent"><em>ρ</em><sub>xy</sub> is positive just like <em>r</em><sub>xy</sub>; the value of 0.771 indicates a moderate-to-strong positive association between the observations in <em>x</em> and <em>y</em>. Again, <em>ρ</em><sub>xy</sub> ≡ <em>ρ</em><sub>yx</sub>.</p>&#13;
<p class="indent">The R commands <code>cov</code> and <code>cor</code> are used for the sample covariance and correlation; you need only to supply the two corresponding vectors of data.</p>&#13;
<pre>R&gt; xdata &lt;- c(2,4.4,3,3,2,2.2,2,4)<br/>R&gt; ydata &lt;- c(1,4.4,1,3,2,2.2,2,7)<br/>R&gt; cov(xdata,ydata)<br/>[1] 1.479286<br/>R&gt; cov(xdata,ydata)/(sd(xdata)*sd(ydata))<br/>[1] 0.7713962<br/>R&gt; cor(xdata,ydata)<br/>[1] 0.7713962</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_282"/>You can plot these bivariate observations as a coordinate-based plot (a <em>scatterplot</em>—see more examples in <a href="ch14.xhtml#ch14lev1sec47">Section 14.4</a>). Executing the following gives you <a href="ch13.xhtml#ch13fig4">Figure 13-4</a>:</p>&#13;
<pre>R&gt; plot(xdata,ydata,pch=13,cex=1.5)</pre>&#13;
<div class="image"><img src="../images/f13-04.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch13fig4"/>Figure 13-4: Plotting the</em> <code>xdata</code> <em>and</em> <code>ydata</code> <em>observations as bivariate data points to illustrate the interpretation of the correlation coefficient</em></p>&#13;
<p class="indent">As discussed earlier, the correlation coefficient estimates the nature of the <em>linear</em> relationship between two sets of observations, so if you look at the pattern formed by the points in <a href="ch13.xhtml#ch13fig4">Figure 13-4</a> and imagine drawing a perfectly straight line that best represents all the points, you can determine the strength of the linear association by how close those points are to your line. Points closer to a perfect straight line will have a value of <em>ρ</em><sub>xy</sub> closer to either −1 or 1. The direction is determined by how the line is sloped—an increasing trend, with the line sloping upward toward the right, indicates positive correlation; a negative trend would be shown by the line sloping downward toward the right. Considering this, you can see that the estimated correlation coefficient for the data plotted in <a href="ch13.xhtml#ch13fig4">Figure 13-4</a> makes sense according to the previous calculations. The points do appear to increase together as a rough straight line in terms of the values in <code>xdata</code> and <code>ydata</code>, but this linear association is by no means perfect. How you can compute the “ideal” or “best” straight line to fit such data is discussed in <a href="ch20.xhtml#ch20">Chapter 20</a>.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_283"/>To aid your understanding of the idea of correlation, <a href="ch13.xhtml#ch13fig5">Figure 13-5</a> displays different scatterplots, each showing 100 points. These observations have been randomly and artificially generated to follow preset “true” values of <em>ρ</em><sub>xy</sub>, labeled above each plot.</p>&#13;
<div class="image"><img src="../images/f13-05.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch13fig5"/>Figure 13-5: Artificial</em> x <em>and</em> y <em>observations, generated to illustrate a given value of the correlation coefficient</em></p>&#13;
<p class="indent">The first row of scatterplots shows negatively correlated data; the second shows positively correlated data. These match what you would expect to see—the direction of the line shows the negative or positive correlation of the trend, and the extremity of the coefficient corresponds to the closeness to a “perfect line.”</p>&#13;
<p class="indent">The third and final row shows data sets generated with a correlation coefficient set to zero, implying no linear relationship between the observations in <em>x</em> and <em>y</em>. The middle and rightmost plots are particularly important because they highlight the fact that Pearson’s correlation coefficient identifies only “straight-line” relationships; these last two plots clearly show some kind of trend or pattern, but this particular statistic cannot be used to detect such a trend.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_284"/>To wrap up this section, look again at the <code>quakes</code> data. Two of the variables are <code>mag</code> (the magnitude of each event) and <code>stations</code> (the number of stations that reported detection of the event). A plot of <code>stations</code> on the <em>y</em>-axis against <code>mag</code> on the <em>x</em>-axis can be produced with the following:</p>&#13;
<pre>R&gt; plot(quakes$mag,quakes$stations,xlab="Magnitude",ylab="No. of stations")</pre>&#13;
<p class="indent"><a href="ch13.xhtml#ch13fig6">Figure 13-6</a> shows this image.</p>&#13;
<div class="image"><img src="../images/f13-06.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch13fig6"/>Figure 13-6: Plotting the number of stations reporting the event (</em> y<em>) and the magnitude (</em> x<em>) of each event in the</em> <code>quakes</code> <em>data frame</em></p>&#13;
<p class="indent">You can see by the vertical patterning that the magnitudes appear to have been recorded to a certain specific level of precision (this is owed to the difficulty associated with measuring earthquake magnitudes exactly). Nevertheless, a positive relationship (more stations tend to detect events of higher magnitude) is clearly visible in the scatterplot, a feature that is confirmed by a positive covariance.</p>&#13;
<pre>R&gt; cov(quakes$mag,quakes$stations)<br/>[1] 7.508181</pre>&#13;
<p class="indent">As you might expect from examining the pattern, Pearson’s correlation coefficient confirms that the linear association is quite strong.</p>&#13;
<pre>R&gt; cor(quakes$mag,quakes$stations)<br/>[1] 0.8511824</pre>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>It is important to remember that</em> correlation does not imply causation<em>. When you detect a high correlative effect between two variables, this does not mean that one</em> causes <em>the other. Causation is difficult to prove in even the most controlled situations. Correlation merely allows you to measure</em> association.</p>&#13;
</div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_285"/>As mentioned earlier, there are other representations of correlation that can be used; <em>rank</em> coefficients, such as Spearman’s and Kendall’s correlation coefficients, differ from Pearson’s estimate in that they do not require the relationship to be linear. These are also available through the <code>cor</code> function by accessing the optional <code>method</code> argument (see <code>?cor</code> for details). Pearson’s correlation coefficient is the most commonly used, however, and is related to linear regression methods, which you’ll start to examine in <a href="ch20.xhtml#ch20">Chapter 20</a>.</p>&#13;
<h4 class="h4" id="ch13lev2sec121"><strong><em>13.2.6 Outliers</em></strong></h4>&#13;
<p class="noindent">An <em>outlier</em> is an observation that does not appear to “fit” with the rest of the data. It is a noticeably extreme value when compared with the bulk of the data, in other words, an anomaly. In some cases, you might suspect that such an extreme observation has not actually come from the same mechanism that generated the other observations, but there is no hard-and-fast numeric rule as to what constitutes an outlier. For example, consider the 10 hypothetical data points in <code>foo</code>.</p>&#13;
<pre>R&gt; foo &lt;- c(0.6,-0.6,0.1,-0.2,-1.0,0.4,0.3,-1.8,1.1,6.0)</pre>&#13;
<p class="indent">Using skills from <a href="ch07.xhtml#ch07">Chapter 7</a> (and from creating <a href="ch13.xhtml#ch13fig3">Figure 13-3</a>), you can plot <code>foo</code> on a line as follows.</p>&#13;
<pre>R&gt; plot(foo,rep(0,10),yaxt="n",ylab="",bty="n",cex=2,cex.axis=1.5,cex.lab=1.5)<br/>R&gt; abline(h=0,col="gray",lty=2)<br/>R&gt; arrows(5,0.5,5.9,0.1,lwd=2)<br/>R&gt; text(5,0.7,labels="outlier?",cex=3)</pre>&#13;
<p class="indent">The result is given on the left of <a href="ch13.xhtml#ch13fig7">Figure 13-7</a>.</p>&#13;
<div class="image"><img src="../images/f13-07.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch13fig7"/>Figure 13-7: Illustrating the definition of outliers for univariate (left) and bivariate (right) data. Should you include such values in your statistical analysis? The answer can be difficult to determine.</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_286"/>From this plot, you see that most of the observations are centered around zero, but one value is way out at 6. To give a bivariate example, I’ll use two further vectors, <code>bar</code> and <code>baz</code>, shown here:</p>&#13;
<pre>R&gt; bar &lt;- c(0.1,0.3,1.3,0.6,0.2,-1.7,0.8,0.9,-0.8,-1.0)<br/>R&gt; baz &lt;- c(-0.3,0.9,2.8,2.3,1.2,-4.1,-0.4,4.1,-2.3,-100.0)</pre>&#13;
<p class="indent">I’ll plot these data using the following code; the result is on the right of <a href="ch13.xhtml#ch13fig7">Figure 13-7</a>.</p>&#13;
<pre>R&gt; plot(bar,baz,axes=T,cex=2,cex.axis=1.5,cex.lab=1.5)<br/>R&gt; arrows(-0.5,-80,-0.94,-97,lwd=2)<br/>R&gt; text(-0.45,-74,labels="outlier?",cex=3)</pre>&#13;
<p class="indent">It’s important to identify outliers because of the potential impact they can have on any statistical calculations or model fitting. For this reason, many researchers will try to identify possible outliers before computing results by conducting an “exploratory” analysis of their data using basic summary statistics and data visualization tools (like those you’ll look at in <a href="ch14.xhtml#ch14">Chapter 14</a>).</p>&#13;
<p class="indent">Outliers can occur naturally, where the outlier is a “true” or accurate observation recorded from the population, or unnaturally, where something has “contaminated” that particular contribution to the sample, such as incorrectly inputting data. As such, it is common to omit any outliers occurring through unnatural sources prior to analysis, but in practice this is not always easy because the cause of an outlier can be difficult to determine. In some cases, researchers conduct their analysis both ways—presenting results including and excluding any perceived outliers.</p>&#13;
<p class="indent">With this in mind, if you return to the example shown on the left in <a href="ch13.xhtml#ch13fig7">Figure 13-7</a>, you can see that when you include all observations, you get the following:</p>&#13;
<pre>R&gt; mean(foo)<br/>[1] 0.49</pre>&#13;
<p class="indent">However, when the possible outlier of 6 (the 10th observation) is deleted, you get the following:</p>&#13;
<pre>R&gt; mean(foo[-10])<br/>[1] -0.1222222</pre>&#13;
<p class="indent">This highlights the impact a single extreme observation can have. Without any additional information about the sample, it would be difficult to say whether it’s sensible to exclude the outlier 6. The same kind of effect is noticeable if you compute, say, the correlation coefficient of <code>bar</code> with <code>baz</code>, shown on the right in <a href="ch13.xhtml#ch13fig7">Figure 13-7</a> (again, it’s the 10th observation that is the possible outlier).</p>&#13;
<pre><span epub:type="pagebreak" id="page_287"/>R&gt; cor(bar,baz)<br/>[1] 0.4566361<br/>R&gt; cor(bar[-10],baz[-10])<br/>[1] 0.8898639</pre>&#13;
<p class="indent">You see the correlation becomes much stronger without that outlier. Again, knowing whether to delete the outlier can be hard to correctly gauge in practice. At this stage, it’s important simply to be aware of the impact outliers can have on an analysis and to perform at least a cursory inspection of the raw data before beginning more rigorous statistical investigations.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>The extent of the effect that extreme observations have on your data analysis depends not only on their extremity but on the statistics you intend to calculate. The sample mean, for example, is highly sensitive to outliers and will differ greatly when including or excluding them, so any statistic that depends on the mean, like the variance or covariance, will be affected too. Quantiles and related statistics, such as the median or IQR, are relatively unaffected by outliers. In statistical parlance this property is referred to as</em> robustness.</p>&#13;
</div>&#13;
<div class="ex">&#13;
<p class="ext"><a id="ch13exc4"/><strong>Exercise 13.4</strong></p>&#13;
<ol type="a">&#13;
<li><p class="noindents">In <a href="ch07.xhtml#ch7exc1">Exercise 7.1</a> (b) on <a href="ch07.xhtml#page_139">page 139</a>, you plotted height against weight measurements. Compute the correlation coefficient based on the observed data of these two variables.</p></li>&#13;
<li><p class="noindents">Another of R’s built-in, ready-to-use data sets is <code>mtcars</code>, containing a number of descriptive details on performance aspects of 32 automobiles.</p>&#13;
<ol type="i">&#13;
<li><p class="noindents">Ensure you can access this data frame by entering <code>mtcars</code> at the prompt. Then inspect its help file to get an idea of the types of data present.</p></li>&#13;
<li><p class="noindents">Two of the variables describe a vehicle’s horsepower and shortest time taken to travel a quarter-mile distance. Using base R graphics, plot these two data vectors with horsepower on the <em>x</em>-axis and compute the correlation coefficient.</p></li>&#13;
<li><p class="noindents">Identify the variable in <code>mtcars</code> that corresponds to transmission type. Use your knowledge of factors in R to create a new factor from this variable called <code>tranfac</code>, where manual cars should be labeled <code>"manual"</code> and automatic cars <code>"auto"</code>.</p></li>&#13;
<li><p class="noindents">Now, use <code>qplot</code> from <code>ggplot2</code> in conjunction with <code>tranfac</code> to produce the same scatterplot as in (ii) so that you’re able to visually differentiate between manual and automatic cars.</p></li>&#13;
<li><p class="noindents"><span epub:type="pagebreak" id="page_288"/>Finally, compute separate correlation coefficients for horsepower and quarter-mile time based on the transmission of the vehicles and, comparing these estimates with the overall value from (ii), briefly comment on what you note.</p></li>&#13;
</ol></li>&#13;
<li><p class="noindents">Return to <code>chickwts</code> to complete the following tasks:</p>&#13;
<ol type="i">&#13;
<li><p class="noindents">Produce a plot like the left panel of <a href="ch13.xhtml#ch13fig7">Figure 13-7</a>, based on the weights of chicks on the sunflower diet only. Note that one of the sunflower-fed chicks has a far lower weight than the others.</p></li>&#13;
<li><p class="noindents">Compute the standard deviation and IQR of the weights of the sunflower-fed chicks.</p></li>&#13;
<li><p class="noindents">Now, suppose you’re told that the lowest weight of the sunflower-fed chicks was caused by a certain illness, irrelevant to your research. Delete this observation and recalculate the standard deviation and IQR of the remaining sunflower chicks. Briefly comment on the difference in calculated values.</p></li>&#13;
</ol></li>&#13;
</ol>&#13;
</div>&#13;
<h5 class="h5" id="ch13lev3sec37"><strong>Important Code in This Chapter</strong></h5>&#13;
<table class="topbot">&#13;
<thead>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table_th"><p class="table"><strong>Function/operator</strong></p></td>&#13;
<td style="vertical-align: top;" class="table_th"><p class="table"><strong>Brief description</strong></p></td>&#13;
<td style="vertical-align: top;" class="table_th"><p class="table"><strong>First occurrence</strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>mean</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Arithmetic mean</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a>, <a href="ch13.xhtml#page_268">p. 268</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>median</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Median</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a>, <a href="ch13.xhtml#page_268">p. 268</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>table</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Tabulate frequencies</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a>, <a href="ch13.xhtml#page_268">p. 268</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>min, max, range</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Minimum and maximum</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a>, <a href="ch13.xhtml#page_268">p. 268</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>round</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Round numeric values</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec117">Section 13.2.2</a>, <a href="ch13.xhtml#page_272">p. 272</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>quantile</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Quantiles/percentiles</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec118">Section 13.2.3</a>, <a href="ch13.xhtml#page_274">p. 274</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>summary</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Five-number summary</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec118">Section 13.2.3</a>, <a href="ch13.xhtml#page_275">p. 275</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>jitter</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Jitter points in plotting</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec119">Section 13.2.4</a>, <a href="ch13.xhtml#page_276">p. 276</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>var, sd</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Variance, standard deviation</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec119">Section 13.2.4</a>, <a href="ch13.xhtml#page_278">p. 278</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>IQR</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Interquartile range</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec119">Section 13.2.4</a>, <a href="ch13.xhtml#page_278">p. 278</a></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><code>cov, cor</code></p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table">Covariance, correlation</p></td>&#13;
<td style="vertical-align: top;" class="table"><p class="table"><a href="ch13.xhtml#ch13lev2sec120">Section 13.2.5</a>, <a href="ch13.xhtml#page_281">p. 281</a></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</body></html>