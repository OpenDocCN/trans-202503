- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: 'Shawshank Redemption: Breaking Out'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 《肖申克的救赎》：越狱
- en: '![](image_fi/book_art/chapterart.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](image_fi/book_art/chapterart.png)'
- en: Armed with this new understanding of Kubernetes, we head back to our improvised
    remote shell on the survey application to gather information, escalate privileges,
    and hopefully find our way to interesting data about user targeting.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有了对 Kubernetes 的全新理解后，我们回到了调查应用程序中的临时远程 shell，收集信息、提升权限，并希望能够找到有关用户定向的有趣数据。
- en: 'We resume our earlier shell access on the surveyapp container and take a look
    at the environment variables:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们恢复了之前在 surveyapp 容器中的 shell 访问，并查看了环境变量：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'With our new knowledge, these environment variables take on a new meaning:
    `KUBERNETES_PORT_443_TCP` must refer to the cluster IP hiding the API server,
    the famous Kube orchestrator. The documentation states that the API follows the
    OpenAPI standard, so we can target the default */api* route using the infamous
    `curl` utility. The `-L` switch in `curl` follows HTTP redirections, while the
    `-k` switch ignores SSL certificate warnings. We give it a go in [Listing 8-1](#listing8-1).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我们的新知识，这些环境变量变得意义重大：`KUBERNETES_PORT_443_TCP` 必须指向隐藏 API 服务器的集群 IP，这个著名的 Kube
    协调器。文档指出 API 遵循 OpenAPI 标准，因此我们可以使用臭名昭著的 `curl` 工具，访问默认的 */api* 路由。`curl` 中的 `-L`
    选项会跟随 HTTP 重定向，而 `-k` 选项则忽略 SSL 证书警告。我们在[清单 8-1](#listing8-1)中尝试了一下。
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Listing 8-1: Attempting to access the default */api* route on the API server'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 8-1：尝试访问 API 服务器上的默认 */api* 路由
- en: 'Ah, we’re locked out. The response we get is all but surprising. Starting from
    version 1.8, Kubernetes released a stable version of *role-based access control*
    *(RBAC**)*, a security model that locks access to the API server to unauthorized
    users. Even the “insecure” API listening on port 8080 is restricted to the localhost
    address:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 啊，我们被锁定了。我们得到的响应并不令人惊讶。从 1.8 版本开始，Kubernetes 发布了稳定版的 *基于角色的访问控制*（*RBAC*），这是一种安全模型，可以限制未经授权的用户访问
    API 服务器。即使是监听在 8080 端口上的“不安全” API 也被限制为只允许本地地址访问：
- en: '[PRE2]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To see if we can get around this, we’ll take a closer look at the Kubernetes
    RBAC system.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看看我们是否能够绕过这一点，我们将更仔细地研究 Kubernetes 的 RBAC 系统。
- en: RBAC in Kube
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kube 中的 RBAC
- en: Kubernetes RBAC follows a pretty standard implementation. Admins can create
    user accounts for human operators or service accounts that can be assigned to
    pods. Each user or service account is further bound to a role holding particular
    privileges—`get`, `list`, `change`, and so on—over resources such as pods, nodes,
    and secrets. The association between a subject (user or service account) and a
    role is called a *binding*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes RBAC 遵循了一个相当标准的实现。管理员可以为人工操作员创建用户账户，或为 pod 分配服务账户。每个用户或服务账户都可以绑定到一个持有特定权限的角色——如
    `get`、`list`、`change` 等——该角色控制对 pod、节点和机密等资源的访问。主体（用户或服务账户）与角色之间的关联被称为 *绑定*。
- en: Just like any other Kube resource, service accounts, roles, and their bindings
    are defined in manifest files stored in the etcd database. A service account definition
    looks something like [Listing 8-2](#listing8-2).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 就像其他任何 Kube 资源一样，服务账户、角色及其绑定也定义在存储在 etcd 数据库中的清单文件中。服务账户的定义类似于[清单 8-2](#listing8-2)。
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Listing 8-2: The `ClusterRoleBinding` manifest file'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 8-2：`ClusterRoleBinding` 清单文件
- en: 'An admin who wants to assign a service account to a regular pod can add the
    single property `serviceAccountName`, like so:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一个管理员如果想要将服务账户分配给普通的 pod，可以添加一个名为 `serviceAccountName` 的属性，像这样：
- en: '[PRE4]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Earlier, we hit the API server without providing any kind of authentication—so
    we naturally got assigned the default `system:anonymous` user, which lacks any
    privileges. This prevented us from accessing the API server. Common sense would
    dictate, then, that a container lacking the `serviceAccountName` attribute would
    also inherit the same anonymous account status.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们在没有提供任何身份验证的情况下访问了 API 服务器——因此我们自然被分配了默认的 `system:anonymous` 用户，该用户没有任何权限。这使得我们无法访问
    API 服务器。常识告诉我们，一个没有 `serviceAccountName` 属性的容器，也会继承相同的匿名账户状态。
- en: That's a sensible assumption, but Kube operates differently. Every pod without
    a service account is automatically assigned the `system:serviceaccount:default:default`
    account. Notice the subtle difference between “anonymous” and “default.” Default
    seems less dangerous than anonymous. It carries more trust. It even has an authentication
    token mounted inside the container!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个合理的假设，但 Kube 的操作方式不同。每个没有服务账户的 pod 会自动分配 `system:serviceaccount:default:default`
    账户。注意“匿名”和“默认”之间的微妙区别。默认看起来比匿名更不危险，它更值得信任，甚至在容器内部挂载了认证令牌！
- en: 'We search for the service account mounted by default by the container:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们搜索容器默认挂载的服务帐户：
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The account token is actually a signed JavaScript Object Notation (JSON) string—also
    known as a *JSON Web Token* (*JWT*)—holding information identifying the service
    account. We can base64-decode a portion of the JWT string to confirm the identity
    of the default service account and get a bit of information:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该帐户令牌实际上是一个签名的JavaScript对象表示法（JSON）字符串——也称为*JSON Web Token*（*JWT*）——包含识别服务帐户的信息。我们可以对JWT字符串的部分进行base64解码，以确认默认服务帐户的身份并获取一些信息：
- en: '[PRE6]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'A JWT has several regular fields, also called *registered claims*: the issuer
    (`iss`), which in this case is the Kubernetes service account controller; the
    subject (`sub`), which is the account’s name; and the namespace (more on this
    in a moment), which in this case is `prod`. Obviously, we cannot alter this information
    to impersonate another account without invalidating the signature appended to
    this JSON file.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: JWT有几个常规字段，也称为*注册声明*：发行者（`iss`），在此情况下是Kubernetes服务帐户控制器；主题（`sub`），即帐户的名称；以及命名空间（稍后会详细说明），在此情况下是`prod`。显然，我们无法更改这些信息以冒充另一个帐户，否则会使附加到此JSON文件的签名无效。
- en: The *namespace* is a logical partition that separates groups of Kube resources,
    such as pods, service accounts, secrets, and so on, generally set by the admin.
    It’s a soft barrier that allows more granular RBAC permissions; for example, a
    role with the “list all pods” permission would be limited to listing pods belonging
    to its namespace. The default service account is also namespace-dependent. The
    canonical name of the account we just retrieved is `system:serviceaccount:prod:default`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*命名空间*是将Kube资源（如Pods、服务帐户、秘密等）分组的逻辑分区，通常由管理员设置。它是一个软性隔离，允许更细粒度的RBAC权限；例如，具有“列出所有Pods”权限的角色将仅限于列出属于其命名空间的Pods。默认服务帐户也依赖于命名空间。我们刚刚检索到的帐户的标准名称是`system:serviceaccount:prod:default`。'
- en: 'This token gives us a second opportunity to query the API server. We load the
    file’s content into a `TOKEN` variable and retry our first HTTP request from [Listing
    8-1](#listing8-1), sending the `TOKEN` variable as an `Authorization` header:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 该令牌为我们提供了第二次查询API服务器的机会。我们将文件内容加载到`TOKEN`变量中，并重试我们在[清单8-1](#listing8-1)中的第一个HTTP请求，将`TOKEN`变量作为`Authorization`头发送：
- en: '[PRE7]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Ho! It seems that the default service account indeed has more privileges than
    the anonymous account. We’ve managed to grab a valid identity inside the cluster.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 哦！看起来默认的服务帐户确实比匿名帐户拥有更多权限。我们成功地在集群内部获取了一个有效的身份。
- en: Recon 2.0
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 侦查 2.0
- en: Time for some reconnaissance. We download the API specification available on
    the *https://10.100.0.1/openapi/v2* endpoint and explore our options.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进行一些侦查。我们下载位于*https://10.100.0.1/openapi/v2*端点的API规范并探索我们的选项。
- en: 'We start by fetching the cluster’s */version* endpoint. If the cluster is old
    enough, there may be the possibility to leverage a public exploit to elevate privileges:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从获取集群的*/version*端点开始。如果集群足够老，可能有机会利用公共漏洞提升权限：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: MXR Ads is running Kubernetes 1.14 supported by Elastic Kubernetes Service (EKS),
    AWS’s managed version of Kubernetes. In this setup, AWS hosts the API server,
    etcd, and other controllers on their own pool of master nodes, also called the
    *controller plane*. The customer (MXR Ads, in this case) only hosts the worker
    nodes (data plane).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: MXR Ads正在运行由Elastic Kubernetes Service（EKS）支持的Kubernetes 1.14，这是AWS托管版的Kubernetes。在这种设置中，AWS在他们自己的主节点池中托管API服务器、etcd和其他控制器，这些节点也被称为*控制平面*。客户（此处为MXR
    Ads）只托管工作节点（数据平面）。
- en: This is important information because AWS’s version of Kube allows a stronger
    binding between IAM roles and service accounts than the self-hosted version. If
    we pwn the right pod and grab the token, we not only can attack the Kube cluster
    but also AWS resources!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是重要信息，因为AWS版本的Kube允许IAM角色与服务帐户之间建立比自托管版本更强的绑定。如果我们攻破正确的Pod并获取令牌，我们不仅可以攻击Kube集群，还可以攻击AWS资源！
- en: We continue our exploration by trying several API endpoints from the OpenAPI
    documentation we retrieved. We try *api/v1/namespaces/default/secrets/*, *api/v1/namespaces/default/serviceaccounts*,
    and a bunch of other endpoints that correspond to Kube resources, but we repeatedly
    get shut down with a 401 error message. If we continue like this, the error rate
    will draw unnecessary attention. Luckily, there is a Kube API called */apis/authorization.k8s.io/v1/selfsubjectaccessreview*
    that tells us right away if we can perform an action on a given object.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续探索，通过尝试从我们获取的OpenAPI文档中使用几个API端点。我们尝试了*api/v1/namespaces/default/secrets/*，*api/v1/namespaces/default/serviceaccounts*，以及一系列其他与Kube资源对应的端点，但我们反复收到401错误消息。如果我们继续这样下去，错误率将引起不必要的关注。幸运的是，有一个Kube
    API叫做*/apis/authorization.k8s.io/v1/selfsubjectaccessreview*，它可以立即告诉我们是否能够对给定对象执行操作。
- en: 'It’s a hassle to call it manually through a `curl` query, as that would require
    a long and ugly payload in JSON, so we download the Kubectl program through our
    reverse shell. This time we don’t need to set up a config file, because Kubectl
    autodiscovers environment variables injected by the cluster, loads the current
    token from the mounted directory, and is 100 percent operational right away. Here
    we download the Kubectl binary, make it executable, and retrieve the cluster version
    once more:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 手动通过`curl`查询调用它很麻烦，因为这需要一个长而丑陋的JSON负载，所以我们通过反向Shell下载Kubectl程序。这次我们不需要设置配置文件，因为Kubectl会自动发现由集群注入的环境变量，从挂载的目录加载当前令牌，并立即100%正常运行。在这里，我们下载Kubectl二进制文件，使其可执行，并再次获取集群版本：
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Perfect! Everything is working fine. Now we repeatedly call the `auth can-i`
    command on the most common instructions—`get pods`, `get services`, `get roles`,
    `get secrets`, and so on—to fully explore all the privileges assigned to this
    default token we are operating with:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 完美！一切正常运行。现在我们反复执行`auth can-i`命令，针对最常见的指令——`get pods`、`get services`、`get roles`、`get
    secrets`等——全面探索我们正在操作的默认令牌所分配的所有权限：
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We quickly come to the conclusion that the only permission we currently have
    is to list pods in the cluster. But when we explicitly call the `get pods` command,
    we get the following error:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快得出结论，目前我们唯一拥有的权限是列出集群中的Pods。但当我们明确执行`get pods`命令时，出现了以下错误：
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: What if we try targeting the `prod` namespace—the same one hosting our service
    account?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试针对`prod`命名空间——也就是托管我们服务账户的命名空间——进行操作，会怎么样呢？
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Not bad! We get a list of hundreds and hundreds of pods running in the `prod`
    namespace.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 不错！我们获得了在`prod`命名空间中运行的数百个Pods的列表。
- en: 'Since all pods lacking an identity run with the same default service account,
    if one person grants extra privileges to this default account, all the other pods
    running with the same identity will automatically inherit these same privileges.
    All it takes is for someone to execute an unwitting `kubectl apply -f` `<url>`
    that grabs an ill-conceived resource definition from an obscure GitHub repo and
    hastily apply it to the cluster. It is sometimes said that this Kubectl installation
    command is the new `curl` `<url>` `| sh`. That’s the hidden cost of complexity:
    people can blindly pull and apply manifest files from GitHub without inspecting
    or even understanding the implications of the very instructions they execute,
    sometimes even granting extra privileges to the default service account. This
    is probably what occurred in this case, since the default account has no built-in
    set of privileges.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有缺乏身份的Pods都使用相同的默认服务账户运行，如果某人授予此默认账户额外的权限，则所有与相同身份运行的其他Pods都会自动继承这些权限。只需要有人执行一个不经意的`kubectl
    apply -f` `<url>`，从一个不显眼的GitHub仓库获取一个设计不良的资源定义，并匆忙将其应用到集群中。人们有时说，这个Kubectl安装命令是新的`curl`
    `<url>` `| sh`。这就是复杂性的隐藏代价：人们可以盲目地从GitHub拉取并应用清单文件，而不检查或甚至理解他们所执行的指令的影响，有时还会授予默认服务账户额外的权限。这很可能就是本案例中发生的情况，因为默认账户没有内建的权限集。
- en: But that’s just the tip of the iceberg. With the right flags, we can even pull
    the entire manifest of each pod, giving us an absolute plethora of information,
    as shown in [Listing 8-3](#listing8-3).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 但这仅仅是冰山一角。使用正确的标志，我们甚至可以提取每个Pod的完整清单，提供大量信息，如[列表8-3](#listing8-3)所示。
- en: '[PRE13]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Listing 8-3: Downloading the pod manifest file'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8-3：下载Pod清单文件
- en: And that truncated output, my friends, was just barely one pod! We only have
    the permission to get pod information, but that fortunately means accessing the
    pod manifest files, which include the nodes the pods are running on, the names
    of secrets, service accounts, mounted volumes, and much more. That’s almost full
    reconnaissance at the namespace level with one tiny permission.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 而且那个截断的输出，朋友们，仅仅是一个pod！我们只有获取pod信息的权限，但幸运的是，这意味着我们可以访问pod清单文件，其中包含pod运行的节点、机密名称、服务账户、挂载的卷等等。这几乎是在命名空间级别上进行的完全侦察，只需要一个小小的权限。
- en: 'The output, though, is horribly unexploitable. Manually digging through YAML
    files is a form of punishment that should only be bestowed on your archenemy.
    We can format the result from [Listing 8-3](#listing8-3) using Kubectl’s powerful
    custom output filters:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，输出是极其难以利用的。手动挖掘YAML文件是一种惩罚，应该只留给你的死敌。我们可以使用Kubectl强大的自定义输出过滤器来格式化[清单 8-3](#listing8-3)的结果：
- en: '[PRE14]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This rather explicit command only displays the `spec.nodeName` and `metadata.name`
    fields of the pods’ manifests. Let’s get some additional data, like secrets, service
    accounts, pod IPs, and so on. As you can see in [Listing 8-4](#listing8-4), the
    filter grows thicker to read, but it essentially walks through arrays and maps
    in YAML to fetch the relevant information.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这个相当明确的命令只显示pods清单中的`spec.nodeName`和`metadata.name`字段。让我们获取一些额外的数据，比如机密、服务账户、pod
    IP等。如[清单 8-4](#listing8-4)所示，过滤器变得更厚了，但它基本上是遍历YAML中的数组和映射，以提取相关信息。
- en: '[PRE15]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Listing 8-4: Full recon at the namespace level: node and pod names, pod IPs,
    service accounts, and secrets'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 8-4：命名空间级别的完全侦察：节点和pod名称、pod IP、服务账户和机密
- en: I’ve truncated the output to fit on the page, so I’ll describe it here. The
    first two columns contain the names of the node and the pod, which help us deduce
    the nature of the application running inside. The third column is the pod’s IP,
    which gets us straight to the application, thanks to Kube’s flat network design.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经截断了输出以适应页面，因此在这里描述一下。前两列包含节点和pod的名称，帮助我们推测运行在里面的应用性质。第三列是pod的IP，感谢Kube的扁平网络设计，这直接将我们带到应用。
- en: The fourth column lists the service account attached to each pod. Any value
    other than `default` means that the pod is likely running with additional privileges.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 第四列列出了附加到每个pod的服务账户。任何非`default`的值意味着该pod可能以额外的权限运行。
- en: The last two columns list the secrets loaded by the pod, either via environment
    variables or through a file mounted on disk. Secrets can be database passwords,
    service account tokens like the one we used to perform this command, and so on.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两列列出了pod加载的机密，可能是通过环境变量或通过磁盘上挂载的文件加载的。机密可以是数据库密码、我们用来执行此命令的服务账户令牌等。
- en: What a great time to be a hacker! Remember when reconnaissance entailed scanning
    the /16 network and waiting four hours to get a partially similar output? Now
    it’s barely one command away. Of course, had the default service account lacked
    the “get pods” privilege, we would have had to resort to a blind network scan
    of our container’s IP range. AWS is very keen on this kind of unusual network
    traffic, so be careful when tuning your Nmap to stay under the radar.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 做黑客真是个好时光！还记得之前侦察需要扫描/16网络，等待四小时才能得到部分相似的输出吗？现在只需要一个命令。当然，如果默认服务账户没有“获取pod”权限，我们就得依赖盲目的网络扫描，扫描我们的容器IP范围。AWS非常关注这种异常的网络流量，所以在调整Nmap时要小心，避免暴露在雷达下。
- en: 'The pod names we retrieved in [Listing 8-4](#listing8-4) are full of advertising
    and technical keywords such as SSP, api, kakfa, and so forth. It’s safe to assume
    that MXR Ads runs all its applications involved in the ad delivery process on
    Kubernetes. This must allow them to scale their applications up and down according
    to traffic. We continue exploring other pods and come across some containers that
    literally load AWS credentials. Oh, this is going to hurt:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[清单 8-4](#listing8-4)中检索到的pod名称充满了广告和技术关键词，例如SSP、api、kakfa等。可以放心假设，MXR Ads在Kubernetes上运行了所有涉及广告投放过程的应用。这一定使他们能够根据流量上下扩展应用。我们继续探索其他pods，并发现一些容器实际加载了AWS凭证。哦，这将会带来麻烦：
- en: '[PRE16]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We also spot a couple of datastores, like Redis and Elasticsearch. This is going
    to be interesting.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还发现了一些数据存储，如Redis和Elasticsearch。这将会很有趣。
- en: Breaking Into Datastores
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 破入数据存储
- en: 'Our most crucial advantage right now is the fact that we managed to cross the
    firewall border. We are inside the cluster, within the so-called *trusted zone*.
    DevOps admins still operate under the false pretense that there is such a thing
    as a trusted network, even when the damn thing belongs to a cloud provider. John
    Lambert’s piece on the defender’s mindset ([https://github.com/JohnLaTwC/Shared](https://github.com/JohnLaTwC/Shared))
    is still on point: “Defenders think in lists. Attackers think in graphs. As long
    as this is true, attackers win.”'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们最重要的优势是我们成功穿越了防火墙边界。我们已进入集群，处于所谓的*受信区*。DevOps 管理员仍然抱有错误的假设，认为存在受信网络，即便这个网络属于云服务提供商。John
    Lambert 关于防御者心态的文章（[https://github.com/JohnLaTwC/Shared](https://github.com/JohnLaTwC/Shared)）依然准确：“防御者以列表为思维，攻击者以图形为思维。只要这个事实存在，攻击者就赢了。”
- en: 'Redis is a key-value memory database mostly used for caching purposes, and
    Elasticsearch is a document-based database geared toward text search queries.
    We gather from this pod’s description that Elasticsearch is used for storing audit
    logs of some, and maybe all, applications:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Redis 是一个主要用于缓存的键值内存数据库，而 Elasticsearch 是一个面向文本搜索查询的文档数据库。从这个 pod 的描述中，我们可以得知
    Elasticsearch 用于存储某些（或可能是所有）应用的审计日志：
- en: '[PRE17]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Authentication and encryption are the first measures dropped due to the trusted
    network nonsense. I have yet to stumble upon a Redis database in an internal network
    that requires authentication. The same goes for Elasticsearch and other famous
    nonrelational databases that jokingly ask admins to run the application in a “secure”
    environment, whatever that means.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于受信网络的荒谬性，认证和加密是最先被放弃的措施。我至今还没遇到过需要认证的内网 Redis 数据库。Elasticsearch 和其他著名的非关系型数据库也是如此，它们开玩笑地要求管理员在“安全”的环境中运行应用程序，不知道那意味着什么。
- en: I understand. Security is supposedly not the job of the admin; they’d rather
    focus on performance, availability, and consistency of data. But this mindset
    is not only flawed, it’s reckless. Security is the foremost requirement of any
    data-driven technology. Data holds information. Information equals power. This
    has been true ever since humans learned to gossip. Admins ignoring security is
    like a nuclear plant stating that its only job is to split uranium isotopes. Safety
    measures? “No, we don’t do that. We run the reactor inside a secure building.”
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我理解。安全性显然不是管理员的工作；他们更愿意关注性能、可用性和数据一致性。但这种思维方式不仅是有缺陷的，而且是鲁莽的。安全是任何数据驱动技术的首要要求。数据承载信息，信息等同于权力。自从人类学会八卦以来，这一点就一直是对的。管理员忽视安全，就像核电厂声称它的唯一工作是分裂铀同位素。安全措施？“不，我们不做这些。我们把反应堆放在一个安全的建筑里运行。”
- en: We choose to focus first on the Elasticsearch pods, since audit logs always
    prove to be a valuable source of intelligence. They’ll document things like which
    service is communicating with which database, what URL endpoints are active, and
    what database queries look like. We can even find passwords in environment variables
    neglectfully dumped into debug stack traces.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择首先关注 Elasticsearch 的 pods，因为审计日志总是一个有价值的情报来源。它们会记录诸如哪个服务与哪个数据库通信、哪些 URL
    端点是活动的、数据库查询是什么样的。我们甚至能在不小心泄露到调试堆栈跟踪中的环境变量里找到密码。
- en: We go back to Elasticsearch’s pod description, extract the pod’s IP (10.20.86.24)
    and port (9200), and prepare to query the service. Elasticsearch is shipped with
    zero authentication by default, so thanks to the “trusted environment” fairytale,
    we have full access to the data stored in it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到 Elasticsearch 的 pod 描述，提取该 pod 的 IP 地址（10.20.86.24）和端口（9200），并准备查询该服务。默认情况下，Elasticsearch
    没有启用认证，因此多亏了“受信环境”的神话，我们可以完全访问其中存储的数据。
- en: 'Elasticsearch organizes its data into *indexes*,which are just collections
    of documents. Think of an index as the equivalent of a database in a traditional
    relational database system like MySQL. Here we pull a list of the indices defined
    in the cluster:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch 将数据组织成*索引*，这些索引实际上是文档的集合。可以将索引视为传统关系型数据库系统（如 MySQL）中的数据库。在这里，我们拉取集群中定义的索引列表：
- en: '[PRE18]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We see there’s 154GB of audit log data ready to be explored. We pull the last
    couple of documents from the log index:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到有 154GB 的审计日志数据准备好进行探索。我们从日志索引中拉取最后几条文档：
- en: '[PRE19]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `message` field of each of the four elements returned by Elasticsearch contains
    the raw log message stored. We dig up what appears to be an HTTP request to the
    [api/dashboard/campaign/1395412512](http://api/dashboard/campaign/1395412512)
    URL 2. We also catch a reference to the dashboard application we spotted way back
    in our external reconnaissance phase in Chapter 4 1. The URL in the audit log
    suggests that campaign data loaded by the dashboard app is likely retrieved from
    some internal endpoint named `api-core` (see the `Host` header) 2.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch 返回的四个元素中的 `message` 字段包含存储的原始日志信息。我们挖掘出看似是对 [api/dashboard/campaign/1395412512](http://api/dashboard/campaign/1395412512)
    URL 2 的 HTTP 请求。我们还发现了在第四章外部侦察阶段曾注意到的关于仪表盘应用的引用 1。审计日志中的 URL 暗示，由仪表盘应用加载的活动数据可能是通过名为
    `api-core` 的内部端点检索的（参见 `Host` 头）2。
- en: 'Interestingly the HTTP message we retrieved carries an authorization token,
    probably to identify the user requesting the data. We can zero in on all the tokens
    stored in the log index by applying the proper search filter in Elasticsearch:
    `message:Authorization`. This should allow us to gather enough tokens to impersonate
    all currently active users on the dashboard application:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们检索到的 HTTP 消息携带了一个授权令牌，可能是用来识别请求数据的用户。我们可以通过在 Elasticsearch 中应用正确的搜索过滤器
    `message:Authorization` 来集中查看所有存储的令牌。这应该能帮助我们收集足够的令牌，伪装成仪表盘应用上所有当前活跃的用户：
- en: '[PRE20]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Good, we have over a dozen tokens used in the last 12 hours to access the dashboard
    app and, by extension, the api-core pods. Hopefully some of them will still be
    valid and can be used for a replay attack.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们有十多个在过去 12 小时内用于访问仪表盘应用及其扩展的 api-core Pod 的令牌。希望其中一些令牌仍然有效，并可以用于重放攻击。
- en: 'We can reach the pods behind the `api-core` service name thanks to Kube’s automatic
    DNS resolution. Alternatively, we can always just pull one of the pods’ IP address,
    like so:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 Kube 的自动 DNS 解析到达 `api-core` 服务名称后面的 Pod。或者，我们也可以随时直接提取其中一个 Pod 的 IP
    地址，方法如下：
- en: '[PRE21]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We replay a random URL we extracted from the audit index, complete with its
    authorization token:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重放了从审计索引中提取的随机 URL，并附上其授权令牌：
- en: '[PRE22]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We’re in! We may not have access to the pretty dashboards to visualize these
    metrics—not yet anyway—but we finally caught a glimpse of partial raw campaign
    data. Bonus: we retrieved the location of video files and images served in ads
    1. Let’s take a look at that URL:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们成功了！虽然我们可能无法访问漂亮的仪表盘来可视化这些指标——至少目前还不能——但我们终于看到了一部分原始的活动数据。附加奖励：我们找到了广告中视频文件和图像的存储位置
    1。让我们看一下这个 URL：
- en: '[PRE23]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Surprise, surprise, it redirects to an S3 bucket. We see if we can get into
    that bucket but, sadly, we are not allowed to list its contents, and the keys
    appear too random to brute-force. Maybe the API provides a way to search by client
    name to ease our burden?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 惊讶，惊讶，它重定向到了一个 S3 桶。我们尝试进入该桶，但遗憾的是，我们没有权限列出其中的内容，而且密钥看起来过于随机，无法暴力破解。也许 API 提供了一种按客户名称搜索的方式，来减轻我们的负担？
- en: API Exploration
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API 探索
- en: 'We want to find a method in the API to list client names, videos, and anything
    else that might be relevant. We start messing with the API, sending invalid IDs
    and random URL paths, along with our valid bearer token, in the hope of triggering
    any kind of help message or verbose error:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想在 API 中找到一个列出客户名称、视频和任何其他可能相关内容的方法。我们开始与 API 进行调试，发送无效的 ID 和随机的 URL 路径，并附上我们的有效令牌，希望能触发任何帮助信息或详细错误：
- en: '[PRE24]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We’re directed to some documentation URL. One query to the */docs/v3* URL spills
    out the entire documentation of the API: which endpoints are available, parameters
    to send, headers to include, and so much more. How nice of them!'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们被引导到了一个文档 URL。对 */docs/v3* URL 发起的查询暴露了整个 API 文档：有哪些可用的端点、需要发送的参数、需要包含的头信息等等。真是太贴心了！
- en: 'It turns out that our hunch was not so far from the truth: the authorization
    token is indeed tied to an end user and the scope of their campaigns. The random
    tokens we grabbed are unlikely eligible to view or edit Gretsch Politico’s campaigns
    (unless, of course, there happens to be an active GP user or admin currently communicating
    with the api-core pod—but come on, we both know that Christmas is not due for
    another couple of months).'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 结果证明，我们的直觉并没有错：授权令牌确实与最终用户及其活动范围相关联。我们抓取的随机令牌不太可能有资格查看或编辑 Gretsch Politico 的活动（除非，当然，恰巧有一个活跃的
    GP 用户或管理员当前正在与 api-core Pod 通信——不过，拜托，我们都知道圣诞节还得等好几个月）。
- en: The docs make it clear that the api-core endpoint is the entry point of literally
    every delivery app used by MXR Ads. It is their main database abstraction layer.
    It aggregates business information from multiple data sources and provides a single
    unified overview of the delivery process.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 文档明确表示，api-core 端点是 MXR Ads 使用的每个交付应用程序的入口点。它是他们的主要数据库抽象层。它从多个数据源汇总业务信息，并提供交付过程的统一概览。
- en: 'Apart from the regular commands you would expect from an all-powerful API (fetching
    campaigns, listing insertions, finding exclusion lists, and so on), the documentation
    mentions an extra feature that tickles our hacker intuition: usage reports. This
    feature is described as follows: “the */usage-report* endpoint generates a report
    file detailing the health of the API and several metrics to track its performance
    and configuration*.*”'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 除了你会从一个全能 API 中期待的常规命令（获取广告系列、列出插入项、查找排除列表等），文档中提到的一个额外功能激起了我们的黑客直觉：使用报告。该功能描述如下：“*/usage-report*
    端点生成一个报告文件，详细列出 API 的健康状况以及跟踪其性能和配置的多个指标*。”
- en: Configuration is nice. We like the word *configuration*. Configuration data
    often holds passwords, endpoint definitions, and other API secrets. But there
    is more. That report file they mentioned . . . how is it generated? How is it
    retrieved? Do we get to download it? If so, can we alter the URL to grab another
    file instead? Are there any checks? The dynamic aspect of report generation may
    give us an entry point.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 配置真不错。我们喜欢“配置”这个词。配置数据通常包含密码、端点定义和其他 API 秘密。但还有更多。他们提到的那个报告文件……它是如何生成的？如何获取的？我们能下载它吗？如果能，能否修改
    URL 来抓取其他文件？有没有任何检查？报告生成的动态特性可能会为我们提供一个切入点。
- en: 'Let’s give this report usage feature the old college try. We attempt to generate
    a report to inspect it more closely:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试这个报告使用功能。我们尝试生成一个报告，仔细检查一下：
- en: '[PRE25]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Very interesting indeed! Lucky for MXR Ads, the developers of the usage report
    generator masked the database user and password, so there’s no easy access there,
    but we still got the database endpoint 3: `984195.cehmrvc73g1g.eu-west-1.rds.amazonaws.com`.
    Evidently, data is fetched from a managed relational database on AWS—a service
    called RDS.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 确实非常有趣！幸运的是，对于 MXR Ads 来说，使用报告生成器的开发者屏蔽了数据库用户和密码，所以没有简单的访问方式，但我们仍然得到了数据库端点 3：`984195.cehmrvc73g1g.eu-west-1.rds.amazonaws.com`。显然，数据是从
    AWS 上的托管关系型数据库 RDS 中获取的。
- en: But never mind the database for now. We’ve spotted something that might give
    us a little more power.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 但暂时先不管数据库。我们发现了一些可能让我们更有优势的东西。
- en: 'We’re going to focus on the two special variables: `AWS_ROLE_ARN` and `AWS_WEB_IDENTITY_TOKEN_FILE`.
    According to the AWS documentation, these two variables are injected by AWS’s
    managed version of Kubernetes (EKS) whenever an IAM role is attached to a Kube
    service account. The api-core pod here can exchange its Kube authentication token
    for regular IAM access keys that carry the privileges of the api-core.ec2 role
    1. An excellent privilege promotion!'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重点关注这两个特殊变量：`AWS_ROLE_ARN` 和 `AWS_WEB_IDENTITY_TOKEN_FILE`。根据 AWS 文档，当一个
    IAM 角色被附加到 Kubernetes 服务账户时，AWS 管理版 Kubernetes（EKS）会注入这两个变量。这里的 api-core pod 可以用其
    Kube 身份验证令牌交换为普通的 IAM 访问密钥，这些密钥携带 api-core.ec2 角色的权限 1。这是一次绝妙的权限提升！
- en: It would be interesting to load the service account token stored in the file
    referenced by `AWS_WEB_IDENTITY_TOKEN_FILE` and exchange it for IAM access keys
    to see what we can and can’t access with those keys.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果能加载存储在 `AWS_WEB_IDENTITY_TOKEN_FILE` 文件中服务账户令牌，并将其交换为 IAM 访问密钥，看看我们能访问哪些内容，不能访问哪些内容，那将会很有意思。
- en: 'The `usage-report` function may well help us in this endeavor. The download
    URL points to an S3 URL, but chances are it accepts other URL handlers as well,
    such as `file://` to load documents from disk, like the service `AWS_WEB_IDENTITY_TOKEN_FILE`
    token file 2:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`usage-report` 功能很可能能帮助我们实现这个目标。下载 URL 指向一个 S3 URL，但很可能它也接受其他 URL 处理程序，比如 `file://`
    从磁盘加载文档，就像服务 `AWS_WEB_IDENTITY_TOKEN_FILE` 令牌文件 2：'
- en: '[PRE26]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'It’s so nice when things work out as intended! We get a service account token.
    Let’s see if we can exchange it for IAM keys. If we decode this token and compare
    it to the default JWT we got earlier, we will notice some key differences:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当事情按预期顺利进行时真是太好了！我们获得了一个服务账户令牌。让我们看看能否将其交换为 IAM 密钥。如果我们解码这个令牌并与之前获得的默认 JWT 进行比较，我们会注意到一些关键的区别：
- en: '[PRE27]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The service account token has an audience property, `aud` 1, that is the resource
    server that will accept the token we just decoded. Here it’s set to STS—the AWS
    service that grants temporary IAM credentials. The token’s issuer 2 is no longer
    the service account controller, but is instead an OpenID server provisioned along
    with the EKS cluster. *OpenID* is an authentication standard used to delegate
    authentication to a third party. AWS IAM trusts this OpenID server to properly
    sign and authenticate claims in this JWT.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 服务帐户令牌具有一个观众属性 `aud` 1，它是接受我们刚解码的令牌的资源服务器。这里设置为 STS——AWS 服务，用于授予临时 IAM 凭证。令牌的颁发者
    2 不再是服务帐户控制器，而是与 EKS 集群一起配置的 OpenID 服务器。*OpenID* 是一种认证标准，用于将认证委托给第三方。AWS IAM 信任该
    OpenID 服务器，确保 JWT 中的声明被正确签名和认证。
- en: According to the AWS documentation, if everything has been set up properly,
    the IAM role api-core.ec2 will also be configured to trust impersonation requests
    issued by this OpenID server and bearing the subject claim `system:serviceaccount:prod:api-core-account`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 AWS 文档，如果一切设置正确，IAM 角色 api-core.ec2 也将被配置为信任由该 OpenID 服务器发出的模拟请求，并带有主题声明
    `system:serviceaccount:prod:api-core-account`。
- en: 'When we call the `aws sts assume-role-with-web-identity` API and provide the
    necessary information (web token and role name), we should get back valid IAM
    credentials:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们调用 `aws sts assume-role-with-web-identity` API 并提供必要的信息（网络令牌和角色名称）时，我们应该会得到有效的
    IAM 凭证：
- en: '[PRE28]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Hallelujah! We just upgraded our Kubernetes service token to an IAM role capable
    of interacting with AWS services. What kind of damage can we inflict with this
    new type of access?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 哈利路亚！我们刚刚将 Kubernetes 服务令牌升级为可以与 AWS 服务交互的 IAM 角色。通过这种新类型的访问权限，我们能造成什么样的影响？
- en: Abusing the IAM Role Privileges
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 滥用 IAM 角色权限
- en: 'The api-core application manages campaigns, has links to creatives hosted on
    S3, and has many further capabilities. It’s safe to assume that the associated
    IAM role has some extended privileges. Let’s start with an obvious one that has
    been taunting us since the beginning—listing buckets on S3:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: api-core 应用程序管理广告活动，包含指向存储在 S3 上的创意文件的链接，并具有许多其他功能。可以合理推测，相关的 IAM 角色具有一些扩展权限。我们从一个显而易见的权限开始，它从一开始就一直困扰着我们——列出
    S3 上的桶：
- en: '[PRE29]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Finally! After countless tries, we’ve finally managed to land an IAM role that
    has the `ListBuckets` permission. That took some time!
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 终于！经过无数次尝试，我们终于找到了一个拥有 `ListBuckets` 权限的 IAM 角色。这花了一些时间！
- en: Don’t get too excited just yet, though. We can indeed list buckets, but that
    says nothing about our ability to retrieve individual files from said buckets.
    However, by just looking at the buckets list, we gain new insight into MXR Ads’
    modus operandi.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 不要太兴奋了。我们确实可以列出桶，但这并不能说明我们是否能够从这些桶中检索单个文件。然而，通过查看桶列表，我们获得了对 MXR Ads 操作模式的新见解。
- en: 'The bucket mxrads-terraform, for instance, most likely stores the state generated
    by *Terraform*, a tool used to set up and configure cloud resources such as servers,
    databases, and network. The state is a declarative description of all the assets
    generated and managed by Terraform, such as the server’s IP, subnets, IAM role,
    permissions associated with each role and user, and so on. It even stores cleartext
    passwords. Even if our target is using a secret management tool like Vault, AWS
    Key Management Service (KMS), or AWS Secrets Manager, Terraform will decrypt them
    on the fly and store their cleartext version in the state file. Oh, what wouldn’t
    we give to access that bucket. Let’s give it a try:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，桶 mxrads-terraform 很可能存储了 *Terraform* 生成的状态，Terraform 是一个用于设置和配置云资源（如服务器、数据库和网络）的工具。状态是所有由
    Terraform 生成和管理的资产的声明性描述，例如服务器的 IP、子网、IAM 角色、与每个角色和用户关联的权限等等。它甚至存储明文密码。即使我们的目标使用了像
    Vault、AWS 密钥管理服务（KMS）或 AWS Secrets Manager 这样的密钥管理工具，Terraform 也会动态解密这些密码并将其明文版本存储在状态文件中。哦，我们愿意为访问那个桶付出什么代价。让我们试试看：
- en: '[PRE30]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Alas, no luck. Everything in good time. Let’s return to our list of buckets.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 唉，运气不好。凡事都得慢慢来。让我们回到我们的桶列表。
- en: 'There is at least one bucket we are sure api-core should be able to access:
    s4d.mxrads.com, the bucket storing all the creatives. We’ll use our IAM privileges
    to list the bucket’s contents:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确认至少有一个桶 api-core 应该能够访问：s4d.mxrads.com，这是存储所有创意文件的桶。我们将使用我们的 IAM 权限列出该桶的内容：
- en: '[PRE31]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Hmm . . . yes, we sure have access to all the videos and images MXR Ads uses
    in its advertising campaigns, but we’re not going to download and play terabytes
    of media ads just to find the ones used by Gretsch Politico. There must be a better
    way to inspect these files.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯……是的，我们确实有权限访问 MXR Ads 在广告活动中使用的所有视频和图片，但我们不打算下载并播放数以 TB 计的媒体广告，只为找出 Gretsch
    Politico 使用的广告内容。肯定有更好的方法来检查这些文件。
- en: And there is. Remember that Kubernetes service account token we retrieved a
    few minutes ago? We were so hasty in converting it to AWS credentials that we
    almost forgot the privileges it held on its own. That service account is the golden
    pass to retrieve cluster resources attributed to the api-core pod. And guess what
    properties api-core needs to function? Database credentials! We will leverage
    the DB access to target Gretsch Politico creatives and then use our newly acquired
    IAM access to download these videos from S3.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，记得我们几分钟前获取的 Kubernetes 服务账户令牌吗？我们匆忙将其转换为 AWS 凭证，以至于几乎忘记了它本身所拥有的权限。那个服务账户是获取归属于
    api-core pod 的集群资源的金钥匙。你猜猜 api-core 需要什么属性才能运行？数据库凭证！我们将利用数据库访问权限，瞄准 Gretsch Politico
    的创意内容，然后使用我们新获得的 IAM 权限从 S3 下载这些视频。
- en: Abusing the Service Account Privileges
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 滥用服务账户权限
- en: 'We go back to our faithful reverse shell and issue a new `curl` command to
    the API server, this time bearing the api-core JWT. We request the secrets found
    in the pod’s description, `dbCorepassword`:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到忠实的反向 shell，发出一条新的 `curl` 命令给 API 服务器，这次带上了 api-core 的 JWT。我们请求在 pod 描述中找到的机密
    `dbCorepassword`：
- en: '[PRE32]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We then decode the user and password:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接着我们解码用户名和密码：
- en: '[PRE33]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: And voilà, the campaign database credentials are `api-core-rw` / `zO5jLWlgrG7AS6l`.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 瞧，广告活动数据库凭证是 `api-core-rw` / `zO5jLWlgrG7AS6l`。
- en: Infiltrating the Database
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 渗透数据库
- en: 'Let’s initiate the connection to the database from the cluster in case the
    RDS instance is protected by some ingress firewall rules. We don’t know exactly
    which database backend we will query (RDS supports MySQL, Aurora, Oracle, SQL
    Server, and more). Because MySQL is the most popular engine, we’ll try that first:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从集群中启动数据库连接，以防 RDS 实例受到某些入口防火墙规则的保护。我们不确定要查询哪个数据库后端（RDS 支持 MySQL、Aurora、Oracle、SQL
    Server 等）。由于 MySQL 是最受欢迎的引擎，我们先尝试 MySQL：
- en: '[PRE34]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We are in.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们成功进入了。
- en: 'Locating Gretsch Politico’s campaigns requires rudimental SQL knowledge that
    I won’t go into detail on here. We start by listing every column, table, and database
    on the server. This information is readily available in the *information_schema*
    database in the `COLUMN_NAME` table:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 定位 Gretsch Politico 的广告活动需要一些基本的 SQL 知识，这里我就不再详细讲解了。我们从列出服务器上的每一列、表和数据库开始。这些信息可以在`information_schema`数据库的`COLUMN_NAME`表中轻松找到：
- en: '[PRE35]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We cherry-pick the few columns and tables that most likely hold campaign data
    and then query the information with a couple of `select` statements punctuated
    by `join` operations. This should give us the list of campaigns, creative URLs,
    and budget of each campaign—all the information we could ask for. We make sure
    to pass in our stolen credentials again:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们精挑细选了几列和表，这些很可能存有广告活动数据，然后通过几个`select`语句和`join`操作查询这些信息。这应该能给我们提供广告活动列表、创意
    URL 和每个广告活动的预算——所有我们所需要的信息。我们确保再次使用我们偷来的凭证：
- en: '[PRE36]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: It seems GP’s customers are spending hundreds of thousands of dollars on every
    single one of the 200 ads currently running. That’s some good money all right.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来 GP 的客户每一则广告都花费了成百上千美元，而目前有 200 条广告正在投放。真是一笔可观的收入。
- en: We loop through all the creative URLs found in the database and retrieve them
    from S3.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历数据库中找到的所有创意 URL，并从 S3 获取它们。
- en: Remember the time when hackers needed to carefully design exfiltration tools
    and techniques to bypass data loss prevention measures and painstakingly extract
    data from the company’s network? Yeah, we don’t need to do that anymore.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得黑客们曾经需要小心设计外泄工具和技术，绕过数据丢失防护措施，并费劲地从公司网络中提取数据吗？是的，现在我们不需要再做这些了。
- en: A cloud provider does not care where you are. As long as you have the right
    credentials, you can download whatever you want. The target will probably get
    a salty bill at the end of the month, but that will hardly tip off anyone in the
    accounting department. MXR Ads continuously serves most of these videos worldwide
    anyway. We are just downloading everything in a single sweep.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商不关心你在哪里。只要你拥有正确的凭证，你可以下载任何你想要的内容。目标方可能会在月底收到一份昂贵的账单，但这几乎不会引起财务部门的任何怀疑。反正MXR广告公司一直在全球范围内提供这些视频。我们只是在一次性扫荡所有的内容。
- en: 'Given the number of creatives involved (a few hundred belonging to GP), we
    will leverage some `xargs` magic to parallelize the call to the `get-object` API.
    We prepare a file with the list of creatives to fetch and then loop over every
    line and feed it to `xargs`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到涉及的创意数量（属于GP的几百个创意），我们将利用一些`xargs`魔法来并行化调用`get-object` API。我们准备了一个包含创意列表的文件，然后循环遍历每一行并将其传递给`xargs`：
- en: '[PRE37]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The `-I` flag is the replacement token that determines where to inject the
    line that was read. The `-P` flag in `xargs` is the maximum number of concurrent
    processes (16 on my machine). Finally, `RANDOM` is a default bash variable that
    returns a random number on each evaluation and will be the local name of the downloaded
    creative. Let''s see how many creatives we''ve nabbed:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`-I`标志是替换令牌，决定在哪里注入读取的行。`xargs`中的`-P`标志表示最大并发进程数（在我的机器上为16）。最后，`RANDOM`是一个默认的bash变量，在每次评估时返回一个随机数字，它将成为下载的创意的本地名称。让我们看看我们抓取了多少创意：'
- en: '[PRE38]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We get 264 creatives—that’s 264 hate messages, Photoshopped images, doctored
    videos, and carefully cut scenes emphasizing polarizing messages. Some images
    even discourage people from voting. Clearly, nothing is out of bounds to get the
    desired election outcome.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了264个创意——也就是264条仇恨信息、PS合成的图像、修改过的视频和精心剪辑的场景，强调两极化的信息。有些图像甚至劝阻人们投票。显然，为了得到理想的选举结果，什么都不在话下。
- en: 'In getting these video files, we successfully completed goal number 3 from
    Chapter 4\. We still have two crucial objectives to complete: uncovering the real
    identity of GP’s clients and understanding the extent of the data-profiling activity.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在获取这些视频文件时，我们成功完成了第4章的目标3。我们还有两个关键目标需要完成：揭示GP客户的真实身份，并了解数据分析活动的范围。
- en: We go back to our S3 bucket list, hoping to find clues or references to some
    machine learning or profiling technology (Hadoop, Spark, Flink, Yarn, BigQuery,
    Jupyter, and so on), but find nothing meaningful we can access.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到S3存储桶列表，试图寻找与一些机器学习或分析技术（如Hadoop、Spark、Flink、Yarn、BigQuery、Jupyter等）相关的线索或参考，但没有找到任何我们能访问到的有意义的内容。
- en: 'How about another component in the delivery chain? We list all the pods running
    in the `prod` namespace looking for inspiration:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，交付链中的另一个组件怎么样？我们列出了在`prod`命名空间中运行的所有Pod，寻找灵感：
- en: '[PRE39]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: These pod names are as cryptic as they come. The ad business, not unlike Wall
    Street, has a nasty habit of hiding behind obscure acronyms that sow doubt and
    confusion. So, after a couple of hours of research on Wikipedia deciphering these
    names, we decide to focus on the `ads-rtb` application. RTB stands for *real-time
    bidding*,a protocol used to conduct the auction that leads to the display of a
    particular ad over all others on a website.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这些Pod的名称晦涩难懂。广告行业，和华尔街一样，有一个不太好的习惯，那就是躲在晦涩的缩写背后，制造疑惑和混乱。因此，在维基百科上研究了几个小时解读这些名称后，我们决定专注于`ads-rtb`应用。RTB代表*实时竞价*，它是一种用于进行拍卖的协议，从而决定在网站上展示特定广告，而不是其他广告。
- en: 'Every time a user loads a page on a website in partnership with MXR Ads, a
    piece of JavaScript code fires up a call to MXR Ads’ supply-side platform (SSP)
    to run an auction. MXR Ads’ SSP relays the request to other SSPs, advertising
    agencies, or brands to collect their bids. Each agency, acting as a demand-side
    platform (DSP), bids a certain amount of dollars to display their chosen ad. The
    amount they’re willing to bid is usually based on multiple criteria: the URL of
    the website, the position of the ad on the page, the keywords in the page, and,
    most importantly, the user’s data. If these criteria are suitable to the client
    running the ad, they’ll bid higher. This auction is conducted automatically using
    the RTB protocol.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 每当用户在与 MXR Ads 合作的网站上加载页面时，一段 JavaScript 代码会触发对 MXR Ads 的供应方平台（SSP）的调用，进行一次拍卖。MXR
    Ads 的 SSP 将请求转发给其他 SSP、广告公司或品牌，收集它们的竞标。每个代理商，作为需求方平台（DSP），会出价一定的金额来展示他们选择的广告。他们愿意出价的金额通常基于多个标准：网站的
    URL、广告在页面上的位置、页面中的关键词，以及最重要的，用户的数据。如果这些标准符合广告主的需求，他们会出价更高。这场拍卖通过 RTB 协议自动进行。
- en: It might be the case the RTB pods do not have access to personal data and simply
    blindly relay requests to servers hosted by GP, but seeing how central the RTB
    protocol is in the delivery of an ad, these pods may well lead us to our next
    target.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 可能 RTB Pod 并没有访问个人数据，仅仅是盲目地将请求转发给由 GP 托管的服务器，但考虑到 RTB 协议在广告投放中的核心地位，这些 Pod 很可能将引导我们进入下一个目标。
- en: Redis and Real-Time Bidding
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Redis 和实时竞价
- en: 'We pull ads-rtb’s pod manifest:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拉取 ads-rtb 的 Pod 清单：
- en: '[PRE40]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Look at that! A Redis container is running alongside the RTB application, listening
    on port 6379.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 看！一个 Redis 容器正在与 RTB 应用程序并行运行，监听端口 6379。
- en: 'As stated previously, I have yet to see a Redis database protected with authentication
    in an internal network, so you can imagine that our Redis hiding inside a pod
    in a Kubernetes cluster obviously welcomes us with open arms. We download the
    Redis client and proceed to list the keys saved in the database:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我尚未见过在内部网络中受身份验证保护的 Redis 数据库，所以你可以想象我们的 Redis 藏在 Kubernetes 集群中的 Pod 里，显然是张开双臂欢迎我们的。我们下载
    Redis 客户端并开始列出数据库中保存的键：
- en: '[PRE41]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Each RTB application is shipped with its own companion Redis container that
    acts as a local cache to store various objects. The key `select_3799ec543582b38c`
    holds a literal Java object serialized into bytes. We can tell this because any
    Java serialized object has the hex string marker 00 05 73 72, which we see when
    we query the key’s value:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 RTB 应用程序都配有一个伴随的 Redis 容器，作为本地缓存存储各种对象。键 `select_3799ec543582b38c` 存储着一个字节序列化的
    Java 对象。我们可以从中看出，因为任何 Java 序列化对象都有一个十六进制字符串标记 00 05 73 72，我们在查询该键的值时正好看到了这个标记：
- en: '[PRE42]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Instead of retrieving the same result time and time again from the database
    and needlessly incurring the expensive cost of network latency, the ads-rtb container
    keeps previous database results (strings, objects, and so forth) in its local
    Redis container cache. Should the same request present itself later, it fetches
    the corresponding result almost instantly from Redis.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免从数据库中反复获取相同的结果并无谓地消耗网络延迟的高昂成本，ads-rtb 容器将之前的数据库结果（如字符串、对象等）保存在本地 Redis 容器缓存中。如果相同的请求再次出现，它几乎可以立即从
    Redis 中获取相应的结果。
- en: 'This form of caching was probably hailed as a fantastic idea during the initial
    application design, but it involves a dangerous and often overlooked operation:
    deserialization.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这种缓存形式在初期应用设计时可能被视为一个绝妙的主意，但它涉及一个危险且常被忽视的操作：反序列化。
- en: Deserialization
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反序列化
- en: When a Java object (or object from almost any high-level language for that matter,
    like Python, C#, and so forth) is deserialized, it is transformed back from a
    stream of bytes into a series of attributes that populate a real Java object.
    This process is usually carried out by the `readObject` method of the target class.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个 Java 对象（或几乎任何高级语言中的对象，如 Python、C# 等）被反序列化时，它会从一串字节流中转回为一系列属性，从而填充一个实际的 Java
    对象。这个过程通常是通过目标类的 `readObject` 方法来完成的。
- en: 'Here’s a quick example showing what might be going on inside ads-rtb. Somewhere
    in the code, the application loads an array of bytes from the Redis cache and
    initializes an input stream:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个简单的例子，展示了 ads-rtb 内部可能发生的情况。在代码的某个地方，应用程序从 Redis 缓存加载了一个字节数组，并初始化了一个输入流：
- en: '[PRE43]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Next, this series of bytes is consumed by the `ObjectInputStream` class, which
    implements the `readObject` method. This method extracts the class, its signature,
    and static and nonstatic attributes, effectively transforming a series of bytes
    into a real Java object:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，这一系列字节由`ObjectInputStream`类消耗，该类实现了`readObject`方法。这个方法提取类、类签名以及静态和非静态属性，实际上是将一系列字节转换为一个真实的Java对象：
- en: '[PRE44]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Here’s where we may find an in. We did not call the default `readObject` method
    of the `ObjectInputStream` but instead called a custom `readObject` method defined
    in the target class `BidRequest`1.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这时我们可能会找到突破口。我们并没有调用`ObjectInputStream`的默认`readObject`方法，而是调用了目标类`BidRequest`1中定义的自定义`readObject`方法。
- en: 'This custom `readObject` method can pretty much do anything with the data it
    receives. In this next boring scenario, it just lowers the case of an attribute
    called `auctionID`, but anything is possible: it could perform network calls,
    read files, and even execute system commands. And it does so based on the input
    it got from the untrusted serialized object:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个自定义的`readObject`方法几乎可以对接收到的数据做任何操作。在接下来的这个无聊的场景中，它只是将一个名为`auctionID`的属性转换为小写，但任何事情都有可能发生：它可以进行网络调用、读取文件，甚至执行系统命令。而且它是根据从不可信的序列化对象中获得的输入来执行的：
- en: '[PRE45]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Thus, the challenge is to craft a serialized object that contains the right
    values and navigates the execution flow of a `readObject` method until it reaches
    a system command execution or other interesting outcome. It might seem like a
    long shot, but that’s exactly what a couple of researchers did a couple of years
    back. The only difference is that they found this flaw in the `readObject` method
    of a class inside commons-collections, a Java library shipped by default in the
    Java Runtime Environment (check out the talk “Exploiting Deserialization Vulnerabilities
    in Java” by Matthias Kaiser).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，挑战在于制作一个包含正确值的序列化对象，并引导`readObject`方法的执行流程，直到它到达系统命令执行或其他有趣的结果。这看起来可能是一个很长的过程，但这正是几位研究人员几年前所做的。唯一的不同是，他们发现了这个漏洞存在于commons-collections库中`readObject`方法的一个类里，而commons-collections是Java运行时环境（JRE）中默认随附的一个Java库（可以查看Matthias
    Kaiser的讲座《Exploiting Deserialization Vulnerabilities in Java》）。
- en: During a brief moment after this talk, deserialization vulnerabilities almost
    rivaled Windows exploits in quantity. It was uncanny! The `readObject` method
    of the faulty classes was patched in newer versions of the commons-collections
    library (starting from 3.2.2), but since tuning the Java Virtual Machine (JVM)
    is such a hazardous process more often than not, based on folklore and ancient
    wisdom, many companies resist the urge to upgrade JVMs, thus leaving the door
    wide open for deserialization vulnerabilities.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次讲座后的短暂时刻，反序列化漏洞几乎与Windows漏洞在数量上相媲美，真是让人难以置信！故障类的`readObject`方法在commons-collections库的更新版本（从3.2.2开始）中被修复，但由于调优Java虚拟机（JVM）通常是一个危险的过程，根据民间传说和古老的智慧，许多公司抵制升级JVM的冲动，从而为反序列化漏洞敞开了大门。
- en: First, we need to make sure that our pod is vulnerable to this attack.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要确保我们的pod存在这个漏洞。
- en: If you remember, in Chapter 5 we came across the bucket mxrads-dl that seemed
    to act as a private repository of public JAR files and binaries. This bucket should
    contain almost every version of external JAR files used by apps like ads-rtb.
    The answer, therefore, may lie in there. We search through the bucket’s key for
    vulnerable Java libraries supported by the ysoserial tool ([https://github.com/frohoff/ysoserial/](https://github.com/frohoff/ysoserial/)),
    which is used to craft payloads triggering deserialization vulnerabilities in
    many Java classes. The tool’s GitHub page lists a number of well-known libraries
    that can be exploited, such as commons-collections 3.1, spring-core 4.1.4, and
    so on.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得，在第5章我们遇到了一个名为mxrads-dl的存储桶，它似乎充当了一个公共JAR文件和二进制文件的私人仓库。这个存储桶应该包含像ads-rtb这样的应用程序使用的几乎所有版本的外部JAR文件。因此，答案可能就在里面。我们通过搜索存储桶中的键，查找由ysoserial工具支持的易受攻击的Java库（[https://github.com/frohoff/ysoserial/](https://github.com/frohoff/ysoserial/)），该工具用于制作有效载荷，触发许多Java类中的反序列化漏洞。该工具的GitHub页面列出了许多可以被利用的著名库，如commons-collections
    3.1、spring-core 4.1.4等。
- en: '[PRE46]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We find commons-collections version 3.3.2\. So close. We could venture a blind
    exploit hoping the bucket still uses a local, old version of the commons-collections
    library, but the odds are stacked against us, so we’ll move on.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们找到了commons-collections版本3.3.2，差一点就能成功了。我们本可以尝试盲目利用，假设该存储桶仍然使用本地的旧版本commons-collections库，但胜算不大，因此我们继续向前推进。
- en: Cache Poisoning
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缓存投毒
- en: 'We continue exploring other keys in the Redis cache, hoping for some new inspiration:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续探索 Redis 缓存中的其他密钥，希望能获得一些新的灵感：
- en: '[PRE47]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We list the contents of the key `vast_c88b4ab3d_19devear` and find a URL this
    time:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们列出密钥 `vast_c88b4ab3d_19devear` 的内容，这次找到了一个 URL：
- en: '[PRE48]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'VAST (Video Ad Serving Template) is a standard XML template for describing
    ads to browser video players, including where to download the media, which tracking
    events to send, after how many seconds, to which endpoint, and so on. Here is
    an example of a VAST file pointing to a video file stored on *s4d.mxards.com*
    for an ad titled “Exotic Approach”:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: VAST（视频广告服务模板）是一个标准的 XML 模板，用于向浏览器视频播放器描述广告内容，包括媒体下载的位置、要发送的跟踪事件、在多少秒后、发送到哪个端点等等。以下是一个
    VAST 文件的示例，指向存储在 *s4d.mxards.com* 上的名为“Exotic Approach”的广告视频文件：
- en: '[PRE49]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: XML parsers can be such fickle beasts—the wrong tag, and all hell breaks loose.
    The parser will spit out stack traces bigger than the original file itself into
    the standard error output. So many exceptions that need to be properly handled
    . . . and logged!
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: XML 解析器可以是非常挑剔的怪物——只要标签错误，整个系统就会崩溃。解析器会将比原文件还要大的堆栈追踪信息输出到标准错误输出中。出现了许多异常需要被正确处理……并且记录日志！
- en: See where I’m going with this? We already have access to the pods handling the
    application logs related to ad delivery. If we replace a VAST URL with, say, the
    metadata API URL that responds with a JSON/text format, will the application send
    a verbose error to the Elasticsearch audit store that we can look at?
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你能明白我想表达的意思吗？我们已经获得了访问处理与广告投放相关的应用日志的 pod。如果我们将 VAST URL 替换为例如返回 JSON/文本格式的元数据
    API URL，应用程序是否会向 Elasticsearch 审计存储发送详细错误，我们可以查看？
- en: 'Only one way to find out. We replace a dozen valid VAST URLs with the infamous
    endpoint URL `http://169.254.169.254/latest/meta-data/iam/info`, like so:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 只有一个办法能弄清楚。我们将十几个有效的 VAST URL 替换为臭名昭著的端点 URL `http://169.254.169.254/latest/meta-data/iam/info`，如下所示：
- en: '[PRE50]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'This metadata endpoint should return a JSON response containing the IAM role
    attached to the node running the ads-rtb pod. We know the role exists because
    EKS requires it. Bonus point: this role has some interesting privileges.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这个元数据端点应该返回一个 JSON 响应，包含附加到运行 ads-rtb pod 的节点上的 IAM 角色。我们知道角色存在，因为 EKS 要求它。附加分数：这个角色有一些有趣的权限。
- en: 'It takes a good 10 minutes for one of the poisoned cache entries to be triggered,
    but we finally get the verbose error we were hoping for. We can locate the error
    in the log index by searching for MXR Ads’ AWS account ID, 886371554408:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 大约需要 10 分钟才能触发一个被毒化的缓存条目，但我们最终得到了我们期待的详细错误信息。我们可以通过搜索 MXR Ads 的 AWS 账户 ID 886371554408
    来定位日志索引中的错误：
- en: '[PRE51]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The pod that triggered the query is running with the IAM role `eks-workers-prod-common-NodeInstanceProfile-BZUD6DGQKFGC`.
    All we have to do now is poison the Redis cache once more, but this time append
    the role name to the URL to fetch its temporary access keys:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 触发查询的 pod 正在运行具有 IAM 角色 `eks-workers-prod-common-NodeInstanceProfile-BZUD6DGQKFGC`。我们现在要做的就是再次毒化
    Redis 缓存，但这次需要将角色名附加到 URL 上，以便获取其临时访问密钥：
- en: '[PRE52]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'A few minutes later we get our coveted prize, valid AWS access keys with EKS
    node privileges in the log index:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，我们终于得到了梦寐以求的奖品，有效的 AWS 访问密钥，具有 EKS 节点权限，并且可以在日志索引中看到：
- en: '[PRE53]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'According to the AWS docs, the default role attached to a Kubernetes node will
    have basic permissions over EC2 to discover its environment: `describe-instances`,
    `describe-security-groups`, `describe-volumes`, `describe-subnets`, and so on.
    Let’s give these new credentials a spin and list all instances in the `eu-west-1`
    region (Ireland):'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 AWS 文档，附加到 Kubernetes 节点的默认角色将具有基本的 EC2 权限，以发现其环境：`describe-instances`、`describe-security-groups`、`describe-volumes`、`describe-subnets`
    等。让我们试一下这些新凭证，并列出 `eu-west-1` 区域（爱尔兰）的所有实例：
- en: '[PRE54]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Things are looking great. We get the full descriptions of approximately 700
    EC2 machines, including private and public IP addresses, firewall rules, machine
    types, and more. That’s a lot of machines, but the figure is relatively small
    for a company with the scale of MXR Ads. Something is off.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一切看起来都很顺利。我们得到了大约 700 台 EC2 机器的完整描述，包括私有和公共 IP 地址、防火墙规则、机器类型等。虽然这是很多机器，但对于像
    MXR Ads 这样规模的公司来说，这个数字相对较小。有什么地方不对劲。
- en: All the machines we got have the special tag `k8s.io/cluster-autoscaler/prod-euw1`.
    This is a common tag used by the autoscaler tool ([https://github.com/kubernetes/autoscaler/](https://github.com/kubernetes/autoscaler/))
    to mark disposable nodes that can be killed off when the pods’ activity is running
    low. MXR Ads probably took advantage of this tag to limit the scope of the default
    permissions assigned to Kubernetes nodes. Clever indeed.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得的所有机器都有一个特殊标签 `k8s.io/cluster-autoscaler/prod-euw1`。这是 autoscaler 工具（[https://github.com/kubernetes/autoscaler/](https://github.com/kubernetes/autoscaler/)）常用的标签，用于标记那些可以在
    pod 活动较低时被销毁的可丢弃节点。MXR Ads 可能利用了这个标签来限制分配给 Kubernetes 节点的默认权限范围。确实非常聪明。
- en: 'Ironically, the tag spills out the Kubernetes cluster name `(prod-euw1)`, which
    is a required parameter in a call to the `describeCluster` API. Let’s call `describeCluster`
    then:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 有讽刺意味的是，标签泄露了 Kubernetes 集群的名称 `(prod-euw1)`，这是调用 `describeCluster` API 时所需的一个参数。那么我们就调用
    `describeCluster` 吧：
- en: '[PRE55]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: The API server is that long URL conveniently named `endpoint` 1. In some rare
    configurations, it may be exposed on the internet, making it much more convenient
    to query/alter the cluster’s desired state.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器是那个长得很方便的 URL，名为 `endpoint` 1。在一些罕见的配置下，它可能会暴露在互联网中，这样就可以更加方便地查询或更改集群的期望状态。
- en: The role we got 2 can do much more than simply explore Kubernetes resources.
    In a default setting, this role has the power to attach any security group to
    any other node in the cluster. Now that we’ve been granted this role, we just
    need to find an existing security group that exposes every port on the internet—there
    is always one—and assign it to the machine hosting our current shell.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得的这个角色可以做的远不止仅仅探索 Kubernetes 资源。在默认设置下，这个角色有权将任何安全组附加到集群中的任何节点上。既然我们已经被授予了这个角色，我们只需要找到一个暴露所有端口到互联网的现有安全组——这种安全组总是存在——并将其分配给托管我们当前
    shell 的机器。
- en: Not so fast, though. While it might be tempting to promote our handcrafted S3-based
    reverse shell into a full-blown duplex communication channel, it is very probable
    that MXR Ads Terraformed their Kube cluster by declaring how many machines should
    ideally be running, what their network configuration should look like, and which
    security groups are assigned to each machine. If we alter these parameters, the
    change will be flagged on the next `terraform plan` command. A security group
    that allows all ingress traffic to a random node can only raise questions we’d
    rather avoid.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，事情并不像想象的那么简单。虽然可能很诱人将我们手工制作的基于 S3 的反向 shell 升级为完整的双工通信通道，但很可能 MXR Ads 通过声明理想中应该运行的机器数量、网络配置和分配给每台机器的安全组来
    Terraform 了他们的 Kube 集群。如果我们更改这些参数，下一次运行 `terraform plan` 命令时就会标记出变化。允许所有流量进入随机节点的安全组只会引发我们宁愿避免的问题。
- en: We continue to toy around with the role attached to the Kube node, but it quickly
    hits its limits. It was so severely restricted that it lost every ounce of interest.
    We can only describe general information about the cluster’s components. We don’t
    have access to the machines’ user data and can hardly change anything without
    sounding the whistle.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续玩弄附加到 Kube 节点的角色，但很快就达到了极限。它被严格限制到几乎失去了任何兴趣。我们只能描述集群组件的基本信息。我们无法访问机器的用户数据，几乎无法在不引起警报的情况下更改任何东西。
- en: Come to think of it, why are we only considering this node as an AWS resource?
    It is first and foremost a Kubernetes resource. A privileged one at that. This
    node may have laughable permissions in the AWS environment, but it is a supreme
    god in the Kubernetes world as it literally has life and death authority over
    the pods in its realm.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 想想看，为什么我们只将这个节点视为 AWS 资源？它首先是一个 Kubernetes 资源，而且是一个特权资源。这个节点在 AWS 环境中可能只有可笑的权限，但在
    Kubernetes 世界中，它是一个至高无上的存在，因为它在其领域内对 pods 拥有生死权。
- en: As explained earlier, every node has a running process called the kubelet that
    polls the API server for new pods to spawn or terminate. Running containers means
    mounting volumes, injecting secrets . . . how the hell does it achieve this level
    of access?
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，每个节点都有一个运行中的过程叫做 kubelet，它会轮询 API 服务器以生成或终止新 pod。运行的容器意味着挂载卷、注入密钥...它是如何实现这种级别的访问权限的？
- en: 'Answer: via the node’s instance profile—aka the role we were playing with this
    whole time.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：通过节点的实例配置文件——也就是我们一直在操作的那个角色。
- en: 'When you set up a Kubernetes cluster on EKS, one of the first configurations
    to apply before even starting the nodes is to add the node IAM role name to the
    `system:nodes` group. This group is bound to the Kubernetes role `system:node`,
    which has read permissions on various Kube objects: services, nodes, pods, persistent
    volumes, and 18 other resources!'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在 EKS 上设置 Kubernetes 集群时，第一个要配置的内容之一是在启动节点之前，将节点 IAM 角色名称添加到 `system:nodes`
    组中。该组绑定到 Kubernetes 角色 `system:node`，该角色对各种 Kube 对象具有读取权限：服务、节点、Pods、持久卷以及其他 18
    种资源！
- en: 'All we have to do to inherit these powers is ask AWS to morph our IAM access
    keys into a valid Kubernetes token so we can query the API server as a valid member
    of the `system:nodes` group. To do this we call the `get-token` API:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所要做的就是请求 AWS 将我们的 IAM 访问密钥转换为有效的 Kubernetes 令牌，这样我们就可以作为 `system:nodes` 组的有效成员查询
    API 服务器。为此，我们调用 `get-token` API：
- en: '[PRE56]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The token we get this time is not a standard JWT; rather, it contains the building
    blocks of a call to the `GetCallerIdentity` API of the STS service. Let’s decode
    a portion of the token we obtained earlier using a combination of `jq`, `cut`,
    `base64`, and `sed`:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这次获得的令牌不是标准的 JWT；相反，它包含了调用 STS 服务的 `GetCallerIdentity` API 所需的构建块。让我们使用 `jq`、`cut`、`base64`
    和 `sed` 等工具解码我们之前获得的部分令牌：
- en: '[PRE57]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The JWT is actually an encoded pre-signed URL that bears the node’s identity.
    Anyone can replay this URL to verify that the node is indeed who it claims to
    be. That’s exactly what EKS does upon receiving this token. Just as AWS IAM trusts
    OpenID to identify and authenticate Kube users (through the means of a JWT), EKS
    trusts IAM to do the same through a web call to the `sts.amazon.com` endpoint.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: JWT 实际上是一个编码过的预签名 URL，包含节点的身份。任何人都可以重新播放这个 URL 来验证该节点是否确实是它声称的那样。EKS 接收到这个令牌时，正是这么做的。正如
    AWS IAM 通过 JWT 信任 OpenID 来识别和认证 Kube 用户一样，EKS 也通过 Web 调用 `sts.amazon.com` 端点信任
    IAM 来做同样的事情。
- en: 'We can use this token in a `curl` command to the API server like we did earlier,
    but we are better off generating a full Kubectl config that we can download into
    that trustworthy pod of ours:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像之前一样使用这个令牌通过 `curl` 命令向 API 服务器发起请求，但我们最好生成一个完整的 Kubectl 配置文件，将其下载到我们那个值得信赖的
    Pod 中：
- en: '[PRE58]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'A quick way to test whether we’ve gained our new privileges is to list the
    pods in the sacred `kube-system` namespace. This is the namespace that contains
    the master pods—the kube api-server, etcd, coredns—and other critical pods used
    to administer Kubernetes. Remember that our previous tokens were limited to the
    `prod` namespace, so gaining access to `kube-system` would be a huge step forward:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 测试我们是否获得新权限的一个快速方法是列出 `kube-system` 命名空间中的 Pods。这个命名空间包含了主控 Pod —— kube api-server、etcd、coredns
    —— 以及其他用于管理 Kubernetes 的关键 Pod。记住，我们之前的令牌仅限于 `prod` 命名空间，因此获得对 `kube-system` 的访问权限将是一个巨大的进步：
- en: '[PRE59]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: We manage to list the pods! Nice! Obviously, since we are in a managed Kubernetes,
    the most vital pods (kube-apiserver, etcd, kube-controller-manager) are kept hidden
    by Amazon, but the rest of the pods are there.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们成功列出了 Pods！太棒了！显然，由于我们处于托管的 Kubernetes 中，最重要的 Pods（kube-apiserver、etcd、kube-controller-manager）被
    Amazon 隐藏起来，但其余的 Pods 还是能看到。
- en: Kube Privilege Escalation
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kube 权限提升
- en: 'Let’s put our new privileges to good use. The first thing we want to do is
    grab all the secrets defined in Kube; however, when we try it, we find that even
    though the `system:nodes` group technically has the permission to do so, it cannot
    arbitrarily request secrets:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们好好利用我们新的权限。我们要做的第一件事是获取 Kube 中定义的所有秘密；然而，当我们尝试时，我们发现即使 `system:nodes` 组理论上有权限这么做，它也不能随意请求秘密：
- en: '[PRE60]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'A security feature introduced in Kubernetes version 1.10 limits the excessive
    power attributed to nodes: node authorization. This feature sits on top of classic
    role-based access control. A node can only exercise its ability to retrieve a
    secret if there are scheduled pods on that same node that need that secret. When
    those pods are terminated, the node loses access to the secret.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 1.10 版本中引入了一项安全特性，限制了节点的过度权限：节点授权。此特性基于经典的基于角色的访问控制之上。一个节点只能在该节点上有需要该秘密的调度
    Pods 时，才能获取该秘密。当这些 Pods 被终止时，节点就会失去访问该秘密的权限。
- en: 'There is no reason to panic, though. Any random node usually hosts dozens,
    if not hundreds, of different pods at any given time, each with its own dirty
    secrets, volume data, and so on. Maybe at 11 pm today our node can only retrieve
    the password of a dummy database, but give it 30 minutes and the kube-scheduler
    may send the node a pod with cluster admin privileges. It’s all about being on
    the right node at the right moment. We list the pods running on the current machine
    to find out which secrets we are entitled to fetch:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Lots of heterogeneous applications are hosted on this single node. That seems
    promising. The node will probably have access to a large number of secrets spanning
    various components. We use our custom parser to automatically list the secrets
    mounted by each pod:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'A treasure trove! Cassandra databases, AWS access keys, service accounts, Aurora
    database passwords, GitHub tokens, more AWS access keys . . . is this even real?
    We download (and decode) every secret with the rather explicit command `kubectl
    get secret`, as shown next:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Look at all these credentials and tokens we’re retrieving! And we’re not even
    done. Not by a long shot. See, this was just one node that happened to run the
    ads-rtb pod with the insecure Redis container. There are 200 other similar pods
    distributed over 700 machines that are vulnerable to the same cache poisoning
    technique.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula for this kind of hack is simple: locate these pods (with the `get
    pods` command), connect to the Redis container, replace a few VAST URLs with the
    metadata API, collect the machine’s temporary AWS keys spilled to the audit database,
    convert them to a Kubernetes token, and retrieve the secrets loaded by the pods
    running on the node.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'We rinse and repeat, checking each node, and stop when we notice something
    very interesting in the output:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'We’ve come across lucky node number 192.168.133.34 1, which says it hosts a
    few pods belonging to the all-powerful `kube-system` namespace. There is almost
    a 90 percent likelihood that this tiller pod has cluster admin privileges. It
    plays a central role in *helm* *v2*, the packet manager used to deploy and manage
    applications on Kubernetes. We impersonate this node and download tiller’s service
    account token:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Armed with this powerful account, we can catch all secrets with one fat command.
    To hell with node authorization! We write the account token into a valid Kubectl
    config we name *tiller_config* and use it to query the cluster:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'From this, we get over 100 credentials spanning almost every database: Cassandra,
    MySQL, you name it. If it has something to do with the delivery of an ad, rest
    assured that we have a way to access it. We even recovered a few SSH private keys.
    We have no idea how to use them yet, but that should not take us too long to figure
    out.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'We also won a couple of valid AWS access keys, one of which belongs to a developer
    called Kevin Duncan. This will prove handy. We add them to our *credentials* file
    and perform a single API call to confirm they are indeed working:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还获得了几把有效的AWS访问密钥，其中一把属于名为Kevin Duncan的开发人员。这将非常有用。我们将其添加到我们的*凭证*文件中，并执行一次API调用以确认它们确实有效：
- en: '[PRE67]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'And finally, we also make sure to grab that GitHub token belonging to `github-bot-ro`.
    We make sure it is still valid by performing a quick API call using these few
    lines of Python code:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还确保获取了属于`github-bot-ro`的GitHub令牌。我们通过执行以下几行Python代码，确保它仍然有效：
- en: '[PRE68]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: They were right after all. Kubernetes sure is fun!
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 他们最终是对的。Kubernetes确实很有趣！
- en: We can safely say that we currently own MXR Ads’ delivery infrastructure. We
    still don’t know how the profile targeting works or who the end clients of Gretsch
    Politico are, but we can alter, delete, and block all their campaigns—and probably
    much more.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以安全地说，目前我们掌控着MXR Ads的交付基础设施。我们仍然不知道个人资料定向是如何工作的，或者Gretsch Politico的最终客户是谁，但我们可以修改、删除和阻止他们的所有活动—可能还包括更多操作。
- en: Before we dive even deeper into this rabbit hole, we need to secure the position
    we worked so hard to attain. Containers have a high volatility that puts our current
    access at risk. All it would take is a new deployment of the surveys app to kill
    our shell access—and with it, our main entry point to MXR Ads’ Kubernetes cluster.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入这个“兔子洞”之前，我们需要巩固我们辛苦取得的立足点。容器具有很高的波动性，可能会使我们当前的访问权限面临风险。只需要重新部署一次调查应用程序，就能终止我们的Shell访问—这样，我们对MXR
    Ads的Kubernetes集群的主要入口点也将消失。
- en: Resources
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源
- en: 'More info about RBAC in Kubernetes: [https://www.liquidweb.com/kb/kubernetes-rbac-authorization/](https://www.liquidweb.com/kb/kubernetes-rbac-authorization/).'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多关于Kubernetes中RBAC的信息：[https://www.liquidweb.com/kb/kubernetes-rbac-authorization/](https://www.liquidweb.com/kb/kubernetes-rbac-authorization/)。
- en: 'John Lambert’s seminal piece on the defender’s mindset: [https://github.com/JohnLaTwC/Shared](https://github.com/JohnLaTwC/Shared).'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: John Lambert关于防守者心态的开创性文章：[https://github.com/JohnLaTwC/Shared](https://github.com/JohnLaTwC/Shared)。
- en: 'An intro to JSON Web Tokens: [http://bit.ly/35JTJyp](http://bit.ly/35JTJyp).'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON Web令牌简介：[http://bit.ly/35JTJyp](http://bit.ly/35JTJyp)。
- en: 'The Kubernetes API reference: [https://www.sparcflow.com/docs/kube-api-v1.19.html](https://www.sparcflow.com/docs/kube-api-v1.19.html).'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes API参考：[https://www.sparcflow.com/docs/kube-api-v1.19.html](https://www.sparcflow.com/docs/kube-api-v1.19.html)。
- en: 'A list of Kubectl commands: [https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands).'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubectl命令列表：[https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands)。
- en: 'Information on OpenID, an authentication standard used to delegate authentication
    to a third party: [https://developers.onelogin.com/openid-connect/](https://developers.onelogin.com/openid-connect/).'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关OpenID的信息，它是一种用于将身份验证委托给第三方的身份验证标准：[https://developers.onelogin.com/openid-connect/](https://developers.onelogin.com/openid-connect/)。
- en: 'IAM roles attached to pods: [https://docs.aws.amazon.com/eks/latest/userguide/worker_node_IAM_role.html](https://docs.aws.amazon.com/eks/latest/userguide/worker_node_IAM_role.html).'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 附加到Pods的IAM角色：[https://docs.aws.amazon.com/eks/latest/userguide/worker_node_IAM_role.html](https://docs.aws.amazon.com/eks/latest/userguide/worker_node_IAM_role.html)。
- en: 'AWS docs on managing Auto Scaling groups for EKS: [https://amzn.to/2uJeXQb](https://amzn.to/2uJeXQb).'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS关于管理EKS的自动扩展组的文档：[https://amzn.to/2uJeXQb](https://amzn.to/2uJeXQb)。
- en: 'An exploration of network policies in Kubernetes: [https://banzaicloud.com/blog/network-policy/](https://banzaicloud.com/blog/network-policy/).'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索Kubernetes中的网络策略：[https://banzaicloud.com/blog/network-policy/](https://banzaicloud.com/blog/network-policy/)。
- en: 'A walkthrough of installing Helm and Tiller on a Minikube cluster: [http://bit.ly/2tgPBIQ](http://bit.ly/2tgPBIQ).'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Minikube集群上安装Helm和Tiller的操作步骤：[http://bit.ly/2tgPBIQ](http://bit.ly/2tgPBIQ)。
- en: 'An explanation of real-time bidding: [https://digiday.com/media/what-is-real-time-bidding/](https://digiday.com/media/what-is-real-time-bidding/).'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时竞价的解释：[https://digiday.com/media/what-is-real-time-bidding/](https://digiday.com/media/what-is-real-time-bidding/)。
