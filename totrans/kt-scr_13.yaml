- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: 9 AGENT-BASED ALGORITHMS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/icon.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this chapter, we’ll continue to explore NIAs, focusing on two algorithms
    based on the collective behavior of social animals: particle swarm optimization
    and ant colony systems. These algorithms are designed for agent-based models,
    in which a swarm of simple agents work together and interact with their surroundings
    to create outcomes that benefit the whole colony.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll explain the key concepts and principles behind these algorithms and implement
    them using pseudocode. We’ll also put these algorithms to the test by developing
    two Kotlin applications to solve real-world problems. The first is function minimization,
    which uses particle swarm optimization to find the global minimum of a given function.
    The second is the traveling salesman problem, which uses ant colony systems to
    find the shortest route that connects a large number of cities.
  prefs: []
  type: TYPE_NORMAL
- en: '### An Overview of Particle Swarm Optimization'
  prefs: []
  type: TYPE_NORMAL
- en: The particle swarm optimization (PSO) algorithm has been used to solve a wide
    range of optimization problems. PSO has a few similarities with the genetic algorithm.
    Both methods involve working with a population (of chromosomes or particles),
    members of which help us look for an optimal solution until a stopping condition
    is met. Both methods are also stochastic and rely on underlying processes with
    built-in elements of randomness.
  prefs: []
  type: TYPE_NORMAL
- en: That’s where the similarities end. Unlike the genetic algorithm, the PSO algorithm
    does not depend on genetic operators such as selection, crossover, and mutation.
    Instead, it is driven by autonomous agents that update their positions in the
    decision space based on their current and past positions, as well as the best
    position identified by the swarm. PSO involves a deliberate effort to continuously
    move toward a better solution, which is very different from the passive selection-driven
    upgrading of chromosomes in the genetic algorithm. Individual chromosomes do not
    have any ability to sense their neighborhood or make decisions to update their
    composition as the particles do in PSO. Further, PSO is conceptually simpler and
    easier to implement, involves fewer parameters, and tends to converge more quickly
    on the global optima, compared with the genetic algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'At its core, the PSO algorithm consists of three key steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 1.  Initialize the position and velocity of the particles.
  prefs: []
  type: TYPE_NORMAL
- en: 2.  Proceed through the time steps, and update particle velocities based on
    the current velocity, the best-so-far individual position, and the global best
    position identified by the swarm up to that time step.
  prefs: []
  type: TYPE_NORMAL
- en: 3.  Update the current position by moving to a better position.
  prefs: []
  type: TYPE_NORMAL
- en: These steps are repeated for a set number of times or until a stopping condition
    is met.
  prefs: []
  type: TYPE_NORMAL
- en: Let ***x***i⁰ and ***v***i⁰ be the position and velocity vectors at time *t*
    = 0, where *i* ∈ **I** denotes the *i*th particle in a swarm of size N (**I**
    = [1, 2, . . . , N]). Also, let ***x***max and ***x***min be the upper and lower
    bounds for the position vector and *r* be a random value between 0 and 1 selected
    from a uniform distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The first step of PSO is to initialize the position and velocity vectors as
    shown in Equations 9.1 and 9.2.
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.1)$Equation$ (9.2) ![](../images/eq9-1-2.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: In Equation 9.2, for the purposes of this chapter, we set the initial velocities
    to zero. The alternative is to set them to small random values. In most cases,
    the swarm will quickly move away from the randomly assigned initial position,
    and the choice of initial velocity will not have a noticeable impact on the convergence
    rate as long as the magnitude of the velocity stays within the decision space.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second step of PSO is to update the velocity vector $Equation$ ![](../images/pg347-in-1.jpg)
    for the particles by using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.3) ![](../images/eq9-3.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: 'The variables and parameters in Equation 9.3 stand for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*w*             Inertia factor'
  prefs: []
  type: TYPE_NORMAL
- en: c1            Particle memory/cognitive factor
  prefs: []
  type: TYPE_NORMAL
- en: c2            Swarm memory/social factor
  prefs: []
  type: TYPE_NORMAL
- en: r1, r2       Random values between 0 and 1 chosen from a uniform distribution
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ ![](../images/pg347-in-2.jpg)            Best position vector found
    by particle *i* up to time *t*
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ ![](../images/pg347-in-3.jpg)            Best position vector found
    by the swarm up to time *t*
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ ![](../images/pg347-in-4.jpg) Velocity vectors of particle *i* at
    time *t* and *t* + 1, respectively
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ ![](../images/pg347-in-5.jpg)            Position vector of particle
    *i* at time *t*
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 9-1](chapter9.xhtml#fig9-1) provides a visual and more intuitive interpretation
    of Equation 9.3.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-1: A graphical representation of the strategy for updating velocity
    in PSO'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider an arbitrary particle *i* whose current position is $Equation$
    ![](../images/pg347-in-6.jpg) (for simplicity’s sake, we’ll consider a one-dimensional
    problem). Because of inertia, the particle will tend to move toward the direction
    of its current velocity, $Equation$ ![](../images/pg347-in-7.jpg). However, PSO
    relies on learning from both particle- and swarm-level best solutions found so
    far—$Equation$ ![](../images/pg347-in-8.jpg) and $Equation$ ![](../images/pg347-in-9.jpg).
    As a result, the particle incorporates this information by moving a bit toward
    $Equation$ ![](../images/pg347-in-10.jpg) ❶ and then toward $Equation$ ![](../images/pg347-in-11.jpg)
    ❷, as well as toward its own velocity $Equation$ ![](../images/pg347-in-12.jpg)
    ❸. [Figure 9-1](chapter9.xhtml#fig9-1) shows the result of all these movements
    as $Equation$ ![](../images/pg347-in-13.jpg). Equation 9.3 captures the same movements
    symbolically in multiple dimensions, along with the relative weights assigned
    to each of these components.
  prefs: []
  type: TYPE_NORMAL
- en: The inertia factor *w* is typically assigned a value between 0 and 1, where
    a value of 0 would imply no impact of $Equation$ ![](../images/pg347-in-14.jpg)
    on $Equation$ ![](../images/pg347-in-15.jpg) and 1 would imply full impact. It
    is also possible to adjust the value of *w* over time, which can lead to better
    convergence properties. This scheme is implemented by initially setting *w* to
    ≥ 1 and gradually decreasing it per Equation 9.4.
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.4) ![](../images/eq9-4.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: The c1 and c2 factors in Equation 9.3 are also called *acceleration coefficients*.
    Along with the random variables r1 and r2, these coefficients determine the degree
    of influence of the particle-best and swarm-best positions on the updated velocity
    of a particle.
  prefs: []
  type: TYPE_NORMAL
- en: As is evident from Equation 9.3, when both c1 and c2 = 0, particles will keep
    moving at constant velocities until they hit the boundaries of the decision space.
    If c1 > 0 and c2 = 0, particles will behave as if they’re independent (no information
    gathered from the swarm). When c1 = 0 and c2 > 0, the entire swarm will move toward
    the best position found collectively so far.
  prefs: []
  type: TYPE_NORMAL
- en: 'While the optimal values for these parameters are likely to be problem specific,
    the commonly used values found in the literature range from 0.5 to 2.5 for both
    c1 and c2\. It is also common practice to keep c1 equal to c2 and ensure both
    values are relatively small to allow for a thorough exploration of the decision
    space without causing *velocity explosion*, which refers to excessive velocity
    and large jumps across the decision space. To avoid this, an upper limit for the
    velocity of particle *i* along dimension *j* is set as follows (for all time steps):'
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.5) ![](../images/eq9-5.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.6) ![](../images/eq9-6.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: 'The final step for PSO is to update the position vector of particle *i* for
    the next time step *t* + 1 as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.7) ![](../images/eq9-7.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: As with velocities, the updated position vectors will also have to be checked
    against the specified bounds for the decision variables.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing PSO for Function Minimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can use the PSO algorithm to either maximize or minimize a function. In this
    chapter, we’ll apply PSO to function minimization. Consequently, when aiming to
    minimize a multivariate function by using this implementation, we don’t need to
    multiply the objective function value by –1, as we did for function minimization
    in [Chapter 8](chapter8.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: In contrast to the other algorithms covered in this book, the PSO algorithm
    involves more interlinked steps, which makes it difficult to understand and code
    the algorithm without a thorough overview of the entire process. To address this,
    I’ll provide pseudocode outlining the entire process to guide us through actual
    code development. *Pseudocode* is a high-level description of an algorithm or
    a computer program. It’s written in plain language that closely resembles the
    structure of a programming language, but it is not meant to be executed on a computer.
    It allows programmers to plan out and communicate the logic of a program without
    getting bogged down in the details of a specific programming language.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s the pseudocode for the PSO algorithm. Notice that we’ve used boldface
    to mark where loops and conditional blocks begin and end, as well as to emphasize
    specific tasks carried out by code segments.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We’ll follow this pseudocode closely as we develop the code for implementing
    the PSO algorithm in the next project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 36: Optimize a Multivariate Function with a Particle Swarm'
  prefs: []
  type: TYPE_NORMAL
- en: For this project, we’ll revisit the Eggholder function optimization problem
    defined in [Chapter 8](chapter8.xhtml), this time solving it with the PSO algorithm
    rather than with the genetic algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We’ll develop the code for the PSO algorithm following the pseudocode provided
    earlier and discuss its implementation in four segments: problem definition and
    global parameters, initializing the swarm, the runPSO() driver function, and the
    main() function.'
  prefs: []
  type: TYPE_NORMAL
- en: Problem Definition and Global Parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This segment is composed of an import block, a collection of classes, global
    variables and parameters, and lists to save particle states and best solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The first block in the code snippet imports a number of math functions from
    the standard Kotlin library. The next two blocks define the data classes used
    for this project. The Solution() class is used to store particle-best and swarm-best
    solutions ❶. The Particle() class is the primary class that is used to create
    a swarm ❷. Each particle has an identification number (id), position and velocity
    vectors (pos and vel), a fitness property, and a Solution property. The latter
    is used to store information on the best solution identified by the particle up
    to a certain point in time.
  prefs: []
  type: TYPE_NORMAL
- en: The next code block defines the eggHolder function ❸ and its dimensions in nDim
    (equal to 2 for the Eggholder function). It also defines the bounds and ranges
    for pos and vel and then defines vMax per Equation 9.5 to ensure that updated
    velocities remain within the set bounds.
  prefs: []
  type: TYPE_NORMAL
- en: The final code block defines PSO-specific global parameters. Currently, the
    maximum number of time steps (iterations) is set to 50, and the swarm size is
    set to 30\. We’ll also dynamically adjust the inertia factor *w* per Equation
    9.4 for which wmax and wmin have been set to 1.2 and 0.5, respectively. The cognitive
    and social factors c1 and c2 have been set to 2.0\. These parameter values were
    chosen based on the recommendations found in the relevant literature.
  prefs: []
  type: TYPE_NORMAL
- en: The code block ends by creating a mutable list (swarm) and initializing BestSolution,
    which we’ll use to store the swarm-best solution. Since we’re framing the problem
    as a minimization problem, the fitness value of the BestSolution has been set
    to Double.MAX_VALUE, which is the maximum possible of type Double.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the Swarm
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The initSwarm() function is responsible for initializing the PSO algorithm by
    creating and initializing individual particles and adding them to the collection
    of particles (the swarm).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The function begins by printing a message indicating the start of the initialization
    process. It then iterates using a for loop over a specified swarm size (SWARMSIZE)
    ❶, creating individual particles with random initial positions within predefined
    bounds for each dimension ❷. The initial velocities for each particle are set
    to zero, per Equation 9.2.
  prefs: []
  type: TYPE_NORMAL
- en: The getFitness function allows us to calculate the fitness value for each particle
    ❸. Notice that during initialization, the personal best fitness is the same as
    its current fitness, meaning that pBest initially has the same position and fitness
    as the particle. These particles are characterized by identification number (id),
    position (pos) and velocity (vel) vectors, a fitness value (fitness), and a personal
    best solution (pBest). We use these attributes to create the particles and add
    them to the swarm ❹.
  prefs: []
  type: TYPE_NORMAL
- en: The best solution across the entire swarm is updated if a particle’s fitness
    is better than the current best ❺. After initialization, the function prints the
    best solution.
  prefs: []
  type: TYPE_NORMAL
- en: The Driver Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The code block for the runPSO() driver function carries out all the core tasks
    of PSO, including updating the velocity and position vectors and tracking the
    personal- and swarm-level best solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Unlike the runGA() function for implementing the genetic algorithm, the runPSO()
    function is self-sufficient and doesn’t rely on any helper functions other than
    getFitness(), which simply calculates the value of the function being minimized.
    It iterates over a fixed number of time steps (TMAX) ❶, beginning each iteration
    by initializing the inertia factor (w) and the random factors r1 and r2.
  prefs: []
  type: TYPE_NORMAL
- en: For each time step, the code loops over each particle in the swarm ❷ and updates
    its velocity and position vectors according to the PSO formula. The code also
    implements bounds for the velocity and position values, using the minimum and
    maximum values defined in the arrays vMax and xBbounds.
  prefs: []
  type: TYPE_NORMAL
- en: The code evaluates the fitness of each particle by using the getFitness() function
    ❸, which takes the position vector as an input and returns the corresponding fitness
    as a scalar value.
  prefs: []
  type: TYPE_NORMAL
- en: The code then compares each particle’s current fitness with its personal best
    fitness (pBest) and updates the latter if the former is lower ❹. It also compares
    the current fitness with the global best fitness (BestSolution) and updates the
    latter if the former is lower ❺. The personal and global best solutions store
    both the position and the fitness values.
  prefs: []
  type: TYPE_NORMAL
- en: The function terminates when it completes TMAX iterations. It doesn’t return
    anything, since the best overall solution is saved as the global object BestSolution.
  prefs: []
  type: TYPE_NORMAL
- en: The main() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This function is a short code block that prints values of key global parameters,
    calls other functions to initialize the swarm and run the PSO driver function,
    and prints the best solution found.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The main() function is the entry point of the program that uses PSO to perform
    real-valued function optimization. It prints some information about the problem
    parameters, such as the function dimensions, the swarm size, the maximum time
    steps, and the PSO coefficients.
  prefs: []
  type: TYPE_NORMAL
- en: The function then calls two other functions, initSwarm() and runPSO(). The first
    function initializes the swarm of particles with random positions and velocities
    and evaluates their initial fitness values. The second function runs the PSO algorithm
    for a fixed number of iterations, updating the particles’ velocities, positions,
    and fitness values, as well as the personal and global best solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The main() function finally prints the best solution found by the PSO algorithm
    after the specified number of iterations, showing both the position vector and
    the fitness value of the global best solution.
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'I’ve deliberately kept the output of the PSO program brief and to the point.
    By now, you should be comfortable with writing your own additional lines of code
    to print or save other intermediate results for further analysis or visualization.
    If you run the code with the same parameters used in this example, the output
    might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The first segment of the output shows the values of key global parameters. Next,
    it shows the best solutions at the start and the end of the iterations. The PSO
    algorithm achieved a near-optimal solution for the Eggholder function within the
    given decision space, matching the result obtained by the genetic algorithm in
    [Chapter 8](chapter8.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 9-2](chapter9.xhtml#fig9-2) shows the convergence behavior of the PSO
    algorithm over time when applied to the Eggholder function. Unlike the genetic
    algorithm discussed in [Chapter 8](chapter8.xhtml), PSO achieves optimal solutions
    more rapidly, requiring fewer iterations.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-2: The convergence pattern for the Eggholder function, using the particle
    swarm algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: PSO seems to have an advantage over the genetic algorithm for this problem.
    Though the PSO algorithm had a worse initial global best fitness value of around
    –742, compared to –810 for the genetic algorithm, it reached the global optimum
    in about 40 iterations, while the genetic algorithm took 117 iterations. This
    suggests that the PSO algorithm can explore and exploit the search space more
    efficiently than the genetic algorithm for the Eggholder function. This efficiency
    likely stems from PSO’s unique approach to exploring the solution space through
    collaborative particle interactions.
  prefs: []
  type: TYPE_NORMAL
- en: I encourage you to use this code to solve other known test problems and further
    investigate how the PSO algorithm performs vis-à-vis the genetic algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Ant Colony Optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ant colony optimization (ACO) refers to a family of algorithms that are based
    on lessons learned from real-world ants, especially from their foraging behavior.
    The original algorithm, known as the ant system (AS), was proposed by Marco Dorigo
    in 1992\. Since then, the algorithm has been modified several times to help it
    more effectively solve a class of problems that requires finding the least-cost
    tour through all nodes of a weighted graph. In discrete mathematics, a graph is
    a set of nodes or vertices that are related, and the imaginary or real line connecting
    a pair of nodes is called an *edge*. (You can revisit [Chapter 7](chapter7.xhtml)
    for a review of graphs and conventional graph-search algorithms.)
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the basic concept of ACO, let’s review the simple illustration
    in [Figure 9-3](chapter9.xhtml#fig9-3) of ants exploring the best paths to a source
    of food.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-3: Ants exploring different trails leading to the food source'
  prefs: []
  type: TYPE_NORMAL
- en: When ants start looking for a food source, they initially disperse randomly
    in all directions, as shown in [Figure 9-3(a)](chapter9.xhtml#fig9-3). As they
    move, they lay down a scent (pheromone) to mark their trails. Once an ant finds
    a food source, it picks up a piece of food and brings that back to the nest by
    following its scent mark. It also lays down more pheromones as it returns to the
    nest.
  prefs: []
  type: TYPE_NORMAL
- en: In the meantime, other ants notice the trail. Given more than one source, each
    trail will develop a scent mark of greater or lesser intensity, depending on how
    many ants are traveling back and forth along that trail and how far the source
    is from the nest. In general, the stronger the scent mark of a trail, the greater
    the number of ants following that trail will be. Once a food source is found,
    ants will therefore follow the most well-defined trails, as shown in [Figure 9-3(b)](chapter9.xhtml#fig9-3).
  prefs: []
  type: TYPE_NORMAL
- en: Crucially, pheromones are not permanent—they tend to decay or evaporate over
    time. If a trail is not frequently visited, it gradually becomes less traceable
    and eventually is forgotten. Additionally, the closest food source will take the
    least amount of time to visit, which means the corresponding trail will be traveled
    more frequently, which will result in a stronger concentration of pheromone—which
    will create a positive feedback loop and attract even more ants to choose the
    shortest route. Over time, most of the ants will start to use this shortest route
    (the optimal path), as shown in [Figure 9-3(c)](chapter9.xhtml#fig9-3). The ant
    colony will have used a very simple rule to solve a very difficult combinatorial
    optimization problem!
  prefs: []
  type: TYPE_NORMAL
- en: In this ingenious natural scheme, individual agents (ants) do not have any idea
    about the impact of their actions on the entire colony. And yet by repeating their
    simple routine, they enable the colony to find its food sources as efficiently
    as if the whole search process were centrally coordinated.
  prefs: []
  type: TYPE_NORMAL
- en: '#### The ACS Algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: Based on the conceptual model presented in the previous section, we can envision
    the key components of ACO as creating a colony of artificial ants, moving ants
    from one node to the next based on pheromone intensity and the distance between
    the nodes, and updating the pheromone trails until the shortest route is found.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll explore an enhanced version of ACO called the ant colony
    system (ACS). The ACS algorithm is implemented in three key steps: constructing
    a tour, updating a local pheromone trail, and updating a global pheromone trail.
    We’ll discuss each of these steps in detail shortly.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the ACS algorithm to solve a particular case of the traveling salesman
    problem (TSP), which belongs to a class of hard-to-solve problems called the NP-hard
    problems. Mathematically speaking, a problem is *NP-hard* if it is at least as
    hard as the hardest problem in NP, a class of problems for which a solution can
    be verified in polynomial time. It is beyond the scope of this book to discuss
    the NP-hard problems further; instead, we will focus on how to use ACS to solve
    TSPs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Solving a TSP entails answering the following question:'
  prefs: []
  type: TYPE_NORMAL
- en: Given a list of nodes and the distances between every pair of those nodes, what
    is the shortest possible route a traveler can take that passes through each node
    exactly once and brings the traveler back to the start node?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, we’re looking for a closed-loop solution that goes through each
    node and has the shortest possible length. Notice that it is theoretically possible
    for multiple routes to have the same shortest length of travel.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll make two additional assumptions regarding the form of TSP we’ll try to
    solve:'
  prefs: []
  type: TYPE_NORMAL
- en: The network of nodes (graph) is fully connected, meaning a traveler can visit
    from any particular node to all other remaining nodes (during implementation,
    we’ll exclude the nodes that have already been visited).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The distance between any pair of nodes is symmetric, meaning the distance does
    not change with the direction of travel (a pair of nodes are connected by a single,
    unique path—an edge).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Symbols and Their Meanings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: ACS is a fairly complex algorithm with many parameters and variables, listed
    in [Table 9-1](chapter9.xhtml#tab9-1) along with the symbols used to represent
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 9-1: Symbols Used in the ACS Algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: '| Symbol | Interpretation |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ![](../images/pg358-in-1.jpg) | The neighborhood of ant k when it is at node
    i; it is a set of nodes that an ant is allowed to visit given its current location.
    |'
  prefs: []
  type: TYPE_TB
- en: '| τij | The pheromone intensity of edge [i, j] connecting node i to node j.
    |'
  prefs: []
  type: TYPE_TB
- en: '| τ0 | Initial pheromone level for all edges, set to 1/(nCnn); n is the total
    number of nodes in the nearest-neighbor tour and Cnn is the tour length. |'
  prefs: []
  type: TYPE_TB
- en: '| dij | The length of the edge from node i to node j (distance between these
    nodes). Also, dij = dji. |'
  prefs: []
  type: TYPE_TB
- en: '| ηij | Heuristic information defined as 1/dij. |'
  prefs: []
  type: TYPE_TB
- en: '| α | Parameter, set to 1 for ACS. |'
  prefs: []
  type: TYPE_TB
- en: '| ß | Parameter [2.0–5.0], used as the exponent of η. |'
  prefs: []
  type: TYPE_TB
- en: '| q | A uniformly distributed random variable in [0, 1]. |'
  prefs: []
  type: TYPE_TB
- en: '| q0 | A parameter in (0, 1); an ant explores the learned knowledge based on
    the intensity of pheromone trails and heuristics when q ≤ q0. |'
  prefs: []
  type: TYPE_TB
- en: '| pij | The normalized probability for choosing edge [i, j] during roulette
    wheel selection if q > q0. |'
  prefs: []
  type: TYPE_TB
- en: '| ζ | Parameter, set to a small value such as 0.005; used as the weighting
    factor for updating the local pheromone trail. |'
  prefs: []
  type: TYPE_TB
- en: '| ρ | Parameter, set to the recommended value of 0.1 for ACS; used as the weighting
    factor for updating the best-so-far global pheromone trail. |'
  prefs: []
  type: TYPE_TB
- en: '| Cnn | Tour length for the nearest-neighbor tour used for estimating initial
    pheromone concentration. |'
  prefs: []
  type: TYPE_TB
- en: '| Cbs | Tour length for the best-so-far solution or tour. |'
  prefs: []
  type: TYPE_TB
- en: '| T bs | The best-so-far tour (collection of edges that constitute the tour).
    |'
  prefs: []
  type: TYPE_TB
- en: In addition to listing the parameters and variables, [Table 9-1](chapter9.xhtml#tab9-1)
    also provides short descriptions of those elements. (You may need to revisit these
    descriptions as you read the rest of this section.)
  prefs: []
  type: TYPE_NORMAL
- en: The Steps of ACS
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we’ll explore the key steps of the ACS algorithm, expressed
    mathematically. This will include three steps: tour construction, updating the
    local pheromone trail, and updating the global pheromone trail.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Tour Construction'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The first step of ACS entails applying a pseudorandom proportional rule used
    by an ant to choose its next location *j* given its current location *i*, defined
    in Equation 9.8.
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.8) ![](../images/eq9-8.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: The *argmax* function in Equation 9.8 chooses an argument *l* from the feasible
    set of nodes that can be visited from node *i*, for which the expression inside
    the curly brackets is maximized. This value of *l* is set to *j* as the next destination
    for the ant provided *q* ≤ *q*[0]. The parameter *q*[0] allows us to control the
    degree to which learned knowledge (pheromone trails and heuristics) is prioritized
    over random exploration of new routes.
  prefs: []
  type: TYPE_NORMAL
- en: 'When *q* > *q*[0], the next node *j* is set to *J*, which is a random variable
    selected using a roulette wheel scheme. Equation 9.9 estimates the normalized
    probabilities for the feasible paths from node *i* to node *j* for ant *k*:'
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.9) ![](../images/eq9-9.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: For a refresher on the roulette wheel scheme, please review “Selection” on [page
    312](chapter8.xhtml#pg_312) in [Chapter 8](chapter8.xhtml). This time, we’ll implement
    the scheme in our final coding project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Updating the Local Pheromone Trail'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As soon as an ant moves from node *i* to node *j*, the weighted average scheme
    in Equation 9.10 is applied to update the local pheromone trail.
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.10) ![](../images/eq9-10.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: In the original ACO, no local updates occur, which allows one to implement the
    tour construction either sequentially or concurrently. When tours are built concurrently
    (in parallel), they can result in significant computational time savings for large
    real-world problems. Due to the local updating rule of ACS, it is implied that
    the process will be implemented sequentially. This is because the tour created
    by a specific ant is influenced by the preceding ants’ local updates to the pheromone
    trails.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Updating the Global Pheromone Trail'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Once all ants are done building their tours, the global pheromone update rule
    is applied once per iteration and only along the edges of the best-so-far tour,
    *T*^(bs), as shown in Equation 9.11.
  prefs: []
  type: TYPE_NORMAL
- en: $Equation$ (9.11) ![](../images/eq9-11.jpg)
  prefs: []
  type: TYPE_NORMAL
- en: Equation 9.11 implies that *T*^(bs) will need to be compared with the best solution
    identified by the colony at the end of each iteration and then be updated as needed.
  prefs: []
  type: TYPE_NORMAL
- en: The Pseudocode
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The following pseudocode shows how the components of the ACS algorithm come
    together to form a sophisticated heuristic algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We’ll follow this pseudocode to develop a complete ACS application in Kotlin
    in the next project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Project 37: Solve the Traveling Salesman Problem with an Ant Colony System'
  prefs: []
  type: TYPE_NORMAL
- en: In this project, we’ll solve the well-known test problem Berlin52\. This is
    a combinatorial optimization problem that involves finding the shortest route
    through 52 destinations in Berlin, Germany. The dataset for this problem was retrieved
    from TSPLIB, which is a collection of traveling salesman problems with known global
    optimal solutions. See “Resources” on [page 377](#pg_377) for the download link
    for these problems, which you can try solving by using the ACS algorithm and other
    NIAs discussed in this book.
  prefs: []
  type: TYPE_NORMAL
- en: The Code
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Berlin52 TSP requires datasets for 52 different locations. It’s more convenient
    to create a separate datafile for this project (for example, a file in CSV format)
    and read the location data from the file at runtime. So we’ll adopt that approach
    for this project.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll discuss the code segments in four primary blocks: problem definition
    and global parameters, the main() block, the runACS() driver function and its
    helper functions, and additional intermediate and postprocessing of results.'
  prefs: []
  type: TYPE_NORMAL
- en: '##### Problem Definition and Global Declarations'
  prefs: []
  type: TYPE_NORMAL
- en: This segment specifies the import block and defines the input file location,
    global variables and parameters, and a collection of classes, lists, and arrays
    required to implement the ASC algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The code segment begins by importing the required methods from the standard
    Kotlin and Java libraries. We’ll use java.io.File to read data from an input file
    from a specified location (in this case, from *berlin52.csv*) ❶. (The input file
    you’ll use will likely have a different location, so you must change the input
    file location as needed.)
  prefs: []
  type: TYPE_NORMAL
- en: 'The input file for the Berlin52 TSP follows a set format. The first value in
    the initial line contains a brief title describing the problem, while subsequent
    values serve as column headers for the data points. From the second line to the
    last, city-specific information is presented in groups of four comma-separated
    values (hence the file extension *.csv*): city name, city identification, x-coordinate,
    and y-coordinate, respectively. Each row contains data for a particular city or
    location.'
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the datafile consists of 53 lines, including the introductory
    line that provides descriptive information. [Table 9-2](chapter9.xhtml#tab9-2)
    shows how the file will look when you open it with Microsoft Excel or another
    spreadsheet program.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 9-2: Input File Format for the Berlin52 TSP'
  prefs: []
  type: TYPE_NORMAL
- en: '| Berlin52 | ID | X | Y |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| C1 | 0 | 565 | 575 |'
  prefs: []
  type: TYPE_TB
- en: '| C2 | 1 | 25 | 185 |'
  prefs: []
  type: TYPE_TB
- en: '| C3 | 2 | 345 | 750 |'
  prefs: []
  type: TYPE_TB
- en: '| C4 | 3 | 945 | 685 |'
  prefs: []
  type: TYPE_TB
- en: '| C5 | 4 | 845 | 655 |'
  prefs: []
  type: TYPE_TB
- en: '| C6 | 5 | 880 | 660 |'
  prefs: []
  type: TYPE_TB
- en: '| ... | ... | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| C50 | 49 | 595 | 360 |'
  prefs: []
  type: TYPE_TB
- en: '| C51 | 50 | 1340 | 725 |'
  prefs: []
  type: TYPE_TB
- en: '| C52 | 51 | 1740 | 245 |'
  prefs: []
  type: TYPE_TB
- en: The next code block declares all the global parameters ❷. For example, the number
    of cities (numCities) is set to 52, the number of ants (numAnts) is set to 30,
    the maximum number of iterations per round (iterMax) is set to 300, and the number
    of times the entire process is repeated (maxRounds) is set to 50\. The comments
    next to the parameters indicate suggested ranges or values for these parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we define the classes and collections used in this project ❸. The City
    data class stores information on the locations to visit, including their names,
    ID numbers, and coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: The Ant class is used to create the ant colony, which is at the heart of ACS.
    The Ant class has several properties required for managing and monitoring ant
    movements. In particular, citiesToVisit dynamically keeps track of the remaining
    cities to visit, pathNodes stores the start and the end nodes for each path (edge)
    already traversed, and pathSegments stores the corresponding edge lengths. This
    class also has a method called setCitiesToVisit() that defines the initial list
    of cities each ant can visit.
  prefs: []
  type: TYPE_NORMAL
- en: The ArgMax class is used during the tour construction phase. The Solution class
    stores information on completed tours, including the nodes and edges comprising
    a tour and its fitness value (length of the tour).
  prefs: []
  type: TYPE_NORMAL
- en: These classes are followed by a block that initializes a number of collections,
    arrays, and parameters. For example, cities is used to build a list of locations
    to visit, and ants is used to create the ant colony. Others are used to store
    ant solutions (antSolutions), best solutions (bestSolutions), and the best overall
    tour (bestOverallTour).
  prefs: []
  type: TYPE_NORMAL
- en: We use two-dimensional arrays to store information on the edges (edges) and
    corresponding pheromone levels (pheromone) and edge probabilities (prob). The
    final two lines set the default values for the best overall fitness (bestOverallFitness)
    and the counter variable optimaCount.
  prefs: []
  type: TYPE_NORMAL
- en: The main() Block
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The main() block is a minimal block with a few function calls and print functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The function starts by printing a problem-specific message on the console and
    then moves on to the preprocessing block. It calls the readCities() function to
    read off the location data from the input file. The calculateEdges() function
    uses the location coordinates to estimate the distances between pairs of nodes.
    The calculatePheromone0() function finds the nearest-neighbor tour length *C*^(nn)
    and uses that to estimate the initial pheromone levels *τ*[0] for all edges.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we introduce a for loop ❶ to carry out the entire ACS process a set number
    of times (maxRounds). The Berlin52 TSP is a challenging problem, and the ACS algorithm
    may not be able to locate the global optimal solution during each round of the
    ACS process, which involves iterMax attempts.
  prefs: []
  type: TYPE_NORMAL
- en: Inside the for loop, the initializePheromone() function ❷ sets the initial pheromone
    level for all edges of the graph. Next, the driver function runACS() carries out
    the search for the optimal route. The processInterimResults() function updates
    the best overall fitness and best overall tour values, then prints the best solution
    for each round of search. Finally, the list of best solutions is cleared before
    starting the next round ❸.
  prefs: []
  type: TYPE_NORMAL
- en: The success rate of the ACS algorithm depends on the combination of global parameter
    values and the random initialization of the ants and their start nodes (in addition
    to the random selection of edges that happens during the implementation of the
    algorithm). In general, when a heuristic algorithm gets stuck at a local optimum
    even after attempting to find the global optimal solution a reasonable number
    of times, it may be beneficial to restart the entire process by resetting the
    initial conditions and changing the global parameters if needed, rather than increasing
    the number of iterations. The for loop in the main() block helps us automatically
    reset and restart the ACS process and carry it out maxRounds times.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that we need to read the input data, calculate edge lengths, and calculate
    the initial pheromone level only once. Thus, those tasks are completed before
    initiating the for loop inside the main() block. However, we need to reset the
    pheromone levels to *τ*[0] each time we call the runACS() function.
  prefs: []
  type: TYPE_NORMAL
- en: The main() block ends with printing the best overall fitness and tour (from
    all rounds and iterations). It also prints the number of times the algorithm was
    successful in finding the global optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: The readCities() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The sole purpose of this function is to read the location data from an input
    file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The Java File class ❶ opens the input file from a location specified in the
    datafile string. The entire content of the datafile is read into memory as an
    array of strings (lines) ❷. We are applying .filterNot{it.isEmpty()} to file.readLines()
    to make reading the file safer with respect to empty lines.
  prefs: []
  type: TYPE_NORMAL
- en: Then, each line is split by using a comma (,) as the separator ❸ (recall that
    the input file was created as a comma-separated value, or CSV, file). Finally,
    different parts of the split line are used to create a list of nodes (cities)
    by using the City class ❹.
  prefs: []
  type: TYPE_NORMAL
- en: The calculateEdges() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The purpose of this function is to calculate and save the edge lengths (path
    segments) of a tour.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The edge lengths are saved in a two-dimensional array, where the diagonal elements
    (i = j) are set to 0.0 ❶ (the distance of a node from itself is zero), and the
    off-diagonal elements are set to Euclidian distances between a pair of nodes ❷.
    We’re assuming that a pair of nodes is connected by a single edge or path. This
    allows us to calculate only the upper triangle of the matrix and set the lower
    triangle values by using the property of symmetry ❸.
  prefs: []
  type: TYPE_NORMAL
- en: The calculatePheromone0() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This function calculates the nearest-neighbor tour length *C*^(nn) and uses
    that to estimate the initial pheromone level, pheromone0.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This function finds the nearest-neighbor tour by starting the tour from node
    0 ❶ and moving to the nearest nodes with a while loop ❷ until all nodes or cities
    are visited. At each step, the shortest edge is identified and added to the nearest-neighbor
    tour length ❸. Once the node is added to the tour, it is removed from the list
    of cities to visit ❹. The tour is closed by connecting the last node visited to
    the start node and adding the corresponding edge length to the total tour length
    ❺. Finally, the initial pheromone level pheromone0 is calculated as equal to 1/(*nC*^(nn))
    ❻.
  prefs: []
  type: TYPE_NORMAL
- en: The initializePheromone() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This function sets initial pheromone levels for all edges of the graph to pheromone0.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The pheromone levels are stored in a two-dimensional array (a matrix), and the
    property of symmetry is used to calculate the lower triangle elements of the matrix
    by setting *τ*ji = *τ*ij. Notice that when *i* = *j*, the node is simply referring
    to itself, and the corresponding diagonal elements are set to 0.0\. These values
    are not required or used by the ACS algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The runACS() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The runACS() function creates the ant colony, coordinates the tour construction
    for individual ants, saves intermediate results, and implements the global pheromone
    update rule. We’ll begin by providing an overview of the key elements of this
    function, which will be followed by discussions on the individual helper functions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The code segment begins by setting the iteration counter iter to 1. A while
    loop is used to repeat the search iterMax times. Inside the loop, initializeAnts()
    creates the ant colony for a specific iteration ❶.
  prefs: []
  type: TYPE_NORMAL
- en: Once the ant colony is initiated, a tour for each ant is constructed inside
    a for loop. The process starts with setting a list of cities to visit for each
    ant ❷ by invoking the setCitiesToVisit() method of the Ant class. The actual tour
    is built by the buildAntTour() function ❸.
  prefs: []
  type: TYPE_NORMAL
- en: Once the optimal tour for an individual ant is completed, relevant information
    is saved in antSolutions ❹. The best of all ant solutions (for the current iteration)
    is found by using the minWith() function of Kotlin ❺, which is then added to the
    bestSolutions list ❻. At this stage, the globalPheromoneUpdate() function is called
    to apply the global pheromone update rule ❼. Next, ants and antSolutions are cleared
    in preparation for the next iteration. Finally, iter is incremented by 1 ❽; the
    process will exit the while loop when iter > iterMax.
  prefs: []
  type: TYPE_NORMAL
- en: The initializeAnts() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The code snippet for the initializeAnts() function is very short.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This code begins by creating a list of indices, each designating a city or node.
    Next, it creates the ants one by one and assigns each ant a start node selected
    randomly from the list of cities to visit.
  prefs: []
  type: TYPE_NORMAL
- en: This scheme allows multiple ants to have the same start node, while some nodes
    may not have any ants assigned to them. This flexibility is beneficial when the
    number of ants differs from the number of nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '##### The buildAntTour() Function'
  prefs: []
  type: TYPE_NORMAL
- en: This function identifies the next node to visit, updates relevant ant properties
    to reflect that choice, and recursively builds the entire tour. It also calculates
    the ant fitness when the tour is complete and applies the local pheromone update
    for each edge traveled.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The function starts with setting the current location index i to the ant’s currentNode
    property (which is initially the same as startNode) ❶. Subsequent nodes to visit
    are found by using a while loop until the list of cities to visit is exhausted.
    The process of selecting the next node is quite involved and is implanted by selectNodeToVisit()
    ❷, a function we’ll discuss in more detail shortly.
  prefs: []
  type: TYPE_NORMAL
- en: After locating nextNode, the local pheromone update rule is applied ❸, and the
    currentNode property of the ant is set to nextNode. At this time, relevant ant
    properties are updated based on the move from node i to nextNode. Before repeating
    the iteration for the next node or city to visit, the current node index i is
    updated to currentNode (that is, to the most recent nextNode) and then nextNode
    is removed from the list of cities to visit ❹.
  prefs: []
  type: TYPE_NORMAL
- en: Once the ant is done visiting all the cities it is allowed to visit, the tour
    is closed by connecting the last city visited to the city from which the ant started
    its tour. This is done by updating the ant’s pathNodes and pathSegments properties.
    When the tour is complete, its fitness (length) is calculated ❺, and the local
    pheromone update rule is applied one more time for the last segment of the tour
    ❻.
  prefs: []
  type: TYPE_NORMAL
- en: The selectNodeToVisit() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This function implements the most mathematically involved part of the ACS algorithm
    that uses both an argmax type function and the roulette wheel scheme to decide
    which node to visit next.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The function first creates local variables for saving the chosen node (chosenNode,
    initially set to an unlikely value) and a mutable list to which an argmax operation
    will be applied per Equation 9.8\. Next, edge-specific raw probabilities are calculated
    inside the first for loop ❶. This loop also populates the argmaxList, which stores
    the possible destination node index *j* as its index property and the corresponding
    prob[i][j] (before being normalized) as its value. The second for loop ❷ converts
    the raw probabilities to normalized probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: After the initial processing, a random number *q* is drawn from a uniform distribution
    ❸. If *q* <= *q*[0], the argmax rule is used to choose the next node index ❹.
    Otherwise, Equation 9.9 is used to find the next node index by using the roulette
    wheel scheme ❺. In particular, when the spin value is less than or equal to the
    sum of normalized probabilities up to index *j*, we set chosenNode equal to *j*
    ❻ and break out of the loop. Finally, the value of chosenNode is returned ❼.
  prefs: []
  type: TYPE_NORMAL
- en: The globalPheromoneUpdate() Function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This function applies the global pheromone update rule once all ants finish
    building their tours for a particular iteration.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This function has two key steps. First, it identifies the best-so-far solution
    since the beginning of the iterations inside the while loop of runACS(). Next,
    pheromone levels are updated only for the edges (path segments) that belong to
    the best-so-far tour.
  prefs: []
  type: TYPE_NORMAL
- en: Other Functions in the main() Block
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The other functions in the main() block are not part of the ACS algorithm. Instead,
    we use these functions to monitor the convergence of the algorithm and to print
    final values of the best overall fitness and corresponding solution at the end.
  prefs: []
  type: TYPE_NORMAL
- en: The processInterimResults() function helps save and print intermediate results
    after the completion of each round of calculations inside the for loop of the
    main() function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This function first sorts the bestSolutions to find the best-so-far solution
    based on the fitness values of the solutions ❶. Next, it updates the value of
    bestOverallFitness, the best fitness found from all rounds up to this point ❷.
    The current number of rounds, the iteration number, and the antID are then printed
    along with the best-so-far fitness ❸. This helps us monitor how the algorithm
    is doing as it proceeds through the number of rounds (as mentioned earlier, the
    maximum number of rounds is set by maxRounds).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we check to see if the fitness of bestSoFar matches the known global
    optimal fitness for the Berlin52 problem (7544.3659) and count the number of such
    matches ❹ (which is later printed from the main() function).
  prefs: []
  type: TYPE_NORMAL
- en: The final function called from main() is printBestOverallFitnessAndTour(), which
    prints the optimal function value and solution found by the ACS algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The first line inside the function prints the value of the best overall fitness.
    The optimal solution in this case is a list of Pairs, where each pair consists
    of the start and the end nodes for the edges that belong to the best overall tour.
    We use a for loop and an if statement to print five pairs of nodes per line so
    that the entire solution can be examined easily in the console.
  prefs: []
  type: TYPE_NORMAL
- en: The Result
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Following is a sample output from a test run of the ACS application. I encourage
    you to compare this output with the various print statements and functions used
    in the entire ACS code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We can see that on this occasion, the first instance of global optima was found
    in the second round (during iter = 105 and by ant number 0). A near-optimal solution
    with a fitness of 7548.99 was found multiple times (not shown). The best overall
    solution had a fitness of 7544.3659, which is the known shortest tour length for
    the Berlin52 problem.
  prefs: []
  type: TYPE_NORMAL
- en: All the nodes that belong to the optimal (best overall) tour are also shown
    in the output. Notice that the optimal tour is a closed loop, and it returns to
    the same node it starts from. The sequence of the nodes in the optimal solution
    may differ when you run the code. This will not affect the tour length (therefore,
    its fitness will remain the same).
  prefs: []
  type: TYPE_NORMAL
- en: The final item in the output, optimaCount, indicates that during the entire
    process, the global optimal solution was found 5 times out of 50 rounds (although
    each of those rounds might have found the global optimal solution more than once).
    If you plot the nodes that belong to the best overall tour by using their x- and
    y-coordinates, the optimal tour will look like the path shown in [Figure 9-4](chapter9.xhtml#fig9-4).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-4: The optimal tour for the Berlin52 traveling salesman problem'
  prefs: []
  type: TYPE_NORMAL
- en: To visualize the convergence patterns for the rounds that found the global optima,
    you can add a few additional lines of code to save the relevant data from intermediate
    steps and plot the data. A typical convergence plot will look like the patterns
    shown in [Figure 9-5](chapter9.xhtml#fig9-5).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure9-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9-5: Convergence patterns for the Berlin52 problem'
  prefs: []
  type: TYPE_NORMAL
- en: Before concluding this project, I want to make a couple of points regarding
    the success rate of the ACS algorithm and the accuracy of the solution generated
    by the code we developed. These comments will clarify some questions that you
    may have when you run the code on your device or compare the results with the
    same published elsewhere.
  prefs: []
  type: TYPE_NORMAL
- en: First, recalling that the NIAs used in this book are stochastic, the optimaCount
    will vary each time you run the program. For the given set of values for the global
    parameters, I found the average optimaCount to be around 5 (based on 10 runs).
    However, if you change the values of the global parameters, this average success
    rate will change. I encourage you to play with those parameters to develop an
    understanding of their relative influence in finding the global optima.
  prefs: []
  type: TYPE_NORMAL
- en: Second, you may find in the literature that the optimal (shortest) tour length
    for the Berlin52 problem is 7542, which is slightly different from the optimal
    value we found, 7544.3659\. This does not indicate any issues with the ACS algorithm
    or with the code developed in this project; it is due to the fact that some algorithms
    convert the nodal (intercity) distances to the nearest integer values before solving
    the problem, for mathematical efficiency. Therefore, those methods essentially
    solve a slightly different problem. However, our ACS application has identified
    the exact same optimal route as reported in the literature.
  prefs: []
  type: TYPE_NORMAL
- en: Ant colony optimization is an area of active research, just like other NIAs.
    New modifications are being proposed and tested to improve the convergence and
    accuracy of this algorithm. I strongly encourage you to consult recently published
    literature if you are interested in using ACS or similar algorithms to solve large
    real-world routing problems.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This chapter completes your introduction to the fascinating world of NIAs and
    their applications. You discovered two more powerful tools—particle swarm optimization
    and ant colony systems—and you learned how to harness the power of these algorithms
    in Kotlin. You put your skills to the test with two real-world optimization problems:
    finding the global minimum of a complex mathematical function and solving the
    traveling salesman problem for a network of 52 locations in Berlin. You explored
    how the algorithms converged to the optimal solutions over time and how to measure
    their performance. And of course, you challenged yourself with exercises to reinforce
    your learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Brownlee, Jason. *Clever Algorithms: Nature-Inspired Programming Recipes*.
    Electronic version, June 16, 2012\. *[https://github.com/clever-algorithms/CleverAlgorithms](https://github.com/clever-algorithms/CleverAlgorithms)*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Clerc, Maurice. *Particle Swarm Optimization*. London: ISTE, 2006.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dorigo, Marco, and Thomas Stützle. *Ant Colony Optimization*. Cambridge, MA:
    MIT Press, 2004.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Olsson, Andrea E., ed. *Particle Swarm Optimization: Theory, Techniques and
    Applications*. New York: Nova Science, 2011.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Parsopoulos, Konstantinos E. “Particle Swarm Methods.” In *Handbook of Heuristics*,
    edited by Rafael Martí, Panos M. Pardalos, and Mauricio G. C. Resende, 639–685\.
    Cham, Switzerland: Springer, 2018.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Solnon, Christine. *Ant Colony Optimization and Constraint Programming*. London:
    ISTE, 2013.'
  prefs: []
  type: TYPE_NORMAL
- en: TSPLIB. Symmetric Traveling Salesman Problem (TSP). Accessed June 15, 2024\.
    *[http://<wbr>comopt<wbr>.ifi<wbr>.uni<wbr>-heidelberg<wbr>.de<wbr>/software<wbr>/TSPLIB95<wbr>/](http://comopt.ifi.uni-heidelberg.de/software/TSPLIB95/)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Yang, Xin-She. *Nature-Inspired Optimization Algorithms*. 2nd ed. London: Academic
    Press, 2021.'
  prefs: []
  type: TYPE_NORMAL
