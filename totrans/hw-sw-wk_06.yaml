- en: '**6**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Data Compression**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/common-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Sometimes the hard work of software is obvious to everyone, as it is with movie
    CGI and video game graphics. You don’t have to know anything about how computers
    work to be impressed with the visuals in films like *Avatar* and games like *Crysis*.
    Sometimes, though, software is doing its most amazing work when it looks like
    it’s not working hard at all.
  prefs: []
  type: TYPE_NORMAL
- en: Watching a high-definition movie on a disc or streamed over the Internet is
    something most of us take for granted. Isn’t that just storing and displaying
    images? Why would that require special techniques? To understand why we should
    be impressed with Blu-ray video and Netflix streaming, let’s look at what video
    was like before these formats came to be.
  prefs: []
  type: TYPE_NORMAL
- en: 'Videocassettes, the earliest home video medium, recorded images on a roll of
    magnetic tape. These were analog recordings—magnetic transcriptions of the same
    signal that would’ve been broadcast by television antennas. The video resolution
    was even lower than what we now call “standard definition,” and as with other
    analog recordings like audiocassettes and vinyl records, the quality of the video
    would degrade over time. The one upside to videocassettes was their capacity:
    a longer movie merely required a longer spool of tape.'
  prefs: []
  type: TYPE_NORMAL
- en: Next came the LaserDisc. About the size of LP records, these discs looked like
    larger versions of today’s DVDs and Blu-ray discs, but like videocassettes, they
    were still storing the analog broadcast-format signal. However, LaserDiscs recorded
    a higher-resolution picture that came close to standard definition, and allowed
    you to jump to particular places in the video without having to rewind or fast-forward
    the way you would with a videocassette. For a while, the LaserDisc seemed like
    the future of video, but now capacity was a problem. Unlike the effectively limitless
    capacity of a magnetic tape roll, LaserDiscs could hold only 60 minutes of video
    per side, so watching a movie meant flipping the disc halfway through or even
    switching discs.
  prefs: []
  type: TYPE_NORMAL
- en: Today, the problem of capacity is even more serious. Our Blu-ray discs are much
    smaller than LaserDiscs, but our videos are a much higher resolution. Let me put
    the problem into numbers. In high-definition video each frame is a 1920×1080 bitmap,
    a total of 2,073,600 pixels. If each pixel is stored in three-byte RGB format,
    one frame of a high-definition movie would require 6,220,800 bytes, or about 6.2
    megabytes (*mega* means “million”). Movies are recorded at 24 or 30 frames per
    second, which is 1,800 frames per minute, 108,000 frames per hour, or 216,000
    frames for a two-hour film. If each frame is 6,220,800 bytes, then 216,000 frames
    is 1,343,693 megabytes, or about 1,345 gigabytes (*giga* means “billion”).
  prefs: []
  type: TYPE_NORMAL
- en: How can all of that data fit on a Blu-ray disc? Part of the answer is the “blu-ray”
    itself, a blue laser that’s narrower than the laser used on LaserDiscs or even
    conventional DVDs, allowing more data to be packed into a smaller area, just as
    smaller print allows more words on a page. Even so, a Blu-ray can store only about
    50 gigabytes(GB) of data, less than 4 percent of what’s required.
  prefs: []
  type: TYPE_NORMAL
- en: Streaming video has the same problem. If one frame of video is 6.2 megabytes
    (MB), and the video is running at 30 frames per second, then streaming requires
    an Internet connection of 186 megabytes per second (MBps). A typical home broadband
    connection is more like 4MBps. What’s worse, because of traffic congestion and
    hiccups in the network, you can’t count on maintaining the full rated bandwidth
    over the course of a long transmission. Realistically, streaming video should
    use no more than a couple of MBps at most.
  prefs: []
  type: TYPE_NORMAL
- en: So how can we fit giant amounts of video data into these small containers? The
    answer is *data compression*—storing data in a format that requires fewer bytes
    than the original format. Compression techniques can be broadly divided into two
    categories. With *lossless compression*, the compressed data can be restored to
    its exact original state. In contrast, *lossy compression* accepts that the restored
    data may be slightly different than the original. Video streaming and storage
    uses a combination of both types of compression. In this chapter, we’ll first
    investigate some general compression techniques using simple examples. Then we’ll
    see how these ideas apply to video, producing highly compressed sequences of images
    that look nearly as good as the uncompressed originals.
  prefs: []
  type: TYPE_NORMAL
- en: '**Run-Length Encoding**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Most of us have employed some form of lossless compression, though we wouldn’t
    have called it that, because many techniques for lossless compression are commonsense
    ideas. One such method is *run-length encoding*. Suppose I were to show you a
    27-digit number for one minute to see whether you could remember it an hour later.
    That might sound hard, but look at the number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: I suspect you wouldn’t try to remember each digit individually. Instead, you’d
    count the occurrences of each digit, and remember it as “nine sevens, nine fives,
    and nine twos.”
  prefs: []
  type: TYPE_NORMAL
- en: That’s run-length encoding in action. Repeats of the same piece of data (in
    this case, a digit) are called *runs*, and when runs are common, we can shorten
    the data by recording the lengths of the runs rather than the whole number. Run-length
    encoding is lossless compression, because if we remember the shorthand version
    of the number, we can reproduce the number in its original form whenever needed.
  prefs: []
  type: TYPE_NORMAL
- en: Just by itself, run-length encoding can provide excellent compression for certain
    types of images, such as icons, logos, comic-book-style illustrations— any image
    with large blocks of solid color. When pixels have the same color as their neighbors,
    we can reduce the storage requirements considerably. As an example, I’ll describe
    the system used by the *TGA* image file format. TGA is short for *Truevision Graphics
    Adapter*, an early piece of graphics hardware designed for video editors. The
    file format, if not the adapter, is still in use in the video industry, and is
    probably the simplest example of run-length encoding for images.
  prefs: []
  type: TYPE_NORMAL
- en: The image data in a TGA file is compressed on a row-by-row basis. Within each
    row, each run of two or more pixels of exactly the same color is identified. The
    remaining pixels are called *raw* pixels. Consider the selected row in the sample
    image in [Figure 6-1](ch06.html#ch6fig1). In this row, there are several short
    runs of pixels, and several raw pixels that are different from their neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-1: The selected row has a mix of runs and raw pixels.*'
  prefs: []
  type: TYPE_NORMAL
- en: The TGA format organizes runs and raw pixels into *packets*. Each packet begins
    with a one-byte header. The leftmost bit of the header byte determines whether
    it is a run packet or a raw packet. The other seven bits denote the size of the
    packet in pixels. Because the smallest packet has one pixel, TGA encodes the packet’s
    size as one less than its actual size; that is, a size field of 0000000 represents
    a size of 1, and 0000001 represents 2, and so on. Following the header is either
    the encoded color of all the pixels in the run, or for a raw packet, the colors
    of each individual pixel. Using the RGB color format, the row of pixels from [Figure
    6-1](ch06.html#ch6fig1) would be encoded as shown in [Table 6-1](ch06.html#ch6tab1).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-1:** TGA Encoding of Pixel Row'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Run/raw** | **Size** | **Red** | **Green** | **Blue** | **Description**
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0000001 | 11111111 | 11111111 | 11111111 | Run of two white pixels |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0000010 | 11001100 | 11001100 | 00000000 | Run of three yellow pixels
    |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0000001 | 11111111 | 11111111 | 11111111 | Raw packet of two pixels;
    first is white |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | 00000000 | 10000000 | 00000000 | Second pixel in raw packet; dark green
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0000001 | 00000000 | 00000000 | 11111111 | Run of two blue pixels |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0000000 | 11111111 | 11111111 | 11111111 | One raw white pixel |'
  prefs: []
  type: TYPE_TB
- en: This encoding requires 23 bytes versus the uncompressed size of 30 bytes. This
    *compression ratio* of 30:23, or about 4:3, isn’t very high, but note that a mere
    4 bytes are needed to store rows where every pixel is the same color, like the
    top row of [Figure 6-1](ch06.html#ch6fig1). The overall compression ratio of this
    bitmap in TGA format is an impressive 300:114, or about 5:2.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dictionary Compression**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Just by itself, run-length encoding can compress pictures with large blocks
    of solid colors, but most of the images in movies aren’t like that. For photographs
    and other types of digital images with lots of color variation, software has to
    work much harder to find patterns exploitable by compression. One of the key tools
    is known as *dictionary compression*.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Basic Method***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Later we’ll see how dictionary compression is used on images, but the idea is
    easiest to understand when it is applied to a text document, so let’s start there.
    An uncompressed text document is stored as a series of character codes such as
    ASCII.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll compress this sample paragraph:'
  prefs: []
  type: TYPE_NORMAL
- en: Those pictures created by a computer are called computer graphics. When these
    pictures created by the computer are viewed in a sequence, that sequence is called
    an animation. An entire movie created from an animation, a sequence of pictures
    created by a computer, is called a computer-animated movie.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this example simpler, I’ll ignore the spaces and punctuation in this
    text and just worry about the letters. There are 234 letters in this paragraph;
    stored as uncompressed ASCII text, the letters would require 234 bytes. To employ
    dictionary compression on this text, we first need a *dictionary*, which in this
    context is a numbered list of every word in the document being compressed. [Table
    6-2](ch06.html#ch6tab2) is our list of words, numbered both in decimal and binary.
    Note that capitalization counts: *an* and *An* are separate entries.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-2:** Dictionary Compression'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Position** | **Binary-encoded position** | **Word** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 00000 | a |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 00001 | an |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 00010 | An |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 00011 | animated |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 00100 | animation |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 00101 | are |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 00110 | by |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 00111 | called |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 01000 | computer |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 01001 | created |'
  prefs: []
  type: TYPE_TB
- en: '| 11 | 01010 | entire |'
  prefs: []
  type: TYPE_TB
- en: '| 12 | 01011 | from |'
  prefs: []
  type: TYPE_TB
- en: '| 13 | 01100 | graphics |'
  prefs: []
  type: TYPE_TB
- en: '| 14 | 01101 | in |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 01110 | is |'
  prefs: []
  type: TYPE_TB
- en: '| 16 | 01111 | movie |'
  prefs: []
  type: TYPE_TB
- en: '| 17 | 10000 | of |'
  prefs: []
  type: TYPE_TB
- en: '| 18 | 10001 | pictures |'
  prefs: []
  type: TYPE_TB
- en: '| 19 | 10010 | sequence |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | 10011 | the |'
  prefs: []
  type: TYPE_TB
- en: '| 21 | 10100 | these |'
  prefs: []
  type: TYPE_TB
- en: '| 22 | 10101 | Those |'
  prefs: []
  type: TYPE_TB
- en: '| 23 | 10110 | viewed |'
  prefs: []
  type: TYPE_TB
- en: '| 24 | 10111 | When |'
  prefs: []
  type: TYPE_TB
- en: As shown, 5 bits are sufficient to represent the range of positions used. Each
    word in the original paragraph is replaced with its position in this table. For
    example, instead of using eight ASCII codes (64 bits) for each appearance of the
    word *computer*, the 5-bit dictionary entry is used instead.
  prefs: []
  type: TYPE_NORMAL
- en: The dictionary itself takes up space, however, and must be included in the compressed
    document, so we save space only when a word appears more than once. In this example,
    the total number of letters for all words in our dictionary is 116, requiring
    116 bytes. Replacing each of the 48 words in the sample paragraph with a 5-bit
    dictionary reference requires 235 bits, or about 30 bytes. The total compressed
    storage, then, is 146 bytes, which compared to the original 234 uncompressed bytes
    is a compression ratio of about 8:5\. With longer documents the savings will be
    even better, because the text grows much faster than the dictionary. A typical
    novel, for example, is about 80,000 words long, but uses a vocabulary of only
    a few thousand words.
  prefs: []
  type: TYPE_NORMAL
- en: '***Huffman Encoding***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In almost every text, some words are used much more than others. A technique
    called *Huffman encoding* takes advantage of this fact to improve on basic dictionary
    compression.
  prefs: []
  type: TYPE_NORMAL
- en: To create a Huffman code, the words in the document are ranked by frequency.
    Imagine a children’s story with the 10-word vocabulary shown in [Table 6-3](ch06.html#ch6tab3).
    As with basic dictionary compression, each word is assigned a binary code, but
    here shorter codes are assigned to the words that appear most frequently in the
    story.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-3:** Huffman Code for a Children’s Story'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Word** | **Frequency** | **Binary code** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| the | 25% | 01 |'
  prefs: []
  type: TYPE_TB
- en: '| a | 20% | 000 |'
  prefs: []
  type: TYPE_TB
- en: '| princess | 12% | 100 |'
  prefs: []
  type: TYPE_TB
- en: '| good | 11% | 110 |'
  prefs: []
  type: TYPE_TB
- en: '| witch | 10% | 111 |'
  prefs: []
  type: TYPE_TB
- en: '| evil | 8% | 0010 |'
  prefs: []
  type: TYPE_TB
- en: '| ate | 7% | 0011 |'
  prefs: []
  type: TYPE_TB
- en: '| magic | 4% | 1010 |'
  prefs: []
  type: TYPE_TB
- en: '| toadstool | 2% | 10110 |'
  prefs: []
  type: TYPE_TB
- en: '| forevermore | 1% | 10111 |'
  prefs: []
  type: TYPE_TB
- en: 'With the table in place, Huffman code compression is the same as basic dictionary
    compression: each word is replaced with its corresponding binary code. For example,
    the encoding for *the princess ate a magic toadstool* would start with 01 for
    *the*, then 100 for *princess*, and so on. In full, the encoding is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'As you may have noticed, the list of binary codes in [Table 6-3](ch06.html#ch6tab3)
    skips some possible codes, such as 011 or 0110\. Skipping codes is necessary to
    make this a *prefix code*, in which no binary code appears at the start of another.
    For example, because 01 is the code for *the*, other codes that begin with 01,
    such as 011 or 0110, are forbidden. Because the individual codes vary in length,
    a prefix code is necessary to know where each code ends. With our example, the
    01 that begins the bit sequence must be the code for *the* because no other code
    starts with 01; the only way to partition the whole sequence is as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If we allowed a code that broke the prefix rule, the sequences could become
    ambiguous. Suppose *forevermore* is assigned the code 00\. While this is a shorter
    code, it means the example sequence could also be partitioned as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This would decode as the phrase *the princess forevermore good forevermore magic
    toadstool*.
  prefs: []
  type: TYPE_NORMAL
- en: By assigning the shortest codes to the most common words, Huffman encoding can
    achieve greater compression than dictionary compression alone when data can be
    stored as a relatively small set of codes and some codes are more common than
    others.
  prefs: []
  type: TYPE_NORMAL
- en: '**Reorganizing Data for Better Compression**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unfortunately, the images we see in videos are not good candidates for Huffman
    encoding. Unlike the color-block images we compressed with the run-length technique,
    the pixels in a video image vary across the full range of possible colors. With
    16 million different possible RGB colors, it’s unlikely video images will have
    enough repetition to allow Huffman encoding to work. However, sometimes it’s possible
    to create repetition in varied data by changing how the data is stored.
  prefs: []
  type: TYPE_NORMAL
- en: '***Predictive Encoding***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For one such approach, consider a weather station that records the temperature
    once per hour, and over the course of one day stores the following readings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '**COMPRESSION IN ZIP FILES**'
  prefs: []
  type: TYPE_NORMAL
- en: Dictionary compression and Huffman encoding are at the heart of most general
    compression schemes. The *.zip* archive format, for example, can choose from a
    half-dozen compression methods but usually employs an algorithm called *deflate*.
    Rather than replacing duplicated data with a reference number from a list of words,
    this algorithm employs a variation of dictionary compression called a *sliding
    window*.
  prefs: []
  type: TYPE_NORMAL
- en: With this method, duplicate data is replaced with numerical indicators showing
    where the data occurred previously. In the textual example of [Figure 6-2](ch06.html#ch6fig2),
    there are three duplicate runs of characters. The first member of each pair is
    the number of characters to go back, and the second number is the length of the
    run. For example, the pair 5, 2 means “go back five characters, and copy two characters.”
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-2: Sliding-window compression*'
  prefs: []
  type: TYPE_NORMAL
- en: The compressed version of this text can be symbolically written as “Then t[5,2]
    scar[5,5]ed[16,4]m.” Instead of the number pairs being stored directly, though,
    they are Huffman-encoded, so the most commonly occurring pairs are assigned shorter
    codes. The deflate method is a highly effective general compression scheme, capable
    of reducing the 3,138,473 characters in a raw text version of Tolstoy’s *War and
    Peace* to a *.zip* file of around 930,000 bytes, about a 10:3 ratio.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we assume a temperature range of 120 to –50, we can store each temperature
    in an 8-bit byte, using 192 bits total. There aren’t many duplicates in this list,
    though, so Huffman encoding won’t be effective. The situation improves if we rewrite
    this list using *predictive encoding*. For every temperature after the first,
    we’ll record not the temperature itself, but its difference from the previous
    temperature. Now the list looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Whereas the original data had few duplicates, the predictive-encoded data has
    many. Now we can apply Huffman encoding with excellent results.
  prefs: []
  type: TYPE_NORMAL
- en: '***Quantization***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Another approach, if we are willing to accept some degradation of the data,
    is *quantization*, where we store the data with less precision. Suppose the weather
    station from the previous example also records daily rainfall amounts, taking
    the following readings over the course of three weeks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'These readings have two decimal places, but maybe we don’t actually need this
    much precision in the data. For one thing, any amount below 0.05 might represent
    condensation on the collector rather than actual rain; likewise, condensation
    might also be the only difference between readings like 1.23 and 1.21\. So let’s
    leave off the last digit of every number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: By itself, this compresses the data, since storing one place after the decimal
    will take fewer bits than storing two. In addition, the quantized data also has
    several runs of zeros that can be compressed with run-length encoding, and some
    duplicates that can be compressed by Huffman encoding.
  prefs: []
  type: TYPE_NORMAL
- en: These techniques point to a general multistage approach for compression. First,
    reorganize the data to increase the runs and duplicates, by storing small differences
    between numbers rather than the raw numbers themselves, quantizing the data, or
    both. Then compress the data with run-length and Huffman encoding.
  prefs: []
  type: TYPE_NORMAL
- en: '**JPEG Images**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We now have almost all the tools needed to compress video. The logical first
    step in compressing a video is to compress the individual images in the video.
    However, we can’t directly apply predictive encoding and quantization to digital
    photographs and other images with lots of subtle color variation; we need to convert
    these pictures to another format first.
  prefs: []
  type: TYPE_NORMAL
- en: That’s the idea behind *JPEG*, a common compressed-image format designed specifically
    for digital photographs. (The name is the acronym for the *Joint Photography Experts
    Group* that developed the format.) The compression method for this format is based
    on a couple of key observations of photography and human perception.
  prefs: []
  type: TYPE_NORMAL
- en: First, although pixel colors may vary widely throughout an image, individual
    pixels tend to be similar to their neighbors. If you take a picture of a leafy
    tree against a partly cloudy sky, lots of green leaf pixels will be next to other
    green pixels, blue sky pixels will neighbor blue sky pixels, and gray cloud pixels
    will neighbor gray cloud pixels.
  prefs: []
  type: TYPE_NORMAL
- en: Second, among neighboring pixels, there will be more noticeable variation in
    brightness levels than in color tone. For our tree photograph, each of the myriad
    leaf pixels will reflect a different quantity of sunlight, but the underlying
    color of each pixel will be roughly similar. Also, although the mechanisms of
    human vision are not completely understood, tests indicate that we perceive differences
    in brightness more distinctly than differences in color.
  prefs: []
  type: TYPE_NORMAL
- en: High compression of digital photographs is possible only with lossy compression;
    we have to accept some degradation of the image. Following these key observations,
    though, allows the JPEG format to throw away the data that is least likely to
    be missed. In our tree photograph, the most important distinctions are the broad
    differences between leaf and sky, or sky and cloud, not between two neighboring
    cloud pixels. After that, the most important distinction is the relative brightness
    of pixels, more so than relative color. The JPEG format therefore gives priority
    to broad differences over fine differences, and brightness over color.
  prefs: []
  type: TYPE_NORMAL
- en: '***A Different Way to Store Colors***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'JPEG compression divides images into 8×8 blocks of pixels that are independently
    compressed. To compress brightness and color differently, each pixel’s R, G, and
    B values are converted to three other numbers *Y*, *Cb*, and *Cr*. Here, Y is
    the *luminance* of the pixel, or how much light the pixel produces. Cb is the
    *blue difference*, and Cr is the *red difference*. The simplest way to envision
    the YCbCr system is to imagine a dark green video screen with three knobs labeled
    Y, Cb, and Cr initially set to zero: turn up Y and the screen is brighter; turn
    up Cb and the screen becomes more blue and less green; turn up Cr and the screen
    becomes more red and less green. [Table 6-4](ch06.html#ch6tab4) lists a few named
    colors in both systems for comparison. (A historical note: YCbCr is derived from
    the color system used in broadcast television. In the early days of color television,
    the remaining black-and-white televisions could properly display color transmissions
    by interpreting only the Y component of the signal.)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-4:** Select Colors in the RGB and YCbCr Color Systems'
  prefs: []
  type: TYPE_NORMAL
- en: '| **R** | **G** | **B** | **Color description** | **Y** | **Cb** | **Cr** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 255 | 0 | Lime green | 145 | 54 | 34 |'
  prefs: []
  type: TYPE_TB
- en: '| 255 | 255 | 255 | Pure white | 235 | 128 | 128 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 255 | 255 | Aqua | 170 | 166 | 16 |'
  prefs: []
  type: TYPE_TB
- en: '| 128 | 0 | 0 | Maroon | 49 | 109 | 184 |'
  prefs: []
  type: TYPE_TB
- en: JPEG compresses the Y, Cb, and Cr data separately, so we can think of each 8×8
    block of pixels as becoming three 8×8 blocks of Y, Cb, and Cr data. Separating
    the data this way takes advantage of the greater variation in brightness than
    in color. Under the YCbCr system, most of the differences between the pixels will
    be concentrated in the Y component. The lower variance in the Cb and Cr blocks
    will make them easier to compress, and because we’re more sensitive to variations
    in luminance than variations of color, the Cb and Cr blocks can be compressed
    more heavily.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Discrete Cosine Transform***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The conversion to YCbCr follows the observation that brightness is more important
    than color. To take advantage of the greater importance of broad changes over
    narrow changes, though, we need to convert each 8×8 data blocks yet again. The
    *discrete cosine transform (DCT)* converts the absolute luminance and color data
    into relative measurements of how these values differ from pixel to pixel. Although
    this transformation is applied to an entire 8×8 block of numbers, I’ll first illustrate
    the idea with a single row of eight numbers from the luminance (Y) block, shown
    as shades of gray in [Figure 6-3](ch06.html#ch6fig3).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-3: A row of luminance levels*'
  prefs: []
  type: TYPE_NORMAL
- en: To begin the DCT, we subtract 128 from each number, which has the effect of
    moving the 0–255 range to a range centered around 0, so that maximum brightness
    is 127 and absolute black is –128\. The resulting luminance levels for the row
    are depicted as a line chart in [Figure 6-4](ch06.html#ch6fig4).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-4: Subtracting 128 from each luminance level centers the range of
    possible numbers around 0.*'
  prefs: []
  type: TYPE_NORMAL
- en: The DCT produces eight new numbers that each combine the eight luminance levels
    in a different way. [Figure 6-5](ch06.html#ch6fig5) shows the DCT of the previous
    figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-5: The discrete cosine transform of the data in [Figure 6-4](ch06.html#ch6fig4).*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the numbers are labeled with a range from “coarse” to “fine.” The
    leftmost number in the DCT is the simplest combination of the luminance levels:
    their sum. Thus, the first number is the overall brightness of the pixels, and
    will be positive for a bright row of pixels and negative for a dark row. The second
    number effectively compares the luminance levels on the left end of the row against
    those on the right, and is positive in this example because our luminance levels
    are brighter on the left than on the right. The rightmost number effectively compares
    each luminance value against its immediate neighbors, and is close to 0 here because
    the numbers in [Figure 6-4](ch06.html#ch6fig4) change gradually.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These DCT numbers are the coefficients that result from an operation called
    *matrix multiplication*. If your eyes just glazed over, don’t worry: the operation
    involves nothing more than multiplication and addition. We produce each coefficient
    by multiplying the luminance values by a different, predetermined vector. In this
    context, a *vector* is just an ordered list of numbers. The eight vectors used
    in the DCT are illustrated in [Figure 6-6](ch06.html#ch6fig6). (The numbers in
    each vector are related to the cosine function from trigonometry, which is where
    the discrete cosine transform gets its name, but we can safely ignore that for
    this discussion.)'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-6: The vectors needed for our single-row DCT*'
  prefs: []
  type: TYPE_NORMAL
- en: To produce a coefficient for our luminance row, we multiply each number in a
    vector by the luminance in the same position. For example, [Table 6-5](ch06.html#ch6tab5)
    shows the computation of the Vector 2 coefficient for our luminance row. Each
    number from the luminance row is multiplied by the number in the same position
    in Vector 1; then, these products are summed to get 157.386.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-5:** Computing the Coefficient for Vector 2'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Position** | **Luminance (from [Figure 6-4](ch06.html#ch6fig4))** | **Vector**
    | **Product** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 76 | 0.49 | 37.24 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 127 | 0.416 | 52.832 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 127 | 0.278 | 35.306 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 76 | 0.098 | 7.448 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 25 | –0.098 | –2.45 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | –26 | –0.278 | 7.228 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | –77 | –0.416 | 32.032 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 25 | –0.49 | –12.25 |'
  prefs: []
  type: TYPE_TB
- en: '| Total |  |  | 157.386 |'
  prefs: []
  type: TYPE_TB
- en: Looking at the vectors of [Figure 6-6](ch06.html#ch6fig6), you can see how each
    combines the luminance levels differently. Because every number in Vector 1 is
    the same positive number, the Vector 1 coefficient becomes a measure of overall
    brightness. Because Vector 2’s numbers gradually sweep from high to low, the second
    coefficient will be positive when luminance tends to fall off from the left to
    right in the pixel row, and negative when luminance tends to increase. Vector
    3’s coefficient is a measure of how the ends of the row differ from the middle,
    and so on. You’ve already seen the resulting coefficients charted in [Figure 6-5](ch06.html#ch6fig5);
    [Table 6-6](ch06.html#ch6tab6) shows the result numerically.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-6:** Coefficients from the Discrete Cosine Transform of the Sample
    Luminance Row'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Vector number** | **Coefficient** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 124.804 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 157.296 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | –9.758 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | –87.894 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 18.031 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | –49.746 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 23.559 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | –13.096 |'
  prefs: []
  type: TYPE_TB
- en: 'The process is reversible: we can retrieve the original luminance numbers from
    [Figure 6-4](ch06.html#ch6fig4) by multiplying the eight coefficients against
    eight different vectors, a process called the *inverse discrete cosine transform
    (IDCT)*. [Table 6-7](ch06.html#ch6tab7) shows how the second luminance value,
    127, is extracted from the coefficients.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-7:** Computing the Second Luminance Value from the Coefficients'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Position** | **Coefficient** | **Vector** | **Product** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 124.804 | 0.354 | 44.125 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 157.296 | 0.416 | 65.393 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | –9.758 | 0.191 | –1.867 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | –87.894 | –0.098 | 8.574 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 18.031 | –0.354 | –6.375 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | –49.746 | –0.49 | 24.395 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | –23.559 | –0.462 | –10.833 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | –13.096 | –0.278 | 3.638 |'
  prefs: []
  type: TYPE_TB
- en: '| Total |  |  | 127 |'
  prefs: []
  type: TYPE_TB
- en: 'The DCT, then, gives us a different way of storing the same numbers: as the
    relationship between the data rather than the data itself. Why is this useful?
    Remember that fine distinctions between pixels are less noticeable than broader
    distinctions. Later, you’ll see how the DCT allows the JPEG format to compress
    the fine details more than the broad.'
  prefs: []
  type: TYPE_NORMAL
- en: '***The DCT for Two Dimensions***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: JPEG compression works not on rows of pixels but on 8×8 pixel blocks, so now
    let’s see how the DCT operates in two dimensions. The one-dimensional DCT multiplies
    eight vectors with the original eight numbers to produce eight coefficients. The
    two-dimensional DCT, though, requires 64 *matrices*, each matrix being an 8×8
    table of numbers. Like the vectors, each matrix will multiply all 64 pieces of
    data in the 8×8 block.
  prefs: []
  type: TYPE_NORMAL
- en: The matrices themselves are two-dimensional combinations of the vectors we saw
    earlier. This is easiest to understand pictorially. [Figure 6-7](ch06.html#ch6fig7)
    shows the combination of a horizontal Vector 1 and a vertical Vector 1\. Because
    the numbers in Vector 1 are all the same, the numbers in the resulting matrix
    are as well. In these matrix illustrations, lighter gray means a higher number.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-7: The matrix combination of Vector 1 and itself*'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 6-8](ch06.html#ch6fig8), horizontal Vector 1 is combined with vertical
    Vector 2\. The resulting matrix gradually varies from top to bottom as Vector
    2 gradually varies, but doesn’t vary left to right because the numbers in Vector
    1 don’t vary.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-8: The matrix combination of Vector 1 and Vector 2*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6-9](ch06.html#ch6fig9) shows a last example, Vector 8 combined with
    Vector 8\. Because Vector 8 swings back and forth from positive to negative, the
    combination matrix has a checkerboard quality.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-9: The matrix combination of Vector 8 and itself*'
  prefs: []
  type: TYPE_NORMAL
- en: The two-dimensional DCT replaces each of the 64 numbers in an 8×8 block with
    a matrix coefficient. [Figure 6-10](ch06.html#ch6fig10) shows which matrices are
    used for a few locations. Similar to the one-dimensional DCT, the coefficient
    in the upper left, which is the same shown in [Figure 6-7](ch06.html#ch6fig7),
    sums all the numbers in the original block equally. As we progress downward and
    to the right, the distinctions being measured grow finer.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-10: Some of the matrices used in the two-dimensional DCT*'
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the two-dimensional DCT, I’ll use just the luminance values of
    the pixel block shown in [Figure 6-11](ch06.html#ch6fig11).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-11: A block of pixels and the associated luminance (Y) block*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6-12](ch06.html#ch6fig12) shows the same luminance block with 128 subtracted
    from each number to make a range from –127 to 128 centered around 0.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-12: The luminance block from [Figure 6-11](ch06.html#ch6fig11) with
    the range of possible values centered around 0*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 6-13](ch06.html#ch6fig13) shows the luminance block after DCT. Each
    number is the coefficient resulting from multiplying the matrix of luminance values
    in [Figure 6-12](ch06.html#ch6fig12) with one of the matrices from [Figure 6-10](ch06.html#ch6fig10).
    Remember that these numbers, too, are centered around 0\. So the 132 in the upper
    left, for example, indicates a high luminance level for the block as a whole.
    Notice that the numbers in the upper left are largest in magnitude (furthest from
    0 in either direction), indicating that broad luminance differences are much greater
    than the fine differences in this pixel block. This result is typical of JPEG-encoded
    photographs.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-13: The DCT of the block in [Figure 6-12](ch06.html#ch6fig12)*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Compressing the Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now the real compression can begin, the first step of which is quantization.
    [Figure 6-14](ch06.html#ch6fig14) shows the 8×8 block of divisors used for quantizing
    the luminance block. Each number in the coefficient block of [Figure 6-13](ch06.html#ch6fig13)
    is divided by the number in the same position in [Figure 6-14](ch06.html#ch6fig14),
    with results rounded to the nearest whole number. This degrades the image through
    quantization error, but note that the divisors in [Figure 6-14](ch06.html#ch6fig14)
    are smallest in the upper left. Thus, the quantization error is most pronounced
    in the coefficients that measure the finest distinctions, where the error is least
    likely to be noticed. The actual values of the divisors varies according to the
    compression quality, with larger divisors used to quantize the Cr and Cb blocks,
    but the divisor block always follows this general pattern (lower values in the
    upper left, higher in the bottom right).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-14: The divisors used to quantize luminance blocks*'
  prefs: []
  type: TYPE_NORMAL
- en: The result of quantization for our sample block is shown in [Figure 6-15](ch06.html#ch6fig15).
  prefs: []
  type: TYPE_NORMAL
- en: You can see how suitable these numbers are for run-length and Huffman encoding.
    Most of the coefficients have been quantized all the way down to 0, with many
    duplicate coefficients among the rest.
  prefs: []
  type: TYPE_NORMAL
- en: After quantization, nonzero results tend to cluster in the upper left of the
    matrix, so the quantized numbers are listed in the zigzag pattern shown in [Figure
    6-16](ch06.html#ch6fig16).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-15: The quantized luminance block*'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-16: Storing coefficients in a zigzag order*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This zigzag pattern tends to produce a very long run of zeros at the end, as
    it does in our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'To encode the runs of zeros, we replace each nonzero entry in the list by a
    pair of numbers: the number of zeros skipped (possibly none), and the coefficient
    itself. For example, the eighth number in our list is a –2 that is preceded by
    one 0\. This would become the number pair 1, –2\. At this stage, our list looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Some of these number pairs, such as 0, –1, appear very frequently in these lists
    compared to other pairs like 0, 10\. For maximum compression, the JPEG standard
    defines a Huffman encoding for every possible number pair in these lists. The
    common 0, –1 pair, for example, becomes the short Huffman code 001, while the
    uncommon 0, 10 pair becomes the longer code 10110010\. There’s also a special
    code, 1010, to signal that all the rest of the coefficients in the list are 0\.
    The Huffman encoding for our list is shown in [Table 6-8](ch06.html#ch6tab8).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-8:** The Huffman Encoding of the Coefficients from [Figure 6-15](ch06.html#ch6fig15)'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Zeros skipped** | **Coefficient** | **Huffman encoding** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 |   8 | 10110000 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 10 | 10110010 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | –7 | 100111 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | –7 | 100111 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 |   6 | 100010 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | –4 | 100100 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | –2 | 11100110 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 |   1 | 000 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | –2 | 0110 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | –1 | 001 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | –1 | 001 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 |   1 | 000 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | –1 | 001 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | –1 | 11001 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 |   1 | 110110 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | –1 | 110111 |'
  prefs: []
  type: TYPE_TB
- en: '| (Nothing left but zeros) |  | 1010 |'
  prefs: []
  type: TYPE_TB
- en: All of the bits in the rightmost column, strung together, represent the compressed
    encoding of our original luminance block. The original block represented the luminance
    levels as 64 bytes, or 512 bits total. In contrast, the encoding in [Table 6-8](ch06.html#ch6tab8)
    uses a mere 88 bits.
  prefs: []
  type: TYPE_NORMAL
- en: The two color blocks, Cr and Cb, would show even higher compression because
    the divisors used on the color blocks are even larger, which produces smaller
    numbers with shorter Huffman codes and more zeros for the run-length encoding.
    Overall, JPEG images typically achieve a 10:1 compression ratio. The amount of
    compression can be increased or reduced by using smaller or larger divisors than
    those shown in [Figure 6-14](ch06.html#ch6fig14). These divisors are adjusted
    by the “quality” slider in image-manipulation programs. Sliding the control to
    “low quality” increases the divisors, reducing the file size while increasing
    the quantization error.
  prefs: []
  type: TYPE_NORMAL
- en: '***JPEG Picture Quality***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: High compression is great only if the restored image is indistinguishable from
    the original, or nearly so. Typically the alterations JPEG compression makes to
    an image are difficult to see. To get a feel for the changes introduced by compression,
    let’s compare the original block of luminance values to the block that results
    from compressing and decompressing, as shown in [Figure 6-17](ch06.html#ch6fig17).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-17: The original luminance block, and the result of compressing and
    decompressing the block*'
  prefs: []
  type: TYPE_NORMAL
- en: Since it’s tough to visually compare these two blocks of numbers, [Figure 6-18](ch06.html#ch6fig18)
    shows the differences as a grayscale matrix. As you can see, most of the matrix
    is neutral gray, indicating numbers very close to the original.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-19: The amount of error in each location of the luminance block*'
  prefs: []
  type: TYPE_NORMAL
- en: The best evidence for the quality of JPEGs is shown in [Figure 6-19](ch06.html#ch6fig19).
    On the top is an uncompressed digital photograph. Because this photo is in grayscale,
    we don’t need RGB pixel color, just a single byte indicating the grayscale level.
    At a resolution of 975×731, this uncompressed photo requires just under 713 kilobytes
    of storage. In the middle is a compressed JPEG version of the original photo,
    requiring just 75 kilobytes of storage, which is virtually indistinguishable from
    the original. The photo on the bottom is a low-quality JPEG using larger divisors.
    While the photo takes up only about 7 kilobytes, compression artifacts are clearly
    visible. Many of the individual 8×8 pixel blocks have been reduced to solid squares
    of the same gray level. In general, JPEG can result in a 10:1 compression ratio
    without sacrificing visual quality.
  prefs: []
  type: TYPE_NORMAL
- en: '**Compressing High-Definition Video**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The JPEG format does a fantastic job of compressing images with only small sacrifices
    in quality, but for high-definition video we need even more compression. Remember,
    uncompressed high-definition video requires about 186MBps. Individually compressing
    each image as a JPEG would reduce that requirement to about 18MBps—a big improvement,
    but for streaming or disc storage we need to shrink the data to just a few MBps
    per second.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-18: An uncompressed photo (top), high-quality JPEG compression (middle),
    and low-quality JPEG compression (bottom)*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Temporal Redundancy***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To hit this target, video compression techniques take advantage of similarities
    between images in sequence. [Figure 6-20](ch06.html#ch6fig20) shows an image sequence
    from a movie’s opening credits.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-20: A few frames of an opening title sequence*'
  prefs: []
  type: TYPE_NORMAL
- en: Each of these images will be shown for several seconds; which means that the
    sequence will contain many duplicate frames in a row. Also, even as the video
    transitions from one image to the next, most of the picture remains unchanged.
    Only the area in the center varies.
  prefs: []
  type: TYPE_NORMAL
- en: Now consider the image sequence shown in [Figure 6-21](ch06.html#ch6fig21).
    Although each frame differs from the next, the same elements are present in each
    frame, just in different places on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-21: An image sequence with a moving object*'
  prefs: []
  type: TYPE_NORMAL
- en: These examples show two different forms of *temporal redundancy*, continuity
    of data from one frame to the next. Compression that exploits such redundancy
    is called *temporal compression*, and as we’ll see in the next section, it’s the
    key to achieving the compression ratios needed for video streaming and storage.
  prefs: []
  type: TYPE_NORMAL
- en: '***MPEG-2 Video Compression***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One method of temporal compression is employed by *MPEG-2*, a common video format
    supported by Blu-ray discs and digital broadcast television. More advanced techniques
    exist, but they are extensions of the ideas demonstrated here.
  prefs: []
  type: TYPE_NORMAL
- en: '**Groups of Frames**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: MPEG-2 videos are divided into sequences of around 15 frames called *groups
    of pictures (GOPs)*. Exactly one frame in each GOP is selected to be a basic JPEG-encoded
    image called an *intracoded frame (I-Frame)*. This frame is the rock upon which
    the rest of the GOP is built. All of the other frames use temporal compression,
    which means they are stored not as the absolute colors of the pixels in the image,
    but by how those colors differ from those in another image in the GOP, as we’ll
    see shortly.
  prefs: []
  type: TYPE_NORMAL
- en: The other frames in the group are assigned one of two types, *predicted frames
    (P-Frames)* and *bidirectional frames (B-Frames)*. A P-Frame stores the difference
    between its pixels and those of a previous frame, while a B-Frame stores the difference
    between its pixels and those of a previous *and* a later frame.
  prefs: []
  type: TYPE_NORMAL
- en: A GOP is shown in [Figure 6-22](ch06.html#ch6fig22), with arrows indicating
    the frames referenced by the temporal compression. As you can see, everything
    depends on the I-Frame. During playback, it must be decoded before any other image
    in the GOP, after which the frames that directly reference the I-Frame can be
    decoded, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-22: A GOP, or group of pictures*'
  prefs: []
  type: TYPE_NORMAL
- en: Grouping pictures this way simplifies encoding and decoding, and also limits
    the length of the reference “chain.” Just like a photocopy of a photocopy, the
    longer the chain of temporal compression, the fuzzier the image gets. The regular
    appearance of I-Frames is also what allows you to see images as you fast-forward
    or rewind; the video player just picks out the I-Frames, which can be decoded
    and displayed independently of the other frames in its GOP.
  prefs: []
  type: TYPE_NORMAL
- en: The MPEG specification gives encoding software wide discretion in forming GOPs.
    The number of I-Frames, which directly determines the size of GOPs, is up to the
    encoder, as is the number of B-Frames between the other frame types. Like the
    divisors used in JPEG quantization, the ability to change the relative numbers
    of the three frame types offers a trade-off between quality and compression. In
    applications where compression is paramount, like videoconferencing, I-Frames
    are rare and B-Frames are common, while in a Blu-ray, the encoder will use as
    many I-Frames as possible while still fitting all the video data on the disc.
  prefs: []
  type: TYPE_NORMAL
- en: '**Temporal Compression**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'So how does the temporal compression of P-Frames and B-Frames work? In this
    example, we’re compressing a P-Frame by referencing an I-Frame. First, the pixels
    in the P-Frame are divided into 16×16 *macroblocks*. For each macroblock, the
    I-Frame is searched for a matching block of pixels with the same color data. This
    matching block may not appear in exactly the same place in the I-Frame, though,
    so it is indicated by its *offset*: the difference between the location in the
    P-Frame and the location in the I-Frame, expressed in screen coordinates. For
    example, an offset of –100, 50 indicates that the macroblock’s location in the
    I-Frame is 100 pixels left and 50 pixels down from its location in the P-Frame,
    as shown in [Figure 6-23](ch06.html#ch6fig23).'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-23: A macroblock in a P-Frame referencing a matching block of pixels
    in a previous frame*'
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, an exact match won’t be found, so in addition to storing the
    location of the best match, the differences between the two macroblocks must also
    be stored. [Figure 6-24](ch06.html#ch6fig24) shows a luminance block from the
    P-Frame and the best match in the I-Frame. (I’m using 8×8 blocks instead of a
    full 16×16 macroblock to keep the example manageable.)
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-24: A luminance block and its best match in a prior frame*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, a block of differences is computed: each number in the I-Frame block
    is subtracted from the number in the same position in the P-Frame block. The result
    for our example is shown in [Figure 6-25](ch06.html#ch6fig25).'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-25: The difference between the two luminance blocks in [Figure 6-24](ch06.html#ch6fig24)*'
  prefs: []
  type: TYPE_NORMAL
- en: Because the blocks are a close match, these values are all small. This is a
    form of predictive encoding, just like the list of temperatures shown earlier
    in the chapter. By storing differences, we’ve made the range of data much smaller,
    and therefore more easily compressed. When we apply the DCT and quantize the results,
    the numbers are downright tiny, as shown in [Figure 6-26](ch06.html#ch6fig26).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f06-26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 6-26: The result of quantizing the block in [Figure 6-25](ch06.html#ch6fig25)
    and applying the DCT*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This block is highly susceptible to the last stage of compression: the combination
    of run-length and Huffman encoding. As shown in [Table 6-9](ch06.html#ch6tab9),
    the original luminance block has been reduced to a mere 39 bits.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 6-9:** The Huffman Encoding of the Numbers in [Figure 6-26](ch06.html#ch6fig26)'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Run length** | **Coefficient** | **Huffman encoding** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 4 |   1 | 1110110 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | –1 | 11001 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 |   1 | 000 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 |   1 | 000 |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | –1 | 001 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 |   1 | 11000 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 |   1 | 111110100 |'
  prefs: []
  type: TYPE_TB
- en: '| (Nothing left but zeros) |  | 1010 |'
  prefs: []
  type: TYPE_TB
- en: Not every macroblock in the P-Frame is encoded in this way. In some cases, a
    macroblock may not be similar enough to any block of pixels in the previous frame
    to save any space by storing the difference. Those macroblocks can be recorded
    directly, like the macroblocks in an I-Frame. For a B-Frame, matching macroblocks
    can be found in a previous frame or a later frame, which improves the odds of
    a close match.
  prefs: []
  type: TYPE_NORMAL
- en: '***Video Quality with Temporal Compression***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Temporal compression depends upon temporal redundancy—sequences of frames with
    few changes. For this reason, some videos compress much better than others. Movies
    with lots of camera movement, like *Cloverfield* or *The Blair Witch Project*,
    are difficult to compress, while movies with long takes where the camera doesn’t
    move, like *2001: A Space Odyssey*, are ideal.'
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, video compression is a bit of an art as well as a science. As stated
    earlier, different MPEG-2 encoders can produce different results for the same
    sequence of images. Shorter GOPs, with more I-Frames and fewer B-Frames, produce
    better-looking video than longer GOPs, but longer GOPs mean better compression.
    An encoder can vary the mix of frames even within the same video, using longer
    GOPs when there’s high temporal redundancy and shorter GOPs when there isn’t.
    Also, good encoders will try to line up GOP boundaries with sharp cuts in a movie;
    if you’ve ever seen a video that was momentarily very blocky when the scene changed,
    it’s likely because a GOP stretched over the cut.
  prefs: []
  type: TYPE_NORMAL
- en: There’s also the question of performance, especially if the video is being compressed
    in real time, as with a live event. There might not be enough time to find the
    absolute best match for a macroblock in the other frame.
  prefs: []
  type: TYPE_NORMAL
- en: Playback quality can vary as well. For example, because of how frames are broken
    into individually processed macroblocks, seams may appear along the borders of
    the blocks. To reduce this effect, a decoder may apply a *deblocking filter*.
    This smoothes block boundaries by averaging pixel colors, much like the anti-aliasing
    methods shown in previous chapters. The strength of the filter can be adjusted
    based on the likelihood of a clean boundary. In a B-Frame, for example, if one
    block references the previous frame while an adjacent block references the next
    frame, there’s a greater likelihood of a rough boundary, which calls for stronger
    filtering.
  prefs: []
  type: TYPE_NORMAL
- en: In other cases, the resolution of the video and the display resolution may not
    match. For example, when you’re streaming an episode of the old cop show *Adam-12*
    (it’s not just me, right?) on a high-definition television, either the television
    or the player has to convert the original 640×480 images to fill the 1920×1080
    display. This is the same problem we solved in [Chapter 5](ch05.html#ch05) with
    texture mapping—applying a bitmap to a larger area—and video devices can employ
    the same sorts of techniques. Early high-definition players effectively used nearest-neighbor
    sampling, which produced poor results. Newer players employ techniques similar
    to trilinear filtering. Instead of blending between bilinear samples from two
    different levels in a mipmap, however, they blend between successive frames. This
    is especially effective in smoothing objects in motion.
  prefs: []
  type: TYPE_NORMAL
- en: Although not as computationally intense as the original encoding, playing back
    a temporally compressed video is still a lot of work for a processor. Also, the
    structure of a GOP requires decoding the frames out of order. This in turn requires
    that frames be *buffered*, held in a queue prior to display. For streaming video,
    much larger buffers are used so that minor hiccups in the network don’t disrupt
    playback.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Present and Future of Video Compression**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The latest video compression standard, known as H.264 or MPEG-4, extends the
    techniques used in MPEG-2 but isn’t fundamentally different. The primary differences
    improve the quality of macroblock matching. Instead of being matched against just
    one or two other frames, macroblocks can be matched against 32 other frames. Also,
    the 16×16 macroblocks themselves can be broken down into separately matched 8×8
    blocks.
  prefs: []
  type: TYPE_NORMAL
- en: Through such improvements, MPEG-4 can often achieve twice the compression ratio
    of MPEG-2 with the same quality result. For that reason, MPEG-4 is an industry
    standard for both streaming and storage. Most Blu-ray videos use it, as do YouTube
    and Netflix. Its chief competition is a format called Theora, which uses similar
    compression methods but is freely licensed, unlike the proprietary MPEG-4.
  prefs: []
  type: TYPE_NORMAL
- en: Today’s compression formats do an amazing job at shrinking video data, but they
    do so at a high computational cost. The next time you watch a clip on YouTube,
    think about a GOP, all the macroblocks being copied and updated from one frame
    to the next, and all the number crunching that goes into performing the DCT over
    and over again. It’s a dizzying amount of calculation just to show a cat falling
    off a piano.
  prefs: []
  type: TYPE_NORMAL
- en: Even more computational horsepower will be needed in the future. The new *ultra
    high definition (UHD)* format, seen in theaters in films like Peter Jackson’s
    *Hobbit* series, is starting to trickle down to home video. UHD images are 3840×2160,
    which is four times the number of pixels as current high definition. The frame
    rate will also increase, from today’s 24 or 30 fps to 48, 60, or even 120 fps.
    UHD video could increase the bit requirements from today’s 1,400Mbps to over 23,000,
    which will require a corresponding increase in bandwidth and disc storage capacity—unless
    someone clever comes up with an even better way for software to shrink the data.
  prefs: []
  type: TYPE_NORMAL
