["```\n; Listing 2-1\n\n; Displays some numeric values on the console.\n\n        option  casemap:none\n\nnl      =       10  ; ASCII code for newline\n\n         .data\ni        qword  1\nj        qword  123\nk        qword  456789\n\ntitleStr byte   'Listing 2-1', 0\n\nfmtStrI  byte   \"i=%d, converted to hex=%x\", nl, 0\nfmtStrJ  byte   \"j=%d, converted to hex=%x\", nl, 0\nfmtStrK  byte   \"k=%d, converted to hex=%x\", nl, 0\n\n        .code\n        externdef   printf:proc\n\n; Return program title to C++ program:\n\n         public getTitle\ngetTitle proc\n\n; Load address of \"titleStr\" into the RAX register (RAX holds\n; the function return result) and return back to the caller:\n\n         lea rax, titleStr\n         ret\ngetTitle endp\n\n; Here is the \"asmMain\" function.\n\n        public  asmMain\nasmMain proc\n\n; \"Magic\" instruction offered without explanation at this point:\n\n        sub     rsp, 56\n\n; Call printf three times to print the three values i, j, and k:\n\n; printf(\"i=%d, converted to hex=%x\\n\", i, i);\n\n lea     rcx, fmtStrI\n        mov     rdx, i\n        mov     r8, rdx\n        call    printf\n\n; printf(\"j=%d, converted to hex=%x\\n\", j, j);\n\n        lea     rcx, fmtStrJ\n        mov     rdx, j\n        mov     r8, rdx\n        call    printf\n\n; printf(\"k=%d, converted to hex=%x\\n\", k, k);\n\n        lea     rcx, fmtStrK\n        mov     rdx, k\n        mov     r8, rdx\n        call    printf\n\n; Another \"magic\" instruction that undoes the effect of the previous\n; one before this procedure returns to its caller.\n\n        add     rsp, 56\n\n        ret     ; Returns to caller\n\nasmMain endp\n        end\n```", "```\nC:\\>**build  listing2-1**\n\nC:\\>**echo off**\n Assembling: listing2-1.asm\nc.cpp\n\nC:\\> **listing2-1**\nCalling Listing 2-1:\ni=1, converted to hex=1\nj=123, converted to hex=7b\nk=456789, converted to hex=6f855\nListing 2-1 terminated\n```", "```\n0000\n0001\n0010\n0011\n0100\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\n```", "```\n .data\nbyteVar  byte ?\n```", "```\n .data\nw        word  ?\n```", "```\n .data\nd     dword  ?\n```", "```\n .data\no     oword ?\nq     qword ?\n```", "```\n0 and 0 = 0\n0 and 1 = 0\n1 and 0 = 0\n1 and 1 = 1\n```", "```\n0 or 0 = 0\n0 or 1 = 1\n1 or 0 = 1\n1 or 1 = 1\n```", "```\n0 xor 0 = 0\n0 xor 1 = 1\n1 xor 0 = 1\n1 xor 1 = 0\n```", "```\nnot 0 = 1\nnot 1 = 0\n```", "```\n1011_0101b\n1110_1110b\n----------\n1010_0100b\n```", "```\nand  `dest`, `source`\nor   `dest`, `source`\nxor  `dest`, `source`\n```", "```\ndest = `dest` `operator` `source`\n```", "```\nnot  `dest` \n```", "```\ndest = not(`dest`)\n```", "```\n; Listing 2-2\n\n; Demonstrate AND, OR, XOR, and NOT logical instructions.\n\n            option  casemap:none\n\nnl          =       10  ; ASCII code for newline\n\n             .data\nleftOp       dword   0f0f0f0fh\nrightOp1     dword   0f0f0f0f0h\nrightOp2     dword   12345678h\n\ntitleStr     byte   'Listing 2-2', 0\n\nfmtStr1      byte   \"%lx AND %lx = %lx\", nl, 0\nfmtStr2      byte   \"%lx OR  %lx = %lx\", nl, 0\nfmtStr3      byte   \"%lx XOR %lx = %lx\", nl, 0\nfmtStr4      byte   \"NOT %lx = %lx\", nl, 0\n\n            .code\n            externdef   printf:proc\n\n; Return program title to C++ program:\n\n            public getTitle\ngetTitle    proc\n\n;  Load address of \"titleStr\" into the RAX register (RAX holds the\n;  function return result) and return back to the caller:\n\n            lea rax, titleStr\n            ret\ngetTitle    endp\n\n; Here is the \"asmMain\" function.\n\n            public  asmMain\nasmMain     proc\n\n; \"Magic\" instruction offered without explanation at this point:\n\n            sub     rsp, 56\n\n; Demonstrate the AND instruction:\n\n            lea     rcx, fmtStr1\n            mov     edx, leftOp\n            mov     r8d, rightOp1\n            mov     r9d, edx  ; Compute leftOp\n            and     r9d, r8d  ; AND rightOp1\n            call    printf\n\n            lea     rcx, fmtStr1\n            mov     edx, leftOp\n            mov     r8d, rightOp2\n            mov     r9d, r8d\n            and     r9d, edx\n            call    printf\n\n; Demonstrate the OR instruction:\n\n            lea     rcx, fmtStr2\n            mov     edx, leftOp\n            mov     r8d, rightOp1\n            mov     r9d, edx  ; Compute leftOp\n            or      r9d, r8d  ; OR rightOp1\n            call    printf\n\n            lea     rcx, fmtStr2\n            mov     edx, leftOp\n            mov     r8d, rightOp2\n            mov     r9d, r8d\n            or      r9d, edx\n            call    printf\n\n; Demonstrate the XOR instruction:\n\n            lea     rcx, fmtStr3\n            mov     edx, leftOp\n            mov     r8d, rightOp1\n            mov     r9d, edx  ; Compute leftOp\n            xor     r9d, r8d  ; XOR rightOp1\n            call    printf\n\n            lea     rcx, fmtStr3\n            mov     edx, leftOp\n            mov     r8d, rightOp2\n            mov     r9d, r8d\n xor     r9d, edx\n            call    printf\n\n; Demonstrate the NOT instruction:\n\n            lea     rcx, fmtStr4\n            mov     edx, leftOp\n            mov     r8d, edx  ; Compute not leftOp\n            not     r8d\n            call    printf\n\n            lea     rcx, fmtStr4\n            mov     edx, rightOp1\n            mov     r8d, edx  ; Compute not rightOp1\n            not     r8d\n            call    printf\n\n            lea     rcx, fmtStr4\n            mov     edx, rightOp2\n            mov     r8d, edx  ; Compute not rightOp2\n            not     r8d\n            call    printf\n\n; Another \"magic\" instruction that undoes the effect of the previous\n; one before this procedure returns to its caller.\n\n            add     rsp, 56\n\n            ret     ; Returns to caller\n\nasmMain     endp\n            end\n```", "```\nC:\\MASM64>**build  listing2-2**\n\nC:\\MASM64>**ml64 /nologo /c /Zi /Cp  listing2-2.asm**\n Assembling: listing2-2.asm\n\nC:\\MASM64>**cl /nologo /O2 /Zi /utf-8 /Fe listing2-2.exe c.cpp  listing2-2.obj**\nc.cpp\n\nC:\\MASM64> **listing2-2**\nCalling Listing 2-2:\nf0f0f0f AND f0f0f0f0 = 0\nf0f0f0f AND 12345678 = 2040608\nf0f0f0f OR  f0f0f0f0 = ffffffff\nf0f0f0f OR  12345678 = 1f3f5f7f\nf0f0f0f XOR f0f0f0f0 = ffffffff\nf0f0f0f XOR 12345678 = 1d3b5977\nNOT f0f0f0f = f0f0f0f0\nNOT f0f0f0f0 = f0f0f0f\nNOT 12345678 = edcba987\nListing 2-2 terminated\n```", "```\nxor `reg`, `reg`\n```", "```\nxor eax, eax  ; Just 2 bytes long in machine code\nmov eax, 0    ; Depending on register, often 6 bytes long\n```", "```\n 1111_1011b         Two's complement for -5\n    + 0000_0101b         Invert all the bits and add 1\n      ----------\n  (1) 0000_0000b         Sum is zero, if we ignore carry\n```", "```\n7FFFh:      0111_1111_1111_1111b   +32,767\n            1000_0000_0000_0000b   Invert all the bits (8000h)\n            1000_0000_0000_0001b   Add 1 (8001h or -32,767)\n\n4000h:      0100_0000_0000_0000b   16,384\n            1011_1111_1111_1111b   Invert all the bits (0BFFFh)\n            1100_0000_0000_0000b   Add 1 (0C000h or -16,384)\n\n8000h:      1000_0000_0000_0000b   -32,768\n            0111_1111_1111_1111b   Invert all the bits (7FFFh)\n            1000_0000_0000_0000b   Add one (8000h or -32,768)\n```", "```\nneg `dest` \n```", "```\n; Listing 2-3\n\n; Demonstrate two's complement operation and input of numeric values.\n\n        option  casemap:none\n\nnl       =      10  ; ASCII code for newline\nmaxLen   =      256\n\n         .data\ntitleStr byte   'Listing 2-3', 0\n\nprompt1  byte   \"Enter an integer between 0 and 127:\", 0\nfmtStr1  byte   \"Value in hexadecimal: %x\", nl, 0\nfmtStr2  byte   \"Invert all the bits (hexadecimal): %x\", nl, 0\nfmtStr3  byte   \"Add 1 (hexadecimal): %x\", nl, 0\nfmtStr4  byte   \"Output as signed integer: %d\", nl, 0\nfmtStr5  byte   \"Using neg instruction: %d\", nl, 0\n\nintValue sqword ?\ninput    byte   maxLen dup (?)\n\n            .code\n            externdef printf:proc\n            externdef atoi:proc\n            externdef readLine:proc\n\n; Return program title to C++ program:\n\n            public getTitle\ngetTitle    proc\n            lea rax, titleStr\n ret\ngetTitle    endp\n\n; Here is the \"asmMain\" function.\n\n            public  asmMain\nasmMain     proc\n\n; \"Magic\" instruction offered without explanation at this point:\n\n            sub     rsp, 56\n\n; Read an unsigned integer from the user: This code will blindly\n; assume that the user's input was correct. The atoi function returns\n; zero if there was some sort of error on the user input. Later\n; chapters in Ao64A will describe how to check for errors from the\n; user.\n\n            lea     rcx, prompt1\n            call    printf\n\n            lea     rcx, input\n            mov     rdx, maxLen\n            call    readLine\n\n; Call C stdlib atoi function.\n\n; i = atoi(str)\n\n            lea     rcx, input\n            call    atoi\n            and     rax, 0ffh      ; Only keep LO 8 bits\n            mov     intValue, rax\n\n; Print the input value (in decimal) as a hexadecimal number:\n\n            lea     rcx, fmtStr1\n            mov     rdx, rax\n            call    printf\n\n; Perform the two's complement operation on the input number.\n; Begin by inverting all the bits (just work with a byte here).\n\n            mov     rdx, intValue\n            not     dl             ; Only work with 8-bit values!\n            lea     rcx, fmtStr2\n            call    printf\n\n; Invert all the bits and add 1 (still working with just a byte).\n\n            mov     rdx, intValue\n            not     rdx\n            add     rdx, 1\n            and     rdx, 0ffh      ; Only keep LO eight bits\n lea     rcx, fmtStr3\n            call    printf\n\n; Negate the value and print as a signed integer (work with a full\n; integer here, because C++ %d format specifier expects a 32-bit\n; integer). HO 32 bits of RDX get ignored by C++.\n\n            mov     rdx, intValue\n            not     rdx\n            add     rdx, 1\n            lea     rcx, fmtStr4\n            call    printf\n\n; Negate the value using the neg instruction.\n\n            mov     rdx, intValue\n            neg     rdx\n            lea     rcx, fmtStr5\n            call    printf\n\n; Another \"magic\" instruction that undoes the effect of the previous\n; one before this procedure returns to its caller.\n\n            add     rsp, 56\n            ret     ; Returns to caller\nasmMain     endp\n            end\n```", "```\nC:\\>**build  listing2-3**\n\nC:\\>**echo off**\n Assembling: listing2-3.asm\nc.cpp\n\nC:\\> **listing2-3**\nCalling Listing 2-3:\nEnter an integer between 0 and 127:123\nValue in hexadecimal: 7b\nInvert all the bits (hexadecimal): 84\nAdd 1 (hexadecimal): 85\nOutput as signed integer: -123\nUsing neg instruction: -123\nListing 2-3 terminated\n```", "```\njmp `statement_label`\n```", "```\nstmtLbl: mov eax, 55\n```", "```\nanotherLabel:\n   mov eax, 55\n```", "```\n mov eax, int32Var\n    add eax, anotherVar\n    jc  overflowOccurred\n\n; Continue down here if the addition did not\n; produce an overflow.\n\n    .\n    .\n    .\n\noverflowOccurred:\n\n; Execute this code if the sum of int32Var and anotherVar\n; does not fit into 32 bits.\n```", "```\ncmp `left_operand`, `right_operand`\n```", "```\nshl `dest`, `count`\n```", "```\n1234 shl 1 = 12340\n```", "```\nshr `dest`, `count`\n```", "```\nsar `dest`, `count`\n```", "```\nrol `dest`, `count`\nror `dest`, `count`\n```", "```` ``` rcl `dest`, `count` rcr `dest`, `count` ```    The `count` operand is either a constant or the CL register, and the `dest` operand is a memory location or register. The `count` operand must be a value that is less than the number of bits in the `dest` operand. For a count value of 1, these two instructions do the rotation shown in [Figure 2-17](#figure2-17).  ![f02017a](image_fi/501089c02/f02017a.png)![f02017b](image_fi/501089c02/f02017b.png)    Figure 2-17: `rcl` `dest``, 1` and `rcr` `dest``, 1` operations      Unlike the shift instructions, the rotate-through-carry instructions do not affect the settings of the sign or zero flags. The OF flag is defined only for the 1-bit rotates. For left rotates, the OF flag is set if the original HO 2 bits change. For right rotates, the OF flag is set to the exclusive OR of the resultant HO 2 bits.    ## 2.12 Bit Fields and Packed Data    Although the x86-64 operates most efficiently on `byte`, `word`, `dword`, and `qword` data types, occasionally you’ll need to work with a data type that uses a number of bits other than 8, 16, 32, or 64\\. You can also zero-extend a nonstandard data size to the next larger power of 2 (such as extending a 22-bit value to a 32-bit value). This turns out to be fast, but if you have a large array of such values, slightly more than 31 percent of the memory is going to waste (10 bits in every 32-bit value). However, suppose you were to repurpose those 10 bits for something else? By *packing* the separate 22-bit and 10-bit values into a single 32-bit value, you don’t waste any space.    For example, consider a date of the form 04/02/01\\. Representing this date requires three numeric values: month, day, and year values. Months, of course, take on the values 1 to 12\\. At least 4 bits (a maximum of 16 different values) are needed to represent the month. Days range from 1 to 31\\. So it will take 5 bits (a maximum of 32 different values) to represent the day entry. The year value, assuming that we’re working with values in the range 0 to 99, requires 7 bits (which can be used to represent up to 128 different values). So, 4 + 5 + 7 = 16 bits, or 2 bytes.    In other words, we can pack our date data into 2 bytes rather than the 3 that would be required if we used a separate byte for each of the month, day, and year values. This saves 1 byte of memory for each date stored, which could be a substantial savings if you need to store many dates. The bits could be arranged as shown in [Figure 2-18](#figure2-18).  ![f02018](image_fi/501089c02/f02018.png)    Figure 2-18: Short packed date format (2 bytes)      *MMMM* represents the 4 bits making up the month value, *DDDDD* represents the 5 bits making up the day, and *YYYYYYY* is the 7 bits composing the year. Each collection of bits representing a data item is a *bit field*. For example, April 2, 2001, would be represented as 4101h:    ``` 0100      00010   0000001      = 0100_0001_0000_0001b or 4101h  4          2       01 ```    Although packed values are *space-efficient* (that is, they make efficient use of memory), they are computationally *inefficient* (slow!). The reason? It takes extra instructions to unpack the data packed into the various bit fields. These extra instructions take additional time to execute (and additional bytes to hold the instructions); hence, you must carefully consider whether packed data fields will save you anything. The sample program in [Listing 2-4](#listing2-4) demonstrates the effort that must go into packing and unpacking this 16-bit date format.    ``` ; Listing 2-4   ; Demonstrate packed data types.          option  casemap:none  NULL    =       0 nl      =       10  ; ASCII code for newline maxLen  =       256  ; New data declaration section. ; .const holds data values for read-only constants.              .const ttlStr      byte    'Listing 2-4', 0 moPrompt    byte    'Enter current month: ', 0 dayPrompt   byte    'Enter current day: ', 0 yearPrompt  byte    'Enter current year '             byte    '(last 2 digits only): ', 0             packed      byte    'Packed date is %04x', nl, 0 theDate     byte    'The date is %02d/%02d/%02d'             byte    nl, 0             badDayStr   byte    'Bad day value was entered '             byte    '(expected 1-31)', nl, 0             badMonthStr byte    'Bad month value was entered '             byte    '(expected 1-12)', nl, 0 badYearStr  byte    'Bad year value was entered '             byte    '(expected 00-99)', nl, 0              .data month       byte    ? day         byte    ? year        byte    ? date        word    ?  input       byte    maxLen dup (?)              .code             externdef printf:proc             externdef readLine:proc             externdef atoi:proc  ; Return program title to C++ program:              public getTitle getTitle    proc             lea rax, ttlStr             ret getTitle    endp  ; Here's a user-written function that reads a numeric value from the ; user:   ; int readNum(char *prompt);   ; A pointer to a string containing a prompt message is passed in the ; RCX register.   ; This procedure prints the prompt, reads an input string from the ; user, then converts the input string to an integer and returns the ; integer value in RAX.  readNum     proc  ; Must set up stack properly (using this \"magic\" instruction) before ; we can call any C/C++ functions:              sub     rsp, 56  ; Print the prompt message. Note that the prompt message was passed to ; this procedure in RCX, we're just passing it on to printf:              call    printf  ; Set up arguments for readLine and read a line of text from the user. ; Note that readLine returns NULL (0) in RAX if there was an error.              lea     rcx, input             mov     rdx, maxLen             call    readLine  ; Test for a bad input string:              cmp     rax, NULL             je      badInput  ; Okay, good input at this point, try converting the string to an ; integer by calling atoi. The atoi function returns zero if there was ; an error, but zero is a perfectly fine return result, so we ignore ; errors.              lea     rcx, input      ; Ptr to string             call    atoi            ; Convert to integer  badInput:             add     rsp, 56         ; Undo stack setup             ret readNum     endp  ; Here is the \"asmMain\" function.              public  asmMain asmMain     proc             sub     rsp, 56  ; Read the date from the user. Begin by reading the month:              lea     rcx, moPrompt             call    readNum  ; Verify the month is in the range 1..12:              cmp     rax, 1             jl      badMonth             cmp     rax, 12             jg      badMonth  ; Good month, save it for now:              mov     month, al       ; 1..12 fits in a byte  ; Read the day:              lea     rcx, dayPrompt             call    readNum  ; We'll be lazy here and verify only that the day is in the range ; 1..31.              cmp     rax, 1             jl      badDay             cmp     rax, 31             jg      badDay  ; Good day, save it for now:              mov     day, al         ; 1..31 fits in a byte  ; Read the year:              lea     rcx, yearPrompt             call    readNum  ; Verify that the year is in the range 0..99.              cmp     rax, 0             jl      badYear             cmp     rax, 99             jg      badYear  ; Good year, save it for now:              mov     year, al        ; 0..99 fits in a byte  ; Pack the data into the following bits:   ;  15 14 13 12 11 10  9  8  7  6  5  4  3  2  1  0 ;   m  m  m  m  d  d  d  d  d  y  y  y  y  y  y  y              movzx   ax, month             shl     ax, 5             or      al, day             shl     ax, 7             or      al, year             mov     date, ax  ; Print the packed date:              lea     rcx, packed             movzx   rdx, date             call    printf  ; Unpack the date and print it:              movzx   rdx, date             mov     r9, rdx             and     r9, 7fh         ; Keep LO 7 bits (year)             shr     rdx, 7          ; Get day in position             mov     r8, rdx  and     r8, 1fh         ; Keep LO 5 bits             shr     rdx, 5          ; Get month in position             lea     rcx, theDate             call    printf               jmp     allDone  ; Come down here if a bad day was entered:  badDay:             lea     rcx, badDayStr             call    printf             jmp     allDone  ; Come down here if a bad month was entered:  badMonth:             lea     rcx, badMonthStr             call    printf             jmp     allDone  ; Come down here if a bad year was entered:  badYear:             lea     rcx, badYearStr             call    printf    allDone:                    add     rsp, 56             ret     ; Returns to caller asmMain     endp             end ```    Listing 2-4: Packing and unpacking date data    Here’s the result of building and running this program:    ``` C:\\>**build  listing2-4**  C:\\>**echo off**  Assembling: listing2-4.asm c.cpp  C:\\> **listing2-4** Calling Listing 2-4: Enter current month: 2 Enter current day: 4 Enter current year (last 2 digits only): 68 Packed date is 2244 The date is 02/04/68 Listing 2-4 terminated ```    Of course, having gone through the problems with Y2K (Year 2000),^([10](#c02-footnote-10)) you know that using a date format that limits you to 100 years (or even 127 years) would be quite foolish. To future-proof the packed date format, we can extend it to 4 bytes packed into a double-word variable, as shown in [Figure 2-19](#figure2-19). (As you will see in Chapter 4, you should always try to create data objects whose length is an even power of 2—1 byte, 2 bytes, 4 bytes, 8 bytes, and so on—or you will pay a performance penalty.)  ![f02019](image_fi/501089c02/f02019.png)    Figure 2-19: Long packed date format (4 bytes)      The Month and Day fields now consist of 8 bits each, so they can be extracted as a byte object from the double word. This leaves 16 bits for the year, with a range of 65,536 years. By rearranging the bits so the Year field is in the HO bit positions, the Month field is in the middle bit positions, and the Day field is in the LO bit positions, the long date format allows you to easily compare two dates to see if one date is less than, equal to, or greater than another date. Consider the following code:    ```  mov eax, Date1  ; Assume Date1 and Date2 are dword variables     cmp eax, Date2  ; using the Long Packed Date format     jna d1LEd2              `Do something if Date1 > Date2`  d1LEd2: ```    Had you kept the different date fields in separate variables, or organized the fields differently, you would not have been able to compare `Date1` and `Date2` as easily as for the short packed data format. Therefore, this example demonstrates another reason for packing data even if you don’t realize any space savings—it can make certain computations more convenient or even more efficient (contrary to what normally happens when you pack data).    Examples of practical packed data types abound. You could pack eight Boolean values into a single byte, you could pack two BCD digits into a byte, and so on.    A classic example of packed data is the RFLAGS register. This register packs nine important Boolean objects (along with seven important system flags) into a single 16-bit register. You will commonly need to access many of these flags. You can test many of the condition code flags by using the conditional jump instructions and manipulate the individual bits in the FLAGS register with the instructions in [Table 2-12](#table2-12) that directly affect certain flags.      Table 2-12: Instructions That Affect Certain Flags       | **Instruction** | **Explanation** | | --- | --- | | `cld` | Clears (sets to `0`) the direction flag. | | `std` | Sets (to `1`) the direction flag. | | `cli` | Clears the interrupt disable flag. | | `sti` | Sets the interrupt disable flag. | | `clc` | Clears the carry flag. | | `stc` | Sets the carry flag. | | `cmc` | Complements (inverts) the carry flag. | | `sahf` | Stores the AH register into the LO 8 bits of the FLAGS register. (Warning: certain early x86-64 CPUs do not support this instruction.) | | `lahf` | Loads AH from the LO 8 bits of the FLAGS register. (Warning: certain early x86-64 CPUs do not support this instruction.) |    The `lahf` and `sahf` instructions provide a convenient way to access the LO 8 bits of the FLAGS register as an 8-bit byte (rather than as eight separate 1-bit values). See [Figure 2-20](#figure2-20) for a layout of the FLAGS register.  ![f02020](image_fi/501089c02/f02020.png)    Figure 2-20: FLAGS register as packed Boolean data      The `lahf` (*load AH with the LO eight bits of the FLAGS register*) and the `sahf` (*store AH into the LO byte of the RFLAGS register*) use the following syntax:    ```  lahf         sahf ```    ## 2.13 IEEE Floating-Point Formats    When Intel planned to introduce a floating-point unit (the 8087 FPU) for its new 8086 microprocessor, it hired the best numerical analyst it could find to design a floating-point format. That person then hired two other experts in the field, and the three of them (William Kahan, Jerome Coonen, and Harold Stone) designed Intel’s floating-point format. They did such a good job designing the KCS Floating-Point Standard that the Institute of Electrical and Electronics Engineers (IEEE) adopted this format for its floating-point format.^([11](#c02-footnote-11))    To handle a wide range of performance and accuracy requirements, Intel actually introduced *three* floating-point formats: single-precision, double-precision, and extended-precision. The single- and double-precision formats corresponded to C’s float and double types or FORTRAN’s real and double-precision types. The extended-precision format contains 16 extra bits that long chains of computations could use as guard bits before rounding down to a double-precision value when storing the result.    ### 2.13.1 Single-Precision Format    The *single-precision format* uses aone’s complement 24-bit mantissa, an 8-bit excess-127 exponent, and a single sign bit. The *mantissa* usually represents a value from 1.0 to just under 2.0\\. The HO bit of the mantissa is always assumed to be 1 and represents a value just to the left of the *binary point*.^([12](#c02-footnote-12)) The remaining 23 mantissa bits appear to the right of the binary point. Therefore, the mantissa represents the value:    ``` 1.mmmmmmm mmmmmmmm ```    The `mmmm` characters represent the 23 bits of the mantissa. Note that because the HO bit of the mantissa is always 1, the single-precision format doesn’t actually store this bit within the 32 bits of the floating-point number. This is known as an *implied bit*.    Because we are working with binary numbers, each position to the right of the binary point represents a value (`0` or `1`) times a successive negative power of 2\\. The implied 1 bit is always multiplied by 2⁰, which is 1\\. This is why the mantissa is always greater than or equal to 1\\. Even if the other mantissa bits are all 0, the implied 1 bit always gives us the value 1.^([13](#c02-footnote-13)) Of course, even if we had an almost infinite number of 1 bits after the binary point, they still would not add up to 2\\. This is why the mantissa can represent values in the range 1 to just under 2.    Although there is an infinite number of values between 1 and 2, we can represent only 8 million of them because we use a 23-bit mantissa (with the implied 24th bit always 1). This is the reason for inaccuracy in floating-point arithmetic—we are limited to a fixed number of bits in computations involving single-precision floating-point values.    The mantissa uses a *one’s* *complement* format rather than two’s complement to represent signed values. The 24-bit value of the mantissa is simply an unsigned binary number, and the sign bit determines whether that value is positive or negative. One’s complement numbers have the unusual property that there are two representations for 0 (with the sign bit set or clear). Generally, this is important only to the person designing the floating-point software or hardware system. We will assume that the value 0 always has the sign bit clear.    To represent values outside the range 1.0 to just under 2.0, the exponent portion of the floating-point format comes into play. The floating-point format raises 2 to the power specified by the exponent and then multiplies the mantissa by this value. The exponent is 8 bits and is stored in an *excess-127* format. In excess-127 format, the exponent 0 is represented by the value 127 (7Fh), negative exponents are values in the range 0 to 126, and positive exponents are values in the range 128 to 255\\. To convert an exponent to excess-127 format, add 127 to the exponent value. The use of excess-127 format makes it easier to compare floating-point values. The single-precision floating-point format takes the form shown in [Figure 2-21](#figure2-21).  ![f02021](image_fi/501089c02/f02021.png)    Figure 2-21: Single-precision (32-bit) floating-point format      With a 24-bit mantissa, you will get approximately six and a half (decimal) digits of precision (half a digit of precision means that the first six digits can all be in the range 0 to 9, but the seventh digit can be only in the range 0 to *x*, where *x* < 9 and is generally close to 5). With an 8-bit excess-127 exponent, the dynamic range^([14](#c02-footnote-14)) of single-precision floating-point numbers is approximately 2^(±127), or about 10^(±38).    Although single-precision floating-point numbers are perfectly suitable for many applications, the precision and dynamic range are somewhat limited and unsuitable for many financial, scientific, and other applications. Furthermore, during long chains of computations, the limited accuracy of the single-precision format may introduce serious error.    ### 2.13.2 Double-Precision Format    The *double-precision format* helps overcome the problems of single-precision floating-point. Using twice the space, the double-precision format has an 11-bit excess-1023 exponent and a 53-bit mantissa (with an implied HO bit of 1) plus a sign bit. This provides a dynamic range of about 10^(±308) and 14.5 digits of precision, sufficient for most applications. Double-precision floating-point values take the form shown in [Figure 2-22](#figure2-22).  ![f02022](image_fi/501089c02/f02022.png)    Figure 2-22: 64-bit double-precision floating-point format      ### 2.13.3 Extended-Precision Format    To ensure accuracy during long chains of computations involving double-precision floating-point numbers, Intel designed the *extended-precision format*. It uses 80 bits. Twelve of the additional 16 bits are appended to the mantissa, and 4 of the additional bits are appended to the end of the exponent. Unlike the single- and double-precision values, the extended-precision format’s mantissa does not have an implied HO bit. Therefore, the extended-precision format provides a 64-bit mantissa, a 15-bit excess-16383 exponent, and a 1-bit sign. [Figure 2-23](#figure2-23) shows the format for the extended-precision floating-point value.  ![f02023](image_fi/501089c02/f02023.png)    Figure 2-23: 80-bit extended-precision floating-point format      On the x86-64 FPU, all computations are done using the extended-precision format. Whenever you load a single- or double-precision value, the FPU automatically converts it to an extended-precision value. Likewise, when you store a single- or double-precision value to memory, the FPU automatically rounds the value down to the appropriate size before storing it. By always working with the extended-precision format, Intel guarantees that a large number of guard bits are present to ensure the accuracy of your computations.    ### 2.13.4 Normalized Floating-Point Values    To maintain maximum precision during computation, most computations use normalized values. A *normalized floating-point value* is one whose HO mantissa bit contains 1\\. Almost any non-normalized value can be normalized: shift the mantissa bits to the left and decrement the exponent until a 1 appears in the HO bit of the mantissa.    Remember, the exponent is a binary exponent. Each time you increment the exponent, you multiply the floating-point value by 2\\. Likewise, whenever you decrement the exponent, you divide the floating-point value by 2\\. By the same token, shifting the mantissa to the left one bit position multiplies the floating-point value by 2; likewise, shifting the mantissa to the right divides the floating-point value by 2\\. Therefore, shifting the mantissa to the left one position *and* decrementing the exponent does not change the value of the floating-point number at all.    Keeping floating-point numbers normalized is beneficial because it maintains the maximum number of bits of precision for a computation. If the HO *n* bits of the mantissa are all 0, the mantissa has that many fewer bits of precision available for computation. Therefore, a floating-point computation will be more accurate if it involves only normalized values.    In two important cases, a floating-point number cannot be normalized. Zero is one of these special cases. Obviously, it cannot be normalized because the floating-point representation for 0 has no 1 bits in the mantissa. This, however, is not a problem because we can exactly represent the value 0 with only a single bit.    In the second case, we have some HO bits in the mantissa that are 0, but the biased exponent is also 0 (and we cannot decrement it to normalize the mantissa). Rather than disallow certain small values, whose HO mantissa bits and biased exponent are 0 (the most negative exponent possible), the IEEE standard allows special *denormalized*values to represent these smaller values.^([15](#c02-footnote-15)) Although the use of denormalized values allows IEEE floating-point computations to produce better results than if underflow occurred, keep in mind that denormalized values offer fewer bits of precision.    ### 2.13.5 Non-Numeric Values    The IEEE floating-point standard recognizes three special non-numeric values: –infinity, +infinity, and a special not-a-number (NaN). For each of these special numbers, the exponent field is filled with all 1 bits.    If the exponent is all 1 bits and the mantissa is all 0 bits, then the value is infinity. The sign bit will be `0` for +infinity, and `1` for –infinity.    If the exponent is all 1 bits and the mantissa is not all 0 bits, then the value is an invalid number (known as a *not-a-number* in IEEE 754 terminology). NaNs represent illegal operations, such as trying to take the square root of a negative number.    Unordered comparisons occur whenever either operand (or both) is a NaN. As NaNs have an indeterminate value, they cannot be compared (that is, they are incomparable). Any attempt to perform an unordered comparison typically results in an exception or some sort of error. Ordered comparisons, on the other hand, involve two operands, neither of which are NaNs.    ### 2.13.6 MASM Support for Floating-Point Values    MASM provides several data types to support the use of floating-point data in your assembly language programs. MASM floating-point constants allow the following syntax:    *   An optional `+` or `-` symbol, denoting the sign of the mantissa (if this is not present, MASM assumes that the mantissa is positive) *   Followed by one or more decimal digits *   Followed by a decimal point and zero or more decimal digits *   Optionally followed by an `e` or `E`, optionally followed by a sign (`+` or `-`) and one or more decimal digits    The decimal point or the `e`/`E` must be present in order to differentiate this value from an integer or unsigned literal constant. Here are some examples of legal literal floating-point constants:    ``` 1.234  3.75e2  -1.0  1.1e-1  1.e+4  0.1  -123.456e+789  +25.0e0  1.e3 ```    A floating-point literal constant must begin with a decimal digit, so you must use, for example, 0.1 to represent .1 in your programs.    To declare a floating-point variable, you use the `real4`, `real8`, or `real10` data types. The number at the end of these data type declarations specifies the number of bytes used for each type’s binary representation. Therefore, you use `real4` to declare single-precision real values, `real8` to declare double-precision floating-point values, and `real10` to declare extended-precision floating-point values. Aside from using these types to declare floating-point variables rather than integers, their use is nearly identical to that of `byte`, `word`, `dword`*,* and so on. The following examples demonstrate these declarations and their syntax:    ```  .data  fltVar1  real4  ? fltVar1a real4  2.7 pi       real4  3.14159 DblVar   real8  ? DblVar2  real8  1.23456789e+10 XPVar    real10 ? XPVar2   real10 -1.0e-104 ```    As usual, this book uses the C/C++ `printf()` function to print floating-point values to the console output. Certainly, an assembly language routine could be written to do this same thing, but the C Standard Library provides a convenient way to avoid writing that (complex) code, at least for the time being.    ## 2.14 Binary-Coded Decimal Representation    Although the integer and floating-point formats cover most of the numeric needs of an average program, in some special cases other numeric representations are convenient. In this section, we’ll discuss the *binary-coded decimal (BCD)* format because the x86-64 CPU provides a small amount of hardware support for this data representation.    BCD values are a sequence of nibbles, with each nibble representing a value in the range 0 to 9\\. With a single byte, we can represent values containing two decimal digits, or values in the range 0 to 99 (see [Figure 2-24](#figure2-24)).  ![f02024](image_fi/501089c02/f02024.png)    Figure 2-24: BCD data representation in memory      As you can see, BCD storage isn’t particularly memory efficient. For example, an 8-bit BCD variable can represent values in the range 0 to 99, while that same 8 bits, when holding a binary value, can represent values in the range 0 to 255\\. Likewise, a 16-bit binary value can represent values in the range 0 to 65,535, while a 16-bit BCD value can represent only about one-sixth of those values (0 to 9999).    However, it’s easy to convert BCD values between the internal numeric representation and their string representation, and to encode multi-digit decimal values in hardware (for example, using a thumb wheel or dial) using BCD. For these two reasons, you’re likely to see people using BCD in embedded systems (such as toaster ovens, alarm clocks, and nuclear reactors) but rarely in general-purpose computer software.    The Intel x86-64 floating-point unit supports a pair of instructions for loading and storing BCD values. Internally, however, the FPU converts these BCD values to binary and performs all calculations in binary. It uses BCD only as an external data format (external to the FPU, that is). This generally produces more-accurate results and requires far less silicon than having a separate coprocessor that supports decimal arithmetic.    ## 2.15 Characters    Perhaps the most important data type on a personal computer is the `character` data type. The term *character* refers to a human or machine-readable symbol that is typically a non-numeric entity, specifically any symbol that you can normally type on a keyboard (including some symbols that may require multiple keypresses to produce) or display on a video display. Letters (*alphabetic characters*), punctuation symbols, numeric digits, spaces, tabs, carriage returns (enter), other control characters, and other special symbols are all characters.    Most computer systems use a 1- or 2-byte sequence to encode the various characters in binary form. Windows, macOS, FreeBSD, and Linux use either the ASCII or Unicode encodings for characters. This section discusses the ASCII and Unicode character sets and the character declaration facilities that MASM provides.    ### 2.15.1 The ASCII Character Encoding    The *American Standard Code for Information Interchange (ASCII) character set* maps 128 textual characters to the unsigned integer values 0 to 127 (0 to 7Fh). Although the exact mapping of characters to numeric values is arbitrary and unimportant, using a standardized code for this mapping is important because when you communicate with other programs and peripheral devices, you all need to speak the same “language.” ASCII is a standardized code that nearly everyone has agreed on: if you use the ASCII code 65 to represent the character `A`, then you know that a peripheral device (such as a printer) will correctly interpret this value as the character `A` whenever you transmit data to that device.    Despite some major shortcomings, ASCII data has become thestandard for data interchange across computer systems and programs.^([16](#c02-footnote-16)) Most programs can accept ASCII data; likewise, most programs can produce ASCII data. Because you will be dealing with ASCII characters in assembly language, it would be wise to study the layout of the character set and memorize a few key ASCII codes (for example, for `0`, `A`, `a`, and so on). See Appendix A for a list of all the ASCII character codes.    The ASCII character set is divided into four groups of 32 characters. The first 32 characters, ASCII codes 0 to 1Fh (31), form a special set of nonprinting characters, the *control characters*. We call them control characters because they perform various printer/display control operations rather than display symbols. Examples include *carriage return*, which positions the cursor to the left side of the current line of characters;^([17](#c02-footnote-17)) line feed, which moves the cursor down one line on the output device; and backspace, which moves the cursor back one position to the left.    Unfortunately, different control characters perform different operations on different output devices. Little standardization exists among output devices. To find out exactly how a control character affects a particular device, you will need to consult its manual.    The second group of 32 ASCII character codes contains various punctuation symbols, special characters, and the numeric digits. The most notable characters in this group include the space character (ASCII code 20h) and the numeric digits (ASCII codes 30h to 39h).    The third group of 32 ASCII characters contains the uppercase alphabetic characters. The ASCII codes for the characters `A` to `Z` lie in the range 41h to 5Ah (65 to 90). Because there are only 26 alphabetic characters, the remaining 6 codes hold various special symbols.    The fourth, and final, group of 32 ASCII character codes represents the lowercase alphabetic symbols, 5 additional special symbols, and another control character (delete). The lowercase character symbols use the ASCII codes 61h to 7Ah. If you convert the codes for the upper- and lowercase characters to binary, you will notice that the uppercase symbols differ from their lowercase equivalents in exactly one bit position. For example, consider the character codes for `E` and `e` appearing in [Figure 2-25](#figure2-25).  ![f02025](image_fi/501089c02/f02025.png)    Figure 2-25: ASCII codes for *E* and *e*      The only place these two codes differ is in bit 5\\. Uppercase characters always contain a 0 in bit 5; lowercase alphabetic characters always contain a 1 in bit 5\\. You can use this fact to quickly convert between upper- and lowercase. If you have an uppercase character, you can force it to lowercase by setting bit 5 to 1\\. If you have a lowercase character, you can force it to uppercase by setting bit 5 to 0\\. You can toggle an alphabetic character between upper- and lowercase by simply inverting bit 5.    Indeed, bits 5 and 6 determine which of the four groups in the ASCII character set you’re in, as [Table 2-13](#table2-13) shows.      Table 2-13: ASCII Groups       | **Bit 6** | **Bit 5** | **Group** | | --- | --- | --- | | 0 | 0 | Control characters | | 0 | 1 | Digits and punctuation | | 1 | 0 | Uppercase and special | | 1 | 1 | Lowercase and special |    So you could, for instance, convert any upper- or lowercase (or corresponding special) character to its equivalent control character by setting bits 5 and 6 to 0\\.    Consider, for a moment, the ASCII codes of the numeric digit characters appearing in [Table 2-14](#table2-14).      Table 2-14: ASCII Codes for Numeric Digits       | **Character** | **Decimal** | **Hexadecimal** | | --- | --- | --- | | 0 | 48 | 30h | | 1 | 49 | 31h | | 2 | 50 | 32h | | 3 | 51 | 33h | | 4 | 52 | 34h | | 5 | 53 | 35h | | 6 | 54 | 36h | | 7 | 55 | 37h | | 8 | 56 | 38h | | 9 | 57 | 39h |    The LO nibble of the ASCII code is the binary equivalent of the represented number. By stripping away (that is, setting to `0`) the HO nibble of a numeric character, you can convert that character code to the corresponding binary representation. Conversely, you can convert a binary value in the range 0 to 9 to its ASCII character representation by simply setting the HO nibble to `3`. You can use the logical AND operation to force the HO bits to 0; likewise, you can use the logical OR operation to force the HO bits to 0011b (3).    Unfortunately, you *cannot* convert a string of numeric characters to their equivalent binary representation by simply stripping the HO nibble from each digit in the string. Converting 123 (31h 32h 33h) in this fashion yields 3 bytes, 010203h, but the correct value for 123 is 7Bh. The conversion described in the preceding paragraph works only for single digits.    ### 2.15.2 MASM Support for ASCII Characters    MASM provides support for character variables and literals in your assembly language programs. Character literal constants in MASM take one of two forms: a single character surrounded by apostrophes or a single character surrounded by quotes, as follows:    ``` 'A'  \"A\"  ```    Both forms represent the same character (`A`).    If you wish to represent an apostrophe or a quote within a string, use the other character as the string delimiter. For example:    ``` 'A \"quotation\" appears within this string' \"Can't have quotes in this string\"  ```    Unlike the C/C++ language, MASM doesn’t use different delimiters for single-character objects versus string objects, or differentiate between a character constant and a string constant with a single character. A character literal constant has a single character between the quotes (or apostrophes); a string literal has multiple characters between the delimiters.    To declare a character variable in a MASM program, you use the `byte` data type. For example, the following declaration demonstrates how to declare a variable named `UserInput`:    ```  .data UserInput      byte ? ```    This declaration reserves 1 byte of storage that you could use to store any character value (including 8-bit extended ASCII/ANSI characters). You can also initialize character variables as follows:    ```  .data TheCharA      byte 'A' ExtendedChar  byte 128 ; Character code greater than 7Fh ```    Because character variables are 8-bit objects, you can manipulate them using 8-bit registers. You can move character variables into 8-bit registers, and you can store the value of an 8-bit register into a character variable.    ## 2.16 The Unicode Character Set    The problem with ASCII is that it supports only 128 character codes. Even if you extend the definition to 8 bits (as IBM did on the original PC), you’re limited to 256 characters. This is way too small for modern multinational/multilingual applications. Back in the 1990s, several companies developed an extension to ASCII, known as *Unicode*, using a 2-byte character size. Therefore, (the original) Unicode supported up to 65,536 character codes.    Alas, as well-thought-out as the original Unicode standard could be, systems engineers discovered that even 65,536 symbols were insufficient. Today, Unicode defines 1,112,064 possible characters, encoded using a variable-length character format.    ### 2.16.1 Unicode Code Points    A Unicode *code point* is an integer value that Unicode associates with a particular character symbol. The convention for Unicode code points is to specify the value in hexadecimal with a preceding U+ prefix; for example, U+0041 is the Unicode code point for the `A` character (41h is also the ASCII code for `A`; Unicode code points in the range U+0000 to U+007F correspond to the ASCII character set).    ### 2.16.2 Unicode Code Planes    The Unicode standard defines code points in the range U+000000 to U+10FFFF (10FFFFh is 1,114,111, which is where most of the 1,112,064 characters in the Unicode character set come from; the remaining 2047 code points are reserved for use as *surrogates*, which are Unicode extensions).^([18](#c02-footnote-18)) The Unicode standard breaks this range up into 17 *multilingual planes*, each supporting up to 65,536 code points. The HO two hexadecimal digits of the six-digit code point value specify the multilingual plane, and the remaining four digits specify the character within the plane.    The first multilingual plane, U+000000 to U+00FFFF, roughly corresponds to the original 16-bit Unicode definition; the Unicode standard calls this the *Basic Multilingual Plane (BMP)*. Planes 1 (U+010000 to U+01FFFF), 2 (U+020000 to U+02FFFF), and 14 (U+0E0000 to U+0EFFFF) are supplementary (extension) planes. Unicode reserves planes 3 to 13 for future expansion, and planes 15 and 16 for user-defined character sets.    Obviously, representing Unicode code points outside the BMP requires more than 2 bytes. To reduce memory usage, Unicode (specifically the UTF-16 encoding; see the next section) uses 2 bytes for the Unicode code points in the BMP, and uses 4 bytes to represent code points outside the BMP. Within the BMP, Unicode reserves the surrogate code points (U+D800–U+DFFF) to specify the 16 planes after the BMP. [Figure 2-26](#figure2-26) shows the encoding.  ![f02026](image_fi/501089c02/f02026.png)    Figure 2-26: Surrogate code point encoding for Unicode planes 1 to 16      Note that the two words (unit 1 and unit 2) always appear together. The unit 1 value (with HO bits 110110b) specifies the upper 10 bits (b[10] to b[19]) of the Unicode scalar, and the unit 2 value (with HO bits 110111b) specifies the lower 10 bits (b[0] to b[9]) of the Unicode scalar. Therefore, bits b[16] to b[19] (plus one) specify Unicode plane 1 to 16\\. Bits b[0] to b[15] specify the Unicode scalar value within the plane.    ### 2.16.3 Unicode Encodings    As of Unicode v2.0, the standard supports a 21-bit character space capable of handling over a million characters (though most of the code points remain reserved for future use). Rather than use a 3-byte (or worse, 4-byte) encoding to allow the larger character set, Unicode, Inc., allowed different encodings, each with its own advantages and disadvantages.    *UTF-32* uses 32-bit integers to hold Unicode scalars.^([19](#c02-footnote-19)) The advantage to this scheme is that a 32-bit integer can represent every Unicode scalar value (which requires only 21 bits). Programs that require random access to characters in strings (without having to search for surrogate pairs) and other constant-time operations are (mostly) possible when using UTF-32\\. The obvious drawback to UTF-32 is that each Unicode scalar value requires 4 bytes of storage (twice that of the original Unicode definition and four times that of ASCII characters).    The second encoding format the Unicode supports is *UTF-16*. As the name suggests, UTF-16 uses 16-bit (unsigned) integers to represent Unicode values. To handle scalar values greater than 0FFFFh, UTF-16 uses the surrogate pair scheme to represent values in the range 010000h to 10FFFFh (see the discussion of code planes and surrogate code points in the previous section). Because the vast majority of useful characters fit into 16 bits, most UTF-16 characters require only 2 bytes. For those rare cases where surrogates are necessary, UTF-16 requires two words (32 bits) to represent the character.    The last encoding, and unquestionably the most popular, is *UTF-8*. The UTF-8 encoding is upward compatible from the ASCII character set. In particular, all ASCII characters have a single-byte representation (their original ASCII code, where the HO bit of the byte containing the character contains a 0 bit). If the UTF-8 HO bit is 1, UTF-8 requires additional bytes (1 to 3 additional bytes) to represent the Unicode code point. [Table 2-15](#table2-15) provides the UTF-8 encoding schema.      Table 2-15: UTF-8 Encoding       | **Bytes** | **Bits for code point** | **First code point** | **Last code point** | **Byte 1** | **Byte 2** | **Byte 3** | **Byte 4** | | --- | --- | --- | --- | --- | --- | --- | --- | | 1 | 7 | U+00 | U+7F | 0*xxxxxxx* |  |  |  | | 2 | 11 | U+80 | U+7FF | 110*xxxxx* | 10*xxxxxx* |  |  | | 3 | 16 | U+800 | U+FFFF | 1110*xxxx* | 10*xxxxxx* | 10*xxxxxx* |  | | 4 | 21 | U+10000 | U+10FFFF | 11110*xxx* | 10*xxxxxx* | 10*xxxxxx* | 10*xxxxxx* |    The `xxx...` bits are the Unicode code point bits. For multi-byte sequences, byte 1 contains the HO bits, byte 2 contains the next HO bits, and so on. For example, the 2-byte sequence 11011111b, 10000001b corresponds to the Unicode scalar 0000_0111_1100_0001b (U+07C1).    ## 2.17 MASM Support for Unicode    Unfortunately, MASM provides almost zero support for Unicode text in a source file. Fortunately, MASM’s macro facilities provide a way for you to create your own Unicode support for strings in MASM. See Chapter 13 for more details on MASM macros. I will also return to this subject in *The Art of 64-Bit Assembly*, Volume 2, where I will spend considerable time describing how to force MASM to accept and process Unicode strings in source and resource files.    ## 2.18 For More Information    For general information about data representation and Boolean functions, consider reading my book *Write Great Code*, Volume 1, Second Edition (No Starch Press, 2020), or a textbook on data structures and algorithms (available at any bookstore).    ASCII, EBCDIC, and Unicode are all international standards. You can find out more about the Extended Binary Coded Decimal Interchange Code (EBCDIC) character set families on IBM’s website ([http://www.ibm.com/](http://www.ibm.com/)). ASCII and Unicode are both International Organization for Standardization (ISO) standards, and ISO provides reports for both character sets. Generally, those reports cost money, but you can also find out lots of information about the ASCII and Unicode character sets by searching for them by name on the internet. You can also read about Unicode at [http://www.unicode.org/](http://www.unicode.org/). *Write Great Code* also contains additional information on the history, use, and encoding of the Unicode character set.    ## 2.19 Test Yourself    1.  What does the decimal value 9384.576 represent (in terms of powers of 10)? 2.  Convert the following binary values to decimal:     1.  1010     2.  1100     3.  0111     4.  1001     5.  0011     6.  1111 3.  Convert the following binary values to hexadecimal:     1.  1010     2.  1110     3.  1011     4.  1101     5.  0010     6.  1100     7.  1100_1111     8.  1001_1000_1101_0001 4.  Convert the following hexadecimal values to binary:          1.  12AF     2.  9BE7     3.  4A     4.  137F     5.  F00D     6.  BEAD     7.  4938  5.  Convert the following hexadecimal values to decimal:     1.  A     2.  B     3.  F     4.  D     5.  E     6.  C 6.  How many bits are there in a     1.  Word     2.  Qword     3.  Oword     4.  Dword     5.  BCD digit     6.  Byte     7.  Nibble 7.  How many bytes are there in a     1.  Word     2.  Dword     3.  Qword     4.  Oword 8.  How different values can you represent with a     1.  Nibble     2.  Byte     3.  Word     4.  Bit 9.  How many bits does it take to represent a hexadecimal digit? 10.  How are the bits in a byte numbered? 11.  Which bit number is the LO bit of a word? 12.  Which bit number is the HO bit of a dword? 13.  Compute the logical AND of the following binary values:     1.  0 and 0     2.  0 and 1     3.  1 and 0     4.  1 and 1 14.  Compute the logical OR of the following binary values:     1.  0 and 0     2.  0 and 1     3.  1 and 0     4.  1 and 1 15.  Compute the logical XOR of the following binary values:     1.  0 and 0     2.  0 and 1     3.  1 and 0     4.  1 and 1 16.  The logical NOT operation is the same as XORing with what value? 17.  Which logical operation would you use to force bits to 0 in a bit string? 18.  Which logical operation would you use to force bits to 1 in a bit string? 19.  Which logical operation would you use to invert all the bits in a bit string? 20.  Which logical operation would you use to invert selected bits in a bit string? 21.  Which machine instruction will invert all the bits in a register? 22.  What is the two’s complement of the 8-bit value 5 (00000101b)? 23.  What is the two’s complement of the signed 8-bit value –2 (11111110)? 24.  Which of the following signed 8-bit values are negative?     1.  1111_1111b     2.  0111_0001b     3.  1000_0000b     4.  0000_0000b     5.  1000_0001b     6.  0000_0001b 25.  Which machine instruction takes the two’s complement of a value in a register or memory location? 26.  Which of the following 16-bit values can be correctly sign-contracted to 8 bits?          1.  1111_1111_1111_1111     2.  1000_0000_0000_0000     3.  000_0000_0000_0001     4.  1111_1111_1111_0000     5.  1111_1111_0000_0000     6.  0000_1111_0000_1111     7.  0000_0000_1111_1111     8.  0000_0001_0000_0000  27.  What machine instruction provides the equivalent of an HLL `goto` statement? 28.  What is the syntax for a MASM statement label? 29.  What flags are the condition codes? 30.  *JE* is a synonym for what instruction that tests a condition code? 31.  *JB* is a synonym for what instruction that tests a condition code? 32.  Which conditional jump instructions transfer control based on an unsigned comparison? 33.  Which conditional jump instructions transfer control based on a signed comparison? 34.  How does the SHL instruction affect the zero flag? 35.  How does the SHL instruction affect the carry flag? 36.  How does the SHL instruction affect the overflow flag? 37.  How does the SHL instruction affect the sign flag? 38.  How does the SHR instruction affect the zero flag? 39.  How does the SHR instruction affect the carry flag? 40.  How does the SHR instruction affect the overflow flag? 41.  How does the SHR instruction affect the sign flag? 42.  How does the SAR instruction affect the zero flag? 43.  How does the SAR instruction affect the carry flag? 44.  How does the SAR instruction affect the overflow flag? 45.  How does the SAR instruction affect the sign flag? 46.  How does the RCL instruction affect the carry flag? 47.  How does the RCL instruction affect the zero flag? 48.  How does the RCR instruction affect the carry flag? 49.  How does the RCR instruction affect the sign flag? 50.  A shift left is equivalent to what arithmetic operation? 51.  A shift right is equivalent to what arithmetic operation? 52.  When performing a chain of floating-point addition, subtraction, multiplication, and division operations, which operations should you try to do first? 53.  How should you compare floating-point values for equality? 54.  What is a normalized floating-point value? 55.  How many bits does a (standard) ASCII character require? 56.  What is the hexadecimal representation of the ASCII characters 0 through 9? 57.  What delimiter character(s) does MASM use to define character constants? 58.  What are the three common encodings for Unicode characters? 59.  What is a Unicode code point? 60.  What is a Unicode code plane? ````"]