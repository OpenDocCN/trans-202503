<html><head></head><body>
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="125" id="Page_125"/>10</span><br/>
<span class="ChapterTitle">Troubleshooting Hosts</span></h1>
</header>
<figure class="opener">
<img src="image_fi/book_art/chapterart.png" alt=""/>
</figure>
<p class="ChapterIntro">Engineers spend a lot of time trying to figure out why something isn’t working as intended. Instrumentation, tracing, and monitoring play big roles in determining the health of a host or application, but sometimes, observability is not enough. There will be times when you’ll need to roll up your sleeves and figure out why something is broken and how to fix it. In other words, you’ll be troubleshooting and debugging. <em>Troubleshooting</em> is the process of analyzing the system and rooting out potential causes of trouble. <em>Debugging</em>, on the other hand, is the process of discovering the cause of trouble and possibly implementing steps to remedy it. The differences are subtle, and in fact, you can think of debugging as a subset of troubleshooting. Most of what you’ll do in this chapter is considered troubleshooting.</p>
<p><span epub:type="pagebreak" title="126" id="Page_126"/>In this chapter, you’ll explore common performance problems and issues you may encounter on a Linux host. You’ll look at symptoms, commands you can use to diagnose various potential problems, and the next steps to take after troubleshooting. By the end of this chapter, you’ll have expanded your command line arsenal and sleuthing skills to troubleshoot common issues.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p> 	All scenarios in this chapter are geared toward Linux. If you are using another OS, like macOS, these concepts might cross over, but the tools can behave differently. Check the tools’ documentation for your OS for any potential differences. I mostly used tools that were installed by default, but you’ll need to install some of them using your local package manager. The tools I chose have some overlap in some cases, but I wanted to give you a variety to make you comfortable with different ways to poke a host. </p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1-502482c10-0001">Troubleshooting and Debugging: A Primer</h2>
<p class="BodyFirst">Troubleshooting and debugging is an art, not an exact science. Rarely will you see a big neon sign with an arrow pointing to the exact issue. Most of the time, you’ll find a trail of breadcrumbs that leads you from clue to clue. You may have to crawl through the weeds to find those crumbs, and you may want to pull out your hair before you find what you’re looking for. But diagnosing a broken system can be very rewarding, and figuring out an issue that’s plaguing your customers or haunting a coworker can feel amazing. </p>
<p>But even an artist needs a method, and having a standard set of steps and techniques to follow whenever you are investigating an issue is a great way to start. So here are some tips to keep in mind when venturing forth to confront those fickle beasts we call hosts:</p>
<ol class="none">
<li><span class="RunInHead">Start simple. </span>  When troubleshooting a problem, it can be tempting to jump to conclusions and assume it’s the worst-case scenario. Instead, be methodical and build upon the knowledge you have gained. The problem is usually human error.</li>
<li><span class="RunInHead">Build a mental model. </span>  Understanding what the system’s role is and how it interacts with other systems will help you troubleshoot faster. You will find yourself spending less time worrying about architecture and more time working on the issue.</li>
<li><span class="RunInHead">Take your time developing a theory. </span>  You may want to latch on to the first clue you find, but it’s always worth checking to see if the breadcrumb trail leads any farther. Come up with a test to validate your theory.</li>
<li><span class="RunInHead">Have consistent tools across hosts. </span>  Make sure your hosts were built with the same tooling. There is nothing worse than logging in to a host and finding out it is not like the others. Tool consistency is one of the benefits of building your hosts with automation.</li>
<li><span epub:type="pagebreak" title="127" id="Page_127"/><span class="RunInHead">Keep a journal. </span>  Keep a high-level account of problems, symptoms, and fixes so you don’t forget important details about an issue. Your future self will thank you.</li>
<li><span class="RunInHead">Know when to ask for help. </span>  If your business depends on solving an issue but you are struggling to find the cause, it is best to send up a flare. Someone with more experience can usually help, and someday, you will pay that knowledge forward or maybe even return the favor.<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	All the commands used in this chapter have many more use cases and a plethora of parameters and flags they can accept. If you are unsure about a flag or want to learn more, visit the command’s man pages for more information.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside></li>
</ol>
<h2 id="h1-502482c10-0002">Scenario: High Load Average</h2>
<p class="BodyFirst">Linux has a metric called <em>load average</em> that provides an idea of how busy a host is. The load average takes into account data like CPU and I/O when calculating this number. The load of a system is displayed in 1-minute, 5-minute, and 15-minute averages. At first glance, any high number in an average might seem like a problem. But troubleshooting a high load average can be tricky because a high load doesn’t always indicate that your host is in a degraded state. A busy host can have a high load but still respond to requests and commands without issue. It’s like when two people have the same temperature, but one person is awake and functioning in a normal capacity and the other is bedridden and lethargic. Each host and workload is different, so you first need to identify what a normal range for your host looks like. A good rule of thumb is if the load average is larger than the CPU core count, you may have processes waiting and causing latency or performance degradation. When investigating this scenario, a good first step is to identify the high load and try to locate any process that could be causing it. </p>
<h3 id="h2-502482c10-0001">uptime</h3>
<p class="BodyFirst">Enter the <code class="bold">uptime</code> command to display how long a host has been running, the number of logged-in users, and the system load. It reports the load in 1-minute, 5-minute, and 15-minute averages:</p>
<pre><code>$ <b>uptime</b>
09:30:38 up 47 days, 31 min, 2 users, load average: 8.05, 1.01, 0.00</code></pre>
<p>This four-core CPU host has been <code>up</code> for <code>47 days</code> and <code>31 minutes</code>, and <code>2 users</code> are currently logged in. The 1-minute <code>load average</code> is <code>8.05</code>. The 5-minute <code>load average</code> is <code>1.01</code>, which means the pressure on the system has been increasing during somewhere between 1 and 5 minutes of runtime. You know this because the 15-minute <code>load average</code> is <code>0.00</code> (no load at that time). If the numbers were reversed, with the 15-minute load showing <span epub:type="pagebreak" title="128" id="Page_128"/>the higher number and the 1-minute load at zero, you could infer that the spike in load is not ongoing and happened around 15 minutes ago. Since this load seems to be increasing and has been climbing for more than 5 minutes, and since it is greater than the CPU core count, it may be worth investigating why.</p>
<h3 id="h2-502482c10-0002">top</h3>
<p class="BodyFirst">The <code>top</code> command displays information about a system and the processes running on that host. It provides details like CPU percentage, load average, memory, and process information. Execute the <code class="bold">top</code> command to launch an interactive real-time dashboard showing system information, as shown in <a href="#figure10-1" id="figureanchor10-1">Figure 10-1</a>.</p>

<figure>
<img src="image_fi/502482c10/f10001.png" class="" alt="Screenshot of running the top command, showing all the system information in several columns with a summary at the top"/>
<figcaption><p><a id="figure10-1">Figure 10-1</a>: The <span class="LiteralInCaption"><code>top</code></span> command output on a mostly idle host</p></figcaption>
</figure>


<p>By default, <code>top</code> sorts all the processes by <code>CPU</code> percentage. The first row contains the process using the most <code>CPU</code> percentage at that given poll cycle. The display refreshes (polls) every 3.0 seconds, so you’ll want to view <code>top</code> for a few cycles before settling on a process or any data that might be or indicate the cause of the high load. </p>
<p>The following snippet is from a <code>top</code> report where a process is using 120 percent CPU:</p>
<pre><code>PID  USER   ...    RES   SHR  S  %CPU  %MEM     TIME+  COMMAND
3048 root   ... 177740  5164  S 120.3   1.8 173:02.78  fail2ban-server</code></pre>
<p>The key columns are <code>PID</code>, <code>RES</code>, <code>%CPU</code>, <code>%MEM</code>, and <code>COMMAND</code>. (Others are omitted here for readability.) The <code>fail2ban-server</code> command (in the <code>COMMAND</code> column) is using 120.3 percent CPU and is consuming around <code>177,740</code>KB of memory, as shown in the <code>RES</code> column. This process is using around <code>1.8</code> percent of the total memory (<code>%MEM</code>) available on the host. Taking everything into account, it would be a good idea for you to investigate process <code>3048</code> to determine why it is using so much CPU.</p>
<h3 id="h2-502482c10-0003"><span epub:type="pagebreak" title="129" id="Page_129"/>Next Steps</h3>
<p class="BodyFirst">In a scenario with a high load average, you’ll want to dig down further into the offending process. Perhaps this application is misconfigured, hung, or busy waiting on external resources (like a disk or an HTTP call). Maybe the host is undersized for its use case. If it’s a cloud-based instance, perhaps there aren’t enough CPU cores or disk IOPS. Also, check whether the host is experiencing increased traffic during this time, as that could indicate an intermittent spike. You can also use tools like <code>vmstat</code>, <code>strace</code>, and <code>lsof</code> to discover more about a process’s interaction with the system. (You’ll learn more details about those tools in later sections.)</p>
<h2 id="h1-502482c10-0003">Scenario: High Memory Usage</h2>
<p class="BodyFirst">Temporary spikes in traffic, performance-related issues, or an application with a memory leak can cause memory to be consumed at a high rate. The first step in investigating high memory usage is to make sure the host is really running low on memory. Linux likes to use all the memory for caches and buffers, so it can appear that free memory is low. But the Linux kernel can reallocate that cached memory elsewhere if needed. The <code>free</code>, <code>vmstat</code>, and <code>ps</code> commands can help identify how much memory is being used and what process may be the culprit.</p>
<h3 id="h2-502482c10-0004">free</h3>
<p class="BodyFirst">The <code>free</code> command provides a quick sanity check on system memory by displaying used and available memory at the time it is run. Pass the <code>-h</code> and <code>-m</code> flags to instruct the <code>free</code> command to show all output fields in human-readable (<code>-h</code>) format using the <em>mebibyte</em> unit (<code>-m</code>) of measure. In <em>human-readable format</em>, data appears in familiar units like <em>mebibyte</em> or <em>gibibyte</em> instead of bytes. The following example shows a host that’s low on available memory. Enter the following command to display memory:</p>
<pre><code>$ <b>free -hm</b>
           total        used        free     shared  buff/cache available
Mem:       981Mi       838Mi        95Mi      3.0Mi        47Mi      43Mi
Swap:      1.0Gi       141Mi       882Mi</code></pre>
<p>The system contains <code>981Mi</code> of <code>total </code>memory, and <code>838Mi</code> of memory is being <code>used</code>, with <code>95Mi</code> <code>free</code>. The <code>buff/cache</code> column contains information from data that has been read off disk and the metadata associated with it. This is used for fast retrieval if you need to access it again, which is why Linux tries to use all the system memory it can instead of letting it sit idle. A Linux host will swap data out of memory and write it to disk if a system is running low on memory. As you can imagine, using disk as memory is much slower than using actual RAM. If the <code>free</code> column for <code>Swap</code> is ever low, your system may be performing slower than it normally can. In this example, the system is swapping to disk only a little (<code>141Mi</code>), which can be normal. </p>
<p><span epub:type="pagebreak" title="130" id="Page_130"/>The <code>used</code> and <code>free</code> columns can be misleading on a Linux host. Linux likes to use every bit of RAM on a system, so it may appear at a quick glance that a host is low on memory. Or, as in this case, it can appear that there is more memory than actually is available. Here, the <code>free</code> column shows <code>95Mi</code>, but according to the <code>available</code> column, only <code>43Mi</code> is left. When using the <code>free</code> command to display system memory, pay attention to the <code>available</code> column as a barometer of actual memory available to the system and new processes.</p>
<p>Looking at how little memory is available in this example, it’s safe to say this host has a memory shortage. Having roughly <code>43Mi</code> out of 1Gi left on a system can cause stability issues and stop new processes from being created. It can also force the Linux kernel to invoke the out of memory manager (OOM) and select a process to kill, which can and will cause unexpected behavior.</p>
<h3 id="h2-502482c10-0005">vmstat</h3>
<p class="BodyFirst">The <code>vmstat</code> command provides useful information about processes, memory, IO, disks, and CPU activity. It can report this data over a period of time, which is an upgrade over the <code>free</code> command and makes trends much easier to spot. You’ll pass two parameters to the <code>vmstat</code> command: <code>delay</code>, which specifies the time delay between each of the polling counts, and <code>count</code>, which specifies the number of times <code>vmstat</code> will fetch data until it quits. For this example, you will poll the data five times with a one-second delay between each poll. Enter the following command to poll the data:</p>
<pre><code>$ <b>vmstat 1 5</b>
procs ---------memory--------  --swap-- -----io---- -system- ---cpu--------
 r b   swpd   free buff  cache  si   so   bi    bo   in   cs us sy id wa st
 2 0  54392  74068 7260 117804   0   10   84   432   81  158  3  1 96  0  0
 1 0  54392  73864 7260 117852   0    0    8     0  379  104 44  0 56  0  0
 1 2  54392  71768  484  38724 104    0  496   196  469  327 41  1 57  1  0
 1 0  54392  71508  484  39768  20    0 1024     0  357   82 44  0 56  0  0
 1 0  54392  71508  484  39768   4    0    0     0  370   43 46  0 54  0  0</code></pre>
<p>The <code>vmstat</code> report is divided into multiple categories: <code>procs</code>, <code>memory</code>, <code>swap</code>, <code>io</code>, <code>system</code>, and <code>cpu</code>. Each category contains like columns. The first row of data is an average of each statistic since the last boot time. Since you are hunting for high memory usage, you’ll focus only on the <code>memory</code> and <code>swap</code> sections from the <code>vmstat</code> output. </p>
<p>The <code>swpd</code> column of the <code>memory</code> section shows the total swap space used; in this case, it’s around 54Mi (<code>54,392</code>Ki). Next comes the <code>free</code> column. According to <code>vmstat</code>, the free memory has fluctuated between 71,000Ki and 74,000Ki in the polling snapshot. This does not mean you have only 71,000Ki of memory available; it’s an estimate because of the free-able cache and buffers. </p>
<p>Under the <code>swap</code> section are two columns: <code>si</code> (swapped in) and <code>so</code> (swapped out). The <code>si</code> and <code>so</code> columns indicate you are paging memory to and from the disk. At one point, you were swapping memory from the disk at about <code>104</code>KiB per second. As mentioned previously, a little swapping can be okay, but being low on free memory plus swapping usually indicates a memory bottleneck. </p>
<p><span epub:type="pagebreak" title="131" id="Page_131"/>The <code>r</code> and <code>b</code> columns under <code>procs</code> can provide good indications of possible bottlenecks. The <code>r</code> column is the number of running (or waiting-to-run) processes. A high number here can indicate a CPU bottleneck. The <code>b</code> column is the number of processes in an uninterruptable sleep. If the number in the <code>b</code> column is high, it can be a good signal that there are processes waiting on resources like disk or network IO.</p>
<h3 id="h2-502482c10-0006">ps</h3>
<p class="BodyFirst">If memory usage is high on the host, you’ll want to check all the running processes to find where the memory is being used. The <code>ps</code> command provides a snapshot of the current processes on a host. You’ll use some flags to narrow down the results and show only the top-10 hosts sorted by most memory. Enter the following command:</p>
<pre><code>$ <b>ps -efly --sort=-rss | head</b>
S UID   PID PPID  C PRI  NI   RSS    SZ WCHAN STIME TTY TIME CMD
R root  931 930  93  80   0 890652 209077 -   05:56 ?   ...   memory-hog
S root  469   1   0 -40   - 18212 86454 -     Jan16 ?   ...  /sbin/multipathd
S root  672   1   0  80   0 10420 233460 -    Jan16 ?   ...  /usr/lib/snapd
S root  350   1   0  79  -1  7416 12919 -     Jan16 ?   ...  /lib/systemd</code></pre>
<p>The <code>-efly</code> and <code>--sort=-rss</code> flags are used to show all the processes in a long format. The <code>RSS</code> (resident set size) column shows the amount of non-swappable physical memory a process uses (in kilobytes), in descending numerical order. You pipe those results to the <code>head</code> command, which displays only 10 by default. The <code>CMD</code> column shows the command that belongs to each process. In this example, the <code>memory-hog</code> command is using around 890MB (<code>890,652</code>KB) of physical memory, according to the <code>RSS</code> column. Considering that this host has only 1Gi of total memory, that application is hogging all the memory. </p>
<h3 id="h2-502482c10-0007">Next Steps</h3>
<p class="BodyFirst">The steps you’ll take to resolve a high-memory-usage issue like this will depend on risk factors for your system and/or users. If you’re dealing with a production system, you’ll want to tread lightly and check the logs, traces, and metrics to determine when and where the problem started. If this were a new behavior on a production system, rolling back <code>memory-hog</code> to a previous version would be a great first step. (Any time you can recover quickly in production is a win.) Once you have remediated the issue in production, do a performance profile in a different environment and dig through the clues to figure out why and where the memory is being used.</p>
<h2 id="h1-502482c10-0004">Scenario: High iowait</h2>
<p class="BodyFirst">A host that is spending too much time waiting for disk I/O is said to have a condition called <em>high iowait</em>. The way to measure iowait is to check the percentage of time that CPUs are idle because the system has unfinished disk <span epub:type="pagebreak" title="132" id="Page_132"/>I/O requests that are blocking processes from doing other work. Significant iowait usually results in a host having an increased load and possibly higher reported CPU usage than it normally would. To put it another way, if your CPU is waiting for the disk to respond, it has less time to service other requests from other parts of the system. One cause of high iowait might be an aging, slow, or failing disk. Another culprit could be an application that is performing heavy disk reads and writes. If you are in a virtualized environment, slow network-attached storage is most likely where your congestion lies.</p>
<p>All systems will have some iowait, and modern CPUs are faster than storage. High iowait by itself, however, is not enough to signal a problem. Some systems with high iowait can perform without issues, while others will show significant signs of a bottleneck. The goal is to identify issues that are accompanied by high iowait. There’s no bright line with normal iowait on one side and high iowait on the other, so I have set the threshold for high iowait at anything over 30 percent that is sustained over a significant period. </p>
<p>Two command line tools, <code>iostat</code> and <code>iotop</code>, will help you troubleshoot a host with high iowait.</p>
<h3 id="h2-502482c10-0008">iostat</h3>
<p class="BodyFirst">The <code>iostat</code> command line tool reports CPU and I/O stats for devices, so it’s a great tool to help you determine whether your system is experiencing any iowait. If <code>iostat</code> is not installed by default, use your package manager to install the sysstat package. </p>
<p>As I mentioned previously, having some iowait is normal. You are looking for abnormal behavior, so you’ll want to poll the system over a period of time to get a better view of the problem, like you did with the <code>vmstat</code> command. For this example, enter the command below to poll for statistics every second for a total of 20 times. The command and output should look like the following:</p>
<pre><code>$ <b>iostat -xz 1 20</b>
<var>--snip--</var>
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           6.25    0.00   27.08   66.67    0.00    0.00

Device             r/s    rkB/s      w/s      wkB/s    %util ...
vda               0.00     0.00  1179.00  712388.00   100.00 ...</code></pre>
<p>The first report <code>iostat </code>prints is from the last time the host was booted. Since that data is not relevant to your current troubleshooting scenario, I’ve omitted it here, along with multiple columns from the <code>Device</code> output. The <code>-xz</code> flag shows only active devices using an extended stat format. The <code>w/s</code> column shows that the <code>vda</code> device is executing a lot of write requests per second (<code>1179.00</code>). The <code>CPU</code> is waiting on outstanding disk requests around <code>66.67%</code> of the time (<code>%iowait</code>). Finally, as further proof that this disk is quite busy, the <code>%util</code> (percent utilization) column shows <code>100%</code>. </p>
<p>You can conclude that the host is suffering from high iowait that is sustained and not just intermittent. More importantly, you know that the <span epub:type="pagebreak" title="133" id="Page_133"/>iowait is occurring on the device named <code>vda</code>. From here, it is worth trying to find a process that could be the cause of the increased iowait. You can do that with the <code>iotop</code> command, which you’ll explore next.</p>
<h3 id="h2-502482c10-0009">iotop</h3>
<p class="BodyFirst">The <code>iotop</code> command displays I/O usage in a <code>top</code>-like format. Not only does it provide an overview of I/O on the host, but it lets you drill down to the process level to locate any processes that might be causing a lot of disk I/O. Most distributions don’t include <code>iotop</code> by default, so use your package manager to install it. </p>
<p>When running <code>iotop</code>, you’ll want to limit the output to show only active processes that are performing I/O, using a batch mode that polls constantly to keep the output concise and reveal any possible I/O patterns. This command requires elevated permissions, so you’ll need to run it with <code>sudo</code> or as a privileged user. Enter the command below:</p>
<pre><code>$ <b>sudo iotop -oPab</b>
Total DISK READ:        15.04 M/s | Total DISK WRITE:     446.28 M/s
Current DISK READ:      15.04 M/s | Current DISK WRITE:   321.58 M/s
    PID  PRIO  USER   DISK READ  DISK WRITE  SWAPIN    IO  COMMAND
  88576 be/4 bob      512.00 M    616.81 M  0.00 % 83.26%  heavy-io
    469 rt/4 root       0.00 B      0.00 B  0.00 %  0.00%  multipathd -d -s
  <var>--snip--</var></code></pre>
<p>The <code>-oPab</code> flags make <code>iotop</code> show only processes performing I/O with accumulative stats in a batch mode. In this example, the <code>heavy-io</code> command is at <code>83.26%</code>, according to the <code>IO</code> column. The <code>PID</code> column reports the process ID, which in this case is <code>88576</code>. No other processes in your report are using a lot of I/O, so it’s safe to assume that the <code>heavy-io</code> process is part of the reason for the high iowait.</p>
<h3 id="h2-502482c10-0010">Next Steps</h3>
<p class="BodyFirst">After checking the stats and finding the process ID that is causing high iowait, you might want to explore what this application is used for. If you have the source code or configuration files, look for more clues by checking any disk operations or files the process has access to. Another cause for high iowait could be that your VM is in a cloud provider and you do not have enough provisioned I/O operations for your disk. Check the disk metrics to confirm and adjust the number to compensate the load. If all else fails, use tools like <code>lsof</code><code> </code>to examine what files are open, <code>strace</code> to trace any system calls the process is making, or <code>dmesg</code> for any hardware kernel errors. (We’ll discuss <code>lsof</code>, <code>strace</code>, and <code>dmesg</code> later in this chapter.)</p>
<h2 id="h1-502482c10-0005">Scenario: Hostname Resolution Failure</h2>
<p class="BodyFirst">Traditionally, when a service needs to connect to another service, it uses Domain Name System (DNS) to look up the IP address to send it a request. <em/><span epub:type="pagebreak" title="134" id="Page_134"/>DNS is a directory for host IP address mappings. It allows us to use names like google.com or nostarch.com without needing to know those hosts’ exact IP addresses. Humans are far better at remembering names than IP addresses like 142.250.72.78 or 104.20.208.3. Imagine if you had to find a store by trying to remember its latitude and longitude coordinates without using GPS instead of just remembering it’s at 123 Main Street. You would get lost . . . a lot.</p>
<p>For this scenario, say you have an application that is trying to connect to a Postgres database in your local environment. The application starts emitting errors in the logs that look like this: </p>
<pre><code>psql: error: could not translate host name "db.smith.lab" to address: Temporary failure in name resolution </code></pre>
<p>It appears that the application can’t resolve the DNS record for <em>db.smith.lab</em>. There can be multiple reasons for the failure in name resolution. We’ll explore a few tools to help troubleshoot this error. Before that, though, you really need to understand how your host uses DNS.</p>
<h3 id="h2-502482c10-0011">resolv.conf</h3>
<p class="BodyFirst">The first place to start investigating DNS issues on any Linux host is the <em>/etc/resolv.conf</em> file that provides information on what DNS servers to query and any special options needed (like timeout or security). The following is a <em>resolv.conf</em> file from a typical Ubuntu host:</p>
<pre><code># This file is managed by man:systemd-resolved(8). <b>Do not edit.</b>
#
# This is a dynamic resolv.conf file for connecting local clients to the
# internal DNS stub resolver of systemd-resolved. This file lists all
# configured search domains.
#
# Run "resolvectl status" to see details about the uplink DNS servers
# currently in use.
#
# Third party programs must not access this file directly, but only through 
# the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a 
# different way, replace this symlink by a static file or a different 
# symlink.
#
# See man:systemd-resolved.service(8) for details about the supported 
# modes of operation for /etc/resolv.conf.

nameserver 127.0.0.53
options edns0 trust-ad</code></pre>
<p>The file contains several comments describing <code>systemd-resolved</code>, and most importantly, it notes that you shouldn’t edit it. This file is controlled by the <code>systemd-resolved</code> service provided by <em>systemd</em>, and it will overwrite the file next time the host or service restarts. After the comments, the second line from the bottom contains the <code>nameserver</code> keyword and the IP address <span epub:type="pagebreak" title="135" id="Page_135"/>of the DNS server to query. On this Ubuntu host, the <code>nameserver</code> is set to <code>127.0.0.53</code>, which means any DNS requests will be sent to this address. If the local <code>resolver</code> does not know the answer to the query, the <code>resolver</code> will forward the request to an upstream <code>DNS server</code>. </p>
<p>The DNS upstream servers are usually set when you receive an IP address lease from a DHCP server. These upstream DNS servers can be internal servers that handle all your requests, or they can be any of the many public servers that the internet uses. For example, Cloudflare hosts public DNS servers at 1.1.1.1. There are quite a few public DNS servers around the globe. </p>
<p>The last line in the file modifies some specific resolver attributes using the <code>options</code> keyword. In this example, the <code>edns0</code> and <code>trust-ad</code> options are set. The <code>edns0</code> option enables expanded features to the DNS protocol. See RFC 2671 (<a href="https://tools.ietf.org/html/rfc2671/" class="LinkURL">https://tools.ietf.org/html/rfc2671/</a>) for more details. The <code>trust-ad</code>, or authenticated data (AD) bit, option will include the authenticated data on all outbound DNS queries and preserve the authenticated data in the response. This will allow the client and server to validate the exchange between each other. This option is a part of a larger set of extensions that add security to DNS. See <a href="https://www.dnssec.net/" class="LinkURL">https://www.dnssec.net/</a> for more information.</p>
<h3 id="h2-502482c10-0012">resolvectl</h3>
<p class="BodyFirst">In this example host’s <em>resolv.conf</em>, the DNS server is set to <code>127.0.0.53</code>, which is a local resolver that proxies any DNS request it does not know about. Each DNS server typically will have an upstream server that it forwards unknown requests to. Since you are using <code>systemd-resolver</code>, you can use a tool called <code>resolvectl</code> to interact with your local resolver. If this command line application is missing, you can install it via your package manager.</p>
<p>You’ll want to know where your local DNS resolver (<code>127.0.0.53</code>) sends unknown requests. This might help you figure out why <em>db.smith.lab</em> resolution is failing. To see what DNS servers the resolver points to upstream, enter the following command:</p>
<pre><code>$ <b>resolvectl dns</b>
Global:
<var>--snip--</var>
Link 2 (enp0s3): 10.0.2.3</code></pre>
<p>The results show the downstream DNS server is set to <code>10.0.2.3</code> for interface <code>enp0s3</code>, which is the default interface and route on this host. Your setup and interface might be different. When any application on this host tries to connect to <em>db.smith.lab</em>, it first sends a DNS request to <code>127.0.0.53</code>, asking what IP address the hostname resolves to. The local resolver first looks for the answer locally. If the mapping is there, the results are returned immediately. However, if the answer is unknown, the resolver forwards the request to the upstream DNS server at IP <code>10.0.2.3</code>. Now, if the DNS server at <code>10.0.2.3</code> knows the answer for <em>db.smith.lab</em>, it will return a response to the local resolver, which in turn will respond to the user. If it doesn’t know the <span epub:type="pagebreak" title="136" id="Page_136"/>answer, the upstream server will forward that request to its upstream server until it reaches the authoritative server for the domain it’s looking for.</p>
<p>Now that you know the IP address of your local resolver and upstream DNS server, you can query both to look for clues.</p>
<h3 id="h2-502482c10-0013">dig</h3>
<p class="BodyFirst">The <code>dig</code> command line tool queries DNS servers and displays the results. This is extremely handy when you are troubleshooting DNS issues or need to fetch an IP address for a host. All you need to do is pass <code>dig</code> the hostname, and the response will provide information about the query and server that is responding.</p>
<p>Try querying the local resolver for the IP address of <em>db.smith.lab</em>. Enter the following command:</p>
<pre><code>$ <b>dig db.smith.lab</b>
;  DiG 9.16.1-Ubuntu  db.smith.lab
;; global options: +cmd
;; Got answer:
;; -HEADER- opcode: QUERY, status: <span class="CodeAnnotation" aria-label="annotation1">1</span>SERVFAIL, id: 35816
;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 65494
;; <b>QUESTION SECTION</b>:
;db.smith.lab.	              IN      <span class="CodeAnnotation" aria-label="annotation2">2</span>A

;; Query time: 32 msec
;; <b>SERVER</b>: <span class="CodeAnnotation" aria-label="annotation3">3</span>127.0.0.53#53(127.0.0.53)
<var>--snip--</var></code></pre>
<p>The <code>status</code> field <span class="CodeAnnotation" aria-label="annotation1">1</span> lets us know whether the query was successful. A successful query would have a status of <code>NOERROR</code>. In this example, the status is set to <code>SERVFAIL</code>, showing that no answer could be given. This makes sense, as the local DNS does not know where to find <em>db.smith.lab</em>. The <code>QUESTION SECTION</code> displays the query that was sent to the DNS server. In this case, the query is for the A record for <em>db.smith.lab</em> <span class="CodeAnnotation" aria-label="annotation2">2</span>. (An <em>A record</em> is a type of DNS record that maps a domain to an IP address.) The <code>SERVER</code> section tells us which DNS server was contacted to make the query. In this example, it’s the local resolver (<code>127.0.0.53</code>) <span class="CodeAnnotation" aria-label="annotation3">3</span>, as expected.</p>
<p>To test your upstream server, you can instruct <code>dig</code> to talk to a specific DNS server instead of the local one. This will let you verify whether DNS resolution is failing locally or upstream. To do this, enter the following command:</p>
<pre><code>$ <b>dig @10.0.2.3 db.smith.lab</b>
...
;; -HEADER- opcode: QUERY, status: SERVFAIL, id: 57409
...
;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
<span epub:type="pagebreak" title="137" id="Page_137"/>;; QUESTION SECTION:
;db.smith.lab.			IN	A
...
;; Query time: 32 msec
;; SERVER: 10.0.2.3#53(10.0.2.3)
;; WHEN: Sat Jun 19 18:20:23 UTC 2022
;; MSG SIZE  rcvd: 116</code></pre>
<p>The <code>@10.0.2.3</code> parameter makes <code>dig</code> skip the local DNS and query the upstream host directly. The results, however, are the same, and you received a <code>SERVFAIL</code> for the status. This means the upstream server couldn’t provide an answer for the hostname. You know you queried the correct server, because the <code>SERVER</code> section now states <code>10.0.2.3</code> instead of <code>127.0.0.53</code>.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Pass <code>dig</code> the <code>+short</code> flag to show only the IP address, if it exists.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p>To be safe, you should try one more query to make sure the local and upstream DNS servers are working correctly. First, you’ll query for a DNS record that you are positive will return a response. This will let you verify whether DNS is broken for any domains, not just <em>db.smith.lab</em>. Enter the following command to query the A record for google.com:</p>
<pre><code>$ <b>dig google.com</b>
...
;; -HEADER- opcode: QUERY, status: NOERROR, id: 15154
...
;; QUESTION SECTION:
;google.com.			IN	A

;; ANSWER SECTION:
google.com.		300	IN	A	142.250.72.78

;; Query time: 36 msec
;; SERVER: 127.0.0.53#53(127.0.0.53)
...</code></pre>
<p>The status is <code>NOERROR</code>, and you received the A record of <code>142.250.72.78</code> in the <code>ANSWER SECTION</code>. This means the DNS server can resolve another hostname without error, but for some reason, it doesn’t know about the <em>db.smith.lab</em> A record. Note that when there is an error or no answer to be given, the <code>ANSWER SECTION</code> is omitted from the results.</p>
<h2 id="h1-502482c10-0006">Next Steps</h2>
<p class="BodyFirst">If there are resolution issues with a given hostname and DNS is functioning correctly and can resolve other hostnames, then the issues might stem from a DNS resolver that is missing the information that maps the hostname to an IP address. If your DNS is hosted on a service like Amazon Route53, make sure the record has not been removed by configuration management software or due to human error. If you manage the DNS server locally, you <span epub:type="pagebreak" title="138" id="Page_138"/>can look to see if the A record is present. If it is not, perhaps the configuration contains some syntax error preventing the record from being served, or perhaps the DNS server needs to be restarted to read in its new records. </p>
<h2 id="h1-502482c10-0007">Scenario: Out of Disk Space</h2>
<p class="BodyFirst">You will run out of disk space eventually. When this happens, you need to find out what is using all the space. The culprit could be anything from a misbehaving application to uncapped logfiles to a buildup of Docker images. To find the source of the problem, you’ll first need to figure out which drive and filesystem are low on space. Once you locate those pieces, you will be able to search for files on the disk that may be using a lot of space. </p>
<h3 id="h2-502482c10-0014">df</h3>
<p class="BodyFirst">The <code>df</code> command displays the free disk space on all the mounted filesystems on a host. It has multiple options, but the <code>-h</code> flag (for human-readable) is probably all you’ll need. To see the free space on the mounted filesystems, enter the following command in a terminal:</p>
<pre><code>$ <b>df -h</b>
Filesystem     Size  Used Avail Use% Mounted on
/dev/vda1       25G   25G     0 100% /
<var>--snip--</var></code></pre>
<p>In this example, device <em>/dev/vda1</em> is using <code>100%</code> of its <code>25G</code> of disk space. The filesystem is mounted at <em>/</em>, which is the root directory. If your host has multiple mounted disks, they’ll be visible in the output as well. </p>
<h3 id="h2-502482c10-0015">find</h3>
<p class="BodyFirst">The <code>find</code> command searches the filesystem for directories and files, and you can filter it to narrow down the search by looking for files that match only certain criteria or a specific directory. You can also locate files by their sizes on disk. </p>
<p>In your example, since you know the <em>root</em> filesystem is out of space after running the <code>df</code> command, you should direct <code>find</code> to search there. You’ll execute the <code>find</code> command and search the <em>root</em> filesystem, looking for any files over <code>100M</code>. You’ll sort them by size and display the top 10 with the <code>head</code> command. This could take a while, depending on the number of files on your drive. Enter the following command:</p>
<pre><code>$ <b>sudo find / -type f -size +100M -exec du -ah {} + | sort -hr | head</b>
<var>--snip--</var>
10G   /var/log/php7.2-fpm.log
5G    /var/lib/docker/containers/.../...a3b76-json.log 
<var>--snip--</var></code></pre>
<p><span epub:type="pagebreak" title="139" id="Page_139"/>For each file located that is more than 100M, you’ll execute (<code>-exec</code> flag) the <code>du -ah</code> command to fetch the file size on disk in human-readable format. The results, with file size, are sorted with largest files first. Then, the first 10 results are displayed.</p>
<p>This output shows a file named <em>php7.2-fpm.log</em> that is located under <em>/var/log</em> and is <code>10G</code> in size. Also, a Docker container log located in <em>/var/lib/docker/containers</em> is using <code>5G</code> of space. Together, these files are taking up 15GB of space on your disk. Usually, application logs like these should rotate and not become so large. The fact that both files are so big should trip your Spidey sense that something is not right here.</p>
<p>With more breadcrumbs to follow, check to see what process, if any, is using the <em>php7.2-fpm.log</em> file before you form a hypothesis. </p>
<h3 id="h2-502482c10-0016">lsof</h3>
<p class="BodyFirst">Use the <code>lsof </code>command to list open files on a host. Files on a Linux host can be regular files, directories, or sockets, to name just a few. You can search for files owned by a particular process or by a specific user. </p>
<p>You’ll use <code>lsof</code>, which requires elevated privileges, to find the process writing to the <em>/var/log/php7.2-fpm.log</em> file. Enter the following command:</p>
<pre><code>$ <b>sudo lsof /var/log/php7.2-fpm.log</b>
  COMMAND   PID  USER  FD  TYPE DEVICE    SIZE/OFF  NODE  NAME
php-fpm7. 23496  root  2w   REG  252,1  1048580000  1529  /var/log/php7.2-fpm.log
<var>--snip--</var></code></pre>
<p>You must pass the full path to the file you are interested in. In this case, it’s the logfile. The <code>php-fpm7</code> command with the <code>PID 23496</code> owns the logfile in question. The file descriptor is <code>2w</code>, which means the file’s descriptor is <code>2</code> and the file is opened for write access (<code>w</code>). The <code>TYPE</code> of file is <code>REG</code> (regular), representing a typical ASCII text file.</p>
<h3 id="h2-502482c10-0017">Next Steps</h3>
<p class="BodyFirst">When your free disk space is low and you have tracked down a file that is contributing to the lack of space, you have a couple of options to remedy the situation. Since this logfile is currently being used, truncating or deleting it out from under the <code>php-fpm7</code> process isn’t wise. Doing so could cause the process to die or stop writing logs completely. Instead, you can start by looking at the log output to see whether there are any telling errors or the application log level is perhaps stuck on <code>debug</code>. Also, there might be some correlation between this logfile and the fact that a Docker container log is large. Perhaps this process is running inside that container. Check the contents of the container log as well for any visible errors. On a housecleaning note, you should always make sure the host is set up to use the <code>logrotate</code> command to compress and rotate logfiles on a schedule. This can keep your logfiles from growing unbound and eating up your disk space. The <code>logrotate</code> configuration files are located in the <em>/etc/logrotate.d</em><em>/</em> directory on Ubuntu systems.</p>
<h2 id="h1-502482c10-0008"><span epub:type="pagebreak" title="140" id="Page_140"/>Scenario: Connection Refused</h2>
<p class="BodyFirst">Sometimes, services refuse connections and do not leave an obvious reason why. For example, say you have an internal API that is reporting a high error rate, and say other services that use this API are throwing a lot of errors as well. The errors in the application logs would look something like this:</p>
<pre><code>Failed to connect to api.smith.lab port 8080: Connection refused</code></pre>
<p>It appears users are receiving a <code>Connection refused</code> error when trying to connect to the API server. You know the Docker container is up and running, or you would have gotten an alert that it was down. To troubleshoot this, you’ll use a few commands that will help you identify any network- or configuration-related issues. </p>
<h3 id="h2-502482c10-0018">curl</h3>
<p class="BodyFirst">Anytime you need to check whether a web server is responding to requests or just want to fetch some data or a file, turn to the <code>curl</code> command. For this example, you’ll want to verify that an endpoint is down for everyone and that there is not just a routing issue on other hosts. The API server should respond with an <code>HTTP 200</code> status if it is functioning properly. To double-check that the API server is refusing connections, you could use <code>curl</code> by entering the following command:</p>
<pre><code>$ <b>curl http://api.smith.lab:8080</b>
curl: (7) Failed to connect to api.smith.lab port 8080: Connection refused</code></pre>
<p>The output shows you are getting a <code>Connection refused</code> error as well. This usually means the host is not listening on your port or a firewall is rejecting packets. Regardless of the reason, something is breaking your API requests.  </p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">note</span></h2>
<p>	Another common connection error you will encounter is <code>connection timeout</code>. This error occurs when there is nothing responding to the request or a firewall is silently dropping the packets.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2-502482c10-0019">ss</h3>
<p class="BodyFirst">The <code>ss</code> (socket statistics) command is used to dump socket information on a host. For your troubleshooting scenario, you’ll use it to see whether any application on the host is bound (or listening) to requests on <code>port 8080</code>. Enter the following command:</p>
<pre><code>$ <b>sudo ss -l -n -p | grep 8080</b>
...<code> </code>0.0.0.0:8080 0.0.0.0:* users:(("docker-proxy",pid=1448197,fd=4))
<var>--snip--  </var></code></pre>
<p>The <code>-l</code> flag shows all the listening sockets on the host. The <code>-n</code> flag instructs <code>ss</code> not to resolve any service names like HTTP or SSH, and the <code>-p</code> flag shows the process that’s using the socket. For <code>ss</code> to determine which <span epub:type="pagebreak" title="141" id="Page_141"/>process owns the socket, <code>sudo</code> or elevated permissions are required. I truncated the beginning of the output line for readability, but the important part shows that the <code>docker-proxy</code> process is listening on all interfaces for port 8080 (<code>0.0.0.0:8080</code>). Next, you can verify that the requests destined for <em>api.smith.lab</em> are making it all the way to the host, where it lives.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Before <code>ss</code>, there was a tool called <code>netstat</code>. The two tools basically do the same thing, but <code>netstat</code> is considered obsolete by today’s standards. Most likely, you will still see tutorials and blog posts that still use <code>netstat</code>. Nevertheless, you should use <code>ss</code><em> </em>going forward.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2-502482c10-0020">tcpdump</h3>
<p class="BodyFirst">One way to verify network traffic on a host is with the <code>tcpdump</code> command, which has many options and can capture traffic on one or all interfaces. It can even write out the network capture into a file for later analysis. Not only is <code>tcpdump</code> great for troubleshooting network issues, but you can use it for security auditing as well. For your example, you’ll use it to capture network traffic intended for the <em>api.smith.lab</em> host on port 8080. This will let you know whether traffic being sent to that host is reaching its target, and it will hopefully shed some light on why you are getting the <code>Connection refused</code> error message. </p>
<p>On the host where the API application is running, enter the following command in a terminal. This will start the network packet capture on all interfaces for any TCP packet headed for port 8080 (note that elevated privileges are needed to listen on a network interface):</p>
<pre><code>$ <b>sudo tcpdump -ni any tcp port 8080</b>
IP 192.168.50.26.50563 &gt; 192.168.50.4.8080: Flags [<b>S</b>], seq 3446688967, win 65535, options [mss 1460,nop,wscale 6,nop,nop,TS val 157893401 ecr 0,sackOK,eol], length 0
IP 192.168.50.4.8080 &gt; 192.168.50.26.50563: Flags [<b>R.</b>], seq 0, ack 3446688968, win 0, length 0
IP 192.168.50.26.50563 &gt; 192.168.50.4.8080: Flags [<b>S</b>], seq 3446688967, win 65535, options [mss 1460,nop,wscale 6,nop,nop,TS val 157893501 ecr 0,sackOK,eol], length 0
IP 192.168.50.4.8080 &gt; 192.168.50.26.50563: Flags [<b>R.</b>], seq 0, ack 1, win 0, length 0</code></pre>
<p>The <code>-n</code> flag makes sure you do not try to resolve any host or port names. The <code>-i</code> flag tells <code>tcpdump</code> the network interface on which to listen. In this case, the term <code>any</code> is specified and means “Listen on all interfaces.” You want to capture all packets destined for port 8080 since there might be numerous network interfaces on this host. The final <code>tcp port 8080</code> parameter states that you want only TCP packets that have port 8080 in them. These will include packets from both the client and the server. </p>
<p>Let’s focus on the parts of the output that help with the <code>Connection refused</code> error problem. On the first line, the <code>IP</code> section shows that something from source <code>IP</code> <code>192.168.50.26</code> is trying to connect to <code>192.168.50.4</code> on port <code>8080</code>. The <code>&gt;</code> (greater-than) sign tells us the direction of the communication from one IP to another. The <code>Flags</code> being set show the types of network packets being sent. The first packet has an <code>S</code> (synchronize) flag. Anytime a client wants to establish a connection to another host, it sends the synchronize packet. In the next packet, host <code>192.168.50.4</code> responds to <code>192.168.50.26</code> with <span epub:type="pagebreak" title="142" id="Page_142"/>a reset (<code>R</code>) packet. A reset packet is usually sent when there is an unrecoverable error and the server wants the client to terminate the connection immediately. Undeterred by the “Get off my lawn!” reset packet, the client tries again with another synchronize packet, which in turn causes server <code>192.168.50.4</code> to send another reset packet back to <code>192.168.50.26</code>. The client at <code>192.168.50.26</code> finally takes a hint, and the connection is closed.</p>
<p>The flags show this connection isn’t normal. A normal TCP connection starts off with a <code>SYN</code> packet from the client, followed by a <code>SYN-ACK</code> packet from the server. Once that packet is received, the client sends back an <code>ACK</code> packet to the server, acknowledging the last packet. This is referred to as a <em>three-way handshake</em>. See <a href="#figure10-2" id="figureanchor10-2">Figure 10-2</a> for details. </p>

<figure>
<img src="image_fi/502482c10/f10002.png" class="" alt="Diagram showing one client server on the left with the IP 192.168.50.26 passing packets back and forth with the server at 192.168.50.4 on the right"/>
<figcaption><p><a id="figure10-2">Figure 10-2</a>: TCP three-way handshake</p></figcaption>
</figure>


<p>You clearly do not see any other packets (except resets) being sent from the server. The reset packets will cause the connecting clients to report that the connection is being refused. The good news is you verified that connections are making it all the way to server. The bad news is you still do not know why you are being refused.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	Visit <a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol" class="LinkURL">https://en.wikipedia.org/wiki/Transmission_Control_Protocol</a> for more information.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h3 id="h2-502482c10-0021">Next Steps</h3>
<p class="BodyFirst">At this point, you know the service is listening on port 8080. You verified this with the <code>ss</code> command. You also know traffic is making it all the way to the server, according to your network capture with <code>tcpdump</code>. </p>
<p>The next places to look are the Docker container and the application configuration. It is possible <code>docker-proxy</code> is having issues and not forwarding the traffic to the container running the API. Another possibility is that the container was started with incorrect internal port mappings. You know the external port, 8080, is mapped correctly, since it is listening for connections. But it’s possible the mapped internal port is misconfigured. You can check both of these scenarios by looking at Docker’s system logs for proxy errors, or by running <code class="bold">docker ps </code><var class="bold">&lt;container id&gt;</var> or <code class="bold">docker inspect </code><var class="bold">&lt;container_id&gt;</var> to check the port mappings.</p>
<h2 id="h1-502482c10-0009">Searching Logs</h2>
<p class="BodyFirst">In almost every troubleshooting scenario, you’ll most likely need to check logs. System and application logs hold a wealth of information you can view from the command line. Modern Linux distributions use <code>systemd</code>, which <span epub:type="pagebreak" title="143" id="Page_143"/>has a log-collection mechanism called the <em>journal</em> that pulls in log events from multiple sources like <em>syslog</em>, <em>auth.log</em>, and <em>kern.log</em>. This lets you view and search logs in a single stream. As a troubleshooting archaeologist, you should know where logs are located and how to view and parse them.</p>
<h3 id="h2-502482c10-0022">Common Logs</h3>
<p class="BodyFirst">Most system and application logs on a Linux host are stored in the <em>/var/log</em> directory. The most common logs on a host that will aid in troubleshooting are <em>syslog</em>, <em>auth.log</em>, <em>kern.log</em>, and <em>dmesg</em>. Depending on your Linux distribution, the names of the logfiles may be different.</p>
<h4 id="h3-502482c10-0001">/var/log/syslog</h4>
<p class="BodyFirst">The <em>syslog </em>file contains general global system messages for the Linux OS. Here is an example of a log line for <code>systemd</code>, stating that the logs are finished rotating:</p>
<pre><code>Jun 11 00:00:03 box systemd[1]: Finished Rotate log files.</code></pre>
<p>The line begins with a timestamp, followed by the host it is on (<code>box</code>) and the process (<code>systemd[1]</code>) that is reporting the log event. The last part of the line is the text message. This structured line format, also called <em>syslog</em>, is the default protocol for logging on a Linux host.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	The two most widely used versions of the <em>syslog</em> protocol are 3164 (<a href="https://tools.ietf.org/html/rfc3164/" class="LinkURL">https://tools.ietf.org/html/rfc3164/</a>) and 5424 (<a href="https://tools.ietf.org/html/rfc5424/" class="LinkURL">https://tools.ietf.org/html/rfc5424/</a>). Although some systems still use 3164’s format, the 5424 format is the official standard of the <em>syslog</em> protocol.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h4 id="h3-502482c10-0002">/var/log/auth.log</h4>
<p class="BodyFirst">The <em>auth.log</em> file contains information regarding authorization and authentication events. This makes it a great place to investigate user logins and brute-force attacks, or to track a user’s <code>sudo</code> commands. Here is an example of an <em>auth.log</em> message:</p>
<pre><code>Jan 15 20:57:35 box sshd[27162]: Invalid user aiden from 192.168.1.133 port 59876</code></pre>
<p>This message shows a failed login attempt over SSH for the user <em>aiden</em>, from the IP address <code>192.168.1.133</code>. </p>
<h4 id="h3-502482c10-0003">/var/log/kern.log</h4>
<p class="BodyFirst">The <em>kern.log</em> is a good place to look for Linux kernel messages, such as hardware issues or general information related to the Linux kernel. The following log line shows the Linux out of memory manager (OOM) in action:</p>
<pre><code>Jan 16 19:18:47 box kernel: [2397.472979] Out of memory: Killed process 20371 (nginx) total-vm:571408kB, anon-rss:524540kB, file-rss:456kB, shmem-rss:8kB, UID:0 pgtables:1100kB oom_score_adj:1000</code></pre>
<p><span epub:type="pagebreak" title="144" id="Page_144"/>Process <code>20371</code> was killed by the <code>Out of memory</code> manager because the system was running low on memory.</p>
<h4 id="h3-502482c10-0004">/var/log/dmesg</h4>
<p class="BodyFirst">The <em>dmesg</em> log contains bootup messages from the host since last boot time. These messages can be anything from a USB device being recognized to a possible SYN packet flood attack. This sample log line from <em>dmesg</em> shows a <code>Network driver</code> being loaded into the kernel:</p>
<pre><code>[1.036655] kernel: e1000: Intel(R) PRO/1000 Network Driver - version 7.3.21-k8-NAPI</code></pre>
<p>The <em>dmesg</em> log has its own command line application, <code>dmesg</code>, to view the kernel ring buffer in real time. The <code>dmesg</code> command prints information, just like the <em>dmesg</em> log, but it can show information after bootup as well. You can also use it to troubleshoot multiple scenarios, such as port exhaustion, hardware failures, and OOM.</p>
<h3 id="h2-502482c10-0023">Common journalctl Commands</h3>
<p class="BodyFirst">On a host that is using <code>systemd</code>, all of these common logs are stored in a single binary stream called a journal, which is orchestrated by the <code>journald</code> daemon. You can access the journal with the <code>journalctl</code> command line application. The journal is a handy troubleshooting tool because you can use it to view and search multiple logs at the same time. The <code>journalctl</code> command mimics many other logging commands you’ve discussed in this book, such as <code>tail</code>, minikube <code>minikube kubectl -- logs</code> and <code>docker logs</code>.</p>
<p>Say you want to review the logs, with the newest lines first. Enter the <code class="bold">sudo </code>command and pass the <code class="bold">-r</code> flag (reverse) to <code class="bold">journalctl</code> to view all logs in that order:</p>
<pre><code>$ <b>sudo journalctl -r</b>
-- Logs begin at Sat 2022-02-27 23:10:19 UTC, end at Sun 2022-02-28 18:18:29 UTC. --
Feb 28 18:18:29 box sudo[73978]: pam_unix(sudo:session): session opened for user root by vagrant(uid=0)
Feb 28 18:18:10 box systemd[7265]: Startup finished in 66ms.
<var>--snip--</var></code></pre>
<p class="BodyContinued">This output shows log lines for all services, with newest lines first.</p>
<p>Next, view logs during a certain time frame with the <code>--since</code> flag. Enter the following command:</p>
<pre><code>$ <b>sudo journalctl -r --since "2 hours ago"</b>
-- Logs begin at Sat 2022-02-27 23:10:19 UTC, end at Sun 2022-02-28 18:27:20 UTC. --
Feb 28 18:27:20 box sudo[74471]: pam_unix(sudo:session): session opened for user root by vagrant(uid=0)
Feb 28 18:27:20 box sudo[74471]:  vagrant : TTY=pts/2 ; PWD=/home/vagrant ; USER=root ; COMMAND=/usr/bin/journalctl -r --since 2 hours ago
<var>--snip--</var></code></pre>
<p class="BodyContinued"><span epub:type="pagebreak" title="145" id="Page_145"/>This output shows the logs that have a timestamp starting <code>2 hours ago</code> up till the current time, when the command is run. With the <code>-r</code> flag, the newest logs are displayed first.</p>
<p>You can filter logs based on a <code>systemd</code> service name. For example, to view all the logs that were written by the SSH service, enter the following command to pass the <code>-u</code> (unit) flag to <code>journalctl</code>:</p>
<pre><code>$ <b>sudo journalctl -r -u ssh</b>
<var>--snip--</var>
Feb 27 23:17:31 ... sshd[16481]: pam_unix(sshd:session): session opened for user akira by (uid=0)
Feb 27 23:17:31 ... sshd[16481]: Accepted publickey for akira from 10.0.2.2 port 55468 ...
<var>--snip--</var></code></pre>
<p class="BodyContinued">The output shows log lines for SSH pertaining to a login <code>session</code>, in reverse order.</p>
<p>You can also display log lines that match a specific log level, like info or error. Choose the priority level (<code>-p</code>) by using keywords like <code>info</code>, <code>err</code>, <code>debug</code>, or <code>crit</code>. The following is the same command as above but with the <code>-p err</code> flag to show only error logs from the SSH daemon:</p>
<pre><code>$ <b>sudo journalctl -r -u ssh -p err</b>
<var>--snip--</var>
Feb 28 08:39:13 box sshd[4182]: error: maximum authentication attempts exceeded for root from 192.168.25.4 port 34622 ssh2 [preauth]<code> </code>
<var>--snip--</var></code></pre>
<p>The output shows an <code>error</code> log line where the <em>root</em> user reached the maximum failed login attempts.</p>
<p>Narrowing down logs to a specific time frame or showing log lines that match a given log level is great, but what if you want to find a specific message in the journal stream? The pattern-matching flag (<code>-g</code>) in <code>journalctl</code> can match any message using a regular expression. The following example searches the SSH logs for the <code>session opened</code> message. Enter the following command:</p>
<pre><code>$ <b>sudo journalctl -r -u ssh -g "session opened"</b>
<var>--snip--</var>
Jun 10 21:31:40 box sshd[2047134]: pam_unix(sshd:session): session opened for user vagrant by (uid=0)
Jun 09 16:49:10 box sshd[2008012]: pam_unix(sshd:session): session opened for user x7b7 by (uid=0)
<var>--snip--</var></code></pre>
<p>Here, SSH sessions for two different users (<em>vagrant</em> and <em>x7b7</em>) are filtered out.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Warning</span></h2>
<p>	If you are using an older version of <code>journald</code>, the <code>grep</code> pattern matching might not be included. If this is the case, you can pipe the search results to the <code>grep</code> command by entering this command: <code class="bold">sudo journalctl -r -u ssh | grep "session opened"</code>.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<p><span epub:type="pagebreak" title="146" id="Page_146"/>The <code>journalctl</code> tool is helpful when you want to view many logs at once, but you’ll also encounter logs that are not captured in the journal system.</p>
<h3 id="h2-502482c10-0024">Parsing Logs</h3>
<p class="BodyFirst">Parsing logs is a key troubleshooting skill. In addition to <code>journalctl</code>, you can parse and traverse logs with the <code>grep</code> and <code>awk</code> commands. The <code>grep</code> command is used to search for patterns in text or a file. The <code>awk</code> command is a scripting language tool that can filter text, but it also has more advanced features like built-in functions for math and time. </p>
<h4 id="h3-502482c10-0005">grep</h4>
<p class="BodyFirst">The <code>grep</code> command allows you to search for a pattern quickly. For example, to use <code>grep</code> to find any occurrences of the IP address 10.0.2.33 in <em>/var/log/syslog</em>, pass <code>grep</code> the search pattern and the file to search by entering this command:</p>
<pre><code>$ <b>grep "10.0.2.33" /var/log/syslog</b>
... box postfix/smtpd[6520]: connect from unknown[10.0.2.33]
... box postfix/smtpd[6520]: disconnect from unknown[10.0.2.33] ehlo=1 auth=0/1 quit=1 commands=2/3</code></pre>
<p class="BodyContinued">This command returned two log lines for the postfix daemon containing the <code>10.0.2.33</code> IP address. </p>
<p>To find users trying to execute the <code>sudo</code> command who don’t have permission, search <em>/var/log/auth.log</em> using <code>grep</code> by entering the following command:</p>
<pre><code>$ <b>grep "user NOT in sudoers" /var/log/auth.log</b>
Jan 31 17:37:40 box sudo: akira : user NOT in sudoers ; TTY=pts/0 ; PWD=/home/akira ; USER=root ; COMMAND=/usr/bin/cat /etc/passwd</code></pre>
<p class="BodyContinued">The search pattern <code>"user NOT in sudoers</code><code>"</code> indicates an unauthorized <code>sudo</code> attempt violation. This search returns one match showing that the user <em>akira</em> tried to read the contents of the <em>/etc/passwd</em> file but was denied. </p>
<p>Taking it one step further, it would be helpful to check the <em>auth.log</em> to see what else this user was doing around the same time. To get extra log lines with <code>grep</code>, use the <code>-A</code> flag to grab a given number of lines after the matched lines or use the <code>-B</code> flag to fetch a given number of lines before the matched results. You can also use the <code>-C</code> flag to fetch before and after the match, simultaneously.</p>
<p>Now, you should grab the five log lines before the log line alerting to the <code>sudo</code> violation for the user <em>akira</em>. This will help you get an idea of what else might have been going on around that time in the log. Enter the following command:</p>
<pre><code>$ <b>grep -B 5 "user NOT in sudoers" /var/log/auth.log</b>
Jan 31 17:37:35 box sshd[64646]: pam_unix(sshd:session): session opened for user akira by (uid=0) <span class="CodeAnnotationCode" aria-label="annotation1">1</span>
Jan 31 17:37:35 box systemd-logind[632]: New session 169 of user akira.
<span epub:type="pagebreak" title="147" id="Page_147"/>Jan 31 17:37:35 box systemd: pam_unix(systemd-user:session): session opened for user akira by (uid=0)
Jan 31 17:37:38 box sudo: pam_unix(sudo:auth): Couldn't open /etc/securetty: No such file or directory
Jan 31 17:37:40 box sudo: pam_unix(sudo:auth): Couldn't open /etc/securetty: No such file or directory
Jan 31 17:37:40 box sudo: akira : user NOT in sudoers ; TTY=pts/0 ; PWD=/home/akira ; USER=root ; COMMAND=/usr/bin/cat /etc/passwd <span class="CodeAnnotationCode" aria-label="annotation2">2</span></code></pre>
<p>The first five lines show the user <em>akira</em> logging in over SSH <span class="CodeAnnotation" aria-label="annotation1">1</span>. Within five seconds of logging in (<code>17:37:35</code> to <code>17:37:40</code>), the user <em>akira </em>tried to read the contents of the <em>/etc/passwd</em> file <span class="CodeAnnotation" aria-label="annotation2">2</span>. Without the extra context, it might be tempting to overlook this action, but after seeing the user’s behavior upon logging in, grabbing additional lines around a match can provide more insight.</p>
<h4 id="h3-502482c10-0006">awk</h4>
<p class="BodyFirst">The <code>awk</code> command can search for specific patterns like <code>grep</code> does, but it can also filter out information from any column. For this example, you should grab all the source IP addresses from the requests in <em>/var/log/nginx/access.log</em>. This log contains all the requests to a website proxied by Nginx. The source IP address is usually the first column in the log line, unless you have modified Nginx’s default logging format. You’ll use <code>awk</code>’s <code>print</code> function and pass the <code>$1</code> argument so it prints only the first column. By default, <code>awk</code> splits columns on whitespace. Enter the following command:</p>
<pre><code>$ <b>sudo awk '{print $1}' /var/log/nginx/access.log</b>
127.0.0.1
192.168.1.44</code></pre>
<p>The output shows only two IP addresses. Clearly, it’s not a busy web server, but the output doesn’t show the whole log line as do the previous <code>grep</code> examples. You can parse the text and display the column of your choosing with the <code>awk</code> command. Each column in the log line is given a unique column number. For example, to see only the date timestamps (fourth column) in the <em>access.log</em>, pass <code>$4</code> to the <code>print</code> function. If you want to return more than the one column, pass multiple column numbers to the <code>print</code> function, separating each from the next with a comma, like this: <code class="bold">'{print $1,$4}'</code>.</p>
<p>You’ll use <code>awk</code> to search for all the HTTP 500 response code, which is usually in the ninth column (<code>$9</code>) in the Nginx <em>access.log</em> file. Enter the following command:</p>
<pre><code>$ <b>sudo awk '($9 ~ /500/)' /var/log/nginx/access.log</b>
10.0.2.15 - - [15/Feb/2022:19:41:46 +0000] "GET / HTTP/1.1" 500 396 "-" "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36"</code></pre>
<p>Inside the parentheses, the tilde (<code>~</code>) is a field number that tells <code>awk</code> to apply the search pattern only to a specific column. In this case, you want to search in the ninth column for anything matching 500. The command returned a single result for a <code>GET</code> request that responded with an HTTP <code>500</code>. </p>
<p><span epub:type="pagebreak" title="148" id="Page_148"/>You can change the search pattern to suit your needs. For instance, if you want to search the logs for any unauthorized HTTP requests, change the pattern of <code>/500/</code> to <code>/401/</code>. To expand on this even further, you can change the search pattern from <code>/500/</code> to <code>/404/</code> and add a requirement that any 404 responses must be from an HTTP POST method. You do this by adding an <code>if</code> conditional block to <code>awk</code>. To search for any lines that match those criteria, enter the following in a terminal:</p>
<pre><code>$ <b>sudo awk '($9 ~ /404/) {if (/POST/) print}' /var/log/nginx/access.log</b>
127.0.0.1 - - [31/Jan/2022:18:16:45 +0000] "POST /login HTTP/1.1" 404 162 "-" "curl/7.68.0"</code></pre>
<p>The search pattern is like the previous one. Match the value at column <code>$9</code> to the number <code>404</code>. Then pass an <code>if</code> block that states, “If the line from the column <code>$9</code> match contains the word <code>POST</code> anywhere in it, print that whole log line.” The result shows an HTTP <code>POST</code> to the <em>/login</em> path that returned an HTTP <code>404</code>.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<h2><span class="NoteHead">Note</span></h2>
<p>	You can also use OR <em>(|)</em> logic in your search pattern. For example, to search for a HTTP <code>401</code> or <code>403</code> error code, you could do something like this: <code>sudo awk '($9 ~ /401|403/) /var/log/nginx/access.log</code><em>.</em> Notice how the pipe operator splits the values<em>.</em></p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1-502482c10-0010">Probing Processes</h2>
<p class="BodyFirst">Sometimes, you won’t encounter many symptoms when investigating issues on a host. The health stats may look okay, the logs may show nothing interesting . . . but something will still not be right. Maybe a scheduled job didn’t execute cleanly, or an application appears to be hung. One way to dig deeper is to investigate the running process on the host. </p>
<h3 id="h2-502482c10-0025">strace</h3>
<p class="BodyFirst">The <code>strace</code> command traces system calls and signals, allowing you to attach to a process and gain valuable knowledge in real time. Your application uses system calls to ask the Linux kernel to perform tasks like opening a network socket, reading and writing a file, or creating a child process. You should use the <code>strace</code> command to troubleshoot a process that looks for issues in these calls, or when you need an overview of what a process is doing. Note that the <code>strace</code> command needs <em>root</em> privileges since it is attaching to another process. </p>
<p>Many system calls are available, but here are a few for reference:</p>
<ol class="none">
<li><code class="bold">open()</code>  Create or open files.</li>
<li><code class="bold">read()</code>  Read from a file descriptor.</li>
<li><code class="bold">write()</code>  Write to a file.</li>
<li><code class="bold">connect()</code>  Open a connection.</li>
<li><code class="bold">futex()</code>  Wait or wake up threads when a condition becomes true (blocking lock).<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<span epub:type="pagebreak" title="149" id="Page_149"/><h2><span class="NoteHead">Warning</span></h2>
<p>	The <code>strace</code> command can be very verbose and may cause performance issues for the process you are probing. Use it with caution in a production environment.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside></li>
</ol>
<p>Now, you should trace a process. The following command attaches to the running process <code>19419</code>, which is the Greeting web server from <span class="xref" itemid="xref_target_Chapter 4">Chapter 4</span> and prints out any system calls that are happening when the trace begins:</p>
<pre><code>$<b> sudo strace -s 128 -p 19419</b>
strace: Process 19419 attached
<var>--snip--</var>
accept4(5, {sa_family=AF_INET, sin_port=htons(64221), sin_addr=inet_addr("172.28.128.1")}, [16], SOCK_CLOEXEC) = 9
<var>--snip--</var>
recvfrom(9, "GET / HTTP/1.1\r\nHost: 172.28.128"<code>...</code>, 8192, 0, NULL, NULL) = 82 
getpeername(9, {sa_family=AF_INET, sin_port=htons(64221), sin_addr=inet_addr("172.28.128.1")}, [16]) = 0
<var>--snip--</var>
sendto(9, "HTTP/1.1 200 OK\r\nServer: gunicorn/20.0.4\r\nDate: Mon, 01 Feb 2022 22:03:12 GMT\r\nConnection: close\r\nContent-Type: text/html; chars"..., 160, 0, NULL, 0) = 160
sendto(9, "&lt;h1 style='color:green'&gt;Greetings!&lt;/h1&gt;", 39, 0, NULL, 0) = 39
<var>--snip--</var>
write(1, "172.28.128.1 - - [01/Feb/2022:21"..., 88) = 88
close(9) = 0
<var>--snip--</var></code></pre>
<p>The <code>-s</code> flag sets the message output size of <code>128</code> bytes. The <code>-p</code> flag tells <code>strace</code> which PID to attach to (in this case, it’s <code>19419</code>). I cherry-picked some system calls from the output to make it easier to follow. The <code>accept4</code> system call creates a new connection from IP address <code>172.28.128.1</code> and returns file descriptor <code>9</code>. The <code>recvfrom</code> system call receives an HTTP <code>GET</code> request from a socket with file descriptor <code>9</code>. The first <code>sendto</code> system call sends an HTTP header response from the web server back over the socket. The following <code>sendto</code> system call transmits the body of the HTTP <code>GET</code> response back to the socket as well. The <code>write</code> system call writes what appears to be a <em>syslog</em> line to file descriptor <code>1</code>. Finally, the <code>close</code> system call is executed, closing the previous socket file descriptor <code>9</code>, which closes the network connection. You have captured the transaction between an HTTP client and an HTTP server for a <code>GET</code> request. </p>
<p>Now, imagine you’re trying to investigate an issue but are lacking context on a process. You have exhausted other means, like log spelunking and metric watching. Everything seems in order, but your application is still not behaving correctly. You can use the summary flag (<code>-c</code>) for <code>strace</code> to get an overview of what system calls the process is using. It will output a running count of what system calls are being executed, how long each one is taking, and any errors that those calls return. Once you run the command, it will pause in the foreground while it collects data, and it won’t display the results until you press <span class="KeyCaps">CTRL-C</span>. The longer you let it run, the more data you will accumulate.</p>
<p>The <code>strace</code> command has numerous flags and options to use for tracing. You can use the follow (<code>-f</code>) flag to follow any new processes created (forked) <span epub:type="pagebreak" title="150" id="Page_150"/>from the parent. You can use the syscall (<code>-e</code>) flag when you want to track only specific system calls. You can use the summarize (<code>-c</code>) flag when you want an overall view of the system calls, timings, and errors. Finally, the output (<code>-o</code>) flag can be extremely useful for storing the trace output to a file so you can review and parse it later.</p>
<p>For example, enter the following command to fetch a summary for process ID <code>28485</code>:</p>
<pre><code>$ <b>sudo strace -p 28485 -c</b>
strace: Process 28485 attached
 % time     seconds  usecs/call     calls    errors syscall
------- ----------- ----------- --------- --------- ----------------
<span class="CodeAnnotationCode" aria-label="annotation1">1</span> 49.47    0.000141          14        10           sendto
  13.68    0.000039           2        17           fchmod
  10.53    0.000030           6         5           close
   7.37    0.000021           3         6           select
   7.02    0.000020           4         5           write
<span class="CodeAnnotationCode" aria-label="annotation2">2</span>  7.02    0.000020           1        11         6 openat
   2.11    0.000006           1         6           getppid
   1.75    0.000005           0        10           getpid
   0.35    0.000001           0         5           ioctl
   0.35    0.000001           0         5           recvfrom
<span class="CodeAnnotationCode" aria-label="annotation3">3</span>  0.35    0.000001           0        50           getpeername
   0.00    0.000000           0        10           getsockname
   0.00    0.000000           0        10           fcntl
------- ----------- ----------- --------- --------- ----------------
 100.00    0.000285                   150         6 total</code></pre>
<p>The <code>% time</code> column shows the percentage of time each call made up during the trace capture. In this example, the process spent most of its trace time <span class="CodeAnnotation" aria-label="annotation1">1</span> (before the trace was stopped) in the <code>sendto</code> system call. The <code>calls</code> column shows how many times the system call was executed. In this case, <code>getpeername</code> <span class="CodeAnnotation" aria-label="annotation3">3</span> was executed the most (50 times). The <code>getpeername</code> call returns the IP address of the peer connected over the socket. During the trace, process <code>28485</code> counted six errors <span class="CodeAnnotation" aria-label="annotation2">2</span> when calling the <code>openat</code> system call. You can use this call to open a file by its specified path name. </p>
<p>You should run <code>strace</code> again to focus on the errors for the <code>openat</code> system call. Enter the following command:</p>
<pre><code> $ <b>sudo strace -p 28485 -e openat</b>
<var>--snip--</var>
openat(AT_FDCWD, "/var/log/telnet-server.log", O_RDONLY) = -1 ENOENT (No such file or directory)
<var>--snip--</var></code></pre>
<p>The output shows that process <code>28485</code> is trying to open the <em>/var/log/telnet-server.log</em> file. The call is returning <code>-1</code>, which means the file does not exist. This matches the error output from the earlier summary. As you can see, being able to peer down into a running process and understand what it is doing at the system call level can be invaluable.</p>
<aside epub:type="sidebar">
<div class="top hr"><hr/></div>
<section class="note">
<span epub:type="pagebreak" title="151" id="Page_151"/><h2><span class="NoteHead">Note</span></h2>
<p> 	Other tools can explore a process. The <code>ltrace</code> command is like <code>strace</code>, but it reports on the dynamic library calls made. The <code>dtrace</code> framework is also like <code>strace</code>, but it can trace kernel-level issues as well.</p>
<div class="bottom hr"><hr/></div>
</section>
</aside>
<h2 id="h1-502482c10-0011">Summary</h2>
<p class="BodyFirst">Most of the scenarios described here reflect issues you will encounter throughout your career. Experience and repetition will help you build muscle memory for making quick work of these issues. My goal in describing these scenarios has been to show you how to use deductive reasoning to follow clues to find causes.</p>
<p>In this chapter, you learned about helpful forensic tools like <code>top</code>, <code>lsof</code>, <code>tcpdump</code>, <code>iostat</code>, and <code>vmstat</code>, which will help you diagnose symptoms. You also learned how to parse common logfiles using tools like <code>journalctl</code>, <code>grep</code>, and <code>awk</code>. All the tools and tactics discussed here should aid you the next time you find yourself trying to investigate problems.</p>
<p>This concludes Part III, which has been on monitoring and troubleshooting. You now can monitor and alert on any application you deploy to Kubernetes. You have also gotten a troubleshooting primer to help you investigate common problems that arise when managing hosts and software.</p>
</section>
</body></html>