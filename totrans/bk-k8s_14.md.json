["```\nroot@host01:~# systemctl status kubelet\n  kubelet.service - kubelet: The Kubernetes Node Agent\n     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; ...\n    Drop-In: /etc/systemd/system/kubelet.service.d\n               10-kubeadm.conf\n     Active: active (running) since ...\n```", "```\nroot@host01:~# strings /proc/$(pgrep kubelet)/cmdline\n/usr/bin/kubelet\n--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf\n--kubeconfig=/etc/kubernetes/kubelet.conf\n--config=/var/lib/kubelet/config.yaml\n--container-runtime=remote\n--container-runtime-endpoint=/run/containerd/containerd.sock\n--node-ip=192.168.61.11\n--pod-infra-container-image=k8s.gcr.io/pause:3.4.1\n```", "```\nroot@host01:~# cat /var/lib/kubelet/config.yaml\n...\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\n...\n```", "```\nroot@host01:~# strings /proc/$(pgrep kubelet)/cmdline\n...\n--container-runtime-endpoint=/var/run/crio/crio.sock\n...\n```", "```\nroot@host01:~# crictl images\nIMAGE             TAG                 IMAGE ID            SIZE\n,,,\nk8s.gcr.io/pause  3.4.1               0f8457a4c2eca       301kB\n...\n```", "```\nroot@host01:~# cat /var/lib/kubelet/config.yaml\n...\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\n...\n```", "```\nroot@host01:~# kubectl apply -f /opt/pod.yaml \npod/debug created\n```", "```\nroot@host01:~# kubectl exec -ti debug -- /bin/sh\n/ #\n```", "```\n/ # mount | grep resolv\n/dev/sda1 on /etc/resolv.conf type ext4 ...\n```", "```\n/ # cat /etc/resolv.conf \nsearch default.svc.cluster.local svc.cluster.local cluster.local \nnameserver 10.96.0.10\noptions ndots:5\n```", "```\n/ # mount | grep run\ntmpfs on /run/secrets/kubernetes.io/serviceaccount type tmpfs (ro,relatime)\n```", "```\n/ # exit\nroot@host01:~# kubectl delete pod debug\n```", "```\nroot@host01:~# cat /var/lib/kubelet/config.yaml \n...\nstaticPodPath: /etc/kubernetes/manifests\n...\n```", "```\nroot@host01:~# ls -1 /etc/kubernetes/manifests\netcd.yaml\nkube-apiserver.yaml\nkube-controller-manager.yaml\nkube-scheduler.yaml\n```", "```\nroot@host01:~# cat /etc/kubernetes/manifests/kube-apiserver.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n...\n  name: kube-apiserver\n  namespace: kube-system\nspec:\n  containers:\n  - command:\n    - kube-apiserver\n...\n```", "```\nroot@host04:~# ls -1 /etc/kubernetes/manifests\nroot@host04:~#\n```", "```\nroot@host01:~# kubectl apply -f /opt/deploy.yaml \ndeployment.apps/debug created\n```", "```\nroot@host01:~# kubectl get pods -o wide\nNAME                     READY   STATUS    ... NODE   ...\ndebug-8677494fdd-7znxn   1/1     Running   ... host02 ...  \ndebug-8677494fdd-9dgvd   1/1     Running   ... host03 ...  \ndebug-8677494fdd-hv6mt   1/1     Running   ... host04 ...  \ndebug-8677494fdd-ntqjp   1/1     Running   ... host02 ...  \ndebug-8677494fdd-pfw5n   1/1     Running   ... host03 ...  \ndebug-8677494fdd-qbhmn   1/1     Running   ... host02 ...  \ndebug-8677494fdd-qp9zv   1/1     Running   ... host03 ...  \ndebug-8677494fdd-xt8dm   1/1     Running   ... host03 ...\n```", "```\nroot@host01:~# kubectl drain --ignore-daemonsets host04\nnode/host04 cordoned\nWARNING: ignoring DaemonSet-managed Pods: ...\n...\npod/debug-8677494fdd-hv6mt evicted\nnode/host04 evicted\n```", "```\nroot@host01:~# kubectl get pods -o wide\nNAME                     READY   STATUS    ... NODE     ...\ndebug-8677494fdd-7znxn   1/1     Running   ... host02   ...\ndebug-8677494fdd-9dgvd   1/1     Running   ... host03   ...\ndebug-8677494fdd-ntqjp   1/1     Running   ... host02   ...\ndebug-8677494fdd-pfw5n   1/1     Running   ... host03   ...\ndebug-8677494fdd-qbhmn   1/1     Running   ... host02   ...\ndebug-8677494fdd-qfnml   1/1     Running   ... host01   ...\ndebug-8677494fdd-qp9zv   1/1     Running   ... host03   ...\ndebug-8677494fdd-xt8dm   1/1     Running   ... host03   ...\n```", "```\nroot@host01:~# kubectl get nodes\nNAME     STATUS                     ROLES        ...\nhost01   Ready                      control-plane...\nhost02   Ready                      control-plane...\nhost03   Ready                      control-plane...\nhost04   Ready,SchedulingDisabled   <none>       ...\n```", "```\nroot@host01:~# kubectl delete node host04\nnode \"host04\" deleted\n```", "```\nroot@host04:~# systemctl restart kubelet\n```", "```\nroot@host01:~# kubectl get nodes\nNAME     STATUS   ROLES        ...\nhost01   Ready    control-plane...\nhost02   Ready    control-plane...\nhost03   Ready    control-plane...\nhost04   Ready    <none>       ...\n```", "```\nroot@host01:~# kubectl scale deployment debug --replicas=1\ndeployment.apps/debug scaled\nroot@host01:~# kubectl scale deployment debug --replicas=12\ndeployment.apps/debug scaled\n```", "```\nroot@host01:~# kubectl get pods -o wide\nNAME                     READY   STATUS    ... NODE     ...\n...\ndebug-8677494fdd-j7cth   1/1     Running   ... host04   ...\ndebug-8677494fdd-jlj4v   1/1     Running   ... host04   ...\n...\n```", "```\nroot@host01:~# kubectl top nodes\nNAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \nhost01   503m         25%    1239Mi          65%       \nhost02   518m         25%    1346Mi          71%       \nhost03   534m         26%    1382Mi          73%       \nhost04   288m         14%    542Mi           29%\n```", "```\nevictionHard:\n  memory.available: \"1900Mi\"\n```", "```\nroot@host04:~# cat /opt/node-evict.yaml >> /var/lib/kubelet/config.yaml\nroot@host04:~# systemctl restart kubelet\n```", "```\nroot@host01:~# kubectl get nodes\nNAME     STATUS   ROLES        ...\nhost01   Ready    control-plane...\nhost02   Ready    control-plane...\nhost03   Ready    control-plane...\nhost04   Ready    <none>       ...\n```", "```\nroot@host01:~# kubectl describe node host04\nName:               host04\n...\n  Normal   NodeHasInsufficientMemory  6m31s                ...\n  Warning  EvictionThresholdMet       7s (x14 over 6m39s)  ...\n```", "```\nroot@host01:~# kubectl get pods -o wide\nNAME                     READY   STATUS        ... NODE     ...\ndebug-8677494fdd-4274k   1/1     Running       ... host01   ...\ndebug-8677494fdd-4pnzb   1/1     Running       ... host01   ...\ndebug-8677494fdd-5nw6n   1/1     Running       ... host01   ...\ndebug-8677494fdd-7kbp8   1/1     Running       ... host03   ...\ndebug-8677494fdd-dsnp5   1/1     Running       ... host03   ...\ndebug-8677494fdd-hgdbc   1/1     Running       ... host01   ...\ndebug-8677494fdd-j7cth   1/1     Running       ... host04   ...\ndebug-8677494fdd-jlj4v   0/1     OutOfmemory   ... host04   ...\ndebug-8677494fdd-lft7h   1/1     Running       ... host01   ...\ndebug-8677494fdd-mnk6r   1/1     Running       ... host01   ...\ndebug-8677494fdd-pc8q8   1/1     Running       ... host01   ...\ndebug-8677494fdd-sr2kw   0/1     OutOfmemory   ... host04   ...\ndebug-8677494fdd-tgpb2   1/1     Running       ... host03   ...\ndebug-8677494fdd-vnjks   0/1     OutOfmemory   ... host04   ...\ndebug-8677494fdd-xn8t8   1/1     Running       ... host02   ...\n```", "```\nroot@host04:~# sed -i '/^evictionHard/,+2d' /var/lib/kubelet/config.yaml \nroot@host04:~# systemctl restart kubelet\n```", "```\nroot@host01:~# kubectl scale deployment debug --replicas=1\nroot@host01:~# kubectl scale deployment debug --replicas=12\n```", "```\nroot@host04:~# iptables -I INPUT -s 192.168.61.10 -j DROP\nroot@host04:~# iptables -I OUTPUT -d 192.168.61.10 -j DROP\n```", "```\nroot@host01:~# kubectl get nodes\nNAME     STATUS     ROLES        ...\nhost01   Ready      control-plane...\nhost02   Ready      control-plane...\nhost03   Ready      control-plane...\nhost04   NotReady   <none>       ...\n```", "```\nroot@host01:~# kubectl get pods -o wide\nNAME                     READY   STATUS        ... NODE     ...\ndebug-8677494fdd-2wrn2   1/1     Running       ... host01   ...\ndebug-8677494fdd-4lz48   1/1     Running       ... host02   ...\ndebug-8677494fdd-78874   1/1     Running       ... host01   ...\ndebug-8677494fdd-7f8fw   1/1     Running       ... host01   ...\ndebug-8677494fdd-9vb5m   1/1     Running       ... host03   ...\ndebug-8677494fdd-b7vj6   1/1     Running       ... host03   ...\ndebug-8677494fdd-c2c4v   1/1     Terminating   ... host04   ...\ndebug-8677494fdd-c8tzv   1/1     Running       ... host03   ...\ndebug-8677494fdd-d2r6b   1/1     Terminating   ... host04   ...\ndebug-8677494fdd-d5t6b   1/1     Running       ... host01   ...\ndebug-8677494fdd-j7cth   1/1     Terminating   ... host04   ...\ndebug-8677494fdd-jjfsl   1/1     Terminating   ... host04   ...\ndebug-8677494fdd-nqb8z   1/1     Running       ... host03   ...\ndebug-8677494fdd-sskd5   1/1     Running       ... host02   ...\ndebug-8677494fdd-wz6c6   1/1     Terminating   ... host04   ...\ndebug-8677494fdd-x5b4w   1/1     Running       ... host02   ...\ndebug-8677494fdd-zfbml   1/1     Running       ... host01   ...\n```", "```\nroot@host04:~# crictl ps\nCONTAINER           IMAGE          ...  STATE      NAME  ...\n2129a1cb00607       16ea53ea7c652  ...  Running    debug ...\ncfd7fd6142321       16ea53ea7c652  ...  Running    debug ...\n0289ffa5c816d       16ea53ea7c652  ...  Running    debug ...\nfb2d297d11efb       16ea53ea7c652  ...  Running    debug ...\n...\n```"]