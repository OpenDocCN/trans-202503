<html><head></head><body><div id="sbo-rt-content"><section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" title="3" id="Page_3"/>1</span><br/>
<span class="ChapterTitle">An Overview of Machine Learning</span></h1>
</header>
<figure class="opener">
<img src="Images/chapterart.png" alt="" width="206" height="206"/>
</figure>
<p class="ChapterIntro">This book is about <em>deep learning</em>, a subfield of <em>machine learning</em>. The phrase <em>machine learning</em><b> </b>describes a growing body of techniques that share a common goal: extracting meaningful information from data. Here, <em>data</em> refers to anything that can be represented numerically. Data can be raw numbers (like stock prices on successive days, the masses of different planets, or the heights of people visiting a county fair), but it can also be sounds (the words someone speaks into their cell phone), pictures (photographs of flowers or cats), words (the text of a newspaper article or a novel), behavior (what activities someone enjoys), preferences (the music or films someone likes), or anything else that we can collect and describe with numbers.</p>
<p><span epub:type="pagebreak" title="4" id="Page_4"/>Our goal is to discover meaningful information, where it’s up to us to decide what’s meaningful. We usually want to find patterns that help us understand the data or use past measurements to predict future events. For example, we might want to predict a movie someone would like based on movies they’ve already rated, read the handwriting on a note, or identify a song from just a few notes.</p>
<p>We generally find the information we’re after in three steps: we identify the information that we want to find, we collect data that we hope will hold that information, and then we design and run algorithms to extract as much of that information as possible from that data. </p>
<p>In this chapter, we’ll cover some of the major movements in machine learning. We’ll begin by discussing an early approach to machine learning called an expert system. We’ll then discuss three of the major approaches to learning: supervised learning, unsupervised learning, and reinforcement learning. We’ll end the chapter by looking at deep learning. </p>
<h2 id="h1-500723c01-0001">Expert Systems</h2>
<p class="BodyFirst">Before deep learning became practical on a widespread basis, a popular approach to learning from data involved creating <em>expert systems</em>. Still used today, these are computer programs intended to encapsulate the thought processes of human experts such as doctors, engineers, and even musicians. The idea is to study a human expert at work, watch what they do and how they do it, and perhaps ask them to describe their process out loud. We capture that thinking and behavior with a set of rules. The hope is that a computer could then do the expert’s job just by following those rules. </p>
<p>These kinds of systems can work well once they’re built, but they’re difficult to create and maintain. It’s worth taking a moment to see why. The problem is that the key step of producing the rules, called <em>feature engineering</em>, can require impractical amounts of human intervention and ingenuity. Part of deep learning’s success is that it addresses exactly this problem by creating the rules algorithmically.</p>
<p>Let’s illustrate the problem faced by expert systems with a practical example: recognizing digits. Let’s say that we want to teach a computer to recognize the number 7. By talking to people and asking questions, we might come up with a set of three small rules that let us distinguish a 7 from all other digits: first, 7s have a mostly horizontal line near the top of the figure; second, they have a mostly northeast-southwest diagonal line; and third, those two lines meet in the upper right. The rules are illustrated in <a href="#figure1-1" id="figureanchor1-1">Figure 1-1</a>.</p>
<p>This might work well enough until we get a 7 like <a href="#figure1-2" id="figureanchor1-2">Figure 1-2</a>.</p>
<span epub:type="pagebreak" title="5" id="Page_5"/><figure>
<img src="Images/f01001.png" alt="f01001" width="835" height="261"/>
<figcaption><p><a id="figure1-1">Figure 1-1</a>: Top: A handwritten 7. Bottom: A set of rules for distinguishing a handwritten 7 from other digits. </p></figcaption>
</figure>
<figure>
<img src="Images/f01002.png" alt="f01002" width="124" height="161"/>
<figcaption><p><a id="figure1-2">Figure 1-2</a>: A 7 that would not be recognized by the rules of <a href="#figure1-1">Figure 1-1</a> because of the extra horizontal line</p></figcaption>
</figure>
<p>Our set of rules won’t recognize this as a 7, because we hadn’t originally considered that some people put a bar through the middle of the diagonal stroke. So now we need to add another rule for that special case. In practice, this kind of thing happens over and over again to anyone developing an expert system. In a problem of any complexity, finding a good and complete set of rules is frequently an overwhelmingly difficult task. Turning human expertise into a series of explicit instructions often means laboriously uncovering inferences and decisions that people make without even realizing it, turning those into huge numbers of instructions, then adjusting and hand-tuning those instructions to cover all of the situations that were initially overlooked, debugging the rules where they contradict, and so on, in a seemingly never-ending series of tasks performed on a massive, complicated set of rules.</p>
<p>This process of finding the rules to accomplish a job is tough work: the rules human experts follow are often not explicit, and as we saw, it’s easy to overlook exceptions and special cases. Imagine trying to find a comprehensive set of rules that can mimic a radiologist’s thought process as they determine whether a smudge on an MRI image is benign or not, or the way an air-traffic controller handles heavily scheduled air traffic, or how someone drives a car safely in extreme weather conditions. To make things even more complex, the technology, laws, and social conventions around human activities are constantly changing, requiring us to constantly monitor, update, and repair this tangled web of interconnecting rules. </p>
<p><span epub:type="pagebreak" title="6" id="Page_6"/>Rule-based expert systems can be made to work in some cases, but the difficulties of crafting the right set of rules, making sure they work properly across a wide variety of data, and keeping them up to date, makes them impractical as a general solution. </p>
<p>If we could only find and manage this set of rules, then computers could indeed emulate some forms of human decision making. This is just what deep learning is all about. These algorithms, given enough training data, can discover the decision-making rules <em>automatically. </em>We don’t have to explicitly tell the algorithm how to recognize a 2 or a 7, because the system figures that out for itself. It can work out whether an MRI smudge is benign or not, whether a cellphone’s photo has been ideally exposed, or whether a piece of text was really written by some historical figure. These are all among the many applications deep learning is already carrying out for us.</p>
<p>The computer discovers the decision-making rules by examining the input data and extracting patterns. The system never “understands” what it’s doing, as a person does. It has no common sense, awareness, or comprehension. It just measures patterns in the training data and then uses those patterns to evaluate new data, producing a decision or result based on the examples it was trained on.</p>
<p>Generally speaking, we train deep learning algorithms in one of three different ways, depending on the data we have and what we want the computer to produce for us. Let’s survey them briefly.</p>
<h2 id="h1-500723c01-0002">Supervised Learning</h2>
<p class="BodyFirst">We’ll first consider <em>supervised learning</em>. Here, the word <em>supervised</em> is a synonym for “labeled.” In supervised learning, we typically give the computer pairs of values: an item drawn from a dataset, and a label that we’ve assigned to that item. </p>
<p>For example, we might be training a system called an <em>image classifier</em>, with the goal of having it tell us what object is most prominent in a photograph. To train this system, we’d give it a collection of images, and accompany each image with a label describing the most prominent object. So, for example, we might give the computer a picture of a tiger and a label consisting of the word <em>tiger</em>. </p>
<p>This idea can be extended to any kind of input. Suppose that we have a few cookbooks full of recipes that we’ve tried out, and we’ve kept records on how much we liked each dish. In this case, the recipe would be the input, and our rating of it would be that recipe’s label. After training a program on all of our cookbooks, we could give our trained system a new recipe, and it could predict how much we’d enjoy eating the result. Generally speaking, the better we’re able to train the system (usually by providing more pieces of training data), the better its prediction will be.</p>
<p>Regardless of the type of data, by giving the computer an enormous number of pairs of inputs and labels, a successful system designed for the task will gradually discover enough rules or patterns from the inputs that it will be able to correctly <em>predict</em> each provided label. That is, as a result of this training, the system has learned<em> </em>what to measure in each input so that <span epub:type="pagebreak" title="7" id="Page_7"/>it can identify which of its learned labels it should return. When it gets the right answer frequently enough for our needs, we say that the system has been <em>trained</em>.</p>
<p>Keep in mind that the computer has no sense of what a recipe actually is, or how things taste. It’s just using the data in the input to find the closest matching label, using the rules it learned during training. </p>
<p><a href="#figure1-3" id="figureanchor1-3">Figure 1-3</a> shows the results of giving four photographs to a trained image classifier. </p>
<p>These photos were found on the web, and the system had never seen them before. In response to each image, the classifier tells us the likelihood for each of the 1,000 labels it was trained to recognize. Here we show the top five predictions for each photo, with their associated probabilities.</p>
<p>The picture in the upper left of <a href="#figure1-3">Figure 1-3</a> is a bunch of bananas, so ideally we’d like to get back a label like <span class="CustomCharStyle">bunch of bananas</span>. But this particular classifier wasn’t trained on any images labeled <span class="CustomCharStyle">bunch of bananas</span>. The algorithm can only return one of the labels it was trained on, in the same way that we can only identify objects by the words we know. The closest match it could find from the labels it was trained on was just <span class="CustomCharStyle">banana</span>, so that’s the label it returned to us.</p>
<figure>
<img src="Images/f01003.png" alt="f01003" width="694" height="593"/>
<figcaption><p><a id="figure1-3">Figure 1-3</a>: Four images and their predicted labels, with probabilities, from a deep learning classifier</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="8" id="Page_8"/>In the upper left, the computer has very high confidence in the label of <span class="CustomCharStyle">banana</span>. In the lower right, the computer is about 60 percent confident that the proper label is <span class="CustomCharStyle">ear</span>. but it’s about 40 percent confident it could be <span class="CustomCharStyle">corn</span>. If we follow a common practice and return just one label per image to the user, it would be helpful to also return the computer’s confidence that the label is correct. If the confidence isn’t reassuring, such as only about 60 percent for <span class="CustomCharStyle">ear</span>, we might decide to try again with a different algorithm, or perhaps even ask a human for help.</p>
<h2 id="h1-500723c01-0003">Unsupervised Learning</h2>
<p class="BodyFirst">When we don’t have labels associated with our data, we use techniques that are known collectively as <em>unsupervised learning</em>. These algorithms learn about relationships between the elements of the input, rather than between each input and a label.</p>
<p>Unsupervised learning is frequently used for <em>clustering</em>, or grouping, pieces of data that we think are related. For example, suppose that we’re digging out the foundation for a new house, and while excavating, we find the ground is filled with old clay pots and vases. We call an archaeologist friend who realizes that we’ve found a jumbled collection of ancient pottery, apparently from many different places and perhaps even different times.</p>
<p>The archaeologist doesn’t recognize any of the markings and decorations, so she can’t say for sure where each one came from. Some of the marks look like variations on the same theme, but other marks look like different symbols. To get a handle on the problem, she takes rubbings of the markings and then tries to sort them into groups. But there are far too many for her to sort through, and since all of her graduate students are working on other projects, she turns to a machine learning algorithm to automatically group the markings together in a sensible way.</p>
<p><a href="#figure1-4" id="figureanchor1-4">Figure 1-4</a> shows her captured marks and the groupings an algorithm might produce. </p>
<figure>
<img src="Images/f01004.png" alt="f01004" width="694" height="318"/>
<figcaption><p><a id="figure1-4">Figure 1-4</a>: Using a clustering algorithm to organize marks on clay pots. Left: The markings from the pots. Right: The marks grouped into similar clusters.</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="9" id="Page_9"/>Because this technique arranges our data into related groups (or <em>clusters</em>), we call the process <em>clustering</em>, and we refer to this algorithm as a <em>clustering algorithm</em>. </p>
<p>Unsupervised learning algorithms can also be used to improve the quality of measured data (for example, removing speckles in a photo taken with a cellphone camera) or compress datasets so they take up less room on our disks, without losing any qualities we care about (such as what MP3 and JPG encoders do for sound and images).</p>
<h2 id="h1-500723c01-0004">Reinforcement Learning </h2>
<p class="BodyFirst">Sometimes we want to train a computer to learn how to perform a task, but we don’t even know the best way to do it ourselves. Maybe we’re playing a complex game or writing some music. What’s the next best move to take or the next best note to choose? Often there isn’t a single best answer. But we might be able to roughly say that one answer is better than another. It would be great to be able to train a computer to find the best steps toward a good result by letting it try out possible approaches, which we only need to rank in a very general manner, such as “probably good,” or “better than the last one.”</p>
<p>For example, suppose we’re responsible for designing the operation of the elevators in a new office building, as in <a href="#figure1-5" id="figureanchor1-5">Figure 1-5</a>. Our job is to decide where elevator cars should wait when they’re not needed, and which car should answer a request when someone pushes a call button. Let’s say that our goal is to minimize the average wait time for all riders.</p>
<figure>
<img src="Images/f01005.png" alt="f01005" width="694" height="440"/>
<figcaption><p><a id="figure1-5">Figure 1-5</a>: We want to find the best schedule for these elevators.</p></figcaption>
</figure>
<p><span epub:type="pagebreak" title="10" id="Page_10"/>How should we do that? The quality of any solution we might imagine will depend entirely on the patterns of when and where people want to travel. Maybe in the morning everyone’s arriving for work, so we should always bring empty cars to the first floor where they’ll be ready for new arrivals. But perhaps at lunch everyone wants to go outside, so we should keep idle cars near the top floors, always ready to come down and take people to the ground floor. But if it’s raining, perhaps most people will instead want to go to the cafeteria on the top floor. Day by day, hour by hour, what’s the best policy?</p>
<p>There probably isn’t any single best policy, so the computer can’t learn to give it to us. All we can do is try out different approaches over time, and choose the one that seems to be giving us the best results. So we’ll have the computer invent a policy, or maybe make a variation on an existing one, and see how well it performs. We’ll then give it a score based on the average wait time of our riders. After trying out lots of variations, we can pick the policy with the best score. And then, over time, as patterns change, we can try out new approaches, always searching, but keeping the schedule with the best score. </p>
<p>This is an example of <em>reinforcement learning (RL)</em>. The technique of RL is at the heart of the recent game-playing algorithms that have been beating human masters at games like Go, and even online strategy games like <em>StarCraft</em>. </p>
<h2 id="h1-500723c01-0005">Deep Learning</h2>
<p class="BodyFirst">The phrase <em>deep learning</em> refers to machine learning algorithms that use a series of steps, or <em>layers,</em> of computation (Bishop 2006; Goodfellow, Bengio, and Courville 2017). We can draw these layers on the page in any way we like as long the structure is clear. If we draw the layers vertically, we can imagine looking up from the bottom and saying that the system is tall, or, looking down from the top and calling it deep. If we draw many layers horizontally, we might say that the system is wide. For no particular reason, the “deep” language is what caught on, lending its name to the whole field of deep learning.  </p>
<p>It’s important to keep in mind that these systems are called “deep” only because of their appearance when we draw them stacked up vertically. They’re not deep in the sense of having profound understanding or penetrating insights. When a deep learning system attaches a name to a face in a photo, it has no knowledge of what faces are, or what people are, or even that people exist. The computer just measures pixels and, using the patterns it learned from the training data, produces the most likely label. </p>
<p>Let’s jump many chapters ahead and take a quick look at a deep network, pictured in <a href="#figure1-6" id="figureanchor1-6">Figure 1-6</a>. In this simple network, we start with four input numbers, shown at the bottom of the figure. These might be the values of the four pixels in a 2 by 2 grayscale image, the closing price of a stock over four sequential days, or four samples from a snippet of voice data. Each input value is just a floating-point number, such as –2.982 or 3.1142. </p>
<span epub:type="pagebreak" title="11" id="Page_11"/><figure>
<img src="Images/f01006.png" alt="f01006" width="693" height="658"/>
<figcaption><p><a id="figure1-6">Figure 1-6</a>: A simple deep neural network</p></figcaption>
</figure>
<p>Those four values go upward in the diagram into a <em>layer</em>, or grouping, of three <em>artificial neurons</em>. Although they have the word <em>neuron</em> in their name and were distantly inspired by real neurons, these artificial neurons are extremely simple. We’ll see them in detail in Chapter 13, but it’s best to think of them as units that perform a tiny calculation and are not remotely as complex as real neurons.</p>
<p>In this diagram, each neuron on layer 1 receives each of the four starting numbers as input. Note that each of the 12 lines that take an input value into a neuron has a little dot on it. In this figure, each dot represents the idea that the input value traveling on that line is multiplied by another number, called the <em>weight,</em> before it reaches the neuron. These weights are vital to the network, and we’ll return to them in a moment.</p>
<p>The output of each artificial neuron in layer 1 is a new number. In <a href="#figure1-6">Figure 1-6</a>, each of those outputs is fed into each of the neurons on layer 2, and again each value is multiplied by a weight along the way. Finally, the values produced by the two neurons on layer 2 are the output of the network. We might interpret these output values to be the chance that the input is <span epub:type="pagebreak" title="12" id="Page_12"/>in each of two classes, or the first and last name of the person who spoke that sound fragment, or the predicted price of the stock on each of the next two days.</p>
<p>Each of the big circles representing an artificial neuron turns its input values into a number. These computations are fixed: once we set up the network, each of these neurons will always compute the same output for a given input. So, once we’ve chosen the artificial neurons and arranged them into the network of <a href="#figure1-6">Figure 1-6</a>, almost everything is specified. </p>
<p>The only things in <a href="#figure1-6">Figure 1-6</a> that can change are the inputs and the weights. That’s the key insight that makes it possible to train the network. The weights start out as random numbers. That means the output of the network will initially be nonsense, and we’ll never get back the results we want (unless we happen to occasionally get lucky).</p>
<p>To get the network to reliably produce the answers we want, we carefully change the weights, just a little at a time, after each mistaken output, to make the network more likely to produce the desired values at the output. If we do this carefully, then over time the output values will gradually get closer and closer to the results we want. Eventually, if we’ve done our job well, the network will produce the right answer in response to almost all the data in our training database, and we can release our network to the web, or offer it as a product or service.</p>
<p>In short, training this network, or teaching it, is nothing more than finding values for the weights so that every input produces the desired output. Amazingly, this is all there is to it! Even when our networks grow to hundreds of layers of many varieties, and tens of thousands of artificial neurons, and millions of weights, learning usually means just gradually changing the weights until we get the answers we want. More sophisticated networks might learn some other values as well, but the weights are always important. </p>
<p>One of the beautiful things about this process is that it makes good on the promise of feature engineering. For example, consider a system that takes a photo as input and tells us what breed of dog is in the picture. When the training process for this system has finished and the weights have settled into their best values, they have the effect of turning the neurons into little feature detectors. For example, one of the neurons on an early layer might produce a large value if it “sees” an eye, and another if it “sees” a floppy ear (we’ll see just how this is done in Chapter 16). Then later neurons might look for combinations of these, such as a bushy tail along with short legs, or dark eyes with a long nose and large body, to help it determine the breed. In short, the neurons are looking for features, though we never explicitly guided them to. Feature detection is just a natural result of training the weights to produce the correct answers.</p>
<p>So although manually building an expert system that acts like a radiologist is a near-impossible task, creating a complex deep network and training it successfully can implement that agenda automatically. The system finds its own ways of combining the values of the pixels in each image into features and then using those features to make a determination about whether that image shows healthy tissue or not (Saba et al. 2019). </p>
<h2 id="h1-500723c01-0006"><span epub:type="pagebreak" title="13" id="Page_13"/>Summary</h2>
<p class="BodyFirst">In this chapter, we got a general sense of deep learning. We began with expert systems, which required too much manual work to be successful in practice. We saw that training a deep learning system usually follows one of three approaches. Supervised learning means that we provide a label with every piece of data so that we can train the system to predict the correct label for new data. Unsupervised learning means that we give the system just the data, without labels, so we train the system to cluster the data into similar groups. And reinforcement learning means that we score various proposals put forth by the computer in the hope that it will eventually come up with an acceptably good solution.</p>
<p>We then looked at a real, but tiny, deep learning system. The basic structure organized artificial neurons into layers. Neurons on each layer communicate with the neurons on the previous and following layer. It’s the shape of this structure when we draw it in this form (like a tall tower of layers) that gives deep learning its name.</p>
<p>Finally, we saw the importance of the weights, or the values that multiply every number before it arrives at the input of an artificial neuron. When we teach a system, or we say it’s learning, all we’re usually doing is adjusting these weights. When the weights have found sufficiently good values, the system is able to do the job we’ve asked of it. </p>
<p>The next few chapters will dig into the background that we’ll need to design and build deep learning systems.</p>
</section>
</div></body></html>