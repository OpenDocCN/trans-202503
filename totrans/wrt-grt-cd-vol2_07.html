<html><head></head><body>
		<h2 class="h2" id="ch07"><span epub:type="pagebreak" id="page_173"/><strong><span class="big">7</span></strong><br/><strong>VARIABLES IN A HIGH-LEVEL LANGUAGE</strong></h2>&#13;
		<div class="image1">&#13;
			<img alt="image" src="../images/common01.jpg"/>&#13;
		</div>&#13;
		<p class="noindent">This chapter explores the low-level implementation of variables found in high-level languages. Although assembly language programmers usually have a good feel for the connection between variables and memory locations, HLLs add sufficient abstraction to obscure this relationship. We’ll cover the following topics:</p>&#13;
		<ul>&#13;
			<li>&#13;
				<p class="noindent">The runtime memory organization typical for most compilers</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">How the compiler breaks up memory into different sections and places variables into each</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">The attributes that differentiate variables from other objects</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">The difference between static, automatic, and dynamic variables</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">How compilers organize automatic variables in a stack frame</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">The primitive data types that hardware provides for variables</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">How machine instructions encode the address of a variable</p>&#13;
				</li>&#13;
		</ul>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_174"/>When you finish reading this chapter, you should have a good understanding of how to declare variables in your program to use the least amount of memory and produce fast-running code.</p>&#13;
		<h3 class="h3" id="ch00lev1sec63"><strong>7.1 Runtime Memory Organization</strong></h3>&#13;
		<p class="noindent">As <a href="ch04.xhtml#ch04">Chapter 4</a> discussed, operating systems (like macOS, Linux, or Windows) put different types of data into different sections (or <em>segments</em>) of main memory. Although it’s possible to control the memory organization by running a linker and specifying various command-line parameters, by default Windows loads a typical program into memory using an organization like the one shown in <a href="ch07.xhtml#ch7fig1">Figure 7-1</a> (macOS and Linux are similar, although they rearrange some of the sections).</p>&#13;
		<div class="image" id="ch7fig1">&#13;
			<img alt="Image" src="../images/07fig01.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-1: Typical runtime memory organization for Windows</em></p>&#13;
		<p class="indent">The operating system reserves the lowest memory addresses. Generally, your application cannot access data (or execute instructions) at the lowest addresses in memory. One reason the OS reserves this space is to help detect <code>NULL</code> pointer references. Programmers often initialize pointers with <code>NULL</code> (<code>0</code>) to indicate that the pointer is not valid. Should you attempt to access memory location <code>0</code> under such an OS, the OS will generate a <em>general protection fault</em> to indicate that it’s an invalid memory location.</p>&#13;
		<p class="indent">The remaining seven sections of memory hold different types of data associated with your program: the stack, the heap, the code, constants, read-only data, static (initialized) variables, and storage (uninitialized) variables.</p>&#13;
		<p class="indent">Most of the time, a given application can live with the default layouts chosen for these sections by the compiler and linker/loader. In some cases, however, knowing the memory layout can help you develop shorter programs. For example, because the code section is usually read-only, you might be able to combine the code, constant, and read-only data sections into a single section, thereby saving any padding space that the compiler/linker may place between these sections. Although for large applications <span epub:type="pagebreak" id="page_175"/>this is probably insignificant, for small programs it can have a big impact on the size of the executable.</p>&#13;
		<p class="indent">Next we’ll discuss each of these sections in detail.</p>&#13;
		<h4 class="h4" id="ch00lev2sec67"><strong>7.1.1 The Code, Constant, and Read-Only Sections</strong></h4>&#13;
		<p class="noindent">The code (or <em>text</em>) section in memory contains the machine instructions for a program. Your compiler translates each statement you write into a sequence of one or more byte values (machine instruction opcodes). The CPU interprets these opcode values during program execution.</p>&#13;
		<p class="indent">Most compilers also attach a program’s read-only data and constant pool (constant table) sections to the code section because, like the code instructions, the read-only data is already write-protected. However, it is perfectly possible under Windows, macOS, Linux, and many other operating systems to create a separate section in the executable file and mark it as read-only. As a result, some compilers do support a separate read-only data section, and some compilers even create a different section (the constant pool) for the constants that the compiler emits. These sections contain initialized data, tables, and other objects that the program should not change during program execution.</p>&#13;
		<p class="indent">Many compilers generate multiple code sections and leave it up to the linker to combine them into a single code segment prior to execution. To understand why, consider the following short Pascal code fragment:</p>&#13;
		<pre class="programs">&#13;
			if( <span class="codeitalic1">SomeBooleanExpression</span> ) then begin<br/><br/>    &lt;&lt; Some code that executes 99.9% of the time &gt;&gt;<br/><br/>end<br/>else begin<br/><br/>    &lt;&lt; Some code that executes 0.01% of the time &gt;&gt;<br/><br/>end;</pre>&#13;
		<p class="indent">Without worrying about how it does so, assume that the compiler can figure out that the <code>then</code> section of this <code>if</code> statement executes far more often than the <code>else</code> section. An assembly programmer, wanting to write the fastest possible code, might encode this sequence as follows:</p>&#13;
		<pre class="programs">&#13;
			    &lt;&lt; evaluate Boolean expression, leave true/false in EAX &gt;&gt;<br/>    test( eax, eax );<br/>    jz exprWasFalse;<br/>    &lt;&lt; Some code that executes 99.9% of the time &gt;&gt;<br/>rtnLabel:<br/>    &lt;&lt; Code normally following the last END in the<br/>               Pascal example &gt;&gt;<br/>        .<br/>        .<br/>        .<br/><span epub:type="pagebreak" id="page_176"/>// somewhere else in the code, not in the direct execution path<br/>// of the above:<br/><br/>exprWasFalse:<br/>    &lt;&lt; Some code that executes 0.1% of the time &gt;&gt;<br/><br/>    jmp rtnLabel;</pre>&#13;
		<p class="indent">This assembly code might seem a bit convoluted, but keep in mind that any control transfer instruction is probably going to consume a lot of time because of pipelined operation on modern CPUs (see <a href="ch09.xhtml#ch09">Chapter 9</a> of <em>WGC1</em> for the details). Code that executes without branching (or that falls straight through) executes the fastest. In the previous example, the common case falls straight through 99.9 percent of the time. The rare case winds up executing two branches (one to transfer to the <code>else</code> section and one to return to the normal control flow). But because this code rarely executes, it can afford to take longer to do so.</p>&#13;
		<p class="indent">Many compilers use a little trick to move sections of code around like this in the machine code they generate—they emit the code sequentially, but place the <code>else</code> code in a separate section. The following MASM code demonstrates this technique:</p>&#13;
		<pre class="programs">&#13;
			    &lt;&lt; evaluate Boolean expression, leave true/false in EAX &gt;&gt;<br/>    test eax, eax<br/>    jz exprWasFalse<br/>    &lt;&lt; Some code that executes 99.9% of the time &gt;&gt;<br/>alternateCode segment<br/><br/>exprWasFalse:<br/>    &lt;&lt; Some code that executes 0.1% of the time &gt;&gt;<br/><br/>    jmp rtnLabel;<br/>alternateCode ends<br/><br/>rtnLabel:<br/>    &lt;&lt; Code normally following the last END in the Pascal example &gt;&gt;</pre>&#13;
		<p class="indent">Even though the <code>else</code> section code appears to immediately follow the <code>then</code> section’s code, placing it in a different segment tells the assembler/linker to move this code and combine it with other code in the <code>alternateCode</code> segment. This little trick, because it relies upon the assembler or linker to move the code, can simplify HLL compilers. (GCC, for example, uses this approach to move code around in the assembly language file it emits.) As a result, you will see this trick being used on occasion and can expect some compilers to produce multiple code segments.</p>&#13;
		<h4 class="h4" id="ch00lev2sec68"><span epub:type="pagebreak" id="page_177"/><strong>7.1.2 The Static Variables Section</strong></h4>&#13;
		<p class="noindent">Many languages provide the ability to initialize a global variable during the compilation phase. For example, in C/C++ you could use statements like the following to provide initial values for these static objects:</p>&#13;
		<pre class="programs">&#13;
			static int i = 10;<br/>static char ch[] = { 'a', 'b', 'c', 'd' };</pre>&#13;
		<p class="indent">In C/C++ and other languages, the compiler places these initial values in the executable file. When you execute the application, the OS loads the portion of the executable file that contains these static variables into memory so that the values appear at the addresses associated with those variables. Therefore, when the program in this example first begins execution, <code>i</code> and <code>ch</code> will have these values bound to them.</p>&#13;
		<p class="indent">The static section is often called the <code>DATA</code> or <code>_DATA</code> segment in the assembly listings that most compilers produce. As an example, consider the following C code fragment:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdlib.h&gt;<br/>#include &lt;stdio.h&gt;<br/><br/>static char *c = "";<br/>static int i = 2;<br/>static int j = 1;<br/>static double array[4] = {0.0, 1.0, 2.0, 3.0};<br/><br/>int main( void )<br/>{<br/><br/>      .<br/>      .<br/>      .</pre>&#13;
		<p class="indent">Here’s the MASM assembly code that the Visual C++ compiler emits for those declarations:</p>&#13;
		<pre class="programs">&#13;
			_DATA   SEGMENT<br/>?c@@3PEADEA   DQ  FLAT:$SG6912                 ; c<br/>?i@@3HA       DD  02H                          ; i<br/>?j@@3HA       DD  01H                          ; j<br/>?array@@3PANA DQ  00000000000000000r      ; 0  ; array<br/>              DQ  03ff0000000000000r      ; 1<br/>              DQ  04000000000000000r      ; 2<br/>              DQ  04008000000000000r      ; 3<br/>_DATA   ENDS</pre>&#13;
		<p class="indent">As you can see, the Visual C++ compiler places these variables in the <code>_DATA</code> segment.</p>&#13;
		<h4 class="h4" id="ch00lev2sec69"><span epub:type="pagebreak" id="page_178"/><strong>7.1.3 The Storage Variables Section</strong></h4>&#13;
		<p class="noindent">Most operating systems zero out memory prior to program execution. Therefore, if an initial value of <code>0</code> is suitable, you don’t need to waste any disk space with the static object’s initial value. Generally, however, compilers treat uninitialized variables in a static section as though you’ve initialized them with <code>0</code>, which consumes disk space. Some operating systems provide another section type, the storage variables section (also known as the <em>BSS section</em>), to avoid this wasted disk space.</p>&#13;
		<p class="indent">This section is where compilers typically store static objects that don’t have an explicit initial value. BSS, as noted in <a href="ch04.xhtml#ch04">Chapter 4</a>, stands for “block started by a symbol,” which is an old assembly language term describing a pseudo-opcode you would use to allocate storage for an uninitialized static array. In modern operating systems like Windows and Linux, the compiler/linker puts all uninitialized variables into a BSS section that simply tells the OS how many bytes to set aside for that section. When the OS loads the program into memory, it reserves sufficient memory for all the objects in the BSS section and fills this range of memory with zeros. Note that the BSS section in the executable file doesn’t contain any actual data, so programs that declare large uninitialized static arrays in a BSS section will consume less disk space. The following is the C/C++ example from the previous section, modified to remove the initializers so that the compiler will place the variables in the BSS section:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdlib.h&gt;<br/>#include &lt;stdio.h&gt;<br/><br/>static char *c;<br/>static int i;<br/>static int j;<br/>static double array[4];<br/><br/>int main( void )<br/>{<br/>      .<br/>      .<br/>      .</pre>&#13;
		<p class="indent">Here is the Visual C++ output:</p>&#13;
		<pre class="programs">&#13;
			_BSS    SEGMENT<br/>?c@@3PEADEA   DQ  01H DUP (?)                             ; c<br/>?i@@3HA       DD  01H DUP (?)                             ; i<br/>?j@@3HA       DD  01H DUP (?)                             ; j<br/>?array@@3PANA DQ  04H DUP (?)                             ; array<br/>_BSS    ENDS</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_179"/>Not all compilers use a BSS section. Many Microsoft languages and linkers, for example, simply combine the uninitialized objects with the static/read-only data section and explicitly give them an initial value of <code>0</code>. Although Microsoft claims that this scheme is faster, it certainly makes executable files larger if your code has large, uninitialized arrays (because each byte of the array winds up in the executable file—something that would not happen if the compiler placed the array in a BSS section). Note, however, that this is a default condition and you can change it by setting the appropriate linker flags.</p>&#13;
		<h4 class="h4" id="ch00lev2sec70"><strong>7.1.4 The Stack Section</strong></h4>&#13;
		<p class="noindent">The stack is a data structure that expands and contracts in response to procedure invocations and returns, among other things. At runtime, the system places all automatic variables (nonstatic local variables), subroutine parameters, temporary values, and other objects in the stack section of memory in a special data structure called the <em>activation record</em> (which is aptly named, as the system creates it when a subroutine first begins execution and deallocates it when the subroutine returns to its caller). Therefore, the stack section in memory is very busy.</p>&#13;
		<p class="indent">Many CPUs implement the stack using a special-purpose register called the <em>stack pointer</em>. Other CPUs (particularly some RISC CPUs) don’t provide an explicit stack pointer, instead using a general-purpose register for stack implementation. If a CPU provides a stack pointer, we say that the CPU supports a <em>hardware stack</em>; if it uses a general-purpose register, then we say that it uses a <em>software-implemented stack</em>. The 80x86 is a good example of a CPU that provides a hardware stack, and the PowerPC family is a good example of a CPU family with a software-implemented stack (most PowerPC programs use R1 as the stack pointer register). The ARM CPU supports a pseudo–hardware stack; it assigns one of the general-purpose registers as the hardware stack pointer but still requires an application to explicitly maintain the stack. Systems that provide hardware stacks can generally manipulate data on the stack using fewer instructions than systems with a software-implemented stack. On the other hand, RISC CPU designers who’ve chosen to use a software stack implementation feel that the presence of a hardware stack actually slows down all instructions the CPU executes. In theory, you could argue that the RISC designers are right; in practice, the 80x86 family includes some of the fastest CPUs around, providing ample proof that having a hardware stack doesn’t necessarily mean you’ll wind up with a slow CPU.</p>&#13;
		<h4 class="h4" id="ch00lev2sec71"><strong>7.1.5 The Heap Section and Dynamic Memory Allocation</strong></h4>&#13;
		<p class="noindent">Although simple programs may need only static and automatic variables, sophisticated programs need to be able to allocate and deallocate storage dynamically under program control. In the C and HLA languages, you would use the <code>malloc()</code> and <code>free()</code> functions for this purpose. C++ provides the <code>new</code> and <code>delete</code> (and <code>std::unique_ptr</code>) operators. Pascal uses <span epub:type="pagebreak" id="page_180"/><code>new</code> and <code>dispose</code>. Java and Swift use <code>new</code> (deallocation is automatic in these languages). Other languages provide comparable routines. These memory allocation routines have a few things in common:</p>&#13;
		<ul>&#13;
			<li>&#13;
				<p class="noindent">They let the programmer request how many bytes of storage to allocate (either by explicitly specifying the number of bytes to allocate or by specifying some data type whose size is known).</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">They return a <em>pointer</em> to the newly allocated storage (that is, the address of that storage).</p>&#13;
				</li>&#13;
			<li>&#13;
				<p class="noindent">They provide a facility for returning the storage space to the system once it is no longer needed so the system can reuse it in a future allocation call.</p>&#13;
				</li>&#13;
		</ul>&#13;
		<p class="indent">Dynamic memory allocation takes place in a section of memory known as the <em>heap</em>. Generally, an application refers to data on the heap using pointer variables, either implicitly or explicitly; some languages, like Java and Swift, implicitly use pointers behind the scenes. Thus, these objects in heap memory are usually referred to as <em>anonymous variables</em> because they are referred to by their memory address (via pointers) rather than by a name.</p>&#13;
		<p class="indent">The OS and application create the heap section in memory after the program begins execution; the heap is never a part of the executable file. Generally, the OS and language runtime libraries maintain the heap for an application. Despite the variations in memory management implementations, it’s a good idea for you to have a basic idea of how heap allocation and deallocation operate, because using them inappropriately will have a very negative impact on your application performance.</p>&#13;
		<h3 class="h3" id="ch00lev1sec64"><strong>7.2 What Is a Variable?</strong></h3>&#13;
		<p class="noindent">If you consider the word <em>variable</em>, it’s obvious that it describes something that <em>varies</em>. But exactly what is it that varies? Most programmers would say that it’s the value that can vary during program execution. In fact, though, there are several things that can vary, so before defining a variable explicitly, we’ll discuss some characteristics that variables (and other objects) may possess.</p>&#13;
		<h4 class="h4" id="ch00lev2sec72"><strong>7.2.1 Attributes</strong></h4>&#13;
		<p class="noindent">An <em>attribute</em> is some feature that is associated with an object. For example, common attributes of a variable include its name, its memory address, its size (in bytes), its runtime value, and a data type associated with that value. Different objects may have different sets of attributes. For example, a data type is an object that has attributes such as a name and size, but it won’t usually have a value or memory location associated with it. A constant can have attributes such as a value and a data type, but it doesn’t have a memory location and it might not have a name (for example, if it’s a literal constant). A variable may possess all of these attributes. Indeed, the attribute list usually determines whether an object is a constant, data type, variable, or something else.</p>&#13;
		<h4 class="h4" id="ch00lev2sec73"><span epub:type="pagebreak" id="page_181"/><strong>7.2.2 Binding</strong></h4>&#13;
		<p class="noindent"><em>Binding</em>, introduced in <a href="ch06.xhtml#ch06">Chapter 6</a>, is the process of associating an attribute with an object. For example, when a value is assigned to a variable, the value is bound to that variable at the point of the assignment. This bond remains until some other value is bound to the variable (via another assignment operation). Likewise, if you allocate memory for a variable while the program is running, the variable is bound to the memory address at that point. The variable and address are bound until you associate a different address with the variable. Binding needn’t occur at runtime. For example, values are bound to constant objects during compilation, and these bonds cannot change while the program is running. Similarly, addresses are bound to some variables at compile time, and those memory addresses cannot change during program execution (see “Binding Times” on <a href="ch06.xhtml#page_150">page 150</a> for more details).</p>&#13;
		<h4 class="h4" id="ch00lev2sec74"><strong>7.2.3 Static Objects</strong></h4>&#13;
		<p class="noindent"><em>Static</em> objects have an attribute bound to them prior to the application’s execution. Constants are good examples of static objects; they have the same value bound to them throughout program execution.<sup><a id="ch7fn_1"/><a href="footnotes.xhtml#ch7fn1">1</a></sup> Global (program-level) variables in programming languages like Pascal, C/C++, and Ada are also examples of static objects because they have the same memory address bound to them throughout the program’s lifetime. The system binds attributes to a static object before the program begins execution (usually during compilation, linking, or even loading, though it is possible to bind values even earlier).</p>&#13;
		<h4 class="h4" id="ch00lev2sec75"><strong>7.2.4 Dynamic Objects</strong></h4>&#13;
		<p class="noindent"><em>Dynamic</em> objects have some attribute bound to them during program execution. While it is running, the program may choose to change that attribute (<em>dynamically</em>). Dynamic attributes usually cannot be determined at compile time. Examples of dynamic attributes include values bound to variables at runtime and memory addresses bound to certain variables at runtime (for example, via a <code>malloc()</code> or other memory allocation function call).</p>&#13;
		<h4 class="h4" id="ch00lev2sec76"><strong>7.2.5 Scope</strong></h4>&#13;
		<p class="noindent">The <em>scope</em> of an identifier is the section of the program where the identifier’s name is bound to the object. Because names in most compiled languages exist only during compilation, scope is usually a static attribute (although in some languages it can be dynamic, as I’ll explain shortly). By controlling where a name is bound to an object, you can reuse that name elsewhere in the program.</p>&#13;
		<p class="indent">Most modern programming languages (such as C/C++/C#, Java, Pascal, Swift, and Ada) support the concept of <em>local</em> and <em>global</em> variables. A local <span epub:type="pagebreak" id="page_182"/>variable’s name is bound to a particular object only within a given section of a program (for example, within a particular function). Outside the scope of that object, the name can be bound to a different object. This allows a global and a local object to share the same name without any ambiguity. This may seem potentially confusing, but being able to reuse variable names like <code>i</code> or <code>j</code> throughout a project can spare you from having to dream up equally meaningless unique variable names for loop indexes and other uses in the program. The scope of the object’s declaration determines where the name applies to a given object.</p>&#13;
		<p class="indent">In interpretive languages, where the interpreter maintains the identifier names during program execution, scope can be a dynamic attribute. For example, in various versions of the BASIC programming language, <code>dim</code> is an executable statement. Before you execute <code>dim</code>, the name you define might have a completely different meaning than it does after you execute <code>dim</code>. SNOBOL4 is another language that supports dynamic scope. Still, most programming languages avoid dynamic scope because using it can result in difficult-to-understand programs.</p>&#13;
		<p class="indent">Technically, scope can apply to any attribute, not just names, but this book will use the term only in contexts where a name is bound to a given variable.</p>&#13;
		<h4 class="h4" id="ch00lev2sec77"><strong>7.2.6 Lifetime</strong></h4>&#13;
		<p class="noindent">The <em>lifetime</em> of an attribute extends from the point when you first bind an attribute to an object to the point you break that bond, perhaps by binding a different attribute to the object. If the program associates some attribute with an object and never breaks that bond, the lifetime of the attribute is from the point of association to the point the program terminates. For example, the lifetime of a variable is from the time you first allocate memory for the variable to the moment you deallocate that variable’s storage. Because a program binds static objects prior to execution (and static attributes do not change during program execution), the lifetime of a static object extends from when the program begins execution to when it terminates.</p>&#13;
		<h4 class="h4" id="ch00lev2sec78"><strong>7.2.7 Variable Definition</strong></h4>&#13;
		<p class="noindent">To return to the question that started this section, we can now define <em>variable</em> as an object that can have a value bound to it dynamically. That is, the program can change the variable’s value attribute at runtime. Note the operative word <em>can</em>. It is necessary only for the program <em>to be able</em> to change a variable’s value at runtime; it doesn’t <em>have</em> to do so for the object to be considered a variable.</p>&#13;
		<p class="indent">While dynamic binding of a value to an object is the defining attribute of a variable, other attributes may be dynamic or static. For example, the memory address of a variable can be statically bound to the variable at compile time or dynamically bound at runtime. Likewise, variables in some languages have dynamic types that change during program execution, while other variables have static types that remain fixed over an application’s execution. Only the binding of the value determines whether the object is a variable or something else (such as a constant).</p>&#13;
		<h3 class="h3" id="ch00lev1sec65"><span epub:type="pagebreak" id="page_183"/><strong>7.3 Variable Storage</strong></h3>&#13;
		<p class="noindent">Values must be stored in and retrieved from memory.<sup><a id="ch7fn_2"/><a href="footnotes.xhtml#ch7fn2">2</a></sup> To do this, a compiler must bind a variable to one or more memory locations. The variable’s type determines the amount of storage it requires. Character variables may require as little as a single byte of storage, while large arrays or records can require thousands, millions, or more. To associate a variable with some memory, a compiler (or runtime system) binds the address of that memory location to that variable. When a variable requires two or more memory locations, the system usually binds the address of the first memory location to the variable and assumes that the contiguous locations following that address are also bound to the variable at runtime.</p>&#13;
		<p class="indent">Three types of bindings are possible between variables and memory locations: static binding, pseudo-static (automatic) binding, and dynamic binding. Variables are generally classified as static, automatic, or dynamic based upon how they are bound to their memory locations.</p>&#13;
		<h4 class="h4" id="ch00lev2sec79"><strong>7.3.1 Static Binding and Static Variables</strong></h4>&#13;
		<p class="noindent">Static binding occurs prior to runtime, at one of four possible times: at language design time, at compile time, at link time, or when the system loads the application into memory (but prior to execution). Binding at language design time is not all that common, but it does occur in some languages (especially assembly languages). Binding at compile time is common in assemblers and compilers that directly produce executable code. Binding at link time is fairly common (for example, some Windows compilers do this). Binding at load time, when the OS copies the executable into memory, is probably the most common for static variables. We’ll look at each possibility in turn.</p>&#13;
		<h5 class="h5" id="ch00lev3sec41"><strong>7.3.1.1 Binding at Language Design Time</strong></h5>&#13;
		<p class="noindent">An address can be assigned at language design time when a language designer associates a language-defined variable with a specific hardware address (for example, an I/O device or a special kind of memory), and that address never changes in any program. Such objects are common in embedded systems and rarely found in applications on general-purpose computer systems. For example, on an 8051 microcontroller, many C compilers and assemblers automatically associate certain names with fixed locations in the 128 bytes of data space found on the CPU. CPU register references in assembly language are good examples of variables bound to some location at language design time.</p>&#13;
		<h5 class="h5" id="ch00lev3sec42"><strong>7.3.1.2 Binding at Compile Time</strong></h5>&#13;
		<p class="noindent">An address can be assigned at compile time when the compiler knows the memory region where it can place static variables at runtime. Generally, <span epub:type="pagebreak" id="page_184"/>such compilers generate absolute machine code that must be loaded at a specific address in memory prior to execution. Most modern compilers generate relocatable code and, therefore, don’t fall into this category. Nevertheless, lower-end compilers, high-speed student compilers, and compilers for embedded systems often use this binding technique.</p>&#13;
		<h5 class="h5" id="ch00lev3sec43"><strong>7.3.1.3 Binding at Link Time</strong></h5>&#13;
		<p class="noindent">Certain linkers and related tools can link together various relocatable object modules of an application and create an absolute load module. So, while the compiler produces relocatable code, the linker binds memory addresses to the variables (and machine instructions). Usually, the programmer specifies (via command-line parameters or a linker script file) the base address of all the static variables in the program; the linker will bind the static variables to consecutive addresses starting at the base address. Programmers who are placing their applications in read-only memory (ROM), such as a BIOS (Basic Input/Output System) ROM for a PC, often employ this scheme.</p>&#13;
		<h5 class="h5" id="ch00lev3sec44"><strong>7.3.1.4 Binding at Load Time</strong></h5>&#13;
		<p class="noindent">The most common form of static binding occurs at load time. Executable formats such as Microsoft’s PE/COFF and Linux’s ELF usually embed relocation information in the executable file. The OS, when it loads the application into memory, decides where to place the block of static variable objects and then patches all the addresses within instructions that reference those static objects. This allows the loader (for example, the OS) to assign a different address to a static object each time it loads it into memory.</p>&#13;
		<h5 class="h5" id="ch00lev3sec45"><strong>7.3.1.5 Static Variable Binding</strong></h5>&#13;
		<p class="noindent">A static variable has a memory address bound to it prior to program execution, and enjoys a couple of advantages over other variable types. Because the compiler knows a static variable’s address prior to runtime, it can often use an <em>absolute addressing mode</em> or some other simple addressing mode to access that variable. Static variable access is often more efficient than other variable accesses because it doesn’t require any additional setup.<sup><a id="ch7fn_3"/><a href="footnotes.xhtml#ch7fn3">3</a></sup></p>&#13;
		<p class="indent">Another benefit of static variables is that they retain any value bound to them until you explicitly bind another value or until the program terminates. This means that static variables retain values while other events (such as procedure activation and deactivation) occur. Different threads in a multithreaded application can also share data using static variables.</p>&#13;
		<p class="indent">Static variables also have a few disadvantages worth mentioning. First of all, because the lifetime of a static variable matches that of the program, <span epub:type="pagebreak" id="page_185"/>it consumes memory the entire time the program is running. This is true even if the program no longer requires the value held by the static object.</p>&#13;
		<p class="indent">Another disadvantage to static variables (particularly when using the absolute addressing mode) is that the entire absolute address must usually be encoded as part of the instruction, which makes the instruction much larger. Indeed, on most RISC processors an absolute addressing mode isn’t even available because you cannot encode an absolute address in a single instruction.</p>&#13;
		<p class="indent">Finally, code that uses static objects is not <em>reentrant</em> (meaning two threads or processes can concurrently execute the same code sequence); this means more effort is required to use that code in a multithreaded environment (where two copies of a section of code could be executing simultaneously, both accessing the same static object). However, multithreaded operation introduces a lot of complexity that is beyond the scope of this chapter, so we’ll ignore this issue for now.</p>&#13;
		<div class="note">&#13;
			<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
			<p class="notep"><em>See any good textbook on operating system design or concurrent programming for more details concerning the use of static objects.</em> Foundations of Multithreaded, Parallel, and Distributed Programming <em>by Gregory R. Andrews (Addison-Wesley, 1999) is a good place to start.</em></p>&#13;
		</div>&#13;
		<p class="indent">The following example demonstrates the use of static variables in a C program and shows the 80x86 code that the Visual C++ compiler generates to access them:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>static int i = 5;<br/>static int j = 6;<br/><br/>int main( int argc, char **argv)<br/>{<br/><br/>    i = j + 3;<br/>    j = i + 2;<br/>    printf( "%d %d\n", i, j );<br/>    return 0;<br/>}<br/><br/><br/><br/>; The following are the memory declarations<br/>; for the 'i' and 'j' variables. Note that<br/>; these are declared in the global '_DATA'<br/>; section.<br/><br/>_DATA   SEGMENT<br/>i       DD      05H<br/>j       DD      06H<br/>$SG6835 DB      '%d %d', 0aH, 00H<br/>_DATA   ENDS<br/><span epub:type="pagebreak" id="page_186"/>main    PROC<br/>; File c:\users\rhyde\test\t\t\t.cpp<br/>; Line 8<br/>;<br/>;    int main( int argc, char **argv)<br/>;    {<br/>$LN3:<br/>        mov     QWORD PTR [rsp+16], rdx<br/>        mov     DWORD PTR [rsp+8], ecx<br/>        sub     rsp, 40                                 ; 00000028H<br/>; Line 10<br/>;<br/>;            i = j + 3;<br/>;<br/>; Load the EAX register with the<br/>; current value of the global j<br/>; variable using the displacement-only<br/>; addressing mode, add three to the<br/>; value, and store back into 'i':<br/><br/>        mov     eax, DWORD PTR j<br/>        add     eax, 3<br/>        mov     DWORD PTR i, eax<br/><br/>; Line 11<br/>;<br/>;            j = i + 2;<br/>;<br/>        mov     eax, DWORD PTR i<br/>        add     eax, 2<br/>        mov     DWORD PTR j, eax<br/><br/>; Line 12<br/>; Load i, j, and format string into appropriate registers<br/>; and call printf:<br/><br/>        mov     r8d, DWORD PTR j<br/>        mov     edx, DWORD PTR i<br/>        lea     rcx, OFFSET FLAT:$SG6835<br/>        call    printf<br/>; Line 13<br/>;<br/>; RETURN 0<br/><br/>        xor     eax, eax<br/>; Line 14<br/>        add     rsp, 40                                 ; 00000028H<br/>        ret     0<br/>main    ENDP<br/>_TEXT   ENDS</pre>&#13;
		<p class="indent">As the comments point out, the assembly language code the compiler emits uses the displacement-only addressing mode to access all the static variables.</p>&#13;
		<h4 class="h4" id="ch00lev2sec80"><span epub:type="pagebreak" id="page_187"/><strong>7.3.2 Pseudo-Static Binding and Automatic Variables</strong></h4>&#13;
		<p class="noindent">Automatic variables have an address bound to them when a procedure or other block of code begins execution. The program releases that storage when the block or procedure completes execution. We call these objects <em>automatic</em> variables because the runtime code automatically allocates and deallocates storage for them, as needed.</p>&#13;
		<p class="indent">In most programming languages, automatic variables use a combination of static and dynamic binding known as <em>pseudo-static binding</em>. The compiler assigns an offset from a base address to a variable name during compilation. At runtime the offset always remains fixed, but the base address can vary. For example, a procedure or function allocates storage for a block of local variables (the activation record, introduced earlier in the chapter) and then accesses the local variables at fixed offsets from the start of that block of storage. Although the program cannot determine the final memory address of the variable until runtime, the compiler can select an offset that never changes during program execution, hence the name <em>pseudo-static</em>.</p>&#13;
		<p class="indent">Some programming languages use the term <em>local variables</em> in place of automatic variables. A local variable’s name is statically bound to a given procedure or block (that is, the scope of the name is limited to that procedure or block of code). Therefore, <em>local</em> is a static attribute in this context. It’s easy to see why the terms <em>local variable</em> and <em>automatic variable</em> are often confused. In some programming languages, such as Pascal, local variables are always automatic variables and vice versa. Nonetheless, always keep in mind that <em>local</em> is a static attribute and <em>automatic</em> is a dynamic one.<sup><a id="ch7fn_4"/><a href="footnotes.xhtml#ch7fn4">4</a></sup></p>&#13;
		<p class="indent">Automatic variables have a couple of important advantages. First, they consume storage only while the procedure or block containing them is executing. This allows multiple blocks and procedures to share the same pool of memory for their automatic variable needs. Although some extra code must execute in order to manage automatic variables (in the activation record), this requires only a few machine instructions on most CPUs and has to be done only once for each procedure/block entry and exit. While in certain circumstances, the cost can be significant, the extra time and space needed to set up and tear down the activation record is usually inconsequential. Another advantage of automatic variables is that they often use a <em>base-plus-offset</em> addressing mode, where the base of the activation record is kept in a register and the offsets into the activation record are small—often 256 bytes or fewer. Therefore, CPUs don’t have to encode a full 32-bit (for example) address as part of the machine instruction—just an 8-bit (or other small) displacement, yielding shorter instructions. It’s also worth noting that automatic variables are “thread-safe” and code that uses automatic variables can be reentrant. This is because each thread maintains its own stack space (or similar data structure) where compilers maintain automatic <span epub:type="pagebreak" id="page_188"/>variables; therefore, each thread will have its own copy of any automatic variables the program uses.</p>&#13;
		<p class="indent">Automatic variables do have some disadvantages, though. If you want to initialize an automatic variable, you have to use machine instructions to do so. You can’t initialize an automatic variable, as you can static variables, when the program loads into memory. Also, any values maintained in automatic variables are lost whenever you exit the block or procedure containing them. As noted, automatic variables require a small amount of overhead; some machine instructions must execute in order to build and destroy the activation record containing those variables.</p>&#13;
		<p class="indent">Here’s a short C example that uses automatic variables and the 80x86 assembly code that the Microsoft Visual C++ compiler produces for it:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>int main( int argc, char **argv)<br/>{<br/><br/>    int i;<br/>    int j;<br/><br/>    j = 1;<br/>    i = j + 3;<br/>    j = i + 2;<br/>    printf( "%d %d\n", i, j );<br/>    return 0;<br/>}<br/><br/><br/>; Data emitted for the string constant<br/>; in the printf function call:<br/><br/>CONST   SEGMENT<br/>$SG6917 DB      '%d %d', 0aH, 00H<br/>CONST   ENDS<br/><br/><br/>PUBLIC  _main<br/>EXTRN   _printf:NEAR<br/>; Function compile flags: /Ods<br/><br/>_TEXT   SEGMENT<br/>j$ = 32<br/>i$ = 36<br/>argc$ = 64<br/>argv$ = 72<br/>main    PROC<br/>; File c:\users\rhyde\test\t\t\t.cpp<br/>; Line 5<br/>$LN3:<br/>        mov     QWORD PTR [rsp+16], rdx<br/>        mov     DWORD PTR [rsp+8], ecx<br/><span epub:type="pagebreak" id="page_189"/>        sub     rsp, 56                                 ; 00000038H<br/>; Line 10<br/>        mov     DWORD PTR j$[rsp], 1<br/>; Line 11<br/>        mov     eax, DWORD PTR j$[rsp]<br/>        add     eax, 3<br/>        mov     DWORD PTR i$[rsp], eax<br/>; Line 12<br/>        mov     eax, DWORD PTR i$[rsp]<br/>        add     eax, 2<br/>        mov     DWORD PTR j$[rsp], eax<br/>; Line 13<br/>        mov     r8d, DWORD PTR j$[rsp]<br/>        mov     edx, DWORD PTR i$[rsp]<br/>        lea     rcx, OFFSET FLAT:$SG6917<br/>        call    printf<br/>; Line 14<br/>        xor     eax, eax<br/>; Line 15<br/>        add     rsp, 56                                 ; 00000038H<br/>        ret     0<br/>main    ENDP<br/>_TEXT   ENDS</pre>&#13;
		<p class="indent">Note that when accessing automatic variables, the assembly code uses a <em>base-plus-displacement</em> addressing mode (for example, <code>j$[rsp]</code>). This addressing mode is often shorter than the displacement-only or RIP-relative addressing mode that static variables use (assuming, of course, that the offset to the automatic object is within 127 bytes of the base address held in RSP).<sup><a id="ch7fn_5"/><a href="footnotes.xhtml#ch7fn5">5</a></sup></p>&#13;
		<h4 class="h4" id="ch00lev2sec81"><strong>7.3.3 Dynamic Binding and Dynamic Variables</strong></h4>&#13;
		<p class="noindent">A dynamic variable has storage bound to it at runtime. In some languages, the application programmer is completely responsible for binding addresses to dynamic objects; in other languages, the runtime system automatically allocates and deallocates storage for a dynamic variable.</p>&#13;
		<p class="indent">Dynamic variables are generally allocated on the heap via a memory allocation function such as <code>malloc()</code> or <code>new()</code> (or <code>std::unique_ptr</code>). The compiler has no way of determining the runtime address of a dynamic object, so the program must always refer to a dynamic object indirectly—that is, by using a pointer.</p>&#13;
		<p class="indent">The big advantage to dynamic variables is that the application controls their lifetimes. Dynamic variables consume storage only as long as necessary, and the runtime system can reclaim that storage when the variable no longer requires it. Unlike automatic variables, the lifetime of a dynamic <span epub:type="pagebreak" id="page_190"/>variable is not tied to the lifetime of some other object, such as a procedure or code block entry and exit. Memory is bound to a dynamic variable at the point the variable first needs it, and can be released when the variable no longer needs it. For variables that require considerable storage, then, dynamic allocation can make efficient use of memory.</p>&#13;
		<p class="indent">Another advantage to dynamic variables is that most code references dynamic objects using a pointer. If that pointer value is already sitting in a CPU register, the program can usually reference that data using a short machine instruction, requiring no extra bits to encode an offset or address.</p>&#13;
		<p class="indent">Dynamic variables have several disadvantages as well. First, some storage overhead is often necessary to maintain them. Static and automatic objects usually don’t require extra storage; the runtime system, on the other hand, often requires some number of bytes to keep track of each dynamic variable in the system. This overhead ranges anywhere from 4 or 8 bytes to many dozens of bytes (in an extreme case) and keeps track of things like the current memory address of the object, the size of the object, and its type. If you’re allocating small objects, like integers or characters, the amount of storage required for bookkeeping purposes could exceed the storage required for the actual data. Also, since most languages reference dynamic objects using pointer variables, those pointers require some additional storage above and beyond the actual storage for the dynamic data.</p>&#13;
		<p class="indent">Another problem with dynamic variables is performance. Because dynamic data is usually found in memory, the CPU has to access memory (which is slower than cached memory) on nearly every dynamic variable access. Even worse, accessing dynamic data often requires two memory accesses—one to fetch the pointer’s value and one to fetch the dynamic data, indirectly through the pointer. Managing the heap, where the runtime system keeps the dynamic data, can also impact performance. Whenever an application requests storage for a dynamic object, the runtime system has to search for a contiguous block of free memory large enough to satisfy the request. This search operation can be computationally expensive, depending on the heap’s organization (which affects the amount of overhead storage associated with each dynamic variable). Furthermore, when releasing a dynamic object, the runtime system may need to execute some code in order to free up that storage for use by other dynamic objects. These runtime heap allocation and deallocation operations are usually far more expensive than allocating and deallocating a block of automatic variables during procedure entry/exit.</p>&#13;
		<p class="indent">Another consideration with dynamic variables is that some languages (such as Pascal and C/C++<sup><a id="ch7fn_6"/><a href="footnotes.xhtml#ch7fn6">6</a></sup>) require the application programmer to explicitly allocate and deallocate storage for dynamic variables. Without automatic allocation and deallocation, defects due to human error can creep into the code. This is why languages such as C#, Java, and Swift attempt to handle dynamic allocation automatically, even though this process can be slower.</p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_191"/>Here’s a short example in C that demonstrates the kind of code that the Microsoft Visual C++ compiler generates in order to access dynamic objects allocated with <code>malloc()</code>.</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdlib.h&gt;<br/>#include &lt;stdio.h&gt;<br/><br/><br/>int main( int argc, char **argv)<br/>{<br/><br/>    int *i;<br/>    int *j;<br/><br/><br/>    i = (int *) malloc( sizeof( int ) );<br/>    j = (int *) malloc( sizeof( int ) );<br/>    *i = 1;<br/>    *j = 2;<br/>    printf( "%d %d\n", *i, *j );<br/>    free( i );<br/>    free( j );<br/>    return 0;<br/>}</pre>&#13;
		<p class="indent">Here’s the machine code the compiler generates, including (manually inserted) comments that describe the extra work needed to access dynamically allocated objects:</p>&#13;
		<pre class="programs">&#13;
			_DATA   SEGMENT<br/>$SG6837 DB      '%d %d', 0aH, 00H<br/>_DATA   ENDS<br/>PUBLIC  _main<br/>_TEXT   SEGMENT<br/>i$ = 32<br/>j$ = 40<br/>argc$ = 64<br/>argv$ = 72<br/>main    PROC<br/>; File c:\users\rhyde\test\t\t\t.cpp<br/>; Line 7 // Construct the activation record<br/>$LN3:<br/><br/>        mov     QWORD PTR [rsp+16], rdx<br/>        mov     DWORD PTR [rsp+8], ecx<br/>        sub     rsp, 56                                 ; 00000038H<br/><br/>; Line 13<br/>; Call malloc and store the returned<br/>; pointer value into the i variable:<br/><br/>        mov     ecx, 4<br/>        call    malloc<br/>        mov     QWORD PTR i$[rsp], rax<br/><br/><span epub:type="pagebreak" id="page_192"/>; Line 14<br/>; Call malloc and store the returned<br/>; pointer value into the j variable:<br/><br/>        mov     ecx, 4<br/>        call    malloc<br/>        mov     QWORD PTR j$[rsp], rax<br/><br/>; Line 15<br/>; Store 1 into the dynamic variable pointed<br/>; at by i. Note that this requires two<br/>; instructions.<br/><br/>        mov     rax, QWORD PTR i$[rsp]<br/>        mov     DWORD PTR [rax], 1<br/><br/>; Line 16<br/>; Store 2 into the dynamic variable pointed<br/>; at by j. This also requires two instructions.<br/><br/>        mov     rax, QWORD PTR j$[rsp]<br/>        mov     DWORD PTR [rax], 2<br/><br/>; Line 17<br/>; Call printf to print the dynamic variables'<br/>; values:<br/><br/>        mov     rax, QWORD PTR j$[rsp]<br/>        mov     r8d, DWORD PTR [rax]<br/>        mov     rax, QWORD PTR i$[rsp]<br/>        mov     edx, DWORD PTR [rax]<br/>        lea     rcx, OFFSET FLAT:$SG6837<br/>        call    printf<br/><br/>; Line 18<br/>; Free the two variables<br/>;<br/>        mov     rcx, QWORD PTR i$[rsp]<br/>        call    free<br/>; Line 19<br/>        mov     rcx, QWORD PTR j$[rsp]<br/>        call    free<br/><br/>; Line 20<br/>; Return a function result of zero:<br/>        xor     eax, eax<br/>; Line 21<br/>        add     rsp, 56                                 ; 00000038H<br/>        ret     0<br/>main    ENDP<br/>_TEXT   ENDS<br/>END</pre>&#13;
		<p class="indent">As you can see, accessing dynamically allocated variables via a pointer requires a lot of extra work.</p>&#13;
		<h3 class="h3" id="ch00lev1sec66"><span epub:type="pagebreak" id="page_193"/><strong>7.4 Common Primitive Data Types</strong></h3>&#13;
		<p class="noindent">Computer data always has a data type attribute that describes how the program interprets that data. The data type also determines the size (in bytes) of the data in memory. Data types can be divided into two categories: <em>primitive data types</em>, which the CPU can hold in a CPU register and operate upon directly, and <em>composite data types</em>, which are composed of smaller primitive data types. In the following sections we’ll review (from <em>WGC1</em>) the primitive data types found on most modern CPUs, and in the next chapter I’ll begin discussing composite data types.</p>&#13;
		<h4 class="h4" id="ch00lev2sec82"><strong>7.4.1 Integer Variables</strong></h4>&#13;
		<p class="noindent">Most programming languages provide some mechanism for storing integer values in memory variables. In general, a programming language uses either unsigned binary representation, two’s-complement representation, or binary-coded decimal representation (or a combination of these) to represent integer values.</p>&#13;
		<p class="indent">Perhaps the most fundamental property of an integer variable in a programming language is the number of bits allocated to represent that integer value. In most modern programming languages, the number of bits used to represent an integer value is usually 8, 16, 32, 64, or some other power of two. Many languages provide only a single size for representing integers, but some languages let you select from several different sizes. You choose the size based on the range of values you want to represent, the amount of memory you want the variable to consume, and the performance of arithmetic operations involving that value. <a href="ch07.xhtml#ch7tab1">Table 7-1</a> lists some common sizes and ranges for various signed, unsigned, and decimal integer variables.</p>&#13;
		<p class="indent">Not all languages support all of these different sizes (indeed, to support all of them in the same program, you’d probably have to use assembly language). As noted earlier, some languages provide only a single size, which is usually the processor’s native integer size (that is, the size of a CPU general-purpose integer register).</p>&#13;
		<p class="indent">Languages that do provide multiple integer sizes often don’t give you an explicit selection of sizes from which to choose. For example, the C programming language provides up to five different integer sizes: <code>char</code> (which is always 1 byte), <code>short</code>, <code>int</code>, <code>long</code>, and <code>long long</code>. With the exception of the <code>char</code> type, C does not specify the sizes of these integer types other than to state that <code>short</code> integers are less than or equal to <code>int</code> objects in size, <code>int</code> objects are less than or equal to <code>long</code> integers in size, and <code>long</code> integers are less than or equal to <code>long long</code> integers in size. (In fact, all four could be the same size.) C programs that depend on integers being a certain size may fail when compiled with different compilers that don’t use the same sizes as the original compiler.</p>&#13;
		<div class="note">&#13;
			<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
			<p class="notep"><em>C99 and C++11 include types of exact sizes: <span class="codeitalic">int8_t</span>, <span class="codeitalic">int16_t</span>, <span class="codeitalic">int32_t</span>, <span class="codeitalic">int64_t</span>, and so on.</em></p>&#13;
		</div>&#13;
		<p class="tabcap" id="ch7tab1"><span epub:type="pagebreak" id="page_194"/><strong>Table 7-1:</strong> Common Integer Sizes and Their Ranges</p>&#13;
		<table class="all">&#13;
			<colgroup>&#13;
				<col style="width:20%"/>&#13;
				<col style="width:30%"/>&#13;
				<col style="width:50%"/>&#13;
			</colgroup>&#13;
			<tbody>&#13;
				<tr>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>Size, in bits</strong></p>&#13;
					</td>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>Representation</strong></p>&#13;
					</td>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>Unsigned range</strong></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">8</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Unsigned</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><code>0..255</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Signed</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><code>-128..+127</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Decimal</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><code>0..99</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">16</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">Unsigned</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><code>0..65,536</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">Signed</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><code>-32768..+32,767</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">Decimal</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><code>0..9999</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">32</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Unsigned</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><code>0..4,294,967,295</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Signed</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><code>-2,147,483,648..+2,147,483,647</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Decimal</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><code>0..99999999</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">64</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">Unsigned</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><code>0..18,466,744,073,709,551,615</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">Signed</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><code>-9,223,372,036,854,775,808..<br/>+9,223,372,036,854,775,807</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">Decimal</p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><code>0..9999999999999999</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">128</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Unsigned</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><code>0..340,282,366,920,938,463,563,374,607,431,768,211,455</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Signed</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><code>-170,141,183,460,469,231,731,687,303,715,884,105,728..<br/>+170,141,183,460,469,231,731,687,303,715,884,105,727</code></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"> </p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table">Decimal</p>&#13;
					</td>&#13;
					<td class="table-1b" style="vertical-align: top;">&#13;
						<p class="table"><code>0..99999999999999999999999999999999</code></p>&#13;
					</td>&#13;
				</tr>&#13;
			</tbody>&#13;
		</table>&#13;
		<p class="indent">While it may seem inconvenient that various programming languages avoid specifying an exact size for an integer variable, keep in mind that this ambiguity is intentional. When you declare an “integer” variable in a given programming language, the language leaves it up to the compiler’s implementer to choose the <em>best</em> size for that integer, based on performance and other considerations. The definition of “best” may change based on the CPU for which the compiler generates code. For example, a compiler for a 16-bit processor may choose to implement 16-bit integers because the CPU processes them most efficiently. A compiler for a 32-bit processor, however, may choose to implement 32-bit integers (for the same reason). Languages that specify the exact size of various integer formats (such as Java) can suffer as processor technology evolves and it becomes more efficient to process larger data objects. For example, when the world switched from 16-bit processors to 32-bit processors in general-purpose computer systems, it was actually faster to do 32-bit arithmetic on most of the newer processors. Therefore, compiler writers redefined <em>integer</em> to mean “32-bit integer” in order to maximize the performance of programs employing integer arithmetic.</p>&#13;
		<p class="indent">Some programming languages provide support for unsigned integer variables as well as signed integers. At first glance, it might seem that the whole purpose behind supporting unsigned integers is to provide twice the number of positive values when negative values aren’t required. In fact, there are many other reasons great programmers might choose unsigned over signed integers when writing efficient code.</p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_195"/>The Swift programming language gives you explicit control over the size of integers. Swift provides 8-bit (signed) integers (<code>Int8</code>), 16-bit integers (<code>Int16</code>), 32-bit integers (<code>Int32</code>), and 64-bit integers (<code>Int64</code>). Swift also provides an <code>Int</code> type that’s either 32 bits or 64 bits depending on the native (most efficient) integer format for the underlying CPU. Swift further provides 8-bit unsigned integers (<code>UInt8</code>), 16-bit unsigned integers (<code>UInt16</code>), 32-bit unsigned integers (<code>UInt32</code>), 64-bit unsigned integers (<code>UInt64</code>), and a generic <code>UInt</code> type whose size is determined by the native CPU size.</p>&#13;
		<p class="indent">On some CPUs, unsigned integer multiplication and division are faster than their signed counterparts. You can compare values within the range <code>0..<span class="codeitalic1">n</code></span> more efficiently using unsigned integers rather than signed integers (the unsigned case requires only a single comparison against <span class="codeitalic">n</span>); this is especially important when checking bounds of array indices where the array’s element index begins at <code>0</code>.</p>&#13;
		<p class="indent">Many programming languages allow you to include variables of different sizes within the same arithmetic expression. The compiler automatically sign-extends or zero-extends operands to the larger size within an expression as needed to compute the final result. The problem with this automatic conversion is that it hides the fact that extra work is required to process the expression, and the expressions themselves don’t explicitly show this. An assignment statement such as:</p>&#13;
		<pre class="programs">x = y + z - t;</pre>&#13;
		<p class="noindent">could be a short sequence of machine instructions if the operands are all the same size, or it could require some additional instructions if the operands have different sizes. For example, consider the following C code:</p>&#13;
		<pre class="programs">&#13;
			#include &lt;stdio.h&gt;<br/><br/>static char c;<br/>static short s;<br/>static long l;<br/><br/>static long a;<br/>static long b;<br/>static long d;<br/><br/>int main( int argc, char **argv)<br/>{<br/><br/>    l = l + s + c;<br/>    printf( "%ld %hd %hhd\n", l, s, c );<br/><br/>    a = a + b + d;<br/>    printf( "%ld %ld %ld\n", a, b, d );<br/><br/>    return 0;<br/>}</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_196"/>Compiling it with the Visual C++ compiler gives the following two assembly language sequences for the two assignment statements:</p>&#13;
		<pre class="programs">&#13;
			;            l = l + s + c;<br/>;<br/>        movsx   eax, WORD PTR s<br/>        mov     ecx, DWORD PTR l<br/>        add     ecx, eax<br/>        mov     eax, ecx<br/>        movsx   ecx, BYTE PTR c<br/>        add     eax, ecx<br/>        mov     DWORD PTR l, eax<br/>;<br/>;            a = a + b + d;<br/>;<br/>        mov     eax, DWORD PTR b<br/>        mov     ecx, DWORD PTR a<br/>        add     ecx, eax<br/>        mov     eax, ecx<br/>        add     eax, DWORD PTR d<br/>        mov     DWORD PTR a, eax</pre>&#13;
		<p class="indent">As you can see, the statement that operates on variables whose sizes are all the same uses fewer instructions than the one that mixes operand sizes in the expression.</p>&#13;
		<p class="indent">When using different-sized integers in an expression, it’s also important to note that not all CPUs support all operand sizes equally efficiently. While it makes sense that using an integer size larger than the CPU’s general-purpose integer registers will produce inefficient code, it might not be quite as obvious that using <em>smaller</em> integer values can be inefficient as well. Many RISC CPUs work only on operands that are exactly the same size as the general-purpose registers. Smaller operands must first be zero-extended or sign-extended to the size of a general-purpose register prior to any calculations involving those values. Even on CISC processors, such as the 80x86, that have hardware support for different sizes of integers, using certain sizes can be more expensive. For example, under 32-bit operating systems, instructions that manipulate 16-bit operands require an extra <em>opcode prefix byte</em> and are therefore larger than instructions that operate on 8-bit or 32-bit operands.</p>&#13;
		<h4 class="h4" id="ch00lev2sec83"><strong>7.4.2 Floating-Point/Real Variables</strong></h4>&#13;
		<p class="noindent">Like integers, many HLLs provide multiple floating-point variable sizes. Most languages provide at least two different sizes: a 32-bit single-precision floating-point format and a 64-bit double-precision floating-point format, based on the IEEE 754 floating-point standard. A few languages provide 80-bit floating-point variables (Swift is a good example), based on Intel’s 80-bit extended-precision floating-point format, but that usage is increasingly rare. The later ARM processors support quad-precision floating-point arithmetic (128-bit); some variants of GCC support a <code>_float128</code> type that uses quad-precision arithmetic.</p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_197"/>Different floating-point formats trade off space and performance for precision. Calculations involving smaller floating-point formats are usually quicker than calculations involving the larger formats. However, you give up precision to achieve improved performance and size savings (see <a href="ch04.xhtml#ch04">Chapter 4</a> of <em>WGC1</em> for the details).</p>&#13;
		<p class="indent">As with expressions involving integer arithmetic, you should avoid mixing different-sized floating-point operands in an expression. The CPU (or FPU) must convert all floating-point values to the same format before using them. This can involve additional instructions (consuming more memory) and additional time. Therefore, you should try to use the same floating-point types throughout an expression wherever possible.</p>&#13;
		<p class="indent">Conversion between integer and floating-point formats is another expensive operation you should avoid. Modern HLLs attempt to keep variables’ values in registers as much as possible. Unfortunately, on some modern CPUs it’s impossible to move data between the integer and floating-point registers without first copying that data to memory (which is expensive, because memory is slow). Furthermore, conversion between integer and floating-point numbers often involves several specialized instructions, all of which consume time and memory. Whenever possible, avoid these conversions.</p>&#13;
		<h4 class="h4" id="ch00lev2sec84"><strong>7.4.3 Character Variables</strong></h4>&#13;
		<p class="noindent">Standard character data in most modern HLLs consumes 1 byte per character. On CPUs that support byte addressing, such as the Intel 80x86 processor, a compiler can reserve a single byte of storage for each character variable and efficiently access that character variable in memory. Some RISC CPUs, however, cannot access data in memory except in 32-bit chunks (or another size other than 8 bits).</p>&#13;
		<p class="indent">For CPUs that cannot address individual bytes in memory, HLL compilers usually reserve 32 bits for a character variable and use only the LO byte of that double-word variable for the character data. Because few programs have a large number of scalar character variables,<sup><a id="ch7fn_7"/><a href="footnotes.xhtml#ch7fn7">7</a></sup> the amount of space wasted is hardly an issue in most systems. However, if you have an unpacked array of characters, then the wasted space can become significant. We’ll return to this issue in <a href="ch08.xhtml#ch08">Chapter 8</a>.</p>&#13;
		<p class="indent">Modern programming languages support the Unicode character set. Unicode characters can require between 1 and 4 bytes of memory to hold the character’s data value (depending on the underlying encoding, such as UTF-8, UTF-16, or UTF-32). As time passes, Unicode will likely replace the ASCII character set for most character- and string-oriented operations except in those programs that require high-performance random access to characters within strings (where Unicode performance suffers).</p>&#13;
		<h4 class="h4" id="ch00lev2sec85"><strong>7.4.4 Boolean Variables</strong></h4>&#13;
		<p class="noindent">A Boolean variable requires only a single bit to represent the two values <code>true</code> or <code>false</code>. HLLs usually reserve the smallest amount of memory possible <span epub:type="pagebreak" id="page_198"/>for these variables (a byte on machines that support byte addressing, and a larger amount of memory on those CPUs that can address only 16-bit, 32-bit, or 64-bit memory values). However, this isn’t always the case. Some languages (like FORTRAN) allow you to create multibyte Boolean variables (for example, the FORTRAN <code>LOGICAL*4</code> data type).</p>&#13;
		<p class="indent">Some languages (early versions of C/C++, for example) don’t support an explicit Boolean data type. Instead, they use an integer data type to represent Boolean values. Those C/C++ implementations use <code>0</code> and nonzero to represent <code>false</code> and <code>true</code>, respectively. In such languages, you get to choose the size of your Boolean variables by choosing the size of the integer you use to hold them. For example, in a typical older 32-bit implementation of the C/C++ languages, you can define 1-byte, 2-byte, or 4-byte Boolean values as shown in <a href="ch07.xhtml#ch7tab2">Table 7-2</a>.<sup><a id="ch7fn_8"/><a href="footnotes.xhtml#ch7fn8">8</a></sup></p>&#13;
		<p class="tabcap" id="ch7tab2"><strong>Table 7-2:</strong> Defining Boolean Value Sizes</p>&#13;
		<table class="all">&#13;
			<colgroup>&#13;
				<col style="width:50%"/>&#13;
				<col style="width:50%"/>&#13;
			</colgroup>&#13;
			<tbody>&#13;
				<tr>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>C integer data type</strong></p>&#13;
					</td>&#13;
					<td class="table-h" style="vertical-align: top;">&#13;
						<p class="table"><strong>Size of Boolean object</strong></p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><code>char</code></p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">1 byte</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><code>short int</code></p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">2 bytes</p>&#13;
					</td>&#13;
				</tr>&#13;
				<tr>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table"><code>long int</code></p>&#13;
					</td>&#13;
					<td style="vertical-align: top;">&#13;
						<p class="table">4 bytes</p>&#13;
					</td>&#13;
				</tr>&#13;
			</tbody>&#13;
		</table>&#13;
		<p class="indent">Some languages, under certain circumstances, use only a single bit of storage for a Boolean variable when that variable is a field of a record or an element of an array. We’ll return to this discussion in <a href="ch08.xhtml#ch08">Chapters 8</a>–<a href="ch11.xhtml#ch11">11</a> when considering composite data structures.</p>&#13;
		<h3 class="h3" id="ch00lev1sec67"><strong>7.5 Variable Addresses and High-Level Languages</strong></h3>&#13;
		<p class="noindent">The organization, class, and type of variables in your programs can affect the efficiency of the code that a compiler produces. Additionally, issues like the order of declaration, the size of the object, and the placement of the object in memory can have a big impact on the running time of your programs. This section describes how you can organize your variable declarations to produce efficient code.</p>&#13;
		<p class="indent">As for immediate constants encoded in machine instructions, many CPUs provide specialized addressing modes that access memory more efficiently than other, more general, addressing modes. Just as you can reduce the size and improve the speed of your programs by carefully selecting the constants you use, you can make your programs more efficient by carefully choosing how you declare variables. Whereas with constants you’re primarily concerned with their values, with variables you must consider the address in memory where the compiler places them.</p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_199"/>The 80x86 is a typical example of a CISC processor that provides multiple address sizes. When running on a modern 32- or 64-bit operating system like macOS, Linux, or Windows, the 80x86 CPU supports three address sizes: 0 bit, 8 bit, and 32 bit. The 80x86 uses 0-bit displacements for register-indirect addressing modes. We’ll ignore the 0-bit displacement addressing mode for now because 80x86 compilers generally don’t use it to access variables you explicitly declare in your code. The 8-bit and 32-bit displacement addressing modes are the more interesting ones for the current discussion.</p>&#13;
		<h4 class="h4" id="ch00lev2sec86"><strong>7.5.1 Allocating Storage for Global and Static Variables</strong></h4>&#13;
		<p class="noindent">The 32-bit displacement is, perhaps, the easiest to understand. Variables you declare in your program, which the compiler allocates in memory rather than in a register, have to appear somewhere in memory. On most 32-bit processors, the address bus is 32 bits wide, so it takes a 32-bit address to access a variable at an arbitrary location in memory. An instruction that encodes this 32-bit address can access any memory variable. The 80x86 provides the <em>displacement-only</em> addressing mode, whose effective address is exactly the 32-bit constant embedded in the instruction.</p>&#13;
		<p class="indent">A problem with 32-bit addresses (one that gets even worse as we move to 64-bit processors with a 64-bit address) is that the address winds up consuming the largest portion of the instruction’s encoding. Certain forms of the displacement-only addressing mode on the 80x86, for example, have a 1-byte opcode and a 4-byte address. Therefore, 80 percent of the instruction’s size is consumed by the address. Were the 64-bit variants of the 80x86 (x86-64) to actually encode a 64-bit absolute address as part of the instruction, the instruction would be 9 bytes long and consume nearly 90 percent of the instruction’s bytes. To avoid this, the x86-64 modified the displacement-only addressing mode. It no longer encodes the absolute address in memory as part of the instruction; instead, it encodes a signed 32-bit offset (±2 billion bytes) into the instruction.</p>&#13;
		<p class="indent">On typical RISC processors, the situation is even worse. Because the instructions are uniformly 32 bits long on typical RISC CPUs, you cannot encode a 32-bit address as part of the instruction. In order to access a variable at an arbitrary 32- or 64-bit address in memory, you need to load the 32- or 64-bit address of that variable into a register and then use the register-indirect addressing mode to access it. For a 32-bit address, this could require three 32-bit instructions, as <a href="ch07.xhtml#ch7fig2">Figure 7-2</a> demonstrates; that’s expensive in terms of both speed and space. It gets even more expensive with 64-bit addresses.</p>&#13;
		<p class="indent">Because RISC CPUs don’t run horribly slower than CISC processors, compilers rarely generate code this bad. In reality, programs running on RISC CPUs often keep base addresses to blocks of objects in registers, so they can efficiently access variables in those blocks using short offsets from the base register. But how do compilers deal with arbitrary addresses in memory?</p>&#13;
		<div class="image" id="ch7fig2">&#13;
			<span epub:type="pagebreak" id="page_200"/>&#13;
			<img alt="Image" src="../images/07fig02.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-2: RISC CPU access of an absolute address</em></p>&#13;
		<h4 class="h4" id="ch00lev2sec87"><strong>7.5.2 Using Automatic Variables to Reduce Offset Sizes</strong></h4>&#13;
		<p class="noindent">One way to avoid large instruction sizes with large displacements is to use an addressing mode with a smaller displacement. The 80x86 (and x86-64), for example, provide an 8-bit displacement form for the base-plus-indexed addressing mode. This form allows you to access data at an offset of –128 through +127 bytes around a base address contained in a register. RISC processors have similar features, although the number of displacement bits is usually larger, allowing a greater range of addresses.</p>&#13;
		<p class="indent">By pointing a register at some base address in memory and placing your variables near that base address, you can use the shorter forms of these instructions so your program will be smaller and run faster. This isn’t too difficult if you’re working in assembly language and you have direct access to the CPU’s registers. However, if you’re working in an HLL you may not have direct access to the CPU’s registers, and even if you did, you probably couldn’t convince the compiler to allocate your variables at convenient addresses. How do you take advantage of this small-displacement addressing mode in your HLL programs? The answer is that you don’t explicitly specify the use of this addressing mode; the compiler does it for you automatically.</p>&#13;
		<p class="indent">Consider the following trivial function in Pascal:</p>&#13;
		<pre class="programs">&#13;
			function trivial( i:integer; j:integer ):integer;<br/>var<br/>    k:integer;<br/>begin<br/><br/>    k := i + j;<br/>    trivial := k;<br/><br/>end;</pre>&#13;
		<p class="indent">Upon entry into this function, the compiled code constructs an activation record (sometimes called a <em>stack frame</em>). An activation record, as you saw earlier in the chapter, is a data structure in memory where the system keeps the local data associated with a function or procedure. The activation <span epub:type="pagebreak" id="page_201"/>record includes parameter data, automatic variables, the return address, temporary variables that the compiler allocates, and machine state information (for example, saved register values). The runtime system allocates storage for an activation record on the fly and, in fact, two different calls to the procedure or function may place the activation record at different addresses in memory. In order to access the data in an activation record, most HLLs point a register (usually called the <em>frame pointer</em>) at the activation record, and then the procedure or function references automatic variables and parameters at some offset from this frame pointer. Unless you have many automatic variables and parameters, or your automatic variables and parameters are quite large, these variables generally appear in memory at an offset near the base address. This means that the CPU can use a small offset when referencing variables near the base address held in the frame pointer. In the Pascal example given earlier, parameters <code>i</code> and <code>j</code> and the local variable <code>k</code> would most likely be within a few bytes of the frame pointer’s address, so the compiler can encode these instructions using a small displacement rather than a large displacement. If your compiler allocates local variables and parameters in an activation record, all you have to do is arrange your variables in the activation record so that they appear near its base address. But how do you do that?</p>&#13;
		<p class="indent">Construction of an activation record begins in the code that calls a procedure. The caller places the parameter data (if any) in the activation record. Then the execution of an assembly language <code>call</code> (or equivalent) instruction adds the return address to the activation record. At this point, construction of the activation record continues within the procedure itself. The procedure copies the register values and other important state information and then makes room in the activation record for local variables. The procedure must also update the frame-pointer register (such as EBP on the 80x86, or RBP on the x86-64) so that it points at the base address of the activation record.</p>&#13;
		<p class="indent">To see what a typical activation record looks like, consider the following HLA procedure declaration:</p>&#13;
		<pre class="programs">&#13;
			procedure ARDemo( i:uns32; j:int32; k:dword ); @nodisplay;<br/>var<br/>    a:int32;<br/>    r:real32;<br/>    c:char;<br/>    b:boolean;<br/>    w:word;<br/>begin ARDemo;<br/>    .<br/>    .<br/>    .<br/>end ARDemo;</pre>&#13;
		<p class="indent">Whenever an HLA program calls this <code>ARDemo</code> procedure, it builds the activation record by pushing the data for the parameters onto the stack in the order they appear in the parameter list, from left to right. Therefore, the <span epub:type="pagebreak" id="page_202"/>calling code first pushes the value for the <code>i</code> parameter, then for the <code>j</code> parameter, and finally for the <code>k</code> parameter. After pushing the parameters, the program calls the <code>ARDemo</code> procedure. Immediately upon entry into the procedure, the stack contains these four items, arranged as shown in <a href="ch07.xhtml#ch7fig3">Figure 7-3</a>, assuming the stack grows from high-memory addresses to low-memory addresses (as it does on most processors).</p>&#13;
		<div class="image" id="ch7fig3">&#13;
			<img alt="Image" src="../images/07fig03.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-3: Stack organization immediately upon entry into <span class="codeitalic">ARDemo</span></em></p>&#13;
		<p class="indent">The first few instructions in <code>ARDemo</code> push the current value of the frame-pointer register (such as EBP on the 32-bit 80x86, or RBP on the x86-64) onto the stack and then copy the value of the stack pointer (ESP/RSP on the 80x86/x86-64) into the frame pointer. Next, the code drops the stack pointer down in memory to make room for the local variables. This produces the stack organization shown in <a href="ch07.xhtml#ch7fig4">Figure 7-4</a> on the 80x86 CPU.</p>&#13;
		<p class="indent">To access objects in the activation record, you must use offsets from the frame-pointer register (EBP in <a href="ch07.xhtml#ch7fig4">Figure 7-4</a>) to the desired object.</p>&#13;
		<div class="image" id="ch7fig4">&#13;
			<img alt="Image" src="../images/07fig04.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-4: Activation record for <span class="codeitalic">ARDemo</span> (32-bit 80x86)</em></p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_203"/>The two items of immediate interest are the parameters and the local variables. As <a href="ch07.xhtml#ch7fig5">Figure 7-5</a> shows, you can access the parameters at positive offsets from the frame-pointer register, and the local variables at negative offsets from the frame-pointer register.</p>&#13;
		<div class="image" id="ch7fig5">&#13;
			<img alt="Image" src="../images/07fig05.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-5: Offsets of objects in the <span class="codeitalic">ARDemo</span> activation record on the 32-bit 80x86</em></p>&#13;
		<p class="indent">Intel specifically reserves the EBP/RBP (base-pointer register) to point at the base of the activation record. Therefore, compilers typically use this register as the frame-pointer register when allocating activation records on the stack. Some compilers instead attempt to use the 80x86 ESP/RSP (stack pointer) register to point to the activation record because this reduces the number of instructions in the program. Whether the compiler uses EBP/RBP, ESP/RSP, or some other register as the frame pointer, the bottom line is that the compiler typically points some register at the activation record, and most of the local variables and parameters are near the activation record’s base address.</p>&#13;
		<p class="indent">As you can see in <a href="ch07.xhtml#ch7fig5">Figure 7-5</a>, all the local variables and parameters in the <code>ARDemo</code> procedure are within 127 bytes of the frame-pointer register (EBP). This means that on the 80x86 CPU, an instruction that references one of these variables or parameters will be able to encode the offset from EBP using a single byte. As mentioned earlier, because of the way the program builds the activation record, parameters appear at positive offsets from the frame-pointer register, and local variables appear at negative offsets from the frame-pointer register.</p>&#13;
		<p class="indent">For procedures that have only a few parameters and local variables, the CPU will be able to access all parameters and local variables using a small offset (that is, 8 bits on the 80x86, some possibly larger value on various RISC processors). Consider, however, the following C/C++ function:</p>&#13;
		<pre class="programs"><span epub:type="pagebreak" id="page_204"/>int BigLocals( int i, int j )<br/>{<br/>    int array[256];<br/>    int k;<br/>        .<br/>        .<br/>        .<br/>}</pre>&#13;
		<p class="indent">The activation record for this function on the 32-bit 80x86 appears in <a href="ch07.xhtml#ch7fig6">Figure 7-6</a>.</p>&#13;
		<div class="image" id="ch7fig6">&#13;
			<img alt="Image" src="../images/07fig06.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-6: Activation record for <span class="codeitalic">BigLocals()</span> function</em></p>&#13;
		<div class="note">&#13;
			<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
			<p class="notep"><em>One difference between this activation record and the ones for the Pascal and HLA functions is that C pushes its parameters on the stack in the reverse order (that is, it pushes the last parameter first and the first parameter last). This difference, however, does not impact our discussion at all.</em></p>&#13;
		</div>&#13;
		<p class="indent">The important thing to note in <a href="ch07.xhtml#ch7fig6">Figure 7-6</a> is that the local variables <code>array</code> and <code>k</code> have large negative offsets. With offsets of –1,024 and –1,028, the displacements from EBP to <code>array</code> and <code>k</code> are well outside the range that the compiler can encode into a single byte on the 80x86. Therefore, the compiler has no choice but to encode these displacements using a 32-bit value. Of course, this makes accessing these local variables in the function quite a bit more expensive.</p>&#13;
		<p class="indent">Nothing can be done about the array variable in this example (no matter where you put it, the offset to the base address of the array will be at least 1,024 bytes from the activation record’s base address). However, consider the activation record in <a href="ch07.xhtml#ch7fig7">Figure 7-7</a>.</p>&#13;
		<div class="image" id="ch7fig7">&#13;
			<span epub:type="pagebreak" id="page_205"/>&#13;
			<img alt="Image" src="../images/07fig07.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-7: Another possible activation record layout for the <span class="codeitalic">BigLocals()</span> function</em></p>&#13;
		<p class="indent">The compiler has rearranged the local variables in this activation record. Although it still takes a 32-bit displacement to access the <code>array</code> variable, accessing <code>k</code> now uses an 8-bit displacement (on the 32-bit 80x86) because <code>k</code>’s offset is –4. You can produce these offsets with the following code:</p>&#13;
		<pre class="programs">&#13;
			int BigLocals( int i, int j );<br/>{<br/>    int k;<br/>    int array[256];<br/>        .<br/>        .<br/>        .<br/>}</pre>&#13;
		<p class="indent">In theory, rearranging the order of the variables in the activation record isn’t terribly difficult for a compiler to do, so you’d expect the compiler to make this modification so that it can access as many local variables as possible using small displacements. In practice, not all compilers actually do this optimization, for various technical and practical reasons (specifically, it can break some poorly written code that makes assumptions about the placement of variables in the activation record).</p>&#13;
		<p class="indent">If you want to ensure that the maximum number of local variables in your procedure have the smallest possible displacements, the solution is trivial: declare all your 1-byte variables first, your 2-byte variables second, your 4-byte variables next, and so on, up to the largest local variable in your function. Generally, though, you’re probably more interested in reducing the size of the maximum number of instructions in your function rather than reducing the size of the offsets required by the maximum number of variables in your function. For example, if you have 128 1-byte variables and you declare these variables first, you’ll need only a 1-byte displacement if you access them. However, if you never access these variables, the fact that they have a 1-byte displacement rather than a 4-byte displacement saves you nothing. The only time you save any space is when you actually access that variable’s value in memory via some machine instruction that uses a 1-byte <span epub:type="pagebreak" id="page_206"/>rather than a 4-byte displacement. Therefore, to reduce your function’s object code size, you want to maximize the number of instructions that use a small displacement. If you refer to a 100-byte array far more often than any other variable in your function, you’re probably better off declaring that array first, even if it leaves only 28 bytes of storage (on the 80x86) for other variables that will use the shorter displacement.</p>&#13;
		<p class="indent">RISC processors typically use a signed 12-bit or 16-bit offset to access fields of the activation record. Thus, you have more latitude with your declarations when using a RISC chip (which is good, because when you do exceed the 12-bit or 16-bit limitation, accessing a local variable gets really expensive). Unless you’re declaring one or more arrays that consume more than 2,048 (12 bits) or 32,768 bytes (combined), the typical compiler for a RISC chip will generate decent code.</p>&#13;
		<p class="indent">This same argument applies to parameters as well as local variables. However, it’s rare to find code passing a large data structure (by value) to a function because of the expense involved.</p>&#13;
		<h4 class="h4" id="ch00lev2sec88"><strong>7.5.3 Allocating Storage for Intermediate Variables</strong></h4>&#13;
		<p class="noindent">Intermediate variables are local to one procedure/function but global to another. You’ll find them in block-structured languages—like Free Pascal, Delphi, Ada, Modula-2, Swift, and HLA—that support nested procedures. Consider the following example program in Swift:</p>&#13;
		<pre class="programs">&#13;
			import Cocoa<br/>import Foundation<br/><br/>var globalVariable = 2<br/><br/>func procOne()<br/>{<br/>    var intermediateVariable = 2;<br/><br/>    func procTwo()<br/>    {<br/>        let localVariable =<br/>            intermediateVariable + globalVariable<br/>        print( localVariable )<br/>    }<br/>    procTwo()<br/>}<br/><br/>procOne()</pre>&#13;
		<p class="indent">Note that nested procedures can access variables found in the main program (that is, global variables) as well as variables found in procedures containing the nested procedure (that is, the intermediate variables). As you’ve seen, local variable access is inexpensive compared to global variable access (because you always have to use a larger offset to access global objects within a procedure). Intermediate variable access, as is done in the <code>procTwo</code> procedure, is expensive. The difference between local and global <span epub:type="pagebreak" id="page_207"/>variable accesses is the size of the offset/displacement coded into the instruction, with local variables typically using a shorter offset than is possible for global objects. Intermediate accesses, on the other hand, typically require several machine instructions. This makes the instruction sequence that accesses an intermediate variable several times slower and several times larger than accessing a local (or even global) variable.</p>&#13;
		<p class="indent">The problem with using intermediate variables is that the compiler must maintain either a linked list of activation records or a table of pointers to the activation records (a <em>display</em>) in order to reference intermediate objects. To access an intermediate variable, the <code>procTwo</code> procedure must either follow a chain of links (there would be only one link in this example) or do a table lookup in order to get a pointer to <code>procOne</code>’s activation record. Worse still, maintaining the display of this linked list of pointers isn’t exactly cheap. The work needed to maintain these objects has to be done on every procedure/function entry and exit, even when the procedure or function doesn’t access any intermediate variables on a particular call. Although there are, arguably, some software engineering benefits to using intermediate variables (having to do with information hiding) versus a global variable, keep in mind that accessing intermediate objects is expensive.</p>&#13;
		<h4 class="h4" id="ch00lev2sec89"><strong>7.5.4 Allocating Storage for Dynamic Variables and Pointers</strong></h4>&#13;
		<p class="noindent">Pointer access in an HLL provides another opportunity for optimization in your code. Pointers can be expensive to use but, under certain circumstances, they can actually make your programs more efficient by reducing displacement sizes.</p>&#13;
		<p class="indent">A pointer is simply a memory variable whose value is the address of some other memory object (therefore, pointers are the same size as an address on the machine). Because most modern CPUs support indirection only via a machine register, indirectly accessing an object is typically a two-step process: first the code has to load the value of the pointer variable into a register, and then it has to refer (indirectly) to the object through that register.</p>&#13;
		<p class="indent">Consider the following C/C++ code fragment:</p>&#13;
		<pre class="programs">&#13;
			int *pi;<br/>    .<br/>    .<br/>    .<br/>i = *pi;    // Assume pi is initialized with a<br/>            // reasonable address at this point.</pre>&#13;
		<p class="indent">Here is the corresponding 80x86/HLA assembly code:</p>&#13;
		<pre class="programs">&#13;
			pi: pointer to int32;<br/>    .<br/>    .<br/>    .<br/>mov( pi, ebx );     // Again, assume pi has<br/>mov( [ebx], eax );  // been properly initialized<br/>mov( eax, i );</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_208"/>Had <code>pi</code> been a regular variable rather than pointer object, this code could have dispensed with the <code>mov([ebx], eax);</code> instruction and simply moved <code>pi</code> directly into <code>eax</code>. Therefore, the use of this pointer variable has both increased the program’s size and reduced the execution speed by inserting an extra instruction into the code sequence that the compiler generates.</p>&#13;
		<p class="indent">However, if you indirectly refer to an object several times in close succession, the compiler may be able to reuse the pointer value it has loaded into the register, amortizing the cost of the extra instruction across several different instructions. Consider the following C/C++ code sequence:</p>&#13;
		<pre class="programs">&#13;
			int *pi;<br/>    .<br/>    .   // Assume code in this area<br/>    .   // initializes pi appropriately.<br/>    .<br/>*pi = i;<br/>*pi = *pi + 2;<br/>*pi = *pi + *pi;<br/>printf( "pi = %d\n", *pi );</pre>&#13;
		<p class="indent">Here’s the corresponding 80x86/HLA code:</p>&#13;
		<pre class="programs">&#13;
			pi: pointer to int32;<br/>    .<br/>    . // Assume code in this area<br/>    . // initializes pi appropriately.<br/>    .<br/>// Extra instruction that we need to initialize EBX<br/><br/>mov( pi, ebx );<br/><br/>mov( i, eax );<br/>mov( eax, [ebx] );  //  This code can clearly be optimized,<br/>mov( [ebx], eax );  //  but we'll ignore that fact for the<br/>add( 2, eax );      //  sake of the discussion here.<br/>mov( eax, [ebx] );<br/>mov( [ebx], eax );<br/>add( [ebx], eax );<br/>mov( eax [ebx] );<br/>stdout.put( "pi = ", (type int32 [ebx]), nl );</pre>&#13;
		<p class="indent">This code loads the actual pointer value into EBX only once. From that point forward, the code will simply use the pointer value contained in EBX to reference the object at which <code>pi</code> is pointing. Of course, any compiler that can do this optimization can probably eliminate five redundant memory loads and stores from this assembly language sequence, but let’s assume they’re not redundant for the time being. Because the code didn’t have to reload EBX with the value of <code>pi</code> every time it wanted to access the object at which <code>pi</code> points, there’s only one instruction of overhead (<code>mov(pi, ebx);</code>) amortized across six instructions. That’s not too bad at all.</p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_209"/>Indeed, you could make a good argument that this code is more optimal than accessing a local or global variable directly. An instruction of the form</p>&#13;
		<pre class="programs">mov([ebx],eax);</pre>&#13;
		<p class="noindent">encodes a 0-bit displacement. Therefore, this move instruction is only 2 bytes long rather than 3, 5, or even 6 bytes long. If <code>pi</code> is a local variable, it’s quite possible that the original instruction that copies <code>pi</code> into EBX is only 3 bytes long (a 2-byte opcode and a 1-byte displacement). Because instructions of the form <code>mov([ebx],eax);</code> are only 2 bytes long, it only takes three instructions to “break even” on the byte count using indirection rather than an 8-bit displacement. After the third instruction that references whatever <code>pi</code> points at, the code involving the pointer is actually shorter.</p>&#13;
		<p class="indent">You can even use indirection to provide efficient access to a block of global variables. As noted earlier, the compiler generally cannot determine the address of a global object while it’s compiling your program. Therefore, it has to assume the worst case and allow for the largest possible displacement/offset when generating machine code to access a global variable. Of course, you’ve just seen that you can reduce the size of the displacement value from 32 bits down to 0 bits by using a pointer to the object rather than accessing the object directly. Therefore, you could take the address of the global object (with the C/C++ <code>&amp;</code> operator, for example) and then use indirection to access the variable. The problem with this approach is that it requires a register (a precious commodity on any processor, but especially on the 32-bit 80x86, which has only six general-purpose registers to utilize). If you access the same variable many times in rapid succession, this 0-bit displacement trick can make your code more efficient. However, it’s somewhat rare to access the same variable repeatedly in a short sequence of code without also needing to access several other variables. This means the compiler may have to flush the pointer from the register and reload the pointer value later, reducing the efficiency of this approach. If you’re working on a RISC chip or x86-64 with many registers, you can probably employ this trick to your advantage. On a processor with a limited number of registers, though, you won’t be able to employ it as often.</p>&#13;
		<h4 class="h4" id="ch00lev2sec90"><strong>7.5.5 Using Records/Structures to Reduce Instruction Offset Sizes</strong></h4>&#13;
		<p class="noindent">There’s also a trick you can use to access several variables with a single pointer: put all those variables into a structure and then use the structure’s address. By accessing the fields of the structure via the pointer, you can get away with using smaller instructions to access the objects. This works almost exactly as you’ve seen for activation records (indeed, activation records are, literally, records that the program references indirectly via the frame-pointer register). About the only difference between accessing objects indirectly in a user-defined record/structure and accessing objects in the activation record is that most compilers won’t let you refer to fields in a user structure/record using negative offsets. Therefore, you’re limited to about half the number of bytes that are normally accessible in an activation record. For example, on <span epub:type="pagebreak" id="page_210"/>the 80x86 you can access the object at offset 0 from a pointer using a 0-bit displacement and objects at offsets 1 through +127 using a single-byte displacement. Consider the following C/C++ example that uses this trick:</p>&#13;
		<pre class="programs">&#13;
			typedef struct<br/>{<br/>    int i;<br/>    int j;<br/>    char *s;<br/>    char name[20];<br/>    short t;<br/>} vars;<br/><br/>static vars v;<br/>vars *pv = &amp;v;  // Initialize pv with the address of v.<br/>        .<br/>        .<br/>        .<br/>    pv-&gt;i = 0;<br/>    pv-&gt;j = 5;<br/>    pv-&gt;s = pv-&gt;name;<br/>    pv-&gt;t = 0;<br/>    strcpy( pv-&gt;name, "Write Great Code!" );<br/>        .<br/>        .<br/>        .</pre>&#13;
		<p class="indent">A well-designed compiler will load the value of <code>pv</code> into a register exactly once for this code fragment. Because all the fields of the <code>vars</code> structure are within 127 bytes of the base address of the structure in memory, an 80x86 compiler can emit a sequence of instructions that require only 1-byte offsets, even though the <code>v</code> variable itself is a static/global object. Note, by the way, that the first field in the <code>vars</code> structure is special. Because this is at offset 0 in the structure, you can use a 0-bit displacement when accessing this field. Therefore, it’s a good idea to put your most-often-referenced field first in a structure if you’re going to refer to that structure indirectly.</p>&#13;
		<p class="indent">Using indirection in your code does come at a cost. On a limited-register CPU such as the 32-bit 80x86, using this approach will tie up a register for a while, and that may effectively cause the compiler to generate worse code. If the compiler must constantly reload the register with the address of the structure in memory, the savings from this technique evaporate rather quickly. Tricks such as this one vary in effectiveness across different processors (and different compilers for the same processor), so be sure to look at the code your compiler generates to verify that a trick is actually saving rather than costing you something.</p>&#13;
		<h4 class="h4" id="ch00lev2sec91"><strong>7.5.6 Storing Variables in Machine Registers</strong></h4>&#13;
		<p class="noindent">While we’re on the subject of registers, it’s worthwhile to point out one other 0-bit displacement way to access variables in your programs: by keeping them in machine registers. Machine registers are always the most <span epub:type="pagebreak" id="page_211"/>efficient place to store variables and parameters. Unfortunately, only in assembly language and, to a limited extent, C/C++, do you have any control over whether the compiler should keep a variable or parameter in a register. In some respects, this is not bad. Good compilers do a much better job of register allocation than the casual programmer does. However, an expert programmer can do a better job of register allocation than a compiler, because the expert programmer understands the data the program will be processing and the frequency of access to a particular memory location. (And of course, the expert programmer can first look at what the compiler is doing, whereas the compiler doesn’t have the benefit of seeing what the programmer has done.)</p>&#13;
		<p class="indent">Some languages, such as Delphi, provide limited support for programmer-directed register allocation. In particular, the Delphi compiler allows you to tell it to pass the first three (ordinal) parameters for a function or procedure in the EAX, EDX, and ECX registers. This option is known as the <em>fastcall calling convention</em>, and several C/C++ compilers support it as well.</p>&#13;
		<p class="indent">In Delphi and certain other languages, opting for the fastcall parameter passing convention is the only control you get. The C/C++ language, however, provides the <code>register</code> keyword, a storage specifier (much like the <code>const</code>, <code>static</code>, and <code>auto</code> keywords) that tells the compiler that the programmer expects to use the variable frequently so the compiler should attempt to keep it in a register. Note that the compiler can also choose to ignore the <code>register</code> keyword (in which case it reserves variable storage using automatic allocation). Many compilers ignore the <code>register</code> keyword altogether because the compiler’s authors assume, somewhat arrogantly, that they can do a better job of register allocation than any programmer. Of course, on some register-starved machines such as the 32-bit 80x86, there are so few registers to work with that it might not even be possible to allocate a variable to a register throughout the execution of some function. Nevertheless, some compilers do respect the programmer’s wishes and <em>will</em> allocate a few variables in registers if you request that they do so.</p>&#13;
		<p class="indent">Most RISC compilers reserve several registers for passing parameters and several registers for local variables. Therefore, it’s a good idea (if possible) to place the parameters you access most frequently first in the parameter declaration because they’re probably the ones the compiler would allocate in a register.<sup><a id="ch7fn_9"/><a href="footnotes.xhtml#ch7fn9">9</a></sup> The same is true for local variable declarations. Always declare frequently used local variables first, because many compilers may allocate those (ordinal) variables in registers.</p>&#13;
		<p class="indent">One problem with compiler register allocation is that it is static. That is, the compiler determines which variables to place in registers based on an analysis of your source code during compilation, not during runtime. Compilers often make assumptions (which are usually correct) like “this function references variable <code>xyz</code> far more often than any other variable, so it’s a good candidate for a register variable.” Indeed, by placing the variable in a register, the compiler will certainly reduce the size of the program. <span epub:type="pagebreak" id="page_212"/>However, it could also be the case that all those references to <code>xyz</code> sit in code that rarely, if ever, executes. Although the compiler might save some space (by emitting smaller instructions to access registers rather than memory), the code won’t run appreciably faster. After all, if the code rarely or never executes, then making that code run faster does not contribute much to the program’s execution time. On the other hand, it’s also quite possible to bury a single reference to some variable in a deeply nested loop that executes many times. With only one reference in the entire function, the compiler’s optimizer may overlook the fact that the executing program references the variable frequently. Although compilers have gotten smarter about handling variables inside loops, the fact is, no compiler can predict how many times an arbitrary loop will execute at runtime. Human beings are much better at predicting this sort of behavior (or, at least, measuring it with a profiler) and thus are best positioned to make good decisions about variable allocation in registers.</p>&#13;
		<h3 class="h3" id="ch00lev1sec68"><strong>7.6 Variable Alignment in Memory</strong></h3>&#13;
		<p class="noindent">On many processors (particularly RISC), there is another efficiency concern you must take into consideration. Many modern processors will not let you access data at an arbitrary address in memory. Instead, all accesses must take place on some native boundary (usually 4 bytes) that the CPU supports.<sup><a id="ch7fn_10"/><a href="footnotes.xhtml#ch7fn10">10</a></sup> Even when a CISC processor allows memory accesses at arbitrary byte boundaries, it’s often more efficient to access primitive objects (bytes, words, and double words) on a boundary that is a multiple of the object’s size (see <a href="ch07.xhtml#ch7fig8">Figure 7-8</a>).</p>&#13;
		<div class="image" id="ch7fig8">&#13;
			<img alt="Image" src="../images/07fig08.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-8: Variable alignment in memory</em></p>&#13;
		<p class="indent">If the CPU supports unaligned accesses—that is, if the CPU allows you to access a memory object on a boundary that is not a multiple of the object’s primitive size—then you should be able to pack the variables into the activation record. This way, you would obtain the maximum number of variables having a short offset. However, because unaligned accesses are <span epub:type="pagebreak" id="page_213"/>sometimes slower than aligned accesses, many optimizing compilers insert <em>padding bytes</em> into the activation record in order to ensure that all variables are aligned on a reasonable boundary for their native size (see <a href="ch07.xhtml#ch7fig9">Figure 7-9</a>). This trades off slightly better performance for a slightly larger program.</p>&#13;
		<div class="image" id="ch7fig9">&#13;
			<img alt="Image" src="../images/07fig09.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-9: Padding bytes in an activation record</em></p>&#13;
		<p class="indent">However, if you put all your double-word declarations first, your word declarations second, your byte declarations third, and your array/structure declarations last, you can improve both the speed and size of your code. The compiler usually ensures that the first local variable you declare appears at a reasonable boundary (typically a double-word boundary). By declaring all your double-word variables first, you ensure that they all appear at an address that is a multiple of 4 (because compilers usually allocate adjacent variables in your declarations in adjacent locations in memory). The first word-sized object you declare will also appear at an address that is a multiple of 4—and that means its address is also a multiple of 2 (which is best for word accesses). By declaring all your word variables together, you ensure that each one appears at an address that is a multiple of 2. On processors that allow byte access to memory, the placement of the byte variables (with respect to efficiently accessing the byte data) is irrelevant. By declaring all your local byte variables last in a procedure or function, you generally ensure that such declarations do not impact the performance of the double-word and word variables you also use in the function. <a href="ch07.xhtml#ch7fig10">Figure 7-10</a> shows what a typical activation record will look like if you declare your variables as in the following function:</p>&#13;
		<pre class="programs">&#13;
			int <span class="codeitalic1">someFunction</span>( void )<br/>{<br/>    int d1;   // Assume ints are 32-bit objects<br/>    int d2;<br/><span epub:type="pagebreak" id="page_214"/>    int d3;<br/>    short w1; // Assume shorts are 16-bit objects<br/>    short w2;<br/>    char b1;  // Assume chars are 8-bit objects<br/>    char b2;<br/>    char b3;<br/>        .<br/>        .<br/>        .<br/>} // end <span class="codeitalic1">someFunction</span></pre>&#13;
		<div class="image" id="ch7fig10">&#13;
			<img alt="Image" src="../images/07fig10.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-10: Aligned variables in an activation record (32-bit 80x86)</em></p>&#13;
		<p class="indent">Note how all the double-word variables (<code>d1</code>, <code>d2</code>, and <code>d3</code>) begin at addresses that are multiples of 4 (–4, –8, and –12). Also, notice how all the word-sized variables (<code>w1</code> and <code>w2</code>) begin at addresses that are multiples of 2 (–14 and –16). The byte variables (<code>b1</code>, <code>b2</code>, and <code>b3</code>) begin at arbitrary addresses in memory (both even and odd addresses).</p>&#13;
		<p class="indent">Now consider the following function, which has arbitrary (unordered) variable declarations, and the corresponding activation record shown in <a href="ch07.xhtml#ch7fig11">Figure 7-11</a>:</p>&#13;
		<pre class="programs">&#13;
			int <span class="codeitalic1">someFunction2</span>( void )<br/>{<br/>    char  b1; // Assume chars are 8-bit objects<br/>    int   d1; // Assume ints are 32-bit objects<br/>    short w1; // Assume shorts are 16-bit objects<br/>    int   d2;<br/>    short w2;<br/><span epub:type="pagebreak" id="page_215"/>    char  b2;<br/>    int   d3;<br/>    char  b3;<br/>        .<br/>        .<br/>        .<br/>} // end <span class="codeitalic1">someFunction2</span></pre>&#13;
		<div class="image" id="ch7fig11">&#13;
			<img alt="Image" src="../images/07fig11.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-11: Unaligned variables in an activation record (32-bit 80x86)</em></p>&#13;
		<p class="indent">As you can see, every variable except the byte variables appears at an address that is inappropriate for the object. On processors that allow memory accesses at arbitrary addresses, it may take more time to access a variable that is not aligned on an appropriate address boundary.</p>&#13;
		<p class="indent">Some processors don’t allow a program to access an object at an unaligned address. Most RISC processors, for example, can’t access memory except at 32-bit address boundaries. To access a short or byte value, some RISC processors require the software to read a 32-bit value and extract the 16-bit or 8-bit value (that is, the CPU forces the software to treat bytes and words as packed data). The extra instructions and memory accesses needed to pack and unpack this data reduce the speed of memory access by a considerable amount (two or more instructions—usually more—may be needed to fetch a byte or word from memory). Writing data to memory is even worse because the CPU must first fetch the data from memory, merge the new data with the old data, and then write the result back to memory. Therefore, most RISC compilers won’t create an activation record similar to the one in <a href="ch07.xhtml#ch7fig11">Figure 7-11</a>. Instead, they’ll add padding bytes so that every <span epub:type="pagebreak" id="page_216"/>memory object begins at an address boundary that is a multiple of 4 bytes (see <a href="ch07.xhtml#ch7fig12">Figure 7-12</a>).</p>&#13;
		<div class="image" id="ch7fig12">&#13;
			<img alt="Image" src="../images/07fig12.jpg"/>&#13;
		</div>&#13;
		<p class="figcap"><em>Figure 7-12: RISC compilers force aligned access by adding padding bytes.</em></p>&#13;
		<p class="indent">Notice in <a href="ch07.xhtml#ch7fig12">Figure 7-12</a> that all of the variables are at addresses that are multiples of 32 bits. Therefore, a RISC processor has no problems accessing any of these variables. The cost, of course, is that the activation record is quite a bit larger (the local variables consume 32 bytes rather than 19 bytes).</p>&#13;
		<p class="indent">Although the example in <a href="ch07.xhtml#ch7fig12">Figure 7-12</a> is typical for 32-bit RISC-based compilers, that’s not to suggest that compilers for CISC CPUs don’t do this as well. Many compilers for the 80x86, for example, also build this activation record in order to improve the performance of the code the compiler generates. Although declaring your variables in a misaligned fashion may not slow down your code on a CISC CPU, it may use additional memory.</p>&#13;
		<p class="indent">Of course, if you work in assembly language, it’s generally up to you to declare your variables in a manner that is appropriate or efficient for your particular processor. In HLA (on the 80x86), for example, the following two procedure declarations result in the activation records shown in <a href="ch07.xhtml#ch7fig10">Figures 7-10</a>, <a href="ch07.xhtml#ch7fig11">7-11</a>, and <a href="ch07.xhtml#ch7fig12">7-12</a>.</p>&#13;
		<pre class="programs">&#13;
			procedure <span class="codeitalic1">someFunction</span>; @nodisplay; @noalignstack;<br/>var<br/>    d1  :dword;<br/>    d2  :dword;<br/>    d3  :dword;<br/>    w1  :word;<br/><span epub:type="pagebreak" id="page_217"/>    w2  :word;<br/>    b1  :byte;<br/>    b2  :byte;<br/>    b3  :byte;<br/>begin <span class="codeitalic1">someFunction</span>;<br/>        .<br/>        .<br/>        .<br/>end <span class="codeitalic1">someFunction</span>;<br/><br/><br/>procedure <span class="codeitalic1">someFunction2</span>; @nodisplay; @noalignstack;<br/>var<br/>    b1  :byte;<br/>    d1  :dword;<br/>    w1  :word;<br/>    d2  :dword;<br/>    w2  :word;<br/>    b2  :byte;<br/>    d3  :dword;<br/>    b3  :byte;<br/>begin <span class="codeitalic1">someFunction2</span>;<br/>        .<br/>        .<br/>        .<br/>end <span class="codeitalic1">someFunction2</span>;<br/><br/><br/>procedure <span class="codeitalic1">someFunction3</span>; @nodisplay; @noalignstack;<br/>var<br/>    // HLA align directive forces alignment of the next declaration.<br/><br/>    align(4);<br/>    b1  :byte;<br/>    align(4);<br/>    d1  :dword;<br/>    align(4);<br/>    w1  :word;<br/>    align(4);<br/>    d2  :dword;<br/>    align(4);<br/>    w2  :word;<br/>    align(4);<br/>    b2  :byte;<br/>    align(4);<br/>    d3  :dword;<br/>    align(4);<br/>    b3  :byte;<br/>begin <span class="codeitalic1">someFunction3</span>;<br/>        .<br/>        .<br/>        .<br/>end <span class="codeitalic1">someFunction3</span>;</pre>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_218"/>HLA procedures <span class="codeitalic">someFunction</span> and <span class="codeitalic">someFunction3</span> will produce the fastest-running code on any 80x86 processor because all variables are aligned on an appropriate boundary; HLA procedures <span class="codeitalic">someFunction</span> and <span class="codeitalic">someFunction2</span> will produce the most compact activation records on an 80x86 CPU, because there is no padding between variables in the activation record. If you’re working in assembly language on a RISC CPU, you’ll probably want to choose the equivalent of <span class="codeitalic">someFunction</span> or <span class="codeitalic">someFunction3</span> to make it easier to access the variables in memory.</p>&#13;
		<h4 class="h4" id="ch00lev2sec92"><strong>7.6.1 Records and Alignment</strong></h4>&#13;
		<p class="noindent">Records/structures in HLLs also have alignment issues that should concern you. Recently, CPU manufacturers have been promoting <em>application binary interface (ABI)</em> standards to promote interoperability between different programming languages and their implementations. Although not all languages and compilers adhere to these suggestions, many of the newer compilers do. Among other things, these ABI specifications describe how the compilers should organize fields within a record or structure object in memory. Although the rules vary by CPU, one that applies to most ABIs is that a compiler should align a record/structure field at an offset that is a multiple of the object’s size. If two adjacent fields in the record or structure have different sizes, and the placement of the first field in the structure would cause the second field to appear at an offset that is not a multiple of that second field’s native size, then the compiler will insert some padding bytes to push the second field to a higher offset that is appropriate for that second object’s size.</p>&#13;
		<p class="indent">In actual practice, ABIs for different CPUs and OSes have minor differences based on the CPUs’ ability to access objects at different addresses in memory. Intel, for example, suggests that compiler writers align bytes at any offset, words at even offsets, and everything else at offsets that are a multiple of 4. Some ABIs recommend placing 64-bit objects at 8-byte boundaries within a record. The x86-64 SSE and AVX instructions require 16- and 32-byte alignment for 128-bit and 256-bit data values. Some CPUs, which have a difficult time accessing objects smaller than 32 bits, may suggest a minimum alignment of 32 bits for all objects in a record/structure. The rules vary depending on the CPU and whether the manufacturer wants to promote faster-executing code (the usual case) or smaller data structures.</p>&#13;
		<p class="indent">If you are writing code for a single CPU (such as an Intel-based PC) with a single compiler, learn that compiler’s rules for padding fields and adjust your declarations for maximum performance and minimal waste. However, if you ever need to compile your code using several different compilers, particularly compilers for several different CPUs, following one set of rules will work fine on one machine and produce less efficient code on several others. Fortunately, there are some rules that can help reduce the inefficiencies created by recompiling for a different ABI.</p>&#13;
		<p class="indent">From a performance/memory usage standpoint, the best solution is the same rule we saw earlier for activation records: when declaring fields <span epub:type="pagebreak" id="page_219"/>in a record, group all like-sized objects together and put all the larger (scalar) objects first and the smaller objects last in the record/structure. This scheme produces the least amount of waste (padding bytes) and provides the highest performance across most of the existing ABIs. The only drawback to this approach is that you have to organize the fields by their native size rather than by their logical relationship to one another. However, because all fields of a record/structure are logically related insofar as they are all members of that same record/structure, this problem isn’t as bad as employing this organization for all of a particular function’s local variables.</p>&#13;
		<p class="indent">Many programmers try to add padding fields themselves to a structure. For example, the following type of code is common in the Linux kernel and other bits and pieces of overly hacked software:</p>&#13;
		<pre class="programs">&#13;
			typedef struct IveAligned<br/>{<br/>    char byteValue;<br/>    char padding0[3];<br/>    int  dwordValue;<br/>    short wordValue;<br/>    char padding1[2];<br/>    unsigned long dwordValue2;<br/>        .<br/>        .<br/>        .<br/>};</pre>&#13;
		<p class="indent">The <code>padding0</code> and <code>padding1</code> fields in this structure were added to manually align the <code>dwordValue</code> and <code>dwordValue2</code> fields at offsets that are even multiples of 4.</p>&#13;
		<p class="indent">While this padding is not unreasonable, if you’re using a compiler that doesn’t automatically align the fields, remember that an attempt to compile this code on a different machine can produce unexpected results. For example, if a compiler aligns all fields on a 32-bit boundary, regardless of size, then this structure declaration will consume two extra double words to hold the two <code>paddingX</code> arrays. This winds up wasting space for no good reason. Keep this fact in mind if you decide to manually add the padding fields.</p>&#13;
		<p class="indent">Many compilers that automatically align fields in a structure provide an option to turn off this feature. This is particularly true for compilers generating code for CPUs where the alignment is optional and the compiler does it only to achieve a slight performance boost. If you’re going to manually add padding fields to your record/structure, you need to specify this option so that the compiler doesn’t realign the fields after you’ve manually aligned them.</p>&#13;
		<p class="indent">In theory, a compiler is free to rearrange the offsets of local variables within an activation record. However, it would be extremely rare for a compiler to rearrange the fields of a user-defined record or structure. Too many external programs and data structures depend on the fields of a record <span epub:type="pagebreak" id="page_220"/>appearing in the same order as they are declared. This is particularly true when passing record/structure data between code written in two separate languages (for example, when calling a function written in assembly language) or when dumping record data directly to a disk file.</p>&#13;
		<p class="indent">In assembly language, the amount of effort needed to align fields varies from pure manual labor to a rich set of features capable of automatically handling almost any ABI. Some (low-end) assemblers don’t even provide record or structure data types. In such systems, the assembly programmer has to manually specify the offsets into a record structure (typically by declaring, as constants, the numeric offsets into the structure). Other assemblers (for example, NASM) provide macros that automatically generate the equates for you. In these systems, the programmer has to manually provide padding fields to align certain fields on a given boundary. Some assemblers, such as MASM, provide simple alignment facilities. You may specify the value <code>1</code>, <code>2</code>, or <code>4</code> when declaring a <code>struct</code> in MASM and the assembler will align all fields on either the alignment value you specify or at an offset that is a multiple of the object’s size, whichever is smaller, by automatically adding padding bytes to the structure. Also, note that MASM adds a sufficient number of padding bytes to the end of the structure so that the whole structure’s length is a multiple of the alignment size. Consider the following <code>struct</code> declaration in MASM:</p>&#13;
		<pre class="programs">&#13;
			Student  struct  2<br/>score    word    ?   ; offset:0<br/>id       byte    ?   ; offset 2 + 1 byte of padding<br/>year     dword   ?   ; offset 4<br/>id2      byte    ?   ; offset:8<br/>Student  ends</pre>&#13;
		<p class="indent">In this example, MASM will add an extra byte of padding to the end of the structure so that its length is a multiple of 2 bytes.</p>&#13;
		<p class="indent">MASM also lets you control the alignment of individual fields within a structure by using the <code>align</code> directive. The following structure declaration is equivalent to the current example (note the absence of the alignment value operand in the <code>struct</code> operand field):</p>&#13;
		<pre class="programs">&#13;
			Student  struct<br/>score    word    ?   ; offset:0<br/>id       byte    ?   ; offset 2<br/>         align   2   ; Injects 1 byte of padding.<br/>year     dword   ?   ; offset 4<br/>id2      byte    ?   ; offset:8<br/>         align   2   ; Adds 1 byte of padding to the end of the struct.<br/>Student  ends</pre>&#13;
		<p class="indent">The default field alignment for MASM structures is unaligned. That is, a field begins at the next available offset within the structure, regardless of the field’s (and the previous field’s) size.</p>&#13;
		<p class="indent"><span epub:type="pagebreak" id="page_221"/>The High-Level Assembly (HLA) language probably provides the greatest control (both automatic and manual) over record field alignment. As with MASM, the default record alignment is unaligned. Also as with MASM, you can use HLA’s <code>align</code> directive to manually align fields in an HLA record. The following is the HLA version of the previous MASM example:</p>&#13;
		<pre class="programs">&#13;
			type<br/>    Student :record<br/>        score :word;<br/>        id    :byte;<br/>        align(2);<br/>        year  :dword;<br/>        id2   :byte;<br/>        align(2);<br/>    endrecord;</pre>&#13;
		<p class="indent">HLA also lets you specify an automatic alignment for all fields in a record. For example:</p>&#13;
		<pre class="programs">&#13;
			type<br/>    Student :record[2]  // This tells HLA to align all<br/>                        // fields on a word boundary<br/>        score :word;<br/>        id    :byte;<br/>        year  :dword;<br/>        id2   :byte;<br/>    endrecord;</pre>&#13;
		<p class="indent">There is a subtle difference between this HLA record and the earlier MASM structure (with automatic alignment). Remember, when you specify a directive of the form <code>Student struct 2</code>, MASM aligns all fields on a boundary that is a multiple of 2 or a multiple of the object’s size, <em>whichever is smaller</em>. HLA, on the other hand, will always align all fields on a 2-byte boundary using this declaration, even if the field is a byte.</p>&#13;
		<p class="indent">The ability to force field alignment to a minimum size is a nice feature if you’re working with data structures generated on a different machine (or compiler) that forces this kind of alignment. However, this type of alignment can unnecessarily waste space in a record for certain declarations if you only want the fields to be aligned on their natural boundaries (which is what MASM does). Fortunately, HLA provides another syntax for record declarations that lets you specify both the maximum and minimum alignment that HLA will apply to a field:</p>&#13;
		<pre class="programs">&#13;
			recordID: record[ maxAlign : minAlign ]<br/>    &lt;&lt;fields&gt;&gt;<br/>endrecord;</pre>&#13;
		<p class="indent">The <code>maxAlign</code> item specifies the largest alignment that HLA will use within the record. HLA will align any object whose native size is larger <span epub:type="pagebreak" id="page_222"/>than <code>maxAlign</code> on a boundary of <code>maxAlign</code> bytes. Similarly, HLA will align any object whose size is smaller than <code>minAlign</code> on a boundary of at least <code>minAlign</code> bytes. HLA will align objects whose native size is between <code>minAlign</code> and <code>maxAlign</code> on a boundary that is a multiple of that object’s size. The following HLA and MASM record/structure declarations are equivalent:</p>&#13;
		<p class="indent">Here’s the MASM code:</p>&#13;
		<pre class="programs">&#13;
			Student  struct  4<br/>score    word    ?   ; offset:0<br/>id       byte    ?   ; offset 2<br/><br/>    ; 1 byte of padding appears here<br/><br/>year     dword   ?   ; offset 4<br/>id2      byte    ?   ; offset:8<br/><br/>    ; 3 padding bytes appear here<br/><br/>courses  dword   ?   ; offset:12<br/>Student  ends</pre>&#13;
		<p class="indent">Here’s the HLA code:</p>&#13;
		<pre class="programs">&#13;
			type<br/>    //  Align on 4-byte offset, or object's size, whichever<br/>    //  is the smaller of the two. Also, make sure that the<br/>    //  entire record is a multiple of 4 bytes long.<br/><br/>    Student  :record[4:1]<br/>        score   :word;<br/>        id      :byte;<br/>        year    :dword;<br/>        id2     :byte;<br/>      courses   :dword;<br/>    endrecord;</pre>&#13;
		<p class="indent">Although few HLLs provide facilities within the language’s design to control the alignment of fields within records (or other data structures), many compilers provide extensions to those languages, in the form of compiler pragmas, that let programmers specify default variable and field alignment. Because few languages have standards for this, you’ll have to check your particular compiler’s reference manual (note that C++11 is one of the few languages that provides alignment support). Although such extensions are nonstandard, they are often quite useful, especially when you’re linking code compiled by different languages or trying to squeeze the last bit of performance out of a system.</p>&#13;
		<h3 class="h3" id="ch00lev1sec69"><span epub:type="pagebreak" id="page_223"/><strong>7.7 For More Information</strong></h3>&#13;
		<p class="bib">Aho, Alfred V., Monica S. Lam, Ravi Sethi, and Jeffrey D. Ullman. <em>Compilers: Principles, Techniques, and Tools</em>. 2nd ed. Essex, UK: Pearson Education Limited, 1986.</p>&#13;
		<p class="bib">Barrett, William, and John Couch. <em>Compiler Construction: Theory and Practice</em>. Chicago: SRA, 1986.</p>&#13;
		<p class="bib">Dershem, Herbert, and Michael Jipping. <em>Programming Languages, Structures and Models</em>. Belmont, CA: Wadsworth, 1990.</p>&#13;
		<p class="bib">Duntemann, Jeff. <em>Assembly Language Step-by-Step</em>. 3rd ed. Indianapolis: Wiley, 2009.</p>&#13;
		<p class="bib">Fraser, Christopher, and David Hansen. <em>A Retargetable C Compiler: Design and Implementation</em>. Boston: Addison-Wesley Professional, 1995.</p>&#13;
		<p class="bib">Ghezzi, Carlo, and Jehdi Jazayeri. <em>Programming Language Concepts</em>. 3rd ed. New York: Wiley, 2008.</p>&#13;
		<p class="bib">Hoxey, Steve, Faraydon Karim, Bill Hay, and Hank Warren, eds. <em>The PowerPC Compiler Writer’s Guide</em>. Palo Alto, CA: Warthman Associates for IBM, 1996.</p>&#13;
		<p class="bib">Hyde, Randall. <em>The Art of Assembly Language</em>. 2nd ed. San Francisco: No Starch Press, 2010.</p>&#13;
		<p class="bib">Intel. “Intel 64 and IA-32 Architectures Software Developer Manuals.” Updated November 11, 2019. <em><a href="https://software.intel.com/en-us/articles/intel-sdm">https://software.intel.com/en-us/articles/intel-sdm</a></em>.</p>&#13;
		<p class="bib">Ledgard, Henry, and Michael Marcotty. <em>The Programming Language Landscape</em>. Chicago: SRA, 1986.</p>&#13;
		<p class="bib">Louden, Kenneth C. <em>Compiler Construction: Principles and Practice</em>. Boston: Cengage, 1997.</p>&#13;
		<p class="bib">Louden, Kenneth C., and Kenneth A. Lambert. <em>Programming Languages: Principles and Practice</em>. 3rd ed. Boston: Course Technology, 2012.</p>&#13;
		<p class="bib">Parsons, Thomas W. <em>Introduction to Compiler Construction</em>. New York: W. H. Freeman, 1992.</p>&#13;
		<p class="bib">Pratt, Terrence W., and Marvin V. Zelkowitz. <em>Programming Languages, Design and Implementation</em>. 4th ed. Upper Saddle River, NJ: Prentice Hall, 2001.</p>&#13;
		<p class="bib">Sebesta, Robert. <em>Concepts of Programming Languages</em>. 11th ed. Boston: Pearson, 2016.<span epub:type="pagebreak" id="page_224"/></p>&#13;
	</body></html>