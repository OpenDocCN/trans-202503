- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Dental Hygiene: Introduction to Embedded Security'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: The sheer variety of embedded devices makes studying them fascinating, but that
    same variety can also leave you scratching your head over yet another shape, package,
    or weird integrated circuit (IC) and what it means in relation to its security.
    This chapter begins with a look at various hardware components and the types of
    software running on them. We then discuss attackers, various attacks, assets and
    security objectives, and countermeasures to provide an overview of how security
    threats are modeled. We describe the basics of creating an attack tree you can
    use both for defensive purposes (to find opportunities for countermeasures) and
    offensive purposes (to reason about the easiest possible attack). Finally, we
    conclude with thoughts on coordinated disclosure in the hardware world.
  prefs: []
  type: TYPE_NORMAL
- en: Hardware Components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start by looking at the relevant parts of the physical implementation
    of an embedded device that you’re likely to encounter. We’ll touch on the main
    bits you’ll observe when first opening a device.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside an embedded device is a *printed circuit board (PCB)* that generally
    includes the following hardware components: processor, volatile memory, nonvolatile
    memory, analog components, and external interfaces (see [Figure 1-1](#figure1-1)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![f01001](image_fi/278748c01/f01001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-1: Typical PCB of an embedded device'
  prefs: []
  type: TYPE_NORMAL
- en: The magic of computation happens in a *processor (central processing unit*,
    or *CPU)*. In [Figure 1-1](#figure1-1), the processor is embedded inside the *System-on-Chip
    (SoC)* in the center 1. Generally, the processor executes the main software and
    operating system (OS), and the SoC contains additional hardware peripherals.
  prefs: []
  type: TYPE_NORMAL
- en: Usually implemented in dynamic RAM (DRAM) chips in discrete packages, *volatile
    memory* 2 is memory that the processor uses while it’s in action; its contents
    are lost when the device powers down. DRAM memory operates at frequencies close
    to the processor frequency, and it needs wide buses in order to keep up with the
    processor.
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 1-1](#figure1-1), *nonvolatile memory* 3 is where the embedded device
    stores data that needs to persist after power to the device is removed. This memory
    storage can be in the form of EEPROMs, flash memory, or even SD cards and hard
    drives. Nonvolatile memory usually contains code for booting as well as stored
    applications and saved data.
  prefs: []
  type: TYPE_NORMAL
- en: Although not very interesting for security in their own right, the *analog components*,
    such as resistors, capacitors, and inductors, are the starting point for *side-channel
    analysis* and *fault-injection attacks*, which we’ll discuss at length in this
    book. On a typical PCB the analog components are all the little black, brown,
    and blue parts that don’t look like a chip and may have labels starting with “C,”
    “R,” or “L.”
  prefs: []
  type: TYPE_NORMAL
- en: '*External interfaces* provide the means for the SoC to make connections to
    the outside world. The interfaces can be connected to other commercial off-the-shelf
    (COTS) chips as part of the PCB system interconnect. This includes, for example,
    a high-speed bus interface to DRAM or to flash chips as well as low-speed interfaces,
    such as I2C and SPI to a sensor. The external interfaces can also be exposed as
    connectors and pin headers on the PCB; for example, USB and PCI Express (PCIe)
    are examples of high-speed interfaces that connect devices externally. This is
    where all communication happens; for example, with the internet, local debugging
    interfaces, or sensors and actuators. (See Chapter 2 for more details on interfacing
    with devices.)'
  prefs: []
  type: TYPE_NORMAL
- en: Miniaturization allows an SoC to have more *intellectual property (IP) blocks*.
    [Figure 1-2](#figure1-2) shows an example of an Intel Skylake SoC.
  prefs: []
  type: TYPE_NORMAL
- en: '![f01002](image_fi/278748c01/f01002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-2: Intel Skylake SoC (public domain by Fritzchens Fritz)'
  prefs: []
  type: TYPE_NORMAL
- en: 'This die contains multiple cores, including the main central processing unit
    (CPU) cores, the Intel Converged Security and Management Engine (CSME), the graphics
    processing unit (GPU), and much more. Internal buses in an SoC are harder to access
    than external buses, making SoCs an inconvenient starting point for hacking. SoCs
    can contain the following IP blocks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Several (micro)processors and peripherals**'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, an application processor, a crypto engine, a video accelerator,
    and the I2C interface driver.
  prefs: []
  type: TYPE_NORMAL
- en: '**Volatile memory**'
  prefs: []
  type: TYPE_NORMAL
- en: In the form of DRAM ICs stacked on top of the SoC, SRAMs, or register banks.
  prefs: []
  type: TYPE_NORMAL
- en: '**Nonvolatile memory**'
  prefs: []
  type: TYPE_NORMAL
- en: In the form of on-die read-only memory (ROM), one-time-programmable (OTP) fuses,
    EEPROM, and flash memory. OTP fuses typically encode critical chip configuration
    data, such as identity information, lifecycle stage, and anti-rollback versioning
    information.
  prefs: []
  type: TYPE_NORMAL
- en: '**Internal buses**'
  prefs: []
  type: TYPE_NORMAL
- en: Though technically just a bunch of microscopic wires, the interconnect between
    the different components in the SoC is, in fact, a major security consideration.
    Think of this interconnect as the network between two nodes in an SoC. Being a
    network, the internal buses could be susceptible to spoofing, sniffing, injection,
    and all other forms of man-in-the-middle attacks. Advanced SoCs include access
    control at various levels to ensure that components in the SoC are “firewalled”
    from each other.
  prefs: []
  type: TYPE_NORMAL
- en: Each of these components is part of the *attack surface*, the starting point
    for an attacker, and is therefore of interest. In Chapter 2, we’ll study these
    external interfaces more in depth, and in Chapter 3, we’ll look at ways to find
    information on the various chips and components.
  prefs: []
  type: TYPE_NORMAL
- en: Software Components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Software is a structured collection of CPU instructions and data that a processor
    executes. For our purposes, it doesn’t matter whether that software is stored
    in ROM, flash, or on an SD card—although it may come as a disappointment to our
    elder readers that we will not cover punch cards. Embedded devices can contain
    some (or none) of the following types of software.
  prefs: []
  type: TYPE_NORMAL
- en: Initial Boot Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The initial boot code is the set of instructions a processor executes when it’s
    first powered on. The initial boot code is generated by the processor manufacturer
    and stored in ROM. The main function of *boot ROM code* is to prepare the main
    processor to run the code that follows. Normally, it allows a bootloader to execute
    in the field, including routines for authenticating a bootloader or for supporting
    alternate bootloader sources (such as through USB). It’s also used for support
    during manufacturing for personalization, failure analysis, debugging, and self-tests.
    Often the features available in the boot ROM are configured via *fuses*, which
    are one-time programmable bits integrated into the silicon that provide the option
    to disable some of the boot ROM functionality permanently when the processor leaves
    the manufacturing facility.
  prefs: []
  type: TYPE_NORMAL
- en: 'Boot ROM has properties differentiating it from regular code: it is immutable,
    it is the first code to run on a system, and it must have access to the complete
    CPU/SoC to support manufacturing, debugging, and chip failure analysis. Developing
    ROM code requires a lot of care. Because it’s immutable, it’s usually not possible
    to patch a vulnerability in ROM that is detected post-manufacture (although some
    chips support *ROM* *patching* via fuses). Boot ROM executes before any network
    functionality is active, so physical access is required to exploit any vulnerabilities.
    A vulnerability exploited during this phase of boot likely results in direct access
    to the entire system.'
  prefs: []
  type: TYPE_NORMAL
- en: Considering the high stakes for manufacturers in terms of reliability and reputation,
    in general, boot ROM code is usually small, clean, and well verified (at least
    it should be).
  prefs: []
  type: TYPE_NORMAL
- en: Bootloader
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *bootloader* initializes the system after the boot ROM executes. It is typically
    stored on nonvolatile but mutable storage, so it can be updated in the field.
    The PCB’s original equipment manufacturer (OEM) generates the bootloader, allowing
    it to initialize PCB-level components. It may also optionally lock down some security
    features in addition to its primary task of loading and authenticating an operating
    system or *trusted execution environment (TEE)*. In addition, the bootloader may
    provide functionality for provisioning a device or debugging. Being the earliest
    mutable code to run on a device, the bootloader is an attractive target to attack.
    Less-secure devices may have a boot ROM that doesn’t authenticate the bootloader,
    allowing attackers to replace the bootloader code easily.
  prefs: []
  type: TYPE_NORMAL
- en: Bootloaders are authenticated with digital signatures, which are typically verified
    by embedding a public key (or the hash of a public key) in the boot ROM or fuses.
    Because this public key is hard to modify, it’s considered the *root of trust*.
    The manufacturer signs the bootloader using the private key associated with the
    public key, so the boot ROM code can verify and trust that the manufacturer produced
    it. Once the bootloader is trusted, it can, in turn, embed a public key for the
    next stage of code and provide trust that the next stage is authentic. This *chain
    of trust*can extend all the way down to applications running on an OS (see [Figure
    1-3](#figure1-3)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f01003](image_fi/278748c01/f01003.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-3: Chain of trust—bootloader stages and verification'
  prefs: []
  type: TYPE_NORMAL
- en: Theoretically, creating this chain of trust seems pretty secure, but the scheme
    is vulnerable to a number of attacks, ranging from exploiting verification weaknesses
    to fault injection, timing attacks, and more. See Jasper’s talk at Hardwear.io
    USA 2019 “Top 10 Secure Boot Mistakes” on YouTube ([https://www.youtube.com/watch?v=B9J8qjuxysQ/](https://www.youtube.com/watch?v=B9J8qjuxysQ/))
    for an overview of the top 10 mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: Trusted Execution Environment OS and Trusted Applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At the time of writing, the TEE is a rare feature in smaller embedded devices,
    but it’s very common in phones and tablets based on systems such as Android. The
    idea is to create a “virtual” secure SoC by partitioning an entire SoC into “secure”
    and “nonsecure” worlds. This means that every component on the SoC is either exclusively
    active in the secure world, exclusively active in the nonsecure world, or is able
    to switch between the two dynamically. For instance, an SoC developer may choose
    to put a crypto engine in the secure world, networking hardware in the nonsecure
    world, and allow the main processor to switch between the two worlds. This could
    allow the system to encrypt network packets in the secure world and then transmit
    them via the nonsecure world—that is, the “normal world”—ensuring that the encryption
    key never reaches the main OS or a user application on the processor.
  prefs: []
  type: TYPE_NORMAL
- en: On mobile phones and tablets, the TEE includes its own operating system, with
    access to all secure world components. The *rich execution environment (REE)*
    includes the “normal world” operating system, such as a Linux or iOS kernel and
    user applications.
  prefs: []
  type: TYPE_NORMAL
- en: The goal is to keep all nonsecure and complex operations, such as user applications,
    in the nonsecure world, and all secure operations, such as banking applications,
    in the secure world. These secure applications are called *trusted applications
    (TAs)* . The TEE kernel is an attack target that, once compromised, typically
    provides complete access to both the secure and nonsecure worlds.
  prefs: []
  type: TYPE_NORMAL
- en: Firmware Images
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Firmware is the low-level software that runs on CPUs or peripherals. Simple
    peripherals in a device are often fully hardware based, but more complex peripherals
    can contain a microcontroller that runs firmware. For instance, most Wi-Fi chips
    require a firmware “blob” to be loaded after power-up. For those running Linux,
    a look at */lib/firmware* shows how much firmware is involved in running PC peripherals.
    As with any piece of software, firmware can be complex and therefore sensitive
    to attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Main Operating System Kernel and Applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The main OS in an embedded system can be a general-purpose OS, like Linux, or
    a real-time OS, like VxWorks or FreeRTOS. Smart cards may contain proprietary
    OSs that run applications written in Java Card. These OSs can offer security functionality
    (for example, cryptographic services) and implement *process isolation*, which
    means if one process is compromised, another process may still be secure.
  prefs: []
  type: TYPE_NORMAL
- en: An OS makes life easier for software developers who can rely on a broad range
    of existing functionality, but that may not be a viable option for smaller devices.
    Very small devices may have no OS kernel but run only one *bare-metal* program
    to manage them. This usually implies no process isolation, so compromising one
    function leads to compromising the entire device.
  prefs: []
  type: TYPE_NORMAL
- en: Hardware Threat Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Threat modeling is one of the more important necessities in the defense of any
    system. Resources for defending a system are not unlimited, so analyzing how those
    resources are best spent to minimize attack opportunities is essential. This is
    the road to “good enough” security.
  prefs: []
  type: TYPE_NORMAL
- en: 'When performing threat modeling, we roughly do the following: take a defensive
    view to identify the system’s important assets and ask ourselves how those assets
    should be secured. On the flip side, from an offensive viewpoint, we could identify
    who the attackers might be, what their goals might be, and what attacks they could
    choose to attempt. These considerations provide insights into what to protect
    and how to protect the most valuable assets.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard reference work for threat modeling is Adam Shostack’s book *Threat
    Modeling: Designing for Security* (Wiley, 2014). The broad field of threat modeling
    is fascinating, as it includes security of the development environment through
    to manufacturing, supply chain, shipping, and the operational lifetime. We’ll
    address the basic aspects of threat modeling here and apply them to embedded device
    security, focusing on the device itself.'
  prefs: []
  type: TYPE_NORMAL
- en: What Is Security?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *Oxford English Dictionary* defines security as “the state of being free
    from danger or threat.” This rather binary definition implies that the only secure
    system is either one that no one would bother to attack or one that can defend
    every threat. The former, we call a *brick*, because it no longer can boot; the
    latter, we call a *unicorn*, because unicorns don’t exist. There is no perfect
    security, so you could argue that any defense is not worth the effort. This attitude
    is known as *security nihilism*. However, that attitude disregards the important
    fact that a *cost-benefit* trade-off is associated with each and every attack.
  prefs: []
  type: TYPE_NORMAL
- en: We all understand cost and benefit in terms of money. For an attacker, costs
    are usually related to buying or renting equipment needed for carrying out attacks.
    Benefits come in the form of fraudulent purchases, stolen cars, ransomware payouts,
    and slot machine cash-outs, just to name a few.
  prefs: []
  type: TYPE_NORMAL
- en: 'The costs and benefits of performing attacks are not exclusively monetary,
    however. An obvious non-monetary cost is time; a less obvious cost is attacker
    frustration. For example, an attacker who is hacking for fun may simply move on
    to another target in the face of frustration. There is surely a defense lesson
    here. See Chris Domas’s talk at DEF CON 23 for more on this idea: “Repsych: Psychological
    Warfare in Reverse Engineering.” Nonmonetary benefits include gathering personally
    identifiable information and fame derived from conference publications or successful
    sabotage (although those benefits may also be monetized).'
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we consider a system “secure enough” if the cost of an attack
    is higher than the benefit. A system design may not be impenetrable, but it should
    be hard enough that no one will see an entire attack through to success. In summary,
    threat modeling is the process of determining how to reach a secure-enough state
    in a particular device or system. Next, let’s look at several aspects that affect
    the benefits and costs of an attack.
  prefs: []
  type: TYPE_NORMAL
- en: Attacks Through Time
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The US National Security Agency (NSA) has a saying: “Attacks always get better;
    they never get worse.” In other words, attacks get cheaper and stronger over time.
    This tenet particularly holds at larger timescales, because of increased public
    knowledge of a target, decreased cost of computing power, and the ready availability
    of hacking hardware. The time from a chip’s initial design to final production
    can span several years, followed by at least a year to implement the chip in a
    device, resulting in three to five years before it’s operational in a commercial
    environment. This chip may need to remain operational for a few years (in the
    case of Internet of Things [IoT] products), or 10 years (for an electronic passport),
    or even for 20 years (in automotive and medical environments). Thus, designers
    need to take into account whatever attacks might be happening 5 to 25 years hence.
    This is clearly impossible, so often software fixes have to be pushed out to mitigate
    unpatchable hardware problems. To put it in perspective, 25 years ago a smart
    card may have been very hard to break, but after working your way through this
    book, a 25-year-old smart card should pose little resistance in extracting its
    keys.'
  prefs: []
  type: TYPE_NORMAL
- en: Cost differences also appear on smaller timescales when going from an initial
    attack to repeating that attack. The *identification phase* involves identifying
    vulnerabilities. The *exploitation phase* follows, which involves using the identified
    vulnerabilities to exploit a target. In the case of (scalable) software vulnerabilities,
    the identification cost may be significant, but the exploitation cost is almost
    zero, as the attack can be automated. For hardware attacks, the exploitation cost
    may still be significant.
  prefs: []
  type: TYPE_NORMAL
- en: On the benefits side, attacks typically have a limited window within which they
    have value. Cracking Commodore 64 copy protection today provides little monetary
    advantage. A video stream of your favorite sportsball game has high value only
    while the game is in progress and before the result is known. The day afterward,
    its value is significantly lower.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability of Attacks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The identification and exploitation phases of software and hardware attacks
    differ significantly from each other in terms of cost and benefit. The cost of
    the hardware exploitation phase may be comparable to that of the identification
    phase, which is uncommon for software. For instance, a securely designed smart
    card payment system makes use of diversified keys so that finding the key on one
    card means you learn nothing about the key of another card. If card security is
    sufficiently strong, attackers need weeks or months and expensive equipment to
    make a few thousand dollars’ worth of fraudulent purchases on each card. They
    must repeat the process for every new card to gain the next few thousand dollars.
    If the cards are that strong, obviously no business case exists for financially
    motivated attackers; such an attack scales poorly.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, consider the Xbox 360 modchips. [Figure 1-4](#figure1-4)
    shows the Xenium ICE modchip as the white PCB to the left.
  prefs: []
  type: TYPE_NORMAL
- en: '![f01004](image_fi/278748c01/f01004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-4: Xenium ICE modchip in an Xbox, used to bypass code verification
    (photo by Helohe, CC BY 2.5 license)'
  prefs: []
  type: TYPE_NORMAL
- en: A Xenium ICE modchip on the left in [Figure 1-4](#figure1-4) is soldered to
    the main Xbox PCB in order to perform its attack. The board automates a fault
    injection attack to load arbitrary firmware. This hardware attack is so easily
    performed, selling modchips could be turned into a business; therefore, we say
    it “scales well” (Chapter 13 provides a more detailed description of this attack).
  prefs: []
  type: TYPE_NORMAL
- en: Hardware attackers benefit from economies of scale, but only if the exploitation
    cost is very low. One example of this is hardware attacks to extract secrets that
    can then be used at scale, such as recovery of a master firmware update key hidden
    in hardware facilitating access to a multitude of firmware. Another example is
    the once-off operation of extracting boot ROM or firmware code, which can expose
    system vulnerabilities that can be exploited many times over.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, scale is not important for some hardware attacks. For example, hacking
    once would be sufficient for obtaining an unencrypted copy of a video from a digital
    rights management (DRM) system that is then pirated, as is the case with launching
    a single nuclear missile or decrypting a president’s tax returns.
  prefs: []
  type: TYPE_NORMAL
- en: The Attack Tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An *attack tree* visualizes the steps an attacker takes when going from the
    attack surface to the ability to compromise an asset, allowing us to analyze an
    attack strategy systematically. The four ingredients we consider in an attack
    tree are attackers, attacks, assets (security objectives), and countermeasures
    (see [Figure 1-5](#figure1-5)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f01005](image_fi/278748c01/f01005.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-5: Relationship between elements of threat modeling'
  prefs: []
  type: TYPE_NORMAL
- en: Profiling the Attackers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Profiling the attackers is important because attackers have motives, resources,
    and limitations. You could claim that botnets or worms are nonhuman players lacking
    motivation, but a worm is initially launched by a person pressing enter with glee,
    anger, or greedy anticipation.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling the attacker hinges significantly on the nature of the attack required
    for a particular type of device. The attack itself determines the necessary equipment
    and expense required; both factors help profile the attacker to some extent. The
    government wanting to unlock a mobile phone is an example of a costly attack that
    has a high incentive, such as espionage and state security.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some common attack scenarios and associated motives, characters,
    and capabilities of the corresponding attackers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Criminal enterprise**'
  prefs: []
  type: TYPE_NORMAL
- en: Financial gain primarily motivates criminal enterprise attacks. Maximizing profit
    requires scaling. As discussed before, a hardware attack may be at the root of
    a scalable attack, which necessitates a well-provisioned hardware attack laboratory.
    As an example, consider attacks on the pay-TV industry, where pirates have solid
    business cases that justify millions of dollars’ worth of equipment.
  prefs: []
  type: TYPE_NORMAL
- en: '**Industry competition**'
  prefs: []
  type: TYPE_NORMAL
- en: An attacker’s motivation in this security scenario ranges from *competitive
    analysis* (an innocent euphemism for reverse engineering to see what the competition
    is doing), to sleuthing IP infringement, to gathering ideas and inspiration for
    improving one’s own related product. Indirect sabotage by damaging a competitor’s
    brand image is a similar tactic. This type of attacker is not necessarily an individual
    but may be part of a team employed (perhaps underground) or externally hired by
    a company that has all the needed hardware tools.
  prefs: []
  type: TYPE_NORMAL
- en: '**Nation-states**'
  prefs: []
  type: TYPE_NORMAL
- en: Sabotage, espionage, and counterterrorism are common motivators. Nation-states
    likely have all the tools, knowledge, and time at their disposal. By the infamous
    words of James Mickens, if the Mossad (national intelligence agency of Israel)
    targets you, whatever you do in terms of countermeasures, “you’re still gonna
    be Mossad’ed upon.”
  prefs: []
  type: TYPE_NORMAL
- en: '**Ethical hackers**'
  prefs: []
  type: TYPE_NORMAL
- en: Ethical hackers may be a threat, but with a different risk. They may have hardware
    skills and access to basic tools at home or expensive tools at a local university,
    making them as well-equipped as malicious attackers. Ethical hackers are drawn
    to problems where they feel they can make a difference. They can be hobbyists
    driven to understand how things work, or people who strive to be the best or well
    known for their abilities. They also can be researchers who trade on their skills
    for a primary or secondary income, or patriots or protestors who strongly support
    or oppose causes. An ethical hacker doesn’t necessarily present no risk. One smart
    lock manufacturer once lamented to us that a big concern of the company was ending
    up on stage as an example at an ethical hacking event; they perceived this as
    impacting the trust in their brand. In reality, most criminals will use a brick
    to “hack” the lock, so lock customers have little risk of a hack, but the slogan
    “Don’t worry, they’ll use a brick and not a computer,” doesn’t work so well in
    a public relations campaign.
  prefs: []
  type: TYPE_NORMAL
- en: '**Layperson attackers**'
  prefs: []
  type: TYPE_NORMAL
- en: This last type of attacker is typically an individual or small group of people
    with an axe to grind by way of hurting another individual, company, or infrastructure.
    They might, however, not always have the technical acumen. Their aim could be
    financial gain via blackmail or selling trade secrets, or simply to hurt another
    party. Successful hardware attacks from such attackers are generally unlikely
    due to limited knowledge and budget. (For all laypersons out there, please don’t
    DM us on how to break into your ex’s Facebook account.)
  prefs: []
  type: TYPE_NORMAL
- en: Identifying potential attackers is not necessarily clear-cut and depends on
    the device. In general, it is easier to profile attackers when considering a concrete
    product versus a product’s component. For instance, the threat of hacking a brand
    of IoT coffee makers over the internet to produce a weak brew could be linked
    to the various attacker types just listed. Profiling becomes more complex higher
    up the supply chain of a device. A component in IoT devices may be an *advanced
    encryption standard (AES)* accelerator provided by an IP vendor. This accelerator
    is integrated in an SoC, which is integrated onto a PCB, from which a final device
    is made. How would the IP vendor of the AES accelerator identify the threats on
    the 1,001 different devices using that AES accelerator? The vendor would need
    to concentrate more on the type of attack than on the attackers (for instance,
    by implementing a degree of resistance against side-channel attacks).
  prefs: []
  type: TYPE_NORMAL
- en: When you design a device, we strongly advise you to ascertain from your component
    suppliers what attack types have been guarded against. Threat modeling without
    that knowledge cannot be thorough, and perhaps more important, if suppliers aren’t
    queried on this, they won’t be motivated to improve their security measures.
  prefs: []
  type: TYPE_NORMAL
- en: Types of Attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hardware attacks obviously target hardware, such as opening up a *Joint Test
    Action Group (JTAG)* debugging port, but they may also target software, such as
    bypassing password verification. This book does not address software attacks on
    software, but it does address using software to attack hardware.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, the attack surface is the starting point for an attacker—the
    directly accessible bits of hardware and software. When considering the attack
    surface, we usually assume full physical access to the device. However, being
    within Wi-Fi range (*proximate range*) or being connected through any network
    (*remote*) can also be a starting point for an attack.
  prefs: []
  type: TYPE_NORMAL
- en: The attack surface may start with the PCB, whereas a more skilled attacker may
    extend the attack surface to the chip using decapping and microprobing techniques,
    as described later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Software Attacks on Hardware
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Software attacks on hardware use various software controls over hardware or
    the monitoring of hardware. There are two subclasses of software attacks on hardware:
    fault injection and side-channel attacks.'
  prefs: []
  type: TYPE_NORMAL
- en: Fault Injection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Fault injection* is the practice of pushing hardware to a point that induces
    processing errors. A fault injection by itself is not an attack; it’s what you
    do with the effect of the fault that turns it into an attack. Attackers attempt
    to exploit these artificially produced errors. For example, they can obtain privileged
    access by bypassing security checks. The practice of injecting a fault and then
    exploiting the effect of that fault is called a *fault attack*.'
  prefs: []
  type: TYPE_NORMAL
- en: '*DRAM hammering* is a well-known fault injection technique in which the DRAM
    memory chip is bombarded with an unnatural access pattern in three adjacent rows.
    By repeatedly activating the outer two rows, bit flips occur in the center *victim
    row*. The *Rowhammer attack* exploits DRAM bit flips by causing victim rows to
    be page tables. *Page tables* are structures maintained by an operating system
    that limit the memory access of applications. By changing access control bits
    or physical memory addresses in those page tables, an application can access memory
    it normally would not be able to access, which easily leads to privilege escalation.
    The trick is to massage the memory layout such that the victim row with page tables
    is in between attacker-controlled rows and then activate these rows from high-level
    software. This method has been proven possible on the x86 and ARM processors,
    from low-level software all the way up to JavaScript. See the article “Drammer:
    Deterministic Rowhammer Attacks on Mobile Platforms” by Victor van der Veen et
    al. for more information.'
  prefs: []
  type: TYPE_NORMAL
- en: '*CPU overclocking* is another fault-injection technique. Overclocking the CPU
    causes a temporary fault called a *timing fault* to occur. Such a fault can manifest
    itself as a bit error in a CPU register. *CLKSCREW* is an example of a CPU overclocking
    attack. Because software on mobile phones can control the CPU frequency as well
    as the core voltage, by lowering the voltage and momentarily increasing the CPU
    frequency, an attacker can induce the CPU to make faults. By timing this correctly,
    attackers can generate a fault in the RSA signature verification, which allows
    them to load improperly signed arbitrary code. For more information, see “CLKSCREW:
    Exposing the Perils of Security-Oblivious Energy Management” by Adrian Tang et
    al.'
  prefs: []
  type: TYPE_NORMAL
- en: You can find these kinds of vulnerabilities anywhere software can force hardware
    to run outside normal operating parameters. We expect further variants will continue
    to emerge.
  prefs: []
  type: TYPE_NORMAL
- en: Side-Channel Attacks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Software timing relates to the amount of wall-clock time required for a processor
    to complete a software task. In general, more complex tasks need more time. For
    example, sorting a list of 1,000 numbers takes longer than sorting a list of 100
    numbers. It should be no surprise that an attacker can use software execution
    time as a handle for an attack. In modern embedded systems, it is easy for an
    attacker to measure the execution time, often down to the resolution of a single
    clock cycle! This leads to *timing attacks*, in which an attacker tries to relate
    software execution time to the value of internal secret information.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the `strcmp` function in C determines whether two strings are
    the same. It compares characters one by one, starting at the front, and when it
    encounters a differing character, it terminates. When using `strcmp` to compare
    an entered password to a stored password, the duration of `strcmp`’s execution
    leaks information about the password, as it terminates upon finding the first
    nonmatching character between the attacker’s candidate password and the password
    protecting the device. The `strcmp` execution time therefore leaks the number
    of initial characters in the password that are correct. (We detail this attack
    in Chapter 8 and describe the proper way of implementing this comparison in Chapter
    14.)
  prefs: []
  type: TYPE_NORMAL
- en: '*RAMBleed* is another side-channel attack that can be launched from software,
    as demonstrated by Kwong et al. in “RAMBleed: Reading Bits in Memory Without Accessing
    Them.” It uses the Rowhammer-style weaknesses to read bits from DRAM. In a RAMBleed
    attack, the flips happen in an attacker’s row based on the data in victim rows.
    This way, an attacker can observe the memory contents of another process.'
  prefs: []
  type: TYPE_NORMAL
- en: Microarchitectural Attacks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now that you understand the principle of timing attacks, consider the following.
    Modern-day CPUs are fast because of the huge number of optimizations that have
    been identified and implemented over the years. A cache, for instance, is built
    on the premise that recently accessed memory locations are soon likely to be accessed
    again. Therefore, the data at those memory locations is stored physically closer
    to the CPU for faster access. Another example of an optimization arose from the
    insight that the result of multiplying a number *N* by 0 or 1 is trivial, so performing
    the full multiplication calculation isn’t needed, as the answer is always simply
    0 or *N*. Such optimizations are part of the *microarchitecture*, which is the
    hardware implementation of an instruction set.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is where optimizations for speed and security are at odds. If
    the optimization is activated related to some secret value, that optimization
    may hint at values in the data. For instance, if a multiplication of *N* times
    *K* for an unknown *K* is sometimes faster than other times, the value of *K*
    could be 0 or 1 in the fast cases. Or, if a memory region is cached, it can be
    accessed faster, so a fast access means a particular region has been accessed
    recently.
  prefs: []
  type: TYPE_NORMAL
- en: 'The notorious *Spectre* attack from 2018 exploits a neat optimization called
    *speculative execution*. Computing whether a conditional branch should be taken
    or not takes time. Instead of waiting for the branch condition to be computed,
    speculative execution guesses the branch condition and executes the next instructions
    as if the guess is correct. If the guess is correct, the execution simply continues,
    and if the guess is incorrect, the execution will be rolled back. This speculative
    execution, however, still affects the state of the CPU caches. Spectre forces
    a CPU to perform a speculative operation that affects the cache in a way that
    depends on some secret value, and then it uses a cache timing attack to recover
    the secret. As shown in “Spectre Attacks: Exploiting Speculative Execution,” by
    Paul Kocher et al., we can use this trick in some existing or crafted programs
    to dump the entire process memory of a victim process. The larger issue at hand
    is that processors have been optimized for speed in this way for decades, and
    there are many optimizations that may be exploited similarly.'
  prefs: []
  type: TYPE_NORMAL
- en: PCB-Level Attacks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The PCB is often the initial attack surface for devices, so it’s crucial for
    attackers to learn as much as possible from the PCB design. The design provides
    clues as to where exactly to hook into the PCB or reveals where better attack
    points are located. For example, to reprogram a device’s firmware (potentially
    enabling full control over a device), the attacker first needs to identify the
    firmware programming port on the PCB.
  prefs: []
  type: TYPE_NORMAL
- en: For PCB-level attacks, all that’s needed to access many devices is a screwdriver.
    Some devices implement physical tamper resistance and tamper response, such as
    FIPS (Federal Information Processing Standard) 140 level 3 or 4 validated devices
    or payment terminals. Although it’s an interesting sport in itself, bypassing
    tamper-proofing and getting to the electronics is beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: One example of a PCB-level attack is taking advantage of SoC options that are
    configured by pulling certain pins high or low using *straps*. The straps are
    visible on the PCB as 0 Ω (zero-ohm) resistors (see [Figure 1-6](#figure1-6)).
    These SoC options may well include debug enablement, booting without signature
    checking, or other security-related settings.
  prefs: []
  type: TYPE_NORMAL
- en: '![f01006](image_fi/278748c01/f01006.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-6: Zero-ohm resistors (R29 and R31)'
  prefs: []
  type: TYPE_NORMAL
- en: Adding or removing the straps to change configuration is trivial. Although modern
    multilayer PCBs and surface-mount devices complicate modifications, all you need
    are a steady hand, a microscope, tweezers, a heat gun, and, above all, patience
    to complete the task.
  prefs: []
  type: TYPE_NORMAL
- en: Another useful attack at the PCB level is to read the flash chip on a PCB, which
    typically contains most of the software that runs in the device, revealing a treasure
    trove of information. Although some flash devices are read-only, most allow you
    to write critical changes back to them in a way that removes or limits security
    functions. The flash chip likely enforces read-only permissions via some access
    control mechanism, which may be susceptible to fault injection.
  prefs: []
  type: TYPE_NORMAL
- en: For systems designed with security in mind, changes to flash should result in
    a non-bootable system because the flash image needs to include a valid digital
    signature. Sometimes the flash image is scrambled or encrypted; the former can
    be reversed (we’ve seen simple XORs), and the latter requires acquiring the key.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll discuss PCB reverse engineering in more detail in Chapter 3, and we’ll
    discuss controlling the clock and power when we look at interfacing with real
    targets.
  prefs: []
  type: TYPE_NORMAL
- en: Logical Attacks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Logical attacks* work at the level of logical interfaces (for instance, by
    communicating through existing I/O ports). Unlike a PCB-level attack, a logical
    attack does not work at the physical level. A logical attack is aimed at the embedded
    device’s software or firmware and tries to breach the security without physical
    hacking. You could compare it to breaking into a house (device) by realizing that
    the owner (software) has a habit of leaving the back door (interface) unlocked;
    hence, no lockpicking is needed.'
  prefs: []
  type: TYPE_NORMAL
- en: Famous logical attacks revolve around memory corruption and code injection,
    but logical attacks have a much wider scope. For example, if the debugging console
    is still available on a hidden serial port of an electronic lock, sending the
    “unlock” command may trigger the lock to open. Or, if a device powers down some
    countermeasures in low-power conditions, injecting low-battery signals can disable
    those security measures. Logical attacks target design errors, configuration errors,
    implementation errors, or features that can be abused to break the security of
    a system.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging and Tracing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Among the most powerful control mechanisms built into a CPU during design and
    manufacture are the hardware debugging and tracing functions. This is often implemented
    on top of a *Joint Test Action Group (JTAG)*or *Serial Wire Debug (SWD)* interface.
    [Figure 1-7](#figure1-7) shows an exposed JTAG header.
  prefs: []
  type: TYPE_NORMAL
- en: Be aware that on secure devices, fuses, a PCB strap, or some proprietary secret
    code or challenge/response mechanism can turn off debugging and tracing. Perhaps
    only the JTAG header is removed on less-secure devices (more on JTAG in the following
    chapters).
  prefs: []
  type: TYPE_NORMAL
- en: '![f01007](image_fi/278748c01/f01007.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-7: PCB with exposed JTAG header. Normally, it’s not labeled as nicely
    as in this example!'
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzing Devices
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Fuzzing* is a technique borrowed from software security that aims at identifying
    security problems in code specifically. Fuzzing’s typical goal is to find crashes
    to exploit for code injection. *Dumb fuzzing* amounts to sending random data to
    a target and observing its behavior. Robust and secure targets remain stable under
    such an attack, but less-robust or less-secure targets may show abnormal behavior
    or crash. Crash dumps or a debugger inspection can pinpoint the source of a crash
    and its exploitability. *Smart fuzzing* focuses on protocols, data structures,
    typical crash-causing values, or code structure and is more effective at generating
    *corner cases* (situations that should not normally be expected) that will crash
    a target. *Generation-based fuzzing* creates inputs from scratch, whereas *mutation-based
    fuzzing* takes existing inputs and modifies them. *Coverage-guided fuzzing* uses
    additional data (for instance, coverage information about which parts of the program
    are exercised with a particular input) to allow you to find deeper bugs.'
  prefs: []
  type: TYPE_NORMAL
- en: You also can apply fuzzing to devices, though under much more challenging circumstances
    as compared to fuzzing software. With device fuzzing, it is typically much harder
    to obtain coverage information about the software running on it, because you may
    have much less control over that software. Fuzzing over an external interface
    without further control over the device disallows obtaining coverage information,
    and in some cases, doing so makes establishing whether a corruption occurred difficult.
    Finally, fuzzing is effective when it can be done at high speed. In software fuzzing,
    this can be thousands to millions of cases per second. Achieving this performance
    is nontrivial on embedded devices. *Firmware re-hosting*is a technique that takes
    a device’s firmware and puts it in an emulation environment that can be run on
    PCs. It resolves most of the issues with on-device fuzzing, at the cost of having
    to create a working emulation environment.
  prefs: []
  type: TYPE_NORMAL
- en: Flash Image Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most devices include flash chips that are external to the main CPU. If a device
    is software-upgradeable, you can often find firmware images on the internet. Once
    you’ve obtained an image, you can use various flash image analysis tools, such
    as *binwalk*, to help identify the various parts of the image, including code
    sections, data sections, filesystem(s), and digital signatures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, disassembly and decompiling of the various software images is very
    important in determining possible vulnerabilities. There is also some initial
    interesting work regarding static analysis (such as concolic execution) of device
    firmware. See “BootStomp: On the Security of Bootloaders in Mobile Devices” by
    Nilo Redini et al.'
  prefs: []
  type: TYPE_NORMAL
- en: Noninvasive Attacks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Noninvasive attacks don’t physically modify a chip. Side-channel attacks use
    some measurable behavior of a system to disclose secrets (for example, measuring
    a device’s power consumption to extract an AES key). A fault attack uses fault
    injection into the hardware to circumvent a security mechanism; for example, a
    large electromagnetic (EM) pulse can disable a password verification test so that
    it accepts any password. (Chapters 4 and 5 of this book are devoted to these topics.)
  prefs: []
  type: TYPE_NORMAL
- en: Chip-Invasive Attacks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This class of attack targets the package or silicon inside a package and, therefore,
    operates at a miniature scale—that of the wires and gates. Doing this requires
    much more sophisticated, advanced, and expensive techniques and equipment than
    we’ve discussed so far. Such attacks are beyond the scope of this book, but here’s
    a brief look at what advanced attackers can do.
  prefs: []
  type: TYPE_NORMAL
- en: Decapsulation, Depackaging, and Rebonding
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Decapsulation* is the process of removing some of the IC packaging material
    using chemical warfare, usually by dripping fuming nitric or sulfuric acid onto
    the chip package until it dissolves. The result is a hole in the package through
    which you can examine the microchip itself, and if you do it properly, the chip
    still works.'
  prefs: []
  type: TYPE_NORMAL
- en: When *depackaging*, you dunk the whole package in acid, after which the entire
    chip is laid bare. You need to rebond the chip to restore its functionality, which
    means reattaching the tiny wires that normally connect the chip to the pins of
    a package (see [Figure 1-8](#figure1-8)).
  prefs: []
  type: TYPE_NORMAL
- en: '![f01008](image_fi/278748c01/f01008.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-8: A decapped chip that shows exposed bonding wires (Travis Goodspeed,
    CC BY 2.0 license)'
  prefs: []
  type: TYPE_NORMAL
- en: Even though they may die in the process, dead chips are fine for imaging and
    optical reverse engineering. However, for most attacks, chips must be alive.
  prefs: []
  type: TYPE_NORMAL
- en: Microscopic Imaging and Reverse Engineering
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Once the chip is exposed, the first step is to identify the larger functional
    blocks of the chip and, specifically, find the blocks of interest. [Figure 1-2](#figure1-2)
    shows some of these structures. The largest blocks on the die will be memory,
    like static RAM (SRAM) for CPU caches or tightly coupled memory, and ROM for boot
    code. Any long, mostly straight bunches of lines are buses interconnecting CPUs
    and peripherals. Simply knowing the relative sizes and what the various structures
    look like allows you to begin reverse engineering chips.
  prefs: []
  type: TYPE_NORMAL
- en: When a chip is decapped, as in [Figure 1-8](#figure1-8), you can see only the
    top metal layer. To reverse engineer the entire chip, you also need to *delayer*
    it, which means polishing off the chip’s individual metal layers to expose the
    one below it.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 1-9](#figure1-9) shows a cross section of a *complementary metal oxide
    semiconductor (CMOS)* chip, which is how most modern chips are built. As you can
    see, a number of layers and vias of copper metals eventually connect the transistors
    (polysilicon/substrate). The lowest-level metal is used for creating *standard
    cells*, which are the elements that create logical gates (AND, XOR, and so on)
    from a number of transistors. Top-level metals are usually used for power and
    clock routing.'
  prefs: []
  type: TYPE_NORMAL
- en: '![f01009](image_fi/278748c01/f01009.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-9: Cross section of CMOS'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 1-10](#figure1-10) shows photographs of the different layers inside
    a typical chip.'
  prefs: []
  type: TYPE_NORMAL
- en: '![f01010](image_fi/278748c01/f01010.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-10: Different layers inside a CMOS chip (image courtesy of Christopher
    Tarnovsky, [semiconductor.guru@gmail.com](http://mailto:semiconductor.guru@gmail.com))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Good chip imaging allows you to rebuild a netlist from the images or a binary
    dump of the boot ROM. A *netlist* is essentially a description of how all gates
    are connected, which encompasses all the digital logic in a design. Both a netlist
    and a boot ROM dump allow attackers to find weaknesses in the code or chip design.
    Chris Gerlinsky’s “Bits from the Matrix: Optical ROM Extraction” and Olivier Thomas’s
    “Integrated Circuit Offensive Security,” presented at the Hardwear.io 2019 conference,
    provide good introductions to the topic.'
  prefs: []
  type: TYPE_NORMAL
- en: Scanning Electron Microscope Imaging
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A *scanning electron microscope (SEM)* performs a raster scan of a target using
    an electron beam and takes measurements from an electron detector to form an image
    of the scanned target with a resolution of better than 1 nm, allowing you to image
    individual transistors and wires. As with microscope imaging, you can create netlists
    from the images.
  prefs: []
  type: TYPE_NORMAL
- en: Optical Fault Injection and Optical Emission Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Once a chip surface is visible, it’s possible to have “phun with photons.”
    Due to an effect called *hot carrier luminescence*, switching transistors occasionally
    emit photons. With an IR-sensitive *charge-coupled device (CCD)* sensor like those
    used in hobbyist astronomy, or an *avalanche photodiode (APD)* if you want to
    get fancy, you can detect active photon areas, which contributes to the reverse
    engineering process (or more specifically to side-channel analysis), as in correlating
    secret keys with photon measurements. See “Simple Photonic Emission Analysis of
    AES: Photonic Side Channel Analysis for the Rest of Us” by Alexander Schlösser
    et al.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to using photons to observe processes, you can also use them to
    inject faults by changing the gates’ conductivity, which is called *optical fault
    injection* (see Chapter 5 and Appendix A for more details).
  prefs: []
  type: TYPE_NORMAL
- en: Focused Ion Beam Editing and Microprobing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A *focused ion beam (FIB)* , pronounced “fib,” uses a beam of ions either to
    mill away parts of a chip or deposit material onto a chip at a nanometer scale,
    allowing attackers to cut chip wires, re-route chip wires, or create probe pads
    for microprobing. FIB edits take time and skill (and an expensive FIB), but as
    you can imagine, such edits can circumvent many hardware security mechanisms if
    an attacker is able to locate them. The numbers in [Figure 1-11](#figure1-11)
    show holes a FIB created in order to access lower metal layers. The “hat” structures
    around the holes are created to bypass an active shield countermeasure.
  prefs: []
  type: TYPE_NORMAL
- en: '*Microprobing* is a technique used to measure or inject current into a chip
    wire, which may not require a FIB probe pad for larger feature sizes. Skill is
    a prerequisite for performing any of these attacks, although once an attacker
    has the resources to perform attacks at this level, it is extraordinarily difficult
    to maintain security.'
  prefs: []
  type: TYPE_NORMAL
- en: '![f01011](image_fi/278748c01/f01011.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-11: A number of FIB edits to facilitate microprobing (image courtesy
    of Christopher Tarnovsky, [semiconductor.guru@gmail.com](http://mailto:semiconductor.guru@gmail.com))'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve covered a number of different attacks relative to embedded systems here.
    Remember that any single attack is enough to compromise a system. The cost and
    skills vary drastically, however, so be sure to understand what sort of security
    objective you require. Resisting an attack from someone with a million-dollar
    budget and resisting an attack from someone with $25 and a copy of this book are
    very different endeavors.
  prefs: []
  type: TYPE_NORMAL
- en: Assets and Security Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The question to ask when considering the assets being designed into the product
    is, “What assets do I really care about?” An attacker will ask the same question.
    The assets’ defender might arrive at a wide range of answers to this seemingly
    simple question. The CEO of a company may focus on brand image and financial health.
    The chief privacy officer cares about the confidentiality of consumers’ private
    information, and the cryptographer in residence is paranoid about secret key material.
    All of those responses to the question are interrelated. If keys are exposed,
    customer privacy may be impacted, which in turn negatively impacts brand image
    and consequently threatens the financial health of the entire company. However,
    at each level, the protection mechanisms differ.
  prefs: []
  type: TYPE_NORMAL
- en: An asset also represents a value to an attacker. What exactly is valuable depends
    on the attacker’s motivation. It might be a vulnerability that allows the attacker
    to sell a code execution exploit to other attackers. The desired asset could be
    credit-card details or victims’ payment keys. Corporate-world intentions might
    be to target a competitor’s brand maliciously.
  prefs: []
  type: TYPE_NORMAL
- en: When threat modeling, analyze both attacker and defender perspectives. For the
    purposes of this book, we limit ourselves to technical assets on a device, so
    we assume that our assets are represented as some sequence of bits on a target
    device that are to remain confidential and integrity-protected. *Confidentiality*
    is the property of keeping an asset hidden from attackers, and *integrity* is
    the property of not allowing an attacker to modify it.
  prefs: []
  type: TYPE_NORMAL
- en: As a security enthusiast, you may be wondering why we didn’t mention availability.
    *Availability* is the property of maintaining a responsive and functional system,
    and it’s particularly important for data centers and systems that deal with safety,
    such as industrial control systems and autonomous vehicles, where interruption
    in system functionality can’t happen.
  prefs: []
  type: TYPE_NORMAL
- en: 'It makes sense to defend asset availability only in situations when a device
    cannot be physically accessed, such as when access is via the network and internet.
    Making such services unavailable is the purpose of denial-of-service attacks that
    take down websites. For embedded devices, compromising availability is trivial:
    just switch it off, hit it with a hammer, or blow it up.'
  prefs: []
  type: TYPE_NORMAL
- en: A *security objective* is how well you want to protect the assets you define,
    against what types of attacks and attackers, and for how long. Defining security
    objectives helps focus the design arguments on the strategies to counter the expected
    threats. Inevitably trade-offs will occur due to many possible scenarios, and
    although we realize there are no one-size-fits-all solutions, we give some common
    examples next.
  prefs: []
  type: TYPE_NORMAL
- en: Though not very common, specification of a device’s strengths and weaknesses
    is a sure sign of security maturity of a vendor.
  prefs: []
  type: TYPE_NORMAL
- en: Confidentiality and Integrity of Binary Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Typically, for binary code, the main objective is integrity protection or making
    sure the code that runs on the device is the code the author intended. Integrity
    protection restricts code modification but presents a double-edged sword. Strong
    integrity protection can lock down a device from its owner, limiting the code
    available to run on it. A whole community of hackers tries to circumvent these
    mechanisms on gaming consoles in order to run their own code. On the other hand,
    integrity protection certainly has the unintended benefit of protecting against
    malware infecting the boot chain, game piracy, or governments installing a backdoor.
  prefs: []
  type: TYPE_NORMAL
- en: The goal for confidentiality as a security objective is to make it more difficult
    to copy intellectual property, such as digital content, or to find vulnerabilities
    in firmware. The latter also makes it harder for bona fide security researchers
    to find and report vulnerabilities, as well as for attackers to exploit those
    vulnerabilities. (See the “Disclosing Security Issues” section on page 33 for
    more on this complex dilemma.)
  prefs: []
  type: TYPE_NORMAL
- en: Confidentiality and Integrity of Keys
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Cryptography turns data protection problems into key protection problems. In
    practice, keys are typically easier to protect than full data blobs. For threat
    modeling, note that there are now two assets: the plaintext data and the key itself.
    Confidentiality of keys as an objective, therefore, usually links to confidentiality
    of the data that is being protected.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, integrity is important when public keys are stored on a device
    for authenticity checks: if attackers can substitute the original public keys
    with their own, they can sign arbitrary data that passes signature verification
    on the device. However, integrity is not always an objective for keys; for instance,
    if the purpose of a key is to decrypt a stored data blob, modifying the key simply
    results in the inability to perform the decryption.'
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting aspect is how keys are securely injected into a device or
    generated at the manufacturing stage. An option is to encrypt or sign the keys
    themselves, but that involves yet another key. It’s turtles all the way down.
    Somewhere in the system exists a *root of trust*, a key or mechanism that we simply
    have to trust.
  prefs: []
  type: TYPE_NORMAL
- en: A typical solution is to trust the manufacturing process during initial key
    generation or during key injection. For instance, *Trusted Platform Module (TPM)*
    specification v2.0 calls for an *endorsement primary seed (EPS)*. This EPS is
    a unique identifier for each TPM, and it is used to derive some primary key material.
    As per the specification, this EPS must be injected into the TPM or created on
    the TPM during manufacturing.
  prefs: []
  type: TYPE_NORMAL
- en: This practice does limit exposure of key material, but it creates a critical
    central collection point for key material at the manufacturing facility. Key injection
    systems especially must be well protected to avoid compromising the injected keys
    for *all* parts being configured by this system. Best practices involve key generation
    on-device, such that the manufacturing facility doesn’t have access to all keys,
    as well as secret splitting, making sure that different stages in manufacturing
    inject or generate different parts of the key material.
  prefs: []
  type: TYPE_NORMAL
- en: Remote Boot Attestation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Boot attestation* is the ability to verify cryptographically that a system
    did in fact boot from authentic firmware images. *Remote boot attestation*is the
    ability to do so remotely. Two parties are involved in attestation: the *prover*
    intends to prove to the *verifier* that some *measurements* of the system have
    not been tampered with. For instance, you can use remote boot attestation to allow
    or deny a device access to an enterprise network or to decide to provide an online
    service to a device. In the latter case, the device is the prover, the online
    service is the verifier, and the measurements are hashes of configuration data
    and (firmware) images used during boot. To prove the measurements are not tampered
    with, they are digitally signed using a private key during the boot stages. The
    verifier can check the signatures against an allow or block list and should have
    a means of verifying the private key used for creating the signatures. The verifier
    detects tampering and ensures that the remote device is not running old and perhaps
    vulnerable boot images.'
  prefs: []
  type: TYPE_NORMAL
- en: As always, this presents a few practical issues. First, the verifier must somehow
    be able to trust the prover’s signing key—for instance, by trusting a certificate
    containing the prover’s public key, which is signed by some trustworthy authority.
    In the best case, this authority has been able to establish trust during the manufacturing
    process, as described previously. Second, the more comprehensive the coverage
    of the boot images and data, the more there will be different configurations in
    the field. This means that it becomes infeasible to allow all *known-good* configurations,
    so one has to revert to blocking *known-bad* configurations. However, determining
    a *known-bad* configuration is not a trivial exercise and can usually be done
    only after a modification has been detected and analyzed.
  prefs: []
  type: TYPE_NORMAL
- en: Note that boot attestation guards the boot-time components that are hashed for
    authenticity. It does not guard against runtime attacks, such as code injection.
  prefs: []
  type: TYPE_NORMAL
- en: Confidentiality and Integrity of Personally Identifiable Information
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Personally identifiable information (PII)* is data that can identify an individual.
    The obvious data includes names, cell phone numbers, addresses, and credit card
    numbers, but the less obvious data could be accelerometer data recorded in a wearable
    device. PII confidentiality becomes an issue when applications installed on a
    device exfiltrate this information. For example, accelerometer data that characterizes
    a person’s walking gait can be used to identify that person: see “Gait Identification
    Using Accelerometer on Mobile Phone” by Hoang Minh Thang et al. Mobile phone power
    consumption data can pinpoint a person’s location from the way the radio in the
    phone consumes power, depending on the distance to cell towers, as described in
    “PowerSpy: Location Tracking Using Mobile Device Power Analysis” by Yan Michalevsky
    et al.'
  prefs: []
  type: TYPE_NORMAL
- en: The medical field has regulation around PII as well. The *Health Insurance Portability
    and Accountability Act (HIPAA)* of 1996 is a law in the United States with a strong
    focus on privacy for medical information and applies to any system processing
    patient PII. HIPAA has rather nonspecific requirements for technical security.
  prefs: []
  type: TYPE_NORMAL
- en: Integrity of PII data is essential to avoid impersonation. In banking smart
    cards, the key material is tied to an account and, therefore, to an identity.
    EMVCo, a credit-card consortium, has very explicit technical requirements in contrast
    to HIPAA. For instance, key material must be protected against logical, side-channel,
    and fault attacks, and this protection needs to be proven by actual attacks performed
    by an accredited lab.
  prefs: []
  type: TYPE_NORMAL
- en: Sensor Data Integrity and Confidentiality
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You have just learned how sensor data is related to PII. Integrity has to be
    important, because the device needs to sense and record its environment accurately.
    This is even more crucial when the system is using sensor input to control actuators.
    A great (though disputed) example is that of a US RQ-170 drone being forced to
    land in Iran, allegedly after its GPS signal was spoofed to make it believe it
    was landing at a US base in Afghanistan.
  prefs: []
  type: TYPE_NORMAL
- en: When a device is using some form of artificial intelligence for decision making,
    the integrity of the decisions is challenged by a field of research called *adversarial
    machine learning*. One example is exploiting weaknesses in neural net classifiers
    by artificially modifying pictures of a stop sign. To humans, the modification
    is not detectable, but the picture can be completely unrecognizable using standard
    image recognition algorithms when it should in fact have been recognizable. Although
    the recognition of the neural net may be foiled, modern self-driving cars have
    a database of the locations of signs that they can fall back to, so in this particular
    instance, it shouldn’t be a safety issue. “Practical Black-Box Attacks Against
    Machine Learning” by Nicolas Papernot et al. has more details.
  prefs: []
  type: TYPE_NORMAL
- en: Content Confidentiality Protection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Content protection boils down to trying to make sure people pay for the media
    content they consume and that they stay within some license restrictions, such
    as date and geographic location, using *digital rights/restrictions management
    (DRM)*. DRM mostly depends on encryption of the data stream for transport of content
    in/out of a device and on access control logic inside a device to deny software
    access to plaintext content. For mobile devices, most of the protection requirements
    are aimed at software-only attacks, but for set-top boxes, protection requirements
    include side-channel and fault attacks. Thus, set-top boxes are considered harder
    to break and are used for higher-value content.
  prefs: []
  type: TYPE_NORMAL
- en: Safety and Resilience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Safety* is the property of not causing harm (to people, for example), and
    *resilience* is the ability to remain operational in case of (non-malicious) failures.
    For instance, a microcontroller in a satellite will be subject to intensive radiation
    that causes so-called *single event upsets (SEUs)*. SEUs flip bits in the state
    of the chip, which could lead to errors in its decision making. The resilient
    solution is to detect this and correct the error or detect and reset to a known-good
    state. Such resilience may not necessarily be secure; it gives someone attempting
    fault injection unlimited tries as the system keeps accepting abuse.'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, it isn’t safe to shut down an autonomous vehicle’s control unit at
    highway speeds as soon as a sensor indicates malicious activity. First, any detector
    can generate false positives, and, second, this potentially allows an attacker
    to use the sensor to harm all passengers. As with all objectives, this one presents
    the product’s developer with trade-offs between security and safety/resilience.
    Resilience and safety are not the same as security; sometimes they are at odds
    with security. For an attacker, this means opportunities exist to break a device
    because of good intentions to make it safe or resilient.
  prefs: []
  type: TYPE_NORMAL
- en: Countermeasures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We define *countermeasures* as any (technical) means to reduce the probability
    of success or impact of an attack. Countermeasures have three functions: protect,
    detect, and respond. (We discuss some of these countermeasures further in Chapter
    14.)'
  prefs: []
  type: TYPE_NORMAL
- en: Protect
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This category of countermeasures attempts to avoid or mitigate attacks. An example
    is encrypting the contents of flash memory against prying eyes. If the key is
    hidden well, it provides almost unbreakable protection. Other protection measures
    offer only partial protection. If a single CPU instruction corruption can cause
    an exploitable fault, randomizing the critical instruction’s timing over five
    clock cycles still gives an attacker a 20 percent probability of hitting it. Bypassing
    some protection measures completely is possible because they protect only against
    a specific class of attacks (for instance, a side-channel countermeasure does
    not protect against code injection).
  prefs: []
  type: TYPE_NORMAL
- en: Detect
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This category of countermeasure requires either some kind of hardware detection
    circuitry or detection logic in software. For instance, you can monitor a chip’s
    power supply for voltage peaks or dips that are indicative of a voltage fault
    attack. You can also use software to detect anomalous states. For example, systems
    that constantly analyze network traffic or application logs can detect attacks.
    Other common anomaly detection techniques are the verification of so-called stack
    canaries, detecting guard pages that have been accessed, finding switch statements
    with no matching case, and cyclic redundancy check (CRC) errors on internal variables,
    among many others.
  prefs: []
  type: TYPE_NORMAL
- en: Respond
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Detection has little purpose without a response. The type of response depends
    on the device’s use case. For highly secure devices, like payment smart cards,
    wiping all device secrets (effectively self-inflicting a denial-of-service attack)
    would be wise when detecting an attack. Doing this would not be a good idea in
    safety-critical systems that must continue to operate. In those cases, phoning
    home or falling back to a crippled-but-safe mode are more appropriate responses.
    Another undervalued but effective response for human attackers is to bore the
    will to live out of them (for instance, by resetting a device and increasingly
    lengthening the boot time).
  prefs: []
  type: TYPE_NORMAL
- en: Countermeasures are critical to building a secure system. Especially in hardware,
    where physical attacks may be impossible to protect against fully, adding detection
    and response often raises the bar beyond what an attacker is willing to do or
    is even capable of doing.
  prefs: []
  type: TYPE_NORMAL
- en: An Attack Tree Example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we’ve described the four ingredients needed for effective threat modeling,
    let’s start with an example where we, as attackers, want to hack our way into
    an IoT toothbrush with the purpose of extracting confidential information and
    (just for fun) increasing the brushing speed to something that 9 out of 10 dentists
    would disapprove of (but that last one loves a good challenge).
  prefs: []
  type: TYPE_NORMAL
- en: 'In our sample attack tree, shown in [Figure 1-12](#figure1-12), we have the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Rounded boxes indicate the states an attacker is in or assets an attacker has
    compromised (“nouns”).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Square boxes indicate successful attacks the attacker has performed (“verbs”).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A solid arrow shows the consequential flow between the preceding states and
    attacks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dotted arrow indicates attacks that are mitigated by some countermeasure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Several incoming arrows indicate that “any single one of the arrows can lead
    to this.”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The “and” triangle means all the incoming arrows must be satisfied.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The numbers in the attack tree mark the stages of the toothbrush attack. As
    attackers, we have physical access to an IoT toothbrush (1). Our mission is to
    install a telnet backdoor on the toothbrush to determine what PII is present on
    the device (8) and also to run the toothbrush at ludicrous speed (11).
  prefs: []
  type: TYPE_NORMAL
- en: '![f01012](image_fi/278748c01/f01012.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-12: IoT toothbrush attack tree'
  prefs: []
  type: TYPE_NORMAL
- en: Lowercase letters indicate the attacks, and Roman numerals indicate the mitigations.
    One of the first things we do is desolder the flash and read out the contents—all
    16MB of it (a). We see, however, that the image has no readable strings. After
    some entropy analysis, the content appears to be either encrypted or compressed,
    but since there is no header identifying the compression format, we assume this
    content is encrypted as shown in attack (2) and attack mitigation (i). To decrypt
    it, we need the encryption key. It doesn’t seem to be stored in flash, a mitigation
    shown at (ii), so it’s likely stored somewhere in ROM or fuses. Without access
    to a scanning electron microscope, we are unable to “read them out” from silicon.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we decide to poke around with power analysis. We hook up a power probe
    and oscilloscope and take a power trace of the system while it is booting. The
    trace shows about one million little peaks. Knowing from our flash readout that
    the image is 16MB, we deduce that each peak corresponds to 16 bytes of encrypted
    data. We’ll just assume this is an AES-128 encryption in either of the common
    *electronic code block (ECB)* or *cipher block chaining (CBC)* modes. *ECB* is
    a mode where each block is decrypted independently of other blocks, and *CBC*
    is a mode where the decryption of the latter blocks depends on the earlier blocks.
    Since we know the firmware image’s ciphertext, we can try a power analysis attack
    based on the peaks we measure. After much preprocessing of the traces and doing
    a differential power analysis (DPA) attack (b), we’re able to identify a likely
    key candidate. (Don’t worry; you will learn what DPA is as you progress further
    through this book.) Decryption with ECB produces garbage, but CBC gives us several
    readable strings in attack (c); it seems we have found the right key at stage
    (3) and have successfully decrypted the image at stage (4)!
  prefs: []
  type: TYPE_NORMAL
- en: From the decrypted image, we can use traditional software reverse engineering
    (g) techniques to identify which code blocks do what, where data is stored, how
    actuators are driven, and, important from a security point of view, we can now
    look for vulnerabilities in the code (9). Further, we modify the decrypted image
    at stage (d) to include a backdoor that will allow us to telnet into the toothbrush
    remotely (5).
  prefs: []
  type: TYPE_NORMAL
- en: We re-encrypt the image and flash it in attack (d), only to discover that the
    toothbrush doesn’t boot. We have run into what is most likely firmware signature
    verification. Without the private key used to sign the images, we cannot run a
    modified image due to mitigation (iii). One common attack on this countermeasure
    is that of voltage fault injection. With fault injection, we’ll aim to corrupt
    the one instruction responsible for deciding whether to accept or reject a firmware
    image. This is usually a comparison that uses the Boolean result returned from
    an `rsa_signature_verify()` function. Since this code is implemented in ROM, we
    cannot really get information about the implementation from reverse engineering.
    So, we try an old trick—take a side-channel trace when the unmodified image boots
    and compare it to a side-channel trace of booting a modified image in attack (e).
    The point where the traces differ is likely to be the moment where the boot code
    decides whether to accept the firmware image in stage (6). We generate a fault
    at that instant to attempt to modify the decision.
  prefs: []
  type: TYPE_NORMAL
- en: We load the malicious image and drop the voltage for a few hundred nanoseconds
    at a random point in a 5-microsecond window in attack (f), at around the instant
    when we determined the decision is made. After a few hours of repeating this attack,
    we’re in luck; the toothbrush boots our malicious image in stage (7). Now that
    the modified code allows us to telnet in, we reach the stage (8), where we can
    remotely control the brushing and spy on any usage of the brush. And now in the
    final and fun stage (11), we turn up the speed to ludicrous!
  prefs: []
  type: TYPE_NORMAL
- en: This is obviously a silly example, since the obtained information and access
    are likely not valuable enough for a serious attacker; physical access is needed
    to perform the side-channel and fault attacks, and a reset of the device by the
    proper owner causes a denial of service. However, it’s an enlightening exercise,
    and it’s always worthwhile to play with these toy scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: When drawing attack trees, it’s easy to get carried away and make the tree huge.
    Remember that attackers probably will try only a few of the easiest attacks (this
    tool helps identify what those are). Focus on the relevant attacks, which you
    can determine by profiling the attacker and attack capabilities earlier in the
    threat modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Identification vs. Exploitation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The toothbrush attack path concentrates on the *identification* *phase* of an
    attack by finding a key, reverse engineering the firmware, modifying the image,
    and discovering the fault-injection instant. Remember that exploitation is the
    endeavor to scale up the hack by accessing multiple devices. When repeating the
    attack on another device, you can reuse much of the information gained during
    identification. Subsequent attack results require only flashing an image in attack
    (d) at stage (5), knowing the fault injection point in stage (6), and generating
    the fault by attack (f). Exploitation effort is always lower than identification
    effort. In some formalisms of creating attack trees, each arrow is annotated with
    the attack cost and effort, but here we avoid getting too much into quantitative
    risk modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The toothbrush attack is not scalable, because the exploitation phase requires
    physical access. For PII or remote actuation, it’s usually of interest for an
    attacker only if this can be done at scale.
  prefs: []
  type: TYPE_NORMAL
- en: However, let’s say that in our reverse engineering attack (g), stage (9) manages
    to identify a vulnerability for which we create an exploit (h) in stage (10).
    We find that the vulnerability is accessible through an open TCP port, so attack
    (j) can exploit this vulnerability remotely. This instantly changes the attack’s
    entire scale. Having used hardware attacks in the identification phase, we can
    rely solely on remote software attacks in the exploitation phase (12). Now, we
    can attack any toothbrush, gain access to anyone’s brushing habits, and irritate
    gums on a global scale. What a time to be alive.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the Attack Tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The attack tree helps visualize attack paths in order to discuss them as a team,
    identify points where additional countermeasures can be built, and analyze the
    efficacy of existing countermeasures. For instance, it is easy to see that mitigation
    by firmware image encryption (i) has forced the attacker to use a side-channel
    attack (b), which is more difficult than simply reading out a memory. Similarly,
    mitigation by firmware image signing (iii) forced an attacker into a fault-injection
    attack (f).
  prefs: []
  type: TYPE_NORMAL
- en: However, the main risk is still the scalable attack path through exploitation
    (j), which is currently unmitigated. Obviously, the vulnerability should be patched,
    anti-exploitation countermeasures should be introduced, and network restrictions
    should be put in place to disallow anybody from directly connecting to the toothbrush
    remotely.
  prefs: []
  type: TYPE_NORMAL
- en: Scoring Hardware Attack Paths
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Apart from visualizing attack paths for analysis, we can also add some quantification
    to figure out which attacks are easier or cheaper for an attacker. In this section,
    we introduce several industry-standard rating systems.
  prefs: []
  type: TYPE_NORMAL
- en: The *Common Vulnerability Scoring System (CVSS)* attempts to score vulnerabilities
    for severity, typically in the context of networked computers in an organization.
    It assumes the vulnerability is known and tries to score how bad it would be if
    it were to be exploited. The *Common Weakness Scoring System (CWSS)*quantifies
    weaknesses in systems, but those weaknesses are not necessarily vulnerabilities
    and not necessarily in the context of networked computers. Finally, the *Joint
    Interpretation Library (JIL)* is used to score (hardware) attack paths in the
    Common Criteria (CC) certification scheme.
  prefs: []
  type: TYPE_NORMAL
- en: All of these scoring methods have various parameters and scores for each parameter,
    which together create a final tally to help compare various vulnerabilities or
    attack paths. These scoring methods also share the advantage of replacing indefinite
    arguments about parameters with scores that make sense only in the target context
    of the scoring method. [Table 1-1](#table1-1) provides an overview of the three
    ratings and where they are applicable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1-1: Overview of Attack Rating Systems'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Common Vulnerability Scoring System** | **Common Weakness Scoring System**
    | **Common Criteria Joint Interpretation Library** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Purpose** | Helps organizations with their vulnerability management processes
    | Prioritizes software weakness addressing the needs of government, academia,
    and industry | Rates attacks in order to pass/fail CC evaluation |'
  prefs: []
  type: TYPE_TB
- en: '| **Impact** | Distinguishes confidentiality/integrity/availability | Technical
    impact 0.0–1.0, acquired privilege (layer) | N/A |'
  prefs: []
  type: TYPE_TB
- en: '| **Asset** **v****alue** | N/A | Business impact 0.0–1.0 | N/A |'
  prefs: []
  type: TYPE_TB
- en: '| **Identification** **c****ost** | Assumes identification already happened
    | Likelihood of discovery | Identification phase rating for elapsed time, expertise,
    knowledge, access, equipment, and open samples |'
  prefs: []
  type: TYPE_TB
- en: '| **Exploitation** **c****ost** | Various factors; no hardware aspects | Various
    factors; no hardware aspects | Exploitation phase rating |'
  prefs: []
  type: TYPE_TB
- en: '| **Attack** **v****ector** | Four levels, from physical to remote | Level
    0.0–1.0, from physical to internet | Assumes physically present attacker |'
  prefs: []
  type: TYPE_TB
- en: '| **External** **m****itigations** | “Modified” category includes mitigations
    | External control effectiveness | No external mitigations |'
  prefs: []
  type: TYPE_TB
- en: '| **Scalability** | Not really, some related aspects | Not really, some related
    aspects | Low exploitation cost may imply scalability |'
  prefs: []
  type: TYPE_TB
- en: In a defensive context, you can use ratings to judge the impact of an attack
    after it occurs as a means to decide how to respond to an attack. For instance,
    if a vulnerability is detected in a piece of software, CVSS scoring can help decide
    whether to roll out an emergency patch (with all its associated costs) or push
    out the fix in the next major version if the vulnerability is minor.
  prefs: []
  type: TYPE_NORMAL
- en: You can also use scoring in a defensive context to judge which countermeasures
    are needed. In the context of Common Criteria Smart Card certification, the JIL
    scoring actually becomes a critical part of the security objective—the chip must
    resist attacks rated at up to 30 points to be considered resistant to attackers
    of high attack potential. The SOG-IS document “Application of Attack Potential
    to Smartcards” explains the scoring, and it touches upon a number of hardware
    attacks. To give you an idea of the rating, if it takes a few weeks to pull out
    a secret key using a two-laser beam system for laser fault injection, this attack
    rates 30 or below. If it takes six months to pull out a key using a side-channel
    attack, implementing a countermeasure is not necessary, as this attack rates 31
    or higher.
  prefs: []
  type: TYPE_NORMAL
- en: The CWSS is aimed at rating weaknesses in systems before they are exploited.
    It is a useful scoring method during development, as it helps assign priorities
    to the weaknesses’ remedies. Everyone knows that each fix comes at a cost and
    that attempting to fix all bugs isn’t practical, so rating weaknesses allows developers
    to concentrate on the most significant ones.
  prefs: []
  type: TYPE_NORMAL
- en: In reality, most attackers do some sort of scoring as well to minimize the cost
    and maximize the impact of the attack. Although attackers do not publish much
    on these topics, Dino Dai Zovi had a cool talk called “Attacker Math 101” at SOURCE
    Boston 2011 that attempted to put some bounds on attacker costing.
  prefs: []
  type: TYPE_NORMAL
- en: 'These ratings are limited, ambiguous, imprecise, subjective, and not market
    specific, but they form a good starting point for discussing an attack or vulnerability.
    If you’re doing threat modeling for embedded systems, we recommend starting with
    JIL, which is primarily focused on hardware attacks. When concerned with software
    attacks, use CWSS, as those are the contexts for the scoring methods. With CWSS,
    you can drop irrelevant aspects and tune others, such as business impacts, to
    assess asset values or scalability. Also, make sure you score the entire attack
    path, from the attacker’s starting point all the way through to the impact on
    the asset, so you have a consistent comparison between scores. None of the three
    ratings deal well with scalability: an attack on a million systems may produce
    only a marginally worse score than on a single system. Other limitations undoubtedly
    exist, but currently no better known industry standards exist.'
  prefs: []
  type: TYPE_NORMAL
- en: In various security certification schemes, an implicit or explicit security
    objective is present. For example, as mentioned earlier, for smart cards, attacks
    of only 30 JIL points or lower are considered relevant. An attack like in Tarnovsky’s
    2010 Black Hat DC presentation “Deconstructing a ‘Secure’ Processor” is more than
    30 points and, therefore, not considered part of the security objective. For FIPS
    140-2, no attacks outside the specific list of attacks are considered relevant.
    For example, a side-channel attack can compromise a FIPS 140-2 validated crypto
    engine in a day, and the FIPS 140-2 security objective will still consider it
    to be secure. Any time you use a device that has a security certificate, check
    that the certificate’s security objectives are in line with yours.
  prefs: []
  type: TYPE_NORMAL
- en: Disclosing Security Issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Disclosure of security issues is a hotly debated topic, and we do not purport
    to be solving that in a few paragraphs. We do want to add some color to the debate
    when it comes to hardware security issues. Hardware and software will always have
    security issues. With software, you may be able to distribute new versions or
    patches. Fixing hardware is expensive for many reasons.
  prefs: []
  type: TYPE_NORMAL
- en: We believe the goal of disclosure is public security and safety, not manufacturer
    business cases or researcher fame and fortune. This means disclosure must serve
    the public in the long run. Disclosure is a tool to force manufacturers to fix
    a vulnerability and also to inform the public about a certain product’s risks.
    An unwelcome side effect of full disclosure is that a large group of attackers
    will be able to exploit the vulnerability until a fix is widely available.
  prefs: []
  type: TYPE_NORMAL
- en: For hardware vulnerabilities, the bug is often not patchable after manufacturing,
    though issuing a software patch can mitigate it. In that case, a similar convention
    to software disclosure of 90 days until disclosure may work fine. For pure hardware
    fixes, we are not aware of such conventions (though we’ve seen the application
    of software conventions).
  prefs: []
  type: TYPE_NORMAL
- en: In hardware, it’s common that a software update cannot work around a bug, and
    patches are practically impossible to distribute and install. A well-intentioned
    manufacturer can fix a bug in the next release, but products in the field will
    remain vulnerable. In this situation, the only advantage to disclosure is an informed
    public; the disadvantage is a long time span until the vulnerable products are
    replaced or discontinued. An alternative is partial disclosure. For instance,
    a manufacturer may name the risk and the product but not disclose the details
    of how to exploit the vulnerability. (This strategy hasn’t worked well in the
    software world, where the vulnerabilities are often found quickly even after an
    unspecific disclosure.)
  prefs: []
  type: TYPE_NORMAL
- en: Complications increase when the vulnerability is not patchable and can directly
    affect health and safety. Consider an attack that can shut down every single pacemaker
    remotely. Disclosure of the latter situation will surely spook patients away from
    having pacemakers fitted, causing more people to die from heart attacks. On the
    other hand, it would encourage the supplier to increase the security in the next
    version, reducing the risk of an attack with lethal consequences. Unique trade-offs
    will occur for self-driving cars, IoT toothbrushes, SCADA systems and every other
    application and device. Even more challenges arise when vulnerabilities exist
    in one type of chip used in a variety of products.
  prefs: []
  type: TYPE_NORMAL
- en: We’re not claiming to have the magic answer to all situations here, but we encourage
    everyone to consider carefully the kind of disclosure to pursue. Manufacturers
    should design systems around the premise that they will be broken and plan safe
    scenarios around that premise. Unfortunately, this practice is not prevalent,
    especially in situations where time to market and low cost rule.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This chapter outlined some embedded security basics. We described the software
    and hardware components you’ll undoubtedly stumble upon when analyzing a device,
    and we discussed what “security” means philosophically. To analyze security properly,
    we introduced the four components of a threat model: the attackers, various (hardware)
    attacks, a system’s assets and security objectives, and, finally, the types of
    countermeasures you can implement. We also described tools to create, analyze,
    and rate attacks using an attack tree and industry-standard rating systems. Finally,
    we explored the tricky topic of disclosure in the context of hardware vulnerabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: Laden with all this knowledge, our next step will be to start poking at devices,
    which is what we’ll do in the next chapter.
  prefs: []
  type: TYPE_NORMAL
