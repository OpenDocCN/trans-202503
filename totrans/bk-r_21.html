<html><head></head><body>
<h2 class="h2" id="ch17"><span epub:type="pagebreak" id="page_367"/><span class="big"><strong>17</strong></span><br/><strong>SAMPLING DISTRIBUTIONS AND CONFIDENCE</strong></h2>&#13;
<div class="image"><img src="../images/common-01.jpg" alt="image"/></div>&#13;
<p class="noindent">In <a href="ch15.xhtml#ch15">Chapters 15</a> and <a href="ch16.xhtml#ch16">16</a>, you applied the idea of a probability distribution to examples where a random variable is defined as some measurement or observation of interest. In this chapter, you’ll consider sample statistics themselves as random variables to introduce the concept of a <em>sampling distribution</em>—a probability distribution that is used to account for the variability naturally present when you estimate population parameters using sample statistics. I’ll then introduce the idea of a <em>confidence interval</em>, which is a direct reflection of the variability in a sampling distribution, used in a way that results in an interval estimate of a population parameter. This will form the foundation for formal hypothesis testing in <a href="ch18.xhtml#ch18">Chapter 18</a>.</p>&#13;
<h3 class="h3" id="ch17lev1sec52"><strong>17.1 Sampling Distributions</strong></h3>&#13;
<p class="noindent">A sampling distribution is just like any other probability distribution, but it is specifically associated with a random variable that is a sample statistic. In <a href="ch15.xhtml#ch15">Chapters 15</a> and <a href="ch16.xhtml#ch16">16</a>, we assumed we knew the parameters of the relevant example distribution (for example, the mean and the standard deviation <span epub:type="pagebreak" id="page_368"/>of a normal distribution or the probability of success in a binomial distribution), but in practice these kinds of quantities are often unknown. In these cases, you’d typically estimate the quantities from a sample (see <a href="ch13.xhtml#ch13fig2">Figure 13-2</a> on <a href="ch13.xhtml#page_266">page 266</a> for a visual illustration of this). Any statistic estimated from a sample can be treated as a random variable, with the estimated value itself as the realization of that random variable. It’s therefore entirely possible that different samples from the same population will provide a different value for the same statistic—realizations of random variables are naturally subject to variability. Being able to understand and model this natural variability inherent in estimated sample statistics (using relevant sampling distributions) is a key part of many statistical analyses.</p>&#13;
<p class="indent">Like any other probability distribution, the central “balance” point of a sampling distribution is its mean, but the standard deviation of a sampling distribution is referred to as a <em>standard error</em>. The slight change in terminology reflects the fact that the probabilities of interest are no longer tied to raw measurements or observations per se, but rather to a quantity calculated from a <em>sample</em> of such observations. The theoretical formulas for various sampling distributions therefore depend upon (a) the original probability distributions that are assumed to have generated the raw data and (b) the size of the sample itself.</p>&#13;
<p class="indent">This section will explain the key ideas and provide some examples, and I’ll focus on two simple and easily recognized statistics: a single sample mean and a single sample proportion. I’ll then expand on this in <a href="ch18.xhtml#ch18">Chapter 18</a> when covering hypothesis testing, and you’ll need to understand the role of sampling distributions in assessing important model parameters when you look at regression methods in <a href="ch20.xhtml#ch20">Chapters 20</a> to <a href="ch22.xhtml#ch22">22</a>.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>The validity of the theory of sampling distributions as discussed in this chapter makes an important assumption. Whenever I talk about a sample of data from which a given statistic is calculated, I assume those observations are independent of one another and that they are identically distributed. You’ll see this notion—independent, identically distributed observations—frequently abbreviated as</em> iid <em>in statistical material.</em></p>&#13;
</div>&#13;
<h4 class="h4" id="ch17lev2sec146"><strong><em>17.1.1 Distribution for a Sample Mean</em></strong></h4>&#13;
<p class="noindent">The arithmetic mean is arguably the most common measure of centrality (<a href="ch13.xhtml#ch13lev2sec116">Section 13.2.1</a>) used when summarizing a data set.</p>&#13;
<p class="indent">Mathematically, the variability inherent in an estimated sample mean is described as follows: Formally, denote the random variable of interest as <em><span class="ent">X̄</span></em>. This represents the mean of a sample of <em>n</em> observations from the “raw observation” random variable <em>X</em>, as in <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, . . . , <em>x</em><sub><em>n</em></sub>. Those observations are assumed to have a true finite mean −∞ &lt; <em>μ</em><sub><em>X</em></sub> &lt; ∞ and a true finite standard deviation 0 &lt; <em>σ</em><sub><em>X</em></sub> &lt; ∞. The conditions for finding the probability distribution of a sample mean vary depending on whether you know the value of the standard deviation.</p>&#13;
<h5 class="h5" id="ch17lev3sec64"><span epub:type="pagebreak" id="page_369"/><strong>Situation 1: Standard Deviation Known</strong></h5>&#13;
<p class="noindentb">When the true value of the standard deviation <em>σ</em><sub><em>X</em></sub> is known, then the following are true:</p>&#13;
<p class="bull">• If <em>X</em> itself is normal, the sampling distribution of <em><span class="ent">X̄</span></em> is a normal distribution, with mean <em>μ</em><sub><em>X</em></sub> and standard error <img class="middle" src="../images/common-03.jpg" alt="image"/>.</p>&#13;
<p class="bull">• If <em>X</em> is not normal, the sampling distribution of <em><span class="ent">X̄</span></em> is still approximately normal, with mean <em>μ</em><sub><em>X</em></sub> and standard error <img class="middle" src="../images/common-03.jpg" alt="image"/>, and this approximation improves arbitrarily as <em>n</em> → ∞. This is known as the <em>central limit theorem (CLT)</em>.</p>&#13;
<h5 class="h5" id="ch17lev3sec65"><strong>Situation 2: Standard Deviation Unknown</strong></h5>&#13;
<p class="noindentb">In practice, you commonly won’t know the true value of the standard deviation of the raw measurement distribution that generated your sample data. In this eventuality, it’s usual to just replace <em>σ</em><sub><em>X</em></sub> with <em>s</em><sub><em>X</em></sub>, which is the standard deviation of the sampled data. However, this substitution introduces additional variability that affects the distribution associated with the sample mean random variable.</p>&#13;
<p class="bull">• Standardized values (<a href="ch16.xhtml#ch16lev2sec142">Section 16.2.2</a>) of the sampling distribution of <em><span class="ent">X̄</span></em> follow a <em>t</em>-distribution with <em>ν</em> = <em>n</em> − 1 degrees of freedom; standardization is performed using the standard error <img class="middle" src="../images/common-04.jpg" alt="image"/>.</p>&#13;
<p class="bull">• If, additionally, <em>n</em> is small, then it is necessary to assume the distribution of <em>X</em> is normal for the validity of this <em>t</em>-based sampling distribution of <em><span class="ent">X̄</span></em>.</p>&#13;
<p class="indentt">The nature of the sampling distribution of <em><span class="ent">X̄</span></em> therefore depends upon whether the true standard deviation of the observations is known, as well as the sample size <em>n</em>. The CLT states that normality occurs even if the raw observation distribution is itself not normal, but this approximation is less reliable if <em>n</em> is small. It’s a common rule of thumb to rely on the CLT only if <em>n</em> ≥ 30. If <em>s</em><sub><em>X</em></sub>, the sample standard deviation, is used to calculate the standard error of <em><span class="ent">X̄</span></em>, then the sampling distribution is the <em>t</em>-distribution (following standardization). Again, this is generally taken to be reliable only if <em>n</em> ≥ 30.</p>&#13;
<h5 class="h5" id="ch17lev3sec66"><strong>Example: Dunedin Temperatures</strong></h5>&#13;
<p class="noindent">As an example, suppose that the daily maximum temperature in the month of January in Dunedin, New Zealand, follows a normal distribution, with a mean of 22 degrees Celsius and a standard deviation of 1.5 degrees. Then, in line with the comments for situation 1, for samples of size <em>n</em> = 5, the sampling distribution of <em><span class="ent">X̄</span></em> will be normal, with mean 22 and standard error <img class="middle" src="../images/f0369-03.jpg" alt="image"/>.</p>&#13;
<p class="indent">The top image of <a href="ch17.xhtml#ch17fig1">Figure 17-1</a> shows the raw measurement distribution along with this sampling distribution. You can produce this with code that’s familiar from <a href="ch16.xhtml#ch16">Chapter 16</a>.</p>&#13;
<pre><span epub:type="pagebreak" id="page_370"/>R&gt; xvals &lt;- seq(16,28,by=0.1)<br/>R&gt; fx.samp &lt;- dnorm(xvals,22,1.5/sqrt(5))<br/>R&gt; plot(xvals,fx.samp,type="l",lty=2,lwd=2,xlab="",ylab="")<br/>R&gt; abline(h=0,col="gray")<br/>R&gt; fx &lt;- dnorm(xvals,22,1.5)<br/>R&gt; lines(xvals,fx,lwd=2)<br/>R&gt; legend("topright",legend=c("raw obs. distbn.","sampling distbn. (mean)"),<br/>          lty=1:2,lwd=c(2,2),bty="n")</pre>&#13;
<p class="indent">In this example, the sampling distribution of <em><span class="ent">X̄</span></em> is clearly a taller, skinnier normal distribution than the one tied to the observations. This makes sense—you expect less variability in an <em>average</em> of several measurements as opposed to the raw, individual measurements. Furthermore, the presence of <em>n</em> in the denominator of the standard error dictates a more precise distribution around the mean if you increase the sample size. Again, this makes sense—means will “vary less” between samples of a larger size.</p>&#13;
<p class="indent">You can now ask various probability questions; note that distinguishing between the measurement distribution and the sampling distribution is important. For example, the following code provides Pr(<em>X</em> &lt; 21.5), the probability that a randomly chosen day in January has a maximum temperature of less than 21.5 degrees:</p>&#13;
<pre>R&gt; pnorm(21.5,mean=22,sd=1.5)<br/>[1] 0.3694413</pre>&#13;
<p class="indent">The next bit of code provides the probability that the sample mean will be less than 21.5 degrees, Pr(<em><span class="ent">X̄</span></em> &lt; 21.5), based on a sample of five random days in January:</p>&#13;
<pre>R&gt; pnorm(21.5,mean=22,sd=1.5/sqrt(5))<br/>[1] 0.2280283</pre>&#13;
<p class="indent">The line-shaded areas on the top of <a href="ch17.xhtml#ch17fig1">Figure 17-1</a> show these two probabilities. In R, these shaded areas can be added to that plot by running the following lines directly after the earlier code:</p>&#13;
<pre>R&gt; abline(v=21.5,col="gray")<br/>R&gt; xvals.sub &lt;- xvals[xvals&lt;=21.5]<br/>R&gt; fx.sub &lt;- fx[xvals&lt;=21.5]<br/>R&gt; fx.samp.sub &lt;- fx.samp[xvals&lt;=21.5]<br/>R&gt; polygon(cbind(c(21.5,xvals.sub),c(0,fx.sub)),density=10)<br/>R&gt; polygon(cbind(c(21.5,xvals.sub),c(0,fx.samp.sub)),density=10,<br/>           angle=120,lty=2)</pre>&#13;
<p class="indent">Note that in previous uses of <code>polygon</code>, you’ve simply specified a <code>col</code>; in this example, I implemented shading lines instead, using the arguments <code>density</code> (number of lines per inch) and <code>angle</code> (slope of lines in degrees; defaults to <code>angle=45</code>).</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_371"/><img src="../images/f17-01.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch17fig1"/>Figure 17-1: Illustrating the sampling distribution of a sample mean for</em> n = <em>5, based on an N(22,1.5) raw observation distribution. Top: the normal-based version of the sampling distribution (assuming</em> <em>σ</em><sub><em>X</em></sub> <em>is known) compared to the observation distribution. Bottom: the</em> t<em>-based version of the sampling distribution, using 4 degrees of freedom (in other words, assuming</em> s <em>has been used to calculate the standard error), compared to a standard normal. Shaded areas represent</em> <small>Pr</small>(<em>X</em> &lt; <small>21</small>.<small>5</small>), <small>Pr</small>(<em><span class="ent">X̄</span></em> &lt; <small>21</small>.<small>5</small>) <em>(solid and dashed, topmost plot) and</em> <small>Pr</small>(<em>T</em> &lt; (<small>21</small>.<small>5</small> − <em><span class="ent">x̄</span></em>)/(s/ <img class="middle" src="../images/5.jpg" alt="image"/>)) <em>(dotted, bottom plot).</em></p>&#13;
<p class="indent">To evaluate the probabilities, note that you’ve required knowledge of the parameters governing <em>X</em>. In practice, you’ll rarely have these quantities (as noted in situation 2). Instead, you obtain a sample of data and calculate summary statistics.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_372"/>Running the following line produces five randomly generated Dunedin temperatures from the <em>X</em> ∼ N(22,1.5) distribution:</p>&#13;
<pre>R&gt; obs &lt;- rnorm(5,mean=22,sd=1.5)<br/>R&gt; obs<br/>[1] 22.92233 23.09505 20.98653 20.10941 22.33888</pre>&#13;
<p class="indent">Now, for the sake of the example, say these five values constitute all the data you have for this particular problem; in other words, pretend you don’t know that <em>μ<sub><em>X</em></sub></em> = 22 and <em>σ</em><sub><em>X</em></sub> = 1.5. Your best guesses of the true values of <em>μ</em><sub><em>X</em></sub> and <em>σ</em><sub><em>X</em></sub>, denoted <em><span class="ent">x̄</span></em> and <em>s</em>, respectively, are therefore as follows:</p>&#13;
<pre>R&gt; obs.mean &lt;- mean(obs)<br/>R&gt; obs.mean<br/>[1] 21.89044<br/>R&gt; obs.sd &lt;- sd(obs)<br/>R&gt; obs.sd<br/>[1] 1.294806</pre>&#13;
<p class="indent">The estimated standard error can be calculated:</p>&#13;
<pre>R&gt; obs.mean.se &lt;- obs.sd/sqrt(5)<br/>R&gt; obs.mean.se<br/>[1] 0.5790549</pre>&#13;
<p class="indent">Because <em>n</em> = 5 is relatively small, you must assume the values in <code>obs</code> are realizations from a normal distribution, in line with the points made for situation 2. This allows you to handle the sampling distribution of <em><span class="ent">X̄</span></em> using the <em>t</em>-distribution with 4 degrees of freedom. Recall from <a href="ch16.xhtml#ch16lev2sec143">Section 16.2.3</a>, though, that any <em>t</em>-distribution is typically placed on a standardized scale. Therefore, for you to find the probability that the mean temperature (in a sample of five days) is less than 21.5 based on your calculated sample statistics, you must first standardize this value using the rules outlined in <a href="ch16.xhtml#ch16lev2sec142">Section 16.2.2</a>. Label the corresponding random variable as <em>T</em> and the specific value as <em>t</em><sub>4</sub>, stored as the object <code>t4</code> in R.</p>&#13;
<pre>R&gt; t4 &lt;- (21.5-obs.mean)/obs.mean.se<br/>R&gt; t4<br/>[1] -0.6742706</pre>&#13;
<p class="indent">This has placed the value of interest, 21.5, on the standardized scale, making it interpretable with respect to a standard normal distribution or, as is correct in this setting (because you are using the estimate <em>s</em> rather than the unknown <em>σ</em><sub><em>X</em></sub> in calculating the standard error), <em>t<sub>4</sub></em> follows the aforementioned <em>t</em>-distribution with 4 degrees of freedom. The estimated probability is as follows.</p>&#13;
<pre><span epub:type="pagebreak" id="page_373"/>R&gt; pt(t4,df=4)<br/>[1] 0.26855</pre>&#13;
<p class="indent">Note that when you calculated the “true” theoretical probability from the sampling distribution of Pr(<em><span class="ent">X̄</span></em> &lt; 21.5), you got a result of about 0.23 (see <a href="ch17.xhtml#page_370">page 370</a>), but the same probability based on standardization using sample statistics of the data <code>obs</code> (in other words, <em>estimates</em> of the true theoretical values Pr(<em>T</em> &lt; <em>t</em><sub>4</sub>)) has been computed as 0.27 (2 d.p.).</p>&#13;
<p class="indent">The bottom image of <a href="ch17.xhtml#ch17fig1">Figure 17-1</a> provides the <em>t</em>-distribution with <em>ν</em> = 4, marking off the probability described. The N(0,1) density is also plotted for comparison; this represents the standardized version of the N(22,1.5/ <img class="middle" src="../images/5.jpg" alt="image"/>) sampling distribution from earlier, in situation 1. You can produce this image with the following lines:</p>&#13;
<pre>R&gt; xvals &lt;- seq(-5,5,length=100)<br/>R&gt; fx.samp.t &lt;- dt(xvals,df=4)<br/>R&gt; plot(xvals,dnorm(xvals),type="l",lty=2,lwd=2,col="gray",xlim=c(-4,4),<br/>        xlab="",ylab="")<br/>R&gt; abline(h=0,col="gray")<br/>R&gt; lines(xvals,fx.samp.t,lty=3,lwd=2)<br/>R&gt; polygon(cbind(c(t4,-5,xvals[xvals&lt;=t4]),c(0,0,fx.samp.t[xvals&lt;=t4])),<br/>           density=10,lty=3)<br/>R&gt; legend("topright",legend=c("N(0,1) standard","t (4 df)"),<br/>          col=c("gray","black"),lty=2:3,lwd=c(2,2),bty="n")</pre>&#13;
<p class="indent">Consideration of probability distributions associated with sample means is clearly not a trivial exercise. Using sample statistics governs the nature of the sampling distribution; in particular, it will be <em>t</em> based if you use the sample standard deviation to calculate the standard error. However, as the examples here have shown, once that’s been established, the calculation of various probabilities is easy and follows the same general rules and R functionality detailed in <a href="ch16.xhtml#ch16lev1sec51">Section 16.2</a>.</p>&#13;
<h4 class="h4" id="ch17lev2sec147"><strong><em>17.1.2 Distribution for a Sample Proportion</em></strong></h4>&#13;
<p class="noindent">Sampling distributions for sample proportions are interpreted in much the same way. If <em>n</em> trials of a success/failure event are performed, you can obtain an estimate of the proportion of successes; if another <em>n</em> trials are performed, the new estimate could vary. It’s this variability that you’re investigating.</p>&#13;
<p class="indent">The random variable of interest, <img class="middle" src="../images/p.jpg" alt="image"/>, represents the estimated proportions of successes over any <em>n</em> trials, each resulting in some defined binary outcome. It is estimated as <img class="middle" src="../images/f0373-01.jpg" alt="image"/>, where <em>x</em> is the number of successes in a sample of size <em>n</em>. Let the corresponding true proportion of successes (often unknown) simply be denoted with <em>π</em>.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>Note that <em>π</em> as used in this setting doesn’t refer to the common geometric value 3.14 (2 d.p.). Rather, it’s simply standard notation to refer to a true population proportion using the <em>π</em> symbol.</em></p>&#13;
</div>&#13;
<p class="indentb"><span epub:type="pagebreak" id="page_374"/>The sampling distribution of <img class="middle" src="../images/p.jpg" alt="image"/> is approximately normal with mean <em>π</em> and standard error <img class="middle" src="../images/f0374-01.jpg" alt="image"/>. The following are the key things to note:</p>&#13;
<p class="bull">• This approximation is valid if <em>n</em> is large and/or <em>π</em> is not too close to either 0 or 1.</p>&#13;
<p class="bull">• There are rules of thumb to determine this validity; one such rule is to assume the normal approximation is satisfactory if both <em>nπ</em> and <em>n</em>(1 − <em>π</em>) are greater than 5.</p>&#13;
<p class="bull">• When the true <em>π</em> is unknown or is unassumed to be a certain value, it is typically replaced by <img class="middle" src="../images/p.jpg" alt="image"/> in all of the previous formulas.</p>&#13;
<p class="indentt">As long as you can deem the approximation to the normal distribution valid, this is the only probability distribution that you need to be concerned with. However, it’s worth noting that the standard error of the sampling distribution of a sample proportion depends directly upon the proportion <em>π</em>. This becomes important when constructing confidence intervals and carrying out hypothesis tests, which you’ll begin to explore in <a href="ch18.xhtml#ch18">Chapter 18</a>.</p>&#13;
<p class="indent">Let’s look at a practical example. Suppose a political commentator in the United States is interested in the proportion of voting-age citizens in her home city that already know how they will vote in the next presidential election. She obtains a yes or no answer from 118 suitable randomly selected individuals. Of these individuals, 80 say they know how they’ll vote. To investigate the variability associated with the proportion of interest, you’ll therefore need to consider</p>&#13;
<div class="imagec"><a id="ch17eq1"/><img src="../images/e17-1.jpg" alt="image"/></div>&#13;
<p class="noindent">where <img class="middle" src="../images/f0374-03.jpg" alt="image"/>. In R, the following gives you the estimate of interest:</p>&#13;
<pre>R&gt; p.hat &lt;- 80/118<br/>R&gt; p.hat<br/>[1] 0.6779661</pre>&#13;
<p class="indent">In the sample, about 68 percent of the surveyed individuals know how they will vote in the next election. Note also that, according to the aforementioned rule of thumb, the approximation to the normal distribution is valid because both values are greater than 5.</p>&#13;
<pre>R&gt; 118*p.hat<br/>[1] 80<br/>R&gt; 118*(1-p.hat)<br/>[1] 38</pre>&#13;
<p class="indent">Estimate the standard error with the following:</p>&#13;
<pre>R&gt; p.se &lt;- sqrt(p.hat*(1-p.hat)/118)<br/>R&gt; p.se<br/>[1] 0.04301439</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_375"/>Then, you can plot the corresponding sampling distribution using this code:</p>&#13;
<pre>R&gt; pvals &lt;- seq(p.hat-5*p.se,p.hat+5*p.se,length=100)<br/>R&gt; p.samp &lt;- dnorm(pvals,mean=p.hat,sd=p.se)<br/>R&gt; plot(pvals,p.samp,type="l",xlab="",ylab="",<br/>        xlim=p.hat+c(-4,4)*p.se,ylim=c(0,max(p.samp)))<br/>R&gt; abline(h=0,col="gray")</pre>&#13;
<p class="indent"><a href="ch17.xhtml#ch17fig2">Figure 17-2</a> gives the result.</p>&#13;
<div class="image"><img src="../images/f17-02.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch17fig2"/>Figure 17-2: Visualizing the sampling distribution for the voting example as per <a href="ch17.xhtml#ch17eq1">Equation (17.1)</a>. The shaded area represents</em> <small>Pr</small>(<small>0</small>.<small>7</small> &lt; <img class="middle" src="../images/p.jpg" alt="image"/> &lt; <small>0</small>.<small>75</small>)<em>, which is the probability that the true sample proportion for samples of size</em> n <em>= 118 lies between 0.7 and 0.75.</em></p>&#13;
<p class="indent">Now you can use this distribution to describe the variability in the sample proportion of voters who already know how they will vote, for other samples of this size.</p>&#13;
<p class="indent">For example, the shaded area in <a href="ch17.xhtml#ch17fig2">Figure 17-2</a> highlights the probability that in another sample of the same size, the sample proportion of voters in the given city who already know how they’re going to vote is somewhere between 0.7 and 0.75. This shaded area can be added with the following code:</p>&#13;
<pre>R&gt; pvals.sub &lt;- pvals[pvals&gt;=0.7 &amp; pvals&lt;=0.75]<br/>R&gt; p.samp.sub &lt;- p.samp[pvals&gt;=0.7 &amp; pvals&lt;=0.75]<br/>R&gt; polygon(cbind(c(0.7,pvals.sub,0.75),c(0,p.samp.sub,0)),<br/>           border=NA,col="gray")</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_376"/>And with knowledge of <code>pnorm</code>, introduced in <a href="ch16.xhtml#ch16lev2sec142">Section 16.2.2</a>, you can use the following code to calculate the probability of interest:</p>&#13;
<pre>R&gt; pnorm(0.75,mean=p.hat,sd=p.se) - pnorm(0.7,mean=p.hat,sd=p.se)<br/>[1] 0.257238</pre>&#13;
<p class="indent">This sampling distribution suggests that the chance of another sample proportion, based on the same sample size, lying somewhere between these two values is about 25.7 percent.</p>&#13;
<div class="ex">&#13;
<p class="ext"><a id="ch17exc1"/><strong>Exercise 17.1</strong></p>&#13;
<p class="noindentz">A teacher wants to test all of the 10th-grade students at his school to gauge their basic mathematical understanding, but the photocopier breaks after making only six copies of the test. With no other choice, he chooses six students at random to take the test. Their results, recorded as a score out of 65, have a sample mean of 41.1. The standard deviation of the marks of this test is known to be 11.3.</p>&#13;
<ol type="a">&#13;
<li><p class="noindents">Find the standard error associated with the mean test score.</p></li>&#13;
<li><p class="noindents">Assuming the scores themselves are normally distributed, evaluate the probability that the mean score lies between 45 and 55 if the teacher took another sample of the same size.</p></li>&#13;
<li><p class="noindents">A student who gets less than half the questions correct receives a failing grade (F). Find the probability that the average score is an F based on another sample of the same size.</p></li>&#13;
</ol>&#13;
<p class="noindentz">A marketing company wants to find out which of two energy drinks teenagers prefer—drink A or drink B. It surveys 140 teens, and the results indicate that only 35 percent prefer drink A.</p>&#13;
<ol type="a" start="4">&#13;
<li><p class="noindents">Use a quick check to decide whether it is valid to use the normal distribution to represent the sampling distribution of this proportion.</p></li>&#13;
<li><p class="noindents">What is the probability that in another sample of the same size, the proportion of teenagers who prefer drink A is greater than 0.4?</p></li>&#13;
<li><p class="noindents">Find the two values of this sampling distribution that identify the central 80 percent of values of the proportion of interest.</p></li>&#13;
</ol>&#13;
<p class="noindentz">In <a href="ch16.xhtml#ch16lev2sec144">Section 16.2.4</a>, the time between cars passing an individual’s location was modeled using an exponential distribution. Say that on the other side of town, her friend is curious about a similar problem. Standing outside her house, she records 63 individual times between cars passing. These sampled times have a mean of <em><span class="ent">x̄</span></em> = 37.8 seconds with a standard deviation of <em>s</em> = 34.51 seconds.</p>&#13;
<ol type="a" start="7">&#13;
<li><p class="noindents"><span epub:type="pagebreak" id="page_377"/>The friend inspects a histogram of her raw measurements and notices that her raw data are heavily right-skewed. Briefly identify and describe the nature of the sampling distribution with respect to the sample mean and calculate the appropriate standard error.</p></li>&#13;
<li><p class="noindents">Using the standard error from (g) and the appropriate probability distribution, calculate the probability that in another sample of the same size, the sample mean time between cars passing is as follows:</p>&#13;
<ol type="i">&#13;
<li><p class="noindent">More than 40 seconds</p></li>&#13;
<li><p class="noindent">Less than half a minute</p></li>&#13;
<li><p class="noindent">Between the given sample mean and 40 seconds</p></li>&#13;
</ol></li>&#13;
</ol>&#13;
</div>&#13;
<h4 class="h4" id="ch17lev2sec148"><strong><em>17.1.3 Sampling Distributions for Other Statistics</em></strong></h4>&#13;
<p class="noindent">So far you’ve looked at sampling distributions in cases dealing with a single sample mean or sample proportion, though it’s important to note that many problems require more complicated measures. Nevertheless, you can apply the ideas explored in this section to any statistic estimated from a finite-sized sample. The key, always, is to be able to understand the variability associated with your point estimates.</p>&#13;
<p class="indent">In some settings, such as those covered so far, the sampling distribution is parametric, meaning that the functional (mathematical) form of the probability distribution itself is known and depends only on the provision of specific parameter values. This is sometimes contingent upon the satisfaction of certain conditions, as you’ve seen with the application of the normal distribution covered in this chapter. For other statistics, it may be the case that you do not know the form of the appropriate sampling distribution—in these cases, you could use computer simulation to obtain the required probabilities.</p>&#13;
<p class="indent">In the remainder of this chapter and over the next few chapters, you’ll continue to explore statistics that are tied to parametric sampling distributions for common tests and models.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>The variability of an estimated quantity is actually only one side of the coin. Just as important is the issue of statistical</em> bias<em>. Where “natural variability” should be associated with</em> random error<em>, bias is associated with</em> systematic error<em>, in the sense that a biased statistic does not settle on the corresponding true parameter value as the sample size increases. Bias can be caused by flaws in a study design or collection of data or can be the result of a poor estimator of the statistic of interest. Bias is an undesirable trait of any given estimator and/or statistical analysis unless it can be quantified and removed, which is often difficult if not impossible in practice. I’ve therefore dealt so far only with unbiased statistical estimators, many of which are those you may already be familiar with (for example, the arithmetic mean), and I’ll continue to assume unbiasedness moving forward.</em></p>&#13;
</div>&#13;
<h3 class="h3" id="ch17lev1sec53"><span epub:type="pagebreak" id="page_378"/><strong>17.2 Confidence Intervals</strong></h3>&#13;
<p class="noindent">A <em>confidence interval (CI)</em> is an interval defined by a lower limit <em>l</em> and an upper limit <em>u</em>, used to describe possible values of a corresponding true population parameter in light of observed sample data. Interpretation of a confidence interval therefore allows you to state a “level of confidence” that a true parameter of interest falls between this upper and lower limit, often expressed as a percentage. As such, it is a common and useful tool built directly from the sampling distribution of the statistic of interest.</p>&#13;
<p class="indentb">The following are the important points to note:</p>&#13;
<p class="bull">• The level of confidence is usually expressed as a percentage, such that you’d construct a 100 × (1 − <em>α</em>) percent confidence interval, where 0 &lt; <em>α</em> &lt; 1 is an “amount of tail probability.”</p>&#13;
<p class="bull">• The three most common intervals are defined with either <em>α</em> = 0.1 (a 90 percent interval), <em>α</em> = 0.05 (a 95 percent interval), or <em>α</em> = 0.01 (a 99 percent interval).</p>&#13;
<p class="bull">• Colloquially, you’d state the interpretation of a confidence interval (<em>l</em>, <em>u</em>) as “I am 100 × (1 − <em>α</em>) percent confident that the true parameter value lies somewhere between <em>l</em> and <em>u</em>.”</p>&#13;
<p class="indenttb">Confidence intervals may be constructed in different ways, depending on the type of statistic and therefore the shape of the corresponding sampling distribution. For symmetrically distributed sample statistics, like those involving means and proportions that will be used in this chapter, a general formula is</p>&#13;
<div class="imagec"><a id="ch17eq2"/><img src="../images/e17-2.jpg" alt="image"/></div>&#13;
<p class="noindentt1">where <em>statistic</em> is the sample statistic under scrutiny, <em>critical value</em> is a value from the standardized version of the sampling distribution that corresponds to <em>α</em>, and <em>standard error</em> is the standard deviation of the sampling distribution. The product of the critical value and standard error is referred to as the <em>error component</em> of the interval; subtraction of the error component from the value of the statistic provides <em>l</em>, and addition provides <em>u</em>.</p>&#13;
<p class="indent">With reference to the appropriate sampling distribution, all that a CI yields are the two values of the distribution that mark off the central 100 × (1 − <em>α</em>) percent of the area under the density. (This is the process that was briefly mentioned in <a href="ch17.xhtml#ch17exc1">Exercise 17.1</a> (f).) You then use the CI to make further interpretations concerning the true (typically unknown) parameter value that’s being estimated by the statistic of interest.</p>&#13;
<h4 class="h4" id="ch17lev2sec149"><strong><em>17.2.1 An Interval for a Mean</em></strong></h4>&#13;
<p class="noindent">You know from <a href="ch17.xhtml#ch17lev2sec146">Section 17.1.1</a> that the sampling distribution of a single sample mean depends primarily on whether you know the true standard deviation of the raw measurements, <em>σ</em><sub><em>X</em></sub>. Then, provided the sample size for this sample mean is roughly <em>n</em> ≥ 30, the CLT ensures a symmetric sampling distribution—which will be normal if you know the true value of <em>σ</em><sub><em>X</em></sub>, or <em>t</em> based with <em>ν</em> = <em>n</em> − 1 df if you must use the sample standard deviation, <em>s</em>, to <span epub:type="pagebreak" id="page_379"/>estimate <em>σ</em><sub><em>X</em></sub> (as is more common in practice). You’ve seen that the standard error is defined as the standard deviation divided by the square root of <em>n</em>. For a small <em>n</em>, you must also assume that the raw observations are normally distributed, since the CLT will not apply.</p>&#13;
<p class="indent">To construct an appropriate interval, you must first find the critical value corresponding to <em>α</em>. By definition the CI is symmetric, so this translates to a central probability of (1 − <em>α</em>) around the mean, which is exactly <em>α</em>/2 in the lower tail and the same in the upper tail.</p>&#13;
<p class="indent">Return to the example from <a href="ch17.xhtml#ch17lev2sec146">Section 17.1.1</a>, dealing with the mean daily maximum temperatures (degrees Celsius) in January for Dunedin, New Zealand. Suppose you know the observations are normally distributed but you don’t know the true mean <em>μ</em><sub><em>X</em></sub> (which is set at 22) or the true standard deviation <em>σ</em><sub><em>X</em></sub> (which is set at 1.5). Setting it up in the same way as earlier, assume you’ve made the following five independent observations:</p>&#13;
<pre>R&gt; temp.sample &lt;- rnorm(n=5,mean=22,sd=1.5)<br/>R&gt; temp.sample<br/>[1] 20.46097 21.45658 21.06410 20.49367 24.92843</pre>&#13;
<p class="indent">As you’re interested in the sample mean and its sampling distribution, you must calculate the sample mean <em><span class="ent">x̄</span></em>, the sample standard deviation <em>s</em>, and the appropriate standard error of the sample mean, <img class="middle" src="../images/f0379-01.jpg" alt="image"/>.</p>&#13;
<pre>R&gt; temp.mean &lt;- mean(temp.sample)<br/>R&gt; temp.mean<br/>[1] 21.68075<br/>R&gt; temp.sd &lt;- sd(temp.sample)<br/>R&gt; temp.sd<br/>[1] 1.862456<br/>R&gt; temp.se &lt;- temp.sd/sqrt(5)<br/>R&gt; temp.se<br/>[1] 0.8329155</pre>&#13;
<p class="indent">Now, let’s say the aim is to construct a 95 percent confidence interval for the true, unknown mean <em>μ</em><sub><em>X</em></sub>. This implies <em>α</em> = 0.05 (the total amount of tail probability) for the relevant sampling distribution. Given the fact that you know the raw observations are normal and that you’re using <em>s</em> (not <em>σ</em><sub><em>X</em></sub>), the appropriate distribution is the <em>t</em>-distribution with <em>n</em> − 1 = 4 degrees of freedom. For a central area of 0.95 under this curve, <em>α</em>/2 = 0.025 must be in either tail. Knowing that R’s <code>q</code> functions operate based on a total lower tail area, the (positive) critical value is therefore found by supplying a probability of 1 − <em>α</em>/2 = 0.975 to the appropriate function.</p>&#13;
<pre>R&gt; 1-0.05/2<br/>[1] 0.975<br/>R&gt; critval &lt;- qt(0.975,df=4)<br/>R&gt; critval<br/>[1] 2.776445</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_380"/><a href="ch17.xhtml#ch17fig3">Figure 17-3</a> shows why the <code>qt</code> function is used in this way (since I used similar code throughout <a href="ch16.xhtml#ch16">Chapter 16</a>, I haven’t reproduced the code for <a href="ch17.xhtml#ch17fig3">Figure 17-3</a> here).</p>&#13;
<div class="image"><img src="../images/f17-03.jpg" alt="image"/></div>&#13;
<p class="figt"><em><a id="ch17fig3"/>Figure 17-3: Illustrating the role of the critical value in a confidence interval for a sample mean, using the Dunedin temperature example. The sampling distribution is</em> t <em>with 4 df, and the use of</em> <code>qt</code> <em>with respect to symmetric tail probabilities related to</em> <em>α/2 = 0.025 yields a central area of 0.95.</em></p>&#13;
<p class="indent">Note that when viewed with respect to the negative version of the same critical value (“reflected” around the mean and obtained by using <code>qt(0.025,4)</code>), the central, symmetric area under the curve must be 0.95. You can confirm this using <code>pt</code>.</p>&#13;
<pre>R&gt; pt(critval,4)-pt(-critval,4)<br/>[1] 0.95</pre>&#13;
<p class="indent">So, all the ingredients are present. You find the 95 percent confidence interval for the true mean <em>μ</em><sub><em>X</em></sub> via <a href="ch17.xhtml#ch17eq2">Equation (17.2)</a> with the following lines, which give <em>l</em> and <em>u</em>, respectively:</p>&#13;
<pre>R&gt; temp.mean-critval*temp.se<br/>[1] 19.36821<br/>R&gt; temp.mean+critval*temp.se<br/>[1] 23.99329</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_381"/>The CI given by (19.37,23.99) is therefore interpreted as follows: you are 95 percent confident that the true mean maximum temperature in Dunedin in January lies somewhere between 19.37 and 23.99 degrees Celsius.</p>&#13;
<p class="indent">With this result, you’ve combined knowledge of the estimate of the mean itself with the inherent variability of a sample to define an interval of values in which you’re fairly sure the true mean will lie. As you know, the true mean in this case is 22, which is indeed included in the calculated CI.</p>&#13;
<p class="indent">From this, it’s easy to alter the intervals to change the confidence levels. You need to change only the critical value, which, as always, must define <em>α</em>/2 in each tail. For example, an 80 percent CI (<em>α</em> = 0.2) and a 99 percent CI (<em>α</em> = 0.01) for the same example value given here can be found with these two lines, respectively:</p>&#13;
<pre>R&gt; temp.mean+c(-1,1)*qt(p=0.9,df=4)*temp.se<br/>[1] 20.40372 22.95778<br/>R&gt; temp.mean+c(-1,1)*qt(p=0.995,df=4)*temp.se<br/>[1] 17.84593 25.51557</pre>&#13;
<p class="indent">Note here the use of multiplication by the vector <code>c(-1,1)</code> so that the lower and upper limits can be obtained at once and the result returned as a vector of length 2. As usual, the <code>qt</code> function is used with respect to a complete lower-tail area, so <code>p</code> is set at 1 − <em>α</em>/2.</p>&#13;
<p class="indent">These most recent intervals highlight the natural consequence of moving to a higher confidence level for a given CI. A higher probability in the central area translates directly to a more extreme critical value, resulting in a wider interval. This makes sense—in order to be “more confident” about the true parameter value, you’d need to take into account a larger range of possible values.</p>&#13;
<h4 class="h4" id="ch17lev2sec150"><strong><em>17.2.2 An Interval for a Proportion</em></strong></h4>&#13;
<p class="noindent">Establishing a CI for a sample proportion follows the same rules as for the mean. With knowledge of the sampling distribution as per <a href="ch17.xhtml#ch17lev2sec147">Section 17.1.2</a>, you obtain critical values from the standard normal distribution, and for an estimate of <img class="middle" src="../images/p.jpg" alt="image"/> from a sample of size <em>n</em>, the interval itself is constructed with the standard error <img class="middle" src="../images/f0381-01.jpg" alt="image"/>.</p>&#13;
<p class="indent">Let’s return to the example from <a href="ch17.xhtml#ch17lev2sec147">Section 17.1.2</a>, where 80 of 118 surveyed individuals said that they knew how they were going to vote in the next US presidential election. Recall you have the following:</p>&#13;
<pre>R&gt; p.hat &lt;- 80/118<br/>R&gt; p.hat<br/>[1] 0.6779661<br/>R&gt; p.se &lt;- sqrt(p.hat*(1-p.hat)/118)<br/>R&gt; p.se<br/>[1] 0.04301439</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_382"/>To construct a 90 percent CI (<em>α</em> = 0.1), the appropriate critical value from the standardized sampling distribution of interest is as follows, implying Pr(−1.644854 &lt; <em>Z</em> &lt; 1.644854) = 0.9 for <em>Z</em> ∼ N(0,1):</p>&#13;
<pre>R&gt; qnorm(0.95)<br/>[1] 1.644854</pre>&#13;
<p class="indent">Now you again follow <a href="ch17.xhtml#ch17eq2">Equation (17.2)</a>:</p>&#13;
<pre>R&gt; p.hat+c(-1,1)<sub>*</sub>qnorm(0.95)<sub>*</sub>p.se<br/>[1] 0.6072137 0.7487185</pre>&#13;
<p class="indent">You can conclude that you’re 90 percent confident that the true proportion of voters who know how they will vote in the next election lies somewhere between 0.61 and 0.75 (rounded to two decimal places).</p>&#13;
<h4 class="h4" id="ch17lev2sec151"><strong><em>17.2.3 Other Intervals</em></strong></h4>&#13;
<p class="noindent">The two simple situations presented in <a href="ch17.xhtml#ch17lev2sec149">Sections 17.2.1</a> and <a href="ch17.xhtml#ch17lev2sec150">17.2.2</a> serve to highlight the importance of associating any point estimate (in other words, a sample statistic) with the idea of its variability. Confidence intervals can of course be constructed for other quantities, and over the following sections (as part of testing hypotheses), I’ll expand on the discussion of confidence intervals to investigate differences between two means and two proportions, as well as ratios of categorical counts. These more complicated statistics come with their own standard error formulas, though the corresponding sampling distributions are still symmetric via the normal and <em>t</em>-curves (if, again, some standard assumptions are met), which means that the now familiar formulation of <a href="ch17.xhtml#ch17eq2">Equation (17.2)</a> still applies.</p>&#13;
<p class="indent">Generally, a confidence interval seeks to mark off a central area of 1 − <em>α</em> from the sampling distribution of interest, including sampling distributions that are asymmetric. In those cases, however, it doesn’t make much sense to have a symmetric CI based on a single, standardized critical value as per <a href="ch17.xhtml#ch17eq2">Equation (17.2)</a>. Similarly, you might not know the functional, parametric form of the sampling distribution and so may not be willing to make any distributional assumptions, such as symmetry. In these cases, you can take an alternative path based on the raw quantiles (or estimated raw quantiles; see <a href="ch13.xhtml#ch13lev2sec118">Section 13.2.3</a>) of the supposed asymmetric sampling distribution. Using specific quantile values to mark off identical <em>α</em>/2 upper- and lower-tail areas is a valid method that remains sensitive to the shape of the sampling distribution of interest, while still allowing you to construct a useful interval that describes potential true parameter values.</p>&#13;
<h4 class="h4" id="ch17lev2sec152"><strong><em>17.2.4 Comments on Interpretation of a CI</em></strong></h4>&#13;
<p class="noindent">The typical statement about the interpretation of any CI references a degree of confidence in where the true parameter value lies, but a more formally <span epub:type="pagebreak" id="page_383"/>correct interpretation should consider and clarify the probabilistic nature of the construction. Technically, given a 100(1 − <em>α</em>) percent confidence level, the more accurate interpretation is as follows: over many samples of the same size and from the same population where a CI, of the same confidence level, is constructed with respect to the same statistic from each sample, you would expect the true corresponding parameter value to fall within the limits of 100(1 − <em>α</em>) percent of those intervals.</p>&#13;
<p class="indent">This comes from the fact that the theory of a sampling distribution describes the variability in multiple samples, not just the sample that has been taken. At first glance it may be difficult to fully appreciate the difference between this and the colloquially used “confidence statement,” but it is important to remain aware of the technically correct definition, particularly given that a CI is typically estimated based on only one sample.</p>&#13;
<div class="ex">&#13;
<p class="ext"><a id="ch17exc2"/><strong>Exercise 17.2</strong></p>&#13;
<p class="noindentz">A casual runner records the average time it takes him to sprint 100 meters. He completes the dash 34 times under identical conditions and finds that the mean of these is 14.22 seconds. Assume that he knows the standard deviation of his runs is <em>σ</em><sub><em>X</em></sub> = 2.9 seconds.</p>&#13;
<ol type="a">&#13;
<li><p class="noindents">Construct and interpret a 90 percent confidence interval for the true mean time.</p></li>&#13;
<li><p class="noindents">Repeat (a), but this time, assume that the standard deviation is not known and that <em>s</em> = 2.9 is estimated from the sample. How, if at all, does this change the interval?</p></li>&#13;
</ol>&#13;
<p class="noindentz">In a particular country, the true proportion of citizens who are left handed or ambidextrous is unknown. A random sample of 400 people is taken, and each individual is asked to identify with one of three options: right-handed only, left-handed only, or ambidextrous. The results show that 37 selected left-handed and 11 selected ambidextrous.</p>&#13;
<ol type="a" start="3">&#13;
<li><p class="noindents">Calculate and interpret a 99 percent CI for the true proportion of left-handed-only citizens.</p></li>&#13;
<li><p class="noindents">Calculate and interpret a 99 percent CI for the true proportion of citizens who are either left-handed <em>or</em> ambidextrous.</p></li>&#13;
</ol>&#13;
<p class="noindentz">In <a href="ch17.xhtml#ch17lev2sec152">Section 17.2.4</a>, the technical interpretation of a CI with respect to its confidence level was described as the proportion of many similar intervals (that is, when calculated for samples of the same size from the same population) that contain the true value of the parameter of interest.</p>&#13;
<ol type="a" start="5">&#13;
<li><p class="noindents"><span epub:type="pagebreak" id="page_384"/>Your task is to write an example to demonstrate this behavior of confidence intervals using simulation. To do so, follow these instructions:</p>&#13;
<p class="dash">– Set up a matrix (see <a href="ch03.xhtml#ch03">Chapter 3</a>) filled with <code>NA</code>s (<a href="ch06.xhtml#ch06">Chapter 6</a>) that has 5,000 rows and 3 columns.</p>&#13;
<p class="dash">– Use skills from <a href="ch10.xhtml#ch10">Chapter 10</a> to write a <code>for</code> loop that, at each of 5,000 iterations, generates a random sample of size 300 from an exponential distribution with rate parameter <em>λ<sub>e</sub></em> = 0.1 (<a href="ch16.xhtml#ch16lev2sec144">Section 16.2.4</a>).</p>&#13;
<p class="dash">– Evaluate the sample mean and sample standard deviation of each sample, and use these quantities with the critical values from the appropriate sampling distribution to calculate a 95 percent CI for the true mean of the distribution.</p>&#13;
<p class="dash">– Within the <code>for</code> loop, the matrix should now be filled, row by row, with your results. The first column will contain the lower limit, the second will contain the upper limit, and the third column will be a logical value that is <code>TRUE</code> if the corresponding interval contains the true mean of 1/<em>λ</em><sub>e</sub> and that is <code>FALSE</code> otherwise.</p>&#13;
<p class="dash">– When the loop is completed, compute the proportion of <code>TRUEs</code> in the third column of the filled matrix. You should find that this proportion is close to 0.95; this will vary randomly each time you rerun the loop.</p></li>&#13;
<li><p class="noindents">Create a plot that draws the first 100 of your estimated confidence intervals as separate horizontal lines drawn from <em>l</em> to <em>u</em>, one on top of another. One way to do this is to first create an empty plot with preset <em>x</em>- and <em>y</em>-limits (the latter as <code>c(1,100)</code>) and then progressively add each line using <code>lines</code> with appropriate coordinates (this could be done using another <code>for</code> loop). As a final touch, add to the plot a red vertical line that denotes the true mean. Confidence intervals that do not include the true mean will not intersect that vertical line.</p>&#13;
<p class="indent">The following shows an example of this plot:</p>&#13;
<div class="imagec"><img src="../images/f0384-01.jpg" alt="image"/></div></li>&#13;
</ol>&#13;
</div>&#13;
</body></html>