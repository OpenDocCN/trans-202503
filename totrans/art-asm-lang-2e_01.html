<html><head></head><body><div class="chapter" title="Chapter&#xA0;2.&#xA0;DATA REPRESENTATION"><div class="titlepage"><div><div><h1 class="title"><a id="data_representation"/>Chapter 2. DATA REPRESENTATION</h1></div></div></div><div class="informalfigure"><div class="mediaobject"><a id="I_mediaobject2_d1e5551"/><img alt="DATA REPRESENTATION" src="tagoreillycom20100401nostarchimages577853.png.jpg"/></div></div><p>A major stumbling block many beginners encounter when attempting to learn assembly language is the common use of the binary and hexadecimal numbering systems. Although hexadecimal numbers are a little strange, their advantages outweigh their disadvantages by a large margin. Understanding the binary and hexadecimal numbering systems is important because their use simplifies the discussion of other topics, including bit operations, signed numeric representation, character codes, and packed data.<a class="indexterm" id="IDX-CHP-2-0001"/><a class="indexterm" id="IDX-CHP-2-0002"/></p><p>This chapter discusses several important concepts, including:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The binary and hexadecimal numbering systems</p></li><li class="listitem"><p>Binary data organization (bits, nibbles, bytes, words, and double words)</p></li><li class="listitem"><p>Signed and unsigned numbering systems</p></li><li class="listitem"><p>Arithmetic, logical, shift, and rotate operations on binary values<a class="indexterm" id="IDX-CHP-2-0003"/></p></li><li class="listitem"><p>Bit fields and packed data</p></li></ul></div><p>This is basic material, and the remainder of this text depends on your understanding these concepts. If you are already familiar with these terms from other courses or study, you should at least skim this material before proceeding to the next chapter. If you are unfamiliar with this material, or only vaguely familiar with it, you should study it carefully before proceeding. <span class="emphasis"><em>All of the material in this chapter is important!</em></span> Do not skip over any material.</p><div class="sect1" title="2.1 Numbering Systems"><div class="titlepage"><div><div><h1 class="title"><a id="numbering_systems"/>2.1 Numbering Systems</h1></div></div></div><p>Most modern computer systems do not represent numeric values using the decimal (base-10) system. Instead, they typically use a binary or two's complement numbering system.</p><div class="sect2" title="2.1.1 A Review of the Decimal System"><div class="titlepage"><div><div><h2 class="title"><a id="a_review_of_the_decimal_system"/>2.1.1 A Review of the Decimal System</h2></div></div></div><p>You've been using the decimal numbering system for so long that you probably take it for granted. When you see a number like <span class="emphasis"><em>123</em></span>, you don't think about the value 123; rather, you generate a mental image of how many items this value represents. In reality, however, the number 123 represents:<a class="indexterm" id="IDX-CHP-2-0004"/></p><table border="0" class="simplelist" summary="Simple list"><tr><td>1*10<sup>2</sup> + 2*10<sup>1</sup> + 3*10<sup>0</sup></td></tr></table><p>or</p><table border="0" class="simplelist" summary="Simple list"><tr><td>100 + 20 + 3</td></tr></table><p>In a decimal positional numbering system, each digit appearing to the left of the decimal point represents a value between 0 and 9 times an increasing power of 10. Digits appearing to the right of the decimal point represent a value between 0 and 9 times an increasing negative power of 10. For example, the value 123.456 means:</p><table border="0" class="simplelist" summary="Simple list"><tr><td>1*10<sup>2</sup> + 2*10<sup>1</sup> + 3*10<sup>0</sup> + 4*10<sup>−1</sup> + 5*10<sup>−2</sup> + 6*10<sup>−3</sup></td></tr></table><p>or</p><table border="0" class="simplelist" summary="Simple list"><tr><td>100 + 20 + 3 + 0.4 + 0.05 + 0.006</td></tr></table></div><div class="sect2" title="2.1.2 The Binary Numbering System"><div class="titlepage"><div><div><h2 class="title"><a id="the_binary_numbering_system"/>2.1.2 The Binary Numbering System</h2></div></div></div><p>Most modern computer systems operate using binary logic. The computer represents values using two voltage levels (usually 0v and +2.4..5v). Two such levels can represent exactly two unique values. These could be any two different values, but they typically represent the values 0 and 1. These values, coincidentally, correspond to the two digits in the binary numbering system.</p><p>The binary numbering system works just like the decimal numbering system, with two exceptions: Binary allows only the digits 0 and 1 (rather than 0..9), and binary uses powers of 2 rather than powers of 10. Therefore, it is very easy to convert a binary number to decimal. For each <code class="literal">1</code> in the binary string, add in <code class="literal">2</code><em class="replaceable"><code><sup>n</sup></code></em> where <span class="emphasis"><em>n</em></span> is the zero-based position of the binary digit. For example, the binary value 11001010<sub>2</sub> represents:<a class="indexterm" id="IDX-CHP-2-0005"/><a class="indexterm" id="IDX-CHP-2-0006"/></p><table border="0" class="simplelist" summary="Simple list"><tr><td>1*2<sup>7</sup> + 1*2<sup>6</sup> + 0*2<sup>5</sup> + 0*2<sup>4</sup> + 1*2<sup>3</sup> + 0*2<sup>2</sup> + 1*2<sup>1</sup> + 0*2<sup>0</sup></td></tr><tr><td>=</td></tr><tr><td>128 + 64 + 8 + 2</td></tr><tr><td>=</td></tr><tr><td>202<sub>10</sub></td></tr></table><p>To convert decimal to binary is slightly more difficult. You must find those powers of 2 that, when added together, produce the decimal result.</p><p>A simple way to convert decimal to binary is the <span class="emphasis"><em>even/odd - divide by two</em></span> algorithm. This algorithm uses the following steps:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>If the number is even, emit a 0. If the number is odd, emit a 1.</p></li><li class="listitem"><p>Divide the number by 2 and throw away any fractional component or remainder.</p></li><li class="listitem"><p>If the quotient is 0, the algorithm is complete.</p></li><li class="listitem"><p>If the quotient is not 0 and is odd, insert a 1 before the current string; if the number is even, prefix your binary string with 0.</p></li><li class="listitem"><p>Go back to step 2 and repeat.</p></li></ol></div><p>Binary numbers, although they have little importance in high-level languages, appear everywhere in assembly language programs. So you should be somewhat comfortable with them.</p></div><div class="sect2" title="2.1.3 Binary Formats"><div class="titlepage"><div><div><h2 class="title"><a id="binary_formats"/>2.1.3 Binary Formats</h2></div></div></div><p>In the purest sense, every binary number contains an infinite number of digits (or <span class="emphasis"><em>bits</em></span>, which is short for <span class="emphasis"><em>binary digits</em></span>). For example, we can represent the number 5 by any of the following:<a class="indexterm" id="IDX-CHP-2-0007"/></p><table border="0" class="simplelist" summary="Simple list"><tr><td>101 00000101 0000000000101 ...000000000000101</td></tr></table><p>Any number of leading zero digits may precede the binary number without changing its value.</p><p>We will adopt the convention of ignoring any leading zeros present in a value. For example, 101<sub>2</sub> represents the number 5 but because the 80x86 typically works with groups of 8 bits, we'll find it much easier to zero extend all binary numbers to some multiple of 4 or 8 bits. Therefore, following this convention, we'd represent the number 5 as 0101<sub>2</sub> or 00000101<sub>2</sub>.</p><p>In the United States, most people separate every three digits with a comma to make larger numbers easier to read. For example, 1,023,435,208 is much easier to read and comprehend than 1023435208. We'll adopt a similar convention in this text for binary numbers. We will separate each group of four binary bits with an underscore. For example, we will write the binary value 1010111110110010 as 1010_1111_1011_0010.<a class="indexterm" id="IDX-CHP-2-0008"/><a class="indexterm" id="IDX-CHP-2-0009"/><a class="indexterm" id="IDX-CHP-2-0010"/><a class="indexterm" id="IDX-CHP-2-0011"/></p><p>We'll number each bit as follows:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>The rightmost bit in a binary number is bit position 0.</p></li><li class="listitem"><p>Each bit to the left is given the next successive bit number.</p><p>An 8-bit binary value uses bits 0..7:</p><table border="0" class="simplelist" summary="Simple list"><tr><td>X<sub>7</sub> X<sub>6</sub> X<sub>5</sub> X<sub>4</sub> X<sub>3</sub> X<sub>2</sub> X<sub>1</sub> X<sub>0</sub></td></tr></table><p>A 16-bit binary value uses bit positions 0..15:</p><table border="0" class="simplelist" summary="Simple list"><tr><td>X<sub>15</sub> X<sub>14</sub> X<sub>13</sub> X<sub>12</sub> X<sub>11</sub> X<sub>10</sub> X<sub>9</sub> X<sub>8</sub> X<sub>7</sub> X<sub>6</sub> X<sub>5</sub> X<sub>4</sub> X<sub>3</sub> X<sub>2</sub> X<sub>1</sub> X<sub>0</sub></td></tr></table><p>A 32-bit binary value uses bit positions 0..31, and so on.</p></li></ol></div><p>Bit 0 is the <span class="emphasis"><em>low-order (L.O.)</em></span> bit (some refer to this as the <span class="emphasis"><em>least significant bit</em></span>). The leftmost bit is called the <span class="emphasis"><em>high-order (H.O.)</em></span> bit (or the <span class="emphasis"><em>most significant bit</em></span>). We'll refer to the intermediate bits by their respective bit numbers.<a class="indexterm" id="IDX-CHP-2-0012"/><a class="indexterm" id="IDX-CHP-2-0013"/><a class="indexterm" id="IDX-CHP-2-0014"/><a class="indexterm" id="IDX-CHP-2-0015"/></p></div></div></div>
<div class="sect1" title="2.2 The Hexadecimal Numbering System"><div class="titlepage"><div><div><h1 class="title"><a id="the_hexadecimal_numbering_system"/>2.2 The Hexadecimal Numbering System</h1></div></div></div><p>Unfortunately, binary numbers are verbose. To represent the value 202<sub>10</sub> requires eight binary digits. The decimal version requires only three decimal digits and thus represents numbers much more compactly than in binary. This fact is not lost on the engineers who design binary computer systems. When dealing with large values, binary numbers quickly become unwieldy. Unfortunately, the computer "thinks" in binary, so most of the time it is convenient to use the binary numbering system. Although we can convert between decimal and binary, the conversion is not a trivial task. The hexadecimal (base 16) numbering system solves many of the problems inherent in the binary system. Hexadecimal numbers offer the two features we're looking for: They're very compact, and it's simple to convert them to binary and vice versa. For this reason, most engineers use the hexadecimal numbering system.<a class="indexterm" id="IDX-CHP-2-0016"/></p><p>Because the radix (base) of a hexadecimal number is 16, each hexadecimal digit to the left of the hexadecimal point represents some value times a successive power of 16. For example, the number 1234<sub>16</sub> is equal to:<a class="indexterm" id="IDX-CHP-2-0017"/></p><table border="0" class="simplelist" summary="Simple list"><tr><td>1*16<sup>3</sup> + 2*16<sup>2</sup> + 3*16<sup>1</sup> + 4*16<sup>0</sup></td></tr></table><p>or</p><table border="0" class="simplelist" summary="Simple list"><tr><td>4096 + 512 + 48 + 4 = 4660<sub>10</sub></td></tr></table><p>Each hexadecimal digit can represent one of 16 values between 0 and 15<sub>10</sub>. Because there are only 10 decimal digits, we need to invent 6 additional digits to represent the values in the range 10<sub>10</sub>..15<sub>10</sub>. Rather than create new symbols for these digits, we'll use the letters A..F. The following are all examples of valid hexadecimal numbers:<a class="indexterm" id="IDX-CHP-2-0018"/><a class="indexterm" id="IDX-CHP-2-0019"/></p><table border="0" class="simplelist" summary="Simple list"><tr><td>1234<sub>16</sub> DEAD<sub>16</sub> BEEF<sub>16</sub> 0AFB<sub>16</sub> FEED<sub>16</sub> DEAF<sub>16</sub></td></tr></table><p>Because we'll often need to enter hexadecimal numbers into the computer system, we'll need a different mechanism for representing hexadecimal numbers. After all, on most computer systems you cannot enter a subscript to denote the radix of the associated value. We'll adopt the following conventions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>All hexadecimal values begin with a $ character; for example, $123A4.</p></li><li class="listitem"><p>All binary values begin with a percent sign (%).</p></li><li class="listitem"><p>Decimal numbers do not have a prefix character.</p></li><li class="listitem"><p>If the radix is clear from the context, this book may drop the leading $ or % character.</p><p>Here are some examples of valid hexadecimal numbers:</p><table border="0" class="simplelist" summary="Simple list"><tr><td>$1234 $DEAD $BEEF $AFB $FEED $DEAF</td></tr></table></li></ul></div><p>As you can see, hexadecimal numbers are compact and easy to read. In addition, you can easily convert between hexadecimal and binary. Consider <a class="xref" href="ch02s02.html#binary_solidus_hexadecimal_conversion" title="Table 2-1. Binary/Hexadecimal Conversion">Table 2-1</a>. This table provides all the information you'll ever need to convert any hexadecimal number into a binary number or vice versa.</p><div class="table"><a id="binary_solidus_hexadecimal_conversion"/><p class="title">Table 2-1. Binary/Hexadecimal Conversion</p><div class="table-contents"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; " summary="Binary/Hexadecimal Conversion"><colgroup><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p>Binary</p></th><th style="text-align: left" valign="bottom"><p>Hexadecimal</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>%0000</p></td><td style="text-align: left" valign="top"><p>$0</p></td></tr><tr><td style="text-align: left" valign="top"><p>%0001</p></td><td style="text-align: left" valign="top"><p>$1</p></td></tr><tr><td style="text-align: left" valign="top"><p>%0010</p></td><td style="text-align: left" valign="top"><p>$2</p></td></tr><tr><td style="text-align: left" valign="top"><p>%0011</p></td><td style="text-align: left" valign="top"><p>$3</p></td></tr><tr><td style="text-align: left" valign="top"><p>%0100</p></td><td style="text-align: left" valign="top"><p>$4</p></td></tr><tr><td style="text-align: left" valign="top"><p>%0101</p></td><td style="text-align: left" valign="top"><p>$5</p></td></tr><tr><td style="text-align: left" valign="top"><p>%0110</p></td><td style="text-align: left" valign="top"><p>$6</p></td></tr><tr><td style="text-align: left" valign="top"><p>%0111</p></td><td style="text-align: left" valign="top"><p>$7</p></td></tr><tr><td style="text-align: left" valign="top"><p>%1000</p></td><td style="text-align: left" valign="top"><p>$8</p></td></tr><tr><td style="text-align: left" valign="top"><p>%1001</p></td><td style="text-align: left" valign="top"><p>$9</p></td></tr><tr><td style="text-align: left" valign="top"><p>%1010</p></td><td style="text-align: left" valign="top"><p>$A</p></td></tr><tr><td style="text-align: left" valign="top"><p>%1011</p></td><td style="text-align: left" valign="top"><p>$B</p></td></tr><tr><td style="text-align: left" valign="top"><p>%1100</p></td><td style="text-align: left" valign="top"><p>$C</p></td></tr><tr><td style="text-align: left" valign="top"><p>%1101</p></td><td style="text-align: left" valign="top"><p>$D</p></td></tr><tr><td style="text-align: left" valign="top"><p>%1110</p></td><td style="text-align: left" valign="top"><p>$E</p></td></tr><tr><td style="text-align: left" valign="top"><p>%1111</p></td><td style="text-align: left" valign="top"><p>$F</p></td></tr></tbody></table></div></div><p>To convert a hexadecimal number into a binary number, simply substitute the corresponding 4 bits for each hexadecimal digit in the number. For example, to convert $ABCD into a binary value, simply convert each hexadecimal digit according to <a class="xref" href="ch02s02.html#binary_solidus_hexadecimal_conversion" title="Table 2-1. Binary/Hexadecimal Conversion">Table 2-1</a>, as shown here:<a class="indexterm" id="IDX-CHP-2-0020"/><a class="indexterm" id="IDX-CHP-2-0021"/></p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; "><colgroup><col/><col/><col/><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p>A</p></th><th style="text-align: left" valign="bottom"><p>B</p></th><th style="text-align: left" valign="bottom"><p>C</p></th><th style="text-align: left" valign="bottom"><p>D</p></th><th style="text-align: left" valign="bottom"><p>Hexadecimal</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>1010</p></td><td style="text-align: left" valign="top"><p>1011</p></td><td style="text-align: left" valign="top"><p>1100</p></td><td style="text-align: left" valign="top"><p>1101</p></td><td style="text-align: left" valign="top"><p>Binary</p></td></tr></tbody></table></div><p>To convert a binary number into hexadecimal format is almost as easy. The first step is to pad the binary number with zeros to make sure that there is a multiple of 4 bits in the number. For example, given the binary number 1011001010, the first step would be to add 2 bits to the left of the number so that it contains 12 bits. The converted binary value is 001011001010. The next step is to separate the binary value into groups of 4 bits, for example, 0010_1100_1010. Finally, look up these binary values in <a class="xref" href="ch02s02.html#binary_solidus_hexadecimal_conversion" title="Table 2-1. Binary/Hexadecimal Conversion">Table 2-1</a> and substitute the appropriate hexadecimal digits, that is, $2CA. Contrast this with the difficulty of conversion between decimal and binary or decimal and hexadecimal!</p><p>Because converting between hexadecimal and binary is an operation you will need to perform over and over again, you should take a few minutes and memorize the conversion table. Even if you have a calculator that will do the conversion for you, you'll find manual conversion to be a lot faster and more convenient when converting between binary and hex.</p></div>
<div class="sect1" title="2.3 Data Organization"><div class="titlepage"><div><div><h1 class="title"><a id="data_organization"/>2.3 Data Organization</h1></div></div></div><p>In pure mathematics a value's representation may take require an arbitrary number of bits. Computers, on the other hand, generally work with some specific number of bits. Common collections are single bits, groups of 4 bits (called <span class="emphasis"><em>nibbles</em></span>), groups of 8 bits (<span class="emphasis"><em>bytes</em></span>), groups of 16 bits (<span class="emphasis"><em>words</em></span>), groups of 32 bits (<span class="emphasis"><em>double words</em></span> or <span class="emphasis"><em>dwords</em></span>), groups of 64 bits (<span class="emphasis"><em>quad words</em></span> or <span class="emphasis"><em>qwords</em></span>), groups of 128 bits (<span class="emphasis"><em>long words</em></span> or <span class="emphasis"><em>lwords</em></span>), and more. The sizes are not arbitrary. There is a good reason for these particular values. This section will describe the bit groups commonly used on the Intel 80x86 chips.<a class="indexterm" id="IDX-CHP-2-0022"/><a class="indexterm" id="IDX-CHP-2-0023"/><a class="indexterm" id="IDX-CHP-2-0024"/><a class="indexterm" id="IDX-CHP-2-0025"/><a class="indexterm" id="IDX-CHP-2-0026"/><a class="indexterm" id="IDX-CHP-2-0027"/><a class="indexterm" id="IDX-CHP-2-0028"/></p><div class="sect2" title="2.3.1 Bits"><div class="titlepage"><div><div><h2 class="title"><a id="bits"/>2.3.1 Bits</h2></div></div></div><p>The smallest unit of data on a binary computer is a single bit. With a single bit, you can represent any two distinct items. Examples include 0 or 1, true or false, on or off, male or female, and right or wrong. However, you are <span class="emphasis"><em>not</em></span> limited to representing binary data types (that is, those objects that have only two distinct values). You could use a single bit to represent the numbers 723 and 1,245 or, perhaps, the values 6,254 and 5. You could also use a single bit to represent the colors red and blue. You could even represent two unrelated objects with a single bit. For example, you could represent the color red and the number 3,256 with a single bit. You can represent <span class="emphasis"><em>any two</em></span> different values with a single bit. However, you can represent <span class="emphasis"><em>only two</em></span> different values with a single bit.<a class="indexterm" id="IDX-CHP-2-0029"/></p><p>To confuse things even more, different bits can represent different things. For example, you could use one bit to represent the values 0 and 1, while a different bit could represent the values true and false. How can you tell by looking at the bits? The answer, of course, is that you can't. But this illustrates the whole idea behind computer data structures: <span class="emphasis"><em>data is what you define it to be</em></span>. If you use a bit to represent a boolean (true/false) value, then that bit (by your definition) represents true or false. For the bit to have any real meaning, you must be consistent. If you're using a bit to represent true or false at one point in your program, you shouldn't use that value to represent red or blue later.<a class="indexterm" id="IDX-CHP-2-0030"/><a class="indexterm" id="IDX-CHP-2-0031"/></p><p>Because most items you'll be trying to model require more than two different values, single-bit values aren't the most popular data type you'll use. However, because everything else consists of groups of bits, bits will play an important role in your programs. Of course, there are several data types that require two distinct values, so it would seem that bits are important by themselves. However, you will soon see that individual bits are difficult to manipulate, so we'll often use other data types to represent two-state values.</p></div><div class="sect2" title="2.3.2 Nibbles"><div class="titlepage"><div><div><h2 class="title"><a id="nibbles"/>2.3.2 Nibbles</h2></div></div></div><p>A <span class="emphasis"><em>nibble</em></span> is a collection of 4 bits. It wouldn't be a particularly interesting data structure except for two facts: <span class="emphasis"><em>binary-coded decimal (BCD)</em></span> numbers<sup>[<a class="footnote" href="#ftn.CHP-2-FN-1" id="CHP-2-FN-1">21</a>]</sup> and hexadecimal numbers. It takes 4 bits to represent a single BCD or hexadecimal digit. With a nibble, we can represent up to 16 distinct values because there are 16 unique combinations of a string of 4 bits:<a class="indexterm" id="IDX-CHP-2-0032"/><a class="indexterm" id="IDX-CHP-2-0033"/><a class="indexterm" id="IDX-CHP-2-0034"/></p><a id="I_programlisting2_d1e6328"/><pre class="programlisting">0000
0001
0010
0011
0100
0101
0110
0111
1000
1001
1010
1011
1100
1101
1110
1111</pre><p>In the case of hexadecimal numbers, the values 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, and F are represented with 4 bits. BCD uses 10 different digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) and requires also 4 bits (because we can only represent 8 different values with 3 bits, the additional 6 values we can represent with 4 bits are never used in BCD representation). In fact, any 16 distinct values can be represented with a nibble, though hexadecimal and BCD digits are the primary items we can represent with a single nibble.<a class="indexterm" id="IDX-CHP-2-0035"/><a class="indexterm" id="IDX-CHP-2-0036"/><a class="indexterm" id="IDX-CHP-2-0037"/><a class="indexterm" id="IDX-CHP-2-0038"/></p></div><div class="sect2" title="2.3.3 Bytes"><div class="titlepage"><div><div><h2 class="title"><a id="bytes"/>2.3.3 Bytes</h2></div></div></div><p>Without question, the most important data structure used by the 80x86 microprocessor is the byte, which consists of 8 bits. Main memory and I/O addresses on the 80x86 are all byte addresses. This means that the smallest item that can be individually accessed by an 80x86 program is an 8-bit value. To access anything smaller requires that we read the byte containing the data and eliminate the unwanted bits. The bits in a byte are normally numbered from 0 to 7, as shown in <a class="xref" href="ch02s03.html#bit_numbering" title="Figure 2-1. Bit numbering">Figure 2-1</a>.<a class="indexterm" id="IDX-CHP-2-0039"/><a class="indexterm" id="IDX-CHP-2-0040"/><a class="indexterm" id="IDX-CHP-2-0041"/></p><div class="figure"><a id="bit_numbering"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e6371"/><img alt="Bit numbering" src="tagoreillycom20100401nostarchimages577885.png"/></div></div><p class="title">Figure 2-1. Bit numbering</p></div><p>Bit 0 is the <span class="emphasis"><em>low-order bit</em></span> or <span class="emphasis"><em>least significant bit</em></span>, and bit 7 is the <span class="emphasis"><em>high-order bit</em></span> or <span class="emphasis"><em>most significant bit</em></span> of the byte. We'll refer to all other bits by their number.<a class="indexterm" id="IDX-CHP-2-0042"/><a class="indexterm" id="IDX-CHP-2-0043"/></p><p>Note that a byte also contains exactly two nibbles (see <a class="xref" href="ch02s03.html#the_two_nibbles_in_a_byte" title="Figure 2-2. The two nibbles in a byte">Figure 2-2</a>).</p><div class="figure"><a id="the_two_nibbles_in_a_byte"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e6403"/><img alt="The two nibbles in a byte" src="tagoreillycom20100401nostarchimages577887.png"/></div></div><p class="title">Figure 2-2. The two nibbles in a byte</p></div><p>Bits 0..3 compose the <span class="emphasis"><em>low-order nibble</em></span>, and bits 4..7 form the <span class="emphasis"><em>high-order nibble</em></span>. Because a byte contains exactly two nibbles, byte values require two hexadecimal digits.</p><p>Because a byte contains 8 bits, it can represent 2<sup>8</sup> (256) different values. Generally, we'll use a byte to represent numeric values in the range 0..255, signed numbers in the range −128..+127 (see <a class="xref" href="ch02s08.html" title="2.8 Signed and Unsigned Numbers">2.8 Signed and Unsigned Numbers</a>), ASCII/IBM character codes, and other special data types requiring no more than 256 different values. Many data types have fewer than 256 items, so 8 bits is usually sufficient.</p><p>Because the 80x86 is a byte-addressable machine, it turns out to be more efficient to manipulate a whole byte than an individual bit or nibble. For this reason, most programmers use a whole byte to represent data types that require no more than 256 items, even if fewer than 8 bits would suffice. For example, we'll often represent the boolean values true and false by 00000001<sub>2</sub> and 00000000<sub>2</sub>, respectively.</p><p>Probably the most important use for a byte is holding a character value. Characters typed at the keyboard, displayed on the screen, and printed on the printer all have numeric values. To communicate with the rest of the world, PCs typically use a variant of the <span class="emphasis"><em>ASCII character set</em></span>. There are 128 defined codes in the ASCII character set.<a class="indexterm" id="IDX-CHP-2-0044"/><a class="indexterm" id="IDX-CHP-2-0045"/></p><p>Because bytes are the smallest unit of storage in the 80x86 memory space, bytes also happen to be the smallest variable you can create in an HLA program. As you saw in the last chapter, you can declare an 8-bit signed integer variable using the <code class="literal">int8</code> data type. Because <code class="literal">int8</code> objects are signed, you can represent values in the range −128..+127 using an <code class="literal">int8</code> variable. You should only store signed values into <code class="literal">int8</code> variables; if you want to create an arbitrary byte variable, you should use the <code class="literal">byte</code> data type, as follows:<a class="indexterm" id="IDX-CHP-2-0046"/><a class="indexterm" id="IDX-CHP-2-0047"/></p><a id="I_programlisting2_d1e6473"/><pre class="programlisting">static
          byteVar: byte;</pre><p>The <code class="literal">byte</code> data type is a partially untyped data type. The only type information associated with a <code class="literal">byte</code> object is its size (1 byte). You may store any 8-bit value (small signed integers, small unsigned integers, characters, and the like) into a byte variable. It is up to you to keep track of the type of object you've put into a byte variable.</p></div><div class="sect2" title="2.3.4 Words"><div class="titlepage"><div><div><h2 class="title"><a id="words"/>2.3.4 Words</h2></div></div></div><p>A word is a group of 16 bits. We'll number the bits in a word from 0 to 15, as <a class="xref" href="ch02s03.html#bit_numbers_in_a_word" title="Figure 2-3. Bit numbers in a word">Figure 2-3</a> shows. Like the byte, bit 0 is the low-order bit. For words, bit 15 is the high-order bit. When referencing the other bits in a word, we'll use their bit position number.<a class="indexterm" id="IDX-CHP-2-0048"/></p><div class="figure"><a id="bit_numbers_in_a_word"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e6496"/><img alt="Bit numbers in a word" src="tagoreillycom20100401nostarchimages577889.png.jpg"/></div></div><p class="title">Figure 2-3. Bit numbers in a word</p></div><p>Notice that a word contains exactly 2 bytes. Bits 0..7 form the low-order byte, and bits 8..15 form the high-order byte (see <a class="xref" href="ch02s03.html#the_two_bytes_in_a_word" title="Figure 2-4. The two bytes in a word">Figure 2-4</a>).</p><div class="figure"><a id="the_two_bytes_in_a_word"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e6508"/><img alt="The two bytes in a word" src="tagoreillycom20100401nostarchimages577891.png.jpg"/></div></div><p class="title">Figure 2-4. The two bytes in a word</p></div><p>Of course, a word may be further broken down into four nibbles, as shown in <a class="xref" href="ch02s03.html#nibbles_in_a_word" title="Figure 2-5. Nibbles in a word">Figure 2-5</a>. Nibble 0 is the low-order nibble in the word, and nibble 3 is the high-order nibble of the word. We'll simply refer to the other two nibbles as <span class="emphasis"><em>nibble 1</em></span> or <span class="emphasis"><em>nibble 2</em></span>.<a class="indexterm" id="IDX-CHP-2-0049"/><a class="indexterm" id="IDX-CHP-2-0050"/></p><div class="figure"><a id="nibbles_in_a_word"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e6534"/><img alt="Nibbles in a word" src="tagoreillycom20100401nostarchimages577893.png.jpg"/></div></div><p class="title">Figure 2-5. Nibbles in a word</p></div><p>With 16 bits, you can represent 2<sup>16</sup> (65,536) different values. These could be the values in the range 0..65,535 or, as is usually the case, the signed values −32,768..+32,767, or any other data type with no more than 65,536 values. The three major uses for words are short signed integer values, short unsigned integer values, and Unicode characters.<a class="indexterm" id="IDX-CHP-2-0051"/><a class="indexterm" id="IDX-CHP-2-0052"/><a class="indexterm" id="IDX-CHP-2-0053"/><a class="indexterm" id="IDX-CHP-2-0054"/></p><p>Words can represent integer values in the range 0..65,535 or −32,768..32,767. Unsigned numeric values are represented by the binary value corresponding to the bits in the word. Signed numeric values use the two's complement form for numeric values (see <a class="xref" href="ch02s08.html" title="2.8 Signed and Unsigned Numbers">2.8 Signed and Unsigned Numbers</a>). As Unicode characters, words can represent up to 65,536 different characters, allowing the use of non-Roman character sets in a computer program. Unicode is an international standard, like ASCII, that allows computers to process non-Roman characters such as Asian, Greek, and Russian characters.<a class="indexterm" id="IDX-CHP-2-0055"/></p><p>As with bytes, you can also create word variables in an HLA program. Of course, in the last chapter you saw how to create 16-bit signed integer variables using the <code class="literal">int16</code> data type. To create an arbitrary word variable, just use the <code class="literal">word</code> data type, as follows:</p><a id="I_programlisting2_d1e6577"/><pre class="programlisting">static
          w: word;</pre></div><div class="sect2" title="2.3.5 Double Words"><div class="titlepage"><div><div><h2 class="title"><a id="double_words"/>2.3.5 Double Words</h2></div></div></div><p>A double word is exactly what its name implies, a pair of words. Therefore, a double-word quantity is 32 bits long, as shown in <a class="xref" href="ch02s03.html#bit_numbers_in_a_double_word" title="Figure 2-6. Bit numbers in a double word">Figure 2-6</a>.</p><div class="figure"><a id="bit_numbers_in_a_double_word"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e6589"/><img alt="Bit numbers in a double word" src="tagoreillycom20100401nostarchimages577895.png"/></div></div><p class="title">Figure 2-6. Bit numbers in a double word</p></div><p>Naturally, this double word can be divided into a high-order word and a low-order word, four different bytes, or eight different nibbles (see <a class="xref" href="ch02s03.html#nibbles_comma_bytes_comma_and_words_in_a" title="Figure 2-7. Nibbles, bytes, and words in a double word">Figure 2-7</a>).</p><p>Double words (dwords) can represent all kinds of different things. A common item you will represent with a double word is a 32-bit integer value (that allows unsigned numbers in the range 0..4,294,967,295 or signed numbers in the range −2,147,483,648..2,147,483,647). 32-bit floating-point values also fit into a double word. Another common use for double-word objects is to store pointer values.<a class="indexterm" id="IDX-CHP-2-0056"/><a class="indexterm" id="IDX-CHP-2-0057"/></p><div class="figure"><a id="nibbles_comma_bytes_comma_and_words_in_a"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e6613"/><img alt="Nibbles, bytes, and words in a double word" src="tagoreillycom20100401nostarchimages577897.png.jpg"/></div></div><p class="title">Figure 2-7. Nibbles, bytes, and words in a double word</p></div><p>In <a class="xref" href="ch01.html" title="Chapter 1. HELLO, WORLD OF ASSEMBLY LANGUAGE">Chapter 1</a>, you saw how to create 32-bit signed integer variables using the <code class="literal">int32</code> data type. You can also create an arbitrary double-word variable using the <code class="literal">dword</code> data type, as the following example demonstrates:</p><a id="I_programlisting2_d1e6628"/><pre class="programlisting">static
          d: dword;</pre></div><div class="sect2" title="2.3.6 Quad Words and Long Words"><div class="titlepage"><div><div><h2 class="title"><a id="quad_words_and_long_words"/>2.3.6 Quad Words and Long Words</h2></div></div></div><p>Obviously, we can keep on defining larger and larger word sizes. However, the 80x86 supports only certain native sizes, so there is little reason to keep on defining terms for larger and larger objects. Although bytes, words, and double words are the most common sizes you'll find in 80x86 programs, quad word (64-bit) values are also important because certain floating-point data types require 64 bits. Likewise, the SSE/MMX instruction set of modern 80x86 processors can manipulate 64-bit values. In a similar vein, long-word (128-bit) values are also important because the SSE instruction set on later 80x86 processors can manipulate 128-bit values. HLA allows the declaration of 64- and 128-bit values using the <code class="literal">qword</code> and <code class="literal">lword</code> types, as follows:</p><a id="I_programlisting2_d1e6641"/><pre class="programlisting">static
     q     :qword;
     l     :lword;</pre><p>Note that you may also define 64-bit and 128-bit integer values using HLA declarations like the following:</p><a id="I_programlisting2_d1e6645"/><pre class="programlisting">static
     i64          :int64;
     i128         :int128;</pre><p>However, you may not directly manipulate 64-bit and 128-bit integer objects using standard instructions like <code class="literal">mov</code>, <code class="literal">add</code>, and <code class="literal">sub</code> because the standard 80x86 integer registers process only 32 bits at a time. In <a class="xref" href="ch08.html" title="Chapter 8. ADVANCED ARITHMETIC">Chapter 8</a>, you will see how to manipulate these <span class="emphasis"><em>extended-precision</em></span> values.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-1" id="ftn.CHP-2-FN-1">21</a>] </sup>Binary-coded decimal is a numeric scheme used to represent decimal numbers using 4 bits for each decimal digit.</p></div></div></div>
<div class="sect1" title="2.4 Arithmetic Operations on Binary and Hexadecimal Numbers"><div class="titlepage"><div><div><h1 class="title"><a id="arithmetic_operations_on_binary_and_hexa"/>2.4 Arithmetic Operations on Binary and Hexadecimal Numbers</h1></div></div></div><p>There are several operations we can perform on binary and hexadecimal numbers. For example, we can add, subtract, multiply, divide, and perform other arithmetic operations. Although you needn't become an expert at it, you should be able to, in a pinch, perform these operations manually using a piece of paper and a pencil. Having just said that you should be able to perform these operations manually, the correct way to perform such arithmetic operations is to have a calculator that does them for you. There are several such calculators on the market; the following list shows some of the manufacturers of hexadecimal calculators (in 2010):<a class="indexterm" id="IDX-CHP-2-0058"/></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Casio</p></li><li class="listitem"><p>Hewlett-Packard</p></li><li class="listitem"><p>Sharp</p></li><li class="listitem"><p>Texas Instruments</p></li></ul></div><p>This list is by no means exhaustive. Other calculator manufacturers probably produce these devices as well. The Hewlett-Packard devices are arguably the best of the bunch. However, they are more expensive than the others. Sharp and Casio produce units that sell for well under fifty dollars. If you plan on doing any assembly language programming at all, owning one of these calculators is essential.</p><p>To understand why you should spend the money on a calculator, consider the following arithmetic problem:</p><a id="I_programlisting2_d1e6690"/><pre class="programlisting">$9
+ $1
----</pre><p>You're probably tempted to write in the answer $10 as the solution to this problem. But that is not correct! The correct answer is 10, which is $A, not 16, which is $10. A similar problem exists with the following subtraction problem:</p><a id="I_programlisting2_d1e6694"/><pre class="programlisting">$10
- $1
----</pre><p>You're probably tempted to answer $9 even though the correct answer is $F. Remember, this problem is asking, "What is the difference between 16 and 1?" The answer, of course, is 15, which is $F.</p><p>Even if these two problems don't bother you, in a stressful situation your brain will switch back into decimal while you're thinking about something else and you'll produce the incorrect result. Moral of the story—if you must do an arithmetic computation using hexadecimal numbers by hand, take your time and be careful about it. Either that, or convert the numbers to decimal, perform the operation in decimal, and convert them back to hexadecimal.</p></div>
<div class="sect1" title="2.5 A Note About Numbers vs. Representation"><div class="titlepage"><div><div><h1 class="title"><a id="a_note_about_numbers_vs._representation"/>2.5 A Note About Numbers vs. Representation</h1></div></div></div><p>Many people confuse numbers and their representation. A common question beginning assembly language students ask is, "I have a binary number in the EAX register; how do I convert that to a hexadecimal number in the EAX register?" The answer is, " You don't." Although a strong argument could be made that numbers in memory or in registers are represented in binary, it's best to view values in memory or in a register as <span class="emphasis"><em>abstract numeric quantities</em></span>. Strings of symbols like 128, $80, or %1000_0000 are not different numbers; they are simply different representations for the same abstract quantity that we refer to as "one hundred twenty-eight." Inside the computer, a number is a number regardless of representation; the only time representation matters is when you input or output the value in a human-readable form.<a class="indexterm" id="IDX-CHP-2-0059"/></p><p>Human-readable forms of numeric quantities are always strings of characters. To print the value 128 in human-readable form, you must convert the numeric value 128 to the three-character sequence 1 followed by 2 followed by 8. This would provide the decimal representation of the numeric quantity. If you prefer, you could convert the numeric value 128 to the three-character sequence $80. It's the same number, but we've converted it to a different sequence of characters because (presumably) we wanted to view the number using hexadecimal representation rather than decimal. Likewise, if we want to see the number in binary, then we must convert this numeric value to a string containing a 1 followed by seven 0s.</p><p>By default, HLA displays all <code class="literal">byte</code>, <code class="literal">word</code>, <code class="literal">dword</code>, <code class="literal">qword</code>, and <code class="literal">lword</code> variables using the hexadecimal numbering system when using the <code class="literal">stdout.put</code> routine. Likewise, HLA's <code class="literal">stdout.put</code> routine will display all register values in hexadecimal form. Consider the program in <a class="xref" href="ch02s05.html#decimal-to-hexadecimal_conversion_progra" title="Example 2-1. Decimal-to-hexadecimal conversion program">Example 2-1</a>, which converts values input as decimal numbers to their hexadecimal equivalents.</p><div class="example"><a id="decimal-to-hexadecimal_conversion_progra"/><p class="title">Example 2-1. Decimal-to-hexadecimal conversion program</p><div class="example-contents"><pre class="programlisting">program ConvertToHex;
#include( "stdlib.hhf" )
static
    value: int32;

begin ConvertToHex;

    stdout.put( "Input a decimal value:" );
    stdin.get( value );
    mov( value, eax );
    stdout.put( "The value ", value, " converted to hex is $", eax, nl );

end ConvertToHex;</pre></div></div><p>In a similar fashion, the default input base is also hexadecimal for registers and <code class="literal">byte</code>, <code class="literal">word</code>, <code class="literal">dword</code>, <code class="literal">qword</code>, or <code class="literal">lword</code> variables. The program in <a class="xref" href="ch02s05.html#hexadecimal-to-decimal_conversion_progra" title="Example 2-2. Hexadecimal-to-decimal conversion program">Example 2-2</a> is the converse of the one in <a class="xref" href="ch02s05.html#decimal-to-hexadecimal_conversion_progra" title="Example 2-1. Decimal-to-hexadecimal conversion program">Example 2-1</a>; it inputs a hexadecimal value and outputs it as decimal.<a class="indexterm" id="IDX-CHP-2-0060"/></p><div class="example"><a id="hexadecimal-to-decimal_conversion_progra"/><p class="title">Example 2-2. Hexadecimal-to-decimal conversion program</p><div class="example-contents"><pre class="programlisting">program ConvertToDecimal;
#include( "stdlib.hhf" )
static
    value: int32;

begin ConvertToDecimal;

    stdout.put( "Input a hexadecimal value: " );
    stdin.get( ebx );
    mov( ebx, value );
    stdout.put( "The value $", ebx, " converted to decimal is ", value, nl );

end ConvertToDecimal;</pre></div></div><p>Just because the HLA <code class="literal">stdout.put</code> routine chooses decimal as the default output base for <code class="literal">int8</code>, <code class="literal">int16</code>, and <code class="literal">int32</code> variables doesn't mean that these variables hold decimal numbers. Remember, memory and registers hold numeric values, not hexadecimal or decimal values. The <code class="literal">stdout.put</code> routine converts these numeric values to strings and prints the resulting strings. The choice of hexadecimal versus decimal output was a design choice in the HLA language, nothing more. You could very easily modify HLA so that it outputs registers and <code class="literal">byte</code>, <code class="literal">word</code>, <code class="literal">dword</code>, <code class="literal">qword</code>, or <code class="literal">lword</code> variables as decimal values rather than as hexadecimal. If you need to print the value of a register or <code class="literal">byte</code>, <code class="literal">word</code>, or <code class="literal">dword</code> variable as a decimal value, simply call one of the <code class="literal">putiX</code> routines to do this. The <code class="literal">stdout.puti8</code> routine will output its parameter as an 8-bit signed integer. Any 8-bit parameter will work. So you could pass an 8-bit register, an <code class="literal">int8</code> variable, or a <code class="literal">byte</code> variable as the parameter to <code class="literal">stdout.puti8</code> and the result will always be decimal. The <code class="literal">stdout.puti16</code> and <code class="literal">stdout.puti32</code> routines provide the same capabilities for 16-bit and 32-bit objects. The program in <a class="xref" href="ch02s05.html#variable-less_hexadecimal-to-decimal_con" title="Example 2-3. Variable-less hexadecimal-to-decimal converter">Example 2-3</a> demonstrates the decimal conversion program (<a class="xref" href="ch02s05.html#hexadecimal-to-decimal_conversion_progra" title="Example 2-2. Hexadecimal-to-decimal conversion program">Example 2-2</a>) using only the EBX register (that is, it does not use the variable <code class="literal">iValue</code>).</p><div class="example"><a id="variable-less_hexadecimal-to-decimal_con"/><p class="title">Example 2-3. Variable-less hexadecimal-to-decimal converter</p><div class="example-contents"><pre class="programlisting">program ConvertToDecimal2;
#include( "stdlib.hhf" )
begin ConvertToDecimal2;

    stdout.put( "Input a hexadecimal value: " );
    stdin.get( ebx );
    stdout.put( "The value $", ebx, " converted to decimal is " );
    stdout.puti32( ebx );
    stdout.newln();

end ConvertToDecimal2;</pre></div></div><p>Note that HLA's <code class="literal">stdin.get</code> routine uses the same default base for input as <code class="literal">stdout.put</code> uses for output. That is, if you attempt to read an <code class="literal">int8</code>, <code class="literal">int16</code>, or <code class="literal">int32</code> variable, the default input base is decimal. If you attempt to read a register or <code class="literal">byte</code>, <code class="literal">word</code>, <code class="literal">dword</code>, <code class="literal">qword</code>, or <code class="literal">lword</code> variable, the default input base is hexadecimal. If you want to change the default input base to decimal when reading a register or a <code class="literal">byte</code>, <code class="literal">word</code>, <code class="literal">dword</code>, <code class="literal">qword</code>, or <code class="literal">lword</code> variable, then you can use <code class="literal">stdin.geti8</code>, <code class="literal">stdin.geti16</code>, <code class="literal">stdin.geti32</code>, <code class="literal">stdin.geti64</code>, or <code class="literal">stdin.geti128</code>.<a class="indexterm" id="IDX-CHP-2-0061"/><a class="indexterm" id="IDX-CHP-2-0062"/><a class="indexterm" id="IDX-CHP-2-0063"/><a class="indexterm" id="IDX-CHP-2-0064"/><a class="indexterm" id="IDX-CHP-2-0065"/><a class="indexterm" id="IDX-CHP-2-0066"/><a class="indexterm" id="IDX-CHP-2-0067"/><a class="indexterm" id="IDX-CHP-2-0068"/><a class="indexterm" id="IDX-CHP-2-0069"/><a class="indexterm" id="IDX-CHP-2-0070"/><a class="indexterm" id="IDX-CHP-2-0071"/><a class="indexterm" id="IDX-CHP-2-0072"/><a class="indexterm" id="IDX-CHP-2-0073"/><a class="indexterm" id="IDX-CHP-2-0074"/><a class="indexterm" id="IDX-CHP-2-0075"/><a class="indexterm" id="IDX-CHP-2-0076"/><a class="indexterm" id="IDX-CHP-2-0077"/><a class="indexterm" id="IDX-CHP-2-0078"/></p><p>If you want to go in the opposite direction, that is you want to input or output an <code class="literal">int8</code>, <code class="literal">int16</code>, <code class="literal">int32</code>, <code class="literal">int64</code>, or <code class="literal">int128</code> variable as a hexadecimal value, you can call the <code class="literal">stdout.puth8</code>, <code class="literal">stdout.puth16</code>, <code class="literal">stdout.puth32</code>, <code class="literal">stdout.puth64</code>, <code class="literal">stdout.puth128</code>, <code class="literal">stdin.geth8</code>, <code class="literal">stdin.geth16</code>, <code class="literal">stdin.geth32</code>, <code class="literal">stdin.geth64</code>, or <code class="literal">stdin.geth128</code> routines. The <code class="literal">stdout.puth8</code>, <code class="literal">stdout.puth16</code>, <code class="literal">stdout.puth32</code>, <code class="literal">stdout.puth64</code>, and <code class="literal">stdout.puth128</code> routines write 8-bit, 16-bit, 32-bit, 64-bit, or 128-bit objects as hexadecimal values. The <code class="literal">stdin.geth8</code>, <code class="literal">stdin.geth16</code>, <code class="literal">stdin.geth32</code>, <code class="literal">stdin.geth64</code>, and <code class="literal">stdin.geth128</code> routines read 8-, 16-, 32-, 64-, and 128-bit values, respectively; they return their results in the AL, AX, or EAX registers (or in a parameter location for 64-bit and 128-bit values). The program in <a class="xref" href="ch02s05.html#demonstration_of_stdin.geth32_and_stdout" title="Example 2-4. Demonstration of stdin.geth32 and stdout.puth32">Example 2-4</a> demonstrates the use of a few of these routines:<a class="indexterm" id="IDX-CHP-2-0079"/><a class="indexterm" id="IDX-CHP-2-0080"/><a class="indexterm" id="IDX-CHP-2-0081"/><a class="indexterm" id="IDX-CHP-2-0082"/><a class="indexterm" id="IDX-CHP-2-0083"/><a class="indexterm" id="IDX-CHP-2-0084"/><a class="indexterm" id="IDX-CHP-2-0085"/><a class="indexterm" id="IDX-CHP-2-0086"/><a class="indexterm" id="IDX-CHP-2-0087"/><a class="indexterm" id="IDX-CHP-2-0088"/></p><div class="example"><a id="demonstration_of_stdin.geth32_and_stdout"/><p class="title">Example 2-4. Demonstration of <code class="literal">stdin.geth32</code> and <code class="literal">stdout.puth32</code></p><div class="example-contents"><pre class="programlisting">program HexIO;

#include( "stdlib.hhf" )

static
    i32: int32;

begin HexIO;

    stdout.put( "Enter a hexadecimal value: " );
    stdin.geth32();
    mov( eax, i32 );
    stdout.put( "The value you entered was $" );
    stdout.puth32( i32 );
    stdout.newln();

end HexIO;</pre></div></div></div>
<div class="sect1" title="2.6 Logical Operations on Bits"><div class="titlepage"><div><div><h1 class="title"><a id="logical_operations_on_bits"/>2.6 Logical Operations on Bits</h1></div></div></div><p>There are four primary logical operations we'll do with hexadecimal and binary numbers: <code class="literal">and</code>, <code class="literal">or</code>, <code class="literal">xor</code> (exclusive-or), and <code class="literal">not</code>. Unlike for the arithmetic operations, a hexadecimal calculator isn't necessary to perform these operations. It is often easier to do them by hand than to use an electronic device to compute them. The logical <code class="literal">and</code> operation is a dyadic<sup>[<a class="footnote" href="#ftn.CHP-2-FN-2" id="CHP-2-FN-2">22</a>]</sup> operation (meaning it accepts exactly two operands). These operands are individual binary bits. The <code class="literal">and</code> operation is:<a class="indexterm" id="IDX-CHP-2-0089"/><a class="indexterm" id="IDX-CHP-2-0090"/><a class="indexterm" id="IDX-CHP-2-0091"/></p><a id="I_programlisting2_d1e7186"/><pre class="programlisting">0 and 0 = 0
               0 and 1 = 0
               1 and 0 = 0
               1 and 1 = 1</pre><p>A compact way to represent the logical <code class="literal">and</code> operation is with a truth table. A truth table takes the form shown in <a class="xref" href="ch02s06.html#and_truth_table" title="Table 2-2. and Truth Table">Table 2-2</a>.<a class="indexterm" id="IDX-CHP-2-0092"/><a class="indexterm" id="IDX-CHP-2-0093"/></p><div class="table"><a id="and_truth_table"/><p class="title">Table 2-2. <code class="literal">and</code> Truth Table</p><div class="table-contents"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; " summary="and Truth Table"><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p><strong class="userinput"><code>and</code></strong></p></th><th style="text-align: left" valign="bottom"><p>0</p></th><th style="text-align: left" valign="bottom"><p>1</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>0</p></td></tr><tr><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>1</p></td></tr></tbody></table></div></div><p>This is just like the multiplication tables you've encountered in school. The values in the left column correspond to the leftmost operand of the <code class="literal">and</code> operation. The values in the top row correspond to the rightmost operand of the <code class="literal">and</code> operation. The value located at the intersection of the row and column (for a particular pair of input values) is the result of logically <code class="literal">and</code>ing those two values together.</p><p>In English, the logical <code class="literal">and</code> operation is, "If the first operand is 1 and the second operand is 1, the result is 1; otherwise the result is 0." We could also state this as, "If either or both operands are 0, the result is 0."</p><p>One important fact to note about the logical <code class="literal">and</code> operation is that you can use it to force a 0 result. If one of the operands is 0, the result is always 0 regardless of the other operand. In the truth table above, for example, the row labeled with a 0 input contains only 0s, and the column labeled with a 0 contains only 0 results. Conversely, if one operand contains a 1, the result is exactly the value of the second operand. These results of the <code class="literal">and</code> operation are very important, particularly when we want to force bits to 0. We will investigate these uses of the logical <code class="literal">and</code> operation in the next section.<a class="indexterm" id="IDX-CHP-2-0094"/></p><p>The logical <code class="literal">or</code> operation is also a dyadic operation. Its definition is:</p><a id="I_programlisting2_d1e7282"/><pre class="programlisting">0 or 0 = 0
               0 or 1 = 1
               1 or 0 = 1
               1 or 1 = 1</pre><p>The truth table for the <code class="literal">or</code> operation takes the form appearing in <a class="xref" href="ch02s06.html#or_truth_table" title="Table 2-3. or Truth Table">Table 2-3</a>.</p><div class="table"><a id="or_truth_table"/><p class="title">Table 2-3. <code class="literal">or</code> Truth Table</p><div class="table-contents"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; " summary="or Truth Table"><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p><strong class="userinput"><code>or</code></strong></p></th><th style="text-align: left" valign="bottom"><p>0</p></th><th style="text-align: left" valign="bottom"><p>1</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>1</p></td></tr><tr><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>1</p></td></tr></tbody></table></div></div><p>Colloquially, the logical <code class="literal">or</code> operation is, "If the first operand or the second operand (or both) is 1, the result is 1; otherwise the result is 0." This is also known as the <span class="emphasis"><em>inclusive-or</em></span> operation.<a class="indexterm" id="IDX-CHP-2-0095"/><a class="indexterm" id="IDX-CHP-2-0096"/><a class="indexterm" id="IDX-CHP-2-0097"/><a class="indexterm" id="IDX-CHP-2-0098"/><a class="indexterm" id="IDX-CHP-2-0099"/><a class="indexterm" id="IDX-CHP-2-0100"/><a class="indexterm" id="IDX-CHP-2-0101"/><a class="indexterm" id="IDX-CHP-2-0102"/></p><p>If one of the operands to the logical <code class="literal">or</code> operation is a 1, the result is always 1 regardless of the second operand's value. If one operand is 0, the result is always the value of the second operand. Like the logical <code class="literal">and</code> operation, this is an important side effect of the logical <code class="literal">or</code> operation that will prove quite useful.</p><p>Note that there is a difference between this form of the inclusive logical <code class="literal">or</code> operation and the standard English meaning. Consider the phrase "I am going to the store <span class="emphasis"><em>or</em></span> I am going to the park." Such a statement implies that the speaker is going to the store or to the park but not to both places. Therefore, the English version of logical <code class="literal">or</code> is slightly different from the inclusive-or operation; indeed, this is the definition of the <span class="emphasis"><em>exclusive-or</em></span> operation.<a class="indexterm" id="IDX-CHP-2-0103"/></p><p>The logical <code class="literal">xor</code> (exclusive-or) operation is also a dyadic operation. Its definition follows:</p><a id="I_programlisting2_d1e7410"/><pre class="programlisting">0 xor 0 = 0
               0 xor 1 = 1
               1 xor 0 = 1
               1 xor 1 = 0</pre><p>The truth table for the <code class="literal">xor</code> operation takes the form shown in <a class="xref" href="ch02s06.html#xor_truth_table" title="Table 2-4. xor Truth Table">Table 2-4</a>.</p><div class="table"><a id="xor_truth_table"/><p class="title">Table 2-4. <code class="literal">xor</code> Truth Table</p><div class="table-contents"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; " summary="xor Truth Table"><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p><strong class="userinput"><code>xor</code></strong></p></th><th style="text-align: left" valign="bottom"><p>0</p></th><th style="text-align: left" valign="bottom"><p>1</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>1</p></td></tr><tr><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>0</p></td></tr></tbody></table></div></div><p>In English, the logical <code class="literal">xor</code> operation is, "If the first operand or the second operand, but not both, is 1, the result is 1; otherwise the result is 0." Note that the exclusive-or operation is closer to the English meaning of the word <span class="emphasis"><em>or</em></span> than is the logical <code class="literal">or</code> operation.<a class="indexterm" id="IDX-CHP-2-0104"/></p><p>If one of the operands to the logical exclusive-or operation is a 1, the result is always the <span class="emphasis"><em>inverse</em></span> of the other operand; that is, if one operand is 1, the result is 0 if the other operand is 1, and the result is 1 if the other operand is 0. If the first operand contains a 0, then the result is exactly the value of the second operand. This feature lets you selectively invert bits in a bit string.</p><p>The logical <code class="literal">not</code> operation is a monadic operation (meaning it accepts only one operand):</p><a id="I_programlisting2_d1e7486"/><pre class="programlisting">not 0 = 1
               not 1 = 0</pre><p>The truth table for the <code class="literal">not</code> operation appears in <a class="xref" href="ch02s06.html#not_truth_table" title="Table 2-5. not Truth Table">Table 2-5</a>.</p><div class="table"><a id="not_truth_table"/><p class="title">Table 2-5. <code class="literal">not</code> Truth Table</p><div class="table-contents"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; " summary="not Truth Table"><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p><strong class="userinput"><code>not</code></strong><a class="indexterm" id="IDX-CHP-2-0105"/><a class="indexterm" id="IDX-CHP-2-0106"/><a class="indexterm" id="IDX-CHP-2-0107"/><a class="indexterm" id="IDX-CHP-2-0108"/><a class="indexterm" id="IDX-CHP-2-0109"/><a class="indexterm" id="IDX-CHP-2-0110"/><a class="indexterm" id="IDX-CHP-2-0111"/><a class="indexterm" id="IDX-CHP-2-0112"/><a class="indexterm" id="IDX-CHP-2-0113"/><a class="indexterm" id="IDX-CHP-2-0114"/><a class="indexterm" id="IDX-CHP-2-0115"/><a class="indexterm" id="IDX-CHP-2-0116"/><a class="indexterm" id="IDX-CHP-2-0117"/></p></th><th style="text-align: left" valign="bottom"><p>0</p></th><th style="text-align: left" valign="bottom"><p>1</p></th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; "> </td><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>0</p></td></tr></tbody></table></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-2" id="ftn.CHP-2-FN-2">22</a>] </sup>Many texts call this a binary operation. The term <span class="emphasis"><em>dyadic</em></span> means the same thing and avoids the confusion with the binary numbering system.</p></div></div></div>
<div class="sect1" title="2.7 Logical Operations on Binary Numbers and Bit Strings"><div class="titlepage"><div><div><h1 class="title"><a id="logical_operations_on_binary_numbers_and"/>2.7 Logical Operations on Binary Numbers and Bit Strings</h1></div></div></div><p>The previous section defines the logical functions for single-bit operands. Because the 80x86 uses groups of 8, 16, or 32 bits, we need to extend the definition of these functions to deal with more than 2 bits. Logical functions on the 80x86 operate on a <span class="emphasis"><em>bit-by-bit</em></span> (or <span class="emphasis"><em>bitwise</em></span>) basis. Given two values, these functions operate on bit 0, producing bit 0 of the result. They operate on bit 1 of the input values, producing bit 1 of the result, and so on. For example, if you want to compute the logical <code class="literal">and</code> of the following two 8-bit numbers, you would perform the logical <code class="literal">and</code> operation on each column independently of the others:</p><a id="I_programlisting2_d1e7598"/><pre class="programlisting">%1011_0101
                         %1110_1110
                         ----------
                         %1010_0100</pre><p>You may apply this bit-by-bit calculation to the other logical functions as well.</p><p>Because we've defined logical operations in terms of binary values, you'll find it much easier to perform logical operations on binary values than on other representations. Therefore, if you want to perform a logical operation on two hexadecimal numbers, you should convert them to binary first. This applies to most of the basic logical operations on binary numbers (e.g., <code class="literal">and</code>, <code class="literal">or</code>, <code class="literal">xor</code>, etc.).<a class="indexterm" id="IDX-CHP-2-0118"/><a class="indexterm" id="IDX-CHP-2-0119"/><a class="indexterm" id="IDX-CHP-2-0120"/></p><p>The ability to force bits to 0 or 1 using the logical <code class="literal">and</code>/<code class="literal">or</code> operations and the ability to invert bits using the logical <code class="literal">xor</code> operation are very important when working with strings of bits (e.g., binary numbers). These operations let you selectively manipulate certain bits within some bit string while leaving other bits unaffected. For example, if you have an 8-bit binary value <span class="emphasis"><em>X</em></span> and you want to guarantee that bits 4..7 contain 0s, you could logically <code class="literal">and</code> the value <span class="emphasis"><em>X</em></span> with the binary value %0000_1111. This bitwise logical <code class="literal">and</code> operation would force the H.O. 4 bits to 0 and pass the L.O. 4 bits of <span class="emphasis"><em>X</em></span> unchanged. Likewise, you could force the L.O. bit of <span class="emphasis"><em>X</em></span> to 1 and invert bit 2 of <span class="emphasis"><em>X</em></span> by logically <code class="literal">or</code>ing <span class="emphasis"><em>X</em></span> with %0000_0001 and logically exclusive-<code class="literal">or</code>ing <span class="emphasis"><em>X</em></span> with %0000_0100, respectively. Using the logical <code class="literal">and</code>, <code class="literal">or</code>, and <code class="literal">xor</code> operations to manipulate bit strings in this fashion is known as <span class="emphasis"><em>masking</em></span> bit strings. We use the term <span class="emphasis"><em>masking</em></span> because we can use certain values (1 for <code class="literal">and</code>, 0 for <code class="literal">or</code>/<code class="literal">xor</code>) to mask out or mask in certain bits from the operation when forcing bits to 0, 1, or their inverse.<a class="indexterm" id="IDX-CHP-2-0121"/></p><p>The 80x86 CPUs support four instructions that apply these bitwise logical operations to their operands. The instructions are <code class="literal">and</code>, <code class="literal">or</code>, <code class="literal">xor</code>, and <code class="literal">not</code>. The <code class="literal">and</code>, <code class="literal">or</code>, and <code class="literal">xor</code> instructions use the same syntax as the <code class="literal">add</code> and <code class="literal">sub</code> instructions:</p><a id="I_programlisting2_d1e7732"/><pre class="programlisting">and( <em class="replaceable"><code>source</code></em>, <em class="replaceable"><code>dest</code></em> );
 or( <em class="replaceable"><code>source</code></em>, <em class="replaceable"><code>dest</code></em> );
xor( <em class="replaceable"><code>source</code></em>, <em class="replaceable"><code>dest</code></em> );</pre><p>These operands have the same limitations as the <code class="literal">add</code> operands. Specifically, the <em class="replaceable"><code>source</code></em> operand has to be a constant, memory, or register operand, and the <em class="replaceable"><code>dest</code></em> operand must be a memory or register operand. Also, the operands must be the same size and they cannot both be memory operands. These instructions compute the obvious bitwise logical operation via the following equation:</p><a id="I_programlisting2_d1e7764"/><pre class="programlisting"><em class="replaceable"><code>dest</code></em> = <em class="replaceable"><code>dest operator source</code></em></pre><p>The 80x86 logical <code class="literal">not</code> instruction, because it has only a single operand, uses a slightly different syntax. This instruction takes the following form:</p><a id="I_programlisting2_d1e7776"/><pre class="programlisting">not( <em class="replaceable"><code>dest</code></em> );</pre><p>This instruction computes the following result:</p><a id="I_programlisting2_d1e7783"/><pre class="programlisting"><em class="replaceable"><code>dest</code></em> = not( <em class="replaceable"><code>dest</code></em> )</pre><p>The <em class="replaceable"><code>dest</code></em> operand must be a register or memory operand. This instruction inverts all the bits in the specified destination operand.</p><p>The program in <a class="xref" href="ch02s07.html#and_comma_or_comma_xor_comma_and_not_exa" title="Example 2-5. and, or, xor, and not example">Example 2-5</a> inputs two hexadecimal values from the user and calculates their logical <code class="literal">and</code>, <code class="literal">or</code>, <code class="literal">xor</code>, and <code class="literal">not</code>:</p><div class="example"><a id="and_comma_or_comma_xor_comma_and_not_exa"/><p class="title">Example 2-5. <code class="literal">and</code>, <code class="literal">or</code>, <code class="literal">xor</code>, and <code class="literal">not</code> example</p><div class="example-contents"><pre class="programlisting">program LogicalOp;
#include( "stdlib.hhf" )
begin LogicalOp;

    stdout.put( "Input left operand: " );
    stdin.get( eax );
    stdout.put( "Input right operand: " );
    stdin.get( ebx );

    mov( eax, ecx );
    and( ebx, ecx );
    stdout.put( "$", eax, " and $", ebx, " = $", ecx, nl );

    mov( eax, ecx );
    or( ebx, ecx );
    stdout.put( "$", eax, " or $", ebx, " = $", ecx, nl );

    mov( eax, ecx );
    xor( ebx, ecx );
    stdout.put( "$", eax, " xor $", ebx, " = $", ecx, nl );

    mov( eax, ecx );
    not( ecx );
    stdout.put( "not $", eax, " = $", ecx, nl );

    mov( ebx, ecx );
    not( ecx );
    stdout.put( "not $", ebx, " = $", ecx, nl );

end LogicalOp;</pre></div></div></div>
<div class="sect1" title="2.8 Signed and Unsigned Numbers"><div class="titlepage"><div><div><h1 class="title"><a id="signed_and_unsigned_numbers"/>2.8 Signed and Unsigned Numbers</h1></div></div></div><p>Thus far, we've treated binary numbers as unsigned values. The binary number ...00000 represents 0, ...00001 represents 1, ...00010 represents 2, and so on toward infinity. What about negative numbers? Signed values have been tossed around in previous sections, and we've mentioned the two's complement numbering system, but we haven't discussed how to represent negative numbers using the binary numbering system. Now it is time to describe the two's complement numbering system.<a class="indexterm" id="IDX-CHP-2-0122"/><a class="indexterm" id="IDX-CHP-2-0123"/><a class="indexterm" id="IDX-CHP-2-0124"/><a class="indexterm" id="IDX-CHP-2-0125"/><a class="indexterm" id="IDX-CHP-2-0126"/><a class="indexterm" id="IDX-CHP-2-0127"/></p><p>To represent signed numbers using the binary numbering system, we have to place a restriction on our numbers: They must have a finite and fixed number of bits. For our purposes, we're going to severely limit the number of bits to 8, 16, 32, 64, 128, or some other small number of bits.<a class="indexterm" id="IDX-CHP-2-0128"/></p><p>With a fixed number of bits we can represent only a certain number of objects. For example, with 8 bits we can represent only 256 different values. Negative values are objects in their own right, just like positive numbers and 0; therefore, we'll have to use some of the 256 different 8-bit values to represent negative numbers. In other words, we have to use up some of the bit combinations to represent negative numbers. To make things fair, we'll assign half of the possible combinations to the negative values and half to the positive values and 0. So we can represent the negative values −128..−1 and the nonnegative values 0..127 with a single 8-bit byte. With a 16-bit word we can represent values in the range −32,768..+32,767. With a 32-bit double word we can represent values in the range −2,147,483,648..+2,147,483,647. In general, with <span class="emphasis"><em>n</em></span> bits we can represent the signed values in the range −2<sup><span class="emphasis"><em>n</em></span>−1</sup> to +2<sup><span class="emphasis"><em>n</em></span>−1</sup>−1.</p><p>Okay, so we can represent negative values. Exactly how do we do it? Well, there are many possible ways, but the 80x86 microprocessor uses the two's complement notation, so it makes sense to study that method. In the two's complement system, the H.O. bit of a number is a <span class="emphasis"><em>sign bit</em></span>. If the H.O. bit is 0, the number is positive; if the H.O. bit is 1, the number is negative. Following are some examples.</p><p>For 16-bit numbers:</p><a id="I_programlisting2_d1e7883"/><pre class="programlisting">$8000 is negative because the H.O. bit is 1.
      $100 is positive because the H.O. bit is 0.
      $7FFF is positive.
      $FFFF is negative.
      $FFF ($0FFF) is positive.</pre><p>If the H.O. bit is 0, then the number is positive and uses the standard binary format. If the H.O. bit is 1, then the number is negative and uses the two's complement form. To convert a positive number to its negative, two's complement form, you use the following algorithm:<a class="indexterm" id="IDX-CHP-2-0129"/></p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Invert all the bits in the number; that is, apply the logical <code class="literal">not</code> function.</p></li><li class="listitem"><p>Add 1 to the inverted result and ignore any overflow out of the H.O. bit.</p><p>For example, to compute the 8-bit equivalent of −5:</p><a id="I_programlisting2_d1e7902"/><pre class="programlisting">%0000_0101             5 (in binary).
                %1111_1010             Invert all the bits.
                %1111_1011             Add 1 to obtain result.</pre><p>If we take −5 and perform the two's complement operation on it, we get our original value, %0000_0101, back again, just as we expect:<a class="indexterm" id="IDX-CHP-2-0130"/></p><a id="I_programlisting2_d1e7911"/><pre class="programlisting">%1111_1011             Two's complement for −5.
                %0000_0100             Invert all the bits.
                %0000_0101             Add 1 to obtain result (+5).</pre><p>The following examples provide some positive and negative 16-bit signed values:</p><a id="I_programlisting2_d1e7915"/><pre class="programlisting">$7FFF: +32767, the largest 16-bit positive number.
     $8000: −32768, the smallest 16-bit negative number.
     $4000: +16384.</pre><p>To convert the numbers above to their negative counterpart (that is, to negate them), do the following:</p><a id="I_programlisting2_d1e7919"/><pre class="programlisting">$7FFF:          %0111_1111_1111_1111   +32,767
                %1000_0000_0000_0000   Invert all the bits (8000h)
                %1000_0000_0000_0001   Add 1 (8001h or −32,767)

4000h:          %0100_0000_0000_0000   16,384
                %1011_1111_1111_1111   Invert all the bits ($BFFF)
                %1100_0000_0000_0000   Add 1 ($C000 or −16,384)

$8000:          %1000_0000_0000_0000   −32,768
                %0111_1111_1111_1111   Invert all the bits ($7FFF)
                %1000_0000_0000_0000   Add one (8000h or −32,768)</pre></li></ol></div><p>$8000 inverted becomes $7FFF. After adding 1 we obtain $8000! Wait, what's going on here? −(−32,768) is −32,768? Of course not. But the value +32,768 cannot be represented with a 16-bit signed number, so we cannot negate the smallest negative value.</p><p>Why bother with such a miserable numbering system? Why not use the H.O. bit as a sign flag, storing the positive equivalent of the number in the remaining bits? (This, by the way, is known as the <span class="emphasis"><em>one's complement numbering system</em></span>.) The answer lies in the hardware. As it turns out, negating values is the only tedious job. With the two's complement system, most other operations are as easy as the binary system. For example, suppose you were to perform the addition 5 + (−5). The result is 0. Consider what happens when we add these two values in the two's complement system:<a class="indexterm" id="IDX-CHP-2-0131"/><a class="indexterm" id="IDX-CHP-2-0132"/></p><a id="I_programlisting2_d1e7937"/><pre class="programlisting">%  0000_0101
                          %  1111_1011
                          ------------
                          %1_0000_0000</pre><p>We end up with a carry into the ninth bit, and all other bits are 0. As it turns out, if we ignore the carry out of the H.O. bit, adding two signed values always produces the correct result when using the two's complement numbering system. This means we can use the same hardware for signed and unsigned addition and subtraction. This wouldn't be the case with other numbering systems.</p><p>Usually, you will not need to perform the two's complement operation by hand. The 80x86 microprocessor provides an instruction, <code class="literal">neg</code> (negate), that performs this operation for you. Furthermore, hexadecimal calculators perform this operation by pressing the change sign key (+/− or CHS). Nevertheless, manually computing the two's complement is easy, and you should know how to do it.</p><p>Remember that the data represented by a set of binary bits depends entirely on the context. The 8-bit binary value %1100_0000 could represent a character, it could represent the unsigned decimal value 192, or it could represent the signed decimal value −64. As the programmer, it is your responsibility to define the data's format and then use the data consistently.</p><p>The 80x86 negate instruction, <code class="literal">neg</code>, uses the same syntax as the <code class="literal">not</code> instruction; that is, it takes a single destination operand:</p><a id="I_programlisting2_d1e7956"/><pre class="programlisting">neg( <em class="replaceable"><code>dest</code></em> );</pre><p>This instruction computes <em class="replaceable"><code>dest</code></em> <code class="literal">= -</code><em class="replaceable"><code>dest</code></em><code class="literal">;</code> and the operand has the same limitations as for <code class="literal">not</code> (it must be a memory location or a register). <code class="literal">neg</code> operates on byte-, word-, and dword-sized objects. Because this is a signed integer operation, it only makes sense to operate on signed integer values. The program in <a class="xref" href="ch02s08.html#twoscomplement_example" title="Example 2-6. twosComplement example">Example 2-6</a> demonstrates the two's complement operation by using the <code class="literal">neg</code> instruction:</p><div class="example"><a id="twoscomplement_example"/><p class="title">Example 2-6. <code class="literal">twosComplement</code> example</p><div class="example-contents"><pre class="programlisting">program twosComplement;
#include( "stdlib.hhf" )

static
    PosValue:   int8;
    NegValue:   int8;

begin twosComplement;

    stdout.put( "Enter an integer between 0 and 127: " );
    stdin.get( PosValue );

    stdout.put( nl, "Value in hexadecimal: $" );
    stdout.puth8( PosValue );

    mov( PosValue, al );
    not( al );
    stdout.put( nl, "Invert all the bits: $", al, nl );
    add( 1, al );
    stdout.put( "Add one: $", al, nl );
    mov( al, NegValue );
    stdout.put( "Result in decimal: ", NegValue, nl );

    stdout.put
    (
        nl,
        "Now do the same thing with the NEG instruction: ",
        nl
    );
    mov( PosValue, al );
    neg( al );
    mov( al, NegValue );
    stdout.put( "Hex result = $", al, nl );
    stdout.put( "Decimal result = ", NegValue, nl );

end twosComplement;</pre></div></div><p>As you've seen previously, you use the <code class="literal">int8</code>, <code class="literal">int16</code>, <code class="literal">int32</code>, <code class="literal">int64</code>, and <code class="literal">int128</code> data types to reserve storage for signed integer variables. You've also seen routines like <code class="literal">stdout.puti8</code> and <code class="literal">stdin.geti32</code> that read and write signed integer values. Because this section has made it abundantly clear that you must differentiate signed and unsigned calculations in your programs, you should probably be asking yourself, "How do I declare and use unsigned integer variables?"<a class="indexterm" id="IDX-CHP-2-0133"/><a class="indexterm" id="IDX-CHP-2-0134"/><a class="indexterm" id="IDX-CHP-2-0135"/><a class="indexterm" id="IDX-CHP-2-0136"/><a class="indexterm" id="IDX-CHP-2-0137"/><a class="indexterm" id="IDX-CHP-2-0138"/><a class="indexterm" id="IDX-CHP-2-0139"/><a class="indexterm" id="IDX-CHP-2-0140"/><a class="indexterm" id="IDX-CHP-2-0141"/></p><p>The first part of the question, "How do I declare unsigned integer variables," is the easiest to answer. You simply use the <code class="literal">uns8</code>, <code class="literal">uns16</code>, <code class="literal">uns32</code>, <code class="literal">uns64</code>, and <code class="literal">uns128</code> data types when declaring the variables. For example:<a class="indexterm" id="IDX-CHP-2-0142"/><a class="indexterm" id="IDX-CHP-2-0143"/><a class="indexterm" id="IDX-CHP-2-0144"/></p><a id="I_programlisting2_d1e8085"/><pre class="programlisting">static
     u8:          uns8;
     u16:         uns16;
     u32:         uns32;
     u64:         uns64;
     u128:        uns128;</pre><p>As for using these unsigned variables, the HLA Standard Library provides a complementary set of input/output routines for reading and displaying unsigned variables. As you can probably guess, these routines include <code class="literal">stdout.putu8</code>, <code class="literal">stdout.putu16</code>, <code class="literal">stdout.putu32</code>, <code class="literal">stdout.putu64</code>, <code class="literal">stdout.putu128</code>, <code class="literal">stdout.putu8Size</code>, <code class="literal">stdout.putu16Size</code>, <code class="literal">stdout.putu32Size</code>, <code class="literal">stdout.putu64Size</code>, <code class="literal">stdout.putu128Size</code>, <code class="literal">stdin.getu8</code>, <code class="literal">stdin.getu16</code>, <code class="literal">stdin.getu32</code>, <code class="literal">stdin.getu64</code>, and <code class="literal">stdin.getu128</code>. You use these routines just as you would use their signed integer counterparts except you get to use the full range of the unsigned values with these routines. The source code in <a class="xref" href="ch02s08.html#unsigned_i_solidus_o" title="Example 2-7. Unsigned I/O">Example 2-7</a> demonstrates unsigned I/O as well as demonstrates what can happen if you mix signed and unsigned operations in the same calculation.<a class="indexterm" id="IDX-CHP-2-0145"/><a class="indexterm" id="IDX-CHP-2-0146"/><a class="indexterm" id="IDX-CHP-2-0147"/><a class="indexterm" id="IDX-CHP-2-0148"/><a class="indexterm" id="IDX-CHP-2-0149"/><a class="indexterm" id="IDX-CHP-2-0150"/><a class="indexterm" id="IDX-CHP-2-0151"/><a class="indexterm" id="IDX-CHP-2-0152"/><a class="indexterm" id="IDX-CHP-2-0153"/><a class="indexterm" id="IDX-CHP-2-0154"/><a class="indexterm" id="IDX-CHP-2-0155"/></p><div class="example"><a id="unsigned_i_solidus_o"/><p class="title">Example 2-7. Unsigned I/O</p><div class="example-contents"><pre class="programlisting">program UnsExample;
#include( "stdlib.hhf" )

static
    UnsValue:   uns16;

begin UnsExample;

    stdout.put( "Enter an integer between 32,768 and 65,535: " );
    stdin.getu16();
    mov( ax, UnsValue );

    stdout.put
    (
        "You entered ",
        UnsValue,
        ".  If you treat this as a signed integer, it is "
    );
    stdout.puti16( UnsValue );
    stdout.newln();

end UnsExample;</pre></div></div></div>
<div class="sect1" title="2.9 Sign Extension, Zero Extension, Contraction, and Saturation"><div class="titlepage"><div><div><h1 class="title"><a id="sign_extension_comma_zero_extension_comm"/>2.9 Sign Extension, Zero Extension, Contraction, and Saturation</h1></div></div></div><p>Because two's complement format integers have a fixed length, a small problem develops. What happens if you need to convert an 8-bit two's complement value to 16 bits? This problem and its converse (converting a 16-bit value to 8 bits) can be accomplished via <span class="emphasis"><em>sign extension</em></span> and <span class="emphasis"><em>contraction</em></span> operations.<a class="indexterm" id="IDX-CHP-2-0156"/><a class="indexterm" id="IDX-CHP-2-0157"/></p><p>Consider the value −64. The 8-bit two's complement value for this number is $C0. The 16-bit equivalent of this number is $FFC0. Now consider the value +64. The 8- and 16-bit versions of this value are $40 and $0040, respectively. The difference between the 8- and 16-bit numbers can be described by the rule, "If the number is negative, the H.O. byte of the 16-bit number contains $FF; if the number is positive, the H.O. byte of the 16-bit quantity is 0."</p><p>To extend a signed value from some number of bits to a greater number of bits is easy; just copy the sign bit into all the additional bits in the new format. For example, to sign extend an 8-bit number to a 16-bit number, simply copy bit 7 of the 8-bit number into bits 8..15 of the 16-bit number. To sign extend a 16-bit number to a double word, simply copy bit 15 into bits 16..31 of the double word.<a class="indexterm" id="IDX-CHP-2-0158"/><a class="indexterm" id="IDX-CHP-2-0159"/><a class="indexterm" id="IDX-CHP-2-0160"/><a class="indexterm" id="IDX-CHP-2-0161"/><a class="indexterm" id="IDX-CHP-2-0162"/><a class="indexterm" id="IDX-CHP-2-0163"/><a class="indexterm" id="IDX-CHP-2-0164"/><a class="indexterm" id="IDX-CHP-2-0165"/></p><p>You must use sign extension when manipulating signed values of varying lengths. Often you'll need to add a byte quantity to a word quantity. You must sign extend the byte quantity to a word before the operation takes place. Other operations (multiplication and division, in particular) may require a sign extension to 32 bits:</p><a id="I_programlisting2_d1e8257"/><pre class="programlisting">Sign Extension:
8 Bits      16 Bits       32 Bits

$80         $FF80         $FFFF_FF80
$28         $0028         $0000_0028
$9A         $FF9A         $FFFF_FF9A
$7F         $007F         $0000_007F
            $1020         $0000_1020
            $8086         $FFFF_8086</pre><p>To extend an unsigned value to a larger one, you must zero extend the value. Zero extension is very easy—just store a 0 into the H.O. byte(s) of the larger operand. For example, to zero extend the 8-bit value $82 to 16 bits, you simply add a 0 to the H.O. byte, yielding $0082.</p><a id="I_programlisting2_d1e8261"/><pre class="programlisting">Zero Extension:
8 Bits      16 Bits       32 Bits

$80         $0080         $0000_0080
$28         $0028         $0000_0028
$9A         $009A         $0000_009A
$7F         $007F         $0000_007F
            $1020         $0000_1020
            $8086         $0000_8086</pre><p>The 80x86 provides several instructions that will let you sign or zero extend a smaller number to a larger number. <a class="xref" href="ch02s09.html#instructions_for_extending_al_comma_ax_c" title="Table 2-6. Instructions for Extending AL, AX, and EAX">Table 2-6</a> lists a group of instructions that will sign extend the AL, AX, or EAX register.</p><div class="table"><a id="instructions_for_extending_al_comma_ax_c"/><p class="title">Table 2-6. Instructions for Extending AL, AX, and EAX</p><div class="table-contents"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; " summary="Instructions for Extending AL, AX, and EAX"><colgroup><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p>Instruction</p></th><th style="text-align: left" valign="bottom"><p>Explanation</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p><code class="literal">cbw();</code></p></td><td style="text-align: left" valign="top"><p>Converts the byte in AL to a word in AX via sign extension.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">cwd();</code></p></td><td style="text-align: left" valign="top"><p>Converts the word in AX to a double word in DX:AX via sign extension.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">cdq();</code></p></td><td style="text-align: left" valign="top"><p>Converts the double word in EAX to the quad word in EDX:EAX via sign extension.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">cwde();</code></p></td><td style="text-align: left" valign="top"><p>Converts the word in AX to a double word in EAX via sign extension.</p></td></tr></tbody></table></div></div><p>Note that the <code class="literal">cwd</code> (convert word to double word) instruction does not sign extend the word in AX to the double word in EAX. Instead, it stores the H.O. word of the sign extension into the DX register (the notation DX:AX tells you that you have a double-word value with DX containing the upper 16 bits and AX containing the lower 16 bits of the value). If you want the sign extension of AX to go into EAX, you should use the <code class="literal">cwde</code> (convert word to double word, extended) instruction.<a class="indexterm" id="IDX-CHP-2-0166"/><a class="indexterm" id="IDX-CHP-2-0167"/></p><p>The four instructions above are unusual in the sense that these are the first instructions you've seen that do not have any operands. These instructions' operands are <span class="emphasis"><em>implied</em></span> by the instructions themselves.</p><p>Within a few chapters you will discover just how important these instructions are and why the <code class="literal">cwd</code> and <code class="literal">cdq</code> instructions involve the DX and EDX registers. However, for simple sign extension operations, these instructions have a few major drawbacks—you do not get to specify the source and destination operands, and the operands must be registers.</p><p>For general sign extension operations, the 80x86 provides an extension of the <code class="literal">mov</code> instruction, <code class="literal">movsx</code> (move with sign extension), that copies data and sign extends the data while copying it. The <code class="literal">movsx</code> instruction's syntax is very similar to the <code class="literal">mov</code> instruction:</p><a id="I_programlisting2_d1e8356"/><pre class="programlisting">movsx( <em class="replaceable"><code>source</code></em>, <em class="replaceable"><code>dest</code></em> );</pre><p>The big difference in syntax between this instruction and the <code class="literal">mov</code> instruction is the fact that the destination operand must be larger than the source operand. That is, if the source operand is a byte, the destination operand must be a word or a double word. Likewise, if the source operand is a word, the destination operand must be a double word. Another difference is that the destination operand has to be a register; the source operand, however, can be a memory location.<sup>[<a class="footnote" href="#ftn.CHP-2-FN-3" id="CHP-2-FN-3">23</a>]</sup> The <code class="literal">movsx</code> instruction does not allow constant operands.</p><p>To zero extend a value, you can use the <code class="literal">movzx</code> instruction. It has the same syntax and restrictions as the <code class="literal">movsx</code> instruction. Zero extending certain 8-bit registers (AL, BL, CL, and DL) into their corresponding 16-bit registers is easily accomplished without using <code class="literal">movzx</code> by loading the complementary H.O. register (AH, BH, CH, or DH) with 0. Obviously, to zero extend AX into DX:AX or EAX into EDX:EAX, all you need to do is load DX or EDX with 0.<sup>[<a class="footnote" href="#ftn.CHP-2-FN-4" id="CHP-2-FN-4">24</a>]</sup></p><p>The sample program in <a class="xref" href="ch02s09.html#sign_extension_instructions" title="Example 2-8. Sign extension instructions">Example 2-8</a> demonstrates the use of the sign extension instructions.</p><div class="example"><a id="sign_extension_instructions"/><p class="title">Example 2-8. Sign extension instructions</p><div class="example-contents"><pre class="programlisting">program signExtension;
#include( "stdlib.hhf" )

static
    i8:     int8;
    i16:    int16;
    i32:    int32;

begin signExtension;

    stdout.put( "Enter a small negative number: " );
    stdin.get( i8 );

    stdout.put( nl, "Sign extension using CBW and CWDE:", nl, nl );

    mov( i8, al );
    stdout.put( "You entered ", i8, " ($", al, ")", nl );

    cbw();
    mov( ax, i16 );
    stdout.put( "16-bit sign extension: ", i16, " ($", ax, ")", nl );

    cwde();
    mov( eax, i32 );
    stdout.put( "32-bit sign extension: ", i32, " ($", eax, ")", nl );

    stdout.put( nl, "Sign extension using MOVSX:", nl, nl );

    movsx( i8, ax );
    mov( ax, i16 );
    stdout.put( "16-bit sign extension: ", i16, " ($", ax, ")", nl );

    movsx( i8, eax );
    mov( eax, i32 );
    stdout.put( "32-bit sign extension: ", i32, " ($", eax, ")", nl );

end signExtension;</pre></div></div><p>Sign <span class="emphasis"><em>contraction</em></span>, converting a value with some number of bits to the identical value with a fewer number of bits, is a little more troublesome. Sign extension never fails. Given an <span class="emphasis"><em>m</em></span>-bit signed value, you can always convert it to an <span class="emphasis"><em>n</em></span>-bit number (where <span class="emphasis"><em>n</em></span> &gt; <span class="emphasis"><em>m</em></span>) using sign extension. Unfortunately, given an <span class="emphasis"><em>n</em></span>-bit number, you cannot always convert it to an <span class="emphasis"><em>m</em></span>-bit number if <span class="emphasis"><em>m</em></span> &lt; <span class="emphasis"><em>n</em></span>. For example, consider the value −448. As a 16-bit signed number, its hexadecimal representation is $FE40. Unfortunately, the magnitude of this number is too large for an 8-bit value, so you cannot sign contract it to 8 bits. This is an example of an overflow condition that occurs upon conversion.<a class="indexterm" id="IDX-CHP-2-0168"/></p><p>To properly sign contract a value, you must look at the H.O. byte(s) that you want to discard. The H.O. bytes must all contain either 0 or $FF. If you encounter any other values, you cannot contract it without overflow. Finally, the H.O. bit of your resulting value must match <span class="emphasis"><em>every</em></span> bit you've removed from the number. Here are some examples (16 bits to 8 bits):</p><a id="I_programlisting2_d1e8439"/><pre class="programlisting">$FF80 can be sign contracted to $80.
          $0040 can be sign contracted to $40.
          $FE40 cannot be sign contracted to 8 bits.
          $0100 cannot be sign contracted to 8 bits.</pre><p>Another way to reduce the size of an integer is by <span class="emphasis"><em>saturation</em></span>. Saturation is useful in situations where you must convert a larger object to a smaller object, and you're willing to live with possible loss of precision. To convert a value via saturation you simply copy the larger value to the smaller value if it is not outside the range of the smaller object. If the larger value is outside the range of the smaller value, then you <span class="emphasis"><em>clip</em></span> the value by setting it to the largest (or smallest) value within the range of the smaller object.<a class="indexterm" id="IDX-CHP-2-0169"/><a class="indexterm" id="IDX-CHP-2-0170"/><a class="indexterm" id="IDX-CHP-2-0171"/><a class="indexterm" id="IDX-CHP-2-0172"/><a class="indexterm" id="IDX-CHP-2-0173"/><a class="indexterm" id="IDX-CHP-2-0174"/><a class="indexterm" id="IDX-CHP-2-0175"/><a class="indexterm" id="IDX-CHP-2-0176"/></p><p>For example, when converting a 16-bit signed integer to an 8-bit signed integer, if the 16-bit value is in the range −128..+127, you simply copy the L.O. byte of the 16-bit object to the 8-bit object. If the 16-bit signed value is greater than +127, then you clip the value to +127 and store +127 into the 8-bit object. Likewise, if the value is less than −128, you clip the final 8-bit object to −128. Saturation works the same way when clipping 32-bit values to smaller values. If the larger value is outside the range of the smaller value, then you simply set the smaller value to the value closest to the out-of-range value that you can represent with the smaller value.</p><p>Obviously, if the larger value is outside the range of the smaller value, then there will be a loss of precision during the conversion. While clipping the value to the limits the smaller object imposes is never desirable, sometimes this is acceptable because the alternative is to raise an exception or otherwise reject the calculation. For many applications, such as audio or video processing, the clipped result is still recognizable, so this is a reasonable conversion.</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-3" id="ftn.CHP-2-FN-3">23</a>] </sup>This doesn't turn out to be much of a limitation because sign extension almost always precedes an arithmetic operation that must take place in a register.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-4" id="ftn.CHP-2-FN-4">24</a>] </sup>Zero extending into DX:AX or EDX:EAX is just as necessary as the CWD and CDQ instructions, as you will eventually see.</p></div></div></div>
<div class="sect1" title="2.10 Shifts and Rotates"><div class="titlepage"><div><div><h1 class="title"><a id="shifts_and_rotates"/>2.10 Shifts and Rotates</h1></div></div></div><p>Another set of logical operations that apply to bit strings is the <span class="emphasis"><em>shift</em></span> and <span class="emphasis"><em>rotate</em></span> operations. These two categories can be further broken down into <span class="emphasis"><em>left shifts, left rotates, right shifts</em></span>, and <span class="emphasis"><em>right rotates</em></span>. These operations turn out to be extremely useful.<a class="indexterm" id="IDX-CHP-2-0177"/><a class="indexterm" id="IDX-CHP-2-0178"/><a class="indexterm" id="IDX-CHP-2-0179"/><a class="indexterm" id="IDX-CHP-2-0180"/></p><p>The left-shift operation moves each bit in a bit string one position to the left (<a class="xref" href="ch02s10.html#shift-left_operation" title="Figure 2-8. Shift-left operation">Figure 2-8</a> provides an example of an 8-bit shift).</p><div class="figure"><a id="shift-left_operation"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8528"/><img alt="Shift-left operation" src="tagoreillycom20100401nostarchimages577899.png"/></div></div><p class="title">Figure 2-8. Shift-left operation</p></div><p>Bit 0 moves into bit position 1, the previous value in bit position 1 moves into bit position 2, and so on. There are, of course, two questions that naturally arise: "What goes into bit 0?" and "Where does the high-order bit go?" We'll shift a 0 into bit 0, and the previous value of the high-order bit will become the <span class="emphasis"><em>carry</em></span> out of this operation.</p><p>The 80x86 provides a shift-left instruction, <code class="literal">shl</code>, that performs this useful operation. The syntax for the <code class="literal">shl</code> instruction is:<a class="indexterm" id="IDX-CHP-2-0181"/></p><a id="I_programlisting2_d1e8551"/><pre class="programlisting">shl( <em class="replaceable"><code>count</code></em>, <em class="replaceable"><code>dest</code></em> );</pre><p>The <em class="replaceable"><code>count</code></em> operand is either CL or a constant in the range 0..<span class="emphasis"><em>n</em></span>, where <span class="emphasis"><em>n</em></span> is one less than the number of bits in the destination operand (for example, <span class="emphasis"><em>n</em></span> = 7 for 8-bit operands, <span class="emphasis"><em>n</em></span> = 15 for 16-bit operands, and <span class="emphasis"><em>n</em></span> = 31 for 32-bit operands). The <em class="replaceable"><code>dest</code></em> operand is a typical destination operand. It can be either a memory location or a register.<a class="indexterm" id="IDX-CHP-2-0182"/><a class="indexterm" id="IDX-CHP-2-0183"/></p><p>When the <em class="replaceable"><code>count</code></em> operand is the constant 1, the <code class="literal">shl</code> instruction does the operation shown in <a class="xref" href="ch02s10.html#shift-left_operation-id1" title="Figure 2-9. Shift-left operation">Figure 2-9</a>.</p><div class="figure"><a id="shift-left_operation-id1"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8604"/><img alt="Shift-left operation" src="tagoreillycom20100401nostarchimages577901.png"/></div></div><p class="title">Figure 2-9. Shift-left operation</p></div><p>In <a class="xref" href="ch02s10.html#shift-left_operation-id1" title="Figure 2-9. Shift-left operation">Figure 2-9</a>, the <span class="emphasis"><em>C</em></span> represents the carry flag. That is, the H.O. bit shifted out of the operand moves into the carry flag. Therefore, you can test for overflow after a <code class="literal">shl( 1</code>, <em class="replaceable"><code>dest</code></em> <code class="literal">);</code> instruction by testing the carry flag immediately after executing the instruction (e.g., by using <code class="literal">if( @c ) then...</code> or <code class="literal">if( @nc ) then...</code>).</p><p>Intel's literature suggests that the state of the carry flag is undefined if the shift count is a value other than 1. Usually, the carry flag contains the last bit shifted out of the destination operand, but Intel doesn't seem to guarantee this.</p><p>Note that shifting a value to the left is the same thing as multiplying it by its radix. For example, shifting a decimal number one position to the left (adding a 0 to the right of the number) effectively multiplies it by 10 (the radix):</p><a id="I_programlisting2_d1e8637"/><pre class="programlisting">1234 shl 1 = 12340</pre><p>(<code class="literal">shl 1</code> means shift one digit position to the left.)</p><p>Because the radix of a binary number is 2, shifting it left multiplies it by 2. If you shift a binary value to the left twice, you multiply it by 2 twice (that is, you multiply it by 4). If you shift a binary value to the left three times, you multiply it by 8 (2*2*2). In general, if you shift a value to the left <span class="emphasis"><em>n</em></span> times, you multiply that value by 2<sup><span class="emphasis"><em>n</em></span></sup>.</p><p>A right-shift operation works the same way, except we're moving the data in the opposite direction. For a byte value, bit 7 moves into bit 6, bit 6 moves into bit 5, bit 5 moves into bit 4, and so on. During a right shift, we'll move a 0 into bit 7, and bit 0 will be the carry out of the operation (see <a class="xref" href="ch02s10.html#shift-right_operation" title="Figure 2-10. Shift-right operation">Figure 2-10</a>).</p><div class="figure"><a id="shift-right_operation"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8660"/><img alt="Shift-right operation" src="tagoreillycom20100401nostarchimages577903.png"/></div></div><p class="title">Figure 2-10. Shift-right operation</p></div><p>As you would probably expect, the 80x86 provides a <code class="literal">shr</code> instruction that will shift the bits to the right in a destination operand. The syntax is the same as the <code class="literal">shl</code> instruction except, of course, you specify <code class="literal">shr</code> rather than <code class="literal">shl</code>:<a class="indexterm" id="IDX-CHP-2-0184"/></p><a id="I_programlisting2_d1e8684"/><pre class="programlisting">shr( <em class="replaceable"><code>count</code></em>, <em class="replaceable"><code>dest</code></em> );</pre><p>This instruction shifts a 0 into the H.O. bit of the destination operand, it shifts the other bits one place to the right (that is, from a higher bit number to a lower bit number). Finally, bit 0 is shifted into the carry flag. If you specify a count of 1, the <code class="literal">shr</code> instruction does the operation shown in <a class="xref" href="ch02s10.html#shift-right_operation-id1" title="Figure 2-11. Shift-right operation">Figure 2-11</a>.</p><div class="figure"><a id="shift-right_operation-id1"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8702"/><img alt="Shift-right operation" src="tagoreillycom20100401nostarchimages577905.png"/></div></div><p class="title">Figure 2-11. Shift-right operation</p></div><p>Once again, Intel's documents suggest that shifts of more than 1 bit leave the carry in an undefined state.</p><p>Because a left shift is equivalent to a multiplication by 2, it should come as no surprise that a right shift is roughly comparable to a division by 2 (or, in general, a division by the radix of the number). If you perform <span class="emphasis"><em>n</em></span> right shifts, you will divide that number by 2<sup><span class="emphasis"><em>n</em></span></sup>.</p><p>There is one problem with shift rights with respect to division: A shift right is only equivalent to an <span class="emphasis"><em>unsigned</em></span> division by 2. For example, if you shift the unsigned representation of 254 ($FE) one place to the right, you get 127 ($7F), exactly what you would expect. However, if you shift the binary representation of −2 ($FE) to the right one position, you get 127 ($7F), which is <span class="emphasis"><em>not</em></span> correct. This problem occurs because we're shifting a 0 into bit 7. If bit 7 previously contained a 1, we're changing it from a negative to a positive number. Not a good thing to do when dividing by 2.<a class="indexterm" id="IDX-CHP-2-0185"/><a class="indexterm" id="IDX-CHP-2-0186"/></p><p>To use the shift right as a division operator, we must define a third shift operation: arithmetic shift right.<sup>[<a class="footnote" href="#ftn.CHP-2-FN-5" id="CHP-2-FN-5">25</a>]</sup> An arithmetic shift right works just like the normal shift-right operation (a logical shift right) with one exception: Instead of shifting a 0 into the high-order bit, an arithmetic shift-right operation copies the high-order bit back into itself; that is, during the shift operation it does not modify the high-order bit, as <a class="xref" href="ch02s10.html#arithmetic_shift-right_operation" title="Figure 2-12. Arithmetic shift-right operation">Figure 2-12</a> shows.<a class="indexterm" id="IDX-CHP-2-0187"/></p><div class="figure"><a id="arithmetic_shift-right_operation"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8753"/><img alt="Arithmetic shift-right operation" src="tagoreillycom20100401nostarchimages577907.png"/></div></div><p class="title">Figure 2-12. Arithmetic shift-right operation</p></div><p>An arithmetic shift right generally produces the result you expect. For example, if you perform the arithmetic shift-right operation on −2 ($FE), you get −1 ($FF). Keep one thing in mind about arithmetic shift right, however. This operation always rounds the numbers to the closest integer that is <span class="emphasis"><em>less than or equal to the actual result</em></span>. Based on experiences with high-level programming languages and the standard rules of integer truncation, most people assume this means that a division always truncates toward 0. But this simply isn't the case. For example, if you apply the arithmetic shift-right operation on −1 ($FF), the result is −1, not 0. Because −1 is less than 0, the arithmetic shift-right operation rounds toward −1. This is not a bug in the arithmetic shift-right operation; it just uses a different (though valid) definition of integer division.<a class="indexterm" id="IDX-CHP-2-0188"/><a class="indexterm" id="IDX-CHP-2-0189"/><a class="indexterm" id="IDX-CHP-2-0190"/><a class="indexterm" id="IDX-CHP-2-0191"/></p><p>The 80x86 provides an arithmetic shift-right instruction, <code class="literal">sar</code> (shift arithmetic right). This instruction's syntax is nearly identical to <code class="literal">shl</code> and <code class="literal">shr</code>. The syntax is:<a class="indexterm" id="IDX-CHP-2-0192"/><a class="indexterm" id="IDX-CHP-2-0193"/><a class="indexterm" id="IDX-CHP-2-0194"/><a class="indexterm" id="IDX-CHP-2-0195"/></p><a id="I_programlisting2_d1e8806"/><pre class="programlisting">sar( <em class="replaceable"><code>count</code></em>, <em class="replaceable"><code>dest</code></em> );</pre><p>The usual limitations on the count and destination operands apply. This instruction operates as shown in <a class="xref" href="ch02s10.html#sar_open_parenthesis_1_comma_dest_close" title="Figure 2-13. sar( 1, dest ) operation">Figure 2-13</a> if the count is 1.</p><div class="figure"><a id="sar_open_parenthesis_1_comma_dest_close"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8823"/><img alt="sar( 1, dest ) operation" src="tagoreillycom20100401nostarchimages577909.png"/></div></div><p class="title">Figure 2-13. <code class="literal">sar( 1, dest )</code> operation</p></div><p>Once again, Intel's documents suggest that shifts of more than 1 bit leave the carry in an undefined state.</p><p>Another pair of useful operations are <span class="emphasis"><em>rotate left</em></span> and <span class="emphasis"><em>rotate right</em></span>. These operations behave like the shift-left and shift-right operations with one major difference: The bit shifted out from one end is shifted back in at the other end. <a class="xref" href="ch02s10.html#rotate-left_and_rotate-right_operations" title="Figure 2-14. Rotate-left and rotate-right operations">Figure 2-14</a> diagrams these operations.<a class="indexterm" id="IDX-CHP-2-0196"/><a class="indexterm" id="IDX-CHP-2-0197"/></p><div class="figure"><a id="rotate-left_and_rotate-right_operations"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8852"/><img alt="Rotate-left and rotate-right operations" src="tagoreillycom20100401nostarchimages577911.png"/></div></div><p class="title">Figure 2-14. Rotate-left and rotate-right operations</p></div><p>The 80x86 provides <code class="literal">rol</code> (rotate left) and <code class="literal">ror</code> (rotate right) instructions that do these basic operations on their operands. The syntax for these two instructions is similar to the shift instructions:<a class="indexterm" id="IDX-CHP-2-0198"/><a class="indexterm" id="IDX-CHP-2-0199"/></p><a id="I_programlisting2_d1e8875"/><pre class="programlisting">rol( <em class="replaceable"><code>count</code></em>, <em class="replaceable"><code>dest</code></em> );
ror( <em class="replaceable"><code>count</code></em>, <em class="replaceable"><code>dest</code></em> );</pre><p>Once again, these instructions provide a special behavior if the shift count is 1. Under this condition these two instructions also copy the bit shifted out of the destination operand into the carry flag as <a class="xref" href="ch02s10.html#rol_open_parenthesis_1_comma_dest_close" title="Figure 2-15. rol( 1, dest ) operation">Figure 2-15</a> and <a class="xref" href="ch02s10.html#ror_open_parenthesis_1_comma_dest_close" title="Figure 2-16. ror( 1, dest ) operation">Figure 2-16</a> show.<a class="indexterm" id="IDX-CHP-2-0200"/><a class="indexterm" id="IDX-CHP-2-0201"/><a class="indexterm" id="IDX-CHP-2-0202"/></p><div class="figure"><a id="rol_open_parenthesis_1_comma_dest_close"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8911"/><img alt="rol( 1, dest ) operation" src="tagoreillycom20100401nostarchimages577913.png"/></div></div><p class="title">Figure 2-15. <code class="literal">rol( 1, dest )</code> operation</p></div><p>Note that Intel's documents suggest that rotates of more than 1 bit leave the carry in an undefined state.</p><div class="figure"><a id="ror_open_parenthesis_1_comma_dest_close"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8923"/><img alt="ror( 1, dest ) operation" src="tagoreillycom20100401nostarchimages577915.png"/></div></div><p class="title">Figure 2-16. <code class="literal">ror( 1, dest )</code> operation</p></div><p>It is often more convenient for the rotate operation to shift the output bit through the carry and shift the previous carry value back into the input bit of the shift operation. The 80x86 <code class="literal">rcl</code> (rotate through carry left) and <code class="literal">rcr</code> (rotate through carry right) instructions achieve this for you. These instructions use the following syntax:<a class="indexterm" id="IDX-CHP-2-0203"/><a class="indexterm" id="IDX-CHP-2-0204"/></p><a id="I_programlisting2_d1e8946"/><pre class="programlisting">rcl( <em class="replaceable"><code>count</code></em>, <em class="replaceable"><code>dest</code></em> );
rcr( <em class="replaceable"><code>count</code></em>, <em class="replaceable"><code>dest</code></em> );</pre><p>As is true for the other shift and rotate instructions, the <em class="replaceable"><code>count</code></em> operand is either a constant or the CL register, and the <em class="replaceable"><code>dest</code></em> operand is a memory location or register. The <em class="replaceable"><code>count</code></em> operand must be a value that is less than the number of bits in the <em class="replaceable"><code>dest</code></em> operand. For a count value of 1, these two instructions do the rotation shown in <a class="xref" href="ch02s10.html#rcl_open_parenthesis_1_comma_dest_close" title="Figure 2-17. rcl( 1, dest ) and rcr( 1, dest ) operations">Figure 2-17</a>.</p><div class="figure"><a id="rcl_open_parenthesis_1_comma_dest_close"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e8985"/><img alt="rcl( 1, dest ) and rcr( 1, dest ) operations" src="tagoreillycom20100401nostarchimages577917.png"/></div></div><p class="title">Figure 2-17. <code class="literal">rcl( 1, dest )</code> and <code class="literal">rcr( 1, dest )</code> operations</p></div><p>Again, Intel's documents suggest that rotates of more than 1 bit leave the carry in an undefined state.</p><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-5" id="ftn.CHP-2-FN-5">25</a>] </sup>There is no need for an arithmetic shift left. The standard shift-left operation works for both signed and unsigned numbers, assuming no overflow occurs.</p></div></div></div>
<div class="sect1" title="2.11 Bit Fields and Packed Data"><div class="titlepage"><div><div><h1 class="title"><a id="bit_fields_and_packed_data"/>2.11 Bit Fields and Packed Data</h1></div></div></div><p>Although the 80x86 operates most efficiently on <code class="literal">byte</code>, <code class="literal">word</code>, and <code class="literal">dword</code> data types, occasionally you'll need to work with a data type that uses some number of bits other than 8, 16, or 32. For example, consider a date of the form 04/02/01. It takes three numeric values to represent this date: month, day, and year values. Months, of course, take on the values 1..12. It will require at least 4 bits (maximum of 16 different values) to represent the month. Days range between 1 and 31. So it will take 5 bits (maximum of 32 different values) to represent the day entry. The year value, assuming that we're working with values in the range 0..99, requires 7 bits (that can be used to represent up to 128 different values). 4 + 5 + 7 = 16 bits, or 2 bytes. In other words, we can pack our date data into 2 bytes rather than the 3 that would be required if we used a separate byte for each of the month, day, and year values. This saves 1 byte of memory for each date stored, which could be a substantial saving if you need to store many dates. The bits could be arranged as shown in <a class="xref" href="ch02s11.html#short_packed_date_format_open_parenthesi" title="Figure 2-18. Short packed date format (2 bytes)">Figure 2-18</a>.<a class="indexterm" id="IDX-CHP-2-0205"/></p><div class="figure"><a id="short_packed_date_format_open_parenthesi"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e9016"/><img alt="Short packed date format (2 bytes)" src="tagoreillycom20100401nostarchimages577919.png.jpg"/></div></div><p class="title">Figure 2-18. Short packed date format (2 bytes)</p></div><p>MMMM represents the 4 bits making up the month value, DDDDD represents the 5 bits making up the day, and YYYYYYY is the 7 bits composing the year. Each collection of bits representing a data item is a <span class="emphasis"><em>bit field</em></span>. For example, April 2, 2001, would be represented as $4101:</p><a id="I_programlisting2_d1e9026"/><pre class="programlisting">0100      00010   0000001          = %0100_0001_0000_0001 or $4101
           4          2       01</pre><p>Although packed values are <span class="emphasis"><em>space efficient</em></span> (that is, very efficient in terms of memory usage), they are computationally <span class="emphasis"><em>inefficient</em></span> (slow!). The reason? It takes extra instructions to unpack the data packed into the various bit fields. These extra instructions take additional time to execute (and additional bytes to hold the instructions); hence, you must carefully consider whether packed data fields will save you anything. The sample program in <a class="xref" href="ch02s11.html#packing_and_unpacking_date_data" title="Example 2-9. Packing and unpacking date data">Example 2-9</a> demonstrates the effort that must go into packing and unpacking this 16-bit date format.<a class="indexterm" id="IDX-CHP-2-0206"/><a class="indexterm" id="IDX-CHP-2-0207"/></p><div class="example"><a id="packing_and_unpacking_date_data"/><p class="title">Example 2-9. Packing and unpacking date data</p><div class="example-contents"><pre class="programlisting">program dateDemo;

#include( "stdlib.hhf" )

static
    day:        uns8;
    month:      uns8;
    year:       uns8;

    packedDate: word;

begin dateDemo;

    stdout.put( "Enter the current month, day, and year: " );
    stdin.get( month, day, year );

    // Pack the data into the following bits:
    //
    //  15 14 13 12 11 10  9  8  7  6  5  4  3  2  1  0
    //   m  m  m  m  d  d  d  d  d  y  y  y  y  y  y  y

    mov( 0, ax );
    mov( ax, packedDate );  // Just in case there is an error.
    if( month &gt; 12 ) then

        stdout.put( "Month value is too large", nl );

    elseif( month = 0 ) then

        stdout.put( "Month value must be in the range 1..12", nl );

    elseif( day &gt; 31 ) then

        stdout.put( "Day value is too large", nl );

    elseif( day = 0 ) then

        stdout.put( "Day value must be in the range 1..31", nl );

    elseif( year &gt; 99 ) then

        stdout.put( "Year value must be in the range 0..99", nl );

    else

        mov( month, al );
        shl( 5, ax );
        or( day, al );
        shl( 7, ax );
        or( year, al );
        mov( ax, packedDate );

    endif;

    // Okay, display the packed value:

    stdout.put( "Packed data = $", packedDate, nl );



    // Unpack the date:

    mov( packedDate, ax );
    and( $7f, al );         // Retrieve the year value.
    mov( al, year );

    mov( packedDate, ax );  // Retrieve the day value.
    shr( 7, ax );
    and( %1_1111, al );
    mov( al, day );

    mov( packedDate, ax );  // Retrieve the month value.
    rol( 4, ax );
    and( %1111, al );
    mov( al, month );

    stdout.put( "The date is ", month, "/", day, "/", year, nl );



end dateDemo;</pre></div></div><p>Of course, having gone through the problems with Y2K (Year 2000), you know that using a date format that limits you to 100 years (or even 127 years) would be quite foolish at this time. If you are concerned about your software running 100 years from now, perhaps it would be wise to use a 3-byte date format rather than a 2-byte format. As you will see in the chapter on arrays, however, you should always try to create data objects whose length is an even power of 2 (1 byte, 2 bytes, 4 bytes, 8 bytes, and so on) or you will pay a performance penalty. Hence, it is probably wise to go ahead and use 4 bytes and pack this data into a double-word variable. <a class="xref" href="ch02s11.html#long_packed_date_format_open_parenthesis" title="Figure 2-19. Long packed date format (4 bytes)">Figure 2-19</a> shows one possible data organization for a 4-byte date.<a class="indexterm" id="IDX-CHP-2-0208"/></p><div class="figure"><a id="long_packed_date_format_open_parenthesis"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e9063"/><img alt="Long packed date format (4 bytes)" src="tagoreillycom20100401nostarchimages577921.png.jpg"/></div></div><p class="title">Figure 2-19. Long packed date format (4 bytes)</p></div><p>In this long packed date format we made several changes beyond simply extending the number of bits associated with the year. First, because there are extra bits in a 32-bit double-word variable, this format allocates extra bits to the month and day fields. Because these two fields now consist of 8 bits each, they can be easily extracted as a byte object from the double word. This leaves fewer bits for the year, but 65,536 years is probably sufficient; you can probably assume without too much concern that your software will not still be in use 63,000 years from now when this date format will no longer work.</p><p>Of course, you could argue that this is no longer a packed date format. After all, we needed three numeric values, two of which fit just nicely into 1 byte each and one that should probably have at least 2 bytes. Because this "packed" date format consumes the same 4 bytes as the unpacked version, what is so special about this format? Well, another difference you will note between this long packed date format and the short date format appearing in <a class="xref" href="ch02s11.html#short_packed_date_format_open_parenthesi" title="Figure 2-18. Short packed date format (2 bytes)">Figure 2-18</a> is the fact that this long date format rearranges the bits so the <code class="literal">Year</code> field is in the H.O. bit positions, the <code class="literal">Month</code> field is in the middle bit positions, and the <code class="literal">Day</code> field is in the L.O. bit positions. This is important because it allows you to very easily compare two dates to see if one date is less than, equal to, or greater than another date. Consider the following code:<a class="indexterm" id="IDX-CHP-2-0209"/><a class="indexterm" id="IDX-CHP-2-0210"/><a class="indexterm" id="IDX-CHP-2-0211"/><a class="indexterm" id="IDX-CHP-2-0212"/><a class="indexterm" id="IDX-CHP-2-0213"/><a class="indexterm" id="IDX-CHP-2-0214"/><a class="indexterm" id="IDX-CHP-2-0215"/><a class="indexterm" id="IDX-CHP-2-0216"/><a class="indexterm" id="IDX-CHP-2-0217"/><a class="indexterm" id="IDX-CHP-2-0218"/><a class="indexterm" id="IDX-CHP-2-0219"/><a class="indexterm" id="IDX-CHP-2-0220"/><a class="indexterm" id="IDX-CHP-2-0221"/><a class="indexterm" id="IDX-CHP-2-0222"/><a class="indexterm" id="IDX-CHP-2-0223"/><a class="indexterm" id="IDX-CHP-2-0224"/><a class="indexterm" id="IDX-CHP-2-0225"/><a class="indexterm" id="IDX-CHP-2-0226"/><a class="indexterm" id="IDX-CHP-2-0227"/></p><a id="I_programlisting2_d1e9159"/><pre class="programlisting">mov( <em class="replaceable"><code>Date1</code></em>, eax );          // Assume <em class="replaceable"><code>Date1</code></em> and <em class="replaceable"><code>Date2</code></em> are dword variables
     if( eax &gt; <em class="replaceable"><code>Date2</code></em> ) then      // using the Long Packed Date format.

          &lt;&lt; Do something if <em class="replaceable"><code>Date1</code></em> &gt; <em class="replaceable"><code>Date2</code></em> &gt;&gt;

     endif;</pre><p>Had you kept the different date fields in separate variables, or organized the fields differently, you would not have been able to compare <em class="replaceable"><code>Date1</code></em> and <em class="replaceable"><code>Date2</code></em> in such an easy fashion. Therefore, this example demonstrates another reason for packing data even if you don't realize any space savings—it can make certain computations more convenient or even more efficient (contrary to what normally happens when you pack data).</p><p>Examples of practical packed data types abound. You could pack eight boolean values into a single byte, you could pack two BCD digits into a byte, and so on. Of course, a classic example of packed data is the EFLAGS register (see <a class="xref" href="ch02s11.html#eflags_register_as_packed_boolean_data" title="Figure 2-20. EFLAGS register as packed boolean data">Figure 2-20</a>). This register packs nine important boolean objects (along with seven important system flags) into a single 16-bit register. You will commonly need to access many of these flags. For this reason, the 80x86 instruction set provides many ways to manipulate the individual bits in the EFLAGS register. Of course, you can test many of the condition code flags using the HLA pseudo-boolean variables such as <code class="literal">@c</code>, <code class="literal">@nc</code>, <code class="literal">@z</code>, and <code class="literal">@nz</code> in an <code class="literal">if</code> statement or other statement using a boolean expression.</p><p>In addition to the condition codes, the 80x86 provides instructions that directly affect certain flags (<a class="xref" href="ch02s11.html#instructions_that_affect_certain_flags" title="Table 2-7. Instructions That Affect Certain Flags">Table 2-7</a>).</p><div class="table"><a id="instructions_that_affect_certain_flags"/><p class="title">Table 2-7. Instructions That Affect Certain Flags</p><div class="table-contents"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; " summary="Instructions That Affect Certain Flags"><colgroup><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p>Instruction</p></th><th style="text-align: left" valign="bottom"><p>Explanation</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p><code class="literal">cld();</code></p></td><td style="text-align: left" valign="top"><p>Clears (sets to 0) the direction flag.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">std();</code><a class="indexterm" id="IDX-CHP-2-0228"/></p></td><td style="text-align: left" valign="top"><p>Sets (to 1) the direction flag.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">cli();</code></p></td><td style="text-align: left" valign="top"><p>Clears the interrupt disable flag.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">sti();</code><a class="indexterm" id="IDX-CHP-2-0229"/></p></td><td style="text-align: left" valign="top"><p>Sets the interrupt disable flag.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">clc();</code></p></td><td style="text-align: left" valign="top"><p>Clears the carry flag.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">stc();</code></p></td><td style="text-align: left" valign="top"><p>Sets the carry flag.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">cmc();</code></p></td><td style="text-align: left" valign="top"><p>Complements (inverts) the carry flag.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">sahf();</code><a class="indexterm" id="IDX-CHP-2-0230"/></p></td><td style="text-align: left" valign="top"><p>Stores the AH register into the L.O. 8 bits of the EFLAGS register.</p></td></tr><tr><td style="text-align: left" valign="top"><p><code class="literal">lahf();</code></p></td><td style="text-align: left" valign="top"><p>Loads AH from the L.O. 8 bits of the EFLAGS register.</p></td></tr></tbody></table></div></div><p>There are other instructions that affect the EFLAGS register as well; these instructions, however, demonstrate how to access several of the packed boolean values in the EFLAGS register. The <code class="literal">lahf</code> and <code class="literal">sahf</code> instructions, in particular, provide a convenient way to access the L.O. 8 bits of the EFLAGS register as an 8-bit byte (rather than as eight separate 1-bit values). See <a class="xref" href="ch02s11.html#eflags_register_as_packed_boolean_data" title="Figure 2-20. EFLAGS register as packed boolean data">Figure 2-20</a> for a layout of the EFLAGS register.<a class="indexterm" id="IDX-CHP-2-0231"/><a class="indexterm" id="IDX-CHP-2-0232"/><a class="indexterm" id="IDX-CHP-2-0233"/><a class="indexterm" id="IDX-CHP-2-0234"/><a class="indexterm" id="IDX-CHP-2-0235"/><a class="indexterm" id="IDX-CHP-2-0236"/><a class="indexterm" id="IDX-CHP-2-0237"/></p><div class="figure"><a id="eflags_register_as_packed_boolean_data"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e9355"/><img alt="EFLAGS register as packed boolean data" src="tagoreillycom20100401nostarchimages577923.png"/></div></div><p class="title">Figure 2-20. EFLAGS register as packed boolean data</p></div><p>The <code class="literal">lahf</code> (load AH with the L.O. 8 bits of the EFLAGS register) and the <code class="literal">sahf</code> (store AH into the L.O. byte of the EFLAGS register) use the following syntax:</p><a id="I_programlisting2_d1e9368"/><pre class="programlisting">lahf();
          sahf();</pre></div>
<div class="sect1" title="2.12 An Introduction to Floating-Point Arithmetic"><div class="titlepage"><div><div><h1 class="title"><a id="an_introduction_to_floating-point_arithm"/>2.12 An Introduction to Floating-Point Arithmetic</h1></div></div></div><p>Integer arithmetic does not let you represent fractional numeric values. Therefore, modern CPUs support an approximation of <span class="emphasis"><em>real</em></span> arithmetic: floating-point arithmetic. A big problem with floating-point arithmetic is that it does not follow the standard rules of algebra. Nevertheless, many programmers apply normal algebraic rules when using floating-point arithmetic. This is a source of defects in many programs. One of the primary goals of this section is to describe the limitations of floating-point arithmetic so you will understand how to use it properly.</p><p>Normal algebraic rules apply only to <span class="emphasis"><em>infinite precision</em></span> arithmetic. Consider the simple statement <span class="emphasis"><em>x</em></span> := <span class="emphasis"><em>x</em></span> + 1, where <span class="emphasis"><em>x</em></span> is an integer. On any modern computer this statement follows the normal rules of algebra <span class="emphasis"><em>as long as overflow does not occur</em></span>. That is, this statement is valid only for certain values of <span class="emphasis"><em>x</em></span> (<span class="emphasis"><em>minint</em></span> &lt;= <span class="emphasis"><em>x</em></span> &lt; <span class="emphasis"><em>maxint</em></span>). Most programmers do not have a problem with this because they are well aware of the fact that integers in a program do not follow the standard algebraic rules (e.g., 5/2 does not equal 2.5).</p><p>Integers do not follow the standard rules of algebra because the computer represents them with a finite number of bits. You cannot represent any of the (integer) values above the maximum integer or below the minimum integer. Floating-point values suffer from this same problem, only worse. After all, the integers are a subset of the real numbers. Therefore, the floating-point values must represent the same infinite set of integers. However, there are an infinite number of real values between any two integer values, so this problem is infinitely worse. Therefore, as well as having to limit your values between a maximum and minimum range, you cannot represent all the values between those two ranges either.<a class="indexterm" id="IDX-CHP-2-0238"/><a class="indexterm" id="IDX-CHP-2-0239"/><a class="indexterm" id="IDX-CHP-2-0240"/></p><p>To represent real numbers, most floating-point formats employ scientific notation and use some number of bits to represent a <span class="emphasis"><em>mantissa</em></span> and a smaller number of bits to represent an <span class="emphasis"><em>exponent</em></span>. The end result is that floating-point numbers can only represent numbers with a specific number of <span class="emphasis"><em>significant</em></span> digits. This has a big impact on how floating-point arithmetic operates. To easily see the impact of limited precision arithmetic, we will adopt a simplified decimal floating-point format for our examples. Our floating-point format will provide a mantissa with three significant digits and a decimal exponent with two digits. The mantissa and exponents are both signed values, as shown in <a class="xref" href="ch02s12.html#a_floating-point_format" title="Figure 2-21. A floating-point format">Figure 2-21</a>.<a class="indexterm" id="IDX-CHP-2-0241"/><a class="indexterm" id="IDX-CHP-2-0242"/><a class="indexterm" id="IDX-CHP-2-0243"/></p><div class="figure"><a id="a_floating-point_format"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e9445"/><img alt="A floating-point format" src="tagoreillycom20100401nostarchimages577925.png"/></div></div><p class="title">Figure 2-21. A floating-point format</p></div><p>When adding and subtracting two numbers in scientific notation, we must adjust the two values so that their exponents are the same. For example, when adding 1.23e1 and 4.56e0, we must adjust the values so they have the same exponent. One way to do this is to convert 4.56e0 to 0.456e1 and then add. This produces 1.686e1. Unfortunately, the result does not fit into three significant digits, so we must either <span class="emphasis"><em>round</em></span> or <span class="emphasis"><em>truncate</em></span> the result to three significant digits. Rounding generally produces the most accurate result, so let's round the result to obtain 1.69e1. As you can see, the lack of <span class="emphasis"><em>precision</em></span> (the number of digits or bits we maintain in a computation) affects the accuracy (the correctness of the computation).</p><p>In the previous example, we were able to round the result because we maintained <span class="emphasis"><em>four</em></span> significant digits <span class="emphasis"><em>during</em></span> the calculation. If our floating-point calculation had been limited to three significant digits <span class="emphasis"><em>during</em></span> computation, we would have had to truncate the last digit of the smaller number, obtaining 1.68e1, a value that is even less accurate. To improve the accuracy of floating-point calculations, it is necessary to add extra digits for use during the calculation. Extra digits available during a computation are known as <span class="emphasis"><em>guard digits</em></span> (or <span class="emphasis"><em>guard bits</em></span> in the case of a binary format). They greatly enhance accuracy during a long chain of computations.</p><p>The accuracy loss during a single computation usually isn't enough to worry about unless you are greatly concerned about the accuracy of your computations. However, if you compute a value that is the result of a sequence of floating-point operations, the error can <span class="emphasis"><em>accumulate</em></span> and greatly affect the computation itself. For example, suppose we were to add 1.23e3 to 1.00e0. Adjusting the numbers so their exponents are the same before the addition produces 1.23e3 + 0.001e3. The sum of these two values, even after rounding, is 1.23e3. This might seem perfectly reasonable to you; after all, we can maintain only three significant digits, so adding in a small value shouldn't affect the result at all. However, suppose we were to add 1.00e0 to 1.23e3 <span class="emphasis"><em>ten times</em></span>. The first time we add 1.00e0 to 1.23e3 we get 1.23e3. Likewise, we get this same result the second, third, fourth . . . and tenth times we add 1.00e0 to 1.23e3. On the other hand, had we added 1.00e0 to itself 10 times, then added the result (1.00e1) to 1.23e3, we would have gotten a different result, 1.24e3. This is an important thing to know about limited-precision arithmetic:</p><div class="variablelist"><dl><dt><span class="term"><span class="strong"><strong>The order of evaluation can affect the accuracy of the result</strong></span>.</span></dt><dd><p>You will get more accurate results if the relative magnitudes (that is, the exponents) are close to one another when adding and subtracting floating-point values. If you are performing a chain calculation involving addition and subtraction, you should attempt to group the values appropriately.</p><table border="0" class="simplelist" summary="Simple list"><tr><td>Another problem with addition and subtraction is that you can wind up with <span class="emphasis"><em>false precision</em></span>. Consider the computation 1.23e0 − 1.22e0. This produces 0.01e0. Although this is mathematically equivalent to 1.00e − 2, this latter form suggests that the last two digits are exactly 0. Unfortunately, we have only a single significant digit at this time. Indeed, some floating-point unit (FPU) software packages might actually insert random digits (or bits) into the L.O. positions. This brings up a second important rule concerning limited precision arithmetic:</td></tr></table></dd><dt><span class="term"><span class="strong"><strong>When subtracting two numbers with the same signs or adding two numbers with different signs, the accuracy of the result may be less than the precision available in the floating-point format</strong></span>.</span></dt><dd><p>Multiplication and division do not suffer from the same problems as addition and subtraction because you do not have to adjust the exponents before the operation; all you need to do is add the exponents and multiply the mantissas (or subtract the exponents and divide the mantissas). By themselves, multiplication and division do not produce particularly poor results. However, they tend to multiply any error that already exists in a value. For example, if you multiply 1.23e0 by 2, when you should be multiplying 1.24e0 by 2, the result is even less accurate. This brings up a third important rule when working with limited-precision arithmetic:</p></dd><dt><span class="term"><span class="strong"><strong>When performing a chain of calculations involving addition, subtraction, multiplication, and division, try to perform the multiplication and division operations first</strong></span>.</span></dt><dd><p>Often, by applying normal algebraic transformations, you can arrange a calculation so the multiply and divide operations occur first. For example, suppose you want to compute <span class="emphasis"><em>x</em></span> * ( <span class="emphasis"><em>y</em></span> + <span class="emphasis"><em>z</em></span> ). Normally you would add <span class="emphasis"><em>y</em></span> and <span class="emphasis"><em>z</em></span> together and multiply their sum by <span class="emphasis"><em>x</em></span>. However, you will get a little more accuracy if you transform <span class="emphasis"><em>x</em></span> * ( <span class="emphasis"><em>y</em></span> + <span class="emphasis"><em>z</em></span> ) to get <span class="emphasis"><em>x</em></span> * <span class="emphasis"><em>y</em></span> + <span class="emphasis"><em>x</em></span> * <span class="emphasis"><em>z</em></span> and compute the result by performing the multiplications first.<sup>[<a class="footnote" href="#ftn.CHP-2-FN-6" id="CHP-2-FN-6">26</a>]</sup></p><table border="0" class="simplelist" summary="Simple list"><tr><td>Multiplication and division are not without their own problems. When multiplying two very large or very small numbers, it is quite possible for <span class="emphasis"><em>overflow</em></span> or <span class="emphasis"><em>underflow</em></span> to occur. The same situation occurs when dividing a small number by a large number or dividing a large number by a small number. This brings up a fourth rule you should attempt to follow when multiplying or dividing values:</td></tr></table></dd><dt><span class="term"><span class="strong"><strong>When multiplying and dividing sets of numbers, try to arrange the multiplications so that they multiply large and small numbers together; likewise, try to divide numbers that have the same relative magnitudes</strong></span>.</span></dt><dd><p>Comparing floating-point numbers is very dangerous. Given the inaccuracies present in any computation (including converting an input string to a floating-point value), you should <span class="emphasis"><em>never</em></span> compare two floating-point values to see if they are equal. In a binary floating-point format, different computations that produce the same (mathematical) result may differ in their least significant bits. For example, 1.31e0 + 1.69e0 should produce 3.00e0. Likewise, 1.50e0 + 1.50e0 should produce 3.00e0. However, if you were to compare (1.31e0 + 1.69e0) against (1.50e0 + 1.50e0), you might find out that these sums are <span class="emphasis"><em>not</em></span> equal to one another. The test for equality succeeds if and only if all bits (or digits) in the two operands are exactly the same. Because this is not necessarily true after two different floating-point computations that should produce the same result, a straight test for equality may not work.<a class="indexterm" id="IDX-CHP-2-0244"/><a class="indexterm" id="IDX-CHP-2-0245"/><a class="indexterm" id="IDX-CHP-2-0246"/></p><table border="0" class="simplelist" summary="Simple list"><tr><td>The standard way to test for equality between floating-point numbers is to determine how much error (or tolerance) you will allow in a comparison and check to see if one value is within this error range of the other. The usual way to do this is to use a test like the following:</td></tr></table><a id="I_programlisting2_d1e9602"/><pre class="programlisting">if <em class="replaceable"><code>Value1</code></em> &gt;= (<em class="replaceable"><code>Value2</code></em>-<em class="replaceable"><code>error</code></em>) and <em class="replaceable"><code>Value1</code></em> &lt;= (<em class="replaceable"><code>Value2</code></em>+<em class="replaceable"><code>error</code></em>) then ...</pre><table border="0" class="simplelist" summary="Simple list"><tr><td>Another common way to handle this same comparison is to use a statement of the form</td></tr></table><a id="I_programlisting2_d1e9626"/><pre class="programlisting">if abs(<em class="replaceable"><code>Value1</code></em>-<em class="replaceable"><code>Value2</code></em>) &lt;= <em class="replaceable"><code>error</code></em> then ...</pre><table border="0" class="simplelist" summary="Simple list"><tr><td>You must exercise care when choosing the value for <em class="replaceable"><code>error</code></em>. This should be a value slightly greater than the largest amount of error that will creep into your computations. The exact value will depend upon the particular floating-point format you use, but more on that a little later. Here is the final rule we will state in this section:</td></tr></table></dd><dt><span class="term"><span class="strong"><strong>When comparing two floating-point numbers, always compare one value to see if it is in the range given by the second value plus or minus some small error value</strong></span>.</span></dt><dd><p>There are many other little problems that can occur when using floating-point values. This text can only point out some of the major problems and make you aware of the fact that you cannot treat floating-point arithmetic like real arithmetic—the inaccuracies present in limited-precision arithmetic can get you into trouble if you are not careful. A good text on numerical analysis or even scientific computing can help fill in the details that are beyond the scope of this text. If you are going to be working with floating-point arithmetic, <span class="emphasis"><em>in any language</em></span>, you should take the time to study the effects of limited-precision arithmetic on your computations.<a class="indexterm" id="IDX-CHP-2-0247"/><a class="indexterm" id="IDX-CHP-2-0248"/><a class="indexterm" id="IDX-CHP-2-0249"/><a class="indexterm" id="IDX-CHP-2-0250"/></p><table border="0" class="simplelist" summary="Simple list"><tr><td>HLA's <code class="literal">if</code> statement does not support boolean expressions involving floating-point operands. Therefore, you cannot use statements like <code class="literal">if( x &lt; 3.141) then...</code> in your programs. <a class="xref" href="ch06.html" title="Chapter 6. ARITHMETIC">Chapter 6</a> will teach you how to do floating-point comparisons.</td></tr></table></dd></dl></div><div class="sect2" title="2.12.1 IEEE Floating-Point Formats"><div class="titlepage"><div><div><h2 class="title"><a id="ieee_floating-point_formats"/>2.12.1 IEEE Floating-Point Formats</h2></div></div></div><p>When Intel planned to introduce a floating-point unit for its new 8086 microprocessor, it was smart enough to realize that the electrical engineers and solid-state physicists who design chips were probably not the best people to pick the best possible binary representation for a floating-point format. So Intel went out and hired the best numerical analyst it could find to design a floating-point format for its 8087 FPU. That person then hired two other experts in the field, and the three of them (Kahn, Coonan, and Stone) designed Intel's floating-point format. They did such a good job designing the KCS Floating-Point Standard that the IEEE organization adopted this format for the IEEE floating-point format.<sup>[<a class="footnote" href="#ftn.CHP-2-FN-7" id="CHP-2-FN-7">27</a>]</sup><a class="indexterm" id="IDX-CHP-2-0251"/><a class="indexterm" id="IDX-CHP-2-0252"/></p><p>To handle a wide range of performance and accuracy requirements, Intel actually introduced <span class="emphasis"><em>three</em></span> floating-point formats: single-precision, double-precision, and extended-precision. The single- and double-precision formats corresponded to C's float and double types or FORTRAN's real and double-precision types. Intel intended to use extended-precision for long chains of computations. Extended-precision contains 16 extra bits that the calculations could use as guard bits before rounding down to a double-precision value when storing the result.</p><p>The single-precision format uses a <span class="emphasis"><em>one's complement 24-bit mantissa</em></span> and an <span class="emphasis"><em>8-bit excess-127 exponent</em></span>. The mantissa usually represents a value from 1.0 to just under 2.0. The H.O. bit of the mantissa is always assumed to be 1 and represents a value just to the left of the <span class="emphasis"><em>binary point</em></span>.<sup>[<a class="footnote" href="#ftn.CHP-2-FN-8" id="CHP-2-FN-8">28</a>]</sup> The remaining 23 mantissa bits appear to the right of the binary point. Therefore, the mantissa represents the value<a class="indexterm" id="IDX-CHP-2-0253"/><a class="indexterm" id="IDX-CHP-2-0254"/></p><a id="I_programlisting2_d1e9721"/><pre class="programlisting">1.mmmmmmm mmmmmmmm mmmmmmmm</pre><p>The <code class="literal">mmmm</code> characters represent the 23 bits of the mantissa. Keep in mind that we are working with binary numbers here. Therefore, each position to the right of the binary point represents a value (0 or 1) times a successive negative power of 2. The implied 1 bit is always multiplied by 2<sup>0</sup>, which is 1. This is why the mantissa is always greater than or equal to 1. Even if the other mantissa bits are all 0, the implied 1 bit always gives us the value 1<sup>[<a class="footnote" href="#ftn.CHP-2-FN-9" id="CHP-2-FN-9">29</a>]</sup>. Of course, even if we had an almost infinite number of 1 bits after the binary point, they still would not add up to 2. This is why the mantissa can represent values in the range 1 to just under 2.<a class="indexterm" id="IDX-CHP-2-0255"/><a class="indexterm" id="IDX-CHP-2-0256"/></p><p>Although there are an infinite number of values between 1 and 2, we can only represent 8 million of them because we use a 23-bit mantissa (the 24th bit is always 1). This is the reason for inaccuracy in floating-point arithmetic—we are limited to 23 bits of precision in computations involving single-precision floating-point values.</p><p>The mantissa uses a one's complement format rather than two's complement. This means that the 24-bit value of the mantissa is simply an unsigned binary number, and the sign bit determines whether that value is positive or negative. One's complement numbers have the unusual property that there are two representations for 0 (with the sign bit set or clear). Generally, this is important only to the person designing the floating-point software or hardware system. We will assume that the value 0 always has the sign bit clear.</p><p>To represent values outside the range 1.0 to just under 2.0, the exponent portion of the floating-point format comes into play. The floating-point format raises 2 to the power specified by the exponent and then multiplies the mantissa by this value. The exponent is 8 bits and is stored in an <span class="emphasis"><em>excess-127</em></span> format. In excess-127 format, the exponent 2<sup>0</sup> is represented by the value 127 ($7F ). Therefore, to convert an exponent to excess-127 format, simply add 127 to the exponent value. The use of excess-127 format makes it easier to compare floating-point values. The single-precision floating-point format takes the form shown in <a class="xref" href="ch02s12.html#single-precision_open_parenthesis_32-bit" title="Figure 2-22. Single-precision (32-bit) floating-point format">Figure 2-22</a>.</p><div class="figure"><a id="single-precision_open_parenthesis_32-bit"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e9761"/><img alt="Single-precision (32-bit) floating-point format" src="tagoreillycom20100401nostarchimages577927.png.jpg"/></div></div><p class="title">Figure 2-22. Single-precision (32-bit) floating-point format</p></div><p>With a 24-bit mantissa, you will get approximately 6 ½ digits of precision (½ digit of precision means that the first six digits can all be in the range 0..9, but the seventh digit can only be in the range 0..<span class="emphasis"><em>x</em></span>, where <span class="emphasis"><em>x</em></span> &lt; 9 and is generally close to 5). With an 8-bit excess-127 exponent, the dynamic range of single-precision floating-point numbers is approximately 2 ± 128 or about 10 ± 38.</p><p>Although single-precision floating-point numbers are perfectly suitable for many applications, the dynamic range is somewhat limited and is unsuitable for many financial, scientific, and other applications. Furthermore, during long chains of computations, the limited accuracy of the single-precision format may introduce serious error.</p><p>The double-precision format helps overcome the problems of single-precision floating-point. Using twice the space, the double-precision format has an 11-bit excess-1023 exponent and a 53-bit mantissa (with an implied H.O. bit of 1) plus a sign bit. This provides a dynamic range of about 10<sup>±308</sup> and 14 ½ digits of precision, sufficient for most applications. Double-precision floating-point values take the form shown in <a class="xref" href="ch02s12.html#bit_double-precision_floating-point_for" title="Figure 2-23. 64-bit double-precision floating-point format">Figure 2-23</a>.<a class="indexterm" id="IDX-CHP-2-0257"/><a class="indexterm" id="IDX-CHP-2-0258"/><a class="indexterm" id="IDX-CHP-2-0259"/></p><div class="figure"><a id="bit_double-precision_floating-point_for"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e9798"/><img alt="64-bit double-precision floating-point format" src="tagoreillycom20100401nostarchimages577929.png.jpg"/></div></div><p class="title">Figure 2-23. 64-bit double-precision floating-point format</p></div><p>In order to help ensure accuracy during long chains of computations involving double-precision floating-point numbers, Intel designed the extended-precision format. The extended-precision format uses 80 bits. Twelve of the additional 16 bits are appended to the mantissa and four of the additional bits are appended to the end of the exponent. Unlike the single- and double-precision values, the extended-precision format's mantissa does not have an implied H.O. bit, which is always 1. Therefore, the extended-precision format provides a 64-bit mantissa, a 15-bit excess-16383 exponent, and a 1-bit sign. The format for the extended-precision floating-point value is shown in <a class="xref" href="ch02s12.html#bit_extended-precision_floating-point_f" title="Figure 2-24. 80-bit extended-precision floating-point format">Figure 2-24</a>.</p><div class="figure"><a id="bit_extended-precision_floating-point_f"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e9810"/><img alt="80-bit extended-precision floating-point format" src="tagoreillycom20100401nostarchimages577931.png.jpg"/></div></div><p class="title">Figure 2-24. 80-bit extended-precision floating-point format</p></div><p>On the FPUs all computations are done using the extended-precision format. Whenever you load a single or double-precision value, the FPU automatically converts it to an extended-precision value. Likewise, when you store a single or double-precision value to memory, the FPU automatically rounds the value down to the appropriate size before storing it. By always working with the extended-precision format, Intel guarantees a large number of guard bits are present to ensure the accuracy of your computations.</p><p>To maintain maximum precision during computation, most computations use <span class="emphasis"><em>normalized</em></span> values. A normalized floating-point value is one whose H.O. mantissa bit contains 1. Almost any nonnormalized value can be normalized; shift the mantissa bits to the left and decrement the exponent until a 1 appears in the H.O. bit of the mantissa. Remember, the exponent is a binary exponent. Each time you increment the exponent, you multiply the floating-point value by 2. Likewise, whenever you decrement the exponent, you divide the floating-point value by 2. By the same token, shifting the mantissa to the left one bit position multiplies the floating-point value by 2; likewise, shifting the mantissa to the right divides the floating-point value by 2. Therefore, shifting the mantissa to the left one position <span class="emphasis"><em>and</em></span> decrementing the exponent does not change the value of the floating-point number at all.</p><p>Keeping floating-point numbers normalized is beneficial because it maintains the maximum number of bits of precision for a computation. If the H.O. bits of the mantissa are all 0, the mantissa has that many fewer bits of precision available for computation. Therefore, a floating-point computation will be more accurate if it involves only normalized values.<a class="indexterm" id="IDX-CHP-2-0260"/></p><p>There are two important cases where a floating-point number cannot be normalized. Zero is one of these special cases. Obviously it cannot be normalized because the floating-point representation for 0 has no 1 bits in the mantissa. This, however, is not a problem because we can exactly represent the value 0 with only a single bit.</p><p>The second case is when we have some H.O. bits in the mantissa that are 0 but the biased exponent is also 0 (and we cannot decrement it to normalize the mantissa). Rather than disallow certain small values, whose H.O. mantissa bits and biased exponent are 0 (the most negative exponent possible), the IEEE standard allows special <span class="emphasis"><em>denormalized</em></span> values to represent these smaller values.<sup>[<a class="footnote" href="#ftn.CHP-2-FN-10" id="CHP-2-FN-10">30</a>]</sup> Although the use of denormalized values allows IEEE floating-point computations to produce better results than if underflow occurred, keep in mind that denormalized values offer less bits of precision.</p></div><div class="sect2" title="2.12.2 HLA Support for Floating-Point Values"><div class="titlepage"><div><div><h2 class="title"><a id="hla_support_for_floating-point_values"/>2.12.2 HLA Support for Floating-Point Values</h2></div></div></div><p>HLA provides several data types and library routines to support the use of floating-point data in your assembly language programs. These include built-in types to declare floating-point variables as well as routines that provide floating-point input, output, and conversion.</p><p>Perhaps the best place to start when discussing HLA's floating-point facilities is with a description of floating-point literal constants. HLA floating-point constants allow the following syntax:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>An optional <code class="literal">+</code> or <code class="literal">−</code> symbol, denoting the sign of the mantissa (if this is not present, HLA assumes that the mantissa is positive)</p></li><li class="listitem"><p>Followed by one or more decimal digits</p></li><li class="listitem"><p>Optionally followed by a decimal point and one or more decimal digits</p></li><li class="listitem"><p>Optionally followed by an <code class="literal">e</code> or <code class="literal">E</code>, optionally followed by a sign (<code class="literal">+</code> or <code class="literal">−</code>) and one or more decimal digits</p></li></ul></div><p>Note that the decimal point or the <code class="literal">e</code>/<code class="literal">E</code> must be present in order to differentiate this value from an integer or unsigned literal constant. Here are some examples of legal literal floating-point constants:</p><a id="I_programlisting2_d1e9890"/><pre class="programlisting">1.234  3.75e2  −1.0  1.1e-1  1e+4  0.1  −123.456e+789  +25e0</pre><p>Notice that a floating-point literal constant cannot begin with a decimal point; it must begin with a decimal digit, so you must use 0.1 to represent .1 in your programs.</p><p>HLA also allows you to place an underscore character (<code class="literal">_</code>) between any two consecutive decimal digits in a floating-point literal constant. You may use the underscore character in place of a comma (or other language-specific separator character) to help make your large floating-point numbers easier to read. Here are some examples:</p><a id="I_programlisting2_d1e9899"/><pre class="programlisting">1_234_837.25  1_000.00  789_934.99  9_999.99</pre><p>To declare a floating-point variable you use the <code class="literal">real32</code>, <code class="literal">real64</code>, or <code class="literal">real80</code> data types. Like their integer and unsigned brethren, the number at the end of these data type declarations specifies the number of bits used for each type's binary representation. Therefore, you use <code class="literal">real32</code> to declare single-precision real values, <code class="literal">real64</code> to declare double-precision floating-point values, and <code class="literal">real80</code> to declare extended-precision floating-point values. Other than the fact that you use these types to declare floating-point variables rather than integers, their use is nearly identical to that for <code class="literal">int8</code>, <code class="literal">int16</code>, <code class="literal">int32</code><span class="emphasis"><em>,</em></span> and so on. The following examples demonstrate these declarations and their syntax:</p><a id="I_programlisting2_d1e9933"/><pre class="programlisting">static

          fltVar1:      real32;
          fltVar1a:     real32 := 2.7;
          pi:           real32 := 3.14159;
          DblVar:       real64;
          DblVar2:      real64 := 1.23456789e+10;
          XPVar:        real80;
          XPVar2:       real80 := −1.0e-104;</pre><p>To output a floating-point variable in ASCII form, you would use one of the <code class="literal">stdout.putr32</code><span class="emphasis"><em>,</em></span> <code class="literal">stdout.putr64</code>, or <code class="literal">stdout.putr80</code> routines. These procedures display a number in decimal notation, that is, a string of digits, an optional decimal point, and a closing string of digits. Other than their names, these three routines use exactly the same calling sequence. Here are the calls and parameters for each of these routines:<a class="indexterm" id="IDX-CHP-2-0261"/><a class="indexterm" id="IDX-CHP-2-0262"/><a class="indexterm" id="IDX-CHP-2-0263"/></p><a id="I_programlisting2_d1e9964"/><pre class="programlisting">stdout.putr80( r:real80; width:uns32; decpts:uns32 );
stdout.putr64( r:real64; width:uns32; decpts:uns32 );
stdout.putr32( r:real32; width:uns32; decpts:uns32 );</pre><p>The first parameter to these procedures is the floating-point value you wish to print. The size of this parameter must match the procedure's name (e.g., the <code class="literal">r</code> parameter must be an 80-bit extended-precision floating-point variable when calling the <code class="literal">stdout.putr80</code> routine). The second parameter specifies the field width for the output text; this is the number of print positions the number will require when the procedure displays it. Note that this width must include print positions for the sign of the number and the decimal point. The third parameter specifies the number of print positions after the decimal point. For example:</p><a id="I_programlisting2_d1e9974"/><pre class="programlisting">stdout.putr32( pi, 10, 4 );</pre><p>displays the value</p><a id="I_programlisting2_d1e9978"/><pre class="programlisting">_ _ _ _ 3.1416</pre><p>(underscores represent leading spaces in this example).</p><p>Of course, if the number is very large or very small, you will want to use scientific notation rather than decimal notation for your floating-point numeric output. The HLA Standard Library <code class="literal">stdout.pute32</code>, <code class="literal">stdout.pute64</code>, and <code class="literal">stdout.pute80</code> routines provide this facility. These routines use the following procedure prototypes:</p><a id="I_programlisting2_d1e9993"/><pre class="programlisting">stdout.pute80( r:real80; width:uns32 );
stdout.pute64( r:real64; width:uns32 );
stdout.pute32( r:real32; width:uns32 );</pre><p>Unlike the decimal output routines, these scientific notation output routines do not require a third parameter specifying the number of digits after the decimal point to display. The <code class="literal">width</code> parameter indirectly specifies this value because all but one of the mantissa digits always appear to the right of the decimal point. These routines output their values in decimal notation, similar to the following:</p><a id="I_programlisting2_d1e10000"/><pre class="programlisting">1.23456789e+10  −1.0e-104  1e+2</pre><p>You can also output floating-point values using the HLA Standard Library <code class="literal">stdout.put</code> routine. If you specify the name of a floating-point variable in the <code class="literal">stdout.put</code> parameter list, the <code class="literal">stdout.put</code> code will output the value using scientific notation. The actual field width varies depending on the size of the floating-point variable (the <code class="literal">stdout.put</code> routine attempts to output as many significant digits as possible, in this case). Here's an example:</p><a id="I_programlisting2_d1e10017"/><pre class="programlisting">stdout.put( "XPVar2 = ", XPVar2 );</pre><p>If you specify a field width, by using a colon followed by a signed integer value, then the <code class="literal">stdout.put</code> routine will use the appropriate <code class="literal">stdout.puteXX</code> routine to display the value. That is, the number will still appear in scientific notation, but you get to control the field width of the output value. Like the field width for integer and unsigned values, a positive field width right justifies the number in the specified field, and a negative number left justifies the value.</p><p>Here is an example that prints the <code class="literal">XPVar2</code> variable using 10 print positions:</p><a id="I_programlisting2_d1e10032"/><pre class="programlisting">stdout.put( "XPVar2 = ", XPVar2:10 );</pre><p>If you wish to use <code class="literal">stdout.put</code> to print a floating-point value in decimal notation, you need to use the following syntax:</p><a id="I_programlisting2_d1e10039"/><pre class="programlisting"><em class="replaceable"><code>Variable_Name</code></em> : <em class="replaceable"><code>Width</code></em> : <em class="replaceable"><code>DecPts</code></em></pre><p>Note that the <em class="replaceable"><code>DecPts</code></em> field must be a nonnegative integer value.</p><p>When <code class="literal">stdout.put</code> contains a parameter of this form, it calls the corresponding <code class="literal">stdout.putr</code><em class="replaceable"><code>XX</code></em> routine to display the specified floating-point value. As an example, consider the following call:</p><a id="I_programlisting2_d1e10063"/><pre class="programlisting">stdout.put( "Pi = ", pi:5:3 );</pre><p>The corresponding output is:</p><a id="I_programlisting2_d1e10068"/><pre class="programlisting">3.142</pre><p>The HLA Standard Library provides several other useful routines you can use when outputting floating-point values. Consult the HLA Standard Library reference manual for more information on these routines.</p><p>The HLA Standard Library provides several routines to let you display floating-point values in a wide variety of formats. In contrast, the HLA Standard Library provides only two routines to support floating-point input: <code class="literal">stdin.getf()</code> and <code class="literal">stdin.get()</code>. The <code class="literal">stdin.getf()</code> routine requires the use of the 80x86 FPU stack, a hardware component that this chapter doesn't cover. Therefore, we'll defer the discussion of the <code class="literal">stdin.getf()</code> routine until <a class="xref" href="ch06.html" title="Chapter 6. ARITHMETIC">Chapter 6</a>. Because the <code class="literal">stdin.get()</code> routine provides all the capabilities of the <code class="literal">stdin.getf()</code> routine, this deferral will not be a problem.<a class="indexterm" id="IDX-CHP-2-0264"/><a class="indexterm" id="IDX-CHP-2-0265"/></p><p>You've already seen the syntax for the <code class="literal">stdin.get()</code> routine; its parameter list simply contains a list of variable names. The <code class="literal">stdin.get()</code> function reads appropriate values for the user for each of the variables appearing in the parameter list. If you specify the name of a floating-point variable, the <code class="literal">stdin.get()</code> routine automatically reads a floating-point value from the user and stores the result into the specified variable. The following example demonstrates the use of this routine:</p><a id="I_programlisting2_d1e10116"/><pre class="programlisting">stdout.put( "Input a double-precision floating-point value: " );
     stdin.get( DblVar );</pre><div class="warning" title="Warning"><h3 class="title">Warning</h3><p>This section discussed how you would declare floating-point variables and how you would input and output them. It did not discuss arithmetic. Floating-point arithmetic is different from integer arithmetic; you cannot use the 80x86 <em class="replaceable"><code>add</code></em> and <em class="replaceable"><code>sub</code></em> instructions to operate on floating-point values. Floating-point arithmetic will be the subject of <a class="xref" href="ch06.html" title="Chapter 6. ARITHMETIC">Chapter 6</a>.</p></div></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-6" id="ftn.CHP-2-FN-6">26</a>] </sup>Of course, the drawback is that you must now perform two multiplications rather than one, so the result may be slower.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-7" id="ftn.CHP-2-FN-7">27</a>] </sup>There were some minor changes to the way certain degenerate operations were handled, but the bit representation remained essentially unchanged.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-8" id="ftn.CHP-2-FN-8">28</a>] </sup>The binary point is the same thing as the decimal point except it appears in binary numbers rather than decimal numbers.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-9" id="ftn.CHP-2-FN-9">29</a>] </sup>Actually, this isn't necessarily true. The IEEE floating-point format supports <span class="emphasis"><em>denormalized</em></span> values where the H.O. bit is not 0. However, we will ignore denormalized values in our discussion.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-10" id="ftn.CHP-2-FN-10">30</a>] </sup>The alternative would be to underflow the values to 0.</p></div></div></div>
<div class="sect1" title="2.13 Binary-Coded Decimal Representation"><div class="titlepage"><div><div><h1 class="title"><a id="binary-coded_decimal_representation"/>2.13 Binary-Coded Decimal Representation</h1></div></div></div><p>Although the integer and floating-point formats cover most of the numeric needs of an average program, there are some special cases where other numeric representations are convenient. In this section we'll discuss the binary-coded decimal format because the 80x86 CPU provides a small amount of hardware support for this data representation.<a class="indexterm" id="IDX-CHP-2-0266"/></p><p>BCD values are a sequence of nibbles, with each nibble representing a value in the range 0..9. Of course you can represent values in the range 0..15 using a nibble; the BCD format, however, uses only 10 of the possible 16 different values for each nibble.</p><p>Each nibble in a BCD value represents a single decimal digit. Therefore, with a single byte (i.e., two digits) we can represent values containing two decimal digits, or values in the range 0..99 (see <a class="xref" href="ch02s13.html#cd_data_representation_in_memory" title="Figure 2-25. CD data representation in memory">Figure 2-25</a>). With a word, we can represent values having four decimal digits, or values in the range 0..9,999. Likewise, with a double word we can represent values with up to eight decimal digits (because there are eight nibbles in a double-word value).</p><div class="figure"><a id="cd_data_representation_in_memory"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e10146"/><img alt="CD data representation in memory" src="tagoreillycom20100401nostarchimages577933.png"/></div></div><p class="title">Figure 2-25. CD data representation in memory</p></div><p>As you can see, BCD storage isn't particularly memory efficient. For example, an 8-bit BCD variable can represent values in the range 0..99 while that same 8 bits, when holding a binary value, can represent values in the range 0..255. Likewise, a 16-bit binary value can represent values in the range 0..65,535, while a 16-bit BCD value can represent only about one-sixth of those values (0..9,999). Inefficient storage isn't the only problem. BCD calculations tend to be slower than binary calculations.</p><p>At this point, you're probably wondering why anyone would ever use the BCD format. The BCD format does have two saving graces: It's very easy to convert BCD values between the internal numeric representation and their string representation; also, it's very easy to encode multidigit decimal values in hardware (e.g., using a thumb wheel or dial) using BCD. For these two reasons, you're likely to see people using BCD in embedded systems (such as toaster ovens, alarm clocks, and nuclear reactors) but rarely in general-purpose computer software.</p><p>A few decades ago people mistakenly thought that calculations involving BCD (or just decimal) arithmetic were more accurate than binary calculations. Therefore, they would often perform important calculations, like those involving dollars and cents (or other monetary units) using decimal-based arithmetic. While it is true that certain calculations can produce more accurate results in BCD, this statement is not true in general. Indeed, for most calculations (even those involving fixed-point decimal arithmetic), the binary representation is more accurate. For this reason, most modern computer programs represent all values in a binary form. For example, the Intel 80x86 floating-point unit supports a pair of instructions for loading and storing BCD values. Internally, however, the FPU converts these BCD values to binary and performs all calculations in binary. It uses BCD only as an external data format (external to the FPU, that is). This generally produces more accurate results and requires far less silicon than having a separate coprocessor that supports decimal arithmetic.</p></div>
<div class="sect1" title="2.14 Characters"><div class="titlepage"><div><div><h1 class="title"><a id="characters"/>2.14 Characters</h1></div></div></div><p>Perhaps the most important data type on a personal computer is the character data type. The term <span class="emphasis"><em>character</em></span> refers to a human or machine-readable symbol that is typically a nonnumeric entity. In general, the term <span class="emphasis"><em>character</em></span> refers to any symbol that you can normally type on a keyboard (including some symbols that may require multiple key presses to produce) or display on a video display. Many beginners often confuse the terms <span class="emphasis"><em>character</em></span> and <span class="emphasis"><em>alphabetic character</em></span>. These terms are not the same. Punctuation symbols, numeric digits, spaces, tabs, carriage returns (enter), other control characters, and other special symbols are also characters. When this text uses the term <span class="emphasis"><em>character</em></span> it refers to any of these characters, not just the alphabetic characters. When this text refers to alphabetic characters, it will use phrases like "alphabetic characters," "uppercase characters," or "lowercase characters."<a class="indexterm" id="IDX-CHP-2-0267"/><a class="indexterm" id="IDX-CHP-2-0268"/></p><p>Another common problem beginners have when they first encounter the character data type is differentiating between numeric characters and numbers. The character <code class="literal">1</code> is different from the value 1. The computer (generally) uses two different internal representations for numeric characters (<code class="literal">0</code>, <code class="literal">1</code>, ..., <code class="literal">9</code>) versus the numeric values 0..9. You must take care not to confuse the two.</p><p>Most computer systems use a 1- or 2-byte sequence to encode the various characters in binary form. Windows, Mac OS X, FreeBSD, and Linux certainly fall into this category, using either the ASCII or Unicode encodings for characters. This section will discuss the ASCII character set and the character declaration facilities that HLA provides.<a class="indexterm" id="IDX-CHP-2-0269"/><a class="indexterm" id="IDX-CHP-2-0270"/></p><div class="sect2" title="2.14.1 The ASCII Character Encoding"><div class="titlepage"><div><div><h2 class="title"><a id="the_ascii_character_encoding"/>2.14.1 The ASCII Character Encoding</h2></div></div></div><p>The ASCII (American Standard Code for Information Interchange) character set maps 128 textual characters to the unsigned integer values 0..127 ($0..$7F). Internally, of course, the computer represents everything using binary numbers, so it should come as no surprise that the computer also uses binary values to represent nonnumeric entities such as characters. Although the exact mapping of characters to numeric values is arbitrary and unimportant, it is important to use a standardized code for this mapping because you will need to communicate with other programs and peripheral devices and you need to talk the same "language" as these other programs and devices. This is where the ASCII code comes into play; it is a standardized code that nearly everyone has agreed on. Therefore, if you use the ASCII code 65 to represent the character <code class="literal">'A'</code>, then you know that some peripheral device (such as a printer) will correctly interpret this value as the character <code class="literal">'A'</code> whenever you transmit data to that device.</p><p>You should not get the impression that ASCII is the only character set in use on computer systems. IBM uses the EBCDIC character set family on many of its mainframe computer systems. Another common character set in use is the Unicode character set. Unicode is an extension to the ASCII character set that uses 16 bits rather than 7 bits to represent characters. This allows the use of 65,536 different characters in the character set, allowing the inclusion of most symbols in the world's different languages into a single unified character set.</p><p>Because the ASCII character set provides only 128 different characters and a byte can represent 256 different values, an interesting question arises: "What do we do with the values 128..255 that one could store into a byte?" One answer is to ignore those extra values. That will be the primary approach of this text. Another possibility is to extend the ASCII character set and add an additional 128 characters to it. Of course, this would tend to defeat the whole purpose of having a standardized character set unless you could get everyone to agree on the extensions. That is a difficult task.</p><p>When IBM first created its IBM-PC, it defined these extra 128 character codes to contain various non-English alphabetic characters, some line-drawing graphics characters, some mathematical symbols, and several other special characters. Because IBM's PC was the foundation for what we typically call a PC today, that character set has become a pseudo-standard on all IBM-PC compatible machines. Even on modern machines, which are not IBM-PC compatible and cannot run early PC software, the IBM extended character set survives. Note, however, that this PC character set (an extension of the ASCII character set) is not universal. Most printers will not print the extended characters when using native fonts, and many programs (particularly in non-English-speaking countries) do not use those characters for the upper 128 codes in an 8-bit value. For these reasons, this text will generally stick to the standard 128-character ASCII character set.</p><p>Despite the fact that it is a standard, simply encoding your data using standard ASCII characters does not guarantee compatibility across systems. While it's true that an <code class="literal">'A'</code> on one machine is most likely an <code class="literal">'A'</code> on another machine, there is very little standardization across machines with respect to the use of the control characters. Indeed, of the 32 control codes plus delete, there are only four control codes commonly supported—backspace (BS), tab, carriage return (CR), and line feed (LF). Worse still, different machines often use these control codes in different ways. <span class="emphasis"><em>End of line</em></span> is a particularly troublesome example. Windows, MS-DOS, CP/M, and other systems mark end of line by the two-character sequence CR/LF. Older Apple Macintosh computers (Mac OS 9 and earlier) and many other systems mark the end of a line by a single CR character. Linux, Mac OS X, FreeBSD, and other Unix systems mark the end of a line with a single LF character. Needless to say, attempting to exchange simple text files between such systems can be an experience in frustration. Even if you use standard ASCII characters in all your files on these systems, you will still need to convert the data when exchanging files between them. Fortunately, such conversions are rather simple.</p><p>Despite some major shortcomings, ASCII data is <span class="emphasis"><em>the</em></span> standard for data interchange across computer systems and programs. Most programs can accept ASCII data; likewise most programs can produce ASCII data. Because you will be dealing with ASCII characters in assembly language, it would be wise to study the layout of the character set and memorize a few key ASCII codes (e.g., for <code class="literal">'0'</code>, <code class="literal">'A'</code>, <code class="literal">'a'</code>, etc.).</p><p>The ASCII character set is divided into four groups of 32 characters. The first 32 characters, ASCII codes 0..$1F (31), form a special set of nonprinting characters, the <span class="emphasis"><em>control characters</em></span>. We call them control characters because they perform various printer/display control operations rather than display symbols. Examples include <span class="emphasis"><em>carriage return</em></span>, which positions the cursor to the left side of the current line of characters;<sup>[<a class="footnote" href="#ftn.CHP-2-FN-11" id="CHP-2-FN-11">31</a>]</sup> line feed, which moves the cursor down one line on the output device; and backspace, which moves the cursor back one position to the left. Unfortunately, different control characters perform different operations on different output devices. There is very little standardization among output devices. To find out exactly how a control character affects a particular device, you will need to consult its manual.<a class="indexterm" id="IDX-CHP-2-0271"/></p><p>The second group of 32 ASCII character codes contains various punctuation symbols, special characters, and the numeric digits. The most notable characters in this group include the space character (ASCII code $20) and the numeric digits (ASCII codes $30..$39).</p><p>The third group of 32 ASCII characters contains the uppercase alphabetic characters. The ASCII codes for the characters <code class="literal">'A'</code>..<code class="literal">'Z'</code> lie in the range $41..$5A (65..90). Because there are only 26 different alphabetic characters, the remaining 6 codes hold various special symbols.</p><p>The fourth, and final, group of 32 ASCII character codes represents the lowercase alphabetic symbols, 5 additional special symbols, and another control character (delete). Note that the lowercase character symbols use the ASCII codes $61..$7A. If you convert the codes for the upper- and lowercase characters to binary, you will notice that the uppercase symbols differ from their lowercase equivalents in exactly one bit position. For example, consider the character codes for <code class="literal">'E'</code> and <code class="literal">'e'</code> appearing in <a class="xref" href="ch02s14.html#ascii_codes_for_e_and_e" title="Figure 2-26. ASCII codes for E and e">Figure 2-26</a>.</p><div class="figure"><a id="ascii_codes_for_e_and_e"/><div class="figure-contents"><div class="mediaobject"><a id="I_mediaobject2_d1e10294"/><img alt="ASCII codes for E and e" src="tagoreillycom20100401nostarchimages577935.png"/></div></div><p class="title">Figure 2-26. ASCII codes for E and e</p></div><p>The only place these two codes differ is in bit 5. Uppercase characters always contain a 0 in bit 5; lowercase alphabetic characters always contain a 1 in bit 5. You can use this fact to quickly convert between upper- and lowercase. If you have an uppercase character, you can force it to lowercase by setting bit 5 to 1. If you have a lowercase character and you wish to force it to uppercase, you can do so by setting bit 5 to 0. You can toggle an alphabetic character between upper- and lowercase by simply inverting bit 5.<a class="indexterm" id="IDX-CHP-2-0272"/></p><p>Indeed, bits 5 and 6 determine which of the four groups in the ASCII character set you're in, as <a class="xref" href="ch02s14.html#ascii_groups" title="Table 2-8. ASCII Groups">Table 2-8</a> shows.<a class="indexterm" id="IDX-CHP-2-0273"/></p><div class="table"><a id="ascii_groups"/><p class="title">Table 2-8. ASCII Groups</p><div class="table-contents"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; " summary="ASCII Groups"><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p>Bit 6</p></th><th style="text-align: left" valign="bottom"><p>Bit 5</p></th><th style="text-align: left" valign="bottom"><p>Group</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>Control characters</p></td></tr><tr><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>Digits and punctuation</p></td></tr><tr><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>Uppercase and special</p></td></tr><tr><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>Lowercase and special</p></td></tr></tbody></table></div></div><p>So you could, for instance, convert any upper- or lowercase (or corresponding special) character to its equivalent control character by setting bits 5 and 6 to 0.</p><p>Consider, for a moment, the ASCII codes of the numeric digit characters appearing in <a class="xref" href="ch02s14.html#ascii_codes_for_numeric_digits" title="Table 2-9. ASCII Codes for Numeric Digits">Table 2-9</a>.</p><div class="table"><a id="ascii_codes_for_numeric_digits"/><p class="title">Table 2-9. ASCII Codes for Numeric Digits</p><div class="table-contents"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; border-left: 0.5pt solid ; border-right: 0.5pt solid ; " summary="ASCII Codes for Numeric Digits"><colgroup><col/><col/><col/></colgroup><thead><tr><th style="text-align: left" valign="bottom"><p>Character</p></th><th style="text-align: left" valign="bottom"><p>Decimal</p></th><th style="text-align: left" valign="bottom"><p>Hexadecimal</p></th></tr></thead><tbody><tr><td style="text-align: left" valign="top"><p>0</p></td><td style="text-align: left" valign="top"><p>48</p></td><td style="text-align: left" valign="top"><p>$30</p></td></tr><tr><td style="text-align: left" valign="top"><p>1</p></td><td style="text-align: left" valign="top"><p>49</p></td><td style="text-align: left" valign="top"><p>$31</p></td></tr><tr><td style="text-align: left" valign="top"><p>2</p></td><td style="text-align: left" valign="top"><p>50</p></td><td style="text-align: left" valign="top"><p>$32</p></td></tr><tr><td style="text-align: left" valign="top"><p>3</p></td><td style="text-align: left" valign="top"><p>51</p></td><td style="text-align: left" valign="top"><p>$33</p></td></tr><tr><td style="text-align: left" valign="top"><p>4</p></td><td style="text-align: left" valign="top"><p>52</p></td><td style="text-align: left" valign="top"><p>$34</p></td></tr><tr><td style="text-align: left" valign="top"><p>5</p></td><td style="text-align: left" valign="top"><p>53</p></td><td style="text-align: left" valign="top"><p>$35</p></td></tr><tr><td style="text-align: left" valign="top"><p>6</p></td><td style="text-align: left" valign="top"><p>54</p></td><td style="text-align: left" valign="top"><p>$36</p></td></tr><tr><td style="text-align: left" valign="top"><p>7</p></td><td style="text-align: left" valign="top"><p>55</p></td><td style="text-align: left" valign="top"><p>$37</p></td></tr><tr><td style="text-align: left" valign="top"><p>8</p></td><td style="text-align: left" valign="top"><p>56</p></td><td style="text-align: left" valign="top"><p>$38</p></td></tr><tr><td style="text-align: left" valign="top"><p>9</p></td><td style="text-align: left" valign="top"><p>57</p></td><td style="text-align: left" valign="top"><p>$39</p></td></tr></tbody></table></div></div><p>The decimal representations of these ASCII codes are not very enlightening. However, the hexadecimal representation of these ASCII codes reveals something very important—the L.O. nibble of the ASCII code is the binary equivalent of the represented number. By stripping away (i.e., setting to 0) the H.O. nibble of a numeric character, you can convert that character code to the corresponding binary representation. Conversely, you can convert a binary value in the range 0..9 to its ASCII character representation by simply setting the H.O. nibble to 3. Note that you can use the logical <code class="literal">and</code> operation to force the H.O. bits to 0; likewise, you can use the logical <code class="literal">or</code> operation to force the H.O. bits to %0011 (3).<a class="indexterm" id="IDX-CHP-2-0274"/><a class="indexterm" id="IDX-CHP-2-0275"/><a class="indexterm" id="IDX-CHP-2-0276"/></p><p>Note that you <span class="emphasis"><em>cannot</em></span> convert a string of numeric characters to their equivalent binary representation by simply stripping the H.O. nibble from each digit in the string. Converting 123 ($31 $32 $33) in this fashion yields 3 bytes: $010203; the correct value for 123 is $7B. Converting a string of digits to an integer requires more sophistication than this; the conversion above works only for single digits.</p></div><div class="sect2" title="2.14.2 HLA Support for ASCII Characters"><div class="titlepage"><div><div><h2 class="title"><a id="hla_support_for_ascii_characters"/>2.14.2 HLA Support for ASCII Characters</h2></div></div></div><p>Although you could easily store character values in <code class="literal">byte</code> variables and use the corresponding numeric equivalent ASCII code when using a character literal in your program, such agony is unnecessary. HLA provides support for character variables and literals in your assembly language programs.</p><p>Character literal constants in HLA take one of two forms: a single character surrounded by apostrophes or a hash mark (<code class="literal">#</code>) followed by a numeric constant in the range 0..127 (specifying the ASCII code of the character). Here are some examples:<a class="indexterm" id="IDX-CHP-2-0277"/></p><a id="I_programlisting2_d1e10541"/><pre class="programlisting">'A'   #65    #$41    #%0100_0001</pre><p>Note that these examples all represent the same character (<code class="literal">'A'</code>) because the ASCII code of <code class="literal">'A'</code> is 65.</p><p>With one exception, only a single character may appear between the apostrophes in a literal character constant. That single exception is the apostrophe character itself. If you wish to create an apostrophe literal constant, place four apostrophes in a row (i.e., double up the apostrophe inside the surrounding apostrophes):</p><a id="I_programlisting2_d1e10553"/><pre class="programlisting">''''</pre><p>The hash mark operator (<code class="literal">#</code>) must precede a legal HLA numeric constant (either decimal, hexadecimal, or binary, as the examples above indicate). In particular, the hash mark is not a generic character conversion function; it cannot precede registers or variable names, only constants.</p><p>As a general rule, you should always use the apostrophe form of the character literal constant for graphic characters (that is, those that are printable or displayable). Use the hash mark form for control characters (that are invisible or do funny things when you print them) or for extended ASCII characters that may not display or print properly within your source code.</p><p>Notice the difference between a character literal constant and a string literal constant in your programs. Strings are sequences of zero or more characters surrounded by quotation marks; characters are surrounded by apostrophes.</p><p>It is especially important to realize that</p><a id="I_programlisting2_d1e10567"/><pre class="programlisting">'A' ≠ "A"</pre><p>The character constant <code class="literal">'A'</code> and the string containing the single character <code class="literal">A</code> have two completely different internal representations. If you attempt to use a string containing a single character where HLA expects a character constant, HLA will report an error. Strings and string constants are the subject of <a class="xref" href="ch04.html" title="Chapter 4. CONSTANTS, VARIABLES, AND DATA TYPES">Chapter 4</a>.</p><p>To declare a character variable in an HLA program, you use the <code class="literal">char</code> data type. For example, the following declaration demonstrates how to declare a variable named <code class="literal">UserInput</code>:<a class="indexterm" id="IDX-CHP-2-0278"/></p><a id="I_programlisting2_d1e10592"/><pre class="programlisting">static
     UserInput:          char;</pre><p>This declaration reserves 1 byte of storage that you could use to store any character value (including 8-bit extended ASCII characters). You can also initialize character variables as the following example demonstrates:</p><a id="I_programlisting2_d1e10596"/><pre class="programlisting">static

     TheCharA:          char := 'A';
     ExtendedChar:      char := #128;</pre><p>Because character variables are 8-bit objects, you can manipulate them using 8-bit registers. You can move character variables into 8-bit registers, and you can store the value of an 8-bit register into a character variable.</p><p>The HLA Standard Library provides a handful of routines that you can use for character I/O and manipulation; these include <code class="literal">stdout.putc</code>, <code class="literal">stdout.putcSize</code>, <code class="literal">stdout.put</code><span class="emphasis"><em>,</em></span> <code class="literal">stdin.getc</code><span class="emphasis"><em>,</em></span> and <code class="literal">stdin.get</code>.<a class="indexterm" id="IDX-CHP-2-0279"/><a class="indexterm" id="IDX-CHP-2-0280"/></p><p>The <code class="literal">stdout.putc</code> routine uses the following calling sequence:</p><a id="I_programlisting2_d1e10637"/><pre class="programlisting">stdout.putc( <em class="replaceable"><code>charvar</code></em> );</pre><p>This procedure outputs the single-character parameter passed to it as a character to the standard output device. The parameter may be any <code class="literal">char</code> constant or variable, or a <code class="literal">byte</code> variable or register.<sup>[<a class="footnote" href="#ftn.CHP-2-FN-12" id="CHP-2-FN-12">32</a>]</sup></p><p>The <code class="literal">stdout.putcSize</code> routine provides output width control when displaying character variables. The calling sequence for this procedure is</p><a id="I_programlisting2_d1e10662"/><pre class="programlisting">stdout.putcSize( <em class="replaceable"><code>charvar</code></em>, <em class="replaceable"><code>widthInt32</code></em>, <em class="replaceable"><code>fillchar</code></em> );</pre><p>This routine prints the specified character (parameter <code class="literal">c</code>) using at least <em class="replaceable"><code>widthInt32</code></em> print positions.<sup>[<a class="footnote" href="#ftn.CHP-2-FN-13" id="CHP-2-FN-13">33</a>]</sup> If the absolute value of <em class="replaceable"><code>widthInt32</code></em> is greater than 1, then <code class="literal">stdout.putcSize</code> prints the <em class="replaceable"><code>fillchar</code></em> character as padding. If the value of <em class="replaceable"><code>widthInt32</code></em> is positive, then <code class="literal">stdout.putcSize</code> prints the character right justified in the print field; if <em class="replaceable"><code>widthInt32</code></em> is negative, then <code class="literal">stdout.putcSize</code> prints the character left justified in the print field. Because character output is usually left justified in a field, the <em class="replaceable"><code>widthInt32</code></em> value will normally be negative for this call. The space character is the most common <em class="replaceable"><code>fillchar</code></em> value.</p><p>You can also print character values using the generic <code class="literal">stdout.put</code> routine. If a character variable appears in the <code class="literal">stdout.put</code> parameter list, then <code class="literal">stdout.put</code> will automatically print it as a character value. For example:<a class="indexterm" id="IDX-CHP-2-0281"/></p><a id="I_programlisting2_d1e10733"/><pre class="programlisting">stdout.put( "Character c = '", c, "'", nl );</pre><p>You can read characters from the standard input using the <code class="literal">stdin.getc</code> and <code class="literal">stdin.get</code> routines. The <code class="literal">stdin.getc</code> routine does not have any parameters. It reads a single character from the standard input buffer and returns this character in the AL register. You may then store the character value away or otherwise manipulate the character in the AL register. The program in <a class="xref" href="ch02s14.html#character_input_sample" title="Example 2-10. Character input sample">Example 2-10</a> reads a single character from the user, converts it to uppercase if it is a lowercase character, and then displays the character.<a class="indexterm" id="IDX-CHP-2-0282"/></p><div class="example"><a id="character_input_sample"/><p class="title">Example 2-10. Character input sample</p><div class="example-contents"><pre class="programlisting">program charInputDemo;
#include( "stdlib.hhf" )
begin charInputDemo;

    stdout.put( "Enter a character: " );
    stdin.getc();
    if( al &gt;= 'a' ) then

        if( al &lt;= 'z' ) then

            and( $5f, al );

        endif;

    endif;
    stdout.put
    (
        "The character you entered, possibly ", nl,
        "converted to uppercase, was '"
    );
    stdout.putc( al );
    stdout.put( "'", nl );

end charInputDemo;</pre></div></div><p>You can also use the generic <code class="literal">stdin.get</code> routine to read character variables from the user. If a <code class="literal">stdin.get</code> parameter is a character variable, then the <code class="literal">stdin.get</code> routine will read a character from the user and store the character value into the specified variable. <a class="xref" href="ch02s14.html#stdin.get_character_input_sample" title="Example 2-11. stdin.get character input sample">Example 2-11</a> is a rewrite of <a class="xref" href="ch02s14.html#character_input_sample" title="Example 2-10. Character input sample">Example 2-10</a> using the <code class="literal">stdin.get</code> routine.</p><div class="example"><a id="stdin.get_character_input_sample"/><p class="title">Example 2-11. <code class="literal">stdin.get</code> character input sample</p><div class="example-contents"><pre class="programlisting">program charInputDemo2;
#include( "stdlib.hhf" )
static
    c:char;

begin charInputDemo2;

    stdout.put( "Enter a character: " );
    stdin.get(c);
    if( c &gt;= 'a' ) then

        if( c &lt;= 'z' ) then

            and( $5f, c );

        endif;

    endif;
    stdout.put
    (
        "The character you entered, possibly ", nl,
        "converted to uppercase, was '",
        c,
        "'", nl
    );

end charInputDemo2;</pre></div></div><p>As you may recall from the last chapter, the HLA Standard Library buffers its input. Whenever you read a character from the standard input using <code class="literal">stdin.getc</code> or <code class="literal">stdin.get</code>, the library routines read the next available character from the buffer; if the buffer is empty, then the program reads a new line of text from the user and returns the first character from that line. If you want to guarantee that the program reads a new line of text from the user when you read a character variable, you should call the <code class="literal">stdin.flushInput</code> routine before attempting to read the character. This will flush the current input buffer and force the input of a new line of text on the next input (probably a <code class="literal">stdin.getc</code> or <code class="literal">stdin.get</code> call).<a class="indexterm" id="IDX-CHP-2-0283"/></p><p>The end of line is problematic. Different operating systems handle the end of line differently on output versus input. From the console device, pressing the <span class="keycap"><strong>enter</strong></span> key signals the end of a line; however, when reading data from a file, you get an end-of-line sequence that is a linefeed or a carriage return/line feed pair (under Windows) or just a line feed (under Linux/Mac OS X/FreeBSD). To help solve this problem, HLA's Standard Library provides an "end of line" function. This procedure returns true (1) in the AL register if all the current input characters have been exhausted; it returns false (0) otherwise. The sample program in <a class="xref" href="ch02s14.html#testing_for_end_of_line_using_stdin.eoln" title="Example 2-12. Testing for end of line using stdin.eoln">Example 2-12</a> demonstrates the <code class="literal">stdin.eoln</code> function.<a class="indexterm" id="IDX-CHP-2-0284"/><a class="indexterm" id="IDX-CHP-2-0285"/></p><div class="example"><a id="testing_for_end_of_line_using_stdin.eoln"/><p class="title">Example 2-12. Testing for end of line using <code class="literal">stdin.eoln</code></p><div class="example-contents"><pre class="programlisting">program eolnDemo;
#include( "stdlib.hhf" )
begin eolnDemo;

    stdout.put( "Enter a short line of text: " );
    stdin.flushInput();
    repeat

        stdin.getc();
        stdout.putc( al );
        stdout.put( "=$", al, nl );

    until( stdin.eoln() );

end eolnDemo;</pre></div></div><p>The HLA language and the HLA Standard Library provide many other procedures and additional support for character objects. <a class="xref" href="ch04.html" title="Chapter 4. CONSTANTS, VARIABLES, AND DATA TYPES">Chapter 4</a> and <a class="xref" href="ch11.html" title="Chapter 11. THE STRING INSTRUCTIONS">Chapter 11</a>, as well as the HLA reference documentation, describe how to use these features.</p></div><div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-11" id="ftn.CHP-2-FN-11">31</a>] </sup>Historically, carriage return refers to the <span class="emphasis"><em>paper carriage</em></span> used on typewriters. A carriage return consisted of physically moving the carriage all the way to the right so that the next character typed would appear at the left-hand side of the paper.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-12" id="ftn.CHP-2-FN-12">32</a>] </sup>If you specify a byte variable or a byte-sized register as the parameter, the <code class="literal">stdout.putc</code> routine will output the character whose ASCII code appears in the variable or register.</p></div><div class="footnote"><p><sup>[<a class="para" href="#CHP-2-FN-13" id="ftn.CHP-2-FN-13">33</a>] </sup>The only time <code class="literal">stdout.putcSize</code> uses more print positions than you specify is when you specify 0 as the width; then this routine uses exactly one print position.</p></div></div></div>
<div class="sect1" title="2.15 The Unicode Character Set"><div class="titlepage"><div><div><h1 class="title"><a id="the_unicode_character_set"/>2.15 The Unicode Character Set</h1></div></div></div><p>Although the ASCII character set is, unquestionably, the most popular character representation on computers, it is certainly not the only format around. For example, IBM uses the EBCDIC code on many of its mainframe and minicomputer lines. Because EBCDIC appears mainly on IBM's big iron and you'll rarely encounter it on personal computer systems, we will not consider that character set in this text. Another character representation that is becoming popular on small computer systems (and large ones, for that matter) is the Unicode character set. Unicode overcomes two of ASCII's greatest limitations: the limited character space (i.e., a maximum of 128/256 characters in an 8-bit byte) and the lack of international (beyond the United States) characters.<a class="indexterm" id="IDX-CHP-2-0286"/></p><p>Unicode uses a 16-bit word to represent a single character. Therefore, Unicode supports up to 65,536 different character codes. This is obviously a huge advance over the 256 possible codes we can represent with an 8-bit byte. Unicode is upward compatible from ASCII. Specifically, if the H.O. 9 bits of a Unicode character contain 0, then the L.O. 7 bits represent the same character as the ASCII character with the same character code. If the H.O. 9 bits contain some nonzero value, then the character represents some other value. If you're wondering why so many different character codes are necessary, simply note that certain Asian character sets contain 4,096 characters (at least their Unicode subset does).</p><p>This text will stick to the ASCII character set except for a few brief mentions of Unicode here and there. Eventually, this text may have to eliminate the discussion of ASCII in favor of Unicode because many new operating systems are using Unicode internally (and converting to ASCII as necessary). Unfortunately, many string algorithms are not as conveniently written for Unicode as for ASCII (especially character set functions), so we'll stick with ASCII in this text as long as possible.</p></div>
<div class="sect1" title="2.16 For More Information"><div class="titlepage"><div><div><h1 class="title"><a id="for_more_information-id1"/>2.16 For More Information</h1></div></div></div><p>The electronic edition of this book (on Webster at <a class="ulink" href="http://webster.cs.ucr.edu/">http://webster.cs.ucr.edu/</a> or <a class="ulink" href="http://artofasm.com/">http://artofasm.com/</a>) contains some additional information on data representation you may find useful. For general information about data representation, you should consider reading my book <span class="emphasis"><em>Write Great Code, Volume 1</em></span> (No Starch Press, 2004), or a textbook on data structures and algorithms (available at any bookstore).</p></div></body></html>