<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="index: http://www.index.com/" lang="en" xml:lang="en">
	<head>
		<title>Chapter 8: Delivering Software</title>
		<link href="NSTemplate_v1.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:7db14923-61d0-434f-baa0-3e20bf74259e" name="Adept.expected.resource"/>
	</head>
	<body epub:type="bodymatter chapter">
		<section>
			<header>
				<h1 class="chapter"><span class="ChapterNumber"><span epub:type="pagebreak" id="Page_123" title="123"/>8</span><br/><span class="ChapterTitle">Delivering Software</span></h1>
			</header>
			<p class="BodyFirst"><span class="DropCap">Y</span>ou should understand how your code winds up in front of users. Understanding the delivery process will help you troubleshoot problems and control when changes are made. You might not participate in the process directly—it might be automated or performed by release engineers—but the steps between <code>git commit</code> and live traffic should not be a mystery.</p>
			<p>Software is delivered when it’s running stably in production and customers are using it. Delivery consists of steps such as release, deployment, and rollout. This chapter describes different phases involved in delivering software to customers, source control branching strategies (which affect how software is released), and current best practices.</p>
			<h2 id="h1-501836c08-0001">Software Delivery Phases</h2>
			<p class="BodyFirst">Unfortunately, delivery phases do not have industry-standard definitions. Depending on who you talk to, words like <em>release</em> and <em>deploy</em> can <span epub:type="pagebreak" id="Page_124" title="124"/>refer to completely different parts of the delivery pipeline. Your team might refer to the whole process, from packaging to rollout, as <em>releasing</em>. They might call packaging an artifact a <em>release</em>, while making the artifact available for download is <em>publishing</em>. They might not say a feature is <em>released</em> until it’s turned on in production, while everything preceding that action is <em>deployment</em>.</p>
			<p>
				For the purposes of this chapter, we refer to four software delivery phases, namely <em>build</em>, <em>release</em>, <em>deployment</em>, and <em>rollout</em>, shown in <a href="#figure8-1" id="figureanchor8-1">Figure 8-1</a>. Software must first be <em>built</em> into packages. Packages should be immutable and versioned. Packages must then be <em>released</em>. Release notes and changelogs are updated, and packages are published to a centralized repository. Published release artifacts must be <em>deployed</em> to preproduction and production environments. Deployed software is not yet accessible to users—it’s just been installed. Once deployed, software is <em>rolled out</em> by shifting users to the new software. Once the rollout is complete, software is delivered.</p>
			<figure>
				<img alt="f08001" src="image_fi/501836c08/f08001.png"/>
				<figcaption>
					<p><a id="figure8-1">Figure 8-1</a>: Software delivery phases</p>
				</figcaption>
			</figure>
			<p>The delivery process is part of a larger product development cycle. After rollout, feedback is gathered, bugs are detected, and new product requirements are collected. Feature development begins anew, and eventually the next build is kicked off.</p>
			<p>
				Each delivery phase has a set of best practices. These practices will help you deliver software quickly and safely. But before we dive into each delivery step, we need to cover <em>source control branching strategies</em>. Branching strategies determine where code changes are committed and how release code is maintained. The right branching strategy will make software delivery easy and predictable, while the wrong strategy will turn delivery into a fight against the process itself.</p>
			<h2 id="h1-501836c08-0002"><span epub:type="pagebreak" id="Page_125" title="125"/>Branching Strategies</h2>
			<p class="BodyFirst">Release packages are built from code in version control systems. <em>Trunk</em>—sometimes <em>main</em> or <em>mainline</em>—contains the main version of a codebase with a history of changes. <em>Branches</em> are “cut” from trunk to alter the code; multiple branches allow developers to work in parallel and merge their changes into trunk when ready. Different branching strategies define how long branches should last, how they relate to released versions of the software, and how changes propagate to multiple branches. The two main families of branching strategies are trunk-based and feature branch–based development.</p>
			<p>
				In <em>trunk-based development</em>, all developers work off of trunk. Branches are used for a single small feature, bug fix, or update.</p>
			<p><a href="#figure8-2" id="figureanchor8-2">Figure 8-2</a> shows a trunk-based development strategy. A feature branch is created in feature-1 and merged back to trunk. The bug-1 branch is created to fix a bug. A release branch has also been cut, and developers have decided to cherry-pick the bug fix into the 1.0 release.</p>
			<figure>
				<img alt="f08002" src="image_fi/501836c08/f08002.png"/>
				<figcaption>
					<p><a id="figure8-2">Figure 8-2</a>: Trunk-based development branches</p>
				</figcaption>
			</figure>
			<p>
				Trunk-based development works best when branches are merged back to trunk quickly, in a matter of days if not hours, and not shared between developers. Frequently merging is known as <em>continuous integration</em><em> (CI</em><em>)</em>. CI reduces risk because changes quickly propagate to all developers, making them less likely to diverge from each other significantly. <span epub:type="pagebreak" id="Page_126" title="126"/>Keeping developer codebases in sync prevents potential last-minute integration hurdles and surfaces bugs and incompatibilities early. As a trade-off, bugs in trunk will slow down all developers. To prevent breakages, fast automated tests are run to validate that tests pass before a branch is merged into trunk. Teams often have explicit processes for reacting to a broken trunk; the general expectation is that trunk should always be okay to release, and releases tend to be fairly frequent.</p>
			<p>
				In <em>feature branch–based development</em>, many developers simultaneously work on long-lived feature branches, each associated with a feature in the product. Because feature branches are long lived, developers need to <em>rebase</em>—to pull in changes from trunk—so the feature branch doesn’t diverge too far. Branches are kept stable by controlling when the rebasing occurs. When a release is being prepared, feature branches are pulled into the release branch. Release branches are tested, while feature branches may continue to evolve. Packages are built off stable release branches.</p>
			<p>Feature branch–based development is common when trunk is too unstable to release to users and developers want to avoid entering a feature freeze where feature commits are banned while trunk is stabilized. Feature branch–based development is more common in shrink-wrapped software where different customers run different versions; service-oriented systems usually use trunk-based development strategies.</p>
			<p>
				The most popular feature branch approach, described by Vincent Driesen in 2010, is called <em>Gitflow</em>. Gitflow uses a develop branch, hotfix branch, and release branch. The develop branch is used as the main branch that feature branches merge and rebase with. Release branches are cut from the develop branch when a release is prepared. Development continues on feature branches during release stabilization. Releases are stabilized and merged into trunk. Trunk is always considered to be production-ready, since it only ever contains stabilized releases. If trunk is unstable because it contains critical bugs, the bugs are addressed immediately with hotfixes instead of waiting for the normal release <span epub:type="pagebreak" id="Page_127" title="127"/>cadence. Hotfixes are applied to the hotfix branch and merged into both trunk and the develop branch.</p>
			<p>
				The Gitflow example in <a href="#figure8-3" id="figureanchor8-3">Figure 8-3</a> has two feature branches: feature-1 and feature-2. The feature branches are long lived; there are commits and merges back and forth with the develop branch. The release branch has two releases on it, both of which are pulled into trunk. A hotfix branch is used to fix a bug discovered on trunk. This hotfix has also been pulled into the develop branch so feature branches can pull it in.</p>
			<figure>
				<img alt="f08003" src="image_fi/501836c08/f08003.png"/>
				<figcaption>
					<p><a id="figure8-3">Figure 8-3</a>: Gitflow feature branch–based development</p>
				</figcaption>
			</figure>
			<p>Understand and follow your team’s branching strategy. Branching strategies define when changes go out, set testing expectations, define your bugfix options, and determine the number of versions your changes must be ported to. Many companies develop internal tools to help manage their VCS workflows. These scripts will branch, merge, and tag for you automatically.</p>
			<p>Stick with a trunk-based branching strategy unless you truly need long-lived feature branches. Managing feature branches gets complicated. In fact, Driesen has amended his original Gitflow blog post to discourage Gitflow use for software that can be continuously integrated and delivered.</p>
			<h2 id="h1-501836c08-0003"><span epub:type="pagebreak" id="Page_128" title="128"/>Build Phase</h2>
			<p class="BodyFirst">Software packages must be built before they’re delivered. Building software takes many steps: resolving and linking dependencies, running linters, compiling, testing, and, finally, packaging the software. Most build steps are also used during development and have been covered in Chapters 3 to 6. In this section, we’ll focus on a build’s output: packages.</p>
			<p>Packages are built for each release, so software doesn’t have to be built on each machine it runs on. Prebuilt packages are more consistent than having each machine compile and run code using its own environment and idiosyncratic combination of tools.</p>
			<p>Builds produce multiple packages if the software targets more than one platform or environment. Builds often produce packages for different operating systems, CPU architectures, or language runtimes. You’ve probably come across Linux package names like this:</p>
			<ul>
				<li><em>mysql-server-8.0_8.0.21-1_amd64.deb</em></li>
				<li><em>mysql-server-8.0_8.0.21-1_arm64.deb</em></li>
				<li><em>mysql-server-8.0_8.0.21-1_i386.deb</em></li>
			</ul>
			<p>These MySQL packages were all built for the same MySQL version, but each package is compiled for a different architecture: AMD, ARM, and Intel 386.</p>
			<p>
				Package content and structure varies. Packages can contain binary or source code, dependencies, configurations, release notes, documentation, media, licenses, checksums, and even virtual machine images. Libraries are packaged into language-specific formats such as <em>JARs</em>, <em>wheels</em>, and <em>crates</em>, most of which are just zipped directories arranged to match a spec. Application packages are usually built as zips, tarballs (<em><span epub:type="pagebreak" id="Page_129" title="129"/>.tar</em> files), or installation packages (<em>.dmg</em> or <em>setup.exe</em> files). Container and machine packages allow developers to build not only their software but the environment that it runs in.</p>
			<p>Packaging determines what software gets released. Bad packaging makes software difficult to deploy and debug. To avoid headaches, always version packages and split packages by resource type.</p>
			<h3 id="h2-501836c08-0001">Version Packages</h3>
			<p class="BodyFirst">Packages should be versioned and assigned a unique identifier. Unique identifiers help operators and developers tie a running application to specific source code, feature sets, and documentation. Without a version, you don’t know how a package will behave. If you’re unsure what versioning strategy to use, semantic versioning is a safe bet. Most packages follow some form of semantic versioning (see Chapter 5).</p>
			<h3 id="h2-501836c08-0002">Package Different Resources Separately</h3>
			<p class="BodyFirst">Software is not just code. Configuration, schemas, images, and language packs (translations) are all part of software. Different resources have different release cadences, different build times, and different testing and verification needs.</p>
			<p>Different resources should be packaged separately so they can be modified without having to rebuild the entire software package. Separate packaging lets each resource type have its own release lifecycle and can be rolled forward and backward independently.</p>
			<p>If you are shipping a complete application to a customer, the final package is then a meta-package: a package of packages. If you are shipping a web service or a self-upgrading application, you can ship packages separately, allowing configuration and translation to upgrade separately from code.</p>
			<aside epub:type="sidebar">
				<div class="top hr">
					<hr/>
				</div>
				<section class="box trade">
					<h2><span epub:type="pagebreak" id="Page_130" title="130"/>Python Packaging</h2>
					<p class="BoxBodyFirst">Python has a long and convoluted package management history, which makes it a great case study. The Python Packaging Authority (PyPA) has published <em>An Overview of Packaging for Python</em> (<a class="LinkURL" href="https://packaging.python.org/overview/">https://packaging.python.org/overview/</a>), which attempts to rationalize Python’s packaging options. Figures 8-4 and 8-5, created by Mahmoud Hashemi and included in PyPA’s overview, show Python’s packaging options.</p>
					<figure>
						<img alt="f08004" src="image_fi/501836c08/f08004.png"/>
						<figcaption>
							<p><a id="figure8-4">Figure 8-4</a>: Packaging options available to Python tools and libraries</p>
						</figcaption>
					</figure>
					<p>
						At the core of the Python library onion is a simple <em>.py</em> source file. The next level up, <em>sdist</em>, is a group of <em>.py</em> files—modules—that are compressed into <em>.tar.gz</em> archives. Though sdist packages include all Python code for a module, they don’t include compiled code that the package might need. That goes in the next level. In addition to raw Python code, <em>wheels</em> include compiled native libraries written in C, C++, Fortran, R, or any other language that the Python package might depend on.</p>
					<p><a href="#figure8-5" id="figureanchor8-5">Figure 8-5</a>, which shows application packaging options, is more layered because it includes language runtimes, machine virtualization, and hardware. <em>PEX packages</em> include Python code and all of its library dependencies. <em>Anaconda</em> provides an ecosystem to manage all installed libraries, not just those your application depends on. <em>Freezers</em> bundle not only libraries but also the Python runtime. <em>Images</em>, <em>containers</em>, and <em>virtual machines</em> package operating systems and disk images. In some cases, even <em>hardware</em> <span epub:type="pagebreak" id="Page_131" title="131"/>is a packaging method—shipping embedded systems hardware with application packages, system libraries, and the operating system all installed.</p>
					<figure>
						<img alt="f08005" src="image_fi/501836c08/f08005.png"/>
						<figcaption>
							<p><a id="figure8-5">Figure 8-5</a>: Packaging options available to Python applications</p>
						</figcaption>
					</figure>
					<p>While some of these packaging options are Python specific, many languages have similar patterns. Outer layers like machine and container images are language agnostic, and they map to each layer of the packaging stack you use. Understanding your packaging system’s assumptions and conventions will prevent deployment issues.</p>
					<div class="bottom hr">
						<hr/>
					</div>
				</section>
			</aside>
			<h2 id="h1-501836c08-0004">Release Phase</h2>
			<p class="BodyFirst">Release publication makes software available to users and enables deployment, the next phase of delivery. Release processes vary based on the type and size of software and user sophistication. An internal web service’s release process might be a single step: publishing a software package to a shared package repository. User-facing releases require artifact publication, documentation updates, release notes, and user communication.</p>
			<p><span epub:type="pagebreak" id="Page_132" title="132"/>Release management is the art of publishing stable, well-documented software at a predictable cadence. Proper release management makes for satisfied customers. Complex software with multiple teams committing to it will often have a release manager role. Release managers coordinate the process—tests, feature validation, security procedures, documentation, and so on.</p>
			<p>Understanding release management will help you work with your company’s release process effectively. Take ownership of your software’s publication by releasing immutable packages frequently. Be clear about release schedules, and publish changelogs and release notes along with new releases.</p>
			<h3 id="h2-501836c08-0003">Don’t Throw Releases Over the Fence</h3>
			<p class="BodyFirst">Take responsibility for your software’s release. Even if your organization has a release engineering or operations team, you should know how and when your software ends up in front of users. Release and operations teams can be of great help in setting up tools, advising on best practices, and automating drudgery and bookkeeping, but they do not know your code as well as you do. Ultimately, it’s your responsibility to ensure the software is appropriately deployed and well-functioning.</p>
			<p>Make sure your code works in test environments, keep track of release schedules, understand available options, and choose the right approach for your application. If only half of the application ships or a critical bug finds its way to production, you need to be involved in understanding how that happened and how to prevent it from happening again.</p>
			<h3 id="h2-501836c08-0004">Publish Packages to a Release Repository</h3>
			<p class="BodyFirst">Release packages are usually published to a package repository or simply tagged and housed in a VCS like Git. Though either practice can work, we encourage you to publish release packages to a purpose-built package repository.</p>
			<p>
				Release repositories serve release artifacts to end users. Docker Hub, GitHub Release Pages, PyPI, and Maven Central are all public repositories. <span epub:type="pagebreak" id="Page_133" title="133"/>Many companies also stage releases and publish internal software in private repositories.</p>
			<p>Package repositories make release artifacts (another word for a deployable package) available for deployment. Repositories also act as archives—previous release artifacts are accessible for debugging, rollback, and phased deployments. Package contents and metadata are indexed and browsable. Search support makes it easy to find dependencies, version information, and publication dates—invaluable information when troubleshooting. Release repositories are also built to meet deployment demands, handling thousands of users simultaneously downloading a new release.</p>
			<p>Version control systems like Git can be used as a release repository, too. Go, for example, uses this approach. Rather than a centralized package repository, Go dependencies are expressed through Git URIs (usually GitHub repositories).</p>
			<p>Version control systems work as release repositories, but they aren’t built for this purpose. VCSs don’t have as many useful search and deployment features. They are not built for large deployments and can get overwhelmed. Production deployments will be impacted if the same VCS machines are handling developer checkouts, tooling requests, and deployment requests. If you find yourself releasing from a VCS, make sure it can handle the load. Sharing one system for both release and development causes operational issues because deployment and development demands are very different. Developers make frequent, small commits and fewer checkouts. Deployments check out code, oftentimes from many machines at once. Deployment demands and developer tools can impact each other’s performance if they share the same repository or physical machines.</p>
			<h3 id="h2-501836c08-0005">Keep Releases Immutable</h3>
			<p class="BodyFirst">Once published, never change or overwrite a release package. Immutable releases guarantee that all application instances running a specific version will be identical, byte for byte. Identical release packages let <span epub:type="pagebreak" id="Page_134" title="134"/>developers reason about what code is in an application and how it should behave. Versioned packages that change are no better than unversioned packages.</p>
			<h3 id="h2-501836c08-0006">Release Frequently</h3>
			<p class="BodyFirst">Release as frequently as possible. Slow release cycles give a false sense of security: long periods between releases feel like ample time to test changes. In practice, rapid release cycles produce more stable software that is easier to repair when bugs are found. Fewer changes go out per cycle, so each release carries less risk. When a bug makes it to production, there are fewer changes to look at when debugging. Code is fresh in developers’ minds, which makes the bug easier and faster to fix.</p>
			<p>Software with automated package publication and deployment should be possible to release on every commit. For larger pieces of software that are harder to deploy, balance the frequency of release against the cost of release, deployment, maintenance, and users’ rate of adoption.</p>
			<h3 id="h2-501836c08-0007">Be Transparent About Release Schedules</h3>
			<p class="BodyFirst"><em>Release schedules</em> define how frequently software is released. Some projects have a predictable time-based schedule, releasing every quarter or year. Other projects release when specific features are completed (milestone-based releases) or simply when they feel like it. Internal systems often publish releases on every commit. Regardless of release style, be clear about release schedules. Publish schedules and notify users when new releases are published.</p>
			<h3 id="h2-501836c08-0008">Publish Changelogs and Release Notes</h3>
			<p class="BodyFirst">Changelogs and release notes help your users and your support team understand what is included in a release. <em>Changelogs</em> list every ticket that was fixed or commit that was made in a release. To automate changelog <span epub:type="pagebreak" id="Page_135" title="135"/>creation, track changes in commit messages or issue tracker labels. Release notes are a summary of the new features and bug fixes contained in a release. Changelogs are primarily read by the support and development team, while release notes are for users.</p>
			<aside epub:type="sidebar">
				<div class="top hr">
					<hr/>
				</div>
				<section class="box trade">
					<h2>The Apache Foundation Release Process</h2>
					<p class="BoxBodyFirst">The <em>Apache Software Foundation (ASF)</em> provides guidance and resources for open source projects. The ASF release process guidelines are thorough and a great place to look if you want to see a real-world example.</p>
					<p>A release manager is nominated to run each ASF project release. Releases include source and often binary packages. Release managers sign artifacts using a cryptographic key so users can verify that downloaded packages came from Apache. Checksums are also included to detect corruption. Releases include LICENSE and NOTICE files to declare various software licenses and copyrights, and all source files include license headers.</p>
					<p>
						Release managers then “cut” a release candidate. Packages are created, and members of a project management committee (PMC) vote to accept or reject the release candidate. PMC members are expected to validate the final artifacts before voting—check that checksums and signatures are valid and that the software passes acceptance tests. Once accepted, artifacts are posted to <a class="LinkURL" href="https://downloads.apache.org/">https://downloads.apache.org/</a>. After release, the release manager makes an announcement to Apache project mailing lists and updates the project website with release notes, changelogs, new documentation, and a blog post.</p>
					<p>
						Check out <a class="LinkURL" href="https://www.apache.org/dev/#releases/">https://www.apache.org/dev/#releases/</a> for the complete process, or see Apache Spark’s release page for a detailed playbook (<a class="LinkURL" href="https://spark.apache.org/release-process.html">https://spark.apache.org/release-process.html</a>).</p>
					<div class="bottom hr">
						<hr/>
					</div>
				</section>
			</aside>
			<h2 id="h1-501836c08-0005"><span epub:type="pagebreak" id="Page_136" title="136"/>Deployment Phase</h2>
			<p class="BodyFirst">Deploying software is the act of getting software packages where they need to be to run. Deployment mechanisms vary—deployment for mobile applications will differ from nuclear reactors—but the same underlying principles apply.</p>
			<h3 id="h2-501836c08-0009">Automate Deployments</h3>
			<p class="BodyFirst">Deploy software using scripts rather than manual steps. Automated deployments are more predictable because script behavior is reproducible and version controlled. Operators will be able to reason about deployment behavior when things go wrong.</p>
			<p>Scripts are less likely to make mistakes than humans, and they remove the temptation to make manual system tweaks, log in to machines, or manually copy packages during deployment. Mutating state on an existing machine is hard to get right. Two different deployments of the same software can lead to inconsistent behavior that’s tough to debug.</p>
			<p>
				Highly evolved automation leads to <em>continuous delivery</em>. With continuous delivery, humans are completely removed from deployment. Packaging, testing, release, deployment, and even rollout are all automated. Deployments run as frequently as desired—daily, hourly, or continuously. With continuous delivery, teams can deliver features to their users quickly and get feedback from them. Successful continuous delivery requires a commitment to automated testing (see Chapter 6), automated tooling, and a customer base that is able to absorb rapid changes.</p>
			<p>We recommend automating your deployments with off-the-shelf tools. Custom deployment scripts are easy to start with but grow unwieldy fast. Off-the-shelf solutions like Puppet, Salt, Ansible, and Terraform integrate with existing tooling and are purpose-built for deployment automation.</p>
			<p>
				You might find it impossible to fully automate your deployments—that’s okay. Deployments that depend on physical actions or third parties <span epub:type="pagebreak" id="Page_137" title="137"/>are sometimes impossible to fully automate. Just do your best to shrink the boundary of blocking tasks by automating everything around them.</p>
			<h3 id="h2-501836c08-0010">Make Deployments Atomic</h3>
			<p class="BodyFirst">Installation scripts often involve multiple steps. Do not assume each step succeeds on every execution. Machines run out of disk, get restarted at the wrong time, or have unexpected file permissions. A partially deployed application can cause future deployments to fail if scripts assume installation locations are empty. To avoid failed partial deployments, make deployment all or nothing (atomic). A partially deployed install should never partially replace the previous successful install, and it should be possible to install the same package to the same machine multiple times, even if previous installation attempts terminated abruptly.</p>
			<p>The easiest way to make deployments atomic is by installing software in a different location than the old version; don’t overwrite anything. Once packages are installed, a single shortcut or symbolic link can be flipped atomically. Installing packages in a new location has the added benefit that rollbacks become much easier—just point to the old version again. In some cases, different versions of the same software can be run simultaneously on the same machine!</p>
			<h3 id="h2-501836c08-0011">Deploy Applications Independently</h3>
			<p class="BodyFirst">Deployment ordering, when one application’s deployment requires the upgrade of another application first, is a common problem in software with many applications or services that communicate with each other. Developers ask operations to deploy one application before another or to bring several systems offline to perform the upgrade. Avoid deployment ordering requests. Ordering requirements slow down deployment since applications must wait for each other. Ordering also leads to conflicts where two applications depend on each other to be upgraded.</p>
			<p>
				Build applications that deploy independently. Software that doesn’t depend on deployment ordering must be backward and forward <span epub:type="pagebreak" id="Page_138" title="138"/>compatible. For example, communication protocols must continue to interoperate with newer and older versions. Compatibility is discussed more in Chapter 11.</p>
			<p>When a dependency is unavoidable, use the rollout techniques discussed next to safely deploy out of order. Deploying with your changes turned off and turning them on in a specific order later is faster and simpler than enforcing deployment ordering.</p>
			<aside epub:type="sidebar">
				<div class="top hr">
					<hr/>
				</div>
				<section class="box trade">
					<h2>Deployment by Wiki</h2>
					<p class="BoxBodyFirst">LinkedIn used to release its web services manually. Developers and site reliability engineers attended prerelease meetings to declare which services and configuration changes needed to be deployed, and a large wiki page recorded deployment information.</p>
					<p>Release managers would then break the services to be deployed into phases. Developers were not properly managing compatibility, so some services had to be rolled out before others. In some cases, services even called each other, creating a circular dependency. One deployment had more than 20 deployment phases.</p>
					<p>On the night of deployment, everyone logged in to an internet relay chat (IRC) channel to monitor the deployment. Site reliability engineers painstakingly copied artifacts to production machines, restarted services, and ran database migration scripts. Step by step, the deployment would go into the early morning hours.</p>
					<p>This was a terrible position to be in. Deployments were slow and costly because they had to be done manually. Automation beyond simple scripts was difficult. A failure to deploy one service prevented all downstream services from going out. Developers had to manually verify a deployment before a subsequent phase could progress. Deploys were aggravating, stressful, and tedious.</p>
					<p>
						LinkedIn eventually banned deployment ordering. Services had to support independent deployment or they weren’t allowed to ship. The ban created a lot of work—services, tests, tooling, <span epub:type="pagebreak" id="Page_139" title="139"/>and deployment processes all had to change—but deployments were completely automated. Developers were able to deliver software at their own cadence—multiple times per day if they desired. Site reliability engineers didn’t have to babysit deployments, and everyone got more sleep.</p>
					<div class="bottom hr">
						<hr/>
					</div>
				</section>
			</aside>
			<h2 id="h1-501836c08-0006">Rollout Phase</h2>
			<p class="BodyFirst">Once the new code is deployed, you can turn it on (roll it out). Switching everything to the new code at once is risky. No amount of testing will eliminate the potential for bugs, and rolling out code to all users at once can break things for everyone simultaneously. Instead, it’s best to roll changes out gradually and monitor health metrics.</p>
			<p>
				There are many rollout strategies: feature flags, circuit breakers, dark launches, canary deployments, and blue-green deployments. <em>Feature flags</em> allow you to control what percentage of users receive one code path versus another. <em>Circuit breakers</em> automatically switch code paths when there’s trouble. <em>Dark launches</em>, <em>canary deployments</em>, and <em>blue-green deployments</em> let you run multiple deployed versions of your software simultaneously. These patterns mitigate the risk of dangerous changes when used appropriately. Don’t go crazy using sophisticated rollout strategies, though—they add operational complexity. Operators and developers must support multiple code versions simultaneously and keep track of which features are toggled on or off. Keep fancy rollout strategies in your toolbox for bigger changes.</p>
			<h3 id="h2-501836c08-0012">Monitor Rollouts</h3>
			<p class="BodyFirst">Monitor health metrics such as error rates, response times, and resource consumption as new code is activated. Monitoring can be done manually or automatically. Advanced release pipelines automatically roll a change <span epub:type="pagebreak" id="Page_140" title="140"/>out to more users or roll the change back based on observed statistics. Even in a fully automated process, humans should keep an eye on the statistics and the rollout progress. More commonly, the decision to ramp up or down is still made by humans looking at logs and metrics.</p>
			<p>
				Determine ahead of time what the general health metrics are. <em>Service level indicators</em><em> (SLIs</em><em>)</em>, discussed more in Chapter 9, are metrics that indicate the health of your service; watch these for signs of degradation. Think about what you expect to see in metrics or logs that would tell you that your change is functioning correctly. Verify that what you expected to happen is actually happening.</p>
			<p>Remember, your job is not done when code is committed, and it’s still not done when the code is rolled out. Hold the champagne until metrics and logs are showing your changes running successfully.</p>
			<h3 id="h2-501836c08-0013">Ramp Up with Feature Flags</h3>
			<p class="BodyFirst">Feature flags (sometimes called <em>feature toggles</em> or <em>code splits</em>) allow developers to control when new code is released to users. Code is wrapped in an <code>if</code> statement that checks a flag (set by static configuration or from a dynamic service) to determine which branch of code should be run.</p>
			<p>Feature flags can be on-off Booleans, allow lists, percentage-based ramps, or even small functions. A Boolean will toggle the feature for all users. Allow lists turn on features for specific users. Percent-based ramps allow developers to slowly turn on the feature for larger swaths of users. It is common to start with company-owned test accounts and then ramp to a single customer before doing an incremental percent-based release. Functions dynamically determine flags based on input parameters, usually passed in at request time.</p>
			<p>
				Feature-flagged code that mutates state needs special attention. Databases are often not controlled by feature flags. New code and old code both interact with the same tables. Your code must be forward and backward compatible. State doesn’t go away when a feature is toggled off. If a feature is disabled for a user and then reenabled later, any state <span epub:type="pagebreak" id="Page_141" title="141"/>changes made while the feature was disabled still exist. Some changes, like database alterations, do not lend themselves to gradual rollouts and must be coordinated with extra care. Isolate feature-flag data if possible, test your code in all flagged states, and write scripts to clean rolled-back feature data.</p>
			<p>Make sure to clean up old feature flags that are fully ramped or no longer in use. Code littered with feature flags is difficult to reason about and can even cause bugs; for example, turning off a feature that’s been on for a long time can create havoc. Cleaning feature flags takes discipline. Create tickets to remove old flags in the future. Like refactoring, do cleanup incrementally and opportunistically.</p>
			<p>
				Feature flags are sometimes used for <em>A/B testing</em>, a technique for measuring user behavior with a new feature. A/B testing with feature flags is fine if users are grouped in a statistically meaningful way. Don’t try to A/B test with feature flags unless the flagging system creates test buckets for you, and run your experiment by a data scientist.</p>
			<h3 id="h2-501836c08-0014">Protect Code with Circuit Breakers</h3>
			<p class="BodyFirst">Most feature flags are controlled by humans. Circuit breakers are a special kind of feature flag that are controlled by operational events, like a spike in latency or exceptions. Circuit breakers have several unique characteristics: they’re binary (on/off), they’re permanent, and they’re automated.</p>
			<p>Circuit breakers are used to protect against performance degradation. If a latency threshold is exceeded, certain features can be automatically disabled or rate limited. Similarly, circuits can break if logs show anomalous behavior—exceptions or a jump in log verbosity.</p>
			<p>Circuit breakers also protect against permanent damage. Applications that take irreversible action, such as sending an email or transferring money out of a bank account, use circuit breakers when it’s unclear whether to proceed. Databases can also protect themselves by flipping to a read-only mode. Many databases and filesystems will do this automatically if they detect disk corruption.</p>
			<h3 id="h2-501836c08-0015"><span epub:type="pagebreak" id="Page_142" title="142"/>Ramp Service Versions in Parallel</h3>
			<p class="BodyFirst">It is possible to deploy new versions of web services alongside old versions. Packages can be co-located on the same machine or deployed on entirely new hardware. Parallel deployments let you ramp up slowly to mitigate risk and roll back fast if things go wrong. A percentage of incoming service calls are shifted from the old version to a new version using a switch similar to feature flags, but the switch is at the application entry point—usually a load balancer or proxy. Canary deployments and blue-green deployments are the two most common parallel deployment strategies.</p>
			<p>
				Canary deployments are used for services that process a lot of traffic and are deployed to a large number of instances. A new application version is first deployed to a limited set of machines. A small user subset is routed to the canary version. <a href="#figure8-6" id="figureanchor8-6">Figure 8-6</a> shows canary version 1.1 receiving 1 percent of inbound traffic. Like a canary in a coal mine (used to detect the presence of dangerous gases), the canary deployment is an early warning system for new application versions. Malfunctioning canaries impact only a small portion of users, who can be quickly routed back to an old version when errors are encountered.</p>
			<figure>
				<img alt="f08006" src="image_fi/501836c08/f08006.png"/>
				<figcaption>
					<p><a id="figure8-6">Figure 8-6</a>: In canary deployments, load balancers route a fraction of inbound traffic to a new deployment.</p>
				</figcaption>
			</figure>
			<p><span epub:type="pagebreak" id="Page_143" title="143"/><em>Blue-green deployments</em> run two different versions of the application: one active and one passive. <a href="#figure8-7" id="figureanchor8-7">Figure 8-7</a> shows a passive cluster (called <em>blue</em>) running version 1.0 and an active cluster (called <em>green</em>) running 1.1. The new version is deployed to the passive environment; when it is ready, traffic is flipped to the new version, and it becomes active, while the previous version becomes passive. Like canaries, if the new version has problems, the traffic can be flipped back. Unlike canaries, traffic is flipped atomically, and the blue and green environments are kept as identical as possible. In a cloud environment, the passive environment is usually destroyed once the release is considered stable.</p>
			<figure>
				<img alt="f08007" src="image_fi/501836c08/f08007.png"/>
				<figcaption>
					<p><a id="figure8-7">Figure 8-7</a>: In a blue-green deployment, service 1.0 is kept as a fallback in case service 1.1 malfunctions.</p>
				</figcaption>
			</figure>
			<p>Blue-green deployments are useful when traffic cannot be easily subset or when running different versions in parallel is not feasible. Unlike canaries, each environment must be able to handle 100 percent of user traffic. In disaster scenarios where all users need to be migrated off a misbehaving system, having the ability to get a parallel environment up and running quickly is invaluable.</p>
			<p>Like feature flags, parallel deployments that interact with database and cache state need special care. Both versions of the application must play nicely with each other. Backward and forward compatibility for all schemas must be enforced. This topic is discussed more in Chapter 11.</p>
			<h3 id="h2-501836c08-0016"><span epub:type="pagebreak" id="Page_144" title="144"/>Launch in Dark Mode</h3>
			<p class="BodyFirst">Feature flags, canary deployments, and blue-green releases roll out code to a subset of users and provide mitigation mechanisms when problems arise. Dark launches, sometimes called <em>traffic shadowing</em>, expose new code to real-life traffic without making it visible to end users at all. Even if dark code is bad, no user is impacted.</p>
			<p>Dark-launched software is still enabled, and the code is invoked, but the results are thrown away. Dark launches help developers and operators learn about their software in production with minimal user impact. Take advantage of dark launches whenever you are releasing particularly complex changes. This pattern is especially useful for validating system migrations.</p>
			<p>
				In a dark launch, an application proxy sits between the live traffic and the application. The proxy duplicates requests to the dark system. Responses to these identical requests from both systems are compared, and differences are recorded. Only the production system’s responses are sent to the users. This practice allows the operators to observe their service under real traffic without affecting the customers. The system is said to be in “dark reads” mode when only read traffic is sent to it and no data is modified. A system might be using the same datastore as the production system when operating in dark reads. It is said to be in a “dark writes” mode when writes are also sent to the system and it is using a completely independent datastore. <a href="#figure8-8" id="figureanchor8-8">Figure 8-8</a> shows both modes.</p>
			<p>Since operations are happening twice for the same request, once on the production system and once in the dark, you should take care to avoid duplication-related errors. Traffic to the dark system should be excluded from user analytics, and side effects like double billing have to be avoided. Requests can be marked for exclusion by modifying headers to highlight shadowed traffic. Some service meshes, such as Istio, and API gateways, such as Gloo, have built-in support for these operations.</p>
			<span epub:type="pagebreak" id="Page_145" title="145"/>
			<figure>
				<img alt="f08008" src="image_fi/501836c08/f08008.png"/>
				<figcaption>
					<p><a id="figure8-8">Figure 8-8</a>: Dark reads and dark writes</p>
				</figcaption>
			</figure>
			<p>You can do all kinds of cool things with dark launches. The open source tool Diffy, for example, sends dark traffic to three instances of the backend service: two running the production version of the code and one running the new release candidate. Diffy compares responses from a new version and an old version to identify all differences, and compares the responses from the two old versions to identify nondeterministic noise. This allows Diffy to automatically identify expected differences and remove false positives.</p>
			<aside epub:type="sidebar">
				<div class="top hr">
					<hr/>
				</div>
				<section class="box trade">
					<h2>We Want It Darker</h2>
					<p class="BoxBodyFirst">Through a series of organizational changes that happened during a rapid growth period, a key service at Twitter fell into disrepair. The service had accumulated a lot of technical debt, but additional feature requests kept coming in. Every change shipped to production was risky—the service was particularly tricky to test, and <span epub:type="pagebreak" id="Page_146" title="146"/>corner cases kept popping up. The engineer who had been toiling away at it all alone was overwhelmed. A lot of their time was spent debugging and fixing production problems. Frequent bugs slowed down the rate at which new changes could go out, which made the feature backlog grow, which increased pressure and made it ever harder to slow down and refactor—all while new features made the codebase more complex.</p>
					<p>
						Eventually, another org change took place, and both the engineer and the service joined Dmitriy’s team. After assessing the situation, the team tech lead declared the situation untenable: the team <em>had</em> to stop pumping out features and address the technical debt. The engineer maintaining the system had many ideas for improving the service, but even minor changes seemed to trigger unexpected problems in production.</p>
					<p>The team decided to focus on production stability first, and they did this with dark writes. They implemented a variant of the Diffy approach—comparing objects in a stream rather than HTTP responses—within two weeks. The service now had a safety net; the team could let a new version “bake” for as long as they wanted, analyzing any unexpected differences in the data it was producing. They could dark launch a change, have user traffic tell them about the edge cases, capture them, add tests and address the problem, and try again.</p>
					<p>The test suite grew, the development cycle accelerated, and the team had more confidence in releases. The engineer responsible for the service said it felt like a mountain was lifted off their shoulders. Improvements to the codebase could happen quickly; refactoring it, improving performance, and, yes, even adding new features. It was night and day—and dark writes were what allowed the sun to finally rise.</p>
					<div class="bottom hr">
						<hr/>
					</div>
				</section>
			</aside>
			<h2 id="h1-501836c08-0007"><span epub:type="pagebreak" id="Page_147" title="147"/>Do’s and Don’ts</h2>
			<table border="1" class="trade" id="tabular-501836c08-0001">
				<thead>
					<tr>
						<td><b>Do’s</b></td>
						<td><b>Don’ts</b></td>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td><b>DO</b> use trunk-based development and continuous integration if possible.<br/></td>
						<td><b>DON’T</b> publish unversioned packages.<br/></td>
					</tr>
					<tr>
						<td><b>DO</b> use VCS tools to manage branches.<br/></td>
						<td><b>DON’T </b>package configuration, schema, images, and language packs together.<br/></td>
					</tr>
					<tr>
						<td><b>DO</b> work with release and operations teams to create the right processes for your application.<br/></td>
						<td><b>DON’T</b> blindly rely on release managers and operations teams.<br/></td>
					</tr>
					<tr>
						<td><b>DO</b> publish release changelogs and release notes.<br/></td>
						<td><b>DON’T</b> use VCSs to distribute software.<br/></td>
					</tr>
					<tr>
						<td><b>DO</b> notify users when a release is published.<br/></td>
						<td><b>DON’T</b> change release packages once they’re published.<br/></td>
					</tr>
					<tr>
						<td><b>DO</b> use off-the-shelf tooling to automate deployment.<br/></td>
						<td><b>DON’T</b> roll out without monitoring the results.<br/></td>
					</tr>
					<tr>
						<td><b>DO</b> roll changes out gradually with feature flags.<br/></td>
						<td><b>DON’T</b> depend on deployment ordering.<br/></td>
					</tr>
					<tr>
						<td><b>DO</b> use circuit breakers to prevent applications from causing major damage.<br/></td>
						<td/>
					</tr>
					<tr>
						<td><b>DO</b> use traffic shadowing and dark launches for major changes.<br/></td>
						<td/>
					</tr>
				</tbody>
			</table>
			<h2 id="h1-501836c08-0008">Level Up</h2>
			<p class="BodyFirst"><em>Git for Teams</em>, by Emma Jane Hogbin Westby (O’Reilly Media, 2015), gives more detail on branching strategies. This is a great foundational book and is valuable even if you’re not working with Git.</p>
			<p><span epub:type="pagebreak" id="Page_148" title="148"/>Jez Humble and David Farley’s<em> Continuous Delivery</em> (Addison-Wesley Professional, 2010) is a deep dive into the topics covered in this chapter. If you spend a lot of time with release engineering, read this book. For a shorter read, Google’s <em>Site Reliability Engineering</em> (O’Reilly Media, 2016) covers release engineering in Chapter 8.</p>
			<p>
				Michael T. Nygard’s <em>Release It!</em> (Pragmatic Bookshelf, 2018) is an expansive look at operations topics that our book discusses in Chapters 8 and 9. Nygard’s book also spends significant time on software design patterns for operations, a topic we discuss in Chapter 4. We highly recommend <em>Release It!</em> for developers working on web services.</p>
			<p>
				Amazon’s <em>Builder’s Library</em> is also a great free resource for delivery best practices. Located at <a class="LinkURL" href="https://aws.amazon.com/builders-library/">https://aws.amazon.com/builders-library/</a>, the library has posts on continuous delivery, automated deployment, and rollbacks.</p>
			<aside class="endnote" epub:type="rearnote">
</aside>
		</section>
	</body>
</html>