- en: '**11**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**RECORD, UNION, AND CLASS DATA TYPES**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/common01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Records, unions, and classes are popular composite data types found in many
    modern programming languages. Incorrectly used, these data types can have a very
    negative impact on the performance of your software. Correctly used, however,
    they can actually improve the performance of your applications (compared with
    using alternative data structures). In this chapter we’ll explore how you can
    make the most of these data types to maximize the efficiency of your programs.
    The topics this chapter covers include:'
  prefs: []
  type: TYPE_NORMAL
- en: Definitions for the record, union, and class data types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Declaration syntax for records, unions, and classes in various languages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Record variables and instantiation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compile-time initialization of records
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory representation of record, union, and class data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using records to improve runtime memory performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamic record types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Namespaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variant data types and their implementation as a union
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Virtual method tables for classes and their implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inheritance and polymorphism in classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance cost associated with classes and objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we get into the details of how you can implement these data types to
    produce code that is more efficient, easier to read, and easier to maintain, let’s
    begin with some definitions.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1 Records**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Pascal *record* and the C/C++ *structure* are terms used to describe comparable
    composite data structures. Language design textbooks sometimes refer to these
    types as *Cartesian products* or *tuples*. The Pascal terminology is probably
    best, because it avoids confusion with the term *data structure*, so we’ll use
    *record* here. Regardless of what you call them, records are a great tool for
    organizing your application data, and a good understanding of how languages implement
    them will help you write more efficient code.
  prefs: []
  type: TYPE_NORMAL
- en: An array is *homogeneous*, meaning that its elements are all of the same type.
    A record, on the other hand, is *heterogeneous*—its elements can have differing
    types. The purpose of a record is to let you encapsulate logically related values
    into a single object.
  prefs: []
  type: TYPE_NORMAL
- en: Arrays let you select a particular element via an integer index. With records,
    you must select an element, known as a *field*, by the field’s name. Each of the
    field names within the record must be unique; that is, you can’t use the same
    name more than once in the same record. However, all field names are local to
    their record, so you may reuse those names elsewhere in the program.^([1](footnotes.xhtml#ch11fn1))
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.1 Declaring Records in Various Languages**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before discussing how various languages implement record data types, we’ll take
    a quick look at the declaration syntax for some of them, including Pascal, C/C++/C#,
    Swift, and HLA.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.1.1 Record Declarations in Pascal/Delphi**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Here’s a typical record declaration for a `student` data type in Pascal/Delphi:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: A record declaration consists of the keyword `record`, followed by a sequence
    of *field declarations*, and ending with the keyword `end`. The field declarations
    are syntactically identical to variable declarations in the Pascal language.
  prefs: []
  type: TYPE_NORMAL
- en: Many Pascal compilers allocate all of the fields in contiguous memory locations.
    This means that Pascal will reserve the first 65 bytes for the name,^([2](footnotes.xhtml#ch11fn2))
    the next 2 bytes hold the major code, the next 12 bytes the Social Security number,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.1.2 Record Declarations in C/C++**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Here’s the same declaration in C/C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Record (structure) declarations in C/C++ begin with the keyword `typedef` followed
    by the `struct` keyword, a set of *field declarations* enclosed by a pair of braces,
    and a structure name. As with Pascal, most C/C++ compilers assign memory offsets
    to the fields in the order of their declaration in the record.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.1.3 Record Declarations in C#**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'C# structure declarations are very similar to C/C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Record (structure) declarations in C# begin with the keyword `struct`, a structure
    name, and a set of *field declarations* enclosed by a pair of braces. As with
    Pascal, most C# compilers assign memory offsets to the fields in the order of
    their declaration in the record.
  prefs: []
  type: TYPE_NORMAL
- en: This example defines the `Name` and `SSN` fields as arrays of characters in
    order to match the other record declaration examples in this chapter. In an actual
    C# program you’d probably want to use the `string` data type rather than an array
    of characters for these fields. However, keep in mind that C# uses dynamically
    allocated arrays; thus, the memory layout for the C# structure will differ from
    those for C/C++, Pascal, and HLA.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.1.4 Record Declarations in Java**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Java doesn’t support a pure record, but class declarations with only data members
    serve the same purpose (see the section “Class Declarations in C# and Java” on
    [page 366](ch11.xhtml#page_366)).
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.1.5 Record Declarations in HLA**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In HLA, you can create record types using the `record`/`endrecord` declaration.
    You would encode the record from the previous sections as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the HLA declaration is very similar to the Pascal declaration.
    Note that, to stay consistent with the Pascal declaration, this example uses character
    arrays rather than strings for the `sName` and `SSN` (Social Security number)
    fields. In a typical HLA record declaration, you’d probably use a `string` type
    for at least the `sName` field (keeping in mind that a string variable is only
    a 4-byte pointer).
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.1.6 Record (Tuple) Declarations in Swift**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Although Swift does not support the concept of a record, you can simulate one
    using a Swift *tuple*. Tuples are a useful construct for creating a composite/aggregate
    data type without the overhead of a class. (Note, however, that Swift does not
    store record/tuple elements in memory in the same manner as other programming
    languages.)
  prefs: []
  type: TYPE_NORMAL
- en: 'A Swift tuple is simply a list of values. Syntactically, a tuple takes the
    following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The types of the values within the tuple don’t have to be identical.
  prefs: []
  type: TYPE_NORMAL
- en: 'Swift typically uses tuples to return multiple values from functions. Consider
    the following short Swift code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The `returns3Ints` function returns three values (`1`, `2`, and `3`). The statement
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: stores those three integer values into `r1`, `r2`, and `r3`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also assign tuples to a single variable and access “fields” of the
    tuple using integer indexes as the field names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Using field names like `.0` is inadvisable, as it results in hard-to-maintain
    code. You can create records out of tuples, but referring to the fields using
    integer indices is rarely suitable in real-world programs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, Swift allows you to assign labels to tuple fields and refer to
    those fields by the label name rather than an integer index, via the `typealias`
    keyword:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that the storage of the tuple in memory might not map to the same
    layout as a record or structure in other languages. Like arrays in Swift, tuples
    are an opaque type, without a guaranteed definition of how Swift will store them
    in memory.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.2 Instantiating a Record**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Generally, a record declaration does not reserve storage for a record object;
    instead, it specifies a data type that you can use as a template when declaring
    record variables. *Instantiation* refers to this process of using a record template,
    or type, to create a record variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the HLA type declaration for `student` from the previous section.
    This type declaration doesn’t allocate any storage for a record variable; it simply
    provides the structure for the record object to use. To create an actual `student`
    variable, you must set aside some storage for the record variable, either at compile
    time or at runtime. In HLA, you can set aside storage for a `student` object at
    compile time by using variable declarations such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `var` declaration tells HLA to reserve sufficient storage for a `student`
    object in the current activation record when the program enters the current procedure.
    The `static` statement tells HLA to reserve sufficient storage for a `student`
    object in the static data section; this is done at compilation time.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also allocate storage for a record object dynamically using memory
    allocation functions. For example, in the C language you can use `malloc()`to
    allocate storage for a `student` object like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'A record is simply a collection of (otherwise) unrelated variables. So why
    not just create separate variables? In C, for example, why not just write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: There are several reasons why this approach isn’t ideal. On the software engineering
    side of things, there are maintenance issues to consider. For example, what happens
    if you create several sets of `student` variables and then decide you want to
    add a field? Now you’ve got to go back and edit every set of declarations you’ve
    created—not a pretty sight. With structure/record declarations, however, you only
    need to make one change to the type declaration, and all the variable declarations
    automatically get the new field. Also, consider what happens if you want to create
    an array of `student` objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Software engineering issues aside, collecting disparate fields into a record
    is a good idea for efficiency reasons. Many compilers allow you to treat a whole
    record as a single object for the purposes of assignment, parameter passing, and
    so on. In Pascal, for example, if you have two variables, `s1` and `s2`, of type
    `student`, you can assign all the values of one `student` object to the other
    with a single assignment statement like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Not only is this more convenient than assigning the individual fields, but
    the compiler can often generate better code by using a block move operation. Consider
    the following C++ code and the associated x86 assembly language output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the relevant portion of the x86-64 assembly code that Microsoft’s Visual
    C++ compiler produces (with the `/O2` optimization option):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The important thing to note in this example is that the Visual C++ compiler
    emits a sequence of `movaps` and `movups` instructions whenever you assign whole
    structures. However, it may degenerate to a sequence of individual `mov` instructions
    for each of the fields when you do a field-by-field assignment of two structures.
    Likewise, if you had not encapsulated all the fields into a structure, then assigning
    the variables associated with your “structure” via a block copy operation wouldn’t
    have been possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Combining fields together into a record has many advantages, including:'
  prefs: []
  type: TYPE_NORMAL
- en: It is much easier to maintain the record structure (that is, add, remove, rename,
    and change fields).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compilers can do additional type and semantic checking on records, thereby helping
    catch logic errors in your programs when you use a record improperly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compilers can treat records as monolithic objects, generating more efficient
    code (for example, `movsd` and `movaps` instructions) than they can when working
    with individual field variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most compilers respect the order of declaration in a record, allocating successive
    fields to consecutive memory locations. This is important when interfacing data
    structures from two different languages. There is no guarantee for the organization
    of separate variables in memory in most languages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use records to improve cache memory performance and reduce virtual memory
    thrashing (as you’ll soon see).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Records can contain pointer fields that contain the address of other (like-typed)
    record objects. This isn’t possible when you use bulk variables in memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You’ll see some other advantages of records in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.3 Initializing Record Data at Compile Time**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Some languages—for example, C/C++ and HLA—allow you to initialize record variables
    at compile time. For static objects, this spares your application the code and
    time needed to manually initialize each field of a record. For example, consider
    the following C code, which provides initializers for both static and automatic
    structure variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'When compiled with Visual C++ using the `/O2` and `/Fa` command-line options,
    this example emits the following x86-64 machine code (edited manually to eliminate
    irrelevant output):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Look carefully at the machine code the compiler emits for the initialization
    of the `autoStruct` variable. In contrast to static initialization, the compiler
    cannot initialize memory at compile time because it doesn’t know the addresses
    of the various fields of the automatic record that the system allocates at runtime.
    Unfortunately, this particular compiler generates a field-by-field sequence of
    assignments to initialize the fields of the structure. While this is relatively
    fast, it can consume quite a bit of memory, especially if you’ve got a large structure.
    If you want to reduce the size of the automatic structure variable initialization,
    one possibility is to create an initialized static structure and assign it to
    the automatic variable upon each entry into the function in which you’ve declared
    the automatic variable. Consider the following C++ and 80x86 assembly code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the corresponding x86-64 assembly code that Visual C++ emits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in this assembly code, it takes only a four-instruction sequence
    to copy the data from the statically initialized record into the automatically
    allocated record. This code is quite a bit shorter. Note, however, that it isn’t
    necessarily faster. Copying data from one structure to another involves memory-to-memory
    moves, which can be quite slow if all the memory locations are not currently cached.
    Moving immediate constants directly to the individual fields is often faster,
    though it may take many instructions to accomplish this.
  prefs: []
  type: TYPE_NORMAL
- en: This example should remind you that if you attach an initializer to an automatic
    variable, the compiler will have to emit some code to handle that initialization
    at runtime. Unless your variables need to be reinitialized on each entry to your
    function, consider using static record objects instead.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.4 Storing Records in Memory**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The following Pascal example demonstrates a typical `student` record variable
    declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Given the earlier declaration for the Pascal `student` data type, this allocates
    81 bytes of storage laid out in memory as shown in [Figure 11-1](ch11.xhtml#ch11fig1).
    If the label `John` corresponds to the *base address* of this record, then the
    `Name` field is at offset `John+0`, the `Major` field is at offset `John+65`,
    the `SSN` field is at offset `John+67`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-1: Student data structure storage in memory*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most programming languages let you refer to a record field by its name rather
    than by its numeric offset into the record (indeed, only a few low-end assemblers
    require that you reference fields by numeric offset; it’s safe to say that such
    assemblers don’t really support records). The typical syntax for a field access
    uses the *dot operator* to select a field from a record variable. Given the variable
    `John` from the previous example, here’s how you could access various fields in
    this record:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 11-1](ch11.xhtml#ch11fig1) suggests that all fields of a record appear
    in memory in the order of their declaration, and this is usually the case (although
    in theory, a compiler can freely place the fields anywhere in memory that it chooses).
    The first field usually appears at the lowest address in the record, the second
    field appears at the next-highest address, the third field follows the second
    field in memory, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 11-1](ch11.xhtml#ch11fig1) also suggests that compilers pack the fields
    into adjacent memory locations with no gaps between the fields. While this is
    true for many languages, it’s certainly not the most common memory organization
    for a record. For performance reasons, most compilers align the fields of a record
    on appropriate memory boundaries. The exact details vary by language, compiler
    implementation, and CPU, but a typical compiler places fields at an offset within
    the record’s storage area that is “natural” for that particular field’s data type.
    On the 80x86, for example, compilers that follow the Intel ABI (application binary
    interface) allocate single-byte objects at any offset within the record, words
    only at even offsets, and double word or larger objects on double word boundaries.
    Although not all 80x86 compilers support the Intel ABI, most do, which allows
    records to be shared among functions and procedures written in different languages
    on the 80x86\. Other CPU manufacturers provide their own ABI for their processors,
    and programs that adhere to an ABI can share binary data at runtime with other
    programs that adhere to the same ABI.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to aligning the fields of a record at reasonable offset boundaries,
    most compilers also ensure that the length of the entire record is a multiple
    of 2, 4, 8, or 16 bytes. As you’ve seen in previous chapters, they accomplish
    this by adding padding bytes at the end of the record to fill out the record’s
    size. This ensures that the record’s length is a multiple of the largest scalar
    (nonarray/nonrecord) object in the record.^([3](footnotes.xhtml#ch11fn3)) For
    example, if a record has fields whose lengths are 1, 2, 4, and 8 bytes long, then
    an 80x86 compiler will generally pad the record’s length so that it is a multiple
    of 8\. This allows you to create an array of records and be assured that each
    record in the array starts at a reasonable address in memory.
  prefs: []
  type: TYPE_NORMAL
- en: Although some CPUs don’t allow access to objects in memory at misaligned addresses,
    many compilers allow you to disable the automatic alignment of fields within a
    record. Generally, the compiler will have an option you can use to globally disable
    this feature. Many of these compilers also provide a `pragma`, `alignas`, or `packed`
    keyword that lets you turn off field alignment on a record-by-record basis. Disabling
    the automatic field alignment feature may allow you to save some memory by eliminating
    the padding bytes between the fields (and at the end of the record)—again, provided
    that field misalignment is acceptable on your CPU. The cost, of course, is that
    the program may run a little more slowly when it needs to access misaligned values
    in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'One reason to use a packed record is to gain manual control over the alignment
    of the record’s fields. For example, suppose you have a couple of functions written
    in two different languages, and both of these functions need to access some data
    in a record. Further, suppose that the two compilers for these functions do not
    use the same field alignment algorithm. A record declaration like the following
    (in Pascal) may not be compatible with the way both functions access the record
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The problem here is that the first compiler could use the offsets 0, 2, and
    4 for the `bField`, `wField`, and `dField` fields, respectively, while the second
    compiler might use offsets 0, 4, and 8.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose, however, that the first compiler allows you to specify the `packed`
    keyword before the `record` keyword, causing the compiler to store each field
    immediately following the previous one. Although using the `packed` keyword doesn’t
    make the records compatible with both functions, it does allow you to manually
    add padding fields to the record declaration, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Manually adding padding can make maintaining your code a real chore. However,
    if incompatible compilers need to share data, it’s a trick worth knowing. For
    the exact details on packed records, consult your language’s reference manual.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.5 Using Records to Improve Memory Performance**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For someone who wants to write great code, records provide an important benefit:
    the ability to control variable placement in memory. This capability enables you
    to better control cache usage by those variables, which in turn can help you write
    code that executes much faster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider, for a moment, the following C global/static variable declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'You might think that the compiler would allocate storage for these variables
    in consecutive memory locations. However, few (if any) languages guarantee this.
    C certainly doesn’t and, in fact, C compilers like Microsoft’s Visual C++ compiler
    don’t allocate these variables in sequential memory locations. Consider the Visual
    C++ assembly language output for the preceding variable declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Even if you don’t understand the purpose of all the directives here, it’s clear
    that Visual C++ has rearranged all the variable declarations in memory. Therefore,
    you cannot count on adjacent declarations in your source file yielding adjacent
    storage cells in memory. Indeed, there is nothing to stop the compiler from allocating
    one or more variables in a machine register.
  prefs: []
  type: TYPE_NORMAL
- en: You might be wondering why you’d be concerned about the placement of variables
    in memory. After all, one of the main reasons for using named variables as an
    abstraction for memory is to avoid having to think about low-level memory allocation
    strategies. There are times, however, when being able to control variable placement
    in memory is important. For example, if you want to maximize program performance,
    you should try to place sets of variables that you access together in adjacent
    memory locations. This way, those variables will tend to sit in the same cache
    line, and you won’t pay a heavy latency cost for accessing variables not currently
    held in the cache. Furthermore, by placing variables you use together adjacent
    to one another in memory, you’ll use fewer cache lines and, therefore, have less
    thrashing.
  prefs: []
  type: TYPE_NORMAL
- en: Universally, programming languages that support the traditional notion of records
    maintain the fields of their records in adjacent memory locations; therefore,
    if you have some reason to keep different variables in adjacent memory locations
    (so that they share cache lines as much as possible), putting your variables into
    a record is a reasonable approach. However, the key word here is *traditional*—if
    your language uses a dynamic record type, you’ll need a different approach.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.1.6 Working with Dynamic Record Types and Databases**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Some dynamic languages employ a dynamic type system, and object types can change
    at runtime. We’ll explore dynamic types a little later in this chapter, but suffice
    it to say that if your language uses a dynamic type record structure, then all
    bets are off concerning the placement of fields in memory. Chances are pretty
    good that the fields will not be sitting in adjacent memory locations. Then again,
    if you’re using a dynamic language, the fact that you’re sacrificing a little
    performance because you’re not getting maximal benefit from your cache will be
    the least of your worries.
  prefs: []
  type: TYPE_NORMAL
- en: A classic example of a dynamic record is the data you read from a database engine.
    The engine itself has no preconceived (that is, compile time) notion of what structure
    the database records will take. Instead, the database itself provides metadata
    that tells the database the record structure. The database engine reads this metadata
    from the database, uses it to organize the field data into a single record, and
    then returns this data to the database application. In a dynamic language, the
    actual field data is typically spread out across memory, and the database application
    references that data indirectly.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, if you’re using a dynamic language, you have much greater concerns
    about performance than the placement or organization of your record fields in
    memory. Dynamic languages, such as database engines, execute many instructions
    processing the metadata (or otherwise determining the type of their data operands),
    so losing a few cycles to cache thrashing here and there is unlikely to matter
    much. For more information about the overhead associated with a dynamic typing
    system, see “Variant Types” on [page 356](ch11.xhtml#page_356).
  prefs: []
  type: TYPE_NORMAL
- en: '**11.2 Discriminant Unions**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A discriminant union (or just union) is very similar to a record. A *discriminant*
    is something that distinguishes or separates items in a quantity. In the case
    of a discriminant union, it means that different field names are used to distinguish
    the various ways that a given memory location’s data type can be interpreted.
  prefs: []
  type: TYPE_NORMAL
- en: Like records, unions in typical languages that support them have fields that
    you access using dot notation. In fact, in many languages, about the only syntactical
    difference between records and unions is the use of the keyword `union` rather
    than `record` or `struct`. Semantically, however, there’s a big difference between
    a record and a union. In a record, each field has its own offset from the base
    address of the record, and the fields do not overlap. In a union, however, all
    fields have the same offset, 0, and all the fields of the union overlap. As a
    result, the size of a record is the sum of the sizes of all the fields (plus,
    possibly, some padding bytes), whereas a union’s size is the size of its largest
    field (plus, possibly, some padding bytes at the end).
  prefs: []
  type: TYPE_NORMAL
- en: Because the fields of a union overlap, changing the value of one field changes
    the values of all the other fields as well. This typically means that the use
    of a union’s field is mutually exclusive—that is, you can use only one field at
    any given time. As a result, unions aren’t as generally applicable as records,
    but they still have many uses. As you’ll see later in this chapter, you can use
    unions to save memory by reusing memory for different values, to coerce data types,
    and to create variant data types. For the most part, though, programs use unions
    to share memory between different variable objects whose use never overlaps (that
    is, the variables’ use is mutually exclusive).
  prefs: []
  type: TYPE_NORMAL
- en: For example, imagine that you have a 32-bit double word variable, and you find
    yourself constantly extracting out the LO or the HO 16-bit word. In most HLLs,
    this would require a 32-bit read and then an AND operation to mask out the unwanted
    word. If that wasn’t enough, if you want the HO word, you have to then shift the
    result to the right 16 bits. With a union, you can overlay the 32-bit double word
    and a two-element 16-bit word array and access the words directly. You’ll see
    how to do this in “Using Unions in Other Ways” on [page 355](ch11.xhtml#page_355).
  prefs: []
  type: TYPE_NORMAL
- en: '**11.2.1 Declaring Unions in Various Languages**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The C/C++, Pascal, and HLA languages provide discriminant union type declarations.
    The Java language doesn’t provide the equivalent of a union. Swift has a special
    version of the `Enum` declaration that provides variant record capabilities, but
    it does not store members of such declarations at the same address in memory.
    So, for the purposes of this discussion, we’ll assume Swift doesn’t provide union
    declarations.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.2.1.1 Union Declarations in C/C++**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Here’s an example of a union declaration in C/C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Assuming the C/C++ compiler in use allocates 4 bytes for unsigned integers,
    the size of a `unionType` object will be 4 bytes (because all three fields are
    4-byte objects).
  prefs: []
  type: TYPE_NORMAL
- en: '**11.2.1.2 Union Declarations in Pascal/Delphi**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Pascal and Delphi use *case-variant records* to create a discriminant union.
    The syntax for a case-variant record is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The tag item can be either a type identifier (such as `boolean`, `char`, or
    some user-defined type), or it can be a field declaration of the form `identifier`:type.
    If it takes the latter form, then identifier becomes another field of the record
    (and not a member of the variant section) and has the specified type. In addition,
    the Pascal compiler could generate code that raises an exception whenever the
    application attempts to access any of the variant fields except the one allowed
    by the value of the tag field. In practice, almost no Pascal compilers do this
    check. Still, keep in mind that the Pascal language standard suggests that compilers
    *should* do it, so some compilers might.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of two different case-variant record declarations in Pascal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the `hasTagRecord` union, a Pascal case-variant record does
    not require any normal record fields. This is true even if you do not have a tag
    field.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.2.1.3 Union Declarations in HLA**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'HLA supports unions as well. Here’s a typical union declaration in HLA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '**11.2.2 Storing Unions in Memory**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Remember that the big difference between a union and a record is the fact that
    records allocate storage for each field at different offsets, whereas unions overlay
    each of the fields at the same offset in memory. For example, consider the following
    HLA record and union declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: If you declare a variable, say `n`, of type `numericRec`, you access the fields
    as `n.i`, `n.u`, and `n.r`, exactly as though you had declared the `n` variable
    to be type `numericUnion`. However, the size of a `numericRec` object is 16 bytes,
    because the record contains two double word fields and a quad word (`real64`)
    field. The size of a `numericUnion` variable, however, is 8 bytes. [Figure 11-2](ch11.xhtml#ch11fig2)
    shows the memory arrangement of the `i`, `u`, and `r` fields in both the record
    and union.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-2: Layout of a union versus a record variable*'
  prefs: []
  type: TYPE_NORMAL
- en: '**11.2.3 Using Unions in Other Ways**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In addition to conserving memory, programmers often use unions to create aliases
    in their code. An *alias* is a different name for the same memory object. Although
    aliases are often a source of confusion in a program and should be used sparingly,
    sometimes using them is convenient. For example, in some section of your program
    you might need to constantly use type coercion to refer to a particular object.
    To avoid this, you could use a union variable with each field representing one
    of the different types you want to use for the object. Consider the following
    HLA code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'With a declaration like this one, you can manipulate an `uns32` object by accessing
    `v.u`. If, at some point, you need to treat the LO byte of this `uns32` variable
    as a character, you can do so by simply accessing the `v.c` variable, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Another common practice is to use unions to disassemble a larger object into
    its constituent bytes. Consider the following C/C++ code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Although composing and decomposing data types this way is a useful trick to
    employ every now and then, keep in mind that this code isn’t portable. The HO
    and LO bytes of a multibyte object appear at different addresses on big endian
    versus little endian machines. As a result, this code fragment works fine on little
    endian machines, but fails to display the correct bytes on big endian CPUs. Any
    time you use unions to decompose larger objects, you should be aware of this limitation.
    Still, this trick is usually much more efficient than using shift lefts, shift
    rights, and AND operations, so you’ll see it used quite a bit.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.3 Variant Types**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A variant object has a *dynamic* type—that is, the object’s type can vary at
    runtime. This spares the programmer from having to decide on a data type when
    designing the program and allows the end user to enter whatever data they like
    as the program operates. Programs written in a dynamically typed language are
    typically far more compact than languages written in a traditional statically
    typed language. This makes dynamically typed languages very popular for rapid
    prototyping, interpretive, and very high-level languages. A few mainstream languages
    (including Visual Basic and Delphi) also support variant types. In this section,
    we’ll look at how compilers implement variant types and discuss the efficiency
    costs associated with them.
  prefs: []
  type: TYPE_NORMAL
- en: To implement a variant type, most languages use a union to reserve storage for
    all the different types the variant object supports. This means that a variant
    object will consume at least as much space as the largest primitive data type
    it supports. In addition to the storage required to keep its value, the variant
    object will also need storage to keep track of its current type. If the language
    allows variants to assume an array type, even more storage may be necessary to
    specify how many elements are in the array (or the bounds on each dimension, if
    the language allows multidimensional variant arrays). The bottom line is that
    a variant consumes a fair amount of memory, even if the actual data consumes only
    a single byte.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perhaps the best way to illustrate how a variant data type works is to implement
    one manually. Consider the following Delphi case-variant record declaration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In this record, elements will contain the number of elements in the array if
    the object is a single-dimensional array (this particular data structure does
    not support multidimensional arrays). If, on the other hand, the object is a scalar
    variable, then the elements value will be irrelevant. The `theType` field specifies
    the current type of the object. If this field contains one of the enumerated constants
    `vBoolean`, `vChar`, `vInteger`, `vReal`, or `vString`, the object is a scalar
    variable; if it contains one of the constants `paBoolean`, `paChar`, `paInteger`,
    `paReal`, or `paString`, then the object is a single-dimensional array of the
    specified type.
  prefs: []
  type: TYPE_NORMAL
- en: The fields in the case-variant section of the Pascal record hold the variant’s
    value if it is a scalar object, or they hold a pointer to an array of objects
    if the variant is an array object. Technically, Pascal requires that you specify
    the bounds of the array in its declaration. But fortunately, Delphi lets you turn
    off bounds checking (as well as allowing you to allocate memory for an array of
    arbitrary size), hence the dummy array bounds in this example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Manipulating two variant objects that have the same type is easy. For example,
    suppose you want to add two variant values together. First, you’d determine the
    current type of both objects and whether the addition operation even makes sense
    for the data types.^([4](footnotes.xhtml#ch11fn4)) Once you’ve decided that the
    addition operation is reasonable, it’s easy enough to use a `case` (or `switch`)
    statement based on the tag field of the two variant types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'If the left and right operands are not the same type, then the operation is
    a bit more complex. Some mixed-type operations are legal. For example, adding
    an integer operand and a real operand together is reasonable (it produces a real
    type result in most languages). Other operations may be legal only if the values
    of the operands can be added. For example, it’s reasonable to add a string and
    an integer together if the string happens to contain a string of digits that could
    be converted to an integer prior to the addition (likewise for string and real
    operands). What is needed here is a two-dimensional `case`/`switch` statement.
    Unfortunately, outside of assembly language, you won’t find such a creature.^([5](footnotes.xhtml#ch11fn5))
    However, you can simulate one easily enough by nesting `case`/`switch` statements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Once you expand all the code alluded to in these comments, you’ll have quite
    a few statements. And this is just for one operator! Obviously, it takes considerable
    work to implement all the basic arithmetic, string, character, and Boolean operations—and
    expanding this code inline whenever you need to add two variant values together
    is out of the question. Generally, you’d write a function like `vAdd()` that would
    accept two variant parameters and produce a variant result (or raise some sort
    of exception if the addition of the operands is illegal).
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway here is not that the code to do variant addition is long—the real
    problem is performance. It’s not at all unreasonable to expect a variant addition
    operation to require dozens, if not hundreds, of machine instructions to accomplish.
    By contrast, it takes only two or three machine instructions to add two integer
    or floating-point values together. Therefore, you can expect operations involving
    variant objects to run approximately one to two orders of magnitude slower than
    the standard operations. This, in fact, is one of the major reasons why “typeless”
    languages (usually very high-level languages) are so slow. When you truly need
    a variant type, the performance is often just as good (or even better) than the
    alternative code you’d have to write to get around using one. However, if you’re
    using variant objects to hold values whose type you know when you first write
    the program, you’ll pay a heavy performance penalty for not using typed objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'In object-oriented languages such as C++, Java, Swift, and Delphi (Object Pascal),
    there’s a better solution for variant calculations: inheritance and polymorphism.
    A big problem with the `union`/`switch` statement version is that it can be a
    major pain to extend the variant type by adding a new type to it. For example,
    suppose you want to add a new complex data type supporting complex numbers. You’d
    have to locate every function you’ve written (typically one for each operator)
    and add a new `case` to the `switch` statement. This can be a maintenance nightmare
    (especially if you don’t have access to the original source code). However, by
    using objects, you can create a new class (such as `ComplexNumber`) that overrides
    the existing base class (perhaps `Numeric`) without having to modify any of the
    existing code (for other numeric types and operations). For more information on
    this method, see *Write Great Code, Volume 4: Designing Great Code*.'
  prefs: []
  type: TYPE_NORMAL
- en: '**11.4 Namespaces**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As your programs become larger, and particularly as these large programs use
    third-party software libraries to reduce development time, it becomes increasingly
    likely that name conflicts will arise in your source files. A name conflict occurs
    when you want to use a specific identifier at one point in your program, but that
    name is already in use elsewhere (for example, in a library you’re using). At
    some point in a very large project, you may dream up a new name to resolve a naming
    conflict only to discover that the new name is also already in use. Software engineers
    call this *namespace pollution*. Like environmental pollution, the problem is
    easy to live with when it’s small and localized. As your programs get larger,
    however, dealing with the fact that “all the good identifiers are already used
    up” is a real challenge.
  prefs: []
  type: TYPE_NORMAL
- en: 'At first blush, it might seem that this problem is exaggerated; after all,
    a programmer can always think of a different name. However, programmers who write
    great code often adhere to certain naming conventions so that their source code
    is consistent and easy to read (I’ll come back to this subject in *Write Great
    Code, Volume 5: Great Coding*). Constantly devising new names, even if they aren’t
    all that bad, tends to produce inconsistencies in the source code that make programs
    harder to read. It would be nice to choose whatever name you like for your identifiers
    and not have to worry about conflicts with other code or libraries. Enter namespaces.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A *namespace* is a mechanism by which you can associate a set of identifiers
    with a namespace identifier. In many respects, a namespace is like a record declaration.
    Indeed, you can use a `record` (or `struct`) declaration as a poor man’s namespace
    in languages that don’t support namespaces directly (with a few major restrictions).
    For example, consider the following Pascal variable declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the `i` and `j` fields in these two records are distinct variables.
    There will never be a naming conflict because the program must qualify these two
    field names with the record variable name. That is, you refer to these variables
    using the following names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The record variable that prefixes the fields uniquely identifies each of these
    field names. This is clear to anyone who has ever written code that uses a record
    or structure. Therefore, in languages that don’t support namespaces, you can use
    records (or classes) in their place.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one major problem with creating namespaces by using records or structures,
    though: many languages let you declare only variables within a record. Namespace
    declarations (like those available in C++ and HLA) specifically allow you to include
    other types of objects as well. In HLA, for example, a namespace declaration takes
    the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: A class declaration (if available in your chosen language) can overcome some
    of these problems. At the very least, most languages allow procedure or function
    declarations within a class, but many allow constant and type declarations as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: Namespaces are a declaration section unto themselves. In particular, they do
    not have to go in a `var` or `static` (or any other) section. You can create constants,
    types, variables, static objects, procedures, and so on, all within a namespace.
  prefs: []
  type: TYPE_NORMAL
- en: To access namespace objects in HLA, you use the familiar dot notation that records,
    classes, and unions use. To access a name in a C++ namespace, you use the `::`
    operator.
  prefs: []
  type: TYPE_NORMAL
- en: As long as the namespace identifier is unique and all the fields within the
    namespace are unique to that namespace, you won’t have any problems. By carefully
    partitioning a project into various namespaces, you can easily avoid most of the
    problems that occur because of namespace pollution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another interesting aspect to namespaces is that they are extensible. For example,
    consider the following declarations in C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'This example code is perfectly legal. The second declaration of `aNS` does
    not conflict with the first: it extends the `aNS` namespace to include identifier
    `aNS::k` as well as `aNS::i` and `aNS::j`. This feature is very handy when, for
    example, you want to extend a set of library routines and header files without
    modifying the original header files for that library (assuming the library names
    all appear within a namespace).'
  prefs: []
  type: TYPE_NORMAL
- en: From an implementation point of view, there’s really no difference between a
    namespace and a set of declarations appearing outside a namespace. The compiler
    typically deals with both types of declarations in a nearly identical fashion,
    with the only difference being that the program prefixes all objects located within
    the namespace with the namespace’s identifier.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5 Classes and Objects**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *class* data type is the bedrock of modern object-oriented programming (OOP).
    In most OOP languages, the class is closely related to the record or structure.
    However, unlike records (which have a surprisingly uniform implementation across
    most languages), class implementations tend to vary. Nevertheless, many contemporary
    OOP languages achieve their results using similar approaches, so this section
    demonstrates a few concrete examples from C++, Java, Swift, HLA, and Delphi (Object
    Pascal). Users of other languages will find their languages work similarly.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5.1 Classes vs. Objects**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Many programmers confuse the terms *class* and *object*. A class is a data type;
    it is a template for how the compiler organizes memory with respect to the class’s
    fields. An object is an instantiation of a class—that is, an object is a variable
    of some class type that has memory allocated to hold the data associated with
    the class’s fields. For a given class, there is only one class definition. You
    may, however, have several objects (variables) of that class type.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5.2 Simple Class Declarations in C++**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Classes and structures are syntactically and semantically similar in C++. Indeed,
    there is only one syntactical difference between them: the use of the `class`
    keyword versus the `struct` keyword. Consider the following two valid type declarations
    in C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Although these two data structures contain the same fields, and you would access
    those fields the same way, their memory implementation is slightly different.
    A typical memory layout for the structure appears in [Figure 11-3](ch11.xhtml#ch11fig3),
    which can be compared with the memory layout for the class shown in [Figure 11-4](ch11.xhtml#ch11fig4).
    ([Figure 11-3](ch11.xhtml#ch11fig3) is the same as [Figure 11-1](ch11.xhtml#ch11fig1),
    but appears here for easy comparison with [Figure 11-4](ch11.xhtml#ch11fig4).)
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-3: The student structure storage in memory*'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-4: The student class storage in memory*'
  prefs: []
  type: TYPE_NORMAL
- en: The *VMT pointer* is a field that appears if the class contains any class member
    functions (aka *methods*). Some C++ compilers do not emit a VMT pointer field
    if there are no member functions, in which case the `class` and `struct` objects
    will have the same layout in memory.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: VMT *stands for* virtual method table *and will be discussed further in the
    section “Virtual Method Tables” on [page 367](ch11.xhtml#page_367).*
  prefs: []
  type: TYPE_NORMAL
- en: 'Although a C++ class declaration could contain only data fields, classes generally
    contain member function definitions as well as data members. In the `myClass`
    example, you might have the following member functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The `computeGrade()` function might compute the total grade in the course (based
    on relative weights attached to the midterms, final, homework, and project scores).
    The `testAverage()` function might return the average of all the test scores.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5.3 Class Declarations in C# and Java**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'C# and Java classes look very similar to C/C++ class declarations. Here’s a
    sample C# class declaration (which also works for Java):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '**11.5.4 Class Declarations in Delphi (Object Pascal)**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Delphi (Object Pascal) classes look very similar to Pascal records. Classes
    use the `class` keyword instead of `record`, and you can include function prototype
    declarations in the class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '**11.5.5 Class Declarations in HLA**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: HLA classes look very similar to HLA records. Classes use the `class` keyword
    instead of `record`, and you can include function (method) prototype declarations
    in the class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '**11.5.6 Virtual Method Tables**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As you saw in [Figures 11-3](ch11.xhtml#ch11fig3) and [11-4](ch11.xhtml#ch11fig4),
    the difference between the class definition and the structure definition is that
    the former contains a VMT field. VMT, which stands for *virtual method table*,
    is an array of pointers to all the member functions, or *methods*, within an object’s
    class. Virtual methods (*virtual member functions* in C++) are special class-related
    functions that you declare as fields in the class. In the current student example,
    the class doesn’t actually have any virtual methods, so most C++ compilers would
    eliminate the VMT field, but some OOP languages will still allocate storage for
    the VMT pointer within the class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a little C++ class that actually has a virtual member function and,
    therefore, also has a VMT:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: When C++ calls a standard function, it directly calls that function. Virtual
    member functions are another story, as you can see in [Figure 11-5](ch11.xhtml#ch11fig5).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-5: A virtual method table in C++*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calling a virtual member function requires *two* indirect accesses. First,
    the program has to fetch the VMT pointer from the class object and use that to
    indirectly fetch a particular virtual function address from the VMT. Then the
    program has to make an indirect call to the virtual member function via the pointer
    it retrieved from the VMT. As an example, consider the following C++ function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the corresponding x86-64 assembly code that Visual C++ generates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This example amply demonstrates why object-oriented programs generally run
    a little more slowly than standard procedural programs: extra indirection when
    calling virtual methods. C++ attempts to address this inefficiency by providing
    *static member functions*, but they lose many of the benefits of virtual member
    functions that make object-oriented programming possible.'
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5.7 Abstract Methods**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Some languages (such as C++) allow you to declare *abstract methods* within
    a class. An abstract method declaration tells the compiler that you will not be
    supplying the actual code for that method. Instead, you’re promising that some
    derived class will provide the method’s implementation. Here’s a version of `myclass`
    that has an abstract method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Why the strange syntax? It doesn’t really make sense to assign `0` to a virtual
    function. Why not just use an `abstract` keyword (rather than `virtual`) like
    most other languages do? These are good questions. The answer probably has a lot
    to do with the fact that a `0` (`NULL` pointer) was being placed in the VMT entry
    for the abstract function. In modern versions of C++, compiler implementers typically
    place the address of some function that generates an appropriate runtime message
    (like `cannot call an abstract method`) here, rather than a `NULL` pointer. The
    following code snippet shows the Visual C++ VMT for this version of `myclass`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The `_purecall` entry corresponds to the abstract function `h()`. This is the
    name of the subroutine that handles illegal calls to abstract functions. When
    you override an abstract function, the C++ compiler replaces the pointer in the
    VMT to the `_purecall` function with the address of the overriding function (just
    as it would replace the address of any overridden function).
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5.8 Sharing VMTs**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For a given class there is only one copy of the VMT in memory. This is a static
    object, so all objects of a given class type share the same VMT. This is reasonable,
    because all objects of the same class type have exactly the same member functions
    (see [Figure 11-6](ch11.xhtml#ch11fig6)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-6: Objects sharing the same VMT (note that objects are all the same
    class type)*'
  prefs: []
  type: TYPE_NORMAL
- en: Because the addresses in a VMT never change during program execution, most languages
    place the VMT in a constant (write-protected) section in memory. In the previous
    example, the compiler places the `myclass` VMT in the `CONST` segment.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5.9 Inheritance in Classes**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Inheritance is one of the fundamental concepts behind object-oriented programming.
    The basic idea is that a class inherits, or copies, all the fields from some existing
    class and then possibly expands the number of fields in the new class data type.
    For example, suppose you created a data type point that describes a point in the
    planar (two-dimensional) space. The class for this point might look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: The `distance()` member function would probably compute the distance from the
    origin (0,0) to the coordinate specified by the (`x`,`y`) fields of the object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a typical implementation of this member function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Inheritance allows you to extend an existing class by adding new fields or
    replacing existing fields. For example, suppose you want to extend the two-dimensional
    point definition to a third spatial dimension. You can easily do this with the
    following C++ class definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The `point3D` class inherits the `x` and `y` fields, as well as the `distance()`
    member function. (Of course, `distance()` does not compute the proper result for
    a point in three-dimensional space, but I’ll address that in a moment.) By “inherits,”
    I mean that `point3D` objects locate their `x` and `y` fields at exactly the same
    offsets as `point` objects do (see [Figure 11-7](ch11.xhtml#ch11fig7)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-7: Inheritance in classes*'
  prefs: []
  type: TYPE_NORMAL
- en: As you might have noticed, there were actually two items added to the `point3D`
    class—a new data field, `z`, and a new member function, `rotate()`. In [Figure
    11-7](ch11.xhtml#ch11fig7), you can see that adding the `rotate()` virtual member
    function has had no impact at all on the layout of a `point3D` object. This is
    because virtual member functions’ addresses appear in the VMT, not in the object
    itself. Although both `point` and `point3D` contain a field named `VMT`, these
    fields do not point at the same table in memory. Every class has its own unique
    VMT, which, as previously defined, consists of an array of pointers to all of
    the member functions (inherited or explicitly declared) for the class (see [Figure
    11-8](ch11.xhtml#ch11fig8)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-8: VMTs for inherited classes (assuming 32-bit pointers)*'
  prefs: []
  type: TYPE_NORMAL
- en: All the objects for a given class share the same VMT, but this is not true for
    objects of different classes. Because `point` and `point3D` are different classes,
    their objects’ VMT fields will point at different VMTs in memory. (See [Figure
    11-9](ch11.xhtml#ch11fig9).)
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-9: VMT access*'
  prefs: []
  type: TYPE_NORMAL
- en: 'One problem with the `point3D` definition given thus far is that it inherits
    the `distance()` function from the `point` class. By default, if a class inherits
    member functions from some other class, the entries in the VMT corresponding to
    those inherited functions will point at the functions associated with the base
    class. If you have an object pointer variable of type `point3D`, let’s say `p3D`,
    and you invoke the member function `p3D->distance()`, you will not get a correct
    result. Because `point3D` inherits the `distance()` function from class `point`,
    `p3->distance()` will compute the distance to the projection of (`x,y,z`) onto
    the two-dimensional plane rather than the correct value on the three-dimensional
    plane. In C++ you can overcome this problem by *overloading* the inherited function
    and writing a new, `point3D`-specific member function like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Creating an overloaded member function does not change the layout of the class’s
    data or the layout of the `point3D` VMT. The only change this function evokes
    is that the C++ compiler initializes the `distance()` entry in the `point3D` VMT
    with the address of the `point3D::distance()` function rather than the address
    of the `point::distance()` function.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5.10 Polymorphism in Classes**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In addition to inheritance and overloading, *polymorphism* is the other anchor
    upon which object-oriented programming is based. Polymorphism, which literally
    means “many-faced” (or, translated a little better, “many forms” or “many shapes”),
    describes how a single instance of a function call in your program, such as `x->distance()`,
    could wind up calling different functions (in the examples from the previous section,
    this could be the `point::distance()` or `point3D::distance()` function). What
    makes this possible is the fact that C++ relaxes its type-checking facilities
    a bit when dealing with derived (inherited) classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example. Normally, a C++ compiler will generate an error if
    you try to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'C++ does not allow you to assign the address of some object to a pointer whose
    base type doesn’t exactly match the object’s type—with one major exception. C++
    relaxes this restriction so you can assign the address of some object to a pointer
    as long as the pointer’s base type either matches *or is an ancestor of* the object’s
    type (an ancestor class is one from which some other class type is derived, directly
    or indirectly, via inheritance). That means the following code is legal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: If you’re wondering how this could be legitimate, take another look at [Figure
    11-7](ch11.xhtml#ch11fig7). If `generic`’s base type is `point`, then the C++
    compiler will allow access to a VMT at offset 0 in the object, an `x` field at
    offset 4 (8 on 64-bit machines) in the object, and a `y` field at offset 8 (16)
    in the object. Similarly, any attempt to invoke the `distance()` member function
    will access the function pointer at offset 0 into the VMT pointed at by the object’s
    VMT field. If `generic` points at an object of type `point`, all of these requirements
    are satisfied. This is also true if `generic` points at any derived class of `point`
    (that is, any class that inherits the fields from `point`). None of the extra
    fields in the derived class (`point3D`) will be accessible via the generic pointer,
    but that’s to be expected because `generic`’s base class is `point`.
  prefs: []
  type: TYPE_NORMAL
- en: A crucial thing to note, however, is that when you invoke the `distance()` member
    function, you’re calling the one pointed at by the `point3D` VMT, not the one
    pointed at by the `point` VMT. This fact is the basis for polymorphism in an OOP
    language such as C++. The code a compiler emits is exactly the same code it would
    emit if `generic` contained the address of an object of type `point`. All of the
    “magic” occurs because the compiler allows the programmer to load the address
    of a `point3D` object into `generic`.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5.11 Multiple Inheritance (in C++)**'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'C++ is one of the few modern programming languages that support *multiple inheritance*,
    whereby a class can inherit the data and member functions from multiple classes.
    Consider the following C++ code fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: In this example, class `c` inherits all the information from classes `a` and
    `b`. In memory, a typical C++ compiler will create an object like that shown in
    [Figure 11-10](ch11.xhtml#ch11fig10).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-10: Multiple inheritance memory layout*'
  prefs: []
  type: TYPE_NORMAL
- en: The VMT pointer entry points at a typical VMT containing the addresses of the
    `setI()`, `setJ()`, and `setK()` methods, as shown in [Figure 11-11](ch11.xhtml#ch11fig11).
    If you call the `setI()` method, the compiler will generate code that loads the
    `this` pointer with the address of the VMT pointer entry in the object (the base
    address of the `c` object in [Figure 11-10](ch11.xhtml#ch11fig10)). Upon entry
    into `setI()`, the system believes that `this` is pointing at an object of type
    `a`. In particular, the `this`.`VMT` field points at a VMT whose first (and, as
    far as type `a` is concerned, only) entry is the address of the `setI()` method.
    Likewise, at offset (`this+8`) in memory (as the VMT pointer is 8 bytes, assuming
    64-bit pointers), the `setI()` method will find the `i` data value. As far as
    `setI()` is concerned, `this` is pointing at a class type `a` object (even though
    it’s actually pointing at a type `c` object).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-11: Multiple inheritance this values*'
  prefs: []
  type: TYPE_NORMAL
- en: When you call the `setK()` method, the system also passes the base address of
    the `c` object. Of course, `setK()` is expecting a type `c` object and `this`
    is pointing at a type `c` object, so all the offsets into the object are exactly
    as `setK()` expects. Note that objects of type `c` (and methods in the `c` class)
    will normally ignore the `VMT2` pointer field in the `c` object.
  prefs: []
  type: TYPE_NORMAL
- en: The problem occurs when the program attempts to call the `setJ()` method. Because
    `setJ()` belongs to class `b`, it expects `this` to hold the address of a VMT
    pointer pointing at a VMT for class `b`. It also expects to find data field `j`
    at offset (`this+8`). Were we to pass the `c` object’s `this` pointer to `setJ()`,
    accessing (`this+8`) would reference the `i` data field, not `j`. Furthermore,
    were a class `b` method to make a call to another method in class `b` (such as
    `setJ()` making a recursive call to itself), the VMT pointer would be wrong—it
    points at a VMT with a pointer to `setI()` at offset 0, whereas class `b` expects
    it to point at a VMT with a pointer to `setJ()` at offset 0\. To resolve this
    issue, a typical C++ compiler will insert an extra VMT pointer into the `c` object
    immediately prior to the `j` data field. It will initialize this second VMT field
    to point into the `c` VMT at the location where the class `b` method pointers
    begin (see [Figure 11-11](ch11.xhtml#ch11fig11)). When calling a method in class
    `b`, the compiler will emit code that initializes the `this` pointer with the
    address of this second VMT pointer (rather than pointing at the beginning of `c`-type
    object in memory). Now, upon entry to a class `b` method—such as `setJ()`—`this`
    will point at a legitimate VMT pointer for class `b`, and the `j` data field will
    appear at the offset (`this+8`) that class `b` methods expect.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.6 Protocols and Interfaces**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Java and Swift don’t support multiple inheritance, because it has some logical
    problems. The classic example is the “diamond lattice” data structure. This occurs
    when two classes (say, `b` and `c`) both inherit information from the same class
    (say, `a`), and then a fourth class (say, `d`) inherits from both `b` and `c`.
    As a result, `d` inherits the data from `a` twice—once through `b` and once through
    `c`. This can create some consistency problems.
  prefs: []
  type: TYPE_NORMAL
- en: Although multiple inheritance can lead to some weird problems like this, there’s
    no question that being able to inherit from multiple locations is often useful.
    Thus, the solution in languages like Java and Swift is to allow a class to inherit
    methods/functions from multiple parents but allow inheritance from only a single
    ancestor class. This avoids most of the problems with multiple inheritance (specifically,
    an ambiguous choice of inherited data fields) while allowing programmers to include
    methods from various sources. Java calls such extensions *interfaces*, and Swift
    calls them *protocols*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of a couple Swift protocol declarations and a class supporting
    that protocol:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Swift protocols don’t supply any functions. Instead, a class that supports a
    protocol promises to provide an implementation of the functions the protocol(s)
    specify. In the preceding example, the `supportsProtocols` class is responsible
    for supplying all functions required by the protocols it supports. Effectively,
    protocols are like abstract classes containing only abstract methods—the inheriting
    class must provide actual implementations for all the abstract methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the previous example coded in Java and demonstrating its comparable
    mechanism, the interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Interfaces/protocols behave somewhat like base class types in Java and Swift.
    If you instantiate a class object and assign that instance to a variable that
    is an interface/protocol type, you can execute the supported member functions
    for that interface/protocol. Consider the following Java example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a comparable example in Swift:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of a protocol or interface is quite simple—it’s just a pointer
    to a VMT that contains the addresses of the functions declared in that protocol/interface.
    So, the data structure for the Swift `g` class in the previous example would have
    three VMT pointers in it: one for protocol `a`, one for protocol `d`, and one
    for the class `g` (holding a pointer to the `local()` function). [Figure 11-12](ch11.xhtml#ch11fig12)
    shows the class and VMT layout.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/11fig12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 11-12: Multiple inheritance memory layout*'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 11-12](ch11.xhtml#ch11fig12) the VMT pointer for class `g` contains
    the address of the entire VMT. There are two entries in the class that contain
    pointers to the VMTs for protocol `a` and protocol `d`. As the VMT for class `g`
    also contains pointers to the functions belonging to these protocols, there’s
    no need to create a separate VMT for these two protocols; instead, the `aPtr`
    and `dPtr` fields can point to the corresponding entries within class `g`’s VMT.
  prefs: []
  type: TYPE_NORMAL
- en: When the assignment `var x:a = g()` occurs in the previous example, the Swift
    code will load variable `x` with the `aPtr` pointer held in the `g` object. Therefore,
    the calls to `x.b()` and `x.c()` work just like a normal method call—the system
    uses the pointer held in `x` to reference the VMT and then it calls `b` or `c`
    by indexing the appropriate amount into the VMT. Had `x` been of type `d` rather
    than `a`, then the assignment `var x:d = g()` would have loaded `x` with the address
    of the `d` protocol VMT (pointed at by `dPtr`). Calls to `d` and `e` would happen
    at offsets 0 and 8 (64-bit pointers) into the `d` VMT.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.7 Classes, Objects, and Performance**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As you’ve seen in this chapter, the direct cost associated with object-oriented
    programming isn’t terribly significant. Calls to member functions (methods) are
    a bit more expensive because of double indirection; however, that’s a small price
    to pay for the flexibility OOP gives you. The extra instructions and memory accesses
    will probably cost only about 10 percent of your application’s total performance.
    Some languages, such as C++ and HLA, support the notion of a *static member function*
    that allows direct calls to member functions when polymorphism is unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: The big problem that object-oriented programmers sometimes face is taking things
    to an extreme. Rather than directly accessing the fields of an object, they write
    accessor functions to read and write those field values. Unless the compiler does
    a very good job of inlining such accessor functions, the cost of accessing the
    object’s fields increases by about an order of magnitude. In other words, application
    performance can actually suffer when OOP paradigms are overused. There may be
    good reasons for doing things the “object-oriented way” (such as using accessor
    functions to access all fields of an object), but keep in mind that these costs
    add up rather quickly. Unless you absolutely need the facilities provided by OOP
    techniques, your programs may wind up running considerably slower (and taking
    up a whole lot more space) than necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Swift is a good example of object-oriented programming taken to an extreme.
    Anyone who has compared the performance of compiled Swift code against an equivalent
    C++ program knows that Swift is much slower. Largely, this is because Swift makes
    objects out of everything (and constantly checks their types and bounds at runtime).
    The result is that it can take hundreds of machine instructions in Swift to do
    the same task as a half-dozen machine instructions produced by an optimizing C++
    compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Another common problem with many object-oriented programs is overgeneralization.
    This can occur when a programmer uses a lot of class libraries, extending classes
    through inheritance in order to solve some problem with as little programming
    effort as possible. While saving programming effort is generally a good idea,
    extending class libraries can lead to situations where you need some minor task
    done and you call a library routine that does everything you want. The problem
    is that in object-oriented systems, library routines tend to be highly layered.
    That is, you need some work done, so you invoke some member function from a class
    you’ve inherited. That function probably does a little bit of work on the data
    you pass it and then it calls a member function in a class that it inherits. And
    then that function massages the data a bit and calls a member function it inherits,
    and so on down the line. Before too long, the CPU spends more time calling and
    returning from functions than it does doing any useful work. While this same situation
    could occur in standard (non-OOP) libraries, it’s far more common in object-oriented
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Carefully designed object-oriented programs needn’t run significantly slower
    than comparable procedural programs. Just be careful not to make a lot of expensive
    function calls to do trivial tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.8 For More Information**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Dershem, Herbert, and Michael Jipping. *Programming Languages, Structures and
    Models*. Belmont, CA: Wadsworth, 1990.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Duntemann, Jeff. *Assembly Language Step-by-Step*. 3rd ed. Indianapolis: Wiley,
    2009.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ghezzi, Carlo, and Jehdi Jazayeri. *Programming Language Concepts*. 3rd ed.
    New York: Wiley, 2008.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hyde, Randall. *The Art of Assembly Language*. 2nd ed. San Francisco: No Starch
    Press, 2010.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Knuth, Donald. *The Art of Computer Programming, Volume I: Fundamental Algorithms.*
    3rd ed. Boston: Addison-Wesley Professional, 1997.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ledgard, Henry, and Michael Marcotty. *The Programming Language Landscape*.
    Chicago: SRA, 1986.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Louden, Kenneth C., and Kenneth A. Lambert. *Programming Languages, Principles
    and Practice*. 3rd ed. Boston: Course Technology, 2012.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pratt, Terrence W., and Marvin V. Zelkowitz. *Programming Languages, Design
    and Implementation*. 4th ed. Upper Saddle River, NJ: Prentice Hall, 2001.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sebesta, Robert. *Concepts of Programming Languages*. 11th ed. Boston: Pearson,
    2016.'
  prefs: []
  type: TYPE_NORMAL
