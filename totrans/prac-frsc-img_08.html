<html><head></head><body>
<h2 class="h2" id="ch07"><span epub:type="pagebreak" id="page_187"/><span class="big"><strong>7</strong></span><br/><strong>FORENSIC IMAGE MANAGEMENT</strong></h2>&#13;
<div class="imagef"><img src="../images/common-01.jpg" alt="image"/></div>&#13;
<p class="noindent">This chapter covers various aspects of managing forensic image files after acquisition. Disk images are enormous compared to typical files on a disk, and moving, copying, and converting large image files can be cumbersome and time-consuming. You’ll learn a number of techniques for managing large image files to help overcome various challenges. These techniques include compressing and splitting images for easier handling, securing images with encryption, and converting images between formats. In addition, I describe procedures for read-only mounting of an image for safe local browsing and demonstrate forensic cloning (or disk duplication). I also discuss the secure, reliable storage and network transfer of large image files. The chapter ends with a description of secure wiping and disposal of images and files. I’ll begin with the topic of managing image compression.</p>&#13;
<h3 class="h3" id="ch07lev1sec01"><strong>Manage Image Compression</strong></h3>&#13;
<p class="noindent">Raw disk images are always the same size as the total number of sectors they contain. The number of files or amount of data on the drive is irrelevant and does not affect the size of an uncompressed raw image. With the <span epub:type="pagebreak" id="page_188"/>current widespread use of multiterabyte disks, maneuvering images within time and disk capacity constraints can be a challenge. Even simply copying an image can take many hours to complete. You can reduce this problem somewhat by keeping images compressed.</p>&#13;
<p class="indent">Compressing images in a forensic context involves sector-by-sector compression of the entire drive (as opposed to compressing each file on the disk). Disks with many gigabytes or terabytes of space that have never been written to over the life of the drive will compress better, because much of the drive still consists of untouched sectors filled with zeros. Well-used disks won’t compress as well if most sectors on the drive have been allocated over the lifetime of the drive and still contain residual data. Disk images with large numbers of audio and video files will compress poorly as well, because these files are already compressed with their own algorithms.</p>&#13;
<p class="indent">It’s important to choose the most appropriate and efficient compression tool and technique. Some tools might have file size limitations, either for the original source file or the compressed destination file. Other tools may be inefficient or use temporary files during compression, causing memory exhaustion or creating disk space issues. To solve some of these problems when you’re performing compression activity, you can use piping and redirection.</p>&#13;
<p class="indent">One of the most useful features of working with a compressed forensic image is the ability to use forensic tools against it without having to uncompress the entire image. But this is problematic with some compression tools, because they’re not able to seek within a compressed file. <em>Seeking</em> allows a program to randomly access any point in a file. Forensic formats are designed to allow analysis programs on-the-fly, random access to compressed images. The popular forensic formats all support image compression, which usually occurs during acquisition, although not all tools compress by default.</p>&#13;
<h4 class="h4" id="ch07lev2sec01"><em><strong>Standard Linux Compression Tools</strong></em></h4>&#13;
<p class="noindenta">Commonly used compression tools in the open source world today are zip, gzip, and bzip (version 1 or 2). The examples in this section use gzip, but you can use other compression tools as well. To attempt better compression at the expense of time and CPU cycles, you can adjust the level of compression.</p>&#13;
<p class="indent">Given enough disk space, you can simply compress a disk image file in place, like this:</p>&#13;
<p class="programs">$ <strong>gzip image.raw</strong></p>&#13;
<p class="indent">This command creates the file <em>image.raw.gz</em> and deletes the original file on completion. Enough space needs to be available for the compressed and uncompressed files to coexist during the compression process. The same applies for uncompressing files using gunzip.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_189"/>You can also compress images on the fly during acquisition using piping and redirection. For example:</p>&#13;
<p class="programs"># <strong>dcfldd if=/dev/sde | gzip &gt; image.raw.gz</strong></p>&#13;
<p class="indent">Here the input file is a raw disk device. Not specifying an output file for dcfldd sends the image data stream to stdout, which is piped into gzip, which is finally redirected into a compressed file.</p>&#13;
<p class="indent">The compressed file can be uncompressed to a raw image file, where you can use forensic tools to directly operate on it. Alternatively, you can pipe an uncompressed stream into some programs using stdout and stdin. For example:</p>&#13;
<p class="programs">$ <strong>zcat image.raw.gz | sha256sum</strong><br/>1b52ab6c1ff8f292ca88404acfc9f576ff9db3c1bbeb73e50697a4f3bbf42dd0 -</p>&#13;
<p class="indent">Here zcat uncompresses the image and pipes it into a program to produce a sha256 cryptographic hash. It’s worth noting that the gzip file format contains additional metadata, such as a creation timestamp, original filename, and other information. The hash of a gzip container (<em>image.raw.gz</em>) will be different each time it’s created, even though the hash of the compressed file inside will be the same.</p>&#13;
<h4 class="h4" id="ch07lev2sec02"><em><strong>EnCase EWF Compressed Format</strong></em></h4>&#13;
<p class="noindenta">The ewfacquire tool provides flags to control compression during the acquisition process. For example:</p>&#13;
<p class="programs"># <strong>ewfacquire -c bzip2:best -f encase7-v2 /dev/sdj</strong><br/>ewfacquire 20150126<br/>...<br/>EWF file format:                        EnCase 7 (.Ex01)<br/>Compression method:                     bzip2<br/>Compression level:                      best<br/>...<br/>MD5 hash calculated over data:          9749f1561dacd9ae85ac0e08f4e4272e<br/>ewfacquire: SUCCESS</p>&#13;
<p class="indent">In this example, the <span class="literal">-c</span> flag can specify a compression algorithm together with a compression level. Here, the algorithm was bzip2 configured with the best possible compression level. Because only EWFv2 formats support bzip2, the format version <span class="literal">encase7-v2</span> was specified as a parameter. Note that ewftools needs to be compiled with bzip2 support.<sup><a id="fn_39" href="footnote.xhtml#fn39">1</a></sup></p>&#13;
<h4 class="h4" id="ch07lev2sec03"><span epub:type="pagebreak" id="page_190"/><em><strong>FTK SMART Compressed Format</strong></em></h4>&#13;
<p class="noindenta">The command line ftkimager tool supports compressed images during acquisition, as the following example shows:</p>&#13;
<p class="programs"># <strong>ftkimager --compress 9 --s01 /dev/sdj image</strong><br/>AccessData FTK Imager v3.1.1 CLI (Aug 24 2012)<br/>Copyright 2006-2012 AccessData Corp., 384 South 400 West, Lindon, UT 84042<br/>All rights reserved.<br/><br/>Creating image...<br/>Image creation complete.</p>&#13;
<p class="indent">Here the <span class="literal">--s01</span> flag specifies the creation of a SMART ew-compressed image, and the <span class="literal">--compress</span> flag sets the highest compression level. You can use the <span class="literal">--help</span> flag to get more information about compression options for ftkimager.</p>&#13;
<h4 class="h4" id="ch07lev2sec04"><em><strong>AFFlib Built-In Compression</strong></em></h4>&#13;
<p class="noindenta">Although AFFv3 has been deprecated (<em><a href="http://forensicswiki.org/wiki/AFF">http://forensicswiki.org/wiki/AFF</a></em>) and the use of aimage is discouraged (<em><a href="http://forensicswiki.org/wiki/Aimage">http://forensicswiki.org/wiki/Aimage</a></em>), aimage’s use of AFFv3 compression is mentioned here for illustration purposes.</p>&#13;
<p class="indent">The following example demonstrates imaging a disk using aimage and specifying the LZMA compression algorithm (rather than the zlib default):</p>&#13;
<p class="programs"># <strong>aimage --lzma_compress --compression=9 /dev/sdj image.aff</strong><br/>im-&gt;outfile=image.aff<br/>image.aff****************************** IMAGING REPORT ******************************<br/>Input: /dev/sdj<br/>  Model: Nano S/N: 07A40C03C895171A<br/>  Output file: image.aff<br/>  Bytes read: 2,003,828,736<br/>  Bytes written: 628,991,770<br/><br/>raw image md5:  9749 F156 1DAC D9AE 85AC 0E08 F4E4 272E<br/>raw image sha1: 9871 0FB5 531E F390 2ED0 47A7 5BE4 747E 6BC1 BDB0<br/>raw image sha256: 85B7 6D38 D60A 91F6 A0B6 9F65 B2C5 3BD9 F7E7 D944 639C 6F40 B3C4<br/>    0B06 83D8 A7E5<br/>Free space remaining on capture drive:  527,524 MB</p>&#13;
<p class="indent">The Sleuth Kit forensics software provides integrated support for AFFlib compressed images. AFFv4 introduces the aff4imager tool, which adds additional features. This can be fournd at <em><a href="https://github.com/google/aff4/">https://github.com/google/aff4/</a></em>.</p>&#13;
<h4 class="h4" id="ch07lev2sec05"><span epub:type="pagebreak" id="page_191"/><em><strong>SquashFS Compressed Evidence Containers</strong></em></h4>&#13;
<p class="noindenta">Recall that using SquashFS as a forensic evidence container was described in <a href="ch06.xhtml#ch06">Chapter 6</a>. When you’re creating a SquashFS file, you can tune several compression parameters. Three compression algorithms (gzip, lzo, xz) are available, various metadata from SquashFS can be compressed (inode table, extended attributes), and other tweaks can be made as well. See the squashfs(1) manual page for more information.</p>&#13;
<p class="indent">In this example, a raw image file was converted to a compressed SquashFS file:</p>&#13;
<p class="programs"># <strong>mksquashfs image.raw image.sfs -comp lzo -noI</strong><br/>Parallel mksquashfs: Using 8 processors<br/>Creating 4.0 filesystem on image.sfs, block size 131072.<br/>...<br/>Exportable Squashfs 4.0 filesystem, lzo compressed, data block size 131072<br/>        compressed data, uncompressed metadata, compressed fragments, compressed<br/>    xattrs<br/>        duplicates are removed<br/>Filesystem size 615435.77 Kbytes (601.01 Mbytes)<br/>        31.45% of uncompressed filesystem size (1956923.96 Kbytes)<br/>Inode table size 61232 bytes (59.80 Kbytes)<br/>        100.00% of uncompressed inode table size (61232 bytes)<br/>Directory table size 31 bytes (0.03 Kbytes)<br/>        100.00% of uncompressed directory table size (31 bytes)<br/>...</p>&#13;
<p class="indent">Here, the <span class="literal">-comp</span> flag sets the compression algorithm to lzo (gzip is the default), and the <span class="literal">-noI</span> flag prevents compression of the inodes (of the SquashFS container, not the evidence image).</p>&#13;
<p class="indent">The sfsimage shell script manages the creation of SquashFS forensic evidence containers with a few added forensic features.</p>&#13;
<p class="indent">The use of compression is fundamental when you’re working with large forensic images. However, even compressed images can still be very large to manage. There is another method that makes this process easier: you can split forensic images into multiple smaller pieces.</p>&#13;
<h3 class="h3" id="ch07lev1sec02"><strong>Manage Split Images</strong></h3>&#13;
<p class="noindentb">Managing acquired disk images can be problematic due to their large file sizes. Breaking an image into smaller, easier-to-handle pieces can help solve this problem. Consider the following examples in which a split image can be beneficial:</p>&#13;
<p class="bull">• Network transfers over unstable connections can be done with multiple smaller downloads using split images.</p>&#13;
<p class="bull">• A large image might exceed the maximum file size for a software tool. Splitting the image offers a workaround.</p>&#13;
<p class="bull"><span epub:type="pagebreak" id="page_192"/>• Storage media, such as tapes, CDs, or DVDs, have a fixed maximum capacity. Split images allow you to use a set of these media.</p>&#13;
<p class="bull">• Some filesystems (notably FAT) have a relatively small maximum file size.</p>&#13;
<p class="indentt">The most common use of split images in digital forensics is for the transfer and storage of evidence. Historically, this has been done by burning the image to a set of CDs or DVDs.</p>&#13;
<h4 class="h4" id="ch07lev2sec06"><em><strong>The GNU split Command</strong></em></h4>&#13;
<p class="noindenta">Standard Unix and Linux systems have the split tool for breaking a large file into several smaller files. The following example uses the <span class="literal">split</span> command to break an existing image into DVD-sized chunks:</p>&#13;
<p class="programs">$ <strong>split -d -b 4G image.raw image.raw.</strong><br/>$ <strong>ls</strong><br/>image.raw.00  image.raw.01  image.raw.02  image.raw.03  image.raw.04<br/>...</p>&#13;
<p class="indent">The <span class="literal">-d</span> flag specifies that a numeric extension should be added to <em>image.raw.</em> (note the trailing dot); the <span class="literal">-b</span> flag specifies the size of the chunks made from the <em>image.raw</em> file.</p>&#13;
<p class="indent">Using a combination of piping between several tools, you can combine compressing and splitting during acquisition to save time and space. Here’s an example of a single command acquiring an image with dd, compressing it with gzip, and splitting it into CD-sized chunks:</p>&#13;
<p class="programs"># <strong>dd if=/dev/sdb | gzip | split -d -b 640m - image.raw.gz.</strong></p>&#13;
<p class="indent">The <span class="literal">split</span> command’s input file is <em>-</em>, which specifies stdin, and it splits the compressed byte stream into pieces. It’s important to note that the parts are not individually gzipped and cannot be individually uncompressed. The split parts must be reassembled before they can be uncompressed.</p>&#13;
<h4 class="h4" id="ch07lev2sec07"><em><strong>Split Images During Acquisition</strong></em></h4>&#13;
<p class="noindenta">You can split an imaged hard disk into parts during the acquisition process rather than in a separate step at a later date. Before acquiring a large disk, consider whether you might need a split image in the future and what fragment size would make the most sense. Starting with the right split image could save you time and disk space during an investigation.</p>&#13;
<p class="indent">Split images are common in digital forensics and therefore are well supported by forensic acquisition and analysis tools. Typically, flags can set the fragment size and customize the extension of a split image.</p>&#13;
<p class="indent">The dcfldd tool provides built-in splitting functionality. For example, if you’ll later transfer an image to a third party via a set of 16GB USB sticks, <span epub:type="pagebreak" id="page_193"/>you can use dcfldd to acquire an image using the <span class="literal">split=16G</span> flag before the output file:</p>&#13;
<p class="programs"># <strong>dcfldd if=/dev/sdc split=16G of=image.raw</strong><br/># <strong>ls</strong><br/>image.raw.000  image.raw.001  image.raw.002  image.raw.003  image.raw.004<br/>...</p>&#13;
<p class="indent">The default extension is a three-digit number appended to the output filename.</p>&#13;
<p class="indent">Using the dc3dd tool, you can split images during acquisition by specifying the output size with <span class="literal">ofsz=</span>. The file extensions are numerical, as shown here:</p>&#13;
<p class="programs"># <strong>dc3dd if=/dev/sdh ofsz=640M ofs=image.raw.000</strong><br/># <strong>ls -l</strong><br/>total 7733284<br/>-rw-r----- 1 root root 671088640 Jan 14 10:59 image.raw.000<br/>-rw-r----- 1 root root 671088640 Jan 14 10:59 image.raw.001<br/>-rw-r----- 1 root root 671088640 Jan 14 10:59 image.raw.002<br/>...<br/>-rw-r----- 1 root root 671088640 Jan 14 11:00 image.raw.009<br/>-rw-r----- 1 root root 671088640 Jan 14 11:00 image.raw.010<br/>-rw-r----- 1 root root 536870912 Jan 14 11:00 image.raw.011</p>&#13;
<p class="indent">Be sure the file extension has enough zeros, or else dc3dd will fail to complete and generate an error message, such as <span class="literal">[!!] file extensions exhausted for image.raw.0</span>. The last file in the set will usually be smaller than the others (unless the image size is perfectly divisible by the split file size).</p>&#13;
<p class="indent">EnCase tools typically default to splitting images during acquisition. You can acquire a disk to a split EnCase image using ewfacquire by specifying a maximum segment file size using the <span class="literal">-S</span> flag:</p>&#13;
<p class="programs"># <strong>ewfacquire -S 2G /dev/sdc</strong><br/>...<br/># <strong>ls</strong><br/>image.E01  image.E02  image.E03  image.E04  image.E05  image.E06<br/>...</p>&#13;
<p class="indent">The commercial EnCase forensic suite can then use these images directly.</p>&#13;
<p class="indent">The ftkimager tool provides the <span class="literal">--frag</span> flag to save an image into parts during acquisition, as shown in this example:</p>&#13;
<p class="programs"># <strong>ftkimager /dev/sdk image --frag 20GB --s01</strong><br/>AccessData FTK Imager v3.1.1 CLI (Aug 24 2012)<br/>Copyright 2006-2012 AccessData Corp., 384 South 400 West, Lindon, UT 84042<br/>All rights reserved.<br/>...<br/># <strong>ls -l</strong><br/>total 53771524<br/>-rw-r----- 1 holmes root 2147442006 Jul  2 08:01 image.s01<br/>-rw-r----- 1 holmes root       1038 Jul  2 08:43 image.s01.txt<br/>-rw-r----- 1 holmes root 2147412323 Jul  2 08:01 image.s02<br/>-rw-r----- 1 holmes root 2147423595 Jul  2 08:02 image.s03<br/>-rw-r----- 1 holmes root 2147420805 Jul  2 08:02 image.s04<br/>...</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_194"/>Here the disk is acquired with a maximum fragment size set at 20GB, and the format is a SMART compressed image. Notice the addition of the <em>*.txt</em> file containing the metadata. Unlike some forensic formats, this is not embedded into FTK split files created by ftkimager.</p>&#13;
<h4 class="h4" id="ch07lev2sec08"><em><strong>Access a Set of Split Image Files</strong></em></h4>&#13;
<p class="noindenta">Forensic tools, such as Sleuth Kit, provide support for operating directly on a set of split images without needing to reassemble them first. To list the supported images in Sleuth Kit, use the <span class="literal">-i list</span> flag with any Sleuth Kit image-processing tool:</p>&#13;
<p class="programs">$ <strong>mmls -i list</strong><br/>Supported image format types:<br/>        raw (Single raw file (dd))<br/>        aff (Advanced Forensic Format)<br/>        afd (AFF Multiple File)<br/>        afm (AFF with external metadata)<br/>        afflib (All AFFLIB image formats (including beta ones))<br/>        ewf (Expert Witness format (encase))<br/>        split (Split raw files)</p>&#13;
<p class="indent">In this example, there is support for split raw images (including Unix split files), split AFF images, and split EnCase files (though this is not explicitly stated, split EnCase files are supported). Some of these image format types might need to be explicitly included when compiling the Sleuth Kit software.</p>&#13;
<p class="indent">In the following example, an EWF image is split into 54 pieces. Running the <span class="literal">img_stat</span> command on the first file provides information about the complete set of files:</p>&#13;
<p class="programs">$ <strong>img_stat image.E01</strong><br/>IMAGE FILE INFORMATION<br/>--------------------------------------------<br/>Image Type:            ewf<br/><br/>Size of data in bytes: 121332826112<br/>MD5 hash of data:      ce85c1dffc2807a205f49355f4f5a029</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_195"/>Using various tools, you can operate on split images directly. Most Sleuth Kit commands will work with a set of split raw files when you specify the first file of the split image type.</p>&#13;
<p class="indent">Recent versions of Sleuth Kit will automatically check for sets of split files:</p>&#13;
<p class="programs">$ <strong>mmls image.raw.000</strong></p>&#13;
<p class="indent">Earlier versions of Sleuth Kit may require that you specify a split image type:</p>&#13;
<p class="programs">$ <strong>fls -o 63 -i split image.000 image.001 image.002</strong></p>&#13;
<p class="indent">To check whether a set of split files is recognized, the <span class="literal">img_stat</span> command will show the total bytes recognized, and for raw types, the byte offset ranges for each piece:</p>&#13;
<p class="programs">$ <strong>img_stat image.raw.000</strong><br/>IMAGE FILE INFORMATION<br/>--------------------------------------------<br/>Image Type: raw<br/><br/>Size in bytes: 2003828736<br/><br/>--------------------------------------------<br/>Split Information:<br/>image.raw.000  (0 to 16777215)<br/>image.raw.001  (16777216 to 33554431)<br/>image.raw.002  (33554432 to 50331647)<br/>image.raw.003  (50331648 to 67108863)<br/>image.raw.004  (67108864 to 83886079)<br/>...</p>&#13;
<p class="indent">An alternative method for determining whether split files are supported is to run the command or tool with <span class="literal">strace -e open</span> and see if it opens each of the split file pieces.</p>&#13;
<p class="indent">Splitting files and working with a set of split files are useful, but sometimes you need to reassemble them into a single image. This is shown in the next section.</p>&#13;
<h4 class="h4" id="ch07lev2sec09"><em><strong>Reassemble a Split Image</strong></em></h4>&#13;
<p class="noindenta">Reassembling split forensic formats is generally not needed, because tools that are compatible with a particular forensic format (EWF, SMART, or AFF) should support split files.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_196"/>Because no header or meta information is contained in a raw image, reassembly is simply a matter of concatenating the set of image fragments into a single image. Doing this carefully should be a two-step process, as shown here:</p>&#13;
<p class="programs">$ <strong>ls -1 image.raw.*</strong><br/>image.raw.000<br/>image.raw.001<br/>image.raw.002<br/>image.raw.003<br/>...<br/>$ <strong>cat image.raw.* &gt; image.raw</strong></p>&#13;
<p class="indent">The <span class="literal">ls -1</span> flag will list the files recognized by the shell-globbing pattern. Be sure to confirm that this is a complete and ordered list before using it to concatenate the files into a single image. If split pieces are missing or the file order is wrong, the assembled parts will not create the correct forensic image.</p>&#13;
<p class="indent">If you’ve received a stack of DVDs, each containing a fragment of a compressed raw image, you can reassemble them as follows:</p>&#13;
<p class="programs">$ <strong>cat /dvd/image.raw.gz.00 &gt; image.raw.gz</strong><br/>$ <strong>cat /dvd/image.raw.gz.01 &gt;&gt; image.raw.gz</strong><br/>$ <strong>cat /dvd/image.raw.gz.02 &gt;&gt; image.raw.gz</strong><br/>$ <strong>cat /dvd/image.raw.gz.03 &gt;&gt; image.raw.gz</strong><br/>...</p>&#13;
<p class="indent">Here, DVDs are repeatedly inserted and mounted on <span class="literal">/dvd</span>, and split parts are added until the image file is restored. Note that <span class="literal">&gt;</span> in the initial cat command creates the image file, and <span class="literal">&gt;&gt;</span> in the subsequent commands appends the data (not overwriting it). After all parts have been appended to the destination file, the cryptographic hash of the uncompressed image should match the one taken during acquisition.</p>&#13;
<p class="indent">You can also uncompress and assemble a set of split files from a compressed image by piping all the split files into zcat and redirecting the output to a file:</p>&#13;
<p class="programs"># <strong>cat image.raw.gz.* | zcat &gt; image.raw</strong></p>&#13;
<p class="indent">A useful method provided by AFFlib allows for the <em>virtual reassembly</em> of a set of fragments using a FUSE filesystem. The affuse tool can present a set of split files as a fully assembled raw image file, as follows:</p>&#13;
<p class="programs"># <strong>ls</strong><br/>image.raw.000  image.raw.011  image.raw.022  image.raw.033  image.raw.044<br/>image.raw.001  image.raw.012  image.raw.023  image.raw.034  image.raw.045<br/>...<br/>#<br/># <strong>affuse image.raw.000 /mnt</strong><br/># <strong>ls -l /mnt</strong><br/>total 0<br/>-r--r--r-- 1 root root 8011120640 1970-01-01 01:00 image.raw.000.raw</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_197"/>Here, a directory full of raw files is represented as a single disk image file and is found in the <em>/mnt</em> virtual filesystem. You can directly operate on this raw file using forensic tools.</p>&#13;
<h3 class="h3" id="ch07lev1sec03"><strong>Verify the Integrity of a Forensic Image</strong></h3>&#13;
<p class="noindent">Verifying the cryptographic hash of an image is fundamental to performing digital forensics, and it’s the basis of preserving digital evidence. This section provides examples of verifying an image’s cryptographic hashes and signatures.</p>&#13;
<p class="indent">Verifying the preservation of evidence involves confirming that a current cryptographic hash of an image is identical to a hash taken at an earlier point in time. You can use hashing to verify a successful operation on a disk or image (acquisition, conversion, transfer, backup, and so on). You can also use it to verify that a disk or image file has not been tampered with over a longer period of time (months or even years).</p>&#13;
<p class="indent">The requirements for hashing (procedures and algorithms) depend on the legal jurisdiction where they are used and on the organizational policies governing a forensic lab. Thus, no hashing recommendations are provided here.</p>&#13;
<h4 class="h4" id="ch07lev2sec10"><em><strong>Verify the Hash Taken During Acquisition</strong></em></h4>&#13;
<p class="noindenta">After acquiring a disk, if you need to validate the acquisition hash, it’s a simple (but possibly time-consuming) task of piping the contents of the disk into a cryptographic hashing program. Using a different program to validate a disk’s hash provides an independent verification at the tool level. For example:</p>&#13;
<p class="programs"># <strong>img_stat image.E01</strong><br/>IMAGE FILE INFORMATION<br/>--------------------------------------------<br/>Image Type:             ewf<br/><br/>Size of data in bytes:  2003828736<br/>MD5 hash of data:       9749f1561dacd9ae85ac0e08f4e4272e<br/># <strong>dd if=/dev/sdj | md5sum</strong><br/>3913728+0 records in<br/>3913728+0 records out<br/>9749f1561dacd9ae85ac0e08f4e4272e  -<br/>2003828736 bytes (2.0 GB) copied, 126.639 s, 15.8 MB/s</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_198"/>Here, the img_stat output indicates the MD5 acquisition hash recorded by an EnCase imaging tool. A second tool, regular dd, is then used to recalculate the hash from the raw disk device. In this example, the two MD5 hashes match, confirming that the evidence integrity has been preserved.</p>&#13;
<h4 class="h4" id="ch07lev2sec11"><em><strong>Recalculate the Hash of a Forensic Image</strong></em></h4>&#13;
<p class="noindenta">Each of the forensic formats and the dd-based forensic tools can record or log a hash value of a disk image. To validate the recorded hash, you can recalculate the disk image’s hash. In the following example, the hash was recorded during acquisition with dc3dd and stored in the <em>hashlog.txt</em>. The hash can be verified as follows:</p>&#13;
<p class="programs"># <strong>grep "(md5)" hashlog.txt</strong><br/>   5dfe68597f8ad9f20600a453101f2c57 (md5)<br/># <strong>md5sum image.raw</strong><br/>5dfe68597f8ad9f20600a453101f2c57  image.raw</p>&#13;
<p class="indent">The hashes match, confirming that the evidence file and the hash log are consistent and thus indicating that the evidence integrity has been preserved.</p>&#13;
<p class="indent">The following example validates the image stored in the metadata of the EnCase format. In this example, a dedicated tool, ewfverify, is used to validate the hash:</p>&#13;
<p class="programs"># <strong>ewfverify image.Ex01</strong><br/>ewfverify 20160424<br/><br/>Verify started at: May 14, 2016 14:47:32<br/>This could take a while.<br/>...<br/>MD5 hash stored in file:                 5dfe68597f8ad9f20600a453101f2c57<br/>MD5 hash calculated over data:           5dfe68597f8ad9f20600a453101f2c57<br/><br/>ewfverify: SUCCESS</p>&#13;
<p class="indent">Here, the recalculated hash matches, confirming the consistency of the EWF image file. This tool will automatically validate the hash of a set of split files in the EnCase forensic format.</p>&#13;
<p class="indent">The affinfo tool performs similar validity checking for AFF files. In this example, the SHA1 hash is validated:</p>&#13;
<p class="programs">$ <strong>affinfo -S image.aff</strong><br/>image.aff is a AFF file<br/>...<br/>Validating SHA1 hash codes.<br/>computed sha1: 9871 0FB5 531E F390 2ED0 47A7 5BE4 747E 6BC1 BDB0<br/>  stored sha1: 9871 0FB5 531E F390 2ED0 47A7 5BE4 747E 6BC1 BDB0   MATCH</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_199"/>This output confirms that the hash of the image contained inside the AFF file is the same as the hash recorded in the AFF metadata.</p>&#13;
<h4 class="h4" id="ch07lev2sec12"><em><strong>Cryptographic Hashes of Split Raw Images</strong></em></h4>&#13;
<p class="noindenta">Calculating the cryptographic hash of a set of raw split files is straightforward, and you can do this by piping the concatenated parts into a hashing program. This example calculates the sha256 hash of a set of split raw files:</p>&#13;
<p class="programs">$ <strong>cat image.raw.* | sha256sum</strong><br/>12ef4b26e01eb306d732a314753fd86de099b02105ba534d1b365a232c2fd36a -</p>&#13;
<p class="indent">This example assumes the filenames of the parts can be sorted in the correct order (can be verified in this example with <span class="literal">ls -1 image.raw.*</span>). The <span class="literal">cat</span> command is necessary here, as it is concatenating (assembling) all of the pieces before they are piped into sha256sum.</p>&#13;
<p class="indent">You can verify the cryptographic hash of an image that has been compressed and split into pieces by forming a command pipeline of several programs. In the following example, cat assembles the image and pipes it into zcat for uncompression. The output of zcat is sent to the hashing program, which produces a hash value upon completion:</p>&#13;
<p class="programs">$ <strong>cat image.raw.gz.* | zcat | md5sum</strong><br/>9749f1561dacd9ae85ac0e08f4e4272e  -</p>&#13;
<p class="indent">Here, the <span class="literal">cat</span> command is necessary because it is concatenating all the split pieces before passing to zcat. Using <span class="literal">zcat image.raw.gz.*</span> will fail because it will try to uncompress each piece rather than the assembled image.</p>&#13;
<p class="indent">In the Unix community, <em>useless use of cat (UUOC)</em> describes using the <span class="literal">cat</span> command to send a file to command when <span class="literal">&lt;</span> could be used instead. Traditional Unix communities have given out UUOC awards to encourage more efficient use of shell command redirection. However, the examples in this section do need <span class="literal">cat</span> because they perform a concatenation function.</p>&#13;
<h4 class="h4" id="ch07lev2sec13"><em><strong>Identify Mismatched Hash Windows</strong></em></h4>&#13;
<p class="noindenta">As disks age, or as they are transported and handled, there’s a risk of damage, possibly introducing bad sectors. If an original evidence disk produces unreadable sector errors since it was first imaged, the cryptographic checksum for the disk will fail to match. Hash windows become valuable in this case, because you can use them to identify more precisely which part of the disk failed to match. More important, hash windows can show which areas of a disk are still preserved, even though the hash for the entire disk has failed to match.</p>&#13;
<p class="indent">The specified size of a hash window determines how often a new hash is written during the acquisition of a disk or when you’re verifying disk hash windows. When you’re comparing two lists of hashes for verification, both <span epub:type="pagebreak" id="page_200"/>lists must use the same size of hash window. To find the mismatching areas, you can compare the two hash logs using the Unix diff tool.</p>&#13;
<p class="indent">In the following example, a disk was imaged with dcfldd and a hash log with a 10M hash window size was saved. A subsequent verification failed to match the MD5 for the entire disk and provided a new hash log, also with a 10M hash window size:</p>&#13;
<p class="programs">$ <strong>diff hash1.log hash2.log</strong><br/>3c3<br/>&lt; 20971520 - 31457280: b587779d76eac5711e92334922f5649e<br/>---<br/>&gt; 20971520 - 31457280: cf6453e4453210a3fd8383ff8ad1511d<br/>193c193<br/>&lt; Total (md5): 9749f1561dacd9ae85ac0e08f4e4272e<br/>---<br/>&gt; Total (md5): fde1aa944dd8027c7b874a400a56dde1</p>&#13;
<p class="indent">This output reveals mismatched hashes for the full image and also for the range of bytes between 20971520 and 31457280. Dividing by the 512-byte sector size identifies the sector range between 40960 and 61440 where the hash mismatch occurred. The hashes on the rest of the disk are still good; only the sectors with mismatched hashes have not been forensically preserved. Content (blocks, files, portions of files, and so on) residing on a hash-mismatched sector range can be excluded from the presented evidence at a later stage. If two cryptographic hashes of a full image are a match, you can assume that all the hash windows also match.</p>&#13;
<p class="indent">The cryptographic hashes of forensic images preserve the integrity of collected evidence. However, the hash values themselves are not protected against malicious or accidental modification. Confirming the integrity of the calculated hashes can be preserved using cryptographic signing and time-stamping. Confirming the validity of signatures and timestamps is shown in the next section.</p>&#13;
<h4 class="h4" id="ch07lev2sec14"><em><strong>Verify Signature and Timestamp</strong></em></h4>&#13;
<p class="noindenta">The previous chapter demonstrated the use of GnuPG to sign a disk’s hashes. You can verify the signature without having the signing private key. The original person who signed the evidence is not needed; only their public key is needed. This example verifies the gpg signature of the person who signed the acquired disk image:</p>&#13;
<p class="programs">$ <strong>gpg &lt; hash.log.asc</strong><br/><br/>dc3dd 7.2.641 started at 2016-05-07 17:23:49 +0200<br/>compiled options:<br/>command line: dc3dd if=/dev/sda hof=image.raw ofs=image.000 ofsz=1G hlog=hash.log<br/>   hash=md5<br/>input results for device `/dev/sda':<br/>   5dfe68597f8ad9f20600a453101f2c57 (md5)<br/>...<br/>dc3dd completed at 2016-05-07 17:25:40 +0200<br/><br/>gpg: Signature made Sat 07 May 2016 17:29:44 CEST using RSA key ID CF87856B<br/>gpg: Good signature from "Sherlock Holmes &lt;holmes@digitalforensics.ch&gt;"</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_201"/>Here, the contents of the signed message (the acquisition output and hash) are displayed together with a gpg message indicating that the signature is valid.</p>&#13;
<p class="indent">For S/MIME signed messages, a similar command will validate (or invalidate) the signature from a PEM file and looks like this:</p>&#13;
<p class="programs">$ <strong>gpgsm --verify image.log.pem</strong><br/>gpgsm: Signature made 2016-01-25 19:49:42 using certificate ID 0xFFFFFFFFABCD1234<br/>...<br/>gpgsm: Good signature from "/CN=holmes@digitalforensics.ch/EMail=holmes@<br/>    digitalforensics.ch"<br/>gpgsm:                 aka "holmes@digitalforensics.ch"</p>&#13;
<p class="indent"><a href="ch06.xhtml#ch06">Chapter 6</a> discussed using timestamping services to generate RFC-3161 timestamps from a timestamp authority. Validating a timestamp is similar to validating a signature with S/MIME and requires the correct chain of certificate authority (CA) certificates to be installed for verification to be successful. This example verifies the previous timestamp created with FreeTSA (<em><a href="http://freetsa.org/">http://freetsa.org/</a></em>).</p>&#13;
<p class="indent">If the timestamping service’s CA certificate is not installed on your system, it can be manually fetched. The TSA certificate should have been returned as part of the timestamp when the request was made (because of the <span class="literal">-cert</span> flag). For this example, the CA cert is fetched from FreeTSA as follows:</p>&#13;
<p class="programs">$ <strong>curl http://freetsa.org/files/cacert.pem &gt; cacert.pem</strong></p>&#13;
<p class="indent">Assuming CA and TSA certificates are available to OpenSSL and valid, you can validate the timestamp as follows:</p>&#13;
<p class="programs">$ <strong>openssl ts -verify -in hash.log.tsr -queryfile hash.log.tsq -CAfile cacert.pem</strong><br/>Verification: OK</p>&#13;
<p class="indent">The <span class="literal">openssl ts</span> command is used to verify the timestamp. The timestamp query (<span class="literal">tsq</span>) and timestamp reponse (<span class="literal">tsr</span>) are provided, and in this example, the file containing the timestamp server’s CA certificate is specified. The third-party timestamp is valid (<span class="literal">Verification: OK</span>), indicating that the file (and the forensic acquisition hashes it contains) has not been modified <span epub:type="pagebreak" id="page_202"/>since the specified time. If a particular timestamp authority is expected to be used permanently, you can add the CA certificates to the OS’s trusted CA store.</p>&#13;
<p class="indent">AFFlib also has provisions for signing and validating signatures for acquired images using X.509 certificates.</p>&#13;
<p class="indent">This section did not discuss the web-of-trust or the public key infrastructure (PKI) needed to trust the keys being used to sign images and verify timestamps. The examples assume this trust is already established.</p>&#13;
<h3 class="h3" id="ch07lev1sec04"><strong>Convert Between Image Formats</strong></h3>&#13;
<p class="noindent">Converting between forensic image formats can be advantageous for various reasons. If a lab has new software or infrastructure and the current format is unsupported or less efficient, converting to another format could be an option. If you’ll be transferring an image to a third party, they might have a preferred image format. If you are receiving an image from a third party, you might want to convert it to your preferred format. This section provides examples of converting between formats on the command line. Conversion from a few source formats is shown, including EnCase, FTK, AFF, and raw images. In addition, the examples demonstrate converting various formats into SquashFS evidence containers.</p>&#13;
<p class="indent">When you’re converting between image formats, it’s preferable to use pipes and redirection. Avoid tools that use temporary files. During the conversion process, two copies of an image might coexist (one or both might be compressed). To prepare for the conversion process, do some capacity planning.</p>&#13;
<p class="indent">After conversion, check the hash values from the original image and the destination to ensure a match.</p>&#13;
<h4 class="h4" id="ch07lev2sec15"><em><strong>Convert from Raw Images</strong></em></h4>&#13;
<p class="noindenta">Converting a raw image to another format is usually straightforward, because you can use regular disk-imaging functionality. Instead of a raw device name, the filename of the raw image is used.</p>&#13;
<p class="indent">The following examples show a raw image file being converted into EnCase and FTK formats. The first example uses <span class="literal">ewfacquire</span> to convert <em>image.raw</em> to EnCase Expert Witness format:</p>&#13;
<p class="programs">$ <strong>ewfacquire image.raw -t image -f encase7</strong><br/>ewfacquire 20160424<br/><br/>Storage media information:<br/>Type:                                   RAW image<br/>Media size:                             7.9 GB (7918845952 bytes)<br/>Bytes per sector:                       512<br/><br/>Acquiry parameters required, please provide the necessary input<br/>Case number: 42<br/>Description: The case of the missing red stapler<br/>Evidence number: 1<br/>Examiner name: S. Holmes<br/>Notes: This red USB stick was found at the scene<br/>...<br/>Acquiry completed at: May 14, 2016 15:03:40<br/><br/>Written: 7.3 GiB (7918846140 bytes) in 54 second(s) with 139 MiB/s<br/>    (146645298 bytes/second)<br/>MD5 hash calculated over data:          5dfe68597f8ad9f20600a453101f2c57<br/>ewfacquire: SUCCESS</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_203"/>Here, the specified source file is the raw image; <span class="literal">-t</span> is the base name of the EnCase target <em>*.e01</em> files. EnCase version 7 was specified, and when the command is executed, a series of questions is asked. Because the raw file has no case metadata, you need to enter it manually.</p>&#13;
<p class="indent">Converting from a raw image to FTK SMART is similar: you specify the raw image as a source and manually add the case metadata. Using ftkimage, you specify the case metadata on the command line, as shown in this example:</p>&#13;
<p class="programs">$ <strong>ftkimager image.raw image --s01 --case-number 1 --evidence-number 1 --description</strong><br/>    <strong>"The case of the missing red stapler" --examiner "S. Holmes" --notes "This USB</strong><br/>    <strong>stick was found at the scene"</strong><br/>AccessData FTK Imager v3.1.1 CLI (Aug 24 2012)<br/>Copyright 2006-2012 AccessData Corp., 384 South 400 West, Lindon, UT 84042<br/>All rights reserved.<br/><br/>Creating image...<br/>Image creation complete.</p>&#13;
<p class="indent">The <span class="literal">--s01</span> flag specifies that a SMART compressed image will be created. The base filename is specified simply as <span class="literal">image</span>, and appropriate file extensions will be automatically added.</p>&#13;
<p class="indent">Converting an image to a SquashFS forensic evidence container is also just a simple command if you use the sfsimage script, like this:</p>&#13;
<p class="programs">$ <strong>sfsimage -i image.raw image.sfs</strong><br/>Started: 2016-05-14T15:14:13<br/>Sfsimage version: Sfsimage Version 0.8<br/>Sfsimage command: /usr/bin/sfsimage -i image.raw<br/>Current working directory: /exam<br/>Forensic evidence source: if=/exam/image.raw<br/>Destination squashfs container: image.sfs<br/>Image filename inside container: image.raw<br/>Aquisition command: sudo dc3dd if=/exam/image.raw log=errorlog.txt hlog=hashlog.txt<br/>    hash=md5 2&gt;/dev/null | pv -s 7918845952<br/>7.38GiB 0:00:22 [ 339MiB/s] [=================================&gt;] 100%<br/>Completed: 2016-05-14T15:14:37</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_204"/>Here, the raw image file was specified together with the destination SquashFS container filename. The sfsimage script builds the required SquashFS pseudo device and adds the log and hash information as regular text files. You can append additional case metadata to the evidence container manually (with <span class="literal">sfsimage -a</span>).</p>&#13;
<p class="indent">You can’t directly access a gzip compressed raw image using typical forensic tools because of the inability to seek (randomly access any block within the file) within a gzip file. It’s best to convert such files into compressed formats that are seekable. Then you can operate on them directly using forensic analysis tools. In this example, a gzipped raw image file is converted into a SquashFS compressed file using sfsimage:</p>&#13;
<p class="programs">$ <strong>zcat image.raw.gz | sfsimage -i - image.sfs</strong><br/>Started: 2016-05-14T15:20:39<br/>Sfsimage version: Sfsimage Version 0.8<br/>Sfsimage command: /usr/bin/sfsimage -i -<br/>Current working directory: /exam<br/>Forensic evidence source:<br/>Destination squashfs container: image.sfs<br/>Image filename inside container: image.raw<br/>Aquisition command: sudo dc3dd   log=errorlog.txt hlog=hashlog.txt hash=md5<br/>    2&gt;/dev/null | pv -s 0<br/>7.38GiB 0:00:38 [ 195MiB/s] [     &lt;=&gt; ]<br/>Completed: 2016-05-14T15:21:18</p>&#13;
<p class="indent">The original file remains in raw form, but it’s now inside a compressed filesystem. You can mount the resulting <em>*.sfs</em> file to access the raw image, as shown here:</p>&#13;
<p class="programs">$ <strong>sfsimage -m image.sfs</strong><br/>image.sfs.d mount created<br/>$ <strong>ls image.sfs.d/</strong><br/>errorlog.txt  hashlog.txt  image.raw  sfsimagelog.txt</p>&#13;
<p class="indent">You can convert a raw image file into an AFF file by using a simple <span class="literal">affconvert</span> command:</p>&#13;
<p class="programs">$ <strong>affconvert image.raw</strong><br/>convert image.raw --&gt; image.aff<br/>Converting <a href="ch05.xhtml#page_119">page 119</a> of 119<br/>md5: 9749f1561dacd9ae85ac0e08f4e4272e<br/>sha1: 98710fb5531ef3902ed047a75be4747e6bc1bdb0<br/>bytes converted: 2003828736<br/>Total pages: 120  (117 compressed)<br/>Conversion finished.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_205"/>Then you can add the case metadata with a separate tool, such as affsegment. The affconvert tool provides sensible defaults for compression, and the resulting file has the <em>*.aff</em> extension with the basename of the raw file.</p>&#13;
<p class="indent">The following and final example shows the conversion of a raw image inside a SquashFS forensic evidence container to an AFF file using the <span class="literal">affconvert</span> command:</p>&#13;
<p class="programs"># <strong>affconvert -Oaff image.sfs.d/image.raw</strong><br/>convert image.sfs.d/image.raw --&gt; aff/image.aff<br/>Converting page 953 of 953<br/>md5: d469842a3233cc4e7d4e77fd81e21035<br/>sha1: 9ad205b1c7889d0e4ccc9185efce2c4b9a1a8ec6<br/>bytes converted: 16001269760<br/>Total pages: 954  (954 compressed)<br/>Conversion finished.</p>&#13;
<p class="indent">Because SquashFS is read-only, you need to tell <span class="literal">affconvert</span> to write the output file to a different directory that is writable.</p>&#13;
<h4 class="h4" id="ch07lev2sec16"><em><strong>Convert from EnCase/E01 Format</strong></em></h4>&#13;
<p class="noindenta">The libewf package contains the ewfexport tool for converting EnCase EWF (<em>*.E0*</em>) files to other formats. This includes the ability to read one or more files and pipe them into other programs.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong>NOTE</strong></p>&#13;
<p class="notep"><em>There is a bug in some older versions of ewfexport that appends the line</em> <span class="literal"><span class="codeitalic">ewfexport: SUCCESS</span></span> <em>to the end of an image after an export to stdout. This added string will cause a mismatch in the image MD5 hashes. The string is a fixed length of 19 bytes, so you can suppress it by piping it through</em> <span class="literal"><span class="codeitalic">tail -c 19</span></span>.</p>&#13;
</div>&#13;
<h5 class="h5" id="ch07lev3sec01"><strong>Manual Creation of a SquashFS Container</strong></h5>&#13;
<p class="noindenta">Throughout the book, you’ve seen examples of the sfsimage shell script. But it’s useful to see one example of creating a SquashFS file without the script. This next example will make it easier to understand how sfsimage works internally.</p>&#13;
<p class="indent">The following EnCase acquisition contains 54 <em>*.E0</em> files that will be assembled into a single raw image and placed into a SquashFS evidence container:</p>&#13;
<p class="programs"># <strong>ls</strong><br/>image.E01  image.E10  image.E19  image.E28  image.E37  image.E46<br/>image.E02  image.E11  image.E20  image.E29  image.E38  image.E47<br/>image.E03  image.E12  image.E21  image.E30  image.E39  image.E48<br/>image.E04  image.E13  image.E22  image.E31  image.E40  image.E49<br/>image.E05  image.E14  image.E23  image.E32  image.E41  image.E50<br/>image.E06  image.E15  image.E24  image.E33  image.E42  image.E51<br/>image.E07  image.E16  image.E25  image.E34  image.E43  image.E52<br/>image.E08  image.E17  image.E26  image.E35  image.E44  image.E53<br/>image.E09  image.E18  image.E27  image.E36  image.E45  image.E54</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_206"/>To begin, you need a mksquashfs pseudo definition file to define the commands that will create files inside the SquashFS container. The pseudo definition file contains the target filename, file type, permissions, ownership, and command to be executed. The output of that command will become the contents of the defined filename inside the SquashFS filesystem.</p>&#13;
<p class="indent">In the following example, a file named <em>pseudo_files.txt</em> has been created that contains two definitions. The first extracts the EnCase metadata with ewfinfo and places it into <em>image.txt</em> (this metadata would otherwise be lost). The second definition exports a raw image from the <em>*.E0</em> files into <em>image.raw</em>:</p>&#13;
<p class="programs"># <strong>cat pseudo_files.txt</strong><br/>image.txt f 444 root root ewfinfo image.E01<br/>image.raw f 444 root root ewfexport -u -t - image.E01</p>&#13;
<p class="indent">The <span class="literal">ewfexport</span> flag <span class="literal">-u</span> allows the conversion to execute unattended (otherwise it prompts the user with questions). The <span class="literal">-t</span> flag specifies the target, which in this example is stdout or the dash <span class="literal">-</span>.</p>&#13;
<p class="indent">With this definition file, you can create the compressed filesystem containing the generated files as follows:</p>&#13;
<p class="programs"># <strong>mksquashfs pseudo_files.txt image.sfs -pf pseudo_files.txt</strong><br/>Parallel mksquashfs: Using 12 processors<br/>Creating 4.0 filesystem on image.sfs, block size 131072.<br/>ewfexport 20160424<br/><br/><br/>Export started at: May 12, 2016 19:09:42<br/>This could take a while.<br/>...<br/>Export completed at: May 12, 2016 19:28:56<br/><br/>Written: 113 GiB (121332826112 bytes) in 19 minute(s) and 14 second(s) with<br/>    100 MiB/s (105141097 bytes/second)<br/>MD5 hash calculated over data:          083e2131d0a59a9e3b59d48dbc451591<br/>ewfexport: SUCCESS<br/>...<br/>Filesystem size 62068754.40 Kbytes (60614.02 Mbytes)<br/>        52.38% of uncompressed filesystem size (118492706.13 Kbytes)<br/>...</p>&#13;
<p class="indent">The resulting SquashFS filesystem <em>image.sfs</em> will contain three files: the raw image file <em>image.raw</em>, <em>image.txt</em> containing the metadata, and the <em>pseudo_files.txt</em> file containing the definitions with the executed commands. <span epub:type="pagebreak" id="page_207"/>The mksquashfs(1) manual page has more information about the flags and options for creating SquashFS file systems.</p>&#13;
<p class="indent">You can view the contents of a SquashFS file with the <span class="literal">unsquashfs</span> command as follows:</p>&#13;
<p class="programs"># <strong>unsquashfs -lls image.sfs</strong><br/>...<br/>-r--r--r-- root/root      121332826112 2016-05-12 19:09 squashfs-root/image.raw<br/>-r--r--r-- root/root               770 2016-05-12 19:09 squashfs-root/image.txt<br/>-rw-r----- root/root                98 2016-05-12 16:58 squashfs-root/<br/>    pseudo_files.txt</p>&#13;
<p class="indent">The final step is to verify the preservation of evidence by comparing MD5 hash values. The <span class="literal">ewfinfo</span> command provides the MD5 hash calculated during the original EnCase acquisition. A second MD5 checksum can be calculated with md5sum on the newly converted raw image inside the SquashFS container. To do this, you need to mount the SquashFS filesystem first. The following example shows each of these steps:</p>&#13;
<p class="programs"># <strong>ewfinfo image.E01</strong><br/>ewfinfo 20160424<br/>...<br/>Digest hash information<br/>        MD5:                    083e2131d0a59a9e3b59d48dbc451591<br/><br/># <strong>mkdir image.sfs.d; mount image.sfs image.sfs.d</strong><br/># <strong>md5sum image.sfs.d/image.raw</strong><br/>083e2131d0a59a9e3b59d48dbc451591  image.sfs.d/image.raw</p>&#13;
<p class="indent">The result shows that the two MD5 hashes match, indicating a successfully preserved evidence conversion from EnCase to a raw image inside a SquashFS container. A third matching MD5 hash can be seen in the ewfexport output that was calculated during the conversion process. The ewfexport tool can also convert, or export, to other EnCase formats.</p>&#13;
<p class="indent">When the mounted SquashFS filesystem <em>image.sfs.d</em> is no longer needed, it can be unmounted with <span class="literal">umount image.sfs.d</span>. The sfsimage script manages these steps for you.</p>&#13;
<h5 class="h5" id="ch07lev3sec02"><strong>Convert Files from EnCase to FTK</strong></h5>&#13;
<p class="noindenta">The ftkimager tool can convert from EnCase to FTK. In this example, a set of EnCase <em>*.e01</em> files are converted to SMART ew-compressed files with the same name but with the <em>*.s01</em> extension:</p>&#13;
<p class="programs"># <strong>ftkimager image.E01 image --s01</strong><br/>AccessData FTK Imager v3.1.1 CLI (Aug 24 2012)<br/>Copyright 2006-2012 AccessData Corp., 384 South 400 West, Lindon, UT 84042<br/>All rights reserved.<br/>Creating image...<br/>Image creation complete.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_208"/>Hashes are checked and added to the new FTK file. The original case metadata is not added to the newly converted files. Instead, it’s extracted from the original format and saved as a separate file with the same name but with a <em>*.txt</em> extension (<em>image.s01.txt</em> in this example).</p>&#13;
<h4 class="h4" id="ch07lev2sec17"><em><strong>Convert from FTK Format</strong></em></h4>&#13;
<p class="noindenta">The command line ftkimager tool converts between EnCase and FTK formats, and it allows you to use stdin and stdout for conversion with raw image files.</p>&#13;
<p class="indent">In the following example, a set of compressed FTK SMART <em>*.s01</em> files are converted to the EnCase EWF *E01 format:</p>&#13;
<p class="programs"># <strong>ftkimager image.s01 image --e01</strong><br/>AccessData FTK Imager v3.1.1 CLI (Aug 24 2012)<br/>Copyright 2006-2012 AccessData Corp., 384 South 400 West, Lindon, UT 84042<br/>All rights reserved.<br/><br/>Creating image...<br/>Image creation complete.</p>&#13;
<p class="indent">The case metadata is not transferred to the new format but is automatically saved to a separate file (<em>image.E01.txt</em>).</p>&#13;
<p class="indent">The ftkimager can convert SMART <em>*.s01</em> files to stdout, where you can redirect them to raw image files or pipe them into other programs. In the following example, a set of FTK SMART files are converted into a SquashFS forensic evidence container using ftkimager output piped into sfsimage:</p>&#13;
<p class="programs"># <strong>ftkimager sandisk.s01 - | sfsimage -i - sandisk.sfs</strong><br/>Started: 2016-05-12T19:59:13<br/>Sfsimage version: Sfsimage Version 0.8<br/>Sfsimage command: /usr/bin/sfsimage -i -<br/>Current working directory: /exam<br/>Forensic evidence source:<br/>Destination squashfs container: sandisk.sfs<br/>Image filename inside container: image.raw<br/>Aquisition command: sudo dc3dd   log=errorlog.txt hlog=hashlog.txt hash=md5<br/>    2&gt;/dev/null | pv -s 0<br/>AccessData FTK Imager v3.1.1 CLI (Aug 24 2012)<br/>Copyright 2006-2012 AccessData Corp., 384 South 400 West, Lindon, UT 84042<br/>All rights reserved.<br/><br/>14.5GiB 0:01:37 [ 151MiB/s] [    &lt;=&gt;    ]<br/>Completed: 2016-05-12T20:00:51<br/># <strong>sfsimage -a sandisk.s01.txt sandisk.sfs</strong><br/>Appending to existing 4.0 filesystem on sandisk.sfs, block size 131072</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_209"/>When you’re converting from an FTK format into a raw disk image, the case metadata is not transferred. You need to manually save the case metadata, which is usually found in a separate text file. You can add this to the SquashFS container as shown in the previous example with the <span class="literal">sfsimage -a</span> command.</p>&#13;
<p class="indent">After performing a format conversion of any kind, you should verify the hash value separately on the destination format to ensure the evidence integrity has been preserved.</p>&#13;
<h4 class="h4" id="ch07lev2sec18"><em><strong>Convert from AFF Format</strong></em></h4>&#13;
<p class="noindenta">The affconvert tool can convert AFF images to a raw image (and from a raw image to the AFF format). The affconvert tool does not use stdin or stdout; instead, it reads or creates stand-alone files. The following simple example shows converting an AFF file to a raw image:</p>&#13;
<p class="programs">$ <strong>affconvert -r image.aff</strong><br/>convert image.aff --&gt; image.raw<br/>Converting <a href="ch04.xhtml#page_96">page 96</a> of 96<br/>bytes converted: 1625702400<br/>Conversion finished.</p>&#13;
<p class="indent">To convert a raw image to an AFF format, simply use <span class="literal">affconvert image.raw</span>, and the corresponding <em>image.aff</em> file will be created.</p>&#13;
<p class="indent">To use piping and redirection with AFF files, you can use the affcat tool. The previous example can be also be done with <span class="literal">affcat</span> and redirected to a file (without any status or completion information, which is useful for scripts) as follows:</p>&#13;
<p class="programs">$ <strong>affcat image.aff &gt; image.raw</strong></p>&#13;
<p class="indent">To convert an AFF image to EnCase or FTK, the affcat tool can pipe an image via stdout or stdin into the appropriate tool, creating a new image in the desired format. For example, you can convert from AFF to a compressed FTK SMART image like this:</p>&#13;
<p class="programs">$ <strong>affcat image.aff | ftkimager - image --s01</strong><br/>AccessData FTK Imager v3.1.1 CLI (Aug 24 2012)<br/>Copyright 2006-2012 AccessData Corp., 384 South 400 West, Lindon, UT 84042<br/>All rights reserved.<br/><br/>Creating image...<br/>Image creation complete.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_210"/>Here, the <span class="literal">-</span> represents the stdin file descriptor receiving the raw image data, <span class="literal">image</span> is the base filename, and the final flag <span class="literal">--s01</span> specifies the compressed format.</p>&#13;
<p class="indent">Similarly, you can convert to various EnCase formats using efwacquirestream. For example:</p>&#13;
<p class="programs">$ <strong>affcat image.aff | ewfacquirestream -C 42 -E 1 -e "S. Holmes" -D "Data theft</strong><br/>    <strong>case" image</strong><br/>ewfacquirestream 20160424<br/><br/>Using the following acquiry parameters:<br/>Image path and filename:                image.E01<br/>Case number:                            42<br/>Description:                            Data theft case<br/>Evidence number:                        1<br/>Examiner name:                          S. Holmes<br/>...<br/>Acquiry completed at: May 14, 2016 15:41:42<br/><br/>Written: 1.8 GiB (2003934492 bytes) in 10 second(s) with 191 MiB/s (200393449<br/>    bytes/second)<br/>MD5 hash calculated over data:          9749f1561dacd9ae85ac0e08f4e4272e<br/>ewfacquirestream: SUCCESS</p>&#13;
<p class="indent">In the previous AFF conversion examples, the case metadata (case name, examiner name, acquisition times, hashes, and so on) is not preserved in the conversion from AFF to other formats. But you can export this information using affinfo and then add or save it manually to the destination format. Depending on the tool, you can also include metadata as command line flags as seen in the previous example with <span class="literal">-C 42 -E 1 -e "S. Holmes" -D "Data theft case"</span>.</p>&#13;
<p class="indent">This final example demonstrates converting an AFF file to a compressed SquashFS forensic evidence container using sfsimage:</p>&#13;
<p class="programs">$ <strong>affcat image.aff | sfsimage -i - image.sfs</strong><br/>Started: 2016-05-14T15:47:19<br/>Sfsimage version: Sfsimage Version 0.8<br/>Sfsimage command: /usr/bin/sfsimage -i -<br/>Current working directory: /exam<br/>Forensic evidence source:<br/>Destination squashfs container: image.sfs<br/>Image filename inside container: image.raw<br/>Aquisition command: sudo dc3dd   log=errorlog.txt hlog=hashlog.txt hash=md5<br/>    2&gt;/dev/null | pv -s 0<br/>1.87GiB 0:00:06 [ 276MiB/s] [          &lt;=&gt;         ]<br/>Completed: 2016-05-14T15:47:26</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_211"/>You can extract the metadata from AFF files using affinfo and then add it to the SquashFS forensic evidence container as follows:</p>&#13;
<p class="programs">$ <strong>affinfo image.aff &gt; affinfo.txt</strong><br/>$ <strong>sfsimage -a affinfo.txt image.sfs</strong><br/>Appending to existing 4.0 filesystem on image.sfs, block size 131072</p>&#13;
<p class="indent">Once the image is converted, compare the hash values of the original image and the destination to ensure a match.</p>&#13;
<h3 class="h3" id="ch07lev1sec05"><strong>Secure an Image with Encryption</strong></h3>&#13;
<p class="noindent">An important but often neglected component of digital forensics is information security. You should consider the information you acquire and extract during an investigation as sensitive and adequately protect its security.</p>&#13;
<p class="indent">The loss of data confidentiality may have undesired consequences. For example, it may violate organizational policy requirements, jeopardize legal and regulatory compliance, raise victim privacy issues, and do damage to the reputation of the investigating organization. Failing to adequately protect acquired evidence could result in damage to any of the parties involved, including the investigators and their employer, the victim, the defendant, and other participating parties. Leaked information could also interfere with or compromise an ongoing investigation.</p>&#13;
<p class="indent">This section focuses on methods for ensuring that information is protected, in particular, maintaining security during data transfer and storage (both long- and short-term storage). Adding security to images increases the complexity and the time needed to encrypt and then later decrypt the images, but the examples you’ll see here attempt to keep this process as simple and efficient as possible. Basic symmetric encryption is used instead of more complex PKI or web-of-trust systems.</p>&#13;
<p class="indent">In addition to the methods shown in this section, the ZIP archive format could be used for encryption. Newer versions with the ZIP64 extensions support file sizes larger than 4GB. ZIP has the advantage of high compatability with other platforms such as Windows.</p>&#13;
<h4 class="h4" id="ch07lev2sec19"><em><strong>GPG Encryption</strong></em></h4>&#13;
<p class="noindenta">Using symmetric encryption, you can easily encrypt disk images for protection during network transfer or storage. GNU Privacy Guard (GPG) encryption provides a free implementation of the OpenPGP standard defined by RFC-4880. It’s an alternative to the traditional PGP encryption created by PhilZimmerman in the early 1990s.</p>&#13;
<p class="indent">It’s useful to start the agent when you’re using GPG. (The agent is started automatically when using gpg2.) This is typically done at login with the following command:</p>&#13;
<p class="programs">$ <strong>eval $(gpg-agent --daemon)</strong></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_212"/>For all the examples that follow, the <span class="literal">-v</span> flag is used to increase verbosity. This makes the output more useful for documentation purposes (both in this book and for creating formal forensic reports describing the steps taken).</p>&#13;
<p class="indent">Using GPG to encrypt an existing image is very simple, as shown here:</p>&#13;
<p class="programs">$ <strong>gpg -cv image.raw</strong><br/>gpg: using cipher AES<br/>gpg: writing to `image.raw.gpg'<br/>Enter passphrase:</p>&#13;
<p class="indent">A passphrase is requested, and the image is encrypted with the default symmetric encryption algorithm, creating a new file with the extension <em>.gpg</em>. The size of the image is smaller because GPG compresses as it encrypts. This can be seen here:</p>&#13;
<p class="programs">$ <strong>ls -lh</strong><br/>total 1.2G<br/>-r--r----- 1 holmes holmes 1.9G May 14 15:56 image.raw<br/>-rw-r----- 1 holmes holmes 603M May 14 15:57 image.raw.gpg</p>&#13;
<p class="indent">The previous example showed encrypting a file in place. But you can also encrypt on the fly during acquisition:</p>&#13;
<p class="programs">$ <strong>sudo dcfldd if=/dev/sde | gpg -cv &gt; image.raw.gpg</strong><br/>Enter passphrase:<br/>gpg: using cipher AES<br/>gpg: writing to stdout<br/>241664 blocks (7552Mb) written.<br/>241664+0 records in<br/>241664+0 records out</p>&#13;
<p class="indent">Here, dcfldd acquires the attached disk via <em>/dev/sde</em> and pipes it directly into the GPG program. The encrypted output of GPG is then redirected to a file. The <span class="literal">sudo</span> command escalates privileges to root in order to read the raw device.</p>&#13;
<p class="indent">Decrypting a GPG-encrypted image is just as simple as encrypting one. The only differences are the use of the decryption flag and the requirement to specify an output file (by default, it outputs to stdout). In the following example, a GPG-encrypted image file is decrypted to a regular (unprotected) file:</p>&#13;
<p class="programs">$ <strong>gpg -dv -o image.raw image.raw.gpg</strong><br/>gpg: AES encrypted data<br/>Enter passphrase:<br/>gpg: encrypted with 1 passphrase<br/>gpg: original file name='image.raw'</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_213"/>This example demonstrates symmetric encryption without signing. You can also use GPG public and private keys to encrypt, decrypt, and sign images. The integrity is verified by comparing the hash of the GPG-encrypted image with the hash of the raw image file, as follows:</p>&#13;
<p class="programs">$ <strong>gpg -dv image.raw.gpg | md5sum</strong><br/>gpg: AES encrypted data<br/>Enter passphrase:<br/>gpg: encrypted with 1 passphrase<br/>gpg: original file name='image.raw'<br/>5dfe68597f8ad9f20600a453101f2c57  -<br/><strong>md5sum image.raw</strong><br/>5dfe68597f8ad9f20600a453101f2c57  image.raw</p>&#13;
<p class="indent">When you’re decrypting an image, you need to do some capacity planning. After decryption, two copies of the image will exist (one or both will be compressed).</p>&#13;
<p class="indent">A GPG-encrypted file is not seekable, so you cannot operate on its contents directly with forensic analysis tools.</p>&#13;
<h4 class="h4" id="ch07lev2sec20"><em><strong>OpenSSL Encryption</strong></em></h4>&#13;
<p class="noindenta">Other cryptographic systems can also provide security for disk images. The OpenSSL toolkit (<em><a href="http://www.openssl.org/">http://www.openssl.org/</a></em>) provides a number of algorithms you can use to encrypt files. For example, to password encrypt an image with 256-bit AES using cipher block chaining mode, use this command:</p>&#13;
<p class="programs"># <strong>openssl enc -aes-256-cbc -in image.raw -out image.raw.aes</strong><br/>enter aes-256-cbc encryption password:<br/>Verifying - enter aes-256-cbc encryption password:</p>&#13;
<p class="indent">OpenSSL is flexible regarding cipher types and modes, providing dozens of choices. Also supported are piping and redirection, and you can easily perform encryption during acquisition, for example:</p>&#13;
<p class="programs"># <strong>dcfldd if=/dev/sdg | openssl enc -aes-256-cbc &gt; image.raw.aes</strong><br/>enter aes-256-cbc encryption password:<br/>Verifying - enter aes-256-cbc encryption password:<br/>241664 blocks (7552Mb) written.<br/>241664+0 records in<br/>241664+0 records out</p>&#13;
<p class="indent">Decrypting an OpenSSL-encrypted file is also relatively straightforward, provided you know the encryption algorithm, as shown here:</p>&#13;
<p class="programs"># <strong>openssl enc -d -aes-256-cbc -in image.raw.aes -out image.raw</strong><br/>enter aes-256-cbc decryption password:</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_214"/>The addition of the <span class="literal">-d</span> flag signifies this is a decryption operation (<span class="literal">enc</span> specifies that symmetric ciphers are being used). Because OpenSSL doesn’t provide an automatic method to detect which symmetric encryption was used, it’s important to document how the file was encrypted.</p>&#13;
<p class="indent">Unless specifically compiled with zlib, OpenSSL doesn’t compress files. To add compression on the fly during an acquisition, add gzip to the pipeline, like this:</p>&#13;
<p class="programs"># <strong>dcfldd if=/dev/sdg | gzip | openssl enc -aes-256-cbc &gt; image.raw.gz.aes</strong><br/>enter aes-256-cbc encryption password:<br/>Verifying - enter aes-256-cbc encryption password:<br/>241664 blocks (7552Mb) written.<br/>241664+0 records in<br/>241664+0 records out</p>&#13;
<p class="indent">To verify the cryptographic hash of the image, you can run a similar command pipe, as follows:</p>&#13;
<p class="programs">$ <strong>openssl enc -d -aes-256-cbc &lt; image.raw.gz.aes | gunzip | md5sum</strong><br/>enter aes-256-cbc decryption password:<br/>4f9f576113d981ad420bbc9c251bea0c  -</p>&#13;
<p class="indent">Here, the decryption command takes the compressed and encrypted file as input and pipes the decrypted output to gunzip, which outputs the raw image to the hashing program.</p>&#13;
<p class="indent">Some implementations of ZIP also support built-in encryption and can be used to secure images and other evidence files.</p>&#13;
<h4 class="h4" id="ch07lev2sec21"><em><strong>Forensic Format Built-In Encryption</strong></em></h4>&#13;
<p class="noindenta">GPG and OpenSSL are well-known tools for performing various encryption tasks, providing compatibility and interoperability with other tools. However, they’re not designed for digital forensics, and encrypted image files cannot be used directly by standard forensic tools (they must be decrypted first). Some versions of the popular forensic formats discussed throughout this book support randomly accessible encrypted images.</p>&#13;
<p class="indent">The ftkimager program can protect image files using a password or a certificate. An example of encrypting with a password (<em>monkey99</em>) during acquisition is shown here:</p>&#13;
<p class="programs"># <strong>ftkimager --outpass monkey99 --e01 /dev/sdg image</strong><br/>AccessData FTK Imager v3.1.1 CLI (Aug 24 2012)<br/>Copyright 2006-2012 AccessData Corp., 384 South 400 West, Lindon, UT 84042<br/>All rights reserved.<br/><br/>Creating image...<br/>Image creation complete.</p>&#13;
<div class="note">&#13;
<p class="notet"><span epub:type="pagebreak" id="page_215"/><strong>NOTE</strong></p>&#13;
<p class="notep"><em>Including a password in command parameters is generally bad practice. The password is visible in the shell history, and anyone can view the password in the process table.</em></p>&#13;
</div>&#13;
<p class="indent">Attempting to access an encrypted image without a password, or with the incorrect password, will generate the following error messages:</p>&#13;
<p class="programs">** Source is encrypted; please provide credentials for decryption.<br/>** AD Decryption setup failed.</p>&#13;
<p class="indent">Operating on an encrypted image requires including the password on the command line, as follows:</p>&#13;
<p class="programs"># <strong>ftkimager --inpass monkey99 image.E01 - &gt; image.raw</strong><br/>AccessData FTK Imager v3.1.1 CLI (Aug 24 2012)<br/>Copyright 2006-2012 AccessData Corp., 384 South 400 West, Lindon, UT 84042<br/>All rights reserved.</p>&#13;
<p class="indent">Some versions of the EWF format support encryption, and as of this writing, libewf support was at various stages of development. Refer to the latest source code for current encrypted-format support.</p>&#13;
<p class="indent">The AFFlibsuite allows you to directly access encrypted images via the Advanced Forensics Format (AFF) library. From the start, AFFlib was developed with information security in mind. It has a number of encryption possibilities for protecting forensic images, including password-based (symmetric) and certificate-based (X.509) encryption. You can add the protection to an existing acquired image using the affcrypto tool. Here is an example:</p>&#13;
<p class="programs"># <strong>affcrypto -e -N monkey99 image.aff</strong><br/>image.aff:   967 segments;     0 signed;   967 encrypted;     0 pages;<br/>    0 encrypted pages</p>&#13;
<p class="indent">Recent versions of dd_rescue implement a plugin interface and (at the time of this writing) had plugins for LZO compression, cryptographic hashing, and symmetric encryption (AES). The following example shows imaging a disk (<em>/dev/sdc</em>) and saving the output in encrypted form using the AES plugin:</p>&#13;
<p class="programs"># <strong>dd_rescue -L crypt=enc:passfd=0:pbkdf2 /dev/sdc samsung.raw.aes</strong><br/>dd_rescue: (info): Using softbs=128.0kiB, hardbs=4.0kiB<br/>dd_rescue: (input): crypt(0): Enter passphrase:<br/>dd_rescue: (warning): some plugins don't handle sparse, enabled -A/--nosparse!<br/>dd_rescue: (info): expect to copy 156290904.0kiB from /dev/sdc<br/>dd_rescue: (info): crypt(0): Derived salt from samsung.raw.aes=00000025433d6000<br/>dd_rescue: (info): crypt(0): Generate KEY and IV from same passwd/salt<br/>dd_rescue: (info): ipos: 156286976.0k, opos: 156286976.0k, xferd: 156286976.0k<br/>                   errs:      0, errxfer:         0.0k, succxfer: 156286976.0k<br/>             +curr.rate:    38650kB/s, avg.rate:    56830kB/s, avg.load: 14.9%<br/>             &gt;----------------------------------------.&lt;  99%  ETA:  0:00:00<br/>dd_rescue: (info): read /dev/sdc (156290904.0kiB): EOF<br/>dd_rescue: (info): Summary for /dev/sdc -&gt; samsung.raw.aes<br/>dd_rescue: (info): ipos: 156290904.0k, opos: 156290904.0k, xferd: 156290904.0k<br/>                   errs:      0, errxfer:         0.0k, succxfer: 156290904.0k<br/>             +curr.rate:    29345kB/s, avg.rate:    56775kB/s, avg.load: 14.9%<br/>             &gt;-----------------------------------------&lt; 100%  TOT:  0:45:53</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_216"/>If examiners in a forensics lab expect high volumes of encryption, signing, and timestamping of images and evidence, it’s worth investing the use of a PKI. This could be an in-house PKI system or an external commercial PKI provider.</p>&#13;
<h4 class="h4" id="ch07lev2sec22"><em><strong>General Purpose Disk Encryption</strong></em></h4>&#13;
<p class="noindenta">The examples in the previous sections focused on protecting individual files or file containers. An alternative is to protect the entire drive where the image files reside. You can do this with filesystem encryption, in hardware, in user space, or in the kernel. You’ll see several examples in this section.</p>&#13;
<p class="indent">There are high-capacity secure external drives on the market that can be used to safely transport image files, such as Lenovo’s ThinkPad Secure Hard Drives, one of which is shown in <a href="ch07.xhtml#ch7fig1">Figure 7-1</a>. These drives are OS independent and encrypt drive contents with a pin entered in a physical keypad on the device.</p>&#13;
<div class="image"><img src="../images/f07-01.jpg" alt="image"/></div>&#13;
<p class="figcap"><a id="ch7fig1"/><em>Figure 7-1: ThinkPad Secure Hard Drive</em></p>&#13;
<p class="indentb">TrueCrypt was once the most popular free and cross-platform filesystem software available. But in May 2014, an unexpected and unexplained announcement from the developers recommended people find alternatives <span epub:type="pagebreak" id="page_217"/>to TrueCrypt because development was stopped. A number of forks and compatible projects resulted, several of which are listed here:</p>&#13;
<p class="bull">• VeraCrypt: <em><a href="https://veracrypt.codeplex.com/">https://veracrypt.codeplex.com/</a></em></p>&#13;
<p class="bull">• tc-play: <em><a href="https://github.com/bwalex/tc-play/">https://github.com/bwalex/tc-play/</a></em></p>&#13;
<p class="bull">• CipherShed: <em><a href="https://ciphershed.org/">https://ciphershed.org/</a></em></p>&#13;
<p class="bull">• zuluCrypt: <em><a href="http://mhogomchungu.github.io/zuluCrypt/">http://mhogomchungu.github.io/zuluCrypt/</a></em> (not an implementation of TrueCrypt but a TrueCrypt manager worth mentioning)</p>&#13;
<p class="indentt">The rest of the examples in this section use VeraCrypt. As of this writing, VeraCrypt was under active development and gaining in popularity as an alternative to TrueCrypt.</p>&#13;
<p class="indent">The following example encrypts an empty external drive in its entirety. You can then use the encrypted container for secure transfer or storage of evidence data. The veracrypt tool asks a number of questions regarding the setup of the encrypted container. Note that in this example, <em>/dev/sda</em> is an examiner’s drive, not a subject drive.</p>&#13;
<p class="programs"># <strong>veracrypt -c /dev/sda</strong><br/>Volume type:<br/> 1) Normal<br/> 2) Hidden<br/>Select [1]:<br/><br/>Encryption Algorithm:<br/> 1) AES<br/> 2) Serpent<br/> 3) Twofish<br/> 4) AES(Twofish)<br/> 5) AES(Twofish(Serpent))<br/> 6) Serpent(AES)<br/> 7) Serpent(Twofish(AES))<br/> 8) Twofish(Serpent)<br/>Select [1]:<br/><br/>Hash algorithm:<br/> 1) SHA-512<br/> 2) Whirlpool<br/> 3) SHA-256<br/>Select [1]:<br/><br/>Filesystem:<br/> 1) None<br/> 2) FAT<br/> 3) Linux Ext2<br/> 4) Linux Ext3<br/> 5) Linux Ext4<br/> 6) NTFS<br/><br/>Select [2]: 5<br/><br/>Enter password:<br/>Re-enter password:<br/><br/>Enter PIM:<br/><br/>Enter keyfile path [none]:<br/><br/>Please type at least 320 randomly chosen characters and then press Enter:<br/><br/>The VeraCrypt volume has been successfully created.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_218"/>The drive has now been initialized as a VeraCrypt container (this can take a long time, depending on the speed of the PC and the size of the drive). To mount a VeraCrypt volume, you use a simple command that includes the source device and the mount point:</p>&#13;
<p class="programs"># <strong>veracrypt /dev/sda /mnt</strong><br/>Enter password for /dev/sda:<br/>Enter PIM for /dev/sda:<br/>Enter keyfile [none]:<br/>Protect hidden volume (if any)? (y=Yes/n=No) [No]:<br/># <strong>veracrypt -l</strong><br/>1: /dev/sda /dev/mapper/veracrypt1 /mnt</p>&#13;
<p class="indent">Safely removing the device requires “dismounting” the VeraCrypt volume and is also done using a simple command that specifies the mount point:</p>&#13;
<p class="programs"># <strong>veracrypt --dismount /mnt</strong></p>&#13;
<p class="indent">At this point, you can physically detach the drive from the system. The encrypted drive in this example is an entire raw device, but it’s also possible to use a VeraCrypt container file. The mount point in this example is <em>/mnt</em>, but it can be anywhere in the filesystem.</p>&#13;
<p class="indent">There are other full-disk encryption systems that can be used to secure forensic image files and other data. You can use self-encrypting drives (SEDs), discussed in detail in “<a href="ch05.xhtml#ch05lev2sec12">Identify and Unlock Opal Self-Encrypting Drives</a>” on <a href="ch05.xhtml#page_128">page 128</a>, with the <span class="literal">sedutil-cli</span> command to create an encrypted drive for storage and transport. Filesystem encryption, such as Linux LUKS and dm-crypt, offers similar levels of protection. Although these encryption systems will secure evidence data on a drive, they might not be interoperable with other OSes (Windows or OS X, for example).</p>&#13;
<h3 class="h3" id="ch07lev1sec06"><span epub:type="pagebreak" id="page_219"/><strong>Disk Cloning and Duplication</strong></h3>&#13;
<p class="noindentb">In some situations, a clone or duplicate copy of a disk is preferred to an image file. Each duplicate is an exact sector-by-sector copy of the original disk. A newly cloned disk will have a cryptographic checksum that matches the original. A cloned disk can be useful for several reasons:</p>&#13;
<p class="bull">• To use analysis tools and methods that require writing to disk</p>&#13;
<p class="bull">• To boot a PC with the disk clone</p>&#13;
<p class="bull">• To reconstruct RAID arrays using proprietary controllers</p>&#13;
<p class="indentt">Cloning disks is a straightforward process; it is basically acquisition in reverse. Be sure to exercise caution during the duplication process, because you could destroy data if the wrong device is mistakenly used as the destination.</p>&#13;
<h4 class="h4" id="ch07lev2sec23"><em><strong>Prepare a Clone Disk</strong></em></h4>&#13;
<p class="noindenta">The size (number of sectors) of the destination, or clone, disk must be equal to or larger than the original disk. Because cloning involves a sector-by-sector copy, the destination disk must have the capacity to hold all sectors of the original disk. In some cases, having a larger destination disk is not a problem, because the PC and OS will be limited to what was defined in the partition table and ignore the rest of the disk. In other cases, duplicating the exact number of sectors of the disk is important, as software and tools may have certain sector number expectations. Some examples include the analysis of GPT partitions (where a backup is stored at the end of a disk) and RAID systems, and the analysis of certain strains of malware that partly reside in the final sectors of the disk.</p>&#13;
<p class="indent">Securely wiping (with zeroed sectors) the destination disk before cloning is critical to remove traces of previous data and reduce the risk of contaminating the clone.</p>&#13;
<h4 class="h4" id="ch07lev2sec24"><em><strong>Use HPA to Replicate Sector Size</strong></em></h4>&#13;
<p class="noindenta">The HPA can be used to simulate the same number of sectors on the cloned disk as on the original.<sup><a id="fn_40" href="footnote.xhtml#fn40">2</a></sup> Setting the HPA on a cloned disk is beneficial if there is an expectation of the exact same number of sectors as the original. This is especially important when you’re reconstructing a RAID system with a proprietary controller or duplicating a disk with data expected in the final sectors of the disk.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong>NOTE</strong></p>&#13;
<p class="notep"><em>You should know the exact sector count of the original drive (this was determined when the drive was attached to the examination host) before setting the HPA with the hdparm tool.</em></p>&#13;
</div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_220"/>In this example, the HPA on a 500GB disk is set to duplicate a 120GB drive. The original disk reports 234441648 512-byte sectors, which you can use to set the <em>maximum visible sectors</em> on the clone drive. Use the following commands:</p>&#13;
<p class="programs"># <strong>hdparm -N /dev/sdk</strong><br/><br/>/dev/sdk:<br/> max sectors   = 976773168/976773168, HPA is disabled<br/># <strong>hdparm --yes-i-know-what-i-am-doing -N p234441648 /dev/sdk</strong><br/><br/>/dev/sdk:<br/> setting max visible sectors to 234441648 (permanent)<br/> max sectors   = 234441648/976773168, HPA is enabled<br/># <strong>hdparm -I /dev/sdk</strong><br/>...<br/>        LBA    user addressable sectors:  234441648<br/>...<br/>        device size with M = 1000*1000:      120034 MBytes (120 GB)<br/>...</p>&#13;
<p class="indent">The first <span class="literal">hdparm -N</span> command shows the initial state with 500GB of accessible sectors and a disabled HPA. The second <span class="literal">hdparm</span> command requires the <span class="literal">--yes-i-know-what-i-am-doing</span> flag to configure dangerous settings, such as changing the sector size. The <span class="literal">-N p234441648</span> specifies the number of sectors. It is prefixed with the letter <span class="literal">p</span> so the change is permanent across drive restarts. The final <span class="literal">hdparm</span> command checks whether the drive is now reporting the new sector size, which is now the same as that of the clone (120GB).</p>&#13;
<h4 class="h4" id="ch07lev2sec25"><em><strong>Write an Image File to a Clone Disk</strong></em></h4>&#13;
<p class="noindenta">To write an image to a new disk, use the same tools as when you acquire a disk but in reverse.</p>&#13;
<p class="indent">You can create a disk clone directly from the original suspect disk or from a previously acquired image file using the standard dd utilities. This example shows writing a raw image file to a clone disk using dc3dd:</p>&#13;
<p class="programs"># <strong>dc3dd if=image.raw of=/dev/sdk log=clone.log</strong><br/><br/>dc3dd 7.2.641 started at 2016-01-16 01:41:44 +0100<br/>compiled options:<br/>command line: dc3dd if=image.raw of=/dev/sdk log=clone.log<br/>sector size: 512 bytes (assumed)<br/>120034123776 bytes ( 112 G ) copied ( 100% ), 663 s, 173 M/s<br/><br/>input results for file `image.raw':<br/>   234441648 sectors in<br/>output results for device `/dev/sdk':<br/>   234441648 sectors out<br/><br/>dc3dd completed at 2016-01-16 01:52:48 +0100</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_221"/>Now you can verify the cryptographic hash against the original. If the sector count of the original and clone disks don’t match, either an error is generated (if the clone doesn’t have enough sectors to complete the duplication activity) or the hash values won’t match.</p>&#13;
<p class="indent">You can write a set of split images, compressed images, or encrypted images back to a clone disk without creating a regular image file first.</p>&#13;
<p class="indent">You can also use non-raw formats, such as AFF, EnCase EWF, or FTK SMART, to create clone disks. If a particular forensic tool cannot write an image back to a device, it might be able to pipe a raw image into a dd program, which can.</p>&#13;
<h3 class="h3" id="ch07lev1sec07"><strong>Image Transfer and Storage</strong></h3>&#13;
<p class="noindent">Managing the transfer and long-term storage of forensic images safely and successfully requires some thought and planning. Often, situations occur in which you need to transfer an image to another party, such as another department within a large organization, an independent third-party forensics firm, or a law enforcement agency.</p>&#13;
<p class="indent">Several factors influence how transfers are completed, primarily the size of the data and the security of that data. In addition, depending on the organization, you might have to consider legal and regulatory requirements, as well as organizational policy requirements. For example, a global bank might not be able to transfer some disk images across national borders due to banking regulations prohibiting the transfer of client data outside the country.</p>&#13;
<p class="indent">Storing images for the long term also requires some thought and plan-ning. If an image will be reopened several years later, different staff, tools, and infrastructure could be in place. It is important to document what has been stored and maintain backward compatibility with the software used in the past.</p>&#13;
<h4 class="h4" id="ch07lev2sec26"><em><strong>Write to Removable Media</strong></em></h4>&#13;
<p class="noindenta">In the past, a stack of CDs or DVDs were used in the transfer of acquired drive images. With compression and splitting, using these media was a cheap and feasible transfer method. Today, 4TB and 6TB disks are common, and 10TB disks are already on the consumer market. Optical discs are no longer a practical transfer medium for today’s larger image sizes, even with compression. However, for completeness, several examples are shown here.</p>&#13;
<p class="indent">The following simple example shows burning a SquashFS file to CDROM. The <span class="literal">mkisofs</span> command is a symlink to genisoimage and is used to create the filesystem to be burned to a disk with the wodim tool.</p>&#13;
<p class="programs"><span epub:type="pagebreak" id="page_222"/># <strong>mkisofs -r -J maxtor-2gb-L905T60S.sfs | wodim dev=/dev/cdrom -</strong><br/>...<br/>Starting to write CD/DVD at speed 48.0 in real TAO mode for single session.<br/>...<br/> 97.45% done, estimate finish Sat Jan 16 02:36:16 2016<br/> 98.88% done, estimate finish Sat Jan 16 02:36:15 2016<br/>...<br/>348929 extents written (681 MB)<br/>Track 01: Total bytes read/written: 714606592/714606592 (348929 sectors).</p>&#13;
<p class="indent">Here is a simple example of burning an image to a DVD. The growisofs tool began as a frontend to genisoimage and developed into a generalpurpose DVD and Blu-ray burning tool.</p>&#13;
<p class="programs"># <strong>growisofs -Z /dev/dvd -R -J ibm-4gb-J30J30K5215.sfs</strong><br/>Executing 'genisoimage -R -J ibm-4gb-J30J30K5215.sfs | builtin_dd of=/dev/dvd<br/>    obs=32k seek=0'<br/>...<br/> 99.58% done, estimate finish Sat Jan 16 02:30:07 2016<br/> 99.98% done, estimate finish Sat Jan 16 02:30:07 2016<br/>1240225 extents written (2422 MB)<br/>...</p>&#13;
<p class="indent">The following example shows burning an image to a Blu-ray disc using the <span class="literal">growisofs</span> command:</p>&#13;
<p class="programs"># <strong>growisofs -allow-limited-size  -Z /dev/dvd -R -J atlas-18gb.sfs</strong><br/>Executing 'genisoimage -allow-limited-size -R -J atlas-18gb.sfs | builtin_dd<br/>    of=/dev/dvd obs=32k seek=0'<br/>...<br/>This size can only be represented in the UDF filesystem.<br/>...<br/>/dev/dvd: pre-formatting blank BD-R for 24.8GB...<br/>...<br/> 99.79% done, estimate finish Sat Jan 16 02:20:10 2016<br/> 99.98% done, estimate finish Sat Jan 16 02:20:10 2016<br/>2525420 extents written (4932 MB)<br/>...</p>&#13;
<p class="indent">Burning large images to optical discs under Linux can be quirky. Depending on the drive and the media used, unexpected or inconsistent behavior might be observed. Be sure to test the compatibility of drives and media before using them in a production environment.</p>&#13;
<h4 class="h4" id="ch07lev2sec27"><span epub:type="pagebreak" id="page_223"/><em><strong>Inexpensive Disks for Storage and Transfer</strong></em></h4>&#13;
<p class="noindenta">Creating a stack of optical discs from a set of split and compressed images requires a systematic process that can be time-consuming and error prone. The maximum capacity of Blu-ray discs is currently 100GB (BD-R XL). The cost per gigabyte of Blu-ray discs is more than the cost per gigabyte for cheap hard disks.</p>&#13;
<p class="indent">When you factor in human effort, risk of error, time required to burn data to optical discs, and cost per gigabtye, simply buying and using cheap hard disks becomes an attractive possibility for offline storage and transfer of forensic images.</p>&#13;
<h4 class="h4" id="ch07lev2sec28"><em><strong>Perform Large Network Transfers</strong></em></h4>&#13;
<p class="noindenta">Some of the issues concerning acquiring images via a network were already discussed in <a href="ch06.xhtml#ch06">Chapter 6</a>.</p>&#13;
<p class="indent">Large network transfers of acquired images may take long periods of time to complete and might saturate a corporate internal network or internet link. Dropped connections and timeouts might also occur during such long network transfers.</p>&#13;
<p class="indent">Transferring large forensic images between hosts on a network is not nearly as fast as transferring them between disks on a local machine. To put network bandwidth speeds into perspective, it helpful to compare them to common disk speeds. <a href="ch07.xhtml#ch7table1">Table 7-1</a> compares two fast drive interfaces to two fast network interfaces.</p>&#13;
<p class="tablecap"><a id="ch7table1"/><strong>Table 7-1:</strong> Transfer Speeds of Common Interfaces</p>&#13;
<table class="topbot">&#13;
<thead>&#13;
<tr>&#13;
<td style="vertical-align: top;" class="tableth"><p class="table"><strong>Interface</strong></p></td>&#13;
<td style="vertical-align: top;" class="tableth"><p class="table"><strong>Speed</strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top;"><p class="table">NVME</p></td>&#13;
<td style="vertical-align: top;"><p class="table">4000MB/s</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;"><p class="table">SATA III</p></td>&#13;
<td style="vertical-align: top;"><p class="table">600MB/s</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;"><p class="table">Gigibit Ethernet</p></td>&#13;
<td style="vertical-align: top;"><p class="table">125MB/s</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top;"><p class="table">Fast Ethernet</p></td>&#13;
<td style="vertical-align: top;"><p class="table">12.5MB/s</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">For a more detailed comparison of different bandwidths, see the Wikipedia page at <em><a href="https://en.wikipedia.org/wiki/List_of_device_bit_rates">https://en.wikipedia.org/wiki/List_of_device_bit_rates</a></em>.</p>&#13;
<p class="indent">Depending on the network bandwidth and the image size, the physical delivery of a storage container with the acquired subject image(s) could be faster than a network transfer.</p>&#13;
<p class="indent">But in some situations, secure network data transfer is necessary. Ensuring security during a transfer may have certain side effects, such as increased complexity or performance penalties. For network data transfer over untrusted or unknown networks, you can use several standard secure protocols, including SSL/TLS, ssh/sftp, or IPSEC.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_224"/>The following simple example shows the transfer of a forensic image file using scp (secure copy) from the OpenSSH software package:</p>&#13;
<p class="programs">$ <strong>scp image.raw server1.company.com:/data/image.raw</strong><br/>image.raw                11% 1955MB  37.8MB/s   06:51 ETA<br/>...</p>&#13;
<p class="indent">Here, an image file (<em>image.raw</em>) is copied over an insecure network to a specific data directory on a remote server. Using scp has several advantages, including strong encryption algorithms, built-in compression, real-time progress status, estimated completion time, and strong authentication possibilities. Most important for forensic investigators, scp allows for very large file sizes (assuming the software binary was compiled with 64-bit large file size support) and is easily capable of transferring large disk images.</p>&#13;
<p class="indent">If an image file is already encrypted, the underlying security might be less of a concern, and you can use traditional file transfer protocols, such as File Transfer Protocol (FTP) or Windows Server Message Block (SMB). However, when you’re using insecure and weakly authenticated protocols to transfer encrypted files, you should confirm the file integrity by verifying the cryptographic hash after the transfer is complete.</p>&#13;
<h3 class="h3" id="ch07lev1sec08"><strong>Secure Wiping and Data Disposal</strong></h3>&#13;
<p class="noindent">Whenever you discard or reuse a disk, or you no longer need temporary files, take diligent steps to properly erase the contents. Several command line wiping and secure deletion methods are available for this purpose.</p>&#13;
<h4 class="h4" id="ch07lev2sec29"><em><strong>Dispose of Individual Files</strong></em></h4>&#13;
<p class="noindenta">In some situations, you’ll need to securely erase individual files but not the entire disk. For example, you might need to dispose of temporary acquired images on the acquisition host. In this scenario, using a file shredder/wiper is sensible because it reduces the risk of destroying other data on the examiner’s workstation.</p>&#13;
<p class="indent">The standard Linux coreutils package includes the shred tool, which attempts to securely delete files, as shown here:</p>&#13;
<p class="programs">$ <strong>shred -v confidential-case-notes.txt</strong><br/>shred: confidential-case-notes.txt: pass 1/3 (random)...<br/>shred: confidential-case-notes.txt: pass 2/3 (random)...<br/>shred: confidential-case-notes.txt: pass 3/3 (random)...</p>&#13;
<p class="indent">A software package called the secure_deletion toolkit provides a suite of tools that attempts to erase swap, cache, memory, inodes, and files. In particular, srm will wipe an individual file. Another command line tool called wipe also will erase files.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_225"/>Wiping individual files is a complex process and depends on many variables related to the OS and filesystem used. There are no guarantees that all fragments of a wiped or shredded file have been completely destroyed.</p>&#13;
<h4 class="h4" id="ch07lev2sec30"><em><strong>Secure Wipe a Storage Device</strong></em></h4>&#13;
<p class="noindenta">Wiping entire physical drives involves writing zeros or random bytes to every user-accessible sector on the drive. This does not guarantee that all hidden or user-inaccessible areas of a physical drive are wiped. Sectors protected by an HPA or DCO (which can be removed), remapped bad sectors, overprovisioned areas of flash drives, and inaccessible system areas of a drive are not user accessible and therefore cannot be wiped with normal Linux tools. In spite of this, wiping all user-accessible sectors still provides a reasonable level of assurance, so this is a diligent method of data disposal for reusing drives within a lab.</p>&#13;
<p class="indentb">Depending on a particular organization’s risk appetite and policies, data disposal might require one or more of the following:</p>&#13;
<p class="bull">• No wiping at all, just common reformatting</p>&#13;
<p class="bull">• Wiping all visible sectors with one pass of zeros</p>&#13;
<p class="bull">• Wiping all visible sectors with multiple passes of random data</p>&#13;
<p class="bull">• Physically degaussing drives</p>&#13;
<p class="bull">• Physically shredding drives</p>&#13;
<p class="indentt">The disposal method required is a risk-based decision that depends on the sensitivity of the data on the drive, who might have an interest in recovering the data, cost and effort for recovery, and other factors.</p>&#13;
<p class="indent">This first example uses dc3dd to write zeros to each visible sector on the disk. The dc3dd tool has built-in wiping functionality, and you can use it as follows:</p>&#13;
<p class="programs"># <strong>dc3dd wipe=/dev/sdi</strong><br/><br/>dc3dd 7.2.641 started at 2016-01-16 00:03:16 +0100<br/>compiled options:<br/>command line: dc3dd wipe=/dev/sdi<br/>device size: 29305206 sectors (probed),   120,034,123,776 bytes<br/>sector size: 4096 bytes (probed)<br/>120034123776 bytes ( 112 G ) copied ( 100% ), 3619 s, 32 M/s<br/><br/>input results for pattern `00':<br/>   29305206 sectors in<br/><br/>output results for device `/dev/sdi':<br/>   29305206 sectors out<br/><br/>dc3dd completed at 2016-01-16 01:03:35 +0100</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_226"/>You could also complete this task using dd with <em>/dev/zero</em> as the input file, but dc3dd is faster.</p>&#13;
<p class="indent">To confirm the disk has been wiped with zeros, you can use dd to read the disk into a hexdump program:</p>&#13;
<p class="programs"># <strong>dd if=/dev/sda | hd</strong></p>&#13;
<p class="indent">If the entire disk is full of zeros, the hexdump (hd) tool will display one line of zeros followed by an asterisk (<span class="literal"><sub>*</sub></span>), indicating a repeated pattern across the entire disk.</p>&#13;
<p class="programs">0000000 000000 000000 000000 000000 000000 000000 000000 000000<br/>*</p>&#13;
<p class="indent">If the result shows only zeros, the user-accessible sectors of the drive have been successfully wiped.</p>&#13;
<p class="indent">The following example uses the nwipe tool, a fork of Darik’s Boot and Nuke (dban) tool. The nwipe tool can specify different wiping standards, randomicity, and number of rounds, and it will provide a log file of the activity. The Canadian RCMP TSSIT OPS-II wipe version is shown here:<sup><a id="fn_41" href="footnote.xhtml#fn41">3</a></sup></p>&#13;
<p class="programs"># <strong>nwipe --autonuke --nogui --method=ops2 /dev/sdj</strong><br/>[2016/01/15 23:14:56] nwipe: notice: Opened entropy source '/dev/urandom'.<br/>[2016/01/15 23:14:56] nwipe: info: Device '/dev/sdj' has sector size 512.<br/>[2016/01/15 23:14:56] nwipe: warning: Changing '/dev/sdj' block size from 4096 to<br/>    512.<br/>[2016/01/15 23:14:56] nwipe: info: Device '/dev/sdj' is size 160041885696.<br/>[2016/01/15 23:14:56] nwipe: notice: Invoking method 'RCMP TSSIT OPS-II' on device<br/>    '/dev/sdj'.<br/>[2016/01/15 23:14:56] nwipe: notice: Starting round 1 of 1 on device '/dev/sdj'.<br/>[2016/01/15 23:14:56] nwipe: notice: Starting pass 1 of 8, round 1 of 1, on device<br/>    '/dev/sdj'.<br/>[2016/01/15 23:57:00] nwipe: notice: 160041885696 bytes written to device<br/>    '/dev/sdj'.<br/>[2016/01/15 23:57:00] nwipe: notice: Finished pass 1 of 8, round 1 of 1, on device<br/>    '/dev/sdj'.<br/>...</p>&#13;
<p class="indent">When you’re wiping drives, ensure the DCO and HPA have been removed. With NVME drives, make sure each individual namespace has been wiped (most consumer NVME drives have only a single namespace).</p>&#13;
<h4 class="h4" id="ch07lev2sec31"><em><strong>Issue ATA Security Erase Unit Commands</strong></em></h4>&#13;
<p class="noindenta">The ATA standard specifies a security erase command that you can issue directly to a drive to wipe a disk. The <span class="literal">ATA SECURITY ERASE UNIT</span> command will <span epub:type="pagebreak" id="page_227"/>write zeros to all user accessible sectors of the disk. The <span class="literal">EXTENDED SECURITY ERASE</span> command will write a predefined pattern (defined by the drive manufacturer) instead of zeros.</p>&#13;
<p class="indent">Running <span class="literal">hdparm</span> displays the capabilities and status of security on the drive. Also provided is the estimated time needed to securely erase the drive, as shown here:</p>&#13;
<p class="programs"># <strong>hdparm -I /dev/sdh</strong><br/>...<br/>        device size with M = 1000*1000:     500107 MBytes (500 GB)<br/>...<br/>Security:<br/>        Master password revision code = 7<br/>                supported<br/>                enabled<br/>        not     locked<br/>        not     frozen<br/>        not     expired: security count<br/>                supported: enhanced erase<br/>        Security level high<br/>        60min for SECURITY ERASE UNIT. 60min for ENHANCED SECURITY ERASE UNIT.</p>&#13;
<p class="indent">Some drives will reject the erase command if you don’t explicitly set a password first. In the following example, a Western Digital drive was used, and the password was first set to <em>dummy</em> before the <span class="literal">--security-erase</span> command was accepted:</p>&#13;
<p class="programs"># <strong>hdparm --security-erase dummy /dev/sdh</strong><br/>security_password="dummy"<br/><br/>/dev/sdh:<br/> Issuing SECURITY_ERASE command, password="dummy", user=user</p>&#13;
<p class="indent">The drive has now been securely wiped and can be reused. If a drive requires setting a password, don’t forget to disable the password after the security erase has completed.</p>&#13;
<h4 class="h4" id="ch07lev2sec32"><em><strong>Destroy Encrypted Disk Keys</strong></em></h4>&#13;
<p class="noindenta">You can securely destroy encrypted disks and filesystems by destroying all known copies of the encryption key. If the key was generated on a secure device such as a smartcard, a TPM, or an Opal drive, then only one copy of the key will exist. If a drive or filesystem was provisioned in an enterprise environment, there might be backup or escrow copies of the key for recovery purposes.</p>&#13;
<p class="indent">Key-wiping procedures for OS-based encrypted drives, such as Microsoft BitLocker, Apple FileVault, Linux LUKS/dm-crypt, or TrueCrypt variants, require detailed knowledge of where the keys are stored. Keys might be <span epub:type="pagebreak" id="page_228"/>password/passphrase protected and stored in a file or in a certain block on the drive. They might also be stored in a key file elsewhere. If it’s not possible to locate and securely destroy all copies of a private key, the alternative is to wipe the disk with the full drive-wiping method described in a previous section.</p>&#13;
<p class="indent">Typically, secure external USB thumb drives have a factory reset function for lost passwords. This can be used to destroy the key and hence the contents of the drive. For example, you can reset the Corsair Padlock2 thumb drive by holding down both the KEY and 0/1 buttons for three seconds, followed by entering <span class="literal"><span class="codestrong">911</span></span> to reset the key and destroy the drive contents. On iStorage datashur drives, hold down both the KEY and 2 buttons for three seconds and then enter <span class="literal"><span class="codestrong">999</span></span> to reset the key.</p>&#13;
<p class="indent">Destroying the contents of Opal SED drives is also instantaneous and simply involves destroying the encryption key on the drive by entering the <em>Physical Security ID (PSID)</em>. The PSID usually has a QR code on the physical cover of the drive that you can scan instead of typing it in by hand. You cannot get the PSID by querying the drive with ATA commands; it’s only visible on the cover of the physical drive.</p>&#13;
<p class="indent">The <span class="literal">sedutil-cli</span> command has a special option for irrevocably resetting the drive key using the PSID:</p>&#13;
<p class="programs"># <strong>time sedutil-cli --yesIreallywanttoERASEALLmydatausingthePSID</strong><br/>     <strong>3HTEWZB0TVOLH2MZU8F7LCFD28U7GJPG /dev/sdi</strong><br/>- 22:21:13.738 INFO: revertTper completed successfully<br/><br/>real    0m0.541s<br/>user    0m0.000s<br/>sys     0m0.000s</p>&#13;
<p class="indent">The encryption key in the drive is now reset, and the data is effectively destroyed. The disk is factory reset, unlocked, and can be reused. The time needed to destroy the data on this 120GB drive was half a second.</p>&#13;
<h3 class="h3" id="ch07lev1sec09"><strong>Closing Thoughts</strong></h3>&#13;
<p class="noindent">In this chapter, you learned a variety of techniques for managing forensic images, including the use of compression with common Linux tools and built-in compression with forensic formats. You saw more examples of the SquashFS compressed filesystem and the sfsimage script for managing forensic evidence containers. I demonstrated splitting and reassembling images, duplicating drives, and converting between image formats. You also learned how to verify hashes, signatures, and timestamps and how to protect images with encryption during network transfer and storage. Finally, I showed the secure disposal of forensic image files and drives.</p>&#13;
</body></html>