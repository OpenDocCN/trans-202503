<html><head></head><body>
<h2 class="h2" id="ch11"><span epub:type="pagebreak" id="page_199"/><strong><span class="big">11</span></strong><br/><br/>BUILDING A NEURAL NETWORK MALWARE DETECTOR WITH KERAS</h2>
<div class="image1"><img alt="image" src="../images/common01.jpg"/></div>
<p class="noindent">A decade ago, building a functioning, scalable, and fast neural network was time consuming and required quite a lot of code. In the past few years, however, this process has become far less painful, as more and more high-level interfaces to neural network design have been developed. The Python package <span class="literal">Keras</span> is one of these interfaces.</p>
<p class="indent">In this chapter, I walk you through how to build a sample neural network using the <span class="literal">Keras</span> package. First, I explain how to define a model’s architecture in <span class="literal">Keras</span>. Second, we train this model to differentiate between benign and malicious HTML files, and you learn how to save and load such models. Third, using the Python package <span class="literal">sklearn</span>, you learn how to evaluate the model’s accuracy on validation data. Finally, we use what you’ve learned to integrate validation accuracy reporting into the model training process.</p>
<p class="indent">I encourage you to read this chapter while reading and editing the associated code in the data accompanying this book. You can find all the code <span epub:type="pagebreak" id="page_200"/>discussed in this chapter there (organized into parameterized functions to make things easier to run and adjust), as well as a few extra examples. By the end of this chapter, you’ll feel ready to start building some networks of your own!</p>
<p class="indent">To run code listings in this chapter, you not only need to install the packages listed in this chapter’s <em>ch11/requirements.txt</em> file (<span class="literal">pip install –r requirements.txt</span>), but also follow the directions to install one of <span class="literal">Keras</span>’s backend engines on your system (TensorFlow, Theano, or CNTK). Install TensorFlow by following the directions here: <em><a href="https://www.tensorflow.org/install/">https://www.tensorflow.org/install/</a></em>.</p>
<h3 class="h3" id="lev184"><strong>Defining a Model’s Architecture</strong></h3>
<p class="noindent">To build a neural network, you need to define its architecture: which neurons go where, how they connect to subsequent neurons, and how data flows through the whole thing. Luckily, <span class="literal">Keras</span> provides a simple, flexible interface to define all this. <span class="literal">Keras</span> actually supports two similar syntaxes for model definition, but we’re going to use the Functional API syntax, as it’s more flexible and powerful that the other (“sequential”) syntax.</p>
<p class="indent">When designing a model, you need three things: input, stuff in the middle that processes the input, and output. Sometimes your models will have multiple inputs, multiple outputs, and very complex stuff in the middle, but the basic idea is that when defining a model’s architecture, you’re just defining how the input—your data, such as features relating to an HTML file—flows through various neurons (stuff in the middle), until finally the last neurons end up yielding some output.</p>
<p class="indent">To define this architecture, <span class="literal">Keras</span> uses layers. A <em>layer</em> is a group of neurons that all use the same type of activation function, all receive data from a previous layer, and all send their outputs to a subsequent layer of neurons. In a neural network, input data is generally fed to an initial layer of neurons, which sends its outputs to a subsequent layer, which sends its outputs to another layer, and so on and so forth, until the last layer of neurons generates the network’s final output.</p>
<p class="indent"><a href="ch11.xhtml#ch11list1">Listing 11-1</a> is an example of a simple model defined using <span class="literal">Keras</span>’s functional API syntax. I encourage you to open a new Python file to write and run the code yourself as we walk through the code, line by line. Alternatively, you can try running the associated code in the data accompanying this book, either by copying and pasting parts of the <em>ch11/model_architecture.py</em> file into an ipython session or by running <span class="literal">python</span> <span class="literal">ch11</span><span class="literal">/model_architecture.py</span> in a terminal window.</p>
<p class="programs"><span class="ent">➊</span> from keras import layers<br/><span class="ent">➋</span> from keras.models import Model<br/><br/>   input = layers.Input(<span class="ent">➌</span>shape=(1024,), <span class="ent">➍</span>dtype='float32')<br/><span class="ent">➎</span> middle = layers.Dense(units=512, activation='relu')(input)<br/><span class="ent">➏</span> output = layers.Dense(units=1, activation='sigmoid')(middle)<br/><span epub:type="pagebreak" id="page_201"/><span class="ent">➐</span> model = Model(inputs=input, outputs=output)<br/>   model.compile(<span class="ent">➑</span>optimizer='adam', <br/>                 <span class="ent">➒</span>loss='binary_crossentropy', <br/>                 <span class="ent">➓</span>metrics=['accuracy'])</p>
<p class="listing" id="ch11list1"><em>Listing 11-1: Defining a simple model using functional API syntax</em></p>
<p class="indent">First, we import the <span class="literal">Keras</span> package’s <span class="literal">layers</span> submodule <span class="ent">➊</span> as well as the <span class="literal">Model</span> class from <span class="literal">Keras</span>’s <span class="literal">models</span> submodule <span class="ent">➋</span>.</p>
<p class="indent">Next, we specify what kind of data this model will accept for one observation by passing a <span class="literal">shape</span> value (a tuple of integers) <span class="ent">➌</span> and a data type (string) <span class="ent">➍</span> to the <span class="literal">layers.Input()</span> function. Here, we declared that the input data to our model will be an array of 1,024 floats. If our input was, for example, a matrix of integers instead, the first line would look more like <span class="literal">input = Input(shape=(100, 100,) dtype='int32')</span>.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>If the model takes in variable-sized inputs on one dimension, you can use</em> <span class="codeitalic">None</span> <em>instead of a number—for example,</em> <span class="codeitalic">(100, None,)</span><em>.</em></p>
</div>
<p class="indent">Next, we specify the layer of neurons that this input data will be sent to. To do this, we again use the <span class="literal">layers</span> submodule we imported, specifically the <span class="literal">Dense</span> function <span class="ent">➎</span>, to specify that this layer will be a densely connected (also called fully connected) layer, which means that every output from the previous layer is sent to every neuron in this layer. <span class="literal">Dense</span> is the most common type of layer you’ll likely use when developing <span class="literal">Keras</span> models. Others allow you to do things like change the shape of the data (<span class="literal">Reshape</span>) and implement your own custom layer (<span class="literal">Lambda</span>).</p>
<p class="indent">We pass the <span class="literal">Dense</span> function two arguments: <span class="literal">units=512</span>, to specify that we want 512 neurons in this layer, and <span class="literal">activation='relu'</span>, to specify that we want these neurons to be rectified linear unit (ReLU) neurons. (Recall from <a href="ch10.xhtml#ch10">Chapter 10</a> that ReLU neurons use a simple type of activation function that outputs whichever is larger: either 0, or the weighted sum of the neuron’s inputs.) We use <span class="literal">layers.Dense(units=512, activation='relu')</span> to define the layer, and then the last part of the line—<span class="literal">(input)</span>—declares the input to this layer (namely, our <span class="literal">input</span> object). It’s important to understand that this passing of <span class="literal">input</span> to our layer is how data flow is defined in the model, as opposed to the ordering of the lines of the code.</p>
<p class="indent">In the next line, we define our model’s output layer, which again uses the <span class="literal">Dense</span> function. But this time, we designate only a single neuron to the layer and use a <span class="literal">'sigmoid'</span> activation function <span class="ent">➏</span>, which is great for combining a lot of data into a single score between 0 and 1. The output layer takes the <span class="literal">(middle)</span> object as input, declaring that the outputs from our 512 neurons in our <span class="literal">middle</span> layer should all be sent to this neuron.</p>
<p class="indent">Now that we’ve defined our layers, we use the <span class="literal">Model</span> class from the <span class="literal">models</span> submodule to wrap up all these layers together as a model <span class="ent">➐</span>. Note that you <em>only</em> have to specify your input layer(s) and output layer(s). Because each layer after the first is given the preceding layer as input, the final output <span epub:type="pagebreak" id="page_202"/>layer contains all the information the model needs about the previous layers. We could have 10 more <span class="literal">middle</span> layers declared between our <span class="literal">input</span> and <span class="literal">output</span> layers, but the line of code at <span class="ent">➐</span> would remain the same.</p>
<h3 class="h3" id="lev185"><strong>Compiling the Model</strong></h3>
<p class="noindent">Finally, we need to compile our model. We’ve defined the model’s architecture and flow of data, but we haven’t yet specified how we want the model to perform its training. To do this, we use our <span class="literal">model</span>’s own <span class="literal">compile</span> method and pass it three parameters:</p>
<ul>
<li class="noindent">The first parameter, <span class="literal">optimizer</span> <span class="ent">➑</span>, specifies the type of backpropagation algorithm to use. You can specify the name of the algorithm you wish to use via a character string like we did here, or you can import an algorithm directly from <span class="literal">keras.optimizers</span> to pass in specific parameters to the algorithm or even design your own.</li>
<li class="noindent">The <span class="literal">loss</span> parameter <span class="ent">➒</span> specifies the thing that is minimized during the training process (backpropagation). Specifically, this specifies the formula you wish to use to represent the difference between your true training labels and your model’s predicted labels (output). Again, you can specify the name of a loss function, or pass in an actual function, like <span class="literal">keras.losses.mean_squared_error</span>.</li>
<li class="noindent">Lastly, for the <span class="literal">metrics</span> parameter <span class="ent">➓</span>, you can pass a list of metrics that you want <span class="literal">Keras</span> to report when analyzing model performance during and after training. Again, you can pass strings or actual metric functions, like <span class="literal">['categorical_accuracy', keras.metrics.top_k_categorical_accuracy]</span>.</li>
</ul>
<p class="indent">After running the code in <a href="ch11.xhtml#ch11list1">Listing 11-1</a>, run <span class="literal">model.summary()</span> to see the model structure printed to your screen. Your output should look something like <a href="ch11.xhtml#ch11fig1">Figure 11-1</a>.</p>
<div class="image"><a id="ch11fig1"/><img alt="image" src="../images/f0202-01.jpg"/></div>
<p class="figcap"><em>Figure 11-1: Output of</em> <span class="codeitalic">model.summary()</span></p>
<p class="indent"><span epub:type="pagebreak" id="page_203"/><a href="ch11.xhtml#ch11fig1">Figure 11-1</a> shows the output of <span class="literal">model.summary()</span>. Each layer’s description is printed to the screen, along with the number of parameters associated with that layer. For example, the <span class="literal">dense_1</span> layer has 524,800 parameters because each of its 512 neurons gets a copy of each of the 1,024 input values from the input layer, meaning that there are 1,024 × 512 weights. Add 512 bias parameters, and you get 1,024 × 512 + 512 = 524,800.</p>
<p class="indent">Although we haven’t yet trained our model or tested it on validation data, this is a compiled <span class="literal">Keras</span> model that is ready to train!</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Check out the sample code in</em> ch11/model_architecture.py <em>for an example of a slightly more complex model!</em></p>
</div>
<h3 class="h3" id="lev186"><strong>Training the Model</strong></h3>
<p class="noindent">To train our model, we need training data. The virtual machine that comes with this book includes a set of about half a million benign and malicious HTML files. This consists of two folders of benign (<em>ch11/data/html/benign_files/</em>) and malicious (<em>ch11/data/html/malicious_files/</em>) HTML files. (Remember not to open these files in a browser!) In this section, we use these to train our neural network to predict whether an HTML file is benign (0) or malicious (1).</p>
<h4 class="h4" id="lev187"><strong><em>Extracting Features</em></strong></h4>
<p class="noindent">To do this, we first need to decide how to represent our data. In other words, what features do we want to extract from each HTML file to use as input to our model? For example, we could simply pass the first 1,000 characters in each HTML file to the model, we could pass in the frequency counts of all letters in the alphabet, or we could use an HTML parser to develop some more complex features. To make things easier, we’ll transform each variable-length, potentially very large HTML file into a uniformly sized, compressed representation that allows our model to quickly process and learn important patterns.</p>
<p class="indent">In this example, we transform each HTML file into a 1,024-length vector of category counts, where each category count represents the number of tokens in the HTML file whose hash resolved to the given category. <a href="ch11.xhtml#ch11list2">Listing 11-2</a> shows the feature extraction code.</p>
<p class="programs">import numpy as np<br/>import murmur<br/>import re<br/>import os<br/><br/>def read_file(sha, dir):<br/>    with open(os.path.join(dir, sha), 'r') as fp:<br/>       file = fp.read()<br/>    return file<br/><br/><span epub:type="pagebreak" id="page_204"/>def extract_features(sha, path_to_files_dir,<br/>                     hash_dim=1024, <span class="ent">➊</span>split_regex=r"\s+"):<br/>  <span class="ent">➋</span> file = read_file(sha=sha, dir=path_to_files_dir)<br/>  <span class="ent">➌</span> tokens = re.split(pattern=split_regex, string=file)<br/>    # now take the modulo(hash of each token) so that each token is replaced<br/>    # by bucket (category) from 1:hash_dim.<br/>    token_hash_buckets = [<br/>      <span class="ent">➍</span> (murmur.string_hash(w) % (hash_dim - 1) + 1) for w in tokens<br/>    ]<br/>    # Finally, we'll count how many hits each bucket got, so that our features<br/>    # always have length hash_dim, regardless of the size of the HTML file:<br/>    token_bucket_counts = np.zeros(hash_dim)<br/>    # this returns the frequency counts for each unique value in<br/>    # token_hash_buckets:<br/>    buckets, counts = np.unique(token_hash_buckets, return_counts=True)<br/>    # and now we insert these counts into our token_bucket_counts object:<br/>    for bucket, count in zip(buckets, counts):<br/>      <span class="ent">➎</span> token_bucket_counts[bucket] = count<br/>    return np.array(token_bucket_counts)</p>
<p class="listing" id="ch11list2"><em>Listing 11-2: Feature extraction code</em></p>
<p class="indent">You don’t have to understand all the details of this code to understand how <span class="literal">Keras</span> works, but I encourage you to read through the comments in the code to better understand what’s going on.</p>
<p class="indent">The <span class="literal">extract_features</span> function starts by reading in an HTML file as a big string <span class="ent">➋</span> and then splits up this string into a set of tokens based on a regular expression <span class="ent">➌</span>. Next, the numeric hash of each token is taken, and these hashes are divided into categories by taking the modulo of each hash <span class="ent">➍</span>. The final set of features is the number of hashes in each category <span class="ent">➎</span>, like a histogram bin count. If you want, you can try altering the regular expression <span class="literal">split_regex</span> <span class="ent">➊</span> that splits up the HTML file into chunks to see how it affects the resulting tokens and features.</p>
<p class="indent">If you skipped or didn’t understand all that, that’s okay: just know that our <span class="literal">extract_features</span> function takes the path to an HTML file as input and then transforms it into a feature array of length 1,024, or whatever <span class="literal">hash_dim</span> is.</p>
<h4 class="h4" id="lev188"><strong><em>Creating a Data Generator</em></strong></h4>
<p class="noindent">Now we need to make our <span class="literal">Keras</span> model actually train on these features. When working with small amounts of data already loaded into memory, you can use a simple line of code like <a href="ch11.xhtml#ch11list3">Listing 11-3</a> to train your model in <span class="literal">Keras</span>.</p>
<p class="programs"># first you would load in my_data and my_labels via some means, and then:<br/>model.fit(my_data, my_labels, epochs=10, batch_size=32)</p>
<p class="listing" id="ch11list3"><em>Listing 11-3: Training your model when data is already loaded into memory</em></p>
<p class="indent">However, this isn’t really useful when you start working with large amounts of data, because you can’t fit all your training data into your computer’s memory at once. To get around this, we use the slightly more <span epub:type="pagebreak" id="page_205"/>complex but more scalable <span class="literal">model.fit_generator</span> function. Instead of passing in all the training data at once to this function, you pass a generator that yields training data in batches so that your computer’s RAM won’t choke.</p>
<p class="indent">Python generators work just like Python functions, except they have a <span class="literal">yield</span> statement. Instead of returning a single result, generators return an object that can be called again and again to yield many, or infinite, sets of results. <a href="ch11.xhtml#ch11list4">Listing 11-4</a> shows how we can create our own data generator using our feature extraction function.</p>
<p class="programs">def my_generator(benign_files, malicious_files,<br/>                 path_to_benign_files, path_to_malicious_files,<br/>                 batch_size, features_length=1024):<br/>    n_samples_per_class = batch_size / 2<br/>  <span class="ent">➊</span> assert len(benign_files) &gt;= n_samples_per_class<br/>    assert len(malicious_files) &gt;= n_samples_per_class<br/>  <span class="ent">➋</span> while True:<br/>        ben_features = [<br/>            extract_features(sha, path_to_files_dir=path_to_benign_files,<br/>                             hash_dim=features_length)<br/>            for sha in np.random.choice(benign_files, n_samples_per_class,<br/>                                        replace=False)<br/>        ]<br/>        mal_features = [<br/>          <span class="ent">➌</span> extract_features(sha, path_to_files_dir=path_to_malicious_files,<br/>                             hash_dim=features_length)<br/>          <span class="ent">➍</span> for sha in np.random.choice(malicious_files, n_samples_per_class,<br/>                                        replace=False)<br/>        ]<br/>      <span class="ent">➎</span> all_features = ben_features + mal_features<br/>        labels = [0 for i in range(n_samples_per_class)] + [1 for i in range(<br/>                  n_samples_per_class)]<br/><br/>        idx = np.random.choice(range(batch_size), batch_size)<br/>      <span class="ent">➏</span> all_features = np.array([np.array(all_features[i]) for i in idx]) <br/>        labels = np.array([labels[i] for i in idx])<br/>      <span class="ent">➐</span> yield all_features, labels</p>
<p class="listing" id="ch11list4"><em>Listing 11-4: Writing a data generator</em></p>
<p class="indent">First, the code makes two <span class="literal">assert</span> statements to check that enough data is there <span class="ent">➊</span>. Then inside a <span class="literal">while</span> <span class="ent">➋</span> loop (so it’ll just iterate forever), both benign and malicious features are grabbed by choosing a random sample <span class="ent">➍</span> of file keys and then extracting features for those files using our <span class="literal">extract_features</span> function <span class="ent">➌</span>. Next, the benign and malicious features and associated labels (0 and 1) are concatenated <span class="ent">➎</span> and shuffled <span class="ent">➏</span>. Finally, these features and labels are returned <span class="ent">➐</span>.</p>
<p class="indent">Once instantiated, this generator should yield <span class="literal">batch_size</span> features and labels for the model to train on (50 percent malicious, 50 percent benign) each time the generator’s <span class="literal">next()</span> method is called.</p>
<p class="indent"><a href="ch11.xhtml#ch11list5">Listing 11-5</a> shows how to create a training data generator using the data that comes with this book, and how to train our model by passing the generator to our model’s <span class="literal">fit_generator</span> method.</p>
<p class="programs"><span epub:type="pagebreak" id="page_206"/>   import os<br/><br/>   batch_size = 128<br/>   features_length = 1024<br/>   path_to_training_benign_files = 'data/html/benign_files/training/'<br/>   path_to_training_malicious_files = 'data/html/malicious_files/training/'<br/>   steps_per_epoch = 1000 # artificially small for example-code speed!<br/><br/><span class="ent">➊</span> train_benign_files = os.listdir(path_to_training_benign_files)<br/><span class="ent">➋</span> train_malicious_files = os.listdir(path_to_training_malicious_files)<br/><br/>   # make our training data generator!<br/><span class="ent">➌</span> training_generator = my_generator(<br/>       benign_files=train_benign_files,<br/>       malicious_files=train_malicious_files,<br/>       path_to_benign_files=path_to_training_benign_files,<br/>       path_to_malicious_files=path_to_training_malicious_files,<br/>       batch_size=batch_size,<br/>       features_length=features_length<br/>   )<br/><br/><span class="ent">➍</span> model.fit_generator(<br/>    <span class="ent">➎</span> generator=training_generator,<br/>    <span class="ent">➏</span> steps_per_epoch=steps_per_epoch,<br/>    <span class="ent">➐</span> epochs=10<br/>   )</p>
<p class="listing" id="ch11list5"><em>Listing 11-5: Creating the training generator and using it to train the model</em></p>
<p class="indent">Try reading through this code to understand what’s happening. After importing a necessary package and creating some parameter variables, we read the filenames for our benign <span class="ent">➊</span> and malicious training data <span class="ent">➋</span> into memory (but not the files themselves). We pass these values to our new <span class="literal">my_generator</span> function <span class="ent">➌</span> to get our training data generator. Finally, using our <span class="literal">model</span> from <a href="ch11.xhtml#ch11list1">Listing 11-1</a>, we use the <span class="literal">model</span>’s built-in <span class="literal">fit_generator</span> method <span class="ent">➍</span> to start training.</p>
<p class="indent">The <span class="literal">fit_generator</span> method takes three parameters. The <span class="literal">generator</span> parameter <span class="ent">➎</span> specifies the data generator that produces training data for each <em>batch</em>. During training, parameters are updated once per batch by averaging all the training observations’ signals for that batch. The <span class="literal">steps_per_epoch</span> parameter <span class="ent">➏</span> sets the number of batches we want the model to process each <em>epoch</em>. As a result, the total number of observations the model sees per epoch is <span class="literal">batch_size*steps_per_epoch</span>. By convention, the number of observations a model sees per epoch should be equal to the dataset size, but in this chapter and in the virtual machine sample code, I reduce <span class="literal">steps_per_epoch</span> to make our code run faster. The <span class="literal">epochs</span> parameter <span class="ent">➐</span> sets the number of epochs we want to run.</p>
<p class="indent">Try running this code in the <em>ch11/</em> directory that accompanies this book. Depending on the power of your computer, each training epoch will take a certain amount of time to run. If you’re using an interactive session, feel free to cancel the process (<small>CTRL</small>-C) after a few epochs if it’s taking a while. This <span epub:type="pagebreak" id="page_207"/>will stop the training without losing progress. After you cancel the process (or the code completes), you’ll have a trained model! The readout on your virtual machine screen should look something like <a href="ch11.xhtml#ch11fig2">Figure 11-2</a>.</p>
<div class="image"><a id="ch11fig2"/><img alt="image" src="../images/f0207-01.jpg"/></div>
<p class="figcap"><em>Figure 11-2: Console output from training a</em> <span class="codeitalic">Keras</span> <em>model</em></p>
<p class="indent">The top few lines note that TensorFlow, which is the default backend to <span class="literal">Keras</span>, has been loaded. You’ll also see some warnings like in <a href="ch11.xhtml#ch11fig2">Figure 11-2</a>; these just mean that the training will be done on CPUs instead of GPUs (GPUs are often around 2–20 times faster for training neural networks, but for the purposes of this book, CPU-based training is fine). Finally, you’ll see a progress bar for each epoch indicating how much longer the given epoch will take, as well as the epoch’s loss and accuracy metrics.</p>
<h4 class="h4" id="lev189"><strong><em>Incorporating Validation Data</em></strong></h4>
<p class="noindent">In the previous section, you learned how to train a <span class="literal">Keras</span> model on HTML files using the scalable <span class="literal">fit_generator</span> method. As you saw, the model prints statements during training, indicating each epoch’s current loss and accuracy statistics. However, what you really care about is how your trained model does on <em>validation data</em>, or data that it has never seen before. This better represents the kind of data your model will face in a real-life production environment.</p>
<p class="indent">When trying to design better models and figure out how long to train your model for, you should try to maximize <em>validation accuracy</em> rather than <em>training accuracy</em>, the latter of which was shown in <a href="ch11.xhtml#ch11fig2">Figure 11-2</a>. Even better would be using validation files originating from dates after the training data to better simulate a production environment.</p>
<p class="indent"><a href="ch11.xhtml#ch11list6">Listing 11-6</a> shows how to load our validation features into memory using our <span class="literal">my_generator</span> function from <a href="ch11.xhtml#ch11list4">Listing 11-4</a>.</p>
<p class="programs">   import os<br/>   path_to_validation_benign_files = 'data/html/benign_files/validation/'<br/><span epub:type="pagebreak" id="page_208"/>   path_to_validation_malicious_files = 'data/html/malicious_files/validation/'<br/>   # get the validation keys:<br/>   val_benign_file_keys = os.listdir(path_to_validation_benign_files)<br/>   val_malicious_file_keys = os.listdir(path_to_validation_malicious_files)<br/>   # grab the validation data and extract the features:<br/><span class="ent">➊</span> validation_data = my_generator(<br/>       benign_files=val_benign_files,<br/>       malicious_files=val_malicious_files,<br/>       path_to_benign_files=path_to_validation_benign_files,<br/>       path_to_malicious_files=path_to_validation_malicious_files,<br/>     <span class="ent">➋</span> batch_size=10000,<br/>       features_length=features_length<br/><span class="ent">➌</span> ).next()</p>
<p class="listing" id="ch11list6"><em>Listing 11-6: Reading validation features and labels into memory by using the</em> <span class="codeitalic">my_generator</span> <em>function</em></p>
<p class="indent">This code is very similar to how we created our training data generator, except that the file paths have changed and now we want to load all the validation data into memory. So instead of just creating the generator, we create a validation data generator <span class="ent">➊</span> with a large <span class="literal">batch_size</span> <span class="ent">➋</span> equal to the number of files we want to validate on, and we immediately call its <span class="literal">.next()</span> <span class="ent">➌</span> method just once.</p>
<p class="indent">Now that we have some validation data loaded into memory, <span class="literal">Keras</span> allows us to simply pass <span class="literal">fit_generator()</span> our validation data during training, as shown in <a href="ch11.xhtml#ch11list7">Listing 11-7</a>.</p>
<p class="programs">model.fit_generator(<br/>  <span class="ent">➊</span> validation_data=validation_data,<br/>    generator=training_generator,<br/>    steps_per_epoch=steps_per_epoch,<br/>    epochs=10<br/>)</p>
<p class="listing" id="ch11list7"><em>Listing 11-7: Using validation data for automatic monitoring during training</em></p>
<p class="indent"><a href="ch11.xhtml#ch11list7">Listing 11-7</a> is almost identical to the end of <a href="ch11.xhtml#ch11list5">Listing 11-5</a>, except that <span class="literal">validation_data</span> is now passed to <span class="literal">fit_generator</span> <span class="ent">➊</span>. This helps enhance model monitoring by ensuring that validation loss and accuracy are calculated alongside training loss and accuracy.</p>
<p class="indent">Now, training statements should look something like <a href="ch11.xhtml#ch11fig3">Figure 11-3</a>.</p>
<div class="image"><a id="ch11fig3"/><img alt="image" src="../images/f0208-01.jpg"/></div>
<p class="figcap"><em>Figure 11-3: Console output from training a</em> <span class="codeitalic">Keras</span> <em>model with validation data</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_209"/><a href="ch11.xhtml#ch11fig3">Figure 11-3</a> is similar to <a href="ch11.xhtml#ch11fig2">Figure 11-2</a>, except that instead of just showing training <span class="literal">loss</span> and <span class="literal">acc</span> metrics for each epoch, now <span class="literal">Keras</span> also calculates and shows <span class="literal">val_loss</span> (validation loss) and <span class="literal">val_acc</span> (validation accuracy) for each epoch. In general, if validation accuracy is going down instead of up, that’s an indication your model is overfitting to your training data, and it would be best to halt training. If validation accuracy is going up, as is the case here, it means your model is still getting better and you should continue training.</p>
<h4 class="h4" id="lev190"><strong><em>Saving and Loading the Model</em></strong></h4>
<p class="noindent">Now that you know how to build and train a neural network, let’s go over how to save it so you can share it with others.</p>
<p class="indent"><a href="ch11.xhtml#ch11list8">Listing 11-8</a> shows how to save our trained model to an <em>.h5</em> file <span class="ent">➊</span> and reload <span class="ent">➋</span> it (at a potentially later date).</p>
<p class="programs">   from keras.models import load_model<br/>   # save the model<br/><span class="ent">➊</span> model.save('my_model.h5')<br/>   # load the model back into memory from the file:<br/><span class="ent">➋</span> same_model = load_model('my_model.h5')</p>
<p class="listing" id="ch11list8"><em>Listing 11-8: Saving and loading</em> <span class="codeitalic">Keras</span> <em>models</em></p>
<h3 class="h3" id="lev191"><strong>Evaluating the Model</strong></h3>
<p class="noindent">In the model training section, we observed some default model evaluation metrics like training loss and accuracy as well as validation loss and accuracy. Let’s now review some more complex metrics to better evaluate our models.</p>
<p class="indent">One useful metric for evaluating the accuracy of a binary predictor is called <em>area under the curve (AUC)</em>. The curve refers to a Receiver Operating Characteristic (ROC) curve (see <a href="ch08.xhtml#ch08">Chapter 8</a>), which plots false-positive rates (x-axis) against true-positive rates (y-axis) for all possible score thresholds.</p>
<p class="indent">For example, our model tries to predict whether a file is malicious by using a score between 0 (benign) and 1 (malicious). If we choose a relatively high score threshold to classify a file as malicious we’ll get fewer false-positives (good) but also fewer true-positives (bad). On the other hand, if we choose a low score threshold, we’ll likely have a high false-positive rate (bad) but a very high detection rate (good).</p>
<p class="indent">These two sample possibilities would be represented as two points on our model’s ROC curve, where the first would be located toward the left side of the curve and the second near the right side. AUC represents all these possibilities by simply taking the area under this ROC curve, as shown in <a href="ch11.xhtml#ch11fig4">Figure 11-4</a>.</p>
<p class="indent">In simple terms, an AUC of 0.5 represents the predictive capability of a coin flip, while an AUC of 1 is perfect.</p>
<div class="image"><span epub:type="pagebreak" id="page_210"/><a id="ch11fig4"/><img alt="image" src="../images/f0210-01.jpg"/></div>
<p class="figcap"><em>Figure 11-4: Various sample ROC curves. Each ROC curve (line) corresponds to a different AUC value.</em></p>
<p class="indent">Let’s use our validation data to calculate validation AUC using the code in <a href="ch11.xhtml#ch11list9">Listing 11-9</a>.</p>
<p class="programs">   from sklearn import metrics<br/><br/><span class="ent">➊</span> validation_labels = validation_data[1]<br/><span class="ent">➋</span> validation_scores = [el[0] for el in model.predict(validation_data[0])]<br/><span class="ent">➌</span> fpr, tpr, thres = metrics.roc_curve(y_true=validation_labels,<br/>                                       y_score=validation_scores)<br/><span class="ent">➍</span> auc = metrics.auc(fpr, tpr)<br/>   print('Validation AUC = {}'.format(auc))</p>
<p class="listing" id="ch11list9"><em>Listing 11-9: Calculating validation AUC using</em> <span class="codeitalic">sklearn</span><em>’s</em> <span class="codeitalic">metric</span> <em>submodule</em></p>
<p class="indent">Here, we split our <span class="literal">validation_data</span> tuple into two objects: the validation labels represented by <span class="literal">validation_labels</span> <span class="ent">➊</span>, and flattened validation model predictions represented by <span class="literal">validation_scores</span> <span class="ent">➋</span>. Then, we use the <span class="literal">metrics.roc_curve</span> function from <span class="literal">sklearn</span> to calculate false-positive rates, true-positive rates, and associated threshold values for the model predictions <span class="ent">➌</span>. Using these, we calculate our AUC metric, again using an <span class="literal">sklearn</span> function <span class="ent">➍</span>.</p>
<p class="indent">Although I won’t go over the function code here, you can also use the <span class="literal">roc_plot()</span> function included in the <em>ch11/model_evaluation.py</em> file in the data accompanying this book to plot the actual ROC curve, as shown in <a href="ch11.xhtml#ch11list10">Listing 11-10</a>.</p>
<p class="programs">from ch11.model_evaluation import roc_plot<br/>roc_plot(fpr=fpr, tpr=tpr, path_to_file='roc_curve.png')</p>
<p class="listing" id="ch11list10"><em>Listing 11-10: Creating a ROC curve plot using the</em> <span class="codeitalic">roc_plot</span> <em>function from this book’s accompanying data, in</em> ch11/model_evaluation.py</p>
<p class="indent"><span epub:type="pagebreak" id="page_211"/>Running the code in <a href="ch11.xhtml#ch11list10">Listing 11-10</a> should generate a plot (saved to <em>roc_curve.png</em>) that looks like <a href="ch11.xhtml#ch11fig5">Figure 11-5</a>.</p>
<div class="image"><a id="ch11fig5"/><img alt="image" src="../images/f0211-01.jpg"/></div>
<p class="figcap"><em>Figure 11-5:</em> A ROC curve!</p>
<p class="indent">Each point in the ROC curve in <a href="ch11.xhtml#ch11fig5">Figure 11-5</a> represents a specific false-positive rate (x-axis) and true-positive rate (y-axis) associated with various model prediction thresholds ranging from 0 to 1. As false-positive rates increase, true-positive rates increase, and vice versa. In production environments, you generally have to pick a single threshold (a single point on this curve, assuming validation data mimics production data) with which to make your decision, based on your willingness to tolerate false positives, versus your willingness to risk allowing a malicious file to slip through the cracks.</p>
<h3 class="h3" id="lev192"><strong>Enhancing the Model Training Process with Callbacks</strong></h3>
<p class="noindent">So far, you’ve learned how to design, train, save, load, and evaluate <span class="literal">Keras</span> models. Although this is really all you need to get a fairly good start, I also want to introduce <span class="literal">Keras</span> callbacks, which can make our model training process even better.</p>
<p class="indent">A <span class="literal">Keras</span> callback represents a set of functions that <span class="literal">Keras</span> applies during certain stages of the training process. For example, you can use a <span class="literal">Keras</span> callback to make sure that an <em>.h5</em> file is saved at the end of each epoch, or that validation AUC is printed to the screen at the end of each epoch. This can help record and inform you more precisely of how your model is doing during the training process.</p>
<p class="indent">We begin by using a built-in callback, and then we try writing our own custom callback.</p>
<h4 class="h4" id="lev193"><span epub:type="pagebreak" id="page_212"/><strong><em>Using a Built-in Callback</em></strong></h4>
<p class="noindent">To use a built-in callback, simply pass your model’s <span class="literal">fit_generator()</span> method a callback instance during training. We’ll use the <span class="literal">callbacks.ModelCheckpoint</span> callback, which evaluates validation loss after each training epoch, and saves the current model to a file <em>if</em> the validation loss is smaller than any previous epoch’s validation losses. To do this, the callback needs access to our validation data, so we’ll pass that in to the <span class="literal">fit_generator()</span> method, as shown in <a href="ch11.xhtml#ch11list11">Listing 11-11</a>.</p>
<p class="programs">from keras import callbacks<br/><br/>model.fit_generator(<br/>    generator=training_generator,<br/>    # lowering steps_per_epoch so the example code runs fast:<br/>    steps_per_epoch=50,<br/>    epochs=5,<br/>    validation_data=validation_data,<br/>    callbacks=[<br/>        callbacks.ModelCheckpoint(save_best_only=True,<span class="ent">➊</span><br/>                                  <span class="ent">➋</span> filepath='results/best_model.h5',<br/>                                  <span class="ent">➌</span> monitor='val_loss')<br/>   ],<br/>)</p>
<p class="listing" id="ch11list11"><em>Listing 11-11: Adding a</em> <span class="codeitalic">ModelCheckpoint</span> <em>callback to the training process</em></p>
<p class="indent">This code ensures that the model is overwritten <span class="ent">➊</span> to a single file, <span class="literal">'results/best_model.h5'</span> <span class="ent">➋</span>, whenever <span class="literal">'val_loss'</span> <span class="ent">➌</span> (validation loss) reaches a new low. This ensures that the current saved model (<span class="literal">'results/best_model.h5'</span>) always represents the best model across all completed epochs with regard to validation loss.</p>
<p class="indent">Alternatively, we can use the code in <a href="ch11.xhtml#ch11list12">Listing 11-12</a> to save the model after every epoch to a <em>separate</em> file regardless of validation loss.</p>
<p class="programs">callbacks.ModelCheckpoint(save_best_only=False,<span class="ent">➍</span><br/>                        <span class="ent">➎</span> filepath='results/model_epoch_{epoch}.h5',<br/>                          monitor='val_loss')</p>
<p class="listing" id="ch11list12"><em>Listing 11-12: Adding a</em> <span class="codeitalic">ModelCheckpoint</span> <em>callback to the training process that saves the model to a different file after each epoch</em></p>
<p class="indent">To do this, we use the same code in <a href="ch11.xhtml#ch11list11">Listing 11-11</a> and the same function <span class="literal">ModelCheckpoint</span>, but with <span class="literal">save_best_only=False</span> <span class="ent">➍</span> and a <span class="literal">filepath</span> that asks <span class="literal">Keras</span> to fill in the epoch number <span class="ent">➎</span>. Instead of only saving the single “best” version of our model, <a href="ch11.xhtml#ch11list12">Listing 11-12</a>’s callback saves each epoch’s version of our model, in <em>results/model_epoch_0.h5</em>, <em>results/model_epoch_1.h5</em>, <em>results/model_epoch_2.h5</em>, and so on.</p>
<h4 class="h4" id="lev194"><span epub:type="pagebreak" id="page_213"/><strong><em>Using a Custom Callback</em></strong></h4>
<p class="noindent">Although <span class="literal">Keras</span> doesn’t support AUC, we can design our own custom callback to, for example, allow us to print AUC to the screen after each epoch.</p>
<p class="indent">To create a custom <span class="literal">Keras</span> callback, we need to create a class that inherits from <span class="literal">keras.callbacks.Callback</span>, the abstract base class used to build new callbacks. We can add one or more of a selection of methods, which will be run automatically during training, at times that their names specify: <span class="literal">on_epoch_begin</span>, <span class="literal">on_epoch_end</span>, <span class="literal">on_batch_begin</span>, <span class="literal">on_batch_end</span>, <span class="literal">on_train_begin</span>, and <span class="literal">on_train_end</span>.</p>
<p class="indent"><a href="ch11.xhtml#ch11list13">Listing 11-13</a> shows how to create a callback that calculates and prints validation AUC to the screen at the end of each epoch.</p>
<p class="programs">   import numpy as np<br/>   from keras import callbacks<br/>   from sklearn import metrics<br/><br/><span class="ent">➊</span> class MyCallback(callbacks.Callback):<br/><br/>    <span class="ent">➋</span> def on_epoch_end(self, epoch, logs={}):<br/>        <span class="ent">➌</span> validation_labels = self.validation_data[1]<br/>           validation_scores = self.model.predict(self.validation_data[0])<br/>           # flatten the scores:<br/>           validation_scores = [el[0] for el in validation_scores]<br/>           fpr, tpr, thres = metrics.roc_curve(y_true=validation_labels,<br/>                                               y_score=validation_scores)<br/>        <span class="ent">➍</span> auc = metrics.auc(fpr, tpr)<br/>           print('\n\tEpoch {}, Validation AUC = {}'.format(epoch,<br/>                                                            np.round(auc, 6)))<br/>   model.fit_generator(<br/>       generator=training_generator,<br/>       # lowering steps_per_epoch so the example code runs fast:<br/>       steps_per_epoch=50,<br/>       epochs=5,<br/>    <span class="ent">➎</span> validation_data=validation_data,<br/>    <span class="ent">➏</span> callbacks=[<br/>           callbacks.ModelCheckpoint('results/model_epoch_{epoch}.h5',<br/>                                     monitor='val_loss',<br/>                                     save_best_only=False,<br/>                                     save_weights_only=False)<br/>       ]<br/>   )</p>
<p class="listing" id="ch11list13"><em>Listing 11-13: Creating and using a custom callback to print AUC to the screen after each training epoch</em></p>
<p class="indent">In this example, we first create our <span class="literal">MyCallback</span> class <span class="ent">➊</span>, which inherits from <span class="literal">callbacks.Callbacks</span>. Keeping things simple, we overwrite a single method, <span class="literal">on_epoch_end</span> <span class="ent">➋</span>, and give it two arguments expected by <span class="literal">Keras</span>: <span class="literal">epoch</span> and <span class="literal">logs</span> (a dictionary of log information), both of which <span class="literal">Keras</span> will supply when it calls the function during training.</p>
<p class="indent"><span epub:type="pagebreak" id="page_214"/>Then, we grab the <span class="literal">validation_data</span> <span class="ent">➌</span>, which is already stored in the <span class="literal">self</span> object thanks to <span class="literal">callbacks.Callback</span> inheritance, and we calculate and print out AUC <span class="ent">➍</span> like we did in “<a href="ch11.xhtml#lev191">Evaluating the Model</a>” on <a href="ch11.xhtml#page_209">page 209</a>. Note that for this code to work, the validation data needs to be passed to <span class="literal">fit_generator()</span> so that the callback has access to <span class="literal">self.validation_data</span> during training <span class="ent">➎</span>. Finally, we tell the model to train and specify our new callback <span class="ent">➏</span>. The result should look something like <a href="ch11.xhtml#ch11fig6">Figure 11-6</a>.</p>
<div class="image"><a id="ch11fig6"/><img alt="image" src="../images/f0214-01.jpg"/></div>
<p class="figcap"><em>Figure 11-6: Console output from training a</em> <span class="codeitalic">Keras</span> <em>model with a custom AUC callback</em></p>
<p class="indent">If what you really care about is minimizing validation AUC, this callback makes it easy to see how your model is doing during training, thus helping you assess whether you should stop the training process (for example, if validation accuracy is going consistently down over time).</p>
<h3 class="h3" id="lev195"><strong>Summary</strong></h3>
<p class="noindent">In this chapter, you learned how to build your own neural network using <span class="literal">Keras</span>. You also learned to train, evaluate, save, and load it. You then learned how to enhance the model training process by adding built-in and custom callbacks. I encourage you to play around with the code accompanying this book to see what changes model architecture and feature extraction can have on model accuracy.</p>
<p class="indent">This chapter is meant to get your feet wet, but is not meant as a reference guide. Visit <em><a href="https://keras.io">https://keras.io</a></em> for the most up-to-date official documentation. I strongly encourage you to spend time researching aspects of <span class="literal">Keras</span> that interest you. Hopefully, this chapter has served as a good jumping-off point for all your security deep learning adventures!</p>
</body></html>