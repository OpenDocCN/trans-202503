- en: '**21'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**21'
- en: DATA-CENTRIC AI**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据中心化 AI**'
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: What is data-centric AI, how does it compare to the conventional modeling paradigm,
    and how do we decide whether it’s the right fit for a project?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是数据中心化 AI，它与传统的建模范式有何不同，以及我们如何判断它是否适合一个项目？
- en: Data-centric AI is a paradigm or workflow in which we keep the model training
    procedure fixed and iterate over the dataset to improve the predictive performance
    of a model. The following sections define what data-centric AI means in more detail
    and compare it to conventional model-centric approaches.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心化 AI 是一种范式或工作流，其中我们保持模型训练过程不变，并在数据集上反复迭代，以提高模型的预测性能。以下部分将更详细地定义数据中心化 AI
    的含义，并将其与传统的模型中心化方法进行比较。
- en: '**Data-Centric vs. Model-Centric AI**'
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**数据中心化与模型中心化 AI**'
- en: In the context of data-centric AI, we can think of the conventional workflow,
    which is often part of academic publishing, as model-centric AI. However, in an
    academic research setting, we are typically interested in developing new methods
    (for example, neural network architectures or loss functions). Here, we consider
    existing benchmark datasets to compare the new method to previous approaches and
    determine whether it is an improvement over the status quo.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据中心化 AI 的背景下，我们可以将传统的工作流，通常是学术出版中的一部分，视为模型中心化 AI。然而，在学术研究环境中，我们通常更关注开发新方法（例如，神经网络架构或损失函数）。在这里，我们考虑使用现有的基准数据集，将新方法与先前的方案进行比较，并判断它是否优于现状。
- en: '[Figure 21-1](ch21.xhtml#ch21fig1) summarizes the difference between data-centric
    and model-centric workflows.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 21-1](ch21.xhtml#ch21fig1) 总结了数据中心化与模型中心化工作流的区别。'
- en: '![Image](../images/21fig01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/21fig01.jpg)'
- en: '*Figure 21-1: Data-centric versus model-centric machine learning workflow*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 21-1：数据中心化与模型中心化机器学习工作流*'
- en: While *data-centric AI* is a relatively new term, the idea behind it is not.
    Many people I’ve spoken with say they used a data-centric approach in their projects
    before the term was coined. In my opinion, data-centric AI was created to make
    “caring about data quality” attractive again, as data collection and curation
    are often considered tedious or thankless. This is analogous to how the term *deep
    learning* made neural networks interesting again in the early 2010s.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管*数据中心化 AI*是一个相对较新的术语，但其背后的理念并不新鲜。我与许多人交流过，他们表示，在这个术语被创造之前，他们的项目中已经使用了数据中心化的方法。在我看来，数据中心化
    AI 的出现是为了重新吸引人们“关心数据质量”，因为数据收集和数据整理通常被认为是单调乏味或得不到应有回报的。这类似于“深度学习”一词在2010年代初期使得神经网络重新引起兴趣。
- en: Do we need to choose between data-centric and model-centric AI, or can we rely
    on both? In short, data-centric AI focuses on changing the data to improve performance,
    while model-centric approaches focus on modifying the model to improve performance.
    Ideally, we should use both in an applied setting where we want to get the best
    possible predictive performance. However, in a research setting or an exploratory
    stage of an applied project, working with too many variables simultaneously is
    messy. If we change both model and data at once, it’s hard to pinpoint which change
    is responsible for the improvement.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否需要在数据中心化与模型中心化 AI 之间做出选择，还是可以同时依赖这两者？简而言之，数据中心化 AI 侧重于通过改变数据来提高性能，而模型中心化方法则侧重于修改模型以提高性能。在应用场景中，我们理想情况下应该同时使用这两种方法，以获得最佳的预测性能。然而，在研究环境或应用项目的探索阶段，同时处理过多的变量是混乱的。如果我们同时改变模型和数据，就很难明确指出哪个变化导致了性能的提升。
- en: 'It is important to emphasize that data-centric AI is a paradigm and work-flow,
    not a particular technique. Data-centric AI therefore implicitly includes the
    following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 需要强调的是，数据中心化 AI 是一种范式和工作流，而不是一种特定的技术。因此，数据中心化 AI 隐含地包括以下内容：
- en: Analyses and modifications of training data, from outlier removal to missing
    data imputation
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据的分析和修改，从去除异常值到缺失数据的填补
- en: Data synthesis and data augmentation techniques
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据合成和数据增强技术
- en: Data labeling and label-cleaning methods
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据标注和标签清理方法
- en: The classic active learning setting where a model suggests which data points
    to label
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典的主动学习设置，其中模型建议需要标注的数据点
- en: We consider an approach *data centric* if we change only the data (using the
    methods listed here), not the other aspects of the modeling pipeline.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只改变数据（使用这里列出的技术），而不改变建模流程的其他方面，那么我们就认为这是*数据中心化*的方法。
- en: In machine learning and AI, we often use the phrase “garbage in, garbage out,”
    meaning that poor-quality data will result in a poor predictive model. In other
    words, we cannot expect a well-performing model from a low-quality dataset.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习和人工智能中，我们常用“垃圾进，垃圾出”这一说法，意思是低质量的数据会导致低质量的预测模型。换句话说，我们不能指望从低质量的数据集中得到一个表现良好的模型。
- en: I’ve observed a common pattern in applied academic projects that attempt to
    use machine learning to replace an existing methodology. Often, researchers have
    only a small dataset of examples (say, hundreds of training examples). Labeling
    data is often expensive or considered boring and thus best avoided. In these cases,
    the researchers spend an unreasonable amount of time trying out different machine-learning
    algorithms and model tuning. To resolve this issue, investing additional time
    or resources in labeling additional data would be worthwhile.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我在尝试用机器学习取代现有方法的应用学术项目中观察到一种常见模式。通常，研究人员只有一个小型数据集（比如几百个训练样本）。标注数据往往成本较高，或者被认为枯燥乏味，因此最好避免。在这些情况下，研究人员花费大量时间尝试不同的机器学习算法和模型调优。为了解决这个问题，投入更多时间或资源标注更多数据是值得的。
- en: The main advantage of data-centric AI is that it puts the data first so that
    if we invest resources to create a higher-quality dataset, all modeling approaches
    will benefit from it downstream.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中心化人工智能的主要优势在于它将数据置于首位，这样如果我们投入资源创建更高质量的数据集，所有建模方法都会从中受益。
- en: '**Recommendations**'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**建议**'
- en: Taking a data-centric approach is often a good idea in an applied project where
    we want to improve the predictive performance to solve a particular problem. In
    this context, it makes sense to start with a modeling baseline and improve the
    dataset since it’s often more worthwhile than trying out bigger, more expensive
    models.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用项目中，采取数据中心化的方法通常是一个好主意，尤其是在我们希望提高预测性能以解决特定问题的情况下。在这种背景下，从建模基准开始，并改善数据集是有意义的，因为这通常比尝试更大、更昂贵的模型更值得投资。
- en: If our task is to develop a new or better methodology, such as a new neural
    network architecture or loss function, a model-centric approach might be a better
    choice. Using an established benchmark dataset without changing it makes it easier
    to compare the new modeling approach to previous work. Increasing the model size
    usually improves performance, but so does the addition of training examples. Assuming
    small training sets (< 2*k*) for classification, extractive question answering,
    and multiple-choice tasks, adding a hundred examples can result in the same performance
    gain as adding billions of parameters.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的任务是开发一种新的或更好的方法论，比如新的神经网络架构或损失函数，基于模型的方法可能是一个更好的选择。使用已建立的基准数据集而不进行修改，使得将新的建模方法与以前的工作进行比较变得更加容易。增加模型的规模通常会提高性能，但增加训练样本数量也能带来类似的效果。假设对于分类、抽取式问答和多选任务来说，训练集较小（<
    2*k*），增加一百个样本可能会带来与增加数十亿参数相同的性能提升。
- en: In a real-world project, alternating between data-centric and model-centric
    modes makes a lot of sense. Investing in data quality early on will benefit all
    models. Once a good dataset is available, we can begin to focus on model tuning
    to improve performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际项目中，交替使用数据中心化和模型中心化的模式是非常有意义的。早期投资于数据质量将惠及所有模型。一旦获得了好的数据集，我们可以开始专注于模型调优以提升性能。
- en: '**Exercises**'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**练习**'
- en: '**21-1.** A recent trend is the increased use of predictive analytics in healthcare.
    For example, suppose a healthcare provider develops an AI system that analyzes
    patients’ electronic health records and provides recommendations for lifestyle
    changes or preventive measures. For this, the provider requires patients to monitor
    and share their health data (such as pulse and blood pressure) daily. Is this
    an example of data-centric AI?'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**21-1.** 最近的一个趋势是医疗保健领域对预测分析的日益重视。例如，假设一家医疗服务提供商开发了一个AI系统，分析患者的电子健康记录，并提供生活方式改变或预防措施的建议。为此，提供商要求患者每天监测并共享健康数据（如脉搏和血压）。这是数据中心化人工智能的一个例子吗？'
- en: '**21-2.** Suppose we train a ResNet-34 convolutional neural network to classify
    images in the CIFAR-10 and ImageNet datasets. To reduce overfitting and improve
    classification accuracy, we experiment with data augmentation techniques such
    as image rotation and cropping. Is this approach data centric?'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**21-2.** 假设我们训练一个ResNet-34卷积神经网络，用于对CIFAR-10和ImageNet数据集中的图像进行分类。为了减少过拟合并提高分类准确性，我们实验了数据增强技术，如图像旋转和裁剪。这种方法算是数据中心化吗？'
- en: '**References**'
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: 'An example of how adding more training data can benefit model performance more
    than an increase in model size: Yuval Kirstain et al., “A Few More Examples May
    Be Worth Billions of Parameters” (2021), *[https://arxiv.org/abs/2110.04374](https://arxiv.org/abs/2110.04374)*.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个例子说明了增加更多训练数据如何比增加模型大小更能提升模型性能：Yuval Kirstain等人，《更多示例可能比数十亿参数更有价值》（2021），*[https://arxiv.org/abs/2110.04374](https://arxiv.org/abs/2110.04374)*。
- en: 'Cleanlab is an open source library that includes methods for improving labeling
    errors and data quality in computer vision and natural language processing contexts:
    *[https://github.com/cleanlab/cleanlab](https://github.com/cleanlab/cleanlab)*.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cleanlab是一个开源库，包含了在计算机视觉和自然语言处理领域中提高标签错误和数据质量的方法：*[https://github.com/cleanlab/cleanlab](https://github.com/cleanlab/cleanlab)*。
