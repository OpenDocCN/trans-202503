<html><head></head><body>
<h2 class="h2c" id="ch11"><span epub:type="pagebreak" id="page_221"/><span class="big1"><strong>11</strong></span><br/><strong>PUTTING IT ALL TOGETHER: WRITING AUTONOMOUS BOTS</strong></h2>&#13;
<div class="image"><img src="../images/common.jpg" alt="image"/></div>&#13;
<p class="noindent">The end goal of game hacking is to make a full-fledged automated bot capable of playing a game for hours on end. Such bots can heal, drink potions, farm monsters, loot corpses, walk around, sell loot, buy supplies, and more. Making bots this powerful requires you to combine your hooks and memory reads with concepts like control theory, state machines, and search algorithms, which are all covered in this chapter.</p>&#13;
<p class="indent">Throughout the lessons here, you’ll also learn about common automated hacks and how they should behave at a high level. After covering the theory and code behind automated hacks, I’ll give you a high-level look at two types of bots that rely on such code: <em>cavebots</em>, which can explore <span epub:type="pagebreak" id="page_222"/>caves and bring home the loot, and <em>warbots</em>, which can fight enemies for you. By the end of the chapter, you should be ready to bust out your tools, fire up your development environment, and start making some really awesome bots.</p>&#13;
<h3 class="h3" id="ch00lev1sec221"><strong>Control Theory and Game Hacking</strong></h3>&#13;
<p class="noindent"><em>Control theory</em> is a branch of engineering that provides a way to control the behavior of dynamic systems. Control theory determines the state of a <em>system</em> using <em>sensors</em>, after which a <em>controller</em> determines the set of actions needed to bring the system’s current state to some other desired state. After the controller executes the first action in the set, the entire process—known as a <em>feedback loop</em>—repeats (see <a href="ch11.xhtml#ch11fig1">Figure 11-1</a>).</p>&#13;
<div class="image"><img src="../images/f11-01.jpg" alt="image"/></div>&#13;
<p class="figcap"><a id="ch11fig1"/><em>Figure 11-1: A control theory feedback loop</em></p>&#13;
<p class="indent">Let’s apply this feedback loop to game hacking. To automate play within a game (the system), a bot implements some algorithms (the controller) that understand how to play the game in any state observed by the memory reads, network hooks, and so on (the sensors). The controller typically has some human inputs, like the path to walk, creatures to attack, and loot to pick up. Thus, to reach the desired state, the controller must perform some subset of these inputs that are possible given the current state.</p>&#13;
<p class="indent">For instance, if there are no creatures onscreen and no corpses to loot, the desired state may be for the player to reach the next location (called a <em>waypoint</em>) in the predefined path. In this case, the controller moves the player one step closer to the waypoint on each iteration. If the player encounters a creature, the controller might decide to attack the creature in the first frame and, in the following frames, switch between running from the creature (known as <em>kiting</em>) and shooting spells at it. Once the creature dies, the controller executes a set of actions to loot the body and continue to the next waypoint.</p>&#13;
<p class="indent">Given this example of how a feedback loop might operate, it might seem overwhelming to code such a system. Luckily, there are a few design patterns that make the task much easier than it sounds.</p>&#13;
<h3 class="h3" id="ch00lev1sec222"><span epub:type="pagebreak" id="page_223"/><strong>State Machines</strong></h3>&#13;
<p class="noindent"><em>State machines</em> are mathematical models of computation that describe how a system behaves based on input. <a href="ch11.xhtml#ch11fig2">Figure 11-2</a> shows a simple state machine that reads a list of binary digits. The machine starts with an initial state of <em>S</em><sub>1</sub>. As it iterates over the digits in the input, it changes its state accordingly. In this case, states <em>S</em><sub>1</sub> and <em>S</em><sub>2</sub> repeat themselves when the machine encounters a 1 and activate one another when it encounters a 0. For example, for the binary digits 11000111, the state transitions would be <em>S</em><sub>1</sub>, <em>S</em><sub>1</sub>, <em>S</em><sub>2</sub>, <em>S</em><sub>1</sub>, <em>S</em><sub>2</sub>, <em>S</em><sub>2</sub>, <em>S</em><sub>2</sub>, and finally <em>S</em><sub>2</sub>.</p>&#13;
<div class="image"><img src="../images/f11-02.jpg" alt="image"/></div>&#13;
<p class="figcap"><a id="ch11fig2"/><em>Figure 11-2: A simple state machine</em></p>&#13;
<p class="indent">With a small spin on the classical state machine theory, a state machine can be the controller in a control theory feedback loop. This tweaked version of a state machine comprises a list of states, the conditions signifying each state, and the actions that must happen to reach each state.</p>&#13;
<div class="sidebar">&#13;
<p class="sidebart"><strong>STATE MACHINES AND GAME HACKING</strong></p>&#13;
<p class="noindent">A game-hacking state machine not only must keep an internal state but also must respond to (or <em>actuate</em>) the game environment based on that state. The overall game state can change based on your bot’s actuation, the behavior of other players, and other unpredictable occurrences in the game environment. For this reason, trying to persistently walk a state machine based on the observed game environment is futile; it’s nearly impossible to create a set of transitions for each state to account for every possible observation that can be made between iterations. It makes more sense for the state machine to reevaluate the game environment as a fresh slate each time it considers the input. To do this, the state machine must use the game environment itself as the mechanism for transitioning between states—that is, the machine’s actuation on the environment should have enough of an effect on the next iterations that it activates a new state. Classical state machines can be devised that are capable of working like this, but we’re going to flatten them out and use them in a much simpler, yet still very powerful, way.</p>&#13;
<p class="indent">If you’re familiar with classical state machines, this may not seem intuitive, but in the coming sections you’ll see how state machines can be mutated and paired with control theory to achieve what we want.</p>&#13;
</div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_224"/>The major difference is that instead of one state merely activating another, for each state in a game automation state machine, a bot will perform in-game actions that change the overall state of the game and, thus, the state that is detected on the next iteration of the feedback loop. In code, an object to represent a state in this machine might look like this:</p>&#13;
<pre>class StateDefinition {<br/>public:<br/>    StateDefinition(){}<br/>    ~StateDefinition(){}<br/>    bool condition();<br/>    void reach();<br/>};</pre>&#13;
<p class="indent">You can assemble <code>StateDefinition</code> objects into a state machine with a simple <code>std::vector</code> definition, like this:</p>&#13;
<pre>std::vector&lt;StateDefinition&gt; stateMachine;</pre>&#13;
<p class="indent">And presto, you have the skeleton of a state machine, ready to receive any <code>StateDefinition</code> objects you create. In conjunction with a feedback loop, this state machine can be used to define the flow of automation.</p>&#13;
<p class="indent">First, you can create a list of definitions that model your bot’s desired behavior, ordered in the vector by importance. Each <code>StateDefinition</code> object can use information from your sensors as input, passing that data to the <code>condition()</code> function to determine whether or not the state should be activated. Then, you can create a controller that loops over the list of states, calling the <code>reach()</code> function of the first state whose <code>condition()</code> function returns <code>false</code>. Finally, you can wrap the controller in a feedback loop. If you don’t see how this feedback loop would work yet, don’t worry; I’ll show you how to code it now.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>You can think of the statement in your</em> <code><span class="codeitalic">condition()</code></span> <em>function as a requirement for the machine to transition to the next state. If the statement is true, it means no actuation must happen before the next state in the list can be evaluated and the loop can continue iterating. If the statement is false, it means some actuator must occur before the transition can happen.</em></p>&#13;
</div>&#13;
<p class="indent">You’ll find all of the example code for the following section and “<a href="ch11.xhtml#ch00lev1sec226">Error Correction</a>” on <a href="ch11.xhtml#page_230">page 230</a> in the <em>GameHackingExamples/Chapter11_ StateMachines</em> directory of this book’s source files. The included projects can be compiled with Visual Studio 2010, but they should also work with any other C++ compiler. Download them at <em><a href="https://www.nostarch.com/gamehacking/">https://www.nostarch.com/gamehacking/</a></em> and compile them if you want to follow along.</p>&#13;
<h3 class="h3" id="ch00lev1sec223"><span epub:type="pagebreak" id="page_225"/><strong>Combining Control Theory and State Machines</strong></h3>&#13;
<p class="noindent">To tie states together with a feedback loop, first you have to provide each <code>StateDefinition</code> object with a generic way to access the sensors and actuators that you’ve implemented. The <code>StateDefinition</code> class then becomes the following:</p>&#13;
<pre>class StateDefinition {<br/>public:<br/>    StateDefinition(){}<br/>    ~StateDefinition(){}<br/>    bool condition(GameSensors* sensors);<br/>    void reach(GameSensors* sensors, GameActuators* actuators);<br/>};</pre>&#13;
<p class="indent">This change simply modifies the <code>condition()</code> and <code>reach()</code> functions to accept instances of the classes <code>GameSensors</code> and <code>GameActuators</code> as arguments. <code>GameSensors</code> and <code>GameActuators</code> are classes you need to define; <code>GameSensors</code> will contain the results of memory reads, network hooks, and other data sources your bot intercepts from the game, while <code>GameActuators</code> will be a collection of actor functions capable of performing actions inside the game.</p>&#13;
<p class="indent">Next, you need a generic way to define each individual state. You could abstract the definition of each state to its own class that inherits <code>StateDefinition</code> and implements <code>condition()</code> and <code>reach()</code> as virtual functions. Alternatively, if the source code needs to fit in a small space (like a book, <em>wink wink</em>), you could keep a single class to represent each definition and use <code>std::function</code> to implement the <code>condition()</code> and <code>reach()</code> functions outside the class definition.</p>&#13;
<p class="indent">Following that alternative method, the final version of <code>StateDefinition</code> would look like this:</p>&#13;
<pre>class StateDefinition {<br/>public:<br/>    StateDefinition(){}<br/>    ~StateDefinition(){}<br/>    std::function&lt;bool(GameSensors*)&gt; condition;<br/>    std::function&lt;void(GameSensors*, GameActuators*)&gt; reach;<br/>};</pre>&#13;
<p class="indent">With this version of the <code>StateDefinition</code> class, you could define a new state by creating an instance of the class and assigning <code>condition()</code> and <code>reach()</code> to functions that correspond with the intended behavior.</p>&#13;
<h4 class="h4" id="ch00lev1sec224"><strong><em>A Basic Healer State Machine</em></strong></h4>&#13;
<p class="noindent">The next step is defining the bot’s actual behavior. To keep the example code simple, let’s say you’re implementing an automatic healer. This healer <span epub:type="pagebreak" id="page_226"/>has two healing methods: it uses strong healing if the player is at or below 50 percent health and weak healing if the player is between 51 and 70 percent health.</p>&#13;
<p class="indent">A state machine representing this behavior needs two states, one for strong healing and one for weak healing. To start, you need to define the state machine as a vector with two <code>StateDefinition</code> objects:</p>&#13;
<pre>std::vector&lt;StateDefinition&gt; stateMachine(2);</pre>&#13;
<p class="indent">This code creates a state machine called <code>stateMachine</code> and initializes it with two empty <code>StateDefinition</code> objects. Next, you define the <code>condition()</code> and <code>reach()</code> functions for these state definitions. The strong healing state is the most important because it keeps the character from dying, so it should come first in the vector, as shown in <a href="ch11.xhtml#ch11exe1">Listing 11-1</a>.</p>&#13;
<pre>   auto curDef = stateMachine.begin();<br/>   curDef-&gt;condition = [](GameSensors* sensors) {<br/><span class="ent">➊</span>     return sensors-&gt;getHealthPercent() &gt; 50;<br/>   };<br/>   curDef-&gt;reach = [](GameSensors* sensors, GameActuators* actuators) {<br/><span class="ent">➋</span>     actuators-&gt;strongHeal();<br/>   };</pre>&#13;
<p class="listt"><a id="ch11exe1"/><em>Listing 11-1: Code for a strong healing state</em></p>&#13;
<p class="indent">This code first creates an iterator called <code>curDef</code> that points to the first <code>StateDefinition</code> object in the <code>stateMachine</code> vector. The object’s <code>condition()</code> function is then defined <span class="ent">➊</span>; in English, this definition says, “The state is met if the player’s health percent is greater than 50.” If the state isn’t met, then the object’s <code>reach()</code> function calls the <code>strongHeal()</code> actor function <span class="ent">➋</span> so that strong healing can be performed.</p>&#13;
<p class="indent">With the strong healing state defined, next you define the weak healing state, as shown in <a href="ch11.xhtml#ch11exe2">Listing 11-2</a>.</p>&#13;
<pre>   curDef++;<br/>   curDef-&gt;condition = [](GameSensors* sensors) {<br/><span class="ent">➊</span>     return sensors-&gt;getHealthPercent() &gt; 70;<br/>   };<br/>   curDef-&gt;reach = [](GameSensors* sensors, GameActuators* actuators) {<br/><span class="ent">➋</span>     actuators-&gt;weakHeal();<br/>   };</pre>&#13;
<p class="listt"><a id="ch11exe2"/><em>Listing 11-2: Code for weak healing</em></p>&#13;
<p class="indent">After incrementing <code>curDef</code> so it points to the second <code>StateDefinition</code> object in the <code>stateMachine</code> vector, this code defines the object’s <code>condition()</code> <span epub:type="pagebreak" id="page_227"/>function <span class="ent">➊</span> as, “The state is met if the player’s health percent is greater than 70.” It also defines the object’s <code>reach()</code> function as an <code>actuators-&gt;weakHeal()</code> call <span class="ent">➋</span>.</p>&#13;
<p class="indent">Once you’ve finished defining the state machine, you must implement the controller. Since the actual behavior of the controller is contained in the state machine, you only need to add a simple loop to complete it:</p>&#13;
<pre>for (auto state = stateMachine.begin(); state != stateMachine.end(); state++) {<br/>    if (<span class="ent">➊</span>!state-&gt;condition(&amp;sensors)) {<br/>        state-&gt;reach(&amp;sensors, &amp;actuators);<br/>        break;<br/>    }<br/>}</pre>&#13;
<p class="indent">This controller loop iterates over the state machine, executes the <code>reach()</code> function of the first state whose <code>condition()</code> function returns <code>false</code> <span class="ent">➊</span>, and breaks out if any <code>reach()</code> function is called. The final step is to implement the feedback loop and plop the controller loop inside it, as shown in <a href="ch11.xhtml#ch11exe3">Listing 11-3</a>.</p>&#13;
<pre>while (true) {<br/>    for (auto state = stateMachine.begin();<br/>         state != stateMachine.end();<br/>         state++) {<br/>        if (!state-&gt;condition(&amp;sensors)) {<br/>            state-&gt;reach(&amp;sensors, &amp;actuators);<br/>            break;<br/>    }<br/>    Sleep(FEEDBACK_LOOP_TIMEOUT);<br/>}</pre>&#13;
<p class="listt"><a id="ch11exe3"/><em>Listing 11-3: Final healing state machine and feedback loop</em></p>&#13;
<p class="indent">This loop continuously executes the controller loop and sleeps for <code>FEEDBACK_LOOP_TIMEOUT</code> milliseconds between each execution. The <code>Sleep()</code> call allows the game server to receive and process any actuation from the previous iteration and allows the game client to receive any results of the actuation from the server before executing the next controller loop.</p>&#13;
<p class="indent">If you’re still a bit confused about what I just showed you, check out <a href="ch11.xhtml#ch11fig3">Figure 11-3</a>, which shows how the infinitely looping code in <a href="ch11.xhtml#ch11exe3">Listing 11-3</a> works. First, it checks whether the strong healing condition is <code>true</code>, and if it is, the weak healing condition is checked. If the strong healing condition is <code>false</code>, then the player’s health must be at or below 50 percent, so a strong healing method gets called. If the weak healing condition check is <code>false</code>, then the player’s health must be between 51 and 70 percent, so the weak healing method is executed.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_228"/><img src="../images/f11-03.jpg" alt="image"/></div>&#13;
<p class="figcap"><a id="ch11fig3"/><em>Figure 11-3: Flowchart of the healing state machine and feedback loop</em></p>&#13;
<p class="indent">After either method, the machine sleeps. If both condition checks are <code>true</code>, then the player needs no healing. The machine does nothing to change the state and sleeps before starting again at the top of the <code>while</code> loop.</p>&#13;
<h4 class="h4" id="ch00lev1sec225"><strong><em>A Complex Hypothetical State Machine</em></strong></h4>&#13;
<p class="noindentb">The behavior implemented in the healing state machine is simple, so rolling it into this kind of control structure may seem like overkill, but it’s useful if you want to expand the controller. If, for example, you wanted to combine the healing state machine with the “walk, attack, loot” behavior that I discussed in “<a href="ch11.xhtml#ch00lev1sec221">Control Theory and Game Hacking</a>” on <a href="ch11.xhtml#page_222">page 222</a>, the control structure would be much more complex. Let’s take a high-level look at the states you’d need:</p>&#13;
<p class="noindenth"><strong>Strong healing</strong> Condition met if health is over 50 percent. Reach by casting strong healing spell.</p>&#13;
<p class="noindenth"><strong>Weak healing</strong> Condition met if health is over 70 percent. Reach by casting weak healing spell.</p>&#13;
<p class="noindenth"><strong>Attack spell</strong> Condition met if no target is available or if attack spell is on cooldown. Reach by casting attack spell on target.</p>&#13;
<p class="noindenth"><span epub:type="pagebreak" id="page_229"/><strong>Kite monster</strong> Condition met if no target is available or if distance from target is adequate. (The definition of “adequate” depends on how far away you want to be from enemies when kiting.) Reach by taking a step away from target.</p>&#13;
<p class="noindenth"><strong>Target monster</strong> Condition met if there’s no creature to attack. Reach by attacking a creature.</p>&#13;
<p class="noindenth"><strong>Loot item</strong> Condition met if there’s no corpse open or if open corpse has nothing to loot. Reach by taking an item from open corpse.</p>&#13;
<p class="noindenth"><strong>Approach corpse</strong> Condition met if there are no corpses to open or if adjacent to a corpse. Reach by taking a step toward a corpse that will be opened.</p>&#13;
<p class="noindenth"><strong>Open corpse</strong> Condition met if the character is not adjacent to a corpse that can be opened. Reach by opening adjacent corpse.</p>&#13;
<p class="noindenth"><strong>Follow path</strong> Condition met if the character is unable to move to current waypoint or if standing on current waypoint. Reach by taking a step toward current waypoint.</p>&#13;
<p class="noindenth"><strong>Advance waypoint</strong> Condition met if there are no waypoints left to follow. Reach by updating the current waypoint to the next waypoint in the list. If the character can’t reach the current waypoint for some reason (say, if the character is stuck), then the Advance Waypoint state keeps it from being stuck. If the character has reached the current waypoint, Advance Waypoint selects the next waypoint to keep things moving along.</p>&#13;
<p class="indentt">This state machine is quite a bit more complex than the healing-only state machine. If I diagrammed this state machine, there would be 23 objects in the diagram, with arrows going over 33 control paths. Compare that to <a href="ch11.xhtml#ch11fig3">Figure 11-3</a>, which has only 7 objects and 9 control paths.</p>&#13;
<p class="indent">You could code the healer behavior without using a state machine or feedback loop, but I can’t imagine how to easily do the same for this full-fledged bot. Each of these 10 states relies on not only its own condition but also the condition of every state preceding it. Moreover, hardcoding the logic would either require a ton of nested <code>if()</code> statements or a bunch of stacked <code>if()</code>/<code>return()</code> statements—and, either way, it would just behave exactly like the state machine but with no runtime flexibility.</p>&#13;
<p class="indent"><em>Runtime flexibility</em> refers to a state machine’s ability to mutate. Unlike hardcoded condition checks, state definitions in a state machine can be moved, removed, and added dynamically. The state machine method allows you to plug and play different behaviors and features depending on user input.</p>&#13;
<p class="indent">To take this concept a step further, you could expose your sensors and actuators to a Lua environment, create Lua functions capable of adding and removing states from the state machine, and modify the <code>StateDefinition</code> so that its <code>condition()</code> and <code>reach()</code> functions can call Lua functions exposed by the Lua environment. Writing a control system this way would allow you <span epub:type="pagebreak" id="page_230"/>to code the core of your bot (hooks, memory reading, actuation) in C++ while making Lua (a high-level, dynamic language) available to you for automation.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>You can embed Lua in your own programs by including a few headers and linking against the Lua library. This process is not difficult, but it’s outside the scope of this book, so I encourage you to check out Chapter 24 of</em> Programming in Lua <em>by Roberto Ierusalimschy</em> (<a href="http://www.lua.org/pil/24.html">http://www.lua.org/pil/24.html</a>) <em>for more information.</em></p>&#13;
</div>&#13;
<h4 class="h4" id="ch00lev1sec226"><strong><em>Error Correction</em></strong></h4>&#13;
<p class="noindent">Another piece of control theory that’s useful for game hacking is <em>error correction</em>. An error correction mechanism in a controller observes the outcome of actuation, compares the outcome to an expected result, and adjusts future calculations to bring later outcomes closer to the expected one. Error correction can come in handy when you’re working with <em>stochastic systems</em>, where the output generated from a given input is not fully predictable.</p>&#13;
<p class="indent">Games as a whole are stochastic, but, luckily for game hackers, the results of actions are mostly deterministic. Take the healing controller, for example. In most games, you can calculate exactly how much health you can heal with a given spell, and, thus, you know exactly when to heal. But imagine you’re writing a healer for the small spectrum of situations where your healing is impossible to calculate; for instance, maybe the bot is supposed to work on a variety of characters spanning many levels without user input.</p>&#13;
<p class="indent">Error correction could enable your bot to learn how to best heal the players. In this scenario, there are two ways you can implement error correction, each of which depends on how the healing system works.</p>&#13;
<h5 class="h5" id="ch00lev1sec227"><strong>Adjusting for a Constant Ratio</strong></h5>&#13;
<p class="noindent">If you heal for a constant ratio of health, you’ll only need to adjust your controller after the first heal. Assuming that your sensors can detect how much you’ve healed, this adds only a few lines of code. You could easily modify the weak healing state in <a href="ch11.xhtml#ch11exe2">Listing 11-2</a> to something like this:</p>&#13;
<pre>curDef-&gt;condition = [](GameSensors* sensors) -&gt; bool {<br/>    static float healAt = 70;<br/>    static bool hasLearned = false;<br/>    if (!hasLearned &amp;&amp; sensors-&gt;detectedWeakHeal()) {<br/>        hasLearned = true;<br/>        healAt = 100 - sensors-&gt;getWeakHealIncrease();<br/>    }<br/>    return sensors-&gt;getHealthPercent() &gt; healAt;<br/>};</pre>&#13;
<p class="indent">Instead of hardcoding <code>70</code> as the threshold for weak healing, this code moves the threshold to a static variable called <code>healAt</code>. It also adds another static variable called <code>hasLearned</code> so that the code knows when learning is complete.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_231"/>On each invocation of this <code>condition()</code> function, the code checks two conditions: whether <code>hasLearned</code> is <code>false</code> and whether the sensors detected a weak healing event. When this check passes, the code sets <code>hasLearned</code> to <code>true</code> and updates <code>healAt</code> to heal at or below the perfect percentage; that is, if your weak healing mustered up a 20 percent increase in health, <code>healAt</code> would be set to 80 percent health instead of 70 percent, so each heal would bring the player back up to 100 percent health.</p>&#13;
<h5 class="h5" id="ch00lev1sec228"><strong>Implementing Adaptable Error Correction</strong></h5>&#13;
<p class="noindent">But what if your healing power increases? If a character can gain levels, apply skill points, or increase maximum health, the amount of health it can heal may change accordingly. For example, if you start a bot on a level-10 character and let it run until the character is level 40, your healing code will need to adapt. A level-40 character healing like it did at level 10 would either immensely overheal or die quickly against on-level game enemies.</p>&#13;
<p class="indent">To handle this scenario, a bot needs to constantly update its healing threshold to reflect the observed healing amount. <a href="ch11.xhtml#ch11exe4">Listing 11-4</a> shows how you can modify the strong healing condition function in <a href="ch11.xhtml#ch11exe1">Listing 11-1</a> to do this.</p>&#13;
<pre>   curDef-&gt;condition = [](GameSensors* sensors) -&gt; bool {<br/>       static float healAt = 50;<br/><span class="ent">➊</span>     if (sensors-&gt;detectedStrongHeal()) {<br/>          auto newHealAt = 100 - sensors-&gt;getStrongHealIncrease();<br/><span class="ent">➋</span>         healAt = (healAt + newHealAt) / 2.00f;<br/><span class="ent">➌</span>         sensors-&gt;clearStrongHealInfo();<br/>       }<br/>       return sensors-&gt;getHealthPercent() &gt; healAt;<br/>   };</pre>&#13;
<p class="listt"><a id="ch11exe4"/><em>Listing 11-4: Tweaking the strong healing condition code</em></p>&#13;
<p class="indent">As in the modified weak healing function, the healing threshold has been moved to a static variable called <code>healAt</code>, but this time, the logic is a bit different. Since learning must happen continually, there’s no variable to track whether the bot has already learned its true healing capacity. Instead, the code just checks whether the sensors have seen a strong healing event since its last invocation <span class="ent">➊</span>. If so, the code replaces <code>healAt</code> with the average of <code>healAt</code> and <code>newHealAt</code> and calls a function to clear the sensors of information related to strong healing <span class="ent">➌</span>.</p>&#13;
<p class="indent">Clearing the sensors is actually very important, because it keeps the code from constantly updating <code>healAt</code> against feedback from the same strong healing cast. Notice, too, that this function doesn’t update <code>healAt</code> to a perfect value but instead slides it toward the observed optimal value. This behavior makes the new function ideal for situations where there is some amount of randomness in how much you can actually heal. If your bot needs to slide toward the new value faster, you might change the line at <span class="ent">➋</span> to something like this:</p>&#13;
<pre>healAt = (healAt + newHealAt * 2) / 3.00f;</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_232"/>This code to update <code>healAt</code> uses an average weighted toward the <code>newHealAt</code> value. There are a few points to consider when using this approach, however. First, what happens when you overheal? In some games, when you heal to full health, your sensors might be able to detect only how much you actually healed. In other games, your sensors may be able to detect the actual amount healed. Put another way, if you cast a 30 percent strong heal from 85 percent health, do your sensors see a heal of 30 percent or 15 percent? If the answer is 30 percent, you’re set. If the answer is 15 percent, your code needs a way to adjust downward.</p>&#13;
<p class="indent">One way to adjust accordingly is to decrement <code>healAt</code> when your sensors see a heal that brings you to full health, like this:</p>&#13;
<pre>   curDef-&gt;condition = [](GameSensors* sensors) -&gt; bool {<br/>       static float healAt = 50;<br/>       if (sensors-&gt;detectedStrongHeal()) {<br/><span class="ent">➊</span>         if (sensors-&gt;getStrongHealMaxed()) {<br/>               healAt--;<br/>           } else {<br/>               auto newHealAt = 100 - sensors-&gt;getStrongHealIncrease();<br/>               healAt = (healAt + newHealAt) / 2.00f;<br/>           }<br/>           sensors-&gt;clearStrongHealInfo();<br/>       }<br/>       return sensors-&gt;getHealthPercent() &gt; healAt;<br/>   };</pre>&#13;
<p class="indent">This code is almost the same as <a href="ch11.xhtml#ch11exe4">Listing 11-4</a>, but it adds an <code>if()</code> clause to decrement <code>healAt</code> if a max heal is detected <span class="ent">➊</span>. Otherwise, the function should behave like <a href="ch11.xhtml#ch11exe4">Listing 11-4</a>.</p>&#13;
<p class="indent">Healing is a simple case, but this code shows a great example of how you can use error correction to dynamically improve your bots’ behavior. One more advanced use case is adjusting skillshots to account for enemy movement patterns. Every player has patterns in how they avoid skillshots, so if your sensors are able to measure the direction and distance an enemy moves when dodging a skillshot, your controller code can adjust the location where the bot initially shoots the skillshot. In this same scenario, learning would also help the bot account for differences in game server latency, character movement speed, and so on.</p>&#13;
<p class="indent">When using error correction, note that your code will be cleaner and more portable if your state definitions have some form of internal bookkeeping other than static variables. Moreover, to avoid cluttering your state definitions, I suggest encapsulating the error correction logic in some external modules that are easily invoked when needed.</p>&#13;
<h3 class="h3" id="ch00lev1sec229"><strong>Pathfinding with Search Algorithms</strong></h3>&#13;
<p class="noindent">One common challenge you’ll face when writing an autonomous bot is calculating a path for a character to follow from one location to another. Aside from the sheer reverse engineering challenge of creating sensors to read <span epub:type="pagebreak" id="page_233"/>which coordinates on the game map are blocking forward movement or not, there’s also the algorithmic challenge of calculating a path within that map. Calculating a path is called <em>pathfinding</em>, and game hackers often use a <em>search algorithm</em> to tackle it.</p>&#13;
<h4 class="h4" id="ch00lev1sec230"><strong><em>Two Common Search Techniques</em></strong></h4>&#13;
<p class="noindent">Given a grid of tiles, a starting location <em>a</em>, and an ending location <em>b</em>, a search algorithm calculates a path from <em>a</em> to <em>b</em>. The algorithm does this by creating a <em>node</em> at <em>a</em>, adding nodes adjacent to <em>a</em> to a list of tiles to be explored (called the <em>frontier</em>), updating the node to the best tile in the frontier, and repeating the process until the node reaches <em>b</em>. Different search algorithms select the best node differently, using either a <em>cost</em>, a <em>heuristic</em>, or both.</p>&#13;
<p class="indent"><em>Dijkstra’s algorithm</em>, for example, calculates the cost of a tile based on its distance from the <em>a</em> node and selects the tile with the lowest cost. Imagine an empty two-dimensional grid with <em>a</em> in the middle. In a search following Dijkstra’s algorithm, the frontier will expand in a circular pattern around <em>a</em> until <em>b</em> lies on the edge of the circle, as seen in <a href="ch11.xhtml#ch11fig4">Figure 11-4</a>.</p>&#13;
<p class="indent">The <em>greedy best-first search</em> algorithm, instead of prioritizing nodes by their distance from the starting point, uses a heuristic to estimate the distance from a node in the frontier to <em>b.</em> The algorithm then selects the node with the shortest estimated distance. Imagine this algorithm in the same grid as before; the frontier would be a line going almost directly from <em>a</em> to <em>b</em>, as seen in <a href="ch11.xhtml#ch11fig5">Figure 11-5</a>.</p>&#13;
<div class="image"><img src="../images/f11-04.jpg" alt="image"/></div>&#13;
<p class="figcap"><a id="ch11fig4"/><em>Figure 11-4: The frontier of Dijkstra’s algorithm. Lighter tiles are higher cost.</em></p>&#13;
<div class="image"><img src="../images/f11-05.jpg" alt="image"/></div>&#13;
<p class="figcap"><a id="ch11fig5"/><em>Figure 11-5: The frontier of the greedy best-first search algorithm. Lighter tiles are higher cost.</em></p>&#13;
<h4 class="h4" id="ch00lev1sec231"><strong><em>How Obstacles Disrupt Searches</em></strong></h4>&#13;
<p class="noindent">The difference in how these algorithms behave becomes clearer once obstacles are added to the grid. If, for instance, a wall separates <em>a</em> and <em>b</em>, Dijkstra’s <span epub:type="pagebreak" id="page_234"/>algorithm will always find the quickest path, but with a huge consequence. The radius of the circular frontier around <em>a</em> will be equal to the length of the final path; let’s call that radius <em>r</em>. If no grid boundaries clip the frontier, you can roughly calculate the number of nodes opened by taking the area of a circle with radius <em>r</em>. If the path around the wall is 50 tiles, the algorithm will open roughly 7,854 tiles, as shown in this equation:</p>&#13;
<p class="center1">π × 50<sup>2</sup> = 7,854</p>&#13;
<p class="indent">In the same scenario, greedy best-first search will calculate a less-than-optimal path but open substantially fewer tiles. It’s not as easy to visualize how the frontier will expand, and it’s not important right now, so I won’t go into it here. At the end of the day, neither of these algorithms really fits the pathfinding problem well. The optimal path is slow, and the fast path isn’t optimal.</p>&#13;
<p class="indent">To quickly calculate an optimal path, you need to fuse Dijkstra’s algorithm with greedy best-first search. Luckily, someone has already done this, and the resulting algorithm is a monster known as <em>A-star search</em> (often just called <em>A*</em>).</p>&#13;
<p class="indent">A* uses the sum of a cost, called <em>g</em>, and a heuristic, called <em>h</em>, to select nodes. These resulting sum is called the <em>score</em>. Put simply, score = <em>g</em> + <em>h</em>. Like Dijkstra’s algorithm, A* can calculate the most optimal path from <em>a</em> to <em>b</em>, and like greedy best-first search, it can do so relatively quickly.</p>&#13;
<h4 class="h4" id="ch00lev1sec232"><strong><em>An A* Search Algorithm</em></strong></h4>&#13;
<p class="noindent">Now that you know the fundamentals, let’s write code to implement the A* algorithm. This implementation will work in a two-dimensional grid. It won’t allow diagonal movement at first, but I’ll discuss in a bit how you can modify the code to work with diagonal movement, too.</p>&#13;
<p class="indent">All of the example code for this section is in the <em>GameHackingExamples/Chapter11_SearchAlgorithms</em> directory of this book’s source files. The included projects can be compiled with Visual Studio 2010, but they should also work with any other C++ compiler. Download them at <em><a href="https://www.nostarch.com/gamehacking/">https://www.nostarch.com/gamehacking/</a></em> and compile them to follow along. If you execute <em>Chapter11_ SearchAlgorithms.exe</em>, you’ll be able to define your own 20×20 grid and watch the algorithm calculate a search path.</p>&#13;
<h5 class="h5" id="ch00lev1sec233"><strong>Creating an A* Node</strong></h5>&#13;
<p class="noindent">To start, define an empty <code>AStarNode</code> class as follows:</p>&#13;
<pre>typedef std::shared_ptr&lt;class AStarNode&gt; AStarNodePtr;<br/>class AStarNode<br/>{<br/>public:<br/>};</pre>&#13;
<p class="indent">This code defines the <code>AStarNode</code> class and a <code>std::shared_ptr</code> type definition called <code>AStarNodePtr</code> to make it easier to create safe pointers to the class. <span epub:type="pagebreak" id="page_235"/>Next, within the public scope of this class, declare member variables for the node’s x-position, y-position, cost, and node’s score:</p>&#13;
<pre>int x, y;<br/>int g, score;</pre>&#13;
<p class="indent">Additionally, you need a public member of type <code>AStarNodePtr</code> that references the parent node:</p>&#13;
<pre>AStarNodePtr parent;</pre>&#13;
<p class="indent">After declaring all member variables, declare a public constructor that initializes them upon instance creation, as follows:</p>&#13;
<pre>AStarNode(int x, int y, int cost, AStarNodePtr p, int score = 0)<br/>    : x(x), y(y), g(cost), score(score), parent(p)<br/>{}</pre>&#13;
<p class="indent">Now, to make creating safe pointers easier, add a static helper function like this:</p>&#13;
<pre>static AStarNodePtr makePtr(<br/>    int x, int y, int cost,<br/>    AStarNodePtr p,<br/>    int score = 0)<br/>{<br/>    return AStarNodePtr(new AStarNode(x, y, cost, p, score));<br/>}</pre>&#13;
<p class="indent">This <code>makePtr()</code> function creates a new instance of <code>AStarNode</code> and returns the instance wrapped inside of an <code>AstarNodePtr</code>.</p>&#13;
<p class="indent">Let’s recap. The <code>AStarNode</code> class has member variables <code>x</code>, <code>y</code>, <code>g</code>, <code>score</code>, and <code>parent</code>. When the class is constructed, all of these members are initialized from values passed to the constructor, with the exception of <code>score</code>, which is optional (because you use it only when making copies of an <code>AStarNode</code> instance) and set to <code>0</code> if not provided.</p>&#13;
<p class="indent">Next, define a public member function to calculate the heuristic when given the destination coordinates:</p>&#13;
<pre>   int heuristic(const int destx, int desty) const<br/>   {<br/>       int xd = destx - x;<br/>       int yd = desty - y;<br/><span class="ent">➊</span>     return abs(xd) + abs(yd);<br/>   }</pre>&#13;
<p class="indent">This function returns the <em>Manhattan distance heuristic</em> <span class="ent">➊</span>, a distance calculation designed for grids where diagonal movement is not possible:</p>&#13;
<p class="center">|Δ<em>x</em>| + |Δ<em>y</em>|</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_236"/>To calculate a path that allows diagonal movement, you’d need to modify this function to use the <em>Euclidean distance heuristic</em>, which looks like this:</p>&#13;
<div class="imagec"><img src="../images/f0236-01.jpg" alt="image"/></div>&#13;
<p class="indent">The class also needs a function to update <code>score</code>. You add that function to the public scope as follows:</p>&#13;
<pre>#define TILE_COST 1<br/>void updateScore(int endx, int endy)<br/>{<br/>    auto h = this-&gt;heuristic(endx, endy) * TILE_COST;<br/>    this-&gt;score = g + h;<br/>}</pre>&#13;
<p class="indent">Now, <code>score</code> should change to <code>g + h</code> when given destination coordinates to calculate <code>h</code>.</p>&#13;
<p class="indent">To wrap up, the node class also needs a function that can calculate all of its child nodes. The function could do this by creating new nodes for each tile adjacent to the current node. Each new node refers to the current node as its parent, so the class needs to be able to create an <code>AStarNodePtr</code> to a copy of the current node as well. Here’s how all that works:</p>&#13;
<pre>   AStarNodePtr getCopy()<br/>   {<br/>       return AStarNode::makePtr(x, y, g, parent, score);<br/>   }<br/>   std::vector&lt;AStarNodePtr&gt; getChildren(int width, int height)<br/>   {<br/>       std::vector&lt;AStarNodePtr&gt; ret;<br/>       auto copy = getCopy();<br/>       if (x &gt; 0)<br/><span class="ent">➊</span>         ret.push_back(AStarNode::makePtr(x - 1, y, g + TILE_COST, copy));<br/>       if (y &gt; 0)<br/><span class="ent">➋</span>         ret.push_back(AStarNode::makePtr(x, y - 1, g + TILE_COST, copy));<br/>       if (x &lt; width - 1)<br/><span class="ent">➌</span>         ret.push_back(AStarNode::makePtr(x + 1, y, g + TILE_COST, copy));<br/>       if (y &lt; height - 1)<br/><span class="ent">➍</span>         ret.push_back(AStarNode::makePtr(x, y + 1, g + TILE_COST, copy));<br/>       return ret;<br/>   }</pre>&#13;
<p class="indent">This function creates child nodes at (x – 1, y) <span class="ent">➊</span>, (x, y – 1) <span class="ent">➋</span>, (x + 1, y) <span class="ent">➌</span>, and (x, y + 1) <span class="ent">➍</span>. Their <code>parent</code> is the node that called <code>getChildren</code>, and their <code>g</code> is the parent’s <code>g</code> plus <code>TILE_COST</code>.</p>&#13;
<p class="indent">To allow for diagonal movement, this function needs to add children at (x – 1, y – 1), (x + 1, y – 1), (x + 1, y + 1), and (x – 1, y + 1). Additionally, if <span epub:type="pagebreak" id="page_237"/>moving diagonally would cost more—that is, if the character requires more time to do it—you’d also need to do the following:</p>&#13;
<ol>&#13;
<li><p class="noindenta">Change <code>TILE_COST</code> to <code>10</code>.</p></li>&#13;
<li><p class="noindenta">Define a constant <code>DIAG_TILE_COST</code> as <code>TILE_COST</code> multiplied by the time increase. If a diagonal step takes 1.5 times as long, <code>DIAG_TILE_COST</code> would be <code>15</code>.</p></li>&#13;
<li><p class="noindenta">Give diagonal children a <code>g</code> of the parent’s <code>g</code> plus <code>DIAG_TILE_COST</code>.</p></li>&#13;
</ol>&#13;
<p class="indent">To finish off <code>AStarNode</code>, declare operators for comparing the priority and equality of two nodes. You could place these declarations outside the class in global scope like this:</p>&#13;
<pre><span class="ent">➊</span> bool operator&lt;(const AStarNodePtr &amp;a, const AStarNodePtr &amp;b)<br/>   {<br/>       return a.score &gt; b.score;<br/>   }<br/><span class="ent">➋</span> bool operator==(const AStarNodePtr &amp;a, const AStarNodePtr &amp;b)<br/>   {<br/>       return a.x == b.x &amp;&amp; a.y == b.y;<br/>   }</pre>&#13;
<p class="indent">These operators allow <code>std::priority_queue</code> to sort nodes by <code>score</code> <span class="ent">➊</span> and <code>std::find</code> to determine node equality by location <span class="ent">➋</span>.</p>&#13;
<h5 class="h5" id="ch00lev1sec234"><strong>Writing the A* Search Function</strong></h5>&#13;
<p class="noindent">Now that you’ve completed the <code>AStarNode</code> class, you can code the actual search function. Start by defining the function prototype:</p>&#13;
<pre>template&lt;int WIDTH, int HEIGHT, int BLOCKING&gt;<br/>bool doAStarSearch(<br/>    int map[WIDTH][HEIGHT],<br/>    int startx, int starty,<br/>    int endx, int endy,<br/>    int path[WIDTH][HEIGHT])<br/>{ }</pre>&#13;
<p class="indent">The prototype accepts the game map’s width and height, as well as the value that signifies a blocking tile on the map, as template parameters. The <code>doAStarSearch()</code> function also takes the map itself (<code>map</code>), the starting coordinates (<code>startx</code> and <code>starty</code>), the destination coordinates (<code>endx</code> and <code>endy</code>), and a blank map (<code>path</code>) where it can fill the calculated path when it finishes.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>The first three parameters are template parameters, so you can pass them as compiletime constants. I’ve done this for the example code to allow explicit array size declarations for the</em> <code><span class="codeitalic">map</code></span> <em>and</em> <code><span class="codeitalic">path</code></span> <em>parameters and to allow a definite value to signify blocking tiles on the map. In practice, the map you read from a game will have a dynamic size, and you’ll probably need a more robust way to pass this data.</em></p>&#13;
</div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_238"/>Next, the <code>doAStarSearch()</code> function needs a sorted list to hold the frontier and a container to track all created notes so you can update the score and parent of an existing node if it’s opened as a child of a different parent. You can create these as follows:</p>&#13;
<pre>std::vector&lt;AStarNodePtr&gt; allNodes;<br/>std::priority_queue&lt;AStarNodePtr&gt; frontier;</pre>&#13;
<p class="indent">The <code>frontier</code> is defined with <code>std::priority_queue</code> since it can automatically sort the nodes based on their score. The node container, <code>allNodes</code>, is defined as a <code>std::vector</code>.</p>&#13;
<p class="indent">Now, let’s create the first node:</p>&#13;
<pre>auto node = AStarNode::makePtr(startx, starty, 0, nullptr);<br/>node-&gt;updateScore(endx, endy);<br/>allNodes.push_back(node);</pre>&#13;
<p class="indent">The first node is a no-cost orphan node at the position (<code>startx</code>, <code>starty</code>). The node is given a score based on what the <code>updateScore()</code> function returns, and then it’s added to the <code>allNodes</code> container.</p>&#13;
<p class="indent">With a node in the container, it’s time to write the meat of the A* algorithm, starting with a simple loop:</p>&#13;
<pre>while (true) {<br/>}</pre>&#13;
<p class="indent">Until otherwise specified, the rest of the code in this section will appear inside of this loop, in the order shown.</p>&#13;
<p class="indent">From here, the first step is to check the <em>goal state</em>. In this case, the goal is to find a path for the player to follow to the next waypoint, which happens when the <code>node</code> object’s position is (<code>endx</code>, <code>endy</code>). Thus, to check the goal state, the program needs to check whether <code>node</code> has reached those coordinates or not. Here’s how that check should look:</p>&#13;
<pre>if (node-&gt;x == endx &amp;&amp; node-&gt;y == endy) {<br/>    makeList&lt;WIDTH, HEIGHT&gt;(node, allNodes, path);<br/>    return true;<br/>}</pre>&#13;
<p class="indent">When the goal state is met, the program reports <code>true</code> back to the caller and fills <code>path</code> with the final path. For now, assume a function called <code>makeList()</code> can fill in <code>path</code> for you; I’ll show you this function shortly. If the goal state isn’t met, you need to expand the children of <code>node</code>, which is actually a pretty complicated process:</p>&#13;
<pre>   auto children = node-&gt;getChildren(WIDTH, HEIGHT);<br/>   for (auto c = children.begin(); c != children.end(); c++) {<br/><span class="ent">➊</span>     if (map[(*c)-&gt;x][(*c)-&gt;y] == BLOCKING) continue;<br/>       auto found = std::find(allNodes.rbegin(), allNodes.rend(), *c);<br/><span class="ent">➋</span>     if (found != allNodes.rend()) {<br/><span class="ent">➌</span>         if (*found &gt; *c) {<br/>               (*found)-&gt;g = (*c)-&gt;g;<br/>               (*found)-&gt;parent = (*c)-&gt;parent;<br/>               (*found)-&gt;updateScore(endx, endy);<br/>           }<br/>       } else {<br/>           (*c)-&gt;updateScore(endx, endy);<br/><span class="ent">➍</span>         frontier.push(*c);<br/><span class="ent">➎</span>         allNodes.push_back(*c);<br/>       }<br/>   }</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_239"/>After calling <code>node-&gt;getChildren</code> to generate a list of nodes that can be added to the frontier, the code iterates over each child and ignores any that are on blocking tiles <span class="ent">➊</span>. Next, for each child, the code checks whether a node has already been opened at the same coordinates <span class="ent">➋</span>. If so, and if the <code>score</code> of the existing node is greater than the <code>score</code> of the new child, the existing node is updated to the <code>parent</code>, <code>cost</code>, and <code>score</code> of the new child by the <code>if()</code> statement at <span class="ent">➌</span>. If the new child doesn’t have a brother-from-another-mother, it will be added as is to the frontier <span class="ent">➍</span> and the node list <span class="ent">➎</span>.</p>&#13;
<p class="indent">Also notice that <code>std::find</code> uses the reverse begin and reverse end iterators of <code>allNodes</code> instead of the regular iterators <span class="ent">➊</span>. The example does this because new nodes are appended to the end of the vector and duplicate nodes will be close together, so duplicates will usually be closer to the end of the vector. (This step could also be done directly against the frontier, but <code>std::priority_queue</code> doesn’t allow iteration over nodes and writing the sort in place would make the code too large for print.)</p>&#13;
<p class="indent">Eventually, the function will run out of new children to add to the frontier; the following <code>if()</code> statement handles that situation:</p>&#13;
<pre>   if (frontier.size() == 0) return false;<br/><span class="ent">➊</span> node = frontier.top();<br/><span class="ent">➋</span> frontier.pop();</pre>&#13;
<p class="indent">This code points <code>node</code> to the cheapest node from the frontier <span class="ent">➊</span>, removes it from the frontier <span class="ent">➋</span>, and lets the loop repeat. If the frontier ends up empty, the function reports <code>false</code> back to the caller, since there’s nothing left to search.</p>&#13;
<h5 class="h5" id="ch00lev1sec235"><strong>Creating the Path List</strong></h5>&#13;
<p class="noindent">Finally, it’s time to implement the <code>makeList()</code> function:</p>&#13;
<pre>   template&lt;int WIDTH, int HEIGHT&gt;<br/>   void makeList(<br/>       AStarNodePtr end,<br/>       std::vector&lt;AStarNodePtr&gt; nodes,<br/>       int path[WIDTH][HEIGHT])<br/>   {<br/>       for (auto n = nodes.begin(); n != nodes.end(); n++)<br/><span class="ent">➊</span>         path[(*n)-&gt;x][(*n)-&gt;y] = 2;<br/>       auto node = end;<br/>       while (node.get() != nullptr) {<br/><span class="ent">➋</span>         path[node-&gt;x][node-&gt;y] = 1;<br/>           node = node-&gt;parent;<br/>       }<br/>   }</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_240"/>This function updates <code>path</code> with both a list of closed nodes <span class="ent">➊</span> and the calculated path <span class="ent">➋</span>. For this example, the value <code>2</code> represents the closed nodes and <code>1</code> represents the path nodes. The program calculates nodes in the path by following parent nodes from the goal node until it reaches the starting node, which is an orphan with <code>nullptr</code> as a parent.</p>&#13;
<h4 class="h4" id="ch00lev1sec236"><strong><em>When A* Searches Are Particularly Useful</em></strong></h4>&#13;
<p class="noindent">Make sure to play with the example code and executable for the previous section, because that’s the only way you’ll really get acquainted with the behavior of A* searches. In most newer games, you should be able to just send a packet with the destination or even emulate a click on the map at the desired spot, but when you come across a situation where you need to calculate a path, you’ll be glad you learned A*.</p>&#13;
<p class="indentb">There are actually many situations where calculating a path can be useful:</p>&#13;
<p class="term"><strong>Selecting targets</strong></p>&#13;
<p class="termp">When your bot is selecting targets to attack, you may want to check whether your character can actually reach them. Otherwise, if an enemy is isolated in an unreachable room, you might get stuck in place trying to target them forever!</p>&#13;
<p class="term"><strong>Selecting corpses</strong></p>&#13;
<p class="termp">As your looting state(s) determine which corpses to open, you can optimize by always trying to loot the closest corpse first.</p>&#13;
<p class="term"><strong>Emulating mouse movements</strong></p>&#13;
<p class="termp">Very rarely, some heavily protected games actually correlate in-game actions with mouse movements to ensure that there’s no bot running. In this case, you might need to emulate the mouse. Using a modified version of A* where the screen is the map, there are no blocking tiles, and node costs are slightly randomized, you can calculate human-like paths for your mouse to follow when you simulate movement.</p>&#13;
<p class="term"><strong>Kiting monsters</strong></p>&#13;
<p class="termp">If you ever need to write code to kite monsters, you can implement A* with a goal state of being <em>N</em> units away from all creatures. Using the same cost mechanism shown in this chapter, play with the heuristic <span epub:type="pagebreak" id="page_241"/>to give a higher cost to nodes that are closer to creatures. Kiting isn’t exactly a conventional use case, and the heuristic will require a bunch of tweaking, but it works amazingly once you’ve got it going. Some implementations can kite any number of monsters better than a human!</p>&#13;
<p class="term"><strong>Predicting enemy movements</strong></p>&#13;
<p class="termp">If you’re writing a bot that fights other players, you can use A* to predict their movements and act accordingly. For instance, if your enemy starts running away, your bot can assume they are running to their base, calculate their route, and use a spell to block their path or even teleport to a location where it expects them to be.</p>&#13;
<p class="indentt">These are just a few use cases for A* searches, and you’ll definitely find many more as you improve your bots. For the rest of the chapter, I’ll describe some popular automated hacks that you can implement using the techniques described in this book.</p>&#13;
<div class="sidebar">&#13;
<p class="sidebart"><strong>OTHER USES FOR A* SEARCH</strong></p>&#13;
<p class="noindent">A* isn’t just for calculating paths. With abstractions on top of the <code>AStarNode</code> class, you can adapt the same algorithm to any search problem. Realistically, A* is just a weighted iteration over a multidimensional data set that iterates until some goal object is found, and, thus, it can solve any problem that can be represented as a multidimensional data set. More advanced applications for A* include playing chess and checkers, and—when it’s paired with a three-dimensional Manhattan distance heuristic and a depth-first search implementation—even solving a Rubik’s cube. Sadly, I’m not going to go into these use cases; if you want to get really good with search algorithms, I encourage you to research more online.</p>&#13;
</div>&#13;
<h3 class="h3" id="ch00lev1sec237"><strong>Common and Cool Automated Hacks</strong></h3>&#13;
<p class="noindent">Now that you’ve seen the design patterns and algorithms needed to create efficient, self-teaching bots, it’s time to learn about some popular automated hacks that go beyond simple healing and pathfinding. Let’s fly up to 10,000 feet to explore two types of bots at a high level.</p>&#13;
<h4 class="h4" id="ch00lev1sec238"><strong><em>Looting with Cavebots</em></strong></h4>&#13;
<p class="noindent">While discussing control theory, state machines, and search algorithms, I touched on the idea of a cavebot that kills creatures, grabs loot, and walks around caves. The abilities of cavebots can vary greatly.</p>&#13;
<h5 class="h5" id="ch00lev1sec239"><span epub:type="pagebreak" id="page_242"/><strong>Depositing Gold and Restocking Supplies</strong></h5>&#13;
<p class="noindentb">If you want to leave a character botting for days on end, you’ll need a <em>depositor</em> and a <em>refiller</em>. A depositor can deposit loot in your bank or vault, while a refiller refills your potions, runes, and other supplies. These features can be described with six basic states:</p>&#13;
<p class="noindenth"><strong>Leave spawn</strong> Condition met if the character is in the spawn area or cave, if it has nothing to deposit, and if it has enough supplies. Reach this state by exiting the spawn area or cave.</p>&#13;
<p class="noindenth"><strong>Walk to town</strong> Condition met if the character is in the spawn area or cave. Reach this state by walking from the spawn or cave to town.</p>&#13;
<p class="noindenth"><strong>Deposit</strong> Condition met if the character is in the spawn area or cave, or if the character is in town and has nothing to deposit. Reach this state by putting loot in the bank or vault.</p>&#13;
<p class="noindenth"><strong>Withdraw cash</strong> Condition met if the character is in the spawn area or cave, is in town with no supplies to purchase, or has enough gold to purchase supplies. Reach this state by withdrawing gold from the bank or vault.</p>&#13;
<p class="noindenth"><strong>Purchase supplies</strong> Condition met if the character is in the spawn area or cave or if the character has enough supplies to start hunting. Reach by buying supplies.</p>&#13;
<p class="noindenth"><strong>Enter spawn</strong> Condition met if the character is in the spawn area or cave. Reach this state by walking to the spawn area or cave.</p>&#13;
<p class="indentt">These states would come before the states related to following waypoints (I describe a couple of those states in “<a href="ch11.xhtml#ch00lev1sec225">A Complex Hypothetical State Machine</a>” on <a href="ch11.xhtml#page_228">page 228</a>) in the vector of <code>StateDefinition</code> objects. Placing them first gives them priority over remaining in the cave, while still allowing the character to target, kill, and loot monsters on the way back to town. Depending on where you’re hunting and how you want the bot to behave, you may also tell your targeting states not to attack creatures if the character isn’t in the spawn area or cave, and you might add an extra state before walk to town that attacks only creatures that block the character’s path to town. Specifying that extra state increases the bot’s efficiency, since trips to and from town will be much quicker if the monsters on the way aren’t worth killing.</p>&#13;
<h5 class="h5" id="ch00lev1sec240"><strong>Using the Character as Bait</strong></h5>&#13;
<p class="noindent">Two other cavebot features that can make your bot awesome are <em>lure mode</em> and <em>dynamic lure</em>. You wouldn’t implement these two features as actual states in a complex bot; rather, you’d have them inform the bot’s targeting and walking states to help the bot make decisions.</p>&#13;
<p class="indent">You can control lure mode with special waypoints in your path, and its code will tell your targeting states to attack creatures only if the bot is stuck, similar to the mechanism discussed for walking to or from town. The difference is that lure mode can be switched on and off at different areas in the <span epub:type="pagebreak" id="page_243"/>cave, allowing you to lure multiple mobs of monsters to certain locations before attacking them. This can make your bot much more efficient, as certain types of characters may excel at killing many monsters at once.</p>&#13;
<p class="indent">Dynamic lure is similar, but instead of turning it on and off at definite locations via waypoints, you can automatically turn lure mode on when there aren’t enough monsters. For example, a bot with the dynamic lure feature might tell the targeting states not to attack any creature until five monsters are on screen. The targeting states would resume attacking and kiting until all five monsters are dead, and the bot would snap back into lure mode until a suitably sized mob appears again.</p>&#13;
<p class="indent">If your character is quick enough to outrun monsters, though, you’ll need to modify your bot’s walking states to walk slowly when lure mode is on and creatures are present. Otherwise, your character will leave mobs behind without killing them. You can slow down a character by adding a state before the follow path state in your state machine definition that delays movement slightly when lure mode is on and any creatures are too far away.</p>&#13;
<h5 class="h5" id="ch00lev1sec241"><strong>Allowing Players to Script Custom Behaviors</strong></h5>&#13;
<p class="noindent">Nearly every cavebot includes a scripting interface that allows players to add their own behaviors. You could implement this interface as a way to specify custom waypoints to follow, spells to use, or items to loot. In more advanced bots, you might make your targeting, looting, walking, and luring systems as dynamic as possible so players can add unique features. If you implement your automation in Lua, third parties could easily improve and expand your bot’s abilities.</p>&#13;
<p class="indent">Making your bot easy to write scripts for takes a lot of work off your shoulders, since other programmers who play the game might release scripts to add support for new hunting spots and improve your automation. Such scripting services are common in botting communities, and players often create and sell professional-grade scripts that integrate with bots.</p>&#13;
<h4 class="h4" id="ch00lev1sec242"><strong><em>Automating Combat with Warbots</em></strong></h4>&#13;
<p class="noindent">Another class of automated bots is used for <em>player versus player (PvP)</em> combat. These warbots, or <em>PvP bots</em>, have many features categorized as responsive or ESP hacks, since the bots focus on responding to incoming damage or spells, revealing hidden enemies, and giving the player an information advantage.</p>&#13;
<p class="indent">Fully automated warbots are rare, but I’ve already lightly discussed how you can use some automation techniques to make smarter healers, teach bots to land more accurate skillshots, and predict players’ paths to stop them in their tracks. Let’s explore a few other cool hacks that fall on the fringe of responsive, ESP, and automated.</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep"><em>In games that are completely PvP based, such as battlegrounds or real-time strategy games, some players might also just call these</em> bots<em>, since war or PvP is the bot’s only purpose.</em></p>&#13;
</div>&#13;
<p class="term"><span epub:type="pagebreak" id="page_244"/><strong>Autowall Bots</strong></p>&#13;
<p class="termp">If your character has a spell to create a temporary wall, you can code a bot that automatically blocks enemy players when they enter small corridors. Using error correction, the bot could learn how far ahead of the enemy to place the wall. With some really creative engineering, the bot could even learn which enemies can jump over walls by checking whether each enemy manages to get past the wall before it disappears.</p>&#13;
<p class="term"><strong>Autosnipe Bots</strong></p>&#13;
<p class="termp">For characters with a long-range skillshot or global execution spell, you can use automation to detect when an enemy across the map has low health and cast your spell to kill them. You can also use error correction to more accurately guess where to shoot a long-range skillshot. If you’re unable to calculate exact damage amounts, error correction can also help a bot determine how much damage a spell does and tweak the casting threshold accordingly.</p>&#13;
<p class="term"><strong>Autokite Bots</strong></p>&#13;
<p class="termp">If you’re playing a carry character that does most of its damage by attacking at a short distance, you might implement a bot to automatically kite enemies. Using a set of states similar to the ones a cavebot might use to kite monsters, you can make a bot that automatically kites enemy characters when you attack them. When you stop targeting the enemy, the bot can stop kiting. Using A* search, you can improve the kiting mechanism to avoid multiple enemies, or, if you want to escape while attacking, guide the kiting mechanism back to a safe place, such as your team’s base or a neutral location.</p>&#13;
<h3 class="h3" id="ch00lev1sec243"><strong>Closing Thoughts</strong></h3>&#13;
<p class="noindent">By this point, you should be ready to go out and make some pretty awesome bots. Don’t worry if you’re still not completely comfortable with the techniques in this chapter; the best way to learn is to just dive in and start hacking. Use the thousands of lines of example code provided for this book to get started without working from scratch, and most of all, have fun!</p>&#13;
<p class="indent">In the next chapter, I’ll discuss ways that bots can hide from anti-cheat mechanisms, which are pieces of software that games use to detect and stop botters.</p>&#13;
</body></html>