- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying Code
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: You have been methodically building up your infrastructure to get to this point,
    and you have put in place all the foundational pieces you need to run your application.
    You have built and deployed in the Kubernetes cluster the container image for
    the telnet-server application. If you want to release a new version of your application,
    all you need to do is rebuild the container image and then redeploy the Kubernetes
    manifests.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are some glaring flaws within your setup. For one, you are not
    running any tests to verify that the code or container image is defect-free. Also,
    the way you have set it up, every time any code or configuration changes, you’ll
    need to build the container image and release the Deployment manually. This manual
    process is fine for kicking the tires on new technologies, but hopefully you have
    learned (and agree) that these steps can and should be automated. Successful software
    engineering teams often release small code changes using automation, allowing
    them to find errors quickly and reduce complexities in their infrastructure. As
    mentioned in an earlier chapter, this process of getting code from your editor
    to your stakeholders in a consistent and automated manner is usually referred
    to as *continuous integration and continuous deployment (CI/CD).*
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you’re going to build a simple CI/CD pipeline for the telnet-server
    application using freely available tools. This pipeline will watch the telnet-server
    source code changes, and if there are any, it will kick off a series of steps
    to get the changes deployed to the Kubernetes cluster. By the end of this chapter,
    you’ll have a local development pipeline that builds, tests, and deploys your
    code to the Kubernetes cluster using automation.
  prefs: []
  type: TYPE_NORMAL
- en: CI/CD in Modern Application Stacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Continuous integration and continuous deployment are software development methodologies
    that describe the way code is built, tested, and delivered. The CI steps cover
    the testing and building of code and configuration changes, while the CD steps
    automate the deployment (or delivery) of new code.
  prefs: []
  type: TYPE_NORMAL
- en: During the CI stage, a software engineer introduces new features or bug fixes
    through a version control system like Git. This code gets run through a series
    of builds and tests before finally producing an artifact like a container image.
    This process solves the “works on my machine” problem because everything is tested
    and built in the same way to produce a consistent product. The testing steps usually
    consist of unit tests, integration tests, and security scans. The unit and integration
    tests make sure the application behaves in an expected manner, whether in isolation
    or interacting with other components in your stack. The security scans usually
    check for known vulnerabilities in your applications software dependencies or
    for vulnerable base container images you are importing. After the testing steps,
    the new artifact is built and pushed to a shared repository, where the CD stage
    has access to it.
  prefs: []
  type: TYPE_NORMAL
- en: During the CD stage, an artifact is taken from a repository and then deployed,
    usually to production infrastructure. CDs can use different strategies to release
    code. These strategies are usually either *canary*, *rolling* (in our case), or
    *blue-green*. See [Table 8-1](#table8-1) for more information on each strategy.
  prefs: []
  type: TYPE_NORMAL
- en: The idea behind deployment strategies is to minimize problematic code before
    it can have an impact on many users. The infrastructure you’ll be deploying to
    most likely will be a container orchestrator like our Kubernetes cluster, but
    it could just as easily be VMs in a cloud provider.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8-1: Deployment Strategies'
  prefs: []
  type: TYPE_NORMAL
- en: '| Canary | This strategy rolls out new code so only a small subset of users
    can access it. If the canary’s code presents zero errors, the new code can be
    rolled out further to more customers. |'
  prefs: []
  type: TYPE_TB
- en: '| Blue-Green | In this strategy, a production service (blue) takes traffic
    while the new service (green) is tested. If the green code is operating as expected,
    the green service will replace the blue service, and all customer requests will
    funnel through it. |'
  prefs: []
  type: TYPE_TB
- en: '| Rolling | This strategy deploys new codes one by one, alongside the current
    code in production, until it is fully released. |'
  prefs: []
  type: TYPE_TB
- en: After the deployment is successful, a monitoring step should observe the new
    code and make sure nothing has slipped past the CI phase. If a problem is detected,
    like high latency or increased error counts, it will be no problem to roll back
    the application to a previous version that was deemed safe. This is one of the
    great features of a container orchestrator like Kubernetes. It makes rolling code
    forward and backward very simple. (We’ll test the rollback feature later.)
  prefs: []
  type: TYPE_NORMAL
- en: Setting Up Your Pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before creating your pipeline, you’ll need to install a few tools to help automate
    code building, testing, and delivery. There are many tools on the market that
    do this, but for our scope, I am using two pieces of software that are open source
    and integrate nicely with Kubernetes. The first tool is called Skaffold, and it
    helps with continuous development for Kubernetes-native applications. It will
    make setting up the CI/CD pipeline to the local k8s cluster easy. If Skaffold
    is not installed, follow the instructions at [https://skaffold.dev/docs/install/](https://skaffold.dev/docs/install/)
    for your OS to complete the installation.
  prefs: []
  type: TYPE_NORMAL
- en: The other tool, `container-structure-test`, is a command line application that
    validates the container image’s structure after it’s built. It can test whether
    the image was constructed properly by verifying whether a specific file exists,
    or it can execute a command and validate its output. You can also use it to verify
    that a container image was built with the correct metadata, like the ports or
    environment variables you would set in a Dockerfile. The installation instructions
    for `container-structure-test` are available at [https://github.com/GoogleContainerTools/container-structure-test/](https://github.com/GoogleContainerTools/container-structure-test/).
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the skaffold.yaml File
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The *skaffold.yaml* file describes how to build, test, and deploy your application.
    This file should live in the root of your project and be kept under version control.
    The YAML file has many different options to choose from, but your pipeline will
    focus on three main sections: `build`, `test`, and `deploy`. The `build` section
    describes how to build your container image, the `test` section describes what
    tests to perform, and the `deploy` section describes how to release your application
    to the Kubernetes cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: The *skaffold.yaml* file is in the *telnet-server/* directory inside the cloned
    repository ([https://github.com/bradleyd/devops_for_the_desperate/](https://github.com/bradleyd/devops_for_the_desperate/)).
    You don’t need to edit or open this file, but you should have some familiarity
    with its basics and structure.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `build` section uses the default build action, which is the `docker build`
    command, to create our container image locally. The container `image` name is
    set to `dftd/telnet-server`. This matches the same image name you are using in
    the *deployment.yaml* file. You’ll see why that is important when you look at
    the `deploy` section. The Skaffold tool precalculates the container image tag
    using the current Git commit hash, which is the default behavior. The generated
    tag is appended to the container image name automatically, and it’s conveniently
    set to an environment variable (`$IMAGE`) that can be referenced if needed.
  prefs: []
  type: TYPE_NORMAL
- en: The `test` section allows you to run any tests against the application and container
    image. In this case, you’ll use unit tests that exist for the `telnet-server`
    application that I’ve provided for you. The unit tests, which are under the `custom`
    field, run the `go test` command for all the test files. This step requires that
    the Go programming language be installed. If you do not have Go installed, follow
    the instructions at [https://go.dev/doc/install/](https://go.dev/doc/install/)
    for your OS.
  prefs: []
  type: TYPE_NORMAL
- en: The next test that gets run is `structureTests`. This test checks the final
    container image for defects. We’ll go over these container tests briefly in a
    later section.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `deploy` section uses the Kubernetes manifest files inside the
    *kubernetes/* directory to release the `telnet-server` Deployment. The Skaffold
    tool performs a patch against the running Deployment and replaces the current
    container image and tag (which is *dftd/telnet-server:v1*) with the new one Skaffold
    generated during the `build` step. Because these names match the tag, they can
    be easily updated to a new one in the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the Container Tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the telnet-server container image is built and the application tests pass,
    the container tests are run on the newly built image. The container tests are
    located in a subdirectory called *container-tests/*, which is under the *telnet-server/*
    directory. This directory contains one test file named *command-and-metadata-test.yaml*.
    In this file, I have provided one application test to make sure the binary was
    built correctly, and I have also provided a few container image tests to verify
    that the container was built with the expected instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should review the structure tests now. Open the YAML file in your editor
    or follow along below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `commandTests` command executes the `telnet-server` binary, passing the
    `-i` (info) flag to it to output the ports on which the application is listening
    to STDOUT. The command output is then matched against what is in the `expectedOutput`
    field. For a successful test, the output should match `telnet port :2323\nMetrics
    Port: :9000` so you can make sure your binary was compiled correctly during the
    container `build` phase. This test makes sure the `telnet-server` application
    can at least run and function on a basic level.'
  prefs: []
  type: TYPE_NORMAL
- en: The `metadataTest` looks to see whether the container image was built with the
    proper instructions in the Dockerfile. The metadata tests verify environment variables
    (`env`), command (`cmd`), and `workdir`. These tests are useful for catching any
    delta between Dockerfile changes across different commits.
  prefs: []
  type: TYPE_NORMAL
- en: Simulating a Development Pipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you understand the pipeline configuration, let’s get a running pipeline.
    You can execute the `skaffold` command with either the `run` or the `dev` subcommand.
    The `run` subcommand is a one-off that builds, tests, and deploys the application
    and then exits. It does not watch for any new code changes. The `dev` command
    does everything `run` does, but it watches the source files for any changes. Once
    it detects a change, it kicks off the `build`, `test`, and `deploy` steps described
    in the *skaffold.yaml* file. For this example, you’ll use the `dev` subcommand
    to simulate a development pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: After the `dev` subcommand is run successfully, it will wait and block looking
    for any changes. By default, you’ll need to press CTRL-C to exit the `skaffold`
    `dev` mode. However, when you use CTRL-C to exit, the default behavior is to clean
    up after itself by removing the telnet-server Deployment and Services from the
    Kubernetes cluster. Since you’ll be using the telnet-server Deployment throughout
    this chapter and book, add the `--cleanup=false` flag to the end of the `dev`
    command to bypass this behavior. This way, the Pods will stay running after you
    quit the command.
  prefs: []
  type: TYPE_NORMAL
- en: To kick off the pipeline, make sure you are in the *telnet-server/* directory
    and your Kubernetes cluster is still running. The `skaffold` command can be quite
    chatty when executed. To make it easier to follow, you’ll break down the output
    as it aligns with the three `skaffold` sections above (`build`, `test`, and `deploy`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the following command in a terminal to run `skaffold`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The first action this command executes is to set the container tag to `4622725`,
    after which the Docker image is built. Your tag will likely be different, as it’s
    based off the current Git commit hash of my repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'After a successful build, `skaffold` triggers the test section where the unit
    and container infrastructure tests are kept:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The container tests and `telnet-server` unit tests pass with zero errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, after the container is built and all the tests pass, `skaffold` attempts
    to deploy the container to Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The Deployment is using our Kubernetes manifest files for the `telnet-server`
    application. For this Deployment, `skaffold` is using the new container image
    and tag (*dftd/telnet-server:4622725*) that was just built and tested to replace
    the one that is currently running (*dftd/telnet-server:v1*). If the `build`, `test`,
    and `deploy` steps are successful, there will not be any visible errors, and the
    final line should say, “`Watching for changes`.” If there are errors in any of
    the steps, the pipeline will halt immediately and throw an `error` with some clues
    to where the fault occurred. If any errors do occur, tack the `--verbosity debug`
    flag onto the `skaffold dev` command to increase the output’s verbosity.
  prefs: []
  type: TYPE_NORMAL
- en: If the container image and tag already exist, `skaffold` will skip the `build`
    and `test` sections and go right to the `deploy` step. This is a great time-saver,
    as you won’t need to repeat all the steps if all you are doing is redeploying
    the same container image. If your repository has uncommitted changes, `skaffold`
    adds `-dirty` to the end of your tag (`4622725-dirty`) to signal that changes
    are yet to be committed. In most cases, you’ll see this often when developing
    locally. That is because you’ll likely be constantly tinkering and making changes
    before committing your code.
  prefs: []
  type: TYPE_NORMAL
- en: Making a Code Change
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The pipeline is now set up, so you’ll want to make a code change to test the
    workflow. Let’s try something simple, like changing the color of the DFTD banner
    that greets you when you connect to the telnet-server. The source code for telnet-server
    is located in the *telnet-server/* directory. Currently, the banner is set to
    green (my favorite color). Once you make the code change and save the file, `skaffold`
    should recognize the change and trigger `build`, `test`, and `deploy` again.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a different terminal from the one in which you are already running `skaffold`,
    open the *banner.go* file, located in the *telnet/* subdirectory, using your favorite
    editor. Don’t worry about the code or the file’s contents; you’re just going to
    change the color. On line 26, you’ll see some code that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This is the line that sets the banner color.
  prefs: []
  type: TYPE_NORMAL
- en: 'Replace the string `colorGreen` with the string `colorYellow`, so the line
    now looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'After the change, save and close the file. Head back to the terminal where
    you are running the `skaffold dev` command. You should now see new activity that
    looks very similar to the output from the first `skaffold` run. All the steps
    will have been triggered again because you made a change in the source code that
    `skaffold` watches. The end result should be the same: you will have completed
    the Deployment rollout, and two new Pods will be running. If that isn’t the case,
    make sure that you actually saved the *banner.go* file and that `skaffold dev`
    is still running.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing the Code Change
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, you should make sure the new code was delivered to the Kubernetes cluster.
    Do this by validating that the DFTD banner color changed from green to yellow.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, you used the `minikube tunnel` command to access the
    telnet-server application. If you still have it running in a terminal, jump to
    the telnet client instructions below. If not, open another terminal and run the
    `minikube tunnel` command once again.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll need the IP address of the telnet-server Service again to access it.
    Run this command to get the telnet-server Service IP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Your `EXTERNAL-IP` may be different from mine, so use the IP from that column
    and port `2323`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Access the application again with the `telnet` client command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The DFTD banner, shown in [Figure 8-1](#figure8-1), should now be yellow.
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot showing the DFTD banner in ASCII art in a terminal window with
    a black background](image_fi/502482c08/f08001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-1: The telnet session should have a yellow banner'
  prefs: []
  type: TYPE_NORMAL
- en: If it’s not yellow, go back and make sure that the color was changed in the
    code correctly and that the file was saved. Also, you can use the `minikube kubectl
    get pods` command to verify that you have new Pods running. Make sure the age
    of the Pods goes back to within a short time after you saved the *banner.go* file.
    You should also look at the output in the terminal where `skaffold dev` is running,
    to detect any noticeable errors.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a Rollback
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There will be times when you need to roll back the application you have deployed.
    This can be due to many reasons, from problematic code to misalignment between
    product and engineering. Let’s say you wanted to go back to the release where
    the welcome banner was green. You would have two choices. On the one hand, you
    could make the necessary code change to set the banner back to green and put the
    application back through the CI/CD pipeline again. On the other hand, you could
    roll back the Deployment to the older version, where the DFTD banner is green.
    We’ll explore the latter option.
  prefs: []
  type: TYPE_NORMAL
- en: If the troubled application does not pose any immediate service disruption or
    cause ongoing customer impacts, you should make a hotfix for the code and follow
    your release cycle through your CI/CD pipeline. But what if this bug (error) caused
    a service disruption to your customers as soon as you deployed the code? You might
    not have time to wait for a thorough investigation to happen and a hotfix to run
    through the pipeline. But Kubernetes provides a way to roll back a Deployment,
    and other resources, to a previous revision. So in this case, you’ll roll back
    only one revision, to when the banner was green.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, check the rollout history. Every time you deploy new code, Kubernetes
    tracks the Deployments and saves the resource state at that given time. Enter
    the following in a terminal to fetch the Deployment history for `telnet-server`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: If you have been following along without any hiccups, the output should show
    two tracked Deployments. Currently, `REVISION` `2` is active. Notice the `CHANGE-CAUSE`
    column has `<none>`. That is because you did not tell Kubernetes to record the
    change. Using the `--record` flag when running `kubectl apply` makes Kubernetes
    record which command triggered the `deploy`. Don’t worry about using --`record`
    for this book. Depending on how many times you deployed the manifests from Chapter
    7 or how many times you ran `skaffold dev`, your `REVISION` numbers may be different.
    The actual number doesn’t matter here; you’re just going back to the previous
    revision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s force a rollback from the command line to `REVISION` `1`, which should
    reapply the manifests used in the first `deploy`, when the banner was green. The
    `kubectl rollout` command has an `undo` subcommand for this case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: You can leave off the `--to-revision=1` flag, as the default is to roll back
    to the previous revision. I added it here in case you ever need to roll back to
    a revision that was not the previous one.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a few seconds, the previous release should be running and accepting new
    connections. Verify this by running the `minikube kubectl get pods` command to
    show the Pods are new and have been running for only a few seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: These Pods’ names have changed, and the Pods have been running for only 29 seconds,
    which is what you’d expect after just rolling them back.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, check the banner’s color. Make sure the `minikube tunnel` command is still
    running, and then enter the `telnet` command into the application one more time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If everything went well, your DFTD banner should be green again.
  prefs: []
  type: TYPE_NORMAL
- en: If you run the `rollout history` command again, the current revision deployed
    will be `3`, and the previous revision, when the banner was yellow, will be `2`.
  prefs: []
  type: TYPE_NORMAL
- en: You now know how to do an emergency rollback in Kubernetes, to recover from
    any immediate service disruption. This technique can be useful when your organization
    focuses on *mean time to recovery (MTTR**)*, which basically means how long it
    takes for a service to go from “down” to “up” from a customer’s point of view.
  prefs: []
  type: TYPE_NORMAL
- en: Other CI/CD Tooling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Development pipelines are complex pieces of your infrastructure. In my quest
    to break them down in a simple manner, I’ve oversimplified some aspects. However,
    my main goal has been to show you how to create a simple pipeline to test and
    deploy code on a local Kubernetes cluster. You can also use this same pattern
    in nonlocal setups, like the ones in AWS or Google. The common strands that bind
    these processes together are portability and the use of a single file to describe
    the pipeline for an application. This means that if your pipeline YAML file works
    locally, it should also work on remote infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: That said, it might be helpful to describe some tools that are popular in the
    CI/CD space. There are more tools available that I can count, but popular ones
    include Jenkins, ArgoCD, and GitLab CI/CD. Of these, Jenkins is probably the most
    widely used, and it can operate both CI and CD for VMs, containers, and any other
    artifact you’re using. There are also a lot of widely available community plug-ins
    that make Jenkins extensible, but a lot of security issues come with them. Be
    diligent about updating plug-ins and looking out for issues.
  prefs: []
  type: TYPE_NORMAL
- en: Jenkins can deploy to any infrastructure and use any version control for code
    repositories. Argo CD, on the other hand, is a Kubernetes deployment tool that
    focuses only on the `deploy` phase. It can do canary or blue-green deployments
    out of the box, and it comes with a nice command line tool to manage the infrastructure.
    You can hook Argo CD into your pipeline after CI is done. Finally, GitLab CI/CD
    offers a full-featured pipeline (like Jenkins) that leverages Gitlab’s version
    control product to manage code repositories. It was designed for DevOps and includes
    almost everything you need to get up and running in a modern infrastructure stack.
  prefs: []
  type: TYPE_NORMAL
- en: Although these tools do a good job of empowering you to have a pipeline, it
    is important to separate the philosophy behind CI/CD from the tools used in this
    space. The truth is, each organization you work at may or may not use the tools
    or processes described here. The methodologies, rather than the individual tools
    themselves, are what’s important. No matter what tools you use, the main goal
    behind CI/CD is to validate and deliver code in small, predictable iterations,
    thus reducing the chance of errors or defects.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter introduced you to continuous integration and continuous deployment
    methodologies. The CI/CD pipeline you created used two tools to `build`, `test`,
    and `deploy` code. This allowed you to automate an application’s lifecycle in
    a Kubernetes cluster. You also learned about a rollback feature built into Kubernetes
    that makes it easy to recover quickly from errant code or misconfigured releases.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes Part II, which has focused on containerization and orchestration.
    You now can build and deploy a simple application inside a Kubernetes cluster.
    Going forward, we’ll shift gears and discuss observability, with a focus on metrics,
    monitoring, and alerting. We’ll also explore common troubleshooting scenarios
    you will find on a host or network, plus the tools you can use to diagnose them.
  prefs: []
  type: TYPE_NORMAL
