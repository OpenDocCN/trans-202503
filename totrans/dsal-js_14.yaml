- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: 11 BAGS, SETS, AND MAPS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/opener.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In this chapter we’ll consider some widely used abstract data types (ADTs):
    bags, sets, and maps. A *bag* is just a collection of values (repeated or not),
    a *set* is a collection of *distinct* values, and a *map* is a set of key + data
    pairs. We’ll consider some new ways of implementing these ADTs, starting with
    JavaScript’s own objects, and then move on to bitmaps, lists, and *hashing*, a
    new method we haven’t yet explored.'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Bags, Sets, and Maps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In [Chapter 3](chapter3.xhtml) we defined the ADT for bags with the set operations
    shown in [Table 11-1](chapter11.xhtml#tab11-1). (The use of the word *set* in
    this context is fully correct according to its mathematical definition.) When
    you need to store many (possibly repeated) values, you need a bag.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11-1: Operations on Bags'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Signature | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | → bag | Create a new bag. |'
  prefs: []
  type: TYPE_TB
- en: '| Empty? | bag → boolean | Given a bag, determine whether it is empty. |'
  prefs: []
  type: TYPE_TB
- en: '| Add | bag × value → bag | Given a new value, add it to the bag. |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | bag × value → bag | Given a value, remove it from the bag. |'
  prefs: []
  type: TYPE_TB
- en: '| Find | bag × value → boolean | Given a value, check whether it exists in
    the bag. |'
  prefs: []
  type: TYPE_TB
- en: In [Chapter 3](chapter3.xhtml) we had an extra operation to retrieve the greatest
    value from the bag, but that won’t be considered here because it’s not standard.
    You could also have an operation to find the current size of the bag, and possibly
    some more, but these are enough.
  prefs: []
  type: TYPE_NORMAL
- en: In some cases you want an actual set, so you don’t want to allow for repeated
    values, and that restriction calls for a slightly different set of operations,
    as shown in [Table 11-2](chapter11.xhtml#tab11-2).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11-2: Operations on Sets'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Signature | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | → set | Create a new set. |'
  prefs: []
  type: TYPE_TB
- en: '| Empty? | set → boolean | Given a set, determine whether it is empty. |'
  prefs: []
  type: TYPE_TB
- en: '| Add | set × value → set &#124; error | Given a new value, add it to the set.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | set × value → set | Given a value, remove it from the set. |'
  prefs: []
  type: TYPE_TB
- en: '| Find | set × value → boolean | Given a value, check whether it exists in
    the set. |'
  prefs: []
  type: TYPE_TB
- en: All operations are the same, except that when you try to add a new value and
    find that it is already there, you’ll do something different. One possibility
    is just to ignore the situation (after all, if you want to include a value in
    the set and the value is already there, everything is fine), or you could throw
    an error or perform some other action. You could always test beforehand whether
    the value to be added is in the set already, but it’s usually more efficient to
    do it when adding.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in some cases you’ll want to store key + data pairs. For example, for
    an application that uses information about countries, the key might be an ISO
    3166 country code (such as CH for Switzerland, TV for Tuvalu, or UY for Uruguay),
    and the data could be the country name, its population, and so on. Having implemented
    sets, implementing maps is simple. Instead of storing single values, you would
    store objects with key + data and make changes so *find* and *remove* work with
    just keys; the former returns the data if found instead of a boolean. See [Table
    11-3](chapter11.xhtml#tab11-3) for all operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11-3: Operations on Maps'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Signature | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | → map | Create a new map. |'
  prefs: []
  type: TYPE_TB
- en: '| Empty? | map → boolean | Given a map, determine if it is empty. |'
  prefs: []
  type: TYPE_TB
- en: '| Add | map × (key + data) → map &#124; error | Given a new key + data, add
    it to the map. |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | map × key → map | Given a key, remove it from the map. |'
  prefs: []
  type: TYPE_TB
- en: '| Find | map × key → data &#124; undefined | Given a key, check whether it
    exists in the map, and if found, return the data or undefined instead. |'
  prefs: []
  type: TYPE_TB
- en: All of these changes are fairly straightforward to do, so we’ll work with plain
    bags and sets. Let’s now consider specific implementations, starting with JavaScript’s
    own.
  prefs: []
  type: TYPE_NORMAL
- en: JavaScript’s Solutions for Sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You learned how to implement a bag in [Chapter 3](chapter3.xhtml) using several
    different methods. With a few changes, you can implement sets instead of bags;
    all you need to do is before adding a new value, check whether it was already
    present. In this section we’ll consider two more ways to implement sets in JavaScript:
    using plain objects (which is not the best way) and using standard set objects.'
  prefs: []
  type: TYPE_NORMAL
- en: Objects as Sets
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Even if objects aren’t designed to be used as sets (or maps), many developers
    use plain objects for them. If you can use values as attributes (mostly strings
    or numbers converted to strings), you can use them as property names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In plain JavaScript, creating an object means assigning an empty object ❶ and
    adding values to it ❷. Here, you now have a set with two keys: one and two. (If
    you want a map, the values associated with those keys are the data.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can test whether a key is in the object with the in operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, you can use delete to remove a key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: As extra operations, you can get a list of all an object’s attributes with Object.keys(...),
    and you can even iterate over them with for...in.
  prefs: []
  type: TYPE_NORMAL
- en: Using plain JavaScript objects obviously works, but you probably will want to
    make your intentions clearer for more understandable code and use a proper set,
    which, after all, directly represents the data structure you want.
  prefs: []
  type: TYPE_NORMAL
- en: Set Objects
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Sets are objects that let you store unique values. Creating a new JavaScript
    set and adding a couple of values is straightforward; try redoing the examples
    from the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a set by producing a new instance of the Set class ❶ and add values
    to it with its .add(...) method ❷. By the way, you can chain calls, so you can
    write those two additions on a single line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To test whether a value is in the set, use a .has(...) method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, you can remove values with the .delete(...) method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: JavaScript’s sets have a couple of extra interesting methods. To remove all
    values, you can use set.clear(). You also can find the number of elements in a
    set using the .size property.
  prefs: []
  type: TYPE_NORMAL
- en: Bitmaps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In some cases you can implement sets by making do with bitmaps (recall the bitmap
    sort from [Chapter 6](chapter6.xhtml)). If the values to store are numbers with
    a restricted range of values, an array of boolean flags will suffice.
  prefs: []
  type: TYPE_NORMAL
- en: We won’t see the code here, as it’s directly based upon the sorting you learned
    in [Chapter 6](chapter6.xhtml). The main idea is to set up an array filled with
    false values. The index to that array is the value itself. To add a value, set
    its flag to true; to remove it, reset its flag to false. Finally, to test whether
    a value is in the set, check the corresponding flag. You can’t do any better.
  prefs: []
  type: TYPE_NORMAL
- en: '### Using Lists'
  prefs: []
  type: TYPE_NORMAL
- en: 'We discussed lists in [Chapter 10](chapter10.xhtml), and you can adapt them
    to work as bags or sets. Consider three distinct possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ordered lists **Plain lists that keep their values in ascending order'
  prefs: []
  type: TYPE_NORMAL
- en: '**Skip lists **Two-dimensional structures with fast searches'
  prefs: []
  type: TYPE_NORMAL
- en: '**Self-organizing lists **Interesting applications that work for caches and
    similar situations'
  prefs: []
  type: TYPE_NORMAL
- en: Note that some of the solutions you’ll consider in the “Hashing” section on
    page 218 will also use lists.
  prefs: []
  type: TYPE_NORMAL
- en: Ordered Lists
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As mentioned in [Chapter 10](chapter10.xhtml), the concept of an ordered list
    is simple: instead of always adding values at one extreme or the other, you’ll
    add them so the values remain in order. This practice slows down insertions (you
    have to look for the right place to add the new value), but it makes for faster
    searches on average (when you reach a higher value than the one you wanted, you
    can stop the search). Take a look at the implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: Searching for a Value in an Ordered List
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The logic for searching is as direct as it gets: start at the beginning and
    follow the links until you reach the value or learn that the value isn’t there,
    because you either reached the end of the list or found a greater value than the
    one you wanted. [Figure 11-1](chapter11.xhtml#fig11-1) shows how you’d (successfully)
    look for value 22 in an ordered list.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-1: A successful search for a value (22) in a list'
  prefs: []
  type: TYPE_NORMAL
- en: This works the same way as linear searching ([Chapter 9](chapter9.xhtml)). Start
    at the head of the list and keep going. In this case you found the value you wanted,
    so you succeeded. If you were searching for 20 instead, at this same point you’d
    have given up the search. If you reach a value that’s higher than what you wanted,
    the search has failed.
  prefs: []
  type: TYPE_NORMAL
- en: The other possibility for failure is searching past the end of the list; see
    [Figure 11-2](chapter11.xhtml#fig11-2), which shows a search for 86.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-2: A failed search for a value (86) in a list'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for a linear search is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If you got an empty list—either it was empty from the beginning or you traveled
    down it and reached its end (you saw the code for this in [Chapter 10](chapter10.xhtml))—you
    know the value isn’t there. It also isn’t there if the list isn’t empty but its
    first value is greater than the value you’re seeking ❶. If the list isn’t empty
    and its first element matches the value you want ❷, the value was found. Finally,
    if the list isn’t empty and the value you want is greater than the first element
    of the list ❸, continue the search starting at the next node of the list.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a New Value to an Ordered List
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To add a new value, first do a search until you reach the place where the new
    value should go (meaning between a node with a smaller value and a node with a
    greater one), and then change a couple of pointers to include the new value in
    the list. [Figure 11-3](chapter11.xhtml#fig11-3) shows how to add 20 to the list.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-3: Adding a new value (20) to an ordered list'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to add a value that’s smaller than the one at the head of the list,
    you’ll need to change the pointer to the list itself. Another border case is adding
    a value greater than the last one in the list; you have to be careful when going
    down the list. You can use recursion to implement all of these cases more easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The logic is similar to what you saw for the linear search. If the list is empty,
    or if it’s not empty but the first value is greater than the one you want to add
    ❶, create a single node with the new value whose next pointer points to the list
    you had. (This covers the case of adding a value past the end; can you see how?)
    If you want to make a set, add a test ❷, because if you find the value you want
    to add, you would throw an error or otherwise reject the operation. If you’re
    making a bag and the value to add is greater than the first of the list ❸, add
    it using recursion, after the first element.
  prefs: []
  type: TYPE_NORMAL
- en: Removing a Value from an Ordered List
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Removing a value is a matter of finding it (which you already know how to do)
    and then modifying its predecessor’s link to point at the next value, as shown
    in [Figure 11-4](chapter11.xhtml#fig11-4).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-4: Removing the value (22) from an ordered list'
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned, do a search, and if it’s successful, skip the value to be removed.
    The only unusual case is when you delete the head of the list, you need to modify
    the pointer to the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The logic fully matches the search, case by case. It’s also logical; you must
    first find the value before you can remove it from the list. If the list is empty
    or if its first value is greater than the value ❶, return the list as-is, because
    there’s nothing to remove. If the value to remove is at the head of the list ❷,
    return the list’s tail, skipping the value to be removed. Finally, if the value
    to be removed is greater than the head of the list ❸, proceed recursively to delete
    the value from the tail of the list and return the (updated) list.
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance for Ordered Lists
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: There’s no way to speed up any of the processes, and if the list has *n* nodes,
    all functions are *O*(*n*). On average, all operations will visit half the nodes
    of the list. This implementation is good enough for small values of *n*, but for
    larger values, you’ll need something that allows you to move faster through the
    list—and in the next section we’ll see just that.
  prefs: []
  type: TYPE_NORMAL
- en: Skip Lists
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As just mentioned, searching a list is an *O*(*n*) process, because there’s
    no way to speed things up and move faster. However, you can take a tip from the
    jump search method ([Chapter 9](chapter9.xhtml)). What would happen if you could
    take long jumps to skip many places quickly, and when you get closer to the needed
    value, start doing smaller jumps, and then even smaller ones, until you finish
    with a one-by-one search? In this section we’ll consider *skip lists*, which allow
    you to traverse a list much more quickly by providing ways to skip ahead faster.
  prefs: []
  type: TYPE_NORMAL
- en: Consider an ordered list as shown in [Figure 11-5](chapter11.xhtml#fig11-5)
    (for clarity, I haven’t included the arrows; all go from left to right).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-5: Searching a long list is logically slower.'
  prefs: []
  type: TYPE_NORMAL
- en: As is, you can’t jump quickly as with a jump search, but with an auxiliary second
    list, doing so is possible, as shown in [Figure 11-6](chapter11.xhtml#fig11-6)
    (the vertical lines indicate pointers from top to bottom).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-6: Adding a second list to advance faster when searching the list'
  prefs: []
  type: TYPE_NORMAL
- en: If you wanted to search for 42, you’d start at the topmost list and move right
    until you get past 42; then you’d go back and down and continue the search (see
    [Figure 11-7](chapter11.xhtml#fig11-7)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-7: Searching for a value (42) with the aid of the second list'
  prefs: []
  type: TYPE_NORMAL
- en: The topmost list, which includes only a few values of the bottom list, allows
    you to make longer jumps, so the searches are speedier. Of course, for even faster
    processes, you could have three or more levels, as shown in [Figure 11-8](chapter11.xhtml#fig11-8).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-8: A third list helps speed up the search even more.'
  prefs: []
  type: TYPE_NORMAL
- en: This works well and provides better expected performance of *O*(log *n*). However,
    having all of these lists with repeated values everywhere isn’t good in practice.
    It would be better to have each value only once in a node with several pointers,
    according to the different levels, as shown in [Figure 11-9](chapter11.xhtml#fig11-9).
    (In reality, all nodes could have the same number of pointers, but [Figure 11-9](chapter11.xhtml#fig11-9)
    shows only the used ones.)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-9: An actual implementation of skip lists, with several pointers
    per node'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use this style of search to simplify our work. We’ll also add some sentinel
    nodes at the beginning and end of the lists to simplify all logic. You won’t ever
    have cases like “adding at the beginning” or “adding at the end,” because no value
    can be lower than the first sentinel or higher than the last one. Also, you won’t
    have to deal with empty lists (at least the sentinels will be there), and you’ll
    never go past the last item of a list.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Skip List
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'An empty list will consist of a node with two sentinels: a minus infinity value
    and a single level with a plus infinity value. Implementing it is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You have a list with just two values: -Infinity first and Infinity last. (You
    are working with numeric values here; for strings, you’d have to use appropriate
    low and high strings.) The skip list is flat, having just one level. (No next
    array has more than one element.) Knowing this, testing whether a skip list is
    empty is a tad more complex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If a skip list doesn’t have any values added to it, you’ll have the initial
    configuration, so your sentinels will be on the bottom level. In this data structure,
    the only value that has a null pointer to the next is the +Infinity sentinel;
    all other nodes have non-null pointers.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find how many levels a skip list has by simply looking at the length
    of the next arrays. Another function that will come in handy just returns the
    last index of the array of pointers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: You have to subtract 1 because the array of pointers is zero indexed, as usual.
  prefs: []
  type: TYPE_NORMAL
- en: Searching for a Value in a Skip List
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You saw the general idea for searches earlier, but now consider how they’d work
    with the actual implementation. Searches begin at the topmost level and advance
    to the right unless they go past the searched-for value, in which case they go
    down a level. If there are no more levels, the search is a failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code isn’t very long, but dealing with multiple levels requires care:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll use an auxiliary recursive function for the search. This function has
    three arguments: a node (somewhere in the skip list), the level at which it is
    searching, and the value to find ❶. If you try to go below level 0 ❷, you’ve failed,
    as you were at the bottom level and couldn’t find the value there. If the node
    has the value that you want ❸, the search succeeded. If the value you want is
    greater than or equal to the next value at the same level ❹, keep going without
    changing level. Otherwise, if you’ve already reached a higher value ❺, go down
    to the next level. The implementation of a general search ❻ starts at the first
    node at the top level.'
  prefs: []
  type: TYPE_NORMAL
- en: '##### Adding a Value to a Skip List'
  prefs: []
  type: TYPE_NORMAL
- en: We haven’t really discussed how to decide what values go at which levels. The
    solution we’ll use is based on random numbers. Obviously, all values will be at
    the bottom level, but they all won’t be at the other levels. We’ll decide whether
    a new value goes up one level by “flipping a coin”; we want approximately 50 percent
    of values to be in the next level. We’ll keep deciding randomly whether to move
    the value up one more level until the flip fails or you get a maximum level. In
    the code that follows, set MAX_LEVEL to 32, which implies that, on average, one
    value out of 2^(³²) will go that high—a really big structure!
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll require an auxiliary function to add a value at a certain level and all
    levels below it. An obvious question is why do you first add the value at a higher
    level and then at lower levels? Lists that are higher up have fewer elements,
    so insertions are faster there. Here’s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: If the new value is greater than the next value at this level ❶, you must advance;
    you’ll be able to add the new value when it lies between two consecutive values
    in the list. If you’re at a level lower than or equal to the maximum new level
    ❷, add the value and adjust the pointers to include the new value in the list
    ❸. Finally, if you haven’t reached bottom yet ❹, use recursion to add the value
    one level down ❺.
  prefs: []
  type: TYPE_NORMAL
- en: 'With this function, adding a value is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: First, decide up to which level you’ll find the new node ❶. Going up one more
    level will depend on the “coin flip.” After deciding that ❷, create a node with
    the value and an array with the right number of pointers. There’s the possibility
    that you’re going “higher” than before ❸ and that the skip list will be taller.
    If so ❹, you’ll have to add new pointers to the rightmost value. After this is
    taken care of ❺, use the auxiliary function to add the value to all the corresponding
    lists.
  prefs: []
  type: TYPE_NORMAL
- en: Removing a Value from a Skip List
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Removing a value requires two steps: first, remove it from all the lists it’s
    in, which you’ll do with an auxiliary function, and than possibly make the skip
    list “shorter” because by removing the value, it may not be as tall as before.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the logic for actually removing the value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Advance down the list ❶ until you find where the value should be. If you actually
    found it ❷ (the user may be asking to remove a value that simply isn’t in the
    list), fix the pointers ❸. Then keep doing removals until you reach the bottom
    level ❹.
  prefs: []
  type: TYPE_NORMAL
- en: 'Removing the value is the first step, as described; you may have to restructure
    multiple levels after that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: After removing the value ❶, go down all levels from the top ❷, and while the
    lists are basically empty (only the sentinels) ❸, you’ve made the list shorter
    ❹.
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance for Skip Lists
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Skip lists are probabilistic in nature, and the average performance can be shown
    to be logarithmic (see [Table 11-4](chapter11.xhtml#tab11-4)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11-4: Performance of Operations for Skip Lists'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Average performance | Worst case |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | O(1) | O(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Add | O(log n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | O(log n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Find | O(log n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: There is a quite low probability that the structure will behave badly (maybe
    having just a single level or having most values at all levels), but that’s not
    likely.
  prefs: []
  type: TYPE_NORMAL
- en: As with hashing (which you’ll explore later in this chapter) and other structures,
    you can solve performance problems by restructuring the skip list; see question
    11.4 for a possible idea. You can also modify the list to allow retrieving a value
    by position; see question 11.5.
  prefs: []
  type: TYPE_NORMAL
- en: Self-Organizing Lists
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There’s a particular case for which you can use an “auto-modified” bag successfully.
    Think about a cache with a limited maximum size. It’s not infrequent that one
    may require a given element several times in a short interval and then for a long
    time may not require it at all. In that case you can use a self-organizing list
    that places the elements required most often near the beginning (for quicker searches)
    and the ones required less often near the end (allowing a slower search).
  prefs: []
  type: TYPE_NORMAL
- en: As an example, think of a mapping (Global Positioning System [GPS]–style) application.
    You can’t hold every street name in memory, but to optimize speed, you could have
    a small cache of street names. Traveling in a certain zone, one often requires
    a certain group of street names, and it’s more unlikely one will need to find
    streets much farther away. The idea of a self-organizing list is to always add
    new values at the front, and if you search for a value and find it, move it to
    the front with the idea that if you soon require it again, you’ll get to it in
    a few steps.
  prefs: []
  type: TYPE_NORMAL
- en: Searching for a Value in a Self-Organizing List
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Searching an unordered list is not hard; you just have to keep going until you
    either find the value or reach the end of the list. You saw how to do this kind
    of search in [Chapter 10](chapter10.xhtml) (see the section “Implementing Lists
    with Dynamic Memory” on page 180). The important detail is what to do if you find
    the element. Make it the head of the list and take it out of its original place.
    [Figure 11-10](chapter11.xhtml#fig11-10) shows an example search for 12.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-10: After a successful search in a self-organizing list, the found
    node is brought to the head of the list.'
  prefs: []
  type: TYPE_NORMAL
- en: First, do a search for 12 (this is nothing new), but after finding it, there
    are some changes. Since the value wasn’t already at the head of the list, you’ll
    restructure the list so 12 is at the head, pointing to the old head of the list.
    If in the future you need to search for it again, those searches will be quite
    fast, because the value will be either at the head of the list or very close.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'When you search now you’re also modifying the list, so you’ll have to return
    two values: the list itself (which was possibly updated if the value was found)
    and a boolean value with the result of the search. (Too much bother? See question
    11.3.) If the list is empty ❶, return the list and false, because trivially the
    value isn’t there. If the list isn’t empty and the value you want is at the list’s
    head ❷, you don’t have to change the list, so you return it as is, plus true because
    you succeeded. If the list isn’t empty and the value you want isn’t at the list’s
    head ❸, set up a loop in which prev and curr will point to consecutive nodes in
    the list. That loop will finish when either you get to the list’s end or you find
    the value you want ❹. In the case of the former condition ❺, return the list and
    a false value, just as when the list is empty ❶; if the latter ❻, change pointers
    and return the current node as the new list’s head, plus true.'
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Value to a Self-Organizing List
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Since these lists are unordered, you can add values anywhere, using the simple
    logic you’ve used before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Putting the new value at the top of the list, as its head, is as simple as can
    be. Make a new node that points to the old list ❶, and the new list has that node
    as its head. This code is functionally equivalent to the push(...) method that
    you wrote for stacks in [Chapter 10](chapter10.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: Removing a Value from a Self-Organizing List
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Earlier we saw how to remove a value from an ordered list. Doing the same with
    an unordered list is not very different, except that you may always have to go
    to the end of the list, because there’s no way to stop the search earlier. You
    already saw how to do the search in an iterative way, so now do this recursively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: If the list is empty ❶, just return it, because the value to be removed isn’t
    there. If the value you want to remove is the one the list points at ❷, returning
    the tail of the list (which list.next points to) causes the removal. Finally,
    if the head of the list doesn’t have the value you want ❸, make that node point
    to the result of removing the value from the tail of the list.
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance and Variants for Self-Organizing Lists
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This structure’s performance is *O*(*n*), as with common lists, and a search
    looks at *n*/2 elements on average. However, in actual experience with clustered
    requirements, it behaves much better, with far fewer looks at elements. It’s not
    a theoretical advantage, but a fully empirical, pragmatic one, and in the worst
    case, you are no worse off.
  prefs: []
  type: TYPE_NORMAL
- en: There are other variants with similar performance. The “move to front” (MTF)
    solution is not the only possible one. Another possibility is “swap with previous”
    in which instead of moving the found element to the head of the list, you just
    swap it with the one before, making it closer to the head. If you make many searches
    for a given value, it eventually reaches the front of the list, but if the search
    was just a one-off case, then it stays around where it was.
  prefs: []
  type: TYPE_NORMAL
- en: Another variant is to add a count of references to each value, increment it
    by 1 every time a value is searched for and found, and move it nearer the head
    of the list so that the values are in descending order of counts.
  prefs: []
  type: TYPE_NORMAL
- en: Hashing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section we’ll move on to a different concept that potentially provides
    the fastest possible searches: *hashing*. The idea of hashing is somewhat related
    to bitmaps. If the values to be stored in the set are taken from a small range,
    you can use a bitmap, which provides *O*(1) searches, as you saw. However, if
    the values are from a very large range (for instance, US Social Security Numbers,
    nine digits long, with 1,000,000,000 possible values), a bitmap becomes prohibitive
    because of the needed space. In addition, it’s most likely that you’ll be dealing
    with a very small percentage of all possible keys. The idea is to first use an
    array of *slots* to store values, but then instead of using the key as an index
    (as in bitmaps), you’ll compute a hash of the value and use that hash as the index.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In reference to a hash, Ambrose Bierce said, “There’s no definition for this
    word—nobody knows what [a] hash is.” For us, a hash is any function that transforms
    a value—numeric, string, and so on—into a number in a given range. For the Social
    Security number example, to get a hash between 000 and 999, you could just take
    the three final numbers. To get a hash between 0 and a top number *K*, dividing
    values by *K* and taking the remainder would do. There are many ways to compute
    hashes, but we’ll use the remainder function, like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: When using hashing to decide where to store (or look for) a value, we first
    compute the hash and then go to the corresponding slot in the array (see [Figure
    11-11](chapter11.xhtml#fig11-11)). It’s quite similar to what we did with bitmaps,
    but in that case, we used the key as an index; here we assume that the number
    of possible keys is exceedingly large, so we apply hashing to reduce it to a manageable
    value.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-11: In hashing, a hash function is used to decide where a value should
    be stored in a table.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the value you want occupies the slot, you’ve found it. If the slot is free,
    you know for sure that the value isn’t in the set. But how do you deal with different
    values that produce the same hash, so that all should go in the same slot? This
    situation is called a *collision*, and you must specify how to solve it. (If you
    think this isn’t likely, try searching for “Birthday Paradox” online; you’ll be
    surprised!) Different hashing strategies differ in how they handle collisions.
    This chapter will discuss three distinct strategies: buckets with chaining, open
    addressing, and double hashing. The implementations will be bags, but we’ll consider
    how to do sets in the questions at the end of the chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Hashing with Chaining
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A first solution to collisions is to consider each slot as a bucket into which
    you may place multiple values. The simplest way to implement this is by taking
    advantage of the ordered lists you saw earlier in the chapter, and most of the
    work will already be done for you. All values that go into the slot are placed
    in a list, and you’ll work with a small set of numbers for simplicity. [Figure
    11-12](chapter11.xhtml#fig11-12) shows slots at the left (slot #3 is unoccupied)
    and the lists at the right.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-12: Hashing with chaining uses lists for values that hash to the
    same value.'
  prefs: []
  type: TYPE_NORMAL
- en: To search for a value, first compute in which slot to look for it (which in
    this case means finding the remainder of the value divided by 5, the table’s length)
    and then search the corresponding list. If the value is in the set, you should
    find it in the list. This implementation isn’t hard, considering you already saw
    how to use lists for bags or sets, so here are the details.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Chained Hash Table
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'To create a new hash table for use with chaining, create an empty array and
    fill it with new lists (you’ll use ordered lists, as shown earlier in this chapter,
    as a refresher):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: You are creating an object instead of an array in case of other solutions that
    will require extra fields—for instance, to keep track of how many slots are used
    or are free. (See question 11.6 for a common mistake.)
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Value to a Chained Hash Table
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'You can add a new value to this hash table easily; the code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: You just have to compute into which slot the new value should go ❶ and then
    add it to the corresponding list ❷.
  prefs: []
  type: TYPE_NORMAL
- en: Searching for a Value in a Chained Hash Table
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Searching for a value is also simple: after deciding in which slot the value
    should be, search the corresponding list. You could write the search in a single
    line, but it’s clearer as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Calculate the corresponding slot ❶ and then search for it ❷. Note that you had
    to rename the find(...) method from lists to findInList(...) to avoid recursively
    calling the wrong function. Another possibility would be writing something like
    List.find(...).
  prefs: []
  type: TYPE_NORMAL
- en: '##### Removing a Value from a Chained Hash Table'
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, removing a value is easy because of all the code you developed earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As when adding a value, first compute the correct slot ❶ and then remove the
    value from the list ❷ by using the removeFromList(...) method from lists, which
    is also renamed to avoid conflicts.
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance for Chaining
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The performance of the worst case of hashing with chaining is, obviously, *O*(*n*)
    if all values map to the very same slot. If the situation isn’t as extreme and
    there are *s* slots, each chain should be around *n/s* values long, so searches
    are *O*(*n/s*), which is actually *O*(*n*) but with a better expected constant.
    The more slots you have, the shorter the chains and the better the performance.
  prefs: []
  type: TYPE_NORMAL
- en: You could keep track of how many values are in the table (or of the lengths
    of the individual chains), and should those numbers exceed some limit, you could
    re-create the table with a larger number of slots to improve performance. We’ll
    study this kind of process in the next sections.
  prefs: []
  type: TYPE_NORMAL
- en: Hashing with Open Addressing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Another common solution to dealing with collisions is this: if the slot to
    use is already occupied, try the following place (and, if needed, the one after
    that, and the next, and so on, returning to the beginning cyclically after reaching
    the end of the table) until you find an empty slot. To do a search, apply the
    same scheme: first check the corresponding hash, and if the slot is empty, the
    search failed. If the slot is occupied and it’s the value you wanted, the search
    succeeded; otherwise, proceed to the (cyclically) next place and try again. You
    can see how this works with a simple example. Start with an empty hash table into
    which just 22 was added; see [Figure 11-13](chapter11.xhtml#fig11-13).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-13: A hash table with just one element'
  prefs: []
  type: TYPE_NORMAL
- en: You could add 04, 75, 09, and 60, and each would go into its corresponding slot,
    as shown in [Figure 11-14](chapter11.xhtml#fig11-14).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-14: Four more elements were added, with no collisions so far.'
  prefs: []
  type: TYPE_NORMAL
- en: The problem appears if you try to add 12, because the corresponding slot, the
    second one, is already occupied. You must start advancing, so 12 ends up in slot
    3, as shown in [Figure 11-15](chapter11.xhtml#fig11-15).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-15: A collision occurs when you try to add a value (12) to an occupied
    slot.'
  prefs: []
  type: TYPE_NORMAL
- en: As the table becomes more and more full, it’s more likely that new values will
    end up far from their correct slot; for instance, if you add 63, it ends up at
    slot 6, as shown in [Figure 11-16](chapter11.xhtml#fig11-16).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-16: In a fuller table, values end up far from their corresponding
    slot.'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, as defined, it becomes apparent that if the table becomes full, you’ll
    be in an infinite loop. The *load factor* is defined as the ratio between occupied
    slots and total slots. An empty hash table has a zero load, and a totally full
    one has a load factor of 1\. The result is intuitive, but you can show mathematically
    that as the load factor grows, insertions and searches will progressively become
    slower. As a rule of thumb, if the load factor gets above 0.75, you should move
    to a larger hash table.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: When conducting searches, the process is exactly the same as for insertions.
    If you are looking for 63, you’d start at slot 3, and if it’s not there, advance
    by one until finding it at slot 6\. If you are looking for 73 instead, you’d advance
    until slot 7, which is empty, and then decide that 73 isn’t in the table.
  prefs: []
  type: TYPE_NORMAL
- en: Deletions are not a straightforward process. Consider removing 22, as shown
    in [Figure 11-17](chapter11.xhtml#fig11-17).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-17: The wrong way to delete a value (22) messes up other searches.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, if you want to search for 12, what happens? Finding that slot 2 is empty,
    you’d decide that 12 isn’t there, which is bad. We’ll have to do lazy deletions.
    Instead of actually emptying a slot when removing a value, we’ll mark it as available.
    We’ll treat deleted locations as empty when adding new values, but as occupied
    when searching. Deleting 12 would get the result shown in [Figure 11-18](chapter11.xhtml#fig11-18).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-18: The right way to delete a value (22) just marks the slot (#2)
    as “used but available.”'
  prefs: []
  type: TYPE_NORMAL
- en: For searches, slot 2 is considered to be occupied, so when looking for 12, you
    won’t stop at slot 2, but will instead keep advancing. For insertions (suppose
    at a later time you wanted to add 42 to the table), slot 2 is considered available,
    so you could use it, as shown in [Figure 11-19](chapter11.xhtml#fig11-19).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-19: A “used but available” slot (#2) may be used for new insertions.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you’ve explored how a hash table works with the important detail of
    how to deal with deletions, consider the actual code.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Open-Addressed Hash Table
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'For open addressing, all you need is a table, but you’ll also keep track of
    how many slots have been used in order to compute the load factor. You’ll start
    by defining, for ease of coding, a couple of constants:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The EMPTY value will be assigned to all as yet unused slots, and AVAILABLE will
    be used for slots that were occupied before but that are now available because
    you removed the original value that was there.
  prefs: []
  type: TYPE_NORMAL
- en: 'A new hash table will be an object with 100 slots by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Given the desired size for the hash table (defaulting to 100), create an empty
    array of that size, filled with the EMPTY value ❶, and set the initial count of
    used slots to 0 ❷.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Value to an Open-Addressed Hash Table
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'You’ve already seen the logic for additions, and the code is somewhat long:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Start by calculating in which slot the value should go ❶. Then start a linear
    search ❷ that stops when you get to an EMPTY or AVAILABLE slot; note that using
    the modulus operation ❸ makes the search wrap to the beginning. After the search
    for an open slot succeeds, if the slot was empty ❹, add one to the count of used
    slots. If you’re wondering why you don’t do it if the slot was AVAILABLE instead,
    you’ll understand why when you look at removing a value. An important detail is
    that you assume the table has some free space. You’ll see how that works when
    you look at performance for hashing with open addresses.
  prefs: []
  type: TYPE_NORMAL
- en: You’re actually implementing a bag here. To do a set instead, see question 11.7.
  prefs: []
  type: TYPE_NORMAL
- en: Searching for a Value in an Open-Addressed Hash Table
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As described previously, the search is similar to the insertion process. You’ll
    do the same kind of process as if you were looking to insert a new value, but
    you’ll skip the actual insertion. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: As when inserting, first decide in which slot the value should be found ❶, and
    if needed, loop ❷ until you either get the value or reach an EMPTY slot. Depending
    on how the loop ends, return true or false ❸. You’re ignoring AVAILABLE slots,
    for reasons that will become apparent.
  prefs: []
  type: TYPE_NORMAL
- en: Removing a Value from an Open-Addressed Hash Table
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Removing a value is strongly based on how you do searches. The key issue is
    that upon finding the value to be deleted, you’ll mark the slot as AVAILABLE,
    implying that the slot is free now for future insertions, but it isn’t really
    free, so for searches, consider it as filled and keep going.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The first part ❶ is the same code as in the search function. The only difference
    with that code is that after exiting the loop, if the search succeeded, set the
    slot to AVAILABLE ❷.
  prefs: []
  type: TYPE_NORMAL
- en: 'An important question is why you didn’t decrement the used count. A border
    case shows the problem: imagine you entered *n* values, from 1 to *n*, into a
    hash table of size *n*, then removed them all, and finally tried to add any new
    value. What would happen? An infinite loop when checking if the value was already
    in the table! The load factor considers all slots that are or were occupied; you’ll
    see what to do when that load becomes too high in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance for Hashing with Open Addressing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As mentioned, the search performance degrades considerably when the load factor
    tends to 1, eventually becoming *O*(*n*). The worst case is always *O*(*n*); an
    example of this (not the only one, for sure) would be if all keys hash to the
    same slot. See [Table 11-5](chapter11.xhtml#tab11-5).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 11-5: Performance of Operations for Open-Addressed Hash Tables'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Average performance | Worst case |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | O(1) | O(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Add | O(1) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | O(1) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Find | O(1) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: 'If you keep the load factor limited, you can expect good performance, but as
    you add more values to the table, it will degrade. There’s no way out of this,
    but you can modify the add(...) logic to produce a larger table automatically
    to avoid high loads. You just have to change the final return ht from the code
    for adding a value to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: If the load factor has exceeded the recommended 0.75 threshold ❶, create a new
    hash table, double the size ❷, and go through the original table slot by slot
    ❸. Every value you find ❹ will be added to the new table ❺. At the end, instead
    of returning the original table as you did before, you’ll return the new larger
    table ❻. Had the load factor been acceptable ❼, you’d return the original table
    as before. For an alternative technique, see question 11.9.
  prefs: []
  type: TYPE_NORMAL
- en: This sort of logic also comes in handy for the versions of hashing tables that
    we’ll consider next.
  prefs: []
  type: TYPE_NORMAL
- en: Double Hashing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The logic you’ve been applying doesn’t really help much with collisions. Should
    two values coincide at a slot, they’ll also coincide at the following slot, and
    the next, and so on. This scheme is likely to produce long lengths of adjacent
    occupied slots that will slow down searches and insertions.
  prefs: []
  type: TYPE_NORMAL
- en: 'An idea that helps in that situation is not always trying the next slot, but
    rather skip a number of slots and make that number depend on the value, so different
    values skip different numbers of slots. The concept of *double hashing* works
    this way: a first hashing function finds the first slot to try, but if that’s
    occupied, a second hashing function determines what size steps to take, instead
    of always jumping to the immediate next slot.'
  prefs: []
  type: TYPE_NORMAL
- en: If you return to the example from the “Hashing with Open Addressing” section
    on page 221, while there are no collisions, everything works the same way, so
    after the first five insertions, you’d have the situation shown in [Figure 11-20](chapter11.xhtml#fig11-20).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-20: A hash table using double hashing, with no collisions so far'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you want to add 12, and the #2 slot is occupied. In the previous section
    you used open addressing, so you tried slot #3, and if that also was occupied,
    you would have tried slots #4, #5, and so on, in succession, until finding an
    empty one. With double hashing, you’ll use a second function to decide how far
    to jump. Use the remainder of dividing the value by 9, plus 1, which is guaranteed
    to be a number between 1 and 9 inclusive. For value 12, the step would be 4, so
    the next attempt would be at slot #6, as shown in [Figure 11-21](chapter11.xhtml#fig11-21).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure11-21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11-21: Double hashing uses a second function to work with collisions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If slot #6 had been occupied, you’d have advanced four slots again (cyclically)
    and tried slot #0, and after that slot #4, and so on. There’s a possible problem
    here. If you wanted to add value 130 to the table in [Figure 11-21](chapter11.xhtml#fig11-21),
    what would happen? The first attempt would be at slot #0, and that fails. The
    second attempt would be at slot #5 (because the step for 130 would be 5), but
    that also fails. The third attempt would be at slot #0 again (because of the cyclical
    search), and you’d be in a loop.'
  prefs: []
  type: TYPE_NORMAL
- en: You’ll have to take care of detecting (and solving) these loops; there are two
    different ways to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Table That Uses Double Hashing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Creating a table for double hashing is exactly the same as for open addressing,
    so we don’t need special code here. Here’s the needed logic again for easier reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The key differences are in how you add, search for, and remove values.
  prefs: []
  type: TYPE_NORMAL
- en: '##### Adding a Value to a Table That Uses Double Hashing'
  prefs: []
  type: TYPE_NORMAL
- en: 'You saw the procedure for adding a value in a double hash earlier in this section,
    so let’s get to the code. You’ll use two hashing functions: a first one to determine
    the initial slot to try and a second one to skip in the search. It’s very important
    that the second function must never return a zero value.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The logic to add a value needs careful attention to avoid infinite looping:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Start by using the first hash function ❶ to get the initial slot. If that slot
    isn’t empty ❷, use the second hash function ❸ to see how far to jump at every
    step. You’ll save the initial slot at i0 ❹ to detect a loop, and then start looking
    for an empty or available slot ❺. At each pass of the loop, advance step places
    ❻, and if you detect that you’re back at the initial i0 place, then advance just
    one place and save the new initial slot ❼. After finding where to put the new
    value ❽, the logic is as for the previous hash methods: update the count of used
    slots and save the value. You should regenerate the table in case of a high load
    factor, in the same way as in the open addressing section.'
  prefs: []
  type: TYPE_NORMAL
- en: Searching for a Value in a Table That Uses Double Hashing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The logic for searching for a value matches the way you add new values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Start by deciding on the initial slot to test ❶ and the step amount to jump
    ❷. Then save the initial spot to detect a loop ❸ and start jumping until you find
    an empty slot or the desired value ❹; the logic for jumps is exactly the same
    as for insertions, including the loop detection ❺. At the end, return true or
    false ❻ depending on where you stopped the search.
  prefs: []
  type: TYPE_NORMAL
- en: Removing a Value from a Table That Uses Double Hashing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'I won’t repeat the explanation here, but to remove a value, you’ll use the
    same technique as for open addressing. You won’t mark removed values as EMPTY,
    but rather as AVAILABLE. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The code is exactly the same as for the open addressing search, and you change
    only what to do after finishing the loop. If you found the value ❶, mark the slot
    as AVAILABLE; if it’s not found, don’t do anything.
  prefs: []
  type: TYPE_NORMAL
- en: The logic for double hashing works well, but you can easily make it more streamlined,
    as we’ll see next.
  prefs: []
  type: TYPE_NORMAL
- en: Double Hashing with Prime Lengths
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The only problem with the logic that you saw with double hashing operations
    is the need to deal with possible loops. You’ll get a loop whenever the step size
    you choose happens to have some common factor with the table’s length. For instance,
    if the table size is 18 and the step is 12, after three steps you’ll be back where
    you started. If you could choose a table length that doesn’t have any common factors
    with all possible steps, the logic would be simpler. There’s an easy way to do
    that: if the table length is a prime number (divisible only by itself or by 1),
    no loops are possible, because a prime number has no common divisors with any
    lower number. Also, if the step is 1, everything is fine, because before returning
    to the initial slot, you’ll have gone through the complete array.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Table That Uses Double Hashing with Prime Lengths
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'You can create a new hash table exactly as before, except you must ensure that
    its length is a prime number. First you need to check whether a number is prime:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Small numbers are prime (and for the purposes here 1 works as a prime number,
    no matter what mathematicians may say) ❶. Even numbers (you excluded 2 in the
    previous if) aren’t prime ❷, so those cases are simple. For other numbers, test
    all odd possible divisors starting at 3 ❸ and stop when you find an exact division
    ❹ or when the tested possible divisor exceeds the square root of the number, in
    which case the number is prime ❺.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next you need a simple function to find the first prime number greater than
    a given value, and you can write it simply by using the isPrime(...) function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The logic is straightforward: given a number, if it’s not prime ❶, add 1 to
    it ❷ until the number becomes a prime.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can create a table. The logic is the same as before, except you make
    sure that the length of the table is a prime number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Whatever size you get, you find the next higher prime and use it as the table
    length.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Value to a Table That Uses Double Hashing with Prime Lengths
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'To add a value, work the same way as with the double hashing code, except you
    don’t have to test for loops; prime numbers have this covered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: You’ll advance as before, but all the code related to i0 (which you used for
    loop detection) is now gone.
  prefs: []
  type: TYPE_NORMAL
- en: Searching for a Value in a Table That Uses Double Hashing with Prime Lengths
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Searching is also simpler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Again comparing this code with the code for common double hashing, the key difference
    is that you did away with all the loop detection and prevention.
  prefs: []
  type: TYPE_NORMAL
- en: '##### Removing a Value from a Table That Uses Double Hashing with Prime Lengths'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, as expected, removing a value is also easier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Once more, the code is the same as for common double hashing, but without checking
    for loops; it’s faster, simpler code.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter we’ve considered several ways to implement bags and sets, including
    the hashing technique that, when properly applied, can provide the fastest possible
    search times. The structures considered here were basically linear; in the next
    chapter we’ll start considering nonlinear ones such as trees to explore further
    implementations of bags and sets.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**11.1  Sentinels for Searches**'
  prefs: []
  type: TYPE_NORMAL
- en: Show how an ordered list could benefit from a final +Infinity sentinel value
    for simpler code.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.2  More Sentinels?**'
  prefs: []
  type: TYPE_NORMAL
- en: Would adding an initial -Infinity sentinel help with ordered lists?
  prefs: []
  type: TYPE_NORMAL
- en: '**11.3  A Simpler Search?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Can you simplify the code to avoid having to return two values when searching
    a self-organizing list? A tip: if the search was successful, the list won’t be
    empty and its head will have the searched value.'
  prefs: []
  type: TYPE_NORMAL
- en: '**11.4  Re-skipping Lists**'
  prefs: []
  type: TYPE_NORMAL
- en: Can you sketch out an algorithm that will restructure a skip list to make sure
    it is well balanced?
  prefs: []
  type: TYPE_NORMAL
- en: '**11.5  Skip to an Index**'
  prefs: []
  type: TYPE_NORMAL
- en: In the earlier definition you just wanted to search for a value, but what if
    you had an index *i* and wanted the *i*th value of the list? Can you think of
    a way to modify skip lists in order to find a value by index in an efficient way?
  prefs: []
  type: TYPE_NORMAL
- en: '**11.6  Simpler Filling**'
  prefs: []
  type: TYPE_NORMAL
- en: Why wouldn’t the following code work to create a hashing table with chaining?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '**11.7  A Hashed Set**'
  prefs: []
  type: TYPE_NORMAL
- en: In the hash table code for insertions you allowed repeated values, so you’re
    doing bags instead of sets. Can you modify the code as efficiently as possible
    to implement sets instead? Obviously, you could start by doing a search, but if
    that search failed, you’d be redoing a lot of work for the addition.
  prefs: []
  type: TYPE_NORMAL
- en: '**11.8  Wrong Seating**'
  prefs: []
  type: TYPE_NORMAL
- en: This puzzle will remind you of hashing. Imagine that 100 people were given tickets
    for a show. The theater has 100 seats, and each ticket is assigned to a different
    seat. There was a problem, though. The first person to arrive at the theater didn’t
    pay attention and sat in a random seat. All the other people tried to go to their
    seats, and if their seats were already occupied, they also took random seats.
    What’s the probability that the last person (the 100th one) will find that their
    seat is unoccupied?
  prefs: []
  type: TYPE_NORMAL
- en: '**11.9  Progressive Resizing**'
  prefs: []
  type: TYPE_NORMAL
- en: Doing a whole resizing operation (with the corresponding delay in time) may
    not be acceptable for some systems, so you need some kind of progressive resizing
    solution. Can you sketch a way to do the rehashing gradually, somehow working
    with two tables (an old one and a new one) but not rehashing the entire old table
    at once?
  prefs: []
  type: TYPE_NORMAL
