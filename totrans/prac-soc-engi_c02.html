<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="index: http://www.index.com/" lang="en" xml:lang="en">
<head>
<title>Chapter 2: Ethical Considerations in Social Engineering</title>
<link href="NSTemplate_v1.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:5e8bb34b-260b-4fef-91f3-caabb4446e65" name="Adept.expected.resource"/>
</head>
<body epub:type="bodymatter chapter">
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" id="Page_13" title="13"/>2</span><br/>
<span class="ChapterTitle">Ethical Considerations in Social Engineering</span></h1>
</header>
<figure class="opener">
<img alt="" src="image_fi/book_art/chapterart.png"/>
</figure>
<p class="ChapterIntro">Unlike network and web application penetration testing, the impact of social engineering can extend beyond the confines of a laptop or server. When you’re interacting with real people, you have to take special precautions to avoid hurting them. </p>
<p>You must also make sure you abide by the laws in your area, as well as the location of any potential people or businesses you’ll be targeting. While there may not be a legal precedent that directs you to collect OSINT in a specific way—or restricts you from collecting OSINT at all—some laws, like the European Union (EU) General Data Protection Regulation (GDPR), place specific liabilities and repercussions on you for the data that you collect and dictate how you must protect it. This chapter outlines guidelines for conducting social engineering and collecting OSINT legally and ethically.</p>
<h2 id="h1-500983c02-0001"><span epub:type="pagebreak" id="Page_14" title="14"/>Ethical Social Engineering</h2>
<p class="BodyFirst">Let’s start by talking about the social engineering attack itself. In a social engineering engagement, you must be sensitive to how a target will feel as a result of your actions. This can be tricky, because you have to develop ways of showing that a company is vulnerable, usually because the employees lack proper training or processes to follow, without victimizing or villainizing the person who revealed those vulnerabilities to you. </p>
<p>One way to protect people is to keep them relatively anonymous to your client. For example, instead of reporting that Ed in Accounting clicked a link in a phishing email, say that someone in either Accounting or Finance fell victim to a phishing attack. In doing so, you should consider the size of the organization and the ability for peers to guess the identity of the victim from the details you give. If you’re working at a small company—say, No Starch Press, the publisher of this book—you might avoid saying that Bill Pollock, the company’s founder, had too much permissive information publicly posted to Facebook, and opt instead to state that a manager lacked privacy and access controls on social media.</p>
<p>The actual bad guys likely won’t adhere to similar boundaries. In penetration testing, however, we shouldn’t copy <em>everything</em> the bad guys do. If we did, we’d be using <em>denial-of-service attacks</em> (attacks against networks and systems that keep legitimate users and services from being able to access them) against penetration testing clients; <em>doxing</em> clients by publicly releasing their personal information, such as their address, email address, and phone number; and deploying <em>ransomware</em> (malicious software that requires victims to pay a ransom in order to unlock it). </p>
<p>Here are some tips for protecting people in your social engineering engagements.</p>
<h3 id="h2-500983c02-0001">Establishing Boundaries</h3>
<p class="BodyFirst">The following should go without saying: if people ask you to stop talking to them, or if they end conversations, you should stop. Also, although you can view a target’s public posts on social media and build a profile on them, you should never do the following: </p>
<ul>
<li>Target their personal accounts (this includes connecting with them)</li>
<li>Target them outside of work </li>
</ul>
<p>Imagine that someone continuously asked you work questions when you were at home. You wouldn’t like it, would you? Acceptable use of social media for collecting OSINT includes looking for public data about work, mentions of specific software or technologies, or occurrences of a routine username.</p>
<h3 id="h2-500983c02-0002">Understanding Legal Considerations</h3>
<p class="BodyFirst">When it comes to performing social engineering, there are two main legal considerations: spoofing and recording. Other than these issues, one best <span epub:type="pagebreak" id="Page_15" title="15"/>practice for avoiding legal trouble is to ensure that you’re targeting assets owned by your client, rather than any bring-your-own-device (BYOD) systems owned by employees.</p>
<p>Some states, like Tennessee, have laws that make spoofing phone numbers illegal. If you’re spoofing as an adversary emulation that is authorized by contract with your client company, and if you’re targeting company-owned assets only, you are generally clear. When it comes to recording a call, some states require you to have two-party consent, meaning both you and the victim must consent, and others require single-party consent, meaning it’s enough for you to consent. Whether a company can serve as the second party of consent for recording its employees on company-owned devices is a legal gray area. <a href="#table2-1" id="tableanchor2-1">Table 2-1</a> lists two-party states. If asked to record calls, refer to your legal counsel for further clarification in your specific location. </p>
<figure>
<figcaption class="TableTitle"><p><a id="table2-1">Table 2-1</a>: States That Require Both Parties to Consent to a Phone Call Recording</p></figcaption>
<table border="1" id="table-500983c02-0001">
<thead>
<tr>
<td><b>Two-party states</b></td>
<td><b>Notes</b></td>
</tr>
</thead>
<tbody>
<tr>
<td>California<br/></td>
<td/>
</tr>
<tr>
<td>Connecticut</td>
<td>From the perspective of criminal cases, it is illegal for someone aside from the sender or receiver to record the call. From the perspective of civil cases, Connecticut is a two-party consent state. <br/></td>
</tr>
<tr>
<td>Delaware<br/></td>
<td/>
</tr>
<tr>
<td>Florida<br/></td>
<td/>
</tr>
<tr>
<td>Illinois</td>
<td>Has the most confusing laws governing consent. It’s a two-party consent state with special concessions for public places like courtrooms. The law applies to “private electronic communications,” which includes messages sent via phone, computer, and other communication devices.<br/></td>
</tr>
<tr>
<td>Maryland<br/></td>
<td/>
</tr>
<tr>
<td>Massachusetts<br/></td>
<td/>
</tr>
<tr>
<td>Montana<br/></td>
<td/>
</tr>
<tr>
<td>Nevada</td>
<td>By law, Nevada is a single-party state, as long as the recording party is taking part in the communication. But based on a precedent set by the Nevada Supreme Court in <em>Lane v</em><em>.</em><em> Allstate, </em>you should treat Nevada<em> </em>as a two-party state. <br/></td>
</tr>
<tr>
<td>New Hampshire<br/></td>
<td/>
</tr>
<tr>
<td>Oregon</td>
<td>When it comes to recording phone calls, Oregon is a single-party state. When it comes to recording in-person communications, Oregon is a two-party state.</td>
</tr>
<tr>
<td>Pennsylvania<br/></td>
<td/>
</tr>
<tr>
<td>Washington<br/></td>
<td/>
</tr>
</tbody>
</table>
</figure>
<h3 id="h2-500983c02-0003">Understanding Service Considerations</h3>
<p class="BodyFirst">You might also run into trouble if you violate a service’s terms of use. In 2019, Mike Felch at Black Hills Information Security published a pair of <span epub:type="pagebreak" id="Page_16" title="16"/>blog posts about selecting the software services to use when phishing. Entitled “How to Purge Google and Start Over” parts 1 and 2, these posts discuss his experience using G Suite (the Google productivity platform now called Google Workspace) as both a target and a tool for attacking. Felch explains how he compromised credentials and used CredSniper to bypass multifactor authentication. </p>
<p>That’s where the story takes an interesting turn. He was detected by both the client Security Operations Center (SOC) and Google’s SOC. As a byproduct, Google not only took actions to disable the account he was using, but also (presumably through the use of some OSINT and its own detection algorithms) started to lock him and his wife out of other unrelated accounts to Google services that they used. The moral of the story is to ensure that you coordinate with any other providers the client may use before the engagement to ensure you don’t get locked out of everything, including, as in Mike’s case, your thermostat.</p>
<h3 id="h2-500983c02-0004">Debriefing After the Engagement</h3>
<p class="BodyFirst">After performing social engineering operations, it’s important to <em>debrief</em> the organization and the targeted employees. Debriefing involves making victims aware of the techniques you used and the information you gathered, in a broad sense. You don’t have to tell the entire organization that Jane in Finance uses her husband John’s name as a password, or that Madison is having problems with her uncle. Keep the report you give your clients anonymous and leave out specifics; tell them simply you found that <em>some</em> employees were using their spouses’ names as passwords, or that you easily discovered information about their personal relationships. </p>
<p>One way to navigate this ethical issue is to maintain a list of those who fall victim to the engagement and how they failed the assessment, while still redacting their names from the report. If your point of contact at the organization asks for that information, you might provide names so long as the company agrees not to terminate the employee. This negotiation can sometimes be a clause used in contracts between social engineers and their clients. If the company is failing to train their employees, it’s not fair to fire them for security missteps. On the other hand, your report should name the people who stopped the engagement from succeeding. These people took actions to protect the organization, and they should be recognized and rewarded. </p>
<p>From an organizational perspective, management should let employees know that the company itself did not go snooping on them. Instead, it should be clear that the company paid someone else to snoop, then filtered the data down to information relevant to the business only, to keep the employees’ personal lives private. Furthermore, the organization should use the report you provide to them, along with recommendations and example scenarios, to train the employees so that they can be more secure.</p>
<p>When giving presentations at conferences like DerbyCon, Hacker Halted, and various Security BSides events, I follow the same rules as I do in reporting. You never know if one of the people who fell victim to the attack is in <span epub:type="pagebreak" id="Page_17" title="17"/>the room, so avoid publicly shaming people. Praise in public, and reprimand in private. Inspire people to be more vigilant and report issues to the appropriate people. </p>
<h2 id="h1-500983c02-0002">Case Study: Social Engineering Taken Too Far</h2>
<p class="BodyFirst">In 2012, while pregnant with Prince George of Cambridge, Duchess Kate Middleton was hospitalized for extreme morning sickness. The public and the media soon found out, and at 5:30 <span class="KeyCaps">AM</span>, a pair of DJs at an Australian radio show called the hospital, posing as the Queen of England and Prince Charles. The hosts mimicked their accents and requested an update on Middleton. The nurse working reception answered the phone. Believing the call was legitimate, she put them through to Middleton’s personal nurse, who provided various details of her condition.</p>
<p>The DJs recorded the call and played it on the air. The program got international attention. Before the hospital could take any action, the nurse was found dead of an apparent suicide. Prince William and Duchess Kate released a statement regarding their deep sadness for the incident and offering condolences to those close to the nurse. </p>
<p>This is an example of social engineering gone too far. Pranks are pranks, but at some point during the call, the pranksters should have revealed themselves. They also shouldn’t have made the stunts publicly known to a vast audience. The radio show seems to have been canceled, and the show and hosts’ Twitter accounts seem to have been deleted. The hosts issued a formal public apology—all too late after an avoidable tragedy.</p>
<p>While this action is more of a tasteless prank than an attack, the incident fits the APA definition of <em>manipulation</em>, because the DJs were not acting with the victim’s best interests in mind. Had they not broadcasted the call, their action may have been closer to influence, though the best solution would have been to not make the call in the first place. </p>
<h2 id="h1-500983c02-0003">Ethical OSINT Collection </h2>
<p class="BodyFirst">Now that I’ve established the legal and ethical boundaries for social engineering, we should do the same for OSINT. Much of the same considerations come into play, but the stakes are generally lower, because while the information you find through OSINT gathering could affect the well-being of your targets, you’re not interacting with them directly. Still, this doesn’t mean you should collect all the data out there on every target. </p>
<h3 id="h2-500983c02-0005">Protecting Data</h3>
<p class="BodyFirst">You should assess how long to retain any data you collect, how to destroy the data, what value to assign to the data, what the outcome of losing the data would yield, and how someone might attempt to compromise the data. </p>
<p>Digital forensics and law enforcement often rely on the concept of the <em>chain of custody</em> when dealing with data. The chain of custody seeks to <span epub:type="pagebreak" id="Page_18" title="18"/>preserve in a secure state any evidence collected, from the time of collection to disposal. This requires keeping all evidence in a secure and controlled location, such as an evidence locker, as you may have seen in police shows on TV. The person accessing the evidence has to demonstrate a legitimate need and sign the evidence out, then back in, for accountability. </p>
<p>Digitally, enforcing a chain of custody is a little harder, but it’s possible to accomplish if you take certain precautions. The first is practicing good security hygiene, which we’ll discuss next. For each investigation, you need a dedicated virtual machine that you will use exclusively for that engagement. The machine needs to be encrypted with a strong password. Once you’re finished with the investigation, determine the retention requirements. Store the files that make up the virtual machine on a disk. A CD or DVD may be big enough, or you may need a bigger drive, such as a USB thumb drive or external hard drive. As an additional layer of security, you could encrypt the drive itself and securely store it, disconnected from any computers, with some sort of physical access controls, such as a lock and key. </p>
<p><em>Digital hygiene</em> is nothing more than the consistent application of security best practices. Have a form of malware protection on your devices, and don’t reuse passwords (and use strong passwords). You should also set up a password manager and multifactor authentication at every opportunity. This is but the tip of the iceberg, but these steps can help ensure that no one can call the integrity of your data into question, especially if the OSINT you’re collecting is for litigation.</p>
<p>To assign value to data, consider what damage could be done to the company or person with it. I never collect social security numbers, but if I did, I would assign them a very high value. If I collect a name or an email along with a password, I will assign them the highest level possible. Finding this information indicates that an organization or employee has suffered a breach, and that you should exercise due care. That being said, if the organization can demonstrate that the user in question is technically prohibited from using the password in question, you might reduce the finding to low- or informational-level severity. Merely a password without a person tied to it will also have a lower value, although you could use it in a password-spraying attack on the company. (In <em>password spraying</em>, an adversary uses a single password in an attempt to brute-force numerous accounts, such as using a default password across all observed accounts.)</p>
<p>In summary, protect your sensitive data by minimizing access to the system on which it’s stored, keeping it patched and up to date, disabling unnecessary services, employing strong passwords, and using multifactor authentication when you can. Encrypt the data whenever possible as well. Even if someone compromises the data, it will be worthless to them if they can’t break the encryption key.</p>
<h3 id="h2-500983c02-0006">Following Laws and Regulations</h3>
<p class="BodyFirst">This section covers potential legal considerations for collecting OSINT. While the GDPR is the main law affecting OSINT, other countries, states, and jurisdictions have enacted similar laws associated with the loss of <span epub:type="pagebreak" id="Page_19" title="19"/>personal information as a result of a data breach. Collecting OSINT is not a data breach in itself, but because no legal precedent has yet established the outcome of GDPR and similar laws when applied to OSINT, you should treat these laws as relevant to your activities. </p>
<h4 id="h3-500983c02-0001">General Data Protection Regulation</h4>
<p class="BodyFirst">As of May 25, 2018, GDPR regulates what you can do with data belonging to citizens of the EU. The regulation aims to protect citizens and residents of the EU regarding the collection and use of their data. In essence, it empowered EU citizens and residents as consumers to take agency over the data that is collected from them and about them. After GDPR passed in 2016, businesses were given two years to become compliant. May 25, 2018 was the date that all companies, globally, had to be in compliance with GDPR. A company that violates GDPR can face fines of 4 percent of its global annual revenue. This should provide an incentive to protect any information gathered about EU citizens (in the EU and abroad) and people visiting the EU. </p>
<p>GDPR’s main impact on social engineering and OSINT is that it gives people the ability to limit others’ collection of their personal information (PI) and sensitive personal information (SPI), which, in turn, reduces their OSINT attack surface. Additionally, it creates penalties for companies that collect and store PI and SPI belonging to EU citizens if that data is breached and the information made publicly accessible.</p>
<p>Another important provision in GDPR is the right to be forgotten. This provision allows private citizens to query the information a data owner or data processor holds on them in addition to a request for timely removal of their PI or SPI. </p>
<h4 id="h3-500983c02-0002">Collecting Data as Law Enforcement</h4>
<p class="BodyFirst">If you are in law enforcement (federal, state, municipal, or otherwise) or a licensed private investigator, specific codes of ethics and legal precedents direct the parameters by which you can gather and use OSINT. Review any applicable laws or consult legal counsel before engaging in any OSINT gathering operations. </p>
<p>The American Civil Liberties Union (ACLU) published a document in 2012 warning about the slippery slope associated with using big data and other techniques, including OSINT, to attempt to identify potential criminals before they act. The ACLU discussed the practice of gathering mass data from law enforcement agencies about people, and then using it to implicate them in crimes they may not have committed, often by using data science to make predictions. Jay Stanley, the author of the ACLU piece, posits that such collection and analysis will encourage more collection, with or without a just cause. It may cause people to enter the criminal justice system without due process.</p>
<h4 id="h3-500983c02-0003">Collecting Data as Private Citizens</h4>
<p class="BodyFirst">Private citizens: you’re not off the hook yet. Some countries and areas have laws governing OSINT gathering for all citizens, even outside law <span epub:type="pagebreak" id="Page_20" title="20"/>enforcement. For example, in the state of South Carolina, you must be a licensed private investigator to have digital forensics research be admissible in court. <em>Digital forensics research</em> includes anything gleaned from the analysis of a computer system, whether it be the hard drive or network. </p>
<p>Bottom line: you are responsible for knowing the laws in the areas where you and your target are located. Before practicing any OSINT collection, it’s best that you consult a lawyer in your area with specific knowledge of cyber laws as related to business and consulting, just to be safe.</p>
<h2 id="h1-500983c02-0004">Case Study: Ethical Limits of Social Engineering</h2>
<p class="BodyFirst">The following scenario occurred when I was a consultant assisting a penetration testing team with an engagement on an organization. I was to vish up to 25 targets and write a report on the calls. The company did not provide me with a pretext to use. (Some clients like to provide one, although I prefer to create my own scenario, to make sure the employees haven’t been preemptively briefed.)</p>
<p>I pretended to conduct an <em>organizational transparency survey</em>, which is something I made up to allow me to ask victims fairly intrusive questions under the supposed authority of the CEO. Instead of finding phone numbers via OSINT, the organization provided me a list of numbers, without names or departments. Because blindly calling a number doesn’t typically lead to success, I needed to do more research. Of the phone numbers, one was police dispatch and two others were local court phone numbers. I spoke to my manager about these, and we decided to pass on vishing them out of caution. </p>
<p>To make the calls, I spoofed my number to reflect a phone number from Nielsen, a company that conducts surveys for other organizations. I claimed I was conducting a survey authorized by the head of the target’s organization to see how much employees knew about the workplace and other departments of the organization. I asked a set of questions similar to these:</p>
<ol class="decimal">
<li value="1">How long have you been an employee?</li>
<li value="2">Do you have access to wireless internet? If so, what is the network name or Service Set Identifier (SSID)?</li>
<li value="3">Do you have vending machines?</li>
<li value="4">What kind of computer are you on? Operating system?</li>
<li value="5">Which brand and type of antivirus do you use?</li>
<li value="6">Who is your janitor?</li>
<li value="7">What was your mother’s name before she was married?</li>
<li value="8">Can you provide an example of a previous or current password that you use?</li>
</ol>
<p>As mitigations, I did not record the calls and conducted them in a private place. After some time, a couple of people had given me their mother’s maiden names, but nobody had given me any passwords yet. </p>
<p><span epub:type="pagebreak" id="Page_21" title="21"/>Next, I called a public works number. A nice lady in her 60s answered. We exchanged pleasantries, and I explained the survey. She agreed to help as much as she could but told me she wasn’t very tech savvy.</p>
<p>“Me either,” I said. “I’m doing this work part-time while I go to the ACME Community College for psychology.” We shared a laugh, and I began the survey.</p>
<p>I went through the list. She answered the first six questions, but when I asked her for her mother’s name before she got married, she told me I was asking for a password reset question, which she really shouldn’t tell anyone. I agreed to move on, telling her that I didn’t always like the questions that I had to ask. I reminded her she could always say no to a question. When I asked her for a password she often used, she hesitated, then sighed and told me “buttermilk.” </p>
<p>“Buttermilk?” I repeated. </p>
<p>To build rapport with her, I shared a true story about how, as a kid, I used to enjoy eating crumbled cornbread in buttermilk with my late grandfather. </p>
<p>The woman started sobbing. When I asked if she was okay, she told me that cornbread in buttermilk was her late husband’s favorite meal. I immediately felt low. She told me that the upcoming Thanksgiving would be his birthday and that she’d lost him about three years prior, to cancer.</p>
<p>What should you do in scenarios like this? I chose to stay in character, but I chatted with her until I was confident that she had returned to a good place mentally. It would have been unethical to drop the call and move on. We reminisced about our late family members, people in her area, the weather, and other small-talk subjects.</p>
<p>Before disconnecting, I asked her if she was okay. After I disconnected, I spoke to the practice lead, repeated the story, and told him that I would prefer not to do any more calls that day. He agreed, so I shifted to another project that didn’t involve calling people. </p>
<p>Key takeaways:</p>
<ul>
<li>Always allow people to opt out of the engagement. You can attempt to influence them to keep going, but don’t get too forceful. If they say no, move on. If you feel confident, ask again later, but if they say no again, drop it. Being forceful will not help your cause.</li>
<li>When asking sensitive questions, ensure that you’re in a quiet and secure place. Avoid recording the call if asking such questions.</li>
<li>If you have indications that you’ve struck a nerve with someone, take the time to either debrief them or bring them back to a stable place, depending on what is appropriate for your campaign.</li>
<li>Communicate with your management if you end up in a situation like mine. They should be aware that an incident occurred in case the target contacts them, but they should also know about your mental state and anything that could impact your performance.</li>
</ul>
<h2 id="h1-500983c02-0005"><span epub:type="pagebreak" id="Page_22" title="22"/>Conclusion</h2>
<p class="BodyFirst">Social engineering and OSINT both have implications for the people associated with the engagement, even outside the workplace. In this aspect, it’s different from conventional penetration testing, which for the most part allows victims to leave work at work. In performing these engagements, exercise due care and diligence to ensure that the person being targeted won’t suffer adverse psychological stress or be otherwise harmed. The best way to do so is to set specific boundaries, like the ones described in this chapter. Otherwise, my best advice to practitioners is to trust your instinct. Don’t hesitate to contact legal counsel when working with international clients. If what you’re doing to a victim of the engagement is something that would upset you, chances are that you shouldn’t be doing it.</p>
</section>
</body>
</html>