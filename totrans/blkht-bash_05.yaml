- en: <hgroup>
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <hgroup>
- en: 5 VULNERABILITY SCANNING AND FUZZING
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 漏洞扫描与模糊测试
- en: </hgroup>
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: </hgroup>
- en: '![](../images/opener.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/opener.jpg)'
- en: In [Chapter 4](chapter4.xhtml), we identified hosts on a network and a few running
    services, including HTTP, FTP, and SSH. Each of these protocols has its own set
    of tests we could perform. In this chapter, we’ll use specialized tools on the
    discovered services to find out as much as we can about them.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](chapter4.xhtml)中，我们识别了网络上的主机和几个运行中的服务，包括HTTP、FTP和SSH。每种协议都有我们可以执行的一组测试。在本章中，我们将使用专门的工具对已发现的服务进行测试，尽可能多地了解它们。
- en: In the process, we’ll use bash to run security testing tools, parse their output,
    and write custom scripts to scale security testing across many URLs. We’ll fuzz
    with tools such as ffuf and Wfuzz, write custom security checks using the Nuclei
    templating system, extract personally identifiable information (PII) from the
    output of tools, and create our own quick-and-dirty vulnerability scanners.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，我们将使用bash运行安全测试工具，解析其输出，并编写自定义脚本，以便在多个URL上进行大规模的安全测试。我们将使用ffuf和Wfuzz等工具进行模糊测试，使用Nuclei模板系统编写自定义安全检查，从工具的输出中提取个人身份信息（PII），并创建我们自己的简易漏洞扫描器。
- en: Scanning Websites with Nikto
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Nikto扫描网站
- en: '*Nikto* is a web scanning tool available on Kali. It performs banner grabbing
    and runs a few basic checks to determine if the web server uses security headers
    to mitigate known web vulnerabilities; these vulnerabilities include *cross-site
    scripting (XSS)*, which is a client-side injection vulnerability targeting web
    browsers, and *UI redressing* (also known as *clickjacking*), a vulnerability
    that lets attackers use decoy layers in a web page to hijack user clicks. The
    security headers indicate to browsers what to do when loading certain resources
    and opening URLs, protecting the user from falling victim to an attack.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*Nikto*是Kali中可用的Web扫描工具。它执行横幅抓取并进行一些基本检查，以确定Web服务器是否使用安全头部来缓解已知的Web漏洞；这些漏洞包括*跨站脚本攻击（XSS）*，这是一种针对Web浏览器的客户端注入漏洞，以及*UI重定向*（也称为*点击劫持*），这是一种漏洞，允许攻击者在网页中使用诱饵层来劫持用户点击。安全头部指示浏览器在加载特定资源和打开URL时该如何处理，从而保护用户免受攻击。'
- en: After performing these security checks, Nikto also sends requests to possible
    endpoints on the server by using its built-in wordlist of common paths. The requests
    can discover interesting endpoints that could be useful for penetration testers.
    Let’s use Nikto to perform a basic web assessment of the three web servers we’ve
    identified on the IP addresses 172.16.10.10 (*p-web-01*), 172.16.10.11 (*p-ftp-01*),
    and 172.16.10.12 (*p-web-02*).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行这些安全检查后，Nikto还通过使用其内置的常见路径词典向服务器的可能端点发送请求。这些请求可以发现一些有趣的端点，对于渗透测试人员来说可能很有用。让我们使用Nikto对我们在IP地址172.16.10.10（*p-web-01*）、172.16.10.11（*p-ftp-01*）和172.16.10.12（*p-web-02*）上识别出的三个Web服务器进行基本的Web评估。
- en: 'We’ll run a Nikto scan against the web ports we found to be open on the three
    target IP addresses. Open a terminal and run the following commands one at a time
    so you can dissect the output for each IP address:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将针对我们发现开放的Web端口，对三个目标IP地址运行Nikto扫描。打开终端，依次运行以下命令，这样你可以逐一分析每个IP地址的输出结果：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output for 172.16.10.10 on port 8081 shouldn’t yield much interesting information
    about discovered endpoints, but it should indicate that the server doesn’t seem
    to be hardened, as it doesn’t use security headers:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 172.16.10.10在8081端口的输出应该不会提供太多关于发现端点的有趣信息，但它应该表明该服务器似乎没有经过加固，因为它没有使用安全头部：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Nikto was able to perform a banner grab of the server, as indicated by the line
    that starts with the word Server. It then listed a few missing security headers.
    These are useful pieces of information but not enough to take over a server just
    yet.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Nikto能够执行服务器的横幅抓取，这从以“Server”开头的行中可以看出。然后它列出了几个缺失的安全头部。这些是有用的信息，但还不足以完全接管服务器。
- en: 'The IP address 172.16.10.11 on port 80 should give you a similar result, though
    Nikto also discovered a new endpoint, */backup*, and that directory indexing mode
    is enabled:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: IP地址172.16.10.11上的80端口应该会给出类似的结果，尽管Nikto还发现了一个新端点，*/backup*，并且启用了该目录的索引模式：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Directory indexing* is a server-side setting that, instead of a web page,
    lists files located at certain web paths. When enabled, the directory indexing
    setting lists the content of a directory when an index file is missing (such as
    *index.html* or *index.php*). Directory indexing is interesting to find because
    it could highlight sensitive files in an application, such as configuration files
    with connection strings, local database files (such as SQLite files), and other
    environmental files. Open the browser in Kali to *http://172.16.10.11/backup*
    to see the content of this endpoint ([Figure 5-1](chapter5.xhtml#fig5-1)).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/pg97.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-1: Directory indexing found on 172.16.10.11/backup'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'Directory indexing lets you view files in the browser. You can click directories
    to open them, click files to download them, and so on. On the web page, you should
    identify two folders: *acme-hyper-branding* and *acme-impact -alliance*. The *acme-hyper-branding*
    folder appears to contain a file named *app.py*. Download it to Kali by clicking
    it so it’s available for later inspection.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: We’ll explore the third IP address in a moment, but first let’s use bash automation
    to take advantage of directory indexing.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Building a Directory Indexing Scanner
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What if we wanted to run a scan against a list of URLs to check whether they
    enable directory indexing, then download all the files they serve? In [Listing
    5-1](chapter5.xhtml#Lis5-1), we use bash to carry out such a task.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: directory _indexing _scanner.sh
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Listing 5-1: Automatically downloading files available via directory indexing'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: In this script, we define the FILE and OUTPUT_FOLDER variables. Their assigned
    values are taken from the arguments the user passes on the command line ($1 and
    $2). We then fail and exit the script (exit 1) if the FILE variable is not of
    the file type and of length zero (-s) ❶. If the file has a length of zero, it
    means the file is empty.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: We then use a while loop to read the file at the path assigned to the FILE variable.
    At ❸, we ensure that each whitespace character in each line from the file is removed
    by piping it to the xargs command. At ❹, we use curl to make an HTTP GET request
    and follow any HTTP redirects (using -L). We silence verbose output from curl
    (using -s) and pipe it to grep to find any instances of the strings Index of /
    and [PARENTDIR]. These two strings exist in directory indexing pages. You can
    verify this by viewing the source HTML page at *http://172.16.10.11/backup*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: If we find either string, we call the wget command ❺ with the quiet option (-q)
    to silence verbose output, the recursive option (-r) to download files recursively
    from folders, the no-parent option (-np) to ensure we download only files at the
    same level of hierarchy or lower (subfolders), and the reject option (-R) to exclude
    files starting with *index.html*. We then use the target folder option (-P) to
    download the content to the path specified by the user calling the script (the
    OUTPUT_FOLDER variable). If the user didn’t provide a destination folder, the
    script will default to using the *data* folder ❷.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们找到任一字符串，我们会调用 wget 命令 ❺，并加上静默选项 (-q) 来抑制详细输出，递归选项 (-r) 用于递归下载文件，禁止父目录选项
    (-np) 确保我们只下载与当前目录同级或更低层次的文件（子文件夹），以及拒绝选项 (-R) 用于排除以 *index.html* 开头的文件。然后我们使用目标文件夹选项
    (-P) 将内容下载到用户调用脚本时指定的路径（OUTPUT_FOLDER 变量）。如果用户没有提供目标文件夹，脚本将默认使用 *data* 文件夹 ❷。
- en: NOTE
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意
- en: '*You can download this chapter’s scripts from* [https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05](https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可以从以下链接下载本章的脚本* [https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05](https://github.com/dolevf/Black-Hat-Bash/blob/master/ch05)。'
- en: The *acme-impact-alliance* folder we downloaded appears to be empty. But is
    it really? When dealing with web servers, you may run into what seem to be dead
    ends only to find out that something is hiding there, just not in an obvious place.
    Take note of the empty folder for now; we’ll resume this exploration in a little
    bit.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下载的 *acme-impact-alliance* 文件夹似乎是空的。但真的是空的吗？在处理 Web 服务器时，你可能会遇到看似死胡同的情况，但最终会发现有东西隐藏在那里，只是没有在明显的地方。暂时记下这个空文件夹；稍后我们将继续这个探索。
- en: Identifying Suspicious robots.txt Entries
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别可疑的 robots.txt 条目
- en: 'After scanning the third IP address, 172.16.10.12 (*p-web-02*), Nikto outputs
    the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在扫描完第三个 IP 地址 172.16.10.12（*p-web-02*）后，Nikto 输出如下内容：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Nikto was able to find a lot more information this time! It caught missing security
    headers (which is extremely common to see in the wild, unfortunately). Next, Nikto
    found that the server is running on Apache and Debian and that it is powered by
    PHP, a backend programming language commonly used in web applications.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这次 Nikto 能发现更多信息了！它捕获了缺失的安全头（不幸的是，这在野外是非常常见的）。接下来，Nikto 发现服务器正在运行 Apache 和 Debian，并且它是由
    PHP 支持的，PHP 是一种常用于 Web 应用程序中的后端编程语言。
- en: It also found an uncommon link that points to *http://172.16.10.12/wp-json*
    and found two suspicious entries in the *robots.txt* file—namely, */wp-admin/*
    and */donate.php*. The *robots.txt* file is a special file used to indicate to
    web crawlers (such as Google’s search engine) which endpoints to index and which
    to ignore. Nikto hints that the *robots.txt* file may have more entries than just
    these two and advises us to inspect it manually.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 它还发现了一个不常见的链接，指向 *http://172.16.10.12/wp-json*，并在 *robots.txt* 文件中发现了两个可疑条目——即
    */wp-admin/* 和 */donate.php*。*robots.txt* 文件是一个特殊文件，用于指示网络爬虫（例如 Google 搜索引擎）哪些端点应该被索引，哪些应该被忽略。Nikto
    提示 *robots.txt* 文件可能包含比这两个条目更多的内容，并建议我们手动检查。
- en: Finally, it also identified another endpoint at */wp-login.php*, which is a
    login page for WordPress, a blog platform. Navigate to the main page at *http://172.16.10.12/*
    to confirm you’ve identified a blog.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，它还识别出了另一个端点 */wp-login.php*，这是一个用于 WordPress 博客平台的登录页面。访问主页面 *http://172.16.10.12/*
    来确认你已经识别出一个博客。
- en: 'Finding these non-indexed endpoints is useful during a penetration test because
    you can add them to your list of possible targets to test. When you open this
    file, you should notice a list of paths:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在渗透测试中，发现这些未索引的端点是非常有用的，因为你可以将它们添加到可能的目标列表中进行测试。当你打开这个文件时，你应该会注意到一系列路径：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We identified some of these endpoints earlier (such as */donate.php* and */wp-admin*),
    but others we didn’t see when scanning with Nikto. In Exercise 5, you’ll use bash
    to automate your exploration of them.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前识别了一些这些端点（例如 */donate.php* 和 */wp-admin*），但有些端点在使用 Nikto 扫描时没有看到。在练习 5 中，你将使用
    bash 自动化探索这些端点。
- en: 'Exercise 5: Exploring Non-indexed Endpoints'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 5：探索未索引的端点
- en: Nikto scanning returned a list of non-indexed endpoints. In this exercise, you’ll
    use bash to see whether they really exist on the server. Put together a script
    that will make an HTTP request to *robots.txt*, return the response, and iterate
    over each line, parsing the output to extract only the paths. Then the script
    should make an additional HTTP request to each path and check the status code
    it returns.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 5-2](chapter5.xhtml#Lis5-2) is an example script that can get you
    started. It relies on a useful curl feature you’ll find handy in your bash scripts:
    built-in variables you can reference to extract particular values from HTTP requests
    and responses, such as the size of the request sent (%{size_request}) and the
    size of the headers returned in bytes (%{size_header}).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: curl_fetch _robots_txt.sh
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Listing 5-2: Reading robots.txt and making requests to individual paths'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: At ❶, we read the output from the curl command at ❹ line by line. This command
    makes an HTTP GET request to *http://172.16.10.12/robots.txt*. We then parse each
    line and grab the second field (which is separated from the others by a space)
    to extract the path and assign it to the path variable ❷. We check that the path
    variable length is greater than zero to ensure we were able to properly parse
    it ❸.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Then we create a url variable, which is a string concatenated from the TARGET_URL
    variable plus each path from the *robots.txt* file, and make an HTTP request to
    the URL. We use the -w (write-out) variable %{http_code} to extract only the status
    code from the response returned by the web server.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: To go beyond this script, try using other curl variables. You can find the full
    list of variables at *[https://curl.se/docs/manpage.html](https://curl.se/docs/manpage.html)*
    or by running the man curl command.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Brute-Forcing Directories with dirsearch
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *dirsearch* fast directory brute-forcing tool is used to find hidden paths
    and files on web servers. Written in Python by Mauro Soria, dirsearch provides
    features such as built-in web directory wordlists, bring-your-own-dictionary options,
    and advanced response filtering. We’ll use it to try to identify additional attack
    vectors and verify that Nikto hasn’t missed anything obvious.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s rescan port 8081 on *p-web-01* (172.16.10.10), which yielded no
    discovered endpoints when scanned by Nikto. The following dirsearch command uses
    the -u (URL) option to specify a base URL from which to start crawling:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Great! This tool was able to pick up two previously unknown endpoints named
    */upload* and */uploads*. This is why it’s important to double- and triple-check
    your results by using more than one tool and to manually verify the findings;
    tools sometimes produce false positives or use limited path-list databases. If
    you navigate to the */upload* page, you should see a file-upload form. Take note
    of this endpoint because we’ll test it in [Chapter 6](chapter6.xhtml).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s also use dirsearch to look for attack vectors in what looked like an
    empty folder on *p-ftp-01*, at *http://172.16.10.11/backup/acme-impact-alliance*:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: dirsearch inspects responses returned from the web server to identify interesting
    behaviors that could indicate the existence of an asset. For example, the tool
    might note whether a certain URL redirects to a new location (specified by an
    HTTP status code 301) and the response size in bytes. Sometimes you can infer
    information and observe behaviors solely by inspecting this data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: This time, we’ve identified a subfolder within the *acme-impact-alliance* folder
    named *.git*. A folder with this name usually indicates the existence of a Git
    repository on the server. *Git* is a source code management tool, and in this
    case, it likely manages code running locally on the remote server.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Use dirsearch again to perform brute forcing against the second directory, */backup/acme-hyper-branding*.
    Save the results into their own folder, then check them. You should find a Git
    repository there too.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Git Repositories
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you find a Git repository, it’s often useful to run a specialized Git cloner
    that pulls the repository and all its associated metadata so you can inspect it
    locally. For this task, we’ll use Gitjacker.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Cloning the Repository
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Gitjacker’s command is pretty simple. The first argument is a URL, and the
    -o (output) argument takes a folder name into which the data will be saved if
    Gitjacker succeeds at pulling the repository:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As you can see, the tool returned a successful status and a few thousand objects.
    At this point, you should have a folder named *acme-impact-alliance-git*:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Notice some familiar filenames in this list? We saw *donate.php* and *robots.txt*
    earlier, when we scanned the 172.16.10.12 (*p-web-02*) host.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Viewing Commits with git log
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you run into a Git repository, you should attempt a git log command to
    see the history of Git code commits made to the repository, as they may include
    interesting data we could use as attackers. In source code management, a *commit*
    is a snapshot of the code’s state that is taken before the code is pushed to the
    main repository and made permanent. Commit information could include details about
    who made the commit and a description of the change (such as whether it was a
    code addition or deletion):'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We’ve identified a person who has committed code to the Git repository: Kevin
    Peterson, at *kpeterson@acme-impact-alliance.com*. Take note of this information
    because this account could exist in other places found during the penetration
    test.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'Try running Gitjacker again to hijack the Git repository that lives on the
    second folder, at */backup/acme-hyper-branding*. Then execute another git log
    command to see who committed code to this repository, as we did before. The log
    should reveal the identity of a second person: Melissa Rogers, at *mrogers@acme-hyper-branding.com*.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 'You may sometimes run into Git repositories with many contributors and many
    commits. We can use Git’s built-in --pretty=format option to easily extract all
    this metadata, like so:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The %ae (author name) and %ae (email) fields are built-in placeholders in Git
    that allow you to specify values of interest to include in the output. For the
    list of all available variables, see *[https://git-scm.com/docs/pretty-formats#_pretty_formats](https://git-scm.com/docs/pretty-formats#_pretty_formats)*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Filtering git log Information
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Even without the pretty formatting, bash can filter git log output with a single
    line:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This bash code runs git log, uses grep to search for any lines that start with
    the word Author, and then pipes the results to another grep command, which uses
    regular expressions (-oP) to filter anything after the word Author: and print
    only the words that matched. This filtering leaves us with the Git commit author’s
    name and email.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Because the same author could have made multiple commits, we use sort to sort
    the list and use the -u option to remove any duplicated lines, leaving us with
    a list free of duplicated entries. Finally, since the email is surrounded by the
    characters <> by default, we trim these characters by using tr -d '<>'.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting Repository Files
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The repository contains a file called *app.py*. Let’s inspect its contents
    by viewing it in a text editor. You should see that the file contains web server
    code written with Python’s Flask library:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The interesting parts here are the endpoints that are exposed via @app.route().
    You can see that the application exposes endpoints such as */*, */files*, */upload*,
    and */uploads*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: When we scanned the target IP address range with dirsearch and Nikto, we saw
    two endpoints, named */upload* and */uploads*, on *p-web-01* (172.16.10.10:8081).
    Because this Python file includes the same endpoints, this source code likely
    belongs to the application running on the server.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'You may be asking yourself why we didn’t find the */files* endpoint in our
    scans. Well, web scanners often rely on response status codes returned by web
    servers to determine whether certain endpoints exist. If you run the following
    curl command with the -I (HEAD request) option, you’ll see that the */files* endpoint
    returns the HTTP status code 404 Not Found:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Web scanners interpret these 404 errors as indicating that an endpoint doesn’t
    exist. Yet the reason we get 404 errors here is that, when called directly, */files*
    doesn’t serve any requests. Instead, it serves requests for web paths appended
    to */files*, such as */files/abc.jpg* or */files/salary.docx*.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerability Scanning with Nuclei
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Nuclei* is one of the most impressive open source vulnerability scanners released
    in recent years. Its advantage over other tools stems from its community-powered
    templating system, which reduces false positives by matching known patterns against
    responses it receives from network services and files. It also reduces barriers
    to writing vulnerability checks, as it doesn’t require learning how to code. You
    can also easily extend it to do custom security checks.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Nuclei naturally supports common network services, such as HTTP, DNS, and network
    sockets, as well as local file scanning. You can use it to send HTTP requests,
    DNS queries, and raw bytes over the network. Nuclei can even scan files to find
    credentials (for example, when you’ve identified an open Git repository and want
    to pull it locally to find secrets).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: As of this writing, Nuclei has more than 8,000 templates in its database. In
    this section, we’ll introduce Nuclei and how to use it.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Templates
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Nuclei templates are based on YAML files with the following high-level structure:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '**ID **A unique identifier for the template'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '**Metadata **Information about the template, such as a description, the author,
    the severity, and tags (arbitrary labels that can group multiple templates, such
    as *injection* or *denial of service*)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '**Protocol **The mechanism that the template uses to make its requests; for
    example, http is a protocol type that uses HTTP for web requests'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '**Operators **Used for matching patterns against responses received by a template
    execution (*matchers*) and extracting data (*extractors*), similarly to the filtering
    performed by tools like grep'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Here is a simple example of a Nuclei template that uses HTTP to find the default
    Apache HTML welcome page. Navigate to *http://172.16.10.11/* to see what this
    page looks like.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We define the template metadata, such as the template’s name, author, severity,
    and so on ❶. We then instruct Nuclei to use an HTTP client when executing this
    template ❷. We also declare that the template should use the GET method. Next,
    we define a variable that will be swapped with the target URL we’ll provide to
    Nuclei on the command line at scan time. Then, we define a single matcher of type
    word ❸ and a search pattern to match against the HTTP response body coming back
    from the server, defined by part: body.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'As a result, when Nuclei performs a scan against an IP address that runs some
    form of a web server, this template will make a GET request to its base URL (/)
    and look for the string Apache2 ubuntu Default Page: It works in the response.
    If it finds this string in the response’s body, the check will be considered successful
    because the pattern matched.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: We encourage you to explore Nuclei’s templating system at *[https://docs.projectdiscovery.io/introduction](https://docs.projectdiscovery.io/introduction)*,
    as you can easily use Nuclei with bash to perform continuous assessments.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Writing a Custom Template
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s write a simple template that finds the Git repositories we discovered
    earlier, on *p-ftp-01* (172.16.10.11). We’ll define multiple BaseURL paths to
    represent the two paths we’ve identified. Then, using Nuclei’s matchers, we’ll
    define a string ref: refs/heads/master to match the response body returned by
    the scanned server:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: git-finder.yaml
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This template works just like the one in the previous example, except this
    time we provide two paths to check against: */backup/acme-hyper-branding/.git/HEAD*
    and */backup/acme-impact-alliance/.git/HEAD*. The matcher defines the string we
    expect to see in the *HEAD* file. You can confirm the match by making a curl request
    to the Git repository at 172.16.10.11:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Download this custom Nuclei template from the book’s GitHub repository.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Applying the Template
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s run Nuclei against *p-ftp-01* (172.16.10.11) with the custom template
    we just wrote. Nuclei stores its built-in templates in the folder *~/.local/nuclei-templates*.
    First, run the following command to update Nuclei’s template database:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Next, save the custom template into the folder *~/.local/nuclei-templates/custom*
    and give it a name such as *git-finder.yaml*.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following command, the -u (URL) option specifies the address, and -t
    (template) specifies the path to the template:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you can see, we were able to identify the two Git repositories with the custom
    template.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Running a Full Scan
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When not provided with a specific template, Nuclei will use its built-in templates
    during the scan. Running Nuclei is noisy, so we recommend tailoring the execution
    to a specific target. For instance, if you know a server is running Apache, you
    could select just the Apache-related templates by specifying the -tags option:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Run nuclei -tl to get a list of all available templates.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s run a full Nuclei scan against the three IP addresses in the 172.16.10.0/24
    network by using all its built-in templates:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Nuclei tries to optimize the number of total requests made by using *clustering*.
    When multiple templates call the same web path (such as */backup*), Nuclei consolidates
    these into a single request to reduce network overhead. However, Nuclei could
    still send thousands of requests during a single scan. You can control the number
    of requests sent by specifying the rate limit option (-rl), followed by an integer
    indicating the number of allowed requests per second.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'The full scan results in a lot of findings, so append the output to a file
    (using >>) so that you can examine them one by one. As you’ll see, Nuclei can
    identify vulnerabilities, but it can also fingerprint the target server and the
    technologies running on it. Nuclei should have highlighted findings seen previously,
    as well as a few new ones. Here are some of the issues it detected:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: An FTP server with anonymous access enabled on 172.16.10.11 port 21
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A WordPress login page at *172.16.10.12/wp-login.php*
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A WordPress user-enumeration vulnerability (CVE-2017-5487) at *[http://172.16.10.12/?rest_route=/wp/v2/users/](http://172.16.10.12/?rest_route=/wp/v2/users/)*
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s manually confirm these three findings to ensure there are no false positives.
    Connect to the identified FTP server at 172.16.10.11 by issuing the following
    ftp command. This command will connect to the server by using the *anonymous*
    user and an empty password:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We were able to connect! Let’s issue an ls command to verify that we can list
    files and directories on the server:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We see an *index.html* file and a *backup* folder. This is the same folder that
    stores the two Git repositories we saw earlier, except now we have access to the
    FTP server where these files actually live.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Next, open a browser to *http://172.16.10.12/wp-login.php* from your Kali machine.
    You should see the page in [Figure 5-2](chapter5.xhtml#fig5-2).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/pg109.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-2: The WordPress login page'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, verify the third finding: the WordPress user-enumeration vulnerability,
    which allows you to gather information about WordPress accounts. By default, every
    WordPress instance exposes an API endpoint that lists WordPress system users.
    The endpoint usually doesn’t require authentication or authorization, so a simple
    GET request should return the list of users.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use curl to send this request and then pipe the response to jq to prettify
    the JSON output that comes back. The result should be an array of user data:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The blog has a single user, *jtorres*. This can be a good target to brute-force
    later. If this curl command had returned many users, you could have parsed only
    the usernames with jq ([Listing 5-3](chapter5.xhtml#Lis5-3)).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Listing 5-3: Extracting usernames from an HTTP response'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: All three findings were true positives, which is great news for us. [Table 5-1](chapter5.xhtml#tab5-1)
    recaps the users we’ve identified so far.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5-1: Identity Information Gathered from Repositories and WordPress'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '| Source | Name | Email |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
- en: '| acme-impact-alliance Git repository | Kevin Peterson | kpeterson@acme-impact-alliance.com
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
- en: '| acme-hyper-branding Git repository | Melissa Rogers | mrogers@acme-hyper-branding.com
    |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
- en: '| WordPress account | J. Torres | jtorres@acme-impact-alliance.com |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
- en: Because the *jtorres* account was found on the ACME Impact Alliance website
    and we already know the email scheme the website uses, it’s pretty safe to assume
    that the *jtorres* email is *jtorres@acme-impact-alliance.com*.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 6: Parsing Nuclei’s Findings'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: 'Nuclei’s scan output is a little noisy and can be difficult to parse with bash,
    but not impossible. Nuclei allows you to pass a -silent parameter to show only
    the findings in the output. Before you write a script to parse it, consider Nuclei’s
    output format:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[template] [protocol] [severity] url [extractor]'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Each field is enclosed in square brackets [] and separated by spaces. The template
    field is a template name (taken from the name of the template file); the protocol
    shows the protocol, such as HTTP; and the severity shows the severity of the finding
    (informational, low, medium, high, or critical). The fourth field is the URL or
    IP address, and the fifth field is metadata extracted by the template’s logic
    using extractors.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Now you should be able to parse this information with bash. [Listing 5-4](chapter5.xhtml#Lis5-4)
    shows an example script that runs Nuclei, filters for a specific severity of interest,
    parses the interesting parts, and emails you the results.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: nuclei-notifier.sh
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Listing 5-4: Scanning with Nuclei and sending yourself the results'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dissect the code to better understand what it’s doing. We use a for loop
    to iterate through values in the $@ variable, a special value you learned about
    in [Chapter 1](chapter1.xhtml) that contains the arguments passed to the script
    on the command line. We assign each argument to the ip_address variable.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Next, we run a Nuclei scan, passing it the -severity argument to scan for vulnerabilities
    categorized as either medium, high, or critical, and save the output to the result
    variable ❶. At ❷, we read the output passed to the while loop at ❹ line by line.
    From each line, we extract the first field, using the tr -d '[]' command to remove
    the [] characters for a cleaner output. We also extract the fourth field from
    each line, which is where Nuclei stores the vulnerable URL. At ❸, we send an email
    containing the relevant information.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'To run this script, save it to a file and pass the IP addresses to scan on
    the command line:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: To make this script your own, try having Nuclei output JSON data by using the
    -j option. Then pipe this output to jq, as shown in [Chapter 4](chapter4.xhtml).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzing for Hidden Files
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we’ve identified the potential location of files, let’s use fuzzing
    tools to find hidden files on *p-web-01* (*http://172.16.10.10:8081/files*). *Fuzzers*
    generate semi-random data to use as part of a payload. When sent to an application,
    these payloads can trigger anomalous behavior or reveal covert information. You
    can use fuzzers against web servers to find hidden paths or against local binaries
    to find vulnerabilities such as buffer overflows or DoS.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Wordlist of Possible Filenames
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Fuzzing tools in the context of web application enumeration work best when fed
    custom wordlists tailored to your target. These lists could contain the name of
    the company, the individuals you’ve identified, relevant locations, and so on.
    These tailored wordlists can help you identify user accounts to attack, network
    and application services, valid domain names, covert files, email addresses, and
    web paths, for example.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use bash to write a custom wordlist containing potential filenames of
    interest ([Listing 5-5](chapter5.xhtml#Lis5-5)).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Listing 5-5: Using brace expansion to create multiple files with various extensions'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: This command creates files with probable file extensions tailored to our target’s
    name, ACME Hyper Branding. It uses echo with brace expansion {0..100} to create
    arbitrary strings ranging from 0 to 100 and then appends these to the company
    name. We also use brace expansion to create multiple file extension types, such
    as *.txt*, *.csv*, *.pdf*, and *.jpg*. The -e option, for echo, enables us to
    interpret backslash (\) escapes. This means that \n will be interpreted as a newline.
    We then pipe this output to the sed command to remove all whitespace from the
    output for a cleaner list.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: 'Use head to view the created files:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As you can see, this command’s output follows the format *acme-hyper-branding-<some_number>.<some_extension>*.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzing with ffuf
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*ffuf* (an acronym for *Fuzz Faster U Fool*) is a versatile and blazing-fast
    web fuzzing tool. We’ll use ffuf to discover potential files under the */files*
    endpoint that could contain interesting data.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'The following ffuf command uses the -c (color) option to highlight the results
    in the terminal, the -w (wordlist) option to specify a custom wordlist, the -u
    (URL) option to specify a path, and the full URL to the endpoint to fuzz. We run
    ffuf against *p-web-01* (172.16.10.10):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Note that the word FUZZ at the end of the URL is a placeholder that tells the
    tool where to inject the words from the wordlist. In essence, it will swap the
    word FUZZ with each line from our file.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: According to the output, ffuf identified that the path *http://172.16.10.10:8081/files/acme-hyper-branding-5.csv*
    returned a status code of HTTP 200 OK. If you look closely at the output, you
    should see that the fuzzer sent 405 requests in less than a second, which is pretty
    impressive.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzing with Wfuzz
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Wfuzz* is another web fuzzing tool similar to ffuf. In fact, ffuf is based
    on Wfuzz. Let’s use Wfuzz to perform the same type of wordlist-based scan (-w)
    and then use its filtering capabilities to show only files that receive a response
    status code of 200 OK (--sc 200):'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, let’s use the wget command to download the identified file:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We’ve located a table of PII, including first and last names, titles, and email
    addresses. Take notes of every detail we’ve managed to extract in this chapter;
    you never know when it will come in handy.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Note that fuzzers can cause unintentional DoS conditions, especially if they’re
    optimized for speed. You may encounter applications running on low-powered servers
    that will crash if you run a highly capable fuzzer against them, so make sure
    you have explicit permission from the company you’re working with to perform such
    activities.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Assessing SSH Servers with Nmap’s Scripting Engine
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Nmap contains many NSE scripts to test for vulnerabilities and misconfigurations.
    All Nmap scripts live in the */usr/share/nmap/scripts* path. When you run Nmap
    with the -A flag, it will blast all NSE scripts at the target, as well as enable
    operating system detection, version detection, script scanning, and traceroute.
    This is probably the noisiest scan you can do with Nmap, so never use it when
    you need to be covert.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Chapter 4](chapter4.xhtml), we identified a server running OpenSSH on *p-jumpbox-01*
    (172.16.10.13). Let’s use an NSE script tailored to SSH servers to see what we
    can discover about the supported authentication methods:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The *ssh-auth-methods* NSE script enumerates the authentication methods offered
    by the SSH server. If *password* is one of them, this means that the server accepts
    passwords as an authentication mechanism. SSH servers that allow password authentication
    are prone to brute-force attacks. In [Chapter 7](chapter7.xhtml), we’ll perform
    a brute-force attack against SSH servers.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7: Combining Tools to Find FTP Issues'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: The goal of this exercise is to write a script that calls several security tools,
    parses their output, and passes the output to other tools to act on it. Orchestrating
    multiple tools in this way is a common task in penetration testing, so we encourage
    you to get comfortable with building such workflows.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'Your script should do the following:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 1.  Accept one or more IP addresses on the command line.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 2.  Run a port scanner against the IP addresses; which port scanner you use
    is completely up to you.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 3.  Identify open ports. If any of them are FTP ports (21/TCP), the script should
    pass the address to the vulnerability scanner in step 4.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: 4.  Use Nuclei to scan the IP addresses and ports. Try applying templates dedicated
    to finding issues in FTP servers. Search the Nuclei templates folder */home/kali/.local/nuclei-templates*
    for FTP-related templates, or use the -tags ftp Nuclei flag.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: 5.  Scan the IP addresses with Nmap. Use NSE scripts that find vulnerabilities
    in FTP servers, which you can search for in the */usr/share/nmap/scripts* folder.
    For example, try *ftp-anon.nse*.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: 6.  Parse and write the results to a file, in a format of your choice. The file
    should include a description of the vulnerability, the relevant IP address and
    port, the timestamp at which it was found, and the name of the tool that detected
    the issue. There is no hard requirement about how to present the data; one option
    is to use an HTML table. If you need an example table, download *vulnerability_table.html*
    from the book’s GitHub repository and open it in a browser. Alternatively, you
    could write the results to a CSV file.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: As you should know by now, there is more than one way to write such a script.
    Only the end result matters, so craft the script as you see fit.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we wrapped up reconnaissance activities by performing vulnerability
    scanning and fuzzing. We also verified the vulnerabilities we discovered, weeding
    out potential false positives.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Along the way, we used bash scripting to perform several tasks. We scanned for
    vulnerabilities, wrote custom scripts that can perform recursive downloads from
    misconfigured web servers, extracted sensitive information from Git repositories,
    and more. We also created custom wordlists using clever bash scripting and orchestrated
    the execution of multiple security tools to generate a report.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s recap what we’ve identified so far, from a reconnaissance perspective:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Hosts running multiple services (HTTP, FTP, and SSH) and their versions
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A web server running WordPress with a login page enabled and a few vulnerabilities,
    such as user enumeration and an absence of HTTP security headers
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A web server with a revealing *robots.txt* file containing paths to custom upload
    forms and a donation page
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An anonymous, login-enabled FTP server
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple open Git repositories
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenSSH servers that allow password-based logins
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we’ll use the information identified in this chapter to
    establish an initial foothold by exploiting vulnerabilities and taking over servers.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
