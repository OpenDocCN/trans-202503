- en: '**18'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: WHEN DATA DOESN’T CONVINCE YOU**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the previous chapter, we used Bayesian reasoning to reason about two hypotheses
    from an episode of *The Twilight Zone*:'
  prefs: []
  type: TYPE_NORMAL
- en: '***H*** The fortune-telling Mystic Seer is supernatural.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Image](../images/h-bar.jpg) The fortune-telling Mystic Seer isn’t supernatural,
    just lucky.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also learned how to account for skepticism by changing the prior odds ratio.
    For example, if you, like me, believe that the Mystic Seer definitely isn’t psychic,
    then you might want to set the prior odds extremely low—something like 1/1,000,000.
  prefs: []
  type: TYPE_NORMAL
- en: However, depending on your level of personal skepticism, you might feel that
    even a 1/1,000,000 odds ratio wouldn’t be quite enough to convince you of the
    seer’s power.
  prefs: []
  type: TYPE_NORMAL
- en: Maybe even after receiving 1,000 correct answers from the seer—which, despite
    your very skeptical prior odds, would suggest you were astronomically in favor
    of believing the seer is psychic—you still wouldn’t buy into its supernatural
    powers. We could represent this by simply making our prior odds even more extreme,
    but I personally don’t find this solution very satisfying because no amount of
    data would convince me that the Mystic Seer is, in fact, psychic.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll take a deeper look at problems where the data doesn’t
    convince people in the way we expect it to. In the real world, these situations
    are fairly common. Anyone who has argued with a relative over a holiday dinner
    has likely noticed that oftentimes the more contradictory evidence you give, the
    more they seem to be convinced of their preexisting belief! In order to fully
    understand Bayesian reasoning, we need to be able to understand, mathematically,
    why situations like these arise. This will help us identify and avoid them in
    our statistical analysis.
  prefs: []
  type: TYPE_NORMAL
- en: '**A Psychic Friend Rolling Dice**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Suppose your friend tells you they can predict the outcome of a six-sided die
    roll with 90 percent accuracy because they are psychic. You find this claim difficult
    to believe, so you set up a hypothesis test using the Bayes factor. As in the
    Mystic Seer example, you have two hypotheses you want to compare:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0176-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The first hypothesis, *H*[1], represents your belief that the die is fair, and
    that your friend is not psychic. If the die is fair, there is a 1 in 6 chance
    of guessing the result correctly. The second hypothesis, *H*[2], represents your
    friend’s belief that they can, in fact, predict the outcome of a die roll 90 percent
    of the time and is therefore given a 9/10 ratio. Next we need some data to start
    testing their claim. Your friend rolls the die 10 times and correctly guesses
    the outcome of the roll 9 times.
  prefs: []
  type: TYPE_NORMAL
- en: '***Comparing Likelihoods***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As we often have in previous chapters, we’ll start by looking at the Bayes
    factor, assuming for now that the prior odds for each hypothesis are equal. We’ll
    formulate our likelihood ratio as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0176-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'so that our results will tell us how many times better (or worse) your friend’s
    claim of being psychic explains the data than your hypothesis does. For this example,
    we’ll use the variable *BF* for “Bayes factor” in our equations for brevity. Here
    is our result, taking into account the fact that your friend correctly predicted
    9 out of 10 rolls:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0177-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Our likelihood ratio shows that the friend-being-psychic hypothesis explains
    the data 468,517 times better than the hypothesis that your friend is just lucky.
    This is a bit concerning. According to the Bayes factor chart we saw in earlier
    chapters, this means we should be nearly certain that *H*[2] is true and your
    friend is psychic. Unless you’re already a deep believer in the possibility of
    psychic powers, something seems very wrong here.
  prefs: []
  type: TYPE_NORMAL
- en: '***Incorporating Prior Odds***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In most cases in this book where the likelihood alone gives us strange results,
    we can solve the problem by including our prior probabilities. Clearly, we don’t
    believe in our friend’s hypothesis nearly as strongly as we believe in our own,
    so it makes sense to create a strong prior odds in favor of our hypothesis. We
    can start by simply setting our odds ratio high enough that it cancels out the
    extreme result of the Bayes factor, and see if this fixes our problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0177-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, when we work out our full posterior odds, we find that we are, once again,
    unconvinced that your friend is psychic:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0177-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For now, it looks like prior odds have once again saved us from a problem that
    occurred when we looked only at the Bayes factor.
  prefs: []
  type: TYPE_NORMAL
- en: 'But suppose your friend rolls the die five more times and successfully predicts
    all five outcomes. Now we have a new set of data, *D*[15], which represents 15
    rolls of a die, 14 of which your friend guessed accurately. Now when we calculate
    our posterior odds, we see that even our extreme prior is of little help:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0177-04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Using our existing prior, with just five more rolls of the die, we have posterior
    odds of 4,592—which means we’re back to being nearly certain that your friend
    is truly psychic!
  prefs: []
  type: TYPE_NORMAL
- en: In most of our previous problems, we’ve corrected nonintuitive posterior results
    by adding a sane prior. We’ve added a pretty extreme prior against your friend
    being psychic, but our posterior odds are still strongly in favor of the hypothesis
    that they’re psychic.
  prefs: []
  type: TYPE_NORMAL
- en: This is a major problem, because Bayesian reasoning should align with our everyday
    sense of logic. Clearly, 15 rolls of a die with 14 successful guesses is highly
    unusual, but it’s unlikely to convince many people that the guesser truly possesses
    psychic powers! However, if we can’t explain what’s going on here with our hypothesis
    test, it means that we really can’t rely on our test to solve our everyday statistical
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: '***Considering Alternative Hypotheses***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The issue here is that we *don’t want to believe your friend is psychic*. If
    you found yourself in this situation in real life, it’s likely you would quickly
    come to some alternative conclusion. You might come to believe that your friend
    is using a loaded die that rolls a certain value about 90 percent of the time,
    for example. This represents a *third* hypothesis. Our Bayes factor is looking
    at only two possible hypotheses: *H*[1], the hypothesis that the die is fair,
    and *H*[2], the hypothesis that your friend is psychic.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our Bayes factor so far tells us that it’s far more likely that our friend
    is psychic than that they are guessing the rolls of a fair die correctly. When
    we think of the conclusion in those terms, it makes more sense: with these results,
    it’s extremely unlikely that the die is fair. We don’t feel comfortable accepting
    the *H*[2] alternative, because our own beliefs about the world don’t support
    the idea that *H*[2] is a realistic explanation.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to understand that a hypothesis test compares only two explanations
    for an event, but very often there are countless possible explanations. If the
    winning hypothesis doesn’t convince you, you could always consider a third one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at what happens when we compare *H*[2], our winning hypothesis,
    with a new hypothesis, *H*[3]: that the die is rigged so it has a certain outcome
    90 percent of the time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start with a new prior odds about *H*[2], which we’ll call *O*(*H*[2])′
    (the tick mark is a common notation in mathematics meaning “like but not the same
    as”). This will represent the odds of *H*[2]/*H*[3]. For now, we’ll just say that
    we believe it’s 1,000 times more likely that your friend is using a loaded die
    than that your friend is really psychic (though our real prior might be much more
    extreme). That means the prior odds of your friend being psychic is 1/1,000\.
    If we reexamine our new posterior odds, we get the following interesting result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0178-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: According to this calculation, our posterior odds are the same as our prior
    odds, *O*(*H*[2])′. This happens because our two likelihoods are the same. In
    other words, *P*(*D*[15] | *H*[2]) = *P*(*D*[15] | *H*[3]). For both hypotheses,
    the likelihood of your friend correctly guessing the outcome of the die roll is
    exactly the same for the loaded die because the probability each assigns to success
    is the same. This means that our Bayes factor will always be 1.
  prefs: []
  type: TYPE_NORMAL
- en: These results correspond quite well to our everyday intuition; after all, prior
    odds aside, each hypothesis explains the data we’ve seen equally well. That means
    that if, before considering the data, we believe one explanation is far more likely
    than the other, then no amount of new evidence will change our minds. So we no
    longer have a problem with the data we observed; we’ve simply found a better explanation
    for it.
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, no amount of data will change our mind about believing *H*[3]
    over *H*[2] because both explain what we’ve observed equally well, and we already
    think that *H*[3] is a far more likely explanation than *H*[2]. What’s interesting
    here is that we can find ourselves in this situation even if our prior beliefs
    are entirely irrational. Maybe you’re a strong believer in psychic phenomena and
    think that your friend is the most honest person on earth. In this case, you might
    make the prior odds *O*(*H*[2])′ = 1,000\. If you believed this, no amount of
    data could convince you that your friend is using a loaded die.
  prefs: []
  type: TYPE_NORMAL
- en: In cases like this, it’s important to realize that if you want to solve a problem,
    you need to be willing to change your prior beliefs. If you’re unwilling to let
    go of unjustifiable prior beliefs, then, at the very least, you must acknowledge
    that you’re no longer reasoning in a Bayesian—or logical—way at all. We all hold
    irrational beliefs, and that’s perfectly okay, so long as we don’t attempt to
    use Bayesian reasoning to justify them.
  prefs: []
  type: TYPE_NORMAL
- en: '**Arguing with Relatives and Conspiracy Theorists**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Anyone who has argued with relatives over a holiday dinner about politics, climate
    change, or their favorite movies has experienced firsthand a situation in which
    they are comparing two hypotheses that both explain the data equally well (to
    the person arguing), and only the prior remains. How can we change someone else’s
    (or our own) beliefs even when more data doesn’t change anything?
  prefs: []
  type: TYPE_NORMAL
- en: We’ve already seen that if you compare the belief that your friend has a loaded
    die and the belief that they are psychic, more data will do nothing to change
    your beliefs about your friend’s claim. This is because both your hypothesis and
    your friend’s hypothesis explain the data equally well. In order for your friend
    to convince you that they are psychic, they have to alter your prior beliefs.
    For example, since you’re suspicious that the die might be loaded, your friend
    could then offer to let you choose the die they roll. If you bought a new die
    and gave it to your friend, and they continued to accurately predict their rolls,
    you might start to be convinced. This same logic holds anytime you run into a
    problem where two hypotheses equally explain the data. In these cases, you must
    then see if there’s anything you can change in your prior.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose after you purchase the new die for your friend and they continue to
    succeed, you *still* don’t believe them; you now claim that they must have a secret
    way of rolling. In response, your friend lets you roll the die for them, and they
    continue to successfully predict the rolls—yet you *still* don’t believe them.
    In this scenario, something else is happening beyond just a hidden hypothesis.
    You now have an *H*[4]—that your friend is completely cheating—and you won’t change
    your mind. This means that for any *D[n]*, *P*(*D[n]* | *H*[4]) = 1\. Clearly
    we’re out of Bayesian territory since you’ve essentially conceded that you won’t
    change your mind, but let’s see what happens mathematically if your friend persists
    in trying to convince you.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at how these two explanations, *H*[2] and *H*[4], compete using
    our data *D*[10] with 9 correct predictions and 1 missed prediction. The Bayes
    factor for this is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0180-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Because you refuse to believe anything other than that your friend is cheating,
    the probability of what you observe is, and will always be, 1\. Even though the
    data is exactly as we would expect in the case of your friend being psychic, we
    find our beliefs explain the data 26 times as well. Your friend, deeply determined
    to change your stubborn mind, persists and rolls 100 times, getting 90 guesses
    right and 10 wrong. Our Bayes factor shows something very strange that happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0180-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Even though the data seems to strongly support your friend’s hypothesis, because
    you refuse to budge in your beliefs, you’re now even more wildly convinced that
    you’re right! When we don’t allow our minds to be changed at all, more data only
    further convinces us we are correct.
  prefs: []
  type: TYPE_NORMAL
- en: This pattern may seem familiar to anyone who has argued with a politically radical
    relative or someone who adamantly believes in a conspiracy theory. In Bayesian
    reasoning, it is vital that our beliefs are at least falsifiable. In traditional
    science, *falsifiability* means that something can be disproved, but in our case
    it just means there has to be some way to reduce our belief in a hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: The danger of nonfalsifiable beliefs in Bayesian reasoning isn’t just that they
    can’t be proved wrong—it’s that they are strengthened even by evidence that seems
    to contradict them. Rather than persisting in trying to convince you, your friend
    should have first asked, “What can I show you that would change your mind?” If
    your reply had been that *nothing* could change your mind, then your friend would
    be better off not presenting you with more evidence.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the next time you argue with a relative over politics or conspiracy theories,
    you should ask them: “What evidence would change your mind?” If they have no answer
    to this, you’re better off not trying to defend your views with more evidence,
    as it will only increase your relative’s certainty in their belief.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Wrapping Up**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, you learned about a few ways hypothesis tests can go wrong.
    Although the Bayes factor is a competition between two ideas, it’s quite possible
    that there are other, equally valid, hypotheses worth testing out.
  prefs: []
  type: TYPE_NORMAL
- en: Other times, we find that two hypotheses explain the data equally well; you’re
    just as likely to see your friend’s correct predictions if they were caused by
    your friend’s psychic ability or a trick in the die. When this is the case, only
    the prior odds ratio for each hypothesis matters. This also means that acquiring
    more data in those situations will never change our beliefs, because it will never
    give either hypothesis an edge over the other. In these cases, it’s best to consider
    how you can alter the prior beliefs that are affecting the results.
  prefs: []
  type: TYPE_NORMAL
- en: In more extreme cases, we might have a hypothesis that simply refuses to be
    changed. This is like having a conspiracy theory about the data. When this is
    the case, not only will more data never convince us to change our beliefs, but
    it will actually have the opposite effect. If a hypothesis is not falsifiable,
    more data will only serve to make us more certain of the conspiracy.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Try answering the following questions to see how well you understand how to
    deal with extreme cases in Bayesian reasoning. The solutions can be found at *[https://nostarch.com/learnbayes/](https://nostarch.com/learnbayes/)*.
  prefs: []
  type: TYPE_NORMAL
- en: When two hypotheses explain the data equally well, one way to change our minds
    is to see if we can attack the prior probability. What are some factors that might
    increase your prior belief in your friend’s psychic powers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An experiment claims that when people hear the word *Florida*, they think of
    the elderly and this has an impact on their walking speed. To test this, we have
    two groups of 15 students walk across a room; one group hears the word *Florida*
    and one does not. Assume *H*[1] = the groups don’t move at different speeds, and
    *H*[2] = the Florida group is slower because of hearing the word *Florida*. Also
    assume:![Image](../images/f0181-01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The experiment shows that *H*[2] has a Bayes factor of 19\. Suppose someone
    is unconvinced by this experiment because *H*[2] had a lower prior odds. What
    prior odds would explain someone being unconvinced and what would the BF need
    to be to bring the posterior odds to 50 for this unconvinced person?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now suppose the prior odds do not change the skeptic’s mind. Think of an alternate
    *H*[3] that explains the observation that the Florida group is slower. Remember
    if *H*[2] and *H*[3] both explain the data equally well, only prior odds in favor
    of *H*[3] would lead someone to claim *H*[3] is true over *H*[2], so we need to
    rethink the experiment so that these odds are decreased. Come up with an experiment
    that could change the prior odds in *H*[3] over *H*[2].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
