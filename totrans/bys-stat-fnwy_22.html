<html><head></head><body>
<h2 class="h2" id="ch18"><span epub:type="pagebreak" id="page_175"/><strong><span class="big">18</span><br/>WHEN DATA DOESN’T CONVINCE YOU</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">In the previous chapter, we used Bayesian reasoning to reason about two hypotheses from an episode of <em>The Twilight Zone</em>:</p>&#13;
<ul>&#13;
<li class="noindent"><em><strong>H</strong></em> The fortune-telling Mystic Seer is supernatural.</li>&#13;
<li class="noindent"><img alt="Image" class="middle" src="../images/h-bar.jpg"/> The fortune-telling Mystic Seer isn’t supernatural, just lucky.</li>&#13;
</ul>&#13;
<p class="indent">We also learned how to account for skepticism by changing the prior odds ratio. For example, if you, like me, believe that the Mystic Seer definitely isn’t psychic, then you might want to set the prior odds extremely low—something like 1/1,000,000.</p>&#13;
<p class="indent">However, depending on your level of personal skepticism, you might feel that even a 1/1,000,000 odds ratio wouldn’t be quite enough to convince you of the seer’s power.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_176"/>Maybe even after receiving 1,000 correct answers from the seer—which, despite your very skeptical prior odds, would suggest you were astronomically in favor of believing the seer is psychic—you still wouldn’t buy into its supernatural powers. We could represent this by simply making our prior odds even more extreme, but I personally don’t find this solution very satisfying because no amount of data would convince me that the Mystic Seer is, in fact, psychic.</p>&#13;
<p class="indent">In this chapter, we’ll take a deeper look at problems where the data doesn’t convince people in the way we expect it to. In the real world, these situations are fairly common. Anyone who has argued with a relative over a holiday dinner has likely noticed that oftentimes the more contradictory evidence you give, the more they seem to be convinced of their preexisting belief! In order to fully understand Bayesian reasoning, we need to be able to understand, mathematically, why situations like these arise. This will help us identify and avoid them in our statistical analysis.</p>&#13;
<h3 class="h3" id="ch18lev1sec1"><strong>A Psychic Friend Rolling Dice</strong></h3>&#13;
<p class="noindent">Suppose your friend tells you they can predict the outcome of a six-sided die roll with 90 percent accuracy because they are psychic. You find this claim difficult to believe, so you set up a hypothesis test using the Bayes factor. As in the Mystic Seer example, you have two hypotheses you want to compare:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0176-01.jpg"/></div>&#13;
<p class="indent">The first hypothesis, <em>H</em><sub>1</sub>, represents your belief that the die is fair, and that your friend is not psychic. If the die is fair, there is a 1 in 6 chance of guessing the result correctly. The second hypothesis, <em>H</em><sub>2</sub>, represents your friend’s belief that they can, in fact, predict the outcome of a die roll 90 percent of the time and is therefore given a 9/10 ratio. Next we need some data to start testing their claim. Your friend rolls the die 10 times and correctly guesses the outcome of the roll 9 times.</p>&#13;
<h4 class="h4" id="ch18lev2sec1"><strong><em>Comparing Likelihoods</em></strong></h4>&#13;
<p class="noindent">As we often have in previous chapters, we’ll start by looking at the Bayes factor, assuming for now that the prior odds for each hypothesis are equal. We’ll formulate our likelihood ratio as:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0176-02.jpg"/></div>&#13;
<p class="noindent">so that our results will tell us how many times better (or worse) your friend’s claim of being psychic explains the data than your hypothesis does. For this example, we’ll use the variable <em>BF</em> for “Bayes factor” in our equations for brevity. Here is our result, taking into account the fact that your friend correctly predicted 9 out of 10 rolls:</p>&#13;
<div class="equ-image"><span epub:type="pagebreak" id="page_177"/><img alt="Image" src="../images/f0177-01.jpg"/></div>&#13;
<p class="indent">Our likelihood ratio shows that the friend-being-psychic hypothesis explains the data 468,517 times better than the hypothesis that your friend is just lucky. This is a bit concerning. According to the Bayes factor chart we saw in earlier chapters, this means we should be nearly certain that <em>H</em><sub>2</sub> is true and your friend is psychic. Unless you’re already a deep believer in the possibility of psychic powers, something seems very wrong here.</p>&#13;
<h4 class="h4" id="ch18lev2sec2"><strong><em>Incorporating Prior Odds</em></strong></h4>&#13;
<p class="noindent">In most cases in this book where the likelihood alone gives us strange results, we can solve the problem by including our prior probabilities. Clearly, we don’t believe in our friend’s hypothesis nearly as strongly as we believe in our own, so it makes sense to create a strong prior odds in favor of our hypothesis. We can start by simply setting our odds ratio high enough that it cancels out the extreme result of the Bayes factor, and see if this fixes our problem:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0177-02.jpg"/></div>&#13;
<p class="indent">Now, when we work out our full posterior odds, we find that we are, once again, unconvinced that your friend is psychic:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0177-03.jpg"/></div>&#13;
<p class="indent">For now, it looks like prior odds have once again saved us from a problem that occurred when we looked only at the Bayes factor.</p>&#13;
<p class="indent">But suppose your friend rolls the die five more times and successfully predicts all five outcomes. Now we have a new set of data, <em>D</em><sub>15</sub>, which represents 15 rolls of a die, 14 of which your friend guessed accurately. Now when we calculate our posterior odds, we see that even our extreme prior is of little help:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0177-04.jpg"/></div>&#13;
<p class="indent">Using our existing prior, with just five more rolls of the die, we have posterior odds of 4,592—which means we’re back to being nearly certain that your friend is truly psychic!</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_178"/>In most of our previous problems, we’ve corrected nonintuitive posterior results by adding a sane prior. We’ve added a pretty extreme prior against your friend being psychic, but our posterior odds are still strongly in favor of the hypothesis that they’re psychic.</p>&#13;
<p class="indent">This is a major problem, because Bayesian reasoning should align with our everyday sense of logic. Clearly, 15 rolls of a die with 14 successful guesses is highly unusual, but it’s unlikely to convince many people that the guesser truly possesses psychic powers! However, if we can’t explain what’s going on here with our hypothesis test, it means that we really can’t rely on our test to solve our everyday statistical problems.</p>&#13;
<h4 class="h4" id="ch18lev2sec3"><strong><em>Considering Alternative Hypotheses</em></strong></h4>&#13;
<p class="noindent">The issue here is that we <em>don’t want to believe your friend is psychic</em>. If you found yourself in this situation in real life, it’s likely you would quickly come to some alternative conclusion. You might come to believe that your friend is using a loaded die that rolls a certain value about 90 percent of the time, for example. This represents a <em>third</em> hypothesis. Our Bayes factor is looking at only two possible hypotheses: <em>H</em><sub>1</sub>, the hypothesis that the die is fair, and <em>H</em><sub>2</sub>, the hypothesis that your friend is psychic.</p>&#13;
<p class="indent">Our Bayes factor so far tells us that it’s far more likely that our friend is psychic than that they are guessing the rolls of a fair die correctly. When we think of the conclusion in those terms, it makes more sense: with these results, it’s extremely unlikely that the die is fair. We don’t feel comfortable accepting the <em>H</em><sub>2</sub> alternative, because our own beliefs about the world don’t support the idea that <em>H</em><sub>2</sub> is a realistic explanation.</p>&#13;
<p class="indent">It’s important to understand that a hypothesis test compares only two explanations for an event, but very often there are countless possible explanations. If the winning hypothesis doesn’t convince you, you could always consider a third one.</p>&#13;
<p class="indent">Let’s look at what happens when we compare <em>H</em><sub>2</sub>, our winning hypothesis, with a new hypothesis, <em>H</em><sub>3</sub>: that the die is rigged so it has a certain outcome 90 percent of the time.</p>&#13;
<p class="indent">We’ll start with a new prior odds about <em>H</em><sub>2</sub>, which we’ll call <em>O</em>(<em>H</em><sub>2</sub>)′ (the tick mark is a common notation in mathematics meaning “like but not the same as”). This will represent the odds of <em>H</em><sub>2</sub>/<em>H</em><sub>3</sub>. For now, we’ll just say that we believe it’s 1,000 times more likely that your friend is using a loaded die than that your friend is really psychic (though our real prior might be much more extreme). That means the prior odds of your friend being psychic is 1/1,000. If we reexamine our new posterior odds, we get the following interesting result:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0178-01.jpg"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_179"/>According to this calculation, our posterior odds are the same as our prior odds, <em>O</em>(<em>H</em><sub>2</sub>)′. This happens because our two likelihoods are the same. In other words, <em>P</em>(<em>D</em><sub>15</sub> | <em>H</em><sub>2</sub>) = <em>P</em>(<em>D</em><sub>15</sub> | <em>H</em><sub>3</sub>). For both hypotheses, the likelihood of your friend correctly guessing the outcome of the die roll is exactly the same for the loaded die because the probability each assigns to success is the same. This means that our Bayes factor will always be 1.</p>&#13;
<p class="indent">These results correspond quite well to our everyday intuition; after all, prior odds aside, each hypothesis explains the data we’ve seen equally well. That means that if, before considering the data, we believe one explanation is far more likely than the other, then no amount of new evidence will change our minds. So we no longer have a problem with the data we observed; we’ve simply found a better explanation for it.</p>&#13;
<p class="indent">In this scenario, no amount of data will change our mind about believing <em>H</em><sub>3</sub> over <em>H</em><sub>2</sub> because both explain what we’ve observed equally well, and we already think that <em>H</em><sub>3</sub> is a far more likely explanation than <em>H</em><sub>2</sub>. What’s interesting here is that we can find ourselves in this situation even if our prior beliefs are entirely irrational. Maybe you’re a strong believer in psychic phenomena and think that your friend is the most honest person on earth. In this case, you might make the prior odds <em>O</em>(<em>H</em><sub>2</sub>)′ = 1,000. If you believed this, no amount of data could convince you that your friend is using a loaded die.</p>&#13;
<p class="indent">In cases like this, it’s important to realize that if you want to solve a problem, you need to be willing to change your prior beliefs. If you’re unwilling to let go of unjustifiable prior beliefs, then, at the very least, you must acknowledge that you’re no longer reasoning in a Bayesian—or logical—way at all. We all hold irrational beliefs, and that’s perfectly okay, so long as we don’t attempt to use Bayesian reasoning to justify them.</p>&#13;
<h3 class="h3" id="ch18lev1sec2"><strong>Arguing with Relatives and Conspiracy Theorists</strong></h3>&#13;
<p class="noindent">Anyone who has argued with relatives over a holiday dinner about politics, climate change, or their favorite movies has experienced firsthand a situation in which they are comparing two hypotheses that both explain the data equally well (to the person arguing), and only the prior remains. How can we change someone else’s (or our own) beliefs even when more data doesn’t change anything?</p>&#13;
<p class="indent">We’ve already seen that if you compare the belief that your friend has a loaded die and the belief that they are psychic, more data will do nothing to change your beliefs about your friend’s claim. This is because both your hypothesis and your friend’s hypothesis explain the data equally well. In order for your friend to convince you that they are psychic, they have to alter your prior beliefs. For example, since you’re suspicious that the die might be loaded, your friend could then offer to let you choose the die they roll. If you bought a new die and gave it to your friend, and they continued to accurately predict their rolls, you might start to be convinced. This same logic holds anytime you run into a problem where two hypotheses equally explain the data. In these cases, you must then see if there’s anything you can change in your prior.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_180"/>Suppose after you purchase the new die for your friend and they continue to succeed, you <em>still</em> don’t believe them; you now claim that they must have a secret way of rolling. In response, your friend lets you roll the die for them, and they continue to successfully predict the rolls—yet you <em>still</em> don’t believe them. In this scenario, something else is happening beyond just a hidden hypothesis. You now have an <em>H</em><sub>4</sub>—that your friend is completely cheating—and you won’t change your mind. This means that for any <em>D<sub>n</sub></em>, <em>P</em>(<em>D<sub>n</sub></em> | <em>H</em><sub>4</sub>) = 1. Clearly we’re out of Bayesian territory since you’ve essentially conceded that you won’t change your mind, but let’s see what happens mathematically if your friend persists in trying to convince you.</p>&#13;
<p class="indent">Let’s look at how these two explanations, <em>H</em><sub>2</sub> and <em>H</em><sub>4</sub>, compete using our data <em>D</em><sub>10</sub> with 9 correct predictions and 1 missed prediction. The Bayes factor for this is:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0180-01.jpg"/></div>&#13;
<p class="indent">Because you refuse to believe anything other than that your friend is cheating, the probability of what you observe is, and will always be, 1. Even though the data is exactly as we would expect in the case of your friend being psychic, we find our beliefs explain the data 26 times as well. Your friend, deeply determined to change your stubborn mind, persists and rolls 100 times, getting 90 guesses right and 10 wrong. Our Bayes factor shows something very strange that happens:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0180-02.jpg"/></div>&#13;
<p class="indent">Even though the data seems to strongly support your friend’s hypothesis, because you refuse to budge in your beliefs, you’re now even more wildly convinced that you’re right! When we don’t allow our minds to be changed at all, more data only further convinces us we are correct.</p>&#13;
<p class="indent">This pattern may seem familiar to anyone who has argued with a politically radical relative or someone who adamantly believes in a conspiracy theory. In Bayesian reasoning, it is vital that our beliefs are at least falsifiable. In traditional science, <em>falsifiability</em> means that something can be disproved, but in our case it just means there has to be some way to reduce our belief in a hypothesis.</p>&#13;
<p class="indent">The danger of nonfalsifiable beliefs in Bayesian reasoning isn’t just that they can’t be proved wrong—it’s that they are strengthened even by evidence that seems to contradict them. Rather than persisting in trying to convince you, your friend should have first asked, “What can I show you that would change your mind?” If your reply had been that <em>nothing</em> could change your mind, then your friend would be better off not presenting you with more evidence.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_181"/>So, the next time you argue with a relative over politics or conspiracy theories, you should ask them: “What evidence would change your mind?” If they have no answer to this, you’re better off not trying to defend your views with more evidence, as it will only increase your relative’s certainty in their belief.</p>&#13;
<h3 class="h3" id="ch18lev1sec3"><strong>Wrapping Up</strong></h3>&#13;
<p class="noindent">In this chapter, you learned about a few ways hypothesis tests can go wrong. Although the Bayes factor is a competition between two ideas, it’s quite possible that there are other, equally valid, hypotheses worth testing out.</p>&#13;
<p class="indent">Other times, we find that two hypotheses explain the data equally well; you’re just as likely to see your friend’s correct predictions if they were caused by your friend’s psychic ability or a trick in the die. When this is the case, only the prior odds ratio for each hypothesis matters. This also means that acquiring more data in those situations will never change our beliefs, because it will never give either hypothesis an edge over the other. In these cases, it’s best to consider how you can alter the prior beliefs that are affecting the results.</p>&#13;
<p class="indent">In more extreme cases, we might have a hypothesis that simply refuses to be changed. This is like having a conspiracy theory about the data. When this is the case, not only will more data never convince us to change our beliefs, but it will actually have the opposite effect. If a hypothesis is not falsifiable, more data will only serve to make us more certain of the conspiracy.</p>&#13;
<h3 class="h3" id="ch18lev1sec4"><strong>Exercises</strong></h3>&#13;
<p class="noindent">Try answering the following questions to see how well you understand how to deal with extreme cases in Bayesian reasoning. The solutions can be found at <em><a href="https://nostarch.com/learnbayes/">https://nostarch.com/learnbayes/</a></em>.</p>&#13;
<ol>&#13;
<li class="noindent">When two hypotheses explain the data equally well, one way to change our minds is to see if we can attack the prior probability. What are some factors that might increase your prior belief in your friend’s psychic powers?</li>&#13;
<li class="noindent">An experiment claims that when people hear the word <em>Florida</em>, they think of the elderly and this has an impact on their walking speed. To test this, we have two groups of 15 students walk across a room; one group hears the word <em>Florida</em> and one does not. Assume <em>H</em><sub>1</sub> = the groups don’t move at different speeds, and <em>H</em><sub>2</sub> = the Florida group is slower because of hearing the word <em>Florida</em>. Also assume:&#13;
<div class="equ-image"><img alt="Image" src="../images/f0181-01.jpg"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_182"/>The experiment shows that <em>H</em><sub>2</sub> has a Bayes factor of 19. Suppose someone is unconvinced by this experiment because <em>H</em><sub>2</sub> had a lower prior odds. What prior odds would explain someone being unconvinced and what would the BF need to be to bring the posterior odds to 50 for this unconvinced person?</p>&#13;
<p class="indent">Now suppose the prior odds do not change the skeptic’s mind. Think of an alternate <em>H</em><sub>3</sub> that explains the observation that the Florida group is slower. Remember if <em>H</em><sub>2</sub> and <em>H</em><sub>3</sub> both explain the data equally well, only prior odds in favor of <em>H</em><sub>3</sub> would lead someone to claim <em>H</em><sub>3</sub> is true over <em>H</em><sub>2</sub>, so we need to rethink the experiment so that these odds are decreased. Come up with an experiment that could change the prior odds in <em>H</em><sub>3</sub> over <em>H</em><sub>2</sub>.</p></li>&#13;
</ol>&#13;
</body></html>