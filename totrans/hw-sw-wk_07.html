<html><head></head><body>
<h2 class="h2" id="ch07"><a id="page_145"/><strong><span class="big">7</span></strong><br/><strong>Search</strong></h2>
<div class="image1"><img alt="image" src="graphics/common-01.jpg"/></div>
<p class="noindent">This chapter is about a topic that, perhaps more than any other subject covered in this book, we all take for granted: finding the data we want, known as a <em>search</em>. Searching happens so often, and so quickly, that it’s easy to miss the magic. When a word processor underlines a misspelled word that you just typed, a fast search has taken place behind the scenes. When you enter part of a filename and get a list of matching files on your laptop’s hard drive, that’s another near-instant search. And then there’s the ultimate search achievement: the Web. The Web is so unfathomably large that we can only guess its true size, and yet, web search engines can find relevant web pages in a fraction of a second.</p>
<p class="indent">How does software find what we want so fast?</p>
<h3 class="h3" id="ch07lev1sec01"><a id="page_146"/><strong>Defining the Search Problem</strong></h3>
<p class="noindent">Let’s start by getting our terminology straight. A collection of data is known, appropriately enough, as a <em>data collection</em>. Each item in the data collection is a <em>record</em>. A record is uniquely identified by a <em>key</em> (no relation to the cryptography term). A search retrieves the record that matches a given key. For a real-world example, when you use a dictionary the word you’re looking up is the key, and the definition of that word is the record.</p>
<p class="indent">The main goal of searching is to find the right record. But the speed of the search is just as important. If searches could go on indefinitely, searching would be simple. But as the wait time increases, so does our frustration. The length of time we’ll wait on a search varies, but it’s never very long, and in many situations, the search must appear to finish instantaneously.</p>
<h3 class="h3" id="ch07lev1sec02"><strong>Putting Data in Order</strong></h3>
<p class="noindent">Efficient searching requires well-organized data. When you visit a bookstore, for example, finding a novel by a particular author is easy if the store has ordered the shelves by authors’ last names. For one thing, you know where to start looking. Once you look at the first book on the shelf and see how close its author’s name is alphabetically to the author you seek, you would have a good idea where to look next.</p>
<p class="indent">If the store didn’t shelve its books in any particular order, then finding a book would be hard work. The best option is to start at one end of the shelf and examine every single book, which is known as a <em>sequential search</em>. In the worst case, the book you want isn’t even on the shelf, but you wouldn’t know that until you’ve looked through the whole collection.</p>
<p class="indent">Therefore, putting the data collection in a particular order, known as <em>sorting</em>, is essential for efficient searching. There are many different ways to sort; entire books have been written to describe different sorting algorithms for software. We’ll look at two methods here.</p>
<h4 class="h4" id="ch07lev2sec01"><strong><em>Selection Sort</em></strong></h4>
<p class="noindent">If I asked you to put a list of numbers in order, you would most likely use what is known as a <em>selection sort</em>. First, you’d scan the list to find the lowest number, and then you’d cross the number out and copy it to a new list. You would repeat the process until all the numbers were in order in the new, sorted list.</p>
<p class="indent">The first three steps of a selection sort of nine numbers are shown in <a href="ch07.html#ch7fig1">Figure 7-1</a>. In the first step, the lowest number is copied to the beginning of a new list. In the steps that follow, the lowest remaining numbers are copied to the new list.</p>
<div class="image"><a id="page_147"/><img alt="image" src="graphics/f07-01.jpg"/></div>
<p class="figuret"><a id="ch7fig1"/><em>Figure 7-1: The first three steps in a selection sort of nine numbers</em></p>
<h4 class="h4" id="ch07lev2sec02"><strong><em>Quicksort</em></strong></h4>
<p class="noindent">While selection sort is easy to understand, software rarely uses it because it isn’t efficient. Each step requires us to process every number in the unsorted list, and for that effort all we get is one number in its correct position.</p>
<p class="indent">A better sorting method, called <em>quicksort</em>, partially orders all of the data processed during each pass, reducing later effort and time. Instead of scanning the entire list for the lowest number, we select a number in the list to be the <em>pivot</em>. We use the pivot to <em>partition</em> the list, dividing the list around the pivot. Numbers that are less than the pivot go to the front of the list, and those that are greater go to the back.</p>
<p class="indent">For this example we’ll use the same list of numbers used in the selection sort. <a href="ch07.html#ch7fig2">Figure 7-2</a> shows the first step of partitioning. Different versions of quicksort select the pivot in different way; we’ll keep things simple and use the first number in the list, 47, as the pivot. The next number, 93, is copied to the end of the new list because it is greater than 47.</p>
<div class="image"><a id="page_148"/><img alt="image" src="graphics/f07-02.jpg"/></div>
<p class="figuret"><a id="ch7fig2"/><em>Figure 7-2: The number 93 is more than the pivot, so it moves to the end of the new list.</em></p>
<p class="indent">In <a href="ch07.html#ch7fig3">Figure 7-3</a>, 56 is also greater than 47, so it’s copied to the next space on the end.</p>
<div class="image"><img alt="image" src="graphics/f07-03.jpg"/></div>
<p class="figuret"><a id="ch7fig3"/><em>Figure 7-3: The number 56 is more than the pivot, so it moves to the end of the new list.</em></p>
<p class="indent">In <a href="ch07.html#ch7fig4">Figure 7-4</a>, 33 is less than 47, so it’s copied to the front of the new list.</p>
<div class="image"><img alt="image" src="graphics/f07-04.jpg"/></div>
<p class="figuret"><a id="ch7fig4"/><em>Figure 7-4: The number 33 is less than the pivot, so it moves to the front of the new list.</em></p>
<p class="indent"><a href="ch07.html#ch7fig5">Figure 7-5</a> combines the next five steps. Three of the remaining numbers go to the front of the list and two go to the back. This leaves a gap for one more number.</p>
<div class="image"><img alt="image" src="graphics/f07-05.jpg"/></div>
<p class="figuret"><a id="ch7fig5"/><em>Figure 7-5: The remaining numbers in the list are partitioned.</em></p>
<p class="indent"><a id="page_149"/>In <a href="ch07.html#ch7fig6">Figure 7-6</a>, this gap is filled with 47, the pivot. This completes the initial partitioning.</p>
<div class="image"><img alt="image" src="graphics/f07-06.jpg"/></div>
<p class="figuret"><a id="ch7fig6"/><em>Figure 7-6: The pivot fills the open space in the new list.</em></p>
<p class="indent">This new list isn’t sorted, but it’s in better shape than before. The pivot is in its correct sorted position, indicated by the shading. The first four numbers in the list are less than 47, and the last four are greater than 47. A single partitioning does more than put one number in its correct place, like one step of a selection sort; it also divides the remaining numbers in the list into sublists, as shown in <a href="ch07.html#ch7fig7">Figure 7-7</a>. These sublists can be sorted independently. Sorting two shorter lists requires less effort than sorting one longer list. If you doubt this, consider an extreme case: would you rather sort 50 short lists of 2 numbers, or 1 long list of 100 numbers?</p>
<div class="image"><img alt="image" src="graphics/f07-07.jpg"/></div>
<p class="figuret"><a id="ch7fig7"/><em>Figure 7-7: Partitioning has transformed the list into two separate, smaller lists that can be sorted independently.</em></p>
<p class="indent">The two sublists are now independently partitioned. In <a href="ch07.html#ch7fig8">Figure 7-8</a>, the first number in the sublist, 33, becomes the new pivot and the four numbers of sublist 1 are partitioned. This puts 22 and 11 to the left of the 33, and 45 to the right.</p>
<div class="image"><img alt="image" src="graphics/f07-08.jpg"/></div>
<p class="figuret"><a id="ch7fig8"/><em>Figure 7-8: Partitioning sublist 1 of <a href="ch07.html#ch7fig7">Figure 7-7</a></em></p>
<p class="indent">In <a href="ch07.html#ch7fig9">Figure 7-9</a>, sublist 2 is partitioned using 74 as a pivot.</p>
<div class="image"><a id="page_150"/><img alt="image" src="graphics/f07-09.jpg"/></div>
<p class="figuret"><a id="ch7fig9"/><em>Figure 7-9: Partitioning sublist 2 of <a href="ch07.html#ch7fig7">Figure 7-7</a></em></p>
<p class="indent">These partitions put both of their pivots in their correct sorted places in the list. The partitions also create four new sublists, as shown in <a href="ch07.html#ch7fig10">Figure 7-10</a>.</p>
<div class="image"><img alt="image" src="graphics/f07-10.jpg"/></div>
<p class="figuret"><a id="ch7fig10"/><em>Figure 7-10: Now four sublists remain. Single-number sublists are trivial.</em></p>
<p class="indent">Sublists 4 and 6 contain a single number, which means there’s nothing to partition. In <a href="ch07.html#ch7fig11">Figure 7-11</a>, sublists 3 and 5 are partitioned.</p>
<div class="image"><img alt="image" src="graphics/f07-11.jpg"/></div>
<p class="figuret"><a id="ch7fig11"/><em>Figure 7-11: Only two trivial sublists remain, which means the whole list is sorted.</em></p>
<p class="indent">Now we have just two single-number sublists left, which means that the sort is complete.</p>
<p class="indent">In this example, the pivots evenly divided their partitions, but quicksort isn’t always so lucky. Sometimes the split is uneven, and in the worst case, the pivot could be the lowest or highest number in the list, which means the partitioning produces the same result as a step in a selection sort. But most partitions will be roughly even, which tends to result in a much faster sort.</p>
<p class="indent">More generally, quicksort <em>scales</em> much better than selection sort. For any sorting method, sorting time increases as the size of the data collection increases, but selection sort slows down much more than quicksort. Let’s say a particular computer can sort 10,000 records in around a second using either method. On the same computer, a selection sort of 1,000,000 records would take nearly 3 hours, while a quicksort would take only about 11 minutes.</p>
<h3 class="h3" id="ch07lev1sec03"><a id="page_151"/><strong>Binary Search</strong></h3>
<p class="noindent">When data is in order, software can find a particular record easily. One simple search method for ordered data is <em>binary search</em>. The word <em>binary</em> in this case doesn’t refer to binary numbers, but to choosing between two alternatives.</p>
<p class="indent"><a href="ch07.html#ch7fig12">Figure 7-12</a> shows binary search in action. The record we want has a key of 48. Initially, all we know is that the data in the collection is ordered on our key, so the record could appear anywhere. In step 1, we examine the record in the middle of the collection. If this record had a key of 48, we would we be done, but this is unlikely. However, because this record has a key of 62, which is larger than 48, we know that the desired record must appear among the first seven records. Thus, examining one record has eliminated not just that record from consideration, but also the seven records that appear later in the collection.</p>
<p class="indent">In step 2, we examine the fourth record, the midpoint of the remaining seven records. This record has a key of 23, which is lower than 48. Therefore the desired record must be in the three records between 23 and 62.</p>
<p class="indent">In step 3, we examine the middle of these remaining three records, which has a key of 47. This tells us the desired record must be the one record between 47 and 62. If that record did not have a key of 48, it would mean the collection did not include a record with that key.</p>
<div class="image"><img alt="image" src="graphics/f07-12.jpg"/></div>
<p class="figuret"><a id="ch7fig12"/><em>Figure 7-12: Binary search taking four steps to find a particular record in a collection of size 15</em></p>
<p class="indent">Each step in a binary search eliminates half of the records from consideration, which means binary search scales fantastically well. With a <a id="page_152"/>sequential search, doubling the size of a data collection doubles the time needed for the average search. With binary search, doubling the number of records requires just one more step. If we start with 31 records, for example, after examining the middle record, either we get lucky and find the desired record, or we find out whether the desired record is in the first or last 15 records. Either way we would now have only 15 records left to search, putting us back where we started in <a href="ch07.html#ch7fig12">Figure 7-12</a>. For huge data collections, the difference between binary and sequential search is dramatic. A sequential search of 1,000,000 records will examine 500,000 records on average, while a binary search of 1,000,000 records will examine no more than 20.</p>
<h3 class="h3" id="ch07lev1sec04"><strong>Indexing</strong></h3>
<p class="noindent">To keep the figures simple, our examples to this point have used just record keys. In practice, though, the rest of the record has to be stored somewhere, and this can cause problems. To see why, we have to understand the choice software faces when allocating storage space for data, whether in main memory, on a hard drive, or anywhere else.</p>
<p class="indent"><em>Fixed-size</em> storage allocation assigns each record the same amount of space and is used for data that is either always the same size or has a small maximum size. Credit card numbers, for example, are always 16 digits. The names of credit card owners, on the other hand, vary in size, but there are only so many letters that will fit on the card. Both card numbers and card-holder names could be stored in a fixed number of bytes. In <a href="ch07.html#ch7fig13">Figure 7-13</a>, the maximum size of a last name is 15 characters, just long enough for Hammond-Hammond. The other names are shorter, resulting in wasted bytes, shown as shaded squares. Because the space needed to store a name is small, though, this wasted space is of no great concern.</p>
<div class="image"><img alt="image" src="graphics/f07-13.jpg"/></div>
<p class="figuret"><a id="ch7fig13"/><em>Figure 7-13: Fixed allocation of storage results in wasted space</em></p>
<p class="indent"><em>Variable-size</em> storage allocation exactly fits the data. Consider a collection of MP3 files. Roughly speaking, the longer the song, the larger the MP3 file. A short pop song might be 3 or 4MB, while a progressive-rock epic might be as large as 20MB. We wouldn’t want to store song data in fixed space because this would waste too much space for shorter songs, and this would limit the length of a song. Instead, the data should be stored in just as much space as needed.</p>
<p class="indent"><a id="page_153"/>Variable-size storage allocation uses space efficiently, but fixed-size storage allocation is required for software to use efficient search methods. When all the records in a collection are the same size, software can quickly find a record in a particular position.</p>
<p class="indent">This is because storage locations are identified by numerical <em>addresses</em>. Every byte in digital storage—whether in a computer’s main memory, or on a flash drive or hard drive—can be precisely located by its address. If a computer has 8GB of main memory, for example, those bytes are numbered from zero to just over eight trillion. Collections of fixed-size records are stored contiguously, which makes finding a record’s address simple. Suppose a collection has 100 records, each 20 bytes in size, and the collection begins at address 1,000. That puts the first record at address 1,000, the second at 1,020, the third at 1,040, and so on. We can calculate the address of any record by multiplying its position number by 20 and adding the result to 1,000. In this way, software can quickly locate any record in any collection of fixed-size records.</p>
<p class="indent">Finding records quickly is essential for a method like binary search. Without fixed-size records, the only way to find a record in a particular position is to start from the beginning of the data collection and count the records. That’s just a sequential search, and defeats the point.</p>
<p class="indent">Choosing between fixed-size and variable-size storage allocation means choosing between efficient search and efficient storage. However, a technique called <em>indexing</em> gives us both. Indexing separates the keys from the rest of the records, much as a library card catalog allows patrons to search for books on cards before ultimately retrieving the books from the shelves.</p>
<p class="indent">An index is a table of record keys and addresses. The addresses themselves are stored as binary numbers with a fixed number of bits. For example, when Microsoft releases versions of Windows in “32-bit” and “64-bit” editions, those bit counts refer to the size of the addresses for main memory. Because the addresses are a fixed size, we can store the addresses and keys together in an index of fixed-size records that can be searched efficiently using a method like binary search. The rest of each record’s data is stored in a variable-size allocation. This produces a data collection that is efficient for storage <em>and</em> searching.</p>
<p class="indent"><a href="ch07.html#ch7fig14">Figure 7-14</a> shows an indexed data collection of four songs. On the left, the index contains the song titles and the addresses for the remaining data of each song, such as the artist name and the encoded music. On the right is a block of memory cells numbered from 1 to 400. The arrows point to each address.</p>
<p class="indent">As shown in the example, this split data allocation allows each record to use as much or as little space as needed. It even allows the index and remaining data to be on different storage devices. For example, the index might be kept in a computer’s fast main memory, while the encoded music data is left on its relatively slow hard drive. Because only the index is needed for search, such an arrangement allows for efficient search while using the minimum amount of main memory.</p>
<div class="image"><a id="page_154"/><img alt="image" src="graphics/f07-14.jpg"/></div>
<p class="figuret"><a id="ch7fig14"/><em>Figure 7-14: An indexed data collection of digital music</em></p>
<p class="indent">We can also have multiple indexes for the same data collection. The arrangement in <a href="ch07.html#ch7fig14">Figure 7-14</a> allows individual songs to be quickly located by song title, but doesn’t help us search for a song based on artist name or album title. Data collections can have multiple indexes for different search criteria, and because the main record data is simply referenced by an address, having multiple indexes doesn’t greatly affect the total storage requirements for the data collection.</p>
<h3 class="h3" id="ch07lev1sec05"><strong>Hashing</strong></h3>
<p class="noindent">Although ordered data is required for efficient searching, sorting data takes time. So far we’ve discussed sorting as though data collections need to be sorted just once. Sometimes that is the case; for example, a word processor needs a list of correctly spelled words for spell checking, but that list is created once and supplied as part of the application. A spellcheck word list is a <em>static</em> data collection, one that changes infrequently. However, many of the collections we search are <em>dynamic</em>—records are frequently added or removed. Because efficient searching requires ordered data, collections must be re-sorted following each addition or removal. When insertions and deletions are common, the time spent re-sorting the data collection can negate the benefit of a faster search. In such cases, it may be better to structure the data to facilitate frequent changes.</p>
<p class="indent">One data structure that eases additions and removals of records involves hash functions, which were introduced in <a href="ch02.html#ch02">Chapter 2</a>. For this example let’s imagine a hash function that produces a mere 3-bit hash, equivalent to a decimal number in the range of 0 to 7. We can use this to store records in a <em>hash table</em> with slots for 8 records. A <em>slot</em> is a place where a record could be stored.</p>
<p class="indent"><a id="page_155"/>To store a record in the hash table, we hash the record’s key to determine which slot to use. Suppose we are storing MP3 files with song titles as the keys. Four titles and their associated hash codes are shown in <a href="ch07.html#ch7tab1">Table 7-1</a>.</p>
<p class="tablet"><a id="ch7tab1"/><strong>Table 7-1:</strong> Hash Codes for Sample Song Titles</p>
<table border="0" cellpadding="0" cellspacing="0" class="topbot" width="50%">
<thead>
<tr>
<td class="table_th" valign="top"><p class="table"><strong>Song title</strong></p></td>
<td class="table_th" valign="top"><p class="table"><strong>Hash code</strong></p></td>
</tr>
</thead>
<tbody>
<tr>
<td class="table" valign="top"><p class="table">Life on Mars</p></td>
<td class="table" valign="top"><p class="table">6</p></td>
</tr>
<tr>
<td class="table" valign="top"><p class="table">Nite Flights</p></td>
<td class="table" valign="top"><p class="table">4</p></td>
</tr>
<tr>
<td class="table" valign="top"><p class="table">Surrender</p></td>
<td class="table" valign="top"><p class="table">1</p></td>
</tr>
<tr>
<td class="table" valign="top"><p class="table">The True Wheel</p></td>
<td class="table" valign="top"><p class="table">4</p></td>
</tr>
</tbody>
</table>
<p class="indent"><a href="ch07.html#ch7fig15">Figure 7-15</a> shows the hash table after the insertion of the first three songs from <a href="ch07.html#ch7tab1">Table 7-1</a>. The first column in each record is a bit, which is 1 if the slot is in use and 0 if not. The second column is the title, and the third column holds the address of the remaining data.</p>
<div class="image"><img alt="image" src="graphics/f07-15.jpg"/></div>
<p class="figuret"><a id="ch7fig15"/><em>Figure 7-15: An eight-slot hash table</em></p>
<p class="indent">The beauty of a hash table is that a search doesn’t really require searching. We just run the key through the hash function and the result tells us where the record should be. If there’s no record in that slot, we know right away that the collection doesn’t contain a record with that key. Even better, hash tables avoid the effort of sorting. This makes a hash table an excellent choice for a collection with frequent additions and deletions of records.</p>
<p class="indent">However, we haven’t inserted the fourth song in the list. The song title “The True Wheel” hashes to 4, the same number as “Nite Flights.” As you may remember from <a href="ch02.html#ch02">Chapter 2</a>, a hash function is not guaranteed to produce a different hash value for every input, and indeed, some matching hash values, or <em>collisions</em>, are inevitable. Since we can put only one record in a slot, we need a rule for handling collisions. The simplest rule is to use the first empty slot after the collision point. Because slot 4 is already occupied with “Nite Flights,” we would place “The True Wheel” in the next open slot, which is slot 5, as shown in <a href="ch07.html#ch7fig16">Figure 7-16</a>.</p>
<div class="image"><a id="page_156"/><img alt="image" src="graphics/f07-16.jpg"/></div>
<p class="figuret"><a id="ch7fig16"/><em>Figure 7-16: Resolving a collision. The second song that hashes to 4 is placed in the next empty slot, which is slot 5.</em></p>
<p class="indent">This handles the collision problem, but it complicates the use of the hash table.</p>
<p class="indent">With this collision rule in place, finding a record is no longer a one-step process. Each search still starts at the slot indicated by the hash code, but then checks the slots one by one until it finds the matching song title. If the search reaches an empty slot, the song isn’t in the collection.</p>
<p class="indent">Collisions can also cause records to be stored far from the position indicated by the hash code. For example, if a title with a hash code of 5 is inserted into the table shown in <a href="ch07.html#ch7fig16">Figure 7-16</a>, even though no previous song title has hashed to 5, the slot is already filled by “The True Wheel,” and the new song would move all the way to slot 7. As a hash table fills, these situations become more common, degrading search performance; in effect, some hash table searches become miniature sequential searches.</p>
<p class="indent">Collisions also complicate the deletion of records. Suppose “Nite Flights” is removed from the hash table of <a href="ch07.html#ch7fig16">Figure 7-16</a>. The obvious way to remove a record is just to mark the slot “empty” again, but that doesn’t work. To see why, remember that the song title “The True Wheel” hashed to 4, and the song was stored in slot 5 only because slot 4 was occupied at the time. A search for “The True Wheel” will begin at slot 4 as indicated by the hash code, find the slot empty, and end the search unsuccessfully. The song is still in the index table, but can’t be found by a hash search.</p>
<p class="indent">To avoid this problem, we can remove the song data but keep the slot marked as occupied, as shown in <a href="ch07.html#ch7fig17">Figure 7-17</a>.</p>
<p class="indent">Slot 4 is now what is called a <em>tombstone</em>. By leaving the slot marked as occupied while deleting the data, we ensure that searches still work. However, tombstones waste space. Furthermore, because the table never really frees any record slots, the performance issues of congestion remain.</p>
<p class="indent">For these reasons, hash tables are periodically <em>rehashed</em>. Once a certain percentage of the slots in a table are occupied, a new, larger table is created, and each key in the original table is hashed with a new hash function, producing a fresh, sparsely populated table without any tombstones.</p>
<div class="image"><a id="page_157"/><img alt="image" src="graphics/f07-17.jpg"/></div>
<p class="figuret"><a id="ch7fig17"/><em>Figure 7-17: Leaving slot 4 marked as occupied after deletion of its data</em></p>
<h3 class="h3" id="ch07lev1sec06"><strong>Web Search</strong></h3>
<p class="noindent">All of the techniques shown in this chapter are needed for efficiently searching large data collections, and no collection is larger than the Web. A search engine such as Google depends upon a vast index, where the keys are search terms, the addresses are URLs, and the web pages are the records. The size of the Google index is estimated at around 100 petabytes, or 100,000,000 gigabytes. To find something in an index this large requires all of the best search techniques. Although these techniques help illustrate how an index this large could be searched, they don’t tell us how the index was created in the first place.</p>
<p class="indent">Search engines use <em>robots</em>, programs that run without direct human intervention, to build their indexes. The robots crawl all over the Web. Starting at some particular web page, they make a list of all the links on that page. Those linked pages are then processed to find links to other pages, and so on. Eventually the robot has links to most of the content on the Web.</p>
<p class="indent">Some content, though, is more difficult to locate. Some pages can’t be reached from a site’s home page but are instead found through the site’s own search engine. A news site, for example, may not link to older articles but does provide a local search for its archives. This unlinked but valuable content is known as the <em>deep web</em>. Incorporating deep web content into a search engine index usually requires some assistance from the site. Site managers have several ways to provide web-crawling robots a “table of contents” for all the pages on the site, such as a document called a <em>Sitemap</em>. This document is named after the <em>site map</em> page some sites provide for users to quickly find the content they are looking for, but has a specific format that’s easy for robots to process. Sitemaps keep search engines updated with content changes and are especially useful for sites with deep content that would otherwise be left out of search engine indexes.</p>
<h4 class="h4" id="ch07lev2sec03"><a id="page_158"/><strong><em>Ranking Results</em></strong></h4>
<p class="noindent">As robots gather pages, search engines mine the pages for keywords, counting how often each keyword appears on each page. Early search engines employed little more than a list of keywords along with their page counts. If you searched for <em>cake</em>, the page where <em>cake</em> most often appeared would be at the top of the returned list. That’s logical enough, but a mere word count doesn’t produce what we now consider to be good search results.</p>
<p class="indent">The first problem is that it’s too easy for someone to exploit the system for personal gain. Suppose the operator of a site selling knockoff pharmaceuticals wants to get a lot of traffic and doesn’t care how it’s done. When the operator discovers that legions of people are searching for <em>omelette recipe</em>, the operator might put those words on the home page as many times as possible, even hiding the words in the behind-the-scenes formatting code. As a result, the site might be among the first returned on searches for omelette recipes, even though no such recipes appear on the site. Word counts do not guarantee a match between search terms and content.</p>
<p class="indent">Another website operator might build a site that is legitimately about omelettes, but it’s filled with content stolen from Wikipedia, in order to generate revenue from ads about a zero-cholesterol egg substitute. In this case, the word count correctly connects the search term to matching content, but the quality of the content is poor.</p>
<p class="indent">The underlying issue is that the websites are self-reporting the nature and the quality of their content. What’s missing is the opinion of a disinterested viewer. Ideally, search engines could employ an army of reviewers to determine what pages are about and how well they cover their chosen topics. The Web is so vast and ever-changing, though, that this is a practical impossibility.</p>
<p class="indent">Instead, search engines rely on the opinions of other websites. They acquire these opinions in the form of <em>inbound links</em>. The number of links to a particular page is a good metric for how that page is regarded by the online community. In <a href="ch07.html#ch7fig18">Figure 7-18</a>, page C has four inbound links, page D has none, and each of the others has one. On this basis alone, page C appears to be the most valued resource, while A, B, and E appear equally useful.</p>
<div class="image"><img alt="image" src="graphics/f07-18.jpg"/></div>
<p class="figuret"><a id="ch7fig18"/><em>Figure 7-18: The number of links pointing to a page is one factor used by search engines to determine ranking.</em></p>
<p class="indent"><a id="page_159"/>There’s more to the story though. A page with a high inbound link count grants more points to the pages it links to. In the previous figure, three pages have only one inbound link, but the quality of each link is different. Page E is linked from page C, which has a high inbound link count, while pages A and B are linked only from each other. Factoring the quality of each link into the link count helps to foil <em>link farming</em>, in which large numbers of pointless websites are created, often through free host services, for the purpose of increasing a target site’s inbound link count.</p>
<p class="indent">In effect, this turns the Web into a collection of self-organized expert communities. When a number of well-regarded cooking sites begin linking to a new omelette-focused site, which in turn links back to omelette-related content in the established sites, the new site is inducted into the online cooking community. Thereafter, the new site’s links count as much as the older, established sites.</p>
<h4 class="h4" id="ch07lev2sec04"><strong><em>Using the Index Effectively</em></strong></h4>
<p class="noindent">While building the index is the bulk of the work of making a search engine, how the index is used during a search is just as important. Good search results require attention to detail.</p>
<p class="indent">For one thing, a search engine cannot merely use the supplied search terms as keywords. Consider the differences in word forms. You might type <em>frozen rain</em> in a search box, but most pages with relevant information use the form <em>freezing rain</em>. By linking together different forms of keywords in its index, a search engine can maximize the usefulness of results. This idea applies to synonymous terms as well. Because the words <em>insomnia</em> and <em>sleeplessness</em> mean the same thing, searching for either term produces similar results, even though some pages predominantly use one word or the other. For example, the Wikipedia article on insomnia appears in the first few results for either search term, even though, at the time of this writing, the word <em>sleeplessness</em> appears only twice in the article, while the word <em>insomnia</em> appears over 200 times.</p>
<p class="indent">The results from these search terms are not identical, though. A search for <em>insomnia</em> will also include links to the 2002 film <em>Insomnia</em>, but these links aren’t returned by a search for <em>sleeplessness</em>. That result makes sense—presumably, no one searching for the film would have entered a synonym of the film’s title—but how can a search engine know the two terms are linked in some ways but not others?</p>
<p class="indent">Tracking how search terms are combined can yield valuable clues. If searchers frequently add the terms <em>movie</em> or <em>film</em> to the term <em>insomnia</em>, then searches for just <em>insomnia</em> may indicate someone interested in the film and not the medical condition.</p>
<p class="indent">Furthermore, the links on a search results page are not actually direct links to the listed pages. Instead, they are <em>pass-through links</em>. For example, if you search Google for <em>insomnia</em>, then click on the link for the Wikipedia entry, you’ll first be taken to the google.com server, which will then redirect you to <a href="http://wikipedia.org">wikipedia.org</a>. Google tracks which result you selected, and this data, collected from countless users over time, allows Google to fine-tune the results, keeping the links that users actually find useful near the top.</p>
<p class="indent"><a id="page_160"/>Search engines can also make use of the location of the person searching. For example, when you search for <em>smiley’s pizza</em> while you’re standing in a particular town, the search engine appends the town’s name to the search, so that the results are localized, instead of returning the websites of the most popular pizzerias with that name in the entire world.</p>
<h3 class="h3" id="ch07lev1sec07"><strong>What’s Next for Web Search</strong></h3>
<p class="noindent">As impressive as current web search capabilities are, there’s still room for improvement.</p>
<p class="indent">For example, images provide unique challenges for search engines. Currently, image files are indexed based on accompanying text. A search engine might gather clues from an image’s filename, or make educated guesses based on the text surrounding the image on the page.</p>
<p class="indent">We can soon expect the use of <em>computer vision</em> techniques in web indexes. Such software techniques transform an image into a description of the image. In some ways this is the reverse of the graphics techniques described in <a href="ch04.html#ch04">Chapters 4</a> and <a href="ch05.html#ch05">5</a>, where mathematical models were rendered into images. With computer vision, images are simplified into mathematical descriptions that are then categorized by pattern. Such software is currently used in self-governing robots, so that they can recognize an object they have been sent to retrieve. Future search engines may process the Web’s images using these techniques, identifying both general subjects (“clear sky,” “kittens”) and specific subjects (“Eiffel Tower,” “Abraham Lincoln”) within the images.</p>
<p class="indent">Indexes will also be updated faster. Currently web indexes update only when a web-crawling robot passes through. In the future, indexes may be updated in near real time, so that conversations quickly developing throughout social media can be indexed as they happen. Eventually, real-time search may be combined with artificial intelligence to automatically generate basic news stories from social media for fast-breaking events like natural disasters.</p>
<p class="indent">But those are tomorrow’s marvels. The Web and its search engines are the marvel of today, a powerhouse of information unfathomable just a few decades ago.</p>
</body></html>