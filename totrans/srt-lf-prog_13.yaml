- en: '**13'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**13  '
- en: SECURITY**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 安全**
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: Security is an advanced topic. The cryptography component in particular involves
    lots of esoteric mathematics. But it’s a really important topic. Rather than go
    into all the gory details, this chapter gives you the lay of the land. While this
    isn’t enough for you to qualify as a security expert, it should enable you to
    ask questions about the viability of security implementations. And there are lots
    of things that you can do without having to be a security expert to make both
    you and your code more secure.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 安全是一个高级话题。特别是密码学部分，涉及大量深奥的数学内容。但它是一个非常重要的话题。与其深入探讨所有复杂的细节，本章将为你概述该领域的全貌。虽然这些内容不足以让你成为安全专家，但应该能帮助你提出有关安全实现可行性的问题。而且有许多事情，即使你不是安全专家，也能做出改进，让你和你的代码更加安全。
- en: For the most part, computer security is not very different from regular old
    security, such as home security. In many respects, the advent of networked computers
    transformed security issues from those needed for a small apartment to those required
    to secure a large castle. As you can imagine, a large castle has many more entrances
    that need guarding and more inhabitants who can compromise the defenses. And it’s
    bigger, so a lot more trash accumulates, making it harder to keep clean and giving
    bugs more places to hide.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，计算机安全与常见的安全问题（例如家庭安全）没有太大区别。在许多方面，联网计算机的出现将安全问题从小型公寓所需的安全措施，转变为保护大型城堡所需的安全措施。正如你能想象的那样，大城堡有更多的入口需要防守，更多的居民可能会破坏防御。而且它更大，因此积累的垃圾更多，导致清理更加困难，也给虫子提供了更多的藏身之处。
- en: At its core, security is about keeping you and your stuff safe by *your* definition
    of *safe*. It’s not just a technological issue—it’s a social issue. You and your
    stuff, along with your definition of safe, must be balanced against everybody
    else, their stuff, and their definitions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，安全是通过*你*对*安全*的定义来保护你和你的财物。这不仅仅是一个技术问题——它还是一个社会问题。你和你的财物，以及你对安全的定义，必须与其他所有人、他们的财物和他们的定义进行平衡。
- en: Security and privacy are intertwined, in part because security comes from keeping
    your information private. For example, your bank account wouldn’t be secure if
    everybody had the password. Privacy is difficult to maintain given the number
    of inane practices at organizations with which we are forced to interact. Every
    time I see a new doctor, their office asks me for all my personally identifying
    information. I always ask them, “Why do you need this information?” They always
    reply, “To protect your privacy.” To which I always ask, “How does giving you
    and everybody else who asks for it all my personal information protect my privacy?”
    They just give an exasperated sigh and say, “We just need it.” And whether they
    do or not, they’re not required to give you a truthful answer. Nowadays, privacy
    is also impacted by the ease of connecting disparate pieces of information (a
    topic covered in more detail in the next chapter) resulting from pervasive data
    collection, which includes surveillance cameras, automatic license plate readers
    (ALPRs), cell phone surveillance including IMSI catchers (StingRays), internet
    surveillance (room 641A), facial recognition, and so on. Protecting your privacy
    is increasingly difficult, which negatively impacts your security.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 安全与隐私是相互交织的，部分原因在于安全来自于保持信息的私密性。例如，如果每个人都有密码，那么你的银行账户就不安全。鉴于我们必须与一些组织互动，隐私变得越来越难以维持。每次我看新医生时，他们的办公室都会要求我提供所有个人身份信息。我总是问他们：“你们为什么需要这些信息？”他们总是回答：“为了保护您的隐私。”对此，我总是问：“为什么向你们和所有其他要求的人提供我的个人信息能保护我的隐私？”他们只是叹口气，说：“我们就是需要这些信息。”无论他们是否需要，事实上，他们并不被要求给你一个真实的答案。如今，隐私也受到了信息拼接便利性的影响（下章将详细讨论），而这种拼接得益于普遍的数据收集，包括监控摄像头、自动车牌识别（ALPR）、手机监控（如IMSI捕捉器/StingRays）、互联网监控（如641A房间）、面部识别等等。保护隐私变得越来越困难，进而影响了你的安全。
- en: Good security is hard. The old adage that “a chain is only as strong as its
    weakest link” describes the situation perfectly. Think about online banking. There
    are many components ranging from computer hardware, software, and communications
    networks to people. The best technology won’t protect you if you leave your password
    written down next to your computer!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的安全性是难以实现的。那句“链条的强度等于最弱环节”恰如其分地描述了这种情况。想一想网上银行。涉及的组件有很多，从计算机硬件、软件和通信网络，到人员。如果你把密码写在电脑旁边，最好的技术也无法保护你！
- en: '**Overview of Security and Privacy**'
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**安全性和隐私概述**'
- en: This section provides a nontechnical introduction to the issues involved in
    security and privacy. It defines many of the terms that later sections cover in
    more depth.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了关于安全性和隐私问题的非技术性介绍。它定义了许多后续章节中会更深入讨论的术语。
- en: '***Threat Model***'
  id: totrans-10
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***威胁模型***'
- en: We wouldn’t be talking about security in the absence of threats. There wouldn’t
    be security worries if everybody behaved nicely. But they don’t.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有威胁，我们就不会谈论安全问题。如果每个人都表现得很好，也就没有安全顾虑了。但事实并非如此。
- en: Security doesn’t exist in a vacuum; it’s relative to a *threat model*, which
    lists the things to be secured and enumerates the possible attacks on whatever
    needs securing so that appropriate defenses can be designed. Contrary to what
    you might infer from the behavior of “smart devices” such as internet-connected
    televisions, security cameras, light bulbs, and such, “What could possibly go
    wrong?” is not a valid threat model.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性并非孤立存在；它相对于一个*威胁模型*，该模型列出了需要保障的事物，并列举了可能对这些事物造成攻击的方式，从而可以设计出适当的防御措施。与“智能设备”如互联网连接电视、监控摄像头、灯泡等的行为相反，"可能出什么问题呢？"并不是一个有效的威胁模型。
- en: For example, at the time of writing, Fender had recently introduced a Bluetooth-enabled
    guitar amplifier. But the company didn’t bother to implement the Bluetooth pairing
    protocol, which would secure the wireless connection between a performer’s guitar
    and amp. That means a crafty audience member could connect to the stage amp as
    well from a cell phone if they were close enough, broadcasting whatever they wanted.
    (This could become a new art form, but that was likely not Fender’s intent.)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在撰写本文时，Fender公司刚刚推出了一款蓝牙吉他放大器。但该公司并没有实现蓝牙配对协议，这本应当保障表演者吉他与放大器之间的无线连接安全。这意味着，一位机智的观众如果足够接近，可以通过手机连接到舞台上的放大器，广播任何他们想要的内容。（这可能成为一种新的艺术形式，但显然这不是Fender的意图。）
- en: Understanding the threat model is important because there’s no such thing as
    100 percent security. You have to design defenses that are appropriate for the
    threat model. For example, it might be nice to have your own personal armed guard
    to keep your backpack safe when you’re in class, but it’s not cost-effective and
    probably wouldn’t go over well with the school administration. A locker is a more
    appropriate defense for this particular threat.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 理解威胁模型很重要，因为没有什么是百分之百安全的。你必须设计适合威胁模型的防御措施。例如，拥有一个私人武装保镖来保护你上课时的背包可能看起来不错，但这既不划算，也可能不被学校管理层接受。在这种情况下，使用储物柜是一种更合适的防御措施。
- en: 'Here’s another example: I live on a farm in the middle of nowhere. I can put
    all the expensive locks I want on the doors, but if someone wanted to cut through
    a wall with a chainsaw or dynamite their way in, nobody would notice because those
    are normal country sounds. Of course, I do have locks, but in this case, carrying
    good insurance is a large component of my security because I’m protecting the
    value of my property, which would be too expensive to secure by physical means.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是：我住在一个偏远的农场。我可以在门上装上所有昂贵的锁，但如果有人想用链锯砍穿墙壁或用炸药闯入，没人会注意到，因为这些都是乡村里常见的声音。当然，我确实有锁，但在这种情况下，购买良好的保险是我的安全保障的重要组成部分，因为我在保护我的财产价值，而通过物理手段来保护它将变得过于昂贵。
- en: Many of my neighbors don’t really understand this and engage in practices that
    decrease their security. It’s unfortunately common for people to move to the country
    and immediately install streetlights on their property. I’ve asked many of them
    why they installed the lights, because part of living in the country is being
    able to see the stars at night and light pollution interferes. The answer is always
    “for security.” I’ve tried to explain that those lights are just a big advertisement
    that something is worth stealing and that nobody is home.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我的许多邻居实际上并不理解这一点，反而采取一些降低安全性的做法。不幸的是，很多人搬到乡村后，立刻就在自己的财产上安装路灯。我问过许多人为什么要安装这些路灯，因为住在乡村的一部分乐趣就是能在晚上看到星星，而光污染会干扰这一点。他们的回答总是“为了安全”。我曾尝试解释，这些路灯不过是一个大广告，告诉别人这里有值得偷的东西，而且家里没人。
- en: Self-defeating security measures are common in the computer world too. For example,
    many organizations choose to have rules dictating the composition of passwords
    and how often they must be changed. The result is that people either choose easily
    guessable passwords or write them down because they can’t remember them.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机世界中，自我败坏的安全措施也很常见。例如，许多组织选择制定密码的组成规则和更改频率。结果是，人们要么选择容易猜到的密码，要么因为记不住密码而写下来。
- en: The upshot is that you can’t do effective security without defining the threat
    model. There has to be a balance between threats and defending against them. The
    goal is have inexpensive defenses that are expensive to attack. A side effect
    of the internet is that it has dramatically reduced attack costs but not defense
    costs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，没有定义威胁模型，你无法进行有效的安全防护。必须在威胁与防御之间找到平衡。目标是拥有便宜的防御，但攻击成本却很高。互联网的副作用是，它大大降低了攻击成本，却没有降低防御成本。
- en: '***Trust***'
  id: totrans-19
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***信任***'
- en: One of the hardest things to do when determining a threat model is deciding
    what you can *trust*. Trust in a bygone era came from face-to-face interactions,
    although people still got taken by charismatic grifters. Deciding who and what
    to trust is much harder in the modern world. Can you recognize an honest Wi-Fi
    access point by looking it in the eyes? Not very likely, even if you know where
    to find its eyes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定威胁模型时，最难做的事情之一就是决定你可以*信任*什么。过去，信任来自面对面的互动，尽管人们仍然会被富有魅力的骗子所欺骗。在现代社会，决定信任谁和什么要困难得多。你能通过盯着Wi-Fi接入点看它的眼睛来识别它是否诚实吗？即使你知道如何找到它的眼睛，可能也不太容易。
- en: You know how important trust is if you’ve ever asked friends to keep a secret.
    There’s a 50/50 chance that a friend will violate your trust. Probability math
    tells us that there’s a 75 percent chance that your secret will get out if you
    tell it to two friends. The odds of your secret getting out increase with each
    friend; it’s 87 percent with three friends, 94 with four, 97 with five, and so
    on. You can see that putting trust in anything that you don’t control reduces
    security; it starts off bad and gets worse from there.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经要求朋友保守秘密，你就知道信任有多重要。朋友违反你信任的几率是50/50。概率学告诉我们，如果你告诉两个朋友你的秘密，你的秘密泄露的概率是75%。随着朋友数的增加，秘密泄露的几率也增加；三个朋友是87%，四个朋友是94%，五个朋友是97%，以此类推。你可以看到，把信任寄托在你无法控制的事物上会降低安全性；一开始就不好，后面只会更糟。
- en: With friends, you get to decide who is worthy of your trust. Your ability to
    make that choice is very limited in the networked computer world. For example,
    if you’re one of those rare people who reads terms and conditions before accepting,
    you might have noticed that almost all of them say something like “Your privacy
    is very important to us. As a result, you’re going to hold us harmless for breaches
    of your privacy.” Doesn’t sound very trustworthy. But you have no choice if you
    want to use the service.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于朋友，你可以决定谁值得信任。在网络化的计算机世界中，你做出这个选择的能力是非常有限的。例如，如果你是那种在接受之前会阅读条款和条件的少数人之一，你可能已经注意到，几乎所有的条款都说类似“您的隐私对我们非常重要。因此，您将不会因为隐私泄露而追究我们的责任。”这听起来不太可信。但如果你想使用这项服务，你别无选择。
- en: In the computer security world, *trust* refers to those components that you
    have no choice but to rely on. Your security depends on the security of those
    components. As you saw earlier, you want to keep these to the absolute minimum
    necessary for the greatest security.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机安全领域，*信任*是指那些你无法选择、只能依赖的组件。你的安全性取决于这些组件的安全性。正如你之前看到的，你希望将这些依赖降到最低，以确保最大的安全性。
- en: When you’re using computers, you’re relying on a huge collection of third-party
    hardware and software. You don’t have access to the hardware or the software and
    have no choice but to rely on them, even though they’ve done nothing to earn your
    trust. Even if you had access, would you really have the time and knowledge to
    review it all?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用计算机时，你依赖于大量第三方硬件和软件。你无法访问这些硬件或软件，只能依赖它们，尽管它们并没有做任何事情来赢得你的信任。即使你能访问，你真的有时间和知识来审查它们吗？
- en: 'The notion of trust comes up again and again in security. For now, consider
    three classes of trust violations:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 信任的概念在安全领域中反复出现。现在，考虑三类信任违反：
- en: '**Deliberate** Examples include the 2005 *rootkit* (a collection of software
    that bypasses protections) that Sony BMG installed on customers’ computers and
    the pop-up ad delivering *malware* (malicious software) in Lenovo laptops a few
    years ago. These weren’t programs accidentally installed by users; they were installed
    by the computer suppliers.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**故意** 故意的例子包括2005年索尼BMG在客户电脑上安装的*rootkit*（一类绕过保护的软件集合），以及几年前联想笔记本中弹出的广告传播的*恶意软件*（有害软件）。这些并不是用户意外安装的程序，而是由计算机供应商安装的。'
- en: '**Incompetent** Examples of incompetence include unencrypted wireless tire
    pressure sensors that make it possible for your car to be targeted, the unencrypted
    RFID tags in newer U.S. passports that make it simple to detect someone carrying
    one or the proposed vehicle-to-vehicle communications standards being discussed
    for “safety” that would allow vehicles to be targeted by bad information. Attackers
    have found a way to get access to and change the settings in a large number of
    Wi-Fi routers without having to know the administrator password. In the extremely
    dangerous category, Siemens included a hardcoded password in some of its industrial
    control systems, meaning that anyone with that password could access equipment
    that was thought to be supposedly secured. A hardcoded password was just found
    in some of Cisco’s products as well. The largest DDoS (discussed shortly) attack
    to date leveraged default passwords in IoT devices made by Hangzhou XiongMai.
    These sadly all harken back to the “What could possibly go wrong?” threat model
    combined with the “security by obscurity” mindset (more on this in a moment).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**无能** 无能的例子包括未加密的无线轮胎压力传感器，这使得你的车可能成为攻击目标；美国新护照中的未加密RFID标签，使得携带者很容易被发现；以及正在讨论中的“安全”车与车之间通信标准，这些标准可能允许车辆受到错误信息的攻击。攻击者已找到一种方法，能够在无需知道管理员密码的情况下获取并更改大量Wi-Fi路由器的设置。在极其危险的类别中，西门子在其一些工业控制系统中硬编码了密码，这意味着任何拥有该密码的人都可以访问本应安全的设备。思科的某些产品中也发现了硬编码的密码。迄今为止，最大的DDoS（稍后讨论）攻击利用了杭州雄迈公司生产的IoT设备中的默认密码。这些不幸的事件都回到了“有什么可能出错呢？”的威胁模型，以及“安全性通过模糊性”心态（稍后会详细讨论）。'
- en: '**Disingenuous** This is when people flat out lie. I talk about this more in
    “[The Social Context](ch13.xhtml#ch13lev2sec7)” on [page 359](ch13.xhtml#page_359).
    A good example is when the American National Institute of Standards and Technology
    (NIST) was working on encryption standards with the assistance of “experts” from
    the American National Security Agency (NSA). It turns out that the NSA experts
    deliberately weakened the standard instead of strengthening it. This made it easier
    for them to spy while also making it easier for someone to break into your bank
    account. Trust violations are so common that the term *kleptography* has been
    coined to describe the class of violations in which an adversary secretly and
    securely steals information.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**不诚实** 这指的是人们直接撒谎。我在《[社会背景](ch13.xhtml#ch13lev2sec7)》一章中详细讨论了这一点，参见[第359页](ch13.xhtml#page_359)。一个好的例子是，当美国国家标准与技术研究所（NIST）与美国国家安全局（NSA）的“专家”合作制定加密标准时，结果是NSA的专家故意削弱了该标准，而不是加强它。这使得他们更容易进行间谍活动，同时也使得别人更容易入侵你的银行账户。信任违规行为如此普遍，以至于有了“*窃密*”这一术语，用来描述敌人秘密且安全地窃取信息的行为。'
- en: The phrase *security by obscurity* is used to categorize claims that things
    are secure because the secret sauce is, well, secret. That’s been repeatedly demonstrated
    not to be the case. In fact, better security comes from *transparency* and *openness*.
    When as many people as possible are educated about the security methods being
    used, it fosters discussion and discovery of flaws. History tells us that no one
    person is perfect or will think of everything. In computer programming, we sometimes
    call this the *thousands of eyeballs principle*. This is evident in the industry
    statistic that Windows has a hundred times more critical vulnerabilities than
    Linux.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*安全性通过模糊性*这一短语用来描述一种观点，即事物之所以安全，是因为其秘密手段，嗯，就是秘密。实际上，这种观点已经被多次证明是错误的。事实上，更好的安全性来自于*透明性*和*开放性*。当尽可能多的人了解正在使用的安全方法时，它会促进讨论和发现缺陷。历史告诉我们，没有任何一个人是完美的，或者能想到所有的事情。在计算机编程中，我们有时将其称为*千人眼睛原则*。这一点在业内统计数据中得到了体现：Windows的关键漏洞比Linux多出一百倍。'
- en: This stuff isn’t easy; it sometimes takes years or even decades to discover
    security issues, even when smart people are looking for them. For example, the
    recent “Spectre” and “Meltdown” exploits have their genesis in CPU architectural
    design decisions made in the 1960s.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题并不容易解决；有时候即使是聪明的人也需要花费多年，甚至几十年的时间，才能发现安全问题。例如，最近的“幽灵”（Spectre）和“熔断”（Meltdown）漏洞，其根源可以追溯到1960年代在CPU架构设计中的决策。
- en: '***Physical Security***'
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***物理安全***'
- en: Think about a school locker. You put your belongings in it to keep them safe
    from other people. It’s made of fairly heavy steel and designed to be hard to
    pry open. Security folks would call the door an *attack surface* because it’s
    something that someone trying to break into your locker can attack. It’s a pretty
    good response to the threat of theft, because you can’t break it open without
    making a lot of noise. Lots of people are around during the day when your stuff
    is in your locker, and they would probably notice. Although someone could break
    in after hours, it’s less likely that things of value would be in the locker at
    those times.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下一个学校的储物柜。你把个人物品放在里面，以防被其他人拿走。它是由相当重的钢铁制成的，设计上很难被撬开。安全人员会称这个门为*攻击面*，因为它是别人试图破坏你储物柜时可以攻击的部分。对于盗窃威胁来说，这是一种相当不错的防御措施，因为你无法在不发出很大声音的情况下撬开它。白天有很多人在周围，当你的东西在储物柜里时，他们可能会注意到。如果有人在非上课时间偷溜进去，东西也很可能没有在柜子里。
- en: The combination lock on the door opens only with the correct combination, which
    you know. When the school gave you the combination, they gave you *authorization*
    to open that particular locker. The lock is another attack surface. The lock is
    designed so that breaking the dial off doesn’t cause it to open and so that it’s
    hard to get to the innards of the lock with the locker closed. Of course, now
    some new issues arise. You need to keep the combination secret. You can write
    it down on a piece of paper somewhere, but someone else might find it. You have
    to make sure that someone else doesn’t learn your combination by watching you
    open your locker. And, as you know from watching movies, safecrackers can open
    combination locks, and it’s not practical for the school to spend the money for
    really good locks. Devices called *autodialers* can be attached to a combination
    lock to try all the possible combinations. They used to be specialty devices,
    but people have built their own using small, inexpensive microcomputers such as
    Arduinos combined with cheap stepper motors. But just like with the door, enough
    people are roaming the halls that a break-in attempt would likely be noticed.
    It would take either a talented safecracker or a bad lock design (as many “tough-looking”
    locks are all show). Note that there is a popular brand of combination lock that
    can easily be opened in less than a minute by anyone with easily obtainable knowledge.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 门上的密码锁只有在输入正确的密码时才能打开，而你知道这个密码。当学校给你密码时，他们授予了你*授权*，允许你打开这个特定的储物柜。锁也是另一种攻击面。这个锁的设计使得撬掉旋转盘并不会让它打开，而且在储物柜关闭的情况下，很难接触到锁的内部。当然，现在有些新问题出现了。你需要保密密码。你可以把它写在纸上，但别人可能会发现它。你还得确保别人不会通过看你打开柜子来学到你的密码。而且，正如你在电影里看到的，开锁专家能够打开密码锁，而学校也不可能花大钱购买非常好的锁。可以通过设备叫做*自动拨号器*，将其连接到密码锁上，尝试所有可能的组合。以前这些设备是专用的，但人们已经用小型、廉价的微型计算机（如Arduino）和便宜的步进电机，自己动手制作了这类设备。但就像门一样，走廊里有足够多的人，一旦有人尝试破门而入，很可能会被注意到。这可能需要一个有才华的开锁专家，或者是一个不够坚固的锁设计（因为许多“看起来坚固”的锁其实都是空有其表）。值得注意的是，有一种流行的密码锁品牌，任何人只需具备一些容易获得的知识，就能在不到一分钟的时间内轻松打开它。
- en: There’s a third attack surface that may have escaped your notice. There’s a
    keyhole in the middle of the lock. It’s what security people would call a *backdoor*,
    even though in this case it’s on the front door. It’s another way of getting into
    your locker that’s not under your control. Why is it there? Obviously the school
    knows the combination to your locker, or they wouldn’t have been able to give
    it to you. This backdoor is there for their convenience so that they can quickly
    open everybody’s lockers. But it reduces everybody’s security. Locks with keyholes
    are pretty easy to pick in seconds. And because one key opens everybody’s locker,
    they’re all vulnerable if someone gets a copy of the key, which isn’t as hard
    as you might think.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 还有第三个攻击面，可能你没有注意到。锁的中间有个钥匙孔。这就是安全人员所说的*后门*，尽管在这个情况下，它是在前门。这是另一种进入你储物柜的方式，不受你控制。为什么它在那里？显然学校知道你储物柜的密码，否则他们不可能把密码告诉你。这个后门是为了他们的便利，方便他们快速打开每个人的储物柜。但它降低了每个人的安全性。带有钥匙孔的锁很容易在几秒钟内被撬开。而且因为一把钥匙能打开每个人的储物柜，如果有人拿到了钥匙副本，大家都会变得脆弱，这并不像你想的那么难。
- en: When the school gave you the combination to your locker, they conferred a *privilege*
    on you—namely, the ability to get into your locker. Someone with the key has a
    higher *privilege level*, as they’re authorized to open all lockers, not just
    one. Acquiring a copy of the key would raise your privilege level. Many budding
    engineers, including this author, discovered locksmithing and found ways to become
    “privileged” in our youths.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当学校给你储物柜的密码时，他们授予了你一个*特权*——也就是你可以进入你的储物柜的能力。拥有钥匙的人有更高的*特权等级*，因为他们有权限打开所有储物柜，而不仅仅是一个。获得钥匙的副本会提高你的特权等级。许多年轻的工程师，包括本文作者，在青春期时发现了锁匠技术，并找到了“获得特权”的方法。
- en: '***Communications Security***'
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***通信安全***'
- en: Now that we’ve learned a little about keeping stuff secure, let’s tackle a harder
    problem. How do you transfer something of yours to someone else? Let’s start with
    an easy case. You have a homework assignment about Orion that’s due, but you have
    to miss class for a doctor’s appointment. You see your friend Edgar in the hall
    and ask him to turn in your homework for you. Seems simple enough.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学了一些如何保护东西的知识，接下来我们要解决一个更难的问题。如何把你的一些东西转交给别人？我们从一个简单的例子开始。你有一个关于猎户座的作业，但你因为要去看医生而不能上课。你在走廊上看到你的朋友艾德加，便请求他代你交作业。看起来很简单。
- en: The first step in this process is *authentication*. This is you recognizing
    that the person you’re handing your homework to is indeed Edgar. But in your rush,
    you may have forgotten that Edgar has an evil twin brother. Or “Edgar” could be
    something wearing Edgar, like an Edgar suit. You really don’t want to accidentally
    authenticate something buggy (see the 1997 movie *Men in Black*)!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的第一步是*认证*。这就是你确认你交作业的对象确实是艾德加。但在你匆忙之中，你可能忘记了艾德加有一个邪恶的双胞胎兄弟，或者“艾德加”可能是穿着艾德加衣服的某个东西。你可不想不小心认证了一个有问题的东西（参见1997年电影《*黑衣人*》）！
- en: Edgar impersonators aren’t the only attack surface. All bets are off once your
    homework is out of your hands; you’re trusting Edgar to act in your best interest.
    But Edgar could space out and forget to hand it in. Evil Edgar could change your
    homework so that some of the answers are wrong, or worse, he could make it look
    like you copied someone else’s work. There’s no way to prove *authenticity*—that
    Edgar turned in what you handed him. If you had planned ahead, you could have
    put your homework into an envelope secured by a wax seal. Of course, these can
    often be opened and resealed without leaving a trace.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 艾德加的冒充者并不是唯一的攻击面。一旦你的作业离开了你的手，你就把信任交给了艾德加，让他代表你行事。但艾德加可能会分心，忘记交作业。邪恶的艾德加可能会篡改你的作业，弄错一些答案，或者更糟的是，他可能会让作业看起来像是你抄袭了别人的工作。无法证明*真实性*——无法证明艾德加交了你交给他的作业。如果你提前做好准备，你可以把作业放进一个用蜡封住的信封里。当然，这些信封通常可以在不留下痕迹的情况下被打开并重新封好。
- en: This becomes a much more difficult problem when you don’t have an authenticated,
    *trusted* courier delivering your homework. Maybe you had an unplanned absence
    and your teacher said that you could mail in your homework. Any number of unknown
    people may handle your letter, making it vulnerable to a *man-in-the-middle attack*,
    which is when an attacker gets between parties and intercepts and/or modifies
    their communications. You don’t know who’s handling your mail, and, unlike with
    Edgar, you don’t even have an opportunity for authentication.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当你没有一个经过身份认证的、*可信任的* 快递员送交你的作业时，这个问题就变得更加困难了。也许你因为突发情况缺席了，老师说你可以邮寄作业过去。不知道多少陌生人可能会处理你的信件，这使得它容易受到
    *中间人攻击* 的威胁，这种攻击是指攻击者在两个通信方之间插入并截取和/或修改它们的通信。你不知道谁在处理你的邮件，而且，与埃德加不同的是，你甚至没有机会进行身份验证。
- en: The solution to these issues is *cryptography*. You can *encrypt* your communication
    using a secret code known only to you and the intended recipient, who can use
    that code to *decrypt* it. Of course, like your locker combination, the secret
    code must be kept secret. Codes can be broken, and you have no way to know if
    someone knows or broke your code. A properly designed *cryptosystem* reduces the
    need to trust components between parties; leaked communications that can’t be
    read aren’t as big a risk.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的解决方案是 *密码学*。你可以使用只有你和预期接收者知道的秘密代码来 *加密* 你的通信，接收者可以用该代码来 *解密* 它。当然，就像你的储物柜组合密码一样，秘密代码必须保密。密码是可以被破解的，而你无法知道是否有人知道或破解了你的代码。一个设计良好的
    *密码系统* 可以减少在各方之间信任组件的需求；泄露的无法阅读的通信并不会带来如此大的风险。
- en: Codes get changed when their users figure out that they’ve been broken. An interesting
    aspect of World War II code breaking was the various ruses concocted to camouflage
    actions resulting from broken codes. For example, sending out an airplane to “accidentally”
    spot fleet movements so that the fleet could be attacked hid the fact that code
    breaking was how the location of the fleet was actually determined. Neal Stephenson’s
    novel *Cryptonomicon* is a highly entertaining read about this type of information
    security.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户发现它们已经被破解时，代码就会发生变化。二战期间密码破译的一个有趣方面是为了掩盖因破译密码而引起的行动而编造的各种诡计。例如，派出一架飞机“意外地”发现舰队的移动，以便进攻，隐藏了舰队位置实际上是通过密码破译确定的事实。尼尔·斯蒂芬森的小说
    *Cryptonomicon* 十分有趣地讲述了这种信息安全类型。
- en: '***Modern Times***'
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***现代时代***'
- en: The “connected computer” age combines the problems of physical security with
    those of communications security. Psychedelic cowboy, poet, lyricist, and futurist
    John Perry Barlow (1947–2018) remarked that “cyberspace is where your money is”
    during a 1990 SIGGRAPH panel. And it’s not just your money. People used to purchase
    music on records or CDs and movies on videotape or DVDs. Now, this entertainment
    is mostly just bits on a computer. And of course, banking has moved online.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: “联网计算机”时代结合了物理安全和通信安全的问题。迷幻牛仔、诗人、作词家和未来学家约翰·佩里·巴洛（1947-2018）在1990年SIGGRAPH小组讨论中曾说过“网络空间就是你的钱”。而且不仅仅是你的钱。人们过去购买唱片或CD上的音乐，以及录像带或DVD上的电影。现在，这些娱乐内容大多只是计算机上的数据。当然，银行业务也已经搬到了网上。
- en: It would be one thing if those bits were just sitting on your various computers.
    But your computers, including your phone, are connected to the global internet.
    This is such a huge attack surface that you have to assume that trust will be
    violated in at least one place. And the attackers are essentially invisible.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些数据仅仅保存在你的各种计算机上，那就没什么大不了的。但是你的计算机，包括手机，都连接到全球互联网。这是一个如此巨大的攻击面，以至于你必须假设信任至少会在某一个地方被违反。而且攻击者基本上是看不见的。
- en: In ancient times, someone who wanted to annoy you could ring your doorbell and
    run away. You had a good chance of catching them if you were in the right place
    at the right time and could see them. And there was a limit to how many times
    someone could do that in a day. On the internet, even if you could see the annoying
    attacker, there’s not much you could do about it. The attackers are rarely even
    people anymore; they’re programs. Because they’re programs, they can try to break
    into your machines thousands of times per second. That’s a whole different game.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在古代，想要惹恼你的人可以按门铃然后逃跑。如果你在合适的时间和地点能看到他们，你有很大机会抓住他们。而且一个人一天能这样做的次数是有限的。但是在互联网上，即使你能看到这个惹人讨厌的攻击者，你也无能为力。攻击者现在很少是真正的人，它们是程序。因为它们是程序，它们可以每秒尝试成千上万次地入侵你的机器。这是一个完全不同的游戏。
- en: Attackers don’t need to break into a machine in order to cause problems. If
    our doorbell ringer were persistent enough, they’d block others from reaching
    your door. This is called a *denial of service (DoS)* attack, because it keeps
    legitimate folks away. This could put you out of business if you’re running a
    store. Most attacks of this nature today are *distributed denial of service (DDoS)*,
    where large numbers of bell ringers coordinate their actions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者不需要破坏机器才能制造问题。如果我们的门铃足够顽固，它们会阻止其他人到达你的门口。这种攻击被称为*拒绝服务（DoS）*攻击，因为它使合法用户无法访问。这种攻击如果发生在商店运营中，可能会让你破产。如今，大多数这类攻击是*分布式拒绝服务（DDoS）*攻击，成千上万的门铃铃声协调一致地行动。
- en: One of the things that makes tracking attackers mostly useless is that they’re
    often using *proxies*. Launching millions of attacks from their own computer would
    leave a trail that would be easy to follow. Instead, attackers break into a few
    machines, install their software (often called *malware*), and let these other
    machines do their dirty work for them. This often takes the form of a multilevel
    tree containing millions of compromised machines. It’s much harder to catch the
    relatively few *command and control* messages that tell the other compromised
    machines what to do. And attack results don’t have to be sent back to the attacker;
    they can just be posted on some public website in encrypted form, where the attacker
    can fetch them at their convenience.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使追踪攻击者大多无效的原因之一是攻击者通常使用*代理*。从他们自己的计算机发起数百万次攻击会留下容易追踪的痕迹。相反，攻击者会侵入几台机器，安装他们的软件（通常称为*恶意软件*），然后让这些机器替他们做脏活。这通常表现为一个多层次的树状结构，包含数百万台被攻陷的机器。捕捉这些相对较少的*指挥与控制*信息（告诉其他被攻陷机器该做什么）要困难得多。而且攻击结果不必返回给攻击者；它们可以以加密形式发布到某个公共网站，攻击者可以随时方便地取回。
- en: How is all this possible? Primarily because a large number of machines in the
    world run software from Microsoft, which set a standard for buggy and insecure
    software. This wasn’t accidental. In an October 1995 *Focus* magazine interview,
    Bill Gates said, “I’m saying we don’t do a new version to fix bugs. We don’t.
    Not enough people would buy it.” Microsoft has made some recent improvements,
    and it’s also losing market dominance in the insecure software sector to Internet-of-Things
    devices, many of which have more processing power than was available on a desktop
    computer not that long ago.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切怎么可能发生呢？主要是因为全球有大量机器运行微软的软件，而微软为错误百出的不安全软件设定了标准。这不是偶然的。在1995年10月的*Focus*杂志采访中，比尔·盖茨曾说：“我说的是我们不发布新版本来修复漏洞。我们不会。没有足够多的人会为此购买它。”微软最近做了一些改进，而且它在不安全软件领域的市场主导地位正在被物联网设备所取代，许多物联网设备拥有的处理能力甚至超过了不久前台式计算机的能力。
- en: There are two major classes of attacks. The first, breaking a cryptography system,
    is relatively rare and difficult in a well-designed system. Much more common are
    “social” attacks in which a user is tricked into installing software on their
    system. The best cryptography can’t protect you if some malicious piece of code
    that you installed is watching you type your password. Some common social attack
    mechanisms represent some of the dumbest things ever done by supposedly smart
    people—running arbitrary programs sent via email or contained on whatever USB
    drive you find on the ground, for example, or plugging your phone into a random
    USB port. What could possibly go wrong? These avoidable mechanisms are being replaced
    by attacks via web browsers. Remember from [Chapter 9](ch09.xhtml#ch09) how complex
    these are.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有两类主要的攻击方式。第一类是破解加密系统，这在设计良好的系统中相对较少且困难。更常见的是“社交”攻击，即用户被欺骗安装某些软件到系统中。如果你安装了某个恶意代码，它在监听你输入密码时，即使是最好的加密技术也无法保护你。一些常见的社交攻击机制代表了那些自认为聪明的人所做的最愚蠢的事情——例如，运行通过电子邮件发送的任意程序或你在地上捡到的任何
    USB 驱动器上的程序，或者将手机插入随机的 USB 端口。可能会有什么问题呢？这些可以避免的攻击方式正在被通过浏览器的攻击所取代。记得在[第9章](ch09.xhtml#ch09)中提到这些攻击有多复杂吗？
- en: One example of an extremely clever and dangerous attack was a 2009 online banking
    exploit. When someone logged into their bank account, the attack would transfer
    some of their money out of their account. It would then rewrite the web page coming
    back from the bank so that the transfer wouldn’t be detected by the account owner.
    This made the theft something you’d never notice unless you still received paper
    statements and carefully checked them.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一个极其巧妙且危险的攻击例子是2009年的在线银行攻击。当有人登录到他们的银行账户时，攻击会将他们账户中的一部分钱转移出去。然后，它会重写从银行返回的网页，使得账户持有者无法发现这笔转账。这使得盗窃行为几乎无法察觉，除非你还收到纸质账单并仔细检查。
- en: Another modern-era problem is that messing with bits can have physical repercussions.
    In the name of progress or convenience, all sorts of critical infrastructure is
    connected to the internet now. This means an attacker can make a power plant fail
    or simply turn off the heat in your house in winter so the pipes freeze. And,
    with the rise of robotics and the Internet of Things, an attacker could potentially
    program your vacuum cleaner to terrorize your cats or set off burglar alarms when
    you’re away.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个现代问题是，操控比特数据可能会带来物理后果。以进步或便利的名义，所有类型的关键基础设施如今都连接到互联网。这意味着攻击者可以让发电厂瘫痪，或者仅仅是在冬天关闭你家里的暖气，让管道冻结。而随着机器人技术和物联网的发展，攻击者甚至可能编程你的吸尘器去吓唬你的猫，或者在你不在时触发防盗警报。
- en: Finally, modern technology has greatly complicated the ability to determine
    whether something is authentic. It’s pretty trivial to create *deep* *fakes*—realistic
    fake photographs, audio, and video. There’s a theory that a lot of the current
    batch of robocalls is just harvesting voice samples so that they can be used elsewhere.
    How long will it be before voice-search data is converted into robocalls that
    sound like one of your friends is calling?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，现代技术极大地增加了判断某物是否真实的复杂性。制作*深度* *伪造*——逼真的虚假照片、音频和视频，已经变得相当容易。有一种理论认为，目前大量的自动拨号电话只是用来收集声音样本，以便在其他地方使用。多久之后，语音搜索数据会被转化为自动拨打电话，听起来就像是你的朋友在打电话给你呢？
- en: '***Metadata and Surveillance***'
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***元数据与监控***'
- en: There’s another big change brought about by modern technology. Even if cryptography
    can keep the contents of communications secret, you can learn a lot by observing
    patterns of communication. As the late Yogi Berra said, “You can observe a lot
    by just watching.” For example, even if nobody ever opens your letters, someone
    can glean a lot by examining who you’re writing to and who’s writing to you, not
    to mention the size and weight of the envelopes and how often they’re sent. This
    is unavoidable in America where the post office photographs every piece of mail.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现代技术带来了另一个巨大的变化。即使加密技术能够保持通信内容的机密性，通过观察通信模式，你仍然能获得大量信息。正如已故的尤吉·贝拉所说：“光是观察，你就能学到很多。”例如，即使没人打开你的信件，通过检查你写给谁以及谁给你写信，就能获得很多信息，更不用说信封的大小、重量以及它们发送的频率。这在美国是不可避免的，因为邮局会拍摄每一封邮件的照片。
- en: The information on the outside of the envelope is called *metadata*. It’s data
    about the data, not the data itself. Someone could use this information to deduce
    your network of friends. That may not sound so bad to you if you live in a modern
    Western society. But imagine for a minute if you and your friends lived in a more
    oppressive society, where having this information about you known could endanger
    your friends. An example of this is China’s “social credit” score.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 信封外部的信息被称为*元数据*。它是关于数据的数据，而不是数据本身。有人可以利用这些信息推断出你的朋友圈。如果你生活在一个现代西方社会，这可能听起来不算什么问题。但试想一下，如果你和你的朋友生活在一个更压迫的社会里，知道这些信息可能会危及你们的朋友。中国的“社会信用”分数就是一个例子。
- en: Of course, hardly anybody needs to do such things by tracking mail anymore.
    They can just look at your social media friends. Makes the job much easier. Also,
    tracking you and yours no longer depends on having a lot of manpower. Nobody has
    to follow you when you leave your house because your online activities can be
    tracked remotely, and your movements in the real world can be tracked using an
    increasing variety of spy cameras. Of course, if you carry a cell phone, you’re
    tracked all the time because the information that’s used to make the cell phone
    system function is metadata too.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，几乎没有人再需要通过追踪邮件来做这些事情了。他们只需要查看你的社交媒体朋友，这样工作变得轻松多了。此外，追踪你和你的人再也不需要大量的人力了。当你离开家时，没有人需要跟踪你，因为你的在线活动可以远程追踪，而你在现实世界中的行动也可以通过日益增多的监控摄像头进行追踪。当然，如果你携带手机，你随时都在被追踪，因为用于使手机系统正常运行的信息也是元数据。
- en: '***The Social Context***'
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***社会背景***'
- en: It’s hard to talk about security without getting political. That’s because there
    are really two prongs to security. One is the techniques for building robust security.
    The other is trading off one’s personal security against the security of society
    as a whole. That’s where it gets complicated, because it’s hard to discuss technical
    measures absent societal goals.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论安全问题时，很难不涉及政治。这是因为安全问题有两个方面。一方面是建立强大安全防护的技术；另一方面是将个人安全与社会整体安全之间做权衡。正是在这点上问题变得复杂，因为在没有社会目标的背景下，很难讨论技术手段。
- en: Not only is security a social issue, but it’s different from country to country
    because of different laws and norms. That gets especially complicated in an age
    where communications easily cross national borders and are subject to different
    regulations. There’s no intent to start a political argument here; it’s just that
    you can’t discuss security from a solely technological perspective. The political
    part of this chapter is written from a mostly American perspective.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 安全不仅是一个社会问题，而且因为不同国家的法律和规范不同，它在国家间存在差异。在一个通讯轻松跨越国界并且受不同法规约束的时代，这种问题变得尤为复杂。这里没有意图引发政治争论；问题在于，你无法仅从技术角度讨论安全。本章的政治部分主要是从美国的视角写的。
- en: It’s a common misperception that “national security” is enshrined in the US
    Constitution. This is understandable because courts routinely dismiss cases about
    constitutional rights when government officials raise the specters of “national
    security” and “state secrets.” The Fourth Amendment to the US Constitution has
    the clearest expression of national security when it says, “The right of the people
    to be secure in their persons, houses, papers, and effects against unreasonable
    searches and seizures, shall not be violated.” Unfortunately, *unreasonable* wasn’t
    defined, probably because reasonable people understood it at the time. Note that
    this amendment confers security on the people, not the state—that whole “by the
    people, for the people” thing.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 认为“国家安全”是美国宪法中所规定的权利是一个常见的误解。这是可以理解的，因为法院通常在政府官员提到“国家安全”和“国家机密”时驳回关于宪法权利的案件。美国宪法第四修正案在表达国家安全时最为明确，其中写道：“人民在其人身、住宅、文件和物品上的安全，不得受不合理搜查和扣押的侵犯。”不幸的是，*不合理*没有被定义，可能是因为当时理智的人们已经理解了这个意思。请注意，这一修正案赋予的是人民的安全，而不是国家的安全——那种“为人民，来自人民”的精神。
- en: The heart of the issue is whether or not the government’s duty to protect people
    is stronger than the rights of those people.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 问题的核心在于，政府保护人民的责任是否比人民的权利更重要。
- en: Most people would like to be able to relax knowing that someone else was keeping
    them safe. One could consider it a social contract. Unfortunately, that social
    contract has been undermined by violations of trust.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数人希望能放松心情，知道有人在保护他们的安全。这可以被视为一种社会契约。不幸的是，这种社会契约已经因为信任被侵犯而受到削弱。
- en: There’s a bias, completely unsupported by fact, that people in government are
    “better” or “more honest” than everyone else. At best, they’re like people everywhere;
    some are good, some are bad. There’s more than enough documented evidence of law
    enforcement personnel committing crimes. An aggravating factor is secrecy; positions
    lacking oversight and accountability tend to accumulate bad people, which is exactly
    why the notions of transparency and openness are the foundation of a good trust
    model. For example, as part of mind-control experiments in the 1960s, the CIA
    illegally dosed men with LSD and observed their reactions. Known as MKUltra, this
    program had no oversight and led to at least one known death of an unwitting test
    subject. After MKUltra was shut down, agent George White said, “Where else could
    a red-blooded American boy lie, kill, cheat, steal, rape, and pillage with the
    sanction and blessing of the All-Highest?” And the FBI under J. Edgar Hoover had
    quite the history of political abuse—not just spying for political purposes but
    actively sabotaging perceived enemies.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一种完全没有事实依据的偏见，认为政府中的人“比其他人更好”或“更诚实”。充其量，他们和世界上其他地方的人一样；有些人好，有些人坏。已经有足够多的证据记录了执法人员犯罪的行为。一个令人恼火的因素是保密性；缺乏监督和问责制的职位往往会吸引不良人员，这正是透明性和开放性作为良好信任模型基础的原因。例如，作为1960年代的精神控制实验的一部分，CIA非法给男性服用了LSD并观察他们的反应。这个项目被称为MKUltra，缺乏监督，导致至少一名无知的测试对象死亡。MKUltra被关闭后，特工乔治·怀特曾说：“还有哪里可以让一个充满活力的美国男孩，在最高的授权和祝福下撒谎、杀人、作弊、偷窃、强奸和掠夺？”而由J.埃德加·胡佛领导的FBI则有着相当复杂的政治滥用历史——不仅仅是出于政治目的的间谍行为，还包括积极破坏他们认为的敌人。
- en: In case you’ve been sleeping under a rock, more and more trust abuses have recently
    come to light, and these are likely only a small fraction of actual abuses, given
    the secrecy and lack of oversight. Most relevant to this chapter are Edward Snowden’s
    revelations about illegal government surveillance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你最近没注意到，越来越多的信任滥用行为曝光出来，而且这些曝光的只是实际滥用行为的一个小部分，考虑到保密性和缺乏监督，实际的滥用可能更严重。与本章最相关的是爱德华·斯诺登关于非法政府监控的揭露。
- en: Without oversight, it’s difficult to tell whether government secrecy is covering
    up illegal activities or just incompetence. Back in 1998, the US government encouraged
    the use of an encryption scheme called the Data Encryption Standard (DES). The
    Electronic Frontier Foundation (EFF) built a machine called Deep Crack for about
    $250,000 (which was *way* less than the NSA budget) that broke the DES code. Part
    of the reason they did so was to be able to point out that either agency experts
    were incompetent or they were lying about the security of the algorithm. The EFF
    was trying to expose the disingenuous violation of trust perpetrated for the convenience
    of American spies. And it worked somewhat—while it didn’t change the behavior
    of the agency experts, it did spur the development of the Advanced Encryption
    Standard that replaced DES.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 没有监督的情况下，很难判断政府的保密行为是掩盖非法活动还是仅仅因为无能。早在1998年，美国政府就鼓励使用一种名为数据加密标准（DES）的加密方案。电子前沿基金会（EFF）花费约25万美元（*远远*低于NSA的预算）构建了一台名为Deep
    Crack的机器，成功破解了DES代码。他们这么做的部分原因，是为了能够指出无论是政府专家无能，还是他们在关于算法安全性的问题上撒谎。EFF试图揭露出为了美国间谍的方便而进行的不诚实的信任侵犯。虽然这种做法并没有改变政府专家的行为，但它确实促使了替代DES的高级加密标准（AES）的发展。
- en: It’s easy to argue that “it’s a dangerous world.” But if lots of bad folks were
    being caught by these secret programs, we’d be hearing about it. Instead, what
    we hear about is the entrapment of “clueless and broke” people who weren’t actual
    threats. Another thing people often say is, “I don’t care if the government looks
    at my stuff; I have nothing to hide.” That may be true, but it’s a reasonable
    guess that people saying that *do* want to hide their bank account password. It
    often seems like those raising the scariest arguments are actually the ones behaving
    badly.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易说“这是一个危险的世界”。但是如果这些秘密程序真能抓住大量坏人，我们肯定会听说的。相反，我们听到的是“无知且贫困”的人被陷害，他们根本不是威胁。另一个常有人说的是，“我不在乎政府查看我的东西；我没什么可隐瞒的。”这也许是真的，但可以合理猜测，讲这种话的人*确实*希望隐藏自己的银行账户密码。似乎那些提出最可怕论点的人，实际上是那些行为不端的人。
- en: Trust violations have international implications. There’s a reluctance to purchase
    products whose security might be compromised. Outsourcing poses threats too. There
    may be laws in your country protecting your information, but someone elsewhere
    might have access to that data. There have been cases of outsourced data being
    sold. There are recent indications that personal data acquired by outside actors
    has been used to meddle in political processes, possibly spelling the end of “Westphalian
    sovereignty.”
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 信任侵犯具有国际影响。人们不愿购买那些安全性可能受到威胁的产品。外包也带来威胁。虽然在你的国家可能有保护你信息的法律，但其他地方的人可能能访问这些数据。曾经有外包数据被出售的案例。最近有迹象表明，外部人员获取的个人数据已被用于干预政治过程，这可能意味着“威斯特伐利亚主权”的终结。
- en: Trust violations also impact freedom. A “chilling effect” results when people
    engage in self-censorship or become afraid of being tracked when meeting or communicating
    with others online. There’s plenty of historical evidence showing the impact of
    chilling effects on political movements.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 信任侵犯还会影响自由。当人们在与他人在线交流或会面时，因担心被追踪而进行自我审查，或感到害怕时，就会产生“寒蝉效应”。有大量历史证据表明，寒蝉效应对政治运动有深远影响。
- en: 'Modern cell phones have several different unlocking options: passcode or pattern,
    fingerprint reader, facial recognition. Which should you use? At least in America,
    I recommend using a passcode or pattern, even though they’re slightly less convenient.
    There are three reasons for this. First, some courts have interpreted the portion
    of the Fifth Amendment that states “No person . . . shall be compelled in any
    criminal case to be a witness against himself” to mean that you can’t be ordered
    to give “testimonial” information that’s in your head. In other words, you can’t
    be forced to divulge passwords, passcodes, patterns, and so on. But some courts
    have ruled that you *can* be compelled to provide your fingerprint or face. Second,
    there is a trust issue. Even if you don’t mind unlocking your phone on request,
    how do you know what your phone is doing with your fingerprint or facial data?
    Is it just unlocking your phone, or is it uploading it to databases for some future
    undisclosed uses? Will you start getting targeted ads when walking in front of
    stores that recognize your face? Third, plastic fingerprints and fake retinas,
    long staples of cheesy movies, have actually been demonstrated in real life. Biometric
    data is easier to fake than a password.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现代手机有多种解锁方式：密码或图案、指纹识别、面部识别。你应该选择哪种方式？至少在美国，我推荐使用密码或图案，尽管它们略微不那么方便。这有三个原因。首先，一些法院解读了第五修正案中的部分内容：“任何人……不得在任何刑事案件中被强迫成为对自己不利的证人”，意思是你不能被强迫提供存在你脑海中的“证词”信息。换句话说，你不能被强迫透露密码、密码图案、图案等。但一些法院裁定，你*可以*被迫提供指纹或面部信息。第二，存在信任问题。即使你不介意在别人要求下解锁手机，你怎么知道你的手机在处理你的指纹或面部数据时在做什么？它仅仅是解锁你的手机，还是将其上传到数据库中，供未来未公开的用途使用？你会不会在走过商店时，开始看到那些识别你面部的商店向你推送定向广告？第三，塑料指纹和假眼角膜，这些曾经是低劣电影的常见情节，实际上在现实生活中已经被证明是可行的。生物识别数据比密码更容易伪造。
- en: '***Authentication and Authorization***'
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***身份验证和授权***'
- en: I’ve mentioned authentication and authorization. *Authentication* is proving
    that someone or something is what it claims to be. *Authorization* is limiting
    access to something unless proper “credentials” are presented.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我提到过身份验证和授权。*身份验证*是证明某人或某物确实是它所声称的那样。*授权*则是限制对某些东西的访问，除非提供了适当的“凭证”。
- en: Authorization is arguably the easier of the two; it requires properly designed
    and implemented hardware and software. Authentication is much trickier. How can
    a piece of software tell whether it was you who entered a password or someone
    else?
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 授权无疑是两者中更简单的一种；它需要适当设计和实施的硬件和软件。身份验证则要复杂得多。一个软件怎么判断是你自己输入的密码，还是别人输入的？
- en: '*Two-factor authentication (2FA)* is now available on many systems. A *factor*
    is an independent means of verification. Factors include things hopefully unique
    to you (such as a fingerprint), things in your possession (for example, a cell
    phone), and things that you know (for example, passwords or PINs). Two-factor
    authentication therefore uses two of these. For example, using a bank card with
    a PIN or entering a password that sends a message to your phone to supply a one-time
    code. Some of these systems work better than others; obviously, sending a message
    to a cell phone that others can access isn’t secure. Parts of the cell phone infrastructure
    make relying on 2FA dangerous. Attackers can use your email address and other
    easily available information to port your phone number to a SIM card in a phone
    that they control. This not only gives them access to your data but locks you
    out.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，许多系统都提供*双重认证（2FA）*。*因素*是独立的验证手段。因素包括一些希望是独一无二的东西（例如指纹）、你所拥有的东西（例如手机）以及你所知道的东西（例如密码或PIN）。因此，双重认证使用其中的两种。例如，使用银行卡和PIN，或者输入一个密码后，系统会向你的手机发送一条消息，让你输入一次性密码。这些系统中有些比其他的更有效；显然，将信息发送到别人也能访问的手机上并不安全。手机基础设施的某些部分使得依赖2FA变得危险。攻击者可以利用你的电子邮件地址和其他容易获取的信息，将你的电话号码转移到他们控制的SIM卡上。这不仅让他们能够访问你的数据，还能将你锁在外面。
- en: '**Cryptography**'
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**加密术**'
- en: As I mentioned earlier, cryptography allows a sender to scramble a communication
    so that only the designated recipients can decode it. It’s pretty important when
    you’re taking money out of your bank account; you don’t want someone else to be
    able to do it too.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如我之前提到的，加密技术允许发送方对通信进行加扰，使得只有指定的接收者能够解码。当你从银行账户中取钱时，这非常重要；你肯定不希望别人也能做同样的事。
- en: Cryptography isn’t important just for privacy and security, however. Cryptographic
    signatures allow one to attest to the veracity of data. It used to be that physical
    originals could be consulted if there was some question as to the source of information.
    Those don’t often exist for documents, audio, video, and so on because the originals
    were created on computers and never reduced to physical form. Cryptographic techniques
    can be used to prevent and detect forgeries.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，加密技术不仅仅对隐私和安全重要。加密签名允许验证数据的真实性。以前，如果有人质疑信息的来源，可以查阅物理原件。但对于文档、音频、视频等来说，原件通常不存在，因为这些原件是在计算机上创建的，并未转化为物理形式。加密技术可以用来防止和检测伪造。
- en: Cryptography alone doesn’t turn your castle into a mighty fortress, though.
    It’s part of a security system, and all parts matter.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅靠加密技术并不能将你的城堡变成一座坚不可摧的堡垒。它是安全系统的一部分，而所有部分都很重要。
- en: '***Steganography***'
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***隐写术***'
- en: Hiding one thing within another is called *steganography*. It’s a great way
    to communicate secrets because there’s no traceable connection between the sender
    and the recipient. This used to be done through newspaper classified ads, but
    it’s now much easier to do online since there’s a near-infinite number of places
    to post.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 将一种事物隐藏在另一种事物中的做法被称为*隐写术*。这是一种非常好的秘密通讯方式，因为发送者和接收者之间没有可追踪的联系。以前通过报纸上的分类广告来实现，但现在在网上做这件事要容易得多，因为可以发布的地方几乎是无限的。
- en: Steganography is not technically cryptography, but it’s close enough for our
    purposes. Take a look at [Figure 13-1](ch13.xhtml#ch13fig01). On the left is a
    photo of Mister Duck and Tony Cat. In the center is that same photo that includes
    a hidden secret message. Can you tell the two photos apart? On the right is the
    secret message.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 隐写术在技术上并不是加密术，但对于我们的目的来说，它足够接近了。看看[图13-1](ch13.xhtml#ch13fig01)。左边是一张鸭先生和猫托尼的照片。中间是包含隐藏秘密信息的同一张照片。你能分辨出这两张照片吗？右侧是秘密信息。
- en: '![Image](../images/13fig01.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/13fig01.jpg)'
- en: '*Figure 13-1: Secret message hidden in image*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13-1：隐藏在图像中的秘密信息*'
- en: How was this accomplished? On the left is an 8-bit grayscale image. The center
    image was made by replacing the least significant bit on each pixel of the image
    with the corresponding least significant bit from the secret message on the right.
    Recovering the secret message, then, is just a matter of stripping away the seven
    most significant bits from the center image.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何实现的？左侧是一个8位灰度图像。中间的图像是通过将每个像素的最低有效位替换为右侧秘密信息中对应的最低有效位制作的。因此，恢复秘密信息的过程就是从中间图像中去除七个最高有效位。
- en: This isn’t the best way to hide a message. It would be much less obvious if
    the secret message were given in ASCII character codes instead of images of the
    characters. And it would be pretty much impossible to discover if the secret message
    bits were scattered throughout the image or encrypted. Another approach, recently
    published by researchers Chang Xiao, Cheng Zhang, and Changxi Zheng at Columbia
    University, encodes messages by slightly altering the shape of text characters.
    This isn’t a completely novel idea; “America’s first female cryptanalyst,” Elizebeth
    Smith Friedman (1892–1980), used a similar technique to include a secret message
    on her husband’s tombstone.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Steganograpy is used by advertisers to track web pages that you visit because
    they don’t get that “no means no” when you block ads. Many websites include a
    single-pixel image hidden on web pages linked to an identifying URL. This isn’t
    always innocuous; this type of tracking software was abused to accuse thousands
    of treason in Turkey in 2016.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: This technique isn’t limited to images. Secret messages could even be encoded
    as the number of blank lines in a blog posting or web page comment. Messages can
    be scattered among frames in a video or hidden in digital audio in a similar manner
    to the previous one-pixel example. One crazy-sounding example of the latter is
    *dog-whistle marketing*, in which web pages and ads play ultrasonic sounds, which
    are above the human audio range. These sounds can be picked up by the microphone
    on your cell phone, allowing advertisers to make connections between your various
    computing devices and determine what ads you have seen.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Steganography has other uses, too. For example, a studio might embed unique
    identifying marks in unreleased movies that it sends to reviewers. This would
    allow them to track down the source if the movie gets leaked. This use is akin
    to the practice of using a watermark on paper.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Steganography is used in almost every computer printer. The EFF received a document
    in response to a Freedom of Information Act request that suggests the existence
    of a secret agreement between governments and manufacturers to make sure that
    all printed documents are traceable. Color printers, for example, add small yellow
    dots to each page that encode the printer’s serial number. EFF distributed special
    LED flashlights that one could use to find them. This could be considered an invasion
    of privacy.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '***Substitution Ciphers***'
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If you ever had a secret decoder ring, it probably implemented a substitution
    *cipher*. The idea is pretty simple: you build a table that maps each character
    to another, such as that shown in [Figure 13-2](ch13.xhtml#ch13fig02). You *encrypt*
    a message by replacing each original character with its counterpart from the table
    and *decrypt* by doing the reverse. The original message is called *cleartext*,
    and the encrypted version is called *ciphertext*.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig02.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-2: Substitution cipher*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: This cipher maps *c* to *a*, *r* to *t*, *y* to *j*, and so on, so the word
    *cryptography* would be enciphered as *atjgvketqgnj*. The reverse mapping (*a*
    to *c*, *t* to *r*, and so on) deciphers the ciphertext. This is called a *symmetric*
    code, since the same cipher is used to both encode and decode a message.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Why isn’t this a good idea? Substitution ciphers are easy to break using statistics.
    People have analyzed how often letters are used in various languages. For example,
    in English the most common five letters are *e*, *t*, *a*, *o*, *n*, in that order—or
    at least they were when Herbert Zim (1909–1994) published *Codes & Secret Writing*
    in 1948\. Breaking a substitution cipher involves looking for the most common
    letter in the ciphertext and guessing that it’s an *e*, and so on. Once a few
    letters are guessed correctly, it’s easy to figure out some words, which makes
    figuring out other letters easy. Let’s use the plaintext paragraph in [Listing
    13-1](ch13.xhtml#ch13list01) as an example. We’ll make it all lowercase and remove
    the punctuation to keep it simple.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*Listing 13-1: Plaintext example*'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the same paragraph as ciphertext using the code from [Figure 13-2](ch13.xhtml#ch13fig02):'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[Listing 13-2](ch13.xhtml#ch13list02) shows the distribution of letters in
    the enciphered version of the paragraph. It’s sorted by letter frequency, with
    the most commonly occurring letter at the top.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Listing 13-2: Letter frequency analysis*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: A code breaker could use this analysis to guess that the letter `z` in the ciphertext
    corresponds to the letter `e` in the plaintext, since there are more of them in
    the ciphertext than any other letter. Continuing along those lines, we can also
    guess that `v` means `t`, `q` means `a`, `k` means `o`, and `x` means `n`. Let’s
    make those substitutions using uppercase letters so that we can tell them apart.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: From here we can do some simple guessing based on general knowledge of English.
    There are very few three-letter words that begin with *t* and end with *e*, and
    *the* is the most common, so let’s guess that `n` means `h`. This is easy to check
    on my Linux system, as it has a dictionary of words and a pattern-matching utility;
    `grep '^t.e$' /usr/share/dict/words` finds all three-letter words beginning with
    a `t` and ending with an `e`. Also, there is only one grammatically correct choice
    for the `c` in `cEET cE`, which is `m`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'There are only four words that match `o□`en: `omen`, `open`, `oven`, and `oxen`;
    only `open` makes sense, so `g` must be `p`. Likewise, the only word that makes
    sense in `to open the □`ate is `gate`, so `e` must be `g`. There’s only one two-letter
    word that begins with `o`, so `ow` must be `of`, making the `w` an `f`. The `j`
    must be a `y` because the words `and` and `ant` don’t work.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We don’t need to completely decode the message to see that statistics and knowledge
    of the language will let us do so. And so far we’ve used only simple methods.
    We can also use knowledge of common letter pairs, such as `th`, `er`, `on`, and
    `an`, called *digraphs*. There are statistics for most commonly doubled letters,
    such as `ss`, and many more tricks.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, simple substitution ciphers are fun but not very secure.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '***Transposition Ciphers***'
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another way to encode messages is to scramble the positions of the characters.
    An ancient transposition cipher system supposedly used by the Greeks is the *scytale*,
    which sounds impressive but is just a round stick. A ribbon of parchment was wound
    around the stick. The message was written out in a row along the stick. Extra
    dummy messages were written out in other rows. As a result, the strip contained
    a random-looking set of characters. Decoding the message required that the recipient
    wrap the ribbon around a stick with the same diameter as the one used for encoding.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: We can easily generate a transposition cipher by writing a message out of a
    grid of a particular size, the size being the key. For example, let’s write out
    the plaintext from [Listing 13-1](ch13.xhtml#ch13list01) on an 11-column grid
    with the spaces removed, as shown in [Figure 13-3](ch13.xhtml#ch13fig03). We’ll
    fill in the gaps in the bottom row with some random letters shown in italics.
    To generate the ciphertext shown at the bottom, we read down the columns instead
    of across the rows.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig03.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-3: Transposition cipher grid*'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: The letter frequency in a transposition cipher is the same as that of the plaintext,
    but that doesn’t help as much since the order of the letters in the words is also
    scrambled. However, ciphers like this are still pretty easy to solve, especially
    now that computers can try different grid sizes.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '***More Complex Ciphers***'
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There’s an infinite variety of more complex ciphers that are substitution ciphers,
    transposition ciphers, or combinations of the two. It’s common to convert letters
    to their numeric values and then convert the numbers back to letters after performing
    some mathematical operations on the numbers. Some codes include extra tables of
    numbers added in to inhibit letter-frequency analysis.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: The history of code breaking during World War II makes fascinating reading.
    One of the methods used to break codes was to listen to messages that were transmitted
    by radio. These *intercepts* were subjected to exhaustive statistical analysis
    and were eventually broken. The human mind’s ability to recognize patterns was
    also a key factor, as was some clever subterfuge.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Clues were also gleaned from messages that were sent about known events. The
    Americans won a major victory at the Battle of Midway because they knew that the
    Japanese were going to attack, but didn’t know where. They had broken the code,
    but the Japanese used code names for targets, in this case `AF`. The Americans
    arranged to have a message sent from Midway that they knew could be intercepted,
    saying that the island was short on fresh water. Shortly, the Japanese re-sent
    this message in code, confirming that `AF` was Midway.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: The complexity of ciphers was limited by human speed. Although the Americans
    had some punch-card tabulating machines available to help with code breaking,
    this was before the computer age. Codes had to be simple so that messages could
    be encoded and decoded quickly enough to be useful.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '***One-Time Pads***'
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The most secure method of encryption, called a *one-time pad*, harkens back
    to the work of American cryptographer Frank Miller (1842–1925) in 1882\. A one-time
    pad is a set of unique substitution ciphers, each of which is only used once.
    The name comes from the way in which the ciphers were printed on pads of paper
    so that the one on top could be removed once it was used.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we want to encode our earlier message. We grab a page from our pad that
    looks something like [Listing 13-3](ch13.xhtml#ch13list03).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*Listing 13-3: One-time pad*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: The way it works is that each letter in the original message is converted to
    a number between 1 and 26, as is each corresponding letter in the one-time pad.
    The values are added together using base-26 arithmetic. For example, the first
    letter in the message is `T`, which has a value of `20`. It’s paired with the
    first letter in the one-time pad, which is `F` with a value of `6`. They’re added
    together, giving a value of `26`, so the encoded letter is `Z`. Likewise, the
    second letter `H` has a value of `8` and is paired with `G`, which has a value
    of `7`, so the encoded letter would be `O`. The fourth letter in the message is
    `Y` with a value of `24`, which when paired with a `D` with a value of `4` results
    in `28`. Then, `26` is subtracted, leaving `2`, making the encoded letter `B`.
    Decryption is performed with subtraction instead of addition.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: One-time pads are perfectly secure provided they’re used properly, but there
    are a couple of problems. First, both parties to a communication must have the
    same pad. Second, they must be in sync; somehow they need to both be using the
    same cipher. Communication becomes impossible if someone forgets to tear off a
    page or accidentally tears off more than one. Third, the pad must be at least
    as long as the message to prevent any repeating patterns.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: An interesting application of one-time pads was the World War II–era SIGSALY
    voice encryption system that went into service in 1943\. It scrambled and unscrambled
    audio using one-time pads stored on phonograph records. These were not portable
    devices; each one weighed over 50 tons!
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '***The Key Exchange Problem***'
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the problems with symmetric encryption systems is the need for both ends
    of a communication to be using the same key. You can mail a one-time pad to somebody
    or use a hopefully trusted courier, but you won’t know if it was intercepted along
    the way and a copy made. And it’s useless if it gets lost or damaged. It’s just
    like mailing a house key to a friend; you have no way to know whether or not someone
    made a copy along the way. In other words, it’s vulnerable to a man-in-the-middle
    attack.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '***Public Key Cryptography***'
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Public key cryptography* solves many of the problems we’ve discussed so far.
    It uses a pair of *related* keys. It’s like a house with a mail slot in the front
    door. The first key, called the *public key*, can be given to anybody and allows
    them to put mail in the slot. But only you, who can unlock the front door using
    the second or *private key*, can *read* that mail.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Public key cryptography is an *asymmetric* system in that the encoding and decoding
    keys are different. This solves the key exchange problem because it doesn’t matter
    if people have your public key since that can’t be used to decode messages.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Public key cryptography relies on *trapdoor functions*, mathematical functions
    that are easy to compute in one direction but not in the other without some piece
    of secret information. The term originates from the fact that it’s easy to fall
    through a trapdoor, but climbing back out is difficult without a ladder. As a
    really simple example, suppose we have a function *y* = *x*². Pretty easy to compute
    *y* from *x*. But computing *x* from *y* using ![Image](../images/eq368-01.jpg)
    is harder. Not a lot harder, because this is a simple example, but you’ve probably
    discovered that multiplication is easier than finding a square root. There is
    no mathematical secret for this function, but you could consider having a calculator
    to be the secret because that makes solving for *x* as easy as solving for *y*.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: The idea is that the public and private keys are related by some complicated
    mathematical function, with the public key as the trapdoor and the private key
    as the ladder, making messages easy to encrypt but hard to decrypt. A high-level
    view of this is to have the keys be factors of a really large random number.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Asymmetric encryption is computationally expensive. As a result, it’s often
    used only to secretly generate a symmetric *session key* that’s used for the actual
    message content. A common way to do this is with the *Diffie–Hellman Key Exchange*,
    named after American cryptographers Whitfield Diffie and Martin Hellman.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Diffie and Hellman published a paper about public key cryptography in 1976\.
    But it wasn’t until 1977 that an implementation became available because, although
    the concept of a trapdoor function is relatively simple, it turns out to be very
    difficult to invent one. It was solved by cryptographer Ronald Rivest in 1977,
    reportedly after a Manischewitz drinking binge, thus proving that mathematical
    prowess is unrelated to taste buds. Together with Israeli cryptographer Adi Shamir
    and American scientist Leonard Adleman, Rivest produced the *RSA* algorithm, whose
    name derives from the first letter of each contributor’s last name. Unfortunately,
    in a trust violation exposed by government contractor-leaker Edward Snowden, it
    turns out their company, RSA Security, took money from the NSA to install a kleptographic
    backdoor in their default random-number generator. This made it easier for the
    NSA, and anyone else who knew about it, to crack RSA-encoded messages.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '***Forward Secrecy***'
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the problems with using a symmetric cipher session key for actual communications
    is that all messages can be read if that key is discovered. We know that many
    governments have the technical capability to record and store communications.
    If, for example, you’re a human rights activist whose safety depends on the security
    of your communications, you don’t want to take a chance that your key could be
    discovered and all your messages decoded.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: The way to avoid this is with *forward secrecy*, wherein a new session key is
    created for each message. That way, discovering a single key is useful only for
    decoding a single message.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '***Cryptographic Hash Functions***'
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We touched on hash functions back in [Chapter 7](ch07.xhtml#ch07) as a technique
    for fast searching. Hash functions are also used in cryptography, but only functions
    with certain properties are suitable. Just like with regular hash functions, cryptographic
    hash functions map arbitrary inputs into fixed-size numbers. Hash functions for
    searching map their input into a much smaller range of outputs than their cryptographic
    cousins, as the former are used as memory locations and the latter are just used
    as numbers.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: A key property of cryptographic hash functions is that they’re *one-way* functions.
    That means that although it’s easy to generate the hash from the input, it’s not
    practical to generate the input from the hash.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important property is that small changes to the input data generate
    hashes that aren’t correlated. Back in [Chapter 7](ch07.xhtml#ch07), we used a
    hash function that summed the character values modulo some prime number. With
    such a function, the string `b` would have a hash value 1 greater than that of
    the string `a`. That’s too predictable for cryptographic purposes. [Table 13-1](ch13.xhtml#ch13tab01)
    shows the SHA-1 (Secure Hash Algorithm #1) hashes for three strings that differ
    in only one letter. As you can see, there’s no discernible relationship between
    the input and the hash value.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 13-1:** Corned Beef Hash'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input** | **SHA-1 Hash Value** |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
- en: '| Corned Beef | 005f5a5954e7eadabbbf3189ccc65af6b8035320 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
- en: '| Corned Beeg | 527a7b63eb7b92f0ecf91a770aa12b1a88557ab8 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
- en: '| Corned Beeh | 34bc20e4c7b9ca8c3069b4e23e5086fba9118e6c |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
- en: Cryptographic hash functions must be hard to spoof; given a hash value, it should
    be very difficult to come up with input that generates it. In other words, it
    should be difficult to produce collisions. Using the hash algorithm in [Chapter
    7](ch07.xhtml#ch07) with prime number of 13, we’d get a hash value of 4 for an
    input of `Corned Beef`. But we’d get the same hash value for an input of `Tofu
    Jerky Tastes Weird`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: For a long time, the MD5 hash function was the most widely used algorithm. But
    in the late 1990s, a way was found to produce *collisions*, which you saw back
    in “[Making a Hash of Things](ch07.xhtml#ch07lev1sec19).” At the time of writing,
    MD5 has been replaced by variants of the SHA algorithm. Unfortunately, the SHA-0
    and SHA-1 variations of this algorithm were developed by the NSA, which makes
    them untrustworthy.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '***Digital Signatures***'
  id: totrans-154
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Cryptography can help to verify the authenticity of data though *digital signatures*,
    which provide integrity, nonrepudiation, and authentication.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '*Integrity* verification means we can determine whether or not a message was
    altered. For example, in ancient times, report cards were actual printed paper
    cards that listed classes and grades, which students brought home to their parents.
    I remember a poorly performing classmate in fourth grade adding vertical lines
    to the right side of his *F*s to turn them into *A*s. His parents couldn’t tell
    that the message was altered.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Integrity verification is accomplished by attaching a cryptographic hash of
    the data. But, of course, anybody can attach a hash to a message. To prevent this,
    the sender encrypts the hash using their private key, which the recipient can
    decrypt using the corresponding public key. Note that for signatures, the roles
    of the public and private keys are reversed.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: The use of the private key provides both nonrepudiation and authentication.
    *Nonrepudiation* means it would be hard for a sender to claim that they didn’t
    sign a message that’s signed with their private key. *Authentication* means that
    that the recipient knows who signed the message since their public key is paired
    with the signer’s private key.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '***Public Key Infrastructure***'
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There’s a big gaping hole in public key encryption. Suppose you use your web
    browser to connect to your bank using a secure (HTTPS) connection. The bank sends
    its public key to your browser so that your browser can encrypt your data, such
    that the bank can decrypt it using its private key. But how do you know that that
    public key came from your bank instead of some third party tapping into your communications?
    How does your browser authenticate that key? Who can it trust if it can’t trust
    the key?
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Though unfortunately not a great solution, what’s used today is a *public key
    infrastructure (PKI)*. Part of such an infrastructure is a trusted third party
    called a *certificate authority (CA)* to vouch for the authenticity of keys. In
    theory, a CA makes sure that a party is who they say they are and issues a cryptographically
    signed document called a *certificate* that one can use to validate their key.
    These certificates are in a format called X.509, a standard defined by the International
    Telecommunications Union (ITU).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: While PKI generally works, it comes back to the trust problem. CAs have been
    hacked. Sloppy mistakes at CAs have caused their private keys to be accidentally
    published, making it possible for anyone to sign bogus certificates (fortunately,
    there’s a mechanism to *revoke* certificates). Some CAs have been found to be
    insecure in that they didn’t authenticate parties requesting certificates. And
    one can reasonably assume that governments believe that they have the right to
    force CAs to generate bogus certificates.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '***Blockchain***'
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Blockchain* is another application of cryptography. It’s a pretty simple idea
    backed by a lot of complicated math. Much of the media discussion of blockchain
    in connection to Bitcoin and other cryptocurrencies is about its applications,
    not about how it works.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: You can think of blockchain as a mechanism for managing a ledger, similar to
    your bank account statement. A problem with ledgers is that they’re easy to alter
    on paper, and even easier to alter electronically since computers don’t leave
    eraser smudges.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: A ledger usually consists of a set of records, each on subsequent lines. The
    blockchain equivalent of a ledger line is a *block*. Blockchain adds a cryptographic
    hash of the previous block (line) and a block creation timestamp to the next block.
    This makes a chain of blocks (hence the name) linked by the hashes and timestamps,
    as shown in [Figure 13-4](ch13.xhtml#ch13fig04).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig04.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-4: Simplified blockchain*'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, if the contents of block *n* were modified, it would change
    its hash so that it wouldn’t match the one stored in block *n* + 1\. The properties
    of cryptographic hashes make it unlikely that a block could be modified in any
    useful way and still have the same hash. Each block effectively includes a digital
    signature of the prior block.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: The only effective way to attack a blockchain is to compromise the software
    that manages it, an approach that can be somewhat mitigated by having the blockchain
    data be both public and duplicated on multiple systems. Attacking such a distributed
    system would require collusion among a number of people.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '***Password Management***'
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another application of cryptography is *password management*. In the good old
    days, computers maintained a file of passwords as *cleartext*. When someone logged
    in, the password they entered would be compared to the one stored in the file.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: This is a bad approach primarily because anyone with access to the file knows
    everybody’s passwords. Keep in mind that this doesn’t have to be the result of
    an attack on the computer. Many organizations send their backups to third parties
    for storage (it’s a good idea to have at least three backups geographically far
    from each other, preferably on different tectonic plates). We’re back to trust
    again because someone could access the password file or any other data on these
    backups. You can encrypt your backups, but that’s a bit more fragile, as small-storage
    medium defects (such as a bad disk drive block) can render the entire backup unrecoverable.
    There’s a trade-off between protecting your data and being able to recover it.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: A simple solution to this problem is to store the passwords in an encrypted
    format such as a cryptographic hash. When a user tries to log in, their password
    is converted to the cryptographic hash, which is then compared to the one on file.
    The properties of cryptographic hashes make it very unlikely that a password could
    be guessed. As an additional precaution, most systems prevent the password file
    from being accessible by normal users.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Passwords are problematic even with these practices, though. In the early days
    of shared computing, you might have needed passwords for a handful of systems.
    But now, you need countless passwords for bank accounts, school websites, many
    different online stores, and so on. Many people navigate this situation by using
    the same password everywhere; it turns out that the most common password is `password`,
    followed by `password123` for sites that require numbers in the password. Reusing
    a password is equivalent to not using forward secrecy; if one site is compromised,
    your password can be used on every other site. You can have a different password
    for each site, but then you have to remember them all. You can use a *password
    manager* that stores all of your various passwords in one place protected by a
    single password, but if that password or the password manager itself is compromised,
    so are all of your other passwords. Probably the most effective but problematic
    approach is two-factor authentication, mentioned earlier. But that often relies
    on something like a cell phone and prevents you from accessing your accounts when
    you’re somewhere without cell service. Also, it’s cumbersome, which causes people
    to stay logged in to many sites.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '**Software Hygiene**'
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you know a little about security and cryptography, what can you do
    about it as a programmer? You don’t need to be a cryptography expert or security
    wizard to be able to avoid many common pitfalls. The vast majority of security
    flaws in the wild result from easily avoidable situations, many of which can be
    found in Henry Spencer’s *The Ten Commandments for C Programmers*. We’ll look
    at some of these in this section.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '***Protect the Right Stuff***'
  id: totrans-178
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When designing a system that keeps things secure, it’s tempting to make it keep
    everything secure. But that’s not always a good idea. If, for example, you make
    users log in to view things that don’t need to be secure, it makes users log in
    and stay logged in. Since logged-in users can access the “secure” content, that
    increases the chances that someone else can get access—for example, if the user
    walks away from their computer for a short time.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: This is illustrated by the way in which many cell phones work. For the most
    part, everything is locked up, except possibly the camera. There are things that
    *should* be locked up; you don’t necessarily want someone to be able to send messages
    in your name if you lose your phone. But suppose you and your friends are listening
    to music. You have to hand your unlocked phone to someone else if they’re picking
    the tunes, giving them access to everything. Texting a code to your phone is a
    common second factor in two-factor authentication, and handing that factor to
    a third party defeats the purpose.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '***Triple-Check Your Logic***'
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It’s pretty easy to write a program that you *think* does something when in
    fact it doesn’t. Errors in logic can be exploited, especially when an attacker
    has access to the source code and can find bugs that you didn’t. One method that
    helps is to walk through your code with someone else out loud. Reading aloud forces
    you to go through things more slowly than when reading silently, and it’s always
    amazing what you find.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '***Check for Errors***'
  id: totrans-183
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Code that you write will use system calls and call library functions. Most of
    these calls return error codes if something goes wrong. Don’t ignore them! For
    example, if you try to allocate memory and the allocation fails, don’t use the
    memory. If a read of user input fails, don’t assume valid input. There are many
    of these cases, and handling every error can be tedious, but do it anyway.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Avoid library functions that can silently fail or overflow bounds. Make sure
    that error and warning reporting is enabled on your language tools. Treat memory
    allocation errors as fatal because many library functions rely on allocated memory
    and they may fail in mysterious ways after an allocation failure elsewhere.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '***Minimize Attack Surfaces***'
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This section paraphrases some of the April 19, 2016, testimony by cryptography
    researcher Matt Blaze to a US House of Representatives subcommittee following
    the San Bernardino shootings. It’s worth reading the whole thing.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: We have to assume that all software has bugs because it’s so complex. Researchers
    have tried to produce “formal methods,” akin to mathematical proofs, that could
    be used to demonstrate that computer programs are “correct.” Unfortunately, to
    date this is an unsolved problem.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: It follows that every feature added to a piece of software presents a new attack
    surface. We can’t even prove that one attack surface is 100 percent secure. But
    we know that each new attack surface adds new vulnerabilities and that they add
    up.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: This is the fundamental reason that actual security professionals, as opposed
    to politicians, are against the notion of installing backdoors for law enforcement.
    Not only does it make the software more complicated by adding another attack surface,
    but just like the locker example earlier in this chapter, there’s a pretty good
    chance that unauthorized parties will figure out how to access such a backdoor.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: It turns out that Matt Blaze really knows what he’s talking about here. The
    NSA announced its development of the Clipper chip in 1993\. The NSA’s intent was
    to mandate that it be used for encryption. It contained a government-access backdoor.
    This was a difficult political sell because people in other countries would be
    reluctant to use American products that could spy on them. The Clipper sank both
    because of political opposition and because Blaze published a paper titled “Protocol
    Failure in the Escrowed Encryption Standard” in 1994 that showed how easy it was
    to exploit the backdoor. As an aside, Blaze found himself completely unprepared
    to be hauled in front of Congress to testify but is now very good at it. It was
    a part of the universe that he didn’t understand at the time. Consider learning
    to speak in public, as it might come in handy someday.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Good security practice is to keep your code as simple as possible, thus minimizing
    the number of attack surfaces.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '***Stay in Bounds***'
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Chapter 10](ch10.xhtml#ch10) introduced the concept of buffer overflows. They’re
    one example of a class of bugs attackers can exploit that can remain undetected
    in programs for a long time.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: To recap, a buffer overflow occurs when software doesn’t check for boundaries
    and can end up overwriting other data. For example, if a “you’re authorized” variable
    exists past the end of a password buffer, a long password can result in authorization
    even if it’s not correct. Buffer overflows on the stack can be especially troublesome
    because they can allow an attacker to change the return address from a function
    call, allowing other parts of the program to be executed in an unintended manner.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Buffer overflows aren’t just limited to strings. You also must ensure that array
    indices are in bounds.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Another bounds problem is the size of variables. Don’t just assume, for example,
    that an integer is 32 bits. It might be 16, and setting the 17th bit might do
    something unexpected. Watch out for user input, and make sure to check that any
    user-supplied numbers fit into your variables. Most systems include definitions
    files that your code can use to ensure that you’re using the correct sizes for
    things. In the worst case, you should use these to prevent your code from building
    when the sizes are wrong. In the best case, you can use these definitions to automatically
    choose the correct sizes. Definitions exist for the sizes of numbers and even
    the number of bits in a byte. Don’t make assumptions!
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important to stay in memory bounds. If you’re using dynamically allocated
    memory and allocate *n* bytes, make sure that your accesses are in the range of
    0 to *n* – 1\. I’ve had to debug code in which memory was allocated and then the
    address of memory was incremented because it was convenient for the algorithm
    to reference `memory[-1]`. The code then freed `memory` instead of `memory[-1]`,
    causing problems.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Many microcomputers designed for embedded use include much more memory than
    is needed by a program. Avoid dynamic allocation in these cases and just use static
    data; it avoids a lot of potential problems. Of course, make sure that your code
    respects the bounds of the data storage.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Another bounds area is timing. Make sure your program can handle cases where
    input comes in faster than your interrupt handlers can respond. Avoid allowing
    your interrupt handlers to be interrupted so that you don’t blow off of the end
    of the stack.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: There’s a testing technique called *fuzzing* for which tools are available that
    can help catch these types of bugs. But it’s a statistical technique and not a
    substitute for writing good code. Fuzzing involves hitting your code with a large
    number of variations on legal input.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '***Generating Good Random Numbers Is Hard***'
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Good random numbers are important for cryptography. How do you get them?
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: The most common random-number generators actually generate *pseudorandom* numbers.
    That’s because logic circuits can’t generate true random numbers. They’ll always
    generate the same sequence of numbers if they start at the same place. A simple
    circuit called a *linear feedback shift register (LFSR)*, such as that shown in
    [Figure 13-5](ch13.xhtml#ch13fig05), can be used as a pseudorandom-number generator
    (PRNG).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig05.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-5: Linear feedback shift register*'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: You can see that as the number is shifted right, a new bit comes in from the
    left that is generated from some of the other bits. The version in the figure
    generates only 8-bit numbers, but larger versions can be constructed. There are
    two problems here. The first is that the numbers repeat cyclically. The second
    is that if you know the most recent random number, you always know the next one;
    if it just generated 0xa4, the next is always 0x52\. Note that although this is
    a problem for cryptography, it’s useful when debugging programs.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: The initial value in the register is called the *seed*. Many software implementations
    allow the seed to be set. There have been many improvements on the LFSR, such
    as the Mersenne Twister, but in the end they all have the same two problems I
    mentioned. There’s no true randomness.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Modern software addresses this problem by harvesting entropy from a variety
    of sources. The term *entropy* was co-opted from thermodynamics, where it refers
    to the universal tendency toward randomness.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: One of the first entropy sources, called LavaRand, was invented at SGI in 1997\.
    It worked by pointing a webcam at a couple of lava lamps. It could generate almost
    200Kb of random data per second. The performance of entropy sources is important;
    if you’re a website generating lots of session identifiers for lots of clients,
    you need lots of good random numbers quickly.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: It’s not practical to ship a pair of lava lamps with every computer, even though
    it would be groovy. Some chip manufacturers have added random-number generators
    to their hardware. Intel added an on-chip thermal noise generator random-number
    generator in 2012 that produced 500MB of random numbers per second. But people
    refused to use it because it was released right after the Snowden revelations
    and couldn’t be trusted.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: There’s another factor in trusting on-chip random-number generators. A manufacturer
    could publish its design so that it could be reviewed. You could even *decap*,
    or remove the lid from, a chip and examine it using an electron microscope to
    verify that it matches the design. But it’s possible to undetectably change it
    during manufacturing. This is the hardware equivalent of a doping scandal. [Chapter
    2](ch02.xhtml#ch02) mentioned doping in our discussion of transistors; *dopants*
    are the nasty chemicals that are used to create *p* and *n* regions. The behavior
    of the circuit can be altered by subtly adjusting the dopant levels. The result
    would be undetectable even through a microscope.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Security professionals have realized that they can’t trust hardware random-number
    generators. Entropy is harvested from random occurrences that are independent
    of computer programs, such as mouse movements, time between keyboard clicks, disk
    access speeds, and so on. This approach works pretty well, but quickly producing
    large quantities of random numbers is difficult.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Entropy harvesting has run afoul of some major dumb bugs, especially in the
    Linux-based Android operating system. It turns out that Android phones don’t generate
    entropy quickly, so random numbers used shortly after booting up aren’t so random.
    And it turns out that some of the early implementations copied code that harvested
    entropy from disk access times. Of course, cell phones don’t have disks; they
    have flash memory with predictable access times, making for predictable entropy.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: If your security depends on good random numbers, make sure you understand the
    system that’s generating them.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '***Know Thy Code***'
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Large projects often include *third-party code*, code not written by members
    of the project team. In many cases, your team doesn’t even have access to the
    source code; you have to take the vendor’s word that their code works and is secure.
    What could possibly go wrong?
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: First of all, how do you know that that code really works and is secure? How
    do you know that someone working on that code didn’t install a secret backdoor?
    This isn’t a hypothetical question; a secret backdoor was found in a major networking
    vendor’s products in 2015\. An extra account with a hardcoded password was found
    in another vendor’s products in 2016\. The list goes on, and will continue to
    grow as long as bad practices are tolerated. Plan for future abuses that are worse
    than the ones already known.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Ken Thompson’s 1984 Turing Award Lecture entitled “Reflections on Trusting Trust”
    gives an idea of how much damage a malicious actor can do.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Using third-party code causes another, subtler problem, which shows up with
    terrifying frequency in physical infrastructure software—the stuff that makes
    power plants and such work. You would think that critical software like this would
    be designed by engineers, but that’s the rare case. Engineers may specify the
    software, but it’s usually constructed by “system integrators.” These are people
    whose training is similar to what you’re getting under the auspices of “learning
    to code”; system integration pretty much boils down to importing code that others
    have written and gluing function calls together. The result is that product code
    ends up looking like [Figure 13-6](ch13.xhtml#ch13fig06).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig06.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-6: Unused vendor code and product code*'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: This means a lot of unused code is included in products; in the figure, there’s
    more nonproduct code than product code. I once gave a series of talks about this
    where I labeled it “digital herpes,” because there’s all this code coiled around
    the central nervous system of your product, waiting for an external stimulus in
    order to break out, just like the human version of the virus.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: This puts a coder into a difficult situation. How do you decide what third-party
    code is safe to use? Not everybody working on a power plant is an expert in cryptography
    or networking protocols.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: First, this is an area in which open source code has an advantage. You can actually
    look at open source code and, because you can, there’s a good chance that others
    are looking at it too. This “more eyeballs” principle means that there’s at least
    a better chance of bugs being found than in closed source code that is seen by
    only a few. Of course, this isn’t a panacea. A major bug was discovered in the
    popular OpenSSL cryptography library in 2014\. On the bright side, the discovery
    of this bug caused a large number of people to eyeball that code plus other security-critical
    packages.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Another good practice is to keep an eye on the ratio of code that you’re actually
    using in a third-party package to the overall size of the package. I once worked
    on a medical instrument project where management said, “Let’s use this cool operating
    system that we can get for a good price.” But that operating system included all
    sorts of functionality we weren’t going to use. I pushed back, and we just wrote
    our own code for the stuff that we needed. This was a couple of decades ago, and
    bugs have just been found in some deployments of this operating system.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: One more area to watch is debugging code. It’s common to include extra code
    for debugging during product development. Make sure it gets removed before it’s
    shipped! That includes passwords. If you included default passwords or other shortcuts
    to make your code easier to debug, make sure that they’re gone.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '***Extreme Cleverness Is Your Enemy***'
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you’re using third-party code, avoid using obscure, clever facilities. That’s
    because vendors often discontinue support for features that aren’t widely used
    by their customers. When that happens, you’re often locked out of the upgrade
    path. Vendors often provide fixes only for the latest version of their products,
    so if your code depends on a no-longer-supported feature, you may not be able
    to install critical security fixes.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '***Understand What’s Visible***'
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Think about the ways in which sensitive data can be accessed by programs other
    than yours—and not just data but metadata too. Who else can see your program’s
    data? This is an important part of defining a threat model. What could be compromised
    if someone absconds with your otherwise perfectly secure system? Can an attacker
    bypass protections by pulling the memory chips out of your device and accessing
    them directly?
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Apart from making your code secure, you need to watch out for *side-channel
    attacks*—exploits based on metadata, or side effects, of the implementation. For
    example, say you have code that checks a password. If it takes longer to run on
    a password that’s close to correct than it does on one that isn’t, that gives
    clues to an attacker. This sort of thing is called a *timing attack*.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: A camera pointed at the keypad on an ATM is a side-channel attack.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Attacks based on electromagnetic emissions have been documented. A cool one
    is called *van Eck phreaking*, which uses an antenna to pick up the radiation
    from a monitor to generate a remote copy of the displayed image. It has been demonstrated
    that ballot secrecy in some electronic voting systems can be compromised in this
    manner.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Side-channel attacks are really insidious and take serious systems thinking
    to ameliorate; just knowing how to write code isn’t enough. Examples abound, especially
    from the World War II era, which was the beginning of modern cryptography. The
    Germans were able to determine that Los Alamos National Laboratory existed because
    several hundred Sears catalogs were all being mailed to the same PO box. And British
    chemical plant locations were determined from the scores of the plant soccer team
    games published in local newspapers.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: In general, make sure that your critical security code’s externally visible
    behavior is independent of what it’s actually doing. Avoid exposing information
    via side channels.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '***Don’t Overcollect***'
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This is so obvious that I shouldn’t need to say anything, but experience demonstrates
    that few people get this. The best way to keep things secure is not to keep them
    at all. Don’t collect sensitive information unless you really need to.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: A classic example is found on a lot of medical forms. I’m always perplexed when
    the forms ask for both my birthdate and my age. Do I really want a doctor who
    can’t figure out one from the other? If you collect them both, you have to protect
    them both, so collect only the one that you need.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '***Don’t Hoard***'
  id: totrans-240
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Just because you’ve collected sensitive information doesn’t mean you should
    keep it around forever. Get rid of it as soon as possible. For example, you may
    need somebody’s password to log them in to some system. Once you’re done checking
    the password, it’s no longer needed. Clean it up. The longer you leave it around,
    the better the chances of someone discovering it.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning up is becoming more legally important as the world struggles to understand
    the European Union’s General Data Protection Regulation (GDPR), which adds consequences
    for leaking personal information.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '***Dynamic Memory Allocation Isn’t Your Friend***'
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Chapter 7](ch07.xhtml#ch07) talked about dynamic memory allocation using the
    heap. In this section, we’ll look at the C standard library functions `malloc`,
    `realloc`, and `free`, which can cause a number of different problems.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by looking at what happens when dynamically allocated memory is
    freed; see [Figure 13-7](ch13.xhtml#ch13fig07).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig07.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-7: Freeing memory*'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: 'On the left side of [Figure 13-8](ch13.xhtml#ch13fig08), you can see the heap
    sitting in memory. Moving to the right, a piece of memory from the heap is allocated
    for use by the program. Continuing toward the right, a piece of `secret` information
    is copied into the allocated memory. At some point later, that memory is no longer
    needed, so it’s freed and goes back onto the heap. Finally, on the far right,
    memory is allocated from the heap for some other purpose. But the secret is still
    in that piece of memory where it can be read. Rule #1 of using dynamic memory
    is to make sure you erase any sensitive information in memory before freeing.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: The `realloc` function lets you grow or shrink the size of allocated memory.
    Look at the shrink case in [Figure 13-8](ch13.xhtml#ch13fig08).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig08.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-8: Memory shrink*'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'The first steps are the same as in the previous example. But then the amount
    of allocated memory is shrunk. The secret was in the excess memory, so it goes
    back onto the heap. Then a later allocation of memory gets a block that contains
    the secret. Rule #2 of using dynamic memory is to make sure that any memory that’s
    going back on the heap due to a shrink is erased. This is similar to Rule #1.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: There are two cases to consider when using `realloc` to grow the size of an
    allocated memory block. The first case is easy and isn’t a security problem. As
    shown in [Figure 13-9](ch13.xhtml#ch13fig09), if there’s room above the already
    allocated block on the heap, the size of the block is increased.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig09.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-9: Good memory grow*'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 13-10](ch13.xhtml#ch13fig10) shows the case that can cause security
    problems.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig10.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-10: Bad memory grow*'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, there’s another piece of memory that has already been allocated
    for some other purpose. When we try to increase the size of our allocated memory
    block, there’s not enough space because of the other block, so the heap is searched
    for a large enough contiguous block of memory. The memory is allocated, the data
    from the old block is copied in, and the old block is freed. Now there are two
    copies of the secret in memory, and one is in unallocated memory that could be
    allocated. The big problem here is that the `realloc` caller has no visibility
    into what’s happening. The only way to tell whether or not the memory block was
    moved is to compare its address to the original address. But even if it moved,
    you’ve found out too late because the old block is no longer under your control.
    This leads to rule #3: Don’t use `realloc` when security is critical. Use `malloc`
    to allocate new memory, copy the old to the new, erase the old, and then call
    `free`. Not as efficient, but much more secure.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '***Garbage Collection Is Not Your Friend Either***'
  id: totrans-260
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: I’ve talked about erasing critical data once it’s no longer needed. The preceding
    section showed that this isn’t as easy to do as it sounds with explicit memory
    management. Garbage-collected systems have their own set of unique problems. Let’s
    say we have a program in C that contains something “sensitive,” as shown in [Figure
    13-11](ch13.xhtml#ch13fig11).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig11.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-11: C string of sensitive data*'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: How do we clean this up once we’re done with it? Because C strings are NUL terminated,
    we can make it an empty string by setting the first character to NUL, as in [Figure
    13-12](ch13.xhtml#ch13fig12).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/13fig12.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
- en: '*Figure 13-12: Poorly erased C string of sensitive data*'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: It wouldn’t be hard for a nefarious individual to guess the contents. We really
    need to overwrite the entire string.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: This string could be in a memory array, or it could be in memory dynamically
    obtained using `malloc`. Make sure the string is set to NULs or some recognizable
    value that’s easy to spot when debugging, erasing every character before calling
    `free`; otherwise, the sensitive data just ends up back on the heap and might
    be given out on a later `malloc` call.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: What if we’re using a language that uses garbage collection instead of explicit
    memory management? Something like `secret = "xxxxxxxxxxxxxxx"` doesn’t do what
    you think in languages like JavaScript, PHP, and Java. Rather than overwrite the
    sensitive data, these languages might just make a new string for you and add the
    sensitive data string to the list of things to be garbage-collected. The sensitive
    data isn’t erased, and you have no ability to force it to be erased.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: It would be nice if these sorts of issues were limited to programming languages
    and environments, but that’s not the case. Flash memory is used in more and more
    places. One of those places is in solid-state disk drives (SSDs). Because flash
    memories wear out, these drives use *load leveling* to equalize the usage among
    the various flash memory chips. That means that writing something to one of these
    devices doesn’t guarantee that the old version was erased. It’s just like freeing
    allocated memory and having it end up on the heap.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, even the act of erasing something securely is more complex than
    anything you’re being taught while “learning to code.” You need a thorough understanding
    of all aspects of an environment in order to do the job well, which is of course
    why you’re reading this book.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '***Data as Code***'
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You should be aware by now that “code” is just data in a particular format that’s
    understood by a computer. That originally meant computer hardware, but now many
    programs, such as web browsers, execute data including in the form of JavaScript
    programs. And JavaScript can also execute data; its `eval` statement treats any
    string as if it’s a program and runs it.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](ch05.xhtml#ch05), we looked at some of the hardware that prevents
    computers from treating arbitrary data as code. Memory management units or Harvard
    architecture machines keep code and data separate, preventing data from being
    executed. Programs that can execute data don’t have that sort of protection, so
    you have to provide it yourself.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: A classic example is *SQL injection*. SQL, short for Structured Query Language,
    is the interface to many database systems. The *structured* part allows data to
    be organized into, for example, personnel records. The *query* part allows that
    data to be accessed. And, of course, the *language* is how it’s done.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: SQL databases organize data as a set of *tables*, which are rectangular arrays
    of rows and columns. Programmers can create tables and specify the columns. Queries
    insert, remove, modify, or return rows in tables.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: You don’t need to know all the details of SQL to understand the following example.
    What you do need to know is that SQL statements are terminated with semicolons
    (`;`) and that comments begin with the number or hash sign (`#`).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Your school probably has a website you can use to check your grades. Our example
    uses a SQL database that includes a table called students, as shown in [Table
    13-2](ch13.xhtml#ch13tab02).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 13-2:** Students Table in Database'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '| **student** | **class** | **grade** |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
- en: '| David Lightman | Biology 2 | F |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
- en: '| David Lightman | English 11B | D |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
- en: '| David Lightman | World History 11B | C |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
- en: '| David Lightman | Trig 2 | B |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
- en: '| Jennifer Mack | Biology 2 | F |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
- en: '| Jennifer Mack | English 11B | A |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
- en: '| Jennifer Mack | World History 11B | B |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
- en: '| Jennifer Mack | Geometry 2 | D |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
- en: The website offers an HTML text field in which a student can enter the name
    of a class. A bit of JavaScript and jQuery sends the class name to the web server
    and displays the returned grade. The web server has some PHP code that looks up
    the grade in the database and sends it back to the web page. When a student logs
    in, the `$student` variable is set to their name so that they can access only
    their own grades. [Listing 13-4](ch13.xhtml#ch13list04) shows the code.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*Listing 13-4: Student website code fragments*'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: The database query is straightforward. It selects all (`*`) columns from all
    rows in the `students` table where the `class` column matches the `class` field
    from the web page and the `student` column matches the variable containing the
    logged-in student name. What could possibly go wrong?
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, David may not be paying much attention to Biology, but he’s good with
    computers. He logs in to his account. Instead of entering `Biology 2` for a class,
    he enters `Biology 2'' || 1=1 || ''; #`. This turns the `select` statement into
    what’s shown in [Listing 13-5](ch13.xhtml#ch13list05).'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '*Listing 13-5: SQL injection*'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: This reads as “select all columns from students where class is `Biology 2` or
    1 equals 1 or an empty string.” The semicolon ends the query early, and the rest
    of the line is turned into a comment. Because 1 always equals 1, David has just
    gained access to the entire set of student grades. I could go on to show you how
    David impresses Jennifer by changing her Biology grade, but you can just watch
    the 1983 movie *WarGames*. As a teaser, he could enter something in the field
    with a semicolon, then follow that with a database update command.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'These aren’t just theoretical science fiction movie scenarios; see xkcd cartoon
    #327\. As recently as 2017, a major SQL injection bug was found in the popular
    WordPress website software, which was used by a very large number of websites.
    This should further demonstrate the problems that can occur when you rely on third-party
    code.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: As another example, many websites allow users to submit comments. You must be
    careful to sanitize every comment to make sure it doesn’t contain JavaScript code.
    Otherwise, a user viewing those comments would inadvertently run that code. And
    if you don’t prevent users from submitting comments in HTML, you’ll likely find
    the comments filled with advertisements and links to other websites. Make sure
    user input can never be interpreted as code.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, you’ve gained a basic understanding of security principles.
    You learned a bit about cryptography, a key computer security technology. You
    also learned about a number of things that you can do to make your code more secure.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: In addition, hopefully you’ve learned that security is very difficult and not
    for amateurs. Consult experts until you’ve become one. Don’t go it alone.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Just like security, machine intelligence is another advanced topic that’s worth
    knowing a bit about. We’ll turn our attention to it in the next chapter.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
