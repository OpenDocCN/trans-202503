["```\nfrom sklearn import tree\nfrom sklearn.feature_extraction import DictVectorizer\n```", "```\nclassifier = ➊tree.DecisionTreeClassifier()\nvectorizer = ➋DictVectorizer(sparse=➌False)\n```", "```\n   # declare toy training data\n➊ training_examples = [\n   {'packed':1,'contains_encrypted':0},\n   {'packed':0,'contains_encrypted':0},\n   {'packed':1,'contains_encrypted':1},\n   {'packed':1,'contains_encrypted':0},\n   {'packed':0,'contains_encrypted':1},\n   {'packed':1,'contains_encrypted':0},\n   {'packed':0,'contains_encrypted':0},\n   {'packed':0,'contains_encrypted':0},\n   ]\n➋ ground_truth = [1,1,1,1,0,0,0,0]\n```", "```\n   # initialize the vectorizer with the training data\n➊ vectorizer.fit(training_examples)\n   # transform the training examples to vector form\n➋ X = vectorizer.transform(training_examples)\n   y = ground_truth # call ground truth 'y', by convention\n```", "```\n# train the classifier (a.k.a. 'fit' the classifier)\nclassifier.fit(X,y)\n```", "```\n   test_example = ➊{'packed':1,'contains_encrypted':0}\n   test_vector = ➋vectorizer.transform(test_example)\n➌ print classifier.predict(test_vector) # prints [1]\n```", "```\n# visualize the decision tree\nwith open(➊\"classifier.dot\",\"w\") as output_file:\n  ➋ tree.export_graphviz(\n        classifier,\n        feature_names=vectorizer.get_feature_names(),\n        out_file=output_file\n    )\n\nimport os\nos.system(\"dot classifier.dot -Tpng -o classifier.png\")\n```", "```\n#!/usr/bin/python\n\n# import sklearn modules\nfrom sklearn import tree\nfrom sklearn.feature_extraction import DictVectorizer\n\n# initialize the decision tree classifier and vectorizer\nclassifier = tree.DecisionTreeClassifier()\nvectorizer = DictVectorizer(sparse=False)\n\n# declare toy training data\ntraining_examples = [\n{'packed':1,'contains_encrypted':0},\n{'packed':0,'contains_encrypted':0},\n{'packed':1,'contains_encrypted':1},\n{'packed':1,'contains_encrypted':0},\n{'packed':0,'contains_encrypted':1},\n{'packed':1,'contains_encrypted':0},\n{'packed':0,'contains_encrypted':0},\n{'packed':0,'contains_encrypted':0},\n]\nground_truth = [1,1,1,1,0,0,0,0]\n\n# initialize the vectorizer with the training data\nvectorizer.fit(training_examples)\n\n# transform the training examples to vector form\nX = vectorizer.transform(training_examples)\ny = ground_truth # call ground truth 'y', by convention\n\n# train the classifier (a.k.a. 'fit' the classifier)\nclassifier.fit(X,y)\n\ntest_example = {'packed':1,'contains_encrypted':0}\ntest_vector = vectorizer.transform(test_example)\nprint `classifier.predict(test_vector)` # prints [1]\n\n#visualize the decision tree\nwith open(\"classifier.dot\",\"w\") as output_file:\n    tree.export_graphviz(\n        classifier,\n        feature_names=vectorizer.get_feature_names(),\n        out_file=output_file\n    )\n\nimport os\nos.system(\"dot classifier.dot -Tpng -o classifier.png\")\n```", "```\n[\"A\", \"The\", \"PE executable\", \"Malicious payload\"]\n```", "```\ndef apply_hashing_trick(feature_dict, vector_size=2000):\n```", "```\n    new_features = [0 for x in range(vector_size)]\n```", "```\n    for key in ➊feature_dict:\n        array_index = ➋hash(key) % vector_size\n        new_features[array_index] += ➌feature_dict[key]\n```", "```\n    return new_features\n```", "```\ndef apply_hashing_trick(feature_dict,vector_size=2000):\n    # create an array of zeros of length 'vector_size'\n    new_features = [0 for x in range(vector_size)]\n\n    # iterate over every feature in the feature dictionary\n    for key in feature_dict:\n\n        # get the index into the new feature array\n        array_index = hash(key) % vector_size\n\n        # add the value of the feature to the new feature array\n        # at the index we got using the hashing trick\n        new_features[array_index] += feature_dict[key]\n\n    return new_features\n```", "```\nfrom sklearn.feature_extraction import FeatureHasher\n```", "```\nhasher = FeatureHasher(n_features=2000)\n```", "```\nfeatures = [{'how': 1, 'now': 2, 'brown': 4},{'cow': 2, '.': 5}]\nhashed_features = hasher.transform(features)\n```", "```\nfrom sklearn.feature_extraction import FeatureHasher\nhasher = FeatureHasher(n_features=10)\nfeatures = [{'how': 1, 'now': 2, 'brown': 4},{'cow': 2, '.': 5}]\nhashed_features = hasher.transform(features)\n```", "```\ndef get_string_features(➊path,➋hasher):\n    # extract strings from binary file using regular expressions\n    chars = r\" -~\"\n    min_length = 5\n    string_regexp = '[%s]{%d,}' % (chars, min_length)\n    file_object = open(path)\n    data = file_object.read()\n    pattern = re.compile(string_regexp)\n    strings = pattern.findall(data)\n\n    # store string features in dictionary form\n  ➌ string_features = {}\n    for string in strings:\n        string_features[string] = 1\n\n    # hash the features using the hashing trick\n  ➍ hashed_features = hasher.transform([string_features])\n\n    # do some data munging to get the feature array\n    hashed_features = hashed_features.todense()\n    hashed_features = numpy.asarray(hashed_features)\n    hashed_features = hashed_features[0]\n\n    # return hashed string features\n  ➎ print \"Extracted {0} strings from {1}\".format(len(string_features),path)\n    return hashed_features\n```", "```\ndef ➊get_training_data(benign_path,malicious_path,hasher):\n    def ➋get_training_paths(directory):\n        targets = []\n        for path in os.listdir(directory):\n            targets.append(os.path.join(directory,path))\n        return targets\n  ➌ malicious_paths = get_training_paths(malicious_path)\n  ➍ benign_paths = get_training_paths(benign_path)\n  ➎ X = [get_string_features(path,hasher) \n    for path in malicious_paths + benign_paths]\n    y = [1 for i in range(len(malicious_paths))] \n    + [0 for i in range(len(benign_paths))]\n    return X, y\ndef ➏train_detector(X,y,hasher):\n    classifier = tree.RandomForestClassifier()\n  ➐ classifier.fit(X,y)\n  ➑ pickle.dump((classifier,hasher),open(\"saved_detector.pkl\",\"w+\"))\n```", "```\ndef scan_file(path):\n    if not os.path.exists(\"saved_detector.pkl\"):\n        print \"Train a detector before scanning files.\"\n        sys.exit(1)\n  ➊ with open(\"saved_detector.pkl\") as saved_detector:\n        classifier, hasher = pickle.load(saved_detector)\n    features = ➋get_string_features(path,hasher)\n    result_proba = ➌classifier.predict_proba(features)[1]\n    # if the user specifies malware_paths and \n    # benignware_paths, train a detector\n  ➍ if result_proba > 0.5:\n        print \"It appears this file is malicious!\",`result_proba`\n    else:\n        print \"It appears this file is benign.\",`result_proba`\n```", "```\n#!/usr/bin/python\n\nimport os\nimport sys\nimport pickle\nimport argparse\nimport re\nimport numpy\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction import FeatureHasher\n\ndef get_string_features(path,hasher):\n    # extract strings from binary file using regular expressions\n    chars = r\" -~\"\n    min_length = 5\n    string_regexp = '[%s]{%d,}' % (chars, min_length)\n    file_object = open(path)\n    data = file_object.read()\n    pattern = re.compile(string_regexp)\n    strings = pattern.findall(data)\n\n    # store string features in dictionary form\n    string_features = {}\n    for string in strings:\n        string_features[string] = 1\n\n    # hash the features using the hashing trick\n    hashed_features = hasher.transform([string_features])\n\n    # do some data munging to get the feature array\n    hashed_features = hashed_features.todense()\n    hashed_features = numpy.asarray(hashed_features)\n    hashed_features = hashed_features[0]\n\n    # return hashed string features\n    print \"Extracted {0} strings from {1}\".format(len(string_features),path)\n    return hashed_features\n\ndef scan_file(path):\n    # scan a file to determine if it is malicious or benign\n    if not os.path.exists(\"saved_detector.pkl\"):\n        print \"Train a detector before scanning files.\"\n        sys.exit(1)\n    with open(\"saved_detector.pkl\") as saved_detector:\n        classifier, hasher = pickle.load(saved_detector)\n    features = get_string_features(path,hasher)\n    result_proba = classifier.predict_proba([features])[:,1]\n    # if the user specifies malware_paths and \n    # benignware_paths, train a detector\n    if result_proba > 0.5:\n        print \"It appears this file is malicious!\",`result_proba`\n    else:\n        print \"It appears this file is benign.\",`result_proba`\n\ndef train_detector(benign_path,malicious_path,hasher):\n    # train the detector on the specified training data\n    def get_training_paths(directory):\n        targets = []\n        for path in os.listdir(directory):\n            targets.append(os.path.join(directory,path))\n        return targets\n    malicious_paths = get_training_paths(malicious_path)\n    benign_paths = get_training_paths(benign_path)\n    X = [get_string_features(path,hasher) for path in malicious_paths + benign_paths]\n    y = [1 for i in range(len(malicious_paths))] + [0 for i in range(len(benign_paths))]\n    classifier = tree.RandomForestClassifier(64)\n    classifier.fit(X,y)\n    pickle.dump((classifier,hasher),open(\"saved_detector.pkl\",\"w+\"))\n\ndef get_training_data(benign_path,malicious_path,hasher):\n    def get_training_paths(directory):\n        targets = []\n        for path in os.listdir(directory):\n            targets.append(os.path.join(directory,path))\n        return targets\n    malicious_paths = get_training_paths(malicious_path)\n    benign_paths = get_training_paths(benign_path)\n    X = [get_string_features(path,hasher) for path in malicious_paths + benign_paths]\n    y = [1 for i in range(len(malicious_paths))] + [0 for i in range(len(benign_paths))]\n    return X, y\n\nparser = argparse.ArgumentParser(\"get windows object vectors for files\")\nparser.add_argument(\"--malware_paths\",default=None,help=\"Path to malware training files\")\nparser.add_argument(\"--benignware_paths\",default=None,help=\"Path to benignware training files\")\nparser.add_argument(\"--scan_file_path\",default=None,help=\"File to scan\")\nargs = parser.parse_args()\n\nhasher = FeatureHasher(20000)\nif args.malware_paths and args.benignware_paths:\n    train_detector(args.benignware_paths,args.malware_paths,hasher)\nelif args.scan_file_path:\n    scan_file(args.scan_file_path)\nelse:\n    print \"[*] You did not specify a path to scan,\" \\\n        \" nor did you specify paths to malicious and benign training files\" \\\n        \" please specify one of these to use the detector.\\n\"\n    parser.print_help()\n```", "```\nparser.add_argument(\"--evaluate\",default=False,\naction=\"store_true\",help=\"Perform cross-validation\")\n```", "```\nelif args.malware_paths and args.benignware_paths and args.evaluate:\n  ➊ hasher = FeatureHasher()\n    X, y = ➋get_training_data(\n    args.benignware_paths,args.malware_paths,hasher)\n    evaluate(X,y,hasher)\ndef ➌evaluate(X,y,hasher):\n    import random\n    from sklearn import metrics\n    from matplotlib import pyplot\n```", "```\n    ➊ X, y = numpy.array(X), numpy.array(y)\n    ➋ indices = range(len(y))\n    ➌ random.shuffle(indices)\n    ➍ X, y = X[indices], y[indices]\n       splitpoint = len(X) * 0.5\n    ➎ splitpoint = int(splitpoint)\n    ➏ training_X, test_X = X[:splitpoint], X[splitpoint:]\n       training_y, test_y = y[:splitpoint], y[splitpoint:]\n```", "```\n    classifier = RandomForestClassifier()\n    classifier.fit(training_X,training_y)\n```", "```\n    scores = classifier.predict_proba(test_X)[:,-1]\n```", "```\n    fpr, tpr, thresholds = metrics.roc_curve(test_y, scores)\n```", "```\n    pyplot.plot(fpr,tpr,'r-')\n    pyplot.xlabel(\"Detector false positive rate\")\n    pyplot.ylabel(\"Detector true positive rate\")\n    pyplot.title(\"Detector ROC Curve\")\n    pyplot.show()\n```", "```\ndef cv_evaluate(X,y,hasher):\n    import random\n    from sklearn import metrics\n    from matplotlib import pyplot\n    from sklearn.cross_validation import KFold\n```", "```\n    X, y = numpy.array(X), numpy.array(y)\n```", "```\n    fold_counter = 0\n       for train, test in KFold(len(X),3,➊shuffle=True):\n        ➋ training_X, training_y = X[train], y[train]\n           test_X, test_y = X[test], y[test]\n```", "```\n        classifier = RandomForestClassifier()\n        classifier.fit(training_X,training_y)\n```", "```\n        scores = classifier.predict_proba(test_X)[:,-1]\n        fpr, tpr, thresholds = metrics.roc_curve(test_y, scores)\n        pyplot.semilogx(fpr,tpr,label=\"Fold number {0}\".format(fold_counter))\n        fold_counter += 1\n```", "```\n    pyplot.xlabel(\"Detector false positive rate\")\n    pyplot.ylabel(\"Detector true positive rate\")\n    pyplot.title(\"Detector Cross-Validation ROC Curves\")\n    pyplot.legend()\n    pyplot.grid()\n    pyplot.show()\n```", "```\n        classifier = RandomForestClassifier()\n        classifier.fit(training_X,training_y)\n```", "```\n        from sklearn.linear_model import LogisticRegression\n        classifier = LogisticRegression()\n        classifier.fit(training_X,training_y)\n```"]