<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><h2 class="chn"><span epub:type="pagebreak" id="page_301"/><strong>13</strong></h2>&#13;
<h2 class="cht"><strong>DESKTOP ARCHITECTURES</strong></h2>&#13;
<div class="image1"><img src="../images/f0301-01.jpg" alt="Image" width="189" height="189"/></div>&#13;
<p class="chq">“A computer on every desk” was Bill Gates’s ambition during the 32-bit era of the 1990s, and while the current trend is toward the Internet of Things and the cloud, a personal computer (PC) can still be found on many desks and laps today. The PC isn’t a single computer design; rather, it’s a set of loose conventions for combining many different components from different manufacturers into computers, based around the x86 family of CPUs.</p>&#13;
<p class="indent">Thanks to a business-led focus on backward compatibility, modern PCs retain many features from earlier stages of their evolution, so in this chapter we’ll study how these conventions came into being and how they’ve affected x86 architecture and PC computer design. We’ll examine x86’s CISC philosophy and its Silicon Valley history and instruction set, then look at some computer design elements used to build modern PCs around it.</p>&#13;
<h3 class="h3" id="lev262"><span epub:type="pagebreak" id="page_302"/>CISC Design Philosophy</h3>&#13;
<p class="noindent">Most desktop computers use CPUs from the x86 family, which are usually described as CISC architectures. We’ve seen CISC architectures a few times, but let’s take a closer look at some of the CISC principles that appear in x86.</p>&#13;
<p class="indent">In a CISC architecture, you try to do as many big and clever things as you can on a large, complex chip with lots of silicon. You design many different small machines that all do different specialized things; you also provide dedicated instructions for each of them. As you can imagine, this is very hard to design, and you end up having to pay your architects a lot of money—especially when all the new complex features need to be made to play nicely with other innovations, such as pipelining and out-of-order execution (OOOE). Using lots of silicon typically consumes lots of power, so CISC processors often have to be plugged into the wall, with heavy power transformers and large cooling systems such as fans. These requirements are easier to meet in a desktop setting than in embedded and smart-type environments.</p>&#13;
<p class="indent">A classic aspect of CISC philosophy is having lots of instructions that combine memory access with arithmetic logic unit (ALU) instructions, such as “multiply the contents of a first address by the contents of a second address and store the result in a third address,” where the addresses are in RAM. This is, in fact, a compound instruction involving many steps: we need to load both addresses, multiply their values, put the resulting value in a register, and store it in memory again.</p>&#13;
<p class="indent">CISC also emphasizes implementing new instructions in hardware essentially saying, “Throw more silicon at the problem.” For example, if users demand lots of video codec streaming, you can create special instructions that perform the specific mathematical operations used in video codecs, and build lots of new simple machines in digital logic to implement each of them.</p>&#13;
<p class="indent">A “decode my video” instruction is going to take more than one clock cycle, and accommodating different instructions that take differing amounts of time is a major challenge that arises in CISC architectures. In particular, pipelining and OOOE are harder to get right when instructions have different durations. This problem can be fixed by throwing even more silicon at it: you can create even more complex digital logic in the control unit (CU) to identify these durations and schedule around them.</p>&#13;
<p class="indent">One supposed advantage of CISC architectures is that the compiler has to do very little work to translate common high-level language statements into assembly; this is because the instruction set architecture (ISA) has dedicated instructions for commands such as “decode my video,” which then have a simple one-to-one translation. But these instructions make life harder for compiler writers, who now need to wade through a five-volume set of instructions for <em>every</em> backend CPU they target; they’re also now expected to make some attempt to optimize their compiler for each particular ISA. It would be much easier for compiler writers to just use one volume of instructions and ignore all the advanced ones. In practice, this means that CISC architectures are more likely to come with compilers written by the same <span epub:type="pagebreak" id="page_303"/>people who built the CPU, because no one else wants to work to optimize for one particular CPU. These compilers tend to be proprietary and to run faster than the open source versions due to the complexity involved; only those who built the system fully understand all the features.</p>&#13;
<p class="indent">Another upside is that assembly programs can be short, as every instruction does a lot of work. In the 1980s, this was important: RAM was limited, so shorter programs freed up more RAM for data. It’s not so important today.</p>&#13;
<p class="indent">CISC was invented by an Englishman, Maurice Wilkes, seen previously in <a href="ch01.xhtml#ch01fig19">Figure 1-19</a>, but was commercialized by Americans. Stereotypical CISC architects and users are business-driven, and CISC is dominant in real-world desktop computing. You’re probably using a CISC architecture on your desktop today. If a CISC client asks for a new instruction to speed up their particular multimedia application, then the CISC business will often design and add it for them—for a cost. New features are often bolted on in this way, without necessarily being designed to beautifully fit together with what was there before. The older features will usually be retained, however, in order to avoid breaking other customers’ existing systems.</p>&#13;
<h3 class="h3" id="lev263">Microprogramming</h3>&#13;
<p class="noindent">Building new CPUs in hardware is hard and expensive. A chip mask set costs around $5 million to make, and if you get it wrong anywhere, new masks will be needed. This problem is acute for CISC due to its complex designs. <em>Microprogramming</em> is a solution to this problem in which the architecture consists of many simple machines that can be connected and disconnected through basic switches. Instructions are then defined as sequences of connections and disconnections. For example, to add two registers, you first connect one of them to an ALU input, then connect the other register to the other ALU input. Then you connect the ALU to a signal asking it to add, and finally you connect the result in the ALU output to a register.</p>&#13;
<p class="indent">This idea is reminiscent of the rotating barrel CU in Babbage’s Analytical Engine. The barrel has pins that are placed to trigger sequences of the simple machines. If the pins are moved around, different instructions and architectures can be easily created. Modern electronic microprogramming—and hence CISC—is credited to Wilkes, who studied and taught the history of computing and was very open about having picked up the idea from Babbage’s mechanical barrel. This is a paradigmatic example of how studying the arc of history can enable major, Turing Award–winning advances in modern architecture.</p>&#13;
<p class="indent">The electronic version of Babbage’s barrel pins is usually firmware, known as <em>microcode</em>, inside the CPU, containing a list of connections to make and break in sequence for each instruction. (This isn’t ROM in the CPU’s address space, it’s a non-addressable, separate region inside the CPU itself.) As firmware, it can be electronically reprogrammed at any time. This massively reduces the cost of fixing hardware bugs in the CPU, as they can be <span epub:type="pagebreak" id="page_304"/>corrected with a firmware update rather than having to return and remanufacture the chip itself.</p>&#13;
<p class="indent">Microprograms aren’t machine code programs; they exist at a lower level, defining the machine that the machine code runs on. The actions of microprograms can be notated using register transfer language (RTL), as in <a href="ch07.xhtml">Chapter 7</a>. Modern CISC chips may have many thousands of complex instructions all defined in microcode. You can re-microprogram your CPU to implement a completely different instruction set if you like, such as turning an x86 into a retro 6502! There’s now so much reconfigurability that microprograms can behave almost like FPGAs.</p>&#13;
<p class="indent">Now that we’ve seen some of the design concepts, let’s turn to the history of x86. Doing so will help you make sense of features still present in modern x86s that have accumulated through this history.</p>&#13;
<h3 class="h3" id="lev264">x86 History</h3>&#13;
<p class="noindent">The x86 architecture has been the most commercially successful and resilient CPU architecture to date, reaching its 45th anniversary in 2023. x86 is a family of CISC architectures whose designs and names derive from the model numbers of the first few generations of Intel processors: 8086, 80286, 80386, and 80486. x86 has persisted across three generations of word lengths: 16-, 32-, and 64-bit architectures. As a commercial product, it has strongly emphasized rigorous backward compatibility with all previous generations, at the cost of adding complexity to the design, including digital logic to ensure historical bugs are kept in order to allow old games that exploit them as features to continue to run. You can still take your executable machine code from the 1970s and run it on a modern x86 and it will “just work.” (This is a similar approach to software design in commercial operating systems, which similarly grow to huge, bloated sizes to maintain compatibility for customers at the expense of performance and beauty.) As a result of continually adding new CISC instructions and keeping all the old ones, the latest version of x86—the <em>amd64</em> ISA—now includes over 3,000 instructions, documented in a five-volume set of reference books.</p>&#13;
<h4 class="h4" id="lev265"><em>Prehistory</em></h4>&#13;
<p class="noindent">The history of x86 design is one of Silicon Valley architecture and politics, and specifically of the companies Intel and AMD. Both companies make processors using the same proprietary instruction set, and they’re constantly locked in legal battles with each other, which have now spanned decades.</p>&#13;
<p class="indent">William Shockley, John Bardeen, and Walter Brattain were awarded the Nobel Prize in Physics in 1956 for their invention of the transistor at Bell Labs, New Jersey. Shockley’s family was from Palo Alto, California, though he was born in London. After winning a Nobel Prize, you can live and work wherever you like, so Shockley decided to relocate from New Jersey to Mountain View, California, because he wanted to be near his mother <span epub:type="pagebreak" id="page_305"/>in Palo Alto. He set up Shockley Semiconductor there to continue his transistor research and commercialization.</p>&#13;
<p class="indent">By 1957, Shockley had become a difficult person to work with due to a mixture of Nobel laureate hubris and obsession with topics considered fringe by his staff. A group of employees, the so-called “traitorous eight”—including Gordon Moore and Robert Noyce—walked out on Shockley to set a rival firm, Fairchild Semiconductor. This was considered almost blasphemous by the commercial culture of the time, in which it was assumed people would join a big company and be loyal company servants for their whole careers. It has since become the blueprint for Silicon Valley’s startup culture, in which it’s assumed employees will and should leave big companies to start their own.</p>&#13;
<p class="indent">Fairchild created the first commercial version of the integrated circuit (chip). Demand for computing at this time was almost entirely from the American military, which used taxpayer money to subsidize research and buy the products of chipmakers to power missiles and planes for the Cold War. These government funds fed the silicon industry, accelerating the growth of Fairchild and also many rival upstarts as Fairchild staff copied the Fairchild model and left to start their own competing chip companies, giving rise to modern Silicon Valley.</p>&#13;
<p class="indent">In 1968, Fairchild politics led Gordon Moore and Robert Noyce to quit again—this time leaving Fairchild to set up Intel (short for Integrated Electronics). AMD (Advanced Micro Devices) was founded the following year by Jerry Sanders. AMD’s early goal was to copy Intel’s products and produce them more cheaply as a second source. Before the x86 series proper, Intel produced the 4-bit 4004 in 1971. AMD cloned it shortly afterward in 1975 as the Am9080. Intel preempted this in 1974 with an 8-bit version, the 8080 (3 MHz), which was then also copied by AMD.</p>&#13;
<h4 class="h4" id="lev266"><em>16-Bit Classical Era</em></h4>&#13;
<p class="noindent">The first member of the x86 family proper—defined by modern backward compatibility—was Intel’s 16-bit, 5 MHz 8086 chip, made in 1978. This was a CISC chip that used microprogramming. x86 is named after its last two digits.</p>&#13;
<p class="indent">Competition between Intel and AMD became formalized in 1982 by a three-way contract between Intel, AMD, and IBM, whose business at the time was building computers. IBM wanted to buy CPUs for its computers but didn’t want to be locked into using a proprietary design from a single company, because such a company could then hold IBM to ransom via the lock-in and increase its prices. As a huge company, IBM had enough buying power to play suppliers against one another to get what it really wanted, which was for more than one company to compete to produce the same chips as generic commodities; this would push down the prices and enable IBM to get them cheap in perpetuity. IBM said to Intel, “We want to buy your chips, but we’ll buy them only if you sign this contract saying you’ll let AMD copy them. If you don’t sign, then we won’t buy from either of you.” <span epub:type="pagebreak" id="page_306"/>The three companies agreed and thus created the famous Intel-AMD cross-license for both chipmakers to design and sell chips implementing the same x86 ISA.</p>&#13;
<p class="notes"><strong><span class="nt">NOTE</span></strong></p>&#13;
<p class="noindent"><em>This is a general lesson about computer economics: after a sale, the seller of a hardware or software platform can wield extreme power over the buyer via lock-in. Platform sellers should thus try to initially give away their platforms for free or at large discounts, to get users locked into them, before ramping up their sales terms once they have the buyer over a barrel. But before the buyer selects a platform, it’s the buyer who holds all the power and calls the shots. Thus, buyers should negotiate hard to formalize a contract that mitigates the seller’s power over them later. Once you hand over the money, you have no power except what was agreed in that contract.</em></p>&#13;
<p class="indenta">The IBM deal propelled both chipmakers into the business computing market, enabling them to scale rapidly. After the deal, Intel updated the 8086 with its 80186 (1982; 6 MHz), followed soon after by the 80286 (1982; 8 MHz), which added protected mode for OS support for the first time. AMD then quickly cloned the 80286 as its Am286 (1982; 8 MHz). These 16-bit devices were appearing in the early 1980s as high-end business machines, at the same time that the 8-bit golden age was arriving in homes.</p>&#13;
<h4 class="h4" id="lev267"><em>32-Bit Clone Wars Era</em></h4>&#13;
<p class="noindent">The 32-bit era began with Intel’s 386 (1985; 16 MHz), which introduced the 32-bit instruction set x86 IA-32. Throughout this era, we saw continual antagonism and legal action between the two big chipmakers; this was made more entertaining by the entry of additional competitors Cyrix and Via, who also made x86 clones. <a href="ch13.xhtml#ch13tab1">Table 13-1</a> summarizes these developments.</p>&#13;
<p class="tabcap" id="ch13tab1"><strong>Table 13-1:</strong> 32-Bit Era x86 Developments</p>&#13;
<table class="allc">&#13;
<colgroup>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:55%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Year</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Maker</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Architecture</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Features</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">1985</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">386</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">16 MHz</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">1989</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">486</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">50 MHz, pipelined, FPU</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">1991</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Am386</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Clone of 386</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">1993</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Pentium</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">75 MHz, superscalar</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">1993</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Am486</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Clone of 486 (last clone)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">1995</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">P5</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">150 MHz, MMX SIMD “Pentium MMX”</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">1995</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">P6 (i686)</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">200 MHz, SSE SIMD, OOOE, “Pentium Pro”</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">1996</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">K5</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">133 MHz, Pentium-like</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">1995</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Cyrix</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Cx5x86</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">140 MHz, Pentium-like</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">1996</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Cyrix</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">6x86</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">140 MHz, Pentium-like</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">1997</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">K6</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">300 MHz, 3D-NOW, rival SIMD</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">2001</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">VIA</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">C3</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">500 MHz, Pentium-like</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2001</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Athlon</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2 GHz</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">Intel was usually the technical leader, creating new technologies such as pipelined designs and extension instructions, with the others copying a year <span epub:type="pagebreak" id="page_307"/>or two later to bring the price down. At every step, clock speeds reliably got faster, following Moore’s law for clock speed. This was the “bland 1990s,” where customers assumed they would need to buy a new beige desktop computer every 18 months to keep up with doubling clock speeds.</p>&#13;
<p class="indent">After the 486, Intel got sick of competitors copying the untrademarkable 86 name, so they switched to the trademarkable brand name “Pentium.” This was the dominant chip for some time, but then AMD took the lead by becoming the first to reach 1 GHz speed with its Athlon in 2001.</p>&#13;
<h4 class="h4" id="lev268"><em>64-Bit Branding Era</em></h4>&#13;
<p class="noindent">The 64-bit era of x86 arrived in 2000 when AMD formally defined the amd64 ISA, which was adopted by most CISC processors following it. This was a coup: the x86 ISA family had previously always been defined by Intel, with others pegging their own products to them.</p>&#13;
<p class="indent">Intel attempted to define its own failed 64-bit competitor ISA, called IA-64, but this was released after amd64 and never caught on; today, everyone uses amd64. Intel, however, refuses to acknowledge the name amd64, instead referring to the same ISA as x86_64. Confusingly, you’ll see both names used to describe executable software downloads for this ISA, such as in the names of Linux distribution packages.</p>&#13;
<p class="indent">The 64-bit era is characterized by a separation of marketing terms from the underlying technologies, with the same marketing brand often used to label completely different architectures. Unlike the previous 32-bit Pentium, the branding is no longer attached to specific designs. You’re probably used to seeing 64-bit products with brands like Pentium, Celeron, and Xeon. You may also see the numbers 3, 5, 7, and 9 in brand names, as in Core i3, Core i5, and so on. For Intel, these numbers don’t mean anything other than suggesting an ordering of which products are better; AMD uses the same numbers to suggest which products are similar to Intel’s.</p>&#13;
<p class="indent"><a href="ch13.xhtml#ch13tab2">Table 13-2</a> shows examples of Intel and AMD releases and some of their notable features during the 64-bit era.</p>&#13;
<p class="indent">Pipelines have varied between around 14 and 20 stages during this period, and OOOE has been used throughout. AMD Piledriver was the first to introduce neural network–based branch prediction hardware.</p>&#13;
<p class="indent">Clock speeds hit 3.5 GHz around the start of the 64-bit era and have been stuck there ever since, due to the end of Moore’s law for clock speed. However, Moore’s law for transistor size continued to hold, and it became common to define machines by their transistor scale, in nanometers (nm) per transistor, rather than their clock speed, to show the continued progress. Between 2006 and 2016, Intel used a “tick-tock” cycle, in which their new products alternated between new digital logic designs (tock) and the use of new transistor technologies to make the same design smaller and faster (tick). <em>Boosts</em> are a feature first added in Nehalem, which <em>temporarily</em> increase the clock speed beyond the usual 3.5 GHz heat limit for short periods of time at the bottlenecks of intensive computations.</p>&#13;
<p class="tabcap" id="ch13tab2"><span epub:type="pagebreak" id="page_308"/><strong>Table 13-2:</strong> 64-Bit Era x86 Developments</p>&#13;
<table class="allc">&#13;
<colgroup>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:15%"/>&#13;
<col style="width:40%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Year</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Maker</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Architecture</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Transistor size (nm)</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Branding</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2003</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Hammer (K8)</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">130</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Opteron</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">2005</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Hammer (K8)</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">90</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Athlon 64 X2</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2006</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Core</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">65</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Celeron/Pentium/Xeon</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">2007</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">10h (K10)</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">65</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Opteron</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2008</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Nehalem</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">45</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Pentium, Xeon, Core (1st generation)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">2011</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Sandy Bridge</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">32</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">2nd-generation Core i3/i5/i9; Xeon</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2012</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Piledriver</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">32</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Opteron</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">2013</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Haswell</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">22</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">4th-generation Core i3/5/7; Celeron/Pentium/Xeon</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2015</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Skylake</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">14</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">6th-generation Core i3/5/7; Celeron/Pentium/Xeon; CoreM</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">2017</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Coffee Lake</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">14</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">8th-generation Core i3/5/7; Celeron/Pentium Gold/Xeon</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2017</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Zen</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">14</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Ryzen 3/5/7 1000 series</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">2018</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Zen+</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">12</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Ryzen 3/5/7 2000 series</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2019</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Zen2</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">7</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Ryzen 3/5/7 3000 series</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">2020</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Zen3</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">7</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Ryzen 5/7/9 5000 series</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2021</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Cypress Cove</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">14</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">11th-generation Core i5/7/9; Xeon</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">2021</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Intel</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Golden Cove</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">7</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">12th-generation Core i5/7/9; Xeon</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">2022</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AMD</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Zen4</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">5</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Ryzen 5/7/9 7000 series</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">Now that we’ve seen how x86 evolved, let’s look at its instruction set and learn how to program it. This will be a messier experience than for the other architectures we’ve studied, but hopefully, by understanding the history, you can at least understand why things ended up this way.</p>&#13;
<h3 class="h3" id="lev269">Programming x86</h3>&#13;
<p class="noindent">x86 is big and ugly; its code is usually generated by compilers rather than written by hand. Still, it’s worth your time to study it if you want to better understand what your compiler and computer are doing, or if you want to write compilers or other system software such as operating systems and bootloaders. Because x86 is such a widely used architecture, understanding it is also useful in security applications, such as cracking and defending code, including cheat and anti-cheat systems for games.</p>&#13;
<p class="indent">As a CISC architecture, x86 often has many variations of each instruction, taking different types of operand, such as constants, registers, and memory locations. Groups of instructions have been added at different points in the architecture’s history, and they don’t always use the same conventions: for example, integer addition, integer multiplication, and floating-point operations all present very different interfaces to the programmer. You wouldn’t design a new CPU from scratch using such different interfaces; this mess is simply how the architecture has grown over time.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_309"/>This won’t be an exhaustive tour of x86 features. Rather, we’ll look at a couple of examples to give a flavor of how CISC extensions are created and how they operate.</p>&#13;
<h4 class="h4" id="lev270"><em>Registers</em></h4>&#13;
<p class="noindent">Because of the way x86 has evolved over time and its requirement for backward compatibility, its register set has grown into a particular form. There are two general types of register; let’s look at each.</p>&#13;
<h4 class="h4a"><strong>General-Purpose Registers</strong></h4>&#13;
<p class="noindent">There are eight general-purpose user registers in x86 architecture. Their names reflect their traditional uses. <a href="ch13.xhtml#ch13tab3">Table 13-3</a> shows them.</p>&#13;
<p class="tabcap" id="ch13tab3"><strong>Table 13-3:</strong> x86 General-Purpose Registers</p>&#13;
<table class="allc">&#13;
<colgroup>&#13;
<col style="width:15%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:60%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Register</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Meaning</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Use</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">AX</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Accumulator register</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Arithmetic operations</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">BX</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Base register</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">A pointer to data</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">CX</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Counter register</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Shift, rotate, and loop instructions</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">DX</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Data register</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Arithmetic and I/O operations</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">SP</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Stack pointer register</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">A pointer to the top of the stack</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">BP</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Stack base pointer register</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">A pointer to the base of the stack</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">SI</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Source index register</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">A pointer to a source for data copies</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">DI</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Destination index register</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">A pointer to a destination for data copies</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">In the original 16-bit 8086, the general-purpose registers all had 16 bits. To retain partial backward compatibility with the previous 8-bit 8080, the first four—AX, BX, CX, and DX—can also be split into two 8-bit registers, named with H and L for high and low bytes, which can be accessed independently.</p>&#13;
<p class="indent">IA-32 extended the eight registers to have 32-bits. They can still be accessed as 16- or 8-bit registers as before, to maintain compatibility. To access them in their full 32-bit mode, we add the prefix E (for <em>extended</em>) to their names: EAX, EBX, ECX, and so on.</p>&#13;
<p class="indent">amd64 extended the eight registers again, to 64 bits. As before, the 32-, 16-, and 8-bit versions are left intact for compatibility. To access them in 64-bit mode, we add the prefix R to their names: RAX, RBX, RCX, and so on. amd64 also added eight more 64-bit general-purpose registers, named R8 through R15.</p>&#13;
<p class="indent">As x86 is defined as the family based on the 16-bit system, and has to retain backward compatibility, a <em>word</em> in x86 speak still means 16 bits of data, rather than the full size of the modern registers. <em>Doubleword</em> or <em>dword</em> means 32 bits, and <em>quadword</em> or <em>qword</em> means 64 bits.</p>&#13;
<p class="indent"><a href="ch13.xhtml#ch13fig1">Figure 13-1</a> summarizes the evolution of the general-purpose x86 registers.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_310"/><img id="ch13fig1" src="../images/f0310-01.jpg" alt="Image" width="892" height="544"/></div>&#13;
<p class="figcap"><em>Figure 13-1: The x86 registers. Register names are shown to the left of each register, apart from 8-bit register names, which are shown in the center of the register.</em></p>&#13;
<p class="indent">For compatibility with these different word sizes, memory addressing is always done <em>per byte</em>, even on a modern amd64. This is in contrast to addressing, say, non-overlapping 64-bit <em>words</em> of memory. Words are stored in memory as little-endian bytes.</p>&#13;
<h4 class="h4a"><strong>Internal Registers</strong></h4>&#13;
<p class="noindent">The program counter is called the <em>instruction pointer</em> in x86 speak, identified as IP, EIP, or RIP when used in its 16-, 32-, or 64-bit form, respectively.</p>&#13;
<p class="indent">The status register is called FLAGS, EFLAGS, or RFLAGS, again when used in 16-, 32-, or 64-bit form. Its structure is shown in <a href="ch13.xhtml#ch13fig2">Figure 13-2</a>.</p>&#13;
<div class="image"><img id="ch13fig2" src="../images/f0310-02.jpg" alt="Image" width="1118" height="285"/></div>&#13;
<p class="figcap"><em>Figure 13-2: The x86 status register (compare with <a href="ch11.xhtml#ch11fig6">Figure 11-6</a>)</em></p>&#13;
<p class="indent">This is very like the 6502’s status register, with similar mnemonics. As with the 6502, these flags are set with comparison instructions, then consulted with separate branch instructions. There are also instructions to clear flags. Two important flags, as in other architectures, are the zero flag (ZF) and sign flag (SF).</p>&#13;
<h4 class="h4" id="lev271"><span epub:type="pagebreak" id="page_311"/><em>Netwide Assembler Syntax</em></h4>&#13;
<p class="noindent">Because of its long history, x86 has acquired several different assembly languages with different syntaxes, which all assemble into the same machine code. Here we’ll use the <em>Netwide Assembler (NASM)</em> style, which is the least worst of them.</p>&#13;
<p class="noindent">x86 instructions usually have two operands. In NASM syntax, the first is usually the destination and sometimes also an input that gets updated to store the result, like an accumulator; the second operand is an input.</p>&#13;
<p class="indent">Like most assemblers, NASM enables us to label lines of a program with text labels by inserting the label as text, followed by a colon, like so:</p>&#13;
<pre>mylabel:</pre>&#13;
<p class="noindent">If a label is inserted on line 5, we can jump to or load from line 5 by using its label name rather than the number 5.</p>&#13;
<h4 class="h4a"><strong>Data Movement</strong></h4>&#13;
<p class="noindent">To copy constants or register contents between registers and RAM, you can use the same <code>mov</code> (move) instruction. This generalizes all of loading, storing, and moving. Several different addressing modes are provided.</p>&#13;
<p class="indent"><em>Immediate addressing</em> places constants into registers. For example:</p>&#13;
<pre>mov rbx, 123         ; place decimal 123 into register RBX&#13;
mov ebx, 4c6h        ; place hex 4c6 into register EBX&#13;
mov bh, 01101100b    ; place binary 01101100 into register BH</pre>&#13;
<p class="indent"><em>Register addressing</em> copies data from one register to another inside the CPU, such as:</p>&#13;
<pre>mov rax, rbx         ; copy to RAX from RBX</pre>&#13;
<p class="indent"><em>Direct addressing</em> loads from and stores to memory through a specified address. Labels can be used in place of numerical addresses, in which context they’re known as <em>variables</em>. For example:</p>&#13;
<pre>mov rbx, [1000h]      ; load to RBX from hex address 1000&#13;
mov [1000h], rbx      ; store to hex address 1000 from RBX&#13;
mov rbx, [1000h+20h]  ; load from an address with offset&#13;
mov [1000h+20h], rbx  ;  store to an address with offset&#13;
mov rbx, myvar        ; load a labeled address (address, not its content)&#13;
mov rbx, [myvar]      ; load content of a labeled address&#13;
mov [myvar], rbx      ; store to a labeled address from RBX</pre>&#13;
<p class="indent"><em>Register indirect addressing</em> is notated using square brackets, such as:</p>&#13;
<pre>mov rax, [rdi]         ; copy to RAX, from content of the address in RDI&#13;
mov [rdi], rax         ; copy to address in RDI, from RAX</pre>&#13;
<p class="indent">In these two instructions, RDI is assumed to contain an address that in turn is used to load or store the value from RAX.</p>&#13;
<h4 class="h4a"><span epub:type="pagebreak" id="page_312"/><strong>Data Creation</strong></h4>&#13;
<p class="noindent">Data locations in RAM can be given names, and can be initialized or uninitialized. To initialize a location with a value and create a name for it, we use commands beginning with <code>d</code>, for <em>define</em>. For example:</p>&#13;
<pre>mybyte: db 15          ; define byte&#13;
myword: dw 452         ; define word (2 bytes)&#13;
mydword: dd 478569     ; define doubleword (4 bytes)&#13;
myqword: dq 100000000  ; define quadword (8 bytes)</pre>&#13;
<p class="indent">To name an uninitialized location, we use commands beginning with <code>r</code>, for <em>reserve</em>:</p>&#13;
<pre>mybyte:  resb 1        ; reserve uninitialized 1 byte&#13;
myword:  resw 1        ; reserve uninitialized 1 word&#13;
mydword: resw 1        ; reserve uninitialized 1 doubleword&#13;
myqword: resw 1        ; reserve uninitialized 1 quadword</pre>&#13;
<p class="noindent">Note that these aren’t x86 instructions, but rather just labeled regions of data, with the directives telling NASM to treat them as such.</p>&#13;
<p class="indent">To create arrays, we simply allocate a set of consecutive addresses. For example:</p>&#13;
<pre>myarray:  dq 1, 2, 3, 4 ; define 4 quadwords, myarray addresses first element&#13;
myzeros:  times 4 dw 0  ; define 4 doublewords all to 0&#13;
mywords:  resw 100      ; reserve uninitialized 100 words&#13;
mystring: db "hello", "world", 10, 0    ; define a single 12-char ASCII string</pre>&#13;
<p class="indent">NASM also provides macro directives, which enable you to define numeric <code>(equ)</code> and string <code>(%define)</code> constants:</p>&#13;
<pre>SCREEN_WIDTH equ 1920&#13;
%define isTrue 1</pre>&#13;
<p class="indent">NASM substitutes for these constants’ values before doing the assembly. These macro directives aren’t part of the x86 instructions set, but NASM provides them for convenience.</p>&#13;
<h4 class="h4a"><strong>Arithmetic and Logic</strong></h4>&#13;
<p class="noindent">As x86 instructions are usually designed to take two arguments, most arithmetic is done accumulator-style. There isn’t a single accumulator register, but any register can act like one. For example, here we place the value 1 into RBX and add 2 into it, so it ends up storing the result, 3:</p>&#13;
<pre>mov rbx, 1&#13;
add rbx, 2</pre>&#13;
<p class="indent">As a CISC architecture, variations of arithmetic instructions usually exist that combine loading data from memory with the arithmetic. For example, <span epub:type="pagebreak" id="page_313"/>here’s how to add two numbers from addresses 1000h and 2000h and put the result in RBX:</p>&#13;
<pre>mov rbx, [1000h]&#13;
add rbx, [2000h]</pre>&#13;
<p class="noindent">Note that x86 <em>doesn’t</em> include the most extreme CISC style of addition, such as <code>[3000h] := [1000h]+[2000h]</code>, which combines two loads, one addition, and one store in a single instruction.</p>&#13;
<p class="indent">Subtraction works similarly to addition:</p>&#13;
<pre>sub ax, 5</pre>&#13;
<p class="indent">Incrementing and decrementing 8-, 16-, or 32-bit operands can be done using the <code>inc</code> and <code>dec</code> instructions:</p>&#13;
<pre>dec ax                ; decrement content of register&#13;
inc [mybyte]          ; increment content of variable mybyte</pre>&#13;
<p class="indent">To multiply or divide integer operands, x86 provides <code>mul</code> and <code>div</code> instructions. Unlike addition and subtraction, these always use the A register as the accumulator (hence its name) and act on it with the operand given to the instruction. For example:</p>&#13;
<pre>; 64-bit multiplication&#13;
mov rax, 2&#13;
mov rbx, 3&#13;
mul rbx      ; result 6 is in accumulator RAX&#13;
; 16-bit multiplication&#13;
mov ax, 20   ; first operand&#13;
mov bx, 4    ; second operand&#13;
mul bx       ; result is stored in AX&#13;
; 8-bit division&#13;
mov al, 10   ; dividend&#13;
mov bl, 2    ; divisor&#13;
div bl       ; result stored in AL&#13;
; 16-bit signed division&#13;
mov ax, -48 ; dividend is negative, need signed version&#13;
cwd          ; extend AX into DX&#13;
mov bx, 5&#13;
idiv bx      ; result in AX, remainder in DX</pre>&#13;
<p class="indent">In the last of the above examples, the prefix <code>i</code> is added to the <code>div</code> instruction to indicate that signed integers are used. The <code>cwd</code> instruction converts a word to a double by allowing the DX register to be used as an extension of AX in order to accommodate the sign information.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_314"/>Bitwise logic instructions include <code>and, or, not</code>, and <code>xor</code>. For example:</p>&#13;
<pre>and ax, 01h&#13;
or  ax, bx&#13;
not ax</pre>&#13;
<p class="noindent">As with addition, the first operand acts as an accumulator so gets overwritten with the result.</p>&#13;
<h4 class="h4a"><strong>Flow Control</strong></h4>&#13;
<p class="noindent">NASM provides two types of labels, symbolic and numeric, that can both be used for jumps and branches. Symbolic labels consist of an identifier followed by a colon (:). They must be defined only once, as they have global scope. If the label identifier begins with a period (.), it’s considered local and can be used only in the current file. Here’s an infinite loop using a symbolic label and a jump:</p>&#13;
<pre>mylabel:&#13;
    jmp mylabel</pre>&#13;
<p class="indent">Numeric labels consist of a single digit in the range 0 to 9 followed by a colon. Numeric labels are considered local. They also have limited scope so can be redefined repeatedly. When a numeric label is used as a reference (as an instruction operand, for example), the suffixes <code>b</code> (for backward) or <code>f</code> (for forward) should be added to the numeric label. For numeric label <code>1</code>, the reference <code>1b</code> refers to the nearest label <code>1</code> defined before the reference, and the reference <code>1f</code> refers to the nearest label <code>1</code> defined after the reference. For example:</p>&#13;
<pre>main:&#13;
    1:                ; define new numeric label&#13;
    ; do something&#13;
    jmp 1f            ; jump to first numeric label "1" defined&#13;
    1:                ; redefine existing label&#13;
    ; do something&#13;
    jmp 1b            ; jump to last numeric label "1" defined</pre>&#13;
<p class="indent">Conditional jumps are performed using pairs of instructions. First, we use the <code>cmp</code> instruction to compare two values. It takes two operands to compare and raises appropriate flags in the status register. Next, a conditional jump instruction consults the status register to determine whether or not to make the jump. Some of the available conditional jump types are listed in <a href="ch13.xhtml#ch13tab4">Table 13-4</a>.</p>&#13;
<p class="tabcap" id="ch13tab4"><span epub:type="pagebreak" id="page_315"/><strong>Table 13-4:</strong> x86 Conditional Jump Instructions</p>&#13;
<table class="allc">&#13;
<colgroup>&#13;
<col style="width:15%"/>&#13;
<col style="width:85%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Instruction</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Condition</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext"><code>je</code></p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Jump if <code>cmp</code> is equal</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext"><code>jne</code></p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Jump if <code>cmp</code> is not equal</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext"><code>jg</code></p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Signed &gt; (greater)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext"><code>jge</code></p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Signed &gt;=</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext"><code>jl</code></p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Signed &lt; (less than)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext"><code>jle</code></p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Signed &lt;=</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext"><code>ja</code></p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Unsigned &gt; (above)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext"><code>jae</code></p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Unsigned &gt;=</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext"><code>jb</code></p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Unsigned &lt; (below)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext"><code>jbe</code></p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Unsigned &lt;=</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext"><code>jc</code></p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Jump if carry (used for unsigned overflow or multi-precision add)</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext"><code>jo</code></p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Jump if there was signed overflow</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">To illustrate, this program uses the <code>cmp</code> and <code>je</code> instructions to make a jump if the compared values are equal:</p>&#13;
<pre>cmp 15, 10&#13;
je equal              ; jump to "equal" label if equal&#13;
; continue if jump condition is false&#13;
cmp 10,10&#13;
je equal&#13;
equal:&#13;
    ; they are equal</pre>&#13;
<p class="indent">Subroutines are called and returned from as follows:</p>&#13;
<pre>main:&#13;
    call somefunction&#13;
&#13;
somefunction:&#13;
    ; some content&#13;
    ret</pre>&#13;
<p class="noindent">The <code>call</code> instruction jumps to the subroutine with the given label, and <code>ret</code> returns from the subroutine to the calling location.</p>&#13;
<h4 class="h4a"><strong>The Stack</strong></h4>&#13;
<p class="noindent">Subroutine calls and returns are implemented internally using a stack. If you’re just writing simple calls and returns, as in the example we just looked at, you don’t need to see or think about the stack yourself. However, x86 also allows you to access the stack directly to pass arguments or for other purposes. Specifically, registers SS and ESP (or SP) are provided and used <span epub:type="pagebreak" id="page_316"/>for implementing the stack. The stack is limited to storing only words and doublewords. Here’s how it works:</p>&#13;
<pre>; save register values&#13;
push ax&#13;
push bx&#13;
; perform whatever you want with these registers&#13;
; restore the value&#13;
pop bx&#13;
pop ax</pre>&#13;
<p class="indent">Here, the contents of registers AX and BX are pushed to the stack, meaning these registers can then be overwritten and used for other purposes, before being restored by the pop instructions.</p>&#13;
<div class="sidebar">&#13;
<p class="stitle"><strong>X86 CALLING CONVENTIONS</strong></p>&#13;
<p class="stext">The x86 architecture has been used with many different calling conventions during its history. Due to the small number of architectural registers, and a historical focus on simplicity and small code size, many x86 calling conventions pass arguments on the stack. The return value (or a pointer to it) is returned in a register. Some conventions use registers for the first few parameters, which may improve performance, especially for short and simple <em>leaf routines</em> that are very frequently invoked (these are routines that don’t call other routines).</p>&#13;
<p class="stext">For amd64, there are two current conventions in widespread use, one suggested by System V UNIX designers and the other by Microsoft. They agree that the caller rather than callee should clean up the stack. They both require the first few arguments to be passed in registers, with the later arguments on the stack, right to left, though they disagree on how many and which registers to use. They disagree on which registers are <em>temporary</em>—that is, which can be overwritten by the callee during a function call. This is in contrast to those that are <em>safe</em>, guaranteed to not be changed by function calls.</p>&#13;
</div>&#13;
<h4 class="h4a"><strong>BIOS I/O</strong></h4>&#13;
<p class="noindent">We can call BIOS routines from ROM to communicate with the screen and keyboard, as on a retro computer. For example:</p>&#13;
<pre>; BIOS Character display&#13;
mov ah, 0eh      ; set mode&#13;
mov al, 'H'      ; char 'H' to print&#13;
int 10h          ; ask BIOS to display letter on screen&#13;
; BIOS Character input&#13;
mov ah, 00h&#13;
int 16h          ; ask BIOS to read a keypress char to AL&#13;
; BIOS Graphics   (only works in 16-bit mode)&#13;
mov al, 13h      ; desired graphics mode&#13;
mov ah, 0        ; set graphics mode&#13;
int 10h          ; ask BIOS to set graphics mode&#13;
mov al, 1100b    ; desired pixel RGB color&#13;
mov cx, 10       ; desired pixel x coordinate&#13;
mov dx, 20       ; desired pixel y coordinate&#13;
mov ah, 0ch      ; ask BIOS to light the pixel&#13;
int 10h</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_317"/>This sets a screen mode, prints an ASCII character to a location on the screen, reads an ASCII character from the keyboard, and sets a pixel color. These are all the basic ingredients you need to make 8 bit–style video games. The <code>int</code> instructions here generate interrupt requests, which pass control to the BIOS, and their operands tell the BIOS which of its subroutines is to be run. These subroutines each assume that their arguments have been placed into particular registers such as AH and AL before the interrupt is made.</p>&#13;
<h4 class="h4a"><strong>Floating Point</strong></h4>&#13;
<p class="noindent">The x86 floating-point architecture derives from the 8086’s old coprocessor, the 8087. This was a separate, optional chip for accelerating numerical computation. Since the 486, the FPU moved into the main x86 architecture, where it has become known as the <em>x87 extension</em>.</p>&#13;
<p class="indent">The x87 extension adds dedicated floating-point registers called ST0 to ST7, which are used as a stack (hence the prefix <em>ST</em>); the stack has a maximum of eight elements, with ST0 being the top. New floating-point instructions start with the letter <code>F</code> and move data to and from this stack; they instruct the FPU to perform arithmetic using the top items of the stack.</p>&#13;
<p class="indent">You can push floats to the x87 stack, call arithmetic on them, and pop the result back, such as:</p>&#13;
<pre>a: dw 1.456            ; a word (16-bit) float&#13;
b: dd 1.456            ; a doubleword (32-bit) float&#13;
c: resq 1              ; reserve for output float&#13;
;FP add&#13;
fld qword [a]          ; load a (pushed on flt pt stack, st0)&#13;
fadd qword [b]         ; floating add b (to st0)&#13;
fstp qword [c]         ; store result into c (pop flt pt stack)&#13;
;FP multiply&#13;
fld qword [a]          ; load a (pushed on flt pt stack, st0)&#13;
fmul qword [b]         ; floating multiply by b (to st0)&#13;
fstp qword [c]         ; store result into c (pop flt pt stack)</pre>&#13;
<p class="indent">Here, when you give an ASCII representation of a float to NASM for any of the word lengths used, NASM knows to convert it to IEEE binary representation for you.</p>&#13;
<h4 class="h4" id="lev272"><em>Segmentation</em></h4>&#13;
<p class="noindent">x86 programs can be written as collections of <em>segments</em>, which are separate chunks of a program that can be stored in different locations in memory. <span epub:type="pagebreak" id="page_318"/>For example, if you wish to keep your instructions apart from your data (as in a Harvard architecture), you can do this by using a separate code segment and data segment. A stack segment can also be used to keep the hardware stack data separate from both. Segments all live in the same global address space, but by storing the start address of each segment in a dedicated register, addresses within them can afterward be referred to by just their offset from the segment start. This system was intended as a way for 16-bit CPUs to work with more than 64 k<sub>2</sub>B of RAM. It still exists but isn’t used much in modern 64-bit x86, because the 64-bit address space is so large anyway. Six <em>segment registers</em>, called CS, SS, DS, ES, FS, and GS, are specified to hold the segment start addresses.</p>&#13;
<p class="indent">If you’re using the segment system, the NASM directive <code>section</code> specifies code and data segments. In some settings, some assemblers will still look for sections and assume that <code>section .text</code> is read-only and that <code>section .data</code> is read-write, even though the concepts are no longer used at the amd64 hardware level. A <em>segmentation fault</em> will occur if you try to access a segment that the assembler doesn’t want you to access.</p>&#13;
<h4 class="h4" id="lev273"><em>Backward-Compatible Modes</em></h4>&#13;
<p class="noindent">Part of the x86 standard is that all CPUs have to be backward-compatible with the original 16-bit 8086. This means that when they first power on, they have to start in 16-bit mode and behave exactly like an 8086.</p>&#13;
<p class="indent">From there, 32-bit x86s have instructions that switch them into 32-bit mode, and 64-bit x86s have further instructions to switch from 32-bit to 64-bit mode. To boot an amd64, you therefore progressively switch up into 32- and then 64-bit mode, replaying the history of its architecture in a fraction of a second.</p>&#13;
<p class="indent">Now that we have an understanding of the x86 architecture, let’s zoom out to consider the PC computer design that uses it as the CPU component.</p>&#13;
<h3 class="h3" id="lev274">PC Computer Design</h3>&#13;
<p class="noindent">The desktop PC is a different concept from the other computers we’ve studied: rather than specifying one particular computer design, it’s a loose collection of formal and informal standards. The first PCs were designed and defined as such by IBM, beginning in 1981 with the IBM 5150, seen in <a href="ch11.xhtml#ch11fig1">Figure 11-1</a>; they were then copied by other manufacturers using similar compatible components.</p>&#13;
<p class="indent">In the 1990s, any computer with an x86 CPU capable of running a Microsoft DOS or Windows operating system was generally considered to be a PC. Microsoft chose what computer design features to support in this software, so it effectively set the standard definition. Other operating systems could also run on many of these machines while making different support choices. Often there are multiple competing standards for computer design features, and it becomes a political as well as technical question which ones get taken up by the PC community.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_319"/>Programming and using PCs thus feels different than more standardized platforms. For example, games created for a particular machine, such as a Commodore 64, can assume a precise hardware feature set and will run exactly the same on any Commodore 64. This enables the game designer to work as an artist, making the game look and feel exactly as they intend. But a game made for PCs will run differently on different PCs with different features, requiring game designers to create what is really a whole set of similar games, some of which they’ll never see themselves and can only guess at how to implement. Similarly, game players may have to get more involved in configuring their hardware and software to customize which version of the game they want to play.</p>&#13;
<p class="indent">Here we’ll look at some specific examples of buses, I/O modules, and devices used in today’s desktop PCs. These can often form the bottlenecks in modern PCS—there’s little use in having a highly optimized CPU if it has to spend its time waiting on other parts of the system. When you buy a computer, don’t just look at CPU speed—think about these supporting structures, too.</p>&#13;
<h4 class="h4" id="lev275"><em>The Bus Hierarchy</em></h4>&#13;
<p class="noindent">Like CPUs, buses are continually being improved and replaced, so the PC architecture has used various standard bus hierarchies over time. Buses can be found in a desktop PC at several layers; each layer has different uses and different bandwidths, and is optimized for different purposes. <a href="ch13.xhtml#ch13tab5">Table 13-5</a> shows some recent standards with their speeds and typical uses.</p>&#13;
<p class="tabcap" id="ch13tab5"><strong>Table 13-5:</strong> PC Bus Speeds and Uses</p>&#13;
<table class="allc">&#13;
<colgroup>&#13;
<col style="width:25%"/>&#13;
<col style="width:25%"/>&#13;
<col style="width:50%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Standard</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Bandwidth (GBps)</strong></p></th>&#13;
<th style="vertical-align: top" class="borderb"><p class="tabtext"><strong>Uses</strong></p></th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Gigabit Ethernet</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">1</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Network</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">USB3</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">5</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Peripherals</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">SATA3</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">6</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Secondary storage</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top"><p class="tabtext">NVMe</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">32</p></td>&#13;
<td style="vertical-align: top"><p class="tabtext">Secondary storage</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">PCI express 5.0 x16</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">63</p></td>&#13;
<td style="vertical-align: top" class="gray"><p class="tabtext">Graphics cards</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">You can see that communication with the outside world via Ethernet is at the slower end, local peripherals and secondary storage are in the middle, and graphics cards have had a lot of work done to make them communicate quickly.</p>&#13;
<p class="indent">The classic PC hierarchy used two structures called Northbridge and Southbridge—known together as the <em>chipset</em>—as the main skeleton of the bus hierarchy. This is shown in <a href="ch13.xhtml#ch13fig3">Figure 13-3</a>.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_320"/><img id="ch13fig3" src="../images/f0320-01.jpg" alt="Image" width="542" height="798"/></div>&#13;
<p class="figcap"><em>Figure 13-3: The Northbridge-Southbridge bus architecture</em></p>&#13;
<p class="indent"><em>Northbridge</em> connects directly to the CPU’s FSB (front-side bus) and links it to RAM and to fast I/O modules using the same address space via PCIe bus. It also connects to Southbridge. Northbridge is fast and powerful. It was traditionally constructed on a separate chip from the CPU that also hosted some memory cache levels. More recently, Northbridge has moved onto CPU silicon in many systems.</p>&#13;
<p class="indent"><em>Southbridge</em> bridges a second time, from Northbridge to slower I/O bus hierarchies. It’s still usually located in its own dedicated silicon chip (which is sometimes also called “the chipset” even when Northbridge is located on the CPU chip). Southbridge contains many different standard I/O modules, all printed on the same silicon. Here you’ll see structures such as USB controllers, hard disk controllers, and the older PCI (not PCIe) bus.</p>&#13;
<p class="indent"><a href="fm03.xhtml#fig2">Figure 2</a> in the introduction shows the physical layout of this design on a 2010s PC mainboard. In the figure, both Northbridge and Southbridge are covered by large heatsinks, showing that they’re major consumers of power and producers of heat, just like the CPU. Compared to retro computers, there are few other chips remaining on the mainboard, because most of their functionality has migrated to either Southbridge, Northbridge, or the CPU. The rest of the mainboard is taken up mostly by physical connectors and analog components used in power management.</p>&#13;
<p class="indent">With Northbridge now migrated onto the same silicon as the CPU in many cases, it’s become harder to identify it on more modern mainboards.</p>&#13;
<h4 class="h4a"><span epub:type="pagebreak" id="page_321"/><strong>Standardized I/O</strong></h4>&#13;
<p class="noindent">A current desktop PC trend is toward standardized I/O. In the bad old days, every device would have its own I/O module, a physical component sitting on the bus. That meant that each device had its own IRQ (interrupt request) line into the processor. You would need a specific I/O-level driver to look after that module, which could be painful to configure.</p>&#13;
<p class="indent">Bus hierarchies such as USB have now largely solved this problem for PCs. These use a single I/O module, such as a USB controller, which has to be configured only once and uses only a single IRQ. All the devices then connect to this controller using a lower-level bus with its own protocol, which can include communications that inform the controller what the device is. They can easily share the single IRQ allocated to the controller.</p>&#13;
<h4 class="h4a"><strong>Fast Serial Buses</strong></h4>&#13;
<p class="noindent">In the golden age, a bus meant a whole load of parallel wires, often in the form of a ribbon cable, as in the left of <a href="ch13.xhtml#ch13fig4">Figure 13-4</a>.</p>&#13;
<div class="image"><img id="ch13fig4" src="../images/f0321-01.jpg" alt="Image" width="622" height="206"/></div>&#13;
<p class="figcap"><em>Figure 13-4: A 1980s parallel bus ribbon cable with lots of wires (left) versus a fast serial 2020s connector with fewer wires</em></p>&#13;
<p class="indent">It’s rare to see ribbon cables nowadays, as most buses are serial, having just one wire for communication plus a few control and power wires, as on the right of <a href="ch13.xhtml#ch13fig4">Figure 13-4</a>. For example, SATA, SSA-SCSI, USB, and CAN are all serial buses.</p>&#13;
<p class="indent">This change was prompted by technical problems with parallel buses that arrived once speeds exceeded around 1Gbps. Small differences in delays on out-of-box parallel wires can put signals on different wires out of sync, and resynchronizing their data is very hard. Serial buses, on the other hand, can be made faster and faster as there’s no need to sync multiple wires.</p>&#13;
<h4 class="h4a"><strong>Migration Up the Hierarchy</strong></h4>&#13;
<p class="noindent">As I/O modules get faster they want to move up the bus hierarchy to be closer to the CPU. Devices that used to hang off standardized buses, such as USB, want to connect directly to Southbridge; devices that used to hang off Southbridge want to get promoted to Northbridge; and devices that used to hang off Northbridge want to get promoted up into system-on-chip (SoC) silicon. At the same time, Northbridge, Southbridge, and standardized buses all want to increase their own speeds, meaning a device wanting <span epub:type="pagebreak" id="page_322"/>to move from Southbridge to Northbridge, for example, might get overtaken by a new, faster Southbridge that makes its migration unnecessary. Since Moore’s law stopped the central CPU clock from getting faster, there’s been a big push to move innovation to all of these levels, which perhaps is making it a little more glamorous for the non-CPU architects who work on them.</p>&#13;
<p class="indent">Migration up the bus hierarchy and onto silicon makes the economics and legal structures of computer design harder to understand. In 8-bit times, different companies could make separate physical chips, such as CPU and I/O modules. Computer manufacturers would buy these chips, then design and build PCBs to integrate them. Nowadays, as more of these structures need to be fabricated together on the same piece of silicon, the CPU and I/O module companies need to share their designs with the computer manufacturer, using software files similar to LogiSim designs. The manufacturer then adds designs to these files to link them together, then sends them to a fabrication company. The units of digital logic design provided by each company are known as <em>IP (intellectual property) cores</em> and need to be closely guarded by lawyers and patent agents rather than just bought and sold as physical chips in plastic packages.</p>&#13;
<h4 class="h4" id="lev276"><em>Common Buses</em></h4>&#13;
<p class="noindent">Most of the space on mainboards is now taken up by connectors rather than chips, as you saw in <a href="fm03.xhtml#fig2">Figure 2</a> of the introduction. The connectors seen in that figure are typical of other parts of the bus hierarchy. We’ll examine some of the main ones next.</p>&#13;
<h4 class="h4a"><strong>Peripheral Component Interconnect Express Bus</strong></h4>&#13;
<p class="noindent">PCIe (not to be confused with the older PCI) stands for Peripheral Component Interconnect Express and is a general-purpose bus for connecting graphics and other cards. PCIe comes in several flavors, as shown in <a href="ch13.xhtml#ch13fig5">Figure 13-5</a>; the connectors have physically different widths because they have different numbers of lanes.</p>&#13;
<div class="image"><img id="ch13fig5" src="../images/f0322-01.jpg" alt="Image" width="552" height="296"/></div>&#13;
<p class="figcap"><em>Figure 13-5: Some PCIe bus connectors</em></p>&#13;
<p class="indent">You can get various powers of 2 between 1 and 32 lanes, depending on how much data you want to transfer. PCIe also comes in different generations, with speeds going from 250MBps to 2GBps per lane.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_323"/>Like many modern “buses,” PCIe began as an actual bus—in which many nodes share the same set of wires, each with its own address—but has evolved into a mesh network, with nodes now performing some routing to avoid congestion on the bus.</p>&#13;
<h4 class="h4a"><strong>SCSI and SATA Buses</strong></h4>&#13;
<p class="noindent">SCSI and SATA are competing buses for mass storage devices (for example, hard disks). The Small Computer System Interface (SCSI, pronounced “scuzzy”) is a very ancient, classic, well-tested, reliable, and expensive standard, dating from the 1980s. It pioneered moving compute work for I/O control from CPU into digital logic in the I/O module, freeing up the CPU to work on other tasks more quickly. It’s used today in servers. SCSI has been through many versions; the latest update is Serial Storage Architecture (SSA), a serial bus version.</p>&#13;
<p class="indent">Serial Advanced Technology Attachment (SATA) is cheaper and simpler than SCSI. For these reasons, it’s used in most consumer systems rather than SCSI.</p>&#13;
<h4 class="h4a"><strong>Universal Serial Bus</strong></h4>&#13;
<p class="noindent">The <em>Universal Serial “Bus” (USB)</em> is the one you’re probably most familiar with. However, USB isn’t a bus at all—it’s not even a mesh network. It’s actually a point-to-point connector, intended to upgrade the older serial port.</p>&#13;
<p class="indent">Before USB was invented, whenever you got a new piece of hardware you would spend a day trying to get the device driver working and configuring the IRQ lines. USB now makes all of this instant so you can “plug and play” many devices. USB is designed so that devices can be connected and disconnected while the computer is turned on, and part of its standard defines a generic method for devices to state their type and model over the basic USB protocol itself rather than requiring a device driver. This enables computer software to automatically see what’s been plugged in, and in many cases to download and run the appropriate drivers for it without intervention.</p>&#13;
<p class="indent">USB also defines standards for requesting and sending power down the wires. A USB cable has four wires, two for sending a serial signal and two for power. There are 5 V and a ground in there, so, for example, you can use the same USB cable to charge your mobile phone and exchange data with it.</p>&#13;
<p class="indent">All of this is done through a centralized USB controller, which is a single I/O module, so you don’t have to worry about IRQs anymore. The USB controller itself has an IRQ, but then everything else is hanging off a USB network. There have been different versions of USB, including USB 1 running at 12Mbps and USB 3 running at 5Gbps.</p>&#13;
<p class="indent">Unlike some point-to-point networks, USB connections have a manager end and a worker end, with the manager in charge of the communications protocol. If you plug a USB memory stick into your computer, your computer is the manager. As the worker, your USB stick can’t take over and start sending its own requests to copy data from your computer. This is why USB wires have different endings: one end plugs into the manager that controls <span epub:type="pagebreak" id="page_324"/>it and the other end goes into the worker, and you can’t connect them the other way around.</p>&#13;
<p class="indent"><em>On-the-go (OTG)</em> is part of the USB protocol that allows a worker device to act as a manager via a physical adapter. Sometimes you do want to connect them the wrong way around. For example, when you connect your smartphone to your computer, you usually want it to be the worker, like a USB stick, with your computer as the manager. But other times you want the phone to be the manager, such as when connecting a memory stick or sound card to it.</p>&#13;
<h4 class="h4a"><strong>Ethernet</strong></h4>&#13;
<p class="noindent"><em>Ethernet</em>, in its oldest and simplest form, is a true bus, with multiple PCs in a local area network all writing and reading on public wires. Each message is packaged as a “frame,” containing the address (Media Access Control, or MAC, address) of the recipient. Senders must take care to avoid collisions—that is, people talking at the same time—by watching the bus and waiting for a suitable time to transmit. Everyone can see everything on the bus, so it’s easy to “sniff” the bus and spy on other users.</p>&#13;
<p class="indent">Modern networks build non-bus features on top of the basic Ethernet bus structure. For example, rather than connecting all computers in a building to a single shared Ethernet bus, it’s now common for each to connect only to a central <em>switch</em> using a dedicated Ethernet cable. The switch receives all messages that are sent, but rather than forwarding them, bus-style, to all machines on the network, it forwards them only to the intended destination.</p>&#13;
<h4 class="h4" id="lev277"><em>Standard Devices</em></h4>&#13;
<p class="noindent">Your desktop PC wouldn’t be complete without some other standard devices. To complete our study of PCs, let’s take a quick look at how these have evolved.</p>&#13;
<h4 class="h4a"><strong>Flat-Screen Displays</strong></h4>&#13;
<p class="noindent">Modern flat-screen displays are used in mobile phone screens and large-screen TVs and monitors. They’re made from transistors and capacitors, laid down like chips by photolithography masks and gas processes. Many rare elements are used to produce the specific red, green, and blue light-emitting pixels, including yttrium, lanthanum, terbium, praseodymium, europium, dysprosium, and gadolinium. Some of these are so rare that they can be mined only in one or two places. Many specific combinations of electronics and elements have been used as display “technologies,” including TFT. The latest at the time of writing is organic LED (OLED).</p>&#13;
<h4 class="h4a"><strong>Graphics Cards</strong></h4>&#13;
<p class="noindent">In the 1980s, graphics was simple. An area of memory was allocated to represent the array of pixels on the screen. User programs would write to it like any other part of memory. Then a graphics chip would read from it and turn the data into CRT scanning commands to send to the monitor. Now <span epub:type="pagebreak" id="page_325"/>things are more complicated, as programmers expect graphics hardware to provide commands for complex rendering of 2D and 3D shapes without taking up CPU time.</p>&#13;
<p class="indent">To respond to this demand, the modern graphics processing unit (GPU) evolved from 1980s visual display units (VDUs). Rather than taking commands to light up pixels, GPUs typically take commands to render 3D triangles with sprite-like textures, and to shade them using complex lighting models.</p>&#13;
<p class="indent">If you’ve been playing video games over the last couple of decades, you’ll have seen the visual abilities of GPUs evolve with Moore’s law, doubling in quality and getting closer to photorealistic, real-time rendering.</p>&#13;
<p class="indent">The GPU traditionally sits on one of the buses of the mainboard, such as PCI, AGP, or PCIe. GPUs have been the one part of computer architecture that’s been getting physically bigger rather than shrinking over the years, starting off as a small chip and now most likely a full card (<a href="ch13.xhtml#ch13fig6">Figure 13-6</a>).</p>&#13;
<div class="image"><img id="ch13fig6" src="../images/f0325-01.jpg" alt="Image" width="452" height="170"/></div>&#13;
<p class="figcap"><em>Figure 13-6: A 2022 Nvidia RTX 3080 GPU</em></p>&#13;
<p class="indent">There has, however, also been a recent trend to shrink GPUs back to put on a single chip on the mainboard, or onto the same silicon as the CPU. This is particularly the case in machines where the GPU isn’t the main focus, such as generic business PCs where the graphics requirements don’t extend much beyond displaying the desktop.</p>&#13;
<p class="indent">Graphics cards sit on the system bus as I/O modules. Importantly, they can use direct memory access (DMA). For example, an image can be placed in regular RAM, then a single command can be given to the GPU to load it from main RAM into the GPU. This DMA action doesn’t go through the CPU, so from the CPU’s point of view it’s almost instant. (It will, however, slow down if the bus is needed for other things, such as additional DMAs from a webcam into the main RAM.)</p>&#13;
<p class="indent">Early GPUs were designed to accelerate rendering of the popular OpenGL 3D graphics API by implementing its commands directly in hardware, beginning with a memory-mapped area and a chip that read that area and figured out how to display that memory block on the screen. In the 2000s, in addition to or instead of memory-mapped graphics, optional plug-in graphics cards sat on the system bus as I/O modules and drew graphics in response to compiled and assembled commands of graphics languages such as OpenGL or DirectX, sent to them via the system bus. Graphics cards were labeled and sold as implementing one or more of these language interfaces.</p>&#13;
<p class="indent">A 3D graphics language usually assumes that 3D objects are composed of many small triangles. Triangles are chosen because their three points always lie in a plane, making the math easier. Their implementations, in <span epub:type="pagebreak" id="page_326"/>hardware and/or software, usually split into two main parts, known as <em>shaders</em>. First, vertex calculations convert the 3D coordinates of each vertex into 2D pixel coordinates. Second, pixel calculations compute the color (shade) of each display pixel.</p>&#13;
<p class="indent">The latter can be done in many different ways according to different mathematical models of how surfaces and lights interact. Most shaders allow triangles to be translucent (partly transparent), modeled via an alpha channel in their RGBA color, as discussed on <a href="ch02.xhtml#page_68">page 68</a>. Some shaders allow normal (orthogonal) vectors to be described for each triangle as a hint that they’re part of smooth, continuous surfaces.</p>&#13;
<p class="indent"><a href="ch13.xhtml#ch13fig7">Figure 13-7</a> shows the results of three traditional shaders built into early OpenGL implementations, rendering the same triangle mesh approximation to a sphere.</p>&#13;
<div class="image"><img id="ch13fig7" src="../images/f0326-01.jpg" alt="Image" width="631" height="211"/></div>&#13;
<p class="figcap"><em>Figure 13-7: Traditional OpenGL shaders: flat (left), Gouraud (center), and Phong (right)</em></p>&#13;
<p class="indent">Graphics users demanded more flexibility in shaders. New shading models are often proposed in graphics research, and users wanted them to be quickly available in their own systems. The graphics languages rapidly gained many extension commands in their later versions, to enable particular additional shaders, and graphics card architects struggled to keep up with designing new hardware to implement them and make them compatible with one another. These architects instead began to open up new and simpler shader languages (such as GLSL) to enable these and other arbitrary shaders to be implemented in user programs, and executed on the graphics card—now known as a GPU—via their own ISAs. This allowed programmers—especially game designers and movie studios—to create their own custom shaders to give their creations a more individual feel, as in the examples in <a href="ch13.xhtml#ch13fig8">Figure 13-8</a>.</p>&#13;
<div class="image"><img id="ch13fig8" src="../images/f0326-02.jpg" alt="Image" width="959" height="237"/></div>&#13;
<p class="figcap"><em>Figure 13-8: Custom shaders: water effects from</em> 0 A.D. <em>(left), “toon” shading (center), and retro CRT emulation (right)</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_327"/>Today’s graphics systems have continued this architectural trend, with GPUs now functioning as highly general parallel processors of their own instruction sets, and the graphics-specific shaders moved into software. Former hardware interfaces including OpenGL and DirectX are now implemented in software, written in the GPU’s own assembly and machine code. Such code can now also be generated directly by other graphics tools, such as Wayland compositors and the Vulkan SPIR-V language. The resulting GPU machine code is sent over the bus to the graphics card, where it runs on the GPU. We’ll study this code in more detail in <a href="ch15.xhtml">Chapter 15</a>.</p>&#13;
<h4 class="h4a"><strong>Sound Cards</strong></h4>&#13;
<p class="noindent">Unlike retro sound chips, such as the SID, modern sound cards don’t generate signals at all. Instead, they manage the flow of quantized, digital sound wave signals. As a result, computers have lost their characteristic sound effects and musical culture: modern game music can consist of ordinary recordings of orchestras or rock bands rather than any particular “computer music.” Like graphics cards, sound cards are always now under OS control, so user programmers are unlikely to see much of their architecture.</p>&#13;
<p class="indent">A modern sound card is really just a group of digital-to-analog converters (DACs), and indeed it’s possible to make your own from any DAC, such as the one found on a Labjack, a software-defined radio, or an Arduino Due. Typically, professional sound cards are optimized for low latency, sound quality, and many channels, while consumer cards are optimized for lower cost. Human hearing has a maximum frequency of around 20 kHz, which requires a 40 kHz sampling rate to be represented accurately. It’s common to use 48 kHz to allow some wiggle room and because it’s almost a power of 2. Professional systems may use higher rates to reduce the buildup of audible errors from repeated processing.</p>&#13;
<p class="indent">Sound card hardware typically consists of a ring buffer for each channel, as well as DAC hardware, which reads or writes to and from it. A ring buffer maintains a pointer to the next location to write, and wraps the storage around the ring so space doesn’t run out. The buffer size provides a trade-off between latency and dropouts. A small buffer means low latency but risks dropouts. We can also choose the bit depth of the audio.</p>&#13;
<p class="indent">Sound cards, like graphics cards, connect to the system bus. They’re less bandwidth-hungry than video, so they’re usually found on a bus hanging off of Southbridge, such as PCI for internal cards or USB or Firewire for external cards.</p>&#13;
<p class="indent">Sound card I/O protocols vary by manufacturer, and like GPUs, their details may be proprietary and known only to the driver writers inside the company, who then make a software API available. As with GPUs, the hardware or software interfaces are then reverse engineered by open source driver writers, who wrap them in generic software APIs such as <em>ALSA</em>.</p>&#13;
<h4 class="h4a"><span epub:type="pagebreak" id="page_328"/><strong>Keyboards and Mice</strong></h4>&#13;
<p class="noindent">Modern keyboards are nothing like the memory-mapped keyboards of the 1980s. They now contain small, embedded computers (see <a href="ch13.xhtml#ch13fig9">Figure 13-9</a>).</p>&#13;
<div class="image"><img id="ch13fig9" src="../images/f0328-01.jpg" alt="Image" width="552" height="413"/></div>&#13;
<p class="figcap"><em>Figure 13-9: The key pressure sensors and embedded system inside a modern keyboard</em></p>&#13;
<p class="indent">The keyboard’s embedded computer is actually doing a lot of work, similar to a typical Arduino application. It takes the matrix of key presses, converts them to a keycode data representation scheme, and transmits them over a virtual serial port wrapped in USB protocol.</p>&#13;
<p class="indent">Something similar has happened with mice. A modern optical mouse performs some extremely complicated real-time machine vision processing known as <em>optic flow</em> on a dedicated internal embedded system. If you try to implement optic flow in software, you’ll find it’s hard to do fast. It’s still a research area, with recent implementations in software libraries such as OpenCV. In a mouse, however, it’s implemented directly as low-level digital electronics, as in <a href="ch13.xhtml#ch13fig10">Figure 13-10</a>.</p>&#13;
<div class="image"><img id="ch13fig10" src="../images/f0328-02.jpg" alt="Image" width="394" height="334"/></div>&#13;
<p class="figcap"><em>Figure 13-10: The inside of an optical mouse</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_329"/>This digital logic is just about simple enough for you to still be able to see the connections. You can see from the overall, fairly homogeneous structure that it’s processing a region of 2D space—the image underneath the mouse. It tracks how light and dark areas of this image are moving around and from that infers the movement of the mouse.</p>&#13;
<p class="indent">There’s also usually a USB controller attached to the device. This is actually a complex embedded system—possibly a computer in its own right—and the fact that it’s now available for a few dollars in every mouse is very impressive.</p>&#13;
<div class="sidebar">&#13;
<p class="stitle"><strong>THE PC BOOT PROCESS</strong></p>&#13;
<p class="stext">The term <em>booting</em> comes from the paradoxical expression “pulling yourself up by your bootstraps.” It means starting with nothing and getting into a complex computer system by having small programs execute that load slightly larger and more powerful programs, in a sequence. On both retro systems and modern PCs, this begins by the CPU fetching an instruction from a hardwired ROM address.</p>&#13;
<p class="stext">Unlike retro computers, modern PCs aren’t made from standard components; instead, they are assembled from many different optional components, such as RAM modules of various types, caches, and I/O extension cards. It’s not initially obvious where all these things are, how they should be initialized, or how they should be mounted in the address space. To address this, the modern PC boot process is split into two parts.</p>&#13;
<p class="stext">First, a <em>bootloader</em> such as <em>coreboot</em> is burned into ROM firmware, at the address of the CPU’s initial program counter. For x86, this is ffff,fff0<sub>16</sub>. This is a 16-bit address, because x86 processors always power on in “legacy mode” (Intel calls it “real mode”), which makes them behave like 1980s 16-bit chips for backward compatibility. In this mode, only 1 M<sub>2</sub>B of combined ROM and RAM memory is addressable, and the initial program counter address is near the top of it. The bootloader runs from here and is responsible for inspecting, initializing, and assigning addresses to the available hardware. The boot-loader doesn’t display anything onscreen because there aren’t yet any routines available for doing I/O. Because it’s invisible, it can be hard to understand all the hard work the bootloader is doing.</p>&#13;
<p class="stext">Second, after this initialization, the bootloader performs a jump to code in the BIOS. The BIOS, as in a retro computer, contains subroutines for basic I/O such as ASCII character display, keyboard reading, and hard disk access. At this stage, your PC can look and feel much like a retro computer.</p>&#13;
<p class="stext"><span epub:type="pagebreak" id="page_330"/>Usually, the BIOS code jumped to from the bootloader will print a few strings on the screen, such as the name and logo of the BIOS. A PC BIOS ROM and an example of BIOS display I/O capabilities are shown here.</p>&#13;
<div class="imagec"><img src="../images/f0330-01.jpg" alt="Image" width="677" height="515"/></div>&#13;
<p class="stext">A BIOS will usually first offer the user the chance to “go into the BIOS” by pressing a key, which will call graphical routines for setting configuration options. One of these options is usually to give the name of a storage device whose first data contains the next program to be loaded and jumped to, usually at address 7c00<sub>16</sub>. What this program does is up to you—a common first move is to switch the x86 up into 32-, then 64-bit modes.</p>&#13;
<p class="stext">There was a time when different x86 BIOS manufacturers all made different and incompatible libraries of routines, but they’ve now converged on two standards. One, PCBIOS, was defined by IBM (who just call it “BIOS”) in early x86 PCs. It was cloned by other manufacturers and is still used by many x86 machines today. SeaBIOS is an open source implementation. The other standard, UEFI, is more recent. It assumes more advanced graphics and I/O are available, so its library of routines includes higher resolution and more colorful graphics, and access to additional devices such as USB. TianoCore is an open source implementation.</p>&#13;
</div>&#13;
<h3 class="h3" id="lev278">Summary</h3>&#13;
<p class="noindent">No one would design a modern desktop PC to have its current form if they were able to start from scratch. Like many successful commercial, real-world systems, the PC has evolved over time as new features have been requested and bolted on, while existing customers demand backward compatibility. As a result, both the x86 architecture and PC computer design have accumulated layers of legacy features. The CISC philosophy is a good fit for this environment. It’s common for multiple competing standards to be supported <span epub:type="pagebreak" id="page_331"/>within single designs, even including multiple choices for x86 assemblers including but not limited to NASM. Recent x86 has extended beyond the features seen in this chapter by adding parallelization, which we’ll examine in <a href="ch15.xhtml">Chapter 15</a>. But before this, we’ll take a breather by looking at developments in the cleaner, more beautiful world of RISC in the next chapter.</p>&#13;
<h3 class="h3" id="lev279">Exercises</h3>&#13;
<h4 class="h4a"><strong>Creating a Bootable ISO Image</strong></h4>&#13;
<p class="noindent">Here you’ll create a simple 16-bit “Hello, world!” program, assemble it with NASM into executable machine code, then store this machine code in an ISO file, an image of the contents of a physical secondary storage device that you can use to boot a real PC or a virtual machine.</p>&#13;
<ol class="number">&#13;
<li class="tm">Create the following <em>hello16bit.asm</em> file:<br/><pre>bits 16                ; tell NASM we're only using 16-bit x86&#13;
org 0x7c00             ; base address for bootloader to place this code&#13;
section .data          ; this segment is read-write data&#13;
message db 'Hello, World!', 13, 10, 0&#13;
section .text          ; this segment is read-only code&#13;
entry:&#13;
  jmp start&#13;
printer:               ; subroutine for printing ASCII strings&#13;
  lodsb                ; load SI into AL and increment SI [next char]&#13;
  or al, al            ; check if the end of the string&#13;
  jz printer_end;&#13;
  int 0x10             ; otherwise, call interrupt to print char&#13;
  jmp printer          ; loop&#13;
printer_end:&#13;
  ret                  ; return flow&#13;
start:&#13;
  mov si, message      ; say what we want to print&#13;
  mov ah, 0x0e&#13;
  call printer         ; print it&#13;
                       ; ** add your own code here ... **&#13;
  hlt&#13;
times 510-($-$$) db 0  ; zero out rest of 512-byte boot sector&#13;
dw 0xaa55              ; code to mark sector as bootable</pre></li>&#13;
<li class="tm">Run the following commands:<br/><pre><span class="codestrong1">mkdir -p cd/boot</span>&#13;
<span class="codestrong1">nasm hello16bit.asm -o cd/boot/loader.sys</span>&#13;
<span class="codestrong1">mkisofs -R -J -c boot/bootcat -b boot/loader.sys -no-emul-boot -o cd.iso cd</span></pre></li>&#13;
</ol>&#13;
<p class="notes"><span epub:type="pagebreak" id="page_332"/><strong><span class="nt">NOTE</span></strong></p>&#13;
<p class="noindent"><em>If you’re using Microsoft Windows, these commands can be run by installing and using the Windows Subsystem for Linux. If you don’t already have NASM, install it from</em> <a href="https://nasm.us">https://nasm.us</a>. <em>You may also need to install mkisofs for your system.</em></p>&#13;
<ol class="number">&#13;
<li class="tm" value="3">If everything worked, you’ll now have a <em>cd.iso</em> file for booting a physical or virtual x86 machine. This will allow you to run on “bare metal” x86, without an operating system getting in the way.</li>&#13;
</ol>&#13;
<p class="indent">We’ll discuss how to boot into your ISO file in the next exercises. When you do, you should see something like <a href="ch13.xhtml#ch13fig11">Figure 13-11</a> on the screen.</p>&#13;
<div class="image"><img id="ch13fig11" src="../images/f0332-01.jpg" alt="Image" width="628" height="284"/></div>&#13;
<p class="figcap"><em>Figure 13-11: The result of booting into a bare metal test program</em></p>&#13;
<p class="indent">Before going any further, let’s look at what <em>hello16bit.asm</em> actually does. In addition to actual x86 instruction mnemonics, a NASM program usually also includes some directives, which are lines that aren’t assembled themselves but instead tell NASM to change its behaviors in various ways. The <code>section</code> directive tells NASM to change which segment of the output file to write the next assembled instructions to. In some file formats, the number and names of sections are fixed; in others, the user may make up as many as they wish. The Unix object and bin formats all support the standardized section names <code>.text</code> (contains executable instructions), <code>.data</code> (contains initialized variables), and <code>.bss</code> (contains uninitialized variables). The ASCII string includes special ASCII codes 13, 10, and 0 after the human readable letters. What are these? (Hint: See <a href="ch02.xhtml">Chapter 2</a>.)</p>&#13;
<h4 class="h4a"><strong>Booting on a Virtual x86</strong></h4>&#13;
<p class="noindent">The ISO can be booted on a virtual machine as if it were a physical disk. Follow these steps to try it out using the VirtualBox virtual machine. (Open source Linux users may prefer to use virt-manager at <em><a href="https://virt-manager.org">https://virt-manager.org</a></em>.)</p>&#13;
<ol class="number">&#13;
<li class="tm">Visit <em><a href="https://www.virtualbox.org">https://www.virtualbox.org</a></em> for instructions on how to install VirtualBox on your system.</li>&#13;
<li class="tm">Once installed, create a new virtual machine by clicking the <strong>New</strong> icon; use the default settings.</li>&#13;
<li class="tm">Start your virtual machine and “insert” your bootable virtual CD by selecting your <em>cd.iso</em> file when asked.</li>&#13;
</ol>&#13;
<h4 class="h4a"><span epub:type="pagebreak" id="page_333"/><strong>Booting on a Physical x86</strong></h4>&#13;
<p class="noindent">The ISO can also be booted on a physical x86 machine if you first “burn” it onto a physical USB stick. Here’s how:</p>&#13;
<ol class="number">&#13;
<li class="tm">Use a program such as Etcher (<em><a href="https://www.balena.io">https://www.balena.io</a></em>) for your current operating system to burn the ISO to a USB stick.</li>&#13;
<li class="tm">Once you have a bootable USB stick, you need to tell your PC to boot from it. Your PC is probably currently configured to boot from a hard disk, but it will have some method—which varies by manufacturer—to change to booting from USB as part of its BIOS configuration tools. Editing these settings is called “going into the BIOS.” On most machines it’s done by holding down a particular key for a few seconds as you turn on the machine. This is often <small>ESC, DEL</small>, F1, F2, F8, F10, or F11, depending on the manufacturer (if it doesn’t say which, try running a finger over the whole top row of the keyboard to hit them all). You’ll usually see some low-resolution BIOS menus: if you hunt around, there will be some way to specify the boot order and bring USB to the top of it. Some machines may have additional security features that need to be disabled before you can boot from a new device.</li>&#13;
</ol>&#13;
<h4 class="h4a"><strong>Booting to and Programming in 64-Bit Mode</strong></h4>&#13;
<p class="noindent">Switching a modern x86 into 32- and 64-bit modes isn’t trivial. Due to historical baggage, it requires a couple of screens of instructions and data. How these work is fairly obscure, but luckily it’s a standard process that can now be done using the boilerplate code shown here:<span epub:type="pagebreak" id="page_334"/><span epub:type="pagebreak" id="page_335"/></p>&#13;
<pre>org 0x7c00          ; base address where this code will be placed (by bootloader)&#13;
entry:&#13;
    jmp real_to_protected&#13;
GDT32:              ; Global Descriptor Table for 32-bit mode&#13;
    .Null: equ $ - GDT32&#13;
    dq 0            ; defines 32 bits of zeros for the null entry&#13;
    .Code: equ $ - GDT32&#13;
    dw 0xFFFF       ; segment limit&#13;
    dw 0            ; base address&#13;
    db 0            ; base address (again)&#13;
    db 0b10011010   ; binary flags describing mode&#13;
    db 0b11001111   ; binary flags describing mode&#13;
    db 0            ; last remaining 8 bits on the base address&#13;
    .Data: equ $ - GDT32&#13;
    dw 0xFFF        ; --|&#13;
    dw 0            ;   | - identical to code segment&#13;
    db 0            ; --|&#13;
    db 0b10010010&#13;
    db 0b11001111&#13;
    db 0&#13;
    .Pointer:&#13;
    dw $ - GDT32 - 1&#13;
    dd GDT32&#13;
GDT64:                 ; Global Descriptor Table for 64-bit mode&#13;
    .Null: equ $ - GDT64&#13;
    dw 0xFFFF&#13;
    dw 0&#13;
    db 0&#13;
    db 0&#13;
    db 1&#13;
    db 0&#13;
    .Code: equ $ - GDT64&#13;
    dw 0&#13;
    dw 0&#13;
    db 0&#13;
    db 10011010b       ; binary flags describing mode&#13;
    db 10101111b       ; binary flags describing mode&#13;
    db 0&#13;
    .Data: equ $ - GDT64&#13;
    dw 0&#13;
    dw 0&#13;
    db 0&#13;
    db 10010010b       ; binary flags describing mode&#13;
    db 00000000b       ; binary flags describing mode&#13;
    db 0&#13;
    .Pointer:&#13;
    dw $ - GDT64 - 1&#13;
    dq GDT64&#13;
bits 16                ; tells NASM the following is 16-bit x86 code&#13;
real_to_protected:     ; switch from 16 bits to 32 bits&#13;
    mov ax, 0x2401&#13;
    int 0x15           ; enable a20 gate&#13;
    mov ax, 0x3&#13;
    int 0x10           ; change video mode&#13;
    cli&#13;
    lgdt [GDT32.Pointer]&#13;
    mov eax, cr0&#13;
    or eax, 1&#13;
    mov cr0, eax&#13;
    jmp GDT32.Code:protected_to_long    ; perform long jump&#13;
bits 32                 ; tells NASM the following is 32-bit x86 code&#13;
protected_to_long:      ; switch from 32 bits to 64 bits&#13;
    mov ax, GDT32.Data&#13;
    mov ds, ax&#13;
    mov fs, ax&#13;
    mov gs, ax&#13;
    mov ss, ax&#13;
    ; root table - page-map level-4 table (PM4T)&#13;
    mov edi, 0x1000     ; starting address of 0x1000&#13;
    mov cr3, edi        ; base address of page entry into control register 3&#13;
    xor eax, eax        ; set EAX to 0&#13;
    mov ecx, 4096&#13;
    rep stosd&#13;
    mov edi, cr3        ; restore original starting address&#13;
    mov dword [edi], 0x2003&#13;
    add edi, 0x1000&#13;
    mov dword [edi], 0x3003&#13;
    add edi, 0x1000&#13;
    mov dword [edi], 0x4003&#13;
    add edi, 0x1000&#13;
    mov ebx, 0x00000003 ; used to identity map the first 2MiB&#13;
    mov ecx, 512&#13;
    .set_entry:&#13;
        mov dword [edi], ebx&#13;
        add ebx, 0x1000&#13;
        add edi, 8&#13;
        loop .set_entry&#13;
    mov eax, cr4&#13;
    or eax, 1 &lt;&lt; 5&#13;
    mov cr4, eax&#13;
    mov ecx, 0xC0000080 ; magic value actually refers to the EFER MSR&#13;
    rdmsr               ; read model-specific register&#13;
    or eax, 1 &lt;&lt; 8      ; set long-mode bit (bit 8)&#13;
    wrmsr               ; write back to model-specific register&#13;
    mov eax, cr0&#13;
    or eax, 1 &lt;&lt; 31 | 1 &lt;&lt; 0   ; set PG bit (31st) &amp; PM bit (0th)&#13;
    mov cr0, eax&#13;
    lgdt [GDT64.Pointer]&#13;
    jmp GDT64.Code:real_long_mode&#13;
bits 64                 ; tells NASM the following is 64-bit x86 code&#13;
printer:                ; subroutine for printing ASCII strings&#13;
    printer_loop:&#13;
        lodsb&#13;
        or al, al&#13;
        jz printer_exit&#13;
        or rax, 0x0F00&#13;
        mov qword [rbx], rax&#13;
        add rbx, 2&#13;
        jmp printer_loop&#13;
    printer_exit:&#13;
        ret&#13;
real_long_mode:&#13;
    cli&#13;
    mov ax, GDT64.Data&#13;
    mov ds, ax&#13;
    mov fs, ax&#13;
    mov gs, ax&#13;
    mov ss, ax&#13;
    xor rax, rax         ; clears register rax&#13;
    mov rsi, boot_msg    ; say what we want to print&#13;
    mov rbx, 0xb8000&#13;
    call printer         ; print it&#13;
    mov rsi, l_mode      ; say what we want to print&#13;
    mov rbx, 0xb80A0&#13;
    call printer         ; print it&#13;
                         ; ** add your own code here ... **&#13;
    hlt&#13;
boot_msg db "Hello, world!",0&#13;
l_mode db "This is 64-bit (long mode) !",0&#13;
times 510 - ($-$$) db 0  ; zero out rest of 512-byte boot sector&#13;
dw 0xaa55                ; code to mark sector as bootable</pre>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_336"/>If you save this, assemble it, and put it into an ISO as for the 16-bit version, it will boot your real or virtual x86 into 64-bit mode and print another “Hello, world!” message. You can then use the “Hello, world!” program as a starting point, modifying it into your own bootable programs for the following tasks:</p>&#13;
<ol class="number">&#13;
<li class="tm">Write a subroutine that reads integers and converts them into ASCII strings. Extend it to floating point. Use it to print out some numbers along with “Hello, world!”</li>&#13;
<li class="tm">Try porting previous programs from the Analytical Engine and Manchester Baby to run on x86. What’s gotten easier or harder to do in modern x86 compared to those systems?</li>&#13;
<li class="tm">Call the BIOS routine to light up pixels on the screen several times to draw a simple shape.</li>&#13;
</ol>&#13;
<h4 class="h4a"><strong>More Challenging</strong></h4>&#13;
<p class="noindent">Write a simple game such as <em>Space Invaders</em> using the above BIOS calls, on bare metal x86.</p>&#13;
<h3 class="h3" id="lev280">Further Reading</h3>&#13;
<ul class="bullet">&#13;
<li class="tm">For the official NASM manual, see “NASM: The Netwide Assembler,” <em><a href="https://www.nasm.us/xdoc/2.13.03/html/nasmdoc0.html">https://www.nasm.us/xdoc/2.13.03/html/nasmdoc0.html</a></em>.</li>&#13;
<li class="tm">For an overview of x86 history, see P. Lilly, “A Brief History of CPUs: 31 Awesome Years of x86,” <em>Maximum PC</em>, April 2009, <em><a href="https://www.pcgamer.com/a-brief-history-of-cpus-31-awesome-years-of-x86">https://www.pcgamer.com/a-brief-history-of-cpus-31-awesome-years-of-x86</a></em>.</li>&#13;
<li class="tm"><span epub:type="pagebreak" id="page_337"/>For the full five-volume amd64 reference set, see AMD Technology, <em>AMD64 Architecture Programmer’s Manual Volumes 1–5</em> (Santa Clara: AMD Technology, 2023), <em><a href="https://www.amd.com/en/support/tech-docs/amd64-architecture-programmers-manual-volumes-1-5">https://www.amd.com/en/support/tech-docs/amd64-architecture-programmers-manual-volumes-1-5</a></em>.</li>&#13;
<li class="tm">For information on 3D graphics programming, see Graham Sellars, <em>Vulkan Programming Guide</em> (Boston: Addison-Wesley, 2017).</li>&#13;
<li class="tm">For details of how the x86 boot assembly code works, see Gregor Brunmar, “The World of Protected Mode” (<em><a href="http://www.osdever.net/tutorials/view/the-world-of-protected-mode">http://www.osdever.net/tutorials/view/the-world-of-protected-mode</a></em>), the lame_bootloader GitHub repository (<em><a href="https://github.com/sedflix/lame_bootloader">https://github.com/sedflix/lame_bootloader</a></em>), and “Setting Up Long Mode” (<em><a href="https://wiki.osdev.org/Setting_Up_Long_Mode">https://wiki.osdev.org/Setting_Up_Long_Mode</a></em>).<span epub:type="pagebreak" id="page_338"/></li>&#13;
</ul>&#13;
</div>
</div>
</body></html>