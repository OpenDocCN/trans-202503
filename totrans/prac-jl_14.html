<html><head></head><body>
<h2 class="h" id="ch12"><span epub:type="pagebreak" id="page_381" class="calibre1"/><strong class="calibre2"><span class="big">12</span><br class="calibre3"/>MATHEMATICS</strong></h2>
<div class="bq">
<p class="center"><em class="calibre11">The people of Ulm are mathematicians.</em></p>
<p class="center1">—Motto of Ulm, the birthplace of Albert Einstein</p>
</div>
<div class="image"><img alt="Image" src="../images/common.jpg" class="calibre6"/></div>
<p class="noindent">In this chapter, we’ll explore several Julia packages for symbolic and numerical mathematics. Symbolic mathematical software can replace tedious pencil-and-paper calculations or long evenings in the company of tables of integrals with automated manipulations of mathematical expressions. Numerical packages include modules for linear algebra, equation solving, and related fields. The two classes of packages have substantial overlap, and both are a boon to the applied mathematician or, potentially, to anyone who uses mathematics in research.</p>
<h3 class="h2" id="ch12lev1"><span epub:type="pagebreak" id="page_382" class="calibre1"/><strong class="calibre2">Symbolic Mathematics</strong></h3>
<p class="noindent">This category of software is sometimes called <em class="calibre11">computer algebra</em>, but it includes all types of automated symbol manipulation, such as algebraic and trigonometric simplification; generation of Taylor series; calculation of limits, derivatives, and integrals; and more specialized areas such as algebraic number theory.</p>
<p class="indent">Symbolic mathematical software is distinguished from the more familiar intersection of computers and math by its ability to handle mathematics as mathematics, rather than by simply performing arithmetic. We feed it expressions incorporating variables, and it returns rewritten expressions, or the solution to a problem, in terms of those variables, rather than numbers.</p>
<h4 class="h3" id="ch12lev1sec1"><strong class="calibre2"><em class="calibre4">Numerical-Symbolic Modeling with Symbolics</em></strong></h4>
<p class="noindent">This section introduces <span class="literal">Symbolics</span>, which is described as a symbolic modeling language and as numerical-symbolic software. These descriptions are meant to suggest that <span class="literal">Symbolics</span> emphasizes the synergy between symbolic and numerical calculations, and is designed with efficiency in mind. <span class="literal">Symbolics</span> does not feature all the abilities of a full-blown computer algebra system—it can’t calculate indefinite integrals, for example. But it has other, unique abilities. For example, it can transform a normal Julia function into a symbolic function, and it can create a C program from a Julia <span class="literal">Symbolics</span> program. <span class="literal">Symbolics</span> is written entirely in Julia, which means that we can reach for any part of the language in working with its symbolic expressions. <span class="literal">Symbolics</span> is a key part of the <span class="literal">ModelingToolkit</span> package, a framework for automatically parallelized scientific machine learning.</p>
<p class="indent">To establish names as symbolic variables, as shown in <a href="ch12.xhtml#ch12lis1" class="calibre10">Listing 12-1</a>, it’s most convenient to use a macro supplied by the <span class="literal">Symbolics</span> package.</p>
<pre class="calibre13">@variables a b c φ z;
 5-element Vector{Num}:
 a
 b
 c
 φ
 z</pre>
<p class="list" id="ch12lis1"><em class="calibre11">Listing 12-1: Declaring</em> <span class="codeitalic">Symbolics</span> <em class="calibre11">variables</em></p>
<p class="indent">After calling this macro, we can use the five mentioned variables similarly to how we would use variables in mathematical expressions. They have the type <span class="literal">Num</span> and share much of the behavior of the <span class="literal">Real</span> type, but they have extra powers, which we’ll explore next.</p>
<p class="indent">Let’s create a rotation matrix as we did in “Matrix Multiplication” on <a href="ch05.xhtml#ch05lev1sec18" class="calibre10">page 146</a>:</p>
<pre class="calibre13">RM = [cos(φ) -sin(φ); sin(φ) cos(φ)]</pre>
<p class="indent">Since φ is a <span class="literal">Symbolics</span> variable, this matrix is a <span class="literal">Symbolics</span> expression.</p>
<p class="indent"><span epub:type="pagebreak" id="page_383"/>Let’s see what happens if we try to rotate a vector with it using matrix multiplication, as we did with the “normal” rotation matrix in <a href="ch05.xhtml" class="calibre10">Chapter 5</a>:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">RM * [1, 0]</span>
2-element Vector{Num}:
 cos(φ)
 sin(φ)

julia&gt; <span class="codestrong">RM * [0, 1]</span>
2-element Vector{Num}:
 -sin(φ)
  cos(φ)

julia&gt; <span class="codestrong">RM * [1, 1]</span>
2-element Vector{Num}:
 cos(φ) - sin(φ)
 cos(φ) + sin(φ)

julia&gt; <span class="codestrong">RM * [0.5, 0]</span>
2-element Vector{Num}:
 0.5cos(φ)
 0.5sin(φ)

julia&gt; <span class="codestrong">RM * [0.5, 0.6]</span>
2-element Vector{Num}:
 0.5cos(φ) - 0.6sin(φ)
 0.5sin(φ) + 0.6cos(φ)</pre>
<p class="indent">In each case, the matrix multiplication returns an exact result, correct for any value of φ. The <span class="literal">*</span> operator is able to operate on <span class="literal">Symbolics</span> expressions, performing matrix multiplication as it does with matrices of numbers. This is another example of the composability of Julia packages. Most array and numerical operators and functions will handle <span class="literal">Symbolics</span> expressions the way we would expect.</p>
<p class="indent">To compute a numerical result, we can use the <span class="literal">substitute()</span> function:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">substitute(RM * [1, 0], Dict(φ =&gt; π/2))</span>
2-element Vector{Num}:
 6.123233995736766e-17
 1.0</pre>
<p class="noindent">The result is identical to the one in “Matrix Multiplication” on <a href="ch05.xhtml#ch05lev1sec18" class="calibre10">page 146</a>.</p>
<p class="indent">The <span class="literal">substitute()</span> function takes a <span class="literal">Symbolics</span> expression in its first argument and a dictionary of substitutions to make in its second argument. The resulting expression is not always simplified as we might expect:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">ex = a^2*z^2 + a^4*z^4;</span>

julia&gt; <span class="codestrong">substitute(ex, Dict(a =&gt; sqrt(b)))</span>
<span epub:type="pagebreak" id="page_384"/>(z^2)*(sqrt(b)^2) + (z^4)*(sqrt(b)^4)

julia&gt; <span class="codestrong">substitute(ex, Dict(a =&gt; b^(1//2)))</span>
b*(z^2) + (b^(2//1))*(z^4)</pre>
<p class="indent">Here we have a polynomial that we attempt to write in a slightly simpler form by making a change of variable. Our first attempt is foiled because <span class="literal">Symbolics</span> seems not to know that, for example, <span class="literal">sqrt(b)^2 = b</span>. We had better luck on our second try.</p>
<p class="indent"><span class="literal">Symbolics</span> is able to automatically simplify expressions involving multiplication or division of variables raised to integer powers:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">z^3 * z^5</span>
z^8

julia&gt; <span class="codestrong">a^5/a^3</span>
a^2</pre>
<p class="indent">It also comes with a <span class="literal">simplify()</span> function, but it’s not able to do much—not even the limited simplification that appears in the documentation. The emphasis of <span class="literal">Symbolics</span>, as mentioned previously, is on efficient numeric-symbolic modeling. We can always turn to <span class="literal">SymPy</span>, explored in the next section, to perform nontrivial simplifications of an expression, the results of which we can use in a <span class="literal">Symbolics</span> program.</p>
<h5 class="h4" id="ch12sec1sec1"><strong class="calibre2">An Example: Bessel Functions</strong></h5>
<p class="noindent">As an example of a practical use of <span class="literal">Symbolics</span>, let’s say we need to compute the Bessel function of the first kind, of various orders, and some of its derivatives. These functions appear throughout physics and engineering. We used a Bessel function in <a href="ch07.xhtml#ch7lis5" class="calibre10">Listing 7-5</a> on <a href="ch07.xhtml#ch07lev4" class="calibre10">page 206</a> to represent the shape of a vibrating drumhead, where we gained access to it through the <span class="literal">SpecialFunctions</span> package.</p>
<p class="indent">To roll our own Bessel function, which we’ll denote <em class="calibre11">J</em><sub class="calibre24"><em class="calibre11">m</em></sub>(<em class="calibre11">x</em>), where <em class="calibre11">m</em> is the order, we can turn to its well-known series representation:</p>
<div class="image"><img alt="Image" src="../images/384math.jpg" class="calibre6"/></div>
<p class="indent">A Julia function implementing this representation, shown in <a href="ch12.xhtml#ch12lis2" class="calibre10">Listing 12-2</a>, will accept <span class="literal">x</span>, <span class="literal">m</span>, and a number of terms (because we can’t compute an infinite number of terms) that we’ll call <span class="literal">N</span>.</p>
<pre class="calibre13">function Jm(x, m::Int, N)
    s = 0
    for k in N:-1:0
        s += (-1)^k * x^(2k + m) / (2^(2k + m)*factorial(k)*factorial(k + m))
    end
    return s
end</pre>
<p class="list" id="ch12lis2"><em class="calibre11">Listing 12-2: Calculating a Bessel function using its series expansion</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_385"/>This function will return the value of <em class="calibre11">J</em><sub class="calibre24"><em class="calibre11">m</em></sub>(<em class="calibre11">x</em>) computed using <span class="literal">N</span> terms in the series. Because it uses normal integers, rather than <span class="literal">big</span> integers, we can only use it with <span class="literal">N</span> &lt; 19 (see “‘Big’ and Irrational Types” on <a href="ch08.xhtml#ch08lev1sec1" class="calibre10">page 216</a>). Keeping nine terms is more than sufficient for an extremely accurate approximation in the interval 0 ≤ <em class="calibre11">x</em> ≤ 6.</p>
<p class="indent">Our little function <span class="literal">Jm()</span> is useful if we need to know the numerical value of <em class="calibre11">J</em><sub class="calibre24"><em class="calibre11">m</em></sub>(<em class="calibre11">x</em>) at various values of <em class="calibre11">x</em>, especially if we don’t know about the <span class="literal">Special</span> <span class="literal">Functions</span> package. If we happen to need the value of various derivatives of <em class="calibre11">J</em><sub class="calibre24"><em class="calibre11">m</em></sub>(<em class="calibre11">x</em>), we could calculate them using some finite difference scheme, calling <span class="literal">Jm(x, m, N)</span> at two or more closely spaced values of <span class="literal">x</span> to compute the derivative at <em class="calibre11">x</em>. However, the numerical error intrinsic to these methods accumulates as the order of the derivative increases, and the repeated evaluations of <span class="literal">Jm(x, m, N)</span> are an additional computational cost. Let’s see how an approach using <span class="literal">Symbolics</span> neatly dispenses with both of those issues.</p>
<p class="indent">If we call <span class="literal">Jm(x, m, N)</span> with numerical values for <span class="literal">x</span>, <span class="literal">m</span>, and <span class="literal">N</span>, we get a number back, the approximation for the <em class="calibre11">m</em>th Bessel function at <em class="calibre11">x</em>. <a href="ch12.xhtml#ch12lis3" class="calibre10">Listing 12-3</a> shows what we get if, instead of a number for <span class="literal">x</span>, we supply the name of a <span class="literal">Symbolics</span> variable.</p>
<pre class="calibre13">julia&gt; <span class="codestrong">J19 = Jm(z, 1, 9)</span>
(1//1917756584755200)*(z^17) + (1//1474560)*(z^9) +
(1//29727129600)*(z^13) + (1//384)*(z^5) + (1//2)*z -
(1//176947200)*(z^11) - (1//18432)*(z^7) - (1//6658877030400)*(z^15) -
(1//690392370511872000)*(z^19) - (1//16)*(z^3)</pre>
<p class="list" id="ch12lis3"><em class="calibre11">Listing 12-3: A</em> <span class="codeitalic2">Symbolics</span> <em class="calibre11">expression approximating</em> J<em class="calibre11"><sub class="calibre25">1</sub>(z)</em></p>
<p class="indent">In <a href="ch12.xhtml#ch12lis1" class="calibre10">Listing 12-1</a>, we created the <span class="literal">Symbolics</span> variable <span class="literal">z</span>, among others. When we pass <span class="literal">z</span> to <span class="literal">Jm()</span>, it returns the nine terms of the series expansion generated with <span class="literal">m</span> = 1 and <span class="literal">N</span> = 9, in an unfortunate random order. We assigned this <span class="literal">Symbolics</span> expression to the variable <span class="literal">J19</span>. We can get the numerical value of this expression through substitution:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">substitute(J19, Dict(z =&gt; 1.2))</span>
0.4982890575672154

julia&gt; <span class="codestrong">Jm(1.2, 1, 9)</span>
0.4982890575672155</pre>
<p class="indent">The difference in the value in the last place is due to a difference in the order of operations. The strategy shown in <a href="ch12.xhtml#ch12lis2" class="calibre10">Listing 12-2</a> of adding up the small terms in a series before the larger ones should be somewhat more accurate.</p>
<p class="indent">As another example of the power of composing Julia packages, we can use <span class="literal">Latexify</span> to render a LaTeX version of a <span class="literal">Symbolics</span> expression:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">using Latexify</span>

julia&gt; <span class="codestrong">latexify(J19)</span>
L"\begin{equation}
<span epub:type="pagebreak" id="page_386"/>\frac{1}{1917756584755200} z^{17} + \frac{1}{1474560} z^{9} - [etc.]
\end{equation}
"</pre>
<p class="indent">Copying and pasting the contents (with some line breaks added) of the resulting LaTeX string into the source of this book, which is typeset using LaTeX, shows us the rendered expression:</p>
<div class="image"><img alt="Image" src="../images/386math.jpg" class="calibre6"/></div>
<p class="indent">The process illustrated here, of taking a normal Julia function and repurposing it to generate a <span class="literal">Symbolics</span> expression, is sometimes called <em class="calibre11">tracing</em>. Only functions that are in a sense deterministic can be traced. What this means, in the case of our <span class="literal">Jm()</span> function, is that we can supply a <span class="literal">Symbolics</span> variable for <span class="literal">x</span>, but not for the number of terms, <span class="literal">N</span>. For that, we must supply an integer. If we try to sneak in a <span class="literal">Symbolics</span> variable for the third positional argument, we get a cryptic error message:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">Jm(z, 1, a)</span>
ERROR: TypeError: non-boolean (Num) used in boolean context</pre>
<p class="indent">The reason we didn’t enforce an integer <span class="literal">N</span> in the function signature, as we did for <span class="literal">m</span>, was to illustrate this behavior.</p>
<p class="indent">The problem with attempting to trace <span class="literal">Jm()</span> while using a <span class="literal">Symbolics</span> variable representing the number of terms is that the loop limits are unknown: what expression is to be returned? We can trace only functions that generate a completely determined expression based on their inputs. The particular error message appearing in this listing is a signal that we’ve run into this problem.</p>
<h5 class="h4" id="ch12sec1sec2"><strong class="calibre2">Differentiating the Bessel Function</strong></h5>
<p class="noindent">Since we’re in possession of an <em class="calibre11">analytic</em> expression, generated in <a href="ch12.xhtml#ch12lis2" class="calibre10">Listing 12-2</a>, for the approximation to <em class="calibre11">J</em><sub class="calibre24">1</sub>(<em class="calibre11">z</em>), we can derive its analytic derivative at <em class="calibre11">any order</em> to get d<sup class="calibre23"><em class="calibre11">p</em></sup><em class="calibre11">J</em><sub class="calibre24">1</sub>/d<em class="calibre11">z</em><sup class="calibre23"><em class="calibre11">p</em></sup>, the <em class="calibre11">p</em>th derivative. Since <span class="literal">J19</span> is only a polynomial, this is a simple, albeit tedious and error-prone, procedure.</p>
<p class="indent"><span epub:type="pagebreak" id="page_387"/><span class="literal">Symbolics</span> can relieve us of the burden of differentiating by hand:</p>
<pre class="calibre13">
julia&gt; <span class="codestrong">Differential(z)(J19) |&gt; expand_derivatives</span>
(1//2) + (13//29727129600)*(z^12) + (17//1917756584755200)*(z^16) +
(5//384)*(z^4) + (1//163840)*(z^8) - (19//690392370511872000)*(z^18) -
(11//176947200)*(z^10) - (3//16)*(z^2) - (7//18432)*(z^6) - (1//443925135360)*(z^14)</pre>
<p class="indent">Here we use the <span class="literal">Differential()</span> function. <span class="literal">Differential(t)</span> returns another function that calculates the derivative with respect to <span class="literal">t</span> of the <span class="literal">Symbolics</span> expression that it receives. To actually see the result of this manipulation, we need to pass it to <span class="literal">expand_derivatives()</span>. The result is the correct differentiation of the polynomial <span class="literal">J19</span>, with its terms in yet another random order.</p>
<p class="indent">As suggested previously, we can repeatedly apply <span class="literal">Differential()</span> to generate derivatives at any order without worrying about the accumulation of finite differencing errors. Let’s take a look at the first 10 derivatives of the Bessel function:</p>
<pre class="calibre13">   julia&gt; <span class="codestrong">using Plots, LaTeXStrings</span>

   julia&gt; <span class="codestrong">dnJ19 = [Differential(z)(J19) |&gt; expand_derivatives];</span>

<span class="ent">➊</span> julia&gt; <span class="codestrong">for ord in 2:10
              push!(dnJ19, Differential(z)(dnJ19[ord-1]) |&gt; expand_derivatives)
          end</span>

   julia&gt; <span class="codestrong">plot(J19; lw=2, xrange=(0, 6), yrange=(-0.6, 0.6), legend=false,
               xlabel=L"x", ylabel=L"J_1, J_1^\prime, J_1^{\prime\prime}, ...")</span>

<span class="ent">➋</span> julia&gt; <span class="codestrong">for ord in 1:10
              plot!(dnJ19[ord]; linestyle=:auto)
              gui()
          end</span></pre>
<p class="indent">We intend to plot the derivatives, so first we import <span class="literal">Plots</span> and, to get typeset math in the axis labels, <span class="literal">LaTeXStrings</span>. We calculate the derivative of the Bessel function, as we did before, and place the result inside a vector. In a loop <span class="ent">➊</span> we apply the derivative operator repeatedly to the previous result, generating the first 10 derivatives. We set up the plot by graphing <em class="calibre11">J</em><sub class="calibre24">1</sub>(<em class="calibre11">x</em>), using LaTeX strings for the labels, and then loop through <span class="ent">➋</span> the elements of the vector of derivatives, adding each one to the visualization. <a href="ch12.xhtml#ch12fig1" class="calibre10">Figure 12-1</a> shows the result.</p>
<div class="image1"><img alt="Image" id="ch12fig1" src="../images/ch12fig01.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-1: The first 10 derivatives of</em> J<em class="calibre11"><sub class="calibre25">1</sub>(z)</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_388"/>The thick solid line shows <em class="calibre11">J</em><sub class="calibre24">1</sub>(<em class="calibre11">x</em>). The <span class="literal">linestyle=auto</span> keyword argument to <span class="literal">plot!()</span> creates a series of lines with different dash patterns, which are plotted using the default line thickness. These are the 10 derivatives.</p>
<p class="indent">That we’re able to plot these <span class="literal">Symbolics</span> expressions directly, without setting up vectors of numerical variables or having to make numerical substitutions by hand, is another example of composability. The <span class="literal">Plots</span> package was written without any knowledge of the (future) <span class="literal">Symbolics</span> package, yet it’s able to deal with <span class="literal">Symbolics</span> expressions in a natural way.</p>
<h4 class="h3" id="ch12lev1sec2"><strong class="calibre2"><em class="calibre4">Math Manipulation with SymPy and Pluto</em></strong></h4>
<p class="noindent">For more general symbolic mathematics, <span class="literal">SymPy</span> is probably the best package available at the moment. This package is a Julia wrapper around the highly capable Python library of the same name, so it’s limited to Python performance; however, for the kind of work typically done with such packages, raw speed is not usually a crucial consideration.</p>
<div class="note">
<p class="notet"><strong class="calibre2"><span class="notes">NOTE</span></strong></p>
<p class="notep"><em class="calibre11">In order to use</em> <span class="codeitalic1">SymPy</span> <em class="calibre11">from Julia, with some systems and configurations it may be sufficient to merely execute</em> <span class="codeitalic1">add SymPy</span> <em class="calibre11">in Julia’s package mode, followed by</em> <span class="codeitalic1">using SymPy</span><em class="calibre11">. On other systems, we need to install the Python</em> <span class="codeitalic1">SymPy</span> <em class="calibre11">library (and perhaps Python itself) outside of Julia. For example, on Linux (where Python is routinely available with most distributions), we can execute</em> <span class="codeitalic1">pip3 install sympy</span> <em class="calibre11">in the shell. However, as there is no official method of installing libraries or resolving dependencies in the Python world, it’s impossible to provide a command that will work for everyone. The remainder of this section assumes that you’ve successfully executed</em> <span class="codeitalic1">add SymPy</span> <em class="calibre11">and</em> <span class="codeitalic1">using SymPy</span> <em class="calibre11">in a Julia environment.</em></p>
</div>
<p class="indent"><span epub:type="pagebreak" id="page_389"/><span class="literal">SymPy</span> works from any such environment, and does a nice job of rendering mathematical notation in the terminal REPL. Its use from Pluto, however, is more delightful, and we’ll use examples from that environment. In Pluto, math is automatically rendered in LaTeX, so the results are immediately in the form of beautifully typeset formulas, embedded within the notebook. Pluto uses MathJax for its math rendering. A right-click on any displayed expression brings up a contextual menu providing several options, the most important providing one to copy the LaTeX commands that create the expression to the clipboard.</p>
<p class="indent">Another reason Pluto is a natural fit for <span class="literal">SymPy</span> is that, when using a computer algebra library, we’re usually in discovery or exploration mode, or using Julia with <span class="literal">SymPy</span> as a calculator, rather than developing a large program. The reactive nature of Pluto lends itself well to this mode of interaction (see “Pluto: A Better Notebook” on <a href="ch01.xhtml#ch01lev1sec9" class="calibre10">page 17</a>). Because of Pluto’s dependency graph, we can know that all the equations displayed in the notebook at any time are consistent with each other, something that is decidedly not true with Jupyter.</p>
<p class="indent">The ability to use Pluto is one reason we might prefer to use <span class="literal">SymPy</span> from within Julia rather than with Python directly. Another is that the wrapping of functions and data structures provided by <span class="literal">SymPy</span> presents a more familiar interface for the Julia programmer and eases interoperation with other Julia programs and libraries. This wrapping is not complete in a sense, however. The user of <span class="literal">SymPy</span> will encounter remnants of Python’s class-method syntax, as we’ll see in such calls as <span class="literal">sol.rhs()</span>, for the right-hand side of a solution <span class="literal">sol</span>.</p>
<p class="indent">Since Pluto is such a powerful (and fun) environment for using <span class="literal">SymPy</span>, the examples in this section will take the form of screenshots from a Pluto session (see <a href="ch01.xhtml" class="calibre10">Chapter 1</a> for a reminder of how to start up a Pluto notebook session).</p>
<p class="indent"><a href="ch12.xhtml#ch12fig2" class="calibre10">Figure 12-2</a> shows the start of the session.</p>
<div class="image1"><img alt="Image" id="ch12fig2" src="../images/ch12fig02.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-2: Starting a</em> <span class="codeitalic">SymPy</span> <em class="calibre11">session within Pluto</em></p>
<p class="indent">After importing the package, we establish some variables as <span class="literal">SymPy</span> symbolic names using the <span class="literal">@syms</span> macro. This serves the same purpose as the <span class="literal">@variables</span> macro used with the <span class="literal">Symbolics</span> package. Entering one of the names as <span class="literal">f()</span> establishes <span class="literal">f</span> as the symbolic name of a function that we can use as an <span epub:type="pagebreak" id="page_390"/>unknown in, for instance, the definition of a differential equation (we’ll look at this shortly).</p>
<h5 class="h4" id="ch12sec1sec3"><strong class="calibre2">Algebra with SymPy</strong></h5>
<p class="noindent"><span class="literal">SymPy</span> can perform algebraic simplification, expansion, and its inverse, factoring, as shown in <a href="ch12.xhtml#ch12fig3" class="calibre10">Figure 12-3</a>.</p>
<div class="image1"><img alt="Image" id="ch12fig3" src="../images/ch12fig03.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-3: Simplification, expansion, and factoring</em></p>
<p class="indent">The subtle underlines adorning some characters in the input cells in <a href="ch12.xhtml#ch12fig3" class="calibre10">Figure 12-3</a> indicate which are <span class="literal">SymPy</span> symbols—a nice refinement to the interface.</p>
<p class="indent">In order to solve systems of algebraic equations, we can place the equations into a vector and call <span class="literal">solve()</span> with the vector as an argument, as shown in <a href="ch12.xhtml#ch12fig4" class="calibre10">Figure 12-4</a>.</p>
<div class="image1"><img alt="Image" id="ch12fig4" src="../images/ch12fig04.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-4: Solving a system of equations</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_391"/>The vector <span class="literal">p</span> contains two equations, entered so their right-hand sides equal 0; therefore, <span class="literal">p</span> represents the following system:</p>
<div class="image"><img alt="Image" src="../images/391math.jpg" class="calibre6"/></div>
<p class="indent">The result of the call to <span class="literal">solve()</span> is the solution <em class="calibre11">a</em> = <em class="calibre11">–</em>1/7, <em class="calibre11">b</em> = 3/7.</p>
<h5 class="h4" id="ch12sec1sec4"><strong class="calibre2">Numerical Solutions with SymPy</strong></h5>
<p class="noindent">Our example happens to involve linear equations, but <span class="literal">SymPy</span> can handle higher-order polynomials, rational equations, and more, and it can find complex and multiple solutions. We can also turn to its built-in numerical solver, useful in cases where no symbolic solution exists.</p>
<p class="indent">As an example, let’s say we were interested in values of <span class="literal">a</span> for which</p>
<p class="center">sin(<em class="calibre11">a</em>) + log(<em class="calibre11">a</em>) = 1</p>
<p class="indent">An attempt to throw this at the symbolic solver only gets us an error message lamenting that <span class="literal">SymPy</span> knows no algorithms for its analytic solution. This is a job for an approximate, numerical solver.</p>
<p class="indent">Intelligent numerical solution behooves us to understand something about the behavior of the equation of interest, at least within and near the neighborhood where we seek solutions. A good first step is to look at a graph of the equation, as shown in <a href="ch12.xhtml#ch12fig5" class="calibre10">Figure 12-5</a>.</p>
<div class="image1"><img alt="Image" id="ch12fig5" src="../images/ch12fig05.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-5: The first step in finding a numerical solution</em></p>
<p class="indent">Here we’ve plotted the left-hand side of the equation; the curve’s intersections with the horizontal line at 1 show us where we can expect the solutions. Inspection of the graph shows three solutions near <span class="literal">a =</span> 1, 3, and 5.</p>
<p class="indent"><span epub:type="pagebreak" id="page_392"/><span class="literal">SymPy</span>’s numerical solver is the <span class="literal">nsolve()</span> function. It expects a symbolic expression in its first argument and a guess for a root for the expression in its second argument. By calling the function three times with three approximate roots, we can get three precise answers, as shown in <a href="ch12.xhtml#ch12fig6" class="calibre10">Figure 12-6</a>.</p>
<div class="image1"><img alt="Image" id="ch12fig6" src="../images/ch12fig06.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-6: Numerical root finding</em></p>
<h5 class="h4" id="ch12sec1sec5"><strong class="calibre2">Integration with SymPy</strong></h5>
<p class="noindent"><span class="literal">SymPy</span> knows calculus, and it can largely replace weighty tables of integrals. We’ll use the package to evaluate the indefinite and a definite integral of the Gaussian distribution (see “The Normal Distribution” on <a href="ch10.xhtml#ch10lev1sec3" class="calibre10">page 323</a>). We can evaluate these integrals in one step by using the <span class="literal">integrate()</span> function, but we can also divide the problem into two stages. The first stage will be to define expressions for the <em class="calibre11">unevaluated</em> integrals, shown in <a href="ch12.xhtml#ch12fig7" class="calibre10">Figure 12-7</a>.</p>
<div class="image1"><img alt="Image" id="ch12fig7" src="../images/ch12fig07.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-7: Unevaluated integrals</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_393"/>We create an unevaluated integral using the <span class="literal">sympy.Integral()</span> function, which requires the namespace prefix because it’s not exported by the package. In this case, the expression under the integral has only one independent variable, but if it had more than one, we would supply the variable of integration as a second argument (which we can in any case, with the same result). The second argument appears in the definite integral version, where the tuple contains the variable of integration and the lower and upper limits. Here <em class="calibre11">e</em> is Euler’s number, which we can enter by typing <span class="codestrong1">\euler</span> followed by TAB or by directly entering the Unicode character. We enter symbolic infinity using a double <span class="literal">o</span>, and symbolic π using <span class="literal">PI</span>—which is not to be confused with the irrational Julia π. The two are not interchangeable: if we use π instead of <span class="literal">PI</span>, the former will be converted into an approximation to π, and factors of π will fail to cancel in subsequent manipulations.</p>
<p class="indent">There can be several reasons for creating such intermediate expressions, rather than integrating in one step. We may want to use these unevaluated integrals in other calculations, or we may simply want to examine their typeset form to ensure that we’ve entered them correctly—something that’s easier to accomplish with conventional mathematical notation than even the exceptionally legible computerese that Julia makes available to us.</p>
<p class="indent">To evaluate the integrals, we pass them to the <span class="literal">doit()</span> function, as shown in <a href="ch12.xhtml#ch12fig8" class="calibre10">Figure 12-8</a>.</p>
<div class="image1"><img alt="Image" id="ch12fig8" src="../images/ch12fig08.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-8: Evaluating the integrals</em></p>
<p class="indent">The indefinite integral (antiderivative) of the Gaussian is not expressible in closed form in terms of elementary functions. It’s defined as the <em class="calibre11">error function</em>, abbreviated erf(<em class="calibre11">z</em>). This is the type of mathematical knowledge built into most capable computer algebra systems, and <span class="literal">SymPy</span> is no exception. The <img alt="Image" class="inline" src="../images/393math.jpg"/> factor in the integral normalizes the result so that the definite integral over the whole line yields 1. With this normalization, the integrand is a probability density function, and the definite integral from <em class="calibre11">a</em> to <em class="calibre11">b</em> is the probability of an observation falling within that interval.</p>
<h5 class="h4" id="ch12sec1sec6"><strong class="calibre2">Differential Equations with SymPy</strong></h5>
<p class="noindent"><span class="literal">SymPy</span> can also solve differential equations. In keeping with our minor theme of the Bessel functions, let’s recall that these mainstays of applied mathematics arise as the solutions of differential equations. <a href="ch12.xhtml#ch12fig9" class="calibre10">Figure 12-9</a> shows a particular example that demonstrates how to define a differential equation in <span class="literal">SymPy</span>.</p>
<div class="image1"><img alt="Image" id="ch12fig9" src="../images/ch12fig09.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-9: Bessell’s equation</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_394"/><a href="ch12.xhtml#ch12fig9" class="calibre10">Figure 12-9</a> shows the construction of the differential equation for the Bessel function of the first kind of order 1. We define the equation using the <span class="literal">Eq()</span> function, which takes the left-hand and right-hand sides as its two arguments. In the definition, we’ve used the symbolic differential operator: <span class="literal">diff(f(z), z, n)</span> is the <em class="calibre11">n</em>th derivative of <em class="calibre11">f</em>(<em class="calibre11">z</em>) with respect to <em class="calibre11">z</em>. It was with this in mind that we established <span class="literal">f()</span> as a symbolic function in <a href="ch12.xhtml#ch12fig2" class="calibre10">Figure 12-2</a>.</p>
<p class="indent">To find the solution to a differential equation, we use <span class="literal">SymPy</span>’s <span class="literal">dsolve()</span> function, which takes the equation to solve and the function to solve it for in its first two arguments. But since boundary conditions are essential for nailing down which solutions we’re interested in, <span class="literal">dsolve()</span> also takes a dictionary of boundary conditions as the value of the keyword argument <span class="literal">ics</span>. We can specify values or derivatives at specific points in this dictionary; here we only need a simple condition to exclude another Bessel function that’s singular at the origin. <a href="ch12.xhtml#ch12fig10" class="calibre10">Figure 12-10</a> shows the call that generates the solution of interest.</p>
<div class="image1"><img alt="Image" id="ch12fig10" src="../images/ch12fig10.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-10: Solving a differential equation</em></p>
<p class="indent"><a href="ch12.xhtml#ch12fig10" class="calibre10">Figure 12-10</a> shows that <span class="literal">SymPy</span> uses the conventional notation for the Bessel function (in Pluto; in the REPL it spells out the name). The solution with the supplied boundary condition is undetermined up to a multiplicative constant, which <span class="literal">SymPy</span> names <em class="calibre11">C</em><sub class="calibre24">1</sub>. The second cell in <a href="ch12.xhtml#ch12fig10" class="calibre10">Figure 12-10</a> shows how to extract the <span class="literal">rhs</span> (right-hand side) of the solution while specifying a value for the constant, in this case 1. We can use the <span class="literal">rhs</span> to plot the solution, as shown in <a href="ch12.xhtml#ch12fig11" class="calibre10">Figure 12-11</a>.</p>
<div class="image1"><img alt="Image" id="ch12fig11" src="../images/ch12fig11.jpg" class="calibre6"/></div>
<p class="figcap"><em class="calibre11">Figure 12-11: Plotting the solution to Bessel’s equation</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_395"/>The curve shown in <a href="ch12.xhtml#ch12fig11" class="calibre10">Figure 12-11</a> agrees with the Bessel function calculated by other means in <a href="ch12.xhtml#ch12fig1" class="calibre10">Figure 12-1</a>.</p>
<h3 class="h2" id="ch12lev2"><strong class="calibre2">Linear Algebra</strong></h3>
<p class="noindent">As Professor L. Fox says in his 1965 textbook <em class="calibre11">An Introduction to Numerical Linear Algebra</em>, about 75 percent of scientific computing involves, wholly or in part, numerical linear algebra. Whatever the current proportion happens to be, linear algebra is, and likely always will be, a central part of any enterprise where we turn to computers to help us solve problems in science, mathematics, or engineering. The fundamental reason for this is because the central problem of numerical linear algebra, the solution of simultaneous systems of linear equations, arises repeatedly in the modeling of an enormous variety of systems—not only those whose behavior is truly linear, but those whose behavior can be linearly modeled within some range of parameters. For example, a system of partial differential equations can often be approximated by a linear algebraic system close to some initial condition or for a small range of a controlling parameter.</p>
<h4 class="h3" id="ch12lev1sec3"><strong class="calibre2"><em class="calibre4">Views</em></strong></h4>
<p class="noindent">In performing calculations using matrices (or arrays of other shapes), we often employ views. A <em class="calibre11">view</em> in Julia is a reference to a part of an array that we can create and manipulate without copying any data; modifications to the view modify the original array.</p>
<p class="indent"><span epub:type="pagebreak" id="page_396"/>We can create views using the <span class="literal">@view</span> or <span class="literal">@views</span> macros. The first version immediately precedes the array expression that we want to turn into a view, while the second transforms all the slicing operations within an entire expression or code block into views:</p>
<pre class="calibre13">   julia&gt; <span class="codestrong">R = rand(5, 5)</span>
   5×5 Matrix{Float64}:
    0.957982  0.206423  0.00489974  0.0881235  0.708827
    0.301785  0.107707  0.524776    0.83413    0.771915
    0.049844  0.031097  0.22972     0.415245   0.735899
    0.438108  0.57943   0.144575    0.131095   0.103629
    0.473649  0.237991  0.148043    0.0351828  0.724837

   julia&gt; <span class="codestrong">row1Rview = @view R[1, :]</span>
   5-element view(::Matrix{Float64}, 1, :) with eltype Float64:
    0.9579822727773696
    0.20642276219972644
    0.004899741566674942
    0.0881235008776815
    0.7088267041115207

<span class="ent">➊</span> julia&gt; <span class="codestrong">row1Rview .= 17;</span>

<span class="ent">➋</span> julia&gt; <span class="codestrong">R</span>
   5×5 Matrix{Float64}:
    17.0       17.0       17.0       17.0        17.0
     0.301785   0.107707   0.524776   0.83413     0.771915
     0.049844   0.031097   0.22972    0.415245    0.735899
     0.438108   0.57943    0.144575   0.131095    0.103629
     0.473649   0.237991   0.148043   0.0351828   0.724837

   julia&gt; <span class="codestrong">@views row1RviewAgain = R[1, :];</span>

   julia&gt; <span class="codestrong">row1RviewAgain === row1Rview</span>
   true</pre>
<p class="indent">After creating a view of the first row of the random matrix <span class="literal">R</span>, we set all of its elements to 17 <span class="ent">➊</span>. Since modifying a view modifies the original, the first row of <span class="literal">R</span> is transformed <span class="ent">➋</span>. We create the same view using the <span class="literal">@views</span> macro, and verify that the views are indeed the same with the last expression.</p>
<p class="indent">The slice syntax used earlier, without the <span class="literal">@view</span> or <span class="literal">@views</span> macros, would create a new array with a <em class="calibre11">copy</em> of the data from the first row of <span class="literal">R</span>. Modifying the copy would do nothing to the original array.</p>
<p class="indent">When should we use copies and when should we use views? The answer depends on the pattern of computation to which we intend to subject the data structures. In this example, since arrays are stored in column-major order, manipulating a row uses noncontiguous memory accesses. If, after extracting the row, we use it repeatedly, then the time consumed in creating <span epub:type="pagebreak" id="page_397"/>the copy may be a good investment. However, if the array is large, the copy will consume significant memory that the use of a view would avoid. Copies use more memory, but can lead to faster code. There is no universal answer to the question beginning this paragraph. Whether it’s better to use views or copies depends on the size of the arrays involved and how we use the data.</p>
<h4 class="h3" id="ch12lev1sec4"><strong class="calibre2"><em class="calibre4">Linear Algebra Examples</em></strong></h4>
<p class="noindent">Let’s look at a simple example problem. Consider the 2×2 system shown in <a href="#ch12equ1" class="calibre10">Equation 12.1</a>.</p>
<div class="image"><img alt="Image" id="ch12equ1" src="../images/397math.jpg" class="calibre6"/></div>
<p class="noindent">In this system of equations, <em class="calibre11">x</em><sub class="calibre24">1</sub> and <em class="calibre11">x</em><sub class="calibre24">2</sub> are the unknowns for which we ultimately seek a solution; the <em class="calibre11">a</em><sub class="calibre24"><em class="calibre11">xx</em></sub>s are numerical coefficients, whose indices indicate their positions in the system. The right-hand side of the system consists of the two numbers <em class="calibre11">b</em><sub class="calibre24">1</sub> and <em class="calibre11">b</em><sub class="calibre24">2</sub>.</p>
<p class="indent">In order to apply the machinery of numerical linear algebra, we’ll follow the universal convention and write the system more compactly as</p>
<div class="image"><img alt="Image" id="ch12equ2" src="../images/397math1.jpg" class="calibre6"/></div>
<p class="calibre26">where A is the matrix</p>
<div class="image"><img alt="Image" src="../images/397math2.jpg" class="calibre6"/></div>
<p class="calibre26"><em class="calibre11">x</em> is the vector [<em class="calibre11">x</em><sub class="calibre24">1</sub>, <em class="calibre11">x</em><sub class="calibre24">2</sub>], and <em class="calibre11">b</em> is the vector [<em class="calibre11">b</em><sub class="calibre24">1</sub>, <em class="calibre11">b</em><sub class="calibre24">2</sub>]. The juxtaposition of A and <em class="calibre11">x</em> indicates the usual matrix multiplication.</p>
<p class="indent">The form of <a href="#ch12equ2" class="calibre10">Equation 12.2</a> suggests that we can somehow divide by A to solve for <em class="calibre11">x</em>, and that is indeed true. As this is a section on <em class="calibre11">numerical</em> linear algebra, in <a href="#ch12equ3" class="calibre10">Equation 12.3</a>, let’s try some actual numbers in place of the symbols in <a href="#ch12equ1" class="calibre10">Equation 12.1</a>:</p>
<div class="image"><img alt="Image" id="ch12equ3" src="../images/397math3.jpg" class="calibre6"/></div>
<p class="noindent">This equation may, or may not, have a solution for <em class="calibre11">x</em><sub class="calibre24">1</sub> and <em class="calibre11">x</em><sub class="calibre24">2</sub>. In order to try to solve it numerically, we’ll define a Julia matrix and a vector for the right-hand side, corresponding to A and <em class="calibre11">b</em> in <a href="#ch12equ2" class="calibre10">Equation 12.2</a>, as shown in <a href="ch12.xhtml#ch12lis4" class="calibre10">Listing 12-4</a>.</p>
<pre class="calibre13">julia&gt; <span class="codestrong">A = [1 3; 2 4]</span>
2×2 Matrix{Int64}:
 1  3
 2  4

julia&gt; <span class="codestrong">b = [1, 7]</span>
2-element Vector{Int64}:
 <span epub:type="pagebreak" id="page_398"/>1
 7</pre>
<p class="list" id="ch12lis4"><em class="calibre11">Listing 12-4: A small linear system</em></p>
<p class="indent">At this point, if we could make sense of the idea of dividing by a matrix, then we would expect that the solution could be calculated by dividing <span class="literal">b</span> by <span class="literal">A</span>. This, in fact, will be our first approach to solving the equation system in <a href="ch12.xhtml#ch12lis4" class="calibre10">Listing 12-4</a>.</p>
<p class="indent">Of course we’re familiar with the <span class="literal">/</span> operator for division. Julia comes with a “reverse” version, called the <em class="calibre11">left division operator</em>, that we haven’t had occasion to use until now:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">1 / 3 == 3 \ 1</span>
true</pre>
<p class="indent">Julia’s <span class="literal">Base</span> extends the left division operator to operate on matrices, calculating the inverse of a matrix and then performing a matrix multiplication. The result should be a column array containing the solution:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">A \ b</span>
2-element Vector{Float64}:
  8.5
 -2.5</pre>
<p class="indent">This is indeed the solution, as we can immediately verify:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">A * [8.5, -2.5]</span>
2-element Vector{Float64}:
 1.0
 7.0</pre>
<p class="noindent">The result is <span class="literal">b</span>, as defined in <a href="ch12.xhtml#ch12lis4" class="calibre10">Listing 12-4</a>.</p>
<p class="indent">As mentioned, the meaning of <span class="literal">A \ b</span> is the matrix multiplication of the <em class="calibre11">inverse</em> of <span class="literal">A</span> with <span class="literal">b</span>:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">inv(A) * b</span>
2-element Vector{Float64}:
  8.5
 -2.5

julia&gt; <span class="codestrong">inv(A) == A^-1</span>
true</pre>
<p class="noindent">The second input expression shows another way to spell the inverse of a matrix.</p>
<p class="indent">Although this is the formal meaning of the <span class="literal">\</span> operator, we should never solve equation systems using <span class="literal">inv()</span>, but instead with an expression such as <span class="literal">A \ b</span>. This is because the left division operator solves the system using the most efficient algorithm available, which may not involve the calculation of the inverse matrix.</p>
<p class="indent"><span epub:type="pagebreak" id="page_399"/>The inverse of a matrix is defined such that A<sup class="calibre23">−1</sup> A and AA<sup class="calibre23">−1</sup> are both equal to the <em class="calibre11">identity matrix</em>, which has the same shape as A and has 1.0 on the diagonal and 0.0 elsewhere:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">A * inv(A)</span>
2×2 Matrix{Float64}:
 1.0  0.0
 0.0  1.0</pre>
<p class="indent">The identity matrix is conventionally represented as I, and is called thus because it is the identity element under matrix multiplication:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">I22 = A * inv(A);</span>
julia&gt; <span class="codestrong">I22 * A == A * I22 == A</span>
true</pre>
<p class="noindent">In general, matrix multiplication is not commutative, but multiplication by the identity matrix, and multiplication of a matrix by its inverse, are.</p>
<h4 class="h3" id="ch12lev1sec5"><strong class="calibre2"><em class="calibre4">The LinearAlgebra Package</em></strong></h4>
<p class="noindent">The examples in this section so far require no package imports, as <span class="literal">inv()</span> and the extension of <span class="literal">\</span> to matrices are part of <span class="literal">Base</span>. To go further, we need to import the <span class="literal">LinearAlgebra</span> package, which is part of the standard library, so it imports quickly and nothing needs to be downloaded. The rest of the code examples in this section assume that you’ve executed <span class="literal">using LinearAlgebra</span>.</p>
<p class="indent">The <span class="literal">LinearAlgebra</span> package can perform all of the standard operations on matrices. We’ll demonstrate using our little matrix <span class="literal">A</span>. First, the trace and the determinant:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">tr(A) # Trace of A</span>
5

julia&gt; <span class="codestrong">det(A) # Determinant of A</span>
-2.0</pre>
<p class="indent">Next, the calculations of eigenvalues and eigenvectors (A<em class="calibre11">x</em> = <em class="calibre11">λx</em> if <em class="calibre11">x</em> is an eigenvector of A and <em class="calibre11">λ</em> is its eigenvalue):</p>
<pre class="calibre13">julia&gt; <span class="codestrong">eigvecs(A) # Eigenvectors</span>
2×2 Matrix{Float64}:
 -0.909377  -0.565767
  0.415974  -0.824565

julia&gt; <span class="codestrong">eigvals(A) # Eigenvalues</span>
2-element Vector{Float64}:
 -0.3722813232690143
  5.372281323269014</pre>
<p class="indent"><span epub:type="pagebreak" id="page_400"/>The <em class="calibre11">n</em>th eigenvector/eigenvalue pair is the <em class="calibre11">n</em>th column of the matrix returned by <span class="literal">eigvecs()</span> along with the <em class="calibre11">n</em>th element of the vector returned by <span class="literal">eigvals()</span>. We can check to see if the <span class="literal">LinearAlgebra</span> functions return the correct values:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">evec1 = eigvecs(A)[:,1];</span>

julia&gt; <span class="codestrong">eval1 = eigvals(A)[1];</span>

julia&gt; <span class="codestrong">A * evec1  - evec1 * eval1</span>
2-element Vector{Float64}:
  0.0
 -5.551115123125783e-17</pre>
<p class="indent">Here we’ve assigned names to the first eigenvector and its eigenvalue; we should see that <span class="literal">A * evec1</span> is equal to <span class="literal">eval1 * evec1</span>. Comparing the two values in the final expression, we see that they are the same within floating-point accuracy.</p>
<h4 class="h3" id="ch12lev1sec6"><strong class="calibre2"><em class="calibre4">Specialized Matrix Types</em></strong></h4>
<p class="noindent">Linear algebra routines, such as <span class="literal">eigvals()</span> and others, are written to dispatch an algorithm designed to take advantage of the symmetries or other properties of the matrices involved. The routines check for relevant properties of the matrix arguments passed to them in order to choose the most efficient method of solution. For example, the <span class="literal">eigvals()</span> function checks for symmetry of real matrices using the <span class="literal">issymmetric()</span> function, and hermiticity of complex matrices using <span class="literal">ishermitian()</span>.</p>
<p class="indent">The matrix properties that are important in choosing an efficient routine include, among others, whether a matrix is symmetric, banded, triangular, hermitian, sparse (see “The Adjacency Matrix” on <a href="ch07.xhtml#ch07lev1sec1" class="calibre10">page 196</a>), or diagonal. Each of these matrix classes has an associated Julia type. We can convert a general matrix to one of these more specific types by creating a view using the appropriate function. For example, <span class="literal">Symmetric(M)</span> creates a view of the matrix <span class="literal">M</span> that is symmetric. We might want to do this in order to pass the result to a linear algebra function ensuring that it selects the optimal algorithm, in case it doesn’t detect the character of the matrix.</p>
<p class="indent">To get an idea of how all this works, let’s look at the behavior of the <span class="literal">eigvals()</span> function. First, we create a moderately large matrix for our timing study, as shown in <a href="ch12.xhtml#ch12lis5" class="calibre10">Listing 12-5</a>.</p>
<pre class="calibre13">julia&gt; <span class="codestrong">N = 3000;</span>

julia&gt; <span class="codestrong">G = rand(N, N);</span>

julia&gt; <span class="codestrong">sG = (G + G') / maximum(G + G');</span></pre>
<p class="list" id="ch12lis5"><em class="calibre11">Listing 12-5: Creating a random, symmetric matrix</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_401"/>The final assignment creates a symmetric matrix by adding <span class="literal">G</span>, elementwise, to its transpose. Let’s compute the eigenvalues of <span class="literal">G</span> in several ways, as shown in <a href="ch12.xhtml#ch12lis6" class="calibre10">Listing 12-6</a>. We don’t care about the results, but we’re interested in the timings.</p>
<pre class="calibre13">   julia&gt; <span class="codestrong">using BenchmarkTools</span>

   julia&gt; <span class="codestrong">@btime eigvals(G);</span>
     24.044 s (20 allocations: 69.58 MiB)

   julia&gt; <span class="codestrong">@btime eigvals(sG);</span>
     4.612 s (14 allocations: 69.74 MiB)

<span class="ent">➊</span> julia&gt; <span class="codestrong">SsG = Symmetric(sG);</span>

   julia&gt; <span class="codestrong">SsG == sG</span>
   true

   julia&gt; <span class="codestrong">typeof(SsG)</span>
   Symmetric{Float64, Matrix{Float64}}

<span class="ent">➋</span> julia&gt; <span class="codestrong">@btime eigvals(SsG);</span>
     4.481 s (14 allocations: 69.74 MiB)</pre>
<p class="list" id="ch12lis6"><em class="calibre11">Listing 12-6: Timing the calculation of eigenvalues</em></p>
<p class="indent">The first two timings demonstrate that the <span class="literal">eigvals()</span> function can exploit the symmetry of the matrix to drastically reduce the calculation time. We also create a <span class="literal">Symmetric</span> view of <span class="literal">sG</span> <span class="ent">➊</span>, which contains the same values as the original matrix, but is of a different type. In this case, the use of <span class="literal">SsG</span> doesn’t affect the calculation time <span class="ent">➋</span>, as <span class="literal">eigvals()</span> has already detected that <span class="literal">sG</span> is symmetric. We could also ask <span class="literal">eigvals()</span> to compute <span class="literal">eigvals(Symmetric(G))</span>, and it would do so as quickly as it computed the eigenvalues of the actually symmetric matrix just shown. But in this case, the computed eigenvalues would not be the eigenvalues of <span class="literal">G</span>, as <span class="literal">G</span> is not symmetric.</p>
<p class="indent">The <span class="literal">eigvals()</span> and <span class="literal">eigvecs()</span> functions check for symmetric or hermitian arguments, but not for other properties. We can demonstrate this by calculating the eigenvalues of an upper triangular matrix: a matrix with zero elements below the diagonal. First we need to construct the matrices for use in the test:</p>
<pre class="calibre13">   julia&gt; <span class="codestrong">N = 3000;</span>

   julia&gt; <span class="codestrong">G = rand(N, N);</span>

<span class="ent">➊</span> julia&gt; <span class="codestrong">UTt = UpperTriangular(G);</span>

   julia&gt; <span class="codestrong">typeof(UTt)</span>
   UpperTriangular{Float64, Matrix{Float64}}

   <span epub:type="pagebreak" id="page_402"/>julia&gt; <span class="codestrong">UT = Matrix(UTt);</span>

   julia&gt; <span class="codestrong">typeof(UT)</span>
   Matrix{Float64} (alias for Array{Float64, 2})

<span class="ent">➋</span> julia&gt; <span class="codestrong">UT == UTt</span>
   true</pre>
<p class="indent">After making, again, a random matrix <span class="literal">G</span>, we create <span class="ent">➊</span> an <span class="literal">UpperTriangular</span> view of this matrix and assign it to <span class="literal">UTt</span>. Then we assign it to <span class="literal">UT</span> after converting it to a basic <span class="literal">Matrix</span> type. This is a convenient way to make a full matrix that happens to be upper triangular. The two objects contain the same elements <span class="ent">➋</span> but are of different types. The type of <span class="literal">UTt</span> tells <span class="literal">LinearAlgebra</span> functions that it’s upper triangular, so they can take advantage of that in case a specialized algorithm is available. <span class="literal">eigvals()</span> is one of these functions:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">@btime eigvals(UT);</span>
  119.571 ms (18 allocations: 69.53 MiB)

julia&gt; <span class="codestrong">@btime eigvals(UTt);</span>
  35.905 μs (2 allocations: 23.48 KiB)</pre>
<p class="indent">The time to compute the 3,000 eigenvalues is much shorter than for a matrix with no structure (<a href="ch12.xhtml#ch12lis6" class="calibre10">Listing 12-6</a>) due to all the zeros in <span class="literal">UT</span>. The time that <span class="literal">eigvals()</span> needs to work on the <span class="literal">UpperTriangular</span> view of the matrix is drastically reduced (note the units in the timings returned by <span class="literal">@btime</span>), as are the memory requirements. The matrices have identical elements, and the computed eigenvalues are the same (but are returned in a different order). However, the information carried by the <span class="literal">UpperTriangular</span> type informs <span class="literal">eigvals()</span> about the matrix’s structure, which is information it can use in dispatching to an algorithm more efficient than the general-purpose one.</p>
<p class="indent">The moral of this story is that we should pass the most informative view possible to any <span class="literal">LinearAlgebra</span> function.</p>
<h4 class="h3" id="ch12lev1sec7"><strong class="calibre2"><em class="calibre4">Equation Solving and factorize()</em></strong></h4>
<p class="noindent">A <em class="calibre11">factorization</em> of a matrix, analogous to the factorization of a number, is a series of matrices that, when (matrix) multiplied together, yield the original matrix. Matrix factoring is often an early step in the solution of a matrix equation (a system of linear equations), and is attempted by the left division operator, the standard function for solving such systems. The factorization can be the most time-consuming part of the calculation of the solution, which often proceeds rapidly after the factorization is complete. As many problems involve the repeated solution of equations in the form of <a href="#ch12equ2" class="calibre10">Equation 12.2</a> using different <em class="calibre11">b</em> vectors, it would save significant time if we could perform the factorization once, separating out that part of the calculation. This is what the <span class="literal">LinearAlgebra</span> function <span class="literal">factorize()</span> enables:</p>
<pre class="calibre13"><span epub:type="pagebreak" id="page_403"/>julia&gt; <span class="codestrong">N = 8000;</span>

julia&gt; <span class="codestrong">G = rand(N, N);</span>

julia&gt; <span class="codestrong">g = rand(N);</span>

julia&gt; <span class="codestrong">fG = factorize(G);</span>

julia&gt; <span class="codestrong">@btime G \ g;</span>
  10.073 s (6 allocations: 488.40 MiB)

julia&gt; <span class="codestrong">@btime fG \ g;</span>
  37.942 ms (2 allocations: 62.55 KiB)</pre>
<p class="indent">Here we see that solving the equation system using the pre-factored matrix is about 200 times faster, and uses a small fraction of the memory required, than when we use the unfactored matrix. However, the call to <span class="literal">factorize()</span> itself takes about as much time as the calculation <span class="literal">G \ g</span>. The advantage is that we can use <span class="literal">fG</span> in subsequent problems that vary only in their right-hand sides to get solutions cheaply.</p>
<p class="indent">Telling <span class="literal">\</span> about the properties of the matrix using views doesn’t help, as it did with <span class="literal">eigvals()</span>:</p>
<pre class="calibre13">julia&gt; <span class="codestrong">g = rand(3000)</span>

julia&gt; <span class="codestrong">@btime sG \ g;</span>
  504.239 ms (6 allocations: 68.71 MiB)

julia&gt; <span class="codestrong">@btime SsG \ g;</span>
  556.492 ms (8 allocations: 70.18 MiB)

julia&gt; <span class="codestrong">fSsG = factorize(SsG);</span>

julia&gt; <span class="codestrong">@btime fSsG \ g;</span>
  6.161 ms (2 allocations: 23.48 KiB)</pre>
<p class="indent">Here, also, although the <span class="literal">Symmetric</span> view doesn’t help, we observe a large speedup and decrease in memory consumed when using the factorized matrix.</p>
<h3 class="h2" id="ch12lev3"><strong class="calibre2">Conclusion</strong></h3>
<p class="noindent">This chapter covers two large topics that, I believe, are generally useful to scientists, engineers, and other technical users of Julia.</p>
<p class="indent">The use of symbolic mathematics packages is potentially valuable for everyone, and my discussions with various students and researchers convinces me that many are unaware that computers can calculate integrals and derivatives, solve equations symbolically, and perform other feats of real <span epub:type="pagebreak" id="page_404"/>mathematical manipulation—not merely arithmetic. Opening this door leads to many possibilities, especially when symbolic and numerical methods are combined, as encouraged by the <span class="literal">Symbolics</span> package.</p>
<p class="indent">Of course, linear algebra is a vast traditional area for computer application, and we only scratched the surface here. Julia is particularly convenient for calculations in this arena. BLAS (Basic Linear Algebra Subprograms) and LAPACK are the Fortran libraries at the heart of numerical linear algebra, and most languages’ linear algebra abilities amount to interfaces to these venerable collections of optimized routines. Julia is unusual in several regards: BLAS and LAPACK are being rewritten in pure Julia, an ongoing project, and, through the <span class="literal">libblastrampoline</span> package, Julia offers the unique ability to switch between BLAS implementations on the fly.</p>
<div class="box">
<p class="boxtitle-d"><strong class="calibre2">FURTHER READING</strong></p>
<ul class="calibre12">
<li class="noindent1">See  “Symbolic Mathematics on Linux” for more details on symbolic math: <a href="https://lwn.net/Articles/710537/" class="calibre10"><em class="calibre11">https://lwn.net/Articles/710537/</em></a>.</li>
<li class="noindent1">Documentation for  <span class="literal">Symbolics.jl</span> is available at  <a href="https://symbolics.juliasymbolics.org/stable/" class="calibre10"><em class="calibre11">https://symbolics.juliasymbolics.org/stable/</em></a>.</li>
<li class="noindent1">OSCAR is a computer algebra package that covers algebra,  geometry,  and number theory: <a href="https://oscar.computeralgebra.de" class="calibre10"><em class="calibre11">https://oscar.computeralgebra.de</em></a>.</li>
<li class="noindent1">For a list of matrices with special symmetries and structures,  visit  <a href="https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#Special-matrices" class="calibre10"><em class="calibre11">https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#Special-matrices</em></a>.</li>
<li class="noindent1"><span class="literal">libblastrampoline</span> is available at <a href="https://github.com/JuliaLinearAlgebra/libblastrampoline" class="calibre10"><em class="calibre11">https://github.com/JuliaLinearAlgebra/libblastrampoline</em></a>.</li>
<li class="noindent1">The recently developed  <span class="literal">LinearSolve</span> package provides a unified interface for a selection of linear equation solvers: <a href="https://github.com/SciML/LinearSolve.jl" class="calibre10"><em class="calibre11">https://github.com/SciML/LinearSolve.jl</em></a>.</li>
</ul>
</div>
</body></html>