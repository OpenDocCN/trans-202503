<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="index: http://www.index.com/" lang="en" xml:lang="en">
<head>
<title>Chapter 13: Delivering Python Applications</title>
<link href="NSTemplate_v1.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:1ff3c234-c763-4a12-a0c7-4ddf7c732e40" name="Adept.expected.resource"/>
</head>
<body epub:type="bodymatter chapter">
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" id="Page_257" title="257"/>13</span><br/>
<span class="ChapterTitle">Delivering Python Applications</span></h1>
</header>
<figure class="opener">
<img alt="" src="image_fi/book_art/chapterart.png"/>
</figure>
<p class="ChapterIntro">Once you feel you’ve met the requirements for a minimum viable product, it’s time to focus on the delivery pipeline. A <em>delivery pipeline</em> defines how your users will get your application and any future updates. Truthfully, I tend to start my projects by defining these attributes, as they can make some development choices more or less advantageous. For example, if you decide to deploy your application to the cloud, saving the data as local files doesn’t make as much sense as it would if you plan to deliver your code as a local package. In this chapter, we’ll take a high-level look at four potential delivery pipelines. Each method has a deep pool of resource material to help you deliver your project, so I’ll focus on the important considerations, strengths, and weaknesses of each method.</p>
<p>In addition to discussing the delivery aspects of each method, I’ll talk about the removal process. One part of an MVP that people often neglect is the uninstall capability. Having a good, clean uninstall function for your <span epub:type="pagebreak" id="Page_258" title="258"/>application is, in my opinion, one of the keys to being a good software vendor. The objective for your uninstaller should be to leave nothing behind for the user to clean up. As you’ll see, some methods make this easier than others.</p>
<p>One major influence on which delivery method to choose is whether or not you plan to monetize access to the application, and how. For example, if you want to charge users a subscription fee, you probably want to skip to the sections “<span class="xref" itemid="xref_target_Distributing with Cloud Microservices"><a href="#h1-502567c13-0003">Distributing with Cloud Microservices</a></span>” or “<span class="xref" itemid="xref_target_Licensing with PyArmor"><a href="#h1-502567c13-0004">Licensing with PyArmor</a></span>,” both options that would allow you to define who has access to your application. The downside is that neither option is free, so if you don’t plan to charge for access to your application, it may be more cost-effective to distribute the application via GitHub using the setup script or prepackage the application with all the files needed to run the application. </p>
<h2 id="h1-502567c13-0001">Using Setup Scripts</h2>
<p class="BodyFirst">The simplest choice for distributing a Python application is to use a special configuration script named <em>setup.py</em>, which configures the underlying system with the libraries and supporting files necessary to run the code. You’ve probably run into this method if you’ve installed a Python module after manually downloading a GitHub repository. More generally speaking, installing code packaged using this method requires your users to install a library called setuptools, which handles the installation based on the structure you define in the setup script. You can learn more about the structure and options for the setup scripts by reading the PyPi documentation (<a class="LinkURL" href="https://pythonhosted.org/an_example_pypi_project/setuptools.html">https://pythonhosted.org/an_example_pypi_project/setuptools.html</a>). </p>
<p>The major benefit to using this method is that you can get your project hosted on PyPi, which will then allow your users to install it simply using the pip tool. When you install a project from PyPi, the pip tool pulls the appropriate version of your project from a storage location you define (most often, a public GitHub repository, although there are other options as well). Your users won’t need to manually download repositories or run setup scripts, all of which is handled in the background. </p>
<p>However, there are some definite drawbacks to this method. First, it’s very difficult to monetize the code. There are no controls to stop a user from copying the source code to another machine. There’s also no native way to remove the code once it’s installed, which means even if you found a way to monetize access, you’d be limited to charging a one-time fee for lifetime access. There would be no way to enforce something like a subscription plan. Second, the setup script relies on your users installing the application from the command line. This is fine if you expect your users to be familiar with that process, but this isn’t the best choice for delivering applications to the general population. Finally, installing an application this way makes changes to the user’s underlying system. It installs the packages and configures them. While this works most of the time, making any changes to a system runs the risk of corrupting something, colliding with existing files, and so on. If the user doesn’t install your application in an isolated virtual environment, <span epub:type="pagebreak" id="Page_259" title="259"/>there’s the very real risk of running into incompatible library versions with some other application the user installed.</p>
<p>Removing applications installed with this method poses its own problems and usually requires the user to remove the requirements and other resources from their system. If you opt to go this route, I recommend pushing your users to use separate virtual environments. If the user hasn’t set up the application in an isolated virtual environment, trying to helpfully uninstall a dependency may break other applications on their system. On the other hand, if your users do install everything in its own virtual environment, uninstalling is as easy as deleting the environment.</p>
<p>I recommend using the setup script method for open source applications and smaller projects that aren’t backed by the resources for a more complex delivery pipeline. You can deploy a module and setup script to PyPi in a matter of minutes once you have an account. Setup scripts are also a good entry point for understanding more complex deployments, like cloud services, because at some level, all these methods need a way to understand what dependencies must be present for the code to function. Overall, this is a solid delivery method every Python developer should be familiar with.</p>
<h2 id="h1-502567c13-0002">Packaging with Python Interpreters</h2>
<p class="BodyFirst">The next option aims to address some of the shortcomings of the setup script method by taking some work off the user. The idea is to package the code, support files, and the Python interpreter to run it into a single archive that can be delivered to the user. The user then simply needs to extract the archive to a directory on their system and they’re ready to run the application. </p>
<p>This allows for better monetization than the setup script. By hosting the packaged application download behind a website, you can charge users for each new version or you can charge a monthly subscription fee to the site that includes access to the latest versions for download. There’s still nothing to stop a user from paying once and keeping that version forever, but they also have incentive to maintain their account for access to the latest features.</p>
<p>To handle the packaging, I use PyInstaller, a free application to help collect the necessary files to make your program stand-alone, meaning able to run without configuring the underlying system. Packaging with this method is often called <em>freezing</em> an application because it collects a copy of the current version of all dependencies and the Python interpreter installed on the system, and then it packages them such that the included interpreter will use only those packaged libraries to operate. The advantage here is that you don’t need to worry about what version of a package is installed or whether it will conflict with other applications on the user’s machine. The disadvantage is that if you need to update one of the underlying libraries after freezing the application—for instance, to mitigate a security risk in one of the dependencies—it requires releasing a patch or a new build of the application for distribution. If a user doesn’t apply the patch or download the latest version (all too common), their system is left at risk. </p>
<p><span epub:type="pagebreak" id="Page_260" title="260"/>The other drawback is the size of most frozen applications. To make sure the internal code functions properly, the entire standard library is usually frozen along with the other dependencies. The large code base and the Python interpreter mean that even simple applications may end up being multiple megabytes. PyInstaller does what it can to minimize the bloat, and you can configure it to reduce the weight even further, but ultimately there will always be additional bloat with this method.</p>
<p>Like energy, complexity doesn’t just disappear. Taking the complexity off the user means putting it onto yourself. For the frozen delivery method to work, you’ll need to create a different package for each type of system you want to support. For example, you may end up with one package named <em>agp_linux64_amd.tar.gz</em> intended for users on a 64-bit Linux system that has an AMD, one named <em>agp_win64_intel.zip</em> intended for users who have 64-bit Windows running on an Intel platform, and so on. To package each of these, you need access to a copy of the underlying OS that can be used to package the system files. To run the application during development, I use VirtualBox with a copy of each OS as a virtual machine preconfigured with the proper dependencies and version of Python. I like this method because it allows me to automate the build process for several platforms at once using the VirtualBox-manager application and some custom scripting (<a class="LinkURL" href="https://www.virtualbox.org/wiki/Documentation">https://www.virtualbox.org/wiki/Documentation</a>).</p>
<p>For Windows, you face a unique circumstance. At the time of writing, some of the necessary drivers are protected by Microsoft licenses. Redistributing these libraries within your application without paying a licensing fee could be a breach of the Microsoft terms of service, and may even result in you being held liable for any perceived loss of revenue. The caveat is that if the end user already has a copy of the libraries (as is usually the case), then sending them the application wouldn’t violate the Microsoft agreement. Suffice to say: when and how you can deliver a prepackaged Python application for Windows is a bit of a gray area. Don’t interpret this as legal advice; I am not a lawyer. I insist you consult with an attorney in your area who specializes in intellectual property disputes around technology licenses. They’ll be able to help you steer clear of any legal risks.</p>
<p>Freezing your application might be a good choice if you want to deliver a stand-alone version of it for users. The benefit of a stand-alone project is that it’s easy to set up and remove from a machine—uninstalling can be as simple as deleting a folder. In a lot of cases, frozen applications can even be run from a USB storage device, meaning you can carry it with you anywhere, and you won’t need to install the code on a system to use it!</p>
<h2 id="h1-502567c13-0003">Distributing with Cloud Microservices</h2>
<p class="BodyFirst">Deploying to the cloud means different things for different people. You could argue that hosting the packages from the previous messages using some data storage service (like Amazon’s S3 or Google’s Cloud Storage) and hosting the website in a virtual machine served by the same vendor <span epub:type="pagebreak" id="Page_261" title="261"/>constitutes a cloud deployment. It’s true that the delivery pipeline is a cloud service at that point, but the application itself would still be downloaded and run locally by the user, so I don’t consider it a true cloud service. </p>
<p>To me, a cloud deployment runs the majority of its functional code from infrastructure hosted by a service provider (like Google or Amazon), meaning your application is served to users in a functional state, rather than sending them source code to run. For the rest of the chapter, I’ll refrain from speaking about any one service provider. The two major global cloud providers, Google Cloud Platform (GCP) and Amazon Web Services (AWS), maintain approximately equivalent features, so I think it’s more beneficial to discuss the concepts generally. You can take these concepts and learn how to apply them using your particular provider. </p>
<p>Rather than hosting code to download, the user will generally be given access to your software via a website of some sort. It’s possible to have a user-side application that acts as the interface to the cloud structure, but this is less common because it adds complexity to an already complex process. The code is broken up into small chunks called <em>microservices</em>, each of which handles one small part of the application. </p>
<p><a href="#figure13-1" id="figureanchor13-1">Figure 13-1</a> shows a simplified microservice architecture for the AGP project.</p>
<figure>
<img alt="" class="" src="image_fi/502567c13/f13001.png"/>
<figcaption><p><a id="figure13-1">Figure 13-1</a>: Microservice architecture diagram</p></figcaption>
</figure>
<p>Each oval represents a small part of the application run inside a virtual machine with just enough resources to execute the function and then disappear once it’s no longer needed. The key to a good microservice deployment lies in cleanly separating the functions into services and efficiently managing the communication between the services (the black arrows in the figure). </p>
<p><span epub:type="pagebreak" id="Page_262" title="262"/>In <a href="#figure13-1">Figure 13-1</a>, I’ve divided the project into four services. The user interface is moved into a website that most likely uses HTML5 for the interactive drawing and JavaScript for communicating with the rest of the services. JSON is a good choice for the communication protocol since the communication between services is mostly handled using HTTP requests, and both languages involved (Python and JavaScript) handle the format easily. The Data Manager service holds the functions for saving and loading project data for users. </p>
<p>One limitation of a lot of microservice designs is that they lack a permanent filesystem to serve files from. You can overcome this by creating a persistent storage location, or you could make the storage location a persistent database instance. In fact, with a bit of ingenuity, you can make any network-accessible storage location work for this purpose. In any case, placing the Data Manager service between the other services and the storage container means the Data Manager is the only service that needs to know how to read and write from the Cloud Storage container. If you decide to migrate to a different method of storage later, you’ll only need to update one service. </p>
<p>The Graph builder service contains all of the functions for the application to manage the graph representation of a gallery. It communicates with both the User Web Interface (to take in the JSON data representing the graph) and the Data Manager (to save the information once completed). The Triangle Solver service contains the functions for managing the polygon representation of a gallery, including the code to ultimately solve each floor using the Triangle library. It also talks with the User Web Interface service and the Data Manager service to handle the input and output for the code. </p>
<p>Docker is great for microservices because it allows you to configure each virtual machine to contain only the pieces necessary to run the service’s code, making them faster to create and more secure to operate. You can use Docker containers to define these tiny machines on most cloud providers (<a class="LinkURL" href="https://docs.docker.com">https://docs.docker.com</a>). Furthermore, you can use a container orchestration platform like Kubernetes to automatically manage the creation and deletion of each service container as needed. </p>
<p>Automatically creating more instances of your application to serve to users is called <em>horizontal scaling</em>. Taking advantage of the horizontal scaling capabilities of your platform will allow your application to seamlessly adapt to changes in processing needs. You can define rules for each service individually, meaning you’ll scale only the parts of the application that need to and leave the rest alone. For example, suppose your application has 20 users who simultaneously request the solution for different floor plans. With a traditional architecture, the Triangle service would have to handle all 20 requests, so the last user in the queue will have a longer wait than the first. With horizontal scaling, the orchestration engine will see the increase in demand and add 19 more copies of the Triangle Solver service. The additional copies all run in parallel, so all the requests can be handled simultaneously. On the other hand, 20 users on a web server is usually fine, so you wouldn’t want the orchestration platform to add more copies of the <span epub:type="pagebreak" id="Page_263" title="263"/>User Interface Service. By configuring automated horizontal scaling rules for each service individually, you can save yourself hours of maintenance down the road. This is the third form of parallelism you can take advantage of: <em>hardware parallelism.</em> It’s similar to process parallelism, discussed in <span class="xref" itemid="xref_target_Chapter 12"><a href="c12.xhtml">Chapter 12</a></span>, but the work is spread across different machines instead of different cores on the same machine.</p>
<p>The cloud microservices method is probably the most complex to achieve initially, but the benefits are also numerous. We’ve already seen how its flexibility can allow for quick iterations and reduce maintenance time. Another benefit is that you can easily monetize the application with much greater control. Since the source code is never sent to the end user, they must maintain their account to continue accessing the service. There’s usually little to nothing for the user to uninstall if they choose to stop using the service as well. All a user needs to do is terminate their account and the service is gone, making it the cleanest exit method from this perspective. </p>
<p>You can run multiple versions of the application to serve users at your discretion. Most cloud service providers offer application layer traffic routing, which allows you to intelligently direct traffic to different copies of your application based on some rules you define. Kubernetes also has some traffic routing capabilities that can be used to achieve the same effect. You can use the traffic routing ability to selectively beta-test changes before distributing them to all users or to define separate testing and production versions (called <em>A/B</em> or <em>blue/green testing</em>).<sup class="endnote"><a href="b01.xhtml#c13-endnote-001" id="c13-noteref-001">1</a></sup></p>
<p>Finally, updates are entirely under your control. Users automatically have access to the newest production version as soon as you update it. Typically, microservices are built in several stages. The stages can vary from project to project but roughly follow these phases: code push, continuous integration testing, Docker container build, and finally, service deployment. The code push is probably already familiar to you. It occurs when you push some changes to the code repositories (for example, with the command <code>git push</code>). Pushing the code triggers the continuous integration tests. These tests are designed to ensure that you don’t introduce any common bugs with your changes (<a class="LinkURL" href="https://circleci.com/blog/proactive-integration-testing">https://circleci.com/blog/proactive-integration-testing</a>).</p>
<p>The major drawback is the monetary and time costs associated with building and maintaining the network of services required to make the application behave seamlessly for users. Each cloud provider comes with its own unique way of implementing the pieces, and the pieces themselves require you to understand auxiliary applications like Docker and Kubernetes to work. If you decide to deploy your application in the cloud, you’ll need to spend some time learning the idiosyncrasies of the platform you choose. It also doesn’t hurt to have a development team to support your cloud deployment efforts. </p>
<p>You can’t expect to become an expert in all the different components necessary for a solid cloud deployment pipeline. I’ve been lucky through my career to have the pleasure of working with some of the best cloud engineers in the field, and what I learned was the value of a strong team made up of different specialists. Having someone who can focus on the architecture while another person focuses on the user interface while a third writes <span epub:type="pagebreak" id="Page_264" title="264"/>the main service code means the work can get done much quicker; this is parallel development. Having a team also allows each person to maintain focus on the areas where they are most knowledgeable, and your project to benefit from the added expertise. Of course, running a development team brings its own host of problems: conflicting personalities, failures on delivery dates, and so on. Deciding to use a development team means you also need someone who will be responsible for communication and coordination among the team members<sup class="endnote"><a href="b01.xhtml#c13-endnote-002" id="c13-noteref-002">2</a></sup> (called the <em>project manager</em>). Cloud deployments are at the heart of all modern software-as-a-service (SaaS) companies because the long-term benefits far outweigh the initial development cost. Of course, cloud deployments may not be the best choice for a small project with only a few planned users.</p>
<h2 id="h1-502567c13-0004">Licensing with PyArmor</h2>
<p class="BodyFirst">The next method is a bit of an oddball. PyArmor is a command line tool for obfuscating Python source code. It’s conceptually similar to the stand-alone application in the sense that you still deliver an executable to your users, but PyArmor tries to ensure that your Python applications are saved and run only from approved machines in an attempt to protect your intellectual property and help monetize executables you deliver to your users. <em>Obfuscation</em> is the process of hiding the structure and operation of the code to render the application inoperable without the proper de-obfuscation technique. An example of obfuscation might be changing the string <code>"Hello from PyArmor"</code> to something like <code>"H7ejl8l3ocb1fRr4osm9blPjy9Afr4mvo0rp"</code>. The application obfuscates constants and literal strings as well as the runtime code of each function. If someone attempts to read your source code, either at rest or in memory, they’ll be met by a wall of gibberish. </p>
<p>Obfuscating your application’s source code also enables you to bind your application to a single machine and expire the application remotely. Your code is hidden behind a startup application that contains the proper de-obfuscation technique. PyArmor startup scripts check for a license file that was created when the user installed your application. The license file uses some unique machine attributes to ensure it’s run on the same machine at each start. </p>
<p>You can also define a license server that manages the validity of each license. On each start, your application calls out to the license server with its license identifier. Your server can then respond with an authenticated message saying whether or not the application should allow itself to execute. Of course, this relies on your user having network access every time they want to run your software, which may or may not make sense for your project. </p>
<p>Obfuscation shouldn’t be confused with encryption, and it certainly doesn’t offer the security of a strong encryption scheme. With encryption, you have some mathematical proof of security using some form of secret information. The bigger and harder to guess that secret is, the more secure the application. Obfuscation, on the other hand, is more like camouflage: it’s meant to hide the code from casual attempts at reverse engineering or <span epub:type="pagebreak" id="Page_265" title="265"/>bypassing the license restrictions. But once someone understands how the code has been obfuscated, they can always reverse the process. Going back to my previous example, if you examined the second string more closely, you may have realized that all I did was insert random characters between the letters of the phrase. Next, I replaced the spaces with a constant character, <code>b</code>. By reversing this process, replacing the even-numbered <code>b</code> characters with spaces and stripping every other character out, you can convert the jumbled string back to the original phrase. As if that weren’t bad enough, the part of the startup script that handles the de-obfuscation can’t be obfuscated itself, meaning the technique used is available to anyone who wishes to look for it. (If it could be obfuscated, you’d create a feedback loop as you’d need a de-obfuscator for the de-obfuscator.) To borrow a phrase used in the lock-picking world: “It’s good enough to keep honest people honest.” Depending on the level of obfuscation, this may only hinder a talented reverse engineer by a couple hours.</p>
<p>Although there are some obvious limitations, I wouldn’t completely dismiss PyArmor either. PyArmor may make a good addition if you plan to monetize the stand-alone package delivery method because it does add some control and monitoring to the process. You can’t guarantee your controls won’t be bypassed, but it certainly makes it less likely than a stand-alone application without obfuscation and licensing applied. Another potential use for PyArmor’s licensing is tracking the number of active users. Even if you don’t plan to monetize your project, having a license in place allows you to approximate the number of users by looking at which licenses have checked in (meaning the application was started). As your project gains popularity, you can use these estimates to gain investor interest or potentially sell your project to a larger SaaS provider.</p>
<h2 id="h1-502567c13-0005">Open Source Delivery</h2>
<p class="BodyFirst">There’s no better place to finish than with the option of open source delivery. By far the easiest method to deliver your project and to give back to the community is to openly license the source code for your project to everyone. By design, open source software licenses promote collaboration and sharing as they permit other people to make modifications to source code and incorporate those changes into their own projects. By hosting your code base on a public GitHub repository (or similar), you get the benefits of crowd-sourcing development, getting feedback from potential users, reducing hosting costs, and more. Open source projects promote collaboration from diverse perspectives. Different people from around the globe can come together and contribute. People have different and unique ways of solving problems, so including contributions from people with diverse backgrounds can push your project to a level of functionality you never would have achieved on your own, even with a traditional development team.</p>
<p>One common misconception is that “open source” automatically means you can’t monetize your application. This isn’t true at all! While it’s true that most open source projects aren’t started for money, maintaining a <span epub:type="pagebreak" id="Page_266" title="266"/>large open source project—Kubernetes, for instance—is a lot of work! It takes several full-time developers who probably want to get paid for their time, so open source projects will often spawn successful companies. Projects are often open-sourced in conjunction with a cloud delivery option to provide both a free and paid version. Companies will pay for these cloud-hosted versions to reduce the number of systems they have to maintain internally. Red Hat, the maintainer of one of the most popular Linux distributions for enterprise use, is one example of a large open source company that follows this model. While Red Hat continues to offer the open source version of many of its applications, it also offers paid customizations and remote support to maintain the business. In short, choosing to open-source your code often will reduce your stress and encourage a better result for your project, but you don’t have to sacrifice monetization. I highly recommend you research the open source route when considering delivery methods for your application. </p>
<h2 id="h1-502567c13-0006">Summary</h2>
<p class="BodyFirst">Deploying your application for general use can seem like a whole project in itself. As you’ve seen, there are several factors that should influence your choice of method. These include the number of users you plan to serve and whether you want to charge for access. As I said at the start of the chapter, you should start with the basic concept of the delivery platform in place when you begin your project. Once you’ve decided how to deliver your application, you can let the choice inform the rest of your development decisions, such as what storage options are available to your code. </p>
<p>At this point, you should have an idea of the available options and the positives and negatives of each. You can take these basics and learn more about the process that suits your needs best. Whatever method you choose, it’s important to remember to think from a user’s perspective as well as from a developer’s. Be kind to users and give them intuitive ways to install, manage, and remove your application. </p>
<p>The internet is filled with resources for learning about software deployment plans, ranging from the very simple to the exceedingly complex. There are also excellent books covering various deployment technologies like Docker and Kubernetes (<a class="LinkURL" href="https://bookauthority.org/books/new-continuous-delivery-books">https://bookauthority.org/books/new-continuous-delivery-books</a>). I recommend starting small and working your way up. If you’ve never used Git, jumping into a cloud deployment right away is going to lead to frustration. Start with something like PyPi, which will allow you to hone your repository management skills. Once you’re comfortable with each of the underlying pieces, you’ll be better equipped to tackle the large cloud deployment process. </p>
<p>And with that, we’ve come to the end of the book! If you’ve tackled all the concepts and projects, I congratulate you! I hope you feel that you understand the role that applied mathematics can play in your security tools. If you take anything away from this book, I hope it’s the idea that you can tackle seemingly complex research topics with only a basic knowledge of math and an understanding of programming. Topics such as facial recognition, privacy monitoring, and social network analysis may be getting all <span epub:type="pagebreak" id="Page_267" title="267"/>the headlines at the moment, but the number of open research problems in the broader security field is huge, and they would all benefit from a talented and dedicated researcher like you. If there’s a particular field that interests you, I encourage you to take the concepts you’ve learned and apply them to that field as well. The fields covered in the book all lend themselves incredibly well to multiple areas of interest, and when you mix and match them, you can achieve some very powerful analysis tools. </p>
<p>The scariest part of applying security to the real world, where a mistake could cost lives, is the need to make decisions in the face of uncertainty. Analysis tools like the ones presented in the previous chapters allow us to examine the world in different ways and to make the most informed decisions possible. You may not be able to remove uncertainty completely, but you can minimize its impact on yourself and those around you. Remember: security isn’t just a job or career path, but a way of understanding the world. The future of security applications lies in the accurate collection, interpretation, and response to data collected from our physical and digital environments to aid us in that understanding.</p>
</section>
</body>
</html>