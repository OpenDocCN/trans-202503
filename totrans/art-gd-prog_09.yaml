- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with Sound
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Sketch 71: Playing a Sound File'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One *displays* an image but *plays* a sound; why is that? Whatever the reason,
    Processing has no standard facility for displaying audio. It *does* have some
    libraries for that purpose, however, most importantly Minim. (We used a library
    in Sketch 50.)
  prefs: []
  type: TYPE_NORMAL
- en: Using Minim, this sketch will play an MP3 or WAV sound file using the standard
    PC sound interface. Adding to this, if the user presses the A key, the sound will
    move toward the left speaker, and if they press the D key (which is to the right
    of the A key), the sound will move toward the right speaker.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first statement in the program 1 indicates that we want to access the Minim
    library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we need to create a single instance of the Minim library. The Minim library
    is a class, and it contains functions that can load and play sound files. Define
    a variable named `minim` of type `Minim`, and initialize it in the `setup()` function
    3 as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now declare a sound player variable 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Assign it a sound file as read from an MP3 file using the `Minim` function
    `loadFile()` 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can play this file using the PC sound hardware by using the `play()` function
    5, a part of the `AudioPlayer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'To change the balance (pan) of the sound in stereo speakers, the user presses
    the A (left) and D (right) keys. Each key press adds a small value to or subtracts
    one from the `pan` variable, which is then used to set the balance 6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'For other effects, there are a variety of functions that control the sound
    display, including the getting and setting of pan/balance, gain, and volume: `getBalance()`,
    `getVolume()`, `getGain()`. Documentation for Minim can move around the web, but
    in 2022 it’s found at [http://code.compartmental.net/2007/03/27/minim-an-audio-library-for-processing/](http://code.compartmental.net/2007/03/27/minim-an-audio-library-for-processing/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 72: Displaying a Sound’s Volume'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sketch 71 does not have a very visually interesting display. Its display is
    auditory, and while that is in keeping with its primary function, the Processing
    language usually creates more graphical output. One obvious way to accomplish
    this is to display the volume of a sound visually, as numbers on a dial or, as
    in this sketch, as the height of vertical bars.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this sketch work, we must get numerical values for the sound that we
    read from the file. The `AudioInput` component class of `Minim` allows a connection
    to the current record source device for the computer. For this sketch to function
    properly, the user needs to set the source device to monitor the sound as it plays.
    For example, if the sound input is a file, we could use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Assuming this is true, the sketch uses a variable of the `AudioInput` type
    (named `in` 1) and initializes it using `getLineIn()` 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the variable `in` can access the functions belonging to `AudioInput`, which
    include the ability to get individual data values. Sound on a computer consists
    of sampled voltages that have been rescaled to a convenient range. Thus, an audio
    value is a number, normally between −1 and +1, that represents the volume. We
    can access each of the stereo channels: the left channel is `in.left`, and the
    right is `in.right` (these are of type `AudioBuffer`, which is just an array of
    real numbers). The `get()` function allows access to the numerical values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This gets the first value in the buffer, which could be positive or negative,
    so for display purposes it is better to use the value `abs(in.left.get(128))*2`
    4, which is simply the magnitude of the value shifted to the range 0 to 2\. Now
    this number can represent the height of a rectangle 6, proportional to the sound
    volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The same process works for both the left and right channels.
  prefs: []
  type: TYPE_NORMAL
- en: The total duration of a sound loaded into the variable player is `player.duration()`;
    the current position, assuming that it is playing, is `player.position()`. When
    the sound is over, `player.length() <= player.position()`, and the `Minim` specification
    says that it is important to close and stop `Minim` to ensure that resources are
    given back to the system (via `in.close(); minim.stop();` ). In the sketch, the
    `stop()` function 7 does this.
  prefs: []
  type: TYPE_NORMAL
- en: 'The sketch also displays a numerical value for the sound data. A real number
    potentially has a lot of digits, most of which are not really important. To print
    only two decimal places, as in the sketch, multiply the value by 100 and then
    convert it to an integer. This removes the remaining fractional part (all other
    digits to the right). Then convert this back to real and divide by 100 5:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Sketch 73: Bouncing a Ball with Sound Effects'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In movies, animations, theater, and computer games, a sound effect is (usually)
    a short piece of audio that indicates that something has happened. A telephone
    ringing, the smack of a bat hitting a baseball, and the splash of a stone falling
    into a lake are all examples of sound effects. This sketch will illustrate the
    use of a sound effect in a simple simulation.
  prefs: []
  type: TYPE_NORMAL
- en: Sketch 28 simulated a bouncing ball. It looks nice, but it would be better as
    an animation if a sound accompanied each bounce. Sound is an important cue to
    humans, and a sound effect lends realism to the graphics. It does not have to
    be accurate; it just has to be some click or bump noise that corresponds to the
    event. Beginning with the code from Sketch 28, we’ll add an `AudioPlayer` object
    from the Minim library to play a short MP3 file when the ball strikes a side of
    the window.
  prefs: []
  type: TYPE_NORMAL
- en: To create the sound effect, we’ll save the sound of a thump (such as a ball
    bouncing on the floor or a cup being set down on a table) using a PC microphone
    and a freely available sound editor/capture tool such as Audacity ([https://www.audacityteam.org/](https://www.audacityteam.org/))
    or GoldWave ([http://www.goldwave.ca/](http://www.goldwave.ca/)). This sketch
    assumes the sound is saved as *click.mp3*.
  prefs: []
  type: TYPE_NORMAL
- en: After the initialization of `Minim` 1, an `AudioPlayer` (the variable `player`)
    reads the MP3 file. When the ball strikes a side of the window, as detected by
    the functions `xbounce()`2 and `ybounce()` 5, the ball changes direction and we
    play the sound with a call to `player.play()` 3.
  prefs: []
  type: TYPE_NORMAL
- en: We have to rewind the sound file each time before it is played to make sure
    it starts from the beginning. The `rewind()` 4 function within `AudioPlayer` does
    this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 74: Mixing Two Sounds'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the process of sound mixing, we assign each of a number of sound sources
    to different output levels or volumes. In live music concerts, this makes the
    sound of each instrument audible at the proper volume level. We also do this when
    recording multiple sources of sound, such as microphones, guitars, and other instruments,
    which need to have their volume levels adjusted so that no one component overwhelms
    the total. Mixers have been around for a long time, and most have sliding controls
    to adjust volume levels of multiple sound signals. This sketch will use the slider
    control developed in Sketch 43 to adjust the volume of two different sound files.
  prefs: []
  type: TYPE_NORMAL
- en: The sketch begins by declaring two `AudioPlayer` variables 1, one for each sound,
    loading the sound files 2, and starting to play them both 3. Next we create two
    slider controls; one is control A, having position and control variables beginning
    with “a” (`asliderX`, `asliderY`, `avalue`) and the other is control B (`bsliderX`,
    `bsliderY`, and so on). The value of slider A is used to set the volume of the
    first of the sound files being played (by `playera`), and slider B controls the
    volume of the other (`playerb`).
  prefs: []
  type: TYPE_NORMAL
- en: 'We set the output level by calling the `Minim` function `setGain()`. This function
    has a parameter that represents the value of the gain (proportional to volume).
    The units on gain are decibels (dB) and they begin at −80 and end at +14 for a
    total range of 94 dB units. The total range of the slider values is 1,000\. Thus,
    the gain for `playera` is set using the following call 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If the slider value is at the minimum of 0, the gain will be 0/1,000 * 94 −
    80 = 0 − 80 = −80\. If the slider value is at the maximum of 1,000, the gain will
    be 1,000/1,000 * 94 − 80 = 94 − 80 = 14\. That the gain values have the correct
    output for the extreme values supports the idea that the mapping is correct. The
    dB scale is logarithmic, though, so this is an approximation of the truth.
  prefs: []
  type: TYPE_NORMAL
- en: When the sketch is executing, the two sound files will play. Sliding the top
    slider right will increase the volume of the *sounda.mp3* file, and sliding the
    lower slider will control the volume of the *soundb.mp3* file. The idea is to
    find relative levels that sound right.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 75: Displaying Audio Waveforms'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most computer-based sound editors display a graphical rendering of the audio
    signal and allow the user to “grab” parts of it with the mouse and move or delete
    them. This graphical display is actually a plot of audio volume versus time. Some
    music players display such a plot in real time, as the music is playing. That’s
    exactly what this sketch will do. It draws the plot of whatever sound the computer
    is playing.
  prefs: []
  type: TYPE_NORMAL
- en: Drawing this requires the ability to get the sound data as numbers in real time.
    A bit of error does not matter, because this is not a scientific tool, so it’s
    possible to use some of the code from Sketch 72, which also displayed an audio
    visualization. Here we will fill a sound buffer and then play it as sound data
    until the data is finished.
  prefs: []
  type: TYPE_NORMAL
- en: 'Audio is represented as a set of consecutive numerical values that can reasonably
    be stored in an array (a buffer). There are usually two channels (stereo), and
    any value from a buffer can be retrieved using the `in.left_get()` or `in.right_get()`
    functions, specifying which sample is wanted. For example, the program gets a
    data point from the left channel using a call to `left_get()` 3 and uses this
    value to represent all levels in the current buffer. This is just *one* data point
    from many samples, and it is possible to specify the buffer size when the `getLineIn()`
    call is made. The system plays sound from this buffer and refills it whenever
    it needs more data. We specify a size of 1,024 samples per buffer 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If the window is 512 pixels wide, there is 1 pixel for every 2 samples, its
    height being the value retrieved using the call to `get()`. Assuming that the
    value of a data element is between −1 and +1, we draw the 1,024 data points as
    a line from (`i, datai`) to (`i+1, datai+1`) for all `i` between 0 and 1,023 by
    twos 2. This is illustrated in [Figure 75-1](#figure75-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![f075001](Images/f075001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 75-1: Scaling samples and plotting them as lines'
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: We do this in the `draw()` function so it will refresh every 10th of a second
    and display an animated version of the audio. We scale the data by multiplying
    by 100, giving a total height of 200 pixels, and then translate it to the vertical
    center of the window by adding this value to the data point.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 76: Controlling a Graphic with Sound'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PC-based music players frequently offer a set of visualizers that present abstract
    moving images that change in coordination with the music, as shown in [Figure
    76-1](#figure76-1). Sketch 75 is a visualizer that displays the actual signal,
    which can be useful for signal analysis and editing, but the purpose of music
    player visualizations is to entertain by presenting interesting images. This sketch
    represents one attempt to implement such a visualizer.
  prefs: []
  type: TYPE_NORMAL
- en: '![f076001](Images/f076001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 76-1: An example visualizer'
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways to control images using music, but the underlying idea is
    to pull numbers from the sound data and use them as parameters to some graphical
    model so the display reacts to the actual sound. Beyond the raw sound data points
    described in the previous sketch, we want to measure values that indicate changes
    in the sound so that the display is dynamic. The difference between two consecutive
    values is one measure. These numbers would tend to be similar to each other, so
    two values at a fixed time from each other might give a better range of numbers.
    Another idea would be to use the difference between the left and right channels.
    More complicated measurements include the difference between a data value and
    the average for a short time or the difference between the maximum and minimum
    values over a time period.
  prefs: []
  type: TYPE_NORMAL
- en: Once we decide which measurements to use, what will we use the values for? This
    depends on the visual effect we desire. They could represent x, y positions, colors,
    speed, or even shape parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'This sketch will use ellipses as the basis for the display. The data from the
    left and right channels of the current buffer will define the width and height
    parameters of an ellipse to be drawn at the center of the screen. The size of
    the ellipse will increase by five pixels for each frame, so it will grow from
    the center outwards 2. The color of the ellipse will be related to the difference
    between the current left data value and the corresponding left data value from
    the previous buffer 4; this means that color is a function of variation over time.
    By drawing each ellipse with a transparency (alpha) value of 30, we can make the
    colors blend into each other. Because we’re using transparency, we should display
    the largest ellipses first, and then smaller ones, or the smaller ones could be
    overwhelmed by ones drawn above them. We must maintain a set of parameters for
    these ellipses so that we can display all of them correctly each iteration, and
    we do this by saving them in a set of arrays: `colors`, `hsize`, and `vsize` for
    the ellipse color and size.'
  prefs: []
  type: TYPE_NORMAL
- en: Start the program and then play a sound file with another program on your PC.
    The sketch extracts the numeric parameters from the sound 3 and displays the corresponding
    ellipses each frame 1. The visual is surprisingly interesting given the simplicity
    of the method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 77: Positional Sound'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because humans have two ears, we can roughly identify the location of a sound.
    We do this partly by using the difference in time of arrival and the volume of
    the sound at each ear. A sound is louder in the ear that is nearest to the source,
    and we can use this fact to simulate positional sound using a computer. In this
    sketch, we’ll play a sound and let the user select a listening position in the
    center of the sketch window. The user can move about, changing the angle they
    are facing with the A and D keys and stepping forward and backward using W and
    S.
  prefs: []
  type: TYPE_NORMAL
- en: When the user is facing exactly toward or away from a sound source, the loudness
    in each ear should be about equal. When they are facing so that the left ear is
    pointing to the source, the volume in the left ear is loudest and in the right
    ear it is the quietest, and vice versa when the right ear is facing the sound.
    With this in mind, we can map volumes from loudest in the left to equal to loudest
    in the right as a function of the way the listener is facing.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine an angle made between the listener’s position, the source position,
    and the x-axis, labeled θ in [Figure 77-1](#figure77-1). The angle that the listener
    is facing combines with the angle between the listener and the object to determine
    how loud the sound will seem in each ear, and thus determines how loud we should
    play the sound from each speaker to simulate positional sound.
  prefs: []
  type: TYPE_NORMAL
- en: '![f077001](Images/f077001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 77-1: Geometry of positional audio'
  prefs: []
  type: TYPE_NORMAL
- en: 'The angle θ is determined using trigonometry as the arctangent of the difference
    in x over the difference in y 3, or the following, where the `atan2` function
    handles the case where the angle is vertical:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The difference between the facing angle and θ (theta) defines an angle that
    controls the volume between two stereo channels being played, via the `setPan()`
    function. A parameter of −1 means full left channel, 0 means a balance, and +1
    means full right. A bit of fiddling on paper shows that a 0-degree angle to the
    source should correspond to a pan of 0, 90 degrees has a pan of −1, 180 degrees
    has a pan of 0, and 270 degrees has a pan of +1\. These are the extreme points
    of the function `-sin(facing-theta)`, so this value is passed to `setPan()`.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, the sound file (a simple tone) starts playing 1; the sound source
    is initially located at (200, 200) 2, and the user is initially at (300, 200)
    but can rotate and move. The volume of the sound played in each speaker is set
    by determining the angle θ, computing `delta = facing-theta`, and setting the
    pan to `–sin(delta`) 4.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 78: Synthetic Sounds'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This sketch will implement a small sound synthesizer. It will only have eight
    keys, more like a child’s toy piano, but it will be functional and can serve as
    the basis for more complex sound synthesis projects.
  prefs: []
  type: TYPE_NORMAL
- en: '`Minim` provides a type (a class) named `AudioOutput` that allows us to display
    signals, not just sound files, on the PC hardware. It allows the playing of a
    note, although not exactly musical notes as normally understood. A note in this
    context is a digital audio signal having a specific frequency.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The name of the `AudioOutput` variable in the sketch is `out`, and it is initialized
    1 as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This call allocates a new instance of `AudioOut` that is accessible from the
    variable `out`. To play a note, call the `playNote()` function 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This sends a sine wave with a frequency of 440 Hz (the musical note A) to the
    sound card. `playNote()` can be called with nearly any frequency, because the
    “notes” are just snippets of a sine wave.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, the `AudioOutput` object likes to impose a specified duration
    on a note, so the note plays for what the system believes to be a single unit
    of time. To imitate a musical instrument played by a human who can vary the duration,
    we need to call `playNote()` with more parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In this example, 0 is the time until the note is to be played (immediately),
    1,000 is the duration, and the final parameter is the frequency; 1,000 units is
    a long time.
  prefs: []
  type: TYPE_NORMAL
- en: The sketch displays a simple piano image with labeled keys. When the user clicks
    the mouse on one of the graphical piano keys, the program plays that note 2; the
    value of the x position of the mouse tells us what the note is (in `mousePressed()`).
    When the mouse button is released, the program creates a new `AudioOutput` 3 so
    that the old note stops playing and a new one can start (in `mouseReleased()`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Sketch 79: Recording and Saving Sound'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This sketch captures the audio currently playing on the computer and saves it
    in a file in *.wav* format. This would permit recording sound from Skype calls,
    websites, and podcasts, to name a few.
  prefs: []
  type: TYPE_NORMAL
- en: In Sketches 75 and 76 we used `Minim` and an `AudioInput` object to access the
    currently playing sound for visualization. In this case, the next step is to create
    an `AudioRecorder`, which takes as a parameter an input from which we can collect
    sound; that is, the `AudioInput` object connected to the currently playing sound.
  prefs: []
  type: TYPE_NORMAL
- en: 'An `AudioInput` has three functions (methods) of importance:'
  prefs: []
  type: TYPE_NORMAL
- en: '`beginRecord()` Start saving audio samples.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`endRecord()` Stop saving the audio samples.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`save()` Store the saved samples as an audio file.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How much audio data we can save depends on the memory available on the computer.
  prefs: []
  type: TYPE_NORMAL
- en: The sketch opens a window and displays the playing sound signal as in Sketch
    75\. If the user types the R character 2 (handled by `keyReleased()`), we call
    `beginRecord()` and start saving data. When the user types Q 3, we call `endRecord()`
    and the recording stops. If the user types S, we call `save()` 4.
  prefs: []
  type: TYPE_NORMAL
- en: 'We specify the file used to save the data as a parameter on the creation of
    the `AudioRecorder` 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Here, `input` is the already existing `AudioInput` object, *processing.wav*
    is the file where we’ll save the sound data, and the final parameter represents
    whether or not the recording is buffered, which is to say whether the data is
    saved in memory or written directly to the file. If it’s not buffered, the system
    opens the file when recording begins. Otherwise the system opens the file when
    we write the data.
  prefs: []
  type: TYPE_NORMAL
- en: A small change to this code would allow the user to save to a different file
    each time they start and stop recording. This could be useful for voice recording,
    such as reading scripts or reading books to tape.
  prefs: []
  type: TYPE_NORMAL
