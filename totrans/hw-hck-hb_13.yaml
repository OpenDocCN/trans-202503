- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'No Kiddin’: Real-Life Examples'
  prefs: []
  type: TYPE_NORMAL
- en: '![](image_fi/book_art/chapterart.png)'
  prefs: []
  type: TYPE_IMG
- en: You’ve learned about embedded systems, and you’ve learned about embedded attacks.
    You might still feel like the hands-on attack details for real systems is missing.
    This chapter will help bridge the gap between laboratory examples and real life,
    and we’ll provide examples of both fault injection and power analysis attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Fault Injection Attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fault injection attacks have probably been used the most in (published) real-world
    attacks of products (compared to power analysis). Two high-profile examples you
    might have heard about are attacking the Sony PlayStation’s hypervisor and the
    Xbox 360 via the “reset glitch.” Gaming systems are interesting targets because
    they typically have some of the best security in consumer-level equipment. During
    the same timeframe that these PlayStation and Xbox 360 attacks were occurring,
    most other consumer electronics (such as routers and TVs) had no boot signing
    and required no advanced attacks to exploit. You can also explore details on attacks,
    such as the Nintendo Switch attack and beyond, if you want to see how device security
    has been improving.
  prefs: []
  type: TYPE_NORMAL
- en: PlayStation 3 Hypervisor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Game consoles are always going to be a target, as there is a motivated population
    interested in attacking them. Gamers may be looking to run pirated versions of
    games, may be interested in modifying the games themselves (or cheating within
    the games), or they may want to run custom code on a fairly widely available and
    powerful platform. This last reason was especially the case with the Sony PlayStation
    3, which had a unique Cell microprocessor that lent itself well to multiprocessing.
    Although now you would plan on just building an algorithm to put onto your graphics
    processing unit (GPU), the field of GPU computing was not as easily accessible;
    for example, CUDA was released in June 2007 and OpenCL in August 2008, but clusters
    of PlayStation 3 consoles were tested as early as January 2007.
  prefs: []
  type: TYPE_NORMAL
- en: The PlayStation release supported running Linux directly. Linux itself was running
    under control of the PlayStation hypervisor, which prevented the user from accessing
    anything unintended (such as secure key storage). Attacking the PlayStation effectively
    meant finding a way around the hypervisor, as only then could one probe into the
    rest of the system to recover critical secrets. After initial work on breaking
    the PlayStation 3 occurred, Sony announced it no longer would support running
    Linux on future PlayStation updates due to the security risks. This announcement
    had the side effect of giving hackers added incentive to fully break the PlayStation
    3, since running Linux on an updated PlayStation 3 now required a successful attack.
  prefs: []
  type: TYPE_NORMAL
- en: What was this attack? We’re actually going to concentrate on the “initial work,”
    which occurred thanks to George Hotz (GeoHot) and wasn’t the final exploit on
    the PlayStation, but it remains a well-known attack, so it’s worth understanding
    as an example of a fault attack.
  prefs: []
  type: TYPE_NORMAL
- en: To understand the attack, we first have to look at some details on how the Linux
    kernel gets access to memory. To do so, the Linux kernel requests that the hypervisor
    allocate a memory buffer. The hypervisor duly allocates the requested buffer.
    The kernel also requests that a number of references be made in the hash table
    (HTAB) page index, so there are a number of references to this same block of memory.
    You can see an abstract view of the memory at this point in [Figure 13-1](#figure13-1),
    step 1.
  prefs: []
  type: TYPE_NORMAL
- en: '![f13001](image_fi/278748c13/f13001.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-1: The five steps of PS3 pwnage'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 13-1](#figure13-1) shows an abstract view of the memory contents throughout
    the attack. HTABs are “handles” that give the kernel access to a particular memory
    range, as indicated by the arrows. Gray cells are accessible only to the hypervisor,
    whereas white cells are accessible to the kernel.'
  prefs: []
  type: TYPE_NORMAL
- en: Back to the attack. Everything until now is nice and safe. The kernel has read/write
    access to a block of memory, but the hypervisor is well aware of this memory and
    ensures that no out-of-bound reads or writes occur. The attack comes when we request
    that the hypervisor deallocate the memory by closing all those references made
    through the HTAB in step 1 of [Figure 13-1](#figure13-1). At this point in time,
    we insert a glitch onto the PS3 memory bus with the goal of failing one of the
    deallocations. We’ll explain in a second why this is important, but for now note
    that the attack works because the deallocation is never “verified.” If the pointer
    to what we were supposed to deallocate on the hardware is corrupted, the hypervisor
    won’t know about this.
  prefs: []
  type: TYPE_NORMAL
- en: The physical fault comes from a logic-level signal inserted onto the memory
    data bus (that is, DQx pins). The original demo used a field-programmable gate
    array (FPGA) board to generate a short (~40ns) pulse, but later people re-creating
    this also demonstrated it with microcontrollers to generate similar pulses (in
    the 40 to 300ns range). As many deallocations are forced, the fault can simply
    be manually triggered. Specific timing isn’t needed since only one of the deallocations
    needs to fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'This brings us to step 2 in [Figure 13-1](#figure13-1): the kernel has access
    to a piece of memory that was not actually invalidated in the HTAB. The hypervisor
    isn’t aware of this, as it thinks it safely deallocated the memory and removed
    all references to it.'
  prefs: []
  type: TYPE_NORMAL
- en: The final stage of the attack is to generate a new virtual memory space that
    overlaps with this chunk of memory the kernel can read/write to. This virtual
    memory space will also include an HTAB for the page map within this virtual space,
    but if we are lucky, that HTAB will be in a chunk of memory we can read/write
    from, as shown in step 3 in [Figure 13-1](#figure13-1). If we can write to the
    HTAB, this means we can map memory pages into our space, which normally only the
    hypervisor should be able to do. This would bypass most protections since the
    memory pages appear to be passing through the valid HTAB, and the kernel itself
    is reading/writing a memory address that it is allowed to access.
  prefs: []
  type: TYPE_NORMAL
- en: The final step in achieving full read/write access is to remap the original
    HTAB so we can read/write to this table directly, as shown in step 4 in [Figure
    13-1](#figure13-1). By switching back to the original memory space (not the virtual
    memory space created for the attack), we can now write to the main HTAB to remap
    arbitrary memory pages into our buffer. Since we have read/write access to this
    buffer, we can get read/write access to any memory locations, including the hypervisor
    code itself, as shown in step 5 in [Figure 13-1](#figure13-1).
  prefs: []
  type: TYPE_NORMAL
- en: The vulnerability can occur because the hypervisor became decoupled from the
    HTAB status, so it isn’t aware the kernel still has read/write access to the newly
    created virtual memory space. It’s also helped by the hypervisor allowing the
    kernel to discover the actual memory address of that initial buffer by standard
    API calls (which helps when creating the virtual memory space in getting the HTAB
    overlap).
  prefs: []
  type: TYPE_NORMAL
- en: If you’re interested in more details, you may be able to find a mirror of the
    original code posted by Hotz. Due to a lawsuit, Hotz stopped any further work
    on Sony products. You may also find useful a series of blog posts by xorloser
    that include both the original details and some updated versions of the attack
    tools (called XorHack). These blog posts provide complete examples of the attack
    if you want the gory details.
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway is that with fault attacks, one can use a variety of methods to
    apply the fault. The attack may not be limited to the voltage, clock, electromagnetic
    (EM), and optical fault injection methods, for example. In this case, the memory
    bus itself is faulted, which may be a more exposed target than attempting to insert
    a fault onto the power supply of a complex device. The fault injection device
    can be a simple microcontroller, and it even works with an Arduino used to pulse
    the appropriate memory bus pin.
  prefs: []
  type: TYPE_NORMAL
- en: The other takeaway is that clever target preparation makes life much easier.
    Although the attack would work with careful timing to fault a single HTAB entry,
    it’s much easier to force a massive number of entries to be modified at once.
    Doing so allows rather loose timing on the fault injection, as the attack is designed
    such that only a small number of successes would be needed.
  prefs: []
  type: TYPE_NORMAL
- en: Xbox 360
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Xbox 360 is another game console that has been successfully attacked with
    fault injection. This work is primarily credited to GliGli and Tiros, with previous
    reverse engineering work done by various users (see [https://github.com/Free60Project](https://github.com/Free60Project)
    for full credits for the Reset Glitch Hack, and see the detailed hardware on [https://github.com/gligli/tools/tree/master/reset_glitch_hack](https://github.com/gligli/tools/tree/master/reset_glitch_hack)).
    [Figure 13-2](#figure13-2) shows a high-level overview of the attack steps.
  prefs: []
  type: TYPE_NORMAL
- en: The Xbox 360 has a ROM-based first-stage bootloader (1BL) that loads the second-stage
    bootloader (2BL, also referred to as CB on the Xbox) stored in NAND flash. The
    1BL verifies the RSA signature of the 2BL before loading it. Finally, 2BL loads
    a block called CD that includes the hypervisor and kernel—basically meaning we
    would ideally prefer to load our own CD block, as then we don’t even need to exploit
    the hypervisor since we’d simply be running our own code entirely.
  prefs: []
  type: TYPE_NORMAL
- en: The 2BL block will verify the expected SHA-1 hash for the CD block before running
    this code. Because the 2BL block was checked with an RSA signature, we can’t modify
    the SHA-1 hash that the 2BL block expects for the CD block without being detected.
    If we had an SHA-1 hash collision, we could load our own (unexpected) code, but
    there is a much easier way forward.
  prefs: []
  type: TYPE_NORMAL
- en: The SHA-1 will be calculated on the CD code and then compared with something
    like `memcmp()`. We know such operations are susceptible to fault attacks, so
    we could look to insert a glitch at this point in time.
  prefs: []
  type: TYPE_NORMAL
- en: To simplify the timing, some hardware features of the Xbox 360 are used. In
    particular, the main central processing unit (CPU) has an exposed pin that can
    be used to bypass the phase-locked loop (PLL). The result is the CPU runs at a
    much slower 520 kHz. This pin has been labeled CPU_PLL_BYPASS in the examples,
    but keep in mind, these pin names are not based on public documentation such as
    a datasheet. It’s possible this pin is actually something like a feedback loop
    for the PLL, but grounding it has the same effect as if it were a bypass enabled
    for the PLL.
  prefs: []
  type: TYPE_NORMAL
- en: '![f13002](image_fi/278748c13/f13002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-2: Sequence of a successful fault attack on the Xbox 360 “fat” version'
  prefs: []
  type: TYPE_NORMAL
- en: With the CPU now running at a slower speed, it is easier to fine-tune the fault
    injection timing. In this case, the fault injection method is a short spike on
    the reset line of the CPU. Rather than reset the system, this fault causes the
    SHA-1 comparison to report a successful comparison, even if the SHA-1 hash doesn’t
    match.
  prefs: []
  type: TYPE_NORMAL
- en: If the reset line fault isn’t successful, one might expect other avenues, such
    as voltage or electromagnetic fault injection, might be successful. But like the
    PlayStation attacks, the goal is to develop very simple tools such that the attack
    is easy to replicate. Sending simple logic-level signals onto the reset pin is
    something one can do with a complex programmable logic device (CPLD), a field-programmable
    gate array (FPGA), or a microcontroller.
  prefs: []
  type: TYPE_NORMAL
- en: And the modchips are doing exactly that. These chips “weaponize” the fault vulnerability.
    They use details of the power-on self-test (POST) system that reports the boot
    progress. By tying into the POST reporting, it’s possible to know almost exactly
    when to trigger the slow clock operation and then inject the reset glitch. Like
    any fault attack, the reset glitch will not have a perfect success rate. If the
    glitch is unsuccessful, the modchip detects it, resets the system properly, and
    simply tries again. This process allows loading of an unsecured binary in 30–60
    seconds in most cases.
  prefs: []
  type: TYPE_NORMAL
- en: Again, clever preparation has turned a relatively complex target into one that
    can be attacked with basic electronics. In this case, rather than forcing a number
    of vulnerable operations to occur, the target is slowed down considerably. Later
    revisions of the hardware did not have the same test point but instead exposed
    the clock generator on the I2C bus. By tying into the I2C bus, an attacker could
    slow down the main CPU with similar results.
  prefs: []
  type: TYPE_NORMAL
- en: Having external control over the clock frequency may be possible, even for complex
    targets. For example, a target may use a PLL to multiply up a crystal frequency;
    replacing a 12 MHz crystal with a 1 MHz oscillator might make the main CPU run
    at 66.7 MHz instead of the targeted 800 MHz. Whether this is successful is far
    from a sure thing, however. The PLLs and oscillators themselves have limits (they
    may not operate that slowly), external parts such as DRAM will have upper and
    lower frequency limits (DRAM chips have minimum and maximum refresh times), and
    the CPU may detect frequency deviation and shut itself down to prevent attacks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Xbox 360 reset glitch shows that time spent “exploring” a target may be
    useful in finding vulnerabilities that are exploitable at scale. In this case,
    reaching a reliable fault attack combines several observations that alone might
    not have been an obvious attack vector: the boot stages are known to an observer
    in real time; a pin on the CPU allows running at a much slower speed, and short
    glitches on the reset pin (at least when running very slowly) do not correctly
    reset the chip, but instead insert faults.'
  prefs: []
  type: TYPE_NORMAL
- en: Power Analysis Attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The fault injection attacks demonstrated in the previous section were used to
    achieve temporary privileges beyond what the security architecture was supposed
    to permit (allowing loading of unsigned firmware, for example). Although fault
    injection can be about information disclosure through a memory dump or key disclosure
    through differential fault analysis, it is often about gaining privileges to then
    continue the attack. By comparison, power analysis is almost entirely concerned
    with revealing sensitive information, such as encryption keys. The difference
    is that a successful power analysis attack may provide you with the “keys to the
    kingdom.” These keys can make it impossible to discern an attacker from a legitimate
    owner or operator, and they may allow scaling without the further need of a hardware
    attack.
  prefs: []
  type: TYPE_NORMAL
- en: Philips Hue Attack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Philips Hue bulbs are smart lights that allow various settings to be controlled
    remotely by the owner. These lights communicate with the Zigbee Light Link (ZLL),
    which runs over a very constrained wireless network protocol (IEEE 802.15.4).
    Here we present part of “IoT Goes Nuclear: Creating a ZigBee Chain Reaction,”
    by Eyal Ronen et al. This work details recovering Philips Hue firmware encryption
    keys. After finding a bug, the authors also managed to bypass the “proximity test,”
    which these lightbulbs normally use to protect them from being disassociated from
    their network by an attacker more than about 1 meter away. This bug and proximity
    test bypass allow an attacker to create a worm that disassociates a victim bulb
    from the network within full Zigbee range (30–400 meters, depending on conditions)
    and remotely installs the wormed firmware, after which the now-infected bulb starts
    attacking other bulbs. Power analysis is used to compromise the (global) firmware
    encryption and signing key.'
  prefs: []
  type: TYPE_NORMAL
- en: The Zigbee Light Link
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: ZLL is a specific version of Zigbee (not the same as regular Zigbee or Zigbee
    Home Automation) that, like Zigbee, uses a low-power wireless protocol called
    IEEE 802.15.4\. ZLL has a simple method of letting a new device, such as a bulb
    you just purchased, join the network.
  prefs: []
  type: TYPE_NORMAL
- en: This joining process relies on a fixed master key to transfer the unique network
    key to the new bulb, and the device will be connected to a network with the unique
    key. The shared master key is no longer in use in the network once the unique
    key is transferred, as the master key was always at risk of being leaked. The
    network owner would have to put the network in a mode that allows new devices
    to join, so new devices cannot be added without the owner’s knowledge. This explanation,
    however, doesn’t describe how we solve the problem of replacing a bridge that
    has died, or if a user needs to move a bulb from one network to another.
  prefs: []
  type: TYPE_NORMAL
- en: Bypassing Proximity Checking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For scenarios where the unique network key needs to change, we come into the
    second portion, a special “Reset to Factory New” message, which allows someone
    to de-authenticate a bulb from an existing network such that it can now join a
    different network. To perform this step, you needed to be physically close (~1
    meter range). The ZLL master key (as you might expect) was leaked, meaning anyone
    could send those messages.
  prefs: []
  type: TYPE_NORMAL
- en: The proximity check is normally done by rejecting messages less than a certain
    signal strength. Although it’s possible to use high-power radio transmitters to
    fake the radio distance and reset devices from a longer range, doing so isn’t
    “wormable,” as the Hue transmitter itself isn’t strong enough. A wormable solution
    presented itself via a firmware bug and some compatibility requirements. First,
    a crafted “Reset to Factory New” message is sent to the victim. It’s designed
    to exploit the firmware bug such that the proximity test is bypassed. After the
    factory reset, the victim actively starts searching for Zigbee networks. The details
    are in the paper; here we focus on the power analysis part of the attack.
  prefs: []
  type: TYPE_NORMAL
- en: Firmware Updates on Hue
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now we have reached the stage where a device could be forced to join a new,
    attacker-controlled network, at which point you could send a firmware update request.
    The real question is, what is the actual format of the firmware update file and
    how can we send one ourselves? At this stage, we reset your vision of the attack
    setup and return to a legitimate Philips Hue lamp.
  prefs: []
  type: TYPE_NORMAL
- en: The Philips Hue lamps have the ability to perform a firmware update. By standard
    reverse engineering techniques, along with just looking at sample implementations
    of Zigbee over-the-air (OTA) update mechanisms posted as part of reference designs,
    we can learn how it works. When a bulb needs a firmware update, it downloads the
    file from the bridge device (which previously downloaded it from a remote server)
    into an external SPI flash memory chip. The actual OTA download can take some
    time (often at least an hour), as only small amounts are sent in each packet.
    If the network is in a busy wireless environment or the bulb is at the edge of
    radio range, this time can be extended considerably.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than attempt to sniff an update from this slow OTA interface directly,
    we can look at what’s happening to the SPI chip, which provides us with an “update-ready”
    SPI flash image. If we want to trigger an update on a given bulb, we can just
    write this SPI image to the SPI flash chip, and the bulb will perform the actual
    reprogramming of itself. This programming is initiated by a byte in the SPI flash
    image that indicates the bulb is ready for an update. On boot, the bulb checks
    the value of this byte and triggers the programming, if indicated. This programming
    mechanism also means that if you interrupted the reprogramming phase by turning
    the bulb power off, on the next boot, the bulb would automatically restart the
    reprogramming step.
  prefs: []
  type: TYPE_NORMAL
- en: Getting Firmware Keys with Power Analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: AES-CCM is used for encrypting and authenticating the firmware file (the AES-CCM
    specification is available in IETF RFC 3610), so we cannot simply upload any forged
    image. We first need to extract the key. To do this, the SPI flash chip becomes
    our “input” to the encryption algorithm that we can break with power analysis.
    In this case, CCM makes things a little trickier than you might assume at first
    guess. We no longer have a direct input to each of the encryption modes, as AES-CCM
    uses AES-CTR mode along with AES-CBC. [Figure 13-3](#figure13-3) gives an incomplete
    overview of CCM, focused only on what we need for the attack.
  prefs: []
  type: TYPE_NORMAL
- en: 'The top row of AES blocks are AES in CTR mode: an increasing counter is encrypted
    to obtain 128-bit chunks of stream cipher (*CTR*[*m*], 8). This is used to decrypt
    the ciphertext using a simple XOR operation (9). To create the authentication
    tag, the bottom row of AES blocks’ ciphertext is being XOR’d to the input of the
    next block (3, 5), which constitutes the cipher block chaining (*CBC*[*m*], 2,
    4). We left out some pieces of how the authentication tag is precisely calculated,
    but that’s irrelevant for the attack.'
  prefs: []
  type: TYPE_NORMAL
- en: '![f13003](image_fi/278748c13/f13003.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-3: All you need to know about AES-CCM for the attack'
  prefs: []
  type: TYPE_NORMAL
- en: How do we attack CCM using power analysis? Going after AES-CTR is not an option,
    since we don’t know the input (7, because of the unknown IV), and we don’t know
    the output either, as that is the cipher stream, which is never accessible (8).
    On the AES-CBC, we also cannot perform a vanilla CPA; the input is the decrypted
    firmware (9, which we don’t know), and the output of the AES-CBC (2, 4) is never
    accessible. However, Ronen et al. describe how to perform a clever key transformation
    (like we did in Chapter 12) that allows obtaining the key from the AES-CBC (1).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start at the top, with the ciphertext *CT*. We split that into 128-bit
    blocks, *CT*[*m*], where *m* is the block index. AES-CTR decryption is a stream
    cipher, and we’ll write the stream (8) as *CTR*[*m*] = `AES`(*k*, *IV*[*ctr*]
    || *m*), where || is concatenation of bits, so we can write the *PT* (9) coming
    out of it as *PT*[*m*] = *CT*[*m*] ⊕ *CTR*[*m*].
  prefs: []
  type: TYPE_NORMAL
- en: The *IV*[*ctr*] in CCM consists of a few fields, but basically the nonce is
    the big unknown to us at this point. For simplicity, we’ll just say we don’t know
    *IV*[*ctr*] (for now).
  prefs: []
  type: TYPE_NORMAL
- en: Next, AES-CBC is used to encrypt *PT*[*m*], generating the authentication tag.
    We can write output block *m* of CBC (2, 4) as *CBC*[*m*] = `AES`(*k*, *PT*[*m*]
    ⊕ *CBC*[*m–1*]), with block *m* = *0* defined using *CBC*[*-1*] = *IV*[*mac*].
    We can substitute *PT*[*m*]to get *CBC*[*m*] = `AES` (*k*, *CT*[*m*] ⊕ *CTR*[*m*]
    ⊕ *CBC*[*m–1*]).
  prefs: []
  type: TYPE_NORMAL
- en: So far so good, although everything in that formula is unknown except for the
    *CT*. In a regular AES-ECB power analysis attack, we assume we at least know the
    plaintext or the ciphertext, and thus we can recover *k*. The problem with any
    of the preceding AES functions is that we don’t know the input and we don’t know
    the output.
  prefs: []
  type: TYPE_NORMAL
- en: The cleverness comes in at this point. In AES, `AddRoundKey`(*k, p*) is just
    *k* ⊕ *p*, meaning we can rewrite `AddRoundKey`(*k*, *p* ⊕ *d*) = `AddRoundKey`(*k*
    ⊕ *p*, *d*). This means if *p* is unknown and fixed, we can just consider it to
    be part of a transformed key *k* ⊕ *p*. If we control *d*, we can do a CPA attack
    to recover *k* ⊕ *p*.
  prefs: []
  type: TYPE_NORMAL
- en: In our CCM case, we can’t attack `AddRoundKey`(*k*, *CT*[*m*] ⊕ *CTR*[*m*] ⊕
    *CBC*[*m–1*]), but we can attack `AddRoundKey`(*k* ⊕ *CTR*[*m*] ⊕ *CBC*[*m–1*],
    *CT*[*m*]), because we control *CT*[*m*]! Assuming the target leaks, we can use
    *CPA*[*a*] (see [Figure 13-4](#figure13-4)) to find the transformed key *k* ⊕
    *CTR*[*m*] ⊕ *CBC*[*m-1*], which in itself isn’t useful. This transformed key
    allows us to calculate all intermediate data until the second `AddRoundKey`(*k*,
    *p′*). This second `AddRoundKey` again uses *k*, which we don’t know. However,
    since we know the transformed round key and *CT*, we can calculate *p′*. We can
    now apply a vanilla *CPA*[*b*] attack using *p′* to recover *k* from the second
    round of AES.
  prefs: []
  type: TYPE_NORMAL
- en: '![f13004](image_fi/278748c13/f13004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13-4: Two CPA attacks: one on the transformed key and one on the regular
    key'
  prefs: []
  type: TYPE_NORMAL
- en: Once we have *k* (1 in [Figure 13-3](#figure13-3)), we have a few more steps
    to go. Note that we still don’t have *PT* or any of the IVs. However, *k* allows
    us to finish the “modified” AES calculation of [Figure 13-4](#figure13-4) to obtain
    the *CBC*[*m*] blocks 2. This block we can now decrypt to get *CT*[*m*] ⊕ *CTR*[*m*]
    ⊕ *CBC*[*m–1*] 3, and because we know *CT*[*m*], we know *CTR*[*m*] ⊕ *CBC*[*m–1*].
  prefs: []
  type: TYPE_NORMAL
- en: For the final blow, we can use the same attack on the subsequent block *m+1*.
    This allows us to find *CBC*[*m+1*] 4 and *CT*[*m+1*] ⊕ *CTR*[*m+1*]⊕ *CBC*[*m*]
    5. Since we already knew *CT*[*m+1*] and *CBC*[*m*] from the previous attack,
    we can XOR it out and calculate *CTR*[*m+1*] 6, which is equal to `AES`(*k*, *IV*[*ctr*]
    || *m+1*). Since we know *k*, we can decrypt this to find *IV*[*ctr*] 7, and we
    subsequently can calculate *CTR*[*m*] for any *m* 8, which finally allows us to
    decrypt *PT*[*m*] = *CTR*[*m*] ⊕ *CT*[*m*] 9!
  prefs: []
  type: TYPE_NORMAL
- en: We now have the firmware key and plaintext; therefore, we have easy access to
    forge firmware. Using the attack that allows us to disassociate a Hue from its
    network and upload new firmware, we could create a worm that propagates throughout
    a city. In the paper, the authors calculate that for a city like Paris, about
    15,000 Hue lights need to be present for the worm to take over all of the Hue
    lights in the city.
  prefs: []
  type: TYPE_NORMAL
- en: This attack combines a scalable/real-life attack, hardware reverse engineering,
    wireless communication, protocol abuse, exploiting a firmware bug, *and* a power
    analysis attack on CCM. Add whipped cream, and it would be the perfect dessert.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we described how the PlayStation 3, Xbox 360, and Philips Hue
    lights were broken using hardware attacks. Especially in systems that have a small
    density of software flaws, hardware attacks can be a critical step leading to
    compromise.
  prefs: []
  type: TYPE_NORMAL
