<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><h2 class="h2" id="app05"><span epub:type="pagebreak" id="page_319"/><strong>E  More Fault Injections</strong></h2>&#13;
<h3 class="h3" id="app05_1"><strong>E.1 Java Card Invalid Bytecode</strong></h3>&#13;
<p class="noindent">Java Card is a reduced version of Java intended to run on micro-controllers and smart cards. It’s one of those crazy contraptions that could only have been invented in the Nineties, allowing Java development of firmware applets. Here, we’ll discuss a type confusion problem described in Mostowski and Poll (2008) and elsewhere, as well as a way to glitch past protections in that scheme from Barbu, Thiebeauld, and Guerin (2010).</p>&#13;
<p class="indent">Many trade-offs are required to make this work. Within a Java Card applet, you’ll find far more use of primitive types than in regular Java software. The available libraries are limited, and you absolutely must do your cryptography by calling hardware acceleration libraries rather than implementing your own purely in software.</p>&#13;
<p class="indent">Java Card 3 was released in 2008 with mandatory on-chip byte-code validation (OCBV). Prior cards simply trust the developer’s workstation to produce and sign only valid bytecode. This means that anyone with signing authority can simply write illegal byte-code that casts one class to another, then uses the data fields of the misinterpreted class to dump all ROM.</p>&#13;
<p class="indent">While you probably won’t have signing keys for a card whose keys you’d like to extract, it’s often possible to buy a “white card” from eBay that accepts development keys. On these cards, such an exploit can be used to dump the JVM ROM, a very useful artifact for attacking locked cards.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_320"/><img id="chEfig1" src="../images/f0320-01.jpg" alt="Image" width="820" height="391"/></div>&#13;
<p class="figcap">Figure E.1: Catching a Miscast Instruction</p>&#13;
<p class="indent">We already mentioned that Java Card 3 closes this loophole, so let’s discuss a trick to perform the type confusion at runtime without offending the bytecode verifier. It was first described in Barbu, Thiebeauld, and Guerin (2010).</p>&#13;
<p class="indent">The idea is to use Java’s <span class="literal">try</span>/<span class="literal">catch</span> construct, in which the error from an illegal cast is caught without crashing the machine. Very many glitches can be applied, with the applet helping to cover up those that failed until a lucky one succeeds.</p>&#13;
<p class="indent">Barbu presents the concrete example from <a href="app05.xhtml#chEfig1">Figure E.1</a>, in which the <span class="literal">SecurityException</span> is quietly caught and ignored, but if the cast does not trigger an exception, then the cast object is ready for reuse. This will spin forever without fault injection, because the exception will always occur, but a lucky fault will skip the exception and allow the cast. Once successfully cast, the mistyped object can be reused for hours without triggering another exception.</p>&#13;
<h3 class="h3" id="app05_2"><span epub:type="pagebreak" id="page_321"/><strong>E.2 L11, M2351, LPC55 CrowRBAR</strong></h3>&#13;
<p class="noindent">Roth (2019) describes a glitching attack against both NuMicro’s M2351 chip and NXP’s LPC55S69. This was quickly followed by Results (2020b), which describes some very practical effects of those glitches. Roth’s paper concerns voltage glitching attacks against the attribution units, which define the trust levels of regions of memory.</p>&#13;
<p class="indent">He begins by describing ARM’s standardized security attribution unit (SAU). This is the peripheral that describes regions of memory as Secure, Non-Secure, or Non-Secure Callable. Some chips also support an implementation-defined attribution unit (IDAU), which might be custom rather than inherited from ARM’s standard designs.</p>&#13;
<p class="indent">His first target is Microchip’s SAM L11, one of the first chip microcontrollers to ship with TrustZone-M. This chip does not contain an SAU, only an IDAU that is configured by the boot ROM from a row in flash memory.<sup><a id="app5fn_1" href="footnotes.xhtml#app5fn1">1</a></sup></p>&#13;
<p class="indent">The goal of the fault is to read secure-world data while running from the non-secure world. Glitching did not trigger the brown out detector (BOD) peripheral, which was a concern as that peripheral is supposed to reset the chip when the voltage drops too low.</p>&#13;
<p class="indent">As he did not yet have a dump of the boot ROM, he had to hypothesize a good target rather than disassembling to learn the right timing. He used a ChipWhisperer to reveal that the secure mode is first set at 2.18 ms after reset; this shows as a gross difference in the power consumption. A custom firmware image could then be written to immediately reveal the success or failure of a glitch around that time, narrowing the parameters before attacking black-box targets.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_322"/><img id="chEfig2" src="../images/f0322-01.jpg" alt="Image" width="777" height="763"/></div>&#13;
<p class="figcap">Figure E.2: Nuvoton M2351</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_323"/>The SAM L11 is available as a bare chip, but also provisioned with a key and Trustonic’s Kinibi-M, a commercial Trusted Execution Environment library. This variant is called the SAM L11 KPH, and the user is only allowed to write and debug the non-secure world. Roth purchased some from Digikey and glitched the chip until OpenOCD reported a successful read, after which he could read out Knibi for reverse engineering or even replace it for supply chain attacks.</p>&#13;
<p class="indent">Roth’s second target was the Nuvoton M2351. Unlike the SAM L11, this chip contains both an SAU and a fixed IDAU. Its marketing explicitly advertises defenses against voltage glitching.</p>&#13;
<p class="indent">He first expected glitching this chip to be simple, as the more-secure opinion of the SAU or IDAU will override the other. Unfortunately for his attack, this chip uses a special instruction, <span class="literal">blxns</span> or <span class="literal">bxns</span>, to branch (and link) to the non-secure world from the secure world.</p>&#13;
<p class="indent">The last bit of the destination address is also checked by these instructions. Secure code pointers are odd, which in older chips would imply the Thumb instruction set. When the secure world wishes to call the non-secure world, it must first clear a bit of the pointer to be compatible with these instructions.</p>&#13;
<p class="indent">Therefore, a minimum attack might be to first glitch the instruction that sets <span class="literal">SAU-&gt;CTRL=1</span> and then glitch the bit clear that precedes <span class="literal">blxns</span> so the normal-world code runs in a secure-world context. This works, but it is very difficult to make stable.</p>&#13;
<p class="indent">Roth’s better attack against this chip is called CrowRBAR. The idea here is that the IDAU maps each region twice, first as secure and again at a different location as non-secure. Bit 28 distinguishes the mirror, being set for the secure mapping and clear for the non-secure mapping. The SAU’s <span class="literal">RBAR</span> register then <span epub:type="pagebreak" id="page_324"/>describes the start of the non-secure region, and if it were left as zero, the entire region would be non-secure.</p>&#13;
<p class="indent">Glitching the write of the <span class="literal">RBAR</span> register takes about thirty seconds, exposing the entirety of the region to the non-secure world! Roth is unable to read the SAU registers back in this state to know exactly what the effect of the glitch was, but he is able to read the entirety of flash memory from code in the non-secure world.</p>&#13;
<p class="indent">Roth also considered NXP’s LPC55S69, whose layout is quite similar to the M2351. A complication of this target over the M2351 is the <span class="literal">MISC_CTRL_REG</span> register’s <span class="literal">ENABLE_SECURE_CHECKING</span> field, which checks that the attribution unit’s security state matches that of the memory protection checker (MPC). This can also be glitched, but only with multiple faults.</p>&#13;
<p class="indent">While Roth’s interest was largely in privilege escalation to the secure world in these chips, Results (2020b) describes three attacks against cryptography functions in the M2351’s ROM library (MKROM). These attacks depend upon the fact that non-secure code can expose timing on a GPIO pin just before a call into the ROM, so the glitcher has very predictable timing and very little drift.</p>&#13;
<p class="indent">The first glitches the AES key to zero by skipping <span class="literal">XAES_SetKey()</span>, advancing the timing by 2.5 µs. The second glitches the output from <span class="literal">XAES_SetDMATransfer()</span> down to zeroes.</p>&#13;
<p class="indent">You will often hear that AES128 or some other algorithm is vulnerable to cryptanalysis when rounds have been skipped, and when I was younger, I wondered where the hell that might be useful. The third attack from Limited Results glitches to skip the last AES round. Feeding two faulted ciphertexts into Philippe Teuwen’s PhoenixAES tool for differential fault analysis reveals <em>K</em><sub>10</sub>, from which the entire key schedule can be extracted, including the original AES key as <em>K</em><sub>00</sub>.</p>&#13;
<h3 class="h3" id="app05_3"><span epub:type="pagebreak" id="page_325"/><strong>E.3 68HC705 and 6805</strong></h3>&#13;
<p class="noindent">Motorola’s 68HC705 is an early 6800 microcontroller with built-in EEPROM, protected from readout by an option bit that can be bypassed with glitching. The 6805 is related, but features a mask ROM that can be photographed and a test mode that can dump the same electrically.</p>&#13;
<p class="indent">Pemberton (2022) is a custom glitcher built from an Arduino Mega2560 and an Altera MAX7000S CPLD, the latter being chosen for its 5V I/O pins that are convenient for working with the old microcontroller. His CPLD provides 32 MHz (31.25 ns) resolution when glitching the supply voltage and 2 MHz clock of the target.</p>&#13;
<p class="indent">Power glitches are applied through either one or four 2N7000 FETs, and supply current on the 5V rail was limited by a resistor between 10 Ω and 220 Ω.</p>&#13;
<p class="indent">Pemberton used Motorola (1995) as a handy source of the boot ROM’s source code, but he admits that he resorted to brute-forcing the timing rather than choosing a target instruction. He describes a nifty trick of expiring the watchdog timer before pulling the chip out of reset. This way, the watchdog interrupt does not interfere with the regularity of the cycle counting.</p>&#13;
<p class="indent">For both the 68HC705 with EEPROM and the older MC6805 chip with a mask ROM, there is an undocumented test mode to dump the memory. Riddle (2016) is mostly about photographically extracting the ROM, but it also contains this description of an electrical extraction:</p>&#13;
<div class="bq">&#13;
<p class="noindent">I was able to electronically dump the ROM using the non-user-mode (NUM) pin. I used a 1 MHz clock on the EXTAL pin with XTAL grounded, tied !RST, !INT and TIMER high, and connected NUM to +5. I tied the Port A pins to +5 and ground using eight 1K resistors to set it to <span class="literal">0x9D</span>, the opcode for <span class="literal">nop</span>, and I tied Port C.3 high. The ROM contents were output on Port B; I captured the bytes using a logic analyzer.</p>&#13;
</div>&#13;
<div class="image"><span epub:type="pagebreak" id="page_326"/><img id="chEfig3" src="../images/f0326-01.jpg" alt="Image" width="778" height="689"/></div>&#13;
<p class="figcap">Figure E.3: 68HC705C8A</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_327"/>Riddle’s page describes electrical dumps of the EEPROM-based MC68705P5 when not secured, which is the same procedure as above except that Port C.0 is pulled to seven volts through a 1K resistor. The MC68705P3 and ST Micro’s EF6805U3 are the same, except that they do not have support for securing against electrical dumping. He notes that dumping often begins at the target of the reset vector, rather than at address zero.</p>&#13;
<p class="indent">Please do not confuse his method with the self-test mode, which is a way to dump a checksum of memory and not its contents. It sits at <span class="literal">0x784</span> in the ROM of the MC6805P2, where it is activated by putting nine volts on the TIMER pin, shifting the interrupt vector table up by eight bytes. LEDs connected with Port C will flash on a checksum failure.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_328"/><img id="chEfig4" src="../images/f0328-01.jpg" alt="Image" width="777" height="749"/></div>&#13;
<p class="figcap">Figure E.4: Game Boy Color CPU</p>&#13;
<div class="image"><img id="chEfig5" src="../images/f0328-02.jpg" alt="Image" width="811" height="206"/></div>&#13;
<p class="figcap">Figure E.5: Game Boy Color Shellcode from Sideris (2009a)</p>&#13;
<h3 class="h3" id="app05_4"><span epub:type="pagebreak" id="page_329"/><strong>E.4 Super Game Boy and GB Color</strong></h3>&#13;
<p class="noindent">While the ROM of the Game Boy (DMG) can be read photographically, as we saw in <a href="ch23.xhtml#ch23">Chapter 23</a>, the Super Game Boy and Game Boy Color have ROMs in which bits are not visible from the surface. Perhaps Dash etching would expose them, but voltage glitching makes that unnecessary.</p>&#13;
<p class="indent">Described in Sideris (2009a) and Sideris (2009b), the trick is to glitch the final instruction of the ROM, which disables ROM access until the next reboot. By skipping this instruction, a flash memory cartridge programmed with code to dump the ROM can freely read the code out of memory.</p>&#13;
<p class="indent">Sideris glitches this by having an FPGA replace the CPU’s clock and the cartridge. It counts clock cycles at a normal rate until executing the lockout instruction at <span class="literal">0x00FE</span>, then halts the clock and removes power for a few seconds to drain the chip of some state. The hope is that the internal ROM will not be disabled, and that the CPU will come back to life at a later address, somewhere in cartridge memory.</p>&#13;
<p class="indent">On a successful glitch, the cartridge ROM then executes a long nop sled, falling into the shellcode in <a href="app05.xhtml#chEfig5">Figure E.5</a>. That shellcode reads through all memory, writing to <span class="literal">0xA100|x</span> for every byte <span class="literal">x</span> that’s read out of memory. Those writes are silently ignored, but the access log produced by his FPGA then contains every byte of the console’s memory in order.</p>&#13;
<p class="indent">The Super Game Boy maps its ROM from <span class="literal">0x0000</span> to <span class="literal">0x00FF</span>, just like a Game Boy. The Game Boy Color has a 3kB ROM that is mapped into both that region and into the range from <span class="literal">0x0200</span> to <span class="literal">0x08ff</span>, which overlaps the cartridge ROM but leaves a gap for the cartridge ROM header from <span class="literal">0x0100</span> to <span class="literal">0x01FF</span>. It is from within this gap, or after <span class="literal">0x0900</span>, that shellcode must run.</p>&#13;
<h3 class="h3" id="app05_5"><span epub:type="pagebreak" id="page_330"/><strong>E.5 STM32F2 Chip.Fail and Kraken</strong></h3>&#13;
<p class="noindent">Roth, Datko, and Nedospasov (2019) describes a glitch of the STM32F2 boot ROM, used to downgrade from RDP Level 2 (full protection) to Level 1, where flash memory is protected but SRAM is not protected. By extending this with a second glitch, Uncredited (2020) demonstrates dumping firmware from a fully locked chip.</p>&#13;
<p class="indent">Among other details, Roth notes that it is better to time against the reset pin rising high, rather than the application of power. A shunt resistor for power analysis shows the reading of the option bytes that contain the protection mode as the first visible power spike.<sup><a id="app5fn_2" href="footnotes.xhtml#app5fn2">2</a></sup></p>&#13;
<p class="indent">Using an FPGA and MAX4619 analog switch, they successfully glitched the STM32F2 into RDP Level 1 with a delay of 17,900 cycles and a pulse of 50 cycles at 100MHz. RDP Level 1 does not expose flash memory, but early versions of the Trezor cryptocurrency wallet moved key material into SRAM, allowing its extraction with careful timing. Grand (2022) describes using this attack against an old cryptocurrency wallet to record the otherwise lost contents, as updates are not deployed to devices forgotten in safes.</p>&#13;
<p class="indent">Like the RDP downgrade in <a href="app04.xhtml#app04_3">Chapter D.3</a>, this glitch can also be used to later extract memory with STM32 exploits that require RDP Level 1, such as the one in <a href="ch02.xhtml#ch02">Chapter 2</a>.</p>&#13;
<p class="indent">Uncredited (2020) begins by reproducing the RDP downgrade glitch from Roth, Datko, and Nedospasov (2019). Like Roth, he was unable to find a fault that dropped the chip all the way to Level 0, and he was interested in dumping secrets that were held only in flash memory and never copied to SRAM. To do this, he began with some observations.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_331"/>First, he notes that glitching roughly 170 µs after reset will enable JTAG and SWD on an STM32F205. Glitching 180 µs after reset will re-enable the bootloader ROM. Both JTAG/SWD and the ROM behave as if they were in RDP Level 1, but there is a crucial difference: JTAG and SWD will disable access to flash memory in hardware when access attempts are made, but the bootloader prohibits access by a software check that is performed within the command handler.</p>&#13;
<p class="indent">This means that you can dump flash memory from a locked chip by first glitching at startup to drop into RDP Level 1, beginning a bootloader session, and then performing a second glitch during the Read Memory command handler.</p>&#13;
<h3 class="h3" id="app05_6"><strong>E.6 STM8 Bootloader and SWIM</strong></h3>&#13;
<p class="noindent">The STM8 series of 8-bit microcontrollers are used in automotive immobilizers and other useful targets. The chip’s lock is in the form of a code readout protection (CRP) bit, which is checked by the bootloader.</p>&#13;
<p class="indent">There is also a brown out reset (BOR) feature that resets the chip when the voltage drops beneath a threshold. BOR isn’t exactly a glitching defense, but it might require that any glitches be narrow and well calibrated to avoid unnecessary resets.</p>&#13;
<p class="indent">Described in Section 4 of Herrewegen et al. (2020) is a double-glitching attack on the STM8L152 and STM8AF6266. The first glitch faults a read of <span class="literal">0x8000</span>, tricking the bootloader into thinking that the chip is empty, so that the bootloader starts instead of the application. The second glitch faults a read from <span class="literal">0x4800</span>, tricking the chip into thinking that CRP is not enabled.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_332"/><img id="chEfig6" src="../images/f0332-01.jpg" alt="Image" width="661" height="1036"/></div>&#13;
<p class="figcap">Figure E.6: STM8L152</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_333"/>Glitching both of these targets is difficult because there’s no feedback mechanism letting you know that one of them was timed right, until both have successfully been glitched. There’s no way in the locked chip to distinguish a near miss from a total failure. To remedy this, they patched the bootloader to run from flash memory, allowing experimentation with partial feedback before moving to the tricky double-glitch of the locked chip.<sup><a id="app5fn_3" href="footnotes.xhtml#app5fn3">3</a></sup></p>&#13;
<p class="indent">A far easier glitching target than the bootloader is the SWIM debugging interface, which is the STM8’s equivalent of JTAG. The STM8S103 was successfully faulted into an unprotected SWIM session with a single glitch after reset in Fritsch (2020). This result was reproduced more recently in Rainier (2022) with nothing more than a pair of high-speed LMC555 timers! Both reported success when glitching the VCAP pin to ground with very short pulses.</p>&#13;
<h3 class="h3" id="app05_7"><strong>E.7 STM32F1/F3 Shaping the Glitch</strong></h3>&#13;
<p class="noindent">Two glitching attacks against the STM32 are reported in Bozzato, Focardi, and Palmarini (2019), in which the authors used a signal generator to control the shape of each voltage glitch.</p>&#13;
<p class="indent">Against the STM32F1 series, they report glitching the Read Memory command to bypass the bootloader’s readout protection check. When successful, this glitched check returns <span class="literal">ACK</span> and a chunk of memory. Unsuccessful attempts quickly return a <span class="literal">NAK</span> and no memory, but have no penalty against future attacks.</p>&#13;
<p class="indent">For the STM32F3, they perform a glitch at reset to downgrade from RDP Level 2, in which no bootloader or JTAG connections are allowed, down to RDP Level 1, in which limited bootloader and JTAG access are available and the chip is vulnerable to other attacks. They note some complications to the glitch timing, as the boot process takes some time in which the target’s clock drifts away from the glitcher’s clock.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_334"/>But why do they glitch into Level 1 instead of all the way to Level 0? Well, Level 2 is defined as <span class="literal">0xCC33</span> and Level 0 is <span class="literal">0xAA55</span> in the protection configuration word, so damaging these to <em>any other value</em> produces Level 1. For this reason, glitching all the way to Level 0 is much more difficult than simply dropping into Level 1.</p>&#13;
<p class="indent">Other STM32 fault injection attacks follow a similar pattern. Uncredited (2020) in <a href="app05.xhtml#app05_5">Chapter E.5</a>, for example, performs its reads by glitching the protection level check at runtime rather than at boot time.</p>&#13;
<h3 class="h3" id="app05_8"><strong>E.8 MSP430F5172 Glitch Per Word</strong></h3>&#13;
<p class="noindent">The serial boot-strap loader (BSL) of the MSP430F5 family requires a password in the form of the firmware’s interrupt vector table (IVT) before the Read command can operate. The general idea is that if you know the contents of the interrupt table, then you already have a copy of firmware, so there’s nothing for the chip to defend.</p>&#13;
<p class="indent">It’s frustrating to glitch, because the bit that stores the password comparison success is checked for <em>every byte</em> that is read by the TX Data Block command, but a successful attack is documented in Bozzato, Focardi, and Palmarini (2019) that dumps individual bytes. This attack is surprisingly fast once calibrated, nearly two kilobytes per minute.</p>&#13;
<p class="indent">The authors also implemented this attack on a ferroelectric RAM (FRAM) device, the MSP430FR5725. FRAM is a potential <span epub:type="pagebreak" id="page_335"/>replacement for flash memory, but because bit errors are frequent at the lowest levels, it includes an ECC mechanism to correct expected bit errors, making an unreliable memory appear rock solid. They note that this error correction makes the attack much slower, roughly one kilobyte every six minutes.</p>&#13;
<h3 class="h3" id="app05_9"><strong>E.9 CC2640 CC2652 eFuses</strong></h3>&#13;
<p class="noindent">Wouters, Gielichs, and Preneel (2022) describes a fault injection attack against the CC2640R2F and CC2652R1F, 2.4GHz radio microcontrollers in the SimpleLink series by Texas Instruments. Their commercial target was the Tesla Model 3 key fob, which uses the CC2640.</p>&#13;
<p class="indent">By reverse engineering a dump of the bootloader ROM, they identified two good targets for glitching in the form of settings that are fetched from the Customer Configuration (CCFG) and Factory Configuration (FCFG) pages of eFuses. To ease experimentation, they built an emulator for the ROM away from hardware.</p>&#13;
<p class="indent">They first characterized the glitch width that triggered faults but not crashes by glitching a tight loop in an artificial target program, allowing them to temporarily set aside the issue of the glitch offset. The CC2640R2F (Cortex M3) was best faulted for a duration of 100 ns, while the CC2652R1F (Cortex M4) was best faulted for a longer duration, 610 ns. They attribute this to differences in micro-architecture.</p>&#13;
<h4 class="h4" id="ch00lev2sec4"><strong>Customer Configuration (CCFG)</strong></h4>&#13;
<p class="noindent">A first glitching target was the Customer Configuration (CCFG) eFuse parsing, in which the ROM reads <span class="literal">CCFG:CCFG_TAP_DAP_x</span> registers to learn which JTAG features will be enabled. Side channel analysis of power consumption differences between a chip with valid firmware and a chip with invalid firmware gave an estimated “last moment” of the ROM parsing CCFG bits. Potential glitch target times were explored backward from that offset.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_336"/><img id="chEfig7" src="../images/f0336-01.jpg" alt="Image" width="777" height="769"/></div>&#13;
<p class="figcap">Figure E.7: Texas Instruments CC2640</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_337"/>Here they hit a snag: each glitch attempt might enable JTAG, but JTAG is slow, and they were only able to attempt one glitch every 2.5 seconds! To speed things up, they wrote a quick little program that outputs the state of the <span class="literal">JTAGCFG</span> register to a UART. This allowed glitch timings against a test chip to be quickly attempted without waiting on a JTAG connection, at a rate of ten attempts per second. After characterization, the derived glitch offset from the test chip could then be used on the real target chip.</p>&#13;
<p class="indent">Measured in 200 MHz ChipWhisperer cycles after reset, the successful offsets for glitching the CCFG to enable JTAG were between 188,300 and 188,4000 cycles for the CC2640R2F, for a success rate of 5%. The CC2652R1F was glitched between 161,700 and 162,000 cycles after reset, with a success rate of 1%.</p>&#13;
<h4 class="h4" id="ch00lev2sec5"><strong>Factory Test Mode (FCFG)</strong></h4>&#13;
<p class="noindent">By this point, successful glitches were known for both chips, but they were slow. A better target presented itself in an undocumented factory test mode, one that is earlier in the boot process and triggered by the Factory Configuration (FCFG) fuses.</p>&#13;
<p class="indent">If you recall that the principle limitation of glitching CCFG was detecting the open JTAG connection, then you might hope for some other signal that the glitch was successful. The very best such signal would be a GPIO pin, and that’s exactly what was found by reverse engineering early checks in the ROM.</p>&#13;
<p class="indent">Checking the GPIO pin state allows one hundred attempts per second, ten times better than the UART indication. Because the <span epub:type="pagebreak" id="page_338"/>code for the indication exists in ROM, it works on both practice attempts and against a real target of unknown firmware!</p>&#13;
<p class="indent">Successful glitching sets GPIO pin 23 high. The CC2640R2F glitches into this state between 161,100 and 161,200 cycles after reset, with a glitch width of 115ns resulting in a 10% success rate. This takes less than a second! The CC2652R1F glitched into this state between 129,700 and 129,900 clock cycles, but saw no improvement from the earlier glitch width of 610ns. This had a success rate of 0.1%, allowing them to enable all debugging features in no more than a few seconds.</p>&#13;
<h3 class="h3" id="app05_10"><strong>E.10 LC87 Unlooping over USB</strong></h3>&#13;
<p class="noindent">One of my favorite sources for this book is Scott (2016). She describes a glitching attack against the USB <span class="literal">GET_DESCRIPTOR</span> request of the Sanyo/ONsemi LC871W32 microcontroller in a Wacom CTE-450 tablet. Her article is a joy to read, ending with a successful read of a 125 kHz RFID tag using the scanning wires of the tablet and a software-only memory corruption exploit. For the purposes of this book, I’ll focus on her initial extraction of the device’s mask ROM by glitching its USB handlers.</p>&#13;
<p class="indent">The LC87 is an 8-bit microcontroller, sold in very high volumes and without any support for hobbyist or low-volume use. In the case of these pen tablets, Wacom first used a flash memory variant of the chip and later switched to a masked ROM variant.</p>&#13;
<p class="indent">When she first approached the tablet, the debugging port of the LC87 denied any connections and having no serial bootloader, USB was her best bet for a memory corruption attack.</p>&#13;
<p class="indent">Back then, there was little in public writing about USB glitching attacks, so she designed the FaceWhisperer, an extension for <span epub:type="pagebreak" id="page_339"/>Colin O’Flynn’s Chipwhisperer.<sup><a id="app5fn_4" href="footnotes.xhtml#app5fn4">4</a></sup> Like my Facedancer boards, hers uses a Maxim MAX3241E USB controller, but she also provides a 12MHz clock output and a glitch trigger input with an adjustable voltage threshold.</p>&#13;
<p class="indent">While timing the glitch can be harder in USB than against a UART bootloader, there do exist universal commands implemented by all USB devices. Rather than target something unique to the Wacom’s protocol, she targeted the generic <span class="literal">GET_DESCRIPTOR</span> handler, which is implemented in all USB devices. It returns a structure defining the interfaces and endpoints the device provides. While this structure can be dynamically generated, many devices simply store a static copy in code memory and return it when requested.</p>&#13;
<p class="indent">In the tablet’s case, the USB configuration descriptor was 34 bytes long and returned in a single packet. A successful transaction looks something like this.</p>&#13;
<div class="imagel"><img src="../images/f0339-01.jpg" alt="Image" width="811" height="127"/></div>&#13;
<p class="indent">When the timing is just right, a glitch can corrupt the length of the transfer, causing more bytes to be returned. This example shows 268 bytes, 234 of which come after the 34 bytes of the real descriptor. After a few more glitches with similar timing, she managed to luck out with a 65,534-byte transaction, including all 32kB of mask ROM!</p>&#13;
<div class="imagel"><span epub:type="pagebreak" id="page_340"/><img src="../images/f0340-01.jpg" alt="Image" width="821" height="399"/></div>&#13;
<p class="indent">After dumping the ROM, she reverse engineered it to find an undocumented backdoor, a human interface device (HID) request that writes exactly 16 bytes into SRAM at an arbitrary address. While RAM is not executable on this platform, that was enough for her to load and execute a ROP chain for arbitrary behavior.</p>&#13;
<p class="indent">With a little analog magic and a lot of experience, she was able to pulse the tablet’s sense wires in the right way, to both power and read an EM4100 RFID tag. A strange goal, but a damned impressive one, considering that there were zero hardware modifications in her final target.</p>&#13;
<h3 class="h3" id="app05_11"><strong>E.11 78K0 Glitching Checksums</strong></h3>&#13;
<p class="noindent">The first glitching exploit of the Renesas 78K0 was described in Bozzato, Focardi, and Palmarini (2019). Their exploit glitches the Checksum and Verify commands to operate on four bytes instead of the minimum 256 bytes.</p>&#13;
<p class="indent">A later attack in Herrewegen et al. (2020) uses knowledge from a reverse engineered ROM to provide more accurate timing, leaking individual bytes. Because the sanity check must be bypassed <span epub:type="pagebreak" id="page_341"/>for every byte read, a successful dump takes ten hours or so after the equipment has been calibrated.</p>&#13;
<p class="indent">The best-known attack is well described in Wouters et al. (2020), which is mostly about the Texas Instruments DST80 immobilizer system for modern cars. Rather than try to dump firmware from the immobilizer chip, they glitched a Renesas 78K0/KC2 chip from a Toyota ECU.<sup><a id="app5fn_5" href="footnotes.xhtml#app5fn5">5</a></sup> And rather than try to glitch the Checksum or Read commands, Wouters glitches the Set Security command. This command includes a safety check to ensure that the new security state is no less secure than the old one, and bypassing this check allows a single successful glitch to unlock the chip.</p>&#13;
<p class="indent">Glitch parameters can be found on <a href="ch10.xhtml#page_105">page 105</a> of their paper, in which a 16 MHz target’s Security Set command was glitched from 2.7V to 0V with a 100 ns width at an offset of 596.78 µs or 818.05 µs after the first bit of the Security Set message. They believe the timing difference comes from the choice of protections, as one of their targets had more protections enabled than the other.</p>&#13;
<h3 class="h3" id="app05_12"><strong>E.12 RX65 Bootloader Glitching</strong></h3>&#13;
<p class="noindent">Renesas RX65 chips allow readout protections to be set for memory ranges and by installing an ID code. The range restrictions are used to prevent reading the bootloader ROM, while the ID code is the password that protects against readout of flash memory.</p>&#13;
<p class="indent">Julien (2021) describes a voltage glitching attack against the Renesas RX65N, accomplished by first reverse engineering the undocumented FINE protocol that wraps commands of the documented serial communication interface (SCI) protocol. He then removed the target’s decoupling capacitors and glitched through a transistor on the VCL pin, which exposes the internal core voltage. His glitch pulse was applied by a Nucleo-F429L board running at 180MHz, and the source pulse was under 100 ns.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_342"/>While his initial glitching was performed without having a dump of the bootloader ROM, that glitch allowed him to dump reserved areas of memory. Most returned all zeroes, but eventually the bootloader ROM was found in the range from <span class="literal">0xfe7f-9000</span> to <span class="literal">0xfe7fffff</span>. This is a little weird in that it sits beneath a round number, rather than beginning on a round number.</p>&#13;
<h3 class="h3" id="app05_13"><strong>E.13 GPLB52X Tamagotchi</strong></h3>&#13;
<p class="noindent">Many Tamagotchi toys use the GPLB52X, an LCD controller from General Plus with a 6502 microcontroller and an application in custom mask ROM. Here we’ll discuss three ways to get remote code execution inside them for firmware dumping, and one of these techniques seems portable to other 6502 machines with attacker-controlled SRAM buffers.</p>&#13;
<p class="indent">Silvanovich (2013a) describes a reliable software exploit of an unhandled case in a <span class="literal">switch</span> statement of the Tamatown Tama-Go toys, with shellcode loaded as artwork into the LCD framebuffer. This exploit is particularly clever because she had to write it blind, without already having a dump of the mask ROM to reverse engineer.</p>&#13;
<p class="indent">Starting with the die photo on <a href="app05.xhtml#chEfig8">page 343</a>, she searched through wire-bonding documentation from General Plus until the bonding pads in the documentation matched those in the chip from the toy. That told her the chip’s model number and allowed her to write shellcode, but she still needed a way to execute her shellcode.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_343"/><img id="chEfig8" src="../images/f0343-01.jpg" alt="Image" width="778" height="803"/></div>&#13;
<p class="figcap">Figure E.8: General Plus GPLB52X</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_344"/><img id="chEfig9" src="../images/f0344-01.jpg" alt="Image" width="542" height="489"/></div>&#13;
<p class="figcap">Figure E.9: Simplified GPLB52X Memory Map</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_345"/>And executing shellcode is tricky, as the attacker controls only external EEPROM memory. This external memory is not executable in place, so it’s necessary to wait for the device to read the external EEPROM and then copy some of its data to internal SRAM, which is executable. Helpfully, the toy keeps sprites in the external EEPROM that are displayed on the toy’s LCD screen from a memory-mapped frame buffer.</p>&#13;
<p class="indent">So she placed shellcode with a long nop sled into the LCD buffer as plugin graphics from an external EEPROM, then fuzzed all available configuration bytes in the EEPROM until the shell-code ran and dumped the internal ROM. Having the ROM, she reverse engineered it to find a parser vulnerability in a <span class="literal">switch()</span> statement and wrote a clean exploit that reliably triggered the same code execution with minimal side effects.</p>&#13;
<p class="indent">A later toy, Tamagotchi Friends, was released without support for memory chip accessories or infrared communications, but with support for a small EEPROM of persistent data and an NFC peripheral. Silvanovich (2014) describes a successful glitching attack, in which she was able to redirect execution into her 54-byte shellcode that was copied as data from EEPROM into the LCD frame buffer.</p>&#13;
<p class="indent">Rather than trying to skip a specific instruction as many other glitching attacks do in this book, she instead glitched the target hard enough that the program counter was corrupted. The 6502 CPU has no illegal instructions and much of unused memory reads as <span class="literal">0x00</span>, which is a <span class="literal">brk</span> instruction when a debugger is attached but otherwise a <span class="literal">nop</span>, forming a nop sled that leads more or less to her shellcode, shown in <a href="app05.xhtml#chEfig10">Figure E.10</a>.</p>&#13;
<p class="indent">Another example of a brownout glitch can be found in YKT (2023), where the 6502 core of a Mitsubishi M37409M2 is tricked into running shellcode from an SRAM buffer. Like Natalie’s attack, this one also uses shellcode with a long nop sled and relies on randomizing the program counter with a long power fault rather than attempting to glitch an individual instruction.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_346"/><img id="chEfig10" src="../images/f0346-01.jpg" alt="Image" width="821" height="763"/></div>&#13;
<p class="figcap">Figure E.10: GPLB52X (6502) Shellcode for Tamagotchi Friends</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_347"/>YKT describes the attack like this:</p>&#13;
<div class="bq">&#13;
<p class="noindent">Dumped the SC-55mkII’s secondary MCU (Mitsubishi M37409M2) firmware using voltage glitching. Injecting trojan to its ram and using glitch to corrupt PC counter to execute it did the trick.</p>&#13;
<p class="noindent_3">Disabling power of the chip will cause PC register corrupt to randomish value. Since this is a really simple 8-bit MCU with very small memory footprint—only 8kB—there’s very high chances to point PC to ram address and execute it after lots of retries.</p>&#13;
</div>&#13;
<p class="indent">Silvanovich (2013b) describes a test program, resident in ROM at <span class="literal">0xC000</span> in the GPLB52X series. Natalie dumped it along with the Tamagotchi, where it sits just before the application begins at <span class="literal">0xCC00</span>. See <a href="app05.xhtml#chEfig9">Figure E.9</a> for the memory map and <a href="app05.xhtml#chEtab1">Table E.1</a> for a list of test programs. Test mode is started with the test pin of the die, then the program number sampled over Port A. She has particular interest in programs <span class="literal">03</span> and <span class="literal">14</span>.</p>&#13;
<p class="indent">Program <span class="literal">03</span> is a ROM checksum routine. By default, when Port B is not set, the checksum covers the entire ROM. Setting Port B allows a range to be clocked in, but this is sadly not exploitable for dumping individual bytes. The range must be at least 255, and a bug in the ROM leaves Port B in input mode after the transaction, so you can’t read the checksum when a limited range is selected.</p>&#13;
<table class="table95">&#13;
<colgroup>&#13;
<col style="width:20%"/>&#13;
<col style="width:80%"/>&#13;
</colgroup>&#13;
<tbody>&#13;
<tr>&#13;
<td><span epub:type="pagebreak" id="page_348"/><p class="tab-para"><span class="literal">00</span></p></td>&#13;
<td><p class="tab-para">Sleep mode?</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">01</span></p></td>&#13;
<td><p class="tab-para">RAM Test</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">02</span></p></td>&#13;
<td><p class="tab-para">Stress Test</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">03</span></p></td>&#13;
<td><p class="tab-para">ROM Checksum</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">04</span></p></td>&#13;
<td><p class="tab-para">LCD Test</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">05</span></p></td>&#13;
<td><p class="tab-para">Unknown</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">06</span></p></td>&#13;
<td><p class="tab-para">Port Stress Test</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">07</span></p></td>&#13;
<td><p class="tab-para">Timer Interrupt Test</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">08</span></p></td>&#13;
<td><p class="tab-para">Another LCD Test</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">09</span></p></td>&#13;
<td><p class="tab-para">Unknown</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">0A</span></p></td>&#13;
<td><p class="tab-para">Unknown</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">0B</span></p></td>&#13;
<td><p class="tab-para">Something like <span class="literal">09</span></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">0C</span></p></td>&#13;
<td><p class="tab-para">Something like <span class="literal">00</span></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">0D</span></p></td>&#13;
<td><p class="tab-para">Something like <span class="literal">04</span></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">0E</span></p></td>&#13;
<td><p class="tab-para">Unknown</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">0F</span></p></td>&#13;
<td><p class="tab-para">SPI Test</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">10</span></p></td>&#13;
<td><p class="tab-para">Unknown</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">11</span></p></td>&#13;
<td><p class="tab-para">LCD Test</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">12</span></p></td>&#13;
<td><p class="tab-para">Something like <span class="literal">16</span></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">13</span></p></td>&#13;
<td><p class="tab-para">ROM Checksum</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">14</span></p></td>&#13;
<td><p class="tab-para"><strong>Code Execution!</strong></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">15</span></p></td>&#13;
<td><p class="tab-para">Interrupt Test?</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">16</span></p></td>&#13;
<td><p class="tab-para">Jumps to RAM at <span class="literal">0x0200</span></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p class="tab-para"><span class="literal">17</span></p></td>&#13;
<td><p class="tab-para">Sets <span class="literal">0x300b</span> and <span class="literal">0x300c</span></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="tab-cap1" id="chEtab1">Table E.1: GPLB52X Test Codes from Silvanovich (2013b)</p>&#13;
<p class="indent">Program <span class="literal">14</span> is more useful. It accepts bits of a program over port B.7, one bit at a time, with bits 2 and 4 of the same port signaling when the next bit is ready. The program is loaded from <span class="literal">0x0200</span> to <span class="literal">0x05ff</span>, then executed in place after the last bit is loaded. <a href="app05.xhtml#chEfig11">Figure E.11</a> has a listing of this program handler.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_349"/><img id="chEfig11" src="../images/f0349-01.jpg" alt="Image" width="822" height="1066"/></div>&#13;
<p class="figcap">Figure E.11: GeneralPlus Test Program <span class="literal">14</span></p>&#13;
<h3 class="h3" id="app05_14"><span epub:type="pagebreak" id="page_350"/><strong>E.14 MC9S12 Reset Glitch</strong></h3>&#13;
<p class="noindent">HCS12 chips such as Freescale’s MC9S12 chip are popular as automotive ECUs. They are regularly cracked by the automotive chip-tuning industry to adjust the air fuel ratios of fuel injected engines.</p>&#13;
<p class="indent">Stephen Chavez and Specter presented some hints at their crack in Chavez and Specter (2017), and from private correspondence I’ve confirmed that they dumped the chip by pulling the reset line high with a very short pulse to confuse the HCS12 reset state machine.</p>&#13;
<p class="indent">The VVDI Prog is a commercial chip programmer, whose special feature is built-in support for memory extraction attacks against a number of automotive microcontrollers, for performance tuning or key copying. As of version 4.9.5, it advertises attacks against some members of the MC68HC(9)08, MC68HC(9)12, and MC9S12 families.</p>&#13;
<h3 class="h3" id="app05_15"><strong>E.15 Nvidia Tegra X2</strong></h3>&#13;
<p class="noindent">While the Tegra X1 had a very well-publicized deployment in the Nintendo Switch, the X2 was found in more expensive devices, such as autonomous driving units and infotainment systems in modern cars. A voltage fault injection for the X2 is described in Bittner et al. (2021).</p>&#13;
<p class="indent">The X2 boots in three stages: (1) the iROM runs from masked ROM to decrypt and verify the signature of (2) Nvidia’s MB1 bootloader from an eMMC, which then runs (3) the OEM’s MB2 bootloader from eMMC. MB1 is encrypted and its signing key is tightly protected by Nvidia, but MB2 can be freely modified using development kits.</p>&#13;
<p class="indent">Bittner’s first challenge was to write an MB2 image that would dump the iROM for reverse engineering. This was aided by leaked BootROM source code from the X1, which periodically appears online before disappearing in a flurry of DMCA notices.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_351"/><img id="chEfig12" src="../images/f0351-01.jpg" alt="Image" width="821" height="322"/></div>&#13;
<p class="figcap">Figure E.12: Fuse Check in the X2’s UART Bootloader</p>&#13;
<p class="indent">Reverse engineering the iROM revealed that the chip supports a “Failure Analysis Mode,” in which a prompt is sent to a UART and then code is received over that UART for execution. This mode is chosen by a fuse check early in the boot process, so the fuse check is a good glitch target. The reset pin can be used as a trigger signal for glitch timing, and the appearance of a UART prompt indicates a successful glitch.</p>&#13;
<p class="indent">For the fault injection itself, Bittner used an IRF8736 MOSFET to glitch a voltage rail of the X2, controlling the MOSFET by an FPGA’s GPIO pin through a MAX4619 level shifter. The target of the glitch is roughly the code in <a href="app05.xhtml#chEfig12">Figure E.12</a>, with lines 3 or 11 being good candidates for the faulted instruction.</p>&#13;
<p class="indent">Having code execution through the UART bootloader, they then loaded shellcode that used the X2’s internal keys to decrypt the MB1 bootloader.</p>&#13;
<h3 class="h3" id="app05_16"><span epub:type="pagebreak" id="page_352"/><strong>E.16 Zynq 7000 ROM Dump Glitch</strong></h3>&#13;
<p class="noindent">The Zynq series from Xilinx combine an ARM CPU with a Xilinx 7-Series FPGA. They’re commonly found in lab equipment, Bitcoin mining rigs, and anywhere else that a Linux machine and an FPGA are needed in a single package. The chip boots from a signed image in external memory, such as a SPI flash chip or an SD card.</p>&#13;
<p class="indenta">The Zynq boot ROM supports signed and encrypted firmware images, making it a prime target for software exploits, but access to the ROM is disabled before control is handed over to the application. This makes reading the ROM difficult, even from an unlocked development kit.</p>&#13;
<p class="indenta">Schretlen (2021b) describes a fault injection technique for dumping the boot ROM. It requires strapping the PLL_DISABLE pin, and also replacing some of the decoupling caps with SOT23 FETs. Timing was too unpredictable when triggering on the target’s reset signal, and the SD card’s own timing was too noisy to use as a start trigger.</p>&#13;
<p class="indenta">The solution was to trigger after the last byte returned from the SD card to the Zynq. The author notes that the SPI flash boot method might be more deterministic, but the required pins were not broken out on the available development board.</p>&#13;
<p class="indenta">Glitching is a fine way to extract a ROM when there are no other options, as was the case for the first extraction of this ROM. After getting the ROM and reverse engineering it, a common goal is to find a software bug that allows for extraction without glitching. See <a href="app01.xhtml#app01_10">Chapter A.10</a> for just such an exploit against this chip.</p>&#13;
<h3 class="h3" id="app05_17"><span epub:type="pagebreak" id="page_353"/><strong>E.17 STM32 Body Biasing Injection</strong></h3>&#13;
<p class="noindent">Body biasing injection (BBI) attacks were first introduced to literature in Maurine et al. (2012), as a way to induce a fault by regionally raising the voltage on the underside of the microchip die. This requires exposing the backside of the die, then stepping a probe around to explore the best injection spots for any particular attack.</p>&#13;
<p class="indent">While it requires more equipment and preparation than voltage glitching, it has the advantage of inducing a <em>localized</em> fault. These faults are confined to a region of the chip, leaving the rest of the chip to run properly.</p>&#13;
<p class="indent">O’Flynn (2020b) describes a practical attack against the STM32-F415 in wafer-level chip-scale packaging (WLCSP), which naturally exposes the backside of the die. Recall from <a href="ch18.xhtml#ch18">Chapter 18</a> that WLCSP works by putting BGA solder balls directly onto a die, which is soldered to a circuit board without any plastic encapsulation. This dramatically reduces the preparation time, as there’s no need to chemically or mechanically remove the device packaging.</p>&#13;
<p class="indent">He used a custom probe called the ChipJabber BBI that sits at the end of a ChipWhisperer. Whenever the CW glitch fires, a low-voltage pulse from two capacitors fires through a transformer to send a high-voltage pulse into a probe on the backside of the die. Power is provided by a bench supply with current limiting capability. See <a href="app05.xhtml#chEfig13">Figure E.13</a>.</p>&#13;
<p class="indent">O’Flynn used a three-axis motorized stage and a spring-loaded probe to scan 256 unique points on the WLCSP package’s surface. On these packages, the surface layer faces downward into the circuit board, while the backside is exposed away from the board for the probe. Some of them have a thin opaque layer over the backside, but such paint can be scraped away with a knife.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_354"/><img id="chEfig13" src="../images/f0354-01.jpg" alt="Image" width="763" height="191"/></div>&#13;
<p class="figcap">Figure E.13: ChipJabber BBI Schematic</p>&#13;
<div class="image"><img id="chEfig14" src="../images/f0354-02.jpg" alt="Image" width="777" height="767"/></div>&#13;
<p class="figcap">Figure E.14: STM32F103 Bias Points from Balda (2021)</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_355"/>The transformer was custom-wound around a commercial ferrite rod, with six turns of 26 AWG magnetic wire for the primary winding and sixty turns of 30 AWS wire for the secondary winding. Fewer turns result in lower inductance, which is necessary for a fast reaction time. More turns would slow the slew rate and lengthen the pulse duration.</p>&#13;
<p class="indent">In terms of faults, he was more interested in providing a convenient target for research into body biasing techniques than breaking the readout protection of any particular device. His examples include a nested loop for characterization, a classic fault attack on RSA-CRT and the beginnings of characterizing faults in the hardware AES accelerator.</p>&#13;
<p class="indent">As O’Flynn’s excellent paper set up the STM32 as a target but stopped just short of a memory extraction exploit, there was a good opportunity for a second paper. Balda (2021) provided this, reproducing the work against an STM32F103 microcontroller with an aim to extract locked firmware.</p>&#13;
<p class="indent">His STM32F103 is a wire-bonded BGA in which the front side of the die faces away from the board and the backside faces down into the board. This is far less convenient than the WLCSP package, but luckily the center pins of the BGA package weren’t needed for the bootloader. Balda slowly ground through the PCB, the solder bumps, and the bottom of the BGA package to reveal the die. A copper pad that was against the die was pulled away with a scalpel after pieces had been freed by grinding.</p>&#13;
<p class="indent">This chip has a single RDP level, as we saw in <a href="ch11.xhtml#ch11">Chapter 11</a>, and Balda chose to attack it through the bootloader rather than through JTAG. Each time the read request is sent to the boot-loader as <span class="literal">0x11 0xEE</span>, the BBI fault injection has a chance to skip the device’s RDP check and allow the read to continue.</p>&#13;
<p class="indent">Balda notes that successful glitches for the RDP bypass were inserted 8.95 µs after the last rising edge of the bootloader read <span epub:type="pagebreak" id="page_356"/>command. The fault must be performed for every memory read, but a 60% success rate keeps things moving quickly.</p>&#13;
<p class="indent">Plotting the successful locations of those faults produces <a href="app05.xhtml#chEfig14">Figure E.14</a>, showing that at these voltages the useful faults all come in or around the flash memory. None of the faults targeted the CPU, and Balda hypothesizes that this is because the ROM boot-loader reads from the flash memory’s <span class="literal">FLASH_OBR</span> register, which holds a single bit for the RDP status.</p>&#13;
<p class="indent">Glitches 3.5 µs after the last rising edge of the command had a different and undesired effect, mass erasing all flash memory and destroying the information that might be retrieved. Effects like these are why it’s so important to carefully calibrate glitches, rather than adopting a “spray and pray” strategy and leaving the equipment to run unattended in a cupboard.</p>&#13;
<h3 class="h3" id="app05_18"><strong>E.18 PCF7941 Erasure</strong></h3>&#13;
<p class="noindent">NXP has a series of wireless security transponders implemented as RISC microcontrollers. One of these, the PCF7941, has been successfully glitched to program replacement car keys.</p>&#13;
<p class="indent">In a San Francisco dive bar, I heard that this required cooling the chip with alcohol and dry ice for several days before an FPGA was able to glitch the 2Link debugging protocol into an unlock. It sounded like the attack used a single glitch to unlock all the chip at one time, but I’m not entirely sure from the description.</p>&#13;
<p class="indent">Some commercial tools, like VVDI Prog mentioned in <a href="app05.xhtml#app05_14">Chapter E.14</a>, support the PCF7941. They use a wired connection to glitch the chip, erasing it for a new pairing. The glitch is only to allow erasure of a locked chip. These tools don’t seem to extract the firmware, as their customers are more interested in matching keys to new vehicles.</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_357"/><img id="chEfig15" src="../images/f0357-01.jpg" alt="Image" width="777" height="691"/></div>&#13;
<p class="figcap">Figure E.15: NXP PCF7941</p>&#13;
<h3 class="h3" id="app05_19"><span epub:type="pagebreak" id="page_358"/><strong>E.19 EFM32WG without a Brownout</strong></h3>&#13;
<p class="noindent">The EFM32WG is a nice little ARM Cortex-M chip from Silicon Labs. Its longevity is guaranteed until 2026, marketed toward smart meters and industrial automation. While the CPU itself would be vulnerable to glitching, the chip features effective brownout detection (BOD) circuits that reset the chip during bootloader glitching attempts, frustrating the attack.</p>&#13;
<p class="indent">Results (2021a) describes using electromagnetic fault injection (EMFI) to glitch the CPU region of the chip, allowing protected firmware to be read without causing a brownout. This was performed because regular voltage glitching reliably triggered one of four brownout detectors (BODs) before introducing any faults, requiring the localized fault injection that EMFI can provide.</p>&#13;
<p class="indent">The EMFI system is a custom one called Der Injektor. The design has not yet been published as I write this, but it might be by the time you read this.</p>&#13;
<p class="indent">These results were successfully reproduced by Transistor (2023) against a Bosch smart home system. While Limited Results built a custom EMFI tool, Vegan Transistor preferred to modify a Langer BS 06DB-s pulse generator that was intended for electrical fast transient (EFT) pulse testing.</p>&#13;
<p class="indent">To identify the proper time for fault injection, power was traced in both a locked and an unlocked state. This was performed by a magnetic field probe near a decoupling capacitor, amplified to account for the low power consumption of the chip. The glitch target window begins 150 µs after reset, lasting for 47 µs. Immediately afterward, the first instruction begins execution.</p>&#13;
<p class="indent">Faults that were too strong triggered a reset, and by backing up just a bit until the resets ceased, the right power level was identified. Eventually JTAG unlocked and a standard Segger J-Flash read out 128kB of firmware.</p>&#13;
<h3 class="h3" id="app05_20"><span epub:type="pagebreak" id="page_359"/><strong>E.20 MPC55 by EMFI</strong></h3>&#13;
<p class="noindent">O’Flynn (2020a) describes an electromagnetic attack against the boot assist module (BAM) of the NXP MPC5676R and MPC5566 chips, PowerPC devices that are popular in automotive ECUs.</p>&#13;
<p class="indent">Electrically, the only thing special about an automotive grade chip is that it will run at a higher temperature. From a security perspective, though, there’s an entire industry called <em>chip tuning</em> that hacks these chips in order to improve engine performance.</p>&#13;
<p class="indent">It’s worth noting that O’Flynn didn’t bother reverse engineering the BAM ROM, as it wasn’t necessary to implement his attack. Power rail glitching would likely also work, but EMFI allows the attack to be performed without relocating the chip from its board in the ECU of a 2019 Chevy Silverado. There’s no need to remove decoupling capacitors or solder in a transistor for glitching.</p>&#13;
<p class="indent">Similar chips are sold by as the SPC57xx and SPC58xx from ST Micro. These perform their permission check <em>after</em> buffering the code in SRAM. That dramatically slows the fault timing search, because the full transfer must be repeated for every single fault injection attempt. O’Flynn has not yet reported success in breaking them.<span epub:type="pagebreak" id="page_360"/></p>&#13;
</div>
</div>
</body></html>