["```\n#import <AVFoundation/AVCaptureDevice.h>\n\nfor(AVCaptureDevice* audioDevice in [AVCaptureDevice devicesWithMediaType:AVMediaTypeAudio]) {\n    printf(\"audio device: %s\\n\", audioDevice.description.UTF8String);\n\n    // Add code here to add a property listener for each audio device.\n}\nfor(AVCaptureDevice* videoDevice in [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo]) {\n    printf(\"video device: %s\\n\", videoDevice.description.UTF8String);\n\n    // Add code here to add a property listener for each video device.\n} \n```", "```\nAudio device: <AVCaptureHALDevice: 0x11b36a480 [MacBook Pro\nMicrophone][BuiltInMicrophoneDevice]>\n\nAudio device: <AVCaptureHALDevice: 0x11a7e0440 [Bose QuietComfort 35]\n[04-52-C7-77-0D-4E:input]>\n\nVideo device: <AVCaptureDALDevice: 0x10dbb2c00 [FaceTime HD Camera]\n[3F45E80A-0176-46F7-B185-BB9E2C0E82E3]> \n```", "```\nextern OSStatus AudioObjectAddPropertyListenerBlock(AudioObjectID inObjectID,\nconst AudioObjectPropertyAddress* inAddress, dispatch_queue_t __nullable inDispatchQueue,\nAudioObjectPropertyListenerBlock inListener); \n```", "```\n-(UInt32)getAVObjectID:(AVCaptureDevice*)device {\n    UInt32 objectID = 0;\n\n  ❶ SEL methodSelector = NSSelectorFromString(@\"connectionID\");\n    if(YES != [device respondsToSelector:methodSelector]) {\n        goto bail;\n    }\n\n  ❷ #pragma clang diagnostic push\n    #pragma clang diagnostic ignored \"-Wpointer-to-int-cast\"\n    #pragma clang diagnostic ignored \"-Warc-performSelector-leaks\"\n  ❸ objectID = (UInt32)[device performSelector:methodSelector withObject:nil];\n  ❹ #pragma clang diagnostic pop\n\nbail:\n    return objectID;\n} \n```", "```\nAudioObjectPropertyAddress propertyStruct = {0};\npropertyStruct.mSelector = kAudioDevicePropertyDeviceIsRunningSomewhere;\npropertyStruct.mScope = kAudioObjectPropertyScopeGlobal;\npropertyStruct.mElement = kAudioObjectPropertyElementMain; \n```", "```\ntypedef void (^AudioObjectPropertyListenerBlock)(UInt32 inNumberAddresses,\nconst AudioObjectPropertyAddress* inAddresses); \n```", "```\n-(BOOL)watchAudioDevice:(AVCaptureDevice*)device {\n    AudioObjectPropertyAddress propertyStruct = {0};\n\n    propertyStruct.mSelector = kAudioDevicePropertyDeviceIsRunningSomewhere;\n    propertyStruct.mScope = kAudioObjectPropertyScopeGlobal;\n    propertyStruct.mElement = kAudioObjectPropertyElementMain;\n\n    AudioObjectID deviceID = [self getAVObjectID:device];\n\n    AudioObjectPropertyListenerBlock listenerBlock =\n    ^(UInt32 inNumberAddresses, const AudioObjectPropertyAddress* inAddresses) {\n        // Code to handle device's run state changes removed for brevity\n    };\n\n    AudioObjectAddPropertyListenerBlock(deviceID, &propertyStruct, self.eventQueue,\n    listenerBlock);\n    ...\n} \n```", "```\n-(UInt32)getMicState:(AVCaptureDevice*)device {\n    UInt32 isRunning = 0;\n    UInt32 propertySize = sizeof(isRunning);\n\n    AudioObjectID deviceID = [self getAVObjectID:device]; ❶\n    AudioDeviceGetProperty(deviceID, 0, false, kAudioDevicePropertyDeviceIsRunningSomewhere,\n    &propertySize, &isRunning); ❷\n\n    return isRunning;\n} \n```", "```\n-(BOOL)watchVideoDevice:(AVCaptureDevice*)device {\n  ❶ CMIOObjectPropertyAddress propertyStruct = {0};\n    propertyStruct.mScope = kAudioObjectPropertyScopeGlobal;\n    propertyStruct.mElement = kAudioObjectPropertyElementMain;\n    propertyStruct.mSelector = ❷ kAudioDevicePropertyDeviceIsRunningSomewhere;\n\n  ❸ CMIOObjectID deviceID = [self getAVObjectID:device];\n\n  ❹ CMIOObjectPropertyListenerBlock listenerBlock = ^(UInt32\n    inNumberAddresses, const CMIOObjectPropertyAddress addresses[]) {\n        // Code to handle device's run-state changes removed for brevity\n    };\n\n  ❺ CMIOObjectAddPropertyListenerBlock(deviceID, &propertyStruct,\n    self.eventQueue, listenerBlock);\n    ...\n} \n```", "```\n[NSNotificationCenter.defaultCenter addObserver:self\nselector:@selector(handleConnectedDeviceNotification:)\nname:AVCaptureDeviceWasConnectedNotification object:nil];\n\n[NSNotificationCenter.defaultCenter addObserver:self\nselector:@selector(handleDisconnectedDeviceNotification:)\nname:AVCaptureDeviceWasDisconnectedNotification object:nil]; \n```", "```\n-(void)handleConnectedDeviceNotification:(NSNotification *)notification {\n  ❶ AVCaptureDevice* device = notification.object;\n\n  ❷ if(YES == [device hasMediaType:AVMediaTypeAudio]) {\n        [self watchAudioDevice:device];\n  ❸} else if(YES == [device hasMediaType:AVMediaTypeVideo]) {\n        [self watchVideoDevice:device];\n    }\n} \n```", "```\n% **log stream**\n...\nDefault     0x0   367    0    com.apple.cmio.registerassistantservice:\n[com.apple.cmio:] RegisterAssistantService.m:2343:-[RegisterAssistantServer\naddRegisterExtensionConnection:]_block_invoke [{private}**901**][{private}0]\nadded <private> endpoint <private> camera <private>\n\nDefault     0x0   **901**    0    avconferenced: (CoreMediaIO) [com.apple.cmio:]\nCMIOHardware.cpp:747:CMIODeviceStartStream backtrace 0   CoreMediaIO\n0x000000019b4c4040 CMIODeviceStartStream + 228    [0x19b45a000 + 434240] \n```", "```\n% **log stream**\n...\nDefault     0x0   367    0    com.apple.cmio.registerassistantservice:\n[com.apple.cmio:] RegisterAssistantService.m:2343:-[RegisterAssistantServer\naddRegisterExtensionConnection:]_block_invoke [{private}**17873**][{private}0]\nadded <private> endpoint <private> camera <private>\n\nDefault     0x0   **17873**  0    zoom.us: (CoreMediaIO) [com.apple.cmio:]\nCMIOHardware.cpp:747:CMIODeviceStartStream backtrace 0   CoreMediaIO\n0x00007ff8248a6287 CMIODeviceStartStream\n+ 205    [0x7ff824840000 + 418439]CMIOHardware.cpp:747:CMIODeviceStartStream\nbacktrace 0   CoreMediaIO      0x00007ff8248a6287 CMIODeviceStartStream +\n205    [0x7ff824840000 + 418439] \n```", "```\n-(BOOL)start:(NSPredicate*)predicate level:(NSUInteger)level\ncallback:(void(^)(OSLogEvent*))callback; \n```", "```\nif(@available(macOS 14.0, *)) {\n    [self.logMonitor start:[NSPredicate predicateWithFormat:@\"subsystem=='com.apple.cmio' OR\n    subsystem=='com.apple.coremedia'\"] level:Log_Level_Default callback:^(OSLogEvent*\n    logEvent) {\n        // Code that processes cmio and coremedia log messages removed for brevity\n    }];\n} \n```", "```\n❶ NSRegularExpression* cameraRegex = [NSRegularExpression\nregularExpressionWithPattern:@\"\\\\[\\\\{private\\\\}(\\\\d+)\\\\]\"\noptions:0 error:nil];\n\n❷ if((YES == [logEvent.subsystem isEqual:@\"com.apple.cmio\"]) &&\n    (YES == [logEvent.composedMessage hasSuffix:@\"added <private>\n    endpoint <private> camera <private>\"])) {\n  ❸ NSTextCheckingResult* match = [cameraRegex firstMatchInString:logEvent.\n    composedMessage options:0 range:NSMakeRange(0, logEvent.composedMessage.\n    length)];\n    if((nil == match) || (NSNotFound == match.range.location)) {\n return;\n    }\n  ❹ NSInteger pid = [[logEvent.composedMessage substringWithRange:\n    [match rangeAtIndex:1]] integerValue];\n        self.lastCameraClient = pid;\n} \n```", "```\nClient* client = nil;\n\nif(0 != self.lastCameraClient) {\n    client = [[Client alloc] init];\n    client.pid = [NSNumber numberWithInteger:self.**lastCameraClient**];\n    client.path = valueForStringItem(getProcessPath(client.pid.intValue));\n    client.name = valueForStringItem(getProcessName(client.path));\n}\nEvent* event = [[Event alloc] init:client device:device deviceType:\nDevice_Camera state:NSControlStateValueOn];\n\n[self handleEvent:event]; \n```", "```\n#define PREF_EXECUTE_PATH @\"executePath\"\n#define PREF_EXECUTE_ACTION @\"executeAction\"\n❶ self.executePath.stringValue = panel.URL.path;\n...\n❷ [NSUserDefaults.standardUserDefaults setBool:NSControlStateValueOn\nforKey:PREF_EXECUTE_ACTION];\n\n❸ [NSUserDefaults.standardUserDefaults setObject:self.executePath.stringValue\nforKey:PREF_EXECUTE_PATH];\n\n❹ [NSUserDefaults.standardUserDefaults synchronize]; \n```", "```\n#define SHELL @\"/bin/bash\"\n#define PREF_EXECUTE_PATH @\"executePath\"\n#define PREF_EXECUTE_ACTION_ARGS @\"executeActionArgs\"\n\n-(BOOL)executeUserAction:(Event*)event {\n    NSMutableString* args = [NSMutableString string];\n\n    NSString* action = [NSUserDefaults.standardUserDefaults objectForKey:PREF_EXECUTE_PATH]; ❶\n    if(YES == [NSUserDefaults.standardUserDefaults boolForKey:PREF_EXECUTE_ACTION_ARGS]) { ❷\n        [args appendString:@\"-device \"]; ❸\n        (Device_Camera == event.deviceType) ? [args appendString:@\"camera\"] :\n        [args appendString:@\"microphone\"];\n\n        [args appendString:@\" -process \"];\n        [args appendString:event.client.pid.stringValue];\n        ...\n    }\n\n  ❹ execTask(SHELL, @[@\"-c\", [NSString stringWithFormat:@\"\\\"%@\\\" %@\", action, args]], NO, NO);\n    ... \n```", "```\n-(void)stop {\n    ...\n    for(AVCaptureDevice* audioDevice in [AVCaptureDevice devicesWithMediaType:AVMediaType\n    Audio]) {\n        [self unwatchAudioDevice:audioDevice];\n    }\n\n    for(AVCaptureDevice* videoDevice in [AVCaptureDevice devicesWithMediaType:AVMediaType\n    Video]) {\n        [self unwatchVideoDevice:videoDevice];\n    }\n    ...\n} \n```", "```\n-(void)unwatchAudioDevice:(AVCaptureDevice*)device {\n    ...\n    AudioObjectID deviceID = [self getAVObjectID:device];\n\n    AudioObjectPropertyAddress propertyStruct = {0};\n    propertyStruct.mScope = kAudioObjectPropertyScopeGlobal;\n    propertyStruct.mElement = kAudioObjectPropertyElementMain;\n    propertyStruct.mSelector = kAudioDevicePropertyDeviceIsRunningSomewhere;\n\n  ❶ AudioObjectRemovePropertyListenerBlock(deviceID,\n    &propertyStruct, self.eventQueue, self.audioListeners[device.uniqueID]);\n    ...\n} \n```"]