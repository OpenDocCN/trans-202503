- en: '## **8'
  prefs: []
  type: TYPE_NORMAL
- en: DATA TYPES AND DATA STRUCTURES**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](Images/com.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Understanding the data types and data structures that you encounter as you analyze
    a binary is foundational to reverse engineering. The data that is being passed
    into a function is a key to reverse engineering the function’s signature (the
    number, type, and sequence of parameters required by the function). Beyond that,
    the data types and data structures declared and utilized within functions provide
    additional clues to what each function is doing. This reinforces the importance
    of developing a deep understanding of how data types and data structures are represented
    and manipulated at the assembly language level.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we devote significant time to these topics that are so critical
    to the success of a reverse engineering effort. We demonstrate how to recognize
    data structures used in a disassembly and to model those structures in Ghidra.
    We follow with a demonstration of how Ghidra’s rich collection of structure layouts
    can save you time with your analysis. Since C++ classes are a complex extension
    of C structures, the chapter concludes with a discussion of reverse engineering
    compiled C++ programs. So let’s begin our discussion of the manipulation and definition
    of simple and complex data types and structures found within compiled programs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Making Sense of Data**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As a reverse engineer, you want to make sense of the data you see in a disassembly.
    The simplest method for associating a specific data type with a variable is to
    observe the use of the variable as a parameter to a function that we know something
    about. During its analysis phase, Ghidra makes every effort to annotate data types
    when they can be deduced based on a variable’s use with a function for which Ghidra
    possesses a prototype.
  prefs: []
  type: TYPE_NORMAL
- en: With imported library functions, Ghidra often will already know the prototype
    of the function. In such cases, you can easily view the prototype by hovering
    over the function name in the Listing window or the Symbol Tree window. When Ghidra
    has no knowledge of a function’s parameter sequence, it should, at a minimum,
    know the name of the library from which the function was imported (see the *Imports*
    folder in the Symbol Tree window). When this happens, your best resources for
    learning the signature and behavior of the function are any associated man pages
    or other available API documentation. When all else fails, remember the adage
    “Google is your friend.”
  prefs: []
  type: TYPE_NORMAL
- en: The low-hanging fruit in understanding the behavior of binary programs lies
    in cataloging the library functions that the program calls. A C program that calls
    the `connect` function is creating a network connection. A Windows program that
    calls `RegOpenKey` is accessing the Windows registry. Additional analysis is required,
    however, to gain an understanding of how and why these functions are called.
  prefs: []
  type: TYPE_NORMAL
- en: 'Discovering how a function is called requires learning about the parameters
    associated with the function. Let’s consider a C program that calls the `connect`
    function as part of retrieving an HTML page. To call `connect`, the program needs
    to know the IP address and destination port of the server that is hosting the
    page, which is provided by a library function called `getaddrinfo`. Ghidra recognizes
    this as a library function and adds a comment to the call to provide us with additional
    information in the Listing window, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can obtain more information about this call in several ways. Hovering over
    the abbreviated comment to the right of the instruction shows that Ghidra has
    provided the complete function prototype to help you understand the parameters
    that are being passed in the function call. Hovering over the function name in
    the Symbol Tree displays the function prototype and variables in a pop-up window.
    Alternatively, choosing Edit Function from the right-click menu provides the same
    information in an editable format, as shown in [Figure 8-1](ch08.xhtml#fig8_1).
    If you want even more information, you can then use the Data Type Manager window
    to find information on specific parameters such as the `addrinfo` data type. If
    you had clicked `getaddrinfo` in the preceding listing, you would see that the
    content shown in [Figure 8-1](ch08.xhtml#fig8_1) is replicated within the listing.
    (This is within a thunk function, which is discussed in “[Thunk](ch10.xhtml#ch10sb01)”
    on [page 212](ch10.xhtml#page_212).)
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-1: Edit Function window for* getaddrinfo *function*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, you aren’t required to navigate through the Symbol Tree and Data Type
    Manager windows to make these observations, as the decompiler has already applied
    this information in the Decompiler window. If you look at the Decompiler window,
    you will see that Ghidra has already incorporated member names for the fields
    contained within the structure (`addrinfo`) by using information from loaded type
    libraries. For the same example, in the following excerpt of code from the decompiler,
    you can see that the member names `ai_family` and `ai_socktype` help us understand
    that `local_48` is a structure that is used when getting the information needed
    for `connect`. In this case, the `ai_family` assignment indicates that an IPv4
    address is being used (`2` equates to the symbolic constant `AF_INET`), and `ai_socktype`
    indicates the use of a stream socket (`1` equates to the symbolic constant `SOCK_STREAM`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '### **Recognizing Data Structure Use**'
  prefs: []
  type: TYPE_NORMAL
- en: While primitive data types often fit in a processor’s registers or instruction
    operands, composite data types such as arrays and structures typically require
    more complex instruction sequences in order to access the individual data items
    they contain. Before we can discuss Ghidra’s features for improving the readability
    of code that utilizes complex data types, we need to review what that code looks
    like.
  prefs: []
  type: TYPE_NORMAL
- en: '***Array Member Access***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Arrays* are the simplest composite data structures in terms of memory layout.
    Traditionally, arrays are contiguous blocks of memory that contain consecutive
    elements of the same data type (a homogeneous collection). The size of an array
    is the product of the number of elements in the array and the size of each element.
    Using C notation, the minimum number of bytes consumed by declaring the integer
    array'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: is computed as
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Individual array elements can be accessed by supplying an index value, which
    may be a variable or a constant, as shown in these valid array references:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Assuming, for the sake of example, that `sizeof(int)`is 4 bytes, then the first
    array access ➊ accesses the integer value that lies 80 bytes into the array, while
    the second array access ➋ accesses integers at offsets 0, 4, 8, . . . 96 bytes
    into the array. The offset for the first array access can be computed at compile
    time as `20 * 4`. In most cases, the offset for the second array access must be
    computed at runtime because the value of the loop counter, `i`, is not fixed at
    compile time. Thus, the product `i * 4` is computed on each pass through the loop
    to determine the exact offset into the array.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, how an array element is accessed depends not only on the type of
    index used but also on where the array is allocated within the program’s memory
    space.
  prefs: []
  type: TYPE_NORMAL
- en: '**Globally Allocated Arrays**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When an array is allocated within the global data area of a program (within
    the `.data` or `.bss` section, for example), the compiler knows the base address
    of the array at compile time, which enables the compiler to compute fixed addresses
    for any array element that is accessed using a fixed index. Consider the following
    trivial program, which accesses a global array using both fixed and variable indices.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '**WHAT IS C REALLY EXPECTING?**'
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, we said that C is expecting an integer index as either a variable
    or a constant. In reality, any expression that can be evaluated to or interpreted
    as an integer will do. The general guideline is, “anywhere you can use an integer,
    you can use an expression that evaluates to an integer.” Of course, this is not
    limited to just integers. C is perfectly happy to evaluate any expression you
    provide and try to make it work for the variable type expected. What if the values
    are outside the bounds of the array? You have the makings of numerous exploitable
    vulnerabilities, of course! Values will be read from or written to the resulting
    out-of-bounds memory region, or the program will simply crash if the computed
    target address is not valid within the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we disassemble a stripped version of the corresponding binary, the main
    function contains the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'While this program has only one global variable (the global array), the disassembly
    lines ➊ ➋ ➌ seem to indicate three global variables: `DAT_00301018`, `DAT_0030101c`,
    and `DAT_00301020`, respectively. However, the `LEA` instruction ➎ loads the address
    of a global variable seen previously ➊. In this context, when combined with the
    computation of an offset (`RAX*4`) ➍, and scaled memory access ➏, `DAT_00301018`
    is most likely the base address of a global array. The annotated operand `=>DAT_00301018`
    ➏ provides us with the base of the array into which 40 will be written.'
  prefs: []
  type: TYPE_NORMAL
- en: '**WHAT’S A STRIPPED BINARY?**'
  prefs: []
  type: TYPE_NORMAL
- en: When compilers generate object files, they must include enough information for
    the linker to be able to do its job. One of the linker’s jobs is to resolve references
    between object files, such as a call to a function whose body resides in a different
    file, utilizing information from a compiler-generated symbol. In many cases, the
    linker combines all of the symbol table information from the object files and
    includes the consolidated information in the resulting executable file. This information
    is not necessary for the executable to run properly, but it is very useful from
    a reverse engineering perspective, as Ghidra (and other tools like debuggers)
    can use the symbol table information to recover function and global variable names
    and sizes.
  prefs: []
  type: TYPE_NORMAL
- en: '*Stripping* a binary means removing portions of an executable file that are
    not essential to the runtime operation of the binary. This can be accomplished
    by using the command-line `strip` utility to post-process an executable, or by
    providing build options to the compiler and/or linker (`-s` for `gcc`/`ld`) to
    have them generate a stripped binary themselves. In addition to symbol table information,
    `strip` can remove any debugging symbol information, such as local variable `names`
    and type information, that were embedded in a binary when it was built. Lacking
    symbol information, reverse engineering tools must have algorithms for both identifying
    and naming functions and data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the names assigned by Ghidra, we know that the global array starts
    with the 12 bytes beginning at address `00301018`. During compilation, the compiler
    used the fixed indices (0, 1, 2) to compute the actual addresses of the corresponding
    elements in the array (`00301018`, `0030101c`, and `00301020`), which are referenced
    using the global variables at ➊, ➋, and ➌. Based on the values being moved into
    these locations, we can surmise that we are moving 32-bit integer (`dword`) values
    into this array. If we navigate to the associated data in the listing, we see
    the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The question marks indicate that this array is probably allocated within the
    program’s `.bss` section and that no initialization values are present within
    the file image.
  prefs: []
  type: TYPE_NORMAL
- en: It is easier to recognize an array in disassembly when it is accessed using
    variable indices. When constant indices are used to access global arrays, the
    corresponding array elements appear as global variables in the disassembly. However,
    the use of variable index values reveals the base address of the array at ➎ and
    the size of the individual elements at ➍, because the offset into the array must
    be computed using the index. (Such scaling operations are required to convert
    an integer array index from C to a byte offset for the correct array element in
    assembly language.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Using Ghidra’s type- and array-formatting operations discussed in the previous
    chapter (Data ▸ Create Array), we can format `DAT_000301018` as a three-element
    integer array, yielding disassembly lines with a named array accessed with indices
    rather than offsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The default array name assigned by Ghidra, `INT_ARRAY_00301018`, includes the
    array type as well as the starting address of the array.
  prefs: []
  type: TYPE_NORMAL
- en: '**UPDATING SYMBOL INFORMATION IN COMMENTS**'
  prefs: []
  type: TYPE_NORMAL
- en: As you begin identifying data types, changing symbol names, and so on, you can
    make sure that the valuable comments you have added to your listing don’t become
    outdated, or challenging to follow, by using comment annotations that update automatically.
    The `Symbol` annotation option lets you include references to symbols that will
    be updated as you change the symbols to accurately reflect your findings. (See
    “[Annotations](ch07.xhtml#ch07lev131)” on [page 132](ch07.xhtml#page_132).)
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the Decompiler window before ([Figure 8-2](ch08.xhtml#fig8_2))
    and after ([Figure 8-3](ch08.xhtml#fig8_3)) the array has been created. In [Figure
    8-2](ch08.xhtml#fig8_2), the important warning on line 2 is another clue that
    you might be looking at an array, and the assignment of integer values supports
    the assumption that the array type is integer.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-2: Decompiler view indicating potential array*'
  prefs: []
  type: TYPE_NORMAL
- en: After the integer array is created, the code in the Decompiler window is updated
    to use the new array variable, as shown in [Figure 8-3](ch08.xhtml#fig8_3).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-3: Decompiler view after declaring array type*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stack-Allocated Arrays**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The compiler can’t know the absolute address of an array allocated on the stack
    as a local variable in a function at compile time, so even accesses that use constant
    indices require some computation at runtime. Despite the differences, compilers
    often treat stack-allocated arrays almost identically to globally allocated arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following program is a variation of the previous example that uses a stack-allocated
    array rather than a global array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The address at which `stack_array` will be allocated is unknown at compile
    time, so the compiler cannot precompute the address of `stack_array[2]` as it
    did for `global_array[2]`. The compiler can, however, compute the relative location
    of any element within the array. For example, element `stack_array[2]` begins
    at offset `2*sizeof(int)` from the beginning of the array, and the compiler is
    well aware of this at compile time. If the compiler elects to allocate `stack_array`
    at offset `EBP-0x18` within the stack frame, it can compute `EBP-0x18+2*sizeof(int)`,
    which reduces to `EBP-0x10` at compile time and avoids the need for additional
    arithmetic at runtime to access `stack_array[2]`. This becomes evident in the
    following listing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It is even more difficult to detect this array than the global array. This function
    appears to have six unrelated variables ➊ (`local_c`, `local_10`, `local_14`,
    `local_18`, `local_1c`, and `local_28`), rather than an array of three integers
    and an integer index variable. Two of these locals (`local_1c` and `local_28`)
    are the function’s two parameters, `argc` and `argv`, being saved for later use
    ➋.
  prefs: []
  type: TYPE_NORMAL
- en: 'The use of constant index values tends to hide the presence of a stack-allocated
    array, because you see only assignments to separate local variables ➍. Only the
    multiplication ➎ hints at the existence of an array with individual elements that
    are 4 bytes each. Let’s break down that statement further: `RBP` holds the stack
    frame base pointer address; `RAX*4` is the array index (converted by `atoi` and
    stored in `local_c` ➌) multiplied by the size of an array element; `-0x10` is
    the offset to the start of the array from `RBP`.'
  prefs: []
  type: TYPE_NORMAL
- en: The process to convert local variables to an array is a little different from
    creating an array in the data section of the listing. Because the stack structure
    information is associated with the first address in the function, you cannot select
    a subset of the stack variables. Instead, place the cursor on the variable at
    the start of the array, `local_18`, select the Set Data Type followed by the Array
    option from the right-click context menu, and then specify the number of elements
    in the array. Ghidra will display a warning message about conflict with the local
    variables that we are pulling into the array definition, as shown in [Figure 8-4](ch08.xhtml#fig8_4).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-4: Warning about potential conflict when defining stack array*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you proceed, despite the potential conflict, you will see the array in the
    Listing window, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Even after the array is defined, the decompiler listing in [Figure 8-5](ch08.xhtml#fig8_5)
    doesn’t resemble the original source code. The decompiler has omitted the static
    array assignments because it believes they do not contribute to the result of
    the function. The call to `atoi` and resulting assignment remain because Ghidra
    can’t compute the side effects of calling `atoi`, but Ghidra mistakes the saved
    result of `atoi` as the fourth element of the array (`local_c` in the disassembly,
    and `iVar1` in the decompiler listing).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-5: Decompiler view of function with all stack variables after array
    is defined*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Heap-Allocated Arrays**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Heap-allocated arrays* are allocated using a dynamic memory allocation function
    such as `malloc` (C) or `new` (C++). From the compiler’s perspective, the primary
    difference in dealing with a heap-allocated array is that the compiler must generate
    all references into the array based on the address returned from the memory allocation
    function. The following C program allocates a small array in the program heap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The corresponding disassembly is a little more complex than the two previous
    examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The starting address of the array (returned from `malloc` in the `RAX` register)
    is stored in the local variable `heap_array` ➋. In this example, unlike the previous
    examples, every access to the array begins with reading the contents of `heap_array`
    to obtain the array’s base address. The references to `heap_array[0]`, `heap_array[1]`,
    and `heap_array[2]` require offsets of 0 ➌, 4 ➍, and 8 bytes ➎, respectively.
    The variable index array access `heap_array[idx]` is implemented with multiple
    instructions to compute the offset into the array by multiplying the array index
    by the size of an array element ➏, and adding the result to the base address of
    the array ➐.
  prefs: []
  type: TYPE_NORMAL
- en: 'Heap-allocated arrays have one particularly nice feature: the number of elements
    allocated to the array can be computed from the total size of the array and the
    size of each element. The parameter passed to the memory allocation function (`12`
    passed to `malloc` ➊) tells you the number of bytes allocated to the array. Dividing
    this by the size of an element (4 bytes in this example, as observed from the
    offsets ➌ ➍ ➎ , which step by 4, and the scale factor ➏) tells us the number of
    elements in the array. In this example, a three-element array was allocated.'
  prefs: []
  type: TYPE_NORMAL
- en: The decompiler was also able to recognize the array, as seen in [Figure 8-6](ch08.xhtml#fig8_6).
    (The name of the array pointer, `puVar2`, indicates that it is a pointer to an
    unsigned integer using the prefix `pu`.)
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-6: Decompiler view of heap array function*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this function, unlike the stack-allocated array function, the decompiler
    listing shows the constant index array assignments, even though it would normally
    exclude them because the array is not used in other operations or returned from
    the function. This case is different because the assignments are *not* just manipulating
    stack variables: the stack variable is actually a pointer to memory that `malloc`
    requested from the heap. Writing via that variable does not write to the local
    stack variable but rather uses the stack variable to locate the allocated memory.
    The program may lose the pointer (address of the start of the heap array) when
    the function exits, but the values persist in memory. (This particular example
    is actually a demonstration of a memory leak. While not a good programming practice,
    it does allow us to demonstrate the concept of a heap array.)'
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, arrays are easiest to recognize when a variable is used as an
    index into the array. The array-access operation, which requires the index to
    be scaled by the size of an array element before adding the resulting offset to
    the base address of the array, stands out in a disassembly listing.
  prefs: []
  type: TYPE_NORMAL
- en: '***Structure Member Access***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: C-style structs, referred to here generically as *structures*, group collections
    of (often heterogeneous) data items into a composite data type. In source code,
    the data fields within a structure are accessed by name rather than by index.
    Unfortunately, these informative field names are converted to numeric offsets
    by the compiler, so by the time you are looking at a disassembly, structure field
    access looks remarkably similar to accessing array elements using constant indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following structure definition containing five heterogeneous fields will
    be used in the upcoming examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: When a compiler encounters a structure definition, the compiler maintains a
    running total of the number of bytes consumed by the fields of the structure to
    determine the offset of each field within the structure. The sum of the space
    required to allocate each field within a structure determines the minimum space
    required for the structure. However, you should never assume that a compiler utilizes
    the minimum required space to allocate a structure. By default, compilers align
    structure fields to memory addresses that allow for the most efficient reading
    and writing of those fields. For example, 4-byte integer fields will be aligned
    to offsets that are divisible by four, while 8-byte doubles will be aligned to
    offsets that are divisible by eight. Depending on the composition of the structure,
    the compiler may insert padding bytes to meet alignment requirements, meaning
    the actual size of a structure will be larger than the sum of its component fields.
    The default offsets and resulting structure size for the sample structure can
    be seen in the Default offset column in the comments in the preceding structure
    definition, and they sum to 24 rather than the minimum 19.
  prefs: []
  type: TYPE_NORMAL
- en: Structures can be packed into the minimum required space by using compiler options
    to request specific member alignments. Microsoft C/C++ and GNU `gcc`/`g++` both
    recognize the `pack` pragma for controlling structure field alignment. The GNU
    compilers additionally recognize the `packed` attribute for controlling structure
    alignment on a per-structure basis. Requesting 1-byte alignment for structure
    fields causes compilers to squeeze the structure into the minimum required space.
    The offsets and structure size of the sample structure are found in the Minimum
    offset column. (Note that some processors perform better when data is aligned
    according to its type, while other processors may generate exceptions if data
    is *not* aligned on specific boundaries.)
  prefs: []
  type: TYPE_NORMAL
- en: With these facts in mind, let’s look at how structures are treated in compiled
    code. As with arrays, access to structure members is performed by adding the base
    address of the structure to the offset of the desired member. However, while array
    offsets can be computed at runtime from a provided index value (because each element
    in an array has the same size), structure offsets must be computed at compile
    time and will turn up in compiled code as fixed offsets into the structure, looking
    nearly identical to array references that make use of constant indices.
  prefs: []
  type: TYPE_NORMAL
- en: Creating structures in Ghidra is more involved than creating arrays, so we cover
    that in the next section, after we show several examples of disassembled and decompiled
    structures.
  prefs: []
  type: TYPE_NORMAL
- en: '##### **Globally Allocated Structures**'
  prefs: []
  type: TYPE_NORMAL
- en: 'As with globally allocated arrays, the addresses of globally allocated structures
    are known at compile time. This allows the compiler to compute the address of
    each member of the structure at compile time and eliminates the need to do any
    math at runtime. Consider the following program that accesses a globally allocated
    structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'If this program is compiled with default structure alignment options, we can
    expect to see something like the following when we disassemble it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This disassembly contains no math whatsoever to access the members of the structure,
    and, in the absence of source code, it would not be possible to state with any
    certainty that a structure is being used at all. Because the compiler has performed
    all of the offset computations at compile time, this program appears to reference
    five global variables rather than five fields within a single structure. You should
    be able to note the similarities with the previous example of globally allocated
    arrays using constant index values.
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 8-2](ch08.xhtml#fig8_2), the uniform offsets coupled with the values
    allowed us to surmise (accurately) that we were dealing with an array. In this
    example, we are correct to conclude that we are not dealing with an array because
    the size of the variables is nonuniform (`dword`, `word`, `byte`, `dword`, and
    `qword`, respectively), but we lack sufficient evidence to assert that we are
    dealing with a struct.
  prefs: []
  type: TYPE_NORMAL
- en: '##### **Stack-Allocated Structures**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like stack-allocated arrays, stack-allocated structures are challenging to
    recognize based on stack layout alone, and the decompiler doesn’t provide additional
    insight. Modifying the preceding program to use a stack-allocated structure, declared
    in `main`, yields the following disassembly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Again, no math is performed to access the structure’s fields since the compiler
    can determine the relative offsets for each field within the stack frame at compile
    time, and we are left with the same, potentially misleading picture that five
    individual variables are being used rather than a single variable that happens
    to contain five distinct fields. In reality, `local_28` should be the start of
    a 24-byte structure, and each of the other variables should somehow be formatted
    to reflect the fact that they are fields within the structure.
  prefs: []
  type: TYPE_NORMAL
- en: '**Heap-Allocated Structures**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Heap-allocated structures reveal much more about the size of the structure and
    the layout of its fields. When a structure is allocated in the program heap, the
    compiler has no choice but to generate code to compute the proper field address
    whenever a field is accessed, because the structure’s address is unknown at compile
    time. For globally allocated structures, the compiler is able to compute a fixed
    starting address. For stack-allocated structures, the compiler can compute a fixed
    relationship between the start of the structure and the frame pointer for the
    enclosing stack frame. When a structure has been allocated in the heap, the only
    reference to the structure available to the compiler is the pointer to the structure’s
    starting address.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate heap-allocated structures, we modify the sample program to declare
    a pointer within `main` and assign it the address of a block of memory large enough
    to hold the structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the corresponding disassembly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we can discern the exact size and layout of the structure.
    The structure size can be inferred to be 24 bytes based on the amount of memory
    requested from `malloc` ➊. The structure contains the following fields at the
    indicated offsets:'
  prefs: []
  type: TYPE_NORMAL
- en: A 4-byte (`dword`) field at offset 0 ➋
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A 2-byte (`word`) field at offset 4 ➌
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A 1-byte field at offset 6 ➍
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A 4-byte (`dword`) field at offset 8 ➎
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An 8-byte (`qword`) field at offset 16 ➏
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on the use of floating point instructions (`MOVSD`), we can further deduce
    that the `qword` field is actually a `double`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same program compiled to pack structures with a 1-byte alignment yields
    the following disassembly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The only changes are the smaller structure size (now 19 bytes) and the adjusted
    offsets to account for the realignment of each structure field.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regardless of the alignment used when compiling a program, finding structures
    allocated and manipulated in the program heap is the fastest way to determine
    the size and layout of a given data structure. However, keep in mind that many
    functions will not do you the favor of immediately accessing every member of a
    structure to help you understand the structure’s layout. Instead, you may need
    to follow the use of the pointer to the structure and make note of the offsets
    used whenever that pointer is dereferenced, and eventually piece together the
    complete layout of the structure. In “[Example 3: Automated Structure Creation](ch19.xhtml#ch19lev360)”
    on [page 437](ch19.xhtml#page_437), you’ll see how the decompiler can automate
    this process for you.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Arrays of Structures**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Some programmers say that the beauty of composite data structures is that they
    allow you to build arbitrarily complex structures by nesting smaller structures
    within larger structures: arrays of structures, structures within structures,
    and structures that contain arrays as members, for example. The preceding discussions
    regarding arrays and structures apply just as well to such nested types. As an
    example, consider the following simple program in which `heap_struct` points to
    an array of five `ch8_struct` items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Underneath the hood, accessing `field1` involves multiplying the index value
    by the size of an array element (in this case, the size of the structure) and
    then adding the offset to the desired field. The corresponding disassembly is
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The function allocates 120 bytes ➊ in the heap. The array index in `RAX` is
    multiplied by 24 using a series of operations ➋, ending with `SHL RAX, 3` ➌ before
    being added to the start address for the array ➍. (If it is not readily apparent
    to you that the series of operations starting at ➋ is equivalent to multiplication
    by 24, don’t worry. Code sequences such as this are discussed in [Chapter 20](ch20.xhtml#ch20).)
    Because `field1` is the first member of the struct, no additional offset is required
    in order to generate the final address for the assignment into `field1` ➎.
  prefs: []
  type: TYPE_NORMAL
- en: From these facts, we can deduce the size of an array item (24), the number of
    items in the array (120 / 24 = 5), and the fact that there is a 4-byte (`dword`)
    field at offset 0 within each array element. This short listing does not offer
    enough information to draw any conclusions about how the remaining 20 bytes within
    each structure are allocated to additional fields. The size of the array can be
    even more easily deduced using the same formula from the decompiler listing in
    [Figure 8-7](ch08.xhtml#fig8_7) (0x18 hex is 24 decimal).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-7: Decompiler view of function with heap-allocated struct array*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating Structures with Ghidra**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the preceding chapter, you saw how to use Ghidra’s array-aggregation capabilities
    to collapse long lists of data declarations into a single disassembly line representing
    an array. The next few sections explore Ghidra’s facilities for improving the
    readability of code that manipulates structures. Our goal is to move away from
    cryptic structure references such as `[EDX + 10h]` and toward something more readable
    like `[EDX + ch8_struct.field_e]`.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever you discover that a program is manipulating a data structure, you need
    to decide whether you want to incorporate structure field names into your disassembly
    or whether you can make sense of all the numeric offsets sprinkled throughout
    the listing. In some cases, Ghidra may recognize the use of a structure defined
    as part of the C standard library or the Windows API and use its knowledge of
    the exact layout of the structure to convert numeric offsets into symbolic field
    names. This is the ideal case, as it leaves you with a lot less work to do. We
    will return to this scenario once you understand a little more about how Ghidra
    deals with structure definitions in general.
  prefs: []
  type: TYPE_NORMAL
- en: '***Creating a New Structure***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When Ghidra has no layout knowledge for a structure, you can create the structure
    by selecting the data and using the right-click context menu. When you select
    Data ▸ Create Structure (or use the hotkey SHIFT-[), you will see the Create Structure
    window shown in [Figure 8-8](ch08.xhtml#fig8_8). Since you have highlighted a
    block of data (which could be defined or undefined), Ghidra will try to identify
    existing structures that have a matching format or the same size. You can select
    one of the existing structures from the window or create a new structure. In this
    example, we are using the globally allocated structure sample code discussed previously
    and are creating a new structure called `ch8_struct`. As soon as you click OK,
    the structure becomes an official type in the Data Type Manager window and the
    information is propagated to other CodeBrowser windows.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-8: Create Structure window*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the effect of this creation on the associated CodeBrowser windows,
    starting with the Listing window. As shown earlier in the chapter, the disassembly
    listing gives you few hints that you might be dealing with a structure, because
    the code modifies a series of seemingly unrelated global variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: When you navigate to the associated data items, select the range (`00301020`
    through `00301037`), and create the associated structure, you see the individual
    data items in the structure are now associated with a structure called `ch8_struct``_00301020`,
    and each item in the structure has the name `field_` concatenated with its offset
    from the first element in the structure.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This is just one of the windows that changes with the creation of the structure.
    Recall that the Decompiler window gave us a helpful warning that we might be working
    with a structure or array. After we create the structure, the warning disappears
    and the decompiled code more closely resembles the original C code, as shown in
    [Figure 8-9](ch08.xhtml#fig8_9).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-9: Decompiler view after struct is created*'
  prefs: []
  type: TYPE_NORMAL
- en: '**STATE OF THE UNION**'
  prefs: []
  type: TYPE_NORMAL
- en: A *union* is a construct that is similar to a structure. The major difference
    between structures and unions is that structure fields have unique offsets and
    their own dedicated memory space, whereas union fields all overlap one another
    beginning at offset 0\. The result is that all union fields share the same memory
    space. The Union Editor window in Ghidra looks similar to the Structure Editor
    window, and the functionality is basically the same.
  prefs: []
  type: TYPE_NORMAL
- en: The new structure also now appears as an entry in the Data Type Manager window
    in the CodeBrowser. [Figure 8-10](ch08.xhtml#fig8_10) shows the new entry in the
    Data Type Manager window and the associated window showing all uses of `ch8_struct`.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-10: Newly declared structure in Data Type Manager and References
    windows*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Editing Structure Members***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At this point, Ghidra presents the newly created structure as a contiguous collection
    of undefined bytes with cross-references at each offset accessed by the example
    program, instead of a collection of defined data types (which you have identified
    from the size of each item and the way it is being used). To define the type of
    each field, you can edit the structure from the Listing window by right-clicking
    and selecting the appropriate Data option. Alternatively, you can edit the structure
    from within the Data Type Manager by double-clicking the structure.
  prefs: []
  type: TYPE_NORMAL
- en: If you double-click the newly created structure in the Data Type Manager window
    (shown in [Figure 8-10](ch08.xhtml#fig8_10)), the Structure Editor window (shown
    in [Figure 8-11](ch08.xhtml#fig8_11)) opens to show 24 elements of undefined type,
    all with a length of 1\. To determine the number, sizes, and types of the individual
    elements within the structure, you could study the disassembly, or you could let
    the decompiler listing shown earlier in [Figure 8-9](ch08.xhtml#fig8_9) provide
    the answers.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-11: Structure Editor window*'
  prefs: []
  type: TYPE_NORMAL
- en: The original decompiler listing associated with our newly created structure
    shows that five items are referenced within the same structure, `ch8_struct``_00301020`,
    using field names containing two integers. The first integer represents the offset
    from the base address of the structure. The second shows the number of bytes used,
    which is a good indicator of the size of the item. Using this information (and
    some meaningful field names), you can update the Structure Editor window, as shown
    in [Figure 8-12](ch08.xhtml#fig8_12). The Byte Offset/Component Bits scroll bar
    within the Structure Editor provides a visual representation of the structure.
    When a structure is edited, the Decompiler window (on the left of [Figure 8-12](ch08.xhtml#fig8_12)),
    the Listing window, and other associated windows are also updated.
  prefs: []
  type: TYPE_NORMAL
- en: Because `field_c` is a character, the decompiler converted the integer 30 into
    the ASCII character represented by 30 (0x1e), which is an unprintable control
    character (RS). In the Structure Editor, the padding bytes (indicated by the mnemonic
    `??`) have been included for proper field alignment, and the offsets to each field
    and the overall size (24 bytes) of the structure match the values seen in the
    earlier examples.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-12: Decompiler and Structure Editor windows after editing structure*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Applying Structure Layouts***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You have seen how to use existing structure definitions and create new ones
    to associate existing memory with a particular memory layout. You have also seen
    how that association is propagated through the CodeBrowser windows to make the
    contents clearer. Vague memory references such as `[EBX+8]` become more readable
    by converting numeric structure offsets into symbolic references such as `[EBX+ch8_struct.field_d]`,
    especially because symbolic references can be given meaningful names. Ghidra’s
    use of a hierarchical notation makes it clear exactly what type of structure,
    and exactly which field within that structure, is being accessed.
  prefs: []
  type: TYPE_NORMAL
- en: Ghidra’s library of known structure layouts has been populated with information
    gathered by parsing common C header files. The layout of a structure defines its
    total size, the name and size of each field, and the starting offset of each field
    within the structure. You can use structure layouts even without associated content
    in the data section, which is especially helpful when dealing with structure pointers.
  prefs: []
  type: TYPE_NORMAL
- en: Anytime you encounter a memory reference in the form `[reg+N]` (for example,
    `[RAX+0x12]`), where `reg` is a register name and `N` is a small constant, `reg`
    is being used as a pointer and `N` represents an offset into the memory that `reg`
    points to. This is a common pattern for structure member access, with `reg` pointing
    to the beginning of the structure and `N` selecting the field at structure offset
    `N`. Under some circumstances, Ghidra, with your assistance, can clean up this
    type of memory reference to reflect both the type of structure being pointed to
    and the specific field within that structure that is being referenced.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the 32-bit version of the example from the beginning of the chapter,
    where we were requesting an HTTP page from a server. The request is made by a
    function named `get_page`. In this version of the binary, Ghidra asserts that
    the function receives three stack-allocated parameters. These parameters appear
    in the Listing window as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The Decompiler window shows that `param_3` is used with some offsets in a call
    to `connect`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Tracing through the calling sequence and the return values from the called
    functions, we can conclude that `param_3` is a pointer to an `addrinfo` struct
    and retype `param_3` as an `addrinfo*` (using CTRL-L from the Listing or Decompiler
    window). The decompiled statement using `param_3` will be replaced with the far
    more informative statement shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: You can see that pointer arithmetic has been replaced by structure field references.
    Pointer arithmetic in source code is rarely self-explanatory. Any effort you spend
    updating data types for program variables will be well worth it. You’ll have saved
    your colleagues the time required to deduce the type of `param_3` themselves,
    and you’ll thank yourself upon returning from two weeks at the beach that you
    don’t need to reanalyze the code to relearn the type of that variable that you
    forgot to update.
  prefs: []
  type: TYPE_NORMAL
- en: '**C++ Reversing Primer**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: C++ classes are the object-oriented extensions of C structs, so it is somewhat
    logical to wrap up our discussion of data structures by reviewing the features
    of compiled C++ code. Detailed coverage of C++ is beyond the scope of this book.
    Here, we attempt to cover the highlights and a few of the differences between
    Microsoft’s C++ compiler and GNU’s `g++.`
  prefs: []
  type: TYPE_NORMAL
- en: Remember that a solid, fundamental understanding of the C++ language will assist
    you greatly in understanding compiled C++. Object-oriented concepts such as inheritance
    and polymorphism are difficult enough to master at the source level. Attempting
    to dive into these concepts at the assembly level without understanding them at
    the source level can be an exercise in frustration.
  prefs: []
  type: TYPE_NORMAL
- en: '#### ***The this Pointer***'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `this` pointer is available in all nonstatic C++ member functions. Whenever
    such a function is called, `this` is initialized to point to the object used to
    invoke the function. Consider the following function calls in C++:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In the three calls to `member_func`, `this` takes on the values `&object1`,
    `&object2`, and `p_obj`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: It is easiest to view `this` as a hidden first parameter passed in to all non-static
    member functions. As discussed in [Chapter 6](ch06.xhtml#ch06), the Microsoft
    C++ compiler utilizes the `thiscall` calling convention and passes `this` in the
    `ECX` register (x86) or the `RCX` register (x86-x64). The GNU `g++` compiler treats
    `this` exactly as if it were the first (leftmost) parameter to nonstatic member
    functions. On 32-bit Linux x86, the address of the object used to invoke the function
    is pushed as the topmost item on the stack prior to calling the function. On Linux
    x86-64, `this` is passed in the first register parameter, `RDI`.
  prefs: []
  type: TYPE_NORMAL
- en: From a reverse engineering point of view, moving an address into the `ECX` register
    immediately before a function call is a probable indicator of two things. First,
    the file was compiled using Microsoft’s C++ compiler. Second, the function is
    possibly a member function. When the same address is passed to two or more functions,
    we can conclude that those functions all belong to the same class hierarchy.
  prefs: []
  type: TYPE_NORMAL
- en: Within a function, the use of `ECX` prior to initializing it implies that the
    caller must have initialized `ECX` (recall the discussion of *liveness* from “[Register-Based
    Parameters](ch06.xhtml#ch06sb01)” on [page 113](ch06.xhtml#page_113)) and is a
    possible sign that the function is a member function (though the function may
    simply use the `fastcall` calling convention). Further, when a member function
    passes `this` to additional functions, those functions can be inferred to be members
    of the same class as well.
  prefs: []
  type: TYPE_NORMAL
- en: For code compiled using GNU `g++`, calls to member functions stand out somewhat
    less because `this` looks a lot like any other first parameter. However, any function
    that does not take a pointer as its first argument can certainly be ruled out
    as a member function.
  prefs: []
  type: TYPE_NORMAL
- en: '***Virtual Functions and Vftables***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Virtual functions* enable polymorphic behavior in C++ programs. For each class
    (or subclass through inheritance) that contains virtual functions, the compiler
    generates a table containing pointers to each virtual function in the class. Such
    tables are called *vftables* (also *vtables*). Every instance of a class that
    contains virtual functions is given an additional data member that points to the
    class’s vftable. The *vftable pointer* is allocated as the first data member within
    the class instance, and when an object is created at runtime, its constructor
    function sets its vftable pointer to point at the appropriate vftable. When that
    object invokes a virtual function, the correct function is selected by performing
    a lookup in the object’s vftable. Thus, vftables are the underlying mechanism
    that facilitates runtime resolution of calls to virtual functions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A few examples may help to clarify the use of vftables. Consider the following
    C++ class definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: In this case, `SubClass` inherits from `BaseClass` ➌. `BaseClass` contains four
    virtual functions ➊, while `SubClass` contains five ➍ (four from `BaseClass`,
    two of which it overrides, plus the new `vfunc5`). Within `BaseClass`, `vfunc1`
    is a *pure virtual function*, indicated by `= 0` ➋ in its declaration. Pure virtual
    functions have no implementation in their declaring class and *must* be overridden
    in a subclass before the class is considered concrete. In other words, there is
    no function named `BaseClass::vfunc1`, and until a subclass provides an implementation,
    no objects can be instantiated. `SubClass` provides such an implementation, so
    `SubClass` objects can be created. In object-oriented terms, `BaseClass::vfunc1`
    is an *abstract function*, which makes `BaseClass` an *abstract base class* (that
    is, an incomplete class that cannot be directly instantiated since it is missing
    an implementation for at least one function).
  prefs: []
  type: TYPE_NORMAL
- en: At first glance, `BaseClass` appears to contain two data members, and `SubClass`
    three data members. Recall, however, that any class that contains virtual functions,
    either explicitly or because they are inherited, also contains a vftable pointer.
    As a result, the compiled implementation of `BaseClass` has three data members,
    while instantiated `SubClass` objects have four data members. In each case, the
    first data member is the vftable pointer. Within `SubClass`, the vftable pointer
    is actually inherited from `BaseClass` rather than being introduced specifically
    for `SubClass`. You can see this in the simplified memory layout in [Figure 8-13](ch08.xhtml#fig8_13),
    in which a single `SubClass` object has been dynamically allocated. During the
    creation of the object, the new object’s vftable pointer is initialized to point
    to the correct vftable (`SubClass`’s in this case).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-13: A simple vftable layout*'
  prefs: []
  type: TYPE_NORMAL
- en: The vftable for `SubClass` contains two pointers to functions belonging to `BaseClass`
    (`BaseClass::vfunc2` and `BaseClass::vfunc4`) because `SubClass` does not override
    either of these functions and instead inherits them from `BaseClass`. The vftable
    for `BaseClass` shows how pure virtual functions are handled. Because there is
    no implementation for the pure virtual function `BaseClass::vfunc1`, no address
    is available to store in the `BaseClass` vftable slot for `vfunc1`. In such cases,
    compilers insert the address of an error-handling function, dubbed `purecall`
    in Microsoft libraries and `__cxa_pure_virtual` in GNU libraries. In theory, these
    functions should never be called, but in the event that they are, they cause the
    program to be terminated abnormally.
  prefs: []
  type: TYPE_NORMAL
- en: You must account for the vftable pointer when you manipulate classes within
    Ghidra. Because C++ classes are extensions of C structures, you can use Ghidra’s
    structure definition features to define the layout of C++ classes. With polymorphic
    classes, you must include a vftable pointer as the first field within the class
    as well as account for the vftable pointer in the total size of the object. This
    is most apparent when observing the dynamic allocation of an object using the
    `new` operator, where the size value passed to `new` includes the space needed
    by all explicitly declared fields in the class (and any superclasses) as well
    as any space required for a vftable pointer.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, a `SubClass` object is created dynamically and its
    address saved in a `BaseClass` pointer. The pointer is then passed to a function
    (`call_vfunc`), which uses the pointer to call `vfunc3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Since `vfunc3` is a virtual function and `bc` points to a `SubClass` object,
    the compiler must ensure that `SubClass::vfunc3` is called. The following disassembly
    of a 32-bit, Microsoft C++ version of `call_vfunc` demonstrates how the virtual
    function call is resolved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The vftable pointer (the address of `SubClass`’s vftable) is read from the structure
    and saved in `EDX` ➊. Next, the `this` pointer is moved into `ECX` ➋. Then, the
    vftable is indexed to read the third pointer (the address of `SubClass::vfunc3`
    in this case) into the `EAX` register ➌. Finally, the virtual function is called
    ➍.
  prefs: []
  type: TYPE_NORMAL
- en: The vftable indexing operation ➌ looks very much like a structure reference
    operation. In fact, it is no different, and it is possible to define new structures
    for the class and its vftable (right-click in the Data Type Manager window) and
    then use the defined structures (see [Figure 8-14](ch08.xhtml#fig8_14)) to make
    the disassembly and decompilation more readable.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-14: Data Manager Window showing new* SubClass *and* SubClass_vftable'
  prefs: []
  type: TYPE_NORMAL
- en: The Decompiler window with references to the new structures is shown in [Figure
    8-15](ch08.xhtml#fig8_15).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](Images/fig8-15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 8-15: Decompiler window reflecting defined structures for* SubClass'
  prefs: []
  type: TYPE_NORMAL
- en: 'A class’s vftable is referenced directly in only two circumstances: within
    the class constructor(s) and destructor. When you locate a vftable, you can utilize
    Ghidra’s data cross-referencing capabilities (see [Chapter 9](ch09.xhtml#ch09))
    to quickly locate all constructors and destructors for the associated class.'
  prefs: []
  type: TYPE_NORMAL
- en: '***The Object Life Cycle***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Understanding the mechanism by which objects are created and destroyed can help
    to reveal object hierarchies and nested object relationships as well as quickly
    identify class constructor and destructor functions.
  prefs: []
  type: TYPE_NORMAL
- en: '**WHAT’S A CONSTRUCTOR?**'
  prefs: []
  type: TYPE_NORMAL
- en: A *class constructor function* is an initialization function that is invoked
    when a new object of that class is created. Constructors provide an opportunity
    to initialize variables within the class. The inverse of a constructor, a *destructor*,
    is called when an object goes out of scope or a dynamically allocated object is
    explicitly deleted. Destructor functions perform cleanup activities such as releasing
    resources like open file descriptors and dynamically allocated memory. Properly
    written destructors mitigate the potential for memory leaks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The storage class of an object determines when its constructor is called.^([1](footnotes.xhtml#ch08fn1))
    For global and statically allocated objects (static storage class), constructors
    are called during program startup prior to entry into the program’s `main` function.
    Constructors for stack-allocated objects (automatic storage class) are invoked
    when the object comes into scope within the function in which it is declared.
    In many cases, this will be immediately upon entry to the function in which it
    is declared. However, when an object is declared within a nested block statement,
    its constructor is not invoked until that block is entered, if it is entered at
    all. When an object is allocated dynamically in the program heap, its creation
    is a two-step process: the `new` operator is invoked to allocate the object’s
    memory and then the constructor is invoked to initialize the object. Microsoft
    C++ ensures that the result of `new` is not null prior to invoking the constructor,
    but GNU’s `g++` does not.'
  prefs: []
  type: TYPE_NORMAL
- en: '**WHAT’S NEW?**'
  prefs: []
  type: TYPE_NORMAL
- en: The `new` operator is used for dynamic memory allocation in C++ in much the
    same way that `malloc` is used in C. It is used to allocate memory from the heap
    and allows a program to request space as needed during execution. The `new` operator
    is built into the C++ language, whereas `malloc` is merely a standard library
    function. Remember that C is a subset of C++, so you might see either in a C++
    program. The most notable difference between `malloc` and `new` is that invocations
    of `new` for object types will result in an implicit invocation of the object’s
    constructor, where memory returned by `malloc` is not initialized before it is
    made available to the caller.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a constructor executes, the following sequence of actions takes place:'
  prefs: []
  type: TYPE_NORMAL
- en: If the class has a superclass, the superclass constructor is invoked.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the class has any virtual functions, the vftable pointer is initialized to
    point to the class’s vftable. This may overwrite a vftable pointer that was initialized
    in the superclass constructor, which is exactly the desired behavior.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the class has any data members that are themselves objects, the constructor
    for each of those data members is invoked.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the class constructor is executed. This is the C++ constructor code
    specified by the programmer of the class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From a programmer’s perspective, constructors do not specify a return type or
    allow a value to be returned. Some compilers actually return `this` as a result
    that they may further utilize in the caller, but this is a compiler implementation
    detail and C++ programmers cannot access the returned value.
  prefs: []
  type: TYPE_NORMAL
- en: Destructors, as their name implies, are called at the end of an object’s lifetime.
    For global and static objects, destructors are called by cleanup code that is
    executed after the `main` function terminates. Destructors for stack-allocated
    objects are invoked as the objects go out of scope. Destructors for heap-allocated
    objects are invoked via the `delete` operator immediately before the memory allocated
    to the object is released.
  prefs: []
  type: TYPE_NORMAL
- en: 'The actions performed by destructors mimic those performed by constructors,
    with the exception that they are performed in roughly reverse order:'
  prefs: []
  type: TYPE_NORMAL
- en: If the class has any virtual functions, the vftable pointer for the object is
    restored to point to the vftable for the associated class. This is required in
    case a subclass had overwritten the vftable pointer as part of its creation process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The programmer-specified code for the destructor executes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the class has any data members that are themselves objects, the destructor
    for each of those members is executed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, if the object has a superclass, the superclass destructor is called.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By understanding when superclass constructors and destructors are called, it
    is possible to trace an object’s inheritance hierarchy through the chain of calls
    to its related superclass functions.
  prefs: []
  type: TYPE_NORMAL
- en: '**I THINK YOU ARE OVERLOADED**'
  prefs: []
  type: TYPE_NORMAL
- en: Overloaded functions are functions that share the same name but have different
    parameters. C++ requires that each version of an overloaded function differ from
    every other version in the sequence and/or quantity of parameter types that the
    function receives. In other words, while they share the same function name, each
    function prototype must be unique, and each overloaded function body can be uniquely
    identified within the disassembled binary. This is not to be confused with functions,
    such as `printf`, that take a variable number of arguments but are associated
    with a single function body.
  prefs: []
  type: TYPE_NORMAL
- en: '***Name Mangling***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Also called *name decoration*, *name mangling* is the mechanism C++ compilers
    use to distinguish among overloaded versions of a function. To generate unique,
    internal names for overloaded functions, compilers decorate the function name
    with additional characters that encode various pieces of information about the
    function: the namespace to which the function (or its owning class) belongs (if
    any), the class to which the function belongs (if any), and the parameter sequence
    (type and order) required to call the function.'
  prefs: []
  type: TYPE_NORMAL
- en: Name mangling is a compiler implementation detail for C++ programs and, as such,
    is not part of the C++ language specification. Not unexpectedly, compiler vendors
    have developed their own, often-incompatible conventions for name mangling. Fortunately,
    Ghidra understands the name mangling conventions employed by Microsoft’s C++ compiler
    and GNU `g++` v3 (and later) as well as some other compilers. Ghidra provides
    names of the form `FUN_`address in place of the mangled name. Mangled names do
    carry valuable information regarding the signature of each function, and Ghidra
    includes this information in the Symbol Table window as well as propagating the
    information to the disassembly and other related windows. (To determine the signature
    of a function without a mangled name, you might need to conduct time-consuming
    analysis of the data flowing into and out of the function.)
  prefs: []
  type: TYPE_NORMAL
- en: '***Runtime Type Identification***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: C++ provides operators to determine (`typeid`) and check (`dynamic_cast`) an
    object’s data type at runtime. To support these operations, C++ compilers must
    embed type-specific information, for each polymorphic class, within a program
    binary. When a `typeid` or `dynamic_cast` operation is performed at runtime, library
    routines reference the type-specific information in order to determine the exact
    runtime type of the polymorphic object being referenced. Unfortunately, as with
    name mangling, *Runtime Type Identification (RTTI)* is a compiler implementation
    detail rather than a language issue, and there is no standard means by which compilers
    implement RTTI capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: We will take a brief look at the similarities and differences between the RTTI
    implementations of Microsoft’s C++ compiler and GNU `g++`. Specifically, we’ll
    describe how to locate RTTI information and, from there, how to learn the name
    of the class to which that information pertains. Readers desiring more detailed
    discussion of Microsoft’s RTTI implementation should consult the references listed
    at the end of this chapter. In particular, the references detail how to traverse
    a class’s inheritance hierarchy, including how to trace that hierarchy when multiple
    inheritance is being used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following simple program, which uses polymorphism:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The `print_type` function ➊ prints the type of the object being pointed to by
    the pointer `p`. In this case, it must print `"concrete_class"` since a `concrete``_class`
    object is created in the `main` function ➋. How does `print_type`, and more specifically
    `typeid`, know what type of object `p` is pointing to?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is surprisingly simple. Since every polymorphic object contains a
    pointer to a vftable, compilers leverage that fact by co-locating class-type information
    with the class vftable. Specifically, the compiler places a pointer, immediately
    prior to the class vftable, that points to a structure containing information
    about the class that owns the vftable. In GNU `g++` code, this pointer points
    to a `type_info` structure, which contains a pointer to the name of the class.
    In Microsoft C++ code, the pointer points to a Microsoft `RTTICompleteObjectLocator`
    structure, which in turn contains a pointer to a `TypeDescriptor` structure. The
    `TypeDescriptor` structure contains a character array that specifies the name
    of the polymorphic class.
  prefs: []
  type: TYPE_NORMAL
- en: RTTI information is required only in C++ programs that use the `typeid` or `dynamic_cast`
    operator. Most compilers provide options to disable the generation of RTTI in
    binaries that do not require it; therefore, you should not be surprised if you
    encounter compiled binaries that contain no RTTI information even though vftables
    are present.
  prefs: []
  type: TYPE_NORMAL
- en: For C++ programs built with Microsoft’s C++ compiler, Ghidra contains an RTTI
    analyzer that is enabled by default and that is capable of identifying Microsoft
    RTTI structures, annotating those structures (if present) in the disassembly listing,
    and utilizing class names recovered from those RTTI structures in the Symbol Tree’s
    *Classes* folder. Ghidra has no RTTI analyzer for non-Windows binaries. When Ghidra
    encounters an unstripped, non-Windows binary, if it understands the name mangling
    scheme employed in the binary, then Ghidra utilizes available name information
    to populate the Symbol Tree’s *Classes* folder. If a non-Windows binary has been
    stripped, Ghidra will not be able to automatically recover any class names or
    identify vftables or RTTI information.
  prefs: []
  type: TYPE_NORMAL
- en: '***Inheritance Relationships***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is possible to unravel inheritance relationships by using a compiler’s particular
    implementation of RTTI, but RTTI may not be present when a program does not utilize
    the `typeid` or `dynamic_cast` operators. Lacking RTTI information, what techniques
    can be employed to determine inheritance relationships among C++ classes?
  prefs: []
  type: TYPE_NORMAL
- en: The simplest method to determine an inheritance hierarchy is to observe the
    chain of calls to superclass constructors that are called when an object is created.
    The single biggest hindrance to this technique is the use of inline constructors.
    In C/C++, a function declared as `inline` is usually treated as a macro by the
    compiler, and the code for the function is expanded in place of an explicit function
    call. Inline functions hide the fact that a function is being used, since no assembly
    language call statement will be generated. This makes it challenging to understand
    that a superclass constructor has in fact been called.
  prefs: []
  type: TYPE_NORMAL
- en: 'The analysis and comparison of vftables can also reveal inheritance relationships.
    For example, in comparing the vftables shown in [Figure 8-14](ch08.xhtml#fig8_14),
    we note that the vftable for `SubClass` contains two of the same pointers that
    appear in the vftable for `BaseClass`, and we conclude that `BaseClass` and `SubClass`
    must be related in some way. To understand which one is the base class and which
    one is the subclass, we can apply the following guidelines, singly or in combination:'
  prefs: []
  type: TYPE_NORMAL
- en: When two vftables contain the same number of entries, the two corresponding
    classes *may* be involved in an inheritance relationship.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the vftable for class X contains more entries than the vftable for class
    Y, class X *may* be a subclass of class Y.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When the vftable for class X contains entries that are also found in the vftable
    for class Y, then one of the following relationships must exist: X is a subclass
    of Y, Y is a subclass of X, or X and Y are both subclasses of a common superclass
    Z.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the vftable for class X contains entries that are also found in the vftable
    for class Y and the vftable for class X contains at least one `purecall` entry
    that is not also present in the corresponding vftable entry for class Y, then
    class Y is likely to be a subclass of class X.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the preceding list is by no means all-inclusive, we can use these guidelines
    to deduce the relationship between `BaseClass` and `SubClass` in [Figure 8-14](ch08.xhtml#fig8_14).
    In this case, the last three rules all apply, but the last rule specifically leads
    us to conclude, based on vftable analysis alone, that `SubClass` inherits from
    `BaseClass`.
  prefs: []
  type: TYPE_NORMAL
- en: '***C++ Reverse Engineering References***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Several excellent references exist on reverse engineering compiled C++.^([2](footnotes.xhtml#ch08fn2))
    While many of the details in each of these articles apply specifically to programs
    compiled using Microsoft’s C++ compiler, many of the concepts apply equally to
    programs compiled using other C++ compilers.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can expect to encounter complex data types in all but the most trivial programs.
    Understanding how data within data structures is accessed and knowing how to recognize
    clues to the layout of those data structures is an essential reverse engineering
    skill. Ghidra provides a wide variety of features designed specifically to deal
    with data structures. Familiarity with these features will greatly enhance your
    ability to comprehend what data is being manipulated and spend more time understanding
    how and why that data is being manipulated. In the next chapter, we continue our
    discussion of Ghidra’s basic capabilities with an in-depth look at cross-references.
  prefs: []
  type: TYPE_NORMAL
