<html><head></head><body>
<h2 class="h2" id="ch08"><span epub:type="pagebreak" id="page_73"/><strong><span class="big">8</span><br/>THE PRIOR, LIKELIHOOD, AND POSTERIOR OF BAYES’ THEOREM</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">Now that we’ve covered how to derive Bayes’ theorem using spatial reasoning, let’s examine how we can use Bayes’ theorem as a probability tool to logically reason about uncertainty. In this chapter, we’ll use it to calculate and quantify how likely our belief is, given our data. To do so, we’ll use the three parts of the theorem—the posterior probability, likelihood, and prior probability—all of which will come up frequently in your adventures with Bayesian statistics and probability.</p>&#13;
<h3 class="h3" id="ch08lev1sec1"><span epub:type="pagebreak" id="page_74"/><strong>The Three Parts</strong></h3>&#13;
<p class="noindent">Bayes’ theorem allows us to quantify exactly how much our observed data changes our beliefs. In this case, what we want to know is: <em>P</em>(belief | data). In plain English, we want to quantify how strongly we hold our beliefs given the data we’ve observed. The technical term for this part of the formula is the <em>posterior probability</em>, and it’s what we’ll use Bayes’ theorem to solve for.</p>&#13;
<p class="indent">To solve for the posterior, we need the next part: the probability of the data given our beliefs about the data, or <em>P</em>(data | belief). This is known as the <em>likelihood</em>, because it tells us how likely the data is given our belief.</p>&#13;
<p class="indent">Finally, we want to quantify how likely our initial belief is in the first place, or <em>P</em>(belief). This part of Bayes’ theorem is called the <em>prior probability</em>, or simply “the prior,” because it represents the strength of our belief before we see the data. The likelihood and the prior combine to produce a posterior. Typically we need to use the probability of the data, <em>P</em>(data), in order to normalize our posterior so it accurately reflects a probability from 0 to 1. However, in practice, we don’t always need <em>P</em>(data), so this value doesn’t have a special name.</p>&#13;
<p class="indent">As you know by now, we refer to our belief as a hypothesis, <em>H</em>, and we represent our data with the variable <em>D</em>. <a href="ch08.xhtml#ch08fig01">Figure 8-1</a> shows each part of Bayes’ theorem.</p>&#13;
<div class="image"><a id="ch08fig01"/><img alt="Image" src="../images/08fig01.jpg"/></div>&#13;
<p class="figcap"><em>Figure 8-1: The parts of Bayes’ theorem</em></p>&#13;
<p class="indent">In this chapter, we’ll investigate a crime, combining these pieces to reason about the situation.</p>&#13;
<h3 class="h3" id="ch08lev1sec2"><strong>Investigating the Scene of a Crime</strong></h3>&#13;
<p class="noindent">Let’s suppose you come home from work one day and find your window broken, your front door open, and your laptop missing. Your first thought is probably “I’ve been robbed!” But how did you come to this conclusion, and more importantly, how can you quantify this belief?</p>&#13;
<p class="indent">Your immediate hypothesis is that you have been robbed, so <em>H</em> = I’ve been robbed. We want a probability that describes how likely it is that you’ve been robbed, so the posterior we want to solve for given our data is:</p>&#13;
<p class="equ"><em>P</em>(robbed | broken window, open front door, missing laptop)</p>&#13;
<p class="indent">To solve this problem, we’ll fill in the missing pieces from Bayes’ theorem.</p>&#13;
<h4 class="h4" id="ch08lev2sec1"><span epub:type="pagebreak" id="page_75"/><strong><em>Solving for the Likelihood</em></strong></h4>&#13;
<p class="noindent">First, we need to solve for the likelihood, which in this case is the probability that the same evidence would have been observed if you were in fact robbed—in other words, how closely the evidence lines up with the hypothesis:</p>&#13;
<p class="equ"><em>P</em>(broken window, open front door, missing laptop | robbed)</p>&#13;
<p class="indent">What we’re asking is, “If you were robbed, how likely is it that you would see the evidence you saw here?” You can imagine a wide range of scenarios where not all of this evidence was present at a robbery. For example, a clever thief might have picked the lock on your door, stolen your laptop, then locked the door behind them and not needed to break a window. Or they might have just smashed the window, taken the laptop, and then climbed right back out the window. The evidence we’ve seen seems intuitively like it would be pretty common at the scene of a robbery, so we’ll say there’s a 3/10 probability that if you were robbed, you would come home and find this evidence.</p>&#13;
<p class="indent">It’s important to note that, even though we’re making a guess in this example, we could also do some research to get a better estimate. We could go to the local police department and ask for statistics about evidence at crime scenes involving robbery, or read through news reports of recent robberies. This would give us a more accurate estimate for the likelihood that if you were robbed you would see this evidence.</p>&#13;
<p class="indent">The incredible thing about Bayes’ theorem is that we can use it both for organizing our casual beliefs and for working with large data sets of very exact probabilities. Even if you don’t think 3/10 is a good estimate, you can always go back to the calculations—as we will do—and see how the value changes given a different assumption. For example, if you think that the probability of seeing this evidence given a robbery is just 3/100, you can easily go back and plug in those numbers instead. Bayesian statistics lets people disagree about beliefs in a measurable way. Because we are dealing with our beliefs in a quantitative way, you can recalculate everything we do in this chapter to see if this different probability has a substantial impact on any of the final outcomes.</p>&#13;
<h4 class="h4" id="ch08lev2sec2"><strong><em>Calculating the Prior</em></strong></h4>&#13;
<p class="noindent">Next, we need to determine the probability that you would get robbed at all. This is our prior. Priors are extremely important, because they allow us to use background information to adjust a likelihood. For example, suppose the scene described earlier happened on a deserted island where you are the only inhabitant. In this case, it would be nearly impossible for you to get robbed (by a human, at least). In another example, if you owned a home in a neighborhood with a high crime rate, robberies might be a frequent occurrence. For simplicity, let’s set our prior for being robbed as:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0075-01.jpg"/></div>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_76"/>Remember, we can always adjust these figures later given different or additional evidence.</p>&#13;
<p class="indent">We have nearly everything we need to calculate the posterior; we just need to normalize the data. Before moving on, then, let’s look at the unnormalized posterior:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0076-01.jpg"/></div>&#13;
<p class="indent">This value is incredibly small, which is surprising since intuition tells us that the probability of your house being robbed given the evidence you observed seems very, very high. But we haven’t yet looked at the probability of observing our evidence.</p>&#13;
<h4 class="h4" id="ch08lev2sec3"><strong><em>Normalizing the Data</em></strong></h4>&#13;
<p class="noindent">What’s missing from our equation is the probability of the data you observed whether or not you were robbed. In our example, this is the probability that you observe that your window is broken, the door is open, and your laptop is missing <em>all at once</em>, regardless of the cause. As of now, our equation looks like this:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0076-02.jpg"/></div>&#13;
<p class="indent">The reason the probability in the numerator is so low is that we haven’t normalized it with the probability that you would find this strange evidence.</p>&#13;
<p class="indent">We can see how our posterior changes as we change our <em>P</em>(<em>D</em>) in <a href="ch08.xhtml#ch08tab01">Table 8-1</a>.</p>&#13;
<p class="tabcap" id="ch08tab01"><strong>Table 8-1:</strong> How the <em>P</em>(<em>D</em>) Affects the Posterior</p>&#13;
<table class="topbot-d">&#13;
<colgroup>&#13;
<col style="width:60%"/>&#13;
<col style="width:40%"/>&#13;
</colgroup>&#13;
<thead>&#13;
<tr>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong><em>P</em>(<em>D</em>)</strong></p></td>&#13;
<td class="table-h" style="vertical-align: top;"><p class="tab_th"><strong>Posterior</strong></p></td>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.050</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.006</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.010</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.030</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.005</p></td>&#13;
<td class="table-b" style="vertical-align: top;"><p class="taba">0.060</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba">0.001</p></td>&#13;
<td class="table-ba" style="vertical-align: top;"><p class="taba">0.300</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
<p class="indent">As the probability of our data decreases, our posterior probability increases. This is because as the data we observe becomes increasingly unlikely, a typically unlikely explanation does a better job of explaining the event (see <a href="ch08.xhtml#ch08fig02">Figure 8-2</a>).</p>&#13;
<div class="image"><span epub:type="pagebreak" id="page_77"/><a id="ch08fig02"/><img alt="Image" src="../images/08fig02.jpg"/></div>&#13;
<p class="figcap"><em>Figure 8-2: As the probability of the data decreases, the posterior probability increases.</em></p>&#13;
<p class="indent">Consider this extreme example: the only way your friend could become a millionaire is if they won the lottery or inherited money from some family member they didn’t know existed. Your friend becoming a millionaire is therefore shockingly unlikely. However, you find out that your friend <em>did</em> become a millionaire. The possibility that your friend won the lottery then becomes much more likely, because it is one of the only two ways they could have become a millionaire.</p>&#13;
<p class="indent">Being robbed is, of course, only one possible explanation for what you observed, and there are many more explanations. However, if we don’t know the probability of the evidence, we can’t figure out how to normalize all these other possibilities. So what is our <em>P</em>(<em>D</em>)? That’s the tricky part.</p>&#13;
<p class="indent">The common problem with <em>P</em>(<em>D</em>) is that it’s very difficult to accurately calculate in many real-world cases. With every other part of the formula—even though we just guessed at a value for this exercise—we can collect real data to provide a more concrete probability. For our prior, <em>P</em>(robbed), we might simply look at historical crime data and pin down a probability that a given house on your street would be robbed any given day. Likewise, we could, theoretically, investigate past robberies and come up with a more accurate likelihood for observing the evidence you did given a robbery. But how could we ever really even guess at <em>P</em>(broken window,open front door,missing laptop)?</p>&#13;
<p class="indent">Instead of researching the probability of the data you observed, we could try to calculate the probabilities of all other possible events that could explain your observations. Since they must sum to 1, we could work backward and find <em>P</em>(<em>D</em>). But for the case of this particular evidence, there’s a virtually limitless number of possibilities.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_78"/>We’re a bit stuck without <em>P</em>(<em>D</em>). In <a href="ch06.xhtml#ch06">Chapters 6</a> and <a href="ch07.xhtml#ch07">7</a>, where we calculated the probability that a customer service rep was male and the probability of choosing different colored LEGO studs, respectively, we had plenty of information about <em>P</em>(<em>D</em>). This allowed us to come up with an exact probability of our belief in our hypothesis given what we observed. Without <em>P</em>(<em>D</em>) we cannot come up with a value for <em>P</em>(robbed | broken window,open front door,missing laptop). However, we’re not completely lost.</p>&#13;
<p class="indent">The good news is that in some cases we don’t need to explicitly know <em>P</em>(<em>D</em>), because we often just want to <em>compare</em> hypotheses. In this example, we’ll compare how likely it is that you were robbed with another possible explanation. We can do this by looking at the ratio of our unnormalized posterior distributions. Because the <em>P</em>(<em>D</em>) would be a constant, we can safely remove it without changing our analysis.</p>&#13;
<p class="indent">So, instead of calculating the <em>P</em>(<em>D</em>), for the remainder of this chapter we’ll develop an alternative hypothesis, calculate its posterior, and then compare it to the posterior from our original hypothesis. While this means we can’t come up with an exact probability of being robbed as the only possible explanation for the evidence you observed, we can still use Bayes’ theorem to play detective and investigate other possibilities.</p>&#13;
<h3 class="h3" id="ch08lev1sec3"><strong>Considering Alternative Hypotheses</strong></h3>&#13;
<p class="noindent">Let’s come up with another hypothesis to compare with our original one. Our new hypothesis consists of three events:</p>&#13;
<ol>&#13;
<li class="noindent">A neighborhood kid hit a baseball through the front window.</li>&#13;
<li class="noindent">You left your door unlocked.</li>&#13;
<li class="noindent">You forgot that you brought your laptop to work and it’s still there.</li>&#13;
</ol>&#13;
<p class="indent">We’ll refer to each of these explanations simply by its number in our list, and refer to them collectively as <em>H</em><sub>2</sub> so that <em>P</em>(<em>H</em><sub>2</sub>) = <em>P</em>(1,2,3). Now we need to solve for the likelihood and prior of this data.</p>&#13;
<h4 class="h4" id="ch08lev2sec4"><strong><em>The Likelihood for Our Alternative Hypothesis</em></strong></h4>&#13;
<p class="noindent">Recall that, for our likelihood, we want to calculate the probability of what you observed given our hypothesis, or <em>P</em>(<em>D</em> | <em>H</em><sub>2</sub>). Interestingly—and logically, as you’ll see—the likelihood for this explanation turns out to be 1: <em>P</em>(<em>D</em> | <em>H</em><sub>2</sub>) = 1</p>&#13;
<p class="indent">If all the events in our hypothesis did happen, then your observations of a broken window, unlocked door, and missing laptop would be certain.</p>&#13;
<h4 class="h4" id="ch08lev2sec5"><strong><em>The Prior for Our Alternative Hypothesis</em></strong></h4>&#13;
<p class="noindent">Our prior represents the possibility of all three events happening. This means we need to first work out the probability of each of these events and then use the product rule to determine the prior. For this example, we’ll assume that each of these possible outcomes is conditionally independent.</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_79"/>The first part of our hypothesis is that a neighborhood kid hit a baseball through the front window. While this is common in movies, I’ve personally never heard of it happening. I have known far more people who have been robbed, though, so let’s say that a baseball being hit through the window is half as likely as the probability of getting robbed we used earlier:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0079-01.jpg"/></div>&#13;
<p class="indent">The second part of our hypothesis is that you left the door unlocked. This is fairly common; let’s say this happens about once a month, so:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0079-02.jpg"/></div>&#13;
<p class="indent">Finally, let’s look at leaving your laptop at work. While bringing a laptop to work and leaving it there might be common, completely forgetting you took it in the first place is less common. Maybe this happens about once a year:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0079-03.jpg"/></div>&#13;
<p class="indent">Since we’ve given each of these pieces of <em>H</em><sub>2</sub> a probability, we can now calculate our prior probability by applying the product rule:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0079-04.jpg"/></div>&#13;
<p class="indent">As you can see, the prior probability of all three events happening is extremely low. Now we need a posterior for each of our hypotheses to compare.</p>&#13;
<h4 class="h4" id="ch08lev2sec6"><strong><em>The Posterior for Our Alternative Hypothesis</em></strong></h4>&#13;
<p class="noindent">We know that our likelihood, <em>P</em>(<em>D</em> | <em>H</em><sub>2</sub>), equals 1, so if our second hypothesis were to be true, we would be certain to see our evidence. Without a prior probability in our second hypothesis, it looks like the posterior probability for our new hypothesis will be much stronger than it is for our original hypothesis that you were robbed (since we aren’t as likely to see the data even if we were robbed). We can now see how the prior radically alters our unnormalized posterior probability:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0079-05.jpg"/></div>&#13;
<p class="indent">Now we want to compare our posterior beliefs as well as the strength of our hypotheses with a ratio. You’ll see that we don’t need a <em>P</em>(<em>D</em>) to do this.</p>&#13;
<h3 class="h3" id="ch08lev1sec4"><span epub:type="pagebreak" id="page_80"/><strong>Comparing Our Unnormalized Posteriors</strong></h3>&#13;
<p class="noindent">First, we want to compare the ratio of the two posteriors. A ratio tells us how many times more likely one hypothesis is than the other. We’ll define our original hypothesis as <em>H</em><sub>1</sub>, and the ratio looks like this:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0080-01.jpg"/></div>&#13;
<p class="indent">Next let’s expand this using Bayes’ theorem for each of these. We’ll write Bayes’ theorem as <em>P</em>(<em>H</em>) × <em>P</em>(<em>D</em> | <em>H</em>) × 1/<em>P</em>(<em>D</em>) to make the formula easier to read in this context:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0080-02.jpg"/></div>&#13;
<p class="indent">Notice that both the numerator and denominator contain 1/<em>P</em>(<em>D</em>), which means we can remove that and maintain the ratio. This is why <em>P</em>(<em>D</em>) doesn’t matter when we compare hypotheses. Now we have a ratio of the unnormalized posteriors. Because the posterior tells us how strong our belief is, this ratio of posteriors tells us how many times better <em>H</em><sub>1</sub> explains our data than <em>H</em><sub>2</sub> without knowing <em>P</em>(<em>D</em>). Let’s cancel out the <em>P</em>(<em>D</em>) and plug in our numbers:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0080-03.jpg"/></div>&#13;
<p class="indent">What this means is that <em>H</em><sub>1</sub> explains what we observed 6,570 times better than <em>H</em><sub>2</sub>. In other words, our analysis shows that our original hypothesis (<em>H</em><sub>1</sub>) explains our data much, much better than our alternate hypothesis (<em>H</em><sub>2</sub>). This also aligns well with our intuition—given the scene you observed, a robbery certainly sounds like a more likely assessment.</p>&#13;
<p class="indent">We’d like to express this property of the unnormalized posterior mathematically to be able to use it for comparison. For that, we use the following version of Bayes’ theorem, where the symbol ∝ means “proportional to”:</p>&#13;
<p class="equ"><em>P</em>(<em>H</em> | <em>D</em>) ∝ <em>P</em>(<em>H</em>) × <em>P</em>(<em>D</em> | <em>H</em>)</p>&#13;
<p class="indent">We can read this as: “The posterior—that is, the probability of the hypothesis given the data—is <em>proportional to</em> the prior probability of <em>H</em> multiplied by the probability of the data given <em>H</em>.”</p>&#13;
<p class="indent">This form of Bayes’ theorem is extremely useful whenever we want to compare the probability of two ideas but can’t easily calculate <em>P</em>(<em>D</em>). We <span epub:type="pagebreak" id="page_81"/>cannot come up with a meaningful value for the probability of our hypothesis in isolation, but we’re still using a version of Bayes’ theorem to compare hypotheses. Comparing hypotheses means that we can always see exactly how much stronger one explanation of what we’ve observed is than another.</p>&#13;
<h3 class="h3" id="ch08lev1sec5"><strong>Wrapping Up</strong></h3>&#13;
<p class="noindent">This chapter explored how Bayes’ theorem provides a framework for modeling our beliefs about the world, given data that we have observed. For Bayesian analysis, Bayes’ theorem consists of three major parts: the posterior probability, <em>P</em>(<em>H</em> | <em>D</em>); the prior probability, <em>P</em>(<em>H</em>); and the likelihood, <em>P</em>(<em>D</em> | <em>H</em>).</p>&#13;
<p class="indent">The data itself, or <em>P</em>(<em>D</em>), is notably absent from this list, because we often won’t need it to perform our analysis if all we’re worried about is comparing beliefs.</p>&#13;
<h3 class="h3" id="ch08lev1sec6"><strong>Exercises</strong></h3>&#13;
<p class="noindent">Try answering the following questions to see if you have a solid understanding of the different parts of Bayes’ Theorem. The solutions can be found at <em><a href="https://nostarch.com/learnbayes/">https://nostarch.com/learnbayes/</a></em>.</p>&#13;
<ol>&#13;
<li class="noindent">As mentioned, you might disagree with the original probability assigned to the likelihood:&#13;
<div class="equ-image"><img alt="Image" src="../images/f0081-01.jpg"/></div>&#13;
<p class="noindent">How much does this change our strength in believing <em>H</em><sub>1</sub> over <em>H</em><sub>2</sub>?</p></li>&#13;
<li class="noindent">How unlikely would you have to believe being robbed is—our prior for <em>H</em><sub>1</sub>—in order for the ratio of <em>H</em><sub>1</sub> to <em>H</em><sub>2</sub> to be even?<span epub:type="pagebreak" id="page_82"/></li>&#13;
</ol>&#13;
</body></html>