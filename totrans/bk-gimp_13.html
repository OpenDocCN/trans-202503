<html><head></head><body><div class="chapter" title="Chapter&#xA0;7.&#xA0;Image Preprocessing"><div class="titlepage"><div><div><h1 class="title"><a id="image_preprocessing"/>Chapter 7. Image Preprocessing</h1></div></div></div><p><a id="iddle1030" class="indexterm"/><a id="iddle1759" class="indexterm"/><a id="iddle1814" class="indexterm"/><a id="iddle2092" class="indexterm"/><a id="iddle3208" class="indexterm"/><a id="iddle3305" class="indexterm"/><a id="iddle3456" class="indexterm"/><a id="iddle4320" class="indexterm"/><a id="iddle4621" class="indexterm"/><a id="iddle4637" class="indexterm"/><a id="iddle4639" class="indexterm"/>Preprocessing is most commonly used in scientific imaging to remove noise and distortions from an image prior to analyzing its meaningful content. Scientists preprocess satellite images, for example, to remove interference like atmospheric debris and clouds before using the images for research. Even if you’re not a scientist, you may want to preprocess your images, since these techniques can help you correct distortions, improve color balance, and enhance visibility.</p></div>
<div class="sect1" title="7.1 Tutorial: Extracting Information from a Picture"><div class="titlepage"><div><div><h1 class="title"><a id="sevendot1_tutorial_extracting_informatio"/>7.1 Tutorial: Extracting Information from a Picture</h1></div></div></div><p>So, how do you separate noise from the meaningful elements in a picture? One way is to gather information about the image, via histograms, to see if there’s distortion in any of the channels. The image we’ll use in this tutorial isn’t particularly interesting, but it is representative of the problems you may encounter when dealing with badly taken photographs. As you can see in <a class="xref" href="ch07s01.html#initial_photograph-id00073" title="Figure 7-1. The initial photograph">Figure 7-1</a>, the picture’s quality is very poor. The photograph was taken through a closed window, in poor lighting, and with the camera’s automatic settings.</p><div class="figure"><a id="initial_photograph-id00073"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00503"/><img src="httpatomoreillycomsourcenostarchimages1454932.png.jpg" alt="The initial photograph"/></div></div><p class="title">Figure 7-1. The initial photograph</p></div><div class="sect2" title="Dynamics Extension"><div class="titlepage"><div><div><h2 class="title"><a id="dynamics_extension"/>Dynamics Extension</h2></div></div></div><p>Begin by gathering information on the image dynamics, such as the ratio between the smallest and largest values in various channels. The combined histograms shown in <a class="xref" href="ch07s01.html#histogram_for_the_initial_photograph" title="Figure 7-2. The histogram for the initial photograph">Figure 7-2</a> are a way to visualize the image dynamics. Open them via <span class="strong"><strong>Image: Colors &gt; Info &gt; Histogram</strong></span>, and change the C<span class="smaller">HANNEL</span> to RGB. The three channels—Red, Green, and Blue—are shown in the same graph in their corresponding colors. The colors in the areas where the histograms superimpose are additive. A position on the horizontal axis represents a specific value between 0 and 255. The height of the histogram (the vertical axis) represents the number of pixels with that value.</p><div class="figure"><a id="histogram_for_the_initial_photograph"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00504"/><img src="httpatomoreillycomsourcenostarchimages1454934.png.jpg" alt="The histogram for the initial photograph"/></div></div><p class="title">Figure 7-2. The histogram for the initial photograph</p></div><div class="figure"><a id="meaningful_part_of_the_histogram"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00505"/><img src="httpatomoreillycomsourcenostarchimages1454936.png.jpg" alt="The meaningful part of the histogram"/></div></div><p class="title">Figure 7-3. The meaningful part of the histogram</p></div><div class="figure"><a id="after_equalizing"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00506"/><img src="httpatomoreillycomsourcenostarchimages1454938.png.jpg" alt="After equalizing"/></div></div><p class="title">Figure 7-4. After equalizing</p></div><p><a id="iddle2324" class="indexterm"/><a id="iddle3306" class="indexterm"/><a id="iddle5209" class="indexterm"/><a id="iddle5558" class="indexterm"/><a id="iddle5825" class="indexterm"/>Move the small triangles under the horizontal grayscale bar to frame the meaningful interval of values. <a class="xref" href="ch07s01.html#meaningful_part_of_the_histogram" title="Figure 7-3. The meaningful part of the histogram">Figure 7-3</a> shows that almost no pixels have a value less than 65 or greater than 173. In fact, 99.1 percent of the pixels are in the framed interval, which explains why the image is dull and hazy.</p><div class="figure"><a id="histogram_after_equalization"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00507"/><img src="httpatomoreillycomsourcenostarchimages1454940.png.jpg" alt="The histogram after equalization"/></div></div><p class="title">Figure 7-5. The histogram after equalization</p></div><div class="figure"><a id="after_stretching_the_contrast"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00508"/><img src="httpatomoreillycomsourcenostarchimages1454942.png.jpg" alt="After stretching the contrast"/></div></div><p class="title">Figure 7-6. After stretching the contrast</p></div><p>Extending the dynamic range is fairly easy with the tools available in GIMP. The simplest one is <span class="strong"><strong>Image: Colors &gt; Auto &gt; Equalize</strong></span>, which automatically stretches the dynamic range in each channel to span the entire available range. <a class="xref" href="ch07s01.html#after_equalizing" title="Figure 7-4. After equalizing">Figure 7-4</a> shows the result, and <a class="xref" href="ch07s01.html#histogram_after_equalization" title="Figure 7-5. The histogram after equalization">Figure 7-5</a> shows the corresponding histogram. Because the image has only slightly more than a hundred different values, and the range has 255 values, extending the existing values over the full range leaves a lot of values unrepresented, which explains the strange “comb” shape.</p><p>In the resulting image (<a class="xref" href="ch07s01.html#after_equalizing" title="Figure 7-4. After equalizing">Figure 7-4</a>), you see the squirrel is more visible, but the color distortions in the image have been exaggerated.</p><p>The same menu contains other automatic tools. For example, <a class="xref" href="ch07s01.html#after_stretching_the_contrast" title="Figure 7-6. After stretching the contrast">Figure 7-6</a> shows the image and its histograms after we used <span class="strong"><strong>Image: Colors &gt; Auto &gt; Stretch Contrast</strong></span>. You could also <a id="iddle1182" class="indexterm"/><a id="iddle1425" class="indexterm"/><a id="iddle2025" class="indexterm"/><a id="iddle2045" class="indexterm"/><a id="iddle3675" class="indexterm"/><a id="iddle3931" class="indexterm"/><a id="iddle3990" class="indexterm"/><a id="iddle4630" class="indexterm"/><a id="iddle4633" class="indexterm"/><a id="iddle4640" class="indexterm"/><a id="iddle5509" class="indexterm"/><a id="iddle5519" class="indexterm"/><a id="iddle5616" class="indexterm"/><a id="iddle5660" class="indexterm"/><a id="iddle5928" class="indexterm"/>try <span class="strong"><strong>Image: Colors &gt; Auto &gt; Normalize</strong></span>, which gives a similar result.</p><div class="figure"><a id="after_using_auto_in_the_levels_tool"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00509"/><img src="httpatomoreillycomsourcenostarchimages1454944.png.jpg" alt="After using Auto in the Levels tool"/></div></div><p class="title">Figure 7-7. After using Auto in the Levels tool</p></div><div class="figure"><a id="extracting_the_rgb_channels"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00510"/><img src="httpatomoreillycomsourcenostarchimages1454946.png.jpg" alt="Extracting the RGB channels"/></div></div><p class="title">Figure 7-8. Extracting the RGB channels</p></div><p>Pressing the A<span class="smaller">UTO</span> button in the Levels tool yields the image shown in <a class="xref" href="ch07s01.html#after_using_auto_in_the_levels_tool" title="Figure 7-7. After using Auto in the Levels tool">Figure 7-7</a>. You can get a similar result by using <span class="strong"><strong>Image: Colors &gt; Curves</strong></span> to manipulate the curves in each color channel and suppress high and low values, which are not present in this photograph.</p></div><div class="sect2" title="Histogram Modification"><div class="titlepage"><div><div><h2 class="title"><a id="histogram_modification"/>Histogram Modification</h2></div></div></div><p>The histograms you saw in the preceding section are not very useful because they are crammed into one window, and their significance is not obvious in the image. A better way to visualize the three channels is to use <span class="strong"><strong>Image: Colors &gt; Components &gt; Decompose</strong></span>. In the dialog shown in <a class="xref" href="ch07s01.html#extracting_the_rgb_channels" title="Figure 7-8. Extracting the RGB channels">Figure 7-8</a>, choose RGB to decompose the image into its three RGB channels. A new image with three grayscale layers, one for each channel, is created. In the Histogram window, choose the Value channel, which is done automatically because the image has no color or transparency.</p><div class="figure"><a id="red_channel"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00511"/><img src="httpatomoreillycomsourcenostarchimages1454948.png.jpg" alt="The red channel"/></div></div><p class="title">Figure 7-9. The red channel</p></div><div class="figure"><a id="green_channel"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00512"/><img src="httpatomoreillycomsourcenostarchimages1454950.png.jpg" alt="The green channel"/></div></div><p class="title">Figure 7-10. The green channel</p></div><div class="figure"><a id="blue_channel"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00513"/><img src="httpatomoreillycomsourcenostarchimages1454952.png.jpg" alt="The blue channel"/></div></div><p class="title">Figure 7-11. The blue channel</p></div><p><a class="xref" href="ch07s01.html#red_channel" title="Figure 7-9. The red channel">Figure 7-9</a> to <a class="xref" href="ch07s01.html#blue_channel" title="Figure 7-11. The blue channel">Figure 7-11</a> show the three channels, along with their respective histogram. Clearly the Blue channel contributes much less to the image than the other two channels. Let’s see what happens if you stretch its histogram and leave the others unchanged.</p><div class="figure"><a id="stretching_the_dynamics_of_the_blue_laye"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00514"/><img src="httpatomoreillycomsourcenostarchimages1454954.png.jpg" alt="Stretching the dynamics of the Blue layer"/></div></div><p class="title">Figure 7-12. Stretching the dynamics of the Blue layer</p></div><div class="figure"><a id="after_recomposing_the_image"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00515"/><img src="httpatomoreillycomsourcenostarchimages1454956.png.jpg" alt="After recomposing the image"/></div></div><p class="title">Figure 7-13. After recomposing the image</p></div><p><a id="iddle1183" class="indexterm"/><a id="iddle2281" class="indexterm"/><a id="iddle2286" class="indexterm"/><a id="iddle2325" class="indexterm"/><a id="iddle2465" class="indexterm"/><a id="iddle2617" class="indexterm"/><a id="iddle3307" class="indexterm"/><a id="iddle3676" class="indexterm"/><a id="iddle4528" class="indexterm"/><a id="iddle5559" class="indexterm"/><a id="iddle5617" class="indexterm"/><a id="iddle5904" class="indexterm"/>Select the Blue layer in the Layers dialog and apply <span class="strong"><strong>Image: Colors &gt; Auto &gt; Equalize</strong></span>. The result, if you hide the other two layers, appears in <a class="xref" href="ch07s01.html#stretching_the_dynamics_of_the_blue_laye" title="Figure 7-12. Stretching the dynamics of the Blue layer">Figure 7-12</a>. Next, apply <span class="strong"><strong>Image: Colors &gt; Components &gt; Recompose</strong></span>. The result, shown in <a class="xref" href="ch07s01.html#after_recomposing_the_image" title="Figure 7-13. After recomposing the image">Figure 7-13</a>, is worse than the original. This image demonstrates that proper preprocessing requires an understanding of image dynamics that goes beyond being able to use the automatic tools.</p></div><div class="sect2" title="Noise Reduction"><div class="titlepage"><div><div><h2 class="title"><a id="noise_reduction"/>Noise Reduction</h2></div></div></div><p>Noise is a set of small fluctuations around the average value intensity in some region of an image. As you’ll see later in this chapter, noise reduction is useful in many circumstances. But in the present case, the image is mostly noise, and no noise reduction process can really improve it. The only tool that’s even slightly useful is <span class="strong"><strong>Image: Filters &gt; Enhance &gt; Unsharp Mask</strong></span>, which brings up the dialog shown in <a class="xref" href="ch07s01.html#unsharp_mask_dialog" title="Figure 7-14. The Unsharp Mask dialog">Figure 7-14</a>.</p><div class="figure"><a id="unsharp_mask_dialog"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00516"/><img src="httpatomoreillycomsourcenostarchimages1454958.png.jpg" alt="The Unsharp Mask dialog"/></div></div><p class="title">Figure 7-14. The Unsharp Mask dialog</p></div><div class="figure"><a id="after_using_unsharp_mask"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00517"/><img src="httpatomoreillycomsourcenostarchimages1454960.png.jpg" alt="After using Unsharp Mask"/></div></div><p class="title">Figure 7-15. After using Unsharp Mask</p></div><p>If you increase the R<span class="smaller">ADIUS</span> to more than 40, you improve the image a bit, as shown in <a class="xref" href="ch07s01.html#after_using_unsharp_mask" title="Figure 7-15. After using Unsharp Mask">Figure 7-15</a>. The squirrel is more visible and has more relief, but identifying most of the plants in the background would still be very difficult.</p></div><div class="sect2" title="Edge Detection"><div class="titlepage"><div><div><h2 class="title"><a id="edge_detection"/>Edge Detection</h2></div></div></div><p>Generally, edge detection enhances the visibility of objects in a photograph. But when we applied the various filters in the <span class="strong"><strong>Image: Filters &gt; Edge Detect</strong></span> menu to our initial squirrel photograph, we didn’t see any improvement. You can achieve a better result by successively applying several different tools.</p><p>For example, first select the Levels tool, and click A<span class="smaller">UTO</span>. Next, apply the Unsharp Mask filter. Finally, choose the <span class="strong"><strong>Image: Filters &gt; Edge-Detect &gt; Edge</strong></span> filter. Using the settings shown <a id="iddle1344" class="indexterm"/><a id="iddle1940" class="indexterm"/><a id="iddle2282" class="indexterm"/><a id="iddle4325" class="indexterm"/><a id="iddle4400" class="indexterm"/>in <a class="xref" href="ch07s01.html#edge_filter_dialog" title="Figure 7-16. The Edge filter dialog">Figure 7-16</a>, you get the result shown in <a class="xref" href="ch07s01.html#after_using_the_roberts_edge_detection_f" title="Figure 7-17. After using the Roberts edge detection filter">Figure 7-17</a>. Admittedly, this version is not really an improvement if your goal is to create a realistic image of the squirrel in its habitat. You could try applying the last filter on a copy of the layer and then adjusting the blending mode to get a more natural result.</p><div class="figure"><a id="edge_filter_dialog"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00518"/><img src="httpatomoreillycomsourcenostarchimages1454962.png.jpg" alt="The Edge filter dialog"/></div></div><p class="title">Figure 7-16. The Edge filter dialog</p></div><div class="figure"><a id="after_using_the_roberts_edge_detection_f"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00519"/><img src="httpatomoreillycomsourcenostarchimages1454964.png.jpg" alt="After using the Roberts edge detection filter"/></div></div><p class="title">Figure 7-17. After using the Roberts edge detection filter</p></div></div></div>
<div class="sect1" title="7.2 The Principles of Preprocessing"><div class="titlepage"><div><div><h1 class="title"><a id="sevendot2_the_principles_of_preprocessin"/>7.2 The Principles of Preprocessing</h1></div></div></div><p>In this section, we introduce you to the general principles of preprocessing.</p><div class="sect2" title="Subjective Aspects of Preprocessing"><div class="titlepage"><div><div><h2 class="title"><a id="subjective_aspects_of_preprocessing"/>Subjective Aspects of Preprocessing</h2></div></div></div><p>Image preprocessing enhances the visibility of the elements that we’re interested in within an image. In other words, the aim is to restore the original information as faithfully as possible. Generally speaking, preprocessing methods make pixels in the same regions more similar or increase the differences among pixels in different regions. But defining exactly what makes up a “region” is difficult.</p><p>As mentioned at the beginning of this chapter, preprocessing is more commonly used in scientific imaging applications than when creating decorative imagery or photos for fun. If a photographer wants to touch up portraits he’s taken of an actor, he’ll probably use the techniques from <a class="xref" href="ch02.html" title="Chapter 2. Photograph Retouching">Chapter 2</a> and <a class="xref" href="ch05.html" title="Chapter 5. Composite Photography">Chapter 5</a>, not the techniques in this chapter. Erasing wrinkles or blemishes doesn’t require a lot of information, just a steady hand and a little time.</p><p>On the contrary, biologists often want to extract as much information as possible from a <span class="emphasis"><em>micrograph</em></span>, a photo taken through a microscope. If they want to enhance the image quality, they can’t use techniques that degrade the information contained in the image. This also holds true for an intelligence agent using a photo taken via satellite or for an astronomer using a photo taken through a telescope.</p><p>The techniques used in this chapter modify the look of an image so you can extract information from it more easily. They remove useless and detrimental information (i.e., noise) to reinforce the meaningful information.</p><p>The idea of improving an image is a highly subjective one. But the human eye is especially sensitive to high contrasts, so the techniques we present here are generally intended to increase an image’s contrast, as it’s is the best way to improve visibility within a scene.</p><p>Although this chapter’s appeal is narrower than that of previous chapters, we think the techniques presented here can be useful to almost anyone who processes photographs with GIMP. In particular, the noise-reduction and edge-detection techniques have a variety of applications. Moreover, this information will help you to build a more thorough understanding of GIMP’s capabilities, which might come in handy when you least expect it.</p><div class="figure"><a id="micrograph_of_bacteria"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00520"/><img src="httpatomoreillycomsourcenostarchimages1454966.png.jpg" alt="A micrograph of bacteria"/></div></div><p class="title">Figure 7-18. A micrograph of bacteria</p></div><div class="figure"><a id="histogram_for_figure_7dot18"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00521"/><img src="httpatomoreillycomsourcenostarchimages1454968.png.jpg" alt="The histogram for"/></div></div><p class="title">Figure 7-19. The histogram for <a class="xref" href="ch07s02.html#micrograph_of_bacteria" title="Figure 7-18. A micrograph of bacteria">Figure 7-18</a></p></div></div><div class="sect2" title="Histograms and Decomposition into Channels"><div class="titlepage"><div><div><h2 class="title"><a id="histograms_and_decomposition_into_channe"/>Histograms and Decomposition into Channels</h2></div></div></div><p><a id="iddle1941" class="indexterm"/><a id="iddle1947" class="indexterm"/><a id="iddle2046" class="indexterm"/><a id="iddle4313" class="indexterm"/><a id="iddle4634" class="indexterm"/><a id="iddle5520" class="indexterm"/>The main purpose of image preprocessing is to get information that helps make the image more readable. When you use the image histogram to make adjustments, you change the individual pixel intensities. This transformation does not change the shape of the regions, but it can change their texture, color, luminosity, or contrast with the surroundings.</p><p><a class="xref" href="ch07s02.html#micrograph_of_bacteria" title="Figure 7-18. A micrograph of bacteria">Figure 7-18</a> is a grayscale photo of bacteria that was taken with a microscope. <a class="xref" href="ch07s02.html#histogram_for_figure_7dot18" title="Figure 7-19. The histogram for Figure 7-18">Figure 7-19</a> shows its corresponding histogram. Among the 160,000 pixels in this image, 1684 of them have a value of 77, in the interval from 0 to 255.</p><p>Choose the Levels tool and adjust the image’s only level, as shown in <a class="xref" href="ch07s02.html#improving_the_value_dynamics" title="Figure 7-20. Improving the value dynamics">Figure 7-20</a>. The result appears in <a class="xref" href="ch07s02.html#after_improvement" title="Figure 7-21. After improvement">Figure 7-21</a> with its histogram. The histogram now spans the entire range, but not all values are represented because the total number of discrete colors is less than the length of the interval [0:255]. The contrast has been increased, and the resulting image is more readable.</p><div class="figure"><a id="improving_the_value_dynamics"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00522"/><img src="httpatomoreillycomsourcenostarchimages1454970.png.jpg" alt="Improving the value dynamics"/></div></div><p class="title">Figure 7-20. Improving the value dynamics</p></div><div class="figure"><a id="after_improvement"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00523"/><img src="httpatomoreillycomsourcenostarchimages1454972.png.jpg" alt="After improvement"/></div></div><p class="title">Figure 7-21. After improvement</p></div><p><a class="xref" href="ch07s02.html#micrograph_of_human_blood" title="Figure 7-22. A micrograph of human blood">Figure 7-22</a> shows a micrograph of human blood, this time in color. <a class="xref" href="ch07s02.html#combined_histograms_for_figure_7dot22" title="Figure 7-23. The combined histograms for Figure 7-22">Figure 7-23</a> shows the combined histograms for this image. You see that these histograms each have two separated peaks of different heights and in different positions depending on the channel chosen. The Red channel extends further into the high values than the other two, but none of the channels extends all the way to 255.</p><p>You can get more information by decomposing the image into its three channels using <span class="strong"><strong>Image: Colors &gt; Components &gt; Decompose</strong></span>. From <a id="iddle2026" class="indexterm"/><a id="iddle2049" class="indexterm"/><a id="iddle4529" class="indexterm"/><a id="iddle4550" class="indexterm"/><a id="iddle4695" class="indexterm"/><a id="iddle5510" class="indexterm"/>the dialog that appears (<a class="xref" href="ch07s02.html#decompose_tool_dialog" title="Figure 7-24. The Decompose tool dialog">Figure 7-24</a>), choose the first color model—RGB. Leave D<span class="smaller">ECOMPOSE TO LAYERS</span> checked, and click OK. A new image is created with a layer for each channel. Each layer is a grayscale representation of the corresponding channel. For example, <a class="xref" href="ch07s02.html#red_channel_for_figure_7dot22" title="Figure 7-25. The Red channel for Figure 7-22">Figure 7-25</a> shows the Red layer.</p><div class="figure"><a id="micrograph_of_human_blood"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00524"/><img src="httpatomoreillycomsourcenostarchimages1454974.png.jpg" alt="A micrograph of human blood"/></div></div><p class="title">Figure 7-22. A micrograph of human blood</p></div><div class="figure"><a id="combined_histograms_for_figure_7dot22"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00525"/><img src="httpatomoreillycomsourcenostarchimages1454976.png.jpg" alt="The combined histograms for"/></div></div><p class="title">Figure 7-23. The combined histograms for <a class="xref" href="ch07s02.html#micrograph_of_human_blood" title="Figure 7-22. A micrograph of human blood">Figure 7-22</a></p></div><div class="figure"><a id="decompose_tool_dialog"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00526"/><img src="httpatomoreillycomsourcenostarchimages1454978.png.jpg" alt="The Decompose tool dialog"/></div></div><p class="title">Figure 7-24. The Decompose tool dialog</p></div><p>One useful tool for improving these channels separately is <span class="strong"><strong>Image: Colors &gt; Curves</strong></span>. When you apply it to the layer corresponding to the Red channel, you get <a class="xref" href="ch07s02.html#adjusting_the_red_channel" title="Figure 7-26. Adjusting the Red channel">Figure 7-26</a>. Click the small button on the right, just above the curve, to get a logarithmic histogram. In this histogram, the height of the vertical bars is not proportional to the number of pixels: The ratio between the height and the number decreases as the height increases. In many cases, this type of histogram is more readable.</p><div class="figure"><a id="red_channel_for_figure_7dot22"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00527"/><img src="httpatomoreillycomsourcenostarchimages1454980.png.jpg" alt="The Red channel for"/></div></div><p class="title">Figure 7-25. The Red channel for <a class="xref" href="ch07s02.html#micrograph_of_human_blood" title="Figure 7-22. A micrograph of human blood">Figure 7-22</a></p></div><div class="figure"><a id="adjusting_the_red_channel"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00528"/><img src="httpatomoreillycomsourcenostarchimages1454982.png.jpg" alt="Adjusting the Red channel"/></div></div><p class="title">Figure 7-26. Adjusting the Red channel</p></div><p>Adjust the curve as shown in <a class="xref" href="ch07s02.html#changing_the_curve" title="Figure 7-27. Changing the curve">Figure 7-27</a> to keep only the interesting parts of the histogram. <a class="xref" href="ch07s02.html#resulting_red_channel" title="Figure 7-28. The resulting Red channel">Figure 7-28</a> shows the result with the corresponding altered histogram. Note the white vertical bars that correspond to the unrepresented values.</p><p>Do the same thing with the other two channels: Select the corresponding layer, select the Curves tool, and adjust the curve. When you’ve done this for the three layers, choose <span class="strong"><strong>Image: Colors &gt; Components &gt; Recompose</strong></span>, which <a id="iddle3308" class="indexterm"/><a id="iddle4652" class="indexterm"/>reconstitutes the original image using the values of the three channels in the decomposed layers. The result appears in <a class="xref" href="ch07s02.html#after_adjusting_the_three_channels" title="Figure 7-29. After adjusting the three channels">Figure 7-29</a> with its combined RGB histograms. The image is much more readable, and the biologist can now see and interpret some details that weren’t really visible before.</p><div class="figure"><a id="changing_the_curve"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00529"/><img src="httpatomoreillycomsourcenostarchimages1454984.png.jpg" alt="Changing the curve"/></div></div><p class="title">Figure 7-27. Changing the curve</p></div><div class="figure"><a id="resulting_red_channel"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00530"/><img src="httpatomoreillycomsourcenostarchimages1454986.png.jpg" alt="The resulting Red channel"/></div></div><p class="title">Figure 7-28. The resulting Red channel</p></div><div class="figure"><a id="after_adjusting_the_three_channels"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00531"/><img src="httpatomoreillycomsourcenostarchimages1454988.png.jpg" alt="After adjusting the three channels"/></div></div><p class="title">Figure 7-29. After adjusting the three channels</p></div><div class="figure"><a id="after_image_colors_greater_than_auto_gre"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00532"/><img src="httpatomoreillycomsourcenostarchimages1454990.png.jpg" alt="After Image: Colors &gt; Auto &gt; Equalize"/></div></div><p class="title">Figure 7-30. After Image: Colors &gt; Auto &gt; Equalize</p></div><div class="figure"><a id="after_image_colors_greater_than-id00074"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00533"/><img src="httpatomoreillycomsourcenostarchimages1454992.png.jpg" alt="After Image: Colors &gt; Auto &gt; White Balance"/></div></div><p class="title">Figure 7-31. After Image: Colors &gt; Auto &gt; White Balance</p></div><div class="figure"><a id="after_image_colors_greater_than-id00075"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00534"/><img src="httpatomoreillycomsourcenostarchimages1454994.png.jpg" alt="After Image: Colors &gt; Auto &gt; Color Enhance"/></div></div><p class="title">Figure 7-32. After Image: Colors &gt; Auto &gt; Color Enhance</p></div></div><div class="sect2" title="Extracting Information through Dynamics Extension"><div class="titlepage"><div><div><h2 class="title"><a id="extracting_information_through_dynamics"/>Extracting Information through Dynamics Extension</h2></div></div></div><p>In the previous tutorial, we used some automatic tools to extend an image’s dynamics, but the results weren’t very good. Although they can be useful in some cases, you clearly shouldn’t depend on automatic tools to adjust an image’s dynamics. In this section, we use several automatic tools on a micrograph of bacteria—with some interesting results.</p><p><a class="xref" href="ch07s02.html#after_image_colors_greater_than_auto_gre" title="Figure 7-30. After Image: Colors &gt; Auto &gt; Equalize">Figure 7-30</a> to <a class="xref" href="ch07s02.html#after_image_colors_greater_than-id00078" title="Figure 7-35. After Image: Colors &gt; Auto &gt; Stretch HSV">Figure 7-35</a> show the result of using the six entries from the <span class="strong"><strong>Image: Colors &gt; Auto</strong></span> menu. In this case, the best choice is not a matter of taste but rather of utility. The biologist <a id="iddle2027" class="indexterm"/><a id="iddle3046" class="indexterm"/><a id="iddle3677" class="indexterm"/><a id="iddle4631" class="indexterm"/><a id="iddle4648" class="indexterm"/><a id="iddle5214" class="indexterm"/><a id="iddle5511" class="indexterm"/><a id="iddle5618" class="indexterm"/><a id="iddle5830" class="indexterm"/><a id="iddle5861" class="indexterm"/><a id="iddle5929" class="indexterm"/>who will interpret this picture will choose the transformation that provides her with the most significant information.</p><div class="figure"><a id="after_image_colors_greater_than-id00076"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00535"/><img src="httpatomoreillycomsourcenostarchimages1454996.png.jpg" alt="After Image: Colors &gt; Auto &gt; Normalize"/></div></div><p class="title">Figure 7-33. After Image: Colors &gt; Auto &gt; Normalize</p></div><div class="figure"><a id="after_image_colors_greater_than-id00077"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00536"/><img src="httpatomoreillycomsourcenostarchimages1454998.png.jpg" alt="After Image: Colors &gt; Auto &gt; Stretch Contrast"/></div></div><p class="title">Figure 7-34. After Image: Colors &gt; Auto &gt; Stretch Contrast</p></div><div class="figure"><a id="after_image_colors_greater_than-id00078"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00537"/><img src="httpatomoreillycomsourcenostarchimages1455000.png.jpg" alt="After Image: Colors &gt; Auto &gt; Stretch HSV"/></div></div><p class="title">Figure 7-35. After Image: Colors &gt; Auto &gt; Stretch HSV</p></div><p>transformations are global and cannot be parameterized. They work on all the channels in the same way, although the Stretch HSV transformation operates on the HSV model rather than the RGB one. For comparison, <a class="xref" href="ch07s02.html#after_using_auto_in_the_levels_t-id00079" title="Figure 7-36. After using Auto in the Levels tool">Figure 7-36</a> shows the effect of using the A<span class="smaller">UTO</span> button in the Levels tool. That transformation operates separately on each channel, removing the lowest values in the histograms, so it takes away some background noise but can also delete meaningful information.</p><div class="figure"><a id="after_using_auto_in_the_levels_t-id00079"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00538"/><img src="httpatomoreillycomsourcenostarchimages1455002.png.jpg" alt="After using Auto in the Levels tool"/></div></div><p class="title">Figure 7-36. After using Auto in the Levels tool</p></div><div class="figure"><a id="increasing_gray_pixel_values_left_parent"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00539"/><img src="httpatomoreillycomsourcenostarchimages1455004.png.jpg" alt="Increasing gray pixel values (darkening)"/></div></div><p class="title">Figure 7-37. Increasing gray pixel values (darkening)</p></div><p>Next, try some more complicated manipulations with the Curves tool. Work only on the Value channel (i.e., the grayscale values), although you could also work on the three color channels separately. In each case, first apply the curve modification shown in <a class="xref" href="ch07s02.html#changing_the_curve" title="Figure 7-27. Changing the curve">Figure 7-27</a> to remove the unrepresented extreme values.</p><p>In the sequence of figures from <a class="xref" href="ch07s02.html#increasing_gray_pixel_values_left_parent" title="Figure 7-37. Increasing gray pixel values (darkening)">Figure 7-37</a> to <a class="xref" href="ch07s02.html#result_of_diversifying_pixel_values" title="Figure 7-44. The result of diversifying pixel values">Figure 7-44</a>, you see the modification made to each curve, its effect (stated in each figure’s caption), and the resulting image. The results are fairly diverse, and some of them are probably not very useful. In these last examples, the correlation among channels, and thus the general hue, was maintained in the images. Note that if you use the A<span class="smaller">UTO</span> button in the Levels tool, the correlation <a id="iddle2028" class="indexterm"/><a id="iddle5512" class="indexterm"/>would not be maintained. For most users, this makes no difference.</p><div class="figure"><a id="result_of_increasing_pixel_values"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00540"/><img src="httpatomoreillycomsourcenostarchimages1455006.png.jpg" alt="The result of increasing pixel values"/></div></div><p class="title">Figure 7-38. The result of increasing pixel values</p></div><div class="figure"><a id="decreasing_gray_pixel_values_left_parent"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00541"/><img src="httpatomoreillycomsourcenostarchimages1455008.png.jpg" alt="Decreasing gray pixel values (lightening)"/></div></div><p class="title">Figure 7-39. Decreasing gray pixel values (lightening)</p></div><div class="figure"><a id="result_of_decreasing_pixel_values"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00542"/><img src="httpatomoreillycomsourcenostarchimages1455010.png.jpg" alt="The result of decreasing pixel values"/></div></div><p class="title">Figure 7-40. The result of decreasing pixel values</p></div><p>A variety of manipulations are possible with the Curves tool. Changing the shape of the curves can lead to interesting results—but more often to weird and useless results. For example, <a class="xref" href="ch07s02.html#bizarre_curve" title="Figure 7-45. A bizarre curve">Figure 7-45</a> shows a bizarre curve applied to the <a id="iddle2114" class="indexterm"/><a id="iddle2413" class="indexterm"/><a id="iddle4551" class="indexterm"/><a id="iddle4847" class="indexterm"/>Red channel. A similar curve was applied to the two other channels to create <a class="xref" href="ch07s03.html#result_of_applying_bizarre_curves_to_all" title="Figure 7-46. The result of applying bizarre curves to all channels">Figure 7-46</a>, which probably does not provide the biologist with any additional useful information.</p><div class="figure"><a id="homogenizing_gray_pixel_values"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00543"/><img src="httpatomoreillycomsourcenostarchimages1455012.png.jpg" alt="Homogenizing gray pixel values"/></div></div><p class="title">Figure 7-41. Homogenizing gray pixel values</p></div><div class="figure"><a id="result_of_homogenizing_pixel_values"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00544"/><img src="httpatomoreillycomsourcenostarchimages1455014.png.jpg" alt="The result of homogenizing pixel values"/></div></div><p class="title">Figure 7-42. The result of homogenizing pixel values</p></div><div class="figure"><a id="diversifying_the_pixel_values"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00545"/><img src="httpatomoreillycomsourcenostarchimages1455016.png.jpg" alt="Diversifying the pixel values"/></div></div><p class="title">Figure 7-43. Diversifying the pixel values</p></div><div class="figure"><a id="result_of_diversifying_pixel_values"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00546"/><img src="httpatomoreillycomsourcenostarchimages1455018.png.jpg" alt="The result of diversifying pixel values"/></div></div><p class="title">Figure 7-44. The result of diversifying pixel values</p></div><div class="figure"><a id="bizarre_curve"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00547"/><img src="httpatomoreillycomsourcenostarchimages1455020.png.jpg" alt="A bizarre curve"/></div></div><p class="title">Figure 7-45. A bizarre curve</p></div></div></div>
<div class="sect1" title="7.3 Filtering"><div class="titlepage"><div><div><h1 class="title"><a id="sevendot3_filtering"/>7.3 Filtering</h1></div></div></div><p>Filtering removes noise from an image. In this section, we’ll introduce the concept behind filtering and show you some common techniques.</p><div class="sect2" title="The Principles of Filtering"><div class="titlepage"><div><div><h2 class="title"><a id="principles_of_filtering"/>The Principles of Filtering</h2></div></div></div><p>Noise occurs in images for several reasons:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The photograph was taken in poor conditions; there was not enough light, as in <a class="xref" href="ch07s03.html#noise_due_to_poor_conditions" title="Figure 7-47. Noise due to poor conditions">Figure 7-47</a>, or the photographer moved, as in <a class="xref" href="ch07s03.html#noise_because_the_photographer_moved" title="Figure 7-48. Noise because the photographer moved">Figure 7-48</a>.</p><div class="figure"><a id="result_of_applying_bizarre_curves_to_all"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00548"/><img src="httpatomoreillycomsourcenostarchimages1455022.png.jpg" alt="The result of applying bizarre curves to all channels"/></div></div><p class="title">Figure 7-46. The result of applying bizarre curves to all channels</p></div><div class="figure"><a id="noise_due_to_poor_conditions"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00549"/><img src="httpatomoreillycomsourcenostarchimages1455024.png.jpg" alt="Noise due to poor conditions"/></div></div><p class="title">Figure 7-47. Noise due to poor conditions</p></div><div class="figure"><a id="noise_because_the_photographer_moved"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00550"/><img src="httpatomoreillycomsourcenostarchimages1455026.png.jpg" alt="Noise because the photographer moved"/></div></div><p class="title">Figure 7-48. Noise because the photographer moved</p></div></li><li class="listitem"><p>The camera was a very low-cost model with too few CCD sensors, which generated strong RGB noise, as shown in <a class="xref" href="ch07s03.html#noise_caused_by_too_few_image_sensors" title="Figure 7-49. Noise caused by too few image sensors">Figure 7-49</a>.</p></li><li class="listitem"><p>The sampling frequency was too low, as shown in <a class="xref" href="ch07s03.html#noise_due_to_low_sampling_frequency" title="Figure 7-50. Noise due to low sampling frequency">Figure 7-50</a>. This noise is typical in a photograph taken from a mobile phone.</p></li><li class="listitem"><p>The printed photograph has been scratched or otherwise damaged, as in <a class="xref" href="ch07s03.html#noise_due_to_photograph_scratching" title="Figure 7-51. Noise due to photograph scratching">Figure 7-51</a>.</p></li></ul></div><div class="figure"><a id="noise_caused_by_too_few_image_sensors"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00551"/><img src="httpatomoreillycomsourcenostarchimages1455028.png.jpg" alt="Noise caused by too few image sensors"/></div></div><p class="title">Figure 7-49. Noise caused by too few image sensors</p></div><div class="figure"><a id="noise_due_to_low_sampling_frequency"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00552"/><img src="httpatomoreillycomsourcenostarchimages1455030.png.jpg" alt="Noise due to low sampling frequency"/></div></div><p class="title">Figure 7-50. Noise due to low sampling frequency</p></div><p><a id="iddle1968" class="indexterm"/><a id="iddle2445" class="indexterm"/><a id="iddle4315" class="indexterm"/>The most common way to reduce the noise in an image is to use <span class="emphasis"><em>filtering</em></span>. The idea is to reduce the amplitude of the perturbations in areas that should be consistent, such as a wall or the surface of an object, while preserving the transition areas, which are the borders between objects and their surroundings. If possible, these transition areas should actually be emphasized.</p></div><div class="sect2" title="Characteristic Matrices"><div class="titlepage"><div><div><h2 class="title"><a id="characteristic_matrices"/>Characteristic Matrices</h2></div></div></div><p>Filtering changes every pixel value, depending on the values of neighboring pixels. A filter is defined by the formula or mathematical mechanism that computes this new value.</p><div class="figure"><a id="noise_due_to_photograph_scratching"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00553"/><img src="httpatomoreillycomsourcenostarchimages1455032.png.jpg" alt="Noise due to photograph scratching"/></div></div><p class="title">Figure 7-51. Noise due to photograph scratching</p></div><div class="figure"><a id="convolution_matrix_filter_dialog"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00554"/><img src="httpatomoreillycomsourcenostarchimages1455034.png.jpg" alt="The Convolution Matrix filter dialog"/></div></div><p class="title">Figure 7-52. The Convolution Matrix filter dialog</p></div><p>We will consider only the simplest and most frequently used filters from among those available in GIMP. The noise reduction filters are found in various submenus of the <span class="strong"><strong>Image: Filters</strong></span> menu. The most general one is <span class="strong"><strong>Image: Filters &gt; Generic &gt; Convolution Matrix</strong></span>, which brings up the dialog shown in <a class="xref" href="ch07s03.html#convolution_matrix_filter_dialog" title="Figure 7-52. The Convolution Matrix filter dialog">Figure 7-52</a>.</p><p>The M<span class="smaller">ATRIX</span> is an array of numbers with five rows and five columns. Initially only the center point contains a value different from zero, in this <a id="iddle2067" class="indexterm"/><a id="iddle2452" class="indexterm"/><a id="iddle2581" class="indexterm"/><a id="iddle4297" class="indexterm"/><a id="iddle4337" class="indexterm"/><a id="iddle5012" class="indexterm"/>case 1. This means every pixel is replaced by itself (i.e., it is unchanged).</p><div class="figure"><a id="noise_attenuation_matrix"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00555"/><img src="httpatomoreillycomsourcenostarchimages1455036.png.jpg" alt="A noise attenuation matrix"/></div></div><p class="title">Figure 7-53. A noise attenuation matrix</p></div><p>You can modify matrix entries to create various effects. If you change one entry, pressing the <span class="inlinemediaobject"><a id="inline_id00212"/><img src="httpatomoreillycomsourcenostarchimages1453804.png.jpg" alt=""/></span> key takes you to the next one, and its content is selected. If you then key in a new value, it replaces the previous one. In <a class="xref" href="ch07s03.html#noise_attenuation_matrix" title="Figure 7-53. A noise attenuation matrix">Figure 7-53</a>, we set the eight entries that surround the center entry to 1, which means the new pixel is computed as the sum of itself and its eight immediate neighbors. To calculate the pixel value as the average of these nine values, set the D<span class="smaller">IVISOR</span> to 9.</p><p>As the preview shows, this filter reduces the noise and smooths the image. <a class="xref" href="ch07s03.html#after_applying_an_averaging_filter_to_fi" title="Figure 7-54. After applying an averaging filter to Figure 7-49">Figure 7-54</a> shows the result on the image from <a class="xref" href="ch07s03.html#noise_caused_by_too_few_image_sensors" title="Figure 7-49. Noise caused by too few image sensors">Figure 7-49</a>. The Convolution Matrix filter is easy to use, but be warned: The resulting image is blurred. Because its matrix has five rows and five columns, you could define a larger filter by adding the four points in the middle of the matrix sides. The D<span class="smaller">IVISOR</span> would then be 13. The neighboring pixels used by the filter should be evenly spaced around the central target pixel.</p><p>You can use the same filter with different values in the matrix. For example, <a class="xref" href="ch07s03.html#gaussian_filter_matrix" title="Figure 7-55. A Gaussian filter matrix">Figure 7-55</a> shows the values for a Gaussian blur, where the pixels closer to the central pixel are weighted more heavily. Of course, the D<span class="smaller">IVISOR</span> must be adjusted appropriately. This filter blurs the image even more than the preceding one.</p><div class="figure"><a id="after_applying_an_averaging_filter_to_fi"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00556"/><img src="httpatomoreillycomsourcenostarchimages1455038.png.jpg" alt="After applying an averaging filter to"/></div></div><p class="title">Figure 7-54. After applying an averaging filter to <a class="xref" href="ch07s03.html#noise_caused_by_too_few_image_sensors" title="Figure 7-49. Noise caused by too few image sensors">Figure 7-49</a></p></div><div class="figure"><a id="gaussian_filter_matrix"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00557"/><img src="httpatomoreillycomsourcenostarchimages1455040.png.jpg" alt="A Gaussian filter matrix"/></div></div><p class="title">Figure 7-55. A Gaussian filter matrix</p></div></div><div class="sect2" title="Comparing the Built-in Filters"><div class="titlepage"><div><div><h2 class="title"><a id="comparing_the_built-in_filters"/>Comparing the Built-in Filters</h2></div></div></div><p>Of the many filters in the <span class="strong"><strong>Image: Filters</strong></span> menu, several are genuine preprocessing filters. For example, take the <span class="strong"><strong>Image: Filters &gt; Blur</strong></span> menu. The Blur entry is not very useful because you can’t change the settings. Focus Blur and Motion Blur are used for specialized effects. The most useful entries for preprocessing are the two Gaussian filters. <a class="xref" href="ch07s03.html#after_applying_an_iie_gaussian_blur_filt" title="Figure 7-56. After applying an IIE Gaussian Blur filter with a radius of 5 to Figure 7-49">Figure 7-56</a> to <a class="xref" href="ch07s03.html#after_applying_the_selective_gaussian_bl" title="Figure 7-58. After applying the Selective Gaussian Blur filter with a radius of 8 to Figure 7-49">Figure 7-58</a> show various results of using these filters on the image in <a class="xref" href="ch07s03.html#noise_caused_by_too_few_image_sensors" title="Figure 7-49. Noise caused by too few image sensors">Figure 7-49</a>. As you can see, the Selective Gaussian Blur filter worked best for this image.</p><p>Another useful filter is <span class="strong"><strong>Image: Filters &gt; Enhance &gt; Despeckle</strong></span>. The Despeckle filter is called <a id="iddle2549" class="indexterm"/><a id="iddle3979" class="indexterm"/><a id="iddle4848" class="indexterm"/>a <span class="emphasis"><em>median filter</em></span>. It doesn’t use the same method as the Convolution Matrix, although it relies on a matrix too. <a class="xref" href="ch07s03.html#despeckle_filter_dialog" title="Figure 7-59. The Despeckle filter dialog">Figure 7-59</a> shows its dialog, and <a class="xref" href="ch07s03.html#after_using_the_despeckle_filter_on_figu" title="Figure 7-60. After using the Despeckle filter on Figure 7-51">Figure 7-60</a> shows the result of applying the Despeckle filter to the image in <a class="xref" href="ch07s03.html#noise_due_to_photograph_scratching" title="Figure 7-51. Noise due to photograph scratching">Figure 7-51</a>. You could hide the remaining scratches by adjusting the parameters. As a matter of fact, simply checking the R<span class="smaller">ECURSIVE</span> checkbox, which repeats the filter’s last action, would work, but doing so would increase the blurring as well. Still, aesthetically, the result could be considered an improvement over the initial photograph.</p><div class="figure"><a id="after_applying_an_iie_gaussian_blur_filt"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00558"/><img src="httpatomoreillycomsourcenostarchimages1455042.png.jpg" alt="After applying an IIE Gaussian Blur filter with a radius of 5 to"/></div></div><p class="title">Figure 7-56. After applying an IIE Gaussian Blur filter with a radius of 5 to <a class="xref" href="ch07s03.html#noise_caused_by_too_few_image_sensors" title="Figure 7-49. Noise caused by too few image sensors">Figure 7-49</a></p></div><div class="figure"><a id="after_applying_an_rle_gaussian_blur_filt"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00559"/><img src="httpatomoreillycomsourcenostarchimages1455044.png.jpg" alt="After applying an RLE Gaussian Blur filter with a radius of 8 to"/></div></div><p class="title">Figure 7-57. After applying an RLE Gaussian Blur filter with a radius of 8 to <a class="xref" href="ch07s03.html#noise_caused_by_too_few_image_sensors" title="Figure 7-49. Noise caused by too few image sensors">Figure 7-49</a></p></div><p>The preprocessing filters that we’ve tried so far all have the same drawback: They blur the image to some degree. The blurring is because, by averaging the values of neighboring pixels, these filters decrease the image quality at strong transitions, which delimit the various regions of the image. Sharpening, on the other hand, strengthens the transitions.</p><div class="figure"><a id="after_applying_the_selective_gaussian_bl"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00560"/><img src="httpatomoreillycomsourcenostarchimages1455046.png.jpg" alt="After applying the Selective Gaussian Blur filter with a radius of 8 to"/></div></div><p class="title">Figure 7-58. After applying the Selective Gaussian Blur filter with a radius of 8 to <a class="xref" href="ch07s03.html#noise_caused_by_too_few_image_sensors" title="Figure 7-49. Noise caused by too few image sensors">Figure 7-49</a></p></div><div class="figure"><a id="despeckle_filter_dialog"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00561"/><img src="httpatomoreillycomsourcenostarchimages1455048.png.jpg" alt="The Despeckle filter dialog"/></div></div><p class="title">Figure 7-59. The Despeckle filter dialog</p></div><p>Sharpening can be done by building a specific convolution matrix with a more complicated pattern than what you used before. You can also apply <span class="strong"><strong>Image: Filters &gt; Enhance &gt; NL Filter</strong></span>, but <a id="iddle2283" class="indexterm"/><a id="iddle2618" class="indexterm"/><a id="iddle4902" class="indexterm"/><a id="iddle5905" class="indexterm"/>choosing the correct parameters is challenging. The best sharpening filter by far is the familiar filter with the paradoxical name: <span class="strong"><strong>Image: Filters &gt; Enhance &gt; Unsharp Mask</strong></span>. Its dialog is shown in <a class="xref" href="ch07s03.html#unsharp_mask_filter_dialog-id00080" title="Figure 7-61. The Unsharp Mask filter dialog">Figure 7-61</a>.</p><div class="figure"><a id="after_using_the_despeckle_filter_on_figu"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00562"/><img src="httpatomoreillycomsourcenostarchimages1455050.png.jpg" alt="After using the Despeckle filter on"/></div></div><p class="title">Figure 7-60. After using the Despeckle filter on <a class="xref" href="ch07s03.html#noise_due_to_photograph_scratching" title="Figure 7-51. Noise due to photograph scratching">Figure 7-51</a></p></div><div class="figure"><a id="unsharp_mask_filter_dialog-id00080"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00563"/><img src="httpatomoreillycomsourcenostarchimages1455052.png.jpg" alt="The Unsharp Mask filter dialog"/></div></div><p class="title">Figure 7-61. The Unsharp Mask filter dialog</p></div><p>R<span class="smaller">ADIUS</span> sets the thickness of the image edges. A<span class="smaller">MOUNT</span> sets the effect intensity of the mask. Keeping the amount value low (0.25 to 0.5) is generally best. If necessary, repeat the action two or more times. This is what we did with <a class="xref" href="ch07s03.html#noise_because_the_photographer_moved" title="Figure 7-48. Noise because the photographer moved">Figure 7-48</a> to get the result shown in <a class="xref" href="ch07s03.html#after_applying_unsharp_mask_to_figure_7d" title="Figure 7-62. After applying Unsharp Mask to Figure 7-48 twice">Figure 7-62</a>.</p><div class="figure"><a id="after_applying_unsharp_mask_to_figure_7d"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00564"/><img src="httpatomoreillycomsourcenostarchimages1455054.png.jpg" alt="After applying Unsharp Mask to twice"/></div></div><p class="title">Figure 7-62. After applying Unsharp Mask to <a class="xref" href="ch07s03.html#noise_because_the_photographer_moved" title="Figure 7-48. Noise because the photographer moved">Figure 7-48</a> twice</p></div><div class="figure"><a id="original_photograph-id00081"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00565"/><img src="httpatomoreillycomsourcenostarchimages1455056.png.jpg" alt="The original photograph"/></div></div><p class="title">Figure 7-63. The original photograph</p></div></div></div>
<div class="sect1" title="7.4 Edge Detection"><div class="titlepage"><div><div><h1 class="title"><a id="sevendot4_edge_detection"/>7.4 Edge Detection</h1></div></div></div><p>In most cases, major variations in intensity in an image correspond to edges of objects. You can often extract objects in an image by detecting these variations through a process called <span class="emphasis"><em>segmentation</em></span>. In GIMP, you can do this using the <span class="emphasis"><em>edge detection</em></span> tools.</p><div class="sect2" title="The Principles of Edge Detection"><div class="titlepage"><div><div><h2 class="title"><a id="principles_of_edge_detection"/>The Principles of Edge Detection</h2></div></div></div><p>Technically, the edges in an image are any areas where the intensity presents a strong local <a id="iddle2085" class="indexterm"/><a id="iddle2284" class="indexterm"/><a id="iddle2457" class="indexterm"/>variation. Edge detection is a fundamental part of extracting information from an image during preprocessing. Often, the discovered edges are then fed to a shape recognition system. Shape recognition has applications in robotics, medical image analysis, video surveillance, and other fields.</p><div class="figure"><a id="after_a_strong_gaussian_blur"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00566"/><img src="httpatomoreillycomsourcenostarchimages1455058.png.jpg" alt="After a strong Gaussian blur"/></div></div><p class="title">Figure 7-64. After a strong Gaussian blur</p></div><div class="figure"><a id="edge-detect_menu"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00567"/><img src="httpatomoreillycomsourcenostarchimages1455060.png.jpg" alt="The Edge-Detect menu"/></div></div><p class="title">Figure 7-65. The Edge-Detect menu</p></div><p>We won’t go into the mathematical details of the various edge detection methods available. Instead, we’ll demonstrate several of them on one image—the photograph in <a class="xref" href="ch07s03.html#original_photograph-id00081" title="Figure 7-63. The original photograph">Figure 7-63</a>. To make this image worthy of edge detection, we first apply a strong blur to it by applying <span class="strong"><strong>Image: Filters &gt; Blur &gt; Gaussian Blur</strong></span>. The result is shown in <a class="xref" href="ch07s04.html#after_a_strong_gaussian_blur" title="Figure 7-64. After a strong Gaussian blur">Figure 7-64</a>.</p></div><div class="sect2" title="Edge Detection Methods"><div class="titlepage"><div><div><h2 class="title"><a id="edge_detection_methods"/>Edge Detection Methods</h2></div></div></div><p>The edge detection filters in GIMP are all found in the <span class="strong"><strong>Image: Filters &gt; Edge-Detect</strong></span> menu (see <a class="xref" href="ch07s04.html#edge-detect_menu" title="Figure 7-65. The Edge-Detect menu">Figure 7-65</a>). Here, we explore the various entries on this menu.</p><div class="figure"><a id="difference_of_gaussians_dialog"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00568"/><img src="httpatomoreillycomsourcenostarchimages1455062.png.jpg" alt="The Difference of Gaussians dialog"/></div></div><p class="title">Figure 7-66. The Difference of Gaussians dialog</p></div><div class="figure"><a id="after_difference_of_gaussians_edge_detec"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00569"/><img src="httpatomoreillycomsourcenostarchimages1455064.png.jpg" alt="After Difference of Gaussians edge detection"/></div></div><p class="title">Figure 7-67. After Difference of Gaussians edge detection</p></div><p>Choosing <span class="strong"><strong>Image: Filters &gt; Edge-Detect &gt; Difference of Gaussians</strong></span> brings up the dialog shown in <a class="xref" href="ch07s04.html#difference_of_gaussians_dialog" title="Figure 7-66. The Difference of Gaussians dialog">Figure 7-66</a>. Here, we adjusted the radius and suggest you do the same. We also unchecked the I<span class="smaller">NVERT</span> box. <a class="xref" href="ch07s04.html#after_difference_of_gaussians_edge_detec" title="Figure 7-67. After Difference of Gaussians edge detection">Figure 7-67</a> shows <a id="iddle2287" class="indexterm"/><a id="iddle2466" class="indexterm"/><a id="iddle2526" class="indexterm"/><a id="iddle2546" class="indexterm"/><a id="iddle3505" class="indexterm"/><a id="iddle3916" class="indexterm"/><a id="iddle5210" class="indexterm"/><a id="iddle5826" class="indexterm"/>the result. Edge detection using the Difference of Gaussians filter worked rather poorly, at least for this image.</p><div class="figure"><a id="neon_dialog"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00570"/><img src="httpatomoreillycomsourcenostarchimages1455066.png.jpg" alt="The Neon dialog"/></div></div><p class="title">Figure 7-68. The Neon dialog</p></div><div class="figure"><a id="after_neon_edge_detection"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00571"/><img src="httpatomoreillycomsourcenostarchimages1455068.png.jpg" alt="After Neon edge detection"/></div></div><p class="title">Figure 7-69. After Neon edge detection</p></div><p><span class="strong"><strong>Image: Filters &gt; Edge-Detect &gt; Neon</strong></span> works better for this image. <a class="xref" href="ch07s04.html#neon_dialog" title="Figure 7-68. The Neon dialog">Figure 7-68</a> shows this filter’s dialog with the settings we used. See the result in <a class="xref" href="ch07s04.html#after_neon_edge_detection" title="Figure 7-69. After Neon edge detection">Figure 7-69</a>. Note that the important features of the image are much more visible than with the previous filter.</p><p>The <span class="strong"><strong>Image: Filters &gt; Edge-Detect &gt; Laplace</strong></span> filter is a bit disconcerting: When you apply it to this image, no dialog pops up, and the result is completely black. But after applying <span class="strong"><strong>Image: Colors &gt; Auto &gt; Stretch Contrast</strong></span> to this image, you get the result in <a class="xref" href="ch07s04.html#after_laplace_edge_detection_and_applyin" title="Figure 7-70. After Laplace edge detection and applying Stretch Contrast">Figure 7-70</a>. Not great, but better than nothing.</p><div class="figure"><a id="after_laplace_edge_detection_and_applyin"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00572"/><img src="httpatomoreillycomsourcenostarchimages1455070.png.jpg" alt="After Laplace edge detection and applying Stretch Contrast"/></div></div><p class="title">Figure 7-70. After Laplace edge detection and applying Stretch Contrast</p></div><div class="figure"><a id="edge_dialog"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00573"/><img src="httpatomoreillycomsourcenostarchimages1455072.png.jpg" alt="The Edge dialog"/></div></div><p class="title">Figure 7-71. The Edge dialog</p></div><p>Finally, the most handy tool is <span class="strong"><strong>Image: Filters &gt; Edge-Detect &gt; Edge</strong></span>, which contains six different filters (algorithms). The dialog, shown in <a class="xref" href="ch07s04.html#edge_dialog" title="Figure 7-71. The Edge dialog">Figure 7-71</a>, is simple. The only setting is the A<span class="smaller">MOUNT</span>. A low amount value results in a black image with thin edges; a high amount value leads to thicker edges and multicolored dark regions.</p><div class="figure"><a id="after_sobel_edge_detection"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00574"/><img src="httpatomoreillycomsourcenostarchimages1455074.png.jpg" alt="After Sobel edge detection"/></div></div><p class="title">Figure 7-72. After Sobel edge detection</p></div><div class="figure"><a id="after_prewitt_compass_edge_detection"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00575"/><img src="httpatomoreillycomsourcenostarchimages1455076.png.jpg" alt="After Prewitt compass edge detection"/></div></div><p class="title">Figure 7-73. After Prewitt compass edge detection</p></div><p><a id="iddle2594" class="indexterm"/><a id="iddle3074" class="indexterm"/><a id="iddle5135" class="indexterm"/><a id="iddle5211" class="indexterm"/><a id="iddle5827" class="indexterm"/><a class="xref" href="ch07s04.html#after_sobel_edge_detection" title="Figure 7-72. After Sobel edge detection">Figure 7-72</a> shows the result of applying Sobel edge detection with an A<span class="smaller">MOUNT</span> of 6.5. <a class="xref" href="ch07s04.html#after_prewitt_compass_edge_detection" title="Figure 7-73. After Prewitt compass edge detection">Figure 7-73</a> shows the result of applying Prewitt compass edge detection with an A<span class="smaller">MOUNT</span> of 10. <a class="xref" href="ch07s04.html#after_gradient_edge_detection" title="Figure 7-74. After Gradient edge detection">Figure 7-74</a> shows the result of applying Gradient edge detection with the same A<span class="smaller">MOUNT</span>.</p><p>Stretching the contrast of an image you’ve used edge detection on may be useful. For example, we got the image shown in <a class="xref" href="ch07s04.html#after_differential_edge_detection_and_ap" title="Figure 7-75. After Differential edge detection and applying Stretch Contrast">Figure 7-75</a> by using Differential edge detection with an A<span class="smaller">MOUNT</span> of 2.5 and then applying <span class="strong"><strong>Image: Colors &gt; Auto &gt; Stretch Contrast</strong></span>.</p><div class="figure"><a id="after_gradient_edge_detection"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00576"/><img src="httpatomoreillycomsourcenostarchimages1455078.png.jpg" alt="After Gradient edge detection"/></div></div><p class="title">Figure 7-74. After Gradient edge detection</p></div><div class="figure"><a id="after_differential_edge_detection_and_ap"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00577"/><img src="httpatomoreillycomsourcenostarchimages1455080.png.jpg" alt="After Differential edge detection and applying Stretch Contrast"/></div></div><p class="title">Figure 7-75. After Differential edge detection and applying Stretch Contrast</p></div><p>You can use an edge detection filter to decompose the image into more readable objects. We show this in two different examples.</p><div class="figure"><a id="edge_detection_combined_with_the_origina"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00578"/><img src="httpatomoreillycomsourcenostarchimages1455082.png.jpg" alt="Edge detection combined with the original image ()"/></div></div><p class="title">Figure 7-76. Edge detection combined with the original image (<a class="xref" href="ch07s03.html#original_photograph-id00081" title="Figure 7-63. The original photograph">Figure 7-63</a>)</p></div><p><a id="iddle1020" class="indexterm"/><a id="iddle1067" class="indexterm"/><a id="iddle1387" class="indexterm"/><a id="iddle2274" class="indexterm"/><a id="iddle2595" class="indexterm"/><a id="iddle3568" class="indexterm"/><a id="iddle4892" class="indexterm"/><a id="iddle4910" class="indexterm"/><a id="iddle5136" class="indexterm"/><a id="iddle5753" class="indexterm"/>To create <a class="xref" href="ch07s04.html#edge_detection_combined_with_the_origina" title="Figure 7-76. Edge detection combined with the original image (Figure 7-63)">Figure 7-76</a> from <a class="xref" href="ch07s03.html#original_photograph-id00081" title="Figure 7-63. The original photograph">Figure 7-63</a>, do the following:</p><div class="orderedlist"><ol class="orderedlist"><li class="listitem"><p>Duplicate the layer.</p></li><li class="listitem"><p>Add an Alpha channel to the top layer (<span class="strong"><strong>Layers: right-click &gt; Add Alpha Channel</strong></span>).</p></li><li class="listitem"><p>Apply an edge detection filter to this layer (in this case, <span class="strong"><strong>Image: Filters &gt; Edge-Detect &gt; Edge &gt; Sobel</strong></span>).</p></li><li class="listitem"><p>Choose the Select by Color tool (<span class="inlinemediaobject"><a id="inline_id00213"/><img src="httpatomoreillycomsourcenostarchimages1453942.png.jpg" alt=""/></span>) and click a black area in the image.</p></li><li class="listitem"><p>Cut the selection (<span class="inlinemediaobject"><a id="inline_id00214"/><img src="httpatomoreillycomsourcenostarchimages1454122.png.jpg" alt=""/></span>).</p></li><li class="listitem"><p>Hide the selection (<span class="inlinemediaobject"><a id="inline_id00215"/><img src="httpatomoreillycomsourcenostarchimages1453950.png.jpg" alt=""/></span>).</p></li></ol></div><p>Another possible use for edge detection is demonstrated in <a class="xref" href="ch07s04.html#merging_edge_detection_with_the_original" title="Figure 7-77. Merging edge detection with the original image (Figure 7-22)">Figure 7-77</a>. Begin with the image from <a class="xref" href="ch07s02.html#micrograph_of_human_blood" title="Figure 7-22. A micrograph of human blood">Figure 7-22</a>. Duplicate the layer and apply the edge detection operator Sobel, as we did in the previous example. Finally, we experiment with the various merging modes in the Layers window to find the one that suits our needs. We choose Screen.</p><div class="figure"><a id="merging_edge_detection_with_the_original"/><div class="figure-contents"><div class="mediaobject"><a id="med_id00579"/><img src="httpatomoreillycomsourcenostarchimages1455084.png.jpg" alt="Merging edge detection with the original image ()"/></div></div><p class="title">Figure 7-77. Merging edge detection with the original image (<a class="xref" href="ch07s02.html#micrograph_of_human_blood" title="Figure 7-22. A micrograph of human blood">Figure 7-22</a>)</p></div></div></div>
<div class="sect1" title="7.5 Exercises"><div class="titlepage"><div><div><h1 class="title"><a id="sevendot5_exercises"/>7.5 Exercises</h1></div></div></div><p>For these exercises, feel free to utilize the images on this book’s website (<span class="emphasis"><em><a class="ulink" href="http://the-book-ofgimp.blogspot.com">http://the-book-ofgimp.blogspot.com</a></em></span>).</p><p><span class="strong"><strong>Exercise 7.1.</strong></span> One simple tool we did not use in this chapter is <span class="strong"><strong>Image: Colors &gt; Threshold</strong></span>. Try using it on a poor-quality image. Experiment with the placement of the cursors. Try to remove noise and to emphasize the important parts of the image.</p><p><span class="strong"><strong>Exercise 7.2.</strong></span> Because the Threshold tool generates a black and white image, combine its result with the initial image in a different layer. Try various merging modes until you feel that you’ve increased the amount of information that a researcher could extract from your image.</p><p><span class="strong"><strong>Exercise 7.3.</strong></span> Try using the image generated by the Threshold tool to fill a layer mask added to the original image. Do this again, but this time invert the threshold image.</p><p><span class="strong"><strong>Exercise 7.4.</strong></span> Find an image that’s difficult to interpret, either one that we’ve provided or one of your own. Try various methods for improving the edges and making the image’s information more readable. Use a combination of edge detection tools, layer merging modes, and other tools that we demonstrated in this chapter.</p></div></body></html>