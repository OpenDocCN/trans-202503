- en: '**10'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: STATISTICS**
  prefs: []
  type: TYPE_NORMAL
- en: '*The true Logic for this world is the Calculus of Probabilities.*'
  prefs: []
  type: TYPE_NORMAL
- en: —James Clerk Maxwell
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Many readers of this book are likely to skip one or more chapters in [Part II](part2.xhtml).
    A biologist may not be interested in physics applications, for example. But *this*
    particular chapter has something in it for everyone, because sooner or later,
    all scientists must deal with the subject of statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Anyone conducting experiments knows that the treatment and analysis of experimental
    data is a direct application of statistical methods and concepts. Every scientific
    calculator features buttons for calculating means and standard deviations of rows
    of numbers. In this chapter, you will learn how to apply Julia and its statistical
    libraries to manipulate, plot, and analyze all kinds of data. Julia is generally
    faster, more flexible, more extensible, and more powerful than R, the near-standard
    language in this field. But if you have R programs that you are already working
    with, I’ll explain how to use them from within your Julia environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concepts of probabilities and distributions are ubiquitous in physics,
    from the classical theories of statistical mechanics to quantum theory, in which
    probability plays a fundamental role. But statistics, and its basis in the language
    of probabilities, has its fingerprints all over science, even apart from experiments
    and observations. One of the detailed examples in this chapter involves probabilistic
    modeling in biology: an application of these ideas outside of both analysis of
    experiments and physics.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Probability**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We don’t have the space here for a complete course in probability and statistics,
    but fortunately, we can do everything we need to do without a detailed mathematical
    development. Almost all scientists have some familiarity with the basic concepts
    and methods of the discipline, but I will not assume any special knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: To understand and use statistics, we first need a clear grasp of *probability*.
    For our purposes, we can understand a probability as a number between 0 and 1,
    inclusive, that represents the likelihood of an event. A probability of 0 means
    that the event is impossible, and a probability of 1 means that it must occur.
    Any other probability can be interpreted as the frequency, or proportion of times,
    with which the event will occur in a large number of experiments. For example,
    if we say that the probability of heads when you flip a coin is 1/2, this means
    if you flip the coin a large number of times, the ratio of times that it comes
    up heads divided by the total number of flips will be close to 0.5.
  prefs: []
  type: TYPE_NORMAL
- en: How many times is a large number of times? What we really mean is that there
    is a limit
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/306math.jpg)'
  prefs: []
  type: TYPE_IMG
- en: which just says that as we do more and more experiments, the number of times
    that we observe the event *x*, *n*[*x*], divided by the total number of experiments,
    *N*, gets closer and closer to a certain ratio. We call this ratio the probability.
    In probability theory, *experiment* means a process, such as flipping a coin or
    rolling a die.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding paragraph describes a particular view of probability called the
    *frequency interpretation*. There are other ways to look at probability and its
    meaning, but in some sense, they are all equivalent. The frequency interpretation
    is practical, serves our purposes well, and is what most people think of when
    they need to pin down their idea of what probability means in practice. For more
    formal approaches to the subject, see “Further Reading” on [page 359](ch10.xhtml#fur10).
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll often want to simulate events in our computer programs that are supposed
    to occur with certain probabilities. This could be part of the simulation of a
    system, such as the molecules of a gas bouncing around in a box, which we may
    want to initialize with random positions and velocities, or it could be part of
    a statistical test. But this presents a problem: if probability represents chance,
    the outcome of some kind of random process, and what goes on inside our computers
    is (we certainly hope) deterministic, how can we use computers to generate random
    events?'
  prefs: []
  type: TYPE_NORMAL
- en: For the purposes of the examples in this book, we actually don’t want our random
    events to be random, because we may want to repeat simulations or check to see
    whether we get identical results after changing a computational technique. We
    need to be able to repeat particular sequences of “random” events. Surely this
    is a contradiction. If we know what’s going to happen, it can’t be random.
  prefs: []
  type: TYPE_NORMAL
- en: The random numbers we generate in our programs are called *pseudorandom* numbers.
    They look like sequences of random numbers, satisfy certain tests of randomness,
    and adhere to given *distributions* (explained next). However, naturally, they
    are not really random. Again, we don’t actually want them to be.
  prefs: []
  type: TYPE_NORMAL
- en: Except when we do. In some cryptography applications, we really need actual,
    unpredictable random numbers. Because the bad guys know the various algorithms
    for generating pseudorandom numbers, being able to predict such sequences can
    lead to defeating cryptographic systems. For such purposes, computer security
    systems exploit sources of real unpredictability available on any computer (known
    as *entropy sources*). These sources can be stored data derived from the timing
    of key presses on the keyboard, for example. The search for entropy has led to
    some creative solutions, such as pointing cameras at a wall of lava lamps.
  prefs: []
  type: TYPE_NORMAL
- en: Julia actually provides a way to tap into the entropy provided by your operating
    system. However, in this book, we are not interested in cryptography, but in science,
    so we want our random numbers to be not so random, and we’ll be using Julia’s
    pseudorandom number generators. I’ll follow common practice for the rest of this
    chapter and just call these pseudorandom numbers “random numbers.”
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Numbers in Julia**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Julia has functions for generating random numbers with all kinds of numerical
    types, even complex numbers. The basic random number generators are part of `Base`,
    so you can use them without any `import` statements.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*I mentioned earlier that one reason to use pseudorandom numbers is so we can
    repeat a sequence of random numbers when developing code. This sequence repeatability
    is not guaranteed to work forever, however. The random sequence returned by a
    particular function can change when upgrading Julia, so you can’t depend on this
    for code development over the long term. See “Further Reading” on [page 359](ch10.xhtml#fur10)
    if you need long-term reproducible number sequences.*'
  prefs: []
  type: TYPE_NORMAL
- en: The simplest use is just calling `rand()`, which returns a random `Float64`
    *uniformly distributed* in the interval [0, 1). This means that the number might
    be equal to 0, but it will be less than 1, and all numbers in this interval are
    equally likely.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check that the `rand()` function is doing what we expect by generating
    a bunch of random numbers and plotting them with a scatterplot. We could do this
    by calling `rand()` many times, storing its returned values in an array, and plotting
    the array. But `rand()` makes it even easier: if we give it an integer argument,
    it will oblige us by returning an array of random values whose length will be
    determined by the argument. If we give it more than one, we’ll get back a higher-dimensional
    array. The little program shown in [Listing 10-1](ch10.xhtml#ch10lis1) fills a
    length-10⁵ array with random floats and visualizes their distribution with a scatterplot.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-1: Testing random number generation*'
  prefs: []
  type: TYPE_NORMAL
- en: In the resulting plot, shown in [Figure 10-1](ch10.xhtml#ch10fig1), each of
    the 10⁵ numbers is represented by a tiny dot. All the numbers lie within the correct
    interval, and they appear to be randomly and uniformly distributed, as they are
    supposed to be. A plot like this is a useful visual check to ensure that a pseudorandom
    number generator is behaving correctly and not introducing any unwanted patterns
    in the distribution of values.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-1: Uniformly distributed random floats*'
  prefs: []
  type: TYPE_NORMAL
- en: 'To get random integers, or some type other than floats, simply pass the type
    as an argument. The call `rand(Int)`, which is the same as `rand(Int64)`, returns
    a random integer within the range defined by the lowest and highest possible integers
    of that type. This is rarely what you want in applications, however. You’ll probably
    want a random integer within some specified range that is relevant to your problem.
    In that case, simply pass the range as an argument: `rand(1:6)` represents the
    roll of a die, for example.'
  prefs: []
  type: TYPE_NORMAL
- en: In fact, that argument can be a tuple or list as well, from which `rand()` will
    pick a random element, all with equal likelihood. You can even do something like
    `rand([1, 3, "abc"])`, and get either `1`, `3`, or the string `"abc"`, each with
    a probability of 1/3\. If you pass in a single string, it will be considered a
    collection of characters, and you will get a random character back.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simple call `rand()` is useful in simulations where you want events to
    occur with a certain probability. If the probability of the event is supposed
    to be `P`, in your code, you’ll have something like the following, which is a
    way to make something happen with a specified probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The call to `rand()` works because it generates *uniformly distributed* random
    numbers in the interval [0, 1). Imagine repeatedly throwing a dart at a square
    dartboard one meter on a side (and assume it lands in a random place on the board).
    In the long run, the dart will land within the rightmost 90 centimeters 90 percent
    of the time. The `rand()` function is the dart.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping in mind that, over the long term, you can’t count on being able to repeat
    a particular sequence generated by one of Julia’s random number functions, you’ll
    need to know how to do it in the short term when debugging code or developing
    an algorithm. You’ll often want to rerun a program after changing something that
    you believe should not change the results. If the program uses random numbers,
    and the sequence is truly unpredictable, such tests become impossible.
  prefs: []
  type: TYPE_NORMAL
- en: By passing a *seed* to a random number generator, you can generate a sequence
    of high-quality pseudorandom numbers and also repeat the same sequence in subsequent
    runs of your program. To do this, you need to import the `Random` package, as
    you’ll need to use at least one function that’s not in `Base`. But `Random` has
    a few other goodies, as you’ll see shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following listing shows the three lines of code that illustrate the basic
    procedure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: After importing `Random`, the `MersenneTwister()` function, which is a random
    number–generating algorithm, will be available. The name comes from the mathematical
    library from which the function is taken. Its argument, in this case `7654`, is
    called a *seed*. The purpose of the seed is to generate a particular sequence
    that we can repeat if needed. The `rand()` function, and all the other random
    number functions in Julia, accept an optional first argument that specifies the
    particular instance of the generator to use. As before, every time we call `rand()`,
    we get a random number between 0 and 1\. But now we can restart the sequence anytime
    we want by reinitializing `rgen` using the same seed. We can generate a different,
    unpredictable sequence by simply changing the seed. Except for the most casual
    use, you should always specify a generator and supply it with a seed rather than
    using the simpler form of `rand()` as we did in the previous example.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Monty Hall Problem**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The ability to generate random numbers opens up a whole world of possibilities
    for interesting simulations. First, let’s consider the *Monty Hall problem*, which
    is named after the longtime host of the game show *Let’s Make a Deal*. This problem
    is guaranteed to generate lively debate in statistics classes and is something
    that experienced mathematicians, even statisticians, often get wrong—or they used
    to, before the problem became famous. For us, it will serve as an example of how
    a probabilistic computer simulation can verify a result that we believe we have
    calculated analytically. Simulations can supply some additional confidence in
    the solutions to tricky probability problems, where it is so easy to go astray
    analytically.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine three doors. Behind one is a prize, say, a fancy car, and behind the
    other two are joke prizes. Monty often used goats for these “loser” prizes. You
    want the car. Monty asks you to choose a door. He knows where everything is, but
    you know nothing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say, to be definite, that you choose door #1\. Before revealing what’s
    behind that door, Monty opens one of the other ones, say, door #3, to reveal a
    goat. He offers you the chance to switch to door #2 if you like.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the question: should you stick with your original choice or switch
    to door #2? Does it matter?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The correct answer is that you should switch. Nevertheless, many people have
    a strong initial intuition that it must not make any difference. After all, now
    two doors are available: door #1 and door #2\. Surely they have an equal chance
    of leading to the prize, so it’s the same as flipping a coin: heads or tails are
    equally likely.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this thinking is wrong. Initially, the probability that your choice
    was a winner was 1/3\. Everyone agrees with that. That means that the probability
    that the prize was in *one of the other doors* is 2/3\. Since the prize is guaranteed
    to be somewhere, the total probability must add up to 1\. These initial probabilities
    still hold. The probability that door #1 is the winner is still 1/3\. The probability
    that one of the others is, instead, is still 2/3\. But now the set of “one of
    the others” consists of just door #2, since Monty has eliminated door #3\. You
    should switch to increase your chances of winning from 1/3 to 2/3.'
  prefs: []
  type: TYPE_NORMAL
- en: This analysis is just one of many ways to approach the problem, but they all
    (if done correctly) lead to the same conclusion. Nevertheless, at this point many
    people remain unconvinced. Sometimes actually doing the experiment can persuade
    people who don’t believe in math.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following program performs just such an experiment—a simple example of
    a simulation using a random process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This program plays the game `N` times, where `N` is set to 3,000\. It stores
    the record of wins or losses in two arrays, one for the set of 3,000 plays where
    the player stays with the initial choice of door and one for the round where the
    player decides to switch. The arrays are initialized to be all 0s. If the player
    wins game number `game`, that array element is changed to 1.
  prefs: []
  type: TYPE_NORMAL
- en: The two arrays ➊ hold the running average of each strategy, defined using list
    comprehensions. These are the arrays we want to look at.
  prefs: []
  type: TYPE_NORMAL
- en: The plot in [Figure 10-2](ch10.xhtml#ch10fig2) shows that in the long run the
    switching strategy wins 2/3 of the time, while the player who stubbornly sticks
    with the initial choice wins only 1/3 of the time.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-2: Two Monty Hall strategies*'
  prefs: []
  type: TYPE_NORMAL
- en: 'These ratios agree with the argument if we remember the meaning of the frequency
    interpretation of probability: over the long run, the ratio of events (wins, in
    this case) to the total number of experiments should approach the probability.
    Note that if you run this code yourself, the graph may look slightly different,
    because you’ll get a different sequence of random numbers, but the *long-term
    behavior* should be the same.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Counting**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After probability, the next most important idea in statistics is *counting*,
    also called *combinatorics*. Counting has to do with answering questions about
    how many ways an event can happen. If you roll a pair of dice, in how many ways
    can the sum of the two numbers that come up equal six? If there are 30 people
    on the squad, how many nine-person baseball teams are possible?
  prefs: []
  type: TYPE_NORMAL
- en: When simulating systems involving probability on a computer, to calculate correctly
    the probabilities of various events, we often *count* the number of ways a given
    event can happen and divide by the total number of all possibilities. If all of
    the ways are equally likely, this gives us the probability.
  prefs: []
  type: TYPE_NORMAL
- en: In the dice example, there are 10 ways to get a sum of six, so the probability
    is 10/36.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two additional counting concepts arise frequently when dealing with probabilistic
    situations, and often in other places as well: *permutations*, calculated using
    factorials, and *combinations*, which involve binomial coefficients.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Factorials***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The first counting concept is the idea of *permutations*: the number of distinct
    ways to arrange a collection of objects. If you have eight *Scrabble* tiles, all
    bearing different letters, how many different eight-letter strings can you make
    out of them?'
  prefs: []
  type: TYPE_NORMAL
- en: The answer is 8 × 7 × 6 × 5 × 4 × 3 × 2 × 1 = 40, 320.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a quick argument to show why this is true: there are eight ways to choose
    the first tile; once that is chosen, there are seven ways to choose the next tile;
    and so on. This pattern comes up so often that we have a special name and mathematical
    notation for it. It is called the *factorial*, and it’s written as 8! in this
    case. Julia also has a built-in function for it, but since `!` is used for other
    purposes, we need to spell it out: `factorial(8)`.'
  prefs: []
  type: TYPE_NORMAL
- en: The factorial function grows insanely quickly, so above `factorial(20)`, you
    need to supply the argument as a `BigInt`, and you’ll get a `BigInt` back. How
    quickly does the factorial grow? The number of ways to arrange a standard 52-card
    deck is far larger than the number of stars in the universe. It’s so large that,
    after shuffling a deck, there is almost no chance that the particular arrangement
    of cards you are holding in your hand has existed before in the history of the
    world.
  prefs: []
  type: TYPE_NORMAL
- en: '***Binomial Coefficients***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The second combinatorial concept we’ll be using is the *binomial coefficient*.
    This comes up in many mathematical contexts, and Julia has a built-in function
    called `binomial()` that deals with it. In the context of counting, the binomial
    coefficient answers the baseball teams question mentioned earlier. If there are
    30 players available, the number of ways to form nine-member teams is written
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/313math.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The baseball problem is calculated with `binomial(30, 9)`. The combinatorial
    term for these problems, involving binomial coefficients, is *combinations*.
  prefs: []
  type: TYPE_NORMAL
- en: 'See “Further Reading” on [page 359](ch10.xhtml#fur10) to learn more details
    about binomial coefficients: why they are so named, how to calculate them using
    factorials, and their connections to other areas of mathematics.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Modeling a Pandemic**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We now have enough tools to perform a significant calculation. [Listing 10-2](ch10.xhtml#ch10lis2)
    is a simulation that models the spread of an infection through a population. It’s
    similar to models epidemiologists use to perform computational experiments with
    different scenarios for the spread of COVID-19\. This model is a bit simplified
    relative to those, as my purpose is to illustrate an application of the tools
    and ideas from the chapter so far. For a pointer to similar models being used
    now in research, see “Further Reading.”
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-2: A pandemic simulation*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The strategy is to represent the population as a square matrix. Each cell represents
    one person and can be in one of four possible states: `infected`, `dead`, `isolated`,
    or `ok`. An `isolated` person can’t become `infected`. An `ok` person is not `infected`,
    but may become so. An `infected` person may die after a certain number of “days,”
    or iterations, a number assigned to `dud`; if the person survives past this period,
    immortality is achieved. A `dead` person is no longer infectious. Thus, an `ok`
    person can never be infected (is “protected”) if surrounded by `dead` or `isolated`
    people. Death and lockdown prevent the spread of the disease.'
  prefs: []
  type: TYPE_NORMAL
- en: The simulation is initialized with probabilities, to establish both the starting
    state and its evolution. The state at `day = 1` is set up using the probabilities
    in the `initial` dictionary ➊. At every iteration, the state of each person is
    updated according to the probabilities in the `transition` dictionary on the following
    line and the value of `dud` in that dictionary, which is the number of days during
    which someone needs to be infected before the disease may become fatal.
  prefs: []
  type: TYPE_NORMAL
- en: The population matrix is called `world`, and the length of its side is stored
    in `n`. Don’t take the matrix geometry too literally. It does not assume that
    people stand in one spot while the disease runs its course. The matrix `world`
    represents a network of contact rather than a spatial arrangement.
  prefs: []
  type: TYPE_NORMAL
- en: 'After importing some libraries that you have seen before and including a file
    with the plotting function, which we’ll get to later, the `pandemic()` function,
    which does the actual calculation, is defined. This function gets two keyword
    arguments: `seeding` should be either `:normal` or `:center`. In the former case,
    infection is seeded randomly, according to `initial["infected"]`; but if `seeding`
    is set to `:center`, a single infected individual is placed at the center of the
    world.'
  prefs: []
  type: TYPE_NORMAL
- en: The second keyword, `plotmode`, controls whether daily plots are created, and
    if so, whether they are displayed or saved to files. At the end of the calculation,
    the `finish()` function is called, which saves a plot of the final state if the
    `plotmode` = `:last`. This function also uses the `@save` macro to save the `world`
    and the infection and death histories to a *.jld* file (introduced in [Chapter
    9](ch09.xhtml)).
  prefs: []
  type: TYPE_NORMAL
- en: At every iteration, the program has to decide, for each `ok` person, whether
    to change that person to the `infected` state. This is determined randomly, based
    on the probability of infection by each infected neighbor each day, given in `transition["infected"]`,
    and on the number of infected neighbors.
  prefs: []
  type: TYPE_NORMAL
- en: But, we need to be careful here. The probability of infection with two infected
    neighbors is not twice the probability of infection with only a single sick neighbor.
    We need to subtract the probability of becoming infected by both neighbors. We
    won’t provide a full treatment of the combination of events in probability theory
    here, but you likely can easily see why we can’t simply add the probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine you are flipping two coins and want to find the probability of getting
    at least one head. You know that the probability of a head with either coin alone
    is 1/2\. If you add those, you get a probability of 1\. But that can’t be right,
    because it would mean a head *must* appear, and you know there’s a good chance
    you’ll get two tails. The correct calculation includes subtracting the probability
    of *two* heads: 1/2 + 1/2 *–* 1/4 = 3/4\. You will get at least one head three-fourths
    of the time in the long run. At this point, you are in a good position to write
    a little Julia program to verify this, if you have any doubts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The coin problem corresponds exactly to the case where you are in contact with
    two infected people and the probability of infection = 1/2\. On the grid, however,
    each person can have up to eight neighbors. It’s a bit more complicated than the
    case of two neighbors, but the idea is the same. For each new neighbor, you have
    to add the probability of infection by that neighbor, but subtract all the combinations
    it can make with the other neighbors. The word *combinations* suggests that we
    might have to reach for a binomial coefficient, and indeed we do. The formula
    for the total probability of infection by *n* neighbors, if the probability of
    infection by a single neighbor is *p*, is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/317math.jpg)'
  prefs: []
  type: TYPE_IMG
- en: See “Further Reading” on [page 359](ch10.xhtml#fur10) for more about this formula
    and related matters. This probability is pre-calculated for all possible numbers
    of neighbors, `1:8`, and the results are stored in the `tpi` ➋ array.
  prefs: []
  type: TYPE_NORMAL
- en: It is necessary, before each iteration’s calculations begin, to make a copy
    of the `world` array, which is called `next` in the program ➌. We update the cells
    in `next`, and then copy it back into `world`. If `world` is updated in place,
    cells will be transitioned based on the partially updated information in neighbor
    cells, which would be inconsistent. A `copy` is required, as we’ve encountered
    in previous chapters, because a simple `next = world` would create a second reference
    to the array rather than an actual copy.
  prefs: []
  type: TYPE_NORMAL
- en: An array `aoi` is initialized to 0s ➍; it will record the `day` on which each
    person becomes infected, so that the survival probability can be applied at the
    appropriate time.
  prefs: []
  type: TYPE_NORMAL
- en: The subsequent loops over persons within the loop over days, given all the foregoing,
    should be self explanatory. After the sweep of the matrix, we `push!()` ➎ new
    values for the current total number of infected and dead people onto the vectors
    `noi` and `nod`, respectively. Julia’s neat and succinct syntax calculates these
    totals using a sum over a binary array.
  prefs: []
  type: TYPE_NORMAL
- en: Here, and in the previous loops over the `world`, the program treats only elements
    in `2:n-1` rather than the entire array, to implement the boundary condition.
    In keeping one row or column of cells on the boundaries “frozen,” the updating
    logic is simplified, as the expression, for example, for calculating the number
    of each person’s infected neighbors is identical for each nonfrozen person.
  prefs: []
  type: TYPE_NORMAL
- en: As in a physics problem, there are other possibilities for boundary conditions.
    The people on the edges could be updated based on their reduced numbers of neighbors,
    but doing so can induce artifacts. Periodic boundary conditions are another possibility,
    where the neighbor-ness wraps around the matrix to the opposite side. Any choice
    is to some degree arbitrary.
  prefs: []
  type: TYPE_NORMAL
- en: The conditional block ➏ checks to see whether the calculation has reached a
    steady state. If it has, there is no point in continuing, and the cleanup operation
    is called. The final line in the program starts the calculation by calling `pandemic()`.
  prefs: []
  type: TYPE_NORMAL
- en: This simple algorithm can produce interesting behavior, and it can be used to
    explore questions such as the effect of lockdown conformity on the spread of the
    infection, and how a higher fatality rate can slow the growth of a pandemic.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 10-3](ch10.xhtml#ch10fig3) shows the output of a 512×512 simulation
    with these initial and transition probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The simulation stops after 1,064 iterations when reaching a steady state. The
    notation on the figure means that 5.48 percent of the population was protected
    from infection due to the isolation of others and the effects of mortality interrupting
    disease transmission.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-3: Steady state reached in a pandemic simulation*'
  prefs: []
  type: TYPE_NORMAL
- en: See the book’s supplementary website ([*https://julia.lee-phillips.org*](https://julia.lee-phillips.org))
    for a color version of the plot and an animation of a similar simulation. In the
    printed grayscale version, the darkest shades on the heatmap plot represent dead
    or infected people, white represents people who remained protected from infection,
    and the middle tone corresponds to isolated people.
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 10-3](ch10.xhtml#ch10lis3) shows the simple function that calculates
    the protected percentage and makes plots as in [Figure 10-3](ch10.xhtml#ch10fig3).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-3: Visualizing the pandemic*'
  prefs: []
  type: TYPE_NORMAL
- en: The `plotworld()` function uses the `@sprintf` macro ➊, introduced in “Macros
    for String Formatting” on [page 177](ch06.xhtml#ch06sec1sec11), to format the
    variable `protected` and the y-axis label for display. After creating three plots
    and storing them in `p1`, `p2`, and `p3`, the `@layout` macro, described in “Creating
    Complex Layouts Using @layout” on [page 118](ch04.xhtml#ch04lev1sec28), arranges
    them ➋ into a summary display of the simulation.
  prefs: []
  type: TYPE_NORMAL
- en: '**Common Statistics Functions**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Julia provides functions to calculate all of the common statistical parameters,
    as well as special plotting functions for statistical visualization of data.
  prefs: []
  type: TYPE_NORMAL
- en: Some reorganization of the Julia statistics packages is underway, so everything
    may not be where you might expect it. This section describes where the packages
    are at the time of writing, but, when you try things out, you may discover that
    a function or two have moved.
  prefs: []
  type: TYPE_NORMAL
- en: If you are analyzing data of any kind, you will make heavy use of at least some
    of the functions described in this section, most of which are in the `Statistics`
    package, which is part of the standard Julia library. In the remainder of this
    chapter, I will assume you’ve imported the package with the `using Statistics`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: The package provides the basic functions that summarize datasets with statistical
    parameters. For the *mean*, or arithmetic average, use `mean(`data`)`, where,
    here and below, data is some vector of observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the *median*, which is the middle value in the data, use `median(`data`)`.
    If there are an even number of data points, none of them can be the middle value.
    In this case, `median()` returns the mean of the two middle values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: At the time of writing, `Statistics` does not contain a *mode* function. The
    mode is the most common value, or the maximum of a continuous distribution, if
    it exists. From this idea come the terms *bimodal* and *multimodal* to describe
    distributions with more than one local maximum. The height distribution in [Figure
    10-4](ch10.xhtml#ch10fig4) is an example of a bimodal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: If you need a mode function, you can import it from another package called `StatsBase`,
    which you will need to `add`. `StatsBase` contains some other less commonly used
    statistical functions that are not in the standard `Statistics` package, but you
    may want to import only the ones you plan to use. If you just need to add a mode
    function to your toolbox, you can enter `import` `StatsBase.mode`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few examples showing how the `mode()` function behaves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: If there is more than one mode, the function returns the first one. Consequently,
    if each value appears only once, they are all modes, so the function returns the
    first value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard `Statistics` package contains most of the other basic statistical
    functions, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: std  Standard deviation
  prefs: []
  type: TYPE_NORMAL
- en: stdm  Standard deviation with specified mean
  prefs: []
  type: TYPE_NORMAL
- en: var  Variance
  prefs: []
  type: TYPE_NORMAL
- en: varm  Variance with specified mean
  prefs: []
  type: TYPE_NORMAL
- en: cor  Pearson correlation
  prefs: []
  type: TYPE_NORMAL
- en: cov  Covariance
  prefs: []
  type: TYPE_NORMAL
- en: middle  (max + min) / 2
  prefs: []
  type: TYPE_NORMAL
- en: quantile  Quantile
  prefs: []
  type: TYPE_NORMAL
- en: These commands work on vectors or pairs of vectors of data in the way you would
    expect. In addition, the `cor()` function will accept a matrix and return a correlation
    matrix, and the `cov()` function can work similarly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `mean()` function takes an optional first argument that can be a unary
    operator or a function of one numeric variable. The function then maps the operator
    or function over the data vector before calculating the mean. This can be convenient
    if you need to scale or otherwise process the data, but, for the case of a simple
    vector, it gives the same result as broadcasting the function over the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: There are two versions of the standard deviation and the variance used in statistics.
    The formula the `var()` function uses by default is
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/321math.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *μ* is the mean, the *x*[*n*] values are individual data points, *N* is
    the total number of data points, and *σ*² is the *sample variance*, or the variance
    with Bessel’s correction applied. The standard deviation `std()` is just the positive
    square root of this.
  prefs: []
  type: TYPE_NORMAL
- en: In order to calculate the *population variance* and *population standard deviation*,
    supply the keyword argument `corrected` with a value of `false` to either of these
    functions. This will replace the 1/(*N –* 1) term in the formula with 1/*N*. Explaining
    the origin of the correction would take us too far into the arcana of statistical
    theory, but for most purposes, the defaults are what you want, and it makes little
    difference for reasonably large *N* in any case.
  prefs: []
  type: TYPE_NORMAL
- en: In either incarnation, the standard deviation is a measure of the average distance
    from the mean of a set of observations or of a theoretical distribution. It tells
    us how “spread out” the distribution is.
  prefs: []
  type: TYPE_NORMAL
- en: '**Distributions**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ve looked at several examples of how we can do a lot with simple, uniformly
    distributed random numbers. However, not every random occurrence is uniformly
    distributed. Most things in nature display other types of distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the heights of adults in a particular city. Obviously, you don’t expect
    that the probability of finding a 7-foot-tall adult is the same as finding one
    with closer to average height: heights are not uniformly distributed. If you make
    a graph, dividing the horizontal axis into height ranges covering, say, intervals
    of 2 inches, and collect the heights of a sample of residents, you can plot how
    many heights fall into each interval. After collecting a large number of measurements,
    this plot will start to look like a smooth curve, something like [Figure 10-4](ch10.xhtml#ch10fig4).
    It has two peaks, because the average height of men is a little higher than women,
    and it shows that there are more people close to the average than very tall or
    very short.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-4: Possible histogram of adult heights*'
  prefs: []
  type: TYPE_NORMAL
- en: This type of graph is called a *histogram*; it is one way to represent a *distribution*.
    Probability distributions are the mathematical objects at the center of statistics,
    just as a probability forms, naturally, the central idea of probability theory.
    A distribution simply tells you how much of your data, or what proportion of your
    data, falls within different ranges. As a description of actual data it’s called
    an *empirical distribution*, whereas if it comes from a model it’s a *theoretical
    distribution*.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can think of the discipline of statistics this way: probabilities tell
    us how likely something is to happen, and the mathematics of probability theory
    lets us elaborate this, telling us the likelihood of combinations of events and
    answering related questions. Statistics is the reverse: it starts with observations,
    and lets us systematically infer the probabilities that led to those observations.
    With these probabilities, we can make predictions about future observations.'
  prefs: []
  type: TYPE_NORMAL
- en: Julia provides several packages and a great number of functions for helping
    out with statistics, including functions for statistical graphing. To produce
    a histogram like the one shown in [Figure 10-4](ch10.xhtml#ch10fig4), simply call
    (after `using Plots`) `histogram(data, bins = 100)`. The `data` in this call is
    the actual series of observations; the `bins` tells the routine to use that number
    of intervals to construct the histogram. For each interval, it will count the
    number of observations in `data` and draw the rectangle at the appropriate height.
    The area of each rectangle represents the number of observations in the horizontal
    axis interval that it covers. Beware that the same dataset may produce very different
    plots when choosing different numbers of bins; some choices will better reflect
    the underlying distribution than others. If you leave out the `bins` argument,
    the `histogram()` routine will attempt to choose the “best” value, using a formula
    from statistical theory that is designed to best represent the data. This formula
    does not always work perfectly, so the careful scientist or statistician will
    always be aware of the nature of the data being plotted, and intervene manually
    if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Normal Distribution***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider the `rand()` function described earlier in this chapter. Since it generates
    a floating-point number that is equally likely to be anywhere in the interval
    from 0 to 1, the mean value of the numbers it returns should be 0.5\. The number
    is just as likely to be greater than 0.5 as to be smaller than that midpoint.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means if you call `rand()` many times, and calculate the mean of the results,
    you should get something fairly close to 0.5: `mean(rand(1000))` should be approximately
    0.5\. I did it just now and got 0.49869515604579906\. Intuitively, you may expect
    if you use a number smaller than 1,000, the mean is more likely to be farther
    from 0.5, and that is correct.'
  prefs: []
  type: TYPE_NORMAL
- en: But even using 1,000 numbers, the mean will rarely be exactly 0.5\. Since (unless
    you reset the seed) you will get a different set of random numbers each time,
    the mean will be different each time, as well. The numbers themselves, as you
    know, are uniformly distributed in [0, 1). If you call `mean(rand(1000))` many
    times, how will the *means* be distributed?
  prefs: []
  type: TYPE_NORMAL
- en: You know they can’t be distributed uniformly, because they are more likely to
    be near 0.5 than far from it. But what exactly is the distribution of the means?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s write a little program to find out. Even those who have studied statistics
    and know what to expect may find the numerical experiment in [Listing 10-4](ch10.xhtml#ch10lis4)
    interesting.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-4: Exploring the distribution of the mean*'
  prefs: []
  type: TYPE_NORMAL
- en: The program is a straightforward calculation of the `N` means of 1,000 random
    numbers. To see how these means are distributed, we turn to the `histogram()`
    plotting function introduced earlier in the chapter. The purpose of this function
    is exactly to display distributions. The `"Empirical"` label indicates that the
    histogram is the result of a numerical experiment. [Figure 10-5](ch10.xhtml#ch10fig5)
    shows the result.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-5: Distribution of the mean of uniform random numbers*'
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, the distribution of the means is not uniform. As we expect, it shows
    that means closer to 0.5 are more frequent.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, from a central result in probability theory, we can predict the precise
    mathematical form of this distribution. It should be
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/324math.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *x* is the random variable whose distribution we are describing, *σ* is
    the standard deviation, and *μ* is the mean.
  prefs: []
  type: TYPE_NORMAL
- en: This is the equation for the famous *normal distribution*, also called the *Gaussian*.
    Does it describe the empirical distribution from the program? We don’t need to
    translate the equation into code to find out. This distribution is so crucial,
    it’s included in the second most important Julia package for statistical work,
    `Distributions`.
  prefs: []
  type: TYPE_NORMAL
- en: Once you import this package into your namespace, the function `Normal`(μ, σ)
    creates a normal distribution with a mean of μ and a standard deviation of σ.
    You can interact with the distribution by sampling from it using the `rand()`
    function. For example, if you create a normal distribution with a mean of 10 and
    a standard deviation of 2 with `d = Normal(10, 2)`, you can draw 10 samples from
    it with `rand(d, 10)`. Calling `rand()` without supplying an explicit distribution,
    as we’ve been doing up to now, uses the uniform distribution by default.
  prefs: []
  type: TYPE_NORMAL
- en: One way to see if the empirical distribution shown is predicted by the normal
    distribution is to take a healthy sample from the normal distribution and plot
    its histogram with the previous one. To make the plot easier to see, instead of
    trying to plot two `histogram()` plots on the same graph, we can plot the second
    one using a different type of histogram display by supplying the `:scatterhist`
    series type to the normal `plot()` command. Adding the four additional lines shown
    in [Listing 10-5](ch10.xhtml#ch10lis5) to the program in [Listing 10-4](ch10.xhtml#ch10lis4)
    makes the graphical comparison that we want.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-5: Sampling from the normal distribution*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 10-6](ch10.xhtml#ch10fig6) shows that the two distributions are close,
    as theory predicts.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-6: Comparing the empirical and theoretical distributions*'
  prefs: []
  type: TYPE_NORMAL
- en: Note that in order to compare two histograms directly, they must have the same
    bin width, or both be normalized. In these examples, I allow the routines to compute
    the bin width automatically, knowing that for similar distributions the widths
    would be the same.
  prefs: []
  type: TYPE_NORMAL
- en: The `Distributions` package provides many probability distributions in addition
    to the normal distribution. It also includes many functions for using these distributions,
    along with other statistical tools.
  prefs: []
  type: TYPE_NORMAL
- en: '***Probability Density Functions***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One of those tools is `pdf()`, which stands for *probability density function*.
    This function describes the distribution in the following sense: if you integrate
    the probability density function over a certain interval, the result is the probability
    that an observation lies within that interval. In other words, the probability
    that an observation lies between *a* and *b* is the area under the distribution
    curve between *a* and *b*.'
  prefs: []
  type: TYPE_NORMAL
- en: Usually, when referring to the graph of a distribution, we mean the graph of
    its probability density function. The integral over the entire distribution must
    exist and be equal to 1, because it is certain that any observation must have
    some value within the range of possible values.
  prefs: []
  type: TYPE_NORMAL
- en: 'All of the `histogram()` plotting types have an optional `normalize` keyword
    argument that can be set to `true` to make the histogram plot indicate probabilities
    rather than raw counts—for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Those three lines repeat the plots of the two histograms just plotted in [Figure
    10-6](ch10.xhtml#ch10fig6), but normalized. Now the areas of the histogram rectangles,
    shown in [Figure 10-7](ch10.xhtml#ch10fig7), are probabilities rather than raw
    counts. The new curve is a plot ➊ of the probability density function of the normal
    distribution with the same mean and standard deviation as the sample. It is a
    graph of the equation for *ϕ*, displayed after [Figure 10-5](ch10.xhtml#ch10fig5).
    [Figure 10-7](ch10.xhtml#ch10fig7) shows how accurately it predicts the results
    of the numerical experiment in [Listing 10-4](ch10.xhtml#ch10lis4).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-7: Adding the probability density function*'
  prefs: []
  type: TYPE_NORMAL
- en: Because of the normal distribution’s importance, Julia provides another function,
    similar to `rand()`, that returns normally distributed random numbers rather than
    uniformly distributed ones. The `randn()` function is part of `Base`, so you don’t
    need an `import`. It returns single numbers or arrays, normally distributed with
    a mean of 0 and a standard deviation of 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s repeat the plot from [Listing 10-1](ch10.xhtml#ch10lis1) using `randn()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The only difference is in using `randn()` instead of `rand()`. [Figure 10-8](ch10.xhtml#ch10fig8)
    shows the result. As in [Figure 10-1](ch10.xhtml#ch10fig1), each of the 10⁵ numbers
    is represented by a tiny dot, but now the dots are not uniformly distributed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-8: Normally distributed random floats*'
  prefs: []
  type: TYPE_NORMAL
- en: Instead, they are crowded around the value 0 on the vertical axis, with their
    density getting thinner the farther they are from 0, the mean of their distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dealing with Data**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, all the “data” in this chapter has been either made up or the result
    of collecting results from numerical pseudorandom processes. If you are using
    Julia for statistical analysis, the odds are good that you have some actual, real-life
    data to analyze.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll explore the most important methods in Julia for dealing
    with real data. We’ll look at a data type that comes in handy when manipulating
    data in the real world, how to read data from the most common types of datafiles,
    how to use dataframes to view and analyze this data, and how to take advantage
    of Julia’s statistical packages to understand and visualize numerical information.
  prefs: []
  type: TYPE_NORMAL
- en: '***Missing Values***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There is an unusual data type I didn’t mention in [Chapter 8](ch08.xhtml) because
    I was saving it for this chapter. It’s a singleton type called `Missing`, and
    it is used to represent missing values.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you have a sensor that is supposed to record the temperature inside
    a tank of water at regular intervals of time. Unfortunately, every now and then
    it fails to record a measurement. Those failures are recorded as 0s, but that
    number is far outside the range of possible measurements, so these failures can’t
    be mistaken for actual temperatures. At the end of the experiment you have two
    vectors, or perhaps two columns of a matrix, one for the times of the measurements
    and the other for the temperatures. When analyzing this data, you don’t want the
    false zero temperatures to be included in the analysis because that would distort
    your calculations. You want a better solution than simply deleting the failed
    readings because that would create a false record of what actually happened in
    the experiment, and, to keep the timing and temperature vectors the same length,
    perhaps for plotting the results, you will have to delete the corresponding entries
    from the timing vector, leading to a time sequence containing gaps.
  prefs: []
  type: TYPE_NORMAL
- en: The `Missing` type provides one solution to this set of problems and others—for
    example, in data science, where the concept of missing values arises. It has some
    properties that may seem peculiar, illustrated in [Listing 10-6](ch10.xhtml#ch10lis6),
    which is a REPL session exploring arithmetic on the `Missing` type.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-6: Arithmetic properties of* missing *values*'
  prefs: []
  type: TYPE_NORMAL
- en: We see from [Listing 10-6](ch10.xhtml#ch10lis6) that arithmetic on `missing`
    values leads to a `missing` result, even when dividing by 0.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, `missing` values are not floating around by themselves, but are found
    as part of a collection of data. [Listing 10-7](ch10.xhtml#ch10lis7) is a little
    function that creates an array, replaces some of its values with `missing` values,
    and plots the result.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-7: Creating some missing data for plotting*'
  prefs: []
  type: TYPE_NORMAL
- en: We need to declare the array to be able to accept `missing` values as well as
    floating-point numbers. If we omit this declaration, the compiler will complain
    when we try to assign `missing` to any location in the array because it will have
    defined it as `Vector{Float64}`.
  prefs: []
  type: TYPE_NORMAL
- en: The plot in [Figure 10-9](ch10.xhtml#ch10fig9) shows that `Plots` knows how
    to handle missing data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-9: Plotting with missing data*'
  prefs: []
  type: TYPE_NORMAL
- en: By default, it leaves a gap where there are `missing` values.
  prefs: []
  type: TYPE_NORMAL
- en: '**Functions for Handling Missing Values**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Julia provides several functions to do convenient things with `missing` values.
    To illustrate what these do, suppose we have an array, `a`, with some numbers
    and some `missing` elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want the sum of the *numbers* in the array, you might try `sum(a)`,
    but if you refer to [Listing 10-6](ch10.xhtml#ch10lis6), you will see that, since
    adding a number to a `missing` value yields `missing`, the end result of the `sum()`
    operation will just be `missing`. Here, Julia’s `skipmissing()` function, which
    does as its name suggests, comes to the rescue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The `skipmissing()` function, which is built into `Base`, returns an iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run that loop, you’ll see this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: If you need to make a new array with the `missing` values omitted, use `collect(skipmissing(a))`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If, instead, you want to make an array with a particular value substituted
    for the `missing` values in the original array, the function for that is `coalesce()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Notice how we need to use the dot operator to apply `coalesce()` to all the
    elements of the vector, and how the type of the returned array is no longer a
    `Union` with `missing`.
  prefs: []
  type: TYPE_NORMAL
- en: If you have a program that analyzes data, and want to generalize it so it can
    handle data collections with `missing` elements, the `skipmissing()` function
    makes that task relatively straightforward. You may only have to replace occurrences
    of your data arrays with `skipmissing()` acting on those arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may, however, prefer an approach that does not litter your code with a
    multitude of calls to `skipmissing()`. You can take advantage of Julia’s multiple
    dispatch to define your own methods for `sum()`, and for any other functions that
    operate on your data arrays, to handle `missing` elements however you like. If,
    whenever you `sum()` an array of data (and keeping in mind the warning about type
    piracy from [Chapter 8](ch08.xhtml)), you know that you will always want the `missing`
    values ignored and the numerical values added together, you can define a method
    this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: That example works for integers, but it’s easily modified for other numerical
    types.
  prefs: []
  type: TYPE_NORMAL
- en: The function `ismissing()` returns `true` if its argument is `missing` and `false`
    otherwise. It’s often more expressive than comparing against the `Missing` type
    in data expressions.
  prefs: []
  type: TYPE_NORMAL
- en: The `Missings` package provides a few more convenience functions for dealing
    with this data type. This package is not in the standard library, so you’ll have
    to `add` and `import` it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyone making use of `missing` values is likely to appreciate two functions
    from this package. As shown in [Listing 10-7](ch10.xhtml#ch10lis7), it’s a little
    cumbersome to define a vector that can hold both the needed numerical type and
    optional values—and, more important, you may have a numerical array that you need
    to convert to a type that will allow you to add `missing` values to it. The following
    little REPL session shows how to use the `allowmissing()` function from the `Missings`
    package, which solves both of these problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: You can convert a `Vector{Union{Missing, Float64}}` type back into a pure floating-point
    numerical type using `Missings.disallowmissing()`, but first you must eliminate
    any `missing` values from it.
  prefs: []
  type: TYPE_NORMAL
- en: '**Logic with Missing Values**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Before leaving the topic of Julia’s `Missing` data type, let’s look at how it
    behaves in the context of logic expressions. We typically think of operations
    on logical values as following a two-valued (Boolean) logic, where the only possible
    values are `true` and `false`, a calculus that is reviewed in “Logic” on [page
    31](ch02.xhtml#ch02lev1sec3). The `missing` value expands the world of Boolean
    logic to encompass a third truth state, which is neither `true` nor `false`, but
    indeterminate. In Julia, the `missing` type, along with bitwise AND (`&`), bitwise
    OR (`|`), bitwise exclusive OR (`xor`), equality (`==`), and negation (`!`), form
    a system of three-valued logic.
  prefs: []
  type: TYPE_NORMAL
- en: The results of a logical expression thus can be `true`, `false`, or `missing`.
    The following list shows how the system works, and after some thought, the entries
    should make intuitive sense. For example, the result of `true | missing` is `true`
    because the result will be `true` *no matter the truth value of the second operand*.
    And the result of `true & missing` must be `missing`, because it will *depend*
    on the truth value of the second operand, which is undetermined.
  prefs: []
  type: TYPE_NORMAL
- en: true | missing   `true`
  prefs: []
  type: TYPE_NORMAL
- en: true & missing   `true`
  prefs: []
  type: TYPE_NORMAL
- en: false | missing   `missing`
  prefs: []
  type: TYPE_NORMAL
- en: false & missing   `false`
  prefs: []
  type: TYPE_NORMAL
- en: xor(true, missing)   `missing`
  prefs: []
  type: TYPE_NORMAL
- en: xor(false, missing)   `missing`
  prefs: []
  type: TYPE_NORMAL
- en: '!missing   `missing`'
  prefs: []
  type: TYPE_NORMAL
- en: missing == missing   `missing`
  prefs: []
  type: TYPE_NORMAL
- en: missing === missing   `true`
  prefs: []
  type: TYPE_NORMAL
- en: Since the truth value of `missing == missing` depends on the values of the missing
    items, it is itself `missing`. However, since `missing` is a singleton type, all
    instances of it are the same object; hence `missing === missing` must be `true`.
  prefs: []
  type: TYPE_NORMAL
- en: '***CSV Files***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Data that’s of moderate size often comes in the form of a comma-separated value
    (CSV) file. These are text files with items delimited by commas, and optionally
    with descriptive headers. They have the considerable advantages of being human
    readable and amenable to processing with all of the Linux command line tools.
    But they have the disadvantages of taking up more space than necessary, being
    less efficient than binary representations, and possibly not faithfully representing
    the original values after conversion into text. For those reasons, this format
    is probably not the best choice for storing, say, the output of a physics simulation.
    However, CSV is perhaps the most common format for distributing what are commonly
    called “statistics,” such as demographic data or the pandemic data that we’ll
    explore later.
  prefs: []
  type: TYPE_NORMAL
- en: You may be tempted to write your own programs for reading CSV files, parsing
    them, and turning them into some Julia data structure. If you’ve come this far
    in the book, you will certainly be able to do so. However, it would be wise to
    resist the temptation, except as an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'For real work, it’s a better idea to use the `CSV` package, which we’ll need
    to `add` in the package manager. This package can handle any delimiter, in addition
    to commas: the popular tab-separated file format as well as any custom format
    you may come across. It’s even able, in many cases, to figure out by itself what
    delimiter the file is using. This delimiter need not be limited to a single character;
    it can be a string as well. The `CSV` package can deal with comments mixed in
    with the data, column headers, and anything else you’re likely to encounter. It
    can read files from disk or, given a URL, can fetch them over the internet. It
    can handle dates in any format and transform labels into more code-friendly forms.
    Perhaps most importantly, it transforms the textual information into a Julia data
    type that can be further transformed into one of several different table-like
    data formats designed to be easily manipulated for statistical work.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Dataframes***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The most important of these table-like data structures is `dataframe`, provided
    by the `DataFrames` package, which also needs to be `add`ed. Indeed, as the data
    structure returned by CSV after it reads a file is not the most convenient for
    exploration, the usual strategy is to immediately transform it into a `dataframe`.
  prefs: []
  type: TYPE_NORMAL
- en: A `dataframe` is a table of values, like a matrix, but with extra functionality
    designed for data exploration. Along with the `dataframe` data type, the `DataFrames`
    package exports several functions for manipulating it. In addition, many Julia
    functions with which you are already familiar have methods that extend their functionality
    to the `dataframe`.
  prefs: []
  type: TYPE_NORMAL
- en: It is most useful to think of a `dataframe` as a set of columns stuck together.
    Each column has a unique name. A column can be referred to with its integer index,
    with its name as a string, or with its name as a symbol. When you are examining,
    plotting, or manipulating data, you are doing these things to `dataframe` columns.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*We treat dataframes as sets of columns for data analysis and visualization.
    However, most Julia functions that operate on collections treat dataframes as
    collections of rows. See “Further Reading” on [page 359](ch10.xhtml#fur10) for
    an illuminating article on this subject.*'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider an example using real-life data that comes in a typically messy
    form. Our journey through this data will make the earlier discussion of dataframes
    concrete and introduce the important functions for wrangling data from sources
    in the wild.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some data from the COVID-19 Data Repository maintained by the
    Center for Systems Science and Engineering (CSSE) at Johns Hopkins University
    ([*https://github.com/CSSEGISandData/COVID-19*](https://github.com/CSSEGISandData/COVID-19)).
    This data comes in the form of CSV files, using an actual comma as a delimiter.
    The first line contains headings to describe each data column, but the format
    of those headings will make subsequent manipulation in Julia inconvenient. The
    first problem is that some of the headers are names of countries or territories
    that contain spaces. The second is that some of the headers are dates, but these
    are in a format that we need to take into account so that they are parsed correctly.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*The datafile used in the examples here is available in the online resource
    area under the name* time_series_covid19_confirmed_global.csv*. The CSSE data
    grows in size over time, so some of the plots shown in this section may become
    unwieldy with future versions of the file from Johns Hopkins.*'
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, the file reading function in the `CSV` package is equipped to deal
    with both of those common issues. [Listing 10-8](ch10.xhtml#ch10lis8) shows the
    instructions for reading the CSV file and converting it immediately into a `dataframe`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-8: Reading a CSV file*'
  prefs: []
  type: TYPE_NORMAL
- en: The `normalizenames` option replaces spaces and other troublesome characters
    in column names with underscores and performs any other transformations needed
    to turn header text into legal Julia identifiers. The `dateformat` keyword argument
    should be self-explanatory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first argument to `CSV.File()` is the name of the file on disk, which I
    previously downloaded and saved. Another option is to pass the URL of the file
    here. `CSV.File()` will recognize this and automatically download the data over
    the internet. The date format is determined by inspecting the file, whose first
    line, which contains the column headers, looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: There are 432 columns. The end of the second command in [Listing 10-8](ch10.xhtml#ch10lis8)
    converts the `CSV.File()` object into a `DataFrame` object, which is stored in
    the variable `covdat`. If this is executed in a REPL, Julia will print out a truncated
    representation of the dataframe. [Figure 10-10](ch10.xhtml#ch10fig10) shows what
    that looks like. In this particular case, I’ve narrowed the REPL window so it
    fits better on the page.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-10: Representation of a dataframe in the REPL*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The display indicates how much information has been omitted, the names of the
    visible columns, and the type of data they contain. A question mark after the
    data type means some values may be `missing`. Here is a typical use for the `missing`
    data type: most of the countries in the files do not have a province listed, but
    a few do. Missing data is represented in the original CSV file by a number that
    is . . . missing.'
  prefs: []
  type: TYPE_NORMAL
- en: The fancy display of dataframes in the REPL is accomplished by `show()`, usually
    implicitly. A `print()` of a dataframe spits out the whole thing, without the
    nice formatting or type information, and is usually not what you want. In addition,
    `show()` can create HTML and LaTeX versions, and control other aspects of the
    dataframe display. Consult the REPL help to learn the details.
  prefs: []
  type: TYPE_NORMAL
- en: '**The @df Macro**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'For the rest of the chapter, we’re going to make extensive use of a macro found
    in the `StatsPlots` package called `@df`. It’s part of `StatsPlots` because it’s
    especially effective at making commands for plotting from dataframes more concise,
    but its use is not limited to `plot()` commands. From this point on, the following
    command is assumed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The `@df` macro does what macros do best: it rewrites code so that our programs
    are easier to write and read. This macro has one job: it replaces symbols in an
    expression with the columns of the dataframe that appears as its first argument.
    This simple expression rewriting is enough to make this macro popular because
    it frees the programmer from having to repeat the name of the dataframe multiple
    times in an expression. Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In this expression, the symbol `:_1_1_21` is converted to `covdat._1_1_21` each
    time it appears. The argument of the macro following the name of the dataframe
    must be a block or a function call, so the above would fail without wrapping the
    result in the `print()` function.
  prefs: []
  type: TYPE_NORMAL
- en: Since `Symbols` are converted into dataframe columns when using the `@df` macro,
    we need some syntax to indicate when a `Symbol` should be left alone—for example,
    if there is a conflict between a column name and a symbol used for another purpose.
    The macro provides the “`^()`” wrapper to handle these conflicts. If, for example,
    a column called “topleft” happens to be in your dataframe, you’ll need to use
    the syntax `legend=^(:topleft)` in the plotting command to put the legend in the
    Northwest.
  prefs: []
  type: TYPE_NORMAL
- en: '**Indexing and Filtering Dataframes**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A dataframe can be indexed and filtered using the same methods that we apply
    to matrices. However, dataframes come with some extra indexing methods that let
    us take advantage of their named columns.
  prefs: []
  type: TYPE_NORMAL
- en: I include in this chapter only the indexing and filtering methods that I think
    are most likely to be useful in the majority of cases. There are, in addition
    to everything covered here, several packages that supply macros and functions
    providing yet more ways to select and transform the information in a dataframe.
    Their intention is to allow a more streamlined syntax for certain common tasks,
    and these packages can be convenient. However, most of them are in somewhat of
    a state of flux. As in most sections in this book, I try to confine myself to
    methods that have solidified—that you can learn once and use forever.
  prefs: []
  type: TYPE_NORMAL
- en: 'Items in a dataframe can be extracted using the familiar forms of integer indexing.
    Here are a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice how the data type of the result depends on how we index the dataframe.
    If we ask for one element ➊, we get back a single value, in this case a string.
    If we ask for a range of rows in a single column ➋, we get a `Vector`. Finally,
    if we extract data horizontally, by indexing a single row and a range of columns
    ➌, we get a data type that we haven’t seen before: a `DataFrameRow`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s ask Julia for a range of rows and a range of columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We get back a smaller dataframe. What else could it be?
  prefs: []
  type: TYPE_NORMAL
- en: We don’t have to count indices to refer to columns, but can use their names,
    as in [Listing 10-9](ch10.xhtml#ch10lis9).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-9: Selecting columns by name*'
  prefs: []
  type: TYPE_NORMAL
- en: 'We use `Symbol`s to index the dataframe’s columns. For each column title, a
    `Symbol` with the same name is created for efficient indexing. We could just as
    well have used the string versions of the column names in [Listing 10-9](ch10.xhtml#ch10lis9),
    but using `Symbol`s is more efficient. This is one reason for using `normalizenames`
    when reading the data: headers containing spaces would not be valid `Symbol` names,
    and we would be forced to use the string versions. [Listing 10-9](ch10.xhtml#ch10lis9)
    shows the last three countries, their latitude and longitude, and the number of
    COVID cases on January 22, 2021.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The headings of the columns for latitude and longitude have data types printed
    with question marks. This means somewhere in this table is a country or a province
    with one or both of these values missing. To see those countries or provinces,
    we need to find the *row* in the table where `:Lat` or `:Long` has the value `missing`.
    To select rows from a dataframe where one or more columns satisfy some condition,
    we can use the `filter()` function (described in “The filter() Operator” on [page
    163](ch06.xhtml#ch06sec1sec4). The `DataFrame` package extends the `filter()`
    function to operate on dataframes by filtering rows and returning a new dataframe.
    The following line of code filters our COVID dataframe, looking for the rows with
    missing latitude or longitude:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The result is a dataframe with a single row, with the curious notation `Repatriated
    Travellers` in place of the province.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than use the `filter()` function, you can get the same result with bitmask
    indexing or any other technique that works with normal arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice in the example just shown how we specified the columns for the filter
    using the column names as bare words. This is yet another form of indexing, which
    is convenient in filter expressions. We can also use that syntax to select columns
    from the dataframe, turning them into `Vector`s:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Since selecting columns provides us with `Vector`s, we can use this form of
    indexing for plotting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Nothing mysterious is going on here. We simply extracted two vectors from the
    dataframe and plotted them in the usual way, resulting in [Figure 10-11](ch10.xhtml#ch10fig11).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-11: Cases vs. country*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This plot is not ideal, however. It shows us something about the distribution
    of the number of cases on the date in question, but the horizontal axis is essentially
    useless because there is no room for hundreds of country labels. Perhaps, instead
    of trying to plot all the data at once, it would be more useful to plot some meaningful
    subset. Let’s limit our visualization to the countries with a lot of cases, by
    using the filtering mechanism we just learned. Also, let’s switch to a bar chart,
    which is the more appropriate visualization for this type of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have something useful: a chart of the countries with more than two million
    cases on New Year’s Day 2021, shown in [Figure 10-12](ch10.xhtml#ch10fig12).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-12: Countries with over two million cases*'
  prefs: []
  type: TYPE_NORMAL
- en: In the previous indexing commands, we used integer indexing to select columns,
    which worked well, but required us to count to the first column of interest. Also,
    it was only convenient because we knew that the columns we wanted extended to
    the end, which simplified the indexing expression.
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative that lets us use column names directly is the `Between()` function.
    The equivalent expression for selecting the date columns is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This can be easily modified to choose any closed interval of columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another option is the `Not()` function. Here is a selection that returns the
    same `DataFrameRow` as the previous one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The columns that remain after the listed ones are excluded are just the ones
    we want: the date columns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also select columns using regular expressions applied to the names of
    their titles. Here is another way to make the same selection, returning the same
    `DataFrameRow`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Sometimes this is the most convenient way to select data. For example, if we
    want to extract only the columns for February 2021 for Afghanistan, we could just
    say `covdat[1, r"_2_\d*_21"]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'But what if we want to make a `DataFrameRow` with all the date columns *and*,
    say, the `Country_Region` column (but none of the other ones)? None of the indexing
    techniques we’ve seen so far make this convenient, although you might be able
    to twist them to get the desired result. There is no need for contortions, however,
    because we can use the `Cols()` function. The following lines show four different
    ways to use this function to get a `DataFrameRow` similar to the one we created
    using multiple techniques earlier, but with the addition of the `Country_Region`
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see, the `Cols()` function lets you pick out individual columns or
    ranges of columns using numerical indices, regular expressions, or column names
    either as symbols or as strings. It can also reorder columns. The following rearranges
    the `covdat` dataframe to place the latitude and longitude columns at the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: With this, we have a large enough toolbox to do most of the indexing, selecting,
    and rearranging of dataframes that we’re likely to encounter in our work.
  prefs: []
  type: TYPE_NORMAL
- en: '**Mutating Dataframes**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The indexing expressions `covdat[:, :Country_Region]` and `covdat.Country_Region`
    both seem to return a `Vector` with contents identical to the `Country_Region`
    column of the dataframe called `covdat`. However, they are not identical:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This tells us that while the two left- and right-hand sides contain the same
    values, they are not the same object. The syntax `dataframe[:, :col]` makes a
    *copy* of the column and returns it as a `Vector`. But `covdat.Country_Region`
    is a *reference* to the column. If you have a choice, avoid making unnecessary
    copies, as it is slower and consumes memory. Also, if you want to mutate a column
    by assigning to individual elements, you must use a reference rather than a copy,
    as shown in [Listing 10-10](ch10.xhtml#ch10lis10).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-10: Mutating a dataframe*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The direct dot syntax used here only works when using a literal column name
    after the dot, not with a variable holding a column name. If you’re using variables
    to hold the names of columns, you must use square brackets. However, that doesn’t
    mean you are obligated to make copies of columns. Another syntax allows you to
    use square brackets to reference a column using a variable, and without making
    a copy: `dataframe[!`, var`]` means the same thing as `dataframe.columnname` if
    var is set to `"columnname"`.'
  prefs: []
  type: TYPE_NORMAL
- en: A command such as `covdat[:, c][1] = "Disneyworld"` will have no effect on the
    original dataframe. However, the assignment in [Listing 10-10](ch10.xhtml#ch10lis10)
    can also be written as
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: which will mutate the dataframe. The meaning of the exclamation point is suggested
    by its use in mutating functions, introduced in “Functions That Mutate Their Arguments”
    on [page 56](ch02.xhtml#ch02lev1sec17).
  prefs: []
  type: TYPE_NORMAL
- en: '**Transposing Dataframes**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Dataframes make it convenient to plot or operate on columns of data. But suppose,
    using the data in the `covdat` dataframe, that you wanted to plot the time histories
    of case numbers for various countries. For each country, its time series is the
    part of the *row* for that country starting in the fifth column. We know, from
    the indexing section earlier, that we can extract rows from the dataframe, and
    that doing so gets us not a `Vector`, but a `DataFrameRow`. This means that, for
    plotting, we need to convert the result into a `Vector`. Here is one way to put
    all of this together to plot the time histories of COVID cases in the US:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'I snuck in a function you haven’t seen before: `names()` returns the names
    of the columns in a dataframe in the form of a `Vector` of strings, so it is what
    we need to make meaningful x-tick labels.'
  prefs: []
  type: TYPE_NORMAL
- en: The listing employs the `@chain` macro introduced in “The @chain Macro” on [page
    174](ch06.xhtml#ch06sec1sec8). The pipeline syntax is popular when wrangling data
    from dataframes, as this activity inherently involves a series of transformations.
    The code snippet will produce the desired timeline plot, shown in [Figure 10-13](ch10.xhtml#ch10fig13).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-13: US cases vs. date*'
  prefs: []
  type: TYPE_NORMAL
- en: Now, to compare different countries, I would merely need to repeat the plotting
    pipeline using `plot!()` to add a new curve, substituting the country name of
    interest.
  prefs: []
  type: TYPE_NORMAL
- en: You may be thinking that there is a lot to type just to plot a row of data,
    and that this could be a bit of a drag for interactive work. Again, all this typing
    is required because the intention behind dataframes is to deal with them as a
    set of columns, so plotting rows is going against the grain. It would be smoother
    to go with the dataframe flow and somehow flip the dataframe around first, so
    the rows become columns. This would make the code easier to write and read. Selecting
    the data to plot would be more direct, and it would come in the form of a `Vector`
    that can be plotted immediately, eliminating the need for conversion.
  prefs: []
  type: TYPE_NORMAL
- en: We want to end up with a series of columns for different countries, with each
    column containing the series of case numbers for the country. If we have that
    kind of dataframe, we can plot any country’s case number history directly. We
    would also like a column containing the date labels to use in plots. We can omit
    the other columns. We don’t plan to use the latitude and longitude information
    in these plots or in our subsequent analysis, but they will remain in the original
    `covdat` dataframe if we need them. We are just making a new dataframe as a tool
    to ease our exploration of the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before proceeding, however, we need to do something about the fact that some
    of the country names appear more than once, because some of them are listed along
    with several entries for `Province_State`. If these country names are to become
    column titles, they must be unique. A little later on we’ll learn how to incorporate
    this data, but for now, we can simply eliminate the rows with provinces, keeping
    only the main country entries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'With the troublesome rows deleted, we can now safely exchange rows for columns.
    It probably sounds like we need some kind of transpose of the dataframe; however,
    the `transpose()` function, that we know and love from our work with matrices,
    will not work here. Fortunately, the `DataFrame` package comes with a function
    designed exactly for this purpose. We learned about the `permutedims()` function
    in “Adjoints and Transposes” on [page 144](ch05.xhtml#ch05lev1sec17), as a kind
    of generalized transpose operation. The `DataFrames` package extends this function
    to handle `DataFrame`s; here’s how to use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'In the first line, we get rid of the columns that we won’t need. The transpose
    happens in the second line, where the first argument to `permutedims()` is the
    dataframe to be transposed, the second argument selects the column from the original
    dataframe whose contents are to be used as column names for the transposed dataframe,
    and the third argument is the name to give the new column, whose contents will
    be composed of the column names of the original dataframe. Since we eliminated
    the `Province_State` column, the first column of `covmc` is now `Country_Region`,
    so the names in the column of countries are used as the new column titles. We
    can specify the column to pivot around using any kind of selector, so we could
    have written the following as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Our new dataframe, `cdcn`, appears as shown in [Figure 10-14](ch10.xhtml#ch10fig14).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-14: The* cdcn *dataframe in the REPL*'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one problem with our freshly transposed dataframe: some of the column
    titles now have spaces in their names. You can’t see them in the small piece of
    the dataframe shown in [Figure 10-14](ch10.xhtml#ch10fig14), but we know that
    they’re there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: It’s not a serious problem, but, as you now know, legal symbol names are more
    convenient and lead to neater and more efficient code.
  prefs: []
  type: TYPE_NORMAL
- en: The function `rename!()` transforms the column names of a dataframe in place
    (hence the mutation warning sign). It has several methods; the method that we
    shall use takes a function as its first argument and the dataframe to be altered
    as its second argument. The supplied function is applied to each column separately.
    The command in [Listing 10-11](ch10.xhtml#ch10lis11) replaces spaces with underlines
    in the column names of `cdcn`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-11: Renaming columns of a dataframe*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Did it work? Let’s take a peek at a relevant bit of the dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can plot time-dependent case numbers for selected countries with ease:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The `@df` macro from `StatsPlots` was useful there, as the command refers to
    several columns using `Symbol`s; without it, we would be obligated to mention
    the name of the dataframe each time. This `plot()` command produces the graph
    in [Figure 10-15](ch10.xhtml#ch10fig15).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-15: Timeline of cases in three countries*'
  prefs: []
  type: TYPE_NORMAL
- en: In a `plot()` command inside a `@df` macro call, the `cols()` function (note
    the lowercase) can be used to select a numerical range of columns with `cols(a:b)`,
    all the columns with `cols()`, or a column whose `Symbol` name is stored in a
    variable, with `c = :thecol` and `cols(c)`.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*Remember that* Cols*, with an uppercase C, is for column selection within
    square brackets and is part of* DataFrames.jl*, whereas* cols*, using lowercase,
    is a utility function for use in the* @df *macro, provided by* StatsPlots.jl.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With all the machinery that we now have under our belts, we can do more than
    plot random selections of countries. One thing that might be interesting is to
    plot only those countries whose caseloads rise above a certain level on any day
    included in the dataset. Here is one way to do that, using the `@df` macro and
    `cols()` function from `StatsPlots`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: The strategy is to collect the relevant columns as an array of `Symbol`s, so
    that we can select them in the `plot()` statements using `cols()`. [Figure 10-16](ch10.xhtml#ch10fig16)
    shows the result.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-16: Countries with large caseloads*'
  prefs: []
  type: TYPE_NORMAL
- en: '`StatsPlots` has turned the symbols identifying the columns into strings for
    the plot, providing a useful legend.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Summarizing Dataframes**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Another useful device that `DataFrames` provides is the `combine` function.
    This allows us to map a function onto a set of columns to create a new dataframe
    that is a summary of an existing dataframe. For example, suppose we want a table
    that contains the maximum number of cases seen for each country. The `combine()`
    function makes this simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: For each column in the range of columns defined in the second argument, `combine()`
    applies the `maximum()` function to its contents.
  prefs: []
  type: TYPE_NORMAL
- en: The `combine()` function creates new column names by appending the name of the
    function. If you would like to preserve the original name, pass in `renamecols
    = false`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This data is a good candidate for another bar chart, but it would be more convenient
    to have it transposed, with a column of countries and a column of maximums. We
    know how to do that now, but something is missing: we need to add a column to
    hold the new column names. [Listing 10-12](ch10.xhtml#ch10lis12) combines the
    methods we’ve learned to first make a permuted dataframe called `cdmp` and then,
    in the last line, copy only the rows with the largest caseloads into another dataframe,
    `cdmpc`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 10-12: Plotting maximum caseloads*'
  prefs: []
  type: TYPE_NORMAL
- en: 'After executing the code in [Listing 10-12](ch10.xhtml#ch10lis12), `cdmpc`
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'You see that there are only 14 countries that experienced a caseload of more
    than two million during the time period covered by this dataset. Now we can make
    a bar chart with this simple command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This creates the graph in [Figure 10-17](ch10.xhtml#ch10fig17).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-17: The highest maximum caseloads*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The need for summary statistics of the data in a dataframe is so common that
    a function is available that does the foregoing work for us, but it’s good to
    know how to do it “manually,” in case you need something it doesn’t provide. That
    function is called `describe()`, and here’s how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: That’s certainly easier! By default, `describe()` returns a `DataFrame` with
    the means and medians as well, but those are not meaningful for these timelines,
    so we limit the statistics calculated by passing a symbol, `:max`, for the one
    we want. The function can calculate the other summary statistics as well, such
    as standard deviation, and automatically skips `missing` values. It can even report
    the number of `missing` values in each column, if you so desire.
  prefs: []
  type: TYPE_NORMAL
- en: '**Grouping Dataframes**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Earlier we threw away some of the data, namely the additional provinces for
    the several countries for which such entries existed. As promised, we’ll now find
    a way to include that information.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s suppose we are not interested in looking at the data for individual provinces,
    but instead would like to add up the numbers for all the provinces belonging to
    each country and just look at the total case numbers. This makes a bit more sense
    than just deleting that data. The most convenient way to do this kind of thing
    involves the concept of the *grouped dataframe* and an associated new data type,
    the `GroupedDataFrame`.
  prefs: []
  type: TYPE_NORMAL
- en: A `GroupedDataFrame` is something like a vector of dataframes. Each dataframe
    in the vector is created from a source dataframe by collating the rows that have
    the same value in a chosen column. In our case, we’ll group by `Country_Region`.
    Most of the resulting members of the `GroupedDataFrame` will have a single row
    because most countries appear only once. But those countries that appear multiple
    times, because they have `Province_State` values, will give rise to members of
    the `GroupedDataFrame` with more than one row, with one for each `Province_State`.
  prefs: []
  type: TYPE_NORMAL
- en: One small wrinkle is that the members of a `GroupedDataFrame` are not actually
    dataframes, but have a new data type called `SubDataFrame`; however, the distinction
    is usually not important.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following will group the `covdat` dataframe by country:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Now `cvgp` is a `GroupedDataFrame`. Let’s examine it in the REPL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: The grouped dataframe has 192 members ➊, which tells us how may distinct countries
    are included in the data (remembering that one of them is `Repatriated Travellers`).
  prefs: []
  type: TYPE_NORMAL
- en: Subtracting that from the total number of rows ➋, we learn that 82 countries
    have provinces listed.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at individual members of `cvgp` ➌ ➍ confirms that these are dataframes
    devoted to individual countries. The next step is to add up the case numbers across
    all provinces for each date, so each country’s numbers will include all of its
    provinces. That’s what the `combine()` function is for. When I introduced `combine()`,
    we used it on a dataframe, but when applied to a grouped dataframe, it does exactly
    what we want, applying the specified function along the selected columns for each
    group member individually and then returning a normal `DataFrame` as the result.
  prefs: []
  type: TYPE_NORMAL
- en: 'First we need an array holding the columns to sum, which are the date columns,
    and then we can `combine()` them. We’ll store the result in a new variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Now `cvsm` has the same structure as our original `covdat`, but only 192 rows,
    one for each country. As before, it will be convenient to have on hand the transpose
    of this dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: And, as before, it’s better to normalize (remove the spaces from) the column
    names. After repeating the procedure from [Listing 10-11](ch10.xhtml#ch10lis11)
    on `cvsp`, we have a dataframe convenient for plotting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it’s easy to compare the timelines for France, both with and without its
    territories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 10-18](ch10.xhtml#ch10fig18) shows the results.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-18: Time history of the caseload in France*'
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, the inclusion of the `Province_State` columns makes a barely
    visible difference in the plot.
  prefs: []
  type: TYPE_NORMAL
- en: '**Multivariate Data**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The previous examples all dealt with timelines: a single quantity, in this
    case numbers of infections, as a function of date, for various countries. Another
    form of data involves the frequencies of a number of events in, say, different
    places, or compared among different demographic groups. [Figure 10-4](ch10.xhtml#ch10fig4)
    showed a simple example of this form of data, where the events are observations
    of height and the demographic groups are men and women.'
  prefs: []
  type: TYPE_NORMAL
- en: When you have data on more than one variable, you can use statistical methods
    to look for associations among them, always remembering that “correlation does
    not imply causation.” But an association can suggest that it might be worthwhile
    to look further, and the *lack* of correlation might be useful in ruling out hypotheses.
  prefs: []
  type: TYPE_NORMAL
- en: In the (made up) example of men’s and women’s heights, if we also had, from
    the same subjects, data about income level, or age, we could look for associations.
    Are richer people taller? When does the increase of height with age level off?
    Julia’s `DataFrame`s, combined with its convenient statistical functions and the
    visualizations provided by `StatsPlots`, make this kind of data exploration a
    relatively easy and pleasant task.
  prefs: []
  type: TYPE_NORMAL
- en: 'I compiled our second datafile from data maintained by the US Census Bureau
    ([*https://www.census.gov*](https://www.census.gov)). It is available in the supplementary
    website at [*https://julia.lee-phillips.org*](https://julia.lee-phillips.org),
    in the file named *census.dat*. The file is in tabseparated value format, with
    one line of column headers and comment lines that each begin with a hash mark
    (#). The data consists of absolute numbers of reported crimes in several categories
    in 2011 for each county in the US, plus a column for the total population of the
    county and one for the percentage of minors who did not complete high school.
    The comment lines give the totals for each state and for the entire country. Here
    are the first nine lines of the 3,143-line file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Clearly, the first thing we need to do is use the `CSV` package to read this
    and store it in a dataframe. The `CSV.File` function will detect that tabs are
    used as delimiters, and also that the first line is a header, but we should tell
    it about the comments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The second line eliminates any rows (there were three) with a zero population.
    As we plan to divide the absolute numbers by population to convert them into rates,
    we need to delete those rows. Here is the conversion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, our dataframe looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'How is a particular crime category, say, larceny, distributed among the counties?
    Are they all the same? How likely is it for a county to have an unusually high
    larceny rate? We can answer those kinds of questions with a histogram, which we
    can produce with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: In many commands that pull data from the dataframe, the `@df` macro will save
    some typing and make the code easier to read. The histogram, shown in [Figure
    10-19](ch10.xhtml#ch10fig19), shows that about 400 counties had no larceny at
    all during the report year, and most had rates (total number divided by population)
    below 2 percent. Above that rate, the distribution drops off steadily and fairly
    rapidly.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-19: Histogram of larcenies*'
  prefs: []
  type: TYPE_NORMAL
- en: 'With our dataframe set up, exploring this data in the REPL is simple (the following
    assumes that `Statistics` has already been imported):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The average larceny rate is about 1.4 percent. How is this crime correlated
    with other crimes? The correlation with murder is weak, meaning that knowledge
    of a high larceny rate in a particular county tells you nothing about its murder
    rate. However, the correlation with vehicle theft is significant: a county with
    a high larceny rate is a place where you are more likely to get your car stolen.
    That may not be surprising, but before we take it seriously, we should remember
    that the correlation coefficients calculated by the `cor()` function of the `Statistics`
    package are the Pearson coefficients, which assume a linear relationship between
    the two variables under consideration. Does such a linear relationship hold between
    these two crime categories? The way to answer this kind of question is with a
    scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: It does look from [Figure 10-20](ch10.xhtml#ch10fig20) as if there is at least
    a roughly linear relationship between the two rates, so the correlation coefficient
    is meaningful.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-20: Larceny–motor vehicle theft scatterplot*'
  prefs: []
  type: TYPE_NORMAL
- en: Using a small marker size combined with a low opacity is effective when making
    scatterplots with many points. The idea is that there are likely to be regions
    with a lot of overlap. Using small, transparent points allows the point density
    at any location to appear as a buildup of image density there. Using opaque or
    larger points would create a plot where we can’t distinguish between moderate
    and high densities once the markers begin to obscure each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'This idea is made more systematic with a plot recipe from `StatsPlots` called
    `histogram2d()`. As the name suggests, it takes two variables and creates a two-dimensional
    histogram. The result is similar to a scatterplot, but with the plane divided
    into cells and the cells colored according to the number of points they contain.
    Here is how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: As with ordinary histograms, we can adjust the number of bins if the automatic
    calculation is not optimal, but in this case, the algorithm does a good job. The
    result shown in [Figure 10-21](ch10.xhtml#ch10fig21) conveys information similar
    to the scatterplot in [Figure 10-20](ch10.xhtml#ch10fig20), but now we can read
    off the number of cases from the color map.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-21: Two-dimensional histogram of two categories of crime*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `describe()` function that we met earlier is useful for getting an overview
    of this type of data. The result can be made more concise by eliminating the uninteresting
    bits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: The last column in the description table informs us that there are no missing
    values. The reason for the composite data types is that the summary dataframe
    contained a row of county names that we eliminated with the indexing expression,
    so these columns actually contain a mix of numbers and strings.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can combine the two-dimensional histogram of [Figure 10-21](ch10.xhtml#ch10fig21)
    with normal one-dimensional histograms of each variable using the `marginalhist()`
    recipe from `StatsPlots`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: The result, shown in [Figure 10-22](ch10.xhtml#ch10fig22), is a nice visualization
    of two distributions simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-22: Illustrating the marginal histogram plot recipe*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `StatsPlots` package has another trick up its sleeve. It can combine some
    of the plots we’ve already seen into a composite visualization that makes it easy
    to pick out associations and patterns among a group of variables almost at a glance.
    This is achieved with the `corrplot()` recipe, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: We’ve chosen three variables to look at; it’s possible to look at everything
    at once, or any other subset with more than two categories. The need to include
    the `fillcolor` argument is a bug that may be fixed by the time you are reading
    this, so you may want to try omitting it. It controls the palette used in the
    two-dimensional histograms, and, as you saw earlier, it’s not needed in regular
    `histogram2d` plots to get the default coloring.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 10-23](ch10.xhtml#ch10fig23) shows the result.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch10fig23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 10-23: A correlation plot*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The recipe produces a matrix of plots comparing every possible combination
    of pairs of variables from the vector of arrays provided in the first argument.
    Along the diagonal of this plot matrix (where the two variables are identical)
    we have conventional, one-dimensional histograms; above the diagonal, we see all
    three possible two-dimensional histograms; and below the diagonal, we have all
    the scatterplots, using transparent points. As a bonus, the scatterplots also
    feature regression (best fit) lines drawn through the points, and the marker color
    reflects the type of correlation: positive correlations are blue, lack of correlation
    is indicated by yellow, and negative correlations are red. This is a powerful
    visualization that carries a rich payload of information. A quick look tells us
    that failure to complete secondary school is unrelated to rates of vehicle theft
    or robbery, but those two types of crime are correlated with each other.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Other Packages**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section briefly describes a few more tools that readers interested in statistics
    will want to be aware of. See “Further Reading” on [page 359](ch10.xhtml#fur10)
    for some additional resources you may find useful.
  prefs: []
  type: TYPE_NORMAL
- en: '***JuliaDB for Out of Core Datasets***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Dataframes are powerful data types, but they’re intended for data structures
    that fit in RAM. For data that is too large to fit in memory, a better choice
    is `JuliaDB`, which is designed to work efficiently with such “out of core” datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '***RCall for Interacting with R***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The R programming language is a long-established language and system for statistical
    analysis. Like Julia, R is free software and has a large population of devoted
    users. However, it is not a good general-purpose programming language, and it
    can be quite slow for certain types of calculations. If you are starting a new
    project, and do not happen to have a personal library of R code that you have
    developed over the years, I recommend using Julia for your statistics needs. It
    already has a large and capable ecosystem of statistical packages, and more packages
    are being added every day. Julia won’t let you down if your analysis program turns
    into something that needs to run quickly on big data. Its ability to run on GPUs
    and other multiprocessor hardware, and the efficiency of its compiled code, means
    that you won’t need to rewrite your programs in order for them to scale.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you have already invested time and effort into writing R routines
    that you want to keep using, you need not rewrite them. You can use them from,
    and in combination with, Julia. The `RCall` package has several macros for interoperating
    with R routines and data structures, as well as a special REPL mode for interacting
    directly with R within the Julia session. In fact, as soon as you type `using
    RCall`, an R process starts up in the background. It locates your R installation
    and can even install R for you.
  prefs: []
  type: TYPE_NORMAL
- en: '***P-hacking***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For calculating p-values and performing other analyses to contribute to the
    replication crisis in science, the `HypothesisTests` package at [*https://github.com/JuliaStats/HypothesisTests.jl*](https://github.com/JuliaStats/HypothesisTests.jl)
    is invaluable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Conclusion**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The concepts and techniques of statistics cut across all scientific disciplines.
    Julia, with its statistics packages, puts a lot of exploratory and analytical
    power at our fingertips. Good integration with the `Plots` package makes visualization
    fast and easy as well. While systems such as R, a standard for statistical analysis
    for decades, offer some functions not yet built into Julia’s packages, the latter
    are developing quickly. Julia has some advantages today over the venerable workhorses:
    the ease of developing in the language makes it easier to add missing capabilities,
    and Julia’s efficiency frees you from the need to rewrite your code in a faster
    language when faced with big data or computationally intensive analyses.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll revisit some of the concepts introduced in this chapter in the next chapter,
    with simulated evolution, and in [Chapter 13](ch13.xhtml), where we explore the
    techniques of probabilistic programming to make inferences about models.
  prefs: []
  type: TYPE_NORMAL
- en: '**FURTHER READING**'
  prefs: []
  type: TYPE_NORMAL
- en: For details on the lava lamp entropy project, see [*https://blog.cloudflare.com/randomness-101-lavarand-in-production/*](https://blog.cloudflare.com/randomness-101-lavarand-in-production/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The pandemic simulation in this chapter implements a simplified model along
    the lines of the widely used COVID-19 model developed at [*https://github.com/mrc-ide/covid-sim*](https://github.com/mrc-ide/covid-sim).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The formula for the combination of events used in the pandemic simulation is
    derived in Chapter IV of William Feller’s standard work on probability theory,
    *An Introduction to Probability Theory and Its Applications*, Volume 1 (Wiley
    1968).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An alternative random number generator designed for long-term stability is available
    at [*https://github.com/JuliaRandom/StableRNGs.jl*](https://github.com/JuliaRandom/StableRNGs.jl).
    You may want to use it if you would like your programs to use the same pseudorandom
    sequences across future versions of Julia and its packages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `RCall` package resides at [*https://github.com/JuliaInterop/RCall.jl*](https://github.com/JuliaInterop/RCall.jl).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A frequently updated list of Julia statistics and machine learning packages,
    with brief descriptions, is available at [*https://github.com/JuliaStats*](https://github.com/JuliaStats).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'See this 20-minute tutorial video by Juan Klopper for an introduction to statistics
    in Julia: [*https://www.youtube.com/watch?v=xbsr46Dw8hg*](https://www.youtube.com/watch?v=xbsr46Dw8hg).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A textbook by Yoni Nazarathy and Hayden Klok about doing statistics, data science,
    and machine learning with Julia is available at [*https://statisticswithjulia.org*](https://statisticswithjulia.org).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The headquarters of the `JuliaDB` package is [*https://juliadb.juliadata.org/latest/out_of_core/*](https://juliadb.juliadata.org/latest/out_of_core/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More information on dataframes as collections of rows is available at [*https://bkamins.github.io/julialang/2023/02/24/dfrows.html*](https://bkamins.github.io/julialang/2023/02/24/dfrows.html).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
