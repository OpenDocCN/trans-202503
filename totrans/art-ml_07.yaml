- en: '**5'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**5'
- en: 'A STEP BEYOND K-NN: DECISION TREES**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 超越k-NN：决策树**
- en: '![Image](../images/common.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/common.jpg)'
- en: In k-NN, we looked at the neighborhood of the data point to be predicted. Here
    again we will look at neighborhoods, but in a more sophisticated way. This approach
    will be easy to implement and explain, lends itself to nice pictures, and has
    more available hyperparameters with which to fine-tune it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在k-NN中，我们会观察待预测数据点的邻域。在这里，我们同样会观察邻域，但方式更加复杂。这个方法易于实现和解释，能生成直观的图示，并且拥有更多可调的超参数，以便进行微调。
- en: Here we will introduce *decision trees (DTs)*, one of the mainstays in the ML
    field. Besides being used directly, DTs are also the basis for *random forests*
    and *gradient boosting*, which we will cover in later chapters.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将介绍*决策树（DT）*，它是机器学习领域的主要方法之一。除了直接使用外，决策树还是*随机森林*和*梯度提升*的基础，这些内容将在后续章节中介绍。
- en: 5.1 Basics of Decision Trees
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 决策树基础
- en: Though some ideas had been proposed earlier, the DT approach became widely used
    due to the work of statisticians Leo Breiman, Jerry Friedman, Richard Olshen,
    and Chuck Stone. They called their method *classification and regression trees
    (CART)* and described it in their book *Classification and Regression Trees* (Wadsworth,
    1984).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然早期曾有一些相关思想被提出，但决策树方法由于统计学家Leo Breiman、Jerry Friedman、Richard Olshen和Chuck
    Stone的工作而被广泛应用。他们将他们的方法称为*分类与回归树（CART）*，并在他们的书《分类与回归树》（Wadsworth，1984年）中进行了描述。
- en: A DT method basically sets up the prediction process as a flow chart, hence
    the name *decision tree*. For instance, look at [Figure 5-1](ch05.xhtml#ch05fig01)
    in [Section 5.2.1](ch05.xhtml#ch05lev2sec1). There we are predicting ozone level
    from features such as temperature and wind speed. In predicting a new case, we
    start at the top of the tree and follow some path to the bottom, making decisions
    along the way as to whether to turn left or right. At the bottom of the tree,
    we make our prediction.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树方法基本上将预测过程设定为一个流程图，因此得名*决策树*。例如，参见[图5-1](ch05.xhtml#ch05fig01)在[第5.2.1节](ch05.xhtml#ch05lev2sec1)中。我们根据温度、风速等特征来预测臭氧水平。在预测一个新案例时，我们从树的顶部开始，沿着某条路径向下走，并在此过程中做出是否向左或向右转的决策。在树的底部，我们做出最终预测。
- en: We produce a tree using our training set data. The top of the tree (the *root
    node*) contains all of that data. We then split the data into two parts according
    to whether some feature is smaller or larger than a given value. This creates
    two new nodes, below and to the left or right of the root node. Then we split
    each of *those* parts into two further parts and so on. Thus an alternative name
    for the process is *recursive partitioning*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用训练集数据生成一棵树。树的顶部（*根节点*）包含所有数据。然后，我们根据某个特征是否大于或小于给定的值，将数据分成两部分。这会在根节点下方分别创建两个新节点，位于左右两侧。接着，我们将每个部分再分成两部分，如此继续下去。因此，另一种该过程的名称是*递归划分*。
- en: At each step, we have the option of stopping—that is, making no further splits
    along that particular path or branch within the tree. In that case, the non-split
    node is called a *leaf* or *terminal node* of the tree. Any given branch of the
    tree will end at some leaf node.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步中，我们可以选择停止——即在树的某个路径或分支上不再进行进一步分裂。此时，未分裂的节点称为*叶子节点*或*终端节点*。树的任何分支最终都会结束于某个叶节点。
- en: In the end, to predict a new case, we start at the root of the tree and work
    our way down to a leaf. Our predicted *Y* value then depends on the type of application.
    In numeric- *Y* cases, our predicted *Y* is then the average of all the *Y* values
    in that node. For classification applications, our predicted *Y* value is the
    class that is most numerous in the given leaf node. Or equivalently, express *Y*
    as dummy variables and take the average of each dummy. This gives us the probabilities
    of the various classes, and we set the predicted class to be the one of largest
    probability.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，为了预测一个新案例，我们从树的根节点开始，一直走到叶子节点。我们预测的*Y*值取决于应用类型。在数值型*Y*的情况下，我们预测的*Y*值是该节点内所有*Y*值的平均值。对于分类应用，我们预测的*Y*值是给定叶节点中最为常见的类别。或者等效地，可以将*Y*表示为虚拟变量，并计算每个虚拟变量的平均值。这样，我们就得到了各个类别的概率，并将预测类别设置为概率最大的那个。
- en: It is in this sense that DTs are analogous to k-NN. A leaf node serves as analogous
    to the neighborhood concept of k-NN.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个意义上说，决策树（DT）与k-近邻（k-NN）类似。叶节点类似于k-NN中的邻域概念。
- en: Various schemes have been devised to decide (a) *whether* to split a given node
    in the tree, and (b) if so, *how* to do the split. More on this shortly.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了决定（a）*是否*将树中的某个节点进行分割，以及（b）如果分割，*如何*进行分割，已经设计了各种方案。稍后将详细介绍。
- en: 5.2 The qeDT() Function
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 `qeDT()`函数
- en: R’s CRAN repository has several DT packages, but two I like especially are `partykit`
    and its earlier version, `party`. (These names are a pun on the term *recursive
    partitioning*.) Our `qe*`-series function `qeDT()` wraps `party::ctree()`. To
    illustrate, let’s run an example from the package.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: R的CRAN仓库有几个决策树包，我特别喜欢的是`partykit`及其早期版本`party`。（这些名字是对术语*递归分区*的双关。）我们的`qe*`系列函数`qeDT()`是对`party::ctree()`的包装。为了说明这一点，我们运行一个来自该包的示例。
- en: 'The dataset here, `airquality`, is built into R and looks like this:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的数据集`airquality`是内置在R中的，结构如下所示：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Our goal is to predict ozone level from the other features:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是根据其他特征预测臭氧水平：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Since this is such a small dataset, we decided against having a holdout set.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个非常小的数据集，我们决定不使用保留集。
- en: We predict new data points as usual (after all, the `qe*`-series is supposed
    to give a uniform interface to the various functions they wrap). Say we have a
    new day to predict, with values the same as in `airq[1,]` but with wind at 8.8
    miles per hour. What value would we predict for the ozone level?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们像往常一样预测新的数据点（毕竟，`qe*`系列旨在为它们包装的各种函数提供统一的接口）。假设我们有一天的新数据需要预测，数据与`airq[1,]`相同，但风速为8.8英里每小时。我们应该预测臭氧浓度的什么值？
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We would predict ozone at about 18.5 parts per million.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预测臭氧浓度大约为18.5百万分之一。
- en: 'As you know, `qe*`-series functions are wrappers, and their return objects
    usually include a component containing the return object from the wrapped function.
    This is the case here for `qeDT()`:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，`qe*`系列函数是包装器，它们的返回对象通常包括一个组件，该组件包含被包装函数的返回对象。这在`qeDT()`中也适用：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Here `ctout` is the object returned by `ctree()` when the latter is invoked
    from `qeDT()`. By the way, `ctout` is of class `'party'`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的`ctout`是由`ctree()`返回的对象，当后者从`qeDT()`调用时返回。顺便提一句，`ctout`属于`'party'`类。
- en: We are using default hyperparameters here and might get better predictions with
    a better set of them. More on this in [Section 5.6](ch05.xhtml#ch05lev6), but
    let’s focus now on how the tree process works by plotting the flow chart.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的是默认的超参数，可能通过更好的参数设置获得更好的预测效果。有关更多内容，请参见[第5.6节](ch05.xhtml#ch05lev6)，但现在让我们专注于通过绘制流程图来理解决策树的工作过程。
- en: '***5.2.1 Looking at the Plot***'
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.2.1 查看图形***'
- en: Most DT packages allow you to plot the tree, which sometimes can provide useful
    insights for the analyst. In our setting here, though, we will use the plot to
    gain a better understanding of how the DT process works.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数决策树包允许你绘制树图，这有时可以为分析师提供有价值的见解。不过，在我们的设置中，我们将使用该图来更好地理解决策树的工作原理。
- en: 'The call is simple:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 调用非常简单：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As mentioned before, `plot()` is an R *generic function* (that is, a placeholder).
    The above call is dispatched to `plot.qeDT(dtout)`. And since the latter has been
    written to call `plot()` on the `ctout` component, in the end, that `plot()` call
    above will eventually be dispatched to `plot.party()`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`plot()`是一个R的*通用函数*（即占位符）。上述调用被分派到`plot.qeDT(dtout)`。由于后者已编写为在`ctout`组件上调用`plot()`，因此最终上述的`plot()`调用将最终被分派到`plot.party()`。
- en: '[Figure 5-1](ch05.xhtml#ch05fig01) shows the plot. As we are just getting an
    overview now, don’t try to grasp the entire picture in a single glance.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-1](ch05.xhtml#ch05fig01)展示了图形。由于我们现在只是对整体情况进行概述，所以不要试图一眼看懂全部内容。'
- en: '![Image](../images/ch05fig01.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../images/ch05fig01.jpg)'
- en: '*Figure 5-1: Sample plot from*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5-1：示例图*'
- en: A DT indeed takes the form of a flow chart. For a day with given levels of `Solar.R`,
    `Wind`, and so on, what value should we predict for `Ozone`? The graph shows our
    prediction procedure.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树确实呈现为流程图。对于给定的`Solar.R`、`Wind`等值，我们应该预测臭氧的什么值？图中显示了我们的预测过程。
- en: Now let’s see what happens when we predict a new point, say, `w` from above.
    We start at the root, Node 1, and look at `Temp`. Since the value of the latter
    for `w` is 67, which is smaller than 82 degrees, we go left, to Node 2\. There
    we ask whether `Wind` is less than or equal to 6.9 miles per hour. It’s 8.8, so
    we go right, to Node 4, where we are told to compare `Temp` to 77\. Again, the
    value in `w` is 67, so we go left, to Node 5.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看当我们预测一个新的点，例如上面提到的`w`时会发生什么。我们从根节点开始，节点1，然后查看`Temp`。由于`w`中的温度值为67，低于82度，我们向左走，到节点2。在那里我们询问`Wind`是否小于或等于6.9英里每小时。它的值是8.8，所以我们向右走，到节点4，在那里我们被要求将`Temp`与77进行比较。再次地，`w`中的值是67，所以我们向左走，到节点5。
- en: We saw earlier that our predicted value was 18.47917\. How did the tree produce
    this from Node 5?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前看到的预测值是18.47917。那这个值是如何从节点5得出的呢？
- en: 'Our predicted value will be the mean *Y* value for all training set data points
    in Node 5\. There is information in `dtout` as to which data points are in that
    node. Specifically, the `termNodeMembers` component of `qeDT()` output is an R
    list, with one element for each tree node. To gain an understanding of the workings
    of that function, let’s check Node 5 “by hand”:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的预测值将是节点5中所有训练集数据点的均值*Y*。`dtout`中有关于哪些数据点属于该节点的信息。具体来说，`qeDT()`输出的`termNodeMembers`组件是一个R列表，每个树节点对应一个元素。为了更好地理解该函数的工作原理，让我们“手动”检查一下节点5：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We see that 48 data points of `airq` ended up in Node 5, specifically the points
    `airq[1,]`, `airq[2,]`, and so on. DT then computes the mean *Y* for these points:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到`airq`的48个数据点最终落入了节点5，具体包括`airq[1,]`、`airq[2,]`，依此类推。决策树（DT）随后计算这些点的均值*Y*：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This matches the value we obtained from `predict()`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们通过`predict()`获得的值一致。
- en: '5.3 Example: New York City Taxi Data'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 示例：纽约市出租车数据
- en: Let’s try all this on a larger dataset. Fortunately for us data analysts, the
    New York City Taxi and Limousine Commmission makes available voluminous data on
    taxi trips in the city.^([1](footnote.xhtml#ch5fn1b)) A small portion of that
    data is available as `yell10k` in the `regtools` package.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个更大的数据集上尝试这一切。幸运的是，对于我们这些数据分析师来说，纽约市出租车与豪华轿车委员会提供了大量的出租车行程数据。^([1](footnote.xhtml#ch5fn1b))
    其中一小部分数据作为`yell10k`存在于`regtools`包中。
- en: That dataset consists of 10,000 random records from the January 2019 dataset.
    It retains only 7 of the original 18 features, and some date conversion has been
    done.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集由2019年1月的数据中的10,000个随机记录组成。它仅保留了原始的18个特征中的7个，并进行了部分日期转换。
- en: It would be nice if taxi operators had an app to predict travel time, which
    many passengers may wish to know. This will be our goal here.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出租车运营商有一个应用程序来预测行程时间，那将会很好，因为许多乘客可能希望了解这个信息。这也将是我们在这里的目标。
- en: 'Here’s the data:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here `PU` and `DO` mean “pickup” and “dropoff.” Trip distance is in miles, and
    trip time is in seconds.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`PU`和`DO`分别代表“接客”和“送客”。行程距离以英里为单位，行程时间以秒为单位。
- en: On the other hand, trip distance is not enough; the pickup and dropoff locations
    are important, as some parts of the city may be slower to navigate than others.
    The original data also had time of day, which is important but not used here for
    simplicity.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，单单行程距离不足够；接客和送客的地点也很重要，因为城市的某些区域可能比其他地方更难行驶。原始数据中还包含了时间信息，这在这里虽然没有使用，但实际上是非常重要的。
- en: '***5.3.1 Pitfall: Too Many Combinations of Factor Levels***'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.3.1 陷阱：因子水平组合过多***'
- en: 'Now, note the location IDs:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，注意一下位置ID：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: There are potentially 29,315 pickup and dropoff combinations! Since we have
    only *n* = 10000 data points, we risk serious overfitting problems. And at the
    very least, having so many potential tree nodes will affect run time on the training
    set.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在的接客和送客组合有29,315种！由于我们只有*n* = 10000个数据点，我们面临着严重过拟合的风险。而且，至少有这么多潜在的树节点会影响训练集的运行时间。
- en: 'Furthermore, when I tried this with the `partykit` package rather than `party`,
    I encountered an error message: “Too many levels.” The documentation recommends
    using `party` in such cases, but even then we would likely run into trouble with
    larger datasets of this type.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当我使用`partykit`包而不是`party`包时，我遇到了一个错误信息：“水平过多”。文档建议在这种情况下使用`party`，但即使那样，我们也很可能会遇到大数据集的麻烦。
- en: This suggests possible use of consolidation or embedding (see [Section 4.3.1](ch04.xhtml#ch04lev3sec1)).
    We may, for instance, wish to form groups of contiguous locations. Or we could
    try an embedding—that is, replacing location IDs by latitude and longitude. But
    let’s see what happens without taking such measures.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明可能需要使用合并或嵌入（参见[第4.3.1节](ch04.xhtml#ch04lev3sec1)）。例如，我们可能希望形成连续位置的组，或者我们可以尝试嵌入——即用纬度和经度替代位置ID。但我们先看看不采取这些措施时会发生什么。
- en: '***5.3.2 Tree-Based Analysis***'
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '***5.3.2 基于树的分析***'
- en: 'As noted, this dataset may present challenges, especially regarding possible
    overfitting issues. Let’s give it a try:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这个数据集可能存在一些挑战，特别是在可能出现过拟合问题的情况下。我们试试看：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Not bad; we cut MAPE in half by using the features here. Again, we might do
    considerably better with nondefault hyperparameter combinations, as well as by
    adding some of the features in the original dataset that are not in `yell10k`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 不错；通过使用这里的特征，我们将MAPE减少了一半。同样，通过使用非默认的超参数组合，以及添加原始数据集中`yell10k`中没有的一些特征，我们可能会做得更好。
- en: 'The dataset, even in the scaled-down form we are using here, is far too complex
    for plotting its tree. We can still display it in printed form:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是我们在这里使用的缩小版数据集，其复杂度也远高于绘制其树形图所能承载的水平。我们仍然可以以打印形式显示它：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Though the display is quite complex even in printed form, forcing only a partial
    listing here, and though it contains some quantities we have not yet described,
    one may still glean some interesting information. First we see that there were
    40 terminal nodes, as opposed to 5 in our previous example, reflecting the greater
    complexity of this dataset. (There are 79 nodes in the entire tree, as can be
    seen by typing `dtout$nNodes`.)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管即使是打印形式的显示也相当复杂，这里仅强行列出一部分，且其中包含一些我们尚未描述的数量，但仍然可以获得一些有趣的信息。首先，我们看到共有40个终端节点，而在我们之前的例子中只有5个，这反映了该数据集的复杂性更高。（整个树中有79个节点，输入`dtout$nNodes`可以看到。）
- en: 'Second, we see in part how that reduction was accomplished: DT was able to
    form its own groups of pickup and dropoff locations, such as in Node 9:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们看到部分是如何实现该减少的：决策树能够形成自己的接送位置分组，比如在节点9：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We go left if `DOLocationID` is one of 13, 68, and so on, and otherwise go right.
    This addresses our concerns in [Section 5.3.1](ch05.xhtml#ch05lev3sec1). The DT
    grouped the locations for us! No wonder DTs are so popular!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`DOLocationID`是13、68等之一，我们向左走，否则向右走。这解决了我们在[第5.3.1节](ch05.xhtml#ch05lev3sec1)中的问题。决策树（DT）为我们分组了位置！难怪决策树这么受欢迎！
- en: '**NOTE**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: '*If we type an expression when we are in R interactive mode, R prints that
    expression. Here we typed* dtout*, so it’s equivalent to typing* print(dtout)*.
    But* print() *is yet another R generic function, and we will thus have a similar
    chain of calls as for* plot() *above, ending with* print.party(dtout$ctout)*.*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果我们在R交互模式下输入一个表达式，R会打印出该表达式。这里我们输入了*dtout*，所以它等同于输入*print(dtout)*。但是*print()*是另一个R的通用函数，因此我们将有一个类似于*plot()*上面的调用链，最后调用*print.party(dtout$ctout)*。*'
- en: One thing worth checking in DT analysis is the numbers of data points in the
    various leaf nodes. Say some node has rather few data points. That’s analogous
    to having too few points in a k-NN neighborhood. Just as we can try different
    values of *k* in the latter case, here we may wish to tweak some DT hyperparameters.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在决策树分析中，有一件事值得检查，那就是各个叶子节点中的数据点数量。假设某些节点的数据点很少，这类似于在k-NN邻域中点数过少。就像在后者的情况下我们可以尝试不同的*k*值一样，在这里我们可能需要调整一些决策树超参数。
- en: 'We’ll look at hyperparameters in [Section 5.6](ch05.xhtml#ch05lev6), but for
    now, let’s see how to check for leaf nodes with rather few data points:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第5.6节](ch05.xhtml#ch05lev6)讨论超参数，但现在先来看一下如何检查数据点较少的叶子节点：
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: There are a few small nodes, notably Node 78 with only 10 data points. This
    is a possible reason to tweak the hyperparameters.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些较小的节点，特别是节点78，只有10个数据点。这可能是调整超参数的一个原因。
- en: '5.4 Example: Forest Cover Data'
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 示例：森林覆盖数据
- en: Another UCI dataset, Covertype, aims to “[predict] forest cover type from cartographic
    variables only.”^([2](footnote.xhtml#ch5fn2)) The idea is that one might use remote
    sensing to determine what kinds of grasses there are in difficult-to-access regions.
    There are 581,012 data points, with 54 features, such as elevation, hillside shade
    at noon, and distance to the nearest surface water. There are seven different
    cover types, which are stored in column 55.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个UCI数据集，Covertype，旨在“[预测]森林覆盖类型，仅基于制图变量。”^([2](footnote.xhtml#ch5fn2)) 其目的是通过遥感来确定难以到达的地区存在的草种类。数据集中有581,012个数据点，包含54个特征，例如海拔、午间山坡阴影和到最近地表水的距离。共有七种不同的覆盖类型，存储在第55列。
- en: This example is useful for a number of reasons. Here we’ll see DT in action
    in a classification problem, with multiple classes, and of a size larger than
    what we’ve seen so far. And besides, what could be better in a chapter on trees
    than data on forests!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例有很多值得注意的地方。在这里，我们将看到决策树在多类分类问题中的应用，且其规模大于我们迄今为止所见。而且，章节讲解树结构时，数据来自森林难道不更好？
- en: 'Input the data, say, with `data.table::fread()` for speed:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据，例如，使用`data.table::fread()`来提高速度：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The class, in column `V55`, was read in as an integer, whereas `qe*`-series
    functions need *Y* to be R factors in classification problems. We could have used
    `fread()`’s `colClasses` argument, but let’s just fix it directly:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 类别（位于`V55`列）作为整数读取，而`qe*`系列函数需要在分类问题中将*Y*转换为R的因子。我们本可以使用`fread()`的`colClasses`参数，但直接修正它会更方便：
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'There are seven classes, but some are much more common than others:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 有七个类别，但有些类别比其他类别要常见得多：
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Cover types 1 and 2 are the most numerous.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖类型1和2是最常见的。
- en: 'Since both *n* and *p* are large, let’s run on a random subset of 50,000 records
    to more conveniently illustrate the ideas. This approach is also common in data
    analysis: do a preliminary analysis on a subset of the data, again for convenience,
    but then do a more thorough analysis on the full data.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于*n*和*p*都很大，我们可以选择运行一个50,000条记录的随机子集，便于更好地说明这些概念。这样的做法在数据分析中也很常见：先在数据子集上进行初步分析，便于操作，然后再对完整数据进行更为深入的分析。
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Again, we are doing much better with the features (25 percent error rate) than
    without them (51 percent).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，使用特征（25%的错误率）比不使用特征（51%的错误率）要好得多。
- en: 'We might also look at the confusion matrix:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以查看混淆矩阵：
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Class 1 is often mispredicted as Class 2, and vice versa.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 类别1经常被误预测为类别2，反之亦然。
- en: 'With the larger sample size *n* and number of features *p* here, a really large
    tree might be generated. In fact, it is much larger than in our previous examples:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，随着样本量*n*和特征数量*p*的增大，可能会生成一个非常大的树。实际上，它比我们之前的示例要大得多：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The tree has 1,000 nodes, and about half of those are terminal nodes!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这棵树有1,000个节点，其中大约一半是终端节点！
- en: '5.5 Decision Tree Hyperparameters: How to Split?'
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 决策树超参数：如何进行分裂？
- en: DT packages differ from one another in terms of the details of their node-splitting
    actions. In most cases, the process is quite complex and thus beyond the scope
    of this book. The splitting process in `party` is no exception, but we need to
    have at least a rough overview of the process. We will focus on a major splitting
    criterion in `party` known as the *p-value*.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的决策树包在节点分裂的细节上有所不同。在大多数情况下，这个过程相当复杂，因此超出了本书的讨论范围。`party`包中的分裂过程也不例外，但我们至少需要对这个过程有一个大致的了解。我们将重点介绍`party`包中一个主要的分裂标准，即*p值*。
- en: Look again at [Figure 5-1](ch05.xhtml#ch05fig01). The oval contents show that
    the feature used to split is `Wind`, with a p-value of 0.002 and with a split
    point of 6.9\. But originally, as the tree was being built, that oval was empty,
    with no lines emanating out of the bottom. How, then, was this node built to what
    we see in the figure?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 再次查看[图5-1](ch05.xhtml#ch05fig01)。椭圆形区域显示用于分裂的特征是`Wind`，p值为0.002，分裂点为6.9。但最初，当树结构建立时，该椭圆区域是空的，底部没有任何线条延伸。那么，这个节点是如何从图中看到的状态构建出来的呢？
- en: 'Node 2 inherited data points from the left branch out of Node 1\. Then the
    following algorithm was run:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 节点2从节点1的左分支继承了数据点。然后执行了以下算法：
- en: '[PRE19]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We do the following on the output of the above pseudocode:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上述伪代码的输出上做以下操作：
- en: If the smallest p-value is below a user-specified criterion, split the node
    using whichever feature and split point yielded the smallest p-value (in this
    case, `Wind` and 6.9).
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果最小的p值低于用户指定的标准，则使用产生最小p值的特征和分裂点来分裂节点（在本例中是`Wind`和6.9）。
- en: If, on the other hand, the smallest p-value was not smaller than the user-specified
    criterion, do not split the node.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，如果最小的p值没有小于用户指定的标准，就不要拆分节点。
- en: 'We see, for instance, that for Node 2 and the potential (and later, actual)
    splitting feature `Wind`, there are many candidates for a potential split point:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们看到，对于节点2及潜在的（后来实际的）拆分特征`Wind`，有很多候选的潜在拆分点：
- en: '[PRE20]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Any of the values 2.8, 3.4, . . . , 20.1 could be used. The algorithm takes
    each one into consideration.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 值2.8、3.4、...、20.1中的任何一个都可以使用。算法会考虑每一个。
- en: Intuitively, we would like the split to produce two approximately balanced subsets,
    say, with a split at 9.7\. But a more urgent requirement is that the two subsets
    differ a lot in their mean values of *Y*. If mean *Y* is fairly similar in the
    two candidate subsets, the node is deemed homogeneous and not split—at least for
    that feature.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，我们希望拆分能产生两个大致平衡的子集，比如在9.7处分裂。但更紧迫的要求是，两个子集在*Y*的均值上有很大的差异。如果两个候选子集的*Y*均值相差不大，则认为该节点是同质的，不会拆分——至少对于该特征而言。
- en: Well, then, what constitutes differing by “a lot”? This is decided by a formal
    statistical significance test. This book does not assume a background in statistics,
    and, for our purposes here, we just state that a test is summarized by a number
    known as a p-value.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么才算“相差很多”呢？这是由一个正式的统计显著性测试来决定的。本书不假设读者有统计学背景，对于我们的目的，我们只说明一个测试的结果是通过一个叫做p值的数字来总结的。
- en: Testing has come under much criticism in recent years, and for good reason,
    in my opinion (see the file *NoPVals.md* in `regtools`). However, for the node-splitting
    purpose here, the p-value threshold is just another hyperparameter, named `alpha`
    in `qeDT()`. This default value is 0.05.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，测试方法受到许多批评，我认为这有其合理之处（请参见文件*NoPVals.md*，位于`regtools`中）。然而，在这里进行节点拆分时，p值阈值只是另一个超参数，称为`alpha`，在`qeDT()`中默认值为0.05。
- en: If the p-value is less than `alpha` for some candidate feature and candidate
    split point pair, then the node is deemed worth splitting. The feature and split
    point chosen are the pair with the smallest p-value. We see in [Figure 5-1](ch05.xhtml#ch05fig01)
    that the minimum p-value happened to be 0.002, which was associated with the `Wind`
    feature and a split point of 6.9\. Since 0.002 < 0.05, the node was split accordingly.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果某个候选特征和候选拆分点的p值小于`alpha`，则认为该节点值得拆分。所选择的特征和拆分点是具有最小p值的一对。我们在[图5-1](ch05.xhtml#ch05fig01)中看到，最小的p值恰好是0.002，它与`Wind`特征和拆分点6.9相关联。由于0.002
    < 0.05，该节点相应地被拆分了。
- en: If no split point meets the above criterion, the node is not split. That happened
    in Node 3, so it became a terminal node.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有任何分裂点满足上述标准，则该节点不进行拆分。在节点3中发生了这种情况，因此它成为了终端节点。
- en: 5.6 Hyperparameters in the qeDT() Function
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6 `qeDT()`函数中的超参数
- en: As noted, DTs may be viewed as an extension of the k-NN idea. Each leaf node
    forms a kind of neighborhood whose data points have similar values of certain
    features. Recall from [Chapter 3](ch03.xhtml) that small neighborhoods lead to
    larger variance in a predicted *Y* value—just too small a sample to work from—
    while large neighborhoods may have bias problems (that is, points in the same
    neighborhood may be quite different from each other and thus not representative).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，决策树（DT）可以被看作是k-NN思想的延伸。每个叶节点形成一种邻域，其中的数据点在某些特征上具有相似的值。回想一下[第3章](ch03.xhtml)，较小的邻域会导致预测的*Y*值具有更大的方差——因为样本太小，无法有效工作——而较大的邻域则可能存在偏差问题（即，同一邻域中的点可能彼此差异较大，从而不能代表整体）。
- en: In a DT context, then, we should look at the leaf nodes to consider the Bias-Variance
    Trade-off. If there are too many small terminal nodes, we risk a variance problem,
    while too many large terminal nodes may mean a bias issue.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在决策树的背景下，我们应该查看叶节点，考虑偏差-方差权衡。如果有太多小的终端节点，我们就会面临方差问题，而过多大的终端节点则可能意味着偏差问题。
- en: Here is where hyperparameters come into play. They control the tree configuration
    in various ways, and we can use cross-validation to choose the tree configuration
    with the best predictive ability.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是超参数发挥作用的地方。它们以各种方式控制树的配置，我们可以使用交叉验证来选择具有最佳预测能力的树配置。
- en: 'The general call form is:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一般的调用形式是：
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The `data`, `yName`, and `holdout` arguments are common to all the `qe*`-series
    functions. The remainder, `alpha`, `minsplit`, `minbucket`, `maxdepth`, and `mtry`,
    all deal with splitting criteria. Here are their roles:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`data`、`yName`和`holdout`参数在所有`qe*`系列函数中都是通用的。其余的`alpha`、`minsplit`、`minbucket`、`maxdepth`和`mtry`都涉及分裂标准。以下是它们的作用：'
- en: alpha   As explained above.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: alpha   如上所述。
- en: minsplit   Here we can specify the minimum size for any node. The default of
    20 means that we will not allow any node splitting to result in a node with fewer
    than 20 data points.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: minsplit   在这里我们可以指定任何节点的最小大小。默认值为20，意味着我们不会允许任何节点分裂后小于20个数据点。
- en: minbucket   Like `minsplit`, but specifically for terminal nodes.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: minbucket   类似于`minsplit`，但专门针对终端节点。
- en: maxdepth   Maximum number of levels or rows of the tree. In [Figure 5-1](ch05.xhtml#ch05fig01),
    we have 4 levels, with the root in Level 1 and the leaf nodes in Level 4.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: maxdepth   树的最大层数或行数。在[图 5-1](ch05.xhtml#ch05fig01)中，我们有4个层次，根节点在第1层，叶节点在第4层。
- en: mtry   If this is nonzero, it is the number of features to try at each node;
    see below.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: mtry   如果这个值非零，它表示每个节点尝试的特征数量；见下文。
- en: 'If `mtry` is nonzero, our splitting algorithm changes a bit:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`mtry`非零，我们的分裂算法会稍作调整：
- en: '[PRE22]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This adds some randomness to the tree construction process, a step toward the
    ML method of *random forests*. We will see in the next chapter why this may be
    useful, but for the strict DT method, it is usually not used.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这为树的构建过程增加了一些随机性，是朝着机器学习方法*随机森林*的一步。我们将在下一章看到这为什么可能有用，但对于严格的决策树方法，通常不使用它。
- en: Consider each of the above hyperparameters in terms of the Bias-Variance Trade-off.
    Say we wish to make the leaf nodes smaller. All else being equal, we could accomplish
    this by making `alpha` larger, `minsplit` smaller, `minbucket` smaller, `maxdepth`
    larger, and `mtry` larger (or 0).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 从偏差-方差权衡的角度考虑上述每个超参数。假设我们希望使叶节点更小。其他条件相同的情况下，我们可以通过增大`alpha`、减小`minsplit`、减小`minbucket`、增大`maxdepth`和增大`mtry`（或设为0）来实现这一目标。
- en: For instance, with a larger `alpha`, more p-values will be below this high threshold,
    so it is more likely that a node will split. As we go further down a tree, fewer
    data points remain, so if we encourage splits, when we reach a node that can’t
    be split, it won’t have many points left in it.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，增大`alpha`时，更多的p值会低于这个高阈值，因此节点更有可能分裂。随着树的深入，剩余的数据点会减少，因此如果我们鼓励分裂，到了一个无法再分裂的节点时，它将不会有很多剩余的数据点。
- en: These hyperparameters don’t work independently of each other, so setting too
    many of them probably becomes redundant.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这些超参数并非独立工作，因此设置过多的超参数可能会变得冗余。
- en: 5.7 Conclusions
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7 结论
- en: Decision trees play a fundamental role in ML, and we will see them again in
    our material on bagging and boosting. As with any ML algorithm, we must deal with
    various hyperparameters, another topic to be viewed in depth later in the book.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树在机器学习中起着基础性作用，我们将在后续的袋装法和提升法材料中再次遇到它们。与任何机器学习算法一样，我们必须处理各种超参数，这是本书稍后将深入讨论的另一个主题。
