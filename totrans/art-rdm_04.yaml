- en: '**4'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OPTIMIZE THE WORLD**
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Optimization* is the process of finding the best set of something, usually
    of parameters defining a function or an algorithm. In mathematics, optimization
    typically involves functions and uses their derivatives to locate minima or maxima.
    In this chapter, we’ll take a different approach that involves randomness. The
    algorithms we’ll use fall into two broad categories: swarm intelligence and evolutionary
    algorithms. Collectively, these are known as *metaheuristics*.'
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing with metaheuristics is more flexible than calculus-based optimization.
    What we’re optimizing doesn’t need to be a mathematical function; it could be
    an algorithm or another process. In fact, any problem that can be cast as locating
    the best position in a space, where the space represents the problem in some form,
    is amenable to swarm intelligence and evolutionary algorithms. I use both kinds
    of algorithms frequently for everything from curve fitting to evolving neural
    network architectures. Once you understand the process of formulating tasks as
    generic optimization problems, you’ll begin to see them everywhere.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll use swarm intelligence and evolutionary algorithms to
    fit data to a known function. Then, we’ll evolve the best fit function from scratch.
    We’ll begin, however, with a (very) short primer on swarm intelligence and evolutionary
    algorithms. We’ve already used an evolutionary algorithm, though it wasn’t named
    so at the time. The algorithm implemented in [Chapter 3](ch03.xhtml) to explore
    natural selection and genetic drift is a genetic algorithm, one of the two kinds
    of evolutionary algorithms we’ll encounter in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '**Optimization with Randomness**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Imagine a large haystack where each position within the haystack corresponds
    to a possible solution to the problem. We wish to locate the part of the haystack
    that offers the best solution—that is, we want to find a needle. The question
    is: How do we go about finding it?'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use the following generic algorithm to search the haystack:'
  prefs: []
  type: TYPE_NORMAL
- en: A swarm (population) of “agents” are randomly scattered throughout the haystack.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each agent investigates its immediate location and assigns a number to how well
    that location solves the problem.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The agents report their numbers to headquarters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After each agent has reported in, headquarters evaluates all the numbers and
    stores the best position currently known, updating it if, on this iteration, any
    agent finds a better position.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Headquarters then orders each agent to a new position in the haystack based
    on the information received.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The process repeats from step 2 until a best position has been found or we’ve
    run out of time (iterations).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We have a lot of flexibility when it comes to possible implementations. Indeed,
    there are literally hundreds of published algorithms based on this approach. Many
    claim inspiration from nature, but such claims are often quite dubious and generally
    unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Is this an example of a swarm intelligence algorithm or an evolutionary algorithm?
    It’s both. The difference between the two depends on what happens in step 4: the
    process headquarters uses to decide where the agents should go next. The distinction
    is vital for researchers but less so for us.'
  prefs: []
  type: TYPE_NORMAL
- en: In a swarm intelligence algorithm, the agents, called *particles*, work collectively
    to locate new positions in the space to explore. They are actively aware of each
    other and “learn” from each particle’s experiences to move the swarm, as a whole,
    to ever better places in the space, thereby locating increasingly better solutions
    to the problem.
  prefs: []
  type: TYPE_NORMAL
- en: An evolutionary algorithm, on the other hand, applies techniques like crossover
    and mutation to breed new agents (organisms). In [Chapter 3](ch03.xhtml), we defined
    an organism’s fitness as the distance between its genome and the genome of an
    ideal organism for the current environment. Here, fitness is a measure of how
    well the solution represented by the organism’s genome (position in the haystack)
    solves the problem. Generations of breeding fitter solutions, with a dash of random
    mutation, should move the population closer to the best solution to the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In practical terms, all we need to know is that the two kinds of algorithms
    search a space to find the best position in it. We’ll configure our problems such
    that the best position is translatable into a best solution.
  prefs: []
  type: TYPE_NORMAL
- en: With the hundreds of swarm and evolutionary algorithms out there, which ones
    should we use? Each algorithm has strengths and weaknesses, and might work best
    for certain kinds of problems. You need to try several.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this chapter, we’ll use five algorithms: two swarm intelligence, two evolutionary,
    and one that is so obvious many don’t consider it a swarm algorithm at all. We
    don’t have space to walk through each to understand the code; I’ll leave that
    as an exercise (as always, please contact me with questions). We’ll learn about
    the algorithms and the framework using them as we go.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The two swarm intelligence algorithms are *particle swarm optimization (PSO)*
    and *Jaya*. PSO is the grandfather of swarm intelligence algorithms, and many
    nature-inspired algorithms are PSO in disguise. Jaya is a newer algorithm that
    has no parameters to adjust—either it works well or it doesn’t. Although there
    are many flavors of PSO, we’ll use two here: canonical and bare-bones.'
  prefs: []
  type: TYPE_NORMAL
- en: The two evolutionary algorithms are the *genetic algorithm (GA)*, a variation
    on what we used in [Chapter 3](ch03.xhtml), and *differential evolution (DE)*,
    another old-school and widely used technique. DE is one of my go-to algorithms,
    but it has the sometimes annoying habit of converging too quickly to local minima.
  prefs: []
  type: TYPE_NORMAL
- en: The last algorithm is *random optimization (RO)*. In RO, the particles don’t
    communicate; they conduct a local search and move to a new position whenever they
    find one, but are completely unaware of what other particles have discovered.
    Headquarters monitors each particle to track the best position found overall,
    but never issues orders based on that knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: We learn best by doing, so let’s begin fitting a function to data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fitting with Swarms**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A common task in science and engineering is to fit a function to a set of measurements,
    where *fit* means finding the best set of parameters for a known type of function—the
    set that makes the function approximate the data as well as possible. For this
    task, we know the functional form; we need only to learn the parameter values
    to tailor the function to the data. In the next section, we’ll start with the
    data and let the swarms tell us what the best-fit function and parameters are
    (hopefully!). I’m using the word *swarms* in a general sense to mean both the
    swarm of particles manipulated by a swarm intelligence algorithm and the population
    bred and evolved by an evolutionary algorithm. Again, the distinction is minor
    for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with a simple example: some data, a function, and the parameters
    that best fit the function to the data. The code for the example is in *curfit_example.py*.
    It generates a set of points from a quadratic function, with random noise added.
    Then, it uses NumPy’s `polyfit` routine to fit a quadratic: *ax*² + *bx* + *c*.
    [Figure 4-1](ch04.xhtml#ch04fig01) shows the plot and fit function.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-1: Fitting a polynomial to some data*'
  prefs: []
  type: TYPE_NORMAL
- en: With the fit function, we can approximate *y* for any *x*, which is typically
    why we fit the data in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering why we’d bother with swarms if `polyfit` can fit the data.
    Unfortunately, `polyfit` fits only polynomials, or functions that are sums of
    powers of *x*. If your function isn’t a polynomial, there are other functions
    you could use, like SciPy’s `curve_fit`. However, we’re not solely interested
    in curve fitting; we’re using it as a warm-up exercise. SciPy won’t be of much
    use for the other optimization problems we’ll explore later in this chapter and
    in the next.
  prefs: []
  type: TYPE_NORMAL
- en: '***Curves***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Now that we have an idea of what curve fitting entails, let’s try it using a
    swarm. The code we want is in *curves.py*. We’ll use it first, then look at parts
    of it. I strongly recommend you read through the code to get a feel for things.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code expects a datafile that contains the measured points along with the
    function to fit. We’ll use *curves.py* to fit the previous example. The input
    file we need is *curfit_example.txt*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first line is the number of parameters followed by the function to fit.
    The function is given as Python code where the fit parameters are elements of
    a vector, `p`, and the data points are represented by `x`.
  prefs: []
  type: TYPE_NORMAL
- en: We want to fit a function like *ax*² + *bx* + *c*, a three-parameter function,
    so we use `p[0]*x**2+p[1]*x+p[2]`. If you want something like sin *x*, use `np.sin(x)`
    (use NumPy). Note that the data points are listed as *y* then *x*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use *curves.py* and this file to fit the data using differential evolution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The output tells us several things, but look first at the parameters. These
    are the elements of `p`, the best set of parameters found. Compare them with [Figure
    4-1](ch04.xhtml#ch04fig01). The fit is quite good.
  prefs: []
  type: TYPE_NORMAL
- en: The generic algorithm says that particles need to evaluate where they are in
    the haystack to determine how good a solution their current position represents.
    There are three parameters in the fit function; therefore, our haystack is a three-dimensional
    space, and the particles are initially scattered randomly throughout this space.
    Each point in the three-dimensional space corresponds to a `p` vector, a set of
    three parameters. The best position found during the search is reported by *curves.py*.
  prefs: []
  type: TYPE_NORMAL
- en: 'For every particle, at every position in the haystack, we calculate the value
    of the *objective function*, the fitness function that tells us about the quality
    of the solution at that position. For curve fitting, our objective function measures
    the mean squared error between the measured points, (*x*, *y*), and the *y* values
    the function returns for the same *x* positions. If *ŷ* = *f*(*x*, ***p***) is
    the output of the function at *x* for some particle position, ***p***, then the
    *mean squared error (MSE)* is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0107-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The sum is over all the measured points, (*x[i]*, *y[i]*).
  prefs: []
  type: TYPE_NORMAL
- en: The closer the MSE is to zero, the better the function is at fitting the measured
    data, meaning the particle position giving us the smallest MSE is the best fit
    found. The swarm algorithm keeps adjusting particle positions until it finds the
    minimum or we run out of iterations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *curves.py* file accepts many command line parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: curfit_example.txt   Datafile
  prefs: []
  type: TYPE_NORMAL
- en: -10   Lower bound
  prefs: []
  type: TYPE_NORMAL
- en: 20   Upper bound
  prefs: []
  type: TYPE_NORMAL
- en: 20   Number of particles
  prefs: []
  type: TYPE_NORMAL
- en: 1000   Number of iterations
  prefs: []
  type: TYPE_NORMAL
- en: 0   Tolerance
  prefs: []
  type: TYPE_NORMAL
- en: DE   Algorithm (DE, Jaya, PSO, GA, RO)
  prefs: []
  type: TYPE_NORMAL
- en: pcg64   Randomness source
  prefs: []
  type: TYPE_NORMAL
- en: The first argument is the name of the file that has the measured data points.
    Again, the first line is the number of parameters in the fit, followed by the
    code to implement the fit function. The remainder of the file are the actual data
    points, *y* then *x*, one pair per line.
  prefs: []
  type: TYPE_NORMAL
- en: The next two arguments specify the bounds of the search. These limit the size
    of the space the swarm can move through. Specifying a scalar applies that value
    to all dimensions; otherwise, specify each dimension separated by `x`. In this
    case, we tell *curves.py* to limit its search space to the cube from (–10, –10,
    –10) to (20, 20, 20). The bounds are often helpful, but must enclose the actual
    best values; otherwise, the search will return only the best position within the
    given bounds.
  prefs: []
  type: TYPE_NORMAL
- en: The following argument, also `20`, specifies the size of the swarm, or the number
    of particles to scatter throughout the haystack. It’s generally better to have
    a smaller swarm and more iterations—the next parameter, here 1,000—but that’s
    only a rule of thumb; exceptions abound.
  prefs: []
  type: TYPE_NORMAL
- en: We are minimizing the MSE. The search stops early if the MSE is less than the
    given tolerance. By setting the tolerance to 0, we’re telling *curves.py* to search
    for 1,000 iterations of the swarm positions or to stop early if we find a position
    with no error. The last parameter is the randomness source for `RE`. A final parameter,
    the name of an output image file showing the data points and the fit, is also
    allowed.
  prefs: []
  type: TYPE_NORMAL
- en: Swarm algorithms are stochastic, meaning they change their output from run to
    run because they randomly assign initial particle positions and use random values
    during the search. For many problems, the changes are subtle and inconsequential,
    but sometimes the swarm simply gets lost. Therefore, it’s best to repeat searches
    several times, if possible, to be sure the results are meaningful.
  prefs: []
  type: TYPE_NORMAL
- en: To try the other swarm algorithms—PSO, Jaya, GA, and RO—specify them by name.
    I suspect you will find that PSO, Jaya, and even RO give results as good as DE.
    GA, however, is another story. The output, numerically, is poor, though if you
    plot the result, it often looks at least somewhat reasonable. Does this mean GA
    is a flawed algorithm? No, it’s simply not well suited to this task. In general,
    GA is best for non-numerical optimization problems and problems with a higher
    number of dimensions (parameters). In this example, using GA means asking it to
    evolve a population of organisms with three genes each. That doesn’t leave much
    for evolution to work with.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at one more curve fitting example. The function to fit is in *sinexp.txt*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0109-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This function is the sum of a sine and a normal curve and has five parameters:
    we’re in a five-dimensional search space and each particle is a point in this
    space. I can’t picture a five-dimensional haystack, but we’re looking for a needle
    in one regardless.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try *curves.py* using Jaya:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The first time I tried the code, the fit failed and returned a minimum MSE of
    0.1656, which is orders of magnitude larger than the previous fit. A plot of the
    good result is in [Figure 4-2](ch04.xhtml#ch04fig02).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-2: A fit to [Equation 4.2](ch04.xhtml#ch04equ2) using Jaya*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The search used 20 particles and 1,000 iterations as before. I limited the
    search space to the range –3 to 20 in all five dimensions. In this case, the dataset
    was generated directly from the function with parameter values of 2, 3, 20, 8,
    and 0.6, respectively. This explains the extremely low MSE: there is no noise
    in the measurements.'
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*You may encounter runtime warnings when using the code. These are the result
    of the swarm algorithm using parameter values that are too large for the exponential.
    Adding* -W ignore *to the command line after* python3 *will suppress the warnings.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***The curves.py Code***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s look at some code to get a feel for what the swarm algorithms are doing;
    it will also help you see how to put the pieces together. Start at the bottom
    of *curves.py*. The essence of the code, as you’ll see when you read through it,
    is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The first line configures an instance of `RE` using the source given on the
    command line (`kind`). The next four lines set up the search for differential
    evolution. The code is the same for Jaya, PSO, RO, and GA, with the addition of
    one more argument to the constructor in the case of PSO. Let’s go line by line;
    these are the steps to configure any swarm search using the framework, so we’ll
    see them again as we proceed.
  prefs: []
  type: TYPE_NORMAL
- en: First, swarm searches are bounded, so we need an instance of the `Bounds` class,
    or a subclass if we need to override one of its methods, typically `Validate`.
    The arguments are the lower and upper limits, the randomness source, and a parameter
    called `enforce` that’s set to `resample`. Referring back to the generic search
    algorithm, step 5 states that headquarters orders the agents to move to new positions
    based on the objective function values for their current positions. At times,
    these new positions might be outside the specified boundaries. The `enforce` parameter
    decides what to do in these cases. By setting it to `resample`, any particle dimension
    that is out of bounds is replaced by a randomly selected value along that dimension.
    The other option is `clip`, which clips the offending dimension to the minimum
    or maximum allowed. Most of the time, this isn’t what we want.
  prefs: []
  type: TYPE_NORMAL
- en: The `RandomInitializer` parameter provides an initializer to configure the swarm.
    It’s given the number of particles in the swarm (`npart`), the dimensionality
    of the search space (`ndim`), and the bounds configured in the previous line (`b`).
  prefs: []
  type: TYPE_NORMAL
- en: The search also needs to know how to evaluate the objective function, an instance
    of `Objective`. For the curve fit example, `X` and `Y` are the measured points
    and `func` is the function to fit, all read from the datafile given on the command
    line. I’ll show you the objective function in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: We’re now ready to create the swarm algorithm object (`swarm`), here an instance
    of `DE`. We give the objective function, number of particles, dimensions, initializer,
    and bounds, along with the randomness source. We also specify the tolerance (`tol`)
    and the number of iterations (`max_iter`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Given all the configuration, using the swarm object is straightforward: call
    the `Optimize` method. When the call returns, the search is over. Call `Results`
    to return a dictionary with information about the search.'
  prefs: []
  type: TYPE_NORMAL
- en: The most important elements of `res` are `gpos` and `gbest`. Both return lists
    tracing the collection of best positions the swarm found during its search. Therefore,
    the final element of these lists returns the best position (`gpos`) and the corresponding
    objective function value (`gbest`). The position is a vector with one value for
    each dimension of the search space; here each dimension is a parameter value for
    the function we’re fitting to the data. The `gbest` value is a scalar, the MSE
    for this set of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the `Objective` class. The object passed as the objective function
    must have, at a minimum, a method called `Evaluate`. The details aren’t very important,
    but because Python uses duck typing, any object with an `Evaluate` method that
    accepts a single argument is permitted. Here’s the code *curves.py* uses:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The constructor keeps references to the measured points, `x` and `y`, along
    with the string representing the function to fit (`func`). Many applications do
    not have ancillary information, in which case the constructor does nothing and
    need not be specified. Also, notice that `Objective` does not inherit from any
    other class, it needs only to implement `Evaluate` to be acceptable to the optimization
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: The `Evaluate` method is called by the swarm algorithms. The argument, `p`,
    is the current position of a particle in the swarm, that is, a vector of possible
    parameter values. The first line increments `fcount`, an internal counter of the
    number of times `Evaluate` was called. The final value of `fcount` is displayed
    when *curves.py* exits.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next line looks a little strange: it assigns the reference to the *x* data,
    `self.x`, to the local variable `x`. The following line uses Python’s `eval` function
    to evaluate the function value; because `eval` uses both `x` and `p` as variable
    names, we need those names to exist in `Evaluate`—hence the `x = self.x`. The
    calculated function values are in `y`. These are the *ŷ* values in [Equation 4.1](ch04.xhtml#ch04equ1).'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we calculate the MSE and return it to give the objective function value
    (or fitness value) for the supplied particle position in `p`. Notice there is
    no square root. I left it out to save a tiny bit of time. The smallest MSE is
    still the smallest even if the final square root is not applied.
  prefs: []
  type: TYPE_NORMAL
- en: When the swarm algorithm runs, it calls `Evaluate` thousands of times to map
    particle positions to MSE values. The swarm algorithms are utterly ignorant of
    *what* the objective function is measuring; all they know is that they pass a
    vector representing a particle position in a multidimensional space to the objective
    function, and it returns a scalar value where lower values are better than higher
    values. This makes the framework generic and applicable to a wide range of problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'To recap, using the framework involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Determine how to map potential solutions to the problem to a position in a multidimensional
    space for the swarms to search.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use that mapping to create an objective function class supporting at least an
    `Evaluate` method to accept a candidate position vector and return a scalar representing
    the quality of the solution it represents. The framework always minimizes, so
    the smaller the return value, the better the solution. To maximize, return the
    negative of the fitness.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `Bounds` object to set the limits of the search space and what to do
    if those limits are exceeded.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an initializer (`RandomInitializer`) to supply the initial positions
    of the swarm particles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an instance of the swarm class, `DE`, `PSO`, `Jaya`, `RO`, or `GA`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform the search by calling `Optimize`, and use `Results` to return the outcome.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our familiarity with the framework will grow with practice. For now, let’s review
    the swarm intelligence and evolutionary algorithms to understand how they differ
    from each other and where the randomness is. Randomness goes deeper than the initial
    configuration of the swarm particles in the search space; each algorithm depends
    critically on randomness for its operation.
  prefs: []
  type: TYPE_NORMAL
- en: '***The Optimization Algorithms***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are hundreds of swarm optimization algorithms out there, but what distinguishes
    one from another? The short answer is the method used for searching, or how headquarters
    orders the agents to new locations on each iteration.
  prefs: []
  type: TYPE_NORMAL
- en: The various algorithm approaches range from the most straightforward—RO, where
    the agents don’t communicate but wander from better position to better position
    independently—to sophisticated algorithms incorporating information about agents’
    current positions, histories, and associations into groups and neighborhoods.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, I’ll summarize the essential operation of the five algorithms
    selected for the framework. In all cases, the essential operation is the same:
    scatter particles throughout the search space, evaluate the quality of each particle,
    decide where they go next, and repeat until a best position is found or time runs
    out. It’s the “decide where they go next” part that differentiates algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Random Optimization (RO)**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Swarm particles are represented by a vector of floating-point numbers, ***x**[i]*,
    each component of which maps to a dimension of the search space. In other words,
    particles are points in the search space. On each iteration, particles construct
    a new position some distance from their current one and ask if the new position
    has a better fitness value, that is, if the objective function value is lower
    at the new position. If so, the particle moves to the new position; otherwise,
    it stays put. The new candidate position is
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0113-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *η* (eta) is a scale parameter (*η* = 0.1) and ***N***(0, 1) is a vector
    of samples from a normal distribution with mean 0 and standard deviation 1\. If
    ![Image](../images/pg113-01.jpg) has a lower objective function value, then ![Image](../images/pg113-02.jpg);
    otherwise, the particle stays where it is for the next iteration. The particles
    make no use of what other particles have learned about the search space.
  prefs: []
  type: TYPE_NORMAL
- en: '**Jaya**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Jaya, Sanskrit for “victory,” is a swarm intelligence algorithm that has no
    adjustable parameters. Swarm algorithms depend on heuristics, so they often have
    adjustable parameters to improve their performance in different situations. Jaya
    does not. It works or it doesn’t.
  prefs: []
  type: TYPE_NORMAL
- en: On each iteration, the *i*th particle is updated via
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0113-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where ***x***[best] and ***x***[worst] are the current best and worst positions
    of any particle in the swarm, and ***r***[1] and ***r***[2] are random vectors
    in [0, 1) per component. The vertical bars apply the absolute value to each component
    of the vector. In other words, Jaya moves particles toward the swarm’s best position
    and away from the swarm’s worst.
  prefs: []
  type: TYPE_NORMAL
- en: '**Particle Swarm Optimization (PSO)**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The update equations for PSO depend on the flavor. Our framework offers two:
    canonical and bare-bones. The *curves.py* file uses bare-bones, hence `bare=True`
    in the `PSO` constructor. However, it’s easier to begin with canonical PSO.'
  prefs: []
  type: TYPE_NORMAL
- en: In canonical PSO, each particle (***x**[i]*) is associated with two other vectors.
    The first, ![Image](../images/xcap.jpg), is the best position in the search space
    that *that* particle has found, and the second, ***υ**[i]*, is the particle’s
    velocity, which controls how quickly and in which direction the particle moves
    through the search space.
  prefs: []
  type: TYPE_NORMAL
- en: 'The canonical PSO update rule is accomplished in two steps. First, the velocity
    is updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0114-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *ω* is the inertia factor multiplying the current velocity. It’s a scalar,
    usually in [0.5, 1), with a typical initial value of 0.9\. It decreases from iteration
    to iteration. This slows the particle as the search progresses, in theory, because
    the particle is likely moving closer to the best position. The second term calculates
    the difference between the particle’s best-known position so far, ![Image](../images/xcap.jpg),
    and its current position, ***x**[i]*. This value is multiplied, component by component,
    by ***c***[1] = *c*[1]***U***[0, 1), that is, a random vector in [0, 1) multiplied
    by a scalar, *c*[1]. We use 1.49, a typical value. The last term in the velocity
    update calculates the difference between the swarm’s best-known position, ***g***,
    and the particle’s current position, and multiplies it by vector ***c***[2] =
    *c*[2]***U***[0, 1). Usually, *c*[1] = *c*[2].
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, the particle position is updated using the newly calculated velocity:'
  prefs: []
  type: TYPE_NORMAL
- en: '***x**[i]* ← ***x**[i]* + ***υ**[i]*'
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*If you have a physics background and are, like me, bothered by the addition
    of a velocity and a position, imagine a* Δ t = 1 *multiplying* **v***[i] where*
    Δ t *is the time step between iterations. Now the units are correct.*'
  prefs: []
  type: TYPE_NORMAL
- en: Bare-bones PSO, sometimes called BBPSO, does not use a velocity vector. Instead,
    particle positions are updated with samples from a normal distribution. If ***x**[i]*
    is the vector representing particle *i*’s current position, then ***x**[ij]* is
    the *j*th component of that vector. With that in mind, calculate
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0114-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: if *p ∼ U*[0, 1) < *p[b]*, otherwise
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0114-04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: for each component (*j*) of each particle (*i*). Here, ![Image](../images/f0114-05.jpg)
    means draw a sample from a normal distribution with mean ![Image](../images/x-bar.jpg)
    and standard deviation *σ*. Typically, *p[b]* = 0.5, so 50 percent of the time,
    on average, the particle’s *j*th component is calculated from the normal distribution,
    and 50 percent of the time it’s simply a copy of the corresponding component of
    the particle’s best position, ![Image](../images/xcap.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: '**Genetic Algorithm (GA)**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We know from our evolution experiments that a GA involves breeding (crossover)
    and random mutation. The code in *GA.py* follows this pattern, but fits with the
    overall optimization framework. In particular, *GA.py* manipulates floating-point
    values by default, not integers. You can alter this behavior by subclassing `Bounds`
    and implementing a `Validate` method to force integer values.
  prefs: []
  type: TYPE_NORMAL
- en: The update rule for a particle, ***x**[i]*, involves crossover with a randomly
    chosen mate, where in this case the mate is selected from the top 50 percent best
    performing particles—see the `top` parameter of the `GA` constructor. Additionally,
    the current best-particle position, that is, the fittest particle, is passed to
    the next generation unaltered.
  prefs: []
  type: TYPE_NORMAL
- en: Our evolution experiments bred every individual, generation to generation. Here,
    individuals breed only if a random value is below the `CR` probability, 0.8 by
    default. When an individual breeds, it is replaced by the offspring. Whether ***x**[i]*
    breeds, there is a certain probability of a random mutation by assigning a randomly
    selected dimension a random value. Therefore, for any update, a particle may be
    replaced by its offspring, and it may undergo random mutation. The default mutation
    probability is 5 percent (`F` in the `GA` constructor).
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, the GA seems to work best for problems that aren’t mathematical
    (like curve fitting) and involve a higher number of dimensions to give evolution
    a larger “genome” to manipulate. Whether this has implications for biological
    evolution, I don’t know; regardless, another hallmark of the GA is slow convergence.
    You often need an order of magnitude more iterations (or even more) to reach a
    solution similar to that found far more quickly by Jaya or DE. Let’s turn there
    now.
  prefs: []
  type: TYPE_NORMAL
- en: '**Differential Evolution (DE)**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: DE was invented in 1995 by Price and Storn, the same year particle swarm optimization
    was invented by Kennedy and Eberhart. Like PSO, DE has stood the test of time
    and grown into a collection of similar approaches. DE is an evolutionary algorithm
    where particles are updated between iterations by a process involving crossover
    and mutation. However, unlike the straightforward crossover and mutation of the
    GA, DE replaces ***x**[i]* with a new vector that is, in a sense, the offspring
    of *four* parents. DE isn’t modeled on nature.
  prefs: []
  type: TYPE_NORMAL
- en: 'To update particle ***x**[i]*, first select three other members of the swarm,
    unique and not ***x**[i]*. From these three, create a donor vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '***υ*** = ***υ***[1] + *F*(***υ***[2] – ***υ***[3])'
  prefs: []
  type: TYPE_NORMAL
- en: Some variants of DE require that ***υ***[1] be the best performing member of
    the swarm instead of a randomly selected member. Here, *F* plays the role of mutation
    in the GA. In this case, the default value is *F* = 0.8.
  prefs: []
  type: TYPE_NORMAL
- en: The offspring of ***x**[i]* and ***υ*** is created component by component (gene
    by gene) where, with probability *CR*, the corresponding component of ***υ***
    is used; otherwise, the component of ***x**[i]* is retained. The default value
    is *CR* = 0.5, meaning the offspring of ***x**[i]* retains, on average, 50 percent
    of its existing values (genes).
  prefs: []
  type: TYPE_NORMAL
- en: There are so many variants of DE that a nomenclature has arisen to describe
    them. The code in *DE.py* defaults to “DE/rand/1/bin,” meaning the donor vector
    uses three randomly selected vectors (“rand”), a single differential (***υ***[2]
    – ***υ***[3]), and a *Bernoulli* crossover (“bin”). A Bernoulli trial is a coin
    flip where the probability of success is *p* and that of failure 1 – *p*. Here,
    *p* = *CR* is the crossover probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `DE` class supports two additional types of selection and an additional
    type of crossover, should you wish to experiment with them. If one of the three
    vectors used to build the donor is always the current swarm best, then the label
    begins with “DE/best/1.” Additionally, a new selection mode is supported: DE/toggle/1,
    which toggles between “rand” and “best” every other update. Finally, Bernoulli
    crossover may be replaced with GA-style crossover, meaning the `DE` class supports
    six possible differential variants from the three different selection and two
    crossover types. Feel free to experiment with all of them. Do you notice anything
    different between them, especially how quickly the swarm converges? Hint: look
    at all the values in the `gbest` element of the dictionary returned by `DE`’s
    `Results` method combined with the `giter` element that tracks the iteration number
    for each new swarm best position (`gpos`) and objective function value (`gbest`).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of this section was to fit a known function to a dataset by minimizing
    the MSE between the data points and the function value at those points. We were
    after the parameters of the function, as we already knew the form we wanted. This
    raises the question: What if all we have is the data and we don’t know the functional
    form? There are several ways to answer this. One is to use a machine learning
    model—after all, that’s what they are designed to do: learn a model (function)
    from a set of data. We’ll do this in [Chapter 5](ch05.xhtml). Another is to evolve
    a piece of code that approximates the data. Let’s give this approach a shot.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fitting Data**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Curve fitting had us searching for the parameters of a known function. In this
    section, all we have is the data and our goal is to evolve a piece of code approximating
    a function that fits the data. We still want *y* = *f*(*x*)—that is, for a given
    *x* we get an approximated *y*—but here *f*(*x*) is Python code. Evolving code
    is known as *genetic programming (GP)*, and it has a long history dating back
    to the early 1990s. A related term is *symbolic regression*.
  prefs: []
  type: TYPE_NORMAL
- en: As the name suggests, GP often uses the GA. Our implementation, however, uses
    the framework from the previous section so we can select any of the swarm intelligence
    and evolutionary algorithms. To use a swarm, we need to find a mapping between
    what we want (code) and a multidimensional space where each position in the space
    represents a possible solution. For curve fitting, the mapping was straightforward.
    If there were *n* parameters in the function, there were *n* parameters in the
    search space where each coordinate of a specific point was, literally, the parameter
    value.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we have to be more clever. To identify the mapping, let’s think about
    how we want to represent the code of our function, and from there, the mapping
    might be somewhat easier to see.
  prefs: []
  type: TYPE_NORMAL
- en: We want a function manipulating a scalar input value, *x*, to arrive at a scalar
    output value, *y*. So, we need math. We’ll make do with the standard arithmetic
    operations, plus negation, modulo, and powers.
  prefs: []
  type: TYPE_NORMAL
- en: Doing math implies mathematical expressions. Here things become murkier. Manipulating
    mathematical expressions is rather tricky, more tricky than we care to attack
    in a book like this. Traditional GP manipulates expressions using an evolutionary
    algorithm, complete with crossover and mutation, where crossover merges two expressions
    and mutation alters a term in the expression.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, we can use a shortcut. If we have a stack and know about postfix
    notation, we have all we need to generate expressions and map code to a position
    in the search space. I’ll explain, but let’s make sure we’re on the same page
    when it comes to stacks and postfix notation.
  prefs: []
  type: TYPE_NORMAL
- en: '***Introducing Stacks and Postfix Notation***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Imagine a stack of cafeteria trays. As new trays are added to the stack, they
    rest on top of all the existing trays. When someone needs a tray, they take the
    top tray, meaning the last tray added to the stack is the first tray removed from
    it. *Stacks* are like cafeteria trays (though cleaner).
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this example. We have three numbers: 1, 2, and 5\. We also have a
    stack that is currently empty. The first number we *push* on the stack is 1, then
    we push 2, and finally 5\. [Figure 4-3](ch04.xhtml#ch04fig03) shows what the stack
    looks like step by step, from left to right.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-3: Stack manipulation*'
  prefs: []
  type: TYPE_NORMAL
- en: On the left, the stack is empty; then, moving right, we add 1, then 2, and finally
    5\. The stack is now three deep, with 1 at the bottom and 5 at the top.
  prefs: []
  type: TYPE_NORMAL
- en: Now it’s time to *pop* a value off the stack. What value do we get? In a queue,
    we would get 1, the first value in. For a stack, we get 5, the last value pushed.
    Pop the stack again and we get 2, and finally 1, leaving the stack empty. Values
    pop off a stack in reverse order compared to how they are pushed onto the stack.
  prefs: []
  type: TYPE_NORMAL
- en: Stacks are natural structures for manipulating expressions in *postfix* form,
    that is, expressions where the operands come first, followed by the operation.
    For example, infix notation, our usual way of writing expressions, might say *a*
    + *b*, but in postfix notation, this becomes *a b* +. Postfix notation, also called
    reverse Polish notation (RPN), was developed in 1924 by Polish mathematician Jan
    Łukasiewicz. Postfix notation doesn’t require parentheses to alter operator precedence.
    Instead, it builds the expression piece by piece. Combine postfix notation with
    a stack, and it becomes straightforward to evaluate arbitrary expressions. This
    is precisely what we want.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand what I mean, let’s translate the infix expression *y* =
    *a*(*b* + *c*) – *d* to postfix notation and implement it using a stack and pseudocode
    statements. In postfix notation, it becomes *a b c* + × *d* –. To evaluate it,
    move from left to right until you hit an operator, here +. The operands are the
    two variables to the left, *b* and *c*. Compute *b* + *c* and replace “*b c* +”
    with the result, *t*[0]. The expression is now *a t*[0] × *d* –. Repeat to find
    × with operands *a* and *t*[0]. Compute the product and replace it with *t*[1]
    to get *t*[1] *d* –. Finally, evaluate *t*[1] – *d* to get the value of the expression,
    *y*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s implement this process in code using a stack to hold values. Consider
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The values on the right show the stack after each instruction with *t*[0] =
    *b* + *c*, *t*[1] = *a* × *t*[0], and *y* = *t*[1] – *d*. The expressions leave
    the answer, *y*, on the stack, and `push` places values on the stack. Binary operations
    like `add` pop two values off the stack, add them, and push the result back on
    the stack. Therefore, a linear sequence of statements and a stack are all we need
    to implement any function of *x* yielding *y*—at least, any function involving
    arithmetic operations, negation, and powers.
  prefs: []
  type: TYPE_NORMAL
- en: Functions written in this way become sequences of instructions with no loops.
    If we find a way to map the sequences to floating-point vectors, we’re in business.
  prefs: []
  type: TYPE_NORMAL
- en: '***Mapping Code to Points***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To evolve code, we need the four basic arithmetic operations: addition (`add`),
    subtraction (`sub`), multiplication (`mul`), and division (`div`). We also need
    exponentiation (`pow`) and will throw in modulo for good measure (`mod`).'
  prefs: []
  type: TYPE_NORMAL
- en: Postfix notation distinguishes the subtraction operator and negation, treating
    the latter as a different instruction, so we need negation (`neg`) as well, *x
    →* –*x*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we need two more instructions: `halt` and `push`. If `halt` is executed,
    the code stops and ignores any subsequent instructions. The `push` instruction
    pushes *x* or a number (a constant) on the stack.'
  prefs: []
  type: TYPE_NORMAL
- en: We have nine instructions. We want a sequence of instructions executed in order,
    which reminds me of a vector where each element is an instruction, and we execute
    the instructions one at a time from index 0 to the end of the vector.
  prefs: []
  type: TYPE_NORMAL
- en: Each instruction becomes a value, for example, `add` is 1 and `sub` is 2, so
    if a particle has a 2 in a particular component, then that component encodes a
    subtraction instruction. Particle positions are floating-point numbers, not integers,
    so we’ll keep only the integer part of each, meaning a component with a floating-point
    value of 2.718 is interpreted as a 2, implying a subtraction instruction.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 4-1](ch04.xhtml#ch04tab01) has the mapping we’ll use for instructions
    (the integer part of a particle position).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 4-1:** Mapping Particle Positions to Instructions'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Instruction** | **Number** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `add` | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `sub` | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| `mul` | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| `div` | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| `mod` | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| `pow` | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| `neg` | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| `push(x)` | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| `halt` | 9 |'
  prefs: []
  type: TYPE_TB
- en: All that remains is to handle pushing constants on the stack. If we can’t do
    this, we’re stuck evolving expressions of only *x*, like *xx* + *x* – *x* – *x*,
    which will get us nowhere.
  prefs: []
  type: TYPE_NORMAL
- en: The instruction numbers begin with 1, not 0\. This is intentional. Numbering
    this way leaves vector components in the range [0, 1) available as that range
    is not associated with an instruction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use this range to push arbitrary numbers on the stack. When we run a
    search, we’ll specify a lowest and highest number, like –1 and 11\. Then, we’ll
    map values in [0, 1) to [–1, 11). So, to push a constant of 3.1472 on the stack,
    we issue the instruction 0.3456 because:'
  prefs: []
  type: TYPE_NORMAL
- en: '*a* + *f*(*b* – *a*) = –1 + 0.3456(11 – ^–1) = 3.1472'
  prefs: []
  type: TYPE_NORMAL
- en: Handling things this way lets us specify arbitrary constant values within the
    given range.
  prefs: []
  type: TYPE_NORMAL
- en: For example, [Table 4-2](ch04.xhtml#ch04tab02) shows a segment of code generated
    by *gp.py*, the program we’re in the process of developing, along with the actual
    particle position values.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 4-2:** An Evolved Code Sample'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Instruction** | **Particle value** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `push(x)` | — |'
  prefs: []
  type: TYPE_TB
- en: '| `push(x)` | 8.5251446 |'
  prefs: []
  type: TYPE_TB
- en: '| `push(3.00482)` | 0.6502409 |'
  prefs: []
  type: TYPE_TB
- en: '| `mul` | 3.3605457 |'
  prefs: []
  type: TYPE_TB
- en: '| `push(7.07870)` | 0.8539350 |'
  prefs: []
  type: TYPE_TB
- en: '| `push(-9.09650)` | 0.0451748 |'
  prefs: []
  type: TYPE_TB
- en: '| `mod` | 5.0708302 |'
  prefs: []
  type: TYPE_TB
- en: '| `add` | 1.3708454 |'
  prefs: []
  type: TYPE_TB
- en: '| `halt` | 9.7707617 |'
  prefs: []
  type: TYPE_TB
- en: '| `div` | 4.2693693 |'
  prefs: []
  type: TYPE_TB
- en: '| `sub` | 2.6309877 |'
  prefs: []
  type: TYPE_TB
- en: '| `div` | 4.6783009 |'
  prefs: []
  type: TYPE_TB
- en: '| `pow` | 6.5429319 |'
  prefs: []
  type: TYPE_TB
- en: The task was to fit a noisy set of points representing a line. The evolved function
    fit the data quite nicely. The number limit in this case was –10 to 10, and I
    told the search (bare-bones PSO) to use 12 instructions. All evolved functions
    begin with *x* on the stack, here represented by the first `push(x)`. Also, when
    the function exits, it returns the top stack value as *y*. Any remaining stack
    values are ignored.
  prefs: []
  type: TYPE_NORMAL
- en: If the particle value is ≥ 1, the integer part specifies an instruction, so
    8.525 *→* 8, which is the instruction to push *x*, just as 3.360 *→* 3 to indicate
    multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: 'Look at the second particle vector component, 0.6502409, which, with the number
    limits, becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: –10 + 0.6502409(10 – ^–10) = 3.00482
  prefs: []
  type: TYPE_NORMAL
- en: This number is multiplied by *x*, that is, the second and third instructions
    implement 3.00482*x*. The data points were generated by adding a small amount
    of random noise to the line 3*x* – 2\. The evolved function immediately implements
    3.00482*x*, which is quite encouraging.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next three instructions push 7.07870 then –9.09650 on the stack before
    executing `mod`. This seems like a strange thing to do, but consider what Python
    does with the expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: These instructions leave –2.0178 on the stack.
  prefs: []
  type: TYPE_NORMAL
- en: The next instruction is `add`. We add the top two stack values, which we just
    learned are 3.00482*x* and –2.0178\. Interestingly, this is equivalent to the
    infix expression 3.00482*x* – 2.0178, and earlier I stated that the data points
    were generated from 3*x* – 2\. The evolved code implements the expression used
    to create the data points in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: The instruction following `add` is `halt`, which causes the function to exit
    with the sum on the stack. Instructions after `halt` are never executed.
  prefs: []
  type: TYPE_NORMAL
- en: Fabulous! We have an approach, a way to map floating-point vectors to code to
    implement a function. It’s a bit odd, but we’ll run with it and see where we get.
    Our next task is to create *gp.py*.
  prefs: []
  type: TYPE_NORMAL
- en: '***Creating gp.py***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you haven’t already, read through *gp.py*. The essential framework pieces
    are all there, and we won’t discuss every line, so it will help to be familiar
    with it before we begin.
  prefs: []
  type: TYPE_NORMAL
- en: The code imports all the framework components from the earlier curve fitting
    exercise; defines some helper functions (`GetData`, `Number StrExpression`) and
    the objective function class before the main code, which interprets the command
    line; constructs framework objects; and runs the search. Let’s review `Number`
    and the objective function class here. The main code mirrors that of the curve
    fitting code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Number` function transforms particle values in [0, 1) to the range specified
    on the command line when *gp.py* is executed. Specifically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It’s a direct implementation of the previous equation with `gmin` and `gmax`
    being the limits from the command line. These limits restrict the range of possible
    constants available to the evolved code; therefore, some experimentation might
    be necessary to find reasonable limits. For example, if you run a search and see
    constants at the limits, the specified range is likely too small, so double the
    size and try again. Remember, swarm intelligence and evolutionary algorithms are
    stochastic and heuristic. Parameters controlling their operation abound and must
    often be managed to produce good results.
  prefs: []
  type: TYPE_NORMAL
- en: 'A successful swarm search utilizes an objective function that drives the swarm
    toward good solutions, here a piece of code minimizing the MSE between the known
    data points and the output of the code at those data points. Therefore, our next
    port of call is the objective function class, `Objective`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: There are two methods, a constructor and `Evaluate`. The constructor keeps the
    data points and the number limits passed on the command line. It also initializes
    `fcount`, which tracks the number of times the objective function is evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: The `Evaluate` method accepts a particle position (`p`) and passes the *x*-coordinate
    of the data points through it to generate output vector `y`. It then returns the
    MSE between `y` and `self.y` as the objective function value.
  prefs: []
  type: TYPE_NORMAL
- en: Not every piece of code represented by a particle position is valid. It’s likely,
    especially early on in the search, that the randomly generated particle positions
    become failing blocks of code because they try impossible things like extracting
    values from an empty stack or dividing by zero. The NaN check in `Evaluate` captures
    such cases and ensures that a very high objective function value is returned.
  prefs: []
  type: TYPE_NORMAL
- en: The function `Expression` evaluates a particle position as code. It’s given
    the *x* values, the particle position (`p`), and the number range; see [Listing
    4-1](ch04.xhtml#ch04list01).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 4-1: Interpreting a particle position as code*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Listing 4-1](ch04.xhtml#ch04list01) is the heart of *gp.py*. First, there
    is an embedded function, `BinaryOp` ➊, which implements all binary operations
    like addition and exponentiation. The stack (`s`), a standard Python list, is
    popped twice to get the operands. Note the order: if we want *a* – *b* and *b*
    is the top stack item, then the first pop returns *b*, not *a*. The second argument
    indexes the operation. A more compact implementation might use Python’s `eval`
    function. Still, we need to be as fast as possible, so we opt for the verbose
    but significantly faster compound `if`.'
  prefs: []
  type: TYPE_NORMAL
- en: The code initializes the stack with *x* ➋ and then begins a loop over the components
    of the particle position (`expr`) ➌. Everything is inside a `try` block to catch
    any errors. Errors return `bad` as the function value.
  prefs: []
  type: TYPE_NORMAL
- en: If the particle component is less than 1.0, it pushes a constant, the output
    of `Number`, on the stack. Otherwise, the integer part of the value determines
    the operation. If less than 7, the appropriate binary operation is performed;
    otherwise, the instruction is either negation, push *x*, or halt, which breaks
    out of the loop, thereby ignoring the remaining particle components. Finally,
    the function returns the top stack item, if there is one, as the function value
    ➍.
  prefs: []
  type: TYPE_NORMAL
- en: 'The remainder of *gp.py* is straightforward: parse the command line, create
    framework objects (`Bounds`, `RandomInitializer`, `Objective`), then, with the
    proper swarm object, call `Optimize` and `Results` to report how well the search
    went. If a final plot name is given, we generate it showing the data points and
    the fit.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our curve fitting code used bare-bones PSO. This code uses both bare-bones
    and canonical PSO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We can differentiate between the two by passing either `PSO` or `BARE` on the
    command line. Note that PSO uses options we haven’t seen before. One is `LinearInertia`,
    which linearly decreases *ω* during the search from 0.9 down to 0.4\. Inertia
    is the coefficient multiplying the previous iteration’s velocity, per particle.
  prefs: []
  type: TYPE_NORMAL
- en: There are three additional options. Two are `ring` and `neighbors`, which work
    together. A variation of canonical PSO includes the concept of a *neighborhood*,
    a collection of particles that coordinate with each other. The practical effect
    of a neighborhood is to replace the global best position, ***g***, with a neighborhood
    best. The arrangements of particles into neighborhoods is referred to as a *topology*.
    The `PSO` class supports a ring topology—the simplest. Imagine the particles forming
    a circle; then, for any particle, the `neighbors` particles to the left and right
    form the current particle’s neighborhood. As a challenge, try to modify *PSO.py*
    to accommodate von Neumann neighborhoods, which is frequently the best performing
    topology. Careful searching online will show you what a von Neumann topology entails.
  prefs: []
  type: TYPE_NORMAL
- en: The final new option is `vbounds`, which sets limits on the maximum velocity
    per particle component, much as `bounds` sets spatial limits on where the swarm
    can move within the search space. In the velocity case, `enforce` is `clip` to
    keep velocity components at the limits instead of resampling along that dimension.
  prefs: []
  type: TYPE_NORMAL
- en: The number of adjustable parameters makes it sometimes tricky to set up a successful
    canonical PSO search, even with neighborhoods. As a result, these values are more
    what you’d call “guidelines” than actual rules.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s put *gp.py* through its paces to see what it can (and cannot) do
    for us.
  prefs: []
  type: TYPE_NORMAL
- en: '***Evolving Fit Functions***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s put *gp.py* to the test with several experiments.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fitting a Line**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'To run *gp.py*, use a command line like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Illegal operations will likely happen early on in the search, so I recommend
    ignoring runtime errors by adding `-W ignore`. The command line uses the input
    file *x1_2n.txt*, which is the noisy line mentioned previously. Numbers are limited
    to [–5, 5), and the maximum program length is 22 instructions, though `halt` usually
    appears earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'The swarm has 20 particles and runs for 10,000 iterations using bare-bones
    PSO and the MINSTD randomness source. The result is written to *plot.png* with
    the code itself displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Note that `halt` appears as the ninth instruction (the initial `push(x)` is
    always present, so it’s not counted).
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-4](ch04.xhtml#ch04fig04) shows the original data points along with
    the fit function output.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-4: The evolved fit to a noisy line*'
  prefs: []
  type: TYPE_NORMAL
- en: The fit is good, which is encouraging. If we can’t fit a line, we shouldn’t
    expect to fit more complex functions.
  prefs: []
  type: TYPE_NORMAL
- en: We now have two different solutions to fitting the line, but the evolutionary
    path followed to arrive at a solution was quite different. The first solution
    evolved
  prefs: []
  type: TYPE_NORMAL
- en: (*x*)(3.00482) + (7.07870 mod – 9.09650) = 3.00482*x* – 2.0178
  prefs: []
  type: TYPE_NORMAL
- en: 'but the second produced:'
  prefs: []
  type: TYPE_NORMAL
- en: '*x* + *x* + *x* – (4.82483 / 2.39118) = 3*x* – 2.01776'
  prefs: []
  type: TYPE_NORMAL
- en: The second solution added *x* to itself three times instead of multiplying by
    a constant. Both solutions arrived at nearly identical intercepts, not by pushing
    a learned value but by implementing distinct binary operations with two learned
    values.
  prefs: []
  type: TYPE_NORMAL
- en: The *data* directory contains several datasets, many that are the output of
    *gpgen.py*, which you can use to create custom datasets, noisy polynomials up
    to degree five. Run *gpgen.py* without arguments to learn how it works. For now,
    let’s use a few of these datafiles to push *gp.py* to the limit.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fitting a Quadratic**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We evolved the equation of a line easily enough. What about a quadratic?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'For my run, this produced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Instructions after `halt` are ignored as they have no effect. I’ll do this consistently
    from now on. The resulting fit is in [Figure 4-5](ch04.xhtml#ch04fig05).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-5: The evolved fit to a noisy quadratic*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The evolved code is equivalent to:'
  prefs: []
  type: TYPE_NORMAL
- en: (*x*² – ^–2.97844) – *x*) – *x*) = *x*² – 2*x* + 2.97844
  prefs: []
  type: TYPE_NORMAL
- en: The same dataset given to NumPy’s `polyfit` routine produces
  prefs: []
  type: TYPE_NORMAL
- en: '*x*² – 2.02*x* + 2.99'
  prefs: []
  type: TYPE_NORMAL
- en: giving us growing confidence in the evolutionary search.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fitting a Quartic**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The previous examples all use bare-bones PSO, which seems well suited to this
    task. Let’s try a different dataset, a quartic, along with different algorithms.
    Are all of them equally effective?
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we’ll fit the points in *x4_-2x3_3x2_-4x_5_50n.txt*, a noisy
    version of the quartic, *y* = *x*⁴ – 2*x*³ + 3*x*² – 4*x* + 5\. The only parameter
    changing from run to run is the optimization algorithm. For example, here’s the
    command line for bare-bones PSO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: To use differential evolution, change `bare` to `DE` and run again. We’ll examine
    the results for a single run of each algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The framework is designed for clarity, not speed. Since each particle evaluates
    the objective function independently of the others, opportunities for parallelization
    abound. Unfortunately, we take advantage of none of them, so patience is required
    to replicate the search for every algorithm: DE, bare-bones PSO, canonical PSO,
    Jaya, GA, and RO. Also, the framework does not use seed values, so your run of
    the code will produce different, though likely similar, output.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-6](ch04.xhtml#ch04fig06) displays the fit for each algorithm, from
    DE on the upper left to RO on the lower right.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-6: The fits for each algorithm*'
  prefs: []
  type: TYPE_NORMAL
- en: It’s evident that not every algorithm hit the mark. [Table 4-3](ch04.xhtml#ch04tab03)
    shows us the equivalent equations they generated.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 4-3:** The Fit Equations Evolved by Each Algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Algorithm** | **Equivalent equation** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| NumPy | *y* = 1.01*x*⁴ – 2.01*x*³ + 2.76*x*² – 3.34*x* + 5.76 |'
  prefs: []
  type: TYPE_TB
- en: '| Differential evolution | *y* = *x*⁴ – 2.19254*x*³ + 3*x*² |'
  prefs: []
  type: TYPE_TB
- en: '| Bare-bones PSO | *y* = *x*⁴ – 2.23835*x*³ |'
  prefs: []
  type: TYPE_TB
- en: '| Canonical PSO | *y* = *x*^(4.09896) |'
  prefs: []
  type: TYPE_TB
- en: '| Jaya | *y* = –*x*³ + 19.36026*x*² |'
  prefs: []
  type: TYPE_TB
- en: '| GA | *y* = 21.78212*x*² |'
  prefs: []
  type: TYPE_TB
- en: '| RO | ![Image](../images/f0128-01.jpg) |'
  prefs: []
  type: TYPE_TB
- en: The first equation is the fit returned by NumPy’s `polyfit` routine. The data
    was generated from a quartic, so we expect the NumPy fit to be the best, and we’ll
    treat it as the gold standard.
  prefs: []
  type: TYPE_NORMAL
- en: Differential evolution produced the best-evolved fit function. Compare it to
    the NumPy fit. The DE fit recovered the first three terms of the polynomial, with
    coefficients in the same ballpark as the NumPy fit. Similarly, bare-bones PSO
    recovered the first two terms of the polynomial. Canonical PSO recovered only
    the first term, *x*⁴ (or thereabouts).
  prefs: []
  type: TYPE_NORMAL
- en: Jaya produced an exciting result. The two terms fight against each other, but
    their sum becomes a crude approximation of the dataset. As an exercise, try plotting
    –*x*³, 19.36*x*², and their sum to see what I mean.
  prefs: []
  type: TYPE_NORMAL
- en: Both the GA and RO produced inferior output. The GA ended up with a quadratic,
    and whatever RO created fits only the left-hand set of dataset points, *x* < –3
    or so.
  prefs: []
  type: TYPE_NORMAL
- en: 'These results are from single runs. We know that swarm optimization algorithms
    are stochastic and vary from run to run. Perhaps we’re being a bit unfair, then.
    I ran the Jaya search five more times; here are the resulting equivalent equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0129-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The results imply that Jaya isn’t converging well to a local minimum. It either
    captures the essential *x*⁴ aspect of the data or stops at a quadratic.
  prefs: []
  type: TYPE_NORMAL
- en: Jaya isn’t the only algorithm we might be selling short. The GA and RO produced
    inferior results on our initial runs. What if we increase the swarm size and churn
    for more iterations? Intuitively, for these algorithms, it might make sense to
    do this. The more particles searching on their own, the more likely we’ll find
    a good position in the search space, so a larger swarm seems sensible for RO.
    For the GA, a larger population increases the size of the gene pool, so we should
    get better performance as well, much like the genetic drift example from [Chapter
    3](ch03.xhtml) where the larger population was better able to adapt to the environment
    after a catastrophe.
  prefs: []
  type: TYPE_NORMAL
- en: Running a swarm of 125 particles for 150,000 iterations using RO produced a
    function calculating 21.54962*x*², which is not encouraging as RO isn’t even capturing
    the quartic nature of the dataset. A run of the GA with 512 particles (organisms)
    for 30,000 iterations requiring all organisms to breed with a member of the best
    performing 20 percent (`top=0.2`) produced [Figure 4-7](ch04.xhtml#ch04fig07),
    which contains a graph showing the fit.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-7: The genetic algorithm’s solution for 512 organisms and 30,000
    generations*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The evolved set of instructions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The function is quite strange, and used all 22 possible instructions (the initial
    `push(x)` is always present), which is also quite different from the results found
    with other algorithms. The equivalent function is
  prefs: []
  type: TYPE_NORMAL
- en: '*y* = 23.76431*x*² – 21.60479*x* – 46.13863 – 24.96894(10.10315 mod *x*)'
  prefs: []
  type: TYPE_NORMAL
- en: 'which makes more sense in this form: a quadratic with an additional term using
    modulo, thereby accounting for the strange-looking oscillations on top of the
    general quadratic form.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fitting a Normal Curve**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The previous examples attempted to evolve a function to match a polynomial.
    What happens if we try to fit a noisy normal (Gaussian) curve instead? The source
    function, before adding random noise, was:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0131-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The noisy data points are in *noisy_exp.txt*.
  prefs: []
  type: TYPE_NORMAL
- en: I ran three searches, once each for DE, bare-bones PSO, and Jaya. The searches
    all used 25 particles and 20,000 iterations. I restricted numbers to [–25, 25],
    and gave the evolved functions a maximum of 22 instructions.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-8](ch04.xhtml#ch04fig08) shows the resulting fits.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/04fig08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-8: Evolving a function to fit a noisy normal curve*'
  prefs: []
  type: TYPE_NORMAL
- en: The DE and bare-bones PSO results are virtually identical and overlap. They
    fit the dataset well. As we’ve seen with other experiments, Jaya gets close but
    doesn’t produce as nice a fit as the others.
  prefs: []
  type: TYPE_NORMAL
- en: So, what were the evolved functions? In this case, not only is the equivalent
    function illustrative, but so is the form of the code, so we’ll consider both
    together; see [Table 4-4](ch04.xhtml#ch04tab04).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 4-4:** Comparing the Evolved Programs by Algorithm'
  prefs: []
  type: TYPE_NORMAL
- en: '| **DE** | **Bare-bones PSO** | **Jaya** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `push(x)` | `push(x)` | `push(x)` |'
  prefs: []
  type: TYPE_TB
- en: '| `push(x)` | `push(x)` | `neg` |'
  prefs: []
  type: TYPE_TB
- en: '| `push(0.35484)` | `push(x)` | `push(7.95565)` |'
  prefs: []
  type: TYPE_TB
- en: '| `push(x)` | `push(2.80857)` | `push(x)` |'
  prefs: []
  type: TYPE_TB
- en: '| `push(x)` | `push(x)` | `pow` |'
  prefs: []
  type: TYPE_TB
- en: '| `mul` | `neg` | `push(x)` |'
  prefs: []
  type: TYPE_TB
- en: '| `pow` | `push(x)` | `neg` |'
  prefs: []
  type: TYPE_TB
- en: '| `halt` | `mul` | `pow` |'
  prefs: []
  type: TYPE_TB
- en: '|  | `pow` | `halt` |'
  prefs: []
  type: TYPE_TB
- en: '|  | `halt` |  |'
  prefs: []
  type: TYPE_TB
- en: The equivalent function evolved is *y* = 0.35484^(*x*²) (DE), *y* = 2.80857^(–*x*²)
    (bare-bones PSO), and *y* = 7.95565^(–*x*²) (Jaya). Again, the function we’re
    trying to recover from the noisy data is
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0132-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where I’ve approximated *e* with the first five digits of its decimal expansion.
    Written this way, it’s clear that the bare-bones PSO search evolved almost exactly
    this function, so we should expect it to fit the data nicely.
  prefs: []
  type: TYPE_NORMAL
- en: The DE result seems odd at first. It’s an exponential function, but the base
    is 0.35484, not *e*, and the exponent is *x*², not –*x*². However, 1/*e* ≈ 0.36788,
    meaning DE evolved the same function as bare-bones PSO since
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0132-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and 0.35484 is quite close to 0.36788\. Finally, Jaya had the right idea, but
    didn’t converge to the correct base, 7.95565 > *e*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercises**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Swarm algorithm applications are legion. Here are a few things you may wish
    to explore in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: In the *curves* directory you’ll find a *NIST* directory. It contains example
    curve fit datafiles from the National Institute of Standards and Technology (NIST),
    part of the United States Department of Commerce. I formatted the *.txt* versions
    so that they’ll work with *curves.py*. The original versions end with *.dat*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are challenging curve fitting test files meant to test high-performance
    curve fitting routines. Are any of the swarm algorithms up to the challenge? If
    so, which files can be fit, and which fail?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `Results` method of a swarm object returns a dictionary, as we saw throughout
    the chapter. We can track the objective function value as a function of swarm
    iteration by using the `gbest` and `giter` dictionary values. The first is a list
    of each new global best objective function value, and the second is a list marking
    the iteration at which that value became the global best.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examine the code in *plot_gbest_giter.py* to learn how to plot these values
    to track the swarm’s learning during a search. Capture the corresponding lists
    for other searches using the examples in the chapter to make similar plots. Do
    the swarms all converge at the same rate for the same problem?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The file *gaussian.py*, in the *micro* directory, runs a swarm search to minimize
    a two-dimensional function consisting of two inverted normal curves, that is,
    the function is *z* = *f*(*x*, *y*). The file *gaussians.png* shows a 3D plot
    of the function with two minima, one lower than the other. Since the function
    being minimized has two inputs, the search space is two-dimensional, making it
    possible to plot the position of every particle in the swarm and track them as
    they move during the search.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run *gaussian.py* without arguments to learn how to run a search and output
    images of the swarm at each step. Then, page through the images to watch the swarm
    search. The known best position is the empty box. The swarm’s current best position
    is the star. Change the algorithm to observe how each converges and traverses
    the space. Do the algorithms search the space in the same way? Do they converge
    on the global minimum, and, if so, at the same rate?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The file *GWO.py*, also in the *micro* directory, implements the Grey Wolf Optimizer
    (GWO). GWO is a popular swarm intelligence algorithm, in theory, modeling the
    behavior of wolves as they hunt (I don’t buy it).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test GWO using *gaussian.py*, then adapt *curves.py* and *gp.py* to use it as
    well. A quick copy-paste is all that’s needed. How does GWO’s performance compare
    to DE, bare-bones PSO, and Jaya? It’s often claimed that GWO has no adjustable
    parameters, like Jaya. This is not strictly true. The `eta` parameter, which defaults
    to 2, can be adjusted, and this sometimes helps the search. If GWO isn’t performing
    well, adjust `eta`, perhaps to 3 or 4, and try again.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Consider the code in *MiCRO.py*, also in the *micro* directory. It implements
    a tongue-in-cheek swarm algorithm loosely based on grazing cattle that I call
    *Minimally Conscious Random Optimization*. It’s meant to show how easy it is to
    create a “novel,” “nature-inspired” swarm algorithm. The idea behind MiCRO is
    that the swarm is a herd of cattle, mindlessly grazing in complete ignorance of
    each other. With a set probability on any iteration, an animal might look up and
    consider another animal’s position that’s better than its own. If this happens,
    the animal jumps to the region around the better-off neighbor and continues to
    graze. So, the algorithm is RO with a slight probability of noticing a better
    performing neighbor; the swarm is *minimally conscious*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explore how MiCRO performs using *gaussian.py*, then invent your own swarm algorithm
    using the code in *RO.py* and *MiCRO.py* as guides. Does your algorithm work?
    Does it work well? Is it really inspired by nature, or is the nature “inspiration”
    an after-the-fact justification?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The code evolved by *gp.py* is restricted to arithmetic operations plus powers
    and modulo. Add sine, cosine, and tangent as available operators. Each consumes
    one item from the stack and returns one item to the stack.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try to fit the *cos.txt*, *sin.txt*, and *tan.txt* datasets in the *data* directory.
    Can the swarm algorithms do it?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Recent work has demonstrated that GWO, along with several other popular nature-inspired
    algorithms, is not novel at all, but is older PSO ideas wrapped in often strained
    metaphors. That being the case, it’s fair to wonder why I included GWO here. The
    emphasis in this book is on practicality and ease of application. GWO is popular
    and works in terms of providing solutions to problems. In that sense, it doesn’t
    matter whether it’s novel. For the larger optimization field, it’s critically
    important to understand what is novel and what is not. I suspect, in the end,
    that many of the myriads of nature-inspired algorithms will prove to be alternate
    takes on well-known approaches. But, if GWO works, then it works, so we’ll keep
    it in our small collection of algorithms at the risk of alienating genuine optimization
    researchers.
  prefs: []
  type: TYPE_NORMAL
- en: The file *nature-inspired_algorithms.pdf* lists dozens of nature- and physics-inspired
    swarm optimization algorithms. The list is by no means exhaustive.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This chapter introduced us to swarm intelligence and evolutionary algorithms.
    We used a software framework to develop two applications: one to fit data to a
    known functional form, that is, traditional curve fitting, and one to evolve code
    from scratch to implement a best fit function. We learned how to use the framework
    and explored each of the swarm algorithms to develop our intuition about how they
    work and are best applied. Each swarm algorithm critically depends on randomness,
    from the initial configuration of the particles to each update step that moves
    the particles throughout the search space.'
  prefs: []
  type: TYPE_NORMAL
- en: The experiments of this chapter fit data to functions by either locating the
    best parameters for a known functional form or evolving the function from scratch.
    Both attempts were successful, though not every algorithm performed equally well.
  prefs: []
  type: TYPE_NORMAL
- en: DE proved an excellent match to these tasks, further justifying it as a goto
    algorithm. However, I was surprised to see bare-bones PSO do so well. Canonical
    PSO wasn’t as effective, but it has more parameters to tweak, so it might be made
    better with some experimentation (you can adjust *c*[1], *c*[2], *ω*, the inertia
    parameter change over iterations, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: Jaya wasn’t a complete disappointment, but it performed similarly to other places
    where I’ve used it—not particularly good or bad. It was, at times, able to recover
    the essence of the functional form, but not the particulars, even allowing for
    many iterations. As a final example, I ran a search to fit the noisy normal function
    one more time using Jaya and 120,000 iterations, six times as many as before.
    The result was a worse fit than the first run with an equivalent function of
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/f0135-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: which looks vaguely similar to a normal curve but does not fit the data well.
  prefs: []
  type: TYPE_NORMAL
- en: RO is not, strictly speaking, a swarm algorithm because the particles don’t
    influence each other. Still, the examples here, combined with experience in other
    areas, make RO worth trying in many cases. We’ll encounter RO again in [Chapter
    5](ch05.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: Curve fitting is not the GA’s cup of tea. We learned in [Chapter 3](ch03.xhtml)
    that the GA is effective when simulating natural selection and genetic drift.
    Also, we barely explored some of its parameters, such as the fraction of top breeding
    organisms (`top`) or the particular mutation and crossover probabilities (*F*
    and *CR*, respectively).
  prefs: []
  type: TYPE_NORMAL
- en: We’re not through with swarm algorithms. Let’s leave curves and data-sets behind
    to apply swarm techniques to other areas, like image processing and in combination
    with a simulation.
  prefs: []
  type: TYPE_NORMAL
