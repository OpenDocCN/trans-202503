- en: '**17**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**17**'
- en: '**SAMPLING DISTRIBUTIONS AND CONFIDENCE**'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**抽样分布与置信区间**'
- en: '![image](../images/common-01.jpg)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![image](../images/common-01.jpg)'
- en: In [Chapters 15](ch15.xhtml#ch15) and [16](ch16.xhtml#ch16), you applied the
    idea of a probability distribution to examples where a random variable is defined
    as some measurement or observation of interest. In this chapter, you’ll consider
    sample statistics themselves as random variables to introduce the concept of a
    *sampling distribution*—a probability distribution that is used to account for
    the variability naturally present when you estimate population parameters using
    sample statistics. I’ll then introduce the idea of a *confidence interval*, which
    is a direct reflection of the variability in a sampling distribution, used in
    a way that results in an interval estimate of a population parameter. This will
    form the foundation for formal hypothesis testing in [Chapter 18](ch18.xhtml#ch18).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第15章](ch15.xhtml#ch15)和[第16章](ch16.xhtml#ch16)中，你将概率分布的概念应用于定义为某些感兴趣的测量或观察的随机变量的示例。在本章中，你将把样本统计量本身作为随机变量来引入*抽样分布*的概念——这是一种概率分布，用于解释在使用样本统计量估计总体参数时自然存在的变异性。接着，我将引入*置信区间*的概念，它直接反映了抽样分布中的变异性，并以这种方式使用，能够提供总体参数的区间估计。这将为[第18章](ch18.xhtml#ch18)中的正式假设检验奠定基础。
- en: '**17.1 Sampling Distributions**'
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**17.1 抽样分布**'
- en: A sampling distribution is just like any other probability distribution, but
    it is specifically associated with a random variable that is a sample statistic.
    In [Chapters 15](ch15.xhtml#ch15) and [16](ch16.xhtml#ch16), we assumed we knew
    the parameters of the relevant example distribution (for example, the mean and
    the standard deviation of a normal distribution or the probability of success
    in a binomial distribution), but in practice these kinds of quantities are often
    unknown. In these cases, you’d typically estimate the quantities from a sample
    (see [Figure 13-2](ch13.xhtml#ch13fig2) on [page 266](ch13.xhtml#page_266) for
    a visual illustration of this). Any statistic estimated from a sample can be treated
    as a random variable, with the estimated value itself as the realization of that
    random variable. It’s therefore entirely possible that different samples from
    the same population will provide a different value for the same statistic—realizations
    of random variables are naturally subject to variability. Being able to understand
    and model this natural variability inherent in estimated sample statistics (using
    relevant sampling distributions) is a key part of many statistical analyses.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样分布就像任何其他概率分布，但它特别与作为样本统计量的随机变量相关。在[第15章](ch15.xhtml#ch15)和[第16章](ch16.xhtml#ch16)中，我们假设知道相关示例分布的参数（例如，正态分布的均值和标准差，或二项分布中的成功概率），但在实践中，这些数量通常是未知的。在这种情况下，你通常会从样本中估计这些数量（有关这一点的可视化说明，参见[图13-2](ch13.xhtml#ch13fig2)，位于[第266页](ch13.xhtml#page_266)）。任何从样本中估计的统计量都可以视为一个随机变量，其估计值本身就是该随机变量的实现。因此，完全有可能从同一总体中抽取的不同样本会为相同的统计量提供不同的值——随机变量的实现自然会受到变异性的影响。能够理解并建模这种估计样本统计量固有的自然变异性（使用相关的抽样分布）是许多统计分析中的关键部分。
- en: Like any other probability distribution, the central “balance” point of a sampling
    distribution is its mean, but the standard deviation of a sampling distribution
    is referred to as a *standard error*. The slight change in terminology reflects
    the fact that the probabilities of interest are no longer tied to raw measurements
    or observations per se, but rather to a quantity calculated from a *sample* of
    such observations. The theoretical formulas for various sampling distributions
    therefore depend upon (a) the original probability distributions that are assumed
    to have generated the raw data and (b) the size of the sample itself.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他任何概率分布一样，抽样分布的中心“平衡”点是其均值，但抽样分布的标准差被称为*标准误差*。术语上的细微变化反映了这样一个事实：感兴趣的概率不再直接与原始测量或观察值相关，而是与从*样本*中计算出的某个量相关。因此，各种抽样分布的理论公式依赖于（a）假定生成原始数据的原始概率分布，以及（b）样本本身的大小。
- en: 'This section will explain the key ideas and provide some examples, and I’ll
    focus on two simple and easily recognized statistics: a single sample mean and
    a single sample proportion. I’ll then expand on this in [Chapter 18](ch18.xhtml#ch18)
    when covering hypothesis testing, and you’ll need to understand the role of sampling
    distributions in assessing important model parameters when you look at regression
    methods in [Chapters 20](ch20.xhtml#ch20) to [22](ch22.xhtml#ch22).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '*The validity of the theory of sampling distributions as discussed in this
    chapter makes an important assumption. Whenever I talk about a sample of data
    from which a given statistic is calculated, I assume those observations are independent
    of one another and that they are identically distributed. You’ll see this notion—independent,
    identically distributed observations—frequently abbreviated as* iid *in statistical
    material.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '***17.1.1 Distribution for a Sample Mean***'
  id: totrans-10
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The arithmetic mean is arguably the most common measure of centrality ([Section
    13.2.1](ch13.xhtml#ch13lev2sec116)) used when summarizing a data set.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, the variability inherent in an estimated sample mean is described
    as follows: Formally, denote the random variable of interest as *X̄*. This represents
    the mean of a sample of *n* observations from the “raw observation” random variable
    *X*, as in *x*[1], *x*[2], . . . , *x*[*n*]. Those observations are assumed to
    have a true finite mean −∞ < *μ*[*X*] < ∞ and a true finite standard deviation
    0 < *σ*[*X*] < ∞. The conditions for finding the probability distribution of a
    sample mean vary depending on whether you know the value of the standard deviation.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '**Situation 1: Standard Deviation Known**'
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'When the true value of the standard deviation *σ*[*X*] is known, then the following
    are true:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: • If *X* itself is normal, the sampling distribution of *X̄* is a normal distribution,
    with mean *μ*[*X*] and standard error ![image](../images/common-03.jpg).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: • If *X* is not normal, the sampling distribution of *X̄* is still approximately
    normal, with mean *μ*[*X*] and standard error ![image](../images/common-03.jpg),
    and this approximation improves arbitrarily as *n* → ∞. This is known as the *central
    limit theorem (CLT)*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '**Situation 2: Standard Deviation Unknown**'
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In practice, you commonly won’t know the true value of the standard deviation
    of the raw measurement distribution that generated your sample data. In this eventuality,
    it’s usual to just replace *σ*[*X*] with *s*[*X*], which is the standard deviation
    of the sampled data. However, this substitution introduces additional variability
    that affects the distribution associated with the sample mean random variable.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: • Standardized values ([Section 16.2.2](ch16.xhtml#ch16lev2sec142)) of the sampling
    distribution of *X̄* follow a *t*-distribution with *ν* = *n* − 1 degrees of freedom;
    standardization is performed using the standard error ![image](../images/common-04.jpg).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: • If, additionally, *n* is small, then it is necessary to assume the distribution
    of *X* is normal for the validity of this *t*-based sampling distribution of *X̄*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: The nature of the sampling distribution of *X̄* therefore depends upon whether
    the true standard deviation of the observations is known, as well as the sample
    size *n*. The CLT states that normality occurs even if the raw observation distribution
    is itself not normal, but this approximation is less reliable if *n* is small.
    It’s a common rule of thumb to rely on the CLT only if *n* ≥ 30\. If *s*[*X*],
    the sample standard deviation, is used to calculate the standard error of *X̄*,
    then the sampling distribution is the *t*-distribution (following standardization).
    Again, this is generally taken to be reliable only if *n* ≥ 30.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '**Example: Dunedin Temperatures**'
  id: totrans-22
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As an example, suppose that the daily maximum temperature in the month of January
    in Dunedin, New Zealand, follows a normal distribution, with a mean of 22 degrees
    Celsius and a standard deviation of 1.5 degrees. Then, in line with the comments
    for situation 1, for samples of size *n* = 5, the sampling distribution of *X̄*
    will be normal, with mean 22 and standard error ![image](../images/f0369-03.jpg).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: The top image of [Figure 17-1](ch17.xhtml#ch17fig1) shows the raw measurement
    distribution along with this sampling distribution. You can produce this with
    code that’s familiar from [Chapter 16](ch16.xhtml#ch16).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, the sampling distribution of *X̄* is clearly a taller, skinnier
    normal distribution than the one tied to the observations. This makes sense—you
    expect less variability in an *average* of several measurements as opposed to
    the raw, individual measurements. Furthermore, the presence of *n* in the denominator
    of the standard error dictates a more precise distribution around the mean if
    you increase the sample size. Again, this makes sense—means will “vary less” between
    samples of a larger size.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now ask various probability questions; note that distinguishing between
    the measurement distribution and the sampling distribution is important. For example,
    the following code provides Pr(*X* < 21.5), the probability that a randomly chosen
    day in January has a maximum temperature of less than 21.5 degrees:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The next bit of code provides the probability that the sample mean will be
    less than 21.5 degrees, Pr(*X̄* < 21.5), based on a sample of five random days
    in January:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The line-shaded areas on the top of [Figure 17-1](ch17.xhtml#ch17fig1) show
    these two probabilities. In R, these shaded areas can be added to that plot by
    running the following lines directly after the earlier code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that in previous uses of `polygon`, you’ve simply specified a `col`; in
    this example, I implemented shading lines instead, using the arguments `density`
    (number of lines per inch) and `angle` (slope of lines in degrees; defaults to
    `angle=45`).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f17-01.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: '*Figure 17-1: Illustrating the sampling distribution of a sample mean for*
    n = *5, based on an N(22,1.5) raw observation distribution. Top: the normal-based
    version of the sampling distribution (assuming* *σ*[*X*] *is known) compared to
    the observation distribution. Bottom: the* t*-based version of the sampling distribution,
    using 4 degrees of freedom (in other words, assuming* s *has been used to calculate
    the standard error), compared to a standard normal. Shaded areas represent* Pr(*X*
    < 21.5), Pr(*X̄* < 21.5) *(solid and dashed, topmost plot) and* Pr(*T* < (21.5
    − *x̄*)/(s/ ![image](../images/5.jpg))) *(dotted, bottom plot).*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate the probabilities, note that you’ve required knowledge of the parameters
    governing *X*. In practice, you’ll rarely have these quantities (as noted in situation
    2). Instead, you obtain a sample of data and calculate summary statistics.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the following line produces five randomly generated Dunedin temperatures
    from the *X* ∼ N(22,1.5) distribution:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, for the sake of the example, say these five values constitute all the
    data you have for this particular problem; in other words, pretend you don’t know
    that *μ[*X*]* = 22 and *σ*[*X*] = 1.5\. Your best guesses of the true values of
    *μ*[*X*] and *σ*[*X*], denoted *x̄* and *s*, respectively, are therefore as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The estimated standard error can be calculated:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Because *n* = 5 is relatively small, you must assume the values in `obs` are
    realizations from a normal distribution, in line with the points made for situation
    2\. This allows you to handle the sampling distribution of *X̄* using the *t*-distribution
    with 4 degrees of freedom. Recall from [Section 16.2.3](ch16.xhtml#ch16lev2sec143),
    though, that any *t*-distribution is typically placed on a standardized scale.
    Therefore, for you to find the probability that the mean temperature (in a sample
    of five days) is less than 21.5 based on your calculated sample statistics, you
    must first standardize this value using the rules outlined in [Section 16.2.2](ch16.xhtml#ch16lev2sec142).
    Label the corresponding random variable as *T* and the specific value as *t*[4],
    stored as the object `t4` in R.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This has placed the value of interest, 21.5, on the standardized scale, making
    it interpretable with respect to a standard normal distribution or, as is correct
    in this setting (because you are using the estimate *s* rather than the unknown
    *σ*[*X*] in calculating the standard error), *t[4]* follows the aforementioned
    *t*-distribution with 4 degrees of freedom. The estimated probability is as follows.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that when you calculated the “true” theoretical probability from the sampling
    distribution of Pr(*X̄* < 21.5), you got a result of about 0.23 (see [page 370](ch17.xhtml#page_370)),
    but the same probability based on standardization using sample statistics of the
    data `obs` (in other words, *estimates* of the true theoretical values Pr(*T*
    < *t*[4])) has been computed as 0.27 (2 d.p.).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'The bottom image of [Figure 17-1](ch17.xhtml#ch17fig1) provides the *t*-distribution
    with *ν* = 4, marking off the probability described. The N(0,1) density is also
    plotted for comparison; this represents the standardized version of the N(22,1.5/
    ![image](../images/5.jpg)) sampling distribution from earlier, in situation 1\.
    You can produce this image with the following lines:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Consideration of probability distributions associated with sample means is clearly
    not a trivial exercise. Using sample statistics governs the nature of the sampling
    distribution; in particular, it will be *t* based if you use the sample standard
    deviation to calculate the standard error. However, as the examples here have
    shown, once that’s been established, the calculation of various probabilities
    is easy and follows the same general rules and R functionality detailed in [Section
    16.2](ch16.xhtml#ch16lev1sec51).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '***17.1.2 Distribution for a Sample Proportion***'
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Sampling distributions for sample proportions are interpreted in much the same
    way. If *n* trials of a success/failure event are performed, you can obtain an
    estimate of the proportion of successes; if another *n* trials are performed,
    the new estimate could vary. It’s this variability that you’re investigating.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: The random variable of interest, ![image](../images/p.jpg), represents the estimated
    proportions of successes over any *n* trials, each resulting in some defined binary
    outcome. It is estimated as ![image](../images/f0373-01.jpg), where *x* is the
    number of successes in a sample of size *n*. Let the corresponding true proportion
    of successes (often unknown) simply be denoted with *π*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '*Note that *π* as used in this setting doesn’t refer to the common geometric
    value 3.14 (2 d.p.). Rather, it’s simply standard notation to refer to a true
    population proportion using the *π* symbol.*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'The sampling distribution of ![image](../images/p.jpg) is approximately normal
    with mean *π* and standard error ![image](../images/f0374-01.jpg). The following
    are the key things to note:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: • This approximation is valid if *n* is large and/or *π* is not too close to
    either 0 or 1.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: • There are rules of thumb to determine this validity; one such rule is to assume
    the normal approximation is satisfactory if both *nπ* and *n*(1 − *π*) are greater
    than 5.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: • When the true *π* is unknown or is unassumed to be a certain value, it is
    typically replaced by ![image](../images/p.jpg) in all of the previous formulas.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: As long as you can deem the approximation to the normal distribution valid,
    this is the only probability distribution that you need to be concerned with.
    However, it’s worth noting that the standard error of the sampling distribution
    of a sample proportion depends directly upon the proportion *π*. This becomes
    important when constructing confidence intervals and carrying out hypothesis tests,
    which you’ll begin to explore in [Chapter 18](ch18.xhtml#ch18).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at a practical example. Suppose a political commentator in the United
    States is interested in the proportion of voting-age citizens in her home city
    that already know how they will vote in the next presidential election. She obtains
    a yes or no answer from 118 suitable randomly selected individuals. Of these individuals,
    80 say they know how they’ll vote. To investigate the variability associated with
    the proportion of interest, you’ll therefore need to consider
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e17-1.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: 'where ![image](../images/f0374-03.jpg). In R, the following gives you the estimate
    of interest:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the sample, about 68 percent of the surveyed individuals know how they will
    vote in the next election. Note also that, according to the aforementioned rule
    of thumb, the approximation to the normal distribution is valid because both values
    are greater than 5.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Estimate the standard error with the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, you can plot the corresponding sampling distribution using this code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[Figure 17-2](ch17.xhtml#ch17fig2) gives the result.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f17-02.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: '*Figure 17-2: Visualizing the sampling distribution for the voting example
    as per [Equation (17.1)](ch17.xhtml#ch17eq1). The shaded area represents* Pr(0.7
    < ![image](../images/p.jpg) < 0.75)*, which is the probability that the true sample
    proportion for samples of size* n *= 118 lies between 0.7 and 0.75.*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Now you can use this distribution to describe the variability in the sample
    proportion of voters who already know how they will vote, for other samples of
    this size.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the shaded area in [Figure 17-2](ch17.xhtml#ch17fig2) highlights
    the probability that in another sample of the same size, the sample proportion
    of voters in the given city who already know how they’re going to vote is somewhere
    between 0.7 and 0.75\. This shaded area can be added with the following code:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And with knowledge of `pnorm`, introduced in [Section 16.2.2](ch16.xhtml#ch16lev2sec142),
    you can use the following code to calculate the probability of interest:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This sampling distribution suggests that the chance of another sample proportion,
    based on the same sample size, lying somewhere between these two values is about
    25.7 percent.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 17.1**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: A teacher wants to test all of the 10th-grade students at his school to gauge
    their basic mathematical understanding, but the photocopier breaks after making
    only six copies of the test. With no other choice, he chooses six students at
    random to take the test. Their results, recorded as a score out of 65, have a
    sample mean of 41.1\. The standard deviation of the marks of this test is known
    to be 11.3.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Find the standard error associated with the mean test score.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assuming the scores themselves are normally distributed, evaluate the probability
    that the mean score lies between 45 and 55 if the teacher took another sample
    of the same size.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A student who gets less than half the questions correct receives a failing grade
    (F). Find the probability that the average score is an F based on another sample
    of the same size.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A marketing company wants to find out which of two energy drinks teenagers prefer—drink
    A or drink B. It surveys 140 teens, and the results indicate that only 35 percent
    prefer drink A.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Use a quick check to decide whether it is valid to use the normal distribution
    to represent the sampling distribution of this proportion.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the probability that in another sample of the same size, the proportion
    of teenagers who prefer drink A is greater than 0.4?
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the two values of this sampling distribution that identify the central
    80 percent of values of the proportion of interest.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In [Section 16.2.4](ch16.xhtml#ch16lev2sec144), the time between cars passing
    an individual’s location was modeled using an exponential distribution. Say that
    on the other side of town, her friend is curious about a similar problem. Standing
    outside her house, she records 63 individual times between cars passing. These
    sampled times have a mean of *x̄* = 37.8 seconds with a standard deviation of
    *s* = 34.51 seconds.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: The friend inspects a histogram of her raw measurements and notices that her
    raw data are heavily right-skewed. Briefly identify and describe the nature of
    the sampling distribution with respect to the sample mean and calculate the appropriate
    standard error.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using the standard error from (g) and the appropriate probability distribution,
    calculate the probability that in another sample of the same size, the sample
    mean time between cars passing is as follows:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: More than 40 seconds
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Less than half a minute
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Between the given sample mean and 40 seconds
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '***17.1.3 Sampling Distributions for Other Statistics***'
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: So far you’ve looked at sampling distributions in cases dealing with a single
    sample mean or sample proportion, though it’s important to note that many problems
    require more complicated measures. Nevertheless, you can apply the ideas explored
    in this section to any statistic estimated from a finite-sized sample. The key,
    always, is to be able to understand the variability associated with your point
    estimates.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: In some settings, such as those covered so far, the sampling distribution is
    parametric, meaning that the functional (mathematical) form of the probability
    distribution itself is known and depends only on the provision of specific parameter
    values. This is sometimes contingent upon the satisfaction of certain conditions,
    as you’ve seen with the application of the normal distribution covered in this
    chapter. For other statistics, it may be the case that you do not know the form
    of the appropriate sampling distribution—in these cases, you could use computer
    simulation to obtain the required probabilities.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: In the remainder of this chapter and over the next few chapters, you’ll continue
    to explore statistics that are tied to parametric sampling distributions for common
    tests and models.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '*The variability of an estimated quantity is actually only one side of the
    coin. Just as important is the issue of statistical* bias*. Where “natural variability”
    should be associated with* random error*, bias is associated with* systematic
    error*, in the sense that a biased statistic does not settle on the corresponding
    true parameter value as the sample size increases. Bias can be caused by flaws
    in a study design or collection of data or can be the result of a poor estimator
    of the statistic of interest. Bias is an undesirable trait of any given estimator
    and/or statistical analysis unless it can be quantified and removed, which is
    often difficult if not impossible in practice. I’ve therefore dealt so far only
    with unbiased statistical estimators, many of which are those you may already
    be familiar with (for example, the arithmetic mean), and I’ll continue to assume
    unbiasedness moving forward.*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '**17.2 Confidence Intervals**'
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *confidence interval (CI)* is an interval defined by a lower limit *l* and
    an upper limit *u*, used to describe possible values of a corresponding true population
    parameter in light of observed sample data. Interpretation of a confidence interval
    therefore allows you to state a “level of confidence” that a true parameter of
    interest falls between this upper and lower limit, often expressed as a percentage.
    As such, it is a common and useful tool built directly from the sampling distribution
    of the statistic of interest.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the important points to note:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: • The level of confidence is usually expressed as a percentage, such that you’d
    construct a 100 × (1 − *α*) percent confidence interval, where 0 < *α* < 1 is
    an “amount of tail probability.”
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: • The three most common intervals are defined with either *α* = 0.1 (a 90 percent
    interval), *α* = 0.05 (a 95 percent interval), or *α* = 0.01 (a 99 percent interval).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: • Colloquially, you’d state the interpretation of a confidence interval (*l*,
    *u*) as “I am 100 × (1 − *α*) percent confident that the true parameter value
    lies somewhere between *l* and *u*.”
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Confidence intervals may be constructed in different ways, depending on the
    type of statistic and therefore the shape of the corresponding sampling distribution.
    For symmetrically distributed sample statistics, like those involving means and
    proportions that will be used in this chapter, a general formula is
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/e17-2.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: where *statistic* is the sample statistic under scrutiny, *critical value* is
    a value from the standardized version of the sampling distribution that corresponds
    to *α*, and *standard error* is the standard deviation of the sampling distribution.
    The product of the critical value and standard error is referred to as the *error
    component* of the interval; subtraction of the error component from the value
    of the statistic provides *l*, and addition provides *u*.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: With reference to the appropriate sampling distribution, all that a CI yields
    are the two values of the distribution that mark off the central 100 × (1 − *α*)
    percent of the area under the density. (This is the process that was briefly mentioned
    in [Exercise 17.1](ch17.xhtml#ch17exc1) (f).) You then use the CI to make further
    interpretations concerning the true (typically unknown) parameter value that’s
    being estimated by the statistic of interest.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '***17.2.1 An Interval for a Mean***'
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You know from [Section 17.1.1](ch17.xhtml#ch17lev2sec146) that the sampling
    distribution of a single sample mean depends primarily on whether you know the
    true standard deviation of the raw measurements, *σ*[*X*]. Then, provided the
    sample size for this sample mean is roughly *n* ≥ 30, the CLT ensures a symmetric
    sampling distribution—which will be normal if you know the true value of *σ*[*X*],
    or *t* based with *ν* = *n* − 1 df if you must use the sample standard deviation,
    *s*, to estimate *σ*[*X*] (as is more common in practice). You’ve seen that the
    standard error is defined as the standard deviation divided by the square root
    of *n*. For a small *n*, you must also assume that the raw observations are normally
    distributed, since the CLT will not apply.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: To construct an appropriate interval, you must first find the critical value
    corresponding to *α*. By definition the CI is symmetric, so this translates to
    a central probability of (1 − *α*) around the mean, which is exactly *α*/2 in
    the lower tail and the same in the upper tail.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'Return to the example from [Section 17.1.1](ch17.xhtml#ch17lev2sec146), dealing
    with the mean daily maximum temperatures (degrees Celsius) in January for Dunedin,
    New Zealand. Suppose you know the observations are normally distributed but you
    don’t know the true mean *μ*[*X*] (which is set at 22) or the true standard deviation
    *σ*[*X*] (which is set at 1.5). Setting it up in the same way as earlier, assume
    you’ve made the following five independent observations:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you’re interested in the sample mean and its sampling distribution, you must
    calculate the sample mean *x̄*, the sample standard deviation *s*, and the appropriate
    standard error of the sample mean, ![image](../images/f0379-01.jpg).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now, let’s say the aim is to construct a 95 percent confidence interval for
    the true, unknown mean *μ*[*X*]. This implies *α* = 0.05 (the total amount of
    tail probability) for the relevant sampling distribution. Given the fact that
    you know the raw observations are normal and that you’re using *s* (not *σ*[*X*]),
    the appropriate distribution is the *t*-distribution with *n* − 1 = 4 degrees
    of freedom. For a central area of 0.95 under this curve, *α*/2 = 0.025 must be
    in either tail. Knowing that R’s `q` functions operate based on a total lower
    tail area, the (positive) critical value is therefore found by supplying a probability
    of 1 − *α*/2 = 0.975 to the appropriate function.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[Figure 17-3](ch17.xhtml#ch17fig3) shows why the `qt` function is used in this
    way (since I used similar code throughout [Chapter 16](ch16.xhtml#ch16), I haven’t
    reproduced the code for [Figure 17-3](ch17.xhtml#ch17fig3) here).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/f17-03.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: '*Figure 17-3: Illustrating the role of the critical value in a confidence interval
    for a sample mean, using the Dunedin temperature example. The sampling distribution
    is* t *with 4 df, and the use of* `qt` *with respect to symmetric tail probabilities
    related to* *α/2 = 0.025 yields a central area of 0.95.*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Note that when viewed with respect to the negative version of the same critical
    value (“reflected” around the mean and obtained by using `qt(0.025,4)`), the central,
    symmetric area under the curve must be 0.95\. You can confirm this using `pt`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'So, all the ingredients are present. You find the 95 percent confidence interval
    for the true mean *μ*[*X*] via [Equation (17.2)](ch17.xhtml#ch17eq2) with the
    following lines, which give *l* and *u*, respectively:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The CI given by (19.37,23.99) is therefore interpreted as follows: you are
    95 percent confident that the true mean maximum temperature in Dunedin in January
    lies somewhere between 19.37 and 23.99 degrees Celsius.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: With this result, you’ve combined knowledge of the estimate of the mean itself
    with the inherent variability of a sample to define an interval of values in which
    you’re fairly sure the true mean will lie. As you know, the true mean in this
    case is 22, which is indeed included in the calculated CI.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'From this, it’s easy to alter the intervals to change the confidence levels.
    You need to change only the critical value, which, as always, must define *α*/2
    in each tail. For example, an 80 percent CI (*α* = 0.2) and a 99 percent CI (*α*
    = 0.01) for the same example value given here can be found with these two lines,
    respectively:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note here the use of multiplication by the vector `c(-1,1)` so that the lower
    and upper limits can be obtained at once and the result returned as a vector of
    length 2\. As usual, the `qt` function is used with respect to a complete lower-tail
    area, so `p` is set at 1 − *α*/2.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: These most recent intervals highlight the natural consequence of moving to a
    higher confidence level for a given CI. A higher probability in the central area
    translates directly to a more extreme critical value, resulting in a wider interval.
    This makes sense—in order to be “more confident” about the true parameter value,
    you’d need to take into account a larger range of possible values.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '***17.2.2 An Interval for a Proportion***'
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Establishing a CI for a sample proportion follows the same rules as for the
    mean. With knowledge of the sampling distribution as per [Section 17.1.2](ch17.xhtml#ch17lev2sec147),
    you obtain critical values from the standard normal distribution, and for an estimate
    of ![image](../images/p.jpg) from a sample of size *n*, the interval itself is
    constructed with the standard error ![image](../images/f0381-01.jpg).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s return to the example from [Section 17.1.2](ch17.xhtml#ch17lev2sec147),
    where 80 of 118 surveyed individuals said that they knew how they were going to
    vote in the next US presidential election. Recall you have the following:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To construct a 90 percent CI (*α* = 0.1), the appropriate critical value from
    the standardized sampling distribution of interest is as follows, implying Pr(−1.644854
    < *Z* < 1.644854) = 0.9 for *Z* ∼ N(0,1):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now you again follow [Equation (17.2)](ch17.xhtml#ch17eq2):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: You can conclude that you’re 90 percent confident that the true proportion of
    voters who know how they will vote in the next election lies somewhere between
    0.61 and 0.75 (rounded to two decimal places).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '***17.2.3 Other Intervals***'
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The two simple situations presented in [Sections 17.2.1](ch17.xhtml#ch17lev2sec149)
    and [17.2.2](ch17.xhtml#ch17lev2sec150) serve to highlight the importance of associating
    any point estimate (in other words, a sample statistic) with the idea of its variability.
    Confidence intervals can of course be constructed for other quantities, and over
    the following sections (as part of testing hypotheses), I’ll expand on the discussion
    of confidence intervals to investigate differences between two means and two proportions,
    as well as ratios of categorical counts. These more complicated statistics come
    with their own standard error formulas, though the corresponding sampling distributions
    are still symmetric via the normal and *t*-curves (if, again, some standard assumptions
    are met), which means that the now familiar formulation of [Equation (17.2)](ch17.xhtml#ch17eq2)
    still applies.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Generally, a confidence interval seeks to mark off a central area of 1 − *α*
    from the sampling distribution of interest, including sampling distributions that
    are asymmetric. In those cases, however, it doesn’t make much sense to have a
    symmetric CI based on a single, standardized critical value as per [Equation (17.2)](ch17.xhtml#ch17eq2).
    Similarly, you might not know the functional, parametric form of the sampling
    distribution and so may not be willing to make any distributional assumptions,
    such as symmetry. In these cases, you can take an alternative path based on the
    raw quantiles (or estimated raw quantiles; see [Section 13.2.3](ch13.xhtml#ch13lev2sec118))
    of the supposed asymmetric sampling distribution. Using specific quantile values
    to mark off identical *α*/2 upper- and lower-tail areas is a valid method that
    remains sensitive to the shape of the sampling distribution of interest, while
    still allowing you to construct a useful interval that describes potential true
    parameter values.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '***17.2.4 Comments on Interpretation of a CI***'
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The typical statement about the interpretation of any CI references a degree
    of confidence in where the true parameter value lies, but a more formally correct
    interpretation should consider and clarify the probabilistic nature of the construction.
    Technically, given a 100(1 − *α*) percent confidence level, the more accurate
    interpretation is as follows: over many samples of the same size and from the
    same population where a CI, of the same confidence level, is constructed with
    respect to the same statistic from each sample, you would expect the true corresponding
    parameter value to fall within the limits of 100(1 − *α*) percent of those intervals.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: This comes from the fact that the theory of a sampling distribution describes
    the variability in multiple samples, not just the sample that has been taken.
    At first glance it may be difficult to fully appreciate the difference between
    this and the colloquially used “confidence statement,” but it is important to
    remain aware of the technically correct definition, particularly given that a
    CI is typically estimated based on only one sample.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '**Exercise 17.2**'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: A casual runner records the average time it takes him to sprint 100 meters.
    He completes the dash 34 times under identical conditions and finds that the mean
    of these is 14.22 seconds. Assume that he knows the standard deviation of his
    runs is *σ*[*X*] = 2.9 seconds.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Construct and interpret a 90 percent confidence interval for the true mean time.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat (a), but this time, assume that the standard deviation is not known and
    that *s* = 2.9 is estimated from the sample. How, if at all, does this change
    the interval?
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a particular country, the true proportion of citizens who are left handed
    or ambidextrous is unknown. A random sample of 400 people is taken, and each individual
    is asked to identify with one of three options: right-handed only, left-handed
    only, or ambidextrous. The results show that 37 selected left-handed and 11 selected
    ambidextrous.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Calculate and interpret a 99 percent CI for the true proportion of left-handed-only
    citizens.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate and interpret a 99 percent CI for the true proportion of citizens
    who are either left-handed *or* ambidextrous.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In [Section 17.2.4](ch17.xhtml#ch17lev2sec152), the technical interpretation
    of a CI with respect to its confidence level was described as the proportion of
    many similar intervals (that is, when calculated for samples of the same size
    from the same population) that contain the true value of the parameter of interest.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'Your task is to write an example to demonstrate this behavior of confidence
    intervals using simulation. To do so, follow these instructions:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: – Set up a matrix (see [Chapter 3](ch03.xhtml#ch03)) filled with `NA`s ([Chapter
    6](ch06.xhtml#ch06)) that has 5,000 rows and 3 columns.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: – Use skills from [Chapter 10](ch10.xhtml#ch10) to write a `for` loop that,
    at each of 5,000 iterations, generates a random sample of size 300 from an exponential
    distribution with rate parameter *λ[e]* = 0.1 ([Section 16.2.4](ch16.xhtml#ch16lev2sec144)).
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: – Evaluate the sample mean and sample standard deviation of each sample, and
    use these quantities with the critical values from the appropriate sampling distribution
    to calculate a 95 percent CI for the true mean of the distribution.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: – Within the `for` loop, the matrix should now be filled, row by row, with your
    results. The first column will contain the lower limit, the second will contain
    the upper limit, and the third column will be a logical value that is `TRUE` if
    the corresponding interval contains the true mean of 1/*λ*[e] and that is `FALSE`
    otherwise.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: – When the loop is completed, compute the proportion of `TRUEs` in the third
    column of the filled matrix. You should find that this proportion is close to
    0.95; this will vary randomly each time you rerun the loop.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a plot that draws the first 100 of your estimated confidence intervals
    as separate horizontal lines drawn from *l* to *u*, one on top of another. One
    way to do this is to first create an empty plot with preset *x*- and *y*-limits
    (the latter as `c(1,100)`) and then progressively add each line using `lines`
    with appropriate coordinates (this could be done using another `for` loop). As
    a final touch, add to the plot a red vertical line that denotes the true mean.
    Confidence intervals that do not include the true mean will not intersect that
    vertical line.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following shows an example of this plot:'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![image](../images/f0384-01.jpg)'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_IMG
