<html><head></head><body>
<div id="sbo-rt-content"><h2 class="h2" id="ch04"><span epub:type="pagebreak" id="page_69"/><strong><span class="big">4</span><br/>CRYPTOGRAPHIC IMPLEMENTATIONS</strong></h2>
<div class="image1"><img alt="Image" height="252" src="../images/common.jpg" width="252"/></div>
<p class="noindent">In <a href="ch02.xhtml#ch02">Chapter 2</a>, I gave an overview of cryptographic algorithms, their parameters, and typical use cases. However, a mathematical algorithm is still a long way from the secure and efficient <em>implementations</em> of cryptography.</p>
<p class="indent">In the majority of applications, cryptography doesn’t play a leading role. It’s more like a necessary evil to protect device and business assets. Therefore, developers and product managers would love to have cryptographic implementations that run in no time, occupy no memory, and consume no energy. Of course, that’s not possible, but it’s a significant discussion point in many cases. Inefficient implementations might even lead to the elimination of security features, lower product quality, or at the very least, annoyed comments from colleagues who aren’t focused on security.</p>
<p class="indent">In this chapter, I’ll discuss the requirements for cryptographic implementations and selection options for developers. The following sections introduce examples of algorithmic optimizations for symmetric and asymmetric crypto. The final case study analyzes and discusses performance characteristics of crypto implementations in hardware and software on an STM32MP157F device.</p>
<h3 class="h3" id="ch00lev1_35"><span epub:type="pagebreak" id="page_70"/><strong>Implementation Context and Requirements</strong></h3>
<p class="noindent">Developers choose the central microchip early in the product design and architecture development phases because many further decisions depend on it. The microchip might be a single-core microcontroller, a homogeneous or heterogeneous multicore system, a field-programmable gate array (FPGA), or even a system-on-chip (SoC) that combines processors, peripherals, and possibly FPGAs within a single package.</p>
<p class="indent">If a typical processor is selected, several parameters influence general performance, including crypto performance. These parameters start with the <em>instruction set architecture</em>, or <em>ISA</em> (for example, ARM, RISC-V, or MIPS), and the data width (8-bit, 16-bit, 32-bit, 64-bit, or even more). The number of cores and their maximum frequencies are also of significant relevance. Specifically for cryptographic operations, it’s interesting to see whether dedicated crypto instructions are available, like Intel’s AES New Instructions (AES-NI) extension, or whether the given chip comes with a crypto coprocessor.</p>
<p class="indent">In systems intended for industrial, automotive, or datacenter applications, considering microchips that include an FPGA part might be interesting as a way of benefitting from the high-performance properties or the real-time guarantees digital hardware designs can provide. Besides the maximum supported frequency, FPGAs have specific characteristics like the number of lookup tables, flip-flops, blocks of random access memory (RAM), multipliers, and similar options that might set the limits for cryptographic implementations.</p>
<p class="indent">No matter which type of processing unit you choose, it requires internal and/or external memory. Usually, both volatile memory like RAM and nonvolatile memory like flash memory, memory cards, or solid-state drives (SSDs) are necessary. Besides their size, which affects cryptographic implementations on only very resource-constrained devices, their read and write speeds might influence the overall performance of a crypto application.</p>
<p class="indent">Last but not least, the transmission speed of wired and wireless interfaces of the device (for example, Wi-Fi, Bluetooth, Ethernet, and proprietary buses) limits the bandwidth for communication, including cryptographically protected channels.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Sometimes in practice, the device and hardware architecture is already more or less fixed when cryptographic performance is discussed, and you have to make the best of it. However, don’t shy away from contributing crypto performance requirements at an early stage. For example, if your intended application requires thousands of signatures per second, that requirement definitely must be considered for hardware selection.</em></p>
</div>
<p class="indent">Looking at this problem from the application side, you might impose several types of requirements on crypto implementations. While <em>latency</em> describes the time of processing a single data block from input to output, <em>throughput</em> defines the amount of data that can be processed in a given time.</p>
<p class="indent"><span epub:type="pagebreak" id="page_71"/>For software implementations on resource-constrained devices, it might be necessary to limit the static code size of the compiled binary that has to be stored in volatile and/or nonvolatile memory. Further, the dynamic memory usage during runtime can be a relevant factor. On the other hand, FPGA implementations have to statically instantiate digital components, which is why, in addition to performance, the efficiency of digital hardware designs for crypto are usually compared by the number of occupied FPGA resources.</p>
<p class="indent">As several IoT devices are battery-powered and some even rely on energy harvesting, the energy consumption of cryptographic implementations also can be a valid requirement.</p>
<p class="indent">All information about the implementation context of a device is relevant for solid and efficient crypto decisions. And in some cases, finding reasonable compromises between resource consumption and security might be necessary.</p>
<h3 class="h3" id="ch00lev1_36"><strong>Selecting Crypto Implementations</strong></h3>
<p class="noindent">We’ve seen many implementation issues over the past decades that have led to vulnerabilities. If you don’t want to have such valuable but exhausting experiences yourself, take a look at existing optimized and mature cryptographic libraries like OpenSSL, LibreTLS, Mbed TLS, and wolfSSL, just to name a few from the embedded system area.</p>
<p class="indentb">However, this issue leads us to a question many developers face during development: How do you choose a specific crypto library for a device or an application? The decision depends to a large extent on your specific requirements, if already explicitly stated, and the frameworks and programming languages you work with. The following list describes four typical situations:</p>
<p class="hanga"><strong>Freedom to choose</strong>    Sometimes only the intended protection aim is stipulated—for example, that communication should be protected by authenticated encryption, without further details. This might be the case for a company-internal feature that has no external dependencies. In such situations, several cryptographic algorithms could be considered. For example, both AES-GCM and ChaCha20-Poly1305 might be suitable options. Performance evaluation on the target device makes sense in this scenario. Test both algorithms with a set of parameters and various crypto libraries to obtain a preferably efficient solution.</p>
<p class="hanga"><strong>Strong performance requirements</strong>    In some cases, cryptography is essential and has to fulfill high demands regarding performance—for example, if an application requires thousands of digital signatures per second. Since ECDSA is faster in signature generation than RSA, the algorithm should probably be ECC based. However, you still have to choose the type of curve. Testing a set of curves from available crypto libraries on the given hardware is the way to go when choosing the best-performing configuration. If your requirements can’t be reached, <span epub:type="pagebreak" id="page_72"/>replacing the hardware or implementing a custom, optimized solution might be options.</p>
<p class="hanga"><strong>Strong resource constraints</strong>    Devices based on small microcontrollers are present in a large part of the IoT. However, those components usually exhibit significantly weaker performance characteristics compared to Linux-based devices. Although much state-of-the-art cryptography can be run on these processors, requirements regarding latency, throughput, number of connections to serve, and many more have to be selected carefully. Practical evaluations on the target hardware are essential.</p>
<p class="hanga"><strong>Fixed algorithm and security level</strong>    If algorithm and key size are fixed in advance (for example, because of compatibility concerns), the scope is significantly reduced. However, if the specific implementation is not fixed, a quick performance comparison between libraries might still be valuable and unlock performance potential.</p>
<p class="indenttb">Even though this chapter has a strong focus on performance, latency and throughput are by far not the only quality characteristics to consider for cryptographic implementations. Especially for security applications, the following two properties can make a significant difference, even if they result in lower performance:</p>
<p class="hanga"><strong>Transparency and clarity</strong>    Readable, comprehensible, and documented code is wonderful. It reduces mistakes, assumptions, and misconceptions. Further, those properties lead to trustworthiness for the developers and their products. That is even truer for cryptographic implementations. Spaghetti code, optimization to the utmost degree that makes the code completely incomprehensible, and torn structures can be reasons to neglect implementations despite their outstanding performance.</p>
<p class="hanga"><strong>Support and maintenance</strong>    Open source software has enabled the development of incredible projects. However, some projects are not well-documented nor supported. If vulnerabilities are found and reported, there might not be anyone to fix them right away. Of course, the same can be true for commercial and closed source software. The point is, you need to pay attention to how a specific library was maintained in the past and to any warning signs that might indicate loss of maintenance in the near future, especially for cryptographic libraries.</p>
<div class="note">
<p class="notet"><strong><span class="notes">WARNING</span></strong></p>
<p class="notep"><em>Do not develop your own crypto implementations unless you have very good reasons to do so!</em></p>
</div>
<p class="indent">Whatever crypto algorithm you select, issues might arise someday in the future because of quantum computing or new cryptanalytic successes. Therefore, it makes sense to follow the approach of <em>crypto agility</em>, which means that algorithms (for example, a block cipher) can easily be replaced by another one of the same type.</p>
<h3 class="h3" id="ch00lev1_37"><span epub:type="pagebreak" id="page_73"/><strong>AES Implementation Options</strong></h3>
<p class="noindent">In this section, I want to shed light on options to consider if you have to configure or analyze an AES implementation. AES is used as an example here, but since many other symmetric ciphers and hash functions also exhibit a round-based structure and similar operations, you might be able to translate these insights to other algorithms.</p>
<h4 class="h4" id="ch00lev2_44"><strong><em>Basic Architecture</em></strong></h4>
<p class="noindent">A fundamental consideration is the operation width of processed data. In optimal software implementations, the width is chosen to utilize the data width of the underlying hardware. However, a mismatch can lead to issues. For instance, 8-bit implementations on 32-bit central processing units (CPUs) lack performance, and 32-bit implementations on 8-bit CPUs might not compile or lead to inefficient transformations.</p>
<p class="indent">In FPGA implementations, the operation width of an implementation can be arbitrarily selected. If slower performance is acceptable and the focus is on using few resources, an 8-bit implementation is suitable. On the other hand, if high performance is required, we would probably like to operate at a 128-bit data width. If a <em>balanced</em> implementation (one with a reasonable trade-off between required resources and performance) is desired, a 32-bit architecture can be a solid choice.</p>
<p class="indent">AES needs to expand a given key to a set of round keys. This key expansion can be performed once in the beginning to improve performance during bulk data encryption and decryption. However, the second option is to perform it on the fly, just before the corresponding round key is needed for operations. Advantages in dynamic memory consumption are gained because only a single round key has to be stored in memory instead of all round keys.</p>
<p class="indent">For round-based algorithms like AES, implementing a loop structure to run through the necessary rounds seems natural. However, continuously handling and checking a loop variable reduces the maximum performance. Even if a comparison and a conditional branch don’t take seconds, they will impair overall throughput. The term <em>loop unrolling</em> describes an approach you might find in high-speed implementations: a loop is replaced by a sequence of code representing all AES rounds in order to achieve a performance boost at the expense of a larger binary size.</p>
<h4 class="h4" id="ch00lev2_45"><strong><em>Optimized Operations</em></strong></h4>
<p class="noindent">The AES S-box is usually represented as a table that is meant to perform a nonlinear substitution. Therefore, it’s often implemented as a constant lookup table in software implementations. However, it isn’t the only option. If static tables don’t fit your requirements, you could generate the substitution tables dynamically in RAM. Also, for digital hardware designs, a Boolean circuit implementation known as a <em>Canright S-box</em> can be used.</p>
<p class="indent"><span epub:type="pagebreak" id="page_74"/>One of the most popular approaches to implementing AES in an optimized way combines the round operations <code>SubBytes()</code>, <code>ShiftRows()</code>, and <code>MixColumns()</code> to obtain a highly efficient sequence of four table lookups and four XOR operations per column per round, sometimes also known as the <em>T-tables</em> implementation. It requires four tables containing 256 4-byte words that add up to a memory requirement of 4KB for encryption and decryption, respectively. Further optimizations can lower the required table memory to 1KB at the cost of three additional rotation operations per column per round.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Keeping these basic options in mind can help you estimate performance characteristics of given implementations, but it might also allow you to derive the implementation details of a given device when looking at its performance data.</em></p>
</div>
<p class="indent">Clearly, platforms offering dedicated instructions for AES acceleration or specific crypto coprocessors enable further performance optimizations. Some crypto libraries are already prepared to support these optimizations—for example, the popular AES-NI instructions. However, on embedded systems, it’s not unusual that you have to expend effort to utilize hardware acceleration in your application.</p>
<p class="indent">While performance gains are certainly the most common motivation for hardware crypto usage, in some cases it might also improve power consumption of your device or at least take some load off the main CPU.</p>
<h3 class="h3" id="ch00lev1_38"><strong>Implementation Characteristics of RSA and ECDSA</strong></h3>
<p class="noindent">Implementations of asymmetric cryptography like RSA and ECDSA are different from those of symmetric cryptography. The asymmetric options don’t exhibit a round structure filled with a set of transformations, but instead build on mathematical problems that require arithmetic operations on large numbers. Therefore, real-world performance of these algorithms depends to a certain extent on the efficiency of <em>multiple-precision arithmetic</em>, also known as <em>bignum arithmetic</em>.</p>
<p class="indent">The first obstacle these libraries have to overcome is the simple fact that typical processors support 32-bit and 64-bit data operations, but RSA, for example, is based on integers with lengths of 2,048, 4,096, or even more bits. This problem can be solved by splitting those long numbers into an array of <em>limbs</em>, usually equal to the maximum data width of the CPU.</p>
<h4 class="h4" id="ch00lev2_46"><strong><em>RSA Optimizations</em></strong></h4>
<p class="noindent">While general bignum libraries support a comprehensive set of arithmetic operations on large numbers, cryptographic algorithms usually require only a small subset. As shown in <a href="ch02.xhtml#ch02">Chapter 2</a>, the main operation of RSA is the modular exponentiation—for example, for encryption and signature verification: <em>y</em> = <em>x<sup>e</sup></em>mod <em>n</em>. With a naive approach, performing this calculation on integers with thousands of bits wouldn’t be possible. Using the square-and-multiply algorithm enables this computation in the first place.</p>
<p class="indent"><span epub:type="pagebreak" id="page_75"/>RSA has two cases to consider that have very different properties. First, the verification and encryption operations use the public exponent <em>e</em> = 65537 = (10000000000000001)<sub>2</sub>, which leads to pretty high performance. The reason for this is that its length of 17 bits with a leading and a trailing 1 in binary representation leads to only 16 squarings and a single multiplication operation based on the square-and-multiply algorithm. As you’ll see later in this chapter, this not only is drastically faster than the decryption and signing functions, which have to handle integers with the full key length of RSA, but also beats ECDSA verification speed.</p>
<p class="indent">RSA’s private-key operation can’t be optimized in the same way, but an approach called the <em>Chinese remainder theorem (CRT)</em> reduces runtime roughly by a factor of 4. This is possible because CRT exploits that <em>n</em> = <em>pq</em>, which allows it to obtain the result of the exponentiation modulo <em>n</em> from two exponentiations, modulo <em>p</em> and modulo <em>q</em>, respectively. This leads to computational savings because <em>p</em> and <em>q</em> are only roughly half the size of <em>n</em>.</p>
<p class="indent">An important aspect of the square-and-multiply algorithm for RSA performance is that its complexity has a cubic dependency on the bit lengths of the processed exponents. You can feel the painful effect of this relation when you migrate from 2,048-bit RSA to a more future-proof 4,096-bit RSA, because the doubling in key length leads to a runtime increase by a factor of around 2<sup>3</sup> = 8, which might just vaporize all your runtime requirements.</p>
<h4 class="h4" id="ch00lev2_47"><strong><em>ECDSA Specifics</em></strong></h4>
<p class="noindent">Since ECDSA operates on elliptic curves that process significantly smaller numbers, the private-key operations are substantially faster than their RSA counterparts. However, different types of curves facilitate different implementations and optimizations. Although the choice of a suitable curve involves mathematical and trust considerations, performance should not be completely ignored in this process because considerable differences exist across all options.</p>
<p class="indent">FPGA implementations and internal hardware to support asymmetric cryptography are much less common than for symmetric cryptography. You can find them in dedicated security ICs that, for example, provide authentication by digital signatures, as well as in SoC devices that support digital signature verification to protect their boot process. However, you usually won’t know a lot of details about these implementations, and you won’t have arbitrary access to their interfaces.</p>
<h3 class="h3" id="ch00lev1_39"><strong>Case Study: Crypto Performance on an STM32MP157F Device</strong></h3>
<p class="noindent">In this case study, I explore the performance of a diverse set of symmetric and asymmetric cryptographic algorithms on an STM32MP157F device and discuss what you can learn from the results. Measuring performance with high accuracy is difficult for complex embedded systems that have feature-rich OSs. Therefore, all results should be regarded as ballpark figures.</p>
<p class="indent"><span epub:type="pagebreak" id="page_76"/>The SoC at hand is based on an ARM Cortex-A7 dual core running at up to 800 MHz. It comes with two types of cryptographic coprocessors. The <em>CRYP1</em> core offers DES, Triple DES, and AES in different operation modes. The hashing module <em>HASH1</em> provides acceleration of SHA-1, MD5, SHA-224, SHA-256, and corresponding HMAC operations. Both run at approximately 266 MHz.</p>
<p class="indent">In the following test cases, the OpenSSL command line tool is used to assess performance because it’s often available on Linux systems and its software implementations are already highly optimized and suitable for our task.</p>
<p class="indent">The call <code>openssl speed -elapsed -evp</code> <span class="codeitalic">algorithm-to-test</span> is always used to run the tests. The <code>-elapsed</code> option defines that throughput is calculated on the basis of elapsed wall-clock time instead of CPU time spent in user space. The latter would distort the results, especially when using hardware support. The <code>-evp</code> flag stands for <em>envelope</em> and enables a generic high-level crypto interface that can use software as well as hardware implementations, depending on availability.</p>
<p class="indent">The resulting console output always includes the compilation parameters as shown in <a href="ch04.xhtml#ch04list01">Listing 4-1</a> and a list of test results in bytes per second for the following set of input data sizes: 16 bytes, 64 bytes, 256 bytes, 1,024 bytes, 8,192 bytes, and 16,384 bytes.</p>
<pre class="pre">version: 3.0.5&#13;
...&#13;
options: bn(64,32)&#13;
compiler: arm-ostl-linux-gnueabi-gcc  -mthumb -mfpu=neon-vfpv4&#13;
-mfloat-abi=hard -mcpu=cortex-a7 --sysroot=recipe-sysroot -O2 -pipe -g&#13;
-feliminate-unused-debug-types ...&#13;
-DOPENSSL_USE_NODELETE -DOPENSSL_PIC -DOPENSSL_BUILDING_OPENSSL -DNDEBUG&#13;
CPUINFO: OPENSSL_armcap=0x3</pre>
<p class="list-title" id="ch04list01"><em>Listing 4-1: The compiler parameters and metadata of the given OpenSSL tool</em></p>
<p class="indent">For clarity and comprehensibility, the terminal outputs of all the tests are reduced to the main relevant numbers.</p>
<h4 class="h4" id="ch00lev2_48"><strong><em>Parameter Choice for Symmetric Encryption</em></strong></h4>
<p class="noindent">Let’s consider a use case that requires confidentiality protection for sensor values that should be encrypted in chunks of 50KB. Say that your team members already selected AES as the block cipher, but the key size and the operation mode have not been fixed yet.</p>
<p class="indent">The first analysis compares the performance of AES in CTR mode with keys of 128, 192, and 256 bits in order to get a feel for the numbers. <a href="ch04.xhtml#ch04list02">Listing 4-2</a> shows the results obtained on an STM32MP157F device: the top line shows the size of the input data chunks, and the second line shows the throughput in kilobytes per second associated with that specific input data size.</p>
<pre class="pre"><span epub:type="pagebreak" id="page_77"/># <span class="codestrong1">openssl speed -elapsed -evp aes-128-ctr</span>&#13;
...&#13;
type             16 bytes     64 bytes    ...   8192 bytes  16384 bytes&#13;
AES-128-CTR      15102.09k    19198.53k   ...     22915.75k    22943.06k&#13;
# <span class="codestrong1">openssl speed -elapsed -evp aes-192-ctr</span>&#13;
...&#13;
type             16 bytes     64 bytes    ...   8192 bytes  16384 bytes&#13;
AES-192-CTR      13517.07k    16734.31k   ...     19327.66k    19360.43k&#13;
# <span class="codestrong1">openssl speed -elapsed -evp aes-256-ctr</span>&#13;
...&#13;
type             16 bytes     64 bytes    ...   8192 bytes  16384 bytes&#13;
AES-256-CTR      12158.66k    14689.77k   ...     16711.68k    16728.06k</pre>
<p class="list-title" id="ch04list02"><em>Listing 4-2: The performance differences depending on the AES key size</em></p>
<p class="indent">The first general point you might notice is that throughput increases if the input data size rises. This is due to necessary overhead that loses relevance for larger input data.</p>
<p class="indent">For our example, the last column is the one of interest because we want to handle input data of around 50KB. There, we can see that AES-128-CTR achieves roughly 22.9MBps, while AES-256-CTR reaches only 16.7MBps. This is a performance reduction of approximately 27 percent, or a processing-time increase of approximately 37 percent. This makes absolute sense because AES-128 has to compute only 10 rounds, while AES-256 needs 14 rounds, and therefore 40 percent more. However, considering this relation in terms of security level, we gain 128 bits of security while investing approximately only 37 percent more performance. The upgrade could be worth it.</p>
<p class="indent">The second interesting point is the operation mode’s influence on the performance. While CTR, CBC, and GCM mode differ in security, they also exhibit different performance characteristics. In <a href="ch04.xhtml#ch04list03">Listing 4-3</a>, you can see that CTR mode shows a performance of approximately 8 percent above CBC mode for larger input sizes, which might be a reason to choose CTR over CBC in many cases.</p>
<pre class="pre"># <span class="codestrong1">openssl speed -elapsed -evp aes-256-ctr</span>&#13;
...&#13;
type             16 bytes     64 bytes    ...   8192 bytes  16384 bytes&#13;
AES-256-CTR      12157.72k    14690.37k   ...     16708.95k    16722.60k&#13;
# <span class="codestrong1">openssl speed -elapsed -evp aes-256-cbc</span>&#13;
...&#13;
type             16 bytes     64 bytes    ...   8192 bytes  16384 bytes&#13;
AES-256-CBC      11962.59k    14429.91k   ...     15515.65k    15515.65k&#13;
# <span class="codestrong1">openssl speed -elapsed -evp aes-256-gcm</span>&#13;
...&#13;
type             16 bytes     64 bytes    ...   8192 bytes  16384 bytes&#13;
AES-256-GCM       9052.80k    10844.44k   ...     12126.89k    12113.24k</pre>
<p class="list-title" id="ch04list03"><em>Listing 4-3: The impact of the AES operation mode on encryption throughput</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_78"/>GCM provides authenticated encryption, which means that it yields not only ciphertext but also an authentication tag for integrity protection. The processing efforts for the latter lead to a performance decrease of approximately 28 percent. However, if you have to add a MAC generation algorithm to AES-CTR (for example, an HMAC-SHA-256), this would likely cost you more than 28 percent.</p>
<p class="indent">If security has a higher priority than throughput, going with AES-256-GCM would still result in a reasonable performance of 12.1MBps. However, if performance is your key feature, you can achieve the minimal security requirement of confidentiality protection with AES-128-CTR at almost twice the speed—namely, 22.9MBps.</p>
<p class="indent">At this point, you might remember that software implementations of the ChaCha stream cipher often outperform those of AES. And since you are probably the type of person who wants to bring your product to perfection, you should check whether the software at hand supports this algorithm, as shown in <a href="ch04.xhtml#ch04list04">Listing 4-4</a>.</p>
<pre class="pre"># <span class="codestrong1">openssl list -cipher-algorithms | grep -i chacha</span>&#13;
  ChaCha20&#13;
  ChaCha20-Poly1305&#13;
  ChaCha20 @ default&#13;
  ChaCha20-Poly1305 @ default</pre>
<p class="list-title" id="ch04list04"><em>Listing 4-4: The availability of the ChaCha cipher in the given OpenSSL tool</em></p>
<p class="indent">Running speed tests on ChaCha20 and ChaCha20-Poly1305 yields the results shown in <a href="ch04.xhtml#ch04list05">Listing 4-5</a>.</p>
<pre class="pre"># <span class="codestrong1">openssl speed -elapsed -evp ChaCha20</span>&#13;
...&#13;
type             16 bytes     64 bytes    ...   8192 bytes  16384 bytes&#13;
ChaCha20         21168.64k    36814.83k   ...     57442.30k    57507.84k&#13;
# <span class="codestrong1">openssl speed -elapsed -evp ChaCha20-Poly1305</span>&#13;
...&#13;
type                 16 bytes     64 bytes    ...   8192 bytes  16384 bytes&#13;
ChaCha20-Poly1305    16054.38k    28477.87k   ...     47390.72k    47300.61k</pre>
<p class="list-title" id="ch04list05"><em>Listing 4-5: The performance tests for the ChaCha20 and ChaCha20-Poly1305 ciphers</em></p>
<p class="indent">If your team is willing to switch from AES to ChaCha20, it can get 256-bit security and authenticated encryption at data rates of 47.3MBps or more. Therefore, ChaCha20 might be worth a second thought.</p>
<h4 class="h4" id="ch00lev2_49"><strong><em>Software vs. Hardware Implementation for SHA-256 Hashing</em></strong></h4>
<p class="noindent">Imagine that your device generates logfiles split at 100MB and that you want to sign those files for integrity and authenticity protection before they leave the device. Since the input data size is relatively high, the performance of the signing operation is mainly determined by the hashing step and not the <span epub:type="pagebreak" id="page_79"/>asymmetric signing at the end. Therefore, comparing the software implementation of SHA-256 and the accelerator that comes with the <em>HASH1</em> hardware module of the STM32MP157F device might be worthwhile.</p>
<p class="indent"><a href="ch04.xhtml#ch04list06">Listing 4-6</a> shows all hash functions supported by hardware and available through their corresponding drivers.</p>
<pre class="pre"># <span class="codestrong1">cat /proc/crypto | grep stm32-sha*</span>&#13;
driver       : stm32-sha256&#13;
driver       : stm32-sha224&#13;
driver       : stm32-sha1</pre>
<p class="list-title" id="ch04list06"><em>Listing 4-6: The SHA algorithms supported by the STM32MP157F hardware</em></p>
<p class="indent">The hardware acceleration can be made available to the OpenSSL command line tool, by loading the <code>cryptodev</code> kernel module and then adding <code>-engine devcrypto</code> to the speed test parameters. <a href="ch04.xhtml#ch04list07">Listing 4-7</a> shows the basic comparison between OpenSSL’s software implementation of SHA-256 and the hardware-supported operation.</p>
<pre class="pre"># <span class="codestrong1">openssl speed -elapsed -evp sha-256</span>&#13;
...&#13;
type             16 bytes     ...   1024 bytes   8192 bytes  16384 bytes&#13;
sha-256           2868.42k    ...     24365.74k    27598.85k    27841.88k&#13;
<span class="codestrong1"># modprobe cryptodev</span>&#13;
<span class="codestrong1"># openssl speed -elapsed -evp sha-256 -engine devcrypto</span>&#13;
Engine "devcrypto" set.&#13;
...&#13;
type             16 bytes     ...  1024 bytes   8192 bytes  16384 bytes&#13;
sha-256            127.87k    ...     5835.78k    29996.37k    42592.94k</pre>
<p class="list-title" id="ch04list07"><em>Listing 4-7: A comparison of SHA-256 performance in software and hardware</em></p>
<p class="indent">For small input data like 16 bytes, the software solution outperforms the hardware by a factor of 22. This occurs because the test data has to be moved from user space to kernel space to hardware and back, which comes with significant overhead. However, with increasing data size, this effect becomes increasingly irrelevant. It seems that the STM32MP157F hardware has performance advantages for input data of 8KB and larger.</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Even if most hardware suppliers call their crypto modules “accelerators,” they aren’t guaranteed to accelerate anything. It might well be that the use of hardware even slows the crypto operations in your specific case. Make sure you test performance before you make a choice.</em></p>
</div>
<p class="indent">The standard data sizes of the OpenSSL command line tool stop at 16KB, but for our specific use case, it would be interesting if even higher throughput rates could be achieved when hashing a 100MB file. The commands in <a href="ch04.xhtml#ch04list08">Listing 4-8</a> add the options <code>-bytes 104857600</code> and <code>-seconds 60</code> to the calls to tell OpenSSL to use input chunks of 100MB and do the hashing for roughly one minute.</p>
<pre class="pre"><span epub:type="pagebreak" id="page_80"/># <span class="codestrong1">openssl speed -elapsed -evp sha-256 -bytes 104857600 -seconds 60</span>&#13;
...&#13;
type        104857600 bytes&#13;
sha-256          27566.90k&#13;
# <span class="codestrong1">openssl speed -elapsed -evp sha-256 -engine devcrypto -bytes 104857600&#13;
    -seconds 60</span>&#13;
Engine "devcrypto" set.&#13;
...&#13;
type        104857600 bytes&#13;
sha-256          68021.40k</pre>
<p class="list-title" id="ch04list08"><em>Listing 4-8: The performance analysis for hashing 100MB of data with SHA-256</em></p>
<p class="indent">The resulting numbers show that the software implementation doesn’t benefit from large input data, but the hardware implementation can enhance its throughput to about 68.0MBps.</p>
<p class="indent">Sanity checks are small steps that can reduce mistakes, misconceptions, and even vulnerabilities. I definitely recommend doing them when it comes to using hardware crypto.</p>
<p class="indent">First, I want to know whether the hardware is actually used or a software fallback steps in and sets me on the wrong track. Second, my confidence in the chosen solution would increase if the performance numbers given by the chip manufacturer somehow match my experimental data. <a href="ch04.xhtml#ch04list09">Listing 4-9</a> shows a pragmatic way to answer those questions.</p>
<pre class="pre"># <span class="codestrong1">time openssl speed -elapsed -evp sha-256 -bytes 104857600 -seconds 60</span>&#13;
You have chosen to measure elapsed time instead of user CPU time.&#13;
Doing sha-256 for 60s on 104857600 size blocks: 16 sha-256's in 60.87s&#13;
...&#13;
type        104857600 bytes&#13;
sha-256          27562.37k&#13;
real  1m 1.79s&#13;
user  1m 0.94s&#13;
sys   0m 0.75s&#13;
# <span class="codestrong1">time openssl speed -elapsed -evp sha-256 -engine devcrypto -bytes 104857600&#13;
    -seconds 60</span>&#13;
Engine "devcrypto" set.&#13;
You have chosen to measure elapsed time instead of user CPU time.&#13;
Doing sha-256 for 60s on 104857600 size blocks: 39 sha-256's in 61.19s&#13;
...&#13;
type        104857600 bytes&#13;
sha-256          66831.94k&#13;
real  1m 2.26s&#13;
user  0m 0.18s&#13;
sys   0m 2.08s</pre>
<p class="list-title" id="ch04list09"><em>Listing 4-9: A sanity check for SHA-256 hardware hashing</em></p>
<p class="indent"><span epub:type="pagebreak" id="page_81"/>The prefixed <code>time</code> command analyzes execution time of the subsequently called process in terms of three classes: elapsed wall-clock time (<code>real</code>), processing time spent in user space (<code>user</code>), and time used for process-specific kernel space operations (<code>sys</code>).</p>
<p class="indent">The software-only analysis took 1 minute and 1.79 seconds, of which 1 minute and 0.94 seconds were spent in user space and only 0.75 seconds were used for kernel operations. The “missing” 61.79 – 60.94 – 0.75 = 0.10 seconds can probably be attributed to the OS scheduling other processes or performing independent OS tasks.</p>
<p class="indent">Looking at the hardware-assisted run, the situation looks completely different. The speed test lasted 1 minute and 2.26 seconds, but only 0.18 seconds are allotted to user-space computations and 2.08 seconds were spent in kernel space. Despite these low numbers, 39 blocks of 100MB input data were processed by SHA-256.</p>
<p class="indent">The first conclusion is that 62.26 – 0.18 – 2.08 = 60.00 seconds aren’t represented in the results. Besides the previously mentioned scheduling and OS-related tasks, this amount of time also includes delays when waiting for hardware components to process and return data. In <em>Reference Manual RM0436</em> for STM32MP157F devices, ST explains that the processing time of one 512-bit intermediate block for SHA-256 takes 66 cycles. Therefore, an estimation of the time required for pure hardware operations in this specific case can be calculated as follows:</p>
<div class="image1"><img alt="Image" height="33" src="../images/f081-01.jpg" width="464"/></div>
<p class="indent">This number is at least in the right order of magnitude, but it still indicates that 60.00 – 15.82 = 44.18 seconds are “lost” in OS tasks, drivers, and further hardware processes like bus transfers. If performance is your utmost goal, profiling and optimizing driver implementations could be a next step.</p>
<h4 class="h4" id="ch00lev2_50"><strong><em>Comparison of Software Performance of Asymmetric Crypto</em></strong></h4>
<p class="noindent">Operations for asymmetric cryptography are computationally expensive. However, it’s important to get an idea of <em>how</em> costly they are and how the available options differ in performance.</p>
<p class="indent">The first analysis outputs in <a href="ch04.xhtml#ch04list010">Listing 4-10</a> show the significant impact of key lengths in RSA implementations.</p>
<pre class="pre"># <span class="codestrong1">openssl speed -elapsed rsa1024 rsa2048 rsa4096</span>&#13;
...&#13;
                  sign    verify    sign/s verify/s&#13;
rsa 1024 bits 0.004880s 0.000204s    204.9   4897.8&#13;
rsa 2048 bits 0.028736s 0.000672s     34.8   1487.6&#13;
rsa 4096 bits 0.178246s 0.002454s      5.6    407.5</pre>
<p class="list-title" id="ch04list010"><em>Listing 4-10: An RSA performance analysis with keys of 1,024, 2,048, and 4,096 bits</em></p>
<p class="indent">While the deprecated RSA-1024 completes almost 205 signatures per second on my STM32MP157F device, the state-of-the-art version with 2,048-bit keys yields only 35 signatures per second. By doubling the key length, we <span epub:type="pagebreak" id="page_82"/>have to accept a performance drop by a factor of approximately 6. Moving to the 4,096-bit variant leaves us with only five to six signatures per second, which means that the signing operation takes more than 178 milliseconds, although this device is already running at 800 MHz.</p>
<p class="indent">On the other hand, clearly the signature verification, equivalent to the encryption operation, shows a drastically higher performance for all key sizes because it utilizes the short RSA public exponents.</p>
<p class="indent">When it comes to ECDSA, the OpenSSL tool provides a large set of curves. <a href="ch04.xhtml#ch04list011">Listing 4-11</a> gives a performance overview for some of the most popular NIST curves in use.</p>
<pre class="pre"># <span class="codestrong1">openssl speed -elapsed ecdsap224 ecdsap256 ecdsap384 ecdsap521</span>&#13;
...&#13;
                              sign    verify    sign/s verify/s&#13;
 224 bits ecdsa (nistp224)   0.0090s   0.0074s    110.8    134.6&#13;
 256 bits ecdsa (nistp256)   0.0010s   0.0028s    982.3    355.5&#13;
 384 bits ecdsa (nistp384)   0.0322s   0.0243s     31.1     41.1&#13;
 521 bits ecdsa (nistp521)   0.0773s   0.0567s     12.9     17.6</pre>
<p class="list-title" id="ch04list011"><em>Listing 4-11: The signing and verification performance of selected NIST curves</em></p>
<p class="indent">We can instantly see that NIST curve P-256 is tremendously faster than the other curves because of its highly optimized structure and implementation. Further, ballpark estimations of performance cost factors (for example, for RSA) are hard to provide. Measuring a specific implementation on a specific platform is usually the way to go.</p>
<p class="indent">Regarding the comparison of ECDSA and RSA, NIST’s P-224 and RSA-2048, which have a similar security level, differ in signing performance by roughly a factor of 3 to the benefit of ECDSA. But in terms of verification speed, RSA-2048 is more than 11 times faster than the P-224 curve.</p>
<p class="indent">Finally, alternative elliptic curves are often considered because of trust issues with the NIST selection, but performance can also be a positive aspect, as presented in <a href="ch04.xhtml#ch04list012">Listing 4-12</a>.</p>
<pre class="pre"># <span class="codestrong1">openssl speed -elapsed ed25519 ed448 ecdsabrp256t1 ecdsabrp512t1</span>&#13;
...&#13;
                                     sign    verify    sign/s verify/s&#13;
 256 bits ecdsa (brainpoolP256t1)   0.0099s   0.0084s    101.5    119.1&#13;
 512 bits ecdsa (brainpoolP512t1)   0.0420s   0.0317s     23.8     31.6&#13;
                                     sign    verify    sign/s verify/s&#13;
 253 bits EdDSA (Ed25519)           0.0008s   0.0021s   1301.0    478.7&#13;
 456 bits EdDSA (Ed448)             0.0059s   0.0120s    169.4     83.1</pre>
<p class="list-title" id="ch04list012"><em>Listing 4-12: Alternative elliptic curves with interesting performance</em></p>
<p class="indent">The Brainpool curve P512t1 exhibits better performance than NIST P-521 for a similar level of security. Further, Bernstein’s Ed25519 (Curve25519) shows outstanding performance, even higher than that of NIST P-256.</p>
<p class="indent">Assuming you are free to choose an asymmetric signature algorithm for your application, Ed25519 would be a pretty interesting candidate from a <span epub:type="pagebreak" id="page_83"/>performance point of view. If backward compatibility with RSA is a requirement, RSA-2048 might currently be a solid choice, but make sure that RSA-4096 is also feasible on your device to be prepared for future updates.</p>
<h3 class="h3" id="ch00lev1_40"><strong>Summary</strong></h3>
<p class="noindent">Performance is not everything. However, when it comes to the implementation of cryptographic algorithms, it’s a property you should never neglect. In addition to security itself, performance is one of the fundamental quality characteristics of crypto.</p>
<p class="indent">Some embedded systems have strong restrictions regarding processing power, memory size, or power consumption, which makes optimized implementations a necessity. Otherwise, crypto might lose in a trade-off discussion. Other devices serve dedicated purposes in networking or data processing and require high-speed crypto implementations. Sometimes performance requirements can be met by the use of efficient software libraries, but other scenarios demand specific, digital hardware designs in FPGAs (which is an engineering field of its own) or hardware coprocessors built exactly for this task.</p>
<p class="indent">Be aware that even if your chosen crypto algorithms are secure from a mathematical point of view and exhibit nice performance characteristics, they’re not necessarily robust against implementation attacks like side-channel analysis and fault injection. <em>The Hardware Hacking Handbook</em> by Jasper van Woudenberg and Colin O’Flynn (No Starch Press, 2021) is full of practical examples and insights on how to break and secure crypto implementations. <em>Power Analysis Attacks: Revealing the Secrets of Smart Cards</em> by Stefan Mangard, Elisabeth Oswald, and Thomas Popp (Springer, 2007) is also a classic for diving deeper into this field.</p>
<p class="indent">Also, keep in mind that such advanced protection measures often come with a reduction in crypto performance. Make sure to determine as soon as possible in your development life cycle whether your product requires specifically hardened crypto implementations.<span epub:type="pagebreak" id="page_84"/></p>
</div></body></html>