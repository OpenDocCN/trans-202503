- en: '**4'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'NEURAL NETWORKS: BRAIN-LIKE AI**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/common.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Connectionism seeks to provide a substrate from which intelligence might emerge.
    Today, connectionism means neural networks, with *neural* being a nod to biological
    neurons. Despite the name, however, the relationship between the two is superficial.
    Biological neurons and artificial neurons may possess a similar configuration,
    but they operate in an entirely different manner.
  prefs: []
  type: TYPE_NORMAL
- en: Biological neurons accept input on their dendrites, and when a sufficient number
    of inputs are active they “fire” to produce a short-lived voltage spike on their
    axons. In other words, biological neurons are off until they’re on. Some 800 million
    years of animal evolution have made the process considerably more complex, but
    that’s the essence.
  prefs: []
  type: TYPE_NORMAL
- en: The artificial neurons of a neural network likewise possess inputs and outputs,
    but instead of firing, the neurons are mathematical functions with continuous
    behavior. Some models spike like biological neurons, but we ignore them in this
    book. The neural networks powering the AI revolution operate continuously.
  prefs: []
  type: TYPE_NORMAL
- en: Think of a biological neuron like a light switch. It’s off until there is a
    reason (sufficient input) to turn it on. The biological neuron doesn’t turn on
    and stay on but flashes on and off, like flicking the switch. An artificial neuron
    is akin to a light with a dimmer switch. Turn the switch a tiny amount to produce
    a small amount of light; turn the switch further, and the light’s brightness changes
    proportionally. This analogy isn’t accurate in all cases, but it conveys the essential
    notion that artificial neurons are not all or nothing. Instead, they produce output
    in proportion to their input according to some function. The fog will lift as
    we work through the chapter, so don’t worry if this makes little sense at present.
  prefs: []
  type: TYPE_NORMAL
- en: '****'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-1](ch04.xhtml#ch04fig01) is the most critical figure in the book.
    It’s also one of the simplest, as is to be expected if the connectionist approach
    is on the right track. If we understand what [Figure 4-1](ch04.xhtml#ch04fig01)
    represents and how it operates, we have the core understanding necessary to make
    sense of modern AI.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch04fig01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-1: The humble (artificial) neuron*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-1](ch04.xhtml#ch04fig01) contains three squares, a circle, five arrows,
    and labels like “*x*[0]” and “Output.” Let’s examine each in turn, beginning with
    the squares on the left.'
  prefs: []
  type: TYPE_NORMAL
- en: Standard practice presents neural networks with the inputs on the left and data
    flow to the right. In [Figure 4-1](ch04.xhtml#ch04fig01), the three squares labeled
    *x*[0], *x*[1], and *x*[2] are the inputs to the neuron. They are the three features
    of a feature vector, what we want the neuron to process to give us an output leading
    to a class label.
  prefs: []
  type: TYPE_NORMAL
- en: The circle is labeled *h*, a standard notation for the [*activation function*](glossary.xhtml#glo1).
    The activation function’s job is to accept input to the neuron and produce an
    output value, the arrow heading off to the right in [Figure 4-1](ch04.xhtml#ch04fig01).
  prefs: []
  type: TYPE_NORMAL
- en: The three input squares are connected to the circle (the [*node*](glossary.xhtml#glo74))
    by arrows, one from each input square. The arrows’ labels—*w*[0], *w*[1], and
    *w*[2]—are the [*weights*](glossary.xhtml#glo100). Every input to the neuron has
    an associated weight. The lone *b* linked to the circle by an arrow is the [*bias*](glossary.xhtml#glo13).
    It’s a number, as are the weights, the input *x*s, and the output. For this neuron,
    three numbers come in, and one number goes out.
  prefs: []
  type: TYPE_NORMAL
- en: 'The neuron operates like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Multiply every input value, *x*[0], *x*[1], and *x*[2], by its associated weight,
    *w*[0], *w*[1], and *w*[2].
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add all the products from step 1 together along with the bias value, *b*. This
    produces a single number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give the single number to *h*, the activation function, to produce the output,
    also a single number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'That’s all a neuron does: it multiplies its inputs by the weights, sums the
    products, adds the bias value, and passes that total to the activation function
    to produce the output.'
  prefs: []
  type: TYPE_NORMAL
- en: Virtually all the fantastic accomplishments of modern AI are due to this primitive
    construct. String enough of these together in the correct configuration, and you
    have a model that can learn to identify dog breeds, drive a car, or translate
    from French to English. Well, you do if you have the magic weight and bias values,
    which training gives us. These values are so important to neural networks that
    one company has adopted “Weights & Biases” as its name; see [*https://www.wandb.ai*](https://www.wandb.ai).
  prefs: []
  type: TYPE_NORMAL
- en: 'We have choices for the activation function, but in modern networks it’s most
    often the rectified linear unit (ReLU) mentioned in [Chapter 2](ch02.xhtml). The
    ReLU is a question: is the input (the sum of the inputs multiplied by the weights
    plus the bias) less than zero? If so, the output is zero; otherwise, it’s whatever
    the input is.'
  prefs: []
  type: TYPE_NORMAL
- en: Can something as straightforward as a lone neuron be useful? It can. As an experiment,
    I trained the neuron in [Figure 4-1](ch04.xhtml#ch04fig01) using three features
    from the iris flower dataset from [Chapter 1](ch01.xhtml) as input. Recall, this
    dataset contains measurements of the parts of three different species of iris.
    After training, I tested the neuron with an unused test set that had 30 feature
    vectors. The neuron correctly classified 28, for an accuracy of 93 percent.
  prefs: []
  type: TYPE_NORMAL
- en: I trained the neuron by searching for a set of three weights and a bias value
    producing an output that, when rounded to the nearest whole number, matched the
    class label for an iris flower—either 0, 1, or 2\. This is not the standard way
    to train a neural network, but it works for something as modest as a single neuron.
    We’ll discuss standard network training later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: A single neuron can learn, but complex inputs baffle it. Complex inputs imply
    we need a more complex model. Let’s give our single neuron some friends.
  prefs: []
  type: TYPE_NORMAL
- en: Convention arranges neurons in layers, with the outputs from the previous layer
    the inputs to the following layer. Consider [Figure 4-2](ch04.xhtml#ch04fig02),
    which shows networks with two, three, and eight nodes in the layer after the input.
    Arranging the network in layers simplifies the implementation in code and facilitates
    the standard training procedure. That said, there is no requirement to use layers
    if an alternative way to train the model can be found.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch04fig02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-2: Two-, three-, and eight-node networks*'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin with the two-node network at the upper left. The three inputs (squares)
    are there, but this time there are two circles in the middle layer and a single
    circle on the right. The inputs are fully connected to the two nodes in the middle
    layer, meaning a line connects each input square to each middle layer node. The
    middle layer outputs are connected to a single node on the far right, from which
    the network’s output comes.
  prefs: []
  type: TYPE_NORMAL
- en: The middle layers of a neural network between the input on the left and the
    output on the right are known as [*hidden layers*](glossary.xhtml#glo54). For
    example, the networks of [Figure 4-2](ch04.xhtml#ch04fig02) each have one hidden
    layer with 2, 3, and 8 nodes, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: A network with this configuration is suitable for a binary classification task,
    class 0 versus class 1, where the output is a single number representing the model’s
    belief that the input is a member of class 1\. Therefore, the rightmost node uses
    a different activation function known as a [*sigmoid*](glossary.xhtml#glo90) (also
    called a logistic). The sigmoid produces an output between 0 and 1\. This is also
    the range used to represent a probability, so many people refer to the output
    of a node with a sigmoid activation function as a probability. This is not generally
    accurate, but we can live with the sloppiness. The nodes of the hidden layer all
    use ReLU activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: How many weights and biases must we learn to implement the two-node network
    in [Figure 4-2](ch04.xhtml#ch04fig02)? We need one weight for each line (except
    the output arrow) and one bias value for each node. Therefore, we need eight weights
    and three bias values. For the model at the lower left, we need 12 weights and
    4 biases. Finally, for the 8-node model, we need to learn 32 weights and 9 bias
    values. As the number of nodes in a layer increases, the number of weights increases
    even faster. This fact alone restrained neural networks for years, as potentially
    useful models were too big for a single computer’s memory. Of course, model size
    is relative. OpenAI’s GPT-3 has over 175 billion weights, and while they aren’t
    talking about how large GPT-4 is, rumor puts it at 1.7 *trillion* weights.
  prefs: []
  type: TYPE_NORMAL
- en: We need a two-class dataset to explore the models in [Figure 4-2](ch04.xhtml#ch04fig02).
    The dataset we’ll use is a classic one that attempts to distinguish between two
    cultivars of grapes used to make wine in a particular region of Italy. Unfortunately,
    the wines represented by the dataset are, it seems, no longer known. (That’s how
    old the dataset is.) However, we know that models don’t care about the labels—they
    use numbers—so we’ll use 0 and 1 as the labels.
  prefs: []
  type: TYPE_NORMAL
- en: We need three features, *x*[0], *x*[1], and *x*[2]. The features we’ll use are
    alcohol content in percent, malic acid, and total phenols. The goal is to train
    the models in [Figure 4-2](ch04.xhtml#ch04fig02) to see how well each performs
    when identifying an unknown wine given measurements of the three features.
  prefs: []
  type: TYPE_NORMAL
- en: I trained the two-neuron model using a training set of 104 samples and a test
    set of 26 samples. This means I used 104 triplets of measured alcohol content,
    malic acid level, and total phenols, knowing the proper output label, class 0
    or class 1\. The training set conditioned the two-neuron model to give values
    to all eight weights and three biases. I promise we will discuss how training
    works, but for now, assume it happens so we can explore how neural networks behave.
    The trained model achieved an accuracy on the test set of 81 percent, meaning
    it was right better than 8 times out of 10\. That’s not too bad for such a small
    model and training set.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-3](ch04.xhtml#ch04fig03) presents the trained two-neuron model. I
    added the weights to the links and the biases to the nodes so you can see them.
    I think it’s worth looking at the numbers at least once, and it’s best to do that
    with a simple model.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch04fig03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-3: The two-neuron model trained on the wine dataset*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use the model with two test samples to understand the process. The two
    test samples consist of three numbers each, the values of the features, (*x*[0],
    *x*[1], *x*[2]):'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Sample 1** | (–0.7359, 0.9795, –0.1333) |'
  prefs: []
  type: TYPE_TB
- en: '| **Sample 2** | ( 0.0967, –1.2138, –1.0500) |'
  prefs: []
  type: TYPE_TB
- en: You may have a question at this point. I said the features were alcohol content
    in percent, malic acid level, and total phenols. While I have no idea what the
    units are for measuring malic acid or total phenols, a percent is a percent, so
    why is *x*[0] for the first sample a small negative number? We can’t have a negative
    percentage of alcohol.
  prefs: []
  type: TYPE_NORMAL
- en: The answer has to do with [*preprocessing*](glossary.xhtml#glo82). Raw data,
    like the percent alcohol, is seldom used with machine learning models as is. Instead,
    each feature is adjusted by subtracting the average value of the feature over
    the training set and dividing that result by a measure of how scattered the data
    is around the average value (the standard deviation). The original alcohol content
    was 12.29 percent, a reasonable value for wine, but after scaling, it became –0.7359.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s classify sample 1 using the learned weights and biases in [Figure 4-3](ch04.xhtml#ch04fig03).
    The input to the top neuron is each feature multiplied by the weight on the line
    connecting that feature to the neuron, then summed with the bias value. The first
    feature gives us 0.4716 × –0.7359, the second 0.0399 × 0.9795, and the third –0.3902
    × –0.1333, with bias value 0.0532\. Adding all of these together gives – 0.2028\.
    This is the number passed to the activation function, a ReLU. Since it is negative,
    the ReLU returns 0, meaning the output from the top node is 0\. Repeating the
    calculation for the bottom node gives 0.1720 as the input to the ReLU. That’s
    a positive number, so the ReLU returns 0.1720 as the output.
  prefs: []
  type: TYPE_NORMAL
- en: The outputs of the two nodes in the middle layer are now used as the inputs
    to the final node on the right. As before, we multiply the outputs by the weights,
    add them along with the bias value, and pass that to the activation function.
    In this case, the activation function is not a ReLU but a sigmoid.
  prefs: []
  type: TYPE_NORMAL
- en: The top node’s output is 0, and the bottom’s output is 0.1720\. Multiplying
    these by their respective weights, summing, and adding the bias value of 2.2277
    gives us 1.9502 as the argument to the sigmoid activation function, producing
    0.8755 as the network’s output for the first input sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'How should we interpret this output? Here’s where we learn an important aspect
    of neural networks:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks don’t tell us the actual class label for the input, but only
    their confidence in one label relative to another.
  prefs: []
  type: TYPE_NORMAL
- en: Binary models output a confidence value that we’re interpreting as the probability
    of the input belonging to class 1\. Probabilities are numbers between 0 (no chance)
    and 1 (absolutely assured). Humans are generally more comfortable with percentages,
    which we get by multiplying the probability by 100\. Therefore, we can say that
    the network is a little more than 87 percent confident that this input represents
    an instance of class 1.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, we use a threshold—a cutoff value—to decide which label to assign.
    The most common approach for binary models is a threshold of 50 percent. If the
    output exceeds 50 percent (probability 0.5), we assign the input to class 1\.
    This output is above 50 percent, so we assign “class 1” as the label. This sample
    is from class 1, meaning the network’s assigned label is correct.
  prefs: []
  type: TYPE_NORMAL
- en: We can repeat these calculations for the second input sample, (0.0967, –1.2138,
    –1.0500). I’ll leave walking through it to you as an exercise, but the network’s
    output for sample 2 is 0.4883\. In other words, the network’s confidence that
    this sample belongs to class 1 is 49 percent. The cutoff is 50 percent, so we
    reject the class 1 label and assign this input to class 0\. The actual class is
    class 1, so, in this instance, the network is wrong—it assigned a class 1 sample
    to class 0\. Oops.
  prefs: []
  type: TYPE_NORMAL
- en: Is this a useful model? The answer depends on the context. We’re classifying
    wine by cultivar. If the model’s output is wrong 20 percent of the time, which
    is one time in five, is that acceptable? I suspect not, but there might be other
    tasks where a model with this level of accuracy is acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks offer some control over how their outputs are interpreted. For
    example, we might not use 50 percent as the cutoff. If we make it lower, say,
    40 percent, we’ll capture more class 1 samples, but at the expense of mistakenly
    identifying more actual class 0 samples as class 1\. In other words, we get to
    trade off one kind of error for another.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s bring the other models in [Figure 4-2](ch04.xhtml#ch04fig02) into the
    mix. I trained all three models using the same training and test sets used for
    [Figure 4-3](ch04.xhtml#ch04fig03). I repeated the process 240 times for each
    of the three models. Here are the average accuracies:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **2-node** | 81.5 percent |'
  prefs: []
  type: TYPE_TB
- en: '| **3-node** | 83.6 percent |'
  prefs: []
  type: TYPE_TB
- en: '| **8-node** | 86.2 percent |'
  prefs: []
  type: TYPE_TB
- en: The model’s performance improves as the number of nodes in the hidden layer
    increases. This makes intuitive sense, as a more complex model (more nodes) implies
    the ability to learn more complex associations hidden within the training set.
  prefs: []
  type: TYPE_NORMAL
- en: 'I suspect you now have a new question: why did I train each model 240 times
    and report the average accuracy over all 240 models? Here’s another critical thing
    to understand about neural networks:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks are randomly initialized, such that repeated training leads
    to differently performing models even when using the same training data.
  prefs: []
  type: TYPE_NORMAL
- en: The phrase “randomly initialized” demands clarification. Look again at [Figure
    4-3](ch04.xhtml#ch04fig03). The numbers representing the weights and biases came
    from an iterative process. This means that an initial set of weights and biases
    are updated repeatedly, each time moving the network toward a better and better
    approximation of whatever function it is that links the input feature vectors
    and the output labels. Approximating this function well is what we want the network
    to do.
  prefs: []
  type: TYPE_NORMAL
- en: Why not initialize all the weights to the same value? The answer is that doing
    so forces the weights to learn similar characteristics of the data, which is something
    we don’t want, and in the end the model will perform poorly. If we set all of
    the initial weights to zero, the model does not learn at all.
  prefs: []
  type: TYPE_NORMAL
- en: An initial set of values are necessary for the iterative process to work. How
    should we pick the initial values? That’s an important question, and the answer
    for our current level of understanding is “at random,” meaning we roll dice, in
    a sense, to get the initial value for each weight and bias. The iterative process
    then refines these values to arrive at the final set in [Figure 4-3](ch04.xhtml#ch04fig03).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the iterative process doesn’t always end in the same place. Pick a
    different random set of initial weights and biases, and the network will converge
    to a different set of final values. For example, the network in [Figure 4-3](ch04.xhtml#ch04fig03)
    achieved an accuracy of 81 percent, as mentioned previously. Here are 10 more
    accuracies for the same network trained and tested on the same data:'
  prefs: []
  type: TYPE_NORMAL
- en: 89, 85, 73, 81, 81, 81, 81, 85, 85, 85
  prefs: []
  type: TYPE_NORMAL
- en: The accuracies range from a high of 89 percent to a low of 73 percent. All that
    changed between each training session was the collection of initial weights and
    biases. This is an often overlooked issue with neural networks. Networks should
    be trained multiple times, if feasible, to gather data on their effectiveness
    or, as with the 73 percent version of the network, to understand that a bad set
    of initial values was used purely by chance. I should also mention that the wide
    variation in the accuracy of this network is related to its being relatively small
    and containing only a few weights and biases. Larger models tend to be more consistent
    when trained repeatedly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve already covered a lot of ground, so a recap is in order:'
  prefs: []
  type: TYPE_NORMAL
- en: The fundamental unit of a neural network is the neuron, also called a node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neurons multiply their inputs by weights, sum those products, add a bias value,
    and pass all of that to the activation function to produce an output value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks are collections of individual neurons, typically arranged in
    layers with the output of the current layer the input to the following layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a neural network assigns values to the weights and biases by iteratively
    adjusting an initial, randomly selected set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary neural networks produce an output that roughly corresponds to the probability
    of the input belonging to class 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '****'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know what a neural network is and how it’s used, we finally come
    to the crux of the matter: where do the magic weights and biases come from in
    the first place? In [Chapter 2](ch02.xhtml), I briefly mentioned that neural networks
    improved in the 1980s thanks to two essential algorithms: backpropagation and
    gradient descent. These are the algorithms at the heart of neural network training.'
  prefs: []
  type: TYPE_NORMAL
- en: We discussed optimization, the process of finding the best of something according
    to some criteria, in [Chapter 3](ch03.xhtml) in reference to support vector machines.
    Training a neural network is also an optimization process, involving learning
    the weights and biases that best fit the training data. Care must be taken, however,
    to make it more likely that the learned weights and biases fit general trends
    in the training data rather than the details of the specific training data itself.
    What I mean by that will become apparent as we learn more about the training process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The general training algorithm is:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the model’s architecture, including the number of hidden layers, nodes
    per layer, and activation function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Randomly but intelligently initialize all the weights and biases associated
    with the selected architecture.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the training data, or a subset, through the model and calculate the average
    error. This is the [*forward pass*](glossary.xhtml#glo45).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use backpropagation to determine how much each weight and bias contributes to
    that error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the weights and biases according to the gradient descent algorithm. This
    and the previous step make up the [*backward pass*](glossary.xhtml#glo11).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat from step 3 until the network is considered “good enough.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These six steps include many important terms. It’s worth our time to ensure
    that we have an idea of what each means. In this chapter, [*architecture*](glossary.xhtml#glo3)
    refers to the number of layers, typically hidden layers, used by the network.
    We have our input feature vector, and we can imagine each hidden layer working
    collectively to accept an input vector and produce an output vector, which then
    becomes the input to the next layer, and so on. For binary classifiers, the network’s
    output is a single node producing a value from 0 to 1\. We’ll learn later in the
    book that this idea can be extended to multiclass outputs.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm indicates that training is an iterative process that repeats many
    times. Iterative processes have a starting point. If you want to walk from point
    A to point B, place one foot in front of the other. That’s the iterative part.
    Point A is the starting point. For a neural network, the architecture implies
    a set of weights and biases. The initial values assigned to those weights and
    biases are akin to point A, with training akin to placing one foot in front of
    the other.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm uses the phrase “average error.” What error? Here’s where a new
    concept enters the picture. Intuitively, we can see that simply picking some initial
    values for the weights and biases is not likely to lead to a network able to classify
    the training data accurately. Remember, we know the inputs and the expected outputs
    for the training data.
  prefs: []
  type: TYPE_NORMAL
- en: Say we push training sample 1 through the network to give us an output value,
    perhaps 0.44\. If we know that sample 1 belongs to class 1, the error made by
    the network is the difference between the expected output and the actual output.
    Here, that’s 1 – 0.44, or 0.56\. A good model might instead have produced an output
    of 0.97 for this sample, giving an error of only 0.03\. The smaller the error,
    the better the model is at classifying the sample. If we push all the training
    data through the network, or a representative subset of it, we can calculate the
    error for each training sample and find the average over the entire training set.
    That’s the measure used by the (to be described) backpropagation and gradient
    descent algorithms to update the weights and biases.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the training algorithm says to push data through the network, get an
    error, update the weights and biases, and repeat until the network is “good enough.”
    In a way, good enough is when the error, also called the [*loss*](glossary.xhtml#glo63),
    is as close to zero as possible. If the network produces 0 as the output for all
    class 0 samples and 1 as the output for all class 1 samples, then it performs
    perfectly on the training data, and the error will be zero. That’s certainly good
    enough, but we must be careful. Sometimes when that happens the network is [*overfitting*](glossary.xhtml#glo79),
    meaning it’s learned all the details of the training data without actually learning
    the general trends of the data that will allow it to perform well when used with
    unknown inputs in the wild.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, overfitting is addressed in several ways, the best of which is
    acquiring more training data. We use the training data as a stand-in for all the
    possible data that could be produced by whatever process we are trying to model.
    Therefore, more training data means a better representation of that data collection.
    It’s the interpolate versus extrapolate issue we discussed in [Chapter 1](ch01.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: However, getting more training data might not be possible. Alternatives include
    tweaking the training algorithm to introduce things that keep the network from
    focusing on irrelevant details of the training data while learning. One such technique
    you may hear mentioned is *weight decay*, which penalizes the network if it makes
    the weight values too large.
  prefs: []
  type: TYPE_NORMAL
- en: Another common approach is [*data augmentation*](glossary.xhtml#glo26). Out
    of training data? No worries, data augmentation will invent some by slightly modifying
    the data you already have. Data augmentation takes the existing training data
    and mutates it to produce new data that might plausibly have been created by the
    same process that made the actual training data. For example, if the training
    sample is a picture of a dog, it will still be a picture of a dog if you rotate
    it, shift it up a few pixels, flip it left to right, and so on. Each transformation
    produces a new training sample. It might seem like cheating, but in practice,
    data augmentation is a powerful [*regularizer*](glossary.xhtml#glo86) that keeps
    the network from overfitting during training.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s return for a moment to initialization, as its importance was not sufficiently
    appreciated for many years.
  prefs: []
  type: TYPE_NORMAL
- en: At first, weight initialization meant nothing more than “pick a small random
    number” like 0.001 or –0.0056\. That worked much of the time. However, it didn’t
    work consistently, and when it did work, the network’s behavior wasn’t stellar.
  prefs: []
  type: TYPE_NORMAL
- en: 'Shortly after the advent of deep learning, researchers revisited the “small
    random value” idea in search of a more principled approach to initialization.
    The fruit of those efforts is the way neural networks are initialized to this
    day. Three factors need to be considered: the form of the activation function,
    the number of connections coming from the layer below (*fan-in*), and the number
    of outputs to the layer above (*fan-out*). Formulas were devised to use all three
    factors to select the initial weights for each layer. Bias values are usually
    initialized to zero. It isn’t difficult to demonstrate that networks so initialized
    perform better than those initialized the old-fashioned way.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have two steps of the training algorithm yet to discuss: backpropagation
    and gradient descent. Backpropagation is often presented first because its output
    is necessary for gradient descent. However, I think it’s more intuitive to understand
    what gradient descent is doing, then fill in the missing piece it needs with what
    backpropagation provides. Despite the unfamiliar names, I am certain you already
    understand the essence of both algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: '****'
  prefs: []
  type: TYPE_NORMAL
- en: You’re standing in a vast, open grassland of rolling hills. How did you get
    here? You strain your brain, but no answer comes. Then, finally, you spy a small
    village to the north, in the valley far below. Perhaps the people there can give
    you some answers. But what’s the best way to get there?
  prefs: []
  type: TYPE_NORMAL
- en: You want to go north and down, in general, but you must also respect the contour
    of the land. You always want to move from a higher to a lower position. You can’t
    go due north because a large hill is in your way. You could head northeast; the
    terrain is flatter there, but going that way will make your journey a long one,
    as the land drops slowly. So, you decide to head northwest, as that moves you
    both north and down more steeply than to the east. You take a step to the northwest,
    then pause to reassess your position to decide which direction to move in next.
  prefs: []
  type: TYPE_NORMAL
- en: Repeating this two-stage process of examining your current position to determine
    the direction that best moves you both northward and downward, then taking a step
    in that direction, is your best bet for reaching the village in the valley. You
    may not make it; you might get stuck in a small canyon out of which you can’t
    climb. But overall, you’ll make progress toward your goal by consistently moving
    in a direction that is north and down relative to your current position.
  prefs: []
  type: TYPE_NORMAL
- en: Following this process, known as [*gradient descent*](glossary.xhtml#glo52),
    lets us adjust a neural network’s initial weights and biases to give us ever better-performing
    models. In other words, gradient descent trains the model.
  prefs: []
  type: TYPE_NORMAL
- en: The three-dimensional world of the grassland surrounding the village corresponds
    to the *n*-dimensional world of the network, where *n* is the total number of
    weights and biases whose values we are trying to learn. Choosing a direction to
    head in from your current position and then moving some distance in that direction
    is a gradient descent step. Repeated gradient descent steps move you closer and
    closer to the village.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent seeks the minimum position, the village in the valley—but the
    minimum of what? For a neural network, gradient descent aims to adjust the weights
    and biases of the network to minimize the error over the training set.
  prefs: []
  type: TYPE_NORMAL
- en: The vast, open grassland of rolling hills represents the error function, the
    average error over the training data when using the weight and bias values corresponding
    to your current position. This means that each position in the grassland implies
    a complete set of network weights and biases. The position of the village corresponds
    to the smallest error the network can make on the training set. The hope is that
    a model that has a small error on its training set will make few errors on unknown
    inputs when used in the wild. Gradient descent is the algorithm that moves through
    the space of weights and biases to minimize the error.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent is an optimization algorithm, again telling us that training
    a neural network is an optimization problem, a problem where we need to find the
    best set of something. While this is true, it is also true that training a neural
    network is subtly different from other optimization problems. As mentioned previously,
    we don’t necessarily want the smallest possible error on the training data, but
    rather the model that best generalizes to unknown inputs. We want to avoid overfitting.
    I’ll demonstrate visually what that means later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent moves through the landscape of the error function. In everyday
    use, a gradient is a change in something, like the steepness of a road or a color
    gradient varying smoothly from one shade to another. Mathematically, a gradient
    is the multidimensional analog of the slope of a curve at a point. The steepest
    direction to move is down the maximum gradient. The slope of a line at a point
    on a curve is a helpful representation of the gradient, so contemplating slopes
    is a worthy use of our time.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-4](ch04.xhtml#ch04fig04) shows a curve with four lines touching it
    at different points. The lines represent the slope at those points. The slope
    indicates how quickly the value of the function changes in the vicinity of the
    point. The steeper the line, the faster the function’s value changes as you move
    along the *x*-axis.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch04fig04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-4: A curve with the slope at various points marked*'
  prefs: []
  type: TYPE_NORMAL
- en: Line B marks the lowest point on the curve. This is the [*global minimum*](glossary.xhtml#glo51)
    and the point that an optimization algorithm seeks to find. Notice that the line
    touching this point is entirely horizontal. Mathematically, this means that the
    slope of line B is zero. This is true at the minima (and maxima) of functions.
  prefs: []
  type: TYPE_NORMAL
- en: The point touched by line B is the global minimum, but there are three other
    minima in the plot. These are *local minima*, points where the slope of the line
    touching those points is also zero. Ideally, an optimization algorithm would avoid
    these points, favoring the global minimum.
  prefs: []
  type: TYPE_NORMAL
- en: Line A is steep and points toward the global minimum. Therefore, if we were
    at the point on the curve touched by line A, we could move quickly toward the
    global minimum by taking steps in the indicated direction. Moreover, as the slope
    is steep here, we can take reasonably large steps down to the valley.
  prefs: []
  type: TYPE_NORMAL
- en: Line C is also steep but heads toward one of the local minima, the one just
    beyond 3 on the *x*-axis. A gradient descent algorithm that only knows how to
    move down the gradient will locate that local minimum and become stuck there.
    The same applies to line D, which heads toward the local minimum between 4 and
    5 on the *x*-axis.
  prefs: []
  type: TYPE_NORMAL
- en: What are the takeaways from [Figure 4-4](ch04.xhtml#ch04fig04)? First, gradient
    descent moves down the gradient, or slope, from some point. Here the curve is
    one- dimensional, so the point is a specific value of *x*. Gradient descent uses
    the value of the slope at that point to pick a direction and a step size proportional
    to the steepness of the slope. A steep slope means we can take a larger step to
    end up at a new *x* value closer to a minimum. A shallow slope implies a smaller
    step.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose we are initially at the point where line A touches the
    curve. The slope is steep, so we take a big step toward the global minimum. After
    the step, we look at the slope again, but this time it’s the slope at the new
    point on the *x*-axis. Using that slope, we take another step, then another, and
    another until we get to a point where the slope is essentially zero. That’s the
    minimum, so we stop.
  prefs: []
  type: TYPE_NORMAL
- en: The one-dimensional case is straightforward enough because at each point there
    is only one slope, so there is only one direction to go. However, recalling the
    vast, open grassland, we know that from any point there are an infinite number
    of directions we might head in, many of which are useful in that they move us
    northward and downward. One of these directions, the direction of the maximum
    gradient, is the steepest and moves us most quickly toward our desired destination,
    and that’s the direction we step in. Repeating the process, using the maximum
    gradient direction each time, accomplishes in multiple dimensions what we did
    in one dimension. To be precise, we step in the direction *opposite* the maximum
    gradient because the maximum gradient points away from the minimum, not toward
    it.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-5](ch04.xhtml#ch04fig05) presents gradient descent in two dimensions.
    The figure shows a contour plot. Imagine an open pit mine with terraced levels:
    the lighter the shade, the deeper into the mine, but also the flatter the slope.
    That is, lighter shades imply shallower slopes.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../images/ch04fig05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 4-5: Gradient descent in two dimensions*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The figure shows the path taken by gradient descent for three starting positions:
    the circle, the triangle, and the square. Initially, the slopes are steep, so
    the step sizes are big, but the slopes become shallow as the minimum is approached,
    implying smaller steps. Eventually, gradient descent reaches the minimum, regardless
    of the starting point.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve discussed gradient descent in one and two dimensions because we can visualize
    the process. We understand now that we have always known the algorithm and used
    it ourselves whenever we walk from a higher elevation to a lower one. Honestly,
    this is all that training a neural network does. The initial set of weights and
    biases is nothing more than a single starting point in an *n*-dimensional space.
    Gradient descent uses the maximum gradient from that initial starting position
    to march toward a minimum. Each new position in the *n*-dimensional space is a
    new set of the *n* weights and biases generated from the previous set based on
    the steepness of the gradient. When the gradient gets very small, we claim victory
    and fix the weights and biases, believing the network to be trained.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent depends on slopes, on the value of the gradient. But where
    do the gradients come from? Gradient descent minimizes the loss function, or the
    error made by the network. The error over the training set is a function of each
    weight and bias value in the network. The gradient represents how much each weight
    and bias contributes to the overall error.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose we know how much weight 3 (whatever weight that labels)
    contributes to the network’s error as measured by the mistakes the network makes
    on the training set. In that case, we know the steepness of the gradient should
    we change weight 3’s value, keeping all other weights and biases the same. That
    steepness, multiplied by a step size, gives us a value to subtract from weight
    3’s current value. By subtracting, we move in the direction opposite to the maximum
    gradient. Repeating the calculation for every weight and bias in the network takes
    a step in the *n*-dimensional space. This is what gradient descent does during
    training.
  prefs: []
  type: TYPE_NORMAL
- en: '[*Backpropagation*](glossary.xhtml#glo10) is the algorithm that gives us the
    steepness values per weight and bias. Backpropagation is an application of a well-known
    rule from differential calculus, the branch of mathematics telling us how one
    thing changes as another changes. Speed is an example. Speed indicates how distance
    changes with time. It’s even in how we talk about speed: miles per hour or kilometers
    per hour. Backpropagation gives us the “speed” representing how the network’s
    error changes with a change in any weight or bias value. Gradient descent uses
    these “speeds,” multiplied by a scale factor known as the [*learning rate*](glossary.xhtml#glo61),
    to step to the next position in the *n*-dimensional space represented by the *n*
    weights and biases of the network.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, the “big” network in [Figure 4-2](ch04.xhtml#ch04fig02) has 32
    weights and 9 biases; therefore, training that network with gradient descent means
    moving through a 41-dimensional space to find the 41 weight and bias values giving
    us the smallest error averaged over the training set.
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm is called “backpropagation” because it calculates the “speed”
    values for each weight and bias, beginning with the network’s output layer and
    then moving backward, layer by layer, to the input layer. That is, it moves backward
    through the network to propagate the error from a layer to the previous layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The take-home message is this:'
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent uses the gradient direction supplied by backpropagation to
    iteratively update the weights and biases to minimize the network’s error over
    the training set.
  prefs: []
  type: TYPE_NORMAL
- en: And that, in a nutshell, is how neural networks are trained.
  prefs: []
  type: TYPE_NORMAL
- en: '****'
  prefs: []
  type: TYPE_NORMAL
- en: The ability to train a neural network with backpropagation and gradient descent
    is a bit of a fluke. It shouldn’t work. Gradient descent with backpropagation
    is a *first-order* optimization approach. First-order optimization works best
    with simple functions, and the error surfaces of a neural network are anything
    but. However, Fortuna has smiled upon us, and it does work, and rather well at
    that. There is as yet no rigorous mathematical explanation beyond the realization
    that the local minima of the error function are all pretty much the same, meaning
    if you land in one and can’t get out, that’s often just fine.
  prefs: []
  type: TYPE_NORMAL
- en: There is another empirical explanation, but to understand that, we must learn
    more about the training process. The six-step training algorithm I gave earlier
    in the chapter talks about running the training set, or a subset of it, through
    the network, and repeating until things are “good enough.” Let me expand on the
    process implied by these steps.
  prefs: []
  type: TYPE_NORMAL
- en: Each pass of training data through the network, a forward pass followed by a
    backward pass, results in a gradient descent step as shown in [Figure 4-5](ch04.xhtml#ch04fig05).
    If the training set is small, all of it is used in the forward pass, meaning all
    of it is used by gradient descent to decide where to step next. A complete pass
    through the training data is called an [*epoch*](glossary.xhtml#glo37); therefore,
    using all the training data in the forward and backward passes results in one
    gradient descent step per epoch.
  prefs: []
  type: TYPE_NORMAL
- en: Modern machine learning datasets are often massive, making it computationally
    infeasible to use all of the training data for each gradient descent step. Instead,
    a small, randomly selected subset of the data, known as a [*minibatch*](glossary.xhtml#glo67),
    is passed through the network for the forward and backward passes. Using minibatches
    dramatically reduces the computational overhead during gradient descent, resulting
    in many steps per epoch. Minibatches also provide another benefit that helps overcome
    the “this approach to training shouldn’t work” issue.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we had a mathematical function representing the error made by the network.
    In that case, we could use centuries-old calculus techniques to find the exact
    form of each weight and bias’s contribution to the error; gradient descent would
    know the best direction to step each time. Unfortunately, the world isn’t that
    kind. We don’t know the mathematical form of the error function (there isn’t likely
    one to know), so we have to approximate with our training data. This approximation
    improves when using more training data to determine the error. This fact argues
    for using all the training data for each gradient descent step. However, we already
    know this is computationally extremely taxing in many cases.
  prefs: []
  type: TYPE_NORMAL
- en: The compromise is to use minibatches for each gradient descent step. The calculations
    are no longer too taxing, but the approximation of the actual gradient is worse
    because we are estimating it with fewer data points. Randomly selecting something
    is often attached to the word “stochastic,” so training with minibatches is known
    as [*stochastic gradient descent*](glossary.xhtml#glo91). Stochastic gradient
    descent, in one form or another, is the standard training approach used by virtually
    all modern AI.
  prefs: []
  type: TYPE_NORMAL
- en: At first blush, stochastic gradient descent sounds like a losing proposition.
    Sure, we can calculate many gradient descent steps before the heat death of the
    universe, but our gradient fidelity is low, and we’re likely moving in the wrong
    direction through the error space. That can’t be good, can it?
  prefs: []
  type: TYPE_NORMAL
- en: Here’s where Fortuna smiles on humanity a second time. Not only has she given
    us the ability to train complex models with first-order gradient descent because
    local minima are (assumed) roughly equivalent; she’s also arranged things so that
    the “wrong” gradient direction found by stochastic gradient descent is often what
    we need to avoid local minima early in the training process. In other words, walking
    slightly northeast when we should head due north is a blessing in disguise that
    allows us to train large neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: '****'
  prefs: []
  type: TYPE_NORMAL
- en: We’re ready to move on to the next chapter. However, before we do, let’s apply
    traditional neural networks to the dinosaur footprint dataset. We’ll compare the
    results to the classical models of [Chapter 3](ch03.xhtml).
  prefs: []
  type: TYPE_NORMAL
- en: 'We need first to select an architecture: that is, the number of hidden layers,
    the number of nodes per layer, and the type of activation function for each node.
    The dinosaur footprint dataset has two classes: ornithischian (class 0) and theropod
    (class 1). Therefore, the output node should use a sigmoid activation function
    to give us a likelihood of class 1 membership. The network’s output value estimates
    the probability that the input image represents a theropod. If the probability
    is above 50 percent, we’ll assign the input to class 1; otherwise, into class
    0 it goes. We’ll stick with rectified linear unit activations for the hidden layer
    nodes, as we have for all the models in this chapter. All that remains is to select
    the number of hidden layers and the number of nodes per layer.'
  prefs: []
  type: TYPE_NORMAL
- en: There are 1,336 training samples in the footprints dataset. That’s not a lot,
    and we aren’t augmenting the dataset, so we need a smallish model. Large models,
    meaning many nodes and layers, require large training sets; otherwise, there are
    too many weights and biases to learn relative to the number of training samples.
    Therefore, we’ll limit ourselves to trying at most two hidden layer models for
    the footprints dataset. As for the number of nodes in the hidden layers, we’ll
    let the first hidden layer vary from very small to nearly twice the input size
    of 1,600 features (the 40×40-pixel image unraveled). If we try a second hidden
    layer, we’ll restrict the number of nodes to no more than half the number in the
    first hidden layer.
  prefs: []
  type: TYPE_NORMAL
- en: First, we’ll train a collection of one- and two-layer architectures. Second,
    we’ll train the best performing of those 100 times to give us an average level
    of performance. [Table 4-1](ch04.xhtml#ch04tab1) presents the trial models’ results.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 4-1:** Trial Architectures with the Dinosaur Footprint Dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Accuracy (%)** | **Architecture** | **Weights and biases** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 59.4 | 10 | 16,021 |'
  prefs: []
  type: TYPE_TB
- en: '| 77.0 | 400 | 640,801 |'
  prefs: []
  type: TYPE_TB
- en: '| 76.7 | 800 | 1,281,601 |'
  prefs: []
  type: TYPE_TB
- en: '| **81.2** | **2,400** | **3,844,801** |'
  prefs: []
  type: TYPE_TB
- en: '| 75.8 | 100, 50 | 165,201 |'
  prefs: []
  type: TYPE_TB
- en: '| **81.2** | **800, 100** | **1,361,001** |'
  prefs: []
  type: TYPE_TB
- en: '| 77.9 | 2,400, 800 | 5,764,001 |'
  prefs: []
  type: TYPE_TB
- en: The network with a mere 10 nodes in its hidden layer was the worst, returning
    an accuracy of about 60 percent. A binary classifier that does nothing but flips
    a coin is correct about 50 percent of the time, so the 10-node network is performing
    only slightly above chance. We don’t want that one. Most of the other networks
    return accuracies in the mid- to upper 70s.
  prefs: []
  type: TYPE_NORMAL
- en: The two models in **bold** each produced just over 81 percent accuracy. The
    first used a single hidden layer of 2,400 nodes. The second used a hidden layer
    of 800 nodes, followed by another with 100 nodes. Both models produced the same
    accuracy on the test set, but the 2,400-node model had nearly three times as many
    weights and biases as the two-layer model, so we’ll go with the two-layer model.
    (Bear in mind that the results in [Table 4-1](ch04.xhtml#ch04tab1) represent a
    single training session, not the average of many. We’ll fix that shortly.)
  prefs: []
  type: TYPE_NORMAL
- en: The two-layer model is still relatively large. We’re trying to learn 1.4 million
    parameters to condition the model to correctly classify the dinosaur footprint
    images. That’s a lot of parameters to learn, especially with a training set of
    only 1,336 samples. Fully connected neural networks grow quickly in terms of the
    number of parameters required. We’ll revisit this observation in [Chapter 5](ch05.xhtml)
    when discussing convolutional neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have our architecture: two hidden layers using rectified linear activation
    functions with 800 and 100 nodes, respectively, followed by a single node using
    a sigmoid to give us a likelihood of class 1 membership. Training the model 100
    times on the footprints dataset returned an average accuracy of 77.4 percent,
    with a minimum of 69.3 percent and a maximum of 81.5 percent. Let’s put this result
    in its proper relation to those of [Chapter 3](ch03.xhtml); see [Table 4-2](ch04.xhtml#ch04tab2).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 4-2:** Dinosaur Footprint Models'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Model** | **Accuracy (%)** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| RF300 | 83.3 |'
  prefs: []
  type: TYPE_TB
- en: '| RBF SVM | 82.4 |'
  prefs: []
  type: TYPE_TB
- en: '| 7-NN | 80.0 |'
  prefs: []
  type: TYPE_TB
- en: '| 3-NN | 77.6 |'
  prefs: []
  type: TYPE_TB
- en: '| **MLP** | **77.4** |'
  prefs: []
  type: TYPE_TB
- en: '| 1-NN | 76.1 |'
  prefs: []
  type: TYPE_TB
- en: '| Linear SVM | 70.7 |'
  prefs: []
  type: TYPE_TB
- en: Recall that RF300 means a random forest with 300 trees, SVM refers to a support
    vector machine, and, somewhat confusingly, NN refers to a nearest neighbor classifier.
    I’m using MLP (multilayer perceptron) as a stand-in for our neural network. [*Multilayer
    perceptron*](glossary.xhtml#glo70) is an old but still common name for the traditional
    neural networks we’ve been discussing in this chapter—notice the link back to
    Rosenblatt’s original Perceptron from the late 1950s.
  prefs: []
  type: TYPE_NORMAL
- en: Our neural network wasn’t the best performer on this dataset. In fact, it was
    one of the worst. Additional tweaking might move it up a place or two on the list,
    but this level of performance is typical, in my experience, and contributed to
    the general perception (pun intended) before the deep learning revolution that
    neural networks are “meh” models—run-of-the-mill, nothing to write home about.
  prefs: []
  type: TYPE_NORMAL
- en: '****'
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter introduced the fundamental ideas behind modern neural networks.
    The remainder of the book builds on the basic concepts covered in this chapter.
    Here are the principal takeaways:'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks are collections of nodes (neurons) that accept multiple inputs
    and produce a single number as output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks are often arranged in layers so that the current layer’s input
    is the previous layer’s output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks are randomly initialized, so repeated training leads to differently
    performing models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks are trained by gradient descent, using the gradient direction
    supplied by backpropagation to update the weights and biases iteratively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s press on to investigate convolutional neural networks, the architecture
    that ushered in the deep learning revolution. This chapter brought us to the early
    2000s. The next moves us to 2012 and beyond.
  prefs: []
  type: TYPE_NORMAL
- en: '**KEY TERMS**'
  prefs: []
  type: TYPE_NORMAL
- en: activation function, architecture, backward pass, bias, data augmentation, epoch,
    forward pass, global minimum, gradient descent, hidden layer, learning rate, local
    minimum, loss, minibatch, multilayer perceptron, neuron, node, overfitting, preprocessing,
    rectified linear unit, regularizer, sigmoid, stochastic gradient descent, weight
  prefs: []
  type: TYPE_NORMAL
