- en: <hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: 12 BINARY TREES
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: </hgroup>
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/opener.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We’ve considered linear structures in previous chapters, and now we’ll start
    working with more complex structures—in particular, binary trees and some variants.
    (We’ll explore more general trees in the next chapter.) Binary trees find their
    way into lots of places, including data compression algorithms, video games, cryptographic
    techniques, compilers, and more, so they are a structure well worth knowing.
  prefs: []
  type: TYPE_NORMAL
- en: A special variety, binary search trees, can be quite efficient for implementing
    the bags or sets we explored in the previous chapter. However, since those kinds
    of trees can, on occasion, provide not-so-good performance, we’ll also consider
    some variants, such as assuredly balanced binary search trees (AVL trees) and
    probabilistically balanced trees (randomized binary search trees and splay trees).
  prefs: []
  type: TYPE_NORMAL
- en: '### What Are Trees?'
  prefs: []
  type: TYPE_NORMAL
- en: Trees allow you to represent hierarchical data structures. They differ from
    linear structures because a node can be connected to several other nodes, albeit
    with some restrictions. Organizational charts (or *organigrams*) are well-known
    examples of trees where a section of an enterprise can have several subsections,
    which themselves may have sub-subsections, and so on, in a recursive fashion,
    such as shown [Figure 12-1](chapter12.xhtml#fig12-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-1: An organigram from NASA, November 1961\. Don’t worry if the text
    is unreadable; the structure is the important part, not the labels. (From [https://commons.wikimedia.org/wiki/File:NASA_Organizational_Chart_November_1,_1961.jpg](https://commons.wikimedia.org/wiki/File:NASA_Organizational_Chart_November_1,_1961.jpg).)'
  prefs: []
  type: TYPE_NORMAL
- en: HyperText Markup Language (HTML) also has a treelike structure. An HTML element
    can contain several other elements, which may themselves include further elements.
    Directories on your computer employ a tree structure as well. A directory has
    files and more directories, which themselves have files and more directories,
    and so on. (See question 12.2 at the end of this chapter for an exception.)
  prefs: []
  type: TYPE_NORMAL
- en: '#### General Trees'
  prefs: []
  type: TYPE_NORMAL
- en: A tree can be empty or consist of a node (called the *root* of the tree) that
    has several subtrees, each of which may be empty, of course. The root is the *parent*
    of its subtrees, and the roots of those subtrees are *children* of the root. The
    *nodes* that form a tree are connected by *edges* or *arcs*. Nodes with both parents
    and children are called *internal nodes*, and nodes without children are called
    *external nodes* or (more appropriately for the tree motif) *leaves*. Given a
    node, its children, and the children of those children, and so on are called its
    *descendants*. Similarly, the parent of a node, and the parent of that parent,
    and so on are called the node’s *ancestors*. The *level* of the tree’s root is
    1, its children are level 2, the children of those children are level 3, and so
    on. The number of a node’s nonempty children is called its *degree*. Finally,
    for any tree or subtree, its *size* is the number of its nodes, and its *height*
    is the number of nodes in the longest path from the root to a leaf.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*From the previous definitions, it follows that there can be at most one path
    between any two nodes; trees cannot have any cycles or loops anywhere. Another
    property is that given any two nodes, either one is an ancestor of the other or
    they both have a common ancestor.*'
  prefs: []
  type: TYPE_NORMAL
- en: Trees are usually represented with the root at the top and the leaves at the
    bottom. Even if this goes against biology, we’ll follow that style. A possible
    tree could look like [Figure 12-2](chapter12.xhtml#fig12-2) (with the root at
    the top and all links going downward).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-2: Trees are usually shown with the root at the top, branching down
    to the leaves, despite what biology teaches.'
  prefs: []
  type: TYPE_NORMAL
- en: We’ll consider general trees (that is, those with any number of subtrees in
    any node) in the following chapter, so here we’ll focus on the most common version,
    binary trees.
  prefs: []
  type: TYPE_NORMAL
- en: Binary Trees
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A *binary tree* is either empty or has exactly two subtrees. We’ll see some
    additional definitions later, so the tree in [Figure 12-2](chapter12.xhtml#fig12-2)
    actually could be a binary tree. A binary tree is *full* if every node either
    is a leaf or has two nonempty children. [Figure 12-3](chapter12.xhtml#fig12-3)
    shows a possible case.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-3: A full binary tree: all nodes have zero or two children.'
  prefs: []
  type: TYPE_NORMAL
- en: Full binary trees aren’t really that interesting unless they also satisfy some
    other properties. For example, if a tree is full and all leaves are at the same
    level, it’s called a *perfect* binary tree, which implies that nodes are packed
    as tightly as possible, as shown in [Figure 12-4](chapter12.xhtml#fig12-4).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-4: A perfect binary tree is full and has all leaves at the same level.'
  prefs: []
  type: TYPE_NORMAL
- en: An interesting property, which a little math easily proves, is that the size
    of a perfect binary tree of *h* height is 2*^h* – 1, so adding a new level approximately
    doubles the tree’s size. Conversely, the height of a perfect tree with *n* nodes
    is log *n*, rounded up. (We are using logarithms in base 2.)
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if you have a tree of *h* height that becomes perfect if you eliminate
    all nodes at level *h* (with the allowed exception of the last level), it’s called
    a *complete* tree. We’ll look at some of those structures later in [Chapter 14](chapter14.xhtml),
    when we study heaps. [Figure 12-5](chapter12.xhtml#fig12-5) shows a complete tree,
    because if you were to remove all the nodes at the bottom level, you’d be left
    with a perfect tree.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-5: A complete tree would become a full tree if the bottom leaves
    were removed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With the generic definitions out of the way, let’s get started with binary
    trees. We’ll include a key in each node, and you can add more data attributes
    if needed. We’ll also have left and right pointers to the subtrees: each may either
    be null or point to another binary tree. Let’s start writing a binary tree module
    (you’ll reuse some of these methods here for binary tree variants later):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'There’s not much to this code: newTree() ❶ builds an initially empty tree;
    newNode() ❷ creates a new node with a given key and (by default null) subtrees;
    and isEmpty() ❸ detects whether a tree is empty (no surprise here).'
  prefs: []
  type: TYPE_NORMAL
- en: Binary Search Trees
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For the remainder of this chapter, we’ll use *binary search trees*, which are
    a variant of binary trees, to implement the *bag* or *set* abstract data type
    (ADT), because they provide very efficient searching for keys. (Remember, the
    difference is that bags allow repeated values, but sets don’t.) For these trees,
    each node will be an object with a key, plus some links to point at its children;
    in practice, you could also include an extra data field in a node for other usages.
    [Table 12-1](chapter12.xhtml#tab12-1) describes the ADT.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12-1: Operations on Sets'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Signature | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | → set | Create a new set. |'
  prefs: []
  type: TYPE_TB
- en: '| Empty? | set → boolean | Given a set, determine if it is empty. |'
  prefs: []
  type: TYPE_TB
- en: '| Add | set × value → set &#124; error | Given a new value, add it to the set.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | set × value → set | Given a value, remove it from the set. |'
  prefs: []
  type: TYPE_TB
- en: '| Find | set × value → boolean | Given a value, check if it exists in the set.
    |'
  prefs: []
  type: TYPE_TB
- en: 'What’s the difference between a binary tree and a binary search tree? Binary
    search trees satisfy the following property: for all nodes, the left subtree has
    only smaller keys and the right subtree has only greater keys. If you decide to
    allow duplicate keys, you need to amend the condition to say that the left subtree
    has smaller or equal keys and the right subtree has greater or equal keys. In
    [Figure 12-6](chapter12.xhtml#fig12-6), one of the trees is a binary search tree,
    but the other is not because of a single unlucky detail. Can you tell which is
    which?'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-6: Two binary trees, but only one is a binary search tree. Which
    is it?'
  prefs: []
  type: TYPE_NORMAL
- en: The bottom tree isn’t a binary search tree, because the 13 key is to the right
    of key 22, and it should be to its left. Can you figure out exactly where it should
    go?
  prefs: []
  type: TYPE_NORMAL
- en: This property regarding keys of roots and subtrees is what allows you to use
    binary search trees as sets.
  prefs: []
  type: TYPE_NORMAL
- en: Finding a Key in a Binary Search Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The recursive property regarding the relation of keys (which also applies to
    every subtree) provides a simple searching method. If you are looking for a given
    value in a binary search tree, one of three situations must happen:'
  prefs: []
  type: TYPE_NORMAL
- en: If the value is the key at the root of the tree, you’re done.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Otherwise, if the value is smaller than the key at the root, the value (if present)
    must be in the left subtree.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, if the value is greater than the key at the root, the value must be
    in the right subtree.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can test this. [Figure 12-7](chapter12.xhtml#fig12-7) shows a successful
    search for 12, highlighting the path that was taken and all the visited nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-7: A successful search for key 12 in a binary search tree'
  prefs: []
  type: TYPE_NORMAL
- en: The search starts at the root. Since 12 < 22, it moves to the left subtree.
    There, since 12 > 9, it proceeds to the right subtree. Then, as 12 > 11, it again
    goes to the right subtree, and the key is found. If you had been looking for 34
    instead, the search would have failed, as shown in [Figure 12-8](chapter12.xhtml#fig12-8).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-8: A failed search for key 34 in a binary search tree'
  prefs: []
  type: TYPE_NORMAL
- en: Since 34 > 22, the search starts down the root’s right subtree; next, as 34
    < 56, it goes to the left. Then, as 34 > 24, it tries to go to the right but finds
    an empty tree (shown with a dotted border), so the search was unsuccessful.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can code this logic straightaway, even before considering how you would
    do additions or deletions to a tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Since trees are recursive by definition, it should be no surprise that this
    algorithm (and most others in this chapter) is implemented using recursion. There
    are two base cases: if the tree is empty ❶, the key isn’t in the tree, and if
    the key matches the value you’re looking for ❷, the search succeeds. But how do
    you keep searching? If the key you’re looking for is smaller than the key at the
    root, you recursively search the left subtree, and the right subtree otherwise
    ❸.'
  prefs: []
  type: TYPE_NORMAL
- en: Adding Values to a Binary Search Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: How can we add a new key to a tree? Let’s work with a bag, and accept repeated
    keys; you’ll see how to do a set too. Be careful not to disturb the relationship
    between the root key and those of its subtrees—using a recursive algorithm is
    the best way to do this. If the tree is empty, you can simply add a new leaf to
    it. If the tree isn’t empty, apply recursion to go down the left or right subtree,
    depending on where the new key should be, until you reach an empty tree where
    you can insert the new key.
  prefs: []
  type: TYPE_NORMAL
- en: The previous section showed a failed search for a 34 key, so now the new key
    would be added at the place where the search ended, as shown in [Figure 12-9](chapter12.xhtml#fig12-9).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-9: Adding a new key to a binary search tree at the place where it
    should have been found in a search'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If the tree is empty ❶, create a new node with the key to add, and that will
    be the root. If the tree isn’t empty, decide which of its subtrees must add the
    new key ❷ and proceed recursively from there. (If implementing a set instead of
    a bag, you should check whether keyToAdd equals tree.key, and in that case reject
    the addition; see question 12.16.) This example uses a different coding style
    from the one in find() just for variety.
  prefs: []
  type: TYPE_NORMAL
- en: Removing Values from a Binary Search Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now let’s look at how to remove a key from a binary search tree. Consider the
    tree shown in [Figure 12-10](chapter12.xhtml#fig12-10).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-10: A binary search tree before deleting some keys'
  prefs: []
  type: TYPE_NORMAL
- en: If you try to remove a key that you can’t find in the tree, you don’t need to
    do anything. Easy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another simple case is removing a leaf: just remove its key, which makes it
    an empty tree. For instance, removing 10 would result in the following situation,
    where 11 ends up with an empty left subtree, as shown in [Figure 12-11](chapter12.xhtml#fig12-11).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-11: Removing a leaf (key 10, in this case) is straightforward.'
  prefs: []
  type: TYPE_NORMAL
- en: However, things can get complicated. For example, if you want to remove a node
    that has at most one child, that’s still easy. Just replace it with its child,
    as in [Figure 12-12](chapter12.xhtml#fig12-12), where the 24 key was removed by
    making the 23 key the left child of the 56 key.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-12: Removing a key (in this case, 24) with only one child is also
    straightforward.'
  prefs: []
  type: TYPE_NORMAL
- en: A complex problem is dealing with a node that has two nonempty children. The
    most common solution is to find the key immediately following it, remove it, and
    put it in place of the node you wanted to remove. For instance, if you want to
    remove the 9 key in [Figure 12-12](chapter12.xhtml#fig12-12), since that node
    has two subtrees, you would search for the next higher key (in this particular
    example, 10), remove it, and put it into the 9 key’s place, as shown in [Figure
    12-13](chapter12.xhtml#fig12-13).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-13: Removing a key (here, 9) is the hardest case; you have to put
    another key in its place to maintain the binary search tree structure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This method of replacing the removed key doesn’t break the search rules. There’s
    a missing step, though—namely, how to find the next higher key. We’ll get to that
    in the next section, but first here’s the code to remove a key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The first three conditions ❶ ❷ ❸ match the find() method: check for an empty
    tree; if you haven’t found the key to delete, proceed to a subtree recursively.
    The next case ❹ deals with removing a leaf: set the tree to null. The next two
    conditions ❺ ❻ deal with nodes that have a single child; set the tree to that
    child. Finally, in the last case ❼ you must find the key ❽ that follows the one
    you want to delete and use it to replace that key and then finish by recursively
    deleting that key from the right subtree ❾. You can complete the algorithm by
    considering how to find the next higher key.'
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This is not the only way to do a deletion; we’ll see more in the sections
    “Removing a Key from a Randomized Tree” on [page 267](chapter12.xhtml#pg_267)
    and “Removing a Key from a Treap” on [page 336](chapter14.xhtml#pg_336).*'
  prefs: []
  type: TYPE_NORMAL
- en: Finding the Minimum or Maximum Value in a Binary Search Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Because of the relationship between the root and its subtrees, the needed key
    (the following key) must be the minimum value of the right subtree. (Conversely,
    the previous key would be the maximum value of the left subtree.) [Figure 12-14](chapter12.xhtml#fig12-14)
    shows how to look for the key following the 9 key. You need to go to its right
    subtree and then go left until you can’t move in that direction any longer to
    find the 10 key.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-14: Finding the following key; here, you want the minimum key greater
    than 9.'
  prefs: []
  type: TYPE_NORMAL
- en: For a different example, if you wanted to find the *previous* key to 23, you
    would go to its *left* subtree and then move *right* until reaching the end to
    find the 22 key. Keep in mind that this logic works only for nodes that have the
    necessary subtrees. If you want to find the next key of, say, 11, 12, or 22, the
    logic would fail. Fortunately, this doesn’t apply to cases in which you want to
    find the next higher key.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can take advantage of similar logic to implement both minKey() and maxKey():'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: First look at minKey(), which is what you wanted in this case; maxKey() is analogous.
    You have an auxiliary _minMax() method that does the actual searching ❶ based
    on whatever arguments minKey() and maxKey() pass to it. Looking for the minimum
    requires always going to the left, so that takes care of the second parameter
    of _minMax(), which will go down that side ❹ until an empty tree is found ❸. Now,
    if you try to find the minimum of an empty tree ❷, what value should be returned?
    You’ll do the same thing the Math.min() function does; if you call it without
    any arguments, it returns Infinity (similarly Math.max() === -Infinity), so that’s
    the third parameter of _minMax().
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*If you analyze the removal algorithm, you may decide that it does more work
    than needed because it travels down the right subtree once to find the next key
    and then processes the same subtree again to remove the found key. Why not do
    both things at once? See question 12.17 for this optimization.*  ##### Traversing
    a Binary Search Tree'
  prefs: []
  type: TYPE_NORMAL
- en: 'Many processes involve accessing all nodes of a tree (also called *traversing*
    a tree or doing a *tree traversal*) to do something with each—for example, you
    could have stored words in a binary search tree and want to produce an alphabetically
    ordered listing of them. This is called *visiting* the nodes. If you don’t want
    to exclude any nodes, three possible scenarios exist for such a general visitation
    (the pre-, in-, and post- prefixes in these traversal methods are related to when
    the root is visited):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preorder **Visit the root of a tree, then traverse its left subtree, and
    finally traverse its right subtree.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inorder **Traverse the left subtree first, then visit the root, and finally
    traverse the right subtree.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Postorder **Traverse the left subtree first, then traverse the right subtree,
    and finish by visiting the root.'
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you traverse an empty tree by doing nothing at all, as visiting applies
    only to existing keys. Also, note that traversal of subtrees is done by recursively
    applying the same traversal algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a basic algorithm where the default visit() method just prints the visited
    key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The code follows the description: for example, preOrder() first visits the
    root, then traverses the left subtree, and it finally traverses the right subtree.'
  prefs: []
  type: TYPE_NORMAL
- en: For debugging purposes, it’s useful to be able to print the list of the tree’s
    keys in ascending order. If you have a tree and call inOrder(), all keys are listed
    in order. It starts at the root and processes all the keys less than the root
    (listing them in order). Next, it prints the root, and then it processes all the
    keys greater than the root (also listing them in order), providing the desired
    result.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This algorithm is similar to quicksort from [Chapter 6](chapter6.xhtml). You
    have a left set of keys, which you order. Then you have the pivot, and then you
    have a right set of keys, which you also order, and the result is the complete
    ordered array.*'
  prefs: []
  type: TYPE_NORMAL
- en: Getting a list of keys is fine, but seeing the structure is better, so you want
    to get a printout of it. Consider the tree in [Figure 12-15](chapter12.xhtml#fig12-15).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-15: A binary search tree for which we want to print out its structure'
  prefs: []
  type: TYPE_NORMAL
- en: 'You could use console.log() for the printout, but that’s not too user friendly;
    console.dir()is a tad better. You could try something like console.log(JSON.stringify(tree)),
    but that’s really hard to read; you get some very unfriendly output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To understand the tree’s structure, consider a print() method based on the
    preorder code. It prints the root first, on one line, followed by its left subtree
    (with an L: preceding it to signify the left subtree), and then the right subtree
    (with an R:), indenting children to the right, and children’s children even more,
    and so forth.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting content was similar to the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The root (22) is at the top, followed by L: 9 (and further below, R: 60), showing
    both of the root’s children. For each new key, you also see its children, further
    indented, so it’s clear enough for debugging.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code to produce this output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If you compare the logic with the earlier preOrder() method, it’s the exact
    same idea: do something with the key first, and then process its left and right
    subtrees in order.'
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance for Binary Search Trees
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now that we’ve looked at binary search tree algorithms in detail, what about
    their performance? Let’s start with the *worst* possible case. The most dreadful
    situation you might get after adding several keys to a tree is some kind of linear
    structure like the one shown in [Figure 12-16](chapter12.xhtml#fig12-16), which
    in searching terms basically is equivalent to simple linked lists with *O*(*n*)
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-16: Some worst-case binary search trees'
  prefs: []
  type: TYPE_NORMAL
- en: Going back to the shapes we’ve looked at earlier, it’s obvious that a tree’s
    shape impacts an algorithm’s performance. The perfect tree is best, which would
    be *O*(log *n*). With linear-like structures, searches would become *O*(*n*),
    and for large trees, that’s a huge difference.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of probability, if you take a set of keys in random order, it can be
    proved that most of the trees will be relatively short in height, and bad cases
    will be relatively few. While the worst case would still be *O*(*n*), on average,
    we expect *O*(log *n*) performance. [Table 12-2](chapter12.xhtml#tab12-2) shows
    average and worst-case performance for the tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12-2: Performance of Operations for Binary Search Trees'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Average performance | Worst case |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | O(1) | O(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Add | O(log n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | O(log n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Find | O(log n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Traverse | O(n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: What can you do about that? We’ll look at two options in the following sections
    that attempt to ensure that the tree never reaches a bad shape and stays as short
    and balanced as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Assured Balanced Binary Search Trees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we saw earlier, a tree can become a linear (or almost linear) structure,
    and its performance will be quite poor. It’s possible to ensure that a tree is
    kept in balance, however, guaranteeing optimum performance. Here are two different
    ways of dealing with this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Assured balanced trees* become efficient because they follow some explicit
    structural constraint that never lets trees get out of shape, but they imply extra
    running time and memory usage, needing more complex algorithms—usually add() and
    remove()—to ensure that the constraints still apply after modifying the tree.
    These trees offer a consistent performance in an absolute (neither amortized nor
    probabilistic) way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Probabilistically balanced trees* (or *self-adjusting trees*) are efficient
    only in an amortized sense. They do not follow any explicit structure rule, but
    they can be in any possible shape, depending on methods like add() or find() to
    adjust the structure in such a way that it most likely improves over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Height-balanced *AVL trees* do not let trees get out of balance by forcing both
    subtrees of any node to assuredly have approximately the same height. Weight-balanced
    trees also offer assured balance, by keeping the weights of both subtrees of any
    node within a given factor of each other; we’ll consider bounded balance (BB[α])
    trees later.
  prefs: []
  type: TYPE_NORMAL
- en: AVL Trees
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'AVL trees, invented by Adelson-Velsky and Landis in 1962, are well balanced
    by following a simple rule: *for all nodes, the heights of their left and right
    subtrees must differ at most by one*. This automatically rules out all the badly
    performing shapes of binary trees.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 12-17](chapter12.xhtml#fig12-17) shows a correctly balanced tree and
    an unbalanced one. Which is which?'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-17: Two binary trees, but only one is balanced. Which is it?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The rightmost tree is well balanced, and the leftmost tree is not, because
    the left child of the root is out of balance: its left subtree has a height of
    3, and its right subtree has a height of 1\. The balance of a node is the difference
    in heights between its right subtree and left subtree, so the balances in the
    correct tree in [Figure 12-17](chapter12.xhtml#fig12-17) would be as the one shown
    in [Figure 12-18](chapter12.xhtml#fig12-18).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-18: The balanced binary tree showing the balances for all nodes'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve looked at the desired shape of AVL trees, you can code them.
  prefs: []
  type: TYPE_NORMAL
- en: Defining an AVL Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We’ll base the AVL trees on binary search trees. Several of the operations
    will still work—for instance, finding a key in an AVL tree is exactly the same,
    so we won’t see that code again here. There’s a slight difference though: you
    need to add a _height attribute to each node to help check whether it’s in balance,
    and you need code to access or calculate that attribute. The basic code starts
    as follows—note that you are reusing some methods of basic binary search trees:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: When constructing a new node, add the new _height attribute ❶, and then have
    a _getHeight() method to access it; take care so the height of an empty tree is
    0 ❷. The new _calcHeight() method ❸ calculates the height of a node; assume both
    subtrees already have their own heights calculated, and the height of the total
    tree is one more than the height of its tallest subtree. Finally, calculate the
    balance of a node ❹ as the difference between the height of its right and left
    subtrees. That balance can be only –1, 0, or 1; other values imply an unbalanced
    tree.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Key to an AVL Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'To add a new key, the logic is similar to what we already saw, except for a
    single factor: after deciding where to add the new key, the tree may become out
    of balance, so you need to move nodes around to restore it. Here’s the additional
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This is exactly the same code as for binary search trees, except it adds a final
    _fixBalance() call that takes care of balancing the tree if needed. Before getting
    to that part, let’s review how to remove keys, which is also quite similar to
    what you did previously.
  prefs: []
  type: TYPE_NORMAL
- en: Removing a Key from an AVL Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'After seeing how to add a new key, removing a key will look familiar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As with adding a key, the only difference with the previous code is at the end
    where you apply the balance fix.
  prefs: []
  type: TYPE_NORMAL
- en: Rotating Nodes in an AVL Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Adding or removing nodes essentially uses the same logic as for common binary
    search trees, but without intervention, the trees are likely to fall out of balance.
    The solution is to apply *rotations* that won’t affect searching but will restore
    balance.
  prefs: []
  type: TYPE_NORMAL
- en: The two basic tree rotations are symmetrical, as shown in [Figure 12-19](chapter12.xhtml#fig12-19),
    where the minus sign represents a smaller key value than the plus sign. After
    any of the rotations, the tree still allows searching, but the height and balance
    may change, and this allows you to restore an AVL tree.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-19: The two symmetrical rotations that can be used to solve balance
    issues'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rotating from left to right is a right rotation and from right to left is a
    left rotation. To remember which rotation is which, notice the direction the old
    root moves: in a right rotation, the root becomes its own right subtree, and in
    a left rotation, the root becomes its own left subtree. Another way of looking
    at it is in a right rotation, the node that was on the left becomes the root (that
    is, it moved to the right), and the root becomes a subtree, and in a left rotation,
    the node on the right becomes the root.'
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*If you search for more information on tree rotations, you’ll find many inconsistencies,
    and in some cases, what we call a right rotation, other sources call a left one,
    so be careful.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two possible cases when rotations are needed: one needs a single
    rotation, and the other requires two. In the first case (shown in [Figure 12-20](chapter12.xhtml#fig12-20)),
    the tree was balanced, but a new key was added in subtree A, making it taller,
    which put the whole tree out of balance. (Alternatively, you could have removed
    a key from subtree C, making it shorter.) In this case, the problem occurs at
    the left subtree of the left child of the root or, symmetrically, at the right
    subtree of the right child. These situations are logically called *left-left*
    and *right-right*.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-20: Using a right rotation to fix the unbalanced node with key 60'
  prefs: []
  type: TYPE_NORMAL
- en: The solution is to apply a right rotation to the root of the left subtree (because
    the imbalance happened at the left subtree), which results in a balanced situation.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 12-21](chapter12.xhtml#fig12-21) shows a more complex scenario. A new
    key was added at the right subtree of the left subtree of the root, throwing the
    latter out of balance. This *left-right* case and its mirrored *right-left* case
    need two rotations to be fixed.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-21: Fixing balance in a harder case needs a left rotation first (at
    the 9 key node) and then a right rotation (at the 60 key node).'
  prefs: []
  type: TYPE_NORMAL
- en: A first left rotation brings the lowest key (22, in this case) closer to the
    root, and now a right rotation takes it all the way up, restoring balance. [Figure
    12-21](chapter12.xhtml#fig12-21) shows the scenario where the addition was in
    B; if it had been in C, the solution still would be the same, and it would also
    apply if instead of an addition, you had removed a key from D, making it shorter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now consider the code to rotate a node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: You start by finding the “other” side for the rotation ❶, and you also get a
    reference to the node on the side of the root ❷ (the one that will become the
    root of the tree) to make the code briefer. Then, you exchange some pointers ❸
    and finish by recalculating the heights of the two involved nodes; it’s important
    to do the “lower” node ❹ first.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*If you call* _rotate() *with a* left *parameter, it actually does a right
    rotation, which may be a bit confusing. The idea is you’re saying which node should
    become root. So for a right rotation, the left child moves up to be the root.
    In some algorithms, you’ll see that this is more natural.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s finish by providing the missing _fixBalance() method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: If the tree is empty ❶, there’s nothing to do. Otherwise, recalculate the root’s
    height ❷ (since the recent addition or removal may have changed it), and also
    find the node’s balance ❸. If the node is imbalanced on the left ❹, check whether
    an extra rotation is needed ❺ and do it if necessary, ending with a single rotation
    ❻. The other if is just the symmetrical case ❼, and it does the same things, but
    the sides are reversed.
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance for AVL Trees
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Given the assured balance that the structure of AVL trees provides, all the
    operations (adding, removing, finding) have the same logarithmic performance.
    There’s no different worst case, as shown in [Table 12-3](chapter12.xhtml#tab12-3).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12-3: Performance of Operations for AVL Trees'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Average performance | Worst case |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | O(1) | O(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Add | O(log n) | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | O(log n) | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Find | O(log n) | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Traverse | O(n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: It can be proved that the height of an AVL tree is bounded by 1.44 log *n*,
    and that also confirms the performance listed earlier (see question 12.18). In
    the next chapter, you’ll look at *red-black trees*, which have similar restrictions
    and performance but are based on multiway trees. Searches may be a tad slower
    (because those trees may be taller) and insertions a bit faster (requiring fewer
    rotations), but overall, the results are the same.
  prefs: []
  type: TYPE_NORMAL
- en: Weight-Bounded Balanced Trees
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Instead of making sure that the heights of both subtrees of any node are within
    1 of each other, *weight-bounded balanced (BB[α])* trees maintain a different
    invariant: that the *weights* (size of the tree plus 1) in the left and right
    subtrees are in a specific relationship. If a tree has size *n* and its subtrees
    have sizes *p* and *q*, you then have (*p* + 1) ≥ α(*n* + 1) and (*q* + 1) ≥ α(*n*
    + 1), with 0 < α < 0.5.'
  prefs: []
  type: TYPE_NORMAL
- en: An equivalent way of looking at this is requiring that (*p* + 1) / (*n* + 1)
    ≥ α and (*q* + 1) / (*n* + 1) ≥ α. Since both fractions add up to 1 (see question
    12.20), this is the same as saying that both subtrees must satisfy α ≤ weight(subtree)
    / weight(tree) ≤ 1 – α. The quotient in the middle is called the *balance* of
    the subtree. [Figure 12-22](chapter12.xhtml#fig12-22) shows a BB[0.29289] tree
    where keys from 1 to 12 were inserted in ascending order; the numbers on the edges
    show the balance of the corresponding subtree.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-22: A weight-bounded balanced tree (BB[0.29289] in this case) showing
    the calculated balance for every node with children'
  prefs: []
  type: TYPE_NORMAL
- en: The value α = 0.5 sounds like a perfect balance (for all nodes, the right and
    left subtrees would be of equal sizes), but it has been proven that it doesn’t
    really work, and not every value of α does. The α should be between 0.18182 (=
    2/11) and 0.29289 (= 1 – √2/2) for balancing to work.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*When we defined the weight of a node and added 1 to its size, if it weren’t
    for that additional 1, it would be impossible to have a weight-balanced tree of
    just two nodes. Can you see why?*'
  prefs: []
  type: TYPE_NORMAL
- en: A BB[α] tree needs to carry the extra data of its size in every node in order
    to calculate its weight. This is necessary for balancing (so you can check the
    balance condition given previously), but it’s also useful for other operations,
    such as finding a key by its rank.
  prefs: []
  type: TYPE_NORMAL
- en: When adding to or removing keys from the tree, if balance is not kept, we apply
    rotations (as in AVL trees) to restore balance. Since BB[α] trees are binary search
    trees, the find operation and traversals work without any changes. You need to
    consider only additions and removals.
  prefs: []
  type: TYPE_NORMAL
- en: Defining a Weight-Bounded Balanced Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'These new trees and AVL trees share a lot of code. The biggest difference is
    that instead of including the height of a tree in each node, we include a size
    attribute and fix the balance by considering sizes instead of heights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: When creating a new node, set its size to 1 ❶ instead of a height attribute.
    And instead of functions related to getting or calculating heights, you have a
    function as a getter for the tree’s previously calculated size ❷, another function
    to calculate the size of any tree ❸, and a third one to calculate the balance
    of a subtree ❹, which you’ll need for balance fixing.
  prefs: []
  type: TYPE_NORMAL
- en: Adding and Removing Keys to and from a Weight-Bounded Balanced Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'I mentioned there would be a surprise, and it’s that adding or removing keys
    is done in exactly the same way as for AVL trees. Look at the code from the previous
    section. When adding a new key, you did it in the standard way (that is, the same
    way as for binary search trees), and you finished by calling a function to fix
    the balance, if needed. The only difference here is that the latter function will
    be implemented in another way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Deleting a key worked the same way. You first applied the standard binary search
    tree algorithm and, at the end, called the same function as with additions to
    restore balance whenever required.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll see the exact same process here; the only difference is how you restore
    balance.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing Balance in a Weight-Bounded Balanced Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The original paper that described BB[α] trees shows (with math that’s not included
    here) that there are two possible cases (plus their symmetrical ones) and that
    simple or double rotations are enough to restore balance. Now consider cases where
    a node has an overweight left subtree; the symmetrical cases are handled the same
    way.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, a review of some conditions. The balance of a subtree should be α ≤
    balance(subtree) ≤ 1 – α. Several constants will be used when balancing, but we
    won’t derive the values here:'
  prefs: []
  type: TYPE_NORMAL
- en: α is the underweight limit; if a subtree’s balance is below α, the tree is out
    of balance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: β = 1 – α is the overweight limit; if a subtree’s balance is above β, there’s
    also an imbalance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: γ = α/β = α / (1 – α) is the underweight limit for a subtree’s child.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: δ = 1 – γ = (1 – 2α) / (1– α) is the overweight limit for a subtree’s child.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code defines the values (the comments show the approximate value
    of each constant):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Now, you will fix unbalanced trees. The first situation is shown in [Figure
    12-23](chapter12.xhtml#fig12-23). The left subtree has grown too much (or the
    right subtree has decreased in size), so the tree is not in balance. You can calculate
    the balance of the right subtree of the left subtree (B) and find it is below
    δ, so it’s not overweight. In this case, a single rotation to the right (shoving
    the B subtree to the right, which must have been underweight) rebalances the tree.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-23: A single rotation fixes balance issues in some cases.'
  prefs: []
  type: TYPE_NORMAL
- en: The second situation is a bit more complex. The left subtree is overweight,
    and the balance of its left subtree’s right subtree exceeds the δ value. A single
    rotation wouldn’t be enough to restore balance (the tree would still be out of
    balance), and in this case, a double rotation is needed to bring everything back
    to normal. Note that part of the overweight subtree is sent to the right (C),
    and the other part (B) remains on the left, as shown in [Figure 12-24](chapter12.xhtml#fig12-24).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-24: Two rotations are needed to fix balance in more complex situations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the logic for deciding whether rotations are needed (and which) is this:
    first check both children to see if either is overweight (say it’s the left one)
    by comparing its balance to β. Then check whether the other side’s grandchild
    (the right child of the left child) is overweight, but compare its balance to
    a different limit of δ. Depending on the result of the second check, you’ll do
    one or two rotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If the tree isn’t empty, start by updating its size ❶. Then, first check whether
    the left child is overweight ❷; if so, do a second check for the right child of
    the left child ❸, and if that tree is also overweight, do the first of two rotations
    ❹; then do the rotation to the right ❺ that will finish the job. If the left child
    wasn’t overweight, check the right child ❻, and the logic is symmetric to the
    cases noted earlier ❹ ❺.
  prefs: []
  type: TYPE_NORMAL
- en: 'You now know how to update the tree by adding or removing keys, but BB[α] trees
    allow other operations as well, including finding by rank, splitting a tree in
    two, or joining two trees into one.  ##### Finding an Element by Rank in a Weight-Bounded
    Balanced Tree'
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned previously, having the size of each tree at its root, which is
    needed by BB[α] trees for balancing purposes, provides an extra benefit, because
    it allows further operations with good performance. Consider one here: finding
    an element (in this case, the seventh) by rank, as you saw in [Chapter 11](chapter11.xhtml).
    The tree in [Figure 12-25](chapter12.xhtml#fig12-25) is the same as [Figure 12-22](chapter12.xhtml#fig12-22),
    but now the subtrees’ sizes are shown next to each node.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-25: Including the size of each subtree at its root allows you to
    find an element by rank in an efficient way; here you’re looking for the seventh
    key.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The left subtree has three elements, so if you were looking for the fourth
    element, that would be the root itself, and you’d be done! In this case, however,
    you are looking for the seventh element, so you need to keep searching. First,
    decide whether to go left or right: the left subtree has only three elements,
    so the seventh element must be the third element in the right subtree. You need
    to discount the three elements of the left subtree and also the root, so that
    removes four from the count, and you move right.'
  prefs: []
  type: TYPE_NORMAL
- en: Now you are at the 8 key root, which has size 8\. Its left subtree has three
    elements, and as you are looking for the third element of that tree, you keep
    going down to the left. At the 6 key root, repeat the procedure, and this time
    go right, as you need to discount one element from the left subtree and one from
    the root, so now you want the first element of the right subtree. Then you arrive
    at the 7 key, which is what you wanted.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can easily implement this search with recursion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'First, dismiss all the cases in which the search will fail ❶: an empty tree
    or asking for a rank outside the size of the tree. If the rank you want isn’t
    greater than the size of the left subtree ❷, continue the search there. Otherwise,
    if the rank you want is exactly one more than the left subtree’s size ❸, the root
    is the answer, and you are done. Finally, if none of the preceding conditions
    hold, go right, and you have to discount the left subtree’s size and the root
    to continue the search ❹.'
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance for Weight-Balanced Binary Trees
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As in the case of AVL trees, ensuring balance in BB[α] trees makes for constant
    performance, with no worst cases. For all operations (adding, removing, and finding),
    the total cost is logarithmic, so weight-balanced binary trees ensure good performance,
    as shown in [Table 12-4](chapter12.xhtml#tab12-4).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12-4: Performance of Operations for Weight-Balanced Binary Trees'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Average performance | Worst case |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | O(1) | O(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Add | O(log n) | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | O(log n) | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Find | O(log n) | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Find by rank | O(log n) | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Traverse | O(n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: Also in comparison with AVL trees, the code isn’t very complex, and in both
    cases, you just depend on a “balance fix” function to be used after additions
    or removals.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic Balance Binary Search Trees
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Assured balance trees make operations more complex to ensure that a well-balanced
    shape will be kept at all times and thus provide a constant performance for operations.
    The other approach, *probabilistic balanced* trees, are simpler in implementation,
    require no extra memory usage, and can be as efficient (in an amortized sense)
    as assured balance trees—but you have to cope with the possible disadvantage of
    some individual slow operations mixed in with a long series of fast ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, these trees do not ensure balance, but rather, they promise it in a probabilistic
    sense, and unless you are really unlucky, they will perform quite well. In this
    chapter, we’ll consider two versions of these trees: *randomized* *binary search
    trees*, which apply balancing operations in a random manner, and *splay trees*,
    which restructure trees to make future searches faster. In [Chapter 14](chapter14.xhtml)
    we’ll consider one more option: treaps*.*'
  prefs: []
  type: TYPE_NORMAL
- en: Randomized Binary Search Trees
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Balanced trees guarantee performance by enforcing some constraints. This is
    an advantage in terms of performance, but it adds an extra level of complexity
    for operations, plus the need for some bookkeeping information at each node to
    determine whether restructuring is needed. Another way to avoid bad cases is to
    use randomized algorithms that provide a guarantee of their *expected* performance
    in terms of probability for any kind of input data. Depending on the implementation
    (and also on your particular data), a randomized algorithm may be faster than
    the corresponding assured balanced version, and it may be better for your needs.
    For instance, if you add keys in ascending order, balanced trees will have to
    do frequent balancing operations; if the algorithm works with random-based decisions
    at some points, fewer balancing operations may be needed; we’ll see this more
    clearly later.
  prefs: []
  type: TYPE_NORMAL
- en: The first such structure we’ll look at uses random numbers to decide whether
    a new addition should be at the root of the tree or go in its usual place. The
    insertion and deletion algorithms randomly decide how to either add a key to or
    remove a key from the tree. Both procedures produce a random structure, as if
    the input values had been shuffled, as you saw in [Chapter 10](chapter10.xhtml).
    Remember, we won’t need to reconsider how to find a key since we are still dealing
    with binary search trees and the earlier search logic still applies.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the Randomized Binary Search Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Randomized trees will have the same structure as BB[α] trees, including a size
    attribute, but instead of using it for rebalancing the tree, we’ll use it to help
    determine randomly what action to take. The basic code is as follows, and again
    we’ll be reusing some code from standard binary search trees:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This is exactly the same way the BB[α] code started, except here the newNode()
    method lets you provide initial values for the left and right pointers, otherwise
    setting them to null.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Having a* size *attribute means that you’ll also be able to find an element
    by rank quickly, as in BB[α] trees.*'
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Key to a Randomized Binary Search Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In a standard binary search tree, if you start adding keys to an initially empty
    tree, the first key you add becomes its root, and it will stay there unless you
    remove it. This next algorithm acts differently. Each time a key is added, it
    randomly decides whether it should go at the root or be added as a leaf, wherever
    that may be, similar to the sampling algorithms described previously. This method
    ensures that *any* key can be the root, so the order in which you do additions
    won’t matter.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the algorithm chooses to place the new key at the root, it splits the tree
    into two subtrees: one with all keys smaller than the future new root and the
    other with keys greater than it. Otherwise, if the algorithm didn’t opt for placing
    the new key as root, a common insertion logic is applied. Take a look at the basic
    algorithm first; the details will be filled in later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'If the tree is empty ❶, set the key at the root with empty subtrees and calculate
    its size before returning. Since you are moving nodes around, you’ll have to recalculate
    sizes. Just like the sampling algorithm from [Chapter 10](chapter10.xhtml), you
    may decide that the new value has to go at the root ❷. In that case, use an auxiliary
    algorithm to split the tree in two parts ❸: the key that’s being added becomes
    the root, and the two split trees become its subtrees ❹.'
  prefs: []
  type: TYPE_NORMAL
- en: As an alternative, if the random test fails, apply the algorithm you know well
    from binary search trees ❺. (Remember that to implement a set instead of a bag,
    you check if keyToAdd equals tree.key and reject the new key if so.) Note, however,
    that in each recursive step, you’re also using random numbers to decide whether
    to split the current tree, so randomness applies not only to the tree’s root but
    also throughout the structure. The last step of add() is to calculate the size
    of the root ❻, which is done no matter what happens in the earlier steps.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a sample case of this algorithm before dealing with the missing splitting
    code. Suppose you want to add a key of 20 to the tree shown in [Figure 12-26](chapter12.xhtml#fig12-26).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-26: A binary search tree before adding a key of 20'
  prefs: []
  type: TYPE_NORMAL
- en: Before comparing 20 to 23, generate a random number. Because the tree’s size
    is 9, it’s a probability of one in nine that the algorithm will split the tree
    and set 20 at its root, and in eight out of nine cases, the root will still be
    23\. Otherwise, you keep working in the usual fashion to add a key in a binary
    search tree.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose the test passes. Split the tree in two parts and set them as subtrees
    for 20, which becomes the new root, as shown in [Figure 12-27](chapter12.xhtml#fig12-27).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-27: If a random test succeeds, the new key becomes the root of the
    tree.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, assume the test fails. Leave the original root in place and move to its
    left to compare 20 to 9\. This time, since the size of the current tree is 5,
    the random test has a one in five probability of success. If the test succeeds
    this time, 20 goes in place of 9, splitting the tree rooted at 9 and doing the
    same kind of job as before.
  prefs: []
  type: TYPE_NORMAL
- en: 'A third possibility is if the random test fails the first two times. In that
    case, compare 20 with 12 and do another random test, now with one in three odds,
    because the original tree rooted at 12 has three nodes. And if that test fails,
    you still try again, with one in two odds, before comparing 20 to 22\. If and
    *only if* every random test fails, you end by placing 20 exactly where you would
    place it in a normal binary search tree: in this case, to the left of the 22 key.'
  prefs: []
  type: TYPE_NORMAL
- en: Splitting the Randomized Binary Search Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The splitting algorithm is reminiscent of the pivoting part of quicksort from
    [Chapter 6](chapter6.xhtml). You have a “pivot” key and want to split the structure
    into two trees, so all keys in the first tree are smaller than the pivot and all
    keys in the second are greater than it.
  prefs: []
  type: TYPE_NORMAL
- en: Start with the same tree we used before and see how splitting would work with
    regard to a 20 key, as shown in [Figure 12-28](chapter12.xhtml#fig12-28).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-28: The same tree as shown in [Figure 12-26](chapter12.xhtml#fig12-26)
    before splitting it in two with regard to the 20 value'
  prefs: []
  type: TYPE_NORMAL
- en: 'First set up two empty trees: one has values less than 20, and the other has
    values greater than 20\. Both start empty. The first step compares 20 with 23\.
    Since 23 is greater, that root and its right subtree go into the tree with greater
    values. Also, you need to “remember” the left subtree of 23 (now empty), because
    future values greater than 20 but less than 23 will go there. The two split trees
    (the one with lesser values, currently empty) would look like the ones shown in
    [Figure 12-29](chapter12.xhtml#fig12-29), and you’d go on to process the subtree
    rooted at 9.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-29: The first step: 23 is greater than 20, so part of the tree goes
    to the right. The dotted circles show where new subtrees will be added.'
  prefs: []
  type: TYPE_NORMAL
- en: Now you have 20, which is greater than 9, so 9 and its left subtree go into
    the “smaller” tree, and you remember the right subtree of 9, which is where any
    future values greater than 9 but less than 20 will go. The split trees now look
    like the ones in [Figure 12-30](chapter12.xhtml#fig12-30), and you can move on
    to the 12 key.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-30: The second step: 9 is less than 20, so part of the tree goes
    to the left.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the same situation: 20 is greater than 12, so connect 12 and its left
    subtree to the remembered right subtree of the smaller tree, getting the scenario
    shown in [Figure 12-31](chapter12.xhtml#fig12-31). Now remember the right subtree
    of 12 as the possible place to add more values.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-31: The third step: 12 is less than 20, so add to the left tree.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’re almost finished: 20 is less than 22, so 22 (and its right subtree, if
    it has one) goes to the remembered place in the “greater” tree, as shown in [Figure
    12-32](chapter12.xhtml#fig12-32).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-32: The fourth step: 22 is greater than 20, so add to the right tree.'
  prefs: []
  type: TYPE_NORMAL
- en: Since there are no more nodes to process, finish by setting the final tree’s
    root to 20, with the “smaller” and “greater” trees as subtrees. The result, shown
    in [Figure 12-33](chapter12.xhtml#fig12-33) is what you saw earlier.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-33: The fifth step: the tree was split, and now you set 20 at its
    root.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now examine the code, which has the tricky issue of how to remember places
    in split trees:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: First create two trees, newTrees, as you split the original tree. When you are
    done with the tree ❶, just return that pair. Otherwise ❷, decide which side to
    split ❸ and join the split part to the correct new tree; you also have to remember
    where the next joining will be done ❹ before proceeding recursively down the tree
    ❺. Finish by calculating the tree size ❻, because you need it for your random
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: Removing a Key from a Randomized Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The algorithm for removing a key is almost the same as before, but with one
    main difference: what to do if the key to be removed has two children. Here’s
    the basic code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The algorithm is pretty standard, and you have seen this code several times
    now with some small exceptions. When you remove a key from a subtree, you need
    to update the size attribute ❶ ❷, but the interesting difference is when you want
    to remove a key that has two subtrees, you use a joining procedure ❸ to merge
    the left and right subtrees into a new tree, which then replaced the removed key.
    (See question 12.22 for more on the deletion algorithm.)
  prefs: []
  type: TYPE_NORMAL
- en: Joining Two Randomized Binary Search Trees
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You can build a new tree out of two separate ones by picking one of the subtrees,
    using its root as the root for the new subtree, and recursively processing the
    rest of the trees. Consider the sample case shown in [Figure 12-34](chapter12.xhtml#fig12-34)
    and try to delete the 20 key added earlier.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-34: Deleting a root (here, 20) requires joining its subtrees into
    a single tree.'
  prefs: []
  type: TYPE_NORMAL
- en: You need to make a single tree out of both of the root’s left and right subtrees
    and decide how to do it via random selection, so either 9 or 23 will become the
    new root. Suppose the random choice picks 9\. Set 9 as the root of the new tree,
    along with its left subtree, and at its right subtree, set the result of joining
    its right subtree with the other subtree, the one rooted at 23.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you have to choose among 12 and 23; suppose you select the latter. You
    can add 23 and its right subtree to the tree you are building, and then you still
    have to finish joining the subtrees rooted at 12 and 22\. If you randomly pick
    12 to be the next root, you’ll get the situation shown in [Figure 12-35](chapter12.xhtml#fig12-35).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-35: The new tree after randomly selecting 9 for its root and 23 for
    its right subtree'
  prefs: []
  type: TYPE_NORMAL
- en: As the last step, you need to join an empty subtree (12’s right subtree) and
    22’s, so the final tree becomes the one shown in [Figure 12-36](chapter12.xhtml#fig12-36)
    where you’ve removed the 20 key using the new style of algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-36.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-36: The last step, after joining 12’s right empty subtree and 22’s
    subtree'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the code. To decide from which tree to pick the root, use the same
    rule when you considered considered sampling: if the subtrees were of sizes 6
    and 4 you’d pick the first tree’s root with a 6/10 probability and the second
    tree’s root with a 4/10 probability. Here’s the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: First, get the sizes ❶ of the trees to join to make the random choice later.
    If both trees are empty ❷, you’re done. If not, randomly decide (based on the
    trees’ own sizes) which one will provide the root ❸. If it’s the left one, take
    its root and its left subtree with no changes and replace its right subtree, with
    the result of joining it with the other subtree you were working with. Of course,
    if you picked the right subtree ❹, the logic would be the same, but mirrored.
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance for Randomized Binary Search Trees
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The effects of the randomized addition procedure make the average performance
    logarithmic. Even if the structure can become out of shape at times, continued
    operations bring it back to a good shape. The worst cases still are linear in
    time. There is, after all, a possibility that all random numbers may “work against
    you” to produce a badly shaped tree, but on average, that doesn’t happen; check
    [Table 12-5](chapter12.xhtml#tab12-5).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12-5: Performance of Operations for Randomized Binary Search Trees'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Average performance | Worst case |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | O(1) | O(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Add | O(log n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | O(log n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Find | O(log n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: '| Traverse | O(n) | O(n) |'
  prefs: []
  type: TYPE_TB
- en: 'This structure provides logarithmic performance with high probability: the
    shape of the search tree will be that of a tree created with a random sequence
    of keys. Now consider a different structure that will provide amortized logarithmic
    performance, so a series of operations will have a total time that is logarithmic
    on average.'
  prefs: []
  type: TYPE_NORMAL
- en: Splay Trees
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As mentioned previously, binary search trees can have *O*(*n*) performance,
    and although this happens only occasionally, it can be a problem. The balanced
    trees from the previous sections take preventive actions to avoid that issue,
    but *splay trees* provide another solution. This version of binary search trees
    guarantees amortized *O*(log *n*) performance, meaning that a sequence of *k*
    successive operations will have *O*(*k* log *n*) performance, which isn’t as good
    as guaranteed *O*(log *n*), but it’s almost as good.
  prefs: []
  type: TYPE_NORMAL
- en: With splay trees, whenever a node is accessed, it’s moved to the root by a process
    called *splaying*, which is a sequence of rotations that brings up the desired
    node. This doesn’t guarantee a well-balanced tree by any means, but over time,
    splay trees tend to become reasonably well shaped and provide a good alternative
    to other binary search tree implementations.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the situation in [Figure 12-37](chapter12.xhtml#fig12-37) where the
    12 key is sought.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-37: In a splay tree, after a search (here, for key 12), the found
    node becomes the tree’s new root.'
  prefs: []
  type: TYPE_NORMAL
- en: 'After finding 12, that key is brought up to the root (you’ll see how later),
    which also causes other paths to change: 23 is pushed down the root’s right subtree,
    10 moves closer to the root, and 22 moves from left to right. Even if it’s possible
    for the tree to become badly shaped, the sequence of operations usually restructures
    it for better performance over time. If you frequently require access to a few
    sets of keys, searches will be quite fast, because those keys will be nearer to
    the root, which is an advantage for many use cases. An example of this is provided
    by compilers and their symbol tables: usually when a symbol is defined (say, in
    a function), there’s a good probability you’ll be accessing it several times in
    a short period.'
  prefs: []
  type: TYPE_NORMAL
- en: Splaying a Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Splay trees have specific rules, with quaint names like *zig-zig* or *zag*,
    and they are based on simple rotations. Consider the different cases. In [Figures
    12-38](chapter12.xhtml#fig12-38) through [12-40](chapter12.xhtml#fig12-40), the
    key to be moved up is always 1 (highlighted).
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 1: Left Child of the Root**'
  prefs: []
  type: TYPE_NORMAL
- en: If the key is the left child of the root, apply a single right rotation to bring
    the key to the root. This is called a *zig* case, as shown in [Figure 12-38](chapter12.xhtml#fig12-38).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-38: A single right rotation moves a left subtree up to the root.'
  prefs: []
  type: TYPE_NORMAL
- en: The opposite case is if the key were the right child of the root; then you’d
    do a rotation to the left, which is called a *zag*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 2: Right Child of the Left Child of the Root**'
  prefs: []
  type: TYPE_NORMAL
- en: In this *zag-zig* case, first rotate the key to the left and then rotate it
    to the right to bring it up to the root, as shown in [Figure 12-39](chapter12.xhtml#fig12-39).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-39: Two rotations are needed for the right child of a left child.'
  prefs: []
  type: TYPE_NORMAL
- en: In the opposite case (*zig-zag*), first apply a rotation to the right and then
    to the left.
  prefs: []
  type: TYPE_NORMAL
- en: '**Case 3: Left Child of the Left Child of the Root**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This *zig-zig* case might trip you up, because the order of rotations is altered:
    first you rotate the *parent* of the bottom key to the right and *then* you rotate
    the key itself, as shown in [Figure 12-40](chapter12.xhtml#fig12-40).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-40: Two right rotations are needed for the left child of a left child.'
  prefs: []
  type: TYPE_NORMAL
- en: You might think an easier algorithm in this case could rotate the key twice,
    but the result isn’t optimal, and a simple example may convince you of this. Assume
    you started with a (not very good) tree, as shown in [Figure 12-41](chapter12.xhtml#fig12-41),
    and splayed up the 1 key.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-41: Why always rotating the found key isn’t very good'
  prefs: []
  type: TYPE_NORMAL
- en: You could attempt to use rotations to the right to move the 1 up. At each step,
    the 1 moves up one place, relocating the original root to its right (first 2;
    then 3 and 2; then 4, 3, and 2; and so on), and by the time 1 gets up to the root,
    all the other keys (2–5) are still in the same structure they were before, as
    shown in [Figure 12-42](chapter12.xhtml#fig12-42).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-42: After all rotations, the tree’s structure becomes worse.'
  prefs: []
  type: TYPE_NORMAL
- en: In this splaying algorithm, two zig-zig rotations could handle this case. First,
    1 becomes a root with 2 and 3 to its right, and then 1 moves to the tree’s top,
    with 4 and 5 at its right; 2 and 3 are relocated to the left of 4, as shown in
    [Figure 12-43](chapter12.xhtml#fig12-43).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-43.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-43: The rotations suggested in the text produce a better structure.'
  prefs: []
  type: TYPE_NORMAL
- en: The zig-zig logic produces a better balanced tree, with several shorter paths
    from the root to nodes, and that serves as a justification for using more complex
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, consider splaying in terms of actual code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Splaying continues until an empty tree is reached or the key you’re looking
    for is found ❶. As long as those conditions are not met, continue. Decide on which
    subtree you should find the key ❷, and if that subtree is empty, you’re also done.
    (If the tree doesn’t contain the key you’re looking for, the last key you found
    is the one that moves up, so *some* restructuring is always done.) If you find
    the key at the root of the subtree ❸, you have a zig or a zag, and a single rotation
    suffices. If not, if the key you are searching for is at the same side of the
    subtree ❹, you have a zig-zig or zag-zag. First recursively splay the lowest subtree
    ❺, then rotate the root ❻, and finish the last rotation later ❾. The other possibility
    is either a zig-zag or a zag-zig: splay the lowest subtree ❼ and finish with the
    two other rotations ❽ ❾ described earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: Finding a Key in a Splayed Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This algorithm is simple. Apply the splaying algorithm first, then check whether
    the value that got to the root is what you were looking for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Unless the tree is empty, splay it. Splaying ❶ is *always* done, whether or
    not the key exists, so the new key at the root may or may not be what you were
    looking for, which explains the final test ❷.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Key to a Splayed Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To add a key, first apply splaying to restructure the tree and then add a new
    root at the top. The tree in [Figure 12-44](chapter12.xhtml#fig12-44), which is
    the same tree used earlier when showing how splaying worked, shows how to add
    an 11 key.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-44: A splay tree into which you’ll insert an 11 key'
  prefs: []
  type: TYPE_NORMAL
- en: The first step is to splay using 11 as the splaying value. This key isn’t present
    in the tree, so the algorithm ends with 10 at the root, as shown in [Figure 12-45](chapter12.xhtml#fig12-45).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-45.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-45: The first step: the tree is splayed with regard to the 11 value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now it’s easy to finish: 11 should become the root, with 10 (the current root)
    at its left and 23 at the right, as shown in [Figure 12-46](chapter12.xhtml#fig12-46).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-46.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-46: The final step: the 11 becomes the new root, with the splayed
    parts as subtrees.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: First, create the node that will become the new root ❶. Then, splay the tree
    ❷, so the root becomes the nearest key to the one added. Then link the new root
    properly ❸, and the new node will be the tree’s root.
  prefs: []
  type: TYPE_NORMAL
- en: Removing a Key from a Splayed Tree
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Removing a key starts by splaying the tree, so the root becomes either the key
    you wanted to remove or a different one, if the key you wanted to remove wasn’t
    present in the tree. If the key was found, do the usual steps. If it has zero
    children or just one child, removal is simple; if it has two children, find the
    next key in its right subtree and set it at the root, but splay it as well.
  prefs: []
  type: TYPE_NORMAL
- en: You can see how this works by attempting to remove 12 from the tree shown in
    [Figure 12-47](chapter12.xhtml#fig12-47).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-47.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-47: A splay tree from which you want to delete the 12 key'
  prefs: []
  type: TYPE_NORMAL
- en: The first step, as with adding and searching, is to splay the tree using 12
    as the key; you already saw this example, and the result was the updated tree
    shown in [Figure 12-48](chapter12.xhtml#fig12-48).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-48.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-48: The splay tree after splaying, so the 12 becomes the root'
  prefs: []
  type: TYPE_NORMAL
- en: Since the 12 was found, you can proceed. In this case, you have two subtrees,
    so you have to find the key that follows 12 (22) and use that value to splay the
    root’s subtree, getting the new tree shown in [Figure 12-49](chapter12.xhtml#fig12-49).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-49.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-49: The tree after splaying the subtree with 22 at its root'
  prefs: []
  type: TYPE_NORMAL
- en: Now you can easily remove 12 by placing 22 in its place, and you have finished
    the algorithm, as shown in [Figure 12-50](chapter12.xhtml#fig12-50). Note that
    the 22 key cannot have a left subtree, because there’s no value between 12 and
    22.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-50.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-50: The final tree after 22 becomes the root'
  prefs: []
  type: TYPE_NORMAL
- en: 'First look at the code to splay a tree, bringing its minimum value to the top.
    Remember from earlier algorithms that we find the minimum key going left until
    we can’t go any further. The idea here is to apply rotations so the minimum key
    ends up at the top:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The algorithm is basically the same as _splay(), except you always assume you’re
    going left ❶ ❷ ❸. Compare the code; it’s the same as earlier, except side is replaced
    with left. (There’s another way of deriving the _splayMinimum() code; see question
    12.25.) With that out of the way, the code for removal is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: If the tree isn’t empty, start by splaying it ❶ and then check whether the key
    you want to remove is now at the root. If so, you can easily deal with cases where
    the new root has fewer than two children ❷ ❸ ❹. Otherwise, save the left subtree
    ❺ and then splay the right subtree, bringing its minimum to the top ❻, and the
    minimum takes the place of the key you are deleting. You just have to fix its
    left subtree ❼ and you’re done.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*See question 12.24 to verify that you understand an important detail of this
    algorithm: Why are you only overriding the splayed subtree’s left tree in the
    last steps of the removal process?*'
  prefs: []
  type: TYPE_NORMAL
- en: Considering Performance for Splay Trees
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Splay trees can, in the worst case, produce a linear tree, so performance would
    be linear in that case and probably would rule them out in a real-time context
    when you need absolute guarantees as to processing time. However, the amortized
    cost of a series of operations is logarithmic, meaning that, on average, a sequence
    of *k* operations (additions and removals) would have a total cost *O*(*k* log
    *n*), which works to a logarithmic amortized performance; [Table 12-6](chapter12.xhtml#tab12-6)
    sums up the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 12-6: Performance of Operations for Splay Trees'
  prefs: []
  type: TYPE_NORMAL
- en: '| Operation | Amortized performance |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Create | O(1) |'
  prefs: []
  type: TYPE_TB
- en: '| Add | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Remove | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Find | O(log n) |'
  prefs: []
  type: TYPE_TB
- en: '| Traverse | O(n) |'
  prefs: []
  type: TYPE_TB
- en: One interesting feature is that the structure not only self-reorganizes, but
    it also provides better performance, because frequently accessed keys end up close
    to the root. This makes splay trees appropriate for implementing caches, for example.
    The fact that nodes need no extra bookkeeping data (such as the tree’s height
    or size) makes it interesting if lack of memory is a problem, and yet another
    benefit is that performance is, on average, as efficient as other trees.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter introduced trees, in particular, binary search trees, which provide
    a good implementation for the bag and set ADTs, with high-performing *add*, *remove*,
    and *find* methods. You explored the performance of these trees and saw several
    variants aimed to ensure good, fast algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter we’ll explore more general tree-based structures, and
    we’ll also consider special search-oriented structures that provide quite efficient
    searches and updates.
  prefs: []
  type: TYPE_NORMAL
- en: '### Questions'
  prefs: []
  type: TYPE_NORMAL
- en: '**12.1  A Matter of Levels**'
  prefs: []
  type: TYPE_NORMAL
- en: Can you define the height of a tree in terms of levels?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.2  Breaking the Rules**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Filesystem directories are often said to have a treelike structure, but that’s
    not always true. Can you think of a feature that allows directories to be, say,
    like circular lists (as seen in [Chapter 10](chapter10.xhtml)) or even possibly
    like graphs (as you’ll see in [Chapter 17](chapter17.xhtml))? A hint: directory
    entries can be of many types.'
  prefs: []
  type: TYPE_NORMAL
- en: '**12.3  What’s in a Name?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some questions regarding full, perfect, and complete trees: Which
    term implies another? For example, are full trees also complete? And are complete
    trees full? What happens with full and perfect trees? What about perfect and complete?'
  prefs: []
  type: TYPE_NORMAL
- en: '**12.4  A** **find()** **One-Liner**'
  prefs: []
  type: TYPE_NORMAL
- en: It’s certainly less clear, but can you write the find() method with a single
    line of code?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.5  Sizing a Tree**'
  prefs: []
  type: TYPE_NORMAL
- en: Write a calcSize() function that will find the size of a binary tree.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.6  Tall as a Tree**'
  prefs: []
  type: TYPE_NORMAL
- en: Write a calcHeight() function to find the height of a binary tree.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.7  Copy a Tree**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a binary tree, write an algorithm that will produce a copy of it. (Hint:
    you may want to consider using a preorder traversal for this.)'
  prefs: []
  type: TYPE_NORMAL
- en: '**12.8  Do the Math**'
  prefs: []
  type: TYPE_NORMAL
- en: This problem can pop up if you are writing a compiler or an interpreter. Suppose
    you have a binary tree whose nodes can have either a number or a mathematical
    operator (addition, subtraction, multiplication, and division). Such a tree can
    be used to represent any mathematical expression; for instance, the tree in [Figure
    12-51](chapter12.xhtml#fig12-51) stands for (2 + 3) * 6.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../images/Figure12-51.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12-51: Do the math.'
  prefs: []
  type: TYPE_NORMAL
- en: Show that you can evaluate such an expression by properly traversing the tree.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.9  Making It Bad**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In what order should you insert keys in a common binary search tree to produce
    a linear list? And if you have *n* keys, how many ways can you produce a tree
    with not one single full node? (Hint: Which values could you pick first to add
    into the tree? Which values could come next?)'
  prefs: []
  type: TYPE_NORMAL
- en: '**12.10  Rebuild the Tree**'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are given the preorder and inorder listings of the keys in a binary
    search tree with no duplicate keys, you can rebuild it; write an algorithm to
    do this. Your input will be two arrays of values: the first will have the tree’s
    keys in preorder, and the second will have them in inorder.'
  prefs: []
  type: TYPE_NORMAL
- en: '**12.11  More Rebuilding?**'
  prefs: []
  type: TYPE_NORMAL
- en: For the previous question, would you have been able to rebuild the tree out
    of the inorder and postorder listings? What about out of the preorder and postorder
    listings?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.12  Equal Traversals**'
  prefs: []
  type: TYPE_NORMAL
- en: For which trees are keys visited in the same order with preorder and inorder
    traversals? What about for inorder and postorder? Or for preorder and postorder?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.13  Sorting by Traversing**'
  prefs: []
  type: TYPE_NORMAL
- en: Use the inOrder() traversal to, given a binary search tree, produce an ordered
    array of its keys.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.14  Generic Order**'
  prefs: []
  type: TYPE_NORMAL
- en: Write an anyOrder(tree,order,visit) function that will accept an order parameter
    that can be "PRE", "IN", or "POST" and will do the corresponding traversal of
    tree, with the given visit() function.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.15  No Recursion Traversal**'
  prefs: []
  type: TYPE_NORMAL
- en: Implement all traversals without using recursion; use a stack instead.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.16  No Duplicates Allowed**'
  prefs: []
  type: TYPE_NORMAL
- en: Modify the addition logic for binary search trees to reject attempts to add
    duplicate keys. After such an attempt, the tree should remain unchanged, and an
    error should be thrown.
  prefs: []
  type: TYPE_NORMAL
- en: '**12.17  Get and Delete**'
  prefs: []
  type: TYPE_NORMAL
- en: Write a _removeMinFromTree(tree) method that will find the least key in a binary
    search tree, remove it, and return both the key and the updated tree at the same
    time. Use this new method to optimize _remove() by dropping the need for _findNext().
  prefs: []
  type: TYPE_NORMAL
- en: '**12.18  AVL Worst**'
  prefs: []
  type: TYPE_NORMAL
- en: What’s the smallest number of nodes that an AVL tree can have related to its
    height? In other words, if an AVL tree has height 1, 2, 3 ..., what’s the smallest
    number of nodes it may have?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.19  Singles Only**'
  prefs: []
  type: TYPE_NORMAL
- en: Consider a child node with no siblings called *single child*. Can you have more
    than 50 percent single children in an AVL tree?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.20  Why One?**'
  prefs: []
  type: TYPE_NORMAL
- en: In weight-balanced trees, why is it that the balances of the left subtree and
    the right subtree (that is, the fractions *weight(left subtree) / weight(tree)*
    and *weight(right subtree) / weight(tree)*) add up to 1?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.21  Easier Randomizing?**'
  prefs: []
  type: TYPE_NORMAL
- en: 'A developer had the following thought:'
  prefs: []
  type: TYPE_NORMAL
- en: Binary search trees behave badly if keys are added in order, but behave well
    with a random order. What would happen if instead of adding keys to a tree, I
    hashed them first? The hashed keys are, to all effects, random, and so an ordered
    sequence of keys would become a totally disordered one, ensuring good performance.
    Of course, when looking for a key, I’d really need to look for the hashed key,
    but that’s no big deal. Problem solved; binary trees with hashed keys will *always*
    behave well!
  prefs: []
  type: TYPE_NORMAL
- en: Is this reasoning correct?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.22  Why Not Decrement?**'
  prefs: []
  type: TYPE_NORMAL
- en: In the remove() logic for randomized binary trees, why did you use _calcSize()
    instead of decrementing as in the following?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '**12.23  Bad Splay?**'
  prefs: []
  type: TYPE_NORMAL
- en: You saw earlier that adding keys in ascending or descending order was a bad
    case for common binary search trees. What happens with splay trees in those cases?
    And if after those additions you remove a few keys, what tree shape do you get?
    Is it any better?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.24  What Left Subtree?**'
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the remove() method for splay trees, after splaying the root’s
    right subtree, what’s the value of this.right.left and why?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.25  Code Transformation**'
  prefs: []
  type: TYPE_NORMAL
- en: Show that you can transform _splay() to _splayMinimum() by assuming that keyToUp
    equals -Infinity. Why should this work?
  prefs: []
  type: TYPE_NORMAL
- en: '**12.26  Full Rebalance**'
  prefs: []
  type: TYPE_NORMAL
- en: You’ve seen several strategies for rebalancing trees, but you may also want
    to rebalance a common binary search tree. Can you come up with a restructure(tree)
    function that will balance a binary search tree into as perfect a shape as possible?
    You should attempt to split nodes as evenly as possible between left and right
    subtrees, everywhere in the tree.
  prefs: []
  type: TYPE_NORMAL
