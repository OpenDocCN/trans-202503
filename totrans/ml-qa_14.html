<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><h2 class="h2" id="ch12"><span epub:type="pagebreak" id="page_75"/><strong><span class="big">12</span><br/>FULLY CONNECTED AND CONVOLUTIONAL LAYERS</strong></h2>&#13;
<div class="image1"><img src="../images/common.jpg" alt="Image" width="252" height="252"/></div>&#13;
<p class="noindent">Under which circumstances can we replace fully connected layers with convolutional layers to perform the same computation?</p>&#13;
<p class="indent">Replacing fully connected layers with convolutional layers can offer advantages in terms of hardware optimization, such as by utilizing specialized hardware accelerators for convolution operations. This can be particularly relevant for edge devices.</p>&#13;
<p class="indent">There are exactly two scenarios in which fully connected layers and convolutional layers are equivalent: when the size of the convolutional filter is equal to the size of the receptive field and when the size of the convolutional filter is 1. As an illustration of these two scenarios, consider a fully connected layer with two input and four output units, as shown in <a href="ch12.xhtml#ch12fig1">Figure 12-1</a>.</p>&#13;
<div class="image"><img id="ch12fig1" src="../images/12fig01.jpg" alt="Image" width="271" height="196"/></div>&#13;
<p class="figcap"><em>Figure 12-1: Four inputs and two outputs connected via eight weight parameters</em></p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_76"/>The fully connected layer in this figure consists of eight weights and two bias units. We can compute the output nodes via the following dot products:</p>&#13;
<p class="indentt"><strong>Node 1</strong> <em>w</em><sub>1,1</sub> <em>× x</em><sub>1</sub> + <em>w</em><sub>1,2</sub> <em>× x</em><sub>2</sub> + <em>w</em><sub>1,3</sub> <em>× x</em><sub>3</sub> + <em>w</em><sub>1,4</sub> <em>× x</em><sub>4</sub> + <em>b</em><sub>1</sub></p>&#13;
<p class="indent"><strong>Node 2</strong> <em>w</em><sub>2,1</sub> <em>× x</em><sub>1</sub> + <em>w</em><sub>2,2</sub> <em>× x</em><sub>2</sub> + <em>w</em><sub>2,3</sub> <em>× x</em><sub>3</sub> + <em>w</em><sub>2,4</sub> <em>× x</em><sub>4</sub> + <em>b</em><sub>2</sub></p>&#13;
<p class="indentt">The following two sections illustrate scenarios in which convolutional layers can be defined to produce exactly the same computation as the fully connected layer described.</p>&#13;
<h3 class="h3" id="ch00lev56"><strong>When the Kernel and Input Sizes Are Equal</strong></h3>&#13;
<p class="noindent">Let’s start with the first scenario, where the size of the convolutional filter is equal to the size of the receptive field. Recall from <a href="ch11.xhtml">Chapter 11</a> how we compute a number of parameters in a convolutional kernel with one input channel and multiple output channels. We have a kernel size of 2<em>×</em>2, one input channel, and two output channels. The input size is also 2<em>×</em>2, a reshaped version of the four inputs depicted in <a href="ch12.xhtml#ch12fig2">Figure 12-2</a>.</p>&#13;
<div class="image"><img id="ch12fig2" src="../images/12fig02.jpg" alt="Image" width="519" height="254"/></div>&#13;
<p class="figcap"><em>Figure 12-2: A convolutional layer with a 2×2 kernel that equals the input size and two output channels</em></p>&#13;
<p class="indent">If the convolutional kernel dimensions equal the input size, as depicted in <a href="ch12.xhtml#ch12fig2">Figure 12-2</a>, there is no sliding window mechanism in the convolutional layer. For the first output channel, we have the following set of weights:</p>&#13;
<div class="image1"><img src="../images/f0076-01.jpg" alt="Image" width="217" height="84"/></div>&#13;
<p class="indent">For the second output channel, we have the following set of weights:</p>&#13;
<div class="image1"><img src="../images/f0076-02.jpg" alt="Image" width="216" height="84"/><span epub:type="pagebreak" id="page_77"/></div>&#13;
<p class="indent">If the inputs are organized as</p>&#13;
<div class="image1"><img src="../images/f0077-01.jpg" alt="Image" width="146" height="83"/></div>&#13;
<p class="noindent">we calculate the first output channel as <em>o</em><sub>1</sub> = <em>∑i</em>(<em>W</em><sub>1</sub> *<strong>x</strong>)<em><sub>i</sub></em> + <em>b</em><sub>1</sub>, where the convolutional operator * is equal to an element-wise multiplication. In other words, we perform an element-wise multiplication between two matrices, <em>W</em><sub>1</sub> and <strong>x</strong>, and then compute the output as the sum over these elements; this equals the dot product in the fully connected layer. Lastly, we add the bias unit. The computation for the second output channel works analogously: <em>o</em><sub>2</sub> = <em>∑i</em>(<em>W</em><sub>2</sub> * <strong>x</strong>)<em><sub>i</sub></em> + <em>b</em><sub>2</sub>.</p>&#13;
<p class="indent">As a bonus, the supplementary materials for this book include PyTorch code to show this equivalence with a hands-on example in the <em>supplementary/q12-fc-cnn-equivalence</em> subfolder at <em><a href="https://github.com/rasbt/MachineLearning-QandAI-book">https://github.com/rasbt/MachineLearning-QandAI-book</a></em>.</p>&#13;
<h3 class="h3" id="ch00lev57"><strong>When the Kernel Size Is 1</strong></h3>&#13;
<p class="noindent">The second scenario assumes that we reshape the input into an input “image” with 1<em>×</em>1 dimensions where the number of “color channels” equals the number of input features, as depicted in <a href="ch12.xhtml#ch12fig3">Figure 12-3</a>.</p>&#13;
<div class="image"><img id="ch12fig3" src="../images/12fig03.jpg" alt="Image" width="596" height="247"/></div>&#13;
<p class="figcap"><em>Figure 12-3: The number of output nodes equals the number of channels if the kernel size is equal to the input size.</em></p>&#13;
<p class="indent">Each kernel consists of a stack of weights equal to the number of input channels. For instance, for the first output layer, the weights are</p>&#13;
<div class="image1"><img src="../images/f0077-02.jpg" alt="Image" width="268" height="41"/></div>&#13;
<p class="noindent">while the weights for the second channel are:</p>&#13;
<div class="image1"><img src="../images/f0077-03.jpg" alt="Image" width="268" height="42"/></div>&#13;
<p class="indent">To get a better intuitive understanding of this computation, check out the illustrations in <a href="ch11.xhtml">Chapter 11</a>, which describe how to compute the parameters in a convolutional layer.<span epub:type="pagebreak" id="page_78"/></p>&#13;
<h3 class="h3" id="ch00lev58"><strong>Recommendations</strong></h3>&#13;
<p class="noindent">The fact that fully connected layers can be implemented as equivalent convolutional layers does not have immediate performance or other advantages on standard computers. However, replacing fully connected layers with convolutional layers can offer advantages in combination with developing specialized hardware accelerators for convolution operations.</p>&#13;
<p class="indent">Moreover, understanding the scenarios where fully connected layers are equivalent to convolutional layers aids in understanding the mechanics of these layers. It also lets us implement convolutional neural networks without any use of fully connected layers, if desired, to simplify code implementations.</p>&#13;
<h3 class="h3" id="ch00lev59"><strong>Exercises</strong></h3>&#13;
<p class="number1"><strong>12-1.</strong> How would increasing the stride affect the equivalence discussed in this chapter?</p>&#13;
<p class="number1_1"><strong>12-2.</strong> Does padding affect the equivalence between fully connected layers and convolutional layers?</p>&#13;
</div>
</div>
</body></html>