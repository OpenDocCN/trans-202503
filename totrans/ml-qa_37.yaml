- en: '**APPENDIX: ANSWERS TO THE EXERCISES**'
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**附录：习题答案**'
- en: '**Chapter 1**'
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第1章**'
- en: '**1-1.** The final layer before the output layer (the second fully connected
    layer in this case) may be most useful for embeddings. However, we could also
    use all other intermediate layers to create embeddings. Since the later layers
    tend to learn higher-level features, these later layers are typically more semantically
    meaningful and better suited for different types of tasks, including related classification
    tasks.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**1-1.** 输出层之前的最后一层（在这种情况下是第二个全连接层）可能对嵌入最为有用。然而，我们也可以使用所有其他中间层来创建嵌入。由于后面的层通常会学习更高层次的特征，这些层通常在语义上更有意义，更适合不同类型的任务，包括相关的分类任务。'
- en: '**1-2.** One of the traditional methods of input representation that is different
    from embeddings is one-hot encoding, as discussed in [Chapter 1](ch01.xhtml).
    In this method, each categorical variable is represented using a binary vector
    where only one value is “hot” or active (for instance, set to 1), while all other
    positions remain inactive (for instance, set to 0).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**1-2.** 与嵌入（embeddings）不同的一种传统输入表示方法是独热编码（one-hot encoding），如[第1章](ch01.xhtml)所讨论的那样。在这种方法中，每个类别变量使用一个二进制向量表示，其中只有一个值是“热”或激活的（例如，设为1），而所有其他位置则保持不活跃（例如，设为0）。'
- en: Another representation that is not an embedding is histograms. A typical example
    of this is image histograms (see *[https://en.wikipedia.org/wiki/Image_histogram](https://en.wikipedia.org/wiki/Image_histogram)*
    for examples). These histograms provide a graphical representation of the tonal
    distribution in a digital image, capturing the intensity distribution of pixels.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种不是嵌入的表示方式是直方图。一个典型的例子是图像直方图（参见 *[https://en.wikipedia.org/wiki/Image_histogram](https://en.wikipedia.org/wiki/Image_histogram)*
    了解更多示例）。这些直方图提供了数字图像中色调分布的图形表示，捕捉了像素的强度分布。
- en: Additionally, the bag-of-words model offers another approach distinct from embeddings.
    In this model, an input sentence is represented as an unordered collection or
    “bag” of its words, disregarding grammar and even word order. For more details
    about the bag-of-words model, see *[https://en.wikipedia.org/wiki/Bag-of-words_model](https://en.wikipedia.org/wiki/Bag-of-words_model)*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，词袋模型提供了一种与嵌入不同的方法。在这种模型中，输入句子被表示为一个无序的词集合或“袋”，忽略了语法甚至词序。有关词袋模型的更多细节，请参见 *[https://en.wikipedia.org/wiki/Bag-of-words_model](https://en.wikipedia.org/wiki/Bag-of-words_model)*。
- en: '**Chapter 2**'
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第2章**'
- en: '**2-1.** One way to apply self-supervised learning to video data is by predicting
    the next frame in the video. This is analogous to next-word prediction in large
    language models such as GPT. This method challenges the model to anticipate subsequent
    events or movements in a sequence, giving it a temporal understanding of the content.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**2-1.** 将自监督学习应用于视频数据的一种方法是预测视频中的下一帧。这类似于在GPT等大型语言模型中的下一词预测。这种方法挑战模型预测序列中的后续事件或动作，赋予它对内容的时间理解。'
- en: Another approach is to predict missing or masked frames. This idea draws inspiration
    from large language models like BERT, where certain words are masked and the model
    is tasked with predicting them. In the case of video, entire frames can be masked,
    and the model learns to interpolate and predict the masked frame based on the
    context provided by surrounding frames.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是预测缺失或被遮盖的帧。这个想法受到了像BERT这样的巨大语言模型的启发，其中某些词被遮盖，模型的任务是预测这些词。在视频的情况下，可以遮盖整个帧，模型根据周围帧提供的上下文学习插值并预测被遮盖的帧。
- en: Inpainting is yet another avenue for self-supervised learning in videos. Here,
    instead of masking entire frames, specific pixel areas within a frame are masked.
    The model is then trained to predict the missing or masked parts, which can help
    it grasp fine-grained visual details and spatial relationships in the video content.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图像修复（Inpainting）是视频自监督学习的另一种途径。在这种方法中，不是遮盖整个帧，而是遮盖帧中的特定像素区域。然后，模型被训练去预测缺失或被遮盖的部分，这有助于它掌握视频内容中的细粒度视觉细节和空间关系。
- en: Lastly, a coloring technique can be used where the video is converted to grayscale
    and the model is tasked with predicting the color. This not only teaches the model
    about the original colors of objects, but it also gives insights into lighting,
    shadows, and the general mood of the scenes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，可以使用一种着色技术，将视频转换为灰度图像，然后模型的任务是预测颜色。这不仅教会模型物体的原始颜色，还能提供对光照、阴影和场景整体氛围的理解。
- en: '**2-2.** We can remove (mask) feature values and train a model to predict these,
    analogously to classic data imputation. For example, one method that uses this
    approach is TabNet; see Sercan O. Arik and Tomas Pfister, “TabNet: Attentive Interpretable
    Tabular Learning” (2019), *[https://arxiv.org/abs/1908.07442](https://arxiv.org/abs/1908.07442)*.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**2-2.** 我们可以移除（掩码）特征值，并训练一个模型来预测这些值，类似于经典的数据插补方法。例如，使用这种方法的一个方法是 TabNet；参见
    Sercan O. Arik 和 Tomas Pfister，《TabNet：通过注意力机制解释性学习表格数据》（2019）， *[https://arxiv.org/abs/1908.07442](https://arxiv.org/abs/1908.07442)*。'
- en: 'It is also possible to use contrastive learning by generating augmented versions
    of the training examples in the original raw feature space or the embedding space.
    For example, the SAINT and SCARF methods employ this approach. For the former,
    see Gowthami Some-palli et al., “SAINT: Improved Neural Networks for Tabular Data
    via Row Attention and Contrastive Pre-Training” (2021), *[https://arxiv.org/abs/2106.01342](https://arxiv.org/abs/2106.01342)*.
    For the latter, see Dara Bahri et al., “SCARF: Self-Supervised Contrastive Learning
    Using Random Feature Corruption” (2021), *[https://arxiv.org/abs/2106.15147](https://arxiv.org/abs/2106.15147)*.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过在原始特征空间或嵌入空间中生成训练样本的增强版本来使用对比学习。例如，SAINT 和 SCARF 方法采用了这种方法。关于前者，请参阅 Gowthami
    Some-palli 等人，《SAINT：通过行注意力和对比预训练改进的表格数据神经网络》（2021）， *[https://arxiv.org/abs/2106.01342](https://arxiv.org/abs/2106.01342)*。关于后者，请参阅
    Dara Bahri 等人，《SCARF：使用随机特征破坏的自监督对比学习》（2021）， *[https://arxiv.org/abs/2106.15147](https://arxiv.org/abs/2106.15147)*。
- en: '**Chapter 3**'
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第3章**'
- en: '**3-1.** Similar to a supervised learning approach, we first divide the dataset
    into a training set and a test set. We then further divide the training and test
    sets into subsets, with one image from each class. To design the training task,
    we consider only a subset of classes, such as the classes (digits) 0, 1, 2, 5,
    6, 8, 9\. Next, for testing, we use the remaining classes 3, 4, 7\. For each classification
    task, the neural network receives only one example per image.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**3-1.** 类似于监督学习方法，我们首先将数据集划分为训练集和测试集。然后，我们进一步将训练集和测试集划分为子集，每个子集包含一个来自每个类别的图像。为了设计训练任务，我们只考虑一个子集的类别，例如类别（数字）0、1、2、5、6、8、9。接下来，在测试时，我们使用剩余的类别3、4、7。对于每个分类任务，神经网络每次接收一个图像示例。'
- en: '**3-2.** Consider a medical imaging scenario for rare diseases. The training
    dataset may consist of only a few examples corresponding to different types of
    diseases, and a few-shot system may have only one or a handful of cases for a
    new, unseen rare disease (not contained in the training set). The task is then
    to identify a new rare disease based on this limited number of examples.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**3-2.** 考虑一种稀有疾病的医学影像场景。训练数据集可能仅包含少数对应不同类型疾病的示例，而少样本系统可能只对新出现的稀有疾病（训练集中没有的疾病）有一例或几例案例。任务是根据这一有限的示例数量识别新的稀有疾病。'
- en: Another example of a few-shot system is a recommender that has only a limited
    number of items a user rated. Based on this limited number of examples, the model
    has to predict future products the user may like. Imagine a warehouse robot that
    has to learn to recognize new objects as a company increases its inventory. The
    robot has to learn to recognize and adapt to these new objects based on only a
    few examples.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个少样本系统的例子是推荐系统，该系统只有有限数量的用户评分项。基于这些有限的示例，模型必须预测用户可能喜欢的未来产品。假设有一个仓库机器人，随着公司库存的增加，机器人必须学习识别新物品。机器人需要根据仅有的几个例子学习识别并适应这些新物品。
- en: '**Chapter 4**'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第4章**'
- en: '**4-1.** You might try increasing the size of the initial neural network. It
    might be possible that the chosen network is too small to contain a suitable subnetwork.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**4-1.** 你可以尝试增加初始神经网络的大小。可能所选择的网络太小，无法包含适合的子网络。'
- en: Another option is to try a different random initialization (for example, by
    changing the random seed). The lottery hypothesis assumes that *some* randomly
    initialized networks contain highly accurate subnetworks that can be obtained
    by pruning, but not all networks may have such subnetworks.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是尝试不同的随机初始化（例如，通过更改随机种子）。彩票假设认为，*某些* 随机初始化的网络包含可以通过剪枝获得的高度准确的子网络，但并非所有网络都有这样的子网络。
- en: '**4-2.** When training a neural network with ReLU activation functions, specific
    activations will be set to 0 if the function input is less than 0\. This causes
    certain nodes in the hidden layers not to contribute to the computations; these
    nodes are sometimes called *dead neurons*. While ReLU activations do not directly
    cause sparse weights, the zero activation outputs sometimes lead to zero weights
    that are not recoverable. This observation supports the lottery hypothesis, which
    suggests that well-trained networks may contain subnetworks with sparse, trainable
    weights that can be pruned without loss of accuracy.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**4-2.** 当使用 ReLU 激活函数训练神经网络时，如果函数输入小于 0，特定的激活值将被设置为 0。这导致隐藏层中的某些节点不参与计算，这些节点有时被称为*死神经元*。虽然
    ReLU 激活函数不会直接导致稀疏权重，但零激活输出有时会导致无法恢复的零权重。这一观察结果支持了彩票假说，该假说认为训练良好的网络可能包含具有稀疏且可训练权重的子网络，这些权重可以在不损失准确度的情况下进行修剪。'
- en: '**Chapter 5**'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第5章**'
- en: '**5-1.** XGBoost is a tree-based gradient-boosting implementation that does
    not, at the time of writing, support transfer learning. In contrast to artificial
    neural networks, XGBoost is a nonparametric model that we cannot readily update
    as new data arrives; hence, regular transfer learning would not work here.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**5-1.** XGBoost 是一个基于树的梯度提升实现，当前版本不支持迁移学习。与人工神经网络不同，XGBoost 是一个非参数模型，我们不能轻易地在新数据到达时更新它；因此，常规的迁移学习在这里是行不通的。'
- en: However, it is possible to use the results of an XGBoost model trained on one
    task as features for another XGBoost model. Consider an overlapping set of features
    for both datasets. For example, we could design a classification task in a self-supervised
    fashion for the combined dataset. We could then train a second XGBoost model on
    the target dataset that takes the original feature set as input, along with the
    output of the first XGBoost model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以将一个 XGBoost 模型在某个任务上训练得到的结果作为另一个 XGBoost 模型的特征。考虑两个数据集的特征集合重叠。例如，我们可以为合并后的数据集设计一个自监督的分类任务。然后，我们可以在目标数据集上训练第二个
    XGBoost 模型，该模型以原始特征集作为输入，并结合第一个 XGBoost 模型的输出。
- en: '**5-2.** When applying data augmentations, we usually have to increase the
    training time as well; it is possible that we needed to train the model for a
    longer period.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**5-2.** 在应用数据增强时，我们通常还需要增加训练时间；因此，可能需要更长时间来训练模型。'
- en: Alternatively, we may have applied too much data augmentation. Augmenting the
    data too much can result in excessive variations that do not reflect the natural
    variations in the data, leading to overfitting or poor generalization to new data.
    In the case of MNIST, this can also include translating or cropping the image
    in such a way that the digits become unrecognizable due to missing parts.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可能应用了过多的数据增强。过度增强数据可能导致过度变化，这些变化并不反映数据中的自然变化，从而导致过拟合或对新数据的泛化能力差。以 MNIST
    为例，这也可能包括对图像进行平移或裁剪，使得由于缺失部分而使数字变得无法识别。
- en: Another possibility is that we’ve applied naive, domain-inconsistent augmentation.
    For example, suppose we are mirroring or flipping images vertically or horizontally.
    For MNIST, this doesn’t make sense, because flipping handwritten digits vertically
    or horizontally would create numbers that don’t exist in the real world.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可能性是我们应用了过于简单、领域不一致的数据增强。例如，假设我们正在对图像进行垂直或水平翻转。如果是 MNIST 数据集，这样做就没有意义，因为将手写数字垂直或水平翻转会生成现实中不存在的数字。
- en: '**Chapter 6**'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第6章**'
- en: '**6-1.** Tuning the number of training epochs is a simpler and more universal
    approach. This is especially true for older frameworks that don’t support model
    checkpointing. Changing the number of training epochs may therefore be an easier
    solution and is particularly attractive for small datasets and models where each
    hyperparameter configuration is cheap to run and evaluate. This approach also
    eliminates the need for monitoring the performance on a validation set during
    training, making it straightforward and easy to use.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**6-1.** 调整训练周期数是一个更简单且更普遍的方法。这对于不支持模型检查点的旧框架尤为适用。因此，改变训练周期数可能是一个更容易的解决方案，尤其适用于小型数据集和模型，在这些情况下，每个超参数配置的运行和评估成本较低。此方法还避免了在训练过程中需要监控验证集性能，使得使用起来更加简单和直接。'
- en: The early-stopping and checkpointing approach is especially useful when working
    with models that are expensive to train. It’s generally also a more flexible and
    robust method for preventing overfitting. However, a downside of this approach
    is that, in noisy training regimes, we may end up prioritizing an early epoch
    even though the validation set accuracy is not a good estimate of the generalization
    accuracy.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 提前停止和检查点方法对于训练成本高昂的模型特别有用。通常，它也是一种更灵活和更强健的防止过拟合的方法。然而，这种方法的一个缺点是，在噪声较大的训练环境下，我们可能会优先选择一个较早的训练周期，即使验证集的准确度并不能很好地估计泛化精度。
- en: '**6-2.** One obvious downside of ensemble methods is the increased computational
    cost. For example, if we build a neural network ensemble of five neural networks,
    this ensemble can be five times as expensive as every single model.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**6-2.** 集成方法的一个显而易见的缺点是计算成本增加。例如，如果我们建立一个包含五个神经网络的神经网络集成，那么这个集成的成本可能是单个模型的五倍。'
- en: While we often consider the inferencing costs mentioned above, the increased
    storage cost is another significant limitation. Nowadays, most computer vision
    and language models have millions or even billions of parameters that have to
    be stored in a distributed setting. Model ensembling complicates this further.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们通常会考虑上述的推理成本，但存储成本的增加是另一个显著的限制因素。如今，大多数计算机视觉和语言模型拥有数百万甚至数十亿个参数，这些参数必须在分布式环境中存储。模型集成使得这一问题更加复杂。
- en: Reduced interpretability is yet another cost that we incur when using model
    ensembles. Understanding and analyzing the predictions of a single model can already
    be challenging. Depending on the ensembling approach, we add yet another layer
    of complexity that reduces interpretability.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模型集成时，降低可解释性是我们需要承担的另一个成本。理解和分析单个模型的预测已经是一个挑战。根据集成方法的不同，我们可能会增加额外的复杂度，从而降低可解释性。
- en: '**Chapter 7**'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第7章**'
- en: '**7-1.** The Adam optimizer implements an adaptive method that comes with internal
    weight parameters. Adam has two optimizer parameters (mean and variance) per model
    parameter, so instead of only splitting the weight tensors of the model, we also
    have to split the optimizer states to work around memory limitations. (Note that
    this is already implemented in most DeepSpeed parallelization techniques.)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**7-1.** Adam优化器实现了一种带有内部权重参数的自适应方法。Adam每个模型参数有两个优化器参数（均值和方差），因此我们不仅需要拆分模型的权重张量，还需要拆分优化器的状态以应对内存限制。（请注意，这在大多数DeepSpeed并行化技术中已经实现。）'
- en: '**7-2.** Data parallelism could theoretically work on a CPU, but the benefits
    would be limited. For example, instead of duplicating the model in CPU memory
    to train multiple models on different batches of the dataset in parallel, it could
    make more sense to increase the data throughput.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**7-2.** 数据并行性理论上可以在CPU上工作，但其好处将是有限的。例如，和在CPU内存中复制模型以并行训练多个不同数据批次的模型相比，增加数据吞吐量可能更为合理。'
- en: '**Chapter 8**'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第8章**'
- en: '**8-1.** Self-attention has quadratic compute and memory complexity due to
    the *n*-to-*n* comparisons (where *n* is the input sequence length), which makes
    transformers computationally costly compared to other neural network architectures.
    Moreover, decoder-style transformers such as GPT generate outputs one token at
    a time, which cannot be parallelized during inference (although generating each
    token is still highly parallelizable, as discussed in [Chapter 8](ch08.xhtml)).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**8-1.** 自注意力机制由于*n*对*n*的比较（其中*n*是输入序列的长度）而具有二次计算和内存复杂度，这使得与其他神经网络架构相比，变换器的计算成本较高。此外，像GPT这样的解码器风格变换器生成输出是一次生成一个标记，这在推理时不能并行化（尽管正如在[第8章](ch08.xhtml)中讨论的那样，生成每个标记仍然是高度并行化的）。'
- en: '**8-2.** Yes, we can think of self-attention as a form of feature selection,
    although there are differences between this and other types of feature selection.
    It is important to differentiate between hard and soft attention in this context.
    Soft attention computes importance weights for all inputs, whereas hard attention
    selects a subset of the inputs. Hard attention is more like masking, where certain
    inputs are set to 0 or 1, while soft attention allows for a continuous range of
    importance scores. The main difference between attention and feature selection
    is that feature selection is typically a fixed operation, while attention weights
    are computed dynamically based on the input. With feature-selection algorithms,
    the selected features are always the same, whereas with attention, the weights
    can change based on the input.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**8-2.** 是的，我们可以将自注意力看作一种特征选择方式，尽管它与其他类型的特征选择存在差异。在这种情况下，区分硬注意力和软注意力非常重要。软注意力为所有输入计算重要性权重，而硬注意力则选择输入的一个子集。硬注意力更像是掩码操作，其中某些输入被设置为0或1，而软注意力允许一个连续的范围的权重。注意力与特征选择的主要区别在于，特征选择通常是一个固定操作，而注意力权重是基于输入动态计算的。在特征选择算法中，选定的特征始终是相同的，而在注意力机制中，权重则可以根据输入变化。'
- en: '**Chapter 9**'
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第9章**'
- en: '**9-1.** Automating this evaluation is inherently difficult, and the gold standard
    is currently based on human evaluation and judgment. However, a few metrics exist
    as quantitative measures.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**9-1.** 自动化这种评估本身就很困难，目前的黄金标准仍然基于人工评估和判断。然而，也存在一些度量标准作为定量指标。'
- en: To evaluate the diversity of the generated images, one can compare the conditional
    class distribution and the marginal class distribution of generated samples, using,
    for example, a Kullback–Leibler-divergence (KL-divergence) regularization term.
    This measure is also used in the VAE to make the latent space vectors similar
    to a standard Gaussian. The higher the KL-divergence term, the more diverse the
    generated images.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估生成图像的多样性，可以比较生成样本的条件类别分布和边际类别分布，例如使用Kullback–Leibler散度（KL散度）正则化项。这种度量方法在VAE中也用于使潜在空间向量类似于标准高斯分布。KL散度项越高，生成的图像多样性越大。
- en: One can also compare the statistics of generated images to real images in the
    feature space of a pretrained model, such as a convolutional network trained as
    an image classifier. A high similarity (or low distance) indicates that the two
    distributions are close to each other, which is generally a sign of better image
    quality. This approach is also often known as the *Fréchet inception distance
    approach*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以将生成图像的统计数据与真实图像进行比较，使用预训练模型的特征空间，如作为图像分类器训练的卷积网络。如果相似度很高（或距离很小），则表示这两个分布彼此接近，这通常是图像质量更好的标志。这种方法通常也被称为*Fréchet起始距离方法*。
- en: '**9-2.** Like the generators of GANs, VAEs, or diffusion models, a consistency
    model takes a noise tensor sampled from a simple distribution (such as a standard
    Gaussian) as input and generates a new image.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**9-2.** 像GAN、VAE或扩散模型的生成器一样，一致性模型也将从简单分布（如标准高斯分布）中采样的噪声张量作为输入，生成新的图像。'
- en: '**Chapter 10**'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第10章**'
- en: '**10-1.** Yes, we can make top-*k* sampling deterministic by setting *k* =
    1 so that the model will always select the word with the highest probability score
    as the next word when generating the output text.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**10-1.** 是的，我们可以通过设置*k* = 1来使top-*k*采样具有确定性，这样模型在生成输出文本时会始终选择具有最高概率分数的单词作为下一个单词。'
- en: We can also make nucleus sampling deterministic, such as by setting the probability
    mass threshold *p* such that it includes only one item, which either exactly meets
    or exceeds this threshold. This would make the model always choose the token with
    the highest probability.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使核采样具有确定性，例如通过设置概率质量阈值*p*，使其仅包括一个项目，该项目要么恰好满足阈值，要么超过阈值。这将使模型始终选择具有最高概率的标记。
- en: '**10-2.** In some cases, the random behavior of dropout during inference can
    be desirable, such as when building model ensembles with a single model. (Without
    the random behavior in dropout, the model would produce exactly the same results
    for a given input, which would make an ensemble redundant.)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**10-2.** 在某些情况下，推理过程中丢弃层的随机行为是可以接受的，例如在使用单一模型构建模型集成时。（如果没有丢弃层中的随机行为，模型对于给定输入将始终产生相同的结果，这样集成模型就没有意义了。）'
- en: Moreover, the random inference behavior in dropout can be useful for robustness
    testing. For critical applications, like healthcare or autonomous driving, it’s
    essential to understand how slight variations to the model can impact its predictions.
    By using deterministic dropout patterns, we can simulate these slight variations
    and test the robustness of the model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，dropout 中的随机推理行为对于鲁棒性测试非常有用。对于关键应用，如医疗保健或自动驾驶，理解模型的微小变化如何影响其预测至关重要。通过使用确定性
    dropout 模式，我们可以模拟这些微小变化并测试模型的鲁棒性。
- en: '**Chapter 11**'
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第 11 章**'
- en: '**11-1.** SGD has only the learning rate as a hyperparameter, but it does not
    have any parameters. Therefore, it does not add any additional parameters to be
    stored besides the gradients calculated for each weight parameter during backpropagation
    (including the layer activations required for calculating the gradients).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**11-1.** SGD 只有学习率作为超参数，但没有其他参数。因此，除了在反向传播过程中为每个权重参数计算的梯度（包括计算梯度所需的层激活值）之外，它不会增加任何额外的参数存储。'
- en: The Adam optimizer is more complex and requires more storage. Specifically,
    Adam keeps an exponentially decaying average of past gradients (first moment)
    and an exponentially decaying average of past squared gradients (second raw moment)
    for each parameter. Therefore, for each parameter in the network, Adam needs to
    store two additional values. If we have *n* parameters in the network, Adam requires
    storage for 2*n* additional parameters.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Adam 优化器更为复杂，且需要更多的存储。具体来说，Adam 会为每个参数保存过去梯度的指数衰减平均值（第一矩）和过去平方梯度的指数衰减平均值（第二原矩）。因此，对于网络中的每个参数，Adam
    需要存储两个额外的值。如果网络中有 *n* 个参数，Adam 需要为 2*n* 个额外的参数分配存储空间。
- en: If the network has *n* trainable parameters, Adam adds 2*n* parameters to be
    tracked. For example, in the case of AlexNet, which consists of 26,926 parameters,
    as calculated in Exercise 1-1, Adam requires 53,852 additional values in total
    (2 *×* 26,926).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果网络中有 *n* 个可训练参数，Adam 会增加 2*n* 个参数用于跟踪。例如，在 AlexNet 中，网络包含 26,926 个参数（如练习 1-1
    中所计算），因此 Adam 总共需要额外的 53,852 个值（2 *×* 26,926）。
- en: '**11-2.** Each BatchNorm layer learns two sets of parameters during training:
    a set of scaling coefficients (gamma) and a set of shifting coefficients (beta).
    These are learned so that the model can undo the normalization when it is found
    to be detrimental to learning. Each of these sets of parameters (gamma and beta)
    has the same size as the number of channels (or neurons) in the layer they normalize
    because these parameters are learned separately for each channel (or neuron).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**11-2.** 每个 BatchNorm 层在训练过程中学习两组参数：一组缩放系数（gamma）和一组偏移系数（beta）。这些系数的学习目的是让模型在发现标准化对学习不利时能够将其反转。每一组参数（gamma
    和 beta）的大小与它们所标准化的层中的通道数（或神经元数）相同，因为这些参数是为每个通道（或神经元）单独学习的。'
- en: For the first BatchNorm layer following the first convolutional layer with five
    output channels, this adds 10 additional parameters. For the second BatchNorm
    layer, following the second convolutional layer with 12 output channels, this
    adds 24 additional parameters.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个 BatchNorm 层，它位于第一个卷积层之后，且有五个输出通道，这将增加 10 个额外的参数。对于第二个 BatchNorm 层，它位于第二个卷积层之后，且有
    12 个输出通道，这将增加 24 个额外的参数。
- en: The first fully connected layer has 128 output channels, which means 256 additional
    BatchNorm parameters. The second fully connected layer is not accompanied by a
    BatchNorm layer since it’s the output layer.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个全连接层有 128 个输出通道，这意味着需要 256 个额外的 BatchNorm 参数。第二个全连接层没有伴随 BatchNorm 层，因为它是输出层。
- en: Therefore, BatchNorm adds 10 + 24 + 256 = 290 additional parameters to the network.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，BatchNorm 向网络中添加了 10 + 24 + 256 = 290 个额外的参数。
- en: '**Chapter 12**'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第 12 章**'
- en: '**12-1.** Just increasing the stride from 1 to 2 (or larger values) should
    not affect the equivalence since the kernel size is equal to the input size in
    both scenarios, so there is no sliding window mechanism at play here.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**12-1.** 仅仅将步幅从 1 增加到 2（或更大的值）不应影响等价性，因为在这两种情况下，卷积核的大小都等于输入的大小，因此这里没有滑动窗口机制。'
- en: '**12-2.** Increasing the padding to values larger than 0 will affect the results.
    Due to the padded inputs, we will have the sliding window convolutional operation
    where the equivalence with fully connected layers no longer holds. In other words,
    the padding would alter the input’s spatial dimensions, which would no longer
    match the kernel size and would result in more than one output value per feature
    map.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**12-2.** 将填充增加到大于0的值将影响结果。由于填充的输入，我们将进行滑动窗口卷积操作，在这种操作中，完全连接层的等价性不再成立。换句话说，填充会改变输入的空间维度，这将不再与卷积核的大小匹配，并且每个特征图会产生多个输出值。'
- en: '**Chapter 13**'
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第13章**'
- en: '**13-1.** Using smaller patches increases the number of patches for a given
    input image, leading to a higher number of tokens being fed into the transformer.
    This results in increased computational complexity, as the self-attention mechanism
    in transformers has quadratic complexity with respect to the number of input tokens.
    Consequently, smaller input patches make the model computationally more expensive.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**13-1.** 使用更小的补丁会增加给定输入图像的补丁数量，从而导致更多的标记被输入到变换器中。这会增加计算复杂度，因为变换器中的自注意力机制在输入标记数量上具有二次复杂度。因此，更小的输入补丁会使模型的计算成本更高。'
- en: '**13-2.** Using larger input patches may result in the loss of finer details
    and local structures in the input image, which can potentially negatively affect
    the model’s predictive performance. Interested readers might enjoy the FlexiViT
    paper that studies the computational and predictiveperformance trade-offs as a
    consequence of the patch size and number (Lucas Beyer et al., “FlexiViT: One Model
    for All Patch Sizes” [2022], *[https://arxiv.org/abs/2212.08013](https://arxiv.org/abs/2212.08013)*).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**13-2.** 使用更大的输入补丁可能会导致输入图像中较精细的细节和局部结构的丢失，这可能会对模型的预测性能产生负面影响。感兴趣的读者可能会喜欢《FlexiViT》论文，该论文研究了补丁大小和数量对计算和预测性能的权衡（Lucas
    Beyer等，“FlexiViT: One Model for All Patch Sizes” [2022]，*[https://arxiv.org/abs/2212.08013](https://arxiv.org/abs/2212.08013)*）。'
- en: '**Chapter 14**'
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第14章**'
- en: '**14-1.** Because homophones have different meanings, we expect them to appear
    in other contexts, such as *there* and *their* in “I can see you over there” and
    “Their paper is very nice.”'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**14-1.** 由于同音词具有不同的含义，我们预计它们会出现在其他上下文中，例如“there”和“their”在“I can see you over
    there”和“Their paper is very nice”中的使用。'
- en: Since the distributional hypothesis says that words with similar meanings should
    appear in similar contexts, homophones do not contradict the distributional hypothesis.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于分布假设认为具有相似含义的词应出现在相似的上下文中，因此同音词并不违背分布假设。
- en: '**14-2.** The underlying idea of the distributional hypothesis can be applied
    to other domains, such as computer vision. In the case of images, objects that
    appear in similar visual contexts are likely to be semantically related. On a
    lower level, neighboring pixels are likely semantically related, as they are part
    of the same object; this idea is used in masked autoen-coding for self-supervised
    learning on image data. (We covered masked autoencoders in [Chapter 2](ch02.xhtml).)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**14-2.** 分布假设的基本思想可以应用于其他领域，例如计算机视觉。在图像的情况下，出现在相似视觉上下文中的物体可能在语义上相关。在更低的层面，邻近的像素可能在语义上相关，因为它们是同一物体的一部分；这一思想被用于图像数据的自监督学习中的掩码自编码器。（我们在[第2章](ch02.xhtml)中讨论了掩码自编码器。）'
- en: Another example is protein modeling. For example, researchers showed that language
    transformers trained on protein sequences (a string representation where each
    letter represents an amino acid, like *MNGTEGPNFYVPFSNKTGVV . . .*) learn embeddings
    where similar amino acids cluster together (Alexander Rives et al., “Biological
    Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million
    Protein Sequences” [2019], *[https://www.biorxiv.org/content/10.1101/622803v1.full](https://www.biorxiv.org/content/10.1101/622803v1.full)*).
    The hydrophobic amino acids such as V, I, L, and M appear in one cluster, and
    aromatic amino acids such as F, W, and Y appear in another cluster. In this context,
    we can think of an amino acid as an equivalent to a word in a sentence.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是蛋白质建模。例如，研究人员表明，训练在蛋白质序列上的语言变换器（其中每个字母代表一个氨基酸的字符串表示，例如*MNGTEGPNFYVPFSNKTGVV
    . . .*）学习到的嵌入中，类似的氨基酸会聚集在一起（Alexander Rives等，“Biological Structure and Function
    Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences” [2019]，*[https://www.biorxiv.org/content/10.1101/622803v1.full](https://www.biorxiv.org/content/10.1101/622803v1.full)*）。例如，疏水性氨基酸如V、I、L和M出现在同一簇中，而芳香族氨基酸如F、W和Y出现在另一个簇中。在这个背景下，我们可以将氨基酸视为句子中的一个词。
- en: '**Chapter 15**'
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第15章**'
- en: '**15-1.** Assuming that the existing data does not suffer from privacy concerns,
    data augmentation helps generate variations of the existing data without the need
    to collect additional data, which can help with privacy concerns.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**15-1.** 假设现有数据不存在隐私问题，数据增强有助于生成现有数据的变体，而无需收集额外的数据，这有助于解决隐私问题。'
- en: However, if the original data includes personally identifiable information,
    even augmented or synthetic data could potentially be linked back to individuals,
    especially if the augmentation process doesn’t sufficiently obscure or alter the
    original data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果原始数据包含个人可识别信息，即使是增强数据或合成数据也可能会与个人信息产生关联，特别是如果增强过程未能充分遮蔽或改变原始数据。
- en: '**15-2.** Data augmentation might be less beneficial if the original dataset
    is already large and diverse enough that the model isn’t overfitting or underperforming
    due to a lack of data. This is, for example, often the case when pretraining LLMs.
    The performance of highly domain-specific models (for example, in the medical,
    law, and financial domains) could also be adversely affected by techniques such
    as synonym replacement and back translation due to replacing domain-specific terms
    with a certain meaning. In general, in contexts of tasks highly sensitive to wording
    choices, data augmentation must be applied with particular care.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**15-2.** 如果原始数据集已经足够大且多样，以至于模型不会因为数据不足而出现过拟合或性能不足的情况，那么数据增强可能不那么有益。例如，在预训练大型语言模型（LLMs）时，通常会出现这种情况。高度专业化领域的模型（例如医学、法律和金融领域）可能会受到同义词替换和回译等技术的负面影响，因为这些技术可能会将领域特定术语替换为具有特定含义的词汇。一般来说，在那些对措辞选择非常敏感的任务背景中，数据增强必须格外小心地应用。'
- en: '**Chapter 16**'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第16章**'
- en: '**16-1.** The self-attention mechanism has quadratic time and memory complexity.
    More precisely, we can express the time and memory complexity of self-attention
    as *O*(*N*² *× d*), where *N* is the length of the sequence and *d* is the dimensionality
    of the embedding of each element in the sequence.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**16-1.** 自注意力机制具有二次时间和内存复杂度。更精确地说，我们可以将自注意力的时间和内存复杂度表示为 *O*(*N*² *× d*)，其中
    *N* 是序列的长度，*d* 是序列中每个元素的嵌入维度。'
- en: This is because self-attention involves computing a similarity score between
    each pair of elements in the sequence. For example, we have an input matrix *X*
    with *N* tokens (rows) where each token is a *d*-dimensional embedding (columns).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为自注意力机制涉及计算序列中每一对元素之间的相似度。例如，我们有一个输入矩阵 *X*，它有 *N* 个标记（行），其中每个标记是一个 *d* 维的嵌入向量（列）。
- en: When we compute the dot product of each token embedding to each other token
    embedding, we multiply *XX^T*, which results in an *N×N* similarity matrix. This
    multiplication involves *d* multiplications for a single token pair, and we have
    *N*² such pairs. Hence, we have *O*(*N*²*×d*) complexity. The *N×N* similarity
    matrix is then used to compute weighted averages of the sequence elements, resulting
    in an *N×d* output representation. This can make self-attention computationally
    expensive and memory intensive, particularly for long sequences or large values
    of *d*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们计算每个标记嵌入与其他标记嵌入的点积时，我们进行 *XX^T* 乘法，结果是一个 *N×N* 的相似度矩阵。这种乘法对于单个标记对来说涉及 *d*
    次乘法，而我们有 *N*² 对这样的标记对。因此，计算复杂度为 *O*(*N*²*×d*)。然后，*N×N* 的相似度矩阵被用来计算序列元素的加权平均值，最终得到一个
    *N×d* 的输出表示。这使得自注意力机制在计算上非常昂贵，并且对内存要求较高，尤其是在长序列或 *d* 值较大的情况下。
- en: '**16-2.** Yes. Interestingly, self-attention may partly be inspired by the
    spatial attention mechanisms used in convolutional neural networks for image processing
    (Kelvin Xu et al., “Show, Attend and Tell: Neural Image Caption Generation with
    Visual Attention” [2015], *[https://arxiv.org/abs/1502.03044](https://arxiv.org/abs/1502.03044)*).
    Spatial attention is a mechanism that allows a neural network to focus on specific
    regions of an image that are relevant to a given task. It works by selectively
    weighting the importance of different spatial locations in the image, which allows
    the network to “pay more attention” to certain areas and ignore others.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**16-2.** 是的。有趣的是，自注意力机制可能部分受到用于图像处理的卷积神经网络中的空间注意力机制的启发（Kelvin Xu 等，“Show,
    Attend and Tell: Neural Image Caption Generation with Visual Attention” [2015]，*
    [https://arxiv.org/abs/1502.03044](https://arxiv.org/abs/1502.03044) *）。空间注意力是一种机制，允许神经网络专注于图像中与给定任务相关的特定区域。它通过选择性地加权图像中不同空间位置的重要性，使网络能够“更多地关注”某些区域并忽略其他区域。'
- en: '**Chapter 17**'
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第17章**'
- en: '**17-1.** To adapt a pretrained BERT model for classification, you need to
    add an output layer for classification, often referred to as a *classification
    head*.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**17-1.** 要将预训练的BERT模型适应分类任务，您需要添加一个分类的输出层，通常称为*分类头*。'
- en: As discussed, BERT uses a [CLS] token for the next-sentence prediction task
    during pretraining. Instead of training it for next-sentence prediction, we can
    fine-tune a new output layer for our target prediction task, such as sentiment
    classification.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，BERT在预训练时使用[CLS]标记进行下句预测任务。我们可以微调一个新的输出层来完成我们的目标预测任务，比如情感分类，而不是将其训练用于下句预测。
- en: The embedded [CLS] output vector serves as a summary of the entire input sequence.
    We can think of it as a feature vector and train a small neural network on top
    of it, typically a fully connected layer followed by a softmax activation function
    to predict the class probabilities. The fully connected layer’s output size should
    match the number of classes in our classification task. Then we can train it using
    back-propagation as usual. Different fine-tuning strategies (updating all layers
    versus only the last layer) can then be used to train the model on a supervised
    dataset, for example.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入的[CLS]输出向量作为整个输入序列的摘要。我们可以将其视为特征向量，并在其上训练一个小型神经网络，通常是一个全连接层，后跟softmax激活函数，用于预测类别概率。全连接层的输出大小应与我们分类任务中的类别数量相匹配。然后，我们可以像往常一样使用反向传播进行训练。不同的微调策略（更新所有层与仅更新最后一层）可以用来在监督数据集上训练模型，例如。
- en: '**17-2.** Yes, we can fine-tune a decoder-only model like GPT for classification
    tasks, although it might not be as effective as using encoder-based models like
    BERT. In contrast to BERT, we do not need to use a special [CLS], but the fundamental
    concept is similar to fine-tuning an encoder-style model for classification. We
    add a classification head (a fully connected layer and a softmax activation) and
    train it on the embedding (the final hidden state) of the first generated output
    token. (This is analogous to using the [CLS] token embedding.)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**17-2.** 是的，我们可以对像GPT这样的仅解码器模型进行微调，以用于分类任务，尽管它可能不如使用基于编码器的模型（如BERT）有效。与BERT不同，我们不需要使用特殊的[CLS]标记，但基本概念类似于对编码器风格模型进行微调以进行分类。我们添加一个分类头（一个全连接层和一个softmax激活函数），并在第一个生成的输出标记的嵌入（最终的隐藏状态）上进行训练。（这类似于使用[CLS]标记的嵌入。）'
- en: '**Chapter 18**'
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第18章**'
- en: '**18-1.** In-context learning is useful if we don’t have access to the model
    or if we want to adapt the model to similar tasks that the model wasn’t trained
    to do.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**18-1.** 如果我们无法访问模型，或者想将模型适应于其未被训练过的类似任务时，上下文学习是有用的。'
- en: In contrast, fine-tuning is useful for adapting the model to a new target domain.
    For example, suppose the model was pretrained on a general corpus and we want
    to apply it to financial data or documents. Here, it would make sense to fine-tune
    the model on data from that target domain.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，微调对于将模型适应新目标领域非常有用。例如，假设该模型是在一个通用语料库上预训练的，而我们想将其应用于金融数据或文档。在这种情况下，微调模型以适应该目标领域的数据是有意义的。
- en: Note that in-context learning can be used with a fine-tuned model as well. For
    example, when a pretrained language model is fine-tuned on a specific task or
    domain, in-context learning then leverages the model’s ability to generate responses
    based on the context provided within the input that may be more accurate given
    the target domain compared to in-context learning without fine-tuning.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在微调模型时也可以使用上下文学习。例如，当一个预训练的语言模型在特定任务或领域上进行微调时，上下文学习会利用该模型根据输入中提供的上下文生成响应的能力，相较于没有微调的上下文学习，这可能会在目标领域中提供更准确的结果。
- en: '**18-2.** This is done implicitly. In prefix tuning, adapters, and LoRA, the
    original knowledge of the pretrained language model is preserved by keeping the
    core model parameters frozen while introducing additional learnable parameters
    that adapt to the new task.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**18-2.** 这是隐式完成的。在前缀微调、适配器和LoRA中，预训练语言模型的原始知识通过保持核心模型参数冻结的方式得以保留，同时引入额外的可学习参数，这些参数适应新的任务。'
- en: '**Chapter 19**'
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第19章**'
- en: '**19-1.** If we were using an embedding technique like Word2Vec that processes
    each word independently, we would expect the cosine similarity between the “cat”
    embeddings to be 1.0\. However, we are using a transformer model to produce the
    embeddings in this case. Transformers use self-attention mechanisms that consider
    the whole context (for instance, input text) when producing the embedding vectors.
    (See [Chapter 16](ch16.xhtml) for more information about self-attention.) Since
    the word *cat* is used in two different sentences, the BERT model produces a different
    embedding for these two instances of *cat*.”'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**19-1.** 如果我们使用像Word2Vec这样的嵌入技术，它会独立处理每个词，那么我们会期望“cat”词嵌入之间的余弦相似度为1.0。然而，在本例中，我们使用的是变换器模型来生成嵌入。变换器使用自注意力机制，在生成嵌入向量时考虑整个上下文（例如输入文本）。(有关自注意力的更多信息，请参见[第16章](ch16.xhtml))。由于*cat*一词在两个不同的句子中出现，BERT模型为这两个*cat*实例生成了不同的嵌入。'
- en: '**19-2.** Switching the candidate and reference texts has the same effect as
    calculating the maximum cosine similarity scores across columns (as shown in step
    5 of [Figure 19-3](ch19.xhtml#ch19fig3)) versus rows, which can result in different
    BERT-Scores for specific texts. That’s why the BERTScore is often computed as
    an F1 score similar to ROUGE in practice. For instance, we calculate the BERTScore
    one way (recall), then the other (precision), and then compute the harmonic mean
    (F1 score).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**19-2.** 切换候选文本和参考文本的效果与计算跨列的最大余弦相似度（如[图19-3](ch19.xhtml#ch19fig3)第5步所示）与跨行计算相似，这可能导致特定文本的BERT-Score不同。因此，BERTScore通常在实践中计算为类似于ROUGE的F1分数。例如，我们先计算一种方式的BERTScore（召回率），然后计算另一种方式（精准率），最后计算调和均值（F1分数）。'
- en: '**Chapter 20**'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第20章**'
- en: '**20-1.** Random forests, typically based on CART decision trees, cannot be
    readily updated as new data arrives. Hence, a stateless training approach would
    be the only viable option. On the other hand, suppose we switched to using neural
    network models such as recurrent neural networks. In that case, a stateful approach
    could make more sense since the neural network could be readily updated on new
    data. (However, in the beginning, comparing stateful and stateless systems side
    by side is always a good idea before deciding which method works best.)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**20-1.** 随机森林通常基于CART决策树，不能随着新数据的到来轻松更新。因此，无状态训练方法将是唯一可行的选择。另一方面，假设我们改为使用神经网络模型，例如递归神经网络，那么有状态方法可能更有意义，因为神经网络可以根据新数据进行即时更新。（然而，在开始时，比较有状态和无状态系统是个好主意，这样可以在决定使用哪种方法之前了解哪种方法最有效。）'
- en: '**20-2.** A stateful retraining approach makes the most sense here. Instead
    of training a new model on a combination of existing data, including user feedback,
    it makes more sense to update the model based on user feedback. Large language
    models are usually pretrained in a self-supervised fashion and then fine-tuned
    via supervised learning. Training large language models is very expensive, so
    updating the model via stateful retraining makes sense rather than training it
    from scratch again.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**20-2.** 在这里，采用有状态重训练方法最为合理。与其在现有数据（包括用户反馈）的基础上训练一个新模型，更合理的做法是根据用户反馈更新模型。大型语言模型通常是通过自监督的方式预训练，然后通过监督学习进行微调。训练大型语言模型非常昂贵，因此通过有状态重训练来更新模型，而不是重新从头开始训练，是更合适的做法。'
- en: '**Chapter 21**'
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第21章**'
- en: '**21-1.** From the information provided, it is unclear whether this is a data-centric
    approach. The AI system relies heavily on data inputs to make predictions and
    recommendations, but that’s true for any machine learning approach for AI. To
    determine whether this approach is an example of data-centric AI, we need to know
    how the AI system was developed. If it was developed by using a fixed model and
    refining the training data, this could qualify as a data-centric approach; otherwise,
    it’s just regular machine learning and predictive modeling.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**21-1.** 根据提供的信息，目前不清楚这是否是一个以数据为中心的方法。AI系统在做出预测和推荐时，严重依赖数据输入，但这对于任何AI的机器学习方法来说都是如此。为了确定这种方法是否是数据中心的AI示例，我们需要知道AI系统是如何开发的。如果它是通过使用固定模型并精细化训练数据来开发的，那么这可能算作数据中心的方法；否则，它只是常规的机器学习和预测建模。'
- en: '**21-2.** If we are keeping the model fixed—that is, reusing the same ResNet-34
    architecture—and are changing only the data augmentation approach to investigate
    its influence on the model performance, we could consider this a data-centric
    approach. However, data augmentation is also routinely done as part of any modern
    machine learning pipeline, and the use of data augmentation alone does not tell
    us whether an approach is data centric. Under the modern definition, a data-centric
    approach entails actively studying the difference between various dataset-enhancing
    techniques while keeping the remaining modeling and training pipeline fixed.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**21-2.** 如果我们保持模型不变——即重用相同的ResNet-34架构——并且仅改变数据增强方法以研究其对模型性能的影响，那么我们可以将其视为数据驱动的方法。然而，数据增强通常也是现代机器学习管道的一部分，单独使用数据增强并不能告诉我们某种方法是否以数据为中心。根据现代定义，数据驱动的方法意味着在保持其余建模和训练管道不变的情况下，积极研究不同数据集增强技术之间的差异。'
- en: '**Chapter 22**'
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第22章**'
- en: '**22-1.** One downside of using multi-GPU strategies for inference is the additional
    communication overhead between the GPUs. However, for inference tasks, which are
    relatively small compared to training since they don’t require gradient computations
    and updates, the time it takes to communicate between GPUs could outweigh the
    time saved by parallelization.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**22-1.** 使用多GPU策略进行推理的一个缺点是GPU之间的额外通信开销。然而，对于推理任务，由于不需要梯度计算和更新，相比训练，推理任务相对较小，GPU之间的通信所需时间可能会超过并行化所节省的时间。'
- en: Managing multiple GPUs also means higher equipment and energy costs. In practice,
    optimizing models for single-GPU or CPU performance is usually more worthwhile.
    If multiple GPUs are available, processing multiple samples in parallel on separate
    GPUs often makes more sense than processing the same sample via multiple GPUs.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 管理多个GPU也意味着更高的设备和能源成本。实际上，优化单GPU或CPU性能通常更具价值。如果有多个GPU可用，在不同GPU上并行处理多个样本通常比通过多个GPU处理同一样本更有意义。
- en: '**22-2.** Loop tiling is often combined with vectorization. For example, after
    applying loop tiling, each tile can be processed using vectorized operations.
    This allows us to use SIMD instructions on data that is already in the cache,
    increasing the effectiveness of both techniques.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**22-2.** 循环分块通常与向量化结合使用。例如，在应用循环分块后，每个块可以使用向量化操作进行处理。这使我们能够对已经在缓存中的数据使用SIMD指令，从而提高两种技术的效果。'
- en: '**Chapter 23**'
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第23章**'
- en: '**23-1.** The problem is that importance weighting assumes the test set distribution
    matches the deployment distribution. However, this is often not the case for various
    reasons, such as changing user behavior, evolving product features, or dynamic
    environments.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**23-1.** 问题在于重要性加权假设测试集分布与部署分布一致。然而，由于各种原因，如用户行为变化、产品特性演变或环境动态，这种假设通常不成立。'
- en: '**23-2.** It’s common to monitor metrics such as classification accuracy, where
    a drop in performance may indicate a shift in the data. However, this is impractical
    if we don’t have access to the labels of incoming data.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**23-2.** 常见的做法是监控分类准确率等指标，性能下降可能表明数据发生了变化。然而，如果我们无法访问新数据的标签，这种做法就不切实际。'
- en: In cases where it’s infeasible to label new, incoming data, we can use statistical
    two-sample tests to determine whether the examples come from the same distribution.
    We can also use adversarial validation, discussed in [Chapter 29](ch29.xhtml).
    However, these methods won’t help detect concept shifts, as they compare only
    input distributions, not the relationship between inputs and outputs.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在无法标记新到数据的情况下，我们可以使用统计学的两样本检验来确定示例是否来自相同的分布。我们还可以使用对抗验证，详见[第29章](ch29.xhtml)。然而，这些方法无法帮助检测概念漂移，因为它们仅比较输入分布，而不是输入与输出之间的关系。
- en: 'Other methods include measuring the reconstruction error: if we have an autoencoder
    trained on our source data, we can monitor the reconstruction error on new data.
    If the error increases significantly, it may indicate a shift in the input distribution.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 其他方法包括测量重构误差：如果我们有一个在源数据上训练的自编码器，我们可以监控新数据的重构误差。如果误差显著增加，这可能表明输入分布发生了变化。
- en: Outlier detection is another common technique. Here, unusually high rates of
    data points being identified as outliers could suggest a shift in data distribution.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值检测是另一种常见技术。在这里，数据点被识别为异常值的异常高比例可能表明数据分布发生了变化。
- en: '**Chapter 24**'
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第24章**'
- en: '**24-1.** Trying to predict the number of goals a player scores (based on data
    from past seasons, for example) is a Poisson regression problem. On the other
    hand, we could also apply an ordinal regression model to the different players
    to rank them by the number of goals they will score. However, since the goal difference
    is constant and can be quantified (for example, the difference between 3 and 4
    goals is the same as the difference between 15 and 16 goals), it’s not an ideal
    problem for an ordinal regression model.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**24-1.** 尝试预测一个球员进球数（例如基于过去赛季的数据）是一个泊松回归问题。另一方面，我们也可以应用有序回归模型对不同球员进行排名，按照他们将进球的数量进行排序。然而，由于进球差距是固定的并且可以量化（例如，3和4个进球之间的差距与15和16个进球之间的差距是一样的），这并不是一个适合有序回归模型的问题。'
- en: '**24-2.** This is a ranking issue that resembles an ordinal regression issue,
    but there are some differences. Since we are aware of only the relative order
    of the movies, a pairwise ranking algorithm might be a more appropriate solution
    than an ordinal regression model.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**24-2.** 这是一个类似于有序回归问题的排名问题，但也有一些区别。由于我们仅知道电影的相对顺序，成对排名算法可能比有序回归模型更合适。'
- en: However, if the person is asked to assign numerical labels to each movie on
    a scale such as 1 to 5 (similar to the star rating system on Amazon), it would
    be possible to train and use an ordinal regression model on this type of data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果让被评估者为每部电影分配数值标签（如1到5的评分尺度，类似于亚马逊上的星级评分系统），那么就可以对这种类型的数据训练并使用有序回归模型。
- en: '**Chapter 25**'
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第25章**'
- en: '**25-1.** The choice of the confidence level (90 percent, 95 percent, 99 percent,
    and so forth) affects the width of the confidence interval. A higher confidence
    level will produce a wider interval because we need to cast a wider net to be
    more confident that we have captured the true parameter.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**25-1.** 置信度水平（90%、95%、99%等）的选择会影响置信区间的宽度。较高的置信度水平会产生更宽的区间，因为我们需要撒出更大的网，以确保更有信心地捕捉到真实参数。'
- en: Conversely, a lower confidence level produces a narrower interval, reflecting
    more uncertainty about where the true parameter lies. A 90 percent confidence
    interval is therefore narrower than a 95 percent confidence interval, reflecting
    greater uncertainty about the location of the true population parameter. Colloquially
    speaking, we are 90 percent certain that the true parameter lies within a small
    range of values. To increase this certainty, we must increase the width to 95
    percent or 99 percent.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，较低的置信度会产生一个较窄的区间，反映出对于真实参数位置的不确定性较大。因此，90%的置信区间比95%的置信区间要窄，反映出对于真实总体参数位置的更大不确定性。通俗来说，我们有90%的把握认为真实参数位于一个较小的数值范围内。为了增加这种确定性，我们必须将宽度增加到95%或99%。
- en: For example, let’s say we are 90 percent certain that it will rain in the next
    two weeks in Wisconsin. If we want to make a prediction with 95 percent confidence
    without collecting additional data, we would have to increase the time interval.
    For example, we might say that we are 95 percent certain that it will rain within
    the next four weeks, or 99 percent certain that it will rain within the next two
    months.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有90%的把握相信在未来两周内威斯康星州会下雨。如果我们希望在没有收集额外数据的情况下以95%的置信度做出预测，我们需要增加时间间隔。例如，我们可以说我们有95%的把握认为未来四周内会下雨，或者99%的把握认为在未来两个月内会下雨。
- en: '**25-2.** Since the model is already trained and stays the same, applying it
    to each test set would be wasteful. To speed up the process outlined in this section,
    we technically need to apply the model only once, namely on the original test
    set. We can then bootstrap the actual and predicted labels directly (instead of
    the original samples) to create the bootstrapped test sets. We can then compute
    the test set accuracies based on the bootstrapped labels in each set.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**25-2.** 由于模型已经训练完成并且保持不变，将其应用于每个测试集会显得浪费。为了加速本节中描述的过程，我们从技术上来说只需要在原始测试集上应用模型一次。然后，我们可以直接对实际标签和预测标签进行自助抽样（而不是对原始样本进行抽样），以创建自助抽样的测试集。接着，我们可以基于每个集合中自助抽样的标签计算测试集的准确度。'
- en: '**Chapter 26**'
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第26章**'
- en: '**26-1.** The prediction set size can tell us a lot about the certainty of
    the prediction. If the prediction set size is small (for example, 1 in classification
    tasks), it indicates a high level of confidence in the prediction. The algorithm
    has enough evidence to strongly suggest one specific outcome.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**26-1.** 预测集的大小可以告诉我们关于预测置信度的很多信息。如果预测集的大小较小（例如，在分类任务中为 1），这表明对预测有很高的信心。算法有足够的证据强烈推荐某个特定的结果。'
- en: If the prediction set size is larger (for example, 3 in classification tasks),
    it indicates more uncertainty. The model is less confident about the prediction
    and considers multiple outcomes to be plausible. In practice, we can use this
    information to assign more resources to examples with a high prediction set size.
    For example, we may flag these cases for human verification since the machine
    learning model is less certain.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预测集的大小较大（例如，在分类任务中为 3），这表示更多的不确定性。模型对预测的信心较低，并且认为多个结果都是可能的。在实际操作中，我们可以利用这一信息为预测集大小较大的样本分配更多资源。例如，我们可以将这些案例标记为需要人工验证，因为机器学习模型的信心较低。
- en: '**26-2.** Absolutely. Confidence intervals are just as applicable to regression
    models as they are to classification models. In fact, they’re even more versatile
    in the context of regression. For example, we can compute confidence intervals
    for the performance of a model, like the mean squared error, using the methods
    illustrated in [Chapter 25](ch25.xhtml). (But we can also compute confidence intervals
    for individual predictions and model parameters. If you’re interested in confidence
    intervals for model parameters, check out my article “Interpretable Machine Learning—Book
    Review and Thoughts About Linear and Logistic Regression as Interpretable Models”
    at *[https://sebastianraschka.com/blog/2020/interpretable-ml-1.html](https://sebastianraschka.com/blog/2020/interpretable-ml-1.html)*.)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**26-2.** 绝对正确。置信区间同样适用于回归模型，就像它们适用于分类模型一样。实际上，在回归的上下文中，它们甚至更为通用。例如，我们可以使用[第25章](ch25.xhtml)中所示的方法计算模型性能的置信区间，如均方误差。（但我们也可以为个别预测和模型参数计算置信区间。如果你对模型参数的置信区间感兴趣，可以查看我的文章《可解释的机器学习——关于线性和逻辑回归作为可解释模型的书评与思考》，网址为
    *[https://sebastianraschka.com/blog/2020/interpretable-ml-1.html](https://sebastianraschka.com/blog/2020/interpretable-ml-1.html)*。）'
- en: We can also compute conformal prediction intervals for regression models. The
    interval is a range of possible target values instead of a single point estimate.
    The interpretation of such a prediction interval is that, under the assumption
    that the future is statistically similar to the past (for instance, based on the
    data the model was trained on), the true target value for a new instance will
    fall within this range with a certain confidence level, such as 95 percent.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以为回归模型计算符合性预测区间。该区间是一个可能的目标值范围，而不是单一的点估计。对这样的预测区间的解释是，在假设未来与过去在统计上相似的前提下（例如，基于模型训练时的数据），新的实例的真实目标值将在该范围内，以一定的置信度，例如
    95%。
- en: '**Chapter 27**'
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**第27章**'
- en: '**27-1.** Since the MAE is based on an absolute value around the distance,
    it naturally satisfies the first criterion: it can’t be negative. Also, the MAE
    is the same if we swap the values *y* and *ŷ*; hence, it satisfies the second
    criterion. But how about the triangle inequality? Similar to how the RMSE is the
    same as the Euclidean distance or L2 norm, the MAE is similar to the L1 norm between
    two vectors. Since all vector norms satisfy the triangle inequality (Horn and
    Johnson, *Matrix Analysis*, Cambridge University Press, 1990), our colleague is
    incorrect.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**27-1.** 由于 MAE 是基于距离的绝对值，它自然满足第一个标准：不能为负数。此外，如果我们交换 *y* 和 *ŷ* 的值，MAE 的结果保持不变，因此它满足第二个标准。那么，三角不等式如何呢？类似于
    RMSE 与欧几里得距离或 L2 范数的关系，MAE 与两个向量之间的 L1 范数相似。由于所有向量范数都满足三角不等式（Horn 和 Johnson，《矩阵分析》，剑桥大学出版社，1990），所以我们的同事是错误的。'
- en: Furthermore, even if the MAE were not a proper metric, it could still be a useful
    model evaluation metric; for example, consider the classification accuracy.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，即使 MAE 不是一个合适的度量标准，它仍然可以作为一个有用的模型评估指标；例如，考虑分类准确率。
- en: '**27-2.** The MAE assigns equal weight to all errors, while the RMSE places
    more emphasis on errors with larger absolute values due to the quadratic exponent.
    As a result, the RMSE is always at least as large as the MAE. However, no metric
    is universally better than the other, and they have both been used to assess model
    performance in countless studies over the years.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**27-2.** MAE对所有误差赋予相同的权重，而RMSE由于二次幂的关系，对较大绝对值的误差给予更多关注。因此，RMSE总是至少与MAE一样大。然而，没有哪个指标在所有情况下都比另一个好，它们都在多年的无数研究中被用来评估模型性能。'
- en: If you are interested in additional comparisons between MAE and RMSE, you may
    like the article by Cort J. Willmott and Kenji Matsuura, “Advantages of the Mean
    Absolute Error (MAE) Over the Root Mean Square Error (RMSE) in Assessing Average
    Model Performance” (2005), *[https://www.int-res.com/abstracts/cr/v30/n1/p79-82](https://www.int-res.com/abstracts/cr/v30/n1/p79-82)*.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对MAE和RMSE之间的更多比较感兴趣，你可能会喜欢Cort J. Willmott和Kenji Matsuura的文章《在评估平均模型性能时，平均绝对误差（MAE）相对于均方根误差（RMSE）的优点》（2005），*
    [https://www.int-res.com/abstracts/cr/v30/n1/p79-82](https://www.int-res.com/abstracts/cr/v30/n1/p79-82)*。
- en: '**Chapter 28**'
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Chapter 28**'
- en: '**28-1.** This is not a problem if we care about only the average performance.
    For example, if we have a dataset of 100 training examples, and the model predicts
    70 out of the 100 validation folds correctly, we estimate the model accuracy as
    70 percent. However, suppose we are interested in analyzing the variance of the
    estimates from the different folds. In that case, LOOCV is not very useful: since
    each fold consists of only a single training example, we cannot compute the variance
    of each fold and compare it to other folds.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**28-1.** 如果我们只关心平均表现，这就不是问题。例如，如果我们有一个包含100个训练样本的数据集，且模型在100个验证折叠中正确预测了70个，我们估计模型的准确率为70%。然而，假设我们有兴趣分析不同折叠的估计值的方差。在这种情况下，LOOCV就不太有用：因为每个折叠仅包含一个训练样本，我们无法计算每个折叠的方差并将其与其他折叠进行比较。'
- en: '**28-2.** Another use case of *k*-fold cross-validation is model ensembling.
    For example, in 5-fold cross-validation, we train five different models since
    we have five slightly different training sets. However, instead of training a
    final model on the whole training set, we can combine the five models into a model
    ensemble (this is particularly popular on Kaggle). See [Figure 6-3](ch06.xhtml#ch6fig3)
    on [page 34](ch06.xhtml#ch6fig3) for an illustration of this process.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**28-2.** *k*折交叉验证的另一个使用场景是模型集成。例如，在5折交叉验证中，我们训练五个不同的模型，因为我们有五个稍微不同的训练集。然而，除了在整个训练集上训练最终模型之外，我们还可以将这五个模型组合成一个模型集成（这在Kaggle上特别流行）。有关这个过程的示意图，请参见[图6-3](ch06.xhtml#ch6fig3)，位于[第34页](ch06.xhtml#ch6fig3)。'
- en: '**Chapter 29**'
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Chapter 29**'
- en: '**29-1.** As a performance baseline, it’s a good idea to implement a zero-rule
    classifier, such as a majority class classifier. Since we typically have more
    training data than test data, we can compute the performance of a model that always
    predicts *Is test? False*, which should result in 70 percent accuracy if we have
    partitioned the original dataset into 70 percent training data and 30 percent
    test data. If the accuracy of the model trained on the adversarial validation
    dataset noticeably exceeds this baseline (say, 80 percent), we may have a serious
    discrepancy issue to investigate further.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**29-1.** 作为性能基准，实施零规则分类器（例如多数类分类器）是一个好主意。因为我们通常拥有比测试数据更多的训练数据，我们可以计算一个总是预测*Is
    test? False*的模型的表现，如果我们将原始数据集划分为70%的训练数据和30%的测试数据，它应该会得到70%的准确率。如果训练在对抗验证数据集上的模型的准确率明显超过这个基准（比如80%），我们可能需要进一步调查一个严重的差异问题。'
- en: '**29-2.** Overall, this is not a big issue since we are mainly interested in
    whether there is a strong deviation from a majority class prediction baseline.
    For instance, if we compare the accuracy of the adversarial validation model against
    the baseline (rather than 50 percent accuracy), there should be no issue. However,
    it may be even better to consider evaluation metrics like Matthew’s correlation
    coefficient or ROC or precision-recall area-under-the-curve values instead of
    classification accuracy.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**29-2.** 总的来说，这不是一个大问题，因为我们主要关心是否存在偏离多数类预测基准的强偏差。例如，如果我们将对抗验证模型的准确率与基准进行比较（而不是50%的准确率），则不应存在问题。然而，考虑像Matthew相关系数、ROC或精确度-召回曲线下面积等评估指标可能更好，而不是分类准确率。'
- en: '**Chapter 30**'
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**Chapter 30**'
- en: '**30-1.** While we often think of self-supervised learning and transfer learning
    as separate approaches, they don’t have to be exclusive. For instance, we could
    pretrain a model on a labeled or larger unlabeled image dataset using self-supervised
    learning (in this case, the millions of unlabeled images corresponding to the
    various computing devices).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**30-1.** 虽然我们通常将自监督学习和迁移学习视为不同的方法，但它们并不一定是互斥的。例如，我们可以使用自监督学习在一个带标签或更大规模的未标记图像数据集上预训练模型（在这种情况下，未标记的图像可能对应于各种计算设备的数百万张图片）。'
- en: Instead of starting with random weights, we can use the neural network weights
    from self-supervised learning to follow up with transfer learning via the thousands
    of labeled smartphone pictures. Since smart-phones are related to tablets, transfer
    learning is a very promising approach here.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以不从随机权重开始，而是使用自监督学习的神经网络权重，然后通过数千张带标签的智能手机图片进行迁移学习。由于智能手机与平板电脑相关，迁移学习在这里是一种非常有前景的方法。
- en: Finally, after the self-supervised pretraining and transfer learning, we can
    fine-tune the model on the hundreds of labeled images of the target task, the
    tablets.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在自监督预训练和迁移学习之后，我们可以在目标任务的数百张带标签图片上进行微调，这些任务是与平板电脑相关的。
- en: '**30-2.** Besides mitigation techniques for the overconfident scores from a
    neural network’s output layer, we can also consider various ways of ensembling
    to obtain confidence scores. For instance, instead of disabling dropout during
    inference, we can leverage dropout to obtain multiple different predictions for
    a single example to compute the predicted label uncertainty.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**30-2.** 除了针对神经网络输出层中过于自信的分数的缓解技术外，我们还可以考虑通过集成方法来获取置信度分数。例如，在推理过程中，我们可以利用丢弃法（dropout）来获得一个示例的多个不同预测，从而计算预测标签的不确定性，而不是在推理时禁用丢弃法。'
- en: Another option is to construct model ensembles from different segments of the
    training set using *k*-fold cross-validation, as discussed in the ensemble section
    of [Chapter 6](ch06.xhtml).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用* k *折交叉验证从训练集的不同部分构建模型集成，正如在[第6章](ch06.xhtml)的集成部分中讨论的那样。
- en: It is also possible to apply conformal prediction methods, discussed in [Chapter
    26](ch26.xhtml), to active learning.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以将在[第26章](ch26.xhtml)中讨论的符合性预测方法应用于主动学习。
