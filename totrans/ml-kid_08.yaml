- en: '![](Images/chapterart.png)'
  id: totrans-0
  prefs: []
  type: TYPE_IMG
- en: '10'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Smart Assistants
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![Alphabet-I](Images/Alphabet-I.png)n this chapter, we’ll look at a common
    household use of ML: smart assistants like Siri, Alexa, or Google Home that can
    do simple jobs for you when you ask, like set an alarm, start a timer, or play
    some music.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Smart assistants are ML systems trained to recognize the meaning of text. You’ve
    seen that you can train a computer so that when you give it some writing, the
    computer can recognize what you’re trying to say. And if a computer can understand
    what you mean, it can understand what you’re asking it to do.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: To create a program that categorizes text based on recognizing the text’s intention
    (*intent classification*), we collect a large number of examples of each type
    of command that we want it to recognize and then use ML to train a model.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: From the projects you’ve done so far, you’re already familiar with the *classification*
    *part of intent classification. For example, messages can be classified as compliments
    or insults, and news­paper headlines can be classified as tabloids or broadsheets.
    The computer knows about some categories of writing, and when you give it some
    text, it tries to *classify* that text, or work out which category that text should
    go into. The *intent* part is because we’re using the ability to classify the
    text to recognize its intention.*
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '*Intent classification is useful for building computer systems that we can
    interact with in a natural way. For example, a computer could recognize that when
    you say, “Turn on the light,” the intention is for a light to be switched on.
    This is described as a *natural language interface**. In other words, instead
    of needing to press a switch to turn the light on, you’re using *natural language**—a
    language that has evolved naturally in humans, not one designed for computers—to
    communicate that intent.**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '**The computer learns from the patterns in the examples we give it—patterns
    in the words we choose, the way we phrase commands, how we combine words for certain
    types of commands, and when we use commands that are short versus longer, just
    to name a few.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you’ll make a virtual smart assistant that can recognize your
    commands and carry out your instructions (see [Figure 10-1](#figure10-1)).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '![f10001](Images/f10001.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
- en: '[Figure 10-1:](#figureanchor10-1) Making a smart assistant in Scratch'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Build Your Project
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To start with, you’ll train the ML model to recognize commands to turn two devices—a
    fan and a lamp—on or off.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Code Your Project Without ML
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we saw in Chapter 7, it’s useful to see the difference that ML makes by trying
    to code an AI project without it first. You can skip this step if you feel you
    have a good grasp of the difference between a rule-based approach and ML and would
    rather go straight to using ML.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Go to Scratch at [https://machinelearningforkids.co.uk/scratch3/](https://machinelearningforkids.co.uk/scratch3/).
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Project templates** at the top of the screen, as shown in [Figure 10-2](#figure10-2).![f10002](Images/f10002.png)
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 10-2:](#figureanchor10-2) Project templates include starter projects
    to save you time.'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the **Smart Classroom** template.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the script shown in [Figure 10-3](#figure10-3).![f10003](Images/f10003.png)
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 10-3:](#figureanchor10-3) Coding a smart assistant using rules'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This script asks you to enter a command. If you type `Turn``on` (or `off`) `the``fan`
    (or `lamp`), Scratch will play the corresponding animation. Let’s try it out.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Test your project by clicking the Green Flag. Type the command `Turn on the
    fan` and check that the fan really does start spinning.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What happens if you spell something wrong? What happens if you change the wording
    (for example, “Turn on the fan please”)? What happens if you don’t mention the
    word *fan* (for example, “I’m very hot, we need some air in here!”)?
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Why don’t these work?
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Do you think it’s possible to write a script that would work with any phrasing
    of these four commands?
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Think back to the definition in Chapter 1, where I said ML is not the only way
    to create AI systems. Here you’ve created an AI project using a rules-based approach
    instead of ML. By trying other techniques like this one and seeing where they
    fall short, you can better understand why ML is preferred for so many projects.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Train Your Model
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Create a new ML project, name it `Smart Classroom`, and set it to learn to recognize
    text in your preferred language.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Train**, as shown in [Figure 10-4](#figure10-4).![f10004](Images/f10004.png)
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 10-4:](#figureanchor10-4) The first phase is to collect training examples.'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Add new label**, as shown in [Figure 10-5](#figure10-5), and create
    a training bucket called `fan on`. Repeat this step to create three more training
    buckets named `fan off`, `lamp on`, and `lamp off`. (The underscores will be added
    automatically.)![f10005](Images/f10005.png)
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 10-5:](#figureanchor10-5) Create training buckets for the commands
    to recognize.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Add example** **in the **fan_on** bucket and type an example of how
    you would ask someone to turn on the fan, as shown in [Figure 10-6](#figure10-6).![f10006](Images/f10006.png)
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Figure 10-6:](#figureanchor10-6) Collecting examples of how to ask for the
    fan to be turned on'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It can be short (for example, “fan on please”) or long (“Could you turn the
    fan on for me now, please?”).
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It can be polite (“Would you please switch on the fan?”) or less polite (“Turn
    the fan on now”).
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It can include the words *fan* and *on* (“Can you turn on the fan?”) or neither
    (“It’s too hot in here. Can we get some air in here, please?”).
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Type as many as you can think of, as shown in [Figure 10-6](#figure10-6). You
    need at least five examples, but I’ve given you six already, so that should be
    easy!**
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '***   Click **Add example** in the **fan_off** bucket, as shown in [Figure
    10-7](#figure10-7).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: This time, type as many examples as you can think of for asking someone to turn
    off the fan. You need at least five examples. These are the examples your ML model
    will use to learn what a “fan off” command looks like.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Try to include some examples that don’t include the words *fan* or *off*.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f10007](Images/f10007.png)'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 10-7:](#figureanchor10-7) Collecting examples of how to ask for the
    fan to be turned off'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Repeat this process for the last two buckets, until you have at least five examples
    for all four commands, as shown in [Figure 10-8](#figure10-8).![f10008](Images/f10008.png)
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 10-8:](#figureanchor10-8) Training data for the smart assistant project
    *   Click **Back to project** in the top-left corner of the screen.*   Click **Learn
    & Test**.*   Click **Train new machine learning model**, as shown in [Figure 10-9](#figure10-9).'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The computer will use the examples you’ve written to learn how to recognize
    your four commands. This might take a minute.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f10009](Images/f10009.png)'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 10-9:](#figureanchor10-9) Train an ML model for your smart assistant.'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After training an ML model, we test it to see how good it is at recognizing
    new commands. Type a command into the **Test** box, as shown in [Figure 10-10](#figure10-10).**
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**![f10010](Images/f10010.png)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 10-10:](#figureanchor10-10) Testing your ML model'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: If the model makes mistakes, you can go back to the Train phase and add more
    examples of the commands that it keeps getting wrong. This is like a teacher using
    a student’s poor exam result to figure out which subjects they need to review
    with the student to help improve the student’s understanding.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve added more examples, go back to the Learn & Test phase and train
    a new ML model. Then test it again to see if the computer is any better at recognizing
    commands.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Code Your Project with ML
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you have an ML model that is able to recognize your commands, you can
    re-create the earlier project to use ML instead of the rules you used before.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Click **Back to project** in the top-left corner of the screen.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Make**.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Scratch 3**, and then click **Open in Scratch 3** to open a new window
    in Scratch.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should see a new set of blocks for your ML project in the Toolbox, as shown
    in [Figure 10-11](#figure10-11).
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f10011](Images/f10011.png)'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[Figure 10-11:](#figureanchor10-11) Your ML project will be added to the Scratch
    Toolbox.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Project templates** in the top menu bar and choose the **Smart Classroom**
    template.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the script shown in [Figure 10-12](#figure10-12).
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When you give this script commands, it will use your ML model to recognize the
    command and carry out the instruction.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![f10012](Images/f10012.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: '[Figure 10-12:](#figureanchor10-12) ML approach for a smart assistant'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Test Your Project
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Test your project by clicking the Green Flag and entering a variety of commands,
    phrased in lots of different ways. See how your smart assistant performs now compared
    to the version that didn’t use ML.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Review and Improve Your Project
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审查并改进你的项目
- en: 'You’ve created your own smart assistant: a virtual version of Amazon’s Alexa
    or Apple’s Siri that can understand and carry out your commands! What could you
    do to improve the way that it behaves?'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经创建了自己的智能助手：一个虚拟版的亚马逊Alexa或苹果Siri，可以理解并执行你的命令！你可以做些什么来改善它的表现？
- en: Using Your Model’s Confidence Score
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用你的模型的置信度评分
- en: Back in the Learn & Test phase, you should have noticed the confidence score
    displayed when you tested your model. That tells you how confident the computer
    is that it has recognized a command.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到“学习与测试”阶段时，你应该已经注意到测试模型时显示的置信度评分。这告诉你计算机对识别命令的信心程度。
- en: Go back to the Learn & Test phase now and try typing something that doesn’t
    fit into one of the four commands that the computer has learned to recognize.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在返回到“学习与测试”阶段，尝试输入一些不符合计算机已学习识别的四个命令的内容。
- en: For example, you could try “What is the capital city of France?” as shown in
    [Figure 10-13](#figure10-13).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以尝试提问“法国的首都是什么？” 如[图10-13](#figure10-13)所示。
- en: '![f10013](Images/f10013.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![f10013](Images/f10013.png)'
- en: '[Figure 10-13:](#figureanchor10-13) Testing your smart assistant'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-13：](#figureanchor10-13) 测试你的智能助手'
- en: My ML model recognized it as “lamp on,” but it had 0 percent confidence in that
    classification. That was the ML model’s way of telling me that it hadn’t recognized
    the command.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我的机器学习模型将其识别为“灯开”，但它对这个分类的置信度为0%。那是机器学习模型告诉我它没有识别出该命令的方式。
- en: “What is the capital city of France?” doesn’t look like any of the examples
    I’ve given the ML model. The question doesn’t match the patterns it has identified
    in the examples I used to train it. This means it can’t confidently recognize
    the question as one of the four commands it’s been trained to recognize.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: “法国的首都是什么？”看起来不像我给机器学习模型提供的任何示例。这个问题与我用于训练模型的示例中识别的模式不匹配。这意味着它无法自信地识别这个问题为它已训练的四个命令之一。
- en: Your ML model might have a higher confidence than 0, but it should still be
    a relatively low number. (If not, try adding more examples to train your ML model
    with.)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你的机器学习模型可能有高于0的置信度，但它应该仍然是一个相对较低的数字。（如果不是，尝试添加更多示例来训练你的机器学习模型。）
- en: Experiment with other questions and commands that don’t have anything to do
    with a fan or lamp. Compare the confidence scores your ML model gives with those
    it displays when it recognizes actual fan on, fan off, lamp on, and lamp off commands.
    What kinds of confidence scores does your ML model give when it’s correctly recognized
    something?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试其他与风扇或灯具无关的问题和命令。将你的机器学习模型给出的置信度评分与它识别实际的风扇开、风扇关、灯开和灯关命令时显示的置信度评分进行比较。你的机器学习模型在正确识别某个命令时给出的置信度评分是什么？
- en: Once you have a feel for how the confidence scores work for your ML model, you
    can use that in your Scratch project. Update your script to look like [Figure
    10-14](#figure10-14).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你熟悉了你的机器学习模型的置信度评分如何工作，你可以在你的Scratch项目中使用它。更新你的脚本，使其看起来像[图10-14](#figure10-14)所示。
- en: Now, if the model isn’t at least 80 percent confident that it has understood
    the command correctly, it will display a “sorry” response for 2 seconds and not
    carry out the action.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果模型的信心值不到80%，它将显示一个“抱歉”的回应，持续2秒钟，并且不会执行该操作。
- en: You’ll need to change the `80` value in this script to a percentage that matches
    the behavior of your own ML model.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要将脚本中的`80`值更改为与你的机器学习模型行为相匹配的百分比。
- en: What else could you do to improve your project?
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你还能做些什么来改善你的项目？
- en: '![f10014](Images/f10014.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![f10014](Images/f10014.png)'
- en: '[Figure 10-14:](#figureanchor10-14) Using confidence scores in your ML project'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-14：](#figureanchor10-14) 在你的机器学习项目中使用置信度评分'
- en: Using Speech Input Instead of Typing
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用语音输入代替键盘输入
- en: You could modify your project to be more like real-world smart assistants by
    using voice input instead of typing.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用语音输入代替键盘输入，使你的项目更像现实中的智能助手。
- en: In the Toolbox, click the Extensions Library icon (it looks like two blocks
    and a plus sign), add the **Speech to Text** extension, and update your script
    as shown in [Figure 10-5](#figure10-5).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在工具箱中，点击“扩展库”图标（看起来像两个方块和一个加号），添加**语音转文本**扩展，并更新你的脚本，如[图10-5](#figure10-5)所示。
- en: '![f10015](Images/f10015.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![f10015](Images/f10015.png)'
- en: '[Figure 10-15:](#figureanchor10-15) Adding speech recognition to your smart
    assistant'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-15：](#figureanchor10-15) 为你的智能助手添加语音识别'
- en: What else could you do to improve your project?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你还能做些什么来改善你的项目？
- en: Collecting Training Data
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 收集训练数据
- en: ML is often used for recognizing text because it’s quicker than having to write
    rules. But training a model properly requires lots and lots of examples. To build
    these systems in the real world, we’d need more efficient ways of collecting examples
    than simply typing them all yourself like you’ve done so far. For example, instead
    of asking one person to write 100 examples, it might be better to ask 100 people
    to write one example each. Or 1,000 people. Or 10,000 people.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: If you can figure out when your ML model gets something wrong, you can collect
    more examples to add to your training buckets. For example, what if the ML model
    has a very low confidence score? Or what if someone keeps giving a similar command
    in slightly different ways? That probably means that the ML model isn’t recognizing
    the commands correctly or doing what the person wants, and that’s helpful feedback
    for your training. What if the person clicks a thumbs-down “I’m not happy” button?
    What if they end up pressing a button to do something? What if they sound more
    and more annoyed?
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: There are lots of ways to guess that something hasn’t worked well. And every
    time that happens, that’s an example you could collect and add to one of your
    training buckets so a newer ML model can work a little better next time.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: We use all these sorts of techniques (collecting training examples from large
    numbers of people, getting feedback from users, and many more) to help us build
    computers and devices that can understand what you mean.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: What You Learned
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we’ve looked at how ML is used to recognize the meaning of
    text, and how it can be used to build computer systems that can understand what
    we mean and do what we ask.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: In your project, you used the same type of ML technology that enables *smart
    assistants* *like Amazon’s Alexa, Google Home, Microsoft’s Cortana, and Apple’s
    Siri. *Natural language interfaces* *let us tell our devices what we want them
    to do by using languages like English, instead of only by pressing screens or
    buttons.**
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '**When you ask a smartphone what the time is, or to set an alarm or a timer,
    or to play your favorite song, the computer needs to classify that command. It
    needs to take that series of words that you chose and recognize their intent.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: The makers of smartphones and smart assistants trained an ML model to recognize
    the meaning of user commands by working out a list of categories—all of the possible
    commands they thought users might want to give. And then for each one, they collected
    lots and lots of examples of how someone might give that command.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'In both this project and the real world, the process works like this:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Predict commands that you might give.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Collect examples of each of those commands.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use those examples to train an ML model.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Script or code what you want the computer to do when it recognizes each command.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To create a real smart assistant, you’d have to repeat these steps for thousands
    of commands, not just four. And you would need thousands, or tens of thousands,
    of examples for each command.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个真正的智能助手，你需要为成千上万个命令重复这些步骤，而不仅仅是四个。并且，每个命令你都需要成千上万的示例。
- en: In the next chapter, you’ll use this capability to build programs that can answer
    questions.*******
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，你将利用这个能力构建能够回答问题的程序。*******
