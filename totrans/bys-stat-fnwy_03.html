<html><head></head><body>
<h2 class="h2" id="ch02"><span epub:type="pagebreak" id="page_13"/><strong><span class="big">2</span><br/>MEASURING UNCERTAINTY</strong></h2>&#13;
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>&#13;
<p class="noindent">In <a href="ch01.xhtml#ch01">Chapter 1</a> we looked at some basic reasoning tools we use intuitively to understand how data informs our beliefs. We left a crucial issue unresolved: how can we quantify these tools? In probability theory, rather than describing beliefs with terms like <em>very low</em> and <em>high</em>, we need to assign real numbers to these beliefs. This allows us to create quantitative models of our understanding of the world. With these models, we can see just how much the evidence changes our beliefs, decide when we should change our thinking, and gain a solid understanding of our current state of knowledge. In this chapter, we will apply this concept to quantify the probability of an event.</p>&#13;
<h3 class="h3" id="ch02lev1sec1"><span epub:type="pagebreak" id="page_14"/><strong>What Is a Probability?</strong></h3>&#13;
<p class="noindent">The idea of probability is deeply ingrained in our everyday language. Whenever you say something such as “That seems unlikely!” or “I would be surprised if that’s not the case” or “I’m not sure about that,” you’re making a claim about probability. Probability is a measurement of how strongly we believe things about the world.</p>&#13;
<p class="indent">In the previous chapter we used abstract, qualitative terms to describe our beliefs. To really analyze how we develop and change beliefs, we need to define exactly what a probability is by more formally quantifying <em>P</em>(<em>X</em>)—that is, how strongly we believe in <em>X</em>.</p>&#13;
<p class="indent">We can consider probability an extension of logic. In basic logic we have two values, true and false, which correspond to absolute beliefs. When we say something is true, it means that we are completely certain it is the case. While logic is useful for many problems, very rarely do we believe anything to be absolutely true or absolutely false; there is almost always some level of uncertainty in every decision we make. Probability allows us to extend logic to work with uncertain values between true and false.</p>&#13;
<p class="indent">Computers commonly represent true as 1 and false as 0, and we can use this model with probability as well. <em>P</em>(<em>X</em>) = 0 is the same as saying that <em>X</em> = false, and <em>P</em>(<em>X</em>) = 1 is the same as <em>X</em> = true. Between 0 and 1 we have an infinite range of possible values. A value closer to 0 means we are more certain that something is false, and a value closer to 1 means we’re more certain something is true. It’s worth noting that a value of 0.5 means that we are completely unsure whether something is true or false.</p>&#13;
<p class="indent">Another important part of logic is <em>negation</em>. When we say “not true” we mean false. Likewise, saying “not false” means true. We want probability to work the same way, so we make sure that the probability of <em>X</em> and the negation of the probability of <em>X</em> sum to 1 (in other words, values are either <em>X</em>, or not <em>X</em>). We can express this using the following equation:</p>&#13;
<p class="equ"><em>P</em>(<em>X</em>) + ¬<em>P</em>(<em>X</em>) = 1</p>&#13;
<div class="note">&#13;
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>&#13;
<p class="notep">The <em>¬ symbol means “negation” or “not.”</em></p>&#13;
</div>&#13;
<p class="indent">Using this logic, we can always find the negation of <em>P</em>(<em>X</em>) by subtracting it from 1. So, for example, if <em>P</em>(<em>X</em>) = 1, then its negation, 1 – <em>P</em>(<em>X</em>), must equal 0, conforming to our basic logic rules. And if <em>P</em>(<em>X</em>) = 0, then its negation 1 – <em>P</em>(<em>X</em>) = 1.</p>&#13;
<p class="indent">The next question is how to quantify that uncertainty. We could arbitrarily pick values: say 0.95 means very certain, and 0.05 means very uncertain. However, this doesn’t help us determine probability much more than the abstract terms we’ve used before. Instead, we need to use formal methods to calculate our probabilities.</p>&#13;
<h3 class="h3" id="ch02lev1sec2"><span epub:type="pagebreak" id="page_15"/><strong>Calculating Probabilities by Counting Outcomes of Events</strong></h3>&#13;
<p class="noindent">The most common way to calculate probability is to count outcomes of events. We have two sets of outcomes that are important. The first is all possible outcomes of an event. For a coin toss, this would be “heads” or “tails.” The second is the count of the outcomes you’re interested in. If you’ve decided that heads means you win, the outcomes you care about are those involving heads (in the case of a single coin toss, just one event). The events you’re interested in can be anything: flipping a coin and getting heads, catching the flu, or a UFO landing outside your bedroom. Given these two sets of outcomes—ones you’re interested in and ones you’re not interested in—all we care about is the ratio of outcomes we’re interested in to the total number of possible outcomes.</p>&#13;
<p class="indent">We’ll use the simple example of a coin flip, where the only possible outcomes are the coin landing on heads or landing on tails. The first step is to make a count of all the possible events, which in this case is only two: heads or tails. In probability theory, we use Ω (the capital Greek letter omega) to indicate the set of all events:</p>&#13;
<p class="equ">Ω = {heads, tails}</p>&#13;
<p class="indent">We want to know the probability of getting a heads in a single coin toss, written as <em>P</em>(heads). We therefore look at the number of outcomes we care about, 1, and divide that by the total number of possible outcomes, 2:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0015-01.jpg"/></div>&#13;
<p class="indent">For a single coin toss, we can see that there is one outcome we care about out of two possible outcomes. So the probability of heads is just:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0015-02.jpg"/></div>&#13;
<p class="indent">Now let’s ask a trickier question: what is the probability of getting at least one heads when we toss two coins? Our list of possible events is more complicated; it’s not just {heads, tails} but rather all possible pairs of heads and tails:</p>&#13;
<p class="equ">Ω = {(heads, heads),(heads, tails),(tails, tails),(tails, heads)}</p>&#13;
<p class="indent">To figure out the probability of getting at least one heads, we look at how many of our pairs match our condition, which in this case is:</p>&#13;
<p class="equ">{(heads, heads),(heads, tails),(tails, heads)}</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_16"/>As you can see, the set of events we care about has 3 elements, and there are 4 possible pairs we could get. This means that <em>P</em>(at least one heads) = 3/4.</p>&#13;
<p class="indent">These are simple examples, but if you can count the events you care about and the total possible events, you can come up with a quick and easy probability. As you can imagine, as examples get more complicated, manually counting each possible outcome becomes unfeasible. Solving harder probability problems of this nature often involves a field of mathematics called <em>combinatorics</em>. In <a href="ch04.xhtml#ch04">Chapter 4</a> we’ll see how we can use combinatorics to solve a slightly more complex problem.</p>&#13;
<h3 class="h3" id="ch02lev1sec3"><strong>Calculating Probabilities as Ratios of Beliefs</strong></h3>&#13;
<p class="noindent">Counting events is useful for physical objects, but it’s not so great for the vast majority of real-life probability questions we might have, such as:</p>&#13;
<ul>&#13;
<li class="noindent">“What’s the probability it will rain tomorrow?”</li>&#13;
<li class="noindent">“Do you think she’s the president of the company?”</li>&#13;
<li class="noindent">“Is that a UFO!?”</li>&#13;
</ul>&#13;
<p class="indent">Nearly every day you make countless decisions based on probability, but if someone asked you to solve “How likely do think you are to make your train on time?” you couldn’t calculate it with the method just described.</p>&#13;
<p class="indent">This means we need another approach to probability that can be used to reason about these more abstract problems. As an example, suppose you’re chatting about random topics with a friend. Your friend asks if you’ve heard of the Mandela effect and, since you haven’t, proceeds to tell you: “It’s this weird thing where large groups of people misremember events. For example, many people recall Nelson Mandela dying in prison in the 80s. But the wild thing is that he was released from prison, became president of South Africa, and didn’t die until 2013!” Skeptically, you turn to your friend and say, “That sounds like internet pop psychology. I don’t think anyone seriously misremembered that; I bet there’s not even a Wikipedia entry on it!”</p>&#13;
<p class="indent">From this, you want to measure <em>P</em>(No Wikipedia article on Mandela effect). Let’s assume you are in an area with no cell phone reception, so you can’t quickly verify the answer. You have a high certainty of your belief that there is no such article, and therefore you want to assign a high probability for this belief, but you need to formalize that probability by assigning it a number from 0 to 1. Where do you start?</p>&#13;
<p class="indent">You decide to put your money where your mouth is, telling your friend: “There’s no way that’s real. How about this: <em>you give me $5 if there is no article on the Mandela effect, and I’ll give you $100 if there is one</em>!” Making bets is a practical way that we can express how strongly we hold our beliefs. You believe that the article’s existence is so unlikely that you’ll give your friend $100 if you are wrong and only get $5 from them if you are right. Because <span epub:type="pagebreak" id="page_17"/>we’re talking about quantitative values regarding our beliefs, we can start to figure out an exact probability for your belief that there is no Wikipedia article on the Mandela effect.</p>&#13;
<h4 class="h4" id="ch02lev2sec1"><strong><em>Using Odds to Determine Probability</em></strong></h4>&#13;
<p class="noindent">Your friend’s hypothesis is that there is an article about the Mandela effect: <em>H</em><sub>article</sub>. And you have an alternate hypothesis: <em>H</em><sub>no article</sub>.</p>&#13;
<p class="indent">We don’t have concrete probabilities yet, but your bet expresses how strongly you believe in your hypothesis by giving the <em>odds</em> of the bet. Odds are a common way to represent beliefs as a ratio of how much you would be willing to pay if you were wrong about the outcome of an event to how much you’d want to receive for being correct. For example, say the odds of a horse winning a race are 12 to 1. That means if you pay $1 to take the bet, the track will pay you $12 if the horse wins. While odds are commonly expressed as “<em>m</em> to <em>n</em>” we can also view them as a simple ratio: <em>m</em>/<em>n</em>. There is a direct relationship between odds and probabilities.</p>&#13;
<p class="indent">We can express your bet in terms of odds as “100 to 5.” So how can we turn this into probability? Your odds represent how many times more strongly you believe there <em>isn’t</em> an article than you believe there <em>is</em> an article. We can write this as the ratio of your belief in there being no article, <em>P</em>(<em>H</em><sub>no article</sub>), to your friend’s belief that there is one, <em>P</em>(<em>H</em><sub>article</sub>), like so:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0017-01.jpg"/></div>&#13;
<p class="indent">From the ratio of these two hypotheses, we can see that your belief in the hypothesis that there is no article is 20 times greater than your belief in your friend’s hypothesis. We can use this fact to work out the exact probability for your hypothesis using some high school algebra.</p>&#13;
<h4 class="h4" id="ch02lev2sec2"><strong><em>Solving for the Probabilities</em></strong></h4>&#13;
<p class="noindent">We start writing our equation in terms of the probability of your hypothesis, since this is what we are interested in knowing:</p>&#13;
<p class="equ"><em>P</em>(<em>H</em><sub>no article</sub>) = 20 × <em>P</em>(<em>H</em><sub>article</sub>)</p>&#13;
<p class="indent">We can read this equation as “The probability that there is no article is 20 times greater than the probability there is an article.”</p>&#13;
<p class="indent">There are only two possibilities: either there is a Wikipedia article on the Mandela effect or there isn’t. Because our two hypotheses cover all possibilities, we know that the probability of an <em>article</em> is just 1 minus the probability of <em>no article</em>, so we can substitute <em>P</em>(<em>H</em><sub>article</sub>) with its value in terms of <em>P</em>(<em>H</em><sub>no article</sub>) in our equation like so:</p>&#13;
<p class="equ"><em>P</em>(<em>H</em><sub>no article</sub>) = 20 × (1 – <em>P</em>(<em>H</em><sub>article</sub>))</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_18"/>Next we can expand 20 × (1 – <em>P</em>(<em>H</em><sub>no article</sub>)) by multiplying both parts in the parentheses by 20 and we get:</p>&#13;
<p class="equ"><em>P</em>(<em>H</em><sub>no article</sub>) = 20 – 20 × <em>P</em>(<em>H</em><sub>no article</sub>)</p>&#13;
<p class="indent">We can remove the <em>P</em>(<em>H</em><sub>no article</sub>) term from the right side of the equation by adding 20 × <em>P</em>(<em>H</em><sub>no article</sub>) to both sides to isolate <em>P</em>(<em>H</em><sub>no article</sub>) on the left side of the equation:</p>&#13;
<p class="equ">21 × <em>P</em>(<em>H</em><sub>no article</sub>) = 20</p>&#13;
<p class="indent">And we can divide both sides by 21, finally arriving at:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0018-01.jpg"/></div>&#13;
<p class="indent">Now you have a nice, clearly defined value between 0 and 1 to assign as a concrete, quantitative probability to your belief in the hypothesis that there is no article on the Mandela effect. We can generalize this process of converting odds to probability using the following equation:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0018-02.jpg"/></div>&#13;
<p class="indent">Often in practice, when you’re confronted with assigning a probability to an abstract belief, it can be very helpful to think of how much you would bet on that belief. You would likely take a billion to 1 bet that the sun will rise tomorrow, but you might take much lower odds for your favorite baseball team winning. In either case, you can calculate an exact number for the probability of that belief using the steps we just went through.</p>&#13;
<h4 class="h4" id="ch02lev2sec3"><strong><em>Measuring Beliefs in a Coin Toss</em></strong></h4>&#13;
<p class="noindent">We now have a method for determining the probability of abstract ideas using odds, but the real test of the robustness of this method is whether or not it still works with our coin toss, which we calculated by counting outcomes. Rather than thinking about a coin toss as an <em>event</em>, we can rephrase the question as “How strongly do I believe the next coin toss will be heads?” Now we’re not talking about <em>P</em>(heads) but rather a hypothesis or belief about the coin toss, <em>P</em>(<em>H</em><sub>heads</sub>).</p>&#13;
<p class="indent">Just like before, we need an alternate hypothesis to compare our belief with. We could say the alternate hypothesis is simply not getting heads <em>H</em><sub>¬heads</sub>, but the option of getting tails <em>H</em><sub>tails</sub> is closer to our everyday language, so we’ll use that. At the end of the day what we care about most is making sense. However, it is important for this discussion to acknowledge that:</p>&#13;
<p class="equ"><em>H</em><sub>tails</sub> = <em>H</em><sub>¬heads</sub>, and <em>P</em>(<em>H</em><sub>tails</sub>) = 1 – <em>P</em>(<em>H</em><sub>heads</sub>)</p>&#13;
<p class="indent"><span epub:type="pagebreak" id="page_19"/>We can look at how to model our beliefs as the ratio between these competing hypotheses:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0019-01.jpg"/></div>&#13;
<p class="indent">Remember that we want to read this as “How many times greater do I believe that the outcome will be heads than I do that it will be tails?” As far as bets go, since each outcome is equally uncertain, the only fair odds are 1 to 1. Of course, we can pick any odds as long as the two values are equal: 2 to 2, 5 to 5, or 10 to 10. All of these have the same ratio:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0019-02.jpg"/></div>&#13;
<p class="indent">Given that the ratio of these is always the same, we can simply repeat the process we used to calculate the probability of there being no Wikipedia article on the Mandela effect. We know that our probability of heads and probability of tails must sum to 1, and we know that the ratio of these two probabilities is also 1. So, we have two equations that describe our probabilities:</p>&#13;
<div class="equ-image"><img alt="Image" src="../images/f0019-03.jpg"/></div>&#13;
<p class="indent">If you walk through the process we used when reasoning about the Mandela effect, solving in terms of <em>P</em>(<em>H</em><sub>heads</sub>) you should find the only possible solution to this problem is 1/2. This is exactly the same result we arrived at with our first approach to calculating probabilities of events, and it proves that our method for calculating the probability of a belief is robust enough to use for the probability of events!</p>&#13;
<p class="indent">With these two methods in hand, it’s reasonable to ask which one you should use in which situation. The good news is, since we can see they are equivalent, you can use whichever method is easiest for a given problem.</p>&#13;
<h3 class="h3" id="ch02lev1sec4"><strong>Wrapping Up</strong></h3>&#13;
<p class="noindent">In this chapter we explored two different types of probabilities: those of events and those of beliefs. We define probability as the ratio of the outcome(s) we care about to the number of all possible outcomes.</p>&#13;
<p class="indent">While this is the most common definition of probability, it is difficult to apply to beliefs because most practical, everyday probability problems do not have clear-cut outcomes and so aren’t intuitively assigned discrete numbers.</p>&#13;
<p class="indent">To calculate the probability of beliefs, then, we need to establish how many times more we believe in one hypothesis over another. One good test <span epub:type="pagebreak" id="page_20"/>of this is how much you would be willing to bet on your belief—for example, if you made a bet with a friend in which you’d give them $1,000 for proof that UFOs exist and would receive only $1 from them for proof that UFOs don’t exist. Here you are saying you believe UFOs do not exist 1,000 times more than you believe they do exist.</p>&#13;
<p class="indent">With these tools in hand, you can calculate the probability for a wide range of problems. In the next chapter you’ll learn how you can apply the basic operators of logic, AND and OR, to our probabilities. But before moving on, try using what you’ve learned in this chapter to complete the following exercises.</p>&#13;
<h3 class="h3" id="ch02lev1sec5"><strong>Exercises</strong></h3>&#13;
<p class="noindent">Try answering the following questions to make sure you understand how we can assign real values between 0 and 1 to our beliefs. Solutions to the questions can be found at <em><a href="https://nostarch.com/learnbayes/">https://nostarch.com/learnbayes/</a></em>.</p>&#13;
<ol>&#13;
<li class="noindent">What is the probability of rolling two six-sided dice and getting a value greater than 7?</li>&#13;
<li class="noindent">What is the probability of rolling three six-sided dice and getting a value greater than 7?</li>&#13;
<li class="noindent">The Yankees are playing the Red Sox. You’re a diehard Sox fan and bet your friend they’ll win the game. You’ll pay your friend $30 if the Sox lose and your friend will have to pay you only $5 if the Sox win. What is the probability you have intuitively assigned to the belief that the Red Sox will win?</li>&#13;
</ol>&#13;
</body></html>