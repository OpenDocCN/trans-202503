- en: '**7**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Search**'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/common-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This chapter is about a topic that, perhaps more than any other subject covered
    in this book, we all take for granted: finding the data we want, known as a *search*.
    Searching happens so often, and so quickly, that it’s easy to miss the magic.
    When a word processor underlines a misspelled word that you just typed, a fast
    search has taken place behind the scenes. When you enter part of a filename and
    get a list of matching files on your laptop’s hard drive, that’s another near-instant
    search. And then there’s the ultimate search achievement: the Web. The Web is
    so unfathomably large that we can only guess its true size, and yet, web search
    engines can find relevant web pages in a fraction of a second.'
  prefs: []
  type: TYPE_NORMAL
- en: How does software find what we want so fast?
  prefs: []
  type: TYPE_NORMAL
- en: '**Defining the Search Problem**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s start by getting our terminology straight. A collection of data is known,
    appropriately enough, as a *data collection*. Each item in the data collection
    is a *record*. A record is uniquely identified by a *key* (no relation to the
    cryptography term). A search retrieves the record that matches a given key. For
    a real-world example, when you use a dictionary the word you’re looking up is
    the key, and the definition of that word is the record.
  prefs: []
  type: TYPE_NORMAL
- en: The main goal of searching is to find the right record. But the speed of the
    search is just as important. If searches could go on indefinitely, searching would
    be simple. But as the wait time increases, so does our frustration. The length
    of time we’ll wait on a search varies, but it’s never very long, and in many situations,
    the search must appear to finish instantaneously.
  prefs: []
  type: TYPE_NORMAL
- en: '**Putting Data in Order**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Efficient searching requires well-organized data. When you visit a bookstore,
    for example, finding a novel by a particular author is easy if the store has ordered
    the shelves by authors’ last names. For one thing, you know where to start looking.
    Once you look at the first book on the shelf and see how close its author’s name
    is alphabetically to the author you seek, you would have a good idea where to
    look next.
  prefs: []
  type: TYPE_NORMAL
- en: If the store didn’t shelve its books in any particular order, then finding a
    book would be hard work. The best option is to start at one end of the shelf and
    examine every single book, which is known as a *sequential search*. In the worst
    case, the book you want isn’t even on the shelf, but you wouldn’t know that until
    you’ve looked through the whole collection.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, putting the data collection in a particular order, known as *sorting*,
    is essential for efficient searching. There are many different ways to sort; entire
    books have been written to describe different sorting algorithms for software.
    We’ll look at two methods here.
  prefs: []
  type: TYPE_NORMAL
- en: '***Selection Sort***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If I asked you to put a list of numbers in order, you would most likely use
    what is known as a *selection sort*. First, you’d scan the list to find the lowest
    number, and then you’d cross the number out and copy it to a new list. You would
    repeat the process until all the numbers were in order in the new, sorted list.
  prefs: []
  type: TYPE_NORMAL
- en: The first three steps of a selection sort of nine numbers are shown in [Figure
    7-1](ch07.html#ch7fig1). In the first step, the lowest number is copied to the
    beginning of a new list. In the steps that follow, the lowest remaining numbers
    are copied to the new list.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-1: The first three steps in a selection sort of nine numbers*'
  prefs: []
  type: TYPE_NORMAL
- en: '***Quicksort***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While selection sort is easy to understand, software rarely uses it because
    it isn’t efficient. Each step requires us to process every number in the unsorted
    list, and for that effort all we get is one number in its correct position.
  prefs: []
  type: TYPE_NORMAL
- en: A better sorting method, called *quicksort*, partially orders all of the data
    processed during each pass, reducing later effort and time. Instead of scanning
    the entire list for the lowest number, we select a number in the list to be the
    *pivot*. We use the pivot to *partition* the list, dividing the list around the
    pivot. Numbers that are less than the pivot go to the front of the list, and those
    that are greater go to the back.
  prefs: []
  type: TYPE_NORMAL
- en: For this example we’ll use the same list of numbers used in the selection sort.
    [Figure 7-2](ch07.html#ch7fig2) shows the first step of partitioning. Different
    versions of quicksort select the pivot in different way; we’ll keep things simple
    and use the first number in the list, 47, as the pivot. The next number, 93, is
    copied to the end of the new list because it is greater than 47.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-2: The number 93 is more than the pivot, so it moves to the end of
    the new list.*'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 7-3](ch07.html#ch7fig3), 56 is also greater than 47, so it’s copied
    to the next space on the end.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-3: The number 56 is more than the pivot, so it moves to the end of
    the new list.*'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 7-4](ch07.html#ch7fig4), 33 is less than 47, so it’s copied to the
    front of the new list.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-4: The number 33 is less than the pivot, so it moves to the front
    of the new list.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-5](ch07.html#ch7fig5) combines the next five steps. Three of the
    remaining numbers go to the front of the list and two go to the back. This leaves
    a gap for one more number.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-5: The remaining numbers in the list are partitioned.*'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 7-6](ch07.html#ch7fig6), this gap is filled with 47, the pivot. This
    completes the initial partitioning.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-6: The pivot fills the open space in the new list.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This new list isn’t sorted, but it’s in better shape than before. The pivot
    is in its correct sorted position, indicated by the shading. The first four numbers
    in the list are less than 47, and the last four are greater than 47\. A single
    partitioning does more than put one number in its correct place, like one step
    of a selection sort; it also divides the remaining numbers in the list into sublists,
    as shown in [Figure 7-7](ch07.html#ch7fig7). These sublists can be sorted independently.
    Sorting two shorter lists requires less effort than sorting one longer list. If
    you doubt this, consider an extreme case: would you rather sort 50 short lists
    of 2 numbers, or 1 long list of 100 numbers?'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-7: Partitioning has transformed the list into two separate, smaller
    lists that can be sorted independently.*'
  prefs: []
  type: TYPE_NORMAL
- en: The two sublists are now independently partitioned. In [Figure 7-8](ch07.html#ch7fig8),
    the first number in the sublist, 33, becomes the new pivot and the four numbers
    of sublist 1 are partitioned. This puts 22 and 11 to the left of the 33, and 45
    to the right.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-8: Partitioning sublist 1 of [Figure 7-7](ch07.html#ch7fig7)*'
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 7-9](ch07.html#ch7fig9), sublist 2 is partitioned using 74 as a pivot.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-9: Partitioning sublist 2 of [Figure 7-7](ch07.html#ch7fig7)*'
  prefs: []
  type: TYPE_NORMAL
- en: These partitions put both of their pivots in their correct sorted places in
    the list. The partitions also create four new sublists, as shown in [Figure 7-10](ch07.html#ch7fig10).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-10: Now four sublists remain. Single-number sublists are trivial.*'
  prefs: []
  type: TYPE_NORMAL
- en: Sublists 4 and 6 contain a single number, which means there’s nothing to partition.
    In [Figure 7-11](ch07.html#ch7fig11), sublists 3 and 5 are partitioned.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-11: Only two trivial sublists remain, which means the whole list
    is sorted.*'
  prefs: []
  type: TYPE_NORMAL
- en: Now we have just two single-number sublists left, which means that the sort
    is complete.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the pivots evenly divided their partitions, but quicksort isn’t
    always so lucky. Sometimes the split is uneven, and in the worst case, the pivot
    could be the lowest or highest number in the list, which means the partitioning
    produces the same result as a step in a selection sort. But most partitions will
    be roughly even, which tends to result in a much faster sort.
  prefs: []
  type: TYPE_NORMAL
- en: More generally, quicksort *scales* much better than selection sort. For any
    sorting method, sorting time increases as the size of the data collection increases,
    but selection sort slows down much more than quicksort. Let’s say a particular
    computer can sort 10,000 records in around a second using either method. On the
    same computer, a selection sort of 1,000,000 records would take nearly 3 hours,
    while a quicksort would take only about 11 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Binary Search**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When data is in order, software can find a particular record easily. One simple
    search method for ordered data is *binary search*. The word *binary* in this case
    doesn’t refer to binary numbers, but to choosing between two alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-12](ch07.html#ch7fig12) shows binary search in action. The record
    we want has a key of 48\. Initially, all we know is that the data in the collection
    is ordered on our key, so the record could appear anywhere. In step 1, we examine
    the record in the middle of the collection. If this record had a key of 48, we
    would we be done, but this is unlikely. However, because this record has a key
    of 62, which is larger than 48, we know that the desired record must appear among
    the first seven records. Thus, examining one record has eliminated not just that
    record from consideration, but also the seven records that appear later in the
    collection.'
  prefs: []
  type: TYPE_NORMAL
- en: In step 2, we examine the fourth record, the midpoint of the remaining seven
    records. This record has a key of 23, which is lower than 48\. Therefore the desired
    record must be in the three records between 23 and 62.
  prefs: []
  type: TYPE_NORMAL
- en: In step 3, we examine the middle of these remaining three records, which has
    a key of 47\. This tells us the desired record must be the one record between
    47 and 62\. If that record did not have a key of 48, it would mean the collection
    did not include a record with that key.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-12: Binary search taking four steps to find a particular record in
    a collection of size 15*'
  prefs: []
  type: TYPE_NORMAL
- en: Each step in a binary search eliminates half of the records from consideration,
    which means binary search scales fantastically well. With a sequential search,
    doubling the size of a data collection doubles the time needed for the average
    search. With binary search, doubling the number of records requires just one more
    step. If we start with 31 records, for example, after examining the middle record,
    either we get lucky and find the desired record, or we find out whether the desired
    record is in the first or last 15 records. Either way we would now have only 15
    records left to search, putting us back where we started in [Figure 7-12](ch07.html#ch7fig12).
    For huge data collections, the difference between binary and sequential search
    is dramatic. A sequential search of 1,000,000 records will examine 500,000 records
    on average, while a binary search of 1,000,000 records will examine no more than
    20.
  prefs: []
  type: TYPE_NORMAL
- en: '**Indexing**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To keep the figures simple, our examples to this point have used just record
    keys. In practice, though, the rest of the record has to be stored somewhere,
    and this can cause problems. To see why, we have to understand the choice software
    faces when allocating storage space for data, whether in main memory, on a hard
    drive, or anywhere else.
  prefs: []
  type: TYPE_NORMAL
- en: '*Fixed-size* storage allocation assigns each record the same amount of space
    and is used for data that is either always the same size or has a small maximum
    size. Credit card numbers, for example, are always 16 digits. The names of credit
    card owners, on the other hand, vary in size, but there are only so many letters
    that will fit on the card. Both card numbers and card-holder names could be stored
    in a fixed number of bytes. In [Figure 7-13](ch07.html#ch7fig13), the maximum
    size of a last name is 15 characters, just long enough for Hammond-Hammond. The
    other names are shorter, resulting in wasted bytes, shown as shaded squares. Because
    the space needed to store a name is small, though, this wasted space is of no
    great concern.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-13: Fixed allocation of storage results in wasted space*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Variable-size* storage allocation exactly fits the data. Consider a collection
    of MP3 files. Roughly speaking, the longer the song, the larger the MP3 file.
    A short pop song might be 3 or 4MB, while a progressive-rock epic might be as
    large as 20MB. We wouldn’t want to store song data in fixed space because this
    would waste too much space for shorter songs, and this would limit the length
    of a song. Instead, the data should be stored in just as much space as needed.'
  prefs: []
  type: TYPE_NORMAL
- en: Variable-size storage allocation uses space efficiently, but fixed-size storage
    allocation is required for software to use efficient search methods. When all
    the records in a collection are the same size, software can quickly find a record
    in a particular position.
  prefs: []
  type: TYPE_NORMAL
- en: This is because storage locations are identified by numerical *addresses*. Every
    byte in digital storage—whether in a computer’s main memory, or on a flash drive
    or hard drive—can be precisely located by its address. If a computer has 8GB of
    main memory, for example, those bytes are numbered from zero to just over eight
    trillion. Collections of fixed-size records are stored contiguously, which makes
    finding a record’s address simple. Suppose a collection has 100 records, each
    20 bytes in size, and the collection begins at address 1,000\. That puts the first
    record at address 1,000, the second at 1,020, the third at 1,040, and so on. We
    can calculate the address of any record by multiplying its position number by
    20 and adding the result to 1,000\. In this way, software can quickly locate any
    record in any collection of fixed-size records.
  prefs: []
  type: TYPE_NORMAL
- en: Finding records quickly is essential for a method like binary search. Without
    fixed-size records, the only way to find a record in a particular position is
    to start from the beginning of the data collection and count the records. That’s
    just a sequential search, and defeats the point.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing between fixed-size and variable-size storage allocation means choosing
    between efficient search and efficient storage. However, a technique called *indexing*
    gives us both. Indexing separates the keys from the rest of the records, much
    as a library card catalog allows patrons to search for books on cards before ultimately
    retrieving the books from the shelves.
  prefs: []
  type: TYPE_NORMAL
- en: An index is a table of record keys and addresses. The addresses themselves are
    stored as binary numbers with a fixed number of bits. For example, when Microsoft
    releases versions of Windows in “32-bit” and “64-bit” editions, those bit counts
    refer to the size of the addresses for main memory. Because the addresses are
    a fixed size, we can store the addresses and keys together in an index of fixed-size
    records that can be searched efficiently using a method like binary search. The
    rest of each record’s data is stored in a variable-size allocation. This produces
    a data collection that is efficient for storage *and* searching.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-14](ch07.html#ch7fig14) shows an indexed data collection of four
    songs. On the left, the index contains the song titles and the addresses for the
    remaining data of each song, such as the artist name and the encoded music. On
    the right is a block of memory cells numbered from 1 to 400\. The arrows point
    to each address.'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the example, this split data allocation allows each record to use
    as much or as little space as needed. It even allows the index and remaining data
    to be on different storage devices. For example, the index might be kept in a
    computer’s fast main memory, while the encoded music data is left on its relatively
    slow hard drive. Because only the index is needed for search, such an arrangement
    allows for efficient search while using the minimum amount of main memory.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-14: An indexed data collection of digital music*'
  prefs: []
  type: TYPE_NORMAL
- en: We can also have multiple indexes for the same data collection. The arrangement
    in [Figure 7-14](ch07.html#ch7fig14) allows individual songs to be quickly located
    by song title, but doesn’t help us search for a song based on artist name or album
    title. Data collections can have multiple indexes for different search criteria,
    and because the main record data is simply referenced by an address, having multiple
    indexes doesn’t greatly affect the total storage requirements for the data collection.
  prefs: []
  type: TYPE_NORMAL
- en: '**Hashing**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although ordered data is required for efficient searching, sorting data takes
    time. So far we’ve discussed sorting as though data collections need to be sorted
    just once. Sometimes that is the case; for example, a word processor needs a list
    of correctly spelled words for spell checking, but that list is created once and
    supplied as part of the application. A spellcheck word list is a *static* data
    collection, one that changes infrequently. However, many of the collections we
    search are *dynamic*—records are frequently added or removed. Because efficient
    searching requires ordered data, collections must be re-sorted following each
    addition or removal. When insertions and deletions are common, the time spent
    re-sorting the data collection can negate the benefit of a faster search. In such
    cases, it may be better to structure the data to facilitate frequent changes.
  prefs: []
  type: TYPE_NORMAL
- en: One data structure that eases additions and removals of records involves hash
    functions, which were introduced in [Chapter 2](ch02.html#ch02). For this example
    let’s imagine a hash function that produces a mere 3-bit hash, equivalent to a
    decimal number in the range of 0 to 7\. We can use this to store records in a
    *hash table* with slots for 8 records. A *slot* is a place where a record could
    be stored.
  prefs: []
  type: TYPE_NORMAL
- en: To store a record in the hash table, we hash the record’s key to determine which
    slot to use. Suppose we are storing MP3 files with song titles as the keys. Four
    titles and their associated hash codes are shown in [Table 7-1](ch07.html#ch7tab1).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 7-1:** Hash Codes for Sample Song Titles'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Song title** | **Hash code** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Life on Mars | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| Nite Flights | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| Surrender | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| The True Wheel | 4 |'
  prefs: []
  type: TYPE_TB
- en: '[Figure 7-15](ch07.html#ch7fig15) shows the hash table after the insertion
    of the first three songs from [Table 7-1](ch07.html#ch7tab1). The first column
    in each record is a bit, which is 1 if the slot is in use and 0 if not. The second
    column is the title, and the third column holds the address of the remaining data.'
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-15: An eight-slot hash table*'
  prefs: []
  type: TYPE_NORMAL
- en: The beauty of a hash table is that a search doesn’t really require searching.
    We just run the key through the hash function and the result tells us where the
    record should be. If there’s no record in that slot, we know right away that the
    collection doesn’t contain a record with that key. Even better, hash tables avoid
    the effort of sorting. This makes a hash table an excellent choice for a collection
    with frequent additions and deletions of records.
  prefs: []
  type: TYPE_NORMAL
- en: However, we haven’t inserted the fourth song in the list. The song title “The
    True Wheel” hashes to 4, the same number as “Nite Flights.” As you may remember
    from [Chapter 2](ch02.html#ch02), a hash function is not guaranteed to produce
    a different hash value for every input, and indeed, some matching hash values,
    or *collisions*, are inevitable. Since we can put only one record in a slot, we
    need a rule for handling collisions. The simplest rule is to use the first empty
    slot after the collision point. Because slot 4 is already occupied with “Nite
    Flights,” we would place “The True Wheel” in the next open slot, which is slot
    5, as shown in [Figure 7-16](ch07.html#ch7fig16).
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-16: Resolving a collision. The second song that hashes to 4 is placed
    in the next empty slot, which is slot 5.*'
  prefs: []
  type: TYPE_NORMAL
- en: This handles the collision problem, but it complicates the use of the hash table.
  prefs: []
  type: TYPE_NORMAL
- en: With this collision rule in place, finding a record is no longer a one-step
    process. Each search still starts at the slot indicated by the hash code, but
    then checks the slots one by one until it finds the matching song title. If the
    search reaches an empty slot, the song isn’t in the collection.
  prefs: []
  type: TYPE_NORMAL
- en: Collisions can also cause records to be stored far from the position indicated
    by the hash code. For example, if a title with a hash code of 5 is inserted into
    the table shown in [Figure 7-16](ch07.html#ch7fig16), even though no previous
    song title has hashed to 5, the slot is already filled by “The True Wheel,” and
    the new song would move all the way to slot 7\. As a hash table fills, these situations
    become more common, degrading search performance; in effect, some hash table searches
    become miniature sequential searches.
  prefs: []
  type: TYPE_NORMAL
- en: Collisions also complicate the deletion of records. Suppose “Nite Flights” is
    removed from the hash table of [Figure 7-16](ch07.html#ch7fig16). The obvious
    way to remove a record is just to mark the slot “empty” again, but that doesn’t
    work. To see why, remember that the song title “The True Wheel” hashed to 4, and
    the song was stored in slot 5 only because slot 4 was occupied at the time. A
    search for “The True Wheel” will begin at slot 4 as indicated by the hash code,
    find the slot empty, and end the search unsuccessfully. The song is still in the
    index table, but can’t be found by a hash search.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid this problem, we can remove the song data but keep the slot marked
    as occupied, as shown in [Figure 7-17](ch07.html#ch7fig17).
  prefs: []
  type: TYPE_NORMAL
- en: Slot 4 is now what is called a *tombstone*. By leaving the slot marked as occupied
    while deleting the data, we ensure that searches still work. However, tombstones
    waste space. Furthermore, because the table never really frees any record slots,
    the performance issues of congestion remain.
  prefs: []
  type: TYPE_NORMAL
- en: For these reasons, hash tables are periodically *rehashed*. Once a certain percentage
    of the slots in a table are occupied, a new, larger table is created, and each
    key in the original table is hashed with a new hash function, producing a fresh,
    sparsely populated table without any tombstones.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-17: Leaving slot 4 marked as occupied after deletion of its data*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Web Search**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All of the techniques shown in this chapter are needed for efficiently searching
    large data collections, and no collection is larger than the Web. A search engine
    such as Google depends upon a vast index, where the keys are search terms, the
    addresses are URLs, and the web pages are the records. The size of the Google
    index is estimated at around 100 petabytes, or 100,000,000 gigabytes. To find
    something in an index this large requires all of the best search techniques. Although
    these techniques help illustrate how an index this large could be searched, they
    don’t tell us how the index was created in the first place.
  prefs: []
  type: TYPE_NORMAL
- en: Search engines use *robots*, programs that run without direct human intervention,
    to build their indexes. The robots crawl all over the Web. Starting at some particular
    web page, they make a list of all the links on that page. Those linked pages are
    then processed to find links to other pages, and so on. Eventually the robot has
    links to most of the content on the Web.
  prefs: []
  type: TYPE_NORMAL
- en: Some content, though, is more difficult to locate. Some pages can’t be reached
    from a site’s home page but are instead found through the site’s own search engine.
    A news site, for example, may not link to older articles but does provide a local
    search for its archives. This unlinked but valuable content is known as the *deep
    web*. Incorporating deep web content into a search engine index usually requires
    some assistance from the site. Site managers have several ways to provide web-crawling
    robots a “table of contents” for all the pages on the site, such as a document
    called a *Sitemap*. This document is named after the *site map* page some sites
    provide for users to quickly find the content they are looking for, but has a
    specific format that’s easy for robots to process. Sitemaps keep search engines
    updated with content changes and are especially useful for sites with deep content
    that would otherwise be left out of search engine indexes.
  prefs: []
  type: TYPE_NORMAL
- en: '***Ranking Results***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As robots gather pages, search engines mine the pages for keywords, counting
    how often each keyword appears on each page. Early search engines employed little
    more than a list of keywords along with their page counts. If you searched for
    *cake*, the page where *cake* most often appeared would be at the top of the returned
    list. That’s logical enough, but a mere word count doesn’t produce what we now
    consider to be good search results.
  prefs: []
  type: TYPE_NORMAL
- en: The first problem is that it’s too easy for someone to exploit the system for
    personal gain. Suppose the operator of a site selling knockoff pharmaceuticals
    wants to get a lot of traffic and doesn’t care how it’s done. When the operator
    discovers that legions of people are searching for *omelette recipe*, the operator
    might put those words on the home page as many times as possible, even hiding
    the words in the behind-the-scenes formatting code. As a result, the site might
    be among the first returned on searches for omelette recipes, even though no such
    recipes appear on the site. Word counts do not guarantee a match between search
    terms and content.
  prefs: []
  type: TYPE_NORMAL
- en: Another website operator might build a site that is legitimately about omelettes,
    but it’s filled with content stolen from Wikipedia, in order to generate revenue
    from ads about a zero-cholesterol egg substitute. In this case, the word count
    correctly connects the search term to matching content, but the quality of the
    content is poor.
  prefs: []
  type: TYPE_NORMAL
- en: The underlying issue is that the websites are self-reporting the nature and
    the quality of their content. What’s missing is the opinion of a disinterested
    viewer. Ideally, search engines could employ an army of reviewers to determine
    what pages are about and how well they cover their chosen topics. The Web is so
    vast and ever-changing, though, that this is a practical impossibility.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, search engines rely on the opinions of other websites. They acquire
    these opinions in the form of *inbound links*. The number of links to a particular
    page is a good metric for how that page is regarded by the online community. In
    [Figure 7-18](ch07.html#ch7fig18), page C has four inbound links, page D has none,
    and each of the others has one. On this basis alone, page C appears to be the
    most valued resource, while A, B, and E appear equally useful.
  prefs: []
  type: TYPE_NORMAL
- en: '![image](graphics/f07-18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*Figure 7-18: The number of links pointing to a page is one factor used by
    search engines to determine ranking.*'
  prefs: []
  type: TYPE_NORMAL
- en: There’s more to the story though. A page with a high inbound link count grants
    more points to the pages it links to. In the previous figure, three pages have
    only one inbound link, but the quality of each link is different. Page E is linked
    from page C, which has a high inbound link count, while pages A and B are linked
    only from each other. Factoring the quality of each link into the link count helps
    to foil *link farming*, in which large numbers of pointless websites are created,
    often through free host services, for the purpose of increasing a target site’s
    inbound link count.
  prefs: []
  type: TYPE_NORMAL
- en: In effect, this turns the Web into a collection of self-organized expert communities.
    When a number of well-regarded cooking sites begin linking to a new omelette-focused
    site, which in turn links back to omelette-related content in the established
    sites, the new site is inducted into the online cooking community. Thereafter,
    the new site’s links count as much as the older, established sites.
  prefs: []
  type: TYPE_NORMAL
- en: '***Using the Index Effectively***'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While building the index is the bulk of the work of making a search engine,
    how the index is used during a search is just as important. Good search results
    require attention to detail.
  prefs: []
  type: TYPE_NORMAL
- en: For one thing, a search engine cannot merely use the supplied search terms as
    keywords. Consider the differences in word forms. You might type *frozen rain*
    in a search box, but most pages with relevant information use the form *freezing
    rain*. By linking together different forms of keywords in its index, a search
    engine can maximize the usefulness of results. This idea applies to synonymous
    terms as well. Because the words *insomnia* and *sleeplessness* mean the same
    thing, searching for either term produces similar results, even though some pages
    predominantly use one word or the other. For example, the Wikipedia article on
    insomnia appears in the first few results for either search term, even though,
    at the time of this writing, the word *sleeplessness* appears only twice in the
    article, while the word *insomnia* appears over 200 times.
  prefs: []
  type: TYPE_NORMAL
- en: The results from these search terms are not identical, though. A search for
    *insomnia* will also include links to the 2002 film *Insomnia*, but these links
    aren’t returned by a search for *sleeplessness*. That result makes sense—presumably,
    no one searching for the film would have entered a synonym of the film’s title—but
    how can a search engine know the two terms are linked in some ways but not others?
  prefs: []
  type: TYPE_NORMAL
- en: Tracking how search terms are combined can yield valuable clues. If searchers
    frequently add the terms *movie* or *film* to the term *insomnia*, then searches
    for just *insomnia* may indicate someone interested in the film and not the medical
    condition.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the links on a search results page are not actually direct links
    to the listed pages. Instead, they are *pass-through links*. For example, if you
    search Google for *insomnia*, then click on the link for the Wikipedia entry,
    you’ll first be taken to the google.com server, which will then redirect you to
    [wikipedia.org](http://wikipedia.org). Google tracks which result you selected,
    and this data, collected from countless users over time, allows Google to fine-tune
    the results, keeping the links that users actually find useful near the top.
  prefs: []
  type: TYPE_NORMAL
- en: Search engines can also make use of the location of the person searching. For
    example, when you search for *smiley’s pizza* while you’re standing in a particular
    town, the search engine appends the town’s name to the search, so that the results
    are localized, instead of returning the websites of the most popular pizzerias
    with that name in the entire world.
  prefs: []
  type: TYPE_NORMAL
- en: '**What’s Next for Web Search**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As impressive as current web search capabilities are, there’s still room for
    improvement.
  prefs: []
  type: TYPE_NORMAL
- en: For example, images provide unique challenges for search engines. Currently,
    image files are indexed based on accompanying text. A search engine might gather
    clues from an image’s filename, or make educated guesses based on the text surrounding
    the image on the page.
  prefs: []
  type: TYPE_NORMAL
- en: We can soon expect the use of *computer vision* techniques in web indexes. Such
    software techniques transform an image into a description of the image. In some
    ways this is the reverse of the graphics techniques described in [Chapters 4](ch04.html#ch04)
    and [5](ch05.html#ch05), where mathematical models were rendered into images.
    With computer vision, images are simplified into mathematical descriptions that
    are then categorized by pattern. Such software is currently used in self-governing
    robots, so that they can recognize an object they have been sent to retrieve.
    Future search engines may process the Web’s images using these techniques, identifying
    both general subjects (“clear sky,” “kittens”) and specific subjects (“Eiffel
    Tower,” “Abraham Lincoln”) within the images.
  prefs: []
  type: TYPE_NORMAL
- en: Indexes will also be updated faster. Currently web indexes update only when
    a web-crawling robot passes through. In the future, indexes may be updated in
    near real time, so that conversations quickly developing throughout social media
    can be indexed as they happen. Eventually, real-time search may be combined with
    artificial intelligence to automatically generate basic news stories from social
    media for fast-breaking events like natural disasters.
  prefs: []
  type: TYPE_NORMAL
- en: But those are tomorrow’s marvels. The Web and its search engines are the marvel
    of today, a powerhouse of information unfathomable just a few decades ago.
  prefs: []
  type: TYPE_NORMAL
