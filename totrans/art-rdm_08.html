<html><head></head><body>
<h2 class="h2" id="ch08"><span epub:type="pagebreak" id="page_239"/><strong><span class="big">8</span><br/>MUSIC</strong></h2>
<div class="image1"><img alt="Image" src="../images/common.jpg"/></div>
<p class="noindent">In this chapter, we’ll continue exploring randomness in art with sound and music. We’ll begin generating sound via random samples, random walks through frequency space, and random walks up and down a musical scale. These projects will prepare us for the chapter’s most ambitious experiment: evolving pleasant melodies from scratch. While we can’t really quantify such a melody, that won’t stop us from trying.</p>
<h3 class="h3" id="ch00lev1_51"><strong>Creating Random Sounds</strong></h3>
<p class="noindent">At first blush, generating a random sound seems straightforward. For instance, if we have some way of creating a sound file, like a WAV (<em>.wav</em> file extension), it follows that we should just need random sound samples at a specified playback rate—right? Let’s implement this, as it will introduce us to the audio tools we need for this section.</p>
<p class="indent">WAV files are easy to read and write via SciPy’s <code>wavfile</code> module. To write a WAV file, we need two things: a specified sampling rate and the samples <span epub:type="pagebreak" id="page_240"/>themselves in some range that programs like <code>mplayer</code> or Audacity will understand.</p>
<p class="indent">We measure the sampling rate, the speed with which the samples are played back, in samples per second. The higher the sampling rate, the better the audio quality. A sampling rate of 22,050 Hz (cycles per second) is sufficient for our purposes. This is half the rate of a compact disc.</p>
<p class="indent">The samples are quantized voltages, a continuous range partitioned into a specified number of discrete steps, with each discrete value specifying a particular analog voltage level. The discrete samples correspond to the output audio waveform. Samples are usually 16-bit signed integers, but we’ll work with 32-bit floating-point samples in the range [–1, 1]. Most audio programs will have little difficulty with floating-point samples.</p>
<p class="indent">To make random sounds, we need to generate random samples, set up the WAV output, and write the samples to disk for playback. Let’s give it a go and hear what happens. The code we want is in <em>random_sounds.py</em>.</p>
<p class="indent">Let’s run it first:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 random_sounds.py 3 tmp.wav</span></pre>
<p class="noindent">Play the three-second output file, <em>tmp.wav</em>. I recommend turning down the volume first. Did you hear what you expected to? Consider <a href="ch08.xhtml#ch08list01">Listing 8-1</a>.</p>
<pre class="pre">from scipy.io.wavfile import write as wavwrite

def WriteOutputWav(samples, name):
    s = (samples - samples.min()) / (samples.max() - samples.min())
    s = (-1.0 + 2.0*s).astype("float32")
    wavwrite(name, rate, s)

rate = 22050
duration = float(sys.argv[1])
oname = sys.argv[2]

nsamples = int(duration * rate)
samples = -1.0 + 2.0*np.random.random(nsamples)

WriteOutputWav(samples, oname)</pre>
<p class="list" id="ch08list01"><em>Listing 8-1: Generating random samples</em></p>
<p class="noindent">I excluded the usual message about the proper form for the command line to focus on the relevant code.</p>
<p class="indent">First, we import <code>wavwrite</code> from SciPy. I renamed <code>write</code> as <code>wavwrite</code> to clarify what the function does. Ignore the <code>WriteOutputWav</code> function for a moment.</p>
<p class="indent">The main part of the file fixes the sampling <code>rate</code> and reads the duration in seconds from the command line, along with the output WAV filename (<code>oname</code>), before calculating <code>nsamples</code>.</p>
<p class="indent">If the samples are played at a given <code>rate</code>, and we want a total <code>duration</code> in seconds, then the product, rounded to an integer, provides us with the <span epub:type="pagebreak" id="page_241"/>number of samples we must generate. The <code>samples</code> are randomly selected in [–1, 1) using NumPy’s pseudorandom generator. There’s no point in using <code>RE</code> here.</p>
<p class="indent">All that remains is to use <code>WriteOutputWav</code> to create the output WAV file. We’ll use this function for all the experiments in this section. The first line rescales the samples to be in the range [0, 1], which lets us be a bit freer with how we generate samples. The second line changes from [0, 1] to [–1, 1], the valid range for floating-point samples. The last line uses <code>wavwrite</code> to dump the WAV file.</p>
<p class="indent">The output of <em>random_sounds.py</em> is so grating due to how humans perceive sound. We like sound that is represented as nice collections of sine waves summed together; in other words, tones with a fundamental frequency and overtones (harmonics). A random collection of unrelated samples can be represented only by summing a large number of sine waves.</p>
<p class="indent"><a href="ch08.xhtml#ch08fig01">Figure 8-1</a> shows a sine wave at 440 Hz on the left and random noise on the right.</p>
<div class="image"><img alt="Image" id="ch08fig01" src="../images/08fig01.jpg"/></div>
<p class="figcap"><em>Figure 8-1: Top left: a sine wave; top right: random noise; bottom left: the frequency spectrum of the sine wave; bottom right: random noise</em></p>
<p class="indent">The top of <a href="ch08.xhtml#ch08fig01">Figure 8-1</a> shows the actual sound samples over time. The bottom shows the frequency spectrum, the strength of the various sine waves that go into the signal, so the <em>x</em>-axis is no longer time but frequency.</p>
<p class="indent">The sine wave is, fundamentally, a single frequency at 440 Hz. The energy at other frequencies is likely due to an imperfect approximation of the pure sine wave. The vertical scale is logarithmic, meaning there is very little energy outside of 440 Hz. The random noise spectrum, however, is roughly uniform over the entire frequency range up to 8,000 Hz, reflecting the number of sine waves that must be summed to approximate the random signal. The <em>x</em>-axis is similarly logarithmic.</p>
<p class="indent">The following two sections explore other approaches to random sound generation, both utilizing the idea of a random walk—not in space, but in frequency. We’ll produce sound using the sum of sine waves. The first section pays no attention to the mix of frequencies, while the second uses frequencies from the notes of a C major scale.</p>
<h4 class="h4" id="ch00lev2_73"><span epub:type="pagebreak" id="page_242"/><em><strong>Sine Waves</strong></em></h4>
<p class="noindent">If we add two sine waves with different frequencies, they merge to become a new wave. Where the two sine waves are positive, they reinforce each other, and the resulting wave is more positive. When one is positive and the other negative, they cancel each other. For example, consider <a href="ch08.xhtml#ch08fig02">Figure 8-2</a>.</p>
<div class="image"><img alt="Image" id="ch08fig02" src="../images/08fig02.jpg"/></div>
<p class="figcap"><em>Figure 8-2: Two sine waves (left) and their sum (right)</em></p>
<p class="indent">On the left are two sine waves with frequencies in the ratio of 3:1. On the right is the sum of the two sine waves on the left. Sum enough waves and any desired output waveform is possible.</p>
<p class="indent">The code in <em>sine_walker.py</em> creates a collection of random walkers that each generate 0.5-second sine waves before altering the frequency used for the next 0.5 seconds. For each 0.5-second block of time, the final wave is the sum of all the walkers. Let’s run the code and then walk through it:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 sine_walker.py 5 3 walk.wav</span></pre>
<p class="noindent">This should produce a 5-second output file consisting of three independent sine wave random walks. Give <em>walk.wav</em> a listen; it reminds me of sound effects in 1950s science fiction movies.</p>
<p class="indent">The <em>sine_walker.py</em> file parses the command line and then configures the values we need for the random walks:</p>
<pre class="pre">nsamples = int(duration * rate)
samples = np.zeros(nsamples, dtype="float32")
dur = 0.5
step_samp = int(dur * rate)
fstep = 5
freq = np.zeros(nwalkers, dtype="uint32")
freq[:] = (440 + 800*(rng.random(nwalkers)-0.5)).astype("uint32")</pre>
<p class="indent"><span epub:type="pagebreak" id="page_243"/>First, we use <code>nsamples</code> to define <code>samples</code>, which holds all output. The next two lines define <code>dur</code>, the step duration, and <code>step_samp</code>, the number of samples in a step. Each sine wave, for a specific frequency, creates this many samples. Next, <code>fstep</code> sets the step size in Hertz, and <code>freq</code> is a vector of initial frequencies in [40, 840) Hertz. The double-definition handles the case where there’s only one walker.</p>
<p class="indent">We then loop until we have generated all samples. Each step is 0.5 seconds long, and each walker generates a sine wave with <code>step_samp</code> samples using its current frequency and a randomly chosen amplitude. We sum the walkers and assign the summed wave to the next 0.5 second’s worth of samples; see <a href="ch08.xhtml#ch08list02">Listing 8-2</a>.</p>
<pre class="pre">   k = 0
<span class="ent">➊</span> while (k &lt; nsamples):
    <span class="ent">➋</span> for i in range(nwalkers):
           r = rng.random()
           if (r &lt; 0.33333):
               freq[i] += fstep
           elif (r &lt; 0.66666):
               freq[i] -= fstep
           freq[i] = min(max(100,freq[i]),4000)
        <span class="ent">➌</span> amp = rng.random()
           if (i == 0):
               t = amp*np.sin(2*np.pi*np.arange(rate*dur)*freq[i]/rate)
           else:
               t += amp*np.sin(2*np.pi*np.arange(rate*dur)*freq[i]/rate)
       n = 1
    <span class="ent">➍</span> while (np.abs(t[-n]) &gt; 1e-4):
           n += 1
       t = t[:-n]
       if ((k+len(t)) &lt; nsamples):
        <span class="ent">➎</span> samples[k:(k+len(t))] = t
       k += len(t)
   
   lo = np.quantile(samples, 0.1)
   hi = np.quantile(samples, 0.9)
   samples[np.where(samples &lt;= lo)] = lo
   samples[np.where(samples &gt;= hi)] = hi
   WriteOutputWav(samples, oname)</pre>
<p class="list" id="ch08list02"><em>Listing 8-2: Generating sine wave walks</em></p>
<p class="indent">A <code>while</code> loop runs over all the output samples <span class="ent">➊</span>. The next <code>for</code> loop <span class="ent">➋</span> is over all walkers for the current step. A random value decides whether to increment, decrement, or leave each walker’s frequency unchanged. Then a quick check with <code>min</code> and <code>max</code> keeps the frequency in the range [100, 4000].</p>
<p class="indent">A sine wave can be written as <em>y</em> = <em>A</em> sin <em>ωx</em> for amplitude <em>A</em> and frequency <em>ω</em> (omega). We select a random amplitude <span class="ent">➌</span> and use it to create a step’s <span epub:type="pagebreak" id="page_244"/>worth of samples that are added to any existing samples, <code>t</code>, thereby summing across all the walkers for the current step.</p>
<p class="indent">Each step’s waveform begins at zero amplitude because the sine function starts at zero. Therefore, we want the end of the previous step to also be at zero amplitude. The second <code>while</code> loop <span class="ent">➍</span> attempts to scan from the end of the step waveform to find a sample reasonably close to zero.</p>
<p class="indent">Finally, we place the samples for the step in the output <code>samples</code> vector <span class="ent">➎</span> if they fit. When <code>samples</code> is full, it’s clipped to keep samples above the 10th percentile and below the 90th, and then written to disk via <code>WriteOutputWav</code>.</p>
<p class="indent">Generate a 15-second or longer sample with one walker. Do you hear the walk? It might help to temporarily set <code>amp=1</code> to make each step equally loud. Use an app on your smartphone to show the frequency spectrum in real time.</p>
<p class="indent">What happens if you add more walkers? Examine the waveform for 50 walkers using a program like Audacity. It should start to resemble noise with little structure.</p>
<p class="indent">Making strange sounds with arbitrary combinations of sine waves is fun, but let’s see if we can be more musical in our approach.</p>
<h4 class="h4" id="ch00lev2_74"><em><strong>C Major Scale</strong></em></h4>
<p class="noindent">The sine walker stepped in frequency by a fixed interval of 5 Hz. The code in <em>note_walker.py</em> is nearly identical to that in <em>sine_walker.py</em>, but instead of altering the frequency of the sine waves by a constant number of Hertz, the walk takes place over the frequencies of the notes in a C major scale:</p>
<pre class="pre">frequencies = np.array([
146.83 ,  164.81 ,  174.61 ,  196.   ,
220.   ,  246.94 ,  261.63 ,  293.66 ,  329.63 ,  349.23 ,
392.   ,  440.   ,  493.88 ,  523.25 ,  587.33 ,  659.26 ,
698.46 ,  783.99 ,  880.   ,  987.77 , 1046.5  ])</pre>
<p class="noindent">In this list, middle C is 261.63 Hz, and A above middle C is 440 Hz. The <em>note_walker.py</em> file uses the same command line as <em>sine_walker.py</em>. Read through the code and give it a go. Is the result the same as <em>sine_walker.py</em>? What instrument does the output remind you of?</p>
<div class="note">
<p class="notet"><strong><span class="notes">NOTE</span></strong></p>
<p class="notep"><em>Electronic oscillators of various frequencies pieced together with other circuits to modulate the resulting final waveform were the backbone of early analog music synthesizers. We can emulate an analog synthesizer in software; see</em> <a href="https://github.com/yuma-m/synthesizer">https://github.com/yuma-m/synthesizer</a>. <em>It’s Python based, and the page provides complete instructions for installing dependencies. The examples on the GitHub page use sine waves as the base waveform, just as we used here.</em></p>
</div>
<p class="indent">Let’s make the leap from randomly varying sine waves to evolving a melody from scratch.</p>
<h3 class="h3" id="ch00lev1_52"><span epub:type="pagebreak" id="page_245"/><strong>Generating Melodies</strong></h3>
<p class="noindent">We’ll use swarms in the service of generating melodies, with the goal of creating a “pleasant” sounding melody from a clean slate.</p>
<p class="indent">First, we’ll set up our environment. Then we’ll learn how to use the program <em>melody_maker.py</em> to generate melodies. Finally, we’ll walk through the essential parts of the code. The objective function is quite a bit more complicated than what we’ve worked with previously.</p>
<h4 class="h4" id="ch00lev2_75"><em><strong>Swarm Search</strong></em></h4>
<p class="noindent">We’ll use MIDI files in this section instead of directly generating WAV files. <em>MIDI (Musical Instrument Digital Interface)</em> is the standard format for digital music. It can be complicated, but our use is as simple as it gets: a single melody line. Therefore, for us, MIDI becomes a NumPy vector of pairs of numbers, the first a note number (60 is middle C), and then a duration where the ratio between the durations marks whole, half, quarter, eighth notes, and so on.</p>
<p class="indent">The melodies we evolve are expressed, ultimately, as MIDI files. Therefore, we need additional software beyond the usual toolkit to play MIDI files, work with MIDI files in code, and turn a MIDI file into an image of the musical score. Let’s install <code>wildmidi</code>, <code>midiutil</code>, and <code>musescore3</code>.</p>
<p class="indent">Install <code>wildmidi</code> with:</p>
<pre class="pre">&gt; <span class="codestrong1">sudo apt-get install wildmidi</span></pre>
<p class="indent">The <code>wildmidi</code> add-on plays MIDI files (<em>.mid</em>) from the command line. For macOS and Windows, see the main website at <em><a href="https://github.com/Mindwerks/wildmidi/releases">https://github.com/Mindwerks/wildmidi/releases</a></em>.</p>
<p class="indent">We need <code>midiutil</code> to work with MIDI files in Python:</p>
<pre class="pre">&gt; <span class="codestrong1">sudo pip3 install midiutil</span></pre>
<p class="noindent">The <code>midiutil</code> library reads and writes MIDI files, though we’ll only ever write them.</p>
<p class="indent">Finally, to generate sheet music of our evolved melodies, we will need <code>musescore3</code>:</p>
<pre class="pre">&gt; <span class="codestrong1">sudo apt-get install musescore3</span></pre>
<p class="noindent">Versions for macOS and Windows are available from the main site (<em><a href="https://musescore.org/en/download">https://musescore.org/en/download</a></em>). If <code>musescore3</code> is not found, install the latest version (<code>musescore4</code>) and update <em>melody_maker.py</em> accordingly.</p>
<p class="indent">Once everything’s installed, we’re good to go. If you didn’t install <code>musescore3</code>, the code will still run, but you won’t get to see the final result visually.</p>
<span epub:type="pagebreak" id="page_246"/>
<h4 class="h4" id="ch00lev2_76"><em><strong>The melody_maker.py code</strong></em></h4>
<p class="noindent">The code we need to evolve melodies is in <em>melody_maker.py</em>:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 melody_maker.py</span>

melody_maker &lt;length&gt; &lt;outfile&gt; &lt;npart&gt; &lt;max_iter&gt; &lt;alg&gt; &lt;mode&gt; [&lt;kind&gt; | &lt;kind&gt; &lt;seed&gt;]

  &lt;length&gt;   - number of notes in the melody
  &lt;outdir&gt;   - output directory
  &lt;npart&gt;    - swarm size
  &lt;max_iter&gt; - maximum number of iterations
  &lt;alg&gt;      - algorithm: PSO,DE,RO,GWO,JAYA,GA,BARE
  &lt;mode&gt;     - mode
  &lt;kind&gt;     - randomness source
  &lt;seed&gt;     - random seed</pre>
<p class="indent">Many command line arguments are familiar or self-evident, like the number of notes in the melody. The <code>mode</code> argument refers to the musical mode or scale we want to use. Traditionally, there are seven modes, all of which are supported, plus the blues and the pentatonic (rock) scales. The other modes use their classical Greek names, or <code>major</code> or <code>minor</code> for standard major and minor keys. The mode names are in <a href="ch08.xhtml#ch08tab01">Table 8-1</a> along with a sequence of intervals and words often associated with the mode. The intervals of <a href="ch08.xhtml#ch08tab01">Table 8-1</a> refer to the steps between the notes of the scale with <code>H</code> a half step (semitone) and <code>W</code> a whole step (tone).</p>
<p class="tabcap" id="ch08tab01"><strong>Table 8-1:</strong> The Modes, Intervals, and Characteristics</p>
<table class="table-h">
<colgroup>
<col style="width:30%"/>
<col style="width:30%"/>
<col style="width:40%"/>
</colgroup>
<thead>
<tr>
<th class="tab_th"><strong>Mode</strong></th>
<th class="tab_th"><strong>Intervals</strong></th>
<th class="tab_th"><strong>Characteristics</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td class="bg1">Ionian (major)</td>
<td class="bg1"><code>W W H W W W H</code></td>
<td class="bg1">Bright, positive, strong, simple</td>
</tr>
<tr>
<td class="bg">Aeolian (minor)</td>
<td class="bg"><code>W H W W H W W</code></td>
<td class="bg">Sad</td>
</tr>
<tr>
<td class="bg1">Dorian</td>
<td class="bg1"><code>W H W W W H W</code></td>
<td class="bg1">Light, cool, jazzy</td>
</tr>
<tr>
<td class="bg">Lydian</td>
<td class="bg"><code>W W W H W W H</code></td>
<td class="bg">Bright, airy, sharp</td>
</tr>
<tr>
<td class="bg1">Mixolydian</td>
<td class="bg1"><code>W W H W W H W</code></td>
<td class="bg1">Celtic</td>
</tr>
<tr>
<td class="bg">Phrygian</td>
<td class="bg"><code>H W W W H W W</code></td>
<td class="bg">Dark, depressing</td>
</tr>
<tr>
<td class="bg1">Locrian</td>
<td class="bg1"><code>H W W H W W W</code></td>
<td class="bg1">Darker still, “evil”</td>
</tr>
</tbody>
</table>
<p class="indent">For example, if the first note of a candidate melody is middle C (MIDI note 60), and the desired mode is <code>major</code>, then the notes of the scale are:</p>
<div class="image1"><img alt="Image" src="../images/f0246-01.jpg"/></div>
<p class="noindent">The objective function will score a candidate melody, in part, by how closely it follows the desired scale.</p>
<p class="indent">If you’re not familiar with music, scales, or music theory of any kind, have no fear. All we need to know is that there are different scales, or different sets of intervals between notes, that, when played, affect the sound of <span epub:type="pagebreak" id="page_247"/>the melody. For example, melodies in a major scale (Ionian mode) sound bright, while those in a minor key (Aeolian mode) tend to sound sad. These rules are not hard and fast—just guidelines. We’ll generate many melodies in different modes.</p>
<p class="indent">Let’s run <em>melody_maker.py</em>:</p>
<pre class="pre">&gt; <span class="codestrong1">python3 melody_maker.py 20 tmp 20 10000 bare mixolydian</span>

Melody maker:

npart = 20
niter = 10000
alg = BARE
Optimization time = 114.775 seconds
63,0.90 60,0.60 63,0.60 60,0.60 63,0.60 60,0.60 61,1.20 
65,0.60 68,0.60 65,0.60 68,1.20 72,1.20 68,0.60 65,1.20 
70,0.60 67,1.20 63,1.20 67,0.60 70,1.20 73,0.60 

31 best updates, final objective value 1.6637</pre>
<p class="indent">I didn’t specify a seed, so your run will be entirely different. The output tells us about the search, then spits out a long string of integers and floats. This is the evolved melody as written to the output MIDI file, which is in the <em>tmp</em> directory along with several other files, including a NumPy vector, a Python pickle file, and the score (<code>score.png</code>). The melody is in pairs, so the first note is (63,0.9), a dotted eighth note E-flat above middle C.</p>
<p class="indent">The output MIDI file is in <em>tmp</em> as well. Play it with <code>wildmidi</code></p>
<pre class="pre">&gt; <span class="codestrong1">wildmidi tmp/melody_BARE.mid</span></pre>
<p class="noindent">where <code>BARE</code> is replaced by whatever swarm algorithm we select. I chose <code>mixolydian</code> for the mode, so, in theory, the melody should sound somewhat “celtic.” Does it? I really don’t know.</p>
<p class="indent">The evolved melody is in <em>score.png</em>; see <a href="ch08.xhtml#ch08fig03">Figure 8-3</a>.</p>
<div class="image"><img alt="Image" id="ch08fig03" src="../images/08fig03.jpg"/></div>
<p class="figcap"><em>Figure 8-3: An evolved melody</em></p>
<p class="noindent">I glossed over the objective function value for the returned melody. We’ll explore that in more detail when we glance at the code. However, as with all our optimization experiments, lower is better.</p>
<p class="indent">Try experimenting with melodies, modes, algorithms, swarm sizes, and iterations of different lengths. More iterations generally lead to better performance, which should mean a better sounding melody, or, at least, a melody more faithful to the desired mode.</p>
<p class="indent"><span epub:type="pagebreak" id="page_248"/>You might wish to run the examples in <em>melody_examples</em>. The file works as a shell script</p>
<pre class="pre">&gt; <span class="codestrong1">sh melody_examples</span></pre>
<p class="noindent">and produces directories <em>ex0</em> through <em>ex8</em> inside <em>example_melodies</em> using different swarm algorithms and modes. I fixed the seeds, so you’ll hear what I heard, which hints at the range of possible outcomes.</p>
<p class="indent">The following sections experiment with <em>melody_maker.py</em>. The first queries the melodies as they evolve, the second focuses on the algorithms to understand what sort of melodies they favor, and the last builds a library of melodies in four modes.</p>
<h5 class="h5"><strong>Evolving a Melody</strong></h5>
<p class="noindent">Let’s evolve a melody in a major scale using bare-bones PSO. This experiment aims to listen to the melody as it evolves. It should go from erratic and far from the desired mode to a tune that a beginning piano student might play (or so I’ve been told).</p>
<p class="indent">The file <em>evolve.py</em> runs <em>melody_maker.py</em> to evolve a major scale melody of 20 notes using 20 particles and bare-bones PSO. The generator and seed are fixed; all that changes between runs is the number of iterations, which vary from a low of 1 to a high of 50,000, as in <a href="ch08.xhtml#ch08fig04">Figure 8-4</a>.</p>
<p class="indent">The fixed seed means that the best melody found for 10 iterations passed through the best found in 1 iteration. Each higher number of iterations tells us where any earlier iteration would have ended if it were left to run. In other words, the same initial configuration is allowed to evolve for a varying number of iterations.</p>
<div class="image"><img alt="Image" id="ch08fig04" src="../images/08fig04.jpg"/></div>
<p class="figcap"><em>Figure 8-4: Progressive melodies. From top: 1, 1,000, 10,000, and 50,000 iterations.</em></p>
<p class="indent">The directory <em>evolve_results</em> contains the MIDI files and score images for each number of iterations: 1, 10, 100, 1,000, 5,000, 10,000, and 50,000. I recommend using <code>wildmidi</code> to play the files. How does the melody found after 1 iteration of the swarm compare to that after 50,000? <a href="ch08.xhtml#ch08fig04">Figure 8-4</a> shows the score for select melodies by iteration. While the early melodies are a <span epub:type="pagebreak" id="page_249"/>mess, there is little change—other than the key—between the melody after 10,000 iterations and after 50,000.</p>
<p class="indent">The objective function value, which we have yet to understand, decreases as the number of iterations increases. This is, of course, all it can do, but the rate at which it decreases levels off after 1,000 iterations. The slight change in the score between 10,000 iterations and 50,000 implies that we may not want to run the search for too long, as we risk eliminating potentially exciting melodies in the process.</p>
<p class="indent">What, precisely, happens when a melody evolves? Swarm algorithms are initialized randomly over an appropriate range of MIDI note numbers and durations. The selected musical mode effectively alters the objective function used by the swarm as it searches. While the swarm search includes randomness, it is the initial configuration of the swarm that most strongly influences the final result—at least, that’s what I think is happening. The combination of initial swarm configuration, algorithm approach, and randomness leads to convergence on a melody that more or less fits the objective function.</p>
<h5 class="h5"><strong>Exploring the Algorithms</strong></h5>
<p class="noindent">The <em>algorithms.py</em> file runs <em>melody_maker.py</em> 10 times for each of the 7 swarm algorithms we’ve used throughout the book. Each run generates a 36-note melody in the Lydian mode utilizing a swarm of 20 particles and 10,000 iterations. You can run this file to produce output in the <em>algorithms</em> directory. Alternatively, since the seed values are fixed, you can listen to the seven MP3 files that concatenate the output by algorithm.</p>
<p class="indent">Even though the algorithms are tasked with the same overall goal—learning a melody in the Lydian mode—hopefully the resulting melodies reveal distinctions between the algorithms. Let’s see whether it matters which swarm algorithm we use, and whether some produce “nicer” results than others.</p>
<p class="indent">I listened to all the MP3 files (made by using <code>wildmidi</code>’s <code>-o</code> option followed by <code>lame</code>) and ranked the resulting melodies by how nice I thought they sounded. Here’s my ranking from best to worst, including ties where I couldn’t choose one algorithm over another:</p>
<ol>
<li class="noindent">Bare-bones PSO</li>
<li class="noindent">Genetic algorithm, PSO</li>
<li class="noindent">Differential evolution, Jaya</li>
<li class="noindent">GWO</li>
<li class="noindent">Random optimization</li>
</ol>
<p class="noindent">Your ranking might be different, but I suspect you’ll agree that bare-bones PSO works best in this case and random optimization is the worst. Both GWO and random optimization produce rushed output; the melodies play faster, so the resulting MP3 files are about 30 seconds shorter than the other algorithms.</p>
<span epub:type="pagebreak" id="page_250"/>
<p class="indent">We’ll perform one more experiment before exploring the code in which we use the “best” algorithm, bare-bones PSO, to create a library of songs in different modes.</p>
<h5 class="h5"><strong>Building a Library of Melodies</strong></h5>
<p class="noindent">The file <em>songs.py</em> is similar to <em>algorithms.py</em>, but uses bare-bones PSO repeatedly to generate 36-note melodies in four modes: major, minor, Dorian, and blues. In this case, there are 32 particles in the swarm and 30,000 iterations. The code takes some time to run, so I created MP3 files of the output: <em>major.mp3</em>, <em>minor.mp3</em>, <em>dorian.mp3</em>, and <em>blues.mp3</em>. Give them a listen while keeping the descriptions of <a href="ch08.xhtml#ch08tab01">Table 8-1</a> in mind. If you agree with them, it means the objective function has at least captured something of the modes, if not much of what makes a good melody.</p>
<h4 class="h4" id="ch00lev2_77"><em><strong>Implementation</strong></em></h4>
<p class="noindent">The time has come to explore <em>melody_maker.py</em>. At a high level, it’s no different from any of the other swarm optimization experiments: we parse the command line, initialize swarm framework objects, and call <code>Optimize</code> to perform the search. The result is then converted into a MIDI file object and written to disk.</p>
<p class="indent">Let’s understand the structure of the swarm—the mapping between particle position and melody—and then walk through the objective function class, as that’s the heart of the process.</p>
<p class="indent">If we want <em>n</em> notes in a melody, each particle becomes a 2<em>n</em>-element vector, a collection of <em>n</em> pairs, (MIDI note number, duration). MIDI note numbers are restricted (see <code>MusicBounds</code>) to [57, 81] with 57 interpreted as a rest. Again, middle C on the piano is note 60, and each increment or decrement corresponds to a semitone. Durations are integers that we multiply by 0.3 when creating the MIDI file to control the tempo. The ratio between the notes matters so that duration 4 is twice as long as duration 2, and so on. Particles, then, <em>are</em> the melody under consideration, and the search seeks to find, given the random initial collection of melodies and the particulars of the selected algorithm, a best melody as decided by the objective function.</p>
<p class="indent">Everything depends on the <code>MusicObjective</code> class. It’s rather elaborate, with more than 150 lines of code. I’ll start at the end, the <code>Evaluate</code> method, and then fill in the pieces—standard top-down design. Recall, the swarm uses the score to decide the quality of the melody. The lower it is, the better. Here’s the code:</p>
<pre class="pre">def Evaluate(self, p):
    self.fcount += 1
    s = self.Distance(p[::2], self.mode)
    d = self.Durations(p)
    i = self.Intervals(p[::2], self.mode)
    l = self.Leaps(p[::2], self.mode)
    return 4*s+3*d+2*i+l</pre>
<p class="indent"><span epub:type="pagebreak" id="page_251"/>The score is a multipart function of the output from the <code>Distance</code>, <code>Durations</code>, <code>Intervals</code>, and <code>Leaps</code> methods. The respective values are summed but not equally weighted so that the output of <code>Distance</code> is four times as important as the output from the <code>Leaps</code> method. Each part of the final score is in the range [0, 1], with lower being better.</p>
<p class="indent">The <code>Distance</code> method measures the Hamming distance between the notes of the current melody (particle) and the notes expected for a melody in the given mode. The <code>ModeNotes</code> method returns two binary vectors where a 1 indicates that the corresponding note is in the mode. The first vector is for the current melody, and the second includes the notes in that mode, assuming the first note of the melody to be the root. In other words, <code>ModeNotes</code> returns two binary numbers expressed as vectors of 0s and 1s. The Hamming distance between two binary numbers is the number of differing bits. For example, the Hamming distance between 10110111 and 10100101 is 2 because two corresponding bit positions differ. The <code>Distance</code> method scales the Hamming distance by the number of notes to return a value in [0, 1]; it’s deemed the most important part of the objective function because a good melody in a specified mode should consist mostly of notes in that mode.</p>
<p class="indent">The <code>Durations</code> method is an ad hoc measure using a scaled root squared error distance between the count of the different note durations in the melody and the preferred favoring of quarter and half notes. The idea is to minimize dotted notes.</p>
<p class="indent">The <code>Intervals</code> method is another ad hoc metric that looks at the spacing from one note in the melody to the next. We humans generally prefer major or minor thirds and fifths, meaning the interval from note <em>i</em> to note <em>i</em> + 1 should be 3, 4, or 7 semitones.</p>
<p class="indent">Finally, <code>Leaps</code> tries to minimize leaps, or intervals between notes that exceed 5 semitones. This competes with what <code>Intervals</code> is measuring, but <code>Leaps</code> is weighted half as much.</p>
<p class="indent">Now that we have a high-level understanding of what the objective function measures, let’s look at the corresponding code and its essential parts.</p>
<h5 class="h5"><strong>Distance</strong></h5>
<p class="noindent">The <code>Distance</code> method uses the Hamming distance between the notes of the melody and the notes that should be in the melody if it conforms to the desired mode. Here’s the code:</p>
<pre class="pre">def Distance(self, notes, mode):
    A,B = self.ModeNotes(notes, mode)
    lo = int(notes.min() - self.lo)
    hi = int(notes.max() - self.lo)
    a = A[lo:(hi+2)]
    b = B[lo:(hi+2)]
    score = (np.logical_xor(a,b)*1).sum()
    score /= len(a)
    return score</pre>
<p class="indent"><span epub:type="pagebreak" id="page_252"/>The <code>ModeNotes</code> method, not shown, returns two lists where each element is 1 if the corresponding note is in the melody (<code>A</code>) or belongs in the melody given the mode (<code>B</code>). The versions in <code>a</code> and <code>b</code> cover the given melody’s range.</p>
<p class="indent">The <code>score</code> variable holds the Hamming distance between <code>a</code> and <code>b</code>. The Hamming distance is the number of mismatched bit positions. Scaling by the length of the melody transforms the count into a fraction of the melody, [0, 1], which is returned.</p>
<h5 class="h5"><strong>Durations</strong></h5>
<p class="noindent">The <code>Durations</code> method calculates a score reflecting how closely the distribution of note durations matches the ad hoc predefined “best” mix that favors quarter and half notes. In code:</p>
<pre class="pre">def Durations(self, p):
    d = p[1::2].astype("int32")
    dp = np.bincount(d, minlength=8)
    b = dp / dp.sum()
    a = np.array([0,0,100,0,60,0,20,0])
    a = a / a.sum()
    return np.sqrt(((a-b)**2).sum())</pre>
<p class="indent">First, we set <code>d</code> to the durations of the current melody so that <code>bincount</code> can create the corresponding distribution, <code>b</code>, which is scaled to a probability. The desired mix of note durations is in <code>a</code> and likewise scaled to be a probability.</p>
<p class="indent">The sum of the squared distance between the two distributions is returned as the duration score.</p>
<h5 class="h5"><strong>Intervals</strong></h5>
<p class="noindent">The interval between two notes is measured in semitones. The <code>Intervals</code> method counts the number of major thirds (4 semitones), minor thirds (3 semitones), and fifths (7 semitones) in the melody and transforms those numbers into a score. In code this becomes:</p>
<pre class="pre">def Intervals(self, notes, mode):
    _,B = self.ModeNotes(notes, mode)
    minor = major = fifth = 0
    for i in range(len(notes)-1):
        x = int(notes[i]-self.lo)
        y = int(notes[i+1]-self.lo)
        if (B[x] == 1) and (B[y] == 1):
            if (abs(x-y) == 3):
                minor += 1
            if (abs(x-y) == 4):
                major += 1
            if (abs(x-y) == 7):
                fifth += 1
    w = (3*minor + 3*major + fifth) / 7
    return 1.0 - w/len(notes)</pre>
<p class="indent"><span epub:type="pagebreak" id="page_253"/>The code examines each pair of notes in the melody. We use the difference in semitones to count the number of thirds and fifths. We then assign <code>w</code> the weighted mean of these counts where, by fiat, I’m favoring thirds over fifths by 3 to 1.</p>
<p class="indent">The higher <code>w</code> is, the more the melody conforms to the desired interval arrangement; therefore, subtract the scaled <code>w</code> score from 1 to minimize.</p>
<h5 class="h5"><strong>Leaps</strong></h5>
<p class="noindent">The final part of the objective function score is <code>Leaps</code>:</p>
<pre class="pre">def Leaps(self, notes, mode):
    _,B = self.ModeNotes(notes, mode)
    leaps = 0
    for i in range(len(notes)-1):
        x = int(notes[i]-self.lo)
        y = int(notes[i+1]-self.lo)
        if (B[x] == 1) and (B[y] == 1):
            if (abs(x-y) &gt; 5):
                leaps += 1
    return leaps / len(notes)</pre>
<p class="indent">A leap is any difference between a pair of notes that exceeds 5 semitones, either up or down. Smaller distances imply a smoother melody. We return the fraction of the melody that are leaps.</p>
<p class="indent">Why use these components in the objective function and not others? No reason other than a perusal of thoughts on what makes a good melody mentions some of these. Music is subjective, and it isn’t possible to create an objective objective function. “Exercises” on <a href="ch08.xhtml#ch00lev1_53">page 254</a> asks you to think of other terms that might fit well in <code>MusicObjective</code>.</p>
<div class="box">
<p class="box-title"><strong>GENERATIVE AI</strong></p>
<p class="box-para">The discussions of generative art and music in <a href="ch07.xhtml">Chapters 7</a> and <a href="ch08.xhtml">8</a> make no mention of artificial intelligence, and thus are incomplete. However, throwing AI into the mix would turn these chapters into a book. Instead, I’ll point you toward AI-based examples of generative art and music. Most of these use <em>generative adversarial networks</em>, <em>deep style transfer</em>, <em>variational autoencoders</em>, or related techniques that depend on deep neural networks to either sample from some learned representation space or merge features from embedded representations to build new output from multiple inputs.</p>
<p class="box-para">If you want to explore what AI can do in this area, <em><a href="https://aiartists.org">https://aiartists.org</a></em> is a good place to start and has links to artists and tools to make AI-based art and music. A fun, advanced approach to evolutionary algorithms and music is found in Al Biles’ GenJam at <em><a href="https://genjam.org">https://genjam.org</a></em>. I recommend the video examples, especially the TEDx talk demonstrating and explaining the system. <span epub:type="pagebreak" id="page_254"/>We’ve witnessed an explosion of powerful AI-based text, image, and video generation systems, including Stable Diffusion, DALL-E 2, and ChatGPT. New systems and updates appear weekly, but these should get you started:</p>
<div class="bqparan">
<p class="noindentin"><strong>DALL-E 2</strong>   <em><a href="https://openai.com/dall-e-2">https://openai.com/dall-e-2</a></em></p>
<p class="noindentin"><strong>Stable Diffusion</strong>   <em><a href="https://beta.dreamstudio.ai/">https://beta.dreamstudio.ai/</a></em></p>
<p class="noindentin"><strong>ChatGPT</strong>   <em><a href="https://openai.com/blog/chatgpt">https://openai.com/blog/chatgpt</a></em></p>
</div>
</div>
<h3 class="h3" id="ch00lev1_53"><strong>Exercises</strong></h3>
<p class="noindent">Like generative art, there’s no end to what we can do with generative music. Here are some exercises related to this chapter’s experiments.</p>
<ul>
<li class="noindent">Alter the clipping range in <em>sine_walker.py</em>. How does this affect the overall sound? What does the waveform look like in Audacity?</li>
<li class="noindent">You can change the key in <em>note_walker.py</em> by altering the frequency table. For example, to change from C major to D minor, flatten the B notes: 246.94 → 233.08, 493.88 → 466.16, and 987.77 → 932.33.</li>
<li class="noindent">The last argument to <code>addProgramChange</code> in <em>melody_maker</em>’s <code>StoreMelody</code> function specifies the MIDI instrument number. The default is 0 for an acoustic piano. Change this number using the <em>MIDI_instruments.txt</em> list. For example, try 30 for a distorted electric guitar or 13 for a xylophone. The oboe, barely breathing, is 68. Or go for broke with 114, steel drums.</li>
<li class="noindent">Alter <em>melody_maker</em>’s objective function weighting in the <code>Evaluate</code> method. Does it sound as nice if all components are weighted the same? What happens if you reverse the weighting?</li>
<li class="noindent">What other terms can you add to <em>melody_maker</em>’s objective function?</li>
</ul>
<h3 class="h3" id="ch00lev1_54"><strong>Summary</strong></h3>
<p class="noindent">This chapter introduced us to randomness in generative music beginning with audio and a random walk of sine waves to produce otherworldly sound effects. Restricting the frequencies to those of a musical scale transformed the odd sounds into something akin to a pipe organ.</p>
<p class="indent">We closed the chapter by evolving melodies from scratch using swarm intelligence and evolutionary algorithms. We were moderately successful in that the evolved melodies did, for the most part, conform to the desired musical mode. Along the way, we saw an example of how to create simple MIDI files in code.</p>
<p class="indent">We’ll change gears in the next chapter to explore randomness in an entirely different domain: recovering a signal from a small collection of measurements.</p>
</body></html>