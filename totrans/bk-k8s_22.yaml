- en: '19'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TUNING QUALITY OF SERVICE
  prefs: []
  type: TYPE_NORMAL
- en: '![image](../images/common01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Ideally, our applications would use minimal or highly predictable processing,
    memory, storage, and network resources. In the real world, though, applications
    are “bursty,” with changes in load driven by user demand, large amounts of data,
    or complex processing. In a Kubernetes cluster, where application components are
    deployed dynamically to various nodes in the cluster, uneven distribution of load
    across those nodes can cause performance bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: From an application architecture standpoint, the more we can make the application
    components small and scalable, the more we can evenly distribute load across the
    cluster. Unfortunately, it’s not always possible to solve performance issues with
    horizontal scaling. In this chapter, we’ll look at how we can use resource specifications
    to provide hints to the cluster about how to schedule our Pods, with the goal
    of making application performance more predictable.
  prefs: []
  type: TYPE_NORMAL
- en: Achieving Predictability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In normal, everyday language, the term *real time* has the sense of something
    that happens quickly and continuously. But in computer science, we make a distinction
    between *real time* and *real fast* to such a degree that they are thought of
    as opposites. This is due to the importance of predictability.
  prefs: []
  type: TYPE_NORMAL
- en: Real-time processing is simply processing that needs to keep up with some activity
    that is happening in the real world. It could be anything from airplane cockpit
    software that needs to keep up with sensor data input and maintain up-to-date
    electronic flight displays, to a video streaming application that needs to receive
    and decode each frame of video in time to display it. In real-time systems, it
    is critical that we can guarantee that processing will be “fast enough” to keep
    up with the real-world requirement.
  prefs: []
  type: TYPE_NORMAL
- en: Fast enough is all we need. It’s not necessary for the processing to go any
    faster than the real world, as there isn’t anything else for the application to
    do. But even a single time interval when the processing is slower than the real
    world means we fall behind our inputs or outputs, leading to annoyed movie watchers—or
    even to crashed airplanes.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, the main goal in real-time systems is predictability. Resources
    are allocated based on the worst-case scenario the system will encounter, and
    we’re willing to provide significantly more processing than necessary to have
    plenty of margin on that worst case. Indeed, it’s common to require these types
    of systems to stay under 50 percent utilization of the available processing and
    memory, even at maximum expected load.
  prefs: []
  type: TYPE_NORMAL
- en: But whereas responsiveness is always important, most applications don’t operate
    in a real-time environment, and this additional resource margin is expensive.
    For that reason, most systems try to find a balance between predictability and
    efficiency, which means that we are often willing to tolerate a bit of slower
    performance from our application components as long as it is temporary.
  prefs: []
  type: TYPE_NORMAL
- en: Quality of Service Classes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To help us balance predictability and efficiency for the containers in a cluster,
    Kubernetes allocates Pods to one of three different Quality of Service classes:
    `BestEffort`, `Burstable`, and `Guaranteed`. In a way, we can think of these as
    descriptive. `BestEffort` is used when we don’t provide Kubernetes with any resource
    requirements, and it can only do its best to provide enough resources for the
    Pod. `Burstable` is used when a Pod might exceed its resource request. `Guaranteed`
    is used when we provide consistent resource requirements and our Pod is expected
    to stay within them. Because these classes are descriptive and are based solely
    on how the containers in the Pod specify their resource requirements, there is
    no way to specify the QoS for a Pod manually.'
  prefs: []
  type: TYPE_NORMAL
- en: The QoS class is used in two ways. First, Pods in a QoS class are grouped together
    for Linux control groups (cgroups) configuration. As we saw in [Chapter 3](ch03.xhtml#ch03),
    cgroups are used to control resource utilization, especially processing and memory,
    for a group of processes, so a Pod’s cgroup affects its priority in use of processing
    time when the system load is high. Second, if the node needs to start evicting
    Pods due to lack of memory resources, the QoS class affects which Pods are evicted
    first.
  prefs: []
  type: TYPE_NORMAL
- en: BestEffort
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The simplest case is one in which we declare a Pod with no `limits`. In that
    case, the Pod is assigned to the `BestEffort` class. Let’s create an example Pod
    to explore what that means.
  prefs: []
  type: TYPE_NORMAL
- en: '**NOTE**'
  prefs: []
  type: TYPE_NORMAL
- en: '*The example repository for this book is at* [https://github.com/book-of-kubernetes/examples](https://github.com/book-of-kubernetes/examples).
    *See “Running Examples” on [page xx](ch00.xhtml#ch00lev1sec2) for details on getting
    set up.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the Pod definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '*best-effort.yaml*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This definition includes no `resources` field at all, but the QoS class would
    be the same if we included a `resources` field with `requests` but no `limits`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We use `nodeName` to force this Pod onto `host01` so that we can observe how
    its resource use is configured. Let’s apply it to to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'After the Pod is running, we can look at its details to see that it has been
    allocated to the `BestEffort` QoS class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the `cgroup-info` script we saw in [Chapter 14](ch14.xhtml#ch14)
    to see how the QoS class affects the cgroup configuration for containers in the
    Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The Pod is effectively unlimited in CPU and memory usage. However, the Pod’s
    cgroup is under the *kubepods-besteffort.slice* path, reflecting its allocation
    to the `BestEffort` QoS class. This allocation has an immediate effect on its
    CPU priority, as we can see when we compare the `cpu.shares` allocated to the
    `BestEffort` class compared to the `Burstable` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As we saw in [Chapter 14](ch14.xhtml#ch14), these values are relative, so this
    configuration means that when our system’s processing load is high, containers
    in `Burstable` Pods are going to be allocated more than 500 times the processor
    share that containers in `BestEffort` Pods receive. This value is based on the
    number of Pods that are already in the `BestEffort` and `Burstable` QoS classes,
    including the various cluster infrastructure components already running on *host01*,
    thus you might see a slightly different value.
  prefs: []
  type: TYPE_NORMAL
- en: The *kubepods.slice* cgroup sits at the same level as cgroups for user and system
    processes, so when the system is loaded it gets an approximately equal share of
    processing time as those other cgroups. Based on the *cpu.shares* identified within
    the *kubepods.slice* cgroup, `BestEffort` Pods are receiving less than 1 percent
    of the total share of processing compared to `Burstable` Pods, even without considering
    any processor time allocated to `Guaranteed` Pods. This means that `BestEffort`
    Pods receive almost no processor time when the system is loaded, so they should
    be used only for background processing that can run when the cluster is idle.
    In addition, because Pods are placed in the `BestEffort` class only if they have
    no `limits` specified, they cannot be created in a Namespace with limit quotas.
    So most of our application Pods will be in one of the other two QoS classes.
  prefs: []
  type: TYPE_NORMAL
- en: Burstable
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pods are placed in the `Burstable` class if they specify both `requests` and
    `limits` and if those two specifications are different. As we saw in [Chapter
    14](ch14.xhtml#ch14), the `requests` specification is used for scheduling purposes,
    whereas the `limits` specification is used for runtime enforcement. In other words,
    Pods in this situation can have “bursts” of resource utilization above their `requests`
    level, but they cannot exceed their `limits`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '*burstable.yaml*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This Pod definition supplies both `requests` and `limits` resource requirements,
    and they are different, so we should expect this Pod to be placed in the `Burstable`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s apply this Pod to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s verify that it was assigned to the `Burstable` QoS class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Indeed, the cgroup configuration follows the QoS class and the `limits` we
    specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `limits` specified for this Pod were used to set both a CPU limit and a
    memory limit. Also, as we expect, this Pod’s cgroup is placed within *kubepods-burstable.slice*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding another Pod to the `Burstable` QoS class has caused Kubernetes to rebalance
    the allocation of processor time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The result is that Pods in the `Burstable` QoS class now show a value of 1413
    for *cpu.shares*, whereas Pods in the `BestEffort` class still show 2\. This means
    that the relative processor share under load is now 700 to 1 in favor of Pods
    in the `Burstable` class. Again, you may see slightly different values based on
    how many infrastructure Pods Kubernetes has allocated to `host01`.
  prefs: []
  type: TYPE_NORMAL
- en: Because `Burstable` Pods are scheduled based on `requests` but cgroup runtime
    enforcement is based on `limits`, a node’s processor and memory resources can
    be overcommitted. It works fine as long as the Pods on a node balance out one
    another so that the average utilization matches the `requests`. It becomes a problem
    if the average utilization exceeds the `requests`. In that case, Pods will see
    their CPU throttled and may even be evicted if memory becomes scarce, as we saw
    in [Chapter 10](ch10.xhtml#ch10).
  prefs: []
  type: TYPE_NORMAL
- en: Guaranteed
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'If we want to increase predictability for the processing and memory available
    to a Pod, we can place it in the `Guaranteed` QoS class by giving the `requests`
    and `limits` equal settings. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '*guaranteed.yaml*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this example, only `limits` is specified given that Kubernetes automatically
    sets the `requests` to match the `limits` if `requests` is missing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s apply this to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'After the Pod is running, verify the QoS class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The cgroups configuration looks a little different:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Rather than place these containers into a separate directory, containers in
    the `Guaranteed` QoS class are placed directly in *kubepods.slice*. Putting them
    in this location has the effect of privileging containers in `Guaranteed` Pods
    when the system is loaded because those containers receive their CPU shares individually
    rather than as a class.
  prefs: []
  type: TYPE_NORMAL
- en: QoS Class Eviction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The privileged treatment of Pods in the `Guaranteed` QoS class extends to Pod
    eviction as well. As described in [Chapter 3](ch03.xhtml#ch03), cgroup enforcement
    of memory limits is handled by the OOM killer. The OOM killer also runs when a
    node is completely out of memory. To help the OOM killer choose which containers
    to terminate, Kubernetes sets the `oom_score_adj` parameter based on the QoS class
    of the Pod. This parameter can have a value from –1000 to 1000\. The higher the
    number, the more likely the OOM killer will choose a process to be killed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `oom_score_adj` value is recorded in */proc* for each process. The automation
    has added a script called *oom-info* to retrieve it for a given Pod. Let’s check
    the values for the Pods in each QoS class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Pods in the `BestEffort` QoS class have the maximum adjustment of 1000, so they
    would be targeted first by the OOM killer. Pods in the `Burstable` QoS class have
    a score calculated based on the amount of memory specified in the `requests` field,
    as a percentage of the node’s total memory capacity. This value will therefore
    be different for every Pod but will always be between 2 and 999\. Thus, Pods in
    the `Burstable` QoS class will always be second in priority for the OOM killer.
    Meanwhile, Pods in the `Guaranteed` QoS class are set close to the minimum value,
    in this case –997, so they are protected from the OOM killer as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, as mentioned in [Chapter 3](ch03.xhtml#ch03), the OOM killer terminates
    a process immediately, so it is an extreme measure. When memory on a node is low
    but not yet exhausted, Kubernetes attempts to evict Pods to reclaim memory. This
    eviction is also prioritized based on the QoS class. Pods in the `BestEffort`
    class and Pods in the `Burstable` class that are using more than their `requests`
    value (high-use `Burstable`) are the first to be evicted, followed by Pods in
    the `Burstable` class that are using less than their `requests` value (low-use
    `Burstable`) and Pods in the `Guaranteed` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before moving on, let’s do some cleanup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now we can have a fresh start when we look at Pod priorities later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a QoS Class
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Given this prioritization in processing time and eviction priority, it might
    be tempting to place all Pods in the `Guaranteed` QoS class. And there are application
    components for which this is a viable strategy. As described in [Chapter 7](ch07.xhtml#ch07),
    we can configure a HorizontalPodAutoscaler to make new Pod instances automatically
    if the existing instances are consuming a significant percentage of their allocated
    resources. This means that we can request a reasonable `limits` value for Pods
    in a Deployment and allow the cluster to automatically scale the Deployment if
    we’re getting too close to the limit across those Pods. If the cluster is running
    in a cloud environment, we can even extend autoscaling to the node level, dynamically
    creating new cluster nodes when load is high and reducing the number of nodes
    when the cluster is idle.
  prefs: []
  type: TYPE_NORMAL
- en: Using only `Guaranteed` Pods together with autoscaling sounds great, but it
    assumes that our application components are easily scalable. It also only works
    well when our application load consists of many small requests, so that an increase
    in load primarily means we are handing similar-sized requests from more users.
    If we have application components that periodically handle large or complex requests,
    we must set the `limits` for those components to accommodate the worst-case scenario.
    Given that Pods in the `Guaranteed` QoS class have `requests` equal to `limits`,
    our cluster will need enough resources to handle this worst-case scenario, or
    we won’t even be able to schedule our Pods. This results in a cluster that is
    largely idle unless the system is under its maximum load. Similarly, if we have
    scalability limitations such as dependency on specialized hardware, we might have
    a natural limit on the number of Pods we can create for a component, forcing each
    Pod to have more resources to handle its share of the overall load.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, it makes sense to balance the use of the `Guaranteed` and `Burstable`
    QoS classes for our Pods. Any Pods that have consistent load, or that can feasibly
    be scaled horizontally to meet additional demand, should be in the `Guaranteed`
    class. Pods that are harder to scale, or need to handle a mix of large and small
    workloads, should be in the `Burstable` class. These Pods should specify their
    `requests` based on their average utilization, and specify `limits` based on their
    worst-case scenario. Specifying resource requirements in this way will ensure
    that the cluster’s expected performance margin can be monitored by simply comparing
    the allocated resources to the cluster capacity. Finally, if a large request causes
    multiple application components to run at their worst-case utilization simultaneously,
    it may be worth running performance tests and exploring anti-affinity, as described
    in [Chapter 18](ch18.xhtml#ch18), to avoid overloading a single node.
  prefs: []
  type: TYPE_NORMAL
- en: Pod Priority
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to using hints to help the Kubernetes cluster understand how to
    manage Pods when the system is highly loaded, it is possible to tell the cluster
    directly to give some Pods a higher priority than others. This higher priority
    applies during Pod eviction, as Pods will be evicted in priority order within
    their QoS class. It also applies during scheduling because the Kubernetes scheduler
    will evict Pods if necessary to be able to schedule a higher-priority Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pod priority is a simple numeric field; higher numbers are higher priority.
    Numbers greater than one billion are reserved for critical system Pods. To assign
    a priority to a Pod, we must create a *PriorityClass* resource first. Here’s an
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '*essential.yaml*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s apply this to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that this PriorityClass has been defined, we can apply it to Pods. However,
    let’s first create a large number of low-priority Pods through which we can see
    Pods being preempted. We’ll use this Deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a basic Deployment that runs `sleep` and doesn’t request very much
    memory or CPU, but it does set `replicas` to `1000`, so we’re asking our Kubernetes
    cluster to create 1,000 Pods. The example cluster isn’t large enough to deploy
    1,000 Pods, both because we don’t have sufficient resources to meet the specification
    and because a node is limited to 110 Pods by default. Still, let’s apply it to
    the cluster, as shown in [Listing 19-1](ch19.xhtml#ch19list1), and the scheduler
    will create as many Pods as it can:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '*Listing 19-1: Deploy lots of Pods*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s describe the Deployment to see how things are going:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We managed to get only seven Pods in our example cluster, given the number
    of Pods already running for cluster infrastructure components. Unfortunately,
    that’s all the Pods we’ll get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The data for `host01` shows that we’ve allocated 94 percent of the available
    CPU ➊. But each of our Pods is requesting 250 millicores, so there isn’t enough
    capacity remaining to schedule another Pod on this node. The other two nodes are
    in a similar situation, with insufficient CPU room to schedule any more Pods.
    Still, the cluster is performing just fine. We’ve theoretically allocated all
    of the processing power, but those containers are just running `sleep`, and as
    such, they aren’t actually using much CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Also, it’s important to remember that the `requests` field is used for scheduling,
    so even though we have a number of infrastructure `BestEffort` Pods that specify
    `requests` but no `limits` and we have plenty of `Limits` capacity on this node,
    we still don’t have any room for scheduling new Pods. Only `Limits` can be overcommitted,
    not `Requests`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we have no more CPU to allocate to Pods, the rest of the Pods in our
    Deployment are stuck in a Pending state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: All 993 of these Pods have the default pod priority of 0\. As a result, when
    we create a new Pod using the `essential` PriorityClass, it will jump to the front
    of the scheduling queue. Not only that, but the cluster will evict Pods as necessary
    to enable it to be scheduled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the Pod definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '*needed.yaml*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The key difference here is the specification of the `priorityClassName`, matching
    the PriorityClass we created. Let’s apply this to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'It will take the cluster a little time to evict another Pod so that this one
    can be scheduled, but after a minute or so it will start running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'To allow this to happen, one of the Pods from the `lots` Deployment we created
    in [Listing 19-1](ch19.xhtml#ch19list1) had to be evicted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We’re now down to only six Pods available in the Deployment ➊, as one Pod was
    evicted. It’s worth noting that being in the `Guaranteed` QoS class did not prevent
    this Pod from being evicted. The `Guaranteed` QoS class gets priority for evictions
    caused by node resource usage, but not for eviction caused by the scheduler finding
    room for a higher-priority Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the ability to specify a higher priority for a Pod, resulting in
    the eviction of other Pods, is powerful and should be used sparingly. Normal users
    do not have the ability to create a new PriorityClass, and administrators can
    apply a quota to limit the use of a PriorityClass in a given Namespace, effectively
    limiting normal users from creating high-priority Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Final Thoughts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deploying an application to Kubernetes so that it is performant and reliable
    requires an understanding of the application architecture and of the normal and
    worst-case load for each component. Kubernetes QoS classes allow us to shape the
    way that Pods are deployed to nodes to achieve a balance of predictability and
    efficiency in the use of resources. Additionally, both QoS classes and Pod priorities
    allow us to provide hints to the Kubernetes cluster so the deployed applications
    degrade gracefully as the load on the cluster becomes too high.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll bring together the ideas we’ve seen on how to best
    use the features of a Kubernetes cluster to deploy performant, resilient applications.
    We’ll also explore how we can monitor those applications and respond automatically
    to changes in behavior.
  prefs: []
  type: TYPE_NORMAL
