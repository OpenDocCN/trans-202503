<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="index: http://www.index.com/" lang="en" xml:lang="en">
<head>
<title>Chapter 9: Detection, Measurement, and Reporting</title>
<link href="NSTemplate_v1.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:5e8bb34b-260b-4fef-91f3-caabb4446e65" name="Adept.expected.resource"/>
</head>
<body epub:type="bodymatter chapter">
<section>
<header>
<h1 class="chapter">
<span class="ChapterNumber"><span epub:type="pagebreak" id="Page_121" title="121"/>9</span><br/>
<span class="ChapterTitle">Detection, Measurement, and Reporting</span></h1>
</header>
<figure class="opener">
<img alt="" src="image_fi/book_art/chapterart.png"/>
</figure>
<p class="ChapterIntro">The most valuable piece of a social engineering engagement is also the most frequently misdirected or ignored. In this chapter, you’ll learn about the detection, measurement, and reporting phases of the job. Often, part of helping your client organization is making yourself detectable. In the measurement phase, you should derive statistics about your success rates, as well as other key performance indicators. You’ll use these statistics to generate a professional, understandable report.</p>
<p>We will discuss the many ways to measure the outcome of an engagement. This involves considering the various metrics that can make your data understandable to your clients, the most useful of which go beyond simply stating how many opened emails or clicked links the campaign solicited. Finally, I’ll explain how to write a useful, engaging report that executives may actually read.</p>
<h2 id="h1--0001"><span epub:type="pagebreak" id="Page_122" title="122"/>Detection</h2>
<p class="BodyFirst">Though social engineers partly want to gain unauthorized access, the ethical ones should also hope to be detected. Clients don’t pay you to bulldoze their employees. Rather, they want an understanding of their company’s weaknesses, along with advice for overcoming them.</p>
<p> Therefore, you must accept a happy medium: challenge your targets, but do so fairly. Part of that medium lies with having the client train the staff, which is outside of your control. The third section of this book addresses that. The part that you can change is the structure of your engagements. By using attacks with varying levels of difficulty, you can give employees a chance to detect and report you.</p>
<p>When scoping the engagement, you should reach a clear understanding with the client regarding how stealthy to be. If you are performing this attack to kick off an awareness program, you will likely want to be extremely stealthy or incredibly noisy, depending on the maturity of the organization that you’re working with (though the final decision is the client’s to make). A mature organization might be able to handle a covert operation but still want a noisy one, or it may be too immature to gain value from covert operations, even if the manager chooses that route.</p>
<p>If you are operating with stealth, you can get an accurate view of what a sophisticated adversary could accomplish within an organization. Covert operations can set a good benchmark for understanding risks if the motives are good. Organizations that can most benefit from this are those with awareness and training programs already in place. Often, these engagements are best suited to be performed as part of an adversarial emulation campaign, such as a red team or, to a lesser degree, a penetration test. Running such engagements by themselves is also acceptable.</p>
<p>Overt tests are an excellent first touchpoint for an organization that is entirely new to adversarial emulation and social engineering. If the purpose of the adversarial emulation is purely compliance, overt operations may be the best solution and save you and the client the most time.</p>
<h2 id="h1--0002">Measurement</h2>
<p class="BodyFirst">To evaluate the success of your engagement, you need to use metrics. But which metrics matter? How do you measure them? Do you need to take a statistics class or get a data science degree?</p>
<p>Having some knowledge about statistics will help, and in certain situations—for instance, if you wanted to evaluate which of a company’s departments fell victim to social engineering attacks most often, or which schemes and times were most effective—understanding data science concepts such as regression and cluster analysis certainly won’t hurt. In most cases, however, this background is by no means necessary. Also keep in mind that if you plan to do such research, you will need a substantial dataset (thousands of phishing emails, if not millions) and, more importantly, client consent.</p>
<h3 id="h2--0001"><span epub:type="pagebreak" id="Page_123" title="123"/>Selection of Metrics</h3>
<p class="BodyFirst">When selecting metrics, try to be as practical as possible. What could put the client organization on the top half of the local newspaper’s front page, above the fold? What could land it in legal trouble? For the most part, merely opening an email won’t cause a negative outcome, so that metric might not be very useful to measure. Clicking links, providing information, or failing to report having fallen victim <em>do</em> cause negative consequences. </p>
<p>Though you might have your own ideas about which metrics to care about, knowing which metrics the client finds important is also critical. From this point, you can organize the data as necessary to help the client make sense of it. </p>
<h3 id="h2--0002">Ratios, Medians, Means, and Standard Deviations</h3>
<p class="BodyFirst">To present the data meaningfully, you should know how to calculate the following values: ratios, medians, means, and standard deviations. The operations necessary here require a minimum of 30 data points to be statistically significant. </p>
<p><em>Ratios</em>, put in ordinary language, tell you “how many <em>X</em>s occur in <em>Y</em>” as a percentage. In other words, if you send a phish to 100 people and 19 people click, you have a 19 in 100—or 19 percent—chance of someone clicking the link (also called the <em>click rate</em>).</p>
<p>The <em>median</em> is the most central data point for value. If you line up your data points from smallest to greatest, the median would be equidistant from both ends of the line. For instance, assume you’ve performed three phishing engagements on a client with 100 users. The first engagement had 62 users fall victim. The second had 34, and the third had 19. Let’s put these data points in order, from least to greatest. If you dabble in programming, think about an ordered array: [19, 34, 62]. The median is 34, because it is the value in the middle. </p>
<p>On the other hand, the <em>mean</em> is the average of all data points. Using the same three engagements, you could add up all three values and divide the result by 3 (since there are three values), giving you an average of 38.33.</p>
<p>To speak to the pattern as a whole, use <em>standard deviation</em>, the measurement of the variation of a set of values. Simply put, the standard deviation provides a measurement of how far each value differs from the mean. I could bore you with the actual equation, but a positive note is that Excel and most spreadsheet applications will calculate it for you. A low standard deviation means that the data points in the set are more similar than if the standard deviation is high.</p>
<p>Having these data points will help the client understand the general state of an organization in terms of its employees’ behavior. For example, if you have the dataset 1, 1, 1, 1, 5, 7, 24, you could generate the following values:</p>
<ul>
<li>Median: 1</li>
<li>Mean: 5.714</li>
<li>Standard deviation: 8.420</li>
</ul>
<p><span epub:type="pagebreak" id="Page_124" title="124"/>From these statistics, you can generalize, for the client, how their employees performed on the test. For instance, the standard deviation of 8.420 in this example shows that the set of numbers is diverse, likely indicating that people behaved very differently from one another. This standard deviation makes sense if you turn back to the original data and consider the large difference between the highest number, 24, and the next highest, 7. If we change 24 to 12, reducing the variation in the dataset, the standard deviation decreases significantly, to 4.281. </p>
<h3 id="h2--0003">The Number of Times an Email Is Opened</h3>
<p class="BodyFirst"><em>Opens</em> is a relatively minor metric. If you use it in conjunction with clicks and data entry on phishing sites, you can get more useful information, such as a ratio illustrating the rate at which nontechnical employees can identify phishing emails by subject line. Still, clients will often focus on the number of opens by itself. I always try to discourage this. </p>
<p>Emails are meant to be opened, and while some may contain malware, using this metric can prompt users to begin avoiding legitimate emails. Whether the email contains malware should rest on the mail administration and security teams, which should monitor inbound emails for attachments. While users should commit to doing their part to maintain an organization’s security, a company’s accountant is not an information security or malware expert. If the phishing attacks use realistic subject lines and preview information, how can users tell whether an email is a phish without opening it?</p>
<p>There is a caveat: more advanced adversaries can use browser-side exploitation to collect metadata from browsers, if a user opens an email. These are real threats, but if a company cannot withstand a basic phishing engagement, they would likely lack the maturity to mitigate these more advanced attacks. This illustrates a theme we’ll cover in <span class="xref" itemid="xref_target_Chapter 10">Chapter 10</span>, defense in depth. You shouldn’t rely on solely educating or solely technical controls. Seek to educate, but implement email security tools in addition to malware protection.</p>
<p>Instead of focusing solely on the number of opens, focus on the following useful metrics:</p>
<ol class="none">
<li><span class="RunInHead">Open report distance</span>  The time of the first report minus the time of the first open</li>
<li><span class="RunInHead">Open reporting ratio</span>  The number of times that the email was reported divided by the number of opens</li>
</ol>
<p>The <em>open report distance</em> measures the time between when the first email is opened and the time at which it is reported to the security team. This metric is valuable because it gives a clue about the amount of time that the security team has to prevent the phish from having a large impact. After receiving the report, the security team can look at the email, view the linked website in a sandboxed environment, and then start taking defensive actions. These actions might include working to get the site taken down and <em>sinkholing</em> the link (making changes to internal DNS configurations <span epub:type="pagebreak" id="Page_125" title="125"/>to redirect users to a safe place when they click it). A high open report distance value could indicate that many people opened the email before it was reported, which also provides less time for the security team to act, because of the probability that someone will click a link and not report it, as many people have already demonstrated. </p>
<p>The <em>open reporting ratio</em> measures the users’ engagement in terms of reporting. Of the users who opened the email, how many reported it to the security team? This metric indicates whether a collaborative relationship exists between the users and the security team. It also speaks to the users’ ability to recognize a phishing attempt.</p>
<h3 id="h2--0004">The Number of Clicks</h3>
<p class="BodyFirst">The <em>number of clicks</em> on the email’s link is one of the most influential metrics. Clicks could lead to malware infections, file uploads, or the leaking of sensitive information, such as passwords, via phony forms. Still, while more important than opens, this metric is not the most important one. </p>
<p>Combining clicks with other data, such as the time from the first click to the first report, or measuring the click-to-report and click-to-input information metrics, are far more valuable. That’s because it’s important to understand how well an organization can respond to clicks, and not just whether users would click. </p>
<p>While it’s true that users shouldn’t click these links to begin with, it’s once again the responsibility of the security team to protect them if they do. The mail administration, information security teams, and users should collaborate so that if a link is clicked, the system protects the user. The burden of protecting the organization shouldn’t wholly rest with the untrained, nontechnical user. </p>
<p>Useful metrics that involve clicks include the following:</p>
<ol class="none">
<li><span class="RunInHead">Click report distance</span>  The time of the first report minus the time of the first click</li>
<li><span class="RunInHead">Click reporting ratio</span>  The number of times reported divided by the number of clicks</li>
<li><span class="RunInHead">Input ratio</span>  The number of times information is input (to a form, for example) divided by the number of clicks</li>
<li><span class="RunInHead">Input report ratio</span>  The number of times information is input divided by the number of reports</li>
</ol>
<p>Like the open report distance, the <em>click report distance</em> measures the time between when the first email is clicked and the time at which it is reported to the security team. This metric once again indicates the amount of time that the security team has to mitigate the phish’s impact. Also, like the open reporting ratio, the <em>click reporting ratio</em> measures the engagement of users in terms of reporting. </p>
<p>Consider the discrepancy between click reporting and open reporting. Ideally, having a higher open reporting ratio is more beneficial to the organization, since it provides alerts to the security team earlier and affords a greater opportunity to take action. Ideally, organizations would have a high <span epub:type="pagebreak" id="Page_126" title="126"/>open reporting ratio and a minimal dataset from which to measure click reporting. Having a higher click reporting ratio than open reporting ratio, or equal ratios, indicates that people are opening the emails and then clicking before reporting. </p>
<p>The <em>input ratio</em> measures the number of people, of those who clicked the emailed link, who entered information into the linked website. Similarly, the <em>input report ratio</em> compares the number of times that information was input with the number of times it was reported to the security team. In a perfect world, we’d have an input ratio of 0 (seeing as 0 divided by anything is 0). This would indicate that no one input any information, despite opening the email and clicking a link. </p>
<p>Otherwise, we’d want a high input ratio. This indicates that people are noticing when they make mistakes and are comfortable owning up to it with the security team. It’s better to have a user report clicking a link without fear of punishment than for the user to remain silent while the malicious actions occur. It is easier for security practitioners to defend against something they know exists than to be blindsided by something preventable.</p>
<h3 id="h2--0005">Information Input into Forms</h3>
<p class="BodyFirst">The nature of the information that users input into forms is another of the most critical metrics. Users could input passwords, email addresses, and other sensitive pieces of information into this form, and without a robust Security Operations Center actively monitoring users’ systems, internet activities, and activity from the public internet, the organization could be none the wiser. When reporting this metric, avoid sharing the actual passwords or data collected in the report. If you must share the information, try instead to provide only a list of users who must reset their passwords; also, it is best to do so outside of the formal report.</p>
<p>Useful metrics using input information include the following:</p>
<ol class="none">
<li><span class="RunInHead">Input ratio</span>  The number of times information is input divided by the number of clicks</li>
<li><span class="RunInHead">Input report ratio</span>  The number of times information is input divided by the number of reports</li>
<li><span class="RunInHead">Validity ratio</span>  The number of valid credentials input divided by the number of credentials input </li>
<li><span class="RunInHead"><b>Compromised ratio</b></span>  The number of users with data in Have I Been Pwned who entered information divided by the number of users who entered information</li>
</ol>
<p>Calculating the <em>validity ratio</em> requires you to know the hashes of users’ actual credentials. If the client security team is willing to give you the hashes for its users’ passwords, you could hash the information input into the form by using the same hashing algorithm, and then compare the two hashes to see whether the users input valid information. This could tell you the number of people who put legitimate information into the phishing site versus how many people did not, either through error or trolling. </p>
<p><span epub:type="pagebreak" id="Page_127" title="127"/>If the organization performs phishing engagements on the employees too frequently or ties their performance on such engagements to performance evaluations, employees will sometimes enter false information, or even other employees’ information. While we shouldn’t encourage employees to input anything, teaching them to input false information can benefit the organization in two ways: if the organization defines a standard set of false information (email address, name, phone number, password), the Security Operations Center can monitor for its use, employees can test to see whether the site accepts the false information, and the organization can leverage this information (if leaked) to identify actors attempting to use it to gain unauthorized access. Not confirming the validity of the information can skew the statistical analysis and results for your report, making the organization seem as if it performed worse than they actually did. </p>
<p>Calculating the <em>compromised ratio</em> requires a little OSINT. This metric is useful, however, because it acknowledges the influence of social engineering attacks on user behavior beyond the scope of the one being performed. Using the victims’ work email addresses, see how many are listed in the Have I Been Pwned database (introduced in <span class="xref" itemid="xref_target_Chapter 6">Chapter 6</span>). Compare this to the number of users who input information. If you find users in the database, depending on which breach they were a part of, you may want to incorporate acceptable use for company emails into your awareness program and establish a firm policy on it to prevent future occurrences. Finding employees in the database indicates that they may behave in risky ways online and pose a risk to the organization. </p>
<p>This metric will likely always contain biased information, thus skewing the outcome. Some people will use their work email address for everything and either not get caught or not be breached, hence the skew and bias. People frequently use the same passwords at home and work. Unless you assess all the password breaches the user was in, the numbers will be off. A person’s employer cannot commission inquiry on personal assets without the employees consent in most situations. I am not comfortable asking for such consent, but if you had the employee’s consent to search breach databases for their personal accounts, you could remove most bias from this metric, since you would have the capability to measure their holistic security posture.</p>
<h3 id="h2--0006">Actions Taken by the Victim</h3>
<p class="BodyFirst">Actions taken by the victim can include opening the email, deleting the email, forwarding it to nontechnical or non-security personnel, forwarding it to security, clicking links in the email, inputting information, or reporting it (whether after falling victim or not). It’s critical to understand what the user does after falling victim. Do they report it to management, attempt to cover it up, or do nothing? Including this information in the report will require input from the client, but that information is typically not hard to acquire. In my experience, I received it when I simply asked for it.</p>
<h3 id="h2--0007"><span epub:type="pagebreak" id="Page_128" title="128"/>Detection Time</h3>
<p class="BodyFirst">How long does it take the organization’s security team to discover that a phishing attempt has occurred? Was the organization made aware of it from user reporting, an email app or service, or the SEIM system? The time that it takes to detect the event speaks to the maturity of the organization and its information-security capabilities. The longer the time, and whether detection occurs at all, is indicative of how catastrophic an attack could be.</p>
<p>Depending on whose report you read and the publisher’s motives, <em>dwell time</em> (the amount of time that an attacker can perform actions in an environment without arousing detection or other mitigating measures) varies from days to years. Lower dwell times mean less time for an attacker to get a stronghold in place, create adverse outcomes for the organization, or generate bad publicity.</p>
<p>We’ve discussed useful metrics and comparisons for measuring detection time in the other sections of this chapter, so we won’t repeat them here.</p>
<h3 id="h2--0008">The Timeliness of Corrective Actions</h3>
<p class="BodyFirst">How quickly does the organization perform a corrective action? The quicker, the better. This metric indicates the resilience of the organization’s incident response capabilities. The following measurements can help determine how well an incident response team can react to an incident:</p>
<ol class="none">
<li><span class="RunInHead">Open corrective distance</span>  The time that the corrective action occurs minus the time of the first open</li>
<li><span class="RunInHead">Click corrective distance</span>  The time that the corrective action occurs minus the time of the first click</li>
</ol>
<p>The open and click corrective distances are measurements of the time of the first open or click—depending on which is appropriate, given the context—until a corrective action occurs. <em>Corrective actions</em> include sinkholing the link, blocking the sender, beginning the takedown of the site, and informing users about the attack, among others. These metrics don’t say anything about whether the actions taken were adequate (that is the next metric). Once again, they’re concerned about the organization’s response time. Taking the correct actions is important, but the actions mean nothing if they aren’t done in a timely manner.</p>
<h3 id="h2--0009">The Success of Corrective Actions</h3>
<p class="BodyFirst">Just as critical as the timeliness of corrective actions is the success of such efforts. If the steps stop the attack, perfect. In some instances, though, corrective action can enhance the attack and make it work to the attacker’s advantage.</p>
<p>In one of my engagements, I was blocked after sending about 50 percent of my emails. I was sending them in batches of 7 to 15 people at a time. Only about 20 percent of the recipients had clicked my link, and only 6 percent had input any information. I thought I was toast.</p>
<p><span epub:type="pagebreak" id="Page_129" title="129"/>The next morning, I logged in to my system to see that 42 percent of the organization had input information; some people had even done so twice or more. Why did this happen? The network administrator who blocked me had forwarded the email to the whole organization without blocking or sinkholing the link in the email. They’d created a <em>Streisand effect</em> of sorts; by attempting to warn people about the email, they’d exposed more people to it, and curiosity killed the cats.</p>
<h3 id="h2--0010">Risk Ratings</h3>
<p class="BodyFirst">Quantifying risk is not easy, but it’s important to do, because the report you submit to your client should organize your findings based on severity. Various methodologies can be used for rating and quantifying risk, both qualitatively (using subjective labels such as Critical, High, Medium, Low, and Informational) and quantitatively (such as on a scale from 0–10). The OWASP Risk Rating Methodology and the Common Vulnerability Scoring System (CVSS) are two such methodologies. </p>
<p>Unless your employer or client wants a quantitative risk scoring, I recommend sticking with qualitative. Attempting to perform quantitative analysis requires all data points to be in numerical format, and performing translations for some data points creates more complexity and complications than necessary. Most of our metrics are quantitative in nature, but we cannot easily translate actions to numeric values. For example, forwarding an email is not related to deleting an email. If we assign a numeric value to those tasks, we imply the existence of a relationship between them, which doesn’t exist. When determining the severity of risk, consider the likelihood and impact of the incident, and then balance these two factors to get a single rating. </p>
<p>Next, define what should count as Critical, High, Medium, Low, and Informational. The following are boilerplate definitions that you can use in your report as you see fit:</p>
<p class="ListHead"><b>Critical</b></p>
<ol class="none">
<li>These are the risks that could cause catastrophic harm, extended downtimes, or an end to all operations. They are immediately and rather easily exploitable. These are often public facing and have significant impacts to an organization’s ability to do business. They may also threaten human life. In the case of information security, this could also include a breach of regulated or sensitive data, such as personally identifiable information (PII) or protected health information (PHI), which is what occurred in the Equifax, US Office of Personnel Management (OPM), or other breaches of the same magnitude. </li>
</ol>
<p class="ListHead"><b>High</b></p>
<ol class="none">
<li>These risks could cause costly or serious downtime, harm, or disruption to operations. The barrier to entry for exploitation and impact is low. They have a high impact and could involve sensitive data or regulated data, though in lesser amounts than the Critical risks.</li>
</ol>
<p class="ListHead"><b><span epub:type="pagebreak" id="Page_130" title="130"/>Medium</b></p>
<ol class="none">
<li>These items could cause disruption or issues within the client organization, but no major downtime. They could involve gaining access to systems that could be used to pivot to other systems or facilities. These could involve nonpublic data that isn’t particularly sensitive.</li>
</ol>
<p class="ListHead"><b>Low</b></p>
<ol class="none">
<li>These items pose little risk to the client. They could have fringe-case dependencies, like local physical access, or require another exploitation vector to have already been accomplished. These risks involve minimal disruption if successful.</li>
</ol>
<p class="ListHead"><b>Informational</b></p>
<ol class="none">
<li>These pose no current risk but do not adhere to best practices or may become risky later.</li>
</ol>
<h2 id="h1--0003">Reporting</h2>
<p class="BodyFirst">This section will guide you through writing the deliverable report for your client. While not as exciting as the engagement itself, the report is what the clients pay you the big bucks to receive. That said, making it useful is a challenge. The truth is that some customers will read the report carefully, while others will file it away for compliance purposes without glancing at it. If people do not read the report, how can they correct the findings? This section answers that question by looking at two angles: the deliverable report that the client should read and the situations that warrant that you stop what you’re doing and call the client. </p>
<h3 id="h2--0011">Knowing When to Make a Phone Call</h3>
<p class="BodyFirst">The report isn’t your only tool for communicating with your client. Call the client anytime human life or critical computing resources are endangered. For instance, if you discover a malicious actor in the client network or other unsavory condition that may be time sensitive, alert the client immediately. </p>
<p>For everything else involved with the engagement and associated activities, feel free to provide brief and incremental updates via email or phone, but be sure to clarify that none of the information in these informal communications is official. Failure to do so could land you in court if an update you provide contradicts the information in your report. The report should be the main, and ideally only, official communication between you and the client after the sales process is complete.</p>
<h3 id="h2--0012">Writing the Report</h3>
<p class="BodyFirst">I advise you to write the report as you go along so you don’t miss details or have to dig through notes to cover everything. Borrowing some philosophy from Chris Sanders, author of <em>Practical Packet Analysis</em> (No Starch Press, <span epub:type="pagebreak" id="Page_131" title="131"/>2017), your report should be clear and concise, but it should also tell a story. Using storytelling, you can engage readers more effectively to encourage—maybe even social-engineer them—into reading the report in its entirety. </p>
<p>What do I mean by <em>storytelling</em>? Explain the steps you took and why they were important. Make it sound like you were acting like a real malicious actor. Talk about what you saw, your analysis, and the outcomes. To help you engage readers, use active voice instead of passive voice. For example, <em>the consultants successfully enumerated the website</em> is active voice. <em>Enumeration of the website was determined to be possible </em>is passive voice.</p>
<p>Depending on whether you are self-employed or working for a firm, this time may run at a lesser billable rate than the engagement itself, or it may be non-billable. Don’t use all of the allotted time for the sake of using it. Use only what you need to. This time should also account for document reviews (such as by editors, legal teams, or quality assurance).</p>
<h4 id="h3--0001">Structuring the Report</h4>
<p class="BodyFirst">To begin, get your template of choice—your employer’s, one from <span class="xref" itemid="xref_target_Appendix B">Appendix B</span>, one from the internet, or one you make from scratch. For the purposes of this chapter, we’ll walk through the template found on <span class="xref" itemid="xref_target_page 187">page 187</span>. </p>
<p>In the background section, explain the parameters limiting the testing and the reasons that the testing was performed. Include the verbiage of the engagement’s defined scope and statement of work in this section so that you clearly specify the rules you were provided and the parameters you were expected to operate within. This section should be no longer than a page, ideally only a paragraph or two.</p>
<p>Next comes the executive summary, or in modern internet lingo, the <em>too long; didn’t read</em> <em>(TL;DR)</em> portion of the report. Use this section to give a high-level overview of what you did, what you found, and how you assess it. You may add general remediation advice as well. Don’t get into the weeds here, as you should assume that the audience for this section is nontechnical and wants little more than the elevator pitch.</p>
<p>After the executive summary, include a section outlining your major findings. This is where you should define the top issues that should concern the client. Using a risk ratings system, like the one described in <span class="xref" itemid="xref_target_“Risk Ratings” on page 129">“Risk Ratings” on page 129</span>, determine which findings deserve a Critical or High-Risk rating, and include only those. (All other findings belong in a generic “Findings” section later in the document.) For each serious finding, explain what the finding is, how it can be exploited, what the potential outcomes are, how to test for it independently, and how to remediate it.<em> </em>Do your best to convey the severity of these findings to your audience. When talking to executives, I have found it useful to describe a risk by outlining specific negative consequences, such as ending up on the front page of the <em>New York Times</em> or in court, being accused of negligence. Specific details like these can help get the attention of executives.</p>
<p>The next section should detail the OSINT you found. For each piece of information, include the output from the tool you used or a screenshot of the information to serve as evidence. If the data is available on the public <span epub:type="pagebreak" id="Page_132" title="132"/>internet, you could also provide a link. Without the output, screenshots, or links, clients have no way to validate that the information you are providing is factual. </p>
<p>If your screenshots include sensitive, incriminating, or other damning information, you may consider encrypting the document while sending it to the client. I’ve also worked with clients who would not accept any reports digitally. They required the report to be mailed, to avoid e-discovery if anything associated with the report ends up in court. While you don’t need to label risks in this section, because if they are significant enough to be considered a finding, they will be listed and labeled in the findings section, put Critical- and High-level risks in a bold font to draw attention to them. </p>
<p>After the OSINT section comes the social engineering section, which describes your actual engagement. If you performed multiple kinds of social engineering, use subheadings to break up this section into each type of engagement: phishing, vishing, and onsite testing. If you are doing a hybrid engagement, meaning that your phishing and vishing are tied together, put them under a “Hybrid” subsection. Within each subsection, explain each pretext used. Discuss what you did and the outcomes. Then use the metrics described in <span class="xref" itemid="xref_target_“Measurement” on page 122">“Measurement” on page 122</span> to help explain the impact of the outcomes. If you’ve previously worked with the client, you may also compare the findings from this engagement to the previous engagement so that the client can see their progress. </p>
<p>Input the entirety of your findings in the next section. This is the place to be verbose. Explain the issue, how you found it, artifacts of you finding it, references explaining why it is a problem, how to fully remediate it, and possible mitigations if full remediation is not an option. This section will reiterate content in the executive summary and findings sections. This is where you cohesively explain, in paragraph format (though occasional lists may be useful for distilling information) how to fix the issues you uncovered. Then finish with the remediation and recommendations section. Advocate for training, technical solutions, or other cultural changes. Part 3 of this book discusses such protections. </p>
<p>Keep in mind that you are merely recommending. You have no authority to demand any changes, and the client may or may not fix the problem. While you may feel a sense of ownership of the project, it’s ultimately not your problem if they choose not to heed your advice. </p>
<h4 id="h3--0002">Ensuring Verbosity and Accuracy </h4>
<p class="BodyFirst">I recommend having multiple people, under nondisclosure agreements (NDAs), review the report before you deliver it to clients. One person should review all the technical aspects of the report for accuracy, while someone else should review it for grammar, mechanics, and prose. Your reviewers should also assess the verbosity of the report to ensure that it is detailed enough to convey the points appropriately, but not overly wordy. As Frances Saux, the editor of this book, can attest, this is something I struggle with. Many social engineers do. And as my publisher Bill Pollock pointed <span epub:type="pagebreak" id="Page_133" title="133"/>out, social engineers rely on their ability to talk as a point of strength. When working with nontechnical, non-security people, this strength becomes a flaw.</p>
<h2 id="h1--0004">Conclusion</h2>
<p class="BodyFirst">Reporting isn’t the most fun aspect of social engineering or OSINT collection, but it is one of the most important aspects. Do your best to convey to management not only what you performed but also how the employees fared against you, along with actionable advice to improve. </p>
<p>The metrics you measure and the way you measure them will influence your client’s decision-making processes and the overall success of their business. Providing poorly explained or skewed data can embarrass the client, or worse, find them in legal trouble and you with one (or more) fewer clients.</p>
<p>Keep in mind that your report is usually the only thing your client’s management team sees from your engagement. They won’t see how great you were at phishing or vishing, and even if they did, they likely wouldn’t be as impressed by it as your peers in the security industry. What will impress them is a professional report, written in terms that they can understand, with advice that they can implement.</p>
<p/>
</section>
</body>
</html>